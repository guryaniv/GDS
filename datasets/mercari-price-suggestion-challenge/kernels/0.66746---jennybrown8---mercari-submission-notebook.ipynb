{"cells": [{"metadata": {"scrolled": true, "_uuid": "a74c573c40b41ce11abfeee5225df16c46ef07b5", "_cell_guid": "9d8f6bc5-fff3-4e73-afb9-8e8b94234f8a"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"collapsed": true, "_uuid": "667acb994cfd4290a9ee33707ff8de150583dba2", "_cell_guid": "99404083-e498-4c2e-8681-90cc3c513fc4"}, "source": ["import lzma\n", "import os\n", "from scipy import stats, integrate\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import csv\n", "\n", "from sklearn import datasets, linear_model\n", "from sklearn.metrics import mean_squared_error, r2_score\n", "\n", "\n", "pd.options.display.float_format = '{:.0f}'.format"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {"collapsed": true, "_uuid": "08e2ffb1066cb6cbdacbc3636308fd12059b6172", "_cell_guid": "be82be7c-9b82-430a-bb85-45aa900c0bb8"}, "source": ["df_train = pd.read_csv('../input/train.tsv', delimiter='\\t')\n", "df_test = pd.read_csv('../input/test.tsv', delimiter='\\t')\n", "\n", "# These don't help us train. Nor do they make any sense.\n", "df_train.drop(df_train[df_train['price'] == 0].index, inplace=True)"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"collapsed": true, "_uuid": "13915adb1a53893cb21d90cd1450549ce1a8b9ba", "_cell_guid": "d6ca7dc3-1efa-4cf2-b69c-6877d75e41d2"}, "source": ["# We might need to filter out price=0 lines as weird outliers.\n", "# Replace the brand name NaN with 'Unknown' or some real string.\n", "# We want to split category names on the slash, into separate columns, and provide min/max/median for each of those.\n", "# We want to add columns for length of item description and length of item name.\n", "# Eventually pick up words like 'guarantee' or 'authentic*' or 'lot' or 'brand new' or 'tags' or something,\n", "# but first train a model on purely the numeric information.  We'll come back to these.\n", "# We want to augment brand name columns and category columns for min/max/median.\n"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"collapsed": true, "_uuid": "69ed7a4656e72ab0247c28fb6dbbf678ad97b82d", "_cell_guid": "dbff8796-ef61-4356-8cb8-d7dd1ab18e22"}, "source": ["def clean_df(df):\n", "    # Clean up missing attributes\n", "    df['brand_name']=df['brand_name'].fillna('Unknown')\n", "    df['category_name']=df['category_name'].fillna('Unknown/Unknown/Unknown')\n", "    df['item_description']=df['item_description'].fillna('Unknown')\n", "    df['item_condition_id']=df['item_condition_id'].fillna(3)\n", "\n", "    # Handle category split, and count lengths of name/desc\n", "    df[['category1', 'category2', 'category3']] = df['category_name'].str.split('/', 2, expand=True)\n", "    df['category12'] = df['category1'].astype(str)+'_'+df['category2'].astype(str)\n", "    # category123 just = the original category name column.\n", "\n", "    df['name_length'] = df['name'].str.len()\n", "    df['item_description_length'] = df['item_description'].str.len()\n", "\n", "    # Throw in a couple word indicators for the fun of it\n", "    df['word_brand_new'] = df['item_description'].str.lower().str.contains('brand new')\n", "    df['word_brand_new'] = df['word_brand_new'].astype(int)\n", "    df['word_tag'] = df['item_description'].str.lower().str.contains('tag').astype(int)\n", "    df['word_tag'] = df['word_tag'].astype(int)\n", "    # TODO: Use unicodedata.normalize(\"NFKD\", text.casefold()) eventually instead of .lower() ?\n", "\n", "    return df\n", "    \n", "df_train = clean_df(df_train)\n", "df_test = clean_df(df_test)\n", "\n"], "cell_type": "code", "outputs": [], "execution_count": 5}, {"metadata": {"collapsed": true, "_uuid": "f7680dac74f9c3c21718cdc4e91983d9c3942754", "_cell_guid": "fa5144dc-de3e-4811-bb13-6c2e5171c6cc"}, "source": ["# From a grouped name/price aggregation, extracts the kv pairs to a dict for fast lookups.\n", "def create_pricedict(grouped, operation_name, orig_colname):\n", "    pricedict = {}\n", "    for index, row in grouped.iterrows():\n", "        pricedict[row[orig_colname]] = row['price']\n", "    return {orig_colname + \"_\" + operation_name: pricedict}\n", "\n", "\n", "# This training knowledge creates reusable lookups, let's hold on to it for reuse later as pricedicts!\n", "pricedicts = {}    \n", "for col in ['brand_name', 'category1', 'category12', 'category_name']:\n", "    pricedicts.update(create_pricedict(df_train.groupby(col, as_index=False).min(), 'min', col))\n", "    pricedicts.update(create_pricedict(df_train.groupby(col, as_index=False).median(), 'median', col))\n", "    pricedicts.update(create_pricedict(df_train.groupby(col, as_index=False).mean(), 'mean', col))\n", "    pricedicts.update(create_pricedict(df_train.groupby(col, as_index=False).max(), 'max', col))"], "cell_type": "code", "outputs": [], "execution_count": 6}, {"metadata": {"collapsed": true, "_uuid": "ac3a9c0bf5f2fa5c06c18f64f1e242c70aab6a29", "_cell_guid": "3f83303c-8d57-4a7d-a7a4-3b7e1a60d992"}, "source": ["# Now we add the features to the chosen df; this is the real work done on each df.\n", "def price_augment_df(df, pricedicts):\n", "    for col in ['brand_name', 'category1', 'category12', 'category_name']:\n", "        for oper in ['_min', '_median', '_mean', '_max']:\n", "            df[col + oper] = df[col].map(pricedicts[col + oper])\n", "            df[col + oper] = df[col + oper].fillna(pricedicts[col + oper].get('Unknown', 5))\n", "\n", "price_augment_df(df_train, pricedicts)\n", "price_augment_df(df_test, pricedicts)\n"], "cell_type": "code", "outputs": [], "execution_count": 7}, {"metadata": {"collapsed": true, "_uuid": "487ab86ebf4fb2cb4129f26a17aeaec87eba9191", "_cell_guid": "c866e137-c873-4c4e-ba9f-3c8449154fed"}, "source": ["xs = ['item_condition_id', 'shipping', \n", "      'brand_name_min', 'brand_name_max', 'brand_name_median', 'brand_name_mean', \n", "      'category_name_min', 'category_name_max', 'category_name_median', 'category_name_mean', 'word_brand_new', 'word_tag']\n", "\n", "df_train_xs = df_train[xs]\n", "df_train_y = df_train[['price']]\n", "\n", "df_test_xs  = df_test[xs]\n"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {"_uuid": "a97f7269dc5d675bd15faf9ec194a1b4164dafa6", "_cell_guid": "d5cf6f3d-96d1-45c4-b844-714b158b66eb"}, "source": ["# Create linear regression object\n", "regr = linear_model.LinearRegression()\n", "\n", "# Train the model using the training sets\n", "regr.fit(df_train_xs, df_train_y)\n", "\n", "# Make predictions using the testing set\n", "df_test['price'] = regr.predict(df_test_xs)\n", "\n", "# Negative prices throw an error, so fix them for now.\n", "df_test.loc[df_test.price < 0, 'price'] = 0\n", "\n", "# The coefficients\n", "print('Coefficients: \\n', regr.coef_)\n", "\n", "# The mean squared error\n", "#print(\"Mean squared error: %.2f\" % mean_squared_error(df_test_y, y_pred))\n", "# Explained variance score: 1 is perfect prediction\n", "# print('Variance score: %.2f' % r2_score(df_test_y, y_pred))\n"], "cell_type": "code", "outputs": [], "execution_count": 9}, {"metadata": {"collapsed": true, "_uuid": "77a9ae3e61e6c8e3efff364f32908e03d41c5c94", "_cell_guid": "e08cb627-e195-40a3-8834-c9fc9bfa06be"}, "source": ["submissiondf = df_test[['test_id', 'price']]\n", "submissiondf.to_csv('sample_submission.csv', index=False)"], "cell_type": "code", "outputs": [], "execution_count": 10}, {"metadata": {"collapsed": true, "_uuid": "ac7304fda6b9c43d2caa1d9a2020102bf7ae3130", "_cell_guid": "07e8d977-7ca6-4b71-b80e-cb77b028a798"}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}], "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4}