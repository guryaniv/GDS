{"cells":[{"metadata":{"_cell_guid":"11ace83d-045b-40fb-ad6b-6f726751258e","_uuid":"3d921bb9d5cf116ae12d19660f522a556f31cbac","collapsed":true,"trusted":true},"cell_type":"code","source":"#-*- coding:utf-8 -*-\n\nimport os\nimport re\nimport csv\nimport subprocess\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model\nfrom sklearn.model_selection import cross_val_score\n\nVERSION = '12'\n\n# NOTE:\n# BASE_DIR is ../input in kaggle competition\nBASE_DIR = '../input'\nTRAIN_DATA_LIMIT = 30000\n\nMAX_BUFFER = 10000\n\n\ndef info(message):\n    def _func(func):\n        def wrapper(*args):\n            print(\"[INFO] %s\" % message)\n            ret = func(*args)\n            print(\"[INFO] Done!\")\n            return ret\n        return wrapper\n    return _func\n\n\nclass Model():\n    def __init__(self):\n        self.lookup = {\n            'name': {},\n            'category_name': {},\n            'brand_name': {},\n        }\n\n    @info('loading train data into database...')\n    def load_train_data(self):\n        data = []\n        n_lack_data = 0\n\n        path = os.path.join(BASE_DIR, 'train.tsv')\n        with open(path) as file:\n            reader = csv.reader(file, delimiter=\"\\t\")\n\n            # skip header\n            next(reader, None)\n\n            for row in reader:\n                if len(row) == 8:\n                    data.append([\n                        # id\n                        int(row[0]),\n\n                        # name\n                        row[1],\n\n                        # item_condition_id\n                        # int(row[2]),\n\n                        # category_name\n                        row[3],\n\n                        # brand_name\n                        row[4],\n\n                        # price\n                        float(row[5]),\n\n                        # shipping\n                        # int(row[6]),\n\n                        # item_description\n                        # row[7]\n                    ])\n\n                    # prepare lookup table\n                    # for name\n                    # words = re.split('\\s', row[1])\n                    # for word in words:\n                    #     if not word is None and word != \"\" and word not in self.lookup['name']:\n                    #         self.lookup['name'][word] = len(self.lookup['name'])\n\n                    # for category name\n                    words = re.split('\\s', row[3])\n                    for word in words:\n                        if not word is None and word != \"\" and word not in self.lookup['category_name']:\n                            self.lookup['category_name'][word] = len(self.lookup['category_name'])\n\n                    # for brand name\n                    words = re.split('\\s', row[4])\n                    for word in words:\n                        if not word is None and word != \"\" and word not in self.lookup['brand_name']:\n                            self.lookup['brand_name'][word] = len(self.lookup['brand_name'])\n\n                    if len(data) >= TRAIN_DATA_LIMIT:\n                        return data\n\n                else:\n                    n_lack_data += 1\n\n        print(\"%d lack data found.\" % n_lack_data)\n\n        return data\n\n    def _vectorize(self, key, value):\n        \"\"\"\n          returns np.array\n        \"\"\"\n        if not key in self.lookup:\n            raise NameError(key)\n\n        words = re.split('\\s', value)\n        x = np.zeros(len(self.lookup[key]))\n        for word in words:\n            if not word is None and word != \"\" and word in self.lookup[key]:\n                idx = self.lookup[key][word]\n                x[idx] += 1\n        return x\n\n    @info('preparing data...')\n    def prepare_data(self, data):\n        \"\"\"\n          returns x and y, which are indicator variable and target\n        \"\"\"\n\n        x = []\n        y = []\n        for row in data:\n            # fv_name = self._vectorize('name', row[1])\n            fv_brand = self._vectorize('brand_name', row[2])\n            fv_category = self._vectorize('category_name', row[3])\n            fv = np.concatenate((fv_brand, fv_category))\n            x.append(fv)\n            y.append(row[4]) # price\n\n        return (x, y)\n\n    @info('training model...')\n    def train(self, x, y):\n        self.reg = linear_model.SGDRegressor(max_iter=100)\n        self.reg.fit(x, y)\n\n    @info('predict from file...')\n    def predict_from_file(self, path):\n        with open(path, \"r\") as file:\n            reader = csv.reader(file, delimiter=\"\\t\")\n\n            # skip header\n            next(reader, None)\n\n            ids = []\n            pred = []\n            buffer = []\n            n_data = 0\n            for row in reader:\n                # number of data\n                n_data += 1\n\n                if len(buffer) < MAX_BUFFER:\n                    ids.append(row[0])\n                    buffer.append(\n                        np.concatenate((\n                            self._vectorize('brand_name', row[3]),\n                            self._vectorize('category_name', row[4]),\n                        ))\n                    )\n\n                else:\n                    pred += self.reg.predict(buffer).tolist()\n\n                    ids.append(row[0])\n                    buffer = [\n                        np.concatenate((\n                            self._vectorize('brand_name', row[3]),\n                            self._vectorize('category_name', row[4]),\n                        ))\n                    ]\n\n            # out of tsv read loop\n            if len(buffer) > 0:\n                ids += [x[0] for x in buffer]\n                pred += self.reg.predict(buffer).tolist()\n\n            return pd.DataFrame([ids[0:n_data], pred[0:n_data]]).T\n\n    @info('training model and validating...')\n    def train_and_validation(self, x, y):\n        reg = linear_model.SGDRegressor(max_iter=100)\n        scores = cross_val_score(reg, x, y, cv=5)\n        print(scores)\n\n\ndef main():\n    model = Model()\n\n    if not os.path.exists(os.path.join(BASE_DIR, 'train.tsv')):\n        train_7z_file_path = os.path.join(BASE_DIR, 'train.tsv.7z')\n        subprocess.call(['7z', 'e', train_7z_file_path, '-y', '-o' + BASE_DIR + ''])\n\n    if not os.path.exists(os.path.join(BASE_DIR, 'test.tsv')):\n        test_7z_file_path = os.path.join(BASE_DIR, 'test.tsv.7z')\n        subprocess.call(['7z', 'e', test_7z_file_path, '-y', '-o' + BASE_DIR + ''])\n\n    # train\n    train_data = model.load_train_data()\n    x_train, y_train = model.prepare_data(train_data)\n    model.train(x_train, y_train)\n\n    # free memory for variables used in training phase\n    del train_data\n    del x_train\n    del y_train\n\n    frame = model.predict_from_file(os.path.join(BASE_DIR, 'test.tsv'))\n    frame.columns = ['test_id', 'price']\n    frame.to_csv('submission_v' + VERSION + '.csv', index=False)\n\nif __name__ == '__main__':\n    main()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}