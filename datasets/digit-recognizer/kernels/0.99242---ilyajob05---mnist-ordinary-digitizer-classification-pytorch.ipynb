{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import tensor\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lrSheduler\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable\n\nimport pandas as pd\nimport torch as th\n%matplotlib notebook\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# load database \n\ndataRawTrain = pd.read_csv('../input/train.csv')\ndataRawTest = pd.read_csv('../input/test.csv')\n\ndataTrain = np.array(dataRawTrain.iloc[:,1:]).astype('uint8')\ndataTrain = dataTrain.reshape(-1, 1, 28, 28)\n\ntargetTrain = np.array(dataRawTrain.iloc[:,:1])\nzz = np.zeros([len(targetTrain), 10])\nfor i, d in enumerate(targetTrain):\n    zz[i][d.squeeze()] = 0.66\ntargetTrain = zz\n\ndataTest = np.array(dataRawTest.iloc[:,:]).astype('uint8')\ndataTest = dataTest.reshape(-1, 1, 28, 28)\n\nfor i in range(1):\n    plt.matshow(dataTrain[i][0], cmap='rainbow')\n    plt.suptitle('class: {}'.format(targetTrain[i]))\n\nfor i in range(1):    \n    plt.matshow(dataTest[i][0], cmap='rainbow')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35dde8988be8cf6ac352096797f4e8af78157aaf"},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader, TensorDataset\nfrom torchvision import transforms\n\ndataTrainT = torch.from_numpy(dataTrain).float() / 255.0 - 0.5\ntargetTrainT = torch.from_numpy(targetTrain).float()\n\ndataTestT = torch.from_numpy(dataTest).float() / 255.0 - 0.5\n\n\ndef processImgTrain(batch):\n    outBatchData = []\n    outBatchTarget = []\n    for i, (img, target) in enumerate(batch):\n        outBatchData.append(img)\n        outBatchTarget.append(target)\n    outTensorData = th.stack(outBatchData)\n    outTensorTarget = th.stack(outBatchTarget)\n    return [outTensorData, outTensorTarget]\n\ndef scaleImgTest(batch):\n    outBatchData = []\n    outBatchTarget = []\n    for i, (img, target) in enumerate(batch):\n        outBatchData.append(img)\n        outBatchTarget.append(target)\n    outTensorData = th.stack(outBatchData)\n    outTensorTarget = th.stack(outBatchTarget)\n    return [outTensorData, outTensorTarget]\n\ndataTrainArch = TensorDataset(dataTrainT[:-2000], targetTrainT[:-2000])\nloaderTrain = DataLoader(dataTrainArch, shuffle=True, batch_size=64, pin_memory=True, collate_fn=processImgTrain)\n\nprint('train data size: {}'.format(dataTrainT[:-2000].shape))\nprint('test data size: {}'.format(dataTrainT[-2000:].shape))\n\ntestDBD = dataTestT[-2000:].clone()\ntestDBT = targetTrainT[-2000:].clone()\n\ndataTestArch = TensorDataset(dataTrainT[-2000:], targetTrainT[-2000:])\nloaderTest = DataLoader(dataTestArch, shuffle=True, batch_size=1000, pin_memory=True, collate_fn=scaleImgTest)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33f1d506a846990b7540249f649b368945530639"},"cell_type":"code","source":"\nclass NetMNIST2(nn.Module):\n    flag = False\n\n    def __init__(self):\n        super(NetMNIST2, self).__init__()\n\n        # First convolution\n        self.conv0 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1, bias=True)\n        self.relu0 = nn.PReLU()\n        self.pool0 = nn.MaxPool2d(2)\n        self.drop0 = nn.Dropout2d()\n\n        self.conv1p = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu1p = nn.PReLU()\n        self.drop1p = nn.Dropout2d()\n\n        self.conv1 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=True)\n        self.relu1 = nn.PReLU()\n        self.pool1 = nn.MaxPool2d(2)\n        self.drop1 = nn.Dropout2d()\n\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False)\n        self.relu2 = nn.PReLU()\n        self.pool2 = nn.MaxPool2d(2)\n        self.drop2 = nn.Dropout2d()\n\n        self.fc1 = nn.Linear(32 * 6 * 6, 10)\n        self.fc1Prelu = nn.PReLU()\n        self.fc2 = nn.Linear(10, 10)\n\n\n    def forward(self, x):\n        x = self.conv0(x)\n        x = self.relu0(x)\n        x = self.pool0(x)\n        x = self.drop0(x)\n\n        x = self.conv1p(x)\n        x = self.relu1p(x)\n        x = self.drop1p(x)\n\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n        x = self.drop1(x)\n\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.pool2(x)\n        x = self.drop2(x)\n\n        x = x.view(-1, 128*3*3)\n        x = self.fc1(x)\n        x = self.fc1Prelu(x)\n        x = torch.nn.functional.dropout(x)\n        x = self.fc2(x)\n        x = F.softmax(x, dim=1)\n        return x\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8884674591f7a5fb2da8bb287b6593e9adf74725"},"cell_type":"code","source":"\nuse_cuda = True\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nnet = NetMNIST2().to(device)\nprint(net)\noptimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-5)\ncriterion = F.mse_loss\n\ndef trainEpoch(e):\n    net.train()\n    for i, (data, target) in enumerate(loaderTrain):\n        dataCUDA, targetCUDA = Variable(data).to(device), Variable(target.float()).to(device)\n\n        optimizer.zero_grad()\n        outModel = net(dataCUDA)\n\n        loss = F.mse_loss(outModel, targetCUDA)\n        loss.backward()\n        optimizer.step()\n    return loss\n\n\ndef testLoss():\n    net.eval()\n    fit = 0.0\n\n    for i, (data, target) in enumerate(loaderTest):\n        dataCUDA, targetCUDA = Variable(data).to(device), Variable(target.float()).to(device)\n        outModel = net(dataCUDA)\n        pred = outModel.data.max(1)[1]\n        targetMaxIndex = targetCUDA.data.max(1)[1]\n        fit += pred.eq(targetMaxIndex).cpu().sum()\n    acc = float(fit.cpu()) / float(len(loaderTest.dataset))\n    return acc\n\nlossProgress = []\nfor e in range(5):\n    lossTrain = trainEpoch(e)\n    accTest = testLoss()\n    lossProgress.append(accTest)\n    print('Test epoch: {}   acc: {}'.format(e, accTest))\n    print('Train epoch: {}   loss: {}'.format(e, lossTrain))\n\nplt.plot(lossProgress)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ed96e49fe505a4c63da7ba6b7b95bb8ae1c729a","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"packSize = 10\ninputLen = dataTestT.size(0)\nindexInput = np.arange(1, inputLen + 1)\nresult = np.zeros([inputLen],dtype=int)\nprint(inputLen / packSize)\nfor i in range(int(inputLen / packSize)):\n    dataCUDA = Variable(dataTestT[i * packSize:i*packSize+packSize].cuda()) #add one axis\n    outModel = net(dataCUDA)\n    result[i * packSize:i*packSize+packSize] = outModel.data.max(1)[1].cpu().numpy().squeeze()\n\nresult=pd.DataFrame({'ImageId':indexInput, 'Label':result})\nresult.to_csv(\"submission.csv\",index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}