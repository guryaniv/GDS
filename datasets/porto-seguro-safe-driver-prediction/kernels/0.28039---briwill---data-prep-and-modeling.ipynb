{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}}, "nbformat_minor": 1, "cells": [{"cell_type": "code", "metadata": {"_uuid": "3903b539642b92fe50955591d41cb0bedee7165c", "_cell_guid": "90363b4f-3d45-49d6-970f-c4ca98dd89ec", "collapsed": true}, "outputs": [], "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import time\n", "\n", "#This keeps the \"middle\" columns from being omitted when wide dataframes are being displayed\n", "pd.options.display.max_columns = None\n", "\n", "train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')\n", "\n", "potential_features = ['ps_ind_06_bin',\n", "                      'ps_ind_07_bin',\n", "                      'ps_ind_08_bin',\n", "                      'ps_ind_16_bin',\n", "                      'ps_ind_17_bin',\n", "                      'ps_car_08_cat',\n", "                      'ps_ind_04_cat',\n", "                      'ps_car_03_cat',\n", "                      'ps_car_11_cat',\n", "                      'ps_car_09_cat',\n", "                      'ps_car_06_cat',\n", "                      'ps_ind_05_cat',\n", "                      'ps_car_05_cat',\n", "                      'ps_car_04_cat',\n", "                      'ps_car_01_cat',\n", "                      'ps_car_02_cat',\n", "                      'ps_ind_02_cat',\n", "                      'ps_car_07_cat',\n", "                      'ps_car_13',\n", "                      'ps_car_12',\n", "                      'ps_reg_02',\n", "                      'ps_reg_03',\n", "                      'ps_car_15',\n", "                      'ps_reg_01',\n", "                      'ps_ind_15',\n", "                      'ps_ind_01',\n", "                      'ps_car_14',\n", "                      'ps_ind_03',\n", "                      'ps_ind_14']\n", "\n", "train_df = train_df[['target'] + potential_features]\n", "\n", "#save test id's for later\n", "test_ids = test_df['id']\n", "test_df = test_df[potential_features]"], "execution_count": 1}, {"cell_type": "code", "metadata": {"_uuid": "f939b1a31069ce2709b8746d77e09d2a5058f354", "_cell_guid": "5bd3c82c-95f2-4b7e-8934-b988f04c07bf", "collapsed": true}, "outputs": [], "source": ["# Compute gini\n", "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n", "from numba import jit\n", "@jit\n", "def eval_gini(y_true, y_prob):\n", "    y_true = np.asarray(y_true)\n", "    y_true = y_true[np.argsort(y_prob)]\n", "    ntrue = 0\n", "    gini = 0\n", "    delta = 0\n", "    n = len(y_true)\n", "    for i in range(n-1, -1, -1):\n", "        y_i = y_true[i]\n", "        ntrue += y_i\n", "        gini += y_i * delta\n", "        delta += 1 - y_i\n", "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n", "    return gini"], "execution_count": 2}, {"cell_type": "code", "metadata": {"_uuid": "8be9e69947c3afdede00a8e1952550bd43ca4beb", "_cell_guid": "85ca7226-0e33-4bc0-8b3e-53b19bb02509"}, "outputs": [], "source": ["#Balancing: Oversample positive class...add randomly sampled positive class by a factor of over_factor\n", "over_factor = 0.6\n", "row_count = round(len(train_df[train_df['target'] == 1]) * over_factor)\n", "new_rows = train_df[train_df['target'] == 1].sample(row_count, replace=True, random_state=1)\n", "\n", "train_df = train_df.append(new_rows, ignore_index=True)\n", "train_df['target'].value_counts(1)"], "execution_count": 3}, {"cell_type": "code", "metadata": {"_uuid": "96954e0be0a8eabe369f0573273785136cf45565", "_cell_guid": "c74a2069-6fa9-4f13-9986-572adfba548c"}, "outputs": [], "source": ["#Find columns with missing data\n", "train_miss = []\n", "test_miss = []\n", "print(\"train columns with missing data: \")\n", "for col in train_df.columns:\n", "    if (train_df[col].min() == -1) and ('cat' not in col):\n", "        train_miss.append(col)\n", "        print (col)\n", "\n", "print(\"\\ntest columns with missing data: \")\n", "for col in test_df.columns:\n", "    if (test_df[col].min() == -1) and ('cat' not in col):\n", "        test_miss.append(col)\n", "        print (col)"], "execution_count": 4}, {"cell_type": "code", "metadata": {"_uuid": "e122ffa4dae9b72c32a7c953bf6a028b304d8d4a", "_cell_guid": "115c9845-34c0-48b6-ad55-657d90138b80"}, "outputs": [], "source": ["for col in train_miss:\n", "    print (\"Train: \", col, \": \", len(train_df[train_df[col] == -1])) #count number of missing data points\n", "    \n", "for col in test_miss:\n", "    print (\"Test: \", col, \": \", len(test_df[test_df[col] == -1])) #count number of missing data points"], "execution_count": 5}, {"cell_type": "code", "metadata": {"_uuid": "d1bc80254a292add418d40d9a07db3ed37eb2b04", "_cell_guid": "43de601b-83e0-4183-9b84-514b63336663", "collapsed": true}, "outputs": [], "source": ["#Missing Value Handling\n", "\n", "#For categorical features, I plan to treat missing values as another category, so nothing needs to be done\n", "#The other features with remaining missing values are 'ps_car_12', 'ps_reg_03', 'ps_car_14'\n", "#For ps_car_12, I'll simply replace the missing values with the mean of the values present\n", "\n", "train_df.loc[train_df['ps_car_12'] == -1, 'ps_car_12'] = train_df[train_df['ps_car_12'] != -1]['ps_car_12'].mean()"], "execution_count": 6}, {"cell_type": "code", "metadata": {"_uuid": "63eaf23b0661d3d5861b14f98f03fe2079856b72", "_cell_guid": "75eb96e9-3c7e-426e-9e82-f2dfe4a73e88", "collapsed": true}, "outputs": [], "source": ["#For the other two missing features, I'll use linear regression using the most correlated features\n", "from sklearn import linear_model\n", "feature_mod = linear_model.LinearRegression()\n", "\n", "from xgboost import XGBRegressor\n", "feature_xgb = XGBRegressor(n_estimators=200)\n", "\n", "# Fill missing features for ps_car_14, using ps_car_12 and ps_car 13\n", "corr_list = ['ps_car_12', 'ps_car_13']\n", "feature_mod.fit(train_df[train_df['ps_car_14'] != -1][corr_list], train_df[train_df['ps_car_14'] != -1]['ps_car_14'])\n", "train_df.loc[train_df['ps_car_14'] == -1, 'ps_car_14'] = feature_mod.predict(train_df[train_df['ps_car_14'] == -1][corr_list])\n", "test_df.loc[test_df['ps_car_14'] == -1, 'ps_car_14'] = feature_mod.predict(test_df[test_df['ps_car_14'] == -1][corr_list])\n", "\n", "# Fill missing features for ps_reg_03, using ps_reg_02, ps_car_12, ps_car 13, and ps_ind_01\n", "# Should consider trying other models to impute ps_reg_03 if that feature proves to be important\n", "corr_list = ['ps_reg_02', 'ps_car_13', 'ps_car_12', 'ps_ind_01']\n", "feature_xgb.fit(train_df[train_df['ps_reg_03'] != -1][corr_list], train_df[train_df['ps_reg_03'] != -1]['ps_reg_03'])\n", "train_df.loc[train_df['ps_reg_03'] == -1, 'ps_reg_03'] = feature_xgb.predict(train_df[train_df['ps_reg_03'] == -1][corr_list])\n", "test_df.loc[test_df['ps_reg_03'] == -1, 'ps_reg_03'] = feature_xgb.predict(test_df[test_df['ps_reg_03'] == -1][corr_list])"], "execution_count": 7}, {"cell_type": "code", "metadata": {"_uuid": "55e73338f00451d742dadef5c3eb3844d7ced690", "_cell_guid": "0260716b-8076-4f3d-aa8c-9016a096d718", "collapsed": true}, "outputs": [], "source": ["#Encoding\n", "#I'll use one-hot encoding for all categorical variables except ps_car_11_cat (cardinality is too high)\n", "cat_cols = [x for x in potential_features if '_cat' in x ]\n", "cat_cols = list(set(cat_cols) - set(['ps_car_11_cat']))\n", "\n", "train_df = pd.get_dummies(data=train_df, columns=cat_cols, drop_first=True)\n", "test_df = pd.get_dummies(data=test_df, columns=cat_cols, drop_first=True)"], "execution_count": 8}, {"cell_type": "code", "metadata": {"_uuid": "5aca98cea5a9194bdac12d7d5f25caad46690f7a", "_cell_guid": "571f2ccd-a814-4527-accf-7dcfb31899c8", "collapsed": true}, "outputs": [], "source": ["#Next, I'll use binary encoding for ps_car_11_cat\n", "#The following creates binary format with 0 padding for number of columns required\n", "columns_needed = max(train_df['ps_car_11_cat'].max().item().bit_length(), \n", "                    test_df['ps_car_11_cat'].max().item().bit_length())\n", "format_string = '0>'+ str(columns_needed) + 'b'\n", "\n", "#The rest of this cool trick was inspired from here: https://stackoverflow.com/questions/46775546\n", "#First do train_df\n", "bin_cols = train_df['ps_car_11_cat'].apply(lambda x: format(x, format_string)).str.extractall('(\\d)').unstack().astype(np.int8).add_prefix('ps_car_11_cat_b')\n", "\n", "bin_cols.columns = bin_cols.columns.droplevel()\n", "train_df = pd.concat([train_df, bin_cols], axis=1)\n", "train_df.drop('ps_car_11_cat', inplace=True, axis=1)\n", "\n", "#Now do test_df\n", "bin_cols = test_df['ps_car_11_cat'].apply(lambda x: format(x, format_string)).str.extractall('(\\d)').unstack().astype(np.int8).add_prefix('ps_car_11_cat_b')\n", "\n", "bin_cols.columns = bin_cols.columns.droplevel()\n", "test_df = pd.concat([test_df, bin_cols], axis=1)\n", "test_df.drop('ps_car_11_cat', inplace=True, axis=1)"], "execution_count": 9}, {"cell_type": "code", "metadata": {"_uuid": "be59bd416e280a762a2589bfbbca55a0ea3b67fc", "_cell_guid": "ccb4499d-b9cf-4903-bfb5-f4a336ca92c1", "collapsed": true}, "outputs": [], "source": ["# Set up classifier\n", "from xgboost import XGBClassifier\n", "\n", "#MAX_ROUNDS = 400 #original\n", "MAX_ROUNDS = 400\n", "#LEARNING_RATE = 0.07 #original\n", "LEARNING_RATE = 0.07\n", "\n", "model = XGBClassifier(    \n", "                        n_estimators=MAX_ROUNDS,\n", "                        max_depth=4,\n", "                        objective=\"binary:logistic\",\n", "                        learning_rate=LEARNING_RATE, \n", "                        subsample=.8,\n", "                        min_child_weight=6,\n", "                        colsample_bytree=.8,\n", "                        gamma=10,\n", "                        reg_alpha=8,\n", "                        reg_lambda=1.3\n", "                     )"], "execution_count": 10}, {"cell_type": "code", "metadata": {"_uuid": "cbafb23ef87393b622adac3590914b8e44973743", "_cell_guid": "4aa4ad99-2926-45a0-b622-abdd728110fc"}, "outputs": [], "source": ["# based on https://www.kaggle.com/aharless/xgboost-cv-lb-284 with minor modifications\n", "\n", "from sklearn.model_selection import KFold\n", "\n", "K = 5\n", "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n", "\n", "y_valid_preds = 0 * train_df['target']\n", "y_test_preds = 0\n", "\n", "for i, (train_index, valid_index) in enumerate(kf.split(train_df)):\n", "    print(\"\\nStarting fold {}\".format(i+1))\n", "    start = time.time()\n", "    \n", "    y_train = train_df['target'].loc[train_index]\n", "    X_train = train_df.drop('target', axis=1).loc[train_index]\n", "    y_valid = train_df['target'].loc[valid_index]\n", "    X_valid = train_df.drop('target', axis=1).loc[valid_index]\n", "      \n", "    fit_model = model.fit(X_train, y_train, verbose=True)\n", "    \n", "    preds = fit_model.predict_proba(X_valid)[:, 1]\n", "    gini = eval_gini(y_valid, preds)\n", "    y_valid_preds.loc[valid_index] = preds\n", "\n", "    y_test_preds += fit_model.predict_proba(test_df)[:, 1]\n", "    \n", "    print(\"Fold {} Gini score: {}\".format(i, gini))\n", "    print(\"Completed fold {} in {:.2f} minutes\\n\".format(i+1, (time.time() - start)/60))\n", "\n", "y_test_preds /= K\n", "\n", "print( \"\\nGini for full training set:\" )\n", "eval_gini(train_df['target'], y_valid_preds)"], "execution_count": 11}, {"cell_type": "code", "metadata": {"_uuid": "64b1b735ea181621a9fcd5699e95e45101b38444", "_cell_guid": "6c663e59-0707-4620-80a9-655165c6a287"}, "outputs": [], "source": ["from xgboost import plot_importance\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# plot feature importance\n", "fig, ax = plt.subplots(figsize=(14, 18))\n", "plot_importance(fit_model, ax=ax)"], "execution_count": 12}, {"cell_type": "code", "metadata": {"_uuid": "093f2610bc6bd5562a29e27b4970b3d16e5ffd8f", "_cell_guid": "c1a849ba-57b9-44e9-b787-67ece805592b", "collapsed": true}, "outputs": [], "source": ["# Create submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = test_ids\n", "sub['target'] = y_test_preds\n", "sub.to_csv('xgb_submit_3.csv', float_format='%.6f', index=False)"], "execution_count": 13}, {"cell_type": "markdown", "metadata": {"_uuid": "e67f54f37c3b98c1765243a30028031743ad0b20", "_cell_guid": "ef66ef33-2b12-4255-b2aa-f8d358379027"}, "source": ["**Version 1:** \n", "CV Gini score: 0.304170535958173   LB score: 0.279 (position #2458)\n", "* All potential features included\n", "* Over_factor = 0.6\n", "* Binary encoding for ps_car_11_cat\n", "* Linear regression to complete nulls for ps_reg_03\n", "\n", "**Version 2:** \n", "CV Gini score: 0.29678440600440603   LB score: 0.277 (position # n/a)\n", "* All potential features included\n", "* Over_factor = 0.6\n", "* Binary encoding for ps_car_11_cat\n", "* Linear regression to complete nulls for ps_reg_03\n", "* MAX_ROUNDS = 200, reg_alpha=9, reg_lambda=1.7\n", "\n", "**Version 3:** \n", "CV Gini score: 0.30403963632991526   LB score: 0.280 (position #2460)\n", "* All potential features included\n", "* Over_factor = 0.6\n", "* Binary encoding for ps_car_11_cat\n", "* XGBRegression to complete nulls for ps_reg_03\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "dc02ec139f0214f6a30eb7fb1c6b7aa3af2273a0", "_cell_guid": "a20107ce-603d-4037-9c90-007c5e559fbe"}, "source": ["**Variables:**\n", "* Features to include\n", "* Level of over-sampling of positive class\n", "* Null handling technique (particularly for ps_reg_03)\n", "* Presence/absence of scaling\n", "* Category encoding method (particuarly for ps_car_11_cat)\n", "* XGBoost parameters"]}], "nbformat": 4}