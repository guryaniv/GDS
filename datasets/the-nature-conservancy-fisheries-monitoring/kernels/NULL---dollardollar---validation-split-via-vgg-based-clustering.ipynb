{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3a38337a-1505-a1f2-83c1-71a48f952297"
      },
      "source": [
        "# Validation split via VGG-based clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bc060d4c-31fa-54d7-0e84-9fc5bdd40076"
      },
      "source": [
        "In the NCFM competition it is challenging to set up a good validation strategy, since the training set contains many highly similar images. We use a clustering based on the level-4 VGG features in order separate similar images from non-similar ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b192b67-cf0d-7cda-1b3d-f53023623a1b"
      },
      "source": [
        "First, we import standard libraries and fix constants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2261bfc-f81c-5158-276b-1ed0e290d888"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import os\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Model\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "#path to training data\n",
        "DATA_PATH = '../input/train'\n",
        "\n",
        "#Number of clusters for K-Means\n",
        "N_CLUSTS = 5#250\n",
        "\n",
        "#Number of clusters used for validation\n",
        "N_VAL_CLUSTS = 1#50\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "##############################################\n",
        "#######NORMALIZED IMAGE SIZE\n",
        "##############################################\n",
        "IMG_WIDTH = 640\n",
        "IMG_HEIGHT = 360\n",
        "\n",
        "##############################################\n",
        "#######SUBSAMPLE DATA\n",
        "##############################################\n",
        "\n",
        "#how many images to take?\n",
        "SAMP_SIZE = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "943b1e36-1a05-acb5-3c65-7da2c7dcc543"
      },
      "source": [
        "## Subsample data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f8d72bfd-0097-abe2-71ce-cf444df0613e"
      },
      "source": [
        "In order for the notebook to run on Kaggle scripts, we subsample the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44003dfc-0f6d-7ae4-796f-5e2e5788cfc9"
      },
      "outputs": [],
      "source": [
        "subsample = []\n",
        "for fish in os.listdir(DATA_PATH):\n",
        "    if(os.path.isfile(os.path.join(DATA_PATH, fish))): \n",
        "        continue\n",
        "    subsample_class = [os.path.join(DATA_PATH, fish, fn) for \n",
        "                       fn in os.listdir(os.path.join(DATA_PATH, fish))]\n",
        "    subsample += subsample_class\n",
        "subsample = subsample[:SAMP_SIZE]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "846b96d5-7822-889b-d3ef-834e21b2c1cb"
      },
      "source": [
        "## Extract VGG features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce93fdd3-cfdb-5fb7-1fd5-078bb1dddd1a"
      },
      "source": [
        "Next, we extract layer 4 VGG features from the images. The clustering will be based on these features. First, we load the VGG16 model pretrained on imagenet. Unfortunately, imagenet-weights are not available on Kaggle scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "860e969c-bb80-2535-f768-176c979a9850"
      },
      "outputs": [],
      "source": [
        "base_model = VGG16(weights = None, include_top = False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "#base_model = VGG16(weights = 'imagenet', include_top = False, input_shape = (IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "model = Model(input = base_model.input, output = base_model.get_layer('block4_pool').output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd36866f-1046-6279-3461-c1957da13d4e"
      },
      "source": [
        "After a preprocessing the images can be fed to the pretrained VGG16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d6ae3752-c97d-e832-e1b1-b0a9e9ed52be"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(path):\n",
        "    img = image.load_img(path, target_size = (IMG_HEIGHT, IMG_WIDTH))\n",
        "    arr = image.img_to_array(img)\n",
        "    arr = np.expand_dims(arr, axis = 0)\n",
        "    return preprocess_input(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8adafb2-333c-4101-3fbc-bbd1cc250829"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "preprocessed_images = np.vstack([preprocess_image(fn) for fn in subsample])\n",
        "vgg_features = model.predict(preprocessed_images)\n",
        "vgg_features = vgg_features.reshape(len(subsample), -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd5efdec-e8bc-86af-72e6-dc7df86cdb29"
      },
      "source": [
        "## Cluster by K-Means "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "44a1d5d0-8bc4-f78a-2e15-2a4e603afeca"
      },
      "source": [
        "We cluster the images according to the K-Means algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbf8a829-c849-7fb3-a727-07ab03a2b918"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "km = KMeans(n_clusters = N_CLUSTS, n_jobs = -1)\n",
        "clust_preds = km.fit_predict(StandardScaler().fit_transform(vgg_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "28c8d061-e6d7-6536-378b-570b0bebc84a"
      },
      "source": [
        "Then, we select at random the clusters that will form the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b532b52d-2439-b1a8-d387-0915a0c0d9bc"
      },
      "outputs": [],
      "source": [
        "val_clusters = np.random.choice(range(N_CLUSTS), N_VAL_CLUSTS, replace = False)\n",
        "val_sample = np.array(subsample)[np.in1d(clust_preds, val_clusters)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8ef482c-0b4a-162a-fb07-bdae109ddc77"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}