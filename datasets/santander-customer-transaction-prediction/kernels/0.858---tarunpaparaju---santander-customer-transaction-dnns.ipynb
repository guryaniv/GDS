{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras import backend as K\nfrom keras.layers import Layer\nfrom keras.regularizers import L1L2\n\nfrom imblearn import keras\nfrom imblearn.keras import BalancedBatchGenerator\nfrom imblearn.over_sampling import RandomOverSampler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde5917d5eda637b245bbb8365847320e56b1b53"},"cell_type":"code","source":"def get_data():\n    train_df = pd.read_csv('../input/train.csv')\n    test_df = pd.read_csv('../input/test.csv')\n    \n    train_data = train_df.values\n    test_data = test_df.values\n\n    train_features = np.float64(train_data[:, 2:])\n    test_features = np.float64(test_data[:, 1:])\n    \n    scaler = MinMaxScaler(feature_range=(-1, 1))\n    scaler.fit(np.concatenate([train_features, test_features], axis=0))\n    train_features = scaler.transform(train_features)\n    test_features = scaler.transform(test_features)\n    \n    train_target = np.float64(train_data[:, 1])\n    \n    test_ids = test_data[:, 0]\n    \n    return train_features, train_target, test_features, test_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f20a0f31d045a7a7ea144b7e71c85b5de543c3cf"},"cell_type":"code","source":"train_features, train_target, test_features, test_ids = get_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"488d09c5481e3d1d008cb4e6caef552647181d1f"},"cell_type":"code","source":"def binary_crossentropy(y_true, y_pred):\n    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8a05c7c36326099a26c4a7b96ddc829226fc951"},"cell_type":"code","source":"\"\"\"\nSuccessfull architecture :\n\nmodel = Sequential()\nmodel.add(Dense(10, input_shape=(train_features.shape[1],), activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(15, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\"\"\"\n\nmodel = Sequential()\nmodel.add(Dense(100, input_shape=(train_features.shape[1],), activation='selu')) # 40\nmodel.add(Dropout(0.1))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ebb92586d541bd66b499b37afbc834c8a995f38"},"cell_type":"code","source":"model.compile(loss=binary_crossentropy, optimizer='adam', metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b962dea3ce4d2418dcf368fdc2d9262f2197c4e"},"cell_type":"code","source":"split_point = np.int32(0.8*len(train_features))\ntraining_generator = BalancedBatchGenerator(train_features[:split_point], train_target[:split_point], batch_size=10000, random_state=42)\ncallback_history = model.fit_generator(generator=training_generator, validation_data=(train_features[split_point:], train_target[split_point:]), epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dfb6f8521149666c60e2ebc3bfc0c8af6d89be9"},"cell_type":"code","source":"predictions = model.predict(test_features).reshape((len(test_ids)))\nsubmission = pd.DataFrame(np.transpose(np.array([test_ids, predictions])))\nsubmission.columns = ['ID_code', 'target']\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba7ba5416f5f6271708ca97c009bb399297389b"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fe2b0b1d42e6ad758998e1a3d714c08c0d42de9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}