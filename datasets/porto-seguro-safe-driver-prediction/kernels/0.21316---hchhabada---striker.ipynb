{"nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "nbconvert_exporter": "python", "version": "3.6.3"}}, "cells": [{"cell_type": "code", "metadata": {"_uuid": "07560b8aaa5551b396a644be207a2197734e1f29", "collapsed": true, "_cell_guid": "bd4fb2c8-5a25-4eb8-ab43-590e118968be"}, "outputs": [], "source": [], "execution_count": null}, {"cell_type": "code", "metadata": {"_kg_hide-input": true, "_uuid": "e0bb17227b0573ae22527a85e1a17dd8a7ecfc8f", "_cell_guid": "59d497fb-0699-4890-a86d-41413f7d4db6"}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from  sklearn.metrics import accuracy_score\n", "from sklearn.utils import resample\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.base import TransformerMixin\n", "\n", "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n", "     assert( len(actual) == len(pred) )\n", "     all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n", "     all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n", "     totalLosses = all[:,0].sum()\n", "     giniSum = all[:,0].cumsum().sum() / totalLosses\n", " \n", "     giniSum -= (len(actual) + 1) / 2.\n", "     return giniSum / len(actual)\n", " \n", "def gini_normalized(a, p):\n", "     return gini(a, p) / gini(a, a)\n", " \n", "def eval_gini(y_true, y_prob):\n", "    \"\"\"\n", "    Original author CPMP : https://www.kaggle.com/cpmpml\n", "    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n", "    \"\"\"\n", "    y_true = np.asarray(y_true)\n", "    y_true = y_true[np.argsort(y_prob)]\n", "    ntrue = 0\n", "    gini = 0\n", "    delta = 0\n", "    n = len(y_true)\n", "    for i in range(n-1, -1, -1):\n", "        y_i = y_true[i]\n", "        ntrue += y_i\n", "        gini += y_i * delta\n", "        delta += 1 - y_i\n", "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n", "    return gini\n", "\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = eval_gini(labels, preds)\n", "    return [('gini', gini_score)]\n", "\n", "print(\"Reading Input\")\n", "df = pd.read_csv(\"../input/train.csv\")\n", "df_test = pd.read_csv(\"../input/test.csv\")\n", "\n", "\n", "class DataFrameImputer(TransformerMixin):\n", "    def fit(self, X, y=None):\n", "        self.fill = pd.Series([X[c].value_counts().index[0]\n", "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n", "            index=X.columns)\n", "        return self\n", "    def transform(self, X, y=None):\n", "        return X.fillna(self.fill)\n", "\n", "target = df['target']\n", "df.drop('target',axis=1)\n", "\n", "big_X = df.append(df_test)\n", "big_X_imputed = DataFrameImputer().fit_transform(big_X)\n", "\n", "\n", "df = big_X_imputed[0:df.shape[0]]\n", "df_test = big_X_imputed[df.shape[0]::]\n", "\n", "\n", "\n", "# Prepare the inputs for the model\n", "\n", "\n", "df['target'] = target\n", "y = []\n", "def upsampling(df):\n", "    df_majority=df[df.target==0]\n", "    df_minority=df[df.target==1]\n", "    # Upsample minority class\n", "    df_minority_upsampled = resample(df_minority, \n", "                                     replace=True,     # sample with replacement\n", "                                     n_samples=473518,    # to match majority class\n", "                                     random_state=123) # reproducible results\n", "\n", "    # Combine majority class with upsampled minority class  n_samples=573518\n", "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n", "    \n", "    return df_upsampled\n", "\n", "ids = df_test['id'].as_matrix()\n", "df_test.drop('id',axis=1)\n", "\n", "#upsampling\n", "df_upsampled = upsampling(df)\n", "y= df_upsampled['target'].as_matrix().astype(float)\n", "df_upsampled.drop('target',axis=1)\n", "df_upsampled.drop('id',axis=1)\n", "\n", "X = df_upsampled.as_matrix()\n", "X_test_new = df_test.as_matrix()\n", "\n", "\n", "\n", "\n", "scaler = StandardScaler()\n", "# Fit only to the training data\n", "scaler.fit(X_test_new)\n", "# Now apply the transformations to the data:\n", "#X_train = scaler.transform(X_train)\n", "X_test_new = scaler.transform(X_test_new)\n", "\n", "scaler.fit(X)\n", "X = scaler.transform(X)\n", "\n", "from sklearn import decomposition\n", "pca = decomposition.PCA(n_components=4)\n", "\n", "X = pca.fit_transform(X)\n", "\n", "X_test_1 = pca.fit_transform(X_test_new)\n", "\n", "from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.10)\n", "\n", "print(\"Model Building\")\n", "from xgboost import XGBClassifier\n", "\n", "n_estimators = 300\n", "n_splits = 4\n", "print(\"Kfold\")\n", "from sklearn.model_selection import StratifiedKFold\n", "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15)\n", "\n", "'''\n", "param = {\n", " 'n_estimators':[100,150,200,250],\n", " 'max_depth':[2,3,4,5,6,7,8,9],\n", " 'min_child_weight':[2,3,4,5],\n", " 'colsample_bytree':[0.2,0.6,0.8],\n", " 'colsample_bylevel':[0.2,0.6,0.8],\n", " 'learning_rate':[0.02,0.04,0.2]\n", "}\n", "from sklearn.grid_search import GridSearchCV\n", "gsearch1 = GridSearchCV(estimator = XGBClassifier( \n", "        objective= \"binary:logistic\", \n", "        seed=1), \n", "    param_grid = param, \n", "    scoring='neg_log_loss',\n", "    cv=4,\n", "    verbose = 1)\n", "    \n", "# http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n", "# mean_squared_error alternative.\n", "\n", "gsearch1.fit(X_train, y_train)\n", "print(gsearch1.bestscore)\n", "print(gsearch1.bestparams)\n", "'''\n", "\n", "clf = XGBClassifier(n_estimators=n_estimators,\n", "                        max_depth=5,\n", "                        objective=\"binary:logistic\",\n", "                        learning_rate=.02, \n", "                        subsample=.8, \n", "                        colsample_bytree=.8,\n", "                        gamma=1,\n", "                        reg_alpha=0,\n", "                        reg_lambda=1,\n", "                        nthread=2)\n", "\n", "import matplotlib.pyplot as plt\n", "import scikitplot as skplt\n", "from sklearn import metrics\n", "for train_index, test_index in folds.split(X,y):\n", "    \n", "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n", "    X_train, X_test = X[train_index], X[test_index]\n", "    y_train, y_test = y[train_index], y[test_index]\n", "\n", "\n", "    print(\"Model fitting\")\n", "    # Fit the best algorithm to the data. \n", "    clf.fit(X_train, y_train)\n", "    \n", "\n", "    predictions = clf.predict(X_test)\n", "    predictions_prob = clf.predict_proba(X_test)\n", "    print(accuracy_score(y_test, predictions))\n", "    predictions_prob_test = clf.predict_proba(X_test_1)\n", "    skplt.metrics.plot_precision_recall_curve(y_test, predictions_prob)\n", "    plt.show()\n", "    #roc\n", "    preds_roc = predictions_prob[:,1]\n", "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds_roc)\n", "    roc_auc = metrics.auc(fpr, tpr)\n", "    plt.title('Receiver Operating Characteristic')\n", "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n", "    plt.legend(loc = 'lower right')\n", "    plt.plot([0, 1], [0, 1],'r--')\n", "    plt.xlim([0, 1])\n", "    plt.ylim([0, 1])\n", "    plt.ylabel('True Positive Rate')\n", "    plt.xlabel('False Positive Rate')\n", "    plt.show()\n", "\n", "\n", "\n", "\n", "\n", "df2 = pd.DataFrame({'id' : ids})\n", "df2['target'] = predictions_prob_test[:,1]\n", "df2.to_csv(\"submission_5_xgbKold_1.csv\",index= False)\n", "print(df2)\n", "#print(predictions_prob)\n", "#print(predictions_prob[:,1])\n", "\n", "\n", "\n", "\n", "print(\"Full OOF score : %.6f\" % gini_normalized(y_test,predictions_prob[:,1]))\n", "\n", "#print(accuracy_score(y_test, predictions))\n", "\n", "\n", "\n", "#print(accuracy_score(y_test, predictions))\n", "\n", "#print(pd.DataFrame(pca.components_,columns=df_norm.columns,index = ['PC-1','PC-2']))\n", "#list(X)\n", "# Any results you write to the current directory are saved as output."], "execution_count": null}]}