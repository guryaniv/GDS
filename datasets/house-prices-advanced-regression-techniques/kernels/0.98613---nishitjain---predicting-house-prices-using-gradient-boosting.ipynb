{"cells":[{"metadata":{"trusted":true,"_uuid":"b84bfcaebfe2590a8aac6850b8ab17057e1a0ab5"},"cell_type":"code","source":"# Imported all required libraries\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split as tts\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dda8a7407b42e61916f2b28cd9fff2cbe85d71d1"},"cell_type":"code","source":"# Getting our train and test datasets from csv to dataframe.\ndf_train = pd.read_csv(\"../input/train.csv\")\nX_test = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89f91afe87351b633ae99a659fdf336716147bb4"},"cell_type":"code","source":"# Checking shape of both train and test dataset.\nprint('Shape of training dataset: {}'.format(df_train.shape))\nprint('Shape of test datast: {}'.format(X_test.shape))\n\n# Seaprating dependent variable from the independent ones because we do not want to mess with the target variable.\ny_train = df_train.SalePrice\nX_train = df_train.drop('SalePrice',1)\n\n# Storing IDs of test datapoints to make final submissions of predicted Sale Price.\ntest_ids = X_test['Id']\n\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d67b17c43714ab56622896d77bd3b928e15a615"},"cell_type":"code","source":"# Checking if there are any null values in the target variable.\ny_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d76e06c5409da50effc61bc120b8158e4618b64"},"cell_type":"code","source":"# Dropping the ID column from train and test and all those columns having more than tolerable null values.\nX_train.drop('Id',axis=1,inplace=True)\nX_test.drop('Id',axis=1,inplace=True)\ndrop_cols = [col for col in list(X_train.columns) if X_train.isnull().sum()[col]>100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8adfd7dbba9c5e21088d5cba561a55775f2902a"},"cell_type":"code","source":"drop_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eee166afb89af5a08c462d408c26f6435614f5e"},"cell_type":"code","source":"X_train.drop(drop_cols,axis=1,inplace=True)\nX_test.drop(drop_cols,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d50cf5ef1683cf463024497189b0e6d00497e68e"},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c39c35eb51b401b454e6bfccac1a5e3936ebd11"},"cell_type":"code","source":"X_train.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41aad1654d7c311a5b7f4a278d2854f826b649d7"},"cell_type":"code","source":"X_test.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68799a78d6ee65cea1ba926a59afd03bf2aa9809"},"cell_type":"code","source":"'''\nImputing remaining nulll values ->\n    1. Numerical columns' null values with the mean value of the column.\n    2. Categorical columns' null values with the mode value of the column.\n'''\nfor col in list(X_train.columns):\n    if ((X_train[col].dtype == np.int64) or (X_train[col].dtype == np.float64)):\n        X_train[col].fillna(value=X_train[col].mean(),inplace=True)\n        X_test[col].fillna(value=X_test[col].mean(),inplace=True)\n    else:\n        X_train[col].fillna(value=X_train[col].mode()[0],inplace=True)\n        X_test[col].fillna(value=X_test[col].mode()[0],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3915e7a969007bde6962cc5a23c160d70117467f"},"cell_type":"code","source":"X_train.isnull().sum().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2995536d05064b0939a4795a056654be3510b561"},"cell_type":"code","source":"# Separating numerical and categorical datatypes into two different dataframes for train and test both.\ntrain_numerical = X_train.select_dtypes(include=np.number)\ntrain_categorical = X_train.select_dtypes(exclude=np.number)\ntest_numerical = X_test.select_dtypes(include=np.number)\ntest_categorical = X_test.select_dtypes(exclude=np.number)\n\n# Storing column names into a list for future use.\ntrain_categorical_cols = train_categorical.columns\n\n# One-hot encoding the categorical variables.\nonehot_encoder = OneHotEncoder(sparse=False)\ntrain_categorical = pd.DataFrame(onehot_encoder.fit_transform(train_categorical))\ntest_categorical = pd.DataFrame(onehot_encoder.transform(test_categorical))\ntrain_numerical_cols = train_numerical.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b090ebe36ea54b6a494077053ea4acf13b64d0c"},"cell_type":"code","source":"# MinMax Scaling all the numerical columns (except target variable, obviously!) between the 0 to 1 range.\nscaler = MinMaxScaler(feature_range=(0,1))\ntrain_numerical = pd.DataFrame(scaler.fit_transform(train_numerical),columns=train_numerical_cols)\ntest_numerical = pd.DataFrame(scaler.fit(train_numerical).transform(test_numerical),columns=train_numerical_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32f503415822fc75c8f69ab4c9c17529684e6f00"},"cell_type":"code","source":"print('Shape of training dataset:\\n 1.Numerical: {}\\n 2.Categorical: {}\\n'.format(train_numerical.shape,train_categorical.shape))\nprint('Shape of test dataset:\\n 1.Numerical: {}\\n 2.Categorical: {}\\n'.format(test_numerical.shape,test_categorical.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5161266efb9c82a22b1f397c8418be35aa6c7950"},"cell_type":"code","source":"# Concatenating both (numerical and categorical) dataframes for train adn test again for prediction.\nX_train = pd.concat([train_numerical,train_categorical],1)\nX_test = pd.concat([test_numerical,test_categorical],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41105bf858287c3d4efd9dfcb865b51d1a4892ad"},"cell_type":"code","source":"year_cols = [col for col in list(train_numerical.columns) if (col.find('Year')!=-1 or col.find('year')!=-1 or col.find('Yr')!=-1 or col.find('yr')!=-1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b725edf0b6fdb9509448f0ac218ed38a4b839829"},"cell_type":"code","source":"year_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cd5dea56d4d00d2eafd383460d61b8de7660508"},"cell_type":"code","source":"# Splitting the train dataset into train and validation.\nX_train,X_val,y_train,y_val = tts(X_train,y_train,test_size=0.3,random_state=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f894dc0168e062798cf0ce695b99c4ec7eca3d"},"cell_type":"code","source":"# Using XFBRegressor to predict the SalePrice.\nmodel = XGBRegressor(max_depth=80,learning_rate=0.01,n_estimators=1000)\ny_pred_val = model.fit(X_train,y_train).predict(X_val)\nprint('R2 Score On Validation: {}'.format(r2_score(y_val,y_pred_val)))\n\nfeatures = pd.Series(model.feature_importances_, index = X_train.columns)\nfeatures = features.sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb32def58a5201edde92b8f9b46f80b1296dfa13"},"cell_type":"code","source":"# Plotting horizontal bar graph to assess the check the value of all the importance of the features.\nimport matplotlib\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nfeatures[features>=0.01].plot(kind = \"barh\")\nplt.title(\"Feature Importances in the XGBoost Model For Regression\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3a0225f7505ac529fb186485b2a810129ca9a37"},"cell_type":"code","source":"# Making predictions on the test set.\ny_pred_test = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"193964ad7cc9482233446c32a45d91e65d8f8b84"},"cell_type":"code","source":"# Creating dataframe for final submission by concatenating Test IDs and predited Sale Price.\ny_pred_test = pd.Series(y_pred_test)\nsubmission_df = pd.concat([test_ids,y_pred_test],axis=1,keys=['Id','SalePrice']).reset_index(drop=True)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00739931a3fec2bb7a4bf23a43347834a8523ad8"},"cell_type":"code","source":"# Storing the final submission dataframe to a CSV File.\nsubmission_df.to_csv(index=False,path_or_buf='submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}