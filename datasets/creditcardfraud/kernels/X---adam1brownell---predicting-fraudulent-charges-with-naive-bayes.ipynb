{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "55147675-e54c-9015-19e7-04722a61f08a"
      },
      "source": [
        "A simple notebook exploring Naive Bayes' ability to predict fraudulent charges. Even with the ineffectiveness of PCA regularization and Naive Bayes' large assumptions, the model proved to be quite effective: 97% accuracy, with 4% false alarm rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8228439-d4fa-aaa7-9621-fd461dfef032"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1afbb7d1-e0c5-3eb8-b422-44aec777ec5b"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "071722d3-9c3e-d8e0-71f3-39c7dfde62a4"
      },
      "outputs": [],
      "source": [
        "#Load data from csv\n",
        "alldata = pd.read_csv(\"../input/creditcard.csv\")\n",
        "print (alldata.head())\n",
        "#Separate data labels\n",
        "labels = alldata['Class'].as_matrix()\n",
        "\n",
        "#Clear Time and Class elements, Class because this is the labels,\n",
        "#Time because we are will make the (controversial) assumption that\n",
        "#fraudualent and legitamate transactions occur at all hours\n",
        "alldata.drop('Time', axis = 1, inplace = True)\n",
        "alldata.drop('Class',axis = 1, inplace = True)\n",
        "\n",
        "#Make numpy matrix with 29 features\n",
        "dataset = alldata.iloc[:].as_matrix()\n",
        "print(dataset.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "15e28635-7011-1ddc-90ff-16904091373a"
      },
      "source": [
        "**Regularization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60e5041e-f8ec-46a4-7350-54e9e92203a3"
      },
      "outputs": [],
      "source": [
        "#See if PCA is an appropriate regularization method\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.preprocessing as prepro\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(prepro.scale(dataset))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('Scree Plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e16749b6-33f6-61d1-90b0-69ef1c92e8d9"
      },
      "source": [
        "Clearly variance between features is relatively uniform. Unable to cut significant number of features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac975d4c-d43c-45cd-c257-b2c90a895045"
      },
      "source": [
        "**Predictive Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3ab8340e-a18b-8316-fac3-a5cd52125fb6"
      },
      "source": [
        "Naive Bayes: Chosen because...\n",
        "\n",
        " - Cheap Computational Cost\n",
        "\n",
        " - Test model's principle assumption; that all features are independent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ae0e026-6441-bd62-ca85-dc93c99e1440"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes Predictive \n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import sklearn.model_selection as ms\n",
        "\n",
        "#Cross Val for accuracy\n",
        "x_train, x_test, y_train, y_test = ms.train_test_split(dataset, labels)\n",
        "\n",
        "#Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(x_train, y_train)\n",
        "nb_predict = nb_model.predict_proba(x_test)\n",
        "\n",
        "#ROC Curve\n",
        "import sklearn.metrics as met\n",
        "fpr1, tpr1, treshholds = met.roc_curve(y_test,nb_predict[:,1])\n",
        "x1 = [0,1]\n",
        "y1 = [0,1]\n",
        "plt.plot(fpr1,tpr1)\n",
        "plt.plot(x1,y1)\n",
        "plt.title('ROC Curve - All Data')\n",
        "plt.show()\n",
        "print(\"AUC: \", met.auc(fpr1,tpr1))\n",
        "print(\"Accuracy: \", nb_model.score(x_test,y_test))\n",
        "\n",
        "#PCA on 5 features\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(prepro.scale(dataset))\n",
        "\n",
        "#Cross Val for accuracy\n",
        "x_train, x_test, y_train, y_test = ms.train_test_split(X_pca, labels)\n",
        "\n",
        "#Naive Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(x_train, y_train)\n",
        "nb_predict = nb_model.predict_proba(x_test)\n",
        "\n",
        "#ROC Curve\n",
        "import sklearn.metrics as met\n",
        "fpr1, tpr1, treshholds = met.roc_curve(y_test,nb_predict[:,1])\n",
        "x1 = [0,1]\n",
        "y1 = [0,1]\n",
        "plt.plot(fpr1,tpr1)\n",
        "plt.plot(x1,y1)\n",
        "plt.title('ROC Curve - 25 Features')\n",
        "plt.show()\n",
        "print(\"AUC: \", met.auc(fpr1,tpr1))\n",
        "print(\"Accuracy: \", nb_model.score(x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "109faf12-78b9-09de-2c37-a31908e0a182"
      },
      "source": [
        "Used an ROC curve alongside the Accuracy score to see the occurrence of Type 1 Errors. With a strong AUC and Accuracy score, the Naive Bayes model is quite effective (and fast) at identifying fraudulent transactions. The removal of irrelevant features (Found from PCA) did not change these scores significantly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f345095a-50f8-1559-bce9-ece340562bd7"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}