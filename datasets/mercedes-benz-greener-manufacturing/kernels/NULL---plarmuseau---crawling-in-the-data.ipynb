{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2bdcaf35-4cb5-b404-d8d6-6926db172f00"
      },
      "source": [
        "First: the columns X0-X8\n",
        "------------------------\n",
        "\n",
        "we try to find if there is a match between those data , lets construct an artificial key value, and look if there is a match between train - test\n",
        "\n",
        " - the length of test and train matches perfectly, thats probably a balancing\n",
        "-linking on those artifical  key we don't match, so we can't use it to transfer the time\n",
        "\n",
        "**- although its clear that the ID's are not matching...in that sence they simply splitted the database in two parts and have the stats at hand**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09406dcd-c4a7-10af-646f-ed09b90b4aa5"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def grouper (l0,l1,l2,l3,l4,l5,l6,l8):\n",
        "    gr=l0+'0 '+l1+'1 '+l2+'2 '+l3+'3 '+l4+'4 '+l5+'5 '+l6+'6 '+l8+'8 '\n",
        "    return gr\n",
        "    \n",
        "\n",
        "df_train = pd.read_csv('../input/train.csv')\n",
        "print('Size of training set: {} rows and {} columns'.format(*df_train.shape))\n",
        "print('TRAIN',df_train.head(7))\n",
        "print('record 252',df_train.iloc[252][['ID','X0','X1','X2','X3','X4','X5','X6','X8']])\n",
        "# sort smallest first\n",
        "df_train=df_train.sort_values(by='y', axis=0)  \n",
        "bins= [c for c in df_train.columns if 'X' in c]\n",
        "print('Number of features TRAIN: {}'.format(len(bins)))\n",
        "\n",
        "# grouping all types together\n",
        "df_train['keys']=df_train[['X0','X1','X2','X3','X4','X5','X6','X8']].apply(lambda x: grouper(*x), axis=1)  \n",
        "df_train_gr=df_train.groupby(by='keys', axis=0).mean()\n",
        "#print(df_train_gr.sort_values(by='y',axis=0))\n",
        "\n",
        "\n",
        "\n",
        "#reading test___________________________\n",
        "df_test = pd.read_csv('../input/test.csv')\n",
        "print('Size of  TEST: {} rows and {} columns'.format(*df_test.shape))\n",
        "print('Test',df_test.head(7))\n",
        "print('record 252 in test',df_test.iloc[251][['ID','X0','X1','X2','X3','X4','X5','X6','X8']])\n",
        "print('record 252 in test',df_test.ix[df_test['ID']==504][['ID','X0','X1','X2','X3','X4','X5','X6','X8']])\n",
        "# grouping all types together\n",
        "df_test['keys']=df_test[['X0','X1','X2','X3','X4','X5','X6','X8']].apply(lambda x: grouper(*x), axis=1)  \n",
        "\n",
        "\n",
        "#merge two databases____on artificial keys_________________________\n",
        "result = pd.merge(df_test,df_train, how='left', on='keys', left_on=None, right_on=None,\n",
        "         left_index=False, right_index=False, sort=True,\n",
        "         suffixes=['_te', '_tr'], copy=True, indicator=False)\n",
        "print(result.shape)\n",
        "\n",
        "# Benching with 1-1 linking > gives NO  >1-1 link\n",
        "sub = pd.DataFrame()\n",
        "sub['ID'] = result.ID_te\n",
        "sub['y'] = result.y\n",
        "sub2 = sub.groupby(by='ID',axis=0).min()\n",
        "print('transfer time estimate through link on key', sub2.T)\n",
        "\n",
        "result = pd.merge(df_test,df_train, how='left', on='ID',suffixes=['_te', '_tr'], copy=True, indicator=False)\n",
        "\n",
        "print(result[['keys_tr','keys_te','ID']].head())\n",
        "print(result.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "55499458-66f7-e979-7fdf-fcae20e36ed9"
      },
      "source": [
        "CORRELATION ?\n",
        "-------------\n",
        "\n",
        "Yes there is correlation between the data\n",
        "\n",
        "The correlation of the Y-time versus the data can be very positive, and negative...\n",
        "the negative correlated parameters like X127 will reduce the time spend on the car-tests...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ebab082-9879-000f-cded-38d0e81e72fa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "corrtest=bins+['y']\n",
        "#correlation matrix\n",
        "corrm=df_train[corrtest].corr()\n",
        "plt.imshow(corrm,\n",
        "           interpolation='nearest', cmap=cm.gist_rainbow)\n",
        "plt.show()\n",
        "#some rows have no data\n",
        "#print(np.diag(corrm))\n",
        "print(len(corrm))\n",
        "#sort on y\n",
        "corry=corrm[len(corrm)-1:len(corrm)]\n",
        "corry=corry.T.sort_values(by='y',axis=0)\n",
        "\n",
        "ax = corry.plot(kind='bar', title =\"Y\", figsize=(15, 10), legend=True, fontsize=12)\n",
        "# so the uncorrelated to y are the time gaining components...\n",
        "ax = corry[0:30].plot(kind='bar', title =\"Y\", figsize=(15, 10), legend=True, fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1b335493-a97b-a8b6-2400-729dd8beef15"
      },
      "source": [
        "Is there on average a difference between the X-columns in the database TEST versus TRAIN ?\n",
        "========================================================================\n",
        "\n",
        "visually there is no big difference\n",
        "so fe the X127 that is negative correlated will help nearly the most to reduce the time\n",
        "and the data learned from the training set should be useable for the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69273053-7845-77ad-3b20-c5d07331b9a0"
      },
      "outputs": [],
      "source": [
        "from numpy import corrcoef, sum, log, arange\n",
        "usable_columns = list(set(df_train.columns) - set(['ID', 'y','X0', 'X6', 'X3', 'X4', 'X8', 'X2', 'keys', 'X5', 'X1']))\n",
        "\n",
        "trainstats=df_train[usable_columns].describe().T\n",
        "\n",
        "print(trainstats.head())\n",
        "trainstats['count']=trainstats['count']/4209\n",
        "trainstatsort=trainstats.sort_values(by='mean',axis=0)\n",
        "\n",
        "teststats=df_test[usable_columns].describe().T\n",
        "print(teststats.head())\n",
        "teststats['count']=teststats['count']/4209\n",
        "teststatsort=teststats.sort_values(by='mean',axis=0)\n",
        "\n",
        "stats=pd.merge(trainstats, teststats, how='inner', on=None, left_on=None, right_on=None,\n",
        "         left_index=True, right_index=True, sort=False,\n",
        "         suffixes=('_tr', '_te'), copy=True, indicator=False)\n",
        "statssort=stats.sort_values(by='mean_tr')\n",
        "#print(stats)\n",
        "\n",
        "statssort[['mean_tr','mean_te']].tail(50).plot(kind='bar', title =\"Y\", figsize=(15, 10), legend=True, fontsize=12)\n",
        "\n",
        "vcovm=np.cov(df_train[usable_columns].T,df_train['y'].T)\n",
        "df_vcm=pd.DataFrame(vcovm)\n",
        "diagonalen=pd.DataFrame(np.diag(df_vcm))\n",
        "\n",
        "statssort[['std_tr','std_te']].tail(50).plot(kind='bar', title =\"Y\", figsize=(15, 10), legend=True, fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "977195ed-d903-9760-1116-a8dbb493c9ab"
      },
      "source": [
        "Lets treat the artificial key column as a tfidf txt..\n",
        "----\n",
        "we found a big difference in paired values between train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "624df0ab-5cf5-8ef1-b851-28bc48d97548"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer( ngram_range=(1,2))\n",
        "tfidftest=tfidf.fit_transform(df_train['keys'].append(df_test['keys']))\n",
        "\n",
        "print(tfidf)\n",
        "\n",
        "#tfidf2 = TfidfVectorizer( ngram_range=(1,2))\n",
        "#tfidf2.fit_transform(df_test['keys'])\n",
        "#print(tfidf2)\n",
        "\n",
        "wordnr = pd.DataFrame(pd.Series(list(tfidf.vocabulary_.keys()), index=tfidf.vocabulary_.values()),columns=['woord']) # #print(words)  #woordenboek !\n",
        "words=np.asarray(wordnr.woord)\n",
        "\n",
        "#wordnr2 = pd.DataFrame(pd.Series(list(tfidf2.vocabulary_.keys()), index=tfidf2.vocabulary_.values()),columns=['woord']) # #print(words)  #woordenboek !\n",
        "#words2=np.asarray(wordnr2.woord)\n",
        "\n",
        "#are there words not existing in the test ?\n",
        "#print([w for w in words2 if w not in words])\n",
        "#alot of new unique combinations\n",
        "\n",
        "df_train[df_train['keys'].str.contains('az0 s1 as2')]\n",
        "df_test[df_test['keys'].str.contains('az0 s1 as2')]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "19e8065e-761a-0587-ffbd-7402382d9fa9"
      },
      "source": [
        "Find singulars from the keys\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f5aa550-cdb0-8966-ee3a-0206f23628d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "\n",
        "print('svd')     \n",
        "svd = TruncatedSVD(n_components=50, n_iter=30, random_state=42)\n",
        "tempi=pd.DataFrame(svd.fit_transform(tfidf.transform(df_train['keys'])))\n",
        "tempi.rename(columns=lambda x: str(x)+'_i', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "print('before',df_train.shape)\n",
        "df_train=df_train.join(tempi,how='inner')\n",
        "print('tempi',tempi.shape)\n",
        "print('joined with tempi',df_train.shape)\n",
        "\n",
        "\n",
        "print('svd2')     \n",
        "svd2 = TruncatedSVD(n_components=50, n_iter=30, random_state=42)\n",
        "temp2=pd.DataFrame(svd2.fit_transform(tfidf.transform(df_test['keys'])))\n",
        "temp2.rename(columns=lambda x: str(x)+'_i', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "df_test=df_test.join(temp2,how='inner')\n",
        "print('test before',df_test.shape)\n",
        "print('temp2',temp2.shape)\n",
        "print('joined with temp2',df_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb579250-2c63-283c-0da3-022de2c1c067"
      },
      "source": [
        "X314\n",
        "---\n",
        "most positive correlated with y, separates clearly the time\n",
        "it's one of the most powerfull separators, or when this option is installed it takes alot of time to check...\n",
        "its an option that is installed in 30% of the cars... thats sounds like fe manual versus automatic, or benzin versus gasoil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ad6c187-ba38-68af-ecd8-a3b378b7ab2b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.pairplot(df_train[['X314','X261','X263','0_i','1_i','2_i','3_i','4_i','5_i','X232','X29','X279','y']], hue='X314')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "761565ca-d2f8-f188-aefe-4fdb2c51d24b"
      },
      "outputs": [],
      "source": [
        "Option X279 is a huge timegainer, its installed in a minority of carrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68d6b771-ea35-e4cd-d054-08b027c66bc2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.pairplot(df_train[['X314','X261','X263','0_i','1_i','2_i','3_i','4_i','5_i','X232','X29','X279','y']], hue='X279')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd945a3e-f731-211e-3305-0ed97569b79d"
      },
      "source": [
        "XGB\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9eab8798-e45e-dfd6-3eda-03042d32e5a3"
      },
      "outputs": [],
      "source": [
        "y_train = df_train['y'].values\n",
        "\n",
        "usable_columns = list(set(df_train.columns) - set(['ID', 'y','X0', 'X6', 'X3', 'X4', 'X8', 'X2', 'keys', 'X5', 'X1']))\n",
        "x_train = df_train[usable_columns]\n",
        "x_test = df_test[usable_columns]\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=4242)\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "d_test = xgb.DMatrix(x_test)\n",
        "\n",
        "params = {}\n",
        "params['objective'] = 'reg:gamma'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 16\n",
        "\n",
        "def xgb_r2_score(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'r2', r2_score(labels, preds)\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "clf = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=10, feval=xgb_r2_score, maximize=True, verbose_eval=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd4d2bfc-c4fe-2954-b506-f5f95d3519eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for c in df_train.columns:\n",
        "    if df_train[c].dtype == 'object':\n",
        "        lbl = LabelEncoder() \n",
        "        lbl.fit(list(df_train[c].values) + list(df_test[c].values)) \n",
        "        df_train[c] = lbl.transform(list(df_train[c].values))\n",
        "        df_test[c] = lbl.transform(list(df_test[c].values))\n",
        "        \n",
        "print(df_train)\n",
        "df_norm = (df_train - df_train.mean()) / (df_train.max() - df_train.min())\n",
        "print(df_norm)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}