{"cells":[{"metadata":{"_uuid":"738fd9c0626247234fa74f6f7c2cd8797510efb3"},"cell_type":"markdown","source":"# changing\n\nhttps://www.kaggle.com/cristianossd/tf-idf-approach-on-insincere-questions"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom nltk import word_tokenize\nfrom scipy.sparse import coo_matrix\nfrom nltk.corpus import stopwords\nstopWords = set(stopwords.words('english'))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')#[:100000]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"323be5bfdf6a73920f2dddbefc6e35957da33bc7"},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b067c94a1a89074f908ebd860eda5fc050dc4faa"},"cell_type":"markdown","source":"### don't  Resample\n\nTrying undersampling strategy:"},{"metadata":{"_uuid":"00c3a7b82b1e53845e2a656dec1d833fe70770ec"},"cell_type":"markdown","source":"### change tfidf to countvectorizer binary and use 90k features\nuse all words test + train\nusually one uses all train words and omits all new trst words"},{"metadata":{"trusted":true,"_uuid":"5d934e74507db59219320522f61ecefd4108d1e7"},"cell_type":"code","source":"\n\n\ntf_vectorizer =CountVectorizer(binary=True,strip_accents='unicode',max_features=90000).fit(df['question_text'].append(test['question_text']))\nlistOfWords = tf_vectorizer.get_feature_names()\ndictOfWords = { listOfWords[i]:i for i in range(0, len(listOfWords) ) }\ntf_vectorizer.transform(df['question_text'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"297ffa871cca6e9b3e0b0ec52f191778a95ec6aa"},"cell_type":"markdown","source":"**co-occurrance snippet**"},{"metadata":{"trusted":true,"_uuid":"84ec098651898609da054b41017b61f77d06fdd2"},"cell_type":"code","source":"from nltk import word_tokenize\nfrom scipy.sparse import coo_matrix\n\ndef create_cooccurrence_matrix(filename,tokenizer,window_size,vocabulary):\n    #vocabulary={}\n    data=[]\n    row=[]\n    col=[]\n    for sentence in filename:\n        sentence=sentence.strip()\n        #print(sentence)\n        tokens=[token for token in tokenizer(sentence) if token!=u\"\"]\n        for pos,token in enumerate(tokens):\n            i=vocabulary.setdefault(token,len(vocabulary))\n            start=max(0,pos-window_size)\n            end=min(len(tokens),pos+window_size+1)\n            for pos2 in range(start,end):\n                if pos2==pos: \n                    continue\n                j=vocabulary.setdefault(tokens[pos2],len(vocabulary))\n                data.append(1.); row.append(i); col.append(j);\n    \n    cooccurrence_matrix=coo_matrix((data,(row,col)))\n    return vocabulary,cooccurrence_matrix\n#voca,coo=create_cooccurrence_matrix(df.question_text.str.lower().values,word_tokenize,100,dictOfWords)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07f87700a1171c0c1c0d3e563a2459f9e68a7b2e"},"cell_type":"markdown","source":"**splitting and vectorizing**"},{"metadata":{"trusted":true,"_uuid":"1c5216d7038b6a6fc7cdd7d0194cf4cf8f5e949b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n\n\nX_train, X_test, y_train, y_test = train_test_split(df['question_text'],\n                                                    df['target'],\n                                                    test_size=0.2)\n#tf_vectorizer = TfidfVectorizer().fit(df_under['question_text'])\n#tf_vectorizer = CountVectorizer(tokenizer=word_tokenize,stop_words).fit(df['question_text'])\nX_train = tf_vectorizer.transform(X_train)\nX_test = tf_vectorizer.transform(X_test)\nX_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04a680bab8f3a8fe2ad8802b1d2761bf03987be9"},"cell_type":"code","source":"#from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nclf=LogisticRegression(C=1.0,multi_class='multinomial',penalty='l2', solver='saga',n_jobs=-1)\nclf.fit(X_train, y_train)\n#clf = MultinomialNB().fit(X_train, y_train)\npredicted = clf.predict(X_test)\nnp.mean(predicted == y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd65d4ac8c6a4a35c95cd78687345601af4107a6"},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\n\nf1_score(y_test, predicted,average=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80790e9798092407b93d62547d568ca34d1e2e36"},"cell_type":"markdown","source":"### Submission dataset"},{"metadata":{"trusted":true,"_uuid":"6d2a83008b4a507d9c606a5e0f120b00c0d2caf4"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv')\nX_submission = tf_vectorizer.transform(df_test['question_text'])\npredicted_test = clf.predict(X_submission)\n\ndf_test['prediction'] = predicted_test\nsubmission = df_test.drop(columns=['question_text'])\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50fba64d48f018a5db8f80f1e0657aca58848005"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}