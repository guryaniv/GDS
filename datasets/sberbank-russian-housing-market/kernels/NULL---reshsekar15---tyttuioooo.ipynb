{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fbcd76f-c899-bf50-b95d-1597c3f876dd"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05313156-727d-d4ec-e5da-0ea3a7d5ea3a"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1825a5b-d578-cda3-bfba-5a07d3bd944f"
      },
      "outputs": [],
      "source": [
        "# let us perform a linear regression - start with a few features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e92599d4-dd86-df0b-17cc-6a8f3f455b1e"
      },
      "outputs": [],
      "source": [
        "def feature_summary(data):\n",
        "    n_row=data.shape[0]\n",
        "    features=pd.DataFrame()\n",
        "    features_names=[]\n",
        "    features_type = []\n",
        "    features_counts=[]\n",
        "    features_missing=[]\n",
        "    names=data.columns.values\n",
        "    for i in names:\n",
        "        features_names.append(i)\n",
        "        features_type.append(type(data.ix[1,i]))\n",
        "        features_counts.append(data[i].value_counts().count())\n",
        "        features_missing.append(data[data[i].isnull()].shape[0])\n",
        "    features['name']=features_names\n",
        "    features['type'] = features_type\n",
        "    features['value counts']=features_counts\n",
        "    features['missing']=features_missing\n",
        "    features['percentage_missing']=features['missing']/n_row\n",
        "    return (features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ac5247f5-a622-7aaf-c46a-1400bf352305"
      },
      "outputs": [],
      "source": [
        "feature_summ = feature_summary(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5dd4011f-ed1a-36a0-900c-5da39993fa1d"
      },
      "outputs": [],
      "source": [
        "column_names = feature_summ[feature_summ['percentage_missing'] < 0.20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51882c18-a82d-1c21-dc9c-0532f4abfc1f"
      },
      "outputs": [],
      "source": [
        "column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75f2eae0-24b3-c82e-613f-2fd9fe16de17"
      },
      "outputs": [],
      "source": [
        "df_train_quant = df_train.select_dtypes(include=['int64', 'floating'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66c55b92-f5b3-b1ef-f9ef-88a99fb0061e"
      },
      "outputs": [],
      "source": [
        "df_train_quant.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c59a5e3-a817-29ad-15e7-372e69ccddfd"
      },
      "outputs": [],
      "source": [
        "corr_mat = pd.DataFrame()\n",
        "column_names = np.arange(0)\n",
        "correlation_values = np.arange(0)\n",
        "for i in df_train_quant.columns.values:\n",
        "    column_names = np.append(column_names, i)\n",
        "    correlation_values = np.append(correlation_values,df_train_quant[i].corr(df_train_quant['price_doc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f141436-58be-103e-e1d3-4b98664025f5"
      },
      "outputs": [],
      "source": [
        "corr_mat['columns'] = column_names\n",
        "corr_mat['value'] = correlation_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c35044a2-e0fb-8cbf-ae7b-9b3bb60af098"
      },
      "outputs": [],
      "source": [
        "corr_mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e49a98b-a27c-e1f6-9b06-7853d867bb82"
      },
      "outputs": [],
      "source": [
        "corr_mat.plot(kind = 'bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1532911-5daf-c7ad-b8e3-e499e2310b17"
      },
      "outputs": [],
      "source": [
        "# using the above poorly constructed plot, and if you look closely you'll see why i chose 0.20\n",
        "# as a theshold\n",
        "corr_mat_select = corr_mat[corr_mat['value'].abs() > 0.20 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa137323-85e2-99b3-2435-9a051ab0bbc3"
      },
      "outputs": [],
      "source": [
        "corr_mat_select.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e385ad4e-3121-7148-318f-3dcab5e96033"
      },
      "outputs": [],
      "source": [
        "# Implementing Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "922963e1-977a-ebb2-518b-a7c063dcdb0c"
      },
      "outputs": [],
      "source": [
        "# let us use linear regression to solve this\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model as lm "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0976aaa8-287b-d019-dc0e-5a4d59c16148"
      },
      "outputs": [],
      "source": [
        "df_train_quant = df_train[corr_mat_select['columns']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4b178df-a4a2-0496-6c67-2be9c4ab5e29"
      },
      "outputs": [],
      "source": [
        "df_train_quant.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "175bd16a-96fa-e1a8-8183-60c2d660ee17"
      },
      "outputs": [],
      "source": [
        "#handling missing values using mean values? we can explore more methods for this at a later\n",
        "#stage\n",
        "#df_train_quant = df_train_quant.drop('timestamp', 1)\n",
        "for i in range(1,len(df_train_quant.columns)):\n",
        "       df_train_quant.iloc[:,i] = df_train_quant.iloc[:,i].fillna(df_train_quant.iloc[:,i].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0977359-4c7f-cc14-0481-7aac40a157b7"
      },
      "outputs": [],
      "source": [
        "y = df_train_quant['price_doc']\n",
        "df_train_quant = df_train_quant.drop('price_doc', 1)\n",
        "X_train,X_test,y_train,y_test = train_test_split(df_train_quant,y,test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9ae01f4c-f166-77bc-1f05-a3875c906562"
      },
      "outputs": [],
      "source": [
        "model = lm.LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b73b0ac0-8fdb-43e5-33d9-b59cbeb76313"
      },
      "outputs": [],
      "source": [
        "predy = model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e38d1b27-ee52-8aff-a37a-70d2a040712c"
      },
      "outputs": [],
      "source": [
        "residuals = (predy - y_train) * (predy - y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60f712ed-0f31-d526-74d1-154b4c20a8fd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "model_plot = pd.DataFrame()\n",
        "model_plot['y'] = y_train\n",
        "model_plot['residuals'] = residuals\n",
        "plt.plot(y_train, residuals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f12f308a-04f3-11e1-ca01-654a1c7acab2"
      },
      "outputs": [],
      "source": [
        "# We can see that the errors start increasing after the value is 17500. Maybe\n",
        "# we can set this as a threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da60dd63-0213-35c3-ed21-fefaa0a4a629"
      },
      "outputs": [],
      "source": [
        "predy = model.predict(X_test)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,predy)\n",
        "corr_mat_select = corr_mat_select.drop(275)\n",
        "test = df_test[corr_mat_select['columns']]\n",
        "for i in range(1,len(test.columns)):\n",
        "       test.iloc[:,i] = test.iloc[:,i].fillna(test.iloc[:,i].mean())\n",
        "result = model.predict(test)\n",
        "result = pd.DataFrame(result)\n",
        "result['id'] = df_test['id']\n",
        "result['price_doc'] = result.iloc[:,0].abs()\n",
        "result = result.drop(0,1)\n",
        "result['price_doc'] = result['price_doc'].round(2)\n",
        "result.to_csv(\"output_10.csv\", index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66911f73-adfa-0443-a823-7f30f4f9fa75"
      },
      "outputs": [],
      "source": [
        "# The above error plot gives us some insight. \n",
        "# The increasing value of error as y value increases shows us that we need to transform y values\n",
        "# or break it down.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "824861d2-4576-1993-e5b5-823509c1216e"
      },
      "outputs": [],
      "source": [
        "# Let us separate our models by breaking our dataframes based on y values on the set threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "447cc7e7-640e-3e50-b880-efeee9a0b318"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "    # Input data files are available in the \"../input/\" directory.\n",
        "    # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "from subprocess import check_output\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model as lm \n",
        "from sklearn.metrics import r2_score\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "def feature_summary(data):\n",
        "    n_row=data.shape[0]\n",
        "    features=pd.DataFrame()\n",
        "    features_names=[]\n",
        "    features_type = []\n",
        "    features_counts=[]\n",
        "    features_missing=[]\n",
        "    names=data.columns.values\n",
        "    for i in names:\n",
        "        features_names.append(i)\n",
        "        features_type.append(type(data.ix[1,i]))\n",
        "        features_counts.append(data[i].value_counts().count())\n",
        "        features_missing.append(data[data[i].isnull()].shape[0])\n",
        "    features['name']=features_names\n",
        "    features['type'] = features_type\n",
        "    features['value counts']=features_counts\n",
        "    features['missing']=features_missing\n",
        "    features['percentage_missing']=features['missing']/n_row\n",
        "    return (features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77a6a2c7-a973-7933-0c74-a99cf2a647b8"
      },
      "outputs": [],
      "source": [
        "def normalize(test_series):\n",
        "    normalized = np.log(test_series)\n",
        "    return normalized\n",
        "def denormalize(test_series):\n",
        "    denormalized = np.exp(test_series)\n",
        "    return denormalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8710879-50ea-c947-fa3b-1a4524902a6b"
      },
      "outputs": [],
      "source": [
        "y_log = normalize(df_train['price_doc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ede2540-bbb9-dc33-0e57-aeb664012ab1"
      },
      "outputs": [],
      "source": [
        "#column_names = feature_summ[feature_summ['percentage_missing'] < 0.20]\n",
        "df_train_quant = df_train.select_dtypes(include=['int64', 'floating'])\n",
        "corr_mat = pd.DataFrame()\n",
        "column_names = np.arange(0)\n",
        "correlation_values = np.arange(0)\n",
        "for i in df_train_quant.columns.values:\n",
        "    column_names = np.append(column_names, i)\n",
        "    correlation_values = np.append(correlation_values,df_train_quant[i].corr(df_train_quant['price_doc']))\n",
        "corr_mat['columns'] = column_names\n",
        "corr_mat['value'] = correlation_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed952248-36ef-b93a-bf38-7c7cb99d9c1c"
      },
      "outputs": [],
      "source": [
        "# using the above poorly constructed plot, and if you look closely you'll see why i chose 0.20\n",
        "# as a theshold\n",
        "corr_mat_select = corr_mat[corr_mat['value'].abs() > 0.20 ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42bd2f62-e888-f46c-b1b3-2eb2caffe488"
      },
      "outputs": [],
      "source": [
        "# let us use linear regression to solve this\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model as lm \n",
        "df_train_quant = df_train[corr_mat_select['columns']]\n",
        "#handling missing values using mean values? we can explore more methods for this at a later\n",
        "#stage\n",
        "#df_train_quant = df_train_quant.drop('timestamp', 1)\n",
        "for i in range(1,len(df_train_quant.columns)):\n",
        "       df_train_quant.iloc[:,i] = df_train_quant.iloc[:,i].fillna(df_train_quant.iloc[:,i].mean())\n",
        "y_normalized = normalize(df_train_quant['price_doc'])\n",
        "y_original = df_train_quant['price_doc']\n",
        "df_train_quant = df_train_quant.drop('price_doc', 1)\n",
        "X_train,X_test,y_train,y_test = train_test_split(df_train_quant,y_normalized,test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f157951-fc93-bf39-d268-6554d9875768"
      },
      "outputs": [],
      "source": [
        "model = lm.LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30009bb9-f9a0-a094-0d5f-73b3b2fa5c0d"
      },
      "outputs": [],
      "source": [
        "predy = model.predict(X_train)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(denormalize(predy), denormalize(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7922c663-5c41-5f9f-8446-519971235852"
      },
      "outputs": [],
      "source": [
        "denormalize(predy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d03398d-3482-4e01-601b-5582c8547fa6"
      },
      "outputs": [],
      "source": [
        "denormalize(y_train)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}