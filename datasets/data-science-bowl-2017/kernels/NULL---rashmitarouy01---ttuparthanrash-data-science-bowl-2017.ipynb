{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23f083dc-9b8f-ad39-e6b0-b51456a08288"
      },
      "outputs": [],
      "source": [
        "#Import Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dicom\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import math\n",
        "\n",
        "#defining the pixel size and the slice count\n",
        "IMG_SIZE_PX = 50\n",
        "SLICE_COUNT = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9f0d0db-c06e-37b0-0c4c-60b837c0d2dc"
      },
      "outputs": [],
      "source": [
        "stage1_data = np.load('stage1data-50-50-20.npy')\n",
        "\n",
        "train_data = stage1_data[:]\n",
        "print(train_data.shape)\n",
        "\n",
        "train_features = []\n",
        "train_labels = []\n",
        "\n",
        "\n",
        "for i in range(0,train_data.shape[0]):\n",
        "    train_features = train_features + [(train_data[i,0])[0]]\n",
        "    train_labels = train_labels + [(train_data[i,1])[1]]\n",
        "    \n",
        "for i in range(0,len(train_features)):\n",
        "    for j in range(0,len(train_features[i])):\n",
        "        for k in range(0,len((train_features[i])[j])):\n",
        "                       if ((train_features[i])[j])[k] == -2000:\n",
        "                           ((train_features[i])[j])[k] = 0\n",
        "\n",
        "train_features = np.array(train_features)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "nsamples, nx, ny = train_features.shape\n",
        "d2_train_features = train_features.reshape((nsamples,nx*ny))\n",
        "'''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(d2_train_features)\n",
        "d2_train_features = scaler.transform(d2_train_features)\n",
        "'''\n",
        "print(train_features.shape)\n",
        "print(d2_train_features.shape)\n",
        "print(train_labels.shape)\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8449277-f02c-6b56-2ed1-bfde92f7981b"
      },
      "outputs": [],
      "source": [
        "stage2_data = np.load('stage2data-50-50-20.npy')\n",
        "\n",
        "print('Test Data')\n",
        "test_data = stage2_data[:]\n",
        "print(test_data.shape)\n",
        "\n",
        "test_features = []\n",
        "\n",
        "for i in range(0,test_data.shape[0]):\n",
        "    test_features = test_features + [(test_data[i,0])[0]]\n",
        "\n",
        "for i in range(0,len(test_features)):\n",
        "    for j in range(0,len(test_features[i])):\n",
        "        for k in range(0,len((test_features[i])[j])):\n",
        "                       if ((test_features[i])[j])[k] == -2000:\n",
        "                           ((test_features[i])[j])[k] = 0    \n",
        "    \n",
        "test_features = np.array(test_features)\n",
        "nsamples, nx, ny = test_features.shape\n",
        "d2_test_features = test_features.reshape((nsamples,nx*ny))\n",
        "'''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(d2_test_features)\n",
        "d2_test_features = scaler.transform(d2_test_features)\n",
        "'''\n",
        "print('Test Data')\n",
        "print(test_features.shape)\n",
        "print(d2_test_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1822ee0-eb49-a05c-c118-97e237bd95af"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "#Set the tuning parameter\n",
        "params = {'C':[1000,1200,1400], 'tol': [0.00001]}\n",
        "\n",
        "##Create the Logistic Regression model\n",
        "logreg = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
        "##Use the Grid Search with the params\n",
        "clf = GridSearchCV(logreg,params, scoring='log_loss', refit='True', n_jobs=-1, cv=5)\n",
        "##Fit the models\n",
        "clf_fit = clf.fit(d2_train_features,train_labels)\n",
        "\n",
        "test_pred_labels= clf.predict(d2_test_features)\n",
        "\n",
        "test_pred_labProb = clf.predict_proba(d2_test_features)\n",
        "pred = []\n",
        "for i in range(0,test_pred_labProb.shape[0]):\n",
        "    pred = pred + [test_pred_labProb[i,1]]\n",
        "#print(pred)\n",
        "'''\n",
        "test_pred_logProb = clf.predict_log_proba(d2_test_features)\n",
        "pred = []\n",
        "for i in range(0,test_pred_logProb.shape[0]):\n",
        "    pred = pred + [test_pred_logProb[i,1]]\n",
        "'''\n",
        "logisticPatients_df = pd.read_csv('.../Data/stage2_sample_submission.csv')\n",
        "logisticPatients_df['cancer'] = pd.Series(pred)\n",
        "logisticPatients_df.to_csv(\".../Data/stage2_pred_log_3.csv\",index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}