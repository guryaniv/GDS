{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport math\nimport cv2\n\ntf.logging.set_verbosity(tf.logging.WARN)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"IMG_SIZE = 28\ndf = pd.read_csv('../input/train.csv') #df.head()\nlabels = df['label'].values\nfeatures = df.drop(['label'], axis=1).values.reshape((-1, IMG_SIZE, IMG_SIZE)) / 255.\ntest_features = pd.read_csv('../input/test.csv').values.reshape((-1, IMG_SIZE, IMG_SIZE)) / 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c85896956ebb28e15d5125a27217c5eead6f30e","collapsed":true},"cell_type":"code","source":"def auto_crop(img):\n    horz_margin = np.mean(img, axis=0)\n    vert_margin = np.mean(img, axis=1)\n    xstart = 0 \n    xend = img.shape[1]\n    ystart = 0 \n    yend = img.shape[0]\n    img2 = cv2.copyMakeBorder(img, 0, img.shape[0], 0, img.shape[1], cv2.BORDER_CONSTANT, value=[0])\n    while xstart < xend-1:\n        if horz_margin[xstart] > 1/img.shape[0]:\n            break\n        xstart += 1\n    while xstart < xend-1:\n        if horz_margin[xend-1] > 1/img.shape[0]:\n            break\n        xend -= 1\n    while ystart < yend-1:\n        if vert_margin[ystart] > 1/img.shape[1]:\n            break\n        ystart += 1\n    while ystart < yend-1:\n        if vert_margin[yend-1] > 1/img.shape[1]:\n            break\n        yend -= 1\n    rect_size = max(yend - ystart, xend - xstart)\n\n    return cv2.resize(img2[ystart:ystart+rect_size, xstart:xstart+rect_size], dsize=img.shape, interpolation=cv2.INTER_NEAREST)\n\ndef augment_dataset(feature, label, augment_count):\n    aug_features = []\n    aug_labels = []\n    for i in range(augment_count+1):\n        ch1 = feature\n        if i!=0:\n            JITTER = 4\n            pts1 = np.array(np.random.uniform(-JITTER, JITTER, size=(4,2))+np.array([[0,0],[0,ch1.shape[1]],[ch1.shape[0],0],[ch1.shape[0],ch1.shape[1]]])).astype(np.float32)\n            pts2 = np.array([[0,0],[0,ch1.shape[1]],[ch1.shape[0],0],[ch1.shape[0],ch1.shape[1]]]).astype(np.float32)\n\n            M = cv2.getPerspectiveTransform(pts1,pts2)\n\n            ch1 = cv2.warpPerspective(ch1,M,ch1.shape)\n            ch1 = ch1 + np.random.uniform(low=-0.3, high=0.3, size=ch1.shape).clip(0, 1)\n        \n        aug_features.append(ch1)\n        aug_labels.append(label)\n    return aug_features, aug_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"499917f4131deb117bf2d52da45f525c1fd93092","collapsed":true},"cell_type":"code","source":"def train_generator(features, labels, augment_count=10, imgs_per_batch = 10):\n    while True:\n        for i in range(0, len(features), imgs_per_batch):\n            features_batch = []\n            labels_batch = []\n            for j in range(i, min(len(features), i+imgs_per_batch)):\n                cur_features, cur_labels = augment_dataset(features[j], labels[j], augment_count)\n                features_batch.extend(cur_features)\n                labels_batch.extend(cur_labels)\n            yield np.array(features_batch),np.array(labels_batch)\n\ndef steps_per_epoch(features, imgs_per_batch=10):\n    return int(math.ceil(len(features)/imgs_per_batch))\n\ndef test_generator(features):\n    yield np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5a9e2857395ce4cebd7604bd9f4314ec09b351d","collapsed":true},"cell_type":"code","source":"model = tf.keras.models.Sequential()\nmodel.add(tf.keras.layers.Reshape((IMG_SIZE, IMG_SIZE, 1), input_shape=(IMG_SIZE, IMG_SIZE, )))\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(rate=0.3))\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same', activation='relu'))\nmodel.add(tf.keras.layers.BatchNormalization())\nmodel.add(tf.keras.layers.Dropout(rate=0.3))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\n\nmodel.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n              optimizer=tf.keras.optimizers.Adam(lr=0.001),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca74802babcac6b69caa8ea4c2ea43e11287db1f"},"cell_type":"code","source":"EPOCHS=100\nAUG_COUNT = 3\nIMGS_PER_BATCH = 70\nmodel.fit_generator(train_generator(features, labels, AUG_COUNT, IMGS_PER_BATCH),\n                    epochs=EPOCHS,\n                    steps_per_epoch=steps_per_epoch(features, IMGS_PER_BATCH),\n                    validation_data=train_generator(features, labels, AUG_COUNT, IMGS_PER_BATCH),\n                    validation_steps=steps_per_epoch(features, IMGS_PER_BATCH),\n                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5,monitor='val_loss')],\n                    verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1c4addb1a76900e7a05deb60813fc7b45ab00ef"},"cell_type":"code","source":"X_train, X_validate, y_train, y_validate = train_test_split(features, labels, test_size=0.1)\npredicted = np.argmax(model.predict_generator(test_generator(X_validate), steps=1), axis=1)\ntmp = pd.DataFrame(sklearn.metrics.confusion_matrix(y_validate, predicted))\nplt.subplots(figsize=(10,10)) \nsns.heatmap(tmp, annot=True, fmt='.1f')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbaa561c0f6284bd8d58637ffed42bbd8e90467d"},"cell_type":"code","source":"predicted = np.argmax(model.predict_generator(test_generator(test_features), steps=1), axis=1)\nout_df = pd.DataFrame({'Label': predicted})\nout_df['ImageId'] = out_df.index + 1\nout_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bad62d796e82cba751aa5bb9ae2424b7db71c812"},"cell_type":"code","source":"model.save('mnist_model.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}