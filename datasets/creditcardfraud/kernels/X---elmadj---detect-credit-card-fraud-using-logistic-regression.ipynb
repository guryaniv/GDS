{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4614ef06-eee5-993a-3f3d-cff50aa6fa64"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f00c2a1-2f6a-70b2-302c-57c70aa79832"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plot\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "raw_data= pd.read_csv('../input/creditcard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eaa92369-ce48-27ee-d21a-4663861b9336"
      },
      "source": [
        "**Check if classes are imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4098c117-33e7-1d56-3eda-95b04e7ec8d4"
      },
      "outputs": [],
      "source": [
        "count_classes = pd.value_counts(raw_data['Class'], sort = True).sort_index()\n",
        "count_classes.plot(kind = 'bar')\n",
        "plot.title(\"Fraud class histogram\")\n",
        "plot.xlabel(\"Class\")\n",
        "plot.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f9a288fa-8eb8-2e73-0b1f-eae1c1f04d12"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "raw_data['normAmount'] = StandardScaler().fit_transform(raw_data['Amount'].values.reshape(-1, 1))\n",
        "data = raw_data.drop(['Time','Amount'],axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80e1e616-593b-729c-320a-2a16dd3cb485"
      },
      "outputs": [],
      "source": [
        "X = data.ix[:, data.columns != 'Class']\n",
        "y = data.ix[:, data.columns == 'Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bcb248c6-3101-da4c-f618-c95cb4328286"
      },
      "outputs": [],
      "source": [
        "# Number of data points in the minority class\n",
        "number_records_fraud = len(data[data.Class == 1])\n",
        "fraud_indices = np.array(data[data.Class == 1].index)\n",
        "\n",
        "nonfraud_indices = data[data.Class == 0].index\n",
        "\n",
        "random_nonfraud_indices = np.random.choice(nonfraud_indices, number_records_fraud, replace = False)\n",
        "random_nonfraud_indices = np.array(random_nonfraud_indices)\n",
        "\n",
        "# concatenate everything together\n",
        "sampled_indices = np.concatenate([fraud_indices,random_nonfraud_indices])\n",
        "\n",
        "# Under sample dataset\n",
        "sampled_data = data.iloc[sampled_indices,:]\n",
        "\n",
        "X_sampled = sampled_data.ix[:, sampled_data.columns != 'Class']\n",
        "y_sampled = sampled_data.ix[:, sampled_data.columns == 'Class']\n",
        "\n",
        "# Showing ratio\n",
        "print(\"Percentage of normal transactions: \", len(sampled_data[sampled_data.Class == 0])/len(sampled_data))\n",
        "print(\"Percentage of fraud transactions: \", len(sampled_data[sampled_data.Class == 1])/len(sampled_data))\n",
        "print(\"Total number of transactions in resampled data: \", len(sampled_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6639c494-56f8-cdbb-2d25-9480841165f0"
      },
      "source": [
        "**Divide into training and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be40ca92-eda0-e0d0-1e10-0e5a6f29fec5"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sampled,y_sampled,test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41ddf060-189b-6414-696c-d28865b8c158"
      },
      "source": [
        "fit a decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70fb4bfc-3e95-4543-f501-a9a696b274a1"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "166ddbca-b783-b409-a557-5b06a73ee78f"
      },
      "outputs": [],
      "source": [
        "clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "225b993b-0974-736b-7058-db9fc6e40113"
      },
      "source": [
        "not good enough for a fraud detection system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3574967-c689-0b4b-c18f-3c4c9aad9177"
      },
      "outputs": [],
      "source": [
        "clf.get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2270f401-d9ce-faa4-e162-bb831ba3bdbd"
      },
      "source": [
        "    **Try logisitic regression with k fold validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e003d036-048e-b0bc-7cbe-5b8f423e634c"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cross_validation import KFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report, precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95f9c4a4-1c50-db4b-6d36-3fccc756e426"
      },
      "outputs": [],
      "source": [
        "def printing_Kfold_scores(x_train_data,y_train_data,c_param):\n",
        "    fold = KFold(len(y_train_data),5,shuffle=False) \n",
        "    \n",
        "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score', 'Mean '])\n",
        "    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
        "    j = 0\n",
        "    for c_param in c_param_range:\n",
        "        print('C parameter: ', c_param)\n",
        "        \n",
        "        recall_accs = []\n",
        "        for iteration, indices in enumerate(fold,start=1):\n",
        "\n",
        "            # Call the logistic regression model with a certain C parameter\n",
        "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
        "\n",
        "            # Use the training data to fit the model. In this case, we use the portion of the fold to train the model\n",
        "            # with indices[0]. We then predict on the portion assigned as the 'test cross validation' with indices[1]\n",
        "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
        "\n",
        "            # Predict values using the test indices in the training data\n",
        "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
        "\n",
        "            # Calculate the recall score and append it to a list for recall scores representing the current c_parameter\n",
        "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
        "            recall_accs.append(recall_acc)\n",
        "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
        "\n",
        "        # The mean value of those recall scores is the metric we want to save and get hold of.\n",
        "        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
        "        j += 1\n",
        "        print('')\n",
        "        print('Mean recall score ', np.mean(recall_accs))\n",
        "        print('')\n",
        "\n",
        "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
        "    \n",
        "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
        "    print('*********************************************************************************')\n",
        "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
        "    print('*********************************************************************************')\n",
        "    \n",
        "    return best_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65e37b85-2bf6-8bad-f3f2-1ac2a3d2ec40"
      },
      "outputs": [],
      "source": [
        "best = printing_Kfold_scores(X_train,y_train_data,c_param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e1d67fe-bd69-729f-0f2d-d4b875945372"
      },
      "outputs": [],
      "source": [
        "lr.fit(X_train,y_train.values.ravel())\n",
        "y_pred_proba = lr.predict_proba(X_train)\n",
        "    \n",
        "precision_recall_curve(y_train, y_pred_proba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc1d20eb-6436-4fe2-26d0-1804dc007df2"
      },
      "outputs": [],
      "source": [
        "# Call the logistic regression model with the best C parameter w/ to recall\n",
        "lr = LogisticRegression(C = 0.01, penalty = 'l1')\n",
        "\n",
        "lr.fit(X_train,y_train.values.ravel())\n",
        "y_pred_undersample = lr.predict(X_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "669f4767-6a1a-eeba-7fb5-b2df9a9f9a65"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds =  precision_recall_curve(y_train, y_pred_undersample)\n",
        "plt.plot(recall, precision, color='navy', label='Precision-Recall curve')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05655688-1298-ba1c-998c-bc70bac5ae47"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}