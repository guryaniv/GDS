{"cells":[{"metadata":{"trusted":true,"_uuid":"b137820579d21f1e1c1846df8946cfb7810d8676"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\n\nfrom PIL import Image\nfrom keras import backend as K\nfrom keras.callbacks import TensorBoard\nfrom keras.models import Sequential\nfrom keras.layers import Activation , Conv2D , MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom keras.metrics import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras import models\nfrom keras.layers.core import Dense , Flatten , Dropout \nfrom imgaug import augmenters as iaa\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nimport cv2 \nprint(os.listdir(\"../input\"))\n\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b3afef479f499285da946aeb23e6b1d4b3cbcb6"},"cell_type":"code","source":"train_names = \"..//input//train.csv\"\npredict_names = \"..//input//sample_submission.csv\"\ntrain_imgs = \"..//input//train//\" \npredict_imgs = \"..//input//test//\"\n\ntrain_names = pd.read_csv(train_names)\ntrain_names.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b66d92d9156e83f1fb7f99a83e9b0f0e3ff7c24"},"cell_type":"code","source":"trainX , testX , trainY , testY = train_test_split(train_names['Id'], train_names['Target'], test_size=0.3 , random_state=42)\n# print(len(trainX)); print(len(testX))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c1c1a7d5483c0c3815e9bdadf98ecf75c0bcce3"},"cell_type":"code","source":"# Doing the operation with images\ndef merging_imgs(img_size , name_of_image, train_predict_imgs_path):\n    red_path = train_predict_imgs_path + str(name_of_image+\"_red.png\")\n    green_path = train_predict_imgs_path + str(name_of_image+\"_green.png\") \n    blue_path = train_predict_imgs_path + str(name_of_image+\"_blue.png\")\n    yellow_path = train_predict_imgs_path + str(name_of_image+\"_yellow.png\")\n\n    red = cv2.imread(red_path, cv2.IMREAD_UNCHANGED)\n    green = cv2.imread(green_path, cv2.IMREAD_UNCHANGED)\n    yellow = cv2.imread(yellow_path, cv2.IMREAD_UNCHANGED)\n    blue = cv2.imread(blue_path, cv2.IMREAD_UNCHANGED)\n    \n    img = np.stack((red , green , blue ), axis=-1)\n    img = cv2.resize(img , (img_size))\n    return img\n\ndef data_maker(train_data , target_data, img_size, train_predict_img_dir, no_of_images):\n    img_dir = os.listdir(train_predict_img_dir)\n    \n    train_val_lst = train_data.tolist() \n    target_val_lst = target_data.tolist()\n    \n    img_lst =[]; target_lst= []\n    \n#     z =0\n    for i in train_data[:int(no_of_images)]:\n#         print(z)\n        val = train_val_lst.index(i)\n        target_val = target_val_lst[val]\n        small_lst = target_val.split()\n        len_of_target = len(target_val.split())\n        \n#         z = z +1\n        img = merging_imgs(img_size , i, train_predict_img_dir)  \n        for i in range(len_of_target):\n            if i%2 == 0:\n                img_lst.append(img)\n                target_lst.append(small_lst[i])\n            else:\n                img_lst.append(augment(img))\n                target_lst.append(small_lst[i])\n\n    return np.array(img_lst) , np.array([int(i) for i in target_lst])\n\n\ndef augment(image):\n        augment_img = iaa.Sequential([\n            iaa.OneOf([\n                iaa.Affine(rotate=0),\n                iaa.Affine(rotate=90),\n                iaa.Affine(rotate=180),\n                iaa.Affine(rotate=270),\n                iaa.Fliplr(0.5),\n                iaa.Flipud(0.5),\n            ])], random_order=True)        \n        image_aug = augment_img.augment_image(image)\n        return image_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb71a2df7f42f58258ae46c4fb437c02a59228e5","scrolled":true},"cell_type":"code","source":"test_img_data , test_target_data = data_maker(testX , testY ,(224, 224), train_imgs, 10000) # 224\nimgs , targets = data_maker(trainX , trainY , (224, 224), train_imgs, 10000)\n\n# print(test_img[0])\nprint(len(test_img_data)); print(len(test_target_data))\nprint(len(imgs)); print(len(targets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68524be40976619083d6e69cd22d24f1a3c6d473","_kg_hide-output":true},"cell_type":"code","source":"# Finding the channels in images\n# print(imgs)\nprint(imgs[0].shape)\n# print(imgs[0])\n\n# Output layer nurons\noutput_nurons = len(np.unique(targets))\nprint(output_nurons)\n\n# Funtion for reshaping the data\ndef reshaping(data):\n    lst = []\n    shape = data.shape\n    print(\"shape->\", shape)\n    for img in data:\n        imgs_data = np.resize(img, (shape[1], shape[2], 3))\n        lst.append(imgs_data)\n        print(imgs_data.shape)\n        print(imgs_data[:10])\n    return np.array(lst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daa89df02c58088758f781b368497be902140c70"},"cell_type":"code","source":"# Now, Displaying the 50 images\nfor i in range(50):\n        if (i % 5) == 0:\n            fig, ax = plt.subplots(1,5,figsize=(25,5)) \n        else:\n            k = i\n            for j in range(5):\n                ax[j].imshow(imgs[k])\n                k = k + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64cccd73744e861e9e8092d03a7c6b86b2c028ba"},"cell_type":"markdown","source":"1. ###  Now , Using the One Hot Encoding"},{"metadata":{"trusted":true,"_uuid":"86b368b19ac2445f99d76d5fa2c8b05d1b75f28f"},"cell_type":"code","source":"# One Hot Encoding for the target values\ndef one_hot_encoding(list_of_target):\n    one_hot_lst = []\n    lst = pd.get_dummies(np.unique(list_of_target))\n    for i in list_of_target:\n        a = np.array(lst[i]).tolist()\n        one_hot_lst.append(a)\n    return np.array(one_hot_lst) , len(lst) , lst , np.unique(list_of_target)\n\nprint(one_hot_encoding(targets)[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faac20cbaba6f0e53257756095f60d9a9c84c62e"},"cell_type":"markdown","source":"### Now , Using the Image Data Genrator"},{"metadata":{"trusted":true,"_uuid":"f4208ef06e8865d753fd2b87e5f23d4182e7a63f"},"cell_type":"code","source":"\ndef image_generator(files,label_file, batch_size): \n    while True:\n        index = np.random.choice(len(files),batch_size)\n\n        batch_input = []\n        batch_output = [] \n          \n        for i in index:\n            image = augment(files[i])\n            batch_input += [ image ]\n            batch_output += [ label_file[i] ]\n          # Return a tuple of (input,output) to feed the network\n        batch_x = np.array( batch_input )\n        batch_y = np.array( batch_output )\n        \n        yield( batch_x, batch_y )\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7375f566996fdf5e96be886ac601cf9420a6053"},"cell_type":"markdown","source":"###  Funtion to load & save Model****"},{"metadata":{"trusted":true,"_uuid":"ec8700e6a0dd9c60b0ad666fff0762b6ef1def45"},"cell_type":"code","source":"def saving_model(model_instance,model_name):\n    model_instance.save(str(model_name))\n    print(\"Model Saved\")\n    \ndef loading_model(model_name):\n    model = models.load_model(str(model_name))\n    print(\"Model Loaded\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7722e9b48560007aa29c37d082ff03de2004ad0"},"cell_type":"markdown","source":"###  Making the Model"},{"metadata":{"trusted":true,"_uuid":"e56e815cab52fada6ed065530f5386ee935e6e45"},"cell_type":"code","source":"from keras.models import Sequential , Model\nfrom keras.layers import BatchNormalization , GlobalAveragePooling2D, GlobalAveragePooling1D, Input\nfrom keras.layers.core import Flatten, Dense, Dropout\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D , Conv2D\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.optimizers import SGD\n# from keras import backend as K\n# K.clear_session()\n\ndef model_call(input_shape , output_nurons):\n    \n    input_tensor = Input(shape= input_shape)\n    \n#     base_model = keras.applications.vgg16.VGG16(input_tensor = input_tensor, include_top = True , weights = 'imagenet')        \n#     base_model = keras.applications.xception.Xception(input_tensor = input_tensor, include_top = True , weights = 'imagenet')\n    \n    base_model = InceptionV3(input_tensor = input_tensor, include_top = True , weights = 'imagenet')\n#     for layer in base_model.layers[:249]:\n#         layer.trainable = False\n        \n    x = base_model.output\n    x =Dense(1024 , activation = 'relu')(x)\n    predict = Dense(output_nurons , activation = 'sigmoid')(x)\n    model = Model(inputs = input_tensor , outputs= predict)\n    return model\n\nmodel = model_call((224,224, 3), 28)\nmodel.summary()\n# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n\ntrain_img = imgs; train_target = one_hot_encoding(targets)[0]\ntest_img = test_img_data; test_target = one_hot_encoding(test_target_data)[0]\n\nhistory = model.fit_generator(image_generator(train_img, train_target, 32),\n                    steps_per_epoch=int(len(train_img) / 32),\n                    validation_data=image_generator(test_img, test_target, 32),\n                    validation_steps=int(len(test_img) / 32),\n                    epochs=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6766d09847687e1cf158c25324861c5496792f2f"},"cell_type":"code","source":"# Saving the model \n# saving_model(model , \"model_v2.model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8169d3ec74408fa726d3f42e1549e1b507b854f8"},"cell_type":"code","source":"print(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a978b7016b81bb1abfc1629e698ae992786482f3"},"cell_type":"code","source":"# plt\nplt.plot(history.epoch, history.history['acc'] , label=\"acc\")\nplt.plot(history.epoch, history.history['val_acc'] , label = \"val_acc\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76a1162a930406db9140822d120bee6629252801","scrolled":true},"cell_type":"code","source":"# plt\nplt.plot(history.epoch, history.history['loss'] , label = \"loss\")\nplt.plot(history.epoch, history.history['val_loss'] , label = \"val_loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4e63ffafb16b813a78127adbc80994243cfd20a"},"cell_type":"code","source":"# Now Making the Prediction and Evaluating the model test_images , atest_target \nscore = model.evaluate(test_img ,test_target, verbose = 0)\nprint(\"%s: %.2f%%\" % (\"acc\", score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae3cc8e5f7d0e36977ee32c2c90a69b148b075b","scrolled":false},"cell_type":"code","source":"# test_img,  one_hot_encoding(test_target)[0]\nprob = model.predict(test_img[:8])\nclasses = prob.argmax(axis=-1)\nprint(prob)\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a170290ff51d17ad8f42a6e82eca23480f373a"},"cell_type":"code","source":"a , b, c, d = one_hot_encoding(test_target_data) \n# a , b, c, d = one_hot_encoding(b_test)  \n\nlst = [str(i) for i in np.array(c)]\n\noriginal_lst = []\nfor i in test_target[:8]:\n#     print(i)\n    val = lst.index(str(i))\n    original_lst.append(val)\n    \nprint(np.array(original_lst))\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"824bde11c2684b0bbaf7f978705301b9d31db541"},"cell_type":"code","source":"sns.heatmap(confusion_matrix(classes, original_lst),annot=True,fmt='.5g')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d15f2d2dc61eedb565a4d4ef80d3d26881090f4"},"cell_type":"markdown","source":"###  Now , Making the prediction "},{"metadata":{"trusted":true,"_uuid":"5e007e40b776704208518ceff45d8753ec2ba957"},"cell_type":"code","source":"predict_csv = pd.read_csv(predict_names)\npredict_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18c16f2a0ed5cca5e6ee83f526bf28f07c701305"},"cell_type":"code","source":"predict_target = np.array([str(i) for i in predict_csv[\"Predicted\"]])\nprint(predict_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97840357cd4709904b1b70f9018c6f3922dfc983"},"cell_type":"code","source":"# predict_target = [str(i) for i in predict_csv[\"Predicted\"] ]\npredictImg, predictTarget  = data_maker(predict_csv['Id'], predict_target, (224, 224), predict_imgs, len(predict_csv['Id']))\nprint(predictImg.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa323ee1f5722b6f974e38253792d76b6867d751"},"cell_type":"code","source":"prob = model.predict(predictImg)\nclasses = prob.argmax(axis=-1)\n# print(prob)\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dfecca586aa8a2bca0afc6586cd985eabb3116c"},"cell_type":"markdown","source":"###  Output .csv file"},{"metadata":{"trusted":true,"_uuid":"3cf452491cb19b1f0d6f365851d81458cd2c3de2"},"cell_type":"code","source":"df = pd.DataFrame(data = {\"Id\":predict_csv['Id'] ,\n                          \"Predicted\": classes })\ndf.to_csv(\"//kaggle//working//prediction.csv\", sep = \",\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38edc84386b92757f2c9300451f82590f5e70f33"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33deb44ae544dd5553220f5845f4e282d33a587e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b0da2a9abae57f1087700c45eeb5bb86414a308"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f226654976bafa83b3a4b44e0c8f5b682ddf2bc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a719094c1b2f7ca814ef6730c770995845c58b7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92a22fa270b71dacd740a748c040a15f9173cb13"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5efa962b161812a77f0f9e745492ddec5213f903"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffe3a44713944f849f6eae5d9d454b1ffa0d7d7d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}