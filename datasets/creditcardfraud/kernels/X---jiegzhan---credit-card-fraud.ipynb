{"cells":[{"metadata":{"_cell_guid":"f9620daf-c7f2-4000-b65a-fa6a68312c21","_uuid":"308f0587e1e151e417aba2e62cd9a889cc2b1dba"},"cell_type":"markdown","source":"### First, let's import libraries, recruit models, and load the data we will work with.\n\nFirst, let's import the libraries that we'll need."},{"metadata":{"_cell_guid":"c1073826-bab5-4e18-8c81-a69a057166e8","collapsed":true,"_uuid":"e37044e14087444e816bd3524a5cd08be740b280","trusted":false},"cell_type":"code","source":"# print_function for compatibility with Python 3\nfrom __future__ import print_function\n\n# NumPy for numerical computing\nimport numpy as np\n\n# Pandas for DataFrames\nimport pandas as pd\npd.set_option('display.max_columns', 100)\n# pd.options.mode.chained_assignment = None  # default='warn'\n\n# Matplotlib for visualization\nfrom matplotlib import pyplot as plt\n\n# display plots in the notebook\n%matplotlib inline \n\n# Seaborn for easier visualization\nimport seaborn as sns\n\n# Pickle for reading model files\nimport pickle\n\n# Scikit-Learn for Modeling\nimport sklearn\nfrom sklearn.model_selection import train_test_split # Scikit-Learn 0.18+","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ff60a786-a913-4ae5-b716-d0cdd9c21956","_uuid":"5bfb4f3a38f51f85d62e40d7a2a50626777332dd"},"cell_type":"markdown","source":"Next, let's import the classifcation problem algorithms we will work with."},{"metadata":{"_cell_guid":"51ae8397-c477-4f05-ae22-249594801db6","collapsed":true,"_uuid":"f58cac370cea021f451ea4b2991d363d3b578d5c","trusted":false},"cell_type":"code","source":"# Import Logistic Regression\nfrom sklearn.linear_model import LogisticRegression\n\n# Import RandomForestClassifier and GradientBoostingClassifer\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"524ee837-f5c3-437b-b7d5-9e870cb6328a","_uuid":"4fa652c1d11e9373a9a96f7d57b80f26042355ab"},"cell_type":"markdown","source":"Next, let's import the Scikit-Learn functions and helpers we'll need."},{"metadata":{"_cell_guid":"930b6b07-1e27-40e8-a392-bca21856156e","collapsed":true,"_uuid":"3aa271f8c4afcd0be01a28233dc2818f346258cb","trusted":false},"cell_type":"code","source":"# Function for splitting training and test set\nfrom sklearn.model_selection import train_test_split\n\n# Function for creating model pipelines\nfrom sklearn.pipeline import make_pipeline\n\n# For standardization\nfrom sklearn.preprocessing import StandardScaler\n\n# Helper for cross-validation\nfrom sklearn.model_selection import GridSearchCV\n\n# Classification metrics\nfrom sklearn.metrics import roc_curve, precision_recall_curve, auc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1a6d923a-e23a-425b-9487-cbf4f74483e7","_uuid":"6036a495719ea68e89190b3edd882666b583cbbc"},"cell_type":"markdown","source":"Finally, let's read the data we have collected for this problem."},{"metadata":{"scrolled":true,"_cell_guid":"4857c10b-45f8-4f17-8abe-7136a961aa3f","collapsed":true,"_uuid":"e4df3591a5995a10c986394cdfdebb9a7ae491ad","trusted":false},"cell_type":"code","source":"# Load kaggle credit card transactions data\ndf = pd.read_csv('../input/creditcard.csv')\n\ndf.head(50)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5f68e26a-68c2-4cd4-a921-2ddd246ad358","_uuid":"6851c9055b02907fdeb2e217818d204e9cfda59f"},"cell_type":"markdown","source":"<span id=\"split\"></span>\n# 1. Split your dataset\n\nlet's start by splitting our data into separate training and test sets. \n\n<br>\n**First, separate the dataframe into separate objects for the target variable, <code style=\"color:steelblue\">y</code>, and the input features, <code style=\"color:steelblue\">X</code>.**"},{"metadata":{"_cell_guid":"1f16eba9-3c4a-4b75-8704-8edae93a046b","collapsed":true,"_uuid":"6e0e52477dbc9a2486e5fffc90def6a39c4f3c69","trusted":false},"cell_type":"code","source":"# Create separate object for target variable\ny = df.Class\n\n# Create separate object for input features\nX = df.drop('Class', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a1644bc-0422-4975-98e7-200c4c1d9fff","_uuid":"822d285a27b1d9ea955e3424e44fbdb673604375"},"cell_type":"markdown","source":"**After you've imported the <code style=\"color:steelblue\">train_test_split()</code> function, split <code style=\"color:steelblue\">X</code> and <code style=\"color:steelblue\">y</code> into training and test sets.**\n* Pass in the argument <code style=\"color:steelblue\">test_size=<span style=\"color:crimson\">0.2</span></code> to set aside 20% of our observations for the test set.\n* Pass in <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">1234</span></code> to set the random state for replicable results.\n* **Important:** Also pass in the argument <code style=\"color:steelblue\">stratify=<span style=\"color:crimson\">df.Class</span></code> in order to make sure the target variable's classes are balanced in each subset of data! This is **stratified random sampling**.\n* Then, print the number of observations in each subset to check that it was done correctly."},{"metadata":{"_cell_guid":"50c70346-c7de-4bda-957d-71ac38bf58f7","collapsed":true,"_uuid":"3407ee3654a7030eb10bc02a8a789fc136d846db","trusted":false},"cell_type":"code","source":"# Split X and y into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234, stratify=df.Class)\n\n# Print number of observations in X_train, X_test, y_train, and y_test\nprint( len(X_train), len(X_test), len(y_train), len(y_test) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba648f0d-02c5-4504-83ca-73d4322392d6","_uuid":"258eef903b8ff5bdd2eff5b30a4fae8e2afca7a2"},"cell_type":"markdown","source":"<span id=\"pipelines\"></span>\n# 2. Build model pipelines\n\nNext, let's set up preprocessing pipelines for each of our algorithms.\n\n<br>\n**Create a single <span style=\"color:royalblue\">pipeline dictionary</span> with pipelines for each algorithm**.\n* Use the keys:\n    * <code style=\"color:crimson\">'l1'</code> for $L_1$-regularized logistic regression\n    * <code style=\"color:crimson\">'l2'</code> for $L_2$-regularized logistic regression\n    * <code style=\"color:crimson\">'rf'</code> for random forest\n    * <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n* Each pipeline should standardize the data first.\n* Remember to set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> for each algorithm to ensure replicable results."},{"metadata":{"_cell_guid":"86ff7487-d03b-4306-a9ef-8d65816e17cf","collapsed":true,"_uuid":"964ded9ddcbf41390885dab64175eed14b1e2b0c","trusted":false},"cell_type":"code","source":"# Pipeline dictionary\npipelines = {\n    'l1': make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', random_state=123)),\n    'l2': make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', random_state=123)),\n    'rf': make_pipeline(StandardScaler(), RandomForestClassifier(random_state=123)),\n    'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=123))\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4137719-114f-4ca7-bdde-9bef84c04760","_uuid":"20616a3ca5df92ced0d760ab071e4b9498365394"},"cell_type":"markdown","source":"<span id=\"hyperparameters\"></span>\n# 3. Declare hyperparameters to tune\n\nNext, let's declare hyperparameters to tune.\n\n<br>\n**First, list the tunable hyperparameters of your $L_1$-regularized logistic regression pipeline.**"},{"metadata":{"_cell_guid":"35b2828d-0b98-475a-85b7-d22970a2614f","collapsed":true,"_uuid":"22a869790e2ede9336aba1865470f56647369605","trusted":false},"cell_type":"code","source":"# List tuneable hyperparameters of our Logistic pipeline\npipelines['l1'].get_params()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dbb4537c-8633-4785-b78c-494702bbbf53","_uuid":"ec635eb55d5334f786af0c89fd51f89455b9046b"},"cell_type":"markdown","source":"Let's declare the **hyperparameter grids** to tune."},{"metadata":{"_cell_guid":"33e81bf1-d6a0-4f77-a06a-f3a8227d9b6f","collapsed":true,"_uuid":"64cc1c10ba77fa192f8fca7f24e00ec398be1831","trusted":false},"cell_type":"code","source":"# Logistic Regression hyperparameters\nl1_hyperparameters = {\n    'logisticregression__C' : np.linspace(1e-3, 1e3, 10),\n}\n\nl2_hyperparameters = {\n    'logisticregression__C' : np.linspace(1e-3, 1e3, 10),\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"29508fd8-4c68-407e-8480-1f2f3cd5deaa","_uuid":"3cb6fb000d7c553649555479543055ff5ad1e7b5"},"cell_type":"markdown","source":"**Declare the hyperparameter grid for the random forest.**"},{"metadata":{"_cell_guid":"c56b6571-3fa5-4f9e-a74b-48b9f0bf1cdb","collapsed":true,"_uuid":"7d241aef408f0524d0e7bc029e26bbd0c2b129a0","trusted":false},"cell_type":"code","source":"# Random Forest hyperparameters\nrf_hyperparameters = {\n    'randomforestclassifier__n_estimators': [100, 200],\n    'randomforestclassifier__max_features': ['auto', 'sqrt', 0.33]\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1671b043-d01d-42ca-805a-014be73ab482","_uuid":"a354348a0f7edab6e758405f88ca25dfe7a7370e"},"cell_type":"markdown","source":"**Declare the hyperparameter grid for the boosted tree.**"},{"metadata":{"_cell_guid":"69a42ea1-e4ae-49a6-9361-429f52d1339c","collapsed":true,"_uuid":"376ba784f12b7d0f15dc69d03c2e5cc9ed8335c2","trusted":false},"cell_type":"code","source":"# Boosted Tree hyperparameters\ngb_hyperparameters = {\n    'gradientboostingclassifier__n_estimators': [100, 200],\n    'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2],\n    'gradientboostingclassifier__max_depth': [1, 3, 5]\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c7fcd39-ffc4-4ffa-b76c-2077a73709a3","_uuid":"20229240d119f8c557b43115ff4b43fac8e33fb1"},"cell_type":"markdown","source":"**Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary**.\n* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary."},{"metadata":{"_cell_guid":"3600d6ea-b90d-4a5e-b065-e86f045ea803","collapsed":true,"_uuid":"8da2729557872475a9d5d0705747ed618846eccb","trusted":false},"cell_type":"code","source":"# Create hyperparameters dictionary\nhyperparameters = {\n    'l1' : l1_hyperparameters,\n    'l2' : l2_hyperparameters,\n    'rf' : rf_hyperparameters,\n    'gb' : gb_hyperparameters\n}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37dac712-8962-4c64-a952-e9c35ffb9dbe","_uuid":"2e894d7d50a7091caf0796c1a972cab13503b375"},"cell_type":"markdown","source":"<span id=\"fit-tune\"></span>\n# 4. Fit and tune models with cross-validation\n\nNow that we have our <code style=\"color:steelblue\">pipelines</code> and <code style=\"color:steelblue\">hyperparameters</code> dictionaries declared, we're ready to tune our models with **cross-validation**.\n\n<br>\n**Create a <code style=\"color:SteelBlue\">fitted_models</code> dictionary that includes models that have been tuned using cross-validation.**\n* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n* (Optionally) You can set <code style=\"color:steelblue\">n_jobs=<span style=\"color:crimson\">-1</span></code> to use as many cores as available on your computer.\n\nThis step can take a few minutes, so please be patient."},{"metadata":{"_cell_guid":"33f50a50-1cc0-4929-9a0a-21eb425e056d","collapsed":true,"_uuid":"8e2187d7c32da25078e8fe3087e3e23995394dac","trusted":false},"cell_type":"code","source":"# Create empty dictionary called fitted_models\nfitted_models = {}\n\n# Loop through model pipelines, tuning each one and saving it to fitted_models\nfor name, pipeline in pipelines.items():\n    # Create cross-validation object from pipeline and hyperparameters\n    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n    \n    # Fit model on X_train, y_train\n    model.fit(X_train, y_train)\n    \n    # Store model in fitted_models[name] \n    fitted_models[name] = model\n    \n    # Print '{name} has been fitted'\n    print(name, 'has been fitted.')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d50c8b49-1af0-48b4-880a-dad7ef60cf6d","_uuid":"3e2f7db131450a8033ea0715058195941b71e0c5"},"cell_type":"markdown","source":"<span id=\"evaluate\"></span>\n# 5. Evaluate metrics\n\nFinally, it's time to evaluate our models and pick the best one.\n\n<br>\n**First, display the <code style=\"color:steelblue\">best\\_score_</code> attribute for each fitted model.**"},{"metadata":{"_cell_guid":"432bda59-dcef-450c-a485-fdb529f67ea1","collapsed":true,"_uuid":"28d2457cbb930681dd4cea43f47340624cedac3e","trusted":false},"cell_type":"code","source":"# Display best_score_ for each fitted model\nfor name, model in fitted_models.items():\n    print( name, model.best_score_ )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b7e48c12-0cef-484d-b1dd-47b5212dd442","_uuid":"3965aee390800d6e9a31c127ea4ad8133d9496a5"},"cell_type":"markdown","source":"<span id=\"auroc\"></span>\n# 6. Area under ROC (Receiver Operating Characteristics) curve\n\n**Area under ROC curve** is one of the most reliable metric for classification tasks."},{"metadata":{"_cell_guid":"4cc7098a-391e-4ddf-ae4d-b4533909dfba","collapsed":true,"_uuid":"f105047d3168099858d34a6fe3d0b9e5747dbba6","trusted":false},"cell_type":"code","source":"# Code here\nfor name, model in fitted_models.items():\n    pred = model.predict_proba(X_test)\n    pred = [p[1] for p in pred]\n    \n    fpr, tpr, thresholds = roc_curve(y_test, pred)\n    print( name, auc(fpr, tpr) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"730f8fdd-1418-48fe-8ac6-ebb27820b9d1","_uuid":"8255fd4d339cc4ee7516be63a203b32de4f098ac"},"cell_type":"markdown","source":"<span id=\"auroc\"></span>\n# 7. Area under PR (Precision Recall) curve\n\nStraight accuracy (Holdout Accuracy) score from cross-validation is not always the best way to evaluate a classification model especially for class imbalance problems. **Area under PR curve** is one of the most reliable metric for classification tasks and should be used for measuring accuracy for or class imbalance problems like this one."},{"metadata":{"_cell_guid":"8435b44d-2179-4e71-92aa-98d45ba15465","_uuid":"9a60503a40931c167ac2262af5d7be41be64e071"},"cell_type":"markdown","source":"First, let's plot the precision recall curve."},{"metadata":{"_cell_guid":"f94a9045-e60d-4da0-809b-7147d8627d99","collapsed":true,"_uuid":"c652e5120b7aef5b9a6c496940af11ede83c50f8","trusted":false},"cell_type":"code","source":"precision, recall, thresholds = precision_recall_curve(y_test, pred)\n\n# Initialize figure\nfig = plt.figure(figsize=(8,8))\nplt.title('Precision Recall')\n\nplt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n\n# Plot PR curve\nplt.plot(precision, recall, label='l1')\nplt.legend(loc='lower right')\n\n# Diagonal 45 degree line\nplt.plot([0,1],[0,1],'k--')\n\n# Axes limits and labels\nplt.xlim([-0.1,1.1])\nplt.ylim([-0.1,1.1])\nplt.ylabel('Precision')\nplt.xlabel('Recall')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2f2aa43c-404b-475a-a250-2382ce9b4c46","_uuid":"eb06626619d19de184b03d45cf8d7fc38b4dec57"},"cell_type":"markdown","source":"Next, let's calculate AUPR, using the <code style=\"color:steelblue\">auc()</code> function in conjunction with the <code style=\"color:steelblue\">precision_recall_curve()</code> function."},{"metadata":{"_cell_guid":"8c932e6a-5bd7-4c01-aafd-ef5961403268","collapsed":true,"_uuid":"da47ebb86be853597d46fce1296744a8c43a901e","trusted":false},"cell_type":"code","source":"# Code here\nfor name, model in fitted_models.items():\n    pred = model.predict_proba(X_test)\n    pred = [p[1] for p in pred]\n    \n    precision, recall, thresholds = precision_recall_curve(y_test, pred)\n    print( name, auc(recall, precision) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e68f4e0-fa5a-4119-91d2-86cdf2d4d3b1","collapsed":true,"_uuid":"015007acda180088b17ac0f62d330a12930a79b9","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"43696f29-676f-4e72-abfb-9f06d90bb79a","collapsed":true,"_uuid":"d6f03ccabcaa9a5e29ec1d5ea4af80d256ff3e22","trusted":false},"cell_type":"code","source":"# Save winning model as winning_model.pkl\nwith open('winning_model.pkl', 'wb') as f:\n    pickle.dump(fitted_models['rf'].best_estimator_, f)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","mimetype":"text/x-python","version":"3.6.4","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}