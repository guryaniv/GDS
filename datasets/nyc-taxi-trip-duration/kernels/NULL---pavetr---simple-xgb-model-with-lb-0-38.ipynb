{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.1", "name": "python"}}, "nbformat": 4, "cells": [{"metadata": {"collapsed": true, "_uuid": "185cb3a90825e9dec7e89dc50b304a259474cccf", "_cell_guid": "29419b08-ee4d-4b61-82c9-8fe42a2a4d15", "trusted": false}, "outputs": [], "source": "import warnings", "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_execution_state": "idle", "_uuid": "26535c7319b774940823aca1f3a4bc844b161d9d", "_cell_guid": "e4475c3b-f63e-4753-bb0a-99335dbc675d", "trusted": false}, "outputs": [], "source": "warnings.filterwarnings('ignore')", "cell_type": "code", "execution_count": null}, {"metadata": {"trusted": false, "collapsed": true, "_uuid": "e2521595272bda32bb9be83711d6d9f698313cfa", "_cell_guid": "02ea94ee-c35d-4a88-871e-6132ef789265"}, "outputs": [], "source": "import pandas as pd\nimport datetime\nfrom math import sin, cos, sqrt, atan2, radians, degrees\nimport math\nimport shapefile\nimport matplotlib.path as mplPath\nimport numpy as np\nimport json\nfrom sklearn.cross_validation import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import *\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.decomposition import PCA\nimport xgboost as xgb", "cell_type": "code", "execution_count": 1}, {"metadata": {"_uuid": "5d79b6f68cdd30a6e4a81a89a79d88a645839538", "collapsed": true, "_cell_guid": "4c498392-a67b-4191-9d9d-24e1aec1c38f", "trusted": false}, "outputs": [], "source": "base_path1 = '../input/nyc-taxi-trip-duration/'\nbase_path2 = '../input/new-york-city-taxi-with-osrm/'\nbase_path3 = '../input/nypdcollisions/'\nbase_path4 = '../input/nycgeoshapes/'\nbase_path5 = '../input/weather-data-in-new-york-city-2016/'", "cell_type": "code", "execution_count": 3}, {"metadata": {"_uuid": "5ba607d6b6b09eb26e5848d69577cb3c289c680a", "collapsed": true, "_cell_guid": "3f3c06b3-a1a2-4c39-a583-6d1009edb9ae", "trusted": false}, "outputs": [], "source": "train = pd.read_csv(base_path1 + 'train.csv')\ntest = pd.read_csv(base_path1 + 'test.csv')", "cell_type": "code", "execution_count": 4}, {"metadata": {"_uuid": "7ad20bbda794fa32b040d7fd3ae265fb57536511", "collapsed": true, "_cell_guid": "020f6992-5d7a-4fc9-8a29-a603172bd4f2", "trusted": false}, "outputs": [], "source": "### calculate distance per trip\n\ndef distance(lat1, lon1, lat2, lon2):\n\n    # approximate radius of earth in km\n    R = 6373.0\n    lat1 = radians(lat1)\n    lon1 = radians(lon1)\n    lat2 = radians(lat2)\n    lon2 = radians(lon2)\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c\n    return distance\n\n# calculate angle between pickup and dropoff points or angle relative to NYC center\n\ndef angle_between_vectors_degrees(lat1, lon1, lat2, lon2, mode = None):\n    # NYC_center\n    NYC_center = [40.793209, -73.973053]\n    a = np.radians(np.array([lat1, lon1]))\n    b = np.radians(np.array(NYC_center))\n    if mode == 'center':\n        c = np.radians(np.array([NYC_center[0]+1, NYC_center[1]]))\n    else:\n        c = np.radians(np.array([lat2, lon2]))\n    # Vectors in latitude/longitude space\n    avec = a - b\n    cvec = c - b\n\n    # Adjust vectors for changed longitude scale at given latitude into 2D space\n    lat = b[0]\n    avec[1] *= math.cos(lat)\n    cvec[1] *= math.cos(lat)\n    try:\n        return np.degrees(\n            math.acos(np.dot(avec, cvec) / (np.linalg.norm(avec) * np.linalg.norm(cvec))))\n    except ValueError:\n        return 0", "cell_type": "code", "execution_count": 5}, {"metadata": {"_uuid": "ce9c158f79c81924be8977d4010dc9d88d0298b6", "collapsed": true, "_cell_guid": "86984a59-684b-4b2f-bff5-cccb74e50cd0", "trusted": false}, "outputs": [], "source": "### get geoshapes of NYC boroughs\n\ndef get_dicty():\n    json_data=open(base_path4 + 'shapes.json').read()\n\n    data = json.loads(json_data)\n\n    dicty = {}\n    for d in data['features']:\n        dicty[d['properties']['BoroName']] = [mplPath.Path([(xx[1], xx[0]) for xx in x[0]]) for x in d['geometry']['coordinates']]\n    \n    return dicty\n\ndef get_district(point1, point2, dicty):\n    result = 'other'\n    for k, v in dicty.items():\n        for vv in v:\n            if vv.contains_point((point1, point2)):\n                result = k\n                break\n    return result", "cell_type": "code", "execution_count": 6}, {"metadata": {"_uuid": "1768fc9d44c8cb3ac5400bf7bf4cd658d5a60c69", "collapsed": true, "_cell_guid": "ad43f727-f13f-4fd3-ad29-f8c26ade1681", "trusted": false}, "outputs": [], "source": "def process_df(df):\n    dicty = get_dicty()\n    \n    \n    df['pickup_datetime'] = df['pickup_datetime'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n    df['weekday_pickup'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['month_pickup'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['week_pickup'] = df['pickup_datetime'].apply(lambda x: x.week)\n    df['hour_pickup'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['trip_distance'] = df.apply(lambda x: distance(x['pickup_latitude'], \n                                                       x['pickup_longitude'],\n                                                        x['dropoff_latitude'],\n                                                        x['dropoff_longitude']\n                                                       ), axis = 1 )\n    df['angle_start_end'] = df.apply(lambda x: angle_between_vectors_degrees(x['pickup_latitude'], x['pickup_longitude'],\n                                                x['dropoff_latitude'], x['dropoff_longitude']), axis = 1)\n    df['angle_direction'] = df.apply(lambda x: angle_between_vectors_degrees(x['pickup_latitude'], x['pickup_longitude'],\n                                                x['dropoff_latitude'], x['dropoff_longitude'], mode = 'center'), axis = 1)\n    \n    df['borough_start'] = df.apply(lambda x: get_district(x['pickup_latitude'], x['pickup_longitude'],\n                                                dicty), axis = 1)\n    \n    df['borough_end'] = df.apply(lambda x: get_district(x['dropoff_latitude'], x['dropoff_longitude'],\n                                                dicty), axis = 1)\n    \n    df['store_and_fwd_flag'] = (df['store_and_fwd_flag'] == 'Y') * 1\n    \n    return df", "cell_type": "code", "execution_count": 7}, {"metadata": {"_uuid": "18e9825004405891fdcdfe3c7b1fb6dedcc67275", "_cell_guid": "20c7bff6-373b-4cce-ac9b-a45986c500d6"}, "source": "### Generate first features", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "fd633e9506cae0555b26f7dd9d1bf030cea28804", "collapsed": true, "_cell_guid": "892d5a9d-e2cd-4b84-9f41-0ddd302b9796", "trusted": false}, "outputs": [], "source": "train = process_df(train)\ntest = process_df(test)", "cell_type": "code", "execution_count": 8}, {"metadata": {"_uuid": "72441910da96713096a86d96134f209f6bb505d8", "_cell_guid": "b5470bba-3c80-4160-b90b-0ae73f2025b8"}, "source": "### Add clusters", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "81bac65acd8108d5b863bd58a88353c966e09853", "collapsed": true, "_cell_guid": "f3e0d2a4-b9c0-490b-99d8-57d6ca77fd49", "trusted": false}, "outputs": [], "source": "clf = KMeans(n_clusters = 10)\nclf.fit([[x] for x in train['trip_distance'].values])\ntrain['distance_cluster'] = clf.labels_\ntest['distance_cluster'] = clf.predict([[x] for x in test['trip_distance'].values])", "cell_type": "code", "execution_count": 9}, {"metadata": {"_uuid": "b2bdaafa83ed9c3225b345f8a188636b3fe92e67", "collapsed": true, "_cell_guid": "d183b804-482b-40e3-9d60-c683896ace1e", "trusted": false}, "outputs": [], "source": "clf = KMeans(n_clusters = 20)\nclf.fit([[x, y] for x, y in zip(train['pickup_latitude'].values, train['pickup_longitude'].values)])\ntrain['pickup_coord_cluster'] = clf.labels_\ntest['pickup_coord_cluster'] = clf.predict([[x, y] for x, y in zip(test['pickup_latitude'].values, test['pickup_longitude'].values)])", "cell_type": "code", "execution_count": 10}, {"metadata": {"_uuid": "ab45c744f07266e691b9be5c3e1b22d7315b4f55", "collapsed": true, "_cell_guid": "ae10a153-a98a-4fd5-a8af-cad044a5dcc4", "trusted": false}, "outputs": [], "source": "clf = KMeans(n_clusters = 20)\nclf.fit([[x, y] for x, y in zip(train['dropoff_latitude'].values, train['dropoff_longitude'].values)])\ntrain['dropoff_coord_cluster'] = clf.labels_\ntest['dropoff_coord_cluster'] = clf.predict([[x, y] for x, y in zip(test['dropoff_latitude'].values, test['dropoff_longitude'].values)])", "cell_type": "code", "execution_count": 11}, {"metadata": {"_uuid": "9998bacd5efe2888ae162820a42523f1be4fcfd1", "_cell_guid": "021b507b-59ac-4ad2-b77d-684c8517c036"}, "source": "### Add weather data", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "453ade694a294a7290bb73e91d1c0ceef0ed434c", "collapsed": true, "_cell_guid": "a1f93bef-31bc-4afe-9b6b-232650c2e28a", "trusted": false}, "outputs": [], "source": "weather = pd.read_csv(base_path5 + 'weather_data_nyc_centralpark_2016.csv')\nweather['date'] = weather['date'].apply(lambda x: x.replace('-', ''))\ntrain['date'] = train['pickup_datetime'].apply(lambda x: (str(x)[8:10] if str(x)[8] != '0' else str(x)[9]) + \n                                               (str(x)[5:7] if str(x)[5] != '0' else str(x)[6]) + \n                                               str(x)[:4])\ntrain = pd.merge(train, weather, how = 'left', on = 'date')\ntest['date'] = test['pickup_datetime'].apply(lambda x: (str(x)[8:10] if str(x)[8] != '0' else str(x)[9]) + \n                                               (str(x)[5:7] if str(x)[5] != '0' else str(x)[6]) + \n                                               str(x)[:4])\ntest = pd.merge(test, weather, how = 'left', on = 'date')\n\nfor c in ['maximum temerature', 'minimum temperature',\n       'average temperature', 'precipitation', 'snow fall', 'snow depth']:\n    print(c)\n    mean_ = np.mean([x for x in train[c].values if type(x) != str])\n    train[c] = train[c].apply(lambda x: x if type(x) != str else mean_)\n    test[c] = test[c].apply(lambda x: x if type(x) != str else mean_)\n\ntrain.drop('date', axis = 1, inplace = True)\ntest.drop('date', axis = 1, inplace = True)", "cell_type": "code", "execution_count": 12}, {"metadata": {"_uuid": "10ce332682381f8366ad6e00f3c0ec27e564bb86", "_cell_guid": "4ff6feb8-7574-4b5a-85e8-94b379cce7d7"}, "source": "### Add routes", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "e5dcf328e61dbf2253dab07d6c80afce614a3b62", "collapsed": true, "_cell_guid": "8a40ee08-94d7-4ebf-b007-2b1e609ee9d7", "trusted": false}, "outputs": [], "source": "routes1 = pd.read_csv(base_path2 + 'fastest_routes_train_part_1.csv')\nroutes2 = pd.read_csv(base_path2 + 'fastest_routes_train_part_2.csv')\nroutes = routes1.append(routes2, ignore_index = True)\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\ntrain = pd.merge(train, routes, how = 'left', on = 'id')\n\n\nroutes = pd.read_csv(base_path2 + 'fastest_routes_test.csv')\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\ntest = pd.merge(test, routes, how = 'left', on = 'id')\n\n\nroutes = pd.read_csv(base_path2 + 'second_fastest_routes_train.csv')\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\nroutes.columns = ['id', 'total_distance_2', 'total_travel_time_2', 'number_of_steps_2']\ntrain = pd.merge(train, routes, how = 'left', on = 'id')\n\nroutes = pd.read_csv(base_path2 + 'second_fastest_routes_test.csv', engine = 'python',\n                     delimiter = ',', error_bad_lines=False)\nroutes = routes[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\nroutes.columns = ['id', 'total_distance_2', 'total_travel_time_2', 'number_of_steps_2']\ntest = pd.merge(test, routes, how = 'left', on = 'id')\n\ntrain.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)", "cell_type": "code", "execution_count": 13}, {"metadata": {"_uuid": "1fdd7714558b96ed70167297efc7980bc4faefcc", "_cell_guid": "71551bc3-d451-4a12-931f-f4390fdfdacd"}, "source": "### Add traffic collisions", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "8eccb5ebc71af352f225e001b15175871f4e8111", "collapsed": true, "_cell_guid": "ea2ceddb-718a-40dd-8b11-f20352bc54e7", "trusted": false}, "outputs": [], "source": "traffic = pd.read_csv(base_path3 + 'NYPD_Motor_Vehicle_Collisions.csv')\ntraffic['BOROUGH'].fillna('other', inplace = True)\n\ntrain['borough_start'] = train['borough_start'].str.upper()\ntrain['borough_end'] = train['borough_end'].str.upper()\ntest['borough_start'] = test['borough_start'].str.upper()\ntest['borough_end'] = test['borough_end'].str.upper()\n\ntraffic['time'] = traffic['TIME'].apply(lambda x: int(str(x)[:2].replace(':', '')))\n\n### Add collisions in total by date and hour match\n\ntr = traffic.groupby(['DATE', 'time'])['BOROUGH'].count().reset_index()\ntr['DATE'] = tr['DATE'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y'))\ntr.columns = ['DATE', 'time', 'collisions_total']\n\ntrain['year'] = train['pickup_datetime'].apply(lambda x: x.year)\ntrain['month'] = train['pickup_datetime'].apply(lambda x: x.month)\ntrain['day'] = train['pickup_datetime'].apply(lambda x: x.day)\ntrain['time'] = train['pickup_datetime'].apply(lambda x: x.hour)\n\ntest['year'] = test['pickup_datetime'].apply(lambda x: x.year)\ntest['month'] = test['pickup_datetime'].apply(lambda x: x.month)\ntest['day'] = test['pickup_datetime'].apply(lambda x: x.day)\ntest['time'] = test['pickup_datetime'].apply(lambda x: x.hour)\n\ntr['year'] = tr['DATE'].apply(lambda x: x.year)\ntr['day'] = tr['DATE'].apply(lambda x: x.day)\ntr['month'] = tr['DATE'].apply(lambda x: x.month)\n\ntrain = pd.merge(train, tr, how = 'left', on = ['year', 'month', 'day', 'time'])\ntest = pd.merge(test, tr, how = 'left', on = ['year', 'month', 'day', 'time'])\n\ntrain.drop(['DATE'], axis = 1, inplace = True)\ntest.drop(['DATE'], axis = 1, inplace = True)\n\n\n### Add collisions in total by date, hour and borough match\n\n\ntr = traffic.groupby(['DATE', 'time', 'BOROUGH'])['LATITUDE'].count().reset_index()\ntr.columns = ['DATE', 'time', 'BOROUGH','collisions_borough_start']\ntr['DATE'] = tr['DATE'].apply(lambda x: datetime.datetime.strptime(x, '%m/%d/%Y'))\ntr['year'] = tr['DATE'].apply(lambda x: x.year)\ntr['day'] = tr['DATE'].apply(lambda x: x.day)\ntr['month'] = tr['DATE'].apply(lambda x: x.month)\n\n\n\n\ntrain = pd.merge(train, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_start'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntest = pd.merge(test, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_start'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntrain.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\ntest.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\n\ntr.rename(columns = {'collisions_borough_start' : 'collisions_borough_end'}, inplace = True)\n\ntrain = pd.merge(train, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_end'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntest = pd.merge(test, tr, how = 'left', left_on = ['year', 'month', 'day', 'time', 'borough_end'],\n                \n                right_on = ['year', 'month', 'day', 'time', 'BOROUGH']\n                )\n\ntrain.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\ntest.drop(['BOROUGH', 'DATE'], axis = 1, inplace = True)\n\ntrain.fillna(0, inplace = True)\ntest.fillna(0, inplace = True)", "cell_type": "code", "execution_count": 14}, {"metadata": {"_uuid": "8f8e2b19c1251e8fa7f6e7573296b789bc47e630", "_cell_guid": "72b0cabe-5844-49bf-a6d9-0a74320364d8"}, "source": "### Encode text data and delete duplicates", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "65b428fb399bd0600116e91cd33a073c39563a5d", "collapsed": true, "_cell_guid": "83978920-5271-41ba-bf2d-cfd9d32bba81", "trusted": false}, "outputs": [], "source": "for c in test.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n        \ntrain.drop_duplicates(subset = ['id'], keep = 'first', inplace = True)\ntest.drop_duplicates(subset = ['id'], keep = 'first', inplace = True)", "cell_type": "code", "execution_count": 17}, {"metadata": {"_uuid": "f72faa8e7b09d3390f61fe2ee5e33e40cbd5484a", "_cell_guid": "5d31d2ae-00cd-475b-89cf-70f751557313"}, "source": "### Add some extra features", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "bd52806b4e9cf142c876af65518893d3a1186a1c", "collapsed": true, "_cell_guid": "15bc3d11-8e8a-49ba-98ee-fd881b902a3d", "trusted": false}, "outputs": [], "source": "train['borough_same'] = (train['borough_start'] == train['borough_end']) * 1\ntest['borough_same'] = (test['borough_start'] == test['borough_end']) * 1\ntrain['hour_period'] = train['hour_pickup'].apply(lambda x: 0 if x <= 6 else 1 if x <= 12 else 2 if x <= 18 else 3)\ntest['hour_period'] = test['hour_pickup'].apply(lambda x: 0 if x <= 6 else 1 if x <= 12 else 2 if x <= 18 else 3)\ntrain['cluster_same'] = (train['pickup_coord_cluster'] == train['dropoff_coord_cluster']) * 1\ntest['cluster_same'] = (test['pickup_coord_cluster'] == test['dropoff_coord_cluster']) * 1\ntrain['lat_distance'] = train['pickup_latitude'] - train['dropoff_latitude']\ntest['lat_distance'] = test['pickup_latitude'] - test['dropoff_latitude']\n\ntrain['lon_distance'] = train['pickup_longitude'] - train['dropoff_longitude']\ntest['lon_distance'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['week_end'] = (train['weekday_pickup'] == 0)*1 + (train['weekday_pickup'] == 6)*1\ntest['week_end'] = (test['weekday_pickup'] == 0)*1 + (test['weekday_pickup'] == 6)*1\n\nfull = pd.concat([train, test]).reset_index(drop=True)\ncoords = np.vstack((full[['pickup_latitude', 'pickup_longitude']],\n                    full[['dropoff_latitude', 'dropoff_longitude']]))\n\npca = PCA().fit(coords)\ntrain['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntrain['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntrain['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntrain['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\ntest['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntest['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntest['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntest['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n\ntrain['pca_manhattan'] = np.abs(train['dropoff_pca1'] - train['pickup_pca1']) + \\\n                             np.abs(train['dropoff_pca0'] - train['pickup_pca0'])\n\ntest['pca_manhattan'] = np.abs(test['dropoff_pca1'] - test['pickup_pca1']) + \\\n                        np.abs(test['dropoff_pca0'] - test['pickup_pca0'])\n\ntrain['direction_ns'] = (train.pickup_latitude > train.dropoff_latitude) * 1 + 1\nindices = train[(train.pickup_latitude == train.dropoff_longitude) & (train.pickup_latitude != 0)].index\ntrain.loc[indices, 'direction_ns'] = 0\n\ntrain['direction_ew'] = (train.pickup_longitude > train.dropoff_longitude) * 1 + 1\nindices = train[(train.pickup_longitude == train.dropoff_longitude) & (train.pickup_longitude != 0)].index\ntrain.loc[indices, 'direction_ew'] = 0\n\ntest['direction_ns'] = (test.pickup_latitude > test.dropoff_latitude) * 1 + 1\nindices = test[(test.pickup_latitude == test.dropoff_longitude) & (test.pickup_latitude != 0)].index\ntest.loc[indices, 'direction_ns'] = 0\n\ntest['direction_ew'] = (test.pickup_longitude > test.dropoff_longitude) * 1 + 1\nindices = test[(test.pickup_longitude == test.dropoff_longitude) & (test.pickup_longitude != 0)].index\ntest.loc[indices, 'direction_ew'] = 0\n\n\ntrain['speed'] = train['trip_distance'] / train['trip_duration']\nspeed_cluster = train.groupby(['pickup_coord_cluster', 'hour_pickup'])['speed'].mean().reset_index()\ntrain = pd.merge(train, speed_cluster, how = 'left', on = ['pickup_coord_cluster', 'hour_pickup'])\ntest = pd.merge(test, speed_cluster, how = 'left', on = ['pickup_coord_cluster', 'hour_pickup'])\ntrain.drop('speed_x', axis = 1, inplace = True)\ntrain.rename(columns = {'speed_y':'speed'}, inplace = True)\ntrain.rename(columns = {'speed':'speed_pickup'}, inplace = True)\ntest.rename(columns = {'speed':'speed_pickup'}, inplace = True)\n\ntrain['speed'] = train['trip_distance'] / train['trip_duration']\nspeed_cluster = train.groupby(['dropoff_coord_cluster', 'hour_pickup'])['speed'].mean().reset_index()\ntrain = pd.merge(train, speed_cluster, how = 'left', on = ['dropoff_coord_cluster', 'hour_pickup'])\ntest = pd.merge(test, speed_cluster, how = 'left', on = ['dropoff_coord_cluster', 'hour_pickup'])\ntrain.drop('speed_x', axis = 1, inplace = True)\ntrain.rename(columns = {'speed_y':'speed'}, inplace = True)\ntrain.rename(columns = {'speed':'speed_dropoff'}, inplace = True)\ntest.rename(columns = {'speed':'speed_dropoff'}, inplace = True)\ntrain['direction'] = (train['direction_ns'] == train['direction_ew'])*1\ntest['direction'] = (test['direction_ns'] == test['direction_ew'])*1", "cell_type": "code", "execution_count": 20}, {"metadata": {"_uuid": "a22b18824507e13f1f3e69b85403b11ace422a8c", "_cell_guid": "8e8df8af-180c-4027-8053-d91c813c0427"}, "source": "### Save files", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "d9a9e65657434e861b9ffecc3842f14f30dc8488", "collapsed": true, "_cell_guid": "144d3f0e-7403-4de8-a06c-4fc62a123d8b", "trusted": false}, "outputs": [], "source": "train.to_csv(base_path1 + 'train_p.csv', index = False)\ntest.to_csv(base_path1 + 'test_p.csv', index = False)", "cell_type": "code", "execution_count": 21}, {"metadata": {"_uuid": "b48230bc0e32fcd990c7323f33401031d365c3fb", "_cell_guid": "707fe3d4-6948-47a1-92b1-c2461c7cc11b"}, "source": "### Get ready for training xgboost", "cell_type": "markdown", "execution_count": null, "outputs": []}, {"metadata": {"_uuid": "e3713021e37dc1ab99f620cf774afbbcf5033085", "collapsed": true, "_cell_guid": "d9dee8c1-2ae3-4ce0-98e8-9b1463abf4b0", "trusted": false}, "outputs": [], "source": "train_cols = [\n    'borough_start',\n'borough_end',\n  'vendor_id',\n'passenger_count',\n'pickup_longitude',\n'pickup_latitude',\n'dropoff_longitude',\n'dropoff_latitude',\n'store_and_fwd_flag',\n'weekday_pickup',\n'month_pickup',\n'week_pickup',\n'hour_pickup',\n'trip_distance',\n'angle_start_end',\n'angle_direction',\n'distance_cluster',\n'pickup_coord_cluster',\n'dropoff_coord_cluster',\n'maximum temerature',\n'minimum temperature',\n'average temperature',\n'precipitation',\n'snow fall',\n'snow depth',\n'total_distance',\n'total_travel_time',\n'number_of_steps',\n'total_distance_2',\n'total_travel_time_2',\n'number_of_steps_2' ,\n'collisions_total',\n'collisions_borough_start',\n'collisions_borough_end',\n'borough_same',\n'hour_period',\n'cluster_same',\n'lat_distance',\n'lon_distance',\n'week_end',\n'speed_dropoff',\n'speed_pickup',\n'direction',\n'pickup_pca0',\n'pickup_pca1',\n'dropoff_pca0',\n'dropoff_pca1',\n'pca_manhattan',\n'direction_ns',\n'direction_ew'\n]", "cell_type": "code", "execution_count": 22}, {"metadata": {"_uuid": "15ee761397d0f29a5ff527137d6fbc208cf31937", "collapsed": true, "_cell_guid": "edff32e4-f0e1-469d-86a1-62ffb184e341", "trusted": false}, "outputs": [], "source": "train['trip_duration'] = np.log(train['trip_duration'] + 1)", "cell_type": "code", "execution_count": 23}, {"metadata": {"_uuid": "659f5f4629bf658241475771e1a25074b859e74c", "collapsed": true, "_cell_guid": "4e61b4bb-5204-452c-86a1-ae61acd754fd", "trusted": false}, "outputs": [], "source": "X_train, X_valid, y_train, y_valid = train_test_split( train[train_cols], train['trip_duration'], test_size=0.2, random_state=42)", "cell_type": "code", "execution_count": 24}, {"metadata": {"_uuid": "cff85433d97bd5d46315be33bc2565c1116f80db", "collapsed": true, "_cell_guid": "41113d9d-ce48-44ba-95f6-610c5bcdf19a", "trusted": false}, "outputs": [], "source": "xgb_pars = {'min_child_weight': 10, 'eta': 0.025, 'colsample_bytree': 0.3, 'max_depth': 10,\n            'subsample': 0.9, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n\n\nd_train = xgb.DMatrix(X_train, label=y_train)\nd_valid = xgb.DMatrix(X_valid, label=y_valid)\n\nwatchlist = [(d_train, \n              'train'), (d_valid, 'valid')]\n\nbst = xgb.train(xgb_pars, d_train, 10**6, watchlist, early_stopping_rounds=10, verbose_eval=5, \n               maximize = False\n               )", "cell_type": "code", "execution_count": 25}, {"metadata": {"_uuid": "4f78b6d3f2f0fdcd55d5491b9b94d2590e4e12e2", "collapsed": true, "_cell_guid": "324da46d-34b6-4132-b9bb-138aca27d0d1", "trusted": false}, "outputs": [], "source": "d_test = xgb.DMatrix(test[train_cols])", "cell_type": "code", "execution_count": 27}, {"metadata": {"_uuid": "43be12b8c837953df85a9ccadca7329c6f537cea", "collapsed": true, "_cell_guid": "57411c92-8a29-4428-9370-277714c8de13", "trusted": false}, "outputs": [], "source": "ytest = bst.predict(d_test)\ntest['trip_duration'] = np.exp(ytest) - 1\ntest[['id', 'trip_duration']].drop_duplicates(subset = ['id'], keep = 'first').to_csv(base_path1 + 'pavel_xgb_submission.csv.gz', index=False, compression='gzip')", "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "9f32282a718132067185064450230fe2397a962d", "collapsed": true, "_cell_guid": "45f58549-fb4e-43e0-8e62-d2151dc7a66f", "trusted": false}, "outputs": [], "source": "", "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "56f4eed1eb572c454115a4cbd0ca565f88e730f3", "collapsed": true, "_cell_guid": "78e03b0f-3b38-430a-8660-51050d90ae3e", "trusted": false}, "outputs": [], "source": "", "cell_type": "code", "execution_count": null}], "nbformat_minor": 2}