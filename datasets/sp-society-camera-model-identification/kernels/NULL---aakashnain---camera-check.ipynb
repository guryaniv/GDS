{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"source": ["**Welcome** to another image competition. For this competition, we are required to build an algorithm that identifies which camera model captured an image. Without wasting anytime, let's deep dive in the data."], "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "import os\n", "import glob\n", "from pathlib import Path\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import matplotlib.image as mimg\n", "from skimage.io import imread, imshow, imsave\n", "from PIL import Image\n", "%matplotlib inline\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_uuid": "141d372b082ae07bc8766005ce6bf965724f5910", "_cell_guid": "33d1d449-6fc7-4431-8418-dd58e64bcb68"}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["input_path = Path('../input')\n", "train_path = input_path / 'train'\n", "test_path = input_path / 'test'"], "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["Images in the training data were captured with 10 different camera models and all the images taken by a particular camera model are arranged in a single folder with same name as the camera model."], "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "source": ["# Get all the folders. Each folder name is based on the device name\n", "cameras = os.listdir(train_path)\n", "\n", "# Initialize an empty list\n", "train_images = []\n", "\n", "# Iterate over each file in each sub-folder\n", "for camera in cameras:\n", "    for fname in sorted(os.listdir(train_path / camera)):\n", "        train_images.append((camera, '../input/train/' + camera + '/' + fname))\n", "        \n", "# Convert the list to a pandas dataframe and save it for future use\n", "train = pd.DataFrame(data=train_images, columns=['camera', 'fname'])\n", "print(\"Total number of training samples: \", train.shape[0])\n", "train.to_csv('./train_data.csv', index=None)\n", "# Random samples from the data\n", "train.sample(10)"], "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["The images in the test data have also been captured with the same 10 camera models but with a different device. "], "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "source": ["# Do the same for test images\n", "test_images = []\n", "for fname in sorted(os.listdir(test_path)):\n", "    test_images.append('../input/test/' + fname)\n", "\n", "test = pd.DataFrame(test_images, columns=['fname'])\n", "print(\"Number of test samples: \", test.shape[0])\n", "test.to_csv('./test_data.csv', index=None)\n", "test.head(10)"], "metadata": {}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["# Let's look at some samples from the training data first\n", "f,ax = plt.subplots(2,5, figsize=(15,5))\n", "for i in range(10):\n", "    img = imread(train['fname'][i])\n", "    ax[i//5, i%5].imshow(img)\n", "    ax[i//5, i%5].axis('off')\n", "plt.show()    "], "metadata": {}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": ["# Let's look at some samples from the test data \n", "f,ax = plt.subplots(2,5, figsize=(15,10))\n", "for i in range(10):\n", "    # Use PIL to read the tiff file\n", "    img = Image.open(test[\"fname\"][i])\n", "    # Convert it into a numpy array\n", "    img = np.array(img)\n", "    ax[i//5, i%5].imshow(img)\n", "    ax[i//5, i%5].axis('off')\n", "plt.show()"], "metadata": {}, "cell_type": "code", "outputs": []}, {"source": ["The training data contains full images while the test data contains a centre crop of size 500x500. Also, as indicated, half of the test images have been altered with different types of  processing techniques which are:\n", "* JPEG compression with quality factor = 90\n", "* JPEG compression with quality factor = 90\n", "* resizing (via bicubic interpolation) by a factor of 0.5\n", "* resizing (via bicubic interpolation) by a factor of 0.8\n", "* resizing (via bicubic interpolation) by a factor of 1.5\n", "* resizing (via bicubic interpolation) by a factor of 2.0\n", "* gamma correction using gamma = 0.8\n", "* gamma correction using gamma = 1.2\n", "\n", "This information can be very useful while modelling an archietcture for the given problem.\n"], "metadata": {}, "cell_type": "markdown"}, {"execution_count": null, "source": [], "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": [], "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}, {"execution_count": null, "source": [], "metadata": {"collapsed": true}, "cell_type": "code", "outputs": []}], "nbformat": 4}