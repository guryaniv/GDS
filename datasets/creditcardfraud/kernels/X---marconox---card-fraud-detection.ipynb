{"cells":[{"metadata":{"_uuid":"52895512d2ac53a4d0a8252e0eaa824135516526"},"cell_type":"markdown","source":"## **Import packages and data**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import train_test_split\nimport itertools\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\ndata_path = '../input/creditcard.csv'\ndata = pd.read_csv(data_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de68094a4b5967ae4dbbdfbb2a3ab59624a7b9ea"},"cell_type":"markdown","source":"#### Grab some infomation about the data and features (optional)"},{"metadata":{"trusted":true,"_uuid":"0dcde439ca64b98882311489ace00bf1f6d0eea0","collapsed":true},"cell_type":"code","source":"featureInfo = {'Min':data.min(), 'Mean':data.mean(), 'Std':data.std(), 'Max':data.max()}\nprint(pd.DataFrame(data=featureInfo))\nprint('===============================================================')\ndata.info()\nprint('===============================================================')\nnumEachClass = data['Class'].value_counts()\nplt.title(\"Number of samples of each class\")\nplt.xlabel(\"Class\")\nplt.ylabel(\"Number of samples\")\nnumEachClass.plot.bar()\nnumPositives = numEachClass.tolist()[1]\nnumNegatives = numEachClass.tolist()[0]\ntotalNumSamples = len(data)\nprint(\"Total: \" + repr(totalNumSamples))\nprint('Positive samples: ' + repr(numPositives) + \"\\taccount for: \" + repr(numPositives/totalNumSamples*100) + \"%\")\nprint(\"Negative samples: \" + repr(numNegatives) + \"\\taccount for: \" + repr(numNegatives/totalNumSamples*100) + \"%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f832e74444040d30ac5ba44d6b741e741cdb7bb7"},"cell_type":"markdown","source":"**Comments:**\n* Feature 'Time' values vary from 0->172792, data collected in 2 days => Feature 'Time' is measured in 'seconds'. The real time of the 1st transaction is unknown => Assume it's 0h00\n* All features haven't been standardized, have type 'Float64'. 'Class' has type 'Int64' and has 2 unique values (0, 1)\n* No loss in data\n* The dataset is deeply imbalanced, with Positive/Negative rate = 492/284315 (~1/578)"},{"metadata":{"_uuid":"49e7e1f80ff69ae342cb4c08ece90cc6443f4485"},"cell_type":"markdown","source":"#### **Plot the distribution of the feature 'Amount' (optional)**"},{"metadata":{"trusted":true,"_uuid":"012126f7995c3e80470039f52558e11b0b94a161","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(121)\nAmntNotFraud = data[data.Class == 0].Amount\nplt.title('Not Fraud, Mean= %0.2f' %AmntNotFraud.mean())\nplt.xlabel('Amount')\nAmntNotFraud.plot.hist()\nplt.subplot(122)\nAmntFraud = data[data.Class == 1].Amount\nplt.title('Fraud, Mean= %0.2f' %AmntFraud.mean())\nplt.xlabel('Amount')\nAmntFraud.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3d9b99d63067f3e157d719d5b6ba39c4c8513a59","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nplt.subplot(121)\nplt.title('Not Fraud, Amount <= 4000')\nplt.xlabel('Amount')\ndata[(data.Class == 0) & (data.Amount <= 4000)].Amount.plot.hist()\nplt.subplot(122)\nplt.title('Fraud, Amount <= 4000')\nplt.xlabel('Amount')\ndata[(data.Class == 1) & (data.Amount <= 4000)].Amount.plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3199f4d4afe723c66dd33abaa7e3da2e2a4d65cc"},"cell_type":"markdown","source":"**Comments:**\n* Similar\n* MeanNotFraud < MeanFraud but MaxNotFraud > MaxFraud\n* No pattern"},{"metadata":{"_uuid":"2dc03338a88ce9d303a82cd3febe294a0c6f1c0c"},"cell_type":"markdown","source":"#### **Illustrate the correlation between features (optional)**"},{"metadata":{"trusted":true,"_uuid":"1be1e850be4956a8e365e8a61aec5d4333b35b74","collapsed":true},"cell_type":"code","source":"import seaborn as sns\n\nplt.figure(figsize=(20,10))\nplt.title('Correlation values between features')\nsns.heatmap(data.corr(), fmt='.1f', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e651935996620dbbc7809ebf62e742345ea38dd"},"cell_type":"markdown","source":"**Comments:**\n* No pair of feature having significant dependance"},{"metadata":{"_uuid":"3e9d700523f2d7cc2f6a62f93faed27efeb3341d"},"cell_type":"markdown","source":"#### **Explore feature 'Time' - transform the time offset into the hours of day that transactions happened (optional)**"},{"metadata":{"trusted":true,"_uuid":"292ea32a5da1699191484bdaab257d08f758938f","collapsed":true},"cell_type":"code","source":"timeCol = data.loc[:,['Time','Class']]\ntimeCol.Time /= 3600\ntimeCol.Time = timeCol.Time.astype(int)\ntimeCol.Time = timeCol.Time%24\n\ntimeNegative = timeCol.loc[timeCol.Class == 0,:].groupby('Time')['Class'].count()\ntimePositive = timeCol.loc[timeCol.Class == 1,:].groupby('Time')['Class'].count()\n#Plotting\nfig = plt.figure(figsize=(20,8))\nsbplt1 = plt.subplot(121)\nsbplt1.set_ylabel('No. of transactions')\nsbplt1.set_title('Not fraud')\ntimeNegative.plot.bar()\nsbplt2 = plt.subplot(122)\nsbplt2.set_ylabel('No. of transactions')\nsbplt2.set_title('Fraud')\ntimePositive.plot.bar()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1df80711f7ac6ce754649d0fdfa683d5959e6e17"},"cell_type":"markdown","source":"**Comments:**\n* Legal transactions are often conducted at 9h -> 22h\n* Fraud transactions are more random, with 2 peaks at 2h and 11h\n* Perhaps, using this type of 'Time' feature gives more value than original 'Time' feature"},{"metadata":{"_uuid":"ad01c70dcc9a5850e62b98a4b1e4bad2e6d671d1"},"cell_type":"markdown","source":"## **Separate train/test set:**\n* Apply standardization to all features except 'Time' and 'Class'\n* 'data' - dataset without feature 'Time'\n* 'data_incl_time' - dataset with transformed feature 'Time'"},{"metadata":{"trusted":true,"_uuid":"c158e5a1465327fff97383cfdab1bf8e42d6a8f4","collapsed":true},"cell_type":"code","source":"data.iloc[:,1:30] = StandardScaler().fit_transform(data.iloc[:,1:30])\ndata_incl_time = data.copy()\ndata = data.drop(['Time'],axis=1)\n#data.describe()\ndata_incl_time.Time /= 3600\ndata_incl_time.Time = data_incl_time.Time.astype(int)\ndata_incl_time.Time = data_incl_time.Time %24\n#data_incl_time.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2141cfe52e8ddd9124852a04b00c609578d8b9d"},"cell_type":"markdown","source":"**Dataset options:**\n+ OPTION 1: Train model by data including 'Time'\n+ OPTION 2: Train model by data excluding 'Time'\n\n**Train/test split options:**\n+ Random train/test split + Stratified K-fold CV (4 folds)\n+ Stratified train/test split + Stratified K-fold CV (4 folds)\n+ Stratified train/test split + Stratified Holdout CV (60-20-20)"},{"metadata":{"trusted":true,"_uuid":"73d2faec89415399cd95ae8af275bae88bad6e4b","collapsed":true},"cell_type":"code","source":"# Option 1: Dataset includes 'Time' feature\nX = data_incl_time.loc[:,data_incl_time.columns != 'Class']\ny = data_incl_time.loc[:,data_incl_time.columns == 'Class']\n# Option 2: Dataset excludes 'Time' feature\n\"\"\" \nX = data.loc[:,data.columns != 'Class']\ny = data.loc[:,data.columns == 'Class']\n\"\"\"\n# Prepare train set, test set\n    # Without Stratification\ntrainValidX, testX, trainValidy, testy = train_test_split(X, y, test_size = 0.2, random_state = 48)\n\n    # With Stratification\nsTrainValidX, sTestX, sTrainValidy, sTesty = train_test_split(X, y, test_size = 0.2, random_state = 48, stratify=y)\n\n    #Simple Stratified Holdout CV\nsTrainX, sValidX, sTrainy, sValidy = train_test_split(sTrainValidX, sTrainValidy, test_size = 0.25, random_state = 48, stratify=sTrainValidy)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a10967885307418ce1170787470a32a926c14f8"},"cell_type":"markdown","source":"#### **Check the class distribution on train/test sets (optional)**"},{"metadata":{"trusted":true,"_uuid":"04abab1bc4a382a362e7c5a4a0adec877b3b9e13","collapsed":true},"cell_type":"code","source":"print('Train set: ~80%\\tTest set: ~20%')\ndsbTrain = trainValidy['Class'].value_counts()\ndsbTest = testy['Class'].value_counts()\nprcTrain = dsbTrain[1]/numPositives\nprcTest = dsbTest[1]/numPositives\nprint('Without stratification:\\n\\t+ Train set: Negative= ' + repr(dsbTrain[0]) + '\\tPositive= ' + repr(dsbTrain[1]) +' ~%0.3f'%prcTrain)\nprint('\\t+ Test set: Negative= ' + repr(dsbTest[0]) + '\\tPositive= ' + repr(dsbTest[1]) + ' ~%0.3f'%prcTest)\nprint('==============================')\ndsbTrain = sTrainValidy['Class'].value_counts()\ndsbTest = sTesty['Class'].value_counts()\nprcTrain = dsbTrain[1]/numPositives\nprcTest = dsbTest[1]/numPositives\nprint('With stratification:\\n\\t+ Train set: Negative= ' + repr(dsbTrain[0]) + '\\tPositive= ' + repr(dsbTrain[1]) +' ~%0.3f'%prcTrain)\nprint('\\t+ Test set: Negative= ' + repr(dsbTest[0]) + '\\tPositive= ' + repr(dsbTest[1]) + ' ~%0.3f'%prcTest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60439dda8f8fa1a67fd3464f3afb3deb62029be8","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix, mean_absolute_error, roc_curve, auc, average_precision_score\n\ndef evaluate(param, weight, trainX, trainy, testX, testy):\n    print(\"======================================================\")\n    print(\"\\nRegularization Parameter = \", param, \"\\n\")\n    logRegr = LogisticRegression(C = param, penalty = 'l1', class_weight = {0:1/(1+weight), 1:weight/(1+weight)})\n    logRegr.fit(trainX, trainy.values.ravel())\n    \n    prediction = logRegr.predict(testX.values)\n\n    print(\"MAE:\", mean_absolute_error(testy, prediction))\n    print(\"Accuracy score: \", accuracy_score(testy, prediction, normalize = False), \"/\", len(validy))\n    print(\"F1 score: \", f1_score(testy, prediction))\n    print(\"Precision score: \", precision_score(testy, prediction))\n    print(\"Recall score: \", recall_score(testy, prediction))\n    print(\"AUPRC: \", average_precision_score(testy.values.ravel(), logRegr.predict_proba(testX.values)))\n    \n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b35873be41e5ee819def1271883d8fc658bb2246"},"cell_type":"markdown","source":"## **Try a few basic operations on a specific model: **\n+ Logistic Regression: RegParam = 0.3, DefaultThreshold = 0.5, ClassWeight = none\n+ Try: fit/predict, plot confusion matrix, ROC/AUROC, PRC/AUPRC"},{"metadata":{"trusted":true,"_uuid":"2f0f445e5c20cff0d458a591fca10ad539df4888","collapsed":true},"cell_type":"code","source":"print(\"Evaluating on test set. Regularizing param = \", 0.3)\nlogRegr = LogisticRegression(C = 0.3, penalty = 'l1')\nlogRegr.fit(trainValidX, trainValidy.values.ravel())\nprediction = logRegr.predict(testX.values)\nprint(\"Recall score: \", recall_score(testy, prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"88713f489274e0f066f5b6cdd3057cd1d670a5bb"},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0868613a790d06fdccb833c6f6f62130833f6006","collapsed":true},"cell_type":"code","source":"def draw_cnf_matrix(testy, prediction):\n    # Compute confusion matrix\n    cnf_matrix = confusion_matrix(testy, prediction)\n    np.set_printoptions(precision=2)\n\n    # Plot non-normalized confusion matrix\n    #plt.figure()\n    plot_confusion_matrix(cnf_matrix, classes=[0,1], title='Confusion matrix, without normalization')\n\ndraw_cnf_matrix(testy, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dc13db94894904881d6aba3e8a455b9a0513400","collapsed":true},"cell_type":"code","source":"prediction_proba = logRegr.predict_proba(testX.values)[:,1]\n\ndef draw_roc_curve(testy, prediction_proba):\n    fpr, tpr, thresholds = roc_curve(testy.values.ravel(), prediction_proba, pos_label = 1)\n\n    #plt.figure()\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=2, label='ROC curve (area = %0.2f)' % auc(fpr, tpr))\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.0])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\ndraw_roc_curve(testy, prediction_proba)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03fa551f0537f54bf95307cc55f50a24f00acbb2","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, precision_recall_fscore_support\n\ndef draw_prc(testy, prediction_proba):\n    precision, recall, threshold = precision_recall_curve(testy.values.ravel(), prediction_proba)\n    ap = average_precision_score(testy.values.ravel(), prediction_proba)\n    threshold = np.append(threshold, 1)\n    plt.step(recall, precision, color='r', where='post', label = 'AUPRC = %0.2f' %ap)\n    plt.title('Precision Recall Curve')\n    plt.legend(loc='lower left')\n    \ndraw_prc(testy, prediction_proba)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92db33b1481bef2a34461f3d445e73de28301893"},"cell_type":"markdown","source":"## **Optimizing Part:**\n+ Using K-fold CV to choose the best regularization parameter in a specific range of values\n    Number of folds = 4, Criteria: Recall score"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"34ea799feaf23699bf8c43b927ac3d5bc2011240"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\ndef select_skfold(X, y):\n    \n    print('Stratified k-fold cross validation:')\n    reg_params = [0.03, 0.3, 3.0, 30, 300]\n    print('Regularizing parameter range:\\n', reg_params)\n    \n    folds_num = 4\n    folds = StratifiedKFold(n_splits = folds_num)\n    print('Num of folds = ', folds_num)\n    \n    best_recall = 0;\n    best_param = 0;\n    \n    print('Looping...')\n    for param in reg_params:\n        print('Param = ', param)\n        logRegr = LogisticRegression(C = param, penalty = 'l1')\n        avg_recall = 0\n        \n        for train, test in folds.split(X, y):\n            trainX, testX = X.iloc[train,:], X.iloc[test,:]\n            trainy, testy = y.iloc[train,:], y.iloc[test,:]\n            logRegr.fit(trainX, trainy.values.ravel())\n            kfold_predict = logRegr.predict(testX.values)\n            rec = recall_score(testy.values, kfold_predict)\n            avg_recall += rec\n        \n        avg_recall /= folds_num\n        print('Average recall score = ', avg_recall)\n        \n        if rec > best_recall:\n            best_recall = rec\n            best_param = param\n    \n    return best_param\n\ndef draw_prthreshold(test, p, weight = 1):\n    ap = average_precision_score(test.values.ravel(), p)\n    precision, recall, t = precision_recall_curve(test.values.ravel(), p)\n    t = np.append(t, 1)\n    plt.title('N/P class weight: 1:'+ repr(weight) + ' ; AUPRC = {0:0.6f}'.format(ap))\n    plt.plot(t, recall, color='r')\n    plt.plot(t, precision, color='b')\n\n    plt.xlabel('Threshold')\n    plt.legend(('recall','precision'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e70e65d398795c892e87bc25b2ed6aec9dee42d"},"cell_type":"markdown","source":"* Find out the model with the best Negative/Positive Sample Weight Rate by calculating AUPRC. Also show other evaluating scores (MAE, F1score, Accuracy, Precision, Recall)\n* Plot PRC\n* Plot Precision-Recall graphs"},{"metadata":{"trusted":true,"_uuid":"77720b4012948de8f81bfd180e1a44d8e65b8fea","collapsed":true},"cell_type":"code","source":"from itertools import cycle\n\nbest_param = select_skfold(trainValidX, trainValidy)\nweight_range = [1,2,5,10,20,50,100,200,300,400,500]\ncolors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'yellow', 'green', 'blue','black', 'purple'])\nplt.figure(1, figsize=(20,8))\nj = 1\nfor weight, color in zip(weight_range, colors):\n    print('===============================================')\n    print('Positive class weight = ', weight)\n    logRegr = LogisticRegression(C = best_param, penalty = 'l1', class_weight = {0:1/(1+weight), 1:weight/(1+weight)})\n    logRegr.fit(trainValidX, trainValidy.values.ravel())\n    prediction = logRegr.predict(testX.values)\n    \n    print(\"F1 score: \", f1_score(testy, prediction), \"\\tPrecision score: \", precision_score(testy, prediction), \"\\tRecall score: \", recall_score(testy, prediction))\n    proba = logRegr.predict_proba(testX.values)[:,1]\n    ap = average_precision_score(testy.values.ravel(), proba)\n    print(\"Accuracy score: \", accuracy_score(testy, prediction, normalize = True), '\\tAUPRC: ', ap)\n    \n    plt.figure(2, figsize=(28,15))\n    plt.subplot(3,4,j)\n    j += 1\n    draw_prthreshold(testy, proba)\n    \n    plt.figure(1)\n    plt.plot(recall, precision, color=color, label='PosClassWeight= %s'%weight)\n    plt.legend(loc=\"lower left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc2fc06022444293ea89fff350d22d4176310171"},"cell_type":"markdown","source":"### **The best result: AUPRC = 0.829 while:**\n+ Random train/test split, K-fold CV\n+ Using transformed 'Time' feature\n+ Logistic Regression: threshold = 'default', N/P Weight Rate = 1:2"},{"metadata":{"_uuid":"82c19bc58f94208104df9475c1e18e31dc2f0826"},"cell_type":"markdown","source":"### **Try Random Forest**"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7f8b314747f421aaec68b5ee04a109cdeb30d713","collapsed":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nweight_range = [1,2,5,10,20,50,100,200,300,400,500]\ncolors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal', 'red', 'yellow', 'green', 'blue','black', 'purple'])\nplt.figure(0, figsize=(20,8))\nj = 1\nfor weight, color in zip(weight_range, colors):\n    print('===============================================')\n    print('Positive class weight = ', weight)\n    ranFor = RandomForestClassifier(class_weight = {0:1/(1+weight), 1:weight/(1+weight)})\n    ranFor.fit(trainValidX, trainValidy.values.ravel())\n    prediction = ranFor.predict(testX.values)\n    \n    print(\"F1 score: \", f1_score(testy, prediction), \"\\tPrecision score: \", precision_score(testy, prediction), \"\\tRecall score: \", recall_score(testy, prediction))\n    proba = ranFor.predict_proba(testX.values)[:,1]\n    precision, recall, threshold = precision_recall_curve(testy.values.ravel(), proba)\n    threshold = np.append(threshold, 1)\n    ap = average_precision_score(testy.values.ravel(), proba)\n    print(\"Accuracy score: \", accuracy_score(testy, prediction, normalize = True), '\\tAUPRC: ', ap)\n    \n    plt.figure(1, figsize=(28,15))\n    plt.subplot(3,4,j)\n    j += 1\n    plt.title('N/P class weight: 1:'+ repr(weight) + ' ; AUPRC = {0:0.6f}'.format(ap))\n    plt.plot(threshold, recall, color='r')\n    plt.plot(threshold, precision, color='b')\n\n    plt.xlabel('Threshold')\n    plt.legend(('recall','precision'))\n    \n    plt.figure(0)\n    plt.plot(recall, precision, color=color, label='PosClassWeight= %s'%weight)\n    plt.legend(loc=\"lower left\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"990bc19aa602f560e8ad8c42cbfc2af601e31271"},"cell_type":"markdown","source":"**Best result: AUPRC = 0.8611**"},{"metadata":{"_uuid":"f233ad719016321dd2a2a0a411799ff2a69fb4cf"},"cell_type":"markdown","source":"# **UNSUPERVISED LEARNING**"},{"metadata":{"trusted":true,"_uuid":"dae4e7b32da1d8af7db964506a136eb9de30b38a","collapsed":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\nkmclstr = KMeans(n_clusters = 10, random_state = 48)\nkmclstr.fit(trainValidX)\ncentroids_pos = kmclstr.cluster_centers_\ncentroids_pred = kmclstr.predict(testX)\ndistances = [np.linalg.norm(a - b) for a,b in zip(testX.as_matrix(), centroids_pos[centroids_pred])]\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b65e4078b3175c617e6e4ec2e77b1445dc860e8","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\nprediction = np.array(distances)\nthreshold = 98\nthreshold_step = 0.05\nthreshold_end = 99.9\nwhile threshold <= threshold_end:\n    print(\"=======================================\")\n    print(threshold, \"-th percentile\")\n    proba = prediction_proba.copy()\n    #print(proba)\n    print(proba.max())\n    proba[distances >= np.percentile(distances, threshold)] = 1\n    proba[distances < np.percentile(distances, threshold)] = 0\n    #print(proba)\n    print(\"F1 score: \", f1_score(testy, proba), \"\\tPrecision score: \", precision_score(testy, proba), \"\\tRecall score: \", recall_score(testy, proba))\n    print(\"Accuracy score: \", accuracy_score(testy, proba, normalize = True), \"\\tAUPRC score: \", average_precision_score(testy, prediction_proba))\n    print(roc_auc_score(testy, prediction_proba))\n    threshold += threshold_step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0a5e7e51c4e03de4cb9846341279cdee966739a6"},"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\nisoFor = IsolationForest(contamination = 0.01, random_state = 48)\nisoFor.fit(sTrainValidX)\nisoFor_predict = isoFor.predict(sTestX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6da07d9fe7a4e8b5bbb8c3c8796bed2f18e10265","collapsed":true},"cell_type":"code","source":"isoFor_decision = isoFor.decision_function(sTestX)\nisoFor_decision = MinMaxScaler().fit_transform(isoFor_decision.reshape(-1,1))\nisoFor_decision = 1 - isoFor_decision\n\nisoFor_predict[isoFor_predict == 1] = 0\nisoFor_predict[isoFor_predict == -1] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f09a8bdb8959a07eb4a68e5d4d986d366037255","collapsed":true},"cell_type":"code","source":"print(\"F1 score: \", f1_score(sTesty, isoFor_predict), \"\\tPrecision score: \", precision_score(sTesty, isoFor_predict), \"\\tRecall score: \", recall_score(sTesty, isoFor_predict))\nprint(\"Accuracy score: \", accuracy_score(sTesty, isoFor_predict, normalize = True))#, \"\\tAUPRC score: \", average_precision_score(testy, proba))\nprint(\"AUROC score\", roc_auc_score(sTesty, isoFor_decision))\n\ncnf_matrix = confusion_matrix(sTesty, isoFor_predict)\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=[0,1],\n                      title='Confusion matrix, without normalization')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f2e7bf82367b56c0bbe2fa138e8a699f91b392be"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}