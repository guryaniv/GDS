{"cells":[{"metadata":{"_uuid":"27febf2b7d32855cd858f47258c7064ed00a56a4"},"cell_type":"markdown","source":"# Original Code and Paper"},{"metadata":{"_uuid":"6a5aacf5f00b53190588358220b582283780e1a9"},"cell_type":"markdown","source":"- Original code(caffe): https://github.com/richzhang/colorization/blob/master/colorization/demo/colorization_demo_v2.ipynb\n- Paper: https://arxiv.org/pdf/1603.08511.pdf"},{"metadata":{"trusted":true,"_uuid":"42fd7e716dac6c72e4369c61bf0c9988f1da4e40"},"cell_type":"code","source":"import cv2 # opencv 3.4.2+ required\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbcb3e41ec625b462e99d2cf137c8814dfd6b9a"},"cell_type":"code","source":"print(cv2.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f57f30d20637a700c70b2982ed1709b04abb9da4"},"cell_type":"markdown","source":"# Prepare Model\n- You need to download models from Zhang's server\n- Run \"get_models.sh\" to get it"},{"metadata":{"trusted":true,"_uuid":"c41b51e8247a0d58599edd646b19c8d4bb24ab5c"},"cell_type":"code","source":"proto = '../input/colorise-image/colorization_deploy_v2.prototxt.txt'\nweights = '../input/colorise-image/colorization_release_v2_norebal.caffemodel'\n# colorization_release_v2_norebal.caffemodel is trained with a classification loss with no class re-balancing term.\n# The results are duller but \"safer\" colorizations\n# weights = './models/colorization_release_v2_norebal.caffemodel' \n\n# load cluster centers\npts_in_hull = np.load('../input/colorise-image/pts_in_hull.npy')\npts_in_hull = pts_in_hull.transpose().reshape(2, 313, 1, 1).astype(np.float32)\n\n# load model\nnet = cv2.dnn.readNetFromCaffe(proto, weights)\n# net.getLayerNames()\n\n# populate cluster centers as 1x1 convolution kernel\nnet.getLayer(net.getLayerId('class8_ab')).blobs = [pts_in_hull]\n# scale layer doesn't look work in OpenCV dnn module, we need to fill 2.606 to conv8_313_rh layer manually\nnet.getLayer(net.getLayerId('conv8_313_rh')).blobs = [np.full((1, 313), 2.606, np.float32)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9517be3ae10885204a2e58b405f8211acd9fe30"},"cell_type":"code","source":"img_path = '../input/colorise-image/sample_10.jpg'\nimg = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\nimg_input = img.copy()\n\n# convert BGR to RGB\nimg = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n\nimg_rgb = img.copy()\n\n# normalize input\nimg_rgb = (img_rgb / 255.).astype(np.float32)\n\n# convert RGB to LAB\nimg_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2Lab)\n# only L channel to be used\nimg_l = img_lab[:, :, 0]\n\ninput_img = cv2.resize(img_l, (224, 224))\ninput_img -= 50 # subtract 50 for mean-centering\n\n# plot images\n# fig = plt.figure(figsize=(10, 5))\n# fig.add_subplot(1, 2, 1)\n# plt.imshow(img_rgb)\n# fig.add_subplot(1, 2, 2)\n# plt.axis('off')\nplt.figure(figsize=(10,10))\nplt.imshow(input_img, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc4280f8a263792b1471c63db19719175dd132e6"},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true,"_uuid":"a0d5b248ade0aff72414d75aa1da3b685ad10ef8"},"cell_type":"code","source":"net.setInput(cv2.dnn.blobFromImage(input_img))\npred = net.forward()[0,:,:,:].transpose((1, 2, 0))\n\n# resize to original image shape\npred_resize = cv2.resize(pred, (img.shape[1], img.shape[0]))\n\n# concatenate with original image L\npred_lab = np.concatenate([img_l[:, :, np.newaxis], pred_resize], axis=2)\n\n# convert LAB to RGB\npred_rgb = cv2.cvtColor(pred_lab, cv2.COLOR_Lab2RGB)\npred_rgb = np.clip(pred_rgb, 0, 1) * 255\npred_rgb = pred_rgb.astype(np.uint8)\n\n# plot prediction result\nfig = plt.figure(figsize=(20, 10))\nfig.add_subplot(1, 2, 1).axis('off')\nplt.imshow(img_l, cmap='gray')\nfig.add_subplot(1, 2, 2).axis('off')\nplt.imshow(pred_rgb)\n# plt.savefig(output_filename)\n\n# save result image file\nfilename, ext = os.path.splitext(img_path)\n# input_filename = '%s_input%s' % (filename, ext)\n# output_filename = '%s_output%s' % (filename, ext)\n\n# pred_rgb_output = cv2.cvtColor(pred_rgb, cv2.COLOR_RGB2BGR)\n\n# cv2.imwrite(input_filename, img_input)\n# cv2.imwrite(output_filename, np.concatenate([img, pred_rgb_output], axis=1))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}