{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# 1. EDA"},{"metadata":{"trusted":true,"_uuid":"6fd93dc2422fba8bd43d47f606eef972798077df"},"cell_type":"code","source":"import os\nimport csv\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"039fdf16618f1588f6324ff5ee34ccba38860dfc"},"cell_type":"code","source":"from IPython.display import Markdown, display\ndef printmd(string):\n    display(Markdown(string))\n#printmd('**bold**')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be9c8a5a8ff5b319f75e8ab89945761c5910468e"},"cell_type":"code","source":"data_path = \"../input/train.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40260927ae8c4a234a46bf61f7791059e66fd37d"},"cell_type":"code","source":"data_raw = pd.read_csv(data_path)\n#data_raw = data_raw.loc[np.random.choice(data_raw.index, size=2000)]\ndata_raw.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b9f671d3d9ee3e5297c1ab8e9f18e6d576c5323"},"cell_type":"code","source":"\nprint(\"Number of rows in data =\",data_raw.shape[0])\nprint(\"Number of columns in data =\",data_raw.shape[1])\nprint(\"\\n\")\nprintmd(\"**Sample data:**\")\ndata_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec004e0edaf797546e624bdbb8756819a8105413"},"cell_type":"markdown","source":"## Checking for missing values"},{"metadata":{"trusted":true,"_uuid":"6e5d05bf1dd232758e01a217d9b75cc3b82a12f2"},"cell_type":"code","source":"missing_values_check = data_raw.isnull().sum()\nprint(missing_values_check)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53dfa56df5e6791a751afadc977a1f74b4523720"},"cell_type":"markdown","source":"## Calculating number of comments under each label"},{"metadata":{"trusted":true,"_uuid":"08fa2d92af77e193bc01f0fc34df09acd44c678e"},"cell_type":"code","source":"# Comments with no label are considered to be clean comments.\n# Creating seperate column in dataframe to identify clean comments.\n\n# We use axis=1 to count row-wise and axis=0 to count column wise\n\nrowSums = data_raw.iloc[:,2:].sum(axis=1)\nclean_comments_count = (rowSums==0).sum(axis=0)\n\nprint(\"Total number of comments = \",len(data_raw))\nprint(\"Number of clean comments = \",clean_comments_count)\nprint(\"Number of comments with labels =\",(len(data_raw)-clean_comments_count))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f100c8a860412d6958963fdf30ed81643e2dce6"},"cell_type":"code","source":"categories = list(data_raw.columns.values)\ncategories = categories[2:]\nprint(categories)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d247031737f9f542c89e4acb0fe9ff674c2817d"},"cell_type":"code","source":"# Calculating number of comments in each category\n\ncounts = []\nfor category in categories:\n    counts.append((category, data_raw[category].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'number of comments'])\ndf_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4add9bd32b87059a531fb7e744193556ff9fdbe9"},"cell_type":"code","source":"sns.set(font_scale = 2)\nplt.figure(figsize=(15,8))\n\nax= sns.barplot(categories, data_raw.iloc[:,2:].sum().values)\n\nplt.title(\"Comments in each category\", fontsize=24)\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Comment Type ', fontsize=18)\n\n#adding the text labels\nrects = ax.patches\nlabels = data_raw.iloc[:,2:].sum().values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=18)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90f2927f089922413199d30a39b214727058bb73"},"cell_type":"markdown","source":"## Calculating number of comments having multiple labels"},{"metadata":{"trusted":true,"_uuid":"9523292994793d191e7fdc8f3b1b441ad750f421"},"cell_type":"code","source":"rowSums = data_raw.iloc[:,2:].sum(axis=1)\nmultiLabel_counts = rowSums.value_counts()\nmultiLabel_counts = multiLabel_counts.iloc[1:]\n\nsns.set(font_scale = 2)\nplt.figure(figsize=(15,8))\n\nax = sns.barplot(multiLabel_counts.index, multiLabel_counts.values)\n\nplt.title(\"Comments having multiple labels \")\nplt.ylabel('Number of comments', fontsize=18)\nplt.xlabel('Number of labels', fontsize=18)\n\n#adding the text labels\nrects = ax.patches\nlabels = multiLabel_counts.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e36e4d7daa0f18905ffa7b53ac854b524066a3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b61d245a53f0638a27bcb955ac8a896bf2a79bc8"},"cell_type":"markdown","source":"# 2. Data Pre-Processing"},{"metadata":{"trusted":true,"_uuid":"bdc9353f5c84d2819fd1d6196a3ba0d56ed70252"},"cell_type":"code","source":"data = data_raw\ndata = data_raw.loc[np.random.choice(data_raw.index, size=2000)]\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"532ca425f03d5480640437581c7987323ac993e5"},"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nimport re\n\nimport sys\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3742b367fda6829c903ebb858ee6c7bd22dc0014"},"cell_type":"markdown","source":"##  Cleaning Data"},{"metadata":{"trusted":true,"_uuid":"3b8ffbb98593b3b29b45784d2786113b24125142"},"cell_type":"code","source":"def cleanHtml(sentence):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', str(sentence))\n    return cleantext\n\n\ndef cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    cleaned = cleaned.strip()\n    cleaned = cleaned.replace(\"\\n\",\" \")\n    return cleaned\n\n\ndef keepAlpha(sentence):\n    alpha_sent = \"\"\n    for word in sentence.split():\n        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n        alpha_sent += alpha_word\n        alpha_sent += \" \"\n    alpha_sent = alpha_sent.strip()\n    return alpha_sent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1c21815b37d43cf513479052ed21124171af9ce"},"cell_type":"code","source":"data['comment_text'] = data['comment_text'].str.lower()\ndata['comment_text'] = data['comment_text'].apply(cleanHtml)\ndata['comment_text'] = data['comment_text'].apply(cleanPunc)\ndata['comment_text'] = data['comment_text'].apply(keepAlpha)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a62519bb71569a94fd1ddeccd833390fc1ee7106"},"cell_type":"markdown","source":"##  Removing Stop Words"},{"metadata":{"trusted":true,"_uuid":"912ea56f67a21809fed3922e7d2c349b39d78457"},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nstop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\nre_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\ndef removeStopWords(sentence):\n    global re_stop_words\n    return re_stop_words.sub(\" \", sentence)\n\ndata['comment_text'] = data['comment_text'].apply(removeStopWords)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d883ffb614681d7d9c340aa064d1c01be03599a0"},"cell_type":"markdown","source":"## Stemming"},{"metadata":{"trusted":true,"_uuid":"ac21b2da5a44a49c9ba56f0bf2064e92cffb4bfe"},"cell_type":"code","source":"stemmer = SnowballStemmer(\"english\")\ndef stemming(sentence):\n    stemSentence = \"\"\n    for word in sentence.split():\n        stem = stemmer.stem(word)\n        stemSentence += stem\n        stemSentence += \" \"\n    stemSentence = stemSentence.strip()\n    return stemSentence\n\ndata['comment_text'] = data['comment_text'].apply(stemming)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3bbed7538d24bc0831c7513c4656c338fdd4994"},"cell_type":"markdown","source":"## Train-Test Split"},{"metadata":{"trusted":true,"_uuid":"59ee683977fa5f690996167f1ead9889e305b0fc"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(data, random_state=42, test_size=0.30, shuffle=True)\n\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"571db536fddd3f27e6626a5cff967bc703735057"},"cell_type":"code","source":"train_text = train['comment_text']\ntest_text = test['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab70c055a8e89e3615ca9f40c55128a99e80309"},"cell_type":"markdown","source":"## TF-IDF"},{"metadata":{"trusted":true,"_uuid":"5f7d3de3e26508f83ef555af928967d0b3097060"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\nvectorizer.fit(train_text)\nvectorizer.fit(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7117f4c30d6e8e88c9f62635c545169334c38a8"},"cell_type":"code","source":"x_train = vectorizer.transform(train_text)\ny_train = train.drop(labels = ['id','comment_text'], axis=1)\n\nx_test = vectorizer.transform(test_text)\ny_test = test.drop(labels = ['id','comment_text'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3143217350881a7c3437b4031449a0328e2ad92"},"cell_type":"markdown","source":" # 3. Multi-Label Classification\n##  Multiple Binary Classifications - (One Vs Rest Classifier)"},{"metadata":{"trusted":true,"_uuid":"eb2bff8232383d88f4c30aefec59e1cd345ee966"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf3b36e851970d12a311ca1ac09c5a6d6ffb650a"},"cell_type":"code","source":"%%time\n\n# Using pipeline for applying logistic regression and one vs rest classifier\nLogReg_pipeline = Pipeline([\n                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),\n            ])\n\nfor category in categories:\n    printmd('**Processing {} comments...**'.format(category))\n    \n    # Training logistic regression model on train data\n    LogReg_pipeline.fit(x_train, train[category])\n    \n    # calculating test accuracy\n    prediction = LogReg_pipeline.predict(x_test)\n    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))\n    print(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb047dc8ec407d005e4f220145b4586f4311bcd0"},"cell_type":"markdown","source":"## Multiple Binary Classifications - (Binary Relevance)"},{"metadata":{"trusted":true,"_uuid":"4094a22bc355f0f037aa474691edb35ca4ef3260"},"cell_type":"code","source":"%%time\n\n# using binary relevance\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.naive_bayes import GaussianNB\n\n# initialize binary relevance multi-label classifier\n# with a gaussian naive bayes base classifier\nclassifier = BinaryRelevance(GaussianNB())\n\n# train\nclassifier.fit(x_train, y_train)\n\n# predict\npredictions = classifier.predict(x_test)\n\n# accuracy\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\nprint(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbdd9fdcd52b632e63ec5dd269c0aca545da61d4"},"cell_type":"markdown","source":"## Classifier Chains"},{"metadata":{"trusted":true,"_uuid":"0a668fc817b4af138721fadd68324b8662561711"},"cell_type":"code","source":"# using classifier chains\nfrom skmultilearn.problem_transform import ClassifierChain\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74eac8abc5cc4fa42c02d053d0431de68283ab78"},"cell_type":"code","source":"%%time\n\n# initialize classifier chains multi-label classifier\nclassifier = ClassifierChain(LogisticRegression())\n\n# Training logistic regression model on train data\nclassifier.fit(x_train, y_train)\n\n# predict\npredictions = classifier.predict(x_test)\n\n# accuracy\nprint(\"Accuracy = \",accuracy_score(y_test,predictions))\nprint(\"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0a80f1df615fb4f4672b6bd621667e1b7e98de6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f412588736ff88f254a2fe006b64b38cf04726a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}