{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"source": ["# Pytorch DenseNet + Angle + RGB DataLoader\n", "\n", "\n", "- The angle is used as a Third RGB channel\n", "-  An alternative is to use the angle as a second input to the CNN (will do this next) "], "cell_type": "markdown", "metadata": {"_uuid": "779ab5dd78fcdaaf0d1387ae5dc3f175524858d9", "_cell_guid": "a6b7d6ae-f2f1-4ab3-bf7a-50948292cacd"}}, {"source": ["## Imports"], "cell_type": "markdown", "metadata": {}}, {"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "%reset -f\n", "\n", "import torch\n", "from torch.autograd import Variable\n", "import numpy as np\n", "import pandas\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "import matplotlib.pyplot as plt\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n", "import logging\n", "import numpy\n", "import numpy as np\n", "from __future__ import print_function\n", "from __future__ import division\n", "import math\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import pandas as pd\n", "import os\n", "import torch\n", "from torch.utils.data.dataset import Dataset\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torch import nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.autograd import Variable\n", "from sklearn.preprocessing import MultiLabelBinarizer\n", "import time\n", "from sklearn.preprocessing import PolynomialFeatures\n", "import pandas as pd\n", "import numpy as np\n", "import scipy\n", "%matplotlib inline\n", "from pylab import rcParams\n", "\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "import torch\n", "from torch import nn\n", "import torch.nn.functional as F\n", "from torch.autograd import Variable\n", "from torch.optim import Adam\n", "from torch.utils.data import TensorDataset, DataLoader\n", "from tqdm import tqdm_notebook\n", "import seaborn as sns\n"], "cell_type": "code", "metadata": {"_uuid": "c1cf1feee03e3784251c9ae345244d9ae5375af3", "collapsed": true, "_cell_guid": "303a9986-71cd-41d0-b53a-0b26ac4007cb"}, "execution_count": null, "outputs": []}, {"source": ["# %%timeit\n", "use_cuda = torch.cuda.is_available()\n", "# use_cuda = False\n", "\n", "print(\"USE CUDA=\" + str (use_cuda))\n", "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n", "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n", "Tensor = FloatTensor\n"], "cell_type": "code", "metadata": {"_uuid": "4c275216209a4e834ea224cb1d25a3e32b1eea50", "collapsed": true, "_cell_guid": "fcc60e51-f654-45b3-a621-6a2909e934a5"}, "execution_count": null, "outputs": []}, {"source": ["# fix seed\n", "seed=17*19\n", "np.random.seed(seed)\n", "torch.manual_seed(seed)\n", "if use_cuda:\n", "    torch.cuda.manual_seed(seed)"], "cell_type": "code", "metadata": {"_uuid": "97f568d27bfdecaf98e9226fea4c95c465630e67", "collapsed": true, "_cell_guid": "fa31a53f-e031-48b5-9a40-67fca0975794"}, "execution_count": null, "outputs": []}, {"source": [], "cell_type": "code", "metadata": {"_uuid": "db4d4d6154afcb3a5d444b0f288f04b9b15e35c0", "collapsed": true, "_cell_guid": "5861c386-86d2-4177-900e-7ed30aa76795"}, "execution_count": null, "outputs": []}, {"source": [" # PyTorch Custom Image DataLoader"], "cell_type": "markdown", "metadata": {"_uuid": "32093bd16103f80a50ef37fe5251c93ac9308263", "_cell_guid": "27e49cba-77a9-450e-bf7b-129cd41153a3"}}, {"source": ["import os\n", "import sys\n", "import random\n", "import numpy as np\n", "from torchvision import transforms\n", "from PIL import Image\n", "import torch\n", "import torch.utils.data as data\n", "\n", "IMG_EXTENSIONS = [\n", "    '.jpg',\n", "    'png'\n", "]\n", "\n", "to_tensor = transforms.Compose([transforms.ToTensor()])\n", "\n", "def is_img_file(filename):\n", "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n", "\n", "# def default_loader(path):\n", "# \treturn Image.open(path).convert('RGB')\n", "\n", "def tensor_load_rgbimage(filename, size=None, scale=None, keep_asp=False):\n", "    img = Image.open(filename).convert('RGB')\n", "    if size is not None:\n", "        if keep_asp:\n", "            size2 = int(size * 1.0 / img.size[0] * img.size[1])\n", "            img = img.resize((size, size2), Image.ANTIALIAS)\n", "        else:\n", "            img = img.resize((size, size), Image.ANTIALIAS)\n", "\n", "    elif scale is not None:\n", "        img = img.resize((int(img.size[0] / scale), int(img.size[1] / scale)), Image.ANTIALIAS)\n", "    img = np.array(img).transpose(2, 0, 1)\n", "    img = torch.from_numpy(img).float()\n", "    return img\n", "\n", "\n", "def default_loader_scale(input_path, size=20):\n", "    input_image = (Image.open(input_path)).convert('RGB')\n", "    if size is not None:\n", "        input_image = input_image.resize((size, size), Image.ANTIALIAS)\n", "\n", "    # input_image = np.array(input_image).transpose(2, 0, 1)\n", "    # input_image = torch.from_numpy(input_image).float()\n", "    return input_image\n", "\n", "def default_loader(input_path):\n", "    # pil_to_tensor = transforms.ToTensor()\n", "    input_image = (Image.open(input_path)).convert('RGB')\n", "    # input_image = pil_to_tensor(input_image)\n", "    # img = np.array(img).transpose(2, 0, 1)\n", "    # img = torch.from_numpy(img).float()\n", "    return input_image\n", "\n", "def find_classes(dir):\n", "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n", "    classes.sort()\n", "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n", "    return classes, class_to_idx\n", "\n", "def make_dataset(dir, class_to_idx):\n", "    tensors = []\n", "    if not os.path.exists(dir):\n", "        print(\"Seed dataset %s doesn't exist.\" % (dir))\n", "        sys.exit()\n", "    else:\n", "        dir = os.path.expanduser(dir)\n", "        for target in sorted(os.listdir(dir)):\n", "            d = os.path.join(dir, target)\n", "            if not os.path.isdir(d):\n", "                continue\n", "\n", "            for root, _, fnames in sorted(os.walk(d)):\n", "                for fname in sorted(fnames):\n", "                    if is_img_file(fname):\n", "                        path = os.path.join(root, fname)\n", "                        item = (path, class_to_idx[target])\n", "                        tensors.append(item)\n", "\n", "    return tensors\n", "\n", "\n", "class SeedImageDataset(data.Dataset):\n", "    def __init__(self,root,phase,loader=default_loader_scale,transform=None):\n", "\n", "        classes, class_to_idx = find_classes(root)\n", "        print ('Classes: {}'.format(classes))\n", "        print ('# Classes: {}'.format(len(classes)))\n", "        print ('Class to idx: {}'.format(class_to_idx))\n", "\n", "        tensors = make_dataset(root, class_to_idx)\n", "        if len(tensors) == 0:\n", "            raise (RuntimeError(\n", "                \"Found 0 sound files in subfolders of: \" + root + \"Supported img file extensions are: \" + \",\".join(\n", "                    IMG_EXTENSIONS)))\n", "\n", "        self.tensors = tensors\n", "        self.root = root\n", "        self.phase = phase\n", "        self.classes = classes\n", "        self.class_to_idx = class_to_idx\n", "        self.transform = transform\n", "        self.loader = loader\n", "\n", "\n", "    def __getitem__(self, index):\n", "        # Get path of input image and ground truth\n", "        input, target = self.tensors[index]\n", "        # Acquire input image and ground truth\n", "        input_tensor = self.loader(input)\n", "        # print (type(input_tensor)) # <class 'PIL.Image.Image'>\n", "\n", "        if self.transform is not None:\n", "            input_tensor = self.transform(input_tensor)\n", "\n", "        if type(input_tensor) is not torch.FloatTensor:\n", "        # print (type(input_tensor)) # MUST BE <class 'torch.FloatTensor'>\n", "            input_tensor=to_tensor(input_tensor)\n", "\n", "        return input_tensor, target\n", "\n", "    def __len__(self):\n", "        return len(self.tensors)\n"], "cell_type": "code", "metadata": {"_uuid": "48696e30f09b8817ea6f4f07ce5c1ac65e731b97", "_cell_guid": "90d2d22e-51a9-4532-b4bb-1b2d212827e8"}, "execution_count": null, "outputs": []}, {"source": ["#your custom aug function for numpy image:\n", "#seems like all flip augmentations may decrease performance\n", "\n", "\n", "normalize = transforms.Normalize(\n", "   mean=[0.485, 0.456, 0.406],\n", "   std=[0.229, 0.224, 0.225]\n", ")\n", "preprocess = transforms.Compose([\n", "#    transforms.Scale(256),\n", "#    transforms.CenterCrop(224),\n", "   transforms.ToTensor(),\n", "   normalize\n", "])\n", "\n", "train = pd.read_json('../input/train.json')\n", "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce')\n", "train['band_1'] = train['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n", "train['band_2'] = train['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n", "        \n", "batch_size = 32\n", "# train_ds = ImageDataset(train, include_target = True, u =0.5, X_transform = random_vertical_flip)\n", "train_ds = ImageDataset(train, include_target = True, X_transform = preprocess)\n", "USE_CUDA = False #for kernel\n", "THREADS = 1 #for kernel\n", "train_loader = data.DataLoader(train_ds, batch_size,\n", "                                    sampler = RandomSampler(train_ds),\n", "                                    num_workers = THREADS,\n", "                                    pin_memory= USE_CUDA )\n", "                                    \n", "#prseudo code for train\n", "# for i, dict_ in enumerate(train_loader):\n", "#     images  = dict_['img']\n", "#     target  = dict_['target'].type(torch.FloatTensor)\n", "    \n", "#     if USE_CUDA:\n", "#         images = images.cuda()\n", "#         target = target.cuda()\n", "    \n", "#     images = Variable(images)\n", "#     target = Variable(target)    \n", "    \n", "#     #for kernel:\n", "#     print(target)\n", "#     if i ==0 : break\n"], "cell_type": "code", "metadata": {"_uuid": "983c3598967c04c6306897427dd99108750859a4", "_cell_guid": "020bbd02-2ebe-49a7-bb9c-fe0e0c03c0b7"}, "execution_count": null, "outputs": []}, {"source": ["%matplotlib inline\n", "from torchvision.utils import make_grid\n", "    \n", "def flaotTensorToImage(img, mean=0, std=1):\n", "    \"\"\"convert a tensor to an image\"\"\"\n", "    img = img.numpy()\n", "    img= img.reshape(75, 75, 3)    \n", "    img = (img*std+ mean)*255\n", "    img = img.astype(np.uint8)    \n", "#     print (img.shape)\n", "    return img    \n", "    \n", "import matplotlib.pyplot as plt\n", "\n", "imagesToShow=4\n", "\n", "for i, data in enumerate(train_loader, 0):\n", "    print('i=%d: '%(i))            \n", "    images  = data['img']\n", "    target  = data['target'].type(torch.FloatTensor)\n", "    num = len(images)\n", "    ax = plt.subplot(1, imagesToShow, i + 1)\n", "    plt.tight_layout()\n", "    ax.set_title('Sample #{}'.format(i))\n", "    ax.axis('off')\n", "    \n", "    for n in range(num):\n", "        image=images[n]\n", "        label=target[n]\n", "        plt.imshow (flaotTensorToImage(image))\n", "#         show(image)\n", "        \n", "    if i==imagesToShow-1:\n", "        break    \n"], "cell_type": "code", "metadata": {"_uuid": "51392cdecd3f46bd43af13ac2c0fe2205ff4deb1", "collapsed": true, "_cell_guid": "adb275ba-0c2a-42fa-8d9c-82706b4ddfdb"}, "execution_count": null, "outputs": []}, {"source": ["from torch.utils.data import TensorDataset, DataLoader\n", "\n", "class FullTrainningDataset(torch.utils.data.Dataset):\n", "    def __init__(self, full_ds, offset, length):\n", "        self.full_ds = full_ds\n", "        self.offset = offset\n", "        self.length = length\n", "        assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n", "        super(FullTrainningDataset, self).__init__()\n", "        \n", "    def __len__(self):        \n", "        return self.length\n", "    \n", "    def __getitem__(self, i):\n", "        return self.full_ds[i+self.offset]\n", "    \n", "validationRatio=0.11    \n", "\n", "def trainTestSplit(dataset, val_share=0.11):\n", "    val_offset = int(len(dataset)*(1-val_share))\n", "    print (\"Offest:\" + str(val_offset))\n", "    return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, \n", "                                                                              val_offset, len(dataset)-val_offset)\n", "\n", "train_ds, val_ds = trainTestSplit(train_loader)\n", "t_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=False,\n", "                                            num_workers=1)\n", "v_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n", "\n", "print (t_loader)\n", "print (v_loader)"], "cell_type": "code", "metadata": {"_uuid": "64fdca54a5cf0723363021b4ed66a357e4452441", "collapsed": true, "_cell_guid": "9637b0b0-1e44-4158-a7be-4ebc166d2671"}, "execution_count": null, "outputs": []}, {"source": ["## Define simple model"], "cell_type": "markdown", "metadata": {"_uuid": "21eacbdcf5f04eecf86da49621b5aff4d3b92d8d", "_cell_guid": "9655dd9c-c792-4d15-bb8b-94a800eb9c0e"}}, {"source": ["import sys\n", "import math\n", "\n", "class Bottleneck(nn.Module):\n", "    def __init__(self, nChannels, growthRate):\n", "        super(Bottleneck, self).__init__()\n", "        interChannels = 4*growthRate\n", "        self.bn1 = nn.BatchNorm2d(nChannels)\n", "        self.conv1 = nn.Conv2d(nChannels, interChannels, kernel_size=1,\n", "                               bias=False)\n", "        self.bn2 = nn.BatchNorm2d(interChannels)\n", "        self.conv2 = nn.Conv2d(interChannels, growthRate, kernel_size=3,\n", "                               padding=1, bias=False)\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(F.relu(self.bn1(x)))\n", "        out = self.conv2(F.relu(self.bn2(out)))\n", "        out = torch.cat((x, out), 1)\n", "        return out\n", "\n", "class SingleLayer(nn.Module):\n", "    def __init__(self, nChannels, growthRate):\n", "        super(SingleLayer, self).__init__()\n", "        self.bn1 = nn.BatchNorm2d(nChannels)\n", "        self.conv1 = nn.Conv2d(nChannels, growthRate, kernel_size=3,\n", "                               padding=1, bias=False)\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(F.relu(self.bn1(x)))\n", "        out = torch.cat((x, out), 1)\n", "        return out\n", "\n", "class Transition(nn.Module):\n", "    def __init__(self, nChannels, nOutChannels):\n", "        super(Transition, self).__init__()\n", "        self.bn1 = nn.BatchNorm2d(nChannels)\n", "        self.conv1 = nn.Conv2d(nChannels, nOutChannels, kernel_size=1,\n", "                               bias=False)\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(F.relu(self.bn1(x)))\n", "        out = F.avg_pool2d(out, 2)\n", "        return out\n", "\n", "\n", "class DenseNet(nn.Module):\n", "    def __init__(self, growthRate, depth, reduction, nClasses, bottleneck):\n", "        super(DenseNet, self).__init__()\n", "\n", "        nDenseBlocks = (depth-4) // 3\n", "        if bottleneck:\n", "            nDenseBlocks //= 2\n", "\n", "        nChannels = 2*growthRate\n", "        self.conv1 = nn.Conv2d(3, nChannels, kernel_size=3, padding=1,\n", "                               bias=False)\n", "        self.dense1 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n", "        nChannels += nDenseBlocks*growthRate\n", "        nOutChannels = int(math.floor(nChannels*reduction))\n", "        self.trans1 = Transition(nChannels, nOutChannels)\n", "\n", "        nChannels = nOutChannels\n", "        self.dense2 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n", "        nChannels += nDenseBlocks*growthRate\n", "        nOutChannels = int(math.floor(nChannels*reduction))\n", "        self.trans2 = Transition(nChannels, nOutChannels)\n", "\n", "        nChannels = nOutChannels\n", "        self.dense3 = self._make_dense(nChannels, growthRate, nDenseBlocks, bottleneck)\n", "        nChannels += nDenseBlocks*growthRate\n", "\n", "        self.bn1 = nn.BatchNorm2d(nChannels)\n", "        self.fc = nn.Linear(128, nClasses)\n", "\n", "        for m in self.modules():\n", "            if isinstance(m, nn.Conv2d):\n", "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n", "                m.weight.data.normal_(0, math.sqrt(2. / n))\n", "            elif isinstance(m, nn.BatchNorm2d):\n", "                m.weight.data.fill_(1)\n", "                m.bias.data.zero_()\n", "            elif isinstance(m, nn.Linear):\n", "                m.bias.data.zero_()\n", "\n", "    def _make_dense(self, nChannels, growthRate, nDenseBlocks, bottleneck):\n", "        layers = []\n", "        for i in range(int(nDenseBlocks)):\n", "            if bottleneck:\n", "                layers.append(Bottleneck(nChannels, growthRate))\n", "            else:\n", "                layers.append(SingleLayer(nChannels, growthRate))\n", "            nChannels += growthRate\n", "        return nn.Sequential(*layers)\n", "\n", "    def forward(self, x):\n", "        out = self.conv1(x)\n", "        out = self.trans1(self.dense1(out))\n", "        out = self.trans2(self.dense2(out))\n", "        out = self.dense3(out)\n", "        # print(out.data.shape)\n", "        out = F.avg_pool2d(F.relu(self.bn1(out)), 8)\n", "        out = out.view(out.size(0), -1)\n", "        # print(out.data.shape)\n", "        out = F.sigmoid(self.fc(out))\n", "        return out\n", "\n", "model = DenseNet(growthRate=8, depth=20, reduction=0.5,\n", "                            bottleneck=True, nClasses=1)\n", "\n", "print (model)\n", "\n", "print('  + Number of params: {}'.format(sum([p.data.nelement() for p in model.parameters()])))"], "cell_type": "code", "metadata": {"_uuid": "4112e0197ba91e6ab2d39c65d67ed112fdc78729", "collapsed": true, "_cell_guid": "03178a5e-e8ef-4334-a97d-f1cf7c0fecf8"}, "execution_count": null, "outputs": []}, {"source": ["## Train"], "cell_type": "markdown", "metadata": {"_uuid": "d14d6e56da8fc08a04dede4ad982fc95c332c79b", "_cell_guid": "3e6db15e-bcab-421e-bab6-cd0e1d387736"}}, {"source": ["loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n", "\n", "# NN params\n", "LR = 0.0005\n", "MOMENTUM= 0.95\n", "optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\n", "if use_cuda:    \n", "    model.cuda()\n", "    loss_func.cuda()\n", "\n", "print(optimizer)\n", "print(loss_func)\n", "\n", "\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torchvision import datasets, transforms\n", "from torch.autograd import Variable\n", "\n", "criterion = loss_func\n", "all_losses = []\n", "val_losses = []\n", "num_epoches=10\n", "\n", "if __name__ == '__main__':\n", "\n", "    for epoch in range(num_epoches):\n", "        print('Epoch {}'.format(epoch + 1))\n", "        print('*' * 5 + ':')\n", "        running_loss = 0.0\n", "        running_acc = 0.0\n", "        \n", "        for i, data in enumerate(train_loader, 0):        \n", "            img  = data['img']\n", "            label  = data['target'].type(torch.FloatTensor)\n", "\n", "#         for i, data in enumerate(train_loader, 0):    \n", "#             img  = data['img']\n", "#             label  = data['target']#     \n", "            \n", "            img, label = Variable(img), Variable(label)  # RuntimeError: expected CPU tensor (got CUDA tensor)\n", "    \n", "            out = model(img).type(torch.FloatTensor).squeeze(1)\n", "            loss = criterion(out, label)\n", "            running_loss += loss.data[0] * label.size(0)\n", "    \n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()               \n", "    \n", "        print('Finish {} epoch, Loss: {:.6f}'.format(epoch + 1, running_loss / (len(train_ds))))\n", "    \n", "#         model.eval()\n", "#         eval_loss = 0\n", "#         eval_acc = 0\n", "#         for data in v_loader:            \n", "#             img  = data['img']\n", "#             label  = data['target']\n", "            \n", "#             img = Variable(img, volatile=True)\n", "#             label = Variable(label, volatile=True)\n", "    \n", "#             out = model(img).type(torch.FloatTensor).squeeze(1)\n", "#             loss = criterion(out, label)\n", "#             eval_loss += loss.data[0] * label.size(0)\n", "    \n", "#         print('VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_ds))))\n", "#         val_losses.append(eval_loss / (len(val_ds)))\n", "#         print()\n", "    \n", "    torch.save(model.state_dict(), './cnn.pth')"], "cell_type": "code", "metadata": {"_uuid": "dce6970dc7686d32f9b92e49880b578b98dd3647", "collapsed": true, "_cell_guid": "85270692-7f04-4a94-92fb-57c0a3b27ba5"}, "execution_count": null, "outputs": []}, {"source": [], "cell_type": "code", "metadata": {"_uuid": "abad58921a6aeb5ea0603056bb0021436b73d039", "collapsed": true, "_cell_guid": "7025d0d8-206f-4cb0-af69-7b1a85ebd7f8"}, "execution_count": null, "outputs": []}], "nbformat": 4}