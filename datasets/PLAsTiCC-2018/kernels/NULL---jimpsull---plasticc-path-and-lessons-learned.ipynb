{"cells":[{"metadata":{"_uuid":"cf675c2dde7950e45a15230a1e7f321f9a3305fe"},"cell_type":"markdown","source":"## Kernels and discussions used in this kernel\n- [Oliver's kernel](https://www.kaggle.com/ogrellier/plasticc-in-a-kernel-meta-and-data)\n- [Alexander Firsov's kernel](https://www.kaggle.com/alexfir/fast-test-set-reading)\n- [Iprapas' kernel](https://www.kaggle.com/iprapas/ideas-from-kernels-and-discussion-lb-1-135)\n- [Chia-Ta Tsai's kernel](https://www.kaggle.com/cttsai/forked-lgbm-w-ideas-from-kernels-and-discuss)\n- [Lving's kernel](https://www.kaggle.com/qianchao/smote-with-imbalance-data)\n- [Scirpus' class 99 method](https://www.kaggle.com/c/PLAsTiCC-2018/discussion/72104)\n- [My something different kernel](https://www.kaggle.com/jimpsull/something-different)\n- [My Smote the training set kernel](https://www.kaggle.com/jimpsull/smote-the-training-sets)"},{"metadata":{"_uuid":"656982859d470a3dd6b4da04916ea1b3ec84fa3d"},"cell_type":"markdown","source":"## Broad summary of my path\n- Submitted just to proove we could submit where everything was as probable as it's share of the train set and class 99 was 0.01 (3.386)\n- First submission based on our [custom features](https://www.kaggle.com/jimpsull/train-and-submit).  Some of the data resides in deleted kernels. (1.958)\n- Copied  [Iprapas' kernel](https://www.kaggle.com/iprapas/ideas-from-kernels-and-discussion-lb-1-135).\n- [Applied Smote](https://www.kaggle.com/jimpsull/smoteappliedeachstepwithoutweighting) to Iprapas kernel (1.111)\n- [Applied smote ](https://www.kaggle.com/jimpsull/forked-dart-w-ideas-from-kernels-added-smote)to  [Chia-Ta Tsai's kernel](https://www.kaggle.com/cttsai/forked-lgbm-w-ideas-from-kernels-and-discuss) (1.052)\n- Applied  [Scirpus' class 99 method](https://www.kaggle.com/c/PLAsTiCC-2018/discussion/72104) to [Smote Dart With 99](https://www.kaggle.com/jimpsull/improveclass99fordartsmoteset?scriptVersionId=7622634) (1.039)\n- Added [our custom features](https://www.kaggle.com/jimpsull/somethingdifferent-testsetedition) to [SmoteDart99](https://www.kaggle.com/jimpsull/featuremergingkernelwithaggcustom?scriptVersionId=7767390) (1.030)\n- Did [some parameter tuning](https://www.kaggle.com/jimpsull/parametergridsearch) to arrive at [best parameters](https://www.kaggle.com/jimpsull/ourpathtowherewearenewparams) (1.010)\n- [Blended some of models](https://www.kaggle.com/jimpsull/blendmodels?scriptVersionId=8311774) (0.996)\n- [Eliminated near zero values](https://www.kaggle.com/jimpsull/adjustpredictiondataframe?scriptVersionId=8354235) (0.992)\n- Created a [decent neural net model](https://www.kaggle.com/jimpsull/mergeneural512newparams) by processing [extra-galactic](https://www.kaggle.com/jimpsull/egneural512newfeats) and [intra-galactic](https://www.kaggle.com/jimpsull/igneural1024newfeats) separately and by **[log-normalizing our data together](https://www.kaggle.com/jimpsull/lognormalizefeaturesetstogetherwextrafeats)** (better than 1.056)\n- [Blended our neural net model with our LGBM model](https://www.kaggle.com/jimpsull/fiftyfivefourtyfiveblend?scriptVersionId=8460185) (0.952)\n- [Blended](https://www.kaggle.com/jimpsull/latestneuralfiftyfiftyblendwithmoredecisiveneural) our [More Decisive Neural](https://www.kaggle.com/jimpsull/neuralmoredecisive) with our LGBM model (0.939)\n- [Blended](https://www.kaggle.com/jimpsull/fortyfortytwentyblend) our [More Decisive](https://www.kaggle.com/jimpsull/multiclasssvmmoredecisive) SVM with our Decisive Neural and our LGBM.  Note that SVM had to be [trained ](https://www.kaggle.com/jimpsull/svmmulticlassnewdataless)separately, [split up](https://www.kaggle.com/jimpsull/svmclf4top), and then [merged back together](https://www.kaggle.com/jimpsull/mergebottommiddleandtopclf0). (0.942, generalizable)\n\n"},{"metadata":{"_uuid":"561527932df3055d04c8e0b8933b90fac860b5df"},"cell_type":"markdown","source":"## Lessons Learned and interesting things that didn't work\n- The [newTestizeTrain method](https://www.kaggle.com/jimpsull/closethegapbetweencvandlb) showed promise but never delievered (1.076 LB)\n- [Integrated SMOTE with neural networks ](https://www.kaggle.com/jimpsull/egneuraltt512wsmote)but something wasn't quite right\n- [Tried using predictions from three models as features ](https://www.kaggle.com/jimpsull/lgbfourmoreregfastmax)(target leakage).  I tried several variations on this theme.  Some lessons have to be learned more than once."},{"metadata":{"_uuid":"460dc10fd67d7507a39298096d952912becca892"},"cell_type":"markdown","source":"## The code is in the linked kernels.  I have made efforts to make dependencies public\n- but I had quite a spiderweb of kernels by the end of the contest\n- if you want something shared just ask and I'll be happy to make it public"},{"metadata":{"trusted":true,"_uuid":"be62d20789657f7ebbcc77e1048a34c558cae52c"},"cell_type":"code","source":"doSomething=False","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}