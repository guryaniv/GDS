{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# House keeping\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Digit Recognition\n\nIn this notebook we want to explore using keras to build a deep learning model which given an image of a hand-written digit $X$ can predict which digit that image represents.\n\nThis is a **classification problem** and we have a labeled dataset so its **supervised** as well.\n\nLet's start by inspecting our dataset.\n"},{"metadata":{"trusted":true,"_uuid":"6a451e4ccf6771102407dc35d59c59d44b86b4ae"},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ea66b376e995c58e5617b7fca628f41e2ec8298"},"cell_type":"markdown","source":"The first column is our label (the ground truth number for the digit), the rest of the columns are the 784 pixels of each image. This means the images are 28x28 pixels in size.\n\nNow let's look at a sample image."},{"metadata":{"trusted":true,"_uuid":"7e42f0dc4ef92cec37134a8bf2ca99c888415030"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntrain_labels = df['label']\nimage_data = df.iloc[:, 1:].as_matrix()\nprint(image_data.shape)\nprint(train_labels[:5])\nprint('min: {}, max: {}'.format(np.min(image_data), np.max(image_data)))\n\n# plot the histogram distribution of the labels\nplt.hist(train_labels)\nplt.ylabel('# of exemplars')\nplt.xlabel('ground truth number')\nplt.show()\n\ninspection_index = 100\n\ndef plot_image(image_data, label):\n    plt.title(\"Number - {}\".format(label))\n    plt.imshow(image_data.reshape(28,28), cmap='gray')\n    plt.axis('off')\n    plt.show()\n    \nplot_image(image_data[6, :], train_labels[6])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e50ac2e5d6aa93dbe3e37be6dc92806a15b3dd5"},"cell_type":"markdown","source":"### Dataset Information\n\n1. Our Images are 28x28x1 (grayscale)\n2. We have 42,000 training images\n3. The images are roughly uniformly distributed.\n4. The values of each pixel range from 0-255.\n5. Our labels are numerical values from 0-9.\n\nThis is nice because our data is balanced. Now let's split up the dataset into *Train/Test/Validation*.\n\nIts very important that we don't touch our **validation** data until the very end.\n\nI'll do 70 / 20 / 10 for the split.\n\nWe will also need to one-hot encode our labels since we want to have a softmax output function."},{"metadata":{"trusted":true,"_uuid":"ec5fe16a85c7393e9cafeb5ef5cf7bd819f66e85"},"cell_type":"code","source":"from keras.utils import to_categorical\n\n# set the random seed so this is repeatable\nnp.random.seed(42)\n# shuffle our dataset to make sure its good and random\nindices = np.arange(len(image_data))\nnp.random.shuffle(indices)\nshuffled_image_data = image_data[indices]\nshuffled_label_data = train_labels[indices]\n\n# convert the training labels into one hot encodings\nshuffled_labels_one_hot = to_categorical(shuffled_label_data)\nprint(shuffled_labels_one_hot[:5])\n\ndef split_dataset(data, labels, train=0.7, test=0.2, validation=0.1):\n    n = len(data)\n    train_end_index = round(train * n)\n    test_end_index = train_end_index + round(test * n)\n    \n    train_data = data[:train_end_index]\n    train_labels = labels[:train_end_index]\n    \n    test_data  = data[train_end_index:test_end_index]\n    test_labels  = labels[train_end_index:test_end_index]\n    \n    validation_data = data[test_end_index:]\n    validation_labels  = labels[test_end_index:]\n\n    return (train_data, train_labels, test_data, test_labels, validation_data, validation_labels)\n\nx_train, y_train, x_test, y_test, x_val, y_val = split_dataset(shuffled_image_data, shuffled_labels_one_hot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a92374889d2d167d9d8a7a10be9245170402e327"},"cell_type":"code","source":"plot_image(x_train[100], np.argmax(y_train[100]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"725e3fbe95ad34d3cd6743141a4a778c31ef86c3"},"cell_type":"markdown","source":"### Building the model\n\nWe've constructed our dataset so now its time to build the model\n\nWe'll do the following.\n\n1. Construct a simple **Convolutional Neural Network**.\n2. Start with a few layers and not many nodes.\n3. Use `EarlyStopping` to exit if we aren't making progress.\n4. Use the **Adam Optimizer** and **crossentropy** loss function"},{"metadata":{"trusted":true,"_uuid":"07c761763450ff7aaae21cf29d994db9aee7736c"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\n\nn_cols = x_train.shape[1]\nearly_stopping_monitor = EarlyStopping(patience=2)\nlearning_rate = 0.001\n\nmodel = Sequential()\nmodel.add(Dense(784, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nprint(model.summary())\n\nmodel.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad717228d606745620e28de64d470fe4cd60457f","collapsed":true},"cell_type":"code","source":"# Fitting the model\nepochs = 15\nbatch_size = 64\n\nhist = model.fit(x_train, y_train, epochs=epochs, validation_data=(x_test, y_test), batch_size=batch_size, callbacks=[early_stopping_monitor])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90ed1d28b5808509dad0f5e71d11e76230df9676"},"cell_type":"code","source":"from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n\ndef print_stats(y_true, y_pred):\n    y_true = np.argmax(y_true, axis=1)\n    y_pred = np.argmax(y_pred, axis=1)\n    print(\"Accuracy: {:.4f}\".format(accuracy_score(y_true, y_pred)))\n    print(\"Precision: {:.4f}\".format(precision_score(y_true, y_pred, average='macro')))\n    print(\"Recall: {:.4f}\".format(recall_score(y_true, y_pred, average='macro')))\n    print('F1: {:.4f}'.format(f1_score(y_true, y_pred, average='macro')))\n    \npreds = model.predict(x_val)\n\nprint_stats(y_val, preds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1c12f77449948e0841cb105ce982266b1c46fc8"},"cell_type":"markdown","source":"## Results Summary\n\nThat doesn't look too shabby for our very first and also very simple model. But we were just using a Neural Network. Let's try it now with a **Convolution Neural Network**."},{"metadata":{"trusted":true,"_uuid":"be75f0302510d76a6cdb3935eceba9bce6af5f22"},"cell_type":"code","source":"from keras.layers import Conv2D, Flatten, Dropout, MaxPooling2D\n\nlearning_rate = 0.001\n\n# we need to reshape our data to be (rows, image_width, image_height, image_depth)\nx_train2 = x_train.reshape(x_train.shape[0], 28, 28, 1).astype(np.float32)\nx_test2 = x_test.reshape(x_test.shape[0], 28, 28, 1).astype(np.float32)\nx_val2 = x_val.reshape(x_val.shape[0], 28, 28, 1).astype(np.float32)\nx_train2 /= 255\nx_test2 /= 255\nx_val2 /= 255\n\nplot_image(x_train2[10], np.argmax(y_train[10]))\n\nmodel = Sequential()\nmodel.add(Conv2D(128, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(128, (5,5), activation='relu'))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\nprint(model.summary())\n\nmodel.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b52503d60c5e0754a8d63341f278f415befa6820","collapsed":true},"cell_type":"code","source":"# Fitting the model\nepochs = 15\nbatch_size = 128\n\nhist = model.fit(x_train2, y_train, epochs=epochs, validation_data=(x_test2, y_test), batch_size=batch_size, callbacks=[early_stopping_monitor])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f0c957797f4740ce247c421b4e2ed2f99a210e4","collapsed":true},"cell_type":"code","source":"cnn_preds = model.predict(x_val2)\n\nprint_stats(y_val, cnn_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"430b779ec410ce8725894cc517a6f9045db6ed83"},"cell_type":"code","source":"# Now Let's try with Data Augmentation\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rotation_range=15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    horizontal_flip=False)\n\nmodel = Sequential()\nmodel.add(Conv2D(256, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(64, (5,5), activation='relu'))\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nprint(model.summary())\n\nmodel.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbcb6928e188fb4d7985f8a3dc25f8996374e6d2"},"cell_type":"code","source":"datagen.fit(x_train2)\nepochs = 15\n\n# fits the model on batches with real-time data augmentation:\nhist = model.fit_generator(datagen.flow(x_train2, y_train, batch_size=64),\n                    steps_per_epoch=len(x_train2) / 32, epochs=epochs, validation_data=(x_test2, y_test), callbacks=[early_stopping_monitor])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3657681644a43b1af03f6e1aaa37a44b6813b4a4"},"cell_type":"code","source":"## Finally Read in the test.csv and make predictions\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf_test.head(2)\n\nsample = pd.read_csv(\"../input/sample_submission.csv\")\nsample.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2f6ce7b6e75a4ab7476b0f171475044af163a41"},"cell_type":"code","source":"test_image_data = df_test.as_matrix()\ntest_data = test_image_data.reshape(test_image_data.shape[0], 28, 28, 1).astype(np.float32)\ntest_data /= 255\n\npreds_one_hot = model.predict(test_data)\npreds = np.argmax(preds_one_hot, axis=1)\nimage_ids = np.arange(1,len(preds)+1)\n\nout_df = pd.DataFrame({'ImageId' : image_ids, 'Label' : preds })\nout_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a8eef69e7c06ddb97074c22c58572d03363784","collapsed":true},"cell_type":"code","source":"out_df.to_csv('model_predictions3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b6b664f20c4c134ec71a1a4ff5b7c24eca3ea51"},"cell_type":"code","source":"plot_image(test_data[125], preds[125])\nprint(len(out_df))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}