{"cells":[{"metadata":{"_uuid":"3bdfbc41ee048520cb0ed06b8e2e8948f2be8150","_cell_guid":"f1dabba2-b5b9-4f6a-8608-09619fb626ef"},"cell_type":"markdown","source":"**Loading Libraries and Data**"},{"metadata":{"_uuid":"3b692ebafdb3c04a75dfc9784816fb39e0806abd","_cell_guid":"f79946d3-c72e-4c12-8bec-46d62a1dfd93","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import *\nimport nltk, datetime\n\ntrain = pd.read_csv('../input/sales_train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')\nitems = pd.read_csv('../input/items.csv')\nitem_cats = pd.read_csv('../input/item_categories.csv')\nshops = pd.read_csv('../input/shops.csv')\nprint('train:', train.shape, 'test:', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecae934f9f8b77a781af02d1ea9cb690a5c84efd","_cell_guid":"cb2165d6-defc-4a7e-b243-6d790fe7bcd2"},"cell_type":"markdown","source":"**Difference betwee train and test**"},{"metadata":{"_uuid":"8a0f02d7e9e76d34c09586803f2e5b1b8f7eb28c","_cell_guid":"bc132448-3eac-4f87-86b2-c5605c9d6d90","trusted":false,"collapsed":true},"cell_type":"code","source":"[c for c in train.columns if c not in test.columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49b356cd6d2beca9aea2dbc0d0ea0a76211ad294","_cell_guid":"a68200ce-59ee-4f0d-9634-4af5632da8c1","trusted":false,"collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d13d0eb7d0af364e29c083a3cd1433e64a9eb357","_cell_guid":"c554496b-feb5-42ab-a87a-88809538d071","trusted":false,"collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c34fa08c3eb8491840410cbe7a8cba63402a577","_cell_guid":"78d38dd9-4972-45ec-bc26-cde6dd475be3"},"cell_type":"markdown","source":"**Adding Features**\n\n* Text Features\n* Date Features (Not necessarily needed for monthly summary but may help if using daily preds)"},{"metadata":{"_uuid":"c55543aed6c1026d1c9888e73109b57a3bca317b","_cell_guid":"c4adc724-11ed-422d-911f-58f937ba57f6","trusted":false,"collapsed":true},"cell_type":"code","source":"#Text Features\nfeature_cnt = 25\ntfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\nitems['item_name_len'] = items['item_name'].map(len) #Lenth of Item Description\nitems['item_name_wc'] = items['item_name'].map(lambda x: len(str(x).split(' '))) #Item Description Word Count\ntxtFeatures = pd.DataFrame(tfidf.fit_transform(items['item_name']).toarray())\ncols = txtFeatures.columns\nfor i in range(feature_cnt):\n    items['item_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b6d80225d6ceb086dab34e7fac49f4818584b90","_cell_guid":"2ea0fc7b-44dc-4648-9457-5a36caa3f3f5","trusted":false,"collapsed":true},"cell_type":"code","source":"#Text Features\nfeature_cnt = 25\ntfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\nitem_cats['item_category_name_len'] = item_cats['item_category_name'].map(len)  #Lenth of Item Category Description\nitem_cats['item_category_name_wc'] = item_cats['item_category_name'].map(lambda x: len(str(x).split(' '))) #Item Category Description Word Count\ntxtFeatures = pd.DataFrame(tfidf.fit_transform(item_cats['item_category_name']).toarray())\ncols = txtFeatures.columns\nfor i in range(feature_cnt):\n    item_cats['item_category_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\nitem_cats.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7c989c9ef2396e22fafe4d9289b6a7a25342d3b","_cell_guid":"0df4028d-f0d8-4270-9232-91d0582bd640","trusted":false,"collapsed":true},"cell_type":"code","source":"#Text Features\nfeature_cnt = 25\ntfidf = feature_extraction.text.TfidfVectorizer(max_features=feature_cnt)\nshops['shop_name_len'] = shops['shop_name'].map(len)  #Lenth of Shop Name\nshops['shop_name_wc'] = shops['shop_name'].map(lambda x: len(str(x).split(' '))) #Shop Name Word Count\ntxtFeatures = pd.DataFrame(tfidf.fit_transform(shops['shop_name']).toarray())\ncols = txtFeatures.columns\nfor i in range(feature_cnt):\n    shops['shop_name_tfidf_' + str(i)] = txtFeatures[cols[i]]\nshops.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c886ef73ab314f7c3ea166785c3f6f93c1bb49a2","_cell_guid":"510a7163-0946-469d-99a7-70cf6c84b622","trusted":false,"collapsed":true},"cell_type":"code","source":"#Make Monthly\ntrain['date'] = pd.to_datetime(train['date'], format='%d.%m.%Y')\ntrain['month'] = train['date'].dt.month\ntrain['year'] = train['date'].dt.year\ntrain = train.drop(['date','item_price'], axis=1)\ntrain = train.groupby([c for c in train.columns if c not in ['item_cnt_day']], as_index=False)[['item_cnt_day']].sum()\ntrain = train.rename(columns={'item_cnt_day':'item_cnt_month'})\n#Monthly Mean\nshop_item_monthly_mean = train[['shop_id','item_id','item_cnt_month']].groupby(['shop_id','item_id'], as_index=False)[['item_cnt_month']].mean()\nshop_item_monthly_mean = shop_item_monthly_mean.rename(columns={'item_cnt_month':'item_cnt_month_mean'})\n#Add Mean Feature\ntrain = pd.merge(train, shop_item_monthly_mean, how='left', on=['shop_id','item_id'])\n#Last Month (Oct 2015)\nshop_item_prev_month = train[train['date_block_num']==33][['shop_id','item_id','item_cnt_month']]\nshop_item_prev_month = shop_item_prev_month.rename(columns={'item_cnt_month':'item_cnt_prev_month'})\nshop_item_prev_month.head()\n#Add Previous Month Feature\ntrain = pd.merge(train, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n#Items features\ntrain = pd.merge(train, items, how='left', on='item_id')\n#Item Category features\ntrain = pd.merge(train, item_cats, how='left', on='item_category_id')\n#Shops features\ntrain = pd.merge(train, shops, how='left', on='shop_id')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2aebc75e924df4ac7b60262768962c6eedc47800","_cell_guid":"f537a9bc-6d64-4f15-9b7f-13ee5c66b5a2","trusted":false,"collapsed":true},"cell_type":"code","source":"test['month'] = 11\ntest['year'] = 2015\ntest['date_block_num'] = 34\n#Add Mean Feature\ntest = pd.merge(test, shop_item_monthly_mean, how='left', on=['shop_id','item_id']).fillna(0.)\n#Add Previous Month Feature\ntest = pd.merge(test, shop_item_prev_month, how='left', on=['shop_id','item_id']).fillna(0.)\n#Items features\ntest = pd.merge(test, items, how='left', on='item_id')\n#Item Category features\ntest = pd.merge(test, item_cats, how='left', on='item_category_id')\n#Shops features\ntest = pd.merge(test, shops, how='left', on='shop_id')\ntest['item_cnt_month'] = 0.\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0669bd58d0e50136f21abe88b25470102b8cb0fb","_cell_guid":"8e46cd2f-6365-46ea-b7ca-c424dcc8c169"},"cell_type":"markdown","source":"**Visualize**"},{"metadata":{"_uuid":"88f3ec03296fcddf0b097b7543a62ebf23ed1250","_cell_guid":"8311f5f3-ed68-498a-b7a5-ac1242cd2c54","trusted":false,"collapsed":true},"cell_type":"code","source":"from PIL import Image, ImageDraw, ImageFilter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\ndf_all = pd.concat((train, test), axis=0, ignore_index=True)\nstores_hm = df_all.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\nfig, ax = plt.subplots(figsize=(10,10))\n_ = sns.heatmap(stores_hm, ax=ax, cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"467e5849ec6cfeff2b06337fab5d3602e5ef9afa","_cell_guid":"dcf0337e-262f-4352-a953-589cc71f3188","trusted":false,"collapsed":true},"cell_type":"code","source":"stores_hm = test.pivot_table(index='shop_id', columns='item_category_id', values='item_cnt_month', aggfunc='count', fill_value=0)\nfig, ax = plt.subplots(figsize=(10,10))\n_ = sns.heatmap(stores_hm, ax=ax, cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13ca0c3735f362450d1f7857b1518aad3ecec75b","_cell_guid":"3e0a8266-8977-4c53-9f87-60e61ffef7fa"},"cell_type":"markdown","source":"**Label Encoding**\n\n* Try different approaches - weight based sequence, etc."},{"metadata":{"_uuid":"e2a5e0d8ce2d9362182da3c357ccd883c9310137","_cell_guid":"bb6f44d4-d033-4af6-af57-758bb30bb92b","trusted":false,"collapsed":true},"cell_type":"code","source":"for c in ['shop_name','item_name','item_category_name']:\n    lbl = preprocessing.LabelEncoder()\n    lbl.fit(list(train[c].unique())+list(test[c].unique()))\n    train[c] = lbl.transform(train[c].astype(str))\n    test[c] = lbl.transform(test[c].astype(str))\n    print(c)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0066fc6b474c1c3aa278ddb1d51710a1d6d83768","_cell_guid":"292aafcb-d584-4628-9841-28f8e22b3c15"},"cell_type":"markdown","source":"**Train & Predict Models**"},{"metadata":{"_uuid":"d6e6ff63bd26f80789a5f311ac41fbbf324956b9","_cell_guid":"576dd27f-1d3a-4ca0-bd48-2603ff8fc6bf","trusted":false,"collapsed":true},"cell_type":"code","source":"col = [c for c in train.columns if c not in ['item_cnt_month']]\n#Validation Hold Out Month\nx1 = train[train['date_block_num']<33]\ny1 = np.log1p(x1['item_cnt_month'].clip(0.,20.))\nx1 = x1[col]\nx2 = train[train['date_block_num']==33]\ny2 = np.log1p(x2['item_cnt_month'].clip(0.,20.))\nx2 = x2[col]\n\nreg = ensemble.ExtraTreesRegressor(n_estimators=25, n_jobs=-1, max_depth=15, random_state=18)\nreg.fit(x1,y1)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.),reg.predict(x2).clip(0.,20.))))\n#full train\nreg.fit(train[col],train['item_cnt_month'].clip(0.,20.))\ntest['item_cnt_month'] = reg.predict(test[col]).clip(0.,20.)\ntest[['ID','item_cnt_month']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9d619dc405e58b1bcab054fa0a7bb3af6bea146","_cell_guid":"e1bde3b5-2522-4e4f-bace-4db835673122"},"cell_type":"markdown","source":"**Happy Kaggling :)**\n\n* Try XGBoost, LightGBM, CatBoost next\n* Try some more Scikit-Learn Linear Regressors and more\n* Also try TensorFlow, Keras, PyTorch or other NN models for extra fun\n* Add more text features\n* Make some ensembles\n* Tune your models further\n* Add some awesome visualizations\n* Comment on Kernels for feedback, fork some, share your own versions\n\nHave some fun!"},{"metadata":{"_uuid":"fea14fa63f814ddccc1ce4919f5e198e493f45a1","_cell_guid":"32e69ea6-808d-4c05-854c-1ec328accc37"},"cell_type":"markdown","source":"**Getting Started with More Models**\n\n* Off to model tuning land you go now..."},{"metadata":{"_uuid":"75db5e5a937ed284ece9e984e86242f97181aab9","_cell_guid":"3f918185-1964-486c-8ca6-11a021db4776","trusted":false,"collapsed":true},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\nfrom multiprocessing import *\n\n#XGBoost\ndef xgb_rmse(preds, y):\n    y = y.get_label()\n    score = np.sqrt(metrics.mean_squared_error(y.clip(0.,20.), preds.clip(0.,20.)))\n    return 'RMSE', score\n\nparams = {'eta': 0.2, 'max_depth': 4, 'objective': 'reg:linear', 'eval_metric': 'rmse', 'seed': 18, 'silent': True}\n#watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n#xgb_model = xgb.train(params, xgb.DMatrix(x1, y1), 100,  watchlist, verbose_eval=10, feval=xgb_rmse, maximize=False, early_stopping_rounds=20)\n#test['item_cnt_month'] = xgb_model.predict(xgb.DMatrix(test[col]), ntree_limit=xgb_model.best_ntree_limit)\n#test[['ID','item_cnt_month']].to_csv('xgb_submission.csv', index=False)\n\n#LightGBM\ndef lgb_rmse(preds, y):\n    y = np.array(list(y.get_label()))\n    score = np.sqrt(metrics.mean_squared_error(y.clip(0.,20.), preds.clip(0.,20.)))\n    return 'RMSE', score, False\n\nparams = {'learning_rate': 0.2, 'max_depth': 7, 'boosting': 'gbdt', 'objective': 'regression', 'metric': 'mse', 'is_training_metric': False, 'seed': 18}\n#lgb_model = lgb.train(params, lgb.Dataset(x1, label=y1), 100, lgb.Dataset(x2, label=y2), feval=lgb_rmse, verbose_eval=10, early_stopping_rounds=20)\n#test['item_cnt_month'] = lgb_model.predict(test[col], num_iteration=lgb_model.best_iteration)\n#test[['ID','item_cnt_month']].to_csv('lgb_submission.csv', index=False)\n\n#CatBoost\ncb_model = CatBoostRegressor(iterations=100, learning_rate=0.2, depth=7, loss_function='RMSE', eval_metric='RMSE', random_seed=18, od_type='Iter', od_wait=20) \ncb_model.fit(x1, y1, eval_set=(x2, y2), use_best_model=True, verbose=False)\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y2.clip(0.,20.), cb_model.predict(x2).clip(0.,20.))))\ntest['item_cnt_month'] += cb_model.predict(test[col])\ntest['item_cnt_month'] /= 2\ntest[['ID','item_cnt_month']].to_csv('cb_blend_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47f2952e7ce3c35d638788b467e11fbfe9a9809c","_cell_guid":"fd12c4e2-0ce2-43dd-9e8e-35e5157e807d","collapsed":true,"trusted":false},"cell_type":"code","source":"#test['item_cnt_month'] = np.expm1(test['item_cnt_month'])\n#test[['ID','item_cnt_month']].to_csv('cb_submission_exp.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}