{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"**PyTorch Practice -CNN**\n\nHello everyone!! \n\nThis is my first kernel, I'm very new to image classification and deep learnning. \n\nAny comment is very welcome!!"},{"metadata":{"_uuid":"20f8c2639e9ce938e5cfe68d9798c14c3c95a2de"},"cell_type":"markdown","source":"**Reference**\n\n\n[Starting kit for PyTorch Deep Learning](https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning?fbclid=IwAR0ukfUlQjN1LBWJ974ugnFlwvnJ3Q5KfuWLOqRKaKngtVg6anvNBsbZgqg)\n\n[CNN 128x128x4, Keras from scratch [LB 0.328]](https://www.kaggle.com/rejpalcz/cnn-128x128x4-keras-from-scratch-lb-0-328)\n\n[Protein Atlas - Exploration and Baseline](https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline)"},{"metadata":{"_uuid":"0769e6943e7d182819c62a716f479aa846ebd513"},"cell_type":"markdown","source":"**Import libraries**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\n#import seaborn as sns\n#import matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1818804cc261b288fc5dcbffc5b13eb9bb19159"},"cell_type":"markdown","source":"**Loding image data**"},{"metadata":{"trusted":true,"_uuid":"c1a1d6db37bb719e5e41beaa5c589e824ee5688e"},"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, csv_file, img_path, transform=None):\n\n        self.csv_file = csv_file\n        self.img_path = img_path\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.csv_file)\n\n    def __getitem__(self, idx):\n        #csv_file=train_labels\n        #img_path=\"D:/Human Protein Atlas Image Classification/train/\"\n        #idx=0\n        #path= img_path+csv_file.iloc[idx, 0]\n        \n        path = self.img_path+self.csv_file.iloc[idx, 0]\n        \n        R = Image.open(path + '_red.png')\n        G = Image.open(path + '_green.png')\n        B = Image.open(path + '_blue.png')\n        Y = Image.open(path + '_yellow.png')\n\n        im = np.stack((\n            np.array(R)/255, \n            np.array(G)/255, \n            np.array(B)/255,\n            np.array(Y)/255))\n        \n        im=torch.Tensor(im)\n        label = torch.from_numpy(np.array(list(self.csv_file.iloc[idx,1:]))).float()\n        \n        return im, label","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3073c290e6899b4b67274c2daf92ffbca24b032e"},"cell_type":"markdown","source":"**CNN model**"},{"metadata":{"trusted":true,"_uuid":"c1068fab734602a0628e04555e6740c0b503e978"},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n\n        self.C1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3,padding=1)\n        self.C2 = nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3,padding=1)\n        \n        self.C3 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3,padding=1)\n        self.C4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3,padding=1)\n        \n        self.C5 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,padding=1)\n        self.C6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        self.C7 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        self.C8 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3,padding=1)\n        \n        self.C9 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,padding=1)\n        self.C10 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n        self.C11 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n        self.C12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1)\n\n        self.L1 = nn.Linear(32*32*64, 512)\n        self.L2 = nn.Linear(512, 28)\n\n    def forward(self, x):\n        x=self.C1(x)\n        x=self.C2(x)\n        x=F.max_pool2d(F.relu(x),2)\n\n        x=self.C3(x)\n        x=self.C4(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x=self.C5(x)\n        x=self.C6(x)\n        x=self.C7(x)\n        x=self.C8(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x=self.C9(x)\n        x=self.C10(x)\n        x=self.C11(x)\n        x=self.C12(x)\n        x=F.max_pool2d(F.relu(x),2)\n        \n        x = x.view(-1, self.num_flat_features(x))\n\n        x = F.relu(self.L1(x))\n        x = F.relu(self.L2(x))\n        \n        x=F.sigmoid(x)\n\n        return x\n\n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af42d9f7f62bfdd1bfee47528c17eb4ea37f5268"},"cell_type":"markdown","source":"**Loss function**"},{"metadata":{"trusted":true,"_uuid":"eacca1000e6a19c6e1858ddaee2ef236a4ab4432"},"cell_type":"code","source":"def FocalLoss(output, target):\n    gamma=2\n    if not (target.size() == output.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), output.size()))\n\n    max_val = (-output).clamp(min=0)\n    loss = output - output * target + max_val + ((-max_val).exp() + (-output - max_val).exp()).log()\n\n    invprobs = F.logsigmoid(-output * (target * 2.0 - 1.0))\n    loss = (invprobs * gamma).exp() * loss\n        \n    return loss.sum(dim=1).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"81f632abd2c330c5cac5d9745dc4a92fb48981a2"},"cell_type":"markdown","source":"**Trainnig**"},{"metadata":{"trusted":true,"_uuid":"425e5510a443cc36a0e4ff1d35acc6460efb2bf3"},"cell_type":"code","source":"\nif __name__ == \"__main__\":\n    train_labels = pd.read_csv(\"D:/Human Protein Atlas Image Classification/train.csv\")\n    \n    train_labels.head()\n    train_labels.shape[0]\n\n    label_names = {\n        0:  \"Nucleoplasm\",  \n        1:  \"Nuclear membrane\",   \n        2:  \"Nucleoli\",   \n        3:  \"Nucleoli fibrillar center\",   \n        4:  \"Nuclear speckles\",\n        5:  \"Nuclear bodies\",   \n        6:  \"Endoplasmic reticulum\",   \n        7:  \"Golgi apparatus\",   \n        8:  \"Peroxisomes\",   \n        9:  \"Endosomes\",   \n        10:  \"Lysosomes\",   \n        11:  \"Intermediate filaments\",   \n        12:  \"Actin filaments\",   \n        13:  \"Focal adhesion sites\",   \n        14:  \"Microtubules\",   \n        15:  \"Microtubule ends\",   \n        16:  \"Cytokinetic bridge\",   \n        17:  \"Mitotic spindle\",   \n        18:  \"Microtubule organizing center\",   \n        19:  \"Centrosome\",   \n        20:  \"Lipid droplets\",   \n        21:  \"Plasma membrane\",   \n        22:  \"Cell junctions\",   \n        23:  \"Mitochondria\",   \n        24:  \"Aggresome\",   \n        25:  \"Cytosol\",   \n        26:  \"Cytoplasmic bodies\",   \n        27:  \"Rods & rings\"\n    }\n\n    reverse_train_labels = dict((v,k) for k,v in label_names.items())\n\n    for key in label_names.keys():\n        train_labels[label_names[key]] = 0\n        \n    train_labels = train_labels.apply(fill_targets, axis=1)\n    train_labels.head()\n    del train_labels['Target']\n    \n#check sample is ok\n#000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0_blue\n\n    transformations = transforms.Compose([transforms.ToTensor()])\n    \n    model = Net()\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.99))\n\n    for k in train_labels.columns:\n        if k!='Id':\n            folds = StratifiedKFold(n_splits=10, shuffle=True)\n            for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_labels.values,train_labels[k].values)):\n                \n                temp=train_labels.iloc[val_idx].reset_index(drop=True)\n\n                dataset = ImageDataset(csv_file=temp,img_path=\"D:/Human Protein Atlas Image Classification/train/\",transform=transformations )\n                \n                dataloader = DataLoader(dataset, batch_size=64,shuffle=True)\n                for batch_idx, (data, target) in enumerate(dataloader):\n                    print('1')\n\n                    data, target = Variable(data), Variable(target)\n                    optimizer.zero_grad()\n                    output = model(data)\n                    loss = FocalLoss(output, target)\n                    loss.backward()\n                    optimizer.step()\n                    print('Train Epoch: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(batch_idx * len(data), len(dataloader.dataset),100. * batch_idx / len(dataloader), loss.data[0]))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f4908f898dd671f9f0be648dc10401018497ceb"},"cell_type":"markdown","source":"**Thank you for your reading**\n\nThe model above is very poor ,each batch trainning error is  ~10.05  :-) \n\nThere is a lot of work I can do and learn.  :-) "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}