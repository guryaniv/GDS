{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50119e34-c66f-b326-9c12-062f2614a2b6"
      },
      "source": [
        "**Loading the data.**\n",
        "\n",
        "A highly imbalanced dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd0d4ace-77b0-9f55-ac9a-39e5b397daa6"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dat = pd.read_csv('../input/creditcard.csv')\n",
        "\n",
        "print(dat.head())\n",
        "print('\\nThe distribution of the target variable\\n')\n",
        "dat['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b389e0aa-6250-f7d3-3ce4-fbec8ee363de"
      },
      "source": [
        "**Data exploration.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc209b47-55f4-df53-45d5-51d4a5688a37"
      },
      "outputs": [],
      "source": [
        "print(dat.describe())\n",
        "\n",
        "columns = dat.columns[1:30] \n",
        "fig, axes = plt.subplots(nrows=6, ncols=5,figsize=(10,10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(29):\n",
        "  axes[i].hist(dat[columns[i]], normed=1,facecolor='b',alpha=0.75)\n",
        "  axes[i].set_title(columns[i])\n",
        "  plt.setp(axes[i].get_xticklabels(), visible=False) \n",
        "  plt.setp(axes[i].get_yticklabels(), visible=False) \n",
        "\n",
        "plt.setp(axes[29].get_xticklabels(), visible=False) \n",
        "plt.setp(axes[29].get_yticklabels(), visible=False) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2ba53a16-3243-0620-0162-a46bea2e2126"
      },
      "source": [
        "**Data partitioning.**\n",
        "\n",
        "**No data pre-processing**. Partition dataset into 40% training, 30% validation, 30% testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "644d9904-cb9a-458b-f1e3-b1eed3155d55"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(1234)\n",
        "\n",
        "Class = dat['Class'].values\n",
        "dat2 = dat.drop(['Class'], axis=1)\n",
        "\n",
        "allIndices = np.arange(len(Class))\n",
        "\n",
        "numTrain = int(round(0.40*len(Class)))\n",
        "numValid = int(round(0.30*len(Class)))\n",
        "numTest = len(Class)-numTrain-numValid\n",
        "\n",
        "inTrain = sorted(np.random.choice(allIndices, size=numTrain, replace=False))\n",
        "inValidTest = list(set(allIndices)-set(inTrain))\n",
        "inValid= sorted(np.random.choice(inValidTest, size=numValid, replace=False))\n",
        "inTest = list(set(inValidTest)-set(inValid))\n",
        "\n",
        "train = dat2.iloc[inTrain,:]\n",
        "valid= dat2.iloc[inValid,:]\n",
        "test =  dat2.iloc[inTest,:]\n",
        "\n",
        "trainY = Class[inTrain]\n",
        "validY = Class[inValid]\n",
        "testY = Class[inTest]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5da99804-71b5-9f03-b6b7-149202ee159f"
      },
      "source": [
        "**Preparing the Booster.**\n",
        "\n",
        "Set scale_pos_weight equal to the negatives/positives ratio.  \n",
        "Define a function to do the training and report performance on the validation dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7794622-01d0-4e92-8dbb-8c90b6eb60e2"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "dtrain = xgb.DMatrix(train, label=trainY)\n",
        "dvalid = xgb.DMatrix(valid, label=validY)\n",
        "dtest = xgb.DMatrix(test, label=testY)\n",
        "\n",
        "## fixed parameters\n",
        "scale_pos_weight = sum(trainY==0)/sum(trainY==1)  \n",
        "num_rounds=10 # number of boosting iterations\n",
        "\n",
        "param = {'silent':1,\n",
        "         'min_child_weight':1, ## unbalanced dataset\n",
        "         'objective':'binary:logistic',\n",
        "         'eval_metric':'auc', \n",
        "         'scale_pos_weight':scale_pos_weight}\n",
        "\n",
        "def do_train(param, train,train_s,trainY,valid,valid_s,validY):\n",
        "    ## train with given fixed and variable parameters\n",
        "    ## and report performance on validation dataset\n",
        "    evallist  = [(train,train_s), (valid,valid_s)]\n",
        "    model = xgb.train( param, train, num_boost_round=num_rounds, \n",
        "                      evals=evallist )    \n",
        "    preds = model.predict(valid)\n",
        "    labels = valid.get_label()\n",
        "      \n",
        "    act_pos=sum(validY==1)\n",
        "    act_neg=valid.num_row()-act_pos\n",
        "    true_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==1))\n",
        "    false_pos=sum(1 for i in range(len(preds)) if (preds[i]>=0.5) & (labels[i]==0))\n",
        "    false_neg=act_pos-true_pos\n",
        "    true_neg=act_neg-false_pos\n",
        "    \n",
        "    ## precision: tp/(tp+fp) percentage of correctly classified predicted positives\n",
        "    ## recall: tp/(tp+fn) percentage of positives correctly classified\n",
        "    ## F-score with beta=1\n",
        "    ## see Sokolova et al., 2006 \"Beyond Accuracy, F-score and ROC:\n",
        "    ## a Family of Discriminant Measures for Performance Evaluation\"\n",
        "    ## fscore <- 2*precision.neg*recall.neg/(precision.neg+recall.neg)\n",
        "    \n",
        "    precision = true_pos/(true_pos+false_pos)\n",
        "    recall = true_pos/(true_pos+false_neg)\n",
        "    f_score = 2*precision*recall/(precision+recall)  \n",
        "    \n",
        "    print('\\nconfusion matrix')\n",
        "    print('----------------')\n",
        "    print( 'tn:{:6d} fp:{:6d}'.format(true_neg,false_pos))\n",
        "    print( 'fn:{:6d} tp:{:6d}'.format(false_neg,true_pos))\n",
        "    return(f_score)    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "340d6cc7-8c8a-1b84-e509-84a27780d4c9"
      },
      "source": [
        "**Parameters to be tuned and random search on the validation dataset.**\n",
        "\n",
        "Set suitable ranges for 3 parameters and produce 10 random combinations. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca134f79-6778-6ad7-5b4d-07f55ffa9ed3"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "## parameters to be tuned\n",
        "tune_dic = OrderedDict()\n",
        "\n",
        "tune_dic['max_depth']= np.array([20,25,30]) ## maximum tree depth\n",
        "tune_dic['colsample_bytree']= np.linspace(0.5,1.0,6) ## subsample ratio of columns\n",
        "tune_dic['eta']= np.linspace(0.3,0.6,4) ## learning rate\n",
        "\n",
        "best_params = dict()\n",
        "best_f_score = -1\n",
        "\n",
        "import itertools\n",
        "var_params = [ i for i in itertools.product(*tune_dic.values())]\n",
        "search=np.random.choice(np.arange(len(var_params)),10,replace=False)\n",
        "\n",
        "columns=[*tune_dic.keys()]+['F Score']\n",
        "\n",
        "results = pd.DataFrame(index=range(len(search)), columns=columns) ## to check results\n",
        "\n",
        "for i in range(len(search)): ## len(search)\n",
        "    \n",
        "    for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
        "        param[key]=val\n",
        "\n",
        "    print()    \n",
        "    f_score = do_train(param, dtrain,'train',trainY,dvalid,'valid',validY)\n",
        "    \n",
        "    results.loc[i,[*tune_dic.keys()]]=var_params[search[i]]\n",
        "    results.loc[i,'F Score']=f_score\n",
        "    \n",
        "    if f_score > best_f_score:\n",
        "        best_f_score = f_score\n",
        "        print('\\n*** better f-score',f_score)\n",
        "        for (key,val) in zip(tune_dic.keys(),var_params[search[i]]):\n",
        "            best_params[key]=val        \n",
        "            print(key,': ',val,' ',end='')\n",
        "        print()    \n",
        "       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8eac54f9-bbe7-f128-af81-581990fb5d2e"
      },
      "source": [
        "**Evaluation on the test dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a391478-2b82-cc41-cc45-9a7ba81101f9"
      },
      "outputs": [],
      "source": [
        "print('\\nevaluation on the test dataset\\n')  \n",
        "\n",
        "for (key,val) in best_params.items():\n",
        "    print(key,': ',val,' ',end='')\n",
        "    param[key]=val\n",
        "print('\\n\\n')\n",
        "    \n",
        "best_f_score = do_train(param, dtrain,'train',trainY,dtest,'test',testY)\n",
        "print('\\nf-score on the test dataset: {:6.2f}'.format(best_f_score))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}