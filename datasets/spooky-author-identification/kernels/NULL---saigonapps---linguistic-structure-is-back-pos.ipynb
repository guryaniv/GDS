{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "39751e9921e7f4b68cf7a85fab16864417f223ff", "_cell_guid": "8e229ed0-0ee1-46a7-b3aa-acc8fc002750"}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn import metrics\n", "import lightgbm as lgb\n", "from time import time\n", "import spacy\n", "nlp = spacy.load('en')\n", "\n", "## ~~ Happy modeling ~~ ##\n", "t0 = time()\n", "print(\"[*] Loading dataframes\")\n", "train = pd.read_csv(\"../input/train.csv\", encoding='utf-8')\n", "test = pd.read_csv(\"../input/test.csv\", encoding='utf-8')\n", "\n", "# test the extract function\n", "def extract_pos(txt):\n", "    return \" \".join([i.pos_ for i in nlp(txt)])\n", "\n", "def run_gdbt(x1,y1,x2,y2,x_test,n_iter=5000,seed=42,max_depth=10,lr=0.02):\n", "    params = {\n", "        'boosting_type': 'gbdt',\n", "        'max_depth': max_depth,\n", "        'learning_rate': lr,\n", "        'num_leaves': 20,\n", "        'verbose': 0, \n", "        'metric': 'multi_logloss',\n", "        'objective': 'multiclass',\n", "        'num_classes': 3,\n", "        'num_threads': 6,\n", "        'bagging_fraction_seed': seed,\n", "        'feature_fraction_seed': seed,\n", "    }\n", "    n_estimators = n_iter\n", "    d_train = lgb.Dataset(x1, label=y1)\n", "    d_valid = lgb.Dataset(x2, label=y2)\n", "    model = lgb.train(params, d_train, n_estimators, [d_train, d_valid], verbose_eval=200,early_stopping_rounds=120)\n", "\n", "    y2_hat = model.predict(x2)\n", "    y_hat = model.predict(x_test)\n", "    return y2_hat, y_hat, model\n", "\n", "print(\"Hello world! -> (POS)\", extract_pos(u\"hello world!\"))\n", "print(\"[*] Extract POS features\")\n", "train['pos'] = train.text.apply(extract_pos)\n", "test['pos'] = test.text.apply(extract_pos)\n", "\n", "le = LabelEncoder()\n", "y_train = le.fit_transform(train.author.values)\n", "\n", "\n", "\n", "counter = CountVectorizer(stop_words=None, ngram_range=(1,3), input='content',\\\n", "                          encoding='utf-8', decode_error='replace', strip_accents='unicode',\\\n", "                          lowercase=True, analyzer='word')\n", "\n", "counter.fit(train['pos'].values.tolist() + test['pos'].values.tolist())\n", "train_bow = counter.transform(train['pos'].values.tolist())\n", "test_bow = counter.transform(test['pos'].values.tolist())\n", "\n", "train_bow = train_bow.toarray()\n", "test_bow = test_bow.toarray()\n", "\n", "print(\"[*] Train shape\", train_bow.shape, y_train.shape)\n", "print(\"[*] Test shape\", test_bow.shape)\n", "\n", "## main code ##\n", "n_folds = 5\n", "n_classes = 3\n", "cv_scores = []\n", "y_test_cv = 0\n", "y_train_cv = np.zeros([train.shape[0], n_classes])\n", "kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=2017)\n", "for train_index, val_index in kf.split(train.id,y_train):\n", "    x1, x2 = train_bow[train_index], train_bow[val_index]\n", "    y1, y2 = y_train[train_index], y_train[val_index]\n", "    \n", "    y2_hat, y_test_hat, model = run_gdbt(x1, y1, x2, y2, test_bow,n_iter=1000,max_depth=10)\n", "    y_test_cv = y_test_cv + y_test_hat\n", "    y_train_cv[val_index,:] = y2_hat\n", "    cv_scores.append(metrics.log_loss(y2, y2_hat))\n", "\n", "modeling_time = time() - t0\n", "print(\"Mean cv score : \", np.mean(cv_scores),np.std(cv_scores))\n", "print(\"Modeling time: %0.3fs\" % modeling_time)\n", "print(\"[*] Extract submission dataframe\")\n", "y_test_cv = y_test_cv / n_folds\n", "sub = pd.DataFrame({'id': test.id,\\\n", "                    '{}'.format(le.inverse_transform([0])[0]): y_test_cv[:,0], \\\n", "                    '{}'.format(le.inverse_transform([1])[0]): y_test_cv[:,1], \\\n", "                    '{}'.format(le.inverse_transform([2])[0]): y_test_cv[:,2]})\n", "print(\"DONE!\")\n", "## Voila!, you will see POS would help. Linguistic structure is back.(in ~ 3 minutes)\n", "## Mean cv score :  0.80320359782 0.00983586058765\n", "## Modeling time: 177.148s"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": []}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}