{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Importing libraries\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom scipy.io import wavfile\nimport numpy as np\nimport pandas as pd\nfrom scipy import signal\nfrom tqdm import tqdm \nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Step 1 Preprocessing\n# Converting wav to dataframes using log_spectogram\n\ndef get_data(path):\n    datadir = Path(path)\n    files = [(str(f), f.parts[-2]) for f in datadir.glob('**/*.wav') if f]\n    dataset = pd.DataFrame(files, columns=['path', 'label'])\n    return dataset\n\n# Preparing the dataset as described in the dataset\ndef prepare_data(dataset):\n    train_words = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go', 'silence']\n    words = dataset.label.unique().tolist()\n    silence = ['_background_noise_']\n    unknown = [w for w in words if w not in silence + train_words]\n\n    # there are only 6 silence files. Mark them as unknown \n    dataset.loc[dataset.label.isin(silence), 'label'] = 'unknown'\n    dataset.loc[dataset.label.isin(unknown), 'label'] = 'unknown'\n    return dataset\n\ntrain = prepare_data(get_data(\"../input/train/audio/\"))","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc1e9dd84e7cda0ee5cf7eb00fbc99fd25b00f93"},"cell_type":"code","source":"# Spectogram function \ndef log_spectogram(audio, sample_rate, window_size=10,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    _, _, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return np.log(spec.T.astype(np.float32) + eps)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"face52706030f03e6cbe2f56d7734bb90a459bae"},"cell_type":"code","source":"# Getting all the paths to the files\npaths = []\nfiles = train['path']\nfor i in range(len(files)):\n    path = str(files[i])\n    paths.append(path)\n    \ndef audio_to_data(path):\n    # we take a single path and convert it into data\n    sample_rate, audio = wavfile.read(path)\n    spectrogram = log_spectogram(audio, sample_rate, 10, 0)\n    return spectrogram.T\n\ndef data_generator(paths,labels):\n    data = np.zeros(shape = (len(paths), 81, 100))\n    indexes = []\n    for i in tqdm(range(len(paths))):\n        audio = audio_to_data(paths[i])\n        if audio.shape != (81,100):\n            indexes.append(i)\n        else:\n            data[i] = audio\n    final_labels = [l for i,l in enumerate(labels) if i not in indexes]\n    print('Number of instances with inconsistent shape:', len(indexes))\n    return data[:len(data)-len(indexes)], final_labels, indexes","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2202477aa6527061b66ea200c71133deaa16ef01"},"cell_type":"code","source":"# Converting labels to Bitmap using LabelBinarizer\nfrom sklearn.preprocessing import LabelBinarizer\nlabelbinarizer = LabelBinarizer()\ny = labelbinarizer.fit_transform(train.label)\n\n# Obtaining data\ndata,l,indexes = data_generator(paths,y)\n\nlabels = np.zeros(shape = [data.shape[0], 81, len(l[0])])\n\ninput_length = np.zeros([32, 1])\nlabel_length = np.zeros([32, 1])\n\nfor i,array in enumerate(l):\n    for j, element in enumerate(array):\n        labels[i][j] = element\n        \nprint(data.shape)\nprint(labels.shape)\n\ndata,labels = shuffle(data,labels)\n\nprint(data[0].shape)\nprint(labels[0].shape)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"02214b5c6e7f1048b9fcab619160ad9499423092"},"cell_type":"code","source":"# Splitting the converted dataset into training and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"602d8c852be4e330f37fe0b6d74aa88c752a7786"},"cell_type":"code","source":"# Part 2 - Building the model\n\n#Importing the Keras libraries and packages\nfrom keras.layers import Dropout, Dense\nfrom keras.layers import Bidirectional, SimpleRNN, Lambda, Input, TimeDistributed\nfrom keras.models import Sequential,Model\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.activations import relu\n\n# Clipped ReLu function as described in paper\ndef clipped_relu(x):\n    return relu(x, max_value=20)\n\nfrom keras.utils.generic_utils import get_custom_objects\nget_custom_objects().update({\"clipped_relu\": clipped_relu})\nK.set_learning_phase(1)  ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db791b290d9afe5df0342ce0b043b4c9d09aac7b"},"cell_type":"code","source":"model = Sequential()\n\n# Layer 1 with clipped ReLu activation function\nmodel.add(Dense(512, activation = clipped_relu, input_shape=(81,100)))\nmodel.add(Dropout(rate = 0.1))\n\n# Layer 2 with clipped ReLu activation function\nmodel.add(Dense(256, activation = clipped_relu))\nmodel.add(Dropout(rate = 0.1))\n\n# Layer 3 with clipped ReLu activation function\nmodel.add(Dense(256, activation = clipped_relu))\nmodel.add(Dropout(rate = 0.1))\n\n# Layer 4 Bidirectional Recurrent layer with clipped ReLu activtion function\nmodel.add(Bidirectional(SimpleRNN(512, activation = clipped_relu, return_sequences = True)))\nmodel.add(Dropout(rate = 0.1))\n\n# Layer 5 with softmax activaiton function\nmodel.add(Dense(units = 11, activation = \"softmax\"))\n\n# Compiling the model\nmodel.compile(optimizer = 'adam', loss = \"binary_crossentropy\")\nmodel.summary()\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18105235dbcec3694bada8b814167032dbe4e783"},"cell_type":"code","source":"# Fitting the model\nmodel.fit(X_train, y_train, batch_size=32, epochs=1, validation_data=(X_test,y_test))","execution_count":9,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}