{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4214f3ed-3856-e7e9-a514-7f45e1e83925"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d935d88-afa7-5596-84bb-1081da5eeabd"
      },
      "outputs": [],
      "source": [
        "import os, cv2, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "TRAIN_DIR = '../input/train/'\n",
        "TEST_DIR = '../input/test_stg1/'\n",
        "FISH_CLASSES = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
        "ROWS = 90  #720\n",
        "COLS = 160 #1280\n",
        "CHANNELS = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "853f1e57-ae8c-4eb0-d747-c8f13c84a9ff"
      },
      "outputs": [],
      "source": [
        "def get_images(fish):\n",
        "    \"\"\"Load files from train folder\"\"\"\n",
        "    fish_dir = TRAIN_DIR+'{}'.format(fish)\n",
        "    images = [fish+'/'+im for im in os.listdir(fish_dir)]\n",
        "    return images\n",
        "\n",
        "def read_image(src):\n",
        "    \"\"\"Read and resize individual images\"\"\"\n",
        "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
        "    im = cv2.resize(im, (COLS, ROWS), interpolation=cv2.INTER_CUBIC)\n",
        "    return im\n",
        "\n",
        "\n",
        "files = []\n",
        "y_all = []\n",
        "\n",
        "for fish in FISH_CLASSES:\n",
        "    fish_files = get_images(fish)\n",
        "    files.extend(fish_files)\n",
        "    \n",
        "    y_fish = np.tile(fish, len(fish_files))\n",
        "    y_all.extend(y_fish)\n",
        "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
        "    \n",
        "y_all = np.array(y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a19d949-e117-5ff8-8235-40da6cdfacae"
      },
      "outputs": [],
      "source": [
        "X_all = np.ndarray((len(files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "for i, im in enumerate(files): \n",
        "    X_all[i] = read_image(TRAIN_DIR+im)\n",
        "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
        "\n",
        "print(X_all.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "712147e7-5598-20f3-756a-cf48ee2f6057"
      },
      "outputs": [],
      "source": [
        "## Uncomment to check out a fish from each class\n",
        "uniq = np.unique(y_all, return_index=True)\n",
        "print(uniq)\n",
        "for f, i in zip(uniq[0], uniq[1]):\n",
        "    plt.imshow(X_all[i])\n",
        "    plt.title(f)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd595371-ec86-9262-79dc-b37678f50a44"
      },
      "outputs": [],
      "source": [
        "# One Hot Encoding Labels\n",
        "y_all = LabelEncoder().fit_transform(y_all)\n",
        "y_all = np_utils.to_categorical(y_all)\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
        "                                                    test_size=0.2, random_state=23, \n",
        "                                                    stratify=y_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4d408f9-5575-f0f5-0176-204fa58c8508"
      },
      "outputs": [],
      "source": [
        "optimizer = RMSprop(lr=1e-4)\n",
        "objective = 'categorical_crossentropy'\n",
        "\n",
        "def center_normalize(x):\n",
        "    return (x - K.mean(x)) / K.std(x)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Activation(activation=center_normalize, input_shape=(ROWS, COLS, CHANNELS)))\n",
        "\n",
        "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(Convolution2D(32, 5, 5, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu', dim_ordering='tf'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering='tf'))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(len(FISH_CLASSES)))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss=objective, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9944b61e-2393-b72f-c392-628bc8e4a290"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
        "        \n",
        "model.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n",
        "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9393cff6-24b1-c4c9-a457-d5908f6c1557"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_valid, verbose=1)\n",
        "print(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b37e92f9-61e9-cc81-a9d3-034458fd804c"
      },
      "outputs": [],
      "source": [
        "test_files = [im for im in os.listdir(TEST_DIR)]\n",
        "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
        "\n",
        "for i, im in enumerate(test_files): \n",
        "    test[i] = read_image(TEST_DIR+im)\n",
        "    \n",
        "test_preds = model.predict(test, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24596950-c5d1-6712-060d-78042bae243e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
        "submission.insert(0, 'image', test_files)\n",
        "submission.head()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}