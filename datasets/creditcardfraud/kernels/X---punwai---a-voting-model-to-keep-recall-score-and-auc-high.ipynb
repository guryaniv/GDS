{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "version": "3.6.3", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "cells": [{"metadata": {"_uuid": "92649072ffda163f4c7be9db4bb6e195cf51e042", "_cell_guid": "0d71bf51-41e3-4cb0-921e-f25dcff32ddc", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# 1. Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n", "# 2. The blog \"In depth skewed data classif. (93% recall acc now)\", joparga3In, https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now\n", "# 3. Credit-Card-Fraud-Detection, AJ Tong, https://github.com/AJ2802/Credit-Card-Fraud-Detection\n", "\n", "# My model is inspired from [2]\n", "# ReadMe.txt in [3] has detailed explanation and performance of my model.\n", "\n", "import pandas as  pd\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.cross_validation import KFold, cross_val_score\n", "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n", "import itertools\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.svm import SVC\n", "from scipy import stats\n", "from sklearn.neighbors import KNeighborsClassifier\n", "\n", "show_bdry = False\n", "show_best_c = False\n", "# Either all features in the feature sets are normalized or only the amount value is normalized\n", "def normalize_feature(data, amount_only = False):\n", "    if amount_only:\n", "        data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n", "    else:\n", "        for feature in data.columns[:-1]:\n", "            data[feature] = StandardScaler().fit_transform(data[feature].values.reshape(-1,1))\n", "    return data\n", "\n", "#Data are splitted to train and test sets: in each set\n", "#Let total_normal and total_fraud be the total numbers of normal and fraud activities in the data sets.\n", "#The train set contains (1-test_size)*total_normal normal activities and  (1-test_size)*total_fraud fraud activities.\n", "#The test set contains test_size*total_normal normal activities and  test_size*total_fraud fraud activities.\n", "def split_train_test(fraud_indices, normal_indices, test_size = 0.3):\n", "    number_records_fraud = len(fraud_indices)\n", "    number_records_normal = len(normal_indices)\n", "    test_fraud_end = int(number_records_fraud * test_size)\n", "    test_normal_end = int(number_records_normal  * test_size)\n", "\n", "    test_fraud_indices = fraud_indices[0:test_fraud_end]\n", "    train_fraud_indices = fraud_indices[test_fraud_end:]\n", "\n", "    test_normal_indices = normal_indices[0:test_normal_end]\n", "    train_normal_indices = normal_indices[test_normal_end:]\n", "\n", "    return train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices\n", "\n", "#Train set is downsampled so that in the train set the number of normal activities = ratio*the number of normal activities\n", "def getTrainingSample(train_fraud_indices, train_normal_indices, data, train_normal_pos, ratio):\n", "    train_number_records_fraud = int(ratio*len(train_fraud_indices))\n", "    train_number_records_normal = len(train_normal_indices)\n", "    if train_normal_pos + train_number_records_fraud <= train_number_records_normal:\n", "        small_train_normal_indices = train_normal_indices[train_normal_pos: train_normal_pos + train_number_records_fraud]\n", "        train_normal_pos = train_normal_pos + train_number_records_fraud\n", "    else:\n", "        small_train_normal_indices = np.concatenate([train_normal_indices[train_normal_pos: train_number_records_normal],train_normal_indices[0: train_normal_pos + train_number_records_fraud- train_number_records_normal]])\n", "        train_normal_pos = train_normal_pos + train_number_records_fraud - train_number_records_normal\n", "\n", "    # Appending the 2 fraud_indices\n", "    under_train_sample_indices = np.concatenate([train_fraud_indices, small_train_normal_indices])\n", "    np.random.shuffle(under_train_sample_indices)\n", "    # Under sample dataset\n", "    under_train_sample_data = data.iloc[under_train_sample_indices,:]\n", "\n", "    X_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns != 'Class']\n", "    y_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns == 'Class']\n", "\n", "    return X_train_undersample, y_train_undersample, train_normal_pos\n", "\n", "# It is a module of k-nearest nbd. which is called in cross-validation.\n", "def knn_module(X, y, indices, c_param, bdry = None):\n", "    knn = KNeighborsClassifier(n_neighbors = c_param)\n", "    knn.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n", "    y_pred_undersample = knn.predict(X.iloc[indices[1],:].values)\n", "    return y_pred_undersample\n", "\n", "# It is a module of support vector machine using Gaussian radix basis function kernel which is called in cross-validation.\n", "def svm_rbf_module(X, y, indices, c_param, bdry = 0.5):\n", "    svm_rbf = SVC(C=c_param, probability = True)\n", "    svm_rbf.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n", "    y_pred_undersample = svm_rbf.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n", "    return y_pred_undersample\n", "\n", "# It is a module of support vector machine using polynomial kernel which is called in cross-validation.\n", "def svm_poly_module(X, y, indices, c_param, bdry = 0.5):\n", "    svm_poly = SVC(C= c_param[0], kernel = 'poly', degree = c_param[1], probability = True)\n", "    svm_poly.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n", "    y_pred_undersample = svm_poly.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n", "    return y_pred_undersample\n", "\n", "# It is a module of logistic regression which is called in cross-validation.\n", "def lr_module(X, y, indices, c_param, bdry = 0.5):\n", "    lr = LogisticRegression(C = c_param, penalty = 'l1')\n", "    lr.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n", "    y_pred_undersample= lr.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n", "    return y_pred_undersample\n", "\n", "# It is a module of random forest which is called in cross-validation\n", "def rf_module(X, y, indices, c_param, bdry = 0.5):\n", "    rf = RandomForestClassifier(n_jobs=-1, n_estimators = 100, criterion = 'entropy', max_features = 'auto', max_depth = None, min_samples_split  = c_param, random_state=0)\n", "    rf.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n", "    y_pred_undersample = rf.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n", "    return y_pred_undersample\n", "\n", "# This is a method to compute recall score and auc.\n", "# y_t stands for actual label while y_p stands for predicted labels.\n", "def compute_recall_and_auc(y_t, y_p):\n", "    # Compute confusion cnf_matrix\n", "    cnf_matrix = confusion_matrix(y_t,y_p)\n", "    np.set_printoptions(precision = 2)\n", "    recall_score = cnf_matrix[1,1]/(cnf_matrix[1,0] + cnf_matrix[1,1])\n", "\n", "    # ROC CURVE\n", "    y_p = [int(value) for value in y_p]\n", "    fpr, tpr, thresholds = roc_curve(y_t, y_p)\n", "    roc_auc = auc(fpr, tpr)\n", "    return recall_score, roc_auc\n", "\n", "# This is cross_validation method to tune some hyperparameters in a learning models\n", "# such that recall scores in the learning model is optimized.\n", "# The parameter models_dict contains a module of each learning model.\n", "def cross_validation_recall(x_train_data,y_train_data, c_param_range, models_dict, model_name):\n", "    fold = KFold(len(y_train_data),5,shuffle=False)\n", "\n", "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n", "    results_table['C_parameter'] = c_param_range\n", "\n", "    recall_mean = []\n", "    for c_param in c_param_range:\n", "        recall_accs = []\n", "        for iteration, indices in enumerate(fold, start = 1):\n", "\n", "            y_pred_undersample = models_dict[model_name](x_train_data, y_train_data, indices, c_param)\n", "\n", "            recall_acc, _ = compute_recall_and_auc(y_train_data.iloc[indices[1],:].values, y_pred_undersample)\n", "            recall_accs.append(recall_acc)\n", "\n", "        recall_mean.append(np.mean(recall_accs))\n", "\n", "    results_table['Mean recall score'] = recall_mean\n", "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n", "\n", "    return best_c\n", "\n", "# This is cross_validation method to tune the decision boundary threshold in a learning models\n", "# such that a function of auc and recall score is maximized.\n", "# The parameter bdry_dict contains a function of auc and recall score in each learning model.\n", "def decision_boundary(x_train_data,y_train_data, fold,  best_c, bdry_dict, models_dict, model_name):\n", "    bdry_ranges = [0.3, 0.35, 0.4, 0.45, 0.5]\n", "    results_table = pd.DataFrame(index = range(len(bdry_ranges),2), columns = ['C_parameter','Mean recall score * auc'])\n", "    results_table['Bdry_params'] = bdry_ranges\n", "\n", "    recall_mean = []\n", "    for bdry in bdry_ranges:\n", "        recall_accs_aucs = []\n", "        for iteration, indices in enumerate(fold, start = 1):\n", "            y_pred_undersample = models_dict[model_name](x_train_data, y_train_data, indices, best_c, bdry)\n", "            recall_acc, roc_auc = compute_recall_and_auc(y_train_data.iloc[indices[1],:].values, y_pred_undersample)\n", "            recall_accs_aucs.append(bdry_dict[model_name](recall_acc, roc_auc))\n", "        recall_mean.append(np.mean(recall_accs_aucs))\n", "\n", "    results_table['Mean recall score * auc'] = recall_mean\n", "    best_bdry = results_table.loc[results_table['Mean recall score * auc'].idxmax()]['Bdry_params']\n", "\n", "    return best_bdry\n", "\n", "# Model method is our model to classify the fraud and normal activities.\n", "def model(X, y, train, bdry_dict = None, best_c = None, best_bdry = None, models = None, mode = None):\n", "    # This is the training part of our model\n", "    if train:\n", "        # Using cross-validaton, some hyperparameters in the following learning models are determined\n", "        # by optimizing the recall score in the model.\n", "        models_dict = {'knn' : knn_module, 'svm_rbf': svm_rbf_module, 'svm_poly': svm_poly_module,\n", "                        'lr': lr_module, 'rf': rf_module}\n", "\n", "        # The number of k in the k-nearest nbd. model is determined\n", "        c_param_range_knn = [3,5,7,9]\n", "        best_c_knn = cross_validation_recall(X, y, c_param_range_knn, models_dict, 'knn')\n", "\n", "        # The penalty parameter in the support vector machine using Gaussian radix basis function kernel is determined.\n", "        c_param_range_svm_rbf = [0.01, 0.1, 1, 10, 100]\n", "        best_c_svm_rbf = cross_validation_recall(X, y, c_param_range_svm_rbf, models_dict, 'svm_rbf')\n", "        c_param_range_svm_poly = [[0.01, 2], [0.01, 3], [0.01, 4], [0.01, 5], [0.01, 6], [0.01, 7], [0.01, 8], [0.01, 9],\n", "                                  [0.1, 2], [0.1, 3], [0.1, 4], [0.1, 5], [0.1, 6], [0.1, 7], [0.1, 8], [0.1, 9],\n", "                                  [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9],\n", "                                  [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9],\n", "                                  [100, 2], [100, 3], [100, 4], [100, 5], [100, 6], [100, 7], [100, 8], [100, 9]]\n", "\n", "        # The penalty parameter and the degree of the polynomial kernel in the support vector machine\n", "        # are determined.\n", "        best_c_svm_poly = cross_validation_recall(X, y, c_param_range_svm_poly, models_dict, 'svm_poly')\n", "\n", "        # The penalty parameter in the logistic regression model is determined.\n", "        c_param_range_lr = [0.01,0.1,1,10,100]\n", "        best_c_lr = cross_validation_recall(X, y, c_param_range_lr, models_dict, 'lr')\n", "        # The min_samples_split in the random forest model is determined\n", "        c_param_range_rf = [2, 5, 10, 15, 20]\n", "        best_c_rf = cross_validation_recall(X, y, c_param_range_rf, models_dict, 'rf')\n", "        best_c = [best_c_knn, best_c_svm_rbf, best_c_svm_poly, best_c_lr, best_c_rf, best_c]\n", "\n", "        # Using cross-validaton, decision boundary thresholds in the following learning models are determined\n", "        # by optimizing some function of auc and recall score in the model.\n", "        # The function of auc and recall score in each model is stored in the bdry_dict.\n", "        fold = KFold(len(y), 4 ,shuffle=True) # Re-shuffle in the cross-validation are required. Otherise,\n", "                                              # the training in both the previous cross-validation and the current cross\n", "                                              # validation learn the noise in the train set and the quality of decision\n", "                                              # boundary values is damaged.\n", "        # The decision boundary threshold of the support vector machine using Gaussian radix basis function kernel is\n", "        # determined.\n", "        best_bdry_svm_rbf= decision_boundary(X, y, fold, best_c_svm_rbf, bdry_dict, models_dict, 'svm_rbf')\n", "\n", "        # The decision boundary threshold of the support vector machine using polynomial kernel is determined.\n", "        best_bdry_svm_poly = decision_boundary(X, y, fold, best_c_svm_poly, bdry_dict, models_dict, 'svm_poly')\n", "\n", "        # The decision boundary threshold of the logistic regression model is determined.\n", "        best_bdry_lr = decision_boundary(X, y, fold, best_c_lr, bdry_dict, models_dict, 'lr')\n", "\n", "        # The decision boundary threshold of the random forest model is determined.\n", "        best_bdry_rf = decision_boundary(X, y, fold, best_c_lr, bdry_dict, models_dict, 'rf')\n", "        best_bdry = [0.5, best_bdry_svm_rbf, best_bdry_svm_poly, best_bdry_lr, best_bdry_rf]\n", "\n", "        # Each model are trained by using the hyperparamters found in the cross-validation\n", "        knn = KNeighborsClassifier(n_neighbors = int(best_c_knn))\n", "        knn.fit(X.values, y.values.ravel())\n", "\n", "        svm_rbf = SVC(C=best_c_svm_rbf, probability = True)\n", "        svm_rbf.fit(X.values, y.values.ravel())\n", "\n", "        svm_poly = SVC(C=best_c_svm_poly[0], kernel = 'poly', degree = best_c_svm_poly[1], probability = True)\n", "        svm_poly.fit(X.values, y.values.ravel())\n", "\n", "        lr = LogisticRegression(C = best_c_lr, penalty ='l1', warm_start = False)\n", "        lr.fit(X.values, y.values.ravel())\n", "\n", "        rf = RandomForestClassifier(n_jobs=-1, n_estimators = 100, criterion = 'entropy', max_features = 'auto', max_depth = None, min_samples_split  = int(best_c_rf), random_state=0)\n", "        rf.fit(X.values, y.values.ravel())\n", "\n", "        models = [knn, svm_rbf, svm_poly, lr, rf]\n", "\n", "        return best_c, best_bdry, models\n", "    else:\n", "        # This part is to classify fraud and normal activities in a test set by our model.\n", "        [knn, svm_rbf, svm_poly, lr, rf] = models\n", "        [_, best_bdry_svm_rbf, best_bdry_svm_poly, best_bdry_lr, best_bdry_rf] = best_bdry\n", "\n", "        # Class of activities are predicted by the k nearest nbd. model.\n", "        y_pred_knn = knn.predict(X.values)\n", "        # Class of activities are predicted by the support vector machine using Gaussian radix basis function kenerl\n", "        # according to the decision boundary threshold.\n", "        y_pred_svm_rbf = svm_rbf.predict_proba(X.values)[:,1] >= best_bdry_svm_rbf\n", "        # Class of activities are predicted by the support vector machine using polynomial kenerl\n", "        # according to the decision boundary threshold.\n", "        y_pred_svm_poly = svm_poly.predict_proba(X.values)[:,1] >= best_bdry_svm_poly\n", "        # Class of activities are predicted by the logistic regression according to the decision boundary threshold.\n", "        y_pred_lr= lr.predict_proba(X.values)[:,1] >= best_bdry_lr\n", "        # Class of activities are predicted by the random forest according to the decision boundary threshold.\n", "        y_pred_rf = rf.predict_proba(X.values)[:,1] >= best_bdry_rf\n", "\n", "        x_of_three_models = {'knn' : y_pred_knn, 'svm_rbf' : y_pred_svm_rbf, 'svm_poly' : y_pred_svm_poly, 'lr' : y_pred_lr, 'rf': y_pred_rf}\n", "        X_5_data = pd.DataFrame(data = x_of_three_models)\n", "\n", "        y_pred= np.sum(X_5_data, axis = 1)>=mode\n", "\n", "        y_pred_lr_controls = []\n", "        params = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n", "\n", "        # Final class in each test case is determined by a voting system among all these five learning models.\n", "        for param in params:\n", "            y_pred_lr_controls.append(lr.predict_proba(X.values)[:,1] >= param)\n", "        return y_pred, y_pred_lr_controls, params\n", "\n", "\n", "\n", "def run(data, mode, ratio, iteration1, bdry_dict):\n", "    recall_score_list =[]\n", "    auc_list = []\n", "    recall_score_lr_list =[]\n", "    auc_lr_list = []\n", "    best_c = None\n", "    best_bdry = None\n", "    for itr1 in range(iteration1):\n", "        print(\"percentage: %.2f\" %(itr1/iteration1*100))\n", "\n", "        # Number of data points in the minority class\n", "        fraud_indices = np.array(data[data.Class == 1].index)\n", "        np.random.shuffle(fraud_indices)\n", "\n", "        #Picking the indices of the normal count_classes\n", "        normal_indices = np.array(data[data.Class == 0].index)\n", "        np.random.shuffle(normal_indices)\n", "\n", "        # train and test\n", "        train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices = split_train_test(\n", "                                                                                            fraud_indices, normal_indices)\n", "        test_indices = np.concatenate([test_normal_indices,test_fraud_indices])\n", "\n", "        test_data = data.iloc[test_indices,:]\n", "        X_test = test_data.ix[:, test_data.columns != 'Class']\n", "        y_test = test_data.ix[:, test_data.columns == 'Class'].values.ravel()\n", "\n", "        # Under sample dataset\n", "        X_train_undersample, y_train_undersample, train_normal_pos = getTrainingSample(\n", "                                                                    train_fraud_indices, train_normal_indices, data, 0, ratio)\n", "\n", "        # Train our model\n", "        best_c, best_bdry, models = model(X_train_undersample, y_train_undersample, train = True,\n", "                                          bdry_dict = bdry_dict, best_c = best_c, best_bdry = best_bdry)\n", "\n", "        if show_best_c:\n", "            print(\"Some hyperparamter values:\")\n", "            print(\"k-nearest nbd: %.2f, svm (rbf kernel): [%.2f, %.2f], svm (poly kernel): %.2f, logistic reg: %.2f, random forest: %.2f\"\n", "                  %(best_c[0], best_c[1], best_c[2][0], best_c[2][1], best_c[3], best_c[4]))\n", "\n", "        if show_bdry:\n", "            print(\"Decision Boundary thresholds:\")\n", "            print(\"k-nearest nbd: %.2f, svm (rbf kernel): %.2f, svm (poly kernel): %.2f, logistic reg: %.2f, random forest: %.2f\"\n", "                  %(best_bdry[0], best_bdry[1], best_bdry[2], best_bdry[3], best_bdry[4]))\n", "\n", "        # Classify class by our models\n", "        y_pred, y_pred_lr_controls, params = model(X_test, y_test, train = False, bdry_dict = None,\n", "                                                   best_c = best_c, best_bdry = best_bdry, models = models, mode = mode)\n", "\n", "        # Collect recall score and auc in our models and the models in a control set for performance comparison.\n", "        recall_score, roc_auc = compute_recall_and_auc(y_test, y_pred)\n", "        recall_score_list.append(recall_score)\n", "        auc_list.append(roc_auc)\n", "\n", "        control_recall_all_param = []\n", "        control_roc_all_param = []\n", "        for i in range(len(params)):\n", "            recall_score_lr, roc_auc_lr = compute_recall_and_auc(y_test, y_pred_lr_controls[i]) # for control\n", "            control_recall_all_param.append(recall_score_lr)\n", "            control_roc_all_param.append(roc_auc_lr)\n", "\n", "        recall_score_lr_list.append(control_recall_all_param)\n", "        auc_lr_list.append(control_roc_all_param)\n", "\n", "    # Compute the mean value of recall score and auc in our models and the models in a control set for performance comparison\n", "    mean_recall_score = np.mean(recall_score_list)\n", "    std_recall_score = np.std(recall_score_list)\n", "\n", "    mean_auc= np.mean(auc_list)\n", "    std_auc = np.std(auc_list)\n", "\n", "    mean_recall_score_lr = np.mean(recall_score_lr_list, axis = 0)\n", "    std_recall_score_lr = np.std(recall_score_lr_list, axis = 0)\n", "    mean_auc_lr= np.mean(auc_lr_list, axis = 0)\n", "    std_auc_lr = np.std(auc_lr_list, axis = 0)\n", "\n", "    result = [mean_recall_score, std_recall_score, mean_auc, std_auc]\n", "    control = [mean_recall_score_lr, std_recall_score_lr, mean_auc_lr, std_auc_lr]\n", "    return result, control, params\n", "\n", "\n", "#Some parameters setting:\n", "#################################################################################\n", "mode = 2\n", "ratio = 1\n", "iteration1 = 2 #should set at least 10, recommended value is 100 to get a more reliable result\n", "show_best_c = True\n", "show_bdry = True\n", "#function to optimize in the decision_boundary method\n", "def lr_bdry_module(recall_acc, roc_auc):\n", "    return 0.9*recall_acc+0.1*roc_auc\n", "def svm_rbf_bdry_module(recall_acc, roc_auc):\n", "    return recall_acc*roc_auc\n", "def svm_poly_bdry_module(recall_acc, roc_auc):\n", "    return recall_acc*roc_auc\n", "def rf_bdry_module(recall_acc, roc_auc):\n", "    return 0.5*recall_acc+0.5*roc_auc\n", "    \n", "bdry_dict = {'lr': lr_bdry_module,'svm_rbf': svm_rbf_bdry_module,\n", "             'svm_poly': svm_poly_bdry_module, 'rf': rf_bdry_module}\n", "################################################################################\n", "\n", "# Implementation of our model according to these parameters setting.:\n", "data = pd.read_csv(\"../input/creditcard.csv\")\n", "data = data.drop(['Time'], axis = 1)\n", "data = normalize_feature(data, amount_only = True)\n", "\n", "result, control, params = run(data = data, mode = mode, ratio = ratio, iteration1 = iteration1, bdry_dict = bdry_dict)\n", "print(\"Hyperparameter values:\")\n", "print(\"ratio: \", ratio, \" and mode: \", mode)\n", "print(\"Result of our model which a voting models among knn, svm_rbf, svm_poly, lr and rf:\")\n", "print(\"mean_recall is \", result[0], \" and std is \", result[1])\n", "print(\"mean_auc is \", result[2], \" and std is \", result[3])\n", "print()\n", "print(\"Control experiments of logistic regression models with different threshold\")\n", "print(\"i.e., fraud is predicted if the probability value exceeds the threshold\")\n", "for i, param in enumerate(params):\n", "    print(\"Threshold\", param)\n", "    print(\"mean_recall is \", control[0][i], \" and std is \", control[1][i])\n", "    print(\"mean_auc is \", control[2][i], \" and std is \", control[3][i])\n", "    print()\n"]}], "nbformat_minor": 1}