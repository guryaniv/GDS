{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"_cell_guid": "98170804-e981-4bc9-8e70-601b4433f992", "_uuid": "52547f8df5902f19f48289a572e291097481ccf7"}, "source": ["In this notebook, I'm just sharing my implementation for predicting whether a driver will file an insurance or not.\n", "* Here i'm using Random Forest model to predict the target variabe (Yes/No)."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "20b7d319-e726-437f-84d1-d6df45a4fcff", "_uuid": "ada74a87b078f69d3382f1d4454aaecd17812137"}, "source": ["**Objective**\n", "* Develop a machine learning model for predicting whether a driver will file an insurance next year or not. "], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "05d70aa9-df4b-4612-8e9b-951fd4cb6cc6", "_uuid": "595e6a59ba01a71e6a43dba0118f405d524fb4c2"}, "source": ["# Import all needed libraries for seeing the train and test files\n", "import numpy as np \n", "import pandas as pd\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "698f7cc3-4d60-4818-961b-813938b6614c", "_uuid": "41cf77fec8502e2977a1546ca22fdc42e510e30c"}, "source": ["# Let us load in the training data provided using Pandas:\n", "train = pd.read_csv(\"../input/train.csv\")\n", "print(train.shape)\n", "train.head()"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "e5f589ee-52eb-4d69-b6af-c00b52d62902", "_uuid": "cab80bbe274cb1e12de93ba0a1c261ad8e19bbfa"}, "source": ["* The training dataset contains 595212 rows and 59 columns.\n", "* **target** is the column which we are going to predict."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "faddef72-41cf-4d9e-8ac5-f29cf1de5395", "_uuid": "af39f6b5f49e4aec8cb3f901affa9ec1e0b42f19"}, "source": ["# Let us load the testing data.\n", "test = pd.read_csv(\"../input/test.csv\")\n", "print(test.shape)\n", "test.head()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "d4d2eed9-d2e3-4a0a-b20a-816ef0c00886", "_uuid": "3462efbfc5697ca7e5db8505d303b4ebed440894"}, "source": ["* The testing dataset contains 892816 rows and 58 columns. (Bigger than training dataset)\n", "* Other than **target** column in training set all columns will be present."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "9c7426d8-cfff-4473-a93a-4dffb7020cf2", "_uuid": "e9d96eda17ac2419daf1e2de01e7275f8e52ce13"}, "source": ["Let's see the column names and types"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "23b8ddd4-9ec1-4279-ad9e-59683e5586c8", "_uuid": "574b0981954b71390c4ed0ac14da1d3c14fbeea7"}, "source": ["train.columns"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "56c32b5c-4958-471b-9d51-2c9935d1eef3", "_uuid": "a184ec5dc5561833561cda84fd66dac4ea388e52"}, "source": ["* Check for missing values in both training and testing data columns\n", "* Before checking replace all **-1** values to **np.NaN**"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "210f6cd5-4352-4b20-b153-b76819af31b7", "_uuid": "36e70184e9856537ced5c3ca1912a7b22bf6eabd"}, "source": ["train_copy = train\n", "train_copy = train_copy.replace(-1, np.NaN)\n", "test_copy = test\n", "test_copy = test_copy.replace(-1, np.NaN)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "43992aba-2c85-4b43-bcd6-bd02af076e13", "_uuid": "f6af3190d9e9d2305a36581afe89c6241303441f"}, "source": ["import missingno as msno\n", "%matplotlib inline\n", "msno.bar(train_copy)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "2e392040-78f2-4aab-9bf1-67da50248f2a", "_uuid": "4541a02c7ec15d6b23397d529fe04e033365caf1"}, "source": ["msno.bar(test_copy)"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_cell_guid": "cef01bec-437a-4f51-9306-e0a748f74c57", "_uuid": "e39bd47fabb4b0a76606270966b50b91b8ed4511"}, "source": ["* From the graph, we found that 2 features are having more than 50% missing values.\n", "* Before applying models, we will find the important features from these 58. \n", "* **Finding import feature using ExtraTreeClassifier**"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "5df49b88-ba62-4713-b8d0-b0a73e93673f", "_uuid": "702745d68f71bc3d9468e62e4e5f8dd68c35c10b"}, "source": ["# We cannot use all training samples for finding important features. So will split the data first.\n", "from sklearn.model_selection import train_test_split\n", "\n", "X_train = train.drop(['target'], axis=1).values\n", "y_train = train['target'].values\n", "X_train_main, X_train_validate, y_train_main, y_train_validate = train_test_split(X_train,y_train,test_size=0.5,stratify=y_train) "], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"scrolled": false, "_cell_guid": "1e9a001a-9630-4af4-806d-d199d4350264", "_uuid": "cc3a0d4f35bbd3871de9554459985b54a531dfd3"}, "source": ["from sklearn.ensemble import ExtraTreesClassifier\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "forest = ExtraTreesClassifier(n_estimators=250,\n", "                              random_state=0)\n", "forest.fit(X_train_main, y_train_main)\n", "importances = forest.feature_importances_\n", "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n", "             axis=0)\n", "indices = np.argsort(importances)[::-1]\n", "\n", "# Print the feature ranking\n", "print(\"Feature ranking:\")\n", "\n", "for f in range(X_train_main.shape[1]):\n", "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n", "\n", "# Plot the feature importances of the forest\n", "plt.figure(figsize=(20,10))\n", "plt.title(\"Feature importances\")\n", "plt.bar(range(X_train_main.shape[1]), importances[indices],\n", "       color=\"r\", yerr=std[indices], align=\"center\")\n", "plt.xticks(range(X_train_main.shape[1]), indices)\n", "plt.xlim([-1, X_train_main.shape[1]])\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "3747c182-2abf-4319-babf-4a5b8610fdeb", "_uuid": "09fc4c2b017dc5b5071f5a3c2f63032a3f482468"}, "source": ["From the graph, we found that first 28 features are more important in this case. Others are not that much important for predictions. So we are taking only these top 28 features for our predictions."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "b0a4b16e-2121-4c63-b58d-678df268a18d", "_uuid": "9ec524ea927882af6668e5defd7a9fb91510f770"}, "source": ["important_feature = []\n", "for f in range(28):\n", "    important_feature.append(indices[f])\n", "#     print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n", "print(important_feature)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "6d5b23fa-706d-46f0-889a-6609b78ffabf", "_uuid": "c4d8ff2f3caff4a3e464fee3ea0df7aeb555dcd1"}, "source": ["# Final dataframe with only important features\n", "train_copy = train.drop(['target'],axis=1)\n", "final_train = train_copy.iloc[:,important_feature]\n", "X_train = final_train.values\n", "y_train = train['target'].values\n", "# final_train = train.iloc[:,important_feature]\n", "# print(final_train.head())\n", "# X_train = final_train.drop(['target'], axis=1).values\n", "# y_train = final_train['target'].values\n", "X_train_main, X_train_validate, y_train_main, y_train_validate = train_test_split(X_train,y_train,test_size=0.2,stratify=y_train) "], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "cd7febb0-5601-404a-8709-977e2ff5adab", "_uuid": "ed0ad2a78b7d52a9018e8118cefb9dba4ee018ef"}, "source": ["Now this is the stage to implement our model RandomForestClassifier**"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "b1c55dd5-bfec-45b0-a6a8-f7a1633ee5b7", "_uuid": "1dd8987dd21fb71c9dc6cb36979377c350a84490"}, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "clf = RandomForestClassifier(max_depth=2, random_state=0)\n", "clf.fit(X_train_main, y_train_main)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "d416575f-da3c-4ac5-9a5a-01249b721cbc", "_uuid": "8eec6621ae4fba09856a833b2edd2c46fef7c6dd"}, "source": ["predicted_train_validate = clf.predict(X_train_validate)\n", "actual_train_validate = y_train_validate"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "44502f3d-2501-445e-a5d7-698e7c32b744", "_uuid": "5f0e598ff83cb7e1aeb8468fc85bce1f0b5956bf"}, "source": ["To check our model accuracy using accuracy score"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "d6d7d328-9e80-4f56-a753-4e1ca015d9e3", "_uuid": "f93bee5bda902b0659f41d9df3be365cd3390d25"}, "source": ["from sklearn.metrics import accuracy_score\n", "accuracy_score(actual_train_validate, predicted_train_validate)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "f8ed0251-48fd-487b-8e0a-fa1eef76c1e1", "_uuid": "988519ceb0a4d67b24186fce0c70bc68059a848d"}, "source": ["Wow ! Got an accuracy of 96%. Interesting. "], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "f88e78a9-64c6-4bea-9c4c-0c9aa861347c", "_uuid": "a5f360bd88410200d18223434af17bde31d53b60"}, "source": ["# Prepare submission file\n", "test_copy = test.iloc[:,important_feature]\n", "X_test = test_copy.values\n", "predicted_test = clf.predict(X_test)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "d07d1648-4ead-4f88-8c77-b09a6b7007ec", "_uuid": "a0570f8b26128181b67055ca26e380658e802b9f"}, "source": ["output = pd.DataFrame({'id': test['id'].values, 'target': predicted_test})"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "18134277-1c6b-4d57-9db1-3e2f40cfd731", "_uuid": "8ddaf91a9654762ec45311fc2086c3d981c185f2"}, "source": ["output.to_csv(\"submission_output.csv\", index=False) "], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "80fb7f7c-9b21-40a0-8498-3fb2716243b4", "_uuid": "8d5e9ee2966024d19e94e33c86967375a7469d3a"}, "source": ["I hope that you all got atleast one new thing from my kernel. Please upvote and encourage me to write more.\n", "* If any queries, please comment below. I can help you upto my understanding. "], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "fd7e904e-2e57-4ae9-b3d2-a00f5ac784e7", "_uuid": "1b160b88a13c47244c880f50795035b6d4eed4be"}, "source": [], "cell_type": "code", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}