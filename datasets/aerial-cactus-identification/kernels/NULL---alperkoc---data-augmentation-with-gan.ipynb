{"cells":[{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Don't forget to enable GPU on Setting"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys, cv2, glob, os, time\nimport pandas as pd \nimport numpy as np\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten,Activation\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nprint(os.listdir(\"../input\"))\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Directories"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/train/train/\"\ntest_dir = \"../input/test/test/\"\ntrain_df = pd.read_csv('../input/train.csv')\ntrain_df.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Image Size\n- Width: 32, Height:32, 3 Channels for colored image. Set channels 0 for greyscale image"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"img_rows = 32\nimg_cols = 32\nchannels = 3\nimg_shape = (img_rows, img_cols, channels)\nz_dim = 100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GAN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator(img_shape, z_dim):\n    model = Sequential()\n    model.add(Dense(128, input_dim=z_dim))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(img_rows*img_cols*channels, activation='tanh'))\n    model.add(Reshape(img_shape))\n    z = Input(shape=(z_dim,))\n    img = model(z)\n    return Model(z, img)\n\ndef discriminator(img_shape):\n    model = Sequential()\n    model.add(Flatten(input_shape=img_shape))\n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=0.01))\n    model.add(Dense(1, activation='sigmoid'))\n    img = Input(shape=img_shape)\n    prediction = model(img)\n    return Model(img, prediction)\n\ndiscriminator = discriminator(img_shape)\ndiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\ngenerator = generator(img_shape, z_dim)\nz = Input(shape=(100,))\nimg = generator(z)\ndiscriminator.trainable = False\nprediction = discriminator(img)\ncombined = Model(z, prediction)\ncombined.compile(loss='binary_crossentropy', optimizer=Adam())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Single image for test"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_ = cv2.imread(\"../input/train/train/00b4dfbb267109b5f0d0dde365fa6161.jpg\",1)\n#img_ = cv2.cvtColor(img_,cv2.COLOR_BGR2GRAY)\nplt.imshow(img_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Dataset and Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareTrainSet(train_df):\n    train_1 = train_df[train_df.has_cactus == 1]\n    train_0 = train_df[train_df.has_cactus == 0]\n    ids_1 = train_1.id.tolist()\n    ids_0 = train_0.id.tolist()\n\n    path = glob.glob(\"../input/train/train/*.jpg\")\n    imgs_0,imgs_1 = [],[]\n    for img in path:\n        im = cv2.imread(img)\n#     uncomment next line while using single channel image\n        #im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n#     uncomment next line if your want to scale image\n        #im = cv2.resize(im,(80,65))\n        if img.split(\"/\")[-1] in ids_1:\n            imgs_1.append(im)\n        elif img.split(\"/\")[-1] in ids_0:\n            imgs_0.append(im)\n            \n    X_train_0 = np.asarray(imgs_0)\n    X_train_1 = np.asarray(imgs_1)\n\n    X_train_0 = X_train_0 / 127.5 - 1.\n    X_train_1 = X_train_1 / 127.5 - 1.\n    \n#     uncomment next two line while using single channel image\n\n#     X_train_0 = np.expand_dims(X_train_0, axis=3)\n#     X_train_1 = np.expand_dims(X_train_1, axis=3)\n\n    print(X_train_0.shape)\n    print(X_train_1.shape)\n    \n    return X_train_0,X_train_1\n\nlosses = []\naccuracies = []\ndef train(iterations, batch_size, sample_interval):\n    gen_images = []\n    X_train_0,X_train_1 = prepareTrainSet(train_df)\n    \n    # Assign X_train to X_train_0 for augment non-cactus images\n    # Assign X_train to X_train_1 for augment cactus images\n\n    X_train = X_train_0\n    real = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    for iteration in range(iterations):\n       \n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs = X_train[idx]\n\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n\n        d_loss_real = discriminator.train_on_batch(imgs, real)\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        z = np.random.normal(0, 1, (batch_size, 100))\n        gen_imgs = generator.predict(z)\n        g_loss = combined.train_on_batch(z, real)\n\n        if iteration % sample_interval == 0:\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100*d_loss[1], g_loss))\n            losses.append((d_loss[0], g_loss))\n            accuracies.append(100*d_loss[1])\n            gen_images.append(sample_images(iteration))\n    return gen_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Show Sample Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sample_images(iteration, image_grid_rows=4, image_grid_columns=4):\n\n    z = np.random.normal(0, 1, \n              (image_grid_rows * image_grid_columns, z_dim))\n\n    gen_imgs = generator.predict(z)\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    \n    fig, axs = plt.subplots(image_grid_rows, image_grid_columns,  figsize=(10,10), sharey=True, sharex=True)\n    \n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0],)\n            axs[i,j].axis('off')\n            cnt += 1\n            \n    return gen_imgs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings; warnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start Training\n- Generated images can be found in gen_imgs list"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set iterations at least 10000 for good results\niterations = 1000\nbatch_size = 128\nsample_interval = 1000\n\ngen_imgs = train(iterations, batch_size, sample_interval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#row -1 for lastly generated samples\nrow = -1\n\n#columns -1 for last element of lastly generated samples\ncol = -1\n\nplt.imshow(gen_imgs[row][col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}