{"cells": [{"source": ["Three linear classifier solves the fraude\n", "----\n", "         * 'DecisionTree',\n", "         * 'RandomForestClassifier',    \n", "         * 'KNN',\n", "         \n", "         "], "metadata": {}, "cell_type": "markdown"}, {"source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "train = pd.read_csv(\"../input/creditcard.csv\")\n"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "1718d655b3bc025b5a85db1d08ba2801ae3fcc5a", "collapsed": true, "_cell_guid": "ea1c477f-65ef-4cdc-ab97-00adc897f745"}, "outputs": []}, {"source": ["import seaborn as sns\n", "import matplotlib.pyplot as plt # Visuals\n", "plt.style.use('ggplot') # Using ggplot2 style visuals \n", "\n", "f, ax = plt.subplots(figsize=(11, 15))\n", "\n", "ax.set_axis_bgcolor('#fafafa')\n", "ax.set(xlim=(-.05, 50))\n", "plt.ylabel('Dependent Variables')\n", "plt.title(\"Box Plot of Pre-Processed Data Set\")\n", "ax = sns.boxplot(data = train, \n", "  orient = 'h', \n", "  palette = 'Set2')\n", "\n", "\n", "\n", "#sns.set(style=\"ticks\", color_codes=True)\n", "#g = sns.pairplot(train, hue='Dx')\n", "\n", "    \n", "def plot_corr(df,size=10):\n", "    import matplotlib.pyplot as plt\n", "    '''Function plots a graphical correlation matrix for each pair of columns in the dataframe.\n", "\n", "    Input:\n", "        df: pandas DataFrame\n", "        size: vertical and horizontal size of the plot'''\n", "\n", "    corr = df.corr()\n", "    fig, ax = plt.subplots(figsize=(size, size))\n", "    ax.matshow(corr)\n", "    plt.xticks(range(len(corr.columns)), corr.columns);\n", "    plt.yticks(range(len(corr.columns)), corr.columns);\n", "\n", "plot_corr(train)"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "39aba1f568b39e80c7dc4c5e88e5334988158cf8", "collapsed": true, "_cell_guid": "529e05ad-36b4-45eb-9ce5-eb4379c8d520"}, "outputs": []}, {"source": ["new_col= train.groupby('Class').mean()\n", "print(new_col.head().T)\n", "train=train.fillna(0)\n"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "19f3b1ae3257114b05ef574232a8e177ea8dab3d", "collapsed": true, "_cell_guid": "5dbe3438-40bc-489a-b437-09277be255a0"}, "outputs": []}, {"source": ["from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\n", "from sklearn.preprocessing import MinMaxScaler\n", "import seaborn as sns\n", "\n", "def rmsle(y_predicted, y_real):\n", "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n", "def procenterror(y_predicted, y_real):\n", "     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n", "\n", "\n", "from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n", "\n", "n_col=36\n", "X = train.drop(['Class'],axis=1) \n", "Y=train['Class']\n", "#X=X.fillna(value=0)\n", "#scaler = MinMaxScaler()\n", "#scaler.fit(X)\n", "#X=scaler.transform(X)\n", "#poly = PolynomialFeatures(2)\n", "#X=poly.fit_transform(X)\n", "\n", "\n", "names = [\n", "         'DecisionTree',\n", "         'RandomForestClassifier',    \n", "         #'ElasticNet',\n", "         #'SVC',\n", "         #'kSVC',\n", "         'KNN',\n", "         #'GridSearchCV',\n", "         'HuberRegressor',\n", "         'Ridge',\n", "         'Lasso',\n", "         'LassoCV',\n", "         'Lars',\n", "         'BayesianRidge',\n", "         'SGDClassifier',\n", "         'RidgeClassifier',\n", "         'LogisticRegression',\n", "         'OrthogonalMatchingPursuit',\n", "         #'RANSACRegressor',\n", "         ]\n", "\n", "classifiers = [\n", "    DecisionTreeClassifier(),\n", "    RandomForestClassifier(n_estimators = 200),\n", "    #ElasticNetCV(cv=10, random_state=0),\n", "    #SVC(),\n", "    #SVC(kernel = 'rbf', random_state = 0),\n", "    KNeighborsClassifier(n_neighbors = 1),\n", "    #GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n", "    HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n", "    Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n", "    Lasso(alpha=0.05),\n", "    LassoCV(),\n", "    Lars(n_nonzero_coefs=10),\n", "    BayesianRidge(),\n", "    SGDClassifier(),\n", "    RidgeClassifier(),\n", "    LogisticRegression(),\n", "    OrthogonalMatchingPursuit(),\n", "    #RANSACRegressor(),\n", "]\n", "correction= [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n", "\n", "models=zip(names,classifiers,correction)\n", "   \n", "for name, clf,correct in models:\n", "    regr=clf.fit(X,Y)\n", "    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n", "    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n", "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n", "    \n", "    # Confusion Matrix\n", "    print(name,'Confusion Matrix')\n", "    conf=confusion_matrix(Y, np.round(regr.predict(X) ) )     \n", "    label = [\"0\",\"1\"]\n", "    sns.heatmap(conf, annot=True, xticklabels=label, yticklabels=label, cmap=\"YlGnBu\")\n", "    plt.show()\n", "    \n", "    print('--'*40)\n", "\n", "    # Classification Report\n", "    print(name,'Classification Report')\n", "    classif=classification_report(Y,np.round( regr.predict(X) ) )\n", "    print(classif)\n", "\n", "\n", "    # Accuracy\n", "    print('--'*40)\n", "    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n", "    print('Accuracy', logreg_accuracy,'%')"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "87e5af1b134c20db335488522b0daf73ae8c2fc1", "collapsed": true, "_cell_guid": "be255e1b-c2bf-4db6-92c8-29d02a55740b"}, "outputs": []}], "metadata": {"language_info": {"mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 1}