{"cells":[{"metadata":{"_uuid":"2d17ebf65ba57e7727c2d1f48ef7c932b7e56985"},"cell_type":"markdown","source":"# Digit Recognizer"},{"metadata":{"_uuid":"2358a7c98c2ada417c10e72cd602e4731df1232d"},"cell_type":"markdown","source":"**Reference: [Introduction to CNN Keras 0.997(top 6)](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# import libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Load data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d97cd2257c7fa24b85c4de9ec5a6ae1080038128"},"cell_type":"code","source":"y_train = train['label']\nX_train = train.drop(labels = ['label'], axis=1)\n\ndel train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e7938db4b0531cf910d2afbaf106e4709429895"},"cell_type":"code","source":"g = sns.countplot(y_train)\ny_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4823e4cf031c2d6788ac0655613192600658cfd1"},"cell_type":"markdown","source":"## Check for null and missing values"},{"metadata":{"trusted":true,"_uuid":"4f1c5768cebf48ed2e47c95aaa5ede37e2485ef2"},"cell_type":"code","source":"X_train.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63251a7924c3c650faa119f8f1ae97dc4493269f"},"cell_type":"code","source":"test.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1e8696da42c798de70b8bfefc9d2f5d517dd72d"},"cell_type":"markdown","source":"## Normalize the data"},{"metadata":{"trusted":true,"_uuid":"b3ed22fc4d6faa0fc42e0697b49d9a549d41a967"},"cell_type":"code","source":"# Grayscale normalization to reduce effect of illumination's differences.\nX_train = X_train / 255.0\ntest = test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7576d6587bce3e9cc708c69480c2bb60c8fb8fe2"},"cell_type":"code","source":"#reshape image in 3 dimension - height = 28px, width = 28px, canal = 1\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cc0bcf49701533524aecbb12baaccdfb54864b8"},"cell_type":"markdown","source":"## Label encoding"},{"metadata":{"trusted":true,"_uuid":"73c038cd50248c2acb37729fa7741b18529362e9"},"cell_type":"code","source":"# Encode labels to one hot vectors\ny_train = to_categorical(y_train, num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff7918e04f75214b55b8af4d2f37853cad8eb1ea"},"cell_type":"markdown","source":"## Split training and validation set"},{"metadata":{"trusted":true,"_uuid":"327c97c212e2fe4577578bdb1365f0bbaf86d0ff"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size =0.1, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a195add3c9d05b9b295d6f53ed2c662402bda51"},"cell_type":"code","source":"#example\ng = plt.imshow(X_train[0][:,:,0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8033dc2fc9acb9cf265bf06e7a82832714d578ca"},"cell_type":"markdown","source":"# CNN"},{"metadata":{"trusted":true,"_uuid":"05310fc977024d7bc7b91ef9f6dc14497b08d84b"},"cell_type":"code","source":"# Set the CNN model\n# [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='Same', activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83deab32fcc9e8f6d0f87a4d79e5a5baaa7e1b1b"},"cell_type":"code","source":"#set the optimizer\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba679b79cd877e50742541bef566538d4b9fe23d"},"cell_type":"code","source":"#compile the model\n\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58f75bbeaec2ff098a24ccdfed6befd8d9902d36"},"cell_type":"code","source":"#set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f92637a5a22f75957efc795a7ddb1803b973f130"},"cell_type":"code","source":"epochs = 10\nbatch_size = 86","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5263e5bce30ff65ea486b338061f837f270cc33b"},"cell_type":"markdown","source":"## Data augmentation"},{"metadata":{"_uuid":"2390f33430eb2d3a93da2d2bf48a05a62ab772b0"},"cell_type":"markdown","source":"\n*     Randomly rotate some training images by 10 degrees\n*     Randomly Zoom by 10% some training images\n*     Randomly shift images horizontally by 10% of the width\n*     Randomly shift images vertically by 10% of the height\n"},{"metadata":{"trusted":true,"_uuid":"089987144681062f7827d0c9e9977d2a2c7796cd"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n            featurewise_center=False, \n            samplewise_center= False,\n            featurewise_std_normalization=False,\n            samplewise_std_normalization=False,\n            zca_whitening=False,\n            rotation_range=10,  #randomly rotate image in 0 to 180 degree\n            zoom_range=0.1, #randomly zoom image\n            width_shift_range=0.1, #randomly shift images horizontally\n            height_shift_range=0.1, #randomly shift images vertically\n            horizontal_flip = False, #randomly flip images\n            vertical_flip = False #randomly flip images\n)\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02c3b6ac03cef32024c28d481fb128ac99b4345f"},"cell_type":"code","source":"# Fit the model\n# epoch = 1\nclf = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=1, validation_data=(X_val, y_val),\n                             verbose=2, steps_per_epoch=X_train.shape[0] // batch_size, callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ad55113e9c3004618d17fe18173ffcadf402c5cb"},"cell_type":"code","source":"# Fit the model\nclf = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=epochs, validation_data=(X_val, y_val),\n                             verbose=2, steps_per_epoch=X_train.shape[0] // batch_size, callbacks=[learning_rate_reduction])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4295685e0d818effabc13213a7390b71ac45eeeb"},"cell_type":"markdown","source":"## Evaluate the model"},{"metadata":{"trusted":true,"_uuid":"6cd5f764e34135fc7e54452ce474975f055dc35e"},"cell_type":"code","source":"# plot the loss and accuracy curves\nfig, ax = plt.subplots(2,1)\nax[0].plot(clf.history['loss'], color='b', label='Training loss')\nax[0].plot(clf.history['val_loss'], color='r', label='Validation loss', axes=ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(clf.history['acc'], color='b', label='Training accuracy')\nax[1].plot(clf.history['val_acc'], color='r', label='Validation accuracy')\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca83d9bcc3e7b89a51a32e38109ccfb99638b638"},"cell_type":"code","source":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\ny_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \ny_pred_classes = np.argmax(y_pred,axis = 1) \n# Convert validation observations to one hot vectors\ny_true = np.argmax(y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7eab745d45f190cdd1876959b93c66a4aac9ef47"},"cell_type":"code","source":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebbc4a1cd8538ba156483f80af6ed75e367e411c"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"digitrecognizer.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}