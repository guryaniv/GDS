{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b57c08f05933c8ada51122a1218594aa41767d04","collapsed":true},"cell_type":"code","source":"#PROGRAM TO REDUCE MEMORY SIZE OF EACH INPUT FILE\nprint('WRITING PROGRAM TO REDUCE FILE SIZE....')\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n#CONVERT AND RETURN NEW FILE\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df\n\nprint('PROGRAM COMPLETE....')\n","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fe5e3a91d299d1752fdf4fade5b697292f0390c","collapsed":true},"cell_type":"code","source":"#CONVERT ALL AVAILABLE FILES\nprint('CONVERTING ALL INPUT FILES....')\n\nprint('-' * 80)\nprint('train')\napp_train = import_data('../input/application_train.csv')\n\nprint('-' * 80)\nprint('test')\napp_test = import_data('../input/application_test.csv')\n\nprint('-' * 80)\nprint('bureau_balance')\nbur_bal = import_data('../input/bureau_balance.csv')\n\nprint('-' * 80)\nprint('bureau')\nbur = import_data('../input/bureau.csv')\n\nprint('-' * 80)\nprint('credit_card_balance')\ncredit = import_data('../input/credit_card_balance.csv')\n\nprint('-' * 80)\nprint('installments_payments')\ninstall = import_data('../input/installments_payments.csv')\n\nprint('-' * 80)\nprint('pos_cash_balance')\npos = import_data('../input/POS_CASH_balance.csv')\n\nprint('-' * 80)\nprint('previous_application')\nprev = import_data('../input/previous_application.csv')\n\nprint('CONVERSION FOR ALL FILES COMPLETE....')\n","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d46f31097cc5da2a6fc415442aa13cc0be961fd","collapsed":true},"cell_type":"code","source":"#SAVING A COPY OF TEST FILE FOR LATER USE\nprint('SAVING A COPY OF TEST FILE FOR LATER USE....')\n\napp_test1 = app_test\n\nprint('SAVING COMPLETE....')","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdbd90b4dd061ca85379ad5c7d59cf30b277ae62","collapsed":true},"cell_type":"code","source":"#WRITE A PROGRAM TO LABEL CODE THE CATEGORY COLUMNS\nprint('WRITING A PROGRAM TO LABEL CODE CATEGORY COL....')\n\ndef encode(df, nan_as_category = True):\n    original_columns = list(df.columns)\n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n    new_columns = [c for c in df.columns if c not in original_columns]\n    return new_columns,df\n\nprint('PROGRAM COMPLETE....')","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee02d29125e8929813567c89dd5cc452a3666ba","collapsed":true},"cell_type":"code","source":"#IMPUTE MISSING VALUES IN OCCUPATION BASED ON SALARY SLAB\n\nprint('IMPUTING OCCUPATION TYPE BASED ON SALARY SLAB IN TRAIN & TEST DATA....')\n\n#FINDING MISSING DATA LOCATIONS\nmiss = app_train['OCCUPATION_TYPE'].isnull()\nmiss1 = app_test['OCCUPATION_TYPE'].isnull()\n\n#CREATE AN EMPTY LIST TO CAPTURE NEW OCCUPATION DATA\ntest = []\ntest1 = []\n\n#FIND THE INCOME FROM MISSING DATA SET\ndf = app_train.loc[miss,'AMT_INCOME_TOTAL']\ndf_test = app_test.loc[miss1, 'AMT_INCOME_TOTAL']\n\n#IMPUTE BASED ON MEAN INCOME FOR EACH TYPE OF OCCUPATION\nfor x in df:\n    if  x < 130791:\n        test.append('Cleaning staff')\n    elif (x>130791) & (x< 133228):\n        test.append('Low-skill Laborers')\n    elif (x>133228) & (x< 138397):\n        test.append('Cooking staff')\n    elif (x>138397) & (x <144273):\n        test.append('Waiters/barmen staff')\n    elif (x>144273) & (x < 149663):\n        test.append('Security staff')\n    elif (x>149663) & (x < 149710):\n        test.append('Medicine staff')\n    elif (x>149710) & (x <152303):\n        test.append('Sales staff')\n    elif (x>152303) & (x <160542):\n        test.append('Secretaries')\n    elif (x>160542) & (x <166357):\n        test.append('Laborers')\n    elif (x>166357) & (x <172657):\n        test.append('Core staff')\n    elif (x>172657) & (x <182335):\n        test.append('Private service staff')\n    elif (x>182335) & (x <182842):\n        test.append('High skill tech staff')\n    elif (x>182842) & (x <187012):\n        test.append('Drivers')\n    elif (x>187012) & (x <188916):\n        test.append('HR staff')\n    elif (x>188916) & (x <194578):\n        test.append('Accountants')\n    elif (x>194578) & (x <195004):\n        test.append('Realty agents')\n    elif (x>195004) & (x <213446):\n        test.append('IT staff')\n    elif (x>213446):\n        test.append('Managers')\n","execution_count":74,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eab9f7cac50ec85ef3bb150b07fe1c007e4f0e4a","collapsed":true},"cell_type":"code","source":"#DO THE SAME FOR TEST DATA\nfor x in df_test:\n    if  x < 130791:\n        test1.append('Cleaning staff')\n    elif (x>130791) & (x< 133228):\n        test1.append('Low-skill Laborers')\n    elif (x>133228) & (x< 138397):\n        test1.append('Cooking staff')\n    elif (x>138397) & (x <144273):\n        test1.append('Waiters/barmen staff')\n    elif (x>144273) & (x < 149663):\n        test1.append('Security staff')\n    elif (x>149663) & (x < 149710):\n        test1.append('Medicine staff')\n    elif (x>149710) & (x <152303):\n        test1.append('Sales staff')\n    elif (x>152303) & (x <160542):\n        test1.append('Secretaries')\n    elif (x>160542) & (x <166357):\n        test1.append('Laborers')\n    elif (x>166357) & (x <172657):\n        test1.append('Core staff')\n    elif (x>172657) & (x <182335):\n        test1.append('Private service staff')\n    elif (x>182335) & (x <182842):\n        test1.append('High skill tech staff')\n    elif (x>182842) & (x <187012):\n        test1.append('Drivers')\n    elif (x>187012) & (x <188916):\n        test1.append('HR staff')\n    elif (x>188916) & (x <194578):\n        test1.append('Accountants')\n    elif (x>194578) & (x <195004):\n        test1.append('Realty agents')\n    elif (x>195004) & (x <213446):\n        test1.append('IT staff')\n    elif (x>213446):\n        test1.append('Managers')\n\n#ADD THE CAPTURED OCCUPATION DATA  IN MISSING LOCATIONS\napp_train.loc[miss,'OCCUPATION_TYPE'] = test\napp_test.loc[miss1,'OCCUPATION_TYPE'] = test1\n\nprint('IMPUTING IS COMPLETE FOR OCCUPATION TYPE....')\n","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a46ec4e5e777130bdb8d2ddae7d9199d3124e5b","collapsed":true},"cell_type":"code","source":"#BINARIZING Y/N COLUMNS FOR TRAIN & TEST DATA\nprint('BINARIZING Y/N COLUMNS FOR TRAIN AND TEST DATA....')\n\nfor df in (app_train,app_test):\n    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n            df[bin_feature], uniques = pd.factorize(df[bin_feature])\n\nprint('BINARUZING COMPLETE....')\n\n#FEATURE ENGINEERING\nprint('FEATURE ENGINEERING FOR TRAIN & TEST....')\n\nfor df in (app_train,app_test):\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['DAYS_REG_PERC'] = df['DAYS_REGISTRATION'] / df['DAYS_BIRTH']\n    df['DAYS_ID_PERC'] = df['DAYS_ID_PUBLISH'] / df['DAYS_REGISTRATION']\n    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n    df['LOAN_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n    df['CONSUMER_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n    df['ANNUITY LENGTH'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n    df['ANN_LENGTH_EMPLOYED_RATIO'] = df['ANNUITY LENGTH'] / df['DAYS_EMPLOYED']\n    df['WORKING_LIFE_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['TOTAL_DOCS_SUBMITTED'] = df.loc[:, df.columns.str.contains('FLAG_DOCUMENT')].sum(axis=1)\n    \nprint('FEATURE ENGINEERING COMPLETE....')\n","execution_count":76,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e448114e23cba4b496295be044059ac1cab31018","collapsed":true},"cell_type":"code","source":"#REPLACING ODD VALUES WITH NAN\nprint('REPLACE ODD VALUES WITH NAN....')\n\nprev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\nprev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\nprev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\nprev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\nprev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n\n#FEATURE ENGINEERING\nprint('FEATURE ENGINEERING FOR PREVIOUS APP....')\n\nprev['ASK_AMT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\nprev['APPROVED'] = (prev['NAME_CONTRACT_STATUS'] == 'Approved').astype(int)\nprev['REFUSED'] = (prev['NAME_CONTRACT_STATUS'] == 'Refused').astype(int)\nprev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n\n#feature engineering for numerical columns\nagg = {\n    'AMT_ANNUITY': ['mean','max','sum','var','median'],\n    'AMT_APPLICATION': ['mean','max','sum','var','median'],\n    'AMT_CREDIT': ['mean','max','sum','var','median'],\n    'APP_CREDIT_PERC': ['mean','max','sum','var','median'],\n    'AMT_DOWN_PAYMENT': ['mean','max','sum','var','median'],\n    'AMT_GOODS_PRICE': ['mean','max','sum','var','median'],\n    'HOUR_APPR_PROCESS_START': ['mean','max','sum','var','median'],\n    'RATE_DOWN_PAYMENT': ['mean','max','sum','var','median'],\n    'DAYS_DECISION': ['mean','max','sum','var','median'],\n    'CNT_PAYMENT': ['mean', 'sum','max','var','median'],\n}\n    \nprev=prev.groupby('SK_ID_CURR').agg(agg)\nprev.reset_index(inplace=True)\nprev.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in prev.columns.tolist()])\nprev.rename(columns={'SK_ID_CURR_':'SK_ID_CURR'}, inplace=True)\n\nprint('FEATURE ENGINEERING FOR PREV COMPLETE')","execution_count":77,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a1a82614899970d0c65212c8c8ada59ff2bf18d","collapsed":true},"cell_type":"code","source":"prev.head()","execution_count":78,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f01a729ddb0293961ccb7acec9642a5c8777848","collapsed":true},"cell_type":"code","source":"print('FEATURE ENGINEERING FOR CREDIT.....')\ncredit['AMT_DRAW'] = credit['AMT_DRAWINGS_ATM_CURRENT'] + credit['AMT_DRAWINGS_CURRENT'] +credit['AMT_DRAWINGS_OTHER_CURRENT'] + credit['AMT_DRAWINGS_POS_CURRENT']\ncredit['CNT_DRAW'] = credit['CNT_DRAWINGS_ATM_CURRENT'] + credit['CNT_DRAWINGS_CURRENT'] + credit['CNT_DRAWINGS_OTHER_CURRENT'] + credit['CNT_DRAWINGS_POS_CURRENT']\ncredit['cr_util'] = (credit['AMT_BALANCE']*100) / credit['AMT_CREDIT_LIMIT_ACTUAL']\ncredit['PAID%'] = (credit['AMT_PAYMENT_TOTAL_CURRENT']*100) / credit['AMT_TOTAL_RECEIVABLE']\n\n#REPLACING ALL INF AND -INF WITH NAN\ncredit=credit.replace(np.inf, np.nan)\ncredit=credit.replace(-np.inf, np.nan)\n\n#GROUPING AND AGGREGATING\ncredit=credit.groupby('SK_ID_CURR').agg(['mean','sum','max','min','var','median'])\ncredit.reset_index(inplace=True)\ncredit.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in credit.columns.tolist()])\ndel credit['SK_ID_PREV_MEAN']\ndel credit['SK_ID_PREV_MAX']\ndel credit['SK_ID_PREV_MIN']\ndel credit['SK_ID_PREV_SUM']\ndel credit['SK_ID_PREV_VAR']\ndel credit['SK_ID_PREV_MEDIAN']\n           \n\nprint('FEATURE ENGINEERING FOR CREDIT COMPLETE')","execution_count":79,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6897e0e6d3aa0f14b41f3a0f6893fda1e98fbfc0"},"cell_type":"code","source":"credit = credit.rename(columns={'SK_ID_CURR_':'SK_ID_CURR'})","execution_count":80,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ac55a9264fa8997eb97de288ddca380d03b7315","collapsed":true},"cell_type":"code","source":"credit.head()","execution_count":81,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2966172a9fc175883242e26a620638a04f45c157","collapsed":true},"cell_type":"code","source":"# FEATURE ENGINEERING FOR INSTALLMENT\nprint('FEATURE ENGINEERING FOR INSTALLMENT.....')\n\ninstall['PAYMENT_PERC'] = install['AMT_PAYMENT'] / install['AMT_INSTALMENT']\ninstall['PAYMENT_DIFF'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\ninstall['DAYS_INSTALLMENT_LATE'] = install['DAYS_INSTALMENT'] - install['DAYS_ENTRY_PAYMENT']\ninstall['PAYMENT_DISCREPANCY'] = install['AMT_INSTALMENT'] - install['AMT_PAYMENT']\ninstall['DPD'] = install['DAYS_ENTRY_PAYMENT'] - install['DAYS_INSTALMENT']\ninstall['DBD'] = install['DAYS_INSTALMENT'] - install['DAYS_ENTRY_PAYMENT']\ninstall['DPD'] = install['DPD'].apply(lambda x: x if x > 0 else 0)\ninstall['DBD'] = install['DBD'].apply(lambda x: x if x > 0 else 0)\n\n#GROUPING AND AGGREGATING\ninstall = install.groupby('SK_ID_CURR').agg(['mean','sum','max','min','var','median'])\ninstall.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in install.columns.tolist()])\ninstall.reset_index(inplace=True)\ndel install['SK_ID_PREV_MEAN']\ndel install['SK_ID_PREV_SUM']\ndel install['SK_ID_PREV_MAX']\ndel install['SK_ID_PREV_MIN']\ndel install['SK_ID_PREV_VAR']\ndel install['SK_ID_PREV_MEDIAN']\nprint('FEATURE ENGINEERING FOR INSTALL COMPLETED....')","execution_count":82,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a9e802c8a14b0d812da701a267b4531ff9435c9","collapsed":true},"cell_type":"code","source":"install.head()","execution_count":83,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bfed52c8dc0c7cf110f60c409435ea2c2b28f3d","collapsed":true},"cell_type":"code","source":"# FEATURE ENGINEERING FOR POS\nprint('FEATURE ENGINEERING FOR POS.....')\npos=pos.groupby('SK_ID_CURR').agg(['mean','sum','max','var','min','median'])\npos.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in pos.columns.tolist()])\npos.reset_index(inplace=True)\ndel pos['SK_ID_PREV_MEAN']\ndel pos['SK_ID_PREV_MAX']\ndel pos['SK_ID_PREV_VAR']\ndel pos['SK_ID_PREV_SUM']\ndel pos['SK_ID_PREV_MIN']\ndel pos['SK_ID_PREV_MEDIAN']\n\nprint('FEATURE ENGINEERING FOR POS COMPLETED....')","execution_count":84,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56f702768c5d3f08ce4478ed868314c137511f67","collapsed":true},"cell_type":"code","source":"pos.head()","execution_count":85,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0ce2ff71291c7803a08299f9bb55e8ccbdebec1","collapsed":true},"cell_type":"code","source":"print('FEATURE ENGINEERING FOR BUR AND BAL.....')\nbal_agg = {'MONTHS_BALANCE': ['min', 'max','size','mean','var','median']}\nbur_bal = bur_bal.groupby('SK_ID_BUREAU').agg(bal_agg)\nbur_bal.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bur_bal.columns.tolist()])\nbur_bal = bur.join(bur_bal, how='left', on='SK_ID_BUREAU')\nbur_bal.drop(columns= 'SK_ID_BUREAU', inplace= True)\n\na = {\n        'DAYS_CREDIT': ['mean','max','sum','min','var','median'],\n        'CREDIT_DAY_OVERDUE': ['max','min','mean','sum','var','median'],\n        'DAYS_CREDIT_ENDDATE': ['mean','max','min','sum','var','median'],\n        'AMT_CREDIT_MAX_OVERDUE': ['mean','max','min','sum','var','median'],\n        'CNT_CREDIT_PROLONG': ['sum','max','min','mean','var','median'],\n        'AMT_CREDIT_SUM': ['mean', 'sum','max','min','var','median'],\n        'AMT_CREDIT_SUM_DEBT': ['mean', 'sum','max','min','var','median'],\n        'AMT_CREDIT_SUM_OVERDUE': ['mean','max','min','var','sum','median'],\n        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum','max','min','var','median'],\n        'DAYS_CREDIT_UPDATE': ['mean','max','min','var','sum','median'],\n        'AMT_ANNUITY': ['mean','max','min','sum','var','median'],\n        'MONTHS_BALANCE_MIN': ['min'],\n        'MONTHS_BALANCE_MAX': ['max'],\n        'MONTHS_BALANCE_SIZE': ['mean']\n    }\nbur_bal = bur_bal.groupby('SK_ID_CURR').agg(a)\nbur_bal.columns = pd.Index(['BUR_' + e[0] + \"_\" + e[1].upper() for e in bur_bal.columns.tolist()])\nbur_bal.reset_index(inplace=True)\nbur_bal.head()\nprint('FEATURE ENGINEERING FOR BUR AND BAL COMPLETED.....')\n","execution_count":86,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70dd298551e1eb5527c8fefcdb362ba5cf55c74a","collapsed":true},"cell_type":"code","source":"bur_bal.head()","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9353fe527125383188872f555992682e6bbe491","collapsed":true},"cell_type":"code","source":"#joinging all datas on sk_id_curr\nprint('JOIN ALL DATAS ON SK_ID_CURR....')\n\napp_train = app_train.merge(right=bur_bal, how='left', on='SK_ID_CURR')\napp_test = app_test.merge(right=bur_bal, how='left', on='SK_ID_CURR')\n\napp_train = app_train.merge(right=prev, how='left', on='SK_ID_CURR')\napp_test = app_test.merge(right=prev, how='left', on='SK_ID_CURR')\n\napp_train = app_train.merge(right=pos, how='left', on='SK_ID_CURR')\napp_test = app_test.merge(right=pos, how='left', on='SK_ID_CURR')\n\napp_train = app_train.merge(right=credit, how='left', on='SK_ID_CURR')\napp_test = app_test.merge(right=credit, how='left', on='SK_ID_CURR')\n\napp_train = app_train.merge(right=install, how='left', on='SK_ID_CURR')\napp_test = app_test.merge(right=install, how='left', on='SK_ID_CURR')\n\ndel app_train['SK_ID_CURR']\ndel app_test['SK_ID_CURR']\n\nprint('JOIN ALL DATAS ON SK_ID_CURR COMPLETE....')\n","execution_count":88,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60cb91da57d8b038f4d7df8fe1ec8913c39d3a44","collapsed":true},"cell_type":"code","source":"print(app_train.shape)\nprint(app_test.shape)","execution_count":89,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"206ff0f57f1cff9f62d38649cc7961bfbe8a00ad","collapsed":true},"cell_type":"code","source":"#PREPARING THE DATA FOR PREPROCESSING\ntrain = app_train.drop(['TARGET'],axis=1)\ntest = app_test\ntarget = app_train['TARGET']\ndel app_train['TARGET']\n","execution_count":90,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf5cd29883b7dc7148bcfa18d704779397e19885","collapsed":true},"cell_type":"code","source":"#PROGRAM TO LABEL ENCODE CATEGORICAL COL\nprint('LABEL ENCODING ALL CATEGORY COL......')\n\nfrom sklearn.preprocessing import LabelEncoder\nvar_mod = train.select_dtypes(include = 'object').columns.tolist()\nnum = train.columns.tolist()\nle = LabelEncoder()\nfor i in var_mod:\n    train[i] = le.fit_transform(train[i].astype('str'))\n    test[i] = le.fit_transform(test[i].astype('str'))\n    \nprint('LABEL ENCODING ALL CATEGORY COL COMPLETE......')\n","execution_count":91,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb40fdf8aa243f1d2d986ecdb954724985c9fd5a","collapsed":true},"cell_type":"code","source":"print(test.shape)\nprint(train.shape)","execution_count":92,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"120c1a2ed78438dade9b6bdbc4671ba681cef2fd","collapsed":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport gc\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=546789)\noof_preds = np.zeros(train.shape[0])\nsub_preds = np.zeros(test.shape[0])\nfeature_importance_df = pd.DataFrame()\n\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train, target)):\n    train_x, train_y = train.iloc[train_idx], target.iloc[train_idx]\n    valid_x, valid_y = train.iloc[valid_idx], target.iloc[valid_idx]\n\n    #SETTING THE CLASSIFIER\n    print('PREPARING THE LGBM CLASSIFIER.....')\n\n    clf = LGBMClassifier(\n            n_estimators=10000,\n            learning_rate=0.03,\n            num_leaves=45,\n            colsample_bytree=0.9,\n            subsample=0.8,\n            max_depth=8,\n            reg_alpha=.8,\n            reg_lambda=.7,\n            min_split_gain=.01,\n            min_child_weight=300,\n            silent=-1,\n            verbose=-1,\n            class_weight='balanced',\n            boosting_type = 'dart',\n            bagging_fraction = 0.6,\n            bagging_freq = 100\n            )\n    print('CLASSIFIER IS TUNNED....')\n    \n    clf.fit(train_x, train_y, \n            eval_set= [(train_x, train_y), (valid_x, valid_y)], \n            eval_metric='auc', verbose=100, early_stopping_rounds=100, feature_name = num, categorical_feature=var_mod #30\n           )\n    \n    oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n    sub_preds += clf.predict_proba(test, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = train_x.columns.tolist()\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n    del train_x, train_y, valid_x, valid_y\n    gc.collect()","execution_count":93,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5c1b5187a2b96b4ac588a387d31722320bbfb07","collapsed":true},"cell_type":"code","source":"# #print auc score\n# print('AUC : %.6f' % (roc_auc_score(target, sub_preds)))\n\n#feature selection\nbest_features = pd.DataFrame()\nfeature_importance_df.sort_values(by='importance', ascending=False)\ncols = fold_importance_df.sort_values(by=\"importance\", ascending=False)[:100].index\nbest_features = fold_importance_df.loc[(cols)]\nbest_features.sort_values(by='importance',ascending=False)","execution_count":94,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ee13883d66aae44bd4c234bfdc021c31ada80e","collapsed":true},"cell_type":"code","source":"#plot top 150\nbest_features.set_index('feature').plot(kind='barh', figsize=(26,18) )","execution_count":95,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"990aa32a1ceb69f42499dc60cfe556209f8d5a53","collapsed":true},"cell_type":"code","source":"print('FIT MODEL WITH TOP 100 FEATURES.....')\n#cnvert cols to list format\ncols = best_features.feature.tolist()\n\n#selecting top 50 cols\ntrain = train[cols]\ntest = test[cols]\n\nclf.fit(train,target)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db28d243d97023e5f44757bf9a7f13f091ead852","collapsed":true},"cell_type":"code","source":"print('PREDICTING TEST DATA......')\n#predict \npred = clf.predict_proba(test,num_iteration=clf.best_iteration_)[:,1]","execution_count":97,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7603d888b63d3ab482a08069350c2c8bcdaf4ea5","collapsed":true},"cell_type":"code","source":"p5 = pd.Series(data=pred)","execution_count":98,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65211db470708ccecee3175b009dbaca103e7ac9","collapsed":true},"cell_type":"code","source":"sub= app_test1\nsub['TARGET'] = p5\nt2 = sub[['SK_ID_CURR','TARGET']]\nt2.head()","execution_count":99,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93ec9be99b92027320491b8b9e856162db3f3ae6","collapsed":true},"cell_type":"code","source":"print(t2.isnull().sum())\nt2.head()","execution_count":100,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"63956353e71c236924d915a0dd2ecb9de702cd68"},"cell_type":"code","source":"t2.to_csv('submission.csv',index=False)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"976813ebd7d125865d80d88add88a6e2fe524933"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}