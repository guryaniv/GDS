{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2469a3abd81f785459ab8015ce1cfb0ae0f2dc5f"},"cell_type":"markdown","source":"# PUBG DATA SET\n<img src=\"https://saudigamer.com/wp-content/uploads/2018/09/123.jpg\" width=\"10000px\">\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score,KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d100f48a2195ee2e0f7e3fbbaa4b925ececa3a7e"},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6e4d39f942327d17b0e454bea9f218c5b0c1664"},"cell_type":"markdown","source":"# Import the Train Data Set"},{"metadata":{"trusted":true,"_uuid":"89e6e2cc2a003a076a101cd0be12fee2b75c0f10"},"cell_type":"code","source":"train_complete=pd.read_csv(\"../input/train_V2.csv\")\ntrain_complete.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8409714189f029b691f367a00b3d40c7e168d2d2"},"cell_type":"code","source":"train=train_complete.sample(100000,random_state =1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ef7ab66736e9f2951b79b64fdc7cf872ea28cf2"},"cell_type":"markdown","source":"**Removing the columns with unique id's**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"30c068fc5c42488112ed62a772d1445a40458db7"},"cell_type":"code","source":"train=train.drop(['Id','groupId','matchId'],axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1be771b061a247ef96775cf7a6d1ab9fc0bc89b"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31fbe4e1a18af04cebdbe56e21a234f15b866f1a"},"cell_type":"markdown","source":"There are no null values and no non numeric data columns . We can proceed with the visuals"},{"metadata":{"trusted":true,"_uuid":"05b2c905f5976fa93565f944d4c6a9871436a361"},"cell_type":"code","source":"dftrain=train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75990d3a6f7bec48ff8ea9f4e77e66fd21bce9e1"},"cell_type":"code","source":"corr=dftrain.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89c847233273afa484d70dfa6c0d8e6c357b65bd"},"cell_type":"code","source":"\nplt.figure(figsize=(15,10))\nsns.heatmap(corr,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4515c43d5d82d9527358c000f888f86dc1b03b64"},"cell_type":"code","source":"plt.figure(figsize=(15,10))\ncorr1=corr.abs()>0.5\nsns.heatmap(corr1,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14404968f407ef0e5d7cbc67611664a4105c58eb"},"cell_type":"markdown","source":"## Now lets the corelation of the variables with the target variable"},{"metadata":{"trusted":true,"_uuid":"f496cd0fccbab758072bdd9ebcb097835cce4973"},"cell_type":"code","source":"plt.title('Correlation B/w Winning % and other Independent Variable')\ndftrain.corr()['winPlacePerc'].sort_values(ascending=False).plot(kind='bar',figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcd9a0a606f4db2ae8257b4fa582d3d14c56b91b"},"cell_type":"markdown","source":"### Here we can see that walk distance,boosts,weapons Acquired, damage dealt,heals, kills, long kills,kills streaks, ride distance show good corelation with the target variables"},{"metadata":{"trusted":true,"_uuid":"28759cf38889e2f3b4da57464abee616de207b3b"},"cell_type":"markdown","source":"### Let's look at the top ten features which are corelated with the target variables."},{"metadata":{"trusted":true,"_uuid":"21f336b01517998eef8e6559be5f4fdd3f6d5d5c"},"cell_type":"code","source":"k = 10 #number of variables for heatmap\nf,ax = plt.subplots(figsize=(11, 11))\ncols = dftrain.corr().nlargest(k, 'winPlacePerc')['winPlacePerc'].index\ncm = np.corrcoef(dftrain[cols].values.T)\nsns.set(font_scale=1.25)\nhm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc8d5e29ce47bb228344ffc2edce0a82d9a5d999"},"cell_type":"markdown","source":"### Lets do a pair plot analysis for the top six features"},{"metadata":{"trusted":true,"_uuid":"f8ccaf0e8fb9134041e15428bc1cf2700268023c"},"cell_type":"code","source":"sns.set()\ncols = ['winPlacePerc', 'walkDistance', 'boosts', 'weaponsAcquired', 'damageDealt', 'killPlace']\nsns.pairplot(dftrain[cols], size = 2.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"516a4327a8d9b74691f002a7ba0cee5713a5dc36"},"cell_type":"markdown","source":"## Now lets deal with the multicoliearilty and remove the less important variables\n- We will calculate the ** variance inflation factor**  for the complete data set.\n- Feature selection by step wise method and arrive at final features which gives the best accuracy\n- VIF = 1/(1-r2)\n- There is thumb rule that the variables which are more than 10 are highly corelated and hence we can remove then"},{"metadata":{"trusted":true,"_uuid":"23c91419a7d4c7fe66a222d7539ba31bf048bb73"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14d043c97c73c0c540cb452fdf3fa87012cacd2f"},"cell_type":"markdown","source":"**Here we need to convert the non numeric columns to numeric by the creating dummy variables**"},{"metadata":{"trusted":true,"_uuid":"f7fb926eb192ba40d0bee1cf60c710d411913019"},"cell_type":"code","source":"train_complete=pd.get_dummies(train)\ntrain_complete.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fc20fb81f85f17ed221092ee6e5fcc90d6eed07"},"cell_type":"markdown","source":"**Variation Inflation Factor**"},{"metadata":{"trusted":true,"_uuid":"fd11b83986175ad2b3ff1aa5518c7545c153b69f"},"cell_type":"code","source":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nx_features=list(train_complete)\nx_features.remove('winPlacePerc')\ndata_mat = train_complete[x_features].as_matrix()                                                                                                              \nvif = [ variance_inflation_factor( data_mat,i) for i in range(data_mat.shape[1]) ]\nvif_factors = pd.DataFrame()\nvif_factors['column'] = list(x_features)\nvif_factors['vif'] = vif     \nvif_factors.sort_values(by=['vif'],ascending=False)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17432c77481b6cb961d226d26504293b48fe3834"},"cell_type":"markdown","source":"We will try removing the variables and check the Variance Inflation Factor"},{"metadata":{"trusted":true,"_uuid":"2cbc64800c22a36e59bf00dd20b8ca5d4c290e47"},"cell_type":"code","source":"x_features=list(train_complete)\nx_features.remove('winPlacePerc')\nx_features.remove('maxPlace')\nx_features.remove('numGroups')\nx_features.remove('winPoints')\nx_features.remove('rankPoints')\nx_features.remove('matchType_squad-fpp')\nx_features.remove('matchDuration')\ndata_mat = train_complete[x_features].as_matrix()                                                                                                              \nvif = [ variance_inflation_factor( data_mat,i) for i in range(data_mat.shape[1]) ]\nvif_factors = pd.DataFrame()\nvif_factors['column'] = list(x_features)\nvif_factors['vif'] = vif     \nvif_factors.sort_values(by=['vif'],ascending=False)[0:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa19e85a331821b115cd5146059abc3c88e9835d"},"cell_type":"markdown","source":"# Modelling the Data\n- Train Test Split\n- Model Comparision\n- Hyper Parameter Tuning\n- Building the Final Model"},{"metadata":{"_uuid":"253f8b1cda98c404f24634d46c1d02c45bc45de1"},"cell_type":"markdown","source":"#### Train Test Split"},{"metadata":{"trusted":true,"_uuid":"2ca8a77ca36729359ce768cf02fcc5e053a4bb5c"},"cell_type":"code","source":"x=train_complete[x_features]\ny=train_complete[['winPlacePerc']]\n# Train Test Split\nvalidation_size = 0.30\nseed = 1\nx_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=validation_size, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2ed107efe8a49a03811b2caf55090cf8ccd245f"},"cell_type":"markdown","source":"#### Model Comparision"},{"metadata":{"_uuid":"6910d6b8831773cf4d78a2b4a8bf6b8987779fb2"},"cell_type":"markdown","source":"# Spot-Check Algorithms\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('CART', DecisionTreeRegressor()))\nmodels.append(('GB', GradientBoostingRegressor()))# we can set the hyper parameters if needed"},{"metadata":{"_uuid":"82306a9ffdc57b839bd334c3b3a59d67c1fb9622"},"cell_type":"markdown","source":"# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=10, random_state=seed)\n    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring='r2') \n    results.append(cv_results)\n    names.append(name)\n    msg = \"%s: %f (%f)\" % (name, np.sqrt(cv_results.mean()), np.sqrt(cv_results.std()))\n    print(msg)"},{"metadata":{"_uuid":"d2a71c171603a36c549a3bc4e9cb3667f8945e8a"},"cell_type":"markdown","source":"#### Hyper Parameter Tuning"},{"metadata":{"_uuid":"0f1eb40721f9e58977b3da4c699327c248485967"},"cell_type":"markdown","source":"# Gradient Boost Algorithm Hyper Parameter Tuning\nn_estimators = np.arange(50,110,10)\nlearning_rate = np.arange(0.1,1.1,0.1)\nparam_grid = dict(n_estimators=n_estimators,learning_rate=learning_rate)\nmodel = GradientBoostingRegressor()\nkfold = KFold(n_splits=5, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='r2', cv=5)\ngrid_result = grid.fit(x_train, y_train)"},{"metadata":{"_uuid":"bf41006e9919c520c239638f1c4438726d1f954b"},"cell_type":"markdown","source":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{"_uuid":"6a588258629efa5424c9a8583ff02a531217ba7a"},"cell_type":"markdown","source":"#### Final Model"},{"metadata":{"trusted":true,"_uuid":"98ba9390de53dcae30a556458a5d15c7c9978f00"},"cell_type":"code","source":"model_final=GradientBoostingRegressor(n_estimators=100,learning_rate=0.5)\nmodel_final.fit(x_train,y_train)\nprint(model_final.score(x_train,y_train))\nprint(model_final.score(x_validation,y_validation))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"194fb046fadd12ac02a344ceafa98568d29cae87"},"cell_type":"markdown","source":"## Importing Test Data"},{"metadata":{"trusted":true,"_uuid":"9a4959370624cba2296ed12d961af59d698f2d73"},"cell_type":"code","source":"test=pd.read_csv('../input/test_V2.csv')\ndftest=test.drop(['Id','groupId','matchId'],axis=1)\ndftest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe5ec5e88c6ec79a0ae49971afab450d6ee2a76c"},"cell_type":"code","source":"dftest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d7793d0121e2907c2742f17e65e348649d24efe"},"cell_type":"code","source":"test_complete=pd.get_dummies(dftest)\nx_test=test_complete[x_features]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e68331d5ef8f1d57780bebd0f9c8df6a9686bce"},"cell_type":"markdown","source":"# Sample Submission"},{"metadata":{"trusted":true,"_uuid":"925ce932476dc26ecd82910172be26e9d93826cf"},"cell_type":"code","source":"    pred=model_final.predict(x_test)\n    pred[1:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59286ddf0b67e8dbfda35eef13dda36f47b10e45"},"cell_type":"code","source":"pred_df=pd.DataFrame(pred,test['Id'],columns=['winPlacePerc'])\npred_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa828c99f58b2d45724193b0e42c336103c4b6af"},"cell_type":"code","source":"pred_df.to_csv('sample_submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}