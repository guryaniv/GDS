{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\nprint(os.listdir(\"../input\"))","execution_count":76,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":77,"outputs":[]},{"metadata":{"_cell_guid":"d45444c7-8b4e-4dad-ae9b-58954426527e","_uuid":"81410f8cbd974549ab34422623f71a9ad81fcfd2","collapsed":true,"trusted":true},"cell_type":"code","source":"train_pixels = train_df.iloc[:, 1:].values / 255.0\ntrain_labels = train_df.iloc[:, 0].values\ntest_pixels = test_df.values / 255.0","execution_count":78,"outputs":[]},{"metadata":{"_cell_guid":"a48988b7-390b-4009-a1e4-b581d19afb85","_uuid":"e4f825e01466594e9718f1f93bb86173dc570c65","trusted":true},"cell_type":"code","source":"print(train_pixels.shape)\nprint(train_labels.shape)","execution_count":79,"outputs":[]},{"metadata":{"_cell_guid":"55c4ec30-9e94-430a-9d5f-f650d8f1d50c","_uuid":"d590ac51e3e3839644b7315696a9d3111803c3d3","trusted":true},"cell_type":"code","source":"train_pixels = train_pixels.reshape([-1, 28, 28])\nvalidation_size = int(len(train_pixels) * 0.1)\nvalidation_pixels = train_pixels[-validation_size:]\ntrain_pixels = train_pixels[:-validation_size]\ntest_pixels = test_pixels.reshape([-1, 28, 28])\nencoder = OneHotEncoder(10)\ntrain_labels = train_labels.reshape([-1,1])\nlabels = encoder.fit_transform(train_labels).toarray()\nvalidation_labels = labels[-validation_size:]\nlabels = labels[:-validation_size]\nprint(train_pixels.shape)\nprint(validation_pixels.shape)\nprint(test_pixels.shape)\nprint(labels.shape)\nprint(validation_labels.shape)","execution_count":80,"outputs":[]},{"metadata":{"_cell_guid":"bf248b1c-feae-4c32-aec9-14ff9b373b94","_uuid":"3e2f57eeb1fe8e134e6dc94c643023ea4b599c9d","collapsed":true,"trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline  ","execution_count":81,"outputs":[]},{"metadata":{"_cell_guid":"4f2b61bd-b3e7-4b76-a727-ea58725a8c26","_uuid":"388efd6418af9159a2d4bec572e2aba2221a2c7d","trusted":true},"cell_type":"code","source":"plt.figure()\nplt.imshow(train_pixels[69], cmap='gray')\nplt.figure()\nplt.imshow(train_pixels[420], cmap='gray')\nplt.figure()\nplt.imshow(train_pixels[666], cmap='gray')","execution_count":82,"outputs":[]},{"metadata":{"_cell_guid":"7778f83c-2a12-4ef0-aefc-e4b8b0114b69","_uuid":"9209cb0016e6632dbe77f02837196d8a81ecdb44","collapsed":true,"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dropout, Conv2D, Flatten, Dense, MaxPooling2D, Reshape, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":83,"outputs":[]},{"metadata":{"_cell_guid":"b9f9c20f-9d8d-480e-9093-ce5dc145bd5b","_uuid":"7a451398b66d954618f6251541b7f3ae6a303216","collapsed":true,"trusted":true},"cell_type":"code","source":"input_tensor = Input((28,28, 1))\nnet = Conv2D(16, (3,3), padding='same', activation='relu')(input_tensor)\nnet = BatchNormalization()(net)\nnet = Conv2D(16, (3,3), padding='same', activation='relu')(net)\nnet = MaxPooling2D()(net)\nnet = BatchNormalization()(net)\nnet = Conv2D(32, (3,3), padding='same', activation='relu')(net)\nnet = BatchNormalization()(net)\nnet = Conv2D(32, (3,3), padding='same', activation='relu')(net)\nnet = MaxPooling2D()(net)\nnet = BatchNormalization()(net)\nnet = Flatten()(net)\nnet = Dense(512, activation='relu')(net)\nnet = BatchNormalization()(net)\n# net = Dense(2048, activation=\"relu\")(net)\n# net = BatchNormalization()(net)\noutput_logits = Dense(10, activation='softmax')(net)\nmodel = Model(inputs=input_tensor, outputs=output_logits)","execution_count":84,"outputs":[]},{"metadata":{"_cell_guid":"3d5060b6-4331-4081-aa0a-29dc12724baa","_uuid":"d57357ad6b9fc76d6c4a9c5637b07daa6e788989","trusted":true},"cell_type":"code","source":"model.summary()","execution_count":85,"outputs":[]},{"metadata":{"_cell_guid":"fd816b62-6d1d-4564-bb77-7d3b78f84826","_uuid":"2cb899df91568246633a05fa53796a924617f662","collapsed":true,"trusted":true},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=5)","execution_count":86,"outputs":[]},{"metadata":{"_cell_guid":"5936d9c8-d1a9-4c1e-b98c-c72e785ca3a1","_uuid":"7baa6d3341ae9e8f4813190e6c8c674a0b3370e3","collapsed":true,"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":87,"outputs":[]},{"metadata":{"_cell_guid":"91734286-48a5-4b39-ac4f-0e30c57b1950","_uuid":"739999b3659162c745c547304639eb7a75ed072e","trusted":true},"cell_type":"code","source":"train_pixels = train_pixels.reshape([-1,28,28,1])\nvalidation_pixels = validation_pixels.reshape([-1,28,28,1])\ntest_pixels = test_pixels.reshape([-1, 28,28,1])\ngenerator = ImageDataGenerator(rotation_range=10,shear_range=10,zoom_range=0.1, height_shift_range=0.2, width_shift_range=0.2)\ngenerator.fit(train_pixels)\nprint(train_labels.shape)\nprint(labels.shape)","execution_count":88,"outputs":[]},{"metadata":{"_cell_guid":"81c75fa4-bfb9-4b50-aaa3-b4f1c77e16f9","_uuid":"ef026ccfa6e54fa12389c23271840fb9bd1570f0","trusted":true},"cell_type":"code","source":"# model.fit(train_pixels, labels, batch_size=128,epochs=12,validation_split=0.02, callbacks=[reduce_lr])\nmodel.fit_generator(generator.flow(train_pixels, labels, batch_size=128),steps_per_epoch=len(train_pixels) / 128 + 29, epochs=100, validation_data=(validation_pixels, validation_labels), callbacks=[reduce_lr])","execution_count":89,"outputs":[]},{"metadata":{"_cell_guid":"6672a805-b8c5-42bd-a54f-7f77f2c38fdd","_uuid":"4dc0848805fce02af3b46122639660b6be60779d","collapsed":true,"scrolled":true,"trusted":true},"cell_type":"code","source":"test_pixels = test_pixels.reshape([-1, 28, 28, 1])\nwith open('submission.csv', \"w\") as file:\n    file.write(\"ImageId,Label\\n\")\n    for idx in range(len(test_pixels)):\n        if (idx + 1) % 100 == 0:\n            print (\"{}/{}\".format(idx + 1, len(test_pixels)))\n        result = model.predict(np.array([test_pixels[idx]]))[0]\n        file.write(\"{},{}\\n\".format(idx+1, np.argmax(result)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19131d6e-b2a7-43e0-9567-3e1115f44aae","_uuid":"63153c54a8643cbfc45f11b18afa4a159bc56151","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}