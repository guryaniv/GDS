{"cells":[{"metadata":{"trusted":true,"_uuid":"18e574a2a54d91ff58194f8e52a6f9ce5eb4c195"},"cell_type":"markdown","source":"The AUC score can be used to validate a binary classification. With this kernel I want to explain it visually to better understand it."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def run(x_c0, x_c1):\n    # Create Target Variable\n    y = np.array([1 if v < x_c0.size else 0 for v in range(x_c0.size + x_c1.size)])\n\n    fig, axs = plt.subplots(1, 2, figsize = (16,8))\n\n    # Plot the distributions\n    ax = sns.kdeplot(x_c0, ax=axs[0])\n    ax = sns.kdeplot(x_c1, ax=axs[0])\n\n    # Prepare classification\n    X = np.append(x_c0, x_c1)\n    X = X.reshape(-1,1)\n    X_train, X_test, y_train, y_test = train_test_split(X, y)\n\n    # Run a simple linear classifier    \n    clf = LogisticRegression(solver='lbfgs')\n    clf.fit(X_train, y_train)\n    y_preds = clf.predict_proba(X_test)\n\n    # Calculate AUC\n    fpr, tpr, thresholds = roc_curve(y_test, y_preds[:,1])    \n    roc_auc = auc(fpr, tpr)\n\n    # Plot ROC\n    axs[1].plot(fpr, tpr, lw=1, label='(AUC = %0.2f)' % (roc_auc))\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd1b204c994f9699e9e7e7dfae85eed96a8ae335"},"cell_type":"markdown","source":"### Creating normal distributions that clearly separates the target variable\n\nIn the following cell you can see that the AUC score is = 1 if the distributions per class are clearly separable."},{"metadata":{"trusted":true,"_uuid":"fcf14e38f346934716f1513c5ab11dfb955c56b1","_kg_hide-input":false,"scrolled":false},"cell_type":"code","source":"run(np.random.normal(-7, 2, 100), np.random.normal(7, 2, 100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9999bd622c949278d091bf7dcade46592d1a962f"},"cell_type":"markdown","source":"### Creating normal distributions that overlaps a little bit\n\nNow you can see that the AUC score decreases if the distributions per class overlapping a little bit."},{"metadata":{"trusted":true,"_uuid":"0d348a2fc7490d00048820c40b66abcad39f6118"},"cell_type":"code","source":"run(np.random.normal(-7, 5, 100), np.random.normal(7, 5, 100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"943d2ba7fd1eb981671a4c68bbef493b7b0bc1e0"},"cell_type":"markdown","source":"\n### Creating normal distributions that overlaps a little bit\n\nThe more the distributions overlap, the worse the AUC score will be."},{"metadata":{"trusted":true,"_uuid":"d06bec1822da2314f2ea0ac520562ee5ab6802fa","scrolled":false},"cell_type":"code","source":"run(np.random.normal(-7, 14, 100), np.random.normal(7, 14, 100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2af3e0bff2103cf730165f9146dc34127e53989d"},"cell_type":"markdown","source":"I hope the kernel helps one or the other to better understand the AUC score."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}