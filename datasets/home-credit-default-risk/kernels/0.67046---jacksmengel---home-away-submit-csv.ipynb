{"cells":[{"metadata":{"_uuid":"e174ff28e7eaf852b5fc37fb48b0e740234c5fc6"},"cell_type":"markdown","source":"# Inviting our helping friendly libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('fivethirtyeight')\n\nfrom sklearn.preprocessing import Imputer\n\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d76041d5abf211c0d47c39b2002f6ff7eb6d9109"},"cell_type":"markdown","source":"# Function to do EDA on a Feature\n# Takes in dataframe and column, spits out:\n## - KDE plot on this column relative to TARGET (=0 and =1)\n## - Binned histogram of TARGET being 1 (on average) for that bin\n\n# This function is used throughout EDA process"},{"metadata":{"trusted":true,"_uuid":"d93d3aa913807010ea36fc62a4d74dd5ff03a088"},"cell_type":"code","source":"def show_kde_and_bins(df, col):\n    global fig_num\n    plt.figure(fig_num)\n    sns.kdeplot(df.loc[df['TARGET'] == 0, col], label = 'target == 0')\n    sns.kdeplot(df.loc[df['TARGET'] == 1, col], label = 'target == 1')\n    plt.xlabel(col)\n    plt.ylabel('Density')\n    \n    plt.figure(fig_num + 1)\n    axes = plt.gca()\n    axes.set_xlim([df[col].min(), df[col].max()])\n    staging = df[[col,'TARGET']]\n    staging['COL_BINNED'] = pd.cut(staging[col], bins = 10)\n    final = staging.groupby('COL_BINNED').mean()\n    plt.bar(final[col], final['TARGET'])\n    plt.xlabel(col)\n    plt.ylabel('AVG TARGET')\n    \n    fig_num += 2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec3191f82019afc5da7177e570a656913faa80ca"},"cell_type":"markdown","source":"# EDA: application_train.csv\n\n## Found columns which have \"low\" correlation to TARGET.  Nevertheless, built function to do EDA on columns.  \n\n## Findings:\n\n* Age and how long you've been employed are strongest positive correlations.\n* EXT_SOURCE_* columns are strongest negative correlations."},{"metadata":{"trusted":true,"_uuid":"f6c90e630b090690ff3b9eb6943f325448d4abd8"},"cell_type":"code","source":"train = pd.read_csv('../input/application_train.csv')\ntest = pd.read_csv('../input/application_test.csv')\n\nprint(train.shape)\n\n# columns with outliers:\n# DAYS_EMPLOYED\n\noutlier = train[train['DAYS_EMPLOYED'] > 30000]\nnon_outlier = train[train['DAYS_EMPLOYED'] < 30000]\n\n# new column for outlier\ntrain['DAYS_EMPLOYED_OUTLIER'] = 0\ntrain.loc[train['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED_OUTLIER'] = 1\n\n# fill in outliers with mean\ntrain.loc[train['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED'] = non_outlier['DAYS_EMPLOYED'].mean()\n\n# clean up DAYS_BIRTH and DAYS_EMPLOYED to be easy to understand\ntrain['YEARS_BIRTH'] = train['DAYS_BIRTH'] / -365\ntrain['YEARS_EMPLOYED'] = train['DAYS_EMPLOYED'] / -365\n\ntrain = pd.get_dummies(train)\n\n# columns with outliers:\n# DAYS_EMPLOYED\n\noutlier_te = test[test['DAYS_EMPLOYED'] > 30000]\nnon_outlier_te = test[test['DAYS_EMPLOYED'] < 30000]\n\n# new column for outlier\ntest['DAYS_EMPLOYED_OUTLIER'] = 0\ntest.loc[test['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED_OUTLIER'] = 1\n\n# fill in outliers with mean\ntest.loc[test['DAYS_EMPLOYED'] > 30000, 'DAYS_EMPLOYED'] = non_outlier_te['DAYS_EMPLOYED'].mean()\n\n# clean up DAYS_BIRTH and DAYS_EMPLOYED to be easy to understand\ntest['YEARS_BIRTH'] = test['DAYS_BIRTH'] / -365\ntest['YEARS_EMPLOYED'] = test['DAYS_EMPLOYED'] / -365\n\ntest = pd.get_dummies(test)\n\ntarget = train['TARGET']\n\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\ntrain['TARGET'] = target\n\n#corr = train.corr()\n#print(corr['TARGET'].sort_values(ascending = False))\n\n# strong positive corr -> DAYS_BIRTH, DAYS_EMPLOYED,REGION_RATING_CLIENT_W_CITY \n# strong negative corr -> EXT_SOURCE 1,2,3\n# Let's explore!\n\n# KDE / pd.cut()\n\nfig_num = 1\n\n    \nshow_kde_and_bins(train, 'EXT_SOURCE_1')\nshow_kde_and_bins(train, 'EXT_SOURCE_2')\nshow_kde_and_bins(train, 'EXT_SOURCE_3')\nshow_kde_and_bins(train, 'REGION_RATING_CLIENT_W_CITY')\nshow_kde_and_bins(train, 'YEARS_BIRTH')\nshow_kde_and_bins(train, 'YEARS_EMPLOYED')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56919597faae3ac7dfe3af254278b91f8eaed997"},"cell_type":"markdown","source":"# EDA: bureau.csv\n\n## Built function to find rows with outliers to see if there's an easy fix-up.. there is not.  Lots of outliers.  So I let them be.\n\n## Found columns with very little correlation to TARGET.  Still, they added some predictive value.  \n\n## Running .corr() over every column took a long time.  Minimized .corr() to just run on new columns from bureau.csv.\n\n## Features discovered with some predictive value:\n* bureau_DAYS_CREDIT_mean -> mean value for given applicant on DAYS_CREDIT column (how long credit is issued for)\n* bureau_CREDIT_ACTIVE_Active_mean -> average number of loans that are currently active / outstanding\n* bureau_DAYS_CREDIT_min -> Lowest number of days of credit given"},{"metadata":{"trusted":true,"_uuid":"59c9330196fc073d7483253330e0a12c14504ffd"},"cell_type":"code","source":"bureau = pd.read_csv('../input/bureau.csv')\nbureau = pd.get_dummies(bureau)\n\n# odd columns\n# amt_credit_max_overdue\n# AMT_CREDIT_SUM_LIMIT\n# AMT_CREDIT_SUM_OVERDUE\n\ndef outliers(df, col):\n    mean = df[col].mean()\n    std_dev = df[col].std()\n    df['Z_SCORE'] = (df[col] - mean) / std_dev\n    print(df[col].describe())\n    print('mean: ', mean,'. std dev: ', std_dev)\n    print(df.loc[df['Z_SCORE'] > 5, [col, 'Z_SCORE']])\n\n#outliers(bureau, 'AMT_CREDIT_MAX_OVERDUE')\n#outliers(bureau, 'AMT_CREDIT_SUM_LIMIT')\n#outliers(bureau, 'AMT_CREDIT_SUM_OVERDUE')\n# .. definitely outliers but leaving there since it seems legit (not one value or anything mysterious)\n\n# metrics on bureau\nbureau_staging = bureau \\\n    .drop(columns = ['SK_ID_BUREAU']) \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\nfor var in bureau_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in bureau_staging.columns.levels[1][:-1]:\n            columns.append('bureau_%s_%s' % (var, stat))\n\nbureau_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    bureau_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    bureau_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\n# columns.append('TARGET')\n\n# bureau_corr = tr[columns]\n#tr = imputer.fit_transform(tr)\n#print(tr)\n\n# corr = bureau_corr.corr()\n# print(corr['TARGET'].sort_values(ascending = False))\n\n# strong-ish corrs:\n# bureau_DAYS_CREDIT_mean  \n# bureau_CREDIT_ACTIVE_Active_mean\n# bureau_DAYS_CREDIT_min\n\nshow_kde_and_bins(train, 'bureau_DAYS_CREDIT_mean')\nshow_kde_and_bins(train, 'bureau_CREDIT_ACTIVE_Active_mean')\nshow_kde_and_bins(train, 'bureau_DAYS_CREDIT_min')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1b4b012298e04d3814d875ad953c67fb750d9b0"},"cell_type":"markdown","source":"# EDA: bureau_balance.csv\n# Removing -> did not produce any helpful features :)"},{"metadata":{"_uuid":"195d16793ad5e695d25edd6b21e199922c1081bd"},"cell_type":"markdown","source":"# EDA: previous_application.csv\n# See full EDA here: https://www.kaggle.com/jacksmengel/home-away-eda-previous-application-csv"},{"metadata":{"trusted":true,"_uuid":"146767bdccfc551545dd0666a2c27a2918a9df11"},"cell_type":"code","source":"previous_application = pd.read_csv('../input/previous_application.csv')\n\nprevious_application = previous_application[\n    [\n        'SK_ID_CURR',\n        'CODE_REJECT_REASON',                       \n        'NAME_CONTRACT_STATUS',                      \n        'NAME_PRODUCT_TYPE'\n    ]\n]\nprevious_application = pd.get_dummies(previous_application)\n\nprevious_application_staging = previous_application \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\nfor var in previous_application_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in previous_application_staging.columns.levels[1][:-1]:\n            columns.append('previous_application_%s_%s' % (var, stat))\n\nprevious_application_staging.columns = columns\n\nprevious_application = previous_application_staging[\n    [\n        'SK_ID_CURR',\n        'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n        'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n        'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n        'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n        'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n        'previous_application_NAME_PRODUCT_TYPE_walk-in_sum'\n    ]\n]\n\ntrain = pd.merge(\n    train,\n    previous_application_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    previous_application_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66379e0c08419916852d621530366f1b58ef82e8"},"cell_type":"markdown","source":"# EDA: POS_CASH_balance.csv\n# Only found MONTHS_BALANCE feature to be useful"},{"metadata":{"trusted":true,"_uuid":"ba9a67b723aacbc148c475fa12873c85df4471bd"},"cell_type":"code","source":"POS_CASH_balance = pd.read_csv('../input/POS_CASH_balance.csv')\nPOS_CASH_balance = POS_CASH_balance[['SK_ID_CURR', 'MONTHS_BALANCE']]\n\nPOS_CASH_balance_staging = POS_CASH_balance \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\nfor var in POS_CASH_balance_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in POS_CASH_balance_staging.columns.levels[1][:-1]:\n            columns.append('POS_CASH_balance_%s_%s' % (var, stat))\n\nPOS_CASH_balance_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    POS_CASH_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    POS_CASH_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32e20c067cbb712190a1989cfb0c0a5c0ed1d394"},"cell_type":"markdown","source":"# EDA: credit_card_balance.csv\n# Full EDA here: https://www.kaggle.com/jacksmengel/home-away-eda-credit-card-balance-csv\n# These features had .10 on .corr():\n## - credit_card_balance_CNT_DRAWINGS_ATM_CURRENT_mean\n## - credit_card_balance_CNT_DRAWINGS_CURRENT_max"},{"metadata":{"trusted":true,"_uuid":"60d9087eba693d3452684cf2ffa49bd27382b5a0"},"cell_type":"code","source":"credit_card_balance = pd.read_csv('../input/credit_card_balance.csv')\n\ncredit_card_balance_staging = credit_card_balance \\\n    .groupby('SK_ID_CURR') \\\n    .agg(['count','mean','min','max', 'sum']) \\\n    .reset_index()\n\ncolumns = ['SK_ID_CURR']\n\n# Convert multi-level index from .agg() into clean columns\n# borrowing from: https://www.kaggle.com/willkoehrsen/introduction-to-manual-feature-engineering\nfor var in credit_card_balance_staging.columns.levels[0]:\n    if var != 'SK_ID_CURR':\n        for stat in credit_card_balance_staging.columns.levels[1][:-1]:\n            columns.append('credit_card_balance_%s_%s' % (var, stat))\n\ncredit_card_balance_staging.columns = columns\n\ntrain = pd.merge(\n    train,\n    credit_card_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)\n\ntest = pd.merge(\n    test,\n    credit_card_balance_staging,\n    how = 'left',\n    on = 'SK_ID_CURR'\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"441f5bfaf6c43959257cc5af18c2dba462bf731b"},"cell_type":"markdown","source":"# It's time to see what these features can do\n\n# First, create imputer and our y dataframe:"},{"metadata":{"trusted":true,"_uuid":"b4bb85e0b574c853a4fe3438683863fc0bb13e8c"},"cell_type":"code","source":"y = train['TARGET']\nimputer = Imputer(strategy = 'mean')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"810824f70ead768639faf0f4d8a821418f2f7ce4"},"cell_type":"markdown","source":"# Next, train model using just application_train.csv columns"},{"metadata":{"trusted":true,"_uuid":"471a16edceef52db98b2d2c9a12a1f6b1f156669"},"cell_type":"code","source":"x_cols_app = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED'\n]\n\nx_app = train[x_cols_app]\nx_app = imputer.fit_transform(x_app)\n\nx_app_train, x_app_test, y_app_train, y_app_test = train_test_split(x_app, y, test_size = 0.33, random_state = 0)\n\nmodel_app = RandomForestClassifier()\nmodel_app.fit(x_app_train, y_app_train)\npredictions_app = model_app.predict_proba(x_app_test)\n\nauc_app = roc_auc_score(y_app_test, predictions_app[:,1])\nprint('AUC: app only:', auc_app)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c94405e46f3aee319b282752f767404e2c5008ba"},"cell_type":"markdown","source":"# ~.63 score using just application_train.csv...\n# Now, let's try adding on the bureau.csv columns..."},{"metadata":{"trusted":true,"_uuid":"a58ecebe55831a0bdca61676709b8b703807def0"},"cell_type":"code","source":"x_cols_app_bureau = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min'\n]\n\nx_app_bureau = train[x_cols_app_bureau]\nx_app_bureau = imputer.fit_transform(x_app_bureau)\n\nx_app_bureau_train, x_app_bureau_test, y_app_bureau_train, y_app_bureau_test = train_test_split(x_app_bureau, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau = RandomForestClassifier()\nmodel_app_bureau.fit(x_app_bureau_train, y_app_bureau_train)\npredictions_app_bureau = model_app_bureau.predict_proba(x_app_bureau_test)\n\nauc_app_bureau = roc_auc_score(y_app_bureau_test, predictions_app_bureau[:,1])\nprint('AUC: app + bureau:', auc_app_bureau)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7760230c34df2aa3c3bba6718e093bf8fe86cafc"},"cell_type":"markdown","source":"# application_train.csv + bureau.csv = ~.635\n# Very minimal improvement, but improvement nonetheless...\n# Now let's layer on previous_application.csv\n"},{"metadata":{"trusted":true,"_uuid":"c6177664fbb890bb6819007767d409e9a5853e36"},"cell_type":"code","source":"x_cols_app_bureau_prev = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum' \n]\n\nx_app_bureau_prev = train[x_cols_app_bureau_prev]\nx_app_bureau_prev = imputer.fit_transform(x_app_bureau_prev)\n\nx_app_bureau_prev_train, x_app_bureau_prev_test, y_app_bureau_prev_train, y_app_bureau_prev_test = train_test_split(x_app_bureau_prev, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev = RandomForestClassifier()\nmodel_app_bureau_prev.fit(x_app_bureau_prev_train, y_app_bureau_prev_train)\npredictions_app_bureau_prev = model_app_bureau_prev.predict_proba(x_app_bureau_prev_test)\n\nauc_app_bureau_prev = roc_auc_score(y_app_bureau_prev_test, predictions_app_bureau_prev[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv:', auc_app_bureau_prev)\n#previous_application_CODE_REJECT_REASON_XAP_mean                           -0.073930\n#previous_application_NAME_CONTRACT_STATUS_Approved_mean                    -0.063521\n#previous_application_NAME_CONTRACT_STATUS_Refused_mean                      0.077671\n#previous_application_NAME_CONTRACT_STATUS_Refused_sum                       0.064469\n#previous_application_CODE_REJECT_REASON_SCOFR_max                           0.063657\n#previous_application_NAME_PRODUCT_TYPE_walk-in_sum                          0.062628","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dda90ccdc9bb7d2723f3a7ee82330f025207149"},"cell_type":"markdown","source":"# ~.636 .. slightly better!\n\n# Now, add on POS_CASH_balance.csv:"},{"metadata":{"trusted":true,"_uuid":"8364eba32290dfbb76d2dcf9a3d3b671c67a2283"},"cell_type":"code","source":"x_cols_app_bureau_prev_pos = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum',\n    'POS_CASH_balance_MONTHS_BALANCE_min'\n]\n\nx_app_bureau_prev_pos = train[x_cols_app_bureau_prev_pos]\nx_app_bureau_prev_pos = imputer.fit_transform(x_app_bureau_prev_pos)\n\nx_app_bureau_prev_pos_train, x_app_bureau_prev_pos_test, y_app_bureau_prev_pos_train, y_app_bureau_prev_pos_test = train_test_split(x_app_bureau_prev_pos, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev_pos = RandomForestClassifier()\nmodel_app_bureau_prev_pos.fit(x_app_bureau_prev_pos_train, y_app_bureau_prev_pos_train)\npredictions_app_bureau_prev_pos = model_app_bureau_prev_pos.predict_proba(x_app_bureau_prev_pos_test)\n\nauc_app_bureau_prev_pos = roc_auc_score(y_app_bureau_prev_pos_test, predictions_app_bureau_prev_pos[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv + POS_CASH_balance.csv:', auc_app_bureau_prev_pos)\n#previous_application_CODE_REJECT_REASON_XAP_mean                           -0.073930\n#previous_application_NAME_CONTRACT_STATUS_Approved_mean                    -0.063521\n#previous_application_NAME_CONTRACT_STATUS_Refused_mean                      0.077671\n#previous_application_NAME_CONTRACT_STATUS_Refused_sum                       0.064469\n#previous_application_CODE_REJECT_REASON_SCOFR_max                           0.063657\n#previous_application_NAME_PRODUCT_TYPE_walk-in_sum                          0.062628","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3f20d30eb55e9b1d6ce689617d959028a27137c"},"cell_type":"markdown","source":"# ~.642!  Getting better.\n\n# Add on credit_card_balance.csv (score of .1 on .corr()!).. high hopes."},{"metadata":{"trusted":true,"_uuid":"6bd7b11630bcc51e5895d2f454545c2003fc4c7f"},"cell_type":"code","source":"x_cols_app_bureau_prev_pos_credit = [\n    'EXT_SOURCE_1', \n    'EXT_SOURCE_2', \n    'EXT_SOURCE_3', \n    'REGION_RATING_CLIENT_W_CITY', \n    'YEARS_BIRTH',\n    'YEARS_EMPLOYED',\n    'bureau_DAYS_CREDIT_mean',\n    'bureau_CREDIT_ACTIVE_Active_mean',\n    'bureau_DAYS_CREDIT_min',\n    'previous_application_CODE_REJECT_REASON_XAP_mean',                       \n    'previous_application_NAME_CONTRACT_STATUS_Approved_mean',                 \n    'previous_application_NAME_CONTRACT_STATUS_Refused_mean',                      \n    'previous_application_NAME_CONTRACT_STATUS_Refused_sum',                     \n    'previous_application_CODE_REJECT_REASON_SCOFR_max',                        \n    'previous_application_NAME_PRODUCT_TYPE_walk-in_sum',\n    'POS_CASH_balance_MONTHS_BALANCE_min',\n    'credit_card_balance_CNT_DRAWINGS_ATM_CURRENT_mean',\n    'credit_card_balance_CNT_DRAWINGS_CURRENT_max',\n    'credit_card_balance_AMT_BALANCE_mean',\n    'credit_card_balance_AMT_TOTAL_RECEIVABLE_mean'\n]\n\nx_app_bureau_prev_pos_credit = train[x_cols_app_bureau_prev_pos_credit]\nx_app_bureau_prev_pos_credit = imputer.fit_transform(x_app_bureau_prev_pos_credit)\n\nx_app_bureau_prev_pos_credit_train, x_app_bureau_prev_pos_credit_test, y_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_test = train_test_split(x_app_bureau_prev_pos_credit, y, test_size = 0.33, random_state = 0)\n\nmodel_app_bureau_prev_pos_credit = RandomForestClassifier()\nmodel_app_bureau_prev_pos_credit.fit(x_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_train)\npredictions_app_bureau_prev_pos_credit = model_app_bureau_prev_pos_credit.predict_proba(x_app_bureau_prev_pos_credit_test)\n\nauc_app_bureau_prev_pos_credit = roc_auc_score(y_app_bureau_prev_pos_credit_test, predictions_app_bureau_prev_pos_credit[:,1])\nprint('AUC: application_train.csv + bureau.csv + previous_application.csv + POS_CASH_balance.csv + credit_card_balance.csv:', auc_app_bureau_prev_pos_credit)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc183aeb2ff4faa570bfcb4f4266a2682a7644c6"},"cell_type":"markdown","source":"# Returns ~.646 -> Only a slight increase\n\n# Let's try out the lightGBM library because that is all the rage..\n\n"},{"metadata":{"trusted":true,"_uuid":"61fe45deae705a7c947eb126a5baef8186f7bc47"},"cell_type":"code","source":"import lightgbm as lgb\n\nx_app_bureau_prev_pos_credit_train, x_app_bureau_prev_pos_credit_test, y_app_bureau_prev_pos_credit_train, y_app_bureau_prev_pos_credit_test = train_test_split(x_app_bureau_prev_pos_credit, y, test_size = 0.33, random_state = 0)\n\nmodel = lgb.LGBMClassifier(\n    n_estimators=10000, \n    objective = 'binary', \n    class_weight = 'balanced', \n    learning_rate = 0.05, \n    reg_alpha = 0.1, \n    reg_lambda = 0.1, \n    subsample = 0.8, \n    n_jobs = -1, \n    random_state = 50\n)\n\nmodel.fit(\n    x_app_bureau_prev_pos_credit_train,\n    y_app_bureau_prev_pos_credit_train,\n    eval_metric = 'auc'\n)\n\np = model.predict_proba(x_app_bureau_prev_pos_credit_test)\n\nlightGBM_guinea = roc_auc_score(y_app_bureau_prev_pos_credit_test, p[:,1])\nprint('LGBM:', lightGBM_guinea)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"054282faf332e7a53ccb4549c0182fdd7b129edc"},"cell_type":"markdown","source":"# Now I see why .. score improved to .685!  Let's use this in submission"},{"metadata":{"trusted":true,"_uuid":"0389e7b896cf515a481e613a1a1dca8e09af104f"},"cell_type":"code","source":"test_submit = test[x_cols_app_bureau_prev_pos_credit]\ntest_submit = imputer.fit_transform(test_submit)\n\npredictions_final = model.predict_proba(test_submit)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b206233b5db49019eabeab3eeae76a9d32f846b4"},"cell_type":"markdown","source":"# Fire away! -> results in .642 score\n# Model is therefore somewhat overfit to train data.\n\n# Next: layer on any interesting features from bureau_balance.csv .. stay tuned!"},{"metadata":{"trusted":true,"_uuid":"1be37e3d03979deeaf7d06387c2afaa642390900"},"cell_type":"code","source":"submit = pd.DataFrame({\n    \"SK_ID_CURR\": test['SK_ID_CURR'],\n    \"TARGET\": predictions_final[:,1]\n})\n\nsubmit.to_csv('submit.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}