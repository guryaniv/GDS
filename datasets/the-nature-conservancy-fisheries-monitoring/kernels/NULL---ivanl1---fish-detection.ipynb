{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "832eb5b3-8268-bbf7-c144-4410220de130"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f803a3f1-eb26-b320-5122-7c36a5f2c0b9"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "from scipy import ndimage\n",
        "from subprocess import check_output\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a1df6090-90a7-4044-9956-d94fe87bf2af"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cfe401bd-5046-252b-0f98-d137903a7c37"
      },
      "outputs": [],
      "source": [
        "img_rows, img_cols= 350, 425\n",
        "im_array = cv2.imread('../input/train/LAG/img_00091.jpg',0)\n",
        "template = np.zeros([ img_rows, img_cols], dtype='uint8') # initialisation of the template\n",
        "template[:, :] = im_array[100:450,525:950] # I try multiple times to find the correct rectangle. \n",
        "#template /= 255.\n",
        "plt.subplots(figsize=(10, 7))\n",
        "plt.subplot(121),plt.imshow(template, cmap='gray') \n",
        "plt.subplot(122), plt.imshow(im_array, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b87a4db5-9ec4-e859-4d7f-7bb26dbec304"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad21751e-7352-68b1-3b5b-ae536a09da65"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_name = '../input/train/LAG/img_01512.jpg' # img_00176,img_02758, img_01512\n",
        "img = cv2.imread(file_name,0) \n",
        "img2 = img\n",
        "w, h = template.shape[::-1]\n",
        "\n",
        "# All the 6 methods for comparison in a list\n",
        "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
        "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
        "\n",
        "for meth in methods:\n",
        "     img = img2\n",
        "     method = eval(meth)\n",
        " \n",
        "     # Apply template Matching\n",
        "     res = cv2.matchTemplate(img,template,method)\n",
        "     min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        " \n",
        "     # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
        "     if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
        "         top_left = min_loc\n",
        "     else:\n",
        "         top_left = max_loc\n",
        "     bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        " \n",
        "     cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
        "     fig, ax = plt.subplots(figsize=(12, 7))\n",
        "     plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
        "     plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
        "     plt.subplot(122),plt.imshow(img,cmap = 'gray') #,aspect='auto'\n",
        "     plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
        "     plt.suptitle(meth)\n",
        " \n",
        "     plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cdb28fc4-9812-7140-dcc5-6c10375d94ea"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca22f7bc-31d5-05d3-3ecc-03c0fdc8f68d"
      },
      "outputs": [],
      "source": [
        "\n",
        "method = eval('cv2.TM_CCOEFF')\n",
        "indexes=[1,30,40,5]\n",
        "\n",
        "train_path = \"../input/train/\"\n",
        "sub_folders = check_output([\"ls\", train_path]).decode(\"utf8\").strip().split('\\n')\n",
        "for sub_folder in sub_folders:\n",
        "    file_names = check_output([\"ls\", train_path+sub_folder]).decode(\"utf8\").strip().split('\\n')\n",
        "    k=0\n",
        "    _, ax = plt.subplots(2,2,figsize=(10, 7))\n",
        "    for file_name in [file_names[x] for x in indexes]: # I take only 4 images of each group. \n",
        "        img = cv2.imread(train_path+sub_folder+\"/\"+file_name,0)\n",
        "        img2 = img\n",
        "        w, h = template.shape[::-1]\n",
        "        # Apply template Matching\n",
        "        res = cv2.matchTemplate(img,template,method)\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
        "        top_left = max_loc\n",
        "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
        " \n",
        "        cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
        "        if k==0 : \n",
        "            ax[0,0].imshow(img,cmap = 'gray')\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "        if k==1 : \n",
        "            ax[0,1].imshow(img,cmap = 'gray')\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "        if k==2 : \n",
        "            ax[1,0].imshow(img,cmap = 'gray')\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "        if k==3 : \n",
        "            ax[1,1].imshow(img,cmap = 'gray')\n",
        "            plt.xticks([]), plt.yticks([])\n",
        "        k=k+1\n",
        "    plt.suptitle(sub_folder)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b090d10d-2a93-3752-b00d-1f89cf0873ef"
      },
      "source": [
        "### Remark :\n",
        "As we can see, with a LAG template, we almost find all the LAG fish. This is good point. \n",
        "The other good point is that we don't find in our rectangle the other fish. Now the idea is to create the other template and do it for all the images. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "93c8629d-279b-2e33-e38b-a68d41050181"
      },
      "source": [
        "# Part 2\n",
        "\n",
        "### Soon.... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8cde9479-10e6-2d43-5d28-3b5bb65e90a8"
      },
      "source": [
        "\n",
        "On the same way, the goal is to detect the fish in an image. \n",
        "\n",
        "There exist a method to find Shapes in an image. ([*tutorial*](http://www.pyimagesearch.com/2014/10/20/finding-shapes-images-using-python-opencv/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17242af6-6dc8-4f1c-d65a-eb7080b3cecd"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}