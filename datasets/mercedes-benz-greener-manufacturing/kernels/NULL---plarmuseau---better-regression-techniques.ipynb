{"nbformat": 4, "nbformat_minor": 0, "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "version": "3.6.0"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"cell_type": "markdown", "execution_count": null, "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "ddea12fd3896a50ec379293c7606b7ed62e66777", "collapsed": false}, "source": "Regression takes the 'mean': the mean is not what we want here...\n----\nreading scikit i found some alternative regression techniques, they don't differ very much although in text you would think they are completely different.\n\n - **RANSAC** is good for strong outliers in the y direction\n - **TheilSen** is good for small outliers, both in direction X and y, but has a break point above which it performs worse than OLS.\n - The scores of  **HuberRegressor** may not be compared directly to both TheilSen and RANSAC because it does not attempt to completely filter the outliers but lessen their effect.\n\nThe 'important parameters'\n---\nI found these set simply by 'adding' eacht time one parameters and looking to the score changing and taking the most positive one, and redoing all regressions. Tooks two hours to find this set."}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "dfaeadf7e7657e70aadbc48a9dcba27e39315fff"}, "source": "import numpy as np\nimport xgboost as xgb\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression, TheilSenRegressor,RANSACRegressor,HuberRegressor\n\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntotal = train.append(test)\nestimators = [('OLS', LinearRegression()),\n              ('Theil-Sen', TheilSenRegressor(random_state=42)),\n              ('RANSAC', RANSACRegressor(random_state=42)),\n              ('HuberRegressor', HuberRegressor())]\nlw = 2\ncellen=['X'+str(w) for w in range(10,385) if str(w) not in ['25','72','121','149','188','193','303','381']]\ncellen=['X47','X95','X314','X315','X232','X119','X311','X76','X329','X238','X232','X340','X362','X119','X137']\nX_=train[cellen]\ny_=train['y']\nfor name, estimator in estimators:\n    estimator.fit(X_, y_)\n    print(name,estimator.score(X_,y_))\n    y_2=estimator.predict(X_)  \n    print(y_2)\n        \n    sub = pd.DataFrame()\n    sub['ID'] = test['ID']\n    sub['y'] = estimator.predict(test[cellen])\n    print(name,sub.T)\n    sub.to_csv('Ransac'+name+'.csv', index=False)\n"}]}