{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"version": "3.6.3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python", "name": "python"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "02adde30-2633-41f1-a672-af8ff83a1b02", "_uuid": "22754d0cc0847be93bf947c7998d7fb65a2817d7"}, "source": ["**Objective of the competition:**\n", "\n", "The competition dataset contains text from works of fiction written by spooky authors of the public domain: \n", " 1. Edgar Allan Poe (EAP)\n", " 2. HP Lovecraft (HPL)\n", " 3. Mary Wollstonecraft Shelley (MWS)\n", " \n", "The objective  is to accurately identify the author of the sentences in the test set.\n", "\n", "**Objective of the notebook:**\n", "\n", "In this notebook, we discover lime explorer package to understand the predictions and checking some examples with lime explainer package. Lime explainer is based on this research paper https://arxiv.org/abs/1602.04938 and supported by H2Oai. Lime explainer mission is to help human to understand decisions made by machine learning. Basically, lime explainer create a local linear model around the prediction and try to explain factor influence.\n", "\n", "You can download lime explainer here\n", "https://github.com/marcotcr/lime\n", "\n", "Lime: Explaining the predictions of any machine learning classifier.\n", "For the moment, lime explainer packages are not installed into docker python image. How to ask an docker image upgrage ? \n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "b31f62fb-bde8-410e-972c-3c092f22d497", "_uuid": "0fcdf81ce439d2215892af58f839edfc0ca80a91", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["import numpy as np\n", "import pandas as pd\n", "\n", "import matplotlib.pyplot as plt\n", "\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn import ensemble, metrics, model_selection, naive_bayes\n", "from sklearn.pipeline import make_pipeline\n", "\n", "from lime import lime_text\n", "from lime.lime_text import LimeTextExplainer\n", "import itertools  \n", "%matplotlib inline\n", "import warnings\n", "warnings.simplefilter('ignore')\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "dfed78e1-76c8-4042-8cb4-62d7b0c62c79", "_uuid": "a40aa2abe5e7f878b49fedcdb1a7fe9b0078483f", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["train_df = pd.read_csv(\"../input/train.csv\")\n", "test_df = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "3f69fb4e-c75b-4bc0-bc19-77a17c01e537", "_uuid": "5f7695a251ed13a94a88e7375fdd1ff50a1ec236"}, "source": ["# Explainer with basic model"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9608de00-cc2b-4397-8513-9c547378afe2", "_uuid": "bd0d5250163be5ca113227c26adb85c7442edc9f"}, "source": ["## Using explainer with tfdif vectorizer"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "45e4ac6f-6dfa-469d-b1e0-4d8a9071e05f", "_uuid": "25179c62732db71989de659503e8e47b7c13f3e6"}, "source": ["In this section, we implement a basic model based on naive bayes to show how to use Lime. For the example, we use tfidf vectorizer (it could be also countvectorizer)."]}, {"cell_type": "code", "metadata": {"_cell_guid": "338c2ee4-77cb-43f9-917e-f8ebbe7d6a6a", "_uuid": "a2556d493a9de8d971df88f0a7fd8d5a6f62c0cb", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["class_names = ['EAP', 'HPL', 'MWS']\n", "cols_to_drop = ['id', 'text']\n", "train_X = train_df.drop(cols_to_drop+['author'], axis=1)\n", "\n", "## Prepare the data for modeling ###\n", "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n", "train_y = train_df['author'].map(author_mapping_dict)\n", "train_id = train_df['id'].values\n"]}, {"cell_type": "code", "metadata": {"_cell_guid": "69a1d93f-fd34-46bb-a05f-6c11f2aa27a7", "_uuid": "d25f6139b753f93c0a1b59b5902779561ff77a64", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\n", "full_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n", "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())"]}, {"cell_type": "code", "metadata": {"_cell_guid": "56a736cd-bd79-4b20-a813-4ce69724f57b", "_uuid": "d9a30792adb9cd59e43f8aacb687d9d912648c95"}, "outputs": [], "execution_count": null, "source": ["X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, test_size=0.33, random_state=14)\n", "model_tf = naive_bayes.MultinomialNB()\n", "model_tf.fit(X_train, y_train)"]}, {"cell_type": "code", "metadata": {"_cell_guid": "b66b9f39-de04-40d9-9d04-723baaaa6dd3", "_uuid": "015324bf28cdb3c3ab185698d3fd8daafb7e41a2", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["def plot_confusion_matrix(cm, classes,\n", "                          normalize=False,\n", "                          title='Confusion matrix',\n", "                          cmap=plt.cm.Blues):\n", "    \"\"\"\n", "    This function prints and plots the confusion matrix.\n", "    Normalization can be applied by setting `normalize=True`.\n", "    \"\"\"\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "        print(\"Normalized confusion matrix\")\n", "    else:\n", "        print('Confusion matrix, without normalization')\n", "\n", "    print(cm)\n", "\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=45)\n", "    plt.yticks(tick_marks, classes)\n", "\n", "    fmt = '.2f' if normalize else 'd'\n", "    thresh = cm.max() / 2.\n", "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "        plt.text(j, i, format(cm[i, j], fmt),\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n", "\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')"]}, {"cell_type": "code", "metadata": {"_cell_guid": "5ab49bec-3340-4f1e-828d-fed90fbcb17a", "_uuid": "41d9c7914cf99b06345586ccf5cf5cb2afbc834d"}, "outputs": [], "execution_count": null, "source": ["y_pred = model_tf.predict(X_test)\n", "\n", "# Compute confusion matrix\n", "cnf_matrix = confusion_matrix(y_test, y_pred)\n", "np.set_printoptions(precision=2)\n", "\n", "# Plot non-normalized confusion matrix\n", "plt.figure()\n", "plot_confusion_matrix(cnf_matrix, classes=class_names,\n", "                      title='Confusion matrix, without normalization')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2b40c7d8-42c0-4c09-bb78-a4a377e59b1a", "_uuid": "61cf5985f2246f3da6feefe9e9578ab73d87905e"}, "source": ["# Preparing lime explainer"]}, {"cell_type": "code", "metadata": {"_cell_guid": "d0b0c432-a4d8-4aa6-a647-43fcad017813", "_uuid": "39f23f3f7c4fc60c8d39172d37bbe6b30975d1e3", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["c_tf = make_pipeline(tfidf_vec, model_tf)\n", "explainer_tf = LimeTextExplainer(class_names=class_names)"]}, {"cell_type": "code", "metadata": {"_cell_guid": "2e6aeeb7-5f66-4bf4-91bb-14f99d5e30c8", "_uuid": "9276bf6d4e994ab22829abd1dfaff9de56b841c1", "collapsed": true}, "outputs": [], "execution_count": null, "source": ["comp = y_test.to_frame()\n", "comp['idx'] = comp.index.values\n", "comp['pred'] = y_pred\n", "comp.rename(columns={'author': 'real'}, inplace=True)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c5138e41-d0f7-451a-82f4-8dad9ba5651e", "_uuid": "20caa4173039c78c88ab6e00d452d2f46cf3b0ab"}, "source": ["This is the comparison matrix showing predicted and real classes."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ec4b56c7-dd1e-48f0-aa75-c29363f9c990", "_uuid": "ede871b776583695856070a65eb7c368e7fcca0c"}, "source": ["# Explaining errors"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "bd999453-d2d0-4d99-9075-94db2b8f6928", "_uuid": "fe599d3f1e3f996829e91860bbcb825c1c1da5df"}, "source": ["## True POE but classified in HPL"]}, {"cell_type": "code", "metadata": {"_cell_guid": "5bcd77bb-d64b-424b-ad15-1c06ec431d40", "_uuid": "4df1a63bd15fa207862c075977d6ad4a1be113e0"}, "outputs": [], "execution_count": null, "source": ["wrong_poe_hpl = comp[(comp.real ==0) & (comp.pred ==1)]\n", "wrong_poe_hpl.shape\n", "print(wrong_poe_hpl.idx)\n", "idx = wrong_poe_hpl.idx.iloc[1]"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "33d8c0c0-4c25-4c0b-92f0-13a095abc925", "_uuid": "5bfd01e237e3aac133c50ee762a2de96d25776a7"}, "source": ["OK, we got 4 as shown by the confusion matrix above."]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "425959b0-0985-4ea4-af32-d2d4072259bc", "_uuid": "2ec866692194d689c238443b20d3bcf18e2f2d6c"}, "source": ["**Using Lime explainer.**"]}, {"cell_type": "code", "metadata": {"_cell_guid": "2c0bc9dc-a26d-4b82-ab31-c793baf3d6ca", "_uuid": "71af3aab9a7d4826c62bdd7817e48ed025536396"}, "outputs": [], "execution_count": null, "source": ["exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=2)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9e09ca3f-d809-4cf1-9b54-f3a3bb560132", "_uuid": "17bcbd2da817bfa0c6809949802bb8001acc2965"}, "source": ["**This error is created by the use of ancient greek words. Possible to improve the model ? **"]}, {"cell_type": "code", "metadata": {"_cell_guid": "6d8e9b24-f76d-44ea-b0e6-313c2f22812e", "_uuid": "941ff8e46f7baecfa121bb94a2bb5a3e48693592"}, "outputs": [], "execution_count": null, "source": ["idx = wrong_poe_hpl.idx.iloc[3]\n", "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=2)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "34ca22be-8f2d-40d2-93d3-86f92253308f", "_uuid": "42803ad38654a06c7df11a1292fda5ffc405f5c9"}, "source": ["**OK, very difficult case. Only three words > Not enough to properly classify. No improvement possible.**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7ff950ac-9c84-4921-ac8b-4146c5621bb6", "_uuid": "c3106c0c2ac1a748d1fdebe7aa0ea261d814e0fe"}, "source": ["# True POE but classified in MWS"]}, {"cell_type": "code", "metadata": {"_cell_guid": "7af0e1cf-48ac-4791-8a59-59f7b6b7a598", "_uuid": "4bdcc2b14dca1b6006270f275d51dbbac9edb0fb"}, "outputs": [], "execution_count": null, "source": ["wrong_poe_mws = comp[(comp.real ==0) & (comp.pred ==2)]\n", "print(wrong_poe_mws.shape)\n", "idx = wrong_poe_mws.idx.iloc[12]"]}, {"cell_type": "code", "metadata": {"_cell_guid": "4549ff55-7cfe-463f-90d0-7ed9ec31a040", "_uuid": "f63649cfd44732b75515f5f2bfdd95ed1691b592"}, "outputs": [], "execution_count": null, "source": ["exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a280df74-915a-4a94-8aef-ea8b3c378749", "_uuid": "ba58ff5965edd116eba01fbbe78c496ff050fec1"}, "source": ["**OK, this text contains anaphora, possible to improve the model with anaphora feature.**"]}, {"cell_type": "code", "metadata": {"_cell_guid": "3b9a6f8b-13e2-4972-b75b-643be16ce976", "_uuid": "63b8afc39989fae0324574fc0aee66405ce300b1"}, "outputs": [], "execution_count": null, "source": ["idx = wrong_poe_mws.idx.iloc[18]\n", "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "53e0abf0-cbef-40f2-a1f3-c4d07e047562", "_uuid": "1ce6bf195df6511ea16739b4d6e67882db12aedb"}, "source": ["**OK, probabilities (EAP and MWS) are very close. Possible to improve the model.**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9e89d235-1e75-408c-a0e1-4e3d0208826b", "_uuid": "5b85834833a47aea1ebfbb49c30165dd85dc6312"}, "source": ["# True MWS but classified in HPL"]}, {"cell_type": "code", "metadata": {"_cell_guid": "3b678712-de13-4924-b8e2-4e18744258d7", "_uuid": "31ddbbc392c978c1b0f5a79f26d8328e9c84b46d"}, "outputs": [], "execution_count": null, "source": ["wrong_mws_hpl = comp[(comp.real ==2) & (comp.pred ==1)]\n", "print(wrong_mws_hpl.shape)\n", "idx = wrong_mws_hpl.idx.iloc[8]"]}, {"cell_type": "code", "metadata": {"_cell_guid": "d2296f71-406d-4eb1-a02e-3e7501745a8a", "_uuid": "2a8f8f8353cf8cc3d78f0f3bf729d07321765795"}, "outputs": [], "execution_count": null, "source": ["exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a5ccbc33-52de-4cf0-b862-7fef62327d5c", "_uuid": "4623511c45c0bb49dd181afd941c77529deb00e9"}, "source": ["**OK, probabilities (HPL and MWS) are very close. Possible to improve the model.**"]}, {"cell_type": "code", "metadata": {"_cell_guid": "337753c3-da01-4871-9182-4f7fb75cc2d0", "_uuid": "afd5810cd7c82dd706bde2d9acc738473747b96e"}, "outputs": [], "execution_count": null, "source": ["idx = wrong_mws_hpl.idx.iloc[5]\n", "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n", "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "45404814-a361-4529-b47c-4e374fb56e15", "_uuid": "daf03f54f7c6ed95ce5ce576cfdcc70592b6dd71"}, "source": ["**OK, probabilities (EAP, HPL, MWS ) are all very close. Possible to improve the model (using repetition pattern ?).**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1dedaf5c-9c9b-4af3-9f69-3636376c6cc1", "_uuid": "6d753f6de3f0b29c9acbdc46ccb826334abe80f1"}, "source": ["# Conclusions and future steps"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "fcb5ac14-2655-473c-a3fb-1e22d62010f7", "_uuid": "a2eafe18ada2f94c6c907c37144dd39dc76cb96d"}, "source": ["It is easy with lime explorer to understand why the model is mistaken.\n", "Next steps are to extract bad features and creating new features to improve the model but it is a long and difficult work. \n", "**That's why I need your help ! **"]}, {"cell_type": "code", "metadata": {"_cell_guid": "83cce447-2c4f-44f0-8d51-1ddc6544b140", "_uuid": "8e1c674fd8efca5d7bb66e535f351465ff6e2512", "collapsed": true}, "outputs": [], "execution_count": null, "source": []}]}