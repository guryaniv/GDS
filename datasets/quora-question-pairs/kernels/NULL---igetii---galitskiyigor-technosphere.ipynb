{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53dd969a-93cb-268d-133b-06b15be551ec"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6325114f-96d6-2ceb-31a0-2ba9787669aa"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn import model_selection\n",
        "from sklearn import linear_model\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f05b349-e47a-a399-eaf8-0d111f883242"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv')\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d6e5e731-ffa8-5dff-68f2-f689765f548c"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('../input/test.csv')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b2ba0ea1-7a0a-c101-5a57-78924e2c573f"
      },
      "outputs": [],
      "source": [
        "# \u043a\u0440\u0443\u0442\u0430\u044f \u0448\u0442\u0443\u043a\u0430)) \u0441\u0430\u043c\u044b\u0435 \u043f\u043e\u043f\u0443\u043b\u044f\u0440\u043d\u044b\u0435 \u0441\u043b\u043e\u0432\u0430 \u0432 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0442\u0440\u0435\u0438\u043d\n",
        "\n",
        "train_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "cloud = WordCloud(width=1440, height=1080).generate(\" \".join(train_qs.astype(str)))\n",
        "plt.figure(figsize=(20, 15))\n",
        "plt.imshow(cloud)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0f7a9862-14c0-b523-5652-80b8cc0af2e8"
      },
      "source": [
        "\u0421\u0435\u043c\u0430\u043d\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u0439 \u0430\u043d\u0430\u043b\u0438\u0437"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee9615c7-5a29-367d-8f7e-39e73bb70088"
      },
      "outputs": [],
      "source": [
        "# \u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0430\u0437\u043b\u0438\u0447\u043d\u044b\u0445 \u0448\u0442\u0443\u043a \u0432 \u0442\u0435\u043a\u0441\u0442\u0435\n",
        "qmarks = np.mean(train_qs.apply(lambda x: '?' in x))\n",
        "math = np.mean(train_qs.apply(lambda x: '[math]' in x))\n",
        "fullstop = np.mean(train_qs.apply(lambda x: '.' in x))\n",
        "capital_first = np.mean(train_qs.apply(lambda x: x[0].isupper()))\n",
        "capitals = np.mean(train_qs.apply(lambda x: max([y.isupper() for y in x])))\n",
        "numbers = np.mean(train_qs.apply(lambda x: max([y.isdigit() for y in x])))\n",
        "\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u0441 \u0432\u043e\u043f\u0440\u043e\u0441\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u043c \u0437\u043d\u0430\u043a\u043e\u043c: {:.2f}%'.format(qmarks * 100))\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u043f\u0440\u043e \u043c\u0430\u0442\u0435\u043c\u0430\u0442\u0438\u043a\u0443: {:.2f}%'.format(math * 100))\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u0441 \u0442\u043e\u0447\u043a\u0430\u043c\u0438: {:.2f}%'.format(fullstop * 100))\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043f\u0435\u0440\u0432\u0430\u044f \u0431\u0443\u043a\u0432\u0430 \u0437\u0430\u0433\u043b\u0430\u0432\u043d\u0430\u044f: {:.2f}%'.format(capital_first * 100))\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u0441 \u0437\u0430\u0433\u043b\u0430\u0432\u043d\u044b\u043c\u0438 \u0431\u0443\u043a\u0432\u0430\u043c\u0438: {:.2f}%'.format(capitals * 100))\n",
        "print('\u0412\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u0441 \u0446\u0438\u0444\u0438\u0440\u043a\u0430\u043c\u0438: {:.2f}%'.format(numbers * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "34b1dc29-a79c-95cb-3b7c-614036cbb606"
      },
      "source": [
        "\u041e\u0447\u0435\u043d\u044c \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u043e, \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0432 \u043f\u0440\u0438\u0433\u043e\u0434\u0438\u0442\u0441\u044f \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u043c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "354569a5-0fde-3be9-6341-63fd1cc11580"
      },
      "outputs": [],
      "source": [
        "# \u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043e\u0431\u0449\u0438\u0445 \u0441\u043b\u043e\u0432 \u0432 \u0432\u043e\u043f\u0440\u043e\u0441\u0430\u0445 \u0438 \u043a\u0430\u043a \u043e\u0442 \u044d\u0442\u043e\u0433\u043e \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u0438\u0445 \u043f\u043e\u0445\u043e\u0436\u0435\u0441\u0442\u044c\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "def word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "         # \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u043b \u043a\u043e\u043c\u043f\u0443\u0442\u0435\u0440\n",
        "        return 0\n",
        "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
        "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
        "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
        "    return R\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "train_word_match = df_train.apply(word_match_share, axis=1, raw=True)\n",
        "plt.hist(train_word_match[df_train['is_duplicate'] == 0], bins=20, normed=True, label='Not Duplicate')\n",
        "plt.hist(train_word_match[df_train['is_duplicate'] == 1], bins=20, normed=True, alpha=0.7, label='Duplicate')\n",
        "plt.legend()\n",
        "plt.title('Label distribution over word_match_share', fontsize=15)\n",
        "plt.xlabel('word_match_share', fontsize=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "66d0bb05-872e-653a-1234-af1bb37eef91"
      },
      "source": [
        "\u041e\u0447\u0435\u043d\u044c \u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u0430\u044f \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c, \u043f\u043e \u043d\u0435\u0439 \u043c\u043e\u0436\u043d\u043e \u0443\u0432\u0438\u0434\u0435\u0442\u044c \u0447\u0442\u043e \u0435\u0441\u043b\u0438 \u043e\u0431\u0449\u0438\u0445 \u0441\u043b\u043e\u0432 \u043f\u043e\u0447\u0442\u0438 \u043d\u0435\u0442 - \u0442\u043e \u043f\u0440\u0435\u0434\u043b\u043e\u0436\u0435\u043d\u0438\u044f \u0442\u043e\u0447\u043d\u043e \u043d\u0435 \u043f\u043e\u0445\u043e\u0436\u0438, \u0430 \u0432\u043e\u0442 \u0435\u0441\u043b\u0438 \u0434\u0430\u0436\u0435 \u043c\u043d\u043e\u0433\u043e \u043e\u0431\u0449\u0438\u0445 \u0441\u043b\u043e\u0432 - \u0442\u043e \u043d\u0435 \u0444\u0430\u043a\u0442 \u0447\u0442\u043e \u043f\u043e\u0445\u043e\u0436\u0438"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d86a1ff0-5560-3276-4d88-e59511526994"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.dropna(how=\"any\").reset_index(drop=True)\n",
        "\n",
        "featureExtractionStartTime = time.time()\n",
        "maxNumFeatures = 300\n",
        "\n",
        "# bag of letter sequences (chars)\n",
        "BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=maxNumFeatures, \n",
        "                                      analyzer='char', ngram_range=(1,2), \n",
        "                                      binary=True, lowercase=True)\n",
        "# bag of words\n",
        "#BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=10, max_features=maxNumFeatures, \n",
        "#                                      analyzer='word', ngram_range=(1,6), stop_words='english', \n",
        "#                                      binary=True, lowercase=True)\n",
        "\n",
        "BagOfWordsExtractor.fit(pd.concat((df_train.ix[:,'question1'],df_train.ix[:,'question2'])).unique())\n",
        "\n",
        "trainQuestion1_BOW_rep = BagOfWordsExtractor.transform(df_train.ix[:,'question1'])\n",
        "trainQuestion2_BOW_rep = BagOfWordsExtractor.transform(df_train.ix[:,'question2'])\n",
        "lables = np.array(df_train.ix[:,'is_duplicate'])\n",
        "\n",
        "featureExtractionDurationInMinutes = (time.time()-featureExtractionStartTime)/60.0\n",
        "print(\"feature extraction took %.2f minutes\" % (featureExtractionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "09a4d072-14cf-39ba-ff85-e4b9c9b27592"
      },
      "source": [
        "\u041f\u0440\u043e\u0432\u0435\u0440\u0438\u043b \u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044e \u043f\u043e \u0441\u0438\u043c\u0432\u043e\u043b\u0430\u043c \u0438 \u0441\u043b\u043e\u0432\u0430\u043c, \u043f\u043e \u0441\u0438\u043c\u0432\u043e\u043b\u0430\u043c \u043d\u0430\u043c\u043d\u043e\u0433\u043e \u043b\u0443\u0447\u0448\u0435)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aabcd947-964d-08ef-16d3-a775a777d01c"
      },
      "outputs": [],
      "source": [
        "# \u043a\u0440\u043e\u0441\u0441 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f\n",
        "crossValidationStartTime = time.time()\n",
        "\n",
        "numCVSplits = 8\n",
        "numSplitsToBreakAfter = 2\n",
        "\n",
        "X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int)\n",
        "#X = -(trainQuestion1_BOW_rep != trainQuestion2_BOW_rep).astype(int) + \\\n",
        "#      trainQuestion1_BOW_rep.multiply(trainQuestion2_BOW_rep)\n",
        "y = lables\n",
        "\n",
        "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag')\n",
        "\n",
        "logRegAccuracy = []\n",
        "logRegLogLoss = []\n",
        "logRegAUC = []\n",
        "\n",
        "print('---------------------------------------------')\n",
        "stratifiedCV = model_selection.StratifiedKFold(n_splits=numCVSplits, random_state=2)\n",
        "for k, (trainInds, validInds) in enumerate(stratifiedCV.split(X, y)):\n",
        "    foldTrainingStartTime = time.time()\n",
        "\n",
        "    X_train_cv = X[trainInds,:]\n",
        "    X_valid_cv = X[validInds,:]\n",
        "\n",
        "    y_train_cv = y[trainInds]\n",
        "    y_valid_cv = y[validInds]\n",
        "\n",
        "    logisticRegressor.fit(X_train_cv, y_train_cv)\n",
        "\n",
        "    y_train_hat =  logisticRegressor.predict_proba(X_train_cv)[:,1]\n",
        "    y_valid_hat =  logisticRegressor.predict_proba(X_valid_cv)[:,1]\n",
        "\n",
        "    logRegAccuracy.append(accuracy_score(y_valid_cv, y_valid_hat > 0.5))\n",
        "    logRegLogLoss.append(log_loss(y_valid_cv, y_valid_hat))\n",
        "    logRegAUC.append(roc_auc_score(y_valid_cv, y_valid_hat))\n",
        "    \n",
        "    foldTrainingDurationInMinutes = (time.time()-foldTrainingStartTime)/60.0\n",
        "    print('fold %d took %.2f minutes: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (k+1,\n",
        "             foldTrainingDurationInMinutes, logRegAccuracy[-1],logRegLogLoss[-1],logRegAUC[-1]))\n",
        "\n",
        "    if (k+1) >= numSplitsToBreakAfter:\n",
        "        break\n",
        "\n",
        "\n",
        "crossValidationDurationInMinutes = (time.time()-crossValidationStartTime)/60.0\n",
        "\n",
        "print('---------------------------------------------')\n",
        "print('cross validation took %.2f minutes' % (crossValidationDurationInMinutes))\n",
        "print('mean CV: accuracy = %.3f, log loss = %.4f, AUC = %.3f' % (np.array(logRegAccuracy).mean(),\n",
        "                                                                 np.array(logRegLogLoss).mean(),\n",
        "                                                                 np.array(logRegAUC).mean()))\n",
        "print('---------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c613d3e5-68e3-cfd0-35a1-7f2a3a2f3a26"
      },
      "outputs": [],
      "source": [
        "# \u0442\u0440\u0435\u043d\u0435\u0440\u0443\u0435\u043c\u0441\u044f \u043d\u0430 \u043f\u043e\u043b\u043d\u043e\u043c \u043d\u0430\u0431\u043e\u0440\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\n",
        "\n",
        "trainingStartTime = time.time()\n",
        "\n",
        "logisticRegressor = linear_model.LogisticRegression(C=0.1, solver='sag', \n",
        "                                                    class_weight={1: 0.46, 0: 1.32})\n",
        "\n",
        "# \u0421\u0442\u043e\u0438\u0442 \u0437\u0430\u043c\u0435\u0442\u0438\u0442\u044c: class_weight \u043f\u0440\u0438\u043d\u0438\u043c\u0430\u0435\u0442 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f {0.46, 1.32}.\n",
        "# \u041e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f, \u0447\u0442\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u043e\u043a \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435 \u0438 \u0442\u0435\u0441\u0442\u0435 \u0440\u0430\u0437\u043d\u043e\u0435, \u0442\u043e \u0435\u0441\u0442\u044c \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043c\u0435\u0442\u043e\u043a \u043d\u0430 \u0442\u0435\u0441\u0442\u0435 \u043f\u0440\u043e\u0441\u0442\u043e \u0441\u043a\u043e\u0448\u0435\u043d\u043e.\n",
        "    \n",
        "\n",
        "logisticRegressor.fit(X, y)\n",
        "\n",
        "trainingDurationInMinutes = (time.time()-trainingStartTime)/60.0\n",
        "print('full training took %.2f minutes' % (trainingDurationInMinutes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd099799-075c-c2e8-1e18-e9f10b595e9d"
      },
      "outputs": [],
      "source": [
        "# \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u0441 \u043f\u043e\u043b\u043d\u043e\u0439 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0435\u0439\n",
        "\n",
        "testPredictionStartTime = time.time()\n",
        "\n",
        "\n",
        "df_test.ix[df_test['question1'].isnull(),['question1','question2']] = 'random empty question'\n",
        "df_test.ix[df_test['question2'].isnull(),['question1','question2']] = 'random empty question'\n",
        "\n",
        "testQuestion1_BOW_rep = BagOfWordsExtractor.transform(df_test.ix[:,'question1'])\n",
        "testQuestion2_BOW_rep = BagOfWordsExtractor.transform(df_test.ix[:,'question2'])\n",
        "\n",
        "X_test = -(testQuestion1_BOW_rep != testQuestion2_BOW_rep).astype(int)\n",
        "\n",
        "#  \u0434\u043b\u044f \u0438\u0437\u0431\u0435\u0436\u0430\u043d\u0438\u044f \u043e\u0448\u0438\u0431\u043a\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u043e\u0439 \u0441 \u043f\u0430\u043c\u044f\u0442\u044c\u044e\n",
        "seperators= [750000,1500000]\n",
        "testPredictions1 = logisticRegressor.predict_proba(X_test[:seperators[0],:])[:,1]\n",
        "testPredictions2 = logisticRegressor.predict_proba(X_test[seperators[0]:seperators[1],:])[:,1]\n",
        "testPredictions3 = logisticRegressor.predict_proba(X_test[seperators[1]:,:])[:,1]\n",
        "testPredictions = np.hstack((testPredictions1,testPredictions2,testPredictions3))\n",
        "\n",
        "\n",
        "testPredictionDurationInMinutes = (time.time()-testPredictionStartTime)/60.0\n",
        "print('predicting on test took %.2f minutes' % (testPredictionDurationInMinutes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9785b726-1933-84fd-ba70-61074208ea56"
      },
      "outputs": [],
      "source": [
        "# \u0441\u043e\u0437\u0434\u0430\u0435\u043c submission\n",
        "\n",
        "submissionName = 'GalitskiyIgor[Technosphere]'\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['test_id'] = df_test['test_id']\n",
        "submission['is_duplicate'] = testPredictions\n",
        "submission.to_csv(submissionName + '.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f46eee81-745e-bb20-9974-c08dc285bee1"
      },
      "source": [
        "\u0412 \u0438\u0442\u043e\u0433\u0435 \u043e\u0442 \u0442\u043e\u0433\u043e \u043a\u0430\u043a\u0438\u0435 \u043c\u044b \u0437\u0430\u0434\u0430\u0434\u0438\u043c \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438:\n",
        " \n",
        "\n",
        " - max_features\n",
        " - min_df\n",
        " - ngram_range\n",
        "\n",
        "\u0431\u0443\u0434\u0435\u0442 \u0437\u0430\u0432\u0438\u0441\u0435\u0442\u044c \u043d\u0430\u0448 score , \u0447\u0435\u043c \u0431\u043e\u043b\u044c\u0448\u0435 - \u0442\u0435\u043c \u043b\u0443\u0447\u0448\u0435.\n",
        "\u0421 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430\u043c\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0441\u0442\u043e\u044f\u0442 \u0441\u0435\u0439\u0447\u0430\u0441 \u0432\u044b\u0434\u0430\u0435\u0442 0.38773"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d619a4e-eba2-f69e-c9bb-515bd728f722"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}