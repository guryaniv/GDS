{"cells":[{"metadata":{"_uuid":"09815266cf018fa87f9d9a0356a99f8a8c22fd43"},"cell_type":"markdown","source":"# Kernel zur Lösung der MNIST Competition unter Zuhilfenahme der Macht der Convolutional Neural Networks."},{"metadata":{"_uuid":"519b8b16af3e6831f9cfa143000fe33502d69fe9"},"cell_type":"markdown","source":"Zuerst werden die notwendigen Importe importiert."},{"metadata":{"trusted":true,"_uuid":"7e8785f905fa9653642bfe32f457e5e2e69979ef"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, Dropout, MaxPooling2D, Dense, Flatten, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.optimizers import Adam\n\nfrom sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0308007ba5850d3887e549172b79193592f67d9"},"cell_type":"markdown","source":"Wir definieren ein paar wichtige Parameter, um sie einfacher ändern zu können."},{"metadata":{"trusted":true,"_uuid":"29c0ad753c7e37c13e3b2bc49f1569a60ab01235"},"cell_type":"code","source":"batch_size = 64\nepochs = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdb184c96463b019bfed8c5b5bc6c98d7274c10f"},"cell_type":"markdown","source":"Die Trainingsdaten und Testdaten werden aus dem Input-Verzeichnis importiert."},{"metadata":{"trusted":true,"_uuid":"5b823c1bc1e6574a6a43c76336ef6a3dbb02d034"},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2a4e27cf8e5cca78a6ddec218cb46a285e0a9de"},"cell_type":"markdown","source":"Um die Daten nutzen zu können, müssen sie noch vorbereitet werden.\n\nIm ersten Abschnitt werden aus den eingelesenen CSV-Dateien die benötigten Felder extrahiert. Konkret werden als Y-Daten die Labels der Grafiken extrahiert und als X-Daten die restlichen Spalten, also die rohen Pixeldaten.\n\nUm schon im Trainingsprozess die Ergebnisse evaluieren zu können, werden 10% der Trainingssätze abgespalten.\n\nAnschließend werden die X-Daten normalisiert, da Neuronale Netze eher zufriedenstellende Ergebnisse liefern, als wenn die Daten eine zu große Dynamic aufweisen.\n\nDa die Daten Zweidimensionale Bilder repräsentatieren, formen wir sie an dieser Stelle wieder in 28x28 Pixel große Tensoren um. Zusätzlich fügen wir eine weitere Dimension hinzu, da Keras noch eine weitere Dimension für die Channel erwartet. Da wir nur Graustufen Bilder haben, benötigen wir nur einen Channel.\n\nDie Y-Daten werden zur Verwendung in Neuronalen Netzen als One-Hot kodiert."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"train_x_data = (train_data.iloc[:,1:].values).astype('float32')\ntrain_y_data = (train_data.iloc[:,0].values).astype('float32')\ntest_x_data = (test_data.values).astype('float32')\n\nprint('Split 10% of the data for evaluatio')\ntrain_x_data, eval_x_data, train_y_data, eval_y_data = train_test_split(train_x_data, train_y_data, test_size=0.1)\n\nprint('Normalization')\ntrain_x_data, eval_x_data, test_x_data = map(lambda data: data / 255, [train_x_data, eval_x_data, test_x_data])\n\nprint('Reshapig X_data')\ntrain_x_data, eval_x_data, test_x_data = map(lambda data: data.reshape(data.shape[0], 28, 28, 1), [train_x_data, eval_x_data, test_x_data])\n\nprint('Reshaping Y_data')\ntrain_y_data, eval_y_data = map(to_categorical, [train_y_data, eval_y_data])\n\ndel train_data, test_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a66d01865f223e6990d96165e5dd74d168889177"},"cell_type":"markdown","source":"Visualisierung einzelner Bilder zur Veranschaulichung."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\n\n#for i in range(330, 340):\n#    plt.subplot(330 + (i+1))\n#    plt.imshow(train_x_data[i], cmap=plt.get_cmap('gray'))\n#\n#    plt.title(train_y_data[i])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a99921def936ca86126569dbdbfc42f01784875a"},"cell_type":"markdown","source":"Um dem Modell die Möglichkeit zu geben, besser zu generalisieren, arbeiten wir mit Data-Augmention um dem Netz verschiedene Bilder anzubieten.\nMithilfe des DataGenerators wird auf jedes Bild eine zufällige Transformation angewandt."},{"metadata":{"trusted":true,"_uuid":"d231b0b2118c36419ed11910a4d299bbc68a816f"},"cell_type":"code","source":"dataGenerator = ImageDataGenerator(\n    featurewise_center=False,  \n    samplewise_center=False, \n    featurewise_std_normalization=False, \n    samplewise_std_normalization=False,\n    zca_whitening=False, \n    rotation_range=10, \n    zoom_range = 0.1, \n    shear_range = 0.1,\n    width_shift_range=0.1,  \n    height_shift_range=0.1,\n    horizontal_flip=False,\n    vertical_flip=False\n)\n\ndataGenerator.fit(train_x_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"249c1ab3889656890b06aaa2ae8d5714f41a90e6"},"cell_type":"markdown","source":"Das eigentliche Modell wird mithilfe der Keras-Sequential API definiert.\n\nEs besteht aus insgesamt 3 Convolutional-Schichten, jede aus mehreren hintereinander geschalteten Filtern.\nNach den ersten beiden Schichten werden, werden die Daten mithilfe eines MaxPooling Layers etwas ausgedünnt und anschließend eine Dropout Schicht hinzugefügt, um dem Modell helfen besser zu generalisieren und Overfitting zu vermeiden. \nZusätzlich wird nach jedem Filter eine BatchNormalization durchgeführt.\n\nAm Ende wird, wie in jedem CNN üblich, eine Fully Connected Schicht eingefügt.\n\nAls Optimizert wird der Adam-optimizer verwendet."},{"metadata":{"trusted":true,"_uuid":"a7c982760cb28d3958302d42eb0dae5cfc211466"},"cell_type":"code","source":"\nmodel = Sequential()\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=(2, 2), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\n#model.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22952ad0d9b45573a653a1b168afb6024482bb50"},"cell_type":"markdown","source":"An dieser Stelle wird das eigentliche Training ausgeführt. Die Daten werden durch den DataGenerator geschickt, um die oben beschriebenen Transformationen anzuwenden, anstatt die Originalen Daten zu verwenden. "},{"metadata":{"trusted":true,"_uuid":"fb59950ff814d30f0b8b497db22f416339135cf2","scrolled":false},"cell_type":"code","source":"history = model.fit_generator(\n    dataGenerator.flow(train_x_data, train_y_data, batch_size=batch_size),\n    validation_data=(eval_x_data, eval_y_data),\n    epochs=epochs,\n    steps_per_epoch=len(train_x_data)/batch_size\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55c95eb85c91f207e1784409c1284514dbf8f653"},"cell_type":"markdown","source":"Wir plotten hier kurz die Accuracy der Trainingsdaten und der Validierungsdaten, um sicherzustellen, dass das Modell nicht overfittet und um die allgemeine Performance zu verdeutlichen."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9d58db14ae82f8b42036ba8853d5eaa05df510ce"},"cell_type":"code","source":"plt.plot(history.history['acc'], label='Acc')\nplt.plot(history.history['val_acc'], label='Val_Acc')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac2e311dea282cce089867a4bc7978aa6aa91752"},"cell_type":"markdown","source":"Hier werden die Testdaten durch das Netz geschickt um die hoffentlich korrekten Labels zu den Testdaten zu ermitteln."},{"metadata":{"trusted":true,"_uuid":"b105d4054fa9df877cd09f7097233bbe060703da"},"cell_type":"code","source":"\nresults = model.predict(test_x_data)\n\nresults = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97bcf0329f19ca5164ff118b12bc0461f11ce9ba"},"cell_type":"markdown","source":"Die Ergebnisse müssen jetzt noch mit Pandas in eine CSV Datei geschrieben werden, um eine Submission zu ermöglichen."},{"metadata":{"trusted":true,"_uuid":"d3c0395518cb6870ad62c05fc78b1abffe3822c3"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1, 28001), name='ImageId'), results], axis=1)\nsubmission.to_csv('output.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a00a800d40b50254b97a0357f6263f395ca9c6e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}