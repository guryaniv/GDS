{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"file_extension": ".py", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python"}}, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "8c468818-6a8f-a034-61ad-cb895d7ebe94", "_uuid": "53d807f7122da054951a0ac3503553c302b42a36", "collapsed": true, "_execution_state": "idle"}, "cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": []}, {"metadata": {"_cell_guid": "479ec2cd-a87e-4546-8450-f92e5f03b6f4", "_uuid": "48491652d33bf8a37ec3f9465fb4afdd2d410477", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["import matplotlib.pyplot as plt\n", "import re as re\n", "import pandas as pd\n", "import numpy as np\n", "from scipy.stats import norm\n", "import os as os\n", "from sklearn import preprocessing\n", "from collections import OrderedDict\n", "from sklearn.datasets import make_classification\n", "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"], "outputs": []}, {"metadata": {"_cell_guid": "6727f295-8364-4a22-a884-4573541f1903", "_uuid": "99057438577e35741399c02e1b0d95e7adf0da6d", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["# Data cleanup\n", "# TRAIN DATA\n", "train_set = pd.read_csv('../input/train.csv')\n", "test_set = pd.read_csv('../input/test.csv')\n", "train = pd.read_csv('../input/train.csv', dtype={\"Age\": np.float64}, )\n", "test = pd.read_csv('../input/train.csv', dtype={\"Age\": np.float64}, )\n", "le = preprocessing.LabelEncoder()\n", "\n", "\n", "def get_title(name):\n", "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n", "    # If the title exists, extract and return it.\n", "    if title_search:\n", "        return title_search.group(1)\n", "    return \"\"\n", "\n", "\n", "def get_lastname(name):\n", "    title_search = re.search('(?:Mrs\\.|Major\\.|Mr\\.|Miss\\.|Master\\.|Dr\\.|Lady\\.|Countess\\.|Don\\.|Rev\\.|'\n", "                             'Jonkheer\\.|Dona\\.|Mme\\.) (\\(([A-Za-z0-9_]+)\\)|[a-zA-Z]+)', name)\n", "\n", "    # If the title exists, extract and return it.\n", "    if title_search:\n", "        final_result = re.sub('(?:Mr\\.|Major\\.|Mrs\\.|Miss\\.|Master\\.|Dr\\.|Lady\\.|Countess\\.|Don\\.|'\n", "                              'Rev\\.|Jonkheer\\.|Dona\\.|Mme\\.| )', '', title_search.group(0))\n", "        return final_result\n", "    return \"\"\n", "\n", "\n", "def df_freq_table(df, var):\n", "    df_freq = pd.value_counts(df[var]).to_frame().reset_index()\n", "    df_freq.columns = [var, 'Count']\n", "    return df_freq\n", "\n", "\n", "def my_func(b):\n", "    return max(0, b)\n", "\n", "vmy_func = np.vectorize(my_func)\n", "\n", "train['data_label'] = 'train'\n", "test['data_label'] = 'test'\n", "test['Survived'] = -1\n", "\n", "all_data = train.append(test)\n", "\n", "all_age = all_data['Age'].loc[~pd.isnull(all_data['Age'])]\n", "mu, std = norm.fit(all_age)\n", "\n", "all_names = all_data.loc[~pd.isnull(all_data['Name']), ['PassengerId', 'Name']]\n", "all_names['LastName'] = ''\n", "all_names.loc[:, 'LastName'] = all_names.loc[:, 'Name'].apply(get_lastname)\n", "all_names.loc[all_names['LastName'] == '', 'LastName'] = 'MISC'\n", "lastname_df = df_freq_table(all_names, 'LastName')\n", "lastname_dict = lastname_df.set_index('LastName')['Count'].to_dict()\n", "\n", "SEED = 0\n", "np.random.seed(5)\n", "full_data = [train, test]\n", "\n", "\n", "def get_cabin_type(cabin):\n", "    if pd.isnull(cabin):\n", "        return 'Z'\n", "    else:\n", "        letter_list = \" \".join(re.findall(\"[a-zA-Z]+\", cabin))\n", "        unique_cabin_letter = list(set(letter_list))\n", "        unique_cabin_letter = [x for x in unique_cabin_letter if x != ' ']\n", "        if unique_cabin_letter.__len__() != 1:\n", "            unique_cabin_letter.sort()\n", "            print('multiple cabin for one passenger, only keeps the higher cabin')\n", "            return unique_cabin_letter[0]\n", "        else:\n", "            return unique_cabin_letter[0]\n", "\n", "# recode cabin type\n", "all_data['Cabin_type'] = all_data['Cabin'].apply(get_cabin_type)\n", "all_data['Cabin_type'] = all_data['Cabin_type'].map(lambda x: ord(x) - 64 if x.isalpha() else x)\n", "\n", "flag_P1_NA = ((all_data['Cabin_type'] == 26) & (all_data['Pclass'] == 1))\n", "P1_NA_Size = pd.value_counts(all_data['Cabin_type'].loc[flag_P1_NA]).values\n", "all_data.loc[flag_P1_NA, 'Cabin_type'] = np.random.randint(0, 5, P1_NA_Size)\n", "\n", "# Create Family Size\n", "all_data['FamilySize'] = all_data['SibSp'] + all_data['Parch'] + 1\n", "\n", "# Create Flag isalone\n", "all_data['IsAlone'] = 0\n", "all_data.loc[all_data['FamilySize'] == 1, 'IsAlone'] = 1\n", "\n", "# filling empty embarked\n", "all_data['Embarked'] = all_data['Embarked'].fillna('S')\n", "\n", "# filling empty Fare\n", "all_data['Fare'] = all_data['Fare'].fillna(all_data['Fare'].median())\n", "\n", "#  ID\n", "all_data['Title'] = ''\n", "all_data.loc[:, 'Title'] = all_data['Name'].apply(get_title)\n", "all_data['LastName'] = \"\"\n", "all_data.loc[:, 'LastName'] = all_data.loc[:, 'Name'].apply(get_lastname)\n", "all_data.loc[all_data['LastName'] == '', 'LastName'] = 'MISC'\n", "all_data['LastNameFreq'] = all_data['LastName'].map(lastname_dict)\n", "all_data['FamilyID'] = ''\n", "all_data.loc[:, 'FamilyID'] = all_data.apply(lambda row: (str(row['FamilySize']) + row['LastName']), axis=1)\n", "all_data.loc[all_data['FamilySize'] < 3, 'FamilyID'] = 'Small'\n", "le.fit(all_data['FamilyID'].values)\n", "all_data.loc[:, 'FamilyID_Code'] = le.transform(all_data['FamilyID'].values)\n", "\n", "# mapping tile to code\n", "all_data['Title'] = all_data['Title'].replace(\n", "    ['Lady', 'Countess', 'Don', 'Dr', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Noble')\n", "all_data['Title'] = all_data['Title'].replace(\n", "    ['Capt', 'Col', 'Major'], 'Military')\n", "all_data['Title'] = all_data['Title'].replace('Mlle', 'Miss')\n", "all_data['Title'] = all_data['Title'].replace('Ms', 'Miss')\n", "all_data['Title'] = all_data['Title'].replace('Mme', 'Mrs')\n", "all_data.loc[(np.isnan(all_data['Age'])) & (all_data['Title'] == 'Master'), 'Age'] = 8\n", "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 6, \"Military\": 5, \"Noble\": 4}\n", "all_data['Title'] = all_data['Title'].map(title_mapping)\n", "all_data['Title'] = all_data['Title'].fillna(0)\n", "\n", "# code Gender\n", "all_data['Sex'] = all_data['Sex'].map({'female': 0, 'male': 1}).astype(int)\n", "\n", "# Mapping Embarked\n", "all_data['Embarked'] = all_data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n", "\n", "# Mapping Fare\n", "all_data.loc[all_data['Fare'] <= 7.91, 'Fare'] = 0\n", "all_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1\n", "all_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare'] = 2\n", "all_data.loc[all_data['Fare'] > 31, 'Fare'] = 3\n", "all_data['Fare'] = all_data['Fare'].astype(int)\n", "\n", "# Mapping Age\n", "age_null_count = all_data['Age'].isnull().sum()\n", "#age_null_random_list = vmy_func(np.random.normal(mu, std, age_null_count))\n", "age_null_random_list = np.random.randint(mu - std, mu + std, size=age_null_count)\n", "all_data.loc[np.isnan(all_data['Age']), 'Age'] = age_null_random_list\n", "all_data['Age'] = all_data['Age'].astype(int)\n", "all_data.loc[all_data['Age'] <= 16, 'Age'] = 0\n", "all_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 24), 'Age'] = 1\n", "all_data.loc[(all_data['Age'] > 24) & (all_data['Age'] <= 28), 'Age'] = 2\n", "all_data.loc[(all_data['Age'] > 28) & (all_data['Age'] <= 32), 'Age'] = 3\n", "all_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 4\n", "all_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 5\n", "all_data.loc[all_data['Age'] > 64, 'Age'] = 6\n", "\n", "# save all output to file\n", "test_clean = all_data.loc[all_data['data_label'] == 'test', :]\n", "train_clean = all_data.loc[all_data['data_label'] == 'train', :]\n", "\n", "#var_drop_list = ['LastNameFreq', 'LastName', 'IsAlone', 'FamilyID', 'Embarked', 'Parch']\n", "var_drop_list = ['LastName', 'FamilyID']\n", "test_clean = test_clean.drop(['data_label', 'Survived', 'Name', 'Ticket', 'Cabin'] + var_drop_list, axis=1)\n", "train_clean = train_clean.drop(['data_label', 'Name', 'Ticket', 'Cabin'] + var_drop_list, axis=1)"], "outputs": []}, {"metadata": {"_cell_guid": "40987350-5926-4066-9d0b-fb56f8f5c1f6", "_uuid": "e58dabd9a0b1a18c2264b7c1747dac90fb5b5695", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["# import numpy as np\n", "# import pandas as pd\n", "# import numpy as np\n", "# import re as re\n", "\n", "# train_set = pd.read_csv('../input/train.csv')\n", "# test_set = pd.read_csv('../input/test.csv')\n", "# full_data = [train_set, test_set]\n", "\n", "# train_set.info()\n", "# for dataset in full_data:\n", "#     dataset['Family_Size'] = dataset['SibSp'] + dataset['Parch'] + 1\n", "# print(train_set[['Family_Size', 'Survived']].groupby(['Family_Size'], as_index=False).mean())\n", "# for dataset in full_data:\n", "#     dataset['isAlone'] = 0\n", "#     dataset.loc[dataset['Family_Size'] == 1, 'isAlone'] = 1\n", "# print(train_set[['isAlone', 'Survived']].groupby(['isAlone'], as_index=False).mean())\n", "# for dataset in full_data:\n", "#     dataset['Embarked'].fillna('S')\n", "# print(train_set[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())\n", "# train_set['Fare'].fillna(dataset['Fare'].median())\n", "# train_set['Cat_Fare'] = pd.qcut(dataset['Fare'], 4)\n", "# print(train_set[['Cat_Fare', 'Survived']].groupby(['Cat_Fare'], as_index=False).mean())\n", "# for dataset in full_data:\n", "#     mean = dataset['Age'].mean()\n", "#     std = dataset['Age'].std()\n", "#     null_count = dataset['Age'].isnull().sum()\n", "\n", "#     age_null_list = np.random.randint(mean - std, mean + std, size=null_count)\n", "#     dataset['Age'][np.isnan(dataset['Age'])] = age_null_list\n", "#     dataset['Age'] = dataset['Age'].astype(int)\n", "\n", "# train_set['CatAge'] = pd.qcut(train_set['Age'], 5)\n", "# print(train_set[['CatAge', 'Survived']].groupby(['CatAge'], as_index=False).mean())\n", "\n", "\n", "# def get_title(name):\n", "#     search_t = re.search(' ([A-Za-z]+)\\.', name)\n", "#     if (search_t):\n", "#         return search_t.group(1)\n", "#     return \"\"\n", "\n", "\n", "# for dataset in full_data:\n", "#     dataset['Title'] = dataset['Name'].apply(get_title)\n", "# print(pd.crosstab(train_set['Title'], train_set['Sex']))\n", "# for dataset in full_data:\n", "#     dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', \\\n", "#                                                  'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "#     dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n", "#     dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n", "#     dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n", "\n", "# print(train_set[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n", "# for dataset in full_data:\n", "#     # Mapping Sex\n", "#     dataset['Sex'] = dataset['Sex'].map({'female': 0, 'male': 1}).astype(int)\n", "#     title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "#     dataset['Title'] = dataset['Title'].map(title_mapping)\n", "#     dataset['Title'] = dataset['Title'].fillna(0)\n", "\n", "#     # Mapping Embarked\n", "#     dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).fillna(0).astype(int)\n", "\n", "#     # Mapping Fare\n", "#     dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0\n", "#     dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n", "#     dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2\n", "#     dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3\n", "#     dataset['Fare'] = dataset['Fare'].fillna(0).astype(int)\n", "\n", "#     # Mapping Age\n", "#     dataset.loc[dataset['Age'] <= 16, 'Age'] = 0\n", "#     dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n", "#     dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n", "#     dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n", "#     dataset.loc[dataset['Age'] > 64, 'Age'] = 4\n", "\n", "# # Feature Selection\n", "# drop_elements = ['Name', 'SibSp', 'Ticket', 'Cabin', 'Parch', 'Family_Size']\n", "# train_set = train_set.drop(drop_elements, axis=1)\n", "# train_set = train_set.drop(['PassengerId'], axis=1)\n", "# train_set = train_set.drop(['CatAge', 'Cat_Fare'], axis=1)\n", "\n", "# test_set = test_set.drop(drop_elements, axis=1)\n", "\n", "# print(train_set.head(10))\n", "# print(test_set.head(10))"], "outputs": []}, {"metadata": {"_cell_guid": "0bcf8540-c60b-4068-9cee-ef4ff255fae2", "_uuid": "cd92e834ddd5c7c80f247a41e0629d08ccc8e6ed", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import StratifiedShuffleSplit\n", "from sklearn.metrics import accuracy_score, log_loss\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "\n", "from numpy import loadtxt\n", "from xgboost import XGBClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score\n", "from xgboost import XGBClassifier\n", "\n", "train_clean = train_clean.drop(['PassengerId'], axis=1)\n", "train = train_clean.values\n", "test = test_clean.drop(['PassengerId'], axis=1).values"], "outputs": []}, {"metadata": {"_cell_guid": "465c8f22-319f-49d7-af1a-54495ce30426", "_uuid": "18b7a35aaabc552d7d8a0533a41ee571a92bebcb", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["best_param = {'min_samples_split': 2,\n", "              'criterion': 'gini',\n", "              'max_depth': 4,\n", "              'oob_score': False,\n", "              'min_weight_fraction_leaf': 0.0,\n", "              'verbose': 0,\n", "              'max_features': 'sqrt',\n", "              'n_estimators': 500,\n", "              'max_leaf_nodes': None,\n", "              'n_jobs': 1,\n", "              'min_impurity_split': None,\n", "              'min_impurity_decrease': 0.0,\n", "              'bootstrap': True,\n", "              'class_weight': None,\n", "              'warm_start': False,\n", "              'random_state': 55,\n", "              'min_samples_leaf': 2}\n", "\n", "RandomForestclf = RandomForestClassifier(**best_param)\n", "RandomForestclf.fit(train[0::, 1::], train[0::, 0])\n", "y_result = RandomForestclf.predict(test)\n", "submission = pd.DataFrame({\n", "    \"PassengerId\": test_set[\"PassengerId\"],\n", "    \"Survived\": y_result\n", "})"], "outputs": []}, {"metadata": {"_cell_guid": "ffa98af7-5bd0-4990-8d5b-b85bce2cffc3", "_uuid": "688de4ec6c4ccb4edd7012a6f78ebf2793356a00", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["submission.to_csv('submission_RF.csv', index=False)"], "outputs": []}]}