{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "101f8520-5bb6-3b60-185a-bf0071e0cf72"
      },
      "source": [
        "In this notebook I will try to find an algorithm which can predict a transaction being fraud. \n",
        "This is my first worknotebook on Kaggle, so, any remarks are welcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c061fab3-72c4-4a1c-b40b-fddc79b1f415"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns # visualization library alternative to matplotlib.pyplot\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "574010cc-21b9-2d8d-5b40-0a3808bc9710"
      },
      "outputs": [],
      "source": [
        "# first, loading our data\n",
        "data = pd.read_csv(\"../input/PS_20174392719_1491204439457_log.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b5b396f-41fc-7f23-daa6-0ac36ed7d394"
      },
      "source": [
        "General look at our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d15ebd2-7778-3d67-604c-93c902596851"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6736bbba-fbab-ceb1-c31c-96565635a2d0"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f6f61b5a-9673-c2b5-c08f-9a8007ef4c3b"
      },
      "source": [
        "This one was not very informative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b1f75f5-638f-64c0-e947-a6f5eacef3fb"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "24e172e8-ccf1-9c44-8ff1-aca58518f7ec"
      },
      "source": [
        "So, we have overall 11 columns.\n",
        "Type is a categorical variable which we will need in our data.\n",
        "However, destination names for sender and receiver doesn't look very helpful at all. I would also mention the last column called isFlaggedFraud. Looks like, there is a some sort of internal detection for transactions being fraud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22c58078-6a61-11cc-efc1-44809be614fa"
      },
      "outputs": [],
      "source": [
        "data['isFlaggedFraud'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a19f8554-0e20-4b35-276e-2c22aea81c26"
      },
      "source": [
        "We see that, from over 6 million transactions, this \"detector\" could identify only 16 being fraud. I do not consider this column very useful in our dataset, so, I drop it.\n",
        "I will also drop nameOrig  and nameDest columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64a51a7c-8929-10e0-4f58-385d2e448c0f"
      },
      "outputs": [],
      "source": [
        "data.drop(['nameOrig','nameDest','isFlaggedFraud'], axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f84ac06c-5467-43d6-0fb5-85c377d28840"
      },
      "source": [
        "Some visualizations (I am not very good at them, though)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b51b05b7-3ae0-f374-a7e8-6712cf54f647"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data['type'], hue = data['isFraud'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b67bada3-9c87-fc52-9d89-c80f152fcb1a"
      },
      "source": [
        "Looks like, Payment, Debit transactions are safe, no fraud there. Also Cash in is safe, which is understandable.\n",
        "Below, we see the number of fraud transactions per type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "92419eea-139d-3c85-8871-1e6b04d93cae"
      },
      "outputs": [],
      "source": [
        "data[data['isFraud']==1].groupby('type').count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "aa1b6439-2a92-e4c9-6f24-7cffc2bf101d"
      },
      "source": [
        "Now, we can proceed to our algorithm.\n",
        "First things first, in such cases where features are very skewed. Hence, we would be better off, if we standardize the data first.  Because only features should be standardized, I will call them X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29de8ed3-ea11-a417-093d-87cc04d0329b"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_toScale = data[['amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
        "      'oldbalanceDest', 'newbalanceDest'\n",
        "       ]]\n",
        "new_X = sc.fit(X_toScale)\n",
        "X_scaled = new_X.transform(X_toScale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "451070fc-b171-802b-d5d6-46b3e8e9bb47"
      },
      "outputs": [],
      "source": [
        "#creating our dataframe with scaled values\n",
        "\n",
        "scaled_df = pd.DataFrame(X_scaled, columns=['amount', 'oldbalanceOrg', 'newbalanceOrig',\n",
        "      'oldbalanceDest', 'newbalanceDest'\n",
        "       ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22229660-c42d-9fcb-f798-d777e43cd19a"
      },
      "outputs": [],
      "source": [
        "# we have also some categorical variable, called Type. Let's convert it to dummies, and then add to our final dataframe\n",
        "dummy_df = pd.DataFrame(pd.get_dummies(data['type']))\n",
        "#now, final dataframe\n",
        "final_df = scaled_df.join(dummy_df, how = 'outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "591bc0c6-4e64-a408-335d-80e8be58dc80"
      },
      "outputs": [],
      "source": [
        "final_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "666b3dfa-9ea2-1f8b-0aeb-4a7b7d3947b6"
      },
      "source": [
        "Looks like we are good to go. Now I will use RandomForestClassifier in order to develop my algorithm.\n",
        "First I will import the model, split our train and test datasets, then fit, and in the end predict labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b00eed17-73c7-6510-5df8-fa55095d530c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cross_validation import train_test_split\n",
        "# for future, train test split will be moved into model selection\n",
        "# from sklearn.model_selection import train_test_split\n",
        "rfc = RandomForestClassifier() #using default values\n",
        "#splitting our dataset\n",
        "X = final_df #dataset that we scaled and preprocessed\n",
        "y = data['isFraud'] #the column from our original dataset will be our label\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #use this random state to match my results only\n",
        "#training our model\n",
        "model = rfc.fit(X_train,y_train)\n",
        "#predicting our labels\n",
        "predictions = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "670710f1-c545-9a22-ba05-ae205981226e"
      },
      "source": [
        "Time to evaluate our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b856be10-be5f-34e7-c283-06a70b099a21"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test,predictions))\n",
        "print(confusion_matrix(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0d6a2a6c-f2e7-ffac-ddb3-73614e0ff636"
      },
      "source": [
        "Looks like we have very good model in case of detecting non-fraud transactions. Nevertheless, when detecting fraud transactions we have some errors. I am now working on other models  to use for this problem and if you have any suggestions, please, let me know in comments below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e51aced2-6d37-77e8-a339-57bacf84b6ee"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}