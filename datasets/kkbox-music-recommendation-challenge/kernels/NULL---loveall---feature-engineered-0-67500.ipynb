{"cells": [{"execution_count": null, "cell_type": "code", "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport datetime\nimport math\nimport gc\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "metadata": {"_cell_guid": "216be500-721f-45ac-ab63-6b0b67ec5fb9", "_uuid": "c8542907ead88c658cfe43c79118b30fc19487bf", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print('Loading data...')\ndata_path = '../input/'\ntrain = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\ntest = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\nsongs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n                                                  'artist_name' : 'category',\n                                                  'composer' : 'category',\n                                                  'lyricist' : 'category',\n                                                  'song_id' : 'category'})\nmembers = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                     parse_dates=['registration_init_time','expiration_date'])\nsongs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\nprint('Done loading...')", "metadata": {"_cell_guid": "91dfcb80-f6a5-48b8-b889-2b4df0e4a4e1", "_uuid": "81f223f194c6f6f8fb54b908a434a527a3f66c8c", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print('Data merging...')\n\n\ntrain = train.merge(songs, on='song_id', how='left')\ntest = test.merge(songs, on='song_id', how='left')\n\nmembers['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n\nmembers['registration_year'] = members['registration_init_time'].dt.year\nmembers['registration_month'] = members['registration_init_time'].dt.month\nmembers['registration_date'] = members['registration_init_time'].dt.day\n\nmembers['expiration_year'] = members['expiration_date'].dt.year\nmembers['expiration_month'] = members['expiration_date'].dt.month\nmembers['expiration_date'] = members['expiration_date'].dt.day\nmembers = members.drop(['registration_init_time'], axis=1)\n\ndef isrc_to_year(isrc):\n    if type(isrc) == str:\n        if int(isrc[5:7]) > 17:\n            return 1900 + int(isrc[5:7])\n        else:\n            return 2000 + int(isrc[5:7])\n    else:\n        return np.nan\n        \nsongs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\nsongs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n\ntrain = train.merge(members, on='msno', how='left')\ntest = test.merge(members, on='msno', how='left')\n\ntrain = train.merge(songs_extra, on = 'song_id', how = 'left')\ntrain.song_length.fillna(200000,inplace=True)\ntrain.song_length = train.song_length.astype(np.uint32)\ntrain.song_id = train.song_id.astype('category')\n\n\ntest = test.merge(songs_extra, on = 'song_id', how = 'left')\ntest.song_length.fillna(200000,inplace=True)\ntest.song_length = test.song_length.astype(np.uint32)\ntest.song_id = test.song_id.astype('category')\n\n# import gc\n# del members, songs; gc.collect();\n\nprint('Done merging...')", "metadata": {"_cell_guid": "24e253c9-b8f8-4c56-b1a5-5faa9bb17c8d", "_uuid": "95fae49636554eeb26dde3370054fbf6788335a8", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print (\"Adding new features\")\n\ndef genre_id_count(x):\n    if x == 'no_genre_id':\n        return 0\n    else:\n        return x.count('|') + 1\n\ntrain['genre_ids'].fillna('no_genre_id',inplace=True)\ntest['genre_ids'].fillna('no_genre_id',inplace=True)\ntrain['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\ntest['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n\ndef lyricist_count(x):\n    if x == 'no_lyricist':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n\ntrain['lyricist'].fillna('no_lyricist',inplace=True)\ntest['lyricist'].fillna('no_lyricist',inplace=True)\ntrain['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\ntest['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n\ndef composer_count(x):\n    if x == 'no_composer':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n\ntrain['composer'].fillna('no_composer',inplace=True)\ntest['composer'].fillna('no_composer',inplace=True)\ntrain['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\ntest['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n\ndef is_featured(x):\n    if 'feat' in str(x) :\n        return 1\n    return 0\n\ntrain['artist_name'].fillna('no_artist',inplace=True)\ntest['artist_name'].fillna('no_artist',inplace=True)\ntrain['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\ntest['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n\ndef artist_count(x):\n    if x == 'no_artist':\n        return 0\n    else:\n        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n\ntrain['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\ntest['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n\n# if artist is same as composer\ntrain['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\ntest['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n\n\n# if artist, lyricist and composer are all three same\ntrain['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\ntest['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n\n# is song language 17 or 45. \ndef song_lang_boolean(x):\n    if '17.0' in str(x) or '45.0' in str(x):\n        return 1\n    return 0\n\ntrain['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\ntest['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n\n\n_mean_song_length = np.mean(train['song_length'])\ndef smaller_song(x):\n    if x < _mean_song_length:\n        return 1\n    return 0\n\ntrain['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\ntest['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n\n# number of times a song has been played before\n_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\ndef count_song_played(x):\n    try:\n        return _dict_count_song_played_train[x]\n    except KeyError:\n        try:\n            return _dict_count_song_played_test[x]\n        except KeyError:\n            return 0\n    \n\ntrain['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int8)\ntest['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int8)\n\n# number of times the artist has been played\n_dict_count_artist_played = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\ndef count_artist_played(x):\n    return _dict_count_artist_played[x]\n\ntrain['count_artist_played'] = train['artist_name'].apply(count_song_played).astype(np.int8)\ntest['count_artist_played'] = test['artist_name'].apply(count_song_played).astype(np.int8)\n\n\nprint \"Done adding features\"", "metadata": {"_cell_guid": "6d0e7314-91f0-4ff5-9081-ebdcb9b1406d", "_uuid": "2f5475aa07fa7f4b59e8e8928d03f67bbcac9347", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print (\"Train test and validation sets\")\nfor col in train.columns:\n    if train[col].dtype == object:\n        train[col] = train[col].astype('category')\n        test[col] = test[col].astype('category')\n\n\nX_train = train.drop(['target'], axis=1)\ny_train = train['target'].values\n\n\nX_test = test.drop(['id'], axis=1)\nids = test['id'].values\n\n\n# del train, test; gc.collect();\n\nd_train_final = lgb.Dataset(X_train, y_train)\nwatchlist_final = lgb.Dataset(X_train, y_train)\nprint('Processed data...')", "metadata": {"_cell_guid": "05ee917e-dc12-4201-8fe6-0b515286253c", "_uuid": "577e8f31dccc7262514f854b96bb213396aea8f6", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'gbdt',\n        'learning_rate': 0.3 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 256,\n        'max_depth': 10,\n        'num_rounds': 200,\n        'metric' : 'auc'\n    }\n\n%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)", "metadata": {"_cell_guid": "8a7cfb94-afdb-47b1-94d7-88791baa47e5", "_uuid": "42e044686bd89948d06c2471892c9542605a8a05", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'dart',\n        'learning_rate': 0.3 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 256,\n        'max_depth': 10,\n        'num_rounds': 200,\n        'metric' : 'auc'\n    }\n\n%time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)", "metadata": {"_cell_guid": "10895c7a-73f8-45a0-a9b7-e4e489b06268", "_uuid": "a2e8293a6c5ff0c0efdb52fb82f053cfb773e55c", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print('Making predictions')\np_test_1 = model_f1.predict(X_test)\np_test_2 = model_f2.predict(X_test)\np_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n\n\nprint('Done making predictions')", "metadata": {"_cell_guid": "89048be8-a137-4e0d-811c-740645c17d1a", "_uuid": "ea33e6b678757c4f45e1cddfac4a37ce06962d33", "trusted": false, "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": "print ('Saving predictions Model model of gbdt')\n\nsubm = pd.DataFrame()\nsubm['id'] = ids\nsubm['target'] = p_test_avg\nsubm.to_csv(data_path + 'submission_lgbm_avg.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n\nprint('Done!')", "metadata": {"_cell_guid": "e7b31f60-187f-4744-9416-3c9c876fa838", "_uuid": "28888fb62a1efccb51efb762ac1266695bb82002", "trusted": false, "collapsed": true}, "outputs": []}], "metadata": {"language_info": {"name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 1}