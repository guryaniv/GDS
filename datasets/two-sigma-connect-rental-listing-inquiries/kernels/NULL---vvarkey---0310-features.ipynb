{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "381725c2-ac49-6267-623e-667ebaf86853"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def scorer(estimator, X, y):\n",
        "    return -log_loss(y, estimator.predict_proba(X))\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "df=pd.read_json('../input/train.json')\n",
        "df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\n",
        "df['created']=df['created'].astype(np.datetime64)\n",
        "df['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\n",
        "df['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\n",
        "df['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\n",
        "df['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\n",
        "df['features_count']=df.features.apply(lambda x: len(x))\n",
        "df['photos_count']=df.photos.apply(lambda x: len(x))\n",
        "\n",
        "df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\n",
        "for feature in ['hardwood floors',  'laundry in building', 'cats_allowed']:\n",
        "    df[feature]=df['features'].apply(lambda x: feature in x)\n",
        "\n",
        "df['medium']=df['interest_level']=='medium'\n",
        "df['low']=df['interest_level']=='low'\n",
        "df['high']=df['interest_level']=='high'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a73bba0-a48c-03d2-a3b4-e7b7bf062b72"
      },
      "outputs": [],
      "source": [
        "x=[]\n",
        "y_train=[]\n",
        "y_val=[]\n",
        "for i in range(100, df_train.shape[0], 3000):\n",
        "    x+=[i]\n",
        "    clf=ExtraTreesClassifier(max_depth=21, n_estimators=100, random_state=0)\n",
        "    clf.fit(df_train.iloc[:i][cols].values, df_train.iloc[:i]['interest_level'])\n",
        "    y_pred=clf.predict_proba(df_train.iloc[:i][cols])\n",
        "    score=log_loss(df_train.iloc[:i]['interest_level'].values, y_pred)\n",
        "    y_train+=[score]\n",
        "    y_pred=clf.predict_proba(df_test[cols])\n",
        "    score2=log_loss(df_test['interest_level'].values, y_pred)\n",
        "    y_val+=[score2]\n",
        "    print(\"%.6f %.6f\"%(score, score2))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5080f929-7f29-469f-194e-80daf935ce58"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=4)\n",
        "score_sum=0\n",
        "score2_sum=0\n",
        "for ktrain, ktest in kf.split(df_train):\n",
        "    clf=KNeighborsClassifier(n_neighbors=500)\n",
        "    clf.fit(df_train.iloc[ktrain][cols].values, df_train.iloc[ktrain]['interest_level'])\n",
        "    y_pred=clf.predict_proba(df_train.iloc[ktrain][cols])\n",
        "    score=log_loss(df_train.iloc[ktrain]['interest_level'].values, y_pred)\n",
        "    score_sum+=score\n",
        "    y_pred=clf.predict_proba(df_train.iloc[ktest][cols])\n",
        "    score2=log_loss(df_train.iloc[ktest]['interest_level'].values, y_pred)\n",
        "    score2_sum+=score2\n",
        "    print(\"%.6f %.6f\"%(score, score2))\n",
        "print(\"means\")\n",
        "print(\"%.6f %.6f\"%(score_sum/4, score2_sum/4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9763775-72a5-9ee7-da72-5dae8cbfce21"
      },
      "outputs": [],
      "source": [
        "features_rows=(df.features.values)\n",
        "features_rows=np.hstack(features_rows)\n",
        "df_features=pd.DataFrame(features_rows, columns=['feature'])\n",
        "df_feature_counts=pd.DataFrame(df_features.groupby(['feature']).size(), \n",
        "                               columns=['size']).reset_index()\n",
        "df_feature_counts=df_feature_counts.sort_values('size', ascending=False)\n",
        "feature_list=df_feature_counts.loc[df_feature_counts['size']>5000]['feature'].values\n",
        "feature_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36644352-4498-53fe-6a60-6bd9aeabee38"
      },
      "outputs": [],
      "source": [
        "df_feature_counts[(df_feature_counts.feature.str.find(\"laundry\")!=-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8fe696c0-0960-6e87-e955-37170529fb23"
      },
      "outputs": [],
      "source": [
        "feature='dining room'\n",
        "df[feature]=df['features'].apply(lambda x: feature in x)\n",
        "d={}\n",
        "for j in ['high', 'medium', 'low']:\n",
        "    d[j]=[]\n",
        "    for i in [True, False]:\n",
        "        summa=(df[feature]==i).sum()\n",
        "        d[j]+=[((df[feature]==i)&(df.interest_level==j)).sum()/summa]\n",
        "plt.bar([0, 1], d['low'])\n",
        "plt.bar([0, 1], d['medium'], bottom=d['low'])\n",
        "plt.bar([0, 1], d['high'], bottom=np.sum([d['low'], d['medium']], axis=0))\n",
        "plt.show()        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5fb4e92-13a9-4eef-be7c-93b23be892b9"
      },
      "outputs": [],
      "source": [
        "df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\n",
        "df['cats_allowed']=df['features'].apply(lambda x: 'cats allowed' in x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5e7268f8-bf56-2e9e-78d8-5f7d8a38e8f0"
      },
      "outputs": [],
      "source": [
        "cols=['price', 'bathrooms', 'bedrooms', 'priceperbed', 'created_hour', \n",
        "          'desc_count', 'photos_count', 'features_count', 'hardwood floors',\n",
        "          'laundry in building', 'cats_allowed', 'created_day']\n",
        "df_train, df_test = train_test_split(df, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad44aba1-2a92-9fe2-13af-953473c95156"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=4)\n",
        "score_sum=0\n",
        "score2_sum=0\n",
        "for ktrain, ktest in kf.split(df_train):\n",
        "    clf=ExtraTreesClassifier(max_depth=13, n_estimators=100, min_samples_split=12, random_state=0)\n",
        "    clf.fit(df_train.iloc[ktrain][cols].values, df_train.iloc[ktrain]['interest_level'])\n",
        "    y_pred=clf.predict_proba(df_train.iloc[ktrain][cols])\n",
        "    score=log_loss(df_train.iloc[ktrain]['interest_level'].values, y_pred)\n",
        "    score_sum+=score\n",
        "    y_pred=clf.predict_proba(df_train.iloc[ktest][cols])\n",
        "    score2=log_loss(df_train.iloc[ktest]['interest_level'].values, y_pred)\n",
        "    score2_sum+=score2\n",
        "    print(\"%.6f %.6f\"%(score, score2))\n",
        "print(\"means\")\n",
        "print(\"%.6f %.6f\"%(score_sum/4, score2_sum/4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ad71288-47cf-39d1-55be-9ce163ce90db"
      },
      "outputs": [],
      "source": [
        "    clf=ExtraTreesClassifier(max_depth=12, n_estimators=100, random_state=0)\n",
        "                            #min_samples_split=12, \n",
        "    clf.fit(df_train[cols].values, df_train['interest_level'])\n",
        "    y_pred=clf.predict_proba(df_train[cols])\n",
        "    score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "    y_pred=clf.predict_proba(df_test[cols])\n",
        "    score2=log_loss(df_test['interest_level'].values, y_pred)\n",
        "    print(\"%.6f %.6f\"%(score, score2))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}