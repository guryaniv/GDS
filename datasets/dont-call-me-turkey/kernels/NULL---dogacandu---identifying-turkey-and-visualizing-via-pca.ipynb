{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# first read the data\nimport pandas as pd\nvideo=pd.read_json(\"../input/train.json\")\nvideo.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e09d11d9b345ecb6ebded7a99ae705b24e176def"},"cell_type":"markdown","source":"Train data includes audio_embedding of youtube videos and if embedding includes turkey sound. Frames are lists containing (mostly) 128 elements in audio_embedding column. Thus each vid_id has a list of lists (mostly 10 frames) in  audio_embedding column.  I want to combine frames in lists with each list signifying a vid_id. There are 1195 embeddings. Those which are shorter than 10 frames are repeated until they reach 10 frame data as follows"},{"metadata":{"trusted":true,"_uuid":"b70bebd013f2a8b491b3f7794671bab0701bd4f7"},"cell_type":"code","source":"\ndicti={}\nfor i in range(1195):\n    liste=[]\n    for frame in video.audio_embedding[i]:\n        for value in frame:\n            liste.append(value)\n    dicti[i]=liste\nfor i in range(1195):\n    while len(dicti[i])<1280:\n        dicti[i].extend(dicti[i])\n    dicti[i]=dicti[i][:1280]  \naudio=pd.DataFrame.from_dict(dicti, orient='index')\naudio.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbb1e532a58cad792e6f689dc33c544dbad84713"},"cell_type":"code","source":"#now we can create the model using Logistic Regression and check . Accuracy of the model is 93.6%\nfrom sklearn.linear_model import LogisticRegression\nmodel=LogisticRegression()\nis_turkey=video.is_turkey # target variable\nfrom sklearn.model_selection import cross_val_score\ncross_val_score(model, audio, is_turkey, cv=5).mean()  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9155c2e9bffaa5df31957c5ae13c42a19b86c990"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"fc6c569cd8997e9948a838cc9f43ad37a7baabff"},"cell_type":"code","source":"# to visualize the clusters, I project data into 2 dimensions with PCA\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nproj = pca.fit_transform(audio)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.scatter(proj[:, 0], proj[:, 1], c=is_turkey) \nplt.colorbar() ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}