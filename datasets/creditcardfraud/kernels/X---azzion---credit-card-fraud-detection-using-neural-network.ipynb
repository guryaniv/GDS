{"nbformat_minor": 1, "cells": [{"source": ["# Ideas for Fraud check : \n", "# 1) Check locations of transaction - 2 different transactions in a short period. \n", "# 2) User's Credit card use history \n", "# 3) Classifcation on different frauds "], "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null}, {"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import preprocessing\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "22d41ba02b32da646889dba983ba08c08cb38f08", "collapsed": true, "_cell_guid": "479748ca-639b-4448-ae21-3681170a65de"}, "execution_count": null}, {"source": ["# import data set \n", "df = pd.read_csv(\"../input/creditcard.csv\")\n", "\n", "# Exploring the data\n", "df.describe()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "86182358544562cbe369b51e9814655acde61586", "collapsed": true, "_cell_guid": "0841452d-e539-4ece-85d1-15d360043c09"}, "execution_count": null}, {"source": ["df.head()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "b868348d19df2cf2a0899f116a9fdaeec9e609e3", "collapsed": true, "_cell_guid": "ea253bf4-b913-4aaf-8926-eee7235728b6"}, "execution_count": null}, {"source": ["# check if there is any null values\n", "df.isnull().sum() "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "7283579147c0d1ee73527b045b03b9544ff3770b", "collapsed": true, "_cell_guid": "1b5465a9-415a-4234-bda7-83f476de6d12"}, "execution_count": null}, {"source": ["# No missing values in the data "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "dcc6f593cc27cadcfcccb1ab25e3e52f200b4747", "collapsed": true, "_cell_guid": "981699a4-657a-4d67-8ec4-31591d07b0b3"}, "execution_count": null}, {"source": ["# Creating Train Set, Dev Set & Train set\n", "\n", "# Converting the csv data into matrix \n", "columns = \"Time V1 V2 V3 V4 V5 V6 V7 V8 V9 V10 V11 V12 V13 V14 V15 V16 V17 V18 V19 V20 V21 V22 V23 V24 V25 V26 V27 V28 Amount\".split()\n", "X = pd.DataFrame.as_matrix(df,columns=columns)\n", "Y = df.Class\n", "Y = Y.reshape(Y.shape[0],1)\n", "X.shape\n", "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.06)\n", "X_test, X_dev, Y_test, Y_dev = train_test_split(X_test,Y_test, test_size=.5)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "5906208cac3075b9b5d6889561210b3e990cd2ad", "collapsed": true, "_cell_guid": "029fac77-6ded-4a18-a970-e548a49692b4", "_kg_hide-input": false}, "execution_count": null}, {"source": ["# Check if there is Classification Values - 0/1 in training set and other set \n", "\n", "np.where(Y_train == 1)\n", "np.where(Y_test == 1)\n", "np.where(Y_dev == 1)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "3290a1a038c9e414589b9390389aa1fbb6929a39", "collapsed": true, "_cell_guid": "23d6f550-aba4-4046-88c8-c8efca8194ac"}, "execution_count": null}, {"source": ["# Checking the shape's of the new data set as matrix \n", "print(\"No of training Examples : \"+str(X_train.shape[0]))  # 94% data \n", "print(\"No of test Examples : \"+str(X_test.shape[0]))       # 3% data\n", "print(\"No of dev Examples : \"+str(X_dev.shape[0]))         # 3% data\n", "print(\"Shape of training data : \"+str(X_train.shape))\n", "print(\"Shape of test data : \"+str(X_test.shape))\n", "print(\"Shape of dev data : \"+str(X_dev.shape))\n", "print(\"Shape of Y test data : \"+str(Y_test.shape))\n", "print(\"Shape of Y dev data : \"+str(Y_dev.shape))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e8f7ddedd7937d9b340fd79e92a311667acf42e7", "collapsed": true, "_cell_guid": "b8b37d86-23c3-4185-afb4-fc9e796f3410"}, "execution_count": null}, {"source": ["#Flatten the data to so that all Features/X Variables \n", "X_train_flatten = X_train.reshape(X_train.shape[0],-1).T\n", "Y_train_flatten = Y_train.reshape(Y_train.shape[0],-1).T\n", "X_dev_flatten = X_dev.reshape(X_dev.shape[0],-1).T\n", "Y_dev_flatten = Y_dev.reshape(Y_dev.shape[0],-1).T\n", "X_test_flatten = X_test.reshape(X_test.shape[0],-1).T\n", "Y_test_flatten = Y_test.reshape(Y_test.shape[0],-1).T\n", "\n", "print(\"No of training Examples : \"+str(X_train_flatten.shape))  \n", "print(\"No of test Examples : \"+str(Y_train_flatten.shape))  \n", "print(\"No of X_dev Examples : \"+str(X_dev_flatten.shape))  \n", "print(\"No of Y_dev test Examples : \"+str(Y_dev_flatten.shape))  \n", "print(\"No of X_test Examples : \"+str(X_test_flatten.shape))  \n", "print(\"No of Y_test Examples : \"+str(Y_test_flatten.shape))\n", "print(\"No of Sanity_test : \"+str(X_train_flatten[0:5,0]))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "19e721fe5df41744cbf1669a5f6ca0dd817d7635", "collapsed": true, "_cell_guid": "99f15a8c-4d5f-4b5e-9af0-56ee0bdf2e87"}, "execution_count": null}, {"source": ["# Normalize features and create final Train set \n", "X_train_set = preprocessing.normalize(X_train_flatten)\n", "Y_train_set = Y_train_flatten\n", "\n", "print(\"No of X_train_set shape : \"+str(X_train_set.shape))  \n", "print(\"No of Y_train_set shape : \"+str(Y_train_set.shape)) "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "262fd43b1a97c87f2529dfcda8a6761089d92d18", "collapsed": true, "_cell_guid": "6a35d7a9-d1d7-4f24-b9a7-3e999579ec9c"}, "execution_count": null}, {"source": ["# Funcation to intialize weights for forward propogration \n", "def intialize_parameters(layer_dims):\n", "    parameters = {}\n", "    L = len(layer_dims)\n", "    for l in range(1,L):\n", "        parameters['W'+str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n", "        parameters['b'+str(l)] = np.zeros((layer_dims[l],1))\n", "            \n", "    return parameters"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "f1aaea3cbf9087ee414188e394965e2eb2eb3a5d", "collapsed": true, "_cell_guid": "5f27ff04-874e-4d2f-8ca5-e7878fcd5e24"}, "execution_count": null}, {"source": ["# Testing if the function works \n", "parameters = intialize_parameters([30,20,10,5,2])\n", "print(\"W1 =\" + str(parameters[\"W1\"]))\n", "print(\"b1 =\" + str(parameters[\"b1\"]))\n", "print(\"W2 =\" + str(parameters[\"W2\"]))\n", "print(\"b2 =\" + str(parameters[\"b2\"]))\n", "print(\"W3 =\" + str(parameters[\"W3\"]))\n", "print(\"b3 =\" + str(parameters[\"b3\"]))\n", "print(\"W4 =\" + str(parameters[\"W4\"]))\n", "print(\"b4 =\" + str(parameters[\"b4\"]))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "f4088a9a7bcab56a54147cdcce79716e67dafdde", "collapsed": true, "_cell_guid": "cd692215-b46d-4da3-bd78-1e939fd4098f"}, "execution_count": null}, {"source": ["# create the sigmoid function \n", "def sigmoid(z):\n", "    \n", "    s = 1/(1+np.exp(-z))\n", "    cache = z\n", "    return s,cache"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e6d2308bdea3abd099abb65d87569c2dddb14640", "collapsed": true, "_cell_guid": "1fc51a3c-f907-4f27-80f4-96624ca06d7d"}, "execution_count": null}, {"source": ["# test sigmoid function \n", "sigmoid(np.array(([2,7]))) "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "50917cea8c57ce5750326d0ade7a9ebf74362aab", "collapsed": true, "_cell_guid": "bc6e7bf7-fe86-4903-ba78-2067017f6410"}, "execution_count": null}, {"source": ["# create the relu function\n", "def relu(z):\n", "    \n", "    r = np.maximum(0,z)\n", "    cache = z\n", "    return r,cache\n", "        \n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "3e5672dc2c0cc71b3c9995b5c6e5cf257059922b", "collapsed": true, "_cell_guid": "179c9477-4d5f-49aa-b0f3-b35932ffb34e"}, "execution_count": null}, {"source": ["# testing relu function \n", "relu([1,-1,21]) "], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e6ec43668956470dbe88deb1a529d054130ef6d2", "collapsed": true, "_cell_guid": "480a40d0-2865-4822-8abf-5f512dcaba63"}, "execution_count": null}, {"source": ["# Relu Backward and Sigmoid Backward\n", "def relu_backward(dA, cache):\n", "    \n", "    Z = cache\n", "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n", "    \n", "    # When z <= 0, you should set dz to 0 as well. \n", "    dZ[Z <= 0] = 0\n", "    \n", "    assert (dZ.shape == Z.shape)\n", "    \n", "    return dZ\n", "\n", "def sigmoid_backward(dA, cache):\n", "\n", "    Z = cache\n", "    \n", "    s = 1/(1+np.exp(-Z))\n", "    dZ = dA * s * (1-s)\n", "    \n", "    assert (dZ.shape == Z.shape)\n", "    \n", "    return dZ"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "9258d3be0b8e0ef1a489f9cfebb3792d1006eb90", "collapsed": true, "_cell_guid": "3e95543c-87ad-40fe-a32f-0932eec4cddf"}, "execution_count": null}, {"source": ["# Linear_forward\n", "def linear_forward(A, W, b):\n", "\n", "    Z = np.dot(W,A)+b\n", "    cache = (A, W, b)\n", "    \n", "    return Z, cache"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "529ba6df7a42c738a50062895d3953dcc548129f", "collapsed": true, "_cell_guid": "a4868b36-7c59-430d-8b4a-cf3e715e4308"}, "execution_count": null}, {"source": ["#linear_activation_forward\n", "def linear_activation_forward(A_prev, W, b, activation):\n", "\n", "    if activation == \"sigmoid\":\n", "        Z, linear_cache = linear_forward(A_prev,W,b)\n", "        A, activation_cache = sigmoid(Z)\n", "\n", "    \n", "    elif activation == \"relu\":\n", "        Z, linear_cache = linear_forward(A_prev,W,b)\n", "        A, activation_cache = relu(Z)\n", "    \n", "    cache = (linear_cache, activation_cache)\n", "\n", "    return A, cache"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "8d264fb8742c9a33bec1ea7ae2a1987ad732a04b", "collapsed": true, "_cell_guid": "f68b45dd-e5c5-4569-8dfa-473f16c438ba"}, "execution_count": null}, {"source": ["# L layers forward propagation \n", "\n", "def forward_propagation(X, parameters):\n", "    caches = []\n", "    A = X\n", "    L = len(parameters) // 2                  # number of layers in the neural network\n", "    \n", "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n", "    for l in range(1, L):\n", "        A, cache = linear_activation_forward(A,parameters[\"W\" + str(l)],parameters[\"b\" + str(l)],activation=\"relu\")\n", "        caches.append(cache)\n", "    \n", "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n", "    AL, cache = linear_activation_forward(A,parameters[\"W\" + str(L)],parameters[\"b\" + str(L)],activation=\"sigmoid\")\n", "    caches.append(cache)\n", "            \n", "    return AL, caches\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e64dafab0c6590b199581ea85be58e1235d63073", "collapsed": true, "_cell_guid": "f0cf4a00-9d62-47cc-a710-16a08589e6ae"}, "execution_count": null}, {"source": ["#  Cost function\n", "\n", "def cost_function(AL, Y):\n", "    m = Y.shape[1]\n", "\n", "    cost = (-1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n", "\n", "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n", "    \n", "    return cost"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "0e31c95d67b718f598e8a8c4cba33d39d29525ce", "collapsed": true, "_cell_guid": "f796b01b-fc9f-408e-83b5-3b9e1eb3ad6e"}, "execution_count": null}, {"source": ["# linear_backward \n", "\n", "def linear_backward(dZ, cache):\n", "    A_prev, W, b = cache\n", "    m = A_prev.shape[1]\n", "\n", "    dW = (1/m)*np.dot(dZ,A_prev.T)\n", "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True)\n", "    dA_prev = np.dot(W.T,dZ)\n", "    \n", "    return dA_prev, dW, db"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "d36af3b0a6b72e6e4e9d16c0c228f0a2756087f7", "collapsed": true, "_cell_guid": "86f2fc73-9b34-4fea-8ab0-e9c4663b440b"}, "execution_count": null}, {"source": ["# linear_activation_backward\n", "\n", "def linear_activation_backward(dA, cache, activation):\n", "\n", "    linear_cache, activation_cache = cache\n", "    \n", "    if activation == \"relu\":\n", "        dZ = relu_backward(dA,activation_cache)\n", "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n", "        \n", "    elif activation == \"sigmoid\":\n", "        dZ = sigmoid_backward(dA,activation_cache)\n", "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n", "    \n", "    return dA_prev, dW, db"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "57a3263d4067e7d598237fe8541000f3d88f5b47", "collapsed": true, "_cell_guid": "c64d9920-ba8b-41b2-b764-350d7e586dda"}, "execution_count": null}, {"source": ["# backward propagation\n", "\n", "def backward_propagation(AL, Y, caches):\n", "    \n", "    grads = {}\n", "    L = len(caches) # the number of layers\n", "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n", "    \n", "    # Initializing the backpropagation\n", "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n", "    \n", "    # Lth layer (SIGMOID -> LINEAR) gradients. Inputs: \"AL, Y, caches\". Outputs: \"grads[\"dAL\"], grads[\"dWL\"], grads[\"dbL\"]\n", "    current_cache = caches[L-1]\n", "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL,current_cache,activation=\"sigmoid\")\n", "    \n", "    for l in reversed(range(L-1)):\n", "        # lth layer: (RELU -> LINEAR) gradients.\n", "        # Inputs: \"grads[\"dA\" + str(l + 2)], caches\". Outputs: \"grads[\"dA\" + str(l + 1)] , grads[\"dW\" + str(l + 1)] , grads[\"db\" + str(l + 1)] \n", "        current_cache = caches[l]\n", "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\"+str(l+2)],current_cache,activation=\"relu\")\n", "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n", "        grads[\"dW\" + str(l + 1)] = dW_temp\n", "        grads[\"db\" + str(l + 1)] = db_temp\n", "\n", "    return grads"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "f6d61873e37096255a890173385d74198b440caa", "collapsed": true, "_cell_guid": "b04c2e47-7bf3-4632-892b-bea71f52cb61"}, "execution_count": null}, {"source": ["# update parameters \n", "\n", "def update_parameters(parameters, grads, learning_rate):\n", "\n", "    L = len(parameters) // 2 # number of layers in the neural network\n", "    for l in range(1,L+1):\n", "        parameters[\"W\"+str(l)]=parameters[\"W\" + str(l)]-learning_rate*grads[\"dW\" + str(l)]\n", "        parameters[\"b\"+str(l)]=parameters[\"b\" + str(l)]-learning_rate*grads[\"db\" + str(l)]\n", "    return parameters\n"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "5e36ba81e7066c63d63d98b75a79454d031d797d", "collapsed": true, "_cell_guid": "b8cd85d0-ccdd-4932-b804-ba0ea910353b"}, "execution_count": null}, {"source": ["# setting the size of the network \n", "layer_dims = [30,20,10,5,1] #5 Layer model with 3 hidden layers \n", "\n", "# Deep Learning network to classify frauds and normal\n", "layer_dims = [30,20,10,5,1] #5 Layer model with 3 hidden layers \n", "\n", "# Deep Learning network to classify frauds and normal\n", "def nn_model(X,Y,layer_dims,learning_rate=.0065, num_iterations=2500,print_cost=False):\n", "    costs = []\n", "    \n", "    #initialize parameters \n", "    parameters = intialize_parameters(layer_dims)\n", "    # for loop for iterations/epoch \n", "    for i in range(0,num_iterations):\n", "        #forward_propagation\n", "        AL, caches = forward_propagation(X, parameters)\n", "        \n", "        #compute cost\n", "        cost = cost_function(AL, Y)\n", "        \n", "        #backward_propagation \n", "        grads = backward_propagation(AL, Y, caches)\n", "        \n", "        #update parameters\n", "        parameters = update_parameters(parameters,grads,learning_rate)\n", "        \n", "        if print_cost and i % 100 == 0:\n", "            print (\"Cost after iteration %i: %f\" %(i, cost))\n", "        if print_cost and i % 100 == 0:\n", "            costs.append(cost)\n", "        \n", "    # plot the cost\n", "    plt.plot(np.squeeze(costs))\n", "    plt.ylabel('cost')\n", "    plt.xlabel('iterations (per tens)')\n", "    plt.title(\"Learning rate =\" + str(learning_rate))\n", "    plt.show()\n", "    \n", "    return parameters"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "3a728b579a2f41abe935e1509c87a4485ffc691a", "collapsed": true, "_cell_guid": "78646745-cd78-404f-940a-93e65f5a40c6"}, "execution_count": null}, {"source": ["X_train_set.shape\n", "Y_train_set.shape"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "875f6e678115d3764beda535725cbc12593303ec", "collapsed": true, "_cell_guid": "e5481a56-818c-4dff-985b-b47346a357d7"}, "execution_count": null}, {"source": ["# running a model \n", "parameters = nn_model(X_train_set,Y_train_set,layer_dims,learning_rate=.0065,num_iterations = 2500, print_cost = True)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "b2a5307516588e68850fe42fa8c61d305234bef5", "collapsed": true, "_cell_guid": "be051add-e65c-43d4-a4a1-c03c6ca49ae1"}, "execution_count": null}, {"source": ["# predict Function\n", "def predict(X, y, parameters):\n", "    \n", "    m = X.shape[1]\n", "    p = np.zeros((1,m))\n", "    \n", "    # Forward propagation\n", "    probas, caches = forward_propagation(X, parameters)\n", "\n", "    \n", "    # convert probas to 0/1 predictions\n", "    for i in range(0, probas.shape[1]):\n", "        if probas[0,i] > 0.5:\n", "            p[0,i] = 1\n", "        else:\n", "            p[0,i] = 0\n", "    \n", "    #print results\n", "    #print (\"predictions: \" + str(p))\n", "    #print (\"true labels: \" + str(y))\n", "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n", "        \n", "    return p"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "5923f247c5f338cc478f6574b343dd6e8a7451fb", "collapsed": true, "_cell_guid": "51cbf8b6-a5c6-4f76-897e-1918aefabffd"}, "execution_count": null}, {"source": ["pred_train = predict(X_train_set, Y_train_set, parameters)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "9599ce43b5383c122e724b7105da3464d86306bf", "collapsed": true, "_cell_guid": "fb1de1e7-e8b5-42ed-b613-0fdf4a559da9"}, "execution_count": null}, {"source": ["pred_test = predict(X_test_flatten, Y_test_flatten, parameters)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "4acda72d56a5ca5f316ce8dab92c07250ca8f616", "collapsed": true, "_cell_guid": "1d3acfe7-ad22-4b7e-b3ea-d566be0c1b0e"}, "execution_count": null}, {"source": ["pred_dev = predict(X_dev_flatten, Y_dev_flatten, parameters)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "aa4c215d302f7d4f50f62ec432e08640d8c086d3", "collapsed": true, "_cell_guid": "51ee2145-21a6-4bda-8303-21db817cf1e2"}, "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.4", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}