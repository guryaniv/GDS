{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy import stats\nimport time\n\nsns.set(style = \"darkgrid\")\nxsize = 18.0\nysize = 12.0\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_json(\"../input/train.json\").set_index(\"id\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b1fced87cbf23a3bae95fbf11c6a94c9bb683a7"},"cell_type":"code","source":"le = LabelEncoder()\ny = le.fit_transform(train_df[\"cuisine\"].values)\nX = train_df[\"ingredients\"].values\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.33)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87bbcf0bec6bbe1bf4039b5b5feb039e7909564c"},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\", preprocessor = lambda x: x, tokenizer = lambda x: x, token_pattern = None)\ntfidf_train = tfidf_vectorizer.fit_transform(x_train)\ntfidf_valid = tfidf_vectorizer.transform(x_valid)\ntfidf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1360c36f50052ecd5b69219a1ac5d1c5aa9360d"},"cell_type":"code","source":"LogisticRegression().get_params().keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26016d0837a32029e5fde7831bc6df340c7d13dd"},"cell_type":"code","source":"logreg = LogisticRegression(penalty = \"L2\", dual = False, tol = 1e-5, C = 1.0, fit_intercept = True, intercept_scaling = 1, \n                            class_weight = None, random_state = None, solver = \"saga\", max_iter = 250, multi_class = \"ovr\", \n                            verbose = 0, warm_start = False, n_jobs = 1)\nlogreg.fit(tfidf_train, y_train)\ntrain_pred = logreg.predict(tfidf_train)\nvalid_pred = logreg.predict(tfidf_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95ba49215202fe93dd4c2a8054e7b3ef6eaf46d5"},"cell_type":"code","source":"print(\"Train Accuracy: \"+str(accuracy_score(y_train, train_pred)))\nprint(\"Valid Accuracy: \"+str(accuracy_score(y_valid, valid_pred)))\nprint(\"Train F1 Score: \"+str(f1_score(y_train, train_pred, average = \"weighted\")))\nprint(\"Valid F1 Score: \"+str(f1_score(y_valid, valid_pred, average = \"weighted\")))\nprint(\"Train Precision: \"+str(precision_score(y_train, train_pred, average = \"weighted\")))\nprint(\"Valid Precision: \"+str(precision_score(y_valid, valid_pred, average = \"weighted\")))\nprint(\"Train Recall: \"+str(recall_score(y_train, train_pred, average = \"weighted\")))\nprint(\"Valid Recall: \"+str(recall_score(y_valid, valid_pred, average = \"weighted\")))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44ebef571f86e77b8cb5bc6900393e31d27d9987","scrolled":false},"cell_type":"code","source":"Cs = np.geomspace(1e-8, 1e8, 30)\npenalties = [\"L1\", \"L2\"]\n\naccuracy_train = {}\naccuracy_valid = {}\naccuracy_diff = {}\nf1_train = {}\nf1_valid = {}\nf1_diff = {}\nprecision_train = {}\nprecision_valid = {}\nprecision_diff = {}\nrecall_train = {}\nrecall_valid = {}\nrecall_diff = {}\n\nfor i, penalty in enumerate(penalties):\n    accuracy_train[penalty] = np.zeros(len(Cs))\n    f1_train[penalty] = np.zeros(len(Cs))\n    precision_train[penalty] = np.zeros(len(Cs))\n    recall_train[penalty] = np.zeros(len(Cs))\n    accuracy_valid[penalty] = np.zeros(len(Cs))\n    f1_valid[penalty] = np.zeros(len(Cs))\n    precision_valid[penalty] = np.zeros(len(Cs))\n    recall_valid[penalty] = np.zeros(len(Cs))\n    for j, C in enumerate(Cs):\n        start_time = time.time()\n        print(\"(\"+str((i*30)+(j+1))+\") Starting penalty=\"+penalty+\", C=\"+str(C))\n        logreg = LogisticRegression(penalty = penalty, dual = False, tol = 1e-5, C = C, fit_intercept = True, intercept_scaling = 1, \n                                    class_weight = None, random_state = None, solver = \"saga\", max_iter = 250, multi_class = \"ovr\", \n                                    verbose = 0, warm_start = False, n_jobs = 1)\n        logreg.fit(tfidf_train, y_train)\n        train_pred = logreg.predict(tfidf_train)\n        valid_pred = logreg.predict(tfidf_valid)\n        accuracy_train[penalty][j] = accuracy_score(y_train, train_pred)\n        accuracy_valid[penalty][j] = accuracy_score(y_valid, valid_pred)\n        f1_train[penalty][j] = f1_score(y_train, train_pred, average = \"weighted\")\n        f1_valid[penalty][j] = f1_score(y_valid, valid_pred, average = \"weighted\")\n        precision_train[penalty][j] = precision_score(y_train, train_pred, average = \"weighted\")\n        precision_valid[penalty][j] = precision_score(y_valid, valid_pred, average = \"weighted\")\n        recall_train[penalty][j] = recall_score(y_train, train_pred, average = \"weighted\")\n        recall_valid[penalty][j] = recall_score(y_valid, valid_pred, average = \"weighted\")\n        end_time = time.time()\n        print(\"(\"+str((i*30)+(j+1))+\") Finished penalty=\"+penalty+\", C=\"+str(C)+\" in \"+str(end_time - start_time)+\"s\")\n    accuracy_diff[penalty] = np.absolute(accuracy_train[penalty] - accuracy_valid[penalty])\n    f1_diff[penalty] = np.absolute(f1_train[penalty] - f1_valid[penalty])\n    precision_diff[penalty] = np.absolute(precision_train[penalty] - precision_valid[penalty])\n    recall_diff[penalty] = np.absolute(recall_train[penalty] - recall_valid[penalty])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e15aca0a04ddff44f945e55e02c3cfaafae955a0"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 4, ncols = 2)\nfig.set_size_inches(2.0*xsize, 4.0*ysize)\n\naxes = np.array(axes).flatten()\n\naxes[0].semilogx(Cs, accuracy_train[\"L1\"], \"o:\", label = \"Train\")\naxes[0].semilogx(Cs, accuracy_valid[\"L1\"], \"o:\", label = \"Valid\")\naxes[0].semilogx(Cs, accuracy_diff[\"L1\"], \"o:\", label = \"Difference\")\naxes[0].set_title(\"Accuracy Metrics vs Inverse Regularization of Strength with L1 Penalty\")\naxes[0].set_ylabel(\"Accuracy Metrics\")\naxes[0].set_xlabel(\"Inverse Regularization of Strength\")\naxes[0].legend()\n\naxes[1].semilogx(Cs, accuracy_train[\"L2\"], \"o:\", label = \"Train\")\naxes[1].semilogx(Cs, accuracy_valid[\"L2\"], \"o:\", label = \"Valid\")\naxes[1].semilogx(Cs, accuracy_diff[\"L2\"], \"o:\", label = \"Difference\")\naxes[1].set_title(\"Accuracy Metrics vs Inverse Regularization of Strength with L2 Penalty\")\naxes[1].set_ylabel(\"Accuracy Metrics\")\naxes[1].set_xlabel(\"Inverse Regularization of Strength\")\naxes[1].legend()\n\naxes[2].semilogx(Cs, f1_train[\"L1\"], \"o:\", label = \"Train\")\naxes[2].semilogx(Cs, f1_valid[\"L1\"], \"o:\", label = \"Valid\")\naxes[2].semilogx(Cs, f1_diff[\"L1\"], \"o:\", label = \"Difference\")\naxes[2].set_title(\"F1 Metrics vs Inverse Regularization of Strength with L1 Penalty\")\naxes[2].set_ylabel(\"F1 Metrics\")\naxes[2].set_xlabel(\"Inverse Regularization of Strength\")\naxes[2].legend()\n\naxes[3].semilogx(Cs, f1_train[\"L2\"], \"o:\", label = \"Train\")\naxes[3].semilogx(Cs, f1_valid[\"L2\"], \"o:\", label = \"Valid\")\naxes[3].semilogx(Cs, f1_diff[\"L2\"], \"o:\", label = \"Difference\")\naxes[3].set_title(\"F1 Metrics vs Inverse Regularization of Strength with L2 Penalty\")\naxes[3].set_ylabel(\"F1 Metrics\")\naxes[3].set_xlabel(\"Inverse Regularization of Strength\")\naxes[3].legend()\n\naxes[4].semilogx(Cs, precision_train[\"L1\"], \"o:\", label = \"Train\")\naxes[4].semilogx(Cs, precision_valid[\"L1\"], \"o:\", label = \"Valid\")\naxes[4].semilogx(Cs, precision_diff[\"L1\"], \"o:\", label = \"Difference\")\naxes[4].set_title(\"Precision Metrics vs Inverse Regularization of Strength with L1 Penalty\")\naxes[4].set_ylabel(\"Precision Metrics\")\naxes[4].set_xlabel(\"Inverse Regularization of Strength\")\naxes[4].legend()\n\naxes[5].semilogx(Cs, precision_train[\"L2\"], \"o:\", label = \"Train\")\naxes[5].semilogx(Cs, precision_valid[\"L2\"], \"o:\", label = \"Valid\")\naxes[5].semilogx(Cs, precision_diff[\"L2\"], \"o:\", label = \"Difference\")\naxes[5].set_title(\"Precision Metrics vs Inverse Regularization of Strength with L2 Penalty\")\naxes[5].set_ylabel(\"Precision Metrics\")\naxes[5].set_xlabel(\"Inverse Regularization of Strength\")\naxes[5].legend()\n\naxes[6].semilogx(Cs, recall_train[\"L1\"], \"o:\", label = \"Train\")\naxes[6].semilogx(Cs, recall_valid[\"L1\"], \"o:\", label = \"Valid\")\naxes[6].semilogx(Cs, recall_diff[\"L1\"], \"o:\", label = \"Difference\")\naxes[6].set_title(\"Recall Metrics vs Inverse Regularization of Strength with L1 Penalty\")\naxes[6].set_ylabel(\"Recall Metrics\")\naxes[6].set_xlabel(\"Inverse Regularization of Strength\")\naxes[6].legend()\n\naxes[7].semilogx(Cs, recall_train[\"L2\"], \"o:\", label = \"Train\")\naxes[7].semilogx(Cs, recall_valid[\"L2\"], \"o:\", label = \"Valid\")\naxes[7].semilogx(Cs, recall_diff[\"L2\"], \"o:\", label = \"Difference\")\naxes[7].set_title(\"Recall Metrics vs Inverse Regularization of Strength with L2 Penalty\")\naxes[7].set_ylabel(\"Recall Metrics\")\naxes[7].set_xlabel(\"Inverse Regularization of Strength\")\naxes[7].legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8549c0bbeb6420e7b4a93e4652da831a87906209"},"cell_type":"code","source":"xx = np.argmax(accuracy_valid[\"L1\"])\nyx = np.argmax(accuracy_valid[\"L2\"])\nprint(\"Max L1 validation accuracy is at C=\"+str(Cs[xx]))\nprint(\"Train Accuracy : \"+str(accuracy_train[\"L1\"][xx]))\nprint(\"Valid Accuracy : \"+str(accuracy_valid[\"L1\"][xx]))\nprint(\"Difference Accuracy : \"+str(accuracy_diff[\"L1\"][xx]))\nprint(\"Max L2 validation accuracy is at C=\"+str(Cs[yx]))\nprint(\"Train Accuracy : \"+str(accuracy_train[\"L2\"][yx]))\nprint(\"Valid Accuracy : \"+str(accuracy_valid[\"L2\"][yx]))\nprint(\"Difference Accuracy : \"+str(accuracy_diff[\"L2\"][yx]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9347e7f955b5af208e45af5fc591c7aa0539fb6c"},"cell_type":"code","source":"logreg = LogisticRegression(dual = False, tol = 1e-5, fit_intercept = True, intercept_scaling = 1, class_weight = None, \n                            random_state = None, solver = \"saga\", max_iter = 1000, multi_class = \"ovr\", \n                            verbose = 0, warm_start = False, n_jobs = 1)\nparams = {\n    \"penalty\": [\"L1\", \"L2\"],\n    \"C\": stats.lognorm(0.75, scale = Cs[xx])\n}\nclf = RandomizedSearchCV(logreg, params, scoring = \"accuracy\", cv = 5)\nclf.fit(tfidf_train, y_train)\nprint(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a7c6dc57fd966c571941be565a359f35dff0e22"},"cell_type":"code","source":"print(clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1de26a3368fd5221a5238ff3d5a5775f3034e04"},"cell_type":"code","source":"C_best = clf.best_params_[\"C\"]\npenalty_best = clf.best_params_[\"penalty\"]\n\ntfidf_vectorizer = TfidfVectorizer(analyzer = \"word\", preprocessor = lambda x: x, tokenizer = lambda x: x, token_pattern = None)\ntfidf = tfidf_vectorizer.fit_transform(train_df[\"ingredients\"])\n\nle = LabelEncoder()\ny = le.fit_transform(train_df[\"cuisine\"])\n\nlogreg = LogisticRegression(dual = False, tol = 1e-5, fit_intercept = True, intercept_scaling = 1, class_weight = None, \n                            random_state = None, solver = \"saga\", max_iter = 100000, multi_class = \"ovr\", \n                            verbose = 0, warm_start = False, n_jobs = 1, C = C_best, penalty = penalty_best)\nlogreg.fit(tfidf, y)\npred = logreg.predict(tfidf)\nprint(\"Accuracy: \"+str(accuracy_score(y, pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78b347030f9e8c454bba0c7bd4d0ac2f3a933710"},"cell_type":"code","source":"test_df = pd.read_json(\"../input/test.json\").set_index(\"id\")\ntest_tfidf = tfidf_vectorizer.transform(test_df[\"ingredients\"])\npred_test = logreg.predict(test_tfidf)\ntest_df[\"cuisine\"] = le.inverse_transform(pred_test)\ntest_df.drop(columns = [\"ingredients\"], inplace = True)\ntest_df.to_csv(\"tuned_logistic_regression_submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}