{"cells":[{"metadata":{"_uuid":"11fc3ba21a35be2224f178ff315f392c7c1061c3"},"cell_type":"markdown","source":"# <center> Vowpal Wabbit starter\n## <center> Training while reading \n    \n![](https://habrastorage.org/webt/je/do/29/jedo293npvm0uytxuwx-4goid2e.jpeg)\n\n\nIn this kernel, we train a model just on the fly while reading data. If you are in doubt how it's even possible - take a look at [this tutorial](https://www.kaggle.com/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning) on Vowpal Wabbit. We'll skip basic EDA and feature engineering (for that you can pick any kernel, ex. [this one]([this EDA](https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated)). We are not going to beat cool baselines with this model, but it's a nice and fast starter.  "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import math\nimport pandas as pd\nfrom datetime import datetime\nfrom vowpalwabbit import pyvw","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ec7ed4a7606ad994c863e8a1a95f1b8e9d5f943"},"cell_type":"markdown","source":"**Read feature names from the header of the test set.**"},{"metadata":{"trusted":true,"_uuid":"10dd3fdde419ebff46d240e1ce7cd5230bd9db60"},"cell_type":"code","source":"with open('../input/test.csv') as f:\n    # skip header\n    feature_names = f.readline().strip().split(',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d2af2c8e362ad0608eb67ac15c8434026b416a6"},"cell_type":"markdown","source":"**We'll drop features with too many unique values, too many missing values, and too imbalanced value distribution. Motivated by [this EDA](https://www.kaggle.com/artgor/is-this-malware-eda-fe-and-lgb-updated) by Andrew Lukyanenko.**"},{"metadata":{"trusted":true,"_uuid":"b73d4d7775d1867cb60c8f5c3477579e5f9cd6bc"},"cell_type":"code","source":"too_many_unique_vals = ['MachineIdentifier',\n                        'Census_FirmwareVersionIdentifier',\n                        'Census_OEMModelIdentifier',\n                        'CityIdentifier'\n                       ]\ntoo_many_nas = ['PuaMode',\n                'Census_ProcessorClass',\n                'DefaultBrowsersIdentifier',\n                'Census_IsFlightingInternal',\n                'Census_InternalBatteryType',\n                'Census_ThresholdOptIn',\n                'Census_IsWIMBootEnabled'\n               ]\n\ntoo_imbalanced = ['Census_IsFlightsDisabled',\n                  'Census_IsAlwaysOnAlwaysConnectedCapable',\n                  'AVProductsEnabled',\n                  'IsProtected',\n                  'RtpStateBitfield',\n                  'Census_IsVirtualDevice',\n                  'Census_IsPortableOperatingSystem',\n                  'Census_IsPenCapable',\n                  'Census_FlightRing',\n                  'OsVer',\n                  'IsBeta',\n                  'Platform',\n                  'AutoSampleOptIn',\n                  'Census_DeviceFamily',\n                  'ProductName'\n                 ]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aafebb0fae34386fc2001d93d84dc2bcc1122ff4"},"cell_type":"markdown","source":"Let's figure out ids of numeric and categorical features that we'll used for prediction. Inspired by [this post](https://www.kaggle.com/c/microsoft-malware-prediction/discussion/75396) by Aditya Soni."},{"metadata":{"trusted":true,"_uuid":"0f1060660da3da9daf573cd73fbffdbc34a8d309"},"cell_type":"code","source":"numeric_column_ids = [\n    38,  # Census_ProcessorCoreCount\n    42,  # Census_PrimaryDiskTotalCapacity\n    44,  # Census_SystemVolumeTotalCapacity\n    46,  # Census_TotalPhysicalRAM\n    48,  # Census_InternalPrimaryDiagonalDisplaySizeInInches\n    49,  # Census_InternalPrimaryDisplayResolutionHorizontal\n    50,  # Census_InternalPrimaryDisplayResolutionVertical\n    53   # Census_InternalBatteryNumberOfCharges  \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06b5e24478315356075ea4149a98efafc73cdff7"},"cell_type":"code","source":"categorical_column_ids = [i for i, feat_name in zip(range(len(feature_names)), feature_names) \n                          if (feat_name not in too_many_unique_vals + too_many_nas + too_imbalanced\n                          and i not in numeric_column_ids)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31404d0867da76b5b831f08f8066d36988165016"},"cell_type":"markdown","source":"Thus we have 48 categorical features and 8 numeric ones."},{"metadata":{"trusted":true,"_uuid":"0b2bfa717ec08410d48d693dcac14502cc8e2186"},"cell_type":"code","source":"len(categorical_column_ids), len(numeric_column_ids)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d34d1ee63f405e0ce209f5d237df26579dc95735"},"cell_type":"markdown","source":"The following function converts a string to Vowpal Wabbit format. Take a look at [this tutorial](https://www.kaggle.com/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning) on VW to understand the format. "},{"metadata":{"trusted":true,"_uuid":"545455e8147cb32974c1adbd3d5605c9324f1466"},"cell_type":"code","source":"def to_vw(line, categ_column_ids, num_column_ids, column_names, train=True):\n    \"\"\"\n    Converts a string to VW format.\n    \n    :param line: a string with comma-separated feature values, str\n    :param categ_column_ids: ids of categorical features, list\n    :param num_column_ids: ids of numeric features, list\n    :param column_names: column (or feature) names to use (both categorical and numeric), list\n    :param train: whether the line belongs to a training set\n    :return: processed line, str\n    \"\"\"\n    values = line.strip().split(',')\n    # VW treats '|' and ':' as special symbols, so jnust in case we'll replace them\n    for i in range(len(values)):\n        values[i] = values[i].replace('|', '').replace(':', '')\n    label = '-1'\n    if train:\n        label, values = values[-1], values[:-1] \n        # in case of binary classification, VW eats labels 1 and -1, so 1 -> 1, 0 -> -1\n        label = str(2 * int(label) - 1)\n    \n    # for categorical features, we fill in missing values with 'unk'\n    for i in categ_column_ids:\n        if not values[i]:\n            values[i] = 'unk'\n            \n    # for numeric features, we fill in missing values with '-1'\n    for i in num_column_ids:\n        if values[i] == '':\n            values[i] = '-1'\n    \n    categ_vw = ' '.join(['{}={}'.format(column_names[i], values[i])\n                           for i in categ_column_ids])\n    # we apply log1p transformation to numeric features\n    numeric_vw = ' '.join(['{}:{}'.format(column_names[i],round(math.log(1 + float(values[i]) + 1e-10)))\n                           for i in num_column_ids])\n    \n    new_line = label + ' |num ' + numeric_vw + ' |cat ' + categ_vw\n    return new_line","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cb25489e6270a2dee4439f10ceec05525e51152"},"cell_type":"markdown","source":"**Let's see how this function processes the first line from the test set.** "},{"metadata":{"trusted":true,"_uuid":"a78da10ca11c275f654c122021c8858d4684e605"},"cell_type":"code","source":"line = '0000010489e3af074adeac69c53e555e,win8defender,1.1.15400.5,4.18.1810.5,1.281.501.0,0,7,0,,53447,1,1,1,43,58552,18,53,42,windows10,x64,10.0.0.0,15063,768,rs2,15063.0.amd64fre.rs2_release.170317-1834,Home,1,0,,,108,,1,1,Notebook,Windows.Desktop,2689,30661,4,5,3063,,488386,SSD,123179,0,8192,Notebook,15.5,1920,1080,Mobile,,8,10.0.15063.1387,amd64,rs2_release,15063,1387,Core,CORE,Reset,37,158,AutoInstallAndRebootAtMaintenanceTime,0,IS_GENUINE,OEM:DM,,0,Retail,,807,8554,1,,0,0,0,0,0,7'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ee6ec1a40db38e7cfe02ee2d1d9ee79e07f7e14"},"cell_type":"code","source":"to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fb53214701f5a1f2a3a0efd0d69af9aba1d232a"},"cell_type":"markdown","source":"**Reading training data and training Vowpal Wabbit on the fly.**"},{"metadata":{"trusted":true,"_uuid":"248c903fe4cdf04be559964e6a2474c56bc43ea2"},"cell_type":"code","source":"vw = pyvw.vw(b=28, random_seed=17, loss_function='logistic', passes=3, learning_rate=0.7, k=True, c=True, \n             link='logistic', quiet=True)\nwith open('../input/train.csv') as f:\n    # skip header\n    f.readline()\n    start_time = datetime.now()\n    for i, line in enumerate(f):\n        # print when the next 1 mln examples is processed\n        if i % 1e5 == 0: print(\"{}\\t{} passed.\".format(i, datetime.now() - start_time))\n        # training Vowpal Wabbit with current example\n        vw.learn(to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a44e9bde8becfa0b1b06ff3a97d20e9443534a05"},"cell_type":"markdown","source":"**Reading test data and making predictions on the fly.**"},{"metadata":{"trusted":true,"_uuid":"959e47894862df32c2c78233ec06926a64d5e4c9"},"cell_type":"code","source":"predictions = []\nwith open('../input/test.csv') as f:\n    # skip header\n    f.readline()\n    start_time = datetime.now()\n    for i, line in enumerate(f):\n        # print when the next 1 mln examples is processed\n        if i % 1e5 == 0: print(\"{}\\t{} passed.\".format(i, datetime.now() - start_time))\n        # add Vowpal Wabbit prediction for the current example\n        predictions.append(vw.predict(to_vw(line, categorical_column_ids, numeric_column_ids, feature_names, train=False)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6d02c795d63069c8bc1fafe0f14853ef142a2c4"},"cell_type":"markdown","source":"**Form the submission file**"},{"metadata":{"trusted":true,"_uuid":"cea9aece682ddceca09a35c975670b34382a951a"},"cell_type":"code","source":"subm_df = pd.read_csv('../input/sample_submission.csv', index_col='MachineIdentifier')\nsubm_df['HasDetections'] = predictions\nsubm_df.to_csv('submission.csv', header=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efcd1fdcf6c8b7681cf52582868737d1a259b71d"},"cell_type":"markdown","source":"**What was skipped here and what can be improved**\n* train/test split: local validation gave showed ROC AUC 0.70838 for 30% holdout set\n* hyperparam tuning: this was done with [vw-hyperopt](https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/utl/vw-hyperopt.py), take a look at [this Hyperopt tutorial](https://www.kaggle.com/ilialar/hyperparameters-tunning-with-hyperopt)\n* feature engineering: explore other kernels, come up with good features, add them, and see your AUC rise! \n* blending: well, this solutions doesn;t result in a high AUC but try to blend this model predictions with some others"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}