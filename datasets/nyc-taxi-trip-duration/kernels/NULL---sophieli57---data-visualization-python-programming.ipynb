{"cells":[{"metadata":{"_uuid":"fcfbd787a9a913c5d6543a47fe835f544f5f87bc"},"cell_type":"markdown","source":"**Hi, Everyone ! We are going to get into the intro of the python programming and data visualization. **\n\n![NewYorkTaxi](https://steamcdn-a.akamaihd.net/steam/apps/446470/header.jpg?t=1457089684)\n\nSuppose you are hired by the New York City Transportation to analyze the GPS data of the yellow cabs. \n\n**New York Taxi Background: **\nThe taxi and livery system in New York City is the fourth largest transportation provider in the United States. The system is regulated by the New York City Taxi and Limousine Commission (TLC), which oversees yellow taxis, for-hire vehicles, commuter vans, paratransit vehicles, and certain limousines. Despite the scale of the taxi and livery network, the existing system of yellow taxis and for-hire vehicles did not adequately serve all of the boroughs of New York City. Riders in Queens, the Bronx, Brooklyn, Staten Island, and Upper Manhattan had been left out in the cold, too often literally. \n\n**Problems with the New York Taxi: **\nThe pick-up locations are too concentrated on Mid-town and Airport areas. That is to say inadequate taxi service across the five boroughs of New York City prompted the City to undertake an assessment of the existing regulations that governed taxi service to identify opportunities for reform.\n\nTo rephrase the question here: How to balance the supply and demand in New York city cabs ? \n\n**The government collect the following data:**\nThe competition dataset is based on the 2016 NYC Yellow Cab trip record data made available in Big Query on Google Cloud Platform. The data was originally published by the NYC Taxi and Limousine Commission (TLC). The data was sampled and cleaned for the purposes of this playground competition. Based on individual trip attributes, participants should predict the duration of each trip in the test set. **( Data Description by Kaggle) **\n\n**Data fields:**\n* id - a unique identifier for each trip\n* vendor_id - a code indicating the provider associated with the trip record\n* pickup_datetime - date and time when the meter was engaged\n* dropoff_datetime - date and time when the meter was disengaged\n* passenger_count - the number of passengers in the vehicle (driver entered value)\n* pickup_longitude - the longitude where the meter was engaged\n* pickup_latitude - the latitude where the meter was engaged\n* dropoff_longitude - the longitude where the meter was disengaged\n* dropoff_latitude - the latitude where the meter was disengaged\n* store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n* trip_duration - duration of the trip in seconds\n\n**Think about the following questions: <br/>**\n(1) In order to solve the problem, what other data do you need except for the Geospatial data ?   <br/>\n(2) Given the sample data, could you think of what kind of things you need to know before you really do the analysis ? Please hand draw graphs to show what you think ! \n"},{"metadata":{"_uuid":"0db9362d78c3d1472c526a3dc6984d8a4977f554"},"cell_type":"markdown","source":"**Python Basics:** <br/> \n\n*  Open Source:  Anyone could contribute and use without liscense </br> \n*  Object Oriented Design: \n*  Memory Based \n* Flexibility and multifunction\n\n----------------------------------------------------------------------------------------------------------------------\n**What we aim to achieve today ? **\n\n* Understand what are packages/libraries ? \n\n* What are the visualization packages in Python ? \n\n* How to plot/draw visualization tools in Python/ any programming languages ? "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport folium as folium #folium would be the map concentrated package to draw fancy map on the canvas and folium is a wrapper of leafjs \nimport seaborn as sns # another pretty plot package that is based on matplot package in python\nimport missingno as msno #showing the missing value of the dataset\nimport matplotlib.pyplot as plt #basic plots for matplot \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6795874f6d955999ac7569a2eb0abf94fbd74ae5"},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/nyc-taxi-trip-duration/train/\"]).decode(\"utf8\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#check out the data\ntitanic = pd.read_csv(\"../input/titantic/train.csv\")\n#train = pd.read_csv(\"../input/ny-taxi-trip-duration/train.zip/train.csv\") \n\n#find the path in the file path and output the file\ntrain=pd.read_csv(\"../input/nyc-taxi-trip-duration/train/train.csv\")\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bbdcb2842e9d72658c0a86ba0ff6437f7488b76"},"cell_type":"code","source":"#there are two ways to make a basic summary in python compared to R, describe function and info function \nsummary = train.describe() \nsummary ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f771fe7d9b66651c3d33103775f47517975c706"},"cell_type":"code","source":"#Like SAS,you could input what you want for decile and output the summary function\nperc = [0.2,0.4,0.6,0.8]\ninclude = ['object','float','int']\ndesc = train.describe(percentiles = perc,include= include)\ndesc\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ac5f9f56483b56bb89b222b5be790d83a3ba01"},"cell_type":"code","source":"#panda dataframe could check the over missing values\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f549ab8f1b72853f6e84c487d7febfe47799fea"},"cell_type":"markdown","source":"**There are two ways to check missing values, one is to use the pandas info function, the other is to use visualization technique. Python has  data visualization packages to manipulate different kinds of datasets. The most common ones for static data are matplotlib and plotly. These two packages could always offer the best basic plots for two dimensional data. Later on, python developed more advanced data visualization packages like Seaborn, and Bokeh, which are interactive and javascript based**"},{"metadata":{"trusted":true,"_uuid":"9c87016c8c6142c6527d536c3b1af36d09c9c7c9"},"cell_type":"code","source":"#ways to visualizing the missing values,in thie particular dataset,wecould see that none of the data has missing values. \nsns.heatmap(train.isnull(), cbar=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87d366cbe2bb47d076166c812a0c56b6018abc94"},"cell_type":"code","source":"#another example of showing different missing value datasets. \nsns.heatmap(titanic.isnull(),cbar=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fccbf5b20572b2484eb203858ae9f51707a0021f"},"cell_type":"code","source":"#python has another package missing no speicalizing in missing value data visualization \nmsno.matrix(titanic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f201faf11bc63a2aa5c3ba36d008bf87f1b98bd"},"cell_type":"code","source":"#Showing Distribution of the dataset \nsns.distplot(train['trip_duration'],color = 'skyblue',label = 'trip_duration')\nplt.legend()\n#plt.xlim(0,35000)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e0fa0af1567abcfeed5ebfcea2765ce77a18948"},"cell_type":"code","source":"#conver all the seconds into minutes and plot a better duration \ntrain['trip_dur_to_m'] = round(train['trip_duration']/60,0)\ntrain.head(10)\n\n#generate a distribution/freq table \ntrain.trip_dur_to_m.value_counts(sort=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77ebe885235666ba0defc9db53f5256009c4150c"},"cell_type":"code","source":"#plot the duration distribution again\n#initialize a figuresize plot\nfig, ax = plt.subplots(figsize=(14, 4))\ntripduration = train[train.trip_dur_to_m < train.trip_dur_to_m.quantile(.97)]\ntripduration.groupby('trip_dur_to_m').count()['id'].plot()\n\n#add the label to each plot \nplt.xlabel('Trip duration in minutes')\nplt.ylabel('Trip count')\nplt.title('Duration distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6ba5f994d304509d0038b9b1451975f5aca9698"},"cell_type":"code","source":"#Showing the passagers Distribution \nsns.distplot(train['passenger_count'],color = 'red',label = 'passenger_count')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af72c31424e301a14b4db7389cbed609fc746b76"},"cell_type":"code","source":"#the improved way to plot this distribution graph \n#distribution plot \nsns.distplot(train.passenger_count,color = 'orange',kde=False, bins=train.passenger_count.max(), \n                vertical=True, axlabel=\"Passengers distribution\");\ntrain.passenger_count.value_counts(sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d54db8518d5829c04c553b983292defd2e7b9e8"},"cell_type":"code","source":"#plot by vendor id \nvendor_id_count = train['vendor_id'].value_counts() \n#the data structure here is series, so this one should be sorted by inex \nvendor_id_count.sort_index \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae37920738f8bfdb3664ff159463dd3f1b952c48"},"cell_type":"code","source":"#barplot example for vendor id \nsns.barplot(x= vendor_id_count.values,y= vendor_id_count.index,data=vendor_id_count,palette='Set2')\nplt.xlabel('vendor_id')\nplt.ylabel('total rides')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4414d45a0ebc8622fc4ab87f106e23c49c95de1f"},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88ef5910e987958d43a3516124f96caa6695ddcd"},"cell_type":"code","source":"tripduration = train[train.trip_dur_to_m < train.trip_dur_to_m.quantile(.97)]\ntripduration.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d60178c72a436b5630335d71e3c12bad7a392fee"},"cell_type":"code","source":"#extract date/time from the dataset\n#extract columns from two data timestamps\ndef extract_time_interval(df,colname,start,end):\n    df_c = df.copy() \n    df_c[f'{colname}'] = (df_c[end] - df_c[start]).astype('timedelta64[m]')\n    return df_c \n\nimport datetime\n\n#extract all the date and time \n#type(train['pickup_datetime'])\ndef datetime_extract(df, columns, modeling=False):\n    df_ = df.copy()\n    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n    for col in columns:\n        try:\n            prefix = col\n            if \"_\" in col:\n                prefix = col.split(\"_\")[0]\n            ts = f\"{prefix}_ts\"\n            df_[ts] = pd.to_datetime(df_[col])\n            df_[f\"{prefix}_month\"] = df_[ts].dt.month\n            df_[f\"{prefix}_weekday\"] = df_[ts].dt.weekday\n            df_[f\"{prefix}_day\"] = df_[ts].dt.day\n            df_[f\"{prefix}_hour\"] = df_[ts].dt.hour\n            df_[f\"{prefix}_minute\"] = df_[ts].dt.minute\n            if not modeling: \n                df_[f\"{prefix}_date\"] = df_[ts].dt.date\n                df_[f\"{prefix}_dayname\"] = df_[f\"{prefix}_weekday\"].apply(lambda x: day_names[x])\n            else:\n                df_.drop(columns=[ts, col], axis = 1)\n        except:\n            pass\n    return df_\n\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed4b2810901fbeec7fb99360dcdedebd5c6dc4bb"},"cell_type":"code","source":"train = datetime_extract(train, ['pickup_datetime', 'dropoff_datetime'])\ntrain.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71a433f1a2f932f09f39c10bc6454bb804623ca7"},"cell_type":"code","source":"train_time = extract_time_interval(train, 'delta_m', 'pickup_ts', 'dropoff_ts')\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4ae40114ce3ffaabf563fa40b3b3b062e255930"},"cell_type":"code","source":"#time series plot \n#count the passgeners during the day \nfig, ax = plt.subplots(ncols=2, figsize=(14, 5))\nfor i, col in enumerate(['pickup', 'dropoff']):\n    ax[i].plot(train.groupby([f'{col}_date']).sum()['passenger_count'])\n    ax[i].set(xlabel='Months', ylabel=\"Total passengers\", title=\"Total passengers per date\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d53be1f23604c8081ea433724d60a116c228484e"},"cell_type":"code","source":"#Import Libraries\nfrom bokeh.models import BoxZoomTool\nfrom bokeh.plotting import figure, output_notebook, show\nimport datashader as ds\nfrom datashader.bokeh_ext import InteractiveImage\nfrom functools import partial\nfrom datashader.utils import export_image\nfrom datashader.colors import colormap_select, Greys9, Hot, inferno,Set1\nfrom datashader import transfer_functions as tf\noutput_notebook()\n\n#plot datapoints by location coordinates\ndef plot_data_points(longitude,latitude,data_frame,focus_point) :\n    #plot dimensions\n    x_range, y_range = ((-74.14,-73.73), (40.6,40.9))\n    plot_width  = int(750)\n    plot_height = int(plot_width//1.2)\n    export  = partial(export_image, export_path=\"export\", background=\"black\")\n    fig = figure(background_fill_color = \"black\")    \n    #plot data points\n    cvs = ds.Canvas(plot_width=plot_width, plot_height=plot_height,\n                    x_range=x_range, y_range=y_range)\n    agg = cvs.points(data_frame,longitude,latitude,\n                      ds.count(focus_point))\n    img = tf.shade(agg, cmap= Hot, how='eq_hist')\n    image_xpt  =  tf.dynspread(img, threshold=0.5, max_px=4)\n    return export(image_xpt,\"NYCT_hot\")\n\nplot_data_points('pickup_longitude', 'pickup_latitude',train,\"passenger_count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35530fa8f2333c75e52bea033bc48bef91917c58","scrolled":true},"cell_type":"code","source":"plot_data_points('dropoff_longitude', 'dropoff_latitude',train,\"passenger_count\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ef2910139b1106cf1cf3e32b4883de577e72662"},"cell_type":"markdown","source":"# generate pairs of x-y values\ntheta = seq(-2 * pi, 2 * pi, length = 300)\nx = cos(theta)\ny = x + sin(theta) \n \n# set graphical parameters\nop = par(bg = \"white\", mar = rep(0.1, 4))\n \n# plot\nplot(x, y, type = \"n\", xlim = c(-8, 8), ylim = c(-1.5, 1.5))\nfor (i in seq(-2*pi, 2*pi, length = 100))\n{\n  lines(i*x, y, col = hsv(runif(1, 0.85, 0.95), 1, 1, runif(1, 0.2, 0.5)), \n        lwd = sample(seq(.5, 3, length = 10), 1))          \n}\n \n# signature\nlegend(\"bottom\", legend = \"Sophie Champagne\", bty = \"n\", text.col = \"gray70\")"},{"metadata":{"_uuid":"e5d9ca6616a9d484f61d2a0e81761212ae584643"},"cell_type":"markdown","source":"**Reference:** \n\n* [FlowingData](https://flowingdata.com/) \n\n* [MOMA data visualization](https://www.moma.org/explore/inside_out/2015/12/10/data-visualization-design-and-the-art-of-depicting-reality/) \n\n* [Art made of data](https://www.ted.com/playlists/201/art_from_data) \n\n* [Modern Art Gallery](https://www.r-graph-gallery.com/portfolio/data-art/) \n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}