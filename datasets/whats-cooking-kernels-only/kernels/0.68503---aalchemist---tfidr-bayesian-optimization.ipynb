{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nimport pandas as pd\nimport json","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def read_dataset(path):\n    return json.load(open(path))\nfrom random import shuffle\ntrain = read_dataset('../input/train.json')\nshuffle(train)\ntest = read_dataset('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a1c69abec2cea23c064313b285048809729f66ad"},"cell_type":"code","source":"def generate_text(data):\n    text_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n    return text_data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1203dbd011854b01114238be1a342979128e9e8a"},"cell_type":"code","source":"train_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13ce0d73f7a8f05ecbbcbada0ea6899d99ae5b95","collapsed":true},"cell_type":"code","source":"# Feature Engineering \nprint (\"TF-IDF on text data ... \")\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(txt, flag):\n    if flag == \"train\":\n        x = tfidf.fit_transform(txt)\n    else:\n        x = tfidf.transform(txt)\n    #x = x.astype('float16')\n    return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"379a748baeed61cd564ef43cde3b0a4beab6aa5a","collapsed":true},"cell_type":"code","source":"X = tfidf_features(train_text, flag=\"train\")\nX_test = tfidf_features(test_text, flag=\"test\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae06e5a62251602c6496b2d5f09759ba06b3e3df","collapsed":true},"cell_type":"code","source":"X=X.toarray().tolist()\nX_test = X_test.toarray().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e01fe550e9f53a485339f922a7a2278ca2a9d129"},"cell_type":"code","source":"lb = LabelEncoder()\ny = lb.fit_transform(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57f26cc19c030a9ad4266232e0ae7a0b44f8a264","collapsed":true},"cell_type":"code","source":"'''from sklearn import decomposition\nlength1 = len(X)\nlength2=  len(X_test)\nxlines=X[:]+X_test[:]\nlength3=len(xlines)\nprint(length1, length2, length3)\nLENGTH= 500\npca = decomposition.PCA(n_components=LENGTH)\npca.fit(xlines)\nxlines = pca.transform(xlines)\nxlines=xlines.tolist()\nprint(len(xlines[0]))\nX = xlines[0: length1]\nX_test = xlines[length1:]\nprint(len(X), len(X_test))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"555ac08c0d720b87ee315064849ee591ed409f92"},"cell_type":"code","source":"from bayes_opt import BayesianOptimization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2f7486858f7fa660e911a41cda83cfd7b0608b8","collapsed":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n'''def evaluate(gamma,C,degree ):\n    classifier = SVC(C=C, # penalty parameter, setting it to a larger value \n                 kernel='rbf', # kernel type, rbf working fine here\n                 degree=degree, # default value, not tuned yet\n                 gamma=gamma, # kernel coefficient, not tuned yet\n                 coef0=1, # change to 1 from default value of 0.0\n                 shrinking=True, # using shrinking heuristics\n                 tol=0.001, # stopping criterion tolerance \n                 probability=False, # no need to enable probability estimates\n                 cache_size=200, # 200 MB cache size\n                 class_weight='balanced', # all classes are treated equally \n                 verbose=0, # print the logs \n                 max_iter=10, # no limit, let it run\n                 decision_function_shape=None, # will use one vs rest explicitly \n                 random_state=None)\n    model = OneVsRestClassifier(classifier, n_jobs=-1)\n    model.fit(X[0:33000], y[0:33000])\n    return model.score(X[33000:],y[33000:])\n    \nm=BayesianOptimization(evaluate, { \n           #\"kernel\" : [ 'poly', 'rbf', 'sigmoid'],\n           \"gamma\" : (1e-1 , 1e-4),\n           \"C\" : (100, 1000),\n    'degree':(2,4)\n    \n})'''\n'''def evaluate(ESTIMATOR,DEAPTH,LEAF ,MNC):\n    ESTIMATOR=int(ESTIMATOR)\n    DEAPTH=int(DEAPTH)\n    LEAF=int(LEAF)\n    MNC=int(MNC)\n    model = RandomForestClassifier(n_estimators=ESTIMATOR, criterion='gini',\n                                   max_depth=DEAPTH,\n                                   min_samples_split=MNC, \n                                    max_features=\"auto\", max_leaf_nodes=LEAF,\n                                   oob_score=True, n_jobs=-1, verbose=0)\n    model.fit(X[0:33000], y[0:33000])\n    ans= model.score(X[33000:],y[33000:])\n    #model.fit(X[7000:], y[7000:])\n    #ans+=model.score(X[:7000],y[:7000])\n    del(model)\n    return ans\nm=BayesianOptimization(evaluate, { \n           #\"kernel\" : [ 'poly', 'rbf', 'sigmoid'],\n           \"ESTIMATOR\" : (5 , 1000),\n           \"DEAPTH\" : (100, 5000),\n    'LEAF':(5,1000),\n    'MNC':(2,100)\n    \n})\n\n\n\nm.maximize(init_points=3, n_iter=10, acq='ei')'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2827cae778a24a0ff6f5894e52050548703e23e7","collapsed":true},"cell_type":"code","source":"#params = m.res['max']['max_params']\n#params['max_depth'] = float(params['max_depth'])\n#print(params)\n#'ESTIMATOR': 1000.0, 'DEAPTH': 1862.1660840628444, 'LEAF': 1000.0, 'MNC': 100.0}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38fdac8b62d41fc013c0980e5e9f70e355d9ee5f","collapsed":true},"cell_type":"code","source":"'''classifier = SVC(C=1000, # penalty parameter, setting it to a larger value \n                 kernel='rbf', # kernel type, rbf working fine here\n                 degree=3, # default value, not tuned yet\n                 gamma=5, # kernel coefficient, not tuned yet\n                 coef0=1, # change to 1 from default value of 0.0\n                 shrinking=True, # using shrinking heuristics\n                 tol=0.001, # stopping criterion tolerance \n                 probability=False, # no need to enable probability estimates\n                 cache_size=200, # 200 MB cache size\n                 class_weight='balanced', # all classes are treated equally \n                 verbose=False, # print the logs \n                 max_iter=-1, # no limit, let it run\n                 decision_function_shape=None, # will use one vs rest explicitly \n                 random_state=None)\nmodel = OneVsRestClassifier(classifier, n_jobs=-1)\nmodel.fit(X, y)'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c194218398ff61e5368a2d17fe0a90654769580a"},"cell_type":"code","source":"model = RandomForestClassifier(n_estimators=2000, criterion='gini',\n                                   max_depth=20000,\n                                   min_samples_split=200, \n                                    max_features=\"auto\", max_leaf_nodes=2000,\n                                   oob_score=True, n_jobs=-1, verbose=1)\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57a36772cf21d2168b837b158c6fb76cafdce56c"},"cell_type":"code","source":"\n\n\n\n\n# Label Encoding - Target \nprint (\"Label Encode the Target Variable ... \")\n\n\n# Model Training \nprint (\"Train the model ... \")\n\n\n# Predictions \nprint (\"Predict on test data ... \")\ny_test = model.predict(X_test)\ny_pred = lb.inverse_transform(y_test)\n\n# Submission\nprint (\"Generate Submission File ... \")\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eb9c0420485896651a18c6e3695d438470b6d66c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"817098f810e6d92d6f90c33d3c92132988725d5d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}