{"cells":[{"metadata":{"_cell_guid":"1f1ed8e1-2a04-d962-0ae5-865e37b1abe2","_uuid":"1b62110d8f86691423cba2dafce786887ad75a9a"},"cell_type":"markdown","source":"detecting nodules with opencv","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f2a3273c-c9db-8f47-8d08-fbfded82d6b6","_uuid":"67407d16853b8367886ce4ed77a8865f4dd82a0b","trusted":true},"cell_type":"code","source":"# USAGE\n# simply run it and open a dicom File\n## runs particularly weel with the case 12e0e2036f61c8a52ee4471bf813c36a/7e74cdbac4c6db70bade75225258119d.dcm\n# import the necessary packages\n\nimport matplotlib.pyplot as plt\nimport matplotlib.mlab as mlab\nimport scipy\nfrom skimage import measure\nimport numpy as np # numeric library needed\nimport pandas as pd #for dataframe\nimport argparse # simple argparser\n#import imutils\n#from imutils import contours\nimport cv2  # for opencv image recognising tool\nimport dicom\nfrom tkinter import Tk\nfrom tkinter.filedialog import askopenfilename\nimport pdb\n\n#filename = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\nfilename =\"../inputs/12e0e2036f61c8a52ee4471bf813c36a/7e74cdbac4c6db70bade75225258119d.dcm\"\ndicom_file = dicom.read_file(filename) ## original dicom File","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5727f56c-54ef-32a6-1180-d067041f9a05","_uuid":"33e1614c71189145ea888eced845188489a7db9e","trusted":false,"collapsed":true},"cell_type":"code","source":"#### a dicom monochrome file has pixel value between approx -2000 and +2000, opencv doesn't work with it#####\n#### in a first step we transform those pixel values in (R,G,B)\n### to have gray in RGB, simply give the same values for R,G, and B, \n####(0,0,0) will be black, (255,255,255) will be white,\n\n## the threeshold to be automized with a proper quartile function of the pixel distribution\nblack_threeshold=0###pixel value below 0 will be black,\nwhite_threeshold=1400###pixel value above 1400 will be white\nwt=white_threeshold\nbt=black_threeshold\n\n###### function to transform a dicom to RGB for the use of opencv, \n##to be strongly improved, as it takes to much time to run,\n## and the linear process should be replaced with an adapted weighted arctan function.\ndef DicomtoRGB(dicomfile,bt,wt):\n    \"\"\"Create new image(numpy array) filled with certain color in RGB\"\"\"\n    # Create black blank image\n    image = np.zeros((dicomfile.Rows, dicomfile.Columns, 3), np.uint8)\n    #loops on image height and width\n    i=0\n    j=0\n    while i<dicomfile.Rows:\n        j=0\n        while j<dicomfile.Columns:\n            color = yaxpb(dicom_file.pixel_array[i][j],bt,wt) #linear transformation to be adapted\n            image[i][j] = (color,color,color)## same R,G, B value to obtain greyscale\n            j=j+1\n        i=i+1\n    return image\n##linear transformation : from [bt < pxvalue < wt] linear to [0<pyvalue<255]: loss of information... \ndef yaxpb(pxvalue,bt,wt):\n    if pxvalue < bt:\n        y=0\n    elif pxvalue > wt:\n        y=255\n    else:\n        y=pxvalue*255/(wt-bt)-255*bt/(wt-bt)\n    return y\n    \n\n\nimage=DicomtoRGB(dicom_file,bt=0,wt=1400)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a22a484-1969-43a3-89fe-e26fecb069f3","_uuid":"6b052abdf6e90f279c0c5fd9ef93c3161bdd6518","trusted":false,"collapsed":true},"cell_type":"code","source":"##accesing image property pixel property and trying to find the mid pixel value dor the threesholding process\nw,h,bpp = np.shape(image)\npix=0\nfor py in range(0,h):\n    for px in range(0,w):\n        A=sum(image[py][px]) #store pixel property in A\n        pix=pix+A#store image pixel property in pix\n        \n##\nmoyenne= pix/(h*w*bpp)## accessing the average pixelvalue \n\n####### detecting lung region strongly inspired from detetect multiple bright spot, Adrian at Pyimage#####\n\n## loading the RGB in a proper opencv format\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n## look at the gray file\ncv2.imshow(\"gray\", gray)\ncv2.waitKey(0)\ncv2.destroyWindow(\"gray\")\n\n\n\n## blurring process, not mandatory\nblurred = cv2.GaussianBlur(gray, (11, 11), 0)\n\ncv2.imshow(\"Blurred\", blurred)\ncv2.waitKey(0)\ncv2.destroyWindow(\"Blurred\")\n# threshold the image to reveal light regions in the\n# blurred image\n# moyenne + 46 as thrreshold totaly empirical\nthresh = cv2.threshold(blurred, moyenne+46, 255, cv2.THRESH_BINARY)[1] ## to be automized\ncv2.imshow(\"threshold\", thresh)\ncv2.waitKey(0)\ncv2.destroyWindow(\"threshold\")\n\n#dilate = cv2.dilate(thresh, None, iterations=10)# for pic 2\ndilate = cv2.dilate(thresh, None, iterations=2)# TO BE AUTOMIZED\ncv2.imshow(\"dilate\", dilate)\ncv2.waitKey(0)\ncv2.destroyWindow(\"dilate\")\n\n\n# perform a connected component analysis on the thresholded\n# image, then initialize a mask to store only the \"large\"\n# components\n#labels = measure.label(thresh, neighbors=8, background=0)\nthresh=dilate\nlabels = measure.label(thresh, neighbors=8, background=0) ## change background to white ?\nmask = np.zeros(thresh.shape, dtype=\"uint8\")\n\n# loop over the unique components\nfor label in np.unique(labels):\n\t# if this is the background label, ignore it\n\tif label == 1: ## background label 8 \n\t#if label == 0:\n\t\tcontinue\n\n\t# otherwise, construct the label mask and count the\n\t# number of pixels \n\tlabelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n\tlabelMask[labels == label] = 255\n\tnumPixels = cv2.countNonZero(labelMask)\n\n\t# if the number of pixels in the component is sufficiently\n\t# large, then add it to our mask of \"large blobs\"\n\tif numPixels > 50 & numPixels < 100: #TO BE AUTOMIZED\n\t\tmask = cv2.add(mask, labelMask)\n\t#\tcv2.imshow(\"mask\", mask)\n    #    cv2.waitKey(0)\n\n# find the contours in the mask, then sort them from left to\n# right\ncnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n\tcv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if imutils.is_cv2() else cnts[1]\ncnts = contours.sort_contours(cnts)[0]\n\n# loop over the contour\na = np.matrix([])# liste of radius\ndiff = np.array([0])\ndf = pd.DataFrame({'cX':[0], 'cY': [0],'radius':[0]})\nj=0\nfor (i, c) in enumerate(cnts):\n\t# draw the bright spot on the image\n\t(x, y, w, h) = cv2.boundingRect(c)\n\t((cX, cY), radius) = cv2.minEnclosingCircle(c)\n\t\n\tif int(radius)>200 or int(radius)<30:##eliminates to big or too small circles, TO BE AUTOMIZED\n\t    continue\n\t#cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n\tcv2.circle(image, (int(cX)+1, int(cY)+1), int(radius)+1,\n\t\t  (0, 0, 255), 3)\n\tcv2.putText(image, \"#{}\".format(i + 1), (x, y - 15),\n\t\t cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n\tdf.loc[j,'cX']=cX \n\tdf.loc[j,'cY'] = cY\n\tdf.loc[j,'radius'] = radius\n\tj=j+1\n\ncv2.imshow(\"Image\", image)\ncv2.waitKey(0)\ncv2.destroyWindow(\"Image\")\nprint(df)\n\nim = image\nheight,width,depth = im.shape\ncircle_img = np.zeros((height,width), np.uint8)\ncv2.circle(circle_img,(int(cX),int(cY)),int(radius)+2,1,thickness=-1)\n\nmasked_data = cv2.bitwise_and(im, im, mask=circle_img)\n\n\ncv2.imshow(\"im\",im)\ncv2.waitKey(0)\ncv2.destroyWindow(\"im\")\n\n\n\ncv2.imshow(\"masked\", masked_data)\ncv2.waitKey(0)\ncv2.destroyWindow(\"masked\")\nprint(df)\n##df.iloc[0,:] accessing the first line of df\n# show the output image","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4bb2a10a-6daa-8768-4471-a9dd02b7c5c5","_uuid":"9aa711d6e50c4d29cbee2e41c0c542e9c65f547a","trusted":false,"collapsed":true},"cell_type":"code","source":"###################################################################\n## trying to find nodules as bright spot###########################\n###################################################################\n\n\n### in a first step, look at the first lung region, this should be improved to look at both lung regions\n\nlung_region = masked_data\ncv2.imshow(\"lung region\",lung_region)\ncv2.waitKey(0)\ncv2.destroyWindow(\"lung region\")\n#trying to find the moyenne of the pic for the best threeshold value\n\nw,h,bpp = np.shape(lung_region)\npix=0\nfor py in range(0,h):\n    for px in range(0,w):\n        A=sum(image[py][px]) #store pixel property in A\n        pix=pix+A#store image pixel property in pix\n        \n##make some stat on A\nmoyenne = pix/(h*w*bpp)\n\n# load the image, convert it to grayscale, and blur it\ngray = cv2.cvtColor(lung_region, cv2.COLOR_BGR2GRAY)\nblurred = cv2.GaussianBlur(gray, (11, 11), 0)\ncv2.imshow(\"blurred\", blurred)\ncv2.waitKey(0)\ncv2.destroyWindow(\"blurred\")\n# threshold the image to reveal light regions in the\n# blurred image\nthresh = cv2.threshold(blurred, moyenne + 20, 255, cv2.THRESH_BINARY)[1]## please try several value for moyenne+20  \ncv2.imshow(\"thresh\", thresh)\ncv2.waitKey(0)\ncv2.destroyWindow(\"thresh\")\n\n\n# perform a series of erosions and dilations to remove\n# any small blobs of noise from the thresholded image\n#erode = cv2.erode(thresh, None, iterations=2)\n#cv2.imshow(\"erode\", erode)\n#cv2.waitKey(0)\n#cv2.destroyWindow(\"erode\")\n\ndilate = cv2.dilate(thresh, None, iterations=4)## number of iterations to be automized\ncv2.imshow(\"dilate\", dilate)\ncv2.waitKey(0)\ncv2.destroyWindow(\"dilate\")\n# perform a connected component analysis on the thresholded\n# image, then initialize a mask to store only the \"large\"\n# components\nthresh=dilate\nlabels = measure.label(thresh, neighbors=8, background=0)\nmask = np.zeros(thresh.shape, dtype=\"uint8\")\n\n# loop over the unique components\nfor label in np.unique(labels):\n\t# if this is the background label, ignore it\n\tif label == 0:\n\t\tcontinue\n\n\t# otherwise, construct the label mask and count the\n\t# number of pixels \n\tlabelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n\tlabelMask[labels == label] = 255\n\tnumPixels = cv2.countNonZero(labelMask)\n\n\t# if the number of pixels in the component is sufficiently\n\t# large, then add it to our mask of \"large blobs\"\n\tif numPixels > 50 & numPixels < 100:## to be automized\n\t\tmask = cv2.add(mask, labelMask)\n\n# find the contours in the mask, then sort them from left to\n# right\ncnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n\tcv2.CHAIN_APPROX_SIMPLE)\ncnts = cnts[0] if imutils.is_cv2() else cnts[1]\ncnts = contours.sort_contours(cnts)[0]\n\n# loop over the contours\na = np.matrix([])# liste of radius\ndiff = np.array([0])\ndf = pd.DataFrame({'cX':[0], 'cY': [0],'radius':[0]})\nj=0\nfor (i, c) in enumerate(cnts):\n\t# draw the bright spot on the image\n\t\n\t(x, y, w, h) = cv2.boundingRect(c)\n\t((cX, cY), radius) = cv2.minEnclosingCircle(c)\n\tif int(radius)>50 or int(radius)<7:#3 TO BE FUCKIN AUTOMIZED\n\t    continue\n\tcv2.circle(image, (int(cX), int(cY)), int(radius),\n\t\t(0, 0, 255), 3)\n\tcv2.putText(image, \"#{}\".format(i + 1), (x, y - 15),\n\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n\tdf.loc[j,'cX']=cX \n\tdf.loc[j,'cY'] = cY\n\tdf.loc[j,'radius'] = radius\n\tj=j+1\n\n# show the output image\ncv2.imshow(\"Image\", image)\ncv2.waitKey(0)\ncv2.destroyWindow(\"Image\")\nprint(df)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}