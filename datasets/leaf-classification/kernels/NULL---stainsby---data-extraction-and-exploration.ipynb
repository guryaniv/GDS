{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3c0b8314-465d-640d-f803-d9998f496bf8"
      },
      "source": [
        "### A quick look at the data for my first Kaggle script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6077d2d-d5c6-3f01-4deb-a7d480c0f633"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import misc\n",
        "\n",
        "INPUT_IMAGE_SIZE = 300 # pixels; we will resize and embed all input images into a square of this size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5fb34a4-ffd7-05bb-f0b1-9d176d3e6251"
      },
      "outputs": [],
      "source": [
        "train_metadata = pandas.read_csv('../input/train.csv')\n",
        "test_metadata = pandas.read_csv('../input/test.csv')\n",
        "train_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5ad485fc-d369-1fd7-af7c-1cec949f25bd"
      },
      "source": [
        "Ignore all feature columns and just use the 'id' and 'species' columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4151087a-9829-0c65-35b2-92b4700efa4b"
      },
      "outputs": [],
      "source": [
        "train_ids = train_metadata['id']\n",
        "train_species = train_metadata['species']\n",
        "\n",
        "species = list(set(train_species))\n",
        "species.sort()\n",
        "num_species = len(species)\n",
        "\n",
        "print('Read %i training samples of %i species.' % (len(train_ids), num_species))\n",
        "\n",
        "test_ids = test_metadata['id']\n",
        "\n",
        "print('Read %i testing samples.' % len(test_ids))\n",
        "\n",
        "# some useful maps\n",
        "\n",
        "species_name_2_species_id_map = {}\n",
        "species_name_2_sample_ids_map = {}\n",
        "sample_id_2_species_id_map = {}\n",
        "sample_id_2_species_name_map = {}\n",
        "\n",
        "for id, name in zip(range(len(species)), species):\n",
        "    species_name_2_species_id_map[name] = id\n",
        "\n",
        "for i in range(len(train_ids)):\n",
        "    sample_id = train_ids[i]\n",
        "    species_name = train_species[i]\n",
        "    species_id = species_name_2_species_id_map[species_name]\n",
        "    if not species_name_2_sample_ids_map.get(species_name, None):\n",
        "        species_name_2_sample_ids_map[species_name] = []\n",
        "    species_name_2_sample_ids_map[species_name].append(sample_id)\n",
        "    sample_id_2_species_id_map[sample_id] = species_id\n",
        "    sample_id_2_species_name_map[sample_id] = species_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "61198bd7-a12b-c3e2-bb6a-7a472a3dc3fc"
      },
      "source": [
        "How many of each species? We will see there are **exactly ten samples per species**, and so later we should be careful to use stratified sampling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed1a0f19-88cf-ef74-dd89-d228c535193c"
      },
      "outputs": [],
      "source": [
        "species_counts = [len(species_name_2_sample_ids_map[name]) for name in species]\n",
        "print('Distinct counts per species: %s' % set(np.unique(species_counts)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0314a4d6-81b1-e3ae-93f0-bdbcfd4e481f"
      },
      "source": [
        "### Cleaning up the image data\n",
        "\n",
        "Now we read all of the image data into memory. We'll see that the images are not properly thresholded, and that there are noisy pixels around the edges of the leaf shapes. This is likely due to JPEG compression artefacts - the provider would have been better off using PNG. Mostly these have values close to zero, with a few near 255 (you typically need to look *very* closely at the histogram near 255, if it is visible at all). We fix the thresholding as we read in the images.\n",
        "\n",
        "After correcting the threshold, the images are each embedded into a `INPUT_IMAGE_SIZE \u00d7 INPUT_IMAGE_SIZE` square image, which is the standard input resolution we will use during training and evaluation. The values are then normalised on a per-image basis. Lastly, we add a channel dimension of size 1, as our CNNs in Tensorflow that we intend to create later will need this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "369f1b66-a5d1-198d-9568-53e6e8cd8a16"
      },
      "outputs": [],
      "source": [
        "sample_ids = list(set(train_ids).union(set(test_ids)))\n",
        "sample_id_to_image_map = {}\n",
        "\n",
        "\n",
        "# Creates an image in a fixed squared shape with normalised pixel values.\n",
        "def standardise_image(im, size = INPUT_IMAGE_SIZE):\n",
        "    \n",
        "    # Resize the original image if necessary\n",
        "    \n",
        "    major_axis = np.max(im.shape)\n",
        "    if major_axis > size:\n",
        "        resize_factor = size/major_axis\n",
        "        im = misc.imresize(im, resize_factor, interp='bilinear')\n",
        "    im_height, im_width = im.shape\n",
        "    offset_y = (size - im_height)//2\n",
        "    offset_x = (size - im_width)//2\n",
        "    im_sqr = np.zeros((size, size), dtype=np.float)\n",
        "    im_sqr[offset_y:(offset_y + im_height), offset_x:(offset_x + im_width)] = im\n",
        "    im = im_sqr\n",
        "    \n",
        "    # Normalise - this is essential the same as tensoflow's tf.image.per_image_standardization\n",
        "    \n",
        "    mean = np.mean(im)\n",
        "    stddev = np.std(im)\n",
        "    adjusted_stddev = np.max([stddev, 1.0/np.sqrt(im.size)])\n",
        "    im = (im - mean)/adjusted_stddev\n",
        "    \n",
        "    # Add a channel dimension of size 1\n",
        "    \n",
        "    im = im.reshape(size, size, 1)\n",
        "    \n",
        "    return im\n",
        "\n",
        "\n",
        "def read_images():\n",
        "    np.random.shuffle(sample_ids)\n",
        "    print('Number of images to read:', len(sample_ids))\n",
        "    sample_id_to_image_map = {}\n",
        "    is_first = True\n",
        "    image_read_count = 0\n",
        "    for id in sample_ids:\n",
        "        im0 = misc.imread('../input/images/' + str(id) + '.jpg', mode='L')\n",
        "        image_read_count += 1\n",
        "        # ensure properly thresholded\n",
        "        im = 1*(im0 >= 128)\n",
        "        if is_first:\n",
        "            is_first = False\n",
        "            # these input images are not properly thesholded - this will show it:\n",
        "            dirty_pixels = 1*(im0 > 0)*(im0 < 255)\n",
        "            im_dirty = im0*dirty_pixels\n",
        "            print('Showing a random example:')\n",
        "            print('Shape of image:', im.shape, '; id =', id)\n",
        "            f, ((dx1, dx2), (ax1, ax2)) = plt.subplots(2, 2, figsize=(9, 9))\n",
        "            dx1.imshow(dirty_pixels, cmap='gray')\n",
        "            dx1.set_title('locations of values not zero or 255')\n",
        "            dx2.hist(im_dirty.flatten(), bins=64, edgecolor='red', facecolor='red')\n",
        "            dx2.set_title('value histogram')\n",
        "            ax1.imshow(im, cmap='gray')\n",
        "            ax1.set_title('thresholded image')\n",
        "            _, _, bars = ax2.hist(im.flatten(), bins=2)\n",
        "            bars[0].set_facecolor('black')\n",
        "            bars[-1].set_facecolor('white')\n",
        "            ax2.set_title('value histogram')\n",
        "            plt.show()\n",
        "            print('Reading in remaining images ...')\n",
        "\n",
        "        sample_id_to_image_map[id] = standardise_image(im)\n",
        "\n",
        "    print('Finished reading images - read %d images.' % image_read_count)\n",
        "    assert image_read_count == len(sample_ids), 'read the wrong number of images'\n",
        "    \n",
        "    return sample_id_to_image_map\n",
        "\n",
        "\n",
        "sample_id_to_image_map = read_images()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a158f288-c757-1674-6db2-3992f1cbb47c"
      },
      "outputs": [],
      "source": [
        "# Just a test\n",
        "def test_original_images():\n",
        "    print('An input image chosen at random:')\n",
        "    im = sample_id_to_image_map[np.random.choice(sample_ids)]\n",
        "    plt.figure(figsize=(300/90, 300/90), dpi=90)\n",
        "    # we need to squeeze out the channel dimanesion that we added\n",
        "    plt.imshow(np.squeeze(im), cmap='gray')\n",
        "    plt.show()\n",
        "    print('Some more input images:')\n",
        "    rows = 6\n",
        "    for k in range(rows):\n",
        "        _, axs = plt.subplots(1, 9, figsize=(9, 2))\n",
        "        for i, ax in zip(range(len(axs)), axs):\n",
        "            im = sample_id_to_image_map[sample_ids[i + k*rows]]\n",
        "            ax.imshow(np.squeeze(im), cmap='gray')\n",
        "            ax.get_xaxis().set_ticks([])\n",
        "            ax.get_yaxis().set_ticks([])\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "test_original_images() # just a test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a906250-9505-28e7-784a-2431157f55be"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}