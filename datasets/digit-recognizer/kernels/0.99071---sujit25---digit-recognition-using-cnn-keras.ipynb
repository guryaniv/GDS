{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nfrom sklearn.model_selection import train_test_split\n\n# import dependencies\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils, to_categorical\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":35,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_fpath = \"../input/train.csv\"\ntest_fpath = \"../input/test.csv\"\ntrain_df = pd.read_csv(train_fpath)\ntest_df = pd.read_csv(test_fpath)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f88ce455945c57a6c471d63410423e58435ad3fd","collapsed":true},"cell_type":"code","source":"train_df.head()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0c2c1a591d8ccd1bcfa0802798d9df2e948ef62","collapsed":true},"cell_type":"code","source":"test_df.head()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"602908eaeb68a34309dbfa5225d2dfe680a5277b","collapsed":true},"cell_type":"code","source":"#print(train_df.shape)\ndef np_array_from_dataframe(df, istrain):\n    n_rows = df.shape[0]\n    arr_list = []\n    labels = []\n    for row_index in range(n_rows):\n        pixels = None\n        if istrain:\n            pixels =df.iloc[row_index, 1:]\n            labels.append(df.iloc[row_index, 0])\n        else:\n            pixels = df.iloc[row_index, :]\n        arr_list.append(np.array(pixels).reshape(-1,28,28,1))\n    transformed_arr = np.array(arr_list).reshape(-1,28,28,1)\n    transformed_labels = to_categorical(np.array(labels).reshape(-1,1), 10)\n    return transformed_arr, transformed_labels if istrain else transformed_arr","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb76cbde8bd18e4bdf73ec8e8e71755df166679","collapsed":true},"cell_type":"code","source":"# get data from csv\ndata_x, data_y = np_array_from_dataframe(train_df, istrain=True)\nprint(data_x.shape)\nprint(data_y.shape)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3be42c770f5183f31c0367c16ff5bc09236ca6e","collapsed":true},"cell_type":"code","source":"# split data into train and validation sets\ntrain_x, valdn_x, train_y, valdn_y = train_test_split(data_x, data_y, test_size=0.1)\nprint(\"train_x shape\", train_x.shape)\nprint(\"train_y shape\", train_y.shape)\n\nprint(\"valdn_x shape\", valdn_x.shape)\nprint(\"valdn_y shape\", valdn_y.shape)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"082b1d554863fdeee0c430acc1e9cd7f411c3126","collapsed":true},"cell_type":"code","source":"test_x,_ = np_array_from_dataframe(test_df, istrain=False)\nprint(\"test_x shape\", test_x.shape)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d51463981b4463ffe9688a656a17e52f7cf4a147"},"cell_type":"code","source":"# CNN model\nmodel = Sequential()\n\n# -----------------------------------------------------------------------------------\n# conv 1\nmodel.add(Conv2D(16, (3,3), input_shape=(28,28,1))) # input- 28X28X3, output- 25,25,16\nmodel.add(BatchNormalization(axis=3))\n# relu 1\nmodel.add(Activation('relu'))\n\n# conv 2\nmodel.add(Conv2D(16, (3,3)))        # input-25,25,16, output- 22,22,16\nmodel.add(BatchNormalization(axis=3))\n# relu 2\nmodel.add(Activation('relu'))     \n\n# max pool 1\nmodel.add(MaxPooling2D(pool_size=(2,2))) # input - 22,22,16, output\n\n# --------------------------------------------------------------------------------------\n# conv 3\nmodel.add(Conv2D(32, (3,3))) \nmodel.add(BatchNormalization(axis=3))\n# relu 3\nmodel.add(Activation('relu'))\n\n# conv 4\nmodel.add(Conv2D(32, (3,3)))  \nmodel.add(BatchNormalization(axis=3))\n# relu 4\nmodel.add(Activation('relu'))     \n\n# max pool 2\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# ---------------------------------------------------------------------------------------\n\n# flatten\nmodel.add(Flatten())\n\n# fc layer 1\nmodel.add(Dense(512, activation='relu'))\n\n# fc layer 2\nmodel.add(Dense(256, activation='relu'))\n\n# fc layer 3 \nmodel.add(Dense(128, activation='relu'))\n\n# fc layer 4\nmodel.add(Dense(10, activation='softmax'))\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7d4df6236dd2dac1a8bca7c3b59c757f34568ed0"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"590ccd13ffd8f959425ecded91073002110318f6","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7727404a82b0d42d1022f642e95d395119f8806a","collapsed":true},"cell_type":"code","source":"model_hist= model.fit(x=train_x,y=train_y, epochs=10, batch_size= 32, validation_data=(valdn_x, valdn_y), verbose=1)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f78e97d174a77489374a63e847c12b7b09842dc","collapsed":true},"cell_type":"code","source":"#model.(valdn_x, valdn_y, batch_size=32, verbose=1)\npredictions = model.predict(test_x, batch_size=32, verbose=1)\ncomputed_predictions = np.argmax(predictions, axis=1)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22a557be9ff607cdd8f076264905ca98b4b58504","collapsed":true},"cell_type":"code","source":"# plot variation of cost with epochs\n#print(model_hist.history)\nplt.plot(model_hist.history['loss'])\nplt.plot(model_hist.history['val_loss'])\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('model loss')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38978bc5d99ae0b6c1a043cf724986332f1e7dbc","collapsed":true},"cell_type":"code","source":"# plot variation of accuracy with epochs\nplt.plot(model_hist.history['acc'])\nplt.plot(model_hist.history['val_acc'])\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('model accuracy')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a3a034cc0847b1eb9a910536e4eb2cdbc3f238","collapsed":true},"cell_type":"code","source":"# compute max value from predictions\n\n#print(computed_predictions.shape)","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"798063b8e8bb98d9086deaaf9c68e876384a1154","collapsed":true},"cell_type":"code","source":"submissions_df = pd.DataFrame(data=computed_predictions, columns=['label'])\n#submissions_df['ImageId'] = submissions_df['index'] +1\nsubmissions_df.reset_index(inplace=True)\nsubmissions_df['index'] = submissions_df['index'] + 1\nsubmissions_df.rename(columns={'index': 'ImageId'}, inplace=True)\nsubmissions_df.to_csv('submission.csv', index=False)\nsubmissions_df.head()","execution_count":42,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}