{"cells":[{"metadata":{"_cell_guid":"8c8cdf3d-4bab-4ad8-b290-fe08109d7ba6","_uuid":"bd892a4a74b97f67906c166ee50cd6e68c792373"},"cell_type":"markdown","source":"<h1> LeNet-5 Architecture </h1>\nLeNet-5 is small and easy to understand Network. It can be easily trained on CPU so making it easier for beginner in Deep learing.\n![](https://blog.dataiku.com/hs-fs/hubfs/Dataiku%20Dec%202016/Image/le_net.png?t=1524241738688&width=620&name=le_net.png)\n\nLeNet-5  Consists of Following Layers:\n**INPUT -> CONV ->  RELU ->  POOL ->  CONV -> RELU -> POOL -> FC -> RELU -> FC**\n\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"97ba888c-0bff-43dc-a7b6-44a739150986","_uuid":"4c7e155d4e67e377f5efa191818abb89d0d2d78b"},"cell_type":"markdown","source":"<h2>Data Preparation </h2>"},{"metadata":{"_cell_guid":"c678a172-7a42-48c0-9fbc-2f5d4d8c6c28","_uuid":"a9d6128e3bc83d338f4df9260cba3c63a024da18","collapsed":true,"trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\nY_train = train[\"label\"]\nX_train = train.drop(labels = [\"label\"],axis = 1) \n# Normalize the data\nX_train = X_train / 255.0\ntest = test / 255.0\n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)\n# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"**Define LeNeT-5 Model**"},{"metadata":{"_cell_guid":"42088279-59d9-4236-8fac-0cd282489b15","_uuid":"a85d9426d7fd507986d9e9b010c814c6e61193f5","collapsed":true,"trusted":true},"cell_type":"code","source":"model=Sequential()\n#First Layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n# Second Layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"b148c499-951d-462d-9081-e9cf104b71c5","_uuid":"4cd76f94367805c9ee685fc08990dd739edc0477","collapsed":true,"trusted":true},"cell_type":"code","source":"# Define Optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"8ed14f29-b488-4108-b7e9-01fcf6943263","_uuid":"c8587054b37a5e299c8ed8331102b0462d9f024b","trusted":true},"cell_type":"code","source":"epochs = 10\nbatch_size = 75\nle_model = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val), verbose = 2)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"b9563740-d5a9-4618-8356-29674e1fb4d7","_uuid":"b09814c36a49aed99813d24c11be145cf2b352cd","collapsed":true,"trusted":true},"cell_type":"code","source":"#predict results\nresults = model.predict(test) \n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"Lenet3_mnist.csv\",index=False)","execution_count":17,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"6474c2226a5ed930326b1c337193dc953b09add0"},"cell_type":"code","source":"results = model.predict(test) \n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\nsubmission.to_csv(\"Lene_mnist.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48b0c01f605d5a889916cda3140ef7d2467e41f7"},"cell_type":"markdown","source":"**Current Model gives 0.99200 score  with 10 epoch  We can add drop out layer prevent overfitting . Also we can try with Data Augemantation to Increase Accuracy. There are better Convolution Network available which will perform better  like ResNet50. Aim of this Notebook show the standard LeNet-5 Architecture, you can always try out different variation to this network by changing number of layers, number of filter so on.**"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"edc607621518f4f6071a4d55d142618e9f27b6c1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}