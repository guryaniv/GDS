{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nprint(os.listdir(\"../input\"))\nimport numpy as np \nimport pandas as pd\nimport time\ngc.collect()\n# Any results you write to the current directory are saved as output.\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train_ship_segmentations_v2.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efd2ea308ca04f91749ada2dbf67f62b447b5d18","scrolled":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b13464005e7ab0af595b62cc1162d19015dff6e"},"cell_type":"code","source":"list(train.columns.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf7fd68627ba9fb3e48f7e1b80a50cf8e5eba8d0"},"cell_type":"code","source":"train['exist_ship'] = train['EncodedPixels'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54665ce582a6c29499e5f81ab7547f723e95eed7"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06e55fcf5061e5d02dd81dffb0a75f63f6359b28","scrolled":true},"cell_type":"code","source":"train['exist_ship'] != 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0938180caa3d59ebdf3290fda7673502750fcac"},"cell_type":"code","source":"train.loc[train['exist_ship'] != 0 , 'exist_ship'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"759b355ad0730b12f4f097dbacae23677974a4e6"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc89bf7ec3131efe21bc97c9b6fe919b373ca1db"},"cell_type":"code","source":"del train['EncodedPixels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2fd2bf07e24695fd4cef7b4351c3def2ac213c9"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"617d3eb4b674814c1c1102c27c79cff363278bf4"},"cell_type":"code","source":"print(len(train['ImageId']))\nprint(train['ImageId'].value_counts().shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7943ba7be3b0bc580a4fe131416f42ff58c875fd"},"cell_type":"code","source":"train_gp = train.groupby(['ImageId']).sum().reset_index()\ntrain_gp.loc[train_gp['exist_ship']>0,'exist_ship']=1\n\ntrain_sample = train_gp.sample(5000)\ntest_sample = train_gp.sample(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"399ad229cab10b52df239c4246fad61d0cef57e4"},"cell_type":"code","source":"print(train_gp['exist_ship'].value_counts())\nprint(train_sample['exist_ship'].value_counts())\nprint(test_sample['exist_ship'].value_counts())\nprint (train_sample.shape)\nprint (test_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc1e684fa398a89fa776099349e91a43c2a81324"},"cell_type":"code","source":"from keras.utils import np_utils\nimport numpy as np\nfrom glob import glob\n\nTrain_path = '../input/train_v2/'\nTest_path = '../input/test_v2/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a3a1ced6a5960dbdb0cf8b08850c453ec4d4ef2"},"cell_type":"code","source":"# define function to load train, test, and validation datasets\ndef load_dataset(path):\n    files_array = []\n    if str(path) == str(Train_path):\n        data = np.array(train_sample['ImageId'])\n        data_targets = np_utils.to_categorical(np.array(train_sample['exist_ship']), 133)\n\n        for idx, element in  enumerate(data): \n            files_array.append(Train_path + element)\n\n        data = np.array(files_array)\n    else:\n        data = np.array(test_sample['ImageId'])\n        data_targets = np_utils.to_categorical(np.array(test_sample['exist_ship']), 133)\n\n        for idx, element in  enumerate(data): \n            files_array.append(Train_path + element)\n\n        data = np.array(files_array)\n    \n    return data, data_targets\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c03f5db8401150ff745195b65d004d5d6d4acf6f","scrolled":false},"cell_type":"code","source":"# load train, test, and validation datasets\ntrain_files, train_targets = load_dataset(Train_path)\ntest_files, test_targets = load_dataset(Test_path)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36e3af228f3c10fb13558b57f83c7112bb027d97"},"cell_type":"code","source":"from keras.preprocessing import image \nfrom tqdm import tqdm\n\ndef path_to_tensor(img_path):\n    # loads RGB image as PIL.Image.Image type\n    img = image.load_img(img_path, target_size=(224, 224))\n    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n    x = image.img_to_array(img)\n    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n    return np.expand_dims(x, axis=0)\n\ndef paths_to_tensor(img_paths):\n    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n    return np.vstack(list_of_tensors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32606644a49f5b7410ad884f156931ab24a6ee5e"},"cell_type":"code","source":"from PIL import ImageFile                            \nImageFile.LOAD_TRUNCATED_IMAGES = True                 \n\n\ntest_tensors = paths_to_tensor(test_files).astype('float32')/255\ntrain_tensors = paths_to_tensor(train_files).astype('float32')/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8539eb2934a51dc55716c1d124a916c3c1589181"},"cell_type":"code","source":"#https://www.kaggle.com/yassinealouini/f2-score-per-epoch-in-keras\n\nimport numpy as np \nimport pandas as pd \nfrom keras.callbacks import Callback\nfrom sklearn.metrics import fbeta_score\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras.utils.test_utils import get_test_data\n\n\n\n\"\"\" F2 metric implementation for Keras models. Inspired from this Medium\narticle: https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\nBefore we start, you might ask: this is a classic metric, isn't it already \nimplemented in Keras? \nThe answer is: it used to be. It has been removed since. Why?\nWell, since metrics are computed per batch, this metric was confusing \n(should be computed globally over all the samples rather than over a mini-batch).\nFor more details, check this: https://github.com/keras-team/keras/issues/5794.\nIn this short code example, the F2 metric will only be called at the end of \neach epoch making it more useful (and correct).\n\"\"\"\n\n# Notice that since this competition has an unbalanced positive class\n# (fewer ), a beta of 2 is used (thus the F2 score). This favors recall\n# (i.e. capacity of the network to find positive classes). \n\n# Some default constants\n\nSTART = 0.5\nEND = 0.95\nSTEP = 0.05\nN_STEPS = int((END - START) / STEP) + 2\nDEFAULT_THRESHOLDS = np.linspace(START, END, N_STEPS)\nDEFAULT_BETA = 1\nDEFAULT_LOGS = {}\nFBETA_METRIC_NAME = \"val_fbeta\"\n\n# Some unit test constants\ninput_dim = 2\nnum_hidden = 4\nnum_classes = 2\nbatch_size = 5\ntrain_samples = 20\ntest_samples = 20\nSEED = 42\nTEST_BETA = 2\nEPOCHS = 5\n\n\n\n\n# Notice that this callback only works with Keras 2.0.0\n\n\nclass FBetaMetricCallback(Callback):\n\n    def __init__(self, beta=DEFAULT_BETA, thresholds=DEFAULT_THRESHOLDS):\n        self.beta = beta\n        self.thresholds = thresholds\n        # Will be initialized when the training starts\n        self.val_fbeta = None\n\n    def on_train_begin(self, logs=DEFAULT_LOGS):\n        \"\"\" This is where the validation Fbeta\n        validation scores will be saved during training: one value per\n        epoch.\n        \"\"\"\n        self.val_fbeta = []\n\n    def _score_per_threshold(self, predictions, targets, threshold):\n        \"\"\" Compute the Fbeta score per threshold.\n        \"\"\"\n        # Notice that here I am using the sklearn fbeta_score function.\n        # You can read more about it here:\n        # http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html\n        thresholded_predictions = (predictions > threshold).astype(int)\n        return fbeta_score(targets, thresholded_predictions, beta=self.beta, average='micro')\n\n    def on_epoch_end(self, epoch, logs=DEFAULT_LOGS):\n        val_predictions = self.model.predict(self.validation_data[0])\n        val_targets = self.validation_data[1]\n        _val_fbeta = np.mean([self._score_per_threshold(val_predictions,\n                                                        val_targets, threshold)\n                              for threshold in self.thresholds])\n        self.val_fbeta.append(_val_fbeta)\n        print(\"Current F{} metric is: {}\".format(str(self.beta), str(_val_fbeta)))\n        return\n\n    def on_train_end(self, logs=DEFAULT_LOGS):\n        \"\"\" Assign the validation Fbeta computed metric to the History object.\n        \"\"\"\n        self.model.history.history[FBETA_METRIC_NAME] = self.val_fbeta\n\n\"\"\"\nHere is how to use this metric: \nCreate a model and add the FBetaMetricCallback callback (with beta set to 2).\nf2_metric_callback = FBetaMetricCallback(beta=2)\ncallbacks = [f2_metric_callback]\nhistory = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n                    nb_epoch=10, batch_size=64, callbacks=callbacks)\nprint(history.history.val_fbeta)\n\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5511ab3de12eee3c4adc5895217eafd5c6f726d8"},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.models import Sequential\n\nmodel = Sequential()\nmodel.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n                        input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu', \n                        input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', \n                        input_shape=(224, 224, 3)))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(133, activation='softmax'))\n\n### TODO: Define your architecture.\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53ce6783378c55ba0a913a8211ae49276bbe4b80"},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6489b151480e7da640d2c05acc8a9dffac0dabc6"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint  \n\nepochs = 20\n\nfbeta_metric_callback = FBetaMetricCallback(beta=2)\nhistory = model.fit(train_tensors, train_targets, \n          validation_data=(test_tensors, test_targets),\n          epochs=epochs, batch_size=20, callbacks=[fbeta_metric_callback])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e740fb6dc592eda895955f87197a2bf27d8b3237"},"cell_type":"code","source":"print(history.history['val_fbeta'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edc2de631fe57a49184b891da79136b8e875662a"},"cell_type":"code","source":"from matplotlib import pyplot\n\npyplot.plot(history.history['acc'])\npyplot.plot(history.history['val_acc'])\npyplot.plot(history.history['val_fbeta'])\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfcbacbd849d275d0987f500ab36760a8960c26f"},"cell_type":"code","source":"pyplot.plot(history.history['loss'])\npyplot.plot(history.history['val_loss'])\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"141bb153bdffad81a41991544d762a1b30e1f76f"},"cell_type":"code","source":"# get index of predicted ship for each image in test set\npredictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(predictions)==np.argmax(test_targets, axis=1))/len(predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"887d091b182e8cd449f984b3bfe30f7560c35243"},"cell_type":"code","source":"# get index of predicted ship for each image in test set\npredictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in train_tensors]\n\n# report test accuracy\ntest_accuracy = 100*np.sum(np.array(predictions)==np.argmax(train_targets, axis=1))/len(predictions)\nprint('Test accuracy: %.4f%%' % test_accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}