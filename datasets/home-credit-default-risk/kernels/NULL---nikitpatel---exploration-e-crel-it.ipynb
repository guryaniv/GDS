{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport plotly.offline as py\nimport cufflinks as cf\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n%matplotlib inline\n\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.\nimport gc\ngc.enable()\nPATH = '../input/'","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"58d39ac12d3c42fc6badd27d6b975145c520053f"},"cell_type":"markdown","source":"### Exploration Road Map:\n* Load Data\n* Take same insight of categorical variable\n* count na value for each column\n* Na value replace with zero\n* categorical lable convert into int\n* feature engineering\n    * ExtraTreesClassifier\n    * PCA\n* Histogram\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"## load all data\napplication_train = pd.read_csv(PATH+\"/application_train.csv\")\napplication_test = pd.read_csv(PATH+\"/application_test.csv\")\nbureau = pd.read_csv(PATH+\"/bureau.csv\")\nbureau_balance = pd.read_csv(PATH+\"/bureau_balance.csv\")\ncredit_card_balance = pd.read_csv(PATH+\"/credit_card_balance.csv\")\ninstallments_payments = pd.read_csv(PATH+\"/installments_payments.csv\")\nprevious_application = pd.read_csv(PATH+\"/previous_application.csv\")\nPOS_CASH_balance = pd.read_csv(PATH+\"/POS_CASH_balance.csv\")","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556e06d2d3a39001a7cebb0dd50bfb74d65b9ba4"},"cell_type":"code","source":"print(\"application_train -  rows:\",application_train.shape[0],\" columns:\", application_train.shape[1])\nprint(\"application_test -  rows:\",application_test.shape[0],\" columns:\", application_test.shape[1])\nprint(\"bureau -  rows:\",bureau.shape[0],\" columns:\", bureau.shape[1])\nprint(\"bureau_balance -  rows:\",bureau_balance.shape[0],\" columns:\", bureau_balance.shape[1])\nprint(\"credit_card_balance -  rows:\",credit_card_balance.shape[0],\" columns:\", credit_card_balance.shape[1])\nprint(\"installments_payments -  rows:\",installments_payments.shape[0],\" columns:\", installments_payments.shape[1])\nprint(\"previous_application -  rows:\",previous_application.shape[0],\" columns:\", previous_application.shape[1])\nprint(\"POS_CASH_balance -  rows:\",POS_CASH_balance.shape[0],\" columns:\", POS_CASH_balance.shape[1])","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"336084b8c08f4667dfc57c94af90b1f81175c5c1"},"cell_type":"code","source":"application_train.head()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b5b7717201225d39e1ade08d14988013e2e3acd"},"cell_type":"code","source":"### First Exploration of Train data set\ngc.collect()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20a73f0b03b40ea0f12089aabaf0270660e58021","collapsed":true},"cell_type":"code","source":"NAME_CONTRACT_TYPE = application_train.groupby(['TARGET','NAME_CONTRACT_TYPE']).size().unstack(level=0)\nCODE_GENDER = application_train.groupby(['TARGET','CODE_GENDER']).size().unstack(level=0)\nFLAG_OWN_CAR = application_train.groupby(['TARGET','FLAG_OWN_CAR']).size().unstack(level=0)\nNAME_INCOME_TYPE = application_train.groupby(['TARGET','NAME_INCOME_TYPE']).size().unstack(level=0)\nNAME_EDUCATION_TYPE = application_train.groupby(['TARGET','NAME_EDUCATION_TYPE']).size().unstack(level=0)\nOCCUPATION_TYPE = application_train.groupby(['TARGET','OCCUPATION_TYPE']).size().unstack(level=0)\nORGANIZATION_TYPE = application_train.groupby(['TARGET','ORGANIZATION_TYPE']).size().unstack(level=0)\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6f2e2a96c780086ba1ada4164f8456dbe9ecb6d"},"cell_type":"code","source":"\nplt.subplot(NAME_CONTRACT_TYPE.plot(kind='bar', stacked=True, title=\"NAME_CONTRACT_TYPE\"))\nplt.subplot(CODE_GENDER.plot(kind='bar', stacked=True, title=\"CODE_GENDER\"))\nplt.subplot(FLAG_OWN_CAR.plot(kind='bar', stacked=True, title=\"FLAG_OWN_CAR\"))\nplt.subplot(NAME_INCOME_TYPE.plot(kind='bar', stacked=True, title=\"NAME_INCOME_TYPE\"))\nplt.subplot(NAME_EDUCATION_TYPE.plot(kind='bar', stacked=True, title=\"NAME_EDUCATION_TYPE\"))\nplt.subplot(OCCUPATION_TYPE.plot(kind='bar', stacked=True, title=\"OCCUPATION_TYPE\"))\nplt.subplot(ORGANIZATION_TYPE.plot(kind='bar', stacked=True, title=\"ORGANIZATION_TYPE\"))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"22a4479801311848e48599ae0709eda1662bbd68"},"cell_type":"markdown","source":"####  NAME_CONTRACT_TYPE\nIN NAME_CONTRACT_TYPE cash loans more received compare to revolving loan\n#### CODE_GENDER\nFemale get more loan as compare to male\n####  FLAG_OWN_CAR\nperson has not own car getting more loan approve as campare to own car\n#### NAME_INCOME_TYPE\nworking employee approval loan ratio is high as compare to others\n#### NAME_EDUCATION_TYPE\nonly secondary and higer education class getting loan\n#### OCCUPATION_TYPE\nlaborers, sales staff , driver, manager geeting more approval loan as compare to hr staff, it staff and secretaries"},{"metadata":{"trusted":true,"_uuid":"99bb5af1432ce27b3a91767ae2480429665af5ff","collapsed":true},"cell_type":"code","source":"### extract the categorical column name from the applicaiton train dataset\ncategory = application_train.dtypes","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aabdd233313a42459d0689fe62238844002302a"},"cell_type":"code","source":"cate = []\nfor i,value in enumerate(category):\n    if value == 'object':\n        cate.append(category.index[i])\nprint (\"Categorical Variable\", cate)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"a1a9eade4e687cdaf13409347f383f8ac5ae0da0"},"cell_type":"markdown","source":"### Count na value for each column"},{"metadata":{"trusted":true,"_uuid":"9b2b7d0accd18ce1d43d61708a20a8d53e89498b","collapsed":true},"cell_type":"code","source":"na_count = application_train.isnull().sum().sort_values(ascending=False)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"495e8d5e3c37fb68e514c8f7797a507c99f8c0eb"},"cell_type":"code","source":"na_count.head(5)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"70b8767b1ce2df03fb323cd701086c4008f437c7"},"cell_type":"markdown","source":"### Now handling missing value \nmissing value replace with zero and check those column is important for our train data set \nif the column is not important for train dataset we remove those column where we have getting more null value "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4459dff2e98519d6ed7d509fa2a6dac958a59b8b"},"cell_type":"code","source":"application_train = application_train.fillna(0)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d9c739f94fda3c802b65b59e0a6b078d946d6b23"},"cell_type":"code","source":"application_train.isnull().sum().head()","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"0bcb554237e490de060ba7cbb4979954507ef6fe"},"cell_type":"markdown","source":"### Feature Selection Method"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a7355c036446add6fa598cd067f2c418296209b1"},"cell_type":"code","source":"#before feature engineering we have convert all category variable into int\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f987836e67e92f06df0e6833e0749c2a9e158c58"},"cell_type":"code","source":"for i in application_train.columns:\n    if application_train.dtypes[i] == 'object':\n        le.fit(list(application_train[i].unique()))\n        application_train[i] = le.transform(list(application_train[i].values))\nprint(\"Done\")","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"6a31d6f63e385a162cb6b2d35204ace7cf7f45ae"},"cell_type":"markdown","source":"### ExtraTreesClassifier\nBagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features.\nIn the example below we construct a ExtraTreesClassifier classifier for the Pima Indians onset of diabetes dataset. You can learn more about the ExtraTreesClassifier class in the scikit-learn API."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1bcd8b366d0c64ae9709f965914ec913c7b0923"},"cell_type":"code","source":"array = application_train.values","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a15f269b8d6ce0ea7c77c951438b6768c89a807"},"cell_type":"code","source":"# load data\nX = array[:,2:]\nY = array[:,1]\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nprint (X.shape)\nclf = ExtraTreesClassifier()\nclf = clf.fit(X, Y)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13132860048c4173c0460d1d8fd3379c3806878c"},"cell_type":"code","source":"imp_value = clf.feature_importances_.round(4)\nimp_col = application_train.columns[2:]\nd = {'fea_name': imp_col, 'value':imp_value}\nimp_fea = pd.DataFrame(data = d)\nimp_fea = imp_fea.sort_values('value',ascending=False)\nimp_fea = imp_fea.reset_index(drop=True)[:50]\nimp_fea.fea_name[:5].values","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"8fca9f264c5819b26e9650bf866a88638aa9d14c"},"cell_type":"markdown","source":"\n### below plot represent only 5 feature are important\n'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH',\n       'DAYS_REGISTRATION'"},{"metadata":{"trusted":true,"_uuid":"9d54eb6f1b786e79c6155ea1ce7201945ad04f51"},"cell_type":"code","source":"imp_fea = imp_fea.set_index('fea_name')\nimp_fea.plot(kind='barh',figsize=(15,10),title=\"Feature IMportant \")","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26bf47553dab0f8d288580803e8e4fccb3f3405a","collapsed":true},"cell_type":"markdown","source":"\n### Principal Component Analysis\nPrincipal Component Analysis (or PCA) uses linear algebra to transform the dataset into a compressed form.\nGenerally this is called a data reduction technique. A property of PCA is that you can choose the number of dimensions or principal component in the transformed result.\nIn the example below, we use PCA and select 3 principal components.\nLearn more about the PCA class in scikit-learn by reviewing the PCA API. Dive deeper into the math behind PCA on the Principal Component Analysis Wikipedia article."},{"metadata":{"trusted":true,"_uuid":"57eddf53c9e1ec0f209b6bd1b5e44597a335c02b"},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n# feature extraction\npca = PCA(n_components=120,svd_solver='full')\nfit = pca.fit(X)\n# summarize components\nprint(\"Explained Variance: \", fit.explained_variance_ratio_)\nprint(fit.components_)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57b3ea0e349b2ca32e436105e79c0d11f11ae9b2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59cfb5b0db7451c85f36a7cfe0261e1298ab6208"},"cell_type":"code","source":"var=np.cumsum(np.round(fit.explained_variance_ratio_, decimals=3)*100)\nvar #cumulative sum of variance explained with [n] features","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"87c64452664fd798596d6e1b0be3c35f642d9dfd"},"cell_type":"markdown","source":"### Based on the plot below it's clear we should pick 3 features.\n\ni have observed that base on pca plot we have to need require step increase our fearture\n1. Normalise the data\n2. Remove na column\n3. Rest of column na value replace with (min,max,mean or else)\n4. Remove the outlier\n\nIn pca and ExtraTreesClassifier extract same feature\n* pac = 3 feature\n* ExtraTreesClassifier = 5 feature above (0.025 value)"},{"metadata":{"trusted":true,"_uuid":"c820c2a05eb308d0033df77b86d5413ac5c3724e"},"cell_type":"code","source":"plt.ylabel('% Variance Explained')\nplt.xlabel('# of Features')\nplt.title('PCA Analysis')\nplt.ylim(30,100.5)\nplt.style.context('seaborn-whitegrid')\nplt.plot(var)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"0d6354eb85b2c9c1450f2249022a8d3991aca1cf"},"cell_type":"markdown","source":"###  Analysis of all important column and outliers\n"},{"metadata":{"trusted":true,"_uuid":"5c90e5ff46c588202938d5acf016009567671c3c"},"cell_type":"code","source":"fea_df = pd.DataFrame(application_train, columns=imp_fea.index[:20])","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5364fefe439b4ec2fd088047d3ff3e4f80a99992"},"cell_type":"code","source":"fea_df.hist(figsize=(16,16))\n","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e81a11b07f19673cbbc616d3852244a35432f854"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}