{"nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b861f05d-c424-4744-9210-e8f9da819067", "_uuid": "814e05b9899965c78f26deec949eadfa542011fc"}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "SEED = 42\n", "np.random.seed(SEED)\n", "\n", "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n", "\n", "\n", "#binarization of features\n", "class FeatureBinarizatorAndScaler:\n", "    \"\"\" This class needed for scales and factorize features\n", "    \"\"\"\n", "    NUMERICAL_FEATURES = list()\n", "    CATEGORICAL_FEATURES = list()\n", "    BIN_FEATURES = list()\n", "    binarizers = dict()\n", "    scalers = dict()\n", "\n", "    def __init__(self, numerical=list(), categorical=list(), binfeatures = list(), binarizers=dict(), scalers=dict()):\n", "        self.NUMERICAL_FEATURES = numerical\n", "        self.CATEGORICAL_FEATURES = categorical\n", "        self.BIN_FEATURES = binfeatures\n", "        self.binarizers = binarizers\n", "        self.scalers = scalers\n", "\n", "    def fit(self, train_set):\n", "        for feature in train_set.columns:\n", "\n", "            if feature.split('_')[-1] == 'cat':\n", "                self.CATEGORICAL_FEATURES.append(feature)\n", "            elif feature.split('_')[-1] != 'bin':\n", "                self.NUMERICAL_FEATURES.append(feature)\n", "            else:\n", "                self.BIN_FEATURES.append(feature)\n", "        for feature in self.NUMERICAL_FEATURES:\n", "            scaler = StandardScaler()\n", "            self.scalers[feature] = scaler.fit(np.float64(train_set[feature]).reshape((len(train_set[feature]), 1)))\n", "        for feature in self.CATEGORICAL_FEATURES:\n", "            binarizer = LabelBinarizer()\n", "            self.binarizers[feature] = binarizer.fit(train_set[feature])\n", "\n", "\n", "    def transform(self, data):\n", "        binarizedAndScaledFeatures = np.empty((0, 0))\n", "        for feature in self.NUMERICAL_FEATURES:\n", "            if feature == self.NUMERICAL_FEATURES[0]:\n", "                binarizedAndScaledFeatures = self.scalers[feature].transform(np.float64(data[feature]).reshape(\n", "                    (len(data[feature]), 1)))\n", "            else:\n", "                binarizedAndScaledFeatures = np.concatenate((\n", "                    binarizedAndScaledFeatures,\n", "                    self.scalers[feature].transform(np.float64(data[feature]).reshape((len(data[feature]),\n", "                                                                                       1)))), axis=1)\n", "        for feature in self.CATEGORICAL_FEATURES:\n", "\n", "            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures,\n", "                                                         self.binarizers[feature].transform(data[feature])), axis=1)\n", "\n", "        for feature in self.BIN_FEATURES:\n", "            binarizedAndScaledFeatures = np.concatenate((binarizedAndScaledFeatures, np.array(data[feature]).reshape((len(data[feature]),\n", "                                                                                       1))), axis=1)\n", "\n", "        print(binarizedAndScaledFeatures.shape )\n", "\n", "        return binarizedAndScaledFeatures\n", "    \n", "    from keras.models import Sequential\n", "from keras.layers import Dense, Flatten, Convolution1D, Dropout\n", "from keras.optimizers import SGD\n", "from keras.initializers import random_uniform\n", "\n", "import pandas as pd\n", "\n", "X_train = pd.read_csv('../input/train.csv')\n", "y_train = X_train['target']\n", "X_test = pd.read_csv('../input/test.csv')\n", "test_id = X_test['id']\n", "X_test = X_test.drop(['id'], axis=1)\n", "X_train = X_train.drop(['id', 'target'], axis = 1)\n", "y_train1 = abs(-1+y_train)\n", "y_train = pd.concat([y_train, y_train1], axis=1)\n", "binarizerandscaler = FeatureBinarizatorAndScaler()\n", "binarizerandscaler.fit(X_train)\n", "X_train = binarizerandscaler.transform(X_train)\n", "X_test = binarizerandscaler.transform(X_test)\n", "y_train = y_train.as_matrix()\n", "\n", "\n", "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n", "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n", "\n", "#hyperparameters\n", "input_dimension = 226\n", "learning_rate = 0.0025\n", "momentum = 0.85\n", "hidden_initializer = random_uniform(seed=SEED)\n", "dropout_rate = 0.2\n", "\n", "\n", "# create model\n", "model = Sequential()\n", "model.add(Convolution1D(nb_filter=32, filter_length=3, input_shape=X_train.shape[1:3], activation='relu'))\n", "model.add(Convolution1D(nb_filter=16, filter_length=1, activation='relu'))\n", "model.add(Flatten())\n", "model.add(Dropout(dropout_rate))\n", "model.add(Dense(128, input_dim=input_dimension, kernel_initializer=hidden_initializer, activation='relu'))\n", "model.add(Dropout(dropout_rate))\n", "model.add(Dense(64, kernel_initializer=hidden_initializer, activation='relu'))\n", "model.add(Dense(2, kernel_initializer=hidden_initializer, activation='softmax'))\n", "\n", "sgd = SGD(lr=learning_rate, momentum=momentum)\n", "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['acc'])\n", "model.fit(X_train, y_train, epochs=5, batch_size=128)\n", "predictions = model.predict_proba(X_test)\n", "\n", "ans = pd.DataFrame(predictions)\n", "ans = ans[0]"]}]}