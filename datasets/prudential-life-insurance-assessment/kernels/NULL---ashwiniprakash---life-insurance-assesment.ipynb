{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e48ba697552d460836b419e016e36dc71dc40f32"},"cell_type":"markdown","source":"Import Necessary Libraries & Import .csv files into pandas DataFrames \n"},{"metadata":{"trusted":true,"_uuid":"dc47c42cdde847fa03376e16869674ae5e943561","collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76172acc6297bcf71b7d0b6081c9d03afb55558c","collapsed":true},"cell_type":"code","source":"#Lets see data sample\ndata_train.sample(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea4cb8230c403fd41142fa2be56cde7ccb41bced","collapsed":true},"cell_type":"code","source":"# Lets check Df shape\ndata_train.shape\n\n# there are 128 features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d67c5ef495c625d68bbc481dde37e81d68eddbf6","collapsed":true},"cell_type":"code","source":"data_test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8a989aa195328f1729b9487dc0ccfec08f2a72e"},"cell_type":"markdown","source":"**Feature details posted in data overview section - **\nThe following variables are all categorical (nominal):\n\nProduct_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41\n\nThe following variables are continuous:\n\nProduct_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5\n\nThe following variables are discrete:\n\nMedical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32\n\nMedical_Keyword_1-48 are dummy variables."},{"metadata":{"_uuid":"994f8c77fe6e4c826186b7fb3ec8b2d2b10c6b0b"},"cell_type":"markdown","source":"We will check for missing values . \n\nIf a categorical feature has missing values - if required will impute it with median \n\nif a continous feature has missing values - if required will impute it with mean "},{"metadata":{"trusted":true,"_uuid":"30d1e3da363f295e6fb13479829e1c2352e6712c","collapsed":true},"cell_type":"code","source":"data_train.dtypes\ndata_train.dtypes.unique()\n#No string data type - all are numerical values which is good.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"696a2678b16ebcfa7c8c7bd1497d36470e1327eb"},"cell_type":"markdown","source":"\n#Missing Value imputation "},{"metadata":{"trusted":true,"_uuid":"aa3245c4f1616ab2d2a5b48bafe92c3315975350","collapsed":true},"cell_type":"code","source":"data_train.isnull().sum()[data_train.isnull().sum() !=0]\n#Below listed columns have missing values in the combined (Train+test) dataset. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3313565e92d28315bb943b55de5f74da30093c26","collapsed":true},"cell_type":"code","source":"# Lets draw a bar graph to visualize percentage of missing features in train set\nmissing= data_train.isnull().sum()[data_train.isnull().sum() !=0]\nmissing=pd.DataFrame(missing.reset_index())\nmissing.rename(columns={'index':'features',0:'missing_count'},inplace=True)\nmissing['missing_count_percentage']=((missing['missing_count'])/59381)*100\nplt.figure(figsize=(20,8))\nsns.barplot(y=missing['features'],x=missing['missing_count_percentage'])\n\n#Looking at below bar grah- \n#Medical_Hist_32/24/15/10 , Family_hist_5 are top five features with huge amount of missing data ( imputaion to these might not be fruitful - I will drop these features)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df1c2842216d309892a73bbee9347c7c2bac125","collapsed":true},"cell_type":"markdown","source":" \n \n Employment_Info_1_4_6 Insurance_History_5 Family_Hist_2-3-4-5 are continous features . \n\nThe following variables are discrete:\nMedical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32\n\n1. remove rows with missing values and see model performance \n2. impute missing values with mean and median or may be mode.\n\n"},{"metadata":{"trusted":true,"_uuid":"710b6542c372e7336fa10bbfc360f6086e01a806","collapsed":true},"cell_type":"code","source":"# Lets see spread of data before we impute missing values\nplt.plot(figsize=(15,10))\nsns.boxplot(data_train['Employment_Info_1'])\n# Employment_Info_1 seems to have lots of outliers - Median should be right to impute missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1739a512ad97d9e27d420162e2b1b8162010a26","collapsed":true},"cell_type":"code","source":"data_train['Employment_Info_1'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c85e9ccc446d787de492acc319e5f1d8e8c7050","collapsed":true},"cell_type":"code","source":"data_train['Employment_Info_1'].fillna(data_train['Employment_Info_1'].median(),inplace=True) \n# imputing with Meadian , as there are lots of Outliers \ndata_test['Employment_Info_1'].fillna(data_test['Employment_Info_1'].median(),inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f7322dad4bbea3846e714e98cb92eb9d26717f3","collapsed":true},"cell_type":"code","source":"data_train['Employment_Info_1'].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d9d98be42375e3a7bd77b3ca3dfdb58b1d08014","collapsed":true},"cell_type":"code","source":"#Outlier Treatment -\ndata_train['Employment_Info_1'].describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a49390cbd4b6a2fb80d9b9d54f6ddfc4e9c0272","collapsed":true},"cell_type":"code","source":"sns.boxplot(data_train['Employment_Info_4'])\n# ['Employment_Info_4'] is has most of the values centered close to zero , also huge presence of outliers \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"26827f6ff3dadc961cf08e7dc004d072ec01da52"},"cell_type":"code","source":"data_train['Employment_Info_4'].fillna(data_train['Employment_Info_4'].median(),inplace=True)\ndata_test['Employment_Info_4'].fillna(data_test['Employment_Info_4'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057122c1a45c1ba48cc78ec239526eb2dd0b092f","collapsed":true},"cell_type":"code","source":"sns.boxplot(data_train['Employment_Info_6'])\n#No outlieers - mean should be rigth candidate to impute missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2b8b8bba5c5dc090d1a71294abbb9dbb1ad30cb","collapsed":true},"cell_type":"code","source":"data_train['Employment_Info_6'].fillna(data_train['Employment_Info_6'].mean(),inplace=True)\ndata_test['Employment_Info_6'].fillna(data_test['Employment_Info_6'].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0e66d8d482c1250a6dbce5c698e8929350186f4","collapsed":true},"cell_type":"code","source":"sns.boxplot(y=data_train['Medical_History_1'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c35f9d5694aa95d05ac7d0bcca3ad5285b7d987","collapsed":true},"cell_type":"code","source":"data_train['Medical_History_1'].fillna(data_train['Medical_History_1'].median(),inplace=True)\ndata_test['Medical_History_1'].fillna(data_test['Medical_History_1'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68355ffd37b7fa2dacbcb9938f107c01329ff054","collapsed":true},"cell_type":"code","source":"#lets drop features with high number of missing values \ndata_train.drop(['Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32','Family_Hist_3','Family_Hist_5','Family_Hist_2','Family_Hist_4'],axis=1,inplace=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1ff98c8360f28937903ce2f29540295848d961f","collapsed":true},"cell_type":"code","source":"data_test.drop(['Medical_History_10','Medical_History_15','Medical_History_24','Medical_History_32','Family_Hist_3','Family_Hist_5','Family_Hist_2','Family_Hist_4'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfce1fbecd10290c30988db3b0ff1e8cbec76c2e","collapsed":true},"cell_type":"code","source":"data_train.isnull().sum()[data_train.isnull().sum()!=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dcfee893ee7a475d7c0a62bcea6af8994700488d"},"cell_type":"code","source":"#imputing with median \ndata_train['Insurance_History_5'].fillna(data_train['Insurance_History_5'].median(),inplace=True)\ndata_test['Insurance_History_5'].fillna(data_test['Insurance_History_5'].median(),inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9070243ca0c2fe0d4c63266523288ac5006e2ae1","collapsed":true},"cell_type":"code","source":"data_train.isnull().sum()\n#All missing NA values has been treated\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35ef875713bec32d49924cd4b9c726d5724196b1","collapsed":true},"cell_type":"markdown","source":"#Now that we have imputed Missing values - we can move to next step to convert string type feature data into numric data"},{"metadata":{"trusted":true,"_uuid":"80a5e1a640aede84dac9b576d5e0b8521f03ab46","collapsed":true},"cell_type":"code","source":"data_train.head()\n#Product_info_2 seems to be the only feature where we should map string values with numeric categorical values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4565bdf4ff8271e00f1fe6fc15dc1659bbcb8962","collapsed":true},"cell_type":"code","source":"data_train['Product_Info_2'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fe8d350fd2bbfbc6ddefbb7f042339093876b32","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle=LabelEncoder()\ndata_train['Product_Info_2']=le.fit_transform(data_train['Product_Info_2'])\ndata_test['Product_Info_2']=le.transform(data_test['Product_Info_2'])\n\n#data_train.dtypes\n#Employment_Info_1-4-6  Insurance_History_5\n# I faced an error stating dta types of train columns are not float/numeric ill apply encoder on all column and see what happens\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b16e9811237654024cccfb0fe2b2bfdf455422b4","collapsed":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"131ee4974b789fb73a9c09bb692a9831b90f7319","collapsed":true},"cell_type":"code","source":"# feature meatrix and response vector seperation\nX_train=data_train.iloc[:,0:-1]\ny_train=data_train['Response']\nX_train.drop('Id',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c4fda79b1e5eff3f819909fa75464d68e39dd56","collapsed":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10ed0d65520638fc71f41ec9cff2eb20fbe1864d","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"613e33ad578fe2b0239719ea9471168f7da0d8c8"},"cell_type":"markdown","source":"Machine Learning Model fitting and prediction"},{"metadata":{"trusted":true,"_uuid":"9fb978ecf2d0d125486de55366a416e1a19e2cb3","collapsed":true},"cell_type":"code","source":"y_train.unique()\n#there are 8 labels/class in dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64def49ee428f629727d5c572c4fd04c828816e3","collapsed":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.model_selection import cross_val_score,GridSearchCV\nfrom sklearn.multiclass import OneVsRestClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6990d687b9b18301d815ad933cb040ea4903b5d","collapsed":true},"cell_type":"code","source":"# Using a Decision Tree classifier \nfrom sklearn.tree import DecisionTreeClassifier\nparam_grid={'max_depth':range(1,20,2)}\nDT=DecisionTreeClassifier()\nclf_DT=GridSearchCV(DT,param_grid,cv=10,scoring='accuracy',n_jobs=-1).fit(X_train,y_train)\ny_pred=clf_DT.predict(X_test)\nprint(accuracy_score(y_test,y_pred))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a10af5e3c6e72f442c0157b22d9f3f3e7aa05f4","collapsed":true},"cell_type":"code","source":"#Using a Random Forest tree classifier\nfrom sklearn.ensemble import RandomForestClassifier\nparam_grid={'max_depth':range(1,20,2)}\nRF=RandomForestClassifier()\nclf_rf=GridSearchCV(RF,param_grid,cv=10,scoring='accuracy',n_jobs=-1).fit(X_train,y_train)\ny_pred=clf_rf.predict(X_test)\naccuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31fbbac80fef7fbbe79a5636535cc69b5ea4f1bf","collapsed":true},"cell_type":"markdown","source":"For now i'll use Decison tree for summission ,  i'll work on to improve my predictions, any suggestion/feedback is appreciated.\n"},{"metadata":{"trusted":true,"_uuid":"b300a27c8d18cbf4147d303ce97d88eb4aea3252","collapsed":true},"cell_type":"code","source":"ids = data_test['Id']\npredictions = clf_DT.predict(data_test.drop('Id', axis=1))\n\n\noutput = pd.DataFrame({ 'Id' : ids, 'Response': predictions })\noutput.to_csv('/Users/adityaprakash/Downloads/predictions.csv', index = False)\noutput.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"644d7b67036e91e98aa1bd255204cbfa85e3dd56"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}