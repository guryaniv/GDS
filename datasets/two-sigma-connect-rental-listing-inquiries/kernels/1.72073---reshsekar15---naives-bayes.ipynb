{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d3c3aba2-7519-ca0f-a7c3-81ddb0520a9d"
      },
      "source": [
        "In this notebook, we will be trying the naives bayes algorithm to make a submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfc795ca-5091-152a-83d4-9ad03a6c7484"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12ffc1f6-65ba-e1a7-2aec-a9f484f9e1c6"
      },
      "outputs": [],
      "source": [
        "# objective is to predict a number of listing enquiries based on features\n",
        "train = pd.read_json(\"../input/train.json\", \"r\")\n",
        "test = pd.read_json(\"../input/test.json\", \"r\")\n",
        "sample_sub = pd.read_csv(\"../input/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "01fd7711-9c58-acf7-30ce-9df1d69d46ba"
      },
      "outputs": [],
      "source": [
        "sample_sub.head()\n",
        "# the above is what our submission is supposed to look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09d0f362-d523-7d5a-f715-6721e78b456c"
      },
      "outputs": [],
      "source": [
        "train = train[['price', 'listing_id', 'bathrooms', 'bedrooms', 'interest_level', 'latitude', 'longitude']]\n",
        "test = test[['price', 'listing_id', 'bathrooms', 'bedrooms', 'latitude', 'longitude']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b83cdbba-4cbb-b0e6-609e-c90f33b8cc8b"
      },
      "outputs": [],
      "source": [
        "train_target = train['interest_level']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb72663f-d9c3-18a8-081e-870d59ffb47c"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6b3928e3-f1c6-5f08-b6b3-f449794728b6"
      },
      "outputs": [],
      "source": [
        "gnb = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4aa06944-6e0f-8faa-5fd8-ec0d43319042"
      },
      "outputs": [],
      "source": [
        "train.index = train['listing_id']\n",
        "train = train.drop('interest_level', 1)\n",
        "model = gnb.fit(train, train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5cefb4c2-be8f-44d5-eea1-c150996e3cbb"
      },
      "outputs": [],
      "source": [
        "test.index = test['listing_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55cd35cc-f6a2-ca40-ce86-7d5d7f5be91f"
      },
      "outputs": [],
      "source": [
        "y = model.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "557a6cf3-5b5b-7936-a863-4fcd67bcb552"
      },
      "outputs": [],
      "source": [
        "y_dat = pd.DataFrame(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c15a4bed-66a7-8daa-1aed-7e81cfc77872"
      },
      "outputs": [],
      "source": [
        "#y_dat.copy(deep = False)\n",
        "y_dat.loc[:,'listing_id'] = test.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d41a9937-5e8a-155e-fa0d-b2f6d91f830c"
      },
      "outputs": [],
      "source": [
        "y_dat.rename(columns = {'0':'medium', '1':'low', '2':'high'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7421dc0-a742-0a4f-1056-f579bef7ef83"
      },
      "outputs": [],
      "source": [
        "y_dat.columns = ['medium', 'low', 'high', 'listing_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4822d39-0343-a31c-45ac-706d71ce8603"
      },
      "outputs": [],
      "source": [
        "data = y_dat[['listing_id', 'high', 'medium', 'low']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a90760a5-a6d9-5a0f-5eb1-b7167224acf1"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "774dc626-e11e-7c0b-d76f-133c4a5b623f"
      },
      "outputs": [],
      "source": [
        "#medium, low, high\n",
        "#writer = pd.ExcelWriter('/Users/reshmasekar/Desktop/sub.xlsx', engine='xlsxwriter')\n",
        "# Convert the dataframe to an XlsxWriter Excel object.\n",
        "data.to_csv(\"sub_rf_4.csv\", index = False)\n",
        "#y_dat.to_excel(\"/Users/reshmasekar/Desktop\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63ee2319-2e51-b417-d6f1-7b3486d2cf35"
      },
      "outputs": [],
      "source": [
        "# improving predictive accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e1e3c49-ad75-2d72-e129-f6700258153a"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4bc1e038-6991-1b72-2132-98b1e4a4a369"
      },
      "outputs": [],
      "source": [
        "# objective is to predict a number of listing enquiries based on features\n",
        "train = pd.read_json(\"../input/train.json\", \"r\")\n",
        "test = pd.read_json(\"../input/test.json\", \"r\")\n",
        "sample_sub = pd.read_csv(\"../input/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2fa48deb-9e6a-b8fd-b679-c77103ce1340"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ca3334d-507d-3bc0-5bb2-01984e420a0a"
      },
      "outputs": [],
      "source": [
        "# splitting words from description\n",
        "description=train['description']\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "words_total=\"\"\n",
        "for word in description:\n",
        "    words_total = words_total +word\n",
        "tokens=tokenizer.tokenize(words_total)\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer=CountVectorizer(tokens)\n",
        "dtm=vectorizer.fit_transform(train['description'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc8ebdb9-e69d-1fa1-ddc9-5fe4a81e2bbc"
      },
      "outputs": [],
      "source": [
        "#Need to remove stop words and also use three tokens? \n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}