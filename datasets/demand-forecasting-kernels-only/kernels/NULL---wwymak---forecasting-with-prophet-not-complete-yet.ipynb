{"cells":[{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9290ff1df89dc64f5494071e8c38a1d9dc168520"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom fbprophet import Prophet\nfrom fbprophet.diagnostics import cross_validation, performance_metrics\nfrom sklearn.externals import joblib\nfrom sklearn.metrics import m\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport rpy2\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr \nimport datetime\ndatetime.datetime.strptime\n%matplotlib inline \n \nplt.rcParams['figure.figsize']=(20,10)\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b095ed8aa742bb41e661da84e8bef0cf75dfde5a"},"cell_type":"markdown","source":"##### We can see that the test set is for 2018 whereas the train set is 2013-2017. Use 2013-end2016 for train, 2017 for test"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ad95e969f8b1c989df5078f93b62ae4d7b32bccb"},"cell_type":"code","source":"df_test = pd.read_csv('./data/test.csv.zip')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"768f5952aa0a60cc3de22be31b6265a6ad5544a1"},"cell_type":"code","source":"df = pd.read_csv('./data/train.csv.zip')\ndf['datetime'] = pd.to_datetime(df['date'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"87c045945a2a1bf67642f0fb460a35682704b932"},"cell_type":"code","source":"df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7f49edab5d3d786a21cb679fc53d34c4d157f5ff"},"cell_type":"code","source":"df_train = df[df['datetime']<=datetime.date(2016,12,31)]  \ndf_test = df[df['datetime']>datetime.date(2016,12,31)]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"30dcd02b5f971bbd1cef6f399334e94584e18bb4"},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee46b72d3f2159701e1dd2d2b97fa2c7b0df4c7e"},"cell_type":"markdown","source":"### Modelling on only 1 item from one store: \nInvestigating what Prophet does:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e21b79e1e0ad5f0dcbebdb4c13bd039b2aa883fe"},"cell_type":"code","source":"df1 = df[(df.store == 1 ) & (df.item == 1 )]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a1f7a134592b141365406e692567d5157c994cdb"},"cell_type":"code","source":"plt.plot(df1.datetime, df1.sales)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20ee8a7631156c4803347c4ff8065e43013cb253"},"cell_type":"markdown","source":"We have to convert the dataframe into a format that prophet expects:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e4e2a60dd2dd91f7f687f1c86f264427880cce6d"},"cell_type":"code","source":"df2 = pd.DataFrame()\ndf2[['ds', 'y']] = df1[['date', 'sales']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f4ac19dfe6fbefba4697ec3d4444f4efd4b5b5ce"},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1ba889aa609e0dc5abc1ec9bd8455b763f6b55bf"},"cell_type":"code","source":"train_slice = int(0.9 * len(df2['ds']))                      \ntrain = df2[:train_slice]\ntest = df2[train_slice-10:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"b789591470be167ccfef54c4cc3a0a39f3d2a7bb"},"cell_type":"code","source":"m = Prophet()\nm.fit(df2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"004cb9a80e89b3251f6eff14b327897731d687ad"},"cell_type":"code","source":"test = test[['ds']]\nforecast = m.predict(df2)\n# forecast.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"6b3bc5b2fa6728608921c55adae314b2ed178c01"},"cell_type":"code","source":"fig1 = m.plot(forecast)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"638ff2f47cd1c4c9c090be3ee012e5b8d8280029"},"cell_type":"code","source":"fig2=m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"20b5f23d696a97cbf68410b0a133736d03dcc571"},"cell_type":"code","source":"df_cv = cross_validation(m, initial='730 days', period='365 days', horizon = '365 days')\ndf_cv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2672e1f092f8ed35039a9de8a1855be6a46334d6"},"cell_type":"code","source":"df_p = performance_metrics(df_cv)\ndf_p.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"662c991092fc1ad025d457ff47c3fba5a6c610c3"},"cell_type":"code","source":"from fbprophet.plot import plot_cross_validation_metric\nfig = plot_cross_validation_metric(df_cv, metric='mape')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"752a1a211a187440f22249692a046ccf4fdb3e1a"},"cell_type":"code","source":"df_p.mape.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bfde329be5e1d4bb778c20787907c6580ef3e77"},"cell_type":"markdown","source":"### Items across stores-- do they have the same trends?"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"584752b31be0bf663ca73a97d4a734924c812264"},"cell_type":"code","source":"df_item1 = df[df.item ==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"53f01ab0f0dc84a231ceba9be77c89b1ec543a97"},"cell_type":"code","source":"df_item1.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f6bcce43e9aff5843f87c084299cd43eaeccaf01"},"cell_type":"code","source":"groups = df_item1.groupby('store')\nfig, ax = plt.subplots()\nfor name, group in groups:\n    ax.plot(group.datetime, group.sales, label=name)\nax.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10fb39823df7f983d20580811df7cf780e426224"},"cell_type":"markdown","source":"it certainly seems like the stores have the same periodicity etc, but the value are offset from one another. \nCan we train only on 1 store (using e.g mean off the values)? or is one model per store better?"},{"metadata":{"_uuid":"5b2a5e18905a09e0bbc6ac027876f6dab1fc0eda"},"cell_type":"markdown","source":"One per store:"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ce6d0a2fa1f5df02fe0e5eacd7cb9c96f36b0e25"},"cell_type":"code","source":"df_item1 = df[df.item ==1]\ngroups = df_item1.groupby('store')\n\nmodels = []\nhistoric_forecasts = []\nmetrics = []\nfor store, group in groups:\n    alldata = pd.DataFrame()\n    alldata['ds'] = group.datetime\n    alldata['y'] = group.sales\n    \n    train = alldata[alldata['ds']<=datetime.date(2016,12,31)]  \n    test = alldata[alldata['ds']>datetime.date(2016,12,31)]  \n    \n    m = Prophet()\n    m.fit(train)\n    models.append(m)\n    forecast = m.predict(test)\n    historic_forecasts.append(forecast)\n    df_cv = cross_validation(m, initial='730 days', period='365 days', horizon = '365 days')\n    df_p = performance_metrics(df_cv)\n    metrics.append(df_p)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"545b578121faa45d5ef9ce774c0cc6d6ecf631ee"},"cell_type":"code","source":"joblib.dump(models, 'test_models_item1.pkl')\njoblib.dump(historic_forecasts, 'test_historicforecasts_item1.pkl')\njoblib.dump(metrics, 'test_metrics_item1.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9715cba6a196e1f5a1da9589bda2d1ed57fb6a1c"},"cell_type":"code","source":"test_metrics = []\nfor store, group in groups:\n    alldata = pd.DataFrame()\n    alldata['ds'] = group.datetime\n    alldata['y'] = group.sales\n    test = alldata[alldata['ds']>datetime.date(2016,12,31)]  \n    try:\n        metric_df = historic_forecasts[store -1].set_index('ds')[['yhat']].join(test.set_index('ds').y).reset_index()\n        metric_df.dropna(inplace=True)\n        test_metrics.append(metric_df)\n    except Exception as e:\n        print(e, store)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8c718e73cc12dcca68574d24d6283ac32ad413fd"},"cell_type":"code","source":"historic_forecasts[0].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4443119b849f646348d0e918a51672a063c2aac8"},"cell_type":"markdown","source":"#### Define the metric function we'll be using (symmetric mean absolute percentage error)"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2c96fead7b03c0130b255de317cd83cce5b68270"},"cell_type":"code","source":"\n\n# def mape(df):\n#     \"\"\"Mean absolute percent error\n#     Parameters\n#     ----------\n#     df: Cross-validation results dataframe.\n#     Returns\n#     -------\n#     Array of mean absolute percent errors.\n#     \"\"\"\n#     ape = np.abs((df['y'] - df['yhat']) / (df['y'] + 0.000000000001))\n#     return np.mean(ape)\n\n\n\ndef smape(df):\n    \"\"\"Symmetric mean absolute percentage error\n    Parameters\n    ----------\n    df: Results dataframe.\n    Returns\n    -------\n    Array of symmetric mean absolute percent errors.\n    \"\"\"\n    \n    #note: adding in + 0.000000000001 to handle division by zero.\n    return np.mean(2 * np.abs(df['y'] - df['yhat']) /(df['y'] + df['yhat']+ 0.000000000001))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"838b87154a9bd02ef07d25012c6084a66ddeae01"},"cell_type":"code","source":"for m in test_metrics:\n    print(smape(m))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"78d24065bffdfba23059bf8c7fe3a38886ef69fb"},"cell_type":"code","source":"\ngroups_avg = df_item1.groupby('date').mean()\ngroups_avg = groups_avg.reset_index()\ngroups_avg\n\nprophet_input = pd.DataFrame()\nprophet_input['ds'] = pd.to_datetime(groups_avg['date'])\nprophet_input['y'] = groups_avg['sales']\n\n\ntrain_avg = prophet_input[prophet_input['ds']<=datetime.date(2016,12,31)]  \ntest_avg = test_metrics \n\n    \navg_model = Prophet()\navg_model.fit(train)\n\nhistoric_forecasts_avgmodel = []\ntest_metrics_avgmodel = []\nfor store, group in groups:\n    alldata = pd.DataFrame()\n    alldata['ds'] = group.datetime\n    alldata['y'] = group.sales\n    \n    train = alldata[alldata['ds']<=datetime.date(2016,12,31)]  \n    test = alldata[alldata['ds']>datetime.date(2016,12,31)]  \n\n    forecast = avg_model.predict(test)\n    historic_forecasts_avgmodel.append(forecast)\n    \n    try:\n        metric_df = forecast.set_index('ds')[['yhat']].join(test.set_index('ds').y).reset_index()\n        metric_df.dropna(inplace=True)\n        test_metrics_avgmodel.append(metric_df)\n    except Exception as e:\n        print(e, store)\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"8d766488554ac24a3f0b4b9df81d0f68a5817a69"},"cell_type":"code","source":"for m in test_metrics_avgmodel:\n    print(smape(m))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30ad1faf4ab1f74c53de6838c5d3e1dd4a0ec25e"},"cell_type":"markdown","source":"As expected We can see that just making a model on the average items, ignoring the store performed worse. Since prophet models are fairly quick to build, lets build a dumb version first with a model per store per item."},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f820a17726ac99779fb2372d84ac4ae4a23b2f1c"},"cell_type":"code","source":"groupby","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}