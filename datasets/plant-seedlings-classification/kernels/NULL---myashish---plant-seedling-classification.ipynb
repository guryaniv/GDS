{"nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "code", "outputs": [], "metadata": {"_uuid": "b64951258e2f5a5e5f3f17671cc0f8d76aae73e6", "_cell_guid": "fa2d471e-bf4d-4ebe-8474-7973d9a51e1e", "collapsed": true}, "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["%matplotlib inline\n", "import os\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import cv2\n", "import numpy as np\n", "from glob import glob\n", "import seaborn as sns"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["BASE_DATA_FOLDER = \"../input\"\n", "TRAin_DATA_FOLDER = os.path.join(BASE_DATA_FOLDER, \"train\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Reading images\n", "\n", "Reading  images and converting it from RGB to BGR (because OpenCV uses BGR)"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["images_per_class = {}\n", "for class_folder_name in os.listdir(TRAin_DATA_FOLDER):\n", "    class_folder_path = os.path.join(TRAin_DATA_FOLDER, class_folder_name)\n", "    class_label = class_folder_name\n", "    images_per_class[class_label] = []\n", "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n", "        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n", "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n", "        images_per_class[class_label].append(image_bgr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To know the Number of images per class"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["for key,value in images_per_class.items():\n", "    print(\"{0} -> {1}\".format(key, len(value)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Ploting images\n", "\n", "Plotted images so that I can see what the input looks like"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["def plot_for_class(label):\n", "    nb_rows = 3\n", "    nb_cols = 3\n", "    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=(6, 6))\n", "\n", "    n = 0\n", "    for i in range(0, nb_rows):\n", "        for j in range(0, nb_cols):\n", "            axs[i, j].xaxis.set_ticklabels([])\n", "            axs[i, j].yaxis.set_ticklabels([])\n", "            axs[i, j].imshow(images_per_class[label][n])\n", "            n += 1        "]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["plot_for_class(\"Small-flowered Cranesbill\")"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["plot_for_class(\"Maize\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Preprocessing for the images:"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["def create_mask_for_plant(image):\n", "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n", "\n", "    sensitivity = 35\n", "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "\n", "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n", "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n", "    \n", "    return mask\n", "\n", "def segment_plant(image):\n", "    mask = create_mask_for_plant(image)\n", "    output = cv2.bitwise_and(image, image, mask = mask)\n", "    return output\n", "\n", "def sharpen_image(image):\n", "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n", "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n", "    return image_sharp"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["# Test image to see the changes\n", "image = images_per_class[\"Small-flowered Cranesbill\"][97]\n", "\n", "image_mask = create_mask_for_plant(image)\n", "image_segmented = segment_plant(image)\n", "image_sharpen = sharpen_image(image)\n", "\n", "fig, axs = plt.subplots(1, 4, figsize=(20, 20))\n", "axs[0].imshow(image)\n", "axs[1].imshow(image_mask)\n", "axs[2].imshow(image_segmented)\n", "axs[3].imshow(image_sharpen)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["we can see that the image on the right is more recognizable than the original image on the left."]}, {"cell_type": "markdown", "metadata": {}, "source": ["From the mask image what we created above(because we need that for the segmentation), we can extract some features. For example we can see how the area of the plant changes based on their classes.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Of course from the contours we can extract much more information than the area of the contour and the number of components, but this is the one I would like to show you."]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["def find_contours(mask_image):\n", "    return cv2.findContours(mask_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n", "\n", "def calculate_largest_contour_area(contours):\n", "    if len(contours) == 0:\n", "        return 0\n", "    c = max(contours, key=cv2.contourArea)\n", "    return cv2.contourArea(c)\n", "\n", "def calculate_contours_area(contours, min_contour_area = 250):\n", "    area = 0\n", "    for c in contours:\n", "        c_area = cv2.contourArea(c)\n", "        if c_area >= min_contour_area:\n", "            area += c_area\n", "    return area"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["areas = []\n", "larges_contour_areas = []\n", "labels = []\n", "nb_of_contours = []\n", "\n", "for class_label in images_per_class.keys():\n", "    for image in images_per_class[class_label]:\n", "        mask = create_mask_for_plant(image)\n", "        contours = find_contours(mask)\n", "        \n", "        area = calculate_contours_area(contours)\n", "        largest_area = calculate_largest_contour_area(contours)\n", "        \n", "        areas.append(area)\n", "        nb_of_contours.append(len(contours))\n", "        larges_contour_areas.append(largest_area)\n", "        labels.append(class_label)"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["features_df = pd.DataFrame()\n", "features_df[\"label\"] = labels\n", "features_df[\"area\"] = areas\n", "features_df[\"largest_area\"] = larges_contour_areas\n", "features_df[\"number_of_components\"] = nb_of_contours"]}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "execution_count": null, "source": ["features_df.groupby(\"label\").describe()"]}], "metadata": {"language_info": {"mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "version": "3.6.3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}