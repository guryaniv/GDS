{"metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python [default]", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {}, "cell_type": "markdown", "source": ["I'm only just beginning my data science journey so am looking for some constructive feedback/criticism on my work so far. Thanks to the authors of these great kernels for kickstarting my thought processes:\n", "\n", "https://www.kaggle.com/headsortails/be-my-guest-recruit-restaurant-eda\n", "\n", "https://www.kaggle.com/captcalculator/a-very-extensive-recruit-exploratory-analysis"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### Import some useful libraries"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import geopandas as gpd\n", "\n", "import datetime\n", "import calendar\n", "from geopy.geocoders import Nominatim\n", "\n", "import matplotlib.pyplot as plt\n", "import matplotlib.dates as mdates\n", "import matplotlib.ticker as ticker\n", "import seaborn as sns\n", "\n", "import folium\n", "from folium.plugins import MarkerCluster,FastMarkerCluster, HeatMap\n", "\n", "#matplotlib display in notebook\n", "%matplotlib inline \n", "\n", "#seaborn style\n", "sns.set(style='whitegrid', palette='muted', color_codes=True)"], "execution_count": 6}, {"metadata": {}, "cell_type": "markdown", "source": ["### Import the files as dataframes"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_reserve = pd.read_csv('../input/air_reserve.csv')\n", "df_air_store = pd.read_csv('../input/air_store_info.csv')\n", "df_air_visit = pd.read_csv('../input/air_visit_data.csv')\n", "df_hpg_reserve = pd.read_csv('../input/hpg_reserve.csv')\n", "df_hpg_store = pd.read_csv('../input/hpg_store_info.csv')\n", "df_date_info = pd.read_csv('../input/date_info.csv')\n", "df_store_id_rel = pd.read_csv('../input/store_id_relation.csv')"], "execution_count": 7}, {"metadata": {}, "cell_type": "markdown", "source": ["### Let's take a look at the data in the dataframes..."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_reserve.head()"], "execution_count": 8}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_store.head()"], "execution_count": 9}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_visit.head()"], "execution_count": 10}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_hpg_reserve.head()"], "execution_count": 11}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_hpg_store.head()"], "execution_count": 12}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_store_id_rel.head()"], "execution_count": 13}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_date_info.head()"], "execution_count": 14}, {"metadata": {}, "cell_type": "markdown", "source": ["Most holidays fall on a monday which is to be expected"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_date_info.groupby('day_of_week')\\\n", "            .agg({'holiday_flg':'sum'}) \\\n", "            .sort_values(by='holiday_flg', ascending=False)\\\n", "            .reset_index() "], "execution_count": 15}, {"metadata": {}, "cell_type": "markdown", "source": ["### Let's wrangle the reservation data first"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# merge 'air' tables and bring over any 'hpg' store data\n", "df_air_merged = df_air_reserve.merge(df_air_store,on='air_store_id', how='left').merge(\n", "    df_store_id_rel, on='air_store_id', how='left').merge(df_hpg_store,on='hpg_store_id', how='left',suffixes=('_air','_hpg'))"], "execution_count": 16}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# merge 'hpg' tables and bring over any 'air' store data\n", "df_hpg_merged = df_hpg_reserve.merge(df_hpg_store,on='hpg_store_id', how='left').merge(\n", "    df_store_id_rel,on='hpg_store_id', how='left').merge(df_air_store,on='air_store_id', how='left',suffixes=('_hpg','_air'))"], "execution_count": 17}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# add source column\n", "df_air_merged['source'] = 'air'\n", "df_hpg_merged['source'] = 'hpg'"], "execution_count": 18}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# append tables together\n", "df_res_merged = df_air_merged.append(df_hpg_merged)\n", "df_res_merged.reset_index(inplace=True)"], "execution_count": 19}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# format date fields\n", "df_res_merged['visit_datetime'] = pd.to_datetime(df_res_merged.visit_datetime)\n", "df_res_merged['reserve_datetime'] = pd.to_datetime(df_res_merged.reserve_datetime)\n", "\n", "df_res_merged['calendar_date'] = df_res_merged.visit_datetime.dt.date\n", "df_res_merged['visit_time'] = df_res_merged.visit_datetime.dt.time\n", "df_res_merged['reserve_date'] = df_res_merged.reserve_datetime.dt.date\n", "df_res_merged['reserve_time'] = df_res_merged.reserve_datetime.dt.time"], "execution_count": 20}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# add month, year, and season\n", "df_res_merged['visit_month'] = df_res_merged.visit_datetime.apply(lambda x: x.strftime(\"%b\"))\n", "df_res_merged['visit_year'] = df_res_merged.visit_datetime.apply(lambda x: x.strftime(\"%Y\"))\n", "df_res_merged['reserve_month'] = df_res_merged.reserve_datetime.apply(lambda x: x.strftime(\"%b\"))\n", "df_res_merged['reserve_year'] = df_res_merged.reserve_datetime.apply(lambda x: x.strftime(\"%Y\"))\n", "\n", "seasons = {'Jan': 'Winter','Feb': 'Winter','Mar': 'Spring','Apr': 'Spring','May': 'Spring','Jun': 'Summer',\n", "           'Jul': 'Summer','Aug': 'Summer','Sep': 'Autumn','Oct': 'Autumn','Nov': 'Autumn','Dec': 'Winter'}\n", "\n", "df_res_merged['reserve_season'] = df_res_merged['reserve_month'].map(seasons)\n", "df_res_merged['visit_season'] = df_res_merged['visit_month'].map(seasons)"], "execution_count": 21}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# format df_date_info date to merge\n", "df_date_info['calendar_date'] = pd.to_datetime(df_date_info.calendar_date)\n", "df_date_info['calendar_date'] = df_date_info.calendar_date.dt.date\n", "df_res_merged = df_res_merged.merge(df_date_info, on='calendar_date', how='left')\n", "df_res_merged.rename(columns={\"day_of_week\": \"day_of_week_visit\", \"holiday_flg\": \"holiday_flag_visit\"}, inplace=True)\n", "df_date_info.rename(columns={\"calendar_date\": \"reserve_date\"}, inplace=True)\n", "df_res_merged = df_res_merged.merge(df_date_info, on='reserve_date', how='left')\n", "df_res_merged.rename(columns={\"day_of_week\": \"day_of_week_res\", \"holiday_flg\": \"holiday_flag_res\"}, inplace=True)"], "execution_count": 22}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# time between reservation and visit\n", "df_res_merged['res_vs_visit'] = df_res_merged['visit_datetime'] - df_res_merged['reserve_datetime']\n", "df_res_merged['res_vs_visit_days'] = df_res_merged['res_vs_visit'].astype('timedelta64[D]')\n", "df_res_merged['res_vs_visit_hours'] = df_res_merged['res_vs_visit'].astype('timedelta64[h]')"], "execution_count": 23}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# holiday the day before and after visit\n", "df_res_merged['holiday_before_visit'] = df_res_merged.holiday_flag_visit.shift(1)\n", "df_res_merged.holiday_before_visit.fillna(0,inplace=True)\n", "df_res_merged['holiday_after_visit'] = df_res_merged.holiday_flag_visit.shift(-1)\n", "df_res_merged.holiday_after_visit.fillna(0,inplace=True)"], "execution_count": 24}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_res_merged.describe()"], "execution_count": 25}, {"metadata": {}, "cell_type": "markdown", "source": ["### Reservations Visualisation"]}, {"metadata": {}, "cell_type": "markdown", "source": ["First we'll plot some data based on the \"genre\" of the restaurant according to the HPG data"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_genre = df_res_merged[df_res_merged.hpg_genre_name != 'No Data'].groupby(['hpg_genre_name']) \\\n", "                        .agg({'index':'size', 'reserve_visitors':'mean', 'res_vs_visit_hours':'mean'})\\\n", "                        .reset_index()\n", "\n", "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(13, 15))\n", "ax1.set_title('Reservations made total')\n", "ax2.set_title('Mean time between\\n reservation and visit')\n", "ax3.set_title('Mean number of\\n visitors per reservation')\n", "sns.barplot(x='index', y='hpg_genre_name', data=df_genre,\n", "            ax=ax1, color='r')\n", "sns.barplot(x='res_vs_visit_hours', y='hpg_genre_name', data=df_genre, \n", "            ax=ax2, color='g')\n", "sns.barplot(x='reserve_visitors', y='hpg_genre_name', data=df_genre, \n", "            ax=ax3, color='b')"], "execution_count": 26}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Japanese style is far and away the most popular\n", "- Looks like there is usually a long time between the reservation and visit for \"Party\" type restaurants. Also the number of people on the reservation is significantly larger than most others."]}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": ["How about according to the \"Air\" data?        "]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_genre = df_res_merged[df_res_merged.air_genre_name != 'No Data'].groupby(['air_genre_name']) \\\n", "                        .agg({'index':'size', 'reserve_visitors':'mean', 'res_vs_visit_hours':'mean'})\\\n", "                        .reset_index()\n", "\n", "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(13, 10))\n", "ax1.set_title('Reservations made total')\n", "ax2.set_title('Mean time between\\n reservation and visit')\n", "ax3.set_title('Mean number of\\n visitors per reservation')\n", "sns.barplot(x='index', y='air_genre_name', data=df_genre,\n", "            ax=ax1, color='r')\n", "sns.barplot(x='res_vs_visit_hours', y='air_genre_name', data=df_genre, \n", "            ax=ax2, color='g')\n", "sns.barplot(x='reserve_visitors', y='air_genre_name', data=df_genre, \n", "            ax=ax3, color='b')\n"], "execution_count": 27}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Japanese styles (Izakaya + Japanese Food) again most popular\n", "- Unlike the \"HPG\" data there is no significant time difference between the reservation and visit however there is a larger average number of visitors per reservation\n", "- There also seems to be a similar pattern with Asian however this could be an anomaly due to limited data points"]}, {"metadata": {}, "cell_type": "markdown", "source": ["What if we looked at this based on whether the visit occured on a holiday?"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# plot holiday vs non holiday\n", "df_genre_by_holiday = df_res_merged.groupby(['hpg_genre_name', 'holiday_flag_visit']) \\\n", "                                   .agg({'index':'size', 'reserve_visitors':'mean', 'res_vs_visit_hours':'mean'}) \n", "\n", "test = pd.DataFrame(df_genre_by_holiday.groupby(level=0)['index'].apply(lambda x:100 * x / float(x.sum())))\n", "test.rename(columns={\"index\": \"index_pct\"}, inplace=True)\n", "\n", "df_genre_by_holiday = df_genre_by_holiday.merge(test, left_index=True, right_index=True).reset_index()\n", "            \n", "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(13, 15))\n", "ax1.set_title('Reservations made\\n for holiday vs non')\n", "ax2.set_title('Mean time between\\n reservation and visit')\n", "ax3.set_title('Mean number of\\n visitors per reservation')\n", "sns.barplot(x='index_pct', y='hpg_genre_name', data=df_genre_by_holiday,\n", "            ax=ax1, hue='holiday_flag_visit', hue_order=[0,1], color='r')\n", "sns.barplot(x='res_vs_visit_hours', y='hpg_genre_name', data=df_genre_by_holiday, \n", "            ax=ax2, hue='holiday_flag_visit', hue_order=[0,1], color='g')\n", "sns.barplot(x='reserve_visitors', y='hpg_genre_name', data=df_genre_by_holiday, \n", "            ax=ax3, hue='holiday_flag_visit', hue_order=[0,1], color='b')\n"], "execution_count": 28}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# plot holiday vs non holiday\n", "df_genre_by_holiday = df_res_merged.groupby(['air_genre_name', 'holiday_flag_visit']) \\\n", "                                   .agg({'index':'size', 'reserve_visitors':'mean', 'res_vs_visit_hours':'mean'}) \n", "\n", "test = pd.DataFrame(df_genre_by_holiday.groupby(level=0)['index'].apply(lambda x:100 * x / float(x.sum())))\n", "test.rename(columns={\"index\": \"index_pct\"}, inplace=True)\n", "\n", "df_genre_by_holiday = df_genre_by_holiday.merge(test, left_index=True, right_index=True).reset_index()\n", "            \n", "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(13, 10))\n", "ax1.set_title('Reservations made\\n for holiday vs non')\n", "ax2.set_title('Mean time between\\n reservation and visit')\n", "ax3.set_title('Mean number of\\n visitors per reservation')\n", "sns.barplot(x='index_pct', y='air_genre_name', data=df_genre_by_holiday, \n", "            ax=ax1, hue='holiday_flag_visit', hue_order=[0,1], color='r')\n", "sns.barplot(x='res_vs_visit_hours', y='air_genre_name', data=df_genre_by_holiday, \n", "            ax=ax2, hue='holiday_flag_visit', hue_order=[0,1], color='g')\n", "sns.barplot(x='reserve_visitors', y='air_genre_name', data=df_genre_by_holiday, \n", "            ax=ax3, hue='holiday_flag_visit', hue_order=[0,1], color='b')\n"], "execution_count": 29}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Using the percentage of reservations on holidays vs non holidays it appears there are some types of restaurants that are more popular than others, at least with the \"HPG\" data. Is there a pattern eg/ are those that a more \"fun\" or \"out of the ordinary\" more popular? Not enough data to really answer that.\n", "- For some genres the time between reservation and visit as well as the number of visitors appears to have some fluctuation. Is it statistically significant? Not sure there is enough data to make a conclusion."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Let's try and amalgamate some of the genres so we have a common list between the two data sets (\"Air\" and \"HPG\")"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# too many genres - amalgamate\n", "genres = {\n", "    'Japanese style':'Japanese',\n", "    'International cuisine':'Other',\n", "    'Grilled meat':'Other Asian',\n", "    'Creation':'Japanese',\n", "    'Italian':'European',\n", "    'Seafood':'Other',\n", "    'Spain Bar/Italian Bar':'European',\n", "    'Japanese food in general':'Japanese',\n", "    'Shabu-shabu/Sukiyaki':'Japanese',\n", "    'Chinese general':'Other Asian',\n", "    'Creative Japanese food':'Japanese',\n", "    'Japanese cuisine/Kaiseki':'Japanese',\n", "    'Korean cuisine':'Other Asian',\n", "    'Okonomiyaki/Monja/Teppanyaki':'Japanese',\n", "    'Karaoke':'Bar or Club',\n", "    'Steak/Hamburger/Curry':'Other',\n", "    'French':'European',\n", "    'Cafe':'European',\n", "    'Bistro':'Other',\n", "    'Sushi':'Japanese',\n", "    'Party':'Bar or Club',\n", "    'Western food':'Other',\n", "    'Pasta/Pizza':'Other',\n", "    'Thai/Vietnamese food':'Other Asian',\n", "    'Bar/Cocktail':'Bar or Club',\n", "    'Amusement bar':'Bar or Club',\n", "    'Cantonese food':'Other Asian',\n", "    'Dim Sum/Dumplings':'Other Asian',\n", "    'Sichuan food':'Other Asian',\n", "    'Sweets':'Other',\n", "    'Spain/Mediterranean cuisine':'European',\n", "    'Udon/Soba':'Japanese',\n", "    'Shanghai food':'Other Asian',\n", "    'Taiwanese/Hong Kong cuisine':'Other Asian',\n", "    'Japanese food':'Japanese', \n", "    'Dining bar':'Bar or Club', \n", "    'Izakaya':'Japanese',\n", "    'Okonomiyaki/Monja/Teppanyaki':'Japanese', \n", "    'Italian/French':'European', \n", "    'Cafe/Sweets':'Other',\n", "    'Yakiniku/Korean food':'Other Asian', \n", "    'Western food':'Other', \n", "    'Bar/Cocktail':'Bar or Club', \n", "    'Other':'Other',\n", "    'Creative cuisine':'Japanese', \n", "    'Karaoke/Party':'Bar or Club', \n", "    'International cuisine':'Other',\n", "    'Asian':'Other Asian',\n", "    'None':'None',\n", "    'No Data':'No Data'}\n", "df_res_merged.hpg_genre_name.fillna('No Data', inplace=True)\n", "df_res_merged.air_genre_name.fillna('No Data', inplace=True)\n", "df_res_merged.hpg_store_id.fillna('No Data', inplace=True)\n", "df_res_merged.air_store_id.fillna('No Data', inplace=True)\n", "df_res_merged['air_genre_2'] = df_res_merged['air_genre_name'].map(genres)\n", "df_res_merged['hpg_genre_2'] = df_res_merged['hpg_genre_name'].map(genres)\n", "\n", "# take hpg genre first then air\n", "df_res_merged['genre_2']=df_res_merged['hpg_genre_2']\n", "df_res_merged.loc[df_res_merged['hpg_genre_2']=='No Data',['genre_2']] = df_res_merged['air_genre_2']"], "execution_count": 30}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# plot holiday vs non holiday\n", "df_genre_by_holiday = df_res_merged.groupby(['genre_2', 'holiday_flag_visit']) \\\n", "                                   .agg({'index':'size', 'reserve_visitors':'mean', 'res_vs_visit_hours':'mean'}) \n", "\n", "test = pd.DataFrame(df_genre_by_holiday.groupby(level=0)['index'].apply(lambda x:100 * x / float(x.sum())))\n", "test.rename(columns={\"index\": \"index_pct\"}, inplace=True)\n", "\n", "df_genre_by_holiday = df_genre_by_holiday.merge(test, left_index=True, right_index=True).reset_index()\n", "            \n", "f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(13, 8))\n", "ax1.set_title('Reservations made\\n for holiday vs non')\n", "ax2.set_title('Mean time between\\n reservation and visit')\n", "ax3.set_title('Mean number of\\n visitors per reservation')\n", "sns.barplot(x='index_pct', y='genre_2', data=df_genre_by_holiday, \n", "            ax=ax1, hue='holiday_flag_visit', hue_order=[0,1], color='r')\n", "sns.barplot(x='res_vs_visit_hours', y='genre_2', data=df_genre_by_holiday, \n", "            ax=ax2, hue='holiday_flag_visit', hue_order=[0,1], color='g')\n", "sns.barplot(x='reserve_visitors', y='genre_2', data=df_genre_by_holiday, \n", "            ax=ax3, hue='holiday_flag_visit', hue_order=[0,1], color='b')"], "execution_count": 31}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Reservation visits per season\n", "df_visit_by_season = df_res_merged.groupby(['genre_2','visit_season','visit_month']) \\\n", "                             .agg({'index':'size'}) \\\n", "                             .reset_index() \n", "df_visit_by_season['total_size'] = df_visit_by_season.groupby('genre_2')['index'].transform('sum')\n", "df_visit_by_season.sort_values(by='total_size', inplace=True)\n", "df_visit_by_season['visit_pct'] = (df_visit_by_season['index'] / df_visit_by_season['total_size'])*100\n", "        \n", "pal=['blue','blue','green','green','green', 'red','red','red', 'orange','orange','orange', 'blue']\n", "g = sns.FacetGrid(df_visit_by_season, col=\"genre_2\", col_wrap=3, size=5)\n", "g.map(sns.barplot, \"visit_month\", \"visit_pct\", palette=pal, order=['Jan','Feb','Mar','Apr','May','Jun',\n", "           'Jul','Aug','Sep','Oct','Nov','Dec'])"], "execution_count": 32}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Reservation visits per season\n", "df_res_visitors_by_season = df_res_merged.groupby(['visit_month']) \\\n", "                             .agg({'reserve_visitors':'mean'}) \\\n", "                             .reset_index() \n", "pal=['blue','blue','green','green','green', 'red','red','red', 'orange','orange','orange', 'blue']\n", "sns.barplot(\"visit_month\", \"reserve_visitors\", data=df_res_visitors_by_season, palette=pal, \n", "            order=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])"], "execution_count": 33}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- When grouping the genres together there doesn't appear to be any differing patterns that stand out. \n", "- It appears that reservations are more common in winter and spring rather than the summer\n", "- Reservations drop off as spring progresses and increase as autumn turns to winter.\n", "- Number of visitors per reservation don't really change much over the seasons"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Let's take a look at the data based on the day of the week."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# reservations and visits by day of week\n", "dow = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']\n", "\n", "df_res_by_dow = df_res_merged.groupby(['day_of_week_res']) \\\n", "                             .agg({'index':'size'}) \\\n", "                             .reset_index() \n", "df_res_by_dow['day_of_week_res'] = pd.Categorical(df_res_by_dow['day_of_week_res'],categories=dow, ordered=True)\n", "df_res_by_dow.sort_values(by='day_of_week_res', inplace=True) \n", "df_res_by_dow.set_index('day_of_week_res', inplace=True)\n", "df_res_by_dow.rename(columns={\"index\": \"reservation_count\"}, inplace=True)\n", "df_res_by_dow.index.names = ['day_of_week']\n", "\n", "df_visit_by_dow = df_res_merged.groupby(['day_of_week_visit']) \\\n", "                             .agg({'index':'size'}) \\\n", "                             .reset_index() \n", "\n", "df_visit_by_dow['day_of_week_visit'] = pd.Categorical(df_visit_by_dow['day_of_week_visit'],categories=dow, ordered=True)\n", "\n", "df_visit_by_dow.sort_values(by='day_of_week_visit', inplace=True)\n", "df_visit_by_dow.set_index('day_of_week_visit', inplace=True)\n", "df_visit_by_dow.rename(columns={\"index\": \"visit_count\"}, inplace=True)\n", "df_visit_by_dow.index.names = ['day_of_week']\n", "\n", "df_by_dow = df_res_by_dow.merge(df_visit_by_dow, left_index=True, right_index=True).reset_index()\n", "df_by_dow = df_by_dow.melt(id_vars=['day_of_week'], value_vars=['reservation_count', 'visit_count'])\n", "\n", "sns.factorplot(x='day_of_week', y='value', data=df_by_dow, hue='variable', aspect=3)"], "execution_count": 34}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Friday and saturday are the most common days for which to make a reservation which is to be expected.\n", "- People appear to reserve during the weekdays and taper off over the weekend."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now let's look at the time between a reservation and the actual visit"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["      \n", "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True,figsize=(16, 10))\n", "visit_vs_res = df_res_merged.groupby(['res_vs_visit_hours', 'source'])\\\n", "             .agg({'index':'size'}) \\\n", "             .reset_index()\n", "visit_vs_res = visit_vs_res[visit_vs_res.res_vs_visit_hours<150]    \n", "\n", "ax1.bar(x='res_vs_visit_hours', height='index', data=visit_vs_res[visit_vs_res.source == 'air'], color='b')\n", "ax1.set_title('Air')\n", "ax1.set_ylabel('Visits')\n", "ax1.grid(b=None, axis='x')\n", "\n", "ax2.bar(x='res_vs_visit_hours', height='index', data=visit_vs_res[visit_vs_res.source == 'hpg'], color='g')\n", "ax2.set_title('HPG')\n", "ax2.set_ylabel('Visits')\n", "ax2.set_xlabel('Hours')\n", "ax2.set_xlim(0)\n", "ax2.grid(b=None, axis='x')\n", "\n", "ax2.xaxis.set_major_locator(ticker.MultipleLocator(base=24))"], "execution_count": 35}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- There is a 24 hour cyclical pattern for the reservations\n", "- Comparatively, \"Air\" reservations appear to be last minute (<24 hours) whereas \"HPG\" reservations are made more in advance."]}, {"metadata": {}, "cell_type": "markdown", "source": ["How about looking at the number reserved visits by time of day?"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_res_by_time = df_res_merged.groupby(['reserve_time']) \\\n", "                             .agg({'index':'size'}) \\\n", "                             .reset_index() \n", "df_res_by_time.sort_values(by='reserve_time', inplace=True) \n", "df_res_by_time.set_index('reserve_time', inplace=True)\n", "df_res_by_time.rename(columns={\"index\": \"reservation_count\"}, inplace=True)\n", "df_res_by_time.index.names = ['time']\n", "\n", "df_visit_by_time = df_res_merged.groupby(['visit_time']) \\\n", "                             .agg({'index':'size'}) \\\n", "                             .reset_index() \n", "df_visit_by_time.sort_values(by='visit_time', inplace=True)\n", "df_visit_by_time.set_index('visit_time', inplace=True)\n", "df_visit_by_time.rename(columns={\"index\": \"visit_count\"}, inplace=True)\n", "df_visit_by_time.index.names = ['time']\n", "\n", "df_by_time = df_res_by_time.merge(df_visit_by_time, left_index=True, right_index=True).reset_index()\n", "df_by_time = df_by_time.melt(id_vars=['time'], value_vars=['reservation_count', 'visit_count'])\n", "\n", "sns.factorplot(x='time', y='value', data=df_by_time, hue='variable', aspect=3).set_xticklabels(rotation=30)"], "execution_count": 36}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["f, (ax1, ax2) = plt.subplots(2, 1, sharex=True,figsize=(16, 10))\n", "plt.xticks(rotation=30)\n", "visit_time = df_res_merged.groupby(['visit_time', 'source'])\\\n", "             .agg({'index':'size'}) \\\n", "             .reset_index() \n", "visit_time['visit_time'] = visit_time.visit_time.apply(lambda x: str(x))\n", "        \n", "ax1.bar(x='visit_time', height='index', data=visit_time[visit_time.source == 'air'], color='b')\n", "ax1.set_title('Air')\n", "ax1.set_ylabel('Visits')\n", "ax1.grid(b=None, axis='x')\n", "\n", "ax2.bar(x='visit_time', height='index', data=visit_time[visit_time.source == 'hpg'], color='g')\n", "ax2.set_title('HPG')\n", "ax2.set_ylabel('Visits')\n", "ax2.set_xlabel('Hour of the day')\n", "ax2.set_xlim(0)\n", "ax2.grid(b=None, axis='x')"], "execution_count": 37}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Dinner time (5pm to 8pm) is the most common period for which to make a reservation which is to be expected.\n", "- Reservations are made pretty consistently throughout the waking hours with a little peak around lunch time and slightly higher towards the evening.\n", "- Pretty consistent pattern across both \"Air\" and \"HPG\" datasets."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now let's take a view over the entire time period of reservations"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Reservations by visit date and source\n", "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True,figsize=(16, 10))\n", "visits_per = df_res_merged.groupby(['calendar_date', 'source'])\\\n", "             .agg({'index':'size'}) \\\n", "             .reset_index() \n", "\n", "ax1.plot_date(x='calendar_date', y='index', data=visits_per[visits_per.source == 'air'], ms=3, c='b', ls='solid', lw=1)\n", "ax1.set_title('Air visits')\n", "ax1.set_ylabel('Visits')\n", "ax1.grid(b=None, axis='x')\n", "\n", "ax2.plot_date(x='calendar_date', y='index', data=visits_per[visits_per.source == 'hpg'], ms=3, c='g', ls='solid', lw=1)\n", "ax2.set_title('HPG visits')\n", "ax2.set_ylabel('Visits')\n", "ax2.grid(b=None, axis='x')\n", "\n", "ax2.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n", "ax2.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n"], "execution_count": 38}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Pretty consistent weekly peak-trough pattern for both \"Air\" and \"HPG\" datasets.\n", "- Both datsets have a spike around the new year period.\n", "- Big hole in the \"Air\" data from Aug 2016 to Nov 2016. No immediately identifiable reason for this.\n", "- After this hole there is a significant increase in data points compared to before. Not sure what the trigger is.\n", "- For the \"HPG\" dataset the weekly peaks significantly increases in the new year of 2017. Was there a marketing campaign that caused this?\n", "- The downturn in both datasets in May 2017 would probably be due to the fact that these datapoints would overlap with the testing dataset."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Here are the top restaurants according to time between reservation and visit. Could this mean these are hardest at which to get a table? There are 2 (or maybe 3) that clearly stand out at the top of the list."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["visit_vs_res_top = df_res_merged.groupby(['air_store_id', 'hpg_store_id','air_genre_name', 'hpg_genre_name'])\\\n", "                                .agg({'res_vs_visit_hours':'mean', 'index':'size', 'reserve_visitors':'mean'}) \\\n", "                                .reset_index() \\\n", "                                .sort_values(by='res_vs_visit_hours', ascending=False)\n", "visit_vs_res_top['res_vs_visit_hours'] = visit_vs_res_top.res_vs_visit_hours / 24\n", "visit_vs_res_top.rename(columns={'res_vs_visit_hours':'res_vs_visit_days','index':'No. of reservations'}, inplace=True)\n", "visit_vs_res_top = visit_vs_res_top[visit_vs_res_top['No. of reservations']>100]\n", "visit_vs_res_top.head(10)"], "execution_count": 39}, {"metadata": {}, "cell_type": "markdown", "source": ["### Air Visits Data"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now we'll pivot to analysing the actual visitor numbers. First we need to wrangle the data much like we did with the reservations"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# format df_date_info and add month, year, and season\n", "\n", "df_air_visit['visit_date'] = pd.to_datetime(df_air_visit.visit_date)\n", "df_air_visit['visit_date'] = df_air_visit.visit_date.dt.date\n", "df_air_visit = df_air_visit.merge(df_date_info, left_on='visit_date', right_on='reserve_date', how='left')\n", "df_air_visit.drop('reserve_date', axis=1, inplace=True)\n", "df_air_visit = df_air_visit.merge(df_air_store,on='air_store_id', how='left')\n", "df_air_visit['visit_month'] = df_air_visit.visit_date.apply(lambda x: x.strftime(\"%b\"))\n", "df_air_visit['visit_year'] = df_air_visit.visit_date.apply(lambda x: x.strftime(\"%Y\"))\n", "df_air_visit['visit_season'] = df_air_visit['visit_month'].map(seasons)"], "execution_count": 40}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# amalgamate genres like in hpg\n", "df_air_visit.air_genre_name.fillna('No Data', inplace=True)\n", "df_air_visit['air_genre_2'] = df_air_visit['air_genre_name'].map(genres)"], "execution_count": 41}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# holiday the day before and after visit\n", "df_air_visit['holiday_before_visit'] = df_air_visit.holiday_flg.shift(1)\n", "df_air_visit.holiday_before_visit.fillna(0,inplace=True)\n", "df_air_visit['holiday_after_visit'] = df_air_visit.holiday_flg.shift(-1)\n", "df_air_visit.holiday_after_visit.fillna(0,inplace=True)"], "execution_count": 42}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_visit.describe()"], "execution_count": 43}, {"metadata": {}, "cell_type": "markdown", "source": ["First let's analyse the visitors according to the day of the week and the impact that holidays have."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# visitors by day of week and holiday\n", "df_visitors_by_dow = df_air_visit.groupby(['day_of_week','holiday_flg']) \\\n", "                             .agg({'visitors':'mean'}) \\\n", "                             .reset_index() \n", "\n", "df_visitors_by_dow['day_of_week'] = pd.Categorical(df_visitors_by_dow['day_of_week'],categories=dow, ordered=True)\n", "df_visitors_by_dow.sort_values(by='day_of_week', inplace=True)\n", "sns.factorplot(x='day_of_week', y='visitors', data=df_visitors_by_dow, hue='holiday_flg', aspect=3)"], "execution_count": 44}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# visits by day of week and holiday after visit\n", "df_visitors_by_dow = df_air_visit.groupby(['day_of_week','holiday_after_visit']) \\\n", "                             .agg({'visitors':'mean'}) \\\n", "                             .reset_index() \n", "\n", "df_visitors_by_dow['day_of_week'] = pd.Categorical(df_visitors_by_dow['day_of_week'],categories=dow, ordered=True)\n", "df_visitors_by_dow.sort_values(by='day_of_week', inplace=True)\n", "sns.factorplot(x='day_of_week', y='visitors', data=df_visitors_by_dow, hue='holiday_after_visit', aspect=3)"], "execution_count": 45}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- If a holiday falls on a weekday then it significantly increases the number of visitors\n", "- For days Sunday through thursday, if that day precedes a holiday it also positively influences the number of visitors."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Visitors from reservations vs Total visitors\n", "air_res_store = df_res_merged.groupby(['air_store_id', 'calendar_date'])\\\n", "                             .agg({'reserve_visitors':'sum'}) \\\n", "                             .reset_index() \\\n", "                             .rename(columns={'calendar_date':'visit_date'})\n", "air_res_store['visit_date'] = air_res_store.visit_date.apply(lambda x: str(x))\n", "df_air_visit['visit_date'] = df_air_visit.visit_date.apply(lambda x: str(x))\n", "air_res_store['air_store_id'] = air_res_store.air_store_id.apply(lambda x: str(x))\n", "df_air_visit['air_store_id'] = df_air_visit.air_store_id.apply(lambda x: str(x))\n", "air_res = pd.merge(df_air_visit, air_res_store,  how='left', \n", "                         left_on=['air_store_id','visit_date'], right_on = ['air_store_id','visit_date'])\n", "air_res.reserve_visitors.fillna(0.0, inplace=True)\n", "air_res_date = air_res.groupby('visit_date')\\\n", "                 .agg({'reserve_visitors':'sum', 'visitors':'sum'}) \\\n", "                 .reset_index()\n", "air_res_date['visit_date'] = air_res_date.visit_date.apply(lambda x: pd.to_datetime(x).date())\n", "f, ax1 = plt.subplots(figsize=(16, 10))\n", "ax1.plot_date(x='visit_date', y=air_res_date.loc[:,['reserve_visitors', 'visitors']], data=air_res_date, ms=3, ls='solid', lw=1)\n", "ax1.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n", "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n", "ax1.grid(b=None, axis='x')\n", "ax1.set_ylabel('Visitors')\n", "ax1.legend(['Visitors from reservations', 'Total visitors'])"], "execution_count": 46}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- There is a big jump in total visitors from Jul 2016. What causes this?\n", "- As noted during the analysis of the reservation data there is a significant jump in reservations in November 2016 however this does not appear to have an impact on the number of total visitors.\n", "- Both datasets have a signficant climb and precipitous dropoff around the new year period.\n", "- Reservations through these services only provide ~25% of the clientele."]}, {"metadata": {}, "cell_type": "markdown", "source": ["As there is a big change in visitor numbers starting around July 2016 let's plot the distribution of total visitors before and after this date."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Plot total daily visitors distribution before and after jump in visitors(Jul 1st 2016)\n", "\n", "date_jump = pd.to_datetime('2016-07-01').date()\n", "\n", "df_total_vis = df_air_visit.groupby(['visit_date'])\\\n", "                           .agg({'visitors':'sum'}) \\\n", "                           .reset_index() \n", "df_total_vis['before_20160701'] = df_total_vis.visit_date.apply(lambda x: pd.to_datetime(x).date()<date_jump)\n", "\n", "sns.kdeplot(df_total_vis[df_total_vis['before_20160701'] == True].visitors, color= \"b\", lw= 3, label= \"Before 2016-07-01\")\n", "sns.kdeplot(df_total_vis[df_total_vis['before_20160701'] == False].visitors, color= \"g\", lw= 3, label= \"On/After 2016-07-01\")"], "execution_count": 47}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- There is a much wider distribution of values after July 2016"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Like we did with the reservations data let's take a look at the total number of visitors per season"]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Reservation visits per season\n", "df_air_visit_by_season = df_air_visit.groupby(['visit_month']) \\\n", "                             .agg({'visitors':'sum'}) \\\n", "                             .reset_index() \n", "df_air_visit_by_season['total_size'] = df_air_visit_by_season.visitors.sum()\n", "df_air_visit_by_season.sort_values(by='total_size', inplace=True)\n", "df_air_visit_by_season['visit_pct'] = (df_air_visit_by_season['visitors'] / df_air_visit_by_season['total_size'])*100\n", "pal=['blue','blue','green','green','green', 'red','red','red', 'orange','orange','orange', 'blue']\n", "sns.barplot(\"visit_month\", \"visit_pct\", data=df_air_visit_by_season, palette=pal, \n", "            order=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])"], "execution_count": 48}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Compared to the reservations there is a slightly different distribution of visitors. Are people more likely to reserve a table in the winter/spring months rather than just showing up at the restaurant?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Let's look at the total visitors for each type of restaurant. These are colour grouped by the amalgamated genres defined earlier."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Visitors per genre\n", "df_air_visit['visit_date']= df_air_visit.visit_date.apply(lambda x: pd.to_datetime(x).date())\n", "df_visitors_by_genre = df_air_visit.groupby(['air_genre_2','air_genre_name','visit_date']) \\\n", "                             .agg({'visitors':'sum'}) \\\n", "                             .reset_index() \n", "g = sns.FacetGrid(df_visitors_by_genre, col=\"air_genre_name\", col_wrap=4,\n", "                  hue='air_genre_2',aspect=1.5,palette='Set1')\n", "for q in g.axes:\n", "    q.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n", "    q.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n", "g.map(plt.plot, \"visit_date\", \"visitors\")\n", "g.set(yscale='log')\n", "g.add_legend()\n", "plt.subplots_adjust(top=0.9)\n", "g.fig.suptitle('Daily visitors per genre')"], "execution_count": 49}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["df_air_visit['visit_date']= df_air_visit.visit_date.apply(lambda x: pd.to_datetime(x).date())\n", "df_visitors_by_genre = df_air_visit.groupby(['air_genre_2','air_genre_name','day_of_week']) \\\n", "                             .agg({'visitors':'mean'}) \\\n", "                             .reset_index() \n", "\n", "g = sns.FacetGrid(df_visitors_by_genre, col=\"air_genre_name\", col_wrap=4, sharey=False,\n", "                  hue='air_genre_2',aspect=1.5,palette='Set1')\n", "g.map(sns.barplot, \"day_of_week\", \"visitors\",order=dow)\n", "g.add_legend()\n", "plt.subplots_adjust(top=0.9)\n", "g.fig.suptitle('Mean visitors per day by genre')"], "execution_count": 50}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Some genres dont appear until later in the data set ie/ International cuisine, Karaoke/Party, and Asian. Karaoke/Party and International cuisine coincide with the data volume jump observed in July 2016. Asian appears slightly before that.\n", "- Okonomiyaki (and to a lesser extent Yakiniku) shows a trend upwards compared to others\n", "- Demand for some genres remain pretty consistent throughout the weekly cycle. Demand for Karaoke/Party venues fluctuates wildly over the time period.\n", "- Karaoke/Party is pretty dead during the week (and even Friday) but very popular on the weekend, especially Sunday.\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Here's a view of the total visitor counts vs the number of reservations that were made through the two services."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Visitors from reservations vs Total visitors by season\n", "g=sns.lmplot('reserve_visitors', 'visitors', air_res[(air_res.reserve_visitors>0)&(air_res.reserve_visitors<250)],\n", "          hue='visit_season',legend_out=False,scatter_kws={'alpha':0.5})\n", "g.set(xlim=(0,200), ylim=(0,250))\n", "g.fig.set_figwidth(16)\n", "g.fig.set_figheight(7)"], "execution_count": 51}, {"metadata": {}, "cell_type": "markdown", "source": ["**Analysis**\n", "\n", "- Not really much of a pattern between reservations and actual visitors\n", "- In summer the number of reservations is less of a predictor compared to other seasons\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["**Geo plotting of restaurants**\n", "\n", "Let's plot thes restaurants on a map just to get an idea of where they are in Japan. As logic would tell us there is a high concentration around the Tokyo area."]}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["f, (ax1,ax2) = plt.subplots(1,2,figsize=(12,7))\n", "\n", "store_counts_air=pd.DataFrame(df_air_store.air_area_name.value_counts()).reset_index()\n", "store_counts_air.rename(columns={'air_area_name':'store_count','index':'air_area_name'},inplace=True)\n", "store_counts_hpg=pd.DataFrame(df_hpg_store.hpg_area_name.value_counts()).reset_index()\n", "store_counts_hpg.rename(columns={'hpg_area_name':'store_count','index':'hpg_area_name'},inplace=True)\n", "\n", "sns.barplot(y='air_area_name',x='store_count',data=store_counts_air.head(25),color='b', ax=ax1)\n", "sns.barplot(y='hpg_area_name',x='store_count',data=store_counts_hpg.head(25),color='g', ax=ax2)\n", "\n", "ax1.set_title('Air')\n", "ax2.set_title('HPG')\n", "plt.tight_layout()"], "execution_count": 52}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# Plot individual restaurants on map based on lat and long\n", "\n", "# Group and count stores as map function can't handle plotting individual stores\n", "df_hpg_store_merged = df_hpg_store.merge(df_store_id_rel,on='hpg_store_id', how='left').merge(\n", "                                         df_air_store,on='air_store_id', how='left',suffixes=('_hpg','_air'))\n", "\n", "df_air_store_merged = df_air_store.merge(df_store_id_rel,on='air_store_id', how='left').merge(\n", "                                         df_hpg_store,on='hpg_store_id', how='left',suffixes=('_air','_hpg'))\n", "\n", "df_hpg_store_merged = df_hpg_store_merged[~df_hpg_store_merged.hpg_store_id.isin(df_air_store_merged.hpg_store_id)]\n", "\n", "df_hpg_store_merged = df_hpg_store_merged.groupby(['hpg_area_name','latitude_hpg','longitude_hpg','hpg_genre_name'])\\\n", "                                         .agg({'hpg_store_id':'size'}) \\\n", "                                         .reset_index() \n", "        \n", "df_air_store_merged = df_air_store_merged.groupby(['air_area_name','latitude_air','longitude_air','air_genre_name'])\\\n", "                                         .agg({'air_store_id':'size'}) \\\n", "                                         .reset_index() \n", "\n", "maxlat = df_air_store_merged.latitude_air.mean()\n", "maxlong = df_air_store_merged.longitude_air.mean()\n", "        \n", "# Use folium to map\n", "m = folium.Map(\n", "    location=[maxlat, maxlong],\n", "    tiles='CartoDB positron',\n", "    zoom_start=5\n", ")\n", "\n", "marker_cluster = MarkerCluster(\n", "    name='Restaurants',\n", ").add_to(m)\n", "\n", "\n", "for point in df_air_store_merged.iterrows():\n", "    lat=point[1]['latitude_air']\n", "    lon=point[1]['longitude_air']\n", "    store=point[1]['air_store_id']\n", "    genre=point[1]['air_genre_name']\n", "    desc=point[1]['air_area_name']\n", "    folium.Marker((lat,lon), popup='lon:{}<br>lat:{}<br>stores:{}<br>area:{}<br>genre:{}'.format(lon, lat, store, desc,genre),  \n", "                  icon=folium.Icon(color='darkblue', icon_color='white', \n", "                                   icon='male', angle=0, prefix='fa')).add_to(marker_cluster)\n", "\n", "for point in df_hpg_store_merged.iterrows():\n", "    lat=point[1]['latitude_hpg']\n", "    lon=point[1]['longitude_hpg']\n", "    genre=point[1]['hpg_genre_name']\n", "    desc=point[1]['hpg_area_name']\n", "    store=point[1]['hpg_store_id']\n", "    folium.Marker((lat,lon), popup='lon:{}<br>lat:{}<br>stores:{}<br>area:{}<br>genre:{}'.format(lon, lat, store, desc,genre),  \n", "                  icon=folium.Icon(color='red', icon_color='white', \n", "                                   icon='male', angle=0, prefix='fa')).add_to(marker_cluster)    \n", "    \n", "folium.LayerControl().add_to(m)\n", "    \n", "m"], "execution_count": 53}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["# plot restaurants as a heatmap\n", "\n", "heat = df_air_store_merged[['latitude_air','longitude_air']].apply(pd.to_numeric)\n", "heat=heat.values.tolist()\n", "m = folium.Map(\n", "    location=[maxlat, maxlong],\n", "    tiles='CartoDB positron',\n", "    zoom_start=5\n", ")\n", "m.add_child(HeatMap(heat, radius=15, min_opacity=.5))\n", "m"], "execution_count": 54}, {"metadata": {}, "cell_type": "markdown", "source": ["**Potential to use this data to plot by more general areas eg/ prefecture**\n", "\n", "geo = Nominatim(timeout=5)\n", "d = df_air_store_merged.groupby(['latitude_air','longitude_air'])\\\n", "                   .agg({'air_store_id':'sum'}) \\\n", "                   .sort_values(by='air_store_id')\\\n", "                   .reset_index() \n", "            \n", "d['place'] = d.latitude_air.map(str)+','+d.longitude_air.map(str)\n", "\n", "d['place'] = d.place.apply(lambda x: geo.reverse(x, language='en').raw.get('address'))\n", "d['city'] = d.place.apply(lambda x: x.get('city'))\n", "d['state'] = d.place.apply(lambda x: x.get('state'))\n", "\n", "df_air_store_merged = df_air_store_merged.merge(d.drop(labels=['latitude_air','air_store_id'], axis=1), on='longitude_air', how='left')"]}, {"metadata": {"collapsed": true}, "cell_type": "markdown", "source": ["d = df_hpg_store_merged.groupby(['latitude_hpg','longitude_hpg'])\\\n", "                   .agg({'hpg_store_id':'sum'}) \\\n", "                   .sort_values(by='hpg_store_id')\\\n", "                   .reset_index() \n", "            \n", "d['place'] = d.latitude_hpg.map(str)+','+d.longitude_hpg.map(str)\n", "\n", "d['place'] = d.place.apply(lambda x: geo.reverse(x, language='en').raw.get('address'))\n", "d['city'] = d.place.apply(lambda x: x.get('city'))\n", "d['state'] = d.place.apply(lambda x: x.get('state'))\n", "\n", "df_hpg_store_merged = df_hpg_store_merged.merge(d.drop(labels=['latitude_hpg','hpg_store_id'], axis=1), on='longitude_hpg', how='left')"]}, {"metadata": {}, "cell_type": "markdown", "source": ["**To be continued (with predictions)...**"]}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "execution_count": null}]}