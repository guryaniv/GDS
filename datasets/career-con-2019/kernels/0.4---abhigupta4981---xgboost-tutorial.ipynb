{"cells":[{"metadata":{"_uuid":"7aa350e1021033e23202f6a8c2a2fbccdfee00b2"},"cell_type":"markdown","source":"# Imports\nWe are using pathlib library for navigating file system"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a76b791cab4d0caa9a9cad06fdca3eeee73b7aeb"},"cell_type":"code","source":"from pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"PATH = Path('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5195320cd862a0230371ffe815317f2aa2e4d58c"},"cell_type":"code","source":"X_train = pd.read_csv(PATH/'X_train.csv')\nX_test = pd.read_csv(PATH/'X_test.csv')\ny_train = pd.read_csv(PATH/'y_train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"734095503ed383474651880ef164f15957c8d8a1"},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"800927ee91c9d1e285d71d01b42de1926eb233f9"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0627c131b36036776077aa20528f14fb6a39bfa5"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"141edcfd3e7d0c1ecf1237e68066379295a5169f"},"cell_type":"markdown","source":"# This feature engineering is mostly taken from other kaggle kernels"},{"metadata":{"trusted":true,"_uuid":"bec09e7a2db3355613ef919273279850fbe57282"},"cell_type":"code","source":"import math\ndef quarternion_to_euler(x, y, z, w):\n    t0 = +2.0 * (w*x + y*z)\n    t1 = +1.0 - 2.0*(x*x + y*y)\n    X = math.atan2(t0, t1)\n    \n    t2 = +2.0 * (w*y - z*x)\n    t2 = +1.0 if t2>+1.0 else t2\n    t2 = -1.0 if t2<-1.0 else t2\n    Y = math.asin(t2)\n    \n    t3 = +2.0 * (w*z + x*y)\n    t4 = +1.0 - 2.0 * (y*y + z*z)\n    Z = math.atan2(t3, t4)\n    return X, Y, Z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"293860fc43127a7af3be30917c578140a17b56ba"},"cell_type":"code","source":"def feature_engineering(df):\n    new_df = pd.DataFrame()\n    df['total_angular_velocity'] = (df['angular_velocity_X']**2 + df['angular_velocity_Y']**2 + df['angular_velocity_Z']**2)**0.5\n    df['total_linear_acceleration'] = (df['linear_acceleration_X']**2 + df['linear_acceleration_Y']**2 + df['linear_acceleration_Z']**2)**0.5\n    df['acc_vs_velocity'] = df['total_linear_acceleration']/df['total_angular_velocity']\n    x, y, z, w = df['orientation_X'].tolist(), df['orientation_Y'].tolist(), df['orientation_Z'].tolist(), df['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quarternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    df['euler_x'] = nx\n    df['euler_y'] = ny\n    df['euler_z'] = nz\n    \n    df['total_angle'] = (df['euler_x']**2 + df['euler_y']**2 + df['euler_z']**2)**0.5\n    df['angle_vs_acc'] = df['total_angle']/df['total_linear_acceleration']\n    df['angle_vs_vel'] = df['total_angle']/df['total_angular_velocity']\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n    def mean_abs_change(x):\n        return np.mean(np.abs(np.diff(x)))\n    \n    for col in df.columns:\n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        new_df[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n        new_df[col + '_min'] = df.groupby(['series_id'])[col].min()\n        new_df[col + '_max'] = df.groupby(['series_id'])[col].max()\n        new_df[col + '_std'] = df.groupby(['series_id'])[col].std()\n        new_df[col + '_max_to_min'] = new_df[col + '_max']/new_df[col + '_min']\n        new_df[col + '_mean_abs_change'] = df.groupby(['series_id'])[col].apply(mean_abs_change)\n        new_df[col + 'mean_change_of_abs_change'] = df.groupby(['series_id'])[col].apply(mean_change_of_abs_change)\n        new_df[col + '_abs_max'] = df.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n        new_df[col + '_abs_min'] = df.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n        return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2cfb6a30418a4cbc547c62028f2650feb8ecf0c"},"cell_type":"code","source":"X_train_new = feature_engineering(X_train)\nX_test_new = feature_engineering(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28246317c1454c16d53d412153a3678cad6f3359"},"cell_type":"code","source":"X_train_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea3727bb364dc236950db53ad854c7ad461b2876"},"cell_type":"code","source":"X_train_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b341c034b24f277164afdf5629b0b91e0546e988"},"cell_type":"code","source":"X_test_new.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c885ea5e1b97ba67eecdbd478be1c5661553be7"},"cell_type":"markdown","source":"## As the y_train['surface'] is categorical, we will use sklearn's LabelEncoder() function to conver these into numbers that can be passed into xgboost"},{"metadata":{"trusted":true,"_uuid":"bcde6f89f5118498db6c6cb448e3e22110d69129"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2230179acc4cbb53266a92ce88866581a334cc88"},"cell_type":"code","source":"le = LabelEncoder()\ny_train['surface'] = le.fit_transform(y_train['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5c7465e2570b33e3fd837f503b4f683752f566b0"},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81cbfa82d3083b41dfd75c92ff090c48b67419b3"},"cell_type":"code","source":"X_train_new.fillna(0, inplace=True)\nX_train_new.replace(-np.inf, 0, inplace=True)\nX_train_new.replace(np.inf, 0, inplace=True)\nX_test_new.fillna(0, inplace=True)\nX_test_new.replace(-np.inf, 0, inplace=True)\nX_test_new.replace(np.inf, 0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c56e11291a6338db8974617b3bf0f2bcbe60d2a"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27cb1f5714a5bb8bbe523d0721065cad4a55049e"},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85555b4aae3671024b50f39be6b68eeae2b62a23"},"cell_type":"markdown","source":"# The XGBClassifier has following parameters:\n\nn_estimators: Number of trees which we should use\nmax_depth: maximum depth the tree should go to\nlearning_rate: learning rate to be used\nobjective: The objective to use xgboost. Here we have multiclass classification. So we should use *multi:softmax*\n\n## For training, we will use the fit function and prediction, we will use predict_proba() function to get the probabilities of the class"},{"metadata":{"trusted":true,"_uuid":"b9a8519eea8511f8a6ad6c72b62cf11f62da524c"},"cell_type":"code","source":"from xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"11eb90444b24b3b48d20efd2c43920e20c99b8fe"},"cell_type":"code","source":"sub_preds = np.zeros((X_test_new.shape[0], 9))\noof_preds = np.zeros((X_train_new.shape[0]))\nscore = 0\nfor fold, (train_idx, valid_idx) in enumerate(folds.split(X_train_new, y_train['surface'])):\n    eval_set = [(X_train_new.iloc[valid_idx], y_train['surface'][valid_idx])]\n    xgb = XGBClassifier(n_estimators=400, max_depth=5, learning_rate=0.1, objective='multi:softmax',\n                        gamma=0.001, n_jobs=-1)\n    xgb.fit(X_train_new.iloc[train_idx], y_train['surface'][train_idx], eval_set=eval_set,\n            early_stopping_rounds=200, verbose=True)\n    oof_preds[valid_idx] = xgb.predict(X_train_new.iloc[valid_idx])\n    sub_preds+=xgb.predict_proba(X_test_new)/folds.n_splits\n    score+=xgb.score(X_train_new.iloc[valid_idx], y_train['surface'][valid_idx])\n    print(f'Fold: {fold} score: {xgb.score(X_train_new.iloc[valid_idx], y_train[\"surface\"][valid_idx])}')\n    print('Avg Accuracy', score/folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88273c9f683a1a956ad3e14ff1da890b22c29ffa"},"cell_type":"markdown","source":"# Submission\n\nWe will take the class which will have the maximum probability among the 9 classes.\nFor this, we will use the argmax() function of the numpy library."},{"metadata":{"trusted":true,"_uuid":"6fda79889364fd0abd8b0025ede9a5a99361d480"},"cell_type":"code","source":"submission = pd.read_csv(PATH/'sample_submission.csv')\nsubmission['surface'] = le.inverse_transform(sub_preds.argmax(axis=1))\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}