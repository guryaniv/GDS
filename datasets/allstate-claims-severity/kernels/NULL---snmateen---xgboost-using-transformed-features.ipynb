{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5410242d-a705-d45d-9879-011890dd6bb8"
      },
      "source": [
        "Simple XGBoost using transformed features based on [notebook][1]\n",
        "------------------------------------------------\n",
        "\n",
        "No additional features are added, none are dropped.\n",
        "\n",
        " - continuous features are transformed\n",
        " - categorical features are factorized\n",
        " - hyper parameters are tuned using GridSearchCV\n",
        "\n",
        "  [1]: https://www.kaggle.com/snmateen/allstate-claims-severity/simple-eda-feature-transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0bd8fc6-962c-bf6d-72c2-fabe364c503e"
      },
      "outputs": [],
      "source": [
        "# import relevant modules for a start\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import math\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c1e67a5-85cb-a8af-082d-834412a0cc00"
      },
      "outputs": [],
      "source": [
        "# disable warnings!\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d3b035f2-627e-40a6-f104-96b8b7f7856e"
      },
      "outputs": [],
      "source": [
        "# load training dataset\n",
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06bd7aa3-6251-a76d-216c-86985dba8bab"
      },
      "outputs": [],
      "source": [
        "y = np.log(train['loss'])\n",
        "train.drop('loss', axis = 1, inplace= True)\n",
        "train['dftype'] = 'train'\n",
        "test['dftype'] = 'test'\n",
        "full = train.append(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a179c4b0-e9bf-7402-53a0-32595b7819ef"
      },
      "source": [
        "Feature Tranformation:\n",
        "----------------------\n",
        "\n",
        "Based on the EDA on the continous features, let's transform the features, refer eda notebook for more details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f572092-c1f0-1113-3c91-e62eb1499763"
      },
      "outputs": [],
      "source": [
        "feature_transformation = {  'cont1': 'boxcox'\n",
        "                          , 'cont2': 'np.tan'\n",
        "                          , 'cont3': 'none'\n",
        "                          , 'cont4': 'boxcox'\n",
        "                          , 'cont5': 'boxcox'\n",
        "                          , 'cont6': 'boxcox'\n",
        "                          , 'cont7': 'boxcox'\n",
        "                          , 'cont8': 'boxcox'\n",
        "                          , 'cont9': 'boxcox'\n",
        "                          , 'cont10': 'boxcox'\n",
        "                          , 'cont11': 'boxcox'\n",
        "                          , 'cont12': 'boxcox'\n",
        "                          , 'cont13': 'abs_mean_shift'\n",
        "                          , 'cont14': 'abs_mean_shift'\n",
        "                         }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e36c05dc-64f2-1ac5-6c12-78daec1a6e86"
      },
      "outputs": [],
      "source": [
        "# function - absolute of mean shifted data (which will be later used in function transformer)\n",
        "def abs_mean_shift(data):\n",
        "    return np.abs(data - np.mean(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94d397ef-c63e-a7ab-fd76-45781111f1b4"
      },
      "outputs": [],
      "source": [
        "# import modules specific to preprocessing\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "904c585c-e2c5-98b5-4830-2a57a71a20b5"
      },
      "source": [
        "feature transformation based on the best suited transformation picked in the EDA phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1010951a-63cc-9bc7-156d-bf719e3573df"
      },
      "outputs": [],
      "source": [
        "# loop thru the dictionary (created above) and transform the features.\n",
        "transformed_continous_features = []\n",
        "for k, v in feature_transformation.items():\n",
        "    print('processing feature: {0}, with transformation: {1}'.format(k,v))\n",
        "    transformed_feature = 't_' + k\n",
        "    transformed_continous_features.append(transformed_feature)\n",
        "    if v == 'boxcox':\n",
        "        xt, _ = stats.boxcox(full[k]+1)\n",
        "    elif v == 'none':\n",
        "        xt = full[k]\n",
        "    else:\n",
        "        xt = FunctionTransformer(eval(v)).transform(full[k]).reshape(full.shape[0],1)\n",
        "    full[transformed_feature] = xt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "30c3621c-38a0-6181-6f02-3acdc40d408b"
      },
      "source": [
        "factorizing the categorical variables\n",
        "-------------------------------------\n",
        "\n",
        "There are 116 categorical variables which needs to be factorized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2dcc1eb5-fac7-9f0c-3b76-fd34039fd747"
      },
      "outputs": [],
      "source": [
        "factored_categorical_features = []\n",
        "print(\"Factorizing feature: \")\n",
        "for column_name in full.select_dtypes(include = ['object']).columns:\n",
        "    print(column_name)\n",
        "    factored_feature = 'f_' + column_name\n",
        "    factored_categorical_features.append(factored_feature)\n",
        "    full[factored_feature] = pd.factorize(full[column_name], sort = True)[0].reshape(full.shape[0],1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "37da61bd-9940-a669-80a4-ff3fed48e1ac"
      },
      "outputs": [],
      "source": [
        "final_features = transformed_continous_features\n",
        "final_features.extend(factored_categorical_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f0d508ff-1298-efdd-fcd1-90569f755558"
      },
      "source": [
        "Loading the preprocessing and training algorithm module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0b58b600-c890-f88d-4be4-eb6541df707f"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing \n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59792c67-cef7-1815-d2df-bc6689328fdf"
      },
      "source": [
        "Train and Test 75 / 25 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18503149-85dc-a78f-cc64-b1d0dcd820af"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_full = pd.DataFrame(preprocessing.StandardScaler().fit_transform(full[final_features])\n",
        "                      , columns = final_features\n",
        "                      , index = full.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc967769-9a58-045a-8171-cf8066a77c8c"
      },
      "outputs": [],
      "source": [
        "X_train = X_full[full.dftype == 'train']\n",
        "X_test = X_full[full.dftype == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc303a96-3deb-df66-d3c6-5221b9ac6feb"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# custom evalution function which takes into account of log / exp transformation\n",
        "def meaerror(preds, dtrain):\n",
        "    labels = dtrain.get_label()\n",
        "    return 'error', metrics.mean_absolute_error(np.exp(preds),np.exp(labels))\n",
        "\n",
        "# creating train and test Data Matrix for the xgboost training\n",
        "dtrain = xgb.DMatrix(data = X_train, label = y)\n",
        "dtest = xgb.DMatrix(data = X_test)\n",
        "watchlist = [(dtrain, 'train')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e179d339-1bc1-c587-b46f-8e2d5b37b76c"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# These are the parameters picked in the grid search hyper parameter tuning / optimization\n",
        "params = {\"eta\" : \"0.01\" \n",
        "          , \"silent\": \"1\" \n",
        "          , \"booster\": \"gbtree\"\n",
        "          , \"max_depth\" : \"10\" \n",
        "          , \"min_child_weight\" : \"9\" \n",
        "          , \"subsample\" : \"1\" \n",
        "          , \"colsample_bytree\" : \"0.2\"}\n",
        "\n",
        "best = xgb.train(params\n",
        "              , dtrain\n",
        "              , 4500\n",
        "              , watchlist\n",
        "              , early_stopping_rounds = 25\n",
        "              , feval=meaerror\n",
        "              , verbose_eval=False\n",
        "             )\n",
        "print(best.attributes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fd9ce4be-2c4f-ee4e-cfdf-efdc01471b5b"
      },
      "source": [
        "Plotting feature importance\n",
        "---------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "880512e0-0660-c3ab-c816-387a62f00627"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,30))\n",
        "xgb.plot_importance(best, ax = plt.subplot(111))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c6242a9-eb20-0022-b85d-333c84bd85df"
      },
      "outputs": [],
      "source": [
        "dtest = xgb.DMatrix(data = X_test)\n",
        "prediction = np.exp(best.predict(dtest))\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['loss'] = prediction\n",
        "submission['id'] = test.id\n",
        "submission.to_csv('xgboost_tuned_hp.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}