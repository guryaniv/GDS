{"cells":[{"metadata":{"_uuid":"ac118124c576aed49bf92da49d10747d89e63c97"},"cell_type":"markdown","source":"ANN ( Artificial Neural Networks ) are great for many of the problems , they can make a clear relation between  variables , after all it's just matrix multiplication\ni.e Linear Algebra and they are easy to implement using Frameworks like Keras.\nKeras is a great framework when it comes to implementing Neural networks . \nIts just a wrapper around tensorflow . "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#importing libraries\n\nimport pandas as pd\nimport numpy as np","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# Reading and cleaning dataset\n\ndataset = pd.read_csv('../input/creditcard.csv')\ndataset.dropna()\ndataset.head()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94c6a83198cbe1b0c159883f91b845a33eba8b96","collapsed":true},"cell_type":"code","source":"#Getting the no of columns\n\ndataset.columns","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c377c81c49964e9244265b1f4d53d31e14ec74c","collapsed":true},"cell_type":"code","source":"# Getting the X_data\n\nX_data = dataset.iloc[:,0:-1].values\nX_data[0:2]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d85b8157f0bfbf9f22094a366e6453400f80c7","collapsed":true},"cell_type":"code","source":"#Getting the Y_data\n\nY_data = dataset.iloc[:,-1].values\nY_data[0:5]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bfdf1257af40b32f413865ec3b81b0a85f8d525","collapsed":true},"cell_type":"code","source":"# Getting no of instances of each unique class\n\nunique , counts = np.unique(Y_data,return_counts = True)\nprint(unique,counts)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b390f59413990d8c7b1c678f1cc03a48a6876ab9"},"cell_type":"code","source":"# here 0 means not spam and 1 represents spam","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"77d696f878fd4ab58fe7956c7766f3520e6b3d41"},"cell_type":"code","source":"# importing StandardScaler used for scaling\n\nfrom sklearn.preprocessing import StandardScaler\nsclaer = StandardScaler()","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbd515a1895913103b384ffba1faf54201a30033","collapsed":true},"cell_type":"code","source":"# Scaling X_data\n\nX_data = sclaer.fit_transform(X_data)\nX_data[0:2]","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75f4cf32067359b94a9e44900e28c742ba9dd2b0","collapsed":true},"cell_type":"code","source":"# Splitting the data into training and testing  \n\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X_data,Y_data,test_size=0.3)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c0b967b5cc468c5928534b4238bc3f18ec87ad4","collapsed":true},"cell_type":"code","source":"# Libraries that we will need to create ANN\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7006e91db19979fba003548691786078525f1810","collapsed":true},"cell_type":"code","source":"# building our Neural Network\n\nclassifier = Sequential()\nclassifier.add(Dense(40 , input_dim = 30 , activation = 'relu'))\nclassifier.add(Dense(30 , input_dim = 40 , activation = 'relu'))\nclassifier.add(Dense(20 , input_dim = 30 , activation = 'relu'))\nclassifier.add(Dense(10 , input_dim = 20 , activation = 'relu'))\nclassifier.add(Dense(6 , input_dim = 10 , activation = 'relu'))\nclassifier.add(Dense(4 , input_dim = 6 , activation = 'relu'))\nclassifier.add(Dense(1, input_dim = 4 , activation = 'sigmoid'))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c873d2235a75a046e2d35e68f1f88f5873d6d29","collapsed":true},"cell_type":"code","source":"# Specifying our loss and optimizer\n\nclassifier.compile(loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a2642fceec517d1d359c061379d36be128d3b04","collapsed":true},"cell_type":"code","source":"# Fitting our data to ANN\n\nclassifier.fit( x_train , y_train , epochs = 200 , batch_size = 500 )","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b014c0fadfbf339480425095d85d9dfd3469892","collapsed":true},"cell_type":"code","source":"# Getting the results\n\nclassifier.evaluate(x_test,y_test)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"49b799580764c88fe3a92fdde45c4e017c110250"},"cell_type":"markdown","source":"**We got a test score of 99.9% using Artificial Neural Network ** "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}