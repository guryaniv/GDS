{"cells":[{"metadata":{"_cell_guid":"5fa957b4-6df7-4a1d-b2c4-569fa966b989","_uuid":"f46617cbc64e85b77174adfdf6ae53bb8ade93a9","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Import function to create training and test set splits\nfrom sklearn.model_selection  import train_test_split\n\n# Import function to automatically create polynomial features! \nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Import Linear Regression and a regularized regression function\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LassoCV\n\n# Finally, import function to make a machine learning pipeline\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"367fb547-8f87-4293-8caf-0a7043f6c88b","_uuid":"d816201f93cd68d12ee80403fd904e6950a7e03b","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')\ndf_unkwn = pd.read_csv('../input/test.csv')\ndf_unknn_passID = df_unkwn[\"PassengerId\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def df_preproccess1(df):\n    df['Title']= df['Name'].apply(lambda x : x.split(',')[1].split('.')[0])\n    \n    def profile(df):\n        title = df[0]\n        sex = df[1]\n        if title in [' Dr',' Rev',' Major',' Col',' Sir',' Don', ' Jonkheer', ' Capt']:\n            profile = ' MrU'\n        elif title in [' Mlle', ' Ms']:\n            profile = ' Miss'\n        elif title in [' Lady',' Mme', ' the Countess']:\n            profile = ' MrsU'\n        elif title in [' Master',' Mrs',' Miss',' Mr']:\n            profile = title\n        else:\n            if sex == 'male':\n                profile = ' Mr'\n            else:\n                profile = ' Mrs'\n            \n        return profile\n    \n    df['profile']= df[['Title','Sex']].apply(profile,axis=1)\n    df['Count'] = df['SibSp']+ df['Parch']\n    df['Cabin_new'] = df['Cabin'].fillna('XXX').apply(lambda x: x.split()[0][0])\n    df['Embarked'].fillna(value = df['Embarked'].mode()[0],inplace=True)\n    df['Fare'].fillna(value = df['Fare'].mean(),inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ef512b7-358f-4397-be85-2e4dd9b22f9c","_uuid":"8ed2641ac1a3b24d16493a420ca28f4b3cc5f92e","trusted":true},"cell_type":"code","source":"def age_model(df):\n    #preparing the dataset for age prediction\n    age_pred= df[df['Age'].notnull()][['Pclass','Fare','profile','Age']]\n    age_profile = pd.get_dummies(age_pred['profile'],drop_first=True)\n    age_Pclass = pd.get_dummies(age_pred['Pclass'],drop_first=True)\n    age_pred.drop(['profile','Pclass'],axis=1,inplace=True)\n    age_pred = pd.concat([age_pred,age_profile,age_Pclass],axis=1)\n    \n    #Segregating target and predictor variables\n    age_pred_X = age_pred.drop(labels='Age',axis=1)\n    age_pred_Y = age_pred['Age']\n    \n    # Alpha (regularization strength) of LASSO regression\n    lasso_eps = 0.0001\n    lasso_nalpha=1000\n    lasso_iter=10000\n\n    # Min and max degree of polynomials features to consider\n    degree_min = 2\n    degree_max = 3\n\n    # Test/train split\n    X_train, X_test, y_train, y_test = train_test_split(age_pred_X, age_pred_Y,test_size=.3)\n    # Make a pipeline model with polynomial transformation and LASSO regression with cross-validation, run it for increasing degree of polynomial (complexity of the model)\n\n    for degree in range(degree_min,degree_max+1):\n        age_pred_model = make_pipeline(PolynomialFeatures(degree, interaction_only=False), LassoCV(eps=lasso_eps,n_alphas=lasso_nalpha,max_iter=lasso_iter,normalize=True,cv=5))\n        age_pred_model.fit(X_train,y_train)\n        #test_pred = np.array(model.predict(X_test))\n        #RMSE=np.sqrt(np.sum(np.square(test_pred-y_test)))\n        #test_score = model.score(X_test,y_test)\n    return age_pred_model,age_pred","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5f0d1f8-c55c-40f2-9c5c-ff4199ffb25a","_uuid":"11dfada5e673344ab6c0d3d3d3fb60e6e66b6841","trusted":true},"cell_type":"code","source":"def age_predict(df,age_pred):\n    \n    #Creating the new dataframe with missing age values by selecting required variables for age prediction\n    age_test = df[df['Age'].isnull()][['Pclass','Fare','profile']]\n    age_profile_df = pd.get_dummies(age_test['profile'],drop_first=True)\n    age_Pclass_df = pd.get_dummies(age_test['Pclass'],drop_first=True)\n    age_test.drop(['profile','Pclass'],axis=1,inplace=True)\n    age_test = pd.concat([age_test,age_profile_df,age_Pclass_df],axis=1)\n    age_pred,age_test = age_pred.align(age_test, join='outer', axis=1, fill_value=0)\n    return age_test","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23b72cc1-17f9-4cb7-b350-23eff30b6e12","_uuid":"c7a5c200fa919f9b6f423e8c7631de3b0b1a809a","trusted":true},"cell_type":"code","source":"def age_merge(df,age_test,age_pred_model):\n    age_fill = age_pred_model.predict(age_test.drop('Age',axis=1))\n    Age= pd.DataFrame(age_fill, index=df[df['Age'].isnull()].index,columns=['Age'])\n    df = df.merge(Age, how='left',left_index=True, right_index=True)\n    df.fillna(value={'Age_x':0,'Age_y':0},inplace=True)\n    df['Age'] = df['Age_x'] + df['Age_y'].astype('int64')\n    df.drop(labels=['Age_x','Age_y'],inplace=True,axis=1)\n    return df   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22095e2ac0ee338f5cfef1f44ddeeaaae8393a6f","trusted":true},"cell_type":"code","source":"df = df_preproccess1(df)\nage_pred_model,age_pred = age_model(df)\nage_test = age_predict(df,age_pred)\ndf = age_merge(df,age_test,age_pred_model)\ndf.drop(labels=['Name','PassengerId','Ticket','Cabin','Title'],inplace=True,axis=1)\ndf_sex = pd.get_dummies(df['Sex'],drop_first=True)\ndf_embarked = pd.get_dummies(df['Embarked'],drop_first=True)\ndf_profile = pd.get_dummies(df['profile'],drop_first=True)\ndf_pclass = pd.get_dummies(df['Pclass'],drop_first=True)\n\n#df_cabin_new = pd.get_dummies(df['Cabin_new'],drop_first=True)\ndf.drop(['Sex','Embarked','profile','Count','Cabin_new','Pclass'],axis=1,inplace=True)\n#df = pd.concat([df,df_sex,df_embarked,df_profile,df_cabin_new],axis=1)\ndf = pd.concat([df,df_sex,df_embarked,df_profile,df_pclass],axis=1)\nX_train = df.drop('Survived',axis=1)\ny_train = df['Survived']\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\n\n\nlog_model = LogisticRegression()\nlog_model.fit(X_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d157b9db13207fce7e3ef9af7144532f490b845","trusted":true},"cell_type":"code","source":"df_unkwn = df_preproccess1(df_unkwn)\nage_unkwn = age_predict(df_unkwn,age_pred)\ndf_unkwn = age_merge(df_unkwn,age_unkwn,age_pred_model)\ndf_unkwn.drop(labels=['Name','PassengerId','Ticket','Cabin','Title'],inplace=True,axis=1)\ndf_unkwn_sex = pd.get_dummies(df_unkwn['Sex'],drop_first=True)\ndf_unkwn_embarked = pd.get_dummies(df_unkwn['Embarked'],drop_first=True)\ndf_unkwn_pclass = pd.get_dummies(df_unkwn['Pclass'],drop_first=True)\ndf_unkwn_profile = pd.get_dummies(df_unkwn['profile'],drop_first=True)\n#df_cabin_new = pd.get_dummies(df_unkwn['Cabin_new'],drop_first=True)\ndf_unkwn.drop(['Sex','Embarked','profile','Cabin_new','Count','Pclass'],axis=1,inplace=True)\ndf_unkwn = pd.concat([df_unkwn,df_unkwn_sex,df_unkwn_embarked,df_unkwn_profile,df_unkwn_pclass],axis=1)\n#df_unkwn = scaler.transform(df_unkwn)\ndf2,df_unkwn = df.drop('Survived',axis=1).align(df_unkwn, join='outer', axis=1, fill_value=0)\nscaler2 = StandardScaler()\nscaler2.fit(df_unkwn)\ndf_unkwn = scaler2.transform(df_unkwn)\n#predictions = log_model.predict(df_unkwn)\nfrom sklearn.neural_network import MLPClassifier\nmlp_model = MLPClassifier(hidden_layer_sizes=(30,30,30))\nmlp_model.fit(X_train,y_train)\npredictions = mlp_model.predict(df_unkwn)\n#from sklearn.model_selection import GridSearchCV\n#from sklearn.svm import SVC\n#svc_model = SVC()\n#param_grid = {'C':[0.01,0.1,0.5,1,5,10,100],'gamma':[2,1,.5,0.1,.05,0.01,0.001]}\n#grid = GridSearchCV(SVC(),param_grid=param_grid,verbose=2)\n#grid.fit(X_train,y_train)\n#predictions = grid.predict(df_unkwn)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"220ab0fb3a3f92682907315366a8513271f97d1b","trusted":true},"cell_type":"code","source":"predictions.size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c387076874081c675f228232f6b54b537e40938b","trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": df_unknn_passID,\n        \"Survived\": predictions\n    })\nsubmission.to_csv('titanic2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ee9bd123c8c44197f66eb6d3081a2425b817fe5","trusted":true},"cell_type":"code","source":"submission.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f550e87add950ecdf43fa46db5e3e51fb9560ca0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}