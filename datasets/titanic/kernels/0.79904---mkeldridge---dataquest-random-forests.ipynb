{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9fd99917-c709-9604-bcde-10dd2177bdb7"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4635593b-cfc3-4880-02d7-07c1bcd0c713"
      },
      "outputs": [],
      "source": [
        "titanic = pd.read_csv(\"../input/train.csv\")\n",
        "print(titanic.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e4a66d80-7ec7-0e3e-47da-c809258a4b5b"
      },
      "source": [
        "Clean the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a664df4-b57a-4bbd-c8da-b8a80d84be9d"
      },
      "outputs": [],
      "source": [
        "titanic[\"Age\"].fillna(value=titanic[\"Age\"].median(), inplace=True)\n",
        "\n",
        "titanic.loc[titanic[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "titanic.loc[titanic[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "\n",
        "titanic[\"Embarked\"].fillna(value=\"S\", inplace=True)\n",
        "titanic.loc[titanic[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "titanic.loc[titanic[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "titanic.loc[titanic[\"Embarked\"] == \"Q\", \"Embarked\"] = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a3e0083-4a7e-8385-d10b-ae91df625396"
      },
      "outputs": [],
      "source": [
        "from sklearn import cross_validation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "\n",
        "# Initialize our algorithm with the default paramters\n",
        "# n_estimators is the number of trees we want to make\n",
        "# min_samples_split is the minimum number of rows we need to make a split\n",
        "# min_samples_leaf is the minimum number of samples we can have at the place where a tree branch ends (the bottom points of the tree)\n",
        "alg = RandomForestClassifier(random_state=1, n_estimators=10, min_samples_split=2, min_samples_leaf=1)\n",
        "\n",
        "from sklearn.cross_validation import KFold\n",
        "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "298ddf6e-e657-0971-3913-b9f84650f14c"
      },
      "outputs": [],
      "source": [
        "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=4, min_samples_leaf=2)\n",
        "\n",
        "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c1861bb-6e9a-f4d3-52e3-54ec501f4d91"
      },
      "outputs": [],
      "source": [
        "# Generating a familysize column\n",
        "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
        "\n",
        "# The .apply method generates a new series\n",
        "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c75da35-8890-68ab-3b91-61dc53e05bf8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# A function to get the title from a name.\n",
        "def get_title(name):\n",
        "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
        "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
        "    # If the title exists, extract and return it.\n",
        "    if title_search:\n",
        "        return title_search.group(1)\n",
        "    return \"\"\n",
        "\n",
        "# Get all the titles and print how often each one occurs.\n",
        "titles = titanic[\"Name\"].apply(get_title)\n",
        "print(pd.value_counts(titles))\n",
        "\n",
        "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
        "for k,v in title_mapping.items():\n",
        "    titles[titles == k] = v\n",
        "\n",
        "# Verify that we converted everything.\n",
        "print(pd.value_counts(titles))\n",
        "\n",
        "# Add in the title column.\n",
        "titanic[\"Title\"] = titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4dd21cd-51fc-ea4a-36c9-b51b20b73f8f"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "\n",
        "# A dictionary mapping family name to id\n",
        "family_id_mapping = {}\n",
        "\n",
        "# A function to get the id given a row\n",
        "def get_family_id(row):\n",
        "    # Find the last name by splitting on a comma\n",
        "    last_name = row[\"Name\"].split(\",\")[0]\n",
        "    # Create the family id\n",
        "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
        "    # Look up the id in the mapping\n",
        "    if family_id not in family_id_mapping:\n",
        "        if len(family_id_mapping) == 0:\n",
        "            current_id = 1\n",
        "        else:\n",
        "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
        "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
        "        family_id_mapping[family_id] = current_id\n",
        "    return family_id_mapping[family_id]\n",
        "\n",
        "# Get the family ids with the apply method\n",
        "family_ids = titanic.apply(get_family_id, axis=1)\n",
        "\n",
        "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
        "family_ids[titanic[\"FamilySize\"] < 3] = -1\n",
        "\n",
        "# Print the count of each unique id.\n",
        "print(pd.value_counts(family_ids))\n",
        "\n",
        "titanic[\"FamilyId\"] = family_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02fd1895-8049-0d1a-aa21-5b1bef1f664e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\", \"NameLength\"]\n",
        "\n",
        "# Perform feature selection\n",
        "selector = SelectKBest(f_classif, k=5)\n",
        "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "\n",
        "# Get the raw p-values for each feature, and transform from p-values into scores\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "\n",
        "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
        "plt.bar(range(len(predictors)), scores)\n",
        "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "# Pick only the four best features.\n",
        "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
        "\n",
        "alg = RandomForestClassifier(random_state=1, n_estimators=50, min_samples_split=8, min_samples_leaf=4)\n",
        "\n",
        "from sklearn.cross_validation import KFold\n",
        "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=kf)\n",
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a004b308-2f92-2936-ac1a-2b26dbd7bf94"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# The algorithms we want to ensemble.\n",
        "# We're using the more linear predictors for the logistic regression, and everything with the gradient boosting classifier.\n",
        "algorithms = [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]],\n",
        "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
        "]\n",
        "\n",
        "# Initialize the cross validation folds\n",
        "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
        "\n",
        "predictions = []\n",
        "for train, test in kf:\n",
        "    train_target = titanic[\"Survived\"].iloc[train]\n",
        "    full_test_predictions = []\n",
        "    # Make predictions for each algorithm on each fold\n",
        "    for alg, predictors in algorithms:\n",
        "        # Fit the algorithm on the training data.\n",
        "        alg.fit(titanic[predictors].iloc[train,:], train_target)\n",
        "        # Select and predict on the test fold.  \n",
        "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
        "        test_predictions = alg.predict_proba(titanic[predictors].iloc[test,:].astype(float))[:,1]\n",
        "        full_test_predictions.append(test_predictions)\n",
        "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
        "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
        "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
        "    test_predictions[test_predictions <= .5] = 0\n",
        "    test_predictions[test_predictions > .5] = 1\n",
        "    predictions.append(test_predictions)\n",
        "\n",
        "# Put all the predictions together into one array.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# Compute accuracy by comparing to the training data.\n",
        "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e795e089-60da-0f06-a4df-27da42088d38"
      },
      "outputs": [],
      "source": [
        "titanic_test = pd.read_csv(\"../input/test.csv\")\n",
        "\n",
        "titanic_test[\"Age\"].fillna(value=titanic_test[\"Age\"].median(), inplace=True)\n",
        "\n",
        "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
        "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
        "\n",
        "titanic_test[\"Embarked\"].fillna(value=\"S\", inplace=True)\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
        "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
        "\n",
        "# First, we'll add titles to the test set.\n",
        "titles = titanic_test[\"Name\"].apply(get_title)\n",
        "# We're adding the Dona title to the mapping, because it's in the test set, but not the training set\n",
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
        "for k,v in title_mapping.items():\n",
        "    titles[titles == k] = v\n",
        "titanic_test[\"Title\"] = titles\n",
        "# Check the counts of each unique title.\n",
        "print(pd.value_counts(titanic_test[\"Title\"]))\n",
        "\n",
        "# Now, we add the family size column.\n",
        "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
        "\n",
        "# Now we can add family ids.\n",
        "# We'll use the same ids that we did earlier.\n",
        "print(family_id_mapping)\n",
        "\n",
        "family_ids = titanic_test.apply(get_family_id, axis=1)\n",
        "family_ids[titanic_test[\"FamilySize\"] < 3] = -1\n",
        "titanic_test[\"FamilyId\"] = family_ids\n",
        "\n",
        "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed498b98-12af-41f1-6073-92ae75278853"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def print_full(x):\n",
        "    pd.set_option('display.max_rows', len(x))\n",
        "    print(x)\n",
        "    pd.reset_option('display.max_rows')\n",
        "\n",
        "titanic_test[\"Fare\"].fillna(value=titanic_test[\"Fare\"].median(), inplace=True)\n",
        "\n",
        "predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\", \"FamilyId\"]\n",
        "#print(titanic_test[predictors].ix[0])\n",
        "#print_full(titanic_test[predictors].astype(float))\n",
        "print_full(titanic_test[\"Fare\"].astype(float))\n",
        "\n",
        "for index_val, series_val in titanic_test[\"Fare\"].astype(float).iteritems():\n",
        "    if (not np.isfinite(series_val)):\n",
        "        print(series_val)\n",
        "\n",
        "algorithms = [\n",
        "    [GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors],\n",
        "    [LogisticRegression(random_state=1), [\"Pclass\", \"Sex\", \"Fare\", \"FamilySize\", \"Title\", \"Age\", \"Embarked\"]]\n",
        "]\n",
        "\n",
        "full_predictions = []\n",
        "for alg, predictors in algorithms:\n",
        "    # Fit the algorithm using the full training data.\n",
        "    alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
        "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
        "    predictions = alg.predict_proba(titanic_test[predictors].astype(float))[:,1]\n",
        "    full_predictions.append(predictions)\n",
        "\n",
        "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
        "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
        "\n",
        "predictions[predictions > .5] = 1\n",
        "predictions[predictions <=.5] = 0\n",
        "\n",
        "predictions = predictions.astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
        "        \"Survived\": predictions\n",
        "    })\n",
        "\n",
        "submission.to_csv(\"kaggle2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f03fa03-85bb-3040-4c05-23473401c481"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}