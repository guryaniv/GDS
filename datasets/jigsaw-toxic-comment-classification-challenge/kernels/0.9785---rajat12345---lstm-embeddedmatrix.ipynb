{"cells":[{"metadata":{"trusted":true,"_uuid":"27b2ffa217e98e2d0dfc2ca8030470adb54059f9","collapsed":true},"cell_type":"code","source":"\"\"\"\n@author : Rajat Shukla\nThis is is a script which classify the comments,\ndata cab be downloaded fron URL https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\nThe objective of the task is to classify the comments. \nHere comment's type can be toxic severe_toxic obscene threat insult identity_hate\n\"\"\"\nfrom __future__ import print_function\nimport os\nimport numpy as np\nimport pandas as pd\nfrom scipy import interp\nfrom itertools import cycle\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Input, LSTM, Bidirectional, Conv1D\nfrom keras.layers import Dropout, Embedding\nfrom keras.preprocessing import text, sequence\nfrom keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model\nfrom keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\nfrom keras.models import Sequential\nfrom keras import regularizers\nfrom keras.callbacks import Callback\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn import datasets\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n\n#Set here Global variables\nmax_features=100000\nmaxlen=150\nembed_size=300\nembedding_dimension = 300\nglove_data = '../input/glove840b300dtxt/glove.840B.300d.txt'\nbatch_size = 32\nepochs = 1\nnum_filters = 256\nweight_decay = 1e-4\nnum_classes = 6\n\n\nclass roc_callback(Callback):\n    \"\"\"\n    This is class which implements ROC callback for Keras.\n    Reference URL: \n    http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n    https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n    https://hackernoon.com/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier-2ecc6c73115a\n    \"\"\"\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n        #####################################\n        self.train_x = training_data[0]\n        self.train_y = training_data[1]\n        self.test_x = validation_data[0]\n        self.test_y = validation_data[1]\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n    \n    def generate_auc_curve(self, ):\n        #train_y_pred = self.model.predict(self.train_x)\n        test_y_pred = self.model.predict(self.test_x)\n        print(test_y_pred)\n        # Plot linewidth\n        lw = 2\n        # Compute ROC curve and ROC area for each class\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n        n_classes = 6\n        y_score = test_y_pred\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(self.test_y[:, i], y_score[:, i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n        # Compute micro-average ROC curve and ROC area\n        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(self.test_y.ravel(), y_score.ravel())\n        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n        # Compute macro-average ROC curve and ROC area\n        # First aggregate all false positive rates\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(n_classes):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n        # Finally average it and compute AUC\n        mean_tpr /= n_classes\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n        # Plot all ROC curves\n        plt.figure(1)\n        plt.plot(fpr[\"micro\"], tpr[\"micro\"],label='micro-average ROC curve (area = {0:0.2f})'''.format(roc_auc[\"micro\"]),color='deeppink', linestyle=':', linewidth=4)\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],label='macro-average ROC curve (area = {0:0.2f})'''.format(roc_auc[\"macro\"]),color='navy', linestyle=':', linewidth=4)\n        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n        for i, color in zip(range(n_classes), colors):\n            plt.plot(fpr[i], tpr[i], color=color, lw=lw,label='ROC curve of class {0} (area = {1:0.2f})'\n''.format(i, roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Some extension of Receiver operating characteristic to multi-class')\n        plt.legend(loc=\"lower right\")\n        print(\"Save figure\")\n        pp = PdfPages('multipage1.pdf')\n        plt.savefig(pp, format='pdf')\n        plt.show()\n\n\n        # Zoom in view of the upper left corner.\n        plt.figure(2)\n        plt.xlim(0, 0.2)\n        plt.ylim(0.8, 1)\n        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n                 label='micro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"micro\"]),\n                 color='deeppink', linestyle=':', linewidth=4)\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]),\n                 color='navy', linestyle=':', linewidth=4)\n\n        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n        for i, color in zip(range(n_classes), colors):\n            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                     label='ROC curve of class {0} (area = {1:0.2f})'\n                     ''.format(i, roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Some extension of Receiver operating characteristic to multi-class')\n        plt.legend(loc=\"lower right\")\n        print(\"Save figure\")\n        pp = PdfPages('multipage2.pdf')\n        plt.savefig(pp, format='pdf')\n        plt.show()\n\n    \n    \n    \n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = roc_auc_score(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        ############################## New code for curve ###################\n        self.generate_auc_curve()\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n\n\n\nclass CommentPrediction():\n    \"\"\"\n    This class predict the type of comment based on comment.\n    This class does following task.\n    1. Read the train.csv and test.csv by pandas\n    2. Fill NA for the comment which doesn't have any comment\n    3. Analyse the data\n    4. Creates token, convert text to sequence and pad sequences\n    5. Create embedding matrix\n    6. Crate a layer of model, layer is Sequential --> Embedding --> Conv1D --> MaxPolling1D --> Conv1D --> MaxPolling1D --> Dropout -- > Dense\n    7. Train the model\n    6. Predict the model\n    \"\"\"\n    def __init__(self,\n                 ):\n        \"\"\" This method initialize the object\"\"\"\n        pass\n    \n    def __loadData(self):\n        \"\"\" \n        This method loads the train and test csv file\n        Reference URL:\n        https://www.dataquest.io/blog/pandas-python-tutorial/\n        https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\n        \"\"\"\n        print(os.listdir(\".\"))\n        self.train = pd.read_csv('../input/cleaned-toxic-comments/train_preprocessed.csv').fillna(\" \")\n        self.test  = pd.read_csv('../input/cleaned-toxic-comments/test_preprocessed.csv').fillna(\" \")\n    \n    def __cleanData(self):\n        \"\"\" \n        This method clean the data\n        \"\"\"        \n        self.train_x = self.train['comment_text'].fillna(' ')\n        self.test_x  = self.test['comment_text'].fillna(' ')\n        self.train_y = self.train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n        self.train_x = self.train_x.str.lower()\n        self.test_x = self.test_x.str.lower()\n        \n        \n    def __toknizeData(self):\n        \"\"\" \n        This method tokenize data.\n        Reference URL : \n        http://www.orbifold.net/default/2017/01/10/embedding-and-tokenizer-in-keras/\n        https://machinelearningmastery.com/prepare-text-data-deep-learning-keras/\n        \"\"\"\n        self.tokenizer = text.Tokenizer(num_words=max_features, )\n        self.tokenizer.fit_on_texts(list(self.train_x))\n        self.train_x = self.tokenizer.texts_to_sequences(self.train_x)\n        self.test_x = self.tokenizer.texts_to_sequences(self.test_x)\n        self.train_x = sequence.pad_sequences(self.train_x, maxlen=maxlen)\n        self.test_x = sequence.pad_sequences(self.test_x, maxlen=maxlen)\n        \n    \n    \n    def __generateEmbeddingMatrix(self,):\n        \"\"\" \n        This method generates the embedding matrix for the given token using \n        global glob vector \n        Reference I used are\n        https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12\n        http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n        https://nlp.stanford.edu/projects/glove/\n        http://www.orbifold.net/default/2017/01/10/embedding-and-tokenizer-in-keras/\n        \"\"\"\n        embeddings_index = {}\n        f = open(glove_data)\n        for line in f:\n            values = line.rstrip().rsplit(' ')\n            word = values[0]\n            value = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = value\n        f.close()\n        print('Loaded %s word vectors.' % len(embeddings_index))\n        word_index = self.tokenizer.word_index\n        num_words = min(max_features, len(word_index))\n        print(\"No of words : %s, embedding dimension : %s\" % (num_words, embedding_dimension))\n        self.embedding_matrix = np.zeros((num_words , embedding_dimension))\n        for word, i in word_index.items():\n            if i > num_words : continue\n            embedding_vector = embeddings_index.get(word)\n            if embedding_vector is not None:\n                # words not found in embedding index will be all-zeros.\n                self.embedding_matrix[i] = embedding_vector[:embedding_dimension]\n        \n    def __createModel(self):\n        \"\"\" \n        This method creates the model for LSTM.\n        Reference URL\n        https://faroit.github.io/keras-docs/0.3.3/examples/\n        http://philipperemy.github.io/keras-stateful-lstm/\n        https://towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47\n        https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n        https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n        https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n        https://keras.io/getting-started/sequential-model-guide/\n        http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n        \"\"\"\n        self.model = Sequential()\n        self.model.add(Embedding(max_features, embed_size, weights=[self.embedding_matrix], trainable=True))\n        self.model.add(Bidirectional(LSTM(256, dropout=0.15, recurrent_dropout=0.15)))\n        self.model.add(Dropout(0.5))\n        self.model.add(Dense(num_classes, activation='sigmoid')) \n        self.model.compile(loss='binary_crossentropy',\n              optimizer='rmsprop',\n              metrics=['accuracy'])\n        print(self.model.summary())\n        \n    def __trainModel(self):\n        \"\"\" This method train the model \"\"\"\n        X_train, X_test, y_train, y_test = train_test_split(self.train_x, self.train_y, test_size=0.33, random_state=42)\n        self.model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                       callbacks=[roc_callback(training_data=(X_train, y_train), validation_data=(X_test, y_test))])\n        \n    def __predictModel(self):\n        self.predictions = self.model.predict(self.test_x, batch_size=batch_size, verbose=1)\n        \n        \n    def __resultGeneration(self):\n        \"\"\" This method generates result for the test file\"\"\"\n        submission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n        submission[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']] = self.predictions\n        submission.to_csv('submission.csv', index=False)\n        print(os.listdir(\".\"))\n    \n    def run(self):\n        self.__loadData()\n        self.__cleanData()\n        self.__toknizeData()\n        self.__generateEmbeddingMatrix()\n        self.__createModel()\n        self.__trainModel()\n        self.__predictModel()\n        self.__resultGeneration()\n        \n        \n        \nif __name__ == '__main__' :\n    obj = CommentPrediction()\n    obj.run()\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2bd932de553c5a371703caa4cd49db7033be5aa6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}