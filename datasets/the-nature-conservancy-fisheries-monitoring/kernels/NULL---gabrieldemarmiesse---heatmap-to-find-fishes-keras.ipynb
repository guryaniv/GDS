{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c92a0cdc-b392-168e-547f-1cb36f6724d5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5860b2b7-4e52-b74e-1574-6acfd1f26975"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.layers.core import  Lambda, Merge\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras import backend as K\n",
        "from keras.engine import Layer\n",
        "from os import listdir\n",
        "from os.path import isfile, join, dirname\n",
        "from scipy.io import loadmat\n",
        "import gc\n",
        "from keras.utils.layer_utils import layer_from_config\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "\n",
        "# Credits to heuritech for their great code which was a great inspiration.\n",
        "# Some of the code comes directly from their repository.\n",
        "# You can look it up: https://github.com/heuritech/convnets-keras\n",
        "\n",
        "\t\n",
        "# Keras doesn't have a 4D softmax. So we need this.\n",
        "class Softmax4D(Layer):\n",
        "    def __init__(self, axis=-1,**kwargs):\n",
        "        self.axis=axis\n",
        "        super(Softmax4D, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        pass\n",
        "\n",
        "    def call(self, x,mask=None):\n",
        "        e = K.exp(x - K.max(x, axis=self.axis, keepdims=True))\n",
        "        s = K.sum(e, axis=self.axis, keepdims=True)\n",
        "        return e / s\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return input_shape\n",
        "\t\t\n",
        "\n",
        "def get_dim(model, layer_index, input_shape=None):\n",
        "    \n",
        "    # Input shape is the shape of images used during training.\n",
        "    if input_shape is not None:\n",
        "        dummy_vector = np.zeros((1,) + input_shape)\n",
        "    else:\n",
        "        if model.layers[0].input_shape[2] is None:\n",
        "            raise ValueError('You must provide \\\"input_shape = (3,256,256)\\\" for example when calling the function.')\n",
        "        dummy_vector = np.zeros((1,) + model.layers[0].input_shape[1:])\n",
        "    \n",
        "    intermediate_layer_model = Model(input=model.input,\n",
        "                                 output=model.layers[layer_index].output)\n",
        "    \n",
        "    out = intermediate_layer_model.predict(dummy_vector)\n",
        "    \n",
        "    return out.shape[1:]\n",
        "\t\n",
        "\n",
        "def from_config(layer, config_dic):\n",
        "    config_correct = {}\n",
        "    config_correct['class_name'] = type(layer)\n",
        "    config_correct['config'] = config_dic\n",
        "    return layer_from_config(config_correct)\n",
        "\t\n",
        "\n",
        "def add_to_model(x, layer):\n",
        "    new_layer = from_config(layer, layer.get_config())\n",
        "    x = new_layer(x)\n",
        "    if layer.get_weights() is not None:\n",
        "        new_layer.set_weights(layer.get_weights())\n",
        "    return x\n",
        "\t\n",
        "\n",
        "def layer_type(layer):\n",
        "    return str(layer)[10:].split(\" \")[0].split(\".\")[-1]\n",
        "\t\n",
        "\n",
        "def detect_configuration(model):\n",
        "    # must return the configuration and the number of the first pooling layer\n",
        "    \n",
        "    # Names (types) of layers from end to beggining\n",
        "    inverted_list_layers = [layer_type(layer) for layer in model.layers[::-1]]\n",
        "    \n",
        "    layer1 = None\n",
        "    layer2 = None \n",
        "    \n",
        "    i = len(model.layers)\n",
        "    \n",
        "    for layer in inverted_list_layers:\n",
        "        i -= 1\n",
        "        if layer2 is None:\n",
        "            if layer == \"GlobalAveragePooling2D\" or layer == \"GlobalMaxPooling2D\":\n",
        "                layer2 = layer\n",
        "\n",
        "            elif layer == \"Flatten\":\n",
        "                return \"local pooling - flatten\", i-1\n",
        "            \n",
        "        else:\n",
        "            layer1 = layer\n",
        "            break\n",
        "            \n",
        "    if layer1 == \"MaxPooling2D\" and layer2 == \"GlobalMaxPooling2D\":\n",
        "        return \"local pooling - global pooling (same type)\", i\n",
        "    elif layer1 == \"AveragePooling2D\" and layer2 == \"GlobalAveragePooling2D\":\n",
        "        return \"local pooling - global pooling (same type)\", i\n",
        "    \n",
        "    elif layer1 == \"MaxPooling2D\" and layer2 == \"GlobalAveragePooling2D\":\n",
        "        return \"local pooling - global pooling (different type)\", i+1\n",
        "    elif layer1 == \"AveragePooling2D\" and layer2 == \"GlobalMaxPooling2D\":\n",
        "        return \"local pooling - global pooling (different type)\", i+1\n",
        "    \n",
        "    else:\n",
        "        return \"global pooling\", i\n",
        "\t\t\n",
        "    \n",
        "def add_zeros(w, nb_zeros):\n",
        "    \n",
        "    n = w.shape[3]\n",
        "    indexes = np.array(range(1, n))\n",
        "    w1 = w\n",
        "    for i in range(nb_zeros):\n",
        "        w1 = np.insert(w1, indexes + i, 0, axis=2)\n",
        "    for i in range(nb_zeros):\n",
        "        w1 = np.insert(w1, indexes + i, 0, axis=3)\n",
        "    return w1\n",
        "\t\n",
        "    \n",
        "def insert_weights(layer, new_layer):\n",
        "    W,b = layer.get_weights()\n",
        "    n_filter,previous_filter,ax1,ax2 = new_layer.get_weights()[0].shape\n",
        "    ax1 = ax2 = int(np.sqrt(layer.get_weights()[0].shape[0]/new_layer.get_weights()[0].shape[1]))\n",
        "    new_W = W.reshape((previous_filter,ax1,ax2,n_filter))\n",
        "    new_W = new_W.transpose((3,0,1,2))\n",
        "    new_W = new_W[:,:,::-1,::-1]\n",
        "\t\n",
        "    \n",
        "    if ax1!=1:\n",
        "        insert_zeros = int((new_layer.get_weights()[0].shape[2] - ax1)/(ax1-1))\n",
        "        print(\"insert_zeros=\" + str(insert_zeros))\n",
        "        new_W =  add_zeros(new_W, insert_zeros)\n",
        "    \n",
        "    new_layer.set_weights([new_W,b])\n",
        "\t\n",
        "    \n",
        "def copy_last_layers(model, begin,x):\n",
        "    \n",
        "    i=begin\n",
        "    \n",
        "    for layer in model.layers[begin:]:\n",
        "        if layer_type(layer) == \"Dense\":\n",
        "            \n",
        "            if i == len(model.layers)-1:\n",
        "                x = add_reshaped_layer(layer,x,1, no_activation=True)\n",
        "            else:\n",
        "                x = add_reshaped_layer(layer,x,1)\n",
        "            \n",
        "        elif layer_type(layer) == \"Dropout\":\n",
        "            pass\n",
        "                \n",
        "        elif layer_type(layer) == \"Activation\" and i == len(model.layers)-1:\n",
        "            break\n",
        "               \n",
        "        else:\n",
        "            x = add_to_model(x, layer)\n",
        "        i+=1\n",
        "    \n",
        "    x = Softmax4D(axis=1,name=\"softmax\")(x)\n",
        "    return x\n",
        "    \n",
        "                \n",
        "def add_reshaped_layer(layer, x, size, no_activation=False, add_zeros = None):\n",
        "\n",
        "    conf = layer.get_config()\n",
        "    \n",
        "    if no_activation:\n",
        "        activation=\"linear\"\n",
        "    else:\n",
        "        activation=conf[\"activation\"]\n",
        "        \n",
        "    #size = int(np.sqrt(layer.get_weights()[0].shape[0]/conf[\"output_dim\"]))\n",
        "    \n",
        "    new_layer = Convolution2D(conf[\"output_dim\"],size,size, activation=activation, name=conf['name'])\n",
        "         \n",
        "        \n",
        "    x= new_layer(x)\n",
        "    # We transfer the weights:\n",
        "    insert_weights(layer, new_layer)\n",
        "    return x\n",
        "    \n",
        "\n",
        "def to_heatmap(model, input_shape = None, delete = False):\n",
        "    \n",
        "    # there are four configurations possible:\n",
        "    # global pooling\n",
        "    # local pooling - flatten\n",
        "    # local pooling - global pooling (same type)\n",
        "    # local pooling - global pooling (different type)\n",
        "    \n",
        "    model_type, index = detect_configuration(model)\n",
        "    \n",
        "    print(\"Model type detected: \" + model_type)\n",
        "    \n",
        "    #new_layer.set_weights(model.layers[0].get_weights())\n",
        "    img_input = Input(shape=(3,None,None))\n",
        "   \n",
        "    # Inchanged part:\n",
        "    middle_model = Model(input=model.layers[1].input, output=model.layers[index-1].output)\n",
        "    \n",
        "    x = middle_model(img_input)\n",
        "    \n",
        "    print(\"Model cut at layer: \" + str(index))\n",
        "        \n",
        "    if model_type == \"global pooling\":\n",
        "        x = copy_last_layers(model, index+1,x)\n",
        "              \n",
        "    elif model_type == \"local pooling - flatten\":\n",
        "        \n",
        "        layer = model.layers[index]\n",
        "        dic = layer.get_config()\n",
        "        add_zeros = dic[\"strides\"][0] - 1\n",
        "        dic[\"strides\"] = (1,1)\n",
        "        new_pool = from_config(layer, dic)\n",
        "        x = new_pool(x)\n",
        "        \n",
        "        size = get_dim(model, index, input_shape)[1]\n",
        "        print(\"Pool size infered: \" + str(size))\n",
        "        \n",
        "        conv_size = size + (size-1) * add_zeros\n",
        "        \n",
        "        print(\"New convolution size: \" + str(conv_size))\n",
        "        \n",
        "        if index+2 != len(model.layers)-1:\n",
        "            x = add_reshaped_layer(model.layers[index+2],x,conv_size, add_zeros=add_zeros)\n",
        "        else:\n",
        "            x = add_reshaped_layer(model.layers[index+2],x,conv_size, add_zeros=add_zeros,no_activation=True)\n",
        "            \n",
        "        x = copy_last_layers(model, index+3,x)\n",
        "        \n",
        "        \n",
        "    elif model_type == \"local pooling - global pooling (same type)\":\n",
        "        \n",
        "        \n",
        "        dim = get_dim(model, index, input_shape=input_shape)\n",
        "\n",
        "        new_pool_size = model.layers[index].get_config()[\"pool_size\"][0] * dim[1]\n",
        "        \n",
        "        print(\"Pool size infered: \" + str(new_pool_size))\n",
        "        \n",
        "        x = AveragePooling2D(pool_size=(new_pool_size, new_pool_size), strides=(1,1)) (x)\n",
        "        x = copy_last_layers(model, index+2,x)\n",
        "        \n",
        "        \n",
        "    elif model_type == \"local pooling - global pooling (different type)\":\n",
        "        x= copy_last_layers(model, index+1,x)\n",
        "    else:\n",
        "        raise IndexError(\"no type for model: \" + str(model_type))\n",
        "        \n",
        "    \n",
        "    \n",
        "    if delete:\n",
        "        del(model)\n",
        "        gc.collect()\n",
        "        print(\"Original model was deleted.\")\n",
        "    \n",
        "    return Model(img_input, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ff053e7-73a8-e96e-3423-858b303c10e1"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/gabrieldemarmiesse/heatmaps/master/heatmap.py\", \"heatmap.py\")\n",
        "\n",
        "from heatmap import to_heatmap\n",
        "from heatmap import synset_to_dfs_ids\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c009230-ccc8-c2ef-1c9b-566624456560",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def display_heatmap(new_model, img_path):\n",
        "\n",
        "    plt.figure()\n",
        "    img=mpimg.imread(img_path)\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    img = image.load_img(img_path)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    out = new_model.predict(x)\n",
        "\n",
        "    s = \"n02512053\" # Imagenet code for \"fish\"\n",
        "    ids = synset_to_dfs_ids(s)\n",
        "    heatmap_fish = out[0,ids].sum(axis=0)\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(heatmap_fish, interpolation=\"none\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0045aaf7-0369-65b5-ac74-348cadb0b86d"
      },
      "source": [
        "## Let's try with a VGG16:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32dc7ef0-9d4b-59cd-f3ce-9b4132bf502c"
      },
      "outputs": [],
      "source": [
        "model = VGG16()\n",
        "new_model = to_heatmap(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c54c8359-b763-d8c9-8fd2-be22ad10893a"
      },
      "outputs": [],
      "source": [
        "display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0326ff41-ca2b-9e65-7f5c-4d33e9af04f0"
      },
      "source": [
        "## Now with a ResNet50:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "102af9c8-5602-897b-92cf-be64c733905e"
      },
      "outputs": [],
      "source": [
        "model = ResNet50()\n",
        "new_model = to_heatmap(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1a3dd28-0175-41bd-6289-62237953df65"
      },
      "outputs": [],
      "source": [
        "display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5b6c3614-77e7-8d12-1072-88c185de6779"
      },
      "source": [
        "## Now with a custom classifier:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a888065e-b100-fd78-a3bf-575da2a5be54"
      },
      "source": [
        "Class 0 is \"fish\" and class 1 is \"no fish\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36580105-b33a-0b4a-72ee-638b402913b2"
      },
      "outputs": [],
      "source": [
        "# load json and create model\n",
        "json_file = open('model_2c_10e_R50_1.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "model.load_weights(\"model_2c_10e_R50_1.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "47833df7-5394-cac6-e656-0db4c2752e5c"
      },
      "outputs": [],
      "source": [
        "new_model = to_heatmap(model, input_shape=(3,256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f390ee98-bb03-ff15-0987-7d9e70ef0822",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def display_heatmap(new_model, img_path):\n",
        "\n",
        "    plt.figure()\n",
        "    img=mpimg.imread(img_path)\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "    img = image.load_img(img_path)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "\n",
        "    out = new_model.predict(x)\n",
        "\n",
        "    heatmap_fish = out[0,[0]].sum(axis=0)\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(heatmap_fish, interpolation=\"none\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d0b39ad-04af-ab99-64f4-acd82df058ed"
      },
      "outputs": [],
      "source": [
        "display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1bb683fb-21b5-dc69-c379-2122a06c947b"
      },
      "source": [
        "## Now with the InceptionV3:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "57aec5ea-809b-7a29-8f8d-357ee38e058e"
      },
      "source": [
        "It's buggy and I don't know why. If someone could figure it out, it'd be great."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab463322-817d-ae16-dd03-6d84d8309935"
      },
      "outputs": [],
      "source": [
        "model = InceptionV3()\n",
        "new_model = to_heatmap(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ca09e55-1034-6bbb-5f62-7f0ac5acc3de"
      },
      "outputs": [],
      "source": [
        "display_heatmap(new_model, \"./train/ALB/img_00110.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00003.jpg\")\n",
        "display_heatmap(new_model, \"./train/ALB/img_00085.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "730fad14-a4b3-b326-6476-f61ae475acb2"
      },
      "source": [
        "Don't hesitate to contribute!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bbc0f970-2aa9-1423-2d28-f5522fb4baf0"
      },
      "source": [
        "Here is some code to transform a Keras classifier into a heatmap generator. \n",
        "A lot of ideas were taken from this repository: https://github.com/heuritech/convnets-keras \n",
        "This is just an optimised sliding window.\n",
        "It works with classic models from Imagenet and also custom models.\n",
        "It doesn't work well with Tensorflow right now (if someone could contribute to make it work on tensorflow, it'd be super cool).\n",
        "There is also a bug with the InceptionV3. I'm still trying to figure it out.\n",
        "\n",
        "The github repository for the files is here: https://github.com/gabrieldemarmiesse/heatmaps \n",
        "\n",
        "Don't hesitate to contribute!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "384d83d5-2110-dfe1-9b0c-5f62f3bd9c32"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c0babc0-475f-2806-86fa-475ebaf059de",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c6570050-f734-71dd-df16-a5d664f5b947"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3e840c4-1ee3-ea06-35c8-0d4909aeb8a4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec61c552-2bde-ae2b-e7ae-e0fd55de0963"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "83e0157d-6b77-aaf8-cb23-8a2a767b7b4c"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba46d4e8-d174-d896-96ff-c503313289f5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0660971-50b5-9155-49cc-c470ab5998b4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0ee7e481-d13b-b968-ee73-ec120aaec565"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b757cd80-284a-0589-553f-2d965c8d8d20"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68dec84d-648e-ae65-a6fc-de01b42da15f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be2aaa44-3ef4-53ca-70b0-85fb6a85539e"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b639b849-a881-3931-aa15-f0378e7640f9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "548088cf-5bc7-87ae-046e-cc052e32c9ac"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d249160-047b-a508-bfef-db2ffb8d5a4e"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1faee7e-6f26-9c47-eabe-eb57d9086724"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "230132b6-ccc0-884c-6c78-3dcc20368fd1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3104ddd3-54ce-46eb-add1-e480ff3eb8d5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dda58790-595c-976e-1845-ede3268bdb3d"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}