{"cells":[{"metadata":{"_cell_guid":"3de3c57b-3569-4d21-a5b1-c40b17a55d47","_uuid":"5955c5a9717e0758b5f46be03f6246e65c4cb54a","trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n# import pandas as pd\nimport pandas as pd\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd8e71be-ac18-4735-946d-59b2193345a1","_uuid":"224a173852ef534d896fb2507de51990f0409bb3","trusted":true},"cell_type":"code","source":"# file stored in variable\nmain_file_path = '../input/train.csv'\n# file import as dataframe\ndata = pd.read_csv(main_file_path)\n# print columns of dataframe\nprint(data.columns)\n# select survival column from dataframe and store it in variable\nsurvival_data = data.Survived\n# print top 5 values of Survived column\nprint(survival_data.head())\nprint(data.info())\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"91e9d2b4-5819-41e7-b9f0-c604f6580d75","_uuid":"f3bce12cbd2abd7706cc428e4a9760d24e104f7f","trusted":true},"cell_type":"code","source":"# Creating the model\n# select your target variable and store it as y\ny = survival_data\n# create the list of prediction columns named predictors\npredictors = ['Pclass','SibSp','Parch','Fare']\n# select predictors list data and store it as X\nX = data[predictors]\n# Define model\nSurvival_model = DecisionTreeClassifier()\n# fit model\nSurvival_model.fit(X,y)\n# predict using model\nprediction = Survival_model.predict(X.head())\n# print predictions\nprint(\"The predictions for first 5 passengers in training dataset\")\nprint(prediction)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"616f88a1-1025-4c90-890c-350efc911687","_uuid":"9877e354242afedea7dfd117b660fdfb1441349a","trusted":true},"cell_type":"code","source":"# test file stored in variable\ntest_file_path = '../input/test.csv'\n# test file import as dataframe\ntest_data = pd.read_csv(test_file_path)\n# print columns of dataframe\nprint(test_data.columns)\n# extract predictors list data from test_data\ntest_data_predictors = test_data[predictors]\ntest_predictions = Survival_model.predict(test_data_predictors.head())\nprint(\"predictions for first five test data\")\nprint(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e6e9628d-a111-48b1-8e9b-81d935867e94","_uuid":"1576f14dc9bfdb611e264896ee420a9ce6088fb0","trusted":true},"cell_type":"code","source":"# import train_test_split to split the data into train and test data\n\nfrom sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n# Define model\nSurvival_model = DecisionTreeClassifier()\n# Fit model\nSurvival_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = Survival_model.predict(val_X)\nprint(val_predictions)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47309887-1bd5-450c-83e1-a40717b884d4","_uuid":"39eb77df977bdd6c446d37ef8726b6db86bb315d","trusted":true},"cell_type":"code","source":"forest_survival_model = RandomForestClassifier()\nforest_survival_model.fit(train_X, train_y)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c8ca7611-5bf4-4dbf-b075-ad79dff34ab6","_uuid":"6911abfe10bfda190aa699ac73f1a1d19901f906","trusted":true},"cell_type":"code","source":"# predict first 5 test data samples using Random forest classifier\ntest_predictions = forest_survival_model.predict(test_data_predictors.head())\nprint(\"predictions for first five test data\")\nprint(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0d94ac85-e720-4bd3-ae0f-3b15cfacb344","_uuid":"64d39d80ddcbc603fae31b6c9ba016f7422acd22","trusted":true},"cell_type":"code","source":"# considering all columns for prediction\nsurvival_predictors = data.drop((['Survived','Name']), axis=1)\ntest_data_predictors = test_data.drop((['Name']), axis=1)\n\n\n# For the sake of keeping the example simple, we'll use only numeric predictors first\nsurvival_numeric_predictors = survival_predictors.select_dtypes(exclude=['object'])\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(survival_numeric_predictors, \n                                                    y,\n                                                    train_size=0.8, \n                                                    test_size=0.2, \n                                                    random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"752be047-628d-470f-b027-9f220027e5ac","_uuid":"362252cd13a09d20907da787c3732b2ef51fa7e0","trusted":true},"cell_type":"code","source":"# get one-hot encodings for categorical data for test_data\none_hot_encoded_test_data = pd.get_dummies(test_data_predictors)\n# checking the data types for one-hot encoded data\none_hot_encoded_test_data.dtypes.sample(10)\n# get one-hot encodings for categorical data in train data\none_hot_survival_predictors = pd.get_dummies(survival_predictors)\n# checking the data types for one-hot encoded train data\none_hot_survival_predictors.dtypes.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fae6f8dc-97d2-4643-982b-d33d4bf3a302","_uuid":"5ecf64864b424c3f558454f9d3200af7acb6a50d","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\n\nmy_imputer = Imputer()\n# splitting of data after one hot encoding i.e. change of categorical data to numericals\none_hot_X_train, one_hot_X_test, one_hot_y_train, one_hot_y_test = train_test_split(one_hot_survival_predictors, \n                                                    y,\n                                                    train_size=0.8, \n                                                    test_size=0.2, \n                                                    random_state=0)\n\nimputed_one_hot_X_train_plus = one_hot_X_train.copy()\nimputed_one_hot_X_test_plus = one_hot_X_test.copy()\n\n\ncols_with_missing = (col for col in one_hot_X_train.columns \n                                 if one_hot_X_train[col].isnull().any())\nfor col in cols_with_missing:\n    imputed_one_hot_X_train_plus[col + '_was_missing'] = imputed_one_hot_X_train_plus[col].isnull()\n    imputed_one_hot_X_test_plus[col + '_was_missing'] = imputed_one_hot_X_test_plus[col].isnull()\n\n# Imputation\nmy_imputer = Imputer()\nimputed_one_hot_X_train_plus = my_imputer.fit_transform(imputed_one_hot_X_train_plus)\nimputed_one_hot_X_test_plus = my_imputer.transform(imputed_one_hot_X_test_plus)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f731f04b-fa8a-4852-94d0-e3ca80cc439f","_uuid":"382acce5798a5e4247736d5346655274b7b2452e","trusted":true},"cell_type":"code","source":"# Ensure the test data is encoded in the same manner as the training data with the align command\none_hot_encoded_training_predictors = pd.get_dummies(survival_predictors)\none_hot_encoded_test_predictors = pd.get_dummies(test_data_predictors)\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                    join='left', \n                                                                    axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cb5d9288-623c-45ba-84ed-109f468b329c","_uuid":"1faa747a5a494a91a649dd2234ee16229db4ea0e","trusted":true},"cell_type":"code","source":"#splitting of data after alignment of test data with training data\none_hot_X_train, one_hot_X_test, one_hot_y_train, one_hot_y_test = train_test_split(final_train, \n                                                    y,\n                                                    train_size=0.8, \n                                                    test_size=0.2, \n                                                    random_state=0)\n\nimputed_one_hot_X_train_plus = one_hot_X_train.copy()\nimputed_one_hot_X_test_plus = one_hot_X_test.copy()\nimputed_one_hot_test_plus = final_test.copy()\n\ncols_with_missing = (col for col in one_hot_X_train.columns \n                                 if one_hot_X_train[col].isnull().any())\nfor col in cols_with_missing:\n    imputed_one_hot_X_train_plus[col + '_was_missing'] = imputed_one_hot_X_train_plus[col].isnull()\n    imputed_one_hot_X_test_plus[col + '_was_missing'] = imputed_one_hot_X_test_plus[col].isnull()\n    imputed_one_hot_test_plus[col + '_was_missing'] = imputed_one_hot_test_plus[col].isnull()\n# Imputation along with imputation of test data\nmy_imputer = Imputer()\nimputed_one_hot_X_train_plus = my_imputer.fit_transform(imputed_one_hot_X_train_plus)\nimputed_one_hot_X_test_plus = my_imputer.transform(imputed_one_hot_X_test_plus)\nimputed_one_hot_test_plus = my_imputer.transform(imputed_one_hot_test_plus)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cdb772ed-a9e7-4e80-85ea-e797f43b4d9b","_uuid":"5f4ac6ce2a7cd3f96573f0ed1eeb87da03aba719","trusted":true},"cell_type":"code","source":"# running random forest model on one hot encoded plus impututed data\nmodel = RandomForestClassifier()\nmodel.fit(imputed_one_hot_X_train_plus, y_train)\n# prediction on test data\npreds = model.predict(imputed_one_hot_test_plus)\n\nacc_RF = round(model.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_RF","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5b1e8947-0fbe-46bb-8fbd-2706ddd83c5b","_uuid":"c62d8e6fc62695993c84e06c69b019a56789e119","trusted":true},"cell_type":"code","source":"# create csv output file for submission\nmy_submission = pd.DataFrame({'PassengerId': final_test.PassengerId, 'Survived': preds})\n# you could use any filename. We choose submission_6 here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a9a77ef1-3ae5-43c6-8f15-0178d1d4250b","_uuid":"85b8eb635404850fd7bee81f90e9f0ae9e6202c1","trusted":true},"cell_type":"code","source":"# support vector machine\nsvc = SVC()\nsvc.fit(imputed_one_hot_X_train_plus, y_train)\npreds = svc.predict(imputed_one_hot_test_plus)\nacc_svc = round(svc.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e99cb208-b756-4af4-ac63-fdda41ec63d5","_uuid":"1c30e07f7c25af991a8f8056fdf4b6083055e4cc","trusted":true},"cell_type":"code","source":"# Decision tree classifier \n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(imputed_one_hot_X_train_plus, y_train)\npreds = decision_tree.predict(imputed_one_hot_test_plus)\nacc_decision_tree = round(decision_tree.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_decision_tree","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1b96835e-a759-4b6f-bd61-1e94b611ff62","_uuid":"56e9f94809d95970bd197a7def8ec3cc82a48029","trusted":true},"cell_type":"code","source":"# create csv output file for submission\nmy_submission = pd.DataFrame({'PassengerId': final_test.PassengerId, 'Survived': preds})\n# you could use any filename. We choose submission_6 here\nmy_submission.to_csv('submission_2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"75731ea5-531b-4624-9c9e-d1da81394a8e","_uuid":"ef57b2a89b0f0f202a5250d5c21025f8db4c2e24","trusted":true},"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(imputed_one_hot_X_train_plus, y_train)\npreds = sgd.predict(imputed_one_hot_test_plus)\nacc_sgd = round(sgd.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_sgd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"73c592a4-b752-4297-944d-a092a456b3f6","_uuid":"48ed508ae1432a9583c45796ca25ac0261d65ef5","trusted":true},"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(imputed_one_hot_X_train_plus, y_train)\npreds = logreg.predict(imputed_one_hot_test_plus)\nacc_log = round(logreg.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_log","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c12522c8-8925-4699-b808-04b7262b9217","_uuid":"6b21900ae9dd76740b1838e893d19d614c00b2f6","trusted":true},"cell_type":"code","source":"# KNN\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(imputed_one_hot_X_train_plus, y_train)\npreds = knn.predict(imputed_one_hot_test_plus)\nacc_knn = round(knn.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_knn","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7680431f-841a-4c20-a194-c29f233a7612","_uuid":"d577a45c34338a1480f85d03fb2c89d2bda548a3","trusted":true},"cell_type":"code","source":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(imputed_one_hot_X_train_plus, y_train)\npreds = gaussian.predict(imputed_one_hot_test_plus)\nacc_gaussian = round(gaussian.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_gaussian","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b6cd5f03-54a3-4612-aca9-f93371c14826","_uuid":"32b9fb2267583d15d2a17c58010c2e495333396f","trusted":true},"cell_type":"code","source":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(imputed_one_hot_X_train_plus, y_train)\npreds = perceptron.predict(imputed_one_hot_test_plus)\nacc_perceptron = round(perceptron.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_perceptron","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fa589e3f-8721-4839-9b41-85c3fe69a86f","_uuid":"60df2322552c8ce49a49582a1eb063e13f76a8d2","trusted":true},"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(imputed_one_hot_X_train_plus, y_train)\npreds = linear_svc.predict(imputed_one_hot_test_plus)\nacc_linear_svc = round(linear_svc.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_linear_svc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"382cfb14-08ee-407d-af85-654de20f48e1","_uuid":"87d03d895043df9efcf293d4605f3bbc46118c3a","trusted":true},"cell_type":"code","source":"# running XGboost with categorical data\nfrom xgboost import XGBClassifier\nmodel = XGBClassifier(learning_rate=0.05 )\nmodel.fit(imputed_one_hot_X_train_plus, y_train)\n# prediction of house price on test data\npreds = model.predict(imputed_one_hot_test_plus)\nacc_xgboost = round(model.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_xgboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f8daafe982ef2ba0042dad96ff49991ad67669c"},"cell_type":"code","source":"from catboost import CatBoostClassifier\nmodel = CatBoostClassifier(learning_rate=0.05)\nmodel.fit(imputed_one_hot_X_train_plus, y_train)\n# prediction of house price on test data\npreds = model.predict(imputed_one_hot_test_plus)\nacc_catboost = round(model.score(imputed_one_hot_X_train_plus, y_train) * 100, 2)\nacc_catboost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bc2a7f01b0ad237a9ebaca7bd4c0d3f15b444c96"},"cell_type":"code","source":"# create csv output file for submission\nmy_submission = pd.DataFrame({'PassengerId': final_test.PassengerId, 'Survived': preds})\n# you could use any filename. We choose submission_3 here\nmy_submission.to_csv('submission_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae8e4155-db7a-4991-a4a2-8b64350bfaf4","_uuid":"e7456a00f092bd4c570341170afb6274d8a93145","trusted":true},"cell_type":"code","source":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree','XGBoost Classifier','CatBoost Classifier'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_RF, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree,acc_xgboost,acc_catboost]})\nmodels.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}