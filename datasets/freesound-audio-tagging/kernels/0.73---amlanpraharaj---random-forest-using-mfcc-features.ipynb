{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport librosa\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\n\nSAMPLE_RATE = 44100","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"#loading data\naudio_train_files = os.listdir('../input/audio_train')\naudio_test_files = os.listdir('../input/audio_test')\n\ntrain = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"98ec03e6-ff01-4acb-92af-ddae08839162","_uuid":"3007f57b4346ef16effdd1fdb2e134fc3521da81","collapsed":true,"trusted":true},"cell_type":"code","source":"#function from EDA kernel: https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis\ndef clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name\n\n#returns mfcc features with mean and standard deviation along time\ndef get_mfcc(name, path):\n    b, _ = librosa.core.load(path + name, sr = SAMPLE_RATE)\n    assert _ == SAMPLE_RATE\n    try:\n        gmm = librosa.feature.mfcc(b, sr = SAMPLE_RATE, n_mfcc=20)\n        return pd.Series(np.hstack((np.mean(gmm, axis=1), np.std(gmm, axis=1))))\n    except:\n        print('bad file')\n        return pd.Series([0]*40)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"764f6a4d-9f5b-4977-a80f-7c99d0cd15e5","_uuid":"0a7b3047cec100da83d79f593d3c01e3379559fa","scrolled":true,"trusted":true},"cell_type":"code","source":"#preparing data\ntrain_data = pd.DataFrame()\ntrain_data['fname'] = train['fname']\ntest_data = pd.DataFrame()\ntest_data['fname'] = audio_test_files\n\ntrain_data = train_data['fname'].apply(get_mfcc, path='../input/audio_train/')\nprint('done loading train mfcc')\ntest_data = test_data['fname'].apply(get_mfcc, path='../input/audio_test/')\nprint('done loading test mfcc')\n\ntrain_data['label'] = train['label']\ntest_data['label'] = np.zeros((len(audio_test_files)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"082273ba-fca1-46d5-9370-26350e427e96","_uuid":"364dc66fb3dcb899fcb14ce9b2841bb7b7786765","collapsed":true,"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ce971a7-b73a-4719-b50d-967b40da77eb","_uuid":"f61a3992c82e01d0b1c63af1cfe2d8b7dcaa3ba0","collapsed":true,"trusted":true},"cell_type":"code","source":"#Functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\n# Construct features set\nX = train_data.drop('label', axis=1)\nfeature_names = list(X.columns)\nX = X.values\nlabels = np.sort(np.unique(train_data.label.values))\nnum_class = len(labels)\nc2i = {}\ni2c = {}\nfor i, c in enumerate(labels):\n    c2i[c] = i\n    i2c[i] = c\ny = np.array([c2i[x] for x in train_data.label.values])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98a0d2b0-c474-48c9-ac38-ce986f44950e","_uuid":"bda6a2934e3d8369b3ceab67c728b1b149f0f217","collapsed":true,"trusted":true},"cell_type":"code","source":"#fitting random forest on the dataset\nrfc = RandomForestClassifier(n_estimators = 150)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10, shuffle = True)\nrfc.fit(X_train, y_train)\n#more functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\ndef proba2labels(preds, i2c, k=3):\n    ans = []\n    ids = []\n    for p in preds:\n        idx = np.argsort(p)[::-1]\n        ids.append([i for i in idx[:k]])\n        ans.append(' '.join([i2c[i] for i in idx[:k]]))\n\n    return ans, ids\n#checking the accuracy of the model\nprint(rfc.score(X_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ab6e3a6a-458b-4f2b-9109-6d2821f85320","_uuid":"124c03cd99787dfb2c2bde67fe0e48824bd9fafa","collapsed":true,"trusted":true},"cell_type":"code","source":"#fitting on the entire data\nrfc.fit(X, y)\nstr_preds, _ = proba2labels(rfc.predict_proba(test_data.drop('label', axis = 1).values), i2c, k=3)\n# Prepare submission\nsubm = pd.DataFrame()\nsubm['fname'] = audio_test_files\nsubm['label'] = str_preds\nsubm.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64328b80-d5b9-427b-a485-aa086dac2179","_uuid":"90ed554c868c7ba00c1e936b1e5d942dad0b3a9c","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}