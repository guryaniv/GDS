{"cells":[{"metadata":{"_uuid":"f179e68e2be0fa1293b71634c60114c19e4cf8be"},"cell_type":"markdown","source":"# **Happy Thanks Giving!**\n\n---\nOutline of Notebook\n---\n* [**1.Import Dataset**](#1.Import-Dataset)\n* [**2.Design Attention Layer**](#2.Design-Attention-Layer)\n* [**3.Split Dataset**](#3.Split-Dataset)\n* [**4.Model Desing and Result Evaluation**](#4.Model-Desing-and-Result-Evaluation)\n* [**5.KFold LSTM Model Training**](#5.KFold-LSTM-Model-Training)\n* [**6.Result Distribution**](#6.Result-Distribution)\n* [**7.Filter Data Using Threshold**](#7.Filter-Data-Using-Threshold)\n* [**8.Final Model Training**](#8.Final-Model-Training)\n* [**9.Submission**](#9.Submission)\n\n---"},{"metadata":{"_uuid":"8ebd7f138f352a633444704a9c1fa0d1d51b8000"},"cell_type":"markdown","source":"## 1.Import Dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nfrom tqdm import tqdm\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a4ddd7f3767d700e20ff6a8ff5379e2d7eac8fd"},"cell_type":"code","source":"from keras import Sequential\nfrom keras import optimizers\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential,Model\nfrom keras.layers import LSTM, Dense, Bidirectional, Input,Dropout,BatchNormalization,CuDNNLSTM, GRU, CuDNNGRU, Embedding, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom keras.layers import *\nfrom sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cb16358760900c7b9cb8f814252680a075e0005"},"cell_type":"markdown","source":"## 2.Design Attention Layer"},{"metadata":{"trusted":true,"_uuid":"07ee152ecc85dc161ae30649d864436a37484a78"},"cell_type":"code","source":"# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1c37d0c16b6f37d440a8dac62ba28ef9a79c29e"},"cell_type":"markdown","source":"## 3.Split Dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\nsample_submission = pd.read_csv('../input/sample_submission.csv')\nxtrain = [k for k in train['audio_embedding']]\ntest_data = test['audio_embedding'].tolist()\nytrain = train['is_turkey'].values\n# Pad the audio features so that all are \"10 seconds\" long\nx_train = pad_sequences(xtrain, maxlen=10)\ny_train = np.asarray(ytrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b348b6b2f0299c18ec8039a6e13c63293fa9db67"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2d0bc470e94553fa7492f5c3e77a216506693dc"},"cell_type":"markdown","source":"## 4.Model Desing and Result Evaluation"},{"metadata":{"trusted":true,"_uuid":"a98cf37a9d166af2346a8e8f883132afef5a55fb"},"cell_type":"code","source":"def eva_plot(History, epoch):\n    plt.figure(figsize=(20,10))\n    sns.lineplot(range(1, epoch+1), History.history['acc'], label='Train Accuracy')\n    sns.lineplot(range(1, epoch+1), History.history['val_acc'], label='Test Accuracy')\n    plt.legend(['train', 'validaiton'], loc='upper left')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.show()\n    plt.figure(figsize=(20,10))\n    sns.lineplot(range(1, epoch+1), History.history['loss'], label='Train loss')\n    sns.lineplot(range(1, epoch+1), History.history['val_loss'], label='Test loss')\n    plt.legend(['train', 'validaiton'], loc='upper left')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.show()\n\n\ndef get_model():\n    model = Sequential()\n    model.add(BatchNormalization(momentum=0.98,input_shape=(10, 128)))\n    model.add(Bidirectional(GRU(128, return_sequences = True)))\n    # model.add(Bidirectional(CuDNNLSTM(1, return_sequences = True)))\n    model.add(Attention(10))\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer = optimizers.Adam(lr=0.001), metrics=['accuracy'])\n#     print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"474973b7bd97c5054105e0178cf9c9956b4ec4cb"},"cell_type":"markdown","source":"## 5.KFold LSTM Model Training"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ed130aca9464eb8e909e53736093d9babd3cfb43"},"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=42069)\npreds = []\ntest_data = pad_sequences(test_data)\nfold = 0\naucs = 0\nfor train_idx, val_idx in kf.split(x_train):\n    x_train_f = x_train[train_idx]\n    y_train_f = y_train[train_idx]\n    x_val_f = x_train[val_idx]\n    y_val_f = y_train[val_idx]\n    model = get_model()\n    History = model.fit(x_train_f, y_train_f,\n              batch_size=256,\n              epochs=12,\n              verbose = 0,\n              validation_data=(x_val_f, y_val_f))\n    eva_plot(History, epoch = 12)\n    # Get accuracy of model on validation data. It's not AUC but it's something at least!\n    preds_val = model.predict([x_val_f], batch_size=512)\n    preds.append(model.predict(test_data))\n    fold+=1\n    fpr, tpr, thresholds = roc_curve(y_val_f, preds_val, pos_label=1)\n    aucs += auc(fpr,tpr)\n    print('Fold {}, AUC = {}'.format(fold,auc(fpr, tpr)))\nprint(\"Cross Validation AUC = {}\".format(aucs/10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcfa9d7d36fd873ca2b89d276d1d729a15d4c4a2"},"cell_type":"code","source":"preds = np.asarray(preds)[...,0]\npreds = np.mean(preds, axis=0)\nsub_df = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':preds})\n# sub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e9dd3811be83db71c589d6e7b2452e99ac970b4"},"cell_type":"markdown","source":"## 6.Result Distribution"},{"metadata":{"trusted":true,"_uuid":"c681c0ddb6c9f3a4ada97dcf766bd46ed719f380"},"cell_type":"code","source":"probs = sub_df.is_turkey.values\nn,bins,_ = plt.hist(probs,bins=100)\nprint(n, bins)\npos_threshold = 0.99\nneg_threshold = 0.01\npseudo_index = np.argwhere(np.logical_or(probs > pos_threshold, probs < neg_threshold ))[:,0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29add15cd6ab3e52d80f977da65adb0bb19e818e"},"cell_type":"markdown","source":"## 7.Filter Data Using Threshold"},{"metadata":{"trusted":true,"_uuid":"0036f494661ed6d424c8dd12d0ffb790a8df7669"},"cell_type":"code","source":"pseudo_x_train = test_data[pseudo_index]\npseudo_y_train = probs[pseudo_index]\npseudo_y_train[pseudo_y_train > 0.5] = 1\npseudo_y_train[pseudo_y_train <= 0.5] = 0\nx_train = np.concatenate([x_train, pseudo_x_train],axis=0)\ny_train = np.concatenate([y_train,pseudo_y_train])\nprint(x_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eadd0fb7e3d9b570b1452a4530f6ddf5310c8ac8"},"cell_type":"markdown","source":"## 8.Final Model Training"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"b6937a6084204766201f8381657a813062e2db06"},"cell_type":"code","source":"kf = KFold(n_splits=10, shuffle=True, random_state=42069)\npreds = []\ntest_data = pad_sequences(test_data)\nfold = 0\naucs = 0\nfor train_idx, val_idx in kf.split(x_train):\n    x_train_f = x_train[train_idx]\n    y_train_f = y_train[train_idx]\n    x_val_f = x_train[val_idx]\n    y_val_f = y_train[val_idx]\n    model = get_model()\n    History = model.fit(x_train_f, y_train_f,\n              batch_size=256,\n              epochs=12,\n              verbose = 0,\n              validation_data=(x_val_f, y_val_f))\n    eva_plot(History, epoch = 12)\n    # Get accuracy of model on validation data. It's not AUC but it's something at least!\n    preds_val = model.predict([x_val_f], batch_size=512)\n    preds.append(model.predict(test_data))\n    fold+=1\n    fpr, tpr, thresholds = roc_curve(y_val_f, preds_val, pos_label=1)\n    aucs += auc(fpr,tpr)\n    print('Fold {}, AUC = {}'.format(fold,auc(fpr, tpr)))\nprint(\"Cross Validation AUC = {}\".format(aucs/10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"551037863eb3ef35d20a9c4fc9d232fc53af5008"},"cell_type":"markdown","source":"## 9.Submission"},{"metadata":{"trusted":true,"_uuid":"74ed71b475b8cea914730fa18a613424bdc55c5c"},"cell_type":"code","source":"preds = np.asarray(preds)[...,0]\npreds = np.mean(preds, axis=0)\nsub_df = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':preds})\nsub_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}