{"cells":[{"metadata":{"_uuid":"c4d28cdb703b8e6c50bb8cae34709411d452d770"},"cell_type":"markdown","source":"<h1> Anomaly Detection </h1>\n\n<p>\n    Anomaly detection algorithms are a class of machine learning techniques which are used to identify data which is somehow distinct from the majority of the data. This anomalous data may be either true outliers or erronous data which you wish to remove during the cleaning process to improve the quality of the training data. However, it may be that this anomalous data represents something we are interested in identifying. For example, we may wish to detect strange network traffic due to a malicious user gaining unauthorized access, or to detect a tumor in MRI scans. Here I will apply this to the detection of credit card fraud. \n </p>\n <p>\n    Anomaly detection algorithms are closely related to regular classification and clustering tasks, however they are distinguished by the very low frequency of anomalous data.  Anomalies will represent a very small fraction of the data: typically less than 1%. One common approach to anomaly detection is to use the normal (non fraudulent) data to build a profile of the expected behaviour. Then any data points which would not reasonably belong to this profile we can mark as anomalous.\n</p>\n<p>\n    More formally, we can build a multivariate probability density function then use hypothesis testing to calculate the probability of a datapoint belonging to this PDF. We then choose a probability cutoff below which we classify the datapoint as erronous.\n</p>"},{"metadata":{"_uuid":"75c649ae627c942cf4c8c3ff8bfca8cc8e6bf877"},"cell_type":"markdown","source":"<h1> The Dataset </h1>\n\n<p> This dataset consists of  284,807 transactions made by European credit cards occuring over 2 days in September 2013.  492 of these transactions are fraudulent.  Due to confidentiality, the original features are not available, however we have the amount, time and 28 features named V1, V2.... V28 which were obtained using principal component analysis. \n</p>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.style\nfrom sklearn.metrics import fbeta_score, precision_score, recall_score, confusion_matrix\nimport itertools\n\nfrom plotly.offline import download_plotlyjs,init_notebook_mode,plot,iplot\n\nimport warnings  \nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    Copyed from a kernel by joparga3 https://www.kaggle.com/joparga3/kernels\n    \"\"\"\n    plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d5693433e5ecfd4b1270ced6eae95e68f6ce826"},"cell_type":"markdown","source":"<h1>Exploratory Data Analysis</h1>"},{"metadata":{"trusted":true,"_uuid":"116f13535fed6c9b82f6a1fa63bcade621ea740a"},"cell_type":"code","source":"matplotlib.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5201d20095d41c19b978196424cd25b507e2e474"},"cell_type":"code","source":"dataset = pd.read_csv('../input/creditcard.csv')#.drop('Time', axis=1)\n\ndataset['Amount'] = np.log(dataset['Amount'] + 1)\ndataset['Time'] = np.log(dataset['Time'] + 1)\nnormal = dataset[dataset['Class'] == 0]\n\nanomaly = dataset[dataset['Class'] == 1]\nprint(normal.shape)\nprint(anomaly.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c65bc7b9642075581eec1011f31a28b24aade95a"},"cell_type":"markdown","source":"There are 284315 valid transactions and 492 fraudulent transactions.\n\nNext we split the data into training, validation and test datasets. "},{"metadata":{"trusted":true,"_uuid":"29440b0e72152cb95771820b745a66291bc3d850"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, normal_test, _, _ = train_test_split(normal, normal, test_size=.2, random_state=42)\n\nnormal_valid, normal_test, _, _ = train_test_split(normal_test, normal_test, test_size=.5, random_state=42)\nanormal_valid, anormal_test, _, _ = train_test_split(anomaly, anomaly, test_size=.5, random_state=42)\n\ntrain = train.reset_index(drop=True)\nvalid = normal_valid.append(anormal_valid).sample(frac=1).reset_index(drop=True)\ntest = normal_test.append(anormal_test).sample(frac=1).reset_index(drop=True)\n\nprint('Train shape: ', train.shape)\nprint('Proportion os anomaly in training set: %.2f\\n' % train['Class'].mean())\nprint('Valid shape: ', valid.shape)\nprint('Proportion os anomaly in validation set: %.2f\\n' % valid['Class'].mean())\nprint('Test shape:, ', test.shape)\nprint('Proportion os anomaly in test set: %.2f\\n' % test['Class'].mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"457cae1825a026c712dca3ecdbd5bbce766bd284"},"cell_type":"markdown","source":"It is very useful to see how the distributions of normal and fraudulent transactions compare for each feature."},{"metadata":{"trusted":true,"_uuid":"7bd7592099aa7aa0828ae187aacf19c46adf9353"},"cell_type":"code","source":"for feature in ['Amount',\n                'Time',\n                'V1',\n                'V2',\n                'V3',\n                'V4',\n                'V5',\n                'V6',\n                'V7',\n                'V8',\n                'V9',\n                'V10',\n                'V11',\n                'V12',\n                'V13',\n                'V14',\n                'V15',\n                'V16',\n                'V17',\n                'V18',\n                'V19',\n                'V20',\n                'V21',\n                'V22',\n                'V23',\n                'V24',\n                'V25',\n                'V26',\n                'V27',\n                'V28',]:\n    ax = plt.subplot()\n    sns.distplot(dataset[feature][dataset.Class == 1], bins=50, label='Fraudulent')\n    sns.distplot(dataset[feature][dataset.Class == 0], bins=50, label='Normal')\n    ax.set_xlabel('')\n    ax.set_title('histogram of feature: ' + str(feature))\n    plt.legend(loc='best')\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73c9fd0a9085cb6be006ca92011cb97ba1957b46"},"cell_type":"markdown","source":"\n<p>The preceeding graphs show the profile of the normal data compared to the profile of the fraudulent data for all 30 features. It is clear that some features will be much more important for detecting fraudulent data than others. As an example of this, compare features V15 and V14.  Feature V15 has almost identical distributions for normal and fraudulent data wheras feature V14 has a sharp peak centered at 0 for normal data but a flatter peak centered at -6. So clearly a datapoint with a value of -15 for V14 will have quite a high probability of being fraudulent. </p>"},{"metadata":{"trusted":true,"_uuid":"324149a7bf92f2e095ff1601b18f5c22c536a212"},"cell_type":"markdown","source":"<h1> Training and testing </h1>\n<p> We will start with a multivariate normal model. This is one of the simplest anomaly detection algorithms. It fits a multivariate normal distribution (closely related to multivariate gaussian) and will mark any value which is far from the mean as being an anomaly. </p>\n<p>The first step is to determine the values mu and sigma for the model and create the model.</p>"},{"metadata":{"trusted":true,"_uuid":"cdb80dea72a9c4de5e7b69380b55e772785a3b47"},"cell_type":"code","source":"from scipy.stats import multivariate_normal\n\nmu = train.drop('Class', axis=1).mean(axis=0).values\nsigma = train.drop('Class', axis=1).cov().values\nmodel = multivariate_normal(cov=sigma, mean=mu, allow_singular=True)\n\nprint(np.median(model.logpdf(valid[valid['Class'] == 0].drop('Class', axis=1).values))) \nprint(np.median(model.logpdf(valid[valid['Class'] == 1].drop('Class', axis=1).values))) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be6784d090d195216de81b2ae6b95d05675c0d06"},"cell_type":"markdown","source":"We then have to determine a threshold value, below which we classify the value as an outlier. This threshold value is a hyperparameter and can be tuned using a standard rough grid search to give a fairly high accuracy."},{"metadata":{"trusted":true,"_uuid":"d2abcc3cbdcc7dee82554fca20cbb51aa0de283e"},"cell_type":"code","source":"tresholds = np.linspace(-1000,-10, 150)\nscores = []\nfor treshold in tresholds:\n    y_hat = (model.logpdf(valid.drop('Class', axis=1).values) < treshold).astype(int)\n    scores.append([recall_score(y_pred=y_hat, y_true=valid['Class'].values),\n                 precision_score(y_pred=y_hat, y_true=valid['Class'].values),\n                 fbeta_score(y_pred=y_hat, y_true=valid['Class'].values, beta=2)])\n\nscores = np.array(scores)\nprint(scores[:, 2].max(), scores[:, 2].argmax())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49647d44ff97aa4b1191a07b18213bd1fc42a9e5"},"cell_type":"markdown","source":"Next we must analyse the precision and recall values to determine whether the model fits the data well."},{"metadata":{"trusted":true,"_uuid":"546abe00396647ae490ffea6605d463c5fd83ec1"},"cell_type":"code","source":"plt.plot(tresholds, scores[:, 0], label='$Recall$')\nplt.plot(tresholds, scores[:, 1], label='$Precision$')\nplt.plot(tresholds, scores[:, 2], label='$F_2$')\nplt.ylabel('Score')\n# plt.xticks(np.logspace(-10, -200, 3))\nplt.xlabel('Threshold')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c69199d5e81d82b89dd493a32357e69c0da7457"},"cell_type":"code","source":"final_tresh = tresholds[scores[:, 2].argmax()]\ny_hat_test = (model.logpdf(test.drop('Class', axis=1).values) < final_tresh).astype(int)\n\nprint('Final threshold: %d' % final_tresh)\nprint('Test Recall Score: %.3f' % recall_score(y_pred=y_hat_test, y_true=test['Class'].values))\nprint('Test Precision Score: %.3f' % precision_score(y_pred=y_hat_test, y_true=test['Class'].values))\nprint('Test F2 Score: %.3f' % fbeta_score(y_pred=y_hat_test, y_true=test['Class'].values, beta=2))\n\ncnf_matrix = confusion_matrix(test['Class'].values, y_hat_test)\nplot_confusion_matrix(cnf_matrix, classes=['Normal','Anormal']\n                      , title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cb2060e56c111c5d1983812aea3acc0a7640172"},"cell_type":"markdown","source":"From the confusion matrix it is clear that this model gives fairly good predictions.\n\nWe can however improve on these by using a clustering technique based on K-means clustering called the gaussian mixture model. This is assumed that the data is produced by a finite number of gaussian distributions with unknown parameters. We once again use the normal data to fit the model before introducing anomalies which we wish to detect."},{"metadata":{"trusted":true,"_uuid":"b2784d41232cbed9dd4330370952e296141a7f13"},"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\ngmm = GaussianMixture(n_components=3, n_init=4, random_state=42)\ngmm.fit(train.drop('Class', axis=1).values)\nprint(gmm.score(valid[valid['Class'] == 0].drop('Class', axis=1).values))\nprint(gmm.score(valid[valid['Class'] == 1].drop('Class', axis=1).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"395c4a92c5711c6633bdecca033e3f94cf6799b8"},"cell_type":"code","source":"tresholds = np.linspace(-400, 0, 100)\ny_scores = gmm.score_samples(valid.drop('Class', axis=1).values)\nscores = []\nfor treshold in tresholds:\n    y_hat = (y_scores < treshold).astype(int)\n    scores.append([recall_score(y_pred=y_hat, y_true=valid['Class'].values),\n                 precision_score(y_pred=y_hat, y_true=valid['Class'].values),\n                 fbeta_score(y_pred=y_hat, y_true=valid['Class'].values, beta=2)])\n\nscores = np.array(scores)\nprint(scores[:, 2].max(), scores[:, 2].argmax())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ed3fa0a995f430c7517d1613ff3004c3459fd1a"},"cell_type":"code","source":"plt.plot(tresholds, scores[:, 0], label='$Recall$')\nplt.plot(tresholds, scores[:, 1], label='$Precision$')\nplt.plot(tresholds, scores[:, 2], label='$F_2$')\nplt.ylabel('Score')\nplt.xlabel('Threshold')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5901501d309af09ae76833cb8ca457715c1f12f7"},"cell_type":"code","source":"final_tresh = tresholds[scores[:, 2].argmax()]\ny_hat_test = (gmm.score_samples(test.drop('Class', axis=1).values) < final_tresh).astype(int)\n\nprint('Final threshold: %f' % final_tresh)\nprint('Test Recall Score: %.3f' % recall_score(y_pred=y_hat_test, y_true=test['Class'].values))\nprint('Test Precision Score: %.3f' % precision_score(y_pred=y_hat_test, y_true=test['Class'].values))\nprint('Test F2 Score: %.3f' % fbeta_score(y_pred=y_hat_test, y_true=test['Class'].values, beta=2))\n\ncnf_matrix = confusion_matrix(test['Class'].values, y_hat_test)\nplot_confusion_matrix(cnf_matrix, classes=['Normal','Anormal'], title='Confusion matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae714329afe737589ce942e40acee567cd1878f2"},"cell_type":"markdown","source":"<h1> Ethical Considerations </h1>\n\nIt is clear that fraud detection is something which greatly benifits everyone, however in producing these models it encourages fraudsters to become smarter, trying to blend their transactions into the 'regular' transactions, making it ever more difficult to detect and also more difficult to prove. It might be better to try and build a 'profile' based on individual card holders transactions then looking for anomalous data from this. \n\nWe must also be careful that a cardholders transactions are not cancelled when they are legitimate, so false positives are definitely not acceptable in these circumstances as it could leave someone unable to use their card in an emergency for example."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}