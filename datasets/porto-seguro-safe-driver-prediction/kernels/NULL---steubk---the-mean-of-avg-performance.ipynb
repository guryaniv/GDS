{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"source": ["A naive simulation of how  size of test set can affect the models average performance.\n", "\n", "I stole the starting idea from the amazing kernel [Is Your Small Gini Significant?](https://www.kaggle.com/vpaslay/is-your-small-gini-significant) of [Victor Paslay](Victor Paslay)\n", "\n", "It seems that the bigger is the test set the more the average of models over perform single models\n", "As usual any criticism, suggestions and hints are very welcomed. \n", "\n", "\n", "\n", "\n"], "cell_type": "markdown", "metadata": {}}, {"source": ["import numpy as np\n", "from sklearn.metrics import roc_auc_score\n", "\n", "class Sim:\n", "    def __init__(self, length, seed, name):\n", "        self.name = name\n", "        self.LENGTH = length\n", "        self.PRIV_PUB_CUT = int(self.LENGTH * 0.3)\n", "        np.random.seed(seed)\n", "        self.PERFECT_SUB = np.random.rand(self.LENGTH)\n", "        #Assumption\n", "        #Imbalance of positive and negative classes in the test set is the same as in the training set\n", "        #see https://www.kaggle.com/vpaslay/is-your-small-gini-significant\n", "        self.TARGET = (self.PERFECT_SUB > 0.963552).astype(dtype=int)\n", "\n", "    def gini(self,y_target, y_score):\n", "        return 2 * roc_auc_score(y_target, y_score) - 1\n", "\n", "    def gini_private(self,y_score):\n", "        return self.gini(self.TARGET[self.PRIV_PUB_CUT:], y_score[self.PRIV_PUB_CUT:])\n", "\n", "    def gini_public(self, y_score):\n", "        return self.gini(self.TARGET[:self.PRIV_PUB_CUT], y_score[:self.PRIV_PUB_CUT])\n", "\n", "    def evaluate_sub(self,sub):\n", "        return self.gini (self.TARGET, sub ), self.gini_public ( sub ), self.gini_private ( sub )\n", "\n", "\n", "    def evaluate_subs (self, subs):\n", "        samples= subs.shape[1] \n", "        results = np.zeros((samples,3))\n", "\n", "        for i in range ( samples ):\n", "            sub = subs[:,i]\n", "            results[ i, : ] = np.array( self.evaluate_sub(sub) )     \n", "\n", "        return results\n", "\n", "    def create_random_sub (self, naive_target):\n", "\n", "        random_sub =  np.random.rand(self.LENGTH) \n", "        _t = ( np.random.rand(self.LENGTH) >  naive_target ).astype(dtype=int)\n", "\n", "\n", "        return self.PERFECT_SUB + _t*(random_sub-self.PERFECT_SUB)\n", "\n", "\n", "    def create_semi_random_subs (self, naive_target, noise=0.02, samples=5):\n", "        #the naive assumption\n", "        _t = ( np.random.rand(self.LENGTH) >  naive_target   ).astype(dtype=int)\n", "\n", "        subs = np.zeros((self.LENGTH,samples))\n", "\n", "        for i in range (samples):\n", "\n", "            _n = np.maximum(_t,( np.random.rand(self.LENGTH) > 1.0 - noise ).astype(dtype=int))\n", "\n", "            random_sub =  np.random.rand(self.LENGTH) \n", "\n", "\n", "            random_sub = self.PERFECT_SUB + _n*(random_sub - self.PERFECT_SUB)\n", "\n", "            subs [:, i] =  random_sub\n", "\n", "        return subs\n", "\n", "    \n", "TESTSET_LENGTH = 595212\n", "    \n", "sim_testset = Sim(TESTSET_LENGTH, seed=2017, name= \"Testset\")\n", "sim_half_testset = Sim(int(TESTSET_LENGTH/2), seed=2017, name = \"Half a testset\")\n", "sim_doubled_testset = Sim(2*TESTSET_LENGTH, seed=2017, name=\"Doubled testset\")\n", "\n", "simulations = [ sim_half_testset,sim_testset, sim_doubled_testset]\n", "\n", "for sim in simulations:\n", "    \n", "    print(sim.name)\n", "    print(\"\\tgini for perfect score: {:f}\".format(sim.gini ( sim.TARGET, sim.PERFECT_SUB)) )\n", "\n", "    m = sim.evaluate_sub (sim.create_random_sub(0.28))\n", "    print(\"\\trandom sub\")\n", "    print(\"\\tgini : {:f} {:f} {:f}\".format ( m[0], m[1], m[2] ))\n", "\n", "    print(\"\\t10 semi random subs\")\n", "\n", "    subs = sim.create_semi_random_subs (0.284,  noise=0.05, samples=10)\n", "    avg_subs = np.mean(subs,axis=1)\n", "\n", "    m = sim.evaluate_sub (avg_subs)\n", "    print(\"\\tavg gini: {:f} {:f} {:f}\".format ( m[0], m[1], m[2] ))\n", "    mean=np.mean(sim.evaluate_subs(subs),axis=1)\n", "    print (\"\\t    gini: {:f} {:f} {:f}\".format( mean[0], mean[1], mean[2]))\n"], "cell_type": "code", "metadata": {"_uuid": "7ec813c52c64408e40a85caf08ebc0650944ae79", "_cell_guid": "89443289-b883-4d9c-81bc-f03e745bc384"}, "execution_count": null, "outputs": []}, {"source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline  \n", "\n", "\n", "l=100\n", "naive_target=0.28\n", "noise=0.01\n", "samples=5\n", "\n", "\n", "for sim in simulations:\n", "    \n", "\n", "    avg_sub_res = np.zeros((l,3))\n", "    single_sub_res = np.zeros((l*samples,3))\n", "    avg_subs = np.zeros((sim.LENGTH,l))\n", "\n", "    for i in range(l):\n", "        semi_random_subs = sim.create_semi_random_subs (naive_target, noise=noise, samples=samples)\n", "\n", "        for j in range(samples):\n", "            single_sub_res[5*i+j,:] = sim.evaluate_sub (semi_random_subs[:,j])\n", "\n", "        avg_subs [:, i] = np.mean(semi_random_subs,axis=1)\n", "        avg_sub_res [i,:] = sim.evaluate_sub (avg_subs[:,i])\n", "\n", "\n", "    plt.figure(figsize=(5,5))\n", "    plt.title(sim.name)\n", "\n", "\n", "    plt.scatter(single_sub_res[:,1], single_sub_res[:,2], marker='o', color='r',alpha=0.7,label='single sub')\n", "    plt.scatter(avg_sub_res[:,1], avg_sub_res[:,2], marker='x', color='b',alpha=0.7,label='5 subs avg')\n", "\n", "\n", "    plt.ylabel('Private LB')\n", "    plt.xlabel('Public LB')\n", "    plt.legend(loc='lower right')\n", "    plt.show()\n", "\n", "    print(\"single sub mean\")\n", "    print (np.mean(single_sub_res))\n", "\n", "    print(\"5 subs mean\")\n", "    print (np.mean(avg_sub_res))\n"], "cell_type": "code", "metadata": {}, "execution_count": null, "outputs": []}, {"source": [], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "outputs": []}], "nbformat": 4}