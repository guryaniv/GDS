{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import tensorflow as tf #use tensorflow\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "1b8db514-170d-4aa1-88f9-a66c9de1011e", "scrolled": true, "_uuid": "d5997bb1413dca3486ecac698efb5e4de5753c85"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["input=pd.read_csv(\"../input/creditcard.csv\")\n", "print (input[:2])"], "metadata": {"_cell_guid": "548802e8-e887-4cfe-98d5-3bd4de47b887", "_uuid": "0605f97c9f4859492226661ffa6e29af41b572cf"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["columnKeys=input.columns.tolist()\n", "thingsAsData=columnKeys[1:-1]"], "metadata": {"_cell_guid": "54ed3671-6d6a-4972-9aac-40d64b4d53b7", "collapsed": true, "_uuid": "470a58768169aa909ad142fc6b987850da81f045"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["idea:<br>\n", "1lrelu better training  <br>\n", "2 max pooling at last  <br>\n", "3shrink amount of variables to make it faster <br>\n", "4"], "metadata": {"_cell_guid": "b7da524c-ef93-4209-a8a6-8809653f87a4", "_uuid": "f400379052d4eec3b9d5a8400486ed336811c778"}, "cell_type": "markdown"}, {"source": ["data=input[thingsAsData].as_matrix().astype(np.float32)\n", "label=pd.DataFrame({\"zero\":input[\"Class\"]==0,\"one\":input[\"Class\"]==1}).astype(np.float32)\n", "print (label)"], "metadata": {"_cell_guid": "4fa7b041-f391-451c-9e8f-9c8347a53de2", "_uuid": "760b1ad918f41f79b7294ee5c3700481b7a3cf1f"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["def init_weights(shape, name):\n", "    return tf.Variable(tf.random_normal(shape, stddev=0.01), name=name)"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["# This network is the same as the previous one except with an extra hidden layer + dropout\n", "def model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden):\n", "    # Add layer name scopes for better graph visualization\n", "    with tf.name_scope(\"layer1\"):\n", "        X = tf.nn.dropout(X, p_keep_input)\n", "        h = tf.nn.relu(tf.matmul(X, w_h))\n", "    with tf.name_scope(\"layer2\"):\n", "        h = tf.nn.dropout(h, p_keep_hidden)\n", "        h2 = tf.nn.relu(tf.matmul(h, w_h2))\n", "    with tf.name_scope(\"layer3\"):\n", "        h2 = tf.nn.dropout(h2, p_keep_hidden)\n", "        return tf.matmul(h2, w_o)\n"], "metadata": {"_cell_guid": "0e338cde-0fc8-429e-8ce6-43fa7429f6db", "collapsed": true, "_uuid": "03707fa6ca619784765872f84b40c20b1226f6d0"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 1 - Get Input Data\n", "testNum=len(input)//100\n", "trX, trY, teX, teY = data[:-testNum], label[:-testNum],data[-testNum:], label[-testNum:]"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 2 - Create input and output placeholders for data\n", "X = tf.placeholder(\"float\", [None, 29], name=\"X\")\n", "Y = tf.placeholder(\"float\", [None, 2], name=\"Y\")"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 3 - Initialize weights\n", "w_h = init_weights([29, 20], \"w_h\")\n", "w_h2 = init_weights([20, 10], \"w_h2\")\n", "w_o = init_weights([10, 2], \"w_o\")"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 4 - Add histogram summaries for weights\n", "tf.summary.histogram(\"w_h_summ\", w_h)\n", "tf.summary.histogram(\"w_h2_summ\", w_h2)\n", "tf.summary.histogram(\"w_o_summ\", w_o)"], "metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 5 - Add dropout to input and hidden layers\n", "p_keep_input = tf.placeholder(\"float\", name=\"p_keep_input\")\n", "p_keep_hidden = tf.placeholder(\"float\", name=\"p_keep_hidden\")"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 6 - Create Model\n", "py_x = model(X, w_h, w_h2, w_o, p_keep_input, p_keep_hidden)"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 7 Create cost function\n", "with tf.name_scope(\"cost\"):\n", "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))\n", "    train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n", "    # Add scalar summary for cost tensor\n", "    tf.summary.scalar(\"cost\", cost)\n", "\n", "#Step 8 Measure accuracy\n", "with tf.name_scope(\"accuracy\"):\n", "    correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(py_x, 1)) # Count correct predictions\n", "    acc_op = tf.reduce_mean(tf.cast(correct_pred, \"float\")) # Cast boolean to float to average\n", "    # Add scalar summary for accuracy tensor\n", "    tf.summary.scalar(\"accuracy\", acc_op)"], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Step 9 Create a session\n", "with tf.Session() as sess:\n", "    # Step 10 create a log writer. run 'tensorboard --logdir=./logs/nn_logs'\n", "    writer = tf.summary.FileWriter(\"./logs/nn_logs\", sess.graph) # for 0.8\n", "    merged = tf.summary.merge_all()\n", "\n", "    # Step 11 you need to initialize all variables\n", "    tf.initialize_all_variables().run()\n", "\n", "    #Step 12 train the  model\n", "    for i in range(100):\n", "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n", "            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end],\n", "                                          p_keep_input: 0.8, p_keep_hidden: 0.5})\n", "        summary, acc = sess.run([merged, acc_op], feed_dict={X: teX, Y: teY,\n", "                                          p_keep_input: 1.0, p_keep_hidden: 1.0})\n", "        writer.add_summary(summary, i)  # Write summary\n", "        print(i, acc)                   # Report the accuracy"], "metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": [], "metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}], "nbformat_minor": 1, "nbformat": 4}