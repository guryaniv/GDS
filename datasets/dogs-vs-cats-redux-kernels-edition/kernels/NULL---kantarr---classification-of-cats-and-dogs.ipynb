{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"cell_type":"code","source":"# Importing librariles \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Convolution2D,MaxPooling2D\nfrom keras.utils import np_utils\n%matplotlib inline\n\nimport cv2 #resizing images\nimport os \n","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"e5743176-38c4-4037-804f-ccf0f0f37a51","_uuid":"5667dc011b2110265ce4246d740f348be8a6bdf0","collapsed":true,"trusted":true},"cell_type":"code","source":"img_width = 68\nimg_height = 68\nTRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test/'","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"e0bca2c6-9e95-4c51-bacd-f2aa48f6a133","_uuid":"6950554fc68178500d06a1bc7a0f24cee2441c3b","collapsed":true,"trusted":true},"cell_type":"code","source":"# complete dataset \n#this contains both dog and cat paths \n#creating paths\ntrain_images=[]\nfor i in os.listdir(TRAIN_DIR):\n    train_images.append(TRAIN_DIR+i)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"519f56f9-4722-4d05-a52b-ae8d3510e6fe","_uuid":"6f803b8522b3e5f75ededc7d95e20ef5159e4e69","trusted":true},"cell_type":"code","source":"train_images","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"97ba3cc3-9f6c-41e3-976b-e28ce637c1de","_uuid":"c1ee28e7ada610f0b8f2a6c265ae866736b0c876","collapsed":true,"trusted":true},"cell_type":"code","source":"# trainig data set for dogs individually \ndog_train_images=[]\nfor i in os.listdir(TRAIN_DIR):\n    if 'dog' in i:\n        dog_train_images.append(TRAIN_DIR+i)\n    ","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"a24ac918-bf56-470c-8025-1ebb68977187","_uuid":"20c8803a134c74aa224e47f880ddbe7dbc350b4c","trusted":true},"cell_type":"code","source":"dog_train_images\n# all data paths will be stored in this dog_train_images ","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"096b2faf-4a2a-4753-a631-dba7ada3fe8d","_uuid":"3e95e7af120d3379173b2404124eea540a62bf5e","collapsed":true,"trusted":true},"cell_type":"code","source":"cats_train_images=[]\nfor i in os.listdir(TRAIN_DIR):\n    if 'cat' in i:\n        cats_train_images.append(TRAIN_DIR+i)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"9b8b7f00-47cf-4bbd-8381-2a7606e8e11b","_uuid":"c4499b597ea15b7d2ff18ec5273de59eb23fe437","trusted":true},"cell_type":"code","source":"cats_train_images\n#all data paths of cats will be stored in cats_train_images","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"37ba573a-e5e6-4bfc-9057-4a8fa97bc065","_uuid":"e7b27f79a9bb24a2b461362dd99a9b4995a2b12a","collapsed":true,"trusted":true},"cell_type":"code","source":"# creating paths and storing in list\ntest_images=[]\nfor i in os.listdir(TEST_DIR):\n    test_images.append(TEST_DIR+i)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"d99edefb-5bda-479d-b5f2-a6fffc20a5ae","_uuid":"9b9828775fa24b176a10ab6c69f6aa48a5da32f2","trusted":true},"cell_type":"code","source":"test_images","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"8f1ed440-0866-4c22-848a-ecaf0f876b4d","_uuid":"1e4fce2836114d22756e305fcbb84e03c70c9681","collapsed":true},"cell_type":"markdown","source":"We created list of paths for test and training data \nwe segregated dog images ana cat images \n"},{"metadata":{"_cell_guid":"0a51a358-f895-478b-a2b8-abfd2d22db90","_uuid":"22702abc89b4872e97908eac05b045f979c54325","collapsed":true,"trusted":true},"cell_type":"code","source":"# Insted of taking whole set of images we will take sample data pf cats and dogs, buils the model\n#taking 500 images of cats amd 500 images of dogs and we will build the model\ncat_images=cats_train_images[:500]\ndog_images=dog_train_images[:500]\n","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"53287156-8508-4c4d-837d-0a6d124cdc44","_uuid":"3fbc6d3455c9a2ee3f255ad4f3a03782dda6afd7","trusted":true},"cell_type":"code","source":"Number_of_cat_images=np.array(cat_images).shape\nNumber_of_dog_images=np.array(dog_images).shape\nprint(Number_of_cat_images)\nprint(Number_of_dog_images)","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"864f307a-8265-4156-9cb3-1bebd24767c1","_uuid":"743daf1cdf3ed2803e29ad10c4b411d1aeaa6846","collapsed":true,"trusted":true},"cell_type":"code","source":"train_image= cat_images+dog_images","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"56897e17-0e49-4913-8a1b-ffc44b10399c","_uuid":"1da98e68b222facaa4c7e96cf49b505fc0079d12","trusted":true},"cell_type":"code","source":"np.array(train_image).shape","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"b2a592fc-b12e-4df9-9e13-61251680a889","_uuid":"176e47ae8e91450fdd8a92698393c7c76c20a646","collapsed":true,"trusted":true},"cell_type":"code","source":"test_image=test_images[:50]","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"6c0c2138-355f-445c-affb-def8f066a68b","_uuid":"aa0f2a40f6d5ab842c525e5f9787819a643074ec"},"cell_type":"markdown","source":"**We have train images of 1000,where 500 are dogs and 500 are cats/.... and 50 images are for test**"},{"metadata":{"_cell_guid":"4716a87b-a0ae-49ce-8c41-fb9cd0f3f8f8","_uuid":"b395b0f6f98045eff83cb206d7e1fb430634b405","collapsed":true,"trusted":true},"cell_type":"code","source":"# Now we have paths ... we should convert them to matrices by using cv2 lib and convert image to grey scale\n# small example of enumerate \n#this is not related to this project \n#I just wanna show how enuerate works\nlis=['a','b','c']\n\nfor i,j in enumerate(lis):\n    print(i,j)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"017377d6-c83f-495f-9c5d-e8f7859ef530","_uuid":"579f104ee981cffa09a4116bc64e4477b130fa54","collapsed":true,"trusted":true},"cell_type":"code","source":"def prepare_data(list_of_images):\n    \"\"\"\n    Returns two arrays: \n        x is an array of resized images\n        y is an array of labels\n    \"\"\"\n    x = [] # images as arrays\n    y = [] # labels\n    \n    for image in list_of_images:\n        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))\n    \n    for i in list_of_images:\n        if 'dog' in i:\n            y.append(1)\n        elif 'cat' in i:\n            y.append(0)\n        #else:\n            #print('neither cat nor dog name present in images')\n            \n    return x, y","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"99df5009-6a17-46cd-85ca-612671303e6f","_uuid":"da5737eb693adfa6eef8f6e37205dc2a4cb55b3f","collapsed":true,"trusted":true},"cell_type":"code","source":"X, Y = prepare_data(train_images)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"b6c731e5-4d9c-46d2-8dc3-1e21e3cbc3aa","_uuid":"0743f9e098bb7547bb6c955885af5096b21d7e4b","trusted":true},"cell_type":"code","source":"np.array(X).shape","execution_count":37,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"f2da5a31e4cafbee4d6fda5c220e1332bfb28003"},"cell_type":"code","source":"X1=np.array(X)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df4f0cfef5835010a648013f51769e53d9a3fa1b"},"cell_type":"code","source":"X1.shape","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a11b513a27dd7baba8fc5682364c7f1eee68d6c"},"cell_type":"code","source":"X1=X1.reshape(25000,4624)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd0d79302f893f951d98990e8fcb489ff1af1ac"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\n# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 128, activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","execution_count":39,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c8f1a3913fecf6bc93bdeb342fefb8059feecc0"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nval_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n","execution_count":47,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4adb67166882bf5d23a298b2232d2c95022cd39"},"cell_type":"code","source":"train_datagen.flow((X1),Y,batch_size=32)","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4494fac13d0a4116b0d48e1c2ba822d289e7898f"},"cell_type":"code","source":"classifier.fit_generator(train_generator,epochs=30)","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"2ca4a50d-397a-4900-a563-257e7997e94c","_uuid":"8addedef578a916c969998de58338e91d0e65e2e","trusted":true},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=0.2, random_state=1)","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"c7939bff-4877-416c-91e4-bd271651ab3d","_uuid":"2c634c1e68686d2722c5707242f44c809247e279","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b4f43886-ae3a-493f-a6a5-8d9964e467b5","_uuid":"47462f488e45431d97e687f4218d15620011cdd8","collapsed":true,"trusted":true},"cell_type":"code","source":"X, Y = prepare_data(train_images_dogs_cats)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4ec1c280-2bd6-4f08-b487-377a8a372620","_uuid":"8f2a5c07f44e6365e8278347747c40d865d10ccd"},"cell_type":"markdown","source":"If we observe above loop i is assined as index and j is assigined to lis array"},{"metadata":{"_cell_guid":"e9db054b-7f77-4998-8d9a-d53947259ed0","_uuid":"ad4b629f418f045d1f87d6baf2940f2458cfbe8d","collapsed":true,"trusted":true},"cell_type":"code","source":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    return cv2.resize(img, (64, 64), interpolation=cv2.INTER_CUBIC)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a30c307b-37c8-4298-aeae-3fd5c9c9adf9","_uuid":"f0e4f2f5120725378aa9806c4602ed2aa102c1ee","collapsed":true,"trusted":true},"cell_type":"code","source":"def prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, 64, 64,3), dtype=np.uint8)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        return data\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5da4129b-f38e-4866-9c14-cc3cdc629163","_uuid":"b9a300d9821f10740966ed80596937d0f64ce489","collapsed":true,"trusted":true},"cell_type":"code","source":"train = prep_data(train_images)\ntest = prep_data(test_images)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ba4b081-83dc-490c-9d83-a40ec251a1c8","_uuid":"70b713b919a0533dd56fb71a91f1819b08d92b89","collapsed":true,"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b2997c5-fde2-4b95-b372-549068749083","_uuid":"289dc4cb28fb4d13b7a6087285e105ec89c68719","collapsed":true,"trusted":true},"cell_type":"code","source":"labels = []\nfor i in train_images:\n    if 'dog' in i:\n        labels.append(1)\n    else:\n        labels.append(0)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"80c46681-8cf8-4e3a-b45d-1aa62d3095cb","_uuid":"cb9ee942d0019c1118ae9e11aaa3a54ed7d4ed0a","collapsed":true,"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2c69943c-ec51-4d6f-bfa1-1d6721d4b06e","_uuid":"d62c362c0e1dc81a2c38e2b72a9e42fd81be24c7","collapsed":true,"trusted":true},"cell_type":"code","source":"# Importing the Keras libraries and packages\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\n# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 128, activation = 'relu'))\nclassifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5ac65747-8b62-4a23-9c3d-194972768280","_uuid":"5836f473f91ca71726f7f29d91947d61795f4052","collapsed":true,"trusted":true},"cell_type":"code","source":"classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"67c03339-7699-4983-b20a-4ade6db0f1b1","_uuid":"562c488518909c15d063164ab2b1c89fe84ebe05","collapsed":true,"trusted":true},"cell_type":"code","source":"classifier.fit(train, labels, batch_size=16, epochs=10,\n              validation_split=0.25, verbose=0, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0908f21f-38f1-49a4-8d79-29507efb1944","_uuid":"019406af618dd13c79136d188dba4b2a0d5a0486","collapsed":true,"trusted":true},"cell_type":"code","source":"mod = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08bf1ac4-0bb7-449e-ac30-d0d0e1e1f37a","_uuid":"972b1eb8400c7d8eaa96b11405cf60e7afd39813","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"02647b5b-8387-4068-9cf4-1a563b82e447","_uuid":"fd05d0f7fef1df680f5816a9b55b21d4d7211446","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1a7aabb0-f95c-4853-97d9-0f84c781919d","_uuid":"ad4ad0bad47730bc41f2861be9363574537a137c","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"80e419d0-ffde-4d6d-8b5c-9726ed800054","_uuid":"93ae0bacacfe0cc61a74ec3125e9d9b5554ff583","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a963cdd8-fc39-47b6-b008-22f5541a7804","_uuid":"f6dfb48674f466870c53b8d928431ea3d9c2277f","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}