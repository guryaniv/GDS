{"cells":[{"metadata":{"_uuid":"ccb885ed3fe50c4ba2aef8516b387cffb007cdac"},"cell_type":"markdown","source":"# Costa Rican Household Poverty Level Prediction - kNN\n## Poli-USP - PMR3508 - 2018"},{"metadata":{"_uuid":"c8e5cba3e40932db727b383590509fda59205f20","trusted":true},"cell_type":"code","source":"import warnings\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Imputer\nfrom scipy.stats import pearsonr\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Ignore deprecation warnings from scikit-learn 0.20.\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"860d25a611e836d5b5ef85fbc04483f3fa5f4f04","trusted":true},"cell_type":"code","source":"train_raw = pd.read_csv('../input/train.csv',\n                        sep=r'\\s*,\\s*',\n                        engine='python')\n\ntest_raw = pd.read_csv('../input/test.csv',\n                       sep=r'\\s*,\\s*',\n                       engine='python')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c43ed7700a6fb2694352d25bff1a0f9f0167389","trusted":false},"cell_type":"code","source":"train_raw.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce0e652aa12a27bab958a520d04ca683483882f3","trusted":false},"cell_type":"code","source":"train_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"acc3f1a1017cc107574729becfa2f2cf9b8b14cc","trusted":false},"cell_type":"code","source":"train_raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"225a30f319b9692e2153361fb4b407e409225cdd"},"cell_type":"code","source":"# Columns with missing data\ncols_with_na = train_raw.columns[train_raw.isnull().any(axis=0)]\ncols_with_na","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3124bfe3a8b68aa5aa3901c9b35b6b2e849f5ccd"},"cell_type":"code","source":"# Frequency of missing values in each column\n# High for v2a1, v18q1, rez_esc\ntrain_raw[cols_with_na].isnull().sum(axis=0) / train_raw.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e35d705fa2fdd9cc15c0acde2be2cc3e6003cd8f"},"cell_type":"code","source":"# All column dtypes\nprint('Feature types:', *{train_raw[col].dtype.name for col in train_raw.columns})\n\nprint('Non-numeric features:', *train_raw.select_dtypes(exclude=[np.number]).columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"294f41ab78ccf932f64778fbe9e8c008308e34d2"},"cell_type":"code","source":"train_raw.select_dtypes(exclude=[np.number]).head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2968158e39aff130ccd887e6a77991e662f36db"},"cell_type":"markdown","source":"About the non-numeric features:\n\n- Id and idhogar are identifiers and, therefore, useless in classification.\n\n- edjefe and edjefa are education indicators. They can be turned into numerical data by applying the conversion given in the data description (in Kaggle): `yes -> 1`, `no -> 0`.\n\n- dependency is the ratio of dependent people to independent people in the household. The numerical values of yes and no are not specified.\n  Therefore, it might be easier to turn dependency into a binary feature, with the following conversion: `0, no -> 0` and `n, yes -> 1` (`n != 0`)."},{"metadata":{"trusted":true,"_uuid":"57bd57df1fc6ffc50eff61fb795ca7facfd8ed9f"},"cell_type":"code","source":"# Number of 0/1 columns (one-hot encoded)\nsum(set(train_raw[col].unique()) == {0,1} for col in train_raw.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4407ec70308f1ac8f03d2e87a7e403120482eead"},"cell_type":"code","source":"# Frequency of each target value\ntrain_raw['Target'].value_counts() / train_raw.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a50bfcfd1896d7055c72e3a3323499d712e4be49"},"cell_type":"markdown","source":"## Initial tests\n\n- Remove v2a1, v18q1, rez_esc (which have > 70% missing values).\n\n- Work only with numerical values. I.e.:\n    - Remove Id and idhogar (not useful, as seen above)\n    - Convert dependency, edjefe and edjefa into numerical data.\n\n- Two approaches to handle missing values: with `dropna` and imputation."},{"metadata":{"trusted":true,"_uuid":"546e3039af99a7d81ec3eedd8f0a28781fd63907"},"cell_type":"code","source":"def preprocess(data):\n    data = data.copy()\n    dep = data['dependency'].copy()\n    dep[dep == 'no'] = 0\n    dep[(dep != 0) & (~dep.isnull())] = 1\n    data['dependency'] = pd.to_numeric(dep)\n    \n    for col in ['edjefe', 'edjefa']:\n        edjef = data[col].copy()\n        edjef[edjef == 'yes'] = 1\n        edjef[edjef == 'no'] = 0\n        data[col] = pd.to_numeric(edjef)\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e00b3de8c25d6f48e7d940be5187d7c2b037a746"},"cell_type":"code","source":"# After preprocessing, only the Id and idhogar features are not numeric\npreprocess(train_raw).select_dtypes(exclude=[np.number]).columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dccc5c53dacbcc2ee0e74754bb72c9793245824"},"cell_type":"code","source":"train = preprocess(train_raw)\ntest = preprocess(train_raw)\nnumeric_columns = list(train.select_dtypes(include=[np.number]).columns)\ncolumns = list(set(numeric_columns) - {'v2a1', 'v18q1', 'rez_esc', 'Target'})\ntrain_initial = train.copy()[columns + ['Target']]\ntrain_initial.dropna(inplace=True)\nx = train_initial[columns]\ny = train_initial['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"832beac04a76c8e429f623d62823da43ca92902f"},"cell_type":"code","source":"# Use f1_macro scoring by default, since it's the one used in the competition\n\ndef cross_val(knn, x, y, cv, scoring='f1_macro'):\n    scores = cross_val_score(knn, x, y, cv=cv, scoring=scoring)\n    return sum(scores)/len(scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f86e9fd0ddac357c77ddd42512f0f36484852a59"},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=30, p=2)\nprint('Accuracy:', cross_val(knn, x, y, cv=5, scoring='accuracy'))\nprint('F1:', cross_val(knn, x, y, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa8028105cfb3b1807d099911b90a921e9dce766"},"cell_type":"code","source":"# Add imputation (slightly better results)\n\nx = Imputer().fit_transform(train[columns])\ny = train['Target']\n\nprint('Accuracy:', cross_val(knn, x, y, cv=5, scoring='accuracy'))\nprint('F1:', cross_val(knn, x, y, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bb4133b84ddb46fa3627b077118bcd0c9663856"},"cell_type":"markdown","source":"## Further Analysis"},{"metadata":{"trusted":true,"_uuid":"4b7eb752d7804f906f86eb9c43ebb1938031e35d"},"cell_type":"code","source":"corrs = {}\npvals = {}\nprint('Correlations and p-values between the features and the target.')\nprint(f'{\"feature\":<15}{\"corr\":>6}{\"pval\":>9}')\n\nfor col in columns:\n    # Ignore the feature elimbasu5, since it always has value 0\n    dropped = train[[col, 'Target']].dropna()\n    corrs[col], pvals[col] = pearsonr(dropped[col], dropped['Target'])\n    print(f'{col:15}{corrs[col]:6.2f}{pvals[col]:9.6f}')\nprint()\nprint('Min p-value:', min(pvals.values()))\nprint('Max abs(correlation):', max(abs(c) for c in corrs.values()));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae8c3a5ba48a65f5d0ab50141c3a6d4ae35f129e"},"cell_type":"code","source":"# The above warning suggests that a division by zero.\n# Since the correlation for elimbasu5 is nan, we now analyse that feature.\nset(train['elimbasu5'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30c4f42c60c1b1f4342b47632e9e85c59503f2ff"},"cell_type":"markdown","source":"Notice that elimbasu5 (which indicates whether trash disposal is done in the river/sea) is constant and, therefore, useless."},{"metadata":{"trusted":true,"_uuid":"0c5a615f565c4578cb9c052d132eab6fd2b16f73"},"cell_type":"code","source":"# Remove elimbasu5 from the used columns\ncolumns.remove('elimbasu5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"241ac9a42b9eac4aff55524eecf6c05ed72a9d33"},"cell_type":"code","source":"# Most of the p-values are tiny.\nnp.median(list(pvals.values()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d055eb84227feb127109d1bda95a75c733ccaf11"},"cell_type":"code","source":"plt.axhline(color='black')\nplt.plot(corrs.keys(), corrs.values())\nplt.title('pearson correlation coefficients')\nplt.show()\n\nplt.plot(pvals.keys(), pvals.values())\nplt.title('p-values')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b0f7c1d197a8f5354e73e0ca02c328e24911649"},"cell_type":"code","source":"# Columns with pval < .1 and abs(corr) > .15\nfiltered_columns = [col for col in columns\n                    if pvals[col] < .1\n                    and abs(corrs[col]) > .15]\nfiltered_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d700edae51d08d1886571580a04a685881ed53ba"},"cell_type":"code","source":"# New attempt, removing columns based on pval and corr.\n# This improves the quality of the features used, avoids the curse of dimensionality and lowers the runtime.\n# The F1 score and accuracy are higher.\n\nx = Imputer().fit_transform(train[filtered_columns])\ny = train['Target']\n\nprint('Accuracy:', cross_val(knn, x, y, cv=5, scoring='accuracy'))\nprint('F1:', cross_val(knn, x, y, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b7a56753ec42bee52855d278f5805a2bce0d781a"},"cell_type":"code","source":"# Now using p=1 (manhattan distance)\nknn.set_params(p=1)\nprint('Accuracy:', cross_val(knn, x, y, cv=5, scoring='accuracy'))\nprint('F1:', cross_val(knn, x, y, cv=5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a09644b5290c38416fc637418b52255cfe1ca08c"},"cell_type":"markdown","source":"## Hyperparameter search\n\nUse grid search to find the best values for `n_neighbors` and `p`, as well as the best p-value and correlation thresholds."},{"metadata":{"trusted":true,"_uuid":"33a3ec6d8f0908bc19626be9f2522a99f7aa1345"},"cell_type":"code","source":"# TransformerMixin provides the method fit_transform.\n# BaseEstimator provides get_params, set_params.\n\nclass CorrelationSelector(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator):\n    \"\"\"A transformer that removes columns based on pearson correlation and the frequency of each value.\n    \n    Calculates the pearson correlation and p-values between each feature and the target.\n    Removes any column with abs(correlation) < min_corr or pvalue > max_pval.\n    \"\"\"\n    def __init__(self, min_corr=0, max_pval=1):\n        self.min_corr = min_corr\n        self.max_pval = max_pval\n    \n    def fit(self, x, y):\n        x, y = sklearn.utils.check_X_y(x, y, dtype='numeric', y_numeric=True)\n        cols = []\n        for i in range(x.shape[1]):\n            # If x[:, i] has only one value, pearsonr will raise a warning.\n            # Therefore, set cols[i] to False instead of calling pearsonr.\n            if len(np.unique(x[:, i])) == 1:\n                cols.append(False)\n            else:\n                corr, pval = pearsonr(x[:, i], y)\n                cols.append(abs(corr) >= self.min_corr and pval <= self.max_pval)\n            \n        self.columns_ = cols\n        return self\n        \n    def transform(self, x):\n        sklearn.utils.validation.check_is_fitted(self, 'columns_')\n        x = sklearn.utils.check_array(x, dtype='numeric')\n        if x.shape[1] != len(self.columns_):\n            raise ValueError('x has different shape than during fitting.')\n        \n        x = x[:, self.columns_]\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d352929d417d161cc016423704c7fa43e923d939"},"cell_type":"code","source":"from sklearn.utils.estimator_checks import check_estimator\ncheck_estimator(CorrelationSelector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"654fc1dc96e9b886452dd3dc5d76e07dfa9d3119"},"cell_type":"code","source":"p = Pipeline([\n    ('imputer', Imputer()),\n    ('corr', CorrelationSelector()),\n    ('knn', KNeighborsClassifier())\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3872418535ff488594ac5f2e0174bbc0ac02e957"},"cell_type":"code","source":"p.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e318207b38345e6321aeffd4f97fa424c92d998d"},"cell_type":"code","source":"x = train[columns]\ny = train['Target']\n\nparams = {\n    'corr__max_pval': [.1],\n    'corr__min_corr': [.2],\n    'knn__n_neighbors': [10, 20, 30, 40],\n    'knn__p': [1, 2],\n}\n\n# Initially, identify the best values of p (p=1 for euclidean distance, p=2 for manhattan distance)\ngs = GridSearchCV(p, params, scoring='f1_macro', cv=3, return_train_score=True, refit=False)\ngs.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcdd0e4da487ddfd3cfb51d85d99ebde51d3698e"},"cell_type":"code","source":"for i in range(len(gs.cv_results_['params'])):\n    print('k={params[knn__n_neighbors]}  p={params[knn__p]}  score={score:.4f}'\n          .format(params=gs.cv_results_['params'][i], score=gs.cv_results_['mean_test_score'][i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd89c8d9a38f8ae0174fe8ae49b9fd89fb0917eb"},"cell_type":"markdown","source":"The manhattan distance (minkowski with p=1) seems to generate marginally better results.\nWe also see that lower values of k (`n_neighbors`) may be better."},{"metadata":{"trusted":true,"_uuid":"005f69ba8375acf8e038c2c1995057a89ffa00af"},"cell_type":"code","source":"params = {\n    'corr__max_pval': [1e-50, 1e-25, .1],\n    'corr__min_corr': [.1, .15, .2, .25, .3], # max correlation in this dataset is .335 (as seen before)\n    'knn__n_neighbors': [1, 3, 5, 7, 10, 12, 15, 25],\n    'knn__p': [1],\n}\n\n# Now look for the best params\ngs = GridSearchCV(p, params, scoring='f1_macro', cv=3, return_train_score=True, refit=False)\ngs.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1ebbd42ee07348110027433be261063cb75937d9"},"cell_type":"code","source":"# Create a dataframe in order to analyse the results\n\ndef gs_results_to_dataframe(gs):\n    scores = pd.DataFrame(gs.cv_results_['params'],\n                          columns=['knn__n_neighbors', 'corr__max_pval', 'corr__min_corr'])\n\n    scores.rename(columns={'knn__n_neighbors': 'k',\n                           'corr__max_pval': 'max_pval',\n                           'corr__min_corr': 'min_corr'}, inplace=True)\n\n    scores['score'] = gs.cv_results_['mean_test_score']\n    scores.sort_values('score', ascending=False, inplace=True)\n    return scores\n\nscores = gs_results_to_dataframe(gs)\nscores.head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8eeb96eca1ffc5d0709ecf6f14c64eae743e5f6"},"cell_type":"markdown","source":"The highest scores are found with:\n- `k`: 10, 5, 7\n- `min_corr`: .3, .15\n    \nIt is clear from the table that the value of `max_pval` does not affect the score.\n\nWe now try to narrow down on the values for those two parameters."},{"metadata":{"trusted":false,"_uuid":"582d1e73bb9746a22976b3bcc9acd5a3fd0029b0"},"cell_type":"code","source":"params = {\n    'corr__max_pval': [.1],\n    'corr__min_corr': [.14, .15, .16, .29, .30, .31],\n    'knn__n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'knn__p': [1],\n}\n\n# Now look for the best params\ngs = GridSearchCV(p, params, scoring='f1_macro', cv=10, return_train_score=True, refit=False)\ngs.fit(x, y)\ngs_results_to_dataframe(gs).head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dd6f440f53559ef8756ebbefa4c493a5afdfee9"},"cell_type":"markdown","source":"The table above shows that the best values of `k` are 3, 4, 5 and the best values of `min_corr` are .14, .15, .16.\nWe now test those values with 20-fold cross validation, before generating the files for submission."},{"metadata":{"trusted":true,"_uuid":"94dd6c67ef83b1a6d1c4c41970526863a854f52a"},"cell_type":"code","source":"params = {\n    'corr__max_pval': [.1],\n    'corr__min_corr': [.14, .15, .16],\n    'knn__n_neighbors': [3, 4, 5],\n    'knn__p': [1],\n}\n\n# Now look for the best params\ngs = GridSearchCV(p, params, scoring='f1_macro', cv=20, return_train_score=True, refit=False)\ngs.fit(x, y)\ngs_results_to_dataframe(gs).head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d9cd91c1cc0f6fd309b62d2b61d753f6256fe29"},"cell_type":"code","source":"# Features used above\nprint(columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"949256da415f348df9c1aac97e4a8bf8a30270ca"},"cell_type":"markdown","source":"## Submissions"},{"metadata":{"trusted":true,"_uuid":"b0554a6def80dd947f04c6085588e5675669ef23"},"cell_type":"code","source":"base_features = ['r4t3', 'instlevel5', 'SQBage', 'hogar_nin', 'r4t1', 'sanitario6', 'energcocinar1', 'SQBescolari', 'abastaguafuera', 'estadocivil4', 'paredfibras', 'paredzocalo', 'eviv1', 'tipovivi1', 'pisonotiene', 'instlevel3', 'hogar_mayor', 'paredblolad', 'energcocinar2', 'estadocivil1', 'lugar5', 'elimbasu6', 'eviv2', 'parentesco8', 'r4h2', 'edjefa', 'SQBhogar_nin', 'epared3', 'abastaguano', 'qmobilephone', 'elimbasu2', 'paredother', 'dis', 'etecho3', 'cielorazo', 'elimbasu1', 'estadocivil7', 'parentesco6', 'techozinc', 'abastaguadentro', 'tamhog', 'v18q', 'pisoother', 'energcocinar4', 'r4t2', 'lugar3', 'tipovivi2', 'refrig', 'instlevel9', 'rooms', 'r4h3', 'area2', 'lugar4', 'estadocivil6', 'female', 'male', 'tipovivi4', 'area1', 'instlevel6', 'parentesco7', 'r4m1', 'parentesco10', 'SQBedjefe', 'computer', 'r4h1', 'techocane', 'estadocivil5', 'instlevel8', 'etecho1', 'parentesco1', 'parentesco4', 'tipovivi3', 'sanitario3', 'age', 'public', 'planpri', 'elimbasu3', 'tamviv', 'epared1', 'etecho2', 'lugar2', 'pisonatur', 'pisomadera', 'r4m2', 'television', 'lugar6', 'hogar_total', 'parentesco5', 'estadocivil3', 'parentesco2', 'hogar_adul', 'instlevel2', 'parentesco9', 'instlevel4', 'paredpreb', 'coopele', 'sanitario5', 'energcocinar3', 'r4m3', 'dependency', 'parentesco12', 'techoentrepiso', 'mobilephone', 'instlevel7', 'SQBdependency', 'estadocivil2', 'techootro', 'meaneduc', 'bedrooms', 'parentesco3', 'instlevel1', 'sanitario2', 'noelec', 'SQBovercrowding', 'eviv3', 'hacapo', 'sanitario1', 'tipovivi5', 'SQBhogar_total', 'pisocemento', 'epared2', 'paredmad', 'hacdor', 'paredzinc', 'elimbasu4', 'overcrowding', 'pareddes', 'hhsize', 'edjefe', 'parentesco11', 'pisomoscer', 'escolari', 'SQBmeaned', 'v14a', 'agesq', 'lugar1']\n\ndef make_submission(k, p, min_corr, max_pval, out):\n    imp = Imputer()\n    train_processed = preprocess(train_raw)\n    test_processed = preprocess(test_raw)\n    \n    xtrain = train_processed[base_features]\n    ytrain = train_processed['Target']\n    xtest = test_processed[base_features]\n    \n    pipeline = Pipeline([\n        ('imputer', Imputer()),\n        ('corr', CorrelationSelector(min_corr=min_corr, max_pval=max_pval)),\n        ('knn', KNeighborsClassifier(n_neighbors=k, p=p))\n    ])\n    \n    scores_f1 = cross_val_score(pipeline, xtrain, ytrain, scoring='f1_macro', cv=20)\n    score_f1 = sum(scores_f1) / len(scores_f1)\n    scores_acc = cross_val_score(pipeline, xtrain, ytrain, scoring='accuracy', cv=20)\n    score_acc = sum(scores_acc) / len(scores_acc)\n    \n    pipeline.fit(xtrain, ytrain)\n    features = list(xtrain.columns[pipeline.get_params()['corr'].columns_])\n    ytest = pipeline.predict(xtest)\n    df = pd.DataFrame({'Id': test_processed['Id'], 'Target': ytest})\n    df.to_csv(out, index=False)\n    print(f'{out}: k={k}, p={p}, min_corr={min_corr}, max_pval={max_pval}, f1={score_f1:.6f}, acc={score_acc:.6f}')\n    print(f'    features={features}')\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a48bdcd9c9e7ce1dda25ca985c3d4783c3aab441"},"cell_type":"code","source":"make_submission(k=4, p=1, min_corr=0.16, max_pval=0.1, out='sub1.csv')\nmake_submission(k=4, p=1, min_corr=0.14, max_pval=0.1, out='sub2.csv')\nmake_submission(k=4, p=1, min_corr=0.15, max_pval=0.1, out='sub3.csv')\nmake_submission(k=3, p=1, min_corr=0.15, max_pval=0.1, out='sub4.csv')\nmake_submission(k=5, p=1, min_corr=0.15, max_pval=0.1, out='sub5.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}