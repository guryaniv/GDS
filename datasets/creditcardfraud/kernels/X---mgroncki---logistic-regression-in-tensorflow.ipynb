{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"credit_card = pd.read_csv('../input/creditcard.csv')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"8f0b146a-362a-4a96-af7c-694fa40fb63e","_uuid":"e81516a64b2983fea7c09e0cd562f0eef27caf24","collapsed":true,"trusted":true},"cell_type":"code","source":"X = credit_card.drop(columns='Class', axis=1)\ny = credit_card.Class.values","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"d66eb884-7fe7-4a08-a644-88aa965b9a27","_uuid":"b0f365b6bc854e6558fb080368766910d4a98c14","collapsed":true,"trusted":true},"cell_type":"code","source":"np.random.seed(42)\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"8045b5b7-650e-4fc9-aafd-24370ce7eb5c","_uuid":"f46cbae4db147cc30d81d78d6421b802d140485c"},"cell_type":"markdown","source":"## Logistic Regression in TensorFlow\n\nWe could use higher level API such a TensorFlow.Estimator or Keras but we want to build the logisitic regression by ourself to understand learn to program in TensorFlow.\n\n### Short TensorFlow introduction \n\nTensorFlow uses a dataflow graph to represent the computation in terms of the dependencies between individual operations. We first define the dataflow graph, then create a TensorFlow session to run it.\n\nStart with a very simple graph. Lets say we have a two dimensional vector \n$ x =(x_1,x_2) $\nand want to compute $a * x^2 = (ax_1^2, ax_2^2)$ in TensorFlow, where $a$ is a constant (e.g.5).\n\nFirst we define the input, a `tf.placeholder` object, we have to choose the type of the input (in this case it's a floating point number) and the shape of the input (in this a two dimensional vector). \n\nWe will use `tf.placeholder` to represent our input to our models (like our features and the value we try to predict). We can also use `tf.placerholder` to feed hyperparameter in our model (e.g. a learning_rate).\n\nAnother important class is the `tf.constant`, as the name indicates it represent a constant in our computational graph."},{"metadata":{"_cell_guid":"c8c9ebc7-f9b9-4837-a131-caeea4f8377d","_uuid":"683013951b7175c8651a52fd51e0ae1954088e81","collapsed":true,"trusted":true},"cell_type":"code","source":"input_x = tf.placeholder(tf.float32)\na = tf.constant(5., tf.float32, name='a', shape=(2,))","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"a02b8e1b-2f43-41b4-bb0c-16399f78924a","_uuid":"56d9aede3e51c809c3b188c60427a3a26771d858","collapsed":true,"trusted":true},"cell_type":"code","source":"y = a * tf.pow(input_x,2)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"3fa8114f-e5da-42ea-8448-713c52f4759d","_uuid":"98205774cfb40ae86baf6466f796f40a7c6e6f8c"},"cell_type":"markdown","source":"We can run the graph within a TensorFlow Session.\nWe need to start a new session and can then execute the operator with  the ´run()´ method of the session. We have to feed our input as a dictionary into the graph. Lets say $x=(1,2)$"},{"metadata":{"_cell_guid":"e4d2be23-4d0f-44dd-9241-a62e78387103","_uuid":"84315e9597fced012667131707366cfc76b00a2d","trusted":true},"cell_type":"code","source":"with tf.Session() as sess:\n    result = sess.run(y, {input_x: np.array([1,2])})\n    print(result)","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"c6abf39c-d9f9-4e01-9551-9d3d88c56567","_uuid":"7f6801a2390afae050df4f0fdeb20b6592b05563"},"cell_type":"markdown","source":"Most machine learning and deep learning problems are at the end minimization problems of a given loss function or maximization of a reward function in the case of reinforced learning. A bread-and-butter method to solve these kind of problems are gradient descent (ascent) methods. \nThe power of TensorFlow is the automatic differenation of our computational graph. We can get the anayltical derviates (or gradients) for almost 'free'. We dont need to derive the formula for the gradient by ourself and implement it.\n\nThe gradient $\\nabla f(x)$ is the multidimensional generalization of the derivate of a function. Its the vector of the partial derivates of the function and points into the direction with the strongest increase. So if we have have real valued function $f(x)$ with $x$ an n-dimensional vector then $f$ is decreasing the fastest when we go from point $x$ into the direction of the negative gradient. \n\nTo get the gradient we use the `tf.gradient`class. Lets say we want to derive y with respect to our input x. The function call looks like that:"},{"metadata":{"_cell_guid":"72ab7a38-2922-4fbd-bb42-5151c2a3fca9","_uuid":"5d8f40c51837dfc66ab94397ac9975fdee3c959c","trusted":true},"cell_type":"code","source":"# Explain Gradient and automatic differentiation\ng = tf.gradients(y, [input_x])\ngrad_y_x = 0\nwith tf.Session() as sess:\n    grad_y_x = sess.run(g,{input_x: np.array([1,2])})\n    print(grad_y_x)\n","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"e7ba75b5-fa67-4afb-bfe0-202fed2b229d","_uuid":"845a2fa997a9d82cec0f682297deb976fc7abfbf"},"cell_type":"markdown","source":"Lets see an simple example for the chain rule. We come later back to the chain rule when we talk about back propagation in deep learning (in the coming part iii). But lets recap the chain rule, which we all learned at high school:\n\n$$\\frac{d}{dx}f(g(x)) = f'(g(x))g'(x)$$\n\nIn our example we reuse our function y and define a new function z=log(y).\n\nThe 'inner' partial derivate of $g$ with respect to $x_i$ is  $\\frac{\\partial y}{\\partial x_i} = 10x_i $ and the outer one with respect to $y$ is $\\frac{\\partial z}{\\partial y_i} =\\frac{1}{5x_i^2} $. The partial derivate is $\\frac{2x_i }{x_i^2}$.\n\nWith TensorFlow, we can calulate the outer and inner derivate seperatly or in one step.\nIn example we will calculate two gradients one with respect to $y$ and one with respect to $x$. Multiplying elementwise the gradient with respect to $y$ with the gradient from above (inner derivative) yield to the gradient with respect to $x$.\n"},{"metadata":{"_cell_guid":"9b750fba-21ec-466e-be05-03e2f015374f","_uuid":"0c33805554e7dfd3ff11d372cf055fada34565b7","trusted":true},"cell_type":"code","source":"z = tf.log(y)\nwith tf.Session() as sess:\n    result_z = sess.run(z,  {input_x: np.array([1,2])})\n    print('z =', result_z)\n    delta_z = tf.gradients(z, [y, input_x])\n    grad_z_y, grad_z_x = sess.run(delta_z,  {input_x: np.array([1,2])})\n    print('Gradient with respect to y', grad_z_y)\n    print('Gradient with respect to x', grad_z_x)\n    print('Manual chain rule', grad_z_y * grad_y_x)","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"78828a2a-ab7e-4aa3-a24f-f02dfab340c2","_uuid":"1aa41fc42860411e437d3f1a2617a2bd0588d921","collapsed":true},"cell_type":"markdown","source":"As mentioned before the gradient comes very handy if we need to minimize a loss function with a gradient descent method.\n\nSo if we want to minimize the function \n$f$ (e.g.  root mean squared error, negative likelihood, ...) then we can apply an iterative algorithm\n\n$$x_n = x_{n-1} - \\gamma  \\nabla f(x_{n-1}),$$\n\nwith a starting point $x_0$. These kind of methods are called gradient descent methods.\n\nIts like hiking down a hill, we walk step by step into the direction of the steepest descent and finally we reach the valley, but sometimes it can happen that we reach a plateau  and and excactly that can happen with gradient descent as well, we can stuck into local minima.\n\nUnder particular circumstances we can be sure that we reach the global minimum but in general this is not true. To aviod stucking in local minima there are plenty extensions to the plain vanilla gradient descent (e.g. simulated annealing, etc).  In Machine Learning literature the dradient descent  method is often called Batch Gradient method, because you will use all data points to calculate the gradients. \n\nWe will usually multiply the gradient with a factor before we subtract it from our previous value. This parameter is the learning rate. If the learning rate is too large, we will make large steps into the direction but it can happen that we step over the minimum and miss it. If the learning rate is too small the algorithm takes longer to converge. There are extensions which adapt the learning rate to the parameters (e.g ADAM, RMSProp or AdaGrad) to achive faster and better convergence (see for example http://ruder.io/optimizing-gradient-descent/index.html).\n\nLets see how to use it on a linear regression problem. We generate 1000 random observations $y = 2 x_1 + 3x_2 * \\epsilon$, with $\\epsilon$ normal distributed with mean zero and standard deviation of 0.2.\n"},{"metadata":{"_cell_guid":"ad532d22-451c-4e1a-8d64-ba3970afe33a","_uuid":"873113c5d0756cedae119d374d35533bdfeff0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"#Generate data\nnp.random.seed(42)\neps = 0.2 * np.random.randn(1000)\nx = np.random.randn(2,1000)\ny = 2 * x[0,:] + 3 * x[1,:] + eps","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"996d2365-5439-4103-9bfb-16b716bcf291","_uuid":"7580291f51e4c15c1c6af85170d8b4370d3f4ac0"},"cell_type":"markdown","source":"We use a simple linear model to predict y.  Our model is $$\\hat{y_i} = w_1 x_{i,1} + w_2 x_{i,2}$$ for an observation $x_i$ and we want to minimize the mean squared error of our predictions $$\\frac{1}{100}  \\sum (y_i-\\hat(y_i))^2.$$\n\nClearly we could use the well known least square estimators for the weights, but we want to minimize the error with a gradient descent method in TensorFlow. \n\nWe use the `tf.Variable`class to store the parameters $w$ we want to learn (estimate) from the data. We specify the shape of the tensor, through the intial values.  The inital values are the starting point of our minimization. Since we have a linear model, we can represent our model with an single matrix multiplication of our observation matrix (row obs, columns features) with our weight (parameter) matrix w.\n\n"},{"metadata":{"_cell_guid":"5b2e6a74-d998-4c7c-9a43-c96039ef06c6","_uuid":"c5f7882fc202be77e67ffa3057add9b0087b1eb0","collapsed":true,"trusted":true},"cell_type":"code","source":"# Setup the computational graph with loss function\ninput_x = tf.placeholder(tf.float32, shape=(2,None))\ny_true = tf.placeholder(tf.float32, shape=(None,))\nw = tf.Variable(initial_value=np.ones((1,2)), dtype=tf.float32)\ny_hat = tf.matmul(w, input_x)\nloss = tf.reduce_mean(tf.square(y_hat - y_true))","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"2c673a46-cd45-496a-8e73-ef2166d36b2f","_uuid":"f56b302a845aa3dc89d3ccf680f1af560abca1ae"},"cell_type":"markdown","source":"In the next step we are going to apply our batch gradient descent algorithm. We define gradient of the loss with respect to our weights $w$  `grad_loss_w`. We also need to initialize our weights with the inital value (starting point our optimization). TensorFlow has a operator for this `tf.global_variables_initializer()`. In our seesion we have to run this operator first. And then we can apply our algorithm.\n\nWe calculate the gradient and apply it to our weights with the function  `assign()`. "},{"metadata":{"_cell_guid":"170b1423-54d6-4f11-bf1b-ce3c4e090319","_uuid":"2802b24eee65b886b80478e97fffc48e03523807","trusted":true},"cell_type":"code","source":"grad_loss_w = tf.gradients(loss, [w])\ninit = tf.global_variables_initializer()\nlosses = np.zeros(20)\nwith tf.Session() as sess:\n    # Initialize the variables\n    sess.run(init)\n    # Gradient descent\n    for i in range(0,20):\n        # Calculate gradient\n        dloss_dw = sess.run(grad_loss_w, {input_x:x,\n                                          y_true:y})\n        # Apply gradient to weights with learning rate\n        sess.run(w.assign(w - 0.1 * dloss_dw[0]))\n        # Output the loss\n        losses[i] =  sess.run(loss, {input_x:x,\n                                     y_true:y})\n        print(i+1, 'th Step, current loss: ', losses[i])\n    print('Found minimum', sess.run(w))\nplt.plot(range(20), losses)\nplt.title('Loss')\nplt.xlabel('Iteration')\n_ = plt.ylabel('RMSE')","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"9d67392f-497c-4e83-b332-d9ff7d97f08a","_uuid":"5a6e7656ef20bbb4cf2c45a01d64d4adaa4c1515","collapsed":true},"cell_type":"markdown","source":"Luckily we don't need to program everytime the same method by ourself. TensorFlow provide a lot of variation of gradient descent algorithm, e.g. \n`tf.GradientDescentOptimizer`, which automaticly computes the gradient and apply it to the weights.  In the case of the `GradientDescentOptimizer`we only need to specify the learning rate and with tell the optimizer which loss function we want to minimize. We use the method `minimize` which returns our training or optimization operator. In our loop we just need to run the operator."},{"metadata":{"_cell_guid":"23488a4e-4d2b-4431-8c91-adebfe056758","_uuid":"9f6cbda094745f973eaa84a488f96d91418be1d2","trusted":true},"cell_type":"code","source":"optimizer = tf.train.GradientDescentOptimizer(0.1)\ntrain = optimizer.minimize(loss)\ninit = tf.global_variables_initializer()\nlosses = np.zeros(20)\nwith tf.Session() as sess:\n    # Initialize the variables\n    sess.run(init)\n    # Gradient descent\n    for i in range(0,20):\n        _, losses[i] =  sess.run([train, loss], {input_x:x,\n                                     y_true:y})\n    print('Found minimum', sess.run(w))\nplt.plot(range(20), losses)\nplt.title('Loss')\nplt.xlabel('Iteration')\n_ = plt.ylabel('RMSE')","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"0cccca52-090a-4684-a068-fd3a25c156c5","_uuid":"2ba42cb3a0fd3ca3297c22a406d35d54c3d85a44","collapsed":true},"cell_type":"markdown","source":"One extension to batch gradient descent is the stochastic gradient descent. Instead of calculate the gradient for all observation we just randomly pick one observation (without replacement) an evaluate the gradient for this point. We repeat this until we used all data points, we call this an epoch. We repeat that process for several epochs.\n\nAnother variant use more than one random data point per gradient. Its the so called mini-batch gradient. Please feel free to play with the batch_size and the learning rate to see the effect of the optimization."},{"metadata":{"_cell_guid":"8418ed34-56a3-436a-bf3d-cbddc7bb149e","_uuid":"94250b7b8821da34736a6bf574f7295bfb0b6eec","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"np.random.seed(42)\noptimizer = tf.train.GradientDescentOptimizer(0.1)\ntrain = optimizer.minimize(loss)\ninit = tf.global_variables_initializer()\nn_epochs = 10\nbatch_size = 25\nlosses = np.zeros(n_epochs)\nwith tf.Session() as sess:\n    # Initialize the variables\n    sess.run(init)\n    # Gradient descent\n    indices = np.arange(x.shape[1])\n    for epoch in range(0,n_epochs):\n        np.random.shuffle(indices)\n        for i in range(int(np.ceil(x.shape[1]/batch_size))):\n            idx = indices[i*batch_size:(i+1)*batch_size]\n            x_i = x[:,idx]\n            x_i = x_i.reshape(2,batch_size)\n            y_i = y[idx]\n            sess.run(train, {input_x: x_i, \n                             y_true:y_i})\n        \n        if epoch%1==0: \n            loss_i = sess.run(loss, {input_x: x, \n                             y_true:y})\n            print(epoch, 'th Epoch Loss: ', loss_i)\n        loss_i = sess.run(loss, {input_x: x, \n                             y_true:y})\n        losses[epoch]=loss_i\n    print('Found minimum', sess.run(w))\nplt.plot(range(n_epochs), losses)\nplt.title('Loss')\nplt.xlabel('Iteration')\n_ = plt.ylabel('RMSE')","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"b45c744b-b029-45d2-ba7f-a95443f7670d","_uuid":"3975743d7015bea464894b6f0c0af75d2076a3ed","collapsed":true,"trusted":true},"cell_type":"markdown","source":"Now we have all tools to build our Logistic Regression model in TensorFlow. \nIts quite similar to our previous toy example, actually logisitc regression is a generalized linear model with with the logit as a link function. "},{"metadata":{"trusted":true,"_uuid":"1d51ca13239fd54c394be662992c525f5cc21588"},"cell_type":"code","source":"# Setup the computational graph with loss function\ninput_x = tf.placeholder(tf.float32, shape=(None, 30))\ny_true = tf.placeholder(tf.float32, shape=(None,1))\nw = tf.Variable(initial_value=tf.random_normal((30,1), 0, 0.1, seed=42), dtype=tf.float32)\nlogit = tf.matmul(input_x, w)\nloss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=logit))\ny_prob = tf.sigmoid(logit)","execution_count":104,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"226acbd31c3a32148c9fe5325e51316365629b8d"},"cell_type":"code","source":"optimizer = tf.train.GradientDescentOptimizer(0.5)\ntrain = optimizer.minimize(loss)\ninit = tf.global_variables_initializer()\nn_epochs = 100\nloglikelihoods = np.zeros(n_epochs)\naucs = np.zeros(n_epochs)\nwith tf.Session() as sess:\n    # Initialize the variables\n    sess.run(init)\n    # Gradient descent\n    for i in range(0,n_epochs):\n        _, llkl, y_hat =  sess.run([train, loss, y_prob], {input_x: X_train,\n                                                           y_true: y_train.reshape(y_train.shape[0],1)})\n        loglikelihoods[i] = llkl\n        aucs[i] = roc_auc_score(y_train, y_hat)\n        if i%10==0:\n            print('%i th Epoch Train AUC: %.4f LogLklh: %.4f' % (i, aucs[i], loglikelihoods[i]))\n    \n    # Calculate test auc\n    y_test_hat =  sess.run(y_prob, {input_x: X_test,\n                                             y_true: y_test.reshape(y_test.shape[0],1)})\n    weights = sess.run(w)\nplt.figure(figsize=(11,6))\nplt.subplot(2,1,1)\nplt.plot(range(n_epochs), loglikelihoods)\nplt.title('Loss')\nplt.xlabel('Iteration')\nplt.ylabel('LogLikelihood')\nplt.subplot(2,1,2)\nplt.plot(range(n_epochs), aucs)\nplt.title('AUC')\nplt.xlabel('Epoch')\nplt.ylabel('AUC Score')\nplt.tight_layout()","execution_count":105,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce762ae1c32234df01fdb92d6b947ffa36dc3430"},"cell_type":"code","source":"roc_auc_score(y_test, y_test_hat)","execution_count":106,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a9d48ddd1d0d11c0154db3f20f714a068a40450"},"cell_type":"code","source":"def get_color(c):\n    if -0.01 < c and c < 0.0075:\n        return 'orange'\n    elif c>=0.0075:\n        return 'green'\n    else:\n        return 'red'\n\nplt.figure(figsize=(10,8))\ncolors = [get_color(c) for c in np.sort(weights[:,0])]\nplt.bar(np.arange(30), np.sort(weights[:,0]),  width=0.3, color=colors)\nfeature_names = X.columns[np.argsort(weights[:,0])]\nplt.title('Feature influence')\nplt.ylabel('weight')\n_ = plt.xticks(np.arange(30), feature_names, rotation=60, ha='right')","execution_count":110,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7e4d2f607526e43b2c96204eb753f24ee85941ed"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}