{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_uuid": "abb76776e8c07e5bd785723c2cb7adf4531fbf59", "_cell_guid": "44455dc4-15b8-4d95-a3cd-5eeb631115bf"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "execution_count": 1}, {"metadata": {"_uuid": "ab5acc72c3efe993853fa7ff27096b153db44584", "_cell_guid": "7449d853-eb1f-4acf-a5fa-1ee0f77281e7"}, "cell_type": "markdown", "source": ["In my previous kernel for this dataset, I performed exploratory data analysis and built a basic logistic regression model to get a first glimpse of what is the best approach to detect the anomalies. We saw that using a simple supervised classification model without applying upsampling/downsampling of the majority class (recall dataset is imbalanced), the AUCPR was really low. Thus, we need to find another strategy. Recall we saw that for both non-fraudulent and fraudlent classes, features followed Gaussian distributions. For example, for V4, the non-fraudulent class followed a Gaussian distribution with small variance compared to the fraudulent class."]}, {"metadata": {"_uuid": "58a1b7b0a2e9d0274c4921f05e5a6d55c4092a90", "_cell_guid": "fc3413cf-788f-46a1-b543-cc2c0eec96bf"}, "cell_type": "markdown", "source": ["In this kernel, I improve my model by optimizing the GMM threshold T via 5-fold cross validation. Here, I use all available features."]}, {"metadata": {"_uuid": "590674ddedf43646f99a88de9644bd1bdc108862", "_cell_guid": "a2f06696-203b-4d29-b4e0-75ad796beb5d"}, "cell_type": "code", "source": ["df = pd.read_csv('../input/creditcard.csv')\n", "from sklearn.model_selection import train_test_split\n", "from matplotlib.colors import LogNorm\n", "from sklearn import mixture\n", "\n", "df_0=df[df.Class==0]    #Dataset with non-fraudulent only\n", "df_1=df[df.Class==1]    #Dataset with fraudulent only\n", "\n", "#Split non-fraudulent data in 90% for training GMM and 10% for cross-validation and testing\n", "X_N_train, X_N_cv_test, y_N_train, y_N_cv_test = train_test_split(df_0.drop(['Class'],axis=1), df_0['Class'] , test_size=0.1, random_state=1)\n", "#Split the fraudulent data in 50% for cross-validation and 50% for testing\n", "X_F_cv, X_F_test, y_F_cv, y_F_test = train_test_split(df_1.drop(['Class'],axis=1), df_1['Class'] , test_size=0.5, random_state=1)\n", "#Split the remaining 10% non-fraudulent in 50% for cross-validation and 50% for testing\n", "X_N_cv, X_N_test, y_N_cv, y_N_test = train_test_split(X_N_cv_test, y_N_cv_test , test_size=0.5, random_state=1)\n", "\n", "#Generate the 3 new datasets (Train + CV + test)\n", "X_CV = np.vstack([X_N_cv, X_F_cv])\n", "y_CV = np.hstack([y_N_cv, y_F_cv])\n", "X_test = np.vstack([X_N_test, X_F_test])\n", "y_test = np.hstack([y_N_test, y_F_test])\n", "\n", "# Fit a Gaussian Mixture Model with the data from the NORMAL cases. *Note we are using ALL available features now.\n", "clf = mixture.GaussianMixture()\n", "clf.fit(X_N_train)"], "outputs": [], "execution_count": 2}, {"metadata": {"_uuid": "cf92e240842def5523174fb00285fd18b6b79d30", "_cell_guid": "77abce53-362e-45b0-84a4-51b7abc318e7"}, "cell_type": "markdown", "source": ["Now that the GMM is fit, let's find the probabilities of the test set. After we find those probabilities, if the probability is below a threshold we will say it is a fraudulent transaction (that is because our GMM is based on non-fraudulent transactions). Low probability means that is not probable that a given transaction is non-fraudulent."]}, {"metadata": {"_uuid": "999e158c403bb1688abc7f136abf170630b60a03", "collapsed": true, "_cell_guid": "bc4d0aa9-c7b4-4f52-9f42-88b0152fa4ca"}, "cell_type": "code", "source": ["from sklearn.metrics import average_precision_score\n", "from sklearn.metrics import precision_recall_curve\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.metrics import precision_score\n", "from sklearn.metrics import recall_score\n", "\n", "\n", "kfold = StratifiedKFold(n_splits=5, random_state=1)                                   #Create 5-CV split object\n", "T_vec=-np.arange(0,1000,2)          #Trying thresholds in steps of 2, from 0 to -1000. Note we are evaluating the negative log-likelihood.\n", "aucpr_vs_t=[]\n", "precision_vs_t=[]\n", "recall_vs_t=[]\n", "    \n", "for t in T_vec:\n", "    \n", "    aucpr=[]\n", "    precision=[]\n", "    recall=[]\n", "    k=0\n", "    for train_index, test_index in kfold.split(X_CV,y_CV):\n", "            \n", "            y_cv_proba=clf.score_samples(X_CV[test_index])                                 #Predict the probabilities of fold \"k\" using the fitted GMM \n", "            y_cv_pred=y_cv_proba.copy()\n", "            y_cv_pred[y_cv_pred>=t]=0\n", "            y_cv_pred[y_cv_pred<t]=1   \n", "            #print('Classification report')\n", "            #print(classification_report(y_CV[test_index], y_cv_pred))\n", "            precision.append(precision_score( y_CV[test_index], y_cv_pred))\n", "            recall.append(recall_score( y_CV[test_index], y_cv_pred))\n", "            aucpr.append(average_precision_score( y_CV[test_index], y_cv_pred))\n", "            #print(\"Threshold T = %i --> Fold %i - aucpr=%.3f - Precision=%.3f - Recall=%.3f\" %(t, k+1, aucpr[k], precision[k], recall[k]))\n", "            k=k+1  \n", "            \n", "            \n", "    aucpr_vs_t.append(np.mean(aucpr))\n", "    precision_vs_t.append(np.mean(precision))\n", "    recall_vs_t.append(np.mean(recall))\n", "    #print('CV average AUCPR: %.3f +/- %.3f' % ( np.mean(aucpr), np.std(aucpr)))    \n", "    #print('CV average precision: %.3f +/- %.3f' % ( np.mean(precision), np.std(precision)))    \n", "    #print('CV average recall: %.3f +/- %.3f' % ( np.mean(recall), np.std(recall)))"], "outputs": [], "execution_count": 4}, {"metadata": {"_uuid": "8f90baf5460598d21e70ff7cd349f5f6ecaa6ee8", "_cell_guid": "18b50623-8b19-4e3d-b37a-2f90690f5421"}, "cell_type": "markdown", "source": ["Finally, let's plot the performance results vs. the threshold. This allows us to see what is the optimal threshold value for maximum AUCPR."]}, {"metadata": {"_uuid": "9b97cb21dd945f38efb69766672e7b2850cc7557", "_cell_guid": "68b3c09c-7016-449f-ac33-5c62ae3e1e1a"}, "cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "plt.plot(T_vec, aucpr_vs_t)\n", "plt.plot(T_vec, precision_vs_t)\n", "plt.plot(T_vec,recall_vs_t)\n", "ax = plt.gca()\n", "ax.set(title='Evolution of performance scores vs. threshold for GMM probability', xlabel='Threshold T [neg loglikelihood]')\n", "ax.legend(['AUCPR (5 fold CV average)', 'Precision (5 fold CV average)', 'Recall (5 fold CV average)'])\n", "ax.invert_xaxis()"], "outputs": [], "execution_count": 5}, {"metadata": {"_uuid": "06953472c6d5b4f9637ee02cdd5c6101bca0ef55", "_cell_guid": "1f4be93f-83cb-4cb0-a29e-403d1de3cae2"}, "cell_type": "markdown", "source": ["Finally, we select the thershold with maximum AUCPR and use it for the test database in order to obtain the performance of our model in the test database"]}, {"metadata": {"_uuid": "cbe8d2a230f2c297ee66457fda45473e4ed8a7b9", "_cell_guid": "c7e997a8-827f-4a4d-9a91-7e229ff3586a"}, "cell_type": "code", "source": ["print('Maximum cross validation AUCPR='+str(max(aucpr_vs_t)))\n", "T_opt=T_vec[np.argmax(aucpr_vs_t)]\n", "print('Optimal threshold T = '+str(T_opt))\n", "\n", "\n", "y_test_proba = clf.score_samples(X_test)\n", "y_test_pred=y_test_proba.copy()\n", "y_test_pred[y_test_pred>=T_opt]=0\n", "y_test_pred[y_test_pred<T_opt]=1   \n", "\n", "test_precision = (precision_score( y_test, y_test_pred))\n", "test_recall = (recall_score( y_test, y_test_pred))\n", "test_aucpr = (average_precision_score( y_test, y_test_pred))\n", "print(\"TEST results --> aucpr=%.3f - Precision=%.3f - Recall=%.3f\" %(test_aucpr, test_precision, test_recall) )"], "outputs": [], "execution_count": 6}]}