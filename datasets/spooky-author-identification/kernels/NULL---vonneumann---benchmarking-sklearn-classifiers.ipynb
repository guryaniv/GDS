{"nbformat_minor": 1, "cells": [{"source": ["# Benchmarking different Sklearn classifiers\n", "\n", "Inspired by the sklearn sample code here: http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n", "\n", "\"This is an example showing how scikit-learn can be used to classify documents by topics using a bag-of-words approach. This example uses a scipy.sparse matrix to store the features and demonstrates various classifiers that can efficiently handle sparse matrices.\"\n", "\n", "It helps us choose the best classifier for this problem from the different sklearn algos."], "cell_type": "markdown", "metadata": {"_cell_guid": "9b3f522d-2ea3-4407-86bc-7fd88bcd416a", "_uuid": "b5ba1fa166eeca4e37450ab1211e1dbd695e7a72"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3d486dd0-9cc8-4f8f-ac56-7ac12ab60a19", "_uuid": "99eb520adf1db66748b8d4931123fc9887562bf4"}, "execution_count": null, "source": ["import pandas as pd"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "6d1f1e10-d8e3-4524-902a-43d11bc858a9", "_uuid": "b31b32a5919e6a23b31196ec3f8159e6e6de3673"}, "execution_count": null, "source": ["# Loading in the training data with Pandas\n", "train = pd.read_csv(\"../input/train.csv\")"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "84961f71-bbce-4461-bfff-ca132ca9d80d", "_uuid": "e2ecaa7953edd59e7796324336ef34ec9a36e445"}, "execution_count": null, "source": ["train.head()\n", "print(train.groupby('author')['id'].count().sort_values(ascending=False).head())\n", "train.groupby('author')['id'].count().plot(kind='bar',figsize=(16,4))"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "f8803647-5425-4f81-a241-f143aea31e8e", "_uuid": "1ebd34815e652888049b16155f569fe835a6099f"}, "execution_count": null, "source": ["# convert to dictionary and split into 30% 70%\n", "import random"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1f0160e3-f99a-426f-a8e7-5a81aaba06ce", "_uuid": "298e504ea124e1ed9625699f2478b5202c44b5cd"}, "execution_count": null, "source": ["documents = train.to_dict(orient='records')\n", "labels = list(train.author.unique())\n", "print(documents[0], labels)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6f4a01c9-26f6-4222-b16d-87e36cb75050", "_uuid": "b097fa1c81142e7e8dfcbc46a94ecdb1543bdef1"}, "execution_count": null, "source": ["train_set = []\n", "test_set = []\n", "\n", "# make sure our sets are balanced take the same amount for each label\n", "for label in labels:        \n", "    partition = int(len(documents) * 0.7)\n", "    # randomly split documents between test and training\n", "    random.shuffle(documents)\n", "    train_set += documents[:partition]\n", "    test_set += documents[partition:]\n", "\n", "print('training set:', len(train_set),'test set', len(test_set))"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "17fc654b-9077-4c40-b4b0-a9ff09291f9e", "_uuid": "1a40c04aa9af48dc1138a6e311ca5685a802bfc1"}, "execution_count": null, "source": ["# benchmark multiple algos\n", "\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.feature_extraction.text import TfidfTransformer\n", "from sklearn.feature_selection import SelectFromModel\n", "from sklearn.feature_selection import SelectKBest, chi2\n", "from sklearn.linear_model import RidgeClassifier\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.svm import LinearSVC\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import PassiveAggressiveClassifier\n", "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.neighbors import NearestCentroid\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.utils.extmath import density\n", "from sklearn import metrics\n", "from time import time\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "e3a65868-369b-44a2-93d4-1a6c7c007890", "_uuid": "1189c60ebfcb679a5f0439f9f83c645dc6e2fc20"}, "execution_count": null, "source": ["#  map to \n", "\n", "opts = dict()\n", "opts['n_features'] = 2 ** 16\n", "\n", "X_train = [x['text'] for x in train_set]\n", "y_train = [x['author'] for x in train_set]\n", "X_test = [x['text'] for x in test_set]\n", "y_test = [x['author'] for x in test_set]\n", "target_names = set(y_train)"]}, {"source": ["Do a little preprocessing: turn the text into vectors and select the most important features using TF-IDF"], "cell_type": "markdown", "metadata": {"_cell_guid": "408028fe-107d-4a94-a534-dedec810dbd9", "_uuid": "1689db0340f57407d6ea33d12993c33c671d6330"}}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6b60508d-e103-429c-9f18-b3aa6525fb84", "_uuid": "e39c1b7590b30c5d40792559a1344805b4a5f436"}, "execution_count": null, "source": ["token_pattern = r\"[a-zA-Z]+\"\n", "vectorizer = CountVectorizer(token_pattern=token_pattern,\n", "                             stop_words = 'english',\n", "                              max_features=None,\n", "                              max_df=0.5,\n", "                              ngram_range=(1, 2))\n", "\n", "X_train = vectorizer.fit_transform(X_train)\n", "X_test = vectorizer.transform(X_test)\n", "\n", "print(X_train.shape, X_test.shape)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "11842a76-05bf-4b29-8d80-37e586b22819", "_uuid": "4df21a57ac5d853ed944ac22db7c1b120812249b"}, "execution_count": null, "source": ["%%time\n", "\n", "tfidf = TfidfTransformer(norm='l2')\n", "X_train = tfidf.fit_transform(X_train)\n", "X_test = tfidf.transform(X_test)\n", "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n", "print()"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "1e14cc78-00f6-49cb-8653-da6b351bc1f3", "_uuid": "b75d5480de7586c8fcb8c451fe6b2dfd9cae96e5"}, "execution_count": null, "source": ["def trim(s):\n", "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n", "    return s if len(s) <= 80 else s[:77] + \"...\""]}, {"source": ["Define the benchmarking function which takes a classifier as input and outputs the metrics and confusion metrics obtained using the classifier."], "cell_type": "markdown", "metadata": {"_cell_guid": "478dcbf0-d9e3-4b60-bf9e-e5cd35cac579", "_uuid": "dc40016e9c3179eb0cebf65de56ac8b6b0542f67"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "b7121733-97fb-4def-bfb3-f3c0eff9db1c", "_uuid": "ef18c29621e214452fea4dbf2d3205e8e055cca5"}, "execution_count": null, "source": ["def benchmark(clf):\n", "    print('_' * 80)\n", "    print(\"Training: \")\n", "    print(clf)\n", "    t0 = time()\n", "    clf.fit(X_train, y_train)\n", "    train_time = time() - t0\n", "    print(\"train time: %0.3fs\" % train_time)\n", "\n", "    t0 = time()\n", "    pred = clf.predict(X_test)\n", "    test_time = time() - t0\n", "    print(\"test time:  %0.3fs\" % test_time)\n", "\n", "    score = metrics.accuracy_score(y_test, pred)\n", "    print(\"accuracy:   %0.3f\" % score)\n", "\n", "    if hasattr(clf, 'coef_'):\n", "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n", "        print(\"density: %f\" % density(clf.coef_))\n", "    \n", "    print(\"classification report:\")\n", "    print(metrics.classification_report(y_test, pred,\n", "                                        target_names=target_names))\n", "\n", "    print(\"confusion matrix:\")\n", "    print(metrics.confusion_matrix(y_test, pred))\n", "\n", "    print()\n", "    clf_descr = str(clf).split('(')[0]\n", "    return clf_descr, score, train_time, test_time\n", "\n", "\n"]}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "06aa96da-b44b-4cbb-a880-81173f4eef45", "scrolled": false, "_uuid": "7e35e2f90707bfa1e3b6ea11792cd81ea4aee8d0"}, "execution_count": null, "source": ["results = []\n", "for clf, name in (\n", "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n", "        (Perceptron(n_iter=50), \"Perceptron\"),\n", "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n", "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n", "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n", "    print('=' * 80)\n", "    print(name)\n", "    results.append(benchmark(clf))\n", "\n", "for penalty in [\"l2\", \"l1\"]:\n", "    print('=' * 80)\n", "    print(\"%s penalty\" % penalty.upper())\n", "    # Train Liblinear model\n", "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n", "                                       tol=1e-3)))\n", "\n", "    # Train SGD model\n", "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n", "                                           penalty=penalty)))\n", "\n", "# Train SGD with Elastic Net penalty\n", "print('=' * 80)\n", "print(\"Elastic-Net penalty\")\n", "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n", "                                       penalty=\"elasticnet\")))\n", "\n", "# Train NearestCentroid without threshold\n", "print('=' * 80)\n", "print(\"NearestCentroid (aka Rocchio classifier)\")\n", "results.append(benchmark(NearestCentroid()))\n", "\n", "# Train sparse Naive Bayes classifiers\n", "print('=' * 80)\n", "print(\"Naive Bayes\")\n", "results.append(benchmark(MultinomialNB(alpha=.01)))\n", "results.append(benchmark(BernoulliNB(alpha=.01)))\n", "\n", "print('=' * 80)\n", "print(\"LinearSVC with L1-based feature selection\")\n", "# The smaller C, the stronger the regularization.\n", "# The more regularization, the more sparsity.\n", "results.append(benchmark(Pipeline([\n", "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n", "                                                  tol=1e-3))),\n", "  ('classification', LinearSVC(penalty=\"l2\"))])))"]}, {"source": ["## Plot the results"], "cell_type": "markdown", "metadata": {"_cell_guid": "759da6e6-c4fc-4da2-af41-f0911de659ce", "_uuid": "e67b0c62e9aa88e5bc15c725feb82c5321ee6b16"}}, {"outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "35571d1b-128e-402c-b954-50cc68b7aa0d", "_uuid": "54129030c04a613edd0443528b599fea31775b5b"}, "execution_count": null, "source": ["# make some plots\n", "\n", "indices = np.arange(len(results))\n", "\n", "results = [[x[i] for x in results] for i in range(4)]\n", "\n", "clf_names, score, training_time, test_time = results\n", "training_time = np.array(training_time) / np.max(training_time)\n", "test_time = np.array(test_time) / np.max(test_time)\n", "\n", "plt.figure(figsize=(12, 8))\n", "plt.title(\"Score\")\n", "plt.barh(indices, score, .2, label=\"score\", color='navy')\n", "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n", "         color='c')\n", "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n", "plt.yticks(())\n", "plt.legend(loc='best')\n", "plt.subplots_adjust(left=.25)\n", "plt.subplots_adjust(top=.95)\n", "plt.subplots_adjust(bottom=.05)\n", "\n", "for i, c in zip(indices, clf_names):\n", "    plt.text(-.3, i, c)\n", "\n", "plt.show()"]}, {"source": [], "cell_type": "markdown", "metadata": {"collapsed": true, "_cell_guid": "1dbe78a4-ebb5-4b7f-85c1-96d699e7075e", "_uuid": "4d70a388708615c8a8bc9dea58da718bba6edd82"}}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat": 4}