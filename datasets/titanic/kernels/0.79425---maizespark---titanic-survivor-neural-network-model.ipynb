{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":false,"collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"41f9eba2-d570-4b82-94e2-819b8e2167fe","collapsed":true,"_uuid":"6ec662874de7ad15f7432fc8b165a9cb874e504f","trusted":false},"cell_type":"code","source":"# reading in data\ntrain=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eeb0529f-bf1e-44a3-a811-071103a9eb3a","collapsed":true,"_uuid":"30b5b21c41517e9e1fc232acd2abc5a2b53616cb","trusted":false},"cell_type":"code","source":"train.info()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ba82d5ee-ab0d-4051-9e1f-92813ead3103","collapsed":true,"_uuid":"2ee81f22618cf6c760017c4a01e77f59c4a50d7b","trusted":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"80687043-2f9e-46bc-82df-5d05a632c66d","collapsed":true,"_uuid":"7c7d6126b13c60c2628b82321bbfc3c01add47e4","trusted":false},"cell_type":"code","source":"train.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a93c90b-cee2-4bfd-953a-dca4edf81496","collapsed":true,"_uuid":"30ebbf807bd5d95dda0eaba8eea5b506f00edcfb","trusted":false},"cell_type":"code","source":"train[['Pclass','Survived']].groupby(['Pclass'], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33e15ce8-efa7-4f19-8466-12cef11bea00","collapsed":true,"_uuid":"e71b905c2cb0d9dd7d451889ce3f862d57cce67c","trusted":false},"cell_type":"code","source":"train.Sex=pd.Categorical(train.Sex)\ntrain.Sex=train.Sex.cat.codes\nprint(train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False))\ntest.Sex=pd.Categorical(test.Sex)\ntest.Sex=test.Sex.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cb6c9c41-801c-4970-9ddc-5ecc10bb21e8","collapsed":true,"_uuid":"ece63322532dcd1740a9cef165809e09c66e0755","trusted":false},"cell_type":"code","source":"#Survival rate for people without cabin info is significantly lower than the one with info. Therefore, null data matters..\ntrain.Cabin=train.Cabin.fillna('N').str[:1]\nprint(train[[\"Cabin\", \"Survived\"]].groupby(['Cabin'], as_index=False)['Survived'].agg(['mean','count']))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08873f63-d383-4c7b-94b9-3f9fab36122b","collapsed":true,"_uuid":"049e38456c0100e1d63a3a4dbdc378a9480824b1","trusted":false},"cell_type":"code","source":"#Cabin section is found to be related to Pclass. It looks like people with cabin information has significantly better survival rate.\n#Therefore, I will only categorize by existence of cabin info.\ntrain.Cabin=train.Cabin.fillna('N').str[:1]\ntrain['Cabin_info']=1\ntrain['Cabin_info'][train.Cabin=='N']=0\nprint(train[[\"Cabin\",\"Pclass\",\"Survived\"]].groupby([\"Cabin\",\"Pclass\"], as_index=False)['Survived'].agg(['mean','count']))\nprint(train[[\"Cabin_info\",\"Pclass\",\"Survived\"]].groupby([\"Pclass\",\"Cabin_info\"], as_index=False)['Survived'].agg(['mean','count']))\ntest.Cabin=test.Cabin.fillna('N').str[:1]\ntest['Cabin_info']=1\ntest['Cabin_info'][test.Cabin=='N']=0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26fb6076-a18b-4567-8b52-20d0f1bb65d3","collapsed":true,"_uuid":"11f0e01724eb02b5d7c9ab1d2e9b90108e207b8b","trusted":false},"cell_type":"code","source":"#I choose not to use median for null values because it looked like survival rate is significantly lower for null.\ntrain['Age_group']=pd.cut(train.Age, 8).cat.codes\ntest['Age_group']=pd.cut(test.Age, 8).cat.codes\ntrain[[\"Age_group\", \"Survived\"]].groupby(['Age_group'], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1c2ca206-f158-4b00-8369-62639eba9fda","scrolled":true,"collapsed":true,"_uuid":"65c33361a66a3ed7e2fe59dc15cee207a6e338c7","trusted":false},"cell_type":"code","source":"#As you can imagine, if we know family size, parch, sibsp, and age, we, humans, can give a good guess if the person is parent/child/alone.\n#If neural network does things right, one of the nodes should give family size, and use it for estimation of survival rate. However, there is no\n#guarantee that neural net would come up with that. As a result, I chose to add the variable manually. As sample is too small to be significant \n#for 8-member and 11-member family, I chose to merge them to 7.\ntrain['Family_size']=train['Parch']+train['SibSp']+1\ntrain.Family_size[train.Family_size>6]=7\ntest['Family_size']=test['Parch']+test['SibSp']+1\ntest.Family_size[test.Family_size>6]=7\nprint(train[[\"Family_size\",\"Survived\"]].groupby([\"Family_size\"], as_index=False)['Survived'].agg(['mean','count']))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ccb3718-7e46-4a6d-b84b-4117efdf2333","scrolled":true,"collapsed":true,"_uuid":"0c1a0bc3d1ef15adda61287dff5032b0793de5e3","trusted":false},"cell_type":"code","source":"#So far, I have considered having no information as something that matters. However, in this case, there are only 2 nulls. As a result, \n#it is hard to say that null info is significant. Therefore, I chose to make null info to one of the majorities.\ntrain.Embarked=pd.Categorical(train.Embarked)\ntrain.Embarked=train.Embarked.cat.codes\ntrain.Embarked[train.Embarked==-1]=2\ntest.Embarked=pd.Categorical(test.Embarked)\ntest.Embarked=test.Embarked.cat.codes\ntest.Embarked[test.Embarked==-1]=2\ntrain[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c5accb8b-9bfb-4763-91bd-555a28510d13","collapsed":true,"_uuid":"4577e9ab77203ed33d82492d7b8f194f3ca50572","trusted":false},"cell_type":"code","source":"#Fare is definitely related to Pclass, but relationship is not linear. Additionally, there is no clear cut in Fare to distinguish class.\n#However, there is one meaningful observation: expensive first class is more likely to survive. This was not necessarily the case for 2nd and 3rd.\n#As there is significant survival difference from $50, I chose to give category for that.\ntrain['Fare_cut']=pd.cut(train.Fare, 31)\ntest['Fare_cut']=pd.cut(test.Fare, 31)\ntrain[[\"Fare_cut\",\"Pclass\",\"Survived\"]].groupby([\"Fare_cut\",\"Pclass\"], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7e47101f-7a13-484b-aa5c-589895dc5a66","scrolled":true,"collapsed":true,"_uuid":"7b07385716127d0ef9255b3d36161e762c946024","trusted":false},"cell_type":"code","source":"#It looks like fare affects survival rates in a different way by class. This is another reason why neural network would make more sense.\ntrain['Fare_cat']=0\ntrain['Fare_cat'][train.Fare>50]=1\ntest['Fare_cat']=0\ntest['Fare_cat'][test.Fare>50]=1\ntrain[[\"Fare_cat\",\"Pclass\",\"Survived\"]].groupby([\"Fare_cat\",\"Pclass\"], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a5cc1fc0-646f-487e-aa25-76ed7d9a86ce","collapsed":true,"_uuid":"61dfa360e088de1b27fb77b3176d4d4a58ba9180","trusted":false},"cell_type":"code","source":"#There are many different kinds of Prefix, but only few of them have enough sample. I chose to take Rev and Dr separately, but it's your choice.\ntrain['Prefix']=train.Name.str.replace('(.*, )|(\\\\..*)', '')\nfor i in np.arange(len(train.Prefix)):\n    if train.Prefix[i] not in ('Miss','Mrs','Master','Mr','Rev','Dr'):\n        train.Prefix[i]='Unique'\ntrain.Prefix=pd.Categorical(train.Prefix)\ntrain.Prefix=train.Prefix.cat.codes\n\ntest['Prefix']=test.Name.str.replace('(.*, )|(\\\\..*)', '')\nfor i in np.arange(len(test.Prefix)):\n    if test.Prefix[i] not in ('Miss','Mrs','Master','Mr','Rev','Dr'):\n        test.Prefix[i]='Unique'\ntest.Prefix=pd.Categorical(test.Prefix)\ntest.Prefix=test.Prefix.cat.codes\n\ntrain[[\"Prefix\",\"Sex\",\"Survived\"]].groupby([\"Sex\",\"Prefix\"], as_index=False)['Survived'].agg(['mean','count'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"356dcf81-87bd-4d46-8f7f-e2636697822a","collapsed":true,"_uuid":"4e5247e13db0b0982dc8aec13ebd287aea23f327","trusted":false},"cell_type":"code","source":"del train['Name']\ndel train['PassengerId']\ndel train['Age']\ndel train['Ticket']\ndel train['Fare']\ndel train['Cabin']\ndel train['Fare_cut']\n\ndel test['Name']\ndel test['Age']\ndel test['Ticket']\ndel test['Fare']\ndel test['Cabin']\ndel test['Fare_cut']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"61843f87-9e31-41bd-ad3c-da07db325558","collapsed":true,"_uuid":"cbbeafdffaae0f0e7cc06e2ff6da2df5e8cc15ed","trusted":false},"cell_type":"code","source":"print(train.info())\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77dd07c1-7738-4af6-945d-cd93b26841cc","collapsed":true,"_uuid":"152f1ae26b87ad837573a0a07fc2ab353d008d22","trusted":false},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nX_all = train.drop(['Survived'], axis=1)\ny_all = train['Survived']\n\nnum_test = 200\nX_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d6f63155-87fa-4e3a-9e62-421fa9359428","scrolled":true,"collapsed":true,"_uuid":"90a198a2ded2c31f4777727c8287b0a191cd4768","trusted":false},"cell_type":"code","source":"# neural network\n#For choosing the number of neurons, I chose to test all numbers below 22 which is double the number of all variables.\n#After checking results, I chose to use 7 neurons for double layer.\nfrom sklearn.neural_network import MLPClassifier\nneural_record=pd.DataFrame(columns=['Single_In','Double_In','Single_Out','Double_Out','Single_Net','Double_Net'],index=np.arange(21))\nfor i in np.arange(21):\n    c = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i+1), random_state=1,activation='logistic',max_iter=3000)\n    c.fit(X_train, y_train)\n    neural_record['Single_In'][i]=c.score(X_train,y_train) #In-sample result with single layer\n    neural_record['Single_Out'][i]=np.mean(c.predict(X_test)==y_test) #Out-of-sample result with single layer\n    neural_record['Single_Net'][i]=c\n    c2 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i+1,i+1), random_state=1,activation='logistic',max_iter=3000)\n    c2.fit(X_train, y_train)\n    neural_record['Double_In'][i]=c2.score(X_train,y_train) #In-sample result with double layer\n    neural_record['Double_Out'][i]=np.mean(c2.predict(X_test)==y_test) #Out-of-sample result with double layer\n    neural_record['Double_Net'][i]=c2\n    print(i,c.score(X_train,y_train),np.mean(c.predict(X_test)==y_test),c2.score(X_train,y_train),np.mean(c2.predict(X_test)==y_test))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f309fb68-d88b-4965-a4b6-8d6527c7114b","collapsed":true,"_uuid":"277847b0b5f9972bb7e7bb196bb40f0db5bd9b2f","trusted":false},"cell_type":"code","source":"ids = test['PassengerId']\npredictions = neural_record['Single_Net'][10].predict(test.drop('PassengerId', axis=1))\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('titanic-predictions-SP.csv', index = False)\npredictions = neural_record['Double_Net'][6].predict(test.drop('PassengerId', axis=1))\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('titanic-predictions-SP-double-hidden-layer.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}