{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import libraries\nimport pandas as pd\nimport numpy as np\nimport sklearn\nfrom sklearn import datasets\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\n\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb\n\nimport os\n\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.neighbors import DistanceMetric\n\nfrom xgboost import XGBClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8ae39431ede592fd907267be6608eb8665f47e6"},"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70e06164f9ecdf3d7cd30e22485f8a11a4c23935"},"cell_type":"code","source":"cols_to_keep= [\"target\", \"ID_code\",\"var_139\",\"var_12\",\"var_81\",\"var_110\",\"var_53\",\"var_146\",\"var_26\",\"var_6\",\"var_174\",\"var_76\",\n               \"var_166\",\"var_148\",\"var_80\",\"var_22\",\"var_99\",\"var_133\",\"var_21\",\"var_78\",\"var_198\",\"var_165\",\n               \"var_109\",\"var_190\",\"var_1\",\"var_2\",\"var_179\",\"var_44\",\"var_164\",\"var_0\",\"var_13\",\"var_92\",\n               \"var_177\",\"var_40\",\"var_154\",\"var_9\",\"var_34\",\"var_191\",\"var_170\",\"var_94\",\"var_33\",\"var_108\",\n               \"var_169\",\"var_184\",\"var_115\",\"var_123\",\"var_121\",\"var_192\",\"var_67\",\"var_95\",\"var_18\",\"var_75\",\n               \"var_5\",\"var_93\",\"var_149\",\"var_91\",\"var_173\",\"var_122\",\"var_188\",\"var_107\",\"var_135\",\"var_89\",\n               \"var_130\",\"var_186\",\"var_113\",\"var_197\",\"var_72\",\"var_62\",\"var_180\",\"var_11\",\"var_20\",\"var_23\",\n               \"var_24\",\"var_56\",\"var_106\",\"var_28\",\"var_104\",\"var_32\",\"var_37\",\"var_39\",\"var_48\",\"var_77\",\n               \"var_43\",\"var_117\",\"var_85\",\"var_147\",\"var_119\",\"var_157\",\"var_143\",\"var_141\",\"var_162\",\n               \"var_127\",\"var_167\",\"var_153\",\"var_155\",\"var_86\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f66af06987114331cf943de3baaf8d35da05c6e"},"cell_type":"code","source":"# Add RUC metric to monitor NN\ndef auc(y_true, y_pred):\n    return tf.py_func(metrics.roc_auc_score, (y_true, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fced769b3522277375f37553545f4a21fe9b801"},"cell_type":"code","source":"from keras.layers import Dense,Dropout,BatchNormalization\nfrom keras import regularizers\nimport keras\nfrom keras.callbacks import LearningRateScheduler,EarlyStopping\nimport tensorflow as tf\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom keras.constraints import max_norm\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ff78a955150510702064db62de6a183ee8945e4"},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"124509cedfe7ee2bb336535ff1c44f23431687b8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"297668e0006daea009ea748c5efe88134b3f248d"},"cell_type":"code","source":"import gc\nimport random\nfrom keras import models\nfrom keras import regularizers\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.layers.advanced_activations import PReLU,LeakyReLU\nfrom keras import optimizers\nfrom keras.regularizers import l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d7191676edb8eb18abe7b31a273955a2ce0efe"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"442a656b29a75ea610754e2554d03f99086f6105"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc496d44aca7f5b7795b2573d4043f4575a9af95"},"cell_type":"code","source":"def step_decay(epoch):\n   initial_lrate = 0.1\n   drop = 0.5\n   epochs_drop = 10.0\n   lrate = initial_lrate * math.pow(drop,  \n           math.floor((1+epoch)/epochs_drop))\n   return lrate\nlrate = LearningRateScheduler(step_decay)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8526e464ea8a1949fbdd4bb9e58e51c2d87233c6"},"cell_type":"code","source":"class LossHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n       self.losses = []\n       self.lr = []\n \n    def on_epoch_end(self, batch, logs={}):\n       self.losses.append(logs.get('loss'))\n       self.lr.append(step_decay(len(self.losses)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bbb68f72c16016912936559e4def95012f7ab82d"},"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nimport math\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nNFOLDS = 5\nRANDOM_STATE = 42\nannealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)\n#script_name = os.path.basename(__file__).split('.')[0]\n#MODEL_NAME = \"{0}__folds{1}\".format(script_name, NFOLDS)\n\n#print(\"Model: {}\".format(MODEL_NAME))\n\n\n\n\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8054b2c219558df787c80a2e11780746c3236aec"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca36c32ecf675a260cab11b42f43f200e31946d4"},"cell_type":"code","source":"print(\"Reading training data\")\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abf1e748ce32c2345bd1afc17569ba1e22240dd0"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c395f97842c3c5efe97392c39d181ac4a923b0d2"},"cell_type":"code","source":"%%time\ny = train.target.values\ntrain_ids = train.ID_code.values\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64a99b4ae53881152950141da9273e2c68c7c27f"},"cell_type":"code","source":"%%time\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]\nfor feature in features:\n#    train['mean_'+feature] = np.round((train[feature].mean()-train[feature]),2)\n#    train['z_'+feature] = np.round((train[feature] - train[feature].mean())/train[feature].std(ddof=0),2)\n    train['sq_'+feature] = np.round((train[feature])**2,2)\n    train['c_'+feature] = np.round((train[feature])**3,2)\n    train['p4_'+feature] = np.round((train[feature])**4,2)\n    train['sqrt_'+feature] = np.round((train['sq_'+feature])**(1/4),2)\n    train['log_'+feature] = np.round(np.log(train['sq_'+feature]+10)/2,2)\n    \n\nfor feature in features:\n#    test['mean_'+feature] = np.round((test[feature].mean()-test[feature]),2)\n#    test['z_'+feature] = np.round((test[feature] - test[feature].mean())/test[feature].std(ddof=0),2)\n    test['sq_'+feature] = np.round((test[feature])**2,2)\n    test['c_'+feature] = np.round((test[feature])**3,2)\n    test['p4_'+feature] = np.round((test[feature])**4,2)\n    test['sqrt_'+feature] = np.round((test['sq_'+feature])**(1/4),2)\n    test['log_'+feature] = np.round(np.log(test['sq_'+feature]+10)/2,2)\n    \n\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c88042b2169e127d8c2bab7c4453c7d45c364374"},"cell_type":"code","source":"#train= reduce_mem_usage(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1732ac7adbea5538792fa3ff71fed5b26ccdd554"},"cell_type":"code","source":"#test = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86c74a3b8ceeef3cf2b08ec8ccb0c3028c9d7f57"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13d0e4c2ed5fbfa744c9b25d467894ccd2ba8859"},"cell_type":"code","source":"train = train.drop(['ID_code', 'target'], axis=1)\nfeature_list = train.columns\n\nprint('Train',train.shape)\nprint('Test', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5afd638c33c21a555f582d93ea701900f4538b9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ac5abcef92b746ec92635f6a7147c5c0e418414"},"cell_type":"code","source":"test_ids = test.ID_code.values\ntest = test[feature_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41264f0aafc7fd1fdb8c5ea1d1e2777f06afa3f1"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"729164e216cccabe9dbc6e6211d500146f5624b4"},"cell_type":"code","source":"print(train.shape,test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc280031ba2203d561e5ebe8e2481315483791c5"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import PowerTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a378526c5299a04b0cf804a2f555dd0d82dd8b1b"},"cell_type":"code","source":"X = train.values.astype(float)\nX_test = test.values.astype(float)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9018bcf2ecc3c7a1376b96ddd59b35d8334abe7"},"cell_type":"code","source":"%%time\nsc = StandardScaler()\nmmsc =  MinMaxScaler()\nmasc = MaxAbsScaler()\nrbsc =  RobustScaler(quantile_range=(25, 75))\nyeoj= PowerTransformer(method='yeo-johnson')\nboxcox= PowerTransformer(method='box-cox')\nqnormal =  QuantileTransformer(output_distribution='normal')\nquniform= QuantileTransformer(output_distribution='uniform')\nnormal= Normalizer()\nX1= np.round(mmsc.fit_transform(X),3)\nX = np.round(sc.fit_transform(X),3)\nX_test1 = np.round(mmsc.fit_transform(X_test),3)\nX_test = np.round(sc.transform(X_test),3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04b3bb347449beb5b6657bebb1c538df359e6006"},"cell_type":"code","source":"X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ae30423763483cf05d2c72459b2577e6b1477cd"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589da48745157ca9f20b9f134432a08f2b57b4fd"},"cell_type":"code","source":"clfs = []\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=RANDOM_STATE)\noof_preds = np.zeros((len(train), 1))\ntest_preds = np.zeros((len(test), 1))\ndel train, test\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"540c0cb2976387c574367ea8c60c70f9b3c7c5a0"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nloss_history = LossHistory()\nlrate = LearningRateScheduler(step_decay)\nreduce = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5)\ncallbacks_list = [reduce,EarlyStopping(monitor='val_auc', patience=20,mode='max',restore_best_weights=True)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"479286e196ecebbd5623c9044ecab31862798038"},"cell_type":"code","source":"from keras.layers import GaussianNoise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09a1ec894459cb3fd7b2886aea2dc60fe91a8710"},"cell_type":"code","source":"from keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.layers import concatenate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62265164ac31ba2720b50ecc7b0508d9d8c694b5"},"cell_type":"code","source":"def get_model():    \n    x1_in = Input(shape=(X.shape[1],), name='x1_in')\n    x2_in = Input(shape=(X1.shape[1],), name='x2_in')\n    x1 = Dense(512, activation='tanh')(x1_in)\n    x1 = Dropout(0.6)(x1)\n    x1 = BatchNormalization()(x1)\n    x1 = Dense(256, activation='tanh')(x1)\n    x1 = Dropout(0.6)(x1)\n    x1 = BatchNormalization()(x1)\n    x2 = Dense(512, activation='tanh')(x2_in)\n    x2 = Dropout(0.6)(x2)\n    x2 = BatchNormalization()(x2)\n    x2 = Dense(256, activation='tanh')(x2)\n    x2 = Dropout(0.6)(x2)\n    x2 = BatchNormalization()(x2)\n    z = concatenate([x1, x2])\n    z = Dense(256, activation='tanh')(z)\n    z = Dropout(0.5)(z)\n    z = BatchNormalization()(z)\n    out = Dense(1, activation='sigmoid', name='out')(z)\n    model = Model(inputs=[x1_in, x2_in], outputs=[out])\n    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.8, nesterov=True)\n    model.compile(loss='binary_crossentropy', optimizer=sgd,metrics=['accuracy',auc])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86d5da19ecf7185b628177829f2f0cbe0f1cd4a4","scrolled":true},"cell_type":"code","source":"for fold_, (trn_, val_) in enumerate(folds.split(y, y)):\n    print(\"Current Fold: {}\".format(fold_))\n    trn_x1, trn_y = X[trn_, :], y[trn_]\n    val_x1, val_y = X[val_, :], y[val_]\n    trn_x2 = X1[trn_,:]\n    val_x2 = X1[val_,:]\n    clf = get_model()\n\n    clf.fit([trn_x1,trn_x2],trn_y,batch_size=512,epochs=500,verbose=1,callbacks=callbacks_list,validation_data=([val_x1,val_x2],val_y))\n\n    val_pred = clf.predict([val_x1,val_x2])\n    test_fold_pred = clf.predict([X_test,X_test1])\n\n    print(\"AUC = {}\".format(metrics.roc_auc_score(val_y, val_pred)))\n    oof_preds[val_, :] = val_pred.reshape((-1, 1))\n    test_preds += test_fold_pred.reshape((-1, 1))\n    del trn_x1,trn_x2, trn_y , val_x1,val_x2,val_y\n    gc.collect()\n\ntest_preds /= NFOLDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c871505bb029b25f597bb1b6b39cf71c7a6ecd43"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54926ee61b577516c8f19f72e1ac5104d92535f"},"cell_type":"code","source":"roc_score = metrics.roc_auc_score(y, oof_preds.ravel())\nprint(\"Overall AUC = {}\".format(roc_score))\n\nprint(\"Saving OOF predictions\")\noof_preds = pd.DataFrame(np.column_stack((train_ids, oof_preds.ravel())), columns=['ID_code', 'target'])\n#oof_preds.to_csv('../kfolds/nn__{}.csv'.format( str(roc_score)), index=False)\n\nprint(\"Saving code to reproduce\")\n#shutil.copyfile('../model_source/nn__{}.py'.format( str(roc_score)))\n\nprint(\"Saving submission file\")\nsample = pd.read_csv('../input/sample_submission.csv')\nsample.target = test_preds.astype(float)\nsample.ID_code = test_ids\nsample.to_csv('submission__nn__{}.csv'.format(str(roc_score)), index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c75eb4912a23ccc8a76c5cef80221e624df5923"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"435c543b378a18ef24e31a9aca50a94b4ebc6ac3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9602e739f139aa55a4b2ec22f66a6c463541fb6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f707eb73918956bbe32a5de89c342ab21053399"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8944434df2a5cc3731779e22661e96725cf8fbb1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b859493ffb051586ec4a83a9d1c8870d6f9dc904"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}