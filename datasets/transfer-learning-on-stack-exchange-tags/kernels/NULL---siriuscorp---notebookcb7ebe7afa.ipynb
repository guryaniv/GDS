{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6af0549d-473e-abf2-9251-c30c14ed52de"
      },
      "source": [
        "##**Text preprocessing and TF-IDF to predict tags.**  ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2867418f-70c5-d510-c993-257787145651"
      },
      "outputs": [],
      "source": [
        "\n",
        "## Imports for later use.\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dbd20cbd-5f5c-ec7b-f381-28a25a2c480d"
      },
      "source": [
        "Now to load the datasets and transform them into panda dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b0c201dc-6e8f-1390-d825-d040e25b42ba"
      },
      "outputs": [],
      "source": [
        "dataframes = {\n",
        "    \"biology\": pd.read_csv(\"../input/biology.csv\"),\n",
        "    \"cooking\": pd.read_csv(\"../input/cooking.csv\"),\n",
        "    \"crypto\": pd.read_csv(\"../input/crypto.csv\"),\n",
        "    \"diy\": pd.read_csv(\"../input/diy.csv\"),\n",
        "    \"robotics\": pd.read_csv(\"../input/robotics.csv\"),\n",
        "    \"travel\": pd.read_csv(\"../input/travel.csv\"),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f7438643-beb3-c95a-abfc-e865ecc6437f"
      },
      "source": [
        "## 1- Text clean up and processing ##\n",
        "\n",
        "First, we will remove HTML Tags and markups using the BeautifulSoup library. This library removes HTML Tags and markups from text, usually coming from HTML files. In this case, we will extract the text content from the datasets' contentsFirs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "690fede9-24d5-ef72-e358-e3e47f2661cf"
      },
      "outputs": [],
      "source": [
        "## Function that returns only the text from the text content.\n",
        "def getText(content):\n",
        "    if content:\n",
        "        ##Initialize beautiful soup\n",
        "        soup = BeautifulSoup(content, 'html.parser' )\n",
        "        \n",
        "        ## Extracting the text \n",
        "        text = soup.get_text()\n",
        "        \n",
        "        return text\n",
        "    else:\n",
        "        ##if there is no content, return an empty string\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5d019f92-08e9-4d5b-c639-44dd2423b02e"
      },
      "source": [
        "For comparison, let's look at the content of a post with the tags, and with the tags extracted by the function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db6683ef-8526-a81f-409b-4c302d2232fd"
      },
      "outputs": [],
      "source": [
        "testContent=dataframes[\"cooking\"].iloc[1][\"content\"]\n",
        "print(testContent)\n",
        "print(getText(testContent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f673b83c-cd5d-8b53-3903-b669e76b7f21"
      },
      "source": [
        "As we can see, the second text lacks the p or paragraph HTML tags . This means the getText function is working as intended.\n",
        "\n",
        "Next, we will remove numbers and puctuation marks, so that only words remain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "54d73728-74ed-d764-2676-b22786d57f0a"
      },
      "outputs": [],
      "source": [
        "##Function that removes non-alphabetic characters from a text string\n",
        "def removeNonAlpha(content):\n",
        "    ## Regular expresion to search for a pattern and replace it with something else.\n",
        "    return  re.sub(\"[^a-zA-Z]\",           # The pattern to find in the text\n",
        "                      \" \",                # The pattern to replace it with\n",
        "                      content)  # The text to be searched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "927332ec-9b91-a2fd-c744-ee685b63c0f2"
      },
      "source": [
        "\n",
        "Now to explain what is going on in the regular expression pattern above, let's explain the symbols that are used in the pattern:\n",
        "\n",
        "<p> [ ] : means group, so everything inside the brackets is a group. </p>\n",
        "<p> ^ : when used in brackets [ ] means not the following. </p>\n",
        "<p> a-z: Means lower case letters </p>\n",
        "<p> A-Z: Means upper case latters </p> \n",
        "\n",
        "So the expression basically says replace everything that is **NOT** an upper case or lower case  letter with an empty space.  This effectively removes all numbers and punctuation marks.  \n",
        "\n",
        "Let's test the function with the same content we tested the previous function with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9e52bf99-57d1-b00a-5ba7-4e98e2932f7a"
      },
      "outputs": [],
      "source": [
        "test = getText(testContent)\n",
        "print (removeNonAlpha(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d3928f85-91c1-0bde-1feb-08837c286158"
      },
      "source": [
        "Neat. Wouldn't get good grades on an Grammar test though. \n",
        "\n",
        "Now, let's turn uppercase letters into lowercase ones. Simple enough."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dcd5e02e-a8ff-5bf1-b784-39862254258c"
      },
      "outputs": [],
      "source": [
        "print(removeNonAlpha(test.lower()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fcf8c884-76ee-253f-efd1-0c52625a8837"
      },
      "source": [
        "We also split  the content into the individual words that compose each sentence. So instead of having one string that is a sentence, we turn the sentence into a list or array of words. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3009f9c8-e89d-3d09-5d7a-32219c6b27e9"
      },
      "outputs": [],
      "source": [
        "text = removeNonAlpha(test.lower())\n",
        "print (text.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e27aa6a-bd02-7cc6-3ef9-df7d630fc80c"
      },
      "source": [
        "*That's helpful!*  But what is not helpful is all these words that really have no meaning in the end of the day. Words like the, an, on, a , at, etc. They really don't give much meaning to the tags that we want to predict. These words are called 'stopwords' , and there is an easy way to remove them, using the stopwords from the nltk library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c6eadeb-b8b4-3e1d-bd72-e4097dfaf935"
      },
      "outputs": [],
      "source": [
        "sw =  set(stopwords.words(\"english\"))\n",
        "##Define a function to remove stopwords from a list of wards.\n",
        "def removeStopwords(wordlist):\n",
        "    filtered_words = [word for word in wordlist.split() if word not in sw]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "## Test the function\n",
        "print(removeStopwords(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cbfd09b-7703-d8d6-6673-90bc2d43a70c"
      },
      "source": [
        "To be continued..."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}