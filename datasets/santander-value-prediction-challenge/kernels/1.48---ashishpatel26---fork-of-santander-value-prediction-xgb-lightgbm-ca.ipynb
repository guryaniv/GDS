{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import *\nimport pandas as pd\nimport numpy as np\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ncol = [c for c in train.columns if c not in ['ID', 'target']]\nprint(train.shape, test.shape)\n\nscl = preprocessing.StandardScaler()\ndef rmsle(y, pred):\n    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(pred), 2)))\n\nx1, x2, y1, y2 = model_selection.train_test_split(train[col], train.target.values, test_size=0.10, random_state=5)\nmodel = ensemble.RandomForestRegressor(n_jobs = -1, random_state = 7)\nmodel.fit(scl.fit_transform(x1), y1)\nprint(rmsle(y2, model.predict(scl.transform(x2))))\ncol = pd.DataFrame({'importance': model.feature_importances_, 'feature': col}).sort_values(by=['importance'], ascending=[False])[:480]['feature'].values\n\ntest['target_lgb'] = 0.0\ntest['target_xgb'] = 0.0\nfolds = 5\nfor fold in range(folds):\n    x1, x2, y1, y2 = model_selection.train_test_split(train[col], np.log1p(train.target.values), test_size=0.20, random_state=fold)\n    #LightGBM\n    params = {'learning_rate': 0.02,'max_depth': 13,'reg_alpha':0.04,'reg_lambda':0.073,'boosting': 'gbdt','objective': 'regression','metric': 'rmse','is_training_metric': True, 'num_leaves': 12**2,'feature_fraction': 0.9,'bagging_fraction': 0.8, 'bagging_freq': 5,'min_split_gain':0.0222415,'min_child_weight':40,'subsample':0.8715623,'seed':fold,'silent':-1,'verbose':-1}\n    model = lgb.train(params, lgb.Dataset(x1, label=y1), 3000, lgb.Dataset(x2, label=y2), verbose_eval=200, early_stopping_rounds=100)\n    test['target_lgb'] += np.expm1(model.predict(test[col], num_iteration=model.best_iteration))\n    #XGB\n    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n    #https://www.kaggle.com/samratp/santander-value-prediction-xgb-and-lightgbm\n    params = {'objective': 'reg:linear', 'eval_metric': 'rmse', 'eta': 0.005, 'max_depth': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'alpha':0, 'silent': True, 'random_state':fold}\n    model = xgb.train(params, xgb.DMatrix(x1, y1), 5000,  watchlist, maximize=False, verbose_eval=200, early_stopping_rounds=100)\n    test['target_xgb'] += np.expm1(model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit))\n\ntest['target_lgb'] /= folds\ntest['target_xgb'] /= folds\ntest['target'] = (test['target_lgb'] + test['target_xgb'])/2\ntest[['ID', 'target']].to_csv('submission1.csv', index=False)","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/yekenot/baseline-with-decomposition-components\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA, TruncatedSVD, FastICA\nfrom sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\nfrom sklearn.model_selection import KFold\nfrom catboost import CatBoostRegressor\n\nprint(\"Load data...\")\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubm = pd.read_csv('../input/sample_submission.csv')\nprint(\"Train shape: {}\\nTest shape: {}\".format(train.shape, test.shape))\n\n#Added Columns from feature_selection\ntrain = train[['ID', 'target']+list(col)]\ntest = test[['ID']+list(col)]\nprint(\"Train shape: {}\\nTest shape: {}\".format(train.shape, test.shape))\n\nPERC_TRESHOLD = 0.98   ### Percentage of zeros in each feature ###\nN_COMP = 20            ### Number of decomposition components ###\n\ntarget = np.log1p(train['target']).values\ncols_to_drop = [col for col in train.columns[2:]\n                    if [i[1] for i in list(train[col].value_counts().items()) \n                    if i[0] == 0][0] >= train.shape[0] * PERC_TRESHOLD]\n\nprint(\"Define training features...\")\nexclude_other = ['ID', 'target']\ntrain_features = []\nfor c in train.columns:\n    if c not in cols_to_drop \\\n    and c not in exclude_other:\n        train_features.append(c)\nprint(\"Number of featuress for training: %s\" % len(train_features))\n\ntrain, test = train[train_features], test[train_features]\nprint(\"\\nTrain shape: {}\\nTest shape: {}\".format(train.shape, test.shape))\n\nprint(\"\\nStart decomposition process...\")\nprint(\"PCA\")\npca = PCA(n_components=N_COMP, random_state=17)\npca_results_train = pca.fit_transform(train)\npca_results_test = pca.transform(test)\n\nprint(\"tSVD\")\ntsvd = TruncatedSVD(n_components=N_COMP, random_state=17)\ntsvd_results_train = tsvd.fit_transform(train)\ntsvd_results_test = tsvd.transform(test)\n\nprint(\"ICA\")\nica = FastICA(n_components=N_COMP, random_state=17)\nica_results_train = ica.fit_transform(train)\nica_results_test = ica.transform(test)\n\nprint(\"GRP\")\ngrp = GaussianRandomProjection(n_components=N_COMP, eps=0.1, random_state=17)\ngrp_results_train = grp.fit_transform(train)\ngrp_results_test = grp.transform(test)\n\nprint(\"SRP\")\nsrp = SparseRandomProjection(n_components=N_COMP, dense_output=True, random_state=17)\nsrp_results_train = srp.fit_transform(train)\nsrp_results_test = srp.transform(test)\n\nprint(\"Append decomposition components to datasets...\")\nfor i in range(1, N_COMP + 1):\n    train['pca_' + str(i)] = pca_results_train[:, i - 1]\n    test['pca_' + str(i)] = pca_results_test[:, i - 1]\n\n    train['ica_' + str(i)] = ica_results_train[:, i - 1]\n    test['ica_' + str(i)] = ica_results_test[:, i - 1]\n\n    train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n    test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n\n    train['grp_' + str(i)] = grp_results_train[:, i - 1]\n    test['grp_' + str(i)] = grp_results_test[:, i - 1]\n\n    train['srp_' + str(i)] = srp_results_train[:, i - 1]\n    test['srp_' + str(i)] = srp_results_test[:, i - 1]\nprint('\\nTrain shape: {}\\nTest shape: {}'.format(train.shape, test.shape))\n\nprint('\\nModelling...')\ndef rmsle(y_true, y_pred):\n    assert len(y_true) == len(y_pred)\n    return np.sqrt(np.mean(np.power(np.log(y_true + 1) - np.log(y_pred + 1), 2)))\n\nfolds = KFold(n_splits=5, shuffle=True, random_state=546789)\noof_preds = np.zeros(train.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n    trn_x, trn_y = train.ix[trn_idx], target[trn_idx]\n    val_x, val_y = train.ix[val_idx], target[val_idx]\n    cb_model = CatBoostRegressor(iterations=1000, learning_rate=0.01, depth=8, l2_leaf_reg=20, bootstrap_type='Bernoulli',  eval_metric='RMSE', metric_period=50, od_type='Iter', od_wait=45, random_seed=17, allow_writing_files=False)\n    cb_model.fit(trn_x, trn_y, eval_set=(val_x, val_y), cat_features=[], use_best_model=True, verbose=True)\n    oof_preds[val_idx] = cb_model.predict(val_x)\n    sub_preds += cb_model.predict(test) / folds.n_splits\n    print(\"Fold %2d RMSLE : %.6f\" % (n_fold+1, rmsle(np.exp(val_y)-1, np.exp(oof_preds[val_idx])-1)))\n\nprint(\"Full RMSLE score %.6f\" % rmsle(np.exp(target)-1, np.exp(oof_preds)-1)) \nsubm['target'] = np.exp(sub_preds)-1\nsubm.to_csv('submission2.csv', index=False)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71939dbd81d27894570dfa4702781a93d0307b5e"},"cell_type":"code","source":"b1 = pd.read_csv('submission1.csv').rename(columns={'target':'dp1'})\nb2 = pd.read_csv('submission2.csv').rename(columns={'target':'dp2'})\nb1 = pd.merge(b1, b2, how='left', on='ID')\nb1['target'] = (b1['dp1'] * 0.5) + (b1['dp2'] * 0.5)\nb1[['ID','target']].to_csv('Submission_Santander.csv', index=False)\n#!kaggle competitions submit -c santander-value-prediction-challenge -f blend01.csv -m \"z02\"","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8063ffa4faf202e7940f7037fe5fb5eac69b3ad8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}