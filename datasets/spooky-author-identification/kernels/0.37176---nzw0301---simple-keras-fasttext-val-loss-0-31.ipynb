{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "5484dedb6db529f4dc58d0cb433186b3d823f429", "_cell_guid": "73969602-c633-450e-9364-9481a21a879c"}, "source": ["# **This notebook's best result: val_acc is 0.8779, val_loss is 0.3129**"]}, {"cell_type": "markdown", "metadata": {"_uuid": "7ccc3b4516a4fcde346a162ae4f9461016bbfbbf", "_cell_guid": "d5736ce6-a0b0-4cf0-beaf-a73837398da9"}, "source": ["# **1. Few Preprocessings**\n", "# **2. Model: FastText by Keras**\n", "## **2.1** Change Preprocessings:\n", "- Do lower case "]}, {"cell_type": "code", "metadata": {"_kg_hide-input": false, "_uuid": "b05ef71268db76a4e2565177bf6a5668a5fc428e", "collapsed": false, "_kg_hide-output": true, "_cell_guid": "93e00783-a024-4e87-a5e1-6709cb8cc981"}, "outputs": [], "execution_count": null, "source": ["import numpy as np\n", "\n", "import pandas as pd\n", "\n", "from collections import defaultdict\n", "\n", "import keras\n", "import keras.backend as K\n", "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n", "from keras.callbacks import EarlyStopping\n", "from keras.models import Sequential\n", "from keras.preprocessing.sequence import pad_sequences\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.utils import to_categorical\n", "\n", "from sklearn.model_selection import train_test_split\n", "\n", "np.random.seed(7)"]}, {"cell_type": "code", "metadata": {"_uuid": "d700f739101e37903112e1de293323dcfbb577be", "collapsed": true, "_cell_guid": "a5cc2c3e-7960-482e-b548-c447b89925ec"}, "outputs": [], "execution_count": null, "source": ["df = pd.read_csv('./../input/train.csv')\n", "a2c = {'EAP': 0, 'HPL' : 1, 'MWS' : 2}\n", "y = np.array([a2c[a] for a in df.author])\n", "y = to_categorical(y)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "a01bab31ed7b8a55820612063576963488d99eb6", "_cell_guid": "a45cb3ba-d1bc-48e0-956c-27d0f49a9943"}, "source": ["# 1. **Few Preprocessings**\n", "\n", "In traditional NLP tasks, preprocessings play an important role, but...\n", "\n", "## **Low-frequency words**\n", "In my experience, fastText is very fast, but I need to delete rare words to avoid overfitting.\n", "\n", "**NOTE**:\n", "Some keywords are rare words, such like *Cthulhu* in *Cthulhu Mythos* of *Howard Phillips Lovecraft*.\n", "But these are useful for this task.\n", "\n", "## **Removing Stopwords**\n", "\n", "Nothing.\n", "To identify author from a sentence, some stopwords play an important role because one has specific usages of them.\n", "\n", "## **Stemming and Lowercase**\n", "\n", "Nothing.\n", "This reason is the same for stopwords removing.\n", "And I guess some stemming rules provided by libraries is bad for this task because all author is the older author.\n", "\n", "## **Cutting long sentence**\n", "\n", "Too long documents are cut.\n", "\n", "## **Punctuation**\n", "\n", "Because I guess each author has unique punctuations's usage in the novel, I separate them from words.\n", "\n", "e.g. `Don't worry` -> `Don ' t worry`\n", "\n", "## **Is it slow?**\n", "\n", "Don't worry! FastText is a very fast algorithm if it runs on CPU. "]}, {"cell_type": "markdown", "metadata": {"_uuid": "0023cd1542d866d931deb8472f8a0d6fb0262d9a", "_cell_guid": "8182b25a-f490-4b41-9865-ee1c04afecee"}, "source": ["# **Let's check character distribution per author**"]}, {"cell_type": "code", "metadata": {"_uuid": "246a428ca3a063294c15c8c08d234ecf01e4ddbb", "collapsed": false, "_kg_hide-output": true, "_cell_guid": "c1d00b0d-90e0-4f19-842c-51a82de42a10"}, "outputs": [], "execution_count": null, "source": ["counter = {name : defaultdict(int) for name in set(df.author)}\n", "for (text, author) in zip(df.text, df.author):\n", "    text = text.replace(' ', '')\n", "    for c in text:\n", "        counter[author][c] += 1\n", "\n", "chars = set()\n", "for v in counter.values():\n", "    chars |= v.keys()\n", "    \n", "names = [author for author in counter.keys()]\n", "\n", "print('c ', end='')\n", "for n in names:\n", "    print(n, end='   ')\n", "print()\n", "for c in chars:    \n", "    print(c, end=' ')\n", "    for n in names:\n", "        print(counter[n][c], end=' ')\n", "    print()\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "8e72d6f22587780364ed24cae13ece4a403479dd", "_cell_guid": "7a3fdf4e-039d-4c93-bc21-9bad7dfc6ff8"}, "source": ["# **Summary of character distribution**\n", "\n", "- HPL and EAP used non ascii characters like a `\u00e4`.\n", "- The number of punctuations seems to be good feature\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "fee49fd9139b78ae03603d7d37eafa38f3cb29dc", "_cell_guid": "ce97fc0a-b85c-4f34-92c5-ae66a0730ace"}, "source": ["# **Preprocessing**\n", "\n", "My preproceeings are \n", "\n", "- Separate punctuation from words\n", "- Remove lower frequency words ( <= 2)\n", "- Cut a longer document which contains `256` words"]}, {"cell_type": "code", "metadata": {"_uuid": "999012010cd8b9b20d3c5b16c11a2374a5ce44c0", "collapsed": true, "_cell_guid": "72ff2ff5-0945-4f39-8b02-39e4d5df16c5"}, "outputs": [], "execution_count": null, "source": ["def preprocess(text):\n", "    text = text.replace(\"' \", \" ' \")\n", "    signs = set(',.:;\"?!')\n", "    prods = set(text) & signs\n", "    if not prods:\n", "        return text\n", "\n", "    for sign in prods:\n", "        text = text.replace(sign, ' {} '.format(sign) )\n", "    return text"]}, {"cell_type": "code", "metadata": {"_uuid": "53f325a090a44f7109f0537022398797704cdc80", "collapsed": true, "_cell_guid": "f123742f-540f-438d-aba3-ebbca69235be"}, "outputs": [], "execution_count": null, "source": ["def create_docs(df, n_gram_max=2):\n", "    def add_ngram(q, n_gram_max):\n", "            ngrams = []\n", "            for n in range(2, n_gram_max+1):\n", "                for w_index in range(len(q)-n+1):\n", "                    ngrams.append('--'.join(q[w_index:w_index+n]))\n", "            return q + ngrams\n", "        \n", "    docs = []\n", "    for doc in df.text:\n", "        doc = preprocess(doc).split()\n", "        docs.append(' '.join(add_ngram(doc, n_gram_max)))\n", "    \n", "    return docs"]}, {"cell_type": "code", "metadata": {"_uuid": "150f9f6643e6753386b2021ac812ecc0cac66202", "collapsed": true, "_cell_guid": "888047de-806e-4ad2-9fff-18b4d6583d30"}, "outputs": [], "execution_count": null, "source": ["min_count = 2\n", "\n", "docs = create_docs(df)\n", "tokenizer = Tokenizer(lower=False, filters='')\n", "tokenizer.fit_on_texts(docs)\n", "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n", "\n", "tokenizer = Tokenizer(num_words=num_words, lower=False, filters='')\n", "tokenizer.fit_on_texts(docs)\n", "docs = tokenizer.texts_to_sequences(docs)\n", "\n", "maxlen = 256\n", "\n", "docs = pad_sequences(sequences=docs, maxlen=maxlen)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b9e353b548b0dfbd4b42a40d8a2643efeb359a20", "_cell_guid": "f9ebc033-2a26-4656-9472-8990c1a27c79"}, "source": ["# **2. Model: FastText by Keras**\n", "\n", "FastText is very fast and strong baseline algorithm for text classification based on Continuous Bag-of-Words model a.k.a Word2vec.\n", "\n", "FastText contains only three layers:\n", "\n", "1. Embeddings layer: Input words (and word n-grams) are all words in a sentence/document\n", "2. Mean/AveragePooling Layer: Taking average vector of Embedding vectors\n", "3. Softmax layer\n", "\n", "There are some implementations of FastText:\n", "\n", "- Original library provided by Facebook AI research: https://github.com/facebookresearch/fastText\n", "- Keras: https://github.com/fchollet/keras/blob/master/examples/imdb_fasttext.py\n", "- Gensim: https://radimrehurek.com/gensim/models/wrappers/fasttext.html\n", "\n", "Original Paper: https://arxiv.org/abs/1607.01759 : More detail information about fastText classification model"]}, {"cell_type": "markdown", "metadata": {"_uuid": "8b56b2ef90e519b939b7bf9ec5a146f749807b02", "_cell_guid": "636eb75e-6fba-413e-996d-1395609b422c"}, "source": ["# My FastText parameters are:\n", "\n", "- The dimension of word vector is 20\n", "- Optimizer is `Adam`\n", "- Inputs are words and word bi-grams\n", "  - you can change this parameter by passing the max n-gram size to argument of `create_docs` function.\n"]}, {"cell_type": "code", "metadata": {"_uuid": "bba1d1a6416876e74ed688f56e4d5bc4990ec12a", "collapsed": true, "_cell_guid": "393d1ddb-0a87-42a3-8575-53ff7abff1da"}, "outputs": [], "execution_count": null, "source": ["input_dim = np.max(docs) + 1\n", "embedding_dims = 20"]}, {"cell_type": "code", "metadata": {"_uuid": "e6c16572e6b32923af39dfd29467e32b52561bb1", "collapsed": true, "_cell_guid": "2e3e1e3e-22f4-4727-ba6c-67f7b3e80d2f"}, "outputs": [], "execution_count": null, "source": ["def create_model(embedding_dims=20, optimizer='adam'):\n", "    model = Sequential()\n", "    model.add(Embedding(input_dim=input_dim, output_dim=embedding_dims))\n", "    model.add(GlobalAveragePooling1D())\n", "    model.add(Dense(3, activation='softmax'))\n", "\n", "    model.compile(loss='categorical_crossentropy',\n", "                  optimizer=optimizer,\n", "                  metrics=['accuracy'])\n", "    return model"]}, {"cell_type": "code", "metadata": {"scrolled": true, "collapsed": false, "_kg_hide-output": true, "_cell_guid": "0db889db-0b3e-4025-8847-e3eb5f853f37", "_kg_hide-input": false, "_uuid": "22e57e010206a3044adf7b82160c7c3ca78030f8"}, "outputs": [], "execution_count": null, "source": ["epochs = 25\n", "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n", "\n", "model = create_model()\n", "hist = model.fit(x_train, y_train,\n", "                 batch_size=16,\n", "                 validation_data=(x_test, y_test),\n", "                 epochs=epochs,\n", "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### **Result**\n", "\n", "- Best val_loss is 0.3409\n", "- Best val_acc is 0.8700\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# **2.1 Change Preprocessings**\n", "\n", "Next, I change some parameters and preprocessings to improve fastText model.\n", "## **2.1.1 Do lower case**"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "source": ["docs = create_docs(df)\n", "tokenizer = Tokenizer(lower=True, filters='')\n", "tokenizer.fit_on_texts(docs)\n", "num_words = sum([1 for _, v in tokenizer.word_counts.items() if v >= min_count])\n", "\n", "tokenizer = Tokenizer(num_words=num_words, lower=True, filters='')\n", "tokenizer.fit_on_texts(docs)\n", "docs = tokenizer.texts_to_sequences(docs)\n", "\n", "maxlen = 256\n", "\n", "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n", "\n", "input_dim = np.max(docs) + 1"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "execution_count": null, "source": ["epochs = 16\n", "x_train, x_test, y_train, y_test = train_test_split(docs, y, test_size=0.2)\n", "\n", "model = create_model()\n", "hist = model.fit(x_train, y_train,\n", "                 batch_size=16,\n", "                 validation_data=(x_test, y_test),\n", "                 epochs=epochs,\n", "                 callbacks=[EarlyStopping(patience=2, monitor='val_loss')])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Result**\n", "\n", "- Best val_loss is 0.3129\n", "- Best val_acc is 0.8787"]}, {"cell_type": "code", "metadata": {"collapsed": false}, "outputs": [], "execution_count": null, "source": ["test_df = pd.read_csv('../input/test.csv')\n", "docs = create_docs(test_df)\n", "docs = tokenizer.texts_to_sequences(docs)\n", "docs = pad_sequences(sequences=docs, maxlen=maxlen)\n", "y = model.predict_proba(docs)\n", "\n", "result = pd.read_csv('../input/sample_submission.csv')\n", "for a, i in a2c.items():\n", "    result[a] = y[:, i]\n"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "source": ["result.to_csv('fastText_result.csv', index=False)"]}, {"cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "source": []}]}