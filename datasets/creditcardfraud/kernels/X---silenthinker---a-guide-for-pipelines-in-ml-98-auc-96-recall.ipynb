{"cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Credit card fraud detection\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["In this kernel, we will explore the credit card transaction [data](https://www.kaggle.com/dalpozz/creditcardfraud) and detect frauds using classification models. The kernel also demonstrates the basic pipeline of data analysis and modeling."]}, {"metadata": {}, "cell_type": "markdown", "source": ["**TODO**\n", "1. Evaluate different models, including XGBoost, LightGBM\n", "2. Tune hyperparameters using Hyperopt\n", "3. Try stacking, using StackNet"]}, {"metadata": {"collapsed": true}, "source": ["%matplotlib inline\n", "import os\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from imblearn.combine import SMOTEENN \n", "\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import roc_auc_score\n", "\n", "np.random.seed(5)"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {}, "cell_type": "markdown", "source": ["## 1. Obtain the data\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["The [datasets](https://www.kaggle.com/dalpozz/creditcardfraud) contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions."]}, {"metadata": {"collapsed": true}, "source": ["# Load csv data to data frame\n", "file_path = '../input/creditcard.csv'\n", "df = pd.read_csv(file_path, sep=\",\")"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {}, "cell_type": "markdown", "source": ["## 2. Scrub the data\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We need to clean the data if there is some missing value or outlier."]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 2.1. Take a look at the data\n", "---"]}, {"metadata": {}, "source": ["df.head()"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {}, "cell_type": "markdown", "source": ["### 2.2. Move Class to the front of the data frame\n", "---"]}, {"metadata": {}, "source": ["class_ = df.Class # since class is preserved in Python, use class_ instead\n", "df.drop('Class', axis=1, inplace=True)\n", "df.insert(0, 'Class', class_)\n", "df.head()"], "cell_type": "code", "outputs": [], "execution_count": 5}, {"metadata": {}, "cell_type": "markdown", "source": ["### 2.3. Check missing values\n", "---"]}, {"metadata": {}, "source": ["df.isnull().any()"], "cell_type": "code", "outputs": [], "execution_count": 6}, {"metadata": {}, "cell_type": "markdown", "source": ["The data is clean. Go ahead to explore the data."]}, {"metadata": {}, "cell_type": "markdown", "source": ["## 3. Explore the data\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["In this section, we try to answer to these questions:\n", "* How many data points are there?\n", "* How many features are there?\n", "* What are their respective types?\n", "* How many classes are there and what are their counts?\n", "* What are descriptive statistics of the data?\n", "* What are the relations between the class and features, as well as between one feature and another?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 3.1. Statistical overview\n", "---"]}, {"metadata": {}, "source": ["df.shape"], "cell_type": "code", "outputs": [], "execution_count": 7}, {"metadata": {}, "cell_type": "markdown", "source": ["There are 284807 rows and 31 features, including one column of dependent variable, namely, 'Class'."]}, {"metadata": {}, "source": ["df.dtypes"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {}, "source": ["fraud_rate = df.Class.value_counts() / df.shape[0]\n", "fraud_rate"], "cell_type": "code", "outputs": [], "execution_count": 9}, {"metadata": {}, "cell_type": "markdown", "source": ["There are two classes, 0 for normal and 1 for fraud. According to the count, two classes are extremely imbalanced, with only 0.1727% are frauds."]}, {"metadata": {}, "source": ["df.describe()"], "cell_type": "code", "outputs": [], "execution_count": 10}, {"metadata": {}, "cell_type": "markdown", "source": ["Features V1, V2, ..., V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Therefore, there is little need to further infer something from these transformed features. One observation is that V1 to V28 are roughly centered while 'Amount' does not follow the similar statistical pattern. It might be sensible to conduct preprocessing on features such as standarization to facilitate machine learning approaches."]}, {"metadata": {}, "source": ["# Overview of fraud and normal transactions\n", "fraud_summary = df.groupby('Class')\n", "fraud_summary.mean().T"], "cell_type": "code", "outputs": [], "execution_count": 11}, {"metadata": {}, "cell_type": "markdown", "source": ["For V1, V2, ..., V28, a difference in mean value with respect to two classes can be observed: these features have mean values of opposite sign for two classes. This might indicate a difference in data distribution for each class.  "]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 3.2. Correlation matrix\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We now explore the relationship between one variable and another using correlation matrix."]}, {"metadata": {}, "source": ["corr = df.corr()\n", "# plot heat map\n", "fig, ax = plt.subplots()\n", "# the size of A4 paper\n", "fig.set_size_inches(11.7, 8.27)\n", "sns.heatmap(corr, \n", "            xticklabels=corr.columns.values,\n", "            yticklabels=corr.columns.values,\n", "            ax = ax,\n", "            cmap='YlGnBu')\n", "plt.title('Heatmap of Correlation Matrix')"], "cell_type": "code", "outputs": [], "execution_count": 12}, {"metadata": {}, "source": ["corr"], "cell_type": "code", "outputs": [], "execution_count": 13}, {"metadata": {}, "cell_type": "markdown", "source": ["### 3.3. Statistical test for correlation\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["A one-sample t-test checks whether a sample mean differs from the population mean. Let us test to see whether the average amount of transaction classified as fraud differs from the entire population."]}, {"metadata": {}, "source": ["amount_population = df.Amount.mean()\n", "amount_fraud = df[df.Class == 1].Amount.mean()\n", "print('mean amount of population: {}, mean amount of fraud transaction: {}'.format(amount_population, amount_fraud))"], "cell_type": "code", "outputs": [], "execution_count": 14}, {"metadata": {}, "source": ["import scipy.stats as stats\n", "stats.ttest_1samp(a=df[df['Class']==1]['Amount'], \n", "                  popmean=amount_population)"], "cell_type": "code", "outputs": [], "execution_count": 15}, {"metadata": {}, "cell_type": "markdown", "source": ["If the t-statistic value we calculated above is outside the quantiles, then we can reject the null hypothesis"]}, {"metadata": {}, "source": ["degree_freedom = len(df[df['Class']==1])\n", "conf_level = 0.95\n", "\n", "LQ = stats.t.ppf((1-conf_level)/2,degree_freedom)  # Left Quartile\n", "\n", "RQ = stats.t.ppf((1+conf_level)/2,degree_freedom)  # Right Quartile\n", "\n", "print ('The t-distribution left quartile range is: ' + str(LQ))\n", "print ('The t-distribution right quartile range is: ' + str(RQ))"], "cell_type": "code", "outputs": [], "execution_count": 16}, {"metadata": {}, "cell_type": "markdown", "source": ["The result shows that we should reject the null hypothesis that the average amount of transaction classified as fraud is the same as that of population, since the t-statistic value is outside the 95% confidence interval."]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 3.4. Distribution plots\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We explore data distribution through various approaches of visualization."]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 3.4.0. Visualizing pairwise relationships in a dataset"]}, {"metadata": {}, "source": ["# For computational efficiency, only visualize pairwise relationships among several features, \n", "# including two principal components\n", "sns.pairplot(df.loc[:, ['Class', 'Amount', 'Time', 'V1', 'V2']], hue='Class')"], "cell_type": "code", "outputs": [], "execution_count": 17}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 3.4.1. Class vs Amount"]}, {"metadata": {}, "source": ["# Kernel Density Plot\n", "fig = plt.figure(figsize=(16,9),)\n", "ax=sns.kdeplot(df.loc[(df['Class'] == 0), 'Amount'] , color='b', shade=True,label='normal transaction')\n", "ax=sns.kdeplot(df.loc[(df['Class'] == 1), 'Amount'] , color='r', shade=True, label='fraud transaction')\n", "plt.title('Transaction amount distribution - normal V.S. fraud')"], "cell_type": "code", "outputs": [], "execution_count": 18}, {"metadata": {}, "cell_type": "markdown", "source": ["The distribution of the amount of fraud is long-tailed."]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 3.4.2. Class vs Time"]}, {"metadata": {}, "source": ["# Kernel Density Plot\n", "fig = plt.figure(figsize=(16,9),)\n", "ax=sns.kdeplot(df.loc[(df['Class'] == 0), 'Time'] , color='b', shade=True,label='normal transaction')\n", "ax=sns.kdeplot(df.loc[(df['Class'] == 1), 'Time'] , color='r', shade=True, label='fraud transaction')\n", "plt.title('Transaction time distribution - normal V.S. fraud')"], "cell_type": "code", "outputs": [], "execution_count": 19}, {"metadata": {}, "cell_type": "markdown", "source": ["There is a bi-modal distribution for time of normal transactions. The distribution pattern corresponds well to the problem description which states the transactions in dataset occur in two days: two ridges correspond to frequent transactions in the daytime while the trough corresponds to infrequent ones during night."]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 3.4.3. Time vs Amount"]}, {"metadata": {}, "source": ["sns.lmplot(x='Time', y='Amount', data=df,\n", "           fit_reg=False, # No regression line\n", "           hue='Class')   # Color by evolution stage"], "cell_type": "code", "outputs": [], "execution_count": 20}, {"metadata": {}, "cell_type": "markdown", "source": ["Frauds are evenly distributed along the time."]}, {"metadata": {}, "cell_type": "markdown", "source": ["We can also visualize this bivariate distribution using a scatterplot with histogram."]}, {"metadata": {}, "source": ["sns.jointplot(x='Time', y='Amount', data=df[df['Class']==0], color='b')\n", "sns.jointplot(x='Time', y='Amount', data=df[df['Class']==1], color='r')"], "cell_type": "code", "outputs": [], "execution_count": 21}, {"metadata": {}, "cell_type": "markdown", "source": ["## 4. Classification\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 4.1. Prepare train data and test data (with stratified sampling)\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["When dealing with imbalanced cases, it is often advantageous to sample each subpopulation (stratum) independently."]}, {"metadata": {"collapsed": true}, "source": ["from sklearn.model_selection import StratifiedShuffleSplit\n", "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=5)\n", "X = df.drop(['Class', 'Time'], axis=1)\n", "X = StandardScaler().fit_transform(X.values)\n", "y = df['Class'].values\n", "for train_index, test_index in sss.split(X, y):\n", "    X_train_ = X[train_index, :]\n", "    y_train_ = y[train_index]\n", "    X_test = X[test_index, :]\n", "    y_test = y[test_index]"], "cell_type": "code", "outputs": [], "execution_count": 22}, {"metadata": {}, "cell_type": "markdown", "source": ["Verify if the dataset is well stratified:"]}, {"metadata": {}, "source": ["y_train_pos = y_train_[y_train_ == 1]\n", "y_test_pos = y_test[y_test == 1]\n", "print('# positive in train data: {}, {}%'.format(y_train_pos.shape[0], y_train_pos.shape[0]*100. / y_train_.shape[0]))\n", "print('# positive in test data: {}, {}%'.format(y_test_pos.shape[0], y_test_pos.shape[0]*100. / y_test.shape[0]))"], "cell_type": "code", "outputs": [], "execution_count": 23}, {"metadata": {}, "cell_type": "markdown", "source": ["### 4.2. Build a helpful function for cross validation\n", "---"]}, {"metadata": {}, "cell_type": "markdown", "source": ["In order to facilitate model selection and further processing, we can create a helpful function to conduct cross validation and parameter tuning. We select optimal parameters based on recall metric. In addition, we allow the option of using [SMOTE](http://contrib.scikit-learn.org/imbalanced-learn/stable/generated/imblearn.over_sampling.SMOTE.html), an imbalanced learning tool, to boost performance in imbalanced datasets."]}, {"metadata": {"collapsed": true}, "source": ["from sklearn.metrics import roc_auc_score\n", "from sklearn.metrics import recall_score\n", "from sklearn.model_selection import StratifiedKFold\n", "\n", "def kfold_cv(Model, X, y, n_splits=10, smote=False, verbose=False):\n", "    \"\"\"\n", "    Args:\n", "        model: object that has fit, predict_proba methods\n", "        X: array\n", "        y: array\n", "        n_splits: number of splits\n", "    \"\"\"\n", "    skf = StratifiedKFold(n_splits, random_state=5, shuffle=True)\n", "    C = np.logspace(-3, 3, num=7, base=10)\n", "    def sub_cv(model):\n", "        kfold = skf.split(X, y)\n", "        scores = 0\n", "        recall = 0\n", "        if smote:\n", "            sme = SMOTEENN(random_state=5)\n", "        i = 0\n", "        for train_index, test_index in kfold:\n", "            X_train_ = X[train_index, :]\n", "            y_train_ = y[train_index]\n", "            X_test = X[test_index, :]\n", "            y_test = y[test_index]\n", "            if smote:\n", "                X_train, y_train = sme.fit_sample(X_train_, y_train_)\n", "            else:\n", "                X_train = X_train_\n", "                y_train = y_train_\n", "            model.fit(X_train, y_train)\n", "            y_pred = model.predict(X_test)\n", "            y_score = model.predict_proba(X_test)[:, 1]\n", "            score = roc_auc_score(y_test, y_score, average='micro')\n", "            if verbose:\n", "                print('Trained {} th model, AUC score: {}'.format(i+1, score))\n", "            scores += score\n", "            recall += recall_score(y_test, y_pred)\n", "            i += 1\n", "        return scores / i, recall / i\n", "    bestC = 0\n", "    bestauc = 0\n", "    bestrecall = 0\n", "    for c in C:\n", "        model = Model(class_weight='balanced', C=c)\n", "        auc, recall = sub_cv(model)\n", "        if recall > bestrecall:\n", "            bestauc = auc\n", "            bestC = c\n", "            bestrecall = recall\n", "        print('C: {}, AUC: {}, recall: {}, best C: {}'.format(c, auc, recall, bestC))\n", "    return bestC, bestauc, bestrecall"], "cell_type": "code", "outputs": [], "execution_count": 24}, {"metadata": {}, "cell_type": "markdown", "source": ["### 4.3. Baseline: logistic regression with balanced class weight\n", "---"]}, {"metadata": {}, "source": ["Model = LogisticRegression\n", "bestC, bestauc, bestrecall = kfold_cv(Model, X_train_, y_train_, n_splits=5, verbose=False)\n", "print('Best C: {}'.format(bestC))"], "cell_type": "code", "outputs": [], "execution_count": 25}, {"metadata": {}, "source": ["baseline = Model(class_weight='balanced', C=bestC)\n", "baseline.fit(X_train_, y_train_)\n", "y_pred = baseline.predict(X_test)\n", "y_score = baseline.predict_proba(X_test)[:, 1]\n", "auc = roc_auc_score(y_test, y_score, average='micro')\n", "recall = recall_score(y_test, y_pred)\n", "print('AUC: {}, recall: {}'.format(auc, recall))"], "cell_type": "code", "outputs": [], "execution_count": 26}, {"metadata": {}, "cell_type": "markdown", "source": ["### 4.4 Compare different strategies to balance data\n", "---\n", "1. Use class_weight in logistic regression (already done)\n", "2. Naively undersample majority class\n", "3. Use imbalanced learning: smote"]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 4.4.1. Naively undersample majority class\n", "Undersample the data so that it has comparable number of data points for each class. First, create a helpful function for conducting undersampling."]}, {"metadata": {"collapsed": true}, "source": ["def undersample(X_train_, y_train_, n_major):\n", "    \"\"\"\n", "    In y_train_, positive class is far fewer than negative one.\n", "    \"\"\"\n", "    X_train_pos = X_train_[y_train_ == 1]\n", "    X_train_neg = X_train_[y_train_ == 0]\n", "    y_train_pos = y_train_[y_train_ == 1]\n", "    y_train_neg = y_train_[y_train_ == 0]\n", "    undersample_y_train_neg_index = np.random.choice(y_train_neg.shape[0], n_major, replace=False)\n", "    undersample_y_train_ = np.concatenate((y_train_pos, y_train_neg[undersample_y_train_neg_index]), axis=0)\n", "    undersample_X_train_ = np.concatenate((X_train_pos, X_train_neg[undersample_y_train_neg_index]), axis=0)\n", "    indices = np.arange(undersample_X_train_.shape[0])\n", "    np.random.shuffle(indices)\n", "    return undersample_X_train_[indices, :], undersample_y_train_[indices]"], "cell_type": "code", "outputs": [], "execution_count": 27}, {"metadata": {}, "cell_type": "markdown", "source": ["We evaluate the effect of undersampling by varying number of data points belonging to normal transaction."]}, {"metadata": {}, "source": ["n_majority = np.arange(1, 50, 10) * y_train_pos.shape[0]\n", "res = pd.DataFrame(data=np.zeros((len(n_majority), 3)), columns=['best_c', 'auc', 'recall'])\n", "for i, n_major in enumerate(n_majority):\n", "    undersample_X_train_, undersample_y_train_ = undersample(X_train_, y_train_, n_major)\n", "    bestC, auc, recall = kfold_cv(Model, undersample_X_train_, undersample_y_train_, n_splits=5)\n", "    res.loc[i, 'best_c'] = bestC\n", "    res.loc[i, 'auc'] = auc\n", "    res.loc[i, 'recall'] = recall\n", "    print('undersample number: {}, best C: {}'.format(n_major, bestC))"], "cell_type": "code", "outputs": [], "execution_count": 28}, {"metadata": {}, "source": ["res['maj_class_num'] = n_majority\n", "res"], "cell_type": "code", "outputs": [], "execution_count": 29}, {"metadata": {}, "source": ["fig = plt.figure(figsize=(16, 9))\n", "plt.plot(res['maj_class_num'], res['auc'], 'b', label='AUC')\n", "plt.plot(res['maj_class_num'], res['recall'], 'r', label='Recall')\n", "plt.xlabel('maj_class_num')\n", "plt.legend()\n", "plt.grid()\n", "plt.title('AUC and recall of logistic regression with balanced class weight trained on undersampled majority class of different numbers')\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": 30}, {"metadata": {}, "cell_type": "markdown", "source": ["Note that the more imbalanced the data, the lower recall metric tends to be."]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 4.4.2. Use imbalanced learning: SMOTE"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Here, we combine undersampling with SMOTE."]}, {"metadata": {}, "source": ["# Applying SMOTE on the entire training data set is really time-consuming. \n", "# Uncomment the following lines to evaluate effect of SMOTE on entire training data.\n", "'''\n", "model = LogisticRegression\n", "auc, recall = kfold_cv(model, X_train_, y_train_, n_splits=10, smote=True, verbose=True)\n", "print('AUC score: {}, recall: {}'.format(auc, recall))\n", "'''"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {}, "source": ["n_majority = np.arange(1, 50, 10) * y_train_pos.shape[0]\n", "res = pd.DataFrame(data=np.zeros((len(n_majority), 3)), columns=['best_c', 'auc', 'recall'])\n", "for i, n_major in enumerate(n_majority):\n", "    undersample_X_train_, undersample_y_train_ = undersample(X_train_, y_train_, n_major)\n", "    bestC, auc, recall = kfold_cv(Model, undersample_X_train_, undersample_y_train_, n_splits=5, smote=True, verbose=False)\n", "    res.loc[i, 'best_c'] = bestC\n", "    res.loc[i, 'auc'] = auc\n", "    res.loc[i, 'recall'] = recall\n", "    print('undersample number: {}, best C: {}'.format(n_major, bestC))\n", "res['maj_class_num'] = n_majority\n", "print(res)\n", "fig = plt.figure(figsize=(16, 9))\n", "plt.plot(res['maj_class_num'], res['auc'], 'b', label='AUC')\n", "plt.plot(res['maj_class_num'], res['recall'], 'r', label='Recall')\n", "plt.xlabel('maj_class_num')\n", "plt.legend()\n", "plt.grid()\n", "plt.title('AUC and recall of logistic regression with balanced class weight trained on undersampled majority class of different numbers and smoted data')\n", "plt.show()"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["There seems to be no obvious difference in performance when applying SMOTE."]}, {"metadata": {}, "cell_type": "markdown", "source": ["#### 4.4.3. Final evaluation on test data\n", "Train model on undersampled data with optimal parameters. Evaluate model on test data set."]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### 4.4.3.1. Logistic regression with balanced class weight, undersampled training data"]}, {"metadata": {"collapsed": true}, "source": ["bestmodel = LogisticRegression(class_weight='balanced', C=0.001)\n", "undersample_X_train_, undersample_y_train_ = undersample(X_train_, y_train_, y_train_pos.shape[0])\n", "bestmodel.fit(undersample_X_train_, undersample_y_train_)\n", "y_pred = bestmodel.predict(X_test)\n", "y_score = bestmodel.predict_proba(X_test)[:, 1]\n", "auc = roc_auc_score(y_test, y_score, average='micro')\n", "recall = recall_score(y_test, y_pred)\n", "print('AUC: {}, recall: {}'.format(auc, recall))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["##### 4.4.3.2. Logistic regression with balanced class weight, undersampled training data, and smote processing"]}, {"metadata": {"collapsed": true}, "source": ["bestmodel = LogisticRegression(class_weight='balanced', C=0.001)\n", "undersample_X_train_, undersample_y_train_ = undersample(X_train_, y_train_, y_train_pos.shape[0])\n", "sme = SMOTEENN(random_state=5)\n", "X_res, y_res = sme.fit_sample(undersample_X_train_, undersample_y_train_)\n", "bestmodel.fit(X_res, y_res)\n", "y_pred = bestmodel.predict(X_test)\n", "y_score = bestmodel.predict_proba(X_test)[:, 1]\n", "auc = roc_auc_score(y_test, y_score, average='micro')\n", "recall = recall_score(y_test, y_pred)\n", "print('AUC: {}, recall: {}'.format(auc, recall))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["## 5. Summary"]}, {"metadata": {}, "cell_type": "markdown", "source": ["1. We explore data through various statistical analysis and visualization.\n", "2. Compared to naively using the entire imbalanced training data, undersampling can greatly boost performance. AUC increases from 0.9771 to 0.9798 while recall increases from 0.9082 to 0.9592. \n", "3. SMOTE is not significant in this case in contrast to undersampling."]}], "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}