{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f0587cf-7722-1b77-566f-b2606c9cce94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import operator\n",
        "import math\n",
        "from scipy import sparse\n",
        "import xgboost as xgb\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def add_features(df):\n",
        "    fmt = lambda s: s.replace(\"\\u00a0\", \"\").strip().lower()\n",
        "    df[\"photo_count\"] = df[\"photos\"].apply(len)\n",
        "    df[\"street_address\"] = df['street_address'].apply(fmt)\n",
        "    df[\"display_address\"] = df[\"display_address\"].apply(fmt)\n",
        "    df[\"desc_wordcount\"] = df[\"description\"].apply(str.split).apply(len)\n",
        "    df[\"pricePerBed\"] = df['price'] / df['bedrooms']\n",
        "    df[\"pricePerBath\"] = df['price'] / df['bathrooms']\n",
        "    df[\"pricePerRoom\"] = df['price'] / (df['bedrooms'] + df['bathrooms'])\n",
        "    df[\"bedPerBath\"] = df['bedrooms'] / df['bathrooms']\n",
        "    df[\"bedBathDiff\"] = df['bedrooms'] - df['bathrooms']\n",
        "    df[\"bedBathSum\"] = df[\"bedrooms\"] + df['bathrooms']\n",
        "    df[\"bedsPerc\"] = df[\"bedrooms\"] / (df['bedrooms'] + df['bathrooms'])\n",
        "\n",
        "    df = df.fillna(-1).replace(np.inf, -1)\n",
        "    return df\n",
        "\n",
        "\n",
        "def factorize(df1, df2, column):\n",
        "    ps = df1[column].append(df2[column])\n",
        "    factors = ps.factorize()[0]\n",
        "    df1[column] = factors[:len(df1)]\n",
        "    df2[column] = factors[len(df1):]\n",
        "    return df1, df2\n",
        "\n",
        "\n",
        "def designate_single_observations(df1, df2, column):\n",
        "    ps = df1[column].append(df2[column])\n",
        "    grouped = ps.groupby(ps).size().to_frame().rename(columns={0: \"size\"})\n",
        "    df1.loc[df1.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
        "    df2.loc[df2.join(grouped, on=column, how=\"left\")[\"size\"] <= 1, column] = -1\n",
        "    return df1, df2\n",
        "\n",
        "\n",
        "def hcc_encode(train_df, test_df, variable, target, prior_prob, k, f=1, g=1, r_k=None, update_df=None):\n",
        "    \"\"\"\n",
        "    See \"A Preprocessing Scheme for High-Cardinality Categorical Attributes in\n",
        "    Classification and Prediction Problems\" by Daniele Micci-Barreca\n",
        "    \"\"\"\n",
        "    hcc_name = \"_\".join([\"hcc\", variable, target])\n",
        "\n",
        "    grouped = train_df.groupby(variable)[target].agg({\"size\": \"size\", \"mean\": \"mean\"})\n",
        "    grouped[\"lambda\"] = 1 / (g + np.exp((k - grouped[\"size\"]) / f))\n",
        "    grouped[hcc_name] = grouped[\"lambda\"] * grouped[\"mean\"] + (1 - grouped[\"lambda\"]) * prior_prob\n",
        "\n",
        "    df = test_df[[variable]].join(grouped, on=variable, how=\"left\")[hcc_name].fillna(prior_prob)\n",
        "    if r_k: df *= np.random.uniform(1 - r_k, 1 + r_k, len(test_df))     # Add uniform noise. Not mentioned in original paper\n",
        "\n",
        "    if update_df is None: update_df = test_df\n",
        "    if hcc_name not in update_df.columns: update_df[hcc_name] = np.nan\n",
        "    update_df.update(df)\n",
        "    return\n",
        "\n",
        "\n",
        "def create_binary_features(df):\n",
        "    bows = {\n",
        "        \"dogs\": (\"dogs\", \"dog\"),\n",
        "        \"cats\": (\"cats\",),\n",
        "        \"nofee\": (\"no fee\", \"no-fee\", \"no  fee\", \"nofee\", \"no_fee\"),\n",
        "        \"lowfee\": (\"reduced_fee\", \"low_fee\", \"reduced fee\", \"low fee\"),\n",
        "        \"furnished\": (\"furnished\",),\n",
        "        \"parquet\": (\"parquet\", \"hardwood\"),\n",
        "        \"concierge\": (\"concierge\", \"doorman\", \"housekeep\", \"in_super\"),\n",
        "        \"prewar\": (\"prewar\", \"pre_war\", \"pre war\", \"pre-war\"),\n",
        "        \"laundry\": (\"laundry\", \"lndry\"),\n",
        "        \"health\": (\"health\", \"gym\", \"fitness\", \"training\"),\n",
        "        \"transport\": (\"train\", \"subway\", \"transport\"),\n",
        "        \"parking\": (\"parking\",),\n",
        "        \"utilities\": (\"utilities\", \"heat water\", \"water included\")\n",
        "    }\n",
        "\n",
        "    def indicator(bow):\n",
        "        return lambda s: int(any([x in s for x in bow]))\n",
        "\n",
        "    features = df[\"features\"].apply(lambda f: \" \".join(f).lower())   # convert features to string\n",
        "    for key in bows:\n",
        "        df[\"feature_\" + key] = features.apply(indicator(bows[key]))\n",
        "\n",
        "    return df\n",
        "    \n",
        "    \n",
        "# Load data\n",
        "X_train = pd.read_json(\"../input/train.json\").sort_values(by=\"listing_id\")\n",
        "X_test = pd.read_json(\"../input/test.json\").sort_values(by=\"listing_id\")\n",
        "\n",
        "# Make target integer, one hot encoded, calculate target priors\n",
        "X_train = X_train.replace({\"interest_level\": {\"low\": 0, \"medium\": 1, \"high\": 2}})\n",
        "X_train = X_train.join(pd.get_dummies(X_train[\"interest_level\"], prefix=\"pred\").astype(int))\n",
        "prior_0, prior_1, prior_2 = X_train[[\"pred_0\", \"pred_1\", \"pred_2\"]].mean()\n",
        "\n",
        "# Add common features\n",
        "X_train = add_features(X_train)\n",
        "X_test = add_features(X_test)\n",
        "\n",
        "# Special designation for building_ids, manager_ids, display_address with only 1 observation\n",
        "for col in ('building_id', 'manager_id', 'display_address'):\n",
        "    X_train, X_test = designate_single_observations(X_train, X_test, col)\n",
        "\n",
        "# High-Cardinality Categorical encoding\n",
        "skf = StratifiedKFold(5)\n",
        "attributes = product((\"building_id\", \"manager_id\"), zip((\"pred_1\", \"pred_2\"), (prior_1, prior_2)))\n",
        "for variable, (target, prior) in attributes:\n",
        "    hcc_encode(X_train, X_test, variable, target, prior, k=5, r_k=None)\n",
        "    for train, test in skf.split(np.zeros(len(X_train)), X_train['interest_level']):\n",
        "        hcc_encode(X_train.iloc[train], X_train.iloc[test], variable, target, prior, k=5, r_k=0.01, update_df=X_train)\n",
        "\n",
        "# Factorize building_id, display_address, manager_id, street_address\n",
        "for col in ('building_id', 'display_address', 'manager_id', 'street_address'):\n",
        "    X_train, X_test = factorize(X_train, X_test, col)\n",
        "\n",
        "# Create binarized features\n",
        "X_train = create_binary_features(X_train)\n",
        "X_test = create_binary_features(X_test)\n",
        "\n",
        "# Save\n",
        "\"\"\"\n",
        "X_train = X_train.sort_index(axis=1).sort_values(by=\"listing_id\")\n",
        "X_test = X_test.sort_index(axis=1).sort_values(by=\"listing_id\")\n",
        "columns_to_drop = [\"photos\", \"pred_0\",\"pred_1\", \"pred_2\", \"description\", \"features\", \"created\"]\n",
        "X_train.drop(columns_to_drop, axis=1, errors=\"ignore\").to_csv(\"data/train_python.csv\", index=False, encoding='utf-8')\n",
        "X_test.drop(columns_to_drop, axis=1, errors=\"ignore\").to_csv(\"data/test_python.csv\", index=False, encoding='utf-8')\n",
        "\"\"\"    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a606883-acb9-1f33-d319-6f89a162c1b5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def runXGB(train_X, train_y, test_X=None, test_y=None, feature_names=None, seed_val=0, num_rounds=1000):\n",
        "    param = {}\n",
        "    param['objective'] = 'multi:softprob'\n",
        "    param['eta'] = 0.1\n",
        "    param['max_depth'] = 6\n",
        "    param['silent'] = 1\n",
        "    param['num_class'] = 3\n",
        "    param['eval_metric'] = \"mlogloss\"\n",
        "    param['min_child_weight'] = 1\n",
        "    param['subsample'] = 0.7\n",
        "    param['colsample_bytree'] = 0.7\n",
        "    param['seed'] = 8088\n",
        "    num_rounds = num_rounds\n",
        "\n",
        "    plst = list(param.items())\n",
        "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "\n",
        "    if test_X is not None:\n",
        "        if test_y is not None:\n",
        "            xgtest = xgb.DMatrix(test_X, label=test_y)\n",
        "            watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
        "            model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=25,\n",
        "                             verbose_eval=25)#False)\n",
        "        else:\n",
        "            xgtest = xgb.DMatrix(test_X)\n",
        "            model = xgb.train(plst, xgtrain, num_rounds)\n",
        "\n",
        "        pred_test_y = model.predict(xgtest)\n",
        "        return pred_test_y, model\n",
        "    else:\n",
        "        evals=xgb.cv(plst, xgtrain, num_rounds, nfold=5, early_stopping_rounds=25,\n",
        "                             verbose_eval=25, seed=0)\n",
        "        return evals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82577be0-3265-e3aa-31a4-ed919aaa811d"
      },
      "outputs": [],
      "source": [
        "features_list=['bathrooms', 'bedrooms', 'building_id', 'display_address', 'interest_level', 'latitude', 'listing_id', 'longitude', 'manager_id', 'price', 'street_address', 'pred_0', 'pred_1', 'pred_2', 'photo_count', 'desc_wordcount', 'pricePerBed', 'pricePerBath', 'pricePerRoom', 'bedPerBath', 'bedBathDiff', 'bedBathSum', 'bedsPerc', 'hcc_building_id_pred_1', 'hcc_building_id_pred_2', 'hcc_manager_id_pred_1', 'hcc_manager_id_pred_2', 'feature_dogs', 'feature_cats', 'feature_nofee', 'feature_lowfee', 'feature_furnished', 'feature_parquet', 'feature_concierge', 'feature_prewar', 'feature_laundry', 'feature_health', 'feature_transport', 'feature_parking', 'feature_utilities']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "365e1c1a-f812-0eb4-83d7-6a06a7512a04"
      },
      "outputs": [],
      "source": [
        "#skf = StratifiedKFold(5)\n",
        "kf = KFold(n_splits=5, random_state=0)\n",
        "\n",
        "scores=[]\n",
        "best_i=[]\n",
        "#for train_index, test_index in skf.split(X_train.index, X_train['interest_level']):\n",
        "for train_index, test_index in kf.split(X_train):\n",
        "    tr=X_train.loc[train_index, features_list]\n",
        "    tr_y=X_train.loc[train_index, ['interest_level']].values\n",
        "    te=X_train.loc[test_index, features_list]\n",
        "    te_y=X_train.loc[test_index, ['interest_level']].values\n",
        "    preds, model = runXGB(tr, tr_y, te, te_y)\n",
        "    scores+=[model.best_score]\n",
        "    best_i+=[model.best_iteration]\n",
        "    print(\"%.6f %d\"%(model.best_score, model.best_iteration))\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}