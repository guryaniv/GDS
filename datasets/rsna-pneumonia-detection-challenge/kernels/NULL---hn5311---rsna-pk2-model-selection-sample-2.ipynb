{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nimport os \nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nimport pydicom\n\nfrom skimage import io\nfrom skimage import measure\nfrom skimage import transform, exposure\nfrom skimage.transform import resize\n\nfrom tqdm import tqdm\nfrom scipy import ndimage\n\nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential, load_model, Model\nfrom keras import layers\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, UpSampling2D, Conv2DTranspose, concatenate, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Lambda\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\nfrom keras import optimizers, regularizers\nfrom keras import applications","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50a081f1719b85ef3e4892e6b330a19968471b39"},"cell_type":"markdown","source":"# Run time parameters"},{"metadata":{"trusted":true,"_uuid":"3f4a1779d72e7c6ac441ad8e5e63f2fdf6624192"},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c71b014ccace05e9e65a788eb2cf3e0b9737057e"},"cell_type":"code","source":"FRAC = 0.1                                                                 # FRACtion of input to be used for training\nTRAIN_VAL_SPLIT = 0.9                                                      # Proportion of Training to Validation set\nEPOCH = 5\nSAMPLE_N = 2\nBATCH_SIZE = 8\n\nIMG_SIZE = 256\nN_CHANNEL = 3\nTHRESHOLD = 0.5                                                           # probability threshold for prediction \nRANDOM_STATE = SAMPLE_N\nDATA_INPUT_DIR = '/kaggle/input'                                          # path containing inputs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46a3ed34d30623fc99e1ac817f1d6f94d57f376f"},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true,"_uuid":"a34aef3d2f19c6734c41ce27fac95cc523294e1a"},"cell_type":"code","source":"# function to read annotn file and put it into a dataframe\ndef read_annotn(file_path=''):\n    annotn = pd.read_csv(file_path)\n    annotn = annotn.reset_index(drop=True)\n    return annotn\n\n# function to (1) sample input (2) split the input into train val \ndef get_train_val_df(frac=FRAC, train_val_split=TRAIN_VAL_SPLIT, random_state=RANDOM_STATE, file_path=''):\n    df_annotn = read_annotn(file_path=file_path)\n    df_id_label = df_annotn.fillna(0)\n    df_id_label = df_id_label.sample(frac=frac, random_state=RANDOM_STATE)\n    train_sample = round(train_val_split*df_id_label.shape[0])\n    df_train = df_id_label[:train_sample]\n    df_val = df_id_label[train_sample:]\n    return df_train,df_val\n\n# loss function for training\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n\n# metrics function for training\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef dice_bce_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * dice_coef_loss(y_true, y_pred)\n\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n\n# function to put training scores into a dataframe\ndef update_df_score(df, history, model):\n    for i in range(EPOCH): \n        df = df.append( { 'epoch' : i,\n                         'model': model,\n                         'train_loss' : history.history['loss'][i], \n                         'val_loss' : history.history['val_loss'][i], \n                         'train_accuracy' : history.history['acc'][i], \n                         'val_accuracy' : history.history['val_acc'][i],\n                         'train_dice_coef' : history.history['dice_coef'][i], \n                         'val_dice_coef' : history.history['val_dice_coef'][i],\n                         'train_mean_iou' : history.history['mean_iou'][i], \n                         'val_mean_iou' : history.history['val_mean_iou'][i]\n                         } , ignore_index=True)\n    return df\n\n# function to convert mask to list of x,y,w,h\ndef convert_mask_to_xywh (mask, threshold=THRESHOLD):\n    component = mask[:, :, 0] > THRESHOLD\n    component = measure.label(component)\n    xywh_list = []\n    for region in measure.regionprops(component):\n        y, x, y2, x2 = region.bbox\n        height = y2 - y\n        width = x2 - x\n        xywh_list.append([x, y, width, height])\n    return xywh_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f748e8ab463600e8cb0421b92f66326f31c098e"},"cell_type":"markdown","source":"# Generator class"},{"metadata":{"trusted":true,"_uuid":"48830678cd80cabab19c99f5a0a87a16e0d52c05"},"cell_type":"code","source":"# generator class for generating batches of (1) image  and mask array for training and validation (2) image array for prediction \nclass datagen(keras.utils.Sequence):\n    def __init__(self, df_X_y, im_size=IMG_SIZE, batch_size=32, predict=False, augment=True):\n        self.im_size = im_size\n        self.df_X_y = df_X_y\n        self.batch_size = batch_size\n        self.predict = predict\n        self.augment = augment\n        \n    def __len__(self):\n        return int(math.ceil(self.df_X_y.shape[0] / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch = self.df_X_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        X = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, N_CHANNEL))\n        if self.predict:\n            for i, row in enumerate(batch.iterrows()):\n                patientId = row[1]['patientId']\n                dcm_file = DATA_INPUT_DIR + '/stage_2_test_images/%s' %patientId\n                dcm_data = pydicom.read_file(dcm_file)\n                img =  dcm_data.pixel_array\n                img = exposure.equalize_hist(img)\n                img = resize(img, (IMG_SIZE, IMG_SIZE), mode='reflect')\n                img = img - img.mean()\n                img = img / img.std()\n                img = np.expand_dims(img, -1) if N_CHANNEL == 1 else np.stack((img,)*3, axis=-1)            \n                X[i,] = img\n            return np.array(X), batch['patientId']\n        else:\n            masks = np.zeros((self.batch_size, IMG_SIZE, IMG_SIZE, N_CHANNEL))\n            for i, row in enumerate(batch.iterrows()):\n                patientId = row[1]['patientId']\n                dcm_file = DATA_INPUT_DIR + '/stage_2_train_images/%s.dcm' %patientId \n                dcm_data = pydicom.read_file(dcm_file)\n                img =  dcm_data.pixel_array\n                img = exposure.equalize_hist(img)\n                img = resize(img, (IMG_SIZE, IMG_SIZE), mode='reflect')\n                img = img - img.mean()\n                img = img / img.std()\n                img = np.expand_dims(img, -1) if N_CHANNEL == 1 else np.stack((img,)*3, axis=-1)\n                msk = np.zeros(dcm_data.pixel_array.shape)\n                for key, (_, x, y, width, height, _) in self.df_X_y.loc[self.df_X_y['patientId'] == patientId].iterrows():\n                    x, y, w, h = (int(x), int(y), int(width), int(height))\n                    msk[y:y+h, x:x+w] = 1 \n                msk = resize(msk, (IMG_SIZE, IMG_SIZE), mode='reflect') > THRESHOLD\n                msk = np.expand_dims(msk, -1) if N_CHANNEL == 1 else np.stack((msk,)*3, axis=-1)\n                if self.augment and random.random() > 0.5:\n                    img = np.fliplr(img)\n                    msk = np.fliplr(msk)\n                    angle = random.random()*15\n                    img = ndimage.rotate(img, angle, reshape=False, order=1)\n                    msk = ndimage.rotate(msk, angle, reshape=False, order=1)\n                masks[i,] = msk\n                X[i,] = img\n            return np.array(X), np.array(masks)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b3c4fd330dd03dcb074c05f21469aa5a662420d"},"cell_type":"markdown","source":"# Models : (1) UNET+VGG16 (2) UNET+INCEPTIONRESNET (3) UNET+DENSENET (4) UNET+RESNET"},{"metadata":{"trusted":true,"_uuid":"4b62658fe16f484e940bf612f8a0adcd4eb8eeee"},"cell_type":"code","source":"# UNET with initialization from VGG16\ndef get_unet_vgg(LR=1e-4):\n    from keras.applications.vgg16 import VGG16\n    img_input = Input( (IMG_SIZE, IMG_SIZE, N_CHANNEL))\n    vgg16_base = VGG16(input_tensor=img_input, include_top=False)\n    conv1 = vgg16_base.get_layer(index=2).output\n    conv2 = vgg16_base.get_layer(index=5).output\n    conv3 = vgg16_base.get_layer(index=9).output\n    pool3 = vgg16_base.get_layer(index=10).output\n\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool3)\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool4)\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv5)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5)\n\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool5)\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv6)\n    pool6 = MaxPooling2D((2, 2), strides=(2, 2))(conv6)\n\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool6)\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv7)\n    \n    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same' )(conv7), conv6], axis=3)\n    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n\n    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up9)\n\n    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same' )(conv9), conv4], axis=3)\n    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n\n    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n\n    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n\n    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n\n    conv13 = Conv2D(N_CHANNEL, (1, 1))(conv13)\n    conv13 = Activation(\"sigmoid\")(conv13)\n    model = Model(img_input, conv13)\n    Adam = optimizers.Adam(lr=LR)\n    model.compile(optimizer=Adam, loss=dice_coef_loss, metrics=['accuracy', dice_coef, mean_iou])\n    model.name = 'unet+vgg'\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b120a81efae034d9b62d3a22b2445db0b43fbbdc"},"cell_type":"code","source":"# UNET with initialization from INCEPTIONRESNET\ndef get_unet_IR(LR=1e-4):\n    from keras.applications.inception_resnet_v2 import InceptionResNetV2\n    img_input = Input( (IMG_SIZE, IMG_SIZE, N_CHANNEL))\n\n    IR_model = InceptionResNetV2(weights='imagenet', input_tensor=img_input, include_top=False)\n    conv1 = IR_model.get_layer(index=3).output \n    conv1 = keras.layers.UpSampling2D(2)(conv1)\n    conv1 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((2, 0), (2, 0))))(conv1) \n    \n    conv2 = IR_model.get_layer(index=9).output \n    conv2 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((3, 0), (3, 0))))(conv2) \n    \n    conv3 = IR_model.get_layer(index=16).output \n    conv3 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((4, 0), (4, 0))))(conv3) \n    \n    conv3a = IR_model.get_layer(index=266).output\n    conv3a = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((3, 0), (3, 0))))(conv3a) \n\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv3a)\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool4)\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv5)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5)\n\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool5)\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv6)\n    pool6 = MaxPooling2D((2, 2), strides=(2, 2))(conv6)\n\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool6)\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv7)\n    \n    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv7), conv6], axis=3)\n    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n\n    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up9)\n\n    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv9), conv4], axis=3)\n    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n\n    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n\n    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n\n    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n\n    conv13 = Conv2D(N_CHANNEL, (1, 1))(conv13)\n    conv13 = Activation(\"sigmoid\")(conv13)\n    model = Model(img_input, conv13)\n    Adam = optimizers.Adam(lr=LR)\n    model.compile(optimizer=Adam, loss=dice_coef_loss, metrics=['accuracy', dice_coef, mean_iou])\n    model.name = 'unet+IR'\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa6104dfa9521ce2ef54184b0e245bd4248bd18b"},"cell_type":"code","source":"# UNET with initialization from DENSENT\ndef get_unet_Densenet201(LR=1e-4):\n    from keras.applications.densenet import DenseNet201\n    img_input = Input( (IMG_SIZE, IMG_SIZE, N_CHANNEL))\n\n    Densenet_model = DenseNet201(weights='imagenet', input_tensor=img_input, include_top=False)\n    \n    conv1 = Densenet_model.get_layer(index=1).output \n    conv1 = Conv2D(64, (7, 7), activation=\"relu\", kernel_initializer=\"he_normal\")(conv1)    \n    \n    conv2 = Densenet_model.get_layer(index=4).output \n    conv3 = Densenet_model.get_layer(index=51).output \n    conv3a = Densenet_model.get_layer(index=139).output\n\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv3a)\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool4)\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv5)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5)\n\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool5)\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv6)\n    pool6 = MaxPooling2D((2, 2), strides=(2, 2))(conv6)\n\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool6)\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv7)\n    \n    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv7), conv6], axis=3)\n    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n\n    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2),  padding='same')(conv8), conv5], axis=3)\n    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up9)\n\n    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2),  padding='same')(conv9), conv4], axis=3)\n    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up10)\n\n    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2),  padding='same')(conv10), conv3], axis=3)\n    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up11)\n\n    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2),  padding='same')(conv11), conv2], axis=3)\n    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up12)\n\n    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2),  padding='same')(conv12), conv1], axis=3)\n    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up13)\n\n    conv13 = Conv2D(N_CHANNEL, (1, 1))(conv13)\n    conv13 = Activation(\"sigmoid\")(conv13)\n    model = Model(img_input, conv13)\n    \n    Adam = optimizers.Adam(lr=LR)\n    model.compile(optimizer=Adam, loss=dice_coef_loss, metrics=['accuracy', dice_coef, mean_iou])\n    model.name = 'unet+dense'\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1693226765eb8a121ac7c7c3de3374d45fa76e46"},"cell_type":"code","source":"# UNET with initialization from RESNET\ndef get_unet_res(LR=1e-4):\n    from keras.applications.resnet50 import ResNet50\n    img_input = Input( (IMG_SIZE, IMG_SIZE, N_CHANNEL))\n    resnet_model = ResNet50(weights='imagenet', input_tensor=img_input, include_top=False)\n\n    conv1 = resnet_model.get_layer(index=1).output \n    conv1 = Conv2D(64, (7, 7), activation=\"relu\", kernel_initializer=\"he_normal\")(conv1)\n    conv2 = resnet_model.get_layer(index=4).output \n    conv3 = resnet_model.get_layer(index=38).output \n    conv3a = resnet_model.get_layer(index=80).output \n\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv3a)\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2))(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool4)\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv5)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2))(conv5)\n\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool5)\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv6)\n    pool6 = MaxPooling2D((2, 2), strides=(2, 2))(conv6)\n\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(pool6)\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\")(conv7)\n\n    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv7), conv6], axis=3)\n    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n\n    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\",  padding='same')(up9)\n\n    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv9), conv4], axis=3)\n    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n\n    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n\n    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n\n    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n\n    conv13 = Conv2D(N_CHANNEL, (1, 1))(conv13)\n    conv13 = Activation(\"sigmoid\")(conv13)\n    model = Model(img_input, conv13)\n    Adam = optimizers.Adam(lr=LR)\n    model.compile(optimizer=Adam, loss=dice_coef_loss, metrics=['accuracy', dice_coef, mean_iou])\n    model.name = 'unet+res'\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ddcf8f602153f418726a8dfdde9fc311529d3ec"},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true,"_uuid":"091f50efe7c07f4c70471a912f687e7c8e9ae841"},"cell_type":"code","source":"# helper function to train and record scores in df_score\ndef train_model(model, df_score, training_generator, validation_generator):\n    print(model.name)\n    history = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=EPOCH, use_multiprocessing=True, workers=4, verbose=1)\n    df_score = update_df_score(df_score, history, model.name)\n    del model\n    return df_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"439a351fa26fa48f7a67607b771d6ab053ad0014"},"cell_type":"code","source":"# build training, validation generators and create df_score\ndf_train, df_val = get_train_val_df(frac=FRAC, train_val_split=TRAIN_VAL_SPLIT, random_state=SAMPLE_N, file_path=os.path.join(DATA_INPUT_DIR, 'stage_2_train_labels.csv'))\nprint('train size:', df_train.shape, '\\tval size:', df_val.shape)\ntraining_generator = datagen(df_train, batch_size=BATCH_SIZE, augment=True, predict=False)\nvalidation_generator = datagen(df_val, batch_size=BATCH_SIZE, augment=True, predict=False)\ndf_score = pd.DataFrame(columns=['epoch', 'model', \n                                 'train_loss', 'val_loss', \n                                 'train_accuracy', 'val_accuracy',\n                                 'train_dice_coef', 'val_dice_coef', \n                                 'train_mean_iou', 'val_mean_iou'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21084194bf71e4633a91723a5174f79ec4b13d35"},"cell_type":"code","source":"for model in [get_unet_vgg(), get_unet_res(), get_unet_IR(), get_unet_Densenet201()]:\n    df_score = train_model(model, df_score, training_generator, validation_generator)\ndf_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f4def7e3c200daa361a3cd73d0ebbcc75efcf54"},"cell_type":"code","source":"file_name = '/kaggle/working/df_score_model_{}.csv'.format(SAMPLE_N)\ndf_score.to_csv(file_name) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"046cdd6522ed332a491886be8a02293eb243cb81"},"cell_type":"code","source":"fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(28,7))\ntitle = ['Train Loss', 'Train Accuracy', 'Train mean_iou', 'Train dice_coef']\nmodel = ['unet+vgg', 'unet+res', 'unet+IR', 'unet+dense']\nplot = ['train_loss', 'train_accuracy', 'train_mean_iou', 'train_dice_coef']\n\nfor i in range(4):\n    df_score.loc[df_score['model'] == model[i]].plot(x='epoch', y=plot[i], label=model[i], ax=ax[i])\n    _ = ax[i].grid()\n    _ = ax[i].set_title(title[i])   \n    _ = ax[i].set_xticks(np.arange(EPOCH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46cde2e9188c4ce93f51fe1d8ffc784317e5c7a2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}