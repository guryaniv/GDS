{"nbformat": 4, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "version": "3.6.1", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "9b75c8bd-f0a2-4905-987b-e7360c394d2c", "_uuid": "03347c4a62865ae41d3df6bbe93f130a8e2808c8"}, "source": ["# Creating some ML pipelines\n", "\n", "### Introduction"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4661aa0f-01d5-410b-9dad-0321f49c13a9", "_uuid": "80d0b5816a6831396a7386264f397e7348475b91"}, "source": ["I thought I'd do a quick write up on how you can build some simple and effective ML pipelines using sklearn.\n", "\n", "I discovered the pipeline/gridsearch combo a few weeks ago after sending off some of my code for review.\n", "In sending off my code I realized that were a few things that I had tweaked for performance, but weren't obvious to the reviewer.\n", "\n", "- I had median imputed some variables (continuous features), while other variables were filled by mode\n", "- I did a large amount of feature engineering, only to use a subset of those features in my model building (they were the best I swear)\n", "\n", "So even though I did some work to get to that reviewed copy, these experiments that I went through during the process wouldn't be easy to understand unless the reviewer looked at all my commits etc.\n", "\n", "But then I found **pipelines / gridsearch** and all was good in the world.\n", "\n", "**Pipelines** let you combine all your feature engineering / pre-processing / modelling into one object\n", "\n", "**Gridsearch** then lets you test all your assumptions / hyperparameters to find out which combinations generate the best result"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "244bf196-b69b-49fd-bf24-e00adad4c399", "_uuid": "b7cdfec14fa6426abaa3643e78f9b269f681355a"}, "source": ["I haven't seen many write ups about them so I thought I'd do one myself.\n", "\n", "1. **References:**\n", "\n", "- http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n", "- http://scikit-learn.org/stable/modules/pipeline.html\n", "- http://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n", "- https://stackoverflow.com/questions/33091376/python-what-is-exactly-sklearn-pipeline-pipeline\n", "- http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n", "- https://michelleful.github.io/code-blog/2015/06/20/pipelines/"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b5ac5e41-74a7-4d3d-903e-6dd3829e1094", "_uuid": "8bd05815de53fdfb8c4ea626b1ca438a413b7f7e"}, "source": ["# Libraries + MAE"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0536a6c4-9352-4fa1-9a91-c92ffe8db4ca", "collapsed": true, "_uuid": "ab5cb2eebc9bdcdbe25661e7bda3106fd93a1b9e"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import lightgbm as lgb\n", "from lightgbm import LGBMRegressor\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n", "from sklearn.pipeline import Pipeline, FeatureUnion\n", "from sklearn.preprocessing import Imputer, PolynomialFeatures, StandardScaler, OneHotEncoder, MinMaxScaler\n", "from sklearn.decomposition import PCA\n", "from sklearn.ensemble import RandomForestRegressor\n", "import os\n", "import time\n", "\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "def MAE(y, ypred):\n", "    \n", "    import numpy as np\n", "    \n", "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)   "], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9eed3411-889b-4a9d-81ce-9fb536763722", "_uuid": "5c5226c26e309572bec09d58780b2008b4527e80"}, "source": ["# Data read in and prep\n", "### Making sure the data is in a lightGBM friendly format"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c01bc81b-0122-4442-96f7-c5fd61c07a8c", "collapsed": true, "_uuid": "d0498c0248e5a231f419444f64c488c495e13b53"}, "source": ["train = pd.read_csv(\"../input/train_2016_v2.csv\")\n", "properties = pd.read_csv('../input/properties_2016.csv')\n", "\n", "for c, dtype in zip(properties.columns, properties.dtypes):\t\n", "    if dtype == np.float64:\n", "        properties[c] = properties[c].astype(np.float32)\n", "\n", "df_train = (train.merge(properties, how='left', on='parcelid')\n", "            .drop(['parcelid', 'transactiondate', 'propertyzoningdesc', \n", "                         'propertycountylandusecode', 'fireplacecnt', 'fireplaceflag'], axis=1))\n", "\n", "train_columns = df_train.columns "], "execution_count": 2}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0c7a2c82-3802-4e89-9d1b-72c1a4773fab", "_uuid": "31e326a7919d6346891c3cda4fd0ca0e2a158238"}, "source": ["# Splitting the dataset to train/valid sets"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d49c5643-7379-4e65-b955-57bfee2a22cd", "collapsed": true, "_uuid": "d27ffab58012a4014368a95eb95354b7652b5470"}, "source": ["valid = df_train.iloc[1:20000, :]\n", "train = df_train.iloc[20001:90275, :]\n", "\n", "y_train = train['logerror'].values\n", "y_valid = valid['logerror'].values\n", "\n", "x_train = train.drop('logerror', axis = 1)\n", "x_valid = valid.drop('logerror', axis = 1)\n", "\n", "idVars = [i for e in ['id',  'flag', 'has'] for i in list(train_columns) if e in i] + ['fips', 'hashottuborspa']\n", "countVars = [i for e in ['cnt',  'year', 'nbr', 'number'] for i in list(train_columns) if e in i]\n", "taxVars = [col for col in train_columns if 'tax' in col and 'flag' not in col]\n", "          \n", "ttlVars = idVars + countVars + taxVars\n", "dropVars = [i for e in ['census',  'tude', 'error'] for i in list(train_columns) if e in i]\n", "contVars = [col for col in train_columns if col not in ttlVars + dropVars]\n", "\n", "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n", "    x_train[c] = (x_train[c] == True)\n", "    \n", "for c in x_valid.dtypes[x_valid.dtypes == object].index.values:\n", "    x_valid[c] = (x_valid[c] == True)   "], "execution_count": 3}, {"cell_type": "markdown", "metadata": {"_cell_guid": "29944826-85f5-4259-9e9c-8770e9536f02", "_uuid": "2f0db6ad26f0e17cb7b29a76fd1e6b14d042c642"}, "source": ["# The first pipeline\n", "\n", "Since everyone is using lightGBM I'll use that. \n", "Initially we'll just look at the continuous variables in model building, but we'll extend that out too.\n", "\n", "So let's start with the easy pipeline that:\n", "\n", "- Imputes the missing values with the median\n", "- Selects the best 5 features\n", "- Builds a LightGBM model"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4335dbf9-b749-465d-b709-6c53d4b07c5d", "_uuid": "a7edc669ea1abb2f2318b4b49d8ed88e94241acf"}, "source": ["print(contVars)\n", "\n", "x_train_cont = x_train[contVars]\n", "x_valid_cont = x_valid[contVars]"], "execution_count": 4}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3d5f19c0-a1c9-462e-a06f-886f0b3ece6e", "_uuid": "e3b72912e1af6ab402ba37505921bcce965c1dd9"}, "source": ["pipeline = Pipeline(\n", "                    [('imp', Imputer(missing_values='NaN', strategy = 'median', axis=0)),\n", "                     ('feat_select', SelectKBest(k = 5)),\n", "                     ('lgbm', LGBMRegressor())\n", "                     \n", "])\n", "\n", "pipeline.fit(x_train_cont, y_train)   \n", "\n", "y_pred = pipeline.predict(x_valid_cont)\n", "print('MAE on validation set: %s' % (round(MAE(y_valid, y_pred), 5)))"], "execution_count": 5}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1696907d-7d3d-47fa-ae48-d496b5094a14", "_uuid": "b858f9db8792999c58dd06143697cf5e4e7b70c8"}, "source": ["## Pipeline 2.0 - oh hai there gridsearch"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "eb7a1f64-49d7-4aa7-b5d3-40efa520f948", "_uuid": "76729e352b3d514755c5dd6ff23cd5ae7fb57dc4"}, "source": ["But from the above code we have made a few assumptions that haven't been tested.\n", "\n", "**We assume that:**\n", "- Median is the best way of imputing the variables\n", "- Only 5 variables needed for the lowest error \n", "\n", "But we don't need to assume these, we can test these assumptions and find out which actually results in the lowest error."]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3406bc4d-c515-426b-828b-20305832eb00", "_uuid": "b73cad02a02c8bec291c1d0cfb4c5a44733a0e1e"}, "source": ["pipeline = Pipeline(\n", "                    [('imp', Imputer(missing_values='NaN', axis=0)),\n", "                     ('feat_select', SelectKBest()),\n", "                     ('lgbm', LGBMRegressor())\n", "                     \n", "])\n", "\n", "parameters = {}\n", "parameters['imp__strategy'] = ['mean', 'median', 'most_frequent']\n", "parameters['feat_select__k'] = [5, 10]\n", "\n", "CV = GridSearchCV(pipeline, parameters, scoring = 'mean_absolute_error', n_jobs= 1)\n", "CV.fit(x_train_cont, y_train)   \n", "\n", "print('Best score and parameter combination = ')\n", "\n", "print(CV.best_score_)    \n", "print(CV.best_params_)    \n", "\n", "y_pred = CV.predict(x_valid_cont)\n", "print('MAE on validation set: %s' % (round(MAE(y_valid, y_pred), 5)))"], "execution_count": 6}, {"cell_type": "markdown", "metadata": {"_cell_guid": "73ad20cd-df5f-4294-8eec-91a081f7154f", "_uuid": "211c6dd07672c97b70d8b94a501cd1fcc33bd9b6"}, "source": ["Interesting, I never thought that using a mode would come out on top.\n", "\n", "But we since we're also here we let's also test and see what is the best imputation policy for tax variables. First I'll quickly write a column extractor that plays nicely with the pipeline.\n", "\n", "These can look hard at first, but they definitely get easier as you write a few. \n", "And since we're writing some code we should probably do some testing to make sure that it works the way we think it will.\n", "\n", "# Column extractor\n", "\n", "## Takes a list of columns and returns a df with those cols"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "27981adb-de94-4b6e-a6d6-fd03736e04dc", "collapsed": true, "_uuid": "90c48b58a04fd5c41398ec293b9c734f449e87ed"}, "source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "class ColumnSelector(BaseEstimator, TransformerMixin):\n", "    def __init__(self, subset):\n", "        self.subset = subset\n", "\n", "    def transform(self, X, *_):\n", "        return X.loc[:, self.subset]\n", "\n", "    def fit(self, *_):\n", "        return self"], "execution_count": 11}, {"cell_type": "markdown", "metadata": {"_cell_guid": "10b59873-35cb-4931-b49b-61bf3488677b", "_uuid": "df2092a823b681fd3449bd682e70c1554c24af49"}, "source": ["# Testing\n", "\n", "Since we've already created x_train_cont I'll test the column extractor on this case"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fac6f21a-0734-4cfa-8e48-d64b701d95ef", "_uuid": "3bfa806209c0429f03d35e782a2918afcb9eeb93"}, "source": ["contExtractor = ColumnSelector(contVars)\n", "x_train_cont_test = contExtractor.transform(x_train).head()\n", "\n", "x_train_cont.head().equals(x_train_cont_test)"], "execution_count": 12}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2c1fb2f9-187d-44fe-809d-7a6a8748de9d", "_uuid": "39f6d5fd3f3ad4d780f65fa7e6af32793367f40b"}, "source": ["# Pipeline 3.0 - taxes\n", "\n", "So let's use the ColumnExtractor we created earlier to run the same analysis we did earlier on the tax variables"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a58ddde3-a127-4b22-9897-d4dcd8f91071", "_uuid": "1d74714c636e5f50ac52abc677eb9a84514dd634"}, "source": ["pipeline = Pipeline([\n", "                    ('tax_dimension', ColumnSelector(taxVars)),\n", "                    ('imp', Imputer(missing_values='NaN', axis=0)),\n", "                    ('column_purge', SelectKBest()),\n", "                    ('lgbm', LGBMRegressor())\n", "                     \n", "])\n", "\n", "parameters = dict(imp__strategy=['mean', 'median', 'most_frequent'],\n", "                    column_purge__k=[5, 2, 1] \n", "\n", ")   \n", "\n", "CV = GridSearchCV(pipeline, parameters, scoring = 'neg_mean_absolute_error', n_jobs= 1)\n", "CV.fit(x_train, y_train)   \n", "\n", "print(CV.best_params_)    \n", "print(CV.best_score_)    \n", "\n", "y_pred = CV.predict(x_valid)\n", "print('MAE on validation set: %s' % (round(MAE(y_valid, y_pred), 5)))"], "execution_count": 14}, {"cell_type": "markdown", "metadata": {"_cell_guid": "f3310325-0c07-47d9-9e06-171dc3412066", "_uuid": "099f3ab879cd50ad3926405c1ab4d986a912f4d8"}, "source": ["# Pipeline 4.0 - contVars + taxes (FeatureUnion intro)\n", "\n", "Let's use FeatureUnion to apply different pre-processing pipelines to different types of variables"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "756f249e-9803-4a54-aece-081a79cfffd3", "_uuid": "e158bb63967ab76573f33057364ef1b93a023948"}, "source": ["pipeline = Pipeline([\n", "        \n", "    ('unity', FeatureUnion(\n", "        transformer_list=[\n", "\n", "            ('cont_portal', Pipeline([\n", "                ('selector', PortalToColDimension(contVars)),\n", "                ('cont_imp', Imputer(missing_values='NaN', strategy = 'median', axis=0)),\n", "                ('scaler', StandardScaler())             \n", "            ])),\n", "            ('tax_portal', Pipeline([\n", "                ('selector', PortalToColDimension(taxVars)),\n", "                ('tax_imp', Imputer(missing_values='NaN', strategy = 'most_frequent', axis=0)),\n", "                ('scaler', MinMaxScaler(copy=True, feature_range=(0, 3)))\n", "            ])),\n", "        ],\n", "    )),\n", "    ('column_purge', SelectKBest(k = 5)),    \n", "    ('lgbm', LGBMRegressor()),\n", "])\n", "\n", "parameters = {}\n", "parameters['column_purge__k'] = [5, 10]\n", "\n", "grid = GridSearchCV(pipeline, parameters, scoring = 'neg_mean_absolute_error', n_jobs= 2)\n", "grid.fit(x_train, y_train)   \n", "\n", "print('Best score and parameter combination = ')\n", "\n", "print(grid.best_score_)    \n", "print(grid.best_params_)    \n", "\n", "y_pred = grid.predict(x_valid)\n", "print('MAE on validation set: %s' % (round(MAE(y_valid, y_pred), 5)))"], "execution_count": 16}, {"cell_type": "markdown", "metadata": {"_cell_guid": "152cab74-15db-47a0-b8d1-6be46bd836eb", "_uuid": "bca2b195f35ffb810afab46122b71da87be8b055"}, "source": ["# Finished with your model and push it to prod?\n", "\n", "You can use the joblib library to serialize this best case pipeline and push it to a .pkl file.\n", "\n", "You easily move this to your prod server and just re-open it and your pipeline will will work like a charm (assuming no changing in data types, and that's a pretty big IF).\n", "\n", "But when the new data comes through you can open up the following pickle and easily score the model you built against the new data"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "44e59c6a-e707-4d42-80e9-9ece90d9ea0a", "_uuid": "d0d4ae4ef95b2ae6ec653d14d391670300e72f0f"}, "source": ["from sklearn.externals import joblib\n", "joblib.dump(grid.best_estimator_, 'rick.pkl')"], "execution_count": 17}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4e59de25-233a-484a-a88c-2b11414743c4", "_uuid": "77e32c69fdc16929122d43559370bd85c3d6d5bd"}, "source": ["# Summary\n", "\n", "In hindsight, I'd be surprised if anyone used these approaches right out of the box to win this competition.\n", "\n", "BUT, hopefully you see some duplication in your feature engineering / modelling pipeline and that this type of set up might help you re-use some of that code for a better result in your future comps.\n", "\n", "Miller out.\n", "\n", "PS: If you want any of this explained just add a comment and I'll get around to it when I can."]}], "nbformat_minor": 1}