{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "492490c8-0fbe-4503-abfb-2339cef48e84"
      },
      "source": [
        "# Loan data characteristics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56a223a9-751f-4832-b356-e2ddea9598a0"
      },
      "outputs": [],
      "source": [
        "# Imports and setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Kaggle note: Any results written to the current directory are saved as output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65c0a7fa-d76c-4d5c-b0cb-8228ae0581fc"
      },
      "outputs": [],
      "source": [
        "# Read loan data\n",
        "date_cols = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d']\n",
        "loans = pd.read_csv(\"../input/loan.csv\", low_memory=False, index_col='id',\n",
        "    parse_dates=date_cols, infer_datetime_format=True)\n",
        "print(\"Dataset size: {}\".format(loans.shape))\n",
        "print(loans.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bfbaf859-d789-4110-bc07-b4f873daff13"
      },
      "outputs": [],
      "source": [
        "# What columns do we have?\n",
        "print(\"{} columns: {}\".format(len(loans.columns), loans.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6eaa02e2-fad0-4913-9fde-18b75f7289fd"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at the different columns and what data they contain\n",
        "#cols = loans.columns[0:10]  # cycle through 0:10, 10:20, ...\n",
        "cols = ['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length']  # or pick specific columns\n",
        "print(cols)\n",
        "for col in cols:\n",
        "    print(loans[col].describe())  # describe one by one in case of mixed types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0daa8301-bd97-4911-b031-9afd590910d5"
      },
      "outputs": [],
      "source": [
        "# Parse term durations: ' 36 months' -> 36 (numeric)\n",
        "print(\"term before:-\")\n",
        "print(loans.term.head())\n",
        "loans.term = pd.to_numeric(loans.term.str[:3])\n",
        "print(\"term after:-\")\n",
        "print(loans.term.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b342e544-be9b-432b-b42f-0e3ea252205c"
      },
      "outputs": [],
      "source": [
        "# Parse emp_length: '< 1 year' -> 1.0, '1 year' -> 1.0, '7 year' -> 7.0, etc. (numeric)\n",
        "print(\"emp_length before:-\")\n",
        "print(loans.emp_length.head())\n",
        "loans.emp_length = loans.emp_length.str.extract(\"(\\d+)\", expand=False).map(float)\n",
        "print(\"emp_length after:-\")\n",
        "print(loans.emp_length.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4419febe-f639-489a-9170-24ff0ebc8980"
      },
      "outputs": [],
      "source": [
        "# What is the distribution of loans by status?\n",
        "loans_by_status = loans.groupby('loan_status')\n",
        "print(loans_by_status['loan_status'].count())\n",
        "loans_by_status['loan_status'].count().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f526cf41-9d98-4fcf-98a3-b205a8fb9b05"
      },
      "outputs": [],
      "source": [
        "# What is the distribution of loans by purpose?\n",
        "loans_by_purpose = loans.groupby('purpose')\n",
        "print(loans_by_purpose['purpose'].count())\n",
        "loans_by_purpose['purpose'].count().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8eb43c1c-6142-491f-a5f7-611c6f6e140d"
      },
      "outputs": [],
      "source": [
        "# What is the distribution of loans by term?\n",
        "loans_by_term = loans.groupby('term')\n",
        "print(loans_by_term['term'].count())\n",
        "loans_by_term['term'].count().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5df31d6f-2f3a-416f-aa66-90822282dbe8"
      },
      "source": [
        "## Binary Classification Task\n",
        "Goal: Predict loans at application stage that will default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5345e43a-1622-4edf-b175-084732fb8e9f"
      },
      "outputs": [],
      "source": [
        "# Select loans issued within desired date range\n",
        "#loans.issue_d.describe()  # dataset range: 2007-06-01 to 2015-12-01\n",
        "range_selected = ('2007-06-01', '2010-12-31')\n",
        "loans_selected = loans.loc[(range_selected[0] <= loans.issue_d) & (loans.issue_d <= range_selected[1])]\n",
        "print(\"{num} loans were issued from {range[0]} to {range[1]}\".format(num=len(loans_selected), range=range_selected))\n",
        "\n",
        "# What is their distribution by status?\n",
        "print(loans_selected.groupby('loan_status')['loan_status'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02e8f293-2cd3-4a6d-bfc5-5e4e8aef9ba4"
      },
      "outputs": [],
      "source": [
        "# Let's setup a binary classification target 'default': 0 => Fully Paid, 1 => Charged Off\n",
        "loans_subset = loans_selected.copy()\n",
        "loans_subset['default'] = None\n",
        "loans_subset.loc[(loans_subset.loan_status == 'Fully Paid') | (loans_subset.loan_status == 'Does not meet the credit policy. Status:Fully Paid'), 'default'] = 0\n",
        "loans_subset.loc[(loans_subset.loan_status == 'Charged Off') | (loans_subset.loan_status == 'Does not meet the credit policy. Status:Charged Off'), 'default'] = 1\n",
        "\n",
        "# Drop loans that haven't been terminated yet (we don't know what their final status will be)\n",
        "loans_subset = loans_subset[~loans_subset.default.isnull()]\n",
        "print(\"Data subset size: {}\".format(loans_subset.shape))\n",
        "\n",
        "# Re-encode 'default' column as numeric (0 or 1)\n",
        "loans_subset['default'] = pd.to_numeric(loans_subset['default'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bad67d5b-d51e-4614-bde9-627c2e480abe"
      },
      "outputs": [],
      "source": [
        "# Drop columns that are unimportant, superfluous or leak target information\n",
        "# Note: We only want to keep information that is available at loan *application* stage\n",
        "application_cols = [\n",
        "    # Identifiers and dates\n",
        "    #'id',  # used as index column\n",
        "    'member_id',\n",
        "    'issue_d',\n",
        "    \n",
        "    # Loan application details\n",
        "    #'application_type',  # all 'INDIVIDUAL'\n",
        "    'loan_amnt',  # $ applied for\n",
        "    'term',  # 36 or 60 months\n",
        "    'int_rate',  # % annual (?) interest rate\n",
        "    'installment',  # $ monthly payment\n",
        "    'emp_title',  # employee/employer title\n",
        "    'emp_length',  # 0-10+ years\n",
        "    'home_ownership',  # RENT, OWN, MORTGAGE, etc.\n",
        "    'verification_status',  # mostly 'Not Verified'\n",
        "    #'verification_status_joint',  # all 0\n",
        "    'purpose',  # 'debt_consolidation', 'small_business', etc.\n",
        "    'title',  # text\n",
        "    #'desc',  # text, too verbose, may contain updates after application stage\n",
        "    'zip_code',  # 100XX\n",
        "    'addr_state',  # covered by zip_code?\n",
        "    \n",
        "    # Additional loan listing details\n",
        "    #'initial_list_status',  # all 'f'\n",
        "    #'policy_code',  # all 1\n",
        "    #'url',  # unqiue per loan\n",
        "\n",
        "    # Borrower's creditworthiness\n",
        "    'annual_inc', #'annual_inc_joint',  # income ($; individual only, no joint loans)\n",
        "    'dti', #'dti_joint',  # debt-to-income ratio (%; individual only, no joint loans)\n",
        "    'revol_bal', 'revol_util',  # revolving accounts: balance ($), utilization (%)\n",
        "    #'tot_cur_bal', 'max_bal_bc',  # overall balance: total current, max; all null\n",
        "    'earliest_cr_line', 'total_acc', 'open_acc',  # credit accounts\n",
        "    'inq_last_6mths', #'inq_last_12m', 'inq_fi',  # credit inquiries (only 6 mths available)\n",
        "    'delinq_2yrs', 'mths_since_last_delinq', #'acc_now_delinq',  # delinquency (acc_now_delinq is mostly 0)\n",
        "    #'tot_coll_amt', 'collections_12_mths_ex_med',  # collections; all null or 0\n",
        "    #'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',  # installment accounts; all null\n",
        "    #'open_acc_6m', 'open_rv_12m', 'open_rv_24m', 'total_rev_hi_lim', 'total_cu_tl', 'all_util', # revolving trading accounts; all null\n",
        "    \n",
        "    # Public records\n",
        "    'pub_rec', 'mths_since_last_record',\n",
        "    #'mths_since_last_major_derog',  # all null\n",
        "\n",
        "    # Loan rating as determined by lender (potential multi-class targets to predict?)\n",
        "    #'grade',\n",
        "    #'sub_grade',\n",
        "\n",
        "    # Desired binary target to predict\n",
        "    'default'\n",
        "]\n",
        "\n",
        "loans_small = loans_subset[application_cols]\n",
        "\n",
        "# Check selected data subset\n",
        "print(\"Small dataset has {} rows, {} columns:\".format(len(loans_small), len(loans_small.columns)))\n",
        "print(loans_small.head())\n",
        "print(\"Class distribution:\")\n",
        "print(loans_small.groupby('default')['default'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6e96f6b-bd4b-4c0a-95fd-828f60f670e7"
      },
      "outputs": [],
      "source": [
        "# Write dataset to disk (if you want to save it)\n",
        "loans_small.to_csv(\"loans_small.csv\")\n",
        "print(\"Dataset saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62889569-86a2-444e-8f6b-7fae66c1c140"
      },
      "outputs": [],
      "source": [
        "# Read back from disk (to skip all previous steps if you've saved it already)\n",
        "loans_small = pd.read_csv(\"loans_small.csv\", index_col=0, parse_dates=True)\n",
        "print(\"Loaded data has {} rows, {} columns:\".format(len(loans_small), len(loans_small.columns)))\n",
        "print(loans_small.head())\n",
        "print(\"Class distribution:\")\n",
        "print(loans_small.groupby('default')['default'].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d0ddfe9-4325-472d-be76-7663faf481e1"
      },
      "outputs": [],
      "source": [
        "# Specify a subset of feature columns and a target to predict ('default')\n",
        "feature_cols = [\n",
        "    'loan_amnt', 'term', 'int_rate', 'installment', 'purpose',\n",
        "    #'emp_title', # free text\n",
        "    'emp_length', 'home_ownership',\n",
        "    #'zip_code', 'addr_state',  # categorical, but too many levels\n",
        "    'annual_inc', 'dti',\n",
        "    'revol_bal', 'revol_util',\n",
        "    'verification_status'\n",
        "]\n",
        "\n",
        "target_col = 'default'\n",
        "\n",
        "# Create the final dataset we'll use for classification\n",
        "keep_cols = feature_cols + [target_col]\n",
        "loans_final = loans_small[keep_cols]\n",
        "\n",
        "# Drop samples with null values (few enough that we can ignore)\n",
        "loans_final.dropna(inplace=True)\n",
        "\n",
        "print(\"Final dataset: {} features, {} samples\".format(len(loans_final.columns), len(loans_final)))\n",
        "print(loans_final.head())\n",
        "print(\"Final class distribution (after dropping nulls):\")\n",
        "class_counts = loans_final.groupby(target_col)[target_col].agg({\n",
        "    'count': len,\n",
        "    'ratio': lambda x: float(len(x)) / len(loans_final)\n",
        "})\n",
        "print(class_counts)\n",
        "\n",
        "# Extract desired features and target column\n",
        "X = loans_final[feature_cols]\n",
        "y = loans_final[target_col]\n",
        "print(\"{} features: {}\".format(len(X.columns), X.columns))\n",
        "print(\"Target: {}\".format(y.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c4befcd-d9b3-4a35-ba22-94a58c1ca3a2"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables among features\n",
        "categorical_vars = ['home_ownership', 'purpose', 'verification_status']\n",
        "X = pd.get_dummies(X, columns=categorical_vars, drop_first=True)\n",
        "print(\"{} features after encoding categorical variables: {}\".format(len(X.columns), X.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cdc74ab6-d54a-43d8-9626-46652d80a2d9"
      },
      "outputs": [],
      "source": [
        "# Split into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "print(\"Training set: {} samples, test set: {} samples\".format(len(X_train), len(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6cac11d8-e477-4b23-8e83-4be73ff69191"
      },
      "outputs": [],
      "source": [
        "# Common sklearn imports\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define a simple train-predict utility function\n",
        "def train_predict(clf, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Train clf on <X_train, y_train>, predict <X_test, y_test>; return y_pred.\"\"\"\n",
        "    print(\"Training a {}...\".format(clf.__class__.__name__))\n",
        "    %time clf.fit(X_train, y_train)\n",
        "    print(clf)\n",
        "    \n",
        "    print(\"Predicting test labels...\")\n",
        "    y_pred = clf.predict(X_test)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da919a36-e5f6-424f-b9fa-1ac1c67d23a6"
      },
      "outputs": [],
      "source": [
        "# Classify using a Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "y_pred = train_predict(clf, X_train, X_test, y_train, y_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Analyze feature importance\n",
        "feature_imps = pd.DataFrame({'feature': X_train.columns, 'importance': clf.feature_importances_})\n",
        "feature_imps.sort_values(by='importance', ascending=False, inplace=True)\n",
        "print(\"Top 10 important features:\")\n",
        "print(feature_imps[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb988a25-a807-43b5-a0e9-c5f0b9547e65"
      },
      "outputs": [],
      "source": [
        "# Classify using a Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "y_pred = train_predict(clf, X_train, X_test, y_train, y_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f0a4dfa-24d7-48c8-ae64-50f73ba7925b"
      },
      "outputs": [],
      "source": [
        "# Classify using a Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf = GradientBoostingClassifier(n_estimators=100, max_depth=1, learning_rate=1.0, random_state=42)\n",
        "y_pred = train_predict(clf, X_train, X_test, y_train, y_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5877382e-0ebe-4e9e-9afe-34196ef06a1e"
      },
      "outputs": [],
      "source": [
        "# Note: The performance on the interesting class (default=1) is very low!\n",
        "# TODO: Try subsampling the other class (default=0) or other methods to mitigate class imbalance."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}