{"cells":[{"metadata":{"_uuid":"d28baf3a8c22266569f23d22b8dcca007dcb3d98"},"cell_type":"markdown","source":"**Libraries import**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24bc562049ce613d487011c398af8b9569fe2525"},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"_uuid":"3fad949cdb3327bfc9ff881d0939e2c98f77a354"},"cell_type":"markdown","source":"Check for the columns with null values"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"train_df.isnull().sum()[train_df.isnull().sum()>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51f5678b62e0d3906a5fdf2d148c582e1594302a"},"cell_type":"markdown","source":"I proceed by creating a new variable in which I'll store the categorical values of variables 'tipoviviX'. These indicate the household's situation."},{"metadata":{"trusted":true,"_uuid":"46a75b7c6f2620bdf02f5c90718ac4970b6b60c0"},"cell_type":"code","source":"def join_columns(df):\n    df.loc[df['tipovivi1']==1, 'tipovivigral'] = 1 #Owns\n    df.loc[df['tipovivi2']==1, 'tipovivigral'] = 2 #Paying installments\n    df.loc[df['tipovivi3']==1, 'tipovivigral'] = 3 #Rented\n    df.loc[df['tipovivi4']==1, 'tipovivigral'] = 4 #Precarious\n    df.loc[df['tipovivi5']==1, 'tipovivigral'] = 5 #Other\n\njoin_columns(train_df)\n\nf, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(25,8))\n\nsns.countplot(train_df['tipovivigral'][train_df['v2a1'].isnull()], ax=ax1)\nax1.set_title('NULL Rent')\nax1.set_xticklabels(['Owns', 'Precarious', 'Other'], rotation=30)\nax1.set_xlabel('Household Situation')\n\nsns.countplot(train_df['tipovivigral'][train_df['v2a1'].notnull()], ax=ax2)\nax2.set_title('Not NULL Rent')\nax2.set_xticklabels(['Paying Installments', 'Rented'], rotation=30)\nax2.set_xlabel('Household Situation')\n\nsns.countplot(train_df['tipovivigral'][train_df['v2a1']==0], ax=ax3)\nax3.set_title('Rent = 0')\nax3.set_xticklabels(['Paying Installments'], rotation=30)\nax3.set_xlabel('Household Situation')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa469926b8f700c481f9f5777251e6f5c71cdc20"},"cell_type":"markdown","source":"I assume that null values are 0"},{"metadata":{"trusted":true,"_uuid":"5ffc84d0132f37b65f17c0bcfe8937adfebe2e0a"},"cell_type":"code","source":"train_df.loc[train_df['v2a1'].isnull(),'v2a1'] = 0\n\nf, (ax1, ax2) = plt.subplots(1,2, figsize=(25,8))\n\nsns.countplot(train_df['tipovivigral'][train_df['v2a1']==0], ax = ax1)\nax1.set_title('Not paying rent')\nax1.set_xticklabels(['Owns','Paying Installments', 'Precarious', 'Other'], rotation=30)\nax1.set_xlabel('Household Situation')\n\nsns.countplot(train_df['tipovivigral'][train_df['v2a1']!=0], ax = ax2)\nax2.set_title('Paying rent')\nax2.set_xticklabels(['Paying Installments', 'Rented'], rotation=30)\nax2.set_xlabel('Household Situation')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02ca1d4fd3d94ebecc56efd659d02b1a0a74b77f"},"cell_type":"markdown","source":"v18q1 correspond to the number of tablets a household owns"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5f5a9a9b6b2233c86cc22d0645a210de4fa27f0f"},"cell_type":"code","source":"sns.countplot(train_df['v18q1'].isnull())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c417838775b9baa749b8cd0304a4f9dc2be6dd8f"},"cell_type":"markdown","source":"So I convert these values into 0"},{"metadata":{"trusted":true,"_uuid":"0b23af28a62f245cef365b3f2c4c15d0398127dc"},"cell_type":"code","source":"train_df.loc[train_df['v18q1'].isnull(), 'v18q1'] = 0\ntrain_df['v18q1'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d14f87bab4bf10ff53b3740e4933f7e70f58593"},"cell_type":"markdown","source":"'rez_esc' correspond to the Number of years behind in school"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f5608b3644e16ac65f4440479fd5d00e3546832d"},"cell_type":"code","source":"train_df[['rez_esc','escolari']][train_df['rez_esc'].notnull()].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49c3f017bbbb023c1a82053d60ac576a92df159b"},"cell_type":"markdown","source":"The data we have in this column is vague and does not bring any value to the dataset, so I'll drop it"},{"metadata":{"trusted":true,"_uuid":"c71cd845932c8d99c2dfb3b7a09a3f4ff5c5a600"},"cell_type":"code","source":"train_df.drop(columns='rez_esc', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c71d70604782c0d7962a9f5f3e2932603b5711e3"},"cell_type":"markdown","source":"To conlude taking care of the null values, I replace 'meaneduc' values by its mean and 'meaneducSQB' by its squared mean"},{"metadata":{"trusted":true,"_uuid":"40c7414f8fd424ebbb349f8dc521dc1b1071ee6c"},"cell_type":"code","source":"train_df.loc[train_df['meaneduc'].isnull(), 'meaneduc'] = abs(train_df['meaneduc'].mean())\ntrain_df.loc[train_df['SQBmeaned'].isnull(), 'SQBmeaned'] = abs(train_df['meaneduc'].mean())**2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe4f65513fd27f1a6b2ce6f3f0d79fc6e929a93a"},"cell_type":"markdown","source":"As every ML algorithm requires the dataset to have only numeric values..."},{"metadata":{"trusted":true,"_uuid":"baa615135351d44b5dc550372f241d64ac5ac284"},"cell_type":"code","source":"train_df.applymap(np.isreal).any()[(train_df.applymap(np.isreal).any())==False]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a97cbd55c3c5160719584d805ef3d14b6700a9d"},"cell_type":"markdown","source":"I start looking for the non-numerical values of the 'dependency' column "},{"metadata":{"trusted":true,"_uuid":"126ad733eda32c41efa65c28be11dfcf9d3703f7"},"cell_type":"code","source":"train_df.groupby('dependency')['Id'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c9e85c0e8003b4fa99ad92fe370ccab7c76af21"},"cell_type":"markdown","source":"The 'no' values are clearly 0s. And for the 'yes', I'll contemplate them as the mode"},{"metadata":{"trusted":true,"_uuid":"3b6d5bd302fdedafaa84453454debb76b24367de"},"cell_type":"code","source":"train_df.loc[train_df['dependency'] == 'yes', 'dependency'] = train_df.loc[(train_df['dependency']!='yes') & (train_df['dependency']!='no'), 'dependency'].mode()[0]\ntrain_df.loc[train_df['dependency'] == 'no', 'dependency'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2836130318557e07f6f86f2d2be0784ff7baa01c"},"cell_type":"markdown","source":"The column 'edjefe' indicates the amount of years of education of the male head of household, the same for 'edjefa' with females"},{"metadata":{"trusted":true,"_uuid":"538311f372328bf54113c393a0b7ad93432f7d16"},"cell_type":"code","source":"train_df.groupby('edjefe')['Id'].count().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56deb9f45836f11a5984ea19e40c5596cf2ac0d9"},"cell_type":"markdown","source":"So I have a lot of yes-no values again. We'll make an attempt to get a better understanding of this values by considering the household"},{"metadata":{"trusted":true,"_uuid":"2d23b8a3b8352e7fa3bd45c54b7845af41b97c80"},"cell_type":"code","source":"def complete_edjefe_edjefa(edjefe_jefa, sex, new_column, value):\n    no_records = train_df['idhogar'][train_df[edjefe_jefa]==value].drop_duplicates()\n    no_households = train_df[[edjefe_jefa, 'idhogar','escolari','age',sex]].where(lambda x : x['idhogar'].isin(no_records)).dropna()\n   \n    # I create a new column in which we are going to highlight the yes-no households with jefas \n    no_households.loc[(no_households[sex]==1) & (no_households['age']>=18), new_column] = 1\n    no_households.loc[no_households[edjefe_jefa].isnull(), new_column] = 0\n    households_by_jefa = no_households.groupby('idhogar')[[new_column,'escolari']].max().reset_index()\n   \n    # I get rid of the no values that can be replaced by the jefe/jefa's escolari values\n    for index, row in households_by_jefa.iterrows():\n        if row[new_column] == 1:\n            train_df.loc[train_df['idhogar'] == row['idhogar'], edjefe_jefa] = row['escolari']\n\ncomplete_edjefe_edjefa('edjefe', 'male', 'jefeexists', 'yes')\ncomplete_edjefe_edjefa('edjefa', 'female', 'jefaexists', 'yes')\ncomplete_edjefe_edjefa('edjefe', 'male', 'jefeexists', 'no')\ncomplete_edjefe_edjefa('edjefa', 'female', 'jefaexists', 'no')\n\n#The remaining 'no' values correspond to households where there's no pressence of a father (jefe) or mother (jefa), so we'll turn those values into 0\ntrain_df.loc[train_df['edjefe'] == 'no', 'edjefe'] = 0\ntrain_df.loc[train_df['edjefa'] == 'no', 'edjefa'] = 0 ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fb1d903c6789a0adf0748f90d5896e15c5608eb"},"cell_type":"markdown","source":"The 2 remaining columns correspond to id values. Those are going to be dropped\nI also get rid of the 'tipovivigral' variable, I created before"},{"metadata":{"trusted":true,"_uuid":"f3b3ac6ec37b00f53f585e23fc3fe1806b281593"},"cell_type":"code","source":"train_df.drop(columns=['Id','idhogar','tipovivigral'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e3dde8a848a924a2e275537c73491e2812f5d8e"},"cell_type":"markdown","source":"Let's check if all our variables have numerical values"},{"metadata":{"trusted":true,"_uuid":"874f7e7e365fe9ce780b994b119776ac44236a4a"},"cell_type":"code","source":"train_df.dtypes[(train_df.dtypes != 'int64') & (train_df.dtypes != 'float64')]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"401932d4d08e05c12afbdddb2b1f54cfaea7d76e"},"cell_type":"markdown","source":"I cast the ones that reamined as 'object'"},{"metadata":{"trusted":true,"_uuid":"52300b8681e6ea756e2fbd951462e99f25759f45"},"cell_type":"code","source":"train_df['dependency'] = train_df['dependency'].astype(float)\ntrain_df['edjefe'] = train_df['edjefe'].astype(int)\ntrain_df['edjefa'] = train_df['edjefa'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9895741941f34600513ea2b53e8fbf07533898f4"},"cell_type":"markdown","source":"**Training**"},{"metadata":{"_uuid":"118f8aadec3e679fd6081f6d486deba385eaf244"},"cell_type":"markdown","source":"I start by dividing the dataset into training and test set"},{"metadata":{"trusted":true,"_uuid":"5274841d75645dc0eb765a19c1077d65eeca1e9d"},"cell_type":"code","source":"X = train_df.iloc[:,0:len(train_df.columns)-1]\ny = train_df.iloc[:,len(train_df.columns)-1]\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n\nfrom xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c617771ccab1e71129dd1146df80f1144f3e43d"},"cell_type":"markdown","source":"Once I get the classifier, I proceed by predicting the test set.\nThen I calculate the accuracy out of my confusion matrix"},{"metadata":{"trusted":true,"_uuid":"4f311830656ce0cff9921be33077c63962d3ce71"},"cell_type":"code","source":"y_pred = classifier.predict(X_test)\n\n# Creating the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\ndef calculate_accuracy(cm):\n    correct=0\n    incorrect=0\n    for i in range(4):\n        for j in range(4):\n            if i == j:\n                correct = correct + cm[i][j]\n            else:\n                incorrect = incorrect + cm[i][j]\n    return correct/(correct+incorrect)\n\ncalculate_accuracy(cm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e8ce06b9dd09c2aabb45aafede7f3da339e77ec"},"cell_type":"markdown","source":"To improve the results, I'm gonna implement 'grid_search' function to get the best parameters for my classifier"},{"metadata":{"trusted":true,"_uuid":"37f37e3431e408ac706a3d4b4d05611e244a4077"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = {'min_child_weight': [0.5, 1.5],\n              'gamma': [0.1, 0.3],\n              'subsample': [0.7, 0.9],\n              'colsample_bytree': [0.9],\n              'max_depth': [5, 7]}\n\ngrid_search = GridSearchCV(estimator = classifier,\n                            param_grid = parameters,\n                            scoring = 'accuracy',\n                            cv = 5,\n                            n_jobs = -1)\n\ngrid_search = grid_search.fit(X_train, y_train)\nbest_accuracy = grid_search.best_score_\nbest_parameters = grid_search.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589e706183acd447cf757815584ceb3a7a675e39"},"cell_type":"code","source":"best_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65b4ac435c1115f0d7a1f47f18e6cd62dbc3abce"},"cell_type":"code","source":"best_parameters","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a70260a41897e92085e313661006402ee40190a5"},"cell_type":"markdown","source":"With the best_parameters variable, I'm able to retry fitting my classifier, only that this time with better parameters"},{"metadata":{"trusted":true,"_uuid":"08e2be2d3e74ab50ff34eb4fae343b2a79df59d6"},"cell_type":"code","source":"classifier = XGBClassifier(colsample_bytree = 0.9, \n                           gamma = 0.1,\n                           max_depth = 7,\n                           min_child_weight = 0.5,\n                           subsample = 0.9)\nclassifier.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"757a5d4793ccf055c7231dd62dac2eb4ad065c42"},"cell_type":"markdown","source":"To conclude, I'll plot the feature importance to get knowledge of our most important columns"},{"metadata":{"trusted":true,"_uuid":"20e7ad615f88e76c8ca65c4f821cf8a87c08bbce"},"cell_type":"code","source":"feat_imp = pd.DataFrame({'importance':classifier.feature_importances_})    \nfeat_imp['feature'] = X_train.columns\nfeat_imp.sort_values(by='importance', ascending=False, inplace=True)\nfeat_imp = feat_imp.iloc[:10]\nfeat_imp.sort_values(by='importance', inplace=True)\nfeat_imp = feat_imp.set_index('feature', drop=True)\nfeat_imp.plot.barh(title='Feature Importance')\nplt.xlabel('Feature Importance Score')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69738bdeef4de9ffcf7f208ec3949b7c7ab8049d"},"cell_type":"markdown","source":"I produce the same cycle, only that this time for test.csv"},{"metadata":{"trusted":true,"_uuid":"50d37407bcb5e9b69cdcb1db40f7d3909870713c"},"cell_type":"code","source":"test_df.loc[test_df['v2a1'].isnull(),'v2a1'] = 0\ntest_df.loc[test_df['v18q1'].isnull(), 'v18q1'] = 0\ntest_df.drop(columns='rez_esc', inplace = True)\ntest_df.loc[test_df['meaneduc'].isnull(), 'meaneduc'] = abs(test_df['meaneduc'].mean())\ntest_df.loc[test_df['SQBmeaned'].isnull(), 'SQBmeaned'] = abs(test_df['meaneduc'].mean())**2\ntest_df.loc[test_df['dependency'] == 'yes', 'dependency'] = test_df.loc[(test_df['dependency']!='yes') & (test_df['dependency']!='no'), 'dependency'].mode()[0]\ntest_df.loc[test_df['dependency'] == 'no', 'dependency'] = 0\ndef complete_edjefe_edjefa(edjefe_jefa, sex, new_column, value):\n    no_records = test_df['idhogar'][test_df[edjefe_jefa]==value].drop_duplicates()\n    no_households = test_df[[edjefe_jefa, 'idhogar','escolari','age',sex]].where(lambda x : x['idhogar'].isin(no_records)).dropna()\n    #We create a new column in which we are going to highlight the yes-no households with jefas \n    no_households.loc[(no_households[sex]==1) & (no_households['age']>=18), new_column] = 1\n    no_households.loc[no_households[edjefe_jefa].isnull(), new_column] = 0\n    households_by_jefa = no_households.groupby('idhogar')[[new_column,'escolari']].max().reset_index()   \n    #We get rid of the no values that can be replaced by the jefe/jefa's escolari values\n    for index, row in households_by_jefa.iterrows():\n        if row[new_column] == 1:\n            test_df.loc[test_df['idhogar'] == row['idhogar'], edjefe_jefa] = row['escolari']\ncomplete_edjefe_edjefa('edjefe', 'male', 'jefeexists', 'yes')\ncomplete_edjefe_edjefa('edjefa', 'female', 'jefaexists', 'yes')\ncomplete_edjefe_edjefa('edjefe', 'male', 'jefeexists', 'no')\ncomplete_edjefe_edjefa('edjefa', 'female', 'jefaexists', 'no')\ntest_df.loc[test_df['edjefe'] == 'no', 'edjefe'] = 0\ntest_df.loc[test_df['edjefa'] == 'no', 'edjefa'] = 0 \nsubs = pd.DataFrame()\nsubs['Id'] = test_df['Id']\ntest_df.drop(columns=['Id','idhogar'], inplace = True)\ntest_df['dependency'] = test_df['dependency'].astype(float)\ntest_df['edjefe'] = test_df['edjefe'].astype(int)\ntest_df['edjefa'] = test_df['edjefa'].astype(int)\nX = test_df.iloc[:,0:len(test_df.columns)]\n\ny_pred = classifier.predict(X)\ny_pred = pd.DataFrame(y_pred)\n\nsubs['Target'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4922c0023885341d6fed923cc322ed34838041f"},"cell_type":"markdown","source":"I create the submission"},{"metadata":{"trusted":true,"_uuid":"bc9561a7ef4c9a6da94d92f63759295cba2ddf30"},"cell_type":"code","source":"subs.to_csv('sample_submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}