{"cells":[{"metadata":{"_uuid":"6eba611f7f1f6bf1baba0d9f42250aeaebe02356"},"cell_type":"markdown","source":"In this kernel I am trying to predict cooking style from the ingredients of the recipe. To do so, I will use an embedding neural network for each ingredient and sum up the embedding vectors.\nThe embedding layer needs to be pretrained with the ingredients beforehand.\nThe idea behind this approach is that the embedding vector of each ingredient will cointain the relevancy of this ingredient to each type of cuisine, and when these embeddings are summed up, the result will show the relevancy of the whole recipe."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \n\nimport json, csv\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.layers import Input, Embedding, Dense,Lambda,Dropout\nfrom keras.models import Model\nfrom keras.utils import to_categorical\nfrom keras import backend as K\nimport os\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"with open(\"../input/train.json\") as f:\n    data=json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b7a70b8971e15415239c6f749fa42d4513e78a0a"},"cell_type":"code","source":"#First, let's make encoders for the ingredients and cuisines. I preffer to do this manually using dictionaries\ncuisines=[]\ningredients=[]\nn_ingredients=[]\nfor each in data:\n    ingredients+=each['ingredients']\n    cuisines+=[each['cuisine']]\ningredients=list(set(ingredients))\ncuisines=list(set(cuisines))\n\ncuisine_encoder={c:i for i,c in enumerate(cuisines)}\ningredients_encoder={c:(i+1) for i,c in enumerate(ingredients)}\n#For the ingredients we reserve the 0 for unknown","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99ab1342c5b165602dd577b109d75c2f854b434c","collapsed":true},"cell_type":"code","source":"#Then, I create the input and output lists for both the pre-training of the embedding and the final model\nX,y,y_embedding, X_embedding=[],[],[],[]\nfor each in data:\n    y.append(cuisine_encoder[each['cuisine']])\n    each_ingredients=[ingredients_encoder[ingredient] for ingredient in each['ingredients']]\n    X.append(each_ingredients)\n    y_embedding+=[cuisine_encoder[each['cuisine']]]*len(each_ingredients)\n    X_embedding+=each_ingredients\n\nX=np.array(X)\ny=to_categorical(y)\nX_embedding=np.array(X_embedding)\ny_embedding=to_categorical(y_embedding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3b7909296fd7010f0375b721e5be12cba9494f0","collapsed":true},"cell_type":"code","source":"# Here, I define the split strategy and the generator for Keras Library\n\ndef split(n_samples,p_split=0.9):\n    idx=np.arange(n_samples)\n    np.random.seed(42)\n    np.random.shuffle(idx)\n    train_samples=int(n_samples*p_split)\n    idx_train,idx_test = idx[:train_samples],idx[train_samples:]\n    return idx_train,idx_test\n\nclass generator(object):\n    def __init__(self,X,y,idx,batch_shape=1):\n        self.X = X\n        self.y = y\n        self.indexes = idx.copy()\n        self.batch_shape = batch_shape\n    def next(self):\n        while True:\n            self.indexes=np.roll(self.indexes,self.batch_shape)\n            if self.batch_shape != 1:\n                batch_x= np.expand_dims(self.X[self.indexes[:self.batch_shape]],0)\n                batch_y= np.expand_dims(self.y[self.indexes[:self.batch_shape]],0)\n            else:\n                batch_x= np.expand_dims(self.X[self.indexes[0]],0)\n                batch_y= np.expand_dims(self.y[self.indexes[0]],0)\n            yield batch_x,batch_y\n    def __len__(self):\n        return len(self.indexes)//self.batch_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f48fe1f9c80ce3e5e9f9623365270d860a56c88","collapsed":true},"cell_type":"code","source":"# Now we set the lenght of the embedings and the model for pretraining\n\nembedding_dims = 128\n\ninput_ingredients = Input(batch_shape=(None, None))\n\nembed=Embedding(output_dim=embedding_dims,input_dim=10000)(input_ingredients)\nout = Dense(len(cuisines), activation='softmax',name='output')(embed)\n\nmodel = Model(inputs=[input_ingredients], outputs=[out])\n\nmodel.compile(optimizer='adam',\n          loss='categorical_crossentropy',\n          metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44d8c71fe83b6cfcb94d1a82b846e48d067625e4"},"cell_type":"code","source":"# After setting up the generators, we train the model\nidx_train,idx_test=split(len(X_embedding))\ng_train=generator(X_embedding,y_embedding,idx_train,batch_shape=32)\ng_test=generator(X_embedding,y_embedding,idx_test,batch_shape=32)\n\nhistory=model.fit_generator(generator=g_train.next(), steps_per_epoch = len(g_train),\n                            validation_data = g_test.next(), validation_steps = len(g_test),\n                            epochs=10)\n\nplt.figure()\n[plt.plot(v,label=str(k)) for k,v in history.history.items()]\nplt.legend()\nplt.show()\n\nweights = model.layers[1].get_weights()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d78526d6d0c4bf056ba623af0152c9c21944008b","collapsed":true},"cell_type":"code","source":"input_ingredients = Input(batch_shape=(None,None))\n\nembed=Embedding(output_dim=embedding_dims,input_dim=10000,weights=[weights],trainable=False)(input_ingredients)\n\nx = Lambda(lambda x: K.sum(x, axis=1))(embed)\nx=Dropout(0.2)(x)\nx = Dense(1024, activation='relu')(x)\nout = Dense(len(cuisines), activation='softmax',name='output')(x)\n\nmodel = Model(inputs=[input_ingredients], outputs=[out])\n\nmodel.compile(optimizer='adam',\n          loss='categorical_crossentropy',\n          metrics=['categorical_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cd09de949fb586507e43fe6e59cddd79b075543c"},"cell_type":"code","source":"idx_train,idx_test=split(len(X))\ng_train=generator(X,y,idx_train)\ng_test=generator(X,y,idx_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73e6bd3ed53c88463dad93c911703badc9584b50","collapsed":true},"cell_type":"code","source":"log=model.fit_generator(generator=g_train.next(), steps_per_epoch = len(idx_train),\n                            validation_data = g_test.next(), validation_steps = len(idx_test),\n                            use_multiprocessing=False,\n                            epochs=10)\nplt.figure()\n[plt.plot(v,label=str(k)) for k,v in log.history.items()]\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1637178948c993765e69962a131f97716266cb28","collapsed":true},"cell_type":"code","source":"#Stochastic GD unique shapes: acc: 73/70\n#Stochastic GD with pre-training of the embedding: acc: 77/78\n#128: categorical_accuracy: 0.7888 - val_loss: 0.7004 - val_categorical_accuracy: 0.8122","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d0e0ede8348096203e51f8c15e7c0a1c17b6574","collapsed":true},"cell_type":"code","source":"# And finally, predict the test set and write the submission\nwith open(\"../input/test.json\") as f:\n    data=json.load(f)\n    \ncuisine_decoder={i:c for c,i in cuisine_encoder.items()}\n\ncuisines,ids = [], []\nfor each in data:\n    ingredients=[]\n    for ingredient in each['ingredients']:\n        if ingredient in ingredients_encoder.keys():\n            ingredients.append(ingredients_encoder[ingredient])\n        else:\n            ingredients.append(0)\n    ingredients = np.expand_dims(ingredients,0)\n    cuisine = model.predict(ingredients)\n\n    cuisines.append(cuisine_decoder[np.argmax(cuisine)])\n    ids.append(each['id'])\n\nwith open('submission.csv', 'w') as csvfile:\n    csvwriter = csv.writer(csvfile, delimiter=',',\n                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    csvwriter.writerow(('id','cuisine'))\n    for a,b in zip(ids, cuisines):\n        csvwriter.writerow([a,b])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e46d4a7252a44540ddf5516f7b548544665e035c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}