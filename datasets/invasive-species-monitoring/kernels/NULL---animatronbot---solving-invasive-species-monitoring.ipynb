{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.1"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0, "cells": [{"metadata": {"_uuid": "482663ec5ebf5246c168c90db520cf7afb9fabbb", "collapsed": false, "_cell_guid": "eed45511-e357-425b-878b-f25858f9d0cc", "_execution_state": "idle"}, "source": "An attempt at solving a Deep learning problem", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "355173bbf0fc443eca7a5faf49a54ab03ddb9f76", "trusted": false, "_cell_guid": "ad9c97ba-f92a-4efc-813a-8b836379e03b", "_execution_state": "idle"}, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n# modules required for the learning task\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os # for environment related stuff.\nimport scipy\n\n# for visualization stuff\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# keras modules required for this notebook\n# Starting architecture\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras.optimizers import SGD\n\n\n%matplotlib inline\n\n# for checking the os files related stuff (executing shell commands)\nfrom subprocess import check_output", "outputs": [], "cell_type": "code", "execution_count": 1}, {"metadata": {"_uuid": "ae3a275646114eef968db95e2edffe43c9672918", "collapsed": false, "trusted": false, "_cell_guid": "5324f4d2-416c-4a5c-8246-ec3d48b29b98", "_execution_state": "idle"}, "source": "# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# constant path to the data source\npath = \"../input\"\n\ndef exec_command(cmd):\n    '''\n        function to execute a shell command and see it's \n        output in the python console\n        @params\n        cmd = the command to be executed along with the arguments\n              ex: ['ls', '../input']\n    '''\n    print(check_output(cmd).decode(\"utf8\"))", "outputs": [], "cell_type": "code", "execution_count": 2}, {"metadata": {"_uuid": "3f366c3fe5b25c0ff791cfa2d369b81af4cfcf35", "collapsed": false, "trusted": false, "_cell_guid": "c2bff211-7e36-423c-99c8-15d9bc6da748", "_execution_state": "idle"}, "source": "# check the files in the data source environment:\nexec_command([\"ls\", path])", "outputs": [], "cell_type": "code", "execution_count": 3}, {"metadata": {"_uuid": "11455908b263eaf41c8c30c5278427e28d5f4e04", "collapsed": false, "trusted": false, "_cell_guid": "dfe6d087-8b72-45b3-a377-6da5aaacf656", "_execution_state": "idle"}, "source": "# check the structure of the train_labels.csv file\nexec_command(['head', '-10', os.path.join(path, 'train_labels.csv')])", "outputs": [], "cell_type": "code", "execution_count": 4}, {"metadata": {"_uuid": "cc924882e0597aa192de6c95e903fb66653038d8", "collapsed": false, "trusted": false, "_cell_guid": "8023589b-cf80-4eb5-ae37-36a1680ab4cf", "_execution_state": "idle"}, "source": "# load the labels from the csv dataset\nlabels_path = os.path.join(path, \"train_labels.csv\")\nlabels = pd.read_csv(labels_path).values\n\n# check the shape of the labels....\n# I am in love with the shape of you... ooo...o \nlabels.shape", "outputs": [], "cell_type": "code", "execution_count": 5}, {"metadata": {"_uuid": "f957219046491b47b229f6b097f54a01f60730b9", "collapsed": false, "trusted": false, "_cell_guid": "690b1da5-9b3e-4b9b-86b5-af761b01d61f", "_execution_state": "idle"}, "source": "# check the skewness in the data. (No of positive examples and No. of negative examples)\npos_count = (labels[:, 1] == 1).sum()\nneg_count = (labels[:, 1] == 0).sum()\n\nprint(\"No. of positive examples: %d\" %pos_count)\nprint(\"No. of negative examples: %d\" %neg_count)\n\n# plot a bar chart for better view into the dataset\nx_axis = ['Positive', 'Negative']\ny_axis = [pos_count, neg_count]\nsns.barplot(x_axis, y_axis); # semicolon to supress the output", "outputs": [], "cell_type": "code", "execution_count": 6}, {"metadata": {"_uuid": "38811e8e7ba55b20a75dc6c252e6803061e1c2f9", "collapsed": false, "_cell_guid": "607a26f9-e853-4dc4-8eba-a4c1e05744ad", "_execution_state": "idle"}, "source": "##Alright! So, there are only half as many negative examples as the positive examples in the original complete dataset.\n####Now we partition the dataset into train and cross validation datasets.", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "95d7b10332960faba83da78dae93f6817eb995dd", "collapsed": false, "trusted": false, "_cell_guid": "5f5b9f69-d809-4bca-8982-f199d996390b", "_execution_state": "idle"}, "source": "# shuffle the labels in the dataset:\nnp.random.shuffle(labels)\n\npartition = int(labels.shape[0] * 0.70)\ntrain_set = labels[:partition, :]\ncv_set = labels[partition: , :]\n\nprint(\"Train Partition: %s\" %str(train_set.shape))\nprint(\"cross Validation Partition: %s\" %str(cv_set.shape))", "outputs": [], "cell_type": "code", "execution_count": 7}, {"metadata": {"_uuid": "7bc958b624b94edf94bd7278278410f79a152a60", "collapsed": false, "trusted": false, "_cell_guid": "984132c9-0812-4279-b435-c7f15beadf04", "_execution_state": "idle"}, "source": "# now check the positive and negative distribution in the train and cross validation datatsets\np_train = (train_set[:, 1] == 1).sum()\nn_train = (train_set[:, 1] == 0).sum()\n\np_cv = (cv_set[:, 1] == 1).sum()\nn_cv = (cv_set[:, 1] == 0).sum()\n\nfig, axs = plt.subplots(ncols=2)\n\n# plot a bar chart for better view into the dataset\naxs[0].set_title(\"Training Partition\")\nx_axis = ['Positive', 'Negative']\ny_axis = [p_train, n_train]\nsns.barplot(x_axis, y_axis, ax=axs[0]); # semicolon to supress the output\n\naxs[1].set_title(\"Cross-validation Partition\")\nx_axis = ['Positive', 'Negative']\ny_axis = [p_cv, n_cv]\nsns.barplot(x_axis, y_axis, ax=axs[1]); # semicolon to supress the output", "outputs": [], "cell_type": "code", "execution_count": 8}, {"metadata": {"_uuid": "e6af29bf03880f4d820bda9bf0c3ad9b835c75db", "collapsed": false, "_cell_guid": "e01e781b-b874-42f7-9d03-b9bec8059079", "_execution_state": "idle"}, "source": "##Since the data was randomly shuffled before partitioning, it can be observed that the data elements skew has been preserved in the two partitions.", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "98d7fc9a44ed7a5b8bf967b3730c8c5828f27827", "collapsed": false, "trusted": false, "_cell_guid": "057f228d-da26-4638-8cfe-da4e578f1063", "_execution_state": "idle"}, "source": "# visualize a few images from the training set for the positive and negative labels\npos = (train_set[train_set[:, 1] == 1, :])\nneg = (train_set[train_set[:, 1] == 0, :])\n\n# randomly pick three images from the pos set and three images from the neg set\npos_images = pos[np.random.randint(pos.shape[0], size=3), 0]\nneg_images = neg[np.random.randint(neg.shape[0], size=3), 0]\n\n# display the pos_images:\nimages = zip(pos_images, neg_images)\n\nfig, axs = plt.subplots(ncols=2, nrows=3)\nfig.set_size_inches(20.5, 9.5)\n\naxs[0, 0].set_title(\"Positive examples\")\naxs[0, 1].set_title(\"Negative examples\")\n\ni = 0\nfor (pos_image, neg_image) in images:\n    pos_img_path = os.path.join(path, \"train\", str(pos_image) + \".jpg\")\n    neg_img_path = os.path.join(path, \"train\", str(neg_image) + \".jpg\")\n    p_image = scipy.ndimage.imread(pos_img_path)\n    n_image = scipy.ndimage.imread(neg_img_path)\n    axs[i, 0].imshow(p_image); axs[i, 1].imshow(n_image)\n    i += 1", "outputs": [], "cell_type": "code", "execution_count": 9}, {"metadata": {"_uuid": "73f2fe08b717839b914952123ae23226a9dcc83f", "collapsed": false, "trusted": false, "_cell_guid": "56a3cc23-0a6e-4937-93ee-f775cab137b3", "_execution_state": "idle"}, "source": "# check how large are the images and resize them to a standard size.\ntest_image = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", str(pos_images[0]) + \".jpg\")), \n                                 [100, 100, 3])\nplt.imshow(test_image)\nprint(\"shape of the input images: %s\" %str(test_image.shape))", "outputs": [], "cell_type": "code", "execution_count": 10}, {"metadata": {"_uuid": "25da0c1bd4b44be6ec507224e3ca5dd528c2c0e3", "collapsed": false, "_cell_guid": "7e0c2f46-7070-4ad1-ac5b-0ae336b58392", "_execution_state": "idle"}, "source": "##OK! Enough of analysis now. Let's try building a ConvNet on this data", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "bb8e0a1edb9d95d63f05c2c775d62462590f313f", "collapsed": false, "trusted": false, "_cell_guid": "b3cec373-0cd9-4a76-becb-4bd93a1bf896", "_execution_state": "idle"}, "source": "# function to load and provide batches of input images\ndef generate_batch(start, size, source):\n    '''\n        TO load the size number of images into kernel memory and return this data sturcture\n        @Params\n        start = the start index for batch generation\n        size = number of images in the batch \n    '''\n    data = np.ndarray([size, 100, 100, 3], dtype=float) # array for the images\n    labels = np.empty([size], dtype=float) # array for the labels\n    \n    max_value = 255 # the max value of any pixel\n    \n    # traverse the train set to load the images:\n    count = 0 # start the counter from 0\n    for i in range(start, min(len(source), start + size)):\n        data[count] = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", \n                         str(source[i, 0]) + \".jpg\")), [100, 100, 3])\n        #data[count] /= max_value # range normalize the pixel values\n        labels[count] = source[i, 1]\n        count += 1 # increment the counter\n    \n    # load the remaining images by rollover from the source\n    for i in range(0, (start + size) - len(source)):\n        data[count] = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", \n                         str(source[i, 0]) + \".jpg\")), [100, 100, 3])\n        #data[count] /= max_value # range normalize the pixel values\n        labels[count] = source[i, 1]\n        count += 1 # increment the counter\n\n    return data, labels", "outputs": [], "cell_type": "code", "execution_count": 11}, {"metadata": {"_uuid": "f9c0961fb6560d6947702d7c63137c8f4305a5e0", "collapsed": false, "trusted": false, "_cell_guid": "d6878498-3603-4771-a3a2-c6cda439736d", "_execution_state": "idle"}, "source": "# test the method defined above\n# current_data, current_labels = generate_batch(1600, 100) # checking the rollover case\n# print(current_data.shape)\n# print(current_data[3:6], current_labels[3:6]) # check the data inside a random few images\n# alright! so the data batches are getting generated quite properly.\n# test successful. So, now don't run this again since kernel memory is limited", "outputs": [], "cell_type": "code", "execution_count": 12}, {"metadata": {"_uuid": "8dfcda019979d3ce576201de8bc367475dcbaa9a", "collapsed": false, "_cell_guid": "787424ff-cdb7-4664-8657-5574ad0955fa", "_execution_state": "idle"}, "source": "#So, I have not yet figured out if range normalizing the pixel values will be helpful or not. For now I am not range normalizing them.", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "822e77cec6d0fbb68e1862f3b1f5287757527bac", "collapsed": false, "_cell_guid": "7b1b3353-fd23-4b98-bbef-07dd1e8eca36", "_execution_state": "idle"}, "source": "Let's create a Keras ConvNet model to test.", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "fba2a9f56d3495d7fdd5abffddaadc7ad1cf7e94", "collapsed": false, "_execution_state": "idle"}, "source": "def ConvBlock(model, layers, filters):\n    for i in range(layers):\n        model.add(ZeroPadding2D((1, 1)))\n        model.add(Convolution2D(filters, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "af04a1bed451830821fc4267557df45f1cf18ad5", "collapsed": false, "_execution_state": "idle"}, "source": "def FCBlock(model):\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    \ndef input_shape_definer(x):\n    # just an identity function to specify the input shape of the model\n    return x", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "fd73fb2fa7535dde535569450c883e0a80c1fdb3", "collapsed": false, "_execution_state": "idle"}, "source": "# model for solving the problem.\n\nfrom keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.layers.core import Lambda\n\nimg_rows, img_cols, img_channel = 100, 100, 3\n\nmodel = Sequential()\nmodel.add(Lambda(input_shape_definer, input_shape=(100, 100, 3), output_shape=(100, 100, 3)))\n\n# model for computation:\nConvBlock(model, 2, 64)\nConvBlock(model, 2, 128)\nConvBlock(model, 3, 256)\nConvBlock(model, 3, 512)\nConvBlock(model, 3, 512)\n\nmodel.add(Flatten())\nFCBlock(model)\nFCBlock(model)\nmodel.add(Dense(1, activation='sigmoid'))", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "fa6bd0b6a5666d40131db5ebf4cd4b41ec86b6f9", "collapsed": false, "trusted": false, "_cell_guid": "cd7dbcb6-7645-4ee0-82ac-2604e1b5caa2", "_execution_state": "idle"}, "source": "# a detailed description of the model to be used\nprint(model.summary())", "outputs": [], "cell_type": "code", "execution_count": 33}, {"metadata": {"_uuid": "9aef8742a89d30f8ee55523266e2b308cc13351e", "collapsed": false, "_cell_guid": "50ef87c5-b70e-4647-9890-fa504e8748ea", "_execution_state": "idle"}, "source": "#lets start training the model:", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "d89e1f02c8b063bf6d5b376b088066dff441817b", "collapsed": false, "_execution_state": "idle"}, "source": "from keras.utils.data_utils import get_file\n\n# load the pretrained VGGNet weights from the url mentioned:\nmodel.load_weights(get_file('vgg16.h5', 'http://www.platform.ai/models/vgg16.h5', cache_subdir='models'))", "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "52add5369b669a151f417921dd3d1232fde1d888", "collapsed": false, "trusted": false, "_cell_guid": "1a6e0e5c-cac1-4157-8beb-ac7818166469", "_execution_state": "idle"}, "source": "model.compile(optimizer='Adam',\n                loss='categorical_crossentropy', metrics=['accuracy'])\n\n# train the model so that it sees every element in the dataset once:\nbatch_size = 200\ntotal_dataset_size = len(train_set)\n\nsaved_path = \"./Model2\"\n\nif(os.path.isfile(saved_path)):\n    model.load_weights(saved_path)\n\n# let's go over the first 1000 images in the dataset\ncount = 0  #start the count to 0\nfor i in range(0, 15):\n    print(\"count: \" + str(i))\n    x_train, y_train = generate_batch(count, batch_size, train_set)\n    model.fit(x_train, y_train, epochs=2, batch_size=100); # suppress the print output.\n    count = (count + batch_size) % total_dataset_size\n    \n# save the weights to the filesystem\nmodel.save_weights(saved_path)", "outputs": [], "cell_type": "code", "execution_count": 40}, {"metadata": {"_uuid": "1335b954d161042cba4419e2189d4752c740a10e", "collapsed": false, "trusted": false, "_cell_guid": "c7a164c2-f32d-4d3e-ba75-de3d23e51504", "_execution_state": "idle"}, "source": "# extract the cross_validation images from the dataset\nx_eval, y_eval = generate_batch(0, 100, cv_set)\n\nevaluation = model.evaluate(x_eval, y_eval)\nacc = evaluation[1]\nprint('Evaluation accuracy:{0}'.format(round(acc, 4)))\nprint(evaluation)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "386585c3ca5d0057882f25d9883296b540f856d2", "collapsed": false, "trusted": false, "_cell_guid": "5d6eb6b4-9032-4718-8fe6-4667ba67081f", "_execution_state": "idle"}, "source": "layer_dict = dict([(layer.name, layer) for layer in model.layers])\nprint(layer_dict)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "5efa230fe48cedd88227e7029396c38809a0b787", "collapsed": false, "trusted": false, "_cell_guid": "1d15e372-caac-4efd-b9fe-0f8640bf4ab0", "_execution_state": "idle"}, "source": "from keras import backend as K\n\ndef iterate_function_generator(layer_name, filter_index):\n    input_img  = model.input\n\n    # build a loss function that maximizes the activation\n    # of the nth filter of the layer considered\n    layer_output = layer_dict[layer_name].output\n    loss = K.mean(layer_output[:, :, :, filter_index])\n\n    # compute the gradient of the input picture wrt this loss\n    grads = K.gradients(loss, input_img)[0]\n\n\n    # normalization trick: we normalize the gradient\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n    # this function returns the loss and grads given the input picture\n    iterate = K.function([input_img], [loss, grads])\n    return iterate", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "d5dfae675993fdb22fc8660521df9244f0fdd9e7", "collapsed": false, "trusted": false, "_cell_guid": "4b67dda6-7232-4e93-8c55-eda001617d37", "_execution_state": "idle"}, "source": "import numpy as np\n\ndef generate_visualizations(layer_name):\n    # find out how many filters are present:\n    #size = layer_dict[layer_name].output.shape[3]\n    \n    size = 5 # for now we only look at the first 5 filters in that layer\n    \n    # create a list of empty images\n    vizs = np.ndarray([size, 1, 100, 100, 3])\n    # create the visualization arrays\n    for i in range(size):\n        # we start from a gray image with some noise\n        vizs[i] = np.random.random((100, 100, 3)) * 20 + 128.\n       \n    print(vizs.shape)\n        \n    # set the step size for the gradient ascent\n    step = 1\n\n    for filter_index in range(size):\n        for i in range(20):\n            loss_value, grads_value = iterate_function_generator(layer_name, filter_index)([vizs[filter_index]])\n            vizs[filter_index] += grads_value * step\n        print(\"current filter: \" + str(filter_index + 1))            \n\n    return vizs", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "b1b00d0b70a24eec2fcf8f2354399f83f20f15a5", "collapsed": false, "trusted": false, "_cell_guid": "229b9bb9-a1a1-4841-89f8-9884d02e2262", "_execution_state": "idle"}, "source": "# generate the visualizations for the layer number 1 (conv 2d)\nlayer1_conv_vis = generate_visualizations(model.layers[1].name)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "16f387ff2f70c46b794219fdb34a82df76dd39b1", "collapsed": false, "trusted": false, "_cell_guid": "5ea7b155-5882-4b1e-b0dd-e1a3721db169", "_execution_state": "idle"}, "source": "print(layer1_conv_vis[3, 0, :5, :5, 0])", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "072af017cbe93408a5b00017031161b0e8a842bc", "collapsed": false, "trusted": false, "_cell_guid": "c002575a-899a-43ca-b45f-4cba8be21518", "_execution_state": "idle"}, "source": "fig, axs = plt.subplots(ncols= 2, nrows = 2)\nfig.set_size_inches(30, 30)\nfor i in range(2):\n    for j in range(2):\n        axs[i, j].imshow(layer1_conv_vis[(i * 2) + j][0]);", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "92ad51c1d24b8f51fad271332bc678f63782bdbb", "collapsed": false, "_cell_guid": "2eb76aa1-6137-4f97-8c43-7d7c490db73e", "_execution_state": "idle"}, "source": "I require help on how to train the small model that I have constructed here and exactly what might be the problem that is causing this underfitting of the model. Would training for more time help? Suggestions are most welcome.", "outputs": [], "cell_type": "markdown", "execution_count": null}]}