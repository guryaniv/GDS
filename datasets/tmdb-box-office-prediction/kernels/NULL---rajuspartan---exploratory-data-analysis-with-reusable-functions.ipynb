{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.offline as pyo\nimport plotly.graph_objs as go\nimport numpy as np\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\npyo.init_notebook_mode()\nimport warnings\nfrom numpy import percentile\nwarnings.filterwarnings(\"ignore\")\n#train=pd.read_csv('C://Users//nagaraju//Documents//kaggle//Boxoffice//tmdb-box-office-prediction//train.csv')\ntrain=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\nsubfile1=pd.read_csv('../input/sample_submission.csv')\nsubfile2=pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f39e06b960a2c32bd960938353a52005d040e52f"},"cell_type":"code","source":"##### Flatening Json columns\ndef get_dictionary(s):\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\ntrain.belongs_to_collection = train.belongs_to_collection.map(lambda x: len(get_dictionary(x))).clip(0,1)\ntrain.genres = train.genres.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntrain.production_companies = train.production_companies.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntrain.production_countries = train.production_countries.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntrain.spoken_languages = train.spoken_languages.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ntrain.Keywords = train.Keywords.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0db8f66856541d8b1b288a8d3b8d9f6d9f942898"},"cell_type":"code","source":"#Deleting few columns for time being to improve ease of analysis\ntrain.drop(['id','belongs_to_collection','homepage','poster_path','status','cast','crew'],axis=1,inplace=True)\n####Number of genres each movie has\ntrain['numofgenres']=train['genres'].map(lambda x: len(x.split(\",\")))\n####Number of langauges spoken\ntrain['numofspokenlanguages']=train['spoken_languages'].map(lambda x: len(x.split(\",\")))\n####Number of production countries for that movie\ntrain['numofproductioncountries']=train['production_countries'].map(lambda x:len(x.split(\",\")))\n#####Number of production companies for that movie\ntrain['numofproductioncompanies']=train['production_companies'].map(lambda x:len(x.split(\",\")))\n#####Indicates whether a movie to \"Comedy \" genre or not\ntrain['Comedy'] = np.where( train['genres'].str.contains('Comedy') , 1,0)\n#####Indicates whether a movie to \"Action \" genre or not\ntrain['Action'] = np.where( train['genres'].str.contains('Action') , 1,0)\ntrain['Horror'] = np.where( train['genres'].str.contains('Horror') , 1,0)\ntrain['Thriller'] = np.where( train['genres'].str.contains('Thriller') , 1,0)\ntrain['Animation'] = np.where( train['genres'].str.contains('Animation') , 1,0)\n\n#####Indicates whether a movie produced in \"US \" country or not\ntrain['Unitedstates'] = np.where( train['production_countries'].str.contains('United States') , 1,0)\ntrain['UK'] = np.where( train['production_countries'].str.contains('United Kingdom') , 1,0)\ntrain['Russia'] = np.where( train['production_countries'].str.contains('Russia') , 1,0)\ntrain['Japan'] = np.where( train['production_countries'].str.contains('Japan') , 1,0)\ntrain['India'] = np.where( train['production_countries'].str.contains('India') , 1,0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b23100b99bc63e50dedd571526977b2875b028c"},"cell_type":"code","source":"###Imputing budget variable. Few columns have ZERO budget value which is not possible\ntrain['budget']= train['budget'].replace(0,train['budget'].mean())\n###Release date \ndef date_features(df):\n    df['release_date'] = pd.to_datetime(df['release_date'])\n    df['release_year'] = df['release_date'].dt.year\n    df['release_month'] = df['release_date'].dt.month\n    df['release_quarter'] = df['release_date'].dt.quarter\n    df['release_dow'] = df['release_date'].dt.dayofweek\n    df.drop(columns=['release_date'], inplace=True)\n    return df\n\ntrain = date_features(train)\ntrain['release_year']=np.where(train['release_year'] > 2017, train['release_year'] - 100 , train['release_year'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38cc3576ad6c114173f691c6cd9dc3c00c5ce944"},"cell_type":"code","source":"def scatterplot(data,cont1,cont2):\n    data = [go.Scatter(\n        x = data[cont1],\n        y = data[cont2],\n        mode = 'markers',\n        marker = dict(      # change the marker style\n            size = 10,\n            color = 'rgb(51,204,153)',\n            symbol = 'pentagon',\n            line = dict(\n                width = 2,\n            )\n        )\n        )]\n    layout = go.Layout(\n        title = 'Scatterplot ' + '' + cont1 + '     vs    ' + cont2, # Graph title\n        xaxis = dict(title = cont1), # x-axis label\n        yaxis = dict(title = cont2), # y-axis label\n        hovermode ='closest' # handles multiple points landing on the same vertical\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\n\nscatterplot(train,'budget','revenue')\nscatterplot(train,'popularity','revenue')\nscatterplot(train,'runtime','revenue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f7f1e01d4de978a1ee2859c614f66cde857dd54"},"cell_type":"code","source":"def Linecharts(data,cont1,cont2,cat1):\n    data=data.groupby(cat1).mean().reset_index()\n    trace0 = go.Scatter(\n        x = data[cat1],\n        y = data[cont1],\n        mode = 'lines',\n        name = cont1\n    )\n    trace1=go.Scatter(\n        x=data[cat1],\n        y=data[cont2],\n        mode='lines',\n        name=cont2\n    )\n    data = [trace0,trace1]  # assign traces to data\n    layout = go.Layout(\n        title = 'Line charts',\n        xaxis = dict(title = cat1), # x-axis label\n        yaxis = dict(title = cont2),\n        hovermode='closest'# y-axis label\n    )\n    fig = go.Figure(data=data,layout=layout)\n    pyo.iplot(fig)\n\nLinecharts(train,'budget','revenue','release_year')\nLinecharts(train,'budget','revenue','release_month')\nLinecharts(train,'budget','revenue','release_dow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71fc8f49728a47a77a74a0f892cfa2d5f2152d2a"},"cell_type":"code","source":"def Barcharts(data,cat1,cont1):\n    data=data.groupby(cat1).mean().reset_index()\n    trace1 = go.Bar(\n    x=data[cat1],  \n    y=data[cont1],\n    name = cont1,\n    marker=dict(color='#FFD700') \n    )\n    data = [trace1]\n    layout = go.Layout(\n        title='Bar charts',\n        xaxis = dict(title = cat1), # x-axis label\n        yaxis = dict(title = cont1), # y-axis label\n        barmode='stack'\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\n\nBarcharts(train,'numofgenres','revenue')\nBarcharts(train,'numofspokenlanguages','revenue')\nBarcharts(train,'numofgenres','popularity')\nBarcharts(train,'original_language','revenue')\nBarcharts(train,'numofproductioncountries','revenue')\nBarcharts(train,'numofproductioncompanies','revenue')\n\n#Barcharts(train,'Comedy','revenue')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08320a9beb9422b3f70855ae752123170fd3512d"},"cell_type":"markdown","source":"Movies with number of genres : 4 registered maximum average revenue\nMovies with number of genres : 3 have maximum popularity\nMovies release in countries where number of spoken laguages : 5 registered max average revenue"},{"metadata":{"trusted":true,"_uuid":"16ae734ff89f31e6a34b86cf22d9abb3cd8448eb"},"cell_type":"code","source":"def Barcharts(data,cat1,cat2,cat3,cat4,cat5,cont1):\n    data1=data.groupby(cat1).mean().reset_index()\n    trace1 = go.Bar(\n    x=data1[cat1],  \n    y=data1[cont1],\n    name = cat1,\n    marker=dict(color='rgb(49,54,149)') \n    )\n    data2=data.groupby(cat2).mean().reset_index()\n    trace2=go.Bar(\n    x=data2[cat2],\n    y=data2[cont1],\n    name=cat2,\n    marker=dict(color='rgb(254,224,144)')\n    )\n    data3=data.groupby(cat3).mean().reset_index()\n    trace3=go.Bar(\n    x=data3[cat3],\n    y=data3[cont1],\n    name=cat3,\n    marker=dict(color='rgb(171,217,233)')\n    )\n    data4=data.groupby(cat4).mean().reset_index()\n    trace4=go.Bar(\n    x=data4[cat4],\n    y=data4[cont1],\n    name=cat4,\n    marker=dict(color='rgb(215,48,39)')\n    )\n    data5=data.groupby(cat5).mean().reset_index()\n    trace5=go.Bar(\n    x=data5[cat5],\n    y=data5[cont1],\n    name=cat5,\n    marker=dict(color='#CD7F32')\n    )\n    data = [trace1,trace2,trace3,trace4,trace5]\n    layout = go.Layout(\n        title='Bar charts',\n        xaxis = dict(title = \"Noncomedy vs Comedy, NonAction Vs Action, NonHorror vs Horror, Nonthriller vs Thriller, NonAnimation vs Animation\"), # x-axis label\n        yaxis = dict(title = cont1)\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\nBarcharts(train,'Comedy','Action','Horror','Thriller','Animation','revenue')\nBarcharts(train,'Comedy','Action','Horror','Thriller','Animation','popularity')\nBarcharts(train,'Unitedstates','UK','Russia','Japan','India','popularity')\nBarcharts(train,'Unitedstates','UK','Russia','Japan','India','revenue')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99480b18e24cef125d96972a2db50d54a1ca2525"},"cell_type":"markdown","source":"Animation movies have average revenue of 147.74M vs Non-Animated movies with average revenue 62.73M\nAction movies have average popularity of 10.68 vs Non-action movies with average 7.73\nPopularity of movies in UK has 10.39 vs Popularity in Russia with least avg 2.54\nUnited states has max average revenue 81.96M vs Russia with least avg revenue 12.68M\n\n"},{"metadata":{"trusted":true,"_uuid":"05866a45458a48be4017b8c8917d827f663101fa"},"cell_type":"code","source":"def Bar_Stack_charts(data,cat1,cont1,cont3):\n    data=data.groupby(cat1).mean().reset_index()\n    trace1 = go.Bar(\n    x=data[cat1],  # NOC stands for National Olympic Committee\n    y=data[cont1],\n    name = cont1,\n    marker=dict(color='#FFD700') # set the marker color to gold\n    )\n    \n    trace3 = go.Bar(\n    x=data[cat1],  # NOC stands for National Olympic Committee\n    y=data[cont3],\n    name = cont3,\n    marker=dict(color='#CD7F32') # set the marker color to gold\n    )\n    data = [trace1,trace3]\n    layout = go.Layout(\n        title='Bar charts',\n        xaxis = dict(title = cat1), # x-axis label\n        yaxis = dict(title = cont1 + '  ' +'  ' + cont3), # y-axis label\n        barmode='stack'\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\n\nBar_Stack_charts(train,'numofgenres','budget','revenue')\nBar_Stack_charts(train,'numofspokenlanguages','budget','revenue')\nBar_Stack_charts(train,'numofproductioncompanies','budget','revenue')\nBar_Stack_charts(train,'numofproductioncountries','budget','revenue')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccdaa2e884ab8049fb1382640ec80677919801e0"},"cell_type":"code","source":"def Bubblecharts(data,cont1,cont2,cont3,cat1,cat2):\n    data = [go.Scatter(\n            x=data[cont1],\n            y=data[cont2],\n            text=data[cat1],  # use the new column for the hover text\n            mode='markers',\n            marker=dict(size=0.4*data[cont3],color=data[cat2])\n            \n        )]\n    layout = go.Layout(\n        title='Bubble chart' + '  '  + cont1 + ' vs  ' + cont2,\n        xaxis = dict(title = cont1), # x-axis label\n        yaxis = dict(title = cont2), # y-axis label\n        hovermode='closest'\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\n\n\nBubblecharts(train,'budget','revenue','popularity','original_title','Comedy')\nBubblecharts(train,'budget','revenue','popularity','original_title','Animation')\nBubblecharts(train,'budget','revenue','popularity','original_title','Horror')\nBubblecharts(train,'budget','revenue','popularity','original_title','UK')\nBubblecharts(train,'budget','revenue','popularity','original_title','Thriller')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3ff694f6a5ca0e823a2de808abd995c459bb173"},"cell_type":"code","source":"def Boxplots(data,cont1):\n    data = [\n    go.Box(\n        y=data[cont1],\n        name=cont1\n        )\n    #go.Box(\n     #   y=data[cont2],\n      #  name=cont2\n       # )\n    ]\n    layout = go.Layout(\n        title = 'Box plots' + '   ' + cont1 \n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\n\nBoxplots(train,'budget')\nBoxplots(train,'revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6f7a691a7f0a0d947e2686807e266d4ac870b0e"},"cell_type":"code","source":"def Histogram(data,cat1,bins):\n    data = [go.Histogram(\n        x=data[cat1],\n        nbinsx=bins\n    )]\n    layout = go.Layout(\n    title=\"Distribution of values\"\n    )\n    fig = go.Figure(data=data, layout=layout)\n    pyo.iplot(fig)\nHistogram(train,'genres',15)\nHistogram(train,'budget',5)\nHistogram(train,'revenue',5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cda3af1211cfcb68da0d70f1251e568d0fe83e10"},"cell_type":"code","source":"from plotly import tools\ndef Heatmaps(data,cat1,cat2,cont1,cont2):\n    trace1 = go.Heatmap(\n    x=data[cat1],\n    y=data[cat2],\n    z=data[cont1],\n    text=data['original_title'],\n   colorscale='Jet' # add max/min color values to make each plot consistent\n    )\n    trace2 = go.Heatmap(\n    x=data[cat1],\n    y=data[cat2],\n    z=data[cont2],\n    text=data['original_title'],\n    colorscale='Jet' # add max/min color values to make each plot consistent\n    )\n    #trace3 = go.Heatmap(\n    #x=data[cat1],\n    #y=data[cat2],\n    #z=data[cont3],\n    #colorscale='Jet' # add max/min color values to make each plot consistent\n    #)\n    fig = tools.make_subplots(rows=1, cols=2,\n    subplot_titles=('Plot1','Plot2'),\n    shared_yaxes = True,  # this makes the hours appear only on the left\n    )\n    fig.append_trace(trace1, 1, 1)\n    fig.append_trace(trace2, 1, 2)\n    #fig.append_trace(trace3, 1, 3)\n    fig['layout'].update(      # access the layout directly!\n    title='Distribution of values'\n    )\n    pyo.iplot(fig)\n \n\n#Heatmaps(train,'genres','spoken_languages','revenue')\nHeatmaps(train,'release_year','original_language','revenue','budget')\nHeatmaps(train,'release_year','release_month','revenue','budget')\n#Heatmaps(train,'release_year','Comedy','revenue','budget')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca28ce1c61a6c5bb3bde9e7d043229826a19f2b7"},"cell_type":"markdown","source":"THANKS!! for your valuable time .. Will upload further EDA and regression model in upcoming kernels. Comments and suggestions are welcomed. Upvote if you find this helpful. :)"},{"metadata":{"trusted":true,"_uuid":"b9adba9d14b435bac450a9d47c49d9cbf80391f5"},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\nsubfile1=pd.read_csv('../input/sample_submission.csv')\nsubfile2=pd.read_csv('../input/sample_submission.csv')\ndef dataprep(data):\n    def get_dictionary(s):\n        try:\n            d = eval(s)\n        except:\n            d = {}\n        return d\n    #data.belongs_to_collection = data.belongs_to_collection.map(lambda x: len(get_dictionary(x))).clip(0,1)\n    data.genres = data.genres.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.production_companies = data.production_companies.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.production_countries = data.production_countries.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.spoken_languages = data.spoken_languages.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.Keywords = data.Keywords.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.cast = data.cast.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    data.crew = data.crew.map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\n    ####Number of genres each movie has\n    data['numofgenres']=data['genres'].map(lambda x: len(x.split(\",\")))\n    ####Number of langauges spoken\n    data['numofspokenlanguages']=data['spoken_languages'].map(lambda x: len(x.split(\",\")))\n    ####Number of production countries for that movie\n    data['numofproductioncountries']=data['production_countries'].map(lambda x:len(x.split(\",\")))\n    #####Number of production companies for that movie\n    data['numofproductioncompanies']=data['production_companies'].map(lambda x:len(x.split(\",\")))\n    data['numofproductioncompanies']=data['production_companies'].map(lambda x:len(x.split(\",\")))\n    data['numofkeywords']=data['Keywords'].map(lambda x:len(x.split(\",\")))\n    data['numofcast']=data['cast'].map(lambda x:len(x.split(\",\")))\n    data['numofcrew']=data['crew'].map(lambda x:len(x.split(\",\")))\n    def date_features(df):\n        df['release_date'] = pd.to_datetime(df['release_date'])\n        df['release_year'] = df['release_date'].dt.year\n        df['release_month'] = df['release_date'].dt.month\n        df['release_quarter'] = df['release_date'].dt.quarter\n        df['release_dow'] = df['release_date'].dt.dayofweek\n        df.drop(columns=['release_date'], inplace=True)\n        return df\n\n    data = date_features(data)\n    data['release_year']=np.where(data['release_year'] > 2017, data['release_year'] - 100 , data['release_year'])\n    data['budget']= data['budget'].replace(0,data['budget'].mean())\n    k=pd.cut(np.array(data['release_year']),10,retbins=True)\n    def yearsegment(m):\n        for i in range(len(k[1])):\n            if(i!=10):\n                if (m > k[1][i] and m < k[1][i + 1] ):\n                    return (i + 1)\n            else:\n                return (i + 1)\n    data['year_group']=data['release_year'].apply(lambda x: yearsegment(x))\n       \n    data['budget']=np.log(data['budget'])\n    data['original_language'] = np.where( data['original_language']=='en', 1,0)\n    data[\"overview\"]=data[\"overview\"].replace(np.nan,\"empty string\")\n    data['Comedy'] = np.where( data['genres'].str.contains('Comedy') , 1,0)\n    data['Action'] = np.where( data['genres'].str.contains('Action') , 1,0)\n    data['Horror'] = np.where( data['genres'].str.contains('Horror') , 1,0)\n    data['Thriller'] = np.where( data['genres'].str.contains('Thriller') , 1,0)\n    data['Animation'] = np.where( data['genres'].str.contains('Animation') , 1,0)\n    data['Science Fiction'] = np.where( data['genres'].str.contains('Science Fiction') , 1,0)\n    data['Drama'] =  np.where( data['genres'].str.contains('Drama') , 1,0)\n    data['Crime'] =  np.where( data['genres'].str.contains('Crime') , 1,0)\n    data['Family'] =  np.where( data['genres'].str.contains('Family') , 1,0)\n    data['Adventure'] =  np.where( data['genres'].str.contains('Adventure') , 1,0)\n    data['Romance'] =  np.where( data['genres'].str.contains('Romance') , 1,0)\n    data['Istagline']= np.where( data['tagline'].isnull() , 1,0)\n    data['US']=np.where( data['production_countries'].str.contains('United States of America') , 1,0)\n    data['Waltdisney']=np.where(data['production_companies'].str.contains('Walt Disney Pictures') , 1,0)\n    data['Warnerbros']=np.where(data['production_companies'].str.contains('Warner Bros.'),1,0)\n    data.drop(['id','title','imdb_id','belongs_to_collection','spoken_languages',\n               'production_countries','production_companies','cast','crew','homepage',\n               'poster_path','status','title','tagline','Keywords',\n               'original_title','release_year'],axis=1,inplace=True)\n    data=pd.get_dummies(data,columns=['release_month'])\n    del data['release_month_12']\n    data=pd.get_dummies(data,columns=['release_quarter'])\n    del data['release_quarter_4']\n    data=pd.get_dummies(data,columns=['release_dow'])\n    del data['release_dow_6']\n    data=pd.get_dummies(data,columns=['year_group'])\n    del data['year_group_11']\n    #data['runtimeseg']=[lambda x:1 if x<100 else 0 for x in data['runtime']]\n    \n    \ndataprep(train)\ndataprep(test)\n\ntrain['runtimeseg']=[1 if x<100 else 0 for x in train['runtime']]\ndel train['runtime']\ntest['runtimeseg']=[1 if x<100 else 0 for x in test['runtime']]\ndel test['runtime']\n\n    \n#dataset=pd.concat([train[['genres','overview']].reset_index(drop=True),test[['genres','overview']]],axis=0)\n##dataset[\"genres\"]=dataset[\"genres\"].replace(np.nan,\"empty string\")\n##corpus = dataset['genres']\n##vectorizer = TfidfVectorizer(max_features=20,analyzer='word',stop_words=set(stopwords.words('english')))\n##x = vectorizer.fit_transform(corpus)\n##DS=pd.SparseDataFrame(x.todense().tolist(),columns=vectorizer.get_feature_names())\n##DS.reset_index(drop=True, inplace=True)\n##dataset.reset_index(drop=True, inplace=True)\n##dataset = pd.concat([DS, dataset], axis=1)\n###dataset=pd.concat([DS.reset_index(drop=True),dataset],axis=1)\n##\n##dataset.drop(['10749', '12', '18', '27', '28', '35', '53', '80', '878'],axis=1,inplace=True)\n#del dataset['genres']\n#    \n#dataset[\"overview\"]=dataset[\"overview\"].replace(np.nan,\"empty string\")\n#my_stop_words = text.ENGLISH_STOP_WORDS.union([\"book\"])\n#vectorizer=TfidfVectorizer(max_features=50,analyzer='word',stop_words=my_stop_words)\n#response=vectorizer.fit_transform(dataset['overview'])\n#DS1=pd.SparseDataFrame(response.todense().tolist(),columns=vectorizer.get_feature_names())\n#DS1.reset_index(drop=True, inplace=True)\n#dataset.reset_index(drop=True, inplace=True)\n#dataset = pd.concat([DS1, dataset], axis=1)\n##dataset=pd.concat([DS1.reset_index(drop=True),dataset],axis=1)\n#del dataset['overview']\n#\n#train1=dataset.head(3000)\n#test1=dataset.iloc[3000:]\n#test1.reset_index(drop=True, inplace=True)\n#train=pd.concat([train, train1], axis=1)\n#test=pd.concat([test,test1],axis=1)\n\n#del train['id']\n#del test['id']\ndel train['genres']\ndel train['overview']\ndel test['genres']\ndel test['overview']\n\ntrain['revenue']=np.log(train['revenue'])\ny = train['revenue'].values\ndf1=train\ndel df1['revenue']\nX = df1.values\n\nimport lightgbm as lgb\nfrom sklearn.cross_validation import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n\n\n\nmodel = XGBRegressor()\neval_set = [(X_train, y_train), (X_test, y_test)]\nmodel.fit(X_train, y_train, eval_metric=\"rmse\", eval_set=eval_set, verbose=True)\n\nresults = model.evals_result()\nprint(results)\nresults['validation_0']['rmse']\ny_pred = model.predict(X_test)\npredictions = [round(value) for value in y_pred]\n\nfeature_importance = pd.DataFrame(model.feature_importances_, columns = ['importance'])\nfeature_importance['feature'] = train.columns\nfeature_importance.sort_values(by='importance', inplace = True, ascending = False)\nfeature_importance.reset_index(drop = True, inplace = True)\nfeature_importance\n\nx_validation = test.values\ny_test_p_xgb = pd.Series(model.predict(x_validation))\ny_test_p_xgb=np.exp(y_test_p_xgb)\ny_test_p_xgb=pd.DataFrame(y_test_p_xgb)\ny_test_p_xgb.columns=['revenue']\nsubfile1['revenue']=y_test_p_xgb['revenue']\nxgbsubile=subfile1\n\nxgbsubile.to_csv('sub15.csv')\n\nparams_lgb = {'drop_rate': [0.0977], 'feature_fraction': [0.60],\n              'lambda_l1': [0.0391], 'lambda_l2': [26.68],\n              'learning_rate': [0.0132],\n              'max_drop': [67.0], 'min_data_in_leaf': [1.0],\n              'num_leaves': [32.0], 'num_trees': [700.0]}\n\nparams_lgb = {k:v[0] for k,v in params_lgb.items()}\n\nlg = lgb.LGBMRegressor(\n                        objective = 'regression',\n                        metric = 'rmse',\n                        early_stopping_round = 50,\n                        drop_rate = params_lgb['drop_rate'],\n                        feature_fraction = params_lgb['feature_fraction'],\n                        lambda_l1 = params_lgb['lambda_l1'],\n                        lambda_l2 = params_lgb['lambda_l2'],\n                        learning_rate = params_lgb['learning_rate'],\n                        max_drop = int(params_lgb['max_drop']),\n                        min_data_in_leaf = int(params_lgb['min_data_in_leaf']),\n                        num_leaves = int(params_lgb['num_leaves']),\n                        num_trees = int(params_lgb['num_trees']))\n\n\nlg.fit(X_train, y_train, eval_set=[(X_train, y_train)])\n\nfeature_importance = pd.DataFrame(lg.feature_importances_, columns = ['importance'])\nfeature_importance['feature'] = train.columns\nfeature_importance.sort_values(by='importance', inplace = True, ascending = False)\nfeature_importance.reset_index(drop = True, inplace = True)\nfeature_importance\n\nx_validation = test.values\ny_test_p = pd.Series(lg.predict(x_validation))\ny_test_p=np.exp(y_test_p)\ny_test_p=pd.DataFrame(y_test_p)\ny_test_p.columns=['revenue']\nsubfile2['revenue']=y_test_p['revenue']\nlgbsubfile=subfile2\n\n\nlgbsubfile.to_csv('sub14-lg.csv')\n\n\ndf=pd.merge(xgbsubile,lgbsubfile,how='inner',on='id')\ndf['revenue']=((df['revenue_x'] +  df['revenue_y']) / 2 )\ndel df['revenue_x'], df['revenue_y']\ndf.to_csv('submissionfile.csv')\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}