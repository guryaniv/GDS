{"cells":[{"metadata":{"trusted":true,"_uuid":"b007775591aa16b40bc53883cc2721cbb4b704d3"},"cell_type":"code","source":"\"\"\"\nRequired Libraries for PyTorch Nueral network\nSets Torch Seed \nSets Numpy Random Seed\nAnd Random Seed for reproducibility\n\"\"\"\nimport torch\n#--- Seeding and Setting Deterministic GPU behavior ---#\ntorch.manual_seed(60794)\ntorch.backends.cudnn.deterministic = True\n#--- Seeding for Numpy and Random Seeding ---#\nimport numpy as np\nnp.random.seed(60794)\nimport random\nrandom.seed(60794)\n#--- nueral network ---#\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import data\n#--- Additional Libraries ---#\nimport os\nimport glob\nimport warnings\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport torchvision\nfrom pathlib import Path\nfrom tqdm import tqdm, tqdm_notebook\nfrom torchvision import models\nfrom sklearn.metrics import jaccard_similarity_score\nfrom torch.autograd import Variable\nimport _pickle\n#----- Library Code END -----#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e26b59c8aecb1667060e8aab5eee8492510197f4"},"cell_type":"code","source":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels, y_pred = y_true_in, y_pred_in\n    true_objects, pred_objects = 2, 2\n    # Jiaxin fin that if all zeros, then, the background is treated as object\n    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n    intersection = temp1[0]\n    \n    # Compute areas (needed for finding the union between all objects)\n    #print(np.histogram(labels, bins = true_objects))\n    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n    #print(\"area_true = \",area_true)\n    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n    \n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    intersection[intersection == 0] = 1e-9\n    \n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    y_pred_in = y_pred_in > 0.5 # added by sgx 20180728\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b533297d0201f3963d230a072eaf35887445285"},"cell_type":"code","source":"import math\nimport operator\nimport copy\n\n\ndef set_learning_rate(optimizer, lr):\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n\n\ndef get_learning_rate(optimizer):\n    return optimizer.param_groups[0]['lr']\n\n\n\nclass LearningRate():\n    def __init__(self, initial_lr, iteration_type):\n        self.initial_lr = initial_lr\n        self.iteration_type = iteration_type #epoch or mini_batch\n\n    def get_learning_rate(self, optimizer):\n        return optimizer.param_groups[0]['lr']\n\n    def set_learning_rate(self, optimizer, new_lr):\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = new_lr\n\n    def adjust(self, optimizer, lr, iteration, params=None):\n        self.set_learning_rate(optimizer, lr)\n        return lr\n\n\nclass FixedLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type):\n        super().__init__(initial_lr, iteration_type)\n\n    def adjust(self, optimizer, iteration, params=None):\n        new_lr = super().get_learning_rate(optimizer)\n        return new_lr\n\n\nclass LinearLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, fixed_delta):\n        super().__init__(initial_lr, iteration_type)\n        self.fixed_delta = fixed_delta\n\n    def adjust(self, optimizer, iteration, params=None):\n        lr = super().get_learning_rate(optimizer)\n        new_lr = lr + self.fixed_delta\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass SnapshotLR(LearningRate):\n    '''https://arxiv.org/abs/1704.00109'''\n    def __init__(self, initial_lr, iteration_type,\n                 max_lr, total_iters, n_cycles):\n        '''\n        n_iters = total number of mini-batch iterations during training\n        n_cycles = total num snapshots during training\n        max_lr = starting learning rate each cycle'''\n        super().__init__(initial_lr, iteration_type)\n        self.max_lr = max_lr\n        self.total_iters = total_iters\n        self.cycles = n_cycles\n\n    def cosine_annealing(self, t):\n        '''t = current mini-batch iteration'''\n        return self.max_lr/2 * (math.cos(\n         (math.pi * (t % (self.total_iters//self.cycles))) /\n         (self.total_iters//self.cycles)) + 1)\n\n    def adjust(self, optimizer, iteration, params=None):\n        new_lr = self.cosine_annealing(iteration)\n        self.set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass SnapshotParamsLR(LearningRate):\n    '''Snapshot Learning with per-parameter LRs'''\n    def __init__(self, initial_lr, iteration_type,\n                 total_iters, n_cycles):\n        '''\n        n_iters = total number of mini-batch iterations during training\n        n_cycles = total num snapshots during training\n        max_lr = starting learning rate each cycle'''\n        super().__init__(initial_lr, iteration_type)\n        self.total_iters = total_iters\n        self.cycles = n_cycles\n\n    def cosine_annealing(self, t, max_lr):\n        return max_lr/2 * (math.cos(\n         (math.pi * (t % (self.total_iters//self.cycles)))/(\n            self.total_iters//self.cycles)) + 1)\n\n    def adjust(self, optimizer, iteration, params=None):\n        lrs = []\n        for param_group in optimizer.param_groups:\n            new_lr = self.cosine_annealing(iteration, param_group['max_lr'])\n            param_group['lr'] = new_lr\n            lrs.append(new_lr)\n        return new_lr\n\n\nclass DevDecayLR(LearningRate):\n    '''https://arxiv.org/abs/1705.08292'''\n    def __init__(self, initial_lr, iteration_type,\n                 decay_factor=0.9, decay_patience=1):\n        super().__init__(initial_lr, iteration_type)\n        self.decay_factor = decay_factor\n        self.decay_patience = decay_patience\n\n    def adjust(self, optimizer, iteration, params):\n        lr = super().get_learning_rate(optimizer)\n        best_iter = params['best_iter']\n\n        if (iteration - best_iter) > self.decay_patience:\n            print('Decaying learning rate by factor: {:.5f}'.format(\n                self.decay_factor).rstrip('0'))\n            lr *= self.decay_factor\n            super().set_learning_rate(optimizer, lr)\n        return lr\n\n\nclass ScheduledLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, lr_schedule):\n        super().__init__(initial_lr, iteration_type)\n        self.lr_schedule = lr_schedule\n\n    def adjust(self, optimizer, iteration, params=None):\n        if iteration in self.lr_schedule:\n            new_lr = self.lr_schedule[iteration]\n        else:\n            new_lr = self.get_learning_rate(optimizer)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass DecayingLR(LearningRate):\n    def __init__(self, initial_lr, iteration_type, decay, n_epochs):\n         super().__init__(initial_lr, iteration_type)\n         self.decay = decay\n         self.n_epochs = n_epochs\n\n    def exponential_decay(self, iteration, params=None):\n        '''Update learning rate to `initial_lr` decayed\n        by `decay` every `n_epochs`'''\n        return self.initial_lr * (self.decay ** (iteration // self.n_epochs))\n\n    def adjust(self, optimizer, iteration):\n        new_lr = self.exponential_decay(iteration)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\nclass CyclicalLR(LearningRate):\n    '''https://arxiv.org/abs/1506.01186'''\n    def __init__(self, initial_lr, iteration_type, n_iters, cycle_length,\n                 min_lr, max_lr):\n         assert initial_lr == min_lr\n         super(CyclicalLR, self).__init__(initial_lr, iteration_type)\n         self.n_iters = n_iters\n         self.cycle_length = cycle_length\n         self.min_lr = min_lr\n         self.max_lr = max_lr\n\n    def triangular(self, iteration):\n        iteration -= 1 # if iteration count starts at 1\n        cycle = math.floor(1 + iteration/self.cycle_length)\n        x = abs(iteration/(self.cycle_length/2) - 2*cycle + 1)\n        new_lr = self.min_lr + (self.max_lr - self.min_lr) * max(0, (1-x))\n        return new_lr\n\n    def adjust(self, optimizer, iteration, best_iter=1):\n        new_lr = self.triangular(iteration)\n        super().set_learning_rate(optimizer, new_lr)\n        return new_lr\n\n\n\n\n## Helpers\n\ndef cosine_annealing(lr_max, T, M, t):\n    '''\n    t = current mini-batch iteration\n    # lr(t) = f(t-1 % T//M)\n    # lr(t) = lr_max/2 * (math.cos( (math.pi * (t % T/M))/(T/M) ) + 1)\n    '''\n    return lr_max/2 * (math.cos( (math.pi * (t % (T//M)))/(T//M)) + 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\"\"\"\nKeras -> Pytorch considerations\npadding 0 is \"valid\"\npadding 1 is \"same\"\n\"\"\"\ndef conv3by3(in_ch,out_ch,padding):\n\t\"\"\"\n\tConv2d\n\t(3 x 3) kernel size\n\tin_ch input_channels\n\tout_ch output_channels\n\tpadding - 0: equivalent to \"valid\"\n\t          1: equivalent to \"same\" \n\t\"\"\"\n\treturn nn.Conv2d(in_ch,out_ch,3,padding=padding)\n\ndef conv1by1(in_ch,out_ch,padding):\n\t\"\"\"\n\tConv2d\n\t(1 x 1) kernel size\n\tin_ch input_channels\n\tout_ch output_channels\n\tpadding - 0: equivalent to \"valid\"\n\t          1: equivalent to \"same\" \n\t\"\"\"\n\treturn nn.Conv2d(in_ch,out_ch,1,padding=padding)\n\ndef convtrans3by3(in_ch,out_ch,padding):\n\t\"\"\"\n\tConvtrans\n\tStride = 2\n\t(3 x 3) kernel size\n\tin_ch input_channels\n\tout_ch output_channels\n\tpadding - 0: equivalent to \"valid\"\n\t          1: equivalent to \"same\" \n\t\"\"\"\n\treturn nn.ConvTranspose2d(in_ch,out_ch,3,stride=2,padding=padding,output_padding=padding)\n\ndef swish(x):\n\t\"\"\"\n\tSwish Activation function implementation\n\tAdded for improvement on ReLU activation\n\tLink: https://arxiv.org/abs/1710.05941\n\tCite: arXiv:1710.05941v2 [cs.NE]\n\t\"\"\"\n\treturn torch.sigmoid(x) * x\n\nclass GlobalAvgPool(nn.Module):\n\tdef __init__(self):\n\t\tsuper(GlobalAvgPool,self).__init__()\n\tdef forward(self, x):\n\t\treturn x.view(*(x.shape[:-2]),-1).mean(-1)\n\nclass Seq_Ex_Block(nn.Module):\n\t\"\"\"\n\tSqueeze - Excite Block\n\tSource Kaggle Discussion Forum\n\t__insert article link____\n\t\"\"\"\n\tdef __init__(self,in_ch,r=16):\n\t\tsuper(Seq_Ex_Block,self).__init__()\n\t\tself.se = nn.Sequential(\n\t\t\tGlobalAvgPool(),\n\t\t\tnn.Linear(in_ch, in_ch//r),\n\t\t\tnn.ReLU(inplace=True),\n\t\t\tnn.Linear(in_ch//r, in_ch),\n\t\t\tnn.Sigmoid()\n\t\t\t)\n\tdef forward(self,x):\n\t\tse_weight = self.se(x).unsqueeze(-1).unsqueeze(-1)\n\t\treturn x.mul(se_weight)\n\nclass conv_block(nn.Module):\n\t\"\"\"\n\tConvolutional Block\n\tActivation can be changed here\n\tConv2d -> BatchNorm2d (-> Activation)\n\t\"\"\"\n\tdef __init__(self, in_ch, out_ch,activation):\n\t\tsuper().__init__()\n\t\tself.conv = conv3by3(in_ch,out_ch,1)\n\t\tself.batch_norm = nn.BatchNorm2d(out_ch)\n\t\tself.instance_norm = nn.InstanceNorm2d(out_ch)\n\t\t#self.layer_norm = nn.LayerNorm(out_ch)\n\t\tself.activation = activation\n\t\tself.activ = nn.LeakyReLU(0.001,inplace=True)\n# added depth wise convolutions here\n\tdef forward(self,x):\n\t\tif self.activation == True:\n\t\t\tx = self.activ(self.instance_norm(self.batch_norm(self.conv(x))))\n\t\t\t#x = swish(self.layer_norm(self.conv(x)))\n\t\telse:\n\t\t\tx = self.instance_norm(self.batch_norm(self.conv(x)))\n\t\t\t#x = self.layer_norm(self.conv(x))\n\t\treturn x\n\nclass res_block(nn.Module):\n\t\"\"\"\n\tResidual Block\n\tinput\n\tx = input -> conv block w activation -> conv block w/o activation\n\telement wise addition x + input\n\tSqueeze and Excite Block can be added here\n\t\"\"\"\n\tdef __init__(self, in_ch, out_ch):\n\t\tsuper().__init__()\n\t\tself.activation = nn.ReLU(inplace=True)\n\t\tself.batch_norm = nn.BatchNorm2d(in_ch)\n\t\tself.conv_block_activated = conv_block(in_ch,out_ch,True)\n\t\tself.conv_block_no_activ = conv_block(in_ch,out_ch,False)\n\t\tself.squeeze = Seq_Ex_Block(in_ch)\n\n\tdef forward(self,x):\n\t\tblockInput = x\n\t\tx = self.batch_norm(self.activation(x))\n\t\tx = self.conv_block_activated(x)\n\t\tx = self.conv_block_no_activ(x)\n\t\tx = self.squeeze(x)\n\t\tx = torch.add(x,blockInput)\n\t\treturn x\n\n# This model is not modular b/c all values are set\nclass UNet(nn.Module):\n\t\"\"\"\n\tWARNING!!! WARNING!!!WARNING!!! WARNING!!!WARNING!!!\n\t---------------------------------------------------\n\t--- Not entirely modular until calculations are ---\n\t--- not built on a start_nuerons argument. --------\n\t---------------------------------------------------\n\tWARNING!!! WARNING!!!WARNING!!! WARNING!!!WARNING!!!\n\n\tModel Architecture\n\tComposed of Conv and Residual Blocks\n\tWhere we would add CoordinateChannel,\n\tDepthChannel. Tuning on dropout // optimal\n\ton 0.6 through arduous Keras testing\n\t\"\"\"\n\tdef __init__(self,dropout_ratio=0.6):\n\t\tsuper().__init__()\n\t\t# -- Recurring network modules -- #\n\t\tself.relu = nn.ReLU(inplace=True)\n\t\tself.sigmoid = nn.Sigmoid()\n\t\tself.pool = nn.MaxPool2d(2)\n\t\tself.dropoutA = nn.Dropout2d(p = dropout_ratio/4)\n\t\tself.dropoutB = nn.Dropout2d(p = dropout_ratio/2)\n\n\t\t# 101 - 50\n\t\tself.conv1 = conv3by3(3,16,1)\n\t\tself.r_b1 = res_block(16,16)\n\t\tself.r_b2 = res_block(16,16)\n\t\t# 50 - 25\n\t\tself.conv2 = conv3by3(16,32,1)\n\t\tself.r_b3 = res_block(32,32)\n\t\tself.r_b4 = res_block(32,32)\n\t\t# 25 - 12\n\t\tself.conv3 = conv3by3(32,64,1)\n\t\tself.r_b5 = res_block(64,64)\n\t\tself.r_b6 = res_block(64,64)\n\t\t# 12 - 6\n\t\tself.conv4 = conv3by3(64,128,1)\n\t\tself.r_b7 = res_block(128,128)\n\t\tself.r_b8 = res_block(128,128)\n\t\t# Middle\n\t\tself.convm = conv3by3(128,256,1)\n\t\tself.r_bm1 = res_block(256,256)\n\t\tself.r_bm2 = res_block(256,256)\n\t\t# 6 - 12\n\t\tself.deconv4 = convtrans3by3(256,128,1)\n\t\tself.uconv4 = conv3by3(256,128,1)\n\t\tself.r_bu1 = res_block(128,128)\n\t\tself.r_bu2 = res_block(128,128)\n\t\t# 12 - 25\n\t\tself.deconv3 = convtrans3by3(128,64,1)\n\t\tself.uconv3 = conv3by3(128,64,1)\n\t\tself.r_bu3 = res_block(64,64)\n\t\tself.r_bu4 = res_block(64,64)\n\t\t# 25 - 50\n\t\tself.deconv2 = convtrans3by3(64,32,1)\n\t\tself.uconv2 = conv3by3(64,32,1)\n\t\tself.r_bu5 = res_block(32,32)\n\t\tself.r_bu6 = res_block(32,32)\n\t\t# 50 - 101\n\t\tself.deconv1 = convtrans3by3(32,16,1)\n\t\tself.uconv1 = conv3by3(32,16,1)\n\t\tself.r_bu7 = res_block(16,16)\n\t\tself.r_bu8 = res_block(16,16)\n\t\t# Final Part\n\t\tself.final_conv = conv1by1(16,1,0)\n\n\tdef forward(self,x):\n\t\t#print(x.shape)\n\t\t# 101 -> 50\n\t\tconv_1 = swish(self.r_b2(self.r_b1(self.conv1(x))))\n\t\tpool_1 = self.dropoutA(self.pool(conv_1))\n\t\t#print(\"Conv1: \",conv_1.shape)\n\t\t#print(\"Pool1: \",pool_1.shape)\n\t\t# 50 -> 25\n\t\tconv_2 = swish(self.r_b4(self.r_b3(self.conv2(pool_1))))\n\t\tpool_2 = self.dropoutA(self.pool(conv_2))\n\t\t#print(\"Conv2: \",conv_2.shape)\n\t\t#print(\"Pool2: \",pool_2.shape)\n\t\t# 25 -> 12\n\t\tconv_3 = swish(self.r_b6(self.r_b5(self.conv3(pool_2))))\n\t\tpool_3 = self.dropoutA(self.pool(conv_3))\n\t\t#print(\"Conv3: \",conv_3.shape)\n\t\t#print(\"Pool3: \",pool_3.shape)\n\t\t# 12 -> 6\n\t\tconv_4 = swish(self.r_b8(self.r_b7(self.conv4(pool_3))))\n\t\tpool_4 = self.dropoutA(self.pool(conv_4))\n\t\t#print(\"Conv4: \",conv_4.shape)\n\t\t#print(\"Pool4: \",pool_4.shape)\n\t\t# Middle\n\t\tconv_m = swish(self.r_bm2(self.r_bm1(self.convm(pool_4))))\n\t\t#print(\"ConvM: \",conv_m.shape)\n\t\t# 6 -> 12\n\t\tde_conv_4 = self.deconv4(conv_m)\n\t\tuconv_4 = torch.cat([de_conv_4,conv_4],1)\n\t\t#print(\"Uconv4: \",uconv_4.shape)\n\t\tuconv_4 = self.dropoutB(uconv_4)\n\t\tuconv_4 = self.uconv4(uconv_4)\n\t\tuconv_4 = self.r_bu1(uconv_4)\n\t\tuconv_4 = swish(self.r_bu2(uconv_4))\n\t\t#print(\"Uconv4: \",uconv_4.shape)\n\t\t# 12 -> 25\n\t\tde_conv_3 = self.deconv3(uconv_4)\n\t\tuconv_3 = torch.cat([de_conv_3,conv_3],1)\n\t\tuconv_3 = self.dropoutB(uconv_3)\n\t\tuconv_3 = self.uconv3(uconv_3)\n\t\tuconv_3 = self.r_bu3(uconv_3)\n\t\tuconv_3 = swish(self.r_bu4(uconv_3))\n\t\t#print(\"Uconv3:\",uconv_3.shape)\n\t\t# 25 -> 50\n\t\tde_conv_2 = self.deconv2(uconv_3)\n\t\tuconv_2 = torch.cat([de_conv_2,conv_2],1)\n\t\tuconv_2 = self.dropoutB(uconv_2)\n\t\tuconv_2 = self.uconv2(uconv_2)\n\t\tuconv_2 = self.r_bu5(uconv_2)\n\t\tuconv_2 = swish(self.r_bu6(uconv_2))\n\t\t#print(\"Uconv2:\",uconv_2.shape)\n\t\t#50 -> 101\n\t\tde_conv_1 = self.deconv1(uconv_2)\n\t\tuconv_1 = torch.cat([de_conv_1,conv_1],1)\n\t\tuconv_1 = self.dropoutB(uconv_1)\n\t\tuconv_1 = self.uconv1(uconv_1)\n\t\tuconv_1 = self.r_bu7(uconv_1)\n\t\tuconv_1 = swish(self.r_bu8(uconv_1))\n\t\t#print(\"Uconv1:\",uconv_1.shape)\n\t\t#Final\n\t\tconv_final = self.final_conv(uconv_1)\n\t\tconv_final = self.sigmoid(conv_final)\n\t\t#print(\"Conv_final: \",conv_final.shape)\n\t\treturn conv_final\n\ndef gael_net(**kwargs):\n    model = UNet(**kwargs)\n    return model\n\ndef get_model():\n    model = gael_net()\n    model.train()\n    return model.cuda()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8468e466668c98f99a5f582f1c075e132be5e604"},"cell_type":"code","source":"# https://github.com/leigh-plt/cs231n_hw2018/blob/master/assignment2/pytorch_tutorial.ipynb\n\"\"\"\nSave and Load Checkpoints\nBased on Model Training\nSource: https://github.com/leigh-plt/cs231n_hw2018/blob/master/assignment2/pytorch_tutorial.ipynb\nWill be the basis for checkpoint ensembling\n\"\"\"\ndef save_checkpoint(checkpoint_path, model, optimizer):\n    state = {'state_dict': model.state_dict(),\n             'optimizer' : optimizer.state_dict()}\n    torch.save(state, checkpoint_path)\n    print('model saved to %s' % checkpoint_path)\n    \ndef load_checkpoint(checkpoint_path, model, optimizer):\n    state = torch.load(checkpoint_path)\n    model.load_state_dict(state['state_dict'])\n    optimizer.load_state_dict(state['optimizer'])\n    print('model loaded from %s' % checkpoint_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"343bafa049a9a8a0f779c40d02cdfcdeb036dee4"},"cell_type":"code","source":"def train_model(model,epochs,\n                learning_rate,loss_function,\n                optimizer, dataset, dataset_val,\n                batch_size\n               ):\n    \"\"\"\n    function for training our model\n    \"\"\"\n    snapshot = SnapshotLR(\n        initial_lr=0.000001,max_lr=0.0001,\n        total_iters=epochs,n_cycles=30,\n        iteration_type=\"epochs\"\n    )\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                           mode=\"max\",\n                                                           factor=0.97,\n                                                           min_lr=0,\n                                                           patience=10\n                                                          )\n    lowest_train_loss = None\n    lowest_val_loss = None\n    highest_train_iou = None\n    highest_val_iou = None\n    for epoch in range(epochs):\n        # TRAIN BATCH\n        train_loss = []\n        train_iou = []\n        for image, mask in tqdm_notebook(data.DataLoader(dataset,batch_size=batch_size,shuffle=True)):\n            image = image.type(torch.FloatTensor).cuda()\n            y_pred = model(Variable(image))\n            loss = loss_function(y_pred, Variable(mask.cuda()))\n            iou_train = iou_metric_batch(mask.cpu().numpy(),y_pred.cpu().detach().numpy())\n            \n            optimizer.zero_grad()\n            loss.backward()\n            \n            torch.nn.utils.clip_grad_norm(model.parameters(), 1.0)\n            optimizer.step()\n            train_loss.append(loss.data[0])\n            train_iou.append(iou_train)\n        \n        # VAL BATCH\n        val_loss = []\n        val_iou = []\n        for image, mask in data.DataLoader(dataset_val, batch_size = batch_size, shuffle = False):\n            image = image.cuda()\n            y_pred = model(Variable(image))\n            \n            loss = loss_function(y_pred, Variable(mask.cuda()))\n            val_loss.append(loss.data[0])\n            iou_val = iou_metric_batch(mask.cpu().numpy(),y_pred.cpu().detach().numpy())\n            val_iou.append(iou_val)\n        \n        if lowest_train_loss is None:\n            lowest_train_loss = np.mean(train_loss)\n            save_checkpoint('low_train_loss_tgs.pth' ,model, optimizer)\n        if lowest_val_loss is None:\n            lowest_val_loss = np.mean(val_loss)\n            save_checkpoint('low_val_loss_tgs.pth' ,model, optimizer)\n        if highest_train_iou is None:\n            highest_train_iou = np.mean(train_iou)\n            save_checkpoint('high_train_iou_tgs.pth' ,model, optimizer)\n        if highest_val_iou is None:\n            highest_val_iou = np.mean(val_iou)\n            save_checkpoint('high_val_iou_tgs.pth' ,model, optimizer)\n        print(\"Epoch: %d,T_Loss: %.7f, T_IOU: %.7f, V_Loss: %.7f, V_IOU: %.7f\" % (\n            epoch,\n            np.mean(train_loss),\n            np.mean(train_iou),\n            np.mean(val_loss),\n            np.mean(val_iou)\n        )\n             )\n        if np.mean(train_loss) < lowest_train_loss:\n            lowest_train_loss = np.mean(train_loss)\n            save_checkpoint('low_train_loss_tgs.pth' ,model, optimizer)\n        if np.mean(val_loss) < lowest_val_loss:\n            lowest_val_loss = np.mean(val_loss)\n            save_checkpoint('low_val_loss_tgs.pth' ,model, optimizer)\n        if np.mean(train_iou) > highest_train_iou:\n            highest_train_iou = np.mean(train_iou)\n            save_checkpoint('high_train_iou_tgs.pth' ,model, optimizer)\n        if np.mean(val_iou) > highest_val_iou:\n            highest_val_iou = np.mean(val_iou)\n            save_checkpoint('high_val_iou_tgs.pth' ,model, optimizer)\n        scheduler.step(highest_val_iou)\n        resulting_lr = snapshot.adjust(optimizer,epoch)\n        print(\"LR\",resulting_lr)\n    # Saves model post all epochs\n    save_checkpoint('tgs-%i.pth' % epochs, model, optimizer)\n    print(\"Best T_L:\",lowest_train_loss,\n          \" Best T_I:\",highest_train_iou,\n          \" Best V_L:\",lowest_val_loss,\n          \" Best V_I:\", highest_val_iou\n         )\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c676c410ad31202e44edf4c46dfa53f0200dad4"},"cell_type":"code","source":"class TGSSaltDataset(data.Dataset):\n    def __init__(self, root_path, file_list, is_test = False):\n        self.is_test = is_test\n        self.root_path = root_path\n        self.file_list = file_list\n    \n    def __len__(self):\n        return len(self.file_list)\n    \n    def __getitem__(self, index):\n        if index not in range(0, len(self.file_list)):\n            return self.__getitem__(np.random.randint(0, self.__len__()))\n        \n        file_id = self.file_list[index]\n        \n        image_folder = os.path.join(self.root_path, \"images\")\n        image_path = os.path.join(image_folder, file_id + \".png\")\n        \n        mask_folder = os.path.join(self.root_path, \"masks\")\n        mask_path = os.path.join(mask_folder, file_id + \".png\")\n        \n        image = load_image(image_path)\n        \n        if self.is_test:\n            return (image,)\n        else:\n            mask = load_image(mask_path, mask = True)\n            return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"122bf2e3066627560f5fa1e8e726a088423d7b50"},"cell_type":"code","source":"def rle_encoding(x):\n    \"\"\"\n    RLE Encoding function\n    For finding the coordinates from \n    the predicted mask\n    \"\"\"\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b > prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7114b9f3da03d4688ecfdecd7c7008a0be0c8004"},"cell_type":"code","source":"def load_image(path,pad=True, mask = False):\n    \"\"\"\n    Loads an image or its given mask.\n    If (pad== True):\n     Pads it so that it is\n    easier to perform maxpooling and deconvolutions\n    Else:\n     Performs no padding and leaves image as is\n    If (mask == True):\n     perform mask specific conversion\n    Else:\n     does normal image conversion\n    \"\"\"\n    flip = False\n    if \"_gael\" in path:\n        path = path.replace(\"_gael\",\"\")\n        flip = True\n    img = cv2.imread(str(path))\n    if flip:\n        #horizontal flip aka fliplr by cv2\n        img = cv2.flip( img, 0 )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, _ = img.shape\n\n    if pad:\n        if height % 32 == 0:\n            y_min_pad = 0\n            y_max_pad = 0\n        else:\n            y_pad = 32 - height % 32\n            y_min_pad = int(y_pad / 2)\n            y_max_pad = y_pad - y_min_pad\n        \n        if width % 32 == 0:\n            x_min_pad = 0\n            x_max_pad = 0\n        else:\n            x_pad = 32 - width % 32\n            x_min_pad = int(x_pad / 2)\n            x_max_pad = x_pad - x_min_pad\n    \n    img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad, x_min_pad, x_max_pad, cv2.BORDER_REFLECT_101)\n    \n    if mask:\n        img = img[:, :, 0:1] // 255\n        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32'))\n    else:\n        img = img / 255.0\n        return torch.from_numpy(np.transpose(img, (2, 0, 1)).astype('float32'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4ec2c744994387edebc6fe3ca5a1b7d74e81ee6"},"cell_type":"code","source":"#all_predictions_stacked = pred_resize(all_predictions_stacked,101,101)\ndef pred_resize(predictions,height,width):\n    \"\"\"\n    Just resizes image to desired size\n    \"\"\"\n    if height % 32 == 0:\n        y_min_pad = 0\n        y_max_pad = 0\n    else:\n        y_pad = 32 - height % 32\n        y_min_pad = int(y_pad / 2)\n        y_max_pad = y_pad - y_min_pad\n    if width % 32 == 0:\n        x_min_pad = 0\n        x_max_pad = 0\n    else:\n        x_pad = 32 - width % 32\n        x_min_pad = int(x_pad / 2)\n        x_max_pad = x_pad - x_min_pad\n    predictions = predictions[:, y_min_pad:128 - y_max_pad, x_min_pad:128 - x_max_pad]\n    print(\"Prediction Shape: \",predictions.shape)\n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c37812acc9bdddc762b7352bbfe67d3d485ae50"},"cell_type":"code","source":"def stack_and_resize(predictions,height,width):\n    \"\"\"\n    Stacks and resizes the predicitons\n    \"\"\"\n    preds_stacked = np.vstack(predictions)[:, 0, :, :]\n    return pred_resize(preds_stacked,height,width)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73d4df33bcbf0d8f6a44c22db906b406191b27d4"},"cell_type":"code","source":"# Silence All Warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bff91e9c104ec533d860a6d1dbde147a89bdf94d"},"cell_type":"code","source":"\"\"\"\nData Preparation and Gathering\n1. Load in training and validation data\n---Image and it's mask-----\n2. Load in testing data\nA - Pad images where necessary\nWhere would do analysis and update of data\n\"\"\"\n# Directory which contains our data\ndirectory = '../input/tgs-salt-identification-challenge'\n\n# Gets our train_data\ndepths_df = pd.read_csv(os.path.join(directory, 'train.csv'))\n\n# Setting paths for our datasets\ntrain_path = os.path.join(directory, 'train')\ntest_path = os.path.join(directory, 'test')\n\n#Custom Test Split based on salt coverage\nids_val = _pickle.load(open(\"../input/intermediatetgs/val_index.obj\",\"rb\"))\nids_train = _pickle.load(open(\"../input/intermediatetgs/train_index.obj\",\"rb\"))\n\n# Setting the file list\nfile_list = list(depths_df['id'].values)\n#file_list_val = file_list[::10]\nfile_list_val = list(ids_val)\n#file_list_train = [f for f in file_list if f not in file_list_val]\nfile_list_train = list(ids_train)\nfile_list_flip = [s + \"_gael\" for s in file_list_train]\nfile_list_train = file_list_train + file_list_flip\ntest_file_list = glob.glob(os.path.join(test_path, 'images', '*.png'))\ntest_file_list = [f.split('/')[-1].split('.')[0] for f in test_file_list]\n\n# Validating our file list\nprint(\"Training Data:\")\nprint(\"Train: \",len(file_list_train))\nprint(\"Validation: \",len(file_list_val))\nprint(\"Total: \",len(file_list))\nprint(\"Testing Data:\")\nprint(\"Images: \",len(test_file_list))\n\n# Datasets\ndataset = TGSSaltDataset(train_path, file_list_train)\ndataset_val = TGSSaltDataset(train_path, file_list_val)\ntest_dataset = TGSSaltDataset(test_path, test_file_list, is_test = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"767dae95adfbe7fefcb4cc3dd397ea8ba0e3f8d1","scrolled":true},"cell_type":"code","source":"\"\"\"\nModel Training\nSet epochs, learning rate,\nloss functions, optimizers,\nbatch_size, shuffle\nCheckpoint Saving\nAlso what is reported on every epoch\n\"\"\"\nmodel = get_model()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec881b22e5081937f18eb27cc931766734afc81f","scrolled":true},"cell_type":"code","source":"#epoch =115\n#learning_rate = 0.001\n#loss_fn = torch.nn.BCELoss()\n#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, eps=1e-7)\n#model = train_model(model,epoch,learning_rate,\n#                    loss_fn,optimizer, dataset,\n#                    dataset_val,32\n#                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c890d61a04e1d18c98ac948d94b61c497c2f6ae"},"cell_type":"code","source":"#Load From Checkpoint\nepoch =100\nlearning_rate = 0.0001\nloss_fn = torch.nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, eps=1e-7)\nload_checkpoint(\"../input/80pytorchgamma/high_val_iou_tgs.pth\", model, optimizer)\nmodel = train_model(model,epoch,learning_rate,\n                    loss_fn,optimizer, dataset,\n                    dataset_val,32\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"971e75a32512f23aee3cbc629df64c8079940e91"},"cell_type":"code","source":"load_checkpoint(\"high_val_iou_tgs.pth\", model, optimizer)\n# Making predictions Batch Size is the same\nall_predictions = []\nfor image in tqdm_notebook(data.DataLoader(test_dataset, batch_size = 32)):\n    image = image[0].type(torch.FloatTensor).cuda()\n    y_pred = model(Variable(image)).cpu().data.numpy()\n    all_predictions.append(y_pred)\nall_predictions_stacked = stack_and_resize(all_predictions,101,101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65d1b4f79719da90faa68bb73359a5189ea70bfd"},"cell_type":"code","source":"# Making predictions of the validation sets\n# and masks to determine iou\nval_predictions = []\nval_masks = []\nfor image, mask in tqdm_notebook(data.DataLoader(dataset_val, batch_size = 32)):\n    image = Variable(image.type(torch.FloatTensor).cuda())\n    y_pred = model(image).cpu().data.numpy()\n    val_predictions.append(y_pred)\n    val_masks.append(mask)\n    \n\nval_predictions_stacked = stack_and_resize(val_predictions,101,101)\nval_masks_stacked = stack_and_resize(val_masks,101,101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbd7cbac108805a401a445947b4cfd95721e10ee"},"cell_type":"code","source":"# IOU Metric By Threshold\nmetric_by_threshold = []\nfor threshold in np.linspace(0.3, 0.7, 50):\n    val_binary_prediction = (val_predictions_stacked > threshold).astype(int)\n    \n    iou_values = []\n    for y_mask, p_mask in zip(val_masks_stacked, val_binary_prediction):\n        iou = jaccard_similarity_score(y_mask.flatten(), p_mask.flatten())\n        iou_values.append(iou)\n    iou_values = np.array(iou_values)\n    \n    accuracies = [\n        np.mean(iou_values > iou_threshold)\n        for iou_threshold in np.linspace(0.5, 0.95, 10)\n    ]\n    print('Threshold: %.2f, Metric: %.3f' % (threshold, np.mean(accuracies)))\n    metric_by_threshold.append((np.mean(accuracies), threshold))\n    \nbest_metric, best_threshold = max(metric_by_threshold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69b3e6549ac9dac536eacd7d116d1942a61b0b50"},"cell_type":"code","source":"threshold = best_threshold\nbinary_prediction = (all_predictions_stacked > threshold).astype(int)\n\nall_masks = []\nfor p_mask in list(binary_prediction):\n    p_mask = rle_encoding(p_mask)\n    all_masks.append(' '.join(map(str, p_mask)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2d05d0ed3c54619523a55683d6e1afc22dace1f"},"cell_type":"code","source":"# Submission File\nsubmit = pd.DataFrame([test_file_list, all_masks]).T\nsubmit.columns = ['id', 'rle_mask']\nsubmit.to_csv('submit_baseline_torch.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}