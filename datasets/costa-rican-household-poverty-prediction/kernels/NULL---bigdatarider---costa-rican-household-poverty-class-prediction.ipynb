{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#import required libraries\nimport pandas as pd\nimport numpy as np \nfrom xgboost import XGBClassifier\nfrom sklearn.calibration import CalibratedClassifierCV\n\n#Read training data\nd = pd.read_csv('../input/train.csv')\n\n# Fill missing data with appropriate equivalents according to feature descriptions\nd['meaneduc']=d['meaneduc'].fillna(0)\nd['SQBmeaned']=d['SQBmeaned'].fillna(0)\nd['rez_esc']=d['rez_esc'].fillna(0)\nd['v18q1']=d['v18q1'].fillna(0)\nd['v2a1']=d['v2a1'].fillna(0)\n\nd.loc[d['dependency'] == 'yes', 'dependency'] = 1\nd.loc[d['dependency'] == 'no', 'dependency'] = 0\nd['dependency'] = pd.to_numeric(d['dependency'])\n\nd.loc[d['edjefe'] == 'yes', 'edjefe'] = 1\nd.loc[d['edjefe'] == 'no', 'edjefe'] = 0\nd['edjefe'] = pd.to_numeric(d['edjefe'])\n\nd.loc[d['edjefa'] == 'yes', 'edjefa'] = 1\nd.loc[d['edjefa'] == 'no', 'edjefa'] = 1\nd['edjefa'] = pd.to_numeric(d['edjefa'])\n\n\n# Import and use ExtraTreesClassifier for finding feature importances\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import ExtraTreesClassifier\n\n# Create features and labels\nfeatures=d.drop(['Target','Id','idhogar'], axis=1)\nlabels=d.Target\n\n# Split for training and test\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n\n# Fit model\nmodel = ExtraTreesClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Get importances table\nimp=pd.DataFrame(({'features': X_train.columns, 'importances': model.feature_importances_}))\n\n#Decided to use 16 features with top scores\nimp[imp.importances>0.016].features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bd48c9b0fc21408096f9da3fd611d9d377543a9"},"cell_type":"code","source":"#Create dataframe with 16 features\nmodel_df1=d[imp[imp.importances>0.016].features] \n\n# Add household head id and Target columns to source dataframe\nmodel_df1 =pd.concat([model_df1, d[['idhogar','Target']]],axis=1)\n\n# Create a new dataframe with aggregate functions - Trying to find best transformed features\ntop16features_group = (model_df1.groupby(['idhogar','Target'])\n                    .agg({'meaneduc':np.sum,\n                         'cielorazo':np.sum,\n                         'r4t1':np.sum,\n                         'overcrowding':np.median,\n                         'hogar_nin':np.median,\n                         'edjefe':np.median,\n                         'SQBmeaned':np.median,\n                         'paredblolad':np.sum,\n                         'SQBovercrowding':np.median,\n                         'dependency':np.median,\n                         'qmobilephone':np.sum,\n                         'SQBdependency':np.median,\n                         'v18q':np.mean,\n                         'r4m3':np.median,\n                         'SQBedjefe':np.median,\n                         'SQBhogar_nin':np.sum\n                         }))\n\n#Create features and labels\nfeatures=top16features_group.reset_index().drop(['Target','idhogar'], axis=1)\nlabels=top16features_group.reset_index().Target\n\n# Split train and test sets\nX_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n\n\n# Use Calibrated XGB Classifier for training\nclf=XGBClassifier(random_state=1,objective='multi:softprob', max_depth= 8, n_estimators= 25, colsample_bytree=0.8,learning_rate=0.1)\ncal_clf = CalibratedClassifierCV(clf, cv=3) \ncal_clf.fit(X_train, y_train)\n\n#Print scores\nprint(\"Train score : \" + str(cal_clf.score(X_train, y_train)))\nprint(\"Test score : \" + str(cal_clf.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a478f45a669383a45484de45ba06ec5610ceb8ab"},"cell_type":"code","source":"#Read test set for prediction\nt= pd.read_csv('../input/test.csv')\n\n# Clean and replace missing values\nt.loc[t['dependency'] == 'yes', 'dependency'] = 1\nt.loc[t['dependency'] == 'no', 'dependency'] = 0\n\nt['meaneduc']=t['meaneduc'].fillna(0)\nt['SQBmeaned']=t['SQBmeaned'].fillna(0)\nt['rez_esc']=t['rez_esc'].fillna(0)\nt['v18q1']=t['v18q1'].fillna(0)\nt['v2a1']=t['v2a1'].fillna(0)\n\nt.loc[t['dependency'] == 'yes', 'dependency'] = 1\nt.loc[t['dependency'] == 'no', 'dependency'] = 0\nt['dependency'] = pd.to_numeric(t['dependency'])\n\nt.loc[t['edjefe'] == 'yes', 'edjefe'] = 1\nt.loc[t['edjefe'] == 'no', 'edjefe'] = 0\nt['edjefe'] = pd.to_numeric(t['edjefe'])\n\nt.loc[t['edjefa'] == 'yes', 'edjefa'] = 1\nt.loc[t['edjefa'] == 'no', 'edjefa'] = 1\nt['edjefa'] = pd.to_numeric(t['edjefa'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1469c47210db88fd47428763b8967b99038dc7d1"},"cell_type":"code","source":"# Get target features\ntfeatures = t[imp[imp.importances>0.016].features]\n\n# Add household head id and Target columns to source dataframe\ntfeatures =pd.concat([tfeatures, t[['idhogar']]],axis=1)\n\n# Create a new dataframe with aggregate functions - Trying to find best transformed features\ntop16features_testgroup = (tfeatures.groupby(['idhogar'])\n                         .agg({'meaneduc':np.sum,\n                         'cielorazo':np.sum,\n                         'r4t1':np.sum,\n                         'overcrowding':np.median,\n                         'hogar_nin':np.median,\n                         'edjefe':np.median,\n                         'SQBmeaned':np.median,\n                         'paredblolad':np.sum,\n                         'SQBovercrowding':np.median,\n                         'dependency':np.median,\n                         'qmobilephone':np.sum,\n                         'SQBdependency':np.median,\n                         'v18q':np.mean,\n                         'r4m3':np.median,\n                         'SQBedjefe':np.median,\n                         'SQBhogar_nin':np.sum\n                         }))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8c99ed49b11dc862b9c92615249a19380374929"},"cell_type":"code","source":"# Predict test group\ny_pred_test = cal_clf.predict(top16features_testgroup)\n\n#Create dataframe for merging predictions with original household head ids\nsubmission_df = pd.DataFrame({'Id':t.Id,'idhogar':t.idhogar})\n#Set default Target value as zero\nsubmission_df['Target']=0\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"818793190c684365f4fbed725f9850c5ee6c53c6"},"cell_type":"code","source":"#Fill submission Targets with predicted values\nprediction_index=0\nfor household_index,row in top16features_testgroup.iterrows():\n    submission_df.loc[submission_df['idhogar']==household_index,'Target']=y_pred_test[prediction_index]    \n    prediction_index+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a6f152700d842f05d9d1de03d01ef719d370e2a"},"cell_type":"code","source":"#Control Target data\nsubmission_df.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca7d7cc341612c1d2dc34195830b5a28e6595d23"},"cell_type":"code","source":"#Export\nsubmission_df[['Id','Target']].to_csv('submission.csv',sep=',',encoding='utf-8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556ec3ff0c6d5565a5d01e71402afb00abf37fd4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}