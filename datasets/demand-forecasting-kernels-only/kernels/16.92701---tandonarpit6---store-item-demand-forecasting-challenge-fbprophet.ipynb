{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"training_data=pd.read_csv('../input/train.csv')\ntest_data=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b475daa5f35d64465ead15517ce6108d46559e8c","collapsed":true},"cell_type":"code","source":"training_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc51c409e2f7c9082b80a53bfe68bb86bbee076","collapsed":true},"cell_type":"code","source":"training_data['date']= pd.to_datetime(training_data['date'])\ntest_data['date']= pd.to_datetime(test_data['date'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95c2600839bf823a6a6e62ccf6ced5fa9b9b4edb"},"cell_type":"markdown","source":"Planning to use 2 approaches to predict and see which works better as we can submit 2 times. Best thing is that all data is perfectly cleaned up, so no time wasting in cleaning and preprocessing the data.\n\n1. Deep learning prediction\n2. Use Facebook prophet library to predict"},{"metadata":{"trusted":true,"_uuid":"748cf3c7e63bd696928d5804b23311ce8417e5ba","collapsed":true},"cell_type":"code","source":"X_train=training_data.loc[:,['date','store','item']]\nY_train=training_data.loc[:,['sales']]\nX_test=test_data.loc[:,['date','store','item']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d173218b19565378d7df665e1fcfe7782862e740"},"cell_type":"markdown","source":"Need to manage this date as input, since this is an input feature- rather than take it as a full number, better to break it into multiple things like Year, month, date so as to capture any seasonality effects."},{"metadata":{"trusted":true,"_uuid":"550b1f4295cbbb5c91a6ec12ecf6906a5cc70049","collapsed":true},"cell_type":"code","source":"X_train['year']=X_train['date'].dt.year\nX_train['month']=X_train['date'].dt.month\nX_train['day']=X_train['date'].dt.day\nX_train['weekday']=X_train['date'].dt.weekday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4afabe2b2207b34eba958ea450380cb5491acc52","collapsed":true},"cell_type":"code","source":"X_test['year']=X_test['date'].dt.year\nX_test['month']=X_test['date'].dt.month\nX_test['day']=X_test['date'].dt.day\nX_test['weekday']=X_test['date'].dt.weekday","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bce9f6d29eb4ae9ecc2c13d0334a75ef062d3b5c","collapsed":true},"cell_type":"code","source":"X_train= X_train.drop(columns=['date'])\nX_test= X_test.drop(columns=['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e30296cef91dfc2d90fd1d52c818d88d7702df4","collapsed":true},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras.layers import Dense, Dropout\nfrom keras import optimizers\nfrom keras.callbacks import History\nfrom matplotlib import pyplot as plt\n\nhistory=History()\n\nmodel_DL=models.Sequential()\nmodel_DL.add(layers.Dense(32, activation='relu',input_dim=6))\nmodel_DL.add(Dropout(0.2))\nmodel_DL.add(layers.Dense(32, activation='relu',input_dim=6))\nmodel_DL.add(Dropout(0.2))\n\nmodel_DL.add(layers.Dense(1,activation='softmax'))\n\nadam=optimizers.Adagrad(lr=0.0001)\n\nmodel_DL.compile(optimizer=adam,loss='mse')\n\nhistory= model_DL.fit(X_train,Y_train,batch_size=512,epochs=4)\n\nY_pred_DL=model_DL.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96e7e97ffd7e47843377cf52d1f8f9e59fc961ad"},"cell_type":"markdown","source":"Will have to skip the Prophet library because it uses only date data, we have store and item information also here. Can do something by grouping and all but then it focuses only on timeseries variation but here sales could be impacted because of store and item. Good to quickly do a deep learning model prediction. Deep learning model getting stuck at loss of 3456 after lot of parameter hypertuning- changing the learning rate.\n\nThere are 10 different stores and 50 different items."},{"metadata":{"trusted":true,"_uuid":"51b80b5d7af3bc36c4c3518011c78de6b10218ae","collapsed":true},"cell_type":"code","source":"training_data.item.unique()\ntraining_data.store.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d5150079c60f88a82e6fb7e9da90f1d73398db","collapsed":true},"cell_type":"code","source":"Y_pred_DL","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2229d93ad5f8b34b9efe6a66b29b044efd58301"},"cell_type":"markdown","source":"No learning happened, only taking 1 for all prediction."},{"metadata":{"trusted":true,"_uuid":"1b2f585e34890fbac4f0a248fdecc7f5ee25cadc","collapsed":true},"cell_type":"code","source":"from fbprophet import Prophet\n\nsubmission=pd.DataFrame()\nforecast_values=pd.Series([])\nindex=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4908e0ad452b99dca593e37cbbc15dac0d960198","collapsed":true},"cell_type":"code","source":"for item in training_data['item'].unique():\n    for store in training_data['store'].unique():\n        temp_training = training_data.loc[(training_data['store']==store) & (training_data['item']== item)]\n        temp_training=temp_training[['date','sales']]\n        temp_training.rename(columns={'date':'ds','sales':'y'}, inplace=True)\n        model=Prophet()\n        model.add_seasonality(name='monthly',period=30.5,fourier_order=5)\n        model.fit(temp_training)\n        future=model.make_future_dataframe(periods=90)\n        forecast=model.predict(future)\n        forecast=forecast.tail(90)\n        forecast_values=forecast_values.append(forecast['yhat'],ignore_index=True)\n        index=index+1\n        print(\"Iteration\",index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b5cd42767a4d37c67f76dd3041e7aae3a6cb780","collapsed":true},"cell_type":"code","source":"submission['id']=test_data['id']\nsubmission['sales']=forecast_values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfaf167e2aa5e0eeabb232faac61c4811e981695","collapsed":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99665cb98422fb9d04f7cd95d2d00c791414c6d3","collapsed":true},"cell_type":"code","source":"submission.to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}