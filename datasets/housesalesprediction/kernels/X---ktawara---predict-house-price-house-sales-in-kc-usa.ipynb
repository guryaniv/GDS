{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import cross_val_score\n\ndf = pd.read_csv(\"../input/kc_house_data.csv\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a0cb2302cfc8e3e318b6dc347e27b6fa2cb9a68"},"cell_type":"code","source":"display(df.head())\ndisplay(df.tail())","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"546830c2f5568af7a7af2c76b8b96a9ee882ac10"},"cell_type":"code","source":"print(df.info())","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"bb74591ade4c7e5e3a4e3e7c71d3995db6f06ab1"},"cell_type":"markdown","source":"No missing value."},{"metadata":{"trusted":true,"_uuid":"41faa4ed8a8569513605d0f45485cc5407bcb916"},"cell_type":"code","source":"print(\"Data shape: {}\" .format(df.shape))","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"eb366de4876d37e9c29e60d92a82bd1775abc8a0"},"cell_type":"markdown","source":"Number of data points: 21,613 <br>\nNumber of feature quantities: 21"},{"metadata":{"trusted":true,"_uuid":"53743c79c4a93d46d31a096b496fb758984cb38b"},"cell_type":"code","source":"df.describe()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"332116365a603599e29d4ee9b82b97417423a362"},"cell_type":"code","source":"#Take a look at the heat map with seaborn\ncorr = df.corr()\nsns.heatmap(corr, \n            xticklabels=corr.columns.values,\n            yticklabels=corr.columns.values)","execution_count":12,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"e6a523561f76ecc786ff073c773957a14077c161"},"cell_type":"code","source":"#Another way to look at the heat map \ndf.corr().style.background_gradient().format('{:.2f}')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddbd218fcd18f5018b15ea83138a7a57a199c247"},"cell_type":"code","source":"#Check price and the scatter plot of each feature\ndf2 = df.drop(['zipcode','id'],axis=1)\n\nfor c in df2.columns:\n    if (c != 'price') & (c != 'date'):\n        df2[[c,'price']].plot(kind='scatter',x=c,y='price')","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"fc88ad1fe69f3c3fa468a6111de32ff868a092b4"},"cell_type":"markdown","source":"### Selection of feature quantity (1)\n\n- Let's pick up a characteristic amount with high correlation with price\nsqft_living, grade, sqft_above\n- The correlation of sqft_living 15 is also high, but when looking at the description of data (https://www.kaggle.com/harlfoxem/housesalesprediction/data), Living room area in 2015 (implies - some renovations)\n- This is or might not have affected the lotsize area and is excluded because it is old in the 2015 sqft_living data\n- Exclude sqft_lot 15 for the same reason as sqft_living 15"},{"metadata":{"trusted":true,"_uuid":"6255338eb1a5a7790801b6a7fa791c8d102e9111"},"cell_type":"code","source":"df.date.head()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6187095386db8d08ec77c1ea8139788462593911"},"cell_type":"code","source":"#date conversion\npd.to_datetime(df.date).head()","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"400c315ca03e4ab654b4ca5482835ce0b62361a8"},"cell_type":"code","source":"#df_en_fin = df.drop(['date','zipcode','sqft_living15','sqft_lot15'],axis=1)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"80bb2cd7151c6d1ed27f4a471bcf7ec0531bc795"},"cell_type":"markdown","source":"### Check results of each algorithm and select algorithm\nConfirm results with the following algorithm\n\n1. Linear regression\n1. Random Forest\n1. gradient boosting\n1. k neighborhood method"},{"metadata":{"trusted":true,"_uuid":"6a2754120496c473ee1a454198b0fcf784cee06e"},"cell_type":"code","source":"#1.Linear regression\n\ndf = pd.read_csv(\"../input/kc_house_data.csv\")\nX = df.drop([\"id\", \"price\", \"zipcode\", \"date\"], axis=1)\ny = df[\"price\"]\n\nregr = LinearRegression()\nscores = cross_val_score(regr, X, y, cv=10)\nprint(\"score: %s\"%scores.mean())","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d84df95ec639b71e56183e5f2bf15c69c3502074"},"cell_type":"code","source":"#2.Random Forest\n\ndf = pd.read_csv(\"../input/kc_house_data.csv\")\nX = df.drop([\"id\", \"price\", \"zipcode\", \"date\"], axis=1)\ny = df[\"price\"]\n\nregr = RandomForestRegressor()\nscores = cross_val_score(regr, X, y, cv=10)\nprint(\"score: %s\"%scores.mean())","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"866d858f0472e2ccfd832412f583c06b48240c34"},"cell_type":"code","source":"#3.gradient boosting\nfrom sklearn.ensemble import GradientBoostingClassifier\n\ndf = pd.read_csv(\"../input/kc_house_data.csv\")\nX = df.drop([\"id\", \"price\", \"zipcode\", \"date\"], axis=1)\ny = df[\"price\"]\n\ngbrt = GradientBoostingClassifier()\nscores = cross_val_score(regr, X, y, cv=10)\nprint(\"score: %s\"%scores.mean())","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54ff0fccc624e5e1140e3cab4bd6810d6a44a94"},"cell_type":"code","source":"#4.k neighborhood method\nfrom sklearn.neighbors import KNeighborsClassifier\n\ndf = pd.read_csv(\"../input/kc_house_data.csv\")\nX = df.drop([\"id\", \"price\", \"zipcode\", \"date\"], axis=1)\ny = df[\"price\"]\n\nn_neighbors = KNeighborsClassifier()\nscores = cross_val_score(regr, X, y, cv=10)\nprint(\"score: %s\"%scores.mean())","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"519d6c8e89258676e60e63eef2251c95b513ad27"},"cell_type":"markdown","source":"### Conclusion so far and what to do in the future\n- The highest score was random forest followed by the k-nearest neighbor method\n- Evaluate prediction performance with two algorithms of k-neighbor method and random forest"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ef16d9f1f0852fd753dc23c8f843eea89868e544"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}