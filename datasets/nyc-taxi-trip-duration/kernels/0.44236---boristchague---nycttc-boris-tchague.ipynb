{"cells":[{"metadata":{"_uuid":"151e3239dc9090a5ab589060974610993a5aed1f"},"cell_type":"markdown","source":"#                                       ** PREDICTION NEWYORK TAXI TRIP DURATIONS**"},{"metadata":{"_uuid":"ffcdfac7a48a807d62932aee5d8606cec3a7d026"},"cell_type":"markdown","source":"\n### **Headings**\n* I.   Importing modules \n* II.  Loading files \n* II.  Data processing\n* IV. Exporatory data analysis \n* V.  Algorithme \n* VI. submission"},{"metadata":{"_uuid":"042de5146776ebf24319a1c2edf2b5009bcc7845"},"cell_type":"markdown","source":"#  **I. Importing modules**"},{"metadata":{"trusted":true,"_uuid":"d9a7253d315fb6a97fdb2f189b383d240bed7187"},"cell_type":"code","source":"import os \n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nimport matplotlib.mlab as mlab\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, mean_squared_error as MSE\nfrom sklearn.linear_model import LinearRegression, Lasso\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\n\n\n\n# Settings\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (8.5, 5)\nplt.rcParams[\"patch.force_edgecolor\"] = True\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nsns.mpl.rc(\"figure\", figsize=(8.5,5))\n\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b4c99242a47ee164968c4c384e62f47f0316a6e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e450e611494e07b37af6185b8f639a1abf3c10d"},"cell_type":"markdown","source":"# **II. Loading files**"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b38c7cd4830598660e74f723e3efd62e55325c15"},"cell_type":"code","source":"import os\n\ntrain = pd.read_csv ('../input/train.csv')\ntest = pd.read_csv ('../input/test.csv')\n\ntrain.head(2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91c89df0a11d676b636fd90c7ce19e390a229e5d"},"cell_type":"markdown","source":"# **III. Data processing**"},{"metadata":{"_uuid":"d6f4b2eb47fddb0cca8ba0945cfbb53f10462bb5"},"cell_type":"markdown","source":"##  Pre-Processing Data\nAfter loading our data, we need to examine the structure of data to out find out what are possible missing values and outiliers."},{"metadata":{"_uuid":"87d933fba9e492989ccc05a36366447b736622d6"},"cell_type":"markdown","source":"### 1. Pre-processing Data : Missing values "},{"metadata":{"trusted":true,"_uuid":"83812b3dabfb21e095577338a9f16ec96b4ae0f9"},"cell_type":"code","source":"print(train.shape);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3245059cd9071056a465912a40ea2894c1fcd9f"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83839b096dd9cdd83b4d464b2d98e8132bb41831"},"cell_type":"markdown","source":"The pickup and dropoff timestamp variables are being treated as non-null objects. These features should be converted to date objects to allow for easier feature engineering later on in Data type pre-processing section (section **III.a.3**)"},{"metadata":{"trusted":true,"_uuid":"69d704ed300858db4d881cc41bd74fe386662582"},"cell_type":"code","source":"#### we have no missing value in our data set. \ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4eacf14a37bcdf6c1a50686731cf855cf31610e"},"cell_type":"markdown","source":"### 2. Pre-processing Data : Outliers"},{"metadata":{"trusted":true,"_uuid":"087fd7ca88d89e1ee9d257cae897bc1247ec8fc5"},"cell_type":"code","source":"train.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dad3238e7a89b0288a8eb29c55c8a3f74b9e471"},"cell_type":"markdown","source":"**Passenger_count** : Rationaly we would consider a trip with at least a passenger, so values with zero shall be deleted. LIkely trips with number of passengers above 5 shall be deleted because law provide that a a maximum number of passenger should not exced 5 persons, though in some few exception, passengers under the age of 7 who may sit on an adult's lap. However it unlikely that a full 5 person taxi cab would have that many children under the age of 7.   \n\n**Longitude and Latitude Coordinates** \nFurther More, New York City cordinates are normaly found between :\n*          Latitude is between 40.7128 and 40.748817\n*          Longitude is between - 74.0059 and - 73.968285\n\n**Trip_duration**\nLastly, there are unusual observations present in our target variable, trip_duration. The maximum trip_duration is unrealistic : 3526282.00 sec ( approximatively 980 hours). To get ride of this outlayers we will exclude all data points that are a specified number of standard deviations away from the mean.\nWe will remove trip_duration observations that are more than two standard deviations away from the mean duration time, \n\n"},{"metadata":{"trusted":true,"_uuid":"6759f8e0329e5f1492d5707a68cedd1413cb8aa4"},"cell_type":"code","source":"train = train[train['passenger_count']>0]\ntrain = train[train['passenger_count']<9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b91c2339f4c1ccf72e139e027c0f4e3e5d50d0a2"},"cell_type":"code","source":"#Pro-processing Pickup cordinates\ntrain = train[train['pickup_longitude'] <= -73.75]\ntrain = train[train['pickup_longitude'] >= -74.03]\ntrain = train[train['pickup_latitude'] <= 40.85]\ntrain = train[train['pickup_latitude'] >= 40.63]\n\n\n#Pro-processing dropoff cordinates \ntrain = train[train['dropoff_longitude'] <= -73.75]\ntrain = train[train['dropoff_longitude'] >= -74.03]\ntrain = train[train['dropoff_latitude'] <= 40.85]\ntrain = train[train['dropoff_latitude'] >= 40.63]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5e205906a4f60f7bb59d01813351f6f8d390215"},"cell_type":"code","source":"#Pre-processing trip duration \ntrip_duration_mean = np.mean(train['trip_duration'])\ntrip_duration_std = np.std(train['trip_duration'])\ntrain = train[train['trip_duration']<=trip_duration_mean + 2*trip_duration_std]\ntrain = train[train['trip_duration']>= trip_duration_mean - 2*trip_duration_std]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"321596ecd5ce798907b9497efc16bb8f6875c132"},"cell_type":"code","source":"# Confirm removal\ntrain.describe().transpose()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8b10011950ed32e6fcb4d15454dfab80d62fbc7"},"cell_type":"markdown","source":"### 3. Pre-processing Data : Data type\n   Here we extract dates, by converting them  \"object\" type to \"datetime\" type.               "},{"metadata":{"trusted":true,"_uuid":"ba17254c63824e5c7f3e2478b241faa2c522a8bc"},"cell_type":"code","source":"# Pickups\ntrain['pickup_datetime'] = pd.to_datetime(train['pickup_datetime']) \n\n# Drop-offs\ntrain['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"408ceb93884524faee20e6ca1eb08e5e3bf801d0"},"cell_type":"code","source":"# Confirm changes\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de124012c74d882a8c04b827b59145a389c10cdc"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"f003c26eaf38da4f77a77cf7f36beeb2665eedf9"},"cell_type":"markdown","source":"### 4. Pre-processing data : new features\nPickup_date and dropoff_date contain unit information that we can extract individually to get new features that would help us to vizualize the data set. "},{"metadata":{"trusted":true,"_uuid":"6cca21a937a6bbba0eb528ba10a6ecc5f911487e"},"cell_type":"code","source":"# Decomposing pickup_datetime variable into date and time\ntrain['pickup_date'] = train['pickup_datetime'].dt.date # Extract date\ntrain['pickup_time'] = train['pickup_datetime'].dt.time # Extract time\n\n# Decomposing dropoff_datetime variable into date and time \ntrain['dropoff_date'] = train['dropoff_datetime'].dt.date # Extract date\ntrain['dropoff_time'] = train['dropoff_datetime'].dt.time # Extract time\n\n\n\n# Additional pickup features\ntrain['pickup_month'] = train['pickup_datetime'].dt.month # Extract month\n\ntrain['pickup_hour'] = train['pickup_datetime'].dt.hour # Extract hour\n\ntrain['pickup_weekday'] = train['pickup_datetime'].dt.dayofweek # Extract day of week","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e9fa514985c744f85a1eb7125358cfdabbb03fb"},"cell_type":"code","source":"# Drop concatentated timestamp columns\ntrain.drop(['pickup_datetime'], axis = 1, inplace = True)\ntrain.drop(['dropoff_datetime'], axis = 1, inplace = True)\n\n# Confirm removal\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2ce1e39bace28bf516713f853fc9e676293d571"},"cell_type":"code","source":"# Differences between dropoff and pickup geocardiante helps to calculate distance covered during a trips\n\ntrain['dist_long'] = train['pickup_longitude'] - train['dropoff_longitude']\n#test['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\n\ntrain['dist_lat'] = train['pickup_latitude'] - train['dropoff_latitude']\n#test['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\n\n# Distance covered\ntrain['dist'] = np.sqrt(np.square(train['dist_long']) + np.square(train['dist_lat']))\n#test['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58eef9dbbd930934109d152210702b57305e5d5f"},"cell_type":"markdown","source":"\n    "},{"metadata":{"_uuid":"2f46ffa1ad50a8752f099138f2ec742349eec6d2"},"cell_type":"markdown","source":"# **IV. Exploratory Data Analysis (Visualization)**"},{"metadata":{"_uuid":"5c003d83fd709ffa3f58dc584754a190c28cf5cd"},"cell_type":"markdown","source":"## 1.Target Variable: trip_duration"},{"metadata":{"trusted":true,"_uuid":"63949e21bf323ae92c530303255401776f089052"},"cell_type":"code","source":"# Mean distribution\nmu = train['trip_duration'].mean()\n\n# Std distribution\nsigma = train['trip_duration'].std()\nnum_bins = 100\n\n# Histogram \nfig = plt.figure(figsize=(8.5, 5))\nn, bins, patches = plt.hist(train['trip_duration'], num_bins, normed=1,\n                           edgecolor = 'black', lw = 1, alpha = .40)\n# Normal Distribution\ny = mlab.normpdf(bins, mu, sigma)\nplt.plot(bins, y, 'r--', linewidth=2)\nplt.xlabel('trip_duration')\nplt.ylabel('Probability density')\n\n# Adding a title\nplt.title(r'$\\mathrm{Trip\\ duration\\ skewed \\ to \\ the \\ right:}\\ \\mu=%.3f,\\ \\sigma=%.3f$'%(mu,sigma))\nplt.grid(True)\n#fig.tight_layout()\nplt.show();\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57d434341d7223fe9a0a7229a047356a26b8afda"},"cell_type":"markdown","source":"## 2.Passenger count per trip duration"},{"metadata":{"trusted":true,"_uuid":"528f28ece9665ff0c64a09befee3fa1de3d94645"},"cell_type":"code","source":"\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\n\n# Create boxplot\nplt.figure(figsize=(8.5,5))\npassenger_graph = sns.boxplot(x = 'passenger_count', y = 'trip_duration', data = train, \n                          palette = 'gist_rainbow', linewidth = 2.3)\n\n# Customize tick size\npassenger_graph.tick_params(axis = 'both', which = 'major', labelsize = 12)\n\n\n# Customize tick labels of the y-axis\npassenger_graph.set_yticklabels(labels = [-10, '0  ', '2000  ', '4000  ', '6000  ', '8000  ', '10000  ','12000 s'])\n\n\n# Bolding horizontal line at y = 0\npassenger_graph.axhline(y = 0, color = 'black', linewidth = 1.3, alpha = .70)\n\n\n# # Adding a title and a subtitle\npassenger_graph.text(x =-1.05, y = 13800, s = \"Passenger count does not have much effect on trip duration\",\n               fontsize =15 , weight = 'bold', alpha = .90)\npassenger_graph.text(x = -1.05, y = 13000.3, \n               s = 'Median trip times remain similar despite more passengers being aboard',\n              fontsize = 14, alpha = .85)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f59536a4a7a76223c6bbab7837c9dbcf19ce0dc"},"cell_type":"markdown","source":"## 3.Trip duration in a week"},{"metadata":{"trusted":true,"_uuid":"4bea37554d18e1519ee8be0d90c04b6f66f2964b"},"cell_type":"code","source":"# Trips by Hour and Day of Week\ntrip_duration_median = train['trip_duration'].median()\nplt.figure(figsize=(8.5,5))\n\npickup_hourday = train.groupby(['pickup_hour','pickup_weekday'])['trip_duration'].median().unstack()\nhourday_graph = sns.heatmap(pickup_hourday[pickup_hourday>trip_duration_median], lw = .5, annot = True, cmap = 'GnBu', fmt = 'g',annot_kws = {\"size\":10} )\n\n\n# Customize tick labels of the y-axis\nhourday_graph.set_xticklabels(labels = ['Mon', 'Tue', 'Wed','Thu','Fri','Sat','Sun'])\n\n\n# Remove the label of the x-axis\nhourday_graph.xaxis.label.set_visible(False)\n\n# # Adding a title and a subtitle\nhourday_graph.text(x =-.8, y = 27, s = \"Trip durations vary greatly depending on day of week\",\n               fontsize =20 , weight = 'bold', alpha = .90)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2746afac2a62aa8854b4c0fc009da24a6b14fd01"},"cell_type":"markdown","source":"Trips tend much longer than the median trip_duration of 655 seconds during the following parts of the week:\n\n* **Monday** - Thursday Office Hours: 8:00 am - 6:00 pm\n* **Thursday**, **Friday, Saturday Nights**: 6:00 pm - midnight\n* **Early Saturday** & **Sunday Mornings**: 12:00 am - 1:00 am\n* **Sunday Afternoons**: 2:00 pm and 4:00 pm"},{"metadata":{"_uuid":"9160a916a0556ddf12544453092564f8430e136c"},"cell_type":"markdown","source":"## 4.Trip Duration by Month"},{"metadata":{"trusted":true,"_uuid":"353f23fa7c56ce42847bbc672b1455ed6459166e"},"cell_type":"code","source":"# Box plot of pickups by month\nimport matplotlib\nmatplotlib.style.use('fivethirtyeight')\n\n# Create boxplot\nplt.figure(figsize=(8.5,5))\nmonth_graph = sns.boxplot(x = 'pickup_month', y = 'trip_duration', data = train, palette = 'gist_rainbow', linewidth = 2.3)\n\n# Remove the label of the x-axis\nmonth_graph.xaxis.label.set_visible(False)\nmonth_graph.yaxis.label.set_visible(False)\n\nmonth_graph.text(x =-1.05, y = 13800, s = \"Month of transaction has minimal effect on trip duration\",\n               fontsize =20 , weight = 'bold', alpha = .90)\nmonth_graph.text(x = -1.05, y = 13000.3, \n               s = 'Median trip times hover around ~650 seconds throughout the year',\n              fontsize = 14, alpha = .85)\nplt.show()\n\n\n# Statistical summary\ntrain.groupby('pickup_month')['trip_duration'].describe().transpose()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c06d299c822843b0466449ea3af55b9cf1d9872f"},"cell_type":"markdown","source":"June has the highest median trip_duration overall, but only slightly. Median trip times seem to hover around the 10-12 minute mark and do not vary much from month-to-month. This may be an indication that this month feature will not be helpful in predicting our target variable, trip_duration. \n"},{"metadata":{"trusted":true,"_uuid":"2e5ed9e78a8648799f7b22d1656aaea0d37e07bf"},"cell_type":"code","source":"# Correlations to trip_duration\ncorr = train.select_dtypes(include = ['float64', 'int64']).iloc[:, 1:].corr()\ncor_dict = corr['trip_duration'].to_dict()\ndel cor_dict['trip_duration']\nprint(\"List the numerical features in decending order by their correlation with trip_duration:\\n\")\nfor ele in sorted(cor_dict.items(), key = lambda x: -abs(x[1])):\n    print(\"{0}: {1}\".format(*ele))\n    \n# Correlation matrix heatmap\ncorrmat = train.corr()\nplt.figure(figsize=(12, 7))\n\n# Number of variables for heatmap\nk = 76\ncols = corrmat.nlargest(k, 'trip_duration')['trip_duration'].index\ncm = np.corrcoef(train[cols].values.T)\n\n# Generate mask for upper triangle\nmask = np.zeros_like(cm, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nsns.set(font_scale=1)\nsns.heatmap(cm, mask=mask, cbar=True, annot=True, square=True,\\\n                 fmt='.2f',annot_kws={'size': 12}, yticklabels=cols.values,\\\n                 xticklabels=cols.values, cmap = 'coolwarm',lw = .1)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bce54347dbcf1d35c31926abeaf8f73c7a8c0388"},"cell_type":"markdown","source":"There is quite a good correlation between distance and trip duration(our target). "},{"metadata":{"_uuid":"f6e659e3c73afcc7053d9dfd494b10f6906f6b43"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"867519e71f20abbc64bf2da85b68389a7569e49d"},"cell_type":"markdown","source":"# **V. Algorithme**"},{"metadata":{"_uuid":"a46c20fdc22def9c84604c61c41d7c1e936b31ba"},"cell_type":"markdown","source":"## 1.Droping unnecessary features and incoding store_and_fwd_flag\nWe need to convert store_and_fwd_flag to numeric so as to get it into a ready to use in our model."},{"metadata":{"trusted":true,"_uuid":"d2c9659fa9ae5eb0958c47166bb19ce2607d162b"},"cell_type":"code","source":"# Encoding Categoric data (converting 'store_and_fwd_flag' to numeric)\ntrain['store_and_fwd_flag'] = train['store_and_fwd_flag'].map({'N':0,'Y':1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbb81c7d036704bea818b4ccd57023d811d4529e"},"cell_type":"code","source":"train.drop(columns=['pickup_date','pickup_time','dropoff_date', 'dropoff_time', 'dist_long', 'dist_lat'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2988f0072461c963536a9ca918cf594e2e9c568f"},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3216fb8a9507e599e23cc690431d6de051e47911"},"cell_type":"markdown","source":"## 2. Feature Enginering"},{"metadata":{"trusted":true,"_uuid":"f7ff56765dcf26eda11793fadd63289d27ff5c3c"},"cell_type":"code","source":"X = train[['vendor_id', 'passenger_count', 'pickup_longitude',\n       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n       'store_and_fwd_flag','pickup_month', 'pickup_hour',\n       'pickup_weekday', 'dist']]\n\n# Target\ny = train['trip_duration']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65c90abb3675c604c7b1ceced64e4d781f845231"},"cell_type":"markdown","source":"##     3. Train/valid spliting"},{"metadata":{"trusted":true,"_uuid":"9186ffe45ab55fe72e9b47de8a7e0c79f6c4b065"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size = 0.2, random_state = 0)\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6d713a0f59c178398e5e55a7411e87f49d26699"},"cell_type":"markdown","source":"## 3.Model  selection 1 :  (Linear Regression)"},{"metadata":{"trusted":true,"_uuid":"3e70bda332c54162f95206646089a6fd66429b68"},"cell_type":"code","source":"#instantiate model\nlr = LinearRegression()\n\n# Fit to training data\nlr = lr.fit(X_train,y_train);\n\n#Predict\ny_pred_lr = lr.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d606cce095a00eccfd1e10bb952c97e78d8acd99"},"cell_type":"code","source":"#cross_validation_score\ncvs_lr = np.sqrt(\n    -cross_val_score(lr, X_train, y_train, cv=5, scoring='neg_mean_squared_error'))\nprint(cvs_lr)\n\nmean_cvs_lr = np.mean(cvs_lr)\nprint(mean_cvs_lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c538e42aff5f34bf1abe4851f4fb097b07bd93b"},"cell_type":"code","source":"# Score It\nfrom sklearn import metrics\nprint('\\nRandom Forest Regression Performance Metrics')\nprint('R^2 =',metrics.explained_variance_score(y_val,y_pred_lr))\nprint('MAE',metrics.mean_absolute_error(y_val, y_pred_lr))\nprint('MSE',metrics.mean_squared_error(y_val, y_pred_lr))\nprint('RMSE',np.sqrt(metrics.mean_squared_error(y_val, y_pred_lr)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7184772b90b77f7394a6847b2baca5b71ba909df"},"cell_type":"markdown","source":"R2 (R squared) is the proportion of the variance in the dependent variable that is predictable from the independent variable.The better the linear regression fits the data in comparison to the simple average, the closer the value of R^2 is to 1.\nIn this case, R only 60% of the variation in the dependent variable is explained by this model. Such a score is an indication that the relationship between the features and independent variable is average. May be this score can be improuve with a non-linear model. "},{"metadata":{"_uuid":"322a34f488c9536b891b32e2cac0241b4e325c03"},"cell_type":"markdown","source":"## 4.Model selection 2 : RandomForest "},{"metadata":{"trusted":true,"_uuid":"664e5b35015d30e1c0a8bc91dc57ad17375a671d"},"cell_type":"code","source":"#model selection \nfrom sklearn.ensemble import RandomForestRegressor\n\n# Intantiate model \nrf = RandomForestRegressor(n_estimators = 20, n_jobs = -1)\n\n#fit\nrf = rf.fit(X_train, y_train)\n\n#Predict\ny_pred_rf = rf.predict(X_val)\n\n# crosse validation\ncvs_rf = cross_val_score(rf, X_train, y_train, cv=5)\nprint(cvs_rf)\n\nmean_cvs_rf = np.mean(cvs_rf)\nprint(mean_cvs_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf867dc614c13a8e6e32f8e56cd2ae490c14f7c5"},"cell_type":"code","source":"from sklearn import metrics\nprint('\\nRandom Foresst Performance Metrics')\nprint('R^2=',metrics.explained_variance_score(y_val,y_pred_rf))\nprint('MAE:',metrics.mean_absolute_error(y_val,y_pred_rf))\nprint('MSE:',metrics.mean_squared_error(y_val,y_pred_rf))\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_val,y_pred_rf)))\nprint('RMSLE:',np.sqrt(metrics.mean_squared_log_error(y_val, y_pred_rf)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e98aa784497e5ce6eb532ca5c64890adea1d9ed"},"cell_type":"markdown","source":"\n\nBase on comparaison of performance metrics of the both model, we decide to use the Random Forest type to make our submission as following. "},{"metadata":{"_uuid":"59b27ac156c57af7cbbf4a4ad5937332d80bcb70"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8dbac325a18deece2403fc31de46968e157cbf37"},"cell_type":"markdown","source":"#  **VI. Submission**"},{"metadata":{"_uuid":"ac374bd14b4134a083e5e9a5df4fc88b7695dc57"},"cell_type":"markdown","source":"    In order to submit we need to reshape test data like we did on train data set, so that our model(Random Forest) can be use to predict. "},{"metadata":{"_uuid":"c7bb5efe120bb7783468499a37332e0ee3a09c1c"},"cell_type":"markdown","source":"## 1. Preprocessing Test data set "},{"metadata":{"trusted":true,"_uuid":"c26256c282a4c6daaa9095bf5d2c7bc6ced733f2"},"cell_type":"code","source":"# Test data info\ntest.info()\n\n# Test data shape\nprint('shape',test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfaa5eb37ba8a085a98b0ebb05081253a547f2f6"},"cell_type":"code","source":"# Convert timestamps to date objects\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime) # Pickups\n\n# Delimit pickup_datetime variable \ntest['pickup_date'] = test['pickup_datetime'].dt.date # Extract date\ntest['pickup_time'] = test['pickup_datetime'].dt.time # Extract time\n\n# Additional pickup features\ntest['pickup_month'] = test['pickup_datetime'].dt.month # Extract month\n\n#train_data['pickup_YYYYMM'] = train_data['pickup_datetime'].apply(lambda x: x.strftime('%Y%m')) # Extract yearmonth\ntest['pickup_hour'] = test['pickup_datetime'].dt.hour # Extract hour\ntest['pickup_weekday'] = test['pickup_datetime'].dt.dayofweek # Extract day of week\n\n# Encode categorical variables\ntest['store_and_fwd_flag'] = test['store_and_fwd_flag'].map({'N':0,'Y':1})\n\n\n# Differences between dropoff and pickup geocardiante helps to calculate distance covered during a trips\ntest['dist_long'] = test['pickup_longitude'] - test['dropoff_longitude']\ntest['dist_lat'] = test['pickup_latitude'] - test['dropoff_latitude']\n\n# Distance covered\ntest['dist'] = np.sqrt(np.square(test['dist_long']) + np.square(test['dist_lat']))\n\n#drop useless colomns\ntest.drop(columns=['pickup_datetime', 'pickup_date', 'dist_long', 'dist_lat'], axis = 1, inplace = True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f5cd07f6f12bec38603bf63667710c46eea382b"},"cell_type":"code","source":"# Create new matrix of features from test data\nX_test= test[['vendor_id', 'passenger_count', 'pickup_longitude',\n       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n       'store_and_fwd_flag','pickup_month', 'pickup_hour',\n       'pickup_weekday', 'dist']]\n\n# Feed features into random forest\ntest_pred= rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1795dba997b66c539b5f20c5f09a4cdbea9341a8"},"cell_type":"code","source":"submission = pd.DataFrame({'id':test['id'], 'trip_duration': test_pred})\nsubmission.to_csv('mySubmission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"350af9e04b321895c6edf7cdeb47eb30e54b8506"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}