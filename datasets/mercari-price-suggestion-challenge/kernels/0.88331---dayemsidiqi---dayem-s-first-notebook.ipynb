{"cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "df = pd.read_csv(\"..//input//train.tsv\", sep=\"\\t\")\n", "df_test = pd.read_csv(\"..//input//test.tsv\", sep=\"\\t\")\n", "df_sample = pd.read_csv(\"..//input//sample_submission.csv\", sep=\",\")\n", "# Any results you write to the current directory are saved as output.\n", "\n", "df.head()\n"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e8eb34d356556ca10c4befcdacc148b45f59d61d", "_cell_guid": "d3831f1f-5ef1-4de4-871c-c4d63550a06c"}}, {"source": ["df['main_category'], df['sub_category'], df['nested_category'] = df['category_name'].str.split('/', 2).str\n", "df_test['main_category'], df_test['sub_category'], df_test['nested_category'] = df_test['category_name'].str.split('/', 2).str\n", "df.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "25d5d79105057f4da453b06ab255a4b10f48a505", "_cell_guid": "e62e2477-1ac7-4ec4-995f-81d6de4c4968"}}, {"source": ["# Filtered Columns"], "cell_type": "markdown", "metadata": {"_uuid": "5b11d34583796ae4f44b77c5ef12514dc8359d60", "_cell_guid": "e4bd55f3-a0a7-40de-bbd4-4a3aacfedfee"}}, {"source": ["filtered = df[['price', 'item_condition_id', 'shipping', 'main_category', 'sub_category', 'nested_category', 'brand_name', 'name']]\n", "filtered_test = df_test[['test_id','item_condition_id', 'shipping', 'main_category', 'sub_category', 'nested_category', 'brand_name', 'name']]\n", "filtered.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "e5af00cc4d853e8f63d76c227aaaf6474f1be291", "_cell_guid": "b012b718-0afb-467a-96d9-8ed1f43c16b4"}}, {"source": ["# Database Preprocessing\n", "\n", "We will preprocess the data and covert it into lower case"], "cell_type": "markdown", "metadata": {"_uuid": "03f2071e4cf9bd24ec923992d06f14131afcd1c0", "_cell_guid": "a502db8e-3d1f-4fc3-b706-3d6c20e6a83d"}}, {"source": ["filtered = filtered.apply(lambda x: x.astype(str).str.lower())\n", "filtered_test = filtered_test.apply(lambda x: x.astype(str).str.lower())\n", "filtered.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "988e669d61af6a94eadbe51f8b61e1bfbd8cbc7c", "_cell_guid": "a22aab2a-81f4-4815-ae16-a7b5e40ae156"}}, {"source": ["# Sampling the dataset\n", "\n", "We will sample the dataset to get a subset of data. As the current data is too large for analysis, sampling a smaller subset will make our data processing much faster. We are sampling around 30% of our data"], "cell_type": "markdown", "metadata": {"_uuid": "d013261d32ce4cb9676d9ec78d340790d1e7fcea", "_cell_guid": "9f98ab93-c6a4-497b-8f01-5f2222ebd783"}}, {"source": ["# sampled = filtered.sample(frac=0.3)\n", "sampled = filtered\n", "sampled.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "f1500294a209a7f3ec8c0116b3400c4b3d4c565d", "_cell_guid": "22e5ad04-3068-4515-a441-529b31994bba"}}, {"source": ["# One Hot Encoding of Categorical Variables\n", "\n", "Now we are going to transform our categorical variables into one hot encoding so we can use it for regression analysis"], "cell_type": "markdown", "metadata": {"_uuid": "b71e9b49f130caab900c76aca353d4dca680a1e8", "_cell_guid": "4042ef1c-5ee3-486f-bf11-8d235ff2bea3"}}, {"source": ["encoded = pd.get_dummies(sampled, columns=['brand_name', 'main_category', 'sub_category', 'nested_category'])\n", "encoded.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "7770cc91bc37091a6cd967fbe0f357aa89fac57c", "_cell_guid": "bc35b893-5dd6-4d23-8233-b3be468ecb09", "collapsed": true}}, {"source": ["# Factorization\n", "\n", "After trying one hot encoding, I realized that there is an explosion of dimensions, so after doing some research I found out that factorization was another way to handle categorical variables. So lets factorize our data"], "cell_type": "markdown", "metadata": {"_uuid": "64fcc8e755079fa12dc6faa12d349fff561093e2", "_cell_guid": "b08372d0-8f91-46a5-9aa1-e5efae760263"}}, {"source": ["columns = ['main_category', 'brand_name', 'sub_category', 'nested_category', 'name']\n", "factorized = sampled[columns].apply(lambda x: pd.factorize(x)[0])\n", "factorized['price'] = sampled['price']\n", "factorized['shipping'] = sampled['shipping']\n", "factorized['item_condition_id'] = sampled['item_condition_id']\n", "\n", "\n", "factorized_test = filtered_test[columns].apply(lambda x: pd.factorize(x)[0])\n", "factorized_test['shipping'] = filtered_test['shipping']\n", "factorized_test['item_condition_id'] = filtered_test['item_condition_id']\n", "factorized_test['test_id'] = filtered_test['test_id']\n", "\n", "factorized = factorized.apply(lambda x: x.astype('category'))\n", "factorized_test = factorized_test.apply(lambda x: x.astype('category'))\n", "factorized['price'] = factorized['price'].apply(pd.to_numeric)\n", "factorized.head()\n", " "], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "83e50919e474d255a50bbf13a3f3856f5d899056", "_cell_guid": "cfa93004-09df-4f39-81b5-889c7e17dc78", "collapsed": true}}, {"source": ["# Splitting the data\n", "\n", "Now we are going to split the data into training and testing"], "cell_type": "markdown", "metadata": {"_uuid": "4c5203a599227cc1351e4e48fe5ce290efb8909a", "_cell_guid": "4cee3bfe-e903-405d-93c6-c2a744804b65"}}, {"source": ["#Spliting the sampled data into training and testing\n", "factorized['is_train'] = np.random.uniform(0, 1, len(factorized)) <= .75\n", "# Create two new dataframes, one with the training rows, one with the test rows\n", "train, test = factorized[factorized['is_train']==True], factorized[factorized['is_train']==False]\n", "\n", "# Show the number of observations for the test and training dataframes\n", "print('Number of observations in the training data:', len(train))\n", "print('Number of observations in the test data:',len(test))"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "88567ea9c250752f53e04e5c917d6dba0abc99ad", "_cell_guid": "c520ccdb-e1e7-4e24-9174-95c39497bd65", "collapsed": true}}, {"source": ["from sklearn.ensemble import RandomForestRegressor\n", "from sklearn import linear_model\n", "\n", "# regr = linear_model.Ridge (alpha = .9)\n", "# regr = linear_model.LinearRegression()\n", "regr = RandomForestRegressor(max_depth=30, random_state=0)\n", "collist = train.columns.tolist()\n", "collist.remove('price')\n", "collist.remove('is_train')\n", "# collist\n", "regr.fit(train[collist], train['price'])\n"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "60b768a946d5f9ac2b651f78e72611a841677c98", "_cell_guid": "b5d582f9-8dca-41c4-908f-9deb1cad8681", "collapsed": true}}, {"source": ["import math\n", "from decimal import Decimal\n", "def rmsle(y_pred, y):\n", "    assert len(y) == len(y_pred)\n", "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n", "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "29dd0f90fce0a8b3f45f3abbb3b23866a79df549", "_cell_guid": "72c93671-9bb5-478d-8ca7-6cca8e6cbbe9", "collapsed": true}}, {"source": ["# regr.score(test[collist], test['price'], sample_weight=None)\n", "from sklearn.metrics import mean_squared_log_error\n", "\n", "\n", "\n", "# mean_squared_log_error(test['price'], regr.predict(test[collist]))  \n", "print(rmsle(list(regr.predict(test[collist])), list(test['price'])))\n", "# factorized_test['price'] = regr.predict(factorized_test[collist])\n", "# submission = factorized_test[['test_id', 'price']]\n", "# submission.to_csv('final.csv', index=False)\n", "# submission\n", "\n", "\n", "# test.head()"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_uuid": "95ee1c4c9c5df182f142d4d76dfb6ba014f04f91", "_cell_guid": "b456b333-4ec8-436e-8aa1-d997b9fa01b0", "collapsed": true}}, {"source": ["import math\n", "from decimal import Decimal\n", "from keras import backend as K\n", "\n", "def rmsle_k(y_pred, y):\n", "#     assert len(y) == len(y_pred)\n", "    to_sum = [(K.log(y_pred[i] + 1) - K.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n", "    return (K.sum(to_sum) * (1.0/len(y))) ** 0.5"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}}, {"source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Dropout\n", "from keras.callbacks import EarlyStopping\n", "early_stopping = EarlyStopping(monitor='val_loss', patience=4, mode='auto')\n", "\n", "# train = (train - train.mean()) / (train.max() - train.min())\n", "# test = (test - test.mean()) / (test.max() - test.min())\n", "\n", "model = Sequential()\n", "model.add(Dense(units=64, activation='relu', input_dim=len(collist)))\n", "model.add(Dense(units=64, activation='relu'))\n", "model.add(Dense(units=64, activation='relu'))\n", "model.add(Dense(units=64, activation='relu'))\n", "model.add(Dense(units=64, activation='relu'))\n", "model.add(Dense(activation='relu', output_dim=1))\n", "\n", "model.compile(optimizer='rmsprop',loss='mean_squared_logarithmic_error')\n", "# model.fit(train[collist], train['price'],epochs=10, batch_size=128)\n", "# print(rmsle(list(model.predict(test[collist])), list(test['price'])))\n"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}}, {"source": ["df['item_description']"], "execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python"}}}