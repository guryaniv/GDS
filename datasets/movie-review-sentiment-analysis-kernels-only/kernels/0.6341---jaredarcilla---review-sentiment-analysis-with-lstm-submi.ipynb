{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.tsv', sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057d2c9dc71950f4db1e55e701baff0156f2560e"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"104c94ea7aec728a3607d8cd8997674ff3527184"},"cell_type":"code","source":"from keras.preprocessing import text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a20efe312cad14545cb60be6d49d66406283b743","collapsed":true},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\n\ntokenizer = text.Tokenizer(filters='')\ntokenizer.fit_on_texts(train_df.iloc[:,2])\n\nseq = tokenizer.texts_to_sequences(train_df.iloc[:,2])\n\nword_ind = tokenizer.word_index\nX = pad_sequences(seq, maxlen=50, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed126adf1fa63b80ff3e7eb33adf2371c90c3987"},"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, train_df.iloc[:,3], train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c27b313d7e8a6fdf09261266b46210bcc8f4d5a5","collapsed":true},"cell_type":"code","source":"from keras.layers import Embedding, Convolution1D, MaxPooling1D, Flatten, LeakyReLU, Dense, BatchNormalization\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD, rmsprop, adam\nfrom keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"426c2bc704cc07d7f3ad5c1429a11b2eef8236b3","collapsed":true},"cell_type":"code","source":"from keras.layers import CuDNNLSTM","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bff8d108a3f2f113d76df1b3b5b4afae296a402b","scrolled":false},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(len(word_ind) + 1, 300,\n                    input_length=50))\nmodel.add(CuDNNLSTM(300, return_sequences=True))\nmodel.add(CuDNNLSTM(300, return_sequences=True))\nmodel.add(Flatten())\nmodel.add(Dense(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da742812aea4eaccac3eca835e21cfb02376688d","collapsed":true},"cell_type":"code","source":"#65.22% !!\nsgd = SGD(nesterov=True)\nrms = rmsprop()\nmodel.compile(rms, loss='mse', metrics=['accuracy'])\nes = EarlyStopping(patience=2, monitor='val_acc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c74b1e09163402c25b2b55122dd03abc1320ff3","scrolled":false},"cell_type":"code","source":"model.fit(X_train, np.array(y_train), batch_size=32, epochs=50,\n          validation_split=0.25, callbacks=[es])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7837a62a51f430d6dabdc97c2357b7098f8672b1"},"cell_type":"code","source":"model.evaluate(X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddb23cf573c483e13e19181bfb1349504ddbd16c","collapsed":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.tsv', sep='\\t')\nsample = pd.read_csv('../input/sampleSubmission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad827d76ef7e210e41039adf1d33d4106d6bc4a3","collapsed":true},"cell_type":"code","source":"test_seq = tokenizer.texts_to_sequences(test_data.iloc[:,2])\ntest_seq = pad_sequences(test_seq, maxlen=50, padding='post')\n\npred = np.round(model.predict(test_seq))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6144445380c4369777c218de879122d7408f3b48","collapsed":true},"cell_type":"code","source":"def ranged_five(x):\n    if x > 4:\n        return 4\n    elif x < 0:\n        return 0\n    else:\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7079069f9d3520aa453c74a946a35097ef9ecdea","collapsed":true},"cell_type":"code","source":"vranged_five = np.vectorize(ranged_five)\npred = (vranged_five(pred))\npred = np.reshape(pred, pred.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9d087611cbb4a2d9854b93e816825dfdbc5929ad"},"cell_type":"code","source":"sample.iloc[:,1] = pred.astype(np.int64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1aafeb81386b055ee46b99017d34a16e175af79","collapsed":true},"cell_type":"code","source":"sample.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5abb2a7b2517ca65e741888ff642c277b2d28d8c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}