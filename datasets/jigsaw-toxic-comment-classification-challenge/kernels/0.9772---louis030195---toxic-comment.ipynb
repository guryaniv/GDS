{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Deep learning\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten, Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Input\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\nfrom sklearn.model_selection import train_test_split\nimport re\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3f469070aa1477c893ec0339e3505769891d8b00"},"cell_type":"code","source":"comp = 'jigsaw-toxic-comment-classification-challenge/'\nEMBEDDING_FILE='../input/glove-global-vectors-for-word-representation/glove.6B.50d.txt'\nembed_size = 50 # how big is each word vector\nmax_features = 25000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 100 # max number of words in a comment to use","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ntest = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a9043598fe8dd149aa1648ad57be05bc088578a","collapsed":true},"cell_type":"code","source":"print(\"Shapes of the datasets \", train.shape, test.shape)\nprint(train.info())\nprint(train.sample()['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d315e7e638e21d3a32f94e74dcb19c5d8cdab440","collapsed":true},"cell_type":"code","source":"train['comment_text'] = train['comment_text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\ntokenizer = Tokenizer(num_words=max_features, lower=True,split=' ')\ntokenizer.fit_on_texts(train['comment_text'].values)\nX = tokenizer.texts_to_sequences(train['comment_text'].values)\nX_result = tokenizer.texts_to_sequences(test['comment_text'].values)\nX = pad_sequences(X, maxlen=maxlen)\nX_result = pad_sequences(X_result, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b99fa6d526bcd6e5dfd3b70ca0e806bd6d5a301","collapsed":true},"cell_type":"code","source":"print(X[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fd2e2d12f281420e6a84b771586daa67debd012","collapsed":true},"cell_type":"code","source":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab80b2262052fdf6c0b3a1c03ecc7c7012345743","collapsed":true},"cell_type":"code","source":"all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nemb_mean,emb_std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bec72a80b8984a48095b3e6400a20b193274035c","collapsed":true},"cell_type":"code","source":"word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, 50))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3ce0c2dbf4f52f2068a720153bb3d7021063312","collapsed":true},"cell_type":"code","source":"Y = pd.get_dummies(train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]).values\nprint(Y[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a1889d6a5e3717fe5b093e0dd177bd5df45c6d3","collapsed":true},"cell_type":"code","source":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\nx = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67cf5fa2f1d9103d6595c9422eeb45cf8e990a39","collapsed":true},"cell_type":"code","source":"model.fit(X, Y, batch_size=32, epochs=2, validation_split=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eea59d065ddf40e3dc548d14eba324a8f9d4dfae","collapsed":true},"cell_type":"code","source":"y_test = model.predict([X_result], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2836bb45667658dc22d131c39753142452a7123","collapsed":true},"cell_type":"code","source":"y_test[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4df69b010acfe9b3900d37e2f00ac62e6f45dc","collapsed":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\nsample_submission[['toxic','severe_toxic','obscene','threat','insult','identity_hate']] = y_test\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}