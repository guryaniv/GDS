{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pwd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6eae7099da04f2c655c1f972109b971e0593a534"},"cell_type":"code","source":"os.chdir('..')\nos.listdir()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bb3cdbb4752d698b24a7f8d1c38e9702ba91e8d"},"cell_type":"code","source":"import os, shutil\n\noriginal_dataset_dir = 'input/train'\n\nbase_dir = 'cats_and_dogs_small'\nos.mkdir(base_dir)\n\ntrain_dir = os.path.join(base_dir, 'train')\nos.mkdir(train_dir)\nvalidation_dir = os.path.join(base_dir, 'validation')\nos.mkdir(validation_dir)\ntest_dir = os.path.join(base_dir, 'test')\nos.mkdir(test_dir)\n\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.mkdir(train_cats_dir)\n\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.mkdir(train_dogs_dir)\n\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nos.mkdir(validation_cats_dir)\n\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.mkdir(validation_dogs_dir)\n\ntest_cats_dir = os.path.join(test_dir, 'cats')\nos.mkdir(test_cats_dir)\n\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nos.mkdir(test_dogs_dir)\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir,  fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_dataset_dir, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"455abb80afbf5d66fade47a2792b6125fabff85d"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n                            rotation_range=40,\n                            width_shift_range=0.2,\n                            height_shift_range=0.2,\n                            shear_range=0.2,\n                            zoom_range=0.2,\n                            horizontal_flip=True,\n                            fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52b173092cae6bf2bf8d06a925badc2c92359b0e"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom keras.preprocessing import image\n\nfnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n\nimg_path = fnames[500]\n\nimg = image.load_img(img_path, target_size = (150, 150))\n\nx = image.img_to_array(img)\n\nx = x.reshape((1,) + x.shape)\n\ni = 0\nfor batch in datagen.flow(x, batch_size = 1):\n    plt.figure()\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0:\n        break\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbf78025da40fa7b7fe4b7d50251f7c33b8e2cd5"},"cell_type":"code","source":"from keras import layers\nfrom keras import models\nfrom keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Conv2D(128, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(512, activation = 'relu'))\nmodel.add(layers.Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer=optimizers.RMSprop(lr=1e-4),\n             metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f1ea9cf5925f93708847ee245479c808bb34ff1"},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n                rescale = 1./255,\n                rotation_range=40,\n                width_shift_range=0.2,\n                height_shift_range=0.2,\n                shear_range=0.2,\n                zoom_range=0.2,\n                horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n                                train_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n                                validation_dir,\n                                target_size = (150, 150),\n                                batch_size = 32,\n                                class_mode = 'binary')\n\nhistory = model.fit_generator(\n                            train_generator,\n                            steps_per_epoch = 100,\n                            epochs = 100,\n                            validation_data = validation_generator,\n                            validation_steps = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f0886d8213b293d798587bc723d2bb1900c8314"},"cell_type":"code","source":"model.save('cats_and_dogs_small_2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ee2e3b5d7e148e477c0840b6862f91a91637d25"},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('cats_and_dogs_small_2.h5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f35c36aed243c006f040fb17c38830f1d9402dd8"},"cell_type":"markdown","source":"### Preprocessing a single image"},{"metadata":{"trusted":true,"_uuid":"a94672f1b27ddeaec520930a91fa03f957db806c"},"cell_type":"code","source":"img_path = 'cats_and_dogs_small/test/cats/cat.1700.jpg'\n\nfrom keras.preprocessing import image\nimport numpy as np\n\nimg = image.load_img(img_path, target_size=(150, 150))\nimg_tensor = image.img_to_array(img)\nimg_tensor = np.expand_dims(img_tensor, axis = 0)\nimg_tensor /= 255.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd31b16d99831494ce87ed4b6369050af430b640"},"cell_type":"markdown","source":"### Displaying the test picture"},{"metadata":{"trusted":true,"_uuid":"bf08bc6a8ff7520eb4c14168d498c35b94c60acc"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.imshow(img_tensor[0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7943e2f230f45c9bf37c5ff7b14db800ef564e47"},"cell_type":"markdown","source":"### Instantiating a model from an input tensor and a list of output tensors"},{"metadata":{"trusted":true,"_uuid":"87a5513d05a3a7707280a0610056eca09781d25e"},"cell_type":"code","source":"from keras import models\n\nlayer_outputs = [layer.output for layer in model.layers[:8]]\nactivation_model = models.Model(inputs=model.input, outputs=layer_outputs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f9d6e66a10b6dc8ede9b60e662a5b151383240b"},"cell_type":"markdown","source":"### Running the model in predict mode"},{"metadata":{"trusted":true,"_uuid":"2565f33cb94bad0f0458e2ee428474a89075ad95"},"cell_type":"code","source":"activations = activation_model.predict(img_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a04932d664376e0e5c7244a1c7dfca5f49032d9"},"cell_type":"code","source":"first_layer_activation = activations[0]\nprint(first_layer_activation.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8912ebfeddc780fa9bea139ced18f487d122c0cc"},"cell_type":"markdown","source":"### Visualizing the fourth channel"},{"metadata":{"trusted":true,"_uuid":"d8d36c090573f847619cf9686bd082afcafe4ae0"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.matshow(first_layer_activation[0, :, :, 31], cmap = 'viridis')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae29d8dea23b054941e786e3192399bd9416d4cf"},"cell_type":"markdown","source":"### Visualizing the seventh channel"},{"metadata":{"trusted":true,"_uuid":"6186f8dde912f92adf8f861568c5769a09561d6b"},"cell_type":"code","source":"plt.matshow(first_layer_activation[0, :, :, 6], cmap = 'viridis')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9877ee1fed940bd8bf0df3c91d2b26d97fefdfd0"},"cell_type":"markdown","source":"### Visualizing every channel in every intermediate activation"},{"metadata":{"trusted":true,"_uuid":"465e7a4471bb224b9a7bfb406f8983cabff961d6"},"cell_type":"code","source":"layer_names = []\nfor layer in model.layers[:8]:\n    layer_names.append(layer.name)\n    \nimages_per_row = 16\n\nfor layer_name, layer_activation in zip(layer_names, activations):\n    n_features = layer_activation.shape[-1]\n    \n    size = layer_activation.shape[1]\n    n_cols = n_features //images_per_row\n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    \n    for col in range(n_cols):\n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                            :, :,\n                                            col * images_per_row + row]\n            channel_image -= channel_image.mean()\n            channel_image /= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size,\n                        row * size: (row + 1) * size] = channel_image\n            \n    scale = 1./ size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                       scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c6410bd98e59498b12db481b0ed5d30906fa401"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}