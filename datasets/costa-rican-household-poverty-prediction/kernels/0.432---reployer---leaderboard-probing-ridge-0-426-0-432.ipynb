{"cells":[{"metadata":{"_uuid":"2e2484b9459453085438458a0aad3f8de713ce65"},"cell_type":"markdown","source":"# Introduction to Leaderboard Probing\n\nThis is a simple kernel to show how you can extract the hidden target distributions of the test set by making a few fake submissions and use this knowledge to your advantage. This type of leaderboard probing is specific to each competition and might not help you in every case.\n\nFor this competition, the evaluation metric is the macro F1 score, which is the unweighted average of each label's [F1 score](https://en.wikipedia.org/wiki/F1_score). This allows us to find out the percentage of each label in the test set by submitting a sample submission that predicts every test example to have that target.\n****"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true,"_uuid":"d72a79204ac9a338d6fb9844f757f7e65f3697ec"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import f1_score\nfrom scipy.stats import rankdata\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import Normalizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fd9d24ac5975567d2bdbee904435ca44f518a52"},"cell_type":"code","source":"df = pd.read_csv('../input/sample_submission.csv')\nfor i in np.arange(1,5):\n    df['Target'] = i\n    df.to_csv('sample_{}.csv'.format(i), index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f29f37ddc98952aa9d88dd3855a621f7c4805e91"},"cell_type":"markdown","source":"Submitting these files to the leaderboard will return you the following results\n* sample_1.csv - 0.031\n* sample_2.csv - 0.066\n* sample_3.csv - 0.061\n* sample_4.csv - 0.194\n\nIn order to find out the original distribution of labels, you can reverse engineer them using some simple math."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"lb_scores = [0.031, 0.066, 0.061,0.194]\ndist = lambda x: x/(0.5-x)\ntarget_dist = np.array([dist(x) for x in lb_scores])\nprint('Target distribution is',target_dist)\nprint('Total sum is', target_dist.sum())\ntarget_dist = target_dist/target_dist.sum()\nprint('Normalized target distribution is', target_dist)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"150c61ab0b0a5d16ade8d32c56161d0124f17821"},"cell_type":"markdown","source":"As you can see, the extracted distribution does not add up to 1 due to the leaderboard being rounded off. However, this level of precision is sufficient for us to utilise. Let's see how this is different from the distribution from the train set.\n\n"},{"metadata":{"trusted":true,"_uuid":"b8f4757976e3220e81d60ea17b90168f78c98c40","_kg_hide-input":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_scored = train_df.query('parentesco1 == 1')\ntrain_dist = train_scored['Target'].value_counts(normalize = True).tolist()\ntrain_dist = [train_dist[3],train_dist[1],train_dist[2],train_dist[0]]\nprint('Train distributions are', train_dist)\n\ndifference = target_dist - train_dist\nprint('The difference in the test and target distributions is', difference)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"376e8543036f372d3646d83ca9b80d31f9f9da14"},"cell_type":"markdown","source":"This isn't a major discrepency, but let's see how it can improve our scores. To demonstrate, I'll run a simple Ridge regression model on engineered features (taken from [Gaxx's impressive public kernel](https://www.kaggle.com/gaxxxx/exploratory-data-analysis-lightgbm))\n\nDue to the way Macro F1 score works, if we hypothetically only had completely random predictions, the maximal score would be obtained by matching the distribution of the prediction labels to the true target distribution. (Note that this is not the case for all evaluation metrics)  However, in this case, our predictions are not completely random, and we have massively uneven F1 scores for each label, so this might not hold true. "},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"42ce4572fd7c008085d6dfe241b5a05ddf700482"},"cell_type":"code","source":"train_set = pd.read_csv('../input/train.csv')\ntest_set = pd.read_csv('../input/test.csv')\n#outlier in test set which rez_esc is 99.0\ntest_set.loc[test_set['rez_esc'] == 99.0 , 'rez_esc'] = 5\n\n#Fill na\ndef repalce_v18q1(x):\n    if x['v18q'] == 0:\n        return x['v18q']\n    else:\n        return x['v18q1']\n\ntrain_set['v18q1'] = train_set.apply(lambda x : repalce_v18q1(x),axis=1)\ntest_set['v18q1'] = test_set.apply(lambda x : repalce_v18q1(x),axis=1)\n\ntrain_set['v2a1'] = train_set['v2a1'].fillna(value=train_set['tipovivi3'])\ntest_set['v2a1'] = test_set['v2a1'].fillna(value=test_set['tipovivi3'])\n\n#Replace yes/no\ncols = ['edjefe', 'edjefa', 'dependency']\ntrain_set[cols] = train_set[cols].replace({'no': 0, 'yes':1}).astype(float)\ntest_set[cols] = test_set[cols].replace({'no': 0, 'yes':1}).astype(float)\n\n#Feature Engineering\ntrain_set['roof_waste_material'] = np.nan\ntest_set['roof_waste_material'] = np.nan\ntrain_set['electricity_other'] = np.nan\ntest_set['electricity_other'] = np.nan\n\ndef fill_roof_exception(x):\n    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n        return 1\n    else:\n        return 0\n    \ndef fill_no_electricity(x):\n    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n        return 1\n    else:\n        return 0\n\ntrain_set['roof_waste_material'] = train_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntest_set['roof_waste_material'] = test_set.apply(lambda x : fill_roof_exception(x),axis=1)\ntrain_set['electricity_other'] = train_set.apply(lambda x : fill_no_electricity(x),axis=1)\ntest_set['electricity_other'] = test_set.apply(lambda x : fill_no_electricity(x),axis=1)\n\ndef owner_is_adult(x):\n    if x['age'] <= 18:\n        return 0\n    else:\n        return 1\n\ntrain_set['head_less_18'] = train_set.apply(lambda x : owner_is_adult(x),axis=1)\ntest_set['head_less_18'] = test_set.apply(lambda x : owner_is_adult(x),axis=1)\n\ntrain_set['adult'] = train_set['hogar_adul'] - train_set['hogar_mayor']\ntrain_set['dependency_count'] = train_set['hogar_nin'] + train_set['hogar_mayor']\ntrain_set['dependency'] = train_set['dependency_count'] / train_set['adult']\ntrain_set['child_percent'] = train_set['hogar_nin']/train_set['hogar_total']\ntrain_set['elder_percent'] = train_set['hogar_mayor']/train_set['hogar_total']\ntrain_set['adult_percent'] = train_set['hogar_adul']/train_set['hogar_total']\ntest_set['adult'] = test_set['hogar_adul'] - test_set['hogar_mayor']\ntest_set['dependency_count'] = test_set['hogar_nin'] + test_set['hogar_mayor']\ntest_set['dependency'] = test_set['dependency_count'] / test_set['adult']\ntest_set['child_percent'] = test_set['hogar_nin']/test_set['hogar_total']\ntest_set['elder_percent'] = test_set['hogar_mayor']/test_set['hogar_total']\ntest_set['adult_percent'] = test_set['hogar_adul']/test_set['hogar_total']\n\ntrain_set['rent_per_adult'] = train_set['v2a1']/(train_set['hogar_adul']+0.1)\ntrain_set['rent_per_person'] = train_set['v2a1']/train_set['hhsize']\ntest_set['rent_per_adult'] = test_set['v2a1']/(test_set['hogar_adul']+0.1)\ntest_set['rent_per_person'] = test_set['v2a1']/test_set['hhsize']\n\ntrain_set['overcrowding_room_and_bedroom'] = (train_set['hacdor'] + train_set['hacapo'])/2\ntest_set['overcrowding_room_and_bedroom'] = (test_set['hacdor'] + test_set['hacapo'])/2\n\ntrain_set['no_appliances'] = train_set['refrig'] + train_set['computer'] + train_set['television']\ntest_set['no_appliances'] = test_set['refrig'] + test_set['computer'] + test_set['television']\n\ntrain_set['r4h1_percent_in_male'] = train_set['r4h1'] / train_set['r4h3']\ntrain_set['r4m1_percent_in_female'] = train_set['r4m1'] / train_set['r4m3']\ntrain_set['r4h1_percent_in_total'] = train_set['r4h1'] / train_set['hhsize']\ntrain_set['r4m1_percent_in_total'] = train_set['r4m1'] / train_set['hhsize']\ntrain_set['r4t1_percent_in_total'] = train_set['r4t1'] / train_set['hhsize']\ntest_set['r4h1_percent_in_male'] = test_set['r4h1'] / test_set['r4h3']\ntest_set['r4m1_percent_in_female'] = test_set['r4m1'] / test_set['r4m3']\ntest_set['r4h1_percent_in_total'] = test_set['r4h1'] / test_set['hhsize']\ntest_set['r4m1_percent_in_total'] = test_set['r4m1'] / test_set['hhsize']\ntest_set['r4t1_percent_in_total'] = test_set['r4t1'] / test_set['hhsize']\n\ntrain_set['rent_per_room'] = train_set['v2a1']/train_set['rooms']\ntrain_set['bedroom_per_room'] = train_set['bedrooms']/train_set['rooms']\ntrain_set['elder_per_room'] = train_set['hogar_mayor']/train_set['rooms']\ntrain_set['adults_per_room'] = train_set['adult']/train_set['rooms']\ntrain_set['child_per_room'] = train_set['hogar_nin']/train_set['rooms']\ntrain_set['male_per_room'] = train_set['r4h3']/train_set['rooms']\ntrain_set['female_per_room'] = train_set['r4m3']/train_set['rooms']\ntrain_set['room_per_person_household'] = train_set['hhsize']/train_set['rooms']\n\ntest_set['rent_per_room'] = test_set['v2a1']/test_set['rooms']\ntest_set['bedroom_per_room'] = test_set['bedrooms']/test_set['rooms']\ntest_set['elder_per_room'] = test_set['hogar_mayor']/test_set['rooms']\ntest_set['adults_per_room'] = test_set['adult']/test_set['rooms']\ntest_set['child_per_room'] = test_set['hogar_nin']/test_set['rooms']\ntest_set['male_per_room'] = test_set['r4h3']/test_set['rooms']\ntest_set['female_per_room'] = test_set['r4m3']/test_set['rooms']\ntest_set['room_per_person_household'] = test_set['hhsize']/test_set['rooms']\n\ntrain_set['rent_per_bedroom'] = train_set['v2a1']/train_set['bedrooms']\ntrain_set['edler_per_bedroom'] = train_set['hogar_mayor']/train_set['bedrooms']\ntrain_set['adults_per_bedroom'] = train_set['adult']/train_set['bedrooms']\ntrain_set['child_per_bedroom'] = train_set['hogar_nin']/train_set['bedrooms']\ntrain_set['male_per_bedroom'] = train_set['r4h3']/train_set['bedrooms']\ntrain_set['female_per_bedroom'] = train_set['r4m3']/train_set['bedrooms']\ntrain_set['bedrooms_per_person_household'] = train_set['hhsize']/train_set['bedrooms']\n\ntest_set['rent_per_bedroom'] = test_set['v2a1']/test_set['bedrooms']\ntest_set['edler_per_bedroom'] = test_set['hogar_mayor']/test_set['bedrooms']\ntest_set['adults_per_bedroom'] = test_set['adult']/test_set['bedrooms']\ntest_set['child_per_bedroom'] = test_set['hogar_nin']/test_set['bedrooms']\ntest_set['male_per_bedroom'] = test_set['r4h3']/test_set['bedrooms']\ntest_set['female_per_bedroom'] = test_set['r4m3']/test_set['bedrooms']\ntest_set['bedrooms_per_person_household'] = test_set['hhsize']/test_set['bedrooms']\n\ntrain_set['tablet_per_person_household'] = train_set['v18q1']/train_set['hhsize']\ntrain_set['phone_per_person_household'] = train_set['qmobilephone']/train_set['hhsize']\ntest_set['tablet_per_person_household'] = test_set['v18q1']/test_set['hhsize']\ntest_set['phone_per_person_household'] = test_set['qmobilephone']/test_set['hhsize']\n\ntrain_set['age_12_19'] = train_set['hogar_nin'] - train_set['r4t1']\ntest_set['age_12_19'] = test_set['hogar_nin'] - test_set['r4t1']    \n\ntrain_set['escolari_age'] = train_set['escolari']/train_set['age']\ntest_set['escolari_age'] = test_set['escolari']/test_set['age']\n\ntrain_set['rez_esc_escolari'] = train_set['rez_esc']/(train_set['escolari']+0.1)\ntrain_set['rez_esc_r4t1'] = train_set['rez_esc']/(train_set['r4t1']+0.1)\ntrain_set['rez_esc_r4t2'] = train_set['rez_esc']/train_set['r4t2']\ntrain_set['rez_esc_r4t3'] = train_set['rez_esc']/train_set['r4t3']\ntrain_set['rez_esc_age'] = train_set['rez_esc']/train_set['age']\ntest_set['rez_esc_escolari'] = test_set['rez_esc']/(test_set['escolari']+0.1)\ntest_set['rez_esc_r4t1'] = test_set['rez_esc']/(test_set['r4t1']+0.1)\ntest_set['rez_esc_r4t2'] = test_set['rez_esc']/test_set['r4t2']\ntest_set['rez_esc_r4t3'] = test_set['rez_esc']/test_set['r4t3']\ntest_set['rez_esc_age'] = test_set['rez_esc']/test_set['age']\n\ntrain_set['dependency'] = train_set['dependency'].replace({np.inf: 0})\ntest_set['dependency'] = test_set['dependency'].replace({np.inf: 0})\n\ndf_train = pd.DataFrame()\ndf_test = pd.DataFrame()\n\naggr_mean_list = ['rez_esc', 'dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco2',\n             'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', 'parentesco11', 'parentesco12',\n             'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',]\n\nother_list = ['escolari', 'age', 'escolari_age']\n\nfor item in aggr_mean_list:\n    group_train_mean = train_set[item].groupby(train_set['idhogar']).mean()\n    group_test_mean = test_set[item].groupby(test_set['idhogar']).mean()\n    new_col = item + '_aggr_mean'\n    df_train[new_col] = group_train_mean\n    df_test[new_col] = group_test_mean\n\nfor item in other_list:\n    for function in ['mean','std','min','max','sum']:\n        group_train = train_set[item].groupby(train_set['idhogar']).agg(function)\n        group_test = test_set[item].groupby(test_set['idhogar']).agg(function)\n        new_col = item + '_' + function\n        df_train[new_col] = group_train\n        df_test[new_col] = group_test\n        \ndf_test = df_test.reset_index()\ndf_train = df_train.reset_index()\n\ntrain_agg = pd.merge(train_set, df_train, on='idhogar')\ntest = pd.merge(test_set, df_test, on='idhogar')\n\n#fill all na as 0\ntrain_agg.fillna(value=0, inplace=True)\ntest.fillna(value=0, inplace=True)\n\ntrain = train_agg.query('parentesco1==1')\nsubmission = test[['Id']]\ntest = test.query('parentesco1==1')\n\npred_train_dist = test[['Id']]\npred_test_dist = test[['Id']]\n\ntrain.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\ntest.drop(columns=['idhogar','Id', 'tamhog', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n\nprint('Train shape:',train.shape)\nprint('Test shape:', test.shape)\n\ny = train['Target']\ntrain.drop(columns=['Target'], inplace=True)\n\nscaler = MinMaxScaler()\ntrain = scaler.fit_transform(train)\ntest = scaler.transform(test)\n\ndef classifyrank(data, cutoff):\n    data = rankdata(data)\n    length = data.size\n    clas = []\n    for j in data:\n        i = j/length\n        if i < cutoff[0]:\n            clas.append(1)\n        elif i < cutoff[0]+cutoff[1]:\n            clas.append(2)\n        elif i < cutoff[0]+cutoff[1]+cutoff[2]:\n            clas.append(3)\n        else:\n            clas.append(4)\n    return clas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93a0eb7127f1c16e858a44296f6cc1ccea40a5fa","scrolled":true},"cell_type":"code","source":"clf = Ridge(alpha = 5)\n\nkfold = 5\nkf = StratifiedKFold(n_splits=kfold, shuffle=True, random_state = 9)\n\npredicts_result = []\nave_score = 0\nfor train_index, test_index in kf.split(train, y):\n    X_train, X_val = train[train_index], train[test_index]\n    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n    clf.fit(X_train, y_train)\n    predicts_result.append(clf.predict(test))\n    ave_score += f1_score(y_val, classifyrank(clf.predict(X_val), train_dist), average = 'macro')/kfold\nprint('Cross Validation Macro F1 score:',ave_score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd77dd9c3ce048bc79e70b2f1cef68c396abfeee"},"cell_type":"markdown","source":"This model scores **0.432 on CV** using classification weights from the train set. Let's see how it does on LB"},{"metadata":{"trusted":true,"_uuid":"b801cd525c65ca80d5847cffba63e35620e88c01","_kg_hide-input":true},"cell_type":"code","source":"predicts_result = rankdata(np.array(predicts_result).mean(axis = 0))\ntarget_train_dist = classifyrank(predicts_result, train_dist)\ntarget_test_dist = classifyrank(predicts_result, target_dist)\n\npred_train_dist['Target'] = target_train_dist\npred_test_dist['Target'] = target_test_dist\nprint('Using Train Distribution:')\nprint (pred_train_dist['Target'].value_counts())\nprint('\\nUsing Test Distribution:')\nprint (pred_test_dist['Target'].value_counts())\n\ntrain_submission = submission.copy()\ntrain_submission = train_submission.merge(pred_train_dist[['Id', 'Target']], on = 'Id', how = 'left')\ntrain_submission = train_submission.fillna(4)\ntrain_submission['Target'] = train_submission['Target'].astype(int)\ntrain_submission.to_csv('train_dist.csv', index = False)\n\ntest_submission = submission.copy()\ntest_submission = test_submission.merge(pred_test_dist[['Id', 'Target']], on = 'Id', how = 'left')\ntest_submission = test_submission.fillna(4)\ntest_submission['Target'] = test_submission['Target'].astype(int)\ntest_submission.to_csv('test_dist.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9a475f3bc150cd62056ad47e139545e54afe0bc"},"cell_type":"markdown","source":"These 2 submissions come from the exact same regression model, but one is classified using the train target distribution, and the other using the test target distribution which we probed from the leaderboard. \n\nThe submission using the train target distribution scored **0.426** on the LB, while the one using the test target distribution scored **0.432**.  At time of writing, this is an improvement of roughly 30 places on the leaderboard (6.5% of total ranking). Overall, not a bad way to spend our 4 submissions.\n\nUnfortunately, it's not very easy to apply this knowledge when using packaged classifiers such as LightGBM. I noticed that, when running my LGBMClassifiers, the target distribution of the predictions are quite different from the test distribution that we extracted here. Maybe you can find a way to utilise this information?\n\nThank you very much for reading!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}