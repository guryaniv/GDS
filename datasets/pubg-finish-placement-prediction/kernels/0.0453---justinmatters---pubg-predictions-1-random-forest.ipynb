{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# machine learning imports\nimport sklearn as skl\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestRegressor # does not auto import\nfrom sklearn.metrics import mean_absolute_error # does not auto import\nimport numpy as np\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# set up our feature engineering labels\ne_labels = ['matchId','groupId','killPlace', 'boosts', 'walkDistance', 'weaponsAcquired', 'damageDealt', 'heals', \n                        'kills', 'longestKill', 'killStreaks', 'rideDistance', 'winPlacePerc', 'matchType']\n\n# list of the variables discovered to be significant in data analysis\nvariables = ['killPlace', 'boosts', 'walkDistance', 'weaponsAcquired', 'damageDealt', 'heals', \n                        'kills', 'longestKill', 'killStreaks', 'rideDistance', 'winPlacePerc']\n\n# labels for desired columns for dataset to feed to model\n# use normed values for stats except for rideDistance where correlation worsens\n# use category variables for game types where this information assists the model\nlabels = [ \n       'killPlace_g_norm', 'boosts_g_norm', 'walkDistance_g_norm',\n       'weaponsAcquired_g_norm', 'damageDealt_g_norm', 'heals_g_norm',\n       'kills_g_norm', 'longestKill_g_norm', 'killStreaks_g_norm',\n       'rideDistance_group',  'duo', 'duo-fpp', 'solo', 'solo-fpp', 'squad',\n       'squad-fpp']\n\ndef feature_engineering(pubg_data):\n    '''FEATURE ENGINEERING\n    GIVEN: a PUBG dataframe which must have a dummy 'winPlacePerc' column if a test set\n    Conduct data engineering including:\n    producing group data, normalising data with relevant match stats, clipping extreme results\n    RETURNS: pubg_x dataframe consisting of feature engineered input columns\n             pubg_y dataframe with target values (0 dummy frame if this is a test set)\n    '''\n\n    # reduce dataframe to the columns we want to use\n    pubg_data = pubg_data[e_labels]\n\n    # use groupby to get means for team\n    pubg_group_means = pubg_data.groupby(['matchId','groupId']).mean().reset_index()\n\n    # use groupby to get means of matches\n    pubg_match_means = pubg_data.groupby(['matchId']).mean().reset_index()\n\n    # merge back in leaving columns unchanged for one set to allow for future suffixing (only affects shared columns)\n    pubg_engineered = pd.merge(pubg_data, pubg_group_means, \n                               suffixes=[\"\", \"_group\"], how = \"left\", on = ['matchId', 'groupId']) \n    pubg_engineered = pd.merge(pubg_engineered, pubg_match_means, \n                               suffixes=[\"_player\", \"_match\"], how = \"left\", on = ['matchId'])\n\n    # norm the player variables\n    for variable in variables:\n        pubg_engineered[variable+'_norm'] = pubg_engineered[variable+'_player']/(pubg_engineered[variable+'_match']+0.1)\n\n    # norm the group variables\n    for variable in variables:\n        pubg_engineered[variable+'_g_norm'] = pubg_engineered[variable+'_group']/(pubg_engineered[variable+'_match']+0.1)\n\n    # one hot encode the matchTypes since different matches may follow different logics\n    one_hot = pd.get_dummies(pubg_engineered['matchType'])\n    # Drop column B as it is now encoded\n    pubg_engineered = pubg_engineered.drop('matchType',axis = 1)\n    # Join the encoded df\n    pubg_engineered = pubg_engineered.join(one_hot)\n\n    # setting up our basic data\n    pubg_data = pubg_engineered.reset_index(drop=True)\n\n    # create raw input  data\n    pubg_x = pubg_data[labels]\n\n    # clip outliers on a per column basis \n    pubg_x = pubg_x.clip(lower=None, upper= pubg_x.quantile(0.99), axis = 1)\n\n    # set up our target data (not needed for test, so creates a dummy variable\n    pubg_y = pubg_data['winPlacePerc_player']\n\n    #return values\n    return pubg_x, pubg_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"581c6167c1c3f74fb073ab238b005c0671ef17a5"},"cell_type":"code","source":"# import our training data\npubg_data_all = pd.read_csv(\"../input/train_V2.csv\")\npubg_data = pubg_data_all.dropna() # there is an na value we need to drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22938a269b00ec7b54c32d347ed64e67fadbf5a4"},"cell_type":"code","source":"# do our feature engineering and split off our target variable\npubg_x, pubg_y = feature_engineering(pubg_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fdba04f2eed8fdc5fa2c57744ca3086581e7bf0"},"cell_type":"code","source":"# now lets scale data to ensure column scales do not skew results\nscaler = skl.preprocessing.StandardScaler().fit(pubg_x)\n\n# lets look at the head again - we need to convert back to dataframe from numpy array though\npubg_x = pd.DataFrame(scaler.transform(pubg_x), columns= labels)\n# having a scaler object will let us use it on the test data too :-)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9e0019fa901310db23f7977c2ea5adaba155a23"},"cell_type":"code","source":"# now lets create the model\nmodel_rf = RandomForestRegressor(n_estimators=32, oob_score=False, random_state=0, n_jobs = -1, verbose = 2)\n\n# and fit it...\nmodel_rf.fit(pubg_x, pubg_y)\n# save the model out (not needed for kernel run)\n#joblib.dump(model_rf, 'pubg_model_rf.joblib') \n\n# now lets test how well it fits training data (with normalisation AND extreme value clipping)\npredict_train_rf = model_rf.predict(pubg_x)\nprint('Mean absolute error for the training set using random forest regressor model %.4f' %\n      mean_absolute_error(pubg_y, np.clip(predict_train_rf, 0, 1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65970da3d7b6b6d5c5a3a25597f438ba53294c79"},"cell_type":"code","source":"# save memory before running training data\ndel(pubg_data)\ndel(pubg_data_all)\ndel(pubg_x)\ndel(pubg_y)\ndel(predict_train_rf)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"d71dc0b91a6c098679580c1ca3f1c819681cf624"},"cell_type":"code","source":"# now we are ready to read in the test data\npubg_data_test = pd.read_csv('../input/test_V2.csv')\n#print(pubg_data_test.isnull().sum()) # no NaNs\n\n# add a dummy winPlacePerc column to pubg_data_test so we can use our feature engineering function\npubg_data_test['winPlacePerc'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53d98b075d0ffaebd0360c2e2224a4c3ca1eca81"},"cell_type":"code","source":"# do our feature engineering (NB pubg_y is a dummy return here)\npubg_x, pubg_y = feature_engineering(pubg_data_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46004aeafd23b48af519b7470b9ff33888b2cc6"},"cell_type":"code","source":"#use our scaler on the test data too\npubg_x = pd.DataFrame(scaler.transform(pubg_x), columns= labels)\n\n# then make predictions\npredict_test_rf = model_rf.predict(pubg_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e9831661cfc5a0424f8692c48d83d817d922cf7"},"cell_type":"code","source":"# and clip outlying values as they cannot be correct (NB we can likely be more sophisticated than this)\npredict_test_rf_clip = np.clip(predict_test_rf, 0, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe8353ecc6793b701bbd333752b45b8d7c5082c9"},"cell_type":"code","source":"# prepare output\npredict_test_rf_df = pd.DataFrame(data= predict_test_rf_clip, columns=['winPlacePerc'])\noutput_df = pd.merge(pubg_data_test[\"Id\"].to_frame(),predict_test_rf_df['winPlacePerc'].to_frame(), left_index=True, right_index=True)\noutput_df.head()\n\n# write output\noutput_df.to_csv(\"submission2.csv\", index = False, index_label=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}