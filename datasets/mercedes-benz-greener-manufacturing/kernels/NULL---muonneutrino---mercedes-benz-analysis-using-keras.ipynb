{"metadata": {"language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "version": "3.6.1", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 2, "nbformat": 4, "cells": [{"metadata": {"deletable": true, "_uuid": "3d01cbe8d59b5b0c5e54c276bbf2c06afe3a4b95", "editable": true}, "outputs": [], "source": ["# Method 1: Use X0 value to make predictions\n", "\n", "We see that there are many values of X0. It turns out that this is actually a pretty good predictor by itself, so we can start out by looking only at this variable. We don't need to do any fitting: just an X0-->y map using the mean y. It's possible that the median might be better."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "015b2bd53315a8bad6bdcb8266840a217229d00d"}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "\n", "%matplotlib inline"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "f9749d92c345789653cb4b89ed375e875d9c4c87"}, "outputs": [], "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\ntrain = pd.read_csv('../input/train.csv',index_col=0)\ntest = pd.read_csv('../input/test.csv',index_col=0)\ntrain = train[['X0','y']]\ntrain, val = train_test_split(train,test_size=0.3,random_state=1234)\ntest = test['X0']\n\ngroups = train.groupby('X0')\nymap = {}\nfor name,group in groups:\n    ymap[name] = group.y.mean()\n\ntrain['ypred'] = train.X0.map(ymap)\nval['ypred'] = val.X0.map(ymap)    \nval['ypred'] = val.ypred.fillna(train.y.mean())\n\ntrain_score = r2_score(train.y,train.ypred)\nval_score = r2_score(val.y,val.ypred)\n\nprint('Training score: ' + str(train_score))\nprint('Validate score: ' + str(val_score))\n\nytest = test.map(ymap)\nytest = ytest.fillna(train.y.mean())\n        \n        \nytest = pd.DataFrame({'y':ytest})\nytest.to_csv('submission_X0.csv')", "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "753caf0f9ad8a9c3c8841fbc33a84ac58debe2ef", "editable": true}, "outputs": [], "source": ["# Method 2: Linear Regression with Keras\n", "\n", "I don't have much experience with neural nets, so I'll start by setting up a trivial neural net in Keras.\n", "\n", "A single linear output node with no hidden layers is equivalent to linear regression. It should give results that are equivalent to the previous method up to any uncertainties from the minimization procedure. As long as we don't do anything crazy, optimization shouldn't do much to improve things."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "e602c2fb590028272a1a8a6befa93b5f18fdceaa"}, "outputs": [], "source": "from sklearn.model_selection import train_test_split\n\n###\nvalidate = False\n###\n\ntrain = pd.read_csv('../input/train.csv',index_col=0)\ntrain.head()\ntest = pd.read_csv('../input/test.csv',index_col=0)\n\nxtrain = pd.get_dummies(train.X0)\nytrain = train.y\nxtest = pd.get_dummies(test.X0)\n\n# Get list of columns\nfor col in xtrain.columns:\n    if col not in xtest.columns:\n        xtest[col] = 0\n        \nfor col in xtest.columns:\n    if col not in xtrain.columns:\n        xtest = xtest.drop(col,axis=1)\n        \n\nif validate is True: \n    xtrain, xval, ytrain, yval = train_test_split(xtrain,ytrain,test_size=0.3,random_state=1234)\nxtest = xtest.sort_index(axis=1)\nprint(xtrain.head())\nprint(xtest.head())", "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "f9f74b5989bc0415235a3c2319fd698f6fa11cbf"}, "outputs": [], "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Activation\n", "from keras.layers.core import Dropout\n", "from keras import optimizers\n", "from keras import regularizers"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "ac18c27d7678098d6f2f02f5308df18d2e0491ba"}, "outputs": [], "source": ["print('Building Model')\n", "model = Sequential()\n", "model.add(Dense(units=1,input_dim=xtrain.shape[1]))\n", "model.add(Activation('linear')) # Linear to get fit\n", "print('Compiling Model')\n", "sgd = optimizers.SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=True)\n", "model.compile(loss='mean_squared_error',optimizer=sgd)\n", "print('Fit Model')\n", "model.fit(xtrain.as_matrix(), ytrain.as_matrix(), epochs=1000, batch_size=512)\n", "print('Evaluating and predicting')\n", "#loss = model.evaluate(xtrain.as_matrix(),ytrain.as_matrix(),batch_size=128)\n", "train_vals = model.predict(xtrain.as_matrix(),batch_size=128)\n", "if validate is True:\n", "    val_vals = model.predict(xval.as_matrix(), batch_size=128)\n", "test_vals = model.predict(xtest.as_matrix(),batch_size=128)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "4c3fbad689a1a7e4e2d280bf8f042d3174981a88"}, "outputs": [], "source": ["from sklearn.metrics import r2_score\n", "if validate is True:\n", "    val_score = r2_score(yval,val_vals)\n", "    print('Validation score: '+ str(val_score))\n", "\n", "train_score = r2_score(ytrain,train_vals)\n", "print('Training score: ' + str(train_score))\n", "#model.get_weights()[0] + model.get_weights()[1][0]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "b39ca2c8abd4e1e71ecd9c07e96c0d377f32a84f"}, "outputs": [], "source": ["test['y'] = test_vals\n", "test_out = test[['y']]\n", "test_out.to_csv('submission_linearfit.csv')"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "9c6f802a10177276ba3a2ee8b68ba841af9e3e01", "editable": true}, "outputs": [], "source": ["# Method 3: Keras/Theano Fully Connected Feed-Forward Neural Net\n", "\n", "Next, we'll try out a neural net using Keras. I'm using the Theano backend, but the code for TensorFlow should be the same in Keras. To do this, we'll first subtract the X0 predictions from y so that we only fit for the difference. We'll see why this might be a good idea later.\n"], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "06dd0e49a40ea53c928d0ee2fe69a880fa4a0553"}, "outputs": [], "source": "train = pd.read_csv('../input/train.csv',index_col=0)\ntrain.head()\ntest = pd.read_csv('../input/test.csv',index_col=0)\n", "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "bb7a3877a74a9cba738c24429b5b3d6971a7663e"}, "outputs": [], "source": ["dum = pd.get_dummies(train.X0,drop_first = True)\n", "train = pd.merge(train,dum,left_index=True,right_index=True,suffixes=('','_x0'))\n", "dum = pd.get_dummies(test.X0,drop_first = True)\n", "test = pd.merge(test,dum,left_index=True,right_index=True,suffixes=('','_x0'))\n", "train.head()\n", "\n", "# Get list of columns\n", "for col in train.columns:\n", "    if col not in test.columns:\n", "        test[col] = 0\n", "        \n", "for col in test.columns:\n", "    if col not in train.columns:\n", "        test = test.drop(col,axis=1)\n", "        \n", "groups = train.groupby('X0')\n", "ymap = {}\n", "for name,group in groups:\n", "    ymap[name] = group.y.mean()\n", "\n", "train['yX0'] = train.X0.map(ymap)\n", "train['ydiff'] = train.y - train.yX0\n", "test['yX0'] = test.X0.map(ymap)\n", "test['yX0'] = test['yX0'].fillna(train.y.mean())\n", "        \n", "print(test.shape)\n", "print(train.shape)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "20520fea858693777382604a654162e644bb5d73", "editable": true}, "outputs": [], "source": ["## Validation\n", "\n", "To make things faster, I'll just use a regular train/test split rather than k-fold cross validation. 30% of the training data set will go into the validation set."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "cb814340e32fa265053646e8c07616da607b07d3"}, "outputs": [], "source": ["validate = True\n", "\n", "from sklearn.model_selection import train_test_split\n", "if validate is True:\n", "    train, val = train_test_split(train,test_size=0.3,random_state=1234)\n"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "8467923e76c788ec0a519319e1b8a264e9a5321a", "editable": true}, "outputs": [], "source": ["## Plotting\n", "\n", "When we plot the value of y, we see that the distribution has a lot of structure. There are a number of different peaks that are all smeared together.\n", "\n", "However, when we look at $y-y_{X0pred}$, we get a much cleaner distribution. There is still a long high-value tail that may be responsible for much of the $R^2$ value from just the $X_0$ prediction."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "f951025994b7a3b024f1878715ce87be87f5a6cd"}, "outputs": [], "source": ["fig = plt.figure(1,figsize=(10,10))\n", "ax = fig.add_subplot(221)\n", "plt.hist(train.y,bins=80)\n", "plt.xlabel('y')\n", "plt.ylabel('Number of Entries')\n", "ax = fig.add_subplot(222)\n", "plt.hist(np.log(train.y),bins=80)\n", "plt.xlabel('log(y)')\n", "plt.ylabel('Number of Entries')\n", "ax = fig.add_subplot(223)\n", "plt.hist(train.ydiff,bins=80)\n", "plt.xlabel('y-y(X0)')\n", "plt.show()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "a943e30eaff9f4cb26abf035138111c4a0b0be37", "editable": true}, "outputs": [], "source": ["# Drop duplicate columns\n", "\n", "Many columns are just duplicates on the training set, so we should find these and remove them. I'll take duplicates as any pair of columns where standard deviation is less than 0.02 (I just chose this arbitrarily - could be optimized)."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "2a1ba106816c52011e3adf0c2caf1a77f916602a"}, "outputs": [], "source": ["dupl_cols = []\n", "for i in range(10,386):\n", "    for j in range(i+1,386):\n", "        try:\n", "            label1 = 'X%i'%(i)\n", "            label2 = 'X%i'%(j)\n", "            vals = (train[label1]==train[label2])\n", "            if vals.std()<0.02:\n", "                dupl_cols.append(label2)\n", "        except:\n", "            pass\n", "#print(dupl_cols)\n", "dupl_cols = {x for x in dupl_cols} # unique set\n", "print('# of duplicate columns: ' +str(len(dupl_cols)))\n", "\n", "train = train.drop(dupl_cols,axis=1)\n", "if validate is True:\n", "    val = val.drop(dupl_cols,axis=1)\n", "test = test.drop(dupl_cols,axis=1)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "_uuid": "52cbaf31ca45b5865dc13f02f50c257505e38184", "editable": true}, "outputs": [], "source": ["# Look for Binary Fields with Large y Differences\n", "\n", "There are hundreds of binary features here, so we'll look over them and find the ones which have the largest difference between the $y$ residuals for the two values of the feature. Here, I save the features with at least 10 entries in each class and with a difference of at least $\\sigma/20$  where $\\sigma$ is taken from the standard deviations of the two distributions."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "b90429eb21492914ffc88dde860426ba60d28d5f"}, "outputs": [], "source": ["diff = []\n", "name = []\n", "c0 = []\n", "c1 = []\n", "mean0 = []\n", "mean1 = []\n", "std0 = []\n", "std1 = []\n", "for i in range(10,386):\n", "    try:\n", "        yy = train.groupby('X%i'%(i)).ydiff\n", "        diff0 = np.abs(yy.mean()[1] - yy.mean()[0])/np.sqrt(yy.var()[1]+yy.var()[0])\n", "        #c0 = yy.count()[0]\n", "        #c1 = yy.count()[1]\n", "        c0.append(yy.count()[0])\n", "        c1.append(yy.count()[1])\n", "        mean0.append(yy.mean()[0])\n", "        mean1.append(yy.mean()[1])\n", "\n", "        std0.append(yy.std()[0])\n", "        std1.append(yy.std()[1])\n", "        diff.append(diff0)\n", "        name.append('X%i'%(i))\n", "\n", "    except:\n", "        pass\n", "df = pd.DataFrame({'c0':c0,'c1':c1,'diff':diff,'mean0':mean0,'std0':std0,'mean1':mean1,'std1':std1},index=name)\n", "indices = df[((df.c0<=10) | (df.c1<=10) | (df['diff']<=0.05))].index\n", "#df = df[((df.c0>50) & (df.c1>50) & (df['diff']>0.2))].sort_values(by='diff',ascending=False)\n", "df = df[(df.c0>10) & (df.c1>10) & (df['diff']>0.05)].sort_values(by='diff',ascending=False)\n", "df.head(100)"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "ffa81ffd4a2c4df4fbcf3092476cec72dda45b10"}, "outputs": [], "source": ["## Set up output data frames\n", "\n", "We'll fit to $y-y_{X0pred}$ so we need to add $y_{X0pred}$ back in to get the prediction for $y$."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "7c45b43cf63ac06b4024e1e1872506b0f9e78e88"}, "outputs": [], "source": ["ytrain = train.loc[:,['y','yX0','ydiff']]\n", "cols = [x for x in df.index]\n", "if validate is True:\n", "    xval = val[cols]\n", "    yval = val.loc[:,['y','yX0','ydiff']]\n", "ytest = test.loc[:,['yX0']]\n", "xtrain = train[cols]\n", "xtest = test[cols]"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "214f20ba1139cd1242855f97f17ca3f139777817"}, "outputs": [], "source": ["xtrain.head()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "b4eb8a4258cc2d8a98fab8999fb55515dfeb7c95"}, "outputs": [], "source": ["## Setting up the Keras model\n", "\n", "We'll use a simple sequential model with a single densely-connected hidden layer. I've tested both L2 regularization and dropout and similar results are obtained with both. As far as I can tell, it will be feature development that makes most of the difference between models."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "1a0b389950c8172ecbe18708d6fcfb8f649e4249"}, "outputs": [], "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Activation\n", "from keras.layers.core import Dropout\n", "from keras import optimizers\n", "from keras import regularizers"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "scrolled": true, "_uuid": "c954085cf8f7060bf4affd7fb3f5cd365fd43fa7"}, "outputs": [], "source": ["print('Building Model')\n", "model = Sequential()\n", "l2reg = 0.0\n", "model.add(Dropout(0.2,input_shape=(xtrain.shape[1],)))\n", "model.add(Dense(units=10,kernel_regularizer=regularizers.l2(l2reg)))\n", "model.add(Activation('relu')) # These are all categorical so probably doesn't matter\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Dense(units=1,kernel_regularizer=regularizers.l2(l2reg)))\n", "#model.add(Dropout(0.5))\n", "model.add(Activation('linear')) # Linear to get fit\n", "print('Compiling Model')\n", "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=False)\n", "model.compile(loss='mean_squared_error',optimizer=sgd)\n", "print('Fit Model')\n", "model.fit(xtrain.as_matrix(), ytrain.ydiff.as_matrix(), epochs=1000, batch_size=64)\n", "print('Evaluating and predicting')\n", "#loss = model.evaluate(xtrain.as_matrix(),ytrain.as_matrix(),batch_size=128)\n", "train_vals = model.predict(xtrain.as_matrix(),batch_size=128)\n", "test_vals = model.predict(xtest.as_matrix(),batch_size=128)\n", "\n", "ytrain['ypred'] = train_vals\n", "if validate is True:\n", "    val_vals = model.predict(xval.as_matrix(), batch_size=128)\n", "    yval['ypred'] = val_vals\n", "    yval['ypred'] = yval.ypred+yval.yX0\n", "\n", "ytest['ypred'] = test_vals\n", "ytrain['ypred'] = ytrain.ypred+ytrain.yX0\n", "ytest['ypred'] = ytest.ypred+ytest.yX0"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "2be0ae246c8df60b92e9496223df2b604ca25d97"}, "outputs": [], "source": ["from sklearn.metrics import r2_score\n", "train_score = r2_score(ytrain.y,ytrain.ypred)\n", "train_score2 = r2_score(ytrain.ydiff,ytrain.ypred-ytrain.yX0)\n", "print('Training score (X0 diff): ' + str(train_score2))\n", "print('Training score (full): ' + str(train_score))\n", "\n", "if validate is True:\n", "    val_score2 = r2_score(yval.ydiff,yval.ypred-yval.yX0)\n", "    val_score = r2_score(yval.y,yval.ypred)\n", "    print('Validation score (X0 diff): '+ str(val_score2))\n", "    print('Validation score (full): '+ str(val_score))"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "30470fe106de18fe41227343edb107b5bdeeccf7"}, "outputs": [], "source": ["test_out = ytest[['ypred']]\n", "test_out = test_out.sort_index(ascending=True)\n", "test_out['y'] = test_out.ypred\n", "test_out = test_out[['y']]\n", "test_out.to_csv('submission.csv')"], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "526b2a209d110f95bf915d1275f6ed00e12fe082"}, "outputs": [], "source": ["So, after all that work using neural nets, we've actually gained almost nothing in the validation set. This result is a tiny bit better on the public leaderboard than just using X0 but not by much. Looking at the current leaders, it looks like it's possible to get maybe another 0.01 increase or so in R^2 but this actually isn't so far off the leaders. So, basically everyone is only possibly getting minor gains from a very simple model.\n", "\n", "# So What Now?\n", "\n", "Well, we haven't looked at the other categorical variables. Maybe some of those will help.\n", "\n", "I also didn't do any cleaning of X0. If we look at it, there are some values of X0 with very few entries. We probably don't have a good sense of what the mean y should be for these, so we might want to come up with replacement values for these.\n", "\n", "Finally, let's look at the $y-y_{X0pred}$ distribution. It looks like a Gaussian with a long positive tail. How much of our remaining error comes from the tail?"], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "1819553454b52b47d5ee15d6e8896151251fd9e5"}, "outputs": [], "source": ["train.ydiff.std()\n", "quantiles = train.ydiff.quantile([0.16,0.84])\n", "0.25*(quantiles.iloc[1]- quantiles.iloc[0])**2 / train.ydiff.var()"], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "88ab5422c56cfad44e09bf17f5e49fdd01fcc9cd"}, "outputs": [], "source": ["Evidently, the variance calculated from the central 68% percent region and from the actual sample variance are quite different. It looks like the tail might even provide half the remaining error. If we really want to push this analysis, it may be most useful to see if we can find some way to separate the tail events from the main peak and then do an analysis on the tail events only."], "execution_count": null, "cell_type": "markdown"}, {"metadata": {"deletable": true, "collapsed": false, "editable": true, "_uuid": "740a1f9e0259f7c687e371753890e10bad56b6d6"}, "outputs": [], "source": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"deletable": true, "collapsed": true, "editable": true, "_uuid": "1914c2781c1297e66f69611836daa394ac175dff"}, "outputs": [], "source": [], "execution_count": null, "cell_type": "code"}]}