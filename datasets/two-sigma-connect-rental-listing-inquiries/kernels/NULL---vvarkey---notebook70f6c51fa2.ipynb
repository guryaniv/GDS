{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db4e3b5a-6ba3-c346-7115-d9c97b281064"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def scorer(estimator, X, y):\n",
        "    return -log_loss(y, estimator.predict_proba(X))\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "df=pd.read_json('../input/train.json')\n",
        "df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\n",
        "df['created']=df['created'].astype(np.datetime64)\n",
        "df['created_day']=np.array(df.created.values, dtype='datetime64[D]').astype(np.float32)%7\n",
        "df['created_week']=np.array(df.created.values, dtype='datetime64[W]').astype(np.float32)\n",
        "df['created_hour']=np.array(df.created.values, dtype='datetime64[h]').astype(np.float32)%24\n",
        "df['desc_count']=df.description.apply(lambda x: len(x.split())).clip(upper=150)\n",
        "df['features_count']=df.features.apply(lambda x: len(x))\n",
        "df['photos_count']=df.photos.apply(lambda x: len(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9846ca6a-4d37-4dbd-7d52-1d791c1426ca"
      },
      "outputs": [],
      "source": [
        "df['features']=df['features'].apply(lambda x: list(map(str.lower, x)))\n",
        "df_features=pd.DataFrame(np.hstack(df.features.values), columns=['feature'])\n",
        "df_feature_counts=pd.DataFrame(df_features.groupby(['feature']).size(), \n",
        "                               columns=['size']).reset_index()\n",
        "df_feature_counts=df_feature_counts.sort_values('size', ascending=False)\n",
        "feature_list=df_feature_counts.loc[df_feature_counts['size']>5000]['feature'].values\n",
        "feature_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "179e3b03-ccf6-5a29-502e-7619d1db91fb"
      },
      "outputs": [],
      "source": [
        "for feature in feature_list:\n",
        "        df[feature]=df['features'].apply(lambda x: feature in x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "366e84ae-4887-e54a-88e1-6871206baa21"
      },
      "outputs": [],
      "source": [
        "df_tv, df_test = train_test_split(df, random_state=0)\n",
        "df_train, df_val = train_test_split(df_tv, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cacc9493-d310-85c6-b018-2edeb3f796ce"
      },
      "outputs": [],
      "source": [
        "cols=['price', 'bathrooms', 'bedrooms', 'priceperbed', 'created_hour', 'desc_count', 'photos_count', 'features_count', \n",
        "      'elevator', 'hardwood floors', 'cats allowed', 'dogs allowed', 'doorman', 'dishwasher', \n",
        "      'laundry in building', 'no fee', 'fitness center', 'laundry in unit', 'pre-war', 'roof deck', \n",
        "      'outdoor space', 'dining room']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af3f9ed0-a6fd-e94e-8850-cfc9b0d212fe"
      },
      "outputs": [],
      "source": [
        "cols=['price', 'bathrooms', 'bedrooms', 'priceperbed','created_hour',  'desc_count', 'photos_count',\n",
        "'features_count', 'no fee', 'hardwood floors', 'laundry in building']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23303d47-d933-2b4d-d957-9bb3e352ef47"
      },
      "outputs": [],
      "source": [
        "    clf=ExtraTreesClassifier(max_depth=23, n_estimators=1000,\n",
        "                             min_samples_split=10, random_state=0) \n",
        "    clf.fit(df_train[cols].values, df_train['interest_level'])\n",
        "    y_pred=clf.predict_proba(df_train[cols])\n",
        "    score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "    y_pred=clf.predict_proba(df_val[cols])\n",
        "    score2=log_loss(df_val['interest_level'].values, y_pred)\n",
        "    y_pred=clf.predict_proba(df_test[cols])\n",
        "    score3=log_loss(df_test['interest_level'].values, y_pred)\n",
        "    print(\"%.6f %.6f %.6f\"%(score, score2, score3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e633847-f48e-5084-e534-8388f4d378fd"
      },
      "outputs": [],
      "source": [
        "    import xgboost as xgb\n",
        "    \n",
        "    param = {}\n",
        "    param['objective'] = 'multi:softprob'\n",
        "    #param['eta'] = 0.1\n",
        "    #param['max_depth'] = 23\n",
        "    param['num_class'] = 3\n",
        "    param['eval_metric'] = \"mlogloss\"\n",
        "    #param['min_child_weight'] = 10\n",
        "    #param['subsample'] = 0.7\n",
        "    #param['colsample_bytree'] = 0.7\n",
        "    param['seed'] = 0\n",
        "    plst = list(param.items())\n",
        "    target_num_map = {'high':0, 'low':1, 'medium':2}\n",
        "    train_y = np.array(df_train['interest_level'].apply(lambda x: target_num_map[x]))\n",
        "    xgtrain = xgb.DMatrix(df_train[cols].values, label=train_y)\n",
        "    model = xgb.train(plst, xgtrain, 100)\n",
        "    \n",
        "    xgtest = xgb.DMatrix(df_train[cols].values)\n",
        "    y_pred=model.predict(xgtest)\n",
        "    score=log_loss(df_train['interest_level'].values, y_pred)\n",
        "    xgtest = xgb.DMatrix(df_val[cols].values)\n",
        "    y_pred=model.predict(xgtest)\n",
        "    score2=log_loss(df_val['interest_level'].values, y_pred)\n",
        "    xgtest = xgb.DMatrix(df_test[cols].values)\n",
        "    y_pred=model.predict(xgtest)\n",
        "    score3=log_loss(df_test['interest_level'].values, y_pred)\n",
        "    print(\"%.6f %.6f %.6f\"%(score, score2, score3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45044a29-a3a6-14e0-a537-92e296ff98cc"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "sorted(dict(zip(cols, clf.feature_importances_)).items(), key=operator.itemgetter(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f74658f5-f044-6019-7b70-0b9a5faa924f"
      },
      "outputs": [],
      "source": [
        "feature_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b6b12ed0-74dc-d1f3-5f5e-f3345820706f"
      },
      "outputs": [],
      "source": [
        "df['priceperbed']=(df['price'].clip(upper=7000)/df['bedrooms'].clip(lower=1))\n",
        "df['created_month']=np.array(df.created.values, dtype='datetime64[M]').astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "deeedac5-84fe-86ad-8cb2-ba41edb28740"
      },
      "outputs": [],
      "source": [
        "df['created_week'].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd7392ad-b9ff-8d4a-21ef-18fc969cc903"
      },
      "outputs": [],
      "source": [
        "df['laundry in unit']=(df['laundry in unit'])|(df['laundry in building'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5b137c40-b4a9-3d8d-7696-589c5f460a3a"
      },
      "outputs": [],
      "source": [
        "df['laundry in unit'].sum()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}