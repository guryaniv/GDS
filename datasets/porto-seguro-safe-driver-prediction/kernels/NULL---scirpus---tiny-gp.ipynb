{"nbformat": 4, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python", "version": "3.6.1", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["A tiny GP that gets 0.266 - only a single model with twenty lines so not too bad!"]}, {"cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a45a7778-086e-40af-8a0b-48ea9eccdbd5", "collapsed": true, "_uuid": "e7ae05b780d1f277fa39cf12a218a85eba98eb18"}, "source": ["import gc\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.model_selection import KFold\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import roc_auc_score"], "execution_count": 1}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["directory = '../input/'\n", "train = pd.read_csv(directory+'train.csv')\n", "test = pd.read_csv(directory+'test.csv')\n", "test.insert(1,'target',np.nan)"], "execution_count": 2}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["train['missing'] = (train==-1).sum(axis=1).astype(float)\n", "test['missing'] = (test==-1).sum(axis=1).astype(float)"], "execution_count": 3}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["feats = list(set(train.columns).difference(set(['id','target'])))\n", "feats = list(['id'])+feats +list(['target'])\n", "train = train[feats]\n", "test = test[feats]"], "execution_count": 4}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["def ProjectOnMean(data1, data2, columnName):\n", "    grpOutcomes = data1.groupby(list([columnName]))['target'].mean().reset_index()\n", "    grpCount = data1.groupby(list([columnName]))['target'].count().reset_index()\n", "    grpOutcomes['cnt'] = grpCount.target\n", "    grpOutcomes.drop('cnt', inplace=True, axis=1)\n", "    outcomes = data2['target'].values\n", "    x = pd.merge(data2[[columnName, 'target']], grpOutcomes,\n", "                 suffixes=('x_', ''),\n", "                 how='left',\n", "                 on=list([columnName]),\n", "                 left_index=True)['target']\n", "\n", "    \n", "    return x.values"], "execution_count": 5}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["highcardinality =[]\n", "for i in train.columns[1:-1]:\n", "    if((train[i].dtype!='float64')&((i.find('bin')!=-1) or (i.find('cat')!=-1))):\n", "        highcardinality.append(i)\n"], "execution_count": 6}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["blindloodata = None\n", "folds = 10\n", "kf = KFold(n_splits=folds,shuffle=True,random_state=42)\n", "for i, (train_index, test_index) in enumerate(kf.split(range(train.shape[0]))):\n", "    print('Fold:',i)\n", "    blindtrain = train.loc[test_index].copy() \n", "    vistrain = train.loc[train_index].copy()\n", "\n", "\n", "\n", "    for c in highcardinality:\n", "        blindtrain.insert(1,'loo'+c, ProjectOnMean(vistrain,\n", "                                                   blindtrain,c))\n", "    if(blindloodata is None):\n", "        blindloodata = blindtrain.copy()\n", "    else:\n", "        blindloodata = pd.concat([blindloodata,blindtrain])\n", "\n", "for c in highcardinality:\n", "    test.insert(1,'loo'+c, ProjectOnMean(train,\n", "                                           test,c))\n", "test.drop(highcardinality,inplace=True,axis=1)\n", "\n", "train = blindloodata\n", "train.drop(highcardinality,inplace=True,axis=1)\n", "train = train.fillna(train.mean())\n", "test = test.fillna(train.mean())"], "execution_count": 7}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["ss = StandardScaler()\n", "features = train.columns[1:-1]\n", "ss.fit(pd.concat([train[features],test[features]]))\n", "train[features] = ss.transform(train[features] )\n", "test[features] = ss.transform(test[features] )"], "execution_count": 8}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["def GiniScore(y_actual, y_pred):\n", "  return 2*roc_auc_score(y_actual, y_pred)-1\n", "\n", "def Outputs(p):\n", "    return 1./(1.+np.exp(-p))\n", "\n", "def GP(data):\n", "    p = (1.000000*np.tanh(((((data[\"loops_ind_04_cat\"] * (-(data[\"ps_calc_02\"]))) - (12.36611652374267578)) - (12.36611270904541016)) * (12.36611270904541016))) +\n", "        1.000000*np.tanh((data[\"ps_car_14\"] - (66.0 + ((((data[\"loops_ind_16_bin\"] + data[\"loops_ind_08_bin\"])/2.0) - data[\"loops_car_08_cat\"]) * (-(data[\"loops_ind_04_cat\"])))))) +\n", "        1.000000*np.tanh(((data[\"loops_car_07_cat\"] - np.tanh((np.tanh((data[\"loops_car_07_cat\"] + data[\"ps_reg_03\"])) + np.tanh(np.tanh((-(data[\"ps_reg_03\"]))))))) - 6.083330)) +\n", "        1.000000*np.tanh((((((((data[\"loops_ind_06_bin\"] + data[\"loops_ind_05_cat\"]) + data[\"loops_ind_17_bin\"])/2.0) + ((-3.0 + data[\"loops_car_01_cat\"])/2.0))/2.0) + np.tanh(((data[\"ps_reg_03\"] + data[\"ps_car_13\"])/2.0)))/2.0)) +\n", "        1.000000*np.tanh((0.076923 * ((data[\"ps_ind_03\"] + (data[\"loops_ind_09_bin\"] + ((data[\"loops_car_09_cat\"] + data[\"loops_car_11_cat\"])/2.0))) - (0.729412 - (-(data[\"ps_ind_15\"])))))) +\n", "        1.000000*np.tanh(((data[\"loops_ind_05_cat\"] - ((((data[\"loops_calc_17_bin\"] + data[\"missing\"])/2.0) + (data[\"loops_car_07_cat\"] * ((data[\"ps_car_13\"] + data[\"loops_ind_05_cat\"])/2.0)))/2.0)) * 0.076923)) +\n", "        1.000000*np.tanh((0.123077 * np.tanh((data[\"loops_ind_02_cat\"] + ((data[\"loops_car_07_cat\"] * data[\"loops_car_07_cat\"]) + ((((data[\"loops_ind_16_bin\"] + data[\"ps_car_15\"])/2.0) + data[\"loops_ind_04_cat\"])/2.0)))))) +\n", "        0.999805*np.tanh((np.tanh(data[\"loops_ind_02_cat\"]) * ((0.057692 * (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])) - ((0.076923 + 0.123077) * data[\"ps_ind_03\"])))) +\n", "        1.000000*np.tanh((-((0.076923 * (((((data[\"ps_car_15\"] - data[\"ps_ind_03\"]) + data[\"ps_reg_03\"]) * data[\"loops_ind_06_bin\"]) + ((data[\"ps_car_11\"] + data[\"ps_reg_03\"])/2.0))/2.0))))) +\n", "        0.935144*np.tanh((0.057692 * (((data[\"ps_reg_01\"] - data[\"loops_ind_05_cat\"]) + ((data[\"ps_car_11\"] * (-(data[\"loops_car_04_cat\"]))) + (data[\"ps_ind_01\"] * data[\"loops_ind_05_cat\"])))/2.0))) +\n", "        1.000000*np.tanh((0.076923 * ((((-1.0 + (-(data[\"ps_ind_15\"])))/2.0) + (((data[\"loops_ind_09_bin\"] * (data[\"loops_car_03_cat\"] + data[\"ps_ind_01\"])) + data[\"loops_car_03_cat\"])/2.0))/2.0))) +\n", "        1.000000*np.tanh((-((0.057692 * ((data[\"loops_car_10_cat\"] + ((((data[\"loops_car_10_cat\"] + (data[\"ps_reg_03\"] + data[\"loops_ind_17_bin\"])) * data[\"ps_car_13\"]) + data[\"loops_car_01_cat\"])/2.0))/2.0))))) +\n", "        1.000000*np.tanh((0.076923 * np.tanh(((data[\"ps_ind_01\"] * data[\"loops_car_05_cat\"]) + (((data[\"ps_ind_01\"] + data[\"loops_car_05_cat\"]) + (data[\"ps_ind_03\"] * data[\"loops_car_05_cat\"]))/2.0))))) +\n", "        0.999805*np.tanh((0.123077 * np.tanh(((((data[\"loops_ind_05_cat\"] * data[\"loops_ind_05_cat\"]) * ((data[\"loops_ind_07_bin\"] + data[\"ps_reg_02\"])/2.0)) + ((data[\"loops_car_09_cat\"] + data[\"loops_ind_05_cat\"])/2.0))/2.0)))) +\n", "        1.000000*np.tanh((0.123077 * np.tanh((data[\"ps_reg_03\"] * (((-(data[\"loops_car_01_cat\"])) + (((-(data[\"ps_ind_01\"])) + ((data[\"ps_reg_03\"] + data[\"ps_calc_14\"])/2.0))/2.0))/2.0))))) +\n", "        0.939051*np.tanh((0.123077 * np.tanh((data[\"loops_ind_02_cat\"] * (data[\"ps_car_15\"] - (((0.987805 + data[\"ps_calc_10\"]) + data[\"loops_ind_04_cat\"]) + data[\"loops_ind_04_cat\"])))))) +\n", "        0.999805*np.tanh((0.076923 * ((np.tanh(data[\"loops_car_07_cat\"]) + np.tanh((((data[\"loops_car_07_cat\"] * data[\"loops_ind_17_bin\"]) + data[\"ps_car_15\"]) - data[\"loops_ind_17_bin\"])))/2.0))) +\n", "        0.954679*np.tanh(((0.057692 * ((data[\"ps_ind_03\"] + (data[\"loops_ind_09_bin\"] - ((((0.057692 + data[\"ps_reg_01\"])/2.0) + data[\"ps_reg_01\"])/2.0)))/2.0)) * data[\"ps_ind_03\"])) +\n", "        0.999805*np.tanh((0.057692 * (((data[\"ps_ind_01\"] * (-(((data[\"ps_ind_01\"] + data[\"ps_ind_15\"])/2.0)))) + (-((((-(data[\"ps_ind_01\"])) + data[\"loops_car_04_cat\"])/2.0))))/2.0))) +\n", "        1.000000*np.tanh((0.057692 * np.tanh(((data[\"ps_reg_01\"] * (-(data[\"ps_reg_03\"]))) + (((data[\"loops_car_06_cat\"] + data[\"ps_reg_01\"])/2.0) + np.tanh(data[\"loops_ind_04_cat\"])))))))\n", "    return Outputs(p)"], "execution_count": 9}, {"cell_type": "code", "outputs": [], "metadata": {}, "source": ["print(GiniScore(train.target,GP(train)))"], "execution_count": 10}, {"cell_type": "code", "outputs": [], "metadata": {"collapsed": true}, "source": ["sub = pd.read_csv(directory+'sample_submission.csv')\n", "sub.target = GP(test).values\n", "sub.to_csv('gp_266.csv',index=False)"], "execution_count": 11}], "nbformat_minor": 1}