{"cells":[{"metadata":{"_uuid":"273ba0d3304ccf9e354eb06b1aa10930f0be8c6c"},"cell_type":"markdown","source":"**Importing Tensorflow to have access to neural networks tools (in particular the keras module)**"},{"metadata":{"_uuid":"6557edcb67a2037e297b1d050f434dc1b63c5249","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\n\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edcec4a1af47af29e20e0a2f81c1e41375a556b2"},"cell_type":"markdown","source":"Seaborn was not accepted during import"},{"metadata":{"_uuid":"11b40f05ad86ed91cc3bfffa14e8a8d18efe7f98"},"cell_type":"markdown","source":"\nReading train data from an uploaded file which is only 100 MB, which we produced locally after downloading the big train file from NYCTFP repository\n\nReading the test file directly from NYCTFP "},{"metadata":{"_uuid":"6dcd85efb10f5d50ad434be70142e9458ca42371","trusted":true},"cell_type":"code","source":"header_names_train = ['key','fare_amount','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']\nheader_names_test = ['key','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5656675429bd8330e63552f88109bf15584e5c6a","trusted":true},"cell_type":"code","source":"from math import cos, asin, sqrt\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295     #Pi/180\n    a = 0.5 - cos((lat2 - lat1) * p)/2 + cos(lat1 * p) * cos(lat2 * p) * (1 - cos((lon2 - lon1) * p)) / 2\n    return 12742 * asin(sqrt(a)) #2*R*asin...","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bffa9e45710dd3f4da6073f3e9f5915de0fcf26","trusted":true},"cell_type":"code","source":"def data_refine_train(input_file, output_file, ini_row, tot_row):\n    \n    df = pd.read_csv(input_file, sep=',', header = None, names = header_names_train, skiprows = ini_row, nrows = tot_row)\n    \n    df = df[['key','fare_amount','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']]\n    \n    df['distance'] = pd.concat([pd.DataFrame([distance(df['pickup_latitude'][i],df['pickup_longitude'][i],\n                                                         df['dropoff_latitude'][i],df['dropoff_longitude'][i])], \n                                               columns=['distance']) for i in range(len(df))], ignore_index=True)\n    \n    df = df[((df.pickup_longitude >= -75.0) & (df.pickup_longitude <= -72)) \n         & ((df.pickup_latitude >= 38) & (df.pickup_latitude <= 42)) \n         & ((df.dropoff_longitude >= -75.0) & (df.dropoff_longitude <= -72)) \n         & ((df.dropoff_latitude >= 38) & (df.dropoff_latitude <= 42)) \n         & (df.fare_amount > 2.5) & (df.passenger_count > 0)]\n    \n    #df = df[['fare_amount','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','distance','key']] \n    \n    df.to_csv(output_file, index=False, sep=',')\n\ndef data_refine_test(input_file, output_file, ini_row, number_of_rows):\n    \n    df = pd.read_csv(input_file, sep=',', header = None, names = header_names_test, skiprows = ini_row, nrows = number_of_rows)\n   \n    df = df[['key','pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']]\n    \n    df['distance'] = pd.concat([pd.DataFrame([distance(df['pickup_latitude'][i],df['pickup_longitude'][i],\n                                                         df['dropoff_latitude'][i],df['dropoff_longitude'][i])], \n                                               columns=['distance']) for i in range(len(df))], ignore_index=True)\n    \n    #df = df[['key','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count','distance']]\n        \n    df.to_csv(output_file, index=False, sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ceabf0b57ef91b9496df93e7c95b0a6633652a","trusted":true},"cell_type":"code","source":"input_file_train = '../input/train.csv'\ninput_file_test = '../input/test.csv'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c3b2f837106151b9af530403855983750cbb888","trusted":true},"cell_type":"code","source":"import os\n\nnumOfLines_train = int(os.popen('wc -l < ../input/train.csv').read()[:-1])\nnumOfLines_test = int(os.popen('wc -l < ../input/test.csv').read()[:-1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31dc5073f6389714b7a4dad55b85bcb6897e5a59","trusted":true},"cell_type":"code","source":"print(numOfLines_train, numOfLines_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86292a44a887ea498fec3f1c2ec9956d2716e6d7"},"cell_type":"markdown","source":"appRange100K = int(numOfLines/1000000)\nappRange100K"},{"metadata":{"_uuid":"67a86dccebb96587b1da72344c5915e7cfd13c12","trusted":true},"cell_type":"code","source":"data_refine_test(input_file_test, 'test_r0.csv', 1, numOfLines_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd7b8a4dcbeaa2f23ee413db52111c5f093873be","trusted":true},"cell_type":"code","source":"data_refine_train(input_file_train, 'train_r0.csv', 1, 1000000)\ndata_refine_train(input_file_train, 'train_r1.csv', 1000001, 1000000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7df7c6fed40d82e37d855e6b1e24d9f39b34cd5"},"cell_type":"markdown","source":"Checks"},{"metadata":{"_uuid":"247443b32f15f99962270b7a7eb409029cba8e2a"},"cell_type":"markdown","source":"NOTICE: The following lines need to be checked when the kernel is run in kaggle since we do not know were the previous files are saved exactly because they are only created when we leave the kernel, etc. CHECK!!"},{"metadata":{"_uuid":"0ae89b59cbd3c32c8c57a93bbc70839fc293632b"},"cell_type":"markdown","source":"Locally, we move this data to Python_Lab/output/ in order to keep some folder order. Therefore the following lines are \nreading from this folder, but obviuosly this is not the folder of kaggle, so we comment these lines in the kaggle version\nof this kernel. "},{"metadata":{"_uuid":"719025d23cde39436cbe0e5911d9ca133587eb14","trusted":false},"cell_type":"code","source":"#numOfLines_output_r0 = int(os.popen('wc -l < ../Python_Lab/output/train_r0.csv').read()[:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"368ecb579c7ce02eb7ce45f996612717231c2650"},"cell_type":"code","source":"#numOfLines_output_r0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5626a09aaed9d8449f301b56d99a4a8f25592f95"},"cell_type":"code","source":"#numOfLines_output_r1 = int(os.popen('wc -l < ../Python_Lab/output/train_r1.csv').read()[:-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"111ce44aba561cd16294fab0de97b325e480f4ba"},"cell_type":"code","source":"#numOfLines_output_r1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"80e41b614385feb83b231165a6d6ba981b74ee1b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}