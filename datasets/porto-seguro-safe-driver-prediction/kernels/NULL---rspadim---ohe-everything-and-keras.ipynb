{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["from other kernel....\n", "\n", "https://www.kaggle.com/rspadim/humm-float-integer-why-not-categorical"], "metadata": {"_uuid": "d0865ebd80675f1e6a3db00ca6854fc921bd8a4c", "_cell_guid": "5cb825d3-dbf6-432d-aed4-7a59cfab2812"}, "cell_type": "markdown"}, {"outputs": [], "source": ["#reading data :)\n", "import numpy as np\n", "import pandas as pd\n", "train=pd.read_csv('../input/train.csv')\n", "test =pd.read_csv('../input/test.csv')\n", "test['target']=-1 # just to match columns\n", "both=test.copy()\n", "both=both.append(train.copy())\n", "del test  #bye!\n", "del train #bye!\n", "cols=both.columns.drop(['id','target']).tolist()\n", "print('columns: ',both.columns.tolist())\n", "print('target values: ',both['target'].unique())"], "execution_count": null, "metadata": {"_uuid": "2f6546284c9f654d181e28128415998a616e2296", "_cell_guid": "6cb9e2b2-1ed7-494d-8165-99a808a7ec00"}, "cell_type": "code"}, {"outputs": [], "source": ["noncat=[]\n", "cats=[]\n", "cats_prefix={}\n", "for i in cols:\n", "    unique_train=both[both['target']!=-1][i].unique()\n", "    unique_both =both[i].unique()\n", "    equal=(sorted(unique_train) == sorted(unique_both))\n", "    length_train=len(unique_train)\n", "    length_both=len(unique_both)\n", "    print('Column: ',i,'\\t unique values at train/both=',\n", "          length_train,' / ',length_both,\n", "          '\\t <- categorical?!' if equal else ''\n", "         )\n", "    if(not equal):\n", "        noncat.append(i)\n", "    if(equal and length_both>2):\n", "        cats.append(i)\n", "        cats_prefix[i]=\"OHE_\"+i\n", "print(\"these variables should be categorical, or not?! =) \",cats)"], "execution_count": null, "metadata": {"_uuid": "2168b92678d03fb65396c217cb5e6aed5d8f80b2", "_cell_guid": "bd6f6eac-17f0-4ace-b292-efbd4635f401"}, "cell_type": "code"}, {"outputs": [], "source": ["#i will OHE to you :)\n", "both=pd.get_dummies(both,prefix=cats_prefix,columns=cats)\n", "both[both['target']!=-1].to_csv('train.cat.ohe.csv.gzip',index=False,compression='gzip')\n", "both[both['target']==-1].to_csv('test.cat.ohe.csv.gzip' ,index=False,compression='gzip')\n", "\n", "print('features:',len(both.columns.drop(['target','id']).tolist()))"], "execution_count": null, "metadata": {"_uuid": "cf3b9569476462f53ec9c4a8860c870a2c5e56c7", "_cell_guid": "bdf60734-8987-4718-92e4-df2a36effc3a"}, "cell_type": "code"}, {"outputs": [], "source": ["del both\n", "import gc\n", "gc.collect()"], "execution_count": null, "metadata": {"_uuid": "1bb84964d81ad8510c24c40494bdb9015ccf91de", "_cell_guid": "2c9e16c8-ec89-4443-8064-26a31d9673f9"}, "cell_type": "code"}, {"source": ["--------------\n", "keras\n", "\n", "from: https://www.kaggle.com/tilii7/keras-averaging-runs-gini-early-stopping"], "metadata": {"_uuid": "075d90ccdf253a5bc3bfeb4c8f6f37d98443c53b", "collapsed": true, "_cell_guid": "03a13f48-aae2-4800-90a5-e416af4df851"}, "cell_type": "markdown"}, {"outputs": [], "source": ["from datetime import datetime\n", "from sklearn.metrics import log_loss, roc_auc_score\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.preprocessing import MinMaxScaler\n", "from keras.models import load_model\n", "from keras.models import Sequential, Model\n", "from keras.layers import Input, Dense, Dropout, Activation\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger, Callback\n", "from keras.wrappers.scikit_learn import KerasClassifier"], "execution_count": null, "metadata": {}, "cell_type": "code"}, {"outputs": [], "source": ["class roc_auc_callback(Callback):\n", "    def __init__(self,training_data,validation_data):\n", "        self.x = training_data[0]\n", "        self.y = training_data[1]\n", "        self.x_val = validation_data[0]\n", "        self.y_val = validation_data[1]\n", "\n", "    def on_train_begin(self, logs={}):\n", "        return\n", "\n", "    def on_train_end(self, logs={}):\n", "        return\n", "\n", "    def on_epoch_begin(self, epoch, logs={}):\n", "        return\n", "\n", "    def on_epoch_end(self, epoch, logs={}):\n", "        y_pred = self.model.predict_proba(self.x, verbose=0)\n", "        roc = roc_auc_score(self.y, y_pred)\n", "        logs['roc_auc'] = roc_auc_score(self.y, y_pred)\n", "        logs['norm_gini'] = ( roc_auc_score(self.y, y_pred) * 2 ) - 1\n", "\n", "        y_pred_val = self.model.predict_proba(self.x_val, verbose=0)\n", "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n", "        logs['roc_auc_val'] = roc_auc_score(self.y_val, y_pred_val)\n", "        logs['norm_gini_val'] = ( roc_auc_score(self.y_val, y_pred_val) * 2 ) - 1\n", "\n", "        print('\\rroc_auc: %s - roc_auc_val: %s - norm_gini: %s - norm_gini_val: %s' % (str(round(roc,5)),str(round(roc_val,5)),str(round((roc*2-1),5)),str(round((roc_val*2-1),5))), end=10*' '+'\\n')\n", "        return\n", "\n", "    def on_batch_begin(self, batch, logs={}):\n", "        return\n", "\n", "    def on_batch_end(self, batch, logs={}):\n", "        return"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["def timer(start_time=None):\n", "    if not start_time:\n", "        start_time = datetime.now()\n", "        return start_time\n", "    elif start_time:\n", "        thour, temp_sec = divmod(\n", "            (datetime.now() - start_time).total_seconds(), 3600)\n", "        tmin, tsec = divmod(temp_sec, 60)\n", "        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n", "              (thour, tmin, round(tsec, 2)))\n", "\n", "def scale_data(X, scaler=None):\n", "    if not scaler:\n", "        scaler = MinMaxScaler(feature_range=(-1, 1))\n", "        scaler.fit(X)\n", "    X = scaler.transform(X)\n", "    return X, scaler"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["# train and test data path\n", "DATA_TRAIN_PATH = 'train.cat.ohe.csv.gzip'\n", "DATA_TEST_PATH = 'test.cat.ohe.csv.gzip'\n", "\n", "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n", "    train_loader = pd.read_csv(path_train, compression='gzip', \n", "                               dtype={'target': np.int8, 'id': np.int32})\n", "    train = train_loader.drop(['target', 'id'], axis=1)\n", "    train_labels = train_loader['target'].values\n", "    train_ids = train_loader['id'].values\n", "    print('\\n Shape of raw train data:', train.shape)\n", "\n", "    test_loader = pd.read_csv(path_test, compression='gzip', dtype={'id': np.int32})\n", "    \n", "    test = test_loader.drop(['id','target'], axis=1)\n", "    test_ids = test_loader['id'].values\n", "    print(' Shape of raw test data:', test.shape)\n", "\n", "    return train, train_labels, test, train_ids, test_ids"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["folds = 4\n", "runs = 2\n", "\n", "cv_LL = 0\n", "cv_AUC = 0\n", "cv_gini = 0\n", "fpred = []\n", "avpred = []\n", "avreal = []\n", "avids = []"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["# Load data set and target values\n", "train, target, test, tr_ids, te_ids = load_data()\n", "n_train = train.shape[0]\n", "train_test = pd.concat((train, test)).reset_index(drop=True)\n", "train_test_scaled, scaler = scale_data(train_test)\n", "train = train_test_scaled[:n_train, :]\n", "test = train_test_scaled[n_train:, :]\n", "print('\\n Shape of processed train data:', train.shape)\n", "print(' Shape of processed test data:', test.shape)"], "execution_count": null, "metadata": {}, "cell_type": "code"}, {"outputs": [], "source": ["patience = 10\n", "batchsize = 128"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["# Let's split the data into folds. I always use the same random number for reproducibility, \n", "# and suggest that you do the same (you certainly don't have to use 1001).\n", "\n", "skf = StratifiedKFold(n_splits=folds, random_state=1001)\n", "starttime = timer(None)\n", "for i, (train_index, test_index) in enumerate(skf.split(train, target)):\n", "    start_time = timer(None)\n", "    X_train, X_val = train[train_index], train[test_index]\n", "    y_train, y_val = target[train_index], target[test_index]\n", "    train_ids, val_ids = tr_ids[train_index], tr_ids[test_index]\n", "    \n", "# This is where we define and compile the model. These parameters are not optimal, as they were chosen \n", "# to get a notebook to complete in 60 minutes. Other than leaving BatchNormalization and last sigmoid \n", "# activation alone, virtually everything else can be optimized: number of neurons, types of initializers, \n", "# activation functions, dropout values. The same goes for the optimizer at the end.\n", "\n", "#########\n", "# Never move this model definition to the beginning of the file or anywhere else outside of this loop. \n", "# The model needs to be initialized anew every time you run a different fold. If not, it will continue \n", "# the training from a previous model, and that is not what you want.\n", "#########\n", "\n", "    # This definition must be within the for loop or else it will continue training previous model\n", "    def baseline_model():\n", "        model = Sequential()\n", "        model.add(\n", "            Dense(\n", "                200,\n", "                input_dim=X_train.shape[1],\n", "                kernel_initializer='glorot_normal',\n", "                ))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization())\n", "        model.add(Dropout(0.5))\n", "        model.add(Dense(100, kernel_initializer='glorot_normal'))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization())\n", "        model.add(Dropout(0.25))\n", "        model.add(Dense(50, kernel_initializer='glorot_normal'))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization())\n", "        model.add(Dropout(0.15))\n", "        model.add(Dense(25, kernel_initializer='glorot_normal'))\n", "        model.add(Activation('relu'))\n", "        model.add(BatchNormalization())\n", "        model.add(Dropout(0.1))\n", "        model.add(Dense(1, activation='sigmoid'))\n", "\n", "        # Compile model\n", "        model.compile(optimizer='adam', metrics = ['accuracy'], loss='binary_crossentropy')\n", "\n", "        return model\n", "\n", "# This is where we repeat the runs for each fold. If you choose runs=1 above, it will run a \n", "# regular N-fold procedure.\n", "\n", "#########\n", "# It is important to leave the call to random seed here, so each run starts with a different seed.\n", "#########\n", "\n", "    for run in range(runs):\n", "        print('\\n Fold %d - Run %d\\n' % ((i + 1), (run + 1)))\n", "        np.random.seed()\n", "\n", "# Lots to unpack here.\n", "\n", "# The first callback prints out roc_auc and gini values at the end of each epoch. It must be listed \n", "# before the EarlyStopping callback, which monitors gini values saved in the previous callback. Make \n", "# sure to set the mode to \"max\" because the default value (\"auto\") will not handle gini properly \n", "# (it will act as if the model is not improving even when roc/gini go up).\n", "\n", "# CSVLogger creates a record of all iterations. Not really needed but it doesn't hurt to have it.\n", "\n", "# ModelCheckpoint saves a model each time gini improves. Its mode also must be set to \"max\" for reasons \n", "# explained above.\n", "\n", "        callbacks = [\n", "            roc_auc_callback(training_data=(X_train, y_train),validation_data=(X_val, y_val)),  # call this before EarlyStopping\n", "            EarlyStopping(monitor='norm_gini_val', patience=patience, mode='max', verbose=1),\n", "            CSVLogger('keras-5fold-run-01-v1-epochs.log', separator=',', append=False),\n", "            ModelCheckpoint(\n", "                    'keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check',\n", "                    monitor='norm_gini_val', mode='max', # mode must be set to max or Keras will be confused\n", "                    save_best_only=True,\n", "                    verbose=1)\n", "        ]\n", "\n", "# The classifier is defined here. Epochs should be be set to a very large number (not 3 like below) which \n", "# will never be reached anyway because of early stopping. I usually put 5000 there. Because why not.\n", "\n", "        nnet = KerasClassifier(\n", "            build_fn=baseline_model,\n", "# Epoch needs to be set to a very large number ; early stopping will prevent it from reaching\n", "#            epochs=5000,\n", "            epochs=3,\n", "            batch_size=batchsize,\n", "            validation_data=(X_val, y_val),\n", "            verbose=2,\n", "            shuffle=True,\n", "            callbacks=callbacks)\n", "\n", "        fit = nnet.fit(X_train, y_train)\n", "        \n", "# We want the best saved model - not the last one where the training stopped. So we delete the old \n", "# model instance and load the model from the last saved checkpoint. Next we predict values both for \n", "# validation and test data, and create a summary of parameters for each run.\n", "\n", "        del nnet\n", "        nnet = load_model('keras-5fold-run-01-v1-fold-' + str('%02d' % (i + 1)) + '-run-' + str('%02d' % (run + 1)) + '.check')\n", "        scores_val_run = nnet.predict_proba(X_val, verbose=0)\n", "        LL_run = log_loss(y_val, scores_val_run)\n", "        print('\\n Fold %d Run %d Log-loss: %.5f' % ((i + 1), (run + 1), LL_run))\n", "        AUC_run = roc_auc_score(y_val, scores_val_run)\n", "        print(' Fold %d Run %d AUC: %.5f' % ((i + 1), (run + 1), AUC_run))\n", "        print(' Fold %d Run %d normalized gini: %.5f' % ((i + 1), (run + 1), AUC_run*2-1))\n", "        y_pred_run = nnet.predict_proba(test, verbose=0)\n", "        if run > 0:\n", "            scores_val = scores_val + scores_val_run\n", "            y_pred = y_pred + y_pred_run\n", "        else:\n", "            scores_val = scores_val_run\n", "            y_pred = y_pred_run\n", "            \n", "# We average all runs from the same fold and provide a parameter summary for each fold. Unless something \n", "# is wrong, the numbers printed here should be better than any of the individual runs.\n", "\n", "    scores_val = scores_val / runs\n", "    y_pred = y_pred / runs\n", "    LL = log_loss(y_val, scores_val)\n", "    print('\\n Fold %d Log-loss: %.5f' % ((i + 1), LL))\n", "    AUC = roc_auc_score(y_val, scores_val)\n", "    print(' Fold %d AUC: %.5f' % ((i + 1), AUC))\n", "    print(' Fold %d normalized gini: %.5f' % ((i + 1), AUC*2-1))\n", "    timer(start_time)\n", "    \n", "# We add up predictions on the test data for each fold. Create out-of-fold predictions for validation data.\n", "\n", "    if i > 0:\n", "        fpred = pred + y_pred\n", "        avreal = np.concatenate((avreal, y_val), axis=0)\n", "        avpred = np.concatenate((avpred, scores_val), axis=0)\n", "        avids = np.concatenate((avids, val_ids), axis=0)\n", "    else:\n", "        fpred = y_pred\n", "        avreal = y_val\n", "        avpred = scores_val\n", "        avids = val_ids\n", "    pred = fpred\n", "    cv_LL = cv_LL + LL\n", "    cv_AUC = cv_AUC + AUC\n", "    cv_gini = cv_gini + (AUC*2-1)"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["LL_oof = log_loss(avreal, avpred)\n", "print('\\n Average Log-loss: %.5f' % (cv_LL/folds))\n", "print(' Out-of-fold Log-loss: %.5f' % LL_oof)\n", "AUC_oof = roc_auc_score(avreal, avpred)\n", "print('\\n Average AUC: %.5f' % (cv_AUC/folds))\n", "print(' Out-of-fold AUC: %.5f' % AUC_oof)\n", "print('\\n Average normalized gini: %.5f' % (cv_gini/folds))\n", "print(' Out-of-fold normalized gini: %.5f' % (AUC_oof*2-1))\n", "score = str(round((AUC_oof*2-1), 5))\n", "timer(starttime)\n", "mpred = pred / folds"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["print('#\\n Writing results')\n", "now = datetime.now()\n", "oof_result = pd.DataFrame(avreal, columns=['target'])\n", "oof_result['prediction'] = avpred\n", "oof_result['id'] = avids\n", "oof_result.sort_values('id', ascending=True, inplace=True)\n", "oof_result = oof_result.set_index('id')\n", "sub_file = 'train_5fold-keras-run-01-v1-oof_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n", "print('\\n Writing out-of-fold file:  %s' % sub_file)\n", "oof_result.to_csv(sub_file, index=True, index_label='id')"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "source": ["result = pd.DataFrame(mpred, columns=['target'])\n", "result['id'] = te_ids\n", "result = result.set_index('id')\n", "print('\\n First 10 lines of your 5-fold average prediction:\\n')\n", "print(result.head(10))\n", "sub_file = 'submission_5fold-average-keras-run-01-v1_' + str(score) + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n", "print('\\n Writing submission:  %s' % sub_file)\n", "result.to_csv(sub_file, index=True, index_label='id')"], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "version": "3.6.3"}}}