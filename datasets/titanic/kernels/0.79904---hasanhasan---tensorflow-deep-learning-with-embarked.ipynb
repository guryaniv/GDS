{"cells":[{"metadata":{"_cell_guid":"515e1093-d0a2-4c52-b7c9-57c07a048366","_uuid":"17f80c275467372750be12071caea5265a17d32d"},"cell_type":"markdown","source":"# Based on Tensorflow-Deep Learning to Solve Titanic\nForked from https://www.kaggle.com/linxinzhe/tensorflow-deep-learning-to-solve-titanic by Xinzhe Lin\n\nChanges\n* Incorporates the Embarked column, converted to int and fitted.\n* Drops rows without an Embarked entry \n\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e09f3e86-e94b-b5a7-d051-586de4898f7d","_uuid":"e5136b30ee2f1e73dd2340885d3fa83d118503d4","collapsed":true,"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"009db3a9-6481-d7a3-9895-2827bdab5aed","_uuid":"bfdab4e62a0021f9bd3b006f0020a4132487e35d","collapsed":true,"trusted":true},"cell_type":"code","source":"# load data\ntrain_data = pd.read_csv(r\"../input/train.csv\")\ntest_data = pd.read_csv(r\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8e070496-f890-da5b-819d-ecae41505416","_uuid":"bd041d4298058a0dd4dd76890921f3f8766d8326","trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4690d5f5-1d18-b9d0-7fca-31494a4132fd","_uuid":"737b206e30d45d394455794fae3f0fc3825c7ee7","scrolled":true,"trusted":true},"cell_type":"code","source":"test_data","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e2e2685-776a-3e19-f6f3-1188363752c3","_uuid":"16204cb292dc2e10b54eb28ab64bf540d368cd1e","collapsed":true,"trusted":true},"cell_type":"code","source":"# Feature Engineering\nfrom sklearn.preprocessing import Imputer\n\n#Using fit_transform to fill NaN columns \ndef nan_padding(data, columns):\n    for column in columns:\n        imputer=Imputer()\n        data[column]=imputer.fit_transform(data[column].values.reshape(-1,1))\n    return data\n\n\nnan_columns = [\"Age\", \"SibSp\", \"Parch\"]\n\ntrain_data = nan_padding(train_data, nan_columns)\ntest_data = nan_padding(test_data, nan_columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"724e35ee-418d-0ef6-e3d6-25dd158a1203","_uuid":"8fccb3471e4d6a9ebca5b1ad02bbc1a5cf7ea952","trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d9e85bf0-a7eb-71f0-5102-ba0c66a9f36f","_uuid":"e58a79fede2aedc7a3eff2e0ef43b011f03bf969","collapsed":true,"trusted":true},"cell_type":"code","source":"#save PassengerId for evaluation\ntest_passenger_id=test_data[\"PassengerId\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"69f17817-2a9e-9c5d-e460-559588c4d316","_uuid":"5beabafed755159d266b09fcd0b0ef86c83a6a5a","collapsed":true,"trusted":true},"cell_type":"code","source":"def drop_not_concerned(data, columns):\n    return data.drop(columns, axis=1)\n\n# I add back in the Embarked column\nnot_concerned_columns = [\"PassengerId\",\"Name\", \"Ticket\", \"Fare\", \"Cabin\"]\ntrain_data = drop_not_concerned(train_data, not_concerned_columns)\ntest_data = drop_not_concerned(test_data, not_concerned_columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b642846b-31a6-1619-5b88-17ca2c908d6a","_uuid":"6ae148a531c2f5d967e240a5999f514d0c1a4bbe","trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27ad4c12-bcde-78ff-032b-ea58ae86fed6","_uuid":"b34caddc058f7f6074832d1cf2b2152828470ff6","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a50e8d60-454e-b402-6953-21cd95d82f33","_uuid":"31df56652344b55abc9d28ce24e5c7dcb5a35f93","collapsed":true,"trusted":true},"cell_type":"code","source":"def dummy_data(data, columns):\n    for column in columns:\n        data = pd.concat([data, pd.get_dummies(data[column], prefix=column)], axis=1)\n        data = data.drop(column, axis=1)\n    return data\n\n\ndummy_columns = [\"Pclass\"]\ntrain_data=dummy_data(train_data, dummy_columns)\ntest_data=dummy_data(test_data, dummy_columns)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3ce32d22-6e51-ce31-fe73-5b349aa6b894","_uuid":"bc90a2c1a20fb1cee4f3a89090e53db28819b95e","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e7083ea-f227-4d0a-8dd2-baee95d78bf6","_uuid":"78cd0c44c2cba2efc916ac11eb84fe614e40454c"},"cell_type":"markdown","source":"# Changes\n* Drop Rows without an Embarked Entry\n* Fit and Convert Embarked Entry into Int","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3694aa01-3ea5-4e8d-a83a-09469be19f7e","_uuid":"f6cabf3e6f9c6dbd696c6e24aa0ac5ddaabd0c37","trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"980a880b-2935-43eb-a119-da8c29895d43","_uuid":"edf675ed419bf38074fb99b322995c4629b92d53","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\ntrain_data.dropna(inplace=True)\ndef embark_to_int(data):\n    le = LabelEncoder()\n    le.fit([\"S\",\"Q\",\"C\"])\n    data[\"Embarked\"]=le.transform(data[\"Embarked\"].astype(str)) \n    return data\n\ntrain_data = embark_to_int(train_data)\ntest_data = embark_to_int(test_data)\ntrain_data.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"93cd9d05-6ab1-42c2-6222-f16ae21be706","_uuid":"65f64caa45346e2645749687880d2dc9e15cd9a8","trusted":true},"cell_type":"code","source":"\ndef sex_to_int(data):\n    le = LabelEncoder()\n    le.fit([\"male\",\"female\"])\n    data[\"Sex\"]=le.transform(data[\"Sex\"]) \n    return data\n\ntrain_data = sex_to_int(train_data)\ntest_data = sex_to_int(test_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a6d562ac-cfe1-9ce2-53fa-4b2789812d9f","_uuid":"e74d85fd5020175d83e7458455e590cffd91bbd5","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndef normalize_age(data):\n    scaler = MinMaxScaler()\n    data[\"Age\"] = scaler.fit_transform(data[\"Age\"].values.reshape(-1,1))\n    return data\ntrain_data = normalize_age(train_data)\ntest_data = normalize_age(test_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6de2351b-7efb-f681-7b7b-74a6e9d5883d","_uuid":"0d671cce1c310593d36c872a09767cc14a151c84","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\ndef split_valid_test_data(data, fraction=(1 - 0.8)):\n    data_y = data[\"Survived\"]\n    lb = LabelBinarizer()\n    data_y = lb.fit_transform(data_y)\n\n    data_x = data.drop([\"Survived\"], axis=1)\n\n    train_x, valid_x, train_y, valid_y = train_test_split(data_x, data_y, test_size=fraction)\n\n    return train_x.values, train_y, valid_x, valid_y\n\ntrain_x, train_y, valid_x, valid_y = split_valid_test_data(train_data)\nprint(\"train_x:{}\".format(train_x.shape))\nprint(\"train_y:{}\".format(train_y.shape))\nprint(\"train_y content:{}\".format(train_y[:3]))\n\nprint(\"valid_x:{}\".format(valid_x.shape))\nprint(\"valid_y:{}\".format(valid_y.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b18da52c-396a-466c-b13c-3d9c55ab7ea5","_uuid":"d739bce5b8d7adadee838f14f9e6609b701f6dfd","collapsed":true,"trusted":true},"cell_type":"code","source":"# Build Neural Network\nfrom collections import namedtuple\n\ndef build_neural_network(hidden_units=10):\n    tf.reset_default_graph()\n    inputs = tf.placeholder(tf.float32, shape=[None, train_x.shape[1]])\n    labels = tf.placeholder(tf.float32, shape=[None, 1])\n    learning_rate = tf.placeholder(tf.float32)\n    is_training=tf.Variable(True,dtype=tf.bool)\n    \n    initializer = tf.contrib.layers.xavier_initializer()\n    fc = tf.layers.dense(inputs, hidden_units, activation=None,kernel_initializer=initializer)\n    fc=tf.layers.batch_normalization(fc, training=is_training)\n    fc=tf.nn.relu(fc)\n    \n    logits = tf.layers.dense(fc, 1, activation=None)\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n    cost = tf.reduce_mean(cross_entropy)\n    \n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n    predicted = tf.nn.sigmoid(logits)\n    correct_pred = tf.equal(tf.round(predicted), labels)\n    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n\n    # Export the nodes \n    export_nodes = ['inputs', 'labels', 'learning_rate','is_training', 'logits',\n                    'cost', 'optimizer', 'predicted', 'accuracy']\n    Graph = namedtuple('Graph', export_nodes)\n    local_dict = locals()\n    graph = Graph(*[local_dict[each] for each in export_nodes])\n\n    return graph\n\nmodel = build_neural_network()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"55b103de-7ae0-389a-7b8a-0452fbef28c1","_uuid":"afcfa09da528673d6a091e87577783ac0a6dc894","collapsed":true,"trusted":true},"cell_type":"code","source":"def get_batch(data_x,data_y,batch_size=32):\n    batch_n=len(data_x)//batch_size\n    for i in range(batch_n):\n        batch_x=data_x[i*batch_size:(i+1)*batch_size]\n        batch_y=data_y[i*batch_size:(i+1)*batch_size]\n        \n        yield batch_x,batch_y","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27030dd0-a904-b53e-6165-2d7d7e4ee608","_uuid":"4e250f2ff03aaf66b94156a07aab904ead5afec5","trusted":true},"cell_type":"code","source":"epochs = 200\ntrain_collect = 50\ntrain_print=train_collect*2\n\nlearning_rate_value = 0.001\nbatch_size=16\n\nx_collect = []\ntrain_loss_collect = []\ntrain_acc_collect = []\nvalid_loss_collect = []\nvalid_acc_collect = []\n\nsaver = tf.train.Saver()\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    iteration=0\n    for e in range(epochs):\n        for batch_x,batch_y in get_batch(train_x,train_y,batch_size):\n            iteration+=1\n            feed = {model.inputs: train_x,\n                    model.labels: train_y,\n                    model.learning_rate: learning_rate_value,\n                    model.is_training:True\n                   }\n\n            train_loss, _, train_acc = sess.run([model.cost, model.optimizer, model.accuracy], feed_dict=feed)\n            \n            if iteration % train_collect == 0:\n                x_collect.append(e)\n                train_loss_collect.append(train_loss)\n                train_acc_collect.append(train_acc)\n\n                if iteration % train_print==0:\n                     print(\"Epoch: {}/{}\".format(e + 1, epochs),\n                      \"Train Loss: {:.4f}\".format(train_loss),\n                      \"Train Acc: {:.4f}\".format(train_acc))\n                        \n                feed = {model.inputs: valid_x,\n                        model.labels: valid_y,\n                        model.is_training:False\n                       }\n                val_loss, val_acc = sess.run([model.cost, model.accuracy], feed_dict=feed)\n                valid_loss_collect.append(val_loss)\n                valid_acc_collect.append(val_acc)\n                \n                if iteration % train_print==0:\n                    print(\"Epoch: {}/{}\".format(e + 1, epochs),\n                      \"Validation Loss: {:.4f}\".format(val_loss),\n                      \"Validation Acc: {:.4f}\".format(val_acc))\n                \n\n    saver.save(sess, \"./titanic.ckpt\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ed01203-e9b6-423d-045d-11e6194a59f9","_uuid":"cfe1e4ac0d4b3c3e2aaf2b92d7afc9380b93e322","trusted":true},"cell_type":"code","source":"plt.plot(x_collect, train_loss_collect, \"r--\")\nplt.plot(x_collect, valid_loss_collect, \"g^\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26749357-f1eb-8112-2f5f-7b15134f31e6","_uuid":"489470e2db70dee6bf218e59712beac7ec93e740","trusted":true},"cell_type":"code","source":"plt.plot(x_collect, train_acc_collect, \"r--\")\nplt.plot(x_collect, valid_acc_collect, \"g^\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1336e1c-7d5e-c200-bcbb-24a7bb8d6bb7","_uuid":"ba9a2c9db62b4d23cb33e4236617cefa37947920","trusted":true},"cell_type":"code","source":"model=build_neural_network()\nrestorer=tf.train.Saver()\nwith tf.Session() as sess:\n    restorer.restore(sess,\"./titanic.ckpt\")\n    feed={\n        model.inputs:test_data,\n        model.is_training:False\n    }\n    test_predict=sess.run(model.predicted,feed_dict=feed)\n    \ntest_predict[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc7801f4-88e2-9140-5313-17c444506dde","_uuid":"d90aff8b86c1335818a4fdbeff23bf2421c13d93","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Binarizer\nbinarizer=Binarizer(0.5)\ntest_predict_result=binarizer.fit_transform(test_predict)\ntest_predict_result=test_predict_result.astype(np.int32)\ntest_predict_result[:10]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"461ee38a-4b8f-a1af-4448-d2503ccc9be3","_uuid":"ba902e38493bc510456aba475fbf5a03af5e3d81","trusted":true},"cell_type":"code","source":"passenger_id=test_passenger_id.copy()\nevalu = passenger_id.to_frame(\"PassengerId\")\nevalu['Survived'] = test_predict_result\nevalu","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"15867098-96d8-9878-83b1-9741711928cc","_uuid":"79eabf9345329ddf8c8112c56365157e53d131e9","collapsed":true,"trusted":true},"cell_type":"code","source":"evalu.to_csv(\"evaluation.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}