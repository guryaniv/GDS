{"metadata": {"language_info": {"file_extension": ".py", "name": "python", "version": "3.6.1", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "6e4d701a-b37c-44b1-b9c8-9d82acbc451a", "_uuid": "05e11db0fa8e8a17f34b7a3d5d90290109c40d07", "collapsed": true}, "cell_type": "code", "source": ["# crawling data from 2017-09-01 to 2017-09-07\n", "import urllib\n", "import pandas as pd\n", "import numpy as np\n", "import multiprocessing\n", "import warnings\n", "import json\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "def get_views(web_info):\n", "    global date\n", "    url = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/' \\\n", "    '{0}/{1}/{2}/{3}/daily/{4}/{5}'\\\n", "    .format(web_info[1], web_info[2], web_info[3], web_info[0], date[0], date[-1])\n", "    res = np.array([np.nan for i in date])\n", "    try:\n", "        url = urllib.request.urlopen(url)\n", "        api_res = json.loads(url.read().decode())['items']\n", "    except:\n", "        return res\n", "    \n", "    for i in api_res:\n", "        time = i['timestamp'][0:-2]\n", "        res[date.index(time)] = i['views']\n", "    \n", "    return res\n", "\n", "def get_views_main(input_page):\n", "    pool_size = multiprocessing.cpu_count()*2\n", "    pool = multiprocessing.Pool(processes=pool_size)\n", "    res = pool.map(get_views, input_page)\n", "    pool.close()\n", "    pool.join()\n", "    return res\n", "\n", "date = [\n", "    '20170901', \n", "    '20170902', \n", "    '20170903',\n", "    '20170904',\n", "    '20170905',\n", "    '20170906',\n", "    '20170907'\n", "]\n", "\n", "pages = pd.read_csv(\"../input/train_2.csv\", usecols=['Page'], nrows=2)\n", "page_details = pd.DataFrame([i.split(\"_\")[-4:] for i in pages[\"Page\"]],\n", "                            columns=[\"name\", \"project\", \"access\", \"agent\"])\n", "\n", "page_web_traffic = np.array(get_views_main(page_details.values))\n", "# results:\n", "# array([[ 19.,  33.,  33.,  18.,  16.,  27.,  29.],\n", "#        [ 32.,  30.,  11.,  19.,  54.,  25.,  26.]])"], "outputs": [], "execution_count": null}], "nbformat": 4}