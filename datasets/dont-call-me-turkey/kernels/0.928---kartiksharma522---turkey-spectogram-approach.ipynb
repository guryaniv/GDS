{"cells":[{"metadata":{"_uuid":"28c393edb79083325c9d2db2b001681494abd1a4"},"cell_type":"markdown","source":"## Converting the embedding to spectogram\n### This is to be able to use CNN for the task of identification of Turkey voice|"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport keras\nimport seaborn as sns\nimport os\nfrom scipy import signal\nprint(os.listdir(\"../input\"))\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom multiprocessing import Pool\nimport scipy","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_json(\"../input/train.json\")\ntest_df = pd.read_json(\"../input/test.json\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4741e4a58834a7548beccb4bf6f37de414534f85"},"cell_type":"code","source":"sns.countplot(data = train_df, x = \"is_turkey\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8166bada72e8fa21430de0c37ce77faa5507f4ef"},"cell_type":"code","source":"train_df[\"audio_embedding\"] = train_df[\"audio_embedding\"].apply(lambda x: np.asarray(x).reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d7fe3516337a48f0b8bf54659d31ab0307effc0"},"cell_type":"code","source":"plt.plot(train_df[\"audio_embedding\"].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d37a99e5c17540d4bb8674429f7eac715f5eddc"},"cell_type":"code","source":"train_df[\"audio_embedding\"] = train_df[\"audio_embedding\"].apply(lambda x: x - x.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32fb2fbcd3a06d1b54ca487337f3e8b3c17f4d0c"},"cell_type":"code","source":"plt.plot(train_df[\"audio_embedding\"].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34dc5b2d9d985ba4714adc2037d14f4bb5df2aba"},"cell_type":"code","source":"def spect(i):\n    f, t, Sxx = signal.spectrogram(np.array(train_df[\"audio_embedding\"].iloc[i]).reshape(-1))\n    my_dpi = 100\n    plt.figure(figsize=(525/my_dpi, 783/my_dpi), dpi=my_dpi)\n    plt.pcolormesh(t, f, Sxx)\n    plt.axis('off')\n    plt.savefig(\"./{}.png\".format(i), bbox_inches='tight', dpi=my_dpi, frameon='false')\n    plt.clf()\n    plt.close('all')\n    img_file = scipy.misc.imresize(arr=plt.imread(\"./{}.png\".format(i)), size=(640, 465, 3))\n    img_arr = np.asarray(img_file)\n    return img_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3087b71ae7452442f1aede2b9d6597be59bedb33"},"cell_type":"code","source":"with Pool(2) as p:\n    f = list(tqdm(p.imap(spect, range(train_df.shape[0])), total=train_df.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51c17e078f3229a9d73a2fc36c9bee5bf84385f8"},"cell_type":"markdown","source":"### The file labeling is done as index_no.png"},{"metadata":{"trusted":true,"_uuid":"8ebff906248e8a1c7d1c691653351a8805263fd4"},"cell_type":"code","source":"import subprocess as sp\nplt.imshow(plt.imread(\"./0.png\"))\nplt.axis(\"off\")\nplt.show()\nplt.imshow(plt.imread(\"./1.png\"))\nplt.axis(\"off\")\nplt.show()\nplt.imshow(plt.imread(\"./2.png\"))\nplt.axis(\"off\")\nplt.show()\nsp.getoutput(\"rm -rf *.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c3d024c0afb7a13ebc2825c7cba9a50c379d27f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae356a61a0ff1ebae5995f4322573cf8be164a8c"},"cell_type":"code","source":"plt.imshow(f[0])\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8550255a41f5604958ea9d481ec78cb7b5a96a9c"},"cell_type":"code","source":"from keras.layers import Dense, MaxPool2D, Conv2D, Reshape, Input, BatchNormalization, Flatten\nfrom keras.models import Model\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85caccb07f346867ce801adfc0e466746f509645"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf4462d2bfc9b16ac1c17422ab8fd94ce1d1f029"},"cell_type":"code","source":"def mymodel():\n    inp = Input(shape=(640, 465, 4,))\n    k = BatchNormalization()(inp)\n    k = Conv2D(32, (7,7), padding=\"same\",activation=\"relu\",strides=(2,2))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k) \n    k = Conv2D(32, (3,3), padding=\"same\",activation=\"relu\",strides=(1,1))(k)\n    k = MaxPool2D(pool_size=(3, 3), padding=\"same\",strides=(2,2))(k)\n    k = Conv2D(32, (3,3), padding=\"same\",activation=\"relu\")(k)\n    k = Conv2D(32, (3,3), padding=\"same\",activation=\"relu\")(k)\n    k = MaxPool2D(pool_size=(2, 2), padding=\"same\",strides=(1,1))(k)\n    k = Flatten()(k)\n    y = Dense(2,activation=\"softmax\")(k)\n    model = Model(inp, y)\n    opt = optimizers.Adam(lr=0.01,decay=0.0001)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=\"adam\",\n                  metrics=['accuracy'])\n    return model\nmodel = mymodel()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3f5f8b39b0414aac3ce2176b96399f69a57bd7d"},"cell_type":"code","source":"filepath = \"./weight_tr5.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\nhistory = model.fit(np.asarray(f),\n         pd.get_dummies(train_df['is_turkey']),\n         epochs = 100,\n         batch_size = 128,\n         validation_split=0.2,\n         callbacks = callbacks_list,\n         verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ccb84d1ffa7801de173535c237e9de06dd78fe2"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5c227a474fa6aeba2e778931da1912a12b9625f"},"cell_type":"code","source":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b0491a9bbd15752c3f5b741bf909ee232bd8888"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}