{"cells":[{"metadata":{"_uuid":"35d3ba8203269065091b6506e1f79894a4804d46"},"cell_type":"markdown","source":"Image Statistics on PetFinder images.\n\nTechniques and ideas from Shivam Banshal's notebook: https://www.kaggle.com/shivamb/ideas-for-image-features-and-image-quality/notebook"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from collections import defaultdict\nfrom scipy.stats import itemfreq\nfrom scipy import ndimage as ndi\nimport matplotlib.pyplot as plt\nfrom skimage import feature\nfrom PIL import Image as IMG\nimport numpy as np\nimport pandas as pd \nimport operator\nimport cv2\nimport os \n\nfrom IPython.core.display import HTML \nfrom IPython.display import Image\n\nimages_path = '../input/train_images/'\nimgs = os.listdir(images_path)\n\nfeatures = pd.DataFrame()\nfeatures['image'] = imgs","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"features = features.loc[['-1.' in x for x in features.image]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4414b6f06ee339abbef880f2556242c874a7284"},"cell_type":"code","source":"images_path = '../input/test_images/'\nimgs = os.listdir(images_path)\n\nfeatures_test = pd.DataFrame()\nfeatures_test['image'] = imgs\nfeatures_test = features_test.loc[['-1.' in x for x in features_test.image]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ffc8302cfcf9d12012f1792c94ef442bd59b3a5"},"cell_type":"code","source":"def color_analysis(img):\n    # obtain the color palatte of the image \n    palatte = defaultdict(int)\n    for pixel in img.getdata():\n        palatte[pixel] += 1\n    \n    # sort the colors present in the image \n    sorted_x = sorted(palatte.items(), key=operator.itemgetter(1), reverse = True)\n    \n    light_shade, dark_shade, shade_count, pixel_limit = 0, 0, 0, 1000\n    for i, x in enumerate(sorted_x[:pixel_limit]):\n        if all(xx <= 20 for xx in x[0][:3]): ## dull : too much darkness \n            dark_shade += x[1]\n        if all(xx >= 240 for xx in x[0][:3]): ## bright : too much whiteness \n            light_shade += x[1]\n        shade_count += x[1]\n        \n    light_percent = round((float(light_shade)/shade_count)*100, 2)\n    dark_percent = round((float(dark_shade)/shade_count)*100, 2)\n    return light_percent, dark_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"291d47b60ce6238560725f0397416be2ef173f37"},"cell_type":"code","source":"def perform_color_analysis(img):\n\n    path = images_path + img \n    im = IMG.open(path) #.convert(\"RGB\")\n    \n    # cut the images into two halves as complete average may give bias results\n    size = im.size\n    halves = (size[0]/2, size[1]/2)\n    im1 = im.crop((0, 0, size[0], halves[1]))\n    im2 = im.crop((0, halves[1], size[0], size[1]))\n\n    try:\n        light_percent1, dark_percent1 = color_analysis(im1)\n        light_percent2, dark_percent2 = color_analysis(im2)\n    except Exception as e:\n        light_percent1, dark_percent1 = -1, -1\n        light_percent2, dark_percent2 = -1, -1\n\n    light_percent = (light_percent1 + light_percent2)/2 \n    dark_percent = (dark_percent1 + dark_percent2)/2 \n    \n    return dark_percent, light_percent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b0d71780330cba3d92a459a32b453d36f8b100c"},"cell_type":"code","source":"from tqdm import tqdm\ntqdm.pandas()\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a170563500910f6d1d2850e7f7e218eaf523a509"},"cell_type":"code","source":"images_path='../input/train_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84410423d395b35a81687926f10e6f7d6e5d7196"},"cell_type":"code","source":"start=time.time()\nfeatures['dullness_whiteness'] = features['image'].apply(lambda x : perform_color_analysis(x))\nprint(time.time()-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2dd9e35417422e07ea2d29db0ab6d41063c620a"},"cell_type":"code","source":"features['dullness'] = features.dullness_whiteness.map(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"219ea0c4357ab93f39b319e1a71260aaf94e2190"},"cell_type":"code","source":"features['whiteness'] = features.dullness_whiteness.map(lambda x: x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8188945fc24b297de54a061ec0813200bd838eb"},"cell_type":"code","source":"topdull = features.sort_values('dullness', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"80ce5c7e82892b73504c1f3302e7ab442efc27a6"},"cell_type":"code","source":"for j,x in topdull.head(5).iterrows():\n    \n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8d896960024f679f4421ef26ffb5924d2b902c7"},"cell_type":"code","source":"topbright = features.sort_values('whiteness', ascending = False)\nfor j,x in topbright.head(5).iterrows():\n    images_path='../input/train_images/'\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Dullness : \" + str(x['dullness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e1bcb62257489753afcb1a2a8d994320ee42044"},"cell_type":"code","source":"def average_pixel_width(img):\n    path = images_path + img \n    im = IMG.open(path)    \n    im_array = np.asarray(im.convert(mode='L'))\n    edges_sigma1 = feature.canny(im_array, sigma=3)\n    apw = (float(np.sum(edges_sigma1)) / (im.size[0]*im.size[1]))\n    return apw*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e833ebccbd12707d50dbca3b4cbd4915502e7867"},"cell_type":"code","source":"features['average_pixel_width'] = features['image'].apply(average_pixel_width)\ntempdf = features.sort_values('average_pixel_width').head()\ntempdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64f37db6a6b87417964bc72ad9a3d58a3db3737d"},"cell_type":"code","source":"for j,x in tempdf.head(6).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Average Pixel Width : \" + str(x['average_pixel_width']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"320ba0f5c1a832089baac9472085fbd4c62b6ab7"},"cell_type":"code","source":"def getSize(filename):\n    filename = images_path + filename\n    st = os.stat(filename)\n    return st.st_size\n\ndef getDimensions(filename):\n    filename = images_path + filename\n    img_size = IMG.open(filename).size\n    return img_size ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b0d52101595e7bce0c13bdad34557ef145b12e3"},"cell_type":"code","source":"features['image_size'] = features['image'].apply(getSize)\nfeatures['temp_size'] = features['image'].apply(getDimensions)\nfeatures['width'] = features['temp_size'].apply(lambda x : x[0])\nfeatures['height'] = features['temp_size'].apply(lambda x : x[1])\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfb30c1010b4b4b6c1005a2c82147e12653f488f"},"cell_type":"code","source":"def get_blurrness_score(image):\n    path =  images_path + image \n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    fm = cv2.Laplacian(image, cv2.CV_64F).var()\n    return fm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dece2f360d978158b3442af02453f7a26bba97bd"},"cell_type":"code","source":"features['blurrness'] = features['image'].apply(get_blurrness_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cf9a9ac884603cef5399618061a32a983faf55c"},"cell_type":"code","source":"tempdf = features.sort_values('blurrness')\nfor y,x in tempdf.head(5).iterrows():\n    path = images_path + x['image']\n    html = \"<h4>Image : \"+x['image']+\" &nbsp;&nbsp;&nbsp; (Blurrness : \" + str(x['blurrness']) +\")</h4>\"\n    display(HTML(html))\n    display(IMG.open(path).resize((300,300), IMG.ANTIALIAS))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"876069a4ad5d91cd577eaf54b34ac6796fd9a796"},"cell_type":"code","source":"images_path='../input/test_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71c0f49f8d67335af28ebb2aa1d8abea736fa6b3"},"cell_type":"code","source":"start=time.time()\nfeatures_test['dullness_whiteness'] = features_test['image'].apply(lambda x : perform_color_analysis(x))\nprint(time.time()-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"171a254512d2b267401cd1d33e0c69aadaf978e2"},"cell_type":"code","source":"features_test['dullness'] = features_test.dullness_whiteness.map(lambda x: x[0])\nfeatures_test['whiteness'] = features_test.dullness_whiteness.map(lambda x: x[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b86b52522426508fdcb1a8fa7c6b6a9cf6fd13"},"cell_type":"code","source":"features_test['average_pixel_width'] = features_test['image'].apply(average_pixel_width)\nfeatures_test['image_size'] = features_test['image'].apply(getSize)\nfeatures_test['temp_size'] = features_test['image'].apply(getDimensions)\nfeatures_test['width'] = features_test['temp_size'].apply(lambda x : x[0])\nfeatures_test['height'] = features_test['temp_size'].apply(lambda x : x[1])\nfeatures_test['blurrness'] = features_test['image'].apply(get_blurrness_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde4a245097d9d72f8ab18bfb133f611a9fbf3f9"},"cell_type":"code","source":"features.to_csv('train_image.csv',index=False)\nfeatures_test.to_csv('test_image.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}