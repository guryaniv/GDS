{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom tensorflow.keras.models import Sequential\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ce02603d1cb61f7cc1a893b2c0a46bf069b1c47"},"cell_type":"code","source":"train_dir = \"../input/train/train/\"\ntest_dir = \"../input/test/test/\"\ntrain_df = pd.read_csv('../input/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18696a140232bc437a097852473239c7519f6871"},"cell_type":"code","source":"im = cv2.imread(\"../input/train/train/01e30c0ba6e91343a12d2126fcafc0dd.jpg\")\nplt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4290802c9484d9cf8afe14a975423531c64e18f"},"cell_type":"code","source":"ResNet50_net = VGG16(weights='imagenet', \n                     include_top=False, \n                     input_shape=(32, 32, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"070ea255ed183fd2e9636b978db571b86b2bdd7d"},"cell_type":"code","source":"ResNet50_net.trainable = False\nResNet50_net.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c021705cdba972c0bbfbbef00d9b1e145617832"},"cell_type":"code","source":"model = Sequential()\nmodel.add(ResNet50_net)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd4058441c2d95abe9e28a4e713b3e66947dea0f"},"cell_type":"code","source":"# def sigmoid(x):\n    # return 1.0/(1.0 + np.exp(-x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"095873841e26099e0fc549a3356d3de2c6fa287b"},"cell_type":"code","source":"# def binary_crossentropy(y_true, y_pred):\n    # return K.mean(K.binary_crossentropy(y_true, K.sigmoid(y_pred)), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"088a5fe47727a896187abd98dda397f2ef8f0759"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=Adam(lr=1e-5), \n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f19d0ac61d1406e1e2fe1ab898b19fccdd103ef7"},"cell_type":"code","source":"X_tr = []\nY_tr = []\nimges = train_df['id'].values\nfor img_id in tqdm_notebook(imges):\n    X_tr.append(cv2.imread(train_dir + img_id))    \n    Y_tr.append(train_df[train_df['id'] == img_id]['has_cactus'].values[0])  \nX_tr = np.asarray(X_tr)\nX_tr = X_tr.astype('float32')\nX_tr /= 255\nY_tr = np.asarray(Y_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f65fafb60815cbf6c624d82ffcdcdba5d456f1dc"},"cell_type":"code","source":"batch_size = 32\nnb_epoch = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8775e8e67e1c20c811cf0a40ea5259c1bcf41d36"},"cell_type":"code","source":"datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\\n\",\n                             samplewise_center=False,  # set each sample mean to 0\\n\",\n                             featurewise_std_normalization=False,  # divide inputs by dataset std\\n\",\n                             samplewise_std_normalization=False,  # divide each input by its std\\n\",\n                             zca_whitening=False,  # apply ZCA whitening\\n\",\n                             zca_epsilon=1e-06,  # epsilon for ZCA whitening\\n\",\n                             rotation_range=40,  # SET TO 0 IF NEEDED # randomly rotate images in 0 to 180 degrees\\n\",\n                             width_shift_range=0.2,  # randomly shift images horizontally\\n\",\n                             height_shift_range=0.2,  # randomly shift images vertically\\n\",\n                             shear_range=0.2,  # set range for random shear\\n\",\n                             zoom_range=0.2,  # set range for random zoom\\n\",\n                             channel_shift_range=0.,  # set range for random channel shifts\\n\",\n                             fill_mode='nearest',\n                             validation_split=0.1)  # set mode for filling points outside the input\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ndatagen.fit(X_tr)\n\n# fits the model on batches with real-time data augmentation:\nmodel.fit_generator(datagen.flow(X_tr, Y_tr, batch_size=batch_size, subset='training'), validation_data=datagen.flow(X_tr, Y_tr, batch_size=batch_size, subset='validation'), steps_per_epoch=len(X_tr) / batch_size, epochs=nb_epoch, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcc84aadd3649f68bc8243c5da4b5b28ea23e934"},"cell_type":"code","source":"pretrained = True\n\n\"\"\"\n%%time\n# Train model\nhistory = model.fit(X_tr, Y_tr,\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              validation_split=0.1,\n              shuffle=True,\n              verbose=2)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d3b65c4f037811a2dd5c10dfe7aa73ecbf18f66"},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"886bbad30809f3f625131c5dbe8ad81fad59775f"},"cell_type":"code","source":"%%time\nX_tst = []\nTest_imgs = []\nfor img_id in tqdm_notebook(os.listdir(test_dir)):\n    X_tst.append(cv2.imread(test_dir + img_id))     \n    Test_imgs.append(img_id)\nX_tst = np.asarray(X_tst)\nX_tst = X_tst.astype('float32')\nX_tst /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87b606b5682862e89e6a636bb6741c5322aa7f94"},"cell_type":"code","source":"# Prediction\ntest_predictions = model.predict(X_tst) # sigmoid(model.predict(X_tst))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef44e90a01a71ac344a9e9fcd132a579f6ac4e17"},"cell_type":"code","source":"sub_df = pd.DataFrame(test_predictions, columns=['has_cactus'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf15ba71202c72f5de2b267facc3fc61ee4e2662"},"cell_type":"code","source":"sub_df['id'] = ''\ncols = sub_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nsub_df=sub_df[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e1020972a7237cbdcfee5604a66ebcdf5e2dcd3"},"cell_type":"code","source":"for i, img in enumerate(Test_imgs):\n    sub_df.set_value(i,'id',img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d39f86acffc3043e9bc0e99f95b820b5a400e8f"},"cell_type":"code","source":"sub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5544610769599ff02920e239e78590ddd93e0e6f"},"cell_type":"code","source":"sub_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}