{"cells":[{"metadata":{"trusted":true,"_uuid":"86d941977779b6e386db168ea510fb29f5923d5d"},"cell_type":"code","source":"# Based on excellent script by @olivier\n#\n# https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm\n#\n# My additions and changes:\n#\n# StratifiedKFold instead of KFold\n# LightGBM parameters found by Bayesian optimization ( https://github.com/fmfn/BayesianOptimization )\n# Out-of-fold file saved for downstream use in ensembling\n#\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, average_precision_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom lightgbm import LGBMClassifier\nfrom datetime import datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f77580629f0cd8f024e4676306f1ca453cc24a2"},"cell_type":"code","source":"def build_model_input():\n    buro_bal = pd.read_csv('../input/bureau_balance.csv')\n    print('Buro bal shape : ', buro_bal.shape)\n\n    print('transform to dummies')\n    buro_bal = pd.concat(\n        [buro_bal, pd.get_dummies(buro_bal.STATUS, prefix='buro_bal_status')],\n        axis=1).drop(\n            'STATUS', axis=1)\n\n    print('Counting buros')\n    buro_counts = buro_bal[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n    buro_bal['buro_count'] = buro_bal['SK_ID_BUREAU'].map(buro_counts['MONTHS_BALANCE'])\n\n    print('averaging buro bal')\n    avg_buro_bal = buro_bal.groupby('SK_ID_BUREAU').mean()\n\n    avg_buro_bal.columns = ['avg_buro_' + f_ for f_ in avg_buro_bal.columns]\n    del buro_bal\n    gc.collect()\n\n    print('Read Bureau')\n    buro = pd.read_csv('../input/bureau.csv')\n\n    print('Go to dummies')\n    buro_credit_active_dum = pd.get_dummies(buro.CREDIT_ACTIVE, prefix='ca_')\n    buro_credit_currency_dum = pd.get_dummies(buro.CREDIT_CURRENCY, prefix='cu_')\n    buro_credit_type_dum = pd.get_dummies(buro.CREDIT_TYPE, prefix='ty_')\n\n    buro_full = pd.concat(\n        [\n            buro, buro_credit_active_dum, buro_credit_currency_dum,\n            buro_credit_type_dum\n        ],\n        axis=1)\n\n    del buro_credit_active_dum, buro_credit_currency_dum, buro_credit_type_dum\n    gc.collect()\n\n    print('Merge with buro avg')\n    buro_full = buro_full.merge(\n        right=avg_buro_bal.reset_index(),\n        how='left',\n        on='SK_ID_BUREAU',\n        suffixes=('', '_bur_bal'))\n\n    print('Counting buro per SK_ID_CURR')\n    nb_bureau_per_curr = buro_full[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n    buro_full['SK_ID_BUREAU'] = buro_full['SK_ID_CURR'].map(nb_bureau_per_curr['SK_ID_BUREAU'])\n\n    print('Averaging bureau')\n    avg_buro = buro_full.groupby('SK_ID_CURR').mean()\n    print(avg_buro.head())\n\n    del buro, buro_full\n    gc.collect()\n\n    print('Read prev')\n    prev = pd.read_csv('../input/previous_application.csv')\n\n    prev_cat_features = [\n        f_ for f_ in prev.columns if prev[f_].dtype == 'object'\n    ]\n\n    print('Go to dummies')\n    prev_dum = pd.DataFrame()\n    for f_ in prev_cat_features:\n        prev_dum = pd.concat(\n            [prev_dum, pd.get_dummies(prev[f_], prefix=f_).astype(np.uint8)],\n            axis=1)\n\n    prev = pd.concat([prev, prev_dum], axis=1)\n\n    del prev_dum\n    gc.collect()\n\n    print('Counting number of Prevs')\n    nb_prev_per_curr = prev[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    prev['SK_ID_PREV'] = prev['SK_ID_CURR'].map(nb_prev_per_curr['SK_ID_PREV'])\n\n    print('Averaging prev')\n    avg_prev = prev.groupby('SK_ID_CURR').mean()\n    print(avg_prev.head())\n    del prev\n    gc.collect()\n\n    print('Reading POS_CASH')\n    pos = pd.read_csv('../input/POS_CASH_balance.csv')\n\n    print('Go to dummies')\n    pos = pd.concat([pos, pd.get_dummies(pos['NAME_CONTRACT_STATUS'])], axis=1)\n\n    print('Compute nb of prevs per curr')\n    nb_prevs = pos[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    pos['SK_ID_PREV'] = pos['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n\n    print('Go to averages')\n    avg_pos = pos.groupby('SK_ID_CURR').mean()\n\n    del pos, nb_prevs\n    gc.collect()\n\n    print('Reading CC balance')\n    cc_bal = pd.read_csv('../input/credit_card_balance.csv')\n\n    print('Go to dummies')\n    cc_bal = pd.concat(\n        [\n            cc_bal, pd.get_dummies(\n                cc_bal['NAME_CONTRACT_STATUS'], prefix='cc_bal_status_')\n        ],\n        axis=1)\n\n    nb_prevs = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    cc_bal['SK_ID_PREV'] = cc_bal['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n\n    print('Compute average')\n    avg_cc_bal = cc_bal.groupby('SK_ID_CURR').mean()\n    avg_cc_bal.columns = ['cc_bal_' + f_ for f_ in avg_cc_bal.columns]\n\n    del cc_bal, nb_prevs\n    gc.collect()\n\n    print('Reading Installments')\n    inst = pd.read_csv('../input/installments_payments.csv')\n    nb_prevs = inst[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n    inst['SK_ID_PREV'] = inst['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n\n    avg_inst = inst.groupby('SK_ID_CURR').mean()\n    avg_inst.columns = ['inst_' + f_ for f_ in avg_inst.columns]\n\n    print('Read data and test')\n    data = pd.read_csv('../input/application_train.csv')\n    test = pd.read_csv('../input/application_test.csv')\n    print('Shapes : ', data.shape, test.shape)\n\n    y = data['TARGET']\n    ids = data['SK_ID_CURR']\n    del data['TARGET']\n\n    categorical_feats = [f for f in data.columns if data[f].dtype == 'object']\n    categorical_feats\n    for f_ in categorical_feats:\n        data[f_], indexer = pd.factorize(data[f_])\n        test[f_] = indexer.get_indexer(test[f_])\n\n    data = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\n\n    data = data.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_prev.reset_index(), how='left', on='SK_ID_CURR')\n\n    data = data.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_pos.reset_index(), how='left', on='SK_ID_CURR')\n\n    data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n\n    data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n    test = test.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n\n    del avg_buro, avg_prev\n    gc.collect()\n\n    return data, test, y, ids","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"def train_model(data_, test_, y_, folds_):\n\n    oof_preds = np.zeros(data_.shape[0])\n    sub_preds = np.zeros(test_.shape[0])\n\n    feature_importance_df = pd.DataFrame()\n\n    feats = [f for f in data_.columns if f not in ['SK_ID_CURR']]\n\n    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(data_, y_)):\n        trn_x, trn_y = data_[feats].iloc[trn_idx], y_.iloc[trn_idx]\n        val_x, val_y = data_[feats].iloc[val_idx], y_.iloc[val_idx]\n\n        # LightGBM parameters found by Bayesian optimization\n        clf = LGBMClassifier(\n            nthread=4,\n            n_estimators=10000,\n            learning_rate=0.03,\n            num_leaves=34,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.041545473,\n            reg_lambda=0.0735294,\n            min_split_gain=0.0222415,\n            min_child_weight=39.3259775,\n            silent=-1,\n            verbose=-1, )\n\n        clf.fit(\n            trn_x,\n            trn_y,\n            eval_set=[(trn_x, trn_y), (val_x, val_y)],\n            eval_metric='auc',\n            verbose=100,\n            early_stopping_rounds=100  #30\n        )\n\n        oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_[feats],\n            num_iteration=clf.best_iteration_)[:, 1] / folds_.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n\n        print('Fold %2d AUC : %.6f' %\n              (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n        del clf, trn_x, trn_y, val_x, val_y\n        gc.collect()\n\n    print('Full AUC score %.6f' % roc_auc_score(y, oof_preds))\n\n    test_['TARGET'] = sub_preds\n\n    df_oof_preds = pd.DataFrame({'SK_ID_CURR':ids, 'TARGET':y, 'PREDICTION':oof_preds})\n    df_oof_preds = df_oof_preds[['SK_ID_CURR', 'TARGET', 'PREDICTION']]\n\n    return oof_preds, df_oof_preds, test_[['SK_ID_CURR', 'TARGET'\n                             ]], feature_importance_df, roc_auc_score(y, oof_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33df9f4c96ecf5e6bafdef0a392509ecf5f4a164"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fb6194a470b17d951bb3d85944a9424b592a1fa"},"cell_type":"code","source":"def display_importances(feature_importance_df_):\n    # Plot feature importances\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\n        \"feature\").mean().sort_values(\n            by=\"importance\", ascending=False)[:50].index\n\n    best_features = feature_importance_df_.loc[\n        feature_importance_df_.feature.isin(cols)]\n\n    plt.figure(figsize=(8, 10))\n    sns.barplot(\n        x=\"importance\",\n        y=\"feature\",\n        data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances-01.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b88ab01ba4be2178396b79e1152674df068d86fc"},"cell_type":"code","source":"def display_roc_curve(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6, 6))\n    scores = []\n    roc_arr = []\n    for n_fold, (_, val_idx) in enumerate(folds_idx_):\n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = roc_auc_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(\n            fpr,\n            tpr,\n            lw=1,\n            alpha=0.3,\n            label='ROC fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n        roc_arr.append(score)\n        \n    plt.plot(\n        [0, 1], [0, 1],\n        linestyle='--',\n        lw=2,\n        color='r',\n        label='Luck',\n        alpha=.8)\n    fpr, tpr, thresholds = roc_curve(y_, oof_preds_)\n    score = roc_auc_score(y_, oof_preds_)\n    plt.plot(\n        fpr,\n        tpr,\n        color='b',\n        label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n        lw=2,\n        alpha=.8)\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('LightGBM ROC Curve')\n    plt.legend(loc=\"lower right\")\n    plt.tight_layout()\n\n    plt.savefig('roc_curve-01.png')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34057909a346484b2ee45da063885c2334e5ddba","scrolled":true},"cell_type":"code","source":"def display_precision_recall(y_, oof_preds_, folds_idx_):\n    # Plot ROC curves\n    plt.figure(figsize=(6, 6))\n\n    scores = []\n    for n_fold, (_, val_idx) in enumerate(folds_idx_):\n        # Plot the roc curve\n        fpr, tpr, thresholds = roc_curve(y_.iloc[val_idx], oof_preds_[val_idx])\n        score = average_precision_score(y_.iloc[val_idx], oof_preds_[val_idx])\n        scores.append(score)\n        plt.plot(\n            fpr,\n            tpr,\n            lw=1,\n            alpha=0.3,\n            label='AP fold %d (AUC = %0.4f)' % (n_fold + 1, score))\n\n    precision, recall, thresholds = precision_recall_curve(y_, oof_preds_)\n    score = average_precision_score(y_, oof_preds_)\n    plt.plot(\n        precision,\n        recall,\n        color='b',\n        label='Avg ROC (AUC = %0.4f $\\pm$ %0.4f)' % (score, np.std(scores)),\n        lw=2,\n        alpha=.8)\n\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('LightGBM Recall / Precision')\n    plt.legend(loc=\"best\")\n    plt.tight_layout()\n\n    plt.savefig('recall_precision_curve-01.png')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"if __name__ == '__main__':\n    gc.enable()\n    # Build model inputs\n    data, test, y, ids = build_model_input()\n    # Create Folds\n    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n    # Train model and get oof and test predictions\n    oof_preds, df_oof_preds, test_preds, importances, score = train_model(data, test, y, folds)\n    # Save test predictions\n    now = datetime.now()\n    score = str(round(score, 6)).replace('.', '')\n    sub_file = 'submission_5x-average-LGB-run-01-v1_' + score + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n    test_preds.to_csv(sub_file, index=False)\n    oof_file = 'train_5x-LGB-run-01-v1-oof_' + score + '_' + str(now.strftime('%Y-%m-%d-%H-%M')) + '.csv'\n    df_oof_preds.to_csv(oof_file, index=False)\n    # Display a few graphs\n    folds_idx = [(trn_idx, val_idx)\n                 for trn_idx, val_idx in folds.split(data, y)]\n    display_importances(feature_importance_df_=importances)\n    display_roc_curve(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)\n    display_precision_recall(y_=y, oof_preds_=oof_preds, folds_idx_=folds_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fa76a54c93522530a796089fa34e18c6dcf18bd"},"cell_type":"code","source":"data.to_csv('data_all', index=False)\ntest.to_csv('test_all', index=False)\ny.to_csv('target_all', index=False)\nids.to_csv('skids_all', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a99518f59cd370fd87215a7e79c91b6c4051cb0d"},"cell_type":"code","source":"roc_arr = []\nfor n_fold, (_, val_idx) in enumerate(folds_idx):\n    # Plot the roc curve\n    fpr, tpr, thresholds = roc_curve(y.iloc[val_idx], oof_preds[val_idx])\n    score = roc_auc_score(y.iloc[val_idx], oof_preds[val_idx])\n    roc_arr.append(score)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"537a1c8acacb0bc594289693fcb9283832302650"},"cell_type":"code","source":"roc_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0106ff0bdb3a28a9d978cee4715f1cdf2eb6ec05"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}