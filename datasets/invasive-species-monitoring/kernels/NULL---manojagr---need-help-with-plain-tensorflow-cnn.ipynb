{"metadata": {"language_info": {"file_extension": ".py", "name": "python", "version": "3.6.1", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "fcf2a833-d7a4-443c-9068-732eeb538eb7", "_uuid": "e98cdb6136c15d4117df3d5f1df69649a116f48e"}, "cell_type": "markdown", "source": ["I am trying to follow a plain simple TensorFlow CNN implementation tutorial with MNIST data but I am trying to translate it for Invasive Species problem as an excercise. Doesn't give great accuracy at this point and takes a lot of time to train."]}, {"metadata": {"_cell_guid": "eadfda34-fba4-4290-a169-2422895bf3e3", "_uuid": "4d34c20c704342f660af2bd18809dc6655abdfd6", "collapsed": true}, "cell_type": "code", "source": ["from __future__ import print_function\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import cv2\n", "import pandas as pd\n", "from tqdm import tqdm\n", "from sklearn.model_selection import train_test_split\n", "import tensorflow as tf\n", "# Config the matplotlib backend as plotting inline in IPython\n", "%matplotlib inline"], "outputs": [], "execution_count": 2}, {"metadata": {"_cell_guid": "77dd86d5-823e-4238-badc-dc0698f41abe", "_uuid": "85af4168275d1f2ec8bb405c8cc106caeb5dfd5d", "collapsed": true}, "cell_type": "code", "source": ["sess = tf.InteractiveSession()"], "outputs": [], "execution_count": 3}, {"metadata": {"_cell_guid": "3aa48430-770c-4990-ac1d-3dcd13392119", "_uuid": "d8cb161e352563587c67b4f584e3de1d5224e5ad"}, "cell_type": "code", "source": ["train_set = pd.read_csv('../input/train_labels.csv')\n", "test_set = pd.read_csv('../input/sample_submission.csv')\n", "\n", "def read_img(img_path):\n", "    img = cv2.imread(img_path)\n", "    img = cv2.resize(img, (128, 128))\n", "    return img\n", "\n", "train_img, test_img = [], []\n", "for img_path in tqdm(train_set['name'].iloc[: ]):\n", "    train_img.append(read_img('../input/train/' + str(img_path) + '.jpg'))\n", "for img_path in tqdm(test_set['name'].iloc[: ]):\n", "    test_img.append(read_img('../input/test/' + str(img_path) + '.jpg'))\n", "\n", "train_img = np.array(train_img, np.float32) / 255\n", "train_label = np.array(train_set['invasive'].iloc[: ])\n", "test_img = np.array(test_img, np.float32) / 255"], "outputs": [], "execution_count": 4}, {"metadata": {"_cell_guid": "92d01d11-6247-43a3-a037-242479a5dfa5", "_uuid": "9421ea8f897a0bf073e22866c5acfd0af235846e"}, "cell_type": "code", "source": ["dataset = np.array(train_img, dtype=np.float32)\n", "dataset.shape"], "outputs": [], "execution_count": 5}, {"metadata": {"_cell_guid": "9b1b35c3-7e7a-4a6b-8a15-1353a0da89a4", "_uuid": "05731af3c9376a3d93e71f1c218f9923233c2647"}, "cell_type": "markdown", "source": ["Splitting into training and test. "]}, {"metadata": {"_cell_guid": "d0ba9475-e2dd-4104-a2e0-c52cc6807e6e", "_uuid": "14f05259a8fb9bc8103d849eca535e64371344a7", "collapsed": true}, "cell_type": "code", "source": ["X_train, X_test, y_train, y_test = train_test_split(train_img, train_label, test_size=0.3, random_state=324)"], "outputs": [], "execution_count": 6}, {"metadata": {"_cell_guid": "1e6a81c1-6034-44d2-a1ac-60f11ae04d23", "_uuid": "d876007e5df27648201b72fcdd859af66cb6e5e9"}, "cell_type": "code", "source": ["#y_train = np.reshape(y_train, [-1,1])\n", "#y_test = np.reshape(y_test, [-1,1])\n", "y_train = pd.get_dummies(y_train)\n", "y_test =  pd.get_dummies(y_test)\n", "\n", "y_train"], "outputs": [], "execution_count": 7}, {"metadata": {"_cell_guid": "1528da9a-a24f-47be-ba77-c5f6d1ef5102", "_uuid": "27dbfb17f0c7c44b8977087747e61ace5ab2c6b6", "collapsed": true}, "cell_type": "code", "source": ["batch_size, height, width, channels = dataset.shape\n", "class_output = 2 # Not sure about this but there is only one class\n"], "outputs": [], "execution_count": 8}, {"metadata": {"_cell_guid": "173878f0-2384-4e8a-a871-c2aefb9a9b76", "_uuid": "3bc59374acb5244d2cac6d16a1b34c69b9509572", "collapsed": true}, "cell_type": "markdown", "source": ["Placeholders for Input and Output"]}, {"metadata": {"_cell_guid": "6c082251-1170-448e-afdf-ea503d446fc9", "_uuid": "02610c84fb5dae9d8647b8d647d49847b37438db", "collapsed": true}, "cell_type": "code", "source": ["x  = tf.placeholder(tf.float32, shape=[None, height, width, channels])\n", "y_ = tf.placeholder(tf.float32, shape=[None, class_output])"], "outputs": [], "execution_count": 9}, {"metadata": {"_cell_guid": "fa78ae94-8649-4d51-b678-d4174bdb1e37", "_uuid": "0b99ea6b061228825bdc9ab65e1e46e90dab3714"}, "cell_type": "markdown", "source": ["**Convolutional layer 1**"]}, {"metadata": {"_cell_guid": "58245bc9-8da7-43dd-b960-27597358928c", "_uuid": "20d558f620dc9e8b0e97b9a7ea631bb234fb1164"}, "cell_type": "markdown", "source": ["Kernel weight and bias"]}, {"metadata": {"_cell_guid": "cbd0392a-909f-41cf-9b08-6bac11fdfdea", "_uuid": "ac54e7b373a48d8663b9dcf2c0da49dec7fcac20", "collapsed": true}, "cell_type": "code", "source": ["W_conv1 = tf.Variable(tf.truncated_normal([5, 5, channels, 16], stddev=0.1))\n", "b_conv1 = tf.Variable(tf.constant(0.1, shape=[16])) # need 16 biases for 16 outputs"], "outputs": [], "execution_count": 10}, {"metadata": {"_cell_guid": "bc92ddcb-fa0b-436b-8214-69fce9fd0f95", "_uuid": "a3543d507b44daa691522dd2d7e4aea66a5d1eb7", "collapsed": true}, "cell_type": "code", "source": ["convolve1= tf.nn.conv2d(x, W_conv1, strides=[1, 2, 2, 1], padding='SAME') + b_conv1"], "outputs": [], "execution_count": 11}, {"metadata": {"_cell_guid": "59252a27-5113-4525-88bb-fc248b8b2204", "_uuid": "c073f7d66f9222e6af8d0eb86f67923940673b42", "collapsed": true}, "cell_type": "code", "source": ["h_conv1 = tf.nn.relu(convolve1)"], "outputs": [], "execution_count": 12}, {"metadata": {"_cell_guid": "a4840cb3-e982-4f5e-af07-b7b43d58d1e0", "_uuid": "13f2e27dddfab4f80ef8a693ae50f1cef7fb4783"}, "cell_type": "code", "source": ["conv1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n", "conv1"], "outputs": [], "execution_count": 13}, {"metadata": {"_cell_guid": "7ba6a981-9078-491b-b9bc-5f39f2fb670b", "_uuid": "074d07025f6829eafbbdcda45ed3657b5254916e"}, "cell_type": "markdown", "source": ["**Convolution Layer 2**"]}, {"metadata": {"_cell_guid": "9c83d8ae-292b-4d5e-b883-a4e27db82cc8", "_uuid": "475c588a49aaeb9ab9a2c76d5daa3cb5ccd6ce22"}, "cell_type": "markdown", "source": ["Filter/kernel: 5x5 (25 pixels)\n", "Input channels: 16 (from the 1st Conv layer, we had 16 feature maps)\n", "32 output feature maps"]}, {"metadata": {"_cell_guid": "29f45cf9-e8f3-4d02-a03d-3c417c1657f9", "_uuid": "e2da3448bedc8a59819574fa0e58c96283d1a0df"}, "cell_type": "code", "source": ["W_conv2 = tf.Variable(tf.truncated_normal([5, 5, 16, 32], stddev=0.1))\n", "b_conv2 = tf.Variable(tf.constant(0.1, shape=[32])) #need 32 biases for 32 outputs\n", "convolve2= tf.nn.conv2d(conv1, W_conv2, strides=[1, 2, 2, 1], padding='SAME')+ b_conv2\n", "h_conv2 = tf.nn.relu(convolve2)\n", "conv2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME') #max_pool_2x2\n", "conv2"], "outputs": [], "execution_count": 14}, {"metadata": {"_cell_guid": "fc5a93cb-aba9-47df-a683-a640b88eccb6", "_uuid": "d3c106837bdb1f084dd884bdb4761b44790f4c23"}, "cell_type": "markdown", "source": ["**Fully connected layer**"]}, {"metadata": {"_cell_guid": "9de5d921-ae6b-4514-b071-f570b18423a9", "_uuid": "66f1ddda100d708b2fe769b1159e256b70a3284f", "collapsed": true}, "cell_type": "code", "source": ["layer2_matrix = tf.reshape(conv2, [-1, 8*8*32])"], "outputs": [], "execution_count": 15}, {"metadata": {"_cell_guid": "5bd96dc7-3d49-4431-a8f2-0d289911f201", "_uuid": "08ae0d9135ab1cbffa763a20a8e6a0f9e18b0a3c"}, "cell_type": "markdown", "source": ["**Weights and Biases between layer 2 and 3**\n", "Composition of the feature map from the last layer (8x8) multiplied by the number of feature maps (32); 1027 outputs to Softmax layer\n", "(not sure what is 1027 above and 1024 in the code below)"]}, {"metadata": {"_cell_guid": "7a7d1887-aa1d-4afe-8e95-6c3a6526bfc3", "_uuid": "a45b06e3894af131525279c7701674f59e94517e", "collapsed": true}, "cell_type": "code", "source": ["W_fc1 = tf.Variable(tf.truncated_normal([8 * 8 * 32, 512], stddev=0.1))\n", "b_fc1 = tf.Variable(tf.constant(0.1, shape=[512])) # need 512 biases for 512 outputs"], "outputs": [], "execution_count": 16}, {"metadata": {"_cell_guid": "4a027cf1-9c48-4bdb-8746-eb4197d33976", "_uuid": "2c427f184564cd97594af8de515ca6fcce2077a5", "collapsed": true}, "cell_type": "code", "source": ["fcl=tf.matmul(layer2_matrix, W_fc1) + b_fc1"], "outputs": [], "execution_count": 17}, {"metadata": {"_cell_guid": "60df9581-2b8a-4ecc-ba3a-8feddb9d7d4d", "_uuid": "ebd2a312f4bdc5288997ea6e4426b09a995eaefc"}, "cell_type": "code", "source": ["h_fc1 = tf.nn.relu(fcl)\n", "h_fc1"], "outputs": [], "execution_count": 18}, {"metadata": {"_cell_guid": "55e8cbaf-36ae-4db5-aafb-cd7f108efd7e", "_uuid": "ffaaa1c5961bd8386cf26ebeda5a6c02ec38143a"}, "cell_type": "markdown", "source": ["Dropout layer"]}, {"metadata": {"_cell_guid": "af757a05-2606-4465-9519-2b4cd325bcf6", "_uuid": "48249a114bffcee206640da29cfc3805941abb85"}, "cell_type": "code", "source": ["keep_prob = tf.placeholder(tf.float32)\n", "layer_drop = tf.nn.dropout(h_fc1, keep_prob)\n", "layer_drop"], "outputs": [], "execution_count": 19}, {"metadata": {"_cell_guid": "4fb79519-c277-41ab-bff7-160fa46ce124", "_uuid": "bb175da1bf771f80308263a3e602f0292985389b", "collapsed": true}, "cell_type": "code", "source": ["W_fc2 = tf.Variable(tf.truncated_normal([512, 1], stddev=0.1)) #512 neurons\n", "b_fc2 = tf.Variable(tf.constant(0.1, shape=[2])) # 1 possibility"], "outputs": [], "execution_count": 20}, {"metadata": {"_cell_guid": "db7b8a17-ee84-4818-adca-3cc6d696813a", "_uuid": "76c1d25689843e0f9c3d3ca97695b99ea11e7ec8", "collapsed": true}, "cell_type": "code", "source": ["fc=tf.matmul(layer_drop, W_fc2) + b_fc2"], "outputs": [], "execution_count": 21}, {"metadata": {"_cell_guid": "45462d74-08c2-4d3a-a921-1f316f55d2b9", "_uuid": "8d78b2d702f5af01855d6ba5c46d42232ca80401"}, "cell_type": "code", "source": ["y_CNN= tf.nn.softmax(fc)\n", "y_CNN"], "outputs": [], "execution_count": 22}, {"metadata": {"_cell_guid": "33dc95b2-2a12-4ea7-99f5-e9f6431f7d87", "_uuid": "b8762a64e842e6791f60f20a05f4f5de3326fefb", "collapsed": true}, "cell_type": "code", "source": ["cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_CNN), reduction_indices=[1]))\n", "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n", "correct_prediction = tf.equal(tf.argmax(y_CNN,1), tf.argmax(y_,1))\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"], "outputs": [], "execution_count": 23}, {"metadata": {"_cell_guid": "065bf4c3-4936-4222-be47-4a9c7d612e87", "_uuid": "38d0f742ef0e91f57d5afea7b49ac5567a70413e", "collapsed": true}, "cell_type": "code", "source": ["sess.run(tf.global_variables_initializer())"], "outputs": [], "execution_count": 24}, {"metadata": {"_cell_guid": "d9a87e5d-cfe3-4470-9fc3-0ecad7ede99e", "_uuid": "d9b75d7a4beaf561e3635a28b7491a496fda5d06"}, "cell_type": "markdown", "source": ["Original code used batch size from MNIST data but here I am trying to do without that. I am getting timeout so let me try with a smaller training set just to see that the code works."]}, {"metadata": {"_cell_guid": "39961143-269c-471a-8701-11caaef48f1c", "_uuid": "6f42e0ed3dd3aedfc1554a67836a4a16b280dd14"}, "cell_type": "code", "source": ["X_train_tmp = X_train[:200]\n", "y_train_tmp = y_train[:200]"], "outputs": [], "execution_count": 25}, {"metadata": {"_cell_guid": "e23fd172-939d-4d5e-8094-dbb835f2d4df", "_uuid": "34719cd3ed3ff3fd1bec5ad382e861283adf4857"}, "cell_type": "code", "source": ["for i in range(500):\n", "    if i%50 == 0:\n", "        train_accuracy = accuracy.eval(feed_dict={x:X_train_tmp, y_: y_train_tmp, keep_prob: 1.0})\n", "        print(\"step %d, training accuracy %g\"%(i, float(train_accuracy)))\n", "    train_step.run(feed_dict={x: X_train_tmp, y_: y_train_tmp, keep_prob: 0.5})"], "outputs": [], "execution_count": 28}, {"metadata": {"_cell_guid": "dbf26edb-5214-4bfa-ae8e-8d76a5973237", "_uuid": "2e047c32d70de10927c02667f5b174cf7a712e8a"}, "cell_type": "markdown", "source": ["Model doesn't improve somehow. Not sure if this is due to some error in my code. "]}, {"metadata": {"_cell_guid": "d13ed5eb-22ae-4e47-b540-4b3ad96f41cc", "_uuid": "d7fd0fa1e81aba756e87ba4f05bfcef979757b23", "collapsed": true}, "cell_type": "code", "source": ["X_test_tmp = X_test[:100]\n", "y_test_tmp = y_test[:100]"], "outputs": [], "execution_count": 30}, {"metadata": {"_cell_guid": "c226a3be-12eb-4502-b07d-ecd6e2afae5a", "_uuid": "8aead1a3bf800b032908831e1f71e91dd733c7da"}, "cell_type": "code", "source": ["print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: X_test_tmp, y_: y_test_tmp, keep_prob: 1.0}))"], "outputs": [], "execution_count": 31}, {"metadata": {"_cell_guid": "a06294ff-2e46-487b-91a5-bf0b271ee0aa", "_uuid": "6fdd603e305066e78e3c53d63b079afac0dc3cd5"}, "cell_type": "markdown", "source": ["Accuracy 60%. Needs improvement."]}], "nbformat": 4}