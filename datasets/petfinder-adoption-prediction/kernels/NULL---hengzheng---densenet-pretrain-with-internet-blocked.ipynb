{"cells":[{"metadata":{"_uuid":"b3a26be5453165561ebf2ea8c65cc590fd959722"},"cell_type":"markdown","source":"original kernel: https://www.kaggle.com/christofhenkel/extract-image-features-from-pretrained-nn"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom keras.applications.densenet import preprocess_input, DenseNet121\nfrom keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3095bcf8c41ce6318ecd21a654a4bd03fa142344"},"cell_type":"code","source":"train = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\ntest = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\nimg_size = 256\nbatch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def resize_to_square(im):\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(img_size)/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h//2, delta_h-(delta_h//2)\n    left, right = delta_w//2, delta_w-(delta_w//2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    return new_im\n\ndef load_image(path, pet_id):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n    new_image = resize_to_square(image)\n    new_image = preprocess_input(new_image)\n    return new_image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddfc063c74e9f25a80fd0b284e8d499e2ef60897"},"cell_type":"code","source":"inp = Input((img_size, img_size, 3))\nbackbone = DenseNet121(input_tensor=inp, \n                       weights=\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\",\n                       include_top = False)\nx = backbone.output\nx = GlobalAveragePooling2D()(x)\nx = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\nx = AveragePooling1D(4)(x)\nout = Lambda(lambda x: x[:,:,0])(x)\n\nm = Model(inp,out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52d6848808ab823d10f343ac0242af3cfe76393a"},"cell_type":"code","source":"pet_ids = train['PetID'].values\nn_batches = len(pet_ids) // batch_size + 1\n\nfeatures = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_pets = pet_ids[start:end]\n    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n    for i,pet_id in enumerate(batch_pets):\n        try:\n            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/train_images/\", pet_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,pet_id in enumerate(batch_pets):\n        features[pet_id] = batch_preds[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88bb0df2e603864b2f97a96c3586c44523f7d0b1"},"cell_type":"code","source":"train_feats = pd.DataFrame.from_dict(features, orient='index')\ntrain_feats.to_csv('train_img_features.csv')\ntrain_feats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"231f508b4af50df45d05e03bd0d295e9c4d01979"},"cell_type":"code","source":"pet_ids = test['PetID'].values\nn_batches = len(pet_ids) // batch_size + 1\n\nfeatures = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_pets = pet_ids[start:end]\n    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n    for i,pet_id in enumerate(batch_pets):\n        try:\n            batch_images[i] = load_image(\"../input/petfinder-adoption-prediction/test_images/\", pet_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,pet_id in enumerate(batch_pets):\n        features[pet_id] = batch_preds[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb8e1d1abf4dc35c68d78bf38c8eb10d67c5e595"},"cell_type":"code","source":"test_feats = pd.DataFrame.from_dict(features, orient='index')\ntest_feats.to_csv('test_img_features.csv')\ntest_feats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52de05dd9fbbcf01e544f319f7cae487a183d4c8"},"cell_type":"code","source":"print(train_feats.shape, test_feats.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b677ce514554d8510cfec8885f04f720f845850"},"cell_type":"code","source":"train_feats.columns = [\"img_feat{}\".format(i) for i in range(256)]\ntest_feats.columns = [\"img_feat{}\".format(i) for i in range(256)]\n\ntrain_feats[\"PetID\"] = train_feats.index\ntest_feats[\"PetID\"] = test_feats.index\n\ntrain = pd.merge(train, train_feats, on=\"PetID\")\ntest = pd.merge(test, test_feats, on=\"PetID\")\n\nprint(train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e83027368cc85c2ec5944ad26f8724f607525482"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}