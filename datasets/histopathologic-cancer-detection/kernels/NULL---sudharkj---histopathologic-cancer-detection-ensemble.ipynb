{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Check GPU Availability\n\nMake sure that GPU is available. If not turn the GPU state to on in Settings."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30cd364133489f7aa8c9dbfb18a11a21a5b64f5f"},"cell_type":"markdown","source":"## Import Libraries\n\nImport all the required libraries."},{"metadata":{"trusted":true,"_uuid":"dd2b59d1dad8f2f1a34682ed4df15cd2a4f09f00"},"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom torch import Tensor, zeros\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import Module, Conv2d, BatchNorm2d, Dropout, BatchNorm1d, MaxPool2d, Linear, LogSigmoid, functional as F, CrossEntropyLoss, BCEWithLogitsLoss\nfrom torchvision.models import alexnet, densenet121, inception_v3, resnet18, squeezenet1_0, vgg11_bn \nfrom torchvision.transforms import Compose, RandomApply, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, RandomRotation, RandomGrayscale, Normalize, ToTensor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70a72ba28a827d584937a9b1a7070389b2d95382"},"cell_type":"markdown","source":"## Generate required folders\n\nGenerate the required folders to be able to\n* save the states\n* load from saved states\n* save plots\n* save results"},{"metadata":{"trusted":true,"_uuid":"3a5599522fd93efb3974bebd7d6fd5be9840d9de"},"cell_type":"code","source":"folders = {\n    \"plots\": \"plots\",\n    \"models\": \"models\",\n    \"results\": \"results\"\n}\nfor key in folders.keys():\n    try:\n        os.makedirs(folders[key])\n    except FileExistsError:\n        # if file exists, pass\n        pass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d3294d779ad2c64b17c71a913def94f8fc4578c"},"cell_type":"markdown","source":"## PCam Dataset\n\nCustom dataset definition to be able to use PyTorch style of efficient data loading.\n\n### Challenges Faced\n\nA deep neural network tries to get the best performance and so having relatively more number of examples in one class is making the network to have a biased view of it's world. So, have to come up with a way to have same number of examples for each category."},{"metadata":{"trusted":true,"_uuid":"d4a7cf38a8d8059cfc227f09c0f87f4efa85b02e"},"cell_type":"code","source":"class PCam(Dataset):\n    \"\"\"Patch Camelyon dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir, train=True, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with labels.\n            root_dir (string): Root directory.\n            train (boolean): Whether loading training or testing data. \n                            This is required to have same number of examples in each \n                            classification to be able to train better.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        if train:\n            dataframe = pd.read_csv(os.path.join(root_dir, csv_file))\n            min_value = dataframe['label'].value_counts().min()\n#             min_value = 16000\n            frames = []\n            for label in dataframe['label'].unique():\n                frames.append(dataframe[dataframe['label'] == label].sample(min_value))\n            self.labels = pd.DataFrame().append(frames).sample(frac=1).reset_index(drop=True)\n            self.data_folder = \"train\"\n        else:\n            self.labels = pd.read_csv(os.path.join(root_dir, csv_file))\n            self.data_folder = \"test\"\n        \n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        image_name = os.path.join(self.root_dir,\n                                \"%s/%s.tif\" % (self.data_folder, self.labels.iloc[idx, 0]))\n        image = Image.open(image_name)\n        image.thumbnail((40, 40), Image.ANTIALIAS)\n        if self.transform is not None:\n            image = self.transform(image)\n\n        return self.labels.iloc[idx, 0], image, self.labels.iloc[idx, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a74f67187868f0bd6ddcd83d4d56e8acc74cf66d"},"cell_type":"code","source":"NUM_CLASSES = 2  # number of classes\nBATCH_SIZE = 32  # mini_batch size\nMAX_EPOCH = 8  # maximum epoch to train\nSTEP_SIZE = 2  # decrease in learning rate after epochs\nLEARNING_RATE = 0.00007  # learning rate\nGAMMA = 0.1  # used in decreasing the gamma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c50ff6299c7f62aa203bbe26fe0e17eaf1db4da3"},"cell_type":"code","source":"train_transform = Compose([\n    RandomAffine(45, translate=(0.15, 0.15), shear=45),\n    RandomHorizontalFlip(),\n    RandomVerticalFlip(),\n    RandomRotation(45),\n    RandomApply([ColorJitter(saturation=0.5, hue=0.5)]),\n    ToTensor(),\n    Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\ntest_transform = Compose(\n    [ToTensor(),\n     Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = PCam(csv_file='train_labels.csv', root_dir='../input', train=True, transform=train_transform)\ntrainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\ntestset = PCam(csv_file='sample_submission.csv', root_dir='../input', train=False, transform=test_transform)\ntestloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7e032fe58bab371a3781dcac9428b1cee283dce"},"cell_type":"code","source":"def eval_ensemble(nets, criterion, dataloader):\n    correct = 0\n    total = 0\n    total_loss = 0\n\n    for data in dataloader:\n        _, images, labels = data\n        #         images, labels = Variable(images), Variable(labels)\n        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n\n        predictions = torch.zeros([images.size(0), NUM_CLASSES]).cuda()\n        for net in nets:\n            net.eval()\n            outputs = net(images)\n            predictions = predictions.add(outputs)\n\n        predictions = predictions / len(nets)\n        _, predicted = torch.max(predictions.data, 1)\n        \n        total += labels.size(0)\n        correct += (predicted == labels.data).sum().item()\n        \n        loss = criterion(predictions, labels)\n        total_loss += loss.item()\n    return total_loss / total, correct / total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42a533bdc3500fe54bad59ee21f1c81a9e1904d5"},"cell_type":"code","source":"def train_ensemble(nets, optimizers, schedulers, criterion, eval_criterion):\n    ensemble_name = 'ensemble'\n    train_loss_array = []\n    test_loss_array = []\n    train_accuracy_array = []\n    test_accuracy_array = []\n\n    print('Start training...')\n    for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n        for scheduler in schedulers:\n            scheduler.step()\n        \n        running_loss = 0.0\n        for i, data in enumerate(trainloader):\n            _, images, labels = data\n            #             inputs, labels = Variable(inputs), Variable(labels)\n            images, labels = Variable(images).cuda(), Variable(labels).cuda()\n\n            predictions = torch.zeros([images.size(0), NUM_CLASSES]).cuda()\n            for net, optimizer in zip(nets, optimizers):\n                net.train()\n                optimizer.zero_grad()\n                outputs = net(images)\n                predictions = predictions.add(outputs)\n\n            predictions = predictions / len(nets)\n            \n            # back prop\n            loss = criterion(predictions, labels)\n            loss.backward()\n            for optimizer in optimizers:\n                optimizer.step()\n            running_loss += loss.item()\n            \n            if i % 500 == 499:  # print every 2000 mini-batches\n                print('Step: %5d avg_batch_loss: %.5f' % (i + 1, running_loss / 500))\n                running_loss = 0.0\n                \n        print('Finish training this EPOCH, start evaluating...')\n        train_loss, train_acc = eval_ensemble(nets, eval_criterion, trainloader)\n        test_loss, test_acc = eval_ensemble(nets, eval_criterion, testloader)\n        print('EPOCH: %d train_loss: %.5f train_acc: %.5f test_loss: %.5f test_acc %.5f' %\n              (epoch + 1, train_loss, train_acc, test_loss, test_acc))\n\n        train_loss_array.append(train_loss)\n        test_loss_array.append(test_loss)\n\n        train_accuracy_array.append(train_acc)\n        test_accuracy_array.append(test_acc)\n#         print('Saving intermitant models...')\n#         for net in nets:\n#             torch.save(net.state_dict(), './%s/%s-%d.pth' % (folders['models'], net.name, epoch))\n    print('Finished Training')\n\n    # plot loss\n    plt.clf()\n    plt.plot(list(range(1, MAX_EPOCH + 1)), train_loss_array, label='Train')\n    plt.plot(list(range(1, MAX_EPOCH + 1)), test_loss_array, label='Test')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Loss vs Epochs [%s]' % net.name)\n    plt.savefig('./%s/loss-%s.png' % (folders['plots'], ensemble_name))\n\n    # plot accuracy\n    plt.clf()\n    plt.plot(list(range(1, MAX_EPOCH + 1)), train_accuracy_array, label='Train')\n    plt.plot(list(range(1, MAX_EPOCH + 1)), test_accuracy_array, label='Test')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.title('Accuracy vs Epochs [%s]' % net.name)\n    plt.savefig('./%s/accuracy-%s.png' % (folders['plots'], ensemble_name))\n\n    print('Saving models...')\n    for net in nets:\n        torch.save(net.state_dict(), './%s/training-%s.pth' % (folders['models'], net.name))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"388e6abd4393e481b7b8b80e4da09f4591248ce1"},"cell_type":"code","source":"def dump_ensemble_results(dataloader, nets):\n    ensemble_name = 'ensemble'\n    \n    alphas = []\n    for net in nets:\n        net.eval()\n        \n        true_positives = 0\n        for data in trainloader:\n            _, images, labels = data\n            images, labels = Variable(images).cuda(), Variable(labels).cuda()\n            outputs = net(images)\n            _, outputs = torch.max(outputs.data, 1)\n            index = (labels == 1)\n            true_positives += (outputs[index] == labels[index].data).sum().item()\n        alphas.append(true_positives)\n#     total_true_positives = sum(alphas)\n    \n    results = pd.DataFrame()\n    for data in dataloader:\n        image_names, images, labels = data\n#         images, labels = Variable(images), Variable(labels)\n        images, labels = Variable(images).cuda(), Variable(labels).cuda()\n    \n        predictions = torch.zeros([images.size(0), NUM_CLASSES]).cuda()\n        for index, net in enumerate(nets):\n            net.eval()\n            outputs = net(images) * alphas[index]  # / total_true_positives\n            predictions = predictions.add(outputs)\n\n#         predictions = predictions / total_true_positives\n        _, predictions = torch.max(predictions.data, 1)\n        results = results.append(pd.DataFrame({\"id\": image_names, \"label\": predictions.cpu().numpy()}))\n    results.to_csv(\"%s/%s.csv\" % (folders['results'], ensemble_name), index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf9ddc673d24b6c98cbc462592398bc6e60daa75","scrolled":true},"cell_type":"code","source":"start = time.time()\nnet_list = []\noptimizer_list = []\nscheduler_list = []\n\n# AlexNet\n# alex_net = alexnet(pretrained=True)\n# alex_num_ftrs = alex_net.classifier._modules['6'].in_features\n# alex_net.classifier._modules['6'] = Linear(alex_num_ftrs, NUM_CLASSES)\n# alex_net.name = \"AlexNet\"\n# alex_net = alex_net.cuda()\n# alex_optimizer = Adam(alex_net.parameters(), lr=LEARNING_RATE)\n# alex_exp_lr_scheduler = lr_scheduler.StepLR(alex_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n# net_list.append(alex_net)\n# optimizer_list.append(alex_optimizer)\n# scheduler_list.append(alex_exp_lr_scheduler)\n\n# DenseNet121\ndense_net = densenet121(pretrained=True)\ndense_num_ftrs = dense_net.classifier.in_features\ndense_net.classifier = Linear(dense_num_ftrs, NUM_CLASSES)\ndense_net.name = \"DenseNet121\"\ndense_net = dense_net.cuda()\ndense_optimizer = Adam(dense_net.parameters(), lr=LEARNING_RATE)\ndense_exp_lr_scheduler = lr_scheduler.StepLR(dense_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\nnet_list.append(dense_net)\noptimizer_list.append(dense_optimizer)\nscheduler_list.append(dense_exp_lr_scheduler)\n\n# InceptionV3\n# inception_net = inception_v3(aux_logits=False)\n# # have to disable aux_logits because of https://github.com/pytorch/vision/issues/302\n# # it do not have pretrained data for disabled aux_logits\n# inception_num_ftrs = inception_net.fc.in_features\n# inception_net.fc = Linear(inception_num_ftrs, NUM_CLASSES)\n# inception_net.name = \"InceptionV3\"\n# inception_net = inception_net.cuda()\n# inception_optimizer = Adam(inception_net.parameters(), lr=LEARNING_RATE)\n# inception_exp_lr_scheduler = lr_scheduler.StepLR(inception_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n# net_list.append(inception_net)\n# optimizer_list.append(inception_optimizer)\n# scheduler_list.append(inception_exp_lr_scheduler)\n\n# ResNet18\nres_net = resnet18(pretrained=True)\nres_num_ftrs = res_net.fc.in_features\nres_net.fc = Linear(res_num_ftrs, NUM_CLASSES)\nres_net.name = \"ResNet18\"\nres_net = res_net.cuda()\nres_optimizer = Adam(res_net.parameters(), lr=LEARNING_RATE)\nres_exp_lr_scheduler = lr_scheduler.StepLR(res_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\nnet_list.append(res_net)\noptimizer_list.append(res_optimizer)\nscheduler_list.append(res_exp_lr_scheduler)\n\n# SqueezeNet1_0\nsqueeze_net = squeezenet1_0(pretrained=True)\nsqueeze_net.classifier._modules['1'] = Conv2d(512, NUM_CLASSES, kernel_size=1)\nsqueeze_net.num_classes = NUM_CLASSES\nsqueeze_net.name = \"SqueezeNet1_0\"\nsqueeze_net = squeeze_net.cuda()\nsqueeze_optimizer = Adam(squeeze_net.parameters(), lr=LEARNING_RATE)\nsqueeze_exp_lr_scheduler = lr_scheduler.StepLR(squeeze_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\nnet_list.append(squeeze_net)\noptimizer_list.append(squeeze_optimizer)\nscheduler_list.append(squeeze_exp_lr_scheduler)\n\n# VGG11\nvgg_net = vgg11_bn(pretrained=True)\nvgg_num_ftrs = vgg_net.classifier._modules['6'].in_features\nvgg_net.classifier._modules['6'] = Linear(vgg_num_ftrs, NUM_CLASSES)\nvgg_net.name = \"VGG11\"\nvgg_net = vgg_net.cuda()\nvgg_optimizer = Adam(vgg_net.parameters(), lr=LEARNING_RATE)\nvgg_exp_lr_scheduler = lr_scheduler.StepLR(vgg_optimizer, step_size=STEP_SIZE, gamma=GAMMA)\nnet_list.append(vgg_net)\noptimizer_list.append(vgg_optimizer)\nscheduler_list.append(vgg_exp_lr_scheduler)\n\ntrain_criterion = CrossEntropyLoss()\nval_criterion = CrossEntropyLoss(reduction='sum')\ntrain_ensemble(net_list, optimizer_list, scheduler_list, train_criterion, val_criterion)\ndump_ensemble_results(testloader, net_list)\nprint(\"Time taken: %d secs\" % int(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b762139f58f67af6a949045ba4d84a759ff15485"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}