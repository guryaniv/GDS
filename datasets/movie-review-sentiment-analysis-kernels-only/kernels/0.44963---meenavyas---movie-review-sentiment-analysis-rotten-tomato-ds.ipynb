{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#header = infer by default\nrawtraindf = pd.read_csv('../input/train.tsv', delimiter=\"\\t\")\nrawtestdf = pd.read_csv('../input/test.tsv', delimiter=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b898abe3fb9037b5a31a95a94da4d035af32637"},"cell_type":"code","source":"print(rawtraindf.shape) # 156060,4\nprint(rawtraindf.head(2))\ncolnames = rawtraindf.columns\nprint(colnames) # PhraseId, SentenceId, Phrase, Sentiment\n#for index, row in rawtraindf.iterrows():\n#    print(row)\nrawtraindf.describe()\n#sentiment varies from 0 to 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6435b2c369e1f026b9da2cdd5e30ce954fd1339"},"cell_type":"code","source":"#https://ep2018.europython.eu/conference/talks/introduction-to-sentiment-analysis-with-spacy\nimport spacy\nnlp_en = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"688d61fc90ebdd18a6fcc573feb43a44c7dc39cb"},"cell_type":"code","source":"#general experiments ignore this section\n#for index, row in rawtraindf.iterrows():\n#    phrase = row[2]\n#    print(type(phrase))\n#    document = nlp_en(phrase)\n#    for sentence in document.sents:\n#        print(sentence)\n        \n#    print(document.sentiment)\n#    print(\"Entries\")\n#    for ent in document.ents:\n#        print(ent, ent.label, ent.label_)\n#    if (index == 0):\n#        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fcbcba9c1b413429bf7a8522616e2272c1273a6"},"cell_type":"code","source":"#https://github.com/explosion/spacy/blob/master/examples/training/train_textcat.py\n\nfrom sklearn.model_selection import train_test_split\ntrain_df, val_df = train_test_split(rawtraindf,test_size=0.2)\nprint(train_df.shape) # 124k\nprint(val_df.shape) # 312\ntrain_texts = train_df['Phrase']\ntrain_cats = train_df['Sentiment']\nval_texts = val_df['Phrase']\nval_cats = val_df['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f362dac2221f22c4d3c9f8987d887b33b31b56c"},"cell_type":"code","source":"#print(type(train_cats)) # series\ntrain_cats = train_cats.reset_index(drop=True)\n#with pd.option_context('display.max_rows', None,'display.max_columns', None):\n#    print(train_cats)\n\ntrain_texts = train_texts.reset_index(drop=True)\nval_texts = val_texts.reset_index(drop=True)\nval_cats = val_cats.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdd0c860cc7b23f164ff890eee9ff1f85b5fdb1e"},"cell_type":"code","source":"#The sentiment labels are:\n#0 - negative\n#1 - somewhat negative\n#2 - neutral\n#3 - somewhat positive\n#4 - positive\n\ndef getSentimentStr(i) :\n    if (i == 0):\n        return \"negative\"\n    elif (i == 1):\n        return \"somewhat negative\"\n    elif (i == 2):\n        return \"neutral\"\n    elif (i == 3):\n        return \"somewhat positive\"\n    elif (i == 4):\n        return \"positive\"\n    else:\n        return \"unknown sentiment\"\n\ndef getSentimentInt(s) :\n    if (s is \"negative\"):\n        return 0\n    elif (s is \"somewhat negative\"):\n        return 1\n    elif (s is \"neutral\"):\n        return 2\n    elif (s is \"somewhat positive\"):\n        return 3\n    elif (s is \"positive\"):\n        return 4\n    else: \n        return -1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65f1ba27e15515b08f77f113cb03149705bcf066"},"cell_type":"code","source":"#https://spacy.io/usage/training#training-simple-style\n#format of TRAIN_DATA = [  (\"sentence 1\", {'entities': [(0, 4, 'ORG')]}),\n#  (\"sentence 2\", {'entities': [(0, 6, \"ORG\")]})]\n#sample training data\n#data=('I actually really like ... incarnations.', {'cats': {'POSITIVE': True}})\ncats = []\ni = 0\nfor y in train_cats:\n    valueDict = {}\n    for j in 0,1,2,3,4:\n        if (y == j):\n            valueDict[getSentimentStr(j)]= True\n        else:\n            valueDict[getSentimentStr(j)]= False\n    dict1 = { 'cats' : valueDict}\n    cats.append(dict1)\n    i = i +1\n\ntrain_data = list(zip(train_texts,cats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"538e16cbbb0594a1c2680a7b7e360753667751a2"},"cell_type":"code","source":"# print one sample to see if everything is ok\nprint(\"text0=\",train_data[0])\nprint(\"text1=\",train_data[1])\nprint(\"text2=\",train_data[2])\nprint(\"text3=\",train_data[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9cd7b220b013c869150d9c42fcc5ad0015b9cf8"},"cell_type":"code","source":"print(nlp_en.pipe_names)\n# add the text classifier to the pipeline if it doesn't exist\ntextcat = nlp_en.create_pipe('textcat')\n\nnlp_en.add_pipe(textcat, last=True)\n\n# add label to text classifier\nfor i in [getSentimentStr(0), getSentimentStr(1), getSentimentStr(2),getSentimentStr(3),getSentimentStr(4)]:\n    textcat.add_label(i)\n\nprint(nlp_en.pipe_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54dc0849059f356b31173ad156d33baf3a42492a"},"cell_type":"code","source":"from __future__ import unicode_literals, print_function\nfrom spacy.util import minibatch, compounding\n\nNUM_OF_ITERATIONS=5\n\n# get names of other pipes to disable them during training\nother_pipes = [pipe for pipe in nlp_en.pipe_names if pipe != 'textcat']\nwith nlp_en.disable_pipes(*other_pipes):  # only train textcat\n    optimizer = nlp_en.begin_training()\n    print(\"Training the model...\")\n    #print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n    print('{:^5}\\t'.format('LOSS'))\n    \n    for i in range(NUM_OF_ITERATIONS):\n        losses = {}\n        # batch up the examples using spaCy's minibatch\n        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            #print(type(texts)) # class tuple\n            #print(type(annotations)) # class tuple\n            nlp_en.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n            \n        #with textcat.model.use_params(optimizer.averages):\n        # evaluate on the dev data split off in load_data()\n            #scores = evaluate(nlp_en.tokenizer, textcat, val_texts, val_cats)\n            #print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  # print a simple table\n                #.format(losses['textcat'], scores['textcat_p'], scores['textcat_r'], scores['textcat_f']))\n        # print losses\n        print('{0:.3f}'.format(losses['textcat']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"709fda46517594f6ea9baaf4f9854c333c7bbdda"},"cell_type":"code","source":"from pathlib import Path\noutput_dir=\"/tmp/\"\noutput_dir = Path(output_dir)\nnlp_en.to_disk(output_dir)\nprint(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"735f7aa468a6bece6480973784d306bfbbff0eca"},"cell_type":"code","source":"# test the trained model\ntest_text = \"This movie sucked\"\ndoc = nlp_en(test_text)\nprint(test_text, doc.cats)\nprint(test_text, sorted(doc.cats.items(), key=lambda val: val[1], reverse=True))\n    \n# test the saved model\nprint(\"Loading from\", output_dir)\nnlp2 = spacy.load(output_dir)\ndoc2 = nlp2(test_text)\nprint(test_text, doc2.cats)\nprint(test_text, sorted(doc2.cats.items(), key=lambda val: val[1], reverse=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"153f7f89d08711ebca7d8ea3083de21e7aa331b8"},"cell_type":"code","source":"rawtestdf.describe()\n#print(type(doc2.cats)) # dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5459d75c15c4fa8291c91728d2dca51966a0b68b"},"cell_type":"code","source":"mydict = doc2.cats\nfor key, value in sorted(mydict.items(),  key=lambda val: val[1], reverse=True):\n    print (\"%s: %s\" % (key, value))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a87e239bb4e14d865ab98b5540facf00296e145"},"cell_type":"code","source":"# test \nimport csv\nwith open('output.csv', 'w') as csvfile:\n    writer = csv.writer(csvfile, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow(['PhraseId', 'Sentiment'])\n    for index, row in rawtestdf.iterrows():\n        phraseId = row['PhraseId']\n        text = row['Phrase']\n        doc = nlp_en(text)\n        for key, value in sorted(doc.cats.items(),  key=lambda val: val[1], reverse=True):\n            writer.writerow([phraseId, getSentimentInt(key)])\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c65e57a3ee3acecc577c76256e30108e33a6e81a"},"cell_type":"code","source":"from itertools import islice\nwith open('output.csv') as myfile:\n    head = list(islice(myfile, 10))\nprint(head)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}