{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9db529c4d5a6000ef5f7f66dac4bd16b8d2f4f7a"},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1647abc0863c90f50b4c1a76a373f8e4eb89d3d8"},"cell_type":"markdown","source":"Total of 9957 rows in the training set. Let's calculate the NaN values in all the columns. Columns with high % of NaN can be dropped, wit 30-40% of data and rest of it as average or 0 doesn't make sense, better to drop those columns. Only 5 columns have NaN values, rather than worrying about it, let's drop them. Very few features going away anyways. \n\nWill need to drop the same 5 columns from test set also."},{"metadata":{"trusted":true,"_uuid":"afed7c4b814ab4c6ad780d2dd831e5ba28ad3b4f"},"cell_type":"code","source":"train=train.dropna(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123610084a40dcfa68ca7e928d5becbbf0796bc2"},"cell_type":"code","source":"missing_col=set(test)-set(train)\ntest=test.drop(columns=missing_col,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e08c53e17db70e7cd4a3e7769749a73d1fc71bf5"},"cell_type":"code","source":"xtrain=train.copy()\nxtest=test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0efebcd3404678e1404b568973ea6b6889f521a8"},"cell_type":"code","source":"ytrain=xtrain['Target']\nytrain=ytrain.as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bde0fcf462c9d25a23f95eaad04f0a5ad62d6712"},"cell_type":"code","source":"xtrain=xtrain.drop(columns=['Id','Target','idhogar','dependency','edjefe','edjefa'])\nxtest=xtest.drop(columns=['Id','idhogar','dependency','edjefe','edjefa'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b65db7f175dc201385b80796627b7db37bbfc59"},"cell_type":"markdown","source":"Let us use Light GBM (microsoft variant of XGBoost for prediction). Based on our experience, XGBoost gives better prediction results than Deep Learning, so trying Light GBM. Can also use XG Boost and then see the difference."},{"metadata":{"trusted":true,"_uuid":"045ac7c40c7ff1c7e33fca000c8ff3af4d1f7939"},"cell_type":"code","source":"import xgboost as xgb\n\nmodel=xgb.XGBClassifier(eta=0.2)\nmodel.fit(xtrain,ytrain)\n\nypred=model.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bb40cb250c39bfae8f0fd53b0acade0650619ff"},"cell_type":"code","source":"ytrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68874460a54cba95b44c0d76c7294a3ef70bfa92"},"cell_type":"code","source":"from keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras.layers import Dropout\nfrom keras.utils import to_categorical\n\nytrain=to_categorical(ytrain)\n\nmodel_d=models.Sequential()\nmodel_d.add(layers.Dense(128,activation='relu',input_shape=(xtrain.shape[1],)))\nmodel_d.add(Dropout(0.2))\nmodel_d.add(layers.Dense(128,activation='relu'))\nmodel_d.add(Dropout(0.2))\nmodel_d.add(layers.Dense(5,activation='softmax'))\n\nrmsprop=optimizers.RMSprop(lr=0.01)\n\nmodel_d.compile(optimizer=rmsprop,loss='categorical_crossentropy',metrics=['accuracy'])\n\nmodel_d.fit(xtrain,ytrain,epochs=32,batch_size=32)\n\nypred_d=model_d.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d629878fedf0224cbb9a563b03a2fc183766418d"},"cell_type":"code","source":"submission=pd.read_csv('../input/sample_submission.csv')\nsubmission['Target']=ypred\n\nsubmission.to_csv('sample_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"805acdb61e479fe5d5dc077dba457e23d5745405"},"cell_type":"code","source":"ypred_d\nprediction_deep=[]\nfrom numpy import argmax\n\nfor x in ypred_d:\n    prediction_deep.append(np.argmax(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d93aa0f8020250ce6165cf3ca3e1e65083371314"},"cell_type":"code","source":"submission_d=pd.read_csv('../input/sample_submission.csv')\nsubmission_d['Target']=prediction_deep\n\nsubmission_d.to_csv('sample_submission_deeplearning.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}