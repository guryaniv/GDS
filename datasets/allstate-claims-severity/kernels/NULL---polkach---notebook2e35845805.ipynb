{"cells":[{"metadata":{"_cell_guid":"f1d22893-eb14-3a8f-aa2b-c6dfe54e382e","_uuid":"09048a3cceebc784dceaa9c924fd4cad2314d87f","trusted":false,"collapsed":true},"cell_type":"code","source":"ls","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"952176e1-814e-9482-523b-073de0ddc5f4","_uuid":"e9ba568dc9fcaa124d48eb758b34ae30e6930ab4","trusted":false,"collapsed":true},"cell_type":"code","source":"''' \nAuthor: Danijel Kivaranovic \nTitle: Neural network (Keras) with sparse data\n'''\n\n## import libraries\nimport numpy as np\nnp.random.seed(123)\n\nimport pandas as pd\nimport subprocess\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\n\n## Batch generators ##################################################################################################################################\n\ndef batch_generator(X, y, batch_size, shuffle):\n    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n    number_of_batches = np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    if shuffle:\n        np.random.shuffle(sample_index)\n    while True:\n        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n        X_batch = X[batch_index,:].toarray()\n        y_batch = y[batch_index]\n        counter += 1\n        yield X_batch, y_batch\n        if (counter == number_of_batches):\n            if shuffle:\n                np.random.shuffle(sample_index)\n            counter = 0\n\ndef batch_generatorp(X, batch_size, shuffle):\n    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    while True:\n        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n        X_batch = X[batch_index, :].toarray()\n        counter += 1\n        yield X_batch\n        if (counter == number_of_batches):\n            counter = 0\n\n########################################################################################################################################################\n\n## read data\ntrain = pd.read_csv('input/train.csv')\ntest = pd.read_csv('input/test.csv')\n\nindex = list(train.index)\nprint(index[0:10])\nnp.random.shuffle(index)\nprint(index[0:10])\ntrain = train.iloc[index]\n'train = train.iloc[np.random.permutation(len(train))]'\n\n## set test loss to NaN\ntest['loss'] = np.nan\n\n## response and IDs\ny = np.log(train['loss'].values+200)\nid_train = train['id'].values\nid_test = test['id'].values\n\n## stack train test\nntrain = train.shape[0]\ntr_te = pd.concat((train, test), axis = 0)\n\n## Preprocessing and transforming to sparse data\nsparse_data = []\n\nf_cat = [f for f in tr_te.columns if 'cat' in f]\nfor f in f_cat:\n    dummy = pd.get_dummies(tr_te[f].astype('category'))\n    tmp = csr_matrix(dummy)\n    sparse_data.append(tmp)\n\nf_num = [f for f in tr_te.columns if 'cont' in f]\nscaler = StandardScaler()\ntmp = csr_matrix(scaler.fit_transform(tr_te[f_num]))\nsparse_data.append(tmp)\n\ndel(tr_te, train, test)\n\n## sparse train and test data\nxtr_te = hstack(sparse_data, format = 'csr')\nxtrain = xtr_te[:ntrain, :]\nxtest = xtr_te[ntrain:, :]\n\nprint('Dim train', xtrain.shape)\nprint('Dim test', xtest.shape)\n\ndel(xtr_te, sparse_data, tmp)\n\n## neural net\ndef nn_model():\n    model = Sequential()\n    \n    model.add(Dense(400, input_dim = xtrain.shape[1], init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n        \n    model.add(Dense(200, init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(50, init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(1, init = 'he_normal'))\n    model.compile(loss = 'mae', optimizer = 'adadelta')\n    return(model)\n\n## cv-folds\nnfolds = 10\nfolds = KFold(len(y), n_folds = nfolds, shuffle = True, random_state = 111)\n\n## train models\ni = 0\nnbags = 10\nnepochs = 55\npred_oob = np.zeros(xtrain.shape[0])\npred_test = np.zeros(xtest.shape[0])\n\nfor (inTr, inTe) in folds:\n    xtr = xtrain[inTr]\n    ytr = y[inTr]\n    xte = xtrain[inTe]\n    yte = y[inTe]\n    pred = np.zeros(xte.shape[0])\n    for j in range(nbags):\n        model = nn_model()\n        fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),\n                                  nb_epoch = nepochs,\n                                  samples_per_epoch = xtr.shape[0],\n                                  verbose = 0)\n        pred += np.exp(model.predict_generator(generator = batch_generatorp(xte, 800, False), val_samples = xte.shape[0])[:,0])-200\n        pred_test += np.exp(model.predict_generator(generator = batch_generatorp(xtest, 800, False), val_samples = xtest.shape[0])[:,0])-200\n    pred /= nbags\n    pred_oob[inTe] = pred\n    score = mean_absolute_error(np.exp(yte)-200, pred)\n    i += 1\n    print('Fold ', i, '- MAE:', score)\n\nprint('Total - MAE:', mean_absolute_error(np.exp(y)-200, pred_oob))\n\n## train predictions\ndf = pd.DataFrame({'id': id_train, 'loss': pred_oob})\ndf.to_csv('preds_oob.csv', index = False)\n\n## test predictions\npred_test /= (nfolds*nbags)\ndf = pd.DataFrame({'id': id_test, 'loss': pred_test})\ndf.to_csv('submission_keras_shift_perm.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c0ff3a20-b7e2-4123-ece3-90eca111faf5","_uuid":"a3a8ebf2be39aee992a174e77c9b644e1a3ee5c6"},"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n''' \nAuthor: Danijel Kivaranovic \nTitle: Neural network (Keras) with sparse data\n'''\n\n## import libraries\nimport numpy as np\nnp.random.seed(123)\n\nimport pandas as pd\nimport subprocess\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cross_validation import KFold\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.advanced_activations import PReLU\n\n## Batch generators ##################################################################################################################################\n\ndef batch_generator(X, y, batch_size, shuffle):\n    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n    number_of_batches = np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    if shuffle:\n        np.random.shuffle(sample_index)\n    while True:\n        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n        X_batch = X[batch_index,:].toarray()\n        y_batch = y[batch_index]\n        counter += 1\n        yield X_batch, y_batch\n        if (counter == number_of_batches):\n            if shuffle:\n                np.random.shuffle(sample_index)\n            counter = 0\n\ndef batch_generatorp(X, batch_size, shuffle):\n    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    while True:\n        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n        X_batch = X[batch_index, :].toarray()\n        counter += 1\n        yield X_batch\n        if (counter == number_of_batches):\n            counter = 0\n\n########################################################################################################################################################\n\n## read data\ntrain = pd.read_csv('train.csv')\ntest = pd.read_csv('test.csv')\n\nindex = list(train.index)\nprint(index[0:10])\nnp.random.shuffle(index)\nprint(index[0:10])\ntrain = train.iloc[index]\n'train = train.iloc[np.random.permutation(len(train))]'\n\n## set test loss to NaN\ntest['loss'] = np.nan\n\n## response and IDs\ny = np.log(train['loss'].values+200)\nid_train = train['id'].values\nid_test = test['id'].values\n\n## stack train test\nntrain = train.shape[0]\ntr_te = pd.concat((train, test), axis = 0)\n\n## Preprocessing and transforming to sparse data\nsparse_data = []\n\nf_cat = [f for f in tr_te.columns if 'cat' in f]\nfor f in f_cat:\n    dummy = pd.get_dummies(tr_te[f].astype('category'))\n    tmp = csr_matrix(dummy)\n    sparse_data.append(tmp)\n\nf_num = [f for f in tr_te.columns if 'cont' in f]\nscaler = StandardScaler()\ntmp = csr_matrix(scaler.fit_transform(tr_te[f_num]))\nsparse_data.append(tmp)\n\ndel(tr_te, train, test)\n\n## sparse train and test data\nxtr_te = hstack(sparse_data, format = 'csr')\nxtrain = xtr_te[:ntrain, :]\nxtest = xtr_te[ntrain:, :]\n\nprint('Dim train', xtrain.shape)\nprint('Dim test', xtest.shape)\n\ndel(xtr_te, sparse_data, tmp)\n\n## neural net\ndef nn_model():\n    model = Sequential()\n    \n    model.add(Dense(400, input_dim = xtrain.shape[1], init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n        \n    model.add(Dense(200, init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(50, init = 'he_normal'))\n    model.add(PReLU())\n    model.add(BatchNormalization())    \n    model.add(Dropout(0.2))\n    \n    model.add(Dense(1, init = 'he_normal'))\n    model.compile(loss = 'mae', optimizer = 'adadelta')\n    return(model)\n\n## cv-folds\nnfolds = 10\nfolds = KFold(len(y), n_folds = nfolds, shuffle = True, random_state = 111)\n\n## train models\ni = 0\nnbags = 10\nnepochs = 55\npred_oob = np.zeros(xtrain.shape[0])\npred_test = np.zeros(xtest.shape[0])\n\nfor (inTr, inTe) in folds:\n    xtr = xtrain[inTr]\n    ytr = y[inTr]\n    xte = xtrain[inTe]\n    yte = y[inTe]\n    pred = np.zeros(xte.shape[0])\n    for j in range(nbags):\n        model = nn_model()\n        fit = model.fit_generator(generator = batch_generator(xtr, ytr, 128, True),\n                                  nb_epoch = nepochs,\n                                  samples_per_epoch = xtr.shape[0],\n                                  verbose = 0)\n        pred += np.exp(model.predict_generator(generator = batch_generatorp(xte, 800, False), val_samples = xte.shape[0])[:,0])-200\n        pred_test += np.exp(model.predict_generator(generator = batch_generatorp(xtest, 800, False), val_samples = xtest.shape[0])[:,0])-200\n    pred /= nbags\n    pred_oob[inTe] = pred\n    score = mean_absolute_error(np.exp(yte)-200, pred)\n    i += 1\n    print('Fold ', i, '- MAE:', score)\n\nprint('Total - MAE:', mean_absolute_error(np.exp(y)-200, pred_oob))\n\n## train predictions\ndf = pd.DataFrame({'id': id_train, 'loss': pred_oob})\ndf.to_csv('preds_oob.csv', index = False)\n\n## test predictions\npred_test /= (nfolds*nbags)\ndf = pd.DataFrame({'id': id_test, 'loss': pred_test})\ndf.to_csv('submission_keras_shift_perm.csv', index = False)\n\n# Any results you write to the current directory are saved as output."}],"metadata":{"_is_fork":false,"_change_revision":0,"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.5.2","mimetype":"text/x-python","name":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}