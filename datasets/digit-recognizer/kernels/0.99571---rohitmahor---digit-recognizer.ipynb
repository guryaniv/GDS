{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"_uuid":"679b30f517251d65c241667088f178281b61fd54","collapsed":true,"_cell_guid":"eb795308-5318-40c5-97f5-07ac7ea7d166","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/train.csv')\nX = dataset.iloc[:, 1:].values\ny = dataset.iloc[:, 0:1].values\n\ntest_set = pd.read_csv('../input/test.csv').values","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"5e69cf36b01a70f4b4188d90fc20b93b0b68c722","_cell_guid":"3dd9e3f3-8a3f-4cca-b3a4-e7bc6c4197e8","trusted":true},"cell_type":"code","source":"print(dataset.info())\nprint(X.shape)\nprint(y.shape)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"51ba735d4242045478f83f5ba7abe811321359f9","_cell_guid":"1187a88f-1e57-4dff-a16a-ac538bd1083f"},"cell_type":"markdown","source":"### From above we can conclude that,\n*  28 X 28 Image-size\n* 42000 images in training set\n\n# Data preprocessing\n### 1.  Reshape X and test set"},{"metadata":{"_uuid":"5b236ed73ca27f2fd8cf9ec3063763b48147742c","collapsed":true,"_cell_guid":"3a46b0e8-300a-4eae-a771-6cbe44b1f361","trusted":true},"cell_type":"code","source":"X = X.reshape(X.shape[0], 28, 28, 1)\ntest_set = test_set.reshape(test_set.shape[0], 28, 28, 1)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"946c38e75663d4196436f0eccd328bfc96ae0acd","_cell_guid":"8abfb648-0af8-459f-ad44-956bcb3d3371"},"cell_type":"markdown","source":"### 2. Categorical data"},{"metadata":{"_uuid":"c5f678374b9652d9db607f21d5a9bbc1a889950f","_cell_guid":"d095675b-7dd9-4b27-bc40-24b9360e3df4","trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nencoder = OneHotEncoder()\nencoder.fit(y)\ny = encoder.transform(y).toarray()\nprint(y.shape)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"19889e5f7afc2766affeb5a37e957a008b3a61f1","_cell_guid":"43f9d887-7701-4330-a603-002225b428c0"},"cell_type":"markdown","source":"### 3. Normalization"},{"metadata":{"_uuid":"cebe55b858a370765f138493b89b458a456d477c","collapsed":true,"_cell_guid":"54f713c1-6e77-4066-a248-faa954453ddd","trusted":true},"cell_type":"code","source":"X = X/255.0\ntest_set = test_set/255.0","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"97a9caf1890f91217618cc4c0332a37b4947424a","_cell_guid":"17c000fb-db40-4899-ae0c-60019c19de71"},"cell_type":"markdown","source":"### 4. Split Dataset for evaluation"},{"metadata":{"_uuid":"62db76fda72f07ac8422f57a8edbe47af54d2af4","collapsed":true,"_cell_guid":"89917f92-32e1-456d-93dc-bb26f80211c6","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"3c8b7e4b36d71d21b2cc8e045512c9859eae4e1e","_cell_guid":"0c4c8257-d887-4233-8754-d7a9c27a116a"},"cell_type":"markdown","source":"# Define CNN\n### 1. Import libraries"},{"metadata":{"_uuid":"dc37810ba0bf83ed7e4d23efaf929fad1b3a6e9d","_cell_guid":"24d2da6b-38b9-48b6-8402-98e64b88577e","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"81d99002338cf6cde67950c89943c4b6acaa0909","_cell_guid":"88d3b920-2552-448d-8b4b-6cf601e1e1f2"},"cell_type":"markdown","source":"### 2. Define model"},{"metadata":{"_uuid":"a9132015dfa29c3ef248e5f2bd89c839c24ed705","_cell_guid":"de39271d-3bb6-4f03-b459-4d935dd56b0d","trusted":true},"cell_type":"code","source":"# intialization\nclf = Sequential()\n\n# Add layers\nclf.add(Convolution2D(filters=32, kernel_size=(5,5), input_shape=(28, 28, 1), activation='relu'))\nclf.add(Convolution2D(filters=32, kernel_size=(5, 5), activation='relu'))\nclf.add(MaxPooling2D(2,2))\nclf.add(Dropout(0.25))\n\nclf.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'))\nclf.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'))\nclf.add(MaxPooling2D(2,2))\nclf.add(Dropout(0.25))\n\nclf.add(Flatten())\n\n# full connection\nclf.add(Dense(output_dim=256, activation='relu'))\nclf.add(Dropout(0.25))\nclf.add(Dense(output_dim=10, activation='sigmoid'))\n\n# Compile the model\nclf.compile(optimizer = 'adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"07f1b070495c8d370ae0b42503085d3ae0de166b","_cell_guid":"d639c7a7-4c5a-4824-8ee4-501602150280"},"cell_type":"markdown","source":"### 3. Data Augmentation [(Documentation)](https://keras.io/preprocessing/image/)"},{"metadata":{"_uuid":"c630f97748c61d8709d013848f47214b31c70a7b","collapsed":true,"_cell_guid":"45d56601-2daa-481d-baad-76f2ff066315","trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=15,  # Rotate by 15 degree\n    width_shift_range=0.1, # width shift by 10%\n    height_shift_range=0.1, # height shift by 10%\n    zoom_range=0.1,  # Zoom by 10%\n    preprocessing_function=None)","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"a4fdf32fb41295ce49af35ee542506fbfa5f78ba","collapsed":true,"_cell_guid":"74bf540b-866b-4c35-aef0-a75474fddc0f","trusted":true},"cell_type":"code","source":"datagen.fit(X_train)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"6d89aeb0abe37b77c389070590d5f76e41438640","_cell_guid":"722ca9ad-74fd-4972-ba86-73a320a16d76"},"cell_type":"markdown","source":"### 4. Learning rate reduce to half when model hit plateau"},{"metadata":{"_uuid":"4eee6abdc923ce360b47b17c9adb3068f119d323","collapsed":true,"_cell_guid":"c8c1d13e-7f63-46f4-bbd0-0af0d1eabacc","trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nlearningRate = ReduceLROnPlateau(monitor='val_loss',\n                                 factor=0.5,\n                                 patience=5,\n                                 verbose=0,\n                                 min_lr=0.00001)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"1c1ab6bdfb2317afd3a814aef69eddb1cb3a9468","_cell_guid":"9c7e8983-f710-45ef-bb4d-c916af62a99e","trusted":true,"scrolled":true},"cell_type":"code","source":"history = clf.fit_generator(datagen.flow(X_train,y_train, batch_size=100),\n                              epochs = 30, validation_data = (X_test,y_test),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // 100\n                              , callbacks=[learningRate])","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"876e8a43fde451a4d537b8a44638046c3fafd0f2","_cell_guid":"b377da01-7fdc-4ad6-a762-81996344cb4a"},"cell_type":"markdown","source":"# Evaluation \n### 1.  Visualization"},{"metadata":{"_uuid":"6ab32c4fc284ab16f2b6d680e65c1aa669bd68ac","_cell_guid":"1190e828-77ff-4017-b6b1-e2e8edca880f","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"ac9849a16843f99783103fbe139893ad5bfb679c","_cell_guid":"010a07b7-bb66-4846-b0c2-20a644ae72d8"},"cell_type":"markdown","source":"### 2. Confusion matrix"},{"metadata":{"_uuid":"ef49338c12c0b6b333a1b17950dd326ed4473e8d","scrolled":true,"_cell_guid":"c2ef454d-ad97-4c83-9e76-1c718c3ffa82","trusted":true},"cell_type":"code","source":"y_pred = clf.predict(X_test)\ny_pred1 = [w.argmax() for w in y_pred]\ny_test1 = [w.argmax() for w in y_test]\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test1, y_pred1)\nprint(cm)\n\nscore = clf.evaluate(X_test, y_test)\nprint(score)","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"c4b726cf5edd33199956c5ba0078d64569421b6c","collapsed":true,"_cell_guid":"f6ca43c4-32c8-45a2-ab71-469993f7feaf","trusted":true},"cell_type":"code","source":"# predict final results\nresults = clf.predict(test_set)\n\n# select the index with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_result_1.csv\",index=False)","execution_count":32,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}