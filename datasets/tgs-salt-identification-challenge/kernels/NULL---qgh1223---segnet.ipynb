{"cells":[{"metadata":{"_uuid":"57250d0f9272843c722662636889477a801c0b7a"},"cell_type":"markdown","source":"My code references https://www.kaggle.com/rdebbe/is-segnet-a-good-model-for-sharp-edge-masking"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e05f437429ec8eeac2c8afd8360d8e92873059f5"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nfrom skimage.io import imread,imshow\nfrom skimage.transform import resize\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#import Augmentor\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7b7e110dde52f1ac5fad35d7ad6755313e751375"},"cell_type":"code","source":"from keras.models import Model,Sequential\nfrom keras.layers.core import Activation, Reshape, Permute\nfrom keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers import Input, merge, Conv2D,Concatenate\nfrom keras.optimizers import Adam\nfrom keras.optimizers import SGD\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\nfrom keras.callbacks import ReduceLROnPlateau, TensorBoard, Callback\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.losses import binary_crossentropy\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9f6908194f90a6da8c497461e337d5d5026e29d0"},"cell_type":"code","source":"IMG_ROW=IMG_COL=64\nIMG_CHANNEL=3\nTRAIN_IMG_DIR='../input/train/images/'\nTRAIN_MASK_DIR='../input/train/masks/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9d195a4a5a64fc6f7716de4349a8eaece90d5698"},"cell_type":"code","source":"def get_img_mask_array(imgpath,maskpath):\n    img=imread(imgpath)[:,:,:IMG_CHANNEL]\n    img=resize(img,(IMG_ROW,IMG_COL),mode='constant',\n               preserve_range=True)\n    mask=np.zeros((IMG_ROW,IMG_COL,1),dtype=np.bool)\n    mask_=imread(maskpath)\n    mask_=np.expand_dims(resize(mask_,(IMG_ROW,IMG_COL),\n                                mode='constant',preserve_range=True),\n                         axis=-1)\n    mask=np.maximum(mask,mask_)\n    mask1=[]\n    for i in range(len(mask)):\n        arr1=[]\n        for j in range(len(mask[i])):\n            if(mask[i][j]==0.):\n                arr1.append(1)\n                arr1.append(0)\n            else:\n                arr1.append(0)\n                arr1.append(1)\n        mask1.append(np.asarray(arr1))\n    mask1=np.asarray(mask1)\n    mask=mask1.reshape((IMG_ROW*IMG_COL,2))\n    return np.asarray(img),np.asarray(mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"04172861b76680e31aab4180170c0e306ba2f875"},"cell_type":"code","source":"imgarray=[]\nmaskarray=[]\nfor path in os.listdir(TRAIN_IMG_DIR):\n    #print(i)\n    if(os.path.isfile(TRAIN_IMG_DIR+path)):\n        img,mask=get_img_mask_array(TRAIN_IMG_DIR+path,TRAIN_MASK_DIR+path)\n        imgarray.append(img)\n        maskarray.append(mask)\nprint(np.asarray(imgarray).shape)\nprint(np.asarray(maskarray).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"799accdf3c7313b65368992581b98719a11df2cd"},"cell_type":"code","source":"def build_model(img_w, img_h, filters):\n    n_labels = 2\n\n    kernel = 3\n\n    encoding_layers = [\n        Conv2D(64, (kernel, kernel), input_shape=(img_h, img_w, 3), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        MaxPooling2D(),\n    ]\n\n    autoencoder =Sequential()\n    autoencoder.encoding_layers = encoding_layers\n\n    for l in autoencoder.encoding_layers:\n        autoencoder.add(l)\n\n    decoding_layers = [\n        UpSampling2D(),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(512, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(256, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(128, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n\n        UpSampling2D(),\n        Convolution2D(64, (kernel, kernel), padding='same'),\n        BatchNormalization(),\n        Activation('relu'),\n        Convolution2D(n_labels, (1, 1), padding='valid', activation=\"sigmoid\"),\n        BatchNormalization(),\n    ]\n    autoencoder.decoding_layers = decoding_layers\n    for l in autoencoder.decoding_layers:\n        autoencoder.add(l)\n\n    autoencoder.add(Reshape((n_labels, img_h * img_w)))\n    autoencoder.add(Permute((2, 1)))\n    autoencoder.add(Activation('softmax'))\n\n    #with open('model_5l.json', 'w') as outfile:\n    #    outfile.write(json.dumps(json.loads(autoencoder.to_json()), indent=2))\n    autoencoder.summary()\n    return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"cd18d10119e94a089286bf4957b122b431fac0af"},"cell_type":"code","source":"model=build_model(IMG_ROW,IMG_COL,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3581db693dcaca1ceba2e9f23f5945e22287804f"},"cell_type":"code","source":"optimizer = SGD(lr=0.001, momentum=0.9, decay=0.0005, nesterov=False)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"16003200d0f353bf83e56ec8efbeb2bf13da6b58"},"cell_type":"code","source":"callbacks=[\n    EarlyStopping(patience=5,monitor='val_loss',verbose=1),\n    ReduceLROnPlateau(patience=3,monitor='val_loss',verbose=1),\n    ModelCheckpoint('model.h5',save_best_only=True)\n]\nhistory=model.fit(np.asarray(imgarray),np.asarray(maskarray),epochs=40,\n                  validation_split=0.1,callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1ba16e7eb8165a63da86304a59a7617fe91a0336"},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9e25ae247e8257c64ceafddba72601374dead8cc"},"cell_type":"code","source":"predict_result=model.predict(np.asarray(imgarray))\npredict_mask=predict_result.reshape((len(predict_result),IMG_ROW,IMG_COL,2))\nmaskarray=np.asarray(maskarray).reshape((len(maskarray),IMG_ROW,IMG_COL,2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e2bedead1d3bf1c83486a9e2594a592678c17c3b"},"cell_type":"code","source":"for i in range(10):\n    rnd_id=random.randint(0,len(imgarray)-1)\n    f,ax=plt.subplots(1,3,figsize=(15,2))\n    axes=ax.flatten()\n    j=0\n    for ax in axes:\n        if(j==0):\n            ax.imshow(imgarray[rnd_id])\n        elif(j==1):\n            ax.imshow(np.argmax(maskarray[rnd_id],axis=-1))\n        else:\n            ax.imshow(np.argmax(predict_mask[rnd_id],axis=-1))\n        j+=1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}