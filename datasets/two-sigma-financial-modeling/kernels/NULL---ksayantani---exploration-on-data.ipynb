{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8a2ba42-05f6-39ed-b4e1-19209e75ae4d",
        "_active": false
      },
      "outputs": [],
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\nimport sys\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "107ba22d-d52b-2f65-2b98-55decd0529d8",
        "_active": false
      },
      "outputs": [],
      "source": "import kagglegym\n\nenv = kagglegym.make()\nobservation = env.reset()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "abc3ec03-f02a-4427-f436-94121a2c2009",
        "_active": false
      },
      "outputs": [],
      "source": "train = observation.train\nID = \"id\"\nTSTAMP = \"timestamp\"\nTARGET = \"y\"\n(len(train[\"timestamp\"].unique()), min(train[\"timestamp\"]), max(train[\"timestamp\"]))",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93f880fd-9c96-a91e-de8f-558c7f3811dd",
        "_active": false
      },
      "outputs": [],
      "source": "def findMissingCounts(df, columns):\n    labels = []\n    missing = []\n    for column in columns:\n        labels.append(column)\n        missing.append(df[column].isnull().sum())\n    return labels, missing",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16b14e40-2bcd-a01f-df19-e6b501af1f92",
        "_active": false
      },
      "outputs": [],
      "source": "def createHorizontalBarPlot(labels, missing, plot_width, plot_height):\n    N = len(labels)\n    ind = np.arange(N)\n    width = 0.35\n\n    fig, ax = plt.subplots(figsize = (plot_width, plot_height))\n    rects = ax.barh(ind, missing, width, align='center', color=\"lightskyblue\")\n    ax.set_yticks(ind + width)\n    ax.set_yticklabels(labels)\n    plt.show()\n    plt.close()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3609dd54-b59a-d173-226c-d4e4d6e7d58a",
        "_active": false
      },
      "outputs": [],
      "source": "def findMatchedColumnsUsingPrefix(prefix, df):\n    columns = df.columns[df.columns.str.startswith(prefix)]\n    return list(columns.values)\n    \nderived_columns = findMatchedColumnsUsingPrefix(\"derived\", train)\nfundamental_columns = findMatchedColumnsUsingPrefix(\"fundamental\", train)\ntechnical_columns = findMatchedColumnsUsingPrefix(\"technical\", train)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "629ce772-ecec-30dc-e107-00deb209acb0",
        "_active": false
      },
      "outputs": [],
      "source": "ids = train[ID].unique()\ntstamps = train[TSTAMP].unique()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "971cfdd6-0e21-1036-8775-2eebe622a705",
        "_active": false
      },
      "outputs": [],
      "source": "id_groups = train.groupby(ID)\nsample_df = id_groups.get_group(ids[0]).reset_index(drop = True)\nsample_df.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c581052-f36f-c26e-3555-09693e256999",
        "_active": false
      },
      "outputs": [],
      "source": "def findMissingEntriesForIds(columns, train):\n    indexes = []\n    rows = {}\n    for id, group in train.groupby('id'):\n        indexes.append(id)\n        for column in columns:\n            rows[column] = sample_df[column].isnull().sum()\n            \n    df = pd.DataFrame(rows, index = indexes)\n    df.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\n    df = df.stack(0).reset_index(1)\n    df.sort_index()\n    return df",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdd221be-b2d4-126d-2344-0ee5aefb3cd0",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "result = findMissingEntriesForIds(derived_columns, train)\nresult.head(2)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c9009ea-56e0-f4c6-d992-5acc9a975c9d",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "result = findMissingEntriesForIds(fundamental_columns, train)\nresult.head(2)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "194f44d9-f88b-8e44-b1eb-64b542b0292d",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "result = findMissingEntriesForIds(technical_columns, train)\nresult.head(2)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b0c5ee9-994e-1645-9ce3-0ba39b2345cc",
        "_active": false
      },
      "outputs": [],
      "source": "def findMissingEntriesForIds(columns, train):\n    indexes = []\n    rows = {}\n    for id, group in train.groupby('id'):\n        indexes.append(id)\n        for column in columns:\n            rows[column] = sample_df[column].isnull().sum()\n            \n    df = pd.DataFrame(rows, index = indexes)\n    df.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\n    df = df.stack(0).reset_index(1)\n    df.sort_index()\n    return df",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "282fb90d-46cc-7a05-70f9-36e859cac6cb",
        "_active": false
      },
      "outputs": [],
      "source": "def findMaximumNullColumns(res):\n    names = []\n    values = []\n    for column in res.columns:\n        if column == 'level_1':\n            continue\n        if res[column].sum() > 0:\n            name = res['level_1'].unique()[0] + '_' + column\n            names.append(name)\n            values.append(res[column].sum())\n    return pd.DataFrame({'columns' : names, 'counts' : values})",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "813ecb97-6943-936b-11c2-71b4ed22be03",
        "_active": false
      },
      "outputs": [],
      "source": "res = findMaximumNullColumns(findMissingEntriesForIds(derived_columns, train))\nlabels = res['columns']\nmissing = res['counts']\ncreateHorizontalBarPlot(labels, missing, 5, 5)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b22244d6-ba48-5e60-72a9-34a544f6688c",
        "_active": false
      },
      "outputs": [],
      "source": "res = findMaximumNullColumns(findMissingEntriesForIds(fundamental_columns, train))\nlabels = res['columns']\nmissing = res['counts']\ncreateHorizontalBarPlot(labels, missing, 5, 5)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb365fc7-3db5-1e4a-0aa8-41182fb8d5d9",
        "_active": false
      },
      "outputs": [],
      "source": "res = findMaximumNullColumns(findMissingEntriesForIds(technical_columns, train))\nlabels = res['columns']\nmissing = res['counts']\ncreateHorizontalBarPlot(labels, missing, 5, 5)",
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "07af362b-5526-f445-c285-6b2fedfb4578",
        "_active": true,
        "collapsed": false
      },
      "source": null,
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    }
  ]
}