{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1a65030d-fa8f-45f6-4ee1-c43557004640"
      },
      "source": [
        "Single XGB cv score 0.5281,but LB only 0.5447,why???"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc916937-201d-d9a3-1059-8b9d205f2710"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f64d69e-d0ab-e3ec-344b-bfbf872f32d1"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    train_path=\"./train.json\"\n",
        "    test_path=\"./test.json\"\n",
        "    train=pd.read_json(train_path)\n",
        "    y=train['interest_level'].reset_index(drop=True)\n",
        "    y_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "    y = y.apply(lambda x: y_map[x])\n",
        "    test=pd.read_json(test_path).reset_index(drop=True)\n",
        "    listing_id=test.listing_id\n",
        "    return train,test,y,listing_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd3e4b47-db8a-7b11-9324-9d10f4ad854c"
      },
      "outputs": [],
      "source": [
        "def process_buildingid(data,data1):\n",
        "    fea=['building_id','price','manager_id','bathrooms','bedrooms','latitude','longitude']\n",
        "    subdata=data[fea].reset_index(drop=True)\n",
        "    subdata=pd.concat((subdata,data1[['Month','Wday','Diff_days']]),axis=1)\n",
        "    t=subdata[['building_id','price']]\n",
        "    t['building_count']=1\n",
        "    t=t.groupby(['building_id']).agg('count').reset_index()\n",
        "    t.drop('price',axis=1,inplace=True)\n",
        "\n",
        "    t1=subdata[['building_id','price','bathrooms','bedrooms','latitude','longitude','Month','Wday','Diff_days']]\n",
        "    t1['room_size']=t1['bathrooms']+t1['bedrooms']\n",
        "    t1.drop(['bathrooms','bedrooms'],axis=1,inplace=True)\n",
        "    \n",
        "    subdata=pd.merge(subdata,t,on='building_id',how='left')\n",
        "    \n",
        "    status=['sum','mean','min','max','median']\n",
        "    for i,statu in enumerate(status):\n",
        "        temp=t1.groupby('building_id').agg(statu).reset_index()\n",
        "        temp.rename(columns={'price':'build_price_{}'.format(statu),'latitude':'build_lat_{}'.format(statu),'longitude':'build_lon_{}'.format(statu),\n",
        "                             'Month':'build_month_{}'.format(statu),'Wday':'build_Wday_{}'.format(statu),\n",
        "                             'Diff_days':'build_daydiff_{}'.format(statu),'room_size':'build_room_{}'.format(statu)},inplace=True)\n",
        "        subdata=pd.merge(subdata,temp,on='building_id',how='left')\n",
        "\n",
        "    t7=data[fea].reset_index(drop=True)\n",
        "    t7=pd.concat((t7,data1[['Month','Wday','Diff_days']]),axis=1)\n",
        "    t7['room_size']=t7['bathrooms']+t7['bedrooms']\n",
        "    t7.drop(['bathrooms','bedrooms'],axis=1,inplace=True)\n",
        "\n",
        "    t8=t7[['building_id','manager_id']]\n",
        "    t8['build_manager_count']=1\n",
        "    t8=t8.groupby(['building_id','manager_id']).agg('sum').reset_index()\n",
        "    subdata=pd.merge(subdata,t8,on=['building_id','manager_id'],how='left')\n",
        "    \n",
        "    for i,statu in enumerate(status):\n",
        "        temp=t7.groupby(['building_id','manager_id']).agg(statu).reset_index()\n",
        "        temp.rename(columns={'price':'bm_price_{}'.format(statu),'latitude':'bm_lat_{}'.format(statu),'longitude':'bm_lon_{}'.format(statu),\n",
        "                             'Month':'bm_month_{}'.format(statu),'Wday':'bm_Wday_{}'.format(statu),\n",
        "                       'Diff_days':'bm_daydiff_{}'.format(statu),'room_size':'bm_room_{}'.format(statu)},inplace=True)\n",
        "        subdata=pd.merge(subdata,temp,on=['building_id','manager_id'],how='left')\n",
        "\n",
        "    subdata['build_type']=subdata['building_id'].apply(lambda x : 0 if x==0 else 1)\n",
        "    subdata.drop(['building_id','manager_id','Month','Wday','Diff_days'],axis=1,inplace=True)\n",
        "    return subdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1d8ce8e1-6edb-ca43-f46d-4aa29424f539"
      },
      "outputs": [],
      "source": [
        "def Day_situation(x):\n",
        "    if x<=10:\n",
        "        return 1\n",
        "    elif x>20:\n",
        "        return 3\n",
        "    else:\n",
        "        return 2\n",
        "        \n",
        "def process_created(data):\n",
        "    subdata=pd.DataFrame(data['created'])\n",
        "    subdata['date']=pd.to_datetime(data['created'])\n",
        "    subdata['Month']=subdata.date.dt.month\n",
        "    subdata['Season']=1\n",
        "    subdata.loc[subdata['Month'].isin([4,5,6]),'Season']=2\n",
        "    subdata.loc[subdata['Month'].isin([7,8,9]),'Season']=3\n",
        "    subdata.loc[subdata['Month'].isin([10,11,12]),'Season']=4\n",
        "    subdata['Day']=subdata.date.dt.day\n",
        "    subdata['day_situation']=subdata.Day.apply(Day_situation)\n",
        "    subdata['Wday']=subdata.date.dt.dayofweek\n",
        "    subdata['isWeekday']=subdata.Wday.apply(lambda x: 1 if x in [0,6] else 0)\n",
        "    subdata['Yday']=subdata.date.dt.dayofyear\n",
        "    subdata['Hour']=subdata.date.dt.hour\n",
        "    subdata['isNight']=subdata.Hour.apply(lambda x:1 if x>12 else 0)\n",
        "    subdata['Diff_days']=subdata['created'].apply(lambda x:(datetime.date(2017,3,1)-\n",
        "    datetime.date(int(x.split(' ')[0].split('-')[0]),int(x.split(' ')[0].split('-')[1]),int(x.split(' ')[0].split('-')[2]))).days)\n",
        "\n",
        "    subdata.drop(['created','date'],axis=1,inplace=True)\n",
        "    subdata=subdata.reset_index(drop=True)\n",
        "    return subdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0b21ada2-0282-db40-527d-def126cfb28b"
      },
      "outputs": [],
      "source": [
        "def process_managerid(data,data1):\n",
        "    fea=['manager_id','price','bathrooms','bedrooms','latitude','longitude']\n",
        "    subdata=data[fea].reset_index(drop=True)\n",
        "    subdata=pd.concat((subdata,data1[['Month','Wday','Diff_days']]),axis=1)\n",
        "    t=subdata[['manager_id','price']]\n",
        "    t['manager_count']=1\n",
        "    t=t.groupby(['manager_id']).agg('count').reset_index()\n",
        "    t.drop('price',axis=1,inplace=True)\n",
        "\n",
        "    t1=subdata[['manager_id','price','bathrooms','bedrooms','latitude','longitude','Month','Wday','Diff_days']]\n",
        "    t1['room_size']=t1['bathrooms']+t1['bedrooms']\n",
        "    t1.drop(['bathrooms','bedrooms'],axis=1,inplace=True)\n",
        "    subdata=pd.merge(subdata,t,on='manager_id',how='left')\n",
        "    \n",
        "    status=['sum','mean','min','max','median']\n",
        "    for statu in status:\n",
        "        temp=t1.groupby('manager_id').agg(statu).reset_index()\n",
        "        temp.rename(columns={'price':'manager_price_{}'.format(statu),'latitude':'manager_lat_{}'.format(statu),'longitude':'manager_lon_{}'.format(statu),\n",
        "                   'Month':'manager_month_{}'.format(statu),'Wday':'manager_Wday_{}'.format(statu),\n",
        "                   'Diff_days':'manager_daydiff_{}'.format(statu),'room_size':'manager_room_{}'.format(statu)},inplace=True)\n",
        "        subdata=pd.merge(subdata,temp,on='manager_id',how='left')\n",
        "    subdata.drop(['manager_id','price','bathrooms','bedrooms','latitude','longitude','Month','Wday','Diff_days'],axis=1,inplace=True)\n",
        "    return subdata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "716b3763-79f3-8d66-718b-a4524fba055b"
      },
      "outputs": [],
      "source": [
        "def get_word_feature(data):\n",
        "    fea=['description','display_address','features','photos','street_address']\n",
        "    subdata=data[fea].reset_index(drop=True)\n",
        "    feature_transform = CountVectorizer(stop_words='english', max_features=150)\n",
        "    #####features########\n",
        "    subdata['features'] = subdata[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\n",
        "#    data1['features'] = data1[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\n",
        "    feature_transform.fit(list(subdata['features']))\n",
        "    vocabulary=feature_transform.vocabulary_\n",
        "    feat_sparse = feature_transform.transform(subdata[\"features\"])\n",
        "    fea_counter = pd.DataFrame([pd.Series(feat_sparse[i].toarray().ravel()) for i in np.arange(feat_sparse.shape[0])])\n",
        "    fea_counter.columns = list(sorted(vocabulary.keys()))\n",
        "    subdata['features_count']=subdata['features'].apply(lambda x:len(x))\n",
        "    #####description######\n",
        "    subdata['description'] = subdata['description'].apply(lambda x: x.replace('<p><a  website_redacted ', ''))\n",
        "    subdata['description'] = subdata['description'].apply(lambda x: x.replace('!<br /><br />', ''))\n",
        "\n",
        "    string.punctuation.__add__('!!')\n",
        "    string.punctuation.__add__('(')\n",
        "    string.punctuation.__add__(')')\n",
        "    remove_punct_map = dict.fromkeys(map(ord, string.punctuation))\n",
        "\n",
        "    subdata['description'] = subdata['description'].apply(lambda x: x.translate(remove_punct_map))\n",
        "    subdata['desc_letter_count']=subdata['description'].apply(lambda x:len(x.strip()))\n",
        "    subdata['desc_words_count'] = subdata['description'].apply(lambda x: 0 if len(x.strip()) == 0 else len(x.split(' ')))\n",
        "    ######adddress########\n",
        "    subdata['address1'] = subdata['display_address']\n",
        "    subdata['address1'] = subdata['address1'].apply(lambda x: x.lower())\n",
        "\n",
        "    address_map = {\n",
        "        'w': 'west','st.': 'street','ave': 'avenue',\n",
        "        'st': 'street','e': 'east','n': 'north','s': 'south'}\n",
        "\n",
        "    def address_map_func(s):\n",
        "        s = s.split(' ')\n",
        "        out = []\n",
        "        for x in s:\n",
        "            if x in address_map:\n",
        "                out.append(address_map[x])\n",
        "            else:\n",
        "                out.append(x)\n",
        "        return ' '.join(out)\n",
        "\n",
        "    subdata['address1'] = subdata['address1'].apply(lambda x: x.translate(remove_punct_map))\n",
        "    subdata['address1'] = subdata['address1'].apply(lambda x: address_map_func(x))\n",
        "    new_cols = ['street', 'avenue', 'east', 'west', 'north', 'south']\n",
        "\n",
        "    for col in new_cols:\n",
        "        subdata[col] = subdata['address1'].apply(lambda x: 1 if col in x else 0)\n",
        "    subdata['other_address'] = subdata[new_cols].apply(lambda x: 1 if x.sum() == 0 else 0, axis=1)\n",
        "    ###########photos#################\n",
        "    subdata['photos_count'] = subdata['photos'].apply(lambda x: len(str(x).split(',')))\n",
        "    subdata.drop(['description','display_address','features','photos','street_address','address1'],axis=1,inplace=True)\n",
        "\n",
        "    subdata=pd.concat([subdata,fea_counter],axis=1)\n",
        "    return subdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02d07ebb-9a09-46f6-f6ac-43b20c43aeeb"
      },
      "outputs": [],
      "source": [
        "train,test,y,listing_id=load_data()\n",
        "train.drop('interest_level',axis=1,inplace=True)\n",
        "n=train.shape[0]\n",
        "data=pd.concat([train,test])\n",
        "\n",
        "data1=add_room_price(data)\n",
        "data2=process_created(data) \n",
        "data3=process_buildingid(data,data2)\n",
        "data4=process_managerid(data,data2) \n",
        "data5=get_word_feature(data)\n",
        "data_concat=pd.concat([data1,data2,data3,data4,data5],axis=1)\n",
        "\n",
        "X_train=data_concat.iloc[:n,:]\n",
        "X_test=data_concat.iloc[n:,:]\n",
        "\n",
        "X_training,X_val,y_training,y_val=train_test_split(X_train,y,test_size=0.3,random_state=0)\n",
        "dtrain=xgb.DMatrix(data=X_training,label=y_training)\n",
        "dval=xgb.DMatrix(data=X_val,label=y_val)\n",
        "dtest=xgb.DMatrix(data=X_test)\n",
        "\n",
        "params = {\n",
        "    'eta':.02,\n",
        "    'max_depth':4,\n",
        "    'min_child_weight':3,\n",
        "    \"n_estimators\":600,\n",
        "    'early_stopping_rounds':30,\n",
        "    'colsample_bytree':.7,\n",
        "    'subsample':.7,\n",
        "    'gamma':0.1,\n",
        "    'seed':0,\n",
        "    'nthread':-1,\n",
        "    'objective':'multi:softprob',\n",
        "    'eval_metric':'mlogloss',\n",
        "    'num_class':3,\n",
        "    'silent':1\n",
        "    }\n",
        "\n",
        "watchlist=[(dtrain,'train'),(dval,'val')]\n",
        "#xgb_cv=xgb.cv(params,dtrain, num_boost_round=5600, nfold=4,seed=0)\n",
        "#print \"Min_logloss{}\".format(min(xgb_cv['test-mlogloss-mean']))\n",
        "#print \"Best_Rounds{}\".format(np.argmin(xgb_cv['test-mlogloss-mean']))\n",
        "#best_rounds = np.argmin(xgb_cv['test-mlogloss-mean'])\n",
        "bst=xgb.train(params,dtrain,3500,evals=watchlist) #cv 0.5281\n",
        "pre_test=bst.predict(dtest)\n",
        "\n",
        "def prepare_submission(preds):\n",
        "    now = datetime.datetime.now()   \n",
        "    submission = pd.DataFrame(data = {'listing_id': listing_id})\n",
        "    submission['low'] = preds[:, 0]\n",
        "    submission['medium'] = preds[:, 1]\n",
        "    submission['high'] = preds[:, 2]\n",
        "    sub_file = './Submission/'+'Submission_' + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
        "    submission.to_csv(sub_file,index = False)\n",
        "prepare_submission(pre_test)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}