{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"This kernel is a fork from Jonne's kernel (https://www.kaggle.com/jonnedtc/cnn-segmentation-connected-components). Jonne creates a submission using a convolutional neural network. However, Jonne does not use any DICOM data for the prediction. I am creating this kernel to improve on Jonne's predictions by using the DICOM data. The model I am using is LightGBM, since it is fast, often accurate, and reliable."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"This kernel is also a fork from jtlowery's kernel (https://www.kaggle.com/jtlowery/intro-eda-with-dicom-metadata). Jtlowery's kernel has functions I can copy to read in the DICOM data.[](http://)"},{"metadata":{"trusted":true,"_uuid":"21e7abc8829ed96d63ba46f3b1813019371a9185"},"cell_type":"code","source":"from functools import partial\nfrom collections import defaultdict\nimport pydicom\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\nnp.warnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4ba2208dce9ad05faac5eb87135a342dc7ed3b5"},"cell_type":"code","source":"labels = pd.read_csv('../input/rsna-pneumonia-detection-challenge/stage_1_train_labels.csv')\ndetails = pd.read_csv('../input/rsna-pneumonia-detection-challenge/stage_1_detailed_class_info.csv')\n# duplicates in details just have the same class so can be safely dropped\ndetails = details.drop_duplicates('patientId').reset_index(drop=True)\nlabels_w_class = labels.merge(details, how='inner', on='patientId')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb7fa287367ede92a82ac85e4a7ec80fe9989290"},"cell_type":"code","source":"# get lists of all train/test dicom filepaths\ntrain_dcm_fps = glob.glob('../input/rsna-pneumonia-detection-challenge/stage_1_train_images/*.dcm')\ntest_dcm_fps = glob.glob('../input/rsna-pneumonia-detection-challenge/stage_1_test_images/*.dcm')\n\ntrain_dcms = [pydicom.read_file(x, stop_before_pixels=True) for x in train_dcm_fps]\ntest_dcms = [pydicom.read_file(x, stop_before_pixels=True) for x in test_dcm_fps]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d80a30b21c870f73e06e9c3516e742210d636eb"},"cell_type":"code","source":"def parse_dcm_metadata(dcm):\n    unpacked_data = {}\n    group_elem_to_keywords = {}\n    # iterating here to force conversion from lazy RawDataElement to DataElement\n    for d in dcm:\n        pass\n    # keys are pydicom.tag.BaseTag, values are pydicom.dataelem.DataElement\n    for tag, elem in dcm.items():\n        tag_group = tag.group\n        tag_elem = tag.elem\n        keyword = elem.keyword\n        group_elem_to_keywords[(tag_group, tag_elem)] = keyword\n        value = elem.value\n        unpacked_data[keyword] = value\n    return unpacked_data, group_elem_to_keywords\n\ntrain_meta_dicts, tag_to_keyword_train = zip(*[parse_dcm_metadata(x) for x in train_dcms])\ntest_meta_dicts, tag_to_keyword_test = zip(*[parse_dcm_metadata(x) for x in test_dcms])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a27e35027993fcb50790b46e01ff5b719805ca41"},"cell_type":"code","source":"# join all the dicts\nunified_tag_to_key_train = {k:v for dict_ in tag_to_keyword_train for k,v in dict_.items()}\nunified_tag_to_key_test = {k:v for dict_ in tag_to_keyword_test for k,v in dict_.items()}\n\n# quick check to make sure there are no different keys between test/train\nassert len(set(unified_tag_to_key_test.keys()).symmetric_difference(set(unified_tag_to_key_train.keys()))) == 0\n\ntag_to_key = {**unified_tag_to_key_test, **unified_tag_to_key_train}\ntag_to_key","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bd49ed8df9396908ed0d8c9e9af86069b62c56e"},"cell_type":"code","source":"# using from_records here since some values in the dicts will be iterables and some are constants\ntrain_df = pd.DataFrame.from_records(data=train_meta_dicts)\ntest_df = pd.DataFrame.from_records(data=test_meta_dicts)\ntrain_df['dataset'] = 'train'\ntest_df['dataset'] = 'test'\ndf = pd.concat([train_df, test_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0a571df8d8be4779dc7013fa6bef6757d2ca8ed"},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cac5e5330864378443105bac125ec00525f9095"},"cell_type":"code","source":"# separating PixelSpacing list to single values\ndf['PixelSpacing_x'] = df['PixelSpacing'].apply(lambda x: x[0])\ndf['PixelSpacing_y'] = df['PixelSpacing'].apply(lambda x: x[1])\ndf = df.drop(['PixelSpacing'], axis='columns')\n\n# x and y are always the same\nassert sum(df['PixelSpacing_x'] != df['PixelSpacing_y']) == 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"122f7f17f51e9792c21e4c9b41e69d56a8f983b9"},"cell_type":"code","source":"# ReferringPhysicianName appears to just be empty strings\nassert sum(df['ReferringPhysicianName'] != '') == 0\n\n# SeriesDescription appears to be 'view: {}'.format(ViewPosition)\nset(df['SeriesDescription'].unique())\n\n# so these two columns don't have any useful info and can be safely dropped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0b5ddcf2a95f4dca61071feea897290f55acd27"},"cell_type":"code","source":"nunique_all = df.aggregate('nunique')\nnunique_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"851e6dbbe0f1307b7d488a85bb0afbe8d2a0ad6f"},"cell_type":"code","source":"# drop constant cols and other two from above\n#ReferringPhysicianName is all ''\n#PatientName is the same as PatientID\n#PixelSpacing_y is the same as PixelSpacing_x\n#The series and SOP UID's are just random numbers / id's, so I'm deleting them too\ndf = df.drop(nunique_all[nunique_all == 1].index.tolist() + ['SeriesDescription', 'ReferringPhysicianName', 'PatientName', 'PixelSpacing_y', 'SOPInstanceUID','SeriesInstanceUID','StudyInstanceUID'], axis='columns')\n\n# now that we have a clean metadata dataframe we can merge back to our initial tabular data with target and class info\ndf = df.merge(labels_w_class, how='left', left_on='PatientID', right_on='patientId')\n\ndf['PatientAge'] = df['PatientAge'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6add74499872d566d7a43350bb44313afaf31e10"},"cell_type":"code","source":"# df now has multiple rows for some patients (those with multiple bounding boxes in label_w_class)\n# so creating one with no duplicates for patients\ndf_deduped = df.drop_duplicates('PatientID', keep='first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863c112caa0c8c3dcc3ed7490da4a1c2eae16bc6"},"cell_type":"code","source":"df_deduped.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a5329528c7f3566bd194dc774585f4f37c0641f"},"cell_type":"code","source":"#Correct ages that are mistyped\ndf_deduped.loc[df_deduped['PatientAge'] > 140, 'PatientAge'] = df_deduped.loc[df_deduped['PatientAge'] > 140, 'PatientAge'] - 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf93824822563b455df8bd7a1c07d738765083dd"},"cell_type":"code","source":"#Convert binary features from categorical to 0/1\n# Categorical features with Binary encode (0 or 1; two categories)\nfor bin_feature in ['PatientSex', 'ViewPosition']:\n    df_deduped[bin_feature], uniques = pd.factorize(df_deduped[bin_feature])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1542b266153f540cb41fd3b41dfef56493837582"},"cell_type":"code","source":"#Drop the duplicated column patientID\ndel df_deduped['patientId']\n\n#Drop columns that are going to be repetitive\ndel df_deduped['dataset']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61731bdcbb364a16517c4ea526288f5db6f4948e"},"cell_type":"code","source":"df_deduped.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57771f449da5376e278d2f1d5fb2a87c9429d35a"},"cell_type":"markdown","source":"Now that we have a data frame that links PatientID to DICOM data, let's merge this with train and the submission file."},{"metadata":{"trusted":true,"_uuid":"b01cdbc166079c41d8c9f46569b90d1a5eb267bb"},"cell_type":"code","source":"jonneoofs = pd.read_csv(\"../input/jonneoofs/jonne_oofs.csv\")\njonneoofs = jonneoofs.sort_values('patientID').reset_index(drop=True)\nandyharless_sub = pd.read_csv(\"../input/andyharless/submission (7).csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e6b8032ab8e7c83e3f265b5bca218a19948b5e7"},"cell_type":"code","source":"labels.head() #The real train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56debf2037e46dbf564aea9279e6edd142c0a095"},"cell_type":"code","source":"jonneoofs.head() #The oofs from Jonne's kernel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"551cbf6e07851f929353171afe1654427f0ab563"},"cell_type":"code","source":"andyharless_sub.head() # The submission from Andy Harless, which is a fork from Jonne","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f456d4892c19c0e56b9723111aaa9dbc17e6709"},"cell_type":"code","source":"jonneoofs['i_am_train'] = 1\nandyharless_sub['i_am_train'] = 0\ntr_te = jonneoofs.append(andyharless_sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"836ea815df6a29031255c767ecca8debc32d8431"},"cell_type":"code","source":"del tr_te['confidence'] #Not used in grading","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6afd50f78f7cd76b7b265ddd6e8891d49ba734b5"},"cell_type":"code","source":"tr_te.columns = ['PatientID','x_guess','y_guess','width_guess','height_guess','i_am_train']\ntr_te.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5b982e665cbc305175fe0a1a6f868a81e30dd86"},"cell_type":"code","source":"df_deduped.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8309095dde427e2d876520651b49765da98c7057"},"cell_type":"code","source":"merged_df = tr_te.merge(df_deduped, how='left', on='PatientID')\nmerged_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"846ea6f5479ec3322fdd5a0ed73bc5917c06e98e"},"cell_type":"code","source":"filledmerged_df = merged_df.fillna(-1) #Fill in missings","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2548f4be8e49d2bc137a252e8cf3c08ee7feb107"},"cell_type":"markdown","source":"# Predict for x"},{"metadata":{"trusted":true,"_uuid":"3ca6f7aef369604a91d1d8c1f2550c912e435a71"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ntrain_df = filledmerged_df[filledmerged_df['i_am_train']==1]\ntest_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n             \n#Cross validate with K Fold, 5 splits\nfolds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\n             \nfeats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n                         label=train_df['x'].iloc[train_idx], \n                         free_raw_data=False, silent=True)\n    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n                         label=train_df['x'].iloc[valid_idx], \n                         free_raw_data=False, silent=True)\n\n    params = {\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'nthread': 4,\n        'learning_rate': 0.10, \n        'max_depth': 2,\n        #'reg_alpha': 0,\n        #'reg_lambda': 0,\n        #'min_split_gain': 0.0222415,\n        'seed': 15000,\n        'verbose': 50,\n        'metric': 'l2',\n    }\n\n    clf = lgb.train(\n        params=params,\n        train_set=dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        early_stopping_rounds=50,\n        verbose_eval=True\n    )\n\n    oof_preds[valid_idx] = clf.predict(dvalid.data)\n    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ab85d7941f91e0d0039425d4055a611a86049a6"},"cell_type":"code","source":"xpreds_oof = oof_preds.copy()\nxpreds_sub = sub_preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9412fd7fe5d60e0895bee79e47758a4e93e7c74c"},"cell_type":"markdown","source":"# Predict for y"},{"metadata":{"trusted":true,"_uuid":"1742c3128b050cf21345205dbda5b3a6cc2590ca"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ntrain_df = filledmerged_df[filledmerged_df['i_am_train']==1]\ntest_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n             \n#Cross validate with K Fold, 5 splits\nfolds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\n             \nfeats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n                         label=train_df['y'].iloc[train_idx], \n                         free_raw_data=False, silent=True)\n    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n                         label=train_df['y'].iloc[valid_idx], \n                         free_raw_data=False, silent=True)\n\n    params = {\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'nthread': 4,\n        'learning_rate': 0.10, \n        'max_depth': 2,\n        #'reg_alpha': 0,\n        #'reg_lambda': 0,\n        #'min_split_gain': 0.0222415,\n        'seed': 15000,\n        'verbose': 50,\n        'metric': 'l2',\n    }\n\n    clf = lgb.train(\n        params=params,\n        train_set=dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        early_stopping_rounds=50,\n        verbose_eval=True\n    )\n\n    oof_preds[valid_idx] = clf.predict(dvalid.data)\n    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f9bcd81b195a0950c838590c1684c0a341abe63"},"cell_type":"code","source":"ypreds_oof = oof_preds.copy()\nypreds_sub = sub_preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20dec65f7184ecb700e90ca20c0e208bab0af6f4"},"cell_type":"markdown","source":"# Predict for width"},{"metadata":{"trusted":true,"_uuid":"76798f48a253465cd00df1d9520208efdaf3f482"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ntrain_df = filledmerged_df[filledmerged_df['i_am_train']==1]\ntest_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n             \n#Cross validate with K Fold, 5 splits\nfolds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\n             \nfeats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n                         label=train_df['width'].iloc[train_idx], \n                         free_raw_data=False, silent=True)\n    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n                         label=train_df['width'].iloc[valid_idx], \n                         free_raw_data=False, silent=True)\n\n    params = {\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'nthread': 4,\n        'learning_rate': 0.10, \n        'max_depth': 2,\n        #'reg_alpha': 0,\n        #'reg_lambda': 0,\n        #'min_split_gain': 0.0222415,\n        'seed': 15000,\n        'verbose': 50,\n        'metric': 'l2',\n    }\n\n    clf = lgb.train(\n        params=params,\n        train_set=dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        early_stopping_rounds=50,\n        verbose_eval=True\n    )\n\n    oof_preds[valid_idx] = clf.predict(dvalid.data)\n    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e804c15a83c3aee288c609aefa863ec867cd67"},"cell_type":"code","source":"widthpreds_oof = oof_preds.copy()\nwidthpreds_sub = sub_preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62f1d25f02f8be016f7d9be5875fb9344fc36d65"},"cell_type":"markdown","source":"# Predict for height"},{"metadata":{"trusted":true,"_uuid":"206c949dea0f197d6643f120089a9006d3e9952a"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\ntrain_df = filledmerged_df[filledmerged_df['i_am_train']==1]\ntest_df = filledmerged_df[filledmerged_df['i_am_train']==0]\n             \n#Cross validate with K Fold, 5 splits\nfolds = KFold(n_splits= 5, shuffle=True, random_state=2222)\n\n# Create arrays and dataframes to store results\noof_preds = np.zeros(train_df.shape[0])\nsub_preds = np.zeros(test_df.shape[0])\n             \nfeats = [f for f in train_df.columns if f not in ['PatientID', 'i_am_train', 'x','y','width','height','Target','class']]\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats])):\n    dtrain = lgb.Dataset(data=train_df[feats].iloc[train_idx], \n                         label=train_df['height'].iloc[train_idx], \n                         free_raw_data=False, silent=True)\n    dvalid = lgb.Dataset(data=train_df[feats].iloc[valid_idx], \n                         label=train_df['height'].iloc[valid_idx], \n                         free_raw_data=False, silent=True)\n\n    params = {\n        'objective': 'regression',\n        'boosting_type': 'gbdt',\n        'nthread': 4,\n        'learning_rate': 0.10, \n        'max_depth': 2,\n        #'reg_alpha': 0,\n        #'reg_lambda': 0,\n        #'min_split_gain': 0.0222415,\n        'seed': 15000,\n        'verbose': 50,\n        'metric': 'l2',\n    }\n\n    clf = lgb.train(\n        params=params,\n        train_set=dtrain,\n        num_boost_round=1000,\n        valid_sets=[dtrain, dvalid],\n        early_stopping_rounds=50,\n        verbose_eval=True\n    )\n\n    oof_preds[valid_idx] = clf.predict(dvalid.data)\n    sub_preds += clf.predict(test_df[feats]) / folds.n_splits\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc639e4b9c6f928a4472d7e49ca30f9a3645ae4"},"cell_type":"code","source":"heightpreds_oof = oof_preds.copy()\nheightpreds_sub = sub_preds.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b75e25bb054f34ae1b98b635fe67796bfd4f75cc"},"cell_type":"markdown","source":"# Remove any boxes below a threshold"},{"metadata":{"trusted":true,"_uuid":"cbcf2adb6305fcae77130b30178c08e993c21b13"},"cell_type":"code","source":"# What is the number of rows where we have a box?\ntrain_df.loc[train_df['x'] > -1]['x'].shape[0] / train_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4291061afaf94d42dee0fe93bef8f911d638de01"},"cell_type":"markdown","source":"0.22 rows have a box, so now let's cull our predictions until only there is 0.22"},{"metadata":{"trusted":true,"_uuid":"7e9689a1018015520adde4903d377dcf3d38a9db"},"cell_type":"code","source":"train_df['xpredsoof'] = xpreds_oof\ntrain_df['ypredsoof'] = ypreds_oof\ntrain_df['widthpredsoof'] = widthpreds_oof\ntrain_df['heightpredsoof'] = heightpreds_oof","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bac620c20f01a62748a1dd3089fff2a2996998fb"},"cell_type":"code","source":"train_df.loc[train_df['widthpredsoof'] <= 100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d26f359cff69875629aaaf59263eb9deef2681d9"},"cell_type":"code","source":"#train_df.loc[(train_df['xpredsoof'] > 130) & (train_df['ypredsoof'] > 134)].shape[0] / train_df.shape[0]\ntrain_df.loc[(train_df['widthpredsoof'] > 100)].shape[0] / train_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fef99695ddf9ca4d7e379a10dcd41c580988d30"},"cell_type":"code","source":"andyharless_sub['xpred'] = xpreds_sub\nandyharless_sub['ypred'] = ypreds_sub\nandyharless_sub['widthpred'] = widthpreds_sub\nandyharless_sub['heightpred'] = heightpreds_sub\n\nandyharless_sub['xpred'] = andyharless_sub['xpred'].round()\nandyharless_sub['ypred'] = andyharless_sub['ypred'].round()\nandyharless_sub['widthpred'] = andyharless_sub['widthpred'].round()\nandyharless_sub['heightpred'] = andyharless_sub['heightpred'].round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3080b5acee23e706b1444f616ddb89b592782050"},"cell_type":"code","source":"#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'xpred'] = ''\n#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'ypred'] = ''\n#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'heightpred'] = ''\n#andyharless_sub.loc[andyharless_sub['widthpred'] <= 100, 'widthpred'] = ''\nandyharless_sub['confidence'] = '1'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a350cb09d43078f2e92da6c9c17700ec113f3ca"},"cell_type":"code","source":"andyharless_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a510c61098607a5f4bffbe3abc20aaf82becebe8"},"cell_type":"code","source":"#del andyharless_sub['x']\n#del andyharless_sub['y']\n#del andyharless_sub['width']\n#del andyharless_sub['height']\n#del andyharless_sub['i_am_train']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4515e16976a0694c20b0e516142489d8d73606fd"},"cell_type":"code","source":"andyharless_sub['PredictionString'] = andyharless_sub['confidence'].map(str)+' '+andyharless_sub['xpred'].map(str)+' '+andyharless_sub['ypred'].map(str)+' '+andyharless_sub['widthpred'].map(str)+' '+andyharless_sub['heightpred'].map(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7fd9e03aee46dae2e6d4e3621df275cb77b270c"},"cell_type":"code","source":"andyharless_sub.loc[andyharless_sub['PredictionString']=='1    ', 'PredictionString'] = '' #Correct empties","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8945035e527f1320f3d78c36a35b7fd16211cdf6"},"cell_type":"code","source":"andyharless_sub.loc[andyharless_sub['x'].isnull(), 'PredictionString'] = '' #Remove boxes if we predicted there were none","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83dff05122ce8e44e270dbebb1e5351fc01fb78f"},"cell_type":"code","source":"andyharless_sub[['patientID','PredictionString']].to_csv('dicom_corrections.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd31ba9603c36ed609057baba48a98598f32c8c6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}