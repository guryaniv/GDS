{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6cc15807-d7a2-6f12-1d4c-038dfe242ce7"
      },
      "source": [
        "Ok \n",
        "i am mixing here\n",
        "\n",
        "RAKE\n",
        "+ TFIDF ngram(1-3)\n",
        "and group together to make a tag.\n",
        "These tags we will see the ranking soon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0cb1c24c-0638-91b6-020e-b4dc4cf75b08"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import operator\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "def dict_to_df(d):\n",
        "    df = pd.DataFrame()\n",
        "    df['word'] = d.keys()\n",
        "    df['count'] = d.values()\n",
        "    return df\n",
        "RES_DIR = \"../input/\"\n",
        "def load_train_data():\n",
        "    categories = ['cooking', 'robotics', 'travel', 'crypto', 'diy', 'biology']\n",
        "    train_data = []\n",
        "    for cat in categories:\n",
        "        data = pd.read_csv(\"{}{}.csv\".format(RES_DIR, cat), usecols=['id', 'title','content' ,'tags'])\n",
        "        data['category'] = cat\n",
        "        train_data.append(data)\n",
        "    return pd.concat(train_data)\n",
        "train_data = load_train_data()\n",
        "#import the test data\n",
        "\n",
        "#print(train_data.head())\n",
        "\n",
        "#import test data in same format\n",
        "testdoc = pd.read_csv(\"../input/test.csv\")\n",
        "testdoc['tags'] = ''\n",
        "testdoc['category'] = 'physics'\n",
        "print(testdoc.head())\n",
        "#train_data_tot=train_data.append(testdoc)\n",
        "# Implementation of RAKE - Rapid Automtic Keyword Exraction algorithm\n",
        "\n",
        "\n",
        "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\n",
        "\n",
        "def stripTagsAndUris(x):\n",
        "    if x:\n",
        "        # BeautifulSoup on content\n",
        "        soup = BeautifulSoup(x, \"html.parser\")\n",
        "        # Stripping all <code> tags with their content if any\n",
        "        if soup.code:\n",
        "            soup.code.decompose()\n",
        "        # Get all the text out of the html\n",
        "        text =  soup.get_text()\n",
        "        # Returning text stripping out all uris\n",
        "        return re.sub(uri_re, \"\", text)\n",
        "    else:\n",
        "        return \"\"\n",
        "    \n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s) if '.' in s else int(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def load_stop_words(stop_word_file):\n",
        "    \"\"\"\n",
        "    Utility function to load stop words from a file and return as a list of words\n",
        "    @param stop_word_file Path and file name of a file containing stop words.\n",
        "    @return list A list of stop words.\n",
        "    \"\"\"\n",
        "    stop_words = []\n",
        "    for line in open(stop_word_file):\n",
        "        if line.strip()[0:1] != \"#\":\n",
        "            for word in line.split():  # in case more than one per line\n",
        "                stop_words.append(word)\n",
        "    return stop_words\n",
        "\n",
        "\n",
        "def separate_words(text, min_word_return_size):\n",
        "    \"\"\"\n",
        "    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n",
        "    @param text The text that must be split in to words.\n",
        "    @param min_word_return_size The minimum no of characters a word must have to be included.\n",
        "    \"\"\"\n",
        "    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
        "    words = []\n",
        "    for single_word in splitter.split(text):\n",
        "        current_word = single_word.strip().lower()\n",
        "        #leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n",
        "        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n",
        "            words.append(current_word)\n",
        "    return words\n",
        "\n",
        "\n",
        "def split_sentences(text):\n",
        "    \"\"\"\n",
        "    Utility function to return a list of sentences.\n",
        "    @param text The text that must be split in to sentences.\n",
        "    \"\"\"\n",
        "    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n",
        "    sentences = sentence_delimiters.split(text)\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def build_stop_word_regex(stop_word_file_path):\n",
        "    stop_word_list = load_stop_words(stop_word_file_path)\n",
        "    stop_word_regex_list = []\n",
        "    for word in stop_word_list:\n",
        "        word_regex = r'\\b' + word + r'(?![\\w-])'  # added look ahead for hyphen\n",
        "        stop_word_regex_list.append(word_regex)\n",
        "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
        "    return stop_word_pattern\n",
        "\n",
        "def build_stop_word_(stop_word_file_path):\n",
        "    stop_word_list = stop_word_file_path\n",
        "    stop_word_regex_list = []\n",
        "    for word in stop_word_list:\n",
        "        word_regex = r'\\b' + word + r'(?![\\w-])'  # added look ahead for hyphen\n",
        "        stop_word_regex_list.append(word_regex)\n",
        "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
        "    return stop_word_pattern\n",
        "\n",
        "def generate_candidate_keywords(sentence_list, stopword_pattern):\n",
        "    phrase_list = []\n",
        "    for s in sentence_list:\n",
        "        tmp = re.sub(stopword_pattern, '|', s.strip())\n",
        "        phrases = tmp.split(\"|\")\n",
        "        for phrase in phrases:\n",
        "            phrase = phrase.strip().lower()\n",
        "            if phrase != \"\":\n",
        "                phrase_list.append(phrase)\n",
        "    return phrase_list\n",
        "\n",
        "\n",
        "def calculate_word_scores(phraseList):\n",
        "    word_frequency = {}\n",
        "    word_degree = {}\n",
        "    for phrase in phraseList:\n",
        "        word_list = separate_words(phrase, 0)\n",
        "        word_list_length = len(word_list)\n",
        "        word_list_degree = word_list_length - 1\n",
        "        if word_list_degree > 3: word_list_degree = 3 #exp.\n",
        "        for word in word_list:\n",
        "            word_frequency.setdefault(word, 0)\n",
        "            word_frequency[word] += 1\n",
        "            word_degree.setdefault(word, 0)\n",
        "            #word_degree[word] += word_list_degree  #orig.\n",
        "            word_degree[word] += 1/(word_list_length*1.0) #exp.\n",
        "    for item in word_frequency:\n",
        "        word_degree[item] = word_degree[item] + word_frequency[item]\n",
        "\n",
        "    # Calculate Word scores = deg(w)/frew(w)\n",
        "    word_score = {}\n",
        "    for item in word_frequency:\n",
        "        word_score.setdefault(item, 0)\n",
        "        # word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)  #orig.\n",
        "        word_score[item] = word_frequency[item]/(word_degree[item] * 1.0) #exp.\n",
        "    return word_score\n",
        "\n",
        "\n",
        "def generate_candidate_keyword_scores(phrase_list, word_score):\n",
        "    keyword_candidates = {}\n",
        "    for phrase in phrase_list:\n",
        "        keyword_candidates.setdefault(phrase, 2)\n",
        "        word_list = separate_words(phrase, 2)\n",
        "        candidate_score = 0\n",
        "        for word in word_list:\n",
        "            candidate_score += word_score[word]\n",
        "        keyword_candidates[phrase] = candidate_score\n",
        "    return keyword_candidates\n",
        "\n",
        "\n",
        "class Rake(object):\n",
        "    def __init__(self, stop_words_path):\n",
        "        self.stop_words_path = stop_words_path\n",
        "        self.__stop_words_pattern = build_stop_word_regex(stop_words_path)\n",
        "\n",
        "    def run(self, text):\n",
        "        sentence_list = split_sentences(text)\n",
        "        phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern)\n",
        "        word_scores = calculate_word_scores(phrase_list)\n",
        "        keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores)\n",
        "        sorted_keywords = sorted(keyword_candidates.items(), key=operator.itemgetter(1), reverse=True)\n",
        "        return sorted_keywords\n",
        "\n",
        "debug=True\n",
        "for index, row in testdoc.sample(2).iterrows():\n",
        "    #print(row[\"title\"], row[\"content\"]    )\n",
        "    sentenceList = split_sentences(row['title']+' '+row['content'])\n",
        "    #stoppath = \"FoxStoplist.txt\" #Fox stoplist contains \"numbers\", so it will not find \"natural numbers\" like in Table 1.1\n",
        "    stoppath = \"SmartStoplist.txt\"  #SMART stoplist misses some of the lower-scoring keywords in Figure 1.5, which means that the top 1/3 cuts off one of the 4.0 score words in Table 1.1\n",
        "    #stopwordpattern = build_stop_word_regex(stoppath)\n",
        "    stopwordpattern= \"\"\"re.compile(r\"\\ba(?![\\w-])|\\ba's(?![\\w-])|\\bable(?![\\w-])|\\babout(?![\\w-])|\\babove(?![\\w-])|\\baccording(?![\\w-])|\\baccordingly(?![\\w-])|\\bacross(?![\\w-])|\\bactually(?![\\w-])|\\bafter(?![\\w-])|\\bafterwards(?![\\w-])|\\bagain(?![\\w-])|\\bagainst(?![\\w-])|\\bain't(?![\\w-])|\\ball(?![\\w-])|\\ballow(?![\\w-])|\\ballows(?![\\w-])|\\balmost(?![\\w-])|\\balone(?![\\w-])|\\balong(?![\\w-])|\\balready(?![\\w-])|\\balso(?![\\w-])|\\balthough(?![\\w-])|\\balways(?![\\w-])|\\bam(?![\\w-])|\\bamong(?![\\w-])|\\bamongst(?![\\w-])|\\ban(?![\\w-])|\\band(?![\\w-])|\\banother(?![\\w-])|\\bany(?![\\w-])|\\banybody(?![\\w-])|\\banyhow(?![\\w-])|\\banyone(?![\\w-])|\\banything(?![\\w-])|\\banyway(?![\\w-])|\\banyways(?![\\w-])|\\banywhere(?![\\w-])|\\bapart(?![\\w-])|\\bappear(?![\\w-])|\\bappreciate(?![\\w-])|\\bappropriate(?![\\w-])|\\bare(?![\\w-])|\\baren't(?![\\w-])|\\baround(?![\\w-])|\\bas(?![\\w-])|\\baside(?![\\w-])|\\bask(?![\\w-])|\\basking(?![\\w-])|\\bassociated(?![\\w-])|\\bat(?![\\w-])|\\bavailable(?![\\w-])|\\baway(?![\\w-])|\\bawfully(?![\\w-])|\\bb(?![\\w-])|\\bbe(?![\\w-])|\\bbecame(?![\\w-])|\\bbecause(?![\\w-])|\\bbecome(?![\\w-])|\\bbecomes(?![\\w-])|\\bbecoming(?![\\w-])|\\bbeen(?![\\w-])|\\bbefore(?![\\w-])|\\bbeforehand(?![\\w-])|\\bbehind(?![\\w-])|\\bbeing(?![\\w-])|\\bbelieve(?![\\w-])|\\bbelow(?![\\w-])|\\bbeside(?![\\w-])|\\bbesides(?![\\w-])|\\bbest(?![\\w-])|\\bbetter(?![\\w-])|\\bbetween(?![\\w-])|\\bbeyond(?![\\w-])|\\bboth(?![\\w-])|\\bbrief(?![\\w-])|\\bbut(?![\\w-])|\\bby(?![\\w-])|\\bc(?![\\w-])|\\bc'mon(?![\\w-])|\\bc's(?![\\w-])|\\bcame(?![\\w-])|\\bcan(?![\\w-])|\\bcan't(?![\\w-])|\\bcannot(?![\\w-])|\\bcant(?![\\w-])|\\bcause(?![\\w-])|\\bcauses(?![\\w-])|\\bcertain(?![\\w-])|\\bcertainly(?![\\w-])|\\bchanges(?![\\w-])|\\bclearly(?![\\w-])|\\bco(?![\\w-])|\\bcom(?![\\w-])|\\bcome(?![\\w-])|\\bcomes(?![\\w-])|\\bconcerning(?![\\w-])|\\bconsequently(?![\\w-])|\\bconsider(?![\\w-])|\\bconsidering(?![\\w-])|\\bcontain(?![\\w-])|\\bcontaining(?![\\w-])|\\bcontains(?![\\w-])|\\bcorresponding(?![\\w-])|\\bcould(?![\\w-])|\\bcouldn't(?![\\w-])|\\bcourse(?![\\w-])|\\bcurrently(?![\\w-])|\\bd(?![\\w-])|\\bdefinitely(?![\\w-])|\\bdescribed(?![\\w-])|\\bdespite(?![\\w-])|\\bdid(?![\\w-])|\\bdidn't(?![\\w-])|\\bdifferent(?![\\w-])|\\bdo(?![\\w-])|\\bdoes(?![\\w-])|\\bdoesn't(?![\\w-])|\\bdoing(?![\\w-])|\\bdon't(?![\\w-])|\\bdone(?![\\w-])|\\bdown(?![\\w-])|\\bdownwards(?![\\w-])|\\bduring(?![\\w-])|\\be(?![\\w-])|\\beach(?![\\w-])|\\bedu(?![\\w-])|\\beg(?![\\w-])|\\beight(?![\\w-])|\\beither(?![\\w-])|\\belse(?![\\w-])|\\belsewhere(?![\\w-])|\\benough(?![\\w-])|\\bentirely(?![\\w-])|\\bespecially(?![\\w-])|\\bet(?![\\w-])|\\betc(?![\\w-])|\\beven(?![\\w-])|\\bever(?![\\w-])|\\bevery(?![\\w-])|\\beverybody(?![\\w-])|\\beveryone(?![\\w-])|\\beverything(?![\\w-])|\\beverywhere(?![\\w-])|\\bex(?![\\w-])|\\bexactly(?![\\w-])|\\bexample(?![\\w-])|\\bexcept(?![\\w-])|\\bf(?![\\w-])|\\bfar(?![\\w-])|\\bfew(?![\\w-])|\\bfifth(?![\\w-])|\\bfirst(?![\\w-])|\\bfive(?![\\w-])|\\bfollowed(?![\\w-])|\\bfollowing(?![\\w-])|\\bfollows(?![\\w-])|\\bfor(?![\\w-])|\\bformer(?![\\w-])|\\bformerly(?![\\w-])|\\bforth(?![\\w-])|\\bfour(?![\\w-])|\\bfrom(?![\\w-])|\\bfurther(?![\\w-])|\\bfurthermore(?![\\w-])|\\bg(?![\\w-])|\\bget(?![\\w-])|\\bgets(?![\\w-])|\\bgetting(?![\\w-])|\\bgiven(?![\\w-])|\\bgives(?![\\w-])|\\bgo(?![\\w-])|\\bgoes(?![\\w-])|\\bgoing(?![\\w-])|\\bgone(?![\\w-])|\\bgot(?![\\w-])|\\bgotten(?![\\w-])|\\bgreetings(?![\\w-])|\\bh(?![\\w-])|\\bhad(?![\\w-])|\\bhadn't(?![\\w-])|\\bhappens(?![\\w-])|\\bhardly(?![\\w-])|\\bhas(?![\\w-])|\\bhasn't(?![\\w-])|\\bhave(?![\\w-])|\\bhaven't(?![\\w-])|\\bhaving(?![\\w-])|\\bhe(?![\\w-])|\\bhe's(?![\\w-])|\\bhello(?![\\w-])|\\bhelp(?![\\w-])|\\bhence(?![\\w-])|\\bher(?![\\w-])|\\bhere(?![\\w-])|\\bhere's(?![\\w-])|\\bhereafter(?![\\w-])|\\bhereby(?![\\w-])|\\bherein(?![\\w-])|\\bhereupon(?![\\w-])|\\bhers(?![\\w-])|\\bherself(?![\\w-])|\\bhi(?![\\w-])|\\bhim(?![\\w-])|\\bhimself(?![\\w-])|\\bhis(?![\\w-])|\\bhither(?![\\w-])|\\bhopefully(?![\\w-])|\\bhow(?![\\w-])|\\bhowbeit(?![\\w-])|\\bhowever(?![\\w-])|\\bi(?![\\w-])|\\bi'd(?![\\w-])|\\bi'll(?![\\w-])|\\bi'm(?![\\w-])|\\bi've(?![\\w-])|\\bie(?![\\w-])|\\bif(?![\\w-])|\\bignored(?![\\w-])|\\bimmediate(?![\\w-])|\\bin(?![\\w-])|\\binasmuch(?![\\w-])|\\binc(?![\\w-])|\\bindeed(?![\\w-])|\\bindicate(?![\\w-])|\\bindicated(?![\\w-])|\\bindicates(?![\\w-])|\\binner(?![\\w-])|\\binsofar(?![\\w-])|\\binstead(?![\\w-])|\\binto(?![\\w-])|\\binward(?![\\w-])|\\bis(?![\\w-])|\\bisn't(?![\\w-])|\\bit(?![\\w-])|\\bit'd(?![\\w-])|\\bit'll(?![\\w-])|\\bit's(?![\\w-])|\\bits(?![\\w-])|\\bitself(?![\\w-])|\\bj(?![\\w-])|\\bjust(?![\\w-])|\\bk(?![\\w-])|\\bkeep(?![\\w-])|\\bkeeps(?![\\w-])|\\bkept(?![\\w-])|\\bknow(?![\\w-])|\\bknows(?![\\w-])|\\bknown(?![\\w-])|\\bl(?![\\w-])|\\blast(?![\\w-])|\\blately(?![\\w-])|\\blater(?![\\w-])|\\blatter(?![\\w-])|\\blatterly(?![\\w-])|\\bleast(?![\\w-])|\\bless(?![\\w-])|\\blest(?![\\w-])|\\blet(?![\\w-])|\\blet's(?![\\w-])|\\blike(?![\\w-])|\\bliked(?![\\w-])|\\blikely(?![\\w-])|\\blittle(?![\\w-])|\\blook(?![\\w-])|\\blooking(?![\\w-])|\\blooks(?![\\w-])|\\bltd(?![\\w-])|\\bm(?![\\w-])|\\bmainly(?![\\w-])|\\bmany(?![\\w-])|\\bmay(?![\\w-])|\\bmaybe(?![\\w-])|\\bme(?![\\w-])|\\bmean(?![\\w-])|\\bmeanwhile(?![\\w-])|\\bmerely(?![\\w-])|\\bmight(?![\\w-])|\\bmore(?![\\w-])|\\bmoreover(?![\\w-])|\\bmost(?![\\w-])|\\bmostly(?![\\w-])|\\bmuch(?![\\w-])|\\bmust(?![\\w-])|\\bmy(?![\\w-])|\\bmyself(?![\\w-])|\\bn(?![\\w-])|\\bname(?![\\w-])|\\bnamely(?![\\w-])|\\bnd(?![\\w-])|\\bnear(?![\\w-])|\\bnearly(?![\\w-])|\\bnecessary(?![\\w-])|\\bneed(?![\\w-])|\\bneeds(?![\\w-])|\\bneither(?![\\w-])|\\bnever(?![\\w-])|\\bnevertheless(?![\\w-])|\\bnew(?![\\w-])|\\bnext(?![\\w-])|\\bnine(?![\\w-])|\\bno(?![\\w-])|\\bnobody(?![\\w-])|\\bnon(?![\\w-])|\\bnone(?![\\w-])|\\bnoone(?![\\w-])|\\bnor(?![\\w-])|\\bnormally(?![\\w-])|\\bnot(?![\\w-])|\\bnothing(?![\\w-])|\\bnovel(?![\\w-])|\\bnow(?![\\w-])|\\bnowhere(?![\\w-])|\\bo(?![\\w-])|\\bobviously(?![\\w-])|\\bof(?![\\w-])|\\boff(?![\\w-])|\\boften(?![\\w-])|\\boh(?![\\w-])|\\bok(?![\\w-])|\\bokay(?![\\w-])|\\bold(?![\\w-])|\\bon(?![\\w-])|\\bonce(?![\\w-])|\\bone(?![\\w-])|\\bones(?![\\w-])|\\bonly(?![\\w-])|\\bonto(?![\\w-])|\\bor(?![\\w-])|\\bother(?![\\w-])|\\bothers(?![\\w-])|\\botherwise(?![\\w-])|\\bought(?![\\w-])|\\bour(?![\\w-])|\\bours(?![\\w-])|\\bourselves(?![\\w-])|\\bout(?![\\w-])|\\boutside(?![\\w-])|\\bover(?![\\w-])|\\boverall(?![\\w-])|\\bown(?![\\w-])|\\bp(?![\\w-])|\\bparticular(?![\\w-])|\\bparticularly(?![\\w-])|\\bper(?![\\w-])|\\bperhaps(?![\\w-])|\\bplaced(?![\\w-])|\\bplease(?![\\w-])|\\bplus(?![\\w-])|\\bpossible(?![\\w-])|\\bpresumably(?![\\w-])|\\bprobably(?![\\w-])|\\bprovides(?![\\w-])|\\bq(?![\\w-])|\\bque(?![\\w-])|\\bquite(?![\\w-])|\\bqv(?![\\w-])|\\br(?![\\w-])|\\brather(?![\\w-])|\\brd(?![\\w-])|\\bre(?![\\w-])|\\breally(?![\\w-])|\\breasonably(?![\\w-])|\\bregarding(?![\\w-])|\\bregardless(?![\\w-])|\\bregards(?![\\w-])|\\brelatively(?![\\w-])|\\brespectively(?![\\w-])|\\bright(?![\\w-])|\\bs(?![\\w-])|\\bsaid(?![\\w-])|\\bsame(?![\\w-])|\\bsaw(?![\\w-])|\\bsay(?![\\w-])|\\bsaying(?![\\w-])|\\bsays(?![\\w-])|\\bsecond(?![\\w-])|\\bsecondly(?![\\w-])|\\bsee(?![\\w-])|\\bseeing(?![\\w-])|\\bseem(?![\\w-])|\\bseemed(?![\\w-])|\\bseeming(?![\\w-])|\\bseems(?![\\w-])|\\bseen(?![\\w-])|\\bself(?![\\w-])|\\bselves(?![\\w-])|\\bsensible(?![\\w-])|\\bsent(?![\\w-])|\\bserious(?![\\w-])|\\bseriously(?![\\w-])|\\bseven(?![\\w-])|\\bseveral(?![\\w-])|\\bshall(?![\\w-])|\\bshe(?![\\w-])|\\bshould(?![\\w-])|\\bshouldn't(?![\\w-])|\\bsince(?![\\w-])|\\bsix(?![\\w-])|\\bso(?![\\w-])|\\bsome(?![\\w-])|\\bsomebody(?![\\w-])|\\bsomehow(?![\\w-])|\\bsomeone(?![\\w-])|\\bsomething(?![\\w-])|\\bsometime(?![\\w-])|\\bsometimes(?![\\w-])|\\bsomewhat(?![\\w-])|\\bsomewhere(?![\\w-])|\\bsoon(?![\\w-])|\\bsorry(?![\\w-])|\\bspecified(?![\\w-])|\\bspecify(?![\\w-])|\\bspecifying(?![\\w-])|\\bstill(?![\\w-])|\\bsub(?![\\w-])|\\bsuch(?![\\w-])|\\bsup(?![\\w-])|\\bsure(?![\\w-])|\\bt(?![\\w-])|\\bt's(?![\\w-])|\\btake(?![\\w-])|\\btaken(?![\\w-])|\\btell(?![\\w-])|\\btends(?![\\w-])|\\bth(?![\\w-])|\\bthan(?![\\w-])|\\bthank(?![\\w-])|\\bthanks(?![\\w-])|\\bthanx(?![\\w-])|\\bthat(?![\\w-])|\\bthat's(?![\\w-])|\\bthats(?![\\w-])|\\bthe(?![\\w-])|\\btheir(?![\\w-])|\\btheirs(?![\\w-])|\\bthem(?![\\w-])|\\bthemselves(?![\\w-])|\\bthen(?![\\w-])|\\bthence(?![\\w-])|\\bthere(?![\\w-])|\\bthere's(?![\\w-])|\\bthereafter(?![\\w-])|\\bthereby(?![\\w-])|\\btherefore(?![\\w-])|\\btherein(?![\\w-])|\\btheres(?![\\w-])|\\bthereupon(?![\\w-])|\\bthese(?![\\w-])|\\bthey(?![\\w-])|\\bthey'd(?![\\w-])|\\bthey'll(?![\\w-])|\\bthey're(?![\\w-])|\\bthey've(?![\\w-])|\\bthink(?![\\w-])|\\bthird(?![\\w-])|\\bthis(?![\\w-])|\\bthorough(?![\\w-])|\\bthoroughly(?![\\w-])|\\bthose(?![\\w-])|\\bthough(?![\\w-])|\\bthree(?![\\w-])|\\bthrough(?![\\w-])|\\bthroughout(?![\\w-])|\\bthru(?![\\w-])|\\bthus(?![\\w-])|\\bto(?![\\w-])|\\btogether(?![\\w-])|\\btoo(?![\\w-])|\\btook(?![\\w-])|\\btoward(?![\\w-])|\\btowards(?![\\w-])|\\btried(?![\\w-])|\\btries(?![\\w-])|\\btruly(?![\\w-])|\\btry(?![\\w-])|\\btrying(?![\\w-])|\\btwice(?![\\w-])|\\btwo(?![\\w-])|\\bu(?![\\w-])|\\bun(?![\\w-])|\\bunder(?![\\w-])|\\bunfortunately(?![\\w-])|\\bunless(?![\\w-])|\\bunlikely(?![\\w-])|\\buntil(?![\\w-])|\\bunto(?![\\w-])|\\bup(?![\\w-])|\\bupon(?![\\w-])|\\bus(?![\\w-])|\\buse(?![\\w-])|\\bused(?![\\w-])|\\buseful(?![\\w-])|\\buses(?![\\w-])|\\busing(?![\\w-])|\\busually(?![\\w-])|\\buucp(?![\\w-])|\\bv(?![\\w-])|\\bvalue(?![\\w-])|\\bvarious(?![\\w-])|\\bvery(?![\\w-])|\\bvia(?![\\w-])|\\bviz(?![\\w-])|\\bvs(?![\\w-])|\\bw(?![\\w-])|\\bwant(?![\\w-])|\\bwants(?![\\w-])|\\bwas(?![\\w-])|\\bwasn't(?![\\w-])|\\bway(?![\\w-])|\\bwe(?![\\w-])|\\bwe'd(?![\\w-])|\\bwe'll(?![\\w-])|\\bwe're(?![\\w-])|\\bwe've(?![\\w-])|\\bwelcome(?![\\w-])|\\bwell(?![\\w-])|\\bwent(?![\\w-])|\\bwere(?![\\w-])|\\bweren't(?![\\w-])|\\bwhat(?![\\w-])|\\bwhat's(?![\\w-])|\\bwhatever(?![\\w-])|\\bwhen(?![\\w-])|\\bwhence(?![\\w-])|\\bwhenever(?![\\w-])|\\bwhere(?![\\w-])|\\bwhere's(?![\\w-])|\\bwhereafter(?![\\w-])|\\bwhereas(?![\\w-])|\\bwhereby(?![\\w-])|\\bwherein(?![\\w-])|\\bwhereupon(?![\\w-])|\\bwherever(?![\\w-])|\\bwhether(?![\\w-])|\\bwhich(?![\\w-])|\\bwhile(?![\\w-])|\\bwhither(?![\\w-])|\\bwho(?![\\w-])|\\bwho's(?![\\w-])|\\bwhoever(?![\\w-])|\\bwhole(?![\\w-])|\\bwhom(?![\\w-])|\\bwhose(?![\\w-])|\\bwhy(?![\\w-])|\\bwill(?![\\w-])|\\bwilling(?![\\w-])|\\bwish(?![\\w-])|\\bwith(?![\\w-])|\\bwithin(?![\\w-])|\\bwithout(?![\\w-])|\\bwon't(?![\\w-])|\\bwonder(?![\\w-])|\\bwould(?![\\w-])|\\bwould(?![\\w-])|\\bwouldn't(?![\\w-])|\\bx(?![\\w-])|\\by(?![\\w-])|\\byes(?![\\w-])|\\byet(?![\\w-])|\\byou(?![\\w-])|\\byou'd(?![\\w-])|\\byou'll(?![\\w-])|\\byou're(?![\\w-])|\\byou've(?![\\w-])|\\byour(?![\\w-])|\\byours(?![\\w-])|\\byourself(?![\\w-])|\\byourselves(?![\\w-])|\\bz(?![\\w-])|\\bzero(?![\\w-])\",\n",
        "re.IGNORECASE|re.UNICODE)\"\"\"\n",
        "    # generate candidate keywords\n",
        "    phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)\n",
        "    if debug: print('_________Phrases',phraseList)\n",
        "    # calculate individual word scores\n",
        "    wordscores = calculate_word_scores(phraseList)\n",
        "    if debug: print('_________wordscores',wordscores)\n",
        "    # generate candidate keyword scores\n",
        "    keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)\n",
        "    if debug: print('_________keywcand',keywordcandidates)\n",
        "\n",
        "    sortedKeywords = sorted(keywordcandidates.items(), key=operator.itemgetter(1), reverse=True)\n",
        "    if debug: print('_________sorkeyw',sortedKeywords)\n",
        "\n",
        "    totalKeywords = len(sortedKeywords)\n",
        "    if debug: print('_________totalkeyw',totalKeywords)\n",
        "    print (sortedKeywords[0:int(totalKeywords / 3)])\n",
        "\n",
        "    #rake = Rake(\"E:/input/SmartStoplist.txt\")\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bbc8d4c4-5011-3000-3b09-15692af19d2e"
      },
      "outputs": [],
      "source": [
        "# Implementation of RAKE - Rapid Automtic Keyword Exraction algorithm\n",
        "# as described in:\n",
        "# Rose, S., D. Engel, N. Cramer, and W. Cowley (2010). \n",
        "# Automatic keyword extraction from indi-vidual documents. \n",
        "# In M. W. Berry and J. Kogan (Eds.), Text Mining: Applications and Theory.unknown: John Wiley and Sons, Ltd.\n",
        "#\n",
        "# NOTE: The original code (from https://github.com/aneesha/RAKE)\n",
        "# has been extended by a_medelyan (zelandiya)\n",
        "# with a set of heuristics to decide whether a phrase is an acceptable candidate\n",
        "# as well as the ability to set frequency and phrase length parameters\n",
        "# important when dealing with longer documents\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import re\n",
        "import operator\n",
        "import six\n",
        "from six.moves import range\n",
        "\n",
        "debug = True\n",
        "test = True\n",
        "\n",
        "\n",
        "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\n",
        "\n",
        "def stripTagsAndUris(x):\n",
        "    if x:\n",
        "        # BeautifulSoup on content\n",
        "        soup = BeautifulSoup(x, \"html.parser\")\n",
        "        # Stripping all <code> tags with their content if any\n",
        "        if soup.code:\n",
        "            soup.code.decompose()\n",
        "        # Get all the text out of the html\n",
        "        text =  soup.get_text()\n",
        "        # Returning text stripping out all uris\n",
        "        return re.sub(uri_re, \"\", text)\n",
        "    else:\n",
        "        return \"\"\n",
        "    \n",
        "\n",
        "def is_number(s):\n",
        "    try:\n",
        "        float(s) if '.' in s else int(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "def load_stop_words(stop_word_file):\n",
        "    \"\"\"\n",
        "    Utility function to load stop words from a file and return as a list of words\n",
        "    @param stop_word_file Path and file name of a file containing stop words.\n",
        "    @return list A list of stop words.\n",
        "    \"\"\"\n",
        "    stop_words = []\n",
        "    for line in open(stop_word_file):\n",
        "        if line.strip()[0:1] != \"#\":\n",
        "            for word in line.split():  # in case more than one per line\n",
        "                stop_words.append(word)\n",
        "    return stop_words\n",
        "\n",
        "\n",
        "def separate_words(text, min_word_return_size):\n",
        "    \"\"\"\n",
        "    Utility function to return a list of all words that are have a length greater than a specified number of characters.\n",
        "    @param text The text that must be split in to words.\n",
        "    @param min_word_return_size The minimum no of characters a word must have to be included.\n",
        "    \"\"\"\n",
        "    splitter = re.compile('[^a-zA-Z0-9_\\\\+\\\\-/]')\n",
        "    words = []\n",
        "    for single_word in splitter.split(text):\n",
        "        current_word = single_word.strip().lower()\n",
        "        #leave numbers in phrase, but don't count as words, since they tend to invalidate scores of their phrases\n",
        "        if len(current_word) > min_word_return_size and current_word != '' and not is_number(current_word):\n",
        "            words.append(current_word)\n",
        "    return words\n",
        "\n",
        "\n",
        "def split_sentences(text):\n",
        "    \"\"\"\n",
        "    Utility function to return a list of sentences.\n",
        "    @param text The text that must be split in to sentences.\n",
        "    \"\"\"\n",
        "    sentence_delimiters = re.compile(u'[.!?,;:\\t\\\\\\\\\"\\\\(\\\\)\\\\\\'\\u2019\\u2013]|\\\\s\\\\-\\\\s')\n",
        "    sentences = sentence_delimiters.split(text)\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def build_stop_word_regex(stop_word_file_path):\n",
        "    stop_word_list = load_stop_words(stop_word_file_path)\n",
        "    stop_word_regex_list = []\n",
        "    for word in stop_word_list:\n",
        "        word_regex = '\\\\b' + word + '\\\\b'\n",
        "        stop_word_regex_list.append(word_regex)\n",
        "    stop_word_pattern = re.compile('|'.join(stop_word_regex_list), re.IGNORECASE)\n",
        "    return stop_word_pattern\n",
        "\n",
        "\n",
        "def generate_candidate_keywords(sentence_list, stopword_pattern, min_char_length=1, max_words_length=5):\n",
        "    phrase_list = []\n",
        "    for s in sentence_list:\n",
        "        tmp = re.sub(stopword_pattern, '|', s.strip())\n",
        "        phrases = tmp.split(\"|\")\n",
        "        for phrase in phrases:\n",
        "            phrase = phrase.strip().lower()\n",
        "            if phrase != \"\" and is_acceptable(phrase, min_char_length, max_words_length):\n",
        "                phrase_list.append(phrase)\n",
        "    return phrase_list\n",
        "\n",
        "\n",
        "def is_acceptable(phrase, min_char_length, max_words_length):\n",
        "\n",
        "    # a phrase must have a min length in characters\n",
        "    if len(phrase) < min_char_length:\n",
        "        return 0\n",
        "\n",
        "    # a phrase must have a max number of words\n",
        "    words = phrase.split()\n",
        "    if len(words) > max_words_length:\n",
        "        return 0\n",
        "\n",
        "    digits = 0\n",
        "    alpha = 0\n",
        "    for i in range(0, len(phrase)):\n",
        "        if phrase[i].isdigit():\n",
        "            digits += 1\n",
        "        elif phrase[i].isalpha():\n",
        "            alpha += 1\n",
        "\n",
        "    # a phrase must have at least one alpha character\n",
        "    if alpha == 0:\n",
        "        return 0\n",
        "\n",
        "    # a phrase must have more alpha than digits characters\n",
        "    if digits > alpha:\n",
        "        return 0\n",
        "    return 1\n",
        "\n",
        "\n",
        "def calculate_word_scores(phraseList):\n",
        "    word_frequency = {}\n",
        "    word_degree = {}\n",
        "    for phrase in phraseList:\n",
        "        word_list = separate_words(phrase, 0)\n",
        "        word_list_length = len(word_list)\n",
        "        word_list_degree = word_list_length - 1\n",
        "        #if word_list_degree > 3: word_list_degree = 3 #exp.\n",
        "        for word in word_list:\n",
        "            word_frequency.setdefault(word, 0)\n",
        "            word_frequency[word] += 1\n",
        "            word_degree.setdefault(word, 0)\n",
        "            word_degree[word] += word_list_degree  #orig.\n",
        "            #word_degree[word] += 1/(word_list_length*1.0) #exp.\n",
        "    for item in word_frequency:\n",
        "        word_degree[item] = word_degree[item] + word_frequency[item]\n",
        "\n",
        "    # Calculate Word scores = deg(w)/frew(w)\n",
        "    word_score = {}\n",
        "    for item in word_frequency:\n",
        "        word_score.setdefault(item, 0)\n",
        "        word_score[item] = word_degree[item] / (word_frequency[item] * 1.0)  #orig.\n",
        "    #word_score[item] = word_frequency[item]/(word_degree[item] * 1.0) #exp.\n",
        "    return word_score\n",
        "\n",
        "\n",
        "def generate_candidate_keyword_scores(phrase_list, word_score, min_keyword_frequency=1):\n",
        "    keyword_candidates = {}\n",
        "\n",
        "    for phrase in phrase_list:\n",
        "        if min_keyword_frequency > 1:\n",
        "            if phrase_list.count(phrase) < min_keyword_frequency:\n",
        "                continue\n",
        "        keyword_candidates.setdefault(phrase, 0)\n",
        "        word_list = separate_words(phrase, 0)\n",
        "        candidate_score = 0\n",
        "        for word in word_list:\n",
        "            candidate_score += word_score[word]\n",
        "        keyword_candidates[phrase] = candidate_score\n",
        "    return keyword_candidates\n",
        "\n",
        "\n",
        "class Rake(object):\n",
        "    def __init__(self, stop_words_path, min_char_length=1, max_words_length=5, min_keyword_frequency=1):\n",
        "        self.__stop_words_path = stop_words_path\n",
        "        self.__stop_words_pattern = build_stop_word_regex(stop_words_path)\n",
        "        self.__min_char_length = min_char_length\n",
        "        self.__max_words_length = max_words_length\n",
        "        self.__min_keyword_frequency = min_keyword_frequency\n",
        "\n",
        "    def run(self, text):\n",
        "        sentence_list = split_sentences(text)\n",
        "\n",
        "        phrase_list = generate_candidate_keywords(sentence_list, self.__stop_words_pattern, self.__min_char_length, self.__max_words_length)\n",
        "\n",
        "        word_scores = calculate_word_scores(phrase_list)\n",
        "\n",
        "        keyword_candidates = generate_candidate_keyword_scores(phrase_list, word_scores, self.__min_keyword_frequency)\n",
        "\n",
        "        sorted_keywords = sorted(six.iteritems(keyword_candidates), key=operator.itemgetter(1), reverse=True)\n",
        "        return sorted_keywords\n",
        "\n",
        "\n",
        "debug=True\n",
        "for index, row in train_data.sample(2).iterrows():\n",
        "    print('____input',row[\"title\"], row[\"content\"] ,row['tags']   )\n",
        "    print('___content',stripTagsAndUris(row['content']))\n",
        "    sentenceList = split_sentences(row['title']+'. '+stripTagsAndUris(row['content']))\n",
        "    #stoppath = \"FoxStoplist.txt\" #Fox stoplist contains \"numbers\", so it will not find \"natural numbers\" like in Table 1.1\n",
        "    stoppath = \"SmartStoplist.txt\"  #SMART stoplist misses some of the lower-scoring keywords in Figure 1.5, which means that the top 1/3 cuts off one of the 4.0 score words in Table 1.1\n",
        "    #stopwordpattern = build_stop_word_regex(stoppath)\n",
        "    stopwordpattern= \"\"\"re.compile(r\"\\ba(?![\\w-])|\\ba's(?![\\w-])|\\bable(?![\\w-])|\\babout(?![\\w-])|\\babove(?![\\w-])|\\baccording(?![\\w-])|\\baccordingly(?![\\w-])|\\bacross(?![\\w-])|\\bactually(?![\\w-])|\\bafter(?![\\w-])|\\bafterwards(?![\\w-])|\\bagain(?![\\w-])|\\bagainst(?![\\w-])|\\bain't(?![\\w-])|\\ball(?![\\w-])|\\ballow(?![\\w-])|\\ballows(?![\\w-])|\\balmost(?![\\w-])|\\balone(?![\\w-])|\\balong(?![\\w-])|\\balready(?![\\w-])|\\balso(?![\\w-])|\\balthough(?![\\w-])|\\balways(?![\\w-])|\\bam(?![\\w-])|\\bamong(?![\\w-])|\\bamongst(?![\\w-])|\\ban(?![\\w-])|\\band(?![\\w-])|\\banother(?![\\w-])|\\bany(?![\\w-])|\\banybody(?![\\w-])|\\banyhow(?![\\w-])|\\banyone(?![\\w-])|\\banything(?![\\w-])|\\banyway(?![\\w-])|\\banyways(?![\\w-])|\\banywhere(?![\\w-])|\\bapart(?![\\w-])|\\bappear(?![\\w-])|\\bappreciate(?![\\w-])|\\bappropriate(?![\\w-])|\\bare(?![\\w-])|\\baren't(?![\\w-])|\\baround(?![\\w-])|\\bas(?![\\w-])|\\baside(?![\\w-])|\\bask(?![\\w-])|\\basking(?![\\w-])|\\bassociated(?![\\w-])|\\bat(?![\\w-])|\\bavailable(?![\\w-])|\\baway(?![\\w-])|\\bawfully(?![\\w-])|\\bb(?![\\w-])|\\bbe(?![\\w-])|\\bbecame(?![\\w-])|\\bbecause(?![\\w-])|\\bbecome(?![\\w-])|\\bbecomes(?![\\w-])|\\bbecoming(?![\\w-])|\\bbeen(?![\\w-])|\\bbefore(?![\\w-])|\\bbeforehand(?![\\w-])|\\bbehind(?![\\w-])|\\bbeing(?![\\w-])|\\bbelieve(?![\\w-])|\\bbelow(?![\\w-])|\\bbeside(?![\\w-])|\\bbesides(?![\\w-])|\\bbest(?![\\w-])|\\bbetter(?![\\w-])|\\bbetween(?![\\w-])|\\bbeyond(?![\\w-])|\\bboth(?![\\w-])|\\bbrief(?![\\w-])|\\bbut(?![\\w-])|\\bby(?![\\w-])|\\bc(?![\\w-])|\\bc'mon(?![\\w-])|\\bc's(?![\\w-])|\\bcame(?![\\w-])|\\bcan(?![\\w-])|\\bcan't(?![\\w-])|\\bcannot(?![\\w-])|\\bcant(?![\\w-])|\\bcause(?![\\w-])|\\bcauses(?![\\w-])|\\bcertain(?![\\w-])|\\bcertainly(?![\\w-])|\\bchanges(?![\\w-])|\\bclearly(?![\\w-])|\\bco(?![\\w-])|\\bcom(?![\\w-])|\\bcome(?![\\w-])|\\bcomes(?![\\w-])|\\bconcerning(?![\\w-])|\\bconsequently(?![\\w-])|\\bconsider(?![\\w-])|\\bconsidering(?![\\w-])|\\bcontain(?![\\w-])|\\bcontaining(?![\\w-])|\\bcontains(?![\\w-])|\\bcorresponding(?![\\w-])|\\bcould(?![\\w-])|\\bcouldn't(?![\\w-])|\\bcourse(?![\\w-])|\\bcurrently(?![\\w-])|\\bd(?![\\w-])|\\bdefinitely(?![\\w-])|\\bdescribed(?![\\w-])|\\bdespite(?![\\w-])|\\bdid(?![\\w-])|\\bdidn't(?![\\w-])|\\bdifferent(?![\\w-])|\\bdo(?![\\w-])|\\bdoes(?![\\w-])|\\bdoesn't(?![\\w-])|\\bdoing(?![\\w-])|\\bdon't(?![\\w-])|\\bdone(?![\\w-])|\\bdown(?![\\w-])|\\bdownwards(?![\\w-])|\\bduring(?![\\w-])|\\be(?![\\w-])|\\beach(?![\\w-])|\\bedu(?![\\w-])|\\beg(?![\\w-])|\\beight(?![\\w-])|\\beither(?![\\w-])|\\belse(?![\\w-])|\\belsewhere(?![\\w-])|\\benough(?![\\w-])|\\bentirely(?![\\w-])|\\bespecially(?![\\w-])|\\bet(?![\\w-])|\\betc(?![\\w-])|\\beven(?![\\w-])|\\bever(?![\\w-])|\\bevery(?![\\w-])|\\beverybody(?![\\w-])|\\beveryone(?![\\w-])|\\beverything(?![\\w-])|\\beverywhere(?![\\w-])|\\bex(?![\\w-])|\\bexactly(?![\\w-])|\\bexample(?![\\w-])|\\bexcept(?![\\w-])|\\bf(?![\\w-])|\\bfar(?![\\w-])|\\bfew(?![\\w-])|\\bfifth(?![\\w-])|\\bfirst(?![\\w-])|\\bfive(?![\\w-])|\\bfollowed(?![\\w-])|\\bfollowing(?![\\w-])|\\bfollows(?![\\w-])|\\bfor(?![\\w-])|\\bformer(?![\\w-])|\\bformerly(?![\\w-])|\\bforth(?![\\w-])|\\bfour(?![\\w-])|\\bfrom(?![\\w-])|\\bfurther(?![\\w-])|\\bfurthermore(?![\\w-])|\\bg(?![\\w-])|\\bget(?![\\w-])|\\bgets(?![\\w-])|\\bgetting(?![\\w-])|\\bgiven(?![\\w-])|\\bgives(?![\\w-])|\\bgo(?![\\w-])|\\bgoes(?![\\w-])|\\bgoing(?![\\w-])|\\bgone(?![\\w-])|\\bgot(?![\\w-])|\\bgotten(?![\\w-])|\\bgreetings(?![\\w-])|\\bh(?![\\w-])|\\bhad(?![\\w-])|\\bhadn't(?![\\w-])|\\bhappens(?![\\w-])|\\bhardly(?![\\w-])|\\bhas(?![\\w-])|\\bhasn't(?![\\w-])|\\bhave(?![\\w-])|\\bhaven't(?![\\w-])|\\bhaving(?![\\w-])|\\bhe(?![\\w-])|\\bhe's(?![\\w-])|\\bhello(?![\\w-])|\\bhelp(?![\\w-])|\\bhence(?![\\w-])|\\bher(?![\\w-])|\\bhere(?![\\w-])|\\bhere's(?![\\w-])|\\bhereafter(?![\\w-])|\\bhereby(?![\\w-])|\\bherein(?![\\w-])|\\bhereupon(?![\\w-])|\\bhers(?![\\w-])|\\bherself(?![\\w-])|\\bhi(?![\\w-])|\\bhim(?![\\w-])|\\bhimself(?![\\w-])|\\bhis(?![\\w-])|\\bhither(?![\\w-])|\\bhopefully(?![\\w-])|\\bhow(?![\\w-])|\\bhowbeit(?![\\w-])|\\bhowever(?![\\w-])|\\bi(?![\\w-])|\\bi'd(?![\\w-])|\\bi'll(?![\\w-])|\\bi'm(?![\\w-])|\\bi've(?![\\w-])|\\bie(?![\\w-])|\\bif(?![\\w-])|\\bignored(?![\\w-])|\\bimmediate(?![\\w-])|\\bin(?![\\w-])|\\binasmuch(?![\\w-])|\\binc(?![\\w-])|\\bindeed(?![\\w-])|\\bindicate(?![\\w-])|\\bindicated(?![\\w-])|\\bindicates(?![\\w-])|\\binner(?![\\w-])|\\binsofar(?![\\w-])|\\binstead(?![\\w-])|\\binto(?![\\w-])|\\binward(?![\\w-])|\\bis(?![\\w-])|\\bisn't(?![\\w-])|\\bit(?![\\w-])|\\bit'd(?![\\w-])|\\bit'll(?![\\w-])|\\bit's(?![\\w-])|\\bits(?![\\w-])|\\bitself(?![\\w-])|\\bj(?![\\w-])|\\bjust(?![\\w-])|\\bk(?![\\w-])|\\bkeep(?![\\w-])|\\bkeeps(?![\\w-])|\\bkept(?![\\w-])|\\bknow(?![\\w-])|\\bknows(?![\\w-])|\\bknown(?![\\w-])|\\bl(?![\\w-])|\\blast(?![\\w-])|\\blately(?![\\w-])|\\blater(?![\\w-])|\\blatter(?![\\w-])|\\blatterly(?![\\w-])|\\bleast(?![\\w-])|\\bless(?![\\w-])|\\blest(?![\\w-])|\\blet(?![\\w-])|\\blet's(?![\\w-])|\\blike(?![\\w-])|\\bliked(?![\\w-])|\\blikely(?![\\w-])|\\blittle(?![\\w-])|\\blook(?![\\w-])|\\blooking(?![\\w-])|\\blooks(?![\\w-])|\\bltd(?![\\w-])|\\bm(?![\\w-])|\\bmainly(?![\\w-])|\\bmany(?![\\w-])|\\bmay(?![\\w-])|\\bmaybe(?![\\w-])|\\bme(?![\\w-])|\\bmean(?![\\w-])|\\bmeanwhile(?![\\w-])|\\bmerely(?![\\w-])|\\bmight(?![\\w-])|\\bmore(?![\\w-])|\\bmoreover(?![\\w-])|\\bmost(?![\\w-])|\\bmostly(?![\\w-])|\\bmuch(?![\\w-])|\\bmust(?![\\w-])|\\bmy(?![\\w-])|\\bmyself(?![\\w-])|\\bn(?![\\w-])|\\bname(?![\\w-])|\\bnamely(?![\\w-])|\\bnd(?![\\w-])|\\bnear(?![\\w-])|\\bnearly(?![\\w-])|\\bnecessary(?![\\w-])|\\bneed(?![\\w-])|\\bneeds(?![\\w-])|\\bneither(?![\\w-])|\\bnever(?![\\w-])|\\bnevertheless(?![\\w-])|\\bnew(?![\\w-])|\\bnext(?![\\w-])|\\bnine(?![\\w-])|\\bno(?![\\w-])|\\bnobody(?![\\w-])|\\bnon(?![\\w-])|\\bnone(?![\\w-])|\\bnoone(?![\\w-])|\\bnor(?![\\w-])|\\bnormally(?![\\w-])|\\bnot(?![\\w-])|\\bnothing(?![\\w-])|\\bnovel(?![\\w-])|\\bnow(?![\\w-])|\\bnowhere(?![\\w-])|\\bo(?![\\w-])|\\bobviously(?![\\w-])|\\bof(?![\\w-])|\\boff(?![\\w-])|\\boften(?![\\w-])|\\boh(?![\\w-])|\\bok(?![\\w-])|\\bokay(?![\\w-])|\\bold(?![\\w-])|\\bon(?![\\w-])|\\bonce(?![\\w-])|\\bone(?![\\w-])|\\bones(?![\\w-])|\\bonly(?![\\w-])|\\bonto(?![\\w-])|\\bor(?![\\w-])|\\bother(?![\\w-])|\\bothers(?![\\w-])|\\botherwise(?![\\w-])|\\bought(?![\\w-])|\\bour(?![\\w-])|\\bours(?![\\w-])|\\bourselves(?![\\w-])|\\bout(?![\\w-])|\\boutside(?![\\w-])|\\bover(?![\\w-])|\\boverall(?![\\w-])|\\bown(?![\\w-])|\\bp(?![\\w-])|\\bparticular(?![\\w-])|\\bparticularly(?![\\w-])|\\bper(?![\\w-])|\\bperhaps(?![\\w-])|\\bplaced(?![\\w-])|\\bplease(?![\\w-])|\\bplus(?![\\w-])|\\bpossible(?![\\w-])|\\bpresumably(?![\\w-])|\\bprobably(?![\\w-])|\\bprovides(?![\\w-])|\\bq(?![\\w-])|\\bque(?![\\w-])|\\bquite(?![\\w-])|\\bqv(?![\\w-])|\\br(?![\\w-])|\\brather(?![\\w-])|\\brd(?![\\w-])|\\bre(?![\\w-])|\\breally(?![\\w-])|\\breasonably(?![\\w-])|\\bregarding(?![\\w-])|\\bregardless(?![\\w-])|\\bregards(?![\\w-])|\\brelatively(?![\\w-])|\\brespectively(?![\\w-])|\\bright(?![\\w-])|\\bs(?![\\w-])|\\bsaid(?![\\w-])|\\bsame(?![\\w-])|\\bsaw(?![\\w-])|\\bsay(?![\\w-])|\\bsaying(?![\\w-])|\\bsays(?![\\w-])|\\bsecond(?![\\w-])|\\bsecondly(?![\\w-])|\\bsee(?![\\w-])|\\bseeing(?![\\w-])|\\bseem(?![\\w-])|\\bseemed(?![\\w-])|\\bseeming(?![\\w-])|\\bseems(?![\\w-])|\\bseen(?![\\w-])|\\bself(?![\\w-])|\\bselves(?![\\w-])|\\bsensible(?![\\w-])|\\bsent(?![\\w-])|\\bserious(?![\\w-])|\\bseriously(?![\\w-])|\\bseven(?![\\w-])|\\bseveral(?![\\w-])|\\bshall(?![\\w-])|\\bshe(?![\\w-])|\\bshould(?![\\w-])|\\bshouldn't(?![\\w-])|\\bsince(?![\\w-])|\\bsix(?![\\w-])|\\bso(?![\\w-])|\\bsome(?![\\w-])|\\bsomebody(?![\\w-])|\\bsomehow(?![\\w-])|\\bsomeone(?![\\w-])|\\bsomething(?![\\w-])|\\bsometime(?![\\w-])|\\bsometimes(?![\\w-])|\\bsomewhat(?![\\w-])|\\bsomewhere(?![\\w-])|\\bsoon(?![\\w-])|\\bsorry(?![\\w-])|\\bspecified(?![\\w-])|\\bspecify(?![\\w-])|\\bspecifying(?![\\w-])|\\bstill(?![\\w-])|\\bsub(?![\\w-])|\\bsuch(?![\\w-])|\\bsup(?![\\w-])|\\bsure(?![\\w-])|\\bt(?![\\w-])|\\bt's(?![\\w-])|\\btake(?![\\w-])|\\btaken(?![\\w-])|\\btell(?![\\w-])|\\btends(?![\\w-])|\\bth(?![\\w-])|\\bthan(?![\\w-])|\\bthank(?![\\w-])|\\bthanks(?![\\w-])|\\bthanx(?![\\w-])|\\bthat(?![\\w-])|\\bthat's(?![\\w-])|\\bthats(?![\\w-])|\\bthe(?![\\w-])|\\btheir(?![\\w-])|\\btheirs(?![\\w-])|\\bthem(?![\\w-])|\\bthemselves(?![\\w-])|\\bthen(?![\\w-])|\\bthence(?![\\w-])|\\bthere(?![\\w-])|\\bthere's(?![\\w-])|\\bthereafter(?![\\w-])|\\bthereby(?![\\w-])|\\btherefore(?![\\w-])|\\btherein(?![\\w-])|\\btheres(?![\\w-])|\\bthereupon(?![\\w-])|\\bthese(?![\\w-])|\\bthey(?![\\w-])|\\bthey'd(?![\\w-])|\\bthey'll(?![\\w-])|\\bthey're(?![\\w-])|\\bthey've(?![\\w-])|\\bthink(?![\\w-])|\\bthird(?![\\w-])|\\bthis(?![\\w-])|\\bthorough(?![\\w-])|\\bthoroughly(?![\\w-])|\\bthose(?![\\w-])|\\bthough(?![\\w-])|\\bthree(?![\\w-])|\\bthrough(?![\\w-])|\\bthroughout(?![\\w-])|\\bthru(?![\\w-])|\\bthus(?![\\w-])|\\bto(?![\\w-])|\\btogether(?![\\w-])|\\btoo(?![\\w-])|\\btook(?![\\w-])|\\btoward(?![\\w-])|\\btowards(?![\\w-])|\\btried(?![\\w-])|\\btries(?![\\w-])|\\btruly(?![\\w-])|\\btry(?![\\w-])|\\btrying(?![\\w-])|\\btwice(?![\\w-])|\\btwo(?![\\w-])|\\bu(?![\\w-])|\\bun(?![\\w-])|\\bunder(?![\\w-])|\\bunfortunately(?![\\w-])|\\bunless(?![\\w-])|\\bunlikely(?![\\w-])|\\buntil(?![\\w-])|\\bunto(?![\\w-])|\\bup(?![\\w-])|\\bupon(?![\\w-])|\\bus(?![\\w-])|\\buse(?![\\w-])|\\bused(?![\\w-])|\\buseful(?![\\w-])|\\buses(?![\\w-])|\\busing(?![\\w-])|\\busually(?![\\w-])|\\buucp(?![\\w-])|\\bv(?![\\w-])|\\bvalue(?![\\w-])|\\bvarious(?![\\w-])|\\bvery(?![\\w-])|\\bvia(?![\\w-])|\\bviz(?![\\w-])|\\bvs(?![\\w-])|\\bw(?![\\w-])|\\bwant(?![\\w-])|\\bwants(?![\\w-])|\\bwas(?![\\w-])|\\bwasn't(?![\\w-])|\\bway(?![\\w-])|\\bwe(?![\\w-])|\\bwe'd(?![\\w-])|\\bwe'll(?![\\w-])|\\bwe're(?![\\w-])|\\bwe've(?![\\w-])|\\bwelcome(?![\\w-])|\\bwell(?![\\w-])|\\bwent(?![\\w-])|\\bwere(?![\\w-])|\\bweren't(?![\\w-])|\\bwhat(?![\\w-])|\\bwhat's(?![\\w-])|\\bwhatever(?![\\w-])|\\bwhen(?![\\w-])|\\bwhence(?![\\w-])|\\bwhenever(?![\\w-])|\\bwhere(?![\\w-])|\\bwhere's(?![\\w-])|\\bwhereafter(?![\\w-])|\\bwhereas(?![\\w-])|\\bwhereby(?![\\w-])|\\bwherein(?![\\w-])|\\bwhereupon(?![\\w-])|\\bwherever(?![\\w-])|\\bwhether(?![\\w-])|\\bwhich(?![\\w-])|\\bwhile(?![\\w-])|\\bwhither(?![\\w-])|\\bwho(?![\\w-])|\\bwho's(?![\\w-])|\\bwhoever(?![\\w-])|\\bwhole(?![\\w-])|\\bwhom(?![\\w-])|\\bwhose(?![\\w-])|\\bwhy(?![\\w-])|\\bwill(?![\\w-])|\\bwilling(?![\\w-])|\\bwish(?![\\w-])|\\bwith(?![\\w-])|\\bwithin(?![\\w-])|\\bwithout(?![\\w-])|\\bwon't(?![\\w-])|\\bwonder(?![\\w-])|\\bwould(?![\\w-])|\\bwould(?![\\w-])|\\bwouldn't(?![\\w-])|\\bx(?![\\w-])|\\by(?![\\w-])|\\byes(?![\\w-])|\\byet(?![\\w-])|\\byou(?![\\w-])|\\byou'd(?![\\w-])|\\byou'll(?![\\w-])|\\byou're(?![\\w-])|\\byou've(?![\\w-])|\\byour(?![\\w-])|\\byours(?![\\w-])|\\byourself(?![\\w-])|\\byourselves(?![\\w-])|\\bz(?![\\w-])|\\bzero(?![\\w-])\",\n",
        "re.IGNORECASE|re.UNICODE)\"\"\"\n",
        "\n",
        "    #stopwordpattern = build_stop_word_regex(stoppath)\n",
        "\n",
        "    # generate candidate keywords\n",
        "    phraseList = generate_candidate_keywords(sentenceList, stopwordpattern)\n",
        "    if debug: print('____prhas',phraseList)\n",
        "\n",
        "\n",
        "    # calculate individual word scores\n",
        "    wordscores = calculate_word_scores(phraseList)\n",
        "    if debug: print('____words',wordscores)\n",
        "\n",
        "\n",
        "    # generate candidate keyword scores\n",
        "    keywordcandidates = generate_candidate_keyword_scores(phraseList, wordscores)\n",
        "    if debug: print('____keyw',keywordcandidates)\n",
        "\n",
        "    sortedKeywords = sorted(six.iteritems(keywordcandidates), key=operator.itemgetter(1), reverse=True)\n",
        "    if debug: print('____sort',sortedKeywords)\n",
        "\n",
        "    totalKeywords = len(sortedKeywords)\n",
        "    if debug: print('____ total',totalKeywords)\n",
        "    print('____result',sortedKeywords[0:(totalKeywords // 3)])\n",
        "\n",
        "    #rake = Rake(\"SmartStoplist.txt\")\n",
        "    #keywords = rake.run(text)\n",
        "    #print(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "437553c3-56ec-928e-0bcf-1ec2012fe40f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, ngram_range=(1,2),stop_words='english')\n",
        "\n",
        "sample=train_data.sample(3)\n",
        "for index, row in sample.iterrows():\n",
        "    print('____input',row[\"title\"], row[\"content\"] ,'<h1>',row['tags'],'</h1>'   )\n",
        "    data=row['title']+'. '+stripTagsAndUris(row['content'])\n",
        "    sample[index,'content']=data\n",
        "    \n",
        "tfidf = tfidf_vectorizer.fit_transform(sample['content'])\n",
        "print(data_samples)\n",
        "\n",
        "print(tfidf_vectorizer.vocabulary_)\n",
        "words=pd.DataFrame.from_dict(tfidf_vectorizer.vocabulary_,orient='index')\n",
        "print(words.sort_values(by=0,ascending=[0] ))\n",
        "#print(tfidf_vectorizer.idf_)\n",
        "#tfinv= tfidf_vectorizer.inverse_transform(tfidf)\n",
        "#print(tfinv)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}