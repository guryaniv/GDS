{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"_kg_hide-input": true}, "source": ["# Credit-Fraud Detection (Unbalanced Dataset)"], "cell_type": "markdown"}, {"metadata": {}, "source": ["### This notebook makes use of the 'Highly Unbalanced Dataset' for Credit Card Fraud Detection provided on Kaggle(https://www.kaggle.com/dalpozz/creditcardfraud)\n", "\n", "The implementation is done by:\n", "### Nishchal Gaba (nishgaba9@gmail.com)\n", "(October, 2017)\n", "\n", "#### NOTE: The implementation is varied at some points from the Research Papers mentioned later to test effects of such variations for research purposes"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Like, the 'Protected Division' usually returns '1' on having a denominator of 0, whereas the paper on which the Paper of 'Improving fitness...' is based on mentions the protected division to be 0 if the denominator is 0"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["We test two approaches provided in the research papers published for such highly unbalanced datasets\n", "\n", "### 1> Improving Fitness Functions in Genetic Programming for Classification on Unbalanced Credit Card Datasets\n", "(Cao, V. L., Le-Khac, N. A., Nicolau, M., ONeill, M., & McDermott, J. (2017). Improving Fitness Functions in Genetic Programming for Classification on Unbalanced Credit Card Datasets. arXiv preprint arXiv:1704.03522.)\n", "\n", "### 2> Scalable Twin Neural Networks for Classification of Unbalanced Data\n", "(Pant, H., Soman, S., & Sharma, M. (2017). Scalable Twin Neural Networks for Classification of Unbalanced Data. arXiv preprint arXiv:1705.00347.)"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {}, "source": ["import numpy as np\n", "import matplotlib\n", "import sys\n", "import pandas as pd\n", "import time\n", "import math\n", "import matplotlib.pyplot as plt\n", "import random\n", "import tpot as tp\n", "from sklearn.cross_validation import train_test_split\n", "from gplearn import genetic\n", "import gplearn as gp\n", "import itertools\n", "%matplotlib inline"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["## Importing and checking the dataset"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {}, "source": ["dataSet = pd.read_csv(\"../input/creditcard.csv\")\n", "dataSet.head()\n", "\n", "# 30 features with Time and Amount + 28 features from PCA"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {}, "source": ["# Checking the Counts of different classes\n", "# The positive cases for our tests are 492 frauds compared to 284315 for the genuine transactions\n", "dataSet['Class'].value_counts()"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# Implementing the Genetic Algorithm with improved fitness functions"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Population Size\n", "pSize = 500\n", "\n", "# Number of Generations\n", "numGen = 1000\n", "\n", "# Crossover Probability\n", "pCross = 0.9\n", "\n", "# Mutation Probability\n", "pMut = 0.1\n", "\n", "# Tournament Size\n", "tSize = 3"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Creating a DataFrame to store the normalized values of the orignal data with same column names\n", "normDataSet = pd.DataFrame(columns=dataSet.columns)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Normalizing the data using min-max normalization\n", "# normalized value = (value - min(attribute))/(max(attribute)-min(attribute))\n", "for i in range(30):\n", "   normDataSet[normDataSet.columns[i]]=(dataSet[dataSet.columns[i]]- min(dataSet[dataSet.columns[i]]))/(max(dataSet[dataSet.columns[i]])-min(dataSet[dataSet.columns[i]]))"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {}, "source": ["normDataSet['Class']=dataSet['Class']\n", "normDataSet"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Defining Conditional if\n", "# if first argument is negative, return the second, otherwise third argument\n", "# This is done to have an additional operator and avoiding having only smooth decision boundaries\n", "def cond_if(arg1, arg2, arg3):\n", "    return np.where(arg1<0,arg2,arg3)\n", "    \n", "# The function for protected division which returns 0 if the denominator is 0\n", "def p_div(x1,x2):\n", "    with np.errstate(divide='ignore',invalid='ignore'):\n", "        return np.where(np.abs(x2)>0.001, np.divide(x1,x2),0.)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Including the conditional if in the make functions of gp learn\n", "cif = gp.functions.make_function(function=cond_if, name = 'cif', arity=3)\n", "pdiv = gp.functions.make_function(function=p_div,name='pdiv',arity=2)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Creating the new Errors mean fitness function\n", "# f_errors_mean = (TP)/(TP+FN) + TN/(TN+FP) + (1-Err_mean_min)+(1-Err_mean_maj)\n", "# TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative, Err_mean_min = Mean Error Minority class, Err_mean_maj = Mean Error Majority Class\n", "def _fem(y,y_pred,w):\n", "    TP = len([x for x,z in zip(y_pred,y) if ((x<=0) and (z==0))])\n", "    TN = len([x for x,z in zip(y_pred,y) if ((x>0) and (z==1))])\n", "    FP = len([x for x,z in zip(y_pred,y) if ((x<=0) and (z==1))])\n", "    FN = len([x for x,z in zip(y_pred,y) if ((x>0) and (z==0))])\n", "    err_min = p_div(np.sum(np.abs(x) for x,z in zip(y_pred,y) if ((x>0) and (z==0))),FN)\n", "    err_maj = p_div(np.sum(np.abs(x) for x,z in zip(y_pred,y) if ((x<=0) and (z==1))),FP)   \n", "    f = p_div(TP,(TP + FN))+p_div(TN,(TN+FP))+(1-err_min)+(1-err_maj)\n", "    return f\n"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["fem = gp.fitness.make_fitness(_fem,greater_is_better=True)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["est_gp = genetic.SymbolicRegressor(metric=fem, population_size = pSize, generations = numGen, tournament_size = tSize, p_crossover = pCross, p_subtree_mutation=pMut, p_hoist_mutation=0.0,p_point_mutation=0.0,function_set=['add','sub','mul',pdiv,cif],verbose=1)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {}, "source": ["# Sampling 70% of the dataset randomly\n", "tot_train = normDataSet.sample(frac = 0.7)\n", "# Getting the gp-tree for the training data, first 30 columns as values and 31st as the Class Label\n", "est_gp.fit(tot_train.iloc[:,0:30],tot_train['Class'])"], "cell_type": "code", "outputs": []}, {"metadata": {}, "source": ["# Implementing the Twin Neural Networks"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# Work in progress, to be updated soon"], "cell_type": "code", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}