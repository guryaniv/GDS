{"cells":[{"metadata":{"_uuid":"adacf569c731767dbe22c5fc7579db86ee89effe"},"cell_type":"markdown","source":"# EDA with Fake Names"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pylab as plt\ntrain = pd.read_csv('../input/train.csv', parse_dates=[0])\ntest = pd.read_csv('../input/test.csv', parse_dates=[0])\nsubmit = pd.read_csv('../input/sample_submission.csv')\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c2b2f1e91728c8c27b00fa0fe1f90a826a438e6"},"cell_type":"markdown","source":"## Rename from number to something more fun\nNumbers are boring. Lets change the names of the items to make them more fun to refer to - and easier to remember!\n\n**WARNING** THESE ARE NOT THE REAL ITEM AND/OR STORE NAMES (unless I got extremely lucky). These names are just for fun.\n\n- Store Names found here: https://en.wikipedia.org/wiki/List_of_supermarket_chains_in_the_United_States\n    1. Albertsons\n    2. Ahold\n    3. Food Lion\n    4. Hannaford\n    5. Giant\n    6. Stop & Shop\n    7. Kroger\n    8. SpartanNash\n    9. SuperValu\n    10. Walmart\n\n- Items taken from here: https://www.webmd.com/food-recipes/guide/grocery-list#1\n"},{"metadata":{"trusted":true,"_uuid":"b39a90c376b734eafbde6d3276ed1722ab8e9ddd"},"cell_type":"code","source":"fake_store_names = {1: 'Albertsons', 2: 'Ahold', 3: 'Food_Lion', 4: 'Hannaford',\n                    5: 'Giant', 6: 'Stop_n_Shop', 7: 'Kroger', 8: 'SpartanNash',\n                    9: 'SuperValu', 10: 'Walmart'}\n\nfake_items = {1:'Apples', 2:'Bacon', 3:'Bagles', 4:'Beans', 5:'Beer', 6:'Bread',\n              7:'Carrots', 8:'Cheese', 9:'Chips', 10:'Coffee', 11:'Cream', \n              12:'Egg', 13:'Fish', 14:'Foil', 15:'Granola Bars', 16:'Grapes',\n              17:'Ham', 18:'Honey', 19:'Ice Cream', 20:'Ketchup', 21:'Kielbasa',\n              22:'Lemons', 23:'Lettuce', 24:'Margarine', 25:'Mayonnaise', 26:'Milk',\n              27:'Mushrooms', 28:'Mustard', 29:'Oranges', 30:'Paper Towles',\n              31:'Pasta', 32:'Peanut Butter', 33:'Pears', 34:'Pizza', 35:'Plastic Wrap',\n              36:'Potatoes', 37:'Pretzels', 38:'Ribs', 39:'Rice', 40:'Salami', \n              41:'Salsa', 42:'Salt', 43:'Sausage', 44:'Soda', 45:'Soup', 46:'Sugar',\n              47:'Tuna', 48:'Turkey', 49:'Waffles', 50:'Yoghurt'}\n\ntrain['store_name'] = train['store'].replace(fake_store_names)\ntrain['item_name'] = train['item'].replace(fake_items)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a6dcbd5ccccfca91dae1d4126d55819fd8f7748"},"cell_type":"markdown","source":"## Plot each item, scroll through and visually inspect for trends"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"db9bba55f197ef601103b9aaffff077d04e22718"},"cell_type":"code","source":"grouped = train.groupby(by=['item_name'])\nfor i, d in grouped:\n    myplot = d.set_index('date').groupby('store_name')['sales'] \\\n        .plot(figsize=(15,2), style='.', title=str(i), legend=False)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9a265ea363561bda85235e1ca1a36332fae76c0"},"cell_type":"markdown","source":"# Plot Year over Year"},{"metadata":{"trusted":true,"_uuid":"aeb11cae7eccf25de952ca1cde6c603c53e1be63"},"cell_type":"code","source":"def plot_year_over_year(item, store):\n    sample = train.loc[(train['store'] == store) & (train['item'] == item)].set_index('date')\n    pv = pd.pivot_table(sample, index=sample.index.month, columns=sample.index.year,\n                        values='sales', aggfunc='sum')\n    ax = pv.plot(figsize=(15,3), title=fake_store_names[store] + ' - ' + fake_items[item])\n    ax.set_xlabel(\"Month\")\nplot_year_over_year(1, 1)\nplot_year_over_year(1, 2)\nplot_year_over_year(20, 5)\nplot_year_over_year(20, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a00b6babc25abd8784db269b4163494f0459adce"},"cell_type":"markdown","source":"# Plot Day of Week"},{"metadata":{"trusted":true,"_uuid":"acec76b87564e1e2cb9eb06927f9381281eb890d"},"cell_type":"code","source":"def plot_year_over_year_dow(item, store):\n    sample = train.loc[(train['store'] == store) & (train['item'] == item)].set_index('date')\n    pv = pd.pivot_table(sample, index=sample.index.weekday, columns=sample.index.year,\n                        values='sales', aggfunc='sum')\n    ax = pv.plot(figsize=(15,3), title=fake_store_names[store] + ' - ' + fake_items[item])\n    ax.set_xlabel(\"Day of Week\")\nplot_year_over_year_dow(1, 1)\nplot_year_over_year_dow(1, 2)\nplot_year_over_year_dow(20, 5)\nplot_year_over_year_dow(20, 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54b8e877a9a849267a49349154a2ca2852ae0010"},"cell_type":"markdown","source":"# Time Series Clustering"},{"metadata":{"trusted":true,"_uuid":"ba68c2319b6d3c931e3afea2b94e5d08649ab7f2"},"cell_type":"code","source":"# Data prep\ntrain['store_item'] = train['store_name'] + '-' + train['item_name']\ntrain['store_item_mean'] = train.groupby('store_item')['sales'].transform('mean')\ntrain['deviation_from_storeitem_mean'] = train['sales'] - train['store_item_mean']\ntrain['dev_rolling'] = train.groupby('store_item')['deviation_from_storeitem_mean'].rolling(30).mean().reset_index()['deviation_from_storeitem_mean']\ntrain_pivoted = train.pivot(index='store_item', columns='date', values='sales')\ntrain_pivoted.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03625a7e5ae8a952661bacd162d3fb77d87ff0f5"},"cell_type":"code","source":"deviation_pivot = train.pivot(index='store_item', columns='date', values='dev_rolling')\ndeviation_pivot = deviation_pivot.dropna(axis=1)\ndeviation_pivot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64776f9dd5fd614d9e8159a15b616850c0a72ae3"},"cell_type":"code","source":"# Example from here:\n# https://stackoverflow.com/questions/34940808/hierarchical-clustering-of-time-series-in-python-scipy-numpy-pandas\n    \nimport scipy.cluster.hierarchy as hac\nfrom scipy import stats\n# Here we use spearman correlation\ndef my_metric(x, y):\n    r = stats.pearsonr(x, y)[0]\n    return 1 - r # correlation to distance: range 0 to 2\n\nZ = hac.linkage(deviation_pivot, method='single', metric=my_metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32e5371b2e66c231a8261c9dd21bf9b8f69ca989"},"cell_type":"code","source":"from scipy.cluster.hierarchy import fcluster\n\ndef print_clusters(deviation_pivot, Z, k, plot=False):\n    # k Number of clusters I'd like to extract\n    results = fcluster(Z, k, criterion='maxclust')\n\n    # check the results\n    s = pd.Series(results)\n    clusters = s.unique()\n\n    for c in clusters:\n        cluster_indeces = s[s==c].index\n        print(\"Cluster %d number of entries %d\" % (c, len(cluster_indeces)))\n        if plot:\n            deviation_pivot.T.iloc[:,cluster_indeces].plot()\n            plt.show()\n\nprint_clusters(deviation_pivot, Z, 5, plot=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a43ad84dd0a1e8f4d80dcfd8fc93931236236c6"},"cell_type":"markdown","source":"# KMeans Clustering"},{"metadata":{"trusted":true,"_uuid":"8c5dadf8ade44afe62de290496f42f84c9320bf2"},"cell_type":"code","source":"from sklearn.cluster import KMeans\nclust = KMeans()\ndeviation_pivot['cluster'] = clust.fit_predict(deviation_pivot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6f756f19c15251eb40f95f7a5add2b7ef93799b"},"cell_type":"code","source":"deviation_pivot.T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eab1894e508a5022bb4016403dc4873b913c0c0e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}