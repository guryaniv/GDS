{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.4", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}}, "nbformat": 4, "cells": [{"source": ["# Data reading"], "cell_type": "markdown", "metadata": {"_uuid": "0359f1c686397bc52cbb38393ab6d04c74f2267b", "_cell_guid": "5dd5d0cc-e7a4-482f-9a37-f1ad8880e599"}}, {"source": ["%matplotlib inline\n", "from matplotlib import pyplot as plt\n", "import pandas as pd\n", "import numpy as np\n", "import seaborn as sns\n", "from nltk.tokenize import wordpunct_tokenize\n", "from nltk.stem.snowball import EnglishStemmer\n", "from nltk.stem import WordNetLemmatizer\n", "from functools import lru_cache\n", "from tqdm import tqdm as tqdm\n", "from sklearn.metrics import log_loss\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.pipeline import Pipeline\n", "from scipy import sparse"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "032617e230e6d70f8d56bc77d8839c6235411201", "_cell_guid": "c8d8555e-a045-4615-b01f-8acd77af2400", "collapsed": true}, "execution_count": 1}, {"source": ["train = pd.read_csv('../input/train.csv')\n", "train.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "23e1665eaddab6e6273d2cdca9001386e918b361", "_cell_guid": "fed5896b-4c49-4fc6-a7a2-221c4769dde9"}, "execution_count": 2}, {"source": ["train['comment_text'] = train['comment_text'].fillna('nan')"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "609ddd0d9bdf50012fa57a9f33bcdb93effc9a39", "_cell_guid": "2ea66e7b-fdad-4bac-94d3-da8dcd9aa1ac", "collapsed": true}, "execution_count": 4}, {"source": ["test = pd.read_csv('../input/test.csv')\n", "test.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "2c17f0326289dcecac1bc27e677cf60a2637a4a3", "_cell_guid": "027d7a98-ecae-4c9f-9781-24f370a62a5e"}, "execution_count": 5}, {"source": ["test['comment_text'] = test['comment_text'].fillna('nan')"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "0798606a5475744a50534ad040d16e212221095d", "_cell_guid": "c8a8db93-5427-410f-a1c7-7925b360523c", "collapsed": true}, "execution_count": 6}, {"source": ["submission = pd.read_csv('../input/sample_submission.csv')\n", "submission.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "1d854336015dec939acd711eece59f9cd073a013", "_cell_guid": "45bf9df5-f4d0-46f2-914d-81dfa99c5ba5"}, "execution_count": 7}, {"source": ["# Basic analysis\n", "We have multilabel classification task. So let's check proportion of each label:"], "cell_type": "markdown", "metadata": {"_uuid": "5e779c2dedc6b0f26bc1acb1cb61068e0993c021", "_cell_guid": "b8a43edd-30fe-4ef7-be13-ccc465f1f22c"}}, {"source": ["for label in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']:\n", "    print(label, (train[label] == 1.0).sum() / len(train))"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "c84337c7b285de1a82cbf9b057b62171c06fbb4c", "_cell_guid": "e53562a3-9dd9-4550-a545-ecb27ff6e2c5"}, "execution_count": 8}, {"source": ["and correlation between target variables (maybe we'l could build some kind of hierarchy classification or something like it)."], "cell_type": "markdown", "metadata": {"_uuid": "0aca9b0ee990724bdc48c263914adf2a6fec0126", "_cell_guid": "09f6ed4a-9690-4d7c-abd7-038018eb56d3"}}, {"source": ["train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].corr()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "312210b20caa443bc92881cfde50a93540093936", "_cell_guid": "3d4ba7eb-54fc-4d9b-8b38-22c83868ce3c"}, "execution_count": 9}, {"source": ["# Text postprocessing\n", "\n", "I'll try models with:\n", "- text as is\n", "- stemmed text\n", "- lemmatized text"], "cell_type": "markdown", "metadata": {"_uuid": "c1e6613d05570503af75068afb387caaad2a4a99", "_cell_guid": "6723e986-3e8f-4257-94a0-4b93ba7ccf51"}}, {"source": ["stemmer = EnglishStemmer()\n", "\n", "@lru_cache(30000)\n", "def stem_word(text):\n", "    return stemmer.stem(text)\n", "\n", "\n", "lemmatizer = WordNetLemmatizer()\n", "\n", "@lru_cache(30000)\n", "def lemmatize_word(text):\n", "    return lemmatizer.lemmatize(text)\n", "\n", "\n", "def reduce_text(conversion, text):\n", "    return \" \".join(map(conversion, wordpunct_tokenize(text.lower())))\n", "\n", "\n", "def reduce_texts(conversion, texts):\n", "    return [reduce_text(conversion, str(text))\n", "            for text in tqdm(texts)]"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "d66ab0611d7903b3569c479dd928763078d73be6", "_cell_guid": "acde9eca-f73a-489b-a1e6-958f8f9e3f95", "collapsed": true}, "execution_count": 10}, {"source": ["train['comment_text_stemmed'] = reduce_texts(stem_word, train['comment_text'])\n", "test['comment_text_stemmed'] = reduce_texts(stem_word, test['comment_text'])\n", "train['comment_text_lemmatized'] = reduce_texts(lemmatize_word, train['comment_text'])\n", "test['comment_text_lemmatized'] = reduce_texts(lemmatize_word, test['comment_text'])"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "ca6fbd9b79c406d4ce52984532c9b88eecdb8742", "_cell_guid": "bf68cf71-17f5-4636-aef7-524a17f98856"}, "execution_count": 11}, {"source": ["train.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "ce9988ddbf0efc7ca6cbe1b5619e0a119f191ee8", "_cell_guid": "aae35ff5-0d66-4cb9-82e8-0f2ccf168f8f"}, "execution_count": 14}, {"source": ["test.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "1c59d1e3ff66e37cc15a6edd1fa202e575792312", "_cell_guid": "a4c64f6e-3703-4e8f-aac3-561b4a329ffa"}, "execution_count": 15}, {"source": ["# Validation\n", "\n", "Our metric is collumn-average of collumn log_loss values. So let's define custom metric based on binary log loss and define cross-validation function:"], "cell_type": "markdown", "metadata": {"_uuid": "c81b72ec6de3b86280ff32c665103e3a144f02d4", "_cell_guid": "c1715403-26ee-4531-8eca-8357ebd8b202"}}, {"source": ["def metric(y_true, y_pred):\n", "    assert y_true.shape == y_pred.shape\n", "    columns = y_true.shape[1]\n", "    column_losses = []\n", "    for i in range(0, columns):\n", "        column_losses.append(log_loss(y_true[:, i], y_pred[:, i]))\n", "    return np.array(column_losses).mean()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "863c73537f29824bd19cc530a7c5b25d1b0066b5", "_cell_guid": "8901a23a-9307-4360-85da-b86fa3ea05af", "collapsed": true}, "execution_count": 16}, {"source": ["## Cross-validation\n", "\n", "I don't found quickly a way to stratified split for multilabel case.\n", "\n", "So I used next way for stratified splitting:\n", "\n", "- define ordered list of all possible label combinations. E.g.\n", "\n", "    - 0 = [\"toxic\"=0, \"severe_toxic\"=0, \"obscene\"=0, \"threat\"=0, \"insult\"=0, \"identity_hate\"=0]\n", "    - 1 = [\"toxic\"=0, \"severe_toxic\"=0, \"obscene\"=0, \"threat\"=0, \"insult\"=1, \"identity_hate\"=0]\n", "    - 2 = [\"toxic\"=0, \"severe_toxic\"=0, \"obscene\"=0, \"threat\"=0, \"insult\"=1, \"identity_hate\"=1]\n", "\n", "- for each row replace label combination with combination index \n", "- use StratifiedKFold on this\n", "- train and test model by train/test indices from StratifiedKFold\n", "\n", "Basic idea is next:\n", "- we can present label combination as class for multiclass classification - at least for some cases\n", "- we can stratified split by combination indices\n", "    - so in each split distribution of combination indices will be similar to full set\n", "    - so source label distribution also will be similar\n", "    \n", "But I don't sure that all my assumpions are fully correct - at least, for common case."], "cell_type": "markdown", "metadata": {"_uuid": "1be09a4b666a18d411ce5e4d302c22fd871d0d36", "_cell_guid": "fe62a951-1d2e-40e7-bcf2-783cc104dd9a"}}, {"source": ["def cv(model, X, y, label2binary, n_splits=3):\n", "    def split(X, y):\n", "        return StratifiedKFold(n_splits=n_splits).split(X, y)\n", "    \n", "    def convert_y(y):\n", "        new_y = np.zeros([len(y)])\n", "        for i, val in enumerate(label2binary):\n", "            idx = (y == val).max(axis=1)\n", "            new_y[idx] = i\n", "        return new_y\n", "    \n", "    X = np.array(X)\n", "    y = np.array(y)\n", "    scores = []\n", "    for train, test in tqdm(split(X, convert_y(y)), total=n_splits):\n", "        fitted_model = model(X[train], y[train])\n", "        scores.append(metric(y[test], fitted_model(X[test])))\n", "    return np.array(scores)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "5d0aaafc562f06ee8194668781180d4f07773653", "_cell_guid": "7c4a3e83-6dc6-420b-a8f0-4f4c617034bf", "collapsed": true}, "execution_count": 17}, {"source": ["Let's define possible label combinations:"], "cell_type": "markdown", "metadata": {"_uuid": "ca12d3e7a55daec036b96a957ef80d3b5285554c", "_cell_guid": "648ec9f8-c9c7-4ac3-b011-56fa2bbb35fd"}}, {"source": ["label2binary = np.array([\n", "    [0, 0, 0, 0, 0, 0],\n", "    [0, 0, 0, 0, 0, 1],\n", "    [0, 0, 0, 0, 1, 0],\n", "    [0, 0, 0, 0, 1, 1],\n", "    [0, 0, 0, 1, 0, 0],\n", "    [0, 0, 0, 1, 0, 1],\n", "    [0, 0, 0, 1, 1, 0],\n", "    [0, 0, 0, 1, 1, 1],\n", "    [0, 0, 1, 0, 0, 0],\n", "    [0, 0, 1, 0, 0, 1],\n", "    [0, 0, 1, 0, 1, 0],\n", "    [0, 0, 1, 0, 1, 1],\n", "    [0, 0, 1, 1, 0, 0],\n", "    [0, 0, 1, 1, 0, 1],\n", "    [0, 0, 1, 1, 1, 0],\n", "    [0, 0, 1, 1, 1, 1],\n", "    [0, 1, 0, 0, 0, 0],\n", "    [0, 1, 0, 0, 0, 1],\n", "    [0, 1, 0, 0, 1, 0],\n", "    [0, 1, 0, 0, 1, 1],\n", "    [0, 1, 0, 1, 0, 0],\n", "    [0, 1, 0, 1, 0, 1],\n", "    [0, 1, 0, 1, 1, 0],\n", "    [0, 1, 0, 1, 1, 1],\n", "    [0, 1, 1, 0, 0, 0],\n", "    [0, 1, 1, 0, 0, 1],\n", "    [0, 1, 1, 0, 1, 0],\n", "    [0, 1, 1, 0, 1, 1],\n", "    [0, 1, 1, 1, 0, 0],\n", "    [0, 1, 1, 1, 0, 1],\n", "    [0, 1, 1, 1, 1, 0],\n", "    [0, 1, 1, 1, 1, 1],\n", "    [1, 0, 0, 0, 0, 0],\n", "    [1, 0, 0, 0, 0, 1],\n", "    [1, 0, 0, 0, 1, 0],\n", "    [1, 0, 0, 0, 1, 1],\n", "    [1, 0, 0, 1, 0, 0],\n", "    [1, 0, 0, 1, 0, 1],\n", "    [1, 0, 0, 1, 1, 0],\n", "    [1, 0, 0, 1, 1, 1],\n", "    [1, 0, 1, 0, 0, 0],\n", "    [1, 0, 1, 0, 0, 1],\n", "    [1, 0, 1, 0, 1, 0],\n", "    [1, 0, 1, 0, 1, 1],\n", "    [1, 0, 1, 1, 0, 0],\n", "    [1, 0, 1, 1, 0, 1],\n", "    [1, 0, 1, 1, 1, 0],\n", "    [1, 0, 1, 1, 1, 1],\n", "    [1, 1, 0, 0, 0, 0],\n", "    [1, 1, 0, 0, 0, 1],\n", "    [1, 1, 0, 0, 1, 0],\n", "    [1, 1, 0, 0, 1, 1],\n", "    [1, 1, 0, 1, 0, 0],\n", "    [1, 1, 0, 1, 0, 1],\n", "    [1, 1, 0, 1, 1, 0],\n", "    [1, 1, 0, 1, 1, 1],\n", "    [1, 1, 1, 0, 0, 0],\n", "    [1, 1, 1, 0, 0, 1],\n", "    [1, 1, 1, 0, 1, 0],\n", "    [1, 1, 1, 0, 1, 1],\n", "    [1, 1, 1, 1, 0, 0],\n", "    [1, 1, 1, 1, 0, 1],\n", "    [1, 1, 1, 1, 1, 0],\n", "    [1, 1, 1, 1, 1, 1],\n", "])"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "a775bd7990da167fd6f923263e88a3cf143cbfc6", "_cell_guid": "0c1d97b8-67e2-464c-90c1-62c19f182920", "collapsed": true}, "execution_count": 18}, {"source": ["# Dummy model\n", "\n", "Let's build dummy model that always return 0.5 and compare score on cross-validation with test-set public leatherboard \"All 0.5s Benchmark\" (score - 0.693)"], "cell_type": "markdown", "metadata": {"_uuid": "0117807ff37c2807c929e870730c7ae42fbb95bd", "_cell_guid": "c0e974ab-af1a-40e4-b839-1592b118048c"}}, {"source": ["def dummy_model(X, y):\n", "    def _predict(X):\n", "        return np.ones([X.shape[0], 6]) * 0.5\n", "    \n", "    return _predict\n", "\n", "cv(dummy_model,\n", "   train['comment_text'],\n", "   train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n", "   label2binary)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "b167c4e627cc3629ba0c39e8f45f068f8788601b", "_cell_guid": "fe679495-7f7e-4416-ba32-d2dbd3aa07cc"}, "execution_count": 19}, {"source": ["seems like we built metric correctly, so let's go to baseline building\n", "\n", "# Baseline (binary logistic regression over word-based tf-idf)\n", "\n", "Let's build model that:\n", "- compute tf-idf for given train texts\n", "- train 6 logistic regressions (one for each label)\n", "- compute tf-idf on test texts\n", "- compute probability of \"1\" class for all 6 regressions"], "cell_type": "markdown", "metadata": {"_uuid": "45ddeeb39d8252016c019add0ed24b128435cb56", "_cell_guid": "3297eb2e-66db-4d1e-9a28-f83484f4b0b2"}}, {"source": ["def regression_baseline(X, y):\n", "    tfidf = TfidfVectorizer()\n", "    X_tfidf = tfidf.fit_transform(X)\n", "    columns = y.shape[1]\n", "    regressions = [\n", "        LogisticRegression().fit(X_tfidf, y[:, i])\n", "        for i in range(columns)\n", "    ]\n", "    \n", "    def _predict(X):\n", "        X_tfidf = tfidf.transform(X)\n", "        predictions = np.zeros([len(X), columns])\n", "        for i, regression in enumerate(regressions):\n", "            regression_prediction = regression.predict_proba(X_tfidf)\n", "            predictions[:, i] = regression_prediction[:, regression.classes_ == 1][:, 0]\n", "        return predictions\n", "    \n", "    return _predict"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "3adcd67349e34f957bd974886457b21f8c00a1bc", "_cell_guid": "f2932f23-6129-4082-90d3-09238fb2b6b7", "collapsed": true}, "execution_count": 20}, {"source": ["Now let's check model on source texts/stemmed texts/lemmatized texts"], "cell_type": "markdown", "metadata": {"_uuid": "aa6a106976a09922d3b94c588cbc1db7da0ccce7", "_cell_guid": "c4783bb9-9cf4-4758-8a74-7008c20c5fa0"}}, {"source": ["cv(regression_baseline,\n", "   train['comment_text'],\n", "   train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n", "   label2binary)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "22b4fab009572ec1c24e66126d59930e92f6c820", "_cell_guid": "9b13057c-323f-497b-bb56-96036a73700b"}, "execution_count": 21}, {"source": ["cv(regression_baseline,\n", "   train['comment_text_stemmed'],\n", "   train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n", "   label2binary)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "7bf420163021df472b63071e6c14f697a2e8f2eb", "_cell_guid": "84882d30-8883-450b-b5f3-227b737586e1"}, "execution_count": 22}, {"source": ["cv(regression_baseline,\n", "   train['comment_text_lemmatized'],\n", "   train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n", "   label2binary)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "780c3c85e55675a114635b32f54bf8a50759072b", "_cell_guid": "ff732007-2228-47be-96d2-479ffba58862"}, "execution_count": 23}, {"source": ["As you can see - this baseline gives best score on stemmed texts.\n", "Anyway - let's  try to add character-level features:\n", "\n", "# Regressions over tfidf over words and character n-grams\n", "\n", "Let's build model that:\n", "- compute tfidf of words of stemmed texts\n", "- compute tfidf of character n-grams from source text\n", "- train/predict regressions on computed tfidf-s."], "cell_type": "markdown", "metadata": {"_uuid": "b5dfd28d9d63b0ac8648af712d91479c6c1a7da0", "_cell_guid": "a94e8b0e-751d-44f1-a6d2-e56cd8fd2d6e"}}, {"source": ["def regression_wordchars(X, y):\n", "    tfidf_word = TfidfVectorizer()\n", "    X_tfidf_word = tfidf_word.fit_transform(X[:, 1])\n", "    tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(1, 3), lowercase=False)\n", "    X_tfidf_char = tfidf_char.fit_transform(X[:, 0])\n", "    X_tfidf = sparse.hstack([X_tfidf_word, X_tfidf_char])\n", "    \n", "    columns = y.shape[1]\n", "    regressions = [\n", "        LogisticRegression().fit(X_tfidf, y[:, i])\n", "        for i in range(columns)\n", "    ]\n", "    \n", "    def _predict(X):\n", "        X_tfidf_word = tfidf_word.transform(X[:, 1])\n", "        X_tfidf_char = tfidf_char.transform(X[:, 0])\n", "        X_tfidf = sparse.hstack([X_tfidf_word, X_tfidf_char])\n", "        predictions = np.zeros([len(X), columns])\n", "        for i, regression in enumerate(regressions):\n", "            regression_prediction = regression.predict_proba(X_tfidf)\n", "            predictions[:, i] = regression_prediction[:, regression.classes_ == 1][:, 0]\n", "        return predictions\n", "    \n", "    return _predict"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "b165a7eb2bc448c7d1fa191e4579a51fd1a7eced", "_cell_guid": "8bd7fa08-43f0-46f9-8870-499174905a67", "collapsed": true}, "execution_count": 25}, {"source": ["cv(regression_wordchars,\n", "   train[['comment_text', 'comment_text_stemmed']],\n", "   train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']],\n", "   label2binary)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "e268457a05af6da5da8e4b6a2240252f22b5d12b", "_cell_guid": "47b8f303-ed0b-4dd9-998f-947d708249ac"}, "execution_count": 26}, {"source": ["# Prediction\n", "\n", "Let's use our best model - regression over word&chars tfidf to build submission:"], "cell_type": "markdown", "metadata": {"_uuid": "695aca3ecc8f779222b5f2415c6b81b6920d740d", "_cell_guid": "f9912856-a38c-4368-84ca-a66645159941"}}, {"source": ["%%time\n", "model = regression_wordchars(np.array(train[['comment_text', 'comment_text_stemmed']]),\n", "                             np.array(train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']]))"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "c3a7529e9153e2855f2150f708e679540ec1df3a", "_cell_guid": "968580ed-eb6a-4c20-9c98-4991c159a4fa"}, "execution_count": 27}, {"source": ["%%time\n", "prediction = model(np.array(test[['comment_text', 'comment_text_stemmed']]))"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "448dc9b6f3282119059522962b9a8153de9757aa", "_cell_guid": "056ee24d-4a16-41c0-bdf9-19097bfa6868"}, "execution_count": 28}, {"source": ["for i, label in enumerate(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']):\n", "    submission[label] = prediction[:, i]\n", "submission.head()"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "e21dc7e6f3049cd7bc5dc3fda34f27c4f830fddf", "_cell_guid": "7f7f873d-b29c-4cd0-95d7-8bf820f77cf4"}, "execution_count": 30}, {"source": ["submission.to_csv('output.csv', index=None)"], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "3c8a093eb8ddc8102039bfc0536cffd04eac443c", "_cell_guid": "f0aa24bd-de50-4e5d-b739-4f7245037522", "collapsed": true}, "execution_count": 29}, {"source": [], "cell_type": "code", "outputs": [], "metadata": {"_uuid": "66c51ff3cde21d04365f57e98167684b930b2157", "_cell_guid": "18b224db-0c66-4438-92a2-1221f5e43989", "collapsed": true}, "execution_count": null}]}