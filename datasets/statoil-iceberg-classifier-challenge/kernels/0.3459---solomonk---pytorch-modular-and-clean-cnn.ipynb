{"nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["# PyTorch GPU based CNN using BCELoss and torchvision import transforms\n", "\n", "This is my fifth generation PyTorch script which includes many improvements over the previous versions. \n", "The previous versions are here:\n", "\n", "- https://www.kaggle.com/solomonk/pytorch-gpu-cnn-bceloss-0-2198-lb\n", "\n", "- https://www.kaggle.com/solomonk/pytorch-gpu-based-cnn-bceloss-with-predictions\n", " \n", "Improvements include:\n", "1. Automatic calculation of the FC layer size\n", "2. A nice fit() methood which also does validation (but albeit is slower) \n", "3. Saving and loading the CNN model \n", "\n", "Todo:\n", "1. Add image transforms, see:  https://discuss.pytorch.org/t/applying-an-image-transform-data-augumentations-to-a-2d-floattensor-pil/9359 \n", "\n", "Comments are welocmed, \n", "\n", "## Updates \n", "- Update 2/11/2017:\n", "Added IcebergCustomDataSet and torchvision  transforms using https://www.kaggle.com/supersp1234/tools-for-pytorch-transform\n", "\n"], "metadata": {"_uuid": "22e14672b9865f93dd3fd68b60cfe1714e875090", "_cell_guid": "531ab90a-d599-4696-888b-84c851179957"}}, {"outputs": [], "metadata": {"_uuid": "bb1dda3b60c8fbfbed8ed30ffba79f39e3812b06", "_cell_guid": "1c5adb34-239f-457a-9522-41c1b3fb9cdb"}, "cell_type": "code", "source": ["% reset -f\n", "import torch\n", "import sys\n", "import torch\n", "from torch.utils.data.dataset import Dataset\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torch import nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.autograd import Variable\n", "\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n", "\n", "print('__Python VERSION:', sys.version)\n", "print('__pyTorch VERSION:', torch.__version__)\n", "\n", "import numpy\n", "import numpy as np\n", "\n", "use_cuda = torch.cuda.is_available()\n", "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n", "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n", "Tensor = FloatTensor\n", "\n", "import pandas\n", "import pandas as pd\n", "\n", "import logging\n", "handler=logging.basicConfig(level=logging.INFO)\n", "lgr = logging.getLogger(__name__)\n", "%matplotlib inline\n", "\n", "# !pip install psutil\n", "import psutil\n", "import os\n", "def cpuStats():\n", "        print(sys.version)\n", "        print(psutil.cpu_percent())\n", "        print(psutil.virtual_memory())  # physical memory usage\n", "        pid = os.getpid()\n", "        py = psutil.Process(pid)\n", "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n", "        print('memory GB:', memoryUse)\n", "\n", "cpuStats()"], "execution_count": 1}, {"cell_type": "markdown", "source": ["# Concatenate and Reshape\n", "Here we load the data and then combine the two bands and recombine them into a single image/tensor for training"], "metadata": {"_uuid": "d4d08af6a7165ce1b0eba40d3b784a82b2f283ac", "_cell_guid": "f5c415ae-3ab7-4042-ad9c-f843124823cf"}}, {"outputs": [], "metadata": {"_uuid": "196c3599b40df0f044c90371bb732ce7e5424abd", "_cell_guid": "e7258c0a-2d47-4bdf-b1cf-ac7ab9b542ee"}, "cell_type": "code", "source": ["# Data params\n", "TARGET_VAR= 'target'\n", "BASE_FOLDER = '../input/'\n", "data = pd.read_json(BASE_FOLDER + '/train.json')\n", "\n", "data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n", "data['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n", "data['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n", "\n", "print (type(data))\n", "\n", "# Suffle\n", "import random\n", "from datetime import datetime\n", "random.seed(datetime.now())\n", "from sklearn.utils import shuffle\n", "# data = shuffle(data) # otherwise same validation set each time!\n", "# data= data.reindex(np.random.permutation(data.index))\n", "\n", "# data= data.reindex(np.random.permutation(data.index))\n", "# data = shuffle(data) # otherwise same validation set each time!\n", "\n", "band_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\n", "band_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\n", "full_img = np.stack([band_1, band_2], axis=1)\n", "\n", "\n", "from torch.utils.data import TensorDataset, DataLoader\n", "from torch.utils.data.sampler import RandomSampler\n", "import cv2 \n", "\n", "batch_size=64"], "execution_count": 2}, {"cell_type": "markdown", "source": ["# Custom PyTorch Dataset to enable applying image Transforms\n", "- Since we have a non regular image type, a custom Dataset has to be written (adapted from:https://www.kaggle.com/supersp1234/tools-for-pytorch-transform and https://www.kaggle.com/heyt0ny/pytorch-custom-dataload-with-augmentaion)\n", "- This is required for enrichment \n"], "metadata": {"_uuid": "ee42c63c3bd4d0968680ed0c2de108ba7d9266cf", "_cell_guid": "886386d4-ef8e-40e8-9e46-e5a0f92fe151"}}, {"outputs": [], "metadata": {"_uuid": "334fff5c5b44f8136cc6e195a59cc2b6078f4a9c", "_cell_guid": "92eed319-abf5-4035-96ac-93c1f8c906a4"}, "cell_type": "code", "source": ["from torch.utils.data import Dataset, DataLoader\n", "from torchvision import transforms, utils,datasets, models\n", "import random\n", "import PIL\n", "from PIL import Image, ImageOps\n", "import math\n", "import torch.nn.functional as F\n", "import warnings\n", "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n", "\n", "class IcebergCustomDataSet(Dataset):\n", "    \"\"\"total dataset.\"\"\"\n", "\n", "    def __init__(self, data, labels,transform=None):\n", "        self.data= data\n", "        self.labels = labels\n", "        self.transform = transform        \n", "\n", "    def __len__(self):\n", "        return len(self.labels)\n", "\n", "    def __getitem__(self, idx):\n", "        sample = {'image': self.data[idx,:,:,:], 'labels': np.asarray([self.labels[idx]])}\n", "        if self.transform:\n", "            sample = self.transform(sample)\n", "\n", "        return sample\n", "\n", "class ToTensor(object):\n", "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n", "    def __call__(self, sample):\n", "        image, labels = sample['image'], sample['labels']\n", "        # swap color axis because\n", "        # numpy image: H x W x C\n", "        # torch image: C X H X W\n", "        #image = image.transpose((2, 0, 1))\n", "        image = image.astype(float)/255\n", "        return {'image': torch.from_numpy(image.copy()).float(),\n", "                'labels': torch.from_numpy(labels).float()\n", "               }\n", "class RandomHorizontalFlip(object):\n", "    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n", "\n", "    def __call__(self, sample):\n", "        \"\"\"\n", "        Args:\n", "            img (PIL.Image): Image to be flipped.\n", "\n", "        Returns:\n", "            PIL.Image: Randomly flipped image.\n", "        \"\"\"\n", "        image, labels = sample['image'], sample['labels']\n", "        \n", "        if random.random() < 0.5:\n", "            image=np.flip(image,1)\n", "        \n", "        return {'image': image, 'labels': labels}\n", "    \n", "class RandomVerticallFlip(object):\n", "    \"\"\"Horizontally flip the given PIL.Image randomly with a probability of 0.5.\"\"\"\n", "\n", "    def __call__(self, sample):     \n", "        image, labels = sample['image'], sample['labels']\n", "        if random.random() < 0.5:\n", "            image=np.flip(image,0)\n", "        return {'image': image, 'labels': labels} \n", "\n", "class RandomTranspose(object):\n", "    def __call__(self, sample):     \n", "        image, labels = sample['image'], sample['labels']\n", "        if random.random() < 0.7: \n", "            image=np.transpose(image,0)\n", "        return {'image': image, 'labels': labels} \n", "\n", "class Normalize(object):   \n", "    def __init__(self, mean, std):\n", "        self.mean = mean\n", "        self.std = std\n", "\n", "    def __call__(self, tensor):      \n", "        # TODO: make efficient\n", "        img=tensor['image'].float()\n", "        for t, m, s in zip(img, self.mean, self.std):\n", "            t.sub_(m).div_(s)\n", "        return {'image': img, 'labels': tensor['labels']}  \n", "\n", "from random import randrange    \n", "random.seed(datetime.now()) # re seed \n", "\n", "X_train,X_val,y_train,y_val=train_test_split(full_img,data['is_iceberg'].values,\n", "                                                   test_size=0.33, \n", "                                                   random_state=randrange(50000))\n", "\n", "\n", "# val_dataset = IcebergCustomDataSet(X_val, y_val, transform=transforms.Compose([\n", "#                                                               ToTensor(), \n", "#                                                               ])) \n", "# train_dataset = IcebergCustomDataSet(X_train, y_train, transform=transforms.Compose([\n", "#                                                               ToTensor(), \n", "#                                                               ])) \n", "\n", "\n", "train_ds = IcebergCustomDataSet(X_train, y_train, transform=transforms.Compose([\n", "                                                              RandomHorizontalFlip(), \n", "                                                              RandomVerticallFlip(),\n", "                                                              \n", "                                                              ToTensor(), \n", "                                                              ])) \n", "\n", "val_dataset = IcebergCustomDataSet(X_val, y_val, \n", "                                transform=transforms.Compose([\n", "                                                              RandomHorizontalFlip(), \n", "                                                              RandomVerticallFlip(), \n", "                                                               \n", "                                                              ToTensor(), \n", "                                                              ])) \n", "\n", "train_loader = DataLoader(dataset=train_ds, batch_size=batch_size,\n", "                          shuffle=True, num_workers=1)\n", "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size,\n", "                          shuffle=True, num_workers=1)\n", "\n", "print (train_loader)\n", "print (val_loader)    "], "execution_count": 3}, {"cell_type": "markdown", "source": ["# Train/Validation split \n", "(Not currently in use old version that did not involve image transforms)"], "metadata": {"_uuid": "9d2e6d45a634d7d8ef386cced633790de459e08e", "_cell_guid": "07dc65a6-e81b-4fff-b557-330b3b1233eb"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "6682a80e31ec1ddf0887920fec8b86e6b91b8d06", "_cell_guid": "821d15f8-89c5-4a79-b6c2-cb87e2609673"}, "cell_type": "code", "source": ["# # Data params\n", "# TARGET_VAR= 'target'\n", "# BASE_FOLDER = '../input/'\n", "\n", "\n", "# data = pd.read_json(BASE_FOLDER + '/train.json')\n", "\n", "# data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n", "# data['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n", "# data['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n", "\n", "# # Suffle\n", "# import random\n", "# from datetime import datetime\n", "# random.seed(datetime.now())\n", "# # np.random.seed(datetime.now())\n", "# from sklearn.utils import shuffle\n", "# data = shuffle(data) # otherwise same validation set each time!\n", "# data= data.reindex(np.random.permutation(data.index))\n", "\n", "# band_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\n", "# band_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\n", "# full_img = np.stack([band_1, band_2], axis=1)\n", "\n", "# Convert the np arrays into the correct dimention and type\n", "# Note that BCEloss requires Float in X as well as in y\n", "def XnumpyToTensor(x_data_np):\n", "    x_data_np = np.array(x_data_np, dtype=np.float32)        \n", "    print(x_data_np.shape)\n", "    print(type(x_data_np))\n", "\n", "    if use_cuda:\n", "        lgr.info (\"Using the GPU\")    \n", "        X_tensor = (torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n", "    else:\n", "        lgr.info (\"Using the CPU\")\n", "        X_tensor = (torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n", "        \n", "    print((X_tensor.shape)) # torch.Size([108405, 29])\n", "    return X_tensor\n", "\n", "\n", "# Convert the np arrays into the correct dimention and type\n", "# Note that BCEloss requires Float in X as well as in y\n", "def YnumpyToTensor(y_data_np):    \n", "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n", "    print(y_data_np.shape)\n", "    print(type(y_data_np))\n", "\n", "    if use_cuda:\n", "        lgr.info (\"Using the GPU\")            \n", "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n", "        Y_tensor = (torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n", "    else:\n", "        lgr.info (\"Using the CPU\")        \n", "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n", "        Y_tensor = (torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n", "\n", "    print(type(Y_tensor)) # should be 'torch.cuda.FloatTensor'\n", "    print(y_data_np.shape)\n", "    print(type(y_data_np))    \n", "    return Y_tensor\n", "\n", "\n", "# #  Custom data loader\n", "\n", "# In[17]:\n", "\n", "# class FullTrainningDataset(torch.utils.data.Dataset):\n", "#     def __init__(self, full_ds, offset, length):\n", "#         self.full_ds = full_ds\n", "#         self.offset = offset\n", "#         self.length = length\n", "#         assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n", "#         super(FullTrainningDataset, self).__init__()\n", "        \n", "#     def __len__(self):        \n", "#         return self.length\n", "    \n", "#     def __getitem__(self, i):\n", "#         return self.full_ds[i+self.offset]\n", "    \n", "# validationRatio=0.22    \n", "\n", "# def trainTestSplit(dataset, val_share=validationRatio):\n", "#     val_offset = int(len(dataset)*(1-val_share))\n", "#     print (\"Offest:\" + str(val_offset))\n", "#     return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, \n", "#                                                                               val_offset, len(dataset)-val_offset)\n", "# batch_size=32\n", "\n", "# from torch.utils.data import TensorDataset, DataLoader\n", "\n", "# # train_imgs = torch.from_numpy(full_img_tr).float()\n", "# train_imgs=XnumpyToTensor (full_img)\n", "# train_targets = YnumpyToTensor(data['is_iceberg'].values)\n", "# dset_train = TensorDataset(train_imgs, train_targets)\n", "\n", "\n", "# train_ds, val_ds = trainTestSplit(dset_train)\n", "\n", "# train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=False,\n", "#                                             num_workers=1)\n", "# val_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=1)\n", "\n", "# print (train_loader)\n", "# print (val_loader)\n"], "execution_count": 4}, {"cell_type": "markdown", "source": ["# CNN"], "metadata": {"collapsed": true, "_uuid": "47ae7ccfed58965f8c7458a9d49aa164732faaca", "_cell_guid": "c2709d15-9a71-4a2d-ab22-de030dbd6fba"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "1b6fd083b9a2633746c966e5b54669d91a48bab5", "_cell_guid": "eb214f3c-33e1-4cfe-b8e6-dc785ee9350d"}, "cell_type": "code", "source": ["import torch\n", "import numpy as np\n", "from torch.utils.data import TensorDataset, DataLoader\n", "\n", "# See https://github.com/kimhc6028/forward-thinking-pytorch/blob/master/forward_thinking.py for a great example    \n", "# loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n", "# dropout = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n", "# See https://github.com/kimhc6028/forward-thinking-pytorch/blob/master/forward_thinking.py\n", "def cnnBlock(in_planes, out_planes,kernel_size=7, padding=2,pool_size=2):\n", "        conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,padding=padding)\n", "        bn   = torch.nn.BatchNorm2d(out_planes)\n", "        relu = torch.nn.LeakyReLU()        \n", "        pl   = torch.nn.MaxPool2d(pool_size,pool_size)\n", "        av   = torch.nn.AvgPool2d(pool_size,pool_size)\n", "#         dr   = torch.nn.Dropout(d_rate)\n", "        return nn.Sequential(conv, bn, relu,pl,av)\n", "                \n", "dropout = [0.65, 0.55, 0.30, 0.20, 0.10, 0.05]\n", "\n", "class CNNClassifier(torch.nn.Module):        \n", "    def __init__(self, img_size, img_ch, kernel_size, pool_size, n_out, padding):\n", "        super(CNNClassifier, self).__init__()\n", "        self.img_size = img_size\n", "        self.img_ch = img_ch\n", "        self.kernel_size = kernel_size\n", "        self.pool_size = pool_size\n", "        self.padding = padding\n", "        \n", "        self.n_out = n_out\n", "        self.sig=torch.nn.Sigmoid()\n", "        self.all_losses = []\n", "        self.val_losses = []  \n", "        self.cnn_features = []\n", "        self.layers = []\n", "        self.build_model()        \n", "#         print (self)\n", "    # end constructor\n", "        \n", "    def build_model(self):           \n", "        self.conv1=cnnBlock(self.img_ch, 16, kernel_size=self.kernel_size,padding=self.padding)        \n", "        self.conv2=cnnBlock(16, 32, kernel_size=5,padding=self.padding)\n", "        self.conv3=cnnBlock(32, 64, kernel_size=3,padding=self.padding)\n", "        \n", "        self.cnn_features = [self.conv1, \n", "                             self.conv2,\n", "                             self.conv3,\n", "                            ]                \n", "        self.fc = nn.Sequential(\n", "            nn.Linear(64, self.n_out),\n", "        )\n", "        \n", "        self.criterion = torch.nn.BCELoss()          \n", "        LR = 0.0005        \n", "        self.optimizer = torch.optim.Adam(self.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\n", "    # end method build_model\n", "\n", "    def forward(self, x):\n", "        for c in self.cnn_features:\n", "            x = (c(x))\n", "        x= self.shrink(x)\n", "        x= self.fc(x)\n", "        return self.sig(x)\n", "    # end method forward\n", "\n", "    def shrink(self, X):\n", "        return X.view(X.size(0), -1)\n", "    # end method flatten\n", "\n", "    def fit(self,loader, num_epochs, batch_size):               \n", "        self.train()\n", "        for epoch in range(num_epochs):\n", "            self.train()\n", "            print('Epoch {}'.format(epoch + 1))\n", "            print('*' * 5 + ':')\n", "            running_loss = 0.0\n", "            running_acc = 0.0            \n", "    \n", "            for i, dict_ in enumerate(loader):\n", "                images  = dict_['image']\n", "                target  = dict_['labels']\n", "#                 images, target=dict_\n", "#                 self.train()\n", "                inputs = torch.autograd.Variable(images)\n", "                labels = torch.autograd.Variable(target)                \n", "        \n", "                preds = self.forward(inputs)            # cnn output\n", "                loss = self.criterion(preds, labels)    # cross entropy loss\n", "                running_loss += loss.data[0] * labels.size(0)\n", "                self.optimizer.zero_grad()              # clear gradients for this training step\n", "                loss.backward()                         # backpropagation, compute gradients\n", "                self.optimizer.step()                   # apply gradients\n", "                preds = torch.max(preds, 1)[1].data.numpy().squeeze()\n", "                acc = (preds == target.numpy()).mean()\n", "                if (i+1) % 10 == 0:\n", "                    print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Acc: %.4f'\n", "                           %(epoch+1, num_epochs, i+1, \n", "                             int(len(train_ds)/batch_size), loss.data[0], acc)) \n", "                    \n", "            #save model\n", "            torch.save(self.state_dict(), './cnn.pth')\n", "            #Cross validation\n", "            self.LeavOneOutValidation(val_loader)            \n", "        torch.save(self.state_dict(), './cnn.pth')\n", "    # end method fit\n", "    \n", "    def LeavOneOutValidation(self, val_loader): \n", "        print ('Leave one out VALIDATION ...')\n", "        model = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n", "                            pool_size=pool_size, n_out=n_out, padding=padding)\n", "        # .. to load your previously training model:\n", "        model.load_state_dict(torch.load('./cnn.pth'))\n", "        val_losses = []\n", "        model.eval()\n", "        print (val_loader)\n", "        eval_loss = 0\n", "        eval_acc = 0\n", "        for data in val_loader:        \n", "            img  = data['image']\n", "            label  = data['labels']\n", "#             img, label=data\n", "            img = Variable(img, volatile=True)\n", "            label = Variable(label, volatile=True)\n", "\n", "            out = model(img)\n", "            loss = model.criterion(out, label)\n", "            eval_loss += loss.data[0] * label.size(0)\n", "\n", "        print('Leave one out VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset))))\n", "        val_losses.append(eval_loss / (len(val_dataset)))\n", "        print()    \n", "        \n", "    def gen_batch(self, arr, batch_size):\n", "        for i in range(0, len(arr), batch_size):\n", "            yield arr[i : i + batch_size]\n", "    # end method gen_batch\n", "    \n", "   \n", "    # end class CNNClassifier"], "execution_count": null}, {"cell_type": "markdown", "source": ["# Train"], "metadata": {"_uuid": "a86442e28d3d56f5784cbc150f4fdeceda59a390", "_cell_guid": "275ec299-3a7c-4ca7-b0f4-3a6b80299c8f"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "596302a7b101347cc51f2751bf8ce471b0cb3801", "_cell_guid": "d119aa1d-ff01-4c43-b940-82aa32207fe3"}, "cell_type": "code", "source": ["img_size = (75,75)\n", "img_ch = 2\n", "kernel_size = 7\n", "pool_size = 2\n", "padding=2\n", "n_out = 1\n", "n_epoch = 35\n", "\n", "if __name__ == '__main__':\n", "    cnn = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n", "                        pool_size=pool_size, n_out=n_out, padding=padding)\n", "    cnn.fit(train_loader,n_epoch, batch_size)\n", "#     cnn.evaluate(val_loader, batch_size=8)"], "execution_count": null}, {"cell_type": "markdown", "source": [], "metadata": {"_uuid": "c59a404fe0b1294f48a9cb79fbede5094a2c9b4a", "_cell_guid": "7051bf53-14cf-4811-80e5-ede71360e5de"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "c89f9b77c79ea740bcc39bce704a604f387ac4ca", "_cell_guid": "f091cb58-bd95-4d76-8b18-1cd2b471a0b6"}, "cell_type": "code", "source": ["from sklearn.cross_validation import train_test_split\n", "\n", "# def kFoldValidation(folds): \n", "#     print ('K FOLD VALIDATION ...')\n", "#     cnn = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n", "#                         pool_size=pool_size, n_out=n_out, padding=padding)\n", "#     # .. to load your previously training model:\n", "#     model.load_state_dict(torch.load('./cnn.pth'))\n", "#     val_losses = []\n", "#     model.eval()\n", "    \n", "#     for e in range(folds):\n", "#         print ('Fold:' + str(e))        \n", "#         data = pd.read_json('../input/train.json')        \n", "#         data['band_1'] = data['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n", "#         data['band_2'] = data['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n", "#         data['inc_angle'] = pd.to_numeric(data['inc_angle'], errors='coerce')\n", "#         band_1 = np.concatenate([im for im in data['band_1']]).reshape(-1, 75, 75)\n", "#         band_2 = np.concatenate([im for im in data['band_2']]).reshape(-1, 75, 75)\n", "#         full_img = np.stack([band_1, band_2], axis=1)\n", "                                \n", "#         X_train,X_val,y_train,y_val=train_test_split(full_img,data['is_iceberg'].values,\n", "#                                                    test_size=0.11, \n", "#                                                    random_state=randrange(3000))\n", "#         # Only need val set\n", "#         val_dataset_kfold = IcebergCustomDataSet(X_val, y_val, \n", "#                                 transform=transforms.Compose([RandomHorizontalFlip(), \n", "#                                                               RandomVerticallFlip(), \n", "#                                                               ToTensor(), \n", "#                                                               ])) \n", "#         val_loader_kfold = DataLoader(dataset=val_dataset, batch_size=batch_size,\n", "#                           shuffle=True, num_workers=1)\n", "        \n", "#         print (val_loader_kfold)\n", "\n", "#         eval_loss = 0\n", "#         eval_acc = 0\n", "#         for data in val_loader:\n", "#             img  = data['image']\n", "#             label  = data['labels']\n", "\n", "#             img = Variable(img, volatile=True)\n", "#             label = Variable(label, volatile=True)\n", "\n", "#             out = model(img)\n", "#             loss = model.criterion(out, label)\n", "#             eval_loss += loss.data[0] * label.size(0)\n", "\n", "#         print('VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset_kfold))))\n", "#         val_losses.append(eval_loss / (len(val_dataset_kfold)))\n", "#         print()\n", "    \n", "def LeavOneOutValidation(val_loader): \n", "    print ('Leave one out VALIDATION ...')\n", "    model = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n", "                        pool_size=pool_size, n_out=n_out, padding=padding)\n", "    # .. to load your previously training model:\n", "    model.load_state_dict(torch.load('./cnn.pth'))\n", "    val_losses = []\n", "    model.eval()        \n", "    print (val_loader)\n", "    eval_loss = 0\n", "    eval_acc = 0\n", "    for data in val_loader:        \n", "        img  = data['image']\n", "        label  = data['labels']\n", "        img = Variable(img, volatile=True)\n", "        label = Variable(label, volatile=True)\n", "        out = model(img)\n", "        loss = model.criterion(out, label)\n", "        eval_loss += loss.data[0] * label.size(0)\n", "    print('Leave one out VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_dataset))))\n", "    val_losses.append(eval_loss / (len(val_dataset)))\n", "    print()\n", "    print()        \n", "    \n", "LeavOneOutValidation(val_loader)    "], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "1b27b0abe97351669c847040687b6de44fd1fd52", "_cell_guid": "0132970d-1c83-4785-bfea-73876af38b0b"}, "cell_type": "code", "source": ["# kFoldValidation(10)"], "execution_count": null}, {"cell_type": "markdown", "source": ["# Make Predictions\n", "Here we make predictions on the output and export the CSV so we can submit"], "metadata": {"_uuid": "a5f2ddcc3d70b5c41a870e5961fe907ee268d32b", "_cell_guid": "e2ed31f1-3fa0-4b75-bcde-51ad11f70a00"}}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "7e33c89ae19e631fcea492d8b306d2cd47f22c92", "_cell_guid": "f5bc1e63-60a8-42d8-93a1-8c752b0d6f6e"}, "cell_type": "code", "source": ["# load the model\n", "# model=torch.load('./cnn.pth')\n", "model = CNNClassifier(img_size=img_size, img_ch=img_ch, kernel_size=kernel_size, \n", "                        pool_size=pool_size, n_out=n_out, padding=padding)\n", "# .. to load your previously training model:\n", "model.load_state_dict(torch.load('./cnn.pth'))\n", "print (model)\n", "\n", "df_test_set = pd.read_json('../input/test.json')\n", "\n", "df_test_set['band_1'] = df_test_set['band_1'].apply(lambda x: np.array(x).reshape(75, 75))\n", "df_test_set['band_2'] = df_test_set['band_2'].apply(lambda x: np.array(x).reshape(75, 75))\n", "df_test_set['inc_angle'] = pd.to_numeric(df_test_set['inc_angle'], errors='coerce')\n", "\n", "df_test_set.head(3)\n", "\n", "\n", "print (df_test_set.shape)\n", "columns = ['id', 'is_iceberg']\n", "df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n", "# df_pred.id.astype(int)\n", "\n", "for index, row in df_test_set.iterrows():\n", "    rwo_no_id=row.drop('id')    \n", "    band_1_test = (rwo_no_id['band_1']).reshape(-1, 75, 75)\n", "    band_2_test = (rwo_no_id['band_2']).reshape(-1, 75, 75)\n", "    full_img_test = np.stack([band_1_test, band_2_test], axis=1)\n", "\n", "    x_data_np = np.array(full_img_test, dtype=np.float32)        \n", "    if use_cuda:\n", "        X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n", "    else:\n", "        X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n", "                    \n", "#     X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n", "    predicted_val = (model(X_tensor_test).data).float() # probabilities     \n", "    p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n", "    \n", "    df_pred = df_pred.append({'id':row['id'], 'is_iceberg':p_test},ignore_index=True)\n", "#     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n", "\n", "df_pred.head(5)"], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "089b7e22bfb305a21f5ee2f9a0f47ee3ecd11c95", "_cell_guid": "31b60d26-13ad-4004-8e22-5ee20d56defb"}, "cell_type": "code", "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "plt.plot(model.all_losses)\n", "plt.show()"], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "cb940713b1d74f8175ef2bfd904305994db759e1", "_cell_guid": "84882b4a-7f43-4b85-b184-5775bfea3146"}, "cell_type": "code", "source": ["# df_pred.id=df_pred.id.astype(int)\n", "\n", "def savePred(df_pred):\n", "#     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n", "#     csv_path = 'pred_{}_{}.csv'.format(loss, (str(time.time())))\n", "    csv_path='sample_submission.csv'\n", "    df_pred.to_csv(csv_path, columns=('id', 'is_iceberg'), index=None)\n", "    print (csv_path)\n", "    \n", "savePred (df_pred)"], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "0eb588f141c6c88e4a5fb958bc6e4d431b7f56b9", "_cell_guid": "bb0b012f-d5b0-4a59-b33b-273447f5f549"}, "cell_type": "code", "source": [], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "03052e5ab85c3fac83f5a31177243e9774efcd3f", "_cell_guid": "00e5267c-9f38-4654-aa8a-517fcbec4e43"}, "cell_type": "code", "source": [], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "9b3892c0048b1887a5ed97ff907c85fcaa0c1bdc", "_cell_guid": "54f8233e-6a0f-4a29-beee-2a29c76b7228"}, "cell_type": "code", "source": [], "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true, "_uuid": "42940f8bb08d6b48e577141b0a5fedddc22bd78e", "_cell_guid": "6f601c0b-7bce-4e63-b10b-0e500607cd6f"}, "cell_type": "code", "source": [], "execution_count": null}], "nbformat_minor": 1, "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}