{"cells":[{"metadata":{"_uuid":"3104f189b22c878def3f8a90537910f7d5d5ce4b"},"cell_type":"markdown","source":"**Competition Objective:**\n\nIn their 3rd Kaggle competition, Santander Group is asking Kagglers to help them identify the value of transactions for each potential customer. This is a first step that Santander needs to nail in order to personalize their services at scale.\n\n**Objective of the Notebook:**\n\nThe objective of the notebook is to explore the data for this competition.! We will be using python for the same.  "},{"metadata":{"_uuid":"2f0e779a6d98b9c9c06e2abe47f5428fa0e2c68c","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import preprocessing, model_selection, metrics\nimport lightgbm as lgb\n\ncolor = sns.color_palette()\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 9999","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"f0336ea98f1bec0b397d601ef2eaa6169cfa6673"},"cell_type":"markdown","source":"First let us look at the files given for the competition."},{"metadata":{"trusted":true,"_uuid":"f4dcd4bb2ce4e548015fd460b9b7973e6aecbfc9"},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"5d0af89fc10ff86f436239182d06e9bbb5d6bcc6"},"cell_type":"markdown","source":"This follows the standard format of train, test and sample submission files.\n\nNow let us read the train and test file and check the number of rows and columns."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"dbd1810a73b10ea497af768c492bd67820396780"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train rows and columns : \", train_df.shape)\nprint(\"Test rows and columns : \", test_df.shape)","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"cb0b10628234791f9f21a3067a137aaba232ff32"},"cell_type":"markdown","source":"So we have 4459 rows in train set and 49342 rows in test set. We also have 4993 columns in total including the target and id column.\n\n*Observations:*\n1. Test set is almost 10 times as that of train set. \n2. Public LB uses 49% of the test set for evaluation. So may be it is better to give some (if not more) weightage to LB scores.\n3. Number of columns is more than the number of train rows. So need to be careful with feature selection / engineering"},{"metadata":{"trusted":true,"_uuid":"455699c313be72dbaac3247443b1baed5b820432"},"cell_type":"code","source":"train_df.head()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"bb8f46b0bb735c717fe1a1e562f1816ae1712781"},"cell_type":"markdown","source":"*Observations:*\n1. The column names are anonymized and so we do not know what they mean\n2. There are many zero values present in the data\n3. From this [discussion post](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/59128), the dataset is a sparse tabular one.\n\n**Target Variable:**\n\nLet us first do a scatter plot of the target variable to see if there are any visible outliers. "},{"metadata":{"trusted":true,"_uuid":"b7505c980782da4c15fd6901f0078b17070b46e0"},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df['target'].values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('Target', fontsize=12)\nplt.title(\"Target Distribution\", fontsize=14)\nplt.show()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"9add430dd8b3322394d3a245230793f7e6659af0"},"cell_type":"markdown","source":"Looks like there are not any visible outliers in the data but the range is quite high.\n\nWe can now do a histogram plot of the target variable."},{"metadata":{"trusted":true,"_uuid":"6eb44d5246f8422cd3aa3c57e893ce93f18304d6"},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(train_df[\"target\"].values, bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Target Histogram\", fontsize=14)\nplt.show()","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"f889d1dbd3dca2b48dcfff530f1e66ce9cc173b4"},"cell_type":"markdown","source":"This is a right (Thanks to Wesam for pointing out my mistake) skewed distribution with majority of the data points having low value. Our competition admins are aware of this one and so they have chosen the evaluation metric as RMSLE (Root Mean Squared Logarithmic Error.).  \n\nSo let us do a histogram plot on the log of target variables and recheck again."},{"metadata":{"trusted":true,"_uuid":"cc61541ff6f36997b135a8cae9b54502b7278b1a"},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot( np.log1p(train_df[\"target\"].values), bins=50, kde=False)\nplt.xlabel('Target', fontsize=12)\nplt.title(\"Log of Target Histogram\", fontsize=14)\nplt.show()","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"d258b5bad7a781d374f2a5239f724721bbd3594e"},"cell_type":"markdown","source":"This looks much better than the old one. \n\n**Missing values:**\n\nNow let us check if there are missing values in the dataset."},{"metadata":{"trusted":true,"_uuid":"a6a6b1fddbdb882bcf01ef7023ff785c66ec63f9"},"cell_type":"code","source":"missing_df = train_df.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df[missing_df['missing_count']>0]\nmissing_df = missing_df.sort_values(by='missing_count')\nmissing_df","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"cbc8c837c82d6559eab04918847e6fd3cadfeeda"},"cell_type":"markdown","source":"There are no missing values in the dataset :)\n\n** Data Type of Columns:**\n\nNow let us also check the data type of the columns."},{"metadata":{"trusted":true,"_uuid":"b72a9be603697ae6d1c3a79ef4d53a2cd37139d9"},"cell_type":"code","source":"dtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"beca41c8217a31c1ff186fd8c3d14238499cbf6c"},"cell_type":"markdown","source":"Majority of the columns are of integer type and the rest are float type. There is only one string column which is nothing but 'ID' column.\n\n** Columns with constant values: **\n\nGenerally when we get problems with many columns, there might be few columns with constant value in train set. So we can check that one as well."},{"metadata":{"trusted":true,"_uuid":"10a9c7824e17a6cc73593e97bd1284e7350218a9"},"cell_type":"code","source":"unique_df = train_df.nunique().reset_index()\nunique_df.columns = [\"col_name\", \"unique_count\"]\nconstant_df = unique_df[unique_df[\"unique_count\"]==1]\nconstant_df.shape","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"6f0242c0a8f41337286fb775c696e95383024970"},"cell_type":"markdown","source":"So we have 256 columns with constant values in the train set. Probably it is a good idea to remove them from the training. Just printing out the names below for ease."},{"metadata":{"trusted":true,"_uuid":"4f72f8c1380600bca1cb90fcdbdc69b4631d9f49"},"cell_type":"code","source":"str(constant_df.col_name.tolist())","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"36dabb4b627ada0f1f0c145765cd8ef66ea82660"},"cell_type":"markdown","source":"** Correlation of features with target:**\n\nNow let us find the correlation of the variables with target and plot them. \n\nThanks to @Heads or Tails kernel and Tariq's comment, it might be a good idea to use Spearman correlation inplace of pearson since spearman is computed on ranks and so depicts monotonic relationships while pearson is on true values and depicts linear relationships. \n\nThere are thousands of variables and so plotting all of them will give us a cluttered plot. So let us take only those variables whose absolute spearman correlation coefficient is more than 0.1 (just to reduce the number of variables) and plot them. "},{"metadata":{"trusted":true,"_uuid":"16e762f6f5170358635a9241c5de5236b91f5c84"},"cell_type":"code","source":"from scipy.stats import spearmanr\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nlabels = []\nvalues = []\nfor col in train_df.columns:\n    if col not in [\"ID\", \"target\"]:\n        labels.append(col)\n        values.append(spearmanr(train_df[col].values, train_df[\"target\"].values)[0])\ncorr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\ncorr_df = corr_df.sort_values(by='corr_values')\n \ncorr_df = corr_df[(corr_df['corr_values']>0.1) | (corr_df['corr_values']<-0.1)]\nind = np.arange(corr_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,30))\nrects = ax.barh(ind, np.array(corr_df.corr_values.values), color='b')\nax.set_yticks(ind)\nax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\nax.set_xlabel(\"Correlation coefficient\")\nax.set_title(\"Correlation coefficient of the variables\")\nplt.show()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"2fa118870763fcb161224087e44eaad5e4ca626b"},"cell_type":"markdown","source":"There are quite a few variables with absolute correlation greater than 0.1\n\n**Correlation Heat Map:**\n\nNow let us take these variables whose absolute value of correlation with the target is greater than 0.11 (just to reduce the number of features fuether) and do a correlation heat map. \n\nThis is just done to identify if there are any strong monotonic relationships between these important features. If the values are high, then probably we can choose to keep one of those variables in the model building process.  Please note that we are doing this only for the very few features and feel free to add more features to explore more.   "},{"metadata":{"trusted":true,"_uuid":"6f045f3af2dd0b9bfc37eaf818f5bb395fdcf4fe"},"cell_type":"code","source":"cols_to_use = corr_df[(corr_df['corr_values']>0.11) | (corr_df['corr_values']<-0.11)].col_labels.tolist()\n\ntemp_df = train_df[cols_to_use]\ncorrmat = temp_df.corr(method='spearman')\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Draw the heatmap using seaborn\nsns.heatmap(corrmat, vmax=1., square=True, cmap=\"YlGnBu\", annot=True)\nplt.title(\"Important variables correlation map\", fontsize=15)\nplt.show()","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"6bec65afddffae8e5fc644b5c2e8479bee936726"},"cell_type":"markdown","source":"Seems like none of the selected variables have spearman correlation more than 0.7 with each other.  \n\nThe above plots helped us in identifying the important individual variables which are correlated with target. However we generally build many non-linear models in Kaggle competitions. So let us build some non-linear models and get variable importance from them. \n\nIn this notebook, we will build two models to get the feature importances - Extra trees and Light GBM. It could also help us to see if the important features coming out from both of them are consistent. Let us first start with ET model.  \n\n**Feature Importance - Extra trees model**\n\nOur Evaluation metric for the competition is RMSLE. So let us use log of the target variable to build our models. Also please note that we are removing those variables with constant values (that we identified earlier).  "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c34b4cd98a56972d2efc223ee8a19d5397585167"},"cell_type":"code","source":"### Get the X and y variables for building model ###\ntrain_X = train_df.drop(constant_df.col_name.tolist() + [\"ID\", \"target\"], axis=1)\ntest_X = test_df.drop(constant_df.col_name.tolist() + [\"ID\"], axis=1)\ntrain_y = np.log1p(train_df[\"target\"].values)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9de4dfc79dfb21b7bf8c72aafd9c9da72f13c35d","collapsed":true},"cell_type":"code","source":"from sklearn import ensemble\nmodel = ensemble.ExtraTreesRegressor(n_estimators=200, max_depth=20, max_features=0.5, n_jobs=-1, random_state=0)\nmodel.fit(train_X, train_y)\n\n## plot the importances ##\nfeat_names = train_X.columns.values\nimportances = model.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\nindices = np.argsort(importances)[::-1][:20]\n\nplt.figure(figsize=(12,12))\nplt.title(\"Feature importances\")\nplt.bar(range(len(indices)), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\nplt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\nplt.xlim([-1, len(indices)])\nplt.show()","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"ed631fdd7254ecdc16786ef62d3872bb0aed203d"},"cell_type":"markdown","source":"'f190486d6' seems to be the important variable followed by '58e2e02e6'. \n\n** Feature Importance & Baseline - Light GBM:**\n\nNow let us build a  Light GBM model to get the feature importance. \n\nApart from feature importance, let us also get predictions on the test set using this model and keep them as baseline predictions.\n\nBelow code is a custom helper function for Light GBM."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"76eddd8addd2174437e90c2fc7151d9e7631c4de"},"cell_type":"code","source":"def run_lgb(train_X, train_y, val_X, val_y, test_X):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 30,\n        \"learning_rate\" : 0.01,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.7,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 2018,\n        \"verbosity\" : -1\n    }\n    \n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, verbose_eval=200, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"cce4f0193eb0d958a1729f1945442b8c031b1a89"},"cell_type":"markdown","source":"Let us do KFold cross validation and average the predictions of the test set."},{"metadata":{"trusted":true,"_uuid":"5b84333f9ca39c9350319454956429617ed330b9","collapsed":true},"cell_type":"code","source":"kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=2017)\npred_test_full = 0\nfor dev_index, val_index in kf.split(train_X):\n    dev_X, val_X = train_X.loc[dev_index,:], train_X.loc[val_index,:]\n    dev_y, val_y = train_y[dev_index], train_y[val_index]\n    pred_test, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n    pred_test_full += pred_test\npred_test_full /= 5.\npred_test_full = np.expm1(pred_test_full)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"3cc121fdee098920a0d3a5e8f6f1e2312ff158f6"},"cell_type":"markdown","source":"So the validation set RMSLE of the folds range from 1.40 to 1.46.\n\nLet us write the predictions of the model and write it to a file"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"07e14c530ba7208e8e8f61e14cebc3b9d2f7d8e6"},"cell_type":"code","source":"# Making a submission file #\nsub_df = pd.DataFrame({\"ID\":test_df[\"ID\"].values})\nsub_df[\"target\"] = pred_test_full\nsub_df.to_csv(\"baseline_lgb.csv\", index=False)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"cf095c01c8d635a69a06e3cc71275202e048ef3d"},"cell_type":"markdown","source":"This model scored **1.47 RMSLE** on the public LB. We did not do any feature selection (apart from removing the constant variables), feature engineering and parameter tuning. So doing that will further imporve the score. We can use this as our baseline model for any further modeling.\n\nNow let us look at the feature importance of this model."},{"metadata":{"trusted":true,"_uuid":"9edd4286e09d2016732bd92f242a551c222f04e4","collapsed":true},"cell_type":"code","source":"### Feature Importance ###\nfig, ax = plt.subplots(figsize=(12,18))\nlgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"LightGBM - Feature Importance\", fontsize=15)\nplt.show()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"f01cfebefdb62f5a6adcd31e7aa49670739e6c9e"},"cell_type":"markdown","source":"Here again the top two important features are same as that of the Extra trees model. \n\nSo we could also do some form of feature selection using these feature importances and improve our models further. \n\nMay be in the next versions, let us look at the top variables from the non-linear models and do some more further analysis to understand tham.! "},{"metadata":{"_uuid":"dd2678f251df4e0265f67d78ec700467a05feac6"},"cell_type":"markdown","source":"**More to come. Stay tuned.!**"}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}