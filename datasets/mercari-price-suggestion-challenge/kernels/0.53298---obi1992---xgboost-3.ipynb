{"cells":[{"metadata":{"_cell_guid":"73d334dc-1c83-4e5e-be9c-3752fe02d580","_uuid":"c8a3ce7245ca96d7b22a93011ae1fb917eeae375","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom subprocess import check_output\nfrom tqdm import tqdm\nimport time\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom matplotlib import pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3f35ae06-f7be-49d2-9470-f69e3d463622","_uuid":"b2a02c62c76fe408dd0e0d8579de2c2d5bb5e109","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.tsv', sep='\\t')\ntest_df = pd.read_csv('../input/test.tsv', sep='\\t')\nfeature_names = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10f6d7374123948882dea081f39444024c2759b5"},"cell_type":"code","source":"# check percentage of missing values\ntrain_df.isna().sum() / train_df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"81056765-45cd-462e-bda0-18100696f76c","_uuid":"d11cbe7e633f46d9e7d698b43b682c60ed82722d","trusted":true},"cell_type":"code","source":"### exploratory analysis ###","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"10f84eb9-66fc-46dc-bc8b-e1c3b1c6f5b2","_uuid":"5a4b055440bb40325e459421819d72515739df3b","trusted":true},"cell_type":"code","source":"# Lets check how the distribution of test and vaidation set looks like ...\nstart = time.time()\nfig, ax = plt.subplots(nrows=5, sharex=True, sharey=True)\nsns.distplot(train_df.loc[train_df['item_condition_id']==3, 'price'].tolist(), ax=ax[0], color='blue', label='Validation')\nsns.distplot(train_df.loc[train_df['item_condition_id']==1, 'price'].tolist(), ax=ax[1], color='green', label='Test')\nsns.distplot(train_df.loc[train_df['item_condition_id']==2, 'price'].tolist(), ax=ax[2], color='green', label='Test')\nsns.distplot(train_df.loc[train_df['item_condition_id']==4, 'price'].tolist(), ax=ax[3], color='green', label='Test')\nsns.distplot(train_df.loc[train_df['item_condition_id']==5, 'price'].tolist(), ax=ax[4], color='green', label='Test')\nax[0].legend(loc=0)\nax[1].legend(loc=0)\nplt.show()\nend = time.time()\nprint(\"Time taken by above cell is {}.\".format((end-start)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05c6f243765654bd865ca0875c70b1eb2323a6bb"},"cell_type":"code","source":"# temp codes\n# sns.distplot(train_df['price'].tolist(), color='blue', label='Validation')\n# plt.show()\n\n# temp_train_price = np.log(train_df['price']+1)\n# sns.distplot(temp_train_price, color='blue', label='Validation')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a268b2d7-f425-4105-b025-1991108445da","_uuid":"900ad149b02aa9aac9fc460913152d7b3e152423","trusted":true},"cell_type":"code","source":"##### create dummy variables denoting if a record has certain category label ###\n# output: added columns in dataframe, derived from count matrix reduced by svm","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0795d9aa-ce36-4783-9fc3-d651440bf574","_uuid":"ac0c5f9d5c80408795c2254a71f7b16844b5f0aa","trusted":true},"cell_type":"code","source":"# replace all nan with ''\nprint('number of missing in category_name:',train_df['category_name'].isnull().sum())\ntrain_df['category_name'].fillna('', inplace=True)\ntest_df['category_name'].fillna('', inplace=True)\nprint('number of missing in category_name after imputation:',train_df['category_name'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f65945b-f807-41be-a3ab-eda98789e121","_uuid":"31ca155dddf664da1ee7de6630dd5b0f97b6a7a6","trusted":true},"cell_type":"code","source":"start = time.time()\ndef tokenize_category_name(text):\n    return text.lower().strip().split('/')\n\ncount_vec = CountVectorizer(\n    tokenizer=tokenize_category_name, ngram_range=(1,1), stop_words=None)\nfull_count = count_vec.fit_transform(\n    train_df['category_name'].values.tolist() + \n    test_df['category_name'].values.tolist())\ntrain_count = count_vec.transform(train_df['category_name'].values.tolist())\ntest_count = count_vec.transform(test_df['category_name'].values.tolist())\n\nn_comp = 20\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_count.asfptype()) # change int to float, as svd does not accept int type\ntrain_svd = pd.DataFrame(svd_obj.transform(train_count.asfptype()))\ntest_svd = pd.DataFrame(svd_obj.transform(test_count.asfptype()))\ntrain_svd.columns = ['svd_cat_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_cat_'+str(i) for i in range(n_comp)]\nfeature_names += ['svd_cat_'+str(i) for i in range(n_comp)]\n\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\nprint(\"time taken {}\".format((time.time() - start)/60))\ntrain_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ac058fb-2ed2-4f0c-ab6c-c32194f6cb4e","_uuid":"a11287e51ecc35feb28e4577146d6d9a46f12977","trusted":true},"cell_type":"code","source":"### if brand name is missing ###\n# output: add dummy series in dataframe","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb62af16-b4e4-4629-94ef-8e82c09f79f8","_uuid":"567d7f1923e18a8424f678836427a205f0075dc3","trusted":true},"cell_type":"code","source":"train_df['brand_miss'] = train_df['brand_name'].isnull().astype(float)\ntest_df['brand_miss'] = test_df['brand_name'].isnull().astype(float)\nprint('number of records in train set with missing brand name: {}'.format(train_df['brand_miss'].sum()))\nprint('number of records in test set with missing brand name: {}'.format(test_df['brand_miss'].sum()))\nfeature_names += ['brand_miss']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8def7cf-d53a-4084-8eb7-74b1cc181e82","_uuid":"4bc0528e5c67308a4eeec3ac1361e11df6e50bf4","trusted":true},"cell_type":"code","source":"### create dummy variables denoting brands ###\n# output: added columns in dataframe, derived from count matrix reduced by svm","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d3f03247-711b-4bd0-a118-1e0cda58ce07","_uuid":"17e80775ce8490682f9cdf7194f858b7915cbf9d","trusted":true},"cell_type":"code","source":"# replace all nan with ''\nprint('number of missing in category_name:',train_df['brand_name'].isnull().sum())\ntrain_df['brand_name'].fillna('', inplace=True)\ntest_df['brand_name'].fillna('', inplace=True)\nprint('number of missing in category_name after imputation:',train_df['brand_name'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"507232c8-f448-46c1-a1a1-0d04d63d328d","_uuid":"563d31b62cf7679d8b8b8e752cf2a68428b25429","trusted":true},"cell_type":"code","source":"start = time.time()\ndef tokenize_brand_name(text):\n    return [text.lower().strip(' ')]\n\ncount_vec = CountVectorizer(tokenizer=tokenize_brand_name, ngram_range=(1,1), stop_words=None)\n# count_vec.get_feature_names() # can use this to check what tokens are counted\nfull_count = count_vec.fit_transform(\n    train_df['brand_name'].values.tolist() + \n    test_df['brand_name'].values.tolist())\ntrain_count = count_vec.transform(train_df['brand_name'].values.tolist())\ntest_count = count_vec.transform(test_df['brand_name'].values.tolist())\n\nn_comp = 10\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_count.asfptype()) # change int to float, as svd does not accept int type\ntrain_svd = pd.DataFrame(svd_obj.transform(train_count.asfptype()))\ntest_svd = pd.DataFrame(svd_obj.transform(test_count.asfptype()))\ntrain_svd.columns = ['svd_brand_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_brand_'+str(i) for i in range(n_comp)]\nfeature_names += ['svd_brand_'+str(i) for i in range(n_comp)]\n\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\nprint(\"time taken {}\".format((time.time() - start) / 60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"213b5406338cf6c17f6d32f2f8ec175c7ad5dee8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"174a2875-fb95-43f3-8efc-137b29f72362","_uuid":"8ca20b39374906dbe25d3eba49c89d5015e390eb","trusted":true},"cell_type":"code","source":"### add dummies variables for item_condition_id ###","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3649c07e-6491-411c-901a-2d1a620392bc","_uuid":"d1638da0c02216adf887e8189530c4f04b93529f","trusted":true},"cell_type":"code","source":"train_cond_id_dummies = pd.get_dummies(\n    train_df['item_condition_id'], dummy_na=False, drop_first=True)\ntest_cond_id_dummies = pd.get_dummies(\n    test_df['item_condition_id'], dummy_na=False, drop_first=True)\ntrain_cond_id_dummies.columns = ['cond_id_'+str(i) for i in range(train_cond_id_dummies.shape[1])]\ntest_cond_id_dummies.columns = ['cond_id_'+str(i) for i in range(test_cond_id_dummies.shape[1])]\nfeature_names += train_cond_id_dummies.columns.tolist()\ntrain_df = pd.concat([train_df, train_cond_id_dummies], axis=1)\ntest_df = pd.concat([test_df, test_cond_id_dummies], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"39727cc8-2976-4bd3-b6ef-c5c915bcc97a","_uuid":"460deaadd9189614d411d6bcf0dc0712fabe1dcd","trusted":true},"cell_type":"code","source":"### if the item_description is not available ###","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8f5e297-0d51-4e3f-b19f-7636dce09682","_uuid":"28aaa881e09fd338a94b02aa02c0d3090f5608a5","trusted":true},"cell_type":"code","source":"train_df['itemDest_miss'] = (train_df['item_description'] == 'No description yet').astype(float)\ntest_df['itemDest_miss'] = (test_df['item_description'] == 'No description yet').astype(float)\nfeature_names += ['itemDest_miss']\nprint('number of records with no item description: {}'.format(train_df['itemDest_miss'].sum()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f56f480c-3434-4c89-b034-65464fda94f8","_uuid":"25efd3a3b5c98c4648653fb1f2f4b6125c3fbbbf","trusted":true},"cell_type":"code","source":"### add dummies variables for tfidf of item description, reduced by svd ###","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"54e9200a-4e50-4d3d-8b4b-b4e666049444","_uuid":"20c05c967e0d6fc7c9ccf32581802d62d5d4ade4","trusted":true},"cell_type":"code","source":"# replace all nan with ''\ntrain_df['item_description'].fillna('', inplace=True)\ntest_df['item_description'].fillna('', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d34878da-26c8-4d30-abd9-d9907c1a9bba","_uuid":"11d5ff5d9a9b250023f51d8af48529edd2f16b32","trusted":true},"cell_type":"code","source":"start = time.time()\n\ntfidf_vec = TfidfVectorizer(ngram_range=(1,2), stop_words=None)\n# count_vec.get_feature_names() # can use this to check what tokens are counted\nfull_tfidf = tfidf_vec.fit_transform(train_df['item_description'].values.tolist() + \n                                     test_df['item_description'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['item_description'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['item_description'].values.tolist())\n\nn_comp = 20\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf.asfptype()) # change int to float, as svd does not accept int type\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf.asfptype()))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf.asfptype()))\ntrain_svd.columns = ['svd_itemDes_tfidf_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_itemDes_tfidf_'+str(i) for i in range(n_comp)]\nfeature_names += ['svd_itemDes_tfidf_'+str(i) for i in range(n_comp)]\n\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\nprint(\"time taken {}\".format((time.time() - start)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"19875853-b6b1-43cc-ad1e-351d0702b14c","_uuid":"91e90c12f2f4251875f72b857a57d6071c8a4530","trusted":true},"cell_type":"code","source":"### add dummies variables for tfidf of item name (name), reduced by svd ###","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0adcc5e-80d1-40ff-9792-82a1e4320bd8","_uuid":"2a9435464c1359ec6827c2b462def8f0ef6b60d5","trusted":true},"cell_type":"code","source":"# replace all nan with ''\nprint('number of missing in name:',train_df['name'].isnull().sum())\ntrain_df['name'].fillna('', inplace=True)\ntest_df['name'].fillna('', inplace=True)\nprint('number of missing in name after imputation:',train_df['name'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4f851ae-1974-4734-b592-cb1fd2b368ce","_uuid":"ad5dac6de5f15f350b7da9d66d2e12d679077970","trusted":true},"cell_type":"code","source":"start = time.time()\n\ntfidf_vec = TfidfVectorizer(ngram_range=(1,2), stop_words=None)\n# count_vec.get_feature_names() # can use this to check what tokens are counted\nfull_tfidf = tfidf_vec.fit_transform(train_df['name'].values.tolist()+test_df['name'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train_df['name'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test_df['name'].values.tolist())\n\nn_comp = 20\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf.asfptype()) # change int to float, as svd does not accept int type\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf.asfptype()))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf.asfptype()))\ntrain_svd.columns = ['svd_name_tfidf_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_name_tfidf_'+str(i) for i in range(n_comp)]\nfeature_names += ['svd_name_tfidf_'+str(i) for i in range(n_comp)]\n\ntrain_df = pd.concat([train_df, train_svd], axis=1)\ntest_df = pd.concat([test_df, test_svd], axis=1)\n\nprint(\"time taken {}\".format((time.time() - start)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"24baddec-a724-444a-bd82-3ddf46ab98aa","_uuid":"821876d0dd516adfb5b3628d3cf2f7cea7c139d7","trusted":true},"cell_type":"code","source":"feature_names += ['shipping']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"22936b04-9f98-416e-9074-d8e59b75ab92","_uuid":"24ad3b1850429d36abf872beccc750d407503762","trusted":true},"cell_type":"code","source":"feature_names.__len__()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"252be2f2-ad70-4337-9410-2f045434c186","_uuid":"d5901764b1c8268b8512c5624b4f0fdd19fb5e60","trusted":true},"cell_type":"code","source":"feature_names","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0b049185-30fd-4549-a9b5-d57b64165afc","_uuid":"1c3f103caea33644220b8c356fee8666d60cc7f4","trusted":true},"cell_type":"code","source":"# prepare train and validation","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c7dc8de0-3c3c-418c-bddb-11ce0c5ab4f4","_uuid":"a1be6bcca0c8a309415bf5f955c9d27ad20229fb","trusted":true},"cell_type":"code","source":"train = train_df.copy()\ntest = test_df.copy()\n#y = np.log(train['price'].values + 1)\ny = train['price'].values\n\nXtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\ndtrain = xgb.DMatrix(Xtr, label=ytr, feature_names=feature_names)\ndvalid = xgb.DMatrix(Xv, label=yv, feature_names=feature_names)\ndtest = xgb.DMatrix(test[feature_names].values, feature_names=feature_names)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\nXtr.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9524130f-620a-4c5d-91e6-7075521a5b17","_uuid":"3db534076923b206e810403c0651ad61d35211b6","trusted":true},"cell_type":"code","source":"start = time.time()\nxgb_par = {'min_child_weight': 20, 'eta': 0.05, 'colsample_bytree': 0.5, 'max_depth': 13,\n           'subsample': 0.9, 'lambda': 2.0, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n           'eval_metric': 'rmse', 'objective': 'reg:linear'}\n\nmodel_3 = xgb.train(xgb_par, dtrain, 80, watchlist, early_stopping_rounds=20, \n                    maximize=False, verbose_eval=20)\nprint('Modeling RMSLE %.5f' % model_3.best_score)\nprint(\"Time taken in training is {}.\".format((time.time() - start)/60))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"71cc5b86-68e2-4949-8506-87c328adf456","_uuid":"ee2e1264f65579546ab7aa83f00e9d96376c6f4a","trusted":true},"cell_type":"code","source":"# Plot the important variables ##\nfrom matplotlib import pyplot as plt\nfig, ax = plt.subplots(figsize=(12,6))\nxgb.plot_importance(model_3, max_num_features=20, height=0.8, ax=ax)\nplt.title(\"Feature importance - top 20\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9c36cbd3-1a86-4c2b-afe5-a938913f5c68","_uuid":"a88444dd49a02e4f42cfd9716c18ba4d26a53333","trusted":true},"cell_type":"code","source":"start = time.time()\nyvalid = model_3.predict(dvalid)\nytest = model_3.predict(dtest)\nend = time.time()\nprint(\"Time taken in prediction is {}.\".format(end - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a7ea2927-e7d3-4a87-8db8-af468085b157","_uuid":"4a325ea1f0e2ac6e9059f59ceae4826a04917073","trusted":true},"cell_type":"code","source":"# Lets check how the distribution of test and vaidation set looks like ...\nstart = time.time()\nfig, ax = plt.subplots(nrows=2, sharex=True, sharey=True)\nsns.distplot(yvalid, ax=ax[0], color='blue', label='Validation')\nsns.distplot(ytest, ax=ax[1], color='green', label='Test')\nax[0].legend(loc=0)\nax[1].legend(loc=0)\nplt.show()\nend = time.time()\nprint(\"Time taken by above cell is {}.\".format((end-start)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13ad14ec-fd53-41e8-b426-192d38822c58","_uuid":"4a44c89f9b962582ffefb585ae78ba8e6e2d504e","trusted":true},"cell_type":"code","source":"start = time.time()\nif test.shape[0] == ytest.shape[0]:\n    print('Test shape OK.')\n#test['price'] = np.exp(ytest) - 1\ntest['price'] = ytest\n#test[['test_id', 'price']].to_csv('xgb_4.csv', index=False)\ntest[['test_id', 'price']].to_csv('xgb_4_2.csv', index=False)\nend = time.time()\nprint(\"Time taken in training is {}.\".format(end - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e8ad8db-29dc-47c6-8e7c-992b1065825b","_uuid":"d79e348d5f1f992ab7f056bc2979170363c63b60","trusted":true},"cell_type":"code","source":"ytest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff5169798f94170db406e6831bacc31e69b94913"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}