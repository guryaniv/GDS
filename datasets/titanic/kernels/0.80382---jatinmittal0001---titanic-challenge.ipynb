{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\ntest_data_copy = pd.read_csv('../input/test.csv')\nntrain = train_data.shape[0]\ny = train_data.iloc[:,1]\ntrain_data = train_data.drop(['PassengerId','Survived'],axis=1)\ntest_data = test_data.drop(['PassengerId'],axis=1)\ntotal_data = train_data.append(test_data, sort=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"685c7ce1835301aef7d5fd2c427e2c5981d7f817"},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"173ca811b1fbfb519775372f57c04b9059be076c"},"cell_type":"code","source":"# missing value treatment\ntotal_missing_values = total_data.isnull().sum().sort_values(ascending=False)\npercentage_missing_values = (100*total_data.isnull().sum()/total_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total_missing_values,percentage_missing_values], axis=1 , keys=['#missing values', \"missing percentage\"])\nprint(missing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a274ae5b636cff42902d0f73d6b303e0752d6b9f"},"cell_type":"code","source":"# cabin column treatment\n'''\nwe can see that 77% values in that col. are missing, we can do 2 things\n1. Drop that variable\n2. Since it is categorical variable we can replace those 77% values with 'U' which will represent\nunknown class\nWe'll try both methods and finally keep that whih gives best accuracy\n'''\ntotal_data[\"Cabin\"].unique()\ntotal_data[\"Cabin\"] = total_data[\"Cabin\"].fillna('U')\ntotal_data[\"Cabin\"] = total_data[\"Cabin\"].apply(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"956074fb82cab7ec673576e9ec27ffe42c7576c2"},"cell_type":"code","source":"'''\nNow we have to treat age variable, for that we will first extarct Mr., mrs. etc titles and replace \nmsising values with mean of that particuar title group\n'''\ntotal_data[\"Name\"] = total_data[\"Name\"].map(lambda x: x.split(\",\")[1].split(\".\")[0].strip())\n\ntotal_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"510ad0aad69985a4ecea03af155a7c61c052ab53"},"cell_type":"code","source":"pd.crosstab(total_data[\"Name\"], total_data[\"Sex\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01d3f67463c13c6c60cf93371330b444b83ee35"},"cell_type":"code","source":"#We can replace many titles with a more common name or classify them as Rare.\ntotal_data['Name'] = total_data['Name'].replace(['Lady', 'the Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntotal_data['Name'] = total_data['Name'].replace('Mlle', 'Miss')\ntotal_data['Name'] = total_data['Name'].replace('Ms', 'Miss')\ntotal_data['Name'] = total_data['Name'].replace('Mme', 'Mrs')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fae587bee22d99210b803f972e4506466f5fdbde"},"cell_type":"code","source":"unique_titles = total_data[\"Name\"].unique()\nprint(unique_titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39301b00b63a20d900b58f4c12c86403415de123"},"cell_type":"code","source":"# now treating 'age' variable\ntotal_data[\"Age\"] = total_data.groupby(\"Name\")[\"Age\"].transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cfcca3f6caf1d0ae6f81ce5a707413618085b81"},"cell_type":"code","source":"# now checking #missing values\ntotal_missing_values = total_data.isnull().sum().sort_values(ascending=False)\npercentage_missing_values = (100*total_data.isnull().sum()/total_data.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total_missing_values,percentage_missing_values], axis=1 , keys=['#missing values', \"missing percentage\"])\nprint(missing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d7b0843614b9f86a739397d9db2b79b7dcfc146"},"cell_type":"code","source":"# filling embark missing values with values which occured most\ntotal_data['Embarked'] = total_data['Embarked'].fillna(total_data['Embarked'].mode()[0])\n#now for fare it could be decided by the station embarked from and thecabin alloted\n#\ntotal_data[\"Fare\"] = total_data.groupby(['Embarked','Pclass'])[\"Fare\"].transform(lambda x: x.fillna(x.mean()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5d66fe17d3d80c21bc8f2b2f9a29d3f2236ecce"},"cell_type":"code","source":"# also ticket number won't provide aby valueable information so we can drop that\ntotal_data = total_data.drop(['Ticket'],axis=1)\n\n#creating feature\ntotal_data[\"Family_size\"] = total_data['SibSp'] + total_data['Parch'] + 1 \ntotal_data['IsAlone'] = 1\ntotal_data['IsAlone'].loc[total_data['Family_size']>1] =0\n\ntotal_data['AgeBin'] = pd.cut(total_data['Age'].astype(int), 5)\ntotal_data['FareBin'] = pd.cut(total_data['Fare'].astype(int), 4)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"809c7cf00bc9222de1ffe3ef3e21264d85bb1c9c"},"cell_type":"code","source":"#label encoder\nlabel = LabelEncoder()\ntotal_data['AgeBin_Code'] = label.fit_transform(total_data['AgeBin'])\ntotal_data['FareBin_Code'] = label.fit_transform(total_data['FareBin'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a3d9a707ee54c1e3fead8fa1262f31648d1eec1"},"cell_type":"code","source":"total_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db978d99fdb364389f045395887e219ff202210b"},"cell_type":"code","source":"\n# ONE HOT ENCODING OF CATEGORICAL DATA\ntotal_data = total_data.drop(['Cabin'], axis=1)\ntotal_data_onehot = total_data.copy()\ntotal_data_onehot = pd.get_dummies(total_data_onehot, columns=['Sex','Embarked','Name'], prefix = ['Sex','Embarked','Name'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91ec63e87f7f1c73de3f04caa619cf37772ffa92"},"cell_type":"code","source":"total_data_onehot.head()\n#total_data_onehot = total_data_onehot.drop(['Age','Fare'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ee9e6ae8985e10364dcbb052a73899a50e5fb41"},"cell_type":"code","source":"total_data_onehot = total_data_onehot.drop(['AgeBin','FareBin'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c670d4ae1fca0aac1b76b6754acd9dae7138156"},"cell_type":"code","source":"total_data_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60b57419326274ca66bdaac0a44d21971ad0284b"},"cell_type":"code","source":"\nfinal_train_data = total_data_onehot.iloc[:ntrain,:]\nfinal_test_data = total_data_onehot.iloc[ntrain:,:]\n\n#creating train, test split\nx_train, x_test,y_train, y_test = train_test_split(final_train_data, y, shuffle=True,test_size=0.3)\n\n# scaling data\nfrom sklearn.preprocessing import StandardScaler\n\n# fit only to training data i.e. find mean and dev for training data\nscale = StandardScaler()\nscale.fit(x_train)\n\n# apply those transformtions to x_train and x_test data set\nx_train = scale.transform(x_train)\nx_test = scale.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b57c2b14746ad2a0ab8a6e775818838602091ae0"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ndef find_accuracy(y_test,y_pred):\n    return accuracy_score(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97dcb0fcedfab3cc690ec7ee7fae59af9d92656b"},"cell_type":"code","source":"numebr_of_class0_counts = y[y==0].count()\n# it is almost 60%, therefore right now we are not upsampling or downsampling it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f97aaf0e2f16ba463e01381e12d949b31315360"},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada = AdaBoostClassifier(n_estimators=70, learning_rate=1)\nada.fit(x_train, y_train)\ny_pred = ada.predict(x_test)\nprint(find_accuracy(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cb26042cc3593990105cbf14c433d299b500f36"},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel = 'poly',probability=True)\nsvc.fit(x_train, y_train)\ny_pred = svc.predict(x_test)\nprint(find_accuracy(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a721729c6b9f202535e5ed2c60bf67f585d945a7"},"cell_type":"code","source":"# applying model: XGBOOST\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\nfrom xgboost import XGBClassifier\n\nxgb_model = XGBClassifier()\nxgb_model.fit(x_train, y_train)\ny_pred = xgb_model.predict(x_test)\n\nprint(find_accuracy(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e962a097ba34116ca032374f6c7dba16bb3d24c"},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(10,6,5,3),activation='relu',alpha = 0.0001,max_iter = 1000,solver='lbfgs')\nmlp.fit(x_train, y_train)\ny_pred = mlp.predict(x_test)\nprint(find_accuracy(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43ae036c9c63e5a11f1292af051556e618448d05"},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlasso = Lasso(alpha=0.0005)\nlasso.fit(x_train, y_train)\ny_pred = lasso.predict(x_test)\ny_pred = (y_pred>0.6)\nprint(find_accuracy(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffcac537e66b7a0df507aa66671437e43505cb6d"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(x_train, y_train)\ny_pred = rf.predict(x_test)\nprint(find_accuracy(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eab68aec778a23489a0c3c51cf2c50fda94a2be8"},"cell_type":"code","source":"\nfrom sklearn.linear_model import ElasticNet\nelastic_net_model = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\nelastic_net_model.fit(x_train, y_train)\ny_pred = elastic_net_model.predict(x_test)\ny_pred = (y_pred>0.6)\nprint(find_accuracy(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a393cb59d04f8032504b1df3bebcf4670b668707"},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nmodel = VotingClassifier(estimators=[('xgb', xgb_model),('svc',svc)], voting='soft')\nmodel = model.fit(x_train,y_train)\ny_pred = model.predict(x_test)\nprint(find_accuracy(y_pred, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fed948aea1b4351b22f12d54e628f17c127c181"},"cell_type":"code","source":"#NOTE: we have trained our model on x_train, and tested on x_test\n# since the size of data is small, we'll now train on final_train_data, and directly predict test_data\n#and we'll not test it. This is bcoz we know that accuracy will be around 84%, so increasing size of \n# trainging data may give more accuracy\n'''\nscale.fit(final_train_data)\n\n# apply those transformtions to x_train and x_test data set\ntrain = scale.transform(final_train_data)\ntest = scale.transform(final_test_data)\n\nmodel = model.fit(train, y)\n\n#note that we first have to transform test_data\ny_pred = model.predict(test)\n'''\n\ntest = scale.transform(final_test_data)\nmodel = model.fit(x_train, y_train)\ny_pred = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4beeb4170c19d568330617be3137366859868c90"},"cell_type":"code","source":"solution = pd.DataFrame({\"PassengerId\": test_data_copy[\"PassengerId\"],\n        \"Survived\": y_pred})\nsolution.to_csv(\"titanic_final.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a65a506aaa0f177f404ed35a6a83a04675c42ef8"},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5)\nfor train_index, test_index in kf.split(final_train_data):\n    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n    x_train, x_test = final_train_data.iloc[train_index], final_train_data.iloc[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    scale = StandardScaler()\n    scale.fit(x_train)\n\n    # apply those transformtions to x_train and x_test data set\n    x_train = scale.transform(x_train)\n    x_test = scale.transform(x_test)\n    model = VotingClassifier(estimators=[('xgb', xgb_model),('svc',svc)], voting='soft')\n    model = model.fit(x_train,y_train)\n    y_pred = model.predict(x_test)\n    print(find_accuracy(y_pred, y_test))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71bf5711dd7d64930565d91d7b296151d4b56497"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}