{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport json\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\nimport lightgbm as lgb\nimport time\nfrom wordcloud import WordCloud\nimport ast\nimport collections\nfrom collections import Counter\nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.pipeline import make_pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Data overview & Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"d81f6d4eaff9738f19a0a14f8b6ee3357edbf758"},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83307eef78b99f14466bbf9cbd03a4b0f4da6c5e"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d59c6f633295ce29d70501f04340b754e043fe77"},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f700b97fde1a54f647fb82db9380856516b07244"},"cell_type":"code","source":"train.dropna().shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88384ac75e96c62e6290666dcbd5942625d1b2a3","scrolled":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61d8d1020d2e881b55db71c218c5738d1beada4c"},"cell_type":"markdown","source":"We begin to drop the `belongs_to_collection`and `homepage` features because there are too many `NaN`values."},{"metadata":{"trusted":true,"_uuid":"1815bff3dba67cbd3532441af990fb9d440fb4c0"},"cell_type":"code","source":"train = train.drop(['belongs_to_collection', 'homepage'], axis=1)\ntest = test.drop(['belongs_to_collection', 'homepage'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07cbb7b01b439ba3092d65780a3594ca90f90ef0"},"cell_type":"markdown","source":"### Useless Features\nWe drop some of the features that are not useful (at first glance)\n* `imbd_id` : if we stick to the data that is provided, we don't need this id. Perhaps we could add some new external data with it later...\n* `poster_path` : a link to the poster picture (no need for now, if we want to use some ensemble techniques)"},{"metadata":{"trusted":true,"_uuid":"de9375c72697b521a0e01b709741b13fa507149a"},"cell_type":"code","source":"train = train.drop(['imdb_id', 'poster_path'], axis=1)\ntest = test.drop(['imdb_id', 'poster_path'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd75f7d81474313bdd3fc5aa5de644e244c18556"},"cell_type":"markdown","source":"### Let's look at numbers first!\nThe quantitative features that could be helpful are:\n* the **budget**\n* the **popularity**\n* the **runtime**\n* and the target : **revenue**"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"2b8ab0a1edb337e76ccbe98ec835e1180177b794"},"cell_type":"code","source":"# Replace the nan values of the 'runtime' in both datasets by the mean of other movies' runtime\ntrain.runtime[train.runtime.isna()] = train.runtime.mean()\ntest.runtime[test.runtime.isna()] = test.runtime.mean()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5abdea174602b3c902482db757d8ad77df7abae1"},"cell_type":"code","source":"f = ['budget', 'popularity', 'runtime', 'revenue']\nsns.pairplot(train[f].dropna())\nNone","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f80f70c2d10af58671fe91962cc81b36e56a5f57"},"cell_type":"markdown","source":"At first look, the budget and the revenue seem correlated!"},{"metadata":{"_uuid":"f67025e6ef203039115ca6b4a39f5fe6bfd08f80"},"cell_type":"markdown","source":"### Language"},{"metadata":{"_uuid":"0b084bdca24aefa3a5fbfd8ced2970ebd16eef8e"},"cell_type":"markdown","source":"#### Number of spoken languages"},{"metadata":{"_uuid":"be1555e1e6e98d5d7e13c651ea61291641c73de5"},"cell_type":"markdown","source":"The spoken languages are contained in a list of dictionaries, represented by a string, let's symplify it."},{"metadata":{"trusted":true,"_uuid":"548fa58215521342874b66e76de011f98e9249c6"},"cell_type":"code","source":"print(\"raw format:\", train.spoken_languages.iloc[0])\n\ntrain.spoken_languages = train.spoken_languages.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\ntest.spoken_languages = test.spoken_languages.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\n\ntrain.head().spoken_languages","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"300162fe45212e7421b8ec6646e40aaa1cd085b3"},"cell_type":"markdown","source":"Now we can create 2 additional features : the number of spoken languages, and wheter the english belongs to them."},{"metadata":{"trusted":true,"_uuid":"d78a4136747d7f0239a7c768aca6ce0392e5561e"},"cell_type":"code","source":"train['nb_spoken_languages'] = train.spoken_languages.apply(len)\ntest['nb_spoken_languages'] = test.spoken_languages.apply(len)\n\ntrain['english_spoken'] = train.spoken_languages.apply(lambda x: 'en' in x)\ntest['english_spoken'] = test.spoken_languages.apply(lambda x: 'en' in x)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8cd52aa8eb13f568bb6c04c34f517ed25beefdcb"},"cell_type":"code","source":"train.nb_spoken_languages.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42dd028bdd4d93210eab971d71d60938ee95fc9a"},"cell_type":"markdown","source":"There is one film in witch 9 languages are spoken ! Or maybe it is the number of languages in which the film has been translated..."},{"metadata":{"_uuid":"77712a89a4ec61d3dda8a5395bf3010415f45b17"},"cell_type":"markdown","source":"#### Original Language\nLet's see what are the principal main original  languages in both train and test data :"},{"metadata":{"trusted":true,"_uuid":"3cd283cae83d230794f836552e478b230d77b985"},"cell_type":"code","source":"all_lang = pd.concat([train.original_language, test.original_language], axis=0).value_counts()\nall_lang[all_lang>20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f22222bc802823607901344ff3a0808665ab4b88"},"cell_type":"code","source":"# Here are the main languages\nmain_languages = list(all_lang[all_lang>20].index)\n# Let's categorize them, and add a 'other' catergorie\ndict_language = dict(zip(main_languages, range(1, len(main_languages)+1)))\ndict_language['other'] = 0\n\ntrain.original_language = train.original_language.apply(lambda x: x if x in main_languages else 'other')\ntest.original_language = test.original_language.apply(lambda x: x if x in main_languages else 'other')\n\ntrain['language'] = train.original_language.apply(lambda x: dict_language[x])\ntest['language'] = test.original_language.apply(lambda x: dict_language[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"484f4a2655da7021213a759799d9ab89b16ab7c4"},"cell_type":"markdown","source":"### Movie genre"},{"metadata":{"_uuid":"920db676d13e56626c931b7feaaf0604f49cc835"},"cell_type":"markdown","source":"Let's look at the different genres associated with the movies."},{"metadata":{"trusted":true,"_uuid":"fd2ef00fee5ddd89be40d7f115816e817979d99e"},"cell_type":"code","source":"# Apply the same preprocessing on the string values\ntrain.genres = train.genres.apply(lambda x: list(map(lambda d: list(d.values())[1], ast.literal_eval(x)) if isinstance(x, str) else []))\ntest.genres = test.genres.apply(lambda x: list(map(lambda d: list(d.values())[1], ast.literal_eval(x)) if isinstance(x, str) else []))\n\ntrain.genres.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faac56314a94c1a1ccfc213238853943b57fea7e"},"cell_type":"markdown","source":"Here is the distribution of the number of genres per movie. There are 3 films with 7 genres, that's a lot!"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d2e45509b640d7514806dff398b702468c578dd2"},"cell_type":"code","source":"train.genres.apply(len).value_counts().sort_index()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"feff49e1b354a34c5e192259fa22b6f5889b197a"},"cell_type":"code","source":"for v in train[train.genres.apply(len)==7][['title', 'genres']].values:\n    print('film:', v[0], '\\ngenres:', *v[1], '\\n')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3f751372474aa5efbdf0bc21739975ad3b0e194"},"cell_type":"markdown","source":"Let's regroup all the existing genres :"},{"metadata":{"trusted":true,"_uuid":"e7e812c8480e36fab7c9773ab95b76cd35599466","_kg_hide-input":false,"scrolled":true},"cell_type":"code","source":"genres = Counter(itertools.chain.from_iterable(pd.concat((train.genres, test.genres), axis=0).values))\nprint(\"Number of different movie genres:\", len(genres))\nprint()\nprint(\"Genre frequency:\\n\"+'\\n'.join(['{} : {}'.format(g, genres[g]) for g in genres]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd4209fd917f8530f610617877183727556a7a22"},"cell_type":"markdown","source":"As the amount of train sample is limited (3000), I don't want to add too much features. \n\nThus instead of creating 20 categorical features, one for each genre, let's reduce those categories in a smaller space thanks to **SVD**."},{"metadata":{"trusted":true,"_uuid":"5d332477a9fed4119309913fc3452f9902ad523b"},"cell_type":"code","source":"%%time\ntemp_train = train[['id', 'genres']]\ntemp_test = test[['id', 'genres']]\nfor g in genres:\n    temp_train[g] = temp_train.genres.apply(lambda x: 1 if g in x else 0)\n    temp_test[g] = temp_test.genres.apply(lambda x: 1 if g in x else 0)\n    \nX_train = temp_train.drop(['genres', 'id'], axis=1).values\nX_test = temp_test.drop(['genres', 'id'], axis=1).values\n\n# Number of features we want for genres\nn_comp_genres = 3\n\n# Build the SVD pipeline\nsvd = make_pipeline(\n    TruncatedSVD(n_components=n_comp_genres),\n    Normalizer(norm='l2', copy=False)\n)\n\n# Here are our new features\nf_train = svd.fit_transform(X_train)\nf_test = svd.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38837201df14b34837e7193e3f817448208576b0"},"cell_type":"code","source":"for i in range(n_comp_genres):\n    train['genres_reduced_{}'.format(i)] = f_train[:, i]\n    test['genres_reduced_{}'.format(i)] = f_test[:, i]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"931d285303944b8284635aded987c302e4f12d19"},"cell_type":"markdown","source":"### Other multicategorical variables\n\nThe same reasoning is applicable to the other multicategorical variables :\n* `production_companies`\n* `production_countries`\n* `Keywords` and `crew` but those are very sparse, as the number of total keywords or crew members can grow very fast."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ec12f12d16de045aecde95538ac923c28cab1c13"},"cell_type":"code","source":"# Apply the same preprocessing on the string values\ntrain.production_companies = train.production_companies.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\ntest.production_companies = test.production_companies.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\n\ntrain.production_countries = train.production_countries.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\ntest.production_countries = test.production_countries.apply(lambda x: list(map(lambda d: list(d.values())[0], ast.literal_eval(x)) if isinstance(x, str) else []))\n\ntrain.Keywords = train.Keywords.apply(lambda x: list(map(lambda d: list(d.values())[1], ast.literal_eval(x)) if isinstance(x, str) else []))\ntest.Keywords = test.Keywords.apply(lambda x: list(map(lambda d: list(d.values())[1], ast.literal_eval(x)) if isinstance(x, str) else []))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":false,"_uuid":"099e8469f33393efe160c09e97a5dde237126e32"},"cell_type":"code","source":"# Production companies\nproduction_companies = Counter(itertools.chain.from_iterable(pd.concat((train.production_companies, test.production_companies), axis=0).values))\nprint(\"Number of different production companies:\", len(production_companies))\n\n# Production countries\nproduction_countries = Counter(itertools.chain.from_iterable(pd.concat((train.production_countries, test.production_countries), axis=0).values))\nprint(\"Number of different production countries:\", len(production_countries))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87711dff5024b043586637f38a5da5888eddcf66"},"cell_type":"code","source":"# Add the number of each categorical feature  per film in he features\ntrain['nb_production_companies'] = train.production_companies.apply(len)\ntest['nb_production_companies'] = test.production_companies.apply(len)\n\ntrain['nb_production_countries'] = train.production_countries.apply(len)\ntest['nb_production_countries'] = test.production_countries.apply(len)\n\ntrain['nb_keywords'] = train.Keywords.apply(len)\ntest['nb_keywords'] = test.Keywords.apply(len)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"75395f343317e38782c7ddfc6b3ee1dcdd1e4a71"},"cell_type":"code","source":"%%time\nprint('Applying SVD on production companies to create reduced features')\n\n# Factorizing all the little production companies into an 'other' variable\nbig_companies = [p for p in production_companies if production_companies[p] > 30]\ntrain.production_companies = train.production_companies.apply(lambda l: list(map(lambda x: x if x in big_companies else 'other', l)))\n\ntemp_train = train[['id', 'production_companies']]\ntemp_test = test[['id', 'production_companies']]\n\nfor p in big_companies + ['other']:\n    temp_train[p] = temp_train.production_companies.apply(lambda x: 1 if p in x else 0)\n    temp_test[p] = temp_test.production_companies.apply(lambda x: 1 if p in x else 0)\n    \nX_train = temp_train.drop(['production_companies', 'id'], axis=1).values\nX_test = temp_test.drop(['production_companies', 'id'], axis=1).values\n\n# Number of features we want for genres\nn_comp_production_companies = 3\n\n# Build the SVD pipeline\nsvd = make_pipeline(\n    TruncatedSVD(n_components=n_comp_production_companies),\n    Normalizer(norm='l2', copy=False)\n)\n\n# Here are our new features\nf_train = svd.fit_transform(X_train)\nf_test = svd.transform(X_test)\n\nfor i in range(n_comp_production_companies):\n    train['production_companies_reduced_{}'.format(i)] = f_train[:, i]\n    test['production_companies_reduced_{}'.format(i)] = f_test[:, i]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ff7aae0e7771bb0c9d44c69b10271116eeec7140"},"cell_type":"code","source":"%%time\nprint('Applying SVD on production countries to create reduced features')\n\ntemp_train = train[['id', 'production_countries']]\ntemp_test = test[['id', 'production_countries']]\nfor p in production_countries:\n    temp_train[p] = temp_train.production_countries.apply(lambda x: 1 if p in x else 0)\n    temp_test[p] = temp_test.production_countries.apply(lambda x: 1 if p in x else 0)\n    \nX_train = temp_train.drop(['production_countries', 'id'], axis=1).values\nX_test = temp_test.drop(['production_countries', 'id'], axis=1).values\n\n# Number of features we want for genres\nn_comp_production_countries = 3\n\n# Build the SVD pipeline\nsvd = make_pipeline(\n    TruncatedSVD(n_components=n_comp_production_countries),\n    Normalizer(norm='l2', copy=False)\n)\n\n# Here are our new features\nf_train = svd.fit_transform(X_train)\nf_test = svd.transform(X_test)\n\nfor i in range(n_comp_production_countries):\n    train['production_countries_reduced_{}'.format(i)] = f_train[:, i]\n    test['production_countries_reduced_{}'.format(i)] = f_test[:, i]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"640dc08884f075da8de309c4ae6506990810224a"},"cell_type":"markdown","source":"# Models"},{"metadata":{"trusted":true,"_uuid":"ce815f47fd145ac0670464b74c35805b0aaf787e"},"cell_type":"code","source":"features = ['budget', \n            'popularity', \n            'runtime', \n            'nb_spoken_languages', \n            'english_spoken', \n            'language',\n            'nb_production_companies',\n            'nb_production_countries',\n            'nb_keywords'\n           ]\nfeatures += ['production_companies_reduced_{}'.format(i) for i in range(n_comp_production_companies)]\nfeatures += ['production_companies_reduced_{}'.format(i) for i in range(n_comp_production_countries)]\nfeatures += ['genres_reduced_{}'.format(i) for i in range(n_comp_genres)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46067d09134ed5b66d6ba33eb5acb19f7807e0a"},"cell_type":"code","source":"X = train[features]\ny = train.revenue.apply(np.log10)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c7b729c72d7838f1092fe30d1a8e7bf40560c01"},"cell_type":"code","source":"params = {'objective':'regression',\n          'num_leaves' : 40,\n          'min_data_in_leaf' : 20,\n          'max_depth' : 6,\n          'learning_rate': 0.001,\n          \"metric\": 'rmse',\n          \"random_state\" : 42,\n          \"lambda_l2\" : 0.005,\n          \"verbosity\": -1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e524025256625a2e08435d175e793142817f5ba"},"cell_type":"code","source":"# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2808cf3db900bda87e326caec3510174b5cdee0"},"cell_type":"code","source":"print('Starting training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=5000,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec02fccab70e19d0b8f13a3c2ab9dcd29582d292"},"cell_type":"code","source":"X_test = test[features]\ny_pred = 10**gbm.predict(X_test)\npd.DataFrame({'id': test.id, 'revenue': y_pred}).to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e8f39094f0e4164c14428b7fd552d144baede6b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}