{"cells":[{"metadata":{"_uuid":"6cb5249fbd09498806520c378e0c4948a230df54"},"cell_type":"markdown","source":"# Agonizing over your March Madness bracket?\nWho isn't?! Not familiar with this American obsession? Here are the basics from the NCAA in [this](https://www.ncaa.com/news/basketball-men/bracketiq/2018-10-10/what-march-madness-ncaa-tournament-explained) article:\n>**What is March Madness?**\nThe NCAA Division I men’s basketball tournament is a single-elimination tournament of 68 teams that compete in seven rounds for the national championship. The penultimate round is known as the Final Four, when only (you guessed it) four teams are left.\n<br><br>\n>**When did March Madness start?**\n>The first NCAA Division I men’s basketball tournament was in 1939, and it has been held every year since.\n<br><br>\n>**How has the tournament changed since 1939?**\n>The inaugural tournament had just eight teams, and saw Oregon beat Ohio State 46-33 for the title. In 1951, the field doubled to 16, and kept expanding over the next few decades until 1985, when the modern format of a 64-team tournament began. In 2001, after the Mountain West Conference joined Division I and received an automatic bid, pushing the total teams to 65, a single game was added prior to the first round. In 2011, three more teams were added, and with them, three more games to round out the First Four.\n\n\nFrom Smithsonian.com in [this](https://www.smithsonianmag.com/history/when-did-filling-out-march-madness-bracket-become-popular-180950162/) article:\n>The first NCAA bracket pool—putting some money where your bracket is—is thought to have started in 1977 in a Staten Island bar. 88 people filled out brackets in the pool that year, and paid $10 in a winner-take-all format.\n\nFrom the same article, written in 2014:\n>The odds of it happening are one in 9.2 quintillion: you’re more likely to die an excruciating death by vending machine, become president, win the Mega Millions jackpot or die from incorrectly using products made for right-handed people (if you're a lefty) than fill out a perfect NCAA basketball bracket... Over 60 million Americans fill out a bracket each year, with 1 billion dollars potentially spent on off-book gambling... \n<br><br>\n>\"Some things seem so obvious, like the idea these higher seeds should beat lower seeds all the time, but that doesn’t necessarily happen, and that results in all sorts of chaos,\" explains Ken Pomeroy, creator of the college basketball website [kenpom.com](https://kenpom.com/). \"There’s that desire to try to predict something that’s difficult to predict.\"\n\n## Machine learning could help!\n[Wikipedia](https://en.wikipedia.org/wiki/Machine_learning):\n>Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on models and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task... \n<br><br>\n>Classification algorithms are used when the outputs are restricted to a limited set of values.\n\nThe limited set of output values in this case are possible tournament game outcomes: win or loss, and the training data are stats from previous seasons along with each season's tournament outcomes. The following is an attempt to predict which teams will win each game (and each possible match) of the NCAA Division I men’s basketball tournament (the 2018 tourney in this case, but easy to update for 2019):"},{"metadata":{"_uuid":"f13e27ba64787fc536fec95bdac98d1beda73526"},"cell_type":"markdown","source":"<a id='top'></a>\n\n#### BRACKET CRUNCHER OUTLINE\n\n<a href='#1'>1. THE DATA</a>\n* <a href='#1.1'>1.1 Data Cleaning</a>\n\n<a href='#2'>2. BASKETBALL STATISTICS AS FEATURES</a>\n* <a href='#2.1'>2.1 Calculate Statistics</a>\n* <a href='#2.2'>2.2 Regular Season Averages</a>\n\n<a href='#3'>3. EXPLORATORY ANALYSIS</a>\n* <a href='#3.1'>3.1 The Madness in March</a>\n* <a href='#3.2'>3.2 Teams, Conferences</a>\n* <a href='#3.3'>3.3 Features to Model</a>\n\n<a href='#4'>4. MACHINE LEARNING</a>\n* <a href='#4.1'>4.1 Logistic Regression</a>\n* <a href='#4.2'>4.2 Support Vector Machine</a>\n* <a href='#4.3'>4.3 Decision Tree</a>\n* <a href='#4.4'>4.4 Random Forest</a>\n* <a href='#4.5'>4.5 XGBoost</a>\n* <a href='#4.6'>4.6 Best Model</a>\n* <a href='#4.7'>4.7 Model Explainability</a>\n* <a href='#4.8'>4.8 Make Predictions and Build Bracket</a>\n\n\n<a href='#5'>5. RESULTS (with printable bracket)</a>\n\n<br>"},{"metadata":{"trusted":true,"_uuid":"77929b32f55e458c09354f48e9e9fe965fae9981","_kg_hide-input":false},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_columns', 200)\n%matplotlib inline\nfrom matplotlib import rcParams\nrcParams['font.family'] = 'monospace'\nfrom matplotlib.ticker import MaxNLocator\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, log_loss\n\nimport os, eli5, shap\nfrom eli5.sklearn import PermutationImportance\nfrom pdpbox import pdp\n\nprint()\nprint('The odds of correctly predicting each possible outcome for all 63 games are one in {:,}.'.format(2**63))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"828ebf9587cf8c9e77c26038af6ced0a6b3925ba"},"cell_type":"markdown","source":"<a href='#top' id='1'></a>\n\n---\n## 1. THE DATA"},{"metadata":{"trusted":true,"_uuid":"d4d20ec80506135226376a577d0977c337bdf0e8","scrolled":true},"cell_type":"code","source":"print(os.listdir('../input/mens-machine-learning-competition-2019/datafiles'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b05175ba4c068b0ab94a992a429525f56e17756"},"cell_type":"markdown","source":"`NCAATourneyCompactResults.csv`\n\n>This file identifies the game-by-game NCAA® tournament results for all seasons of historical data. The data is formatted exactly like the RegularSeasonCompactResults data. Note that these games also include the play-in games (which always occurred on day 134/135) for those years that had play-in games. Thus each season you will see between 63 and 67 games listed, depending on how many play-in games there were.\n\n>* DayNum=134 or 135 (Tue/Wed) - play-in games to get the tournament field down to the final 64 teams\n>* DayNum=136 or 137 (Thu/Fri) - Round 1, to bring the tournament field from 64 teams to 32 teams\n>* DayNum=138 or 139 (Sat/Sun) - Round 2, to bring the tournament field from 32 teams to 16 teams\n>* DayNum=143 or 144 (Thu/Fri) - Round 3, otherwise known as \"Sweet Sixteen\", to bring the tournament field from 16 teams to 8 teams\n>* DayNum=145 or 146 (Sat/Sun) - Round 4, otherwise known as \"Elite Eight\" or \"regional finals\", to bring the tournament field from 8 teams to 4 teams\n>* DayNum=152 (Sat) - Round 5, otherwise known as \"Final Four\" or \"national semifinals\", to bring the tournament field from 4 teams to 2 teams\n>* DayNum=154 (Mon) - Round 6, otherwise known as \"national final\" or \"national championship\", to bring the tournament field from 2 teams to 1 champion team"},{"metadata":{"trusted":true,"_uuid":"4b7c498d47ef9deb660e5573bf9074347244404f"},"cell_type":"code","source":"df_tourney_all = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/NCAATourneyCompactResults.csv')\ndf_tourney_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccba712299616321a5013360e20d30d7fb224b1f"},"cell_type":"markdown","source":"`RegularSeasonDetailedResults.csv`\n\n> This file provides team-level box scores for many regular seasons of historical data, starting with the 2003 season. \n\n>The column names should be self-explanatory to basketball fans (as above, \"W\" or \"L\" refers to the winning or losing team):\n\n>* WFGM - field goals made (by the winning team)\n>* WFGA - field goals attempted (by the winning team)\n>* WFGM3 - three pointers made (by the winning team)\n>* WFGA3 - three pointers attempted (by the winning team)\n>* WFTM - free throws made (by the winning team)\n>* WFTA - free throws attempted (by the winning team)\n>* WOR - offensive rebounds (pulled by the winning team)\n>* WDR - defensive rebounds (pulled by the winning team)\n>* WAst - assists (by the winning team)\n>* WTO - turnovers committed (by the winning team)\n>* WStl - steals (accomplished by the winning team)\n>* WBlk - blocks (accomplished by the winning team)\n>* WPF - personal fouls committed (by the winning team)"},{"metadata":{"trusted":true,"_uuid":"bab06802b6e6fa74a8e4575a7418ccfade176c4d"},"cell_type":"code","source":"df = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/RegularSeasonDetailedResults.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caff80794118e240056d69fcf77788b46050861a"},"cell_type":"markdown","source":"<a href='#top' id='1.1'>return to menu</a>\n\n## 1.1 Data Cleaning\nNot much to clean up, but including team and conference names would be nice in graphs!"},{"metadata":{"trusted":true,"_uuid":"4c20bec0676308b24bb14af9b993f09ebc533856"},"cell_type":"code","source":"# Drop columns that are not needed:\ndf = df.drop(['DayNum', 'WLoc', 'NumOT'], axis=1)\n\n# Save dataframes with Team and Conference names:\ndf_teams = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/Teams.csv')\ndf_team_conferences = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/TeamConferences.csv')\ndf_conferences = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/Conferences.csv')\n\n# Merge the conference dataframes to eventually use the full conference name:\ndf_conference_names = df_team_conferences.merge(df_conferences, on=['ConfAbbrev'])\n\n# Pre-merge tidying to match with winner and loser IDs:\nwin_teams = df_teams.rename(columns={'TeamID':'WTeamID'})[['WTeamID', 'TeamName']]\nwin_confs = df_conference_names.rename(columns={'TeamID':'WTeamID'})[['Season', 'WTeamID', 'Description']]\nlose_teams = df_teams.rename(columns={'TeamID':'LTeamID'})[['LTeamID', 'TeamName']]\nlose_confs = df_conference_names.rename(columns={'TeamID':'LTeamID'})[['Season', 'LTeamID', 'Description']]\n\n# Merge winning team name and conference, losing team name and conference with season results:\ndf = df.merge(win_teams, on='WTeamID').rename(columns={'TeamName': 'WTeamName'}) \\\n.merge(win_confs, on=['Season', 'WTeamID']).rename(columns={'Description': 'WConfName'}) \\\n.merge(lose_teams, on='LTeamID').rename(columns={'TeamName': 'LTeamName'}) \\\n.merge(lose_confs, on=['Season', 'LTeamID']).rename(columns={'Description': 'LConfName'})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d12de1e75f58b5f44fcb83f0390d0d41f696c5b3"},"cell_type":"code","source":"df['WFGM2'] = df.WFGM - df.WFGM3\ndf['WFGA2'] = df.WFGA - df.WFGA3\ndf['LFGM2'] = df.LFGM - df.LFGM3\ndf['LFGA2'] = df.LFGA - df.LFGA3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fee9e4fea970a3da1c77da3f1e70281aa4a8038f"},"cell_type":"code","source":"print('These are the {} conferences that have participated in NCAA Division I men\\'s basketball with the number of wins in the dataset for each:'.format(len(df.WConfName.value_counts())))\ndf.WConfName.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f036cb11716ec800c6b542b4659f4e7c39d5757d"},"cell_type":"code","source":"print('Season  #Games:')\ndf.Season.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1839269c7e9b12325fdcf75e2300ee6be3241e15"},"cell_type":"markdown","source":"So, the machine learning model will analyze how 2003-2017 season statistics are related to the 2003-2017 tournament outcomes. It will then apply what it 'understands' about that relationship to make predictions for the 2018 tournament games based on 2018 season statistics."},{"metadata":{"_uuid":"ba64794d3e3799511de5d1e6fcf860badfba548a"},"cell_type":"markdown","source":"<a href='#top' id='2'>return to menu</a>\n\n---\n## 2. BASKETBALL STATISTICS AS FEATURES\nBox-score data are used to calculate basketball statistics. These are the features to analyze and possibly model.\n\n### Possession\nA team's possession ends when the team: 1) makes a field goal, 2) misses and fails to get the rebound, 3) turns the ball over, or 4) either makes the last free throw or does not get the rebound. (Or the period ends.) This can be estimated as:\n\n$$ \\text{poss} = \\text{FGA} - \\text{OR} + \\text{TO} + 0.475\\text{FTA} $$\n\nIn any game, the number of possessions is nearly equal for both teams, so **efficiency wins**!\n\n---\n## EFFICIENCY -\n### Shooting Efficiency\nNumber of points per shooting opportunity, estimated as:\n\n$$ \\text{shoot_eff} = \\frac{\\text{Score}}{\\text{FGA} + 0.475\\text{FTA}} $$\n\n### Scoring Opportunity\nNumber of scoring attempts, estimated as:\n\n$$ \\text{score_op} = \\frac{\\text{FGA} + 0.475\\text{FTA}}{\\text{poss}} $$\n\n### Offensive Rating\nPoints scored per 100 possessions, estimated as:\n\n$$ \\text{off_rtg} = \\frac{\\text{Score}}{\\text{poss}}  \\times 100$$\n\n### Defensive Rating\nA team's defensive rating is their opponent's offensive rating:\n\n$$ \\text{def_rtg} = \\text{opp_off_rtg} $$\n\n### Net Efficiency\nSometimes also referred to as **Strength of Schedule**:\n\n$$ \\text{sos} = \\text{off_rtg} - \\text{opp_off_rtg} $$\n\n---\n## MORE ON SHOOTING -\n### True Shooting Percentage\nSimilar to shooting efficiency but accounts for free throws, estimated as:\n\n$$ \\text{ts_pct} = \\frac{\\text{Score}}{2(\\text{FGA} + 0.475\\text{FTA})} \\times 100$$\n\n\n### Effective Field Goal Percentage\nAdjusts for the fact that some field goals are worth more points than others, estimated as:\n\n$$  \\text{efg_pct} = \\frac{\\text{FGM2} + 1.5\\text{FGM3}}{\\text{FGA}} $$\n\n\n---\n## REBOUNDING -\n### Offensive Rebound  Percentage\n$$ \\text{orb_pct} =  \\frac{\\text{OR}}{\\text{OR} + \\text{opp_DR}} $$\n\n### Defensive Rebound  Percentage\n$$ \\text{drb_pct} =  \\frac{\\text{DR}}{\\text{DR} + \\text{opp_OR}} $$\n\n### Rebound  Percentage\n$$ \\text{reb_pct} =  \\frac{\\text{orb_pct} + \\text{drb_pct}}{2} $$\n\n\n---\n## OLIVER'S FOUR FACTORS -\nShoot, protect, recover, draw, frustrate! I know that's five; keep reading: \n\n*Basketball on Paper* author [Dean Oliver](http://www.basketballonpaper.com/author.html) outlines four factors that determine success in basketball:\n1. Effective Field Goal Percentage\n<br><br>\n2. **Turnovers per Possession** \n$$ \\text{to_poss} = \\frac{\\text{TO}}{\\text{poss}} $$\n<br><br>\n3. Offensive Rebound Percentage\n<br><br>\n4. **Free Throw Rate**\n$$ \\text{ft_rate} = \\frac{\\text{FTM}}{\\text{FGA}} $$\n\nSo, a team must shoot the ball well, take care of the ball (avoid turnovers), get back missed shots and get to the free throw line (and make them). But Oliver also stresses that these are important to both offense and defense. A team should cover the four factors, but should frustrate their opponent's efforts to do the same.\n\n\n---\n## OTHER FEATURES TO CONSIDER -\n\nFrom the [NBA Advanced Stats](https://stats.nba.com/help/faq/) page:\n> #### What is PACE? What does PACE tell fans besides the speed of the game?\nEach team plays at a faster or slower pace, thus inflating or deflating player and team statistics. It is important to look at stats at a per possession level, rather than simply looking at points scored per game.\n> #### What is PIE?\nIt is a simple metric that gives an excellent indication of performance at both the team and player level. It’s a major improvement to our EFF Rating. Notably 2 things changed: (1) We included Personal Fouls, (2) We added a denominator. We feel the key here is the denominator because it acts as an \"automatic equalizer\". Using the denominator, we find there is no need to consider the \"PACE\" of the statistics that are being analyzed. In its simplest terms, PIE shows what % of game events did that player or team achieve. The stats being analyzed are your traditional basketball statistics (PTS, REB, AST, TOV, etc..) A team that achieves more than 50% is likely to be a winning team. A player that achieves more than 10% is likely to be better than the average player. A high PIE % is highly correlated to winning. In fact, a team’s PIE rating and a team’s winning percentage correlate at an R square of .908 which indicates a \"strong\" correlation. We’ve introduced this statistic because we feel it incorporates a bit of defense into the equation. When a team misses a shot, all 5 players on the other team’s PIE rating goes up.\n\n### Team Impact Estimate\n$$ \\text{IE_numerator} = \\text{Score} + \\text{FGM} + \\text{FTM} - \\text{FGA} - \\text{FTA} + \\text{DR} + 0.5\\text{OR} + \\text{Ast} + \\text{Stl} + 0.5\\text{Blk} - \\text{PF} - \\text{TO} $$\n\n$$ \\text{IE} = \\frac{\\text{IE_numerator}}{\\text{IE_numerator} + \\text{opp_IE_numerator}} $$\n\n### Assist Ratio\nThe percentage of a team's possessions that end in an assist:\n\n$$ \\text{ast_rtio} = \\frac{\\text{Ast}}{\\text{FGA} + 0.475\\text{FTA} + \\text{TO} + \\text{Ast}} \\times 100 $$\n\n### Block Percentage\nIndicates that a team blocked $n\\%$ of its opponents' shots:\n\n$$ \\text{blk_pct} = \\frac{\\text{Blk}}{\\text{opp_FGA2}} \\times 100 $$\n\n\n### Steal Percentage\nIndicates that the team stole the ball for $n\\%$ of its opponents' possessions:\n\n$$ \\text{stl_pct} = \\frac{\\text{Stl}}{\\text{opp_poss}} \\times 100 $$\n\n"},{"metadata":{"trusted":true,"_uuid":"b70b08890668448c33da88e9f93a11a02f752edf"},"cell_type":"code","source":"# Check winner boxscore data needed to calculate stats:\ndf[['WFGA', 'WFTA', 'WTO', 'WOR', 'WScore', 'WFGM2', 'WFGM3', 'WFGM', 'WFTM', 'WDR', 'WAst', 'WStl', 'WBlk', 'WPF']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9c5d02d891d06c495d9487594cfc7997354548b"},"cell_type":"code","source":"# Check loser boxscore data needed to calculate stats:\ndf[['LFGA', 'LFTA', 'LTO', 'LOR', 'LScore', 'LFGM2', 'LFGM3', 'LFGM', 'LFTM', 'LDR', 'LAst', 'LStl', 'LBlk', 'LPF']].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"209f2780d8174a9d915b79448b672dee64ec7af7"},"cell_type":"markdown","source":"<a href='#top' id='2.1'>return to menu</a>\n\n## 2.1 Calculate Statistics"},{"metadata":{"trusted":true,"_uuid":"ab759f0e3ebf5997275552ab5a077c74dee05a5a"},"cell_type":"code","source":"# Winner stats related to offensive efficiency:\ndf['Wposs'] = df.apply(lambda row: row.WFGA + 0.475 * row.WFTA + row.WTO - row.WOR, axis=1)\ndf['Wshoot_eff'] = df.apply(lambda row: row.WScore / (row.WFGA + 0.475 * row.WFTA), axis=1)\ndf['Wscore_op'] = df.apply(lambda row: (row.WFGA + 0.475 * row.WFTA) / row.Wposs, axis=1)\ndf['Woff_rtg'] = df.apply(lambda row: row.WScore/row.Wposs*100, axis=1)\n\n# Loser stats related to offensive efficiency:\ndf['Lposs'] = df.apply(lambda row: row.LFGA + 0.475 * row.LFTA + row.LTO - row.LOR, axis=1)\ndf['Lshoot_eff'] = df.apply(lambda row: row.LScore / (row.LFGA + 0.475 * row.LFTA), axis=1)\ndf['Lscore_op'] = df.apply(lambda row: (row.LFGA + 0.475 * row.LFTA) / row.Lposs, axis=1)\ndf['Loff_rtg'] = df.apply(lambda row: row.LScore/row.Lposs*100, axis=1)\n\n# Defensive and net efficiency:\ndf['Wdef_rtg'] = df.apply(lambda row: row.Loff_rtg, axis=1)\ndf['Wsos'] = df.apply(lambda row: row.Woff_rtg - row.Loff_rtg, axis=1)\ndf['Ldef_rtg'] = df.apply(lambda row: row.Woff_rtg, axis=1)\ndf['Lsos'] = df.apply(lambda row: row.Loff_rtg - row.Woff_rtg, axis=1)\n\n# Impact Estimate - \n# First calculate the teams' overall statistical contribution (the numerator):\nWie = df.apply(lambda row: row.WScore + row.WFGM + row.WFTM - row.WFGA - row.WFTA + row.WDR + (0.5 * row.WOR) + row.WAst + row.WStl + (0.5 * row.WBlk) - row.WPF - row.WTO, axis=1)\nLie = df.apply(lambda row: row.LScore + row.LFGM + row.LFTM - row.LFGA - row.LFTA + row.LDR + (0.5 * row.LOR) + row.LAst + row.LStl + (0.5 * row.LBlk) - row.LPF - row.LTO, axis=1)\n\n# Then divide by the total game statistics (the denominator):\ndf['Wie'] = Wie / (Wie + Lie) * 100\ndf['Lie'] = Lie / (Lie + Wie) * 100\n\n# Other winner stats:\ndf['Wts_pct'] = df.apply(lambda row: row.WScore / (2 * (row.WFGA + 0.475 * row.WFTA)) * 100, axis=1)\ndf['Wefg_pct'] = df.apply(lambda row: (row.WFGM2 + 1.5 * row.WFGM3) / row.WFGA, axis=1)\ndf['Worb_pct'] = df.apply(lambda row: row.WOR / (row.WOR + row.LDR), axis=1)\ndf['Wdrb_pct'] = df.apply(lambda row: row.WDR / (row.WDR + row.LOR), axis=1)\ndf['Wreb_pct'] = df.apply(lambda row: (row.Worb_pct + row.Wdrb_pct) / 2, axis=1)\ndf['Wto_poss'] = df.apply(lambda row: row.WTO / row.Wposs, axis=1)\ndf['Wft_rate'] = df.apply(lambda row: row.WFTM / row.WFGA, axis=1)\ndf['Wast_rtio'] = df.apply(lambda row: row.WAst / (row.WFGA + 0.475*row.WFTA + row.WTO + row.WAst) * 100, axis=1)\ndf['Wblk_pct'] = df.apply(lambda row: row.WBlk / row.LFGA2 * 100, axis=1)\ndf['Wstl_pct'] = df.apply(lambda row: row.WStl / row.Lposs * 100, axis=1)\n\n# Other loser stats:\ndf['Lts_pct'] = df.apply(lambda row: row.LScore / (2 * (row.LFGA + 0.475 * row.LFTA)) * 100, axis=1)\ndf['Lefg_pct'] = df.apply(lambda row: (row.LFGM2 + 1.5 * row.LFGM3) / row.LFGA, axis=1)\ndf['Lorb_pct'] = df.apply(lambda row: row.LOR / (row.LOR + row.WDR), axis=1)\ndf['Ldrb_pct'] = df.apply(lambda row: row.LDR / (row.LDR + row.WOR), axis=1)\ndf['Lreb_pct'] = df.apply(lambda row: (row.Lorb_pct + row.Ldrb_pct) / 2, axis=1)\ndf['Lto_poss'] = df.apply(lambda row: row.LTO / row.Lposs, axis=1)\ndf['Lft_rate'] = df.apply(lambda row: row.LFTM / row.LFGA, axis=1)\ndf['Last_rtio'] = df.apply(lambda row: row.LAst / (row.LFGA + 0.475*row.LFTA + row.LTO + row.LAst) * 100, axis=1)\ndf['Lblk_pct'] = df.apply(lambda row: row.LBlk / row.WFGA2 * 100, axis=1)\ndf['Lstl_pct'] = df.apply(lambda row: row.LStl / row.Wposs * 100, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cf3d1c1edc8667c8726398133f37e701a968ae9"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f8c049bac0257f5fd639cc9a991c9f061486223"},"cell_type":"markdown","source":"<a href='#top' id='2.2'>return to menu</a>"},{"metadata":{"_uuid":"edc607b242a3c1ef7462e21fc62b94cbd8418017"},"cell_type":"markdown","source":"## 2.2 Regular Season Averages"},{"metadata":{"trusted":true,"_uuid":"3161731f95b252fe67f01281a27e17e0094a1a4c"},"cell_type":"code","source":"# Initialize dataframe to hold season averages:\ndf_avgs = pd.DataFrame()\n\n# Get and save number of wins and losses:\ndf_avgs['n_wins'] = df['WTeamID'].groupby([df.Season, df.WTeamID, df.WTeamName, df.WConfName]).count()\ndf_avgs['n_loss'] = df['LTeamID'].groupby([df.Season, df.LTeamID, df.LTeamName, df.LConfName]).count()\n\ndf_avgs['n_loss'].fillna(0, inplace=True)\n\n# Calculate win percentages:\ndf_avgs['win_pct'] = df_avgs['n_wins'] / (df_avgs['n_wins'] + df_avgs['n_loss'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e491e59e94e757a90a5645280bedc941494231ef"},"cell_type":"code","source":"# Calculate averages for games won:\ndf_avgs['Wshoot_eff'] = df['Wshoot_eff'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wscore_op'] = df['Wscore_op'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Woff_rtg'] = df['Woff_rtg'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wdef_rtg'] = df['Wdef_rtg'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wsos'] = df['Wsos'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wts_pct'] = df['Wts_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wefg_pct'] = df['Wefg_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Worb_pct'] = df['Worb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wdrb_pct'] = df['Wdrb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wreb_pct'] = df['Wreb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wto_poss'] = df['Wto_poss'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wft_rate'] = df['Wft_rate'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wie'] = df['Wie'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wast_rtio'] = df['Wast_rtio'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wblk_pct'] = df['Wblk_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Wstl_pct'] = df['Wstl_pct'].groupby([df['Season'], df['WTeamID']]).mean()\n\n# Calculate averages for games lost:\ndf_avgs['Lshoot_eff'] = df['Lshoot_eff'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lscore_op'] = df['Lscore_op'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Loff_rtg'] = df['Loff_rtg'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Ldef_rtg'] = df['Ldef_rtg'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lsos'] = df['Lsos'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lts_pct'] = df['Lts_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lefg_pct'] = df['Lefg_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lorb_pct'] = df['Lorb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Ldrb_pct'] = df['Ldrb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lreb_pct'] = df['Lreb_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lto_poss'] = df['Lto_poss'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lft_rate'] = df['Lft_rate'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lie'] = df['Lie'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Last_rtio'] = df['Last_rtio'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lblk_pct'] = df['Lblk_pct'].groupby([df['Season'], df['WTeamID']]).mean()\ndf_avgs['Lstl_pct'] = df['Lstl_pct'].groupby([df['Season'], df['WTeamID']]).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af5f8e4394fe2a0c1430b7cc8a9e11d014b6a338"},"cell_type":"code","source":"# Calculate weighted average using win percentage:\ndf_avgs['shoot_eff'] = df_avgs['Wshoot_eff'] * df_avgs['win_pct'] + df_avgs['Lshoot_eff'] * (1 - df_avgs['win_pct'])\ndf_avgs['score_op'] = df_avgs['Wscore_op'] * df_avgs['win_pct'] + df_avgs['Lscore_op'] * (1 - df_avgs['win_pct'])\ndf_avgs['off_rtg'] = df_avgs['Woff_rtg'] * df_avgs['win_pct'] + df_avgs['Loff_rtg'] * (1 - df_avgs['win_pct'])\ndf_avgs['def_rtg'] = df_avgs['Wdef_rtg'] * df_avgs['win_pct'] + df_avgs['Ldef_rtg'] * (1 - df_avgs['win_pct'])\ndf_avgs['sos'] = df_avgs['Wsos'] * df_avgs['win_pct'] + df_avgs['Lsos'] * (1 - df_avgs['win_pct'])\ndf_avgs['ts_pct'] = df_avgs['Wts_pct'] * df_avgs['win_pct'] + df_avgs['Lts_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['efg_pct'] = df_avgs['Wefg_pct'] * df_avgs['win_pct'] + df_avgs['Lefg_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['orb_pct'] = df_avgs['Worb_pct'] * df_avgs['win_pct'] + df_avgs['Lorb_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['drb_pct'] = df_avgs['Wdrb_pct'] * df_avgs['win_pct'] + df_avgs['Ldrb_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['reb_pct'] = df_avgs['Wreb_pct'] * df_avgs['win_pct'] + df_avgs['Lreb_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['to_poss'] = df_avgs['Wto_poss'] * df_avgs['win_pct'] + df_avgs['Lto_poss'] * (1 - df_avgs['win_pct'])\ndf_avgs['ft_rate'] = df_avgs['Wft_rate'] * df_avgs['win_pct'] + df_avgs['Lft_rate'] * (1 - df_avgs['win_pct'])\ndf_avgs['ie'] = df_avgs['Wie'] * df_avgs['win_pct'] + df_avgs['Lie'] * (1 - df_avgs['win_pct'])\ndf_avgs['ast_rtio'] = df_avgs['Wast_rtio'] * df_avgs['win_pct'] + df_avgs['Last_rtio'] * (1 - df_avgs['win_pct'])\ndf_avgs['blk_pct'] = df_avgs['Wblk_pct'] * df_avgs['win_pct'] + df_avgs['Lblk_pct'] * (1 - df_avgs['win_pct'])\ndf_avgs['stl_pct'] = df_avgs['Wstl_pct'] * df_avgs['win_pct'] + df_avgs['Lstl_pct'] * (1 - df_avgs['win_pct'])\n\ndf_avgs.reset_index(inplace = True)\ndf_avgs = df_avgs.rename(columns={'WTeamID': 'TeamID', 'WTeamName': 'TeamName', 'WConfName': 'ConfName'})\ndf_avgs.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1dbc8b909339a5cdb4eece8933e30b59f5d7508a"},"cell_type":"markdown","source":"<a href='#top' id='3'>return to menu</a>\n\n---\n## 3. EXPLORATORY ANALYSIS\nThis is a look at what all of those statistics indicate about teams and conferences. First, an exploration of why the tournament is so damn exciting:  \n\n<a href='#top' id='3.1'></a>\n\n## 3.1 The Madness in March\nNote that while some define upsets differently, in this notebook they are simply games for which the winning seed number was greater than the losing seed number."},{"metadata":{"trusted":true,"_uuid":"6968f54ae869d83a4bd88f05a72e69f3db89198c"},"cell_type":"code","source":"def tourn_round(DayNum):\n    \"\"\"\n    Consolidate tournament rounds into meaningful info.\n    \"\"\"\n    if (DayNum == 136) | (DayNum == 137):\n        return 64\n    elif (DayNum == 138) | (DayNum == 139):\n        return 32\n    elif (DayNum == 143) | (DayNum == 144):\n        return 16\n    elif (DayNum == 145) | (DayNum == 146):\n        return 8\n    elif DayNum == 152:\n        return 4\n    elif DayNum == 154:\n        return 2\n    else:\n        return 68\n    \ndf_tourney_all['tourn_round'] = df_tourney_all.DayNum.apply(tourn_round)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"917666b1b1072f3dcff9401fc9f5d83fdb47f9ae"},"cell_type":"code","source":"df_seeds = pd.read_csv('../input/mens-machine-learning-competition-2019/datafiles/NCAATourneySeeds.csv')\n\n# Get the seed number by taking the last two characters of 'Seed' values:\ndf_seeds['seed'] = df_seeds['Seed'].apply(lambda x : int(x[1:3]))\ndf_seeds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d7c2f453e6d565fb0b01e3c544fd223751c1ca2"},"cell_type":"code","source":"# Drop the old 'Seed' column:\ndf_seeds = df_seeds[['Season', 'TeamID', 'seed']]\n\n# Merge seeds, team names, and conference names with tournament data:\ndf_tourney_all = df_tourney_all.merge(df_seeds, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID']) \\\n.rename(columns={'seed': 'Wseed'}).drop(['TeamID'], axis=1) \\\n.merge(df_seeds, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID']) \\\n.rename(columns={'seed': 'Lseed'}).drop(['TeamID'], axis=1) \\\n.merge(win_teams, on='WTeamID').rename(columns={'TeamName': 'WTeamName'}) \\\n.merge(win_confs, on=['Season', 'WTeamID']).rename(columns={'Description': 'WConfName'}) \\\n.merge(lose_teams, on='LTeamID').rename(columns={'TeamName': 'LTeamName'}) \\\n.merge(lose_confs, on=['Season', 'LTeamID']).rename(columns={'Description': 'LConfName'})\n\n# Calculate the point differential:\ndf_tourney_all['point_diff'] = df_tourney_all.WScore - df_tourney_all.LScore","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3468506f0fea827a7da02f2747245e5d4e03c95a"},"cell_type":"code","source":"df_tourney_all = df_tourney_all[df_tourney_all.Season < 2018]\ndf_tourney_all.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"792fce025de8fc0b1978bb824742a92df85b0707"},"cell_type":"code","source":"def plot_seed_scale():\n    \"\"\"\n    Plot a scale reference of how seeds are represented in this notebook.\n    \"\"\"\n    # Save list of seed integers:\n    seeds = np.arange(16)+1\n    \n    # Set scatter points to the first color if the winning seed >8, otherwise set it to the second color:\n    colors = np.where(seeds > 8, '#3c7f99', '#c5b783')\n    \n    # Scale the point sizes to reflect winning seed:\n    point_size = seeds*100\n    \n    # Plot the seed points in a single line (`y=np.zeros(len(seeds)`):\n    fig, ax = plt.subplots(figsize=(12, 1))\n    plt.scatter(x=seeds, y=np.zeros(len(seeds), dtype=int), color=colors, alpha=0.35, s=point_size)\n    plt.scatter(x=seeds, y=np.zeros(len(seeds), dtype=int), color=colors)\n    plt.box(False)\n\n    # Showw all of the xticks and only one ytick:\n    plt.xticks(seeds), plt.yticks(np.arange(1), (''))\n\n    # Set the ylabel by retrieving an indexed list of labels and changing the first (and only):\n    labels = [item.get_text() for item in ax.get_yticklabels()]\n    labels[0] = '  Seed Scale: '\n    ax.set_yticklabels(labels, fontsize=14)\n\n    # Remove tick marks:\n    plt.tick_params(axis='both', which='both',length=0);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"f2b8a584da751061b4c0dac04134a948a38082be","_kg_hide-input":true},"cell_type":"code","source":"# Save a dataframe of the last 5 years and only games between the final 64 tournament teams:\nmadness = df_tourney_all[(df_tourney_all.Season >= 2013) & (df_tourney_all.tourn_round <= 64)]\nmadness.sort_values(by='tourn_round', ascending=False, inplace=True)\n\n# Set scatter points to the first color if the winning seed >8, otherwise set it to the second color:\ncolors = np.where(madness.Wseed > 8, '#3c7f99', '#c5b783')\n\n# Scale the point sizes to reflect winning seed:\npoint_size = madness.Wseed*100\n\nrounds = ('Round One', 'Round Two', 'Sweet Sixteen', 'Elite Eight', 'Final Four', 'Championship')\n\n# Plot point differential by round, using color and size to reveal winning seed characteristics:\nfig, ax = plt.subplots(figsize=(12, 8))\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.35, s=point_size)\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.75)\nplt.box(False) # get rid of border\n\n# Titles and subtitles:\nfig.text(x=-0.05, y=1.1, s='             This is the Madness!             ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=-0.05, y=1, s='  The first two rounds are the most intense. Though upsets are frequently tight, \\n  obviously this is not always true. Still, the better seeds tend to advance.', fontsize=18)\nplt.title('Seasons 2013-2017', fontsize=16)\n\n# Reverse the y-axis to reflect tournament progression:\nplt.ylim(plt.ylim()[::-1])\n\n# Tick marks and labels, x-axis label -\n# Get rid of tick marks:\nplt.tick_params(axis='both', which='both', length=0)\n\n# Set tick label font size:\nplt.tick_params(axis='both', which='major', labelsize=16)\n\n# Label y-ticks according to tourney round:\nplt.yticks(np.arange(len(rounds)), rounds)\n\n# Label x-axis and show grid lines:\nax.xaxis.grid(which='both', linewidth=0.75)\nplt.xlabel('Point Differential', fontsize=18)\n\n# Add an info bar at the bottom:\nfig.text(x=-0.05, y=0, s=' outer point size = winner seed                         dark points: underdog win ', fontsize=18, weight='bold', color='white', backgroundcolor='#3c7f99')\n\n# Show the full scale of winning seed representation:\nplot_seed_scale();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ea6b58d4f433ac327b1ff98712d9e4ab284b959"},"cell_type":"code","source":"# Championship game statistics for 2013 - 2017:\ndf_tourney_all[(df_tourney_all.Season >= 2013) & (df_tourney_all.tourn_round == 2)].sort_values(by='Season')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ed90b035b705754c6b7046c6be95382175078ef"},"cell_type":"markdown","source":"[2014 NCAA Division I Men's Basketball Tournament, Wikipedia](https://en.wikipedia.org/wiki/2014_NCAA_Division_I_Men%27s_Basketball_Tournament):\n>With No. 7 seed Connecticut and No. 8 seed Kentucky reaching the championship game, this tournament's final was the first ever not to include at least one 1, 2, or 3 seed. It is also only the third final not to feature a 1 or 2 seed (1989 - #3 Michigan vs. #3 Seton Hall and 2011 - #3 Connecticut vs. #8 Butler). Connecticut was the first 7 seed ever to reach and win the championship game. \n\nBut the big Final Four outlier is that Villanova (2) beat Oklahoma (2) 95-51 in 2016! In fact, without that game, there's an obvious trend toward tighter games as the tournament progresses."},{"metadata":{"_uuid":"ef1d5dd67a97abbb1bcc0a45c54bbc46240105ab"},"cell_type":"markdown","source":"---\nSIDE NOTE: Round One (field of 64 teams, for a total of 32 games) is why work productivity during those first two days (always Thurs/Fri) is questioned every year. According to [CNBC](https://www.cnbc.com/2018/03/06/march-madness-takes-a-toll-on-productivity.html) (2018), \"unproductive workers during March Madness amounted to an estimated $6.3 billion in corporate losses last year.\" I'd like to argue (based on my own experience) that it's great for workplace morale!"},{"metadata":{"trusted":true,"_uuid":"ea714709211ba0e791f62a9df20fb07db700b5e4","_kg_hide-input":true},"cell_type":"code","source":"# Save dataframe plot to include all seasons and only games between the final 64 tournament teams:\nmadness = df_tourney_all[df_tourney_all.tourn_round <= 64]\nmadness.sort_values(by='tourn_round', ascending=False, inplace=True)\n\n# Set scatter points to the first color if the winning seed >8, otherwise set it to the second color:\ncolors = np.where(madness.Wseed > 8, '#3c7f99', '#c5b783')\n\n# Scale the point sizes to reflect winning seed:\npoint_size = madness.Wseed*100\n\n# Plot point differential by round, using color and size to reveal winning seed characteristics:\nfig, ax = plt.subplots(figsize=(12, 8))\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.35, s=point_size)\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.75)\nplt.box(False)\n\nplt.title('All Tournament Wins, All Seasons   ', fontsize=32)\n\n# Reverse the y-axis to reflect tournament progression:\nplt.ylim(plt.ylim()[::-1])\n\n# Tick marks and labels, x-axis label -\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nplt.yticks(np.arange(len(rounds)), rounds)\nax.xaxis.grid(which='both', linewidth=0.75)\nplt.xlabel('Point Differential', fontsize=18)\n\nplot_seed_scale();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"66346350ec8e36125d2a0eb1303a7052bb66556d"},"cell_type":"markdown","source":"That Final Four Villanova blowout continues to exist as an outlier when all seasons are included. Without it, the highest point differential for each round is smaller than the highest for the previous round.\n\nNo Round One underdog (seed > 8) has ever been successful in the Final Four! (and only a few have made it that far)"},{"metadata":{"trusted":true,"_uuid":"c752de4b0b6334f7b0a312468d4d5e6b617df0d3","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot a count of every winning seed in the championship round:\nsns.countplot(x=df_tourney_all[df_tourney_all.tourn_round == 2].Wseed, color='#3c7f99')\nplt.box(False)\n\nfig.text(x=0, y=1, s='       Championships per Seed since 1985       ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nplt.title('(When the tournament field expanded to 64 teams.)', fontsize=18)\n\n\nax.yaxis.set_major_locator(MaxNLocator(integer=True, steps=[1, 2, 5, 10]))\nax.yaxis.grid(which='both', linewidth=0.5, color='#3c7f99')\n\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nplt.ylabel('Number of Championships', fontsize=14), plt.xlabel('Tournament Seed', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8fee5011a465ee74a49c94c98a16f02c415cf98","_kg_hide-input":true},"cell_type":"code","source":"championships = df_tourney_all[df_tourney_all.tourn_round == 2]\n\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.countplot(y=championships.WTeamName, order=championships.WTeamName.value_counts().index, color='#3c7f99')\nplt.box(False)\n\nfig.text(x=-0.05, y=0.95, s='       Championships per Team since 1985       ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nplt.title('(When the tournament field expanded to 64 teams.)', fontsize=18)\n\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nax.xaxis.grid(which='both', linewidth=0.5, color='#3c7f99')\nplt.xlabel(''), plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc5b3e600fa696bab184db017c702f731a284cd9"},"cell_type":"markdown","source":"From that Smithsonian [article](https://www.smithsonianmag.com/history/when-did-filling-out-march-madness-bracket-become-popular-180950162/) in the intro:\n>Forty years ago, picking a winner in the NCAA tournament was easy (spell it with me: U-C-L-A)... It wasn't until the tournament expanded to 64 teams—and upsets became easier—that the NCAA bracket became a national phenomenon.\n\n"},{"metadata":{"_uuid":"07795b48187b53f6e84d4dd57b824e8e60f7c45a"},"cell_type":"markdown","source":"But enough about the championship. If a team can't get through that crazy first round..."},{"metadata":{"trusted":true,"_uuid":"2cb7a32d484697b5b3defd0dac2b148c25e90529","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12, 8))\nsns.countplot(x=df_tourney_all[df_tourney_all.tourn_round == 64].Wseed, color='#3c7f99')\nplt.box(False)\n\nfig.text(x=0, y=0.95, s='       First Round Wins by Seed since 1985     ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nplt.title('(When the tournament field expanded to 64 teams.)', fontsize=18)\n\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nax.yaxis.grid(which='both', linewidth=0.5, color='#3c7f99')\nplt.xlabel(''), plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9aff240be42948e7acd6a9c34faa56485d914aa3"},"cell_type":"markdown","source":"Fans of the tournament are familiar with 12-5 upsets, and this shows why. They certainly happen more than expected. While the trend of wins for the top 4 seeds is no surprise, there's a dramatic drop in wins for 5, 6, and 7 seeds. Count on excitement from some 10, 11, 12 seeds!\n\n(Also, this obviously doesn't include the 2018 tournament when a number 16 beat a number 1 for the first time.)"},{"metadata":{"trusted":true,"_uuid":"01daf0ce7b86d0ff6be556cfb4c3823c18ddceb1","_kg_hide-input":true},"cell_type":"code","source":"upsets = df_tourney_all[df_tourney_all.Wseed > df_tourney_all.Lseed]\nupset_counts = upsets.groupby(['Season'], as_index=False).Wseed.count().rename(columns={'Wseed': 'upset_count'})\n\nfig, ax = plt.subplots(figsize=(12, 8))\nsns.lineplot(x=upset_counts.Season, y=upset_counts.upset_count, marker='d', color='#3c7f99')\nplt.box(False)\n\nfig.text(x=0, y=0.95, s='          Tournament Upsets by Season        ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nplt.title('The history of upsets looks like my heart rhythm during an upset!', fontsize=18)\n\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nax.yaxis.grid(which='both', color='#c5b783')\nplt.xlabel(''), plt.ylabel('Number of Upsets', fontsize=16)\n\n# Add an info bar at the bottom:\nfig.text(x=0, y=0, s='              upset: winning seed number > losing seed number                  ', fontsize=18, weight='bold', color='white', backgroundcolor='#3c7f99');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60a2f0003ac1d070e5bf1bfa46804b19a600cf24"},"cell_type":"markdown","source":"There are at least 12 upsets per tournament, and 5 tournaments experienced more than 20. The greatest number occurred in the 1999 tournament:"},{"metadata":{"trusted":true,"_uuid":"b223df7766cf2c9e9d711c41c19c1f8bd73bda78","_kg_hide-input":true},"cell_type":"code","source":"# Save dataframe plot to include all seasons and only games between the final 64 tournament teams:\nmadness = df_tourney_all[(df_tourney_all.tourn_round <= 64) & (df_tourney_all.Season == 1999)]\nmadness.sort_values(by='tourn_round', ascending=False, inplace=True)\n\ncolors = np.where(madness.Wseed > 8, '#3c7f99', '#c5b783')\npoint_size = madness.Wseed*100\n\nfig, ax = plt.subplots(figsize=(12, 8))\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.35, s=point_size)\nplt.scatter(madness.point_diff, madness.tourn_round.astype(str), color=colors, alpha=0.75)\nplt.box(False)\n\nplt.title('1999 Tournament Wins   ', fontsize=32)\n\n# Reverse the y-axis:\nplt.ylim(plt.ylim()[::-1])\n\n# Tick marks and labels, x-axis label -\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\nplt.yticks(np.arange(len(rounds)), rounds)\nax.xaxis.grid(which='both', linewidth=0.75)\nplt.xlabel('Point Differential', fontsize=18)\n\nplot_seed_scale();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc8d90ab3ae5e451ffb8b0b288642a980febc501"},"cell_type":"markdown","source":"<a href='#top' id='3.2'>return to menu</a>\n\n## 3.2 Teams, Conferences\nAs the graphs above demonstrate, and despite all of those upsets, if a team expects to advance, earning a better seed may matter. This means a Final Four hopeful **must** kick ass during the season."},{"metadata":{"trusted":true,"_uuid":"40d406fbbf2eb64472aa0167f5e367313b07e0bd","_kg_hide-input":true},"cell_type":"code","source":"sns.set_style({'xtick.bottom': False, 'ytick.left': False})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a10a232784a0fa19467ec3fe4eabdb5f0b4fcdf6","_kg_hide-input":true},"cell_type":"code","source":"fig, (boxplot, histogram) = plt.subplots(2, sharex=True, figsize=(12, 8), gridspec_kw={\"height_ratios\": (.15, .85)})\n\nsns.boxplot(df_avgs.n_wins, ax=boxplot, color='#c5b783')\nsns.despine(left=True, bottom=True)\nboxplot.set(xlabel='')\n\n\nsns.kdeplot(df_avgs.n_wins, shade=True, ax=histogram, legend=False, color='#c5b783')\nplt.box(False)\nplt.title('Distribution of Wins Since 2003', fontsize=24)\nplt.xlabel('Number of wins per Team')\nplt.tick_params(axis='both', which='both',length=0);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfc6011ec36802306615d86ba13ab77f11f03575","_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(18, 18))\n\n# Save the correlation matrix:\nmatrix = df_avgs[['win_pct', 'shoot_eff', 'score_op', 'off_rtg', 'def_rtg', 'sos', 'ie', 'ts_pct', 'efg_pct', 'orb_pct', 'drb_pct', 'reb_pct', 'to_poss', 'ft_rate', 'ast_rtio', 'blk_pct', 'stl_pct']].corr()\n\n# Create mask for the upper triangle:\nmask = np.zeros_like(matrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Create a custom diverging colormap:\ncmap = sns.diverging_palette(225, 45, as_cmap=True)\n\nsns.heatmap(matrix, mask=mask, cmap=cmap, center=0, annot=True, square=True, linewidths=0.25, cbar_kws={'shrink': 0.25})\nplt.tick_params(axis='both', which='both',length=0)\nplt.tick_params(axis='both', which='major', labelsize=16)\n\nfrom scipy.stats.stats import pearsonr\nplt.title('Team Impact Estimate and Win Percentage correlate at an R square of {:0.3f}!'.format(pearsonr(df_avgs.ie, df_avgs.win_pct)[0]), fontsize=24, weight='bold')\nfig.text(x=0.25, y=0.75, s='In fact, Win Percentage has a moderate or strong positive \\nrelationship with most of the efficiency measures.', fontsize=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af561b70eda7148ee293fc91392df2cf072cdc08","_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ngrid = plt.GridSpec(3, 2, wspace=0.25, hspace=0.5)\n\nfig.text(x=0.30, y=0.95, s='-Winner Stats', fontsize=32, color='#c5b783')\nfig.text(x=0.50, y=0.95, s='vs.', fontsize=32)\nfig.text(x=0.55, y=0.95, s=' -Loser Stats', fontsize=32, color='#3c7f99')\nfig.text(x=0.45, y=0.92, s='(Efficiency)', fontsize=24)\n    \nplt.subplot(grid[0, :1])\nsns.kdeplot(df_avgs.Lshoot_eff, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wshoot_eff, shade=True, legend=False, color='#c5b783')\nplt.title('Shooting Efficiency', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[0, 1:])\nsns.kdeplot(df_avgs.Lscore_op, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wscore_op, shade=True, legend=False, color='#c5b783')\nplt.title('Scoring Opportunity', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[1, :1])\nsns.kdeplot(df_avgs.Loff_rtg, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Woff_rtg, shade=True, legend=False, color='#c5b783')\nplt.title('Offensive Rating', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[1, 1:])\nsns.kdeplot(df_avgs.Ldef_rtg, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wdef_rtg, shade=True, legend=False, color='#c5b783')\nplt.title('Defensive Rating', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[2, :1])\nsns.kdeplot(df_avgs.Lsos, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wsos, shade=True, legend=False, color='#c5b783')\nplt.title('Net Efficiency (SOS)', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[2, 1:])\nsns.kdeplot(df_avgs.Lie, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wie, shade=True, legend=False, color='#c5b783')\nplt.title('Team Impact Estimate', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ca80d9db0084f0316f145c8053e883b5a1eedd5"},"cell_type":"markdown","source":"Most of the efficiency behavior is expected: winners have higher values than losers except for defensive rating."},{"metadata":{"trusted":true,"_uuid":"409c33992dfdb198a2256d0e099dea520072605f","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 14))\ngrid = plt.GridSpec(1, 2, wspace=1)\nfig.text(x=-0.15, y=0.95, s='    Efficiency by Past Champions, Seasons 2003-2017    ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=1, y=0.5, s='Championships\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WTeamName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='ie', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.ie.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Impact Estimate', fontsize=22); plt.ylabel('')\nplt.xticks([50, 67.5, 85], fontsize=12)\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='off_rtg', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.off_rtg.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rating', fontsize=22); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2deb41b3471ae04ce4c92b19b61c438f62d26a81","_kg_hide-input":true},"cell_type":"code","source":"crrnt_seasn = df_avgs[(df_avgs.Season == df_avgs.Season.max()) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))]\nteam_eff = crrnt_seasn['off_rtg'].groupby(crrnt_seasn.TeamName).mean().to_frame()\nteam_eff['def_rtg'] = crrnt_seasn['def_rtg'].groupby(crrnt_seasn.TeamName).mean()\nteam_eff.reset_index(inplace=True)\n\nx_coords = team_eff.off_rtg\ny_coords = team_eff.def_rtg\nteams = team_eff.TeamName\n\nfig, ax = plt.subplots(figsize=(10, 10))\nfig.text(x=0, y=0.95, s='        Efficiency by Past Champions, 2018      ', fontsize=28, weight='bold', color='white', backgroundcolor='#c5b783')\n\nfor i, team in enumerate(teams):\n    x = x_coords[i]\n    y = y_coords[i]\n    plt.plot(x, y, marker='o', markersize=10, markeredgecolor='#3c7f99', markerfacecolor='#3c7f99')\n    plt.text(x+0.000025, y-0.000005, team, fontsize=12)\n    \nplt.autoscale(enable=True, axis='both')\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nplt.xlabel('Offensive Rating', fontsize=18); plt.ylabel('Defensive Rating', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"776ec62f2740e72f0bdf83a0866c8a949b7a2ee7","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 14))\ngrid = plt.GridSpec(1, 2, wspace=1)\nfig.text(x=-0.15, y=0.95, s='         Efficiency Top 25, Seasons 2003-2017       ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=1, y=0.5, s='Championships\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WTeamName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='ie', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.ie.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Impact Estimate', fontsize=22); plt.ylabel('')\nplt.xticks([50, 67.5, 85], fontsize=12)\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='off_rtg', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.off_rtg.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rating', fontsize=22); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f20159c5adf72fdb6dcd9a8fc276a16eb8ed3ec3","_kg_hide-input":true},"cell_type":"code","source":"crrnt_seasn = df_avgs[df_avgs.Season == df_avgs.Season.max()]\nteam_eff = crrnt_seasn['off_rtg'].groupby(crrnt_seasn.TeamName).mean().to_frame()\nteam_eff['def_rtg'] = crrnt_seasn['def_rtg'].groupby(crrnt_seasn.TeamName).mean()\nteam_eff = team_eff.sort_values(['off_rtg'], ascending=False).head(25)\nteam_eff.reset_index(inplace=True)\n\nx_coords = team_eff.off_rtg\ny_coords = team_eff.def_rtg\nteams = team_eff.TeamName\n\nfig, ax = plt.subplots(figsize=(10, 10))\nfig.text(x=0, y=0.95, s='        Offensive Rating Top 25, 2018        ', fontsize=28, weight='bold', color='white', backgroundcolor='#c5b783')\n\nfor i, team in enumerate(teams):\n    x = x_coords[i]\n    y = y_coords[i]\n    plt.plot(x, y, marker='o', markersize=10, markeredgecolor='#3c7f99', markerfacecolor='#3c7f99')\n    plt.text(x+0.000025, y-0.000005, team, fontsize=12)\n    \nplt.autoscale(enable=True, axis='both')\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nplt.xlabel('Offensive Rating', fontsize=18); plt.ylabel('Defensive Rating', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"272f572bfaeefd544c84c3df4de5668aa8092f44","_kg_hide-input":true},"cell_type":"code","source":"crrnt_seasn = df_avgs[df_avgs.Season == df_avgs.Season.max()]\nteam_eff = crrnt_seasn['off_rtg'].groupby(crrnt_seasn.TeamName).mean().to_frame()\nteam_eff['def_rtg'] = crrnt_seasn['def_rtg'].groupby(crrnt_seasn.TeamName).mean()\nteam_eff = team_eff.sort_values(['def_rtg']).head(25)\nteam_eff.reset_index(inplace=True)\n\nx_coords = team_eff.off_rtg\ny_coords = team_eff.def_rtg\nteams = team_eff.TeamName\n\nfig, ax = plt.subplots(figsize=(10, 10))\nfig.text(x=0, y=0.95, s='        Defensive Rating Top 25, 2018       ', fontsize=28, weight='bold', color='white', backgroundcolor='#c5b783')\n\nfor i, team in enumerate(teams):\n    x = x_coords[i]\n    y = y_coords[i]\n    plt.plot(x, y, marker='o', markersize=10, markeredgecolor='#3c7f99', markerfacecolor='#3c7f99')\n    plt.text(x+0.000025, y-0.000005, team, fontsize=12)\n    \nplt.autoscale(enable=True, axis='both')\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nplt.xlabel('Offensive Rating', fontsize=18); plt.ylabel('Defensive Rating', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17048559cd69c392065c50ddc9ace96ab02a0752"},"cell_type":"markdown","source":"Gonzaga and Michigan State are the only two teams in the top 25 for both Offensive and Defensive Rating in 2018."},{"metadata":{"trusted":true,"_uuid":"aa3b3aa6bbc627dab7f4b38d5b3513421285da68","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 14))\ngrid = plt.GridSpec(1, 2, wspace=1)\nfig.text(x=-0.225, y=0.95, s='  Efficiency by Conference, Seasons 2003-2017  ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=-0.15, y=-0.1, s='-'*75 + '\\nChampionships 2003-2017\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WConfName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='ie', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.ie.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Impact Estimate', fontsize=22); plt.ylabel('')\nplt.xticks([25, 50, 75], fontsize=12)\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='off_rtg', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.off_rtg.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rating', fontsize=22); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8baee883fe08dc13e0b750cde2c5e5b116261855","_kg_hide-input":true},"cell_type":"code","source":"crrnt_seasn = df_avgs[df_avgs.Season == df_avgs.Season.max()]\nconf_eff = crrnt_seasn['off_rtg'].groupby(crrnt_seasn.ConfName).mean().to_frame()\nconf_eff['def_rtg'] = crrnt_seasn['def_rtg'].groupby(crrnt_seasn.ConfName).mean()\nconf_eff.reset_index(inplace=True)\n\nx_coords = conf_eff.off_rtg\ny_coords = conf_eff.def_rtg\nconfs = conf_eff.ConfName\n\nfig, ax = plt.subplots(figsize=(10, 10))\nfig.text(x=0, y=0.95, s='           Efficiency by Conference, 2018          ', fontsize=28, weight='bold', color='white', backgroundcolor='#c5b783')\n\nfor i, conf in enumerate(confs):\n    x = x_coords[i]\n    y = y_coords[i]\n    plt.plot(x, y, marker='o', markersize=10, markeredgecolor='#3c7f99', markerfacecolor='#3c7f99')\n    plt.text(x, y, conf, fontsize=12)\n    \nplt.autoscale(enable=True, axis='both')\nax.spines['right'].set_visible(False)\nax.spines['top'].set_visible(False)\nplt.xlabel('Offensive Rating', fontsize=18); plt.ylabel('Defensive Rating', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1a2a9e47a5260969122214a2d8db7232665166a","_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ngrid = plt.GridSpec(2, 2, wspace=0.25, hspace=0.5)\n\nfig.text(x=0.30, y=0.95, s='-Winner Stats', fontsize=32, color='#c5b783')\nfig.text(x=0.50, y=0.95, s='vs.', fontsize=32)\nfig.text(x=0.55, y=0.95, s=' -Loser Stats', fontsize=32, color='#3c7f99')\nfig.text(x=0.45, y=0.92, s='(Four Factors)', fontsize=24)\n    \n\nplt.subplot(grid[0, :1])\nsns.kdeplot(df_avgs.Lefg_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wefg_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Effective Field Goal Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[0, 1:])\nsns.kdeplot(df_avgs.Lto_poss, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wto_poss, shade=True, legend=False, color='#c5b783')\nplt.title('Turnovers per Possession', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[1, :1])\nsns.kdeplot(df_avgs.Lorb_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Worb_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Offensive Rebound Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[1, 1:])\nsns.kdeplot(df_avgs.Lft_rate, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wft_rate, shade=True, legend=False, color='#c5b783')\nplt.title('Free Throw Rate', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3c156e4f9a3459bff3282e914f3fc0478716202","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 20))\ngrid = plt.GridSpec(2, 2, wspace=1)\nfig.text(x=-0.2, y=0.91, s='Four Factors by Past Champions, Seasons 2003-2017', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=-0.15, y=-0.09, s='-'*75 + '\\nChampionships 2003-2017\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WTeamName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='efg_pct', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.efg_pct.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Effective Field Goal Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='to_poss', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.to_poss.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=True).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Turnovers per Possession', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='orb_pct', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.orb_pct.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rebound Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='ft_rate', data=df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))], color='#3c7f99', \n            order=df_avgs.ft_rate.groupby(df_avgs[(df_avgs.Season < 2018) & (df_avgs.TeamName.isin(championships.WTeamName.unique()))].TeamName).mean().sort_values(ascending=False).to_frame().index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Free Throw Rate', fontsize=18); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12e2fc48c8bec7fcffe612bd7f0be2e2d3935fdb","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 20))\ngrid = plt.GridSpec(2, 2, wspace=1)\nfig.text(x=-0.025, y=0.91, s=' Top 25 for each of the Four Factors, Seasons 2003-2017 ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=0.025, y=-0.09, s='-'*90 + '\\nChampionships 2003-2017\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WTeamName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='efg_pct', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.efg_pct.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Effective Field Goal Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='to_poss', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.to_poss.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=True).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Turnovers per Possession', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='orb_pct', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.orb_pct.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rebound Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='TeamName', x='ft_rate', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.ft_rate.groupby(df_avgs[df_avgs.Season < 2018].TeamName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Free Throw Rate', fontsize=18); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aed54cdaf888901354149b7fa3ce83c43e479423"},"cell_type":"markdown","source":"It may be helpful to analyze tournament teams exclusively."},{"metadata":{"trusted":true,"_uuid":"61132992df9e75aee244bf65f3261d23d7a3e8ac","_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15, 20))\ngrid = plt.GridSpec(2, 2, wspace=1)\nfig.text(x=-0.05, y=0.91, s='    Four Factors by Conference, Seasons 2003-2017    ', fontsize=32, weight='bold', color='white', backgroundcolor='#c5b783')\nfig.text(x=0, y=-0.025, s='-'*85 + '\\nChampionships 2003-2017\\n\\n' + '\\n'.join('{}: {}'.format(k, v) for k, v in championships[championships.Season.isin(df_avgs.Season.unique())].WConfName.value_counts().to_dict().items()), fontsize=18)\n\nplt.subplot(grid[0, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='efg_pct', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.efg_pct.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Effective Field Goal Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[0, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='to_poss', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.to_poss.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=True).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Turnovers per Possession', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, :1]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='orb_pct', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.orb_pct.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Offensive Rebound Percentage', fontsize=18); plt.ylabel('')\n\nplt.subplot(grid[1, 1:]).xaxis.grid(which='both', linewidth=0.5, color='#c5b783')\nsns.boxplot(y='ConfName', x='ft_rate', data=df_avgs[df_avgs.Season < 2018], color='#3c7f99', \n            order=df_avgs.ft_rate.groupby(df_avgs[df_avgs.Season < 2018].ConfName).mean().sort_values(ascending=False).to_frame().head(25).index, \n            meanprops=dict(marker='o', markeredgecolor='#c5b783', markerfacecolor='#c5b783'), \n            showmeans=True)\nplt.box(False)\nplt.xlabel('Free Throw Rate', fontsize=18); plt.ylabel('');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fd8e3a36b68d9d1a5e29f2f91010576a96f7832","_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(20, 20))\ngrid = plt.GridSpec(3, 2, wspace=0.25, hspace=0.5)\n\nfig.text(x=0.30, y=0.95, s='-Winner Stats', fontsize=32, color='#c5b783')\nfig.text(x=0.50, y=0.95, s='vs.', fontsize=32)\nfig.text(x=0.55, y=0.95, s=' -Loser Stats', fontsize=32, color='#3c7f99')\n\nplt.subplot(grid[0, :1])\nsns.kdeplot(df_avgs.Lreb_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wreb_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Rebound Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[0, 1:])\nsns.kdeplot(df_avgs.Ldrb_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wdrb_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Defensive Rebound Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[1, :1])\nsns.kdeplot(df_avgs.Lts_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wts_pct, shade=True, legend=False, color='#c5b783')\nplt.title('True Shooting Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n    \nplt.subplot(grid[1, 1:])\nsns.kdeplot(df_avgs.Last_rtio, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wast_rtio, shade=True, legend=False, color='#c5b783')\nplt.title('Assist Ratio', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[2, :1])\nsns.kdeplot(df_avgs.Lblk_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wblk_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Block Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14)\n\nplt.subplot(grid[2, 1:])\nsns.kdeplot(df_avgs.Lstl_pct, shade=True, legend=False, color='#3c7f99')\nsns.kdeplot(df_avgs.Wstl_pct, shade=True, legend=False, color='#c5b783')\nplt.title('Steal Percentage', fontsize=24)\nplt.box(False)\nplt.tick_params(axis='both', which='both', length=0)\nplt.tick_params(axis='both', which='major', labelsize=14);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc2310c18e4e4d12b1c856fdeb5c811ca33d3944"},"cell_type":"markdown","source":"<a href='#top' id='3.3'>return to menu</a>\n\n## 3.3 Features to Model\nTeam season averages of key calculated stats make up the initial set of basketball features to model:"},{"metadata":{"trusted":true,"_uuid":"bbb39f01b676966b3558bb829d1e1b7f4939cd2d"},"cell_type":"code","source":"df_features = df_avgs[['Season', 'TeamID', 'shoot_eff', 'score_op', 'off_rtg', 'def_rtg', 'sos', 'ie', 'efg_pct', 'to_poss', 'orb_pct', 'ft_rate', 'reb_pct', 'drb_pct', 'ts_pct', 'ast_rtio', 'blk_pct', 'stl_pct']]\ndf_features.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9d48a559e7e05b484ae133b62b3b0d4f5600e9b"},"cell_type":"markdown","source":"---\nAnd, since EDA indicated the importance of seed placement for tournament progression and final success, that is included in the model too:"},{"metadata":{"trusted":true,"_uuid":"6738983dd30f7b3b68d228ed294611d37543e228"},"cell_type":"code","source":"df_features = pd.merge(df_seeds, df_features, how='left', left_on=['Season', 'TeamID'], right_on=['Season', 'TeamID'])\n\ndf_tourney = df_tourney_all[(df_tourney_all.Season >= 2003) & (df_tourney_all.Season < 2018)]\ndf_tourney.reset_index(inplace=True, drop=True)\ndf_tourney.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3ac0231e9ba67cae3ff04af71aa80b3ec496b54"},"cell_type":"code","source":"# Merge tourney games with tourney winners' season features:\ndf_winners = pd.merge(left=df_tourney[['Season', 'WTeamID', 'LTeamID']], right=df_features, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'])\ndf_winners.drop(['TeamID'], inplace=True, axis=1) \n\n# Merge tourney games with loser features:\ndf_losers = pd.merge(left=df_tourney[['Season', 'WTeamID', 'LTeamID']], right=df_features, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'])\ndf_losers.drop(['TeamID'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b7aaa7f90c297020387ff06532c8aa305385c09"},"cell_type":"markdown","source":"<a href='#top' id='4'>return to menu</a>\n\n---\n## 4. MACHINE LEARNING\nIn order to predict winners of games in the championship tournament, the classification algorithms require a target output (win or loss) to learn. This information is available, but not explicitly in a data column, so a result column is created by splitting winners from losers and assigning the appropriate outcome: 1 for winner game data, 0 for loser game data. \n\n### Prepare Data for Modeling"},{"metadata":{"trusted":true,"_uuid":"4b21f52cfabea7184a8da26c591cc52f4a7b8a12"},"cell_type":"code","source":"# Create winner target by subtracting loser data from winner data,\n# and assigning a value of 1:\ndf_winner_diff = (df_winners.iloc[:, 3:] - df_losers.iloc[:, 3:])\ndf_winner_diff['result'] = 1\n\n# Create loser target by subtracting winner data from loser data,\n# and assigning a value of 0:\ndf_loser_diff = (df_losers.iloc[:, 3:] - df_winners.iloc[:, 3:])\ndf_loser_diff['result'] = 0\n\n# Concatenate winner data with loser data:\ndf_model = pd.concat((df_winner_diff, df_loser_diff), axis=0)\ndf_model.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8beabc72688f4a92f55b03e9ec7a6c18d8359f85"},"cell_type":"code","source":"X = df_model.iloc[:, :-1]\ny = df_model.result\n\n# Split the dataframe into 65% training and 35% testing:\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b2f777b695f3a1fabe06c81cc7a3b88458d85c8"},"cell_type":"code","source":"sns.countplot(y)\nplt.xlabel(''), plt.ylabel('')\nplt.xticks([0, 1], ('losses', 'wins'))\nplt.title('The Target Classes are Balanced');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce555ce046e6ada003760a83e88970dd12cec6bd"},"cell_type":"markdown","source":"This certainly makes sense because each game has a winner and a loser."},{"metadata":{"trusted":true,"_uuid":"62dd04ca2e8c705b77a36f80993518b8efb71673","_kg_hide-input":true},"cell_type":"code","source":"from yellowbrick.classifier import ClassificationReport\n\ndef clfy_report(clf, X_train, X_test, y_train, y_test, param_grid, clf_label='clf', cv=10, scale=True):\n    \"\"\"\n    Tune classifier hyperparameters and print metrics.\n    \"\"\"\n    \n    # Create pipeline steps for scaling and classifying:\n    if scale:\n        pipe = Pipeline([('scaler', StandardScaler()), (clf_label, clf)])\n    else:\n        pipe = Pipeline([(clf_label, clf)])\n    \n    # Instantiate grid search using 10-fold cross validation:\n    search = GridSearchCV(pipe, param_grid, cv=10)\n    \n    # Learn relationship between predictors (basketball/tourney features) and outcome,\n    # and the best parameters for defining such:\n    search.fit(X_train, y_train)\n    \n    # Predictions on the test set, new data that haven't been introduced to the model:\n    predicted = search.predict(X_test)\n    \n    # Predictions as probabilities:\n    probabilities = search.predict_proba(X_test)[:, 1]\n    \n    # Accuracy scores for the training and test sets:\n    train_accuracy = search.score(X_train, y_train)\n    test_accuracy = search.score(X_test, y_test)\n\n    print('Best Parameters: {}\\n'.format(search.best_params_))\n    print('Training Accuracy: {:0.2}'.format(train_accuracy))\n    print('Test Accuracy: {:0.2}\\n'.format(test_accuracy))\n    \n    # Confusion matrix labels:\n    labels = np.array([['true losses','false wins'], ['false losses','true wins']])\n    \n    # Model evaluation metrics:\n    confusion_mtrx = confusion_matrix(y_test, predicted)\n    auc = roc_auc_score(y_test, probabilities)\n    fpr, tpr, thresholds = roc_curve(y_test, probabilities)\n    logloss = log_loss(y_test, search.predict_proba(X_test))\n    \n    # Plot all metrics in a grid of subplots:\n    fig = plt.figure(figsize=(12, 12))\n    grid = plt.GridSpec(2, 4, wspace=0.75, hspace=0.5)\n    \n    # Top-left plot - confusion matrix:\n    plt.subplot(grid[0, :2])\n    sns.heatmap(confusion_mtrx, annot=labels, fmt='')\n    plt.xlabel('Predicted Games')\n    plt.ylabel('Actual Games');\n    \n    # Top-right plot - ROC curve:\n    plt.subplot(grid[0, 2:])\n    plt.plot([0, 1], [0, 1], linestyle='--')\n    plt.plot(fpr, tpr, marker='.')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('AUROC: {:0.3}'.format(auc));\n    \n    # Bottom-left plot - support, or true predictions:\n    plt.subplot(grid[1, :2])\n    sns.countplot(y=predicted, orient='h')\n    plt.yticks([1, 0], ('wins', 'losses'))\n    plt.ylabel(''), plt.xlabel('Number Predicted');\n    \n    # Bottom-right plot - classification report:\n    plt.subplot(grid[1, 2:])\n    visualizer = ClassificationReport(search, classes=['losses', 'wins'])\n    visualizer.fit(X_train, y_train)\n    visualizer.score(X_test, y_test)\n    g = visualizer.poof();\n    \n    return train_accuracy, test_accuracy, auc, logloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80ea4b1fa9530a3ca018a942c3f21786b9de21dd","_kg_hide-input":true},"cell_type":"code","source":"def summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='model_name'):\n    \n    model_name = pd.DataFrame({\n        'model_name': model_name, \n        'Train Accuracy': round(train_accuracy, 3), \n        'Test Accuracy': round(test_accuracy, 3),\n        'AUROC': round(auc, 3),\n        'Log Loss': round(logloss, 3)\n    }, index=[0])\n    model_name = model_name[['model_name', 'Train Accuracy', 'Test Accuracy', 'AUROC', 'Log Loss']]\n    \n    return model_name","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d8aaddfbe6274e197ecda52fde1317265d4dae5"},"cell_type":"markdown","source":"<a href='#top' id='4.1'>return to menu</a>\n\n## 4.1 Logistic Regression\n>In this model, the probabilities describing the possible outcomes of a single trial are modeled... The implementation of logistic regression in [scikit-learn](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) can be accessed from class `LogisticRegression`. This implementation can fit binary, One-vs- Rest, or multinomial logistic regression with optional L2 or L1 regularization."},{"metadata":{"trusted":true,"_uuid":"02402862f4510f524c4b3aeee741ff967ec55616"},"cell_type":"code","source":"warnings.filterwarnings(action='ignore', category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore', category=UserWarning)\n\nfrom sklearn.linear_model import LogisticRegression\n\n# Tune Logistic Regression for optimal regularization strength\n# and regularization method (penalty):\nlr_clf = LogisticRegression(random_state=32)\nlr_param_grid = {\n    'clf__C': np.logspace(start=-10, stop=10, num=21),\n    'clf__penalty': ['l1', 'l2']\n}\n\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(lr_clf, X_train, X_test, y_train, y_test, lr_param_grid, cv=10, scale=False)\nlogisticRegression = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='logisticRegression')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85035b85ef524f2336f524f90b6db072e95201c2"},"cell_type":"markdown","source":"For this and all other classifiers, the following is the ideal representation from each graph (clockwise from top left):\n1. The confusion matrix would be very light beige (high frequency) on the accuracy diagonal (true values) and black on the false diagonal.\n\n2. The green line on the ROC graph would pull more toward 1 on the y-axis (true positive rate), making the area under the ROC (AUROC) closer to 1.\n\n3. The classification report would be a very deep red, indicating high precision and recall (f1-score is an average of those) for win and loss predictions.\n\n4. The predicted wins and losses would be fairly even given the underlying data, but some unevenness could be expected because of the random splitting of training and test data."},{"metadata":{"_uuid":"9d73e6e9f217fdc76fcf1ece2a3fa029440f1eb5"},"cell_type":"markdown","source":"<a href='#top' id='4.2'>return to menu</a>\n\n## 4.2 Support Vector Machine\n>A support vector machine constructs a hyper-plane or set of hyper-planes in a high or infinite dimensional space, which can be used for classification, regression or other tasks. Intuitively, a good separation is achieved by the hyper-plane that has the largest distance to the nearest training data points of any class (so-called functional margin), since in general the larger the margin the lower the generalization error of the classifier.\n\n[scikit-learn's](https://scikit-learn.org/stable/modules/svm.html#svm-classification) `SVC` class is among those available for support vector machine classification."},{"metadata":{"trusted":true,"_uuid":"32f78079042eac66a526fefc6e4fa12efec9d40d"},"cell_type":"code","source":"from sklearn import svm\n\n# Tune Support Vector classification for optimal regularization strength \n# and the kernel coefficient for the default kernel type implemented, rbf:\nsvm_clf = svm.SVC(probability=True, random_state=32)\nsvm_param_grid = {\n    'clf__C': np.logspace(start=-3, stop=3, num=7), \n    'clf__gamma': np.logspace(start=-4, stop=-1, num=4)\n}\n\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(svm_clf, X_train, X_test, y_train, y_test, svm_param_grid, cv=10, scale=False)\nsvmSVC = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='svmSVC')\n\n# Start a summary of all models:\nall_models = pd.concat([logisticRegression, svmSVC])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4ca98c9077d8d075f7cdd6dc070513843eebb05"},"cell_type":"markdown","source":"<a href='#top' id='4.3'>return to menu</a>\n\n## 4.3 Decision Tree\n>Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.\n\n[scikit-learn's](https://scikit-learn.org/stable/modules/tree.html#classification) `DecisionTreeClassifier` is the class available for decision tree classification."},{"metadata":{"trusted":true,"_uuid":"beb85b846d5a574e4b11ab66b4cd555c1e7ec629"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\n# Tune Decision Tree classifier for\n# minimum fraction of samples required to split an internal node,\n# minimum fraction of samples required to be at a leaf node\n# and function to measure the quality of a split:\ndt_clf = DecisionTreeClassifier(random_state=32)\ndt_param_grid = {\n    'clf__min_samples_split': np.linspace(0.1, 0.5, 5),\n    'clf__min_samples_leaf': np.linspace(0.1, 0.5, 5), \n    'clf__criterion': ['gini', 'entropy']\n}\n\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(dt_clf, X_train, X_test, y_train, y_test, dt_param_grid, cv=10, scale=False)\ndecisionTreeClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='decisionTreeClassifier')\nall_models = pd.concat([all_models, decisionTreeClassifier])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5415672e47bb377d87652507bbe3e54e56bd4f63"},"cell_type":"markdown","source":"<a href='#top' id='4.4'>return to menu</a>\n\n## 4.4 Random Forest\n>The [sklearn.ensemble](https://scikit-learn.org/stable/modules/ensemble.html#random-forests) module includes two averaging algorithms based on randomized decision trees: the RandomForest algorithm and the Extra-Trees method.\n<br><br>\n>In random forests (see `RandomForestClassifier` and `RandomForestRegressor` classes), each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. In addition, when splitting a node during the construction of the tree, the split that is chosen is no longer the best split among all features. Instead, the split that is picked is the best split among a random subset of the features."},{"metadata":{"trusted":true,"_uuid":"146818cf469270572f8389ce5aea545eae310743"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf_clf = RandomForestClassifier(random_state=32, n_jobs=-1)\nrf_param_grid = {\n    'clf__n_estimators': [16, 32, 64, 128],\n    'clf__min_samples_leaf': [2, 4, 8, 16], \n    'clf__criterion': ['entropy']\n}\n\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(rf_clf, X_train, X_test, y_train, y_test, rf_param_grid, cv=10, scale=False)\nrandomForestClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='randomForestClassifier')\nall_models = pd.concat([all_models, randomForestClassifier])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de4f1910f3a2e8771f0333e06b3fe3f28ccf5b71"},"cell_type":"markdown","source":"<a href='#top' id='4.5'>return to menu</a>\n\n## 4.5 XGBoost\nXGBoost is a library of gradient boosting algorithms. \n>Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion like other boosting methods do... [Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)"},{"metadata":{"trusted":true,"_uuid":"46231be41b57c4ffa877f26a53da45d25f6b558f"},"cell_type":"code","source":"import xgboost as xgb\n\nxgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=32)\nxgb_param_grid = {\n    'clf__max_depth': [2, 4, 8, 12],\n    'clf__min_child_weight': [2, 4, 8],\n    'clf__colsample_bytree': [0.25, 0.5, 0.75]\n}\n\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(xgb_clf, X_train, X_test, y_train, y_test, xgb_param_grid, cv=10, scale=False)\nxgbClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='xgbClassifier')\nall_models = pd.concat([all_models, xgbClassifier])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bced31114f1fcc04ae85ed499e29b9e7d0f01b8"},"cell_type":"markdown","source":"<a href='#top' id='4.6'>return to menu</a>\n\n## 4.6 Best Model\n"},{"metadata":{"trusted":true,"_uuid":"f286d715b065e29bb7a325077753cf22230abe8c"},"cell_type":"code","source":"# Sort all models by Test Accuracy:\ncompare_models = all_models.copy()\ncompare_models.set_index('model_name', inplace=True)\ncompare_models.sort_values(by=['Test Accuracy', 'AUROC'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"fa5fee0e228cbbb1553d983ae19e39aa4e7998eb"},"cell_type":"code","source":"# Sort all models by Log Loss:\ncompare_models.sort_values(by=['Log Loss'], ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"946ef4c8cd5d80bb78d63fe82eed2cd734660ecb"},"cell_type":"markdown","source":"<a href='#top' id='4.7'>return to menu</a>\n\n## 4.7 Model Explainability\nWhich features were the most important in making predictions (what contributes most to a team's success in the tournament)?"},{"metadata":{"_uuid":"2de5697f765df4761a9512b68182dc9b886f5876"},"cell_type":"markdown","source":"### LOGISTIC REGRESSION"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"b944cea161b20cfe5630de9d7fac5bd8fa292b18"},"cell_type":"code","source":"# Create pipeline for scaling and classifying:\npipe = Pipeline([('clf', lr_clf)])\n    \nlr_search = GridSearchCV(pipe, lr_param_grid, cv=10)\nlr_search.fit(X_train, y_train)\nprint(lr_search.best_params_)\n\nperm = PermutationImportance(lr_search, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names=X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"feb7872fe6b22fede0cde108ce268cdc09b46268"},"cell_type":"markdown","source":"This means that if the `seed` column is randomly shuffled, the classifier accuracy decreases by 0.1499, and since this involves multiple shuffles, the accuracy varied 0.0086 among the shufflings. Of course, the same concept applies to the other variables and they are all listed in order of importance.\n\nThe negative permutation importance values (highlighted in light red) mean that shuffling increased the accuracy, indicating that the particular feature truly doesn't matter but random chance (from shuffling) falsely caused accuracy improvement."},{"metadata":{"_uuid":"dcb0139d559edd62074194211a243130861f3da8"},"cell_type":"markdown","source":"<a href='#top' id='4.8'>return to menu</a>\n\n## 4.8 Make Predictions and Build Bracket\nUsing the template below of all possible matches for the 2018 tournament (and a 50/50 for all games), season and seed data are retrieved for every team id and used to make predictions:"},{"metadata":{"trusted":true,"_uuid":"39aa24a979401aab8c40965abc340ae936ffef4b"},"cell_type":"code","source":"df_predict = pd.read_csv('../input/mens-machine-learning-competition-2018/SampleSubmissionStage2.csv')\ndf_predict.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91770d3c70d162d1969f4a6f10bd34dfd1308182"},"cell_type":"code","source":"def get_year_team1_team2(ID):\n    \"\"\"Return a tuple with the year, team1 and team2\n    for each ID in the sample submission file of possible matches.\"\"\"\n    return (int(x) for x in ID.split('_'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f7b57a4363ee3b3dfc27efed629d985fd1504a"},"cell_type":"code","source":"def predict_poss_matches(clf, df_predict=df_predict, df_features=df_features):\n    diff = []\n    data = []\n\n    for i, row in df_predict.iterrows():\n\n        year, team1, team2 = get_year_team1_team2(row.ID)\n\n        # Save 2018 stats/features for the first ID:\n        team1 = df_features[(df_features['Season'] == year) & (df_features['TeamID'] == team1)].values[0]\n\n        # Save 2018 stats/features for the first ID:\n        team2 = df_features[(df_features['Season'] == year) & (df_features['TeamID'] == team2)].values[0]   \n\n        diff = team1 - team2\n\n        data.append(diff)\n\n    n_poss_games = len(df_predict)\n    columns = df_features.columns.get_values()\n    final_predictions = pd.DataFrame(np.array(data).reshape(n_poss_games, np.array(data).shape[1]), columns=(columns))\n    final_predictions.drop(['Season', 'TeamID'], inplace=True, axis=1)\n    predictions = clf.predict_proba(final_predictions)[:, 1]\n    clipped_predictions = np.clip(predictions, 0.05, 0.95)\n    df_predict.Pred = clipped_predictions\n    \n    return df_predict\n\npredict_poss_matches(lr_search).to_csv('best_model_results.csv', index=False) # LogLoss = 0.5970823250661108 Thanks to this website: https://www.marksmath.org/visualization/kaggle_brackets/","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e2eaf67677e1be48c92246de1eeb9c6be6d49ca"},"cell_type":"markdown","source":"[Here](https://www.kaggle.com/c/mens-machine-learning-competition-2018/discussion/50200) is where I found the next gem, a package to automatically fill in the bracket using the prediction file:"},{"metadata":{"trusted":true,"_uuid":"ffa4f33f3023e2b9cfdb2cf0afd6a43b919ca111"},"cell_type":"code","source":"%%capture\n!pip install bracketeer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee3b1b5d4cf15485ad9123ba442062d95bfba600"},"cell_type":"code","source":"from bracketeer import build_bracket\n\nb = build_bracket(\n        outputPath='best_bracket.png',\n        submissionPath='best_model_results.csv',\n        teamsPath='../input/mens-machine-learning-competition-2018/datafiles/Teams.csv',\n        seedsPath='../input/mens-machine-learning-competition-2018/Stage2UpdatedDataFiles/NCAATourneySeeds.csv',\n        slotsPath='../input/mens-machine-learning-competition-2018/Stage2UpdatedDataFiles/NCAATourneySlots.csv',\n        year=2018\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f67b895e9af44e2137aa99c691c120e08fd6e124"},"cell_type":"markdown","source":"I can't figure out the problem there so I ran it in a local notebook using the same predictions file with help from this post: https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel."},{"metadata":{"trusted":true,"_uuid":"4840e65284115e7d65bfc3d1e78744edb1ffc5a2"},"cell_type":"code","source":"from IPython.display import HTML\nimport base64\n\ndef create_download_link(df, title='Download predictions file!', filename='best_model_results_kaggle.csv'): \n    \"\"\"\n    Create a text link to download dataframe as a CSV file.\n    \"\"\"\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload, title=title, filename=filename)\n    return HTML(html)\n\ncreate_download_link(predict_poss_matches(lr_search))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8529021c94fe70cbd36cd419269438d2cc0b7673"},"cell_type":"markdown","source":"<a href='#top' id='5'>return to menu</a>\n\n---\n## 5. RESULTS"},{"metadata":{"_uuid":"a9e397ffd1f476582006461c4e1c5ea48681792f"},"cell_type":"markdown","source":"The best model predicted the bracket shown below for 2018:\n\n![](https://imgur.com/fPNSmO9.png)\n\n<br>\n\nI was never crazy about including seed differential in the models, mainly because of the fact that there is little difference between the count of 12-5 upsets and the count of 10-7 upsets, yet the differences in the seed number are 7 and 3. \n\nThough all metrics were decent, and even without the benefit of 2018 results, I would have rejected this model based on the first round picks - only 3 predicted upsets (win seed > lose seed), and those were 9s over 8s. Of course, 2018 results are known and there were 20 total, 9 in the first round. I know the model is not trying to predict which games are going to be upsets, but this bracket would have been a major tournament history outlier.\n\nIt does seem as though earning a decent seed is important for staying in the tournament, but that crazy first round... Maybe that unique upset group needs to be weighted a bit differently?\n\n---\nIn the meantime, I must see a printed bracket from the best no-seed-data model..."},{"metadata":{"trusted":true,"_uuid":"8e96e6b8e6716690615d915a944a3489cbe3f113"},"cell_type":"code","source":"df_features = df_avgs[['Season', 'TeamID', 'shoot_eff', 'score_op', 'off_rtg', 'def_rtg', 'sos', 'ie', 'efg_pct', 'to_poss', 'orb_pct', 'ft_rate', 'reb_pct', 'drb_pct', 'ts_pct', 'ast_rtio', 'blk_pct', 'stl_pct']]\n\n\ndf_tourney = df_tourney_all[(df_tourney_all.Season >= 2003) & (df_tourney_all.Season < 2018)]\ndf_tourney.reset_index(inplace=True, drop=True)\n\n# Merge tourney games with tourney winners' season features:\ndf_winners = pd.merge(left=df_tourney[['Season', 'WTeamID', 'LTeamID']], right=df_features, how='left', left_on=['Season', 'WTeamID'], right_on=['Season', 'TeamID'])\ndf_winners.drop(['TeamID'], inplace=True, axis=1) \n\n# Merge tourney games with loser features:\ndf_losers = pd.merge(left=df_tourney[['Season', 'WTeamID', 'LTeamID']], right=df_features, how='left', left_on=['Season', 'LTeamID'], right_on=['Season', 'TeamID'])\ndf_losers.drop(['TeamID'], inplace=True, axis=1)\n\n# Create winner target by subtracting loser data from winner data,\n# and assigning a value of 1:\ndf_winner_diff = (df_winners.iloc[:, 3:] - df_losers.iloc[:, 3:])\ndf_winner_diff['result'] = 1\n\n# Create loser target by subtracting winner data from loser data,\n# and assigning a value of 0:\ndf_loser_diff = (df_losers.iloc[:, 3:] - df_winners.iloc[:, 3:])\ndf_loser_diff['result'] = 0\n\n# Concatenate winner data with loser data:\ndf_model = pd.concat((df_winner_diff, df_loser_diff), axis=0)\n\nX = df_model.iloc[:, :-1]\ny = df_model.result\n\n# Split the dataframe into 65% training and 35% testing:\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46986b6b2d00cbd286e19e6e242c809c699f296e"},"cell_type":"code","source":"lr_clf = LogisticRegression(random_state=32)\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(lr_clf, X_train, X_test, y_train, y_test, lr_param_grid, cv=10, scale=False)\nlogisticRegression = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='logisticRegression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a7669b15c17224d5a31479d9defe6e6ade683fb"},"cell_type":"code","source":"svm_clf = svm.SVC(probability=True, random_state=32)\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(svm_clf, X_train, X_test, y_train, y_test, svm_param_grid, cv=10, scale=False)\nsvmSVC = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='svmSVC')\n\n# Start a summary of all models:\nall_models = pd.concat([logisticRegression, svmSVC])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03c01735c605127d3c30be1cf50e75563d232820"},"cell_type":"code","source":"dt_clf = DecisionTreeClassifier(random_state=32)\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(dt_clf, X_train, X_test, y_train, y_test, dt_param_grid, cv=10, scale=False)\ndecisionTreeClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='decisionTreeClassifier')\nall_models = pd.concat([all_models, decisionTreeClassifier])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c86401cf69ecd901ffd5f3c6ec4cd5546045d9e"},"cell_type":"code","source":"rf_clf = RandomForestClassifier(random_state=32, n_jobs=-1)\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(rf_clf, X_train, X_test, y_train, y_test, rf_param_grid, cv=10, scale=False)\nrandomForestClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='randomForestClassifier')\nall_models = pd.concat([all_models, randomForestClassifier])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"946b120faaaa53305dd8f8c2371ee59f69444dc7"},"cell_type":"code","source":"xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=32)\ntrain_accuracy, test_accuracy, auc, logloss = clfy_report(xgb_clf, X_train, X_test, y_train, y_test, xgb_param_grid, cv=10, scale=False)\nxgbClassifier = summary_of_models(train_accuracy, test_accuracy, auc, logloss, model_name='xgbClassifier')\nall_models = pd.concat([all_models, xgbClassifier])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0288b0921cd8e3bfb501ddb1184c80af5515f09a"},"cell_type":"code","source":"# Sort all models by Test Accuracy:\ncompare_models2 = all_models.copy()\ncompare_models2.set_index('model_name', inplace=True)\ncompare_models2.sort_values(by=['Test Accuracy', 'AUROC'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ef1112d8d9ac15a89afbb7ef38a100dd10486ee"},"cell_type":"code","source":"compare_models.sort_values(by=['Test Accuracy', 'AUROC'], ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87fbd48c44afee8edafa5453af223fd1e2282efb"},"cell_type":"markdown","source":"### LOGISTIC REGRESSION"},{"metadata":{"trusted":true,"_uuid":"4a9c94520dd655b9066fafedccfd1faf89acebce"},"cell_type":"code","source":"# Create pipeline for scaling and classifying:\npipe = Pipeline([('clf', lr_clf)])\n    \nlr_search_ns = GridSearchCV(pipe, lr_param_grid, cv=10)\nlr_search_ns.fit(X_train, y_train)\nprint(lr_search_ns.best_params_)\n\nperm = PermutationImportance(lr_search_ns, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names=X_test.columns.tolist())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c87459cf37c405bfa6680f027777cfd0acb91d6b"},"cell_type":"markdown","source":"So, after Net and Offensive Efficiency, the logistic regression model benefited most from the Four Factors!"},{"metadata":{"trusted":true,"_uuid":"4251d6a64958da2d82d3577a11d499e28eaa6e0c"},"cell_type":"code","source":"df_predict = pd.read_csv('../input/mens-machine-learning-competition-2018/SampleSubmissionStage2.csv')\n\ndef predict_poss_matches(clf, df_predict=df_predict, df_features=df_features):\n    diff = []\n    data = []\n\n    for i, row in df_predict.iterrows():\n\n        year, team1, team2 = get_year_team1_team2(row.ID)\n\n        # Save 2018 stats/features for the first ID:\n        team1 = df_features[(df_features['Season'] == year) & (df_features['TeamID'] == team1)].values[0]\n\n        # Save 2018 stats/features for the first ID:\n        team2 = df_features[(df_features['Season'] == year) & (df_features['TeamID'] == team2)].values[0]   \n\n        diff = team1 - team2\n\n        data.append(diff)\n\n    n_poss_games = len(df_predict)\n    columns = df_features.columns.get_values()\n    final_predictions = pd.DataFrame(np.array(data).reshape(n_poss_games, np.array(data).shape[1]), columns=(columns))\n    final_predictions.drop(['Season', 'TeamID'], inplace=True, axis=1)\n    predictions = clf.predict_proba(final_predictions)[:, 1]\n    clipped_predictions = np.clip(predictions, 0.05, 0.95)\n    df_predict.Pred = clipped_predictions\n    \n    return df_predict\n\npredict_poss_matches(lr_search_ns).to_csv('best_model_results_noseed.csv', index=False) # LogLoss = 0.6613054887607995 Thanks to this website: https://www.marksmath.org/visualization/kaggle_brackets/\n\n# b = build_bracket(\n#         outputPath='best_bracket_noseeds.png',\n#         submissionPath='../output/best_model_results_noseed.csv',\n#         teamsPath='../input/mens-machine-learning-competition-2018/datafiles/Teams.csv',\n#         seedsPath='../input/mens-machine-learning-competition-2018/Stage2UpdatedDataFiles/NCAATourneySeeds.csv',\n#         slotsPath='../input/mens-machine-learning-competition-2018/Stage2UpdatedDataFiles/NCAATourneySlots.csv',\n#         year=2018\n# )\n\ncreate_download_link(predict_poss_matches(lr_search_ns), filename='best_model_results_noseed_kaggle.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08a58e275700decb09e4b5d0e65dae960f978d9b"},"cell_type":"markdown","source":"![](https://imgur.com/Ra7ciqj.png)\n\nWell this bracket performed worse. But had it been true, ignoring that improbability, nothing stands out that would have defied what we know (and love) about the tournament. At least, nothing quite like a tournament of better seeds winning nearly every game. Blah!\n\n### Machine learning helps, but not enough to take over!\nThe best model with seed data correctly predicted Villanova as the champion, and ultimately predicted games more accurately. The best model without seed data did a crummy job with later rounds, was less accurate, but resembled March Madness.\n\nThis leaves me planning to explore better ways to capture seed importance. Until then, I may make hybrid picks (machine learning AND me), using this next (and last) series of graphs as a guide.\n\nRecall that the modeled data are differences between tournament winners and losers, so each graph shows how that difference in a particular feature value influences the probability of a win. The method used (partial dependence plots) makes multiple predictions using all features while incrementally changing the value of the given feature and calculating the probability of a win for each new value."},{"metadata":{"trusted":true,"_uuid":"d179bbfb605069394787c8eb0cad964706349718"},"cell_type":"code","source":"sos = pdp.pdp_isolate(model=lr_search_ns, dataset=X_test, model_features=X_test.columns.tolist(), feature='sos')\npdp.pdp_plot(sos, 'Net Efficiency');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3eae802ad4a80146d0ca78e23d0fe1c1193a0a3"},"cell_type":"markdown","source":"The first key takeaway is reassurance that what the model learned follows intuition. Generally, as the difference between a team and opponent becomes more positive, so does the probability of a win.\n\nSo, in this case, if all else is equal between two teams, the probability of a win increases by about 0.25 for a team that has a Net Efficiency of 10 more than their opponent."},{"metadata":{"trusted":true,"_uuid":"5e50d056ef188ee0d8b01447921bc031a5483552"},"cell_type":"code","source":"off_rtg = pdp.pdp_isolate(model=lr_search_ns, dataset=X_test, model_features=X_test.columns.tolist(), feature='off_rtg')\npdp.pdp_plot(off_rtg, 'Offensive Rating');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"396d0e1fd1120ac5c9d7c8a433c7bfad62a9ba96"},"cell_type":"code","source":"orb_pct = pdp.pdp_isolate(model=lr_search_ns, dataset=X_test, model_features=X_test.columns.tolist(), feature='orb_pct')\npdp.pdp_plot(orb_pct, 'orb_pct');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eafc034772f81569dc1f80d831b9c047c4c16f4f"},"cell_type":"markdown","source":"---\nBesides getting a handle on seed importance, there are certainly many other basketball statistics to consider - and good info/research available to do so. And non-basketball features - distance from home court perhaps. Or it may help to eliminate some. But I want to win too, so this is where my spirit of friendly competition ends! :)"},{"metadata":{"_uuid":"b95d77002c59cfbd6816a54e58d5125ab96ef808"},"cell_type":"markdown","source":"<a id='seed' href='#top'>back to menu</a>"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}