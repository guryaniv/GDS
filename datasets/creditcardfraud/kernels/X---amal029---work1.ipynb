{"nbformat": 4, "cells": [{"cell_type": "markdown", "execution_count": null, "metadata": {"_uuid": "1ec814e2e3978193b93a9a51c7fd87672c02fc3b", "_execution_state": "idle", "collapsed": false}, "outputs": [], "source": "Simple and efficient Logistic regression model with fraudulent recall approx: 83% and miss-classification of non-fraudulent as fraudulent approximately: 0.06%"}, {"cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "efc18b9e-42fb-43f5-bb9b-f414bc1f7514", "_execution_state": "idle", "_uuid": "ae35a1ad7dd06efa4113e711a39dc9c68b5cc31c"}, "outputs": [], "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression as Logit\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, precision_recall_curve\nfrom sklearn.metrics import confusion_matrix\n\ndef all_logit(X_train, y_train, X_test):\n    lmodel = Logit().fit(X_train, y_train)\n    y_bar = lmodel.predict(X_test)\n    return y_bar\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\ndef main(df):\n    #df = pd.read_csv(f)\n\n   \n    endog = df['Class']\n    exog = df.drop(['Time', 'Class', 'Amount'], axis=1).dropna()\n    X_train, X_test, y_train, y_test = train_test_split(exog, endog)\n    # Undersampling the non-defaulters due to unbalanced dataset\n    # We make it N:1 non-frauds:frauds\n    f = df[df['Class'] == 1]    # All fraudsters\n    nf = df[df['Class'] == 0]   # Non fraudsters\n    if math.ceil(len(nf)/len(f)) > 40:\n        nf = nf.sample(len(f)*40) # This is the main trick\n    df = nf.append(f)\n    endog = df['Class']\n    exog = df.drop(['Time', 'Class', 'Amount'], axis=1).dropna()\n    X_train, _, y_train, _ = train_test_split(exog, endog)\n    y_bar = all_logit(X_train, y_train, X_test)\n\n    # Classification report\n    #print(classification_report(y_test, y_bar))\n    cm = confusion_matrix(y_test, y_bar)\n    \n    #print(\"miss-classification of non-fraud as fraud percentage:\", cm[0,1]/(cm[0,1]+cm[0,0])*100)\n    #print(\"Recall of fraudulent percentage:\", cm[1,1]/(cm[1,0]+cm[1,1])*100)\n    return (cm[0,1]/(cm[0,1]+cm[0,0])), (cm[1,1]/(cm[1,0]+cm[1,1]))\n\n\ndf = pd.read_csv('../input/creditcard.csv')\nmiss, recall = 0, 0\nN = 20\nfor i in range(N):\n    m, r = main(df)\n    miss += m\n    recall += r\n\nprint('miss-classification of non-fraudulent as fraudulent percentage:', miss/N*100)\nprint(\"Recall of fraudulent usage percentage:\", recall/N*100)\n"}], "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "version": "3.6.0"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 0}