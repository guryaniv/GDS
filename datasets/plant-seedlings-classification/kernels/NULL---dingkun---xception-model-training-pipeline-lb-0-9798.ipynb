{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4", "file_extension": ".py"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "2b41bc66-0085-4636-b7e1-40d586995344", "collapsed": true, "_uuid": "f3604b7cb5e50a8da67bc1f3d31f45229601fe4f"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "import os\n", "os.environ['CUDA_VISIBLE_DEVICES']='1'\n", "\n", "from keras.applications import Xception\n", "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n", "from keras.models import Model\n", "from keras.layers import Dense, Dropout\n", "from keras.optimizers import RMSprop\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.regularizers import l2\n", "\n", "CATEGORIES = ['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed', 'Common wheat', 'Fat Hen', 'Loose Silky-bent',\n", "              'Maize', 'Scentless Mayweed', 'Shepherds Purse', 'Small-flowered Cranesbill', 'Sugar beet']\n"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "23b1c3eb-c245-4805-9713-887f1a4cde14", "collapsed": true, "_uuid": "64a829794c69dcc1533f81c064a88d1eaf647bc8"}, "source": ["# split validation set\n", "split=True\n", "\n", "if split:\n", "    import random\n", "    import shutil\n", "    # make dir and mv\n", "    os.mkdir('./dev/')\n", "    for category in CATEGORIES:\n", "        os.mkdir('./dev/' + category)\n", "        name = os.listdir('./train/' + category)\n", "        random.shuffle(name)\n", "        todev = name[:int(len(name) * .2)]\n", "        for file in todev:\n", "            shutil.move(os.path.join('train', category, file), os.path.join('dev', category))\n", "\n"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "3d718276-d336-43ac-93f9-8d0639f61fdd", "collapsed": true, "_uuid": "32fa294ba6f38c1fc84e9873a1ae7b0b9c6e356c"}, "source": ["# lr decay schedule\n", "def lr_schedule(epoch):\n", "    \"\"\"Learning Rate Schedule\n", "    Learning rate is scheduled to be reduced after 80, 120epochs.\n", "    Called automatically every epoch as part of callbacks during training.\n", "    # Arguments\n", "        epoch (int): The number of epochs\n", "    # Returns\n", "        lr (float32): learning rate\n", "    \"\"\"\n", "    lr = 1e-4\n", "    if epoch > 120:\n", "        lr *= 1e-2\n", "    elif epoch > 80:\n", "        lr *= 1e-1\n", "    print('Learning rate: ', lr)\n", "    return lr"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "0c45b072-943e-4e22-8810-c3072287882e", "collapsed": true, "_uuid": "187b6e0c2e6b92ff6a5dfe577e3782c33efdb1ba"}, "source": ["# data generator \n", "train_datagen = ImageDataGenerator(\n", "    rescale=1. / 255,\n", "    rotation_range=50,\n", "    width_shift_range=0.2,\n", "    height_shift_range=0.2,\n", "    shear_range=0.2,\n", "    zoom_range=0.2,\n", "    horizontal_flip=True,\n", "    vertical_flip=True)\n", "\n", "train_generator = train_datagen.flow_from_directory(\n", "    './train',\n", "    target_size=(299, 299),\n", "    batch_size=16,\n", "    class_mode='categorical',\n", "    shuffle=True)\n", "\n", "val_datagen = ImageDataGenerator(rescale=1. / 255)\n", "\n", "val_generator = val_datagen.flow_from_directory(\n", "    './dev',\n", "    target_size=(299, 299),\n", "    batch_size=16,\n", "    class_mode='categorical',\n", "    shuffle=True)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "78494e63-8409-43b8-b6f0-0831a6840768", "collapsed": true, "_uuid": "cff62c4e13e12a88e87a1181c807b32454bd091d"}, "source": ["# pretrain dense layer\n", "# to avoid large gradient to destroy the pretrained model\n", "# build model\n", "tensorboard = TenserBoard('./logs')\n", "\n", "basic_model = Xception(include_top=False, weights='imagenet', pooling='avg')\n", "\n", "for layer in basic_model.layers:\n", "    layer.trainable = False\n", "\n", "input_tensor = basic_model.input\n", "# build top\n", "x = basic_model.output\n", "x = Dropout(.5)(x)\n", "x = Dense(len(CATEGORIES), activation='softmax')(x)\n", "\n", "model = Model(inputs=input_tensor, outputs=x)\n", "model.compile(optimizer=RMSprop(1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n", "\n", "model.fit_generator(train_generator, epochs=40, \n", "                    validation_data=val_generator,\n", "                    callbacks=[tensorboard],\n", "                    workers=4,\n", "                    verbose=0)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_cell_guid": "310b0eca-c481-40aa-8359-17ef3ff65d8a", "collapsed": true, "_uuid": "425c2068281eb4dd0fcf2d530a42f1d2ae4a4f24"}, "source": ["# train with whole model\n", "# train model\n", "for layer in model.layers:\n", "    layer.W_regularizer = l2(1e-2)\n", "    layer.trainable = True\n", "\n", "model.compile(optimizer=RMSprop(lr_schedule(0)), loss='categorical_crossentropy', metrics=['accuracy'])\n", "\n", "# call backs\n", "checkpointer = ModelCheckpoint(filepath='./checkpoint/weights_xception.h5', verbose=1,\n", "                               save_best_only=True)\n", "\n", "\n", "lr = LearningRateScheduler(lr_schedule)\n", "\n", "# train dense layer\n", "model.fit_generator(train_generator, \n", "                    steps_per_epoch=400,\n", "                    epochs=150, \n", "                    validation_data=val_generator,\n", "                    callbacks=[checkpointer, tensorboard, lr],\n", "                    initial_epoch=40,\n", "                    workers=4,\n", "                    verbose=0)\n", "\n", "\n", "model.save('xception.h5')"], "outputs": [], "execution_count": null, "cell_type": "code"}]}