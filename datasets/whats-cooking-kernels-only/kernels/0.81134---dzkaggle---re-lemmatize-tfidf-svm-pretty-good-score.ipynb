{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# data exploring and basic libraries\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom collections import deque as dq\n\n# NLP preprocessing\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import word_tokenize as TK\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder as LE\n\n# binary class classification model\nfrom sklearn.svm import SVC\n\n# One vs All wrapper\nfrom sklearn.multiclass import OneVsRestClassifier as OVRC\n\n# Pretty display for notebooks\nfrom IPython.display import display # Allows the use of display() for DataFrames\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbca192b5697a3ff559548781866a82df6a98c00","collapsed":true},"cell_type":"code","source":"# load the data - test data\nrawdf_te = pd.read_json(path_or_buf='../input/test.json')\nrawdf_te.head(n=3)\n# load the data - train data\nrawdf_tr = pd.read_json(path_or_buf='../input/train.json')\nrawdf_tr.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"518887dcb751d69ddd536ee084154d8204284c1f","collapsed":true},"cell_type":"code","source":"# cuisine distribution\nsns.countplot(y='cuisine', data=rawdf_tr, palette ='Set3')\n\n# number of recipes for each cuisines\nprint('Weight\\t Recipe\\t Cuisine\\n')\nfor _ in (Counter(rawdf_tr['cuisine']).most_common()):print(round(_[1]/rawdf_tr.cuisine.count()*100, 2),'%\\t',_[1],'\\t', _[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3104a1478205693bdec715cfe431d85a3d90312b","collapsed":true},"cell_type":"code","source":"# change id column type to string\nrawdf_tr = rawdf_tr.set_index('id')\nrawdf_te = rawdf_te.set_index('id')\n\n# Total number of recipes\nprint('Total of %d recipes\\n'% len(rawdf_tr))\n\n# total number of UNIQUE cuisines\nprint('Total of %d types of cuisines including %s\\n' % \\\n      (len(rawdf_tr['cuisine'].unique()), rawdf_tr['cuisine'].unique().tolist()))\n                                          \n# UNIQUE # ingredients set - ingredients_set()\n# training ingredient list\ningredients_list_tr = []\nfor _ in rawdf_tr['ingredients']:\n    ingredients_list_tr.append(_)\n# ingredients set - ingredients_set()\ningredients_set_tr = set()\nfor a in range(len(ingredients_list_tr)):\n    for _ in range(len(ingredients_list_tr[a])):\n        ingredients_set_tr.add(ingredients_list_tr[a][_])\nprint(\"Total of %d unique ingredients\\n\" % len(ingredients_set_tr))\n\n# total ingredients list (with repition) occurred in the train data\ntotal_ingredients_list_tr = []\nfor i in range(len(ingredients_list_tr)):\n    for j in range(len(ingredients_list_tr[i])):\n        total_ingredients_list_tr.append(ingredients_list_tr[i][j])\nprint(\"Most common ingredients used:\\n\")\nfor _ in range(len(Counter(total_ingredients_list_tr).most_common(11))):\n    print(Counter(total_ingredients_list_tr).most_common(11)[_])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b4f383b3e736a9a23599b18fe51efc02f4e66d1"},"cell_type":"markdown","source":"What does the ingredients column look like?"},{"metadata":{"trusted":true,"_uuid":"1087a921a046c42222300025bd545ac911b8efdc","collapsed":true},"cell_type":"code","source":"print(rawdf_tr['ingredients'].loc[41935])\nprint(rawdf_tr['ingredients'].loc[27566])\nprint(rawdf_tr['ingredients'].loc[32596])\nprint(rawdf_tr['ingredients'].loc[8476])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79a35b73c6be14f66718278b54d38706d8313091"},"cell_type":"markdown","source":"Preprocess the datasets"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c446b3823461e15c6d428d4a6c3cbb5dd2dbd851"},"cell_type":"code","source":"# copy the series from the dataframe\ningredients_tr = rawdf_tr['ingredients']\n# do the test.json while at it\ningredients_te = rawdf_te['ingredients']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"74f1033437853beeb699de79232c2df6d525dce4"},"cell_type":"code","source":"# substitute the matched pattern\ndef sub_match(pattern, sub_pattern, ingredients):\n    for i in ingredients.index.values:\n        for j in range(len(ingredients[i])):\n            ingredients[i][j] = re.sub(pattern, sub_pattern, ingredients[i][j].strip())\n            ingredients[i][j] = ingredients[i][j].strip()\n    re.purge()\n    return ingredients\n\ndef regex_sub_match(series):\n    # remove all units\n    p0 = re.compile(r'\\s*(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\s*[^a-z]')\n    series = sub_match(p0, ' ', series)\n    # remove all digits\n    p1 = re.compile(r'\\d+')\n    series = sub_match(p1, ' ', series)\n    # remove all the non-letter characters\n    p2 = re.compile('[^\\w]')\n    series = sub_match(p2, ' ', series)\n    return series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b4ec61003a9fa27956727ed20bba4426952c3242"},"cell_type":"code","source":"# regex train data\ningredients_tr = regex_sub_match(ingredients_tr)\n# regex test.json data\ningredients_te = regex_sub_match(ingredients_te)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"875d9f7452b35e11e9d7cd78c070e063f762bbea"},"cell_type":"markdown","source":"Lemmatize!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8632c78a0a8d3dd99ff9831a00bdd700dd1f9a3b"},"cell_type":"code","source":"# declare instance from WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\n# remove all the words that are not nouns -- keep the essential ingredients\ndef lemma(series):\n    for i in series.index.values:\n        for j in range(len(series[i])):\n            # get rid of all extra spaces\n            series[i][j] = series[i][j].strip()\n            # Tokenize a string to split off punctuation other than periods\n            token = TK(series[i][j])\n            # set all the plural nouns into singular nouns\n            for k in range(len(token)):\n                token[k] = lemmatizer.lemmatize(token[k])\n            token = ' '.join(token)\n            # write them back\n            series[i][j] = token\n    return series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aeb9a4caeb0c6125aa7baadd67a04ed2db5574be"},"cell_type":"code","source":"# lemmatize the train data\ningredients_tr = lemma(ingredients_tr)\n# lemmatize test.json\ningredients_te = lemma(ingredients_te)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5e1363bb98ba3aeacc4de72a8d2a55426f1c080f"},"cell_type":"markdown","source":"What do they look like now?"},{"metadata":{"trusted":true,"_uuid":"85edfa9de56a1871ad859fffb360f71979cdfe99","collapsed":true},"cell_type":"code","source":"print(ingredients_tr[41935])\nprint(ingredients_tr[27566])\nprint(ingredients_tr[32596])\nprint(ingredients_tr[8476])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb69596461042cc02df6978a4c38be698b236881"},"cell_type":"code","source":"# copy back to the dataframe\nrawdf_tr['ingredients_lemma'] = ingredients_tr\nrawdf_tr['ingredients_lemma_string'] = [' '.join(_).strip() for _ in rawdf_tr['ingredients_lemma']]\n# do the same for the test.json dataset\nrawdf_te['ingredients_lemma'] = ingredients_te\nrawdf_te['ingredients_lemma_string'] = [' '.join(_).strip() for _ in rawdf_te['ingredients_lemma']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10d53da47b0add4d224d63fbea5cc45124b45d1b"},"cell_type":"markdown","source":"TF-IDF vectorizing"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6ecd0c3dc8032d230be523fb06bb41ed6d10ebdd"},"cell_type":"code","source":"# DataFrame for training and validation\ntraindf = rawdf_tr[['cuisine', 'ingredients_lemma_string']].reset_index(drop=True)\n# same for the test set\ntestdf = rawdf_te[['ingredients_lemma_string']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50a4cd12da19b9004141ffe86dcfec61df0c9bba","collapsed":true},"cell_type":"code","source":"# training ===================\n# X_train\nX_train = traindf['ingredients_lemma_string']\nvectorizertr = TfidfVectorizer(stop_words='english', analyzer=\"word\", max_df=0.65, min_df=2, binary=True)\nX_train = vectorizertr.fit_transform(X_train)\n\n# y_train\ny_train = traindf['cuisine']\n# for xgboost the labels need to be labeled with encoder\nle = LE()\ny_train_ec = le.fit_transform(y_train)\n\n# predicting =================\n# X_pred\nX_pred = testdf['ingredients_lemma_string']\nvectorizerts = TfidfVectorizer(stop_words='english')\nX_pred = vectorizertr.transform(X_pred)\n\n# y_true","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"796a71d261a85a7d0252a605d67d2a52787a1b41"},"cell_type":"markdown","source":"> SVM model wiht 'ovr'"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1131321af81c60a531e83e4f87b6ef9116aba887"},"cell_type":"code","source":"# Best parameters after running the grid search for One-Versus-All SVM\nclf_ovrc_svm = SVC(C=3.25, cache_size=500, class_weight=None, coef0=0.0,\\\n  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\\\n  max_iter=-1, probability=False, random_state=0, shrinking=True,\\\n  tol=0.001, verbose=False)\n\nclf_ovrc_svm = clf_ovrc_svm.fit(X_train, y_train)\n\ny_pred_ovrc_svm = clf_ovrc_svm.predict(X_pred)\n\ntestdf['cuisine'] = y_pred_ovrc_svm\nd = pd.DataFrame(data=testdf['cuisine'], index=testdf.index).sort_index().reset_index().to_csv('submission_ovr_svm.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}