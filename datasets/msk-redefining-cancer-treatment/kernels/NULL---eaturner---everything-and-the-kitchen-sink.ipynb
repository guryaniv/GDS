{"cells": [{"source": "The purpose of this kernel is to demonstrate how to implement model selection methods, and feature engineering.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "d3387a8679da6f8726900841952243a57d381c5d", "_execution_state": "idle", "collapsed": false, "_cell_guid": "f9473971-8bb3-43c1-b883-88ef3e24c494"}, "execution_count": null}, {"source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "41967b613760b1509255ea312fa21be17a2f0bbe", "_execution_state": "idle", "_cell_guid": "d6c93756-2ee2-41a5-a050-823d2e4b7ba5"}, "execution_count": null}, {"source": "train = pd.read_csv('../input/training_variants')\ntest = pd.read_csv('../input/test_variants')\ntrainx = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntestx = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n\ntrain = pd.merge(train, trainx, how='left', on='ID')\n\ntest = pd.merge(test, testx, how='left', on='ID')", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "e0034975e9682c82ad6bcb79b0130497f46f81d4", "_execution_state": "idle", "collapsed": false, "_cell_guid": "fc6741f4-bbbf-4c00-a48d-10d594e62a2d"}, "execution_count": null}, {"source": "First, lets add a few features regarding the length of the textual data.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "abfa0f1c542c35c59293f815cabf2bbdf2888d31", "_execution_state": "idle", "collapsed": false, "_cell_guid": "d04d5006-0ac5-4970-b110-bad2d0404a40"}, "execution_count": null}, {"source": "def catCount( train, test, col ):\n    \n    train.loc[:, col + '_count']  = train[col].apply(lambda x: len(x.split()))\n    test.loc[:, col + '_count'] = test[col].apply(lambda x: len(x.split()))\n\n    return train, test\n\ntrain, test = catCount(train, test, 'Text')", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "766f23ae3b7df2f27eb44331659bd49f9fccc862", "_execution_state": "idle", "collapsed": false, "_cell_guid": "c1cf9bcc-568a-4b48-8672-756bdb1cef05"}, "execution_count": null}, {"source": "def newCatFeatures( train_df, test_df, col, n_comp = 25 ):\n    \n    from sklearn.feature_extraction.text import TfidfVectorizer\n    from sklearn.decomposition import TruncatedSVD\n    \n    print ( 'Features Before: ' + str(train_df.shape[1]) )\n    \n    wordSpace = train_df[col].append(test_df[col])\n    \n    wordCounts = [len(x.split()) for x in wordSpace]\n    \n    if np.max(wordCounts) > 20:\n        tfidf = TfidfVectorizer(strip_accents='unicode',lowercase =True, analyzer='char_wb', \n\t               ngram_range = (2,3), norm = 'l2', sublinear_tf = True, min_df = 1e-2,\n                                   stop_words = 'english').fit(wordSpace)\n    else:\n        tfidf = TfidfVectorizer(strip_accents='unicode',lowercase =True, analyzer='char', \n\t            ngram_range = (1,8), norm = 'l2', sublinear_tf = True, \n                                stop_words = 'english').fit(wordSpace)\n        \n    print ('Found term frequencies')\n    \n    svd = TruncatedSVD(n_components = n_comp, n_iter=25, random_state=12)\n    \n    Xtr = svd.fit_transform( tfidf.transform( train_df[col] ) )\n    Xtst = svd.transform( tfidf.transform( test_df[col] ) )\n\n    print ('Performed SVD')\n    \n    features_ = [ col + '_tfidf_svd_' + str(i+1) for i in range(Xtr.shape[1]) ]\n\n    train_df = pd.concat( [train_df, pd.DataFrame(Xtr, columns = features_) ], axis = 1)\n    test_df = pd.concat( [test_df, pd.DataFrame(Xtst, columns = features_) ], axis = 1)\n\n    print ( 'Features After: ' + str(train_df.shape[1]) + '\\n')\n    \n    train_df.drop(col, axis = 1, inplace = True)\n    test_df.drop(col, axis = 1, inplace = True)\n    \n    return train_df, test_df", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "6eb209860e1328098d52c446410f7d3ff1dacbbf", "_execution_state": "idle", "collapsed": false, "_cell_guid": "eeba9072-4ca6-40e1-8567-bbc0fd604522"}, "execution_count": null}, {"source": "Now lets find the tfidf of our textual features and then perform svd on the tfidf matrix.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "46a5d6840ccb094502e7c4883bc56aa1823225fe", "_execution_state": "idle", "collapsed": false, "_cell_guid": "857a8919-57f3-4c03-928e-fba0a5af16b3"}, "execution_count": null}, {"source": "train, test = newCatFeatures(train, test, 'Gene', n_comp = 20)\n\ntrain, test = newCatFeatures(train, test, 'Variation', n_comp = 20)\n\ntrain, test = newCatFeatures(train, test, 'Text', n_comp = 50)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "67056e6c21ace9607c84ef467985ef453d145b12", "_execution_state": "idle", "collapsed": false, "_cell_guid": "df4c0822-2d6e-4cf0-b55e-994f3a6ce89b"}, "execution_count": null}, {"source": "train.drop('ID', axis = 1, inplace = True)\n\nclasses = ['Class' + str(i + 1) for i in range(9)]\n\ndf_sub = pd.DataFrame( columns = ['ID'] )\n\ndf_sub['ID'] = test.pop('ID')", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "10a11818593140b4c9837efb0971147d330353c8", "_execution_state": "idle", "collapsed": false, "_cell_guid": "29b71d6e-15a9-4489-9b4c-5d973f181353"}, "execution_count": null}, {"source": "To have an idea of the correlations, let us create a correlation plot.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "0e8f38ab245db37783ad5764c9b847d46bd6a318", "_execution_state": "idle", "collapsed": false, "_cell_guid": "e26fa032-fb10-4cb9-9b91-5b043468c3fa"}, "execution_count": null}, {"source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\ncor_ = train.corr()\n\nsns.heatmap(cor_, vmax=.8, square=True)\n\nplt.show()\n\ntrain_labels = train.pop('Class') - 1", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "023a4c3dd1a43f02f7105cb5140be0e375502042", "_execution_state": "idle", "collapsed": false, "_cell_guid": "cd7807a0-a2cb-4fef-8429-78b479ff0d3d"}, "execution_count": null}, {"source": "Let use create a few models for our predictions.", "cell_type": "markdown", "outputs": [], "metadata": {"_uuid": "6940abbe46e48fa8a2bea260bf6996d54aa09c62", "_execution_state": "idle", "collapsed": false, "_cell_guid": "b95f6bd3-b80d-4894-881b-53c8c63bd315"}, "execution_count": null}, {"source": "#base learners\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neural_network import MLPClassifier\n\n#model selection\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n#aid in model selection\nfrom scipy.stats import expon\n\nparam_grid = {\"n_neighbors\": range(2,7)}\nparam_dist = {'C': expon(scale=100) }\n\nclf_list = [\n    GridSearchCV(KNeighborsClassifier(weights = 'uniform'), param_grid, cv = 5, scoring = 'neg_log_loss'),\n    GridSearchCV(KNeighborsClassifier(weights = 'distance'), param_grid, cv = 5, scoring = 'neg_log_loss'),\n    LogisticRegressionCV(cv = 5, solver = 'sag', multi_class = 'multinomial', n_jobs = -1),\n    MLPClassifier(activation = 'logistic', learning_rate = 'adaptive', warm_start = True),\n    MLPClassifier(activation = 'identity', learning_rate = 'adaptive', warm_start = True),\n    MLPClassifier(activation = 'tanh', learning_rate = 'adaptive', warm_start = True),\n    MLPClassifier(activation = 'relu', learning_rate = 'adaptive', warm_start = True)\n]\n\nn = len(clf_list)\n\npredictions = np.zeros( (test.shape[0], 9) )\n\nfor i in range(n):\n    print('At classifer: ' + str(i + 1) )\n    clf = clf_list[i]\n    \n    clf.fit(train, train_labels)\n    \n    predictions = predictions + clf.predict_proba( test )\n\npredictions = (1.0/n) * predictions\n\ndf_pred = pd.DataFrame(predictions, columns = classes)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "19c06e09321e18038d453d35c6e458904aa9ac19", "_execution_state": "idle", "collapsed": false, "_cell_guid": "65c4ced0-6e5d-45c9-b355-f964f325af17"}, "execution_count": null}, {"source": "df_sub = pd.concat([df_sub, df_pred], axis = 1)\n\ndf_sub.to_csv('submission.csv', index=False)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "a31e1e4533c32a000bbb6f256408caac7349a1cf", "_execution_state": "idle", "collapsed": false, "_cell_guid": "b0c4ee9b-ad30-4cde-8353-e3a31a658bc6"}, "execution_count": null}, {"source": "df_sub.head(10)", "cell_type": "code", "outputs": [], "metadata": {"trusted": false, "_uuid": "7e8cacee58615292e3abe01b2e078eb3a650911b", "_execution_state": "idle", "collapsed": false, "_cell_guid": "76166222-0794-4fb6-8a81-1e7ed91c7776"}, "execution_count": null}], "nbformat_minor": 0, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.1", "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4}