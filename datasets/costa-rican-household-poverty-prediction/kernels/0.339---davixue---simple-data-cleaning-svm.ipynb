{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n# Importing the dataset\ndataset = pd.read_csv('../input/train.csv')\ndatasetTest = pd.read_csv('../input/test.csv')\n\n\n# Dealing with Objects in 'dependency'\ndataset.dependency.value_counts()\n# Calculating seperate dependency values\ndataset['dependency_calculated'] = (dataset.hogar_nin + dataset.hogar_mayor)/(dataset.hogar_adul - dataset.hogar_mayor)\ndataset[['dependency','dependency_calculated']]\n# Replacing no, yes, inf\ndataset.dependency.replace('no','0',inplace=True)\ndataset.dependency.replace('yes','1',inplace=True)\ndataset.dependency_calculated.replace(float('inf'),8,inplace=True)\n# Set dataset as float\ndataset.dependency = dataset.dependency.astype('float')\n# Dropping calculated column\ndataset.drop('dependency_calculated', axis=1, inplace=True)\n\n# Dealing with Objects in 'dependency' in test data\ndatasetTest.dependency.replace('no','0',inplace=True)\ndatasetTest.dependency.replace('yes','1',inplace=True)\ndatasetTest.dependency = datasetTest.dependency.astype('float')\n\n# Dealing with Objects in 'edjefe'\ndataset.edjefe.value_counts()\ndataset.edjefe.replace('no','0',inplace=True)\ndataset.edjefe.replace('yes','1',inplace=True)\ndataset.edjefe = dataset.edjefe.astype('float')\ndatasetTest.edjefe.replace('no','0',inplace=True)\ndatasetTest.edjefe.replace('yes','1',inplace=True)\ndatasetTest.edjefe = datasetTest.edjefe.astype('float')\n\n# Dealing with Objects in 'edjefa'\ndataset.edjefa.value_counts()\ndataset.edjefa.replace('no','0',inplace=True)\ndataset.edjefa.replace('yes','1',inplace=True)\ndataset.edjefa = dataset.edjefa.astype('float')\ndatasetTest.edjefa.replace('no','0',inplace=True)\ndatasetTest.edjefa.replace('yes','1',inplace=True)\ndatasetTest.edjefa = datasetTest.edjefa.astype('float')\n\n# Filling NaN columns with 0\ncol_fillna = ['v18q1', 'meaneduc', 'SQBmeaned']\ndataset[col_fillna] = dataset[col_fillna].fillna(0)\ndatasetTest[col_fillna] = datasetTest[col_fillna].fillna(0)\n\n# Excluding columns\ncol_exclude = ['Id','idhogar','v2a1','rez_esc']\ndataset.drop(col_exclude, axis=1, inplace=True)\ndatasetTest.drop(col_exclude, axis=1, inplace=True)\n\n# Selecting training set\nX = dataset.iloc[:, :-1].values\ny = dataset.iloc[:, 138].values\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Fitting Kernel SVM to the Training set\nfrom sklearn.svm import SVC\nclassifier = SVC(kernel = 'rbf', gamma = 'auto', random_state = 0)\nclassifier.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = classifier.predict(X_test)\n\n# Making the Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Selecting test set\nX_sub = datasetTest.iloc[:, :].values\nsubTest = pd.read_csv('../input/test.csv')\n\n# Feature Scaling\nX_sub = sc.transform(X_sub)\n\n# Predicting the Test set results\ny_sub = classifier.predict(X_sub)\n\n# Submission\nsubs = pd.DataFrame()\nsubs['Id'] = subTest['Id']\nsubs['Target'] = y_sub\nsubs.to_csv('submission.csv', index=False)\nsubs.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}