{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n\n# import xgboost as xgb\n# import lightgbm as lgb\n\n# from sklearn.linear_model import LinearRegression, SGDRegressor\n# from sklearn.metrics import mean_squared_error\n\n# # KERAS \n# from keras.models import Sequential\n# from keras.layers import Dense\n# from keras.wrappers.scikit_learn import KerasRegressor\n# from keras import backend as K\n\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86649522e9d91044e980d6dff637b97a972b431a"},"cell_type":"code","source":"# read data in pandas dataframe\ntrain =  pd.read_csv('../input/train.csv', nrows = 1000000, parse_dates=[\"pickup_datetime\"])\n\n# list first few rows (datapoints)\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7078c4365905130be574d36be43622553bf73ae"},"cell_type":"code","source":"train.describe()\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c8777bfcd1b4632ba6a5fba1d02470553987c1d"},"cell_type":"markdown","source":"### Remove Data\n1. We drop all rows which  fare_amount is negative"},{"metadata":{"trusted":true,"_uuid":"1f38671b888b61b179839b652448c2c9400ec40f"},"cell_type":"code","source":"train = train[train.fare_amount>=0]\nprint('Number of rows {:,}'.format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2638f2dff9eeb8d52b686734fd256e5cebdefa9a"},"cell_type":"markdown","source":"2. We drop rows with null values"},{"metadata":{"trusted":true,"_uuid":"0c16bf0a2b8878418a511d772edf847bc4f0f2d2"},"cell_type":"code","source":"train.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40ff7360dacaa82811bd101f85bb5514bd8381f4"},"cell_type":"code","source":"train = train[~train.dropoff_longitude.isnull()]\ntrain = train[~train.dropoff_latitude.isnull()]\nprint('Number of rows {:,}'.format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31933bbcc5abb87f98fbc206646eaef378005fe8"},"cell_type":"markdown","source":"3. We set a bounders based on mini and maxime coodinates in test set. "},{"metadata":{"trusted":true,"_uuid":"1322ef3b28f62f135fafed35b6ecd74c670d631b"},"cell_type":"code","source":"# read data in pandas dataframe\ntest =  pd.read_csv('../input/test.csv', nrows = 2000000, parse_dates=[\"pickup_datetime\"])\n\n# list first few rows (datapoints)\nprint(test.shape)\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"950738d4a38e9d9c5101674bb56a829f3bd1e19a"},"cell_type":"code","source":"plt.boxplot(train[train.pickup_latitude<39].pickup_latitude)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6425b4eacaf14485091208ec917846c243842f5c"},"cell_type":"code","source":"# minimum and maximum longitude test set\nprint('Minimus and maximum longitude Test ')\nmin(test.pickup_longitude.min(), test.dropoff_longitude.min()), \\\nmax(test.pickup_longitude.max(), test.dropoff_longitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bbf6a925a7afa2fc5a62e2bb024ca5a7ac5d1a7"},"cell_type":"code","source":"# minimum and maximum latitude test\nprint('Minimus and maximum latitude Test ')\nmin(test.pickup_latitude.min(), test.dropoff_latitude.min()), \\\nmax(test.pickup_latitude.max(), test.dropoff_latitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73c9d24f467043d41a3c21114427ad35546ae52a"},"cell_type":"code","source":"# this function will also be used with the test set below\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n            \n# load image of NYC map\nBB = (-74.5, -72.8, 40.5, 41.8)\nnyc_map = plt.imread('https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png')\n\n# load extra image to zoom in on NYC\nBB_zoom = (-74.3, -73.7, 40.5, 40.9)\nnyc_map_zoom = plt.imread('https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f75ee5faaeeb64a88a0d2cff0f16f945a3b8e56d"},"cell_type":"code","source":"\ntrain = train[select_within_boundingbox(train, BB)]\nprint('Number of rows {:,}'.format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04a0d2c25cb4dd636fd52a4c4dcdce4a067ca3dd"},"cell_type":"code","source":"# this function will be used more often to plot data on the NYC map\ndef plot_on_map(df, BB, nyc_map, s=10, alpha=0.2):\n    fig, axs = plt.subplots(1, 2, figsize=(16,10))\n    axs[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[0].set_xlim((BB[0], BB[1]))\n    axs[0].set_ylim((BB[2], BB[3]))\n    axs[0].set_title('Pickup locations')\n    axs[0].imshow(nyc_map, zorder=0, extent=BB)\n\n    axs[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder=1, alpha=alpha, c='r', s=s)\n    axs[1].set_xlim((BB[0], BB[1]))\n    axs[1].set_ylim((BB[2], BB[3]))\n    axs[1].set_title('Dropoff locations')\n    axs[1].imshow(nyc_map, zorder=0, extent=BB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4c82801f9d648d5364c95a96fcb7686f9e8e3a0"},"cell_type":"code","source":"# plot training data on map\nplot_on_map(train, BB, nyc_map, s=1, alpha=0.3)\nplot_on_map(train, BB_zoom, nyc_map_zoom, s=1, alpha=0.3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b171000609dd2a8f67bc7c26741d1bca1171ab3"},"cell_type":"markdown","source":" ### Removing datapoints in water\n\nAs can be seen from the map + scatter plots above, some datapoints are located in the water. These are obviously noisy datapoints. To remove these datapoints, I create a boolean land/water map from the NYC map. For this I used Photoshop to threshold on the blue color of the water and to cleanup the map. The resulting map is show below."},{"metadata":{"trusted":true,"_uuid":"bb3012d7d74a614997f58a43c47da20bfb630e17"},"cell_type":"code","source":"# read nyc mask and turn into boolean map with\n# land = True, water = False\nnyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n\nplt.figure(figsize=(8,8))\nplt.imshow(nyc_map, zorder=0)\nplt.imshow(nyc_mask, zorder=1, alpha=0.7); # note: True is show in black, False in white.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65d2bae954b99b950b030681d5fa69df3e117c5c"},"cell_type":"code","source":"# translate longitude/latitude coordinate into image xy coordinate\ndef lonlat_to_xy(longitude, latitude, dx, dy, BB):\n    return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n           (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fbe2fcdc14bfebe5395c54239f67c86edeb6f7f"},"cell_type":"code","source":"pickup_x, pickup_y = lonlat_to_xy(train.pickup_longitude, train.pickup_latitude, \n                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)\ndropoff_x, dropoff_y = lonlat_to_xy(train.dropoff_longitude, train.dropoff_latitude, \n                                  nyc_mask.shape[1], nyc_mask.shape[0], BB)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83fcdee9e445ffc8a775e85612b125791835787a"},"cell_type":"code","source":"idx = (nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x])\nprint(\"Number of trips in water: {}\".format(np.sum(~idx)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0ea149173ca9e8467f0719ab2dbe685601427ef"},"cell_type":"code","source":"def remove_datapoints_from_water(df):\n    def lonlat_to_xy(longitude, latitude, dx, dy, BB):\n        return (dx*(longitude - BB[0])/(BB[1]-BB[0])).astype('int'), \\\n               (dy - dy*(latitude - BB[2])/(BB[3]-BB[2])).astype('int')\n\n    # define bounding box\n    BB = (-74.5, -72.8, 40.5, 41.8)\n    \n    # read nyc mask and turn into boolean map with\n    # land = True, water = False\n    nyc_mask = plt.imread('https://aiblog.nl/download/nyc_mask-74.5_-72.8_40.5_41.8.png')[:,:,0] > 0.9\n    \n    # calculate for each lon,lat coordinate the xy coordinate in the mask map\n    pickup_x, pickup_y = lonlat_to_xy(df.pickup_longitude, df.pickup_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)\n    dropoff_x, dropoff_y = lonlat_to_xy(df.dropoff_longitude, df.dropoff_latitude, \n                                      nyc_mask.shape[1], nyc_mask.shape[0], BB)    \n    # calculate boolean index\n    idx = nyc_mask[pickup_y, pickup_x] & nyc_mask[dropoff_y, dropoff_x]\n    \n    # return only datapoints on land\n    return df[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f31a7b453e73d4b61a2cd6a1e7c7744d38d4cac"},"cell_type":"code","source":"train = remove_datapoints_from_water(train)\nprint('Number of rows {:,}'.format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54503ce24608a219b3c265e21feedc5e371dff99"},"cell_type":"markdown","source":"### Pickup traffic density\nThe density plots of above triggered me to see if I can visualize traffic density by the hour (and year). By counting the number of pickups in an area we should get some impression of the traffic density. The more traffic, the longer it could take to make a drive."},{"metadata":{"trusted":true,"_uuid":"569e0d8fe9e25b7997c3fbb4f4faae5fe51f1cf4"},"cell_type":"code","source":"# add time information\ntrain['year'] = train.pickup_datetime.apply(lambda t: t.year)\ntrain['weekday'] = train.pickup_datetime.apply(lambda t: t.weekday())\ntrain['hour'] = train.pickup_datetime.apply(lambda t: t.hour)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"555aa1edd1eab121fc5c95cc5a8c0c4990d58989"},"cell_type":"code","source":"# some constants needed to calculate pickup traffic density\nn_hours = 24\nn_weekdays = 7\nn_years = 7\nn_bins_lon = 30\nn_bins_lat = 30\n\n# focus on traffic in Manhattan\nBB_traffic = (-74.025, -73.925, 40.7, 40.8)\n\n# define function to calculate pickup traffic density\ndef calculate_trafic_density(df):\n    traffic = np.zeros((n_years, n_weekdays, n_hours, n_bins_lat, n_bins_lon))\n    \n    # To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n    # This function needs an array with the (location) bins for counting the number of datapoints\n    # per bin.\n    bins_lon = np.zeros(n_bins_lon+1) # bin\n    bins_lat = np.zeros(n_bins_lat+1) # bin\n    \n    delta_lon = (BB_traffic[1]-BB_traffic[0]) / n_bins_lon # bin longutide width\n    delta_lat = (BB_traffic[3]-BB_traffic[2]) / n_bins_lat # bin latitude height\n    \n    for i in range(n_bins_lon+1):\n        bins_lon[i] = BB_traffic[0] + i * delta_lon\n    for j in range(n_bins_lat+1):\n        bins_lat[j] = BB_traffic[2] + j * delta_lat\n    \n    # Count per grid bin\n    # note: as the density_pickup will be displayed as image, the first index is the y-direction, \n    #       the second index is the x-direction. Also, the y-direction needs to be reversed for\n    #       properly displaying (therefore the (n_lat-j) term)\n    for y in range(n_years):\n        for d in range(n_weekdays):\n            for h in range(n_hours):\n                idx = (df.year==(2009+y)) & (df.weekday==d) & (df.hour==h)\n\n                # Digitize per longitude, latitude dimension\n                inds_pickup_lon = np.digitize(df[idx].pickup_longitude, bins_lon)\n                inds_pickup_lat = np.digitize(df[idx].pickup_latitude, bins_lat)\n\n                for i in range(n_bins_lon):\n                    for j in range(n_bins_lat):\n                        traffic[y, d, h, j, i] = traffic[y, d, h, j, i] + \\\n                                                 np.sum((inds_pickup_lon==i+1) & (inds_pickup_lat==j+1))\n    \n    return traffic \n\n# define function to plot pickup traffic density\ndef plot_traffic(traffic, y, d):\n    days = {'monday' : 0, 'tuesday' : 1, 'wednesday' : 2, 'thursday' : 3, 'friday' : 4, 'saturday' : 5, 'sunday' : 6}\n    fig, axs = plt.subplots(3,8,figsize=(18,7))\n    axs = axs.ravel()\n    for h in range(24):\n        axs[h].imshow(traffic[y-2009,days[d],h,::-1,:], zorder=1, cmap='coolwarm', clim=(0, traffic.max()))\n        axs[h].get_xaxis().set_visible(False)\n        axs[h].get_yaxis().set_visible(False)\n        axs[h].set_title('h={}'.format(h))\n    fig.suptitle(\"Pickup traffic density, year={}, day={} (max_pickups={})\".format(y, d, traffic.max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f46f16bbe3a478f965ac54c8da78245a02d38a5"},"cell_type":"code","source":"traffic = calculate_trafic_density(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f8d1a8cbb9d98c4c62d31bdbc7629261d5ad24c"},"cell_type":"code","source":"# This function is based on https://stackoverflow.com/questions/27928/\n# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n# return distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc850f24c9e4adfe27cf9f8c22c66415ca91a32b"},"cell_type":"code","source":"# add new column to dataframe with distance in miles\ntrain['distance_miles'] = distance(train.pickup_latitude, train.pickup_longitude, \\\n                                      train.dropoff_latitude, train.dropoff_longitude)\n\ntrain.distance_miles.hist(bins=50, figsize=(12,4))\nplt.xlabel('distance miles')\nplt.title('Histogram ride distances in miles')\ntrain.distance_miles.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3b926dde2490d1e0fd63ead72a819bbafa5d4d"},"cell_type":"code","source":"# remove datapoints with distance <0.05 miles\nprint('Number of rows {:,}'.format(len(train)))\ntrain = train[train.distance_miles >= 0.05]\nprint('Number of rows {:,}'.format(len(train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c13c354d720dbf28682f95a5a80ac1deb6d56a8"},"cell_type":"code","source":"# JFK airport coordinates, see https://www.travelmath.com/airport/JFK\njfk = (-73.7822222222, 40.6441666667)\nnyc = (-74.0063889, 40.7141667)\n\ndef plot_location_fare(loc, name, range=1.5):\n    # select all datapoints with dropoff location within range of airport\n    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n    idx = (distance(train.pickup_latitude, train.pickup_longitude, loc[1], loc[0]) < range)\n    train[idx].fare_amount.hist(bins=100, ax=axs[0])\n    axs[0].set_xlabel('fare $USD')\n    axs[0].set_title('Histogram pickup location within {} miles of {}'.format(range, name))\n\n    idx = (distance(train.dropoff_latitude, train.dropoff_longitude, loc[1], loc[0]) < range)\n    train[idx].fare_amount.hist(bins=100, ax=axs[1])\n    axs[1].set_xlabel('fare $USD')\n    axs[1].set_title('Histogram dropoff location within {} miles of {}'.format(range, name));\n    \nplot_location_fare(jfk, 'JFK Airport')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2cf96a23e6c1952f3dbec70e734176aa9e81b8d"},"cell_type":"code","source":"ewr = (-74.175, 40.69) # Newark Liberty International Airport, see https://www.travelmath.com/airport/EWR\nlgr = (-73.87, 40.77) # LaGuardia Airport, see https://www.travelmath.com/airport/LGA\nplot_location_fare(ewr, 'Newark Airport')\nplot_location_fare(lgr, 'LaGuardia Airport')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a659de2bfa402006c2c943c9289ca63e1536ccaf"},"cell_type":"markdown","source":"### Fare at night is different from day time\nTo visualize the relation between time and fare/km three more columns are added to the data: the year, the hour of the day and the fare $USD per KM."},{"metadata":{"trusted":true,"_uuid":"fbe6a4696ec83c4c5d6db01bd132283d55b1037b"},"cell_type":"code","source":"train['fare_per_mile'] = train.fare_amount / train.distance_miles\n\ntrain['distance_to_center'] = distance(nyc[1], nyc[0], train.pickup_latitude, train.pickup_longitude)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f3942ced7a9afe1755600ddee084702c2a1735f"},"cell_type":"code","source":"train['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0], train.pickup_latitude, train.pickup_longitude)\ntrain['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0], train.dropoff_latitude, train.dropoff_longitude)\ntrain['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], train.pickup_latitude, train.pickup_longitude)\ntrain['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0], train.dropoff_latitude, train.dropoff_longitude)\ntrain['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0], train.pickup_latitude, train.pickup_longitude)\ntrain['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0], train.dropoff_latitude, train.dropoff_longitude)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"124e4e2a9612ed7f6d6185a73552be2fb18d7633"},"cell_type":"code","source":"# add new column to dataframe with distance in km\ntest['distance_miles'] = distance(test.pickup_latitude, test.pickup_longitude, \\\n                                     test.dropoff_latitude, test.dropoff_longitude)\ntest['distance_to_center'] = distance(nyc[1], nyc[0], \\\n                                          test.dropoff_latitude, test.dropoff_longitude)\ntest['hour'] = test.pickup_datetime.apply(lambda t: pd.to_datetime(t).hour)\ntest['year'] = test.pickup_datetime.apply(lambda t: pd.to_datetime(t).year)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33ee36a5ff691d9dd6efd71d3a489ea87085589e"},"cell_type":"markdown","source":"### Model\nBased on the analysis above, I would start with the following model:\n\n                    fare ~ year,hour,distance,passenger_count\n \nFor a baseline model I use a linear regression model."},{"metadata":{"trusted":true,"_uuid":"764de93efd69d4d8301253bd6bd69b57a408a216"},"cell_type":"code","source":"# define dataset\n# select points 15 miles near NYC center and remove zero passenger datapoints\nidx = (train.distance_to_center<15) & (train.passenger_count!=0)\nfeatures = ['year', 'hour', 'distance_miles', 'passenger_count']\nX = train[idx][features].values\ny = train[idx]['fare_amount'].values\n\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3232768bb3145d102b1125ffb4f723e062289427"},"cell_type":"code","source":"# define some handy analysis support function\nfrom sklearn.metrics import mean_squared_error, explained_variance_score\n\ndef plot_prediction_analysis(y, y_pred, figsize=(10,4), title=''):\n    fig, axs = plt.subplots(1, 2, figsize=figsize)\n    axs[0].scatter(y, y_pred)\n    mn = min(np.min(y), np.min(y_pred))\n    mx = max(np.max(y), np.max(y_pred))\n    axs[0].plot([mn, mx], [mn, mx], c='red')\n    axs[0].set_xlabel('$y$')\n    axs[0].set_ylabel('$\\hat{y}$')\n    rmse = np.sqrt(mean_squared_error(y, y_pred))\n    evs = explained_variance_score(y, y_pred)\n    axs[0].set_title('rmse = {:.2f}, evs = {:.2f}'.format(rmse, evs))\n    \n    axs[1].hist(y-y_pred, bins=50)\n    avg = np.mean(y-y_pred)\n    std = np.std(y-y_pred)\n    axs[1].set_xlabel('$y - \\hat{y}$')\n    axs[1].set_title('Histrogram prediction error, $\\mu$ = {:.2f}, $\\sigma$ = {:.2f}'.format(avg, std))\n    \n    if title!='':\n        fig.suptitle(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b230646fd80fd504e82b1e6148e0e2decb8a5d4"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66e88b3fcff1ecfb199f3168b724a5589300372c"},"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\n\nmodel_lin = Pipeline((\n        (\"standard_scaler\", StandardScaler()),\n        (\"lin_reg\", LinearRegression()),\n    ))\nmodel_lin.fit(X_train, y_train)\n\ny_train_pred = model_lin.predict(X_train)\nplot_prediction_analysis(y_train, y_train_pred, title='Linear Model - Trainingset')\n\ny_test_pred = model_lin.predict(X_test)\nplot_prediction_analysis(y_test, y_test_pred, title='Linear Model - Testset')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b578c615f01f56d190e980eccbb8e91998751af"},"cell_type":"code","source":"# define dataset\nXTEST = test[features].values\n\nfilename = './baseline_linear'\n\ny_pred_final = model_lin.predict(XTEST)\n\nsubmission = pd.DataFrame(\n    {'key': test.key, 'fare_amount': y_pred_final},\n    columns = ['key', 'fare_amount'])\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca91617f00f7a4a1e9750f4f2fd5f49ec5a2d76d"},"cell_type":"markdown","source":"### KERAS"},{"metadata":{"trusted":true,"_uuid":"6dde15d281529ebb1293e62284f5eaf4a3dfdbe3"},"cell_type":"code","source":"def rmse_Keras(y_values, pred):\n#     return sqrt(mean_squared_error(y_values, pred))\n    return K.sqrt(K.mean(K.square(pred - y_values), axis=-1)) \n\ndef baseline_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], kernel_initializer='uniform', activation='softplus'))\n    model.add(Dense(1, kernel_initializer='uniform', activation = 'relu'))    \n    \n#     model.add(Dense(20, input_dim=X_trainX_train.shape[1], kernel_initializer='uniform', activation='softplus'))\n#     model.add(Dense(1, kernel_initializer='uniform', activation = 'relu'))\n    \n    # Compile model\n    model.compile(loss='mse', optimizer='Adam', metrics=[rmse_Keras])\n    return model\n    \n\n# estimator = KerasRegressor(build_fn=baseline_model, verbose=1, epochs=25, batch_size = 2**15)\n\n# estimator.fit(X_train, y_train)\n# pred_keras = estimator.predict(X_val)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}