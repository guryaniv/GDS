{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["# Feature engineering\n", "\n", "In this notebook i want try hand-crafting some features that could help to create a model. I want to see what creative ideas i can come up with - and if they indeed seem to work."], "metadata": {"_cell_guid": "91bc9f4c-9535-42bb-969d-80340840ef5f", "_uuid": "1d9358b4afbf4c53c8d90b83198c00628e979020"}}, {"cell_type": "code", "outputs": [], "source": ["import pandas as pd\n", "\n", "df = pd.read_csv('../input/train.csv')"], "metadata": {"_cell_guid": "6f961a24-8ce0-4671-bd14-84077a802a53", "_uuid": "b11eb49ad9b57030d1bbf8729f72ce45ac600c26", "collapsed": true}, "execution_count": 16}, {"cell_type": "code", "outputs": [], "source": ["df.head()"], "metadata": {"_cell_guid": "7f523ded-9393-4b60-abc2-c04891d729d2", "_uuid": "785789b0e4e8fe941dfec90dc544225af5046ed7"}, "execution_count": 17}, {"cell_type": "markdown", "source": ["Below i'm adding features to the dataset that are computed from the comment text. Some i've seen in discussions for this competition, others i came up with while looking at the data. Right now, they are:\n", "\n", "* Length of the comment - my initial assumption is that angry people write short messages\n", "* Number of capitals - observation was many toxic comments being ALL CAPS\n", "* Proportion of capitals - see previous\n", "* Number of exclamation marks - i observed several toxic comments with multiple exclamation marks\n", "* Number of question marks - assumption that angry people might not use question marks\n", "* Number of punctuation symbols - assumption that angry people might not use punctuation\n", "* Number of symbols - assumtion that words like f*ck or $#* or sh*t mean more symbols in foul language (Thx for tip!)\n", "* Number of words - angry people might write short messages?\n", "* Number of unique words - observation that angry comments are sometimes repeated many times\n", "* Proportion of unique words - see previous\n", "* Number of (happy) smilies - Angry people wouldn't use happy smilies, right?"], "metadata": {"_cell_guid": "aa509eed-dfdb-41a7-b41c-b5c08ca328d4", "_uuid": "03003e1fb8a8ff49f0076dd78f1717c7d4f689eb"}}, {"cell_type": "code", "outputs": [], "source": ["df['total_length'] = df['comment_text'].apply(len)\n", "df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n", "df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n", "                                axis=1)\n", "df['num_exclamation_marks'] = df['comment_text'].apply(lambda comment: comment.count('!'))\n", "df['num_question_marks'] = df['comment_text'].apply(lambda comment: comment.count('?'))\n", "df['num_punctuation'] = df['comment_text'].apply(\n", "    lambda comment: sum(comment.count(w) for w in '.,;:'))\n", "df['num_symbols'] = df['comment_text'].apply(\n", "    lambda comment: sum(comment.count(w) for w in '*&$%'))\n", "df['num_words'] = df['comment_text'].apply(lambda comment: len(comment.split()))\n", "df['num_unique_words'] = df['comment_text'].apply(\n", "    lambda comment: len(set(w for w in comment.split())))\n", "df['words_vs_unique'] = df['num_unique_words'] / df['num_words']\n", "df['num_smilies'] = df['comment_text'].apply(\n", "    lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))"], "metadata": {"_cell_guid": "34610778-9d43-4369-a39a-98b0315af51e", "_uuid": "71bafb31ff381838ebee97d4c43dc7a9b30abd2f", "collapsed": true}, "execution_count": 18}, {"cell_type": "markdown", "source": ["Let's inspect data - did this work?"], "metadata": {"_cell_guid": "e66ea469-91d7-4c9c-ae5d-dc17faca1c8f", "_uuid": "3a7bbd42c35f0a6e2572927f472d34de08b4f93b"}}, {"cell_type": "code", "outputs": [], "source": ["df.head()"], "metadata": {"_cell_guid": "5fa2b473-f6b9-4564-9889-78d14ba88d23", "_uuid": "09d66504f7abeb475a833d58421e39008c486832"}, "execution_count": 19}, {"cell_type": "markdown", "source": ["Now we'll calculation correlation between the added features and the to-be-predicted columns, this should be an indication of whether a model could use these features:"], "metadata": {"_cell_guid": "e3f10ae2-718c-4e78-a23f-6f092cb6d72b", "_uuid": "74f817ad4c774172e44deae5212529b90f49cb94"}}, {"cell_type": "code", "outputs": [], "source": ["features = ('total_length', 'capitals', 'caps_vs_length', 'num_exclamation_marks',\n", "            'num_question_marks', 'num_punctuation', 'num_words', 'num_unique_words',\n", "            'words_vs_unique', 'num_smilies', 'num_symbols')\n", "columns = ('toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate')\n", "\n", "rows = [{c:df[f].corr(df[c]) for c in columns} for f in features]\n", "df_correlations = pd.DataFrame(rows, index=features)"], "metadata": {"_cell_guid": "6a576a79-62e7-430a-9d18-3b5ae53e3648", "_uuid": "a1234d2a68c42835b390d767e6a590a9422371f5"}, "execution_count": 20}, {"cell_type": "markdown", "source": ["Let's output the data:"], "metadata": {"_cell_guid": "8fc91ba1-111c-4107-8bc8-3c6c3ccedf22", "_uuid": "544b6a0c71727a17adf833ec9c39ef4daa63fd5f"}}, {"cell_type": "code", "outputs": [], "source": ["df_correlations"], "metadata": {"_cell_guid": "1b7e3f83-8953-4075-80cd-7be6be4f4c59", "_uuid": "61cbee5d4d42de361ff0c4f703a9c4e2ae7e60f4"}, "execution_count": 21}, {"cell_type": "markdown", "source": ["I'll also output the data as a heatmap - that's slightly easier to read."], "metadata": {"_cell_guid": "2b84c0f9-9edd-49bf-92f1-76f2d6af23a6", "_uuid": "2dd30cb117effd9fdd1bb8aa16d1a0f6e252e2bf"}}, {"cell_type": "code", "outputs": [], "source": ["import seaborn as sns\n", "\n", "ax = sns.heatmap(df_correlations, vmin=-0.2, vmax=0.2, center=0.0)"], "metadata": {"_cell_guid": "fcddde11-e833-4292-9874-eb0c675e9966", "_uuid": "613ef976113f51c3e690431b54c6c508bc54961c"}, "execution_count": 22}, {"cell_type": "markdown", "source": ["So, what have we learned? Some of the feature ideas i had make sense: They correlate with the to-be-predicted data, so a model should be able to use them. Other feature ideas don't correlate - so they look less promising.\n", "\n", "For now these feature seem the best candidates:\n", "* Proportion of capitals \n", "* Number of unique words\n", "* Number of exclamation marks\n", "* Number of punctuations\n", "\n", "Hope this could be usefull to someone! If you have more (feature) ideas or feedback - please comment, then i can add them here."], "metadata": {"_cell_guid": "57a7e0a2-8865-4950-bd8c-12ccea7f2de8", "_uuid": "e93dc934e0a4b247bc72471c8617dad17ff97136"}}, {"cell_type": "markdown", "source": [], "metadata": {"_cell_guid": "4b24f890-7c66-469b-9542-9f1261997b6d", "_uuid": "138db0cdfc6185f3a5b538dc05ff33deae57aa5b"}}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "mimetype": "text/x-python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat": 4}