{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58382960c21bc159969c337fcb6ef74147a8794b"},"cell_type":"markdown","source":"## Why this kernel\n   In this competition,I believe many of us use the leak to get a better score.\n   \n  Can get a reference from here:[https://www.kaggle.com/tezdhar/breaking-lb-fresh-start](https://www.kaggle.com/tezdhar/breaking-lb-fresh-start)\n  \n It was originally from Giba's share.[post](https://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61329)\n \n And, 'Jiazhen Xi' Extended it.[kernel](https://www.kaggle.com/johnfarrell/giba-s-property-extended-extended-result)\n \n But, all those work are base on Giba given some rows and columns. Actually,I'm not quite understand how to get them.maybe someone can teach me.\n \n so,I am wondering if there is any way to search for some leaks.This is the exploration of this kernel."},{"metadata":{"trusted":true,"_uuid":"b1207f65475665947240ef2d6cb5f9fbf0698e02","collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bd7ac9673cc8959701654ad7315673c4cb32b5af"},"cell_type":"code","source":"# Horizontal search, to find more columns\n# reference:\n# https://www.kaggle.com/johnfarrell/giba-s-property-extended-extended-result\ndef bf_search_a(df_new, df_cand):\n    cnt = 0\n    head_curr = df_new.values[1:, 0]\n    tail_curr = df_new.values[:-1, -1]\n    while True:\n        for c in df_cand.columns:\n            if c in df_new:\n                continue\n            elif np.all(\n                df_cand[c].iloc[:-1].values==head_curr\n            ) and len(df_cand[c].unique())>1:\n                df_new.insert(0, c, df_cand[c].values)\n                head_curr = df_new.values[1:, 0]\n#                 print(c, 'found head!', 'new shape', df_new.shape)\n                cnt += 1\n                break\n            elif np.all(\n                df_cand[c].iloc[1:].values==tail_curr\n            ) and len(df_cand[c].unique())>1:\n                df_new[c] = df_cand[c].values\n                tail_curr = df_new.values[:-1, -1]\n#                 print(c, 'found tail!', 'new shape', df_new.shape)\n                cnt += 1\n                break\n            else:\n                continue\n        if cnt==0:\n            break\n        else:\n            cnt = 0\n            continue\n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# vertically Search,to find more rows\ndef df_append(df, index, train, target='target', col='col', index_h={}):\n    index_h.add(index)\n    df = df.append(train[[target,col]].loc[index])\n    last_value = df[target].tail(1).values[0]\n    col_index = list(train[train[col]==last_value].index)\n    uni_col_index = list(set(col_index) - index_h)\n\n    if uni_col_index:\n        if df.shape[0] < 2:\n            df = df_append(df, min(uni_col_index), train, target, col, index_h)  \n        for col_index_i in uni_col_index:\n            uni_col_index.remove(col_index_i)\n            df_c = df.copy()\n            bf_search_a(df_c, train.iloc[df_c.index, 2:])\n            if df_c.shape[1] >= 4:\n                print(df_c.index, df_c.shape)\n                df = df_append(df, col_index_i, train, target, col, index_h)\n            else:\n                df = df.drop(df.index[-1])\n                df = df.append(train[[target,col]].loc[col_index_i])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"4cf719049a171a320ee4d433a23e8c2c9fec8320"},"cell_type":"code","source":"## run to search\n# for col in [f for f in train.columns if f not in['ID','target']]:  # use this to search in all columns\nfor col in [f for f in train.columns if f not in['ID','target']][1:3]:\n    print('#################### new col:     ',col)\n#     for i in range(train.shape[0]):  # use this to search in all rows\n    for i in range(50):\n        ff = pd.DataFrame()\n        index_h = set()\n        df_append(ff, i, train, 'target', col, index_h)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39ab661d9d7d22502213d9004bf379061aea8686"},"cell_type":"markdown","source":"## But......\nbut it seems to need to run a lot of time,In fact, I have not finished it.\n\nit maybe helps,maybe not."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}