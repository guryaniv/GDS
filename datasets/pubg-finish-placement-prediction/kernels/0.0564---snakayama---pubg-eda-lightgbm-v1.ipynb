{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\"\"\"\n@author: nakayama.s\n\"\"\"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0faca2da0251624a05844c6a6b5056d20d7d4997"},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf-8\n\"\"\"\n@author: nakayama.s\n\"\"\"\n\nimport os\nimport warnings\nimport gc\nimport time\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import LabelEncoder\nfrom itertools import product\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n\ndef eda(data):\n    # print(data)\n    print(\"----------Top-5- Record----------\")\n    print(data.head(5))\n    print(\"-----------Information-----------\")\n    print(data.info())\n    print(\"-----------Data Types------------\")\n    print(data.dtypes)\n    print(\"----------Missing value----------\")\n    print(data.isnull().sum())\n    print(\"----------Null value-------------\")\n    print(data.isna().sum())\n    print(\"----------Shape of Data----------\")\n    print(data.shape)\n    print(\"----------describe---------------\")\n    print(data.describe())\n    print(\"----------tail-------------------\")\n    print(data.tail())\n    \ndef read_csv(path):\n  # logger.debug('enter')\n  df = pd.read_csv(path)\n  # logger.debug('exit')\n  return df\n\ndef load_train_data():\n  # logger.debug('enter')\n  df = read_csv(SALES_TRAIN_V2)\n  # logger.debug('exit')\n  return df\n\ndef load_test_data():\n  # logger.debug('enter')\n  df = read_csv(TEST_DATA)\n  # logger.debug('exit')\n  return df\n\ndef graph_insight(data):\n    print(set(data.dtypes.tolist()))\n    df_num = data.select_dtypes(include = ['float64', 'int64'])\n    df_num.hist(figsize=(16, 16), bins=50, xlabelsize=8, ylabelsize=8);\n\ndef drop_duplicate(data, subset):\n    print('Before drop shape:', data.shape)\n    before = data.shape[0]\n    data.drop_duplicates(subset,keep='first', inplace=True) #subset is list where you have to put all column for duplicate check\n    data.reset_index(drop=True, inplace=True)\n    print('After drop shape:', data.shape)\n    after = data.shape[0]\n    print('Total Duplicate:', before-after)\n\ndef unresanable_data(data):\n    print(\"Min Value:\",data.min())\n    print(\"Max Value:\",data.max())\n    print(\"Average Value:\",data.mean())\n    print(\"Center Point of Data:\",data.median())\n\nSAMPLE_SUBMISSION    = '../input/sample_submission_V2.csv'\nTRAIN_DATA           = '../input/train_V2.csv'\nTEST_DATA            = '../input/test_V2.csv'\n\nsample       = read_csv(SAMPLE_SUBMISSION)\ntrain           = read_csv(TRAIN_DATA)\ntest            = read_csv(TEST_DATA)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37300a24751edfa20b8ba0e2a152fd3cbf6212f7"},"cell_type":"code","source":"eda(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73f173bbaeeada1bf1eda1d1975f4a8b2eb694ca"},"cell_type":"code","source":"eda(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a29264ea2d8006a0f4706449394e4214ef619c9"},"cell_type":"code","source":"train = pd.get_dummies(train,columns=['matchType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e671f666d21abbde44d93fe013cd4b765fe15b3a"},"cell_type":"code","source":"train =train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d5bed6bee46825b911f38df466847c53c8ec847"},"cell_type":"code","source":"test = pd.get_dummies(test,columns=['matchType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"801f7bca522eafc8ae5676ce178012365b7ee24a"},"cell_type":"code","source":"y_train =train['winPlacePerc']\nx_train =train.drop(['Id','groupId','matchId','winPlacePerc'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ce67a48d88786ea4372bf5c9332bca4eba73fb6"},"cell_type":"code","source":"X_train = x_train.values\nY_train = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"628b2c943eac3399ccc2b56d42678b3637e47948"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce0a752ea964bb323bd5acf6d0be10f91e86b58f"},"cell_type":"code","source":"Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b8bc2e9c877700c15573668fbe0b928cdfed911"},"cell_type":"code","source":"# validation_size = 0.20\n# seed = 1000\n# X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=validation_size, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"544ee7773933bc67a2525d1ba46d804da11a408b"},"cell_type":"code","source":"# XGBoost\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\nprint(\"Parameter optimization\")\nxgb_model = xgb.XGBRegressor()\nreg_xgb = GridSearchCV(xgb_model,\n                   {'max_depth': [1,3,5],\n                    'n_estimators': [50,100,200]},cv=5 ,verbose=1)\nreg_xgb.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"871229843f1972105a2431e7ac622a260b8a239b"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\n\ndef create_model(optimizer='adam'):\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], kernel_initializer='normal', activation='relu'))\n    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(1, kernel_initializer='normal'))\n\n    model.compile(loss='mean_squared_error', optimizer=optimizer)\n    return model\n\nmodel = KerasRegressor(build_fn=create_model, verbose=0)\n# define the grid search parameters\noptimizer = ['SGD','Adam']\nbatch_size = [10, 30, 50]\nepochs = [10, 50, 100]\nparam_grid = dict(optimizer=optimizer, batch_size=batch_size, epochs=epochs)\nreg_dl = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\nreg_dl.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20248671fcb9b6eba30b192c43034cd695a9c031"},"cell_type":"code","source":"train_data = lgb.Dataset(data=X_train, label=Y_train)\nvalid_data = lgb.Dataset(data=X_valid, label=Y_valid)\n\nparams = {\n    'num_leaves': 144,\n    \"metric\" : \"mae\",\n    'learning_rate': 0.1,\n    'n_estimators': 800,\n    'max_depth':13,\n    'max_bin':55,\n    'bagging_fraction':0.8,\n    'bagging_freq':5,\n    'feature_fraction':0.9\n    }\n\nlgb_model = lgb.train(params, train_data, valid_sets=[train_data, valid_data], verbose_eval=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc9c671a8a7db1d4e1009300897078ddd1dacfb8"},"cell_type":"code","source":"X_test = test.drop([\"Id\", \"groupId\", \"matchId\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a37e290170f4f2cd58439305cce15d3a4cb0ab46"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cd23875ab9cc686e87cefab084bb01153744292"},"cell_type":"code","source":"Y_test = lgb_model.predict(X_test)\n\nsubmission = pd.DataFrame({\n    \"Id\": test['Id'],\n    \"winPlacePerc\": Y_test\n})\n\nsubmission.to_csv('sample_submission_20181124_v1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef1ea1e9da6740f8045acd62a2c5b89b7442c256"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}