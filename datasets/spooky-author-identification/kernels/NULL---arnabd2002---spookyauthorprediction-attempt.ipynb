{"cells": [{"cell_type": "markdown", "source": ["**I tried using the TF-IDF Tranform and then fed it to MultinomialNaive Bayes classifier but the accuracy did not get more than 79%. So I have done as below which gives a decent 83%. Please let me know more ways to increase accuracy. Also the final probability distributions would have been corrected to smaller decimal places.**"], "metadata": {"_cell_guid": "b6667c6b-a051-41fb-9bcc-a6309c88667d", "_uuid": "68581555677187e41621424d170e6afd1d1000ad"}}, {"execution_count": null, "cell_type": "code", "source": ["from nltk import word_tokenize\n", "import pandas as pd\n", "from nltk.classify.util import apply_features,accuracy\n", "from nltk.classify.scikitlearn import SklearnClassifier\n", "from sklearn.naive_bayes import MultinomialNB\n", "from nltk.corpus import stopwords\n", "from random import shuffle\n", "import numpy as np\n", "import seaborn as sns\n", "from matplotlib import pyplot as plt"], "outputs": [], "metadata": {"_cell_guid": "be4453a1-64ef-42ac-a2a7-ad267dc7e464", "collapsed": true, "_uuid": "d422d0c4de1a5ec4b785d44aa78b359f05be716c"}}, {"execution_count": null, "cell_type": "code", "source": ["df = pd.read_csv(\"../input/train.csv\")"], "outputs": [], "metadata": {"_cell_guid": "5c1dba64-8c53-409f-b752-d80413430de7", "collapsed": true, "_uuid": "7bdfdda70952b2f38be058fc9b211ba997e284f2"}}, {"execution_count": null, "cell_type": "code", "source": ["X_text=df['text']\n", "y_author=df['author']"], "outputs": [], "metadata": {"_cell_guid": "cf13c579-c25a-4417-8595-6c11fdd9e6e2", "collapsed": true, "_uuid": "5a27e3d7d24be0f49066799d49765d6e3b3bf840"}}, {"execution_count": null, "cell_type": "code", "source": ["def getTextAuthorFeatures(words):\n", "    uniqueWords=set(words)\n", "    return dict({word:True for word in uniqueWords})"], "outputs": [], "metadata": {"_cell_guid": "10a72d6e-d4eb-4131-8cc4-5e17f57d527f", "collapsed": true, "_uuid": "db95a3e1204a104bf698f8c16f6bf8a036cee356"}}, {"cell_type": "markdown", "source": ["**splitting the data as 70% training and 30% test**"], "metadata": {"_cell_guid": "f610d499-faff-4210-994f-11400efb955c", "_uuid": "50cf03794fe9a1e4bfcfec999e6c2cd86e62b2de"}}, {"execution_count": null, "cell_type": "code", "source": ["sw=set(stopwords.words('english'))\n", "from nltk.stem import PorterStemmer\n", "featureList=[]\n", "ps=PorterStemmer()\n", "for entry,author in zip(X_text,y_author):\n", "    wordList=[ps.stem(w.lower()) for w in word_tokenize(entry) if len(w)>=2 and w not in sw]\n", "    featureList.append([getTextAuthorFeatures(wordList),author])\n", "\n", "shuffle(featureList)\n", "X_train=apply_features(getTextAuthorFeatures,featureList[:int(len(featureList)*0.70)])\n", "X_test=apply_features(getTextAuthorFeatures,featureList[int(len(featureList)*0.70):])\n", "\n", "mnb=SklearnClassifier(MultinomialNB())\n", "mnb.train(X_train)\n", "print('Accuracy%:',accuracy(mnb,X_test)*100)\n"], "outputs": [], "metadata": {"_cell_guid": "80e7086f-c9c7-4632-aed4-03f8a19b6e08", "collapsed": true, "_uuid": "39cb0d85bc8679f7804be8a438d165281b8080d6"}}, {"cell_type": "markdown", "source": ["**Results from real test in test.zip.We got a decent accuracy, so let's calculate the probability of each author per entry.**"], "metadata": {"_cell_guid": "5c299ac3-7458-46df-952d-7ebf59da9dc3", "_uuid": "4938c43a6cb64fb63d1c635de7f96cad04adaa50"}}, {"execution_count": null, "cell_type": "code", "source": ["test=pd.read_csv(\"../input/test.csv\")\n", "finalProbList=[]\n", "for idx,row in test.iterrows():\n", "    text=row['text']\n", "    predicted_author=mnb.classify(getTextAuthorFeatures([w.lower() for w in word_tokenize(text) ]))\n", "    predicted_proba=mnb.prob_classify(getTextAuthorFeatures([w.lower() for w in word_tokenize(text) ]))\n", "    finalProbList.append([row['id'],[predicted_proba.prob(i) for i in predicted_proba.samples()]])"], "outputs": [], "metadata": {"_cell_guid": "b7609596-6c38-496c-8b9c-d09664725962", "collapsed": true, "_uuid": "cba9e2e5385e6538dd8ab8308e223cab035a17c2"}}, {"execution_count": null, "cell_type": "code", "source": ["finalProbList"], "outputs": [], "metadata": {"_cell_guid": "ec4c37ee-31d5-42bc-882f-91f14bdb665b", "collapsed": true, "_uuid": "7c71020ecd26be99ed206a16a3267aa6f9cf4c0d"}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.feature_extraction.text import TfidfVectorizer"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["vec=TfidfVectorizer(ngram_range=(1,3),stop_words='english')"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["vecText=vec.fit_transform(X_text)"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.decomposition import TruncatedSVD"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["svd=TruncatedSVD(n_components=np.unique(y_author).shape[0])"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["reducedX=svd.fit_transform(vecText)"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["dfSVD=pd.DataFrame(reducedX)\n", "dfSVD['author']=y_author"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["X=vecText\n", "y=dfSVD['author']"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.preprocessing import StandardScaler"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["scaler=StandardScaler()"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.neural_network import MLPClassifier\n", "from sklearn.model_selection import train_test_split"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["mnb=MultinomialNB()"], "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.70,random_state=42)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["mlpClf=MLPClassifier(random_state=42,verbose=Tr)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["mlpClf.fit(X_train,y_train)"], "outputs": [], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["mlpClf.score(X_test,y_test)*100"], "outputs": [], "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4}