{"cells":[{"metadata":{"_uuid":"f71f8cf43ea7dde2b2ff848194904e12d130d1c7"},"cell_type":"markdown","source":"Hey all. I'm really new at this but I'm trying to get my hands dirty. Please jump in and correct me if you see anything that doesn't make sense, or if you have any pointers I'm all ears! \n\nI'm taking a lot of ideas from Tak's kernel (https://www.kaggle.com/takaishikawa/experiment02-corr-select-logistic-reg) and trying to expand on that a bit."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nX = np.array(train.drop(['id','target'], axis=1))\ny = np.array(train['target'])\nX_test = np.array(test.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1580e377ab8bf5ff083614d8505eb1ece753d6fd"},"cell_type":"markdown","source":"Take a look at correlation between each feature and the target"},{"metadata":{"trusted":true,"_uuid":"cc40bdc7b54996ce750ff0944a3c57e41dd740cb"},"cell_type":"code","source":"# get correlation of each feature with target\ncorr = train.corr()['target'][2:]\nsns.boxplot(corr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96e503a73d2ea7c852ca82c0f6dae3d3a27eb507"},"cell_type":"markdown","source":"Lots of very low correlation features. Seems like ditching some might help in avoiding overfitting.\n\nFirst I'll make a quick function for repeating cross validation. I realized after I wrote this that there it's built in to sklearn, but this way seems to work too. "},{"metadata":{"trusted":true,"_uuid":"8f75ceadf5150f6ff3615a7ad02b0d9ee35d14c1"},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ndef repeat_cross_val(model, X, y, n_iters=10, n_folds=5):\n    \n    folds = StratifiedKFold(n_splits=n_folds, shuffle=True)\n    scores = np.zeros([n_iters, n_folds])\n    \n    for i in range(n_iters):\n        for j, (cv_train, cv_test) in enumerate(folds.split(X,y)):\n            model.fit(X[cv_train], y[cv_train])\n            scores[i,j] = model.score(X[cv_test],y[cv_test])    \n    return scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c331ede5bdb651eed5b31c1cff270e14be67da65"},"cell_type":"markdown","source":"I'm going to define a correlation threshold, this will be a value that used to decide whether a feature is going to be removed from the training data. I'll get the correation with each feature and the target, and then set a value. If the absolute value of correlation is above this, I'll leave that feature in."},{"metadata":{"trusted":true,"_uuid":"0a7820401177acb42ccaf69f40e9b3267000ea95"},"cell_type":"code","source":"#set correltaion threshold and filter training data\ncorr_thresh = 0.1\nhigh_corr = abs(corr)>corr_thresh\nX_corr = X[:,high_corr]\n\nX_corr.shape[1]/X.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92be1d519215df3dd6271d5fba0d1840db197b02"},"cell_type":"code","source":"# give it a quick test\nfrom sklearn.linear_model import LogisticRegression\n\nlrc = LogisticRegression(penalty='l1', solver='liblinear')\nprint(repeat_cross_val(model=lrc, X=X_corr, y=y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4ca35d1dfa460fdb67960612e100b1d3bc5c3ca"},"cell_type":"markdown","source":"Seems alright.\n\nLet's see if we can get some idea of what a good correlation threshold will be."},{"metadata":{"trusted":true,"_uuid":"18887dee57ed8aaed1304f5333433b3068ae9372"},"cell_type":"code","source":"# Testing values from 0-0.3\ncorr_test = np.arange(0, 0.3, 0.01)\ncv_score = np.zeros(corr_test.shape[0])\n\nlrc = LogisticRegression(penalty='l1', solver='liblinear')\n\nfor i, c in enumerate(corr_test):\n    high_corr = abs(corr)>c\n    X_corr = X[:,high_corr]\n    cv_score[i] = repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=25)\n\nplt.scatter(x=corr_test, y=cv_score)\nplt.xlabel('correlation threshold')\nplt.ylabel('cv score')\nplt.title('Testing correlation threshold')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"329c452b90d5c777d1b535e030efa105acb102aa"},"cell_type":"markdown","source":"It looks like 0.1 - 0.13 is the sweet spot. I'll check how many features that leaves."},{"metadata":{"trusted":true,"_uuid":"974171c522383306d0fe687496547edf6b384ceb"},"cell_type":"code","source":"corr_thresh = 0.11\nhigh_corr = abs(corr)>corr_thresh\nX_corr = X[:,high_corr]\nX_corr.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53e90272372b790833b69bf66a7f1c646f1cc7d3"},"cell_type":"markdown","source":"Down form 300 to 45."},{"metadata":{"trusted":true,"_uuid":"c645ae1249a09a2f945c0744bbff59f5fb02c400"},"cell_type":"code","source":"lrc = LogisticRegression(penalty='l1', solver='liblinear')\nprint('l1: {0:.3f}'.format(repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=250)))\nlrc = LogisticRegression(penalty='l2', solver='liblinear')\nprint('l2: {0:.3f}'.format(repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=250)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d0e4c3e17d55b841fbcb7e426b3728fc7d7a92a"},"cell_type":"markdown","source":"l2 seems to be just a touch better. Next up is the C value. Smaller C means more regularization (i.e., the algorithm is more willing to let a training point be on the wrong side of the decision boundry), intuitively it seems like this will help with the overfitting problem. Let's take a look..."},{"metadata":{"trusted":true,"_uuid":"3f8f9e79b7e3d3fb24995b3262839c9302dc8bd0"},"cell_type":"code","source":"# Testing values from 0-0.3\nC_test = np.array([0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]) \ncv_score = np.zeros(C_test.shape[0])\nfor i, C in enumerate(C_test):\n    lrc = LogisticRegression(penalty='l2', solver='liblinear', C=C)\n    cv_score[i] = repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=50)\nplt.scatter(x=C_test, y=cv_score)\nplt.xlabel('C-value')\nplt.ylabel('cv score')\nplt.title('Testing C-value')\nplt.xscale('log')\nplt.xlim((0.00000001,10000))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9b017b078fa475fe95d6e2d19ec49fb3a6daa01"},"cell_type":"markdown","source":"It looks like smaller C values are the way to go! (default is 1.0) I'll zome in on the peak."},{"metadata":{"trusted":true,"_uuid":"f7ac3e1e7bdb5887eaf8cb1e4520f1e633e0604f"},"cell_type":"code","source":"%%time\nC_test = np.logspace(-4.0, 0, 60)\ncv_score = np.zeros(C_test.shape[0])\nfor i, C in enumerate(C_test):\n    lrc = LogisticRegression(penalty='l2', solver='liblinear', C=C)\n    cv_score[i] = repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=50)\nplt.scatter(x=C_test, y=cv_score)\nplt.xlabel('C-value')\nplt.ylabel('cv score')\nplt.title('Testing C-value')\nplt.xscale('log')\nplt.xlim((10**-4.2,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8f6f691e222c08c8757ac2220872babbc8b0eea"},"cell_type":"markdown","source":"Looks like something around 0.05 will be a good option. I'm going to check the corr_threshold again with this C value. "},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a9365a386ebcab36b767def45fc7619a902db2bd"},"cell_type":"code","source":"# Testing values from 0-0.3\ncorr_test = np.arange(0, 0.3, 0.01)\ncv_score = np.zeros(corr_test.shape[0])\nlrc = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\nfor i, c in enumerate(corr_test):\n    high_corr = abs(corr)>c\n    X_corr = X[:,high_corr]\n    cv_score[i] = repeat_cross_val(model=lrc, X=X_corr, y=y, n_iters=25)\nplt.scatter(x=corr_test, y=cv_score)\nplt.xlabel('correlation threshold')\nplt.ylabel('cv score')\nplt.title('Testing correlation threshold')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e1e690985a9355e591e12474fdec671ec585989"},"cell_type":"markdown","source":"Looks about the same. Lets see how it does."},{"metadata":{"trusted":true,"_uuid":"0fd5fb67ff4835c92884f8f418e231d91e5daea6"},"cell_type":"code","source":"# reset X_corr\ncorr_thresh = 0.11\nhigh_corr = abs(corr)>corr_thresh\nX_corr = X[:,high_corr]\n\nlrc = LogisticRegression(penalty='l2', solver='liblinear', C=0.05)\nlrc.fit(X_corr, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0418bd97e4b09f66dd8503267b810ece07727d96"},"cell_type":"code","source":"predict = lrc.predict(X_test[:,high_corr]) # this got a .704\npredict_prob = lrc.predict_proba(X_test[:,high_corr]) # wow! this got a 0.786\nprint(predict[0], predict_prob[:,1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"494253669ae8803a9a143ec85c21103e48b7f07b"},"cell_type":"markdown","source":"Using the probabilities instead of binary predictions got a much better score (0.786 vs 0.704). This surprised me, time to learn more about AUCROC."},{"metadata":{"trusted":true,"_uuid":"1f89197e484791c5ac9414c11b58a39e385c055e"},"cell_type":"code","source":"sub = pd.DataFrame({\n    'id': test['id'],\n    'target': predict_prob[:,1]\n})\nprint(sub.head())\nprint(pd.read_csv('../input/sample_submission.csv').head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8195e983ecc9e30782f56ab185054b5d853eb0f6"},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}