{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "daf4ca5e-0675-9954-652b-aef8eb9fa5e9"
      },
      "source": [
        "This is my first kaggle competition. All suggestions are welcome.\n",
        "\n",
        "I achieved ~98% AUC using tensorflow v1.2 and pretrained VGG16 model downloaded from http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70d2fbd1-523b-f183-8a8b-50c306375c8a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import time\n",
        "\n",
        "import pandas\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.slim.nets import vgg\n",
        "slim = tf.contrib.slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e8cdb69-2d5d-cad8-9b2f-7812eaca4ad2"
      },
      "outputs": [],
      "source": [
        "tfrecords_filename='invasive-train.tfrecords'\n",
        "im_width=224\n",
        "im_height=224\n",
        "\n",
        "#Hyper Parameter to play with\n",
        "batch_size=32\n",
        "num_epochs=10\n",
        "\n",
        "lr = 0.001\n",
        "decay_rate=0.1\n",
        "decay_per=40 #epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "18b90fae-7d34-881e-f364-232878a3475e"
      },
      "source": [
        "### Read all the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1da7c7f1-2bfc-a749-9a46-afb9449188b6"
      },
      "outputs": [],
      "source": [
        "train_labels = pandas.read_csv('train_labels.csv')\n",
        "test_labels = pandas.read_csv('sample_submission.csv')\n",
        "\n",
        "train_imgdir = 'train/'\n",
        "test_imgdir = 'test/'\n",
        "train_images = os.listdir(train_imgdir)\n",
        "test_images = os.listdir(test_imgdir)\n",
        "\n",
        "num_iter = len(train_labels)/batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "95880d5f-61d2-cbef-4548-84e1db7efb8c"
      },
      "source": [
        "### Read all of the image, resize it 224x224 and write it to TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d9103f9-2c53-1a49-7536-d208477e580f"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "if os.path.exists(tfrecords_filename):\n",
        "    print tfrecords_filename, \"already exists\"\n",
        "else:    \n",
        "    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n",
        "    print \"Saving prepocessed file to '%s'\" % tfrecords_filename\n",
        "    for img_path in train_images:\n",
        "        idx = int(img_path.split('.')[0]) - 1\n",
        "        label = train_labels.invasive[idx]\n",
        "        img = Image.open(os.path.join(train_imgdir, img_path))\n",
        "        img = np.array(img.resize((im_width,im_height), Image.ANTIALIAS))\n",
        "\n",
        "        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                    'image_raw': _bytes_feature(img.tostring()),\n",
        "                    'label': _int64_feature(label)\n",
        "                }))\n",
        "        writer.write(example.SerializeToString())\n",
        "    writer.close()\n",
        "    print(\"Preprocessing done in %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4df4b746-3c91-a70d-9326-f866cefdda5d"
      },
      "source": [
        "### Some helper function to create tensorflow graph "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a3f92bf2-eff3-b723-f660-fa7bd532ed13"
      },
      "outputs": [],
      "source": [
        "#Function to read the data from tfrecords\n",
        "def read_and_decode(filename_queue):\n",
        "    \n",
        "    reader = tf.TFRecordReader()\n",
        "\n",
        "    _, serialized_example = reader.read(filename_queue)\n",
        "\n",
        "    features = tf.parse_single_example(\n",
        "      serialized_example,\n",
        "      features={\n",
        "        'image_raw': tf.FixedLenFeature([], tf.string),\n",
        "        'label': tf.FixedLenFeature([], tf.int64)\n",
        "        })\n",
        "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
        "    image = tf.reshape(image, [im_height, im_width, 3])\n",
        "    label = tf.cast(features['label'], tf.int32)\n",
        "    images, labels = tf.train.shuffle_batch([image, label],\n",
        "        batch_size=batch_size, capacity=256, num_threads=2, min_after_dequeue=32)\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f6f72a2-e058-09b1-0418-8e7aee4f9a54"
      },
      "outputs": [],
      "source": [
        "def infer(inputs, is_training=True):\n",
        "    inputs = tf.cast(inputs, tf.float32)\n",
        "    inputs = ((inputs / 255.0)-0.5)*2\n",
        "    #Use Pretrained Base Model\n",
        "    with tf.variable_scope(\"vgg_16\"):\n",
        "        with slim.arg_scope(vgg.vgg_arg_scope()):\n",
        "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
        "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "    #Append fully connected layer\n",
        "    net = slim.flatten(net)\n",
        "    net = slim.fully_connected(net, 512,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "            weights_regularizer=slim.l2_regularizer(0.0005),\n",
        "            scope='finetune/fc1')\n",
        "    net = slim.fully_connected(net, 2,\n",
        "            activation_fn=None,\n",
        "            weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "            weights_regularizer=slim.l2_regularizer(0.0005),\n",
        "            scope='finetune/fc2')\n",
        "    return net\n",
        "\n",
        "def losses(logits, labels):\n",
        "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "    return loss\n",
        "        \n",
        "def optimize(losses):\n",
        "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
        "    learning_rate = tf.train.exponential_decay(lr, global_step,\n",
        "                                             num_iter*decay_per, decay_rate, staircase=True)\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    train_op = optimizer.minimize(losses, global_step=global_step)#,\n",
        "                #var_list=slim.get_model_variables(\"finetune\"))\n",
        "    return train_op"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e2078a1a-fd9e-32fe-6d67-53dd7adc1924"
      },
      "source": [
        "### Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a192835-88ae-03f7-8352-b7b05c05cb3f"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "#Create the training graph\n",
        "filename_queue = tf.train.string_input_producer([tfrecords_filename], num_epochs=num_epochs)\n",
        "image, label = read_and_decode(filename_queue)\n",
        "prediction = infer(image)\n",
        "loss = losses(prediction, label)\n",
        "train_op = optimize(loss)\n",
        "\n",
        "print \"Training started\"\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    init_op = tf.group(tf.global_variables_initializer(),\n",
        "            tf.local_variables_initializer())\n",
        "    restore = slim.assign_from_checkpoint_fn(\n",
        "               'vgg_16.ckpt',\n",
        "               slim.get_model_variables(\"vgg_16\"))\n",
        "    sess.run(init_op)\n",
        "    restore(sess)\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        avg_loss, acc = 0, 0\n",
        "        for i in range(num_iter):\n",
        "            _, l = sess.run([train_op, loss])\n",
        "            avg_loss += l/num_iter\n",
        "        print \"Epoch%03d avg_loss: %f\" % (e+1, avg_loss)\n",
        "    \n",
        "    coord.request_stop()\n",
        "    coord.join(threads)\n",
        "    print 'Training Done'\n",
        "    saver = tf.train.Saver(slim.get_model_variables())\n",
        "    saver.save(sess, 'model.ckpt')\n",
        "    sess.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36809fd1-c9f0-3eaf-d73d-e1032277db0e"
      },
      "source": [
        "### Test the model, and generate submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "74dc006f-51b7-a535-9f1e-53f2e72e2b12"
      },
      "outputs": [],
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "im_placeholder = tf.placeholder(tf.uint8, [None, im_height, im_width, 3])\n",
        "logits = infer(im_placeholder, is_training=False)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "predicted_labels = tf.argmax(prediction, 1)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    saver = tf.train.Saver()\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver.restore(sess, 'model.ckpt')\n",
        "    \n",
        "    for i, img_path in enumerate(test_images):\n",
        "        print \"\\rProcessing %d/%d\"%(i+1, len(test_images)),\n",
        "        img = Image.open(os.path.join(test_imgdir, img_path))\n",
        "        img = np.array(img.resize((im_width,im_height), Image.ANTIALIAS))\n",
        "        prob = sess.run(prediction, feed_dict={im_placeholder:np.expand_dims(img, axis=0)})\n",
        "        \n",
        "        idx = int(img_path.split('.')[0]) - 1\n",
        "        test_labels.invasive[idx] = prob[0][1]\n",
        "            \n",
        "    filename_output = \"predictionVGG.csv\"\n",
        "    test_labels.to_csv(filename_output, index=False)\n",
        "    print \"Writing result to\", filename_output\n",
        "    sess.close()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}