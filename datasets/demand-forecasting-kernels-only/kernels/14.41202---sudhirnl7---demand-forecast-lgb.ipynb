{"cells":[{"metadata":{"_uuid":"490efd187191d0db6f292f071c43d9fb6b33d6f1"},"cell_type":"markdown","source":"## Store item demand forcast"},{"metadata":{"_uuid":"562b1748e92ab92a167d3dfd1fbb5442af46b5dc"},"cell_type":"markdown","source":"### 1.0 Import library"},{"metadata":{"trusted":true,"_uuid":"947fd45a4dfdce7a25db8ac8d187bcd0c1c461ac"},"cell_type":"code","source":"# Import library\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport gc\nfrom sklearn.metrics import mean_squared_error\nimport statsmodels.api as sm\nimport lightgbm as lgb\nplt.style.use('ggplot')\n%matplotlib inline\nseed = 433","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d0e89049e7ecafc1147cd13da237f7091bc855d"},"cell_type":"markdown","source":"### 1.2 Load dataset"},{"metadata":{"trusted":true,"_uuid":"1ba82cc1c4a5c067d5c35cb0e01ad09a6be9433d"},"cell_type":"code","source":"#path ='dataset/'\npath ='../input/'\ntrain = pd.read_csv(path + 'train.csv',parse_dates=[0],nrows=None)\ntest = pd.read_csv(path+ 'test.csv',parse_dates=[1], nrows=None )\nprint('Number of rows and columns in train dataset are:',train.shape)\nprint('Number of rows and columns in test dataset are:', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aba6dc6311458ce6e84a140517567a616d9835f"},"cell_type":"markdown","source":"### 1.3 Useful function"},{"metadata":{"trusted":true,"_uuid":"6f57970caf1a7ef46878014a97299de8a1312313"},"cell_type":"code","source":"def basic_details(df):\n    \"\"\"Find number of missing value,dtyeps, unique value in \n    dataset\"\"\"\n    k = pd.DataFrame()\n    k['Missing value'] = df.isnull().sum()\n    k['% Missing value'] = df.isnull().sum()/df.shape[0]\n    k['dtype'] = df.dtypes\n    k['N unique'] = df.nunique()\n    return k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a882851aa18f9604ed193433e2cb5c7577b3b2e0"},"cell_type":"code","source":"def agg_stats(df,statistics,groupby_column):\n    \"\"\"Aggregate a column by unit sales statistics such as \n    'mean','sum','min','max', 'var', 'std',\"\"\"\n    f,ax = plt.subplots(3,2,figsize=(14,8))\n    ax =ax.ravel()\n    for i,s in enumerate(statistics):\n        tmp = (df\n         .groupby(groupby_column)\n         .agg({'sales':s})\n         )\n        tmp.columns = ['sales_{}'.format(s)]\n        sns.lineplot(x=tmp.index, y = tmp.iloc[:,0],color='blue',ax=ax[i])\n        ax[i].set_xticks(tmp.index)\n        for ticks in ax[i].get_xticklabels(): ticks.set_rotation(90)\n        #plt.xticks(rotation=90)\n        ax[i].set_title('sales_{}'.format(s))\n        ax[i].set_ylabel('')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93c8c19d13b3b73402295493062e2f75d91f36ac"},"cell_type":"code","source":"### date_time_feat\ndef date_time_feat(df,column):\n    \"Extract date time feature\"\n    df['day'] = df[column].dt.day\n    df['dayofweek'] = df[column].dt.dayofweek\n    df['month'] = df[column].dt.month\n    df['year'] = df[column].dt.year\n    \n    df['is_month_end'] = df[column].dt.is_month_end.astype('int8')\n    df['is_month_start'] = df[column].dt.is_month_start.astype('int8')\n    df['weekofyear'] = df[column].dt.weekofyear\n    # conver to category\n    #df['dayofweek'] = pd.Categorical(df['dayofweek'],\n     #       categories=['Monday','Tuesday', 'Wednesday', 'Thursday', 'Friday','Saturday', 'Sunday',])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ea2e7a8a78bdbf99869ea86672a2138f050eecb"},"cell_type":"code","source":"# Reduce memory of dataset\ndef reduce_memory_usage(df):\n    \"\"\" The function will reduce memory of dataframe \"\"\"\n    intial_memory = df.memory_usage().sum()/1024**2\n    print('Intial memory usage:',intial_memory,'MB')\n    for col in df.columns:\n        mn = df[col].min()\n        mx = df[col].max()\n        if df[col].dtype != object:            \n            if df[col].dtype == int:\n                if mn >=0:\n                    if mx < np.iinfo(np.uint8).max:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < np.iinfo(np.uint16).max:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < np.iinfo(np.uint32).max:\n                        df[col] = df[col].astype(np.uint32)\n                    elif mx < np.iinfo(np.uint64).max:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] = df[col].astype(np.int64)\n            if df[col].dtype == float:\n                df[col] =df[col].astype(np.float32)\n    \n    red_memory = df.memory_usage().sum()/1024**2\n    print('Memory usage after complition: ',red_memory,'MB')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe86a430c84a7641146c9c2bafe0c5a8f64e522b"},"cell_type":"markdown","source":"## 2.0 Exploratory data analysis\nGlimpse dataset"},{"metadata":{"trusted":true,"_uuid":"263640b55a990c3c7760de07bf6cf8a2b38a44f8"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3c330a96b20d5e24b275ed091e72f984b56eaf9"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2a80a688aeb68bcc0691c41787be186740fb0af"},"cell_type":"markdown","source":"The test dataset contains id column but train dataset does not contains id column. While importing dataset parse_date is assigned with perticular column index."},{"metadata":{"trusted":true,"_uuid":"fa6dd41d08d98d3cf9ed5906ce27bd808f5f590e"},"cell_type":"code","source":"basic_details(test) # test dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4826494ae5801fe0277f695605b4dfd617e340f8"},"cell_type":"code","source":"train.describe() # descriptive statistics about features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a2917be32961ee1c34d35d8e30098ddae4fd851"},"cell_type":"markdown","source":"There are 50 diffirent item in 10 diffirent stores. The maximum number of items sold is 231 and average item sold is 52.25."},{"metadata":{"_uuid":"db76e66db7138037c9a28c4249aa0ab008553fa6"},"cell_type":"markdown","source":"### 2.1 Date\nLet's extract day, week, month, year from date feature"},{"metadata":{"trusted":true,"_uuid":"386c6202d957131755aa56f43c65714bfd510026"},"cell_type":"code","source":"print('Time series start time: \"{}\" and end time: \"{}\"'.format(train['date'].min(), train['date'].max()))\nprint('Time series start time: \"{}\" and end time: \"{}\"'.format(test['date'].min(), test['date'].max()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9144890a4aa8d0f847a4d8890bd5d6efc67980df"},"cell_type":"code","source":"# Generate date time feature\ndate_time_feat(train,'date')\ndate_time_feat(test,'date')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd4c85a0b1e820202311511fb101446caeacf19b"},"cell_type":"code","source":"plt.figure(figsize=(14,4))\ntrain.set_index('date')['sales'].plot(kind='line')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69b96597ddaa38e5ffc522c5bf52c40610e43450"},"cell_type":"markdown","source":"### 2.1 Sales"},{"metadata":{"trusted":true,"_uuid":"999bf0944f7fa7352440abc5133a8801ab47ebe6"},"cell_type":"code","source":"f,ax = plt.subplots(1,3,figsize=(14,4))\nsns.distplot(train['sales'],ax =ax[0])\nsns.distplot(np.log(train['sales']+1),ax=ax[1], color='b')\nsns.boxenplot(train['sales'],ax =ax[2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e4ed030f9cbac7d828ee0ee22c3582c6919f872"},"cell_type":"code","source":"(train\n .groupby(['year',])\n .agg({'sales':['sum',]})\n .unstack()\n .plot(kind='bar',cmap='viridis'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fa7029c84408377163aedc57363f2a85a4e179a"},"cell_type":"code","source":"(train\n .groupby(['month','year'])\n .agg({'sales':'mean'})\n .unstack()\n .plot(figsize=(14,5)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"256c161cf3f625a245fe7d444f69844b6288d5ee"},"cell_type":"code","source":"(train\n .groupby(['dayofweek','year'])\n .agg({'sales':'mean'})\n .unstack()\n .plot(figsize=(14,5)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff737ab3a53bad7528aa6a6a1e7c28762ddce5e1"},"cell_type":"code","source":"(train\n.groupby(['day'])\n.agg({'sales':['mean','max']})\n.plot(figsize=(14,4),kind='bar',stacked=True,cmap='coolwarm'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6ada96a72db59badf80cd94526b31c6418a567d"},"cell_type":"markdown","source":"### 2.2 Aggregate sales statistics by day"},{"metadata":{"trusted":true,"_uuid":"e771b502a5a98b1ddcd601b9daef833dc85ac060"},"cell_type":"code","source":"agg_stats(train,statistics=['mean','sum','min','max', 'var', 'count'],groupby_column=['day'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"436d53952493f868a6af299dbf3c07b6e878d221"},"cell_type":"code","source":"(train.groupby('month')\n.agg({'sales':['min','mean','max']})\n .plot(figsize=(14,4),kind='bar',stacked=True))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b64d296465884b9d4f2db65a94672cefc7c2a236"},"cell_type":"code","source":"agg_stats(train,statistics=['mean','sum','min','max', 'var', 'count'],groupby_column=['month'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1db0110c40e7dc04baf7ce9e562f755131e6f353"},"cell_type":"markdown","source":"### 2.3 Store"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"c521fadc06718f89232468ca9baac4cd1f2febe7"},"cell_type":"code","source":"(train\n .groupby(['store','month'])\n .agg({'sales':['sum']})\n .unstack()\n .plot(figsize=(14,3),kind='box',stacked=True,cmap='viridis'))\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"086aa89aad9da5d518c146c1d59f00222971e475"},"cell_type":"code","source":"(train\n .groupby(['store','dayofweek'])\n .agg({'sales':['sum']})\n .unstack()\n .plot(figsize=(14,3),kind='box',stacked=True,cmap='viridis'))\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"3925f25811226e1fa1c62969ef8128c26e55e59a"},"cell_type":"code","source":"(train\n .groupby(['store','year'])\n .agg({'sales':['sum']})\n .unstack()\n .plot(figsize=(14,3),kind='box',stacked=True,cmap='viridis'))\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"7244164ad4d0e96065e553ba1891dd871832b7bc"},"cell_type":"code","source":"(train\n .groupby('store')\n .agg({'sales':['min','mean','max']})\n .plot(figsize=(14,4),kind='bar',stacked=True,cmap='magma'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47a8e72a1310333738eae06adb5ccfdd684d48ec"},"cell_type":"code","source":"agg_stats(train,statistics=['mean','sum','min','max', 'var', 'count'],groupby_column=['store'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"113cadedcd8c598ff518bcacee520e7c33bcb434"},"cell_type":"markdown","source":"### 2.4 item"},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"0f4a1628bc2c3e6d21f9d93214adcb5ac02cbadb"},"cell_type":"code","source":"(train\n .groupby('item')\n .agg({'sales':['min','mean','max']})\n .plot(figsize=(14,4),kind='bar',stacked=True,cmap='viridis'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0b7ad14c9b7d9ecec78645e13521423a22f198"},"cell_type":"code","source":"agg_stats(train,statistics=['mean','sum','min','max', 'var', 'count'],groupby_column=['item'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"fbd62c18a351587be12e3cea0267c07aa21fb08e"},"cell_type":"code","source":"(train\n .groupby(['item','month'])\n .agg({'sales':['sum']})\n .unstack()\n .plot(figsize=(14,4),kind='box',stacked=True,cmap='magma'))\nplt.xticks(rotation=90);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92aac5210cf41aa95326e528f7ee6d177665795a"},"cell_type":"code","source":"(train\n .groupby(['item','store'])\n .agg({'sales':'mean'})\n .unstack()\n .plot(figsize=(14,5),kind='line'))\nplt.savefig('agg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b0d39725237f4dcda622db60b47629d5066b3aa"},"cell_type":"code","source":"train1 =train.copy()\ntrain1['month'] = train1['date'].dt.month_name()\nplt.figure(figsize=(14,6))\npd.plotting.parallel_coordinates(train1[['dayofweek','store','sales','item','month']][:1000]\n                                 ,'month',colormap='rainbow')\ndel train1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"634b038e8776e07d38f81b36ea3df392bf0717fb"},"cell_type":"markdown","source":"### 2.5 Rolling window"},{"metadata":{"trusted":true,"_uuid":"51d0a4e62f8f19da3899043ce012d5ae29bbe8eb"},"cell_type":"code","source":"plt.figure(figsize=(14,5))\ntrain['sales'].head(1000).plot(color='darkgray')\ntrain['sales'].head(1000).rolling(window=12).mean().plot(label='mean')\n#train['sales'].head(1000).rolling(window=12).median().plot(label='median')\ntrain['sales'].head(1000).rolling(window=7).min().plot(label='min',color='g')\ntrain['sales'].head(1000).rolling(window=7).max().plot(label='max',color='b')\ntrain['sales'].head(1000).rolling(window=7).std().plot(label='std',color='yellow')\nplt.legend()\n#plt.savefig('Rolling window.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a406836c77aace583caac92b87e3ad6f028b86da"},"cell_type":"markdown","source":"### 2.6 Expanding window"},{"metadata":{"trusted":true,"_uuid":"38e57ba2c4807b66285a56f25af2241395dfa194"},"cell_type":"code","source":"# Expanding window\nplt.figure(figsize=(14,5))\ntrain['sales'].head(1000).plot(color='darkgray')\ntrain['sales'].head(1000).expanding().mean().plot(label='mean')\n#train['sales'].head(1000).rolling(window=12).median().plot(label='median')\ntrain['sales'].head(1000).expanding().min().plot(label='min',color='g')\ntrain['sales'].head(1000).expanding().max().plot(label='max',color='b')\ntrain['sales'].head(1000).expanding().std().plot(label='std',color='yellow')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22f80bcd9e9b600d9dfe1ab5da94c5f2d48e00ed"},"cell_type":"markdown","source":"## 3.0 Data preprocessing"},{"metadata":{"_uuid":"c86e23c2d3e74442a3d8974a4531a0bf53bdbe93"},"cell_type":"markdown","source":"### 3.0 Aggregate / Rolling function"},{"metadata":{"trusted":true,"_uuid":"dfe83c2222fa910426f5538425c315a65c612b6c"},"cell_type":"code","source":"# Claculate groupby statics for lag date \ndef calc_stats(df, end,window,groupby=None,aggregates='mean',value='sales'):\n    \n    # dates\n    last_date = pd.to_datetime(end) - pd.Timedelta(days=1)\n    first_date = pd.to_datetime(end) - pd.Timedelta(days= window)\n    # Aggregate\n    df1 = df[(df.date >=first_date) & (df.date<= last_date) ]\n    df_agg = df1.groupby(groupby)[value].agg(aggregates)\n    # Change name of columns\n    df_agg.name =  str(end).split(' ')[0]+'_' + '_'.join(groupby)+'_'+aggregates+'_'+ str(window)\n    return df_agg.reset_index()\n\n#sales_by_store_item\ndef sales_by_store_item(df, end, aggregates='mean', value='sales'):\n    \n    print('Adding sales by store item')\n    data = calc_stats(df,end, window=1,aggregates=aggregates, \n                      groupby=['store','item'], value=value)\n    print('window 1 added')\n    \n    for window in  [3,7,14,28,90,180,365]:\n        agg = calc_stats(df,end, window=window, aggregates=aggregates,\n                         groupby=['store','item'], value=value )\n        data = pd.merge(data,agg)\n        print('window %d added'% window)\n    return data\n\n# sales by store item dayofweek\ndef sales_by_store_item_dayofweek(df, end, aggregates='mean', value='sales'):\n    \n    print('Adding sales by store item dayofweek')\n    data = calc_stats(df,end, window=7, aggregates=aggregates,\n                      groupby = ['store','item','dayofweek'], value=value)\n    print('window 7 added')\n    \n    for window in  [14,28,28*2,28*3,28*6,28*12]:\n        agg = calc_stats(df,end, window=window, aggregates=aggregates,\n                         groupby=['store','item','dayofweek'], value=value )\n        data = pd.merge(data,agg)\n        print('window %d added'% window)\n    return data\n\n# sales_by_store_item_day\ndef sales_by_store_item_day(df, end, aggregates='mean', value='sales'):\n    \n    print('Adding sales by store item day')\n    data = calc_stats(df,end, window=365, aggregates=aggregates,\n                      groupby = ['store','item','day'], value=value)\n    print('window 365 added')\n    \n    return data\n\n# Sales by item\ndef sales_by_item(df, end, aggregates='mean', value='sales'):\n    \n    print('Adding sales by item ')\n    data = calc_stats(df,end, window=7, aggregates=aggregates,\n                      groupby = ['item'], value=value)\n    print('window 7 added')\n    \n    for window in  [14,28,28*2]:\n        agg = calc_stats(df,end, window=window, aggregates=aggregates,\n                         groupby=['item'], value=value )\n        data = pd.merge(data,agg)\n        print('window %d added'% window)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5e707c42c1a4897e98904d68974e91b5b11811f"},"cell_type":"code","source":"def calc_roll_stat(df,end,groupby=None,window=1,aggregate='mean'):\n    # Rolling statistics method\n    last_date = pd.to_datetime(end) - pd.Timedelta(days=1)\n    first_date = pd.to_datetime(end) - pd.Timedelta(days=window)\n    df1 = df[(df.date >= first_date) & (df.date <= last_date)]\n    \n    dfPivot = df1.set_index(['date']+groupby)['sales'].unstack().unstack()\n    dfPivot = dfPivot.rolling(window=window).mean().fillna(method='bfill')\n    return dfPivot.stack().stack().rename(aggregate+str(window))\n\ndef calc_expand_stat(df,end,window=1,aggregate='mean'):\n    # Expanding statistics method\n    last_date = pd.to_datetime(end) - pd.Timedelta(days=1)\n    first_date = pd.to_datetime(end) - pd.Timedelta(days=window)\n    df1 = df[(df.date >= first_date) & (df.date <= last_date)]\n    \n    dfPivot = df1.set_index(['date','store','item'])['sales'].unstack().unstack()\n    dfPivot = dfPivot.expanding(min_periods=window).mean().fillna(method='bfill')\n    dfPivot = dfPivot.stack().stack().rename(aggregate+'_'+str(window)).reset_index()\n    return dfPivot\n\ndef sales_by_store_item_expading(df,end,aggregate = 'mean', value = 'sales'):\n    print('Adding sales by expanding')\n    data =calc_expand_stat(df,end,window=3, aggregate='mean')\n    return data\n# https://stackoverflow.com/questions/25917287/pandas-groupby-expanding-mean-by-column-value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2203ace41a0b2fa0cc0612d2b471c3543fc84ad"},"cell_type":"code","source":"def create_data1(sales,test,date):\n    \n    # Date input\n    for i in range(2):\n        end = pd.to_datetime(date) - pd.Timedelta(days=7*i+1)\n        print(end)\n    \n        # Rolling feature\n        #for aggregates in ['mean','min','max','sum','std']:\n        for aggregates in ['mean','sum']:\n\n            # store/item\n            print('-'*20+'Aggregate by '+aggregates+'-'*20)\n            data = sales_by_store_item(sales,end, aggregates=aggregates,value='sales')\n            sales = pd.merge(sales,data,on=['store','item'],how='left')\n            test = pd.merge(test,data,on=['store','item'], how='left')\n\n            # store/item/dayofweek\n            df = sales_by_store_item_dayofweek(sales,end, aggregates=aggregates,value='sales')\n            #data = pd.merge(data,df,)\n            sales = pd.merge(sales,df,on=['store','item','dayofweek'],how='left')\n            test = pd.merge(test,df,on=['store','item','dayofweek'], how='left')\n\n            # store/item/day\n            df = sales_by_store_item_day(sales,end, aggregates=aggregates,value='sales')\n            #data = pd.merge(data,df)\n            sales = pd.merge(sales,df,on=['store','item','day'],how='left')\n            test = pd.merge(test,df,on=['store','item','day'], how='left')\n\n            # sales/item\n            df = sales_by_item(sales,end, aggregates=aggregates, value='sales')\n            data = pd.merge(data,df)\n            #data = pd.merge(sales,data)\n            sales = pd.merge(sales,df, on=['item'],how='left')\n            test = pd.merge(test,df, on=['item'], how='left')\n\n    return sales,test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ca13d6763059824985bbfdb3ff0a4cbcf3e8100"},"cell_type":"code","source":"#Time series start time: \"2013-01-01 00:00:00\" and end time: \"2017-12-31 00:00:00\"\n#Time series start time: \"2018-01-01 00:00:00\" and end time: \"2018-03-31 00:00:00\"\ntes_start = '2018-01-01'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af9f9ccac70fba9d1d073770e268790a87551b64"},"cell_type":"code","source":"# Rolling aggregation or lag feature for diffirend window size\ntrain1,test1 = create_data1(train,test,tes_start)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6faa7454bd581d7089ee103292000987ec3a2f5"},"cell_type":"markdown","source":"### 3.1 One hot encoding"},{"metadata":{"trusted":true,"_uuid":"2790ea7f7b74a47897053b5a63bfaa0b773e85bb"},"cell_type":"code","source":"train1['id'] = np.nan\ntrain1['is_train'] = True\ntest1['is_train'] = False\ntest1['sales'] = np.nan\n\n# concat train,test\ntrain_test = pd.concat([train1,test1],axis=0)\n\n#Log transform\ntrain_test['sales_log'] = np.log(train_test['sales']+1)\ngc.collect()\ntrain_test.shape\n\ndef one_hot_encoding(df,columns):\n    print('Original shape',df.shape)\n    df = pd.get_dummies(df,drop_first=True,columns=columns)\n    print('After OHE', df.shape)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8fe36f9b8f698a7bc0d4e94208099de9ddee309"},"cell_type":"code","source":"gc.collect()\ntrain_test = one_hot_encoding(train_test,columns=['month','dayofweek'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"692ecd613613e8c31af6e9c867c0b30aab06b5cd"},"cell_type":"code","source":"reduce_memory_usage(train_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5663e8f658074ff6a6a55139b6cc686822a25661"},"cell_type":"code","source":"#plt.figure(figsize=(14,10))\n#sns.heatmap(train_test1.corr(), cmap='coolwarm', annot=True,fmt='.2f')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb0c82fd6d74f0305f22f5206bfe15e16d9d54b9"},"cell_type":"markdown","source":"## 4.0 Model selection"},{"metadata":{"trusted":true,"_uuid":"283ad54bd75e0aa5bed1e356741f88e28ea6b958"},"cell_type":"code","source":"# Model\ncol_drop = ['id','is_train','sales','sales_log']\nX = train_test[train_test['is_train'] == True].drop(col_drop, axis=1)\ny = train_test[train_test['is_train'] == True]['sales_log']\ntest_new = train_test[train_test['is_train'] == False].drop(col_drop +['date'],axis=1)\n\n# Time series based split\n#Time series start time: \"2013-01-01 00:00:00\" and end time: \"2017-12-31 00:00:00\"\n#Time series start time: \"2018-01-01 00:00:00\" and end time: \"2018-03-31 00:00:00\"\ntra_start, tra_end = '2013-01-01','2016-12-31'\nval_start, val_end = '2017-01-01','2017-12-31'\ntes_start = '2018-01-01'\n\nX_train = X[X.date.isin(pd.date_range(tra_start,tra_end))].drop(['date'],axis=1)\nX_valid = X[X.date.isin(pd.date_range(val_start, val_end))].drop(['date'],axis=1)\ny_train = y[X.date.isin(pd.date_range(tra_start,tra_end))]\ny_valid = y[X.date.isin(pd.date_range(val_start, val_end))]\ngc.collect()\nX.shape,test_new.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"304984fc97dc5bdad7f69c360791607836049d04"},"cell_type":"code","source":"# SMAPE Systematic mean absolute Persent error\ndef smape(y_true,y_pred):\n    \n    n = len(y_pred)\n    masked_arr = ~((y_pred==0)&(y_true==0))\n    y_pred, y_true = y_pred[masked_arr], y_true[masked_arr]\n    nom = np.abs(y_true - y_pred)\n    denom = np.abs(y_true) + np.abs(y_pred)\n    smape = 200/n * np.sum(nom/denom)\n    return smape\ndef lgb_smape(pred,train_data):\n    ''' \n    Custom evaluvation function\n    '''\n    label = train_data.get_label()\n    smape_val = smape(np.expm1(pred), np.expm1(label))\n    return 'SMAPE',smape_val, False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76348d7aceda7d0f07bb6bb9d154f1c498470faf"},"cell_type":"markdown","source":"## 5.0 Model"},{"metadata":{"trusted":true,"_uuid":"1059e7f51381f00a846e49edd6ab44df6c23187f"},"cell_type":"code","source":"def lgb_model(X_train, X_valid, y_valid, y_test,test_new):\n    lgb_param = {}\n    lgb_param['boosting_type'] ='gbdt'\n    lgb_param['max_depth'] = 7\n    lgb_param['num_leaves'] = 2**7\n    lgb_param['learning_rate'] = 0.05\n    #lgb_param['n_estimators'] = 3000\n    lgb_param['feature_fraction'] = 0.9\n    lgb_param['bagging_fraction'] = 0.9\n    lgb_param['lambda_l1'] = 0.06\n    lgb_param['lambda_l2'] =  0.1\n    lgb_param['random_state'] = seed\n    lgb_param['n_jobs'] = 4\n    lgb_param['silent'] = -1\n    lgb_param['verbose'] = -1\n    lgb_param['metric'] = 'mae'\n    \n    model = lgb.LGBMRegressor(**lgb_param)\n    lgb_train = lgb.Dataset(X_train,y_train)\n    lgb_valid = lgb.Dataset(X_valid,y_valid)\n    valid_set = [lgb_train,lgb_valid]\n    model = lgb.train(params=lgb_param,train_set=lgb_train,valid_sets=valid_set,num_boost_round= 300,\n                      feval=lgb_smape,early_stopping_rounds=20,)\n    print('-'*10,'*'*20,'-'*10)\n    #model.fit(X_train,y_train, eval_set= [(X_train,y_train),(X_valid,y_valid)],\n    #          eval_metric ='rmse',early_stopping_rounds=20,verbose=100)\n    \n    y_pred = model.predict(X_valid)\n    print('Root mean_squared_error','-'*20 ,np.sqrt(mean_squared_error(y_valid, y_pred)))\n    y_pred_new = model.predict(test_new)\n    return y_pred_new, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b311a6f65b5a4eeac04c9b6e1604a6e11be0753"},"cell_type":"code","source":"# Model training\ny_pred_new, model = lgb_model(X_train, X_valid, y_valid, y_valid,test_new)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a1c96eb4b7812369aed77462c24f0c0996a9534"},"cell_type":"markdown","source":"### 6.0 Model evaluation"},{"metadata":{"trusted":true,"_uuid":"c8bb91cd9c6645c5bb22f71ebc7542626afd5152"},"cell_type":"code","source":"#print('Root mean_squared_error',np.sqrt(mean_squared_error(y_test, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c0944602e077c9d36b123a2e5c61db7ce7a0102"},"cell_type":"code","source":"# Feature importance\nlgb.plot_importance(model,max_num_features=20);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8082fef5e3b1dc5a41ddb713805acdb57451652"},"cell_type":"code","source":"sns.distplot(y_pred_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9065054429a2a46bc127d303e03df4e2618fee2"},"cell_type":"code","source":"y_pred_new1 = np.exp(y_pred_new)-1\nsubmit = pd.DataFrame({'id': test['id'], 'sales':(y_pred_new1)})\nsubmit.to_csv('store_submit.csv',index=False)\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b9265c89b5e09c6dc8a09e5e2998d587a65f4b0"},"cell_type":"markdown","source":"## Thank you"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}