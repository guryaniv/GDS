{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["Data Exploration assisting kernel \"TensorFlow with 2-layer Neural Network\",\n", "https://github.com/MizioAnd/PortoSeguroInsur/blob/master/porto_seguro_insur.py\n", "\n", "This notebook is also found on my Github profile Mizioand,\n", "https://github.com/MizioAnd/PortoSeguroInsur/blob/master/porto_seguro_notebook.ipynb"], "metadata": {"_uuid": "cac489a7df551c9ee6c1f371b45bb4032b247564", "_cell_guid": "20937555-4b1c-4aeb-8769-df21d0541878"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# porto_seguro_insur.py\n", "#  Assumes python vers. 3.6\n", "# __author__ = 'mizio'\n", "\n", "import csv as csv\n", "import numpy as np\n", "import pandas as pd\n", "import pylab as plt\n", "from fancyimpute import MICE\n", "import random\n", "from sklearn.model_selection import cross_val_score\n", "import datetime\n", "import seaborn as sns\n", "import tensorflow as tf"], "execution_count": null, "metadata": {"_uuid": "387757df74ea205a932f7f576b9acfcc51023a03", "collapsed": true, "_cell_guid": "1990775f-04f2-4875-8b63-d8c6ba2b3040"}, "cell_type": "code"}, {"outputs": [], "source": ["class PortoSeguroInsur:\n", "    def __init__(self):\n", "        self.df = PortoSeguroInsur.df\n", "        self.df_test = PortoSeguroInsur.df_test\n", "        self.df_submission = PortoSeguroInsur.df_submission\n", "        self.timestamp = datetime.datetime.now().strftime('%Y%m%d_%Hh%Mm%Ss')\n", "\n", "\n", "    # Load data into Pandas DataFrame\n", "    # For .read_csv, always use header=0 when you know row 0 is the header row\n", "    df = pd.read_csv('../input/train.csv', header=0)\n", "    df_test = pd.read_csv('../input/test.csv', header=0)\n", "    df_submission = pd.read_csv('../input/sample_submission.csv', header=0)\n", "\n", "    @staticmethod\n", "    def features_with_null_logical(df, axis=1):\n", "        row_length = len(df._get_axis(0))\n", "        # Axis to count non null values in. aggregate_axis=0 implies counting for every feature\n", "        aggregate_axis = 1 - axis\n", "        features_non_null_series = df.count(axis=aggregate_axis)\n", "        # Whenever count() differs from row_length it implies a null value exists in feature column and a False in mask\n", "        mask = row_length == features_non_null_series\n", "        return mask\n", "\n", "    def missing_values_in_dataframe(self, df):\n", "        mask = self.features_with_null_logical(df)\n", "        print(df[mask[mask == 0].index.values].isnull().sum())\n", "        print('\\n')\n", "\n", "    @staticmethod\n", "    def extract_numerical_features(df):\n", "        df = df.copy()\n", "        df = df.copy()\n", "        non_numerical_feature_names = df.columns[np.where(PortoSeguroInsur.numerical_feature_logical_incl_hidden_num(\n", "            df) == 0)]\n", "        return non_numerical_feature_names\n", "\n", "    @staticmethod\n", "    def extract_non_numerical_features(df):\n", "        df = df.copy()\n", "        non_numerical_feature_names = df.columns[np.where(PortoSeguroInsur.numerical_feature_logical_incl_hidden_num(\n", "            df))]\n", "        return non_numerical_feature_names\n", "\n", "    @staticmethod\n", "    def numerical_feature_logical_incl_hidden_num(df):\n", "        logical_of_non_numeric_features = np.zeros(df.columns.shape[0], dtype=int)\n", "        for ite in np.arange(0, df.columns.shape[0]):\n", "            try:\n", "                str(df[df.columns[ite]][0]) + df[df.columns[ite]][0]\n", "                logical_of_non_numeric_features[ite] = True\n", "            except TypeError:\n", "                hej = 'Oops'\n", "        return logical_of_non_numeric_features\n", "\n", "    def clean_data(self, df, is_train_data=1):\n", "        df = df.copy()\n", "        if df.isnull().sum().sum() > 0:\n", "            if is_train_data:\n", "                df = df.dropna()\n", "            else:\n", "                df = df.dropna(1)\n", "        return df\n", "\n", "    def reformat_data(self, labels, num_labels):\n", "        # Map labels/target value to one-hot-encoded frame. None is same as implying newaxis() just replicating array\n", "        # if num_labels > 2:\n", "        labels = (np.arange(num_labels) == labels[:, None]).astype(np.float64)\n", "        return labels\n", "\n", "    def accuracy(self, predictions, labels):\n", "        # Sum the number of cases where the predictions are correct and divide by the number of predictions\n", "        number_of_correct_predictions = np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n", "        return 100*number_of_correct_predictions/predictions.shape[0]\n", "\n", "    def linear_model(self, input_vector, weight_matrix, bias_vector):\n", "        # f(x) = Wx + b\n", "        # W is the weight matrix with elements w_ij\n", "        # x is the input vector\n", "        # b is the bias vector\n", "        # In the machine learning literature f(x) is called an activation\n", "        return tf.matmul(input_vector, weight_matrix) + bias_vector\n", "\n", "    def activation_out(self, logit):\n", "        return self.activation(logit, switch_var=0)\n", "\n", "    def activation_hidden(self, logit):\n", "        return self.activation(logit, switch_var=0)\n", "\n", "    def activation(self, logit, switch_var=0):\n", "        # Also called the activation function\n", "        if switch_var == 0:\n", "            # Logistic sigmoid function.\n", "            # sigma(a) = 1/(1+exp(-a))\n", "            return tf.nn.sigmoid(logit)\n", "        elif switch_var == 1:\n", "            # Using Rectifier as activation function. Rectified linear unit (ReLU). Compared to sigmoid or other\n", "            # activation functions it allows for faster and effective training of neural architectures.\n", "            # f(x) = max(x,0)\n", "            return tf.nn.relu(logit)\n", "        else:\n", "            # Softmax function.\n", "            # S(y_i) = e^y_i/(Sum_j e^y_j)\n", "            return tf.nn.softmax(logit)\n", "\n", "    def missing_values_in_dataframe(self, df):\n", "        mask = self.features_with_null_logical(df)\n", "        print(df[mask[mask == 0].index.values].isnull().sum())\n", "        print('\\n')\n", "        \n", "    @staticmethod\n", "    def extract_numerical_features(df):\n", "        df = df.copy()\n", "        # Identify numerical columns which are of type object\n", "        numerical_features = pd.Series(data=False, index=df.columns, dtype=bool)\n", "\n", "        for feature in df.columns:\n", "            if any(tuple(df[feature].apply(lambda x: type(x)) == int)) or \\\n", "                            any(tuple(df[feature].apply(lambda x: type(x)) == float)) & \\\n", "                            (not any(tuple(df[feature].apply(lambda x: type(x)) == str))):\n", "                numerical_features[feature] = 1\n", "        return numerical_features[numerical_features == 1].index\n"], "execution_count": null, "metadata": {"_uuid": "c9e9578822303c2cd85fb38255c6886f7f5d3bfc", "collapsed": true, "_cell_guid": "9fb3c38d-9013-4933-a811-ce7590a9f186"}, "cell_type": "code"}, {"outputs": [], "source": ["porto_seguro_insur = PortoSeguroInsur()\n", "df = porto_seguro_insur.df.copy()\n", "df_test = porto_seguro_insur.df_test.copy()\n", "df_submission = porto_seguro_insur.df_submission.copy()\n", "\n", "df = df.replace(-1, np.NaN)\n", "df_test = df_test.replace(-1, np.NaN)\n", "\n", "print('All df set missing values')\n", "porto_seguro_insur.missing_values_in_dataframe(df)\n", "\n", "# Train Data: numeric feature columns with none or nan in test data\n", "print('\\nColumns in train data with none/nan values:')\n", "print('\\nTraining set numerical features\\' missing values')\n", "df_numerical_features = porto_seguro_insur.extract_numerical_features(df)\n", "print('\\nNumber of numerical features df: %s' % df_numerical_features.shape[0])\n", "porto_seguro_insur.missing_values_in_dataframe(df[df_numerical_features])\n", "\n", "# Test Data: Print numeric feature columns with none/nan in test data\n", "print('\\nColumns in test data with none/nan values:')\n", "print('\\nTest set numerical features\\' missing values')\n", "df_test_numerical_features = porto_seguro_insur.extract_numerical_features(df_test)\n", "print('\\nNumber of numerical features df_test: %s' % df_test_numerical_features.shape[0])\n", "porto_seguro_insur.missing_values_in_dataframe(df_test[df_test_numerical_features])\n", "\n", "print(df.shape)\n", "print(df_test.shape)\n", "# Clean data for NaN\n", "df = porto_seguro_insur.clean_data(df)\n", "df_test = porto_seguro_insur.clean_data(df_test, is_train_data=0)\n", "print('df_test.shape: %s' % str(df_test.shape))  # (892816, 46)\n", "# df_test = porto_seguro_insur.clean_data(df_test, is_train_data=0)\n", "id_df_test = df_test['id']  # Submission column\n", "print(\"After dropping NaN\")\n", "print(df.shape)\n", "print(df_test.shape)"], "execution_count": null, "metadata": {"_uuid": "5bced9121386187c087d82fe8b6052af0b9ff951", "_cell_guid": "b1702deb-ee35-4a7c-8bad-380c2a0e8a03"}, "cell_type": "code"}, {"outputs": [], "source": ["is_explore_data = 1\n", "if is_explore_data:\n", "    # Overview of train data\n", "    print('\\n TRAINING DATA:----------------------------------------------- \\n')\n", "    print(df.head(3))\n", "    print('\\n')\n", "    print(df.info())\n", "    print('\\n')\n", "    print(df.describe())\n", "    print('\\n')\n", "    print(df.dtypes)\n", "    print(df.get_dtype_counts())\n", "\n", "    # missing_values\n", "    print('All df set missing values')\n", "    porto_seguro_insur.missing_values_in_dataframe(df)\n", "\n", "    print('Uniques')\n", "    uniques_in_id = np.unique(df.id.values).shape[0]\n", "    print(uniques_in_id)\n", "    print('uniques_in_id == df.shape[0]')\n", "    print(uniques_in_id == df.shape[0])\n", "\n", "    # Overview of sample_submission format\n", "    print('\\n sample_submission \\n')\n", "    print(df_submission.head(3))\n", "    print('\\n')\n", "    print(df_submission.info())\n", "    print('\\n')"], "execution_count": null, "metadata": {"_uuid": "d4d08055862307fa76d3f5943c39283e003e4d76", "_cell_guid": "1158fec2-b30f-41b4-83b2-198763ecbba2"}, "cell_type": "code"}, {"outputs": [], "source": ["# Categorical plot with seaborn\n", "is_categorical_plot = 1\n", "if is_categorical_plot:\n", "    # sns.countplot(y='MSZoning', hue='MSSubClass', data=df, palette='Greens_d')\n", "    # plt.show()\n", "    # sns.stripplot(x='SalePrice', y='MSZoning', data=df, jitter=True, hue='LandContour')\n", "    # plt.show()\n", "    # sns.boxplot(x='SalePrice', y='MSZoning', data=df, hue='MSSubClass')\n", "    # plt.show()\n", "\n", "    # Heatmap of feature correlations\n", "    print('\\nCorrelations in training data')\n", "    plt.figure(figsize=(10, 8))\n", "    correlations_train = porto_seguro_insur.df.corr()\n", "    sns.heatmap(correlations_train, vmax=0.8, square=True)\n", "    plt.show()\n", "    \n", "    # Heatmap of feature correlations\n", "    print('\\nCorrelations in test data')\n", "    plt.figure(figsize=(10, 8))\n", "    correlations_test = porto_seguro_insur.df_test.corr()\n", "    sns.heatmap(correlations_test, vmax=0.8, square=True)\n", "    plt.show()"], "execution_count": null, "metadata": {"_uuid": "5bc5557d36fb270c25ee1051dbaf2e54cf5c9602", "_cell_guid": "896b33d7-cae8-479d-9433-abe3667b4a4a"}, "cell_type": "code"}, {"outputs": [], "source": ["# Zoom of heatmap with coefficients\n", "plt.figure(figsize=(20, 12))\n", "top_features = 10\n", "columns = correlations_train.nlargest(top_features, 'target')['target'].index\n", "correlation_coeff = np.corrcoef(porto_seguro_insur.df[columns].values.T)\n", "sns.set(font_scale=1.20)\n", "coeff_heatmap = sns.heatmap(correlation_coeff, annot=True, cmap='YlGn', cbar=True, \n", "                            square=True, fmt='.2f', annot_kws={'size': 10}, \n", "                            yticklabels=columns.values, xticklabels=columns.values)\n", "plt.show()"], "execution_count": null, "metadata": {"_uuid": "1e280bd87a3dfe4e3322f1e3c61168d75d6dbe58", "_cell_guid": "6a76d554-772c-4975-add3-39787af7fa50"}, "cell_type": "code"}, {"source": ["Note that correlations with target are low. The best features are ps_car_13 and ps_car_12.\n", "Check if there are categorical features that need to be one-hot-encoded.\n", "Example note that in features we have,\n", "ps_ind_02_cat\n", "and\n", "ps_ind_06_bin\n", "where 'cat' and 'bin' may be abbreviations for categorical and binary feature values."], "metadata": {"_uuid": "a13e1bbdb8133ead3021ec02994914f0274ad3f3", "_cell_guid": "7902bc3f-59a6-454c-ad29-61bb0d24cde9"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# Check output space for each feature. Expect 58 uniques i.e. one for every feature.\n", "ser_with_uniques = pd.Series()\n", "for ite in df.columns:\n", "    ser_with_uniques[ite] = df[ite].unique().shape[0]\n", "print(ser_with_uniques)"], "execution_count": null, "metadata": {"_uuid": "461024eb0e8c0d17c0fd1daa5f57659c7895c696", "_cell_guid": "540c1379-fd5d-47e7-bd04-5f8f62f9aa60"}, "cell_type": "code"}, {"outputs": [], "source": ["# Check if two-value features are binaries\n", "indices_of_two_value_feats = ser_with_uniques == 2\n", "print(indices_of_two_value_feats)"], "execution_count": null, "metadata": {}, "cell_type": "code"}, {"outputs": [], "source": ["feats_with_two_value = ser_with_uniques[indices_of_two_value_feats]\n", "print(feats_with_two_value.axes[0])\n", "print(type(feats_with_two_value.axes))"], "execution_count": null, "metadata": {}, "cell_type": "code"}, {"outputs": [], "source": ["ser_with_max_of_uniques = pd.Series()\n", "for ite in feats_with_two_value.axes[0]:\n", "    ser_with_max_of_uniques[ite] = df[ite].unique()\n", "print(ser_with_max_of_uniques)"], "execution_count": null, "metadata": {}, "cell_type": "code"}, {"source": ["Hence the two-value features are binaries."], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": [], "execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "version": "3.6.3"}}}