{"cells":[{"metadata":{"_uuid":"8ba2b81da7112bb2c444597f0c683da06f46b532","_cell_guid":"048d1d0f-8c94-4f48-9ed8-66f9b289d55f"},"cell_type":"markdown","source":"This is fast image downloader using this trick:\nhttps://www.kaggle.com/c/landmark-recognition-challenge/discussion/49703\nAnd you can change target size that you prefer.\n\nReference:\nhttps://www.kaggle.com/c/landmark-recognition-challenge/discussion/48895\n```\nFor 256,256 this should be 22 GB\nFor 224,224 this should be 16.8 GB\nFor 139,139 this should be 6.5 GB\nFor 128,128 this should be 5.5 GB\nFor 96,96 this should be 3.1 GB\nFor 64,64 this should be 1.4 GB\n```"},{"metadata":{"_uuid":"37602ab4582f8bb69e165a7c52f33de7a020d480","_cell_guid":"e097aec8-4b08-4a52-a2ea-356ba28f23ca","collapsed":true,"trusted":false},"cell_type":"code","source":"import multiprocessing\nimport os\nfrom io import BytesIO\nfrom urllib import request\nimport pandas as pd\nimport re\nimport tqdm\nfrom PIL import Image\n\n\n# set files and dir\nDATA_FRAME, OUT_DIR = pd.read_csv('../input/train.csv'), '../input/train'  # recognition challenge\n# DATA_FRAME, OUT_DIR = pd.read_csv('../input/index.csv'), '../input/index'  # retrieval challenge\n# DATA_FRAME, OUT_DIR = pd.read_csv('../input/test.csv'), '../input/test'  # test data\n\n# preferences\nTARGET_SIZE = 128  # image resolution to be stored\nIMG_QUALITY = 90  # JPG quality\nNUM_WORKERS = 8  # Num of CPUs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6e1daa19a1099b1cff18c466598cabc5527ab06","_cell_guid":"e09be776-5baa-41c8-a99b-a56c49124d3c","collapsed":true,"trusted":false},"cell_type":"code","source":"DATA_FRAME.url.apply(lambda x: x.split('/')[-2]).value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71befb4791887baf9a9f18c3d365aaae94c88066","_cell_guid":"a4ad759b-4014-4477-b75c-af10e4f718d1"},"cell_type":"markdown","source":"We found that almost images have 1600x resolution.\nDownloading such a high resolution images takes so much time, so I recommend you to download images after changing url \"s1600\" to \"s{TARGET_SIZE}\" like the below script."},{"metadata":{"_uuid":"af08d9b8e92a4a532b1425814bbd5593638763d3","_cell_guid":"b713704e-8e75-4b12-9620-d0b582ad7f7d","collapsed":true,"trusted":false},"cell_type":"code","source":"def overwrite_urls(df):\n    def reso_overwrite(url_tail, reso=TARGET_SIZE):\n        pattern = 's[0-9]+'\n        search_result = re.match(pattern, url_tail)\n        if search_result is None:\n            return url_tail\n        else:\n            return 's{}'.format(reso)\n\n    def join_url(parsed_url, s_reso):\n        parsed_url[-2] = s_reso\n        return '/'.join(parsed_url)\n\n    parsed_url = df.url.apply(lambda x: x.split('/'))\n    train_url_tail = parsed_url.apply(lambda x: x[-2])\n    resos = train_url_tail.apply(lambda x: reso_overwrite(x, reso=TARGET_SIZE))\n\n    overwritten_df = pd.concat([parsed_url, resos], axis=1)\n    overwritten_df.columns = ['url', 's_reso']\n    df['url'] = overwritten_df.apply(lambda x: join_url(x['url'], x['s_reso']), axis=1)\n    return df\n\n\ndef parse_data(df):\n    key_url_list = [line[:2] for line in df.values]\n    return key_url_list\n\n\ndef download_image(key_url):\n    (key, url) = key_url\n    filename = os.path.join(OUT_DIR, '{}.jpg'.format(key))\n\n    if os.path.exists(filename):\n        print('Image {} already exists. Skipping download.'.format(filename))\n        return 0\n\n    try:\n        response = request.urlopen(url)\n        image_data = response.read()\n    except:\n        print('Warning: Could not download image {} from {}'.format(key, url))\n        return 1\n\n    try:\n        pil_image = Image.open(BytesIO(image_data))\n    except:\n        print('Warning: Failed to parse image {}'.format(key))\n        return 1\n\n    try:\n        pil_image_rgb = pil_image.convert('RGB')\n    except:\n        print('Warning: Failed to convert image {} to RGB'.format(key))\n        return 1\n\n    try:\n        pil_image_resize = pil_image_rgb.resize((TARGET_SIZE, TARGET_SIZE))\n    except:\n        print('Warning: Failed to resize image {}'.format(key))\n        return 1\n\n    try:\n        pil_image_resize.save(filename, format='JPEG', quality=IMG_QUALITY)\n    except:\n        print('Warning: Failed to save image {}'.format(filename))\n        return 1\n\n    return 0\n\n\ndef loader(df):\n    if not os.path.exists(OUT_DIR):\n        os.mkdir(OUT_DIR)\n\n    key_url_list = parse_data(df)\n    pool = multiprocessing.Pool(processes=NUM_WORKERS)\n    failures = sum(tqdm.tqdm(pool.imap_unordered(download_image, key_url_list),\n                             total=len(key_url_list)))\n    print('Total number of download failures:', failures)\n    pool.close()\n    pool.terminate()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a17d89433c4bdb281ba7a1dd564b260181c7fd9","_cell_guid":"5a8fb78f-c46e-4b85-95e2-40736aa1e9ec","collapsed":true,"trusted":false},"cell_type":"code","source":"# now, start downloading\nif __name__ == '__main__':\n    loader(overwrite_urls(DATA_FRAME))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}