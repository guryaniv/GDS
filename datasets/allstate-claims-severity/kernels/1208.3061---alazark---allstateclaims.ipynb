{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "538d136d-7996-ae1e-4d22-a6ac3742bc3e"
      },
      "source": [
        "Allstate Claims analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3dc17d8d-31d4-ffd5-aa3d-51dae02e4b42"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68a87654-c30b-d69b-e8c7-a8241e532f9a"
      },
      "outputs": [],
      "source": [
        "#read data from CSV file\n",
        "train = pd.read_csv(\"../input/train.csv\")\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "#Some info about the data\n",
        "#train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "851cf109-aa03-415d-ab16-a516c32aa1a6"
      },
      "outputs": [],
      "source": [
        "#Data housekeeping\n",
        "#Category variables 116\n",
        "train_cat = train.ix[:,'cat1':'cat116']\n",
        "#Continuous variable 14\n",
        "train_cont = train.ix[:,'cont1':'cont14']\n",
        "#train_cat_dummy = pd.get_dummies(train_cat)\n",
        "#print(train_cat.head(2))\n",
        "#print(train_cat_dummy.head(2))\n",
        "#Number of training samples\n",
        "print(\"number of traning samples : {}\".format(train.shape[0]))\n",
        "print(\"number of test samples: {}\".format(test.shape[0]))\n",
        "#count the number of unique values under the categorical variables\n",
        "print(\"number of unique categorical values : {}\".format(len(pd.unique(train_cat[train_cat.columns[1:]].values.ravel()))))\n",
        "#Check if there are any null values\n",
        "#print(train.isnull().values.any())\n",
        "#print(test.isnull().values.any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "102a901c-7c02-7791-7423-f28d2fa75398"
      },
      "outputs": [],
      "source": [
        "#correlation between continuous predictors and traget\n",
        "train_corr_loss = train.corr()[\"loss\"]\n",
        "ax = train_corr_loss.iloc[1:-1].plot(kind='bar',title=\"continuous features correlation with target\", figsize=(5,5), fontsize=12)\n",
        "ax.set_ylabel(\"correlation value\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "47c8bea2-d527-9ca4-2068-dda394e4553c"
      },
      "source": [
        "As we can see cont2 has the higher correlation with target followed by cont8,cont3,cont11 and cont12.\n",
        "cont13 has the lowest correlation.In general, all these features have low correlation values to the target, < 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "150bbd0e-8cf0-ac3e-cf68-141215a140ff"
      },
      "outputs": [],
      "source": [
        "#classifcation just considering the continous features(why?)\n",
        "y_train1 = np.asarray(train['loss'])\n",
        "X_test1 = test.ix[:,'cont1':'cont14']\n",
        "lreg = LinearRegression()\n",
        "lreg.fit(train_cont,y_train1)\n",
        "y_pred = lreg.predict(X_test1)\n",
        "print(\"Training set score: {:.2f}\".format(lreg.score(train_cont, y_train1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9fe494b3-2e63-a902-01ee-1970260b7e70"
      },
      "source": [
        "The fact that a lot of features are missing implies too simple model(under fit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70659f5b-1882-e0a3-7151-9f22bcaa42d1"
      },
      "outputs": [],
      "source": [
        "#Categorical features analysis\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "catFeatures = []\n",
        "for colName in train_cat.columns:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(train_cat[colName].unique())\n",
        "    train_cat[colName] = le.transform(train_cat[colName])\n",
        "train_cat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a7e8e3b-a911-090a-5795-d8c9b95bb3f6"
      },
      "outputs": [],
      "source": [
        "catFeatures = []\n",
        "test_cat = test.ix[:,'cat1':'cat101']\n",
        "for colName in test_cat.columns:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(test_cat[colName].unique())\n",
        "    test_cat[colName] = le.transform(test_cat[colName])\n",
        "test_cat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a6aa207-ac80-e14c-a82e-ed9e4f69508d"
      },
      "outputs": [],
      "source": [
        "test_cont = test.ix[:,'cont1':'cont14']\n",
        "X_train = train_cat.ix[:,'cat1':'cat101'].join(train_cont)\n",
        "X_test = test_cat.join(test_cont)\n",
        "#verify shapes\n",
        "#Categorical features analysis using  dummy variables\n",
        "print(\"(train)(test):{}{}\".format(X_train.shape,X_test.shape))\n",
        "\n",
        "lreg.fit(X_train,y_train1)\n",
        "y_pred = lreg.predict(X_test)\n",
        "print(\"Linear: Training set score: {:.2f}\".format(lreg.score(X_train, y_train1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe79f27e-a1c4-5aa5-85f6-2f579ff9cd89"
      },
      "outputs": [],
      "source": [
        "#Categorical features analysis using  dummy variables\n",
        "train_cat_dummy = pd.get_dummies(train.ix[:,'cat1':'cat101'])\n",
        "test_cat_dummy = pd.get_dummies(test_cat)\n",
        "\n",
        "print(\"new dummy DF shapes(train)(test):{}{}\".format(train_cat_dummy.shape,test_cat_dummy.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a44f78d-a71b-385a-6963-ec23c788ff4c"
      },
      "outputs": [],
      "source": [
        "X_train = train_cat_dummy.join(train_cont)\n",
        "X_test = test_cat_dummy.join(test_cont)\n",
        "lreg.fit(X_train,y_train1)\n",
        "y_pred = lreg.predict(X_test)\n",
        "print(\"Linear: Training set score: {:.2f}\".format(lreg.score(X_train, y_train1)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "07590e4a-01e2-47ca-baf6-38e3eff00314"
      },
      "source": [
        "\"The kernel was killed for trying to exceed the memory limit of\n",
        " 8589934592; you can use the restart button in the toolbar to try.\n",
        "\"\n",
        "It looks like I have to find a way to reduce the number of features so as to reduce the memory requirement for prediction. So I randomly truncated the number of categorical features, including the first 30 gives 32% score for the training data prediction.similarly, including 80 of the categorical features  gives score of 47%, 95|49%, 101|49%,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ddd121c-a9df-0be6-87ae-16ae35f8932b"
      },
      "outputs": [],
      "source": [
        "#Other SGD regressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "reg= SGDRegressor()\n",
        "reg.fit(X_train, y_train1)\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"SGD: Training set score: {:.2f}\".format(reg.score(X_train, y_train1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6bcc3eb9-bdfd-fefb-60d9-e5f6af3a2284"
      },
      "outputs": [],
      "source": [
        "#Using Lasso\n",
        "'''from sklearn import linear_model\n",
        "reg = linear_model.Lasso(alpha = 0.6)\n",
        "reg.fit(X_train, y_train1)\n",
        "y_pred = reg.predict(X_test)\n",
        "print(\"Lasso: Training set score: {:.2f}\".format(reg.score(X_train, y_train1)))'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8af2833-cc55-d215-ab68-2432c1f77f24"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"id\": test[\"id\"],\n",
        "        \"loss\": y_pred\n",
        "    })\n",
        "submission.to_csv('sample_submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}