{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": ["import pandas as pd\n", "import numpy as np \n", "from sklearn.model_selection import cross_val_score, GridSearchCV\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.linear_model import LogisticRegression, Lasso\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n", "from sklearn.preprocessing import StandardScaler\n", "\n"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "a6b142302cee74da622ceb97009aa9c36e68f5b5"}}, {"source": "df = pd.read_csv(\"../input/creditcard.csv\")", "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "22aff22b0dff3f46c8a458deda6d4a814d66d92d", "collapsed": true}}, {"source": ["#rescale Time and Amount\n", "df['normAmount']=StandardScaler().fit_transform(df['Amount'].reshape(-1,1))\n", "df['normTime']=StandardScaler().fit_transform(df['Time'].reshape(-1,1))\n", "#Dropping the old Time and Amount columns\n", "df=df.drop(['Time','Amount'], axis=1)                                                "], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "7a7394f4e1ed2cc5f56582a30cb1b802307193bd"}}, {"source": ["entire_df=df\n", "#Undersampling\n", "fraud_count=len(df[df.Class== 1])\n", "fraud_index=df[df.Class== 1].index\n", "non_fraud_index=df[df.Class==0].index\n", "random_sample_index=np.random.choice(non_fraud_index,fraud_count,replace=False)\n", "random_sample_index=np.array(random_sample_index)\n", "under_sample_index=np.concatenate([random_sample_index,fraud_index])\n", "total_undersample_dataset=df.iloc[under_sample_index,:]\n", "y=total_undersample_dataset.Class\n", "X=total_undersample_dataset.drop('Class', 1)\n", "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.2, random_state=42)\n", "logreg=LogisticRegression()\n", "logreg.fit(X_train, y_train)\n", "modelpredict=logreg.predict(X_test)\n", "#accuracy_score(y_test, modelpredict, normalize=False)\n", "#cross validation 10 folds\n", "cv_score=cross_val_score(logreg, X_train, y_train, cv=10)\n", "\n", "print(\"Mean Cross Validation Score = \",np.mean(cv_score))\n", "print(confusion_matrix(y_test, modelpredict))\n", "print(classification_report(y_test, modelpredict))\n"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "1215ea4b31d06cdc719e54005cd5a0f0fe7cac44"}}, {"source": ["#Hyperparameter Tuning for K\n", "K_list=list(range(1,100))\n", "\n", "#create empty list\n", "cv_scores=[]\n", "\n", "#perform K search\n", "for k in K_list:\n", "    knn=KNeighborsClassifier(n_neighbors=k)\n", "    scores=cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n", "    cv_scores.append(scores.mean())\n", "    \n", "\n", "#Plotting misclassification error\n", "\n", "# changing to misclassification error\n", "MSE = [1 - x for x in cv_scores]\n", "\n", "# determining best k\n", "optimal_k = K_list[MSE.index(min(MSE))]\n", "print (\"The optimal number of neighbors is %d\" % optimal_k)\n", "\n", "# plot misclassification error vs k\n", "plt.plot(K_list, MSE)\n", "plt.xlabel('Number of Neighbors K')\n", "plt.ylabel('Misclassification Error')\n", "plt.show()\n", "\n", "#Look how the number of neighbors drastically increases the MSE rate\n", "\n", "# Try KNN to see how well it predicts fraud on the undersampled dataset\n", "knn=KNeighborsClassifier(n_neighbors=optimal_k)\n", "knn.fit(X_train, y_train)\n", "y_knn_predict=knn.predict(X_test)\n", "print (accuracy_score(y_test, y_knn_predict))\n", "print(classification_report(y_test, y_knn_predict))"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "d7885abb295172d16ebd5754367e8774467c1b36"}}, {"source": ["#applying the model trained on undersampled data to the entire dataset\n", "y_entire=entire_df.Class\n", "X_entire=entire_df.drop('Class', 1)\n", "X_train_entire, X_test_entire, y_train_entire, y_test_entire=train_test_split(X_entire, y_entire, test_size=.2, random_state=42)\n", "predict_y=logreg.predict(X_entire)\n", "print(\"Classification Report = \", classification_report(y_entire, predict_y))\n", "#cross validation\n", "cv_score_entire=cross_val_score(logreg, X_entire, y_entire, cv=10)\n", "print(\"Mean Cross Validation Score = \",np.mean(cv_score_entire))"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "6f013d786d2f68d499b4dabbf062a0bb106d642e"}}, {"source": ["#by bootstrapping the number of postive occurances target a 5:1 ratio\n", "Total_amt_pos_needed=int(len(y_entire[y_entire==0])/5)\n", "new_data_qty=Total_amt_pos_needed-len(y_entire[y_entire==1])\n", "all_y_pos_index=entire_df[entire_df.Class==1].index\n", "new_y_pos_index=np.random.choice(all_y_pos_index, new_data_qty, replace=True)\n", "new_y_pos_index=np.array(new_y_pos_index)\n", "old_y_neg_index=entire_df[entire_df.Class==0].index\n", "overfit_df_index=np.concatenate([new_y_pos_index,old_y_neg_index])\n", "new_overfit_df=entire_df.iloc[overfit_df_index,:]"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "a53693ca4663566ed0b7e2a79b1a167c9a4e40e9", "collapsed": true}}, {"source": [], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "3ac80c1540d99678f29320b1f335de08ab5c9f7f"}}, {"source": ["#creating new LR model based on the bootstrapped data\n", "logreg_2=LogisticRegression()\n", "y_overfit=new_overfit_df.Class\n", "X_overfit=new_overfit_df.drop('Class', 1)\n", "X_train_overfit, X_test_overfit, y_train_overfit, y_test_overfit=train_test_split(X_overfit, y_overfit, test_size=.2, random_state=42)\n", "logreg_2.fit(X_train_overfit, y_train_overfit)\n", "y_overfit_results=logreg_2.predict(X_test_overfit)\n", "print(\"Classification Report = \", classification_report(y_test_overfit, y_overfit_results))\n"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "d40a668e99bf6a63f9aa94c8a6896031f56f41ee"}}, {"source": ["#Trying Lasso on the features\n", "lasso=Lasso(alpha=0.4, normalize=False, random_state=42)\n", "lasso.fit(X_train, y_train)\n", "lasso_coef=lasso.coef_\n", "print(lasso_coef)"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "a15207fb15c98920db2049ec0bd03414398e8108"}}, {"source": ["#checking correlation of the features\n", "#borrowing some code for a pretty matrix\n", "\n", "sns.set(style=\"white\")\n", "\n", "# Compute the correlation matrix\n", "corr = X_train.corr()\n", "\n", "# Generate a mask for the upper triangle\n", "mask = np.zeros_like(corr, dtype=np.bool)\n", "mask[np.triu_indices_from(mask)] = True\n", "\n", "# Set up the matplotlib figure\n", "f, ax = plt.subplots(figsize=(11, 9))\n", "\n", "# Generate a custom diverging colormap\n", "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n", "\n", "# Draw the heatmap with the mask and correct aspect ratio\n", "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n", "            square=True, xticklabels=5, yticklabels=5,\n", "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n", "\n", "plt.show() \n"], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "ab8373e12305352810a0ebbdd68d5bcd25e0f01a"}}, {"source": [], "cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_uuid": "038b7f361cc3c5c9f8a601c37f9dbeaf2d37e8c4", "collapsed": true}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"name": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.1"}}}