{"cells":[{"metadata":{"_uuid":"a692e85c1c8e7eec62e6814ff91c0293f0fe8e48"},"cell_type":"markdown","source":"# Wine Ratings Explanations w/ Supervised ML\n\nThis Notebook is a follow-up of https://www.kaggle.com/olivierg13/wine-ratings-analysis-w-supervised-ml\nWe are trying to explain our RFC model, classifying wines ratings based on their descriptions, and improve it along the way.\nFor this purpose, we are going to use Lime (https://github.com/marcotcr/lime)"},{"metadata":{"_cell_guid":"8cf149aa-f703-4ca9-9235-0957bee89c2c","_uuid":"a4a0d40ad23e45c19bd22030178d1687004131ef","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Plot / Graph stuffs\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# SK learn\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# Explanations libraries\nfrom lime import lime_text\nfrom lime.lime_text import LimeTextExplainer\nfrom sklearn.pipeline import make_pipeline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31b8935465b82b80c52d016e23d1cf1b87510556"},"cell_type":"markdown","source":"# Preparing the data"},{"metadata":{"_cell_guid":"0459917c-0ee0-4755-9dfc-6425d78560c3","_uuid":"f6439bff1c7bc4b01af82499df5cde05a5dc474b","trusted":true,"collapsed":true},"cell_type":"code","source":"init_data = pd.read_csv(\"../input/winemag-data_first150k.csv\")\nprint(\"Length of dataframe before duplicates are removed:\", len(init_data))\ninit_data.head()\n\nparsed_data = init_data[init_data.duplicated('description', keep=False)]\nprint(\"Length of dataframe after duplicates are removed:\", len(parsed_data))\n\nparsed_data.dropna(subset=['description', 'points'])\nprint(\"Length of dataframe after NaNs are removed:\", len(parsed_data))\n\nparsed_data.head()\n\ndp = parsed_data[['description','points']]\ndp.info()\ndp.head()\n\n#Transform method taking points as param\ndef transform_points_simplified(points):\n    if points < 84:\n        return 1\n    elif points >= 84 and points < 88:\n        return 2 \n    elif points >= 88 and points < 92:\n        return 3 \n    elif points >= 92 and points < 96:\n        return 4 \n    else:\n        return 5\n\n#Applying transform method and assigning result to new column \"points_simplified\"\ndp = dp.assign(points_simplified = dp['points'].apply(transform_points_simplified))\ndp.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eecca88e-617c-4f1d-9ee2-810eae27bd35","_uuid":"ee9f86c916c0f27c526552820aa2d68ca4e3233b"},"cell_type":"markdown","source":"# Description Vectorization and Model Training"},{"metadata":{"_cell_guid":"587a2819-d27f-4ff5-a0b1-906abb9564a9","_uuid":"7af813051c8e74ddc529f4672059344286e36c39","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"X = dp['description']\ny = dp['points_simplified']\n\n# Vectorizing model\nvectorizer = TfidfVectorizer()\nvectorizer.fit(X)\nX = vectorizer.transform(X)\n\n# Training model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n\n# Testing model\npredictions = rfc.predict(X_test)\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d5f79f49c8d8d110ec0d8597c74dcf28f41f541"},"cell_type":"markdown","source":"# Explanation of Random Forest Classifier\n\nUsing Lime (https://github.com/marcotcr/lime), we are going to explain this Model and find what words represent the most each group.\nThis notebook will follow Lime's tutorial for text explanation: https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html"},{"metadata":{"trusted":true,"_uuid":"3b3084b96370628caeb464483d5a957aa6fb13d9","collapsed":true},"cell_type":"code","source":"# Pipeline from text to prediction\npipeline = make_pipeline(vectorizer, rfc)\n\n# LimeTextExplainer\nclass_names = ['Not Super Good', 'Average', 'Good', 'Great', 'Exceptional']\nexplainer = LimeTextExplainer(class_names = class_names)\n\nexp = explainer.explain_instance(dp['description'].iloc[0], pipeline.predict_proba, num_features=20, top_labels=1)\nprint('Probability =', pipeline.predict_proba([dp['description'].iloc[0]]))\nexp.show_in_notebook(text=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"88b8134f7a2fbc8052c4a56900e01f6162898df5"},"cell_type":"markdown","source":"# Text cleanup\n\nThanks to the explanation, we can see that TfidfVectorizer is actually not lowering some common words' weights enough: instances of unrelevant words like \"at\", \"is\", \"this\", \"the\" and \"of\" (they change depending on new trainings) are seen as explainations of a \"Great\" wine.\nLet's clean those words from our data using the stopwords collection."},{"metadata":{"trusted":true,"_uuid":"e2991b374d3dbe4f458664f2d4609d072a159bde","collapsed":true},"cell_type":"code","source":"# Stop words import for English\nfrom nltk.corpus import stopwords\nstops = set(stopwords.words(\"english\"))\n\ndef removeStopwords(x):\n    # Removing all the stopwords\n    filtered_words = [word for word in x.split() if word not in stops]\n    return \" \".join(filtered_words)\n\n# Apply to the column\nprint(dp['description'].iloc[0])\ndp['description'] = dp['description'].map(removeStopwords)\nprint(dp['description'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"200ea1699bd77d1a853e9b4fbfe5ea44e514490c"},"cell_type":"markdown","source":"Cool,  no more common words. Let's try to re-train our RFC."},{"metadata":{"trusted":true,"_uuid":"d96de522547aaa65de0349dc7f94e066a63e321e","collapsed":true},"cell_type":"code","source":"X = dp['description']\ny = dp['points_simplified']\n\n# Vectorizing model\nvectorizer = TfidfVectorizer()\nvectorizer.fit(X)\nX = vectorizer.transform(X)\n\n# Training model\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101)\nrfc = RandomForestClassifier()\nrfc.fit(X_train, y_train)\n\n# Testing model\npredictions = rfc.predict(X_test)\nprint(classification_report(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51e890280a48e61b553363809c28ce51ad08217b"},"cell_type":"markdown","source":"Let's run the explaination again:"},{"metadata":{"trusted":true,"_uuid":"7561ddb694cd99f5085841a2027c9804a95cc84a","collapsed":true},"cell_type":"code","source":"# Pipeline from text to prediction\npipeline = make_pipeline(vectorizer, rfc)\n\n# LimeTextExplainer\nclass_names = ['Not Super Good', 'Average', 'Good', 'Great', 'Exceptional']\nexplainer = LimeTextExplainer(class_names = class_names)\n\nexp = explainer.explain_instance(dp['description'].iloc[0], pipeline.predict_proba, num_features=20, top_labels=1)\nprint('Probability =', pipeline.predict_proba([dp['description'].iloc[0]]))\nexp.show_in_notebook(text=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b13bf79e1dc0182d817f9d529285423c8b1370ef"},"cell_type":"markdown","source":"# Conclusion\n\nExplaining Machine Learning Models is really useful!\n\nIn our case, we found out that TfidfVectorizer was not doing that great of a job at lowering common words weights.\nIt did not really improve our Model overall precision, but we can see that the model is more precise on an individual class now."}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}