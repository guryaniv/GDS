{"cells":[{"metadata":{"_uuid":"3d95b11b2e8b7874c5183ca8fc868082845d2eb4"},"cell_type":"markdown","source":"## Titanic Passengers Survival with XGBoost & Tuning through Hyperparameters Grid Search\n\n### Suni Kumar"},{"metadata":{"_uuid":"e0a5606f09c726c1d3b1a5974e8ee4b3e0565f2e"},"cell_type":"markdown","source":"## Import Py libs"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer\n\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73c51997490874ba4bd73c7afd406af600f641bd"},"cell_type":"markdown","source":"## Load dataset"},{"metadata":{"trusted":true,"_uuid":"9898d6a8f314cb425dcd3cc337750a94ff685019"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df  = pd.read_csv(\"../input/test.csv\")\n\n(len(train_df), len(test_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab1080fcffd1471d2b1f8c9eaf8ec9b875fd9391"},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"69b1fc9e621fca8942088c3a53bcd7ab1e277269"},"cell_type":"code","source":"# Full dataset is needed for imputing missing values & also for pruning outliers\n\ntrain_len = len(train_df)\ntitanic_df = pd.concat([train_df, test_df], axis=0, ignore_index=True, sort=True)\ntitanic_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ed50f34445d42c05ad5075923d5c50cb72f2f0a"},"cell_type":"markdown","source":"Variable Name | Description\n------------------|-------------\nPassengerId | Passenger Id (unique)\nSurvived | Survived (1) or died (0)\nPclass | Passenger's class (1/Upper, 2/Middle, 3/Lower)\nName | Passenger's Name (common Surname may be possible)\nSex | Passenger's sex (just 'male' & 'female')\nAge (20% missing values) | Passenger's age\nSibSp | Number of siblings/spouses aboard\nParch | Number of parents/children aboard\nTicket | Ticket number (many of the ticket seem to be common for a group of passengers, i.e., they are group ticket)\nFare (1 missing in 'test') | Fare\nCabin (77% missing in both 'train'& 'test') | Cabin\nEmbarked (2 missing values in 'train') | Port of embarkation"},{"metadata":{"_uuid":"9eac4d630ea01ed601d2fa0857a5190d11d48882"},"cell_type":"markdown","source":"### Imputing missing values in few variables\n\n Note that exact same imputation must be performed on both train_df & test_df using overall clues from full titanic_df  \n Variables suffering from missing observations are Age, Fare, Cabin & Embarked"},{"metadata":{"_uuid":"fda1f4b7256aced52e66f44c6888dd96ff8001f6"},"cell_type":"markdown","source":"### Imputing Embarked"},{"metadata":{"trusted":true,"_uuid":"8a19454d9ef23cb70fbbd41080990f8644d6fc82"},"cell_type":"code","source":"# Impute \"Embarked\" missing values with the most common value 'S'\n\nsns.countplot(x='Embarked', data=titanic_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd0890566eb8a29114909e9fb3c470a341fbc3e1"},"cell_type":"code","source":"titanic_df['Embarked'] = titanic_df['Embarked'].fillna(value='S')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1aba3ef576b7cc3cc4ed1cabb414e66d00b6fa30"},"cell_type":"markdown","source":"### Imputing Age"},{"metadata":{"trusted":true,"_uuid":"f485fdb51ff0f9780f34161417a047cfa53b1b61"},"cell_type":"code","source":"# Extract Title from Name, store in column and plot barplot\n\nimport re\n\ntitanic_df['Title'] = titanic_df.Name.apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n\nsns.countplot(x='Title', data=titanic_df);\nplt.xticks(rotation=45);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a68f1bcf9f43ac3d7f59d9d7530249706cd32476"},"cell_type":"code","source":"# Replace rare Title with corresponding common Title\n\ntitanic_df['Title'] = titanic_df['Title'].replace({'Mlle': 'Miss', \n                                                   'Major': 'Mr', \n                                                   'Col': 'Mr', \n                                                   'Sir': 'Mr', \n                                                   'Don': 'Mr', \n                                                   'Mme': 'Miss', \n                                                   'Jonkheer': 'Mr', \n                                                   'Lady': 'Mrs', \n                                                   'Capt': 'Mr', \n                                                   'Countess': 'Mrs', \n                                                   'Ms': 'Miss', \n                                                   'Dona': 'Mrs'})\n\nsns.countplot(x='Title', data=titanic_df);\nplt.xticks(rotation=45);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c157179fd39fdcdbdff40f2e53ca86b57b1ba4e"},"cell_type":"code","source":"# Impute \"Age\" by median of Age of Name's Title group\n\ntitles = ['Dr', 'Master', 'Miss', 'Mr', 'Mrs', 'Rev']\nfor title in titles:\n    age_to_impute = titanic_df.groupby('Title')['Age'].median()[titles.index(title)]\n    titanic_df.loc[(titanic_df['Age'].isnull()) & (titanic_df['Title'] == title), 'Age'] = age_to_impute","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"581cfb63f184f2f9c5ce3ed6890af2fbf8bfc937"},"cell_type":"markdown","source":"### Defining new feature Familial"},{"metadata":{"trusted":true,"_uuid":"0ce9f79c77f0bbe3c7c951ea43817252d4e68292"},"cell_type":"code","source":"titanic_df['Familial'] = (titanic_df['SibSp'] + titanic_df['Parch']) > 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39993594f87a42c377e6f7827e1447d312f1d47c"},"cell_type":"markdown","source":"### Imputing Fare"},{"metadata":{"trusted":true,"_uuid":"3ae263dac7f474f27bda35a0d2d3ff30dbf12295"},"cell_type":"code","source":"# Impute \"Fare\" missing value\n# Fare seem to be highly correlated to Pclass & the missing observation's Pclass is 3\n\nmedianFare = titanic_df[titanic_df['Pclass'] == 3]['Fare'].median()\ntitanic_df['Fare'] = titanic_df['Fare'].fillna(value = medianFare)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b84d45ce9b7c7cb765fe1cae0fa99e042b4a18f1"},"cell_type":"markdown","source":"### Categorizing continuous variables Age & Fare"},{"metadata":{"trusted":true,"_uuid":"fc4f62a913031ab2bd67000b4ccb0c4fa152184c","scrolled":true},"cell_type":"code","source":"# Categorize continuous variables (Age into 16, i.e., bin width is 80/16)\n\ncustom_bucket_array = np.linspace(0, 80, 17)\ntitanic_df['CatAge'] = pd.cut(titanic_df['Age'], custom_bucket_array)\nlabels, levels = pd.factorize(titanic_df['CatAge'])\ntitanic_df['CatAge'] = labels\ncustom_bucket_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb9c8b4881aa1277a5feb9f2f7df0bdbc54c6fb5"},"cell_type":"code","source":"custom_bucket_array = np.linspace(0, 520, 53)\ntitanic_df['CatFare'] = pd.cut(titanic_df['Fare'], custom_bucket_array)\nlabels, levels = pd.factorize(titanic_df['CatFare'])\ntitanic_df['CatFare'] = labels\ncustom_bucket_array","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a98f9ee891208e5c03469457e59f19fd60252d01"},"cell_type":"markdown","source":"### Categorizing string variables Sex, Ticket & Embarked"},{"metadata":{"trusted":true,"_uuid":"820c30633a2f2888e6a8d68f6bdd1fc8651bf6b9"},"cell_type":"code","source":"titanic_df['SexBool'] = titanic_df['Sex'].map({'male': 0, 'female': 1})\ntitanic_df['EmbarkedInt'] = titanic_df['Embarked'].map({'S': 0, 'C': 1, 'Q':2})\ntitanic_df['TitleInt'] = titanic_df['Title'].map({'Mr':0, 'Mrs':1, 'Miss':2, 'Master':3, 'Rev':4, 'Dr':5})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6171f1c444a0d1c299a57e8df9d03d9d3370fa87"},"cell_type":"markdown","source":"### Done with Feature Engineering => Now extract train_df & test/test_df"},{"metadata":{"trusted":true,"_uuid":"2c8740cb826d04e5d4f5b1fec041d0b19a32bce1"},"cell_type":"code","source":"# Get back the features engineered train_df & test_df\n\ntrain_df = titanic_df.loc[titanic_df['PassengerId'] <= train_len]\ntest_df = titanic_df.loc[titanic_df['PassengerId'] > train_len].iloc[:, titanic_df.columns != 'Survived']\n\n(len(train_df), len(test_df))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a6f365727da0a9b759951bd38f7df6665db8502"},"cell_type":"markdown","source":"## EDA & Features Importance Indentification, i.e., Features Selection\n\nEnsemble Learners like XGBoost can handle mutually correlated/redundant features but at the cost of so much extra iterations (n_estimators & other hyperparameters), so one can afford to ignore features selection or dimentionality reduction and recover through larger grid search space.\n"},{"metadata":{"_uuid":"7a99946e5aec22815f4eb7ea8c9bae47151fbda5"},"cell_type":"markdown","source":"### Label & Features Correlation\n* Label -vs- features strongly correlated (closer to 1.0) or anti-correlated (closer to -1.0) are useful  \n* Feature_i -vs- Feature_j correlation reveals redundancy  \n\n* Notice that Age has so poor correlation with Survived!  \n* Embarked is neihter related to Survived nor to any feature!\n\n* Familial is relatively poorly correlated with Survived, but its cross correlation with Fare & Ticket is extremely strong, hence it is indirectly represented in Model by Fare and/or Ticket... Ticket is further strongly correlated with Fare too\n\n* The most intuitive condition (Label-vs-features > 0.25) narrows down the features set to 'Pclass', 'Fare', and 'Sex_binary  \n* Observe that Age was originally sparse & its correlation with Label is very weak, but its cross correlation with Familial & Ticket  "},{"metadata":{"trusted":true,"_uuid":"08f5e0093abdd7fe99b5dced145f47d42b65e159"},"cell_type":"code","source":"# Heatmap to show Pearson Correlation of bivariate permutations\n\nplt.figure(figsize=(14,12))\nfoo = sns.heatmap(train_df.drop(['PassengerId', 'Name', 'Title', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'CatFare', 'Cabin', 'Embarked'],axis=1).corr(), vmax=0.6, square=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07aa491da28aa0622131b0b9fd96b50d9f994ef1"},"cell_type":"markdown","source":"### EDA.x: Pclass -vs- Survived\nPclass has the best correlation with Survived! The trend of survial across Pclass is different for male -vs- female Sex.\n=> Female survived even in lower Pclass(es)\n=> Male did not survive even in upper Pclass"},{"metadata":{"trusted":true,"_uuid":"04d84ab4bca4b7bb78fc710ddc85d73e224368aa"},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, figsize=(15,5))\naxs[0].set_title('female')\nsns.countplot(x='Survived', hue='Pclass', data=titanic_df.loc[titanic_df['Sex'] == 'female'], ax=axs[0])\naxs[1].set_title('male')\nsns.countplot(x='Survived', hue='Pclass', data=titanic_df.loc[titanic_df['Sex'] == 'male'], ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8768209c76b3fc01aa95f465a0d9cf61feb3e83b"},"cell_type":"markdown","source":"### EDA.x: Sex -vs- Survived\nGood correlation is observed between Sex & Survived. Obvious observation is that more females survived than males, but the root cause seems to Age + SibSp&Parch (which will become clear below)"},{"metadata":{"trusted":true,"_uuid":"dca6dfe598470fa159b231414e65f2e96c47846a"},"cell_type":"code","source":"# The Puzzle\nsns.countplot(x='Survived', hue='Sex', data=titanic_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3b46458134a3745796d84c789c9c6565e88eab5"},"cell_type":"markdown","source":"### EDA.x: Checking the survial distribution of male & female across Age bins\nNOTE that Age data availability is sparse (20% missing data), but available Age data shows a clear trend that male aged 15+ did not survive well. In fact, available Age data shows that majority of passengers were between 15-50."},{"metadata":{"trusted":true,"_uuid":"6fd910253274fd869f119a2e571e8c67b4dd7f26"},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, figsize=(15,5))\naxs[0].set_title('female')\nsns.countplot(x='CatAge', hue='Survived', data=train_df.loc[train_df['Sex'] == 'female'], ax=axs[0])\naxs[1].set_title('male')\nsns.countplot(x='CatAge', hue='Survived', data=train_df.loc[train_df['Sex'] == 'male'], ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42eabd633bad771108415893fe2d98b0be7eb383"},"cell_type":"markdown","source":"### EDA.x: Check the distribution of Survived across Familial\nThis data table shows that 60% were alone, i.e., without relatives and majority of them did not survive... 76% were male among all lone passengers\n\nSummary: Familial can be treated as boolean"},{"metadata":{"trusted":true,"_uuid":"4657897332dc259a7e31ec68791c8bfcd29e55f9"},"cell_type":"code","source":"fig, axs = plt.subplots(ncols=2, figsize=(15,5))\naxs[0].set_title('female')\nsns.countplot(x='Familial', hue='Survived', data=train_df.loc[train_df['Sex'] == 'female'], ax=axs[0])\naxs[1].set_title('male')\nsns.countplot(x='Familial', hue='Survived', data=train_df.loc[train_df['Sex'] == 'male'], ax=axs[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60e4a25fd4c6ee7cd01601f3e62c638cf7743f9c"},"cell_type":"markdown","source":"# Decision Classification using XGB and Hyperparameters Tuning through Grid Search"},{"metadata":{"_uuid":"241eb4e78131727787ccfb0a3e20cd0fc8eef7a7"},"cell_type":"markdown","source":"### Features Selection for Model Learning"},{"metadata":{"trusted":true,"_uuid":"23021a7635e8ea81d2fedcf170bc37708795f835"},"cell_type":"code","source":"# Select feature column names and target variable we are going to use for training\n# Best score with ['Pclass', 'Fare', 'Sex_binary', 'AgeCategoryIndex', 'Alone']\n\nColumns = ['SexBool', 'Pclass', 'Fare', 'CatAge', 'Familial', 'EmbarkedInt', 'TitleInt']\nLabel = 'Survived'\n\ntrain_X = train_df.loc[:, train_df.columns != 'Survived']\ntrain_y = train_df['Survived']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f20b0c4dac8ae6141ee53dca09716d5d5224ad8a"},"cell_type":"code","source":"# Instantiate XGB classifier - its hyperparameters are tuned through SkLearn Grid Search below\n\nmodel = XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1bfb76de31693bb347a8fcee599eeb7143664a1"},"cell_type":"code","source":"# Performing grid search for important hyperparameters of XGBoost\n# It has been observed that non-default value of only n_estimators is useful\n# Other hyerparameters default values are the best (learning_Rate as 0.1, max_depth as 3, alpha L1 regularizer as 0 & lambda L2 regularizer as 1)\n\nboth_scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score), 'Loss':'neg_log_loss'}\nparams = {\n        'n_estimators': [100, 200, 500, 1000, 1500],\n        'learning_rate': [0.05, 0.1, 0.2]\n        #'max_depth':[3, 4, 5]\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48b7f917a64129aa865e69ecb14a53e413a59a11"},"cell_type":"code","source":"clf = GridSearchCV(model, params, cv=5, scoring=both_scoring, refit='AUC', return_train_score=True)\nclf.fit(train_X[Columns], train_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7f2bd1dfa0dcc1211b9e0f2e3c6863bd5b46b89e"},"cell_type":"markdown","source":"### Identify Best Model, i.e., Hyperparameters"},{"metadata":{"trusted":true,"_uuid":"6489ddc1070abedec79434abb9f5b27a73f31471"},"cell_type":"code","source":"print((clf.best_score_, clf.best_params_))\nprint(\"=\"*30)\n\nprint(\"Grid scores on training data:\")\nmeans = clf.cv_results_['mean_test_AUC']\nstds = clf.cv_results_['std_test_AUC']\nlog_losses = clf.cv_results_['std_test_Loss']\n\nfor mean, std, log_loss, params in zip(means, stds, log_losses, clf.cv_results_['params']):\n    print(\"AUC Score: %0.3f (+/-%0.03f); Log Loss: %0.3f for %r\" % (mean, std * 2, log_loss, params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f9a44bcdd64a83c493dd386c0c3877f7059795d"},"cell_type":"code","source":"# If grid params permutes across multiple hyperparameters, then below plot would have many lines (n1*n2*n3..) & may look cluttered\n# Observe the best AUC & Accuracy\n\nresults = clf.cv_results_\n\nplt.figure(figsize=(13, 13))\nplt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n\nplt.xlabel(\"n_estimators: no of boosted trees\")\nplt.ylabel(\"AUC Score\")\n\nax = plt.gca()\nax.set_xlim(80, 1020)\nax.set_ylim(0.7, 1)\n\nX_axis = np.array(results['param_n_estimators'].data, dtype=float)\n\nfor scorer, color in zip(sorted(both_scoring), ['g', 'k']):\n    for sample, style in (('train', '--'), ('test', '-')):\n        sample_score_mean = results['mean_%s_%s' % (sample, scorer)]\n        sample_score_std = results['std_%s_%s' % (sample, scorer)]\n        ax.fill_between(X_axis, sample_score_mean - sample_score_std,\n                        sample_score_mean + sample_score_std,\n                        alpha=0.1 if sample == 'test' else 0, color=color)\n        ax.plot(X_axis, sample_score_mean, style, color=color,\n                alpha=1 if sample == 'test' else 0.7,\n                label=\"%s (%s)\" % (scorer, sample))\n\n    best_index = np.nonzero(results['rank_test_%s' % scorer] == 1)[0][0]\n    best_score = results['mean_test_%s' % scorer][best_index]\n\n    # Plot a dotted vertical line at the best score for that scorer marked by x\n    ax.plot([X_axis[best_index], ] * 2, [0, best_score],\n            linestyle='-.', color=color, marker='x', markeredgewidth=3, ms=8)\n\n    # Annotate the best score for that scorer\n    ax.annotate(\"%0.2f\" % best_score,\n                (X_axis[best_index], best_score + 0.005))\n\nplt.legend(loc=\"best\")\nplt.grid('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8f9def5d27e9a66996452921834da7e353fccc0"},"cell_type":"markdown","source":"### Prepare Submission CSV File"},{"metadata":{"trusted":true,"_uuid":"a82e76a6a7c47f3ba79e797bb881b8cf8179e233"},"cell_type":"code","source":"#Make predictions using the features (Columns) from test_df\n\npredictions = clf.predict(test_df[Columns]).astype(int)\n\nsubmission = pd.DataFrame({'PassengerId':test_df['PassengerId'], 'Survived':predictions})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfb15fadefc558a446dd06d2f50ea2c6a1f10165"},"cell_type":"code","source":"# Fill submission csv file\nfilename = 'submit.csv'\nsubmission.to_csv(filename,index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9fe4edb05700c4c2ba114fe93e0a2041c3d8da5"},"cell_type":"markdown","source":"## Appendix"},{"metadata":{"trusted":true,"_uuid":"c4954c68cf40278da5e72d022b323b0c0106986c"},"cell_type":"code","source":"### EDA.x Extreme Fare which could possibly be outlier\n'''\n# 4 passengers with Fare > 512.0 of which 1 are from test_df (passenger id 1235)\n# All on same Ticket 'PC 17755' => hence pid 1235 can be predicted as SURVIVED\n\n# 17 passengers with Fare < 1.0 of which 2 are from test_df (passenger id 1158 on Ticket_112051 & 1264 on Ticket_112058)\n# Both these passengers can be predicted as DIED\n\n# TODO: Manual row append to 'submission' dataframe needs to be fixed\n#titanic_df = titanic_df.loc[(titanic_df['Fare'] > 1.0) & (titanic_df['Fare'] < 512.0)]\n#titanic_df = titanic_df.loc[titanic_df['Fare'] < 512.0]\n\n# manual row append needs to be fixed... If we prune Fare > 512.0 which consists of 4 observations (3 train & 1 test), then below prediction must be manually added\n#submission = submission.append({1235: 1}, ignore_index=True)\n#sideEntryPrediction = [1235, 1]\n#submission.loc[len(submission)] = sideEntryPrediction\n#submission = submission.astype(int)\n#submission.sort_values(by=['PassengerId','Survived'], ascending=True,inplace=True)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"813bd9df38ad39e71d24d9e05d2b629a9198845d"},"cell_type":"code","source":"### EDA.x: Though not useful... Survival trend among passengers on unique Ticket -vs- common/group Ticket appeared to be quite visible, hence \n# tried to split full dataset into Grouped & Single\n#\n# test/test_df (97 on group ticket -vs- 321 on single ticket)\n# train_df (344 on group ticket -vs- 547 on single ticket)\n\n# train_df has 344 passengers on Group Ticket\n#Survived  0.0  1.0\n#Sex               \n#female     47  133\n#male      118   46\n\n# trainf_df has 547 passengers with Single Ticket\n#Survived  0.0  1.0\n#Sex               \n#female     34  100\n#male      350   63\n\n'''\ntrainTktCount = train_df.groupby(\"Ticket\")[\"Ticket\"].transform(len)\nmaskGroupTrain = (trainTktCount > 1)\ntrainGrouped_df = train_df[maskGroupTrain]\n(len(trainGrouped_df), len(trainSingle_df), len(holdoutGrouped_df), len(holdoutSingle_df))\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51d41c8fcc8c999651c76bc2d73d6a6c5b492af9"},"cell_type":"code","source":"### EDA.x: Checking if child & aged people were accompanied by relatives or were they vulnerable\n#Below 2 data tables clearly shows that there was NO IMPACT of Vulnerable on Suvived\n'''def is_vulnerable(passenger):\n    Age, SibSp, Parch = passenger\n    if (((Age < 18) or (Age > 60)) and (SibSp+Parch == 0)):\n        return 'vulnerable'\n    else:\n        return 'safe'\n\ntrain_df['Vulnerable'] = train_df[['Age', 'SibSp', 'Parch']].apply(is_vulnerable, axis=1)\n\ntab = pd.crosstab(train_df['Vulnerable'], train_df['AgeCategory'])\ntab.iloc[:,:]'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a9320c153388448e860c8969ac00068ba5f160e"},"cell_type":"markdown","source":"### References\n1. [[Approach to impute missing values in Age using Name's Title](http://https://www.kaggle.com/jamesleslie/titanic-random-forrest-use-title-to-impute-age)](http://)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}