{"nbformat": 4, "metadata": {"language_info": {"version": "3.6.3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"metadata": {"_cell_guid": "cf40190e-4ebf-4a2e-8e5b-1d30164f9c74", "_uuid": "e73e536b1c5b44bfe0015cfdb2e4d031d6d4cbeb"}, "cell_type": "markdown", "source": ["## Overview\n", "Let's say you know the mean and standard deviation of a population. How can you tell if a sample is from this population or some other population? Although we may never know with 100% certainty, we can look for statistically significant differences between the sample statistics and the population paramters. This is done by first stating what is refered to as a null hypothesis, which in this scenario would be that there is no difference between the sample mean and the population mean. Then we look for statistical evidence to accept or reject the null hypothesis. What if we don't know the population parameters? After this notebook you will know:\n", "* how to formulate a null hypothesis and alternative hypothesis for comparing a sample mean to a population mean.\n", "* how to conduct a z-test using the z-statistic for the sample mean to gain statistical evidence to accept or reject the null hypothesis.\n", "* how to one-sample, paired sample, and independent sample t-tests when the population standard deviation is unknown and must be estimated using the sample standard deviation.\n", "\n", "There is a terrific set of tutorials on using SPSS to do hypothesis testing at [this Kent State University website](https://libguides.library.kent.edu/SPSS)."]}, {"metadata": {"_cell_guid": "b3296b0c-eb2f-4886-b54b-4a8cd12dbdd7", "_uuid": "c070713f2c711df50418f4137e60055b12dab7ab"}, "cell_type": "markdown", "source": ["The following cell will import the WineEnthusiast data set using pandas. The data is linked to above and is formated as a CSV (comma-separated-values) file. Such a file could be opend in Excel but here we simply load the file into a pandas data structure called a dataframe and print out the first couple rows of the dataframe."]}, {"metadata": {"collapsed": true, "_cell_guid": "bf24efc1-e20f-4817-bd72-52ebe0ca96a0", "_uuid": "eb3e15689e95e9c1118ec39a48b2497af59e3b23"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import scipy.stats as stats # some useful stuff\n", "wine_data = pd.read_csv(\"../input/winemag-data-130k-v2.csv\")"]}, {"metadata": {"_cell_guid": "6947b130-e149-44f0-bb45-f36a88787ce0", "_uuid": "3f5284503c71ef3b19997b3f9a30d20b82ca657f"}, "cell_type": "markdown", "source": ["## Is A Sample of Wine Scores From the Wine Enthusiast Population\n", "Let's assume the WineEnthusiast point scores are interval-scaled normally distributed data. Let's find the population mean and population standard deviation."]}, {"metadata": {"_cell_guid": "57c02446-664b-4cf6-a66a-1b3c2395e2dc", "_uuid": "134fb568bab52c074dc9e7c10f3d67f5c3184a56"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["points = wine_data['points']\n", "mu = points.mean()\n", "sigma = points.std(ddof=0)\n", "print(\"mu: \", mu, \", sigma:\", sigma)"]}, {"metadata": {"_cell_guid": "0c4b6d09-6a40-45b5-afc4-171a97caef7d", "_uuid": "92d2b57b008367b44cd18fb59db9581b0da201ae"}, "cell_type": "markdown", "source": ["A sample of N=10 wine point scores yields a sample mean of x_bar = 90.2. Is this sample from the WineEnthusiast population? To test this question we will use what is refered to as a one-sample z-test. First we state the null hypothesis and alternative hypothesis like this;\n", "* H<sub>0</sub>: The sample is from the WineEnthusiast population, x_bar = &mu;.\n", "* H<sub>A</sub>: The sample is not from the WineEnthusiast population, x_bar != (not equal) &mu;.\n", "\n", "Then, we specify a significance (alpha) level. Usually, statistical significance is associated with an alpha level of &alpha; = 0.05 or smaller. Next, we use a [z table](http://www.stat.ufl.edu/~athienit/Tables/Ztable.pdf) to look up the critical z value that cooresponds to this &alpha; level. Here we are doing a two-tailed test because we don't care if the sample mean is greater than or less than the population mean. We just are testing to see if the two are equal or notl (see the alternative hypothesis above). Next we calculate the z-statitic for the sample mean compared to the population mean dividing by the standard deviation of the sample mean, which is the standard error &sigma;/sqrt(N). If this z-statistic is less than z-critical then we accept the null hypothesis, otherwise we reject the null and accept the alternative hypothesis. Let's do it."]}, {"metadata": {"_cell_guid": "d4bb2a08-fe1d-4653-8d24-019911dcd7bb", "_uuid": "025faf9721bde2a423a7dc279bd435b74233f47f"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["z_critical = 1.96 # alpha level of 0.05 and two-tailed test\n", "x_bar = 90.2\n", "N = 10\n", "SE = sigma/np.sqrt(N)\n", "z_stat = (x_bar - mu)/SE\n", "print(z_stat)"]}, {"metadata": {"_cell_guid": "5fa95660-43e2-4848-b758-b914919865a9", "_uuid": "49395110a1332f8a83c39d928d2b431f79a69b7a"}, "cell_type": "markdown", "source": ["Since z_stat is less than z_critical we accept the null hypothesis and reject the althernative. Statistically, we say the sample mean is no different than the population mean and thus the sample is drawn from the population. But what if the sample size was larger? Let's redo the calculation with N=30."]}, {"metadata": {"_cell_guid": "94724d01-8468-459d-88c2-f812a053ecca", "_uuid": "223f6e27a6c146c4c0bbed8391bdeae95a0b6797"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["N = 30;\n", "SE = sigma/np.sqrt(N)\n", "z_stat = (x_bar - mu)/SE\n", "print(z_stat)"]}, {"metadata": {"_cell_guid": "c827c5cc-bc66-460e-b920-1320f71f942e", "_uuid": "679d215e20614e326f2b57f5d9d616b6d42288e1"}, "cell_type": "markdown", "source": ["Now the z-statistic is greater than z-critical and we reject the null hypothesis. Statistically speaking we say that this sample was drawn from some different population than the WineEnthusiast population. Why the difference? As you can see mathematically, increasing the sample size decreases the standard error of the sample mean. This means the distribution of sample means becomes narrower as N gets larger and thus it is less likely to overlap with the population mean everything else being equal."]}, {"metadata": {"collapsed": true, "_cell_guid": "a870ca15-2539-4ee0-a02f-3bbfc58dd2cb", "_uuid": "c68730a7d4f4fb2ff3c9b9d230ca6f3678b89e5c"}, "cell_type": "markdown", "source": ["## T-Tests\n", "Around 1900, a chemist and statistical wizard named William Sealy Gosset who went by the pen name Student worked for the Guiness Brewery in Ireland. in his mission to use science to make better beer, he noticed that in situations where the population standard deviation is unknown (most situations), it can be estimated using the sample standard deviation (using the unbiased version normalized by N-1). But, if the sample size is small (let's say less than 30 is small) the shape of the distribution of sample means has thicker tails than a normal distribution because there is more variability in the estimate of the standard deviation of the sample mean (the standard error), which itself depends on the sample size. Thus, the z-test is unreliable because z-values are determend using a normal distribuiton. Instead, we must draw our test statistic from a different distribution called the t-distribution. The shape of this distribution narrows and becomes more normal like and the sample size increases or degrees of freedom increases, where degrees of freedom is N-1. Thus, Student's t-test is conducted in a fashion similar to a z-test but the t-statistic is pulled from a different distribution and thus a different table. **The t-statistic itself has a similar form to the z-statistic in that it is a ration of a deviation divided by a measure of variability.** However, the exact for of the ratio for the t-statistic depends on the nature of the data being used. Next I'll show you how to apply Student's t-test to various experimental scenarios."]}, {"metadata": {"_cell_guid": "d3aaab21-ec70-40e2-963a-02bc45957a73", "_uuid": "12dd5dd0c498a151b4d672f224881296ceb75719"}, "cell_type": "markdown", "source": ["## Framework for Statistical Hypothesis Testing with T-Tests\n", "* Do you have one sample that you want to compare to some spcified value? Do a **one-sample t-test**. For example, let's say it is well known that acorns have an average mass of 10 g, and you want to test to see if them mass of acorns from a forest subjected to acid rain are signifcantly different. \n", "* Do you have two independent samples that you want to compare to each other? Do an **independent samples t-test**. For example, let's say you take samples of acorn from a forest upwind and downwind from a coal power plant and you want to test to see if the average mass of the acorns from the two samples is the same.\n", "* Do you have two dependent samples taken from the same indidividuals or objects? Do a **paired samples t-test**. For example, let's say you measure the average mass of acorns from 50 trees in a forest before and after the local power plant converted from coal to natural gas and want to see if there is a difference in the masses pre-conversion to post-conversion. "]}, {"metadata": {"_cell_guid": "4befc072-c910-4ba4-900f-e0fbd7717bc1", "_uuid": "2f1ee61b048b9a4d1e686b9479bb52417682e7c8"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["x = np.random.normal(loc=9.2,scale=1.5,size=30).round(1)\n", "print(x)"]}, {"metadata": {"_cell_guid": "9b9566bb-e9b5-4b48-9b45-0194167d2b2b", "_uuid": "6256e72b89e829fc8583163418120a3e50aaa156"}, "cell_type": "markdown", "source": ["## One-sample location test on whether the mean of a population is equal to a value specified in null hypothesis\n", "\n", "The mass of a sample of N=20 acorns from a forest subjected to acid rain from a coal power plant are m = 8.8, 6.6, 9.5, 11.2, 10.2, 7.4, 8.0, 9.6, 9.9, 9.0, 7.6, 7.4, 10.4, 11.1, 8.5, 10.0, 11.6, 10.7, 10.3, and 7.0 g. Is the average mass of this sample different from the average mass of all acorns of &mu; = 10.0 g?\n", "\n", "* H<sub>0</sub>: x&#772; - &mu; = 0, that is there is no difference between my sample mean and the value of &mu;.\n", "* H<sub>a</sub>: x&#772; - &mu; &ne; 0 (two-sided test)\n", "* &alpha; = 0.05\n", "\n", "[t-table](http://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf)\n", "* degrees of freedom: d<sub>f</sub> = N-1\n", "* t-critical for specified alpha level: t<sub>*</sub> = 2.093\n", "* t-statistic: t = (x&#772; - &mu;)/(s/sqrt(N)) where s is the sample standard deviation.\n"]}, {"metadata": {"scrolled": true, "_cell_guid": "4148d56b-fa5a-4e96-b67c-1e57bccf6417", "_uuid": "763af9076a0089015fc6d5d85c17e344b50b5a48"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["x = [8.8, 6.6, 9.5, 11.2, 10.2, 7.4, 8.0, 9.6, 9.9, 9.0,\n", "     7.6, 7.4, 10.4, 11.1, 8.5, 10.0, 11.6, 10.7, 10.3, 7.0]\n", "mu = 10\n", "t_critical = 2.093\n", "x_bar = np.array(x).mean()\n", "s = np.array(x).std(ddof=1) # subtract 1 from N to get unbiased estimate of sample standard deviation\n", "N = len(x)\n", "SE = s/np.sqrt(N)\n", "t = (x_bar - mu)/SE\n", "print(\"t-statistic: \",t)\n", "\n", "# a one sample t-test that gives you the p-value too can be done with scipy as follows:\n", "t, p = stats.ttest_1samp(x, mu)\n", "print(\"t = \", t, \", p = \", p)"]}, {"metadata": {"_cell_guid": "b2894e2f-f2ab-4004-af72-0cbaa592d286", "_uuid": "662933c050f5d099e89102fa8779f69d1f3ac8b2"}, "cell_type": "markdown", "source": ["Note that t is greater in magnitude that t<sub>*</sub> so there is a statistically significant difference at the &alpha; = 0.05 level between the sample mean and the stated population mean of 10 g. Note that statistical signficance doesn mean the effect is large. Let's report the 95% confidence intervals too.. "]}, {"metadata": {"_cell_guid": "a77658d4-df97-429c-a8cc-f4b0c22a7716", "_uuid": "48295f9db014374bc05c3e8055921a11bd4a0504"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# margin of error\n", "err = t_critical*SE\n", "x_low = x_bar - err\n", "x_high = x_bar + err\n", "print(\"x_bar = {}, 95% CI [{}, {}]\".format(x_bar.round(2), x_low.round(2), x_high.round(2)))\n", "\n", "# you can also get CIs by using the build int t-distribution function like this:\n", "print(\"CI using scipy: \",stats.t.interval(0.95, N-1, loc=x_bar, scale=SE))"]}, {"metadata": {"_cell_guid": "fd17fd23-4f92-403e-aada-0b61433b22e9", "_uuid": "948240552a9daac38010e7ec652d02adbdfab6f7"}, "cell_type": "markdown", "source": ["## Independent (unpaird) two-sample location test with a null hypothesis that the means of the two samples are equal (equal variance assued).\n", "The mass of N<sub>1</sub>=20 acorns from oak trees up wind from a coal power plant and N<sub>2</sub>=30 acorns from oak trees down wind from the same coal power plant are mesured. Are the acorns from trees downwind less massive then the ones from up wind? This will require a one-tail (on the low/left side) test. The sample sizes are not equal but we will assume that the population variance of sample 1 and sample 2 are equal. If we don't make the assumption of equal variance then we do a Welch's t-test.\n", "\n", "* H<sub>0</sub>: x&#772;<sub>1</sub> = x&#772;<sub>2</sub>, or x&#772;<sub>2</sub> - x&#772;<sub>1</sub> = 0, that is , there is no difference between the sample means\n", "* H<sub>A</sub>: x&#772;<sub>2</sub> < x&#772;<sub>1</sub>, or x&#772;<sub>2</sub> - x&#772;<sub>1</sub> < 0\n", "* &alpha; = 0.05\n", "\n", "[t-table](http://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf)\n", "* degrees of freedom: d<sub>f1</sub>= N<sub>1</sub>-1 = 19, d<sub>f2</sub>= N<sub>2</sub>-1 = 29, d<sub>f</sub> = d<sub>f1</sub> + d<sub>f2</sub> = N<sub>1</sub> + N<sub>2</sub> - 2 = 48\n", "\n", "* t-critical for specified alpha level: t<sub>*</sub> = -1.677 (one-tailed, left-side)\n", "* t-statistic: t = (x&#772;<sub>2</sub> - x&#772;<sub>1</sub>)/(s<sub>p</sub> sqrt(1/N<sub>1</sub> + 1/N<sub>2</sub>)))\n", "* pooled variance: s<sub>p</sub> = sqrt( ((d<sub>1</sub>) s<sub>1</sub><sup>2</sup> + (d<sub>2</sub>) s<sub>2</sub><sup>2</sup>)) / d<sub>f</sub> )\n"]}, {"metadata": {"_cell_guid": "f2b15c98-92e0-4f2b-90e1-beb62cc3ae03", "_uuid": "fa96a81f7f2ca3b6cb195dd0e0c087b8d30b348b"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# sample up wind\n", "x1 = [10.8, 10.0, 8.2, 9.9, 11.6, 10.1, 11.3, 10.3, 10.7, 9.7, \n", "      7.8, 9.6, 9.7, 11.6, 10.3, 9.8, 12.3, 11.0, 10.4, 10.4]\n", "\n", "# sample down wind\n", "x2 = [7.8, 7.5, 9.5, 11.7, 8.1, 8.8, 8.8, 7.7, 9.7, 7.0, \n", "      9.0, 9.7, 11.3, 8.7, 8.8, 10.9, 10.3, 9.6, 8.4, 6.6,\n", "      7.2, 7.6, 11.5, 6.6, 8.6, 10.5, 8.4, 8.5, 10.2, 9.2]\n", "\n", "# equal sample size and assume equal population variance\n", "t_critical = 1.677\n", "N1 = len(x1)\n", "N2 = len(x2)\n", "d1 = N1-1\n", "d2 = N2-1\n", "df = d1+d2\n", "s1 = np.std(x1,ddof=1)\n", "s2 = np.std(x2,ddof=1)\n", "x1_bar = np.mean(x1)\n", "x2_bar = np.mean(x2)\n", "\n", "sp = np.sqrt((d1*s1**2 + d2*s2**2)/df)\n", "se = sp*np.sqrt(1/N1 + 1/N2)\n", "t = (x2_bar - x1_bar)/(se)\n", "print(\"t-statistic\", t)\n", "\n", "# a two-sample independent t-test is done with scipy as follows\n", "# NOTE: the p-value given is two-sided so the one-sided p value would be p/2\n", "t, p_twosided = stats.ttest_ind(x2, x1, equal_var=True)\n", "print(\"t = \",t, \", p_twosided = \", p_twosided, \", p_onesided =\", p_twosided/2)"]}, {"metadata": {"_cell_guid": "9fa7e955-2b68-4bb4-bd4a-d8bf115fc8c7", "_uuid": "4b3d56e4e2609e33a4ed094371fea1df67855ecf"}, "cell_type": "markdown", "source": ["## Estimating Effect Size\n", "Since the t-statistic above is less than t-critical, the null is rejected and the alternative hypothesis is accepted. Just because there is a statistically significant difference betwee the two samples doesn't necessaily mean the differene is meaningful. Let's calculate the 95% confidence interval and a measure of effect size, Cohen's d.. \n", "* Cohen's d, d = (mean deviation) / (pooled standard deviation) = (x&#772;<sub>2</sub> - x&#772;<sub>1</sub>) / s<sub>p</sub>\n", "\n", "We can also calculate a correlation of determination r<sup>2</sup> which represents the fraction of the variance in the data explained by the sample  it belongs to. \n", "\n", "* Coefficient of determination, r<sup>2</sup> = t<sup>2</sup> / ( t<sup>2</sup> + df )"]}, {"metadata": {"_cell_guid": "131e8a07-45f9-4ebf-8f6b-472bd32af34d", "_uuid": "e791ba38b62fa34d1a41030620ca1b95840f90cf"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["print(\"Confidence Interval:\")\n", "print(\"x2_bar - x1_bar = \", x2_bar - x1_bar, \", 95% CI \",stats.t.interval(0.95, df, loc=x2_bar-x1_bar, scale=se))\n", "print(\"Cohen's Effect Size, d:\")\n", "print(\"d = \", (x2_bar - x1_bar)/sp)\n", "\n", "rsq = t**2 / (t**2 + df)\n", "print(\"r_squared = \", rsq) # 34.5 % of the variation between samples can be explained by the switch to nat. gas\n", "\n", "# notice that the r_squared value above is equal to the r_squared value you would get from linear regression\n", "x = np.concatenate((np.ones(N1), np.ones(N2)*2))\n", "y = np.concatenate((x1,x2))\n", "\n", "slope, yint, r, p, sterr = stats.linregress(x, y)\n", "print(\"r_squared = \",r**2)\n", "\n", "plt.plot(x,y)\n", "plt.show()"]}, {"metadata": {"collapsed": true, "_cell_guid": "9b5d97b5-9c0c-4a45-b333-36d3bdeecdcc", "_uuid": "8520e337989f942369ad861e6aebece17394efe3"}, "cell_type": "markdown", "source": ["## Paired samples (dependent/repeated measures) t-test with a null hypothesis that the mean difference is a specified constant (usually zero).\n", "The average mass of acorns from the same N=30 trees downwind of a power plant is measured before (x<sub>1</sub>) and after (x<sub>2</sub>) the power plant converts from burning coal to buring natural gas. Does the mass of the acorns increase after the conversion from coal to natural gas? This will require a one-tail (on the low/left side) test.\n", "\n", "* H<sub>0</sub>: x&#772;<sub>2</sub> - x&#772;<sub>1</sub> = 0, that is , there is no difference between the sample means\n", "* H<sub>A</sub>: x&#772;<sub>2</sub> - x&#772;<sub>1</sub> > 0\n", "* &alpha; = 0.05\n", "\n", "[t-table](http://www.sjsu.edu/faculty/gerstman/StatPrimer/t-table.pdf)\n", "* degrees of freedom: d<sub>f</sub> = N-1 = 29\n", "* t-critical for specified alpha level: t<sub>*</sub> = 1.677 (one-tailed, right-side)\n", "* t-statistic: t = (x&#772;<sub>diff</sub> - 0)/(s<sub>diff</sub> / sqrt(N))\n", "* standard deviation of difference: s<sub>d</sub> = sqrt(s<sub>1</sub><sup>2</sup>/N<sub>1</sub> + s<sub>2</sub><sup>2</sup>/N<sub>2</sub>)\n", "* mean difference: x&#772;<sub>diff</sub> = x&#772;<sub>2</sub> - x&#772;<sub>1</sub>"]}, {"metadata": {"_cell_guid": "d5690fde-4d81-4f50-93c0-cad681140c71", "_uuid": "a256d0a2cc6426f642854fc66a63dd146d37bcf7"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# sample before conversion to nat. gas\n", "x1 = np.array([10.8, 6.4, 8.3, 7.6, 11.4, 9.9, 10.6, 8.7, 8.1, 10.9,\n", "      11.0, 11.8, 7.3, 9.6, 9.3, 9.9, 9.0, 9.5, 10.6, 10.3,\n", "      8.8, 12.3, 8.9, 10.5, 11.6, 7.6, 8.9, 10.4, 10.2, 8.8])\n", "# sample after conversion to nat. gas\n", "x2 = np.array([10.1, 6.9, 8.6, 8.8, 12.1, 11.3, 12.4, 9.3, 9.3, 10.8,\n", "      12.4, 11.5, 7.4, 10.0, 11.1, 10.6, 9.4, 9.5, 10.0, 10.0,\n", "      9.7, 13.5, 9.6, 11.6, 11.7, 7.9, 8.6, 10.8, 9.5, 9.6])\n", "N = len(x2)\n", "xbar_diff = np.mean(x2) - np.mean(x1) # could also do np.mean(x2 - x1))\n", "sdiff = np.std(x2-x1,ddof=1)\n", "t = xbar_diff / (sdiff/np.sqrt(N))\n", "print(\"t = \", t)\n", "\n", "t, p = stats.ttest_rel(x2, x1) # using scipy\n", "print(\"t = \", t, \", p = \", p/2) # divide by two because we are doing a one-tail test\n", "\n", "d = xbar_diff / sdiff\n", "print(\"d = \", d) # chohen's d"]}, {"metadata": {"collapsed": true, "_cell_guid": "10cca2fc-bc78-46b0-a4b5-4e3908c90617", "_uuid": "86737f8db76a51ca47d2aa570f81af414eaf712f"}, "cell_type": "markdown", "source": ["So, there is a statistically significant difference between the two samples at the &alpha; = 0.05 level. \n", "\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": []}], "nbformat_minor": 1}