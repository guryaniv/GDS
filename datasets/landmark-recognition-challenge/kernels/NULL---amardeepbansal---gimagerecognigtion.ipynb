{"cells":[{"metadata":{"_uuid":"9e9f913a0b75541471c32aa5aad6bbda42ecac19","_cell_guid":"0561eddc-0d4a-47e0-82ea-e365d002d462"},"cell_type":"markdown","source":"# Introduction\nThe project is used to label famous (and not-so-famous) landmarks in images.This Kernel explore the **train** and **test** datasets from [Google Landmark Recognition Challenge](https://www.kaggle.com/c/landmark-recognition-challenge). \n\nPlease feel free to **fork and further develop** this Kernel. \n\n![Google Landmark Challenge](https://lh3.googleusercontent.com/-3KCpDLA4tl0/V_xSEMwVIsI/AAAAAAAADXg/m6O0bgTtcDAPaXYn96U1x07E_gEvLuDGgCOcB/s1600/\n)\n\n**Load Libraries**"},{"metadata":{"collapsed":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import Image\nfrom IPython.core.display import HTML \nfrom PIL import Image\nfrom PIL.ExifTags import TAGS, GPSTAGS\nfrom urllib import request\nfrom io import BytesIO\n# io related\nfrom skimage.io import imread\nimport os\nfrom glob import glob\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"f75a7650e59b62b3c722dde40ab839baf5dd396b","_cell_guid":"d97cd03e-4c2a-4549-9796-e80f1299bfc4"},"cell_type":"markdown","source":"**Read Data **"},{"metadata":{"collapsed":true,"_uuid":"baa1debf883b04abc36d834abd4330777b9588e9","_cell_guid":"cec379d9-7208-4715-ba46-5ae0dd13b8de","trusted":true},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n# Read the data\ntrain_d = pd.read_csv(\"../input/train.csv\")\ntest_d = pd.read_csv(\"../input/test.csv\")\nsubmission = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"fbb2d934bd2051e990a5a519d3bea830cc3726b3","_cell_guid":"7292117e-d3fd-46c8-84c8-b12bff5a7594"},"cell_type":"markdown","source":"**Inspect Data** "},{"metadata":{"_uuid":"fb752fed803c5490a904ca2c42ef0622903f2c5f","_cell_guid":"042b8df4-c563-4d95-8777-2be18bf65e65"},"cell_type":"markdown","source":"**Data shape**"},{"metadata":{"_uuid":"fe8c173a1333cece3720069c353669212cca4600","_cell_guid":"3c2b6847-c363-482a-a990-dae1c194ce6a","trusted":true},"cell_type":"code","source":"print(\"Train data size -  rows:\",train_d.shape[0],\" columns:\", train_d.shape[1])\nprint(\"Test data size -  rows:\",test_d.shape[0],\" columns:\", test_d.shape[1])\nprint(\"Submission data size -  rows:\",submission.shape[0],\" columns:\", submission.shape[1])","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"2967bb7c0f80aff26d0a191f623197e2d7978d8d","_cell_guid":"87332934-c515-4fec-8d77-37fc59b35ecd"},"cell_type":"markdown","source":"**Glimpse the data**"},{"metadata":{"_uuid":"ed94e71836ea359a48a4511e19817a8f93552c1b","_cell_guid":"df64dcf5-b6bc-44a4-bb5b-d89f36892179"},"cell_type":"markdown","source":"Let's inspect the train and test sets"},{"metadata":{"_uuid":"7945d1768a3b27a2d3d50b5d0ce2af9a4d54ad9a","_cell_guid":"39800fab-296c-4534-895e-586335ba99e1","trusted":true},"cell_type":"code","source":"train_d.head()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"b3752da1ba1746e84bcf5cdd7a7acee97436bd0e","_cell_guid":"4e4a09cf-b4f8-4496-bd7e-5e7d6966acf7"},"cell_type":"markdown","source":"Train set has three columns, first being an id for the image, the second being an url for the image and the third the id of the landmark associated with the image."},{"metadata":{"_uuid":"f3123e10df8c8ea6ada9d714f89135516d8a5fd4","_cell_guid":"5580eb35-554a-4e08-8870-031a7ed1523a","trusted":true},"cell_type":"code","source":"test_d.head()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"210e3c232a85dffd4e2239747736cc8dac2efec1","_cell_guid":"fd72a221-ab76-42fc-bddb-75ae87264c17"},"cell_type":"markdown","source":"Test set has two columns, first being an id for the image, the second being an url for the image. Let's see now the expected format for the submission file."},{"metadata":{"_uuid":"a9020a1a44be6d08d8238bcc0ab6e1d1fe704ccb","_cell_guid":"69ffc2aa-0905-4019-a0a4-f0a8a92ad927","trusted":true},"cell_type":"code","source":"submission.head()","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"c113e86e7d6ea5c249e7205058cdf0b4bb097cd3","_cell_guid":"5a2e3b69-0cdc-4165-8574-140cd60efb29"},"cell_type":"markdown","source":"Submission has two columns, first being an id for the image, the second being the landmark. This has two elements: an landmark id that is associated with the image and its corresponding confidence score. Some query images may contain no landmarks. For these, one can submit no landmark id (and no confidence score).\n\n**Data quality** : Let's look into more details to the data quality\n\n**Train data quality** : Let's see if we do have missing values in the training set"},{"metadata":{"_uuid":"9c6ed784370d763fc05ea43c270bb17d46e88382","_cell_guid":"50105a37-d4ca-4055-8784-610aa32df67a","trusted":true},"cell_type":"code","source":"# missing data in training data set - missingt1 refers to missing values in train dataset\nmissingt1 = train_d.isnull().sum()\nall_val = train_d.count()\n\nmissing_train_d = pd.concat([missingt1, all_val], axis=1, keys=['Missing', 'All'])\nmissing_train_d","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"bc5cc069fd2b8966953c958aee6d5d1e237bfc75","_cell_guid":"d9a43969-67d0-45a4-a590-2ae15aa9ce79"},"cell_type":"markdown","source":"We see that we do not have any missing values (null values) in the training data\n\n**Test data quality** : Let's see if we do have missing values in the test set"},{"metadata":{"_uuid":"618660d21c01342bd6b647738f08a47e28c57b77","_cell_guid":"8c753509-dc57-404f-abe3-2771ab137a11","trusted":true},"cell_type":"code","source":"# missing data in training data set - missingt2 refers to missing values in test dataset\nmissingt2 = test_d.isnull().sum()\nall_val = test_d.count()\n\nmissing_test_d = pd.concat([missingt2, all_val], axis=1, keys=['Missing', 'All'])\nmissing_test_d","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"54c6d4832bd8b374bc6ac82cdf28f04e9a889e06","_cell_guid":"1e7d0c2d-1037-4aba-a472-03b4cbefe039"},"cell_type":"markdown","source":"We can see that we do not have any missing values (null values) in the test data\n\n**Unique values** : Let's inspect the train and test data to check now many unique values are"},{"metadata":{"_uuid":"538309f38f5864e823d2dff8cba0edd91c640ce9","_cell_guid":"ac08ee9c-5934-4abd-90d3-c0a4ac45214b","trusted":true},"cell_type":"code","source":"train_d.nunique()","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"acd250fa0b789e9c49cebf08ebc1b4f5b556a533","_cell_guid":"0cf55660-4948-40c6-a624-2495a6b5c230"},"cell_type":"markdown","source":"In the train dataset, there are only 14951 unique landmark_id data. All id's and url's are unique.Let's see now the test data to check now many unique values are"},{"metadata":{"_uuid":"1bcf68ee01c1985adbde6ef8f5690c6a2b5c6789","_cell_guid":"86d57533-d4ec-4090-a069-1c18795c3ab4","trusted":true},"cell_type":"code","source":"test_d.nunique()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"e045885ee70ce0afc022578f1f41971d42b4732d","_cell_guid":"88c601b4-ba2f-4e9f-8400-bddffb2570a4"},"cell_type":"markdown","source":"All id's and url's are unique in the test data as well. Let's now check if we do have any id's or url's that are in both train and test set."},{"metadata":{"_uuid":"5062db1a3bed46c231b5726c15f9ce2728c4f996","_cell_guid":"63b5338e-b87d-4e8c-a69d-b1373621e2f2","trusted":true},"cell_type":"code","source":"# concatenate train and test datasets\nconcatenated = pd.concat([train_d, test_d])\n# print the shape of the resulted data.frame\nconcatenated.shape","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"2eea22244e82a43c08d4abaf41e52a924795f4ca","_cell_guid":"1f6ac0f6-4149-4692-a6a0-fe7849949f0b","trusted":true},"cell_type":"code","source":"concatenated.nunique()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"50788a8e3cdc34015b49a5e736e44e9385172da2","_cell_guid":"7eaf4775-b85b-4458-bc3f-d232a191614c"},"cell_type":"markdown","source":"All id's and url's are unique for the concatenated data. That means we do not have any id's or url's from train dataset leaked in the test data set as well.\n\n**Landmarks** : We already know how many distincts landmarks there are in the train set. Let's inspect now how many occurences are for these landscapes in the train set."},{"metadata":{"_uuid":"d8b39253c3a3c88391a0edf64cea20fbcafb3457","_cell_guid":"61baf2b2-396f-497f-93a0-6025589e3c36","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (25,9))\nplt.title('Landmark id density plot')\nsns.kdeplot(train_d['landmark_id'], color=\"tomato\", shade=True)\nplt.show()","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"30cf1c6de1196900d46a87c0908563c7dce27ed1","_cell_guid":"a43296f2-31fe-4316-a658-0d98f654a421"},"cell_type":"markdown","source":"Let's represent the same data as a density plot"},{"metadata":{"_uuid":"ca3d7ca895cd3afccc9fd976cf8145fd0f206d44","_cell_guid":"fda32290-bbbc-47c8-b7b1-2cfd476264b8","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (25, 9))\nplt.title('Landmark id distribuition and density plot')\nsns.distplot(train_d['landmark_id'],color='blue', kde=True,bins=75)\nplt.show()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"e30ce787cf9519ea6993a732bb467c193c844b7e","_cell_guid":"38a5920c-116e-4e51-9fbb-292e4e55597b"},"cell_type":"markdown","source":"** To ignore the warnings**"},{"metadata":{"collapsed":true,"_uuid":"5778fdc52a7486d4e1646cc05bec09fa4fde299e","_cell_guid":"f17acd02-9e56-4e18-bb13-e05d9cfe1bd2","trusted":true},"cell_type":"code","source":"import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\nwarnings.filterwarnings(\"ignore\")","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"c6ba05daae3fe3f73ad0d29963308671c30cad10","_cell_guid":"7c1db74d-e2a4-456b-9911-a1803e72cef1"},"cell_type":"markdown","source":"**To print Histogram**"},{"metadata":{"_uuid":"1403534c089142916de2a870493c89faaa6d70db","_cell_guid":"bb7febc4-d81c-484d-96bc-23d6dcbfae6b","trusted":true},"cell_type":"code","source":"train_d['landmark_id'].value_counts().hist()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"8d36a9373e30691ddaf2f35868a2888475d245ed","_cell_guid":"63da922f-e515-4d26-8298-434cd58986dd"},"cell_type":"markdown","source":"Let's look now to the most frequent landmarks in the train set and also to the least frequent landmarks.\n# Occurance of landmark_id in decreasing order(Top categories)"},{"metadata":{"_uuid":"487ae27604d501fd6017ca32100a811c4eca08c9","_cell_guid":"2d8933a4-71b4-42fb-b92c-bf103d9d9f4a","trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(train_d.landmark_id.value_counts().head(25))\ntemp.reset_index(inplace=True)\ntemp.columns = ['landmark_id','count']\ntemp","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"6f2c0b76a2e76a2ea6995371e30cdb1cb1565e11","_cell_guid":"68d1f580-f974-4828-b517-446c6ecf3a5f"},"cell_type":"markdown","source":"# Plot the most frequent landmark_ids count is 25"},{"metadata":{"_uuid":"26cd35249f4fac9e72f5aebaa912317b61f35839","_cell_guid":"cbc12d0c-25bf-457f-a2d6-cf158ecea304","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 16))\nplt.title('Top 25 landmarks in train.csv data ')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp,\n            label=\"Count\")\nplt.show()","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"d3014b855aacc84b68194c9640f98dc50115caa2","_cell_guid":"924a0f94-aa01-4d31-9db4-73b3e61f261f","trusted":true},"cell_type":"code","source":"# Occurance of landmark_id in increasing order\ntemp1 = pd.DataFrame(train_d.landmark_id.value_counts().tail(25))\ntemp1.reset_index(inplace=True)\ntemp1.columns = ['landmark_id','count']\ntemp1","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"20371e640d7bb3607dfc80d36b8bcd7f3c89ba41","_cell_guid":"f2523b9c-8f2d-451f-a6bd-111f54005e2f"},"cell_type":"markdown","source":"# Plot the least frequent landmark_ids count is 25"},{"metadata":{"_uuid":"3ece1de66d3acbd6c451e604919ec1448d0ff947","_cell_guid":"3a6ac8e4-ccd5-4f77-9c42-15d9c091babe","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 16))\nplt.title('Last 25 landmarks in train.csv dataset')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"landmark_id\", y=\"count\", data=temp1,\n            label=\"Count\")\nplt.show()","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"5cabb89c82f1c8b11afa6e53e93561128ce03b8b","_cell_guid":"3da858d8-d7e0-491c-8484-7fb0b53436f3"},"cell_type":"markdown","source":"#Class distribution"},{"metadata":{"_uuid":"6726033f91e9f6218863dbeae3d110569fde55aa","_cell_guid":"1a7fa82b-d35c-45b4-9869-40191b0adb4f","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 16))\nplt.title('Category Distribuition')\nsns.distplot(train_d['landmark_id'])\n\nplt.show()","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"a8c2d2c3f5d99dad43f884b435b155f8e203a615","_cell_guid":"24f2f85c-9d0a-4731-80cc-f2083ef01c76"},"cell_type":"markdown","source":"**Image Thumbnails **\nLet's inspect also the images. We create a function to display a certain number of images, giving a list of images urls. We show here a number of `50` images of the `Pantheon` in Rome, which is the 5th ranged landmark in the selection of landmarks, based on number of occurences. We will define two functions to display landmarks."},{"metadata":{"collapsed":true,"_uuid":"48ec8fbbb11ba0d84788ec9800464bb423a31c52","_cell_guid":"b7745662-f256-42d8-b291-c993bc5a02bf","trusted":true},"cell_type":"code","source":"def displayLandmarkImages(urls):\n    \n    imageStyle = \"height: 60px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' />\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))\n    \n    \ndef displayLandmarkImagesLarge(urls):\n    \n    imageStyle = \"height: 100px; margin: 2px; float: left; border: 1px solid blue;\"\n    imagesList = ''.join([f\"<img style='{imageStyle}' src='{u}' />\" for _, u in urls.iteritems()])\n\n    display(HTML(imagesList))","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"2df8f1146dd55f3a36576cb658ead90f252f0cde","_cell_guid":"223ce654-e87c-4cf1-9b7d-93a6a4dc32e9","trusted":true},"cell_type":"code","source":"IMAGES_NUMBER = 50\nlandmarkId = train_d['landmark_id'].value_counts().keys()[9]\nurls = train_d[train_d['landmark_id'] == landmarkId]['url'].head(IMAGES_NUMBER)\ndisplayLandmarkImages(urls)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"3014fc0547f1a3c42eabb7514ee67fc7b9f35e7f","_cell_guid":"3af45aa7-bfc5-4193-aadb-b7c1dd662ec8"},"cell_type":"markdown","source":"Let's visualize now 5 images for each of the first 8 landmarks, ordered by the number of occurences."},{"metadata":{"_uuid":"aa70f399188906875e00d5176ac72c498d1f707f","_cell_guid":"5fac07af-42d4-4e19-912b-b3117a1d46e0","trusted":true},"cell_type":"code","source":"LANDMARK_NUMBER = 5\nIMAGES_NUMBER = 8\nlandMarkIDs = pd.Series(train_d['landmark_id'].value_counts().keys())[1:LANDMARK_NUMBER+1]\nfor landMarkID in landMarkIDs:\n    url = train_d[train_d['landmark_id'] == landMarkID]['url'].head(IMAGES_NUMBER)\n    displayLandmarkImagesLarge(url)","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"fa49357c666c3d33eb073997f02be97e424d2d8f","_cell_guid":"ca990495-0324-4cd8-9d82-be612a64a31f"},"cell_type":"markdown","source":"If we change key value in Keys() we will get different images every time in dataset "},{"metadata":{"_uuid":"73b2f1eda90d61ef60252343778cfa9e6a9028c4","_cell_guid":"fc38e0c2-f442-4a63-9ef1-6dd40dd7b0f6","trusted":true},"cell_type":"code","source":"from IPython.display import Image\nfrom IPython.core.display import HTML \n\ndef display_category(urls, category_name):\n    img_style = \"width: 180px; margin: 0px; float: right; border: 1px solid black;\"\n    images_list = ''.join([f\"<img style='{img_style}' src='{u}' />\" for _, u in urls.head(25).iteritems()])\n    display(HTML(images_list))\n\ncategory = train_d['landmark_id'].value_counts().keys()[2018]\nurls = train_d[train_d['landmark_id'] == category]['url']\ndisplay_category(urls, \"\")","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"f1c3c227dfdb9e0a7765c34dbc5e98888c89132e","_cell_guid":"151adac1-09f2-4168-92d0-f1b5830f3492"},"cell_type":"markdown","source":"**Baseline Submission** : We are using a random guess, normalized by the frequency in the training set to prepare a submission file.The solution is picked up from Kevin Mader's Kernel, `Baseline Landmark Model`."},{"metadata":{"collapsed":true,"_uuid":"8075c37e7610655a38124520d49c1a58fedc7d1b","_cell_guid":"f85eeb04-4f5b-4b56-b2a6-e308ef9218f2","trusted":true},"cell_type":"code","source":"# take the most frequent label\nfreq_label = train_d['landmark_id'].value_counts()/train_d['landmark_id'].value_counts().sum()","execution_count":26,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7cb892e8d1d50095d46ca7ce0af73010cf603f05","_cell_guid":"35f45794-4d0a-4a25-aa40-d1672b4110c1","trusted":true},"cell_type":"code","source":"# submit the most freq label\nsubmission['landmarks'] = '%d %2.2f' % (freq_label.index[0], freq_label.values[0])\nsubmission.to_csv('submission.csv', index=False)","execution_count":27,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8d24dd9a8b788d4da852e91062eac9175a0930d0","_cell_guid":"ca4f8ca6-dd0a-4921-b7e5-6f607cb1608e","trusted":true},"cell_type":"code","source":"np.random.seed(2018)\nr_idx = lambda : np.random.choice(freq_label.index, p = freq_label.values)","execution_count":28,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fc2a205a7b4d926fec82a02df67c543ffb3abcc1","_cell_guid":"8c4de566-23f6-4ec5-b076-709e1c1e8bab","trusted":true},"cell_type":"code","source":"r_score = lambda idx: '%d %2.4f' % (freq_label.index[idx], freq_label.values[idx])\nsubmission['landmarks'] = submission.id.map(lambda _: r_score(r_idx()))\nsubmission.to_csv('rand_submission.csv', index=False)","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"b9b1ced64bb46dc4cf1f152cf41b64d6a1ef9114","_cell_guid":"69ebb852-92ec-4991-8401-c376e6fca3eb","trusted":true},"cell_type":"code","source":"# Now Lets extract the website name and see their occurances\n\n# Extract site_names for train data\ntemp_l1 = list()\nfor path in train_d['url']:\n    temp_l1.append((path.split('//', 1)[1]).split('/', 1)[0])\ntrain_d['site_name'] = temp_l1\n\n# Extract site_names for test data\ntemp_l1 = list()\nfor path in test_d['url']:\n    temp_l1.append((path.split('//', 1)[1]).split('/', 1)[0])\ntest_d['site_name'] = temp_l1\n\n#We have added one new column \"site_name\".lets see\nprint(\"Training data size\",train_d.shape)\nprint(\"test data size\",test_d.shape)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"9786c3fca285cf5d21ae8c4d796773e5be5eb22a","_cell_guid":"74265782-a174-49bd-8fe7-bf47aa0ae7be","trusted":true},"cell_type":"code","source":"# New columns added to existing dataset\ntrain_d.head()","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"d61bef8ce71c47d19c5235c0f11ec399748ca277","_cell_guid":"f5451088-1610-4b9f-a134-324b7d819ee7","trusted":true},"cell_type":"code","source":"#New column in existing test data \ntest_d.head()","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"13d470c5fe45e3aa9e8f704a565f3c1c024f5f14","_cell_guid":"d252150a-bd5f-46bd-8662-9333bf5e3bfc","trusted":true},"cell_type":"code","source":"#In this we are creating a duplicate table to drop column url in train dataset\ntrain_d1 = train_d\ntrain_d1.head()","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"9920cff397afc6d027c2519883979e0bceacd9f4","_cell_guid":"c847fabf-6ce8-472f-ac90-e0dad1f70dd7","trusted":true},"cell_type":"code","source":"# url column is dropped in train dataset\ntrain_d1 = train_d1.drop('url',1) \ntrain_d1.head()","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"ba85fe937884c3432ec26d52931f75e3d88ef848","_cell_guid":"0a96b301-be46-4137-9626-195ff734f05a","trusted":true},"cell_type":"code","source":"# Occurance of site in decreasing order(Top categories) in train dataset\ntemp = pd.DataFrame(train_d1.site_name.value_counts())\ntemp.reset_index(inplace=True)\ntemp.columns = ['site_name','count']\ntemp","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"53efbdd123c04760407818f5d299877c789b7fdb","_cell_guid":"da394ed3-759a-4a00-bb2d-41c6469de5af","trusted":true},"cell_type":"code","source":"#As we can see there are total 16 unique sites.\n# Plot the Sites with their count\nplt.figure(figsize = (16, 16))\nplt.title('Sites with their count')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"site_name\", y=\"count\", data=temp,\n            label=\"Count\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","execution_count":36,"outputs":[]},{"metadata":{"_uuid":"baf9c71a95bac9ce2e3bdbc910a7fb8ce1f9f6e9","_cell_guid":"7675af6c-32cd-4c3d-a479-c94e47b20fa9","trusted":true},"cell_type":"code","source":"#In this we are creating a duplicate table to drop column url in test dataset\ntest_d1 = test_d\ntest_d1.head()","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"e23bbf9f00de60fed62eb17b6f75507a2e6e5565","_cell_guid":"80361205-835e-4ca9-a357-703c9d838505","trusted":true},"cell_type":"code","source":"# url column is dropped in train dataset\ntest_d1 = test_d1.drop('url',1)\ntest_d1.head()","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"b5ed7b9cb67f260cb58a26ba64d96512a3afa748","_cell_guid":"544e4c43-1147-4573-9bcd-111e206957c9","trusted":true},"cell_type":"code","source":"#occurances of sites in test_data\n# Occurance of site in decreasing order(Top categories)\ntemp = pd.DataFrame(test_d.site_name.value_counts())\ntemp.reset_index(inplace=True)\ntemp.columns = ['site_name','count']\ntemp","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"3ff9a2dc9b241483cad5f5c7d030a6eb52176b57","_cell_guid":"fd4571a0-a79d-4b7b-91ad-ccb2aef776ca","trusted":true},"cell_type":"code","source":"#Total unique sites are 25 in test data and some are different from train_data\n# Plot the Sites with their count\nplt.figure(figsize = (16, 16))\nplt.title('Sites with their count')\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"site_name\", y=\"count\", data=temp,\n            label=\"Count\")\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=90)\nplt.show()","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"9397dd49d68a6e02dbe17cdbdba72ef64eff8b92","_cell_guid":"42316ccd-b62c-4aaf-93e2-10f3ce61d17a","trusted":true},"cell_type":"code","source":"train_d2 = train_d # Dataset with site_name column\ntest_d2 = test_d # Dataset with site_name column\ntrain_d2.head()","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"d349434503420087978072263fdb141a0b0bd178","_cell_guid":"1a70b8ef-28f8-4c19-8872-06d28769f4e3","trusted":true},"cell_type":"code","source":"test_d2.head()","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"145a6b07f9277f066edb00d99b1776dd775b64f0","_cell_guid":"050fead1-1724-474d-84b4-ccaa2ae3ebcc","trusted":true},"cell_type":"code","source":"# To drop site_name column in train dataset this the original dataset for reference\ntrain_d2 = train_d2.drop('site_name',1)\ntrain_d2.head()","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"12dc878da4e5b8e4f8af842df7ffc384c668d4b4","_cell_guid":"b52a6edc-92d7-4616-a367-ed0e58d46567","trusted":true},"cell_type":"code","source":"# To drop site_name column in test dataset this the original dataset for reference\ntest_d2 = test_d2.drop('site_name',1)\ntest_d2.head()","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"abe635fe3d2708e1bc50509293bafaafc5559dc0"},"cell_type":"markdown","source":"**Random Guessing**"},{"metadata":{"trusted":true,"_uuid":"6a5b17186a201a86fd9f8080d1845cf634c5142e"},"cell_type":"code","source":"import pylab as pl\npl.seed = 0\nN = 1500\nprobs = train_d.landmark_id.value_counts() / train_d.shape[0]\nprobs = probs.iloc[:N]\nprobs = pd.DataFrame({'landmark_id': probs.index,\n                      'probability': probs.values}, index=pl.arange(N))\nT = pd.merge(train_d, probs, on='landmark_id', how='outer')\ninx = pl.randint(0, T.shape[0], submission.shape[0])\nsubmission['landmark_id'] = T.landmark_id.iloc[inx].values\nsubmission['prob'] = T.probability.iloc[inx].values\nsubmission['landmarks'] = submission.landmark_id.astype(str) + ' ' + submission.prob.astype(str)\nsubmission[['id','landmarks']].head()\nsubmission[['id','landmarks']].to_csv('submission_inner.csv', index=False)","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e91450053dc71b165b8006a7c64be347fb7e24c2"},"cell_type":"code","source":"import pylab as pl\npl.seed = 0\nN = 1500\nprobs = train_d.landmark_id.value_counts() / train_d.shape[0]\nprobs = probs.iloc[:N]\nprobs = pd.DataFrame({'landmark_id': probs.index,\n                      'probability': probs.values}, index=pl.arange(N))\nT = pd.merge(train_d, probs, on='landmark_id', how='inner')\ninx = pl.randint(0, T.shape[0], submission.shape[0])\nsubmission['landmark_id'] = T.landmark_id.iloc[inx].values\nsubmission['prob'] = T.probability.iloc[inx].values\nsubmission['landmarks'] = submission.landmark_id.astype(str) + ' ' + submission.prob.astype(str)\nsubmission[['id','landmarks']].head()\nsubmission[['id','landmarks']].to_csv('submission_outer.csv', index=False)","execution_count":50,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2261e2073cce364d4f3e7a5f2b3d46410f27e03a"},"cell_type":"code","source":"","execution_count":52,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ef5e401e1462bfcaf1c69f2760deb70f7632476e","_cell_guid":"ac1ee6cb-8823-4e87-96c4-aa11482c7b9d"},"cell_type":"markdown","source":"**Feedback requested **\n\nYour suggestions and comments for improvement of this Kernel are much appreciated. And, of course, if you like it,** upvote!**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}