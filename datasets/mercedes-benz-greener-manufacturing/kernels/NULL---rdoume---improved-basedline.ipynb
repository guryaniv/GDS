{"nbformat_minor": 0, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "version": "3.6.0", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python"}}, "nbformat": 4, "cells": [{"source": "## This is a testing version of some Improvement and ideas regarding this competitions. ", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "idle", "_uuid": "6399b86470f1d71ea58294e5643d4a047d5fab4f"}, "cell_type": "markdown", "outputs": []}, {"execution_count": null, "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\n\n# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n", "cell_type": "code", "metadata": {"_execution_state": "idle", "_uuid": "49f126044300995868ba6828a03d4d2bc7769ea1"}, "outputs": []}, {"source": "Here is the classical features that can be found in many baseline kernels\n------------------------------------------------------------------------", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "idle", "_uuid": "03173da935f59fd16ba728442d59bff8925987ec"}, "cell_type": "markdown", "outputs": []}, {"source": "\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n\n\n##Add decomposed components: PCA / ICA etc.\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.decomposition import TruncatedSVD\nn_comp = 12\n\n# tSVD\ntsvd = TruncatedSVD(n_components=n_comp, random_state=420)\ntsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\ntsvd_results_test = tsvd.transform(test)\n\n# PCA\npca = PCA(n_components=n_comp, random_state=420)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\npca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=420)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\n\n# GRP\ngrp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\ngrp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\ngrp_results_test = grp.transform(test)\n\n# SRP\nsrp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\nsrp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\nsrp_results_test = srp.transform(test)\n\n# Append decomposition components to datasets\n\n", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "a7ffb59414962946f3b1a08a7f0eea3a8a667aae"}, "cell_type": "code", "outputs": []}, {"source": "from sklearn.cluster import KMeans\nkm=KMeans(n_clusters=n_comp, random_state=420)\nkm_train = km.fit_transform(train.drop([\"y\"],axis=1))\nkm_test=km.transform(test)\nprint(km_train.shape)", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "60debedc29beddb6d39273e5834d2dbccde5e347"}, "cell_type": "code", "outputs": []}, {"source": "*Exploring this \"magic feature\"*", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "idle", "_uuid": "135f4074498b6881609ac0fd90dd8cb9c03e242d"}, "cell_type": "markdown", "outputs": []}, {"source": "mean_x0 = train[['X0', 'y']].groupby(['X0'], as_index=False).median()\nmean_x0.columns = ['X0', 'mean_x0']\n\ntrain = pd.merge(train, mean_x0, on='X0', how='outer')\n\nmean_x1 = train[['X1', 'y']].groupby(['X1'], as_index=False).median()\nmean_x1.columns = ['X1', 'mean_x1']\n\ntrain = pd.merge(train, mean_x1, on='X1', how='outer')\n\nmean_x2 = train[['X2', 'y']].groupby(['X2'], as_index=False).median()\nmean_x2.columns = ['X2', 'mean_x2']\n\ntrain = pd.merge(train, mean_x2, on='X2', how='outer')\n\nmean_x3 = train[['X3', 'y']].groupby(['X3'], as_index=False).median()\nmean_x3.columns = ['X3', 'mean_x3']\n\ntrain = pd.merge(train, mean_x3, on='X3', how='outer')\n\nmean_x4 = train[['X4', 'y']].groupby(['X4'], as_index=False).median()\nmean_x4.columns = ['X4', 'mean_x4']\n\ntrain = pd.merge(train, mean_x4, on='X4', how='outer')\n\nmean_x5 = train[['X5', 'y']].groupby(['X5'], as_index=False).median()\nmean_x5.columns = ['X5', 'mean_x5']\n\ntrain = pd.merge(train, mean_x5, on='X5', how='outer')\n\nmean_x6 = train[['X6', 'y']].groupby(['X6'], as_index=False).median()\nmean_x6.columns = ['X6', 'mean_x6']\n\ntrain = pd.merge(train, mean_x6, on='X6', how='outer')\n\nmean_x8 = train[['X8', 'y']].groupby(['X8'], as_index=False).median()\nmean_x8.columns = ['X8', 'mean_x8']\n\ntrain = pd.merge(train, mean_x8, on='X8', how='outer')\n\ntrain.head(100)\ntest = pd.merge(test, mean_x0, on='X0', how='left')\n\ntest['mean_x0'].fillna(test['mean_x0'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x1, on='X1', how='left')\n\ntest['mean_x1'].fillna(test['mean_x1'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x2, on='X2', how='left')\n\ntest['mean_x2'].fillna(test['mean_x2'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x3, on='X3', how='left')\n\ntest['mean_x3'].fillna(test['mean_x3'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x4, on='X4', how='left')\n\ntest['mean_x4'].fillna(test['mean_x4'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x5, on='X5', how='left')\n\ntest['mean_x5'].fillna(test['mean_x5'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x6, on='X6', how='left')\n\ntest['mean_x6'].fillna(test['mean_x6'].dropna().median(), inplace=True)\n\ntest = pd.merge(test, mean_x8, on='X8', how='left')\n\ntest['mean_x8'].fillna(test['mean_x8'].dropna().median(), inplace=True)\n\ntest.head(1)", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "169386cced1e8995678db7df62f8fbf852516919"}, "cell_type": "code", "outputs": []}, {"source": "for i in range(1, n_comp+1):\n    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n    \n    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n\n    train['tsvd_' + str(i)] = tsvd_results_train[:,i-1]\n    test['tsvd_' + str(i)] = tsvd_results_test[:, i-1]\n    \n    train['grp_' + str(i)] = grp_results_train[:,i-1]\n    test['grp_' + str(i)] = grp_results_test[:, i-1]\n    \n    train['srp_' + str(i)] = srp_results_train[:,i-1]\n    test['srp_' + str(i)] = srp_results_test[:, i-1]\n    \n    train['km_'+str(i)]=km_train[:,i-1]\n    test['km_'+str(i)]=km_test[:,i-1]\n\n", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "146e5a6c7dee60740a6eb7b5bd102703678c53e0"}, "cell_type": "code", "outputs": []}, {"source": "\n\ny_train = train[\"y\"]\ny_mean = np.mean(y_train)\n\n\n\n### Regressor\nimport xgboost as xgb\n\n# prepare dict of params for xgboost to run with\nxgb_params = {\n    'n_trees': 520, \n    'eta': 0.0045,\n    'max_depth': 4,\n    'subsample': 0.93,\n    'objective': 'reg:linear',\n    'base_score': y_mean, # base prediction = mean(target)\n    'silent': 1\n}\n\n# form DMatrices for Xgboost training\ndtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\ndtest = xgb.DMatrix(test)\n\n\nnum_boost_rounds = 1250\n# train model\nfrom sklearn.metrics import r2_score\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds,feval=r2_score,maximize=True)\n\n\n# check f2-score (to get higher score - increase num_boost_round in previous cell)\nfrom sklearn.metrics import r2_score\nprint(r2_score(dtrain.get_label(),model.predict(dtrain)))\n", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "baa1704c5cd716a4f66ea51d3fe7c0df7ace4d9e"}, "cell_type": "code", "outputs": []}, {"source": "\n# make predictions and save results\ny_pred = model.predict(dtest)\n\noutput = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\noutput.to_csv('submission.csv', index=False)", "execution_count": null, "metadata": {"collapsed": false, "_execution_state": "busy", "_uuid": "f4a23e3217eda7a25cfe76d40fe07e439dc48ebf"}, "cell_type": "code", "outputs": []}]}