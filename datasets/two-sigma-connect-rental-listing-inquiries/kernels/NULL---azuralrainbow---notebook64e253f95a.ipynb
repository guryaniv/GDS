{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "313a02e2-0a3f-3c41-7ee7-d8d12b1adda5"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import random\n",
        "from math import exp\n",
        "import xgboost as xgb\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e574f96c-d4d4-fb7e-377b-c021138002f6"
      },
      "outputs": [],
      "source": [
        "random.seed(321)\n",
        "np.random.seed(321)\n",
        "\n",
        "X_train = pd.read_json(\"../input/train.json\")\n",
        "X_test = pd.read_json(\"../input/test.json\")\n",
        "\n",
        "interest_level_map = {'low': 0, 'medium': 1, 'high': 2}\n",
        "X_train['interest_level'] = X_train['interest_level'].apply(lambda x: interest_level_map[x])\n",
        "X_test['interest_level'] = -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4ac622b-6748-0a68-9163-65a8f17ec91e"
      },
      "outputs": [],
      "source": [
        "#add features\n",
        "feature_transform = CountVectorizer(stop_words='english', max_features=150)\n",
        "X_train['features'] = X_train[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\n",
        "X_test['features'] = X_test[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.lower().split(\" \")) for i in x]))\n",
        "feature_transform.fit(list(X_train['features']) + list(X_test['features']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6187c7af-578b-3588-7eeb-1184782d733e"
      },
      "outputs": [],
      "source": [
        "train_size = len(X_train)\n",
        "low_count = len(X_train[X_train['interest_level'] == 0])\n",
        "medium_count = len(X_train[X_train['interest_level'] == 1])\n",
        "high_count = len(X_train[X_train['interest_level'] == 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6298ce7-ed3f-675e-81d0-06b5bc249a56"
      },
      "outputs": [],
      "source": [
        "#find some features that only appears once (Why?)\n",
        "def find_objects_with_only_one_record(feature_name):\n",
        "    temp = pd.concat([X_train[feature_name].reset_index(), \n",
        "                      X_test[feature_name].reset_index()])\n",
        "    temp = temp.groupby(feature_name, as_index = False).count()\n",
        "    return temp[temp['index'] == 1]\n",
        "\n",
        "managers_with_one_lot = find_objects_with_only_one_record('manager_id')\n",
        "buildings_with_one_lot = find_objects_with_only_one_record('building_id')\n",
        "addresses_with_one_lot = find_objects_with_only_one_record('display_address')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7f7a741-998d-c9b8-ce81-e3a8826104ae"
      },
      "outputs": [],
      "source": [
        "lambda_val = None\n",
        "k=5.0\n",
        "f=1.0\n",
        "r_k=0.01 \n",
        "g = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d044700b-a595-3b6b-0f08-779407d9252c"
      },
      "outputs": [],
      "source": [
        "def categorical_average(variable, y, pred_0, feature_name):\n",
        "    def calculate_average(sub1, sub2):\n",
        "        s = pd.DataFrame(data = {\n",
        "                                 variable: sub1.groupby(variable, as_index = False).count()[variable],                              \n",
        "                                 'sumy': sub1.groupby(variable, as_index = False).sum()['y'],\n",
        "                                 'avgY': sub1.groupby(variable, as_index = False).mean()['y'],\n",
        "                                 'cnt': sub1.groupby(variable, as_index = False).count()['y']\n",
        "                                 })\n",
        "                                 \n",
        "        tmp = sub2.merge(s.reset_index(), how='left', left_on=variable, right_on=variable) \n",
        "        del tmp['index']                       \n",
        "        tmp.loc[pd.isnull(tmp['cnt']), 'cnt'] = 0.0\n",
        "        tmp.loc[pd.isnull(tmp['cnt']), 'sumy'] = 0.0\n",
        "\n",
        "        def compute_beta(row):\n",
        "            cnt = row['cnt'] if row['cnt'] < 200 else float('inf')\n",
        "            return 1.0 / (g + exp((cnt - k) / f))\n",
        "            \n",
        "        if lambda_val is not None:\n",
        "            tmp['beta'] = lambda_val\n",
        "        else:\n",
        "            tmp['beta'] = tmp.apply(compute_beta, axis = 1)\n",
        "            \n",
        "        tmp['adj_avg'] = tmp.apply(lambda row: (1.0 - row['beta']) * row['avgY'] + row['beta'] * row['pred_0'],\n",
        "                                   axis = 1)\n",
        "                                   \n",
        "        tmp.loc[pd.isnull(tmp['avgY']), 'avgY'] = tmp.loc[pd.isnull(tmp['avgY']), 'pred_0']\n",
        "        tmp.loc[pd.isnull(tmp['adj_avg']), 'adj_avg'] = tmp.loc[pd.isnull(tmp['adj_avg']), 'pred_0']\n",
        "        tmp['random'] = np.random.uniform(size = len(tmp))\n",
        "        tmp['adj_avg'] = tmp.apply(lambda row: row['adj_avg'] *(1 + (row['random'] - 0.5) * r_k),\n",
        "                                   axis = 1)\n",
        "    \n",
        "        return tmp['adj_avg'].ravel()\n",
        "     \n",
        "    #cv for training set \n",
        "    k_fold = StratifiedKFold(5)\n",
        "    X_train[feature_name] = -999 \n",
        "    for (train_index, cv_index) in k_fold.split(np.zeros(len(X_train)),\n",
        "                                                X_train['interest_level'].ravel()):\n",
        "        sub = pd.DataFrame(data = {variable: X_train[variable],\n",
        "                                   'y': X_train[y],\n",
        "                                   'pred_0': X_train[pred_0]})\n",
        "            \n",
        "        sub1 = sub.iloc[train_index]        \n",
        "        sub2 = sub.iloc[cv_index]\n",
        "        \n",
        "        X_train.loc[cv_index, feature_name] = calculate_average(sub1, sub2)\n",
        "    \n",
        "    #for test set\n",
        "    sub1 = pd.DataFrame(data = {variable: X_train[variable],\n",
        "                                'y': X_train[y],\n",
        "                                'pred_0': X_train[pred_0]})\n",
        "    sub2 = pd.DataFrame(data = {variable: X_test[variable],\n",
        "                                'y': X_test[y],\n",
        "                                'pred_0': X_test[pred_0]})\n",
        "    X_test.loc[:, feature_name] = calculate_average(sub1, sub2)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7883fef4-cf63-7547-c6b1-55d66431beba"
      },
      "outputs": [],
      "source": [
        "def transform_data(X):\n",
        "    #add features    \n",
        "    feat_sparse = feature_transform.transform(X[\"features\"])\n",
        "    vocabulary = feature_transform.vocabulary_\n",
        "    del X['features']\n",
        "    X1 = pd.DataFrame([ pd.Series(feat_sparse[i].toarray().ravel()) for i in np.arange(feat_sparse.shape[0]) ])\n",
        "    X1.columns = list(sorted(vocabulary.keys()))\n",
        "    X = pd.concat([X.reset_index(), X1.reset_index()], axis = 1)\n",
        "    del X['index']\n",
        "    \n",
        "    X[\"num_photos\"] = X[\"photos\"].apply(len)\n",
        "    X['created'] = pd.to_datetime(X[\"created\"])\n",
        "    X[\"num_description_words\"] = X[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
        "    X['price_per_bed'] = X['price'] / X['bedrooms']    \n",
        "    X['price_per_bath'] = X['price'] / X['bathrooms']\n",
        "    X['price_per_room'] = X['price'] / (X['bathrooms'] + X['bedrooms'] )\n",
        "    \n",
        "    X['low'] = 0\n",
        "    X.loc[X['interest_level'] == 0, 'low'] = 1\n",
        "    X['medium'] = 0\n",
        "    X.loc[X['interest_level'] == 1, 'medium'] = 1\n",
        "    X['high'] = 0\n",
        "    X.loc[X['interest_level'] == 2, 'high'] = 1\n",
        "    \n",
        "    X['display_address'] = X['display_address'].apply(lambda x: x.lower().strip())\n",
        "    X['street_address'] = X['street_address'].apply(lambda x: x.lower().strip())\n",
        "    \n",
        "    X['pred0_low'] = low_count * 1.0 / train_size\n",
        "    X['pred0_medium'] = medium_count * 1.0 / train_size\n",
        "    X['pred0_high'] = high_count * 1.0 / train_size\n",
        "\n",
        "    #interesting????!\n",
        "    X.loc[X['manager_id'].isin(managers_with_one_lot['manager_id'].ravel()), \n",
        "          'manager_id'] = \"-1\"\n",
        "    X.loc[X['building_id'].isin(buildings_with_one_lot['building_id'].ravel()), \n",
        "          'building_id'] = \"-1\"\n",
        "    X.loc[X['display_address'].isin(addresses_with_one_lot['display_address'].ravel()), \n",
        "          'display_address'] = \"-1\"\n",
        "          \n",
        "    return X\n",
        "\n",
        "def normalize_high_cordiality_data():\n",
        "    high_cardinality = [\"building_id\"]\n",
        "    for c in high_cardinality:\n",
        "        categorical_average(c, \"medium\", \"pred0_medium\", c + \"_mean_medium\")\n",
        "        categorical_average(c, \"high\", \"pred0_high\", c + \"_mean_high\")\n",
        "\n",
        "def transform_categorical_data():\n",
        "    categorical = ['building_id', 'manager_id', \n",
        "                   'display_address', 'street_address']\n",
        "                   \n",
        "    for f in categorical:\n",
        "        encoder = LabelEncoder()\n",
        "        encoder.fit(list(X_train[f]) + list(X_test[f])) \n",
        "        X_train[f] = encoder.transform(X_train[f].ravel())\n",
        "        X_test[f] = encoder.transform(X_test[f].ravel())\n",
        "                  \n",
        "\n",
        "def remove_columns(X):\n",
        "    columns = [\"photos\", \"pred0_high\", \"pred0_low\", \"pred0_medium\",\n",
        "               \"description\", \"low\", \"medium\", \"high\",\n",
        "               \"interest_level\", \"created\"]\n",
        "    for c in columns:\n",
        "        del X[c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "efd15f12-92d4-1101-afeb-80b382e59170"
      },
      "outputs": [],
      "source": [
        "def clean_feature(X):\n",
        "    dup_dict = {'dishwasher': ['_dishwasher_','dishwasher','washer', 'washer_', 'washer_in_unit','unit_washer'],\n",
        "    'dryer':['_dryer','dryer','dryer_in_building','dryer_in_unit'],\n",
        "    'pets_friendly':['_pets_ok_','pet_friendly', 'pets_on_approval'],\n",
        "    'backyard':['backyard','courtyard','patio'],\n",
        "    'central_ac':['central_a','central_ac'],\n",
        "    'childrens_playroom':['childrens_playroom','children'],\n",
        "    'common_parking':['common_parking','parking','parking_space','site_parking', 'site_parking_lot']\n",
        "    'common_roof_deck': ['common_roof_deck', 'common_terrace']\n",
        "    'concierge':['concierge','doorman','ft_doorman','time_doorman']\n",
        "    'fireplace': ['decorative_fireplace','fireplace']\n",
        "    'fitness':['fitness','fitness_center','gym','gym_in_building']\n",
        "    'garden': ['garden','residents_garden']\n",
        "    'hardwood':['hardwood','hardwood_floors']\n",
        "    'high_ceiling':['high_ceiling','high_ceilings']\n",
        "    'high_speed_internet': ['high_speed_internet', 'speed_internet']\n",
        "    'in_super':['in_super','in_superintendent','live_in_super','site_super']\n",
        "    'laundry':['laundry','site_laundry']\n",
        "    'lounge':['lounge','lounge_room','residents_lounge']\n",
        "    'newly_renovated':['newly_renovated','renovated']\n",
        "    'outdoor_space':['outdoor_areas', 'outdoor_entertainment_space','outdoor_space']\n",
        "    'roof':['roof', 'roof_deck', 'roofdeck','terrace']\n",
        "    'wheelchair_access':['wheelchair_access', 'wheelchair_ramp']}\n",
        "    \n",
        "    def n_logical(list,Y):\n",
        "        n = len(list)\n",
        "        log_or = 0\n",
        "        for i in range(0,n-1):\n",
        "            if i == 0:\n",
        "                log_or = np.logical_or(Y[list[i]] == 1, Y[list[i+1]] == 1)\n",
        "            else:\n",
        "                log_or = np.logical_or(Y[list[i]] == 1, log_or)\n",
        "        \n",
        "        return log_or\n",
        "        \n",
        "    for (key, feature_list) in dup_dict:\n",
        "        X.loc[n_logical(feature_list, X), key] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27568176-299f-2ca3-b2fe-7e1d0634340f"
      },
      "outputs": [],
      "source": [
        "def simple_bayes_high_cord(train_df, test_df):\n",
        "    index=list(range(train_df.shape[0]))\n",
        "    random.shuffle(index)\n",
        "    a=[np.nan]*len(train_df)\n",
        "    b=[np.nan]*len(train_df)\n",
        "    c=[np.nan]*len(train_df)\n",
        "\n",
        "    for i in range(5):\n",
        "        building_level={}\n",
        "        for j in train_df['manager_id'].values:\n",
        "            building_level[j]=[0,0,0]\n",
        "        test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
        "        train_index=list(set(index).difference(test_index))\n",
        "        for j in train_index:\n",
        "            temp=train_df.iloc[j]\n",
        "            if temp['interest_level']=='low':\n",
        "                building_level[temp['manager_id']][0]+=1\n",
        "            if temp['interest_level']=='medium':\n",
        "                building_level[temp['manager_id']][1]+=1\n",
        "            if temp['interest_level']=='high':\n",
        "                building_level[temp['manager_id']][2]+=1\n",
        "        for j in test_index:\n",
        "            temp=train_df.iloc[j]\n",
        "            if sum(building_level[temp['manager_id']])!=0:\n",
        "                a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
        "                b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
        "                c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
        "    train_df['manager_level_low']=a\n",
        "    train_df['manager_level_medium']=b\n",
        "    train_df['manager_level_high']=c\n",
        "\n",
        "\n",
        "\n",
        "    a=[]\n",
        "    b=[]\n",
        "    c=[]\n",
        "    building_level={}\n",
        "    for j in train_df['manager_id'].values:\n",
        "        building_level[j]=[0,0,0]\n",
        "    for j in range(train_df.shape[0]):\n",
        "        temp=train_df.iloc[j]\n",
        "        if temp['interest_level']=='low':\n",
        "            building_level[temp['manager_id']][0]+=1\n",
        "        if temp['interest_level']=='medium':\n",
        "            building_level[temp['manager_id']][1]+=1\n",
        "        if temp['interest_level']=='high':\n",
        "            building_level[temp['manager_id']][2]+=1\n",
        "\n",
        "    for i in test_df['manager_id'].values:\n",
        "        if i not in building_level.keys():\n",
        "            a.append(np.nan)\n",
        "            b.append(np.nan)\n",
        "            c.append(np.nan)\n",
        "        else:\n",
        "            a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
        "            b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
        "            c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
        "    test_df['manager_level_low']=a\n",
        "    test_df['manager_level_medium']=b\n",
        "    test_df['manager_level_high']=c\n",
        "\n",
        "    features_to_use.append('manager_level_low') \n",
        "    features_to_use.append('manager_level_medium') \n",
        "    features_to_use.append('manager_level_high')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f167309-9549-b2b1-b7e4-05c7681b13ba"
      },
      "outputs": [],
      "source": [
        "print(\"Starting transformations\")        \n",
        "X_train = transform_data(X_train)    \n",
        "X_test = transform_data(X_test) \n",
        "y = X_train['interest_level'].ravel()\n",
        "\n",
        "print(\"Normalizing high cordiality data...\")\n",
        "simple_bayes_high_cord(X_train, X_test)\n",
        "normalize_high_cordiality_data()\n",
        "transform_categorical_data()\n",
        "\n",
        "remove_columns(X_train)\n",
        "remove_columns(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d43c854e-009a-2f3c-70a1-71b44680a9ec"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52fdf657-07d3-955c-af41-36258c5cfb36"
      },
      "outputs": [],
      "source": [
        "cols = X_train.columns\n",
        "for i in range(0,16):\n",
        "    print(cols[(10*i):(10*i+10)])\n",
        "print(cols[160:len(cols)])"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}