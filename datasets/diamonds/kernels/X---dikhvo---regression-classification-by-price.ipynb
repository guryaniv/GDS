{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a35ba617-6e93-42c1-f1c1-2ef28aa6dddd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('figure', figsize=(15, 12))\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1662ad16-3876-1a4a-5cce-8b5de32df413"
      },
      "outputs": [],
      "source": [
        "# read the data\n",
        "dmds = pd.read_csv('../input/diamonds.csv')\n",
        "dmds.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "dmds.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "73423bea-7c81-6797-482c-315b2ebe21ad"
      },
      "outputs": [],
      "source": [
        "# encode cut, color and clarity\n",
        "categorical_cols = ['cut', 'color', 'clarity']\n",
        "for c in categorical_cols:\n",
        "    dmds[c] = pd.factorize(dmds[c])[0]\n",
        "dmds.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "128c4e73-1b34-1892-2cc2-168ed5e5c14e"
      },
      "outputs": [],
      "source": [
        "# graphs\n",
        "# use a reduced set without categorical columns\n",
        "dmds_reduced = dmds[dmds.columns.difference(['cut', 'color', 'clarity'])]\n",
        "\n",
        "# correlations\n",
        "plt.matshow(dmds_reduced.corr())\n",
        "plt.colorbar()\n",
        "tick_marks = dmds_reduced.columns.values\n",
        "plt.xticks(np.arange(tick_marks.size), tick_marks)\n",
        "plt.yticks(np.arange(tick_marks.size), tick_marks)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91f75b7e-244c-bed5-3efc-fbd4077782d0"
      },
      "outputs": [],
      "source": [
        "# let's compare the correlation visually\n",
        "from pandas.tools.plotting import scatter_matrix\n",
        "\n",
        "scatter_matrix(dmds_reduced, diagonal='kde')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53ec0640-1454-df4c-1fa3-93f402716ab7"
      },
      "outputs": [],
      "source": [
        "# split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = dmds.iloc[:, dmds.columns != 'price'].values, dmds.iloc[:, dmds.columns == 'price'].values.ravel()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "789e949a-cc17-688a-5cae-f348b1159f0f"
      },
      "source": [
        "## Regression ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "de7c6e28-2cea-1e5d-e339-686792ba83a8"
      },
      "source": [
        "Let's compare the basic linear regression and random forest regression. SVR's were lagging on my PC, hence these are commented out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "433ed608-4ac1-0f3c-c1b7-e92993f65a27"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "models = [('LR', LinearRegression(n_jobs=-1)),\n",
        "          ('RF', RandomForestRegressor(n_estimators=100, criterion='mse', random_state=1, n_jobs=-1)),\n",
        "#           ('SVR-lin', SVR(kernel='linear', C=1e3))\n",
        "#           ('SVR-rbf', SVR(kernel='rbf', C=1e3)),\n",
        "#           ('SVR-poly', SVR(kernel='poly', C=1e3, degree=2))\n",
        "         ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c93f893-8d34-2c3c-422d-e3bcd2d71ec5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=5, random_state=123)\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, n_jobs=-1)    \n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ba9ac4a-75c0-9a79-f8ef-e239c5e2562a"
      },
      "outputs": [],
      "source": [
        "# compute ms-error and R^2\n",
        "for name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "    print('%s: MSE train: %.4f, test: %.4f' % (name, mean_squared_error(y_train, y_train_pred),\n",
        "                                           mean_squared_error(y_test, y_test_pred)))\n",
        "    print('%s: R^2 train: %.4f, test: %.4f' % (name, r2_score(y_train, y_train_pred),\n",
        "                                           r2_score(y_test, y_test_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e69dcd42-f1a6-5902-f921-4ff01ce4a8fb"
      },
      "source": [
        "Random forests estimator looks promising, let's compare algorithms visually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1906809a-0ac8-0772-8af5-761cc1388add"
      },
      "outputs": [],
      "source": [
        "# Compare Algorithms\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results, vert=False)\n",
        "ax.set_yticklabels(names)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "299d4b3a-ae4e-1dbc-0fe6-c22d970c7983"
      },
      "source": [
        "## Classification by price ranges ##\n",
        "Let's split the price by price bands and try to train different classifiers on it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1aa6e0e9-5160-865b-07b0-7a352ae8d433"
      },
      "source": [
        "### 10 classes ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd45c15a-ef99-45a3-49f7-15992c3cf70a"
      },
      "outputs": [],
      "source": [
        "# convert price data to classes\n",
        "n_classes = 10\n",
        "\n",
        "y_classes = np.linspace(0, y.max(), n_classes)\n",
        "y_train_cl = np.digitize(y_train, bins=y_classes)\n",
        "y_test_cl = np.digitize(y_test, bins=y_classes)\n",
        "\n",
        "print('Price classes: %s' % (y_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65aa1394-24c8-6e4d-4f5b-89197438dc5b"
      },
      "outputs": [],
      "source": [
        "# test different models on the data\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "models = [('LR', LogisticRegression()),\n",
        "          ('KNN', KNeighborsClassifier()),\n",
        "          ('CART', DecisionTreeClassifier()),\n",
        "          ('NB', GaussianNB()),\n",
        "          ('SVM-lin', SVC(kernel='linear')),\n",
        "          ('SVM-rbf', SVC(kernel='rbf')),\n",
        "          ('RF', RandomForestClassifier()),\n",
        "          ('MLP', MLPClassifier(alpha=1)),\n",
        "          ('ADA', AdaBoostClassifier())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb439ced-703c-922b-6ee8-68cf2411cfd0"
      },
      "outputs": [],
      "source": [
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=5, random_state=42)\n",
        "    cv_results = cross_val_score(model, X_train, y_train_cl, cv=kfold, n_jobs=-1)    \n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8d753a0-2be2-c6b4-200f-a9adffeda367"
      },
      "outputs": [],
      "source": [
        "# Compare Algorithms\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results, vert=False)\n",
        "ax.set_yticklabels(names)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "38391c46-d89f-b813-7ed1-36ef60eb8471"
      },
      "source": [
        "### 5 classes ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de7c3bc8-8fa1-7096-d9ef-1b3d37ef829a"
      },
      "outputs": [],
      "source": [
        "# convert price data to classes\n",
        "n_classes = 5\n",
        "\n",
        "y_classes = np.linspace(0, y.max(), n_classes)\n",
        "y_train_cl = np.digitize(y_train, bins=y_classes)\n",
        "y_test_cl = np.digitize(y_test, bins=y_classes)\n",
        "\n",
        "print('Price classes: %s' % (y_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed13e5a9-42be-3602-ceb9-c70f42cd06f3"
      },
      "outputs": [],
      "source": [
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=5, random_state=42)\n",
        "    cv_results = cross_val_score(model, X_train, y_train_cl, cv=kfold, n_jobs=-1)    \n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "08eeb16f-7e78-3dc8-1462-0ba391026f4a"
      },
      "outputs": [],
      "source": [
        "# Compare Algorithms\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results, vert=False)\n",
        "ax.set_yticklabels(names)\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41596501-ef1f-8cb3-dda3-3f48fe023caa"
      },
      "source": [
        "The random forest classifier has won in both scenarios with 5 & 10 classes. In general, classification accuracy is better with 5 classes"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}