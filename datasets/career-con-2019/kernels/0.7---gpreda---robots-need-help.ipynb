{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Robots need help!</font></center></h1>\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/df/RobotsMODO.jpg\" width=\"400\"></img>\n\n<br>\n\n# <a id='0'>Content</a>\n\n- <a href='#1'>Introduction</a>  \n- <a href='#2'>Prepare the data analysis</a>  \n- <a href='#3'>Data exploration</a>   \n - <a href='#31'>Check the data</a>   \n - <a href='#32'>Distribution of target feature `surface`</a>   \n - <a href='#33'>Density plots of features</a>   \n- <a href='#4'>Feature engineering</a>\n- <a href='#5'>Model</a>\n- <a href='#6'>Submission</a>  \n- <a href='#7'>References</a>"},{"metadata":{"_uuid":"9784cc8ed4bceb3bb0ee60778bab3b3355518f37"},"cell_type":"markdown","source":"# <a id='1'>Introduction</a>  \n\n## Competition\nIn this competition, we willl help robots recognize the floor surface they’re standing on. The floor could be of various types, like carpet, tiles, concrete.\n\n## Data\nThe data provided by the organizers  is collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises.  \n\n## Kernel\nIn this Kernel we perform EDA on the data, explore with feature engineering and build a predictive model."},{"metadata":{"_uuid":"abdb16570ed4a120ab7d9822c12fd3cf5c2339da"},"cell_type":"markdown","source":"# <a id='2'>Prepare for data analysis</a>  \n\n\n## Load packages\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import gc\nimport os\nimport logging\nimport datetime\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom lightgbm import LGBMClassifier\nfrom tqdm import tqdm_notebook\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import mean_squared_error, confusion_matrix\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import StratifiedKFold\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1baf9418913d861c75106802ec96ec409ed9c7d"},"cell_type":"markdown","source":"## Load data   \n\nLet's check what data files are available."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"660a0cee494565f5cabec59168e932d43ca037f1"},"cell_type":"code","source":"IS_LOCAL = False\nif(IS_LOCAL):\n    PATH=\"../input/careercon/\"\nelse:\n    PATH=\"../input/\"\nos.listdir(PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d87a4413ad47c4f1eebba4275f99a731e1ae191"},"cell_type":"markdown","source":"Let's load the data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":false,"_uuid":"ddbbd73634939a6633428bed86290aece4f2b04c"},"cell_type":"code","source":"%%time\nX_train = pd.read_csv(os.path.join(PATH, 'X_train.csv'))\nX_test = pd.read_csv(os.path.join(PATH, 'X_test.csv'))\ny_train = pd.read_csv(os.path.join(PATH, 'y_train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"70f03694af7770fc55246d4fbf133b824369ce50"},"cell_type":"code","source":"print(\"Train X: {}\\nTrain y: {}\\nTest X: {}\".format(X_train.shape, y_train.shape, X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b37dc2ee7a3054c9f7a9d6d120a087208027532"},"cell_type":"markdown","source":"We can observe that train data and labels have different number of rows."},{"metadata":{"_uuid":"d8b1e19622d059e03ff7250d4f76198c254936ec"},"cell_type":"markdown","source":"# <a id='3'>Data exploration</a>  \n\n## <a id='31'>Check the data</a>  \n\nLet's check the train and test set."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"aebb41b2152f76491b80b70e2c838d433993d242"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66c5e3028a2a8160529a165a8908901920d504e9","_kg_hide-input":true},"cell_type":"code","source":"y_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"10a2f9b4e0034866ec9eb1fe5f8f74cf3d6fe6f4"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad951cc65c7cafcf1a5cb987775c691116e5354"},"cell_type":"markdown","source":"X_train and X_test datasets have the following entries:  \n\n* series and measurements identifiers: **row_id**, **series_id**, **measurement_number**: these identify uniquely a series and measurement; there are 3809 series, each with max 127 measurements;  \n* measurement orientations: **orientation_X**, **orientation_Y**, **orientation_Z**, **orientation_W**;   \n* angular velocities: **angular_velocity_X**, **angular_velocity_Y**, **angular_velocity_Z**;\n* linear accelerations: **linear_acceleration_X**, **linear_acceleration_Y**, **linear_acceleration_Z**.\n\ny_train has the following columns:  \n\n* **series_id** - this corresponds to the series in train data;  \n* **group_id**;  \n* **surface** - this is the surface type that need to be predicted.\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"10f26f3760a7d5b15b7587edb452a5d71539e3aa"},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5db2dadb11bfa6f0e130ae566099c7ca8a2baf74"},"cell_type":"code","source":"missing_data(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f73a4fe3ded19c5096a0d532d96e48dd73917b62"},"cell_type":"code","source":"missing_data(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c4f949ea6d589c07ae2ffc46f5f16e77a4cd493"},"cell_type":"markdown","source":"There are no missing values in train and test data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d352ded04b435b79969f654835e53cc843949f30"},"cell_type":"code","source":"missing_data(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06ae1576a757f0e80397df975c5a246140faaed5","_kg_hide-input":true},"cell_type":"markdown","source":"Also, train labels has no missing data."},{"metadata":{"trusted":true,"_uuid":"f415baee23e3f48ec22811f0d9a5266f3693c664","_kg_hide-input":true},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b49d454bf0edba43d2618091260d37101a90857","_kg_hide-input":true},"cell_type":"code","source":"X_test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78747516fd066a70f0f4db78f9543d08b93334d1","_kg_hide-input":true},"cell_type":"code","source":"y_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f62c1341e7d69716f0a599c80ead90d41e0f7473"},"cell_type":"markdown","source":"There is the same number of series in X_train and y_train, numbered from 0 to 3809 (total 3810). Each series have 128 measurements.   \nEach series in train dataset is part of a group (numbered from 0 to 72).  \nThe number of rows in X_train and X_test differs with 6 x 128, 128 being the number of measurements for each group.  "},{"metadata":{"_uuid":"a449515fe43d68dbbcf1d70cec8d663ddf7d5dfb"},"cell_type":"markdown","source":"## <a id='32'>Distribution of target feature - surface</a>  \n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8d0db47428faaa50c9a7a6002dd7e08ca953ca57"},"cell_type":"code","source":"f, ax = plt.subplots(1,1, figsize=(16,4))\ntotal = float(len(y_train))\ng = sns.countplot(y_train['surface'], order = y_train['surface'].value_counts().index)\ng.set_title(\"Number and percentage of labels for each class\")\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(100*height/total),\n            ha=\"center\") \nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42ed8502739e99aaa472c3c36ba70ef2fcb95ebc"},"cell_type":"markdown","source":"## <a id='32'>Density plots of features</a>  \n\nLet's show now the density plot of variables in train and test dataset. \n\nWe represent with different colors the distribution for values with different values of **surface**."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2e0f6a8ca0e6f1c64b24f5d4b9e033516e59d8ec"},"cell_type":"code","source":"def plot_feature_distribution(df1, df2, label1, label2, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(2,5,figsize=(16,8))\n\n    for feature in features:\n        i += 1\n        plt.subplot(2,5,i)\n        sns.kdeplot(df1[feature], bw=0.5,label=label1)\n        sns.kdeplot(df2[feature], bw=0.5,label=label2)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f1260bd87f03984fe5573323837a9f9961a8d25","_kg_hide-input":true},"cell_type":"code","source":"features = X_train.columns.values[3:]\nplot_feature_distribution(X_train, X_test, 'train', 'test', features)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"85d698f6a2898d01f51717be90e4d467eed6ce64"},"cell_type":"code","source":"def plot_feature_class_distribution(classes,tt, features):\n    i = 0\n    sns.set_style('whitegrid')\n    plt.figure()\n    fig, ax = plt.subplots(5,2,figsize=(16,24))\n\n    for feature in features:\n        i += 1\n        plt.subplot(5,2,i)\n        for clas in classes:\n            ttc = tt[tt['surface']==clas]\n            sns.kdeplot(ttc[feature], bw=0.5,label=clas)\n        plt.xlabel(feature, fontsize=9)\n        locs, labels = plt.xticks()\n        plt.tick_params(axis='x', which='major', labelsize=8)\n        plt.tick_params(axis='y', which='major', labelsize=8)\n    plt.show();","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"479d3b7b152a5dae5a07fba203381aa43d973a97"},"cell_type":"code","source":"classes = (y_train['surface'].value_counts()).index\ntt = X_train.merge(y_train, on='series_id', how='inner')\nplot_feature_class_distribution(classes, tt, features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"394b783f6bbfcaf18a43c41faf11f7de121ba2eb"},"cell_type":"markdown","source":"# <a id='4'>Feature engineering</a>  \n"},{"metadata":{"_uuid":"a9ab8347dd0fc263d6a81e2316b0939bfa25f2da"},"cell_type":"markdown","source":"This section is heavily borrowing from: https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots Kernel. \nThe quaternion_to_euler transformation procedure is also credited in the original Kernel, and I kept this reference as well.\nI also corrected few issues and added some more engineered features. Thanks for @timmmmmms for pointing them out."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6735b8e29eeeb48a635a907355fca4f91b34d95d"},"cell_type":"code","source":"# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"b05e1a29dc7cc012384c02643f329be539d3908a"},"cell_type":"code","source":"def perform_feature_engineering(df):\n    df_out = pd.DataFrame()\n    df['total_angular_velocity'] = np.sqrt(np.square(df['angular_velocity_X']) + np.square(df['angular_velocity_Y']) + np.square(df['angular_velocity_Z']))\n    df['total_linear_acceleration'] = np.sqrt(np.square(df['linear_acceleration_X']) + np.square(df['linear_acceleration_Y']) + np.square(df['linear_acceleration_Z']))\n    df['total_xyz'] = np.sqrt(np.square(df['orientation_X']) + np.square(df['orientation_Y']) +\n                              np.square(df['orientation_Z']))\n    df['acc_vs_vel'] = df['total_linear_acceleration'] / df['total_angular_velocity']\n    \n    x, y, z, w = df['orientation_X'].tolist(), df['orientation_Y'].tolist(), df['orientation_Z'].tolist(), df['orientation_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    df['euler_x'] = nx\n    df['euler_y'] = ny\n    df['euler_z'] = nz\n    \n    df['total_angle'] = np.sqrt(np.square(df['euler_x']) + np.square(df['euler_y']) + np.square(df['euler_z']))\n    df['angle_vs_acc'] = df['total_angle'] / df['total_linear_acceleration']\n    df['angle_vs_vel'] = df['total_angle'] / df['total_angular_velocity']\n    \n    def mean_change_of_abs_change(x):\n        return np.mean(np.diff(np.abs(np.diff(x))))\n\n    def mean_abs_change(x):\n        return np.mean(np.abs(np.diff(x)))\n    \n    for col in df.columns:\n        if col in ['row_id', 'series_id', 'measurement_number']:\n            continue\n        df_out[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n        df_out[col + '_min'] = df.groupby(['series_id'])[col].min()\n        df_out[col + '_max'] = df.groupby(['series_id'])[col].max()\n        df_out[col + '_std'] = df.groupby(['series_id'])[col].std()\n        df_out[col + '_mad'] = df.groupby(['series_id'])[col].mad()\n        df_out[col + '_med'] = df.groupby(['series_id'])[col].median()\n        df_out[col + '_skew'] = df.groupby(['series_id'])[col].skew()\n        df_out[col + '_range'] = df_out[col + '_max'] - df_out[col + '_min']\n        df_out[col + '_max_to_min'] = df_out[col + '_max'] / df_out[col + '_min']\n        df_out[col + '_mean_abs_change'] = df.groupby('series_id')[col].apply(mean_abs_change)\n        df_out[col + '_mean_change_of_abs_change'] = df.groupby('series_id')[col].apply(mean_change_of_abs_change)\n        df_out[col + '_abs_max'] = df.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n        df_out[col + '_abs_min'] = df.groupby('series_id')[col].apply(lambda x: np.min(np.abs(x)))\n        df_out[col + '_abs_mean'] = df.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(x)))\n        df_out[col + '_abs_std'] = df.groupby('series_id')[col].apply(lambda x: np.std(np.abs(x)))\n        df_out[col + '_abs_avg'] = (df_out[col + '_abs_min'] + df_out[col + '_abs_max'])/2\n        df_out[col + '_abs_range'] = df_out[col + '_abs_max'] - df_out[col + '_abs_min']\n\n    return df_out","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"310409206394429b14bf60e7bd759234bd2d81c5"},"cell_type":"code","source":"%%time\nX_train = perform_feature_engineering(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9d4aafa4271c524651b68f860d310bb5a64d1e65"},"cell_type":"code","source":"%time\nX_test = perform_feature_engineering(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"eef14b6a9b05bdeca2e8dd2f6bca98e7915ecfdd"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0103613591cb8146a2c20fc0471c8da5d37cd82b"},"cell_type":"code","source":"X_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1de959929ee5a7f643ba02c00390cf8428a0ad90"},"cell_type":"markdown","source":"# <a id='5'>Model</a>  \n\nWe use LabelEncoder for the target feature."},{"metadata":{"trusted":true,"_uuid":"3c0a07575a08df25acf3c2d648f2c15dcbc1de5f","_kg_hide-input":true},"cell_type":"code","source":"le = LabelEncoder()\ny_train['surface'] = le.fit_transform(y_train['surface'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d8bf8326b07d7a813b914e0605ae24c4508a90d"},"cell_type":"markdown","source":"We replace with 0 NAs and $\\infty$."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"67b8bfb18f66307f15270b8fa7fcf0827f3ebe17"},"cell_type":"code","source":"X_train.fillna(0, inplace = True)\nX_train.replace(-np.inf, 0, inplace = True)\nX_train.replace(np.inf, 0, inplace = True)\nX_test.fillna(0, inplace = True)\nX_test.replace(-np.inf, 0, inplace = True)\nX_test.replace(np.inf, 0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4096b3516249d5c54d1b2c909e17a7906fafc923"},"cell_type":"markdown","source":"## Prepare for cross-validation."},{"metadata":{"trusted":true,"_uuid":"613d0b00834f0ed248556b858b4a4d793b8e8180"},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=59)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3b31725e5e353783a5625542936c00175059405"},"cell_type":"markdown","source":"## Random Forest classifier\n\nWe use first a Random Forest Classifier model."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fedc8cba976a3640613080a5e379033090c6d4b3"},"cell_type":"code","source":"sub_preds_rf = np.zeros((X_test.shape[0], 9))\noof_preds_rf = np.zeros((X_train.shape[0]))\nscore = 0\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train['surface'])):\n    clf =  RandomForestClassifier(n_estimators = 2000, n_jobs = -1)\n    clf.fit(X_train.iloc[trn_idx], y_train['surface'][trn_idx])\n    oof_preds_rf[val_idx] = clf.predict(X_train.iloc[val_idx])\n    sub_preds_rf += clf.predict_proba(X_test) / folds.n_splits\n    score += clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])\n    print('Fold: {} score: {}'.format(fold_,clf.score(X_train.iloc[val_idx], y_train['surface'][val_idx])))\nprint('Avg Accuracy', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e7b27f046b9e7b3e72665bd9208db30b006ccd9"},"cell_type":"markdown","source":"\n## LightGBM Classifier\n\nWe also use a LightGBM Classifier model."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a5c46248d71fff6666db8605ba541939e04a4eac"},"cell_type":"code","source":"USE_LGB = False\nif(USE_LGB):\n    sub_preds_lgb = np.zeros((X_test.shape[0], 9))\n    oof_preds_lgb = np.zeros((X_train.shape[0]))\n    score = 0\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train['surface'])):\n        train_x, train_y = X_train.iloc[trn_idx], y_train['surface'][trn_idx]\n        valid_x, valid_y = X_train.iloc[val_idx], y_train['surface'][val_idx]\n        clf =  LGBMClassifier(\n                      nthread=-1,\n                      n_estimators=2000,\n                      learning_rate=0.01,\n                      boosting_type='gbdt',\n                      is_unbalance=True,\n                      objective='multiclass',\n                      numclass=9,\n                      silent=-1,\n                      verbose=-1,\n                      feval=None)\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n                     verbose= 1000, early_stopping_rounds= 200)\n\n        oof_preds_lgb[val_idx] = clf.predict(valid_x)\n        sub_preds_lgb += clf.predict_proba(X_test) / folds.n_splits\n        score += clf.score(valid_x, valid_y)\n        print('Fold: {} score: {}'.format(fold_,clf.score(valid_x, valid_y)))\n    print('Avg Accuracy', score / folds.n_splits)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6849fb0f877d73e91820a46b732c35c4d81f8b63"},"cell_type":"markdown","source":"# <a id='6'>Submission</a>  \n\nWe submit the solution for both the RF and LGB."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"410056706ec800a78050d6850c2620a96ae3a70c"},"cell_type":"code","source":"submission = pd.read_csv(os.path.join(PATH,'sample_submission.csv'))\nsubmission['surface'] = le.inverse_transform(sub_preds_rf.argmax(axis=1))\nsubmission.to_csv('submission_rf.csv', index=False)\nsubmission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29370efad06e957166e5e0b3e7d36e810d421860"},"cell_type":"code","source":"USE_LGB = False\nif(USE_LGB):\n    submission['surface'] = le.inverse_transform(sub_preds_lgb.argmax(axis=1))\n    submission.to_csv('submission_lgb.csv', index=False)\n    submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7664ec331050ab5aefd2cf26c898f7c9c6c7e352"},"cell_type":"markdown","source":"# <a id='7'>References</a>    \n\n[1] https://www.kaggle.com/vanshjatana/help-humanity-by-helping-robots-4e306b  \n[2] https://www.kaggle.com/artgor/where-do-the-robots-drive  \n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}