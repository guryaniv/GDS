{"cells":[{"metadata":{"_uuid":"a592f6a3178600f036299ce22c5d90a3992d1ef8"},"cell_type":"markdown","source":"## Parameter Search Visualization: Dimensionality Reduction and ExtraTree Regressor\n_By Nick Brooks, June 2018_\n\nClucky code brushed under the rug in this notebook..\n\n**Load Data:**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"import time\nnotebookstart= time.time()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport random\nrandom.seed(2018)\n\n# Models Packages\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import display\n\n# Supervised Learning\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import ExtraTreesRegressor\n\n# Unsupervised Models\nfrom sklearn.decomposition import PCA, TruncatedSVD, FastICA\nfrom sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n\n# Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport scipy.stats as st\n\n# Viz\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Specify index/ target name\nid_col = \"ID\"\ntarget_var = \"target\"\n\n# House Keeping Parameters\nrstate = 23\nDebug = False\nHome = False\n\ndebug_num = 200\nif Home is True:\n    import os\n    path = r\"D:\\My Computer\\DATA\\Santander\"\n    os.chdir(path)\n    \n    print(\"Data Load Stage\")\n    training = pd.read_csv('train.csv', index_col = id_col)\n    if Debug is True : training = training.sample(debug_num)\n    traindex = training.index\n    testing = pd.read_csv('test.csv', index_col = id_col)\n    if Debug is True : testing = testing.sample(debug_num)\n    testdex = testing.index\nelse:\n    print(\"Data Load Stage\")\n    training = pd.read_csv('../input/train.csv', index_col = id_col)\n    if Debug is True : training = training.sample(debug_num)\n    traindex = training.index\n    testing = pd.read_csv('../input/test.csv', index_col = id_col)\n    if Debug is True : testing = testing.sample(debug_num)\n    testdex = testing.index\n\ny = np.log1p(training[target_var])\ntraining.drop(target_var,axis=1, inplace=True)\nprint('Train shape: {} Rows, {} Columns'.format(*training.shape))\nprint('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n\nprint(\"Combine Train and Test\")\ndf = pd.concat([training,testing],axis=0)\ndel training, testing\ngc.collect()\nprint('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d391453d017406791922e3fe1cb8e3841e4edef"},"cell_type":"markdown","source":"**Define Variables and Helper Funtions:**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"daf305b629a6b2ce86a799c3520b55a58d43e5f1","collapsed":true},"cell_type":"code","source":"# Feature Names\nfeat_names = df.columns\n\n# Modeling Datasets\ntest_df = df.loc[testdex,:]\nX = df.loc[traindex,:]\n\n# Train/Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.15,random_state=rstate)\nprint(\"X Train\", X_train.shape, \"\\ny Train\",y_train.shape, \"\\nX Test\",X_test.shape, \"\\ny Test\",y_test.shape)\n\nprint(\"Starting Model. Train shape: {}, Test shape: {}\".format(X.shape,test_df.shape))\nprint(\"Feature Num: \",len(feat_names))\n\n# Utility functions:\ndef rmse(y_true, y_pred):\n    return abs(np.sqrt(np.mean((y_true-y_pred)**2)))\nscoring = make_scorer(rmse, greater_is_better=False)\n\n# Report best scores\ndef report(results, n_top=3):\n    for i in list(range(2, n_top + 2)):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"Model with rank: {0}\".format(i))\n            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n                  results['mean_test_score'][candidate]*-1,\n                  results['std_test_score'][candidate]))\n            print(\"Parameters: {0}\".format(results['params'][candidate]))\n            print(\"\")\n\n# Storage for Model and Results\nresults = pd.DataFrame(columns=['Model','Para','Validation_Score','CV Mean','CV STDEV'])\nsubmission_df = pd.DataFrame(index=testdex)\n\ndef save(model, modelname):\n    global results\n    model.best_estimator_.fit(X, y)\n    submission = np.expm1(model.predict(test_df))\n    \n    df = pd.DataFrame({'ID':testdex, \n                        'target':submission})\n    df.to_csv(\"{}.csv\".format(modelname),header=True,index=False)\n    submission_df[modelname] = submission\n    \n    model.best_estimator_.fit(X_train, y_train)\n    top = np.flatnonzero(model.cv_results_['rank_test_score'] == 1)\n    CV_scores = (model.cv_results_['mean_test_score'][top][0])*-1\n    STDev = model.cv_results_['std_test_score'][top][0]\n    Test_scores = rmse(y_test, model.predict(X_test))\n    \n    # CV and Save Scores\n    results = results.append({'Model': modelname,'Para': model.best_params_,'Validation_Score': Test_scores,\n                             'CV Mean':CV_scores, 'CV STDEV': STDev}, ignore_index=True)\n    \n    # Print Evaluation\n    print(\"\\nEvaluation Method: RMSE\")\n    print(\"Optimal Model Parameters: {}\".format(grid.best_params_))\n    print(\"Training Set RMSE: \", rmse(y_train, model.predict(X_train)))\n    print(\"CV Accuracy: {0:.2f} (+/- {1:.2f}) [%{2}]\".format(CV_scores, STDev, modelname))\n    print('Unseen Data Validation Score:', Test_scores)\n\nprint(\"Functions Defined..\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dee6a30702beb003b8c0afb56358a420f9fc9654"},"cell_type":"markdown","source":"## Comparing Dimensional Reduction Methods with ExtraTree Regressor"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"8ca483d97f1a6ff5288e9741c9a667f0a7c1d8dc","collapsed":true},"cell_type":"code","source":"# Save All Search Output\nsearch_output = {}\nalldimmodels= time.time()\n\n# Dimensionality Reduction Central\npca = PCA(random_state=rstate)\ntsvd = TruncatedSVD(random_state=rstate)\nica = FastICA(random_state=rstate)\ngrp = GaussianRandomProjection(random_state=rstate,eps=0.1)\nsrp = SparseRandomProjection(random_state=rstate, dense_output=True,eps=1)\n\ndimensionality_reduction_models = [(srp,\"srp\"),\n                                   (pca, \"pca\"),\n                                   (tsvd,\"tsvd\"),\n                                   # (ica,\"ica\"), # Hits a block..\n                                   (grp,\"grp\")\n                                  ]\n\ncomponent_range = [5,300]\niterations = 50\nprint(\"Extra Tree Regressor Parameters:{}\\n\".format(ExtraTreesRegressor().get_params().keys()))\nfor DR,DR_name in dimensionality_reduction_models:\n    modelstart= time.time()\n    print(\"Starting ExtraTree Regression with\",DR_name.upper())\n    print(\"Parameters for {}:\\n{}\".format(DR_name.upper(),SVR().get_params().keys()))\n    model = Pipeline(steps=[(DR_name,DR), ('xtree', ExtraTreesRegressor())])\n\n    # Use Scipy to create Parameter Distributions to sample from\n    param_grid = {DR_name + '__n_components': st.randint(*component_range),\n                  'xtree__n_estimators': st.randint(200,800),\n                  'xtree__max_depth': [4,8,12]\n                 }\n    grid = RandomizedSearchCV(model, param_grid, cv=2, verbose=1, n_iter=iterations, random_state=rstate, scoring=scoring, return_train_score=True, iid= False)\n    \n    # Train and Save\n    grid.fit(X_train, y_train)\n    save(grid,DR_name)\n    temp = pd.DataFrame.from_dict(grid.cv_results_)\n    search_output[DR_name] = abs(pd.concat([temp.drop(['params'], axis=1), temp['params'].apply(pd.Series)], axis=1)).astype(\"float\")\n    \n    #print(\"\\nReport\")\n    #report(grid.cv_results_)\n    print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n    del temp, grid, model\n    print(\"\\n######################################################################\\n######################################################################\\n\")\nprint(\"All Model Runtime: %0.2f Minutes\"%((time.time() - alldimmodels)/60))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bc76bfccf34f824cf9b579c26a3fd6f1721cc84"},"cell_type":"markdown","source":"## Visualize Parameter Search\n\n**Performance and Dimensionality Reduction Complexity:**"},{"metadata":{"trusted":true,"_uuid":"100702f5e58fbef5b16aac8a16ea146d3047fc2f","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# Score vs. Component Number\ncomponent_scores = pd.DataFrame(columns = [\"N Components\",\"Score\", \"Max Depth\",\"Tree Number\", \"Dimensionality Method\"])\nfor dimred in [algo[1]for algo in dimensionality_reduction_models]:\n    temp = search_output[dimred].loc[:,[\"param_\" + str(dimred) + \"__n_components\", \"mean_test_score\", 'param_xtree__max_depth', \"param_xtree__n_estimators\"]]\n    temp[\"Dimensionality Method\"] = str(dimred.upper())\n    temp.columns = [\"N Components\",\"Score\", \"Max Depth\",\"Tree Number\", \"Dimensionality Method\"]\n    component_scores = pd.concat([component_scores, temp], axis=0)\n    \n# Plot\ncomponent_scores[\"N Components\"] = component_scores[\"N Components\"].astype(int)\ng = sns.lmplot(x=\"N Components\", y=\"Score\", data=component_scores,\n               hue=\"Dimensionality Method\", size=6, aspect = 1.5, order=2)\nplt.title(\"Comparing Dimensionality Reduction Methods\\nScored on Extra Trees\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cd9e738c71aaf35e248dececb29bb00dbeff096"},"cell_type":"markdown","source":"**Correlations:**"},{"metadata":{"trusted":true,"_uuid":"cd45a5b1c3a2206e40abbc128c41e9fc4db0b37c","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"sns.pairplot(component_scores, hue=\"Dimensionality Method\",diag_kind=\"kde\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed221494d8cdb86a677088e47af833b65868324e"},"cell_type":"markdown","source":"**Multi-Variate Analysis:** "},{"metadata":{"trusted":true,"_uuid":"99ddd2c5ea42cce962287aaeaf932d893e266daa","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"g = sns.FacetGrid(component_scores, col=\"Max Depth\", hue = \"Dimensionality Method\")\ng = (g.map(sns.regplot, \"N Components\", \"Score\",lowess=True).add_legend())\ng.fig.suptitle('Number of Dimensionality Components')\nplt.subplots_adjust(top=0.85)\nplt.show()\nprint(\"What About Extra Tree Ensemble Size?\")\ng = sns.FacetGrid(component_scores, col=\"Max Depth\", hue = \"Dimensionality Method\")\ng = (g.map(sns.regplot, \"Tree Number\", \"Score\",lowess=True).add_legend())\nplt.subplots_adjust(top=0.85)\ng.fig.suptitle('Number of Trees')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"925feddbc7f0a5d20d307baff6f5286e51799703"},"cell_type":"markdown","source":"**Is there a relationship between Ensemble Size and Dimensionality Components?**"},{"metadata":{"trusted":true,"_uuid":"608545bddcee6b425da96be2d5ee29594af71e90","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"n_bins = 15\n# Bin Continuous Variables\nfor bin_col in [\"Tree Number\",\"N Components\"]:\n    lower, higher = component_scores[bin_col].min().astype(int), component_scores[bin_col].max().astype(int)\n    edges = range(lower, higher, (higher - lower)//n_bins) # the number of edges is 8\n    lbs = [round((edges[i] + edges[i+1])/2) for i in range(len(edges)-1)]\n    component_scores[bin_col + \" Bins\"] = pd.cut(component_scores[bin_col], bins=n_bins, labels=lbs, include_lowest=True)\n    \n# Plot\nf, ax = plt.subplots(figsize=(8,8))\nax.set_title('Dimensionality Reduction Components and Tree Count Heatmap for Score')\nsns.heatmap(component_scores.loc[component_scores[\"Dimensionality Method\"] == \"GRP\",:].pivot_table(values=\"Score\", index=\"Tree Number Bins\", columns=\"N Components Bins\", aggfunc='mean'),\n                annot=False, linewidths=.5, ax=ax,cbar_kws={'label': 'RMSE Score'}, cmap=\"viridis\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7e24e4b77b68b9c8401f9d3383ae71da733c6b5"},"cell_type":"markdown","source":"**Correlate Best Results by Dimensionality Method:**"},{"metadata":{"trusted":true,"_uuid":"9e842ffb880702631d5d7d746fd42fa93630c976","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"print(\"Algorithms Correlation Matrix\")\ndisplay(submission_df.corr())\n\nprint(\"Algorigthms and N Components - Sorted Scores\")\ndisplay(component_scores.sort_values(by= \"Score\",ascending=True)[:15])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca5f5df95238e17fbd245120b60042e8e4973198"},"cell_type":"markdown","source":"**Submit:**"},{"metadata":{"trusted":true,"_uuid":"f7472c66023970cb071f224fe6291f76a4f87fd0","collapsed":true},"cell_type":"code","source":"# Simple Ensemble\nsubmission_df[\"target\"] = submission_df.mean(axis=1)\nsubmission_df[\"target\"].to_csv(\"mean_score.csv\",index=True)\n\ndisplay(submission_df[\"target\"].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"36054fa1387479703a7267b2a38737a9d6ecbc4e"},"cell_type":"code","source":"print(\"All Model Runtime: %0.2f Minutes\"%((time.time() - alldimmodels)/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0c6a818b181887aa412e177b597bd5e38124b2be"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}