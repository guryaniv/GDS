{"cells":[{"metadata":{"trusted":true,"_uuid":"e33f217c4a5df6cb362e22b7c046c0319311862c"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom tensorflow.python.framework import ops","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68e7f7a667d9ef493eb246488f578aa3d2b45a15"},"cell_type":"markdown","source":"# 1. Load the data"},{"metadata":{"trusted":true,"_uuid":"435c5997e0e8adb394ccacad40f81616dcb70181"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb0b199f7f0b0089a8f24d4115f87a6720dfb75f"},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7433691c0a8a18de062eb52b341afe0796b55eb"},"cell_type":"markdown","source":"# 2. Visualize the digits\n\nLet us look at some random digits from the training sample and their respective labels "},{"metadata":{"trusted":true,"_uuid":"e9da02ea2b1211af389a45484445ad4d6a7f9c7e"},"cell_type":"code","source":"num_images = 6\nm = train.shape[0]\nidx = np.random.choice(m, size=num_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38d61e65ea3ddcc91617e2e6aed8c030f9877d44"},"cell_type":"code","source":"len(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa7e07a9d3e27a68e40d94002420f4e0e2ac9797"},"cell_type":"code","source":"num_rows = 2\nnum_cols = 3\n\nfig, ax = plt.subplots(nrows = num_rows, ncols = num_cols)\nfig.set_size_inches(12,10)\n\nfor i, j in enumerate(idx):\n    # Find the right place to put the images, a is the row in the figure and b is the column\n    \n    a = i//num_cols\n    b = i%num_cols\n\n    # Remove ticks\n    \n    ax[a][b].tick_params(\n    which='both',\n    left=False,\n    right=False,\n    bottom=False,\n    top=False,\n    labelleft = False,\n    labelbottom=False)\n    \n    # Draw image and set x label as the actual label of the image i.e. the value of the digit in the image\n    \n    ax[a][b].imshow(np.array(train.loc[j][1:]).reshape(28,28), cmap=plt.get_cmap('gray'))\n    ax[a][b].set_xlabel(str(train.loc[j][0]), fontsize = 50)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d8d43f582d797187b9b7d48d27cde83108ab400"},"cell_type":"markdown","source":"# 3. Convert data to the right shape for CNN\n\nConvert the flattened arrays to image arrays, normalize by dividing by 255 and separate features (X) from labels (y)"},{"metadata":{"trusted":true,"_uuid":"a579df6407660e1798bb4c24124b2995dbe5da2b"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c58f297a531db7292a26aba88050386b0165f7a"},"cell_type":"code","source":"X = np.array(train.iloc[:,1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f1e1ea09e451ccea46e7b8f0070ff076cecdb64"},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39c33c98549d8862d8273539578711ad9aae9489"},"cell_type":"code","source":"X = X.reshape((m,28,28,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f61273f98030bb380b3879d67206fb6c149b14f1"},"cell_type":"code","source":"y = np.array(train.label)\n\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y]\n    return Y\n\ny = convert_to_one_hot(y,10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ba85f6b3db86e71399fd9758968fb9bb61675f4"},"cell_type":"code","source":"y[0:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaf2bd44f22396973d117c372e74ad2ee2ca07da"},"cell_type":"code","source":"train.label.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d21424daa8f5053ef34a72c06efaf09563870f5"},"cell_type":"code","source":"# Set random seed\n\nseed = 5\nnp.random.seed(seed)\n\n# Get random training index\n\ntrain_index = np.random.choice(m, round(m*0.95), replace=False)\ndev_index = np.array(list(set(range(m)) - set(train_index)))\n\n# Make training and dev\n#X_train = X\nX_train = X[train_index]\nX_dev = X[dev_index]\n#y_train = y\ny_train = y[train_index]\ny_dev = y[dev_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dde48ab8094340657f888970d4d5551514d76517"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8273036c139d7e7d015f551e736ba5b956a4f554"},"cell_type":"code","source":"m_test = test.shape[0]\nX_test = np.array(test).reshape((m_test,28,28,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dbf9c160638c8f2761330ab05974c431f67624c"},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd767f3ca8681114adec49faf87ee05181c32cff"},"cell_type":"code","source":"X_train = X_train/255.\nX_dev = X_dev/255.\nX_test = X_test/255.\nX_test = np.float32(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d58e6ad51975c67fb32b58bb66dce6b1d5065bc"},"cell_type":"code","source":"print (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of validation (dev) examples = \" + str(X_dev.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"y_train shape: \" + str(y_train.shape))\nprint (\"X_dev shape: \" + str(X_dev.shape))\nprint (\"y_dev shape: \" + str(y_dev.shape))\nprint (\"X_test shape: \" + str(X_test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30aaa0500d54d3c7f175ae9bd621cb323ba58110"},"cell_type":"markdown","source":"# 4. Apply LeNet 5 architecture"},{"metadata":{"_uuid":"29e238e779268dcd6ef653f3585ca266cf8fc8f3"},"cell_type":"markdown","source":"The LeNet architecture we will apply is as follows:\n\nINPUT => CONV (28x28x20, f = 5, s = 1) => RELU => POOL (14x14x20, f = 2, s = 2) => CONV (14x14x50, f = 5, s = 1) => RELU => POOL (7x7x50, f = 2, s = 2) + flatten => FC (120) => RELU => FC (84) => softmax\n\nThus, there are 2 conv layers and 2 pooling layers. Then 2 fully connected layers with ReLU activation and the final layer with a softmax"},{"metadata":{"trusted":true,"_uuid":"eacfabcdf8a077a26e0a7c28ca3487b13ce26a6c"},"cell_type":"code","source":"# Create Placeholders\n\ndef create_placeholders(n_H0,n_W0,n_C0,n_y):\n    X = tf.placeholder(dtype = tf.float32,shape = [None, n_H0, n_W0, n_C0])\n    Y = tf.placeholder(dtype = tf.float32,shape = [None, n_y])\n    drop_rate = tf.placeholder(dtype=tf.float32, name = 'drop_rate')\n    return X, Y, drop_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"679aae84f225600ea0d60a23ff92f9cf32a3d1f8"},"cell_type":"code","source":"# Initialize parameters\n\ndef initialize_parameters():\n    tf.set_random_seed(1)\n    initializer = tf.contrib.layers.xavier_initializer(seed = 0)\n    W1a = tf.get_variable(name = 'W1a', shape = [7, 7, 1, 20], initializer = initializer)\n    W1b = tf.get_variable(name = 'W1b', shape = [5, 5, 1, 20], initializer = initializer)\n    W1c = tf.get_variable(name = 'W1c', shape = [3, 3, 1, 20], initializer = initializer)\n    W2a = tf.get_variable(name = 'W2a', shape = [5, 5, 60, 50], initializer = initializer)\n    W2b = tf.get_variable(name = 'W2b', shape = [3, 3, 60, 50], initializer = initializer)\n    W3 = tf.get_variable(name = 'W3', shape = [3, 3, 100, 120], initializer = initializer)\n    parameters = {\"W1a\": W1a,\n                  \"W1b\": W1b,\n                  \"W1c\": W1c,\n                  \"W2a\": W2a,\n                  \"W2b\": W2b,\n                  \"W3\": W3,}\n    \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03f2fac358177dd2519443002225bf8fcc1a3cf2"},"cell_type":"code","source":"# Check parameters\n\ntf.reset_default_graph()\nwith tf.Session() as sess_test:\n    parameters = initialize_parameters()\n    init = tf.global_variables_initializer()\n    sess_test.run(init)\n    print(\"W1a = \" + str(parameters[\"W1a\"].eval()[1,1,0]))\n    print(\"W1b = \" + str(parameters[\"W1b\"].eval()[1,1,0]))\n    print(\"W1c = \" + str(parameters[\"W1c\"].eval()[1,1,0]))\n    print(\"W2a = \" + str(parameters[\"W2a\"].eval()[1,1,1]))\n    print(\"W2b = \" + str(parameters[\"W2b\"].eval()[1,1,1]))\n    print(\"W3 = \" + str(parameters[\"W3\"].eval()[1,1,0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6705519825a93174072e30faa72afdf25a677f8"},"cell_type":"code","source":"# Build forward propagation computation graph\n\ndef forward_propagation(X, parameters, drop_rate):\n    W1a = parameters['W1a']\n    W1b = parameters['W1b']\n    W1c = parameters['W1c']\n    W2a = parameters['W2a']\n    W2b = parameters['W2b']\n    W3 = parameters['W3']\n    #rate_1, rate_2, rate_3 = drop_rate\n \n    # CONV2D: stride of 1, padding 'SAME'\n    Z1a = tf.nn.conv2d(X,W1a, strides = [1,1,1,1], padding = 'SAME')\n    Z1b = tf.nn.conv2d(X,W1b, strides = [1,1,1,1], padding = 'SAME')\n    Z1c = tf.nn.conv2d(X,W1c, strides = [1,1,1,1], padding = 'SAME')\n    Z1 = tf.concat([Z1a, Z1b, Z1c], axis = -1)\n    # RELU\n    A1 = tf.nn.relu(tf.layers.batch_normalization(Z1))\n    # MAXPOOL: window 2x2, stride 2, padding 'VALID'\n    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n    # CONV2D: filters W2, stride 1, padding 'SAME'\n    Z2a = tf.nn.conv2d(P1,W2a, strides = [1,1,1,1], padding = 'SAME')\n    Z2b = tf.nn.conv2d(P1,W2b, strides = [1,1,1,1], padding = 'SAME')\n    Z2 = tf.concat([Z2a, Z2b], axis = -1)\n    # RELU\n    A2 = tf.nn.relu(tf.layers.batch_normalization(Z2))\n    # MAXPOOL: window 2x2, stride 2, padding 'VALID'\n    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n    # CONV2D: filters W3, stride 1, padding 'SAME'\n    Z3 = tf.nn.conv2d(P2,W3, strides = [1,1,1,1], padding = 'SAME')\n    # RELU\n    A3 = tf.nn.relu(tf.layers.batch_normalization(Z3))\n    # MAXPOOL: window 2x2, stride 2, padding 'VALID'\n    P3 = tf.nn.max_pool(A3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'VALID')\n    # FLATTEN\n    P3 = tf.contrib.layers.flatten(P3)\n    # FULLY-CONNECTED \n    Z4 = tf.layers.dropout(tf.contrib.layers.fully_connected(P3, 200, normalizer_fn=tf.layers.batch_normalization), rate = drop_rate)\n    # FULLY-CONNECTED \n    Z5 = tf.layers.dropout(tf.contrib.layers.fully_connected(Z4, 120, normalizer_fn=tf.layers.batch_normalization), rate = drop_rate)\n    # FULLY-CONNECTED \n    Z6 = tf.layers.dropout(tf.contrib.layers.fully_connected(Z5, 84, normalizer_fn=tf.layers.batch_normalization), rate = drop_rate)\n    # FULLY-CONNECTED \n    Z7 = tf.contrib.layers.fully_connected(Z6, 10, normalizer_fn=tf.layers.batch_normalization, activation_fn = tf.nn.softmax)\n    \n    return Z7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c928a890fb6c32e9b3ea68672a0127f08fb2137a"},"cell_type":"code","source":"# Check forward propagation\n\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y, drop_rate = create_placeholders(28, 28, 1, 10)\n    parameters = initialize_parameters()\n    Z7 = forward_propagation(X, parameters, drop_rate)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(Z7, {X: np.random.randn(2,28,28,1), Y: np.random.randn(2,10), drop_rate: 0})\n    print(\"Z7 = \" + str(a))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34b557a268d8d0d38f63a1b49e3fe9e3556a11aa"},"cell_type":"code","source":"# Compute Cost\n\ndef compute_cost(Z7, Y):\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z7, labels = Y))\n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14515dd6a621da1a35422aebb0ccf86715c04be6"},"cell_type":"code","source":"# Check cost function\n\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y, drop_rate = create_placeholders(28, 28, 1, 10)\n    parameters = initialize_parameters()\n    Z7 = forward_propagation(X, parameters, drop_rate)\n    cost = compute_cost(Z7, Y)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(cost, {X: np.random.randn(4,28,28,1), Y: np.random.randn(4,10), drop_rate: 0})\n    print(\"cost = \" + str(a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b62ef7807428c2698db5c5553f20cb45d0bbc74"},"cell_type":"code","source":"# Set hyperparameters and optimization function\n\nlearning_rate = 7e-5\nnum_epochs = 20\nbatch_size = 16\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1424eb907c110ce393af0dc2321aec7a049b3347"},"cell_type":"code","source":"def model(X_train, X_dev, X_test, y_train, y_dev, learning_rate = learning_rate, num_epochs = num_epochs, batch_size = batch_size, print_cost = True):\n    \n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    (m_train, n_H0, n_W0, n_C0) = X_train.shape             \n    n_y = y_train.shape[1]                            \n    costs = []                                        # To keep track of the cost\n    if m_train%batch_size !=0:\n        num_batches = (m_train//batch_size) + 1\n    else:\n        num_batches = m_train//batch_size\n    \n    # Create Placeholders of the correct shape\n    \n    X, Y, drop_rate = create_placeholders(n_H0, n_W0, n_C0, n_y)\n    \n\n    # Initialize parameters\n    \n    parameters = initialize_parameters()\n    \n    \n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    \n    Z7 = forward_propagation(X, parameters, drop_rate)\n    \n    \n    # Cost function: Add cost function to tensorflow graph\n    \n    cost = compute_cost(Z7, Y)\n    \n    \n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n    \n    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n    \n    \n    # Initialize all the variables globally\n    init = tf.global_variables_initializer()\n  \n\n    # Start the session to compute the tensorflow graph\n    with tf.Session() as sess:\n\n        # Run the initialization\n        sess.run(init)\n\n        for epoch in range(num_epochs):\n            # Generate random batch index\n            minibatch_cost = 0\n            full_batch = range(m_train)\n\n            for batch in range(num_batches):        \n                try:\n                    batch_index = np.random.choice(full_batch, size=batch_size, replace = False)\n                    full_batch = np.array(list(set(full_batch) - set(batch_index)))\n                except ValueError:\n                    batch_index = full_batch\n                batch_train_X = X_train[batch_index]\n                batch_train_y = y_train[batch_index]\n\n                # Run session to reach goal \n\n                sess.run(optimizer, feed_dict={X: batch_train_X, Y: batch_train_y, drop_rate: 0.4})\n                temp_cost = sess.run(cost, feed_dict={X: batch_train_X, Y: batch_train_y, drop_rate: 0})\n                minibatch_cost += temp_cost / num_batches\n\n            # Print the cost every epoch\n            \n            print (\"Cost after epoch %i: %f\" % (epoch+1, minibatch_cost))\n            costs.append(minibatch_cost)\n\n\n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        # Calculate the correct predictions\n        #Z6 = forward_propagation(X, parameters, rate = [1, 1])\n        predict_op = tf.argmax(Z7, 1)\n        #correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n      \n        # Calculate accuracy on the train and dev sets\n        \n        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n        #print(accuracy)\n        #train_accuracy = accuracy.eval({X: X_train, Y: y_train})\n        #dev_accuracy = accuracy.eval({X: X_dev, Y: y_dev})\n        \n        #print(\"Dev Accuracy:\", dev_accuracy)\n        \n        # Make predictions\n        train_preds = np.empty(shape = m_train)\n        for batch in range(num_batches):\n            if batch != num_batches - 1:\n                batch_index = range(batch*batch_size, (batch+1)*batch_size)\n            else:\n                batch_index = range(batch*batch_size,m_train)\n            X_train_batch = X_train[batch_index]\n            Y_train_batch_preds = sess.run(predict_op, feed_dict ={X: X_train_batch, drop_rate: 0})\n            train_preds[batch_index] = Y_train_batch_preds\n            #print('Train batch {} completed'.format(batch+1))\n        \n        m_dev = X_dev.shape[0]\n        dev_preds = np.empty(shape = m_dev)\n        if m_dev%batch_size !=0:\n            num_batches = (m_dev//batch_size) + 1\n        else:\n            num_batches = m_dev//batch_size\n        \n        for batch in range(num_batches):\n            if batch != num_batches - 1:\n                batch_index = range(batch*batch_size, (batch+1)*batch_size)\n            else:\n                batch_index = range(batch*batch_size,m_dev)\n            X_dev_batch = X_dev[batch_index]\n            Y_dev_batch_preds = sess.run(predict_op, feed_dict ={X: X_dev_batch, drop_rate: 0})\n            dev_preds[batch_index] = Y_dev_batch_preds\n        \n        m_test = X_test.shape[0]\n        test_preds = np.empty(shape = m_test)\n        if m_test%batch_size !=0:\n            num_batches = (m_test//batch_size) + 1\n        else:\n            num_batches = m_test//batch_size\n        \n        for batch in range(num_batches):\n            if batch != num_batches - 1:\n                batch_index = range(batch*batch_size, (batch+1)*batch_size)\n            else:\n                batch_index = range(batch*batch_size,m_test)\n            X_test_batch = X_test[batch_index]\n            Y_test_batch_preds = sess.run(predict_op, feed_dict ={X: X_test_batch, drop_rate: 0})\n            test_preds[batch_index] = Y_test_batch_preds\n            #print('Train batch {} completed'.format(batch+1))\n        #train_preds = sess.run(predict_op, feed_dict ={X:X_train})\n        #test_preds = sess.run(predict_op, feed_dict ={X:X_test})\n        train_accuracy = np.mean(train_preds.astype(int)==np.argmax(y_train,1))\n        print(\"Train Accuracy:\", train_accuracy)\n        dev_accuracy = np.mean(dev_preds.astype(int)==np.argmax(y_dev,1))\n        print(\"Dev Accuracy:\", dev_accuracy)\n        \n        return parameters, train_preds, dev_preds, test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39eb91f805c96e5b2004c075bd78418a4e553c4e"},"cell_type":"code","source":"parameters, train_preds, dev_preds, test_preds = model(X_train, X_dev, X_test, y_train, y_dev)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3962ce830fc3846d62d3072e13124ab6ab3e8113"},"cell_type":"markdown","source":"# 5. Check random sample prediction from test set"},{"metadata":{"trusted":true,"_uuid":"da536bff85627e615ccbf8acf15f461d6cf0ff2f"},"cell_type":"code","source":"i = np.random.choice(m_test)\nprint(\"Test sample no.: {}\".format(i))\n\nprint('Prediction: {}'.format(test_preds[i]))\nplt.imshow(X_test[i,:,:,0],cmap = plt.get_cmap('gray'))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42ab8a68a5221c01b37496a4d2df543f5ab2b532"},"cell_type":"markdown","source":"# 6. Check which ones are incorrect from the validation set"},{"metadata":{"trusted":true,"_uuid":"90e4b4f5eb18a57461f057a10f281bd64ea8c10f"},"cell_type":"code","source":"train_labels = np.argmax(y_train, axis = 1)\ntrain_accuracy = np.mean(train_labels==train_preds.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9074244d96a5aaa4304c8e4d78d958a42896179a"},"cell_type":"code","source":"train_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c46e6e209aafd0936d62f96d783df828a4f00817"},"cell_type":"code","source":"dev_labels = np.argmax(y_dev, axis = 1)\ndev_accuracy = np.mean(dev_labels==dev_preds.astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58eeb8ba4c245989b35bf3282d238cdfc281f0c3"},"cell_type":"code","source":"dev_accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d66cda965e5662599d0a2bf72f78c116458d2b0"},"cell_type":"code","source":"dev_new = pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"137addd13f95d21b21ca2d2e1757e800988b039a"},"cell_type":"code","source":"dev_new['Label'] = dev_labels\ndev_new['Preds'] = dev_preds.astype(int)\nm_dev = X_dev.shape[0]\ndev_new['ImageId'] = list(range(m_dev))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0ac14d46d78b164199e1c33186d036d431a16e7"},"cell_type":"code","source":"dev_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7084010059e09bcbcfc8d3cd88e7d402a78f9a4e"},"cell_type":"code","source":"dev_mismatch = dev_new[dev_new['Label']!=dev_new['Preds']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc089a4b7afd63cd0cd73387ece929c6bd6de9f4"},"cell_type":"code","source":"dev_mismatch.Label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19fd77c7bca435ff4ad253717c4154a5bbca517b"},"cell_type":"code","source":"i = np.random.choice(dev_mismatch['ImageId'])\nprint(\"Image ID.: {}\".format(i))\nprint('Prediction: {}'.format(int(dev_preds[i])))\nprint('Correct Label: {}'.format(dev_labels[i]))\nplt.imshow(X_dev[i,:,:,0],cmap = plt.get_cmap('gray'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a52bb5ddf7deb3712a7367d1f0c1e3bb7afee0b"},"cell_type":"markdown","source":"# 7. Write submission file"},{"metadata":{"trusted":true,"_uuid":"7920a2c86f28d8fb7296c4c3a45ae44622913958"},"cell_type":"code","source":"test['Label'] = test_preds.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3174fe6cb9815f6d9fbb58299ce77121b543a931"},"cell_type":"code","source":"test['ImageId'] = list(range(1,m_test+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3cbb7e52e1120fcb0153382451891779854773a"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7aba571cbfb731fb946f878ad734ec0ad076840"},"cell_type":"code","source":"test[['ImageId', 'Label']].to_csv('submission_lenet5.csv', index = False, header = ['ImageId','Label'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}