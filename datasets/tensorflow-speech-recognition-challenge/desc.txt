We might be on the verge of too many screens. It seems like everyday, new
versions of common objects are “re-invented” with built-in wifi and bright
touchscreens. A promising antidote to our screen addiction are voice
interfaces. But, for independent makers and entrepreneurs, it’s hard to build
a simple speech detector using free, open data and code. Many voice
recognition datasets require preprocessing before a neural network model can
be built on them. To help with this, TensorFlow recently released the Speech
Commands Datasets. It includes 65,000 one-second long utterances of 30 short
words, by thousands of different people. In this competition, you're
challenged to use the Speech Commands Dataset to build an algorithm that
understands simple spoken commands. By improving the recognition accuracy of
open-sourced voice interface tools, we can improve product effectiveness and
their accessibility.

