{"metadata": {"_change_revision": 0, "_is_fork": false, "language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "version": "3.6.1", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 0, "nbformat": 4, "cells": [{"metadata": {"_uuid": "f02ca183c7b0131276e60b3e95756b0f10cec28d", "collapsed": false, "_cell_guid": "8a069ac4-75fe-4f95-be0d-f629be81eea8", "_execution_state": "idle"}, "outputs": [], "source": "**This kernel illustrates how to calculate the explained variance based on the number PCA components.  It allows to make an informed decision about the trade-off between the complexity reduction and loss in information/explained variance.** ", "execution_count": null, "cell_type": "markdown"}, {"metadata": {"_uuid": "eb91902aeec9b1c4fdbc7d42f4c448e4349a6b11", "collapsed": false, "_cell_guid": "7dd545c3-e035-4e55-a4a6-5f706afb8c13", "_execution_state": "idle"}, "outputs": [], "source": "![Graphical representation][1]\n\n\n  [1]: http://i.imgur.com/NpEphX5.png\n\nImage (c) Coursera / Andrew Ng / Machine Learning", "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "dba63093-2718-c8a8-ec34-fc7012b93476", "_execution_state": "idle", "_uuid": "00f95f126cb009b293fd6ef6bf1de14444d7d3c7"}, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "execution_count": null, "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "d13f1c9d-d77d-071c-f5b4-a0c6d216e8cd", "_execution_state": "idle", "_uuid": "f273aa2c816406bc488b3859456b850453f6ca83"}, "source": "# Let's load data and check if we got what we needed\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\n\nprint (df_train.shape)\nprint (df_test.shape)", "execution_count": null, "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "7fd313a666b1c27b8cfed6f5e479206460bbbc13", "_execution_state": "idle", "_cell_guid": "aabe6f00-f24a-4dbe-b3fb-500f2a02aba3", "collapsed": false}, "source": "# convert categorical values \nnum_train = len(df_train)\nx_all = pd.concat([df_train, df_test])\n\nfor c in x_all.columns:\n    if x_all[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(x_all[c].values))\n        x_all[c] = lbl.transform(list(x_all[c].values))\n\ndf_train = x_all[:num_train]\ndf_test = x_all[num_train:]", "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "90718d43d3e5f8cc1ef0756b4b98c5627555d6c6", "collapsed": false, "_cell_guid": "b99ec876-b6fc-4666-92f8-ba1dcfb78dec", "_execution_state": "idle"}, "outputs": [], "source": "#df_train = StandardScaler().fit_transform(df_train)", "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "0898bc822e9b91790258fa644ce8f1d60c297688", "collapsed": false, "_cell_guid": "2f8e8ac4-d666-42f2-b538-f3e9f6f89fb6", "_execution_state": "idle"}, "outputs": [], "source": "def calculate_optimal_n_comp(df):\n    U, s, V = np.linalg.svd(df, full_matrices=True)\n    total = np.sum(s)\n    ksum = 0\n    for i in range(0, s.shape[0]):\n        ksum += s[i]\n        print(\"n_comp {} - {:.10f}% variance explained \".format(i+1,(ksum/total)*100))", "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "9859dd07c24d42f632055611f2b27e99961c8968", "collapsed": false, "_cell_guid": "bee3742d-cba5-4a7b-9635-f71da1137d42", "_execution_state": "idle"}, "outputs": [], "source": "calculate_optimal_n_comp(df_train)", "execution_count": null, "cell_type": "code"}]}