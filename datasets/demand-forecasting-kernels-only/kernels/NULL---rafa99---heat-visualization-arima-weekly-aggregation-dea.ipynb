{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e65da7cfe7366f45dd7fa255adacbf386d7464d"},"cell_type":"markdown","source":"1. Initial analysis of the data\n    -we agregate different items to see general evolution at a store level\n                ...Conclusion: Very regular patterns, a-increase in anual sales b-seasonal(yearly&weekday) \n    -we calculate sales at item-store level looking for some potential clustering. We visualize with heat-map\n                ...Conclusion: Variations between itemstore each year are also regular\n  2. We agregate weekly  item-store sales. We built an ARIMA model for one item-store.\n  3. We predict on a weekly basis and after we desagregate to daily forecast using itemstore individual weekly pattern"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy.ma as ma\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nfrom sklearn import preprocessing\nimport os #mod\nimport glob #mod\ncolor = sns.color_palette()\nimport sys\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.options.display.max_columns = 999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b265ac3ed8a94da0a444a2cb64bde5af328b06f7"},"cell_type":"code","source":"os.getcwd() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c038076fc2b58130c54462cf709dec4b5c4d459b"},"cell_type":"code","source":"print(glob.glob(\"/kaggle/working/*.*\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebb70c191e971d1edaea55a0d75997223848dc3f"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint(\"Train shape : \", train_df.shape)\nprint(\"Test shape : \", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11fa2d874ab1f118c2413d2ef805302088aef2ea"},"cell_type":"code","source":"#we create some new fields to easy manipulate\n#forecasting probably should be at item-store because demand pattens could vary much dep. items and store \ntrain_df['weekday']=pd.DatetimeIndex(train_df['date']).weekday\ntrain_df['month']=pd.DatetimeIndex(train_df['date']).month \ntrain_df['year']=pd.DatetimeIndex(train_df['date']).year\ntrain_df['itemstore']=train_df.item.astype(str)+\"-\"+train_df.store.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7295f1740b480943fadbc96e641787a42d151036"},"cell_type":"code","source":"#overview of data\nprint(\"number of different items: %i\" %(len(np.unique(train_df.item))))\nprint(\"number of different stores: %i\" %(len(np.unique(train_df.store))))\nprint(\"number of different dates: %i\" %(len(np.unique(train_df.date))))\nprint(\"maximun date in data: %s\" %(max(train_df.date)))\nprint(\"minimum date in data: %s\" %(min(train_df.date)))\nprint(\"number of different itemstore: %i\" %(len(np.unique(train_df.itemstore))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b6494fa648f75f79072d70265be137760936ab6"},"cell_type":"code","source":"#plot values to see range \nplt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.sales.values))\nplt.xlabel('index', fontsize=12)\nplt.ylabel('sales', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64c11039d968160d616497d4e3bb7a4071dcf46a"},"cell_type":"code","source":"#create some lists to see range of unique values\nstores = list(set(train_df.store))\nitem = list(set(train_df.item))\nitemstore = list(set(train_df.itemstore))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbc1b4c91aff166bbcde1dbbe3179f439ef53e35"},"cell_type":"code","source":"#we check anual sales profile comparing stores\nc=train_df.groupby(['year','store']).sum()\nplt.figure(figsize=(15,10))\nd=c.unstack()\nd.plot(y='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e90d81539673a7059713dc2dc3ba2fb1e67c83b"},"cell_type":"code","source":"#we check seasonal sales profile comparing stores\nc=train_df.groupby(['month', 'store']).sum()\nplt.figure(figsize=(15,10))\nd=c.unstack()\nd.plot(y='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76e4f25dea59249d3b5c3493ecb445b27d952e12"},"cell_type":"code","source":"#we check seasonal sales profile comparing stores\nc=train_df.groupby(['weekday', 'store']).sum()\nplt.figure(figsize=(15,10))\nd=c.unstack()\nd.plot(y='sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76f3390a39f596f40493c08f29fa748c67f4db67"},"cell_type":"code","source":"#we evaluate increase in anual sales at itemstore level\nb =train_df.drop(columns=['store', 'item','weekday','date','month'])\nc=b.groupby(['year', 'itemstore']).sum()\nd=c.unstack()\nsales_itemstore_year=d.T\nsales_itemstore_year['delta_2014/2013']=((sales_itemstore_year[2014]-sales_itemstore_year[2013])/sales_itemstore_year[2013])*100\nsales_itemstore_year['delta_2015/2014']=((sales_itemstore_year[2015]-sales_itemstore_year[2014])/sales_itemstore_year[2014])*100\nsales_itemstore_year['delta_2016/2015']=((sales_itemstore_year[2016]-sales_itemstore_year[2015])/sales_itemstore_year[2015])*100\nsales_itemstore_year['delta_2017/2016']=((sales_itemstore_year[2017]-sales_itemstore_year[2016])/sales_itemstore_year[2016])*100\nsales_itemstore_year_deltas =sales_itemstore_year.drop(columns=[2013, 2014, 2015, 2016, 2017], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b72c8c9cc8ca41bcc8dd7546f93a2fdb66472a15"},"cell_type":"code","source":"sales_itemstore_year_deltas =sales_itemstore_year.drop(columns=[2013, 2014, 2015, 2016, 2017], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1a24086070648d4d17649e7c490bc731c962644"},"cell_type":"code","source":"#heat-maps to compare deltas anual and bet. itemstore each year\nsales_itemstore_year_deltas=sales_itemstore_year_deltas.sort_values('delta_2014/2013')\nplt.figure(figsize=(8,10))\nsns.heatmap(sales_itemstore_year_deltas)\nplt.title(\"Percentage variation sales-itemstore. Sort 2014/2013\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cad8344e7da6577b58a9e45f0eade1cc700e4cdb"},"cell_type":"code","source":"sales_itemstore_year_deltas=sales_itemstore_year_deltas.sort_values('delta_2015/2014')\nplt.figure(figsize=(8,10))\nsns.heatmap(sales_itemstore_year_deltas)\nplt.title(\"Percentage variation sales-itemstore. Sort 2015/2014\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"654c8676946435d07b437863357e6c57e322ec4a"},"cell_type":"code","source":"sales_itemstore_year_deltas=sales_itemstore_year_deltas.sort_values('delta_2016/2015')\nplt.figure(figsize=(8,10))\nsns.heatmap(sales_itemstore_year_deltas)\nplt.title(\"Percentage variation sales-itemstore. Sort 2016/2015\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"155c125c12f8e701c351654c38c7191030ce4cf9"},"cell_type":"code","source":"sales_itemstore_year_deltas=sales_itemstore_year_deltas.sort_values('delta_2017/2016')\nplt.figure(figsize=(8,10))\nsns.heatmap(sales_itemstore_year_deltas)\nplt.title(\"Percentage variation sales-itemstore. Sort 2017/2016\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c245f1ed539d716d9380277c050eef5258e3660"},"cell_type":"code","source":"#we pivot, group to weeks\ntrain_df['date'] = pd.to_datetime(train_df['date'])\ntrain_df_train=train_df.pivot(index='date', columns='itemstore', values='sales')\ntrain_df_train=train_df_train.resample('W').sum()\ntrain_df_train = train_df_train[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8107f3c536a3917098559894830817f06d0b9216"},"cell_type":"code","source":"#we will forescat last 3 months so we keep a last test set to check weekly to dayly deaggregation\ntrain_df_train_V1 = train_df_train[:'2017-09-30']\ntrain_df_test_V1 = train_df_train['2017-10-01':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70a3e8a65b1b0e90d139641b277adaa721b8c05a"},"cell_type":"code","source":"len(train_df_train_V1[t]*0.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2b00c9d375f863708f95c5706e7d1f1f330c71b"},"cell_type":"code","source":"# we search ARIMA parameters for item 1 store 1 with 52 weeks differentation for stationary hip\nimport warnings\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom pandas.core import datetools\n\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return np.array(diff)\n\ndef inverse_difference(history, yhat, interval=1):\n    return yhat + history[-interval]\n\n# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\ndef evaluate_arima_model(X, arima_order):\n# prepare training dataset\n    X = X.astype('float32')\n    train_size = int(len(X) * 0.7)\n    train, test = X[0:train_size], X[train_size:]\n    history = [x for x in train]\n    # make predictions\n    predictions = list()\n    for t in range(len(test)):\n    # difference data\n        weeks_in_year = 52\n        diff = difference(history, weeks_in_year)\n        model = ARIMA(diff, order=arima_order)\n        model_fit = model.fit(trend='nc', disp=0)\n        yhat = model_fit.forecast()[0]\n        yhat = inverse_difference(history, yhat, weeks_in_year)\n        predictions.append(yhat)\n        history.append(test[t])\n        # calculate out of sample error\n    rmse = sqrt(mean_squared_error(test, predictions))\n    return rmse\n# evaluate combinations of p, d and q values for an ARIMA model\ndef evaluate_models(dataset, p_values, d_values, q_values):\n    dataset = dataset.astype('float32')\n    best_score, best_cfg = float(\"inf\"), None\n    for p in p_values:\n        for d in d_values:\n            for q in q_values:\n                order = (p,d,q)\n                try:\n                    rmse = evaluate_arima_model(dataset, order)\n                    if rmse < best_score:\n                        best_score, best_cfg = rmse, order\n                    print('ARIMA%s RMSE=%.3f' % (order,rmse))\n                except:\n                    continue\n    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"748a83a80f9782fb607dd2130831c3fa8a44ca9d"},"cell_type":"code","source":"#evaluate models\np_values = range(0, 6)\nd_values = range(0, 2)\nq_values = range(0, 6)\nt = '1-1'\n\nwarnings.filterwarnings(\"ignore\")\n\nevaluate_models(train_df_train_V1[t].values, p_values, d_values, q_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a336888e06cc86bf89e032309922950a244a278"},"cell_type":"code","source":"t = '1-1'\nX = train_df_train_V1[t].values\nX = X.astype('float32')\n\n# difference data\nweeks_in_year = 52\ndiff = difference(X, weeks_in_year)\nmodel = ARIMA(diff, order=(0,0,3))\nmodel_fit = model.fit(trend='nc', disp=0)\n# bias constant, could be calculated from in-sample mean residual\nbias = -0\n\n# save model\nmodel_fit.save('model.pkl')\nnp.save('model_bias.npy', [bias])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bdd78cc2888559272a3cee797096e005468aa96"},"cell_type":"code","source":"# load and evaluate the finalized model on the validation dataset with a 3 month prediction\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.arima_model import ARIMAResults\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n\n# load and prepare datasets\nX = train_df_train_V1[t].values.astype('float32')\nhistory = [x for x in X]\nweeks_in_year = 52\ny = train_df_test_V1[t].values.astype('float32')\n\n# load model\nmodel_fit = ARIMAResults.load('model.pkl')\nbias = np.load('model_bias.npy')\n\n# multi-step out-of-sample forecast\npredictions = list()\nforecast = model_fit.forecast(steps=13)[0]\nfor yhat in forecast:\n    yhat = bias + inverse_difference(history, yhat, weeks_in_year)\n    history.append(yhat)\n    predictions.append(yhat)\n    print('>Predicted=%.3f' %(yhat))\n\n# report performance\nrmse = sqrt(mean_squared_error(y, predictions))\nprint('RMSE: %.3f' % rmse)\nplt.figure(figsize=(15,10))\nplt.plot(y)\nplt.plot(predictions, color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ba1a8280097b68d91a3078347fe5703869cc92"},"cell_type":"code","source":"#Calculate weekly pattern for each itemstore and apply to weekly prediction\ntrain_df_test_V1=train_df_test_V1.reset_index()\npredictions = pd.DataFrame(predictions)\ntrain_df_test_V1_pred = pd.concat([train_df_test_V1['date'], train_df_test_V1[t], predictions], axis=1)\ntrain_df_test_V1_pred['date'] = pd.to_datetime(train_df_test_V1_pred['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf5308b7f409c31b98a54269c9477e63cd6d5b18"},"cell_type":"code","source":"train_df_test_V1_pred=train_df_test_V1_pred.set_index('date')\nnew_dates = pd.date_range('2017-10-01', '2017-12-31', name='date')\ntrain_df_test_V1_pred_daily = train_df_test_V1_pred.reindex(new_dates, method='ffill')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abc22a22b5eacfa20eacbda072801d70023db3d4"},"cell_type":"code","source":"train_df_test_V1_pred_daily","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e58e5d50865c0e668f3579f282ab84b1ec93f7ce"},"cell_type":"code","source":"train_df = train_df.set_index('date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d02388baa952b36e698a283b4670a7a7938cbe44"},"cell_type":"code","source":"#We predict at item-store and day level so we will de-compose week sales prediction for each itemstore into day sales prediction \n#for each itemstore\n\n#First we asign in a dictionary for each item-store the de-composition of sales for SUN-MON-TUE.......-SAT-SUMA\ndictionary_week_sales_itemstore={}\ndictionary_week_sales_itemstore_reparto={}\nfor i in range (len(itemstore)):\n    dictionary_week_sales_itemstore.update({itemstore[i]:[0, 0, 0, 0, 0, 0, 0, 0]})\n    dictionary_week_sales_itemstore_reparto.update({itemstore[i]:[0, 0, 0, 0, 0, 0, 0, 0]})\n\n#Now we group sales at item-store level and week-day    \n#train_df=train_df.set_index('date')\ntrain_sales_weekday=train_df[:'30-09-2017'].groupby(['weekday', 'itemstore']).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3efd71b8039f849d4575a95367d9d1acba8ef1eb"},"cell_type":"code","source":"#def update_dictionary_week_sales_itemstore(itemstore, train_sales_weekday)\nfor i in range (len(itemstore)):\n    for j in range (0,7):\n        dictionary_week_sales_itemstore[itemstore[i]][j]= train_sales_weekday.loc[(j, itemstore[i]),['sales']][0]\n    dictionary_week_sales_itemstore[itemstore[i]][7]= sum(dictionary_week_sales_itemstore[itemstore[i]][0:7])   \n    \n#Now we update second dictionary dictionary_week_sales_itemstore_reparto={}\nfor i in range (len(itemstore)):\n    for j in range (0,7):\n        dictionary_week_sales_itemstore_reparto[itemstore[i]][j]= (dictionary_week_sales_itemstore[itemstore[i]][j]/   \\\n            dictionary_week_sales_itemstore[itemstore[i]][7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5c588461ddd09b5618430e877415adde8d627af"},"cell_type":"code","source":" dictionary_week_sales_itemstore_reparto['1-1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56576a165e82deefabc0fd94dd7f91d117c89bcb"},"cell_type":"code","source":"for i in range (13):\n    for j in range (7):\n        train_df_test_V1_pred_daily[0][(i*7)+j] = train_df_test_V1_pred_daily[0][(i*7)+j]*  \\\n            dictionary_week_sales_itemstore_reparto[t][j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc902718bf77afa2d519bb12356f50e764cde433"},"cell_type":"code","source":"train_df_test_V1_pred_daily[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"192f4a236f228afb691c5b0323ce4dfda89fd7e9"},"cell_type":"code","source":"train_df_test_V1_pred_daily[0]=round(train_df_test_V1_pred_daily[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d49181827af57f4926bd15a2ea14d397169d915"},"cell_type":"code","source":"train_df_test_V1_pred_daily[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bf4f2e490ca9b64ee2ff92b1ab5b54f2222a7bc"},"cell_type":"code","source":"train_df=train_df.reset_index()\ntrain_df_2017=train_df.pivot(index='date', columns='itemstore', values='sales')\ny_d = train_df_2017['1-1']['2017-10-01':].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ad978d462f7ec503ba4701c4e9b765c4335c25b"},"cell_type":"code","source":"predictions_d = train_df_test_V1_pred_daily[0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa8fbd8a6fcbd063e9577f94b59b382f86b2ca6d"},"cell_type":"code","source":"predictions_d[91]=21","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"496ef2057f2f7feb2170842ade782da4cf633fdc"},"cell_type":"code","source":"# report performance\nrmse = sqrt(mean_squared_error(y_d, predictions_d))\nprint('RMSE: %.3f' % rmse)\nplt.figure(figsize=(15,10))\nplt.plot(y_d)\nplt.plot(predictions_d, color='red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee4b19e3b5623b0fdae8656bb3a8cfd8a3586d0d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}