{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python"}}, "cells": [{"metadata": {"_cell_guid": "3cde9785-0990-4a4c-81f5-587aa665127d", "_uuid": "f5249e7a1a1b5f74219c3d567a50b0a2c5f437ff", "collapsed": true}, "outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import pandas as pd\n", "import numpy as np\n", "from datetime import datetime\n", "import xgboost as xgb\n", "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from sklearn.metrics import mean_squared_error\n", "import seaborn as sns\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "air_reserve = pd.read_csv('../input/air_reserve.csv')\n", "air_store_info= pd.read_csv('../input/air_store_info.csv')\n", "air_visit_data = pd.read_csv('../input/air_visit_data.csv')\n", "date_info = pd.read_csv('../input/date_info.csv')\n", "hpg_store_info = pd.read_csv('../input/hpg_store_info.csv')\n", "store_id_relation = pd.read_csv('../input/store_id_relation.csv')\n", "sample_submission = pd.read_csv('../input/sample_submission.csv')\n", "hpg_reserve = pd.read_csv('../input/hpg_reserve.csv')\n", "\n", "air_combined = pd.merge(air_reserve, air_store_info, on='air_store_id', how='outer')\n", "hpg_combined = pd.merge(hpg_reserve, hpg_store_info, on='hpg_store_id', how='left')\n", "\n", "df = store_id_relation.merge(hpg_combined, on='hpg_store_id', how='left')\n", "df2 = air_combined.merge(df, on='air_store_id', how='left')"], "execution_count": 1}, {"metadata": {}, "cell_type": "markdown", "source": ["## Combine air and hpg files together then merge on store_id_relation, 'air_store_id' is primary key."]}, {"metadata": {}, "outputs": [], "cell_type": "code", "source": ["master_col = df2[['air_store_id']]\n", "df2.head(5)"], "execution_count": 3}, {"metadata": {}, "cell_type": "markdown", "source": ["## 11171047 entries in 'air_store_id', with 829 unique restaurants."]}, {"metadata": {}, "outputs": [], "cell_type": "code", "source": ["print(df2.info())\n", "print(len(df2['air_store_id'].value_counts()))"], "execution_count": 5}, {"metadata": {}, "cell_type": "markdown", "source": ["## Add features to date_info"]}, {"metadata": {}, "outputs": [], "cell_type": "code", "source": ["date_info['calendar_date'] = pd.to_datetime(date_info['calendar_date']).dt.date.astype(str)\n", "#date_info['holiday_flg'] = date_info['holiday_flg'].map({1: 'Yes', 0: 'No'})\n", "date_info['MTWTF'] = date_info['day_of_week'].map({'Monday': 1, \n", "                                                   'Tuesday': 2, \n", "                                                   'Wednesday': 3, \n", "                                                   'Thursday': 4, \n", "                                                   'Friday': 5,\n", "                                                   'Saturday': 6, \n", "                                                   'Sunday': 7})\n", "\n", "date_info['weekend_or_weekday'] = date_info['day_of_week'].map({'Monday': 0, \n", "                                                                'Tuesday': 0, \n", "                                                                'Wednesday': 0, \n", "                                                                'Thursday': 0, \n", "                                                                'Friday': 0,\n", "                                                                'Saturday': 1, \n", "                                                                'Sunday': 1})\n", "date_info2 = date_info.drop(['day_of_week'], axis=1)\n", "date_info2.head(5)"], "execution_count": 7}, {"metadata": {}, "cell_type": "markdown", "source": ["## Join sample_submission with date_info"]}, {"metadata": {}, "outputs": [], "cell_type": "code", "source": ["sub_store = sample_submission['id'].apply(lambda x: str(x).split('_', 2)[:2])\n", "sub_dates = pd.to_datetime(sample_submission['id'].apply(lambda x: str(x).split('_', 2)[2]).rename('Date'))\n", "sub_stores = pd.Series(['_'.join(x) for x in sub_store]).rename('air_store_id')\n", "\n", "sub_dt = pd.DataFrame({\n", "        'air_store_id': sub_stores,\n", "        'date': sub_dates.dt.date.astype(str),\n", "        #'year': sub_dates.dt.year,\n", "        'month': sub_dates.dt.month,\n", "        'day': sub_dates.dt.day })\n", "\n", "sub_df = pd.concat([sample_submission, sub_dt], axis=1)\n", "sub_df2 = sub_df.merge(date_info2, left_on= sub_df['date'], right_on=date_info['calendar_date'])\n", "sub_df3 = sub_df2.drop(['id', 'calendar_date', 'date'], axis =1)\n", "sub_df3.head(5)"], "execution_count": 8}, {"metadata": {}, "cell_type": "markdown", "source": ["## Split datetime columns, and join with date_info"]}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ["a = pd.to_datetime(df2['visit_datetime_x'])\n", "#b = pd.to_datetime(df2['reserve_datetime_x'])\n", "#c = pd.to_datetime(df2['visit_datetime_y'])\n", "#d = pd.to_datetime(df2['reserve_datetime_y'])\n", "\n", "datetime_df =pd.DataFrame({\n", "        'air_visit_date': a.dt.date.astype(str),\n", "        #'year': a.dt.year,\n", "        'month': a.dt.month,\n", "        'day': a.dt.day,\n", "        \n", "        #'air_visit_hour': a.dt.hour,\n", "        #'air_visit_date': a.dt.date,\n", "        #'air_visit_year': b.dt.year,\n", "        \n", "        #'air_reserve_month': b.dt.month,\n", "        #'air_reserve_day': b.dt.day,\n", "        #'air_reserve_hour': b.dt.hour,\n", "         \n", "        #'hpg_visit_date': c.dt.date,\n", "        #'hpg_visit_year': c.dt.year,\n", "        #'hpg_visit_month': c.dt.month,\n", "        #'hpg_visit_day': c.dt.day,\n", "        #'hpg_visit_hour': c.dt.hour,\n", "        \n", "        #'hpg_reserve_date': d.dt.date,\n", "        #'hpg_reserve_year': d.dt.year,\n", "        #'hpg_reserve_month': d.dt.month,\n", "        #'hpg_reserve_day': d.dt.day,\n", "        #'hpg_reserve_hour': d.dt.hour        \n", "    }).fillna(0)\n", "\n", "datetime_df2 = datetime_df.merge(date_info, left_on=datetime_df['air_visit_date'], \n", "                                 right_on=date_info['calendar_date'])"], "execution_count": 9}, {"metadata": {}, "cell_type": "markdown", "source": ["## Encode all categorical variable, then join with sample_submission and training set"]}, {"metadata": {}, "outputs": [], "cell_type": "code", "source": ["lbl = LabelEncoder()\n", "categorical_df = pd.concat([master_col, df2[['air_genre_name','air_area_name','latitude_x','longitude_x',\n", "                      'hpg_genre_name','hpg_area_name']].fillna('None_Stated').apply(lbl.fit_transform)], axis=1)\n", "\n", "#categorical_dummy = pd.get_dummies(df2[['air_genre_name','air_area_name','latitude','longitude', 'hpg_genre_name','hpg_area_name']].fillna('None_Stated'))\n", "\n", "sub_df4 = sub_df3.merge(categorical_df, left_on=sub_df3['air_store_id'], right_on=categorical_df['air_store_id'])  \n", "\n", "combined_visitors = pd.Series(df2['reserve_visitors_x'].fillna(0) + df2['reserve_visitors_y'].fillna(0)).rename('visitors')\n", "\n", "\n", "train_df = pd.concat([datetime_df2, combined_visitors, categorical_df], axis=1)"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["## Encode all air_store_id together, then drop all unneeded columns "]}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ["lbl= LabelEncoder()\n", "ids = lbl.fit_transform(feats['air_store_id'].append(sub_df4['air_store_id_x']))\n", "train_df['air_store_id_num'] = pd.Series(ids[:1171046])\n", "sub_df4['air_store_id_num'] = pd.Series(ids[1171047:])\n", "\n", "train_df2 = train_df.drop(['air_store_id', 'air_visit_date', 'calendar_date', 'day_of_week'], axis=1)\n", "sub_df5 = sub_df4.drop(['air_store_id_x', 'air_store_id_y'], axis=1).reindex(columns=list(train_df2.columns.values))"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["##  Statistics of visitors grouped by store, and day of week."]}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ["vis_store = train_df2['visitors'].groupby(train_df2['air_store_id_num']).describe()\n", "vis_dow = train_df2['visitors'].groupby(train_df2['MTWTF']).describe()\n", "vis_store_dow = train_df2['visitors'].groupby([train_df2['air_store_id_num'], train_df2['MTWTF']]).describe()"], "execution_count": 3}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ["vis_store_dow.head(15)"], "execution_count": null}, {"metadata": {}, "cell_type": "markdown", "source": ["## XGB Regressor without  tuning"]}, {"metadata": {"collapsed": true}, "outputs": [], "cell_type": "code", "source": ["X_train, X_test, y_train, y_test = train_test_split(train_df2, train_df2['visitors'], test_size=0.1, random_state=7)\n", "\n", "xgbR = XGBRegressor(learning_rate=0.1,\n", "                   objective='reg:linear')\n", "xgbR.fit(X_train, y_train)\n", "\n", "def rmsle(h, y): \n", "    \"\"\"\n", "    Compute the Root Mean Squared Log Error for hypthesis h and targets y\n", "\n", "    Args:\n", "        h - numpy array containing predictions with shape (n_samples, n_targets)\n", "        y - numpy array containing targets with shape (n_samples, n_targets)\n", "    \"\"\"\n", "    return np.sqrt(np.square(np.log(h + 1) - np.log(y + 1)).mean())\n", "\n", "\n", "pred = xgbR.predict(X_test)\n", "mse = rmsle(pred, y_test)\n", "print(mse)"], "execution_count": null}], "nbformat": 4, "nbformat_minor": 1}