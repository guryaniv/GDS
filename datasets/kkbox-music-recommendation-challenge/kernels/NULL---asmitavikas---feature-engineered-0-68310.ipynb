{"metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4, "cells": [{"outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np\n", "import pandas as pd\n", "import lightgbm as lgb\n", "import datetime\n", "import math\n", "import gc\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "metadata": {"_uuid": "c8542907ead88c658cfe43c79118b30fc19487bf", "_cell_guid": "216be500-721f-45ac-ab63-6b0b67ec5fb9"}}, {"outputs": [], "cell_type": "code", "source": ["print('Loading data...')\n", "data_path = '../input/'\n", "train = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n", "                                                'source_system_tab' : 'category',\n", "                                                  'source_screen_name' : 'category',\n", "                                                  'source_type' : 'category',\n", "                                                  'target' : np.uint8,\n", "                                                  'song_id' : 'category'})\n", "test = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n", "                                                'source_system_tab' : 'category',\n", "                                                'source_screen_name' : 'category',\n", "                                                'source_type' : 'category',\n", "                                                'song_id' : 'category'})\n", "songs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n", "                                                  'language' : 'category',\n", "                                                  'artist_name' : 'category',\n", "                                                  'composer' : 'category',\n", "                                                  'lyricist' : 'category',\n", "                                                  'song_id' : 'category'})\n", "members = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n", "                                                      'bd' : np.uint8,\n", "                                                      'gender' : 'category',\n", "                                                      'registered_via' : 'category'},\n", "                     parse_dates=['registration_init_time','expiration_date'])\n", "songs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\n", "print('Done loading...')"], "execution_count": null, "metadata": {"_uuid": "81f223f194c6f6f8fb54b908a434a527a3f66c8c", "_cell_guid": "91dfcb80-f6a5-48b8-b889-2b4df0e4a4e1"}}, {"outputs": [], "cell_type": "code", "source": ["print('Data merging...')\n", "\n", "\n", "train = train.merge(songs, on='song_id', how='left')\n", "test = test.merge(songs, on='song_id', how='left')\n", "\n", "members['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n", "\n", "members['registration_year'] = members['registration_init_time'].dt.year\n", "members['registration_month'] = members['registration_init_time'].dt.month\n", "members['registration_date'] = members['registration_init_time'].dt.day\n", "\n", "members['expiration_year'] = members['expiration_date'].dt.year\n", "members['expiration_month'] = members['expiration_date'].dt.month\n", "members['expiration_date'] = members['expiration_date'].dt.day\n", "members = members.drop(['registration_init_time'], axis=1)\n", "\n", "def isrc_to_year(isrc):\n", "    if type(isrc) == str:\n", "        if int(isrc[5:7]) > 17:\n", "            return 1900 + int(isrc[5:7])\n", "        else:\n", "            return 2000 + int(isrc[5:7])\n", "    else:\n", "        return np.nan\n", "        \n", "songs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\n", "songs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n", "\n", "train = train.merge(members, on='msno', how='left')\n", "test = test.merge(members, on='msno', how='left')\n", "\n", "train = train.merge(songs_extra, on = 'song_id', how = 'left')\n", "train.song_length.fillna(200000,inplace=True)\n", "train.song_length = train.song_length.astype(np.uint32)\n", "train.song_id = train.song_id.astype('category')\n", "\n", "\n", "test = test.merge(songs_extra, on = 'song_id', how = 'left')\n", "test.song_length.fillna(200000,inplace=True)\n", "test.song_length = test.song_length.astype(np.uint32)\n", "test.song_id = test.song_id.astype('category')\n", "\n", "# import gc\n", "# del members, songs; gc.collect();\n", "\n", "print('Done merging...')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "95fae49636554eeb26dde3370054fbf6788335a8", "_cell_guid": "24e253c9-b8f8-4c56-b1a5-5faa9bb17c8d"}}, {"outputs": [], "cell_type": "code", "source": ["print (\"Adding new features\")\n", "\n", "def genre_id_count(x):\n", "    if x == 'no_genre_id':\n", "        return 0\n", "    else:\n", "        return x.count('|') + 1\n", "\n", "train['genre_ids'].fillna('no_genre_id',inplace=True)\n", "test['genre_ids'].fillna('no_genre_id',inplace=True)\n", "train['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\n", "test['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n", "\n", "def lyricist_count(x):\n", "    if x == 'no_lyricist':\n", "        return 0\n", "    else:\n", "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n", "    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n", "\n", "train['lyricist'].fillna('no_lyricist',inplace=True)\n", "test['lyricist'].fillna('no_lyricist',inplace=True)\n", "train['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\n", "test['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n", "\n", "def composer_count(x):\n", "    if x == 'no_composer':\n", "        return 0\n", "    else:\n", "        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n", "\n", "train['composer'].fillna('no_composer',inplace=True)\n", "test['composer'].fillna('no_composer',inplace=True)\n", "train['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\n", "test['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n", "\n", "def is_featured(x):\n", "    if 'feat' in str(x) :\n", "        return 1\n", "    return 0\n", "\n", "train['artist_name'].fillna('no_artist',inplace=True)\n", "test['artist_name'].fillna('no_artist',inplace=True)\n", "train['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\n", "test['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n", "\n", "def artist_count(x):\n", "    if x == 'no_artist':\n", "        return 0\n", "    else:\n", "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n", "\n", "train['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\n", "test['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n", "\n", "# if artist is same as composer\n", "train['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\n", "test['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n", "\n", "\n", "# if artist, lyricist and composer are all three same\n", "train['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\n", "test['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n", "\n", "# is song language 17 or 45. \n", "def song_lang_boolean(x):\n", "    if '17.0' in str(x) or '45.0' in str(x):\n", "        return 1\n", "    return 0\n", "\n", "train['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\n", "test['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n", "\n", "\n", "_mean_song_length = np.mean(train['song_length'])\n", "def smaller_song(x):\n", "    if x < _mean_song_length:\n", "        return 1\n", "    return 0\n", "\n", "train['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\n", "test['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n", "\n", "# number of times a song has been played before\n", "_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n", "_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\n", "def count_song_played(x):\n", "    try:\n", "        return _dict_count_song_played_train[x]\n", "    except KeyError:\n", "        try:\n", "            return _dict_count_song_played_test[x]\n", "        except KeyError:\n", "            return 0\n", "    \n", "\n", "train['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\n", "test['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n", "\n", "# number of times the artist has been played\n", "_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n", "_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\n", "def count_artist_played(x):\n", "    try:\n", "        return _dict_count_artist_played_train[x]\n", "    except KeyError:\n", "        try:\n", "            return _dict_count_artist_played_test[x]\n", "        except KeyError:\n", "            return 0\n", "\n", "train['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\n", "test['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n", "\n", "\n", "print \"Done adding features\""], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "2f5475aa07fa7f4b59e8e8928d03f67bbcac9347", "_cell_guid": "6d0e7314-91f0-4ff5-9081-ebdcb9b1406d"}}, {"outputs": [], "cell_type": "code", "source": ["print (\"Train test and validation sets\")\n", "for col in train.columns:\n", "    if train[col].dtype == object:\n", "        train[col] = train[col].astype('category')\n", "        test[col] = test[col].astype('category')\n", "\n", "\n", "X_train = train.drop(['target'], axis=1)\n", "y_train = train['target'].values\n", "\n", "\n", "X_test = test.drop(['id'], axis=1)\n", "ids = test['id'].values\n", "\n", "\n", "# del train, test; gc.collect();\n", "\n", "d_train_final = lgb.Dataset(X_train, y_train)\n", "watchlist_final = lgb.Dataset(X_train, y_train)\n", "print('Processed data...')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "577e8f31dccc7262514f854b96bb213396aea8f6", "_cell_guid": "05ee917e-dc12-4201-8fe6-0b515286253c"}}, {"outputs": [], "cell_type": "code", "source": ["params = {\n", "        'objective': 'binary',\n", "        'metric': 'binary_logloss',\n", "        'boosting': 'gbdt',\n", "        'learning_rate': 0.3 ,\n", "        'verbose': 0,\n", "        'num_leaves': 108,\n", "        'bagging_fraction': 0.95,\n", "        'bagging_freq': 1,\n", "        'bagging_seed': 1,\n", "        'feature_fraction': 0.9,\n", "        'feature_fraction_seed': 1,\n", "        'max_bin': 256,\n", "        'max_depth': 10,\n", "        'num_rounds': 200,\n", "        'metric' : 'auc'\n", "    }\n", "\n", "%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "42e044686bd89948d06c2471892c9542605a8a05", "_cell_guid": "8a7cfb94-afdb-47b1-94d7-88791baa47e5"}}, {"outputs": [], "cell_type": "code", "source": ["params = {\n", "        'objective': 'binary',\n", "        'metric': 'binary_logloss',\n", "        'boosting': 'dart',\n", "        'learning_rate': 0.3 ,\n", "        'verbose': 0,\n", "        'num_leaves': 108,\n", "        'bagging_fraction': 0.95,\n", "        'bagging_freq': 1,\n", "        'bagging_seed': 1,\n", "        'feature_fraction': 0.9,\n", "        'feature_fraction_seed': 1,\n", "        'max_bin': 256,\n", "        'max_depth': 10,\n", "        'num_rounds': 200,\n", "        'metric' : 'auc'\n", "    }\n", "\n", "%time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "a2e8293a6c5ff0c0efdb52fb82f053cfb773e55c", "_cell_guid": "10895c7a-73f8-45a0-a9b7-e4e489b06268"}}, {"outputs": [], "cell_type": "code", "source": ["print('Making predictions')\n", "p_test_1 = model_f1.predict(X_test)\n", "p_test_2 = model_f2.predict(X_test)\n", "p_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n", "\n", "\n", "print('Done making predictions')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "ea33e6b678757c4f45e1cddfac4a37ce06962d33", "_cell_guid": "89048be8-a137-4e0d-811c-740645c17d1a"}}, {"outputs": [], "cell_type": "code", "source": ["print ('Saving predictions Model model of gbdt')\n", "\n", "subm = pd.DataFrame()\n", "subm['id'] = ids\n", "subm['target'] = p_test_avg\n", "subm.to_csv(data_path + 'submission_lgbm_avg.csv.gz', compression = 'gzip', index=False, float_format = '%.5f')\n", "\n", "print('Done!')"], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "28888fb62a1efccb51efb762ac1266695bb82002", "_cell_guid": "e7b31f60-187f-4744-9416-3c9c876fa838"}}], "nbformat_minor": 1}