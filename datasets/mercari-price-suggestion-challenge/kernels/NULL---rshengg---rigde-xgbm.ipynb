{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python"}}, "nbformat": 4, "cells": [{"execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import pandas as pd\n", "import numpy as np\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import csv\n", "import matplotlib.pyplot as plt\n", "import re\n", "# Evalaluation\n", "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import metrics\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "import scipy\n", "import lightgbm as lgb\n", "from sklearn.linear_model import Ridge\n", "import time\n", "import gc\n", "from scipy.sparse import csr_matrix, hstack\n", "get_ipython().magic('pylab inline')\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "df = pd.read_csv(\"../input/train.tsv\", delimiter='\\t')\n", "test = pd.read_csv(\"../input/test.tsv\", delimiter='\\t')\n", "Y = df['price']\n", "train_test_split = df.shape[0]\n", "brand = dict()\n", "\n", "for i in range(len(df['brand_name'])):\n", "    if(not pd.isnull(df['brand_name'][i])):\n", "        if (df['brand_name'][i] not in brand):\n", "            brand[df['brand_name'][i]] = []\n", "        brand[df['brand_name'][i]].append(np.log1p(df['price'][i]))\n", "        \n", "del df['price']\n", "del df['train_id']\n", "del test['test_id']\n", "df = pd.concat([df,test])\n", "df = df.reset_index(drop=True)\n", "split_str = df[\"category_name\"].str.split(\"/\", expand=True, n=2)\n", "split_str.columns = [\"cat1\", \"cat2\", \"cat3\"]\n", "split_str[\"cat2\"][split_str[\"cat2\"].isnull()] = -1\n", "split_str[\"cat3\"][split_str[\"cat3\"].isnull()] = -1\n", "df[\"category1\"] = df[\"category_name\"]\n", "df[\"category2\"] = split_str[\"cat2\"]\n", "df[\"category3\"] = split_str[\"cat3\"]\n", "df[\"category1\"][df[\"category1\"].isnull()] = -1\n", "df.drop(['category_name'], axis=1, inplace=True)\n", "df\n", "\n", "avg_col = []\n", "var_col = []\n", "avg_dict = {}\n", "var_dict = {}\n", "for i in range(len(df['brand_name'])):\n", "    if pd.isnull(df['brand_name'][i]):\n", "        avg_col.append(0)\n", "        var_col.append(0)\n", "    else:\n", "        name = df['brand_name'][i]\n", "        if name not in avg_dict:\n", "            if name not in brand:\n", "                avg_col.append(0)\n", "                var_col.append(0)\n", "                continue\n", "            priceList = brand[name]\n", "            avg_dict[name] = np.mean(priceList)\n", "            var_dict[name] = np.var(priceList)\n", "        avg_col.append(avg_dict[name])\n", "        var_col.append(var_dict[name])\n", "print(len(avg_col), len(var_col))\n", "\n", "df[\"brand_avg\"] = avg_col\n", "df[\"brand_var\"] = var_col\n", "df[\"brand_name\"] = pd.Categorical(df[\"brand_name\"])\n", "df[\"brand_code\"] = df.brand_name.cat.codes\n", "\n", "def change_to_code(colName, df):\n", "    df[colName] = pd.Categorical(df[colName])\n", "    df[colName+\"_code\"] = df[colName].cat.codes\n", "for category in [\"category1\", \"category2\", \"category3\"]:\n", "    change_to_code(category, df)\n", "    \n", "df['name'] = df['name'].fillna('missing')\n", "df['item_description'] = df['item_description'].fillna('missing')\n", "\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "count = CountVectorizer(min_df=10)\n", "X_name = count.fit_transform(df[\"name\"])\n", "\n", "count_descp = TfidfVectorizer(max_features = 20000, \n", "                              ngram_range = (1,3),\n", "                              stop_words = \"english\")\n", "X_descp = count_descp.fit_transform(df[\"item_description\"])\n", "del df['name']\n", "del df['item_description']\n", "del df['brand_name']\n", "del df['category1']\n", "del df['category2']\n", "del df['category3']\n", "import scipy\n", "item_condition_dummy = pd.get_dummies(df['item_condition_id'])\n", "item_condition_dummy.columns = [\"c1\", \"c2\", \"c3\", \"c4\", \"c5\"]\n", "df = pd.concat([df, item_condition_dummy], axis=1)\n", "del df['item_condition_id']\n", "Y = np.log1p(Y)\n", "print(df)\n", "sparse_matrix = scipy.sparse.csr_matrix(df.values)\n", "X = scipy.sparse.hstack((sparse_matrix, \n", "                         X_descp,\n", "                         X_name)).tocsr()\n", "\n", "print(X.shape)\n", "train_test_split = 1482535\n", "train_X = X[:train_test_split]\n", "test_X = X[train_test_split:]\n", "\n", "test = pd.read_csv(\"test.tsv\", delimiter='\\t')\n", "submission: pd.DataFrame = test[['test_id']]\n", "def trainAndTest(X_train, Y_train, X_test):\n", "    \n", "    model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3)\n", "    model.fit(X_train, Y_train)\n", "    predsR = model.predict(X=X_test)\n", "    print('Predict ridge completed')\n", "    \n", "    model = Ridge(solver=\"auto\", fit_intercept=True, random_state=144, alpha=3)\n", "    model.fit(X_train, Y_train)\n", "    predsR2 = model.predict(X=X_test)\n", "    print('Predict ridge 2 completed.')\n", "    \n", "    X_train_train, X_train_valid, Y_train_train, Y_train_valid = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 144) \n", "    d_train = lgb.Dataset(X_train_train, label=Y_train_train, max_bin=8192)\n", "    d_valid = lgb.Dataset(X_train_valid, label=Y_train_valid, max_bin=8192)\n", "    watchlist = [d_train, d_valid]\n", "    \n", "    params = {\n", "        'learning_rate': 0.65,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 60,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 1,\n", "        'bagging_fraction': 0.5,\n", "        'nthread': 4\n", "    }\n", "\n", "    params2 = {\n", "        'learning_rate': 0.85,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 140,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 2,\n", "        'bagging_fraction': 1,\n", "        'nthread': 4\n", "    }\n", "    model = lgb.train(params, train_set=d_train, num_boost_round=8000, valid_sets=watchlist, \\\n", "    early_stopping_rounds=500, verbose_eval=500) \n", "    predsL = model.predict(X_test)\n", "    print('Finished to predict lgb 1')\n", "    X_train_train, X_train_valid, Y_train_train, Y_train_valid = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 101) \n", "    d_train2 = lgb.Dataset(X_train_train, label=Y_train_train, max_bin=8192)\n", "    d_valid2 = lgb.Dataset(X_train_valid, label=Y_train_valid, max_bin=8192)\n", "    watchlist2 = [d_train2, d_valid2]\n", "    \n", "    model = lgb.train(params2, train_set=d_train2, num_boost_round=4000, valid_sets=watchlist2, \\\n", "    early_stopping_rounds=500, verbose_eval=500) \n", "    predsL2 = model.predict(X_test)\n", "    print('Finished to predict lgb 2')\n", "    \n", "#     preds = predsR2*0.20 + predsR*0.20 + predsL*0.40 + predsL2*0.20\n", "#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n", "    \n", "#     preds = predsR2*0.19 + predsR*0.19 + predsL*0.44 + predsL2*0.18\n", "#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n", "    \n", "#     preds = predsR2*0.18 + predsR*0.18 + predsL*0.45 + predsL2*0.19\n", "#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n", "    \n", "#     preds = predsR2*0.17 + predsR*0.17 + predsL*0.46 + predsL2*0.20\n", "#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n", "    \n", "    preds = predsR2*0.16 + predsR*0.16 + predsL*0.48 + predsL2*0.20\n", "    submission['price'] = np.expm1(preds)\n", "    submission.to_csv(\"submission.csv\", index=False)\n", "#     print(np.sqrt(mean_squared_log_error(np.expm1(preds),np.expm1(Y_test))))\n", "\n", "from sklearn.model_selection import train_test_split\n", "trainAndTest(train_X, Y, test_X)\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "metadata": {"_cell_guid": "8bd107a5-25f3-40a7-b779-ae8de8e2626b", "_uuid": "178935477b05113e10509214e41ad4d392792a52"}, "outputs": []}], "nbformat_minor": 1}