{"cells":[{"metadata":{"_execution_state":"idle","_uuid":"93d4aa0b93fb1f05c0d6d6d28b33108aad9db847","_cell_guid":"2b789bb2-5f39-840f-a1be-837736094542"},"cell_type":"markdown","source":"# &#x1F4D1; &nbsp;  Digit Recognition Models #2"},{"metadata":{"_uuid":"af4758b544d1fa97cb4bb65ce22b03713daae0dd","_cell_guid":"62d571a6-c7c7-d38e-8e30-663c7f7e9faa"},"cell_type":"markdown","source":"## Links\n[SciPy. Multi-dimensional image processing](https://docs.scipy.org/doc/scipy/reference/ndimage.html)\n\n[Keras. Deep Learning library for Theano and TensorFlow](https://keras.io/)\n \n[TensorFlow. Deep MNIST for Experts](https://www.tensorflow.org/get_started/mnist/pros)\n\n[Tensorflow Deep MNIST Advanced Tutorial](http://docs.seldon.io/tensorflow-deep-mnist-example.html)\n\n[Handwritten Digit Recognition using Convolutional Neural Networks in Python with Keras](http://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/)\n\n## Other variants of this  project\n\n [Digit Recognition Models](https://olgabelitskaya.github.io/kaggle_digits.html)\n \n [Colaboratory Notebook](https://drive.google.com/open?id=1B1qh4ySXeJlWDMAXxAgHtS3jsyNdsmrn)\n\n#### P5: Build a Digit Recognition Program\n\n- https://olgabelitskaya.github.io/MLE_ND_P5_V0_S1.html\n\n- https://olgabelitskaya.github.io/MLE_ND_P5_V0_S2.html\n\n- https://olgabelitskaya.github.io/MLE_ND_P5_V0_S3.html"},{"metadata":{"_uuid":"2b15219ae1b5ab329a54a3556532648363b6c79a","_cell_guid":"d566a0de-36d9-cc81-27cd-f50f1f360ece"},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"_execution_state":"idle","_uuid":"28de8e16c1d7fcd1e04c426558cb37fbec5cae64","_cell_guid":"2ee0a55f-7769-636c-0394-f08a4891b1fa","trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom time import time\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pylab as plt\nimport matplotlib.cm as cm\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"d0dbdf9e2a802cc5a9205b779d20a8cfe8994376","_cell_guid":"db108d4c-3d76-b238-ccf6-09cc9ca865d1","trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn import linear_model, neighbors, svm, ensemble\nfrom sklearn import datasets, metrics \nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"1d44f8302d1c346626223011f6cef970b7a272f6","_cell_guid":"60d9f6cb-f628-4c35-181b-5d5f2c2b7962","trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom keras.preprocessing import image as keras_image\n\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\n\nfrom keras import backend\nfrom keras import losses\nfrom keras.metrics import top_k_categorical_accuracy, categorical_accuracy\nfrom keras.engine.topology import Layer\nfrom keras.optimizers import Adam, Nadam\nfrom keras.engine import InputLayer\nfrom keras.models import Sequential, load_model, Model\n\nfrom keras.layers import Input, BatchNormalization, Flatten, Dropout\nfrom keras.layers import Dense, LSTM, Activation, LeakyReLU\nfrom keras.layers import Conv2D, MaxPool2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.layers import UpSampling2D, Conv2DTranspose, DepthwiseConv2D\nfrom keras.layers.core import RepeatVector, Permute\nfrom keras.layers import Reshape, concatenate, merge","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95ddf093bbec3262c9b45164ae182639c7730ed6","_cell_guid":"027fa82e-e3a0-428d-a3ea-8aa41219dc5f","trusted":true},"cell_type":"code","source":"from keras import __version__\nprint('keras version:', __version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2caa57b5dd893deadb171530c8ab67f8ca9e8928","_cell_guid":"35144acd-04ae-b516-0fe5-82356ecce6ba"},"cell_type":"markdown","source":"## Datasets"},{"metadata":{"_execution_state":"idle","_uuid":"ac8633c8e78d5983a37f02d340d01b23a7d5fdbb","_cell_guid":"fcffbabb-ab3d-583d-06dc-2be2d6e8f39f","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\")\ndf_test = pd.read_csv(\"../input/test.csv\")\ndf_train.shape","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"be54bdbd3ede6f17f78130880bbc7995d70b2a70","_cell_guid":"125a7d51-03ef-8019-5630-818a667c08d5","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"df_train.ix[15:20,15:25]","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"1d310408e33f96f486d94ca14d2bc10acb3e57f3","_cell_guid":"b535ad43-ca8a-8658-447a-338ab89c8b3d","trusted":true},"cell_type":"code","source":"k = 0.48\nimages = [\"%s%s\" %(\"pixel\",pixel_no) for pixel_no in range(0,784)]\ntrain_images = np.array(df_train[images])\ntrain_images = (train_images.astype('float32') / 255) ** k\n#train_images = (train_images.astype('float32') / 255)\ntrain_images.shape","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"c0a010f06f5802d00a7ec23981bb676a06108dac","_cell_guid":"85e35867-86ac-b0d1-e30d-b09b55461a56","trusted":true},"cell_type":"code","source":"train_labels = df_train['label']\ntrain_labels_cat = to_categorical(train_labels, num_classes=10)\ntrain_labels_cat.shape","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"671a8c7bea1372dc97cbbda33659b8c69cfe29b0","_cell_guid":"7baad270-af67-5637-a943-53af8dcc2626","trusted":true},"cell_type":"code","source":"test_images = np.array(df_test[images])\ntest_images = (test_images.astype('float32') / 255) ** k\ntest_images.shape","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"idle","_uuid":"43fc8c6e9a82e593266eee621de832cca13670a3","_cell_guid":"508eb742-757a-fd4e-a229-c69831633809","trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = \\\ntrain_test_split(train_images, train_labels_cat, \n                 test_size=0.2, random_state=32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc8efb4099642674dcd04974a588f87cefc6a03d","_cell_guid":"379d07ed-ed89-460e-ac45-32b2b56ab88e","trusted":true},"cell_type":"code","source":"n = int(len(X_test)/2)\nX_valid, y_valid = X_test[:n], y_test[:n]\nX_test, y_test = X_test[n:], y_test[n:]\nX_train.shape, X_test.shape, X_valid.shape, \\\ny_train.shape, y_test.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"462987a010ea9cae1db4579fc9b9ee97abb61f69"},"cell_type":"code","source":"y_train_num = np.array([np.argmax(x) for x in y_train])\ny_test_num = np.array([np.argmax(x) for x in y_test])\ny_valid_num = np.array([np.argmax(x) for x in y_valid])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"007b97495f7439724621554d9cca7c9132f713d4","_cell_guid":"7adbe0ab-0789-4ddd-2e26-9d76cdad4e4c"},"cell_type":"markdown","source":"## Examples"},{"metadata":{"_execution_state":"idle","_uuid":"a819810ff3a1d9376ae70c9d66b29adcedd27c7d","_cell_guid":"7b83aa52-4aa6-6e82-db05-7c0e5dcd70af","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 2), nrows=1, ncols=10, sharex=True, sharey=True,)\nax = ax.flatten()\nfor i in range(10):\n    image = train_images[i].reshape(28,28)\n    ax[i].imshow(image, cmap=plt.cm.Blues)\n\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.gcf()\nax[7].set_title('Examples of the 784-dimensional digits', fontsize=25);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"300c213f9c7721d7746fd4b989b747bf930eff34","_cell_guid":"5512fff0-1506-97a9-eb77-060f4545a6df"},"cell_type":"markdown","source":"## Models"},{"metadata":{"_uuid":"c0a1d84c173cd1f60d7a5861113879b996b055f1","_cell_guid":"f0571604-0ace-e1bf-7c45-7c03db463a9b"},"cell_type":"markdown","source":"***Model #1. Convolutional Neural Network. Keras***"},{"metadata":{"_execution_state":"idle","_uuid":"edb38d2204652e62891e6c254c98d7c728e08408","_cell_guid":"3686a7f2-6514-c239-69d1-8ecac4df38b1","trusted":true},"cell_type":"code","source":"def top_3_categorical_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n\ndef cnn_model():\n    model_input = Input(shape=(28, 28, 1))\n    x = BatchNormalization()(model_input)\n    \n    x = Conv2D(28, (5, 5), padding='same')(x)\n    x = LeakyReLU(alpha=0.02)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(128, (5, 5))(x)\n    x = LeakyReLU(alpha=0.02)(x)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.25)(x) \n\n    x = GlobalMaxPooling2D()(x)\n    \n    x = Dense(1024)(x)\n    x = LeakyReLU(alpha=0.02)(x)\n    x = Dropout(0.5)(x)\n    \n    y = Dense(10, activation='softmax')(x)\n    \n    model = Model(input=model_input, output=y)\n    \n    model.compile(loss='categorical_crossentropy', optimizer='nadam', \n                  metrics=[categorical_accuracy, top_3_categorical_accuracy])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"821e00bb31108309e124e83262ad6e4a81a0394d","_cell_guid":"eb392eaa-5ae9-4997-872e-51961a0b32ac","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"cnn_model = cnn_model()\nprint(cnn_model.summary())\ncnn_checkpointer = ModelCheckpoint(filepath='weights.best.digits.cnn.hdf5', \n                                   verbose=2, save_best_only=True)\ncnn_lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n                                     patience=5, verbose=2, factor=0.75)","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"busy","_uuid":"cd16026ab0974caf587d4b7db2232675b7010e56","_cell_guid":"52bcdb8f-12ec-81b0-28d1-c1f6cf563d4c","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"cnn_history = cnn_model.fit(X_train.reshape(-1, 28, 28, 1), y_train, \n                            validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid), \n                            epochs=75, batch_size=128, verbose=2, \n                            callbacks=[cnn_checkpointer, cnn_lr_reduction])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b3c59ae5260f1c1404048b71eb96d4512c251d","_cell_guid":"2c980063-52e3-4ed6-8e43-5925d6f9a99b","trusted":true},"cell_type":"code","source":"cnn_model.load_weights('weights.best.digits.cnn.hdf5')\ncnn_scores = cnn_model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test, verbose=0)\n\nprint(\"CNN Scores: \" , (cnn_scores))\nprint(\"CNN Error: %.2f%%\" % (100 - cnn_scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a66799123ab2c04a96a315876eadaa185d2845dd","_cell_guid":"938ff864-b6d2-4901-be02-b9983d369cec","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nplt.plot(cnn_history.history['categorical_accuracy'][3:], '-o', label = 'train')\nplt.plot(cnn_history.history['val_categorical_accuracy'][3:], '-o', label = 'test')\nplt.legend()\nplt.title('CNN Accuracy');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23c5d6cbd8dcb2c2f005f955b33174ef37a90025","_cell_guid":"ac95953e-2717-4bc8-b5fe-a15fbc17f675","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"steps, epochs = 1000, 20\ndata_generator = \\\nImageDataGenerator(featurewise_std_normalization=True,\n                   zoom_range=0.2, \n                   shear_range=0.2,\n                   rotation_range=20,\n                   height_shift_range=0.2,\n                   width_shift_range=0.2)\n\ndg_cnn_history = cnn_model.\\\nfit_generator(data_generator.flow(X_train.reshape(-1, 28, 28, 1), y_train, \n                                  batch_size=128),\n              steps_per_epoch = steps, epochs = epochs,\n              validation_data = (X_valid.reshape(-1, 28, 28, 1), y_valid), \n              callbacks=[cnn_checkpointer, cnn_lr_reduction], verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5447e7909b235e52473b8a490c28b62cbea98e61","_cell_guid":"2927ee47-cf56-41f8-b647-ba03b2fe06a5","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"cnn_model.load_weights('weights.best.digits.cnn.hdf5')\ncnn_scores = cnn_model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test, verbose=0)\n\nprint(\"CNN Scores: \" , (cnn_scores))\nprint(\"CNN Error: %.2f%%\" % (100 - cnn_scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52bcd58daa39fa7356dc768727c48a23557844d6","_cell_guid":"0f404fd5-284d-feb4-ce4a-98187cf11f3b"},"cell_type":"markdown","source":"***Model #2. Multi-layer Perceptron. Keras***"},{"metadata":{"_execution_state":"busy","_uuid":"7890c13c0c6d48c2ce227849529b05a5f85f07c5","_cell_guid":"368ea5b8-347d-7271-e221-f2db42e9f7e5","trusted":true},"cell_type":"code","source":"def mlp_mc_model():\n    model = Sequential()\n    \n    model.add(Dense(784, activation='relu', input_shape=(784,)))\n    model.add(Dropout(0.25))\n\n    model.add(Dense(392, activation='relu'))\n    model.add(Dropout(0.25))\n    \n    model.add(Dense(196, activation='relu'))\n    model.add(Dropout(0.25))\n    \n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(optimizer='nadam', loss='categorical_crossentropy', \n                  metrics=[categorical_accuracy, top_3_categorical_accuracy])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ebb03f6e139a96bbc61c68a1d8946163d473682","_cell_guid":"8baae6b9-29f7-4b2f-ba9d-93335d7e827c","trusted":true},"cell_type":"code","source":"mlp_mc_model = mlp_mc_model()","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"busy","_uuid":"8e2e4f563b195ae0718e5bbc110f818760bf0386","_cell_guid":"b6a61fc0-c740-482f-bb46-f82d60117e2a","trusted":true},"cell_type":"code","source":"\"\"\"\nfit_mlp = mlp_mc_model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                           epochs=3, batch_size=128, verbose=2);\n\nplt.figure(figsize=(12,4))\nplt.plot(fit_mlp.history['acc'], '-o', label = 'train')\nplt.plot(fit_mlp.history['val_acc'], '-o', label = 'test')\nplt.legend()\nplt.title('MLP Accuracy');\n\nmlp_scores = mlp_mc_model.evaluate(X_test, y_test)\n\nprint(\"\\nMLP Scores: \", (mlp_scores))\nprint(\"MLP Error: %.2f%%\" % (100 - mlp_scores[1] * 100))\nprint(mlp_mc_model.summary())\n\"\"\"\n\"\"\" \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f2a5ae38061ca1fc678135a0b322bc9d37ec7f5","_cell_guid":"3a7fb0a8-0c9e-46b2-8476-98815d08eeb2"},"cell_type":"markdown","source":"***Model #3. Recurrent Neural Network. Keras***"},{"metadata":{"_uuid":"e72e0a733f839c055d35bb8eceebcf9872d7fbda","_cell_guid":"618ee982-8385-4486-a819-70c1c95c1cac","trusted":true},"cell_type":"code","source":"def rnn_mc_model():\n    model = Sequential()\n\n    model.add(LSTM(196, return_sequences=True, input_shape=(1, 784)))    \n    model.add(LSTM(196, return_sequences=True))    \n    model.add(LSTM(196))  \n    \n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='nadam', \n                  metrics=[categorical_accuracy, top_3_categorical_accuracy])    \n    return model ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"867466c39c459d3df23ea665c51951d46f1b7a9f","_cell_guid":"bb6eb2f5-9ec7-465e-8e0d-34a7b53a4d9d","trusted":true},"cell_type":"code","source":"rnn_mc_model = rnn_mc_model()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44b119adabdf2e1b8ffc803ab85797ca79bbc02b","_cell_guid":"aba8f2a4-8738-46d0-80cf-bde2f969013e","trusted":true},"cell_type":"code","source":"\"\"\"\nfit_rnn = rnn_mc_model.fit(X_train.reshape(X_train.shape[0], 1, X_train.shape[1]), y_train, \n                           epochs=3, batch_size=128, verbose=2, \n                           validation_data=(X_test.reshape(X_test.shape[0], 1, \n                                                           X_test.shape[1]), y_test))\nplt.figure(figsize=(12,4))\nplt.plot(fit_rnn.history['acc'], '-o', label = 'train')\nplt.plot(fit_rnn.history['val_acc'], '-o', label = 'test')\nplt.legend()\nplt.title('RNN Accuracy');\n\nrnn_scores = rnn_mc_model.evaluate(X_test.reshape(X_test.shape[0], 1, \n                                                  X_test.shape[1]), y_test)\nprint(\"\\nRNN Scores: \", (rnn_scores))\nprint(\"RNN Error: %.2f%%\" % (100 - rnn_scores[1] * 100))\nprint(rnn_mc_model.summary())\n\"\"\"\n\"\"\" \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"735829717c4f7b524b224494c58a263fd45ae022","_cell_guid":"d6fe5fff-0b6a-90f5-34fd-e8314ae6581c"},"cell_type":"markdown","source":"***Model #4. MLPClassifier. Scikit-learn***"},{"metadata":{"_execution_state":"busy","_uuid":"d588a69cff9bbc12fe99faf04313806242bb6768","_cell_guid":"4a71b9ab-c4c3-fafa-bccd-ea3233e1add9","trusted":true},"cell_type":"code","source":"clf = MLPClassifier(hidden_layer_sizes=(784,), max_iter=100, alpha=1e-4,\n                     solver='lbfgs', verbose=1, tol=1e-6, random_state=1,\n                     learning_rate_init=7e-4, batch_size=128)\nclf.fit(X_train, y_train_num);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3833dd55488a97c37436b7184c21a21c4d7a0881"},"cell_type":"code","source":"print(\"MNIST. MLPClassifier. Train score: %f\" % (clf.score(X_train, y_train_num)*100),'%')\nprint(\"MNIST. MLPClassifier. Test score: %f\" % (clf.score(X_test, y_test_num)*100),'%')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2416854d659ccd038793fb7f4c30958e71c239b","_cell_guid":"a2927c7f-7a87-c896-9d66-53fb64f758de"},"cell_type":"markdown","source":"## Predictions"},{"metadata":{"_execution_state":"busy","_uuid":"75711e8ef6d9cb04ea38ad44ffc86deb85b9e814","_cell_guid":"e881a3db-4fbc-a992-0185-36bda597f881","trusted":true},"cell_type":"code","source":"predict_labels = cnn_model.predict(test_images.reshape(28000,28,28,1))\npredict_labels = predict_labels.argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"busy","_uuid":"b941009b5e8cc30416a4bae4249f7d5ff97bbad3","_cell_guid":"09e7d03c-24dd-011e-231a-b9f8f9b5ebdf","trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"ImageId\": range(1, len(predict_labels)+1), \n                           \"Label\": predict_labels})\nprint(submission[0:10])\n\nsubmission.to_csv('kaggle_digits_cnn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_execution_state":"busy","_uuid":"56555c6a84347d062f3f922ca7bfad6d92e2fcd0","_cell_guid":"4446f0b8-f7d5-4fdc-18dc-45d9401fd3ff","trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(14, 2), nrows=1, ncols=10, sharex=True, sharey=True,)\nax = ax.flatten()\nfor i in range(10):\n    image = test_images[i].reshape(28,28)\n    ax[i].imshow(image, cmap=plt.cm.Blues)\n\nax[0].set_xticks([])\nax[0].set_yticks([])\nplt.tight_layout()\nplt.gcf()\nax[4].set_title('Examples of the 784-dimensional digits. Test datapoints', fontsize=25);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"_is_fork":false,"_change_revision":0},"nbformat":4,"nbformat_minor":1}