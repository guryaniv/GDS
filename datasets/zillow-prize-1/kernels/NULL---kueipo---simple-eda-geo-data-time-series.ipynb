{"nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 2, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "d5337f7f-275a-46eb-980e-b0c026021409", "_execution_state": "idle", "_uuid": "db21b0f41fc6d0e332c72bd94ef3898bbaf4272f"}, "source": ["# Zillow House EDA\uff1aThe Fast &  Curious Journey\n", "\n", "`Majin Buu - UPDATED Year Build Error, 9 Sept 2017`\n", "### UPDATE: ` Multiplicative Model`\n", "---\n", "\n", "- **1 First Step**\n", "    - 1.1 Load libraries and helper functions\n", "    - 1.2 Load data\n", "    - 1.3 Check the Memory Usage\n", "    - 1.4 DataType Converting\n", "    - 1.5 DateTime Parsing\n", "- **2 Univariable Analysis**\n", "    - 2.1 Basic Statistic using Pandas and Numpy\n", "    - 2.2 The Distribution of our target variables (**logerror**)\n", "\n", "\n", "- **3 Multivariate Analysis**\n", "    - 3.1 Target Variable Distribution Join Fips by Bokeh\n", "    - 3.2 Geographic Location by Folium and Cluster by KMeans\n", "    - 3.3 Where are the Perfect Estimation area ?\n", "- **4 Time Series Approach**\n", "    - 4.1 Aggragation & Visualization\n", "        - Time Series Components\n", "        - Combining Time Series Components\n", "    - 4.2 Moving Average Smoothing / Random Walk and Stationarity\n", "    - 4.3 Prophet Forecasting\n", "\n", "\n", "\n", "- **Reference**\n", "        \n", "In this Notebook, you will discover time series forecasting. After reading this Notebook, you will know:\n", "1. Basic Time Series analysis, and time series forecasting. \n", "2. The Time Series components to consider in time series data.\n", "3. Examples of Time Series to make your understanding concrete.\n", "4. Time Series Libararies\n", "\n", "Let\u2019s get started.\n", "#### NOTE - Please UPVOTING if you like, **all your support is my motivation to update the notebook**.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "8b6bb590-fd94-4f5b-ab10-74955af824eb", "_uuid": "f95c69a26ddca052dc7ab8aee0b97f7b9dd5a21c"}, "source": ["### 1.1 Load libraries and helper functions"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "bb3e5c02-3fb4-4209-8e2d-43bb25c75c2c", "collapsed": true, "_uuid": "8edd39e48fcade778eb69f78b69952dbf4f2be4b"}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from scipy import stats\n", "\n", "# Forceasting with decompasable model\n", "from pylab import rcParams\n", "import statsmodels.api as sm\n", "from statsmodels.tsa.stattools import adfuller\n", "\n", "# Datetime operations\n", "import time\n", "\n", "# Visualisation\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import folium\n", "from fbprophet import Prophet\n", "plt.style.use('fivethirtyeight')\n", "import pickle\n", "import gc\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e0b7a12a-e6af-41ab-96c0-53ee0811b59f", "_uuid": "37f955f186e680226d2776eb05ecad88c9932b11"}, "source": ["### 1.2 Load Data"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "e8bcba61-e5b7-4e4f-abd8-29aff9c2ec11", "collapsed": true, "_uuid": "d1a5e06d74e0fd720e2849065c0c3eb530b265c7"}, "outputs": [], "source": ["start = time.time()\n", "prop = pd.read_csv('../input/properties_2016.csv')\n", "train = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\n", "df_train = train.merge(prop, how='left', on='parcelid')\n", "end = time.time()\n", "print(\"time taken by thie script by now is {} sec.\".format(end-start))"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "757bcb5d-f656-4700-bc34-9a31edae9f76", "_uuid": "c10c3e21ee9bce417d126a43b39107bbfa753c83"}, "source": ["### 1.3 Check the Memory Usage \n", "- Very useful skill if we only have enough hardware resource"]}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": true, "_cell_guid": "bed1c5e3-a92f-4b57-9712-1ebbe70f44d0", "collapsed": true, "_uuid": "592d3563eb833fc3dfbec6f8b7dbb01895bcbb7e"}, "outputs": [], "source": ["# To avoid Notebook flood, by setting verbose False\n", "train.info(verbose=False)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "fea11cb6-6599-4969-a2a4-ff2cf5abd47d", "collapsed": true, "_uuid": "bddbc2dad579e65c262898bc7555d8e13f6cea63"}, "outputs": [], "source": ["prop.info(verbose=False)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5c2f32ba-5eea-4796-bf98-1cb519d04bb2", "collapsed": true, "_uuid": "ce39417dd41eaf0e9764b31c77a63329eb989bcf"}, "outputs": [], "source": ["df_train.info(verbose=False)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "01b4d7b1-bcd9-4029-a49f-d060dce9de95", "collapsed": true, "_uuid": "7dfaa4dcb595981114f8d01bfad3cf15eac6389c"}, "outputs": [], "source": ["df_train.get_dtype_counts()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "d1d39c3d-867d-4b33-b070-663cf4761877", "collapsed": true, "_uuid": "08e0fcca4efc38e7f98acb7e6df62197260fdc64"}, "outputs": [], "source": ["del prop, train\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4f264c7e-aadd-4220-b504-a23353a4a60e", "_uuid": "af565f010a3b975bda497cb5540407fea7355fc5"}, "source": ["### 1.4 DataType Converting\n", "- Reference: [Anokas](https://www.kaggle.com/anokas) script"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "42a282de-a3d2-483d-a209-ac8592d07683", "collapsed": true, "_uuid": "f8bc78ce1416d566dd32e19a76a21508afc2e7d1"}, "outputs": [], "source": ["for c, dtype in zip(df_train.columns, df_train.dtypes):\n", "    if dtype == np.float64:\n", "        df_train[c] = df_train[c].astype(np.float32) \n", "    elif dtype == np.int64:\n", "        df_train[c] = df_train[c].astype(np.int32) \n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "247a24c7-2af8-4438-bfcc-52b4c5cb715b", "_uuid": "7948a545280b160679efa00c90c4e3c33824c592"}, "source": ["### 1.5 DateTime Parsing"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "0fe6dfe0-cc4b-4a52-9486-1dea469774f6", "collapsed": true, "_uuid": "c516573c0c1f3444aadde66cd8ef9487d8f44fa7"}, "outputs": [], "source": ["df_train['transaction_month'] = df_train['transactiondate'].dt.month\n", "df_train['transaction_year'] = df_train['transactiondate'].dt.year"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "605a3191-e06c-47e4-ad14-24e9ad3d2924", "_uuid": "462ef8df877472f756d522b0f12eedcc4f8e5ee0"}, "source": ["# 2 Univariable Analysis\n", "---\n", "### We'll just focus on the target variable (**Log Error**)\n", "- Fundamental Statistic\n", "- Visaulize the dstribution of logerror\n", "\n", "`logerror = log(Zestimate) - log(Saleprice)`"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5f22d90b-a6a7-4fe5-95a8-bbf9ff91a9ed", "_uuid": "ffb26b848d7c37eac20a7bd722b465c3e95c5bce"}, "source": ["## 2.1 Basic Statistic using Pandas and Numpy\n", "-  **Pandas DataFrame/Numpy API**\n", "\n", "`df.mean(), np.mean(df)`"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3ba985a3-9916-4a7f-bd85-cfabf6bba70d", "collapsed": true, "_uuid": "fc3d095fb93d815b19b34b3428516d119ebecf57"}, "outputs": [], "source": ["me = np.mean(df_train['logerror']); med = np.median(df_train['logerror']); st = df_train['logerror'].std(); \n", "print(df_train['logerror'].describe())"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5d1d2a18-0f13-47a3-84fc-08de64dc6d44", "_uuid": "3daf7f7a0c3f6be7ca5b34199f725523eb0bbfcd"}, "source": ["- The mean, median, and mode of a normal distribution are equal."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "36a43f64-e0ee-4289-9682-7c792fb7a01f", "collapsed": true, "_uuid": "ffa181ece39c54429781c078f5f7390bb5386b02"}, "outputs": [], "source": ["x = df_train['logerror']\n", "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True ,\n", "                                    gridspec_kw={\"height_ratios\": (.15, .85)})\n", "sns.boxplot(x, ax=ax_box)\n", "sns.distplot(x, ax=ax_hist, bins=400, kde=False)\n", "ax_box.set(yticks=[])\n", "sns.despine(ax=ax_hist)\n", "sns.despine(ax=ax_box, left=True)\n", "plt.xlim([me-2*st, me+2*st])\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "50ad9c53-2fc0-4af9-832e-80430df719a7", "_uuid": "9193961eaaa6d2687df5c938afe8b2b8008765f8"}, "source": ["#### We get that the distribution spikes which very close to zero\n", "- Zillow has Good Data Scientists"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4fef2fde-db9f-45ad-bc1e-c66144269c60", "_uuid": "23f284b0c6c228157f56799773d9e483e977909b"}, "source": ["# 3. Multivariate Analysis. \n", "---\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "298f600e-08ab-4a2b-9d05-9d577146991a", "_uuid": "34aca2083211f1c0bc0736e3a85521110044a782"}, "source": ["## 3.1 Target Variable Distribution Join Fips by Bokeh\n", "\n", "- Reference - \n", "[Philipp Spachtholz](https://www.kaggle.com/philippsp/exploratory-analysis-zillow) FanNotebook, we introduce **Absolute logerror** and **FIPS** codes map to city.\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3e6db15b-7304-456e-a844-c5be85f109cc", "collapsed": true, "_uuid": "62fa2f352da450fccab27bc14d6ca46aa2ec16b5"}, "outputs": [], "source": ["df_train.loc[:,'abs_logerror'] = df_train['logerror'].abs()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b14b3d11-adc0-478f-abfc-38b8dd01ba35", "_uuid": "317f253a75847275fc83a7cc19a3576aa87addfb"}, "source": ["- Transaction Date Vs ** Mean Error** in each County"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "ed4c05ed-8ac6-4368-9866-d965a155ce6b", "collapsed": true, "_uuid": "2612022375214f4229d0aa40f1c30e3c25904cbb"}, "outputs": [], "source": ["from bokeh.palettes import Spectral4\n", "from bokeh.plotting import figure, output_notebook, show\n", "\n", "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\n", "fips1.reset_index(inplace = True)\n", "fips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\n", "fips2.reset_index(inplace = True)\n", "fips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\n", "fips3.reset_index(inplace = True)\n", "\n", "\n", "output_notebook()\n", "out = figure(plot_width=800, plot_height=250, x_axis_type=\"datetime\")\n", "\n", "for data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n", "\n", "    out.line(data['transactiondate'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n", "\n", "out.legend.location = \"top_left\"\n", "out.legend.click_policy=\"hide\"\n", "show(out)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d15a10d3-d178-4aa6-8745-9df5a369277f", "_uuid": "677f53c399bb5261533d1b04d5b70cce9d6e1a95"}, "source": ["- Year Build Vs **Mean Error** in each County"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "bcb1bd88-5ffe-48cc-9539-d1ae544a607b", "collapsed": true, "_uuid": "0dccb6f36d85ddfbae844a2786e759d928938952"}, "outputs": [], "source": ["#yearbuilt\n", "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('yearbuilt')['abs_logerror'].mean())\n", "fips1.reset_index(inplace = True)\n", "fips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('yearbuilt')['abs_logerror'].mean())\n", "fips2.reset_index(inplace = True)\n", "fips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('yearbuilt')['abs_logerror'].mean())\n", "fips3.reset_index(inplace = True)\n", "\n", "output_notebook()\n", "out = figure(plot_width=800, plot_height=250)\n", "\n", "for data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n", "\n", "    out.line(data['yearbuilt'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n", "\n", "out.legend.location = \"top_right\"\n", "out.legend.click_policy=\"hide\"\n", "show(out)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2e2b9293-ff4d-4e5e-a280-49cc65cfa87c", "_uuid": "38e986442a6fb0af05690146c79a8c267029e9d3"}, "source": ["### An important note:  \n", "- Ventura Country has **Spikes** means Zillow Estimation Inaccurate"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "1d2b23e9-739f-4386-8b89-d1be7fcd4bf7", "collapsed": true, "_uuid": "238c522a0625f1f7a35290fe87dc533f2cffdf9e"}, "outputs": [], "source": ["import plotly # visualization\n", "from plotly.graph_objs import Scatter, Figure, Layout # visualization\n", "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot # visualization\n", "import plotly.figure_factory as ff # visualization\n", "import plotly.graph_objs as go # visualization\n", "init_notebook_mode(connected=True) # visualization\n", "\n", "worst_prediction = df_train['abs_logerror'].quantile(q=.95)\n", "\n", "\n", "trace0 = go.Scatter(\n", "    y = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean(),\n", "    x = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean().index,\n", "    mode = 'lines+markers',\n", "    name = \"Los Angeles\", \n", ")\n", "trace1 = go.Scatter(\n", "    y = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean(),\n", "    x = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean().index,\n", "    mode = 'lines+markers',\n", "    name = \"Orange County\"\n", ")\n", "trace2 = go.Scatter(\n", "    y = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean(),\n", "    x = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n", "                groupby('yearbuilt')['abs_logerror'].mean().index,\n", "    mode = 'lines+markers',\n", "    name = \"Ventura County\"\n", ")\n", "data = [trace0, trace1, trace2]\n", "\n", "plotly.offline.iplot(data, filename='line-mode')"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "2794f921-b3d0-465b-bc21-326e0a63a64e", "_uuid": "09d69ded3d4e99a36b6efe07677774f852db5bcc"}, "source": ["\n", "\n", "## 3.2 Geographic Location by Folium and Cluster by KMeans\n", "\n", "### Introduction:\n", "\n", "Folium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. \n", "\n", "Manipulate your data in Python, then visualize it in on a Leaflet map via Folium."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "a51855e7-67de-4669-9861-570ed6ffc5e8", "collapsed": true, "_uuid": "2af03c3f8b7499c2447fb52e33c0e30e384ae58b"}, "outputs": [], "source": ["geo_df = df_train[['latitude', 'longitude','logerror']]"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b67dbbd7-1345-4420-90e5-b29bf38d1bd2", "collapsed": true, "_uuid": "3d0574bab1699d7070da6c0c178d516b8e295fa2"}, "outputs": [], "source": ["geo_df['longitude']/=1e6\n", "geo_df['latitude']/=1e6"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7d9b83c5-2308-4072-94c9-8ff88ca1c399", "collapsed": true, "_uuid": "595d7b13bf4854f7fc0b386c5999dd165c1f1d9b"}, "outputs": [], "source": ["geo_df.dropna(subset=['latitude','longitude'], axis=0 ,inplace=True)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "918d195e-d339-4938-9f04-6a7e0ea83370", "collapsed": true, "_uuid": "d3b6b79a2ea71e4377e0db566646156b2a1e9feb"}, "outputs": [], "source": ["from sklearn.cluster import MiniBatchKMeans\n", "kmeans = MiniBatchKMeans(n_clusters=120, batch_size=1000).fit(geo_df[['latitude','longitude']])\n", "geo_df.loc[:, 'label'] = kmeans.labels_"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "f0461ceb-a42e-4632-ba1e-52e78a0428c7", "collapsed": true, "_uuid": "bcf4e9fd314f7bc585ab500dc25736bbbe567dc7"}, "outputs": [], "source": ["map_2 = folium.Map(location=[34.088537, -118.249923],\n", "                   zoom_start=9)\n", "for label in kmeans.cluster_centers_:\n", "    folium.Marker(location=[label][0]).add_to(map_2)\n", "\n", "map_2"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "0200607c-85ac-45cd-910b-9805cdc9efe1", "collapsed": true, "_uuid": "61a6fa5d285f25fc4e52c7338a9334e7f5befd36"}, "outputs": [], "source": ["map_1 = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n", "                   tiles='Stamen Terrain')\n", "for label in kmeans.cluster_centers_:\n", "    folium.Marker(location=[label][0]).add_to(map_1)\n", "map_1\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "bc65e3ca-0434-4ea7-a338-2efdd399b165", "collapsed": true, "_uuid": "2cf8b90f079b2d34dadfd643637652775dfe3790"}, "outputs": [], "source": ["del map_2 ,map_1\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a1d0fa82-2809-4a8a-8cff-9b4ec09fa3a6", "_uuid": "a46402045becddb0463aeb51b510852622a4ca8d"}, "source": ["### Finding:\n", "-  Most houses locat in **Flat Ground**\n", "-  Few locat in **Santa Catalina Island**"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ef46c905-1bd7-4f74-ba1d-4a91db33077c", "_uuid": "30569742d65fb2599dc1d58728df151058365489"}, "source": ["## 3.3 Where are the Perfect Estimation area ?\n", "\n", "- We are going to have a look \n", "- Ignoring Time Series, i.e Without taking month into consideration "]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7b8dce41-681f-4400-b105-89f5bb2c7a7a", "collapsed": true, "_uuid": "eaf7a9fa8354b714e70cbd057163bd3b7cd66b3c"}, "outputs": [], "source": ["gc.collect()\n", "perfect_geo_df = geo_df[geo_df['logerror']==0]\n", "perfect_geo_df.shape"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "10935ad8-676e-4322-90e4-da8428463065", "collapsed": true, "_uuid": "15fc295c5d4616851cd779bb11607ed682eb4d41"}, "outputs": [], "source": ["map_perfect = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n", "                   tiles='Stamen Toner')\n", "for lat, lon in zip(perfect_geo_df.latitude, perfect_geo_df.longitude):\n", "    folium.Marker(location=[lat,lon]).add_to(map_perfect)\n", "map_perfect\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "e7342572-792b-4091-9d84-0ae19b9b1227", "collapsed": true, "_uuid": "2791c3b58d152332d3b257eba0b9f5a5527899a4"}, "outputs": [], "source": ["del perfect_geo_df, map_perfect, geo_df\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0dbb6aa0-ba0d-4cc7-ab94-cbb32d16c30b", "_uuid": "50614405888ca49fa86288f7930be5f402dc37c0"}, "source": ["### An important note:\n", "- There is no pattern between Geo and perfect Estimation\n", "- Never Happen in the Santa Catalina Island (Millionair hard to predict :-) )"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "e5abe7d4-34b6-4cfe-82d3-b1dca8dcca85", "_uuid": "9febbe30e13971755ca2992fedd10bb929d08899"}, "source": ["# 4. Time Series Approach\n", "---\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "fb3cddb2-6a66-465b-a6fa-528a95ddae08", "_uuid": "90a7822cd0ff0fb58c9e78182709d14685387097"}, "source": ["## 4.1 Aggragation & Visualisation\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d2d641d7-f65a-45ce-a3b9-585124b2c93b", "_uuid": "64d06c61b97ba1781d40132c7be539d893401537"}, "source": ["### OverAll Average Absolute Log Error"]}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": true, "_cell_guid": "e2e269bf-744f-4a88-9803-c935350d5819", "collapsed": true, "_uuid": "4a77115d2a06f7e46440c681dfab6c7f5fcef4a2"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))\n", "mean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()\n", "plt.plot(mean_group)\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series - Average')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "266a90d2-b637-4d0a-a735-a2f0abd87ff8", "_uuid": "7168f36fce68b7c8c9d473411348b46f33e803c1"}, "source": ["### Los Angeles Average Absolute Log error"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "34259f40-5777-4f23-9981-7f55a9fa5eda", "collapsed": true, "_uuid": "bcd88500e963fc2f4bb8d8f540385785f6b8ed9e"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6)) \n", "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\n", "plt.plot(fips1,c='k')\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series Los Angeles - Average')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "3fe34c79-d8c0-430e-9a3d-e9abc113400b", "_uuid": "647e3d06219eac9949fbb0729d749bc3e311b493"}, "source": ["### Orange County Average Absolute Log error"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7df285a0-428f-495c-bfe5-97db0f14b2ed", "collapsed": true, "_uuid": "db14b90d63a55b6127b1fa1a2b10b8223ce29e8a"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6)) \n", "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\n", "plt.plot(fips1, c = 'm')\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series Orange County - Average')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ae4f50c0-81cf-43e4-9736-89f07a1d960c", "_uuid": "9d63c9585c454a432928b1012a6685b4b8830a13"}, "source": ["### Ventura County  Average Absolute Log error"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "e1a1d020-839c-48f2-9f8f-cd6ba5d22974", "collapsed": true, "_uuid": "9e7adca71992a7296ae55555effbceb643b957dd"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))\n", "fips1 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\n", "plt.plot(fips1, c = 'y')\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series Ventura County - Average')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a638162d-4168-4bcc-8468-d33db16eafb1", "_uuid": "627d4fe10e9188d25b2f5d9ab134fae28736c4bd"}, "source": ["- Median of Absolute Logerror"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6ae77b1d-847b-466e-b9f2-c199b8191a84", "collapsed": true, "_uuid": "fb0d9c5d3e3aa4d2c43a7b231228c7398f751334"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))\n", "median_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\n", "plt.plot(median_group, c='b')\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series - Median')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "02f64e81-845a-4861-b480-c3a04feb9590", "_uuid": "9d57680573e84d6b282bd484ef535fb1b47e368c"}, "source": ["- Standard Deviation of Absolute Logerror"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "07dd8f59-66ed-44f5-8934-9d5677665c0f", "collapsed": true, "_uuid": "3182a72b98b49b3783a23c11436e486f904ddfbe"}, "outputs": [], "source": ["plt.figure(figsize=(20, 6))\n", "std_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\n", "plt.plot(std_group, c='g')\n", "plt.xlabel('Date', fontsize=15)\n", "plt.ylabel('Absolute Log error', fontsize=15)\n", "plt.title('Time Series - STD')\n", "plt.show()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "15ccf374-369e-45f6-83d9-41dbb1b83669", "collapsed": true, "_uuid": "d022578924eaf1f8dd4a2f32acc2a37c7f3c6d92"}, "outputs": [], "source": ["del mean_group, median_group, std_group\n", "gc.collect()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c94dbd40-6452-4089-a945-cd2588b17343", "_uuid": "2e0ae0f4bf2ed51503f25fcb246670a306f300f1"}, "source": ["\n", "Here, I only use inliner \n", "    - Definition:  Absolute Logerror < Mean + Std"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "cefcf834-c693-4393-b854-33ce1f1bcc13", "collapsed": true, "_uuid": "9a3447b527d0d373659211ec3b0d92b1778873f9"}, "outputs": [], "source": ["df_train = df_train[df_train['abs_logerror']<  me + st ]\n", "mean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "87573303-ab24-4ef6-890a-e339447225f6", "_uuid": "cd4cd79864d1b9330a4450f28b386b391dd15415"}, "source": ["### Time Series Components\n", "  \n", "- A given time series is thought to consist of three systematic components including level, trend, seasonality, and one non-systematic component called noise. These components are defined as follows:\n", "\n", "    1. **Level**: The average value in the series.\n", "    2. **Trend**: The increasing or decreasing value in the series. \n", "    3. **Seasonality**: The repeating short-term cycle in the series. \n", "    4. **Noise**: The random variation in the series.\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "75061381-99a4-40e8-9e9d-ddaf8dff02b6", "_uuid": "ea08875da9eae0a21660437b03467cbffbd0856e"}, "source": ["### Combining Time Series Components\n", "- A series is thought to be an aggregate or combination of these four components. All series have a level and noise. The trend and seasonality components are optional. It is helpful to think of the components as combining either **additively** or **multiplicatively**.\n", "\n", "    - Additive Model\n", "        y(t) = Level + Trend + Seasonality + Noise \n", "        \n", "    - Multiplicative Model\n", "        y(t) = Level x Trend x Seasonality x Noise \n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "727e6061-890c-483d-b2d6-f3096860e6f3", "_uuid": "31f8fd85ece28f8b9f7473c31ee7bccf8fc8553b"}, "source": ["- Additive Model"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6faed842-4f94-4842-8df0-1939b904ff16", "collapsed": true, "_uuid": "6abd04c00596b3a41e24c8a964e200d1ab97f9dd"}, "outputs": [], "source": ["times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\n", "df_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\n", "decomposition = sm.tsa.seasonal_decompose(df_date_index, model='additive',freq = 31)\n", "trend = decomposition.trend\n", "seasonal = decomposition.seasonal\n", "residual = decomposition.resid\n", "rcParams['figure.figsize'] = 15, 8\n", "\n", "plt.subplot(411)\n", "plt.title('Obesered = Level + Trend + Seasonality + Noise ')\n", "plt.plot(df_date_index, label='Observed')\n", "plt.legend(loc='best')\n", "plt.subplot(412)\n", "plt.plot(trend, label='Trend')\n", "plt.legend(loc='best')\n", "plt.subplot(413)\n", "plt.plot(seasonal,label='Seasonality')\n", "plt.legend(loc='best')\n", "plt.subplot(414)\n", "plt.plot(residual, label='Residuals')\n", "plt.legend(loc='best')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "9b6aa4b9-bb07-4276-98a9-d79aea5ee6a5", "_uuid": "1ef2f5fe7eef4b46df1766c1fdcf9c49292d17c9"}, "source": ["- Multiplicative"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b723c772-aa47-435e-b7a5-cf8d2326ccbb", "collapsed": true, "_uuid": "d773e1278ca7cb15be764d0dc681979a1befd0c4"}, "outputs": [], "source": ["times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\n", "df_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\n", "decomposition = sm.tsa.seasonal_decompose(df_date_index, model='multiplicative',freq = 14)\n", "trend = decomposition.trend\n", "seasonal = decomposition.seasonal\n", "residual = decomposition.resid\n", "rcParams['figure.figsize'] = 15, 8\n", "\n", "plt.subplot(411)\n", "plt.title('Obesered = Level x Trend x Seasonality x Noise ')\n", "plt.plot(df_date_index, label='Observed')\n", "plt.legend(loc='best')\n", "plt.subplot(412)\n", "plt.plot(trend, label='Trend')\n", "plt.legend(loc='best')\n", "plt.subplot(413)\n", "plt.plot(seasonal,label='Seasonality')\n", "plt.legend(loc='best')\n", "plt.subplot(414)\n", "plt.plot(residual, label='Residuals')\n", "plt.legend(loc='best')\n", "plt.tight_layout()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4b16dd6f-0fe3-47a9-9753-3df64d9495d8", "_uuid": "e2a0ff6cd24ea4e10b42bb8cef48609a806c0673"}, "source": ["## 4.2 Moving Average Smoothing / Random Walk and Stationarity\n", "\n", "Moving average smoothing is a naive and effective technique in time series forecasting. It can be used for data preparation, feature engineering, and even directly for making predictions.\n", "\n", "A stationary time series is one where the values are not a function of time. We can confirm this using a statistical significance test, specifically the Augmented Dickey-Fuller test.\n", "\n", "- The script is copied from kaggler \n", "    1. [Julien Heiduk](https://www.kaggle.com/zoupet) and  \n", "    2. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/ \n", "    3. [Dr. Jason Brownlee]()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "dd45a4b9-4567-460b-89c7-d25cb2114be0", "collapsed": true, "_uuid": "592590914450ac60d45b02b619c71c744efc49c0"}, "outputs": [], "source": ["def test_stationarity(timeseries):\n", "    plt.figure(figsize=(15, 8))\n", "    #Determing rolling statistics\n", "    rolmean = pd.rolling_mean(timeseries, window=31) # Slide window depend on past 1 month\n", "    rolstd = pd.rolling_std(timeseries, window=31)\n", "\n", "    #Plot rolling statistics:\n", "    orig = plt.plot(timeseries, color='blue',label='Original')\n", "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n", "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n", "    plt.legend(loc='best', fontsize=15)\n", "    plt.title('Rolling Mean & Standard Deviation', fontsize=15)\n", "    plt.xlabel('Date', fontsize=15)\n", "    plt.ylabel('Absolute Log Error', fontsize=15)\n", "    plt.show(block=False)\n", "    \n", "    #Perform Dickey-Fuller test:\n", "    print('Results of Dickey-Fuller Test:')\n", "    dftest = sm.tsa.adfuller(timeseries['abs_logerror'], autolag='AIC')\n", "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n", "    for key,value in dftest[4].items():\n", "        dfoutput['Critical Value (%s)'%key] = value\n", "    print(dfoutput)\n", "    \n", "test_stationarity(df_date_index)   "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "520c5fd3-34e2-4e3e-8719-233f305a39c6", "_uuid": "0df1b75b6ef93a4814874d7df6a4c7929dbe35fe"}, "source": ["The **null hypothesis** of the test is that the time series is **non-stationary** and we can see that the test statistic value was **-1.736474e+01** with a significance level of less than **1%** (i.e. a low probability that the result is a statistical fluke). \n", "\n", "Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is ** stationary** or does not have time-dependent structure.\n", "\n", "# Non Time Dependent Structure\n", "- Under Constraint\n", "    - Exclude Outlier\n", "    - Only depend on past 3 months "]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "14e1fb86-0e31-46f9-9fb8-972fffab4eb4", "_uuid": "1f35e9d8e6142fea1ce2bec2b33e0d2986eaa9a8"}, "source": ["## 4.3 Prophet Forecasting\n", "### This is inspired by kaggler [Julien Heiduk](https://www.kaggle.com/zoupet)\n", "\n", "- This tool was created by Facebook. \n", "More information on the library here: https://research.fb.com/prophet-forecasting-at-scale/\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "a5464aeb-4305-44a2-992d-c46eceab662a", "collapsed": true, "_uuid": "f847108438a7d7af93680ee67732ed1f168d50ff"}, "outputs": [], "source": ["sns.set(font_scale=1) \n", "df_prophet =  pd.DataFrame(mean_group).reset_index(drop=False)\n", "df_prophet = df_prophet.iloc[-92:,:] # Forecast due to past 3 months\n", "df_prophet.columns = ['ds','y']\n", "\n", "m = Prophet()\n", "m.fit(df_prophet)\n", "future = m.make_future_dataframe(periods=59,freq='D') # Forecast Jan 2017\n", "forecast = m.predict(future)\n", "plt.figure(figsize=(30, 6))\n", "fig = m.plot(forecast)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "45585d5d-1223-4d7a-b326-468d55a95670", "_uuid": "7c465130af1055cd981fd6a0450f5609546a77bf"}, "source": ["## Reference\n", "- [1] [Philipp Spachtholz](https://www.kaggle.com/philippsp/exploratory-analysis-zillow)\n", "- [2] [Julien Heiduk](https://www.kaggle.com/zoupet) \n", "- [3] [Aarshay Jain](https://www.analyticsvidhya.com/blog/author/aarshay/) A comprehensive beginner\u2019s guide to create a Time Series Forecast\n", "- [4] [Dr. Jason Brownlee]()\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1cce868d-105e-4336-8d25-a7311fbf8053", "_uuid": "bb01583838220d34a15d0edcf9a9b8b868d2c177"}, "source": ["## Stay tuned, this notebook will be updated on a regular basis\n"]}]}