{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6423d8b0-84d0-084c-45a6-0f118ec8efb2"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from matplotlib import pyplot as plt\n",
        "from pandas import DataFrame,read_csv,isnull,notnull\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from numpy import log# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "from sklearn.preprocessing import Normalizer\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14629450-626b-fe1a-e062-ac3e56bae61d"
      },
      "outputs": [],
      "source": [
        "train=read_csv('../input/train.csv',header='infer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4808b241-32f5-59a3-c04c-6c37603b7359"
      },
      "outputs": [],
      "source": [
        "def find_category_cols(data):\n",
        "    uniques={}\n",
        "    for col in data:\n",
        "            uniques[col]={'Unique_Values':len(pd.unique(data[col])),'Max':np.max(data[col]),'Min':np.min(data[col]),'Missing':len(data[pd.isnull(data[col])])}\n",
        "    return uniques\n",
        "def cat_to_num(data):\n",
        "    cat_strings=data.dtypes[data.dtypes=='object'].index\n",
        "    cat_strings=cat_strings[cat_strings!='timestamp']\n",
        "    for col in cat_strings:\n",
        "        data[col]=pd.Categorical.from_array(data[col]).labels\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c65317a2-9654-f83f-6243-c09508efb99c"
      },
      "outputs": [],
      "source": [
        "#Unique_Info=pd.DataFrame(find_category_cols(train)).T\n",
        "#Unique_Info.sort_values(by='Unique_Values',ascending=True)\n",
        "train=cat_to_num(train)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "86733095-f10e-0bca-f2ff-bd85c4cf4132"
      },
      "source": [
        "**Getting only the internal house features initially and exploring them.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "321f6374-de8c-e69d-0509-84a9c730b94c"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5497841a-bea2-d06b-57b2-63175c92d810"
      },
      "outputs": [],
      "source": [
        "features=train.columns[(train.columns!='id')&(train.columns!='price_doc')&(train.columns!='timestamp')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6fcf34d-3373-ddbd-1bbf-e7e7ccd3158e"
      },
      "outputs": [],
      "source": [
        "nn = MLPRegressor(\n",
        "    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
        "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
        "    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
        "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "#n = nn.fit(train[features], train['price_doc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83c86966-85d1-347e-446a-7a76bff3efd0"
      },
      "outputs": [],
      "source": [
        "np.array(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb3829f9-7e8e-5bd9-e4da-28b4c043641b"
      },
      "source": [
        "## Making the following adjustments in the function adjust_sq_ft: ##\n",
        "\n",
        " 1. Using the observations which have all the sq ft populated obtain average portion of kitch in living area, average portion of living area in full area and average portion of kitchen area in full area. These averages will be later used to impute missing values of kitch area and living area.\n",
        " 2. If full_sq=0 then full_sq=life_sq.\n",
        " 3. If "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4825b729-9086-3b4b-a65e-15730f0d1596"
      },
      "outputs": [],
      "source": [
        "def adjust_sq_ft(house_feat):\n",
        "    no_sq=(house_feat.full_sq==0)|(isnull(house_feat['full_sq']))\n",
        "    #missing_full=house_feat[no_sq]\n",
        "    no_kitch=(house_feat.kitch_sq==0)|(isnull(house_feat['kitch_sq']))\n",
        "    #missing_kitch=house_feat[no_kitch]\n",
        "    no_l_sq=(house_feat.life_sq==0)|(isnull(house_feat['life_sq']))\n",
        "    #missing_life=house_feat[no_l_sq]\n",
        "    has_all_sq_ft=(house_feat.full_sq!=0)&(notnull(house_feat['full_sq']))&(house_feat.kitch_sq!=0)&(notnull(house_feat['kitch_sq']))&(house_feat.life_sq!=0)&(notnull(house_feat['life_sq']))&((house_feat.full_sq-house_feat.kitch_sq)>0)&((house_feat.full_sq-house_feat.life_sq)>0)&((house_feat.life_sq-house_feat.kitch_sq)>0)\n",
        "    all_sq_ft=house_feat[has_all_sq_ft]\n",
        "    all_sq_ft.loc[:,'% Kitch/Full']=100*all_sq_ft.loc[:,'kitch_sq']/all_sq_ft.loc[:,'full_sq']\n",
        "    all_sq_ft.loc[:,'% Kitch/Life']=100*all_sq_ft.loc[:,'kitch_sq']/all_sq_ft.loc[:,'life_sq']\n",
        "    all_sq_ft.loc[:,'% Life/Full']=100*all_sq_ft.loc[:,'life_sq']/all_sq_ft.loc[:,'full_sq']\n",
        "    final_sq_ft=all_sq_ft[all_sq_ft['% Kitch/Life']<=60]\n",
        "    sq_ft_breakage=final_sq_ft.describe()\n",
        "    #Adjusting the missing full sq\n",
        "    house_feat.loc[no_sq,'full_sq']=house_feat.loc[no_sq,'life_sq']\n",
        "    #life_big_than_full=(house_feat.full_sq-house_feat.life_sq)<0\n",
        "    #house_feat.loc[life_big_than_full,'full_sq']=house_feat.loc[life_big_than_full,'life_sq']\n",
        "    # Adjusting kitch_sq using full_sq\n",
        "    too_kitch_in_full=(house_feat.full_sq-house_feat.kitch_sq)<0\n",
        "    house_feat.loc[(no_kitch)|(too_kitch_in_full),'kitch_sq']=house_feat.loc[(no_kitch)|(too_kitch_in_full),'full_sq']*sq_ft_breakage.loc['50%','% Kitch/Full']/100\n",
        "    #Adjusting the life_sq using full sq\n",
        "    too_life_in_full=(house_feat.full_sq-house_feat.life_sq)<0\n",
        "    house_feat.loc[(no_l_sq)|(too_life_in_full),'life_sq']=house_feat.loc[(no_l_sq)|(too_life_in_full),'full_sq']*sq_ft_breakage.loc['50%','% Life/Full']/100\n",
        "    #too_much=house_feat[(too_kitch_in_life)|(too_life_in_full)|(too_kitch_in_full)]\n",
        "    #Adjusting kitch_sq using life_sq\n",
        "    too_kitch_in_life=(house_feat.life_sq/house_feat.kitch_sq)>=0.6\n",
        "    house_feat.loc[(no_kitch)|(too_kitch_in_life),'kitch_sq']=house_feat.loc[(no_kitch)|(too_kitch_in_life),'life_sq']*sq_ft_breakage.loc['50%','% Kitch/Life']/100\n",
        "    return house_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e597e808-44eb-9bf6-d600-870bfa6f7d3e"
      },
      "outputs": [],
      "source": [
        "def adjust_floor(house_feat):\n",
        "    too_high_floor=house_feat.floor>house_feat.max_floor\n",
        "    house_feat.loc[too_high_floor,'floor']=house_feat.loc[too_high_floor,'max_floor']\n",
        "    return house_feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d5c765f-2428-7068-9c58-e3113a9f4fc3"
      },
      "outputs": [],
      "source": [
        "new_house_feat=adjust_floor(adjust_sq_ft(house_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "096516ec-89b9-1b36-33a7-c3692e7cc917"
      },
      "outputs": [],
      "source": [
        "new_house_feat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "680a0242-e0be-2289-4780-f81125ce259d"
      },
      "outputs": [],
      "source": [
        "class neuralnet:        \n",
        "    def initialize(self,inp_nodes,hid_nodes,out_nodes,l_rate):\n",
        "        self.inodes=inp_nodes\n",
        "        self.hnodes=hid_nodes\n",
        "        self.onodes=out_nodes\n",
        "        self.lr=l_rate\n",
        "        self.wih=np.random.rand(hid_nodes,inp_nodes)-0.5\n",
        "        self.woh=np.random.rand(out_nodes,hid_nodes)-0.5\n",
        "        self.activation_function=lambda x:expit(x)\n",
        "        pass\n",
        "    def train(self):\n",
        "        pass\n",
        "    def query(self,input_list):\n",
        "        inputs=np.array(input_list,ndmin=2).T\n",
        "        hidden_inputs=np.dot(self.wih,inputs)\n",
        "        hidden_outputs=self.activation_function(hidden_inputs)\n",
        "        final_inputs=np.dot(self.woh,hidden_outputs)\n",
        "        final_outputs=self.activation_function(final_inputs)\n",
        "        return final_outputs\n",
        "        \n",
        "        \n",
        "        pass\n",
        "    def soph_weights(self):\n",
        "        self.wih=np.random.normal(0.0,np.power(self.hnodes,-0.5),(self.hnodes,self.inodes))\n",
        "        self.woh=np.random.normal(0.0,np.power(self.onodes,-0.5),(self.onodes,self.hnodes))\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d821908c-7080-17f9-a461-7530268b8dec"
      },
      "outputs": [],
      "source": [
        "n1=neuralnet()\n",
        "n1.initialize(3,5,3,0.5)\n",
        "n1.query([1,2,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3156438-eb46-b4f8-7afa-bd054c7e32d1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}