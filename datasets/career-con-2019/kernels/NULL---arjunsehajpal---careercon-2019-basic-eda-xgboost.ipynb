{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing the libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nimport warnings\nimport os\nimport statistics\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# settitng the notebook parameters\n\nplt.rcParams[\"figure.figsize\"] = (12, 12)\nsns.set_style(\"darkgrid\")\nwarnings.filterwarnings(\"ignore\")\nprint(os.listdir(\"../input\"))\npd.set_option(\"display.max_rows\", 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ee63bc2f18078ed3a490b1b95d7e30a025be0c4"},"cell_type":"code","source":"X_train = pd.read_csv('../input/X_train.csv') \nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fdbdf1a563d946860dbd5c3e406e5813cef365e"},"cell_type":"code","source":"Y_train = pd.read_csv('../input/y_train.csv')\nY_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f043d15f89e557a8caf2b9762b06a295eff03343"},"cell_type":"code","source":"X_test = pd.read_csv('../input/X_test.csv')\nX_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dd334174e2c7697b7d5413a1b7541f10dc640b6"},"cell_type":"markdown","source":"### Predictors\n- **row_id** - The ID for this row.\n- **series_id** - ID number for the measurement series. Foreign key to y_train/sample_submission.\n- **measurement_number** - Measurement number within the series.\n- **orientation** - The orientation channels encode the current angles how the robot is oriented as a quaternion.\n- **angular_velocity** - Angular velocity describes the angle and speed of motion.\n- **linear_acceleration** - Linear acceleration components describe how the speed is changing at different times.\n\n### Labels\n- **series_id**: ID number for the measurement series.\n- **group_id**: ID number for all of the measurements taken in a recording session. Provided for the training set only, to enable more cross validation strategies.\n- **surface**: the target for this competition."},{"metadata":{"trusted":true,"_uuid":"50ce7f77483dca10f8a67181fcbe8fa337c27258"},"cell_type":"code","source":"# creating a dataset, info_df, to check the unique values and null values in every column of the dataset.\n\ninfo_df = pd.DataFrame({\n    \"Unique_Count\": X_train.nunique(),\n    \"Null_Count\": X_train.isnull().sum()\n})\n\ninfo_df.T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d8b65282f4421802a0649ff3bed13cf72595ffd"},"cell_type":"markdown","source":"Each element in `series_id` contains 128 elements, hence it has a uniform distribution. Similarly, `measurement_number` also has uniform distribution. For every one series, there are 128 measurements."},{"metadata":{"_uuid":"ef538e6859fde9766453edd247121b5b68d441c3"},"cell_type":"markdown","source":"## Descriptive Statistical Summary of the Predictors"},{"metadata":{"trusted":true,"_uuid":"ee679fc297f5e6de4e72aedb8e2b9d2fd1fe2be6"},"cell_type":"code","source":"col = X_train.columns\ncol_drop = [\"row_id\", \"series_id\", \"measurement_number\"]\ncol_plot = [i for i in col if i not in col_drop]\n\nstats_df = pd.DataFrame({\n    \"Mean\": X_train[col_plot].mean(),\n    \"Median\": X_train[col_plot].median(),\n    \"Std Dev\": X_train[col_plot].std(),\n    \"Variance\": X_train[col_plot].var()\n})\n\nstats_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89cee81ad739bccd6f652826e5ba0670f001c765"},"cell_type":"code","source":"# checking the distribution of the Predictors\n\nfig = plt.figure(figsize = (12, 12))\nfor i in range(0, len(col_plot)):\n    ax = fig.add_subplot(5, 2, i + 1, xticks = [], yticks = [])\n    col = col_plot[i]\n    sns.distplot(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8881d07e86034ae1dcd4c6f461fe0bc51d64560"},"cell_type":"code","source":"# checking the outliers in predictors\n\nfig = plt.figure(figsize = (12, 12))\n\nfor i in range(0, len(col_plot)):\n    ax = fig.add_subplot(5, 2, i+1, xticks = [], yticks = [])\n    col = col_plot[i]\n    sns.boxplot(X_train[col])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6b045745113fdeda678d849ff0da5ad04036a1c"},"cell_type":"markdown","source":"## Random Error\nHere, we will sample the dataset repeatedly and check if the Predictors in our dataset abides to Central Limit Theorem. By establishing that, we can say that, there won't be any random error (error due to random sampling). "},{"metadata":{"trusted":true,"_uuid":"026e83b4c8d87d57bd4057b0780db6da3d53c4b0"},"cell_type":"code","source":"class Central_limit_theorem(object):\n    def __init__(self, sample, xlim = 100):\n        self.sample = sample\n        self.n = len(sample)\n        self.xlim = xlim\n        \n    def resample(self):\n        new_sample = np.random.choice(self.sample, self.n, replace = True)\n        return new_sample\n    \n    def sample_stat(self, sample):\n        return sample.mean()\n    \n    def compute_sampling_distribution(self, iteration = 1000):\n        stats = [self.sample_stat(self.resample()) for i in range(iteration)]\n        return np.array(stats)\n    \n    def plot_sampling_distribution(self):\n        sample_stats = self.compute_sampling_distribution()\n        se = sample_stats.std()\n        ci = np.percentile(sample_stats, [5, 95])\n        \n        sns.distplot(sample_stats, color = \"red\")\n        plt.xlabel(\"sample statistics\")\n        plt.xlim(self.xlim)\n        \n        se_str = \"SE = \" + str(se)\n        ci_str = \"CI = \" + str(ci)\n        \n        ax = plt.gca()\n        plt.text(0.3, 0.95, s = se_str, horizontalalignment = \"center\", verticalalignment = \"center\", transform = ax.transAxes)\n        plt.text(0.7, 0.95, s = ci_str, horizontalalignment = \"center\", verticalalignment = \"center\", transform = ax.transAxes)\n        \n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3570332c2f19cd1e8f965c87c7dcd5aa55cf623"},"cell_type":"code","source":"def random_error(x ,n, xlim):\n    x = x.values\n    sample = np.random.choice(x, n)\n    resampler = Central_limit_theorem(sample, xlim = xlim)\n    resampler.plot_sampling_distribution()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf4e877608cfb28e196bc1094e30b11b940ea25"},"cell_type":"code","source":"# range of xlim can be selected from the stats_df above. Generally, value of sample statistic should be included in your range.\nplt.figure(figsize = (12, 8))\nrandom_error(X_train[\"orientation_X\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d973649f9e9ec0e6c4cd336902388769edf02932"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"orientation_Y\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a439a2faef00213bce775809895a9be592116aed"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"orientation_Z\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e130786bbfc7a3df0ba626cae8cb7b2bfdf9681b"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"orientation_W\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"277e9d5e7fade4dc41607fa2076dd65ddf096442"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"angular_velocity_X\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"194307aef63434b7a6935c6cfdf6e40fa6e3bde1"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"angular_velocity_Y\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b437e56d7fc7dfed13767849b82b839b06f9d255"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"angular_velocity_Z\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a163b6232db35131b4274fa9caed43e8c047b366"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"linear_acceleration_X\"], 100, xlim = [-1, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbafe44d55b7d14c454c884ffa7cb21b54b781fe"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"linear_acceleration_Y\"], 100, xlim = [0, 5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e8e2c510110b31e741b4dd99b1de0edc76fa961"},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\nrandom_error(X_train[\"linear_acceleration_Z\"], 100, xlim = [-20, 0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3b0620f22153a84edc276ebb1ede475fb995ce5"},"cell_type":"markdown","source":"# Effect Size\nAs all are variables, more or less, abided to CLT, we will now check Effect Size of each variable with respect to the target variable. For that, we have to first concatenate the X_train and Y_train.\n\nThe Effect Size, is considered better than p-value, when checking the statistical significance of the variables. Effect size measures either measure the sizes of associations or the sizes of differences. The Effect size of 0.2 is considered to be \"smal\"l effect. Meaning, effect is trivial in nature and is random in nature. Similarly, effect size of around 0.5 is considered \"medium\" and effect size larger that 0.75 is considered \"large\".\n\nHere, we will be using Cohen's Effect size (d).\n\n## Cohen's Effect Size\n\nThere is one other common way to express the difference between distributions. Cohen's $d$ is the difference in means, standardized by dividing by the standard deviation. Here's the math notation:\n\n$ d = \\frac{\\bar{x}_1 - \\bar{x}_2} s $\n\nwhere s is pooled std_dev"},{"metadata":{"trusted":true,"_uuid":"794f1775b11348db2bfb107ea61399e7a41a8e24"},"cell_type":"code","source":"print(\"Shape of X_Train = {}\".format(X_train.shape))\nprint(\"Shape of Y_Train = {}\".format(Y_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6b5a8663f8b480918b3dbdd0e4452718c977fd0"},"cell_type":"markdown","source":"The shapes of X_train and Y_train differs because data is normalized. Here, `series_id` act as the foreign key to Y_train. "},{"metadata":{"trusted":true,"_uuid":"f6cce57e26292f3b84dd0f2feb46a38b64cd97dc"},"cell_type":"code","source":"df = pd.merge(X_train, Y_train, on = \"series_id\", how = \"inner\")\nprint(\"Shape of df = {}\".format(df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3b57e6ee6ad076e01ffacc0451f368e8b53cd5"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22030440ac113ff96afbf13766704bf19100bc9a"},"cell_type":"code","source":"surface_df = df.surface.value_counts()\nsurface_df = pd.DataFrame(surface_df)\nsurface_df = surface_df.reset_index()\nsurface_df.columns = [\"surface\", \"value_counts\"]\n\nsns.barplot(surface_df.surface, surface_df.value_counts, alpha=0.8)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97c6b5e06a3c0dec7f56500c6fc39f3dd31511d7"},"cell_type":"markdown","source":"There is class imbalance problem here. When training model, it would be better if we go for Stratified KFold."},{"metadata":{"trusted":true,"_uuid":"ee6e1b7a35d59c047de07c7d96237d913ec18e12"},"cell_type":"code","source":"def cohen_effect_size(group1, group2):\n    diff = group1.mean() - group2.mean()\n    n1, n2 = len(group1), len(group2)\n    var1, var2 = group1.var(), group2.var()\n    pooled_var = ((n1*var1) + (n2*var2))/(n1 + n2)\n    d = diff/np.sqrt(pooled_var)\n    return d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb49fcb533745150f72f97dc743db3691751af4a"},"cell_type":"code","source":"def surface_effect_size(predictor, cutoff):\n    surface_1 = []\n    surface_2 = []\n    es = []\n    surface_list = list(surface_df.surface)\n    for surface in surface_list:\n        temp_list = surface_list\n        temp_list.remove(surface)\n        for surface_ in temp_list:\n            d = cohen_effect_size(df[predictor][df.surface == surface], df[predictor][df.surface == surface_])\n            if abs(d) > cutoff:\n               surface_1.append(surface)\n               surface_2.append(surface_)\n               es.append(abs(d)) \n    effect_df = pd.DataFrame({\n        \"surface_01\": surface_1,\n        \"surface_02\": surface_2,\n        \"effect_size\": es\n    })\n    return effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd7c2148c5b8ba91e396a850f8ea6cba5be69a27"},"cell_type":"code","source":"orientation_X_effect_df = surface_effect_size(\"orientation_X\", cutoff = 0.75)\norientation_X_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd8144bdf923b5459162a51f4660d0968699c474"},"cell_type":"code","source":"orientation_Y_effect_df = surface_effect_size(\"orientation_Y\", cutoff = 0.75)\norientation_Y_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1692dd52feba4588cccb86293d4f63971df99726"},"cell_type":"code","source":"orientation_Z_effect_df = surface_effect_size(\"orientation_Z\", cutoff = 0.75)\norientation_Z_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbce61166a4ad9296357a62be68c0244f6230f96"},"cell_type":"code","source":"angular_velocity_X_effect_df = surface_effect_size(\"angular_velocity_X\", cutoff = 0.25)\nangular_velocity_X_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da8d2a64a891522f4a2615cb8a036338484063ee"},"cell_type":"code","source":"angular_velocity_Y_effect_df = surface_effect_size(\"angular_velocity_Y\", cutoff = 0.5)\nangular_velocity_Y_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bda7017e16d300d258667d201677f23212b7a05"},"cell_type":"code","source":"angular_velocity_Z_effect_df = surface_effect_size(\"angular_velocity_Z\", cutoff = 0.5)\nangular_velocity_Z_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c8a605fbad8e1f9dee3c6184da24e701f8e06c1"},"cell_type":"code","source":"linear_acceleration_X_effect_df = surface_effect_size(\"linear_acceleration_X\", cutoff = 0.25)\nlinear_acceleration_X_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf7eb16531138bae146de529d2cc60b8e70a12cf"},"cell_type":"code","source":"linear_acceleration_Y_effect_df = surface_effect_size(\"linear_acceleration_Y\", cutoff = 0.25)\nlinear_acceleration_Y_effect_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6acab718349800ac1396d0370b07fbd8aa49083"},"cell_type":"code","source":"linear_acceleration_Z_effect_df = surface_effect_size(\"linear_acceleration_Y\", cutoff = 0.25)\nlinear_acceleration_Z_effect_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52e8147169d3f563d4bbc349314aec3a326ebbf0"},"cell_type":"markdown","source":"The Orientation parameters have significant effect size between various surface types. They can be very helpful for model. But, problem comes in the Angular Velocity and Linear Acceleration Parameters. They don't show any significant effect size. We can't drop these variables because they are important from domain perspective. These variable, if to be used in final prediction model, must be feature engineered so we can extract valuable information out of these variables."},{"metadata":{"_uuid":"82eafae0c9039b4e0fd1b8605e8425b0ecb754b3"},"cell_type":"markdown","source":"---\n# Model"},{"metadata":{"trusted":true,"_uuid":"e139c23edc2b183225dcce33fbda1b05a4e66e69"},"cell_type":"code","source":"encoder = LabelEncoder()\ndf.surface = encoder.fit_transform(df.surface)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"067532485ae49754d96aa7d03a4ea48c5f0d8b00"},"cell_type":"code","source":"drops = [\"row_id\", \"series_id\", \"measurement_number\", \"group_id\"]\nuse_cols = [c for c in df.columns if c not in drops]\n\nfeatures = list(df[use_cols].columns)\nmodel_df = df[use_cols]\n\nmodel_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54db152b973b7a5330c16f129af5823ae735bc59"},"cell_type":"code","source":"x = model_df.drop(columns = [\"surface\"])\ny = model_df[\"surface\"]\n\ntrain_X, test_X, train_Y, test_Y = train_test_split(x, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fece3cda35affb5b6671cd40f630d55a02495548"},"cell_type":"code","source":"xgboost = xgb.XGBClassifier(\n    max_depth = 5,\n    learning_rate = 0.05,\n    n_estimators = 100,\n    gamma = 0,\n    min_child_weight = 1,\n    subsample = 0.8,\n    colsample_bytree = 0.8,\n    reg_alpha = 0.005\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07b9603e2448e0006a27d751ed4190766a04b036"},"cell_type":"code","source":"xgboost.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60eda4e1d8cecff4ab12ece6d981c467d96eb835"},"cell_type":"code","source":"preds = xgboost.predict(test_X)\naccuracy = (preds == test_Y).sum().astype(float) / len(preds)*100\nprint(\"XGBoost's prediction accuracy WITH optimal hyperparameters is: %3.2f\" % (accuracy))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}