{"nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["import numpy as np \n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "import io\n", "import bson\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "from skimage.data import imread   \n", "import multiprocessing as mp\n", "import numpy as np\n", "import pandas as pd\n", "from collections import Counter\n", "from keras.utils import np_utils\n", "from tflearn.data_utils import to_categorical\n", "from tflearn.layers.core import input_data, dropout, fully_connected\n", "from tflearn.layers.conv import conv_2d, max_pool_2d\n", "from tflearn.layers.estimator import regression\n", "import tensorflow as tf\n", "import tflearn\n", "import skimage\n", "from skimage.transform import resize, rescale\n", "from tqdm import tqdm_notebook"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "a30d0276-3fb2-4a6f-a103-182f4c6b361f", "_uuid": "907bfcef5a9532a4ac6a07da03a8b3bf0ea0e673"}}, {"cell_type": "code", "source": ["def getRawFeatures(picture):\n", "    red = [] #red channel\n", "    green = [] #green channel\n", "    blue = [] #blue channel\n", "    for row in range(picture.shape[0]):\n", "        for col in range(picture.shape[1]):\n", "            red.append(picture[row][col][0])\n", "            green.append(picture[row][col][1])\n", "            blue.append(picture[row][col][2])\n", "    feature = red\n", "    feature.extend(green)\n", "    feature.extend(blue)\n", "    return feature"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "3d59df96-b98b-4b06-9c59-3b1657696960", "collapsed": true, "_uuid": "edb04253f1082f20e9d9b0db38bb9a79f89cac28"}}, {"cell_type": "code", "source": ["# pictures = [] \n", "# category_id_array = []\n", "# prod_id = []\n", "# prod_category = []\n", "# prod_num_imgs = []\n", "\n", "# #total\n", "# num_dicts = 82 \n", "\n", "\n", "# with open('../input/train_example.bson', 'rb') as f, tqdm_notebook(total=num_dicts) as bar:\n", "    \n", "#     data = bson.decode_file_iter(f)\n", "\n", "#     for c, d in enumerate(data):\n", "#         bar.update()\n", "#         prod_id.append(d['_id'])\n", "#         prod_category.append(str(d['category_id']))\n", "#         prod_num_imgs.append(len(d['imgs']))\n", "        \n", "#         for e, pic in enumerate(d['imgs']):\n", "#             #for each image\n", "#             picture = imread(io.BytesIO(pic['picture']))\n", "#             #rescaling the image\n", "#             image_rescaled = rescale(picture, 1.0 / 4.0)\n", "#             pictures.append(image_rescaled)\n", "#             category_id_array.append(str(d['category_id']))\n", "            \n", "            \n", "idProduct = []\n", "categoryProduct = []\n", "countProductImgs = []\n", "pictures = []\n", "catergoryIdArray = []\n", "totalDict = 82\n", "trainPath = '../input/train_example.bson'\n", "\n", "with open(trainPath, 'rb') as file, tqdm_notebook(total=totalDict) as bar:\n", "        \n", "    productDict = bson.decode_file_iter(file)\n", "\n", "    for c, myDict in enumerate(productDict):\n", "        bar.update()\n", "        idProduct.append(myDict['_id'])\n", "        categoryProduct.append(str(myDict['category_id']))\n", "        countProductImgs.append(len(myDict['imgs']))\n", "        \n", "        for e, myPic in enumerate(myDict['imgs']):\n", "        #display all images\n", "            picture = imread(io.BytesIO(myPic['picture']))\n", "            image_rescaled = rescale(picture, 1.0 / 4.0)\n", "            pictures.append(image_rescaled)\n", "    #         print(\"PRODUCT ID:\", product_id, \"NUMBER\", e)\n", "            plt.imshow(image_rescaled)\n", "            plt.show()\n", "            catergoryIdArray.append(str(myDict['category_id']))"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "9aa5ad99-854b-4c8d-8272-b7608ade7013", "_uuid": "09e74a2525c6d01eece9c586e3d0e468929aa709"}}, {"cell_type": "code", "source": ["X = np.asarray(pictures)\n", "y = np.asarray(catergoryIdArray)\n", "print(X.shape, y.shape)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "8c6c5612-5ff8-46e0-892e-6f02e33afd8c", "_uuid": "a0de41754653f149c486d638f4b3e60a2b4bb046"}}, {"cell_type": "code", "source": ["#reshaping X in proper format\n", "X = X.reshape(X.shape[0], 3, 45, 45).astype('float32')\n", "#normalizing X\n", "X = X - np.mean(X) / X.std()"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "c8ccdac7-53fd-4e23-a45e-60723dfeb875", "collapsed": true, "_uuid": "af197c03541dda67907f080ce2438d0ddbba1195"}}, {"cell_type": "code", "source": ["#converting class labels to One hot encoding\n", "b,y = np.unique(y, return_inverse=True) #returns the unique values\n", "y = np_utils.to_categorical(y) \n", "#y is converted to one hot representation"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "ae08e877-d96d-4811-a0f3-d76a373d9a37", "collapsed": true, "_uuid": "d8937b1b0ba6659e538e429de6c52994154b0333"}}, {"cell_type": "code", "source": ["print(X.shape)\n", "print(y.shape)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "0f160ce2-e6e0-4012-880c-f0c1a7982024", "_uuid": "25a793bf49164839f61c73103aaa84055b913bd2"}}, {"cell_type": "code", "source": ["#lets split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1234) \n", "#spliting the data\n", "\n", "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "c30bf63f-2976-49e3-a034-993c7a742f17", "_uuid": "fee9bf004b5faa8c9a9017d3b4e3f536c7e40a76"}}, {"cell_type": "code", "source": ["myConvModel = input_data(shape=[None,3,45,45])\n", "\n", "#Layer 1: Convolution and Pooling\n", "myConvModel = conv_2d(myConvModel,45,3,activation='elu')\n", "myConvModel = max_pool_2d(myConvModel,2)\n", "\n", "#Layer 2 Convolution and Pooling on important features\n", "myConvModel = conv_2d(myConvModel,100,2,activation='relu')\n", "myConvModel = max_pool_2d(myConvModel,2)\n", "\n", "#setting the dropout parameter to 30%\n", "myConvModel = dropout(myConvModel,0.3)\n", "\n", "#Layer 3 Convolution and Pooling with activation function elu\n", "myConvModel = conv_2d(myConvModel,100,2, activation='elu')\n", "myConvModel = max_pool_2d(myConvModel,2)\n", "\n", "#Layer 4\n", "myConvModel = fully_connected(myConvModel,512,activation='sigmoid')\n", "myConvModel = dropout(myConvModel,0.3)\n", "#Layer 5\n", "myConvModel = fully_connected(myConvModel,36,activation='softmax')\n", "myConvModel = regression(myConvModel,optimizer='adagrad',loss='categorical_crossentropy',learning_rate=0.05)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "d36632c3-5f3d-4f33-96cd-c2944c3c427f", "_uuid": "2f8a510cb73a6e00b9a4714ad93501cafc99dc2b"}}, {"cell_type": "code", "source": ["with tf.device('cpu:0'):\n", "   myConvModel = tflearn.DNN(myConvModel) #Training using DNN model class\n", "   myConvModel.fit(X_train , y_train, n_epoch=5, validation_set = (X_test, y_test), batch_size = 10) #fitting the data"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "71944e57-c4ea-4a9a-96d1-d9c44c5fc582", "_uuid": "570512a51e0db69eb81d78bb993020d44efa00ef"}}, {"cell_type": "code", "source": ["myConvModel.evaluate(X_test, y_test) #Finding accuracy"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "832f9b30-5a76-4b24-9f9f-333f790d16db", "_uuid": "7223b4fc5be2d015339adf84be607d3306009711"}}, {"cell_type": "code", "source": ["y_predict = myConvModel.predict(X_test)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "7fa6a658-f1dd-4885-b23c-a5e944e74261", "collapsed": true, "_uuid": "409fb578b71272a3fd6e51e59bf881bea0f3aef8"}}, {"cell_type": "code", "source": ["y_predict"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "9bb4296e-3af6-4fd1-982b-df1e6130efe9", "_uuid": "3dbce5268136e8b21333a48af24764a7b5a99de2"}}, {"cell_type": "code", "source": ["from sklearn.metrics import roc_curve, auc\n", "import itertools\n", "n_classes = 36\n", "y_score = y_predict\n", "\n", "# Compute ROC curve and ROC area for each class\n", "fpr = dict()\n", "tpr = dict()\n", "roc_auc = dict()\n", "for i in range(n_classes):\n", "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n", "    roc_auc[i] = auc(fpr[i], tpr[i])\n", "\n", "# Compute micro-average ROC curve and ROC area\n", "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n", "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n", "\n", "plt.figure()\n", "lw = 2\n", "plt.plot(fpr[2], tpr[2], color='darkorange',\n", "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n", "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('Receiver operating characteristic example')\n", "plt.legend(loc=\"lower right\")\n", "plt.show()\n", "\n", "\n", "# Compute macro-average ROC curve and ROC area\n", "\n", "# First aggregate all false positive rates\n", "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n", "\n", "# Then interpolate all ROC curves at this points\n", "mean_tpr = np.zeros_like(all_fpr)\n", "for i in range(n_classes):\n", "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n", "\n", "# Finally average it and compute AUC\n", "mean_tpr /= n_classes\n", "\n", "fpr[\"macro\"] = all_fpr\n", "tpr[\"macro\"] = mean_tpr\n", "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n", "\n", "# Plot all ROC curves\n", "plt.figure()\n", "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n", "         label='micro-average ROC curve (area = {0:0.2f})'\n", "               ''.format(roc_auc[\"micro\"]),\n", "         color='deeppink', linestyle=':', linewidth=4)\n", "\n", "colors = itertools.cycle(['aqua', 'darkorange', 'cornflowerblue'])\n", "\n", "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n", "plt.xlim([0.0, 1.0])\n", "plt.ylim([0.0, 1.05])\n", "plt.xlabel('False Positive Rate')\n", "plt.ylabel('True Positive Rate')\n", "plt.title('ROC Curve')\n", "#plt.legend(loc=\"lower right\")\n", "plt.show()"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "da4270bf-932b-49c1-ba53-e743bf975c17", "_uuid": "3bfae01a1190e27061783b584d261670b06ef24c"}}, {"cell_type": "code", "source": ["from sklearn import metrics\n", "metrics.auc(fpr[\"micro\"],tpr[\"micro\"]) #Area under the curve"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "aa07d395-9304-45a4-8380-e48a62bfd0e2", "_uuid": "6be553311aa8dd9d83721247d06b548ba949c028"}}, {"cell_type": "code", "source": ["metrics.log_loss(y_test, y_predict)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "90a34b2f-e426-43b6-ac82-4583b60d724a", "_uuid": "19dfe0f9bc822e0668db610dcbfff8b847a51132"}}, {"cell_type": "code", "source": [], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "e79df468-ccb9-46a4-ba33-7917777333a0", "collapsed": true, "_uuid": "c58b3eb42df83184532c41b7eb7d7f7a75d04717"}}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}