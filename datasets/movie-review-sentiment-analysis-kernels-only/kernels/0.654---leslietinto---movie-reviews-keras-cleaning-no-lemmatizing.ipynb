{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n'''\nOriginal code forked from: \n\nhttps://www.kaggle.com/dundee2002/rotten-tomatoes-movie-reviews-w-glove-lstm\n\ncode and comments added by Leslie Thomas marked LCT \n\n(Data cleaned, stop words NOT removed; No text blob to break into individual words and did NOT lemmatize) \n'''\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#%matplotlib inline\nimport os\n\nfrom nltk.corpus import stopwords # dealing with stop words\nfrom textblob import TextBlob # dealing with spelling correction\nfrom textblob import Word # dealing with lemmatization\nfrom sklearn.feature_extraction.text import TfidfVectorizer # leading with term frequency\n\nfrom wordcloud import WordCloud\nimport pandas, numpy, string #xgboost,\nimport re\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(\"done\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3853890977f01d20a8ae9444bfb02c35f14aeae8"},"cell_type":"code","source":"train = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/train.tsv', sep=\"\\t\")\ntest = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/test.tsv', sep=\"\\t\")\nsub = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv', sep=\",\")\n\n#EMBEDDING_FILE = ('../input/glovetwitter27b100dtxt/glove.twitter.27B.200d.txt') #, sep=\"\\t\")\n\n#print((EMBEDDING_FILE).head())\nprint(\"done\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df5506d0d516bd8faf9d53d6d06ca350504718d"},"cell_type":"code","source":"# Load Data\ndf = train\npd.set_option('display.max_colwidth', -1)\ndf.head()\n\ndf['Phrase'].tail()\n\ndf.info()\nprint(df.describe())\nprint(sub.describe())  #LCT\nsub_df = test    #   The values for the true test (not validation called test) set for submission \n\n# inspect sentiment\nsns.countplot(df['Sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6149cc2ef9f9570e965dd6d7dba8053527adc3bc"},"cell_type":"code","source":"# text length\ndf['text_length'] = df['Phrase'].apply(len)\ndf[['Sentiment','text_length','Phrase']].head()\n\nprint(df['text_length'].describe())\n\ndf['text_length'].hist(bins=50)\n\ng = sns.FacetGrid(df,col='Sentiment')\ng.map(plt.hist,'text_length')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6771153fdf60042a0ab02d6cfe10afafd4a7d9e"},"cell_type":"code","source":"sns.boxplot(x='Sentiment',y='text_length',data=df,palette='rainbow')\n\n# noted that length of neutral has the shortest phrases and longer towards\n# the extremes with the negative side being slightly longer than the positive end.  \n# maybe the individuals providing bad reviews really like to rant! \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b04c0286219c3af101381cd39da140f486133455"},"cell_type":"code","source":"#Data cleaning added by LCT and Bruce Pham\n\n\ntext1 = df['Phrase'].to_string()  # need to convert to string to create a word cloud\n\n\n###########################  LCT clean data #######################################\ndef clean_text(text):\n     #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n     text = re.sub('[%s]' % re.escape(string.digits), '', text)\n     text = re.sub('[%s]' % re.escape(' +'), ' ', text)\n     text = text.replace(' n\\'t', ' not')   # LCT convert contractions\n     text = text.replace('it \\'s', 'it is')\n     text = text.replace('there \\'s', 'there is')\n     text = text.replace('he \\'s', 'he is')\n     text = text.replace('she \\'s', 'she is')\n     text = text.replace('what \\'s', 'what is')\n     text = text.replace('that \\'s', 'that is')\n     text = text.replace(' \\'s', '')\n     text = text.replace('\\'s', '')\n     text = text.replace('s \\'', '')\n     text = text.replace('-lrb-', '')  # LCT remove left and right brackets as they do not add sentiment\n     text = text.replace('-LRB-', '')\n     text = text.replace('-rrb-', '')\n     text = text.replace('-RRB-', '')\n     text = text.lower()\n     text = text.strip()\n     return text\n\ntext1 = clean_text(text1)\n\ntext = text1\n#############################################################################\n# word cloud\n\nwordcloud = WordCloud(\n        relative_scaling=0.5,\n        stopwords=set(stopwords.words('english'))).generate(text)\n\nplt.figure(figsize=(12,12))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.show()\n\n# notice the words Film and Movie are prominent in the word cloud","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e75dc1a375588be6b38266ed7fe75d20e252335"},"cell_type":"code","source":"################ CLEAN TRAIN AND TEST #####################################################\n\ntrain['Phrase_clean_text'] = train['Phrase'].apply(lambda x: clean_text(x))\nsub_df['Phrase_clean_text'] = sub_df['Phrase'].apply(lambda x: clean_text(x))\n###################################################\n\n# stopwords and lemmatizing based on : \n#https://www.kaggle.com/up201204722/movie-sentiment-analysis\n############## TAKE OUT STOP WORDS\n#Decided not to remove stop words as some phrases are only one word and the reviews are filled with stop words\n#Also, it deteriorated the performance of the model \n\n#del stopwords \n\n#stop = stopwords.words('english')\n\n#newStopWords = ['movie','film']  # LCT add stop words that don't differentiate reviews\n#stop.extend(newStopWords)\n#len(stop)\n\n#train['Phrase_clean_text'] = train['Phrase_clean_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n#sub_df['Phrase_clean_text'] = sub_df['Phrase_clean_text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n\n\n# Also decided not to use text blob to break phrases into individual words as some phrases are only one word long \n# tried this but it made performance worse \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54b770336061d825bfd381c780c19a05dc779399"},"cell_type":"code","source":"######  OMITTING LEMMATIZING THIS TIME TO SEE IMPACT \n\n\n#from #https://www.kaggle.com/up201204722/movie-sentiment-analysis\n#Lemmatization Lemmatization is a more effective option than stemming because\n# it converts the word into its root word, rather than just stripping the suffixes. \n#It makes use of the vocabulary and does a morphological analysis to obtain the root word.\n# Therefore, we usually prefer using lemmatization over stemming.\n ###############\n\n#train['Phrase_clean_text'] = train['Phrase_clean_text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n#sub_df['Phrase_clean_text'] = sub_df['Phrase_clean_text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n\nprint(\"complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0defde2c95dcdc16570e9e8393d925e8a90df2fc"},"cell_type":"code","source":"# Encode Categorical Variable\nfrom keras.utils import to_categorical\nX = df['Phrase_clean_text']   # modified\ny = to_categorical(df['Sentiment'])\nnum_classes = df['Sentiment'].nunique()\ny\n\n# LCT  prepare the data provided for test (not to confused with the validation set\n# called test) \n\nX_sub = sub_df['Phrase_clean_text']  # added by LCT # modified\n########################################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba34643174f8bd73801790dde93350e85cc7a049"},"cell_type":"code","source":"seed = 101 # fix random seed for reproducibility\nnp.random.seed(seed)\n\n# Spilt Train Test sets\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2,\n                                                    stratify=y,\n                                                    random_state=seed)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5bcdd7cf4133fa6e21535680bd3b8c5b2c82ad0"},"cell_type":"code","source":"########################################################\n\n# Tokenize Text\nfrom keras.preprocessing.text import Tokenizer\nmax_features = 15000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)\n\n# tokenize X_sub = test set for submission #LCT\nX_sub = tokenizer.texts_to_sequences(X_sub)  #LCT\n\ntotalNumWords = [len(one_comment) for one_comment in X_train]\nplt.hist(totalNumWords,bins = 30)\nplt.show()\n\nfrom keras.preprocessing import sequence\nmax_words = 30 #max(totalNumWords)\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)\nprint(X_train.shape,X_test.shape)\n\n# pad test set for submission   #LCT \nX_sub = sequence.pad_sequences(X_sub, maxlen=max_words)\n\n\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n\nbatch_size = 256\nepochs = 5\n\ndef get_model(max_features, embed_dim):\n    np.random.seed(seed)\n    K.clear_session()\n    model = Sequential()\n    model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1]))\n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model\n\ndef model_train(model):\n    # train the model\n    model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n                          epochs=epochs, batch_size=batch_size, verbose=2)\n    # plot train history\n    plot_model_history(model_history)\n    \ndef plot_model_history(model_history):\n    fig, axs = plt.subplots(1,2,figsize=(15,5))\n    # summarize history for accuracy\n    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy')\n    axs[0].set_xlabel('Epoch')\n    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n    axs[0].legend(['train', 'val'], loc='best')\n    # summarize history for loss\n    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss')\n    axs[1].set_xlabel('Epoch')\n    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n    axs[1].legend(['train', 'val'], loc='best')\n    plt.show() \n    \n    \ndef model_evaluate(): \n    # predict class with test set\n    y_pred_test =  model.predict_classes(X_test, batch_size=batch_size, verbose=0)\n    print('Accuracy:\\t{:0.1f}%'.format(accuracy_score(np.argmax(y_test,axis=1),y_pred_test)*100))\n    \n    #classification report\n    print('\\n')\n    print(classification_report(np.argmax(y_test,axis=1), y_pred_test))\n\n    #confusion matrix\n    confmat = confusion_matrix(np.argmax(y_test,axis=1), y_pred_test)\n\n    fig, ax = plt.subplots(figsize=(4, 4))\n    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n    for i in range(confmat.shape[0]):\n        for j in range(confmat.shape[1]):\n            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')\n    plt.tight_layout()    \n\n# train the model\nmax_features = 15000\nembed_dim = 100\nmodel = get_model(max_features, embed_dim)\nmodel_train(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"139df2a1cdbce3cef5c2dd3811e6c5a3ec042f43"},"cell_type":"code","source":"# Look at that elbow at the end of the second epoch in graph above for the validation set (orange line)\n# It appears that additioal epochs beyond 2 do not add value in the model. The improvement in model accuracy even for the training set (blue line)\n# even starts to drop off here. \n\n# evaluate model with test set\nmodel_evaluate()\n\n\n#############################################################\n\n# LCT predicts to submit for this model\n\ny_pred=model.predict_classes(X_sub)  # predict for prepared test set to submit\ny_pred\n\nlen(y_pred)\n\ntestPred= np.array(y_pred).transpose().tolist()\n\nlen(testPred)\n\nsub.Sentiment=testPred\nsub.head()\n\nsub.to_csv('keras_dundee_clean_only_No_Lemmat.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d4f710de90dd71eeb3297c14e698efa67307b79"},"cell_type":"code","source":"############KERAS DEEP LEARNING MODEL with Twitter Embedding ###############\n\ndef get_coefs(word, *arr):\n    return word, np.asarray(arr, dtype='float32')\n    \ndef get_embed_mat(EMBEDDING_FILE, max_features=20000):\n    # word vectors\n    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n    print('Found %s word vectors.' % len(embeddings_index))\n\n    # embedding matrix\n    word_index = tokenizer.word_index\n    num_words = min(max_features, len(word_index) + 1)\n    all_embs = np.stack(embeddings_index.values()) #for random init\n    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n                                        (num_words, embed_dim))\n    for word, i in word_index.items():\n        if i >= max_features:\n            continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    max_features = embedding_matrix.shape[0]\n    \n    return max_features, embedding_matrix\n\ndef get_model(max_features, embed_dim, embedding_matrix):\n    np.random.seed(seed)\n    K.clear_session()\n    model = Sequential()\n    model.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],\n                       weights=[embedding_matrix]))#,trainable=False\n    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model\n\nEMBEDDING_FILE = '../input/glovetwitter27b100dtxt/glove.twitter.27B.200d.txt'\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec6a10bbe1786a0c9d28bdb0676e8495803d983e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2642975fc59173a4a820e803228c625b3474eeb"},"cell_type":"code","source":"\nembed_dim = 200 #word vector dim\nmax_features, embedding_matrix = get_embed_mat(EMBEDDING_FILE)\n\n# train the model\nmodel = get_model(max_features, embed_dim, embedding_matrix)\nmodel_train(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"682398127608d8f0af1946af8108b07b216a75fd"},"cell_type":"code","source":"# evaluate model with test set\nmodel_evaluate()\n\n# LCT predicts to submit\n\ny_pred=model.predict_classes(X_sub)  # predict for prepared test set to submit\ny_pred\n\nlen(y_pred)\n\ntestPred= np.array(y_pred).transpose().tolist()\n\nlen(testPred)\n\nsub.Sentiment=testPred\nsub.head()\n\nsub.to_csv('subm_twit_clean_No_Lemma.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}