{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"![](http://)**Analyzing and Cleaning Data**"},{"metadata":{"trusted":true,"_uuid":"20912cbdd88d6c6e2b5f730dde12e60b5b1388a0"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain['Dataset'] = \"train\"\ntest['Dataset'] = \"test\"\n\nall_data = train.append(test, sort='True')\nall_data.info()\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b4c4a7cba6b50a7d8afdbc9756783dff6a30663"},"cell_type":"markdown","source":"**Cabin and Ticket do not look loke a useful variables**"},{"metadata":{"trusted":true,"_uuid":"6204b381374064ac7581671d09f1dbfa17d77179","collapsed":true},"cell_type":"code","source":"to_drop = ['Ticket', 'Cabin']\nall_data.drop(columns = to_drop, inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9dbc2f8293bdf8e52f4ce7ae1d1e1a006914d99"},"cell_type":"code","source":"all_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7ca5c92eb3e9523d16d3d0b61b98ae21198714f"},"cell_type":"code","source":"all_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index = False).mean().sort_values(by = ['Survived'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4650f74131d13c7d086c9cbed6fbccd768040caf"},"cell_type":"code","source":"all_data[['Sex', 'Survived']].groupby(['Sex'], as_index = False).mean().sort_values(by = ['Survived'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aeeb6bbffb6fceb36b88cd511fc23a1f22a075db"},"cell_type":"code","source":"all_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index = False).mean().sort_values(by = ['Survived'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fd1f37f145d6c7bc2eac73c7de99875f4ba731a"},"cell_type":"code","source":"all_data[['Parch', 'Survived']].groupby(['Parch'], as_index = False).mean().sort_values(by = ['Survived'], ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1413b9e629012b979014b0af6055dceceb93a93"},"cell_type":"code","source":"corrMatrix = all_data[['Age', 'Embarked', 'Fare', 'Name', 'Parch', 'Pclass', 'Sex', 'SibSp']].corr()\n\n# Masking upper triangle as values are same as lower traingle\nmask = np.zeros_like(corrMatrix, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nmask[np.diag_indices_from(mask)] = False\n\n# Initializing matplotlib figure\nfig, ax = plt.subplots(figsize=(10,10))\ncolor = sns.diverging_palette(200, 15, as_cmap = True)\nsns.heatmap(corrMatrix, mask = mask, cmap = color, square = True, annot = True, vmax = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b304b67b1c0467ee9135c6f1d27735f4ce2a34e8"},"cell_type":"markdown","source":"**Filling null values for Fare**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e674520c230239065d7bb3630e7e42a45ae4ceba"},"cell_type":"code","source":"display(all_data[all_data['Fare'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5117aeef673c81c72fa10398f3b7250b28c84424"},"cell_type":"code","source":"df_class_emb = all_data['Fare'].loc[(all_data['Embarked'] == 'S') & (all_data['Pclass'] == 3)]\nplt.figure(figsize=[10,10])\nsns.distplot(df_class_emb.dropna(), color='C0')\nplt.plot([df_class_emb.median(), df_class_emb.median()], [0, 0.16], '--', color='C1')\n\nsns.despine(offset = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2e1e8bdedc1ccbd3b358f0d6bdcade3cc0a5dcd","collapsed":true},"cell_type":"code","source":"all_data['Fare'] = all_data['Fare'].fillna(df_class_emb.median())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47a9b455982a645caf80b287654aaaa2ca255fe5"},"cell_type":"markdown","source":"**Creating FareRange**"},{"metadata":{"trusted":true,"_uuid":"9418409d992b63c98a4766f2012e01254201f96b"},"cell_type":"code","source":"all_data['FareRange'] = pd.qcut(all_data['Fare'], 4)\nall_data[['FareRange', 'Survived']].groupby(['FareRange'], as_index = False).mean().sort_values(by = 'FareRange', ascending = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3a38aee81650e0a8ecb9fe16daf50a31c593fb2"},"cell_type":"code","source":"all_data.loc[all_data['Fare'] <= 7.91, 'Fare'] = 0\nall_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1\nall_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare']   = 2\nall_data.loc[ all_data['Fare'] > 31, 'Fare'] = 3\nall_data['Fare'] = all_data['Fare'].astype(int)\n\nall_data = all_data.drop(['FareRange'], axis=1)\n    \nall_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfac39a606716f9869039de286eaa51870cb8f57"},"cell_type":"markdown","source":"**Filling null values for Embarked**"},{"metadata":{"trusted":true,"_uuid":"d8969cb6a9951af8e98c853b4a29ccd8f3df1931"},"cell_type":"code","source":"display(all_data[all_data['Embarked'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d00d59be7d603f522b00ca7088705c9691c85a81"},"cell_type":"code","source":"all_data['Embarked'] = all_data['Embarked'].fillna('C')\ndisplay(all_data[all_data['Embarked'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfc8c92b30ed25979a5a3b4f68f4b7bfa734b2ad"},"cell_type":"markdown","source":"\n**Analyzing null values for Age**"},{"metadata":{"trusted":true,"_uuid":"e59bc09e19039571d4a3b554d69d4d1f9f0f458c"},"cell_type":"code","source":"display(all_data[all_data['Age'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"946f8180cd18ba7d18be03c44271d727847bb0be"},"cell_type":"code","source":"plt.figure(figsize=[10,10])\nsns.distplot(all_data['Age'].dropna(), color='C0')\nplt.plot([all_data['Age'].median(), all_data['Age'].median()], [0, 0.4], '--', color = 'C1')\nplt.plot([all_data['Age'].mean(), all_data['Age'].mean()], [0, 0.2], '-', color = 'C2')\n\nsns.despine(offset = 10)\nplt.title('Distribution plot of Age data for all passengers')\nplt.xlabel('Age')\nplt.legend(['median', 'mean'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"047c57132e93aa9f6f13ffb8cd57d14890d91465"},"cell_type":"code","source":"g = sns.FacetGrid(all_data, col='Survived')\ng.map(plt.hist, 'Age', bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38ec5f725d293bb5a740a96df8ce6bb8e1d3153f"},"cell_type":"code","source":"grid = sns.FacetGrid(all_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"964a8cd5253d478c64044494e309476fd200e462"},"cell_type":"code","source":"grid = sns.FacetGrid(all_data, row='Embarked', size=2.2, aspect=1.6)\ngrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\ngrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"849f6b3e9deb24f35afcc8c03c43f8a6acb5c131"},"cell_type":"markdown","source":"**Creating new features**"},{"metadata":{"trusted":true,"_uuid":"70ebae87c9a020a2af282d30d40ed1ce4fc4266d"},"cell_type":"code","source":"all_data['Title'] = all_data.Name.str.extract(' ([A-Za-z]+)\\.', expand = False)\n    \npd.crosstab(all_data['Title'], all_data['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a681d1ff167a9117e8ed11b289b4bf0147293d3"},"cell_type":"code","source":"# Merging all columns with similar values and grouping rare values as \"Other\"\nall_data['Title'] = all_data['Title'].replace(['Capt', 'Col', 'Countess', 'Don', 'Dona', 'Dr', 'Jonkheer', 'Lady', 'Major', 'Rev', 'Sir'], 'Other')\n\nall_data['Title'] = all_data['Title'].replace(['Ms'], 'Miss')\nall_data['Title'] = all_data['Title'].replace(['Mlle'], 'Miss')\nall_data['Title'] = all_data['Title'].replace(['Mme'], 'Mrs')\n\nall_data[['Title', 'Survived']].groupby('Title', as_index = False).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ced120f4531a91e8e31a1cc9f8c3849a49711e03"},"cell_type":"markdown","source":"**Converting Categorical Features to Numerical Values**"},{"metadata":{"trusted":true,"_uuid":"b87696588fa4354bf174d99eff9cb2428dbb4a49","collapsed":true},"cell_type":"code","source":"# For 'Name' feature\n\ntitle_map = {'Master':0, 'Miss':1, 'Mr':2, 'Mrs':3, 'Other':4}\nall_data['Title'] = all_data['Title'].map(title_map)\nall_data['Title'] = all_data['Title'].fillna(-1)\n\n# Dropping \"Name\" feature after processing\nall_data.drop(columns = ['Name'], inplace = True, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2425010e81b938bed387efe9783e7f2a4c5b56af"},"cell_type":"code","source":"# For Sex feature\nall_data['Sex'] = all_data['Sex'].map({'male':0, 'female':1}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f31b3eaca0060e56c7abbd57ab5be285a241bd68","collapsed":true},"cell_type":"code","source":"# For Embarked feature\nall_data['Embarked'] = all_data['Embarked'].map({'S':0, 'C':1, 'Q':2}).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d5ba0eba9f7d504fb9edd5b463e858f83d1b282"},"cell_type":"markdown","source":"***Filling missing values of Age now***"},{"metadata":{"trusted":true,"_uuid":"55fef0ff498c5a3c7b514f0880414801af8c8cc6"},"cell_type":"code","source":"# Due to correlation between Age and Pclass\nguess_ages = np.zeros((2,3))\nfor i in range(0, 2):\n    for j in range(0, 3):\n        guess_df = all_data[(all_data['Sex'] == i) & (all_data['Pclass'] == j+1)]['Age'].dropna()\n        age_guess = guess_df.median()\n\n        # Convert random age float to nearest .5 age\n        guess_ages[i,j] = int(age_guess / 0.5 + 0.5) * 0.5\n            \nfor i in range(0, 2):\n    for j in range(0, 3):\n        all_data.loc[ (all_data.Age.isnull()) & (all_data.Sex == i) & (all_data.Pclass == j+1),'Age'] = guess_ages[i,j]\n\nall_data['Age'] = all_data['Age'].astype(int)\n\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5548a359260a4f16c36b4adb946fdcd12a3910d0"},"cell_type":"markdown","source":"**Creatin Age ranges and their correlation with Survival**"},{"metadata":{"trusted":true,"_uuid":"0acf1689dd1a3d2305605395db3a00d80081ebf1"},"cell_type":"code","source":"all_data['AgeRange'] = pd.cut(all_data['Age'], 5)\nall_data[['AgeRange', 'Survived']].groupby(['AgeRange'], as_index=False).mean().sort_values(by='AgeRange', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dbc7201b07f72bbef6d33d0cd5f1f92b9290348"},"cell_type":"code","source":"all_data.loc[all_data['Age'] <= 16, 'Age'] = 0\nall_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 32), 'Age'] = 1\nall_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 2\nall_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 3\nall_data.loc[ all_data['Age'] > 64, 'Age']\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d41d49e201135c1a213607638254da417da03d0"},"cell_type":"code","source":"# Now we remove AgeRange feature\nall_data = all_data.drop(['AgeRange'], axis = 1)\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c3e3f4468aae97273d0af3464388431d92e7e44"},"cell_type":"markdown","source":"**Creating new features**"},{"metadata":{"trusted":true,"_uuid":"c92ca70723f634b6c04616ae95217dbdcb2dd1d8"},"cell_type":"code","source":"all_data['FamilySize'] = all_data[\"SibSp\"] + all_data[\"Parch\"] + 1\n\nall_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index= False).mean().sort_values(by = 'Survived', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58465f5a26ad1a03a54d45fb9a8986e82ff5ff60"},"cell_type":"code","source":"all_data['IsAlone'] = 0\nall_data.loc[all_data['FamilySize'] == 1, 'IsAlone'] = 1\n\nall_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index = False).mean().sort_values(by = 'Survived', ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22df835f30dfa670e5dc7281faaacba8fe318fd8"},"cell_type":"code","source":"all_data = all_data.drop(['Parch', 'SibSp', 'FamilySize'], axis = 1)\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0a7e2e38ae9c3e30f7e01d382b5d6047ade01f1"},"cell_type":"markdown","source":"Phew! Done with cleaning, moving on to the fun part :)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"041f04a8e5408882cbbaa76596e66871f40245a5"},"cell_type":"markdown","source":"**Model and get Results!!!!**"},{"metadata":{"trusted":true,"_uuid":"719f4ae1d2aa34ea67536246c8c8f3d9e86a44f9"},"cell_type":"code","source":"train_data = all_data[all_data['Dataset'] == 'train']\ntrain_data = train_data.drop(['Dataset', 'PassengerId'], axis = 1)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10962be88710845da678fae237b7debd46ba77a6"},"cell_type":"code","source":"test_data = all_data[all_data['Dataset'] == 'test']\ntest_data = test_data.drop(['Dataset', 'PassengerId', 'Survived'], axis = 1)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84a07f5aab390255f4bba96e107e4cb98591f4e4"},"cell_type":"markdown","source":"**Split train and validation set**"},{"metadata":{"trusted":true,"_uuid":"7816d814f0c817af88c9f58935e0ce874b6f68c8"},"cell_type":"code","source":"train_size = int(train.shape[0] * 0.85)\n\ntrain_dataset = train_data[:train_size]\nval_dataset = train_data[train_size:]\n\nX_train = (train_dataset.drop(labels=[\"Survived\"], axis=1).values).T\nY_train =  np.reshape(train_dataset[\"Survived\"].values, (1, len(train_dataset)))\n\nX_val = (val_dataset.drop(labels=[\"Survived\"], axis=1).values).T\nY_val = np.reshape(val_dataset[\"Survived\"].values, (1, len(val_dataset)))\n\nX_test = (test_data.values.astype(np.float32)).T\n\ninput_size = len(train_dataset.columns) - 1  # number of final features\ninput_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bda7b20e10ec2dde127e6da2136fdbc571262b7"},"cell_type":"code","source":"print(X_train.shape, X_val.shape)\nprint(Y_train.shape, Y_val.shape)\nprint(X_test.shape)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6e2e405db92d15625c1a515b1e73859a4ac9e86"},"cell_type":"markdown","source":"**Neural Network with TensorFlow**"},{"metadata":{"trusted":true,"_uuid":"295ac923f82f078bfc4bb149c1a1224c0ace5505","collapsed":true},"cell_type":"code","source":"import math\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb4df1f2d6e386a11258dde7be59918e0798f7c","collapsed":true},"cell_type":"code","source":"def create_placeholders(n_x, n_y):\n    # n_x - number of features\n    # n_y - number of classes\n    X = tf.placeholder(tf.float32, [n_x, None], name = 'X')\n    Y = tf.placeholder(tf.float32, [n_y, None], name = 'Y')\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba2ce7718d11ccf5c7ec6b83d258553cb1a5273","collapsed":true},"cell_type":"code","source":"def initialize_parameters():                  \n    W1 = tf.get_variable(\"W1\", [7,7], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b1 = tf.get_variable(\"b1\", [7,1], initializer = tf.zeros_initializer())\n    W2 = tf.get_variable(\"W2\", [5,7], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b2 = tf.get_variable(\"b2\", [5,1], initializer = tf.zeros_initializer())\n    W3 = tf.get_variable(\"W3\", [1,5], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2,\n                  \"W3\": W3,\n                  \"b3\": b3}\n    \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c5f59c220755087bc95ead85866fd2583a651c9","collapsed":true},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    # Retrieve the parameters from the dictionary parameters\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n\n    Z1 = tf.add(tf.matmul(W1, X), b1)                                   \n    A1 = tf.nn.elu(Z1)                                              \n    Z2 = tf.add(tf.matmul(W2, A1), b2)                                      \n    A2 = tf.nn.elu(Z2)                                         \n    Z3 = tf.add(tf.matmul(W3, A2), b3)\n    \n    return Z3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78305ebf728a2214175e6b0cf483d55dfa1b7df5","collapsed":true},"cell_type":"code","source":"def compute_cost(Z3, Y):\n    logits = tf.transpose(Z3)\n    labels = tf.transpose(Y)\n    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logits, labels = labels))\n    \n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ca896e21230abe4f0faa64c22ff7542ab6363680"},"cell_type":"code","source":"def random_mini_batches(X, Y, mini_batch_size = 32, seed = 0):\n    \n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n    \n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49d0760d13681343a74269f5a9744dd4f0855bcf","collapsed":true},"cell_type":"code","source":"def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.003, num_epochs = 1500, minibatch_size = 32, print_cost = True):\n    # Implements a three layer layer neural network using tensorflow\n    \n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep consistent results\n    seed = 3                                          # to keep consistent results\n    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n    n_y = Y_train.shape[0]                            # n_y : output size\n    costs = []                                        # To keep track of the cost\n\n    X, Y = create_placeholders(n_x, n_y)\n\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    cost = compute_cost(Z3, Y)\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n    \n    init = tf.global_variables_initializer()\n\n    with tf.Session() as sess:\n        sess.run(init)\n        for epoch in range(num_epochs):\n            epoch_cost = 0.                       # Defines a cost related to an epoch\n            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n\n            for minibatch in minibatches:\n                (minibatch_X, minibatch_Y) = minibatch\n                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n                epoch_cost += minibatch_cost / num_minibatches\n                \n            if print_cost == True and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n                \n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        parameters = sess.run(parameters)\n        print (\"Parameters have been trained!\")\n        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n        \n        return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5bd7e83a3fdf76b46f2b0fbc4a14d7fe907558"},"cell_type":"code","source":"model_params = model(X_train, Y_train, X_val, Y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57f6808d53add82465e8f3aadf2758c6891f01cb"},"cell_type":"code","source":"def predict(parameters, X):\n    predictions = forward_propagation(X, parameters)\n    \n    return predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c089f7d6c7961700ab6a30bc224cf1cd3896b7f0","collapsed":true},"cell_type":"code","source":"y_prediction = predict(model_params, X_test)\nsess = tf.Session()\nwith sess.as_default():\n    out = np.round((tf.nn.sigmoid(y_prediction)).eval())\ndf_test = pd.read_csv(\"../input/test.csv\")\noutput = pd.DataFrame({'PassengerId': df_test['PassengerId'], 'Survived': np.squeeze((out.astype(int)).reshape(-1))})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d04dd7708f245ea30e8c0d5c261dce8b3b8ce924"},"cell_type":"code","source":"output.to_csv('submission.csv', index=False)\nprint(output.groupby('Survived').count())\noutput","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7c0829df38e8a830b6c636b22a9afe339cce8b77"},"cell_type":"markdown","source":"**Analyzing result**"},{"metadata":{"trusted":true,"_uuid":"87d2fd376bc277c2344d7aee12a850fd2d82c0c4","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\ndf = pd.read_csv(\"../input/gender_submission.csv\")\nsurvived_actual = df['Survived']\nsurvived_predicted = output['Survived']\n\nconf_mat = confusion_matrix(survived_actual, survived_predicted)\n# true positives(tp) : (1,1) --> predicted 1 and actual was 1\n# true negatives(tn) : (0,0) --> predicted 0 and actual was 0\n# false positives(fp): (0,1) --> predicted 1 and actual was 0\n# false negatives(fn): (1,0) --> predicted 0 and actual was 1 \ntp = conf_mat[1,1]\ntn = conf_mat[0,0]\nfp = conf_mat[0,1]\nfn = conf_mat[1,0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68e75ebe6c03bc74947b8da17947191e8f3a0d22"},"cell_type":"markdown","source":"**Calculate precision and recall**"},{"metadata":{"trusted":true,"_uuid":"277dd7cb63f97debba123a2a5f260e98241e1ce8"},"cell_type":"code","source":"precision = tp / (tp + fp)\nrecall = tp / (tp + fn)\nfscore = 2 * (precision * recall)/ (precision + recall)\n\nprint('Precision: ', precision)\nprint('Recall: ', recall)\nprint('F1 Score: ', fscore)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ada448067bb51e07824fd5be3745216fdbdad42c","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"540c6271200229b553b00ebce3c313463051a270","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"17da37622915f23da28d44f3054853ea1b07e260"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce6e3f2e7d7f44423dfa68430e6b238b2cbb0638"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ecb81fbc2b7ebcd205779b2aae59cade602093d6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"19798ef29b98b1fd824f9ee646b06bb8ead1f617"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1ae4de4163f03abc9dd7957a53e7116ff8b3c7a5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}