{"nbformat_minor": 0, "cells": [{"source": "A logistic regression implemented with Sklearn and a simple Neural Network, implied with TensorFlow is applied to the Credit Card fraud data. Due to the highly imbalanced data set, the accuracy is not a good metric. Instead the area und the precision recall curve is used. ", "metadata": {"_execution_state": "idle", "_cell_guid": "85fa6083-cd6d-4c00-a587-deb4d81d49cd", "collapsed": false, "_uuid": "c686f8ba09f7652125d5b0c622a64978e62343b0"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"execution_count": null, "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "bb1577fc-698f-4fc4-86ae-4685d6ac4e2b", "_uuid": "34d9af0ebffbee227d9516f742872219ec5ca926"}, "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import average_precision_score,confusion_matrix,precision_recall_curve\nfrom sklearn.model_selection import train_test_split,GridSearchCV\nimport itertools\n", "cell_type": "code", "outputs": []}, {"source": "### Load and data ###\ndata=pd.read_csv(\"../input/creditcard.csv\",sep=',')\nlabels=np.array(data[:]['Class'])\nfeatures=np.array(data.iloc[:,1:30]) #ommit columns 'time' and 'Class'\n\n#Print some statistics\nnum_samples,num_features=features.shape\nnum_frauds=data[data['Class']==1].shape[0]\nprint(\"Data set consists of {0} samples with {1} features. Only {2} of these samples are frauds\"\n      .format(num_samples,num_features,num_frauds))\n\n# Split data into test and trining data\nX_train, X_test, y_train, y_test = train_test_split(features,labels, test_size=0.25,stratify=labels)", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "ce51ff38-b84a-49ba-85ab-85bbce6e8c09", "collapsed": false, "_uuid": "33cc9567a18c2534dc7eef5f7cf565f73a4639b0"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "##  Logistic Regression", "metadata": {"_execution_state": "idle", "_cell_guid": "1cad4fa9-3b11-4226-bd49-2e4082e186b1", "collapsed": false, "_uuid": "a7edaf3bfeb4560f42f1bfb9e71a0373a6709b2f"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"source": "\n# Fit training data with a  Logistic Regression classifier, using several regularization parameters C\n# As a scoring metric, the area under the precision recall curve is used (detailed later)\n\nparams=[{'C':[1,10,100]}]\nclf=GridSearchCV(LogisticRegression(),params,scoring='roc_auc')\nclf.fit(X_train, y_train)\n\nprint(\"Best parametrers found: {}\".format(clf.best_params_))\n\n## Store the predictions and the probabilities (of the transaction being labeld fraud) of the best model\npredictions_logreg=clf.best_estimator_.predict(X_test)\nprobabilities_logreg=clf.best_estimator_.predict_proba(X_test)", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "883a35a0-6bed-4e1d-b11a-e1be825f768d", "collapsed": false, "_uuid": "e80c333ce28b2bb7687563b44047d575d6b6aa06"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "## Confusion Matrix\n\nAccuracy is not a good metric here as data set is heavily skewed, as we could acchieve a score >99% easily by consistantly predicting False (no fraud). We can plot the confusion matrix to give us a better idea. The elements of the matrix are:\n\n- True-Positive:  Fraud predicted when fraud occured -> (4th quadrant on Confusion matrix)\n- False-Positive: Fraud predicited, when no fraud has occured (\"false alarm\") -> (1st quadrant CM)\n- False-Negative: Regular transaction predicted, actual fraud occured  -> (3rd quadrant CM)\n- True-Negative: Regular transaction correctly predicted -> (2nd Quadrant)", "metadata": {"_execution_state": "idle", "_cell_guid": "533df48b-d951-4c0b-a3c3-88d903302318", "collapsed": false, "_uuid": "8773a1178621daa9de8424f63cddfefd0ad57f08"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"source": "def plot_confusion_matrix(cm, classes, title='Confusion matrix',cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix -> taken from official scikit-learn webpage\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ncnf_matrix=confusion_matrix(y_test,predictions_logreg)     \nfig,ax = plt.subplots()\nplot_confusion_matrix(cnf_matrix, classes=[\"Regular\",\"Fraud\"],\n                      title='Confusion Matrix for Logistic Regression')\nplt.show()", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "14412563-7804-411f-95d0-7a1d92f81b7d", "collapsed": false, "_uuid": "b7fbd3f9e7b548137466944d21a1ba3e40b90334"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "## Precision Recall Curve\n\nConfusion matrix shows classification when p=0.5 is used as a treshold. In our case, it may be reasonable to adjust the threshold in order to obtain less false-negatives, while increasing the false positives. We are interested in a high recall:\n\n$\\mathrm{Precision} = \\frac{T_p}{T_p+F_p}$\n\n$\\mathrm{Recall} = \\frac{T_p}{T_p+F_n}$\n\nChanging the threshold results in: \n\n- Low threshold: More events classified as Fraud -> more false positives, less false negatives -> Precision goes down, recal goes up\n\n- High threshold: Fewer events classified as Fraud -> less False positives, more false negatives -> Precision goes up, Recall down\n\nWe see that there is a tradeoff between precision and recall - we can assess the quality of our model by plotting the recall against the precision -> the larger the area under the graph, the better the model.", "metadata": {"_execution_state": "idle", "_cell_guid": "4a90b212-4596-4e7c-8c96-b8c67c47ddf0", "collapsed": false, "_uuid": "e01905e94b2938773f86b8aea0270f05c30e7840"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"source": "def prc(y_test,probabilities,title=''):\n    \"\"\" Plots the Recall against Precision curve and outputs the area under the Curve\"\"\"\n    precision,recall,thresholds = precision_recall_curve(y_test,probabilities)\n    plt.title(title)\n    ax.plot(recall,precision)\n    ax.set_xlabel('Recall')\n    ax.set_ylabel('Precision')\n    return average_precision_score(y_test,probabilities)\n    \nfig,ax=plt.subplots()      \narea_logreg=prc(y_test,probabilities_logreg[:,1],\n               title='Precision Recall Curve Logistic Regression')\nplt.show()\nprint(\"Area under precision recall graph: {0}\".format(area_logreg))\n\n", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "db468cf8-e25a-4926-9a78-cc1af4dff0db", "collapsed": false, "_uuid": "d6d60bebe1cbdbcf5aeee073e5c665075c99526d"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "## Simple Neural Network Using TensorFlow", "metadata": {"_execution_state": "idle", "_cell_guid": "7be798f1-e3f4-42d6-898a-9c43a055a4b7", "collapsed": false, "_uuid": "40c8a86ce07e23272d5db2bf5be6acc0c3a5654f"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"source": "import tensorflow as tf\n", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "8105a5a1-2df3-4fbe-8f88-1014506c43c1", "collapsed": false, "_uuid": "72c7dcfcc08e2f62a773e56491c7e9bd1095c254"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "#Helper Functions\ndef weight_variable(shape,name=None):\n    initial=tf.truncated_normal(shape,stddev=0.1)\n    return tf.Variable(initial,name)\n\ndef bias_variable(shape,name=None):\n    initial=tf.constant(0.1,shape=shape)\n    return tf.Variable(initial,name)\n", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "f4744916-b52f-42c0-b48d-b5c62d33d378", "collapsed": false, "_uuid": "0e79f8efcec002c666d46a3afe354b386c7b6497"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "# Data Preparation\n\n# One hot encode labels\ny_train_hot=np.eye(2)[y_train]\ny_test_hot=np.eye(2)[y_test] \n# Filter out only fraudulent cases from training data\nX_train_pos=X_train[y_train_hot[:,1]==1] ", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "c75832a0-2303-4f75-bc53-8098c8168eea", "collapsed": false, "_uuid": "0afaa263ab6efdee76d6c35acfc898d9b5014ef5"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### Set up Graph\n\n# Hyperparameters\nn_epoch=20\nbatch_size=96\nlr=0.001\nnum_pos=32\n\n##One hot encode labels\n\nwith tf.name_scope(\"Data\"):\n    X=tf.placeholder(tf.float32,shape=[None,num_features],name=\"X-input\")\n    Y=tf.placeholder(tf.float32,shape=[None,2],name=\"Y-input\")\n    \nwith tf.name_scope(\"Layer_1\"):\n    W1=weight_variable([num_features,20],name=\"Weights\")\n    b1=bias_variable([20],name=\"biases\")\n    h1=tf.nn.sigmoid(tf.matmul(X,W1)+b1)\n   \nwith tf.name_scope(\"Output_Layer\"):\n    W2=weight_variable([20,2],name=\"Weights3\")\n    b2=bias_variable([2],name=\"biases3\")\n    h2=tf.matmul(h1,W2)+b2\n\nwith tf.name_scope(\"Cross_Entropy\"):\n    logits=tf.nn.softmax(h2)\n    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(labels=Y,logits=logits)\n    \nwith tf.name_scope(\"Training\"):\n    train_op=tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n\nwith tf.name_scope(\"Evaluation\"):\n    pred=tf.argmax(logits,1)\n    correct_prediction = tf.equal(pred, tf.argmax(Y, 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n\ndef test_model(X_input,y_input,sess):\n    \"\"\"Tests the current model on a given input (X_input,y_input). Returns the accuracy\n    as well as the predictions and probabilities\"\"\"\n    n_batches=int(y_input.shape[0]/batch_size)\n    avg_sum=0\n    probabilities=np.zeros((y_input.shape))\n    predictions=np.zeros(y_input.shape[0])\n    for i in range(n_batches):\n        X_batch=X_input[i*batch_size:(i+1)*batch_size]\n        Y_batch=y_input[i*batch_size:(i+1)*batch_size]\n        avg_sum += sess.run(accuracy,feed_dict={X:X_batch,Y:Y_batch})\n        # Calculate and store predictions and probabilities\n        preds=sess.run(pred,feed_dict={X:X_batch,Y:Y_batch})\n        probs=sess.run(logits,feed_dict={X:X_batch,Y:Y_batch})\n        predictions[i*batch_size:(i+1)*batch_size]=preds\n        probabilities[i*batch_size:(i+1)*batch_size]=probs\n        acc=avg_sum/n_batches\n    return (acc,predictions,probabilities)\n\n    \n            ", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "6da0d1d0-7805-4c5f-bf78-4440147b79ce", "collapsed": false, "_uuid": "467fc519495f846a11a1a73a2393a596ba026ca8"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### Train the neural network in a session with subsequent testing\n\n#saver = tf.train.Saver()    \n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    n_batches=int(X_train.shape[0]/batch_size)\n    for epoch in range(1,n_epoch+1):\n        for i in range(n_batches):\n            # Add num_pos fraudulent data points to the batch, chosen at random\n            np.random.shuffle(X_train_pos)\n            X_batch=np.vstack((X_train[i*batch_size:(i+1)*batch_size],X_train_pos[:num_pos]))\n            Y_batch=np.vstack((y_train_hot[i*batch_size:(i+1)*batch_size],np.vstack([0,1] for i in range(num_pos))))\n            #Training step\n            sess.run(train_op,feed_dict={X:X_batch,Y:Y_batch})\n        # Reporting after every 10 full iteration\n        if epoch%10==0:\n            acc,_,_=test_model(X_train,y_train_hot,sess)\n            print(\"Finished epoch {0} with a training accuracy of {1}\".format(epoch,acc))\n           \n    acc,predictions_nn,probabilities_nn=test_model(X_test,y_test_hot,sess)\n    print('Accuracy of test set: {0}'.format(acc))\n    #save_path=saver.save(sess,\".//CREDIT_CARDS.ckpt\")\n    #print(\"Model saved in file: %s\" % save_path)\n    \n", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "aabbeb60-8d4f-4c58-9a30-d4396b200cd6", "collapsed": false, "_uuid": "15edeee0939e2d7062695372dfe49f3d36d2f321"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### Confusion Matrix for NN\ncnf_matrix=confusion_matrix(y_test,predictions_nn)     \nfig,ax = plt.subplots()\nplot_confusion_matrix(cnf_matrix, classes=[\"Regular\",\"Fraud\"],\n                     title='Confusion Matrix NN')\nplt.show()", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "21f4500a-d73f-42de-9e82-2027e848ed2e", "collapsed": false, "_uuid": "e85a4ecf827d9ed610a78713bed869b57f541132"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "### Precision_Recall graph for NN\nfig,ax=plt.subplots()      \narea_nn=prc(y_test,probabilities_nn[:,1],title='Precison Recall Curve NN')\nplt.show()\nprint(\"Area under precision recall graph: {0}\".format(area_nn))", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "025da2d0-576e-4ed6-978e-0dfc1e581378", "collapsed": false, "_uuid": "facca619fbf7daff7cbb9d5b5bee95a5365a4472"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "a1bc9b72-f61d-41d3-8bcb-d549ea960bda", "collapsed": false, "_uuid": "699abcaa3d2b72483028fa46bf3a53bcec1096ca"}, "execution_count": null, "cell_type": "code", "outputs": []}], "metadata": {"language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4}