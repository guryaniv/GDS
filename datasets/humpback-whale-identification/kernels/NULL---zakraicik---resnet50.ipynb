{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport os\nfrom PIL import Image\nimport gc\n\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport time\nimport dask\nimport dask.dataframe as dd\n\nfrom subprocess import check_output\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import ResNet50,MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9afcb91d49e5e961197dc292bde249dac7020668"},"cell_type":"code","source":"def read_and_resize(filepath):\n    im = image.load_img(filepath, \n                        color_mode = \"grayscale\", \n                        target_size=(resize, resize))\n    x = image.img_to_array(im)\n    x = preprocess_input(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1003fed82ca9103439f7b5bd7b2e3cbde71dc07a"},"cell_type":"code","source":"train_dir = \"../input/train\"\ntest_dir = \"../input/test\"\nresize = 124 ## size images will be resized to \nsample_to = 5\nbatch_size = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36f37ac697a7e0582380b5a38738a695a4b24aa8"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e01b7af6708e96227616d9e253fef96bf49b7cb0"},"cell_type":"code","source":"print((train.Id=='new_whale').mean())\nprint((train.Id.value_counts()==1).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96b3d03bbe23031721a753f4057def8f764807a6"},"cell_type":"code","source":"im_count = train[train.Id != 'new_whale'].Id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e9b517ca2dc2efcdb0884191d28484d801eedd24"},"cell_type":"code","source":"im_count.name = 'sighting_count'\ntrain = train.join(im_count, on='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0937e23d5989006cde3c75458d76c448f7b4552"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8e62c9a9f31dcccf523163699b2228e2d5db519","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"val_fns = set(train.sample(frac=1)[(train.Id != 'new_whale') & (train.sighting_count > 1)].groupby('Id').first().Image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d43a292c2bfbc5db6d660daedf70ba76ba57e24"},"cell_type":"code","source":"train_xnw = train.loc[train['Id'] != 'new_whale'].reset_index(drop=True) #xnw = exclude new whale\ntrain_nw = train.loc[train['Id'] == 'new_whale'].reset_index(drop=True) #nw = incude new whale\nnum_classes = len(train_xnw['Id'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d0f5bc4eb76c8b848d074660c0015aa8812d6ac"},"cell_type":"code","source":"del train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"129f3256513586fe80087aca94d7133ab10569a8"},"cell_type":"code","source":"train_xnw_val = train_xnw[train_xnw.Image.isin(val_fns)].reset_index(drop=True)\ntrain_xnw_train = train_xnw[~train_xnw.Image.isin(val_fns)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16aa68e63ec3483210d4e950593582a7b790cd6a"},"cell_type":"code","source":"print(train_xnw_train.sighting_count.min())\nprint(train_xnw_train.sighting_count.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06dfcd8e03cbed92de687333c176a5458a1df4e7"},"cell_type":"code","source":"res = None\n\nfor grp in tqdm(train_xnw_train.groupby('Id')):\n    n = grp[1].shape[0]\n    additional_rows = grp[1].sample(0 if sample_to < n  else sample_to - n, replace=True)\n    rows = pd.concat((grp[1], additional_rows))\n    \n    if res is None: res = rows\n    else: res = pd.concat((res, rows))\n        \nres = res.reset_index(drop = True).drop(columns=['sighting_count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fea7712631b842a1696985c350f8b13cbe26859b"},"cell_type":"code","source":"len(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2544a89529b2a18cd699d519d36bc58679ef8ac3"},"cell_type":"code","source":"del train_xnw_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"852634f051282f030d6d91d1c11988d471df3625"},"cell_type":"code","source":"res.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0563a0ce690b7656a51098de99e1e3342d10223b"},"cell_type":"code","source":"im_count_new = res.Id.value_counts()\nim_count_new.name = 'sighting_count'\nres = res.join(im_count_new, on='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4dfec973f58a95f584fc58b304d27b85f1dd6de"},"cell_type":"code","source":"print(res.sighting_count.max()) ## took 1 image for the validation set, therefore its 72 instead of 73\nprint(res.sighting_count.min())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1bc70eac25b757eefb20fad27eed4c8fe7dea9fc"},"cell_type":"markdown","source":"#### Classifier to identify whales that have been seen before"},{"metadata":{"trusted":true,"_uuid":"b27d11c57e88f23f44486a10b60b182a50355831"},"cell_type":"code","source":"df = pd.DataFrame(train_xnw.Id.value_counts().sort_values(ascending=True))\ndf = df.reset_index()\ndf = df.rename(index=str, columns={\"index\": \"Id\", \"Id\": \"Count\"})\ndf.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e8cf39c76b0ca2c1536a52a4e0effef3b2ba96f","scrolled":true},"cell_type":"code","source":"d = {cat: k for k,cat in enumerate(df['Id'])}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7838a37a2eba1cf4ad0d8930797f38c2a02031e4","scrolled":false},"cell_type":"code","source":"x_train = np.zeros((res.shape[0],resize,resize,1))\nfor index, row in tqdm(res.iterrows()):  \n    im = read_and_resize(os.path.join(train_dir,row['Image']))\n    x_train[index,:,:,:] = im\n    del im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a52864c6def123fffe76dd7b0559ee001e4fe66f"},"cell_type":"code","source":"train_labels = []\nfor index, row in tqdm(res.iterrows()):  \n        train_labels.append(d[row['Id']])\ntrain_labels = np.array(train_labels)\ny_train = keras.utils.to_categorical(train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a37e45b5e8952ea4620931c57d53be909d8278"},"cell_type":"code","source":"del res, train_xnw\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6293b19699814c57e6888538be990b8cfe33a936"},"cell_type":"code","source":"x_val = np.zeros((train_xnw_val.shape[0],resize,resize,1))\nfor index, row in tqdm(train_xnw_val.iterrows()):  \n    im = read_and_resize(os.path.join(train_dir,row['Image']))\n    x_val[index,:,:,:] = im\n    del im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"829002b668e78aa7a56b286ee87584f1d6ef999c"},"cell_type":"code","source":"val_labels = []\nfor index, row in tqdm(train_xnw_val.iterrows()):  \n        val_labels.append(d[row['Id']])\nval_labels = np.array(val_labels)\ny_val = keras.utils.to_categorical(val_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30b689fc4e48a9a2e1023c1db402b628a2b77cb6"},"cell_type":"code","source":"del train_xnw_val, val_labels\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a177622c593c6d092064848d3b32aa16fcf27e80"},"cell_type":"code","source":"print(x_train.shape)\nprint(x_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ff5304eeca3746fb96112f52d390fb59301676b"},"cell_type":"code","source":"gen =ImageDataGenerator( )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ba5cf0ba6338d1dc0e38a54f4458ee4d426cee8"},"cell_type":"code","source":"model = ResNet50(input_shape=(resize, resize, 1),\n                      weights=None, \n                      classes=num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89c20c9129d8a07c68a37603fe1da9f34924235d"},"cell_type":"code","source":"model.compile(optimizer=Adam(lr = 0.0005), \n              loss='categorical_crossentropy',\n              metrics=['accuracy', 'top_k_categorical_accuracy'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4215e21c0b7027fd81d832dfe6d8c75059ef61e6"},"cell_type":"code","source":"batches = gen.flow(x_train, y_train, batch_size=batch_size)\nval_batches = gen.flow(x_val,y_val, batch_size=batch_size )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59fe42fb02ea558b3e75d24327ea6bd6b70577cd","scrolled":false},"cell_type":"code","source":"epochs = 10\nhistory=model.fit_generator(generator=batches, \n                            steps_per_epoch= batches.n//batch_size, \n                            validation_data = val_batches,\n                            validation_steps =  val_batches.n//batch_size,\n                            epochs=epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85dc961599142538532b61f34a22f8edb5ac6155"},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"Validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['top_k_categorical_accuracy'], color='b', label=\"Training Top 5 Accuracy\")\nax[1].plot(history.history['val_top_k_categorical_accuracy'], color='r',label=\"Validation Top 5 accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"836de1909b5fb8006be3b95fde7d18a4b257e0aa"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}