{"cells":[{"metadata":{"_uuid":"744a4b88e2d24db83f886490c917fde9cfc6a23c"},"cell_type":"markdown","source":"Jupyter script that implement GridSearchCV with LigthBGM optimizer. Data is worked and enginer features are created.\nThe code is prepeared for parallel computing."},{"metadata":{"trusted":false,"_uuid":"3eb8e2b92e1fc12e5106fdf9d4e91e08671db2ab"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import confusion_matrix, f1_score, make_scorer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport time\n\nimport os\nimport gc\nimport random\nfrom contextlib import contextmanager\n\n\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n_N_JOBS = 1\n\nstart = time.time()\n\n@contextmanager\ndef timer(title):\n    print('{} - Starting'.format(title))    \n    tinit = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\\n\".format(title, time.time() - tinit))    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a394bce95fb0502bfe32ac4e58aaab216f8ebb52"},"cell_type":"markdown","source":"Load Data"},{"metadata":{"trusted":false,"_uuid":"58c7aee1ac0c6b1069e9bbdeee4d252b322db498"},"cell_type":"code","source":"def get_data(Debug = False):\n    train_file = '../input/train.csv'\n    test_file = '../input/test.csv'\n#    train_file = 'C:/Users/maxim/Google Drive/Kaggle/CRHLP/train.csv'\n#    test_file = 'C:/Users/maxim/Google Drive/Kaggle/CRHLP/test.csv'\n    \n    train_data =pd.read_csv(train_file)\n    test_data =pd.read_csv(test_file)\n    \n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef1f3631906809745b64f5644b00bb36077b1b13"},"cell_type":"markdown","source":"Missing Value. Handling Missing Data"},{"metadata":{"trusted":false,"_uuid":"7862f9a9bdd0e74d81b802cccd2f8c5b0a3a3852"},"cell_type":"code","source":"def handling_missing_data(train_data, test_data):\n    # USAR: si no hay tablets en la casa, entonces la cantidad total de tablet es 0! ó si v18q = 0 -> v18q1 = 0!\n    train_data.loc[(train_data['v18q1'].isnull()), 'v18q1'] = train_data.loc[(train_data['v18q1'].isnull()), 'v18q']\n    test_data.loc[(test_data['v18q1'].isnull()), 'v18q1'] = test_data.loc[(test_data['v18q1'].isnull()), 'v18q']\n    \n    # outlier in test set which rez_esc is 99.0\n    test_data.loc[test_data['rez_esc'] > 5 , 'rez_esc'] = 5\n    \n    #Fill na\n    def replace_v18q1(x):\n        if x['v18q'] == 0:\n            return x['v18q']\n        else:\n            return x['v18q1']\n        \n    train_data['v18q1'] = train_data.apply(lambda x : replace_v18q1(x),axis=1)\n    test_data['v18q1'] = test_data.apply(lambda x : replace_v18q1(x),axis=1)\n    # Esta verificado la consistencia entre 'v18q' y 'v18q1'\n    \n    #Fill na in v2a1\n    def replace_v2a1(x):\n        if x['tipovivi1'] == 1 or x['tipovivi4'] == 1 or x['tipovivi5'] == 1:\n            return 0\n        else:\n            return x['v2a1']\n        \n    train_data['v2a1'] = train_data.apply(lambda x: replace_v2a1(x), axis=1)\n    test_data['v2a1'] = test_data.apply(lambda x: replace_v2a1(x), axis=1)\n        \n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1248b8c6c4f15105205927776e36607a5c0bd535"},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":false,"_uuid":"16c8600374a2f8e8f1f0c81cdb6c51455f04f783"},"cell_type":"code","source":"def feature_engineering(train_data, test_data):\n    cols = ['edjefe', 'edjefa']\n    try:\n        train_data[cols] = train_data[cols].replace({'no': 0, 'yes':1}).astype(float)\n        test_data[cols] = test_data[cols].replace({'no': 0, 'yes':1}).astype(float)\n    except:\n        pass\n\n    # It turns out orignial data lost one feature both for roof and electricity, so we manually add new feature\n    train_data['roof_waste_material'] = np.nan\n    test_data['roof_waste_material'] = np.nan\n    train_data['electricity_other'] = np.nan\n    test_data['electricity_other'] = np.nan\n\n    def fill_roof_exception(x):\n        if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n            return 1\n        else:\n            return 0\n    \n    def fill_no_electricity(x):\n        if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n            return 1\n        else:\n            return 0\n\n    train_data['roof_waste_material'] = train_data.apply(lambda x : fill_roof_exception(x),axis=1)\n    test_data['roof_waste_material'] = test_data.apply(lambda x : fill_roof_exception(x),axis=1)\n    train_data['electricity_other'] = train_data.apply(lambda x : fill_no_electricity(x),axis=1)\n    test_data['electricity_other'] = test_data.apply(lambda x : fill_no_electricity(x),axis=1)\n\n\n    # Other features in train_data\n    train_data['adult'] = train_data['hhsize'] - train_data['hogar_mayor'] - train_data['hogar_nin']\n    train_data['no_elder'] = train_data['hhsize'] - train_data['hogar_mayor']\n    train_data['dependency_count'] = train_data['hogar_nin'] + train_data['hogar_mayor']\n    train_data['dependency'] = train_data['dependency_count'] / train_data['adult']\n    train_data['dependency'] = train_data['dependency'].replace({np.inf: 0}) ## No es correcto -> no tienen dependencia o un número muy grande.\n\n    train_data['child_percent'] = train_data['hogar_nin']/train_data['hhsize']\n    train_data['elder_percent'] = train_data['hogar_mayor']/train_data['hhsize']\n    train_data['adult_percent'] = train_data['hogar_adul']/train_data['hhsize']\n\n\n    test_data['adult'] = test_data['hhsize'] - test_data['hogar_mayor'] - test_data['hogar_nin']\n    test_data['no_elder'] = test_data['hhsize'] - test_data['hogar_mayor']\n    test_data['dependency_count'] = test_data['hogar_nin'] + test_data['hogar_mayor']\n    test_data['dependency'] = test_data['dependency_count'] / test_data['adult']\n\n    test_data['child_percent'] = test_data['hogar_nin']/test_data['hhsize']\n    test_data['elder_percent'] = test_data['hogar_mayor']/test_data['hhsize']\n    test_data['adult_percent'] = test_data['hogar_adul']/test_data['hhsize']\n\n\n    train_data['rent_per_adult'] = train_data['v2a1']/train_data['hogar_adul']\n    train_data['rent_per_active_adult'] = train_data['v2a1']/train_data['adult']\n    train_data['rent_per_person'] = train_data['v2a1']/train_data['hhsize']\n\n    train_data['overcrowding_room_and_bedroom'] = (train_data['hacdor'] + train_data['hacapo'])/2\n\n    train_data['no_appliances'] = train_data['refrig'] + train_data['computer'] + train_data['television']\n\n    train_data['r4h1_percent_in_male'] = train_data['r4h1'] / train_data['r4h3']\n    train_data['r4m1_percent_in_female'] = train_data['r4m1'] / train_data['r4m3']\n    train_data['r4h1_percent_in_total'] = train_data['r4h1'] / train_data['hhsize']\n    train_data['r4m1_percent_in_total'] = train_data['r4m1'] / train_data['hhsize']\n    train_data['r4t1_percent_in_total'] = train_data['r4t1'] / train_data['hhsize']\n\n    train_data['rent_per_room'] = train_data['v2a1']/train_data['rooms']\n    train_data['bedroom_per_room'] = train_data['bedrooms']/train_data['rooms']\n    train_data['elder_per_room'] = train_data['hogar_mayor']/train_data['rooms']\n    train_data['adults_per_room'] = train_data['adult']/train_data['rooms']\n    train_data['child_per_room'] = train_data['hogar_nin']/train_data['rooms']\n    train_data['male_per_room'] = train_data['r4h3']/train_data['rooms']\n    train_data['female_per_room'] = train_data['r4m3']/train_data['rooms']\n    train_data['room_per_person_household'] = train_data['hhsize']/train_data['rooms']\n\n    train_data['rent_per_bedroom'] = train_data['v2a1']/train_data['bedrooms']\n    train_data['edler_per_bedroom'] = train_data['hogar_mayor']/train_data['bedrooms']\n    train_data['adults_per_bedroom'] = train_data['adult']/train_data['bedrooms']\n    train_data['child_per_bedroom'] = train_data['hogar_nin']/train_data['bedrooms']\n    train_data['male_per_bedroom'] = train_data['r4h3']/train_data['bedrooms']\n    train_data['female_per_bedroom'] = train_data['r4m3']/train_data['bedrooms']\n    train_data['bedrooms_per_person_household'] = train_data['hhsize']/train_data['bedrooms']\n\n    train_data['tablet_per_person_household'] = train_data['v18q1']/train_data['hhsize']\n    train_data['phone_per_person_household'] = train_data['qmobilephone']/train_data['hhsize']\n\n    train_data['age_12_19'] = train_data['hogar_nin'] - train_data['r4t1']\n\n    train_data['escolari_age'] = train_data['escolari']/train_data['age']\n\n    train_data['rez_esc_escolari'] = train_data['rez_esc']/train_data['escolari']\n    train_data['rez_esc_r4t1'] = train_data['rez_esc']/train_data['r4t1']\n    train_data['rez_esc_r4t2'] = train_data['rez_esc']/train_data['r4t2']\n    train_data['rez_esc_r4t3'] = train_data['rez_esc']/train_data['r4t3']\n    train_data['rez_esc_age'] = train_data['rez_esc']/train_data['age']\n\n    # Other features in test_data\n    test_data['adult'] = test_data['hhsize'] - test_data['hogar_mayor']\n    test_data['dependency_count'] = test_data['hogar_nin'] + test_data['hogar_mayor']\n    test_data['dependency'] = test_data['dependency_count'] / test_data['adult']\n    test_data['dependency'] = test_data['dependency'].replace({np.inf: 0}) ## No es correcto -> no tienen dependencia o un número muy grande.\n\n    test_data['child_percent'] = test_data['hogar_nin']/test_data['hhsize']\n    test_data['elder_percent'] = test_data['hogar_mayor']/test_data['hhsize']\n    test_data['adult_percent'] = test_data['hogar_adul']/test_data['hhsize']\n\n    test_data['adult'] = test_data['hhsize'] - test_data['hogar_mayor'] - test_data['hogar_nin']\n    test_data['dependency_count'] = test_data['hogar_nin'] + test_data['hogar_mayor']\n    test_data['dependency'] = test_data['dependency_count'] / test_data['adult']\n    test_data['child_percent'] = test_data['hogar_nin']/test_data['hhsize']\n    test_data['elder_percent'] = test_data['hogar_mayor']/test_data['hhsize']\n    test_data['adult_percent'] = test_data['hogar_adul']/test_data['hhsize']\n\n    test_data['rent_per_adult'] = test_data['v2a1']/test_data['adult']\n    test_data['rent_per_active_adult'] = test_data['v2a1']/test_data['hogar_adul']\n    test_data['rent_per_person'] = test_data['v2a1']/test_data['hhsize']\n\n    test_data['overcrowding_room_and_bedroom'] = (test_data['hacdor'] + test_data['hacapo'])/2\n\n    test_data['no_appliances'] = test_data['refrig'] + test_data['computer'] + test_data['television']\n\n    test_data['r4h1_percent_in_male'] = test_data['r4h1'] / test_data['r4h3']\n    test_data['r4m1_percent_in_female'] = test_data['r4m1'] / test_data['r4m3']\n    test_data['r4h1_percent_in_total'] = test_data['r4h1'] / test_data['hhsize']\n    test_data['r4m1_percent_in_total'] = test_data['r4m1'] / test_data['hhsize']\n    test_data['r4t1_percent_in_total'] = test_data['r4t1'] / test_data['hhsize']\n\n    test_data['rent_per_room'] = test_data['v2a1']/test_data['rooms']\n    test_data['bedroom_per_room'] = test_data['bedrooms']/test_data['rooms']\n    test_data['elder_per_room'] = test_data['hogar_mayor']/test_data['rooms']\n    test_data['adults_per_room'] = test_data['adult']/test_data['rooms']\n    test_data['child_per_room'] = test_data['hogar_nin']/test_data['rooms']\n    test_data['male_per_room'] = test_data['r4h3']/test_data['rooms']\n    test_data['female_per_room'] = test_data['r4m3']/test_data['rooms']\n    test_data['room_per_person_household'] = test_data['hhsize']/test_data['rooms']\n\n    test_data['rent_per_bedroom'] = test_data['v2a1']/test_data['bedrooms']\n    test_data['edler_per_bedroom'] = test_data['hogar_mayor']/test_data['bedrooms']\n    test_data['adults_per_bedroom'] = test_data['adult']/test_data['bedrooms']\n    test_data['child_per_bedroom'] = test_data['hogar_nin']/test_data['bedrooms']\n    test_data['male_per_bedroom'] = test_data['r4h3']/test_data['bedrooms']\n    test_data['female_per_bedroom'] = test_data['r4m3']/test_data['bedrooms']\n    test_data['bedrooms_per_person_household'] = test_data['hhsize']/test_data['bedrooms']\n\n    test_data['tablet_per_person_household'] = test_data['v18q1']/test_data['hhsize']\n    test_data['phone_per_person_household'] = test_data['qmobilephone']/test_data['hhsize']\n\n    test_data['age_12_19'] = test_data['hogar_nin'] - test_data['r4t1']\n\n\n    test_data['escolari_age'] = test_data['escolari']/test_data['age']\n\n\n    test_data['rez_esc_escolari'] = test_data['rez_esc']/test_data['escolari']\n    test_data['rez_esc_r4t1'] = test_data['rez_esc']/test_data['r4t1']\n    test_data['rez_esc_r4t2'] = test_data['rez_esc']/test_data['r4t2']\n    test_data['rez_esc_r4t3'] = test_data['rez_esc']/test_data['r4t3']\n    test_data['rez_esc_age'] = test_data['rez_esc']/test_data['age']\n\n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98b81ba140e513a3ea8a3c9409ca3bce54b38719"},"cell_type":"markdown","source":"More Feature Engineering"},{"metadata":{"trusted":false,"_uuid":"e4bbf429114b8a62aa63a79e0768694bee061fa8"},"cell_type":"code","source":"def more_feature_engineering(train_data, test_data):\n    def fill_tipovivin(x, column_prefix, asc, n): # debe traer a n en el argumento.\n        value = 0\n        for i in range(1, n+1):\n            if asc == True:\n                value += x[column_prefix+str(i)] * (2 ** (i-1))\n            else:\n                value += x[column_prefix+str(i)] * (2 ** (n-i)) ### Falso!\n\n\n        return value\n\n    train_data['tipovivix'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'tipovivi', asc=False, n=5),axis=1)\n    test_data['tipovivix'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'tipovivi', asc=False, n=5),axis=1)\n\n    train_data['evivx'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'eviv', asc=True, n=3),axis=1)\n    train_data['etechox'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'etecho', asc=True, n=3),axis=1)\n    train_data['eparedx'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'epared', asc=True, n=3),axis=1)\n    train_data['elimbasux'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'elimbasu', asc=False, n=6),axis=1)\n    train_data['elimbasux'] = train_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'elimbasu', asc=False, n=6),axis=1)\n\n    test_data['evivx'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'eviv', asc=True, n=3),axis=1)\n    test_data['etechox'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'etecho', asc=True, n=3),axis=1)\n    test_data['eparedx'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'epared', asc=True, n=3),axis=1)\n    test_data['elimbasux'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'elimbasu', asc=False, n=6),axis=1)\n    test_data['elimbasux'] = test_data.apply(lambda x : fill_tipovivin(x, column_prefix= 'elimbasu', asc=False, n=6),axis=1)\n\n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0c1cf4c12dada5a07e26d5b830692edeeaa4dc5"},"cell_type":"markdown","source":"Even More Feature Engineering"},{"metadata":{"trusted":false,"_uuid":"09493433c94dde86ce45c8d04cc954abf963d739"},"cell_type":"code","source":"def even_more_feature_engineering(train_data, test_data):\n    \n    train_data['edjefx'] = train_data['edjefa'] + train_data['edjefe']\n    test_data['edjefx'] = test_data['edjefa'] + test_data['edjefe']\n\n    # Aproximación a los años que dedico al estudio ...\n    def fill_instlevelx(x):\n        value = 0\n        for i in range(1, 9):\n            value += 5 * x['instlevel'+str(i)] * int(i/2) / (2 ** (1-divmod(i,2)[1]))\n\n\n        return value\n\n    train_data['instlevelx'] = train_data.apply(lambda x : fill_instlevelx(x),axis=1)\n    test_data['instlevelx'] = test_data.apply(lambda x : fill_instlevelx(x),axis=1)\n\n    train_data['instlevelx_to_age'] = train_data['instlevelx'] / train_data['age']\n    test_data['instlevelx_to_age'] = test_data['instlevelx'] / test_data['age']\n\n    # Años que siguieron a la educación. Años laborales que le siguieron a la persona.\n    def fill_laboralperiod(x):\n        value = 0\n        age = x['age']\n        instlevelx = x['instlevelx']\n\n        value = age - instlevelx - 5\n        if instlevelx + 5 > 18:\n            value += 0\n        elif age > 18:\n            value = age - 18 + 0.8 * (18-instlevelx - 5)\n        else:\n            value = 0.8 * value\n\n        if value < 0:\n            value = 0\n\n        return value\n\n    train_data['laboralperiod'] = train_data.apply(lambda x : fill_laboralperiod(x),axis=1)\n    test_data['laboralperiod'] = test_data.apply(lambda x : fill_laboralperiod(x),axis=1)\n\n    train_data['remainlaboralperiod'] = 65 - train_data['laboralperiod']\n    test_data['remainlaboralperiod'] = 65 - test_data['laboralperiod']\n\n    train_data['nobedrooms'] = train_data['rooms'] - train_data['bedrooms']\n    test_data['nobedrooms'] = test_data['rooms'] - test_data['bedrooms']\n\n    train_data['rent_per_nobedroom'] = train_data['v2a1']/train_data['nobedrooms']\n    train_data['bedroom_per_nobedroom'] = train_data['bedrooms']/train_data['nobedrooms']\n    train_data['elder_per_nobedroom'] = train_data['hogar_mayor']/train_data['nobedrooms']\n    train_data['adults_per_nobedroom'] = train_data['adult']/train_data['nobedrooms']\n    train_data['child_per_nobedroom'] = train_data['hogar_nin']/train_data['nobedrooms']\n    train_data['male_per_nobedroom'] = train_data['r4h3']/train_data['nobedrooms']\n    train_data['female_per_nobedroom'] = train_data['r4m3']/train_data['nobedrooms']\n    train_data['nobedrooms_per_person_household'] = train_data['hhsize']/train_data['nobedrooms']\n\n    test_data['rent_per_nobedroom'] = test_data['v2a1']/test_data['nobedrooms']\n    test_data['bedroom_per_nobedroom'] = test_data['bedrooms']/test_data['nobedrooms']\n    test_data['elder_per_nobedroom'] = test_data['hogar_mayor']/test_data['nobedrooms']\n    test_data['adults_per_nobedroom'] = test_data['adult']/test_data['nobedrooms']\n    test_data['child_per_nobedroom'] = test_data['hogar_nin']/test_data['nobedrooms']\n    test_data['male_per_nobedroom'] = test_data['r4h3']/test_data['nobedrooms']\n    test_data['female_per_nobedroom'] = test_data['r4m3']/test_data['nobedrooms']\n    test_data['nobedrooms_per_person_household'] = test_data['hhsize']/test_data['nobedrooms']\n    \n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"241b85c894d190cb85252cb7e41ab58a625fe65d"},"cell_type":"markdown","source":"And Even More Feature Engineering"},{"metadata":{"trusted":false,"_uuid":"8a286ed9db0067c357c347483812c93044b59911"},"cell_type":"code","source":"def and_even_more_feature_engineering(train_data, test_data):\n    \n    # Año que le faltan para emanciparse\n    def fill_remain_to_indep(x):\n        value = 19 - x['age']\n\n        if value < 0:\n            value = 0\n\n        return value\n\n    train_data['remain_to_indep'] = train_data.apply(lambda x : fill_remain_to_indep(x),axis=1)\n    test_data['remain_to_indep'] = test_data.apply(lambda x : fill_remain_to_indep(x),axis=1)\n\n    # hogar_nin - r4t1\n    \n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"257537c03d661934f058d5ccd3c70af05d632d24"},"cell_type":"markdown","source":"Stat Feature Engineering at personnal level"},{"metadata":{"trusted":false,"_uuid":"13c1b664afa676af9be6168ac5719a9afb7be8ed"},"cell_type":"code","source":"def stat_feature_engineering(train_data, test_data):\n\n    stat_features = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n    person_features = ['age','escolari','instlevelx', 'laboralperiod', 'remainlaboralperiod', 'remain_to_indep', 'instlevelx_to_age'] # Completar\n    auxiliar_data = pd.DataFrame()\n\n    ## Train transform\n    #\n\n    print(\"    ... data preparation for train_data ...\")\n    # Transfiero la información a un Dataframe auxiliar\n    auxiliar_data['idhogar'] = train_data['idhogar']\n    auxiliar_data.set_index('idhogar')\n\n    for f in person_features:\n        auxiliar_data[f] = train_data[f]\n\n\n    # Agrupo la info por hogar.\n    auxiliar_data_grouped = auxiliar_data.groupby('idhogar')\n\n\n    #print(auxiliar_data.columns)\n    #print(auxiliar_data.shape)\n\n\n    #Inicializo las columnas de los nuevos atributos con 0 en auxiliar.\n    for pf in person_features:\n        for sf in stat_features:\n            auxiliar_data['household_agg_'+pf+'_'+sf] = 0\n\n    #print(auxiliar_data.columns)    \n\n    # Calculo los valores de los atributos y los cargo en el dataframe auxiliar.\n    print(\"    ... features calc for train_data ...\")\n    for pf in person_features:\n        for name, group in auxiliar_data_grouped:\n            group_result = group[pf].describe()\n            for r in range(8):\n                auxiliar_data.loc[(auxiliar_data['idhogar'] == name),  'household_agg_'+pf+'_'+stat_features[r]] = group_result[r]\n        print('        ... %s  [OK]' % pf)\n\n\n    # Transfiero los resultados a train_data\n    print(\"    ... features tranfer to train_data ...\")\n    for pf in person_features: #Inicializo las columnas de los nuevos atributos con 0 en train_data.\n        for sf in stat_features:\n            train_data['household_agg_'+pf+'_'+sf] = 0\n\n    columns = []\n    for pf in person_features: \n        for sf in stat_features:\n            columns.append('household_agg_'+pf+'_'+sf)\n\n\n    train_data.reset_index()\n    for i in train_data.index:\n        y = auxiliar_data.loc[(auxiliar_data['idhogar']==train_data.get_value(i,'idhogar')), columns]\n    #y['household_agg_'+pf+'_'+sf].\n        for pf in person_features: \n            for sf in stat_features:\n                try:\n                    train_data.set_value(i,'household_agg_'+pf+'_'+sf, y.get_value(i,'household_agg_'+pf+'_'+sf))\n                except:\n                    pass\n\n\n    ##### Test transform\n    #\n\n    print(\"    ... data preparation for test_data ...\")\n    # Transfiero la información a un Dataframe auxiliar\n    auxiliar_data = pd.DataFrame()\n    auxiliar_data['idhogar'] = test_data['idhogar']\n    auxiliar_data.set_index('idhogar')\n\n    for f in person_features:\n        auxiliar_data[f] = test_data[f]\n\n\n    # Agrupo la info por hogar.\n    auxiliar_data_grouped = auxiliar_data.groupby('idhogar')\n\n    #Inicializo las columnas de los nuevos atributos con 0 en auxiliar.\n    for pf in person_features:\n        for sf in stat_features:\n            auxiliar_data['household_agg_'+pf+'_'+sf] = 0\n\n    # Calculo los valores de los atributos y los cargo en el dataframe auxiliar.\n    print(\"    ... features calc for test_data ...\")\n    for pf in person_features:\n        for name, group in auxiliar_data_grouped:\n            group_result = group[pf].describe()\n            for r in range(8):\n                auxiliar_data.loc[(auxiliar_data['idhogar'] == name),  'household_agg_'+pf+'_'+stat_features[r]] = group_result[r]\n        print('        ... %s  [OK]' % pf)\n\n\n    # Transfiero los resultados a train_data\n    print(\"    ... features tranfer to test_data ...\")\n    for pf in person_features: #Inicializo las columnas de los nuevos atributos con 0 en train_data.\n        for sf in stat_features:\n            test_data['household_agg_'+pf+'_'+sf] = 0\n\n    columns = []\n    for pf in person_features: \n        for sf in stat_features:\n            columns.append('household_agg_'+pf+'_'+sf)\n\n\n    test_data.reset_index()\n    for i in test_data.index:\n        y = auxiliar_data.loc[(auxiliar_data['idhogar'] == test_data.get_value(i,'idhogar')), columns]\n        for pf in person_features: \n            for sf in stat_features:\n                try:\n                    test_data.set_value(i,'household_agg_'+pf+'_'+sf, y.get_value(i,'household_agg_'+pf+'_'+sf))\n                except:\n                    pass\n\n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6e5e900d04a8d50addcffa24c7cb923274b3680"},"cell_type":"markdown","source":"Ageing Feature Engineering at home level"},{"metadata":{"trusted":false,"_uuid":"03efa62cb27adf6b41ebebef48fbef0da3fb7117"},"cell_type":"code","source":"def ageing_feature_engineering(train_data, test_data):\n\n    ageing_features = ['0_12','12_18','18_65', '65_80', '80_all'] # Fijo\n    auxiliar_data = pd.DataFrame()\n\n    ## Train transform\n    #\n\n    print(\"    ... data preparation for train_data ...\")\n    # Transfiero la información a un Dataframe auxiliar\n    auxiliar_data['idhogar'] = train_data['idhogar']\n    auxiliar_data.set_index('idhogar')\n\n\n\n    # Agrupo la info por hogar.\n    #auxiliar_data_grouped = auxiliar_data.groupby('idhogar')\n\n\n    #Inicializo las columnas de los nuevos atributos con 0 en auxiliar.\n    for af in ageing_features:\n        auxiliar_data['household_agg_r16m_'+af] = 0\n        auxiliar_data['household_agg_r16f_'+af] = 0\n\n    # Calculo los valores de los atributos y los cargo en el dataframe auxiliar.\n    print(\"    ... features calc for train_data ...\")\n    train_data.reset_index()\n    for i in train_data.index:\n        age = train_data.get_value(i,'age')\n        idhogar = train_data.get_value(i,'idhogar')\n        male = True\n        if train_data.get_value(i,'male') == 0:\n            male = False\n\n        if male == True:\n            if 0 <= age and age <= 12:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_0_12']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_0_12'] = current + 1\n            elif 12 < age and age <= 18:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_12_18']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_12_18'] = current + 1\n            elif 18 < age and age <= 65:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_18_65']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_18_65'] = current + 1\n            elif 65 < age and age <= 80:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_65_80']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_65_80'] = current + 1\n            elif 80 < age :\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_80_all']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_80_all'] = current + 1\n        else:\n            if 0 <= age and age <= 12:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_0_12']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_0_12'] = current + 1\n            elif 12 < age and age <= 18:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_12_18']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_12_18'] = current + 1\n            elif 18 < age and age <= 65:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_18_65']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_18_65'] = current + 1\n            elif 65 < age and age <= 80:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_65_80']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_65_80'] = current + 1\n            elif 80 < age :\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_80_all']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_80_all'] = current + 1\n\n\n    # Transfiero los resultados a train_data\n    print(\"    ... features tranfer to train_data ...\")\n    columns = []\n    for af in ageing_features: \n        columns.append('household_agg_r16m_'+af)\n        columns.append('household_agg_r16f_'+af)\n\n    train_data.reset_index()\n    for i in train_data.index:\n        idhogar = train_data.get_value(i,'idhogar')\n        y = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), columns]\n        for af in ageing_features:\n            train_data.set_value(i,'household_agg_r16m_'+af, y.get_value(i,'household_agg_r16m_'+af))        \n            train_data.set_value(i,'household_agg_r16f_'+af, y.get_value(i,'household_agg_r16f_'+af))       \n\n    for af in ageing_features: \n        train_data['household_agg_r16t_'+af] = train_data['household_agg_r16m_'+af] + train_data['household_agg_r16f_'+af]\n\n\n    for af in ageing_features: \n        # r16m_xx_xx_percent_in_male \n        train_data['household_agg_r16m_'+af+'_percent_in_male'] = train_data['household_agg_r16m_'+af] / train_data['r4h3']\n        # r16f_xx_xx_percent_in_male \n        train_data['household_agg_r16f_'+af+'_percent_in_female'] = train_data['household_agg_r16f_'+af] / train_data['r4m3']\n        # r16m_xx_xx_percent_in_total \n        train_data['household_agg_r16m_'+af+'_percent_in_total'] = train_data['household_agg_r16m_'+af] / train_data['hhsize']\n        # r16f_xx_xx_percent_in_total \n        train_data['household_agg_r16f_'+af+'_percent_in_total'] = train_data['household_agg_r16f_'+af] / train_data['hhsize']\n        # r16t_xx_xx_percent_in_total \n        train_data['household_agg_r16t_'+af+'_percent_in_total'] = train_data['household_agg_r16t_'+af] / train_data['hhsize']\n\n        # r16m_xx_xx_percent_in_r16t_18_65 \n        train_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16m_'+af] / train_data['household_agg_r16t_18_65']\n        # r16f_xx_xx_percent_in_r16t_18_65 \n        train_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16f_'+af] / train_data['household_agg_r16t_18_65']\n        # r16m_xx_xx_percent_in_r16m_18_65 \n        train_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16m_'+af] / train_data['household_agg_r16m_18_65']\n        # r16f_xx_xx_percent_in_r16m_18_65 \n        train_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16f_'+af] / train_data['household_agg_r16m_18_65']\n        # r16m_xx_xx_percent_in_r16f_18_65 \n        train_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16m_'+af] / train_data['household_agg_r16f_18_65']\n        # r16f_xx_xx_percent_in_r16f_18_65 \n        train_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = train_data['household_agg_r16f_'+af] / train_data['household_agg_r16f_18_65']\n\n\n    ## Test transform\n    #\n\n    print(\"    ... data preparation for test_data ...\")\n    # Transfiero la información a un Dataframe auxiliar\n    auxiliar_data = pd.DataFrame()\n    auxiliar_data['idhogar'] = test_data['idhogar']\n    auxiliar_data.set_index('idhogar')\n\n    #Inicializo las columnas de los nuevos atributos con 0 en auxiliar.\n    for af in ageing_features:\n        auxiliar_data['household_agg_r16m_'+af] = 0\n        auxiliar_data['household_agg_r16f_'+af] = 0\n\n    # Calculo los valores de los atributos y los cargo en el dataframe auxiliar.\n    print(\"    ... features calc for test_data ...\")\n    test_data.reset_index()\n    for i in test_data.index:\n        age = test_data.get_value(i,'age')\n        idhogar = test_data.get_value(i,'idhogar')\n        male = True\n        if test_data.get_value(i,'male') == 0:\n            male = False\n\n        if male == True:\n            if 0 <= age and age <= 12:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_0_12']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_0_12'] = current + 1\n            elif 12 < age and age <= 18:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_12_18']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_12_18'] = current + 1\n            elif 18 < age and age <= 65:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_18_65']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_18_65'] = current + 1\n            elif 65 < age and age <= 80:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_65_80']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_65_80'] = current + 1\n            elif 80 < age :\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_80_all']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16m_80_all'] = current + 1\n        else:\n            if 0 <= age and age <= 12:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_0_12']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_0_12'] = current + 1\n            elif 12 < age and age <= 18:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_12_18']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_12_18'] = current + 1\n            elif 18 < age and age <= 65:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_18_65']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_18_65'] = current + 1\n            elif 65 < age and age <= 80:\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_65_80']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_65_80'] = current + 1\n            elif 80 < age :\n                current = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_80_all']\n                auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), 'household_agg_r16f_80_all'] = current + 1\n\n\n    # Transfiero los resultados a test_data\n    print(\"    ... features tranfer to test_data ...\")\n    columns = []\n    for af in ageing_features: \n        columns.append('household_agg_r16m_'+af)\n        columns.append('household_agg_r16f_'+af)\n\n    test_data.reset_index()\n    for i in test_data.index:\n        idhogar = test_data.get_value(i,'idhogar')\n        y = auxiliar_data.loc[(auxiliar_data['idhogar']==idhogar), columns]\n        for af in ageing_features:\n            try:\n                test_data.set_value(i,'household_agg_r16m_'+af, y.get_value(i,'household_agg_r16m_'+af))        \n                test_data.set_value(i,'household_agg_r16f_'+af, y.get_value(i,'household_agg_r16f_'+af))\n            except:\n                print('Exception happends:  column household_agg_r16x_'+af+' idhogar:' +str(idhogar)) #pass\n\n\n    for af in ageing_features: \n        test_data['household_agg_r16t_'+af] = test_data['household_agg_r16m_'+af] + test_data['household_agg_r16f_'+af]\n\n    for af in ageing_features: \n        # r16m_xx_xx_percent_in_male \n        test_data['household_agg_r16m_'+af+'_percent_in_male'] = test_data['household_agg_r16m_'+af] / test_data['r4h3']\n        # r16f_xx_xx_percent_in_male \n        test_data['household_agg_r16f_'+af+'_percent_in_female'] = test_data['household_agg_r16f_'+af] / test_data['r4m3']\n        # r16m_xx_xx_percent_in_total \n        test_data['household_agg_r16m_'+af+'_percent_in_total'] = test_data['household_agg_r16m_'+af] / test_data['hhsize']\n        # r16f_xx_xx_percent_in_total \n        test_data['household_agg_r16f_'+af+'_percent_in_total'] = test_data['household_agg_r16f_'+af] / test_data['hhsize']\n        # r16t_xx_xx_percent_in_total \n        test_data['household_agg_r16t_'+af+'_percent_in_total'] = test_data['household_agg_r16t_'+af] / test_data['hhsize']\n\n        # r16m_xx_xx_percent_in_r16t_18_65 \n        test_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16m_'+af] / test_data['household_agg_r16t_18_65']\n        # r16f_xx_xx_percent_in_r16t_18_65 \n        test_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16f_'+af] / test_data['household_agg_r16t_18_65']\n        # r16m_xx_xx_percent_in_r16m_18_65 \n        test_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16m_'+af] / test_data['household_agg_r16m_18_65']\n        # r16f_xx_xx_percent_in_r16m_18_65 \n        test_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16f_'+af] / test_data['household_agg_r16m_18_65']\n        # r16m_xx_xx_percent_in_r16f_18_65 \n        test_data['household_agg_r16m_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16m_'+af] / test_data['household_agg_r16f_18_65']\n        # r16f_xx_xx_percent_in_r16f_18_65 \n        test_data['household_agg_r16f_'+af+'_percent_in_r16t_18_65'] = test_data['household_agg_r16f_'+af] / test_data['household_agg_r16f_18_65']\n\n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afc8f8c0586a0920964c4f8decfbbbd9042cc226"},"cell_type":"markdown","source":"Back Up & Restore point. Helps during hyperopt to save time."},{"metadata":{"trusted":false,"_uuid":"39701683196f8ee31e6ad7272b58414a3c96dda9"},"cell_type":"code","source":"def save(train_data, test_data):\n    train_data.to_csv('train_data'+ str(start) +'.csv')\n    test_data.to_csv('test_data'+ str(start) +'.csv')\n\n    train_data.to_csv('train_data'+ 'current' +'.csv')\n    test_data.to_csv('test_data'+ 'current' +'.csv')\n    \n    return\n\ndef restore():\n    train_data =pd.read_csv('train_data'+ 'current' +'.csv')\n    test_data =pd.read_csv('test_data'+ 'current' +'.csv')\n    \n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b37e02c6759039e05243fe02d123e0d9fbe5519f"},"cell_type":"markdown","source":"Features importance for a primitive LightGBM Model & consecuent feature reduction. (Drop columns with importance equals 0)."},{"metadata":{"trusted":false,"_uuid":"5b2bf403d5ca3e48f2efe7be1ef2078ffaf4719e"},"cell_type":"code","source":"def feature_reduction(train_data, test_data):\n    \n    aux_data = train_data.copy()\n    aux_data = aux_data.query('parentesco1==1').copy()\n\n    result = pd.DataFrame(columns=['macro_F1_score', 'param', 'Runtime'])\n\n    X_train, X_test, y_train, y_test = train_test_split(aux_data, aux_data['Target'], test_size=0.25, \n                                                            random_state=314, stratify=aux_data['Target'])        \n\n\n    try:\n        X_train.drop(columns=['Target', 'idhogar', 'Id'], inplace=True)\n        X_train.drop(columns=['Unnamed: 0'], inplace=True)\n    except:\n        pass\n\n    try:\n        X_test.drop(columns=['Target', 'idhogar', 'Id'], inplace=True)\n        X_test.drop(columns=['Unnamed: 0'], inplace=True)\n    except:\n        pass\n\n    notebookstart= time.time()\n    clf = lgb.LGBMClassifier(max_depth=11, learning_rate=0.1, objective='multiclass',\n                                 random_state=None, silent=True, verbose=-1, metric='None', \n                                 n_jobs=3, n_estimators=6000, class_weight='balanced',\n                                 colsample_bytree =  0.89, num_leaves = 32,\n                                     min_data_in_leaf=29,\n                                 subsample = 0.96)\n    kfold = 5\n    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n\n    print('    ... training LGBMClassifier.')\n    for train_index, test_index in kf.split(X_train, y_train):\n        X_set, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n        y_set, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n        clf.fit(X_set, y_set, eval_set=[(X_val, y_val)],\n                verbose=False,\n                early_stopping_rounds=400)\n\n    y_test_pred = clf.predict(X_test)\n    f1 = f1_score(y_test, y_test_pred, average='macro')\n\n    print(\"    ... macro F1 score: {0:10.6f}, Runtime: {1:0.2f} min.\\n\".format(f1, (time.time() - notebookstart)/60))\n\n    num_features = clf.feature_importances_.shape[0] \n    importance_split = clf.booster_.feature_importance(importance_type='split')\n    importance_gain = clf.booster_.feature_importance(importance_type='gain')\n    feature_names = clf.booster_.feature_name()\n\n    features = pd.DataFrame(columns=['feature', 'importance_split', 'importance_gain'])\n    for i in range(0,num_features):\n        features.loc[i]=[feature_names[i], importance_split[i], importance_gain[i]]\n\n#    print(\"    ... Feature Ranking:\")\n#    print(features.sort_values(by='importance_split', axis='index', ascending=False))\n\n    null_features = features.loc[(features['importance_split'] == 0), 'feature']\n    cant = X_train.shape[0] #null_features.shape[0]\n    columnas = []\n    for i in range(0,cant):\n        try: \n            null_column = null_features.get_value(i,'feature')\n            if null_column != 'parentesco1' and null_column != 'idhogar':\n                columnas.append( null_column )\n        except:\n            pass\n\n    train_data.drop(columns=columnas, inplace=True)\n    test_data.drop(columns=columnas, inplace=True)\n\n    return train_data, test_data\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"369ded8c966f20c55f1e71de3a290700a8dd6b09"},"cell_type":"markdown","source":"GridSearchCV"},{"metadata":{"trusted":false,"_uuid":"3862f2e48e919a056c36ee318932b26c3afd4a79"},"cell_type":"code","source":"def gridsearch(train_data, test_data):\n\n    param_grid = {\n        'min_child_samples' : [29,30,31,32],\n        'max_depth': [10,11,12]\n    }\n\n    param_grid['min_child_samples'] = range(29,35)\n    param_grid['max_depth'] = range(9,15)\n\n    gridsearchcv_start= time.time()\n    X_set = train_data.copy()\n    X_set = X_set.query('parentesco1==1').copy()\n\n    y_set = X_set['Target']\n    try:\n        X_set.drop(columns=['Target', 'idhogar', 'Id'], inplace=True)\n        X_set.drop(columns=['Unnamed: 0'], inplace=True)\n    except:\n        pass\n\n\n    estimator = lgb.LGBMClassifier(max_depth=11, learning_rate=0.09, objective='multiclass',\n                             random_state=16, silent=True, verbose=-1, metric='None', \n                             n_jobs=16, n_estimators=4000, class_weight='balanced',\n                             colsample_bytree =  0.89, min_child_samples = 33,\n                                 min_data_in_leaf=31,\n                             subsample = 0.96)\n    gbm = GridSearchCV(estimator, param_grid, scoring='f1_macro', cv=5, verbose=6, n_jobs=3)\n    gbm.fit(X_set, y_set)\n    print(\"    ... Ending GridSearchCV cycle. Runtime: {0:0.2f} min.\\n\".format((time.time() - gridsearchcv_start)/60))\n    print('    ... Best score found by grid search are:', gbm.best_score_ )\n    print('    ... and Best parameters search are:', gbm.best_params_)\n    print('    -----------------------------------------------')\n\n    current_best_min_child_samples = gbm.best_params_['min_child_samples']\n    current_best_max_depth = gbm.best_params_['max_depth']\n\n    gbm.best_estimator_.booster_.save_model('boster-'+str(time.time())+'.txt')\n\n    return current_best_min_child_samples, current_best_max_depth, gbm #train_data, test_data\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9dbb8125d2ca00364f62a6c260ff441a57c63330"},"cell_type":"markdown","source":"This function makes a final optimization with the parameters obtained in the GridSearchCV and with all the trainning set. \nOriginally was used to make a guided hyperopt in a for loop."},{"metadata":{"trusted":false,"_uuid":"29dd1d2fc554eca8dfd82dd5ec4badd6bc9dbafc"},"cell_type":"code","source":"def hyperopt(min_child_samples, max_depth, train_data, test_data):\n\n    result = pd.DataFrame(columns=['macro_F1_score', 'num_leaves', 'max_depth', 'Runtime'])\n    index = 0\n\n    aux_data = train_data.query('parentesco1==1').copy()\n    X_train = aux_data.copy()\n    y_train = X_train['Target']\n\n    X_train.drop(columns=['Target', 'idhogar', 'Id', 'Unnamed: 0'], inplace=True)\n\n    clf = lgb.LGBMClassifier(max_depth=max_depth, learning_rate=0.095, objective='multiclass',\n                                     random_state=None, silent=True, verbose=-1, metric='None', \n                                     n_jobs=4, n_estimators=10000, class_weight='balanced',\n                                     colsample_bytree =  0.89, min_data_in_leaf=min_child_samples,\n                                     subsample = 0.96)\n    kfold = 5\n    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n    for train_index, test_index in kf.split(X_train, y_train):\n        X_set, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n        y_set, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n        clf.fit(X_set, y_set, eval_set=[(X_val, y_val)],\n                verbose=False,\n                early_stopping_rounds=400)\n\n\n    return result, clf\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"635635d46bcd518699a2abc9d79fc26492a06963"},"cell_type":"markdown","source":"Here to create the submition file."},{"metadata":{"trusted":false,"_uuid":"9eced57ebeefe84820ae6c2257a3bd3400ec555f"},"cell_type":"code","source":"def submission_preparation(clf,train_data, test_data):\n\n    X_set = test_data.copy()\n\n    try:\n        X_set.drop(columns=['idhogar', 'Id'], inplace=True)\n        X_set.drop(columns=['Unnamed: 0'], inplace=True)\n    except:\n        pass\n\n    sample_submission = pd.DataFrame(columns=['Id', 'Target'])\n\n\n    sample_submission['Id'] = test_data['Id']\n    sample_submission['Target'] = clf.predict(X_set)\n\n    sample_submission.to_csv('submission_'+ str(start) +'.csv')\n    sample_submission.to_csv('submission.csv')\n    \n    return\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a6981bdbb07a1cd27555c2fde5f873cc3ca17b9"},"cell_type":"markdown","source":"Execute All blocks. GridSearchCV is bypassed to save process time in serves."},{"metadata":{"trusted":false,"_uuid":"9ddcdb52699745b9fa0667de72d32560d49979eb"},"cell_type":"code","source":"def main(Debug = False):\n    with timer(\"Load Data\"):\n        train_data, test_data = get_data(Debug=Debug)\n    with timer('Handling Missing Data'):\n        train_data, test_data = handling_missing_data(train_data, test_data)\n    with timer('Feature Engineering'):\n        train_data, test_data = feature_engineering(train_data, test_data)\n    with timer('More Feature Engineering'):\n        train_data, test_data = more_feature_engineering(train_data, test_data)\n    with timer('Even More Feature Engineering'):\n        train_data, test_data = even_more_feature_engineering(train_data, test_data)\n    with timer('And Even More Feature Engineering'):\n        train_data, test_data = and_even_more_feature_engineering(train_data, test_data)\n    with timer('Stat Feature Engineering'):\n        train_data, test_data = stat_feature_engineering(train_data, test_data)\n    with timer('Ageing Feature Engineering'):\n        train_data, test_data = ageing_feature_engineering(train_data, test_data)\n    with timer('Back Up Point'):\n        save(train_data, test_data)\n    with timer('Restore Point'):\n        train_data, test_data = restore()\n    with timer('Features Importance'):\n        train_data, test_data = feature_reduction(train_data, test_data)\n\n#    with timer('GridSearchCV'):\n#        current_best_min_child_samples, current_best_max_depth, gbm = gridsearch(train_data, test_data)\n    current_best_min_child_samples, current_best_max_depth = 29, 13\n    with timer('HyperOPt Liquid Force'):\n        result, clf = hyperopt(current_best_min_child_samples, current_best_max_depth, train_data, test_data)\n\n    with timer('Submission Preparation'):\n        submission_preparation( clf, train_data, test_data)\n\n        \n    return\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fac793d182fdfe5b42fd19873fc6acaaa3039360"},"cell_type":"code","source":"if __name__ == '__main__':\n    main(Debug = False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}