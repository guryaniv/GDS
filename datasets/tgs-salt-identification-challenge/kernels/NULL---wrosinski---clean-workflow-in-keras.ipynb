{"cells":[{"metadata":{"_uuid":"3063e348c500d27ff6688fdfa25e96a5eb935e21"},"cell_type":"markdown","source":"## Keras - Clean Project Workflow\n\n\n### Aim:\n\n\nAim of this notebook is to show an example of clean workflow Computer Vision project/competition in Keras. \n\n### Workflow:\n\n\nWorkflow can be interpreted as following steps:\n1. Dataset initialization (if needed): this step is usually required in case where training samples are separated from from their labels or there is additional information about the samples of a different format. This is the case here, __depth__ is an additional feature that is separate from training images and is thus provided in DataFrame format. For easy integration between the depth and images, each sample has a unique ID. By those IDs images can be connected with their masks and depth added on top of that.\n2. Data loading/processing: set of operations preparing the data for model-ingestible format. Each sample is loaded as image and appended to a list, same happends with masks. Afterwards, dimensions are expanded (if needed), because 2D Convolutional CNN require input samples of dimensionality (HxWxC - height x width x channels) and OpenCV loads grayscale images as (HxW) 2D arrays.\n3. Data is normalized to 0-1 input range. When loaded in OpenCV, grayscale images come in range between 0 and 255. Networks usually converge quicker if data is in 0-1 range. It is also important to keep the values range the same for images and masks (feeding the model with 0-255 images and 0-1 masks is not recommended).\n4. Data is split into training and validation subsets. For this competition, salt coverage is the basis of the split. Then, a stratified split is performed in order to avoid significant discrepancy in distribution between training and validation sets. This could potentially harm model performance or at least skew the validation metric results.\n5. Model definition and training. A lot more about this can be read either in segmentation papers, solutions from past competition or discussions part itself :). One major principle to keep in mind - segmentation model output must be of the same shape as was the input! \n6. Prediction with trained model.\n7. Predictions processing. This can be done in different ways, depending on the final goal. For this competition, predictions and encoded with Run Length Encoding in order to compress their size (raw masks predictions would weight around a GB). Method of processing is very important, as it may require a specific approach to final predictions preparation. In case of RLE, one have to make sure that predictions are scaled (or unpadded) to original image size. Otherwise, RLE will encode wrong pixels and thus final submission score will be low. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import gc\nimport glob\nimport os\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport numpy as np\nimport pandas as pd\n\nfrom keras.callbacks import *\nfrom keras.models import load_model\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (12, 9)\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Define SaltParser\n\nThe first question most probably would be - __why create and use parser like this one?__\n\nIn Machine Learning, you usually can tune two things: models and data. Each parameter can influence the final score, so it's good to know what kind of parameters are used for each run and it's even better to design the pipeline in a way that will minimize potential errors. \n\nWhen a certain operation will be used many times but with different parameters, it is good to parameterize it and just call with chosen parameters. Besides, having functions for processing in one place makes it easier to spot mistakes. This is even more important when you perform an operation in different parts of the pipeline. Then, making sure that all functions are doing the same (for example using different types of padding for training and prediction certainly would not be a good idea!)."},{"metadata":{"trusted":true,"_uuid":"9d271494cfd45b33e90711cd1ef9a466811d3152"},"cell_type":"code","source":"class SaltParser(object):\n\n    \"\"\"\n    Parser for Salt Competition.\n    \"\"\"\n\n    def __init__(self,\n                 data_src='../input/',\n                 image_size=(128, 128),\n                 pad_images=False,\n                 grayscale=True,\n                 load_test_data=True):\n\n        self.data_src = data_src\n        self.image_size = image_size\n        self.pad_images = pad_images\n        self.grayscale = grayscale\n        self.load_test_data = load_test_data\n\n        self.train_df = None\n        self.test_df = None\n        self.padding_pixels = None\n\n        self.X_train = []\n        self.y_train = []\n        self.X_test = []\n\n        self.orig_image_size = (101, 101)\n        \n        \"\"\"\n        # Arguments:\n        \n            data_src: directory containing data\n            image_size: tuple specifying final image size\n            pad_images: whether images should be padded or resized\n            grayscale: whether to load images as grayscale\n            load_test_data: whether to load test data\n            \n        \"\"\"\n\n    def initialize_data(self):\n        \n        \"\"\"\n        Initialize processing by loading .csv files.\n        \"\"\"\n\n        train_df = pd.read_csv('{}train.csv'.format(self.data_src),\n                               usecols=[0], index_col='id')\n        depths_df = pd.read_csv('{}depths.csv'.format(self.data_src),\n                                index_col='id')\n\n        self.train_df = train_df.join(depths_df)\n        self.test_df = depths_df[~depths_df.index.isin(train_df.index)]\n\n        return\n\n    def load_data(self):\n        \n        \"\"\"\n        Load images and masks from training set.\n        \n        # Returns:\n            self.X_train: np.array of training images\n            self.y_train: np.array of training masks\n            self.X_test: np.array of test images\n        \"\"\"\n\n        print('Loading training set.')\n        # Loop over ids in train_df\n        for i in tqdm(self.train_df.index):\n            # Load image and mask according to ID\n            img_src = '{}train/images/{}.png'.format(self.data_src, i)\n            mask_src = '{}train/masks/{}.png'.format(self.data_src, i)\n            # Specify if image should be loaded in grayscale.\n            if self.grayscale:\n                img_temp = cv2.imread(img_src, 0)\n            else:\n                img_temp = cv2.imread(img_src)\n            # Load mask\n            mask_temp = cv2.imread(mask_src, 0)\n            # Resize or pad image and mask\n            if self.orig_image_size != self.image_size:\n                if self.pad_images:\n                    img_temp = self.__pad_image(img_temp)\n                    mask_temp = self.__pad_image(mask_temp)\n                else:\n                    img_temp = cv2.resize(img_temp, self.image_size)\n                    mask_temp = cv2.resize(mask_temp, self.image_size)\n            # Append processed image and mask\n            self.X_train.append(img_temp)\n            self.y_train.append(mask_temp)\n\n        # Transform into arrays\n        self.X_train = np.asarray(self.X_train)\n        self.y_train = np.asarray(self.y_train)\n        # If images were loaded as grayscale, they are loaded as (HxW) arrays\n        # Dimensions must be expanded for the model to be trained.\n        if self.grayscale:\n            self.X_train = np.expand_dims(self.X_train, -1)\n        # Mask must be expanded obligatorily, as they are 1-channel by default.\n        self.y_train = np.expand_dims(self.y_train, -1)\n\n        # Output information about training set.\n        print('Training set ready.')\n        print('X_train shape: {}'.format(self.X_train.shape))\n        print('y_train shape: {}'.format(self.y_train.shape))\n        print('X_train - min: {}, max: {}'.format(\n            np.min(self.X_train), np.max(self.X_train)))\n        print('y_train - min: {}, max: {}'.format(\n            np.min(self.y_train), np.max(self.y_train)))\n\n        # Load test data.\n        # Perform similar steps to the training processing part,\n        # but there are no masks to be loaded.\n        if self.load_test_data:\n            print('Loading test set.')\n            for i in tqdm(self.test_df.index):\n                img_src = '{}test/images/{}.png'.format(self.data_src, i)\n                if self.grayscale:\n                    img_temp = cv2.imread(img_src, 0)\n                else:\n                    img_temp = cv2.imread(img_src)\n                if self.orig_image_size != self.image_size:\n                    if self.pad_images:\n                        img_temp = self.__pad_image(img_temp)\n                    else:\n                        img_temp = cv2.resize(img_temp, self.image_size)\n                self.X_test.append(img_temp)\n\n            self.X_test = np.asarray(self.X_test)\n            if self.grayscale:\n                self.X_test = np.expand_dims(self.X_test, -1)\n\n            print('Test set ready.')\n            print('X_test shape: {}'.format(self.X_test.shape))\n            print('X_test - min: {}, max: {}'.format(\n                np.min(self.X_test), np.max(self.X_test)))\n\n            return self.X_train, self.y_train, self.X_test\n\n        return self.X_train, self.y_train\n\n    def compute_coverage(self):\n        \n        \"\"\"\n        Compute salt coverage of each mask. This will serve as a basis for \n        stratified split between training and validation sets.\n        \n        # Returns:\n            self.train_df: training DF containing coverage information.\n        \"\"\"\n\n        print('Compute mask coverage for each observation.')\n\n        def cov_to_class(val):\n            for i in range(0, 11):\n                if val * 10 <= i:\n                    return i\n\n        # Output percentage of area covered by class\n        self.train_df['coverage'] = np.mean(self.y_train / 255., axis=(1, 2))\n        # Coverage must be split into bins, otherwise stratified split will not be possible,\n        # because each coverage will occur only once.\n        self.train_df['coverage_class'] = self.train_df.coverage.map(\n            cov_to_class)\n\n        return self.train_df\n\n    def predictions_rle_encode(self,\n                               y_pred_test,\n                               confidence_threshold_best):\n        \n        \"\"\"\n        Run Length Encoding of predictions.\n        This is needed for submission output.\n        \n        # Arguments:\n            y_pred_test: model predictions\n            confidence_threshold_best: confidence threshold, according to which\n                masks are set to 1/0.\n        # Returns:\n            y_test_pred_rle: RLEncoded predictions.\n        \"\"\"\n\n        # If images were padded, this padding must now be removed.\n        # Otherwise encoding method will fail to properly encode predictions and\n        # score will be bad.\n        if self.pad_images:\n            print('Remove padding from images.')\n            y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n                0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n            y_pred_test = y_pred_test[:, y_min_pad:-\n                                      y_max_pad, x_min_pad:-x_max_pad, 0]\n            \n        # Situation is similar for previously resized images.\n        # They must be resized again to their original size before encoding.\n        else:\n            y_pred_test = np.asarray([cv2.resize(x, self.orig_image_size)\n                                      for x in y_pred_test])\n\n        assert y_pred_test.shape == (18000, 101, 101), '\\\n        Test predictions shape must be equal to (18000, 101, 101).'\n\n        print('Test predictions shape: {}'.format(y_pred_test.shape))\n\n        # Perform mask predictions binarization and RLEncoding. \n        y_test_pred_rle = {idx:\n                           rle_encode(y_pred_test[i] > confidence_threshold_best)\n                           for i, idx in enumerate(\n                               tqdm(self.test_df.index.values))}\n\n        return y_test_pred_rle\n\n    def generate_submission(self, y_test_pred_rle):\n        \n        \"\"\"\n        Submission generation based on encoded model predictions.\n        \n        # Arguments:\n            y_test_pred_rle: RLEncoded predictions.\n        # Returns:\n            submission: generated submission.\n        \"\"\"\n\n        submission = pd.DataFrame.from_dict(y_test_pred_rle, orient='index')\n        submission.index.names = ['id']\n        submission.columns = ['rle_mask']\n\n        return submission\n\n    def return_padding_borders(self):\n        \"\"\"\n        Return padding borders in case intermediate operations on original images\n        are needed.\n        \n        # Returns:\n            self.padding_pixels: tuple of padding borders.\n        \"\"\"\n        return self.padding_pixels\n\n    def __pad_image(self, img):\n        \n        \"\"\"\n        Helper function for images padding.\n        \n        # Arguments:\n            img: image as np.array\n            \n        # Returns:\n            img: padded image as np.array\n        \"\"\"\n\n        pad_floor = np.floor(\n            (np.asarray(self.image_size) - np.asarray(self.orig_image_size)) / 2)\n        pad_ceil = np.ceil((np.asarray(self.image_size) -\n                            np.asarray(self.orig_image_size)) / 2)\n\n        self.padding_pixels = np.asarray(\n            (pad_floor[0], pad_ceil[0], pad_floor[1], pad_ceil[1])).astype(np.int32)\n\n        y_min_pad, y_max_pad, x_min_pad, x_max_pad = self.padding_pixels[\n            0], self.padding_pixels[1], self.padding_pixels[2], self.padding_pixels[3]\n\n        img = cv2.copyMakeBorder(img, y_min_pad, y_max_pad,\n                                 x_min_pad, x_max_pad,\n                                 cv2.BORDER_REFLECT_101)\n\n        assert img.shape[:2] == self.image_size, '\\\n        Image after padding must have the same shape as input image.'\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20f93da27bd8e6922bfad852edfc769c2095b433"},"cell_type":"markdown","source":"### Define helper functions:"},{"metadata":{"trusted":true,"_uuid":"a68c571ea8d6f5b5b6201e987c1deada9714a503"},"cell_type":"code","source":"# Quick RLEncoding needed for submission generation.\n# Source: another kernel, thanks!\ndef rle_encode(im):\n    pixels = im.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5768297e4d981d42207053fa8a138393fb5ff76"},"cell_type":"markdown","source":"## 1. Initialize parameters:"},{"metadata":{"trusted":true,"_uuid":"fd70c3f34fbf6964219660e84a08e3c99ad61104"},"cell_type":"code","source":"# Input dictionary for SaltParser\nsalt_parameters = {\n    'data_src': '../input/',\n    'image_size': (128, 128),\n    'pad_images': False,\n    'grayscale': False,\n}\n\nsalt_parser = SaltParser(**salt_parameters)\n\nnormalize = True\nsave = False\n\n\n# Automatic input_dim parameter specification\n# for model training.\ninput_dim = salt_parameters['image_size']\n\nif salt_parameters['grayscale']:\n    input_dim = input_dim + (1,)\nelse:\n    input_dim = input_dim + (3,)\n    \n# Run name\nrun_name = '{}_grayscale{}_pad{}_size{}'.format(\n    'Unet',\n    int(salt_parameters['grayscale']),\n    int(salt_parameters['pad_images']),\n    input_dim[0])\n\nprint('Run name: {}'.format(run_name))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46665eec45583df16e464dddffcea2ff805d1550"},"cell_type":"markdown","source":"## 2. Initialize and load data - call SaltParser functions:\n   \n1. Initialize data.\n2. Load train and test set.\n3. Compute coverage for stratified split.\n4. Return padding pixels."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f5ed4567963ac3b9eeb77ed3329d310517ecb6d0"},"cell_type":"code","source":"salt_parser.initialize_data()\nX_train, y_train, X_test = salt_parser.load_data()\ntrain_df = salt_parser.compute_coverage()\npadding_pixels = salt_parser.return_padding_borders()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d6d6bebf40a69a4d03f0c94b62f8bf541e548aa"},"cell_type":"markdown","source":"## 3. Normalize input data to 0-1 range"},{"metadata":{"trusted":true,"_uuid":"5bcb17bbea834396ba526a95ca5d8357cf9d34f5"},"cell_type":"code","source":"if normalize:\n    # X_train, X_test = utils.normalize_along_channel(X_train, X_test)\n    X_train = X_train / 255.\n    y_train = y_train / 255.\n    X_test = X_test / 255.\n    print('X_train - min: {}, max: {}'.format(np.min(X_train), np.max(X_train)))\n    print('y_train - min: {}, max: {}'.format(np.min(y_train), np.max(y_train)))\n    print('Train set: {}, {}'.format(X_train.shape, y_train.shape))\n    print('X_test - min: {}, max: {}'.format(np.min(X_test), np.max(X_test)))\n    print('Test set: {}'.format(X_test.shape))\n    \nX_train = X_train.astype(np.float32)\ny_train = y_train.astype(np.float32)\nX_test = X_test.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d49b31618e2dabede490165fd39b559b9f343e8"},"cell_type":"markdown","source":"## 4. Perform stratified training/validation split based on coverage."},{"metadata":{"trusted":true,"_uuid":"3f06ef1c577c2341bacaa901ae4fda091a22ef5b"},"cell_type":"code","source":"# Perform 80/20 training/validation split based on stratified coverage.\nX_tr, X_val, y_tr, y_val, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    X_train,\n    y_train,\n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state=1234)\n\n\ndel train_df\ngc.collect()\n\ndel X_train, y_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94214b584b843bc238a60c8a9880ed705c87a1f8"},"cell_type":"markdown","source":"## 5. Define UNet model for training.\n\nTaken from another kernel, thanks!"},{"metadata":{"trusted":true,"_uuid":"3768cd5a9c9a4b90908aae3496b983bcb9b7b17d"},"cell_type":"code","source":"from keras import Model\nfrom keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n                          Conv2DTranspose, Dropout, Input, MaxPooling2D,\n                          UpSampling2D, concatenate)\nfrom keras.optimizers import Adam\n\n\ndef conv_block(m, dim, acti, bn, res, do=0):\n    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n    n = BatchNormalization()(n) if bn else n\n    n = Dropout(do)(n) if do else n\n    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n    n = BatchNormalization()(n) if bn else n\n    return Concatenate()([m, n]) if res else n\n\n\ndef level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n    if depth > 0:\n        n = conv_block(m, dim, acti, bn, res)\n        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n        m = level_block(m, int(inc * dim), depth - 1,\n                        inc, acti, do, bn, mp, up, res)\n        if up:\n            m = UpSampling2D()(m)\n            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n        else:\n            m = Conv2DTranspose(dim, 3, strides=2,\n                                activation=acti, padding='same')(m)\n        n = Concatenate()([n, m])\n        m = conv_block(n, dim, acti, bn, res)\n    else:\n        m = conv_block(m, dim, acti, bn, res, do)\n    return m\n\n\ndef UNet(params):\n\n    img_shape = params['input_dim']\n    out_ch = 1\n    start_ch = 8\n    depth = 3\n    inc_rate = 2.\n    activation = 'relu'\n    dropout = 0.5\n    batchnorm = False\n    maxpool = True\n    upconv = True\n    residual = False\n\n    i = Input(shape=img_shape)\n    o = level_block(i, start_ch, depth, inc_rate, activation,\n                    dropout, batchnorm, maxpool, upconv, residual)\n    o = Conv2D(out_ch, 1)(o)\n    # Sigmoid activation is used because model is trained with binary_crossentropy.\n    o =  Activation('sigmoid')(o)\n\n    model = Model(inputs=i, outputs=o)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f87f8bef5fc8d7c4ca0034f7694295d2363ddca4"},"cell_type":"markdown","source":"## 6. Train model:"},{"metadata":{"trusted":true,"_uuid":"448382230fab79dd3fa8ab652b3e8d1581c1531f"},"cell_type":"code","source":"model = UNet({'input_dim': input_dim})\nmodel.compile(optimizer='adam', loss='binary_crossentropy')\n\n\nearly_stopping = EarlyStopping(monitor='val_loss' ,patience=12, verbose=1, mode='min')\nmodel_checkpoint = ModelCheckpoint(\"./{}.h5\".format(run_name),monitor='val_loss',\n                                   save_best_only=True, verbose=1, mode='min')\nreduce_lr = ReduceLROnPlateau(\n    monitor='val_loss',factor=0.33, patience=6, min_lr=1e-6, verbose=1, mode='min')\n\nepochs = 10  # change to more for better score!\nbatch_size = 32\n\n\nhistory = model.fit(X_tr, y_tr,\n                    validation_data=[X_val, y_val], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c42374acdacb8517a7f52ed8b0969746fcb51b9"},"cell_type":"markdown","source":"## 7. Predict validation and test set masks:"},{"metadata":{"trusted":true,"_uuid":"afff0d94ef4a7aedb758f2438fe75856afdc834d"},"cell_type":"code","source":"y_pred_valid = model.predict(X_val)\ny_pred_test = model.predict(X_test)\n\ndel X_tr, X_val, X_test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d81acb8474518e5079b1803ff6a901533a679d6","scrolled":true},"cell_type":"code","source":"# Assume 0.5 threshold for mask binarization.\n# This can be optimized!\ny_pred_test_rle = salt_parser.predictions_rle_encode(\n    y_pred_test, confidence_threshold_best=0.5)\n\nsubmission = salt_parser.generate_submission(y_pred_test_rle)\n\n# Save submission with specified run_name.\nif save:\n    submission.to_csv('submission_{}.csv'.format(run_name))\n    \nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1a6411767b9ddcdb111fa9d3402e7a75dd67f55"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}