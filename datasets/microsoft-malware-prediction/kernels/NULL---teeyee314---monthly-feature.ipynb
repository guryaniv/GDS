{"cells":[{"metadata":{"_uuid":"90f0ff08fc0ef62e7bbebac2da84efbd1f322e2e"},"cell_type":"markdown","source":"# Hacking AvSigVersion\n\nThis notebook is slightly different approach to [Chris' kernel](https://www.kaggle.com/cdeotte/private-leaderboard-0-703). This idea is NOT the same, just an alternative. But upon re-exploring my hacky feature, and EDA, I have realized why I got such a high private LB score, despite not having the gumption, chutzpah, or what-have-you, to stay true to avoiding using public LB as a progress gauge and fell prey to greedy desire to land on the leaderboard. Even after countless warning signs from [here](https://www.kaggle.com/tunguz/ms-malware-adversarial-validation), and [here](https://www.kaggle.com/rquintino/2-months-train-1-month-public-1-day-private) as well as in my own analysis below.\n\nIn this notebook I explore, how I used AvSigVersion to improve Private LB while decreasing Public LB. After getting inspired by  [this kernel](https://www.kaggle.com/cdeotte/time-split-validation-malware-0-68).\n\nMy reasoning behind hacking the AvSigVersion through this approach was that the training data only contains a small sample of months in October, November which is heavily comprised of the private dataset that was discovered in [this kernel](https://www.kaggle.com/rquintino/2-months-train-1-month-public-1-day-private). \n\nBelow is some EDA I had performed around the time the two kernels above were released. Had I stuck to simple feature engineering, avoided overfitting/chasing the LB, I would have scored 0.663 - 0.688 using a simple lightgbm model. I too fell pray to chasing the Public LB and left caution to the wind. I hope some will will find my hindsight in this kernel useful.\n\nSpecial thanks to @cdeotte, **Chris Deotte** for your dedication to publishing your kernels throughout this competition and inspiring this kernel submission. I would have never explored the hacky feature if it weren't for your comments on how you didn't drop unstable features in your time-slit-validation kernel."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime \nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6abef593efb06b6a506f3ce2a6dbc2bee10d7bab"},"cell_type":"code","source":"%%time\ndtypes = {}\ndtypes['MachineIdentifier'] = 'str'\ndtypes['AvSigVersion'] = 'category'\ndtypes['HasDetections'] = 'int8'\n\n# LOAD TRAIN & TEST DATA\ntrain = pd.read_csv('../input/microsoft-malware-prediction/train.csv', usecols=list(dtypes.keys()), dtype=dtypes)\ntest = pd.read_csv('../input/microsoft-malware-prediction/test.csv', usecols=list(dtypes.keys())[0:-1], dtype=dtypes)\n\n# Load AvSigVersion Dates\ndates1 = np.load('../input/avgsig/train_AvSigVersion.npy')[()]\ndates2 = np.load('../input/avgsig/train_AvSigVersion2.npy')[()]\ndates3 = np.load('../input/avgsig/test_AvSigVersion.npy')[()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c293af6b95eeba2be34a8c8ed9e35e240f11e505"},"cell_type":"code","source":"# process the dates, create a dictionary to store all dates\ndate = {}\nfor key, value in zip(dates1.keys(), dates1.values()):\n    if key not in date.keys():\n        date[key] = value\n        \nfor key, value in zip(dates2.keys(), dates2.values()):\n    if key not in date.keys():\n        date[key] = value\n        \nfor key, value in zip(dates3.keys(), dates3.values()):\n    if key not in date.keys():\n        date[key] = value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a527725f12bb9a64816fb6f25c8a46d933cf8f93"},"cell_type":"code","source":"# function for stripping month, year, day, week data. try/except since there are missing dates\ndef strip_month(feature):\n    try:\n        return datetime.strptime(feature, '%b %d,%Y %I:%M %p UTC').month\n    except: \n        return 0\n\ndef strip_year(feature):\n    try:\n        return datetime.strptime(feature, '%b %d,%Y %I:%M %p UTC').year\n    except: \n        return 0\n\ndef strip_day(feature):\n    try:\n        return datetime.strptime(feature, '%b %d,%Y %I:%M %p UTC').day\n    except: \n        return 0\n\ndef strip_week(feature):\n    try:\n        # be careful, there is a leap week. apparently there is a 53rd week!\n        return datetime.strptime(feature, '%b %d,%Y %I:%M %p UTC').isocalendar()[1]\n    except: \n        return 0\n\n# binary featurization\ndef month11(feature):\n    return 1 if feature == 11 else 0\n\ndef month10(feature):\n    return 1 if feature == 10 else 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2f906e8b6bfa15fc613bb6d49c394de39e6406d"},"cell_type":"code","source":"%%time\n# create a numerical feature that includes only months October/November\ntrain['Month'] = train['AvSigVersion'].map(date).apply(strip_month)\ntest['Month'] = test['AvSigVersion'].map(date).apply(strip_month)\ntrain['Year'] = train['AvSigVersion'].map(date).apply(strip_year)\ntest['Year'] = test['AvSigVersion'].map(date).apply(strip_year)\ntrain['Day'] = train['AvSigVersion'].map(date).apply(strip_day)\ntest['Day'] = test['AvSigVersion'].map(date).apply(strip_day)\ntrain['Week'] = train['AvSigVersion'].map(date).apply(strip_week)\ntest['Week'] = test['AvSigVersion'].map(date).apply(strip_week)\n\n# binary features, specifically used to hack those months (for private LB)\ntrain['AvSigMonth_10'] = train['Month'].apply(month10).astype('int8')\ntest['AvSigMonth_10'] = test['Month'].apply(month10).astype('int8')\ntrain['AvSigMonth_11'] = train['Month'].apply(month11).astype('int8')\ntest['AvSigMonth_11'] = test['Month'].apply(month11).astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86b9ce42506f5224a01fe251ec18d02e271f6e42"},"cell_type":"code","source":"# Explore Detection Counts by Month\nplt.figure(figsize=(16,8))\nsns.countplot(train['Month'], hue=train['HasDetections'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d2804ae2ac6d626879540796b330354a08be89f"},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.countplot(test['Month'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7b29c80e0c7e2b1478143e1b956de027eebcba1"},"cell_type":"code","source":"# Zoom into detection counts for Nov - Dec\nsubset_train = train[train['Month'] >= 10]\nsns.countplot(subset_train['Month'], hue=subset_train['HasDetections'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f30a2075b1c2a470229619687b007eeb296a331"},"cell_type":"markdown","source":"Other thoughts regarding the nature of low sample rate of October, November, December months. I thought about upsampling the months at the time (1.5months ago) which only in hindsight would have been a brilliant idea. However, I was risk adverse and unsure of my wild ideas. Everything in my gut was telling me not to follow the crowd and that true detection rates were much lower than led to believe as indicated by my EDA.\n\nBelow is a screenshot of submissions using the hacky features.\n\n![image](https://i.imgur.com/Nf2xE6h.png)","attachments":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}