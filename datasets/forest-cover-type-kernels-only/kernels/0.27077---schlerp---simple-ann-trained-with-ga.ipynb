{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# handle imports\nimport copy\nimport numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a38a81b7168f246a94fc3784bc1034508dc8a037"},"cell_type":"code","source":"class Activation(object):\n    \n    def __init__(self):    \n        pass\n    \n    def forward(self, x):\n        pass\n    \n    def backward(self, x):\n        pass\n    \n    def __call__(self, x, deriv=False):\n        if deriv:\n            return self.backward(x)\n        return self.forward(x)\n\n\nclass Linear(Activation):\n    \n    def __init__(self, m=1.0, c=0.):\n        self.m = m\n        self.c = c\n    \n    def forward(self, x):\n        return (m * x) + c\n    \n    def backward(self, x):\n        return np.ones(x.shape) * m\n\n\nclass ReLU(Activation):\n    \n    def __init__(self, stable=True):\n        self.stable = stable\n    \n    def forward(self, x):\n        if self.stable:\n            x = np.clip(x, -700, 700)\n        return x * (x > 0)\n    \n    def backward(self, x):\n        return 1. * (x > 0)\n\n\nclass LeakyReLU(Activation):\n    \n    def __init__(self, stable=True, alpha=0.5):\n        self.stable = stable\n        self.alpha = alpha\n    \n    def forward(self, x):\n        if self.stable:\n            x = np.clip(x, -700, 700)\n        return x * (x > 0) + x * self.alpha * (x <= 0)\n    \n    def backward(self, x):\n        return 1. * (x > 0) + self.alpha * (x <= 0)\n\n\nclass Sigmoid(Activation):\n    \n    def __init__(self, stable=True):\n        self.stable = stable\n    \n    def forward(self, x):\n        if self.stable:\n            x = np.clip(x, -700, 700)\n        return 1 / (1 + np.exp(-x))\n    \n    def backward(self, x):\n        return np.exp(-x) / np.square(1+np.exp(-x))\n\n\nclass Tanh(Activation):\n    \n    def __init__(self, stable=True):\n        self.stable = stable\n    \n    def forward(self, x):\n        if self.stable:\n            x = np.clip(x, -700, 700)\n        return np.tanh(x)\n    \n    def backward(self, x):\n        return 1.0 - np.square(np.tanh(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2c2c5264afa44e9739c030b7f3404278d5ef7e7b"},"cell_type":"code","source":"def mse(y_true, y_pred):\n    return np.mean(np.square(y_pred - y_true))\n\n\ndef mae(y_true, y_pred):\n    return np.mean(np.abs(y_pred - y_true))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e4eca7d5bca742f612132bd99ffcbec5fdd884d8"},"cell_type":"code","source":"class Network(object):\n    def __init__(self, weights, activation=Sigmoid()):\n        self.weights = weights\n        self.activation = activation\n        self.num_layers = len(weights)\n        self.loss = np.inf\n    \n    def predict(self, x):\n        layer = x\n        for w in self.weights:\n            z = self.activation(np.dot(layer, w.T))\n            layer = z\n        return z\n\nclass GeneticPopulationOld(object):\n    def __init__(self, n_population=50, n_elite=5, top_k=10, mut_rate=0.1):\n        self.n_population = n_population\n        self.n_elite = n_elite\n        self.top_k = top_k\n        self.mutation_rate = mut_rate\n\n    def fit(self, X, Y, n_hidden=10, n_epochs=100, loss=mse, verbose=True, maximize=False):\n        n_features = X.shape[1]\n        n_classes = Y.shape[1]\n        if verbose:\n            print('creating initial population...')\n        self.population = create_population(self.n_population,\n                                            n_features,\n                                            n_classes,\n                                            n_hidden)\n        loss_history = []\n        for epoch in range(n_epochs):\n            individuals = []\n            population_loss = 0\n            if verbose:\n                print('epoch #{}'.format(epoch))\n            for indiv in self.population:\n                y_pred = indiv.predict(X)\n                indiv.score = loss(Y, y_pred)\n                population_loss += indiv.score\n                individuals.append(indiv)\n            if verbose:\n                print('sorting population...')\n            sorted_indivs = sorted(individuals, \n                                   key=lambda x: x.score,\n                                   reverse=maximize)\n            if verbose:\n                print('creating next generation...')\n            next_generation = sorted_indivs[0:self.n_elite-1]\n            if verbose:\n                print('adding top {} individuals'.format(self.n_elite))\n            pop_to_fill = self.n_population - self.n_elite\n            if verbose:\n                print('breeding {} individuals...'.format(pop_to_fill))\n            for i in range(pop_to_fill):\n                parent1, parent2 = np.random.choice(sorted_indivs[0:self.top_k], \n                                                    2)\n                child_weights = breed(parent1.weights, parent2.weights)\n                child_weights = mutate(child_weights)\n                next_generation.append(Network(child_weights))\n            self.population = next_generation\n            avg_pop_loss = population_loss/self.n_population\n            loss_history.append(avg_pop_loss)\n            if verbose:\n                print('finished epoch, total loss: {}'.format(avg_pop_loss))\n        self.best_individual = self.population[0]\n        return loss_history\n    \n    def predict(self, X):\n        return self.best_individual.predict(X)\n    \n\nclass GeneticPopulation(object):\n    def __init__(self, n_population=50, n_elite=5, top_k=10, mut_rate=0.1):\n        self.n_population = n_population\n        self.n_elite = n_elite\n        self.top_k = top_k\n        self.mutation_rate = mut_rate\n\n    def do_epoch(self, X, Y, loss, verbose):\n        sorted_indivs, population_loss = self.do_scoring(X, Y, loss, verbose)\n        next_generation = self.do_breeding(sorted_indivs, verbose)\n        return next_generation, population_loss\n\n    def do_scoring(self, X, Y, loss, verbose):\n        individuals = []\n        population_loss = 0\n        for indiv in self.population:\n            y_pred = indiv.predict(X)\n            indiv.score = loss(Y, y_pred)\n            population_loss += indiv.score\n            individuals.append(indiv)\n        if verbose:\n            print('sorting population...')\n        sorted_indivs = sorted(individuals, key=lambda x: x.score)\n        return sorted_indivs, population_loss\n\n    def do_breeding(self, sorted_indivs, verbose):\n        if verbose:\n            print('creating next generation...')\n        next_generation = sorted_indivs[0:self.n_elite-1]\n        if verbose:\n            print('adding top {} individuals'.format(self.n_elite))\n        pop_to_fill = self.n_population - self.n_elite\n        if verbose:\n            print('breeding {} individuals...'.format(pop_to_fill))\n        for i in range(pop_to_fill):\n            parent1, parent2 = np.random.choice(sorted_indivs[0:self.top_k], 2)\n            child_weights = breed(parent1.weights, parent2.weights)\n            child_weights = mutate(child_weights)\n            next_generation.append(Network(child_weights))\n        return next_generation\n\n    def fit(self, X, Y, n_hidden=10, n_epochs=100, loss=mse, verbose=True):\n        n_features = X.shape[1]\n        n_classes = Y.shape[1]\n        if verbose:\n            print('creating initial population...')\n        self.population = create_population(self.n_population,\n                                            n_features,\n                                            n_classes,\n                                            n_hidden)\n        loss_history = []\n        for epoch in range(n_epochs):\n            if verbose:\n                print('epoch #{}'.format(epoch))            \n            next_generation, population_loss = self.do_epoch(X, Y, loss, verbose)\n            self.population = next_generation\n            avg_pop_loss = population_loss / self.n_population\n            loss_history.append(avg_pop_loss)\n            if verbose:\n                print('finished epoch, total loss: {}'.format(avg_pop_loss))\n            \n        self.best_individual = self.population[0]\n        return loss_history\n    \n    def predict(self, X):\n        return self.best_individual.predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"60f86f223237cc6b594d5ef0c5c322594e7f7dfc"},"cell_type":"code","source":"def breed(weights1, weights2):\n    child_weights = []\n    for weight1, weight2 in zip(weights1, weights2):\n        breed_mask = np.random.randint(2, size=weight1.shape)\n        child_weights.append(np.where(breed_mask, weight1, weight2))\n    return child_weights\n\ndef mutate(weights, mutation_rate=0.01):\n    if random.random() <= mutation_rate:\n        for i in range(len(weights)):\n            x_loc = random.choice(range(weights[i].shape[0]))\n            y_loc = random.choice(range(weights[i].shape[1]))\n            weights[i][x_loc, y_loc] += (random.random() * 2) - 1\n    return weights\n\ndef create_weights(n_features, n_classes, n_hidden, _min=-1, _max=1):\n    weights = [np.random.uniform(_min, _max, (n_hidden, n_features)),\n               np.random.uniform(_min, _max, (n_classes, n_hidden))]\n    return weights\n\ndef create_population(n_population, n_features, n_classes, n_hidden):\n    population = []\n    for i in range(n_population):\n        weights = create_weights(n_features, n_classes, n_hidden)\n        population.append(Network(weights))\n    return population","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dc06c18e6e5cbd5f1b2b7fe7a871d5b56898a982"},"cell_type":"code","source":"def one_hot(x, classes, zero_based=True):\n    '''returns onehot encoded vector for each item in x'''\n    ret = []\n    for value in x:\n        temp = [0. for _ in range(classes)]\n        if zero_based:\n            temp[int(value)] = 1.\n        else:\n            temp[int(value)-1] = 1.\n        ret.append(temp)\n    return np.array(ret)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d1b7298996b5703b52c52fab28f739c6b38d697"},"cell_type":"code","source":"# set up dataset\nnumber_classes = 7\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n# lets take a look...\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6227f0edeab9f18e4bbcaf10812972ee607b3a08"},"cell_type":"code","source":"# create train datasets\nX_train = train_df.drop(['Id', 'Cover_Type'], axis=1)\nY_train = train_df[['Cover_Type']].values\nY_train = Y_train.reshape(len(Y_train))\n\n# create test dataset and ID's\nX_test = test_df.drop(['Id'], axis=1)\nID_test = test_df['Id'].values\nID_test = ID_test.reshape(len(ID_test))\n\n# concatenate both together for feature engineering and normalisation\nX_all = pd.concat([X_train, X_test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"15a789e0b155874d96e1bb0f855be8b6e5f56149"},"cell_type":"code","source":"# mean hillshade\ndef mean_hillshade(df):\n    df['mean_hillshade'] = (df['Hillshade_9am'] + df['Hillshade_Noon'] + df['Hillshade_3pm']) / 3\n    return df\n\n# calculate the distance to hydrology using pythagoras theorem\ndef distance_to_hydrology(df):\n    df['distance_to_hydrology'] = np.sqrt(np.power(df['Horizontal_Distance_To_Hydrology'], 2) + \\\n                                          np.power(df['Vertical_Distance_To_Hydrology'], 2))\n    return df\n\n# calculate diagnial distance down to sea level?\ndef diag_to_sealevl(df):\n    df['diag_to_sealevel'] = np.divide(df['Elevation'], np.cos(180-df['Slope']))\n    return df\n\n# calculate mean distance to features\ndef mean_dist_to_feature(df):\n    df['mean_dist_to_feature'] = (df['Horizontal_Distance_To_Hydrology'] + \\\n                                  df['Horizontal_Distance_To_Roadways'] + \\\n                                  df['Horizontal_Distance_To_Fire_Points']) / 3\n    return df\n\nX_all = mean_hillshade(X_all)\nX_all = distance_to_hydrology(X_all)\nX_all = diag_to_sealevl(X_all)\nX_all = mean_dist_to_feature(X_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fc5c54c7a0cbc75e5c7212c58a32f033a390b6ad"},"cell_type":"code","source":"# normalise dataset\ndef normalise_df(df):\n    df_mean = df.mean()\n    df_std = df.std()    \n    df_norm = (df - df_mean) / (df_std)\n    return df_norm, df_mean, df_std\n\n# define columsn to normalise\ncols_non_onehot = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n                'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n                'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n                'Horizontal_Distance_To_Fire_Points', 'mean_hillshade',\n                'distance_to_hydrology', 'diag_to_sealevel', 'mean_dist_to_feature']\n\nX_all_norm, df_mean, df_std = normalise_df(X_all[cols_non_onehot])\n\n# replace columns with normalised versions\nX_all = X_all.drop(cols_non_onehot, axis=1)\nX_all = pd.concat([X_all_norm, X_all], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1384d8daefc3c806205e0c8f02bfe848b9a058ee"},"cell_type":"code","source":"# split back into test and train sets\nX_train = np.array(X_all[:len(X_train)])\nX_test = np.array(X_all[len(X_train):])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6140e64bed515a006239d20305ffaf27bf9048fa","collapsed":true},"cell_type":"code","source":"Y_train = one_hot(list(Y_train), number_classes, zero_based=False)\nXt, Xv, Yt, Yv = train_test_split(X_train, Y_train, test_size=0.20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a003f330c4272c64a7cbaa45161d38123787f6e5"},"cell_type":"code","source":"print('creating genetic population...')\ngp = GeneticPopulation(n_population=25, n_elite=3, top_k=10, mut_rate=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e5469ee0e673684340c629af280c8bafceda433","scrolled":true},"cell_type":"code","source":"print('fitting genetic population...')\ntrain_error = gp.fit(Xt, Yt, n_hidden=100, n_epochs=100, loss=mse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8797bc9dee794b4e689b6bdfb33468caa66908ae","scrolled":false},"cell_type":"code","source":"print('predicting using genetic population...')\ny_pred = gp.predict(Xv)\n\nprint('mse: {}'.format(mse(Yv, y_pred)))\nprint('mae: {}'.format(mae(Yv, y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bd8db82e4ea71600fecf679050cf2809b0f2884a"},"cell_type":"code","source":"def graph_loss(loss):\n    y = loss\n    x = [x for x in range(len(loss))]\n    min_epoch, min_loss = min(enumerate(loss), key=lambda x: x[1])\n    plt.xlabel = 'Epochs'\n    plt.ylabel = 'error'\n    plt.plot(x, y, 'b-', label='Training loss')\n    plt.plot(min_epoch, min_loss, 'rx', mew=2, ms=20, label='minimum loss')\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9feb448fde3f8fd1f55fc0c6f11f29b7c8d34863","scrolled":false},"cell_type":"code","source":"graph_loss(train_error)\nmin_epoch, min_loss = min(enumerate(train_error), key=lambda loss: loss[1])\nprint('min loss: {}, was acheived at {} epochs'.format(min_loss, min_epoch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5554e0f5289ed0a7db0034d21c82e34a26234769","collapsed":true},"cell_type":"code","source":"y_pred = gp.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08c570cf4fdcb04ecd1fa661bd6ecc38e3964d5b"},"cell_type":"code","source":"y_pred = np.argmax(y_pred, axis=1) + 1\ny_pred = y_pred.astype(int)\n\nprint('max prediction class: {}'.format(np.max(y_pred)))\nprint('min prediction class: {}'.format(np.min(y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acf162a3a5ce7b12ce616e595dee22291ad53a0e"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = ID_test\nsub['Cover_Type'] = y_pred\nsub.to_csv('my_submission.csv', index=False)\nprint('good luck!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b1e995aa2dff171bc1873d1ba9961833faca4db"},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31af39f107e3a9258e640c261daa55a72fedc1ac"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}