{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## FastAi Approach \nThis notebook will guide you through FastAI approach.\n\nWe'll use RandomForest to  find out feature important and find Partial dependence. Also we'll plot the correlation between variables.\n\n### Imports"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"eec26a5533029e7fd106a6d5723f7bbb266fb505"},"cell_type":"code","source":"!pip install fastai==0.7.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88db3be9a4111043ce7f57ee9a3867009e4f238d"},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb3ab6fd05e1328867fa6bab09264397c97339a"},"cell_type":"code","source":"from fastai.imports import *\nfrom fastai.structured import *\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn import metrics\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94d57eda761eaaee9f8c0372ecd1dc615d4647b0"},"cell_type":"code","source":"PATH = '../input/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf97b2bb0616efd19ead40ddcf734c6f33f43d6"},"cell_type":"code","source":"df_raw = pd.read_csv(PATH + 'train.csv',low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1919a5fc4eeda7589835dc768ed860982ea1cdd3"},"cell_type":"code","source":"df_test = pd.read_csv(PATH + 'test.csv',low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b56e9d740bc61b7a77a307c939f81c49fcf11a7"},"cell_type":"code","source":"df_raw.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9db22ae14c409fb6dd59d67372c679f32c61f99d"},"cell_type":"code","source":"df_raw.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a637974651093bac7ad705407fcadd29d6e25a2d"},"cell_type":"code","source":"#check the missing value\ndf_raw.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ed96f5fc2092d11b8cc17cefaf22eac00dc3543"},"cell_type":"markdown","source":"There are no missing values and also we have checked the mean and Standard Deviation of Target Column\n\nNow let's use proc_df function which will handle categorical data and convert into numeric data\n\nNote - There are no categorical data and no missing values so even if we dont do proc_df then it won't matter at all. Here proc df will just split the data into into X and Y(Predictor and Target)"},{"metadata":{"trusted":true,"_uuid":"e19e551004ac1a38bd0bac17f0abbb68d763d29e"},"cell_type":"code","source":"df_trn, y_trn, nas = proc_df(df_raw, 'target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f9355f15fc33fb7a5258a4308fd09aea2600f14"},"cell_type":"code","source":"def split_vals(a,n): return a[:n], a[n:]\nn_valid = 30\nn_trn = len(df_trn)-n_valid\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nraw_train, raw_valid = split_vals(df_raw, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62a0500178a84e28d3fbb0ad51c19adf739ab498"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef auc(x,y): return roc_auc_score(x, y)#x - y_true, y = y_score\n\ndef print_score(m):\n    res = [auc(y_train, m.predict(X_train)), auc(y_valid, m.predict(X_valid)),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#This is definately overfitting\nm = RandomForestRegressor(n_estimators=1000, min_samples_leaf=5, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41a4970c61c98177d56e3aa1b5ac98d2a7466ae0"},"cell_type":"code","source":"#a better fit\nm = RandomForestRegressor(n_estimators=1000, min_samples_leaf=25, max_features=0.6, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1528cd70a46cf31cfc11adb13fb0311e0b3958ae"},"cell_type":"markdown","source":"Let's try cross validation"},{"metadata":{"trusted":true,"_uuid":"dc0f05168e42a95d8041bec7850cbb70af0a6a05"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nscores = cross_val_score(m, df_trn, y_trn, cv=5, scoring='roc_auc')\nscores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29a771b03cd2fba3163ccff078cb6b83a4102bb9"},"cell_type":"markdown","source":"So we are getting 80% AUC on crossval, let's try feature importance and then check cross val again\n## Feature importance\n"},{"metadata":{"trusted":true,"_uuid":"95ac8301a91b13d488a8bb926f8e54f626460fb8"},"cell_type":"code","source":"fi = rf_feat_importance(m, df_trn);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6008ca93f08377f4d33d344b53c8a21ac6802a80"},"cell_type":"code","source":"#top 30 features are\nfi[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ae1adf9fa09cf2e72e6c8fc2619a6dbfda77296"},"cell_type":"code","source":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36989aa8c9496d24844b8687d73e3c960dfb7793"},"cell_type":"code","source":"def plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,7), legend=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a44d5fc27da6b38891892179650e3fbacff0ac57"},"cell_type":"code","source":"plot_fi(fi[:30]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a302a5ce4072c93f28a36a4790e5ac1f29e6144"},"cell_type":"markdown","source":"We'll keep all those varialbes which are above \n* 0.001\n* 0.005"},{"metadata":{"trusted":true,"_uuid":"3c72153d76afa8531af1e32e23ec20b13c77fef0"},"cell_type":"code","source":"to_keep = fi[fi.imp>0.005].cols; \nlen_tokeep = len(to_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5db7071cffd18b9ec8b6adc51537eef795cae99"},"cell_type":"code","source":"df_keep = df_trn[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, 250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d38055fd718cff96747c92ef87685f891124f09"},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0e791408023e01293ab29971feeb552eb658b1d"},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=-1, oob_score=True)\nscores = cross_val_score(m, X_train, y_trn, cv=5, scoring='roc_auc')\nscores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7aed84b887b02c15a86fef624bb5c37accca2d2"},"cell_type":"markdown","source":"Here we can see that we are getting 87.5 AUC on whole set using crossval\n### Now let's try out prediction on this"},{"metadata":{"trusted":true,"_uuid":"331e1e408420f5f2a79eac4d1a3fd2a38732973e"},"cell_type":"code","source":"m.fit(X_train, y_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bd6088dc918e548f558dfe1f758a7179885291f"},"cell_type":"code","source":"df_keep = df_test[to_keep].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3416a7dfc59918e4d48fcc055305e129e3429b0e"},"cell_type":"code","source":"df_keep.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"404485622e18673ed7fabd931b5ddfbfa2613b1e"},"cell_type":"code","source":"y_preds = m.predict(df_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e5ff8bd58a299d6968c60794c7895374f2a8c0b"},"cell_type":"code","source":"y_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f8977e621689b7f86fba71ac4ab1a6fff31736a"},"cell_type":"code","source":"submission_rf = pd.read_csv(PATH + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b79ed5e915285f0e61b1c80a5061875777a18a36"},"cell_type":"code","source":"submission_rf['target'] = y_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c130027d80a3f176d3437906e2219df65eb85e04"},"cell_type":"code","source":"submission_rf.to_csv('submission_0.005.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ab9f36d7520f359483eb6d44bb7a9fe77268329"},"cell_type":"markdown","source":"\n### Now let's try with feature importance > 0.001"},{"metadata":{"trusted":true,"_uuid":"b51baa62dc18534f07d7e141d7789c4b88f0acae"},"cell_type":"code","source":"to_keep = fi[fi.imp>0.001].cols; \nlen(to_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3b58a7d3802c17a6f4cbad4f608f3f11caf3745"},"cell_type":"code","source":"df_keep = df_trn[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, 250)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80c7bdd9074c64d4176e19ab840b0381f7195256"},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=25, max_features=0.5, n_jobs=-1, oob_score=True)\nscores = cross_val_score(m, X_train, y_trn, cv=5, scoring='roc_auc')\nscores","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08e109535f8899b11be2ca6de71d0480f4011ff6"},"cell_type":"markdown","source":"### We can see that  features between 0.001-0.005 are not giving great accuracy"},{"metadata":{"trusted":true,"_uuid":"772c44a5db7ec8e8f151526777cb02511e072e5a"},"cell_type":"code","source":"m.fit(X_train, y_trn)\ndf_keep = df_test[to_keep].copy()\ny_preds = m.predict(df_keep)\nsubmission_rf['target'] = y_preds\nsubmission_rf.to_csv('submission_0.001.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"710fe7b2539d0f148d1d72229ce9aa3d1cd907ff"},"cell_type":"markdown","source":"## Let's try removing redundant features"},{"metadata":{"trusted":true,"_uuid":"8608feffef1418979a036f7971e8c759d2666fd5"},"cell_type":"code","source":"to_keep = fi[fi.imp>0.005].cols; \ndf_keep = df_trn[to_keep].copy()\nlen_tokeep = len(to_keep)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8c0937bccac61c854d953a2e93cd1cacb3a2be7"},"cell_type":"code","source":"from scipy.cluster import hierarchy as hc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a8e4998637c40c979dc6526b0b20d0c89080586"},"cell_type":"code","source":"corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c601986219f53b1cdb350099b30eec40b58e4b7b"},"cell_type":"markdown","source":"We can clearly see that there are no features which are highly correlated with other, so don;t remove anything"},{"metadata":{"_uuid":"271f495a1dba1c2a044b65485f65ae01c337e25b"},"cell_type":"markdown","source":"## Thank you\n\nPlease upvote the kernel if you liked it\n\nConnect with me on - https://www.linkedin.com/in/savannahar/\n\nShare important tips / links / resouces in comment section because sharing is caring."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}