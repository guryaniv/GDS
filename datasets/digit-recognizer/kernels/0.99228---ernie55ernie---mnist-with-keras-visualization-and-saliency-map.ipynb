{"nbformat": 4, "nbformat_minor": 1, "cells": [{"source": ["# Introduction\n", "This notebook contains the basic usage of keras and sklearn on MNIST\n", "There are 5 steps.\n", "\n", "1. Stratified shuffling split on training data set\n", "2. Training and validating a CNN\n", "3. Confusion matrix\n", "4. Convolution fileter visualization\n", "5. Saliency map\n", "\n", "There are 2 outputs\n", "\n", "1. Prediction csv on testing data\n", "2. Keras model"], "cell_type": "markdown", "metadata": {"_cell_guid": "2de56a8c-44b5-a6cc-4285-cc16ab6c68a3", "_uuid": "923b62e73c8922a43d3a84b594cb020ece836ea4"}}, {"execution_count": null, "source": ["%matplotlib inline\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import os\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "b1fee710-4d59-7eca-0aac-60e3bebdcd9c", "_uuid": "3dddd9a64c4d0ca6d711b7b8629be98e54f2b1b7", "collapsed": true}}, {"execution_count": null, "source": ["# read input csv file\n", "train_df = pd.read_csv('../input/train.csv')\n", "test_df = pd.read_csv('../input/test.csv')"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "1a0ff719-d136-c47a-7574-ab841fd692ef", "_uuid": "a807213945886eed5513e512af850b6bbc995bdc", "collapsed": true}}, {"execution_count": null, "source": ["X_train = []\n", "Y_train = []\n", "X_test = []\n", "\n", "# reshape training data from rows into images\n", "for index, row in train_df.iterrows():\n", "    X_train.append(row.values[1 : ].reshape((28, 28, 1)))\n", "    Y_train.append(row['label'])\n", "\n", "# reshape testing data from rows into images\n", "for index, row in test_df.iterrows():\n", "    X_test.append(row.values.reshape((28, 28, 1)))\n", "\n", "# normalization\n", "X_train = np.array(X_train) / 255.\n", "Y_train = np.array(Y_train)\n", "X_test = np.array(X_test) / 255.\n", "\n", "print('There are', X_train.shape[0], 'training data and', X_test.shape[0], 'testing data')\n", "print('Number of occurence for each number in training data (0 stands for 10):')\n", "print(np.vstack((np.unique(Y_train), np.bincount(Y_train))).T)\n", "sns.countplot(Y_train)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fedbe811-b145-4961-b93d-83d7d3b61af9", "_uuid": "18b1e99f22f559b45723c79596bdcc69467d95ed", "collapsed": true}}, {"execution_count": null, "source": ["# plot first 36 images in MNIST\n", "fig, ax = plt.subplots(6, 6, figsize = (12, 12))\n", "fig.suptitle('First 36 images in MNIST')\n", "fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n", "for x, y in [(i, j) for i in range(6) for j in range(6)]:\n", "    ax[x, y].imshow(X_train[x + y * 6].reshape((28, 28)), cmap = 'gray')\n", "    ax[x, y].set_title(Y_train[x + y * 6])"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "59b6f342-9576-47ef-a893-99c7fd7bef61", "_uuid": "160c9521ae9e8e4581d7ee8db6b07dbe10b03e9f", "collapsed": true}}, {"execution_count": null, "source": ["from sklearn.model_selection import StratifiedShuffleSplit\n", "from sklearn import preprocessing\n", "\n", "# transform training label to one-hot encoding\n", "lb = preprocessing.LabelBinarizer()\n", "lb.fit(Y_train)\n", "Y_train = lb.transform(Y_train)\n", "\n", "# split training and validating data\n", "print('Stratified shuffling...')\n", "sss = StratifiedShuffleSplit(10, 0.2, random_state = 15)\n", "for train_idx, val_idx in sss.split(X_train, Y_train):\n", "    X_train_tmp, X_val = X_train[train_idx], X_train[val_idx]\n", "    Y_train_tmp, Y_val = Y_train[train_idx], Y_train[val_idx]\n", "\n", "X_train = X_train_tmp\n", "Y_train = Y_train_tmp\n", "print('Finish stratified shuffling...')"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "8a27786a-a030-46ee-881b-0681091453e1", "_uuid": "321d87b1d7476a10706a197a2ec98a864d2257ed", "collapsed": true}}, {"execution_count": null, "source": ["from keras.models import Sequential, load_model\n", "from keras.layers import Dense, Dropout, Activation, Flatten\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras.preprocessing.image import ImageDataGenerator\n", "\n", "img_size = (28, 28, 1)\n", "n_classes = 10\n", "\n", "if os.path.exists('keras_model.h5'):\n", "    print('Loading model...')\n", "    model = load_model('keras_model.h5')\n", "else:\n", "    print('Building model...')\n", "    model = Sequential()\n", "    model.add(Conv2D(32, (5, 5), input_shape = img_size, kernel_initializer = 'normal'))\n", "    model.add(Activation('relu'))\n", "    model.add(MaxPooling2D(pool_size = (2, 2)))\n", "    model.add(Conv2D(64, (5, 5), kernel_initializer = 'normal'))\n", "    model.add(Activation('relu'))\n", "    model.add(MaxPooling2D(pool_size = (2, 2)))\n", "    model.add(Dropout(0.25))\n", "\n", "    model.add(Flatten())\n", "    model.add(Dense(128))\n", "    model.add(Activation('relu'))\n", "    model.add(Dropout(0.5))\n", "    model.add(Dense(n_classes))\n", "    model.add(Activation('softmax'))\n", "\n", "    model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d8273349-4d53-4913-8f4d-68f8c9d7658b", "_uuid": "f34882a0697c48a97abe4d98d5bf5ce770f59675", "collapsed": true}}, {"execution_count": null, "source": ["# data augmentation\n", "datagen = ImageDataGenerator(\n", "    featurewise_center = False,\n", "    samplewise_center = False,\n", "    featurewise_std_normalization = False,\n", "    samplewise_std_normalization = False,\n", "    zca_whitening = False,\n", "    rotation_range = 0,\n", "    zoom_range = 0.1,\n", "    width_shift_range = 0.1,\n", "    height_shift_range = 0.1,\n", "    horizontal_flip = False,\n", "    vertical_flip = False\n", ")\n", "\n", "datagen.fit(X_train)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "ba113fe7-ab67-490a-8815-bc982114ac16", "_uuid": "d7427c58db9bb6ddb7551c2dc218ba8c2f27d91a", "collapsed": true}}, {"execution_count": null, "source": ["print('Training model...')\n", "model.fit_generator(datagen.flow(X_train, Y_train, batch_size = 1000),\n", "                   epochs = 20,\n", "                   validation_data = (X_val, Y_val),\n", "                   steps_per_epoch = X_train.shape[0] / 1000,\n", "                   verbose = 1)\n", "print('Validating model...')\n", "score, acc = model.evaluate(X_val, Y_val, verbose = 1)\n", "print('\\nLoss:', score, '\\nAcc:', acc)\n", "model.save('keras_model.h5')"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a7391b20-ff36-4762-bff7-9e8ce13e862a", "_uuid": "61dd2e13e9b819100ffb95562076d634fda90c48", "collapsed": true}}, {"execution_count": null, "source": ["print('Predicting...')\n", "Y_test = model.predict(X_test)\n", "Y_test = lb.inverse_transform(Y_test)\n", "Y_test = [[y] for y in Y_test]\n", "index = [[i] for i in range(1, X_test.shape[0] + 1)]\n", "output_np = np.concatenate((index, Y_test), axis = 1)\n", "output_df = pd.DataFrame(data = output_np, columns = ['ImageId', 'Label'])\n", "output_df.to_csv('out.csv', index = False)"], "cell_type": "code", "outputs": [], "metadata": {"_kg_hide-output": false, "_cell_guid": "6f4ee46c-25a2-4e25-a04f-8a773635171e", "_uuid": "7e57d745780d5e5a044e5730e7a9e26a8d68ebe7", "collapsed": true}}, {"execution_count": null, "source": ["from sklearn.metrics import confusion_matrix\n", "import itertools\n", "\n", "Y_pred = model.predict(X_val)\n", "Y_val_pred = lb.inverse_transform(Y_pred)\n", "Y_val_real = lb.inverse_transform(Y_val)\n", "cm = confusion_matrix(Y_val_real, Y_val_pred)\n", "cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n", "\n", "# print(cm)\n", "plt.imshow(cm, cmap = 'gray')\n", "plt.title('Normalized confusion matrix')\n", "plt.colorbar()\n", "tick_marks = np.arange(n_classes)\n", "plt.xticks(tick_marks, np.arange(n_classes), rotation=45)\n", "plt.yticks(tick_marks, np.arange(n_classes))\n", "\n", "fmt = '.2f'\n", "thresh = cm.max() / 2.\n", "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "    plt.text(j, i, format(cm[i, j], fmt),\n", "             horizontalalignment=\"center\",\n", "             color=\"white\" if cm[i, j] > thresh else \"black\")\n", "\n", "plt.tight_layout()\n", "plt.ylabel('True label')\n", "plt.xlabel('Predicted label')"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4e3b8fa9-e376-4211-a54f-6db34388a41d", "_uuid": "a509dc4c1f4354a4aa5f3ca0959b979aa0959337", "collapsed": true}}, {"execution_count": null, "source": ["# Visualizating filters\n", "# https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n", "from keras import backend as K\n", "K.set_learning_phase(1)\n", "import tensorflow as tf\n", "\n", "model = load_model('keras_model.h5')\n", "\n", "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n", "#print('Layer dict', layer_dict)\n", "print(model.summary())"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3f3f446e-6c00-40e3-9094-769c34e98c40", "_uuid": "5ed01b06314216e4029826074838316b28800f56", "collapsed": true}}, {"execution_count": null, "source": ["# util function to convert a tensor into a valid image\n", "def deprocess_image(x):\n", "    # normalize tensor: center on 0., ensure std is 0.1\n", "    x -= x.mean()\n", "    x /= (x.std() + 1e-5)\n", "    x *= 0.1\n", "\n", "    # clip to [0, 1]\n", "    x += 0.5\n", "    x = np.clip(x, 0, 1)\n", "\n", "    # convert to RGB array\n", "    x *= 255\n", "    #x = x.transpose((1, 2, 0))\n", "    x = np.clip(x, 0, 255).astype('uint8')\n", "    return x\n", "\n", "def vis_img_in_filter(img = np.array(X_train[0]).reshape((1, 28, 28, 1)).astype(np.float64), \n", "                      layer_name = 'conv2d_2'):\n", "    layer_output = layer_dict[layer_name].output\n", "    img_ascs = list()\n", "    for filter_index in range(layer_output.shape[3]):\n", "        # build a loss function that maximizes the activation\n", "        # of the nth filter of the layer considered\n", "        loss = K.mean(layer_output[:, :, :, filter_index])\n", "\n", "        # compute the gradient of the input picture wrt this loss\n", "        grads = K.gradients(loss, model.input)[0]\n", "\n", "        # normalization trick: we normalize the gradient\n", "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n", "\n", "        # this function returns the loss and grads given the input picture\n", "        iterate = K.function([model.input], [loss, grads])\n", "\n", "        # step size for gradient ascent\n", "        step = 5.\n", "\n", "        img_asc = np.array(img)\n", "        # run gradient ascent for 20 steps\n", "        for i in range(20):\n", "            loss_value, grads_value = iterate([img_asc])\n", "            img_asc += grads_value * step\n", "\n", "        img_asc = img_asc[0]\n", "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n", "        \n", "    if layer_output.shape[3] >= 35:\n", "        plot_x, plot_y = 6, 6\n", "    elif layer_output.shape[3] >= 23:\n", "        plot_x, plot_y = 4, 6\n", "    elif layer_output.shape[3] >= 11:\n", "        plot_x, plot_y = 2, 6\n", "    else:\n", "        plot_x, plot_y = 1, 2\n", "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n", "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n", "    ax[0, 0].set_title('Input image')\n", "    fig.suptitle('Input image and %s filters' % (layer_name,))\n", "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n", "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n", "        if x == 0 and y == 0:\n", "            continue\n", "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n", "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n", "\n", "vis_img_in_filter()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0f597323-6781-4248-8f80-1b8c94926562", "_uuid": "7bcbd005e65a1bedfe1915defc5afabcd534aa5f", "collapsed": true}}, {"execution_count": null, "source": ["# Saliency map\n", "# https://github.com/experiencor/deep-viz-keras/blob/master/saliency.py\n", "from keras.layers import Input, Conv2DTranspose\n", "from keras.models import Model\n", "from keras.initializers import Ones, Zeros\n", "\n", "class SaliencyMask(object):\n", "    def __init__(self, model, output_index=0):\n", "        pass\n", "\n", "    def get_mask(self, input_image):\n", "        pass\n", "\n", "    def get_smoothed_mask(self, input_image, stdev_spread=.2, nsamples=50):\n", "        stdev = stdev_spread * (np.max(input_image) - np.min(input_image))\n", "\n", "        total_gradients = np.zeros_like(input_image, dtype = np.float64)\n", "        for i in range(nsamples):\n", "            noise = np.random.normal(0, stdev, input_image.shape)\n", "            x_value_plus_noise = input_image + noise\n", "\n", "            total_gradients += self.get_mask(x_value_plus_noise)\n", "\n", "        return total_gradients / nsamples\n", "\n", "class GradientSaliency(SaliencyMask):\n", "\n", "    def __init__(self, model, output_index = 0):\n", "        # Define the function to compute the gradient\n", "        input_tensors = [model.input]\n", "        gradients = model.optimizer.get_gradients(model.output[0][output_index], model.input)\n", "        self.compute_gradients = K.function(inputs = input_tensors, outputs = gradients)\n", "\n", "    def get_mask(self, input_image):\n", "        # Execute the function to compute the gradient\n", "        x_value = np.expand_dims(input_image, axis=0)\n", "        gradients = self.compute_gradients([x_value])[0][0]\n", "\n", "        return gradients\n", "\n", "# https://github.com/experiencor/deep-viz-keras/blob/master/visual_backprop.py\n", "class VisualBackprop(SaliencyMask):\n", "    def __init__(self, model, output_index = 0):\n", "        inps = [model.input]           # input placeholder\n", "        outs = [layer.output for layer in model.layers]    # all layer outputs\n", "        self.forward_pass = K.function(inps, outs)         # evaluation function\n", "        \n", "        self.model = model\n", "\n", "    def get_mask(self, input_image):\n", "        x_value = np.expand_dims(input_image, axis=0)\n", "        \n", "        visual_bpr = None\n", "        layer_outs = self.forward_pass([x_value, 0])\n", "\n", "        for i in range(len(self.model.layers) - 1, -1, -1):\n", "            if 'Conv2D' in str(type(self.model.layers[i])):\n", "                layer = np.mean(layer_outs[i], axis = 3, keepdims = True)\n", "                layer = layer - np.min(layer)\n", "                layer = layer / (np.max(layer) - np.min(layer) + 1e-6)\n", "\n", "                if visual_bpr is not None:\n", "                    if visual_bpr.shape != layer.shape:\n", "                        visual_bpr = self._deconv(visual_bpr)\n", "                    visual_bpr = visual_bpr * layer\n", "                else:\n", "                    visual_bpr = layer\n", "\n", "        return visual_bpr[0]\n", "    \n", "    def _deconv(self, feature_map):\n", "        x = Input(shape = (None, None, 1))\n", "        y = Conv2DTranspose(filters = 1, \n", "                            kernel_size = (3, 3), \n", "                            strides = (2, 2), \n", "                            padding = 'same', \n", "                            kernel_initializer = Ones(), \n", "                            bias_initializer = Zeros())(x)\n", "\n", "        deconv_model = Model(inputs=[x], outputs=[y])\n", "\n", "        inps = [deconv_model.input]   # input placeholder                                \n", "        outs = [deconv_model.layers[-1].output]           # output placeholder\n", "        deconv_func = K.function(inps, outs)              # evaluation function\n", "        \n", "        return deconv_func([feature_map, 0])[0]"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "bf3e4ad5-d0df-4401-9ef3-63656ac5f03a", "_uuid": "6365194e702ff0bcbbd68f808012c483c763aee0", "collapsed": true}}, {"execution_count": null, "source": ["Y_train_label = lb.inverse_transform(Y_train)\n", "\n", "fig, ax = plt.subplots(10, 5, figsize = (12, 16))\n", "fig.suptitle('vanilla gradient')\n", "for i in range(n_classes):\n", "    img = np.array(X_train[i])\n", "    \n", "    vanilla = GradientSaliency(model, Y_train_label[i])\n", "    mask = vanilla.get_mask(img)\n", "    filter_mask = (mask > 0.0).reshape((28, 28))\n", "    smooth_mask = vanilla.get_smoothed_mask(img)\n", "    filter_smoothed_mask = (smooth_mask > 0.0).reshape((28, 28))\n", "\n", "    ax[i, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n", "    cax = ax[i, 1].imshow(mask.reshape((28, 28)), cmap = 'jet')\n", "    fig.colorbar(cax, ax = ax[i, 1])\n", "    ax[i, 2].imshow(mask.reshape((28, 28)) * filter_mask, cmap = 'gray')\n", "    cax = ax[i, 3].imshow(mask.reshape((28, 28)), cmap = 'jet')\n", "    fig.colorbar(cax, ax = ax[i, 3])\n", "    ax[i, 4].imshow(smooth_mask.reshape((28, 28)) * filter_smoothed_mask, cmap = 'gray')"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "949110aa-047b-4cf5-81a5-1cbf0570275b", "_uuid": "fbc36c0c814affb546c2fae342f762e334daba06", "collapsed": true}}, {"execution_count": null, "source": [], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "160805f3-c99c-4858-8664-a641b2276d97", "_uuid": "e6cf03463c9510619833e517f221e2347cee55e0", "collapsed": true}}], "metadata": {"_is_fork": false, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py"}, "_change_revision": 0, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}}