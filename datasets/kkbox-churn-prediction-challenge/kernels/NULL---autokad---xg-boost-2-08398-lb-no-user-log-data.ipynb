{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"file_extension": ".py", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python"}}, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "41848c17-3a2d-4206-a8a4-bfcb1c3300c7", "_uuid": "f373ca6858f76f606bb3f9623cfb0ae78e6f7aff"}, "cell_type": "code", "execution_count": null, "source": ["# This gets 2.08398 on the LB with only XGBoost and no user_log data.\n", "# This is done by adjusting the transaction date distributions between training and test\n", "\n", "############################################################\n", "## Imports\n", "############################################################\n", "from datetime import datetime\n", "import numpy as np\n", "import pandas as pd\n", "from xgboost import XGBClassifier\n", "\n", "############################################################\n", "## other globals\n", "############################################################\n", "PATH = \"../input/\"\n", "gender = {'male':1, 'female':2}\n", "\n", "############################################################\n", "## function definitions\n", "############################################################\n", "## This gets X/Y train/test data\n", "def get_xy(train_data, test_data, features, y_feature='is_churn', istest=False, dropOutliers=False, outlierMinMax=(-0.4, 0.418), replaceNan=True, fold=1, rs=1):\n", "    if istest:\n", "        if replaceNan:\n", "            X = train_data[features].fillna(-999).values\n", "            Y = train_data[y_feature].values\n", "        else:\n", "            X = train_data[features].values\n", "            Y = train_data[y_feature].values\n", "        if dropOutliers:\n", "            X = X[ Y  > outlierMinMax[0] ]\n", "            Y = Y[ Y  > outlierMinMax[0] ]\n", "            X = X[ Y  < outlierMinMax[1] ]\n", "            Y = Y[ Y  < outlierMinMax[1] ]\n", "        from sklearn.model_selection import KFold\n", "        kf = KFold(n_splits=10, random_state=rs, shuffle=True)\n", "        folds = list(kf.split(train_data))\n", "        train_index,test_index = tuple(list(folds)[fold])\n", "        x_train_m, x_test_m = X[train_index], X[test_index]\n", "        y_train_m, y_test_m = Y[train_index], Y[test_index]\n", "    else:\n", "        train_index, test_index = 0, 0\n", "        if replaceNan:\n", "            x_train_m = train_data[features].fillna(-999).values\n", "            x_test_m = test_data[features].fillna(-999).values\n", "        else:\n", "            x_train_m = train_data[features].values\n", "            x_test_m = test_data[features].values\n", "        y_train_m = train_data[y_feature].values\n", "        y_test_m = np.nan\n", "        if dropOutliers:\n", "            x_train_m = x_train_m[ y_train_m  > outlierMinMax[0] ]\n", "            y_train_m = y_train_m[ y_train_m  > outlierMinMax[0] ]\n", "            x_train_m = x_train_m[ y_train_m  < outlierMinMax[1] ]\n", "            y_train_m = y_train_m[ y_train_m  < outlierMinMax[1] ]\n", "    return x_train_m, x_test_m, y_train_m, y_test_m, train_index, test_index\n", " \n", "def get_last_df(df, date_field='date'):\n", "    df = df.sort_values(by=[date_field], ascending=[False]).reset_index(drop=True)\n", "    df = df.drop_duplicates(subset=['msno'], keep='first')\n", "    return df\n", "\n", "############################################################\n", "## loading data\n", "############################################################\n", "print('Loading data...')\n", "sample = pd.read_csv(PATH + 'sample_submission_zero.csv')\n", "train = pd.read_csv(PATH + 'train.csv')\n", "members = pd.read_csv(PATH + 'members.csv')\n", "trans = pd.read_csv(PATH + 'transactions.csv')\n", "test = sample.copy()\n", "\n", "############################################################\n", "## Feature engineering\n", "############################################################\n", "print('Feature engineering...')\n", "\n", "print(' Members...')\n", "## Add duration\n", "members['registration_duration_month'] = (pd.to_datetime(members.expiration_date, format='%Y%m%d') - pd.to_datetime(members.registration_init_time, format='%Y%m%d'))/ np.timedelta64(1, 'M')\n", "\n", "## Add Gender\n", "members['gender'] = members['gender'].map(gender)\n", "\n", "print(' Transactions...')\n", "trans = get_last_df(trans,'transaction_date')\n", "\n", "############################################################\n", "## Join Data\n", "############################################################\n", "print('Join Data...')\n", "train = pd.merge(train, members, how='left', on='msno')\n", "test = pd.merge(test, members, how='left', on='msno')\n", " \n", "## ** try adding 1 month to train, to make it similar to test?\n", "## This was determined by looking at the percentile values of the train vs test\n", "train['expiration_date'] = train['expiration_date'] + 100\n", " \n", "train = pd.merge(train, trans, how='left', on='msno')\n", "test = pd.merge(test, trans, how='left', on='msno')\n", " \n", "feature_names = [feature for feature in train.columns[2:]]\n", "test = test[feature_names]\n", "\n", "############################################################\n", "## create X, Y\n", "############################################################\n", "print('create X, Y...')\n", "istest=False\n", "x_train_xgb, x_test_xgb, y_train_xgb, y_test_xgb, train_index, test_index = get_xy(train, test, feature_names, istest=istest, replaceNan=False, dropOutliers=False)\n", "\n", "############################################################\n", "## Model Parameters\n", "############################################################\n", "print('Setting up model parameters')\n", "params_xgb = {}\n", "params_xgb['random_state'] = 1\n", "params_xgb['learning_rate'] = 0.037\n", "params_xgb['max_depth'] = 7\n", "params_xgb['objective'] = 'binary:logistic'\n", "params_xgb['n_estimators']=242\n", "params_xgb['gamma']=0\n", "params_xgb['subsample']=1\n", "params_xgb['reg_alpha']=0\n", "params_xgb['reg_lambda']=1\n", "params_xgb['base_score']=np.mean(train.is_churn)\n", " \n", "############################################################\n", "## Run Models\n", "############################################################\n", "print('Running Models')\n", " \n", "model_xgb = XGBClassifier(**params_xgb).fit(x_train_xgb, y_train_xgb)\n", "y_hat_xgb = model_xgb.predict(x_test_xgb)\n", "\n", "############################################################\n", "## Results\n", "############################################################\n", "print('Calculating Results...')\n", "results = pd.DataFrame()\n", "sample = pd.read_csv(PATH + 'sample_submission_zero.csv')\n", " \n", "results = sample.copy()\n", "results['is_churn']=y_hat_xgb\n", "\n", "results.to_csv('submission.{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index = False, float_format = '%.0f')\n", "print('Done!')"], "outputs": []}]}