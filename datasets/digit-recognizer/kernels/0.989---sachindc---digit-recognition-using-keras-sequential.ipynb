{"cells":[{"metadata":{"_cell_guid":"74fa7fac-c6e8-4ccb-b62a-8462d7bc2fd3","_uuid":"9e9a3dbda8775d06217ac201d28f14bdc05778f7","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"4e25de41-7041-406d-98d1-bc4b1ddc73dc","_uuid":"d7e8d36b52f73869b3d7ff1529a5da5baef97bd4"},"cell_type":"markdown","source":"### Load the data.."},{"metadata":{"_cell_guid":"085dccfd-14b4-4f83-bc1b-c3f4dc8df423","_kg_hide-output":false,"collapsed":true,"_uuid":"522b840844b24258637866449c787c3d9881d2aa","trusted":true},"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"9e15c182-1a33-4978-9cad-91dea3e3cea1","_uuid":"6e1a2c45bf66a47a6fb977d1b1b3ce6a47444967","trusted":true},"cell_type":"code","source":"Y_train = train[\"label\"]\n\n# Drop 'label' column\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# free some space\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"dc77657e-49e1-4d9d-8de6-fb0377228fb8","_uuid":"6d07c390f0a6d50f3fd98511e2319081030ec4ec"},"cell_type":"markdown","source":"### Check for null and missing values"},{"metadata":{"_cell_guid":"80cb33d7-817b-40ad-af43-f29276113c01","_uuid":"a3d17fe5c157196445c92d80d08542304d7cffbd","trusted":true},"cell_type":"code","source":"# Check the data\nX_train.isnull().any().describe()","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"e6d99a3f-4e8a-48d6-8352-a206359f1347","_uuid":"0cb60c8d4a1bc0138f6b05ea547400e1a3a85124","trusted":true},"cell_type":"code","source":"test.isnull().any().describe()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"8abd4f82-ffb7-4f81-84b9-5b02e86d9505","collapsed":true,"_uuid":"2b2276752d07a28c8a0f1483ddb2f85672cd93c0","trusted":true},"cell_type":"code","source":"# Normalize the data\nX_train = X_train / 255.0\ntest = test / 255.0","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"aa350253-2227-4873-87ce-d12ee12453ff","collapsed":true,"_uuid":"bee78d885a265db19c95700bdba69245087c3ef3","trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 28px, width = 28px , channel = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"91eb4e22-6b25-41e6-a835-383907a435ec","collapsed":true,"_uuid":"1f157efe3f5d80e068a33d8a9cd9dba01d3c656c","trusted":true},"cell_type":"code","source":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"d053b265-2392-417b-b2dc-f08dd088a518","collapsed":true,"_uuid":"7e2eb8fbcec4862cb85e4048b8d551d97cd5a7fb","trusted":true},"cell_type":"code","source":"# Set the random seed\nrandom_seed = 20","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"f1ce6e85-dc54-4b77-a342-aaccc274d6f2","collapsed":true,"_uuid":"7c4882046c410d7a64b7ab590cea6b94a46870f6","trusted":true},"cell_type":"code","source":"# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"37e45fd7-2073-4510-8041-1d47f7ac46a4","_uuid":"dd2a015d3ce1b0048d486b38e6ed91729a366d9b","trusted":true},"cell_type":"code","source":"# Some examples\ng = plt.imshow(X_train[0][:,:,0])","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"0ffa59f9-6a8c-4500-8716-565488517d77","collapsed":true,"_uuid":"8e7971e9c7675e7294e52bbb30bccfa5dff255c4","trusted":true},"cell_type":"code","source":"# Set the CNN model \n# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"12e71f18-ed54-478a-8b15-04351523ef1e","collapsed":true,"_uuid":"2bbfb2e934e1fa718dde16fa0acadcceebcd42e5","trusted":true},"cell_type":"code","source":"# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"0482468e-9d06-404f-99ab-aa0cc90a5df8","collapsed":true,"_uuid":"52d0922b1306c770107609f907ee5c0119bafe49","trusted":true},"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"98d78921-1cb1-4fdf-be79-b6b5a596a5e9","collapsed":true,"_uuid":"7ceed9ad303fa4ee18b0811d63e0162da917cd4f","trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"b71d0aba-45dc-4262-8420-bba7ef1e6131","collapsed":true,"_uuid":"ed45359a4b42db7d483b07909b17c7a9a97b92f8","trusted":true},"cell_type":"code","source":"epochs = 3 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 90","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"52869f83-5d1c-454e-bf7c-dc2532f0706f","collapsed":true,"_uuid":"a2a41771c11805adf20ff9d94b4eaed63829bf48","trusted":true},"cell_type":"code","source":"# Without data augmentation i obtained an accuracy of 0.98114\n#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n#          validation_data = (X_val, Y_val), verbose = 2)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"dc47d100-abd3-4772-9754-67750e6e8e0b","collapsed":true,"_uuid":"a0b04d4379d09cc8e2bcefcefdda819e5100b920","trusted":true},"cell_type":"code","source":"# With data augmentation to prevent overfitting (accuracy 0.99286)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"218a86da-a5b6-4164-a1af-22fe58279a52","_uuid":"022d33790ca6cb8fa7abc3b9f746d706d03d2e84","trusted":true},"cell_type":"code","source":"# Fit the model\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"dc437fb7-7dce-457c-8c13-49cdb4da149f","_uuid":"900b097aa72872ee700a8d00f46fb433f4611864","trusted":true},"cell_type":"code","source":"# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"3fd99aa8-820b-4090-a3d0-2fc1e5faa975","_uuid":"beeaa21db2fbd1628c0a25f445dc5928276a6aec","trusted":true},"cell_type":"code","source":"# Look at confusion matrix \n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predict the values from the validation dataset\nY_pred = model.predict(X_val)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(Y_val,axis = 1) \n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n# plot the confusion matrix\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"86c478f6-1bd8-4325-bacd-852949bb7a2e","_uuid":"5b9b352387ace502352d40dec153eb9dabd1fee6","trusted":true},"cell_type":"code","source":"# Display some error results \n\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilities of the wrong predicted numbers\nY_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n\n# Predicted probabilities of the true values in the error set\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Difference between the probability of the predicted label and the true label\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Sorted list of the delta prob errors\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# Top 6 errors \nmost_important_errors = sorted_dela_errors[-6:]\n\n# Show the top 6 errors\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"5bcd6b87-ccca-4cd1-bd86-479677265fe5","collapsed":true,"_uuid":"2652d97c89b668ff6f4ea72dc276c12d3ab54022","trusted":true},"cell_type":"code","source":"# predict results\nresults = model.predict(test)\n\n# select the indix with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","execution_count":24,"outputs":[]},{"metadata":{"_cell_guid":"19568a7d-1c07-4ec8-8e33-513f9b192424","collapsed":true,"_uuid":"fea6fa36bf5f596bc5860194a4291ceb4c910746","trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"bb5650d7-73d2-4b3b-9f9c-16628b17da6b","collapsed":true,"_uuid":"38fd2e4819c437cb6a7fb82dd38c0b0f6f6176f0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}