{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":false,"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ntest = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")\nembeding_file_path = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ec946d9-1e00-4563-a4ca-b7a818ae50e9","_uuid":"3f4cd4abd0f5f4f1180a9ffe314f02f076dc933e","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nmax_features = 100000\nembed_size = 300\nmaxlen = 100\n\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(pd.concat((train['comment_text'],test['comment_text'])))\ntrain_words = tokenizer.texts_to_sequences(train['comment_text'])\ntest_words = tokenizer.texts_to_sequences(test['comment_text'])\ntrain_words = pad_sequences(train_words, maxlen=maxlen,padding=\"post\", truncating=\"post\")\ntest_words = pad_sequences(test_words, maxlen=maxlen, padding=\"post\", truncating=\"post\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d8350738-88fa-4558-b012-8159a37d8d72","_uuid":"e64c586db6be97805ccd3f547f124c134b3aacc2","collapsed":true,"scrolled":false,"trusted":false},"cell_type":"code","source":"train_words[1099]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc70894e-640d-400d-b46b-256854b2de92","_uuid":"47c6e6137fa82d9101f299b728f359a92831b3dc","collapsed":true,"trusted":false},"cell_type":"code","source":"def get_coef(word, *coefs):\n    return word, np.asarray(coefs, dtype=np.float64)\nembeding_dict = dict(get_coef(*s.strip().split(\" \")) for s in open(embeding_file_path))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4a8c1382-27ad-4fd8-95c3-831be94f7048","_uuid":"6cf0f307139b8c3897ce8eed345635744351a9ce","collapsed":true,"trusted":false},"cell_type":"code","source":"word_index = tokenizer.word_index\nmax_words = min(max_features, len(word_index))\nembeding_matrix = np.random.randn(max_words+1, embed_size)\nfor word,i in word_index.items():\n    if word not in embeding_dict: continue\n    if i>max_words:continue \n    embeding_matrix[i] = embeding_dict[word]\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ccd631d-9fad-49db-87cd-8993a6391e46","_uuid":"8d2f04bb70ca3b0af59bb7a1858c6d7c034d05b4","collapsed":true,"trusted":false},"cell_type":"code","source":"len(embeding_dict)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e1af5e0-e701-4055-b053-9545988de2c6","_uuid":"9157a4bcc389507a01a4ead3851ccf2d43f51a2d","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\nfrom keras.layers import Conv1D, MaxPooling1D, Reshape, Flatten, Dropout\nfrom keras.callbacks import Callback\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.optimizers import Adam\n\nnum_filters = 100\nfilter_sizes = [2,4,5]\n\ndef get_model():\n    inp = Input(shape=(maxlen,)) #maxlen\n    x = Embedding(max_words+1, embed_size, weights=[embeding_matrix])(inp)\n    x = Dropout(0.5)(x)\n    conv_0 = Conv1D(num_filters, filter_sizes[0], activation='relu', init='he_normal', padding='valid', strides=1)(x)\n    conv_1 = Conv1D(num_filters, filter_sizes[1], activation='relu', init='he_normal', padding='valid', strides=1)(x)\n    conv_2 = Conv1D(num_filters, filter_sizes[2], activation='relu', init='he_normal', padding='valid', strides=1)(x)\n    max_pool_0 = MaxPooling1D(2)(conv_0)\n    max_pool_0 = Flatten()(max_pool_0)\n    max_pool_1 = MaxPooling1D(2)(conv_1)\n    max_pool_1 = Flatten()(max_pool_1)\n    max_pool_2 = MaxPooling1D(2)(conv_2)\n    max_pool_2 = Flatten()(max_pool_2)\n    conc = concatenate([max_pool_0, max_pool_1, max_pool_2])\n    conc = Dropout(0.3)(conc)\n    fc = Dense(50, activation='relu')(conc)\n    oup = Dense(6, activation='sigmoid')(fc)\n    \n    model = Model(input=inp, output=oup)\n    model.compile(loss='binary_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n    return model\n\nmodel = get_model()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"317b7ebe-eccb-417f-9deb-bb3ad7a63816","_uuid":"aec3fc53588d7f7c676cbc981fdcf4e72d20a0c4","collapsed":true,"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\n\nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n\nbatch_size = 128\nepochs = 10\ny_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\nX_tra, X_val, y_tra, y_val = train_test_split(train_words, y_train, train_size=0.9, random_state=233)\nRocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\nhist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n                 callbacks=[RocAuc, early_stop], verbose=1)\ny_pred = model.predict(test_words, batch_size=1024)\n          ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6d93a815-620f-4964-9b95-b80c7270d002","_uuid":"d97cf8f7996c1754d98c87392c5447e1bb7ded3f","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e998a27f-70e0-453f-b95a-5c6af5c607e6","_uuid":"78c77234f8ca6ecb6f39d398e9013b9aaa279801","collapsed":true,"trusted":false},"cell_type":"code","source":"model.save(\"text_cnn_v2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"58fe96c9-a30e-4ef4-bb70-d3b489c17db0","_uuid":"facb500e14246438c724bf47a98dae01ce0cb50f","collapsed":true,"trusted":false},"cell_type":"code","source":"submission = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = y_pred\nsubmission.to_csv('text_cnn_v2.csv', index=False)           ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21d0714c-7efb-4bc6-9cd9-bc6c215772e3","_uuid":"4556edbe7833218394b2615db93f98c5f3cb1188","collapsed":true,"trusted":false},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1e6bdcd9-b5ad-423d-bfd5-61d14b042e85","_uuid":"8611bfd5ce95b611c542db5b7cbfbd4ab7401ede","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}