{"cells":[{"metadata":{"_cell_guid":"1576af29-beb0-4b5c-b172-6ce2ed589d2d","_uuid":"484279c1e8f338245caa9e463839e373a0f312f2","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn import preprocessing\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5e0b32e5-ecd6-460d-bdd4-e877f6fb4f1e","_uuid":"9b7cde05e332ffe84f76b23a85add72418821970","trusted":false},"cell_type":"code","source":"train = pd.read_table(\"../input/train.tsv\")\ntest = pd.read_table(\"../input/test_stg2.tsv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ead308d2-ec13-4341-9f9f-d41dd81fc5db","_uuid":"304873047f24831bd38de6f9a3fcb72d14ad97c9","trusted":false,"collapsed":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4142280b-7c07-4de1-b3dd-25172e074a22","_uuid":"965aaf35550eac02e9aedb9ff780da62974a6e28"},"cell_type":"markdown","source":"**Dependent/Target  Variable  Analysis: Price**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"b8f2b4e0-3c46-4203-8072-fd96267dd4fe","_uuid":"f28311ff23bc8660aa9243518db3c1cbca90e2b9","trusted":false},"cell_type":"code","source":"\"\"\"train['price'].describe()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"714df8b0cd912c6d91fd97d6d8220ecab61f7da0","_kg_hide-input":true,"_cell_guid":"e71e55da-5750-4f73-94e2-0b369fd5e1ff","trusted":false},"cell_type":"code","source":"\"\"\"plt.subplot(1,2,1)\ntrain['price'].plot.hist(bins=60, figsize=(20,10), edgecolor=\"black\",range=[0,290])\nplt.xlabel(\"Price range\" , fontsize=20)\nplt.ylabel(\"Frequency\", fontsize=20)\nplt.tick_params(labelsize = 15)\nplt.title(\" Distribution of Price\", fontsize=20)\n\n# Tranforming price using log as price appears to have a left skew \n\nplt.subplot(1,2,2)\nnp.log(train['price']+1).plot.hist(bins=60,edgecolor=\"black\",figsize=(20,10))\nplt.xlabel(\"Price Range with Log transformation (log(price + 1))\", fontsize=20)\nplt.ylabel(\"Frequency\", fontsize=20)\nplt.tick_params(labelsize = 15)\nplt.title(\" Distribution of Log Transformed Price\", fontsize=20)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"287a0a6f-4ac2-4b18-94bc-7daa678dd563","_uuid":"f7885df7becca045b7a279a15fff476f72e42a2c"},"cell_type":"markdown","source":"**Shipping Variable**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"c773af825d89041dde49a6e1b938ebbc41bc48fd","_kg_hide-input":true,"_cell_guid":"7847847f-5d2f-4299-ba05-d1257ad2eef1","trusted":false},"cell_type":"code","source":"\"\"\"# So over half of the values shipping is not free\ntrain['shipping'].astype('category').value_counts()/len(train)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"55a19140-8fd9-4764-b4a5-95f8831d85cd","_uuid":"25278b7fabe20d7309f4927212d8567cae99f1f4"},"cell_type":"markdown","source":"Clearly seen from the histograms below that price is a little higher when product does have shipping included ","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"197f903bb6b916ab463955a89c3e4169068a51b2","_kg_hide-input":true,"_cell_guid":"2abbadf2-dfae-463f-8dc3-2ffc6eef38e5","trusted":false},"cell_type":"code","source":"\"\"\"plt.subplot(1,2,1)\nnp.log(train.loc[train['shipping']==1,'price']+1).plot.hist(bins=20, figsize=(20,10), edgecolor=\"black\")\nplt.xlabel(\"Price range (Shipping is free)\" , fontsize=20)\nplt.ylabel(\"Frequency\", fontsize=20)\nplt.tick_params(labelsize = 15)\nplt.title(\"Price Distribution Shipping Free\", fontsize=20)\n\nplt.subplot(1,2,2)\nnp.log(train.loc[train['shipping']==0,'price']+1).plot.hist(bins=20,edgecolor=\"black\",figsize=(20,10))\nplt.xlabel(\"Price Range (Shipping payed by user)\", fontsize=20)\nplt.ylabel(\"Frequency\", fontsize=20)\nplt.tick_params(labelsize = 15)\nplt.title(\"Price Distribution Shipping Charged\", fontsize=20)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d10000ce-be8f-420b-a7db-0e9ee2159406","_uuid":"db3e4f45f50600b192157250c2198b64ad761384"},"cell_type":"markdown","source":"**Item Condition **","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"98d7cab9-d434-4fac-9db2-7b7dec2e7f4d","_uuid":"e3e50a7ea3759d4da9733bc48477c79809172df7","trusted":false},"cell_type":"code","source":"\"\"\"# Lets see how price distributes over various item_conditions \ntrain['item_condition_id'].value_counts()/len(train)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"769b6789-ed0d-4756-b2cd-20f489749896","_uuid":"71dab3c8cb585d7bc3df77aec785e6703553f24c"},"cell_type":"markdown","source":"*Looking at the plots it looks like item condition doesnt asy anything about the price of an item on its own *","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"6428508312c1010038a5e0c9872e499a1404a9f5","_kg_hide-input":true,"_cell_guid":"2ff2bd9b-abd4-469f-8393-536a89ef56af","trusted":false},"cell_type":"code","source":"\"\"\"plt.figure(figsize=(10,5))\nax = sns.boxplot(x=np.log(train['price']+1),y='item_condition_id',\n                 data=train, dodge=False ,  orient=\"h\", palette=\"Set1\")\nplt.title(\"Price Distribution with Item_condition\",fontsize=15)\nplt.xlabel(\" Log transformed price range\",fontsize = 10)\nplt.ylabel(\"Item quality with 1 (Best) - 5(Worst)\",fontsize = 10)\nplt.tick_params(labelsize=15)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"36d3d423-8f76-40ad-8ba9-f55a78d064a8","_uuid":"f2157c2afcbf60c338a7fbfb7f920036677e48d4"},"cell_type":"markdown","source":"**Category**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"76e4b9b4-0b56-46eb-8e3d-15c5c9b760fd","_uuid":"b266558f5ff481e8c10d204baecab1cd1d818e77","trusted":false},"cell_type":"code","source":"\"\"\"all_categories = pd.Series([cat for cat_list in list(train['category_name'].apply(lambda x:str(x).split(\"/\"))) for cat in cat_list])\nprint(\"There are a total of {0} categories of products\".format(all_categories.value_counts().shape[0]))\nprint(\"Top 10 categories with occurence frequency:\")\nall_categories.value_counts()[:10]/len(all_categories)*100\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"96c42908-0e0b-4343-a2c0-0de75e3f57cf","_uuid":"24b3a2a15313a339448f292fcb2787e5891f26d2","trusted":false},"cell_type":"code","source":"\"\"\"print(\"There are {0} products without any categories\".format(train['category_name'].isnull().sum()))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1bc61cd4-a938-41b8-bb40-ff2fec0d7e86","_uuid":"ea0bdf775c513dc465bf3ba8609091403773e20e","trusted":false,"collapsed":true},"cell_type":"code","source":"###\n# reference: https://www.kaggle.com/thykhuely/mercari-interactive-eda-topic-modelling/notebook\nimport re\ndef split_cat(text):\n    try: \n        return text.split(\"/\")\n    except: return (\"Unknow\", \"Unknown\", \"Unknown\")\n\nfrom sklearn.preprocessing import LabelEncoder as le\ndef encode_labels(df, columns):\n    res = []\n    le = preprocessing.LabelEncoder()\n    for col in columns:\n        print(\"Encoding %s\"%col)\n        res.append(le.fit_transform(df[col].tolist()))\n    return tuple(res)\n\ntrain['general_cat'], train['subcat_1'], train['subcat_2'] = \\\nzip(*train['category_name'].apply(lambda x: split_cat(x)))\ntrain.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"aede8e55-7672-4529-9d09-097794bf168f","_uuid":"f4ed6091172be552999e5ca1a3d9d3bc937e5244","trusted":false,"collapsed":true},"cell_type":"code","source":"###\n#Same operations on test \ntest['general_cat'], test['subcat_1'], test['subcat_2'] = \\\nzip(*test['category_name'].apply(lambda x: split_cat(x)))\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca82ea463f504c5725399b1196f05452ae168f44","_kg_hide-input":false,"_cell_guid":"07ad0579-3f7b-4946-b25f-c1b37ef8f1dc"},"cell_type":"markdown","source":"Clearly categories define some price differences and we need to vectorize these variables to use them ","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_uuid":"dd40b4510e58b4d27d1cf569d114f35afecc5208","_kg_hide-input":true,"_cell_guid":"dc52d903-3c99-4c66-8371-26d7f51ea0e7","trusted":false},"cell_type":"code","source":"\"\"\"#Price distribution of top 10 caqtegories \ntop_cat = train.loc[train['general_cat'].isin(list(all_categories.value_counts().index[:10])),['general_cat','price']]\nplt.figure(figsize=(10,5))\nax = sns.boxplot(x=np.log(top_cat['price']+1),y='general_cat',\n                 data=top_cat, dodge=False ,  orient=\"h\", palette=\"Set2\")\nplt.title(\"Price Distribution with Top Categories\",fontsize=15)\nplt.xlabel(\"Log transformed price range\",fontsize = 10)\nplt.ylabel(\"Item category\",fontsize = 10)\nplt.tick_params(labelsize=15)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"57ec580c-4185-492e-bfea-17ab8c600600","_uuid":"dd0ac73a01d1347ddff8d64042d93a666ef817ba","trusted":false,"collapsed":true},"cell_type":"code","source":"###\n# fILL NULL BRNADS WITH OTHER AND LABEL ENCODE ALL BRANDS \ntrain['brand_name'].fillna(\"Other\",inplace = True)\ncolumns = ['brand_name','general_cat','subcat_1','subcat_2']\ntrain['brand_name'], train['general_cat'],train['subcat_1'],train['subcat_2'] = encode_labels(train,columns)\ntest['brand_name'], test['general_cat'],test['subcat_1'],test['subcat_2'] = encode_labels(test,columns)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"bc0a24a1-b785-4e98-8f77-b9989a885935","_uuid":"9e6bc3ce9f7de01718db638ca9e5bb9ef30e20fc","trusted":false},"cell_type":"code","source":"###\n# reference: https://ahmedbesbes.com/how-to-mine-newsfeed-data-and-extract-interactive-insights-in-python.html\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nimport re\nimport string \nstop = set(stopwords.words('english'))\ndef tokenize(text):\n    \"\"\"\n    sent_tokenize(): segment text into sentences\n    word_tokenize(): break sentences into words\n    \"\"\"\n    try: \n        regex = re.compile('[' +re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n        text = regex.sub(\" \", text) # remove punctuation\n        \n        tokens_ = [word_tokenize(s) for s in sent_tokenize(text)]\n        tokens = []\n        for token_by_sent in tokens_:\n            tokens += token_by_sent\n        tokens = list(filter(lambda t: t.lower() not in stop, tokens))\n        filtered_tokens = [w for w in tokens if re.search('[a-zA-Z]', w)]\n        filtered_tokens = [w.lower() for w in filtered_tokens if len(w)>=3]\n        \n        return filtered_tokens\n            \n    except TypeError as e: print(text,e)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3b9dc986-c873-4cdc-b87f-02670e21a9fe","_uuid":"7063a8c83daade485a4cfc2109077f0fbf24cc3b","trusted":false,"collapsed":true},"cell_type":"code","source":"###\n# Drop null item_descriptions as tfidf does not handle nans\nprint(\"{0} missing values in train['item_description']\".format(test['item_description'].isnull().sum()))\nprint(\"{0} missing values in test['item_description']\".format(train['item_description'].isnull().sum()))\ntrain.fillna(\"No description yet\",inplace =True)\ntest.fillna(\"No description yet\",inplace =True)\nprint(\"{0} missing values in train['item_description']\".format(train['item_description'].isnull().sum()))\nprint(\"{0} missing values in test['item_description']\".format(test['item_description'].isnull().sum()))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"09dd466f-7530-45b2-894b-66e1a546d4a7","_uuid":"af0519f242084c512c0804c350edb5668cac9da7","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvectorizer = TfidfVectorizer(min_df=10,max_features =100000,tokenizer=tokenize, ngram_range=(1, 2))\nimport time\nstart = time.time()\nall_tfidf = vectorizer.fit_transform(train['item_description'].tolist() + test['item_description'].tolist())\nprint(\"Vectorizing the input dataframe this make take some time...\")\ntrain_tfidf = vectorizer.transform(train['item_description'].tolist())\ntest_tfidf = vectorizer.transform(test['item_description'].tolist())\nprint(\"Time taken for Vectorizer {0} seconds\".format(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bcd048dc-acab-48ba-a304-a933fde263ce","_uuid":"e64648cfbd65c4250586cccc949f932e2fb40f98","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nfrom sklearn.decomposition import TruncatedSVD\nn_comp=30\nsvd_obj = TruncatedSVD(n_components=n_comp, random_state=42)\nstart = time.time()\nprint(\"Now Generating {0} components using Singular value Decomposition...\".format(n_comp))\nsvd_obj.fit(all_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n    \ntrain_svd.columns = ['svd_item_description_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_item_description_'+str(i) for i in range(n_comp)]\ntrain= pd.concat([train, train_svd], axis=1)\ntest = pd.concat([test, test_svd], axis=1)\nprint(\"Time taken for SVD {0} seconds\".format(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6cfa7779-0efc-4616-9027-764e03138b50","_uuid":"066ba791b815975bfac5f366a9640667fe76ebe4","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nstart = time.time()\nvectorizer = TfidfVectorizer(min_df=10,max_features =100000,tokenizer=tokenize, ngram_range=(1, 2))\nall_tfidf = vectorizer.fit_transform(train['name'].tolist() + test['name'].tolist())\nprint(\"Vectorizing the input dataframe this make take some time...\")\ntrain_tfidf = vectorizer.transform(train['name'].tolist())\ntest_tfidf = vectorizer.transform(test['name'].tolist())\nprint(\"Time taken for Vectorizer {0} seconds\".format(time.time() - start))\n\nstart = time.time()\nn_comp=30\nsvd_obj = TruncatedSVD(n_components=n_comp, random_state=42)\nprint(\"Now Generating {0} components using Singular value Decomposition...\".format(n_comp))\nsvd_obj.fit(all_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))\n    \ntrain_svd.columns = ['svd_name'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_name'+str(i) for i in range(n_comp)]\ntrain_df = pd.concat([train, train_svd], axis=1)\ntest_df = pd.concat([test, test_svd], axis=1)\nprint(\"Time taken for SVD {0} seconds\".format(time.time() - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"12544e38-92e0-493b-8b97-9f5e14798e9d","_uuid":"9777b08b1d23d374fbf0fef20387eafceea797a1","trusted":false,"collapsed":true},"cell_type":"code","source":"###\ntrain_df = train.copy()\ntest_df = test.copy()\nprint(\"Difference of features in train and test are {}\".format(np.setdiff1d(train.columns, test.columns)))\nprint(\"\")\ndo_not_use_for_training = ['cat_1','test_id','cat_2','cat_3','train_id','name', 'category_name', 'brand_name', 'price', 'item_description']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nprint(\"We will be using following features for training {}.\".format(feature_names))\nprint(\"\")\nprint(\"Total number of features are {}.\".format(len(feature_names)))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"33a9163a-e245-45b0-9857-87ca183005cf","_uuid":"3b6887a1dead53758930b8ed0092854f81b1f957","trusted":false},"cell_type":"code","source":"###\ny = np.log(train['price'].values + 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e1aa4667-dd2e-4e28-bdd0-7d0907d4d559","_uuid":"eb52776c4cd16d9b00a9ee431e3a80e9d374a3d1","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nXtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\ndtrain = xgb.DMatrix(Xtr, label=ytr)\ndvalid = xgb.DMatrix(Xv, label=yv)\ndtest = xgb.DMatrix(test[feature_names].values)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n\nstart = time.time()\nxgb_par = {'min_child_weight': 20, 'eta': 0.05, 'colsample_bytree': 0.5, 'max_depth': 15,\n            'subsample': 0.9, 'lambda': 2.0, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n\nmodel_1 = xgb.train(xgb_par, dtrain, 80, watchlist, early_stopping_rounds=20, maximize=False, verbose_eval=20)\nprint('Modeling RMSLE %.5f' % model_1.best_score)\nend = time.time()\nprint(\"Time taken in training is {}.\".format(end - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"16ad9357-06f6-4496-b23d-8a9ee856eb28","_uuid":"905ef50e09696dd1d5239923330a8f31072e64cd","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nstart = time.time()\nyvalid = model_1.predict(dvalid)\nytest = model_1.predict(dtest)\nend = time.time()\nprint(\"Time taken in prediction is {}.\".format(end - start))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f323a0b-d879-4532-ae93-153d216688dc","_uuid":"14bfa1b074c39af052221c29ec5ae0d933c60b04","trusted":false,"collapsed":true},"cell_type":"code","source":"###\nstart = time.time()\nif test.shape[0] == ytest.shape[0]:\n    print('Test shape OK.') \ntest['price'] = np.exp(ytest) - 1\ntest[['test_id', 'price']].to_csv('xgb_submission_mercari.csv', index=False)\nend = time.time()\nprint(\"Time taken in training is {}.\".format(end - start))","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"mimetype":"text/x-python","file_extension":".py","version":"3.6.4","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}