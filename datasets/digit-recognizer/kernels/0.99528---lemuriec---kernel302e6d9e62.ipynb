{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bcb0e3a5c00b997dc11c0c0ddde7428c085c88a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import metrics\n\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout\nfrom keras.models import Sequential\n\n\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau,LearningRateScheduler\n\nimport cv2\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e320f5f581a0b807262f8147adb36f3b3774138b"},"cell_type":"code","source":"def aug(X_train,y_train):\n    datagen = ImageDataGenerator(\n            rotation_range=10,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            rescale=1,\n            shear_range=0.1,\n            zoom_range=0.1,\n            horizontal_flip=False,\n            fill_mode='nearest')\n    training_data = []\n    label = []\n    \n    for k,l in tqdm(zip(X_train,y_train)):\n    \n        j=0\n        img = k\n        for i in datagen.flow(img.reshape((1,)+img.shape), batch_size=128):\n            if len(training_data) == 0:\n                training_data = [cv2.resize(np.array(i[0,:,:,0]),(28,28))]\n                label = [l]\n            else:\n                training_data.append(cv2.resize(np.array(i[0,:,:,0]),(28,28)))\n                label.append(l)\n            j+=1\n            if j>3:\n                break\n    training_data = np.array(training_data)\n    label = np.array(label)\n    training_data, X_test, label, y_test = train_test_split(training_data.reshape(training_data.shape[0], img_rows, img_cols, 1),label, test_size=0)\n    return training_data,label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"867180963ee54c6c82521bf59d3d422bd35953fc"},"cell_type":"code","source":"def loader(df):\n    \n    data = df.iloc[:,1:].values\n    labels = df.iloc[:,0].values\n    \n    \n    return data, labels\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c170c91b162edbb8e96aa42936c41463b12aa5ff"},"cell_type":"code","source":"def plot_digit(x_set, y_set,id):\n    plt.imshow(x_set[id].reshape(28,28), cmap='Greys',  interpolation='nearest')\n    plt.title('true label: {}'.format(y_set[id]))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4180f1182a2a369e33693ea35bb6374b4ba5639b"},"cell_type":"code","source":"#plot_digit(data, labels,4100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d762869f600acfb73e26fb543f70a58500d36abc"},"cell_type":"code","source":"data, labels =loader(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b40277066800f0fc79ae488625fdddf441e16854"},"cell_type":"code","source":"data[:41000].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32ecc3bf8057de04c653dc0575e676bc70f0e215"},"cell_type":"code","source":"#X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.01)\n\nX_train, X_test, y_train, y_test = data[:41000],data[41000:],labels[:41000],labels[41000:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"685a26e5f304614935bb5a9063a9c116d34ddc0e"},"cell_type":"code","source":"#reshaping\n#this assumes our data format\n#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n\nimg_rows = 28\nimg_cols = 28\n\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n#more reshaping\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n\n\nprint('X_train shape:', X_train.shape) #X_train shape: (60000, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aa181b12ca811b4e7c7ea17ded9a5eb37a8fca5"},"cell_type":"code","source":"'''a,b = aug(X_train,y_train)\n\n\n\n\n\nX_train = np.vstack((X_train,a))\ny_train = np.append(y_train,b)'''\n\nX_train /= 255\nX_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a87c2cbf437ad7984108459fce26739e428d668"},"cell_type":"code","source":"X_train[2].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cbbbb087dd38e3045249e5d093ab4f61d7d2380"},"cell_type":"code","source":"'''from keras.datasets import mnist\n#load mnist dataset\n(X_train1, y_train1), (X_test, y_test) = mnist.load_data()\n\nX_trai1n = X_train1.reshape(X_train1.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\ninput_shape = (img_rows, img_cols, 1)\n#more reshaping\nX_train1 = X_train1.astype('float32')\nX_test = X_test.astype('float32')\nX_train1 /= 255\nX_test /= 255\n\nX_train = np.vstack((X_train,X_train1))\ny_train = np.append(y_train,y_train1)\n\nX_train, X_test1, y_train, y_test1 = train_test_split(X_train, y_train, test_size=0)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac81f5d13cb5909b2da68865bf1829347b401fd5"},"cell_type":"code","source":"print('X_train shape:', X_train.shape)\nprint(X_train.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b47514444f345d5bd6dbf47fcbdc56b4cfb05e97"},"cell_type":"code","source":"import keras\n#set number of categories\nnum_category = 10\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_category)\ny_test = keras.utils.to_categorical(y_test, num_category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e74d77c2dde8af76cad02793ae6dfc1dbbf739a3"},"cell_type":"code","source":"img_rows=28\nimg_cols=28\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\n# Define the optimizer\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nepochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 86\n\n\n# With data augmentation to prevent overfitting (accuracy 0.99286)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n\n\n# Fit the model\nmodel_log = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])\n\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0]) #Test loss: 0.0296396646054\nprint('Test accuracy:', score[1]) #Test accuracy: 0.9904\n\n\nimport os\n# plotting the metrics\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(model_log.history['acc'])\nplt.plot(model_log.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig\n\n\n\ny_pred=model.predict(X_test.reshape(X_test.shape[0], img_rows, img_cols, 1))\ny_pred = np.array([np.argmax(i) for i in y_pred])\n\nscore = 0\n\nfor i in range(y_test.shape[0]):\n  if np.argmax(y_test[i])==y_pred[i]:\n    score+=1\nprint(score/y_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4136f5774aab31c431469c468867b62a3a4f6e64"},"cell_type":"code","source":"'''\n\nimg_rows=28\nimg_cols=28\ninput_shape = (img_rows, img_cols, 1)\n\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n\n##model building\nmodel = Sequential()\n#convolutional layer with rectified linear unit activation\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n#32 convolution filters used each of size 3x3\n#again\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n#64 convolution filters used each of size 3x3\n#choose the best features via pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#randomly turn neurons on and off to improve convergence\nmodel.add(Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nmodel.add(Flatten())\n#fully connected to get all relevant data\nmodel.add(Dense(300, activation='relu'))\n#one more dropout for convergence' sake :) \nmodel.add(Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nmodel.add(Dense(num_category, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nbatch_size = 100\nnum_epoch = 50'''\n\n#model training\n'''model_log = model.fit(X_train, y_train,\n              batch_size=batch_size,\n              epochs=num_epoch,\n              verbose=1,\n              validation_data=(X_test, y_test))'''\n\n\n\n\n'''learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nepochs = 50 # Turn epochs to 30 to get 0.9967 accuracy\nbatch_size = 100\n\n\n# With data augmentation to prevent overfitting (accuracy 0.99286)\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,\n        shear_range=0.1,# randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)\n\n\n# Fit the model\nmodel_log = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_test,y_test),\n                              verbose = 1, steps_per_epoch=X_train.shape[0] // batch_size\n                              , )\n\n\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0]) #Test loss: 0.0296396646054\nprint('Test accuracy:', score[1]) #Test accuracy: 0.9904\n\n\nimport os\n# plotting the metrics\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(model_log.history['acc'])\nplt.plot(model_log.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig\n\n\nprint(model_log.history['val_acc'])\nprint(model_log.history['acc'])\n\n\ny_pred=model.predict(X_test.reshape(X_test.shape[0], img_rows, img_cols, 1))\ny_pred = np.array([np.argmax(i) for i in y_pred])\n\nscore = 0\n\nfor i in range(y_test.shape[0]):\n  if np.argmax(y_test[i])==y_pred[i]:\n    score+=1\nprint(score/y_test.shape[0])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de61e314e4da83f015b8e598602090e90574b98f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12d01aea9c199ab25c2fb4ff3833cf677763d24a"},"cell_type":"code","source":"'''img_rows=28\nimg_cols=28\ninput_shape = (img_rows, img_cols, 1)\n\n\nX_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\nX_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n\n##model building\nmodel = Sequential()\n#convolutional layer with rectified linear unit activation\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n#32 convolution filters used each of size 3x3\n#again\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n#64 convolution filters used each of size 3x3\n#choose the best features via pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#randomly turn neurons on and off to improve convergence\nmodel.add(Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nmodel.add(Flatten())\n#fully connected to get all relevant data\nmodel.add(Dense(300, activation='relu'))\n#one more dropout for convergence' sake :) \nmodel.add(Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nmodel.add(Dense(num_category, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nbatch_size = 100\nnum_epoch = 20\n#model training\nmodel_log = model.fit(X_train, y_train,\n              batch_size=batch_size,\n              epochs=num_epoch,\n              verbose=1,\n              validation_data=(X_test, y_test))\n\nscore = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0]) #Test loss: 0.0296396646054\nprint('Test accuracy:', score[1]) #Test accuracy: 0.9904\n\n\nimport os\n# plotting the metrics\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(model_log.history['acc'])\nplt.plot(model_log.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e70d4904cadf15cc69dacb6fc45275e63a4e6f97"},"cell_type":"code","source":"'''model = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))\n\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\n# CREATE MORE IMAGES VIA DATA AUGMENTATION\ndatagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)'''\n\n'''model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size = 4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(10, activation='softmax'))\n\n    # COMPILE WITH ADAM OPTIMIZER AND CROSS ENTROPY COST\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1653ae41b7a9d9532995993623c752bb48b40b6"},"cell_type":"code","source":"'''learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\nmodel = Sequential()\n#convolutional layer with rectified linear unit activation\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\n#32 convolution filters used each of size 3x3\n#again\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\n#64 convolution filters used each of size 3x3\n#choose the best features via pooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#randomly turn neurons on and off to improve convergence\nmodel.add(Dropout(0.25))\n#flatten since too many dimensions, we only want a classification output\nmodel.add(Flatten())\n#fully connected to get all relevant data\nmodel.add(Dense(300, activation='relu'))\n#one more dropout for convergence' sake :) \nmodel.add(Dropout(0.5))\n#output a softmax to squash the matrix into output probabilities\nmodel.add(Dense(num_category, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\n\nbatch_size = 100\nnum_epoch = 100\n\ndatagen = ImageDataGenerator(\n        rotation_range=10,  \n        zoom_range = 0.10,  \n        width_shift_range=0.1, \n        height_shift_range=0.1)\n\nmodel_log = model.fit_generator(datagen.flow(X_train,y_train, batch_size=100),\n        epochs = num_epoch,   \n        validation_data = (X_test,y_test), verbose=1)'''\n\n'''model_log = model.fit(X_train, y_train,\n              batch_size=batch_size,\n              epochs=num_epoch,\n              verbose=1,\n              validation_data=(X_test, y_test))'''\n\n\n'''epochs = 70\n#X_train, X_test, Y_train, y_test = train_test_split(Data, labels, test_size = 0.1)\nmodel_log = model.fit_generator(datagen.flow(X_train,y_train, batch_size=100),\n        epochs = epochs, steps_per_epoch = X_train.shape[0]//100,  \n        validation_data = (X_test,y_test), callbacks=[annealer], verbose=1)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"697e9b00ffd40225209f0a5edb60ea4ae72a4fa7"},"cell_type":"code","source":"'''batch_size = 1000\nnum_epoch = 39\n#model training\nmodel_log = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=num_epoch,\n          verbose=1,\n          validation_data=(X_test, y_test))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facb7b85ecbb379d4e4a2afd0780d51d6196f270"},"cell_type":"code","source":"'''#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n#categorical ce since we have multiple classes (10) \nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"383a111541d242eb7a1cf2e886f9b9c1b63cca63"},"cell_type":"code","source":"'''batch_size = 10\nnum_epoch = 10\n#model training\nmodel_log = model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=num_epoch,\n          verbose=1,\n          validation_data=(X_test, y_test))'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3aa15cb99ee4f1a97001cda4d5660465263f6e0"},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0]) #Test loss: 0.0296396646054\nprint('Test accuracy:', score[1]) #Test accuracy: 0.9904\nprint(model_log.history['val_acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"296035ac5d6ddeb3b13d5947d7a5f879deefbee7"},"cell_type":"code","source":"import os\n# plotting the metrics\nfig = plt.figure()\nplt.subplot(2,1,1)\nplt.plot(model_log.history['acc'])\nplt.plot(model_log.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(model_log.history['loss'])\nplt.plot(model_log.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4543b8a8129cbf341b506b97bdc930fd930b5807"},"cell_type":"code","source":"df1 = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e5abe68dec908f5906551d749dc6132ea4e711b"},"cell_type":"code","source":"df1.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"676a3fb51842673d5db51f846f0248b93c50d6d3"},"cell_type":"code","source":"y_pred=model.predict(df1.values.reshape(df1.values.shape[0], img_rows, img_cols, 1)/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc9e3c5f90eb969ae601d0c841ff46096fa79560"},"cell_type":"code","source":"y_pred = np.array([np.argmax(i) for i in y_pred])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9831d073f1a83af6df18cbb6d85dbd79fb9e4ac1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b7e3a75d2bee72783cb1898e51e9e1c8aefe567"},"cell_type":"code","source":"y_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba6703132e823adeb1a77617e485f5a1dcb967cb"},"cell_type":"code","source":"ss= pd.read_csv(\"../input/sample_submission.csv\")\nss['Label'] = y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ecf3dcb2b0ab6adf9af75e1d48863d40cf6a003"},"cell_type":"code","source":"ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2e9857ef0beefcc5481f656561237dd26cd0827"},"cell_type":"code","source":"ss.to_csv('sample_submission.csv',sep = ',',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b2b0d0fbdb2c0d2d4dab3ef9f052e3e27430e1e"},"cell_type":"code","source":"pd.read_csv(\"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1de0b647d464e9df87c062f0656a16827b8eebcd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80af8b1b30631f0ae40daef9e0e8bd5b065b9abd"},"cell_type":"code","source":"for i in range(100):\n    plot_digit(df1.values,y_pred,i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84125df732e697de7193d5f12132289cffce61b9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8538552b8bbbdfa0633911be0c619d7cc239171c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bf8cd261c569b8db56d8e49211e43ba1a48d863"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}