{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#for data and data visualization\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly import tools\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n%matplotlib inline\n#%matplotlib inline\n#Classification models\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifierCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, BaggingClassifier, VotingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n#Data cleaning\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n#Model validation and preprocessing\nfrom sklearn.model_selection import train_test_split, cross_validate, ShuffleSplit, GridSearchCV, StratifiedShuffleSplit\nfrom sklearn.metrics import classification_report, make_scorer, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn_pandas import DataFrameMapper, gen_features\nfrom sklearn.feature_selection import SelectFromModel\n#Helpers\nimport re\nfrom datetime import datetime\nfrom scipy.stats import boxcox\nfrom collections import Counter\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = 'all'\n\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"546b2a5db117de0c6dba72e37ca7a87a5e04df72"},"cell_type":"markdown","source":"# **Import and view dataset**"},{"metadata":{"_uuid":"1fbf8be158587a57fceadcd0390b7f200e9d4383"},"cell_type":"markdown","source":"**Import the data**"},{"metadata":{"trusted":true,"_uuid":"7e3100e96480738f8885902d978db8b4ca081e67"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\nval = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d281105e3da09ef2a976e44c6f9c5841d669e4b"},"cell_type":"markdown","source":"**View the data**"},{"metadata":{"trusted":true,"_uuid":"0911f8d60d2beb17a3469e7477199baf929655a5"},"cell_type":"code","source":"'Training set'\ntrain.sample(5)\n'Test set'\nval.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa70699dba95c90406b7d0bceb56a16c247d5001"},"cell_type":"markdown","source":"**Joining the 2 datasets **"},{"metadata":{"trusted":true,"_uuid":"f5f9ceb888e072133d086afd71689bc08045bb2b"},"cell_type":"code","source":"valID = val['PassengerId'].tolist()\nfull = pd.concat([train,val],ignore_index=True,sort=False)\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28944293121478f3e312a74723077bfb529803ce"},"cell_type":"markdown","source":"# **First look at the features**"},{"metadata":{"trusted":true,"_uuid":"3afb26dd1f372f3bcfa0a8dc4cda5d0f0b3cfbd8"},"cell_type":"code","source":"features = full.drop('Survived',axis=1)\nfeatures = features[features.notnull().all(axis=1)].iloc[0].T.to_frame().reset_index()\nfeatures.columns = ['Features','Example']\nfeatures","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"113de0ac69ab5bd79c4336ae1fb28211348cfe66"},"cell_type":"markdown","source":"* PassengerId - Continous - A unique identifier to the passengers onboard the titanic. Not useful in determining the survivability.\n* Pclass - Categorical - A proxy for socio-economic status (SES)\n* Name - String - Name of the passenger with title of passenger\n* Sex - Categeorical - Gender of passenger\n* Age - Continuous - Age of passenger\n* SibSp - Continuous - Number of siblings and spouse\n* Parch - Continuous - Number of parents and children\n* Ticket - String - Ticket ID of passenger, unqiue for each passenger supposedly. Might not be useful for determining survivability.\n* Fare - Continuous - Price of ticket.\n* Cabin - String - Location of cabin on the titanic\n* Embarked - Categorical - Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)"},{"metadata":{"_uuid":"bf99569db983a69f20f097ab7b829d4a97bf989e"},"cell_type":"markdown","source":"**View number of missing data in each column**"},{"metadata":{"trusted":true,"_uuid":"5ad4d38e1cc468d2335dd763eb055dcec128e681"},"cell_type":"code","source":"missing = full.isna().sum().sort_values()\n\ndata= [go.Bar(\n    x=missing.values,\n    y=missing.index,\n    orientation='h',\n    opacity=0.8)]\n\nlayout = go.Layout(title='Missing values count in columns',\n                   autosize=False,\n                   xaxis=dict(title='Missing values count',tickangle=0,fixedrange=True),\n                   yaxis=dict(title='Feature name',fixedrange=True,tickangle=-30))\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6941e6e1dc5617a2ef429e72a9abf055a2921f75"},"cell_type":"markdown","source":"Besides survived, there are 4 other columns that would require some form of imputation. The columns are cabin, age, embarked and fare."},{"metadata":{"_uuid":"678b123a18ea9acbbb73e2fd325a63fd12e02733"},"cell_type":"markdown","source":"# **Exploring the columns**"},{"metadata":{"_uuid":"8eaca4d260d12e7b489545dc6b3baa61212140b9"},"cell_type":"markdown","source":"- **Target variable aka Survived**"},{"metadata":{"trusted":true,"_uuid":"92463adbb48095144b910bd284edf38e7ddd4cc8"},"cell_type":"code","source":"labels = ['Survived','Deceased']\nvalues = [round(train['Survived'].mean(),2),round(1-train['Survived'].mean(),2)]\npie = go.Pie(labels=labels, values=values,opacity=0.9)\nlayout = go.Layout(title='Survival rate',\n                   autosize=False)\nfig = go.Figure(data=[pie], layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"410f8fc3d93854d638adb36978394b650b134906"},"cell_type":"markdown","source":"It seems that survival rate is quite skewed, with only 38% of the passengers survival the unfortunate incident. Hence, the evaluation metric of F1 score would be more appropriate as compared to accuracy."},{"metadata":{"_uuid":"e49bb2e342f57ae9d2ddfd94255ffc349881ae20"},"cell_type":"markdown","source":"- **Passenger ID**"},{"metadata":{"_uuid":"99abc3adc2532a99324f09cb6a569e76f2c5c73c"},"cell_type":"markdown","source":"Passenger ID should be a unique identifier for the passengers and would not give valuable information for the passenger survival. Hence, it should be removed from the list of features used to train the model and predict the test set."},{"metadata":{"trusted":true,"_uuid":"d542d392b230c7fce9186386ab82cb7ff5a60c6b"},"cell_type":"code","source":"if full.shape[0] == full['PassengerId'].nunique():\n    print('PassengerID is unique.\\nColumn will be removed')\n    #full.drop('PassengerId',axis=1,inplace=True)\nelse:\n    print('PassengerId is not unique')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac07c2dc5e95dfb92395d318bc9a3620b463246f"},"cell_type":"code","source":"full.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d2a24010384393bafb4bdca8ab341b20bfeaf2d"},"cell_type":"markdown","source":"- **Pclass**"},{"metadata":{"trusted":true,"_uuid":"bc3dd33e935b843e3bbcccffeb0ebd38f81f4593"},"cell_type":"code","source":"groups = full[['Survived','Pclass']].groupby('Pclass').agg('mean')\ndata = [go.Bar(x=groups.index,\n              y=groups.values.flatten(),\n              text=[round(i,4) for i in groups.values.flatten()],\n              textposition='outside',\n              width=0.5)]\nlayout = go.Layout(autosize=False,title='Survival rate each Pclass',xaxis=dict(dtick=1))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cc203229a662dadc7abf596762c6cd367e53df8"},"cell_type":"markdown","source":"The higher classes appears to have a better chance at surviving, which could be due to those passengers have a priority at evacuation. While technically Pclass is a categorical variable, leaving it as a continuous variable could work as there is sort of a direct comparison relation between the classes."},{"metadata":{"_uuid":"2cb9a3c76523116cd197ae266365d3759b904cdf"},"cell_type":"markdown","source":"-  **Name**"},{"metadata":{"_uuid":"561df2dbaffad95e51b91a4bbe3be13ba75bafe6"},"cell_type":"markdown","source":"While name is usually a unique identifier, in this case the names contain the title of the passengers which could potentially provide information on the survival chances of the passengers."},{"metadata":{"trusted":true,"_uuid":"8578e386a54ac2c12e64f121db24a7499f803d08"},"cell_type":"code","source":"full['Title'] = full['Name'].apply(lambda name:re.findall(' ([a-zA-z]+)\\.',name)[0])\nprint('There are {} unique titles. They are as follow:'.format(full['Title'].nunique()),', '.join(full['Title'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98892935789d204b2f66796c88a9709e1a1bca13"},"cell_type":"code","source":"#Visualize counts for each title\ntitle_counts = full['Title'].value_counts()\nx = title_counts.index\ny = title_counts.values\ndata = [go.Bar(x=x, y=y, width = 0.5, marker=dict(color=y,opacity=0.6,showscale=True,colorscale='Portland'))]\nlayout = go.Layout(title='Counts per title',\n                   autosize=False,\n                   xaxis=dict(title='Title',tickangle=45,fixedrange=True),\n                   yaxis=dict(dtick=100,title='Counts',range=[0,800],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d66be0b8215b0b8f56cc3b9afbca2df0e07a55d"},"cell_type":"markdown","source":"Looking at the counts for each title, it is possible to group the titles into 4 groups.\n\n1. Miss/Mrs/Ms/Mlle/Mme\n2. Mr\n3. Master\n4. Capt/Col/Major/Dr/Rev --> Officers\n5. Lady/the Countess/Countess/Don/Sir/Jonkheer/Dona --> Royalty"},{"metadata":{"trusted":true,"_uuid":"1a7f03e170461d0c8ea0c66abeb21123ec8e0d6b"},"cell_type":"code","source":"full['Title'] = full['Title'].replace(['Capt','Col','Dr','Major','Rev'], 'Officers')\nfull['Title'] = full['Title'].replace(['Lady','the Countess','Countess','Sir','Jonkheer','Dona','Don'],'Royalty')\nfull['Title'] = full['Title'].replace(['Miss','Ms','Mlle'],'Miss')\nfull['Title'] = full['Title'].replace(['Mrs','Mme'],'Mrs')\n\n#Visualizing the surival rates of the title groups\ntitle_counts = full[['Survived','Title']].groupby('Title').agg('mean')\nx = title_counts.index\ny = title_counts.values.flatten()\ndata = [go.Bar(x=x, y=y, width = 0.5, marker=dict(color=y,opacity=0.6,showscale=True,colorscale='Portland'))]\nlayout = go.Layout(title='Counts per title',\n                   autosize=False,\n                   xaxis=dict(title='Title',tickangle=45,fixedrange=True),\n                   yaxis=dict(dtick=0.1,title='Counts',range=[0,1],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21f7b8b4bb394ed7293760929a2aaaa319935490"},"cell_type":"markdown","source":"It seems the different title groups have rather different survival rates, which indicates that the title could potentially be a good predictor of survival. Now that we got the title and have grouped them accordingly, the 'Name' feature is no longer useful and should be dropped."},{"metadata":{"trusted":true,"_uuid":"3cfa537e9ff68956a20c9086bbacc3c3465ec524"},"cell_type":"code","source":"full['Connected_Survival'] = 0\nfull['Surname'] = full['Name'].apply(lambda name:name.split(',')[0])\nfor grp, df_grp in full.groupby(['Surname','Fare']):\n    if len(df_grp) > 1:\n        for idx, row in df_grp.iterrows():\n            count = Counter(df_grp.drop(idx)['Survived'])\n            lived = count[1]\n            died = count[0]\n            passID = row['PassengerId']\n            if lived+died!=0: \n                full.loc[full['PassengerId'] == passID, 'Connected_Survival'] = (lived-died)/(lived+died)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f1c4b39682042c0517caccff10a2fa45df4600"},"cell_type":"code","source":"full.drop(['Name','Surname'],axis=1,inplace=True)\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28251c67f62765494a083de138cd8fe56a153258"},"cell_type":"markdown","source":"- **Sex**"},{"metadata":{"trusted":true,"_uuid":"f7a5acc1bdad1564732bf04e1839030ba5949aeb"},"cell_type":"code","source":"full['Sex'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d6356e36d18d363d93ad355b123e8c9d0fad05"},"cell_type":"markdown","source":"As sex is just a binary category, we could just simply transform it to 1 and 0 to allow the models to train on."},{"metadata":{"trusted":true,"_uuid":"fd68843964382ef9b0ce76994e57c41e0bfe1385"},"cell_type":"code","source":"full['Sex'] = full['Sex'].map({'male':1,'female':0})\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e24058c3087fe4c7ada1ddffc43fd7334ade297e"},"cell_type":"markdown","source":"- **Age**"},{"metadata":{"trusted":true,"_uuid":"c00e1b3df675af803ab591755ace26fbe9d934c9"},"cell_type":"code","source":"#Check for missing variable\nprint('{} missing ages'.format(full['Age'].isna().sum()))\nprint('{:.2f}% missing values in age column'.format(full['Age'].isnull().sum()*100/full.shape[0]))\n\n##Surival rate for each age group\ncm = sns.light_palette(\"blue\", as_cmap=True)\nages = train.loc[train['Age'].notna(),['Survived','Age']]\nbins = [i for i in range(0,int(max(ages['Age']))+5,5)]\nages['Age'] = pd.cut(ages['Age'],bins)\nages = ages.groupby('Age').agg(['mean','count'])\nages_styled = ages.style.background_gradient(cmap=cm,subset=[('Survived','mean')])\\\n                 .format(\"{:.4f}\",subset=[('Survived','mean')])\\\n                 .set_properties(subset=[('Survived','mean'),('Survived','count')], **{'width': '75px'})\nages_styled\n\n##Visualize survival age over age group\ndata = [go.Bar(x=bins, y=ages[('Survived','mean')].values, width = 0.9, marker=dict(opacity=0.6))]\nlayout = go.Layout(title='Survival rate for each age group',\n                   autosize=False,\n                   xaxis=dict(title='Age group',tickangle=45,fixedrange=True,dtick=5),\n                   yaxis=dict(dtick=0.1,title='Surival rate',range=[0,1],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"764418ff9522c8e976064f0f6c86b3eb068a34e3"},"cell_type":"markdown","source":"Looking at the survival rate for each age group, it does look like age does have an impact on the survival rate. Hence it would not be wise to drop it due to the large counts of missing values, but imputing the missing values would be required. However, as there is a large number of missing values, filling it with the mean or median might not be a good choice. It might be better to fill the age column using information from the other columns."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"f15dcb3fe503493d0629aaf08b2f8bd4d2b6bc22"},"cell_type":"code","source":"all_age = full[full['Age'].notna()]\ncolumns = ['Pclass','Sex','Title']\nfor col in columns:\n    groupings = all_age.groupby(col)\n    keys = groupings.groups.keys()\n    lst = [go.Box(x=groupings.get_group(key)['Age'], name='{} {}'.format(col,key)) for key in keys] \n    layout = go.Layout(title=col,\n                   autosize=False,\n                   xaxis=dict(title=col,tickangle=0,fixedrange=True),\n                   yaxis=dict(title='Age',fixedrange=True))\n    fig = go.Figure(data=lst,layout=layout)\n    py.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a93aa91007948da16369e79210872d4897b01460"},"cell_type":"markdown","source":"From the above boxplots, it seems using the 3 features would be a viable method to impute the missing ages. For a more robust impution, the median of the correspending group would be selected."},{"metadata":{"trusted":true,"_uuid":"39d7057b5951d674f86d1d8e3acde0bf1dc70d04"},"cell_type":"code","source":"full['Age'] = full.groupby(['Sex','Pclass','Title'])['Age'].transform(lambda x: x.fillna(x.median()))\nfull['Age'].fillna(full['Age'].median(),inplace=True) #In case there are still NaN\nfull['Age'] = full['Age'].apply(int) #Getting rid of the .5\nprint('Number of missing values: {}'.format(full['Age'].isna().sum()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b331a24e2a74768b3bfd6d6db40f3ba0991777c"},"cell_type":"markdown","source":"After the imputations there are no more missing ages and we can move on to the other features."},{"metadata":{"trusted":true,"_uuid":"730746f5ce6ecb54b544c170bfa6b3e732039eac"},"cell_type":"code","source":"full['Child'] = np.where(full['Age']<12,1,0)\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c2802db33a74b4dba4aab09ee8b8926ac266713"},"cell_type":"markdown","source":"- **SibSP & Parch**"},{"metadata":{"_uuid":"42385ee95d339f944eef8f38b053a7671a7476f2"},"cell_type":"markdown","source":"Since these 2 columns essentially mean the same thing, which is family size, they shall be combined."},{"metadata":{"trusted":true,"_uuid":"f473dd2d8d7269568e9af6a92f0047571e850f95"},"cell_type":"code","source":"full['FamilySize'] = full['SibSp'] + full['Parch'] + 1 #1 to include the passenger himself\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aadf669a9899484f8e48c0a2523ae14f1f10888"},"cell_type":"code","source":"#Visualizing the surival rates of the family size\nfamsize = full.loc[full['Survived'].notna(),['FamilySize','Survived']].groupby('FamilySize').agg('mean')\nx = famsize.index\ny = famsize.values.flatten()\ndata = [go.Bar(x=x, y=y, width = 0.5, marker=dict(color=y,opacity=0.6,showscale=True,colorscale='Portland'))]\nlayout = go.Layout(title='Survival rate per family Size',\n                   autosize=False,\n                   xaxis=dict(title='Family Size',dtick=1,fixedrange=True,range=[0,max(full['FamilySize'])]),\n                   yaxis=dict(dtick=0.1,title='Survival rate',range=[0,1],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5d9786f5729098ebca188a73ab88a6b30266d24"},"cell_type":"markdown","source":"The smaller family sizes seem to have a greater chance at survivor, which makes sense as they would not have to spend time looking for family members during the catastrophe which would waste valuable time."},{"metadata":{"_uuid":"c66d9438cf8c686eee51ec4f624d74240ed88812"},"cell_type":"markdown","source":"- **Ticket**"},{"metadata":{"_uuid":"b7a25cb290a129def7a2e962d083d8cf3097972f"},"cell_type":"markdown","source":"It is possible that passengers that do not travel alone, travel with friends and that might not show up up under the SipSp and Parch columns but could be detected under the ticket columns if the same ticket is bought."},{"metadata":{"trusted":true,"_uuid":"19facd612b101654ef525dd56f8357bc877d2f8a"},"cell_type":"code","source":"full['TicketSize'] = full.groupby('Ticket')['Ticket'].transform('count')\nfull[full['FamilySize']<full['TicketSize']].sort_values('Ticket').head(9)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e8abe146d020bc3331db687f952b26bc1557662"},"cell_type":"markdown","source":"These are some examples where the passenger did not travel with their family member but with someone else instead. Since the ticket is the same we can safely assume that passengers with same ticket would be travelling with each other. In that case a new column, groupsize, could be formed. "},{"metadata":{"trusted":true,"_uuid":"83fb9ecf63ad29b2dc3f03e6b305583cd17ff313"},"cell_type":"code","source":"full['GroupSize'] = full[['FamilySize','TicketSize']].max(axis=1)\nfull.sample(5)\n\n#Visualizing the surival rates of the family size\ngrpsize = full.loc[full['Survived'].notna(),['GroupSize','Survived']].groupby('GroupSize').agg('mean')\nx = grpsize.index\ny = grpsize.values.flatten()\ndata = [go.Bar(x=x, y=y, width = 0.5, marker=dict(color=y,opacity=0.6,showscale=True,colorscale='Portland'))]\nlayout = go.Layout(title='Survival rate per Group Size',\n                   autosize=False,\n                   xaxis=dict(title='Group Size',dtick=1,fixedrange=True,range=[0,max(full['FamilySize'])]),\n                   yaxis=dict(dtick=0.1,title='Survival rate',range=[0,1],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"215497af6e2cec8c40f1654784f04106ea1f51e9"},"cell_type":"markdown","source":"The barplot of surival rate looks very similar to that for family size. From the group size, a boolean column 'IsAlone' can be generated."},{"metadata":{"trusted":true,"_uuid":"fc477b431d60046c114ee337a59d751ba24a64bc"},"cell_type":"code","source":"full['IsAlone'] = np.where(full['GroupSize']==1,1,0)\nfull['SmallGroup'] = np.where((2<=full['GroupSize']) & (full['GroupSize']<=4),1,0)\nfull['LargeGroup'] = np.where(full['GroupSize']>4,1,0)\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3313b26c6dfee935752f6bebd3054f29677042f3"},"cell_type":"code","source":"#full['Connected_Survival'] = 0.5 \nfor grp, df_grp in full.groupby('Ticket'):\n    if len(df_grp) > 1:\n        for idx, row in df_grp.iterrows(): \n            if row['Connected_Survival'] != 0:\n                continue\n            count = Counter(df_grp.drop(idx)['Survived'])\n            lived = count[1]\n            died = count[0]\n            passID = row['PassengerId']\n            if lived+died!=0: \n                full.loc[full['PassengerId'] == passID, 'Connected_Survival'] = (lived-died)/(lived+died)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"348240cfe7bfbfc486c1fccce569047b081ef9ff"},"cell_type":"markdown","source":"Ticket will not be much help after this and shall be dropped."},{"metadata":{"trusted":true,"_uuid":"ae7d31f4687ca35672226521e3e72b213b1c877a"},"cell_type":"code","source":"full.drop(['Ticket','FamilySize','TicketSize','PassengerId'],axis=1,inplace=True)\nfull.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b15f2888e3e503836b29ce1c32741c0f9471f40c"},"cell_type":"markdown","source":"- **Fare**"},{"metadata":{"trusted":true,"_uuid":"cb009203bc50d21d3064e7e67307746adc507109"},"cell_type":"code","source":"#Check for missing variable\nprint('{} missing ages'.format(full['Fare'].isna().sum()))\nprint('{:.2f}% missing values in Fare column'.format(full['Fare'].isnull().sum()*100/full.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ceaec1653c5da20d224d7547eb38755f06d6d7c"},"cell_type":"markdown","source":"Since only 1 value is missing, it should be alright to just impute with the median and skip the trouble of trying to find other features to determine the missing value."},{"metadata":{"trusted":true,"_uuid":"6737f01cc0653626eec8c5ce65743cdbec8b8c97"},"cell_type":"code","source":"full['Fare'].fillna(full['Fare'].median(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"addd0cd7961055657acd77ae7ce2655cdf4670d7"},"cell_type":"code","source":"##Visualize distribution of fares\nfares = [list(full['Fare'])]\nfig = ff.create_distplot(fares, ['Fares'], show_hist=False, show_rug=False)\nfig['layout'].update(title='Fares distribution',\n                     autosize=False,\n                     yaxis=dict(range=[0,0.04],dtick=0.0025,showgrid=True),\n                     xaxis=dict(showgrid=False,title='Fares',dtick=50))\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2fac1701236bb8a9659fd2bf78a61f883b9f2bf1"},"cell_type":"markdown","source":"As the fare data is very right-skewed, it is best to perform a transformation to prevent biasness in the models."},{"metadata":{"trusted":true,"_uuid":"155097796147ed509a1ad2fb7282137729951915"},"cell_type":"code","source":"#Perform boxcox transformation\nfull['Fare'] = boxcox((1+full['Fare']))[0]\nfares = [list(full['Fare'])]\nfig = ff.create_distplot(fares, ['Fares'], show_hist=False, show_rug=False)\nfig['layout'].update(title='Fares distribution',\n                     autosize=False,\n                     yaxis=dict(showgrid=True),\n                     xaxis=dict(showgrid=False,range=[-1,6]))\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae51caebc09751b4027b65e5585814b109b0af69"},"cell_type":"markdown","source":"The distribution of the fares is clearly more 'normal' after the boxcox transformation."},{"metadata":{"trusted":true,"_uuid":"879dabc3c8581b499ff03e20233d17aec7dd323d"},"cell_type":"code","source":"full.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6cd44d7544f380f4eadba9b0c14ba08a17904f2"},"cell_type":"markdown","source":"- **Cabin**"},{"metadata":{"trusted":true,"_uuid":"5aa0f4843adf82a65c5615f925ecce3299a4a589"},"cell_type":"code","source":"full['Cabin'].unique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53b54ed1856ec3c6c56c10eaf124d82211b00cdf"},"cell_type":"markdown","source":"The pattern of the cabin is a alphabet followed by a number. Stripping out the alphabet could provide some information on the survival chances. Also it will be assumed that the NaN's would mean that the passenger is not assigned to a cabin and would be replaced with 'X'."},{"metadata":{"trusted":true,"_uuid":"bbe69456b561a9d1adb1f009864cfcf0adbe1514"},"cell_type":"code","source":"full['Cabin'].fillna('X',inplace=True)\nfull['Cabin'] = full['Cabin'].map(lambda x:x[0])\n\n#Visualizing the surival rates of each cabin\ncabins = full.loc[full['Survived'].notna(),['Cabin','Survived']].groupby('Cabin').agg('mean')\nx = cabins.index\ny = cabins.values.flatten()\ndata = [go.Bar(x=x, y=y, width = 0.5, marker=dict(color=y,opacity=0.6,showscale=True,colorscale='Portland'))]\nlayout = go.Layout(title='Survival rate for each cabin',\n                   autosize=False,\n                   xaxis=dict(title='Cabin',fixedrange=True),\n                   yaxis=dict(dtick=0.1,title='Survival rate',range=[0,1],fixedrange=True))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b64fd38e209ab22b6990be748461b814fd0d0d8"},"cell_type":"markdown","source":"It looks like those with a cabin have a better chance of survival. Within those with cabins there are some difference in survival rates too."},{"metadata":{"trusted":true,"_uuid":"c11ee38f0bdba0b51a9c1e7fd45abaf16e395777"},"cell_type":"code","source":"full.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e447ec8398aecbc3c38d0e646680d5a9ca4ac18"},"cell_type":"markdown","source":"- **Embarked**"},{"metadata":{"trusted":true,"_uuid":"f6a229fce084b4f7a2937f8ef06a34f047d7b162"},"cell_type":"code","source":"#Check for missing variable\nprint('{} missing ages'.format(full['Embarked'].isna().sum()))\nprint('{:.2f}% missing values in age column'.format(full['Embarked'].isnull().sum()*100/full.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ebdff7dadf62a6888b94b0ffc501b74b07010d3"},"cell_type":"code","source":"full['Embarked'].fillna(full['Embarked'].mode(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bedf6c6f97add1c19d6e74d567e72bdc42845b18"},"cell_type":"markdown","source":"Same as fare, due to the low number of missing values, we will skip the trouble of imputing based on other features, just that this time the mode will be imputed since embarked is a categorical variable"},{"metadata":{"_uuid":"1b8d68f4db2316a16ac42e9004f3f55aa39aa6be"},"cell_type":"markdown","source":"# **Dealing with categorical variables in the model**"},{"metadata":{"_uuid":"144907c11959a8cc489eb2d15bb7d05bcb03e3ac"},"cell_type":"markdown","source":"As there are several categorical variables in the model, we will have to encode them. The encoding method choosen is one hot encoder as the categorical variables do not have high cardinality. "},{"metadata":{"trusted":true,"_uuid":"525fc4ad905b0c32760ebf1acf27c9de26a7030d"},"cell_type":"code","source":"full = pd.get_dummies(full,columns=['Cabin','Embarked','Title'])\nfull.sample(5)\nprint('Total independent variables: {}'.format(full.shape[1]-1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8760155fa9714cac7e2b846add3da40a030b816d"},"cell_type":"markdown","source":"# **Splitting to features and target variables**"},{"metadata":{"trusted":true,"_uuid":"cd45856d9aabbbfd934924d42c4eb5a3da27cf61"},"cell_type":"code","source":"train_set = full[full['Survived'].notna()]\ntrain_features = train_set.drop('Survived',axis=1)\ntrain_target = train_set['Survived']\nval_set = full[full['Survived'].isna()].drop('Survived',axis=1)\nx_train,x_test,y_train,y_test = train_test_split(train_features,train_target,test_size=0.1,random_state=0,stratify=train_target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f718d108101760e3cd1f1ac5b9b6b369cfb5361"},"cell_type":"markdown","source":"# **Feature Selection (Not in use as full data gives better result)** "},{"metadata":{"_uuid":"e62b49ec5f2c41578606b125a6b845ec1dfb4324"},"cell_type":"markdown","source":"As there are quite a number of features, we need to try and select the more important ones. This can be done by looking at the feature importance after doing a decision tree or a random forest classification."},{"metadata":{"trusted":true,"_uuid":"2ece4870ee253c8d6bfbf1243aedf4fb0769aa92"},"cell_type":"code","source":"RFC = RandomForestClassifier(n_estimators=100, max_features='sqrt',random_state=0)\nRFC = RFC.fit(train_features, train_target)\nfeatures = pd.DataFrame(index=train_features.columns)\nfeatures['Importance'] = RFC.feature_importances_\nfeatures = features.sort_values('Importance',ascending=True)\n\n#Visualing feature importance\ndata= [go.Bar(\n    x=features.values.flatten(),\n    y=features.index,\n    orientation='h',\n    opacity=0.8)]\n\nlayout = go.Layout(title='Feature Importance',\n                   autosize=True,\n                   xaxis=dict(title='Features',tickangle=0,fixedrange=True),\n                   yaxis=dict(title='Importance',fixedrange=True,tickangle=0),\n                   margin=dict(l=120,t=0))\n\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2af1a87a5ab20c53dcab9ff455c2b03adb5006be"},"cell_type":"code","source":"##Reducing model\nmodel = SelectFromModel(RFC, prefit=True, threshold='median')\ncolumns = list(train_features.columns[model.get_support()])\n#Reduce training features\ndata = model.transform(train_features)\ntrain_features_reduced = pd.DataFrame(data,columns=columns)\n#Reduce validation features\ndata = model.transform(val_set)\nval_set_reduced = pd.DataFrame(data,columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59e0f649ef67eac413ab1ed99570d03789b97f90"},"cell_type":"markdown","source":"# **Selecting classifiers**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f3978cdb7b43e22e75d2f0da5b7609fe720013dc"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n#InteractiveShell.ast_node_interactivity = 'last_expr'\n\nclassifiers = {'LogReg': LogisticRegression(),\n               'RidgeClassifier': RidgeClassifierCV(),\n               'KNN': KNeighborsClassifier(),\n               'SVC': SVC(gamma='auto'),\n               'GaussianNB': GaussianNB(),\n               'DecisionTree': DecisionTreeClassifier(),\n               'RandomForest': RandomForestClassifier(n_estimators=100),\n               'AdaBoost': AdaBoostClassifier(n_estimators=100),\n               'GradientBoosting': GradientBoostingClassifier(n_estimators=100),\n               'ExtraTrees': ExtraTreesClassifier(n_estimators=100),\n               'BaggingClassifier': BaggingClassifier(n_estimators=100),\n               'XGB': XGBClassifier(),\n               'LDA': LinearDiscriminantAnalysis()}\n\nscoring = {'accuracy' : make_scorer(accuracy_score), \n           'f1_score' : make_scorer(f1_score)}\n\ncv_split = ShuffleSplit(n_splits=10, test_size=0.1, train_size=0.9, random_state=0)\nselection_cols = ['Classifier','Mean Train Accuracy','Mean Test Accuracy','Mean F1 train','Mean F1 Test','Prediction']#,'Train Accuracies','Test Accuracies','Train F1 Scores','Test F1 Scores'] \n\nclassifiers_summary = pd.DataFrame(columns=selection_cols)\n\nfor name,classifier in classifiers.items():\n    print('Validating ',name)\n    cv = cross_validate(classifier,train_features,train_target,return_train_score=True,cv=cv_split,scoring=scoring)\n    classifier.fit(x_train, y_train)\n    pred = classifier.predict(x_test)\n    cv_calc = [name,\n               cv['train_accuracy'].mean(),\n               cv['test_accuracy'].mean(),\n               cv['train_f1_score'].mean(),\n               cv['test_f1_score'].mean(),\n               pred\n               #cv['train_accuracy'],\n               #cv['test_accuracy'],\n               #cv['train_f1_score'],\n               #cv['test_f1_score']\n              ]\n    cv_calc_s = pd.Series(cv_calc,index=selection_cols)\n    classifiers_summary = classifiers_summary.append(cv_calc_s,ignore_index=True)\n    \nclassifiers_summary = classifiers_summary.sort_values('Mean F1 Test',ascending=False)\n\nclassifiers_summary_styled = classifiers_summary[['Classifier','Mean Train Accuracy','Mean Test Accuracy','Mean F1 train','Mean F1 Test']].style.highlight_max(axis=0).set_properties(**{'width': '150px'})\nclassifiers_summary_styled\n\n#Comparison visualization\ny = list(classifiers_summary['Classifier'].values)[::-1]\n\ntrace1 = go.Bar(\n    x=(list(classifiers_summary['Mean F1 Test'].values)[::-1]),\n    y=y,\n    name='Test',\n    marker=dict(color='red'),\n    orientation='h',\n    opacity=0.7)\n    \ntrace2 = go.Bar(\n    x=(list(classifiers_summary['Mean F1 train'].values)[::-1]),\n    y=y,\n    name='Train',\n    marker=dict(color='lightgrey'),\n    orientation='h',\n    opacity=0.8)\n\ndata = [trace1,trace2]\nlayout = go.Layout(title='Mean F1 Scores of classifiers',\n                   autosize=True,\n                   xaxis=dict(title='Mean F1 Score',tickangle=0,fixedrange=True,range=[0,0.9],dtick=0.05),\n                   yaxis=dict(fixedrange=True,tickangle=-30))\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"As the survival rate is unbalanced, the F1 score would be a scoring system than accuracy. Comparing the classifiers performance via the F1 scores shows that the LogReg performs best followed by RidgeClassifier. Both also do not show signs of overfitting too. To form an ensemble, the top 5 classifiers would be selected."},{"metadata":{"_uuid":"c1d2a9c58561c1563dac63cedb2ec9c9d7d272ea"},"cell_type":"markdown","source":"# **Hyperparameters tuning to achieve best model**"},{"metadata":{"trusted":true,"_uuid":"4b1081ce4e3f22a938e9ead1409404c56a4ffe96","scrolled":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n#InteractiveShell.ast_node_interactivity = 'last_expr'\n\nselected_classifiers = [('RidgeClassifier',RidgeClassifierCV()),\n                        ('LDA',LinearDiscriminantAnalysis()),\n                        ('LogReg',LogisticRegression()),\n                        ('GradientBoosting',GradientBoostingClassifier()),\n                        ('XGB',XGBClassifier())]\n\ngrid_param = [ #RidgeClassifier\n             [{\n              }],\n               #LDA\n            [{'solver': ['svd', 'lsqr'],\n             }],\n               #LogReg\n            [{ 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], \n               'random_state': [0], \n               'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n             }],\n               #GradientBoostingClassifier\n            [{'loss': ['deviance', 'exponential'],\n               'learning_rate':[0.1,0.05,0.001],\n               'n_estimators':[10,50,100,300],\n               'max_depth':[2,3,5,10],\n               'random_state':[0]\n             }],\n               #XGB\n            [{'learning_rate':np.arange(0.1, 0.6, 0.1),\n              'max_depth':np.arange(2, 11, 1),\n              'n_estimators':[10,50,100,300],\n              'random_state':[0]\n             }]]\n\nfor i in range(5):\n    start = datetime.now()\n    print('Now searching for {}'.format(selected_classifiers[i][1].__class__.__name__))\n    grid_search = GridSearchCV(estimator = selected_classifiers[i][1], param_grid = grid_param[i], cv = cv_split, scoring = 'f1')\n    grid_search = grid_search.fit(train_features, train_target)\n    best_parameters = grid_search.best_params_\n    selected_classifiers[i][1].set_params(**best_parameters)\n    elasped = (datetime.now() - start).total_seconds()\n    print('Best parameters found for {} is {} in {}minutes {}seconds'.format(selected_classifiers[i][1].__class__.__name__,best_parameters,int(elasped//60),elasped%60))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c7d2d71ebeabab3a3e60e9f38fa0f10c82bb805"},"cell_type":"markdown","source":"# **Ensembling Models**"},{"metadata":{"_uuid":"d9aec3af5f16b1052119d45d06d3e3d95dc90918"},"cell_type":"markdown","source":"Before ensembling, lets take a look at the correlation between the previously fitted results of the selected classifiers."},{"metadata":{"trusted":true,"_uuid":"ab2c3354cd6a4861efb94be0eb13d41f3c0a4652"},"cell_type":"code","source":"corr = classifiers_summary[['Classifier','Prediction']].head(5)\ncorr_df = pd.DataFrame()\nfor idx,row in corr.iterrows():\n    corr_df[row['Classifier']]=row['Prediction']\n\nsns.heatmap(corr_df.corr(),annot=True,cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f68c0ec55ba688cfba44719bf5c6b1c77aa48805"},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\nvotings = VotingClassifier(estimators=selected_classifiers,voting='hard',n_jobs=-1)\nhard = cross_validate(votings,train_features,train_target,cv=cv_split,scoring=scoring)\nprint('Hard voting\\nAccuracy: {}\\nF1: {}'.format(hard['test_accuracy'].mean(),hard['test_f1_score'].mean())) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb27c4d5900940eac219dc5ab5e1f233dcbfc6f2"},"cell_type":"markdown","source":"# **Submission**"},{"metadata":{"trusted":true,"_uuid":"23d6b32367f3124351be39e67114ee504997f85d"},"cell_type":"code","source":"\nvotings = votings.fit(x_train, y_train)\nval_pred = pd.Series(votings.predict(val_set), name=\"Survived\").astype(int)\nsubmission = pd.read_csv('../input/gender_submission.csv')\nresults = pd.concat([val['PassengerId'],val_pred],axis=1)\nresults.to_csv(\"titanic.csv\",index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08b6d04eb8b7db256a34d9b8b4f7cbbb93c5243b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27431c61a63c331b9c9c72ac7031393ec52a9339"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}