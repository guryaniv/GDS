{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\nimport tensorflow as tf\nfrom keras.optimizers import Adam\nfrom scipy.misc import imresize\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n%matplotlib inline\n\n\n# from subprocess import check_output\n# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"5d3bda95952fc1bcdfaf6cbcdbd21d03a426d198"},"cell_type":"markdown","source":"Data processing"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data_dir = \"../input/train/\"\nmask_dir = \"../input/train_masks/\"\nall_images_paths = os.listdir(data_dir)\n\n# pick which images we will use for testing and which for validation\ntrain_images_paths, validation_images_paths = train_test_split(all_images_paths, train_size=0.8, test_size=0.2)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eab15227c8403457cbbb39cfc042992f4711ac7","collapsed":true},"cell_type":"code","source":"def grey2rgb(img):\n    new_image = []\n    for i in range(img.shape[0]):\n        for j in range(img.shape[1]):\n            new_image.append([img[i][j]]*3)\n            \n    new_image = np.array(new_image).reshape(img.shape[0], img.shape[1], 3)\n    return new_image\n\ndef data_gen(data_dir, mask_dir,  img_paths, batch_size, dims):\n    while True:\n        index_list = np.random.choice(np.arange(len(img_paths)), batch_size)\n        batch_imgs = []\n        batch_labels = []\n        for i in index_list:\n            #img\n            org_img = load_img(data_dir + img_paths[i])\n            resized_img = imresize(org_img, dims+[3])\n            array_img = img_to_array(resized_img)/255\n            batch_imgs.append(array_img)\n            \n            #masks\n            org_mask = load_img(mask_dir + img_paths[i].split('.')[0]+'_mask.gif')\n            resized_img = imresize(org_img, dims+[3])\n            array_mask = img_to_array(resized_img)/255\n            batch_labels.append(array_mask[:,:,0])\n            \n        batch_imgs = np.array(batch_imgs)\n        batch_labels = np.array(batch_labels).reshape(-1, dims[0], dims[1], 1)\n        yield batch_imgs, batch_labels\n        \ntrain_gen = data_gen(data_dir, mask_dir, train_images_paths, 5, [128, 128])\n\nimg, msk = next(train_gen)\n\nprint(img.shape, msk.shape)\nplt.imshow(img[0])\nplt.show()\nplt.imshow(grey2rgb(msk[0]), alpha=0.5)\nplt.show()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"062e3c260d1cdf310e8a95c12feca488ce520e0d"},"cell_type":"markdown","source":"Desigining Network"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5d06f9aac6ae87a1fc8048f47fbbd97ea4ffe4a6"},"cell_type":"code","source":"def down(input_layer, filters, pool=True):\n    conv1 = Conv2D(filters, (3, 3), padding = 'same', activation = 'relu', )(input_layer)\n    residual = Conv2D(filters, (3, 3), padding = 'same', activation = 'relu', )(conv1)\n    \n    if pool:\n        max_pool = MaxPool2D()(residual)\n        return max_pool, residual\n    else:\n        return residual\n    \ndef up(input_layer, residual, filters):\n    filters = int(filters)\n    upsample = UpSampling2D()(input_layer)\n    upconv = Conv2D(filters, kernel_size = (2,2), padding = 'same')(upsample)\n    concat = Concatenate(axis=3)([residual, upconv])\n    conv1 = Conv2D(filters, (3,3), padding = 'same', activation = 'relu')(concat)\n    conv2 = Conv2D(filters, (3,3), padding = 'same', activation = 'relu')(conv1)\n    return conv2\n","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"fa2e84753706c6b22234cd81c82549fdf2bef44f"},"cell_type":"markdown","source":"Building a custom Unet"},{"metadata":{"trusted":true,"_uuid":"c9a5d35c6d68e3d348bd280a0515ab8fc706dd82","collapsed":true},"cell_type":"code","source":"filters = 64\ninput_layer = Input(shape = [128, 128, 3])\nlayers = [input_layer]\nresiduals = []\n\n#down1 from 128px input and increase filters to 64\nd1, res1 = down(input_layer, filters)\nresiduals.append(res1)\n\nfilters*=2 # double filter size for next unet operation\n\n#down2 from 64px input and increase filters to 128\nd2, res2 = down(d1, filters)\nresiduals.append(res2)\n\nfilters*=2 # double filter size for ...\n\n#down3 ... filters to 256\nd3, res3 = down(d2, filters)\nresiduals.append(res3)\n\nfilters*=2\n\n#down4 ... filters to 512\nd4, res4 = down(d3, filters)\nresiduals.append(res4)\n\nfilters*=2\n\n#down5 ... filters to 1024\nd5, res5 = down(d4, filters)\nresiduals.append(res5)\n\nfilters*=2\nd6 = down(d5, filters, pool=False)\n\n#up1 .. 512\nup1 = up(d6, residuals[-1], filters//2)\nfilters//=2\n\n#up2 .. 256\nup2 = up(up1, residuals[-2], filters//2)\nfilters//=2\n\n#up3 .. 128\nup3 = up(up2, residuals[-3], filters//2)\nfilters//=2\n\n#up4 .. 64\nup4 = up(up3, residuals[-4], filters//2)\nfilters//=2\n\n#up5 .. 128\nup5 = up(up4, residuals[-5], filters//2)\nfilters//=2\n\nout = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(up5)\n\nmodel = Model(input_layer, out)\nmodel.summary()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"37157dc0d04f1ed820b713df4416283ef64833a6"},"cell_type":"code","source":"def dice_coeff(y_true, y_pred):\n    smooth = 10**-5\n    y_true = tf.round(tf.reshape(y_true, [-1]))\n    y_pred = tf.round(tf.reshape(y_pred, [-1]))\n    \n    isct = tf.reduce_sum(y_true*y_pred)\n    \n    return 2*isct/(tf.reduce_sum(y_true)+tf.reduce_sum(y_pred))\n    ","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"171481c58ef546467abd3f392e6fa56db6481305"},"cell_type":"markdown","source":"Training model"},{"metadata":{"trusted":true,"_uuid":"be591522d584d30f823405e12f08359b99f6ad3d","collapsed":true},"cell_type":"code","source":"model.compile(optimizer = Adam(10**-4), loss='binary_crossentropy', metrics = [dice_coeff])\nmodel.fit_generator(train_gen, steps_per_epoch=100, epochs=10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}