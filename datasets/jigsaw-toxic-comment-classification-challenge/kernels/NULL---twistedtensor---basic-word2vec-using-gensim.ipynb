{"nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "f8f5ba11-3e0c-4a8f-a618-a945a73795f4", "_uuid": "0bb829041ba83074c8ca28ffacce647e689dda09", "collapsed": true}, "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "43f3aff0-5d53-42ed-a173-0871144138d5", "_uuid": "2615b707fcc527fb12460fb19d8907dc7344b926", "collapsed": true}, "execution_count": null, "source": ["import nltk\n", "import gensim\n", "import multiprocessing"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "535fba5d-c7f6-4da1-8997-3d125e014056", "_uuid": "fb8b39e2d26ae9ca4e1347fbeed12d0aff153177", "collapsed": true}, "execution_count": null, "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "596bb603-466f-41a0-b0e1-0914b9c311ff", "_uuid": "693521be22cb4214c91f82e5eff29d99d6ffa3cd", "collapsed": true}, "execution_count": null, "source": ["train.head()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "06067578-c820-4334-88dc-44139dedd5a3", "_uuid": "2a9ba16402d42162a330c0631fdaf992dee5e7e4", "collapsed": true}, "execution_count": null, "source": ["# Remove all non-letter characters and make everything lowercase.\n", "train['comment_text'] = train['comment_text'].str.replace('[^a-zA-Z]',' ').str.lower()\n", "test['comment_text'] = test['comment_text'].str.replace('[^a-zA-Z]',' ').str.lower()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "5f17de72-dac8-4249-9059-a7cdbab249e0", "_uuid": "dba250db86588a749d522bb0091d387f89bad15f", "collapsed": true}, "execution_count": null, "source": ["train['comment_text'].head(10)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "a3219361-6390-49b0-878d-72729ff7e2e4", "_uuid": "fdbe8693a46e75658761bbb2888f854d021973f8", "collapsed": true}, "execution_count": null, "source": ["# Remove stop words with regex. '\\\\b' matches any break (space or linebreak or whatever) and '|'\n", "# is an or operator. So, for example '\\\\ba\\\\b|\\\\bis\\\\b|\\\\band\\\\b' will match 'a', 'is' or 'and'.\n", "stop_re = '\\\\b'+'\\\\b|\\\\b'.join(nltk.corpus.stopwords.words('english'))+'\\\\b'\n", "train['comment_text'] = train['comment_text'].str.replace(stop_re, '')\n", "test['comment_text'] = test['comment_text'].str.replace(stop_re, '')\n", "\n", "train['comment_text'].head(10)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "ec67f8bd-daf8-4cbf-928d-88a136d023b8", "_uuid": "6d837ccf6d61f3b8e6a09292a92d5a7df7feb2b9", "collapsed": true}, "execution_count": null, "source": ["# Tokenize words\n", "train['comment_text'] = train['comment_text'].str.split()\n", "test['comment_text'] = test['comment_text'].str.split()\n", "\n", "train['comment_text'].head(10)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "a15e75b4-8a14-4dea-820d-bc2967948035", "_uuid": "430e8485b11ab2bc840b23b4377bffdde9d760fb", "collapsed": true}, "execution_count": null, "source": ["# Detect common phrases so that we may treat each one as its own word\n", "phrases = gensim.models.phrases.Phrases(train['comment_text'].tolist())\n", "phraser = gensim.models.phrases.Phraser(phrases)\n", "train_phrased = phraser[train['comment_text'].tolist()]"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "4180b8cf-e011-4076-8821-83e1a4c79be2", "_uuid": "d60df24895712516817228831bf27d3943fad6b7", "collapsed": true}, "execution_count": null, "source": ["# Gensim has support for multi-core systems\n", "multiprocessing.cpu_count()"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "f4bcb95b-7e3a-4dea-a171-2bc51b4e66e3", "_uuid": "da21a0fd5aa0188c8cac7f5e25d78b46b200287e", "collapsed": true}, "execution_count": null, "source": ["# I have no reason in mind to change the default word2vec parameters, so I will use the defaults\n", "w2v = gensim.models.word2vec.Word2Vec(sentences=train_phrased,workers=32)"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "15cf757a-3cbc-41fd-aec0-68909581f5cd", "_uuid": "1f6b069a8e93eaa58b2641baa9d1e299e9042cc5", "collapsed": true}, "execution_count": null, "source": ["w2v.save('w2v_v1')"], "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "ba273b1c-9407-42d3-893f-a5ed312b1609", "_uuid": "286ef4a861010229979bc53ba39accc0dea0acec", "collapsed": true}, "execution_count": null, "source": [], "outputs": [], "cell_type": "code"}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py"}}}