{"cells": [{"metadata": {"_uuid": "23524d93cd9426cc3c77e18159797a65170bd296", "_cell_guid": "abd8a078-fccc-43d0-a849-b74a7863daf9"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "\n", "# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n", "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n", "    assert( len(actual) == len(pred) )\n", "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n", "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n", "    totalLosses = all[:,0].sum()\n", "    giniSum = all[:,0].cumsum().sum() / totalLosses\n", "    \n", "    giniSum -= (len(actual) + 1) / 2.\n", "    return giniSum / len(actual)\n", " \n", "def gini_normalized(a, p):\n", "    return gini(a, p) / gini(a, a)\n", "\n", "def gini_lgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized(labels, preds)\n", "    return 'gini', gini_score, False\n", "\n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import os\n", "import sys\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "#folder = os.getcwd() + \"\\\\\" + \"portoseguro\\\\\"\n", "\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import LabelEncoder\n", "import lightgbm as lgb\n", "from tqdm import tqdm\n", "\n", "print('Loading data...')\n", "\n", "train = pd.read_csv('../input/train.csv')\n", "test  = pd.read_csv('../input/test.csv')\n", "\n", "print('Train shape:', train.shape)\n", "print('Test shape:', test.shape)\n", "\n", "print(train.columns)    \n", "\n", "# We drop these variables as we don't want to train on them\n", "# The other 57 columns are all numerical and can be trained on without preprocessing\n", "\n", "ids = test['id']\n", "\n", "train = train.drop(['id','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',\\\n", "                'ps_ind_13_bin','ps_car_03_cat','ps_car_05_cat'], axis=1)\n", "test = test.drop(['id','ps_ind_10_bin','ps_ind_11_bin','ps_ind_12_bin',\\\n", "                'ps_ind_13_bin','ps_car_03_cat','ps_car_05_cat'], axis=1)\n", "                \n", "\n", "print('Train shape:', train.shape)\n", "print('Test shape:', test.shape)\n", "\n", "print(\"end loading data...\")\n", "\n", "\n", "\n", "X = np.array(train.drop(['target'], axis=1))\n", "y = train['target'].values\n", "\n", "X_test = np.array(test)\n", "\n", "#Split\n", "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \\\n", "    test_size=0.1, random_state = 12)\n", "\n", "\n", "\n", "d_train = lgb.Dataset(X_train, label=y_train)\n", "d_valid = lgb.Dataset(X_valid, label=y_valid) \n", "\n", "watchlist = [d_train, d_valid]\n", "\n", "\n", "\n", "params = {\n", "    'application': 'binary',\n", "    'objective': 'binary',\n", "    'metric': 'auc',\n", "    'is_unbalance': 'true',\n", "    'boosting': 'gbdt',\n", "    'num_leaves': 30,\n", "    'feature_fraction': 0.5,\n", "    'bagging_fraction': 0.5,\n", "    'bagging_freq': 20,\n", "    'learning_rate': 0.05,\n", "    'max_depth': 15,\n", "    'verbose': 0\n", "}\n", "\n", "\n", "print('Training LGBM model...')\n", "\n", "\n", "#default num_boost_round = 200\n", "model = lgb.train(params, train_set=d_train, num_boost_round=100, valid_sets=watchlist, \\\n", "early_stopping_rounds=100, verbose_eval=10, feval=gini_lgb)\n", "\n", "\n", "print(\"End training\")"], "cell_type": "code", "outputs": [], "execution_count": 3}], "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}