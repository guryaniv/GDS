{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.1", "pygments_lexer": "ipython3", "file_extension": ".py"}}, "nbformat": 4, "cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1ef37ba30d6840dcf0dc1b00dacb4a057ce0a940", "_cell_guid": "c84323d7-f0c5-4eb0-acfa-3ea1f0551e46"}, "source": ["!pip install geopy\n", "!pip install pandas\n", "!pip install pathos\n", "!pip install xgboost\n", "!pip install azure-storage\n", "!pip install reverse_geocoder\n", "!pip install -U scikit-learn"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6998a53c66230d911891fef7d02c0252c324351a", "_cell_guid": "b5f56167-fdd7-4059-b2de-7284b8591819"}, "source": ["import pandas as pd\n", "from azure.storage.file import FileService\n", "import os\n", "\n", "account_name = ''\n", "account_key = ''\n", "file_service = FileService(account_name=account_name, account_key=account_key)\n", "def get_train_data():\n", "    file_service.get_file_to_path('data', None, 'train.csv', 'train.csv')\n", "def get_test_data():\n", "    file_service.get_file_to_path('data', None, 'test.csv', 'test.csv')\n", "\n", "if not os.path.exists('train.csv'):\n", "    get_train_data()\n", "if not os.path.exists('test.csv'):\n", "    get_test_data()\n", "dataframe = pd.read_csv('train.csv', index_col=0)\n", "test_dataframe = pd.read_csv('test.csv', index_col=0)\n", "print dataframe.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b19f62b7ce17a1f1d5ea548e6c5c74df2b281a95", "_cell_guid": "76aa8b53-3070-48b1-b68d-f203f55327bc"}, "source": ["from geopy.distance import great_circle\n", "from dateutil.parser import parse\n", "import time\n", "from pathos.multiprocessing import ProcessingPool as Pool\n", "from pathos.multiprocessing import cpu_count\n", "import numpy as np\n", "\n", "# def get_borough(lat, lng, retries=3):\n", "#     if retries <= -1: return None\n", "#     try:\n", "#         geolocator = Nominatim()\n", "#         location = geolocator.reverse('{}, {}'.format(lat, lng))\n", "#         return location.address.split(', ')[2]\n", "#     except Exception as e:\n", "#         print 'Too many requests. Waiting for 2 mins for {}, {}'.format(lat, lng)\n", "#         time.sleep(30)\n", "#         return get_borough(lat, lng, retries-1)\n", "        \n", "def transform_df(df, great_circle=great_circle, parse=parse, np=np):\n", "    yes_func = lambda x: 1 if x == 'Y' else 0\n", "    df['distance'] = df.apply(lambda row : great_circle((row['pickup_latitude'], row['pickup_longitude']), \n", "                                                        (row['dropoff_latitude'], row['dropoff_longitude'])).miles, axis=1)\n", "                              \n", "    df['month'] = df.apply(lambda row: parse(row['pickup_datetime']).month, axis=1)\n", "    df['day'] = df.apply(lambda row: parse(row['pickup_datetime']).weekday(), axis=1)\n", "    df['pickup_hour'] = df.apply(lambda row: parse(row['pickup_datetime']).hour, axis=1)\n", "    df['store_and_fwd_flag'] = df.apply(lambda row: yes_func(row['store_and_fwd_flag']), axis=1)\n", "    return df\n", "\n", "def parallelize_dataframe(df, func, num_cores, num_partitions):\n", "    df_split = np.array_split(df, num_partitions)\n", "    pool = Pool(num_cores)\n", "    df = pd.concat(pool.map(func, df_split))\n", "    pool.clear()\n", "    return df\n", "\n", "new_df = parallelize_dataframe(dataframe, transform_df, cpu_count(), cpu_count())\n", "new_df['trip_duration'] = new_df.apply(lambda row: np.log1p(row['trip_duration']), axis=1)\n", "print new_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ce61c0f081e31d175246e0eb7b0f286b7b6749ec", "_cell_guid": "3447d228-68a6-4e17-87d6-6bac914dc342"}, "source": ["import reverse_geocoder as rg\n", "from sklearn import preprocessing\n", "\n", "# def get_borough_rev_geocoder(lat, lng):\n", "#     return rg.search((lat, lng))[0]['name']\n", "# dataframe['pickup_borough'] = dataframe.apply(lambda row: \n", "#                                               get_borough_rev_geocoder(row['pickup_latitude'], row['pickup_longitude']), axis=1)\n", "def get_coords(df, lat_key, long_key):\n", "    lats = df[lat_key].values.tolist()\n", "    longs = df[long_key].values.tolist()\n", "    coords = zip(lats, longs)\n", "    return coords\n", "def encode_labels(labels):\n", "    le = preprocessing.LabelEncoder()\n", "    le.fit(labels)\n", "    return le\n", "def add_borough(df):\n", "    pickup_coords = get_coords(df, 'pickup_latitude', 'pickup_longitude')\n", "    dropoff_coords = get_coords(df, 'dropoff_latitude', 'dropoff_longitude')\n", "    pickup_boroughs = np.array([d['admin2'] for d in rg.search(pickup_coords)])\n", "    dropoff_boroughs = np.array([d['admin2'] for d in rg.search(dropoff_coords)])\n", "    df['pickup_borough'] = encode_labels(pickup_boroughs).transform(pickup_boroughs)\n", "    df['dropoff_borough'] = encode_labels(dropoff_boroughs).transform(dropoff_boroughs)\n", "    return df\n", "new_df = add_borough(new_df)\n", "print new_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7b9cb0aa247b2938a230db9d5df0e16498d5821e", "_cell_guid": "9fd45b23-c6c9-4049-99e6-544a128eac93"}, "source": ["features = ['vendor_id', 'month', 'day', 'pickup_hour', 'store_and_fwd_flag', 'distance', 'pickup_borough', 'dropoff_borough']\n", "def scale_df(df, test=False):\n", "    if test:\n", "        customized_df = df[features]\n", "        x = customized_df.values #returns a numpy array\n", "    else:\n", "        customized_df = df[features + ['trip_duration']]\n", "        x = customized_df.values[:,:-1] #returns a numpy array\n", "        \n", "\n", "    min_max_scaler = preprocessing.MinMaxScaler()\n", "    x_scaled = min_max_scaler.fit_transform(x)\n", "    if not test:\n", "        trip_duration_col = np.array([customized_df['trip_duration'].values])\n", "        x_scaled = np.concatenate((x_scaled, trip_duration_col.T), 1)\n", "    scaled_df = pd.DataFrame(x_scaled, columns=customized_df.columns)\n", "    return scaled_df\n", "scaled_df = scale_df(new_df)\n", "print scaled_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "271705276523b4ecdfb55d9d76582451b76d98a8", "_cell_guid": "3b2cd22c-02fc-4351-99d0-0377c9d797de"}, "source": ["from sklearn.ensemble import GradientBoostingRegressor\n", "from xgboost.sklearn import XGBRegressor\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import make_scorer\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.model_selection import cross_val_score\n", "\n", "def rlmse_func(predicted, actual):\n", "    return np.sqrt(np.mean(np.square(np.log(predicted+1.0) - np.log(actual+1.0))))\n", "\n", "rlmse = make_scorer(rlmse_func, greater_is_better=False)\n", "\n", "# param_grid = {'learning_rate': [0.1, 0.05, 0.02, 0.01, 0.3],\n", "#               'max_depth': range(4, 7),\n", "#               'subsample': [0.8, 1],\n", "#               'n_estimators': [1000, 2000]\n", "#               }\n", "\n", "X_train, y_train = scaled_df[features].values, scaled_df[['trip_duration']].values\n", "xgb_model = XGBRegressor(objective='reg:linear', max_depth=7, learning_rate=0.3, n_estimators=2000, nthread=-1)\n", "print -1.0*cross_val_score(xgb_model, X_train, y_train.ravel(), scoring=rlmse, cv=10, verbose=8).mean()\n", "\n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b4d5000e8a385985dc8311b440a7fc5216ed3661", "_cell_guid": "d735b6dd-1cc5-46eb-9953-59963d0d3e7b"}, "source": ["test_df = parallelize_dataframe(test_dataframe, transform_df, cpu_count(), cpu_count())\n", "new_test_df = scale_df(add_borough(test_df), test=True)\n", "print new_test_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "791ecfa50a7b193b7429cea335c14fa9d5b19e47", "_cell_guid": "30c21cec-c2f9-4e1d-84f1-483a41317521"}, "source": ["xgb_model = XGBRegressor(objective='reg:linear', max_depth=7, learning_rate=0.3, reg_lambda = 1.5, n_estimators=2000, nthread=-1)\n", "xgb_model.fit(X_train, y_train)\n", "predictions = xgb_model.predict(new_test_df.values)\n", "print predictions"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4b7edafbdc369d64c98c6b891e048e3993d64861", "_cell_guid": "fd406677-80e2-4261-ba7f-a67a29a581b2"}, "source": ["test_trip_duration = np.expm1(abs(predictions))\n", "result_df = pd.DataFrame({'id': test_dataframe.index.values, 'trip_duration': test_trip_duration})\n", "result_df.to_csv('answer.csv', index=False)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d2558d51c69e9b1b7d8be6c33b3028d3a28b4b18", "_cell_guid": "a62a0497-7519-4a33-9998-092aac37ffeb", "collapsed": true}, "source": []}], "nbformat_minor": 2}