{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# numpy and pandas for data manipulation\nimport numpy as np\nimport pandas as pd \n\n# sklearn preprocessing for dealing with categorical variables\nfrom sklearn.preprocessing import LabelEncoder\n\n# File system manangement\nimport os\n\n# Suppress warnings \nimport warnings\nwarnings.filterwarnings('ignore')\n\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# print out files\nprint(os.listdir(\"../input/\"))\n\n# training data\n\ntraindata = pd.read_csv('../input/train_V2.csv')\ntraindata.head()\n\n# testing data\n\ntestdata = pd.read_csv('../input/test_V2.csv')\ntestdata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c9223ec99e4a1d0f3b1bf41011053fa84092dae"},"cell_type":"code","source":"def missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b60ab6db0d449d75aa866d2a6503d167df706cd"},"cell_type":"code","source":"missing_values = missing_values_table(traindata)\nmissing_values\n\ntraindata[traindata['winPlacePerc'].isnull()]\ntraindata.drop(2744604, inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adcb8e01004ecf84a6bef597efa9c7d9d9e687c4"},"cell_type":"code","source":"traindata = pd.get_dummies(traindata, columns = ['matchType'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90c736fbd53d5573e0c7c629a5698031f3ce3444"},"cell_type":"code","source":"matchType_encoding = traindata.filter(regex='matchType')\nmatchType_encoding.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f92d549fe70fa32c30b053e4214405d535a5cbef"},"cell_type":"code","source":"# Turn groupId and match Id into categorical types\ntraindata['groupId'] = traindata['groupId'].astype('category')\ntraindata['matchId'] = traindata['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntraindata['groupId_cat'] = traindata['groupId'].cat.codes\ntraindata['matchId_cat'] = traindata['matchId'].cat.codes\n\n# Get rid of old columns\ntraindata.drop(columns=['groupId', 'matchId'], inplace=True)\n\n# Lets take a look at our newly created features\ntraindata[['groupId_cat', 'matchId_cat']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd7e7b146cd7a5708b927662a802cee39c43c1a"},"cell_type":"code","source":"traindata.drop(columns = ['Id'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5f248b3dc4fd6099228e469465ec9a6ede6a7be"},"cell_type":"code","source":"traindata['totalDistance'] = traindata['walkDistance'] + traindata['rideDistance'] + traindata['swimDistance']\ntraindata['headshotRate'] = traindata['headshotKills']/traindata['kills']\ntraindata['headshotRate'] = traindata['headshotRate'].fillna(0)\ntraindata['playersJoined'] = traindata.groupby('matchId_cat')['matchId_cat'].transform('count')\n\n# Create normalized features\ntraindata['killsNorm'] = traindata['kills']*((100-traindata['playersJoined'])/100 + 1)\ntraindata['damageDealtNorm'] = traindata['damageDealt']*((100-traindata['playersJoined'])/100 + 1)\ntraindata['maxPlaceNorm'] = traindata['maxPlace']*((100-traindata['playersJoined'])/100 + 1)\ntraindata['matchDurationNorm'] = traindata['matchDuration']*((100-traindata['playersJoined'])/100 + 1)\ntraindata['healsandboosts'] = traindata['heals'] + traindata['boosts']\ntraindata['killsWithoutMoving'] = ((traindata['kills'] > 0) & (traindata['totalDistance'] == 0))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4d1422ac31402ac4d973cc4bbe4a2cd695012ef"},"cell_type":"code","source":"# Check players who kills without moving\ndisplay(traindata[traindata['killsWithoutMoving'] == True].shape)\ntraindata[traindata['killsWithoutMoving'] == True].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79ec8b972af5863d759a582ffef2720e63bb92a8"},"cell_type":"code","source":"# Remove outliers\ntraindata.drop(traindata[traindata['killsWithoutMoving'] == True].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b860d2c8b30a08c0b980542e6a1548819151220e"},"cell_type":"code","source":"# Drop roadKill 'cheaters'\ntraindata.drop(traindata[traindata['roadKills'] > 10].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913227f31f59a5faded783d6a6be49ebbd8b710d"},"cell_type":"code","source":"# Remove outliers\ntraindata.drop(traindata[traindata['kills'] > 30].index, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb8bc91f5bb326a4a3540821ab8830600f8de1d"},"cell_type":"code","source":"# Remove outliers\ntraindata.drop(traindata[traindata['longestKill'] >= 1000].index, inplace=True)\ntraindata.drop(traindata[traindata['walkDistance'] >= 10000].index, inplace=True)\ntraindata.drop(traindata[traindata['rideDistance'] >= 20000].index, inplace=True)\n# Remove outliers\ntraindata.drop(traindata[traindata['swimDistance'] >= 2000].index, inplace=True)\ntraindata.drop(traindata[traindata['weaponsAcquired'] >= 80].index, inplace=True)\n# Remove outliers\ntraindata.drop(traindata[traindata['heals'] >= 40].index, inplace=True)               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd1cbc03f2a7f4194bf4b186ea90f32ea8e13dcc"},"cell_type":"code","source":"sample = 500000\ndf_sample = traindata.sample(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"262da7661916613169c8c0b1d532c97bac645711"},"cell_type":"code","source":"# Split sample into training data and target variable\ndf = df_sample.drop(columns = ['winPlacePerc']) #all columns except target\ny = df_sample['winPlacePerc'] # Only target variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38facceb1ff436f034b7d2859f5b7c737dbcdbcf"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.12, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c33784fab6239c6abe96e45a9dc4b4af25aa07b"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Function to print the MAE (Mean Absolute Error) score\n# This is the metric used by Kaggle in this competition\ndef print_score(m : RandomForestRegressor):\n    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n           'mae val: ', mean_absolute_error(m.predict(X_test), y_test)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73292453a0764f5ff53a3c8264a758271969ab4f"},"cell_type":"code","source":"m1 = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features='sqrt',\n                          n_jobs=-1)\nm1.fit(X_train, y_train)\nprint_score(m1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d586894505fa87d829f728ae5b9a4096503c166"},"cell_type":"code","source":"# provides a way to analyze feature importance \n#takes in a model and a dataframe and pulls the importances and make them into a seperate table \ndef rf_feat_importance(m, df):\n    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n                       ).sort_values('imp', ascending=False)\n\n\nfi = rf_feat_importance(m1, df); fi[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c289fc4a1c95e6965df9be93da81d5709400ca2"},"cell_type":"code","source":"to_keep = fi[fi.imp>0.005].cols\nprint('Significant features: ', len(to_keep))\nto_keep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e88b550e5dc6a742acb946b0a577ca61cfa98b1"},"cell_type":"code","source":"df_keep = df[to_keep].copy()\nX_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.12, random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c8f626718a2493306d9f0bec186eb0e6f9a4391"},"cell_type":"code","source":"m2 = RandomForestRegressor(n_estimators=80, min_samples_leaf=3, max_features='sqrt',\n                          n_jobs=-1)\nm2.fit(X_train, y_train)\nprint_score(m2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9abae6457c72c8f11d526ec5c52578462c98adfc"},"cell_type":"code","source":"from sklearn import metrics\nfrom scipy.cluster import hierarchy as hc\nfrom fastai.imports import *\n\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(14,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d825ad353eef630dc2198c978fb3319fcbcb4aa1"},"cell_type":"code","source":"# Prepare data\nval_perc_full = 0.12 # % to use for validation set\nn_valid_full = int(val_perc_full * len(traindata)) \nn_trn_full = len(traindata)-n_valid_full\ndf_full = traindata.drop(columns = ['winPlacePerc']) # all columns except target\ny = traindata['winPlacePerc'] # target variable\ndf_full = df_full[to_keep] # Keep only relevant features\nX_train, X_test, y_train, y_test = train_test_split(df_full, y, test_size=0.12, random_state=42)\n\n# Check dimensions of data\nprint('Sample train shape: ', X_train.shape, \n      'Sample target shape: ', y_train.shape, \n      'Sample validation shape: ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71e7d0d3960cb7014fb186e51fcc66d688061545"},"cell_type":"code","source":"m3 = RandomForestRegressor(n_estimators=70, min_samples_leaf=3, max_features=0.5,\n                          n_jobs=-1)\nm3.fit(X_train, y_train)\nprint_score(m3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05ba92d3eff6f108a3dbbdf4c1f587705740698d"},"cell_type":"code","source":"# Add engineered features to the testdata set\ntestdata['totalDistance'] = testdata['walkDistance'] + testdata['rideDistance'] + testdata['swimDistance']\ntestdata['headshotRate'] = testdata['headshotKills']/testdata['kills']\ntestdata['headshotRate'] = testdata['headshotRate'].fillna(0)\ntestdata['playersJoined'] = testdata.groupby('matchId')['matchId'].transform('count')\n\n# Create normalized features\ntestdata['killsNorm'] = testdata['kills']*((100-testdata['playersJoined'])/100 + 1)\ntestdata['damageDealtNorm'] = testdata['damageDealt']*((100-testdata['playersJoined'])/100 + 1)\ntestdata['maxPlaceNorm'] = testdata['maxPlace']*((100-testdata['playersJoined'])/100 + 1)\ntestdata['matchDurationNorm'] = testdata['matchDuration']*((100-testdata['playersJoined'])/100 + 1)\ntestdata['healsandboosts'] = testdata['heals'] + testdata['boosts']\n\ntestdata['killsWithoutMoving'] = ((testdata['kills'] > 0) & (testdata['totalDistance'] == 0))\n\n\n# Turn groupId and match Id into categorical types\ntestdata['groupId'] = testdata['groupId'].astype('category')\ntestdata['matchId'] = testdata['matchId'].astype('category')\n\n# Get category coding for groupId and matchID\ntestdata['groupId_cat'] = testdata['groupId'].cat.codes\ntestdata['matchId_cat'] = testdata['matchId'].cat.codes\n\n# Remove irrelevant features from the testdata set\ntest_pred = testdata[to_keep].copy()\n\n# Fill NaN with 0 (temporary)\ntest_pred.fillna(0, inplace=True)\ntest_pred.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e75ed522f6791a57aab58093c5bac6ac64813075"},"cell_type":"code","source":"# Make submission ready for Kaggle\n# We use our final Random Forest model (m3) to get the predictions\npredictions = np.clip(a = m3.predict(test_pred), a_min = 0.0, a_max = 1.0)\npred_df = pd.DataFrame({'Id' : testdata['Id'], 'winPlacePerc' : predictions})\n\n# Create submission file\npred_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}