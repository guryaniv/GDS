{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16336776-a51a-210a-3235-318d01412b23"
      },
      "source": [
        "Forked from Jason Liu and RVK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e6899454-4a9b-7ef8-e2a9-c542a867e571"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cb9ed0f2-dc95-e025-0eb8-3dd3a26614ee"
      },
      "outputs": [],
      "source": [
        "matplotlib.rcParams[\"figure.figsize\"] = \"8, 8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a116041-340d-026f-6c8d-5edc35f4f8cf"
      },
      "outputs": [],
      "source": [
        "NewsComb = pd.read_csv('../input/Combined_News_DJIA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d643dbf9-8824-16b4-1943-62161f02738b"
      },
      "outputs": [],
      "source": [
        "NewsComb.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff41a3d8-e189-d705-9ce3-c596537d4138"
      },
      "outputs": [],
      "source": [
        "NewsComb.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f6a662b-fa22-a2ed-8f41-98571ce43426"
      },
      "outputs": [],
      "source": [
        "NewsComb['Combined']=NewsComb.iloc[:,2:27].apply(lambda row: ''.join(str(row.values)),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e0390af-aed2-6f64-d9da-c7493a171ffc"
      },
      "outputs": [],
      "source": [
        "non_down = NewsComb[NewsComb['Label']==1]\n",
        "down = NewsComb[NewsComb['Label']==0]\n",
        "print(len(non_down)/len(NewsComb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "facf1163-e922-b62d-6d36-10ad6efc7ea4"
      },
      "outputs": [],
      "source": [
        "def to_words(content):\n",
        "    letters = re.sub(\"[^a-zA-Z]\",\" \", content)\n",
        "    words = letters.lower().split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    mwords = [w for w in words if not w in stops]\n",
        "    return(\" \".join( mwords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "100237a5-cd16-ce6e-a322-3946a1d61288"
      },
      "outputs": [],
      "source": [
        "non_down_word = []\n",
        "down_word = []\n",
        "for word in non_down['Combined']:\n",
        "    non_down_word.append(to_words(word))\n",
        "\n",
        "for word in down['Combined']:\n",
        "    down_word.append(to_words(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26baca71-75c2-4c36-18c6-20d00233df6e"
      },
      "outputs": [],
      "source": [
        "down_word[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53151310-0a1a-db5a-763c-921d9011abe5"
      },
      "outputs": [],
      "source": [
        "wordcloud_down = WordCloud(background_color='black',\n",
        "                          width=3000,\n",
        "                          height=2500\n",
        "                          ).generate(down_word[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17e75951-8168-6268-1355-c67c11758f29"
      },
      "outputs": [],
      "source": [
        "plt.figure(1,figsize=(8,8))\n",
        "plt.imshow(wordcloud_down)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5e1c5664-0549-6c10-ac87-73f8c5ef358e"
      },
      "outputs": [],
      "source": [
        "wordcloud_non = WordCloud(background_color='white',\n",
        "                         width=3000,\n",
        "                         height=2500\n",
        "                         ).generate(non_down_word[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98fe3da8-27ac-3844-85f1-34302f6a838c"
      },
      "outputs": [],
      "source": [
        "plt.figure(1,figsize=(8,8))\n",
        "plt.imshow(wordcloud_non)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8beff271-6115-a7c2-3440-2f7c61375c1e"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from stop_words import get_stop_words\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from gensim import corpora, models\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02d7f65d-f60f-e207-f790-b3e55f4925df"
      },
      "outputs": [],
      "source": [
        "mix = []\n",
        "for row in range(0,len(NewsComb.index)):\n",
        "    mix.append(' '.join(str(x) for x in NewsComb.iloc[row,2:27]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb493320-666b-27f1-5698-f5a29056202c"
      },
      "outputs": [],
      "source": [
        "mix[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1bceca0e-ef25-7df0-054f-23ca79707ad5"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "en_stop = get_stop_words('en')\n",
        "ps = PorterStemmer()\n",
        "\n",
        "texts = []\n",
        "\n",
        "for item in mix:\n",
        "    raw = item.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "    \n",
        "    stopped_tokens = [item for item in tokens if not item in en_stop]\n",
        "    stemmed_tokens = [ps.stem(item) for item in stopped_tokens]\n",
        "    \n",
        "    texts.append(stemmed_tokens)\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd63660c-44dc-f9b9-ef77-e06472ef0033"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "lda = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word=dictionary,passes=1,\n",
        "                                     chunksize=10000,update_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f1f1f94-300c-4fd7-0c92-386b71a61a27"
      },
      "outputs": [],
      "source": [
        "%time\n",
        "import pyLDAvis.gensim\n",
        "\n",
        "print(lda.print_topics(num_topics=10,num_words=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "762751a2-759b-469d-a686-9eefe3ef3530"
      },
      "outputs": [],
      "source": [
        "lda.print_topics(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "453ecbc9-a917-c908-0491-0e3cb7acdc9d"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.enable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a56ddada-0322-c12f-72ed-366f382a2f85"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.gensim.prepare(lda, corpus, dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1166e938-a3f9-6d84-3ea3-8650517e18b4"
      },
      "outputs": [],
      "source": [
        "mix_down = []\n",
        "for row in range(0,len(down.index)):\n",
        "    mix_down.append(' '.join(str(x) for x in down.iloc[row,2:27]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd34aab9-3d9f-9d47-6526-cea2523d34e2"
      },
      "outputs": [],
      "source": [
        "texts_down = []\n",
        "\n",
        "for item in mix_down:\n",
        "    raw = item.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "    \n",
        "    stopped_tokens = [item for item in tokens if not item in en_stop]\n",
        "    stemmed_tokens = [ps.stem(item) for item in stopped_tokens]\n",
        "    \n",
        "    texts_down.append(stemmed_tokens)\n",
        "\n",
        "dictionary_down = corpora.Dictionary(texts_down)\n",
        "corpus_down = [dictionary_down.doc2bow(text) for text in texts_down]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8078d68f-8670-c935-6b44-b0b463c7b4b9"
      },
      "outputs": [],
      "source": [
        "lda_down = gensim.models.ldamodel.LdaModel(corpus_down, num_topics=10, id2word=dictionary_down,passes=1,\n",
        "                                     chunksize=10000,update_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba726088-a099-7dc8-214a-b1554a666f3f"
      },
      "outputs": [],
      "source": [
        "print(lda_down.print_topics(num_topics=10,num_words=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15e04789-b277-0dc5-df89-eb93b3014edd"
      },
      "outputs": [],
      "source": [
        "lda_down.print_topics(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "630eef61-c51d-2fc8-d511-99eca26665db"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.gensim.prepare(lda_down, corpus_down, dictionary_down)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3ead649-e7cc-e983-84c0-69dd77fb833b"
      },
      "outputs": [],
      "source": [
        "mix_non_down = []\n",
        "for row in range(0,len(non_down.index)):\n",
        "    mix_non_down.append(' '.join(str(x) for x in non_down.iloc[row,2:27]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c062f97-7e99-6765-7232-d8b8af90f751"
      },
      "outputs": [],
      "source": [
        "texts_non_down = []\n",
        "\n",
        "for item in mix_non_down:\n",
        "    raw = item.lower()\n",
        "    tokens = tokenizer.tokenize(raw)\n",
        "    \n",
        "    stopped_tokens = [item for item in tokens if not item in en_stop]\n",
        "    stemmed_tokens = [ps.stem(item) for item in stopped_tokens]\n",
        "    \n",
        "    texts_non_down.append(stemmed_tokens)\n",
        "\n",
        "dictionary_non_down = corpora.Dictionary(texts_non_down)\n",
        "corpus_non_down = [dictionary_non_down.doc2bow(text) for text in texts_non_down]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44789618-6941-ae0a-69c7-6ed20a6267f0"
      },
      "outputs": [],
      "source": [
        "lda_non_down = gensim.models.ldamodel.LdaModel(corpus_non_down, num_topics=10, id2word=dictionary_non_down,\n",
        "                                               passes=1, chunksize=10000,update_every=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53a4719b-5658-ab7d-1565-a323501060ab"
      },
      "outputs": [],
      "source": [
        "print(lda_non_down.print_topics(num_topics=10,num_words=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ce68481d-eb2d-c5cc-bb2f-48be189a7450"
      },
      "outputs": [],
      "source": [
        "lda_non_down.print_topics(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fa275d9-7dd8-b2a8-062e-a0ea5189b25d"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.gensim.prepare(lda_non_down, corpus_non_down, dictionary_non_down)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e711bdc2-a09e-9054-5f62-73d48b184cd0"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}