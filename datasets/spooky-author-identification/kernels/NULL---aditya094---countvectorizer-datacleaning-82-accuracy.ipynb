{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom nltk.corpus import stopwords # for stopwords\nimport string \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":70,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7ef53f24be0c8afc07bcfc23f7c9c1cd2251f162"},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/test.csv\") ","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d21bf44961420db6fc81e9189ec8b9958a83ca68","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"065f2e505a3276630039274c2e46915f7a23d51e","collapsed":true},"cell_type":"code","source":"train_data[\"author\"].unique()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"232f6a322617a53c1ffc0a4185da297decb578db","collapsed":true},"cell_type":"code","source":"train_data[\"author\"].value_counts()","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fbd177eaa8181bf9359cadc810f6ff913673ede1"},"cell_type":"code","source":"# we don't need id for now, id has no effect on output\ntrain_data.drop( \"id\" , axis=1 , inplace = True)","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d24b0d6bedaf021145eef018d12a666fc2d750a","collapsed":true},"cell_type":"code","source":"# Let's seperate the documents and output(author name) \n\ntrain_document = train_data[\"text\"]\ntrain_authors = train_data[\"author\"]\n\n#for testing data\n\ntest_document = test_data[\"text\"]\n\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d99287d362c5fb3286e52c17f49c36958756428b","collapsed":true},"cell_type":"code","source":"#Let's create stopword list \n\nstopword_list = stopwords.words('english')\nstopword_list[0:5]","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa73a9da0a448a2400ac52ae70523cd964942a54","collapsed":true},"cell_type":"code","source":"#let's create new list of punctuation which should be removed from documents\n\npunct = list(string.punctuation)\npunct[0:5]","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8017e0c1e25bd6bc3235a7264b8461667861c5d4"},"cell_type":"code","source":"stopword_list = stopword_list + punct","execution_count":34,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"40002adde6e551e6a47c01e439c5b8408cc166d4"},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer #for converting documents into matrix form\nfrom sklearn.model_selection import train_test_split # for splitting the training data","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8caee2f41fe78be4ade8d7725ff2fd85dfbb32de"},"cell_type":"code","source":"# Let's split the training data into train and test data\nx_train , x_test , y_train , y_test = train_test_split ( train_document , train_authors)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d073f698d6dda252e815b272eb4aae6a3ce6c82","collapsed":true},"cell_type":"code","source":"cv = CountVectorizer(stop_words = stopword_list)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4415aa9c94ecffb6861607ea4c9a561d300288a","collapsed":true},"cell_type":"code","source":"xtrain = cv.fit_transform( x_train ) # train the model and find features using training data","execution_count":48,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33b69f66312df0f460d76222e4ff77416dc945b8","collapsed":true},"cell_type":"code","source":"xtest = cv.transform( x_test )","execution_count":49,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe6232387ca2e1a256e018e7a94b1a90e43025e4","collapsed":true},"cell_type":"code","source":"#Let's import classifiers \nfrom sklearn.naive_bayes import MultinomialNB ","execution_count":54,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96d3a7d178f9e1ff3b1b5dda08c58e97b74fcbbb"},"cell_type":"code","source":"clf = MultinomialNB()","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"158e23a3764a3d468d9a0b0872366b53be44eb42","collapsed":true},"cell_type":"code","source":"clf.fit(xtrain,y_train)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5558baeeb8077b5d8aebc01837102f2138b61b21","collapsed":true},"cell_type":"code","source":"clf.score(xtest , y_test)","execution_count":59,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aeaba8fe0441e7d468fc61a76b129a3b56d4ef58"},"cell_type":"code","source":"# a gud accuracy we found using multinomial naive bayes","execution_count":60,"outputs":[]},{"metadata":{"_uuid":"08f9b7ebb1955db5aa27da80d60e8a2efecf4921"},"cell_type":"markdown","source":"Now let's predict the actual test data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6de07914cfa8855dd8fc98a12878e6ecbdad4107"},"cell_type":"code","source":"training_data = cv.fit_transform(train_document)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2146ad5fd9804a3d14e5e080b3a9692d7ec8e873"},"cell_type":"code","source":"testing_data = cv.transform(test_document)","execution_count":72,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c916d13001a9d3d91c46c34418861669b5d71ec7"},"cell_type":"code","source":"#It's time to predict the output","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e8a2c86e2766df5b65e1ee7a5686ba7eb5c3e6f","collapsed":true},"cell_type":"code","source":"clf.fit(training_data ,train_authors)","execution_count":75,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2da1ead3446ff6369738911604e08fd32f43b256"},"cell_type":"code","source":"prediction = clf.predict(testing_data)","execution_count":76,"outputs":[]},{"metadata":{"_uuid":"9da8a4b87898a08121920530d6c7b33fa0a29be9"},"cell_type":"markdown","source":"**prediction array contain the prediction of testing data**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}