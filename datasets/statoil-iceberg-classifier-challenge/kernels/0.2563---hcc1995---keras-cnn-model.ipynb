{"nbformat_minor": 1, "cells": [{"metadata": {"_kg_hide-output": false, "_uuid": "797e6828462473335764b3ccca82c625c7d545ab", "_cell_guid": "292b7729-4d40-4068-a4e8-6871d7d18de1"}, "outputs": [], "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import keras as k\n", "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "train = pd.read_json('../input/train.json')\n", "test = pd.read_json('../input/test.json')\n", "train.inc_angle = train.inc_angle.replace('na', 0)\n", "train = train[train.inc_angle>0]\n", "test.inc_angle = test.inc_angle.replace('na', 0)\n", "print('len of train set',len(train))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "a25d62dabf01cac8231a380b60f1778354ca8494", "_cell_guid": "4b5622be-07bb-4e86-8586-e5511c913f8e"}, "outputs": [], "execution_count": null, "source": ["def band_to_images(df):\n", "    images = []\n", "    for x in df.index:\n", "        band_1 = np.array(df.loc[x].band_1).reshape(75, 75)\n", "        band_2 = np.array(df.loc[x].band_2).reshape(75, 75)\n", "        band_3 = (band_1+band_2)/2\n", "        #band_4 = band_1 / band_2\n", "        band_1_scale = (band_1-band_1.mean())/(band_1.max()-band_1.min())\n", "        band_2_scale = (band_2-band_2.mean())/(band_2.max()-band_2.min())\n", "        band_3_scale = (band_3-band_3.mean())/(band_3.max()-band_3.min())\n", "        #band_4_scale = (band_4-band_4.mean())/(band_4.max()-band_4.min())\n", "        images.append(np.dstack((band_1_scale, band_2_scale, band_3_scale)))\n", "    return np.array(images)\n", "def data_augment(images):\n", "    lr_images = []\n", "    ud_images = []\n", "    for x in range(0, images.shape[0]):\n", "        band_1 = images[x, :, :, 0]\n", "        band_2 = images[x, :, :, 1]\n", "        band_3 = images[x, :, :, 2]\n", "        #band_4 = images[x, :, :, 3]\n", "        # lr augment\n", "        band_1_lr = np.fliplr(band_1)\n", "        band_2_lr = np.fliplr(band_2)\n", "        band_3_lr = np.fliplr(band_3)\n", "        #band_4_lr = np.fliplr(band_4)\n", "        lr_images.append(np.dstack((band_1_lr, band_2_lr, band_3_lr)))\n", "        #ud augment\n", "        band_1_ud = np.flipud(band_1)\n", "        band_2_ud = np.flipud(band_2)\n", "        band_3_ud = np.flipud(band_3)\n", "        #band_4_ud = np.flipud(band_4)\n", "        ud_images.append(np.dstack((band_1_ud, band_2_ud, band_3_ud)))\n", "    lr_images = np.array(lr_images)\n", "    ud_images = np.array(ud_images)\n", "    images = np.concatenate((images, ud_images, lr_images))\n", "    return images"], "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "47366722eb88bc5945957bff12a43a52f7c7bb4d", "_cell_guid": "7669f2f4-58ba-4764-a262-403d5f3c15a7"}, "outputs": [], "execution_count": null, "source": ["x_train = band_to_images(train)\n", "x_train = data_augment(x_train)\n", "y_train = train.is_iceberg\n", "y_train = np.concatenate((y_train, y_train, y_train))\n", "x_test = band_to_images(test)\n", "idno_test = test.id"], "cell_type": "code"}, {"metadata": {"collapsed": true, "_uuid": "d4e866f67ab8508b0e6a18f7c595e0fa3c686a12", "_cell_guid": "87601e43-8322-4400-a4cb-455ced95dac1"}, "outputs": [], "execution_count": null, "source": ["model = k.models.Sequential()\n", "# conv1\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(75, 75, 3)))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n", "model.add(k.layers.Dropout(0.2))\n", "#conv2\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu'))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "model.add(k.layers.Dropout(0.2))\n", "#conv3\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "model.add(k.layers.Dropout(0.2))\n", "# conv4\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "model.add(k.layers.Dropout(0.2))\n", "# fc1\n", "model.add(k.layers.Flatten())\n", "model.add(k.layers.Dense(512))\n", "model.add(k.layers.Activation('relu'))\n", "model.add(k.layers.Dropout(0.2))\n", "#fc2\n", "model.add(k.layers.Dense(256))\n", "model.add(k.layers.Activation('relu'))\n", "model.add(k.layers.Dropout(0.2))\n", "#output\n", "model.add(k.layers.Dense(1))\n", "model.add(k.layers.Activation('sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy', optimizer=k.optimizers.Nadam(0.001), metrics=['accuracy'])\n", "#model.summary()"], "cell_type": "code"}, {"metadata": {"_kg_hide-output": true, "collapsed": true, "_uuid": "2d5db491fb3683b493bec9cd351af8a2509164b6", "_cell_guid": "be22fb12-37db-4a69-a492-289a8d7c0f80"}, "outputs": [], "execution_count": null, "source": ["early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n", "mcp_save = ModelCheckpoint('md.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n", "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\n", "history = model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=1, validation_split=0.25, callbacks=[early_stopping, reduce_lr_loss, mcp_save])\n", "\n", "model.load_weights(filepath = 'md.hdf5')\n", "score = model.evaluate(x_train, y_train, verbose=1)\n", "print('Train score:', score[0])\n", "print('Train accuracy:', score[1])\n", "\n", "pred_test = model.predict(x_test)\n", "submission = pd.DataFrame({'id': idno_test, 'is_iceberg': pred_test.reshape((pred_test.shape[0]))})\n", "submission.to_csv('cnn_keras.csv', index=False)\n", "\n"], "cell_type": "code"}, {"metadata": {"_uuid": "fcbd83ff148df6dd6a18c5d2be84b59adca0ab3c", "_cell_guid": "65754e4b-5dbf-4b17-a928-520bc6861e77"}, "source": ["Thanks for fvzaur's kernals\n", "[www.kaggle.com/fvzaur/iceberg-ship-classification-with-cnn-on-keras](http://)"], "cell_type": "markdown"}], "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4}