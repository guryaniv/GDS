{"cells": [{"metadata": {"_cell_guid": "80dd0baa-587f-4310-905e-aa3db57b2f03", "collapsed": true, "_uuid": "641f24aa844008f845fbe6f7f537b62ae72643a6"}, "source": ["#Load modules\n", "#data wrangling\n", "import numpy as np\n", "import pandas as pd\n", "import re as re\n", "\n", "#visualization\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "# machine learning\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC, LinearSVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.linear_model import Perceptron\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.tree import DecisionTreeClassifier"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "f4859016-b48f-4d3a-8176-21efe8111719", "collapsed": true, "_uuid": "563863cf969ead8a37e53a62c480c1fcb403409d"}, "source": ["#load data\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "full_data = pd.concat([train, test])"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "2cd8b2d7-9300-4a9a-9b5b-954b72d1480d", "_uuid": "673cfb8808ccbd1925227fc45b6e1cd49303c741"}, "source": ["### Preview Data"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "950b058c-ecde-4aee-8f0d-665508c59dc9", "collapsed": true, "_uuid": "3813a6b93067fc515a201b447e77e82d2115d4d4"}, "source": ["#preview data\n", "print(\"train\")\n", "print (train.info())\n", "print(\"\\ntest\")\n", "print (test.info())\n", "print(\"full_data\")\n", "print (full_data.info())\n", "train.head(10)"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "bc9b30dc-4084-437c-a5c2-57549b31bb81", "collapsed": true, "_uuid": "60ae95fc274b137224bd9937207c8f52b15908ba"}, "source": ["#Data summary\n", "train.describe(include = \"all\").transpose()\n"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "cf76facf-bbd5-488a-bd35-854128f47da7", "_uuid": "74c56b552040a1f6697c0cea868aefdc03a92435"}, "source": ["#### Observations  in training dataset\n", "|Column|Data Type|Number of Missing Values|Other obervations|\n", "|--|--|--|--|\n", "|PassengerId    |integer|0|-|\n", "|Survived       |integer|0|Survive rate is 38%|\n", "|Pclass         |integer|0||\n", "|Name           |character|0||\n", "|Sex            |character|0|Over half of the passengers were male|\n", "|Age            |float|177|Average age is 29,75% of passengers are under 38. There were infant(6 month old) and elder people(80 years old)|\n", "|SibSp|integer|0|Over half of passengers travel without siblings or spouses|\n", "|Parch          |integer|0|Over 75% of passengers travel without parent or child|\n", "|Ticket         |character|0|-|\n", "|Fare           |float|0|Though average ticket price is 32, there is great variations on ticket price. The most expensive ones are 512|\n", "|Cabin          |character|687||\n", "|Embarked       |character|2||\n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "3c002185-0f47-4ac3-afe2-a0f7321c86f2", "collapsed": true, "_uuid": "ed245cb2d339edd8c9eea317f1d685a8fe08f0cb"}, "source": ["# Pclass\n", "print('Pclass')\n", "print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())\n", "#Extract title from names\n", "print('\\nName(Title)')\n", "train['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "print (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n", "#Sex\n", "print(\"\\nSex\")\n", "print (train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean())\n", "#Age\n", "print(\"\\nAge\")\n", "train['CategoricalAge'] = pd.cut(train['Age'], 5)\n", "print (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())\n", "#Siblings and Spouses\n", "print(\"\\nSibSp\")\n", "print (train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean())\n", "#Parent and child\n", "print(\"\\nParch\")\n", "print (train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean())\n", "#Fare\n", "print(\"\\nFare\")\n", "train['CategoricalFare'] = pd.cut(train['Fare'], 5)\n", "print (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())\n", "print(\"\\nEmbarked\")\n", "print (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "28e589cc-eaa5-41c5-bfdd-cb701cb5a4a3", "_uuid": "c8df4c6c9d69e61aea0212ec9ded77e2356dadc0"}, "source": ["### Replace missing values and create new features(on full data)\n", "\n", "#### Replace missing values\n", "\n", "1. replace missing values from Embarked with S(mode)\n", "2. replace missing age with randomly generated value refering to its title\n", "\n", "#### Add new features\n", "\n", "1. Create \"title: from \"name\"\n", "2. Create \"travel_size\" from \"Parch\" and \"SibSp\""], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "a901a4b3-c42f-413c-82a6-2635e2be4c10", "collapsed": true, "_uuid": "0b062e6ef5d4f46ddf72e78d520f97c95971ffb3"}, "source": ["#1.replace missing values from Embarked with S(mode)\n", "full_data['Embarked'] = full_data['Embarked'].fillna('S')\n", "\n", "#2.Create \"title: from \"name\", and collapse som of the titles\n", "full_data['Title'] = full_data['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n", "full_data['Title'] = full_data['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n", "full_data['Title'] = full_data['Title'].replace('Mlle', 'Miss')\n", "full_data['Title'] = full_data['Title'].replace('Ms', 'Miss')\n", "full_data['Title'] = full_data['Title'].replace('Mme', 'Mrs')\n", "print (full_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())\n", "print(\"\\n\")\n", "\n", "#3.Create \"TravelSize\" from \"Parch\" and \"SibSp\"\n", "full_data['TravelSize'] = full_data['SibSp'] + full_data['Parch'] + 1\n", "#Make TravelGroup from TravelSize\n", "full_data.loc[full_data['TravelSize'] == 1, 'TravelGroup'] = \"alone\"\n", "full_data.loc[(full_data['TravelSize'] > 1) & (full_data['TravelSize'] < 5), 'TravelGroup'] = \"small\"\n", "full_data.loc[full_data['TravelSize'] >= 5, 'TravelGroup'] = \"big\"\n", "print (full_data[['TravelGroup', 'Survived']].groupby(['TravelGroup'], as_index=False).mean())\n", "\n", "#4.\n", "print(\"\\ntitles and average age\")\n", "print (full_data[['Title', 'Age']].groupby(['Title'], as_index=False).mean())\n", "\n", "titles = [\"Master\",\"Miss\",\"Mr\",\"Mrs\",\"Rare\"]\n", "for title in titles:\n", "    sub_dataset = full_data.loc[full_data[\"Title\"] == title,'Age']\n", "    age_avg = sub_dataset.mean()\n", "    age_std    = sub_dataset.std()\n", "    age_null_count = sub_dataset.isnull().sum()\n", "    \n", "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n", "    sub_dataset[np.isnan(sub_dataset)] = age_null_random_list\n", "    full_data.loc[full_data[\"Title\"] == title,'Age'] = sub_dataset.astype(int) \n", "#Notice that one observation's \"fare\" column is null, we find it and use mean fare of its pclass\n", "print(\"There is only on row of fare missing, which is:\")\n", "\n", "print(full_data[full_data[\"Fare\"].isnull()])\n", "temp_mean = full_data[full_data[\"Pclass\"] == 3]['Fare'].mean()\n", "print(\"Since it is class 3, so set the fare to mean fare for class 3:(which is \" + str(round(temp_mean)) +\")\")\n", "full_data.loc[full_data[\"Fare\"].isnull(),\"Fare\"] = full_data[full_data[\"Pclass\"] == 3]['Fare'].mean()"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "eeac5e0f-3243-4a1a-beaa-377b95ae7a35", "collapsed": true, "_uuid": "1a36df927a603f19fdb192eaa27ad7e322e90ce0"}, "source": ["print (full_data.info())\n", "print (full_data.describe())"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "a82d9bc4-121e-40f6-8214-8ee221d14abf", "_uuid": "37b12b96215b91a8fdaddf272f6043d183538b4a"}, "source": ["We can see that, except for Cabin, there are no other columns that contain NAs.\n", "\n", "### Data Mapping"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "1a6e9e04-a185-4e8b-a180-98e5973bff26", "collapsed": true, "_uuid": "3323c7572d487a3a226e153209d4e7a3180dce55"}, "source": ["#Data mapping\n", "# Mapping Sex\n", "full_data['Sex'] = full_data['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n", " \n", "# Mapping titles\n", "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n", "full_data['Title'] = full_data['Title'].map(title_mapping)\n", "full_data['Title'] = full_data['Title'].fillna(0)\n", "    \n", "# Mapping Embarked\n", "full_data['Embarked'] = full_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n", "    \n", "# Mapping Fare\n", "full_data.loc[ full_data['Fare'] <= 7.91, 'Fare'] = 0\n", "full_data.loc[(full_data['Fare'] > 7.91) & (full_data['Fare'] <= 14.454), 'Fare'] = 1\n", "full_data.loc[(full_data['Fare'] > 14.454) & (full_data['Fare'] <= 31), 'Fare']   = 2\n", "full_data.loc[ full_data['Fare'] > 31, 'Fare'] = 3\n", "full_data['Fare'] = full_data['Fare'].astype(int)\n", "    \n", "# Mapping Age\n", "full_data.loc[ full_data['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n", "full_data.loc[(full_data['Age'] > 16) & (full_data['Age'] <= 32), 'Age'] = 1\n", "full_data.loc[(full_data['Age'] > 32) & (full_data['Age'] <= 48), 'Age'] = 2\n", "full_data.loc[(full_data['Age'] > 48) & (full_data['Age'] <= 64), 'Age'] = 3\n", "full_data.loc[ full_data['Age'] > 64, 'Age']  = 4\n", "\n", "#Mapping TravelGroup\n", "full_data['TravelGroup'] = full_data['TravelGroup'].map( {'alone': 0, 'small': 1, 'big': 2} ).astype(int)"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "55b42387-e2a6-4d02-b117-7936c30e6549", "collapsed": true, "_uuid": "70a35d508819efdf7407bd0c2326fd0b178e977c"}, "source": ["drop_features = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp','Parch', 'TravelSize']\n", "droped_dataset = full_data.drop(drop_features,axis = 1)\n", "cols = list(droped_dataset.columns.values)\n", "cols = cols[5:] + cols[0:5]\n", "droped_dataset = droped_dataset[cols]\n", "train = droped_dataset.iloc[0:891,:]\n", "test = droped_dataset.iloc[891:,:]\n", "print(train.head())"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "6f4dd67e-cf0b-4404-9d18-5c0e9cebf9e0", "collapsed": true, "_uuid": "9ade9e07f2dff3933c4eefcc4210c99902a86ab1"}, "source": ["colormap = plt.cm.RdBu\n", "plt.figure(figsize=(14,12))\n", "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n", "sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "fbc04380-1c8c-4f4d-a5ee-7088d00dd7c8", "collapsed": true, "_uuid": "62205349f88e7dce3d6290886c1adca69ec717e2"}, "source": ["X_train = train.drop(\"Survived\",axis=1)\n", "Y_train = train[\"Survived\"]\n", "X_test  = test.drop(\"Survived\",axis=1).copy()"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "c98724da-2551-44ea-903c-3421fa3576ba", "collapsed": true, "_uuid": "7493fd5ea08a21ab393b038dd7a9f47d9b49df30"}, "source": ["# Logistic Regression\n", "logreg = LogisticRegression()\n", "logreg.fit(X_train, Y_train)\n", "Y_pred = logreg.predict(X_test)\n", "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n", "\n", "# Support Vector Machines\n", "svc = SVC()\n", "svc.fit(X_train, Y_train)\n", "Y_pred = svc.predict(X_test)\n", "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n", "\n", "#knn\n", "knn = KNeighborsClassifier(n_neighbors = 3)\n", "knn.fit(X_train, Y_train)\n", "Y_pred = knn.predict(X_test)\n", "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n", "\n", "# Gaussian Naive Bayes\n", "gaussian = GaussianNB()\n", "gaussian.fit(X_train, Y_train)\n", "Y_pred = gaussian.predict(X_test)\n", "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n", "\n", "# Perceptron\n", "perceptron = Perceptron()\n", "perceptron.fit(X_train, Y_train)\n", "Y_pred = perceptron.predict(X_test)\n", "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n", "\n", "# Linear SVC\n", "linear_svc = LinearSVC()\n", "linear_svc.fit(X_train, Y_train)\n", "Y_pred = linear_svc.predict(X_test)\n", "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n", "\n", "# Stochastic Gradient Descent\n", "sgd = SGDClassifier()\n", "sgd.fit(X_train, Y_train)\n", "Y_pred = sgd.predict(X_test)\n", "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n", "\n", "# Decision Tree\n", "decision_tree = DecisionTreeClassifier()\n", "decision_tree.fit(X_train, Y_train)\n", "Y_pred = decision_tree.predict(X_test)\n", "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n", "\n", "# Random Forest\n", "random_forest = RandomForestClassifier(n_estimators=100)\n", "random_forest.fit(X_train, Y_train)\n", "Y_pred = random_forest.predict(X_test)\n", "random_forest.score(X_train, Y_train)\n", "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n", "\n", "models = pd.DataFrame({\n", "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n", "              'Random Forest', 'Naive Bayes', 'Perceptron', \n", "              'Stochastic Gradient Decent', 'Linear SVC', \n", "              'Decision Tree'],\n", "    'Score': [acc_svc, acc_knn, acc_log, \n", "              acc_random_forest, acc_gaussian, acc_perceptron, \n", "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n", "models.sort_values(by='Score', ascending=False)"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "ff293141-919b-4866-8648-30818fc37459", "_uuid": "43712913a25d80a941a4b422d8ba31e254099b48"}, "source": ["### Result\n", "\n", "We can see that: random forest has the best accuracy"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "b1226ad6-0037-4b35-abda-290be2672eb5", "collapsed": true, "_uuid": "6a9a750bbf0b9691cc30e35deb6204d8860e6f21"}, "source": ["Y_pred = random_forest.predict(X_test).astype(int)\n", "test = pd.read_csv('../input/test.csv')\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": Y_pred\n", "    })"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "ffacd06d-b81e-4a6a-a6f8-d1233edaa642", "collapsed": true, "_uuid": "46862ec53632513fe511843d974c223679590287"}, "source": ["submission.to_csv('submission.csv', index=False)"], "cell_type": "code", "execution_count": null, "outputs": []}, {"metadata": {"_cell_guid": "c3a4c7ee-6120-4693-852e-54bf5a37955a", "_uuid": "96b9df4e1ee62baa4d502117c9fbc3b556842a81"}, "source": [], "cell_type": "markdown"}], "metadata": {"language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.4"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "nbformat_minor": 1}