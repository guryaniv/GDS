{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Embedding, Input\nfrom keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\nfrom keras.preprocessing import text, sequence\nimport pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f00059c879ed11b8e731f2366337c20b2d82f80b"},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9607cfd2f3145960489e507adca517de18418cd5"},"cell_type":"code","source":"x_train=train['comment_text']\ny_train=train.iloc[:,2:8]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f1f0b191cd1cf2b52cae1c362dfe8b75bbcdcb2"},"cell_type":"code","source":"x_test=test['comment_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd1b2b68fe9946581e8c36be2151b30b8a14a021"},"cell_type":"code","source":"import re\nclean_data=[]\nfor sent in x_train:     \n    sent=sent.lower()\n    sent = re.sub(\"[^\\w]\", \" \", sent)\n    sent = re.sub(r\"\\d+\", \" \", sent)\n    sent = re.sub(r\"\\s+\", \" \", sent)\n    clean_data.append(sent)\nclean_data = '\\n'.join(clean_data)\nclean_data=clean_data.split('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d658851549732380b83b8a178f6142a152ccdd3"},"cell_type":"code","source":"type(clean_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5904b2a20f45634704cf9077f635a0a71df8de29"},"cell_type":"code","source":"from nltk.corpus import stopwords\nx_data=[]\nfor sentence in clean_data:\n    sentence=sentence.split(' ')\n    word =[word for word in sentence if word not in stopwords.words('english')]\n    x_data.append(word)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a045cbbac84f24c7a18f5b6cdad1eb4fff29668a"},"cell_type":"code","source":"clean_datat=[]\nfor sent in x_test:\n        sent=sent.lower()\n        sent = re.sub(\"[^\\w]\", \" \", sent)\n        sent = re.sub(r\"\\d+\", \" \", sent)\n        sent = re.sub(r\"\\s+\", \" \", sent)\n\n        clean_datat.append(sent)\nclean_datat = '\\n'.join(clean_datat)\nclean_datat=clean_datat.split('\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b53fffe105e0ece7e665460908dd0c2e79e1210"},"cell_type":"code","source":"test_data=[]\nfor sentence in clean_datat:\n    sentence=sentence.split(' ')\n    word =[word for word in sentence if word not in stopwords.words('english')]\n    test_data.append(word)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06ff8f0bac635d70c434ade2c320ba5ce4bdd660"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\ntoken=Tokenizer(num_words=200,split=' ')\ntoken.fit_on_texts(x_data)\nx_train=token.texts_to_sequences(x_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63a62c4a303a53e2dd88dbfc891017ba5f506f67"},"cell_type":"code","source":"token=Tokenizer(num_words=200,split=' ')\ntoken.fit_on_texts(test_data)\nx_tesr=token.texts_to_sequences(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"235d67ded82a590e87797342120380dfccf6bea9"},"cell_type":"code","source":"from keras.preprocessing.sequence import pad_sequences\nmaxlen = 100\nx_train = pad_sequences(x_train, maxlen=maxlen)\nx_test=pad_sequences(x_tesr,maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e7a77d5cdd6311d022236950ffded0d3b53b0e0"},"cell_type":"code","source":"from keras.models import Sequential\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6722d60a214159f2d6546a75f50922edcc98604a"},"cell_type":"code","source":"from keras.layers import MaxPool1D\n\nembed_size = 128\nmodel = Sequential()\nmodel.add(Embedding(200, embed_size))\nmodel.add(Bidirectional(LSTM(32,return_sequences=True)))\nmodel.add(MaxPool1D(2))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(6, activation=\"softmax\"))\nmodel.summary()\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size = 512\nepochs = 2\nhist=model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89e792510904ffb5dfff47217fc8a02262e54992"},"cell_type":"code","source":"prediction = model.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd6c78f6797b95135f3aa7eee6dc21ec1c3a7770"},"cell_type":"code","source":"print(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23d384695972c21d2285d28df957747c1259995d"},"cell_type":"code","source":"submission = ('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\nsubmission[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]] = prediction\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8579370fb9c616e52fd676e02872e724af118c50"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(hist.history['loss'],'g')\nplt.plot(hist.history['val_loss'],'r')\n\nplt.plot(hist.history['acc'],'b')\nplt.plot(hist.history['val_acc'],'black')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54243a47fff654002da43832a071debda2f295bb"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"761b28cab25eac01c9994b1aacb39d473eb5381a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}