{"nbformat_minor": 1, "cells": [{"execution_count": null, "outputs": [], "metadata": {"_uuid": "0cec4d047a2690ce89d616727a99d63c599932df", "_cell_guid": "c9b84c36-51d1-420d-bcb4-e3ba21e329ae"}, "source": ["DATADIR = './data' # unzipped train and test data\n", "OUTDIR = './model-k' # just a random name\n", "# Data Loading\n", "import os\n", "import re\n", "from glob import glob\n", "\n", "\n", "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n", "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n", "name2id = {name: i for i, name in id2name.items()}\n", "\n", "\n", "def load_data(data_dir):\n", "    \"\"\" Return 2 lists of tuples:\n", "    [(class_id, user_id, path), ...] for train\n", "    [(class_id, user_id, path), ...] for validation\n", "    \"\"\"\n", "    # Just a simple regexp for paths with three groups:\n", "    # prefix, label, user_id\n", "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n", "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n", "\n", "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n", "        validation_files = fin.readlines()\n", "    valset = set()\n", "    for entry in validation_files:\n", "        r = re.match(pattern, entry)\n", "        if r:\n", "            valset.add(r.group(3))\n", "\n", "    possible = set(POSSIBLE_LABELS)\n", "    train, val = [], []\n", "    for entry in all_files:\n", "        r = re.match(pattern, entry)\n", "        if r:\n", "            label, uid = r.group(2), r.group(3)\n", "            if label == '_background_noise_':\n", "                label = 'silence'\n", "            if label not in possible:\n", "                label = 'unknown'\n", "\n", "            label_id = name2id[label]\n", "\n", "            sample = (label_id, uid, entry)\n", "            if uid in valset:\n", "                val.append(sample)\n", "            else:\n", "                train.append(sample)\n", "\n", "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n", "    return train, val\n", "\n", "trainset, valset = load_data(DATADIR)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "c0949a3d233e1fbd2f6635a25e418129bdcbff8b", "_cell_guid": "dc61746e-a954-488a-bc79-57769997c81c", "collapsed": true}, "source": ["import numpy as np\n", "from scipy.io import wavfile\n", "\n", "def data_generator(data, params, mode='train'):\n", "    def generator():\n", "        if mode == 'train':\n", "            np.random.shuffle(data)\n", "        # Feel free to add any augmentation\n", "        for (label_id, uid, fname) in data:\n", "            try:\n", "                _, wav = wavfile.read(fname)\n", "                wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n", "\n", "                L = 16000  # be aware, some files are shorter than 1 sec!\n", "                if len(wav) < L:\n", "                    continue\n", "                # let's generate more silence!\n", "                samples_per_file = 1 if label_id != name2id['silence'] else 20\n", "                for _ in range(samples_per_file):\n", "                    if len(wav) > L:\n", "                        beg = np.random.randint(0, len(wav) - L)\n", "                    else:\n", "                        beg = 0\n", "                    yield dict(\n", "                        target=np.int32(label_id),\n", "                        wav=wav[beg: beg + L],\n", "                    )\n", "            except Exception as err:\n", "                print(err, label_id, uid, fname)\n", "\n", "    return generator"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "3311fa56f0c8477d58f43e446f1ba546ce484b18", "_cell_guid": "b2dcec9e-ee86-4dfd-9ee1-8247763eac4f", "collapsed": true}, "source": ["import tensorflow as tf\n", "from tensorflow.contrib import layers\n", "\n", "def baseline(x, params, is_training):\n", "    x = layers.batch_norm(x, is_training=is_training)\n", "    for i in range(4):\n", "        x = layers.conv2d(\n", "            x, 16 * (2 ** i), 3, 1,\n", "            activation_fn=tf.nn.elu,\n", "            normalizer_fn=layers.batch_norm if params.use_batch_norm else None,\n", "            normalizer_params={'is_training': is_training}\n", "        )\n", "        x = layers.max_pool2d(x, 2, 2)\n", "\n", "    # just take two kind of pooling and then mix them, why not :)\n", "    mpool = tf.reduce_max(x, axis=[1, 2], keep_dims=True)\n", "    apool = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n", "\n", "    x = 0.5 * (mpool + apool)\n", "    # we can use conv2d 1x1 instead of dense\n", "    x = layers.conv2d(x, 128, 1, 1, activation_fn=tf.nn.elu)\n", "    x = tf.nn.dropout(x, keep_prob=params.keep_prob if is_training else 1.0)\n", "    \n", "    # again conv2d 1x1 instead of dense layer\n", "    logits = layers.conv2d(x, params.num_classes, 1, 1, activation_fn=None)\n", "    return tf.squeeze(logits, [1, 2])"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "73722beb5345d73b7157230a0b837933cab87c53", "_cell_guid": "4b4a2dd4-7207-418f-bdb7-2ed8f3926f7b", "collapsed": true}, "source": ["from tensorflow.contrib import signal\n", "\n", "# features is a dict with keys: tensors from our datagenerator\n", "# labels also were in features, but excluded in generator_input_fn by target_key\n", "\n", "def model_handler(features, labels, mode, params, config):\n", "    # Im really like to use make_template instead of variable_scopes and re-usage\n", "    extractor = tf.make_template(\n", "        'extractor', baseline,\n", "        create_scope_now_=True,\n", "    )\n", "    # wav is a waveform signal with shape (16000, )\n", "    wav = features['wav']\n", "    # we want to compute spectograms by means of short time fourier transform:\n", "    specgram = signal.stft(\n", "        wav,\n", "        400,  # 16000 [samples per second] * 0.025 [s] -- default stft window frame\n", "        160,  # 16000 * 0.010 -- default stride\n", "    )\n", "    # specgram is a complex tensor, so split it into abs and phase parts:\n", "    phase = tf.angle(specgram) / np.pi\n", "    # log(1 + abs) is a default transformation for energy units\n", "    amp = tf.log1p(tf.abs(specgram))\n", "    \n", "    x = tf.stack([amp, phase], axis=3) # shape is [bs, time, freq_bins, 2]\n", "    x = tf.to_float(x)  # we want to have float32, not float64\n", "\n", "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n", "\n", "    if mode == tf.estimator.ModeKeys.TRAIN:\n", "        loss = tf.reduce_mean(\n", "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n", "        # some lr tuner, you could use move interesting functions\n", "        def learning_rate_decay_fn(learning_rate, global_step):\n", "            return tf.train.exponential_decay(\n", "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n", "\n", "        train_op = tf.contrib.layers.optimize_loss(\n", "            loss=loss,\n", "            global_step=tf.contrib.framework.get_global_step(),\n", "            learning_rate=params.learning_rate,\n", "            optimizer=lambda lr: tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True),\n", "            learning_rate_decay_fn=learning_rate_decay_fn,\n", "            clip_gradients=params.clip_gradients,\n", "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n", "\n", "        specs = dict(\n", "            mode=mode,\n", "            loss=loss,\n", "            train_op=train_op,\n", "        )\n", "\n", "    if mode == tf.estimator.ModeKeys.EVAL:\n", "        prediction = tf.argmax(logits, axis=-1)\n", "        acc, acc_op = tf.metrics.mean_per_class_accuracy(\n", "            labels, prediction, params.num_classes)\n", "        loss = tf.reduce_mean(\n", "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n", "        specs = dict(\n", "            mode=mode,\n", "            loss=loss,\n", "            eval_metric_ops=dict(\n", "                acc=(acc, acc_op),\n", "            )\n", "        )\n", "\n", "    if mode == tf.estimator.ModeKeys.PREDICT:\n", "        predictions = {\n", "            'label': tf.argmax(logits, axis=-1),  # for probability just take tf.nn.softmax()\n", "            'sample': features['sample'], # it's a hack for simplicity\n", "        }\n", "        specs = dict(\n", "            mode=mode,\n", "            predictions=predictions,\n", "        )\n", "    return tf.estimator.EstimatorSpec(**specs)\n", "\n", "\n", "def create_model(config=None, hparams=None):\n", "    return tf.estimator.Estimator(\n", "        model_fn=model_handler,\n", "        config=config,\n", "        params=hparams,\n", "    )"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "cdbf3ad7f4142c1d34d43b89492b4108e1cb99b7", "_cell_guid": "b7d3f860-0367-413f-81bc-87c8cdf32c33", "collapsed": true}, "source": ["params=dict(\n", "    seed=2018,\n", "    batch_size=64,\n", "    keep_prob=0.5,\n", "    learning_rate=1e-3,\n", "    clip_gradients=15.0,\n", "    use_batch_norm=True,\n", "    num_classes=len(POSSIBLE_LABELS),\n", ")\n", "\n", "hparams = tf.contrib.training.HParams(**params)\n", "os.makedirs(os.path.join(OUTDIR, 'eval'), exist_ok=True)\n", "model_dir = OUTDIR\n", "\n", "run_config = tf.contrib.learn.RunConfig(model_dir=model_dir)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "989bb42acc28e698fe5a7267e35d93476c8959a0", "_cell_guid": "72eefb5a-06d4-4a13-b4e5-2d4f81541595", "collapsed": true}, "source": ["# it's a magic function :)\n", "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n", "            \n", "train_input_fn = generator_input_fn(\n", "    x=data_generator(trainset, hparams, 'train'),\n", "    target_key='target',  # you could leave target_key in features, so labels in model_handler will be empty\n", "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n", "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n", ")\n", "\n", "val_input_fn = generator_input_fn(\n", "    x=data_generator(valset, hparams, 'val'),\n", "    target_key='target',\n", "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n", "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n", ")\n", "            \n", "\n", "def _create_my_experiment(run_config, hparams):\n", "    exp = tf.contrib.learn.Experiment(\n", "        estimator=create_model(config=run_config, hparams=hparams),\n", "        train_input_fn=train_input_fn,\n", "        eval_input_fn=val_input_fn,\n", "        train_steps=10000, # just randomly selected params\n", "        eval_steps=200,  # read source code for steps-epochs ariphmetics\n", "        train_steps_per_iteration=1000,\n", "    )\n", "    return exp\n", "\n", "tf.contrib.learn.learn_runner.run(\n", "    experiment_fn=_create_my_experiment,\n", "    run_config=run_config,\n", "    schedule=\"continuous_train_and_eval\",\n", "    hparams=hparams)"], "cell_type": "code"}, {"metadata": {"_uuid": "ef9d2527d72ce27e8c09ccff20408349cb79fb19", "_cell_guid": "58b2914f-8c14-452b-88d8-3a9ae3267810"}, "source": ["\n", "While it trains (~10-20min on i5 + 1080), you could start tensorboard on model_dir and see live chart like this\n", "\n", "![Tensorboard](https://pp.userapi.com/c841329/v841329524/3db60/fdNDyRMJHMQ.jpg)\n", "\n", "\n", "Now we want to predict testset and make submission file.\n", "\n", "1. Create datagenerator and input_function\n", "2. Load model\n", "3. Iterate over predictions and store results"], "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "47a197904a9722e45f5dce0951f850efe7c230d7", "_cell_guid": "cb4c90a2-38d6-4340-b45c-de417c47d94e", "collapsed": true}, "source": ["from tqdm import tqdm\n", "# now we want to predict!\n", "paths = glob(os.path.join(DATADIR, 'test/audio/*wav'))\n", "\n", "def test_data_generator(data):\n", "    def generator():\n", "        for path in data:\n", "            _, wav = wavfile.read(path)\n", "            wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n", "            fname = os.path.basename(path)\n", "            yield dict(\n", "                sample=np.string_(fname),\n", "                wav=wav,\n", "            )\n", "\n", "    return generator\n", "\n", "test_input_fn = generator_input_fn(\n", "    x=test_data_generator(paths),\n", "    batch_size=hparams.batch_size, \n", "    shuffle=False, \n", "    num_epochs=1,\n", "    queue_capacity= 10 * hparams.batch_size, \n", "    num_threads=1)\n", "\n", "model = create_model(config=run_config, hparams=hparams)\n", "it = model.predict(input_fn=test_input_fn)\n", "\n", "\n", "# last batch will contain padding, so remove duplicates\n", "submission = dict()\n", "for t in tqdm(it):\n", "    fname, label = t['sample'].decode(), id2name[t['label']]\n", "    submission[fname] = label\n", "\n", "with open(os.path.join(model_dir, 'submission.csv'), 'w') as fout:\n", "    fout.write('fname,label\\n')\n", "    for fname, label in submission.items():\n", "        fout.write('{},{}\\n'.format(fname, label))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "519da838f8c86adf79ec66228f27119d61d8edbb", "_cell_guid": "ca1689c9-d61f-4111-b18b-31892580ad82", "collapsed": true}, "source": [], "cell_type": "code"}], "metadata": {"language_info": {"nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4}