{"metadata": {"anaconda-cloud": {}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "file_extension": ".py", "version": "3.6.3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "cells": [{"source": ["This code is heavily based on this kernel [here](https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d).\n", "\n", "Thank you [man](https://www.kaggle.com/devm2024) for giving me a start.\n"], "metadata": {"_uuid": "08767d357c959a7ace4fa1674319ab74032cc4b1", "_cell_guid": "4f98d9e9-d3eb-4ade-9261-30e8f1a7d5a4"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "3990ca7462de3675c53529fa31006351631c76b7", "collapsed": true, "_cell_guid": "94409a07-b3b7-4e45-8758-dc3d2aae7d77"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import os\n", "import pylab"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "cd147d5e9b36edee7ddbc857417262402f698ed3", "collapsed": true, "_cell_guid": "ec5f11d2-1c0a-4a5c-b9c0-1379c38a271f"}, "source": ["print(os.listdir(os.getcwd()))"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "ca30e5bb52eb0da209f30bdf4e0d217bcf8838f8", "collapsed": true, "_cell_guid": "3484a8cb-f2eb-4a80-9b9b-74278e2f2111"}, "source": ["from sklearn.model_selection import train_test_split\n", "from matplotlib import pyplot as plt\n", "from mpl_toolkits.mplot3d import Axes3D"], "outputs": [], "cell_type": "code"}, {"source": ["### The following command displays all the loaded modules"], "metadata": {"_uuid": "e3c1a0de1dffb7dbda91c6b83e2c6a98c7e36966", "_cell_guid": "afb19d04-ec39-49e5-92ef-98fcf0027498"}, "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_uuid": "d515afbdc5df598840cbe5a3ef262baf0a068aa8", "collapsed": true, "_cell_guid": "6e05ec98-50ed-4b4f-a7fc-7d1a3f41ec6a"}, "source": ["import sys\n", "modulenames = set(sys.modules)&set(globals())\n", "print(modulenames)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "1d349b7f46a418a18a367d833130d38b59214759", "collapsed": true, "_cell_guid": "ebb484c7-c204-4087-8488-bf1c9bd15897"}, "source": ["plt.rcParams['figure.figsize'] = 10,10"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "c01b50395a2588d0e83b2891f08c151c850a5b39", "collapsed": true, "_cell_guid": "f25ce691-6bc2-422b-922a-6646cf42cd86"}, "source": ["%matplotlib inline"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "ee719a19f776d58936f18b7edfea613e6bf8885f", "collapsed": true, "_cell_guid": "f7e75fef-bd17-45ae-a9ac-64f24ffdfb8e"}, "source": ["# Load the data\n", "train_data = pd.read_json(\"../input/train.json\")"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "9807a245484f37f3660552daac8dc3ae03623cde", "collapsed": true, "_cell_guid": "e98ade32-29b5-47ae-9524-6854fbaf21b9"}, "source": ["train_data.head(10)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "5f66863d96f64a0dcfef19fd83b1fb36518bffc7", "collapsed": true, "_cell_guid": "51c26cfe-9afb-492d-881a-723ea91842e4"}, "source": ["test_data = pd.read_json(\"../input/test.json\")"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "a21ce0c659b2830ea8028b030b3f42fc9777e705", "collapsed": true, "_cell_guid": "8d037f92-915d-4f42-8093-fa54a3f9ae6f"}, "source": ["test_data.head(10)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "5729ab89ba7b61e123aa516ee371b5155eb3b6d2", "collapsed": true, "_cell_guid": "110ec418-1e80-436b-b1dd-b32b2d8b29e5"}, "source": ["Xband1 = np.array([np.array(eachband).reshape(75,75) for eachband in train_data[\"band_1\"]])\n", "Xband2 = np.array([np.array(eachband).reshape(75,75) for eachband in train_data[\"band_2\"]])\n", "Xtrain = np.concatenate((Xband1[:,:,:,np.newaxis],Xband2[:,:,:,np.newaxis],((Xband1+Xband2)/2)[:,:,:,np.newaxis]),axis = -1)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "6fc12c6aca87862647d6e5f6b37ce7d81df26f23", "collapsed": true, "_cell_guid": "358dc5f0-e106-459b-8f03-3d4b3fa4e66b"}, "source": ["# 1604 images\n", "# Each image having 75 rows and each row has 75 parts and each part having 3 rgb channels\n", "Xtrain.shape"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "9328ec19072e9939b9dde627336385ff258bd78c", "collapsed": true, "_cell_guid": "3c06d4a4-cb76-4dc4-8b12-99d6c2147e8b"}, "source": ["import keras\n", "from keras.models import Model\n", "from keras.models import Sequential\n", "from keras.layers import Conv2D,MaxPooling2D,Dense,Dropout,Input,Flatten,Activation\n", "from keras.layers import GlobalMaxPooling2D\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.layers.merge import Concatenate\n", "from keras import initializers\n", "from keras.optimizers import Adam\n", "from keras.callbacks import ModelCheckpoint,Callback,EarlyStopping"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "7eb73b884d084d5a15fe1c82cfb0c8b4227e6f69", "collapsed": true, "_cell_guid": "1f847d81-f25a-418d-b493-2301e471667e"}, "source": ["# Define the model\n", "\n", "model = Sequential()\n", "\n", "model.add(Conv2D(64,kernel_size=(3,3),activation='relu',input_shape=(75,75,3)))\n", "model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Conv2D(128,kernel_size=(3,3),activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Flatten())\n", "\n", "model.add(Dense(512))\n", "model.add(Activation('relu'))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Dense(256))\n", "model.add(Activation('relu'))\n", "model.add(Dropout(0.2))\n", "\n", "model.add(Dense(1))\n", "model.add(Activation('sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy',optimizer=Adam(lr = 0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-08,decay=0.0),metrics=['accuracy'])\n", "model.summary()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "a8a454e4e3f2866c5e2c7bf5a3cd28c0add44720", "collapsed": true, "_cell_guid": "651baa0e-b83f-4ac7-bd3e-f13b1371d037"}, "source": ["def get_callbacks(filepath, patience=2):\n", "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n", "    msave = ModelCheckpoint(filepath, save_best_only=True)\n", "    return [es, msave]\n", "file_path = \".model_weights.hdf5\"\n", "callbacks = get_callbacks(filepath=file_path, patience=5)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "ae072927453ff501eb2c0a93637bcef6163615a7", "collapsed": true, "_cell_guid": "6c7284a1-5906-41c4-aadb-bdb68b07f1ae"}, "source": ["Ytrain = train_data[\"is_iceberg\"]\n", "\n", "XtrainCV,Xvalid,YtrainCV,Yvalid = train_test_split(Xtrain,Ytrain,random_state = 1,train_size = 0.75)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "3a06c5369f24560f008d53db4877ccc1ef551875", "collapsed": true, "_cell_guid": "56b43633-99d9-4c3d-a863-9aa03e8e84e7"}, "source": ["test1 = np.array([np.array(eachband).reshape(75,75) for eachband in test_data[\"band_1\"]])\n", "test2 = np.array([np.array(eachband).reshape(75,75) for eachband in test_data[\"band_2\"]])"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "0f4f7b9f94d0e21be16e8e13e5ddd264d7cb8d0c", "collapsed": true, "_cell_guid": "cf19b466-f64b-492b-8fc9-04d9cea67e21"}, "source": ["Xtest = np.concatenate((test1[:,:,:,np.newaxis],test2[:,:,:,np.newaxis],((test1+test2)/2)[:,:,:,np.newaxis]),axis = -1)\n", "del test1,test2"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "4409b5f2239152d11ababb73e44c756327feaf56", "collapsed": true, "_cell_guid": "b0278112-5994-4ea9-8cfe-9c3f1d931642"}, "source": ["Xtest.shape"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "82aacf2296b9086062d3b895578326f5080fc44a", "collapsed": true, "_cell_guid": "c5be2496-8923-4a0d-9c8c-3188384c8073"}, "source": ["def findmaxindices(model,number,xtest):\n", "    test_proba = model.predict_proba(xtest)\n", "    max_indices = np.argpartition(test_proba,-number,axis=0)[-number:]\n", "    return max_indices\n", "\n", "def addthistoxtrain(indices,xtrain,xtest):\n", "    xtrain = np.append(xtrain,xtest[indices],axis=0)\n", "    return xtrain"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "2c1c90b13a209cb4522e6a6d0ef66f6ddd43cd32", "collapsed": true, "_cell_guid": "e35df7a1-c551-4506-b9ba-f30285e00622"}, "source": ["from sklearn.model_selection import train_test_split\n", "import numpy as np\n", "\n", "class Semisupervise_model(object):\n", "    \n", "    def __init__(self,model,xtest,xtrain,ytrain,percentage = 0.1,seed=69,loopstorun = 20):\n", "        self.model = model\n", "        self.percentage = percentage\n", "        self.seed = seed\n", "        self.xtest = xtest\n", "        self.xtrain = xtrain\n", "        self.ytrain = ytrain\n", "        self.loopstorun = loopstorun\n", "    \n", "    def findmaxminindices(self,xtest,extra_number = None):\n", "        \n", "        # Based on percentage given to include we are adding that many population to current existing training set\n", "        # Taking the length of training set and using percentage of that \n", "        \n", "        number = extra_number if extra_number is not None else int(self.percentage*len(self.xtrain))\n", "        \n", "        # Predicting the probablities of unlabled data using the model that we have already fit\n", "        testproba = self.model.predict_proba(xtest)\n", "        \n", "        # Find the max and min indices until the percentage we want\n", "        max_indices = np.argpartition(testproba,-number,axis=0)[-number:]\n", "        min_indices = np.argpartition(testproba,number,axis=0)[:number]\n", "        \n", "        print(\"Max indices shape is \",max_indices.shape)\n", "        print(\"Mind indices shape is \",min_indices.shape)\n", "        \n", "        return max_indices,min_indices\n", "    \n", "    def get_y(self,X):\n", "        # For a given X find the y's using the model \n", "        return self.model.predict_proba(X)\n", "    \n", "    def addthistotrain(self,indices,xtest,xtrain,ytrain):\n", "        # getting all the y's\n", "        ytest = self.get_y(xtest)\n", "        ytest = np.reshape(ytest,(ytest.shape[0],))\n", "        \n", "        # adding the min and max indices populations to xtrain and ytrain there\n", "        print(\"Ytest shape is \",ytest.shape)\n", "        print(\"Xtrain shape is\",xtrain.shape)\n", "        print(\"Xtest shape is \",xtest.shape)\n", "        print(\"Ytrain shape is \",ytrain.shape)\n", "        print(\"Indices shape is \",indices.shape)\n", "        print(\"xtest[indices] shape is\",xtest[indices].shape)\n", "        \n", "        xtrain = np.concatenate((xtrain,xtest[indices]),axis=0)\n", "        ytrain = np.concatenate((ytrain,ytest[indices]),axis=0)\n", "        ytrain[ytrain>=0.5]=1\n", "        ytrain[ytrain<0.5]=0\n", "        \n", "        print(\"################################\")\n", "        print(\"Ytest shape is \",ytest.shape)\n", "        print(\"Xtrain shape is\",xtrain.shape)\n", "        print(\"Xtest shape is \",xtest.shape)\n", "        print(\"Ytrain shape is \",ytrain.shape)\n", "        print(\"Indices shape is \",indices.shape)\n", "        print(\"xtest[indices] shape is\",xtest[indices].shape)\n", "        \n", "        return xtrain,ytrain\n", "    \n", "    def removethisfromtest(self,indices,xtest):\n", "        print(\"Now in removethisfromtest\")\n", "        print(\"indices shape is\",indices.shape)\n", "        print(\"xtest shape before removing\",xtest.shape)\n", "        indices = sorted(indices,reverse=True)\n", "        xtest=np.delete(xtest,indices,axis=0)\n", "        print(\"xtest shape after\",xtest.shape)\n", "        return xtest\n", "        \n", "        \n", "    def fit_here(self,xtest=None,xtrain=None,ytrain=None,extra_number = None):\n", "        xtest = xtest if xtest is not None else self.xtest\n", "        xtrain = xtrain if xtrain is not None else self.xtrain\n", "        ytrain = ytrain if ytrain is not None else self.ytrain\n", "        extra_number = extra_number if extra_number is not None else self.percentage\n", "        \n", "        # find the max and min indices where the predicted probablities are higher\n", "        maxindices,minindices = self.findmaxminindices(xtest,extra_number)\n", "        \n", "        # joinging both max and minindices in that given order\n", "        indices = np.concatenate((maxindices,minindices),axis=0)\n", "        \n", "        # reshaping the indices so as y dimesion will remain same\n", "        indices = np.reshape(indices,(indices.shape[0],))\n", "        \n", "        # Add the selected max and min population to the existing training set\n", "        xtrain,ytrain = self.addthistotrain(indices,xtest,xtrain,ytrain)\n", "        \n", "        # Remove the selected max and min population to the existing testing set\n", "        xtest = self.removethisfromtest(indices,xtest)\n", "        \n", "        # Split the modified training set to new sets of training and validation \n", "        xtrainnew,Xvalid,ytrainnew,Yvalid = train_test_split(xtrain,ytrain,random_state = 1,train_size = 0.75)\n", "        \n", "        # Fit the new traindata using the model we created (This model is given as input to our created instance)\n", "        self.model.fit(xtrainnew,ytrainnew,batch_size=24,epochs=50,verbose=1,validation_data=(Xvalid,Yvalid))\n", "        \n", "        return self.model,xtrain,ytrain,xtest\n", "    \n", "    def loopthefit(self,xtest = None,xtrain=None,ytrain=None):\n", "        xtrain = xtrain if xtrain is not None else self.xtrain\n", "        xtest = xtest if xtest is not None else self.xtest\n", "        ytrain = ytrain if ytrain is not None else self.ytrain\n", "        \n", "        xtrainlen = xtrain.shape[0]\n", "        xtestlen = xtest.shape[0]\n", "        count = 0\n", "        while(xtestlen>self.percentage*xtrainlen and count<self.loopstorun):\n", "            \n", "            print(\"The count running now is %d\" %count)\n", "            extra_number = int(self.percentage*xtrainlen)\n", "            \n", "            if xtestlen > extra_number:\n", "                \n", "                ## Do the process here\n", "                self.model,xtrain,ytrain,xtest = self.fit_here(xtest,xtrain,ytrain,extra_number)\n", "                model.save_weights(os.getcwd()+'\\Count_%d_modelweights.hdf5' %count)\n", "                \n", "                xtrainlen = xtrain.shape[0]\n", "                xtestlen = xtest.shape[0]\n", "                \n", "            count = count+1\n", "            \n", "        return self.model,xtrain,ytrain,count\n", "        "], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "a9984fd1314570a9a384fa6981d8dd4200366c37", "collapsed": true, "_cell_guid": "06481ae3-4f7a-4bb5-bd34-d18db7b95842"}, "source": ["testrun = Semisupervise_model(model,Xtest,Xtrain,Ytrain,percentage=0.05,seed=69,loopstorun=6)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "1e45fe3961bd0c0215b6273a82f3344227350cc9", "collapsed": true, "_cell_guid": "e839f167-3bb9-4117-8ccb-1698e41b92e8"}, "source": ["model,newxtrain,newytrain,countofsteps = testrun.loopthefit()"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"scrolled": true, "_uuid": "2dbac0ba9871afd303f0e95f345f566495cfb64d", "collapsed": true, "_cell_guid": "6420d9bf-21d3-4d3d-ad53-5bec63002c94"}, "source": ["newxtrain.shape"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "b9877bb9ea2916763ba1e5b7930aa5a1b377db89", "collapsed": true, "_cell_guid": "e5c9219a-7e46-4548-a4cf-8a4b9ecde6a6"}, "source": ["newytrain.shape"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "7399fa919de8e42c939993fb5ec88ac68e388213", "collapsed": true, "_cell_guid": "e59d09aa-6400-4668-a97a-2e56c467e6ae"}, "source": ["probs = model.predict_proba(Xtest)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "a50d4fe92c12554941ca6970391ad829f500d93c", "collapsed": true, "_cell_guid": "d0bc0235-fa6e-47c2-ab64-a48f596f7a66"}, "source": ["test_data['id'].shape"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "b9e14ee31f6d65968fd748df1e414a399ea08edf", "collapsed": true, "_cell_guid": "3b4e76ca-d231-4afc-9faf-82d900d4761b"}, "source": ["submit = pd.DataFrame()\n", "submit[\"id\"]=test_data['id']\n", "submit['is_iceberg']=probs.reshape((probs.shape[0],))\n", "submit.to_csv('sub.csv',index=False)"], "outputs": [], "cell_type": "code"}, {"execution_count": null, "metadata": {"_uuid": "dd3b11517e6c9a2051a4201d45cda585ee7af959", "collapsed": true, "_cell_guid": "8b65a21e-ff31-41fb-b493-b27170e18b67"}, "source": ["def testfunc(l,m,percentage,iterations):\n", "    count = 0\n", "    while(m>percentage*l and count < iterations):\n", "        l = int(l+percentage*l)\n", "        print(\"l is %f\",l)\n", "        if m>percentage*l:\n", "            m = int(m-percentage*l)\n", "            print(\"m is %f\",m)\n", "        count += 1\n", "    return l,m,count"], "outputs": [], "cell_type": "code"}], "nbformat_minor": 1, "nbformat": 4}