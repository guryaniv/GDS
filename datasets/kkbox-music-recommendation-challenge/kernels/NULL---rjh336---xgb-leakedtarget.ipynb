{"nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py"}}, "cells": [{"source": ["## Load in data"], "cell_type": "markdown", "metadata": {"_uuid": "3b21683f055ca7cfcc296cc93b0a51450a7c51d2", "_cell_guid": "42ab74f9-9074-41d1-8b45-cf8a6f936122"}}, {"source": ["!ls .."], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "112eadd7c03f76cd3ac349daed4abe9adbaafe8b"}}, {"source": ["import pandas as pd\n", "import numpy as np\n", "import gc\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns\n", "\n", "df_train = pd.read_csv('../input/train.csv').sample(n=3000000) # transactions\n", "df_members = pd.read_csv('../input/members.csv') # members\n", "df_songs = pd.read_csv('../input/songs.csv') \n", "song_extra = pd.read_csv('../input/song_extra_info.csv')\n", "df_songs = df_songs.merge(song_extra,how='left',on='song_id') # merge of songs and song attributes"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "0abd6f1e8e3b7372f470cc19ddcc8d1af9d59161", "ExecuteTime": {"start_time": "2017-11-20T02:57:31.623265Z", "end_time": "2017-11-20T02:57:58.114468Z"}, "_cell_guid": "6fe90306-ace9-4c0f-889a-21bb260806f0"}}, {"source": ["# Merge songs, members to the transactions data\n", "\n", "df_train = pd.merge(pd.merge(df_train, df_members, how='left', on='msno'), df_songs, how='left', on='song_id')\n", "del df_members, df_songs, song_extra; gc.collect();"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "4040164060b533d2ddaf3214861e73cfb7883075", "ExecuteTime": {"start_time": "2017-11-20T02:57:58.116811Z", "end_time": "2017-11-20T02:58:01.748687Z"}, "_cell_guid": "3921baff-d817-4fbd-b8ce-d18106d3d94f"}}, {"source": ["# Take a look at null counts and dtypes\n", "df_train.info(null_counts=True)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "bbb50ae2101b47394af0aea7ad0c2fc0a747039b", "ExecuteTime": {"start_time": "2017-11-20T02:58:01.752782Z", "end_time": "2017-11-20T02:58:02.809522Z"}}}, {"source": ["# Convert to categorical from numerics:\n", "\n", "df_train['language'] = df_train['language'].apply(str)\n", "df_train['city'] = df_train['city'].apply(str)\n", "df_train['registered_via'] = df_train['registered_via'].apply(str)\n", "df_train['genre_ids'] = df_train['genre_ids'].apply(str)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "be65fd433b80f508a4aa9d60ba23e97b9ef43f6c", "ExecuteTime": {"start_time": "2017-11-20T02:58:02.811424Z", "end_time": "2017-11-20T02:58:03.551574Z"}}}, {"source": ["## EDA and Feature Engineering"], "cell_type": "markdown", "metadata": {"_uuid": "82fb7b5ac462028adb9b681a2b4d4d3c2785b638", "_cell_guid": "fcc61912-dd6f-4675-85ee-9576e567d4ab"}}, {"source": ["### Songs"], "cell_type": "markdown", "metadata": {"_uuid": "fcd8b9503bec3d2795fa2283346ef3bf12b96a1c"}}, {"source": ["First, let's get the likelihood of a song's replay so we can correlate it to our other features."], "cell_type": "markdown", "metadata": {"_uuid": "d9cfcbf2204182783ff5fa82b0eba81a767c429b"}}, {"source": ["listens = df_train[['song_id', 'target']].groupby(['song_id']).agg(['mean','count']).reset_index()\n", "listens.columns = listens.columns.droplevel()\n", "# Because target is binary (1,0) we can take the mean of occurences to get probability\n", "listens.columns = ['song_id','mean','count']\n", "listens['replay_prob'] = listens['mean'] * listens['count']\n", "df_train = df_train.merge(listens[['song_id','replay_prob']], how='left', on='song_id')"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "8517a937c373bae64e7c203d45609d56618dd7ef", "ExecuteTime": {"start_time": "2017-11-20T02:58:03.553250Z", "end_time": "2017-11-20T02:58:05.782673Z"}}}, {"source": ["# Get the year of song release from isrc code\n", "def isrc_to_year(isrc):\n", "    if type(isrc) == str:\n", "        if int(isrc[5:7]) > 17:\n", "            return 1900 + int(isrc[5:7])\n", "        else:\n", "            return 2000 + int(isrc[5:7])\n", "    else:\n", "        return np.nan\n", "        \n", "df_train['song_year'] = pd.to_numeric(df_train.isrc.apply(isrc_to_year))\n", "df_train.song_year.hist(bins=70)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "57c574d7d1df0de424d6cbcb10ce0558023b9364", "ExecuteTime": {"start_time": "2017-11-20T02:58:05.784298Z", "end_time": "2017-11-20T02:58:07.126267Z"}}}, {"source": ["How often do certain songs, genres, artists, song languages appear in the data?"], "cell_type": "markdown", "metadata": {"_uuid": "b012b6c75053fa67b8b1f5e3efda0163fa87b3c7"}}, {"source": ["# Create popularity (counts) for appearances of songs, genres, artists, and languages\n", "\n", "popularity_features = ['song_id','genre_ids','artist_name','language']\n", "for feat in popularity_features:\n", "    pop_df = pd.DataFrame(df_train[feat].value_counts()).reset_index().rename(\n", "        columns={'index': feat, feat: feat+'_popularity'})\n", "    df_train = df_train.merge(pop_df, how='left', on=feat)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "539939529e63822be391dbf46cd7372d9e717784", "ExecuteTime": {"start_time": "2017-11-20T02:58:07.134767Z", "end_time": "2017-11-20T02:58:10.795804Z"}}}, {"source": ["fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(22,18))\n", "sns.barplot(x=\"genre_ids\", y=\"genre_ids_popularity\", data=df_train[df_train.genre_ids_popularity > 15], ax=ax1)\n", "sns.barplot(x=\"language\", y=\"language_popularity\", data=df_train, ax=ax2)\n", "plt.setp(ax1.get_xticklabels(), rotation=90)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "0dacd0279969432dcdc6ec16b639c7326cb403cc", "ExecuteTime": {"start_time": "2017-11-20T02:58:10.803220Z", "end_time": "2017-11-20T02:58:48.716373Z"}}}, {"source": ["### Members"], "cell_type": "markdown", "metadata": {"_uuid": "767cf474b68cb9c0e2bdc6bf06fab31a31e6c02e"}}, {"source": ["How often do users show up in the data? Are there some who listen to a higher volume of songs more than others?"], "cell_type": "markdown", "metadata": {"_uuid": "cac941bf42ce6de202c00a28619918be8b208e91"}}, {"source": ["# Create user song consumption feature ('msno_volume')\n", "volume = pd.DataFrame(df_train.msno.value_counts()).reset_index().rename(\n", "    columns={'index': 'msno', 'msno': 'msno_volume'})\n", "df_train = df_train.merge(volume, how='left', on='msno')\n", "del volume\n", "gc.collect()"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "75689498bf590605ef228be19c81728d0057aaa6", "ExecuteTime": {"start_time": "2017-11-20T02:58:48.717938Z", "end_time": "2017-11-20T02:58:50.140604Z"}}}, {"source": ["df_train.columns"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a342876217697384436b690c927a30a33e6ef32b", "ExecuteTime": {"start_time": "2017-11-20T02:58:50.142407Z", "end_time": "2017-11-20T02:58:50.148150Z"}}}, {"source": ["df_train.msno_volume.hist(bins=40)\n", "plt.title(\"Song Listens across KKBOX Users\")"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "b3b357322b6aa65ac8b42119d14858e0cdb4109f", "ExecuteTime": {"start_time": "2017-11-20T02:58:50.149886Z", "end_time": "2017-11-20T02:58:50.615835Z"}}}, {"source": ["How long have members been registered with KKBOX?"], "cell_type": "markdown", "metadata": {"_uuid": "05ac55d7c04deba055afa12f53b7283a0d4ae087"}}, {"source": ["# get membership length\n", "df_train.registration_init_time = pd.to_datetime(df_train.registration_init_time,format=\"%Y%m%d\")\n", "df_train.expiration_date = pd.to_datetime(df_train.expiration_date,format=\"%Y%m%d\")\n", "df_train['membership_days'] = (df_train.expiration_date - df_train.registration_init_time)\n", "df_train['membership_days'] = (df_train.membership_days/np.timedelta64(1, 'D')).astype('int')\n", "df_train['membership_days'] = df_train.membership_days.clip(lower=0)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "d48e3ea94895fc4e539774f6242ea8d648044409", "ExecuteTime": {"start_time": "2017-11-20T02:58:50.617859Z", "end_time": "2017-11-20T02:58:51.828658Z"}}}, {"source": ["df_train.membership_days.hist(bins=40)\n", "plt.title(\"Membership Days across KKBOX Users\")"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c8d8e01423ec113564c463a9d7749cfc90a5cc46", "ExecuteTime": {"start_time": "2017-11-20T02:58:51.832226Z", "end_time": "2017-11-20T02:58:52.276305Z"}}}, {"source": ["Take a look at the ages. I do not think there are many humans older than 100. If they are around I doubt they are using a streaming music service. Also, I do not think there are many infants using the service.  \n", "I am going to fill in those values with the mean of the ages (excluding invalid values)."], "cell_type": "markdown", "metadata": {"_uuid": "f5ea0a90d90450766ed95bad7a269d2d0755607c"}}, {"source": ["df_train.bd.hist(bins=40)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "cfc7fb21288380f91626a17697ac66707a3ba2c9", "ExecuteTime": {"start_time": "2017-11-20T02:58:52.278591Z", "end_time": "2017-11-20T02:58:52.777662Z"}}}, {"source": ["# There are also some obvious instances of missing data:\n", "df_train.bd[(df_train.bd > 100) | (df_train.bd < 5)].value_counts()"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "98351cd3d8aa57a9fcc2df56866c1e9d29a36c4c", "ExecuteTime": {"start_time": "2017-11-20T02:58:52.789017Z", "end_time": "2017-11-20T02:58:52.828763Z"}}}, {"source": ["# Impute missing ages\n", "age_mean = df_train[(df_train.bd > 0)&(df_train.bd < 100)].bd.mean()\n", "df_train.bd = df_train.bd.apply(lambda x: age_mean if x<=0 or x>100 else x)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "a263e21f81930971c472fa4009965a1273f22675", "ExecuteTime": {"start_time": "2017-11-20T02:58:52.839852Z", "end_time": "2017-11-20T02:58:53.739840Z"}}}, {"source": ["# That looks better\n", "df_train.bd.hist(bins=40)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "fb7d91783cea7694127511a2c9a63591d9a5fba5", "ExecuteTime": {"start_time": "2017-11-20T02:58:53.748617Z", "end_time": "2017-11-20T02:58:54.174484Z"}}}, {"source": ["exlcude_cols = ['genre_ids', 'msno', 'song_id', 'isrc', 'name', 'composer', 'lyricist', 'artist_name','language']\n", "cat_cols = [x for x in df_train.select_dtypes(include=['object']).columns if x not in exlcude_cols]\n", "cat_cols"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "162e897bfef61230851aa5879d4a5f04e591128e", "ExecuteTime": {"start_time": "2017-11-20T02:58:54.183350Z", "end_time": "2017-11-20T02:58:54.432140Z"}}}, {"source": ["fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(nrows=6, figsize=(20,55))\n", "axes=(ax1, ax2, ax3, ax4, ax5, ax6)\n", "for i, col in enumerate(cat_cols):\n", "    vc = df_train[col].value_counts().reset_index().rename(columns={col:'count','index':col})\n", "\n", "    sns.barplot(x=\"count\", y=col, data=vc, ax=axes[i], orient='h')"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "093c75381ef2d89cd5d229921f73198b17618a69", "ExecuteTime": {"start_time": "2017-11-20T02:58:54.434378Z", "end_time": "2017-11-20T02:58:58.238406Z"}}}, {"source": ["Seems we can have mutliple values separated by '|' for artist_name, genre_ids, lyricist, and composer. Is there some sort of relationship between counts of these values and the likelihood of the target?"], "cell_type": "markdown", "metadata": {"_uuid": "620b3c63d2fb73ae3b637e6b6f93ef992df655d5"}}, {"source": ["df_train[['genre_ids','composer','lyricist','artist_name']].tail()"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "176614aa329d118c368f38051a4df5315f047ef8", "ExecuteTime": {"start_time": "2017-11-20T02:58:58.239966Z", "end_time": "2017-11-20T02:58:58.282164Z"}}}, {"source": ["def count_vals(x):\n", "    # count number of values separated by '|'\n", "    if type(x) != str:\n", "        return 1\n", "    else:\n", "        return 1 + x.count('|')\n", "    \n", "df_train['number_of_genres'] = df_train['genre_ids'].apply(count_vals)\n", "df_train['number_of_composers'] = df_train['composer'].apply(count_vals)\n", "df_train['number_of_lyricists'] = df_train['lyricist'].apply(count_vals)\n", "df_train['number_of_artists'] = df_train['artist_name'].apply(count_vals)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "7596afa4f5b46b8d15e697daaba8945c1b1c5e2e", "ExecuteTime": {"start_time": "2017-11-20T02:58:58.284427Z", "end_time": "2017-11-20T02:59:00.676564Z"}}}, {"source": ["### Song and Member Interactions"], "cell_type": "markdown", "metadata": {"_uuid": "4387760a86a5c4939f8fddb846048bdcecaf7fa7"}}, {"source": ["How often do users listen to the same artists, genres, and languages?"], "cell_type": "markdown", "metadata": {"_uuid": "53a926b46c23e97e4d3ec8c93a62c6f926b48bbe"}}, {"source": ["# merge user tendencies by artist, genre, and language\n", "song_features = ['artist_name', 'genre_ids', 'language']\n", "for feature in song_features:\n", "    listens = feature+'_listens'\n", "    listens_pct = listens+'_pct'\n", "    listens_by_feat = df_train.groupby(['msno', feature]).\\\n", "                                count()['song_id'].\\\n", "                                reset_index().\\\n", "                                rename(columns={'song_id':listens})\n", "    df_train = df_train.merge(listens_by_feat,how='left',on=['msno',feature])\n", "    df_train[listens_pct] = df_train[listens] / df_train['msno_volume']\n", "    assert df_train[df_train[listens_pct] > 1].empty and df_train[df_train[listens_pct] < 0].empty\n", "    df_train.drop([listens], axis=1, inplace=True)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "9812c9cd81ba1ec1bdd0bf0d938ac4f4e70e6af2", "ExecuteTime": {"start_time": "2017-11-20T02:59:00.679326Z", "end_time": "2017-11-20T02:59:09.714593Z"}}}, {"source": ["### Correlations in the dataset\n", "Look for correlations to replay probability"], "cell_type": "markdown", "metadata": {"_uuid": "2b76ad1f69aa16e1258f75e374e66dc55807ce97"}}, {"source": ["mask = ['replay_prob', 'song_year','song_id_popularity',\n", "       'genre_ids_popularity', 'artist_name_popularity', 'language_popularity',\n", "       'msno_volume', 'membership_days', 'number_of_genres',\n", "       'number_of_composers', 'number_of_lyricists', 'number_of_artists',\n", "       'artist_name_listens_pct', 'genre_ids_listens_pct', 'language_listens_pct']\n", "\n", "df_corr = df_train[mask].fillna(0)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "93e6d19c4571c814c1403fa1d5adf7f46608fa8e", "ExecuteTime": {"start_time": "2017-11-20T02:59:09.716360Z", "end_time": "2017-11-20T02:59:09.812527Z"}}}, {"source": ["Does not look like there are any strong correlations except for the **song_id_popularity**, from which the the replay_prob is derived."], "cell_type": "markdown", "metadata": {"_uuid": "df97ccfa761603850a7cbe20d761c27bd0fca4ed"}}, {"source": ["df_corr.corr()"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "93cf3ea3cc616ff6462e6959f99ea72b49b224b7", "ExecuteTime": {"start_time": "2017-11-20T02:59:09.818380Z", "end_time": "2017-11-20T02:59:10.431386Z"}}}, {"source": ["### Categorical features"], "cell_type": "markdown", "metadata": {"_uuid": "20afbec25d4cbadb7a04263a593b0cf1eedd8451"}}, {"source": ["# Create dummies for the categorical features and merge back to transactions\n", "for c in cat_cols:\n", "    split = pd.get_dummies(df_train[c])\n", "    new_names = {i : c+str(i) for i in split.columns}\n", "    split.rename(columns = new_names, inplace=True)\n", "    df_train = df_train.merge(split,how='left',left_index=True,right_index=True)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "706a8a4484489c7a9642766ffce8c307768b1af4", "ExecuteTime": {"start_time": "2017-11-20T02:59:10.435361Z", "end_time": "2017-11-20T02:59:12.224981Z"}}}, {"source": ["df_train.shape"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c3e405a0ff48bd555a8e1061fa499b8bda0304e2", "ExecuteTime": {"start_time": "2017-11-20T02:59:12.227886Z", "end_time": "2017-11-20T02:59:12.237991Z"}}}, {"source": ["### Interactions with the target\n", "I am leaking the probability of the target class into the indogenous variables\n", "The code below counts user interactions with a given value if the target was true, divided by all of the user\u2019s interactions with that value. I then merge this feature from the training set to the test set (~ 46% songs, 70% users, 53% artists of the train set were in holdout)"], "cell_type": "markdown", "metadata": {"_uuid": "2555070437f0a46006ab5f1915541c6cfa4993db"}}, {"source": ["from sklearn.model_selection import train_test_split\n", "df_train, df_test = train_test_split(df_train, test_size=.15)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "656a79306cfb9f394a6711981e1a02c751fe74a4", "ExecuteTime": {"start_time": "2017-11-20T02:59:12.240481Z", "end_time": "2017-11-20T02:59:13.576734Z"}}}, {"source": ["# Calculate the prob(repeat) per user for a given cross feature to the train set\n", "# Then merge probs to test set\n", "crosses = ['artist_name', 'language', 'genre_ids']\n", "\n", "for feat in crosses:\n", "    cross_col = \"X_\" + 'msno' + '_' + feat\n", "    df_train[cross_col] = df_train['msno'] + df_train[feat]\n", "    df_test[cross_col] = df_test['msno'] + df_test[feat]\n", "    # Because target is binary [0,1], I can take the mean to get a\n", "    # probability of the target for the given cross feature\n", "    target_total = df_train.groupby(cross_col).mean()['target'].reset_index()\n", "    # Check to make sure probabilities are between 0 and 1\n", "    assert target_total[target_total.target > 1].empty and target_total[target_total.target < 0].empty\n", "    # Create prob columns in train and merge to test\n", "    target_total = target_total.rename(columns={'target': 'target_prob_' + feat})\n", "    df_train = df_train.merge(target_total, how='left', on=cross_col)\n", "    df_test = df_test.merge(target_total, how='left', on=cross_col)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c3f9e20ea96befe6851097dc7b6aaf317a1ac0a9", "ExecuteTime": {"start_time": "2017-11-20T02:59:13.583899Z", "end_time": "2017-11-20T02:59:31.454567Z"}, "_cell_guid": "43c8f460-226e-4805-b255-2b4629df30a4"}}, {"source": ["y_test = df_test.target\n", "X_test = df_test.loc[:,df_train.columns != 'target']\n", "\n", "y_train = df_train.target\n", "X_train = df_train.loc[:,df_train.columns != 'target']"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "a699ac1a82df73cf73fbe3aff761669c93f7d946", "ExecuteTime": {"start_time": "2017-11-20T02:59:31.460028Z", "end_time": "2017-11-20T02:59:32.702293Z"}}}, {"source": ["from sklearn.preprocessing import scale\n", "\n", "def preprocess(df_model):\n", "    # leave numerics only\n", "    df_model = df_model.select_dtypes(include=['int64', 'int32', 'float64', 'uint8']).fillna(0)\n", "    df_scaled = pd.DataFrame(scale(df_model), columns=df_model.columns)\n", "    return df_scaled"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5379958ffb8b5fe389cfc9a34384869a7e7da537", "ExecuteTime": {"start_time": "2017-11-20T02:59:32.706365Z", "end_time": "2017-11-20T02:59:32.732971Z"}, "_cell_guid": "1570f6c2-6af1-44bd-ade4-2115cff384b3"}}, {"source": ["X_test = preprocess(X_test)\n", "X_train = preprocess(X_train)\n", "\n", "del df_train, df_test; gc.collect();\n", "\n", "# Classes are fairly balanced\n", "print(\"\\nCLASS BALANCE: \")\n", "print(y_train.value_counts() / len(y_train))\n", "print(\"\\nSIZES: \")\n", "print(\"X_train: \", X_train.shape)\n", "print(\"y_train: \", y_train.shape)\n", "print(\"X_test: \", X_test.shape)\n", "print(\"y_test: \", y_test.shape)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "28f4bff847742e15e18b9a86e43b1dda30620763", "ExecuteTime": {"start_time": "2017-11-20T02:59:32.742033Z", "end_time": "2017-11-20T02:59:34.930244Z"}, "_cell_guid": "6026f736-ff75-4d8e-879a-1bbcb9b114e8"}}, {"source": ["Classes look pretty balanced. We end up with 88 features to put into our model."], "cell_type": "markdown", "metadata": {"_uuid": "83cfb51ea5cde5ec98f1907e9d7c3a83d09c7d8a"}}, {"source": ["X = pd.concat([X_train, X_test]).fillna(0)\n", "y = pd.concat([y_train, y_test]).fillna(0)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "6e940e169b0a13105105b7329251f775e968fc81", "ExecuteTime": {"start_time": "2017-11-20T02:59:34.938594Z", "end_time": "2017-11-20T02:59:35.482720Z"}, "_cell_guid": "d60ab27d-37b5-4911-82f3-b2837f390ff3"}}, {"source": ["## Modeling"], "cell_type": "markdown", "metadata": {"_uuid": "a57a2be90ab64da311e3ecc6248fdc1ab8518338", "_cell_guid": "7f4284ab-6186-47d8-8652-edde21d35cb6"}}, {"source": ["from sklearn.linear_model import SGDClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from xgboost import XGBClassifier\n", "\n", "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, KFold\n", "from sklearn.metrics import accuracy_score, roc_auc_score"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "e165f55b44df9568e96d23e2b0eb112a3ebdcc31", "ExecuteTime": {"start_time": "2017-11-20T02:59:35.488083Z", "end_time": "2017-11-20T02:59:35.779712Z"}, "_cell_guid": "f15b2636-b9db-4dfc-8792-88d89f64fe80"}}, {"source": ["models = [KNeighborsClassifier(), \n", "               LogisticRegression(),\n", "               SGDClassifier(), \n", "               RandomForestClassifier(), \n", "               XGBClassifier()]"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a691d14b4e31266673991d66c13349e58971673c", "ExecuteTime": {"start_time": "2017-11-20T02:59:35.784133Z", "end_time": "2017-11-20T02:59:35.791949Z"}}}, {"source": ["kf = KFold(n_splits=10, shuffle=True, random_state=42)\n", "step = 100\n", "for est in models:\n", "    print('\\n',est.get_params)\n", "    cv_roc = cross_val_score(est, X[::step], y[::step], scoring='roc_auc', cv=kf, n_jobs=-1)\n", "    cv_acc = cross_val_score(est, X[::step], y[::step], scoring='accuracy', cv=kf, n_jobs=-1)\n", "    print('CV ROC AUC:  ', cv_roc, np.mean(cv_roc))\n", "    print('CV Accuracy: ', cv_acc, np.mean(cv_acc))"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "1baa946a68fd331c07861c8cbb912c62d46a325c", "ExecuteTime": {"start_time": "2017-11-20T02:59:35.811238Z", "end_time": "2017-11-20T03:16:59.552177Z"}}}, {"source": ["### XGBoost"], "cell_type": "markdown", "metadata": {"_uuid": "b015c43a7b95370c3e94df035213507b739a0091", "_cell_guid": "44e33e1d-4b1a-478c-b33b-b496ceb17a0f"}}, {"source": ["def test_train_scores(model):\n", "    predictions = model.predict(X_train[::step])\n", "    auc = roc_auc_score(y_train[::step], predictions)\n", "    accuracy = accuracy_score(y_train[::step], predictions)\n", "    print(\"ROC TRAIN AUC   : \", auc)\n", "    print(\"ACCURACY  : \", accuracy)\n", "\n", "    predictions = model.predict(X_test[::step])\n", "    auc = roc_auc_score(y_test[::step], predictions)\n", "    accuracy = accuracy_score(y_test[::step], predictions)\n", "    print(\"ROC TEST  AUC   : \", auc)\n", "    print(\"ACCURACY  : \", accuracy)\n", "\n", "def plot_learning_curves(model):\n", "    # retrieve performance metrics\n", "    results = model.evals_result()\n", "    epochs = len(results['validation_0']['auc'])\n", "    x_axis = range(0, epochs)\n", "\n", "    # plot roc auc\n", "    fig, ax = plt.subplots(figsize=(10,6))\n", "    ax.plot(x_axis, results['validation_0']['auc'], label='Train')\n", "    ax.plot(x_axis, results['validation_1']['auc'], label='Test')\n", "    ax.legend()\n", "    plt.ylabel('ROC AUC')\n", "    plt.xlabel('Number of Epochs')\n", "    plt.title('XGBoost ROC AUC')\n", "    plt.show()\n", "\n", "    # plot classification error\n", "    fig, ax = plt.subplots(figsize=(10,6))\n", "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n", "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n", "    ax.legend()\n", "    plt.ylabel('Error')\n", "    plt.xlabel('Number of Epochs')\n", "    plt.title('XGBoost Classification Error')\n", "    plt.show()"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "a12afa91df0f092e0c31f6c241fbc35990c852c2", "ExecuteTime": {"start_time": "2017-11-20T03:17:41.386456Z", "end_time": "2017-11-20T03:17:41.496555Z"}, "_cell_guid": "77073086-0bf4-4735-ab63-aeee304481d0"}}, {"source": ["from scipy.stats import randint as sp_randint\n", "\n", "params = {'max_depth': [3,4,5,6],\n", "          'gamma':[15,20,30],\n", "          'subsample':[.1,.8],\n", "          'colsample_bytree':[.1,.8],\n", "          'learning_rate':sp_randint(1e-10,9e-2)\n", "          }\n", "\n", "model = RandomizedSearchCV(XGBClassifier(n_estimators=3000), \n", "                     param_distributions=params, n_jobs=1, scoring='roc_auc')"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c917c7f206e65c818b9904fcefefec3bfbb7bd9d", "ExecuteTime": {"start_time": "2017-11-20T03:17:43.680838Z", "end_time": "2017-11-20T03:17:43.694489Z"}, "_cell_guid": "999e07af-7596-4c99-a52d-b05acde44f41"}}, {"source": ["model = XGBClassifier(n_estimators=1500, learning_rate=.000000001, max_depth=3,\n", "                      gamma=5, subsample=.2, colsample_bytree=.125)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "baffc463d9f9bde5906588e0e15d01e02f81f156", "ExecuteTime": {"start_time": "2017-11-20T03:30:09.728732Z", "end_time": "2017-11-20T03:30:09.745414Z"}, "_cell_guid": "b32cf0bb-7c4f-4ab1-9ca6-4b23cf3dc7d0"}}, {"source": ["%%time\n", "step = 5\n", "eval_set = [(X_train[::step], y_train[::step]), (X_test[::step], y_test[::step])]\n", "model.fit(X_train[::step], y_train[::step], \n", "          eval_metric=['auc','error'],eval_set=eval_set, verbose=False)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "715033119c38837782fc55685db5417ba94ef2e3", "ExecuteTime": {"start_time": "2017-11-20T03:30:10.260894Z", "end_time": "2017-11-20T03:31:15.530270Z"}, "_cell_guid": "b026ff28-7533-4d13-a991-3374f449dba0"}}, {"source": ["test_train_scores(model)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "8195e1741549e9205ff323796898fa3796d24efe", "ExecuteTime": {"start_time": "2017-11-20T03:31:15.532615Z", "end_time": "2017-11-20T03:31:19.538190Z"}, "_cell_guid": "9047891c-b15e-44bb-a907-f4a22db00dd1"}}, {"source": ["plot_learning_curves(model)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "8f1dcd01a3480a4e8b2cd9be3284acac3089b5ef", "ExecuteTime": {"start_time": "2017-11-20T03:31:19.540466Z", "end_time": "2017-11-20T03:31:20.366785Z"}, "_cell_guid": "3f53d9de-e384-4469-b199-bc56ac03a375"}}, {"source": ["feat_imp = sorted(list(zip(X_train.columns, model.feature_importances_)),key=lambda tup: tup[1],reverse=True)\n", "feat_imp = pd.DataFrame(feat_imp)[:20]\n", "sns.set(style=\"whitegrid\")\n", "# Initialize the matplotlib figure\n", "f, ax = plt.subplots(figsize=(15, 10))\n", "sns.set_color_codes(\"pastel\")\n", "fi = sns.barplot(x=1, y=0, data=feat_imp, color=\"b\")\n", "ax.set(xlabel=\"Feature Importance Score\")\n", "sns.despine(left=True, bottom=True)"], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "ec06ad4e3eb8e7e8a02bdd396838ce0133f54d13", "ExecuteTime": {"start_time": "2017-11-20T03:31:57.301194Z", "end_time": "2017-11-20T03:31:57.895339Z"}, "_cell_guid": "206333d6-8189-423c-b9fa-3e8acc883bf8"}}, {"source": [], "outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "720b61f1627a860ea1db56366c206ec0650d1dcb", "_cell_guid": "fa251f7d-c24e-426b-bc7c-743ead8410c7"}}]}