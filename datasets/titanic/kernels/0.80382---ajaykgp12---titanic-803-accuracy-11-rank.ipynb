{"cells":[{"metadata":{"_kg_hide-output":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom lightgbm import LGBMClassifier\n\npd.set_option('display.max_rows', 1000)\ndebug_on = False\nrandom_state = 42\n#This program will preidc on actual data for which labels are not availible.\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e96df2b9f71089133256be8fe44f8283724b9599"},"cell_type":"code","source":"def timer_start():\n    global t0\n    t0 = time.time()\n    \n\ndef timer_end():\n    t1 = time.time()   \n    total = t1-t0\n    print('Time elapsed', total)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37023675b2605679fff3ca856f4da15316d17961","collapsed":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\nsub_df  = pd.read_csv('../input/test.csv')\nprint('Train Shape:', train_df.shape, 'test Shape', sub_df.shape)\n\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a70fe7ad6b2262afa039e3893a3ffdcf0ab71e29","collapsed":true},"cell_type":"code","source":"#Combine Train and Test data\ndata_df = train_df.append(sub_df).reset_index()\ndata_copy_df = data_df.copy()\n\ndata_df.drop(['index', 'PassengerId'], axis = 1, inplace = True)\n\ndata_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f344155db33a3d8b5ad5a6cfccacb49f2cc466ac","collapsed":true},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum().sort_values(ascending = False)\n    percent= (data.isnull().sum() * 100 / data.isnull().count() ).sort_values(ascending = False)\n    df = pd.concat([total, percent], axis = 1, keys = ['Total', 'Percent'])\n    return df[df['Total'] != 0]\nmissing_data(data_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"602275ff535a68cf682e3ef1023e133a737a8088"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ddd29f0a539afa5a99c1e5e9530af7b664b76e6","collapsed":true},"cell_type":"code","source":"def label_encode(df):\n    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n    for cat_cols in categorical_columns:\n        df[cat_cols], uniques = pd.factorize(df[cat_cols])\n    return  df, categorical_columns\n\ndata_df, categorical_columns = label_encode(data_df)\ncategorical_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb4c7b64b6a5c1e4ef2ae9db1521321083f27a35"},"cell_type":"code","source":"#The entries with -1 are null after Label Encoding, set them to null again\nfor col in categorical_columns:\n data_df[col].replace( -1 , np.NaN, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"collapsed":true},"cell_type":"code","source":"data_df[data_df['Age'] == -1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44adb578db8ab8866f96b079c59c640ce140eb35","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train  = data_df[data_df['Survived'].notnull()].copy() \ny_train =  X_train['Survived'].copy()\nX_train.drop(['Survived'], inplace =  True, axis = 1)\n\nX_sub    = data_df[data_df['Survived'].isnull()].copy()\nX_sub.drop(['Survived'], inplace =  True, axis = 1)\n\nfeatures = X_train.columns\n\nif debug_on:\n   X_train, X_test, y_train, y_test = train_test_split( X_train, y_train, test_size=0.33, random_state=42)\n   print('Train Shape:', X_train.shape, 'test Shape', X_test.shape)\nelse:     \n  print('Train Shape:', X_train.shape, 'test Shape', X_sub.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f956e4a428e624c3b0bd8811a484ac3775b158a5"},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true,"_uuid":"833c29c43573e6f7821881c0a15b035d595ce970","collapsed":true},"cell_type":"code","source":"timer_start()\nfolds = KFold(n_splits = 3, shuffle = True, random_state = random_state)\n#folds = StratifiedKFold(n_splits= 3, shuffle=True, random_state = random_state)\n\n# Since there are 5 classes crate a array with 5 cols for prediction prbabilties\noof_prob = np.zeros(shape=(X_train.shape[0],2)) \nsub_prob = np.zeros(shape=(X_sub.shape[0],2))  \ntest_prob =  np.zeros(shape=(X_test.shape[0],2))  \nfeature_importance_df = pd.DataFrame()\n\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n    train_x, train_y = X_train.iloc[train_idx],  y_train.iloc[train_idx]\n    valid_x, valid_y = X_train.iloc[valid_idx],  y_train.iloc[valid_idx]\n    \n   \n    \n    clf = LGBMClassifier(\n                        n_jobs = 4,\n                        n_estimators=10000,\n                        learning_rate = 0.1,\n                        objective = 'binary',                  \n                    #    num_leaves=  25,\n                     #   colsample_bytree= 0.672414,\n                        # min_child_samples = 38,\n                     #     subsample=  0.98233,\n                        #  subsample_freq = 50,                      \n                      #   max_depth= 9,\n                      #   reg_alpha = 0.46512,                     \n                      #   reg_lambda=  2.8242,\n                     #   min_split_gain = 0.07321,\n                     #   min_child_weight= 6.31887,\n                        silent=-1,\n                        verbose=-1,\n                      #  device_type = 'gpu',\n                        random_state  = random_state \n                        )\n\n    clf.fit( \n              train_x, \n              train_y, \n              eval_set=[(train_x, train_y), (valid_x, valid_y)], \n              eval_metric= 'binary_error',\n              verbose= 100,\n              early_stopping_rounds= 200,\n              feature_name  = 'auto',\n              #Make Sure Pandas Dataframe is used or feature_name should be provided \n              categorical_feature = categorical_columns \n               )\n    \n   \n    oof_prob[valid_idx] = clf.predict_proba(valid_x, num_iteration = clf.best_iteration_)\n    oof_pred = np.asarray([np.argmax(line) for line in oof_prob[valid_idx]])\n    \n    if debug_on:\n      \n       test_prob += clf.predict_proba(X_test, num_iteration = clf.best_iteration_) / folds.n_splits\n    else:            \n      #Average out the test set probablities\n     sub_prob += clf.predict_proba(X_sub, num_iteration = clf.best_iteration_) / folds.n_splits\n   \n    \n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df['feature'] = features.copy()\n    fold_importance_df['importance'] = clf.feature_importances_\n    fold_importance_df['fold'] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis = 0)\n    print('\\nFold %2d acuuracy: %.6f' %(n_fold + 1, accuracy_score(valid_y,  oof_pred)))\n    print('Fold %2d error: %.6f' %(n_fold + 1, 1 - accuracy_score(valid_y,  oof_pred)))\n    \n\n\nprint('Number of folds:', folds.n_splits )\n\noof_pred = np.asarray([np.argmax(line) for line in oof_prob])\nif debug_on:\n    print(\"\\nTraining Data Shape\", X_train.shape, \"Test Data Shape\", X_test.shape) \n    test_pred = np.asarray([np.argmax(line) for line in test_prob])\nelse:    \n  print(\"\\nTraining Data Shape\", X_train.shape, \"Test Data Shape\", X_sub.shape) \n  sub_pred = np.asarray([np.argmax(line) for line in sub_prob])\n\nprint('\\nFull Cross Validation accuracy %.6f' %accuracy_score(y_train, oof_pred))  \nprint('Full Cross Validation error %.6f' %(1 -accuracy_score(y_train, oof_pred)))    \n\nif debug_on:\n   print('\\nTest accuracy %.6f' %accuracy_score(y_test, test_pred)) \n   lgb_prob =  test_prob\nelse:  \n    sub_df['Survived'] = sub_pred\n    sub_df[['PassengerId', 'Survived' ]].to_csv('lgb_sub.csv', index = False)\n\n\ntimer_end()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}