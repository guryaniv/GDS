{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "08a048c4-d7d4-0228-8c99-d59c13061555"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "054a80f2-9810-685e-7a27-161b8cf07833"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "df = pd.read_csv(\"../input/train.csv\",nrows=200)\n",
        "#df = pd.read_csv(\"../input/train.csv\",nrows = 20000)\n",
        "df = df.dropna()\n",
        "\n",
        "#from subprocess import check_output\n",
        "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "831f88cc-6290-2bbd-3d17-9f55c7efaf4e"
      },
      "source": [
        "Document term matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b81fb526-5f39-bac7-b3e8-d0ddc5ddedd7"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "words = re.compile(r\"\\w+\",re.I)\n",
        "stopword = stopwords.words('english')\n",
        "#stemmer = PorterStemmer()\n",
        "\n",
        "def tokenize(df):\n",
        "    q1 = []\n",
        "    q2 = []\n",
        "    for q in df.question1.tolist():\n",
        "        q1.append([(i.lower()) for i in words.findall(q) if i not in stopword])\n",
        "    for q in df.question2.tolist():\n",
        "        q2.append([(i.lower()) for i in words.findall(q) if i not in stopword])\n",
        "    df[\"q1_tokens\"] = q1\n",
        "    df[\"q2_tokens\"] = q2\n",
        "    return df\n",
        "\n",
        "def train_dictionary(df):\n",
        "    q_tokens = df.q1_tokens.tolist() + df.q2_tokens.tolist()\n",
        "    dictionary = corpora.Dictionary(q_tokens)\n",
        "    return dictionary\n",
        "    \n",
        "df = tokenize(df)\n",
        "dictionary = train_dictionary(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96cceff5-f0ac-1069-c485-6fc281fd0185"
      },
      "outputs": [],
      "source": [
        "def get_vectors(df, dictionary):\n",
        "    \n",
        "    question1_vec = [dictionary.doc2bow(text) for text in df.q1_tokens.tolist()]\n",
        "    question2_vec = [dictionary.doc2bow(text) for text in df.q2_tokens.tolist()]\n",
        "    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n",
        "    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n",
        "    return question1_csc.transpose(),question2_csc.transpose()\n",
        "q1_csc, q2_csc = get_vectors(df, dictionary)\n",
        "\n",
        "print (q1_csc.shape)\n",
        "print (q2_csc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c902d1c6-3899-69ec-ca08-66d1d73a036b"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
        "from sklearn.metrics.pairwise import manhattan_distances as md\n",
        "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
        "from sklearn.metrics import jaccard_similarity_score as jsc\n",
        "from sklearn.neighbors import DistanceMetric\n",
        "\n",
        "minkowski_dis = DistanceMetric.get_metric('minkowski')\n",
        "\n",
        "def get_similarity_values(q1_csc, q2_csc):\n",
        "    cosine_sim = []\n",
        "    manhattan_dis = []\n",
        "    eucledian_dis = []\n",
        "    jaccard_dis = []\n",
        "    minkowsk_dis = []\n",
        "    \n",
        "    for i,j in zip(q1_csc, q2_csc):\n",
        "        sim = cs(i,j)\n",
        "        cosine_sim.append(sim[0][0])\n",
        "        sim = md(i,j)\n",
        "        manhattan_dis.append(sim[0][0])\n",
        "        sim = ed(i,j)\n",
        "        eucledian_dis.append(sim[0][0])\n",
        "        x = i.toarray()\n",
        "        y = j.toarray()\n",
        "        try:\n",
        "            sim = jsc(x,y)\n",
        "            jaccard_dis.append(sim)\n",
        "        except:\n",
        "            jaccard_dis.append(0)\n",
        "            \n",
        "        sim = minkowski_dis.pairwise(x,y)\n",
        "        minkowsk_dis.append(sim[0][0])\n",
        "    \n",
        "    return cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis    \n",
        "\n",
        "cosine_sim, manhattan_dis, eucledian_dis, jaccard_dis, minkowsk_dis = get_similarity_values(q1_csc, q2_csc)\n",
        "\n",
        "df[\"cosine\"] = cosine_sim\n",
        "df[\"manhattan\"] = manhattan_dis\n",
        "df[\"eucledian\"] = jaccard_dis\n",
        "df[\"minkowsk\"] = minkowsk_dis\n",
        "df[\"jaccard\"] = jaccard_dis\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8ce24f5-166a-82ac-7170-d9b25a888ba4"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import tree\n",
        "reg = linear_model.LogisticRegression()\n",
        "svc = SVC()\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "df_train, df_test = train_test_split(df, test_size = 0.3)\n",
        "ytrain = df_train[\"is_duplicate\"]\n",
        "ytest = df_test[\"is_duplicate\"]\n",
        "#print(df_train.head())\n",
        "xtrain = df_train.ix[:,'cosine':]\n",
        "xtest = df_test.ix[:,'cosine':]\n",
        "#print(xtrain.head())\n",
        "lr_model=reg.fit(np.array(xtrain), np.array(ytrain))\n",
        "svc_model = svc.fit(np.array(xtrain),np.array(ytrain))\n",
        "dt_model = dt.fit(np.array(xtrain),np.array(ytrain))\n",
        "\n",
        "Ypred_lr=lr_model.predict(np.array(xtest))\n",
        "Ypred_svc = svc_model.predict(np.array(xtest))\n",
        "Ypred_dt = dt_model.predict(np.array(xtest))\n",
        "\n",
        "accuracy_lr=accuracy_score(ytest, Ypred_lr)\n",
        "accuracy_svc = accuracy_score(ytest,Ypred_svc)\n",
        "accuracy_dt = accuracy_score(ytest,Ypred_dt)\n",
        "\n",
        "print(\"Accuracy of logistic model\",accuracy_lr)\n",
        "print(\"Accuracy of SVM model\", accuracy_svc)\n",
        "print(\"Accuracy of decision tree classifier model\", accuracy_dt)\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}