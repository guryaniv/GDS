{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"# Accelerating XGboost with GPU\n\nThis kernel uses the Xgboost models, running on CPU and GPU. With the GPU acceleration, we gain a ~8.5x performance improvement on an NVIDIA K80 card compared to the 2-core virtual CPU available in the Kaggle VM (1h 8min 46s vs. 8min 20s).\n\nThe gain on a NVIDIA 1080ti card compared to an Intel i7 6900K 16-core CPU is ~6.6x.\n\nTo turn GPU support on in Kaggle, in notebook settings, set the **GPU beta** option to \"GPU on\".\n\n## Notebook  Content\n1. [Loading the data](#0) <br>    \n1. [Training the model on CPU](#1)\n1. [Training the model on GPU](#2)\n1. [Submission](#3)\n"},{"metadata":{"trusted":true,"_uuid":"a73bddfe08a63414f7dc32ed7cfb82a1a67bfd0d"},"cell_type":"markdown","source":"<a id=\"0\"></a>\n## 1. Loading the data"},{"metadata":{"trusted":true,"_uuid":"e1771b340495c4e7ca3baaa2736011f55b29b6cd"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nimport gc\nimport xgboost as xgb\n\npd.set_option('display.max_columns', 200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19539c2630225e76c85a11268f6629abaabd0a15"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv', engine='python')\ntest_df = pd.read_csv('../input/test.csv', engine='python')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f0bf935dbfd40912360038f626f746f1c67ecbd"},"cell_type":"markdown","source":"<a id=\"1\"></a> \n## 2. Training the model on CPU"},{"metadata":{"trusted":true,"_uuid":"7d502e4dbd21c35300c3e2e25b761d4ed1fa3034"},"cell_type":"code","source":"import subprocess\nprint((subprocess.check_output(\"lscpu\", shell=True).strip()).decode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"649fba8696c1cd36d64f5a05dfbb9219f4a276d8"},"cell_type":"code","source":"MAX_TREE_DEPTH = 8\nTREE_METHOD = 'hist'\nITERATIONS = 1000\nSUBSAMPLE = 0.6\nREGULARIZATION = 0.1\nGAMMA = 0.3\nPOS_WEIGHT = 1\nEARLY_STOP = 10\n\nparams = {'tree_method': TREE_METHOD, 'max_depth': MAX_TREE_DEPTH, 'alpha': REGULARIZATION,\n          'gamma': GAMMA, 'subsample': SUBSAMPLE, 'scale_pos_weight': POS_WEIGHT, 'learning_rate': 0.05, \n          'silent': 1, 'objective':'binary:logistic', 'eval_metric': 'auc', 'silent':True, \n          'verbose_eval': False}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ae730641e1325ce2b14cedf4c83891596362f18"},"cell_type":"code","source":"%%time\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ntarget = 'target'\npredictors = train_df.columns.values.tolist()[2:]\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nFold {}\".format(i))\n    xg_train = xgb.DMatrix(train_df.iloc[train_index][predictors].values,\n                           train_df.iloc[train_index][target].values,                           \n                           )\n    xg_valid = xgb.DMatrix(train_df.iloc[valid_index][predictors].values,\n                           train_df.iloc[valid_index][target].values,                           \n                           )   \n\n    \n    clf = xgb.train(params, xg_train, ITERATIONS, evals=[(xg_train, \"train\"), (xg_valid, \"eval\")],\n                early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n    oof[valid_index] = clf.predict(xgb.DMatrix(train_df.iloc[valid_index][predictors].values)) \n    \n    predictions += clf.predict(xgb.DMatrix(test_df[predictors].values)) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87c975ec4ea6ecec76cd5c2e4844b94d0df9718c"},"cell_type":"markdown","source":"<a id=\"2\"></a>\n## 3. Training the model on GPU"},{"metadata":{"trusted":true,"_uuid":"ee953dedb4c497a50057d937389e94c47871ce16"},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e89590ef3fdc4315ae8b1d3741dace5e9ca5d574"},"cell_type":"markdown","source":"We now train the model with a K80 GPU available in Kaggle. Xgboost provides out of the box support for single GPU training. On a local workstation, a GPU-ready xgboost docker image can be obtained from https://hub.docker.com/r/rapidsai/rapidsai/.\n\nAll we need to change is to set: `TREE_METHOD = 'gpu_hist'`"},{"metadata":{"trusted":true,"_uuid":"0c89daed3e0b04e19494b4e82ed6e8b6a65593e4"},"cell_type":"code","source":"MAX_TREE_DEPTH = 8\nTREE_METHOD = 'gpu_hist'\nITERATIONS = 1000\nSUBSAMPLE = 0.6\nREGULARIZATION = 0.1\nGAMMA = 0.3\nPOS_WEIGHT = 1\nEARLY_STOP = 10\n\nparams = {'tree_method': TREE_METHOD, 'max_depth': MAX_TREE_DEPTH, 'alpha': REGULARIZATION,\n          'gamma': GAMMA, 'subsample': SUBSAMPLE, 'scale_pos_weight': POS_WEIGHT, 'learning_rate': 0.05, \n          'silent': 1, 'objective':'binary:logistic', 'eval_metric': 'auc',\n          'n_gpus': 1}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fec2a76b4c1eccfe2fdd3b8a253d46697eb3ce3"},"cell_type":"code","source":"%%time\nnfold = 5\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(train_df))\npredictions = np.zeros(len(test_df))\n\ntarget = 'target'\npredictors = train_df.columns.values.tolist()[2:]\n\ni = 1\nfor train_index, valid_index in skf.split(train_df, train_df.target.values):\n    print(\"\\nFold {}\".format(i))\n    xg_train = xgb.DMatrix(train_df.iloc[train_index][predictors].values,\n                           train_df.iloc[train_index][target].values,                           \n                           )\n    xg_valid = xgb.DMatrix(train_df.iloc[valid_index][predictors].values,\n                           train_df.iloc[valid_index][target].values,                           \n                           )   \n\n    \n    clf = xgb.train(params, xg_train, ITERATIONS, evals=[(xg_train, \"train\"), (xg_valid, \"eval\")],\n                early_stopping_rounds=EARLY_STOP, verbose_eval=False)\n    oof[valid_index] = clf.predict(xgb.DMatrix(train_df.iloc[valid_index][predictors].values)) \n    \n    predictions += clf.predict(xgb.DMatrix(test_df[predictors].values)) / nfold\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.2f}\".format(metrics.roc_auc_score(train_df.target.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"031837dea84fdf5b0569ed5fa5ae7781569fe27b"},"cell_type":"markdown","source":"<a id=\"3\"></a>\n## 4. Submission"},{"metadata":{"trusted":true,"_uuid":"e6443da861b9f289f8733a04e9c809652efa8187"},"cell_type":"code","source":"sub_df = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\nsub_df[\"target\"] = predictions\nsub_df[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cb882db44e8c31b9075f342f975cb20a122ce05"},"cell_type":"code","source":"sub_df.to_csv(\"xgboost_gpu.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cafc8a0ecc209766bfcfb4056aba0277b7ec930"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}