{"cells":[{"metadata":{"_uuid":"ae6552c692c730ccd19e477eb16f9464be8f247c"},"cell_type":"markdown","source":"Hello there,  this is my first kernel ever in Kaggle. So I will be happy to get any suggestions from you.\n\nI have used LightGBM Classifier for the classification. This is all what I have done untill now:\n* Replaced NaN values with 0\n* Dropped object type columns for time being\n* Used Class weights to cater the class imbalance problem\n* Leaderboard score is **0.415**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\ntest_Id = test_df['Id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"15a9566b41e93c6c7b7e5539113f95e636f08cb0"},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e67ed5a28f30563911d693f0c166f771ec16d50a"},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8f5aacc6528b3af21149aabd431c25d60c0d838","collapsed":true},"cell_type":"code","source":"print (train_df.shape, test_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c7cc9d50091324455529bfa75cc5819c329670a1"},"cell_type":"code","source":"# lets bar plot to see the frequencies of targets\ntrain_df['Target'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"93b7152db042bde81b14b6c34091e1b9959216b2"},"cell_type":"code","source":"def preprocess(train_df, test_df, dropna = False, drop_obtype = True, replace_nan_with = 0, return_with_top100 = False, lgbfactor = 0):\n\n    train_df.drop(columns = ['Id'],inplace = True, errors=\"ignore\")\n    test_df.drop(columns = ['Id'], inplace = True, errors = \"ignore\")\n    nanvalues = train_df.isnull().sum(axis = 0).values\n    nullvalues = pd.DataFrame({\"Column\":train_df.columns, \"Count\":nanvalues})\n    nullvalues.sort_values(by=[\"Count\"], ascending = False, inplace = True)\n    #nullvalues.head()\n    nancols = nullvalues[nullvalues['Count']>0][\"Column\"].values.tolist()\n    \n    # columns with object type. We are dropping them for time being.\n    objcols = train_df[train_df.columns[(train_df.dtypes == 'object').values]].columns.values.tolist()\n    \n    if (drop_obtype == True):\n        train_df.drop(columns = objcols,inplace = True)\n        test_df.drop(columns = objcols,inplace = True)\n    if (dropna == True):\n        train_df.drop(columns = nancols, inplace = True)\n        test_df.drop(columns = nancols, inplace = True)\n    if (dropna == False):\n        train_df.replace(np.nan, replace_nan_with, inplace = True)\n        test_df.replace(np.nan, replace_nan_with, inplace = True)\n    \n    \n    labels = train_df['Target']\n    train_df.drop(columns = ['Target'],inplace = True, errors=\"ignore\")\n\n    \n    # Below we use Random Forest to select top 100 columns. Actually in LightGBM classifier I pass all features.\n    from sklearn.ensemble import RandomForestClassifier\n    rfc = RandomForestClassifier()\n    rfc.fit(train_df, labels)\n    \n    scores = rfc.feature_importances_.tolist()\n    report = pd.DataFrame({\"feature\":train_df.columns, \"score\":scores})\n    report.sort_values(by = [\"score\"],ascending = False, inplace = True)\n    top100cols = report.head(100)['feature'].values.tolist()\n    \n    \n    if (return_with_top100 == True):\n        train_df = train_df[top100cols]\n        test_df = test_df[top100cols]\n    \n    # Since the classes are imbalance. We need to give weights to each class and pass this parameter in LightGBM classifier.\n    from sklearn.utils import class_weight\n    class_weights = class_weight.compute_class_weight('balanced',\n                                                     np.unique(labels),\n                                                     labels)\n    # You might be wondering what is lgbfactor here. Actually LightGBM takes labels starting from 0 i.e 0,1,2,3 instead of 1,2,3,4\n    # so we have to subtract 1 from labels while we use LightGBM.\n    # Note that while submitting the predictions, we have to add 1 again to the predictions so that our labels are from 1,2,3,4\n    class_weights = dict(zip(np.unique(labels.values-lgbfactor), class_weights))\n    \n    \n    return train_df, test_df, labels, nancols, objcols, report, top100cols, class_weights\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f40b7cbc5b445e0887a06a3c50792dcd451d4483","collapsed":true},"cell_type":"code","source":"train, test, labels, nancols,objcols, report, top100cols, class_weightss = preprocess(train_df.copy(), test_df.copy(),dropna = False, lgbfactor = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21428400967102070a1e5e85b87d00cb24963c66","collapsed":true},"cell_type":"code","source":"print (train.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f66806199f339954c89bd128119ec93e5aebf9d0"},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1a4c6d3c026a45208188080bd3bb4b99988f234b"},"cell_type":"code","source":"import lightgbm as lgb\nimport sklearn.model_selection as model_selection\nfrom sklearn.metrics import f1_score, make_scorer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32ea832c18ff7fff7519b6a30b46ae73d729e009","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9cf4c4332813558661460a33403ec95b638a63a","collapsed":true},"cell_type":"code","source":"lgmodel = lgb.LGBMClassifier(class_weight=class_weightss, metric = \"multi_logloss\",num_class = 4)\n#rf_classif = RandomForestClassifier()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ab7a4d3646adaa60631cc0b1076f39883db68432"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d8801994fcc5194df798c062941f910a460e98a0"},"cell_type":"code","source":"def get_score(model, train, label, fold):\n    score = model_selection.cross_val_score(model, train , label, cv = fold, scoring = make_scorer(f1_score, average = \"macro\"))\n    return score.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fc8cc22dfc3e5862fe05332aad493a093f951b5","collapsed":true},"cell_type":"code","source":"kf = model_selection.KFold(n_splits=5, shuffle=True,random_state=2017)\ntemplabel = labels.loc[train['parentesco1']==1]\ntemptrain = train[train['parentesco1']==1]\nheads_scores = get_score(lgmodel, temptrain, templabel-1, kf) # subtract 1 because of LightGBM, remember the expalantion above 0,1,2,3\noverall_scores = get_score(lgmodel, train, labels-1, kf) # subtract 1 because of LightGBM, remember the expalantion above 0,1,2,3\nprint (\"Heads mean score:\",heads_scores.mean())\nprint (\"Overall mean score:\",overall_scores.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea79f33c92bca0e9b297437ad130c2e956f28b3d","collapsed":true},"cell_type":"code","source":"lgmodel.fit(train, labels-1)\nlgpreds = lgmodel.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b4ae6bb037ca1195db95702cd5dab6ac4a49b66","collapsed":true},"cell_type":"code","source":"# Making a submission file #\nsub_df = pd.DataFrame({\"Id\":test_Id.values})\nsub_df[\"Target\"] = lgpreds + 1 # ----------> note here we add 1 to the predictions making the predictions start from 1\nsub_df.to_csv(\"LightGBM.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c2141ea0e38bbf380718185add39ba3787afd3cd"},"cell_type":"markdown","source":"**I know there is still much work remaining like Preprocessing, feature selection, feature engineering, one hot encoding the object type columns.**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b0d2527f9716d85054f2ec60f303789f4f908d08"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}