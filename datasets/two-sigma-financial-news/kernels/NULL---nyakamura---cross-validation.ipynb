{"cells":[{"metadata":{"_uuid":"28f22f01fe854ef209669a33db45bd58190e2036"},"cell_type":"markdown","source":"# Cross Validation"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"# import libraries\nimport gc\nimport time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn import *\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\nfrom kaggle.competitions import twosigmanews","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e089957dd17b0c5b4fb1816987d1c62a28ba2a38","_kg_hide-output":true},"cell_type":"code","source":"env = twosigmanews.make_env()\n(market_train, news_train) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2dad9717c953f794c179d40f4729e5f92dfd829","_kg_hide-input":false},"cell_type":"code","source":"def data_prep(market_train, news_train):\n    '''\n    Data prepararion function\n    Input: \n        - market_train\n        - news_train\n    Output:\n        - merged_train\n            - # include following columns\n            - 'assetCode', 'time', 'firstCreated', 'returnsOpenNextMktres10', 'universe'\n    '''\n    market_train.time = market_train.time.dt.date\n    news_train.time = news_train.time.dt.hour\n    news_train.sourceTimestamp= news_train.sourceTimestamp.dt.hour\n    news_train.firstCreated = news_train.firstCreated.dt.date\n    news_train['assetCodesLen'] = news_train['assetCodes'].map(lambda x: len(eval(x)))\n    news_train['assetCodes'] = news_train['assetCodes'].map(lambda x: list(eval(x))[0])\n    kcol = ['firstCreated', 'assetCodes']\n    news_train = news_train.groupby(kcol, as_index=False).mean()\n    merged_train = pd.merge(market_train, news_train, how='left',\n                            left_on=['time', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n    lbl = {k: v for v, k in enumerate(merged_train['assetCode'].unique())}\n    merged_train['assetCodeT'] = merged_train['assetCode'].map(lbl)\n    \n    merged_train = merged_train.dropna(axis=0)\n    \n    fcol = [\n        c\n        for c in merged_train\n        if c not in ['assetCodes', 'assetCodesLen', 'assetName', 'audiences',\n                     'headline', 'headlineTag', 'marketCommentary', 'provider',\n                     'sourceId', 'subjects', 'time_x', 'sourceTimestamp']]\n\n    gc.collect()\n    return merged_train[fcol]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca54a4bd80889b3693ad124190a2fda688b53ea5"},"cell_type":"code","source":"def generate_x(df):\n    # Remove columns not to use to learning\n    x_columns = [\n        c\n        for c in df\n        if c not in ['assetCode', 'time', 'firstCreated',\n                     'returnsOpenNextMktres10', 'universe']]\n    x = df[x_columns].values\n    \n    # Scaling of X values\n    # It is good to keep these scaling values for later\n    mins = np.min(x, axis=0)\n    maxs = np.max(x, axis=0)\n    rng = maxs - mins\n    x = 1 - ((maxs - x) / rng)\n\n    return x, x_columns    \n\n\ndef data_split(x, y, r, u, index, size=0.25):\n    if len(x) == len(y) == len(r) == len(u) ==len(index):\n        length = len(x)\n    return (\n        x[:round(length * (1-size))],\n        x[round(length * (1-size)):],\n        y[:round(length * (1-size))],\n        y[round(length * (1-size)):],\n        r[:round(length * (1-size))],\n        r[round(length * (1-size)):],\n        u[:round(length * (1-size))],\n        u[round(length * (1-size)):],\n        index[:round(length * (1-size))],\n        index[round(length * (1-size)):]\n    )\n    \ndef format_cv_test_train(df):\n    x, x_columns = generate_x(df)\n    y = (df.returnsOpenNextMktres10 >= 0).values\n    r = df.returnsOpenNextMktres10.values\n    u = df.universe.values\n    index = df[['firstCreated', 'assetCode']].values\n\n    # Check data shape\n    assert x.shape[0] == y.shape[0] == r.shape[0] == u.shape[0]\n    train_x, test_x, train_y, test_y, train_r, test_r, train_u, test_u, train_index, test_index = \\\n        data_split(x, y, r, u, index, 0.25)\n    #         model_selection.train_test_split(x, y, r, u, index, test_size=0.25, random_state=99)\n    \n    test_y_template = pd.DataFrame(test_index, columns=['time', 'assetCode'])\n    test_y_template.loc[:, 'confidenceValue'] = 0\n\n    return train_x, train_y, train_r, train_u, test_x, test_y, test_r, test_u, x_columns, test_y_template","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c560bcf6eaee278e1ddf52d949c2b065cfbe321"},"cell_type":"code","source":"def calculate_score(y_df, r, u=None):\n    ndf = y_df.copy()\n    ndf.loc[:, 'r'] = r\n    if u is not None:\n        ndf.loc[:, 'u'] = u\n    else:\n        ndf.loc[:, 'u'] = 1\n    ndf.loc[:, 'x'] = ndf.confidenceValue * ndf.r * ndf.u\n    xt = ndf.loc[ndf.loc[:, 'r'] <= 1000, :].groupby('time').x.sum()\n    score = np.mean(xt) / np.std(xt)\n    del ndf, xt\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dff38dc6d73fbea62c9b9a92d65e956e5d6a2c3f"},"cell_type":"code","source":"train_df = data_prep(market_train,news_train)\n\ntrain_x, train_y, train_r, train_u, test_x, test_y, test_r, test_u, x_columns, test_y_template = \\\n    format_cv_test_train(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5523094226fce884c6e8ae7f10f8bdcc087b9391"},"cell_type":"code","source":"# Fitting\nxgb_up = XGBClassifier(n_jobs=4,n_estimators=200,max_depth=8,eta=0.1)\nt = time.time()\nprint('Fitting Up')\nxgb_up.fit(train_x, train_y)\nprint(f'Done, time = {time.time() - t}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a68e7c3688f19951ba9d8bb629951ff6fc3aac5"},"cell_type":"code","source":"# Predict and calculate accuracy\npred_y = xgb_up.predict(test_x)\naccuracy = metrics.accuracy_score(pred_y, test_y)\nprint(f'Accuracy: {accuracy}')\n\npred_proba = xgb_up.predict_proba(test_x)\ntest_y_template.confidenceValue = 2 * pred_proba[:,1] - 1\nscore = calculate_score(test_y_template, test_r, test_u)\n# score = calculate_score(test_y_template, test_r, None)\nprint(f'Score: {score}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccf3a60f29450d31486f1a9353465726e08e4881"},"cell_type":"code","source":"# Visualize feature importance\n%matplotlib inline\nplt.figure(num=None, figsize=(10, 10), dpi=80, facecolor='w', edgecolor='k')\nplt.bar(range(len(xgb_up.feature_importances_)), xgb_up.feature_importances_)\nplt.xticks(range(len(xgb_up.feature_importances_)), x_columns, rotation='vertical');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abadf314080975a9df44a3d4bae5495b435fe2cd"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}