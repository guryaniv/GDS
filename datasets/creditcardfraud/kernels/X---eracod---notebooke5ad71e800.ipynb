{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9d8b2025-4188-5586-df07-a332f3bb3bfb"
      },
      "source": [
        "> Blockquote\n",
        "\n",
        "**This is my final project for Kaggle Decal. It focuses on detecting credit card fraud using the provided dataset. I have always had a strong interest in exploring this field through applications of Data Science.** \n",
        "\n",
        "**Here, I will test different methods that we have learned in class and apply them to compare which technique works better. I will mainly be using:** \n",
        "\n",
        " 1. Logistic Regression \n",
        " 2. SVMs  \n",
        " 3. Decision Trees\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "673e1e2e-7c4d-0386-ca53-74bc6ea3385f"
      },
      "outputs": [],
      "source": [
        "#Loading packages..\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a31341a-7920-4831-e7cb-7424888e806a"
      },
      "outputs": [],
      "source": [
        "#Loading dataset...\n",
        "\n",
        "data = pd.read_csv(\"../input/creditcard.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8309df69-70fc-d87c-9b1d-9f66ddf7113d"
      },
      "outputs": [],
      "source": [
        "#Exploring our data\n",
        "\n",
        "df = pd.read_csv(\"../input/creditcard.csv\")\n",
        "df.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e138a9a5-acfd-63da-0bb2-a4d8cdbc0845"
      },
      "outputs": [],
      "source": [
        "#more..\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09d7af3d-0891-25f9-ab5e-6e3a70576585"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c5f149e-420d-c5f9-18da-93da7d898e2c"
      },
      "outputs": [],
      "source": [
        "#Narrowing down to our specific data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "159072ed-8055-1473-ffb4-304cbd450442"
      },
      "outputs": [],
      "source": [
        "#how it compares to normal transactions\n",
        "\n",
        "print (\"Fraud\")\n",
        "print (df.Time[df.Class == 1].describe())\n",
        "print ()\n",
        "print (\"Normal\")\n",
        "print (df.Time[df.Class == 0].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "838c9a2e-733b-c562-751b-a2a1f38c72fb"
      },
      "outputs": [],
      "source": [
        "#targeted classes\n",
        "\n",
        "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
        "count_classes.plot(kind = 'bar')\n",
        "plt.title(\"Fraud class histogram\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5974381-c852-4ab4-77d0-3e5418bd40d2"
      },
      "outputs": [],
      "source": [
        "#as we can see, this is unbalanced. we can't classifly all \"1s\" incorrectly\n",
        "#downgraded in order to contain 30 features (28 anonamised + time + amount).\n",
        "#what happens when using resampling and when not using it. \n",
        "#We will test this using a simple logistic regression classifier.\n",
        "#evaluate models and compare\n",
        "#finally perform classifications model\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1))\n",
        "data = data.drop(['Time','Amount'],axis=1)\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b17115bd-7cf2-7290-c51b-e72d201ab162"
      },
      "outputs": [],
      "source": [
        "X = data.ix[:, data.columns != 'Class']\n",
        "y = data.ix[:, data.columns == 'Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e43cdb2f-b2b0-3c0c-3896-399bda2b39ff"
      },
      "outputs": [],
      "source": [
        "# Minority class\n",
        "number_records_fraud = len(data[data.Class == 1])\n",
        "fraud_indices = np.array(data[data.Class == 1].index)\n",
        "\n",
        "# Normal classes indices\n",
        "normal_indices = data[data.Class == 0].index\n",
        "\n",
        "# Randomly select \"x\" number (number_records_fraud)\n",
        "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace = False)\n",
        "random_normal_indices = np.array(random_normal_indices)\n",
        "\n",
        "# Appending the 2 indices\n",
        "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
        "\n",
        "# Under sample dataset\n",
        "under_sample_data = data.iloc[under_sample_indices,:]\n",
        "\n",
        "X_undersample = under_sample_data.ix[:, under_sample_data.columns != 'Class']\n",
        "y_undersample = under_sample_data.ix[:, under_sample_data.columns == 'Class']\n",
        "\n",
        "# Showing ratio\n",
        "print(\"Percentage of normal transactions: \", len(under_sample_data[under_sample_data.Class == 0])/len(under_sample_data))\n",
        "print(\"Percentage of fraud transactions: \", len(under_sample_data[under_sample_data.Class == 1])/len(under_sample_data))\n",
        "print(\"Total number of transactions in resampled data: \", len(under_sample_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e61e9510-c716-cfdd-8041-c6f347f186a0"
      },
      "outputs": [],
      "source": [
        "#Splitting data. Cross validation\n",
        "\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "# import whole dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n",
        "\n",
        "print(\"Number transactions train dataset: \", len(X_train))\n",
        "print(\"Number transactions test dataset: \", len(X_test))\n",
        "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
        "\n",
        "# Undersampled dataset\n",
        "X_train_undersample, X_test_undersample, y_train_undersample, y_test_undersample = train_test_split(X_undersample\n",
        "                                                                                                   ,y_undersample\n",
        "  #PS: we are using train and test set                                                                                                 ,test_size = 0.3\n",
        "                                                                                                   ,random_state = 0)\n",
        "print(\"\")\n",
        "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
        "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
        "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))\n",
        "/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "991c0fa2-5a84-a1e5-3d0a-6354ca047844"
      },
      "outputs": [],
      "source": [
        "#Logistic regression application\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cross_validation import KFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5678bcab-cc98-f659-f655-b66cb77fb8ed"
      },
      "outputs": [],
      "source": [
        "def printing_Kfold_scores(x_train_data,y_train_data):\n",
        "    fold = KFold(len(y_train_data),5,shuffle=False) \n",
        "\n",
        "    # Different C parameters\n",
        "    c_param_range = [0.01,0.1,1,10,100]\n",
        "\n",
        "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
        "    results_table['C_parameter'] = c_param_range\n",
        "\n",
        "    # the k-fold will give 2 lists: train_indices = indices[0], test_indices = indices[1]\n",
        "    j = 0\n",
        "    for c_param in c_param_range:\n",
        "        print('-------------------------------------------')\n",
        "        print('C parameter: ', c_param)\n",
        "        print('-------------------------------------------')\n",
        "        print('')\n",
        "\n",
        "        recall_accs = []\n",
        "        for iteration, indices in enumerate(fold,start=1):\n",
        "\n",
        "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
        "\n",
        "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:].values.ravel())\n",
        "\n",
        "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:].values)\n",
        "\n",
        "            # Calculate\n",
        "            recall_acc = recall_score(y_train_data.iloc[indices[1],:].values,y_pred_undersample)\n",
        "            recall_accs.append(recall_acc)\n",
        "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
        "\n",
        "            results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
        "        j += 1\n",
        "        print('')\n",
        "        print('Mean recall score ', np.mean(recall_accs))\n",
        "        print('')\n",
        "\n",
        "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
        "    \n",
        "    # here we check which is best\n",
        "    print('*********************************************************************************')\n",
        "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
        "    print('*********************************************************************************')\n",
        "    \n",
        "    return best_c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "456246b1-a987-da28-04dc-7e21f2e629db"
      },
      "outputs": [],
      "source": [
        "best_c = printing_Kfold_scores(X_train,y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bea19ba1-1ee5-32ae-24ba-ef2207d9f76a"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}