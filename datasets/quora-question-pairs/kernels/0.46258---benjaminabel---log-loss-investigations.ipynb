{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca7ebbec-6f30-25b3-b922-b01210094a23"
      },
      "source": [
        "In this notebook I'll investigate on log loss functions and try to understand in a graphical way how the score is related to ratio of positives using constant predictions.\n",
        "\n",
        "Yeah, I know this has already been done by [David Thaler](https://www.kaggle.com/davidthaler) in [How many 1's are in the Public LB?](https://www.kaggle.com/davidthaler)\n",
        "\n",
        "With the calculated ratio: **0.17426778573248283** it scores: **0.46258** on LB\n",
        "\n",
        "#### Summary: positive _rates on train and test\n",
        "\n",
        "|     data     |        train        |         test        |\n",
        "|:------------:|:-------------------:|:-------------------:|\n",
        "| postive rate | 0.36919785302629282 | 0.17426778573248283 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "929e675a-fa66-cf08-a3f3-e8e7ec8d9e0d"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "from math import log\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "578e0660-0053-2ac4-fe62-ecddbda0b8bb"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('../input/test.csv',\n",
        "                     usecols=['test_id'])\n",
        "df_test['is_duplicate'] = 0.5\n",
        "df_test.to_csv('all-half.csv', index=False)\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "924b5511-df72-9208-6c7a-3803e6a51e98"
      },
      "source": [
        "It scores **0.69315** in the public LB.\n",
        "\n",
        "According to the [sklearn docs](http://scikit-learn.org/stable/modules/model_evaluation.html#log-loss):\n",
        "\n",
        "> For binary classification with a true label  $y \\in \\{0,1\\}$\n",
        "and a probability estimate $p = \\operatorname{Pr}(y = 1)$,\n",
        "the log loss per sample is the negative log-likelihood\n",
        "of the classifier given the true label:\n",
        "\n",
        "$$L_{\\log}(y, p) = -\\log \\operatorname{Pr}(y|p) = -(y \\log (p) + (1 - y) \\log (1 - p))$$\n",
        "\n",
        "Here p = 0.5:\n",
        "\n",
        "$$L_{\\log}(y, 0.5) = -\\log \\operatorname{Pr}(y|0.5) = -(y \\log (0.5) + (0.5 - y) \\log (1 - 0.5)) = -(y \\log (0.5) + (1 - y) \\log (0.5)) $$\n",
        "\n",
        "Finally $L_{\\log}(y, 0.5) =  -\\log (0.5)$\n",
        "\n",
        "We don't get the number of positives, but now we are sure that the log-loss function used by Kaggle **uses a logarithm in base e**:  $\\ln$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "185d7d32-709d-3f4e-177d-3e3bc47302d7"
      },
      "outputs": [],
      "source": [
        "log(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "751f8d54-e3ab-6ce9-ec95-26000034e71c"
      },
      "source": [
        "## log loss graph\n",
        "\n",
        "What is the value of log loss for a predicted value if the questions are duplicate or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a860982-8764-9df1-192f-96ebe351c3af"
      },
      "outputs": [],
      "source": [
        "eps = 1E-6\n",
        "xs = np.linspace(0 + eps, 1 - eps)\n",
        "y1s = -np.log(xs)\n",
        "y0s = -np.log(1 - xs)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(xs, y1s, label=\"is duplicate $-\\log(p)$\")\n",
        "plt.plot(xs, y0s, label=\"isn't duplicate: $-\\log(1-p)$\")\n",
        "plt.legend(loc='upper center')\n",
        "axes = plt.gca()\n",
        "axes.set_ylim([0,2])\n",
        "plt.title('log loss in cas of a duplicate or non duplicate question')\n",
        "plt.xlabel('Predicted probability')\n",
        "plt.ylabel('log loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9e154f63-a9e1-a3f5-9907-25d0353566d5"
      },
      "source": [
        "## Try to predict duplicate rate on train test\n",
        "\n",
        "With a constant value in y_pred, it's easy to find the ratio of duplicates in the data.\n",
        "\n",
        "$$ratio = \\frac{ log\\_loss + log(1-y_{pred})}{log(1-y_{pred})- log(y_{pred})}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4711655d-59d6-7f47-a968-62cfb897ae41"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv',\n",
        "                       usecols=['is_duplicate'])\n",
        "df_train['is_duplicate'].sum()/ df_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7f8f92e-9679-439b-1f3f-3d9fb51dfa86"
      },
      "outputs": [],
      "source": [
        "def create_array(val, df=df_train):\n",
        "    \"\"\"Return a constant array with value val of same length as df\"\"\"\n",
        "    return val * np.ones_like(df_train.index)\n",
        "    \n",
        "ll = log_loss(df_train[\"is_duplicate\"], create_array(0.2))\n",
        "ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b09ce800-9ff8-cd34-f1fa-6aa28fcf004e"
      },
      "outputs": [],
      "source": [
        "ratio = (ll + log(0.8)) / (log(0.8) -log(0.2))\n",
        "ratio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a9fa1559-1e3b-c4e8-4885-401a8a073408"
      },
      "source": [
        "### Verify that better constant prediction is the duplicates ratio\n",
        "\n",
        "Let's do it graphically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3447b220-62d3-4513-0cee-5e2661399bb3"
      },
      "outputs": [],
      "source": [
        "xs = np.linspace(0, 1, 100)\n",
        "lls = [log_loss(df_train[\"is_duplicate\"], create_array(x)) for x in xs]\n",
        "# find minimum\n",
        "min_index = np.where(lls == np.min(lls))[0][0]\n",
        "x_min = xs[min_index]\n",
        "y_min = lls[min_index]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(xs, lls, '-gD', markevery=[min_index])\n",
        "\n",
        "plt.annotate('minimum ({:.3f}, {:.3f})'.format(x_min, y_min), xy=(x_min, y_min), xytext=(x_min, y_min - 0.1))\n",
        "plt.title('log loss vs predicted constant probability')\n",
        "plt.xlabel('Predicted probability')\n",
        "plt.ylabel('log loss')\n",
        "axes = plt.gca()\n",
        "axes.set_ylim([0,2])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c469477-9ff8-3dbb-1532-5fcbdf492633"
      },
      "outputs": [],
      "source": [
        "log_loss(df_train[\"is_duplicate\"], create_array(ratio))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f5b2d5dd-26ce-43cb-18f9-0876392756b5"
      },
      "source": [
        "## Easy, let's do the same on the test data\n",
        "\n",
        "Yeah, I know this has already been done by [David Thaler](https://www.kaggle.com/davidthaler) in [How many 1's are in the Public LB?](https://www.kaggle.com/davidthaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "446b2dd4-756e-53b4-0b6c-2a4c43230911"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('../input/test.csv',\n",
        "                      usecols=['test_id']\n",
        "                      )\n",
        "df_test['is_duplicate'] = 0.2\n",
        "df_test.to_csv('submission-0.2.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bdcdbc7e-e9b0-7ead-48c1-803b8f254410"
      },
      "source": [
        "**Score on LB: 0.46473**\n",
        "\n",
        "We can now calculate the ratio, and create the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f78486c-08d9-1680-a61c-bb698e1a703e"
      },
      "outputs": [],
      "source": [
        "ll = 0.46473\n",
        "ratio = (ll + log(0.8)) / (log(0.8) -log(0.2))\n",
        "ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "678a81f3-c809-5896-a009-1e1a65a02b96"
      },
      "outputs": [],
      "source": [
        "df_test['is_duplicate'] = ratio\n",
        "df_test.to_csv('submission-ratio.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0d59aec1-6a63-bebf-d997-214c367ec84a"
      },
      "source": [
        "**Score on LB: 0.46258**"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}