{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.1"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_uuid": "2eb66bcba2ffcb381e161351769d8c96c8f7cfe9", "_cell_guid": "ce15e7ac-99a8-4400-ac1c-b1d783c7feec"}, "source": ["tips:\n", "- https://github.com/rasbt/python-machine-learning-book/blob/master/code/optional-py-scripts/ch04.py\n", "- https://stackoverflow.com/questions/45932773/why-there-are-strips-in-the-predicted-image-in-keras\n", "- https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n", "- https://medium.com/@fromtheast/implement-fit-generator-in-keras-61aa2786ce98\n", "- https://www.kaggle.com/theblackcat/loading-bson-data-for-keras-fit-generator\n", "- https://github.com/abnera/image-classifier/blob/master/code/fine_tune.py#L124\n", "- https://www.kaggle.com/vfdev5/data-visualization-and-analysis/notebook\n", "- https://www.kaggle.com/saptak7/2-layer-cnn-adam-optimizer-and-5-epochs\n", "- https://www.kaggle.com/bguberfain/naive-keras-cdiscount/notebook\n", "\n", "iterator\n", "- https://www.kaggle.com/humananalog/keras-generator-for-reading-directly-from-bson\n", "- https://spark-in.me/post/bird-voice-recognition-eight\n", "- https://www.kaggle.com/vfdev5/random-item-access\n", "- https://www.kaggle.com/ezietsman/keras-convnet-with-fit-generator\n", "- https://gist.github.com/faroit/92ba12373440d092e1096967b530a5b8\n", "- https://github.com/fchollet/keras/blob/master/tests/keras/utils/data_utils_test.py\n", "- https://stanford.edu/~shervine/blog/keras-generator-multiprocessing.html\n", "- https://keunwoochoi.wordpress.com/2017/08/24/tip-fit_generator-in-keras-how-to-parallelise-correctly/\n", "- http://anandology.com/blog/using-iterators-and-generators/\n", "\n", "models\n", "- https://gogul09.github.io/software/flower-recognition-deep-learning\n", "- https://shuaiw.github.io/2017/03/09/smaller-faster-deep-learning-models.html\n", "- https://www.kaggle.com/drn01z3/mxnet-xgboost-baseline-lb-0-57\n", "- https://www.kaggle.com/drn01z3/resnet50-features-xgboost\n", "- http://blog.kaggle.com/2016/04/28/yelp-restaurant-photo-classification-winners-interview-1st-place-dmitrii-tsybulevskii/\n", "- https://github.com/u1234x1234/kaggle-yelp-restaurant-photo-classification\n", "- http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/\n", "- https://www.kaggle.com/zfturbo/python-xgboost-starter/code\n", "- https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge\n", "- https://www.kaggle.com/algila/inception-v3-and-k-fold-in-python-0-98996\n", "- https://www.kaggle.com/abnera/transfer-learning-keras-xception-cnn\n", "\n", "\n", "ensembles\n", "- https://mlwave.com/kaggle-ensembling-guide/\n", "\n", "label\n", "- http://sloth.readthedocs.io/en/latest/\n", "\n", "to order\n", "- https://github.com/LowikC/kaggle_cdiscount\n", "- https://github.com/rdoume/kaggle_cdiscount\n", "- https://github.com/fgmehlin/kaggle_cdiscount\n", "- https://github.com/Cuongvn08/kaggle_cdiscount_image_classify/blob/master/train.py\n", "- https://github.com/petrosgk/Kaggle-Cdiscount-Image-Classification-Challenge\n", "- https://github.com/lidalei/cdiscount\n", "- https://github.com/shawnxiaow1118/Kaggle_Cdiscounts_Image_Classification\n", "- https://github.com/xkumiyu/chainer-cdiscount-kernel\n", "- https://github.com/ilcauchy/cdiscount\n", "- https://github.com/DeepLearningSandbox/DeepLearningSandbox/blob/master/transfer_learning/fine-tune.py\n", "- https://github.com/abnera/image-classifier/blob/master/code/fine_tune.py\n", "\n", "- https://github.com/knjcode/mxnet-finetuner"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "6edcc629573d3ef52b0a758f798e5aa923b50226", "_cell_guid": "c57e30dc-fe6e-48b1-9e85-2487a7b2a84b"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "from skimage.data import imread \n", "import json\n", "import bson\n", "import io"]}, {"metadata": {"collapsed": true, "_uuid": "886e141a8c369d166bdb34ea04a4dc20ddc3547a", "_cell_guid": "dd577ce3-2fa8-48ea-83e8-6439bc7e3086"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import os\n", "INPUT_PATH = os.path.join('..', 'input', 'cdiscount-image-classification-challenge')\n", "\n", "train_example_path = os.path.join(INPUT_PATH, 'train_example.bson')\n", "train_path = os.path.join(INPUT_PATH, 'train.bson')\n", "\n", "#train_example_path = \"../input/cdiscount-image-classification-challenge/train_example.bson\"\n", "#train_path = \"../input/cdiscount-image-classification-challenge/train.bson\""]}, {"metadata": {"collapsed": true, "_uuid": "d32b0ff24790d2787505abfe03d3ea160ece156d", "_cell_guid": "3833568c-14cd-4108-b3d6-df0a44a82307"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import os.path as path\n", "\n", "def split():\n", "    ids = []\n", "    categories = []\n", "    for example in bson.decode_file_iter(open(train_path, 'rb')):\n", "        ids.append(example['_id'])\n", "        categories.append(example['category_id'])\n", "    return ids, categories\n", "        \n", "ids, categories = split()"]}, {"metadata": {"collapsed": true, "_uuid": "9ee870aab83d1c93cbe5fec8f9d50227389d4ea0", "_cell_guid": "e4d628c1-9846-4ac9-b96e-0903bd1083eb"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import random\n", "\n", "_valid_percent=0.1\n", "size = len(ids)\n", "train_size = int(size*(1-_valid_percent))\n", "valid_size = (size-train_size)\n", "split = ['train']*train_size + ['valid']*valid_size\n", "random.shuffle(split)\n", "split_df = pd.DataFrame({'id': ids, 'split': split})\n", "split_df = split_df.set_index(['id'])\n", "split_df.head(11)"]}, {"metadata": {"collapsed": true, "_uuid": "0a20063af9d7de38615c2b4abf40debc79d8e8f0", "_cell_guid": "b3012331-7e60-454b-aab8-ea6e3976b917"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#if self._split.loc[example['_id']]['split'] == name:\n", "#for row in \n", "#split_df.loc[11]['split'] == 'valid'"]}, {"metadata": {"collapsed": true, "_uuid": "964a05457d98d2ef8c5923d0242b374ecf633d3a", "_cell_guid": "892f6ed8-c0bd-4e5a-8a4b-9e60d4e785bd"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.cross_validation import train_test_split\n", "ids_train,ids_test = train_test_split(ids,test_size=0.1)\n", "print(len(ids_train),len(ids_test))\n", "print(ids_train[0], ids_test[0])\n", "\n", "#X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_y,test_size=0.3)\n", "#print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"]}, {"metadata": {"collapsed": true, "_uuid": "d1c23a0ca7c2b9fff4ebf0f3c00667cd460a5cbf", "_cell_guid": "db6cc795-df9e-412d-abba-90a542796798"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#10 in ids, 10 in ids_train, 10 in ids_test"]}, {"metadata": {"collapsed": true, "_uuid": "adc1f7fa17989bb62379d4583394714a64f08b2b", "_cell_guid": "79593b15-f6a0-458f-9fe7-69d02851a4d5"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#data.category_id.values\n", "#path = \"../input/cdiscount-image-classification-challenge/train_example.bson\"\n", "category_names = pd.read_csv(os.path.join(INPUT_PATH, 'category_names.csv'))\n", "print(len(category_names['category_id'].unique()))\n", "category_names.head()"]}, {"metadata": {"collapsed": true, "_uuid": "eca91cee760bf55604d5386e71072456340be5f3", "_cell_guid": "3d71eaff-c1da-4cab-9d43-dfb47707557e"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["num_classes = 5270"]}, {"metadata": {"collapsed": true, "_uuid": "114745f85f772313e00c78f8e089cc94b4f766c8", "_cell_guid": "88cd9522-0606-4c68-bb61-d66f1192905a"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from keras.utils import np_utils\n", "from sklearn.preprocessing import LabelEncoder\n", "\n", "encoder = LabelEncoder()\n", "encoder.fit(category_names['category_id'])\n", "#encoded_y = encoder.transform(y)\n", "#dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n", "#dummy_y.shape"]}, {"metadata": {"collapsed": true, "_uuid": "7096111619a709d772dfc15c296838b40d5f3f16", "_cell_guid": "52850a1a-7fe6-4868-89d0-f0f05436cf07"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#encoder.fit([1000010653])\n", "np_utils.to_categorical(encoder.transform([1000010653]), num_classes=num_classes).shape"]}, {"metadata": {"collapsed": true, "_uuid": "76f5991f9479031218f8b7e468c65435894f95a8", "_cell_guid": "796e9027-b4a6-4c76-8720-74cfce1e9e8d"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["im_size = 180\n", "\n", "batch_size = 32\n", "batch_size_validation = 64\n", "\n", "epochs_top = 10\n", "epochs = 20\n", "\n", "steps_per_epoch_top = 5\n", "steps_per_epoch = 10\n", "\n", "validation_steps_top=2\n", "validation_steps=2\n", "\n", "#minibatch_size = batch_size\n", "#words_per_epoch = 6362906+706990\n", "#6362906 \n", "\n", "#val_words = 706990\n", "\n", "#steps = 7069896/32\n", "#steps = 220,934.25\n", "\n", "#validation_steps = val_words // minibatch_size\n", "#validation_steps = 706990//32\n", "#validation_steps = 22,093.4375\n", "\n", "#steps_per_epoch = (words_per_epoch - val_words) // minibatch_size\n", "#steps_per_epoch = (7069896 - 706990) // 32\n", "#steps_per_epoch = 198,840.8125\n", "\n", "# https://github.com/fchollet/keras/blob/master/examples/image_ocr.py\n", "#val_words = int(words_per_epoch * (val_split))\n", "#val_split = 0.2\n", "#val_split=words_per_epoch - val_words"]}, {"metadata": {"collapsed": true, "_uuid": "dc14990b06c8ae5ee5207cf3b379d20afef77f20", "_cell_guid": "d60beafa-a891-47b1-86bb-32cffd344830"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import cv2\n", "\n", "def _imread(buf):\n", "    return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_ANYCOLOR)\n", "\n", "def img2feat(im):\n", "    x = cv2.resize(im, (im_size, im_size), interpolation=cv2.INTER_AREA)\n", "    return np.float32(x) / 255.\n", "\n", "#X = np.empty((num_images, im_size, im_size, 3), dtype=np.float32)\n", "#y = []\n", "\n", "def load_image(pic, target):\n", "    x = _imread(pic['picture'])\n", "    x = img2feat(x)\n", "#    bar.update()\n", "    \n", "    return x, target\n", "\n", "def generate_arrays_from_file(path, batch_size):\n", "    batch_features = np.zeros((batch_size, im_size, im_size, 3))\n", "    batch_labels = np.zeros((batch_size,1))\n", "    while 1:\n", "        f = open(path,'rb')\n", "        data_iter = bson.decode_file_iter(f)\n", "        for i, d in enumerate(data_iter):\n", "            target = d['category_id']\n", "            for e, pic in enumerate(d['imgs']):\n", "                x, target = load_image(pic, target)\n", "#                yield x, np_utils.to_categorical(encoder.transform([target]), num_classes=num_classes)[0]\n", "\n", "\n", "                encoded_y = encoder.transform([target])\n", "                dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n", "                yield np.array([x]), dummy_y\n", "#                yield ({'input_2': np.array([x])}, {'dense_2': dummy_y})\n", "#                yield batch_features, batch_labels\n", "        f.close()"]}, {"metadata": {"collapsed": true, "_uuid": "df88a396fe1c4415d90447dcff0c32b764c59a05", "_cell_guid": "7f8f8907-61c6-49b0-a612-dfaae8b3345b"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["def convert2onehot(category_id):\n", "    encoded_y = encoder.transform([category_id])\n", "    dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n", "    return True, dummy_y[0]\n", "#convert2onehot(1000010653)"]}, {"metadata": {"collapsed": true, "_uuid": "38202456e421ee1826b73e5b4ff969050c712e83", "_cell_guid": "24888474-1b1f-4476-8602-d1bad2334fd8"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# https://www.kaggle.com/theblackcat/loading-bson-data-for-keras-fit-generator\n", "\n", "from random import randint\n", "    \n", "def data_generator(path, ids, batch_size=128, start_image=0, name=''):\n", "    count_product = 0\n", "    images = []\n", "    y_label = []\n", "    while True:\n", "        f = open(path,'rb')\n", "        data_iter = bson.decode_file_iter(f)\n", "        count = 0\n", "        for c, d in enumerate(data_iter):\n", "#            if d['_id'] not in ids:\n", "            if split_df.loc[d['_id']]['split'] == name:\n", "#                print(name, 'not in', d['_id'])\n", "                continue\n", "#            print(name, 'in', d['_id'])\n", "            category_id = d['category_id']\n", "            if count_product < start_image:\n", "                count_product += 1\n", "                continue\n", "            success, one_hot = convert2onehot(category_id)\n", "            if not success:\n", "                print(\"id conversion failed\")\n", "                continue\n", "            for e, pic in enumerate(d['imgs']):\n", "#                picture = imread(io.BytesIO(pic['picture']))\n", "                picture, _ = load_image(pic, category_id)\n", "                images.append(picture)\n", "                y_label.append(one_hot)\n", "                count += 1\n", "            if count >= batch_size:\n", "                count = 0\n", "                y_label = np.asarray(y_label)\n", "                images = np.asarray(images)\n", "                '''\n", "                    since shuffle in fit function will not work here, \n", "                    a batch shuffle mechnism is added \n", "                '''\n", "                for i,image in enumerate(images[:int(batch_size/2)]):\n", "                    j = randint(0,batch_size-1)\n", "                    y_temp = y_label[i]\n", "                    img_temp = image\n", "                    images[i] = images[j]\n", "                    y_label[i] = y_label[j]\n", "                    images[j] = img_temp\n", "                    y_label[j] = y_temp\n", "                yield images, y_label\n", "                # just to be sure past batch are removed from the memory\n", "                del images\n", "                del y_label\n", "                images = []\n", "                y_label = []\n", "#                return\n", "#list(data_generator(batch_size=2))"]}, {"metadata": {"collapsed": true, "_uuid": "2b42db011bffccad4e9566314fca4e2cde62f98b", "_cell_guid": "bcd56319-7c8c-4b57-aab9-c88df74620af"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#from sklearn.cross_validation import train_test_split\n", "#X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_y,test_size=0.3)\n", "#print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"]}, {"metadata": {"collapsed": true, "_uuid": "01e70489b42fdfadc2e7e6220eab23f3946b7498", "_cell_guid": "1a0220fd-cf25-4761-8810-940a8321d437"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import keras\n", "from keras.datasets import mnist\n", "from keras.models import Sequential, Model\n", "from keras.layers import Dense, Dropout, Flatten,Input\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras import backend as K\n", "\n", "K.set_image_dim_ordering('tf')"]}, {"metadata": {"collapsed": true, "_uuid": "a494a284c2d601199b9aa747a59bc2688ad72895", "_cell_guid": "b40970d6-6d80-4978-9f46-8986f0a3880e"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from keras.applications.inception_v3 import InceptionV3\n", "from keras.preprocessing import image\n", "from keras.models import Model\n", "from keras.layers import Dense, GlobalAveragePooling2D\n", "from keras.layers import Input\n", "from keras import backend as K\n", "\n", "input_tensor = Input(shape=(im_size, im_size, 3))\n", "\n", "# create the base pre-trained model\n", "#base_model = InceptionV3(weights=None, include_top=False, input_tensor=input_tensor)\n", "base_model = InceptionV3(weights=None, include_top=False, input_shape=(im_size, im_size, 3))\n", "\n", "keras_models_dir = \"../input/keras inception v3 notop v0.5\"\n", "base_model.load_weights('%s/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5' % keras_models_dir)"]}, {"metadata": {"collapsed": true, "_uuid": "8ab925a28655f20676cea7c6e5e6e425deae24a0", "_cell_guid": "530af1d6-698d-4178-b58f-f6052406a066"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# add a global spatial average pooling layer\n", "x = base_model.output\n", "x = GlobalAveragePooling2D()(x)\n", "# let's add a fully-connected layer\n", "x = Dense(1024, activation='relu')(x)\n", "# and a logistic layer -- let's say we have 200 classes\n", "predictions = Dense(num_classes, activation='softmax')(x)\n", "\n", "# add a new top layer\n", "#x = base_model.output\n", "#x = Flatten()(x)\n", "#predictions = Dense(17, activation='sigmoid')(x)\n", "\n", "#x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n", "#x = Flatten(name='flatten')(x)\n", "#predictions = Dense(36, activation='softmax', name='predictions')(x)\n", "\n", "# this is the model we will train\n", "model = Model(inputs=base_model.input, outputs=predictions)"]}, {"metadata": {"collapsed": true, "_uuid": "d8ae37ef3309e9fdac2bee14f3daaba5e4fea65b", "_cell_guid": "1be90bc9-50dd-47c9-b807-1a9e1c3867f5"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# first: train only the top layers (which were randomly initialized)\n", "# i.e. freeze all convolutional InceptionV3 layers\n", "for layer in base_model.layers:\n", "    layer.trainable = False\n", "\n", "# compile the model (should be done *after* setting layers to non-trainable)\n", "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"]}, {"metadata": {"collapsed": true, "_uuid": "42ef2858c833baa93c329cb324d8e06cc16da282", "_cell_guid": "437ac1c1-a7b4-4aa2-a5ee-26044694e083"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# train the model on the new data for a few epochs\n", "if True:\n", "    #model.fit_generator(...)\n", "#    batch_size = 32\n", "#    epochs = 10\n", "#    generator=generate_arrays_from_file(path)\n", "    generator = data_generator(train_path, ids_train, batch_size=batch_size, name='train')\n", "    generator_validation = data_generator(train_path, ids_test, batch_size=batch_size_validation, name='valid')\n", "    hist = model.fit_generator(\n", "                  generator=generator,\n", "                  steps_per_epoch=steps_per_epoch_top,\n", "                  epochs=epochs_top,\n", "                  verbose=1,\n", "                  callbacks = None,\n", "                  validation_data=generator_validation,\n", "                  validation_steps=validation_steps_top,\n", "#                  validation_data=(X_test, Y_test)\n", "                  )\n", "else:\n", "#    batch_size = 32\n", "#    epochs = 10\n", "    hist = model.fit(X_train, Y_train,\n", "                  batch_size=batch_size,\n", "                  epochs=epochs_top,\n", "                  verbose=1,\n", "                  callbacks = None,\n", "                  validation_data=(X_test, Y_test))"]}, {"metadata": {"collapsed": true, "_uuid": "bc1141a484e188ca2352ed54478c64f83e4e9f58", "_cell_guid": "c404af9a-6aef-418c-b06f-63b291b064a4"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# at this point, the top layers are well trained and we can start fine-tuning\n", "# convolutional layers from inception V3. We will freeze the bottom N layers\n", "# and train the remaining top layers.\n", "\n", "# let's visualize layer names and layer indices to see how many layers\n", "# we should freeze:\n", "for i, layer in enumerate(base_model.layers):\n", "   print(i, layer.name)\n", "\n", "# we chose to train the top 2 inception blocks, i.e. we will freeze\n", "# the first 249 layers and unfreeze the rest:\n", "for layer in model.layers[:249]:\n", "   layer.trainable = False\n", "for layer in model.layers[249:]:\n", "   layer.trainable = True\n", "\n", "# we need to recompile the model for these modifications to take effect\n", "# we use SGD with a low learning rate\n", "from keras.optimizers import SGD\n", "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n", "              loss='categorical_crossentropy', \n", "              metrics=['accuracy'])"]}, {"metadata": {"collapsed": true, "_uuid": "ab2f29e32b6a005e7452b2039f7e11678af3130d", "_cell_guid": "2d7ccd1c-a080-4aef-a470-94eeaab5d910"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# we train our model again (this time fine-tuning the top 2 inception blocks\n", "# alongside the top Dense layers\n", "#model.fit_generator(...)\n", "if True:\n", "    #model.fit_generator(...)\n", "#    batch_size = 32\n", "#    epochs = 10\n", "#    generator=generate_arrays_from_file(path)\n", "    generator = data_generator(train_path, ids_train, batch_size=batch_size, name='train')\n", "    generator_validation = data_generator(train_path, ids_test, batch_size=batch_size_validation, name='valid')\n", "    hist = model.fit_generator(\n", "                  generator=generator,\n", "                  steps_per_epoch=steps_per_epoch,\n", "                  epochs=epochs,\n", "                  verbose=1,\n", "                  callbacks = None,\n", "                  validation_data=generator_validation,\n", "                  validation_steps=validation_steps,\n", "#                  validation_data=(X_test, Y_test)\n", "                  )\n", "else:\n", "#    batch_size = 32\n", "#    epochs = 10\n", "    hist = model.fit(X_train, Y_train,\n", "                  batch_size=batch_size,\n", "                  epochs=epochs,\n", "                  verbose=1,\n", "                  callbacks = None,\n", "                  validation_data=(X_test, Y_test))"]}, {"metadata": {"collapsed": true, "_uuid": "68c4e047bae1596eb5cb80f57f311ebefcff8617", "_cell_guid": "1a7a6a56-2cb6-45db-bcc2-e56ad6470318"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["def plot_train(hist):\n", "    h = hist.history\n", "    if 'acc' in h:\n", "        meas='acc'\n", "        loc='lower right'\n", "    else:\n", "        meas='loss'\n", "        loc='upper right'\n", "    plt.plot(hist.history[meas])\n", "    plt.plot(hist.history['val_'+meas])\n", "    plt.title('model '+meas)\n", "    plt.ylabel(meas)\n", "    plt.xlabel('epoch')\n", "    plt.legend(['train', 'validation'], loc=loc)\n", "plot_train(hist)"]}, {"metadata": {"collapsed": true, "_uuid": "5b4bde5d7b8f7bfddf4883c2318a5b7a2e42b6bd", "_cell_guid": "8e7ee910-3ad3-46af-b691-3f2187333e94"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#hist.history"]}, {"metadata": {"collapsed": true, "_uuid": "5dc7f2f744492b20b78f5cdf0fa761a9829746f5", "_cell_guid": "e49e36e4-86cb-46de-a834-ecf6a2644681"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# https://www.kaggle.com/saptak7/2-layer-cnn-adam-optimizer-and-5-epochs\n", "# https://www.kaggle.com/bguberfain/naive-keras-cdiscount/notebook\n", "\n", "from tqdm import tqdm_notebook\n", "import concurrent.futures\n", "from multiprocessing import cpu_count\n", "num_cpus = cpu_count()\n", "\n", "submission = pd.read_csv(\n", "    '../input/cdiscount-image-classification-challenge/sample_submission.csv', \n", "    index_col='_id')\n", "\n", "#most_frequent_guess = 1000018296\n", "#submission['category_id'] = most_frequent_guess \n", "\n", "num_images_test = 100\n", "bar = tqdm_notebook(total=num_images_test * 1)\n", "\n", "with open('../input/cdiscount-image-classification-challenge/test.bson', 'rb') as f, \\\n", "         concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n", "\n", "    data = bson.decode_file_iter(f)\n", "\n", "    future_load = []\n", "\n", "    for i,d in enumerate(data):\n", "        if i >= num_images_test:\n", "              break\n", "#        future_load.append(executor.submit(load_image, d['imgs'][0]['picture'], d['_id'], bar))\n", "        future_load.append(executor.submit(load_image, d['imgs'][0], d['_id']))\n", "        \n", "#        print(\"Starting future processing\")\n", "    for future in concurrent.futures.as_completed(future_load):\n", "        x, _id = future.result()\n", "        y_cat = encoder.inverse_transform(np.argmax(model.predict(x[None])[0]))\n", "#        print(y_cat)\n", "#        y_cat = rev_labels[np.argmax(model.predict(x[None])[0])]\n", "#        if y_cat == -1:\n", "#            y_cat = most_frequent_guess\n", "\n", "        bar.update()\n", "        submission.loc[_id, 'category_id'] = y_cat\n", "print('Finished')"]}, {"metadata": {"collapsed": true, "_uuid": "98c0613cdf15938e1d3fb18c290a58f3ea2156a0", "_cell_guid": "ef117828-603b-43fe-b75e-0a1616eb690d"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["submission.to_csv('new_submission.csv.gz', compression='gzip')"]}, {"metadata": {"collapsed": true, "_uuid": "f7f56b63a548e1a2ef77f594da4fd8cc596ac8cd", "_cell_guid": "17e925af-aa4b-44a3-ada9-6d6ae40812e0"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#encoder.inverse_transform(model.predict(x[None]))\n", "#encoder.inverse_transform(np.argmax(model.predict(x[None])[0]))"]}, {"metadata": {"_uuid": "98f0b4eba7db251eeaf6978b7c74afbeb30036f1", "_cell_guid": "16c83905-c7de-4882-88d5-1d05c8c4ba49"}, "source": ["First kernel try in keras \n", "Lot more to come!!\n", "Stay Advance :)"], "cell_type": "markdown"}]}