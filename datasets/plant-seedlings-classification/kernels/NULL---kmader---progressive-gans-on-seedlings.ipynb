{"cells":[{"metadata":{"_uuid":"feeca970eb64fd87f8634486fc709f78f91c1ad0","_cell_guid":"24fd04cb-e295-47c6-b02d-e2776b5b278f"},"cell_type":"markdown","source":"# Overview\nHere we take the [github repo in tensorflow](https://github.com/zhangqianhui/progressive_growing_of_gans_tensorflow) for Progressive Growing of GANS and apply it to seedling data."},{"metadata":{"_uuid":"4e53f5c00b4d89058fecae8cba56e347e97d3411","_cell_guid":"5c46b2ef-4aed-46dd-8435-ade9aeef6453","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport scipy\nfrom tensorflow.contrib.layers.python.layers import batch_norm, variance_scaling_initializer","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"trusted":true},"cell_type":"code","source":"def imsave(images, size, path):\n    return scipy.misc.imsave(path, merge(images, size).astype(np.uint8))\ndef inverse_transform(image):\n    return ((image + 1.)* 127.5).astype(np.uint8)\ndef center_crop(x, crop_h, crop_w=None, resize_w=64):\n\n    if crop_w is None:\n        crop_w = crop_h\n    h, w = x.shape[:2]\n    j = int(round((h - crop_h)/2.))\n    i = int(round((w - crop_w)/2.))\n\n    rate = np.random.uniform(0, 1, size=1)\n\n    if rate < 0.5:\n        x = np.fliplr(x)\n\n    return scipy.misc.imresize(x[j:j+crop_h, i:i+crop_w],\n                               [resize_w, resize_w])\n\ndef save_images(images, size, image_path):\n    return imsave(inverse_transform(images), size, image_path)\n\n# the implements of leakyRelu\n\ndef lrelu(x, alpha=0.2, name=\"LeakyReLU\"):\n    return tf.maximum(x, alpha*x)\n\n\ndef conv2d(input_, output_dim,\n           k_h=3, k_w=3, d_h=2, d_w=2, padding='SAME',\n           name=\"conv2d\", with_w=False):\n    with tf.variable_scope(name):\n        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],\n                            initializer=variance_scaling_initializer())\n        if padding == 'Other':\n\n            padding = 'VALID'\n            input_ = tf.pad(\n                input_, [[0, 0], [3, 3], [3, 3], [0, 0]], \"CONSTANT\")\n\n        elif padding == 'VALID':\n            padding = 'VALID'\n\n        conv = tf.nn.conv2d(input_, w, strides=[\n                            1, d_h, d_w, 1], padding=padding)\n        biases = tf.get_variable(\n            'biases', [output_dim], initializer=tf.constant_initializer(0.0))\n        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())\n\n        if with_w:\n            return conv, w, biases\n\n        else:\n            return conv\n\n\ndef de_conv(input_, output_shape,\n            k_h=3, k_w=3, d_h=2, d_w=2, stddev=0.02,\n            name=\"deconv2d\", with_w=False):\n\n    with tf.variable_scope(name):\n        # filter : [height, width, output_channels, in_channels]\n        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], input_.get_shape()[-1]],\n                            initializer=variance_scaling_initializer())\n        try:\n            deconv = tf.nn.conv2d_transpose(input_, w, output_shape=output_shape,\n                                            strides=[1, d_h, d_w, 1])\n        # Support for verisons of TensorFlow before 0.7.0\n        except AttributeError:\n            deconv = tf.nn.deconv2d(input_, w, output_shape=output_shape,\n                                    strides=[1, d_h, d_w, 1])\n        biases = tf.get_variable(\n            'biases', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n        deconv = tf.reshape(tf.nn.bias_add(deconv, biases), deconv.get_shape())\n\n        if with_w:\n\n            return deconv, w, biases\n\n        else:\n\n            return deconv\n\n\ndef fully_connect(input_, output_size, stddev=0.02, scope=None, with_w=False):\n\n    shape = input_.get_shape().as_list()\n    with tf.variable_scope(scope or \"Linear\"):\n\n        matrix = tf.get_variable(\"Matrix\", [shape[1], output_size], tf.float32,\n                                 variance_scaling_initializer())\n\n        bias = tf.get_variable(\n            \"bias\", [output_size], initializer=tf.constant_initializer(0.0))\n\n        output = tf.matmul(input_, matrix) + bias\n\n        if with_w:\n            return output, with_w, bias\n\n        else:\n            return output\n\n\ndef conv_cond_concat(x, y):\n    \"\"\"Concatenate conditioning vector on feature map axis.\"\"\"\n    x_shapes = x.get_shape()\n    y_shapes = y.get_shape()\n    return tf.concat(3, [x, y*tf.ones([x_shapes[0], x_shapes[1], x_shapes[2], y_shapes[3]])])\n\n\ndef batch_normal(input, scope=\"scope\", reuse=False):\n    return batch_norm(input, epsilon=1e-5, decay=0.9, scale=True, scope=scope, reuse=reuse, updates_collections=None)\n\n\ndef resize_nearest_neighbor(x, new_size):\n    x = tf.image.resize_nearest_neighbor(x, new_size)\n    return x\n\n\ndef upscale(x, scale):\n    _, h, w, _ = get_conv_shape(x)\n    return resize_nearest_neighbor(x, (h * scale, w * scale))\n\n\ndef downscale(x, scale):\n    _, h, w, _ = get_conv_shape(x)\n    return resize_nearest_neighbor(x, (h / scale, w / scale))\n\n\ndef get_conv_shape(tensor):\n    shape = int_shape(tensor)\n    return shape\n\n\ndef int_shape(tensor):\n    shape = tensor.get_shape().as_list()\n    return [num if num is not None else -1 for num in shape]\n\n\ndef avgpool2d(x, k=2):\n    # avgpool wrapper\n    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n                          padding='SAME')\n\n\ndef instance_norm(input, scope=\"instance_norm\"):\n\n    with tf.variable_scope(scope):\n\n        depth = input.get_shape()[3]\n        scale = tf.get_variable(\"scale\", [depth], initializer=tf.random_normal_initializer(\n            1.0, 0.02, dtype=tf.float32))\n        offset = tf.get_variable(\n            \"offset\", [depth], initializer=tf.constant_initializer(0.0))\n        mean, variance = tf.nn.moments(input, axes=[1, 2], keep_dims=True)\n        epsilon = 1e-5\n        inv = tf.rsqrt(variance + epsilon)\n        normalized = (input-mean)*inv\n\n        return scale*normalized + offset\n\n\ndef Pixl_Norm(input, eps=1e-8):\n    return input / tf.sqrt(tf.reduce_mean(input**2, axis=3, keep_dims=True) + eps)\n\n\nclass WScaleLayer(object):\n\n    def __int__(self, weights, biases):\n\n        self.scale = tf.sqrt(tf.reduce_mean(weights ** 2))\n        self.bias = None\n        self.we_assign = weights.assign(weights / self.scale)\n        if biases is not None:\n            self.bias = biases\n\n    def getoutput_for(self, input):\n\n        if self.bias is not None:\n            input = input - self.bias\n\n        return input * self.scale + self.bias, self.we_assign\n\n\ndef MinibatchstateConcat(input, averaging='all'):\n\n    adjusted_std = lambda x, **kwargs: tf.sqrt(tf.reduce_mean(\n        (x - tf.reduce_mean(x, **kwargs)) ** 2, **kwargs) + 1e-8)\n    vals = adjusted_std(input, axis=0, keep_dims=True)\n    if averaging == 'all':\n        vals = tf.reduce_mean(vals, keep_dims=True)\n    else:\n        print(\"nothing\")\n    vals = tf.tile(vals, multiples=[tf.shape(input)[0], 4, 4, 1])\n    return tf.concat([input, vals], axis=3)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"584b31954e9238f6faf3084cae4b8137c29e31fd","_cell_guid":"164a1b7d-9192-458a-9a09-8fb09dcdb1bf","collapsed":true,"trusted":true},"cell_type":"code","source":"class PGGAN(object):\n\n    # build model\n    def __init__(self, batch_size, max_iters, model_path, read_model_path, data, sample_size, sample_path, log_dir,\n                 learn_rate, PG, t):\n\n        self.batch_size = batch_size\n        self.max_iters = max_iters\n        self.gan_model_path = model_path\n        self.read_model_path = read_model_path\n        self.data_In = data\n        self.sample_size = sample_size\n        self.sample_path = sample_path\n        self.log_dir = log_dir\n        self.learning_rate = learn_rate\n        self.pg = PG\n        self.trans = t\n        self.log_vars = []\n        self.channel = 3\n        self.output_size = 4 * pow(2, PG - 1)\n        self.images = tf.placeholder(\n            tf.float32, [batch_size, self.output_size, self.output_size, self.channel])\n        self.z = tf.placeholder(\n            tf.float32, [self.batch_size, self.sample_size])\n        self.alpha_tra = tf.Variable(\n            initial_value=0.0, trainable=False, name='alpha_tra')\n\n    def build_model_PGGan(self):\n\n        self.fake_images = self.generate(\n            self.z, pg=self.pg, t=self.trans, alpha_trans=self.alpha_tra)\n\n        _, self.D_pro_logits = self.discriminate(\n            self.images, reuse=False, pg=self.pg, t=self.trans, alpha_trans=self.alpha_tra)\n        _, self.G_pro_logits = self.discriminate(\n            self.fake_images, reuse=True, pg=self.pg, t=self.trans, alpha_trans=self.alpha_tra)\n\n        # the defination of loss for D and G\n        self.D_loss = tf.reduce_mean(\n            self.G_pro_logits) - tf.reduce_mean(self.D_pro_logits)\n        self.G_loss = -tf.reduce_mean(self.G_pro_logits)\n\n        # gradient penalty from WGAN-GP\n        self.differences = self.fake_images - self.images\n        self.alpha = tf.random_uniform(\n            shape=[self.batch_size, 1, 1, 1], minval=0., maxval=1.)\n        interpolates = self.images + (self.alpha * self.differences)\n        _, discri_logits = self.discriminate(\n            interpolates, reuse=True, pg=self.pg, t=self.trans, alpha_trans=self.alpha_tra)\n        gradients = tf.gradients(discri_logits, [interpolates])[0]\n\n        # 2 norm\n        slopes = tf.sqrt(tf.reduce_sum(\n            tf.square(gradients), reduction_indices=[1, 2, 3]))\n        self.gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)\n        tf.summary.scalar(\"gp_loss\", self.gradient_penalty)\n\n        self.D_origin_loss = self.D_loss\n\n        self.D_loss += 10 * self.gradient_penalty\n        self.D_loss += 0.001 * tf.reduce_mean(tf.square(self.D_pro_logits - 0.0))\n\n        self.log_vars.append((\"generator_loss\", self.G_loss))\n        self.log_vars.append((\"discriminator_loss\", self.D_loss))\n\n        t_vars = tf.trainable_variables()\n        self.d_vars = [var for var in t_vars if 'dis' in var.name]\n\n        total_para = 0\n        for variable in self.d_vars:\n            shape = variable.get_shape()\n            print(variable.name, shape)\n            variable_para = 1\n            for dim in shape:\n                variable_para *= dim.value\n            total_para += variable_para\n        print(\"The total para of D\", total_para)\n\n        self.g_vars = [var for var in t_vars if 'gen' in var.name]\n\n        total_para2 = 0\n        for variable in self.g_vars:\n            shape = variable.get_shape()\n            print(variable.name, shape)\n            variable_para = 1\n            for dim in shape:\n                variable_para *= dim.value\n            total_para2 += variable_para\n        print(\"The total para of G\", total_para2)\n\n        # save the variables , which remain unchanged\n        self.d_vars_n = [var for var in self.d_vars if 'dis_n' in var.name]\n        self.g_vars_n = [var for var in self.g_vars if 'gen_n' in var.name]\n\n        # remove the new variables for the new model\n        self.d_vars_n_read = [var for var in self.d_vars_n if '{}'.format(\n            self.output_size) not in var.name]\n        self.g_vars_n_read = [var for var in self.g_vars_n if '{}'.format(\n            self.output_size) not in var.name]\n\n        # save the rgb variables, which remain unchanged\n        self.d_vars_n_2 = [\n            var for var in self.d_vars if 'dis_y_rgb_conv' in var.name]\n        self.g_vars_n_2 = [\n            var for var in self.g_vars if 'gen_y_rgb_conv' in var.name]\n\n        self.d_vars_n_2_rgb = [var for var in self.d_vars_n_2 if '{}'.format(\n            self.output_size) not in var.name]\n        self.g_vars_n_2_rgb = [var for var in self.g_vars_n_2 if '{}'.format(\n            self.output_size) not in var.name]\n\n        print(\"d_vars\", len(self.d_vars))\n        print(\"g_vars\", len(self.g_vars))\n\n        print(\"self.d_vars_n_read\", len(self.d_vars_n_read))\n        print(\"self.g_vars_n_read\", len(self.g_vars_n_read))\n\n        print(\"d_vars_n_2_rgb\", len(self.d_vars_n_2_rgb))\n        print(\"g_vars_n_2_rgb\", len(self.g_vars_n_2_rgb))\n\n        # for n in self.d_vars:\n        #     print (n.name)\n\n        self.g_d_w = [var for var in self.d_vars +\n                      self.g_vars if 'bias' not in var.name]\n\n        print(\"self.g_d_w\", len(self.g_d_w))\n\n        self.saver = tf.train.Saver(self.d_vars + self.g_vars)\n        self.r_saver = tf.train.Saver(self.d_vars_n_read + self.g_vars_n_read)\n\n        if len(self.d_vars_n_2_rgb + self.g_vars_n_2_rgb):\n            self.rgb_saver = tf.train.Saver(\n                self.d_vars_n_2_rgb + self.g_vars_n_2_rgb)\n\n        for k, v in self.log_vars:\n            tf.summary.scalar(k, v)\n\n    # do train\n    def train(self):\n\n        step_pl = tf.placeholder(tf.float32, shape=None)\n        alpha_tra_assign = self.alpha_tra.assign(step_pl / self.max_iters)\n\n        opti_D = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0.0, beta2=0.99).minimize(\n            self.D_loss, var_list=self.d_vars)\n        opti_G = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta1=0.0, beta2=0.99).minimize(\n            self.G_loss, var_list=self.g_vars)\n\n        init = tf.global_variables_initializer()\n        config = tf.ConfigProto()\n        config.gpu_options.allow_growth = True\n\n        with tf.Session(config=config) as sess:\n\n            sess.run(init)\n            summary_op = tf.summary.merge_all()\n            summary_writer = tf.summary.FileWriter(self.log_dir, sess.graph)\n\n            if self.pg != 1 and self.pg != 7:\n\n                if self.trans:\n                    self.r_saver.restore(sess, self.read_model_path)\n                    self.rgb_saver.restore(sess, self.read_model_path)\n\n                else:\n                    self.saver.restore(sess, self.read_model_path)\n\n            step = 0\n            batch_num = 0\n            while step <= self.max_iters:\n\n                # optimization D\n                n_critic = 1\n                if self.pg == 5 and self.trans:\n                    n_critic = 1\n\n                for i in range(n_critic):\n\n                    sample_z = np.random.normal(\n                        size=[self.batch_size, self.sample_size])\n                    train_list = self.data_In.getNextBatch(\n                        batch_num, self.batch_size)\n                    realbatch_array = self.data_In.getShapeForData(\n                        train_list, resize_w=self.output_size)\n\n                    if self.trans and self.pg != 0:\n\n                        alpha = np.float(step) / self.max_iters\n\n                        low_realbatch_array = scipy.ndimage.zoom(\n                            realbatch_array, zoom=[1, 0.5, 0.5, 1])\n                        low_realbatch_array = scipy.ndimage.zoom(\n                            low_realbatch_array, zoom=[1, 2, 2, 1])\n                        realbatch_array = alpha * realbatch_array + (1 - alpha) * low_realbatch_array\n\n                    sess.run(opti_D, feed_dict={\n                             self.images: realbatch_array, self.z: sample_z})\n                    batch_num += 1\n\n                # optimization G\n                sess.run(opti_G, feed_dict={self.z: sample_z})\n\n                summary_str = sess.run(summary_op, feed_dict={\n                                       self.images: realbatch_array, self.z: sample_z})\n                summary_writer.add_summary(summary_str, step)\n                # the alpha of fake_in process\n                sess.run(alpha_tra_assign, feed_dict={step_pl: step})\n\n                if step % 400 == 0:\n\n                    D_loss, G_loss, D_origin_loss, alpha_tra = sess.run([self.D_loss, self.G_loss, self.D_origin_loss, self.alpha_tra], feed_dict={\n                                                                        self.images: realbatch_array, self.z: sample_z})\n                    print(\"PG %d, step %d: D loss=%.7f G loss=%.7f, D_or loss=%.7f, opt_alpha_tra=%.7f\" % (\n                        self.pg, step, D_loss, G_loss, D_origin_loss, alpha_tra))\n\n                    realbatch_array = np.clip(realbatch_array, -1, 1)\n                    save_images(realbatch_array[0:self.batch_size], [2, self.batch_size/2],\n                                '{}_{:02d}_real.png'.format(self.sample_path, step))\n\n                    if self.trans and self.pg != 0:\n\n                        low_realbatch_array = np.clip(\n                            low_realbatch_array, -1, 1)\n\n                        save_images(low_realbatch_array[0:self.batch_size], [2, self.batch_size / 2],\n                                    '{}_{:02d}_real_lower.png'.format(self.sample_path, step))\n\n                    fake_image = sess.run(self.fake_images,\n                                          feed_dict={self.images: realbatch_array, self.z: sample_z})\n                    fake_image = np.clip(fake_image, -1, 1)\n                    save_images(fake_image[0:self.batch_size], [\n                                2, self.batch_size/2], '{}_{:02d}_train.png'.format(self.sample_path, step))\n\n                if np.mod(step, 4000) == 0 and step != 0:\n                    self.saver.save(sess, self.gan_model_path)\n                step += 1\n\n            save_path = self.saver.save(sess, self.gan_model_path)\n            print(\"Model saved in file: %s\" % save_path)\n\n        tf.reset_default_graph()\n\n    def discriminate(self, conv, reuse=False, pg=1, t=False, alpha_trans=0.01):\n\n        #dis_as_v = []\n        with tf.variable_scope(\"discriminator\") as scope:\n\n            if reuse == True:\n                scope.reuse_variables()\n            if t:\n                conv_iden = avgpool2d(conv)\n                # from RGB\n                conv_iden = lrelu(conv2d(conv_iden, output_dim=self.get_nf(pg - 2), k_w=1, k_h=1, d_h=1, d_w=1,\n                                         name='dis_y_rgb_conv_{}'.format(conv_iden.shape[1])))\n            # fromRGB\n            conv = lrelu(conv2d(conv, output_dim=self.get_nf(\n                pg - 1), k_w=1, k_h=1, d_w=1, d_h=1, name='dis_y_rgb_conv_{}'.format(conv.shape[1])))\n            for i in range(pg - 1):\n\n                conv = lrelu(conv2d(conv, output_dim=self.get_nf(pg - 1 - i), d_h=1, d_w=1,\n                                    name='dis_n_conv_1_{}'.format(conv.shape[1])))\n                conv = lrelu(conv2d(conv, output_dim=self.get_nf(pg - 2 - i), d_h=1, d_w=1,\n                                    name='dis_n_conv_2_{}'.format(conv.shape[1])))\n                conv = avgpool2d(conv, 2)\n                if i == 0 and t:\n                    conv = alpha_trans * conv + (1 - alpha_trans) * conv_iden\n\n            conv = MinibatchstateConcat(conv)\n            conv = lrelu(\n                conv2d(conv, output_dim=self.get_nf(1), k_w=3, k_h=3, d_h=1, d_w=1, name='dis_n_conv_1_{}'.format(conv.shape[1])))\n            conv = lrelu(\n                conv2d(conv, output_dim=self.get_nf(1), k_w=4, k_h=4, d_h=1, d_w=1, padding='VALID', name='dis_n_conv_2_{}'.format(conv.shape[1])))\n            conv = tf.reshape(conv, [self.batch_size, -1])\n\n            # for D\n            output = fully_connect(conv, output_size=1, scope='dis_n_fully')\n\n            return tf.nn.sigmoid(output), output\n\n    def generate(self, z_var, pg=1, t=False, alpha_trans=0.0):\n\n        with tf.variable_scope('generator') as scope:\n\n            de = tf.reshape(z_var, [self.batch_size, 1,\n                                    1, tf.cast(self.get_nf(1), tf.int32)])\n            de = conv2d(de, output_dim=self.get_nf(1), k_h=4, k_w=4,\n                        d_w=1, d_h=1, padding='Other', name='gen_n_1_conv')\n            de = Pixl_Norm(lrelu(de))\n            de = tf.reshape(de, [self.batch_size, 4, 4,\n                                 tf.cast(self.get_nf(1), tf.int32)])\n            de = conv2d(de, output_dim=self.get_nf(\n                1), d_w=1, d_h=1, name='gen_n_2_conv')\n            de = Pixl_Norm(lrelu(de))\n\n            for i in range(pg - 1):\n\n                if i == pg - 2 and t:\n                    # To RGB\n                    de_iden = conv2d(de, output_dim=3, k_w=1, k_h=1, d_w=1, d_h=1,\n                                     name='gen_y_rgb_conv_{}'.format(de.shape[1]))\n                    de_iden = upscale(de_iden, 2)\n\n                de = upscale(de, 2)\n                de = Pixl_Norm(lrelu(\n                    conv2d(de, output_dim=self.get_nf(i + 1), d_w=1, d_h=1, name='gen_n_conv_1_{}'.format(de.shape[1]))))\n                de = Pixl_Norm(lrelu(\n                    conv2d(de, output_dim=self.get_nf(i + 1), d_w=1, d_h=1, name='gen_n_conv_2_{}'.format(de.shape[1]))))\n\n            # To RGB\n            de = conv2d(de, output_dim=3, k_w=1, k_h=1, d_w=1, d_h=1,\n                        name='gen_y_rgb_conv_{}'.format(de.shape[1]))\n\n            if pg == 1:\n                return de\n\n            if t:\n                de = (1 - alpha_trans) * de_iden + alpha_trans*de\n\n            else:\n                de = de\n\n            return de\n\n    def get_nf(self, stage):\n        return min(1024 / (2 ** (stage * 1)), 512)\n\n    def get_fp(self, pg):\n        return max(512 / (2 ** (pg - 1)), 16)\n\n    def sample_z(self, mu, log_var):\n        eps = tf.random_normal(shape=tf.shape(mu))\n        return mu + tf.exp(log_var / 2) * eps","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport errno\nfl = [1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6]\nr_fl = [1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6]\n\n\ndef read_image_list(category):\n\n    filenames = []\n    print(\"list file\")\n    list = os.listdir(category)\n    list.sort()\n    for file in list:\n        if ('jpg' in file) or ('png' in file):\n            filenames.append(category + \"/\" + file)\n    print(\"list file ending!\")\n\n    length = len(filenames)\n    perm = np.arange(length)\n    np.random.shuffle(perm)\n    filenames = np.array(filenames)\n    filenames = filenames[perm]\n\n    return filenames\n\n\nclass BasicDataSet(object):\n\n    def __init__(self, image_path):\n\n        self.dataname = \"CelebA\"\n        self.dims = 64*64\n        self.shape = [64, 64, 3]\n        self.image_size = 64\n        self.image_list = read_image_list(category=image_path)\n\n    def load(self, image_path):\n\n        # get the list of image path\n        images_list = read_image_list(image_path)\n        # get the data array of image\n\n        return images_list\n\n    @staticmethod\n    def getShapeForData(filenames, resize_w=64):\n        array = [get_image(batch_file, 128, is_crop=True, resize_w=resize_w,\n                           is_grayscale=False) for batch_file in filenames]\n\n        sample_images = np.array(array)\n        # return sub_image_mean(array , IMG_CHANNEL)\n        return sample_images\n\n    def getNextBatch(self, batch_num=0, batch_size=64):\n\n        ro_num = len(self.image_list) / batch_size - 1\n        if batch_num % ro_num == 0:\n\n            length = len(self.image_list)\n            perm = np.arange(length)\n            np.random.shuffle(perm)\n            self.image_list = np.array(self.image_list)\n            self.image_list = self.image_list[perm]\n            print(\"images shuffle\")\n        t_slice = slice(int((batch_num % ro_num) * batch_size), int((batch_num % ro_num + 1) * batch_size))\n        return self.image_list[t_slice]\n    \ndef transform(image, npx= 64 , is_crop=False, resize_w= 64):\n\n    # npx : # of pixels width/height of image\n    if is_crop:\n        cropped_image = center_crop(image , npx , resize_w = resize_w)\n    else:\n        cropped_image = image\n        cropped_image = scipy.misc.imresize(cropped_image ,\n                            [resize_w , resize_w])\n    return np.array(cropped_image)/127.5 - 1\n\ndef get_image(image_path , image_size , is_crop=True, resize_w = 64 , is_grayscale = False):\n    return transform(imread(image_path , is_grayscale), image_size, is_crop , resize_w)\n\ndef imread(path, is_grayscale=False):\n    if (is_grayscale):\n        return scipy.misc.imread(path, flatten=True).astype(np.float)\n    else:\n        return scipy.misc.imread(path).astype(np.float)\nfrom skimage.util.montage import montage2d\ndef merge(images, size):\n    if len(np.shape(images[0]))==3:\n        return np.stack([montage2d(np.stack([c_img[:,:,i] for c_img in images],0)) for i in range(np.shape(images[0])[-1])],-1)\n    elif len(np.shape(images[0]))==2:\n        return montage2d(images)\n    else:\n        raise ValueError('Incompatible shape: {}'.format(np.shape(images[0])))\n\ndef mkdir_p(path):\n    try:\n        os.makedirs(path)\n    except OSError as exc:  # Python >2.5\n        if exc.errno == errno.EEXIST and os.path.isdir(path):\n            pass\n        else:\n            raise\n\n\ndata_In = BasicDataSet('../input/train/Charlock')\nroot_log_dir = '.'\nsample_size = 512\nGAN_learn_rate = 0.0001","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7efe980452b10a38ec2dbf9bab799dd42153dd48","scrolled":false,"_cell_guid":"1b09f97b-3632-48d3-b5f2-aa7b66094004","trusted":true},"cell_type":"code","source":"for i in range(11):\n    t = False if (i % 2 == 0) else True\n    pggan_checkpoint_dir_write = \"./model_pggan/{}/\".format(fl[i])\n    sample_path = \"./PGGanCeleba/sample_{}_{}\".format(fl[i], t)\n    mkdir_p(pggan_checkpoint_dir_write)\n    mkdir_p(sample_path)\n    pggan_checkpoint_dir_read = \"./model_pggan/{}/\".format(r_fl[i])\n    pggan = PGGAN(batch_size=32,\n                  max_iters=10,\n                  model_path=pggan_checkpoint_dir_write,\n                  read_model_path=pggan_checkpoint_dir_read,\n                  data=data_In,\n                  sample_size=sample_size,\n                  sample_path=sample_path,\n                  log_dir=root_log_dir,\n                  learn_rate=GAN_learn_rate,\n                  PG=fl[i],\n                  t=t)\n\n    pggan.build_model_PGGan()\n    pggan.train()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43ebe43565fce8559f53f804770eff8e0fb7ce0b","_cell_guid":"e175840c-1c37-4fd7-90dd-07ebba14907f","trusted":true},"cell_type":"code","source":"data_In = BasicDataSet('../input/train/Charlock')\ntf.reset_default_graph()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b3a6a13514f838bf6e051e6c2a2bd4e904f8e22","_cell_guid":"f09f16d0-0073-476b-bdc5-95fbd4eea1e8"},"cell_type":"markdown","source":"# Start Code\nInitialize parameters"},{"metadata":{"_uuid":"0524f3392e41437f7605874599dd41b18879ef8a","_cell_guid":"b4d1c452-e9ed-479b-955c-73982aa62aa7"},"cell_type":"markdown","source":"# Low Resolution 8x8"},{"metadata":{"_uuid":"fda7090c829d5d74214b0f38b36eac433f178d43","_cell_guid":"907e5c24-05c9-4306-aa3f-4aea693443fa"},"cell_type":"markdown","source":"## Step-2 : Transition from 8x8 to 16x16 resolution (fading)\nNote that this step will automatically load model from 8x8 resolution (models/8x8). So, you can leave cfg.load_model = None."},{"metadata":{"_uuid":"c341c5d58b0b86fd558ce243a3466e34f675a678","_cell_guid":"b424de84-a5a9-4a8f-84c7-b60bee9413f7"},"cell_type":"markdown","source":"## Step-4 : Transition from 16x16 to 32x32 resolution (fading)\nAgain, this step will automatically load model from models/16x16."},{"metadata":{"_uuid":"f634bcfbfc633755527b474bb9c6bd75caef78d1","_cell_guid":"20e62e33-e253-4879-a2da-2e3bf1d83515","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}