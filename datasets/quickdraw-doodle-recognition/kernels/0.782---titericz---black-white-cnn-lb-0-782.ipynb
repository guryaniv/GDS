{"cells":[{"metadata":{"_uuid":"1a923c2104562eadf00c5807ee9d5fcbd973f9ec"},"cell_type":"markdown","source":"# Keras Simple CNN Benchmark\n\nI assume you are already familiar with the competition dataset. This benchmark helps you to reach 0.78 MAP@3.\n\nThis kernel has three main components:\n\n* Simple configurable Convolutional Network\n* Fast and memory efficient Image Generator\n* Flip Augmentation\n* Full training & submission with Kaggle Kernel\n* TTA\n\nI did some paramer search but it should not be hard to improve the current score. Simplified versions could be trained without GPU."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%matplotlib inline\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport os\nimport ast\nimport datetime as dt\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.figsize'] = [16, 10]\nplt.rcParams['font.size'] = 14\nimport seaborn as sns\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\n\nstart = dt.datetime.now()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"033879c8451c02295c28b3680ec9e51f023a059f","_kg_hide-input":true},"cell_type":"code","source":"DP_DIR = '../input/shuffle-csvs/'\nINPUT_DIR = '../input/quickdraw-doodle-recognition/'\nBASE_SIZE = 256\nNCSVS = 100\nNCATS = 340\nnp.random.seed(seed=1987)\ntf.set_random_seed(seed=1987)\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1b7f42049a9bda3b2a797abddfe55b8d8e83742","_kg_hide-input":true},"cell_type":"code","source":"def apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i + 1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6b6da3ac9bbf135258b03b04a3e7fd49f617fed"},"cell_type":"markdown","source":"## Simple ConvNet"},{"metadata":{"trusted":true,"_uuid":"4eb6c530d54785696674d2b8240271c91b93f6f1"},"cell_type":"code","source":"def custom_single_cnn(size, conv_layers=(8, 16, 32, 64), dense_layers=(512, 256), conv_dropout=0.2,\n                      dense_dropout=0.2):\n    model = Sequential()\n    model.add( Conv2D(conv_layers[0], kernel_size=(3, 3), padding='same', activation='relu', input_shape=(size, size, 1)) )\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    #if conv_dropout:\n    #    model.add(Dropout(conv_dropout))\n\n    for conv_layer_size in conv_layers[1:]:\n        model.add(Conv2D(conv_layer_size, kernel_size=(3, 3), activation='relu'))\n        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n        if conv_dropout:\n            model.add(Dropout(conv_dropout))\n\n    model.add(Flatten())\n    if dense_dropout:\n        model.add(Dropout(dense_dropout))\n\n    for dense_layer_size in dense_layers:\n        model.add(Dense(dense_layer_size, activation='relu'))\n        model.add(Activation('relu'))\n        if dense_dropout:\n            model.add(Dropout(dense_dropout))\n\n    model.add(Dense(NCATS, activation='softmax'))\n    return model\n\ndef top_3_accuracy(y_true, y_pred):\n    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n\ndef top3_acc( tgt, pred ):\n    sc = np.mean( (pred[:,0]==tgt) | (pred[:,1]==tgt) | (pred[:,2]==tgt) )\n    return sc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08c624ee6f13f928ca915829e99f31d5c783921a"},"cell_type":"code","source":"STEPS = 500\nsize = 32\nbatchsize = 512","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8cf540bbf09ab24bd34a207891eb9d1bd93e7f21"},"cell_type":"code","source":"model = custom_single_cnn(size=size,\n                          conv_layers=[128, 128],\n                          dense_layers=[2048],\n                          conv_dropout=False,\n                          dense_dropout=0.10 )\nmodel.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d378ee2118a50627c8fd0930249b82d3e9ee42b5"},"cell_type":"markdown","source":"## Training with Image Generator"},{"metadata":{"trusted":true,"_uuid":"7c9a777674c6e20392037a3b5113a0e8c92e0a5e"},"cell_type":"code","source":"def draw_cv2(raw_strokes, size=256, lw=6):\n    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n    for stroke in raw_strokes:\n        for i in range(len(stroke[0]) - 1):\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), 255, lw)\n    if np.random.rand()>0.5:\n        img = np.fliplr(img)\n    if np.random.rand()>0.75:\n        if np.random.rand()>0.50:\n            img = img[ 4:, 4: ]\n        else:\n            img = img[ :-4, :-4 ]\n    if np.random.rand()>0.50:\n        img2 = cv2.resize(img, (200, 200))\n        img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n        img[18:218,18:218] = img2\n\n    if size != BASE_SIZE:\n        return cv2.resize(img, (size, size))\n    else:\n        return img\n\ndef image_generator(size, batchsize, ks, lw=6):\n    while True:\n        for k in np.random.permutation(ks):\n            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing'] = df['drawing'].apply(ast.literal_eval)\n                x = np.zeros((len(df), size, size))\n                for i, raw_strokes in enumerate(df.drawing.values):\n                    x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n                x = x / 255.\n                x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield x, y\n\ndef df_to_image_array(df, size, lw=6):\n    df['drawing'] = df['drawing'].apply(ast.literal_eval)\n    x = np.zeros((len(df), size, size))\n    for i, raw_strokes in enumerate(df.drawing.values):\n        x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n    x = x / 255.\n    x = x.reshape((len(df), size, size, 1)).astype(np.float32)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d20f0992f56f63efafb633b2e992f2a00746a22"},"cell_type":"code","source":"valid_df = pd.read_csv(os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(NCSVS - 1)), nrows=55555)\nx_valid = df_to_image_array(valid_df, size)\ny_valid = keras.utils.to_categorical(valid_df.y, num_classes=NCATS)\nprint(x_valid.shape, y_valid.shape)\nprint('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9413b82070175b63f940ddb2c29c53ffa2d666b"},"cell_type":"code","source":"train_datagen = image_generator(size=size, batchsize=batchsize, ks=range(NCSVS - 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94084dbe4e224cb185d0107378497f6f63024069"},"cell_type":"code","source":"x, y = next(train_datagen)\nn = 10\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(10, 10))\nfor i in range(n**2):\n    ax = axs[i // n, i % n]\n    ax.imshow(x[i, :, :, 0], cmap=plt.cm.gray)\n    ax.axis('off')\nplt.tight_layout()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4e239911c2464297c9939d3487ccf747869d89c"},"cell_type":"code","source":"callbacks = [\n    #EarlyStopping(monitor='val_top_3_accuracy', patience=15, min_delta=0.001, mode='max'),\n    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=5, min_delta=0.005, mode='max', cooldown=3),\n    ModelCheckpoint(\"./black-white-7.model\",monitor='val_top_3_accuracy', mode = 'max', save_best_only=True, verbose=1)\n]\nhist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77d4337b9df025e8b7e553c2b8e14e4eb4f9ef8c"},"cell_type":"code","source":"hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a8d3a4fc4f01a6758f1a8a6b5f5f3f781f4b14c"},"cell_type":"code","source":"hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11f4883c7fd2f87ae9a336c117a1ebeb5148ff8b"},"cell_type":"code","source":"hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25b411664558f1598efad14c7dd5a64307f33ec4"},"cell_type":"code","source":"hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6404173191921e78c775b97ed33ea0a2601e97e"},"cell_type":"code","source":"hist = model.fit_generator(\n    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n    validation_data=(x_valid, y_valid),\n    callbacks = callbacks\n)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cbf298635892171c021d3a3171aa30918f0f182e"},"cell_type":"code","source":"hist_df = pd.DataFrame(hist.history)\nfig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\naxs[0].plot(hist_df.val_categorical_accuracy, lw=5)\naxs[0].set_ylabel('Accuracy')\naxs[0].set_xlabel('Epoch')\naxs[0].grid()\naxs[1].plot(hist_df.val_categorical_crossentropy, lw=5)\naxs[1].set_ylabel('MLogLoss')\naxs[1].grid()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0540513f0592b6fb258a425ecb000b6b9f074726"},"cell_type":"code","source":"#Load Best Epoch\n#model = load_model(\"./black-white-1.model\", custom_objects={'top_3_accuracy': top_3_accuracy } )\nvalid_predictions1 = model.predict(x_valid, batch_size=128, verbose=1)\nmap3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions1).values)\ntop3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(valid_predictions1).values)\nprint('Map3: {:.3f}'.format(map3))\nprint('Top3: {:.3f}'.format(top3))\n\nx_valid2 = np.array( [ np.fliplr(x_valid[i]) for i in range(x_valid.shape[0])] )\nvalid_predictions2 = model.predict(x_valid2, batch_size=128, verbose=1)\nmap3 = mapk(valid_df[['y']].values, preds2catids(valid_predictions2).values)\ntop3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(valid_predictions2).values)\nprint('Map3: {:.3f}'.format(map3))\nprint('Top3: {:.3f}'.format(top3))\n\nmap3 = mapk(valid_df[['y']].values, preds2catids(0.5*valid_predictions1+0.5*valid_predictions2).values)\ntop3 = top3_acc(valid_df[['y']].values.flatten(), preds2catids(0.5*valid_predictions1+0.5*valid_predictions2).values)\nprint('Map3: {:.3f}'.format(map3))\nprint('Top3: {:.3f}'.format(top3))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b6a85721c0f0c729304b7850732869e4768a6e3"},"cell_type":"markdown","source":"## Create Submission"},{"metadata":{"trusted":true,"_uuid":"013498ff78e94080beebec27b550880cace10f78"},"cell_type":"code","source":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\ntest.head()\nx_test = df_to_image_array(test, size)\nprint(test.shape, x_test.shape)\nprint('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"272866eba0ba6e82e0146c087dd68c12da28ecde"},"cell_type":"code","source":"test_predictions1 = model.predict(x_test, batch_size=128, verbose=1)\n\nx_test2 = np.array( [ np.fliplr(x_test[i]) for i in range(x_test.shape[0])] )\ntest_predictions2 = model.predict(x_test2, batch_size=128, verbose=1)\n\ntest_predictions = 0.5*test_predictions1 + 0.5*test_predictions2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1e4cdaa29b62d65098b0ab0b322305298b8271d"},"cell_type":"code","source":"top3 = preds2catids(test_predictions)\ntop3.head()\ntop3.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"160a4a63cb0333bbb9d729699d08e6a32ce78ab3"},"cell_type":"code","source":"cats = list_all_categories()\nid2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\ntop3cats = top3.replace(id2cat)\ntop3cats.head()\ntop3cats.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5347d382cb5dc013d10de946f078ed9dd9e54929"},"cell_type":"code","source":"test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\nsubmission = test[['key_id', 'word']]\nsubmission.to_csv('bw_cnn_submission_{}.csv'.format(int(map3 * 10**4)), index=False)\nsubmission.head()\nsubmission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c8c50504611ec3db916b0d6c0a8aec1ca1263bf"},"cell_type":"code","source":"end = dt.datetime.now()\nprint('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4314e4770303e95c7b75f098dcd786a382ba737"},"cell_type":"markdown","source":"## Acknowledments\nThanks for @jpmiller and @mihaskalic for publishing their starter kernels quite early.\n\n [1] https://www.kaggle.com/jpmiller/image-based-cnn\n \n[2] https://www.kaggle.com/mihaskalic/when-in-doubt-convnets"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}