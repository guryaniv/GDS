{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"## General information.\n\nFor EDA please refer to my [another kernel](https://www.kaggle.com/artgor/movie-review-sentiment-analysis-eda-and-models).\n\nRecently Capsule Neural Nets became a known thing. They didn't become really widespread, but still can be useful. Usually they are used in computer vision, but capsule NN prove to be efficient also in NLP. If you wish to know more theory, I recommend this amazing [kernel](https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-capsule-networks). And now let's try it. Here is a [link](https://github.com/mattmotoki/toxic-comment-classification/blob/master/code/modeling/Refine CapsuleNet.ipynb) to the implementation which I used."},{"metadata":{"trusted":true,"_uuid":"55cfd4d0ce27d7470142bcba073de5a1432f47e4","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, PReLU\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/train.tsv', sep=\"\\t\")\ntest = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/test.tsv', sep=\"\\t\")\nsub = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv', sep=\",\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9e3f5c5d7cdf277520362de24efe7a2357f33557"},"cell_type":"code","source":"tk = Tokenizer(lower = True, filters='')\nfull_text = list(train['Phrase'].values) + list(test['Phrase'].values)\ntk.fit_on_texts(full_text)\ntrain_tokenized = tk.texts_to_sequences(train['Phrase'])\ntest_tokenized = tk.texts_to_sequences(test['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48fc66871547fef7b674cf0b016d72688c4e200b","collapsed":true},"cell_type":"code","source":"max_len = 50\nX_train = pad_sequences(train_tokenized, maxlen = max_len)\nX_test = pad_sequences(test_tokenized, maxlen = max_len)\n\nembedding_path = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\n\nembed_size = 300\nmax_features = 20000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e0980e7dc61ea9b3328f16e6cecc5e29df1d75c5"},"cell_type":"code","source":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n\nword_index = tk.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words + 1, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"286fca3690cdd72d5dc628836c5d396e57d1ebb7"},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ny = train['Sentiment']\n\nohe = OneHotEncoder(sparse=False)\ny_ohe = ohe.fit_transform(y.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d31168b6258779fbb075e9542079ff3bd348af0a"},"cell_type":"code","source":"file_path = \"best_model.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c560010df53d9728f53b861c7b837aa809924030"},"cell_type":"code","source":"def squash(x, axis=-1):\n    # s_squared_norm is really small\n    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n    # return scale * x\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n    scale = K.sqrt(s_squared_norm + K.epsilon())\n    return x / scale\n\n# A Capsule Implement with Pure Keras\nclass Capsule(Layer):\n    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n                 activation='default', **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.kernel_size = kernel_size\n        self.share_weights = share_weights\n        if activation == 'default':\n            self.activation = squash\n        else:\n            self.activation = Activation(activation)\n\n    def build(self, input_shape):\n        super(Capsule, self).build(input_shape)\n        input_dim_capsule = input_shape[-1]\n        if self.share_weights:\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(1, input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     # shape=self.kernel_size,\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n        else:\n            input_num_capsule = input_shape[-2]\n            self.W = self.add_weight(name='capsule_kernel',\n                                     shape=(input_num_capsule,\n                                            input_dim_capsule,\n                                            self.num_capsule * self.dim_capsule),\n                                     initializer='glorot_uniform',\n                                     trainable=True)\n\n    def call(self, u_vecs):\n        if self.share_weights:\n            u_hat_vecs = K.conv1d(u_vecs, self.W)\n        else:\n            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n\n        batch_size = K.shape(u_vecs)[0]\n        input_num_capsule = K.shape(u_vecs)[1]\n        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n                                            self.num_capsule, self.dim_capsule))\n        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n\n        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n        for i in range(self.routings):\n            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n            c = K.softmax(b)\n            c = K.permute_dimensions(c, (0, 2, 1))\n            b = K.permute_dimensions(b, (0, 2, 1))\n            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n            if i < self.routings - 1:\n                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n\n        return outputs\n\n    def compute_output_shape(self, input_shape):\n        return (None, self.num_capsule, self.dim_capsule)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dd5d5ed0a9a37867b489cdd55c9a611950251898"},"cell_type":"code","source":"def get_model_capsule(gru_spec=(128, 0), gru_dropout=5e-5, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n    inp = Input(shape = (max_len,))\n    x = Embedding(19479, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n    x1 = SpatialDropout1D(dr)(x)\n\n    x_gru = Bidirectional(CuDNNGRU(units, return_sequences = True))(x1)\n    x_words = PReLU()(x_gru)\n    x_words = Capsule(num_capsule=5, dim_capsule=16, routings=5, share_weights=True)(x_words)\n    x_words = Flatten()(x_words)\n    x_words = Dropout(0.15)(x_words)\n\n    \n    x = Dropout(0.1)(Dense(64,activation='relu') (x_words))\n    pred = Dense(5, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = pred)\n    model.summary()\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, y_ohe, batch_size = 128, epochs = 20, validation_split=0.1, \n                        verbose = 1, callbacks = [check_point, early_stop])\n    #model = load_model(file_path)\n\n    return model\n\nmodel_capsule = get_model_capsule(lr = 1e-3, units = 128, dr = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ad487f8960c4f11c6e6234731b3b13bc9141d882"},"cell_type":"code","source":"pred = model_capsule.predict(X_test, batch_size = 1024, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"562e932966985475ca1f25ddaded4fe51b6adc73"},"cell_type":"code","source":"predictions = np.round(np.argmax(pred, axis=1)).astype(int)\nsub['Sentiment'] = predictions\nsub.to_csv(\"capsule.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}