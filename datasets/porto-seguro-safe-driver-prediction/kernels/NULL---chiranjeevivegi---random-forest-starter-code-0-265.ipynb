{"cells": [{"metadata": {"_cell_guid": "a9a2e09c-5502-4466-8497-5ce474cfc9c6", "_uuid": "0ca347e6b5ec096766285991438a4dc704178400", "collapsed": true}, "source": ["For STARTERS The notebook containes starter code to use Adaboost Machine learning model. I haven't tuned the parameters in this model. Hope this notebook could be of some use. \n", "Gradient Boost Starter Code: https://www.kaggle.com/chiranjeevivegi/gradient-boost-starter-code-0-264/\n", "Adaboost Starter code: https://www.kaggle.com/chiranjeevivegi/adaboost-starter-code-0-254"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "3b8e9e2e-70dd-4c76-b935-0c70ec39c65d", "_uuid": "10551519d7cd6026652bc411117adba09dbf7278", "collapsed": true}, "source": ["### IMPORTING REQUIRED PACKAGES\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# machine learning modules\n", "import sklearn\n", "print(sklearn.__version__)\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "bd703946-079c-420a-ac73-3245e18684bc", "_uuid": "c613a87e9b0055318679f45d619a14b5f29cf624", "collapsed": true}, "source": ["#### LOADING DATA ####\n", "### TRAIN DATA\n", "train_data = pd.read_csv(\"../input/train.csv\", na_values='-1')\n", "                        \n", "## Filling the missing data NAN with median of the column\n", "train_data_nato_median = pd.DataFrame()\n", "for column in train_data.columns:\n", "    train_data_nato_median[column] = train_data[column].fillna(train_data[column].median())\n", "\n", "train_data = train_data_nato_median.copy()\n", "\n", "### TEST DATA\n", "test_data = pd.read_csv(\"../input/test.csv\", na_values='-1')\n", "## Filling the missing data NAN with mean of the column\n", "test_data_nato_median = pd.DataFrame()\n", "for column in test_data.columns:\n", "    test_data_nato_median[column] = test_data[column].fillna(test_data[column].median())\n", "    \n", "test_data = test_data_nato_median.copy()\n", "test_data_id = test_data.pop('id')"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "040fd51a-9ed5-4d46-81bd-b03effc5e44a", "_uuid": "62ccdbaeb6cea102e37748d21b327d474e7be5e0", "collapsed": true}, "source": ["## Identifying Categorical data\n", "column_names = train_data.columns\n", "categorical_column = column_names[column_names.str[10] == 'c']\n", "\n", "## Changing categorical columns to category data type\n", "def int_to_categorical(data):\n", "    \"\"\" \n", "    changing columns to catgorical data type\n", "    \"\"\"\n", "    for column in categorical_column:\n", "        data[column] =  data[column].astype('category')\n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "fc4883c5-c289-44d6-af0b-e03b9a48fd30", "_uuid": "dcbfe74a8ea0d326fffc0e3a8b998eb4e8e7429f", "collapsed": true}, "source": ["## Creating list of train and test data and converting columns of interest to categorical type\n", "datas = [train_data,test_data]\n", "\n", "for data in datas:\n", "    int_to_categorical(data)\n", "\n", "print(test_data.dtypes)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "4b2aaea1-d723-42f2-9f52-f5c678074a94", "_uuid": "283d4739064aedd0444c56ac8490e48a6e91f873", "collapsed": true}, "source": ["\n", "## Decribing categorical variables\n", "# def decribe_Categorical(x):\n", "#     \"\"\" \n", "#     Function to decribe Categorical data\n", "#     \"\"\"\n", "#     from IPython.display import display, HTML\n", "#     display(HTML(x[x.columns[x.dtypes ==\"category\"]].describe().to_html))\n", "\n", "# decribe_Categorical(train_data)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "79d177cd-cfb7-4724-aa38-a213bc642a84", "_uuid": "5967862ce5966de4983bbac43566cbb45102bd55", "collapsed": true}, "source": ["\n", "### FUNCTION TO CREATE DUMMIES COLUMNS FOR CATEGORICAL VARIABLES\n", "def creating_dummies(data):\n", "    \"\"\"creating dummies columns categorical varibles\n", "    \"\"\"\n", "    for column in categorical_column:\n", "        dummies = pd.get_dummies(data[column],prefix=column)\n", "        data = pd.concat([data,dummies],axis =1)\n", "        ## dropping the original columns ##\n", "        data.drop([column],axis=1,inplace= True)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "b9dcc2c1-d657-423d-a48e-ce2f7ef896bf", "_uuid": "3d1133dba05d8fab48eb762369f83ef5e548e9e9", "collapsed": true}, "source": ["\n", "### CREATING DUMMIES FOR CATEGORICAL VARIABLES  \n", "for column in categorical_column:\n", "        dummies = pd.get_dummies(train_data[column],prefix=column)\n", "        train_data = pd.concat([train_data,dummies],axis =1)\n", "        train_data.drop([column],axis=1,inplace= True)\n", "\n", "\n", "for column in categorical_column:\n", "        dummies = pd.get_dummies(test_data[column],prefix=column)\n", "        test_data = pd.concat([test_data,dummies],axis =1)\n", "        test_data.drop([column],axis=1,inplace= True)\n", "\n", "print(train_data.shape)\n", "print(test_data.shape)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"scrolled": true, "_cell_guid": "4971e511-a002-4d7e-80d7-086931e4ee77", "_uuid": "efa03b2f2f67941caa908bbfa61b21af4c10c39c", "collapsed": true}, "source": ["#Define covariates in X and dependent variable in y\n", "X = train_data.iloc[:,2:] ## FEATURE DATA\n", "y= train_data.target ### LABEL DATA\n", "\n", "### CHECKING DIMENSIONS\n", "print(X.shape)\n", "print(y.shape)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "45e0acc2-25f6-461f-8062-580ac814a93c", "_uuid": "733c9c2840814efa3b45ad960a393e34197b5132", "collapsed": true}, "source": ["#### SPLITTING DATA INTO TRAIN AND TEST SETS\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13)\n", "\n", "\n", "### RANDOM FOREST CLASSIFIER\n", "\n", "\"\"\"\n", "number of estimators: 200\n", "out of bagging set to True\n", "N_jobs: Use all the available cores= -1\n", "min_sample_leaf: minimum number of samples required to be at a leaf node\n", "\"\"\"\n", "RF_model_cat= RandomForestClassifier(200,oob_score=True,random_state=13,\n", "                                     n_jobs = -1, min_samples_leaf = 100)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "7eb378b6-2519-486b-8116-531627947113", "_uuid": "0010cca3e7962b59a12f4f294d84edd979404aa7", "collapsed": true}, "source": ["### FITTING RANDOM MODEL \n", "RF_model_cat.fit(X_train, y_train)\n", "\n", "#Obtain class predictions\n", "y_pred_RF_prob = RF_model_cat.predict_proba(X_test)\n", "print('Predicted probabilities: \\n', y_pred_RF_prob)\n", "\n", "#Obtain probability predictions\n", "y_pred_RF_class = RF_model_cat.predict(X_test)\n", "print('Predicted classes: \\n', y_pred_RF_class)\n", "\n", "print('RF Score: ', metrics.accuracy_score(y_test, y_pred_RF_class))\n", "\n", "## CONFUSION MATRIX\n", "RF_cm=metrics.confusion_matrix(y_test,y_pred_RF_class)\n", "print(RF_cm)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "1bc789d9-b7d2-46e7-ac8d-53c2acfd5e3d", "_uuid": "51759fa4973094f501e5bb43c7cc7fa06e931abf", "collapsed": true}, "source": ["#### Predicition on test data ####\n", "y_pred_RF_prob = RF_model_cat.predict_proba(test_data)\n", "pred_values= pd.DataFrame(y_pred_RF_prob)\n", "\n", "submission_simple_RF= pd.DataFrame()\n", "submission_simple_RF['id'] = test_data_id\n", "\n", "submission_simple_RF['target'] = pd.DataFrame(pred_values.iloc[:,1])\n", "submission_simple_RF = submission_simple_RF.set_index('id')\n", "\n", "submission_simple_RF.columns\n", "submission_simple_RF.head()\n", "## Write to CSV\n", "#submission_simple_RF.to_csv(\"Simple Random Forest.csv\")"], "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}