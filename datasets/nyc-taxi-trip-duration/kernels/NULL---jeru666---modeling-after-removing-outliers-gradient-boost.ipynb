{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py"}}, "cells": [{"metadata": {"_execution_state": "busy", "_uuid": "d426e9f4f1bf2f49f271d6c4c09a1bdbb33c069c", "_cell_guid": "2bbba68e-752c-411c-a973-8e36c08a1997"}, "outputs": [], "execution_count": null, "source": "Hey there!!\n\nHere is a list of things I have done so far:\n", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "4c1c0680c64691c34d31d2c17fd35970dff72d0c", "_cell_guid": "a46ebaa5-5a52-432d-b292-4f6131ed8c01"}, "outputs": [], "execution_count": null, "source": "import matplotlib.pyplot as plt    #--- for plotting ---\nimport numpy as np                 #--- linear algebra ---\nimport pandas as pd                #--- data processing, CSV file I/O (e.g. pd.read_csv) ---\nimport seaborn as sns              #--- for plotting and visualizations ---\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Input data files are available in the \"../input/\" directory.\npath = 'D:/BACKUP/Kaggle/New York City Taxi/Data/'\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n#--- Let's peek into the data\nprint (train_df.head())\nprint (test_df.head())", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "f0e0889a2195e0a5ec48c7aa791bfe365febdf39", "_cell_guid": "d71037bd-4156-4d1c-8dee-6e23a075651c"}, "outputs": [], "execution_count": null, "source": "**Adding newer columns to the dataframe**", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "d52ea73e64ce1e0f890d4c57493663df803a3178", "_cell_guid": "657be7f0-bec0-4966-82b4-398f4d950e3a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "from math import radians, cos, sin, asin, sqrt   #--- for the mathematical operations involved in the function ---\n\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians \n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula \n    dlon = lon2 - lon1 \n    dlat = lat2 - lat1 \n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a)) \n    km = 6367 * c\n    return km\n\ntrain_df['Haversine_dist'] = train_df.apply(lambda x: haversine(x['pickup_longitude'], x['pickup_latitude'], x['dropoff_longitude'], x['dropoff_latitude']), axis=1)\ntest_df['Haversine_dist'] = test_df.apply(lambda x: haversine(x['pickup_longitude'], x['pickup_latitude'], x['dropoff_longitude'], x['dropoff_latitude']), axis=1)\n#train_df['Haversine_dist'] = haversine(train_df['pickup_longitude'], train_df['pickup_latitude'],train_df['dropoff_longitude'], train_df['dropoff_latitude'])\n#print (train_df.head())", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "4abbae7040ee67fac14779442f122e5df64f2b57", "_cell_guid": "3444c5bf-cace-4cc2-a653-6531d7b2b534", "collapsed": true}, "outputs": [], "execution_count": null, "source": "def arrays_bearing(lats1, lngs1, lats2, lngs2, R=6371):\n    lats1_rads = np.radians(lats1)\n    lats2_rads = np.radians(lats2)\n    lngs1_rads = np.radians(lngs1)\n    lngs2_rads = np.radians(lngs2)\n    lngs_delta_rads = np.radians(lngs2 - lngs1)\n    \n    y = np.sin(lngs_delta_rads) * np.cos(lats2_rads)\n    x = np.cos(lats1_rads) * np.sin(lats2_rads) - np.sin(lats1_rads) * np.cos(lats2_rads) * np.cos(lngs_delta_rads)\n    \n    return np.degrees(np.arctan2(y, x))\n\ntrain_df['bearing_dist'] = arrays_bearing(\ntrain_df['pickup_latitude'], train_df['pickup_longitude'], \ntrain_df['dropoff_latitude'], train_df['dropoff_longitude'])\n\ntest_df['bearing_dist'] = arrays_bearing(\ntest_df['pickup_latitude'], test_df['pickup_longitude'], \ntest_df['dropoff_latitude'], test_df['dropoff_longitude'])\n\n#print (train_df.head())\n#print (test_df.head())", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "1b9d432313c24ba4251119369ad6d9c36fcc2f15", "_cell_guid": "e43e8b5b-5cc8-4978-82da-e922a6e3c508", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df['Manhattan_dist'] = \\\n    (train_df['dropoff_longitude'] - train_df['pickup_longitude']).abs() + \\\n    (train_df['dropoff_latitude'] - train_df['pickup_latitude']).abs()\n    \ntest_df['Manhattan_dist'] = \\\n    (test_df['dropoff_longitude'] - test_df['pickup_longitude']).abs() + \\\n    (test_df['dropoff_latitude'] - test_df['pickup_latitude']).abs()    \n    \n#print(train_df.head())  \n#print(test_df.head())  ", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "b4281ea17643e70be4e0373fe581b1d4ceb1de5f", "_cell_guid": "a29a2ff1-aa51-4bfc-a586-c7686f3211cf", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Taken from Part 2 ---\ntrain_df['pickup_datetime'] = pd.to_datetime(train_df['pickup_datetime'])\ntrain_df['dropoff_datetime'] = pd.to_datetime(train_df['dropoff_datetime'])\n\ntrain_df['pickup_month'] = train_df.pickup_datetime.dt.month.astype(np.uint8)\ntrain_df['pickup_day'] = train_df.pickup_datetime.dt.weekday.astype(np.uint8)\ntrain_df['pickup_hour'] = train_df.pickup_datetime.dt.hour.astype(np.uint8)\n\ntrain_df['dropoff_month'] = train_df.dropoff_datetime.dt.month.astype(np.uint8)\ntrain_df['dropoff_day'] = train_df.dropoff_datetime.dt.weekday.astype(np.uint8)\ntrain_df['dropoff_hour'] = train_df.dropoff_datetime.dt.hour.astype(np.uint8)\n#print (train_df.head())\n\n#--- Doing the same for the test data excluding dropoff time ---\ntest_df['pickup_datetime'] = pd.to_datetime(test_df['pickup_datetime'])\n\ntest_df['pickup_month'] = test_df.pickup_datetime.dt.month.astype(np.uint8)\ntest_df['pickup_day'] = test_df.pickup_datetime.dt.weekday.astype(np.uint8)\ntest_df['pickup_hour'] = test_df.pickup_datetime.dt.hour.astype(np.uint8)\n\n#print (test_df.head())", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "034b6b72d781800f2a191eb81f6a4740dc6848ba", "_cell_guid": "b685aef9-10cb-45e1-bb1c-cbd46919838a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df['trip_duration_mins'] = train_df['trip_duration'] / 60\ntrain_df['trip_duration_hours'] = train_df['trip_duration_mins'] / 60\n#print (train_df.head())", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "a058abe540ebab6a28890bab2f1704a7017e80ba", "_cell_guid": "6077b6aa-d838-4ab5-ad70-34447a4cdd3d"}, "outputs": [], "execution_count": null, "source": "**Removing Outliers**\n\n**1. Very long trip durations**", "cell_type": "markdown"}, {"metadata": {"_execution_state": "idle", "_uuid": "d4cfc428de930e62c69b3093d1fb7e637ed6c688", "_cell_guid": "751cb2f5-02e1-4c84-8fbb-25517604ce7b"}, "outputs": [], "execution_count": null, "source": "Hourly statitics of trip duration", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "4bad3ebe73a2ed6cbef12ea0755cc433e5af838e", "_cell_guid": "bb50ebb4-33b2-4e01-b202-efbad28f646b"}, "outputs": [], "execution_count": null, "source": "print(max(train_df['trip_duration_hours']))\nprint(min(train_df['trip_duration_hours']))\n\nprint(train_df['trip_duration_hours'].describe())", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "f1a13e5257ceae9df1a2f49428bab9e0c64732e6", "_cell_guid": "9e0d9caf-1987-439e-82a7-5d9ea678b286"}, "outputs": [], "execution_count": null, "source": "Let us remove all the trips that are above 5 hours. ", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "dc8c87db480d4cf6c198894474f8991eb260231e", "_cell_guid": "780b4f29-66b6-4b0c-b4c0-bdce85e2bf40"}, "outputs": [], "execution_count": null, "source": "print (train_df[train_df['trip_duration_hours'] > 5].count()['id'])\nprint (len(train_df))", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "8330184bfddbc61ae761cb2229ab15460edceb4f", "_cell_guid": "17b465e4-d9f5-4bc7-b341-5ad40b2c20dc"}, "outputs": [], "execution_count": null, "source": "train_df.drop(train_df[train_df.trip_duration_hours > 5].index, inplace=True)\nprint (len(train_df))", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "4ecab8dfcc6c0b34b484a5595b60040e964b0475", "_cell_guid": "f9550dee-e56d-471b-a800-38e34ce1a12a"}, "outputs": [], "execution_count": null, "source": "Now let us view the statistics in the trip duration for hours again", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "25d2f2f4665d584fe9055140412eed295966d527", "_cell_guid": "edc87ded-217a-4687-8eac-813a937e19ff"}, "outputs": [], "execution_count": null, "source": "print(max(train_df['trip_duration_hours']))\nprint(min(train_df['trip_duration_hours']))\n\nprint(train_df['trip_duration_hours'].describe())", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "263bb6afed4c1fbd6806929f9908b34ec372894f", "_cell_guid": "125ce56f-cc9f-4989-b5dd-bc56ae3c13af"}, "outputs": [], "execution_count": null, "source": "We can see that the **mean** and **standard deviation** values have decreased.", "cell_type": "markdown"}, {"metadata": {"_execution_state": "idle", "_uuid": "80a6a497bafce52b23d6501382a240bdd140af19", "_cell_guid": "8776f997-67b6-4301-b3a6-6b8794a5fd5c"}, "outputs": [], "execution_count": null, "source": "**2. Traveling with '0' passengers**", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "33e13da0fc364f7180f04bd9505a35406c30ea76", "_cell_guid": "150e8753-9f4a-4e6a-90ed-7d7390975e33"}, "outputs": [], "execution_count": null, "source": "print(train_df['passenger_count'].unique())\nprint(test_df['passenger_count'].unique())\nprint(test_df[(test_df['passenger_count'] == 0)].count()['id'])", "cell_type": "code"}, {"metadata": {"_uuid": "9e920bc17a0420334a13da819dac97af0546a36f", "_cell_guid": "d791ce51-0ea7-4960-bafe-f85a326d6c51"}, "outputs": [], "execution_count": null, "source": "The test data also contains rides having no passengers. Hence it is not advisable to remove them.", "cell_type": "markdown"}, {"metadata": {"_execution_state": "idle", "_uuid": "de5e1c6b30a34191c4fc35ae9f0da230001e636b", "_cell_guid": "d51c7f24-1a33-4d44-9483-b19dc0ae99f2"}, "outputs": [], "execution_count": null, "source": "**3. Extreme latitude and longitude pickups**", "cell_type": "markdown"}, {"metadata": {"_execution_state": "idle", "_uuid": "46425cd3e4cd3b2383acbdb88b2a04b51fbac3ed", "_cell_guid": "4ddf41ba-dc62-40dc-828a-51bdf11b7b37"}, "outputs": [], "execution_count": null, "source": "Let us plot the pickup and dropoff latitudes and longitudes", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "87aa70d4f6ed59b256c48fdc5085fe4f1fccf383", "_cell_guid": "00147e14-91bb-403b-a936-d772ce83c5d9"}, "outputs": [], "execution_count": null, "source": "plt.plot(train_df['pickup_longitude'], train_df['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Pickup Location Lat and Long', weight = 'bold')\nplt.show()\n\nplt.plot(train_df['dropoff_longitude'], train_df['dropoff_latitude'], '.', color='k', alpha=0.8)\nplt.title('Dropoff Location Lat and Long', weight = 'bold')\nplt.show()", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "10e559e9ba093bf61baa4474965809e4ec8eea0e", "_cell_guid": "bf79f454-4d86-4393-b80a-abb37006caca"}, "outputs": [], "execution_count": null, "source": " - In both the plots we can see a clutter of points, where majority of\n   the pickups and drop-offs are located.\n - Every other point is a possible outlier.\n - Among the outliers the are **3 outstanding** ones, in both the plots.\n\nLet us first remove the **outstanding** outliers first, manually and visualize the plot again !!", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "459891a3b18e086278a31f371a8d2fe89814e6f6", "_cell_guid": "12bc659d-9243-4490-9ee1-469265c2c0bc"}, "outputs": [], "execution_count": null, "source": "train_df = train_df[train_df.pickup_latitude != 51.881084442138672]\n\ntrain_df = train_df[train_df.pickup_longitude != -121.93334197998048]\n\ntrain_df = train_df[train_df.dropoff_longitude != -121.93320465087892]\n\n#train_df = train_df[train_df.dropoff_latitude != 32.181140899658203]\n\nplt.plot(train_df['pickup_longitude'], train_df['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Pickup Location Lat and Long', weight = 'bold')\nplt.show()\n\nplt.plot(train_df['dropoff_longitude'], train_df['dropoff_latitude'], '.', color='k', alpha=0.8)\nplt.title('Dropoff Location Lat and Long', weight = 'bold')\nplt.show()", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "d334d1233d732db64904b421b42e1c570c343c52", "_cell_guid": "f3370dbf-0bb1-468d-9eda-8cb4d2425af8"}, "outputs": [], "execution_count": null, "source": "The clutter of points has magnified a bit. But we still do have some outliers present.\n\nNow let us standardize the points are visualize them again.", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "a75c97713335a6bc56aa5bd0d1fce5e300787d37", "_cell_guid": "7e75cc15-bae1-471f-9bed-a67caf4371e1"}, "outputs": [], "execution_count": null, "source": "#--- Mean of locations Lats and Longs ---\nmean_p_lat = np.mean(train_df['pickup_latitude'])\nmean_p_lon = np.mean(train_df['pickup_longitude'])\n\nprint (mean_p_lat)\nprint (mean_p_lon)", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "147c221b40c292e6c25958e25c3d3bb45e77febb", "_cell_guid": "eea3370c-0085-4e62-8b39-6022575de32e"}, "outputs": [], "execution_count": null, "source": "#--- Standard deviation of pickup & dropoff Lats and Longs ---\nstd_p_lat = np.std(train_df['pickup_latitude'])\nstd_p_lon = np.std(train_df['pickup_longitude'])\n\nprint (std_p_lat)\nprint (std_p_lon)", "cell_type": "code"}, {"metadata": {"trusted": true, "_execution_state": "idle", "_uuid": "1cb4705a4921a10961bba20a3b88f3f9d9770698", "_cell_guid": "70a0ce85-2652-41a1-9476-678938b1348d"}, "outputs": [], "execution_count": null, "source": "min_p_lat = mean_p_lat - std_p_lat\nmax_p_lat = mean_p_lat + std_p_lat\nmin_p_lon = mean_p_lon - std_p_lon\nmax_p_lon = mean_p_lon + std_p_lon\n\nlocations = train_df[(train_df.pickup_latitude > min_p_lat) & (train_df.pickup_latitude < max_p_lat) & (train_df.pickup_longitude > min_p_lon) & (train_df.pickup_longitude < max_p_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight = 'bold')\nplt.show()", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "2e47e7e2cdeef5963010cf4f93cffce81ff8839e", "_cell_guid": "a587cec6-2c23-4a8f-9dbb-b5bd08f9c4f2"}, "outputs": [], "execution_count": null, "source": "We have zoomed into Manhattan quite too much!!\n\nLet's zoom out a little", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_cell_guid": "0fc49dce-4b81-42ce-8051-83c3bdfd39b7", "collapsed": true, "_execution_state": "idle", "_uuid": "af7b1d0543e95bbb5fbbd0b79f6f2a6459f56cb2", "scrolled": true}, "outputs": [], "execution_count": null, "source": "min_p_lat = mean_p_lat - (3 * std_p_lat)\nmax_p_lat = mean_p_lat + (3 * std_p_lat)\nmin_p_lon = mean_p_lon - (3 * std_p_lon)\nmax_p_lon = mean_p_lon + (3 * std_p_lon)\n'''\nlocations = train_df[(train_df.pickup_latitude > min_p_lat) & (train_df.pickup_latitude < max_p_lat) & (train_df.pickup_longitude > min_p_lon) & (train_df.pickup_longitude < max_p_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight = 'bold')\nplt.show()\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "c6f30a4e494f815e1aa19341224ad14ed479c83f", "_cell_guid": "88216114-65c4-4b12-bcd5-5e977fc7270b", "collapsed": true}, "outputs": [], "execution_count": null, "source": "min_p_lat = mean_p_lat - (4 * std_p_lat)\nmax_p_lat = mean_p_lat + (4 * std_p_lat)\nmin_p_lon = mean_p_lon - (4 * std_p_lon)\nmax_p_lon = mean_p_lon + (4 * std_p_lon)\n'''\nlocations = train_df[(train_df.pickup_latitude > min_p_lat) & (train_df.pickup_latitude < max_p_lat) & (train_df.pickup_longitude > min_p_lon) & (train_df.pickup_longitude < max_p_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight = 'bold')\nplt.show()\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "883a917d53487939d65a3d6ac94766b7c7c8b71a", "_cell_guid": "9cb7dee4-979f-42aa-8a2d-04433da241ae", "collapsed": true}, "outputs": [], "execution_count": null, "source": "min_p_lat = mean_p_lat - (10 * std_p_lat)\nmax_p_lat = mean_p_lat + (10 * std_p_lat)\nmin_p_lon = mean_p_lon - (10 * std_p_lon)\nmax_p_lon = mean_p_lon + (10 * std_p_lon)\n'''\nlocations = train_df[(train_df.pickup_latitude > min_p_lat) & (train_df.pickup_latitude < max_p_lat) & (train_df.pickup_longitude > min_p_lon) & (train_df.pickup_longitude < max_p_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight = 'bold')\nplt.show()\n'''", "cell_type": "code"}, {"metadata": {"_execution_state": "idle", "_uuid": "798f0befa2de8b5777ac5d5799fc83dff5c06318", "_cell_guid": "03d34125-8841-499c-97d2-ab4bfd387f68"}, "outputs": [], "execution_count": null, "source": "I've decided to stick with **5 standard deviations** away from the mean. I will apply the same for the drop-off latitudes and longitudes.", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "0cb382530cd021275c4385a14d5ab29fde7f8eac", "_cell_guid": "38ee6118-788e-47b1-82d8-f6b6115d3fb6"}, "outputs": [], "execution_count": null, "source": "min_p_lat = mean_p_lat - (5 * std_p_lat)\nmax_p_lat = mean_p_lat + (5 * std_p_lat)\nmin_p_lon = mean_p_lon - (5 * std_p_lon)\nmax_p_lon = mean_p_lon + (5 * std_p_lon)\n\nlocations = train_df[(train_df.pickup_latitude > min_p_lat) & (train_df.pickup_latitude < max_p_lat) & (train_df.pickup_longitude > min_p_lon) & (train_df.pickup_longitude < max_p_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight = 'bold')\nplt.show()", "cell_type": "code"}, {"metadata": {"_uuid": "311b21deccc09b929b7e81d3e600c9d25205dc91", "_cell_guid": "fae5dbeb-9355-4d05-9cfa-99fa184b50f2"}, "outputs": [], "execution_count": null, "source": "* Comparing size of the two dataframes\n* Creating duplicate dataframe to work with", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "1e61787deb33819a6cea95d244f33c4a8cecdb2d", "_cell_guid": "02f90e7f-396e-4d69-b078-caeff697d7fa", "scrolled": true}, "outputs": [], "execution_count": null, "source": "print(len(train_df))\nprint(len(locations))\n\n#--- making a duplicate copy of the df to work on ---\nlocations_1 = locations\nprint(locations_1.head())\n", "cell_type": "code"}, {"metadata": {"_uuid": "346099f98ee9a0c37b40b0fcb4dd6825ff682fe6", "_cell_guid": "4dc1ddbd-5a12-4f58-b797-6cb14b733b06"}, "outputs": [], "execution_count": null, "source": "Modeling!!", "cell_type": "markdown"}, {"metadata": {"_cell_guid": "d4f4acc1-9212-45db-9dd1-cf464ccd69ff", "trusted": true, "_uuid": "fb60b6f8c16943e94a4e96c9e7cc3eb830d48f94", "scrolled": true, "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Assigning the target variable ---\nlabels = train_df['trip_duration']", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "d82a5108edd2474af81a540e55e6116fe3738bcd", "_cell_guid": "857a451b-5f99-4857-a3e7-3ca7925e9e37", "collapsed": true}, "outputs": [], "execution_count": null, "source": "# --- I forgot to convert the categorical variables to numerical variables ---\ndf_s_f_train = pd.get_dummies(train_df['store_and_fwd_flag'])\ndf_s_f_test = pd.get_dummies(test_df['store_and_fwd_flag'])\n\n# --- Join the dummy variables to the main dataframe ---\ntrain_df = pd.concat([train_df, df_s_f_train], axis=1)\ntest_df = pd.concat([test_df, df_s_f_test], axis=1)\n\n# --- Drop the categorical column ---\ntrain_df.drop('store_and_fwd_flag', axis=1, inplace=True)\ntest_df.drop('store_and_fwd_flag', axis=1, inplace=True)\n\n#print (train_df.head())\n#print (test_df.head())", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "467eb6cdb6884b0eeb664a1aeb9daabc808ffb86", "_cell_guid": "2ef872bf-23e0-4624-817a-a91fc62fbe00", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df = train_df.loc[:,~train_df.columns.duplicated()]\ntest_df = test_df.loc[:,~test_df.columns.duplicated()]\n\n#print (train_df.head())\n#print (test_df.head())", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "2da30f36ce4e911ae877c7d9d71771688aa8df96", "_cell_guid": "f247c367-36fd-457f-9327-ee99e5f17381", "collapsed": true}, "outputs": [], "execution_count": null, "source": "train_df.drop('id', axis=1, inplace=True)\n#test_df.drop('id', axis=1, inplace=True)\n\n#print (train_df.head())\n#print (test_df.head())", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "f70b3051a779594ccd8d68336e2ed63e7a207b3a", "_cell_guid": "018ec5e2-902f-472b-912b-0e73a79d478a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#train_df['pickup_longitude'] = train_df['pickup_longitude'].round(3)\n#train_df['pickup_latitude'] = train_df['pickup_latitude'].round(3)\n#train_df['dropoff_longitude'] = train_df['dropoff_longitude'].round(3)\n#train_df['dropoff_latitude'] = train_df['dropoff_latitude'].round(3)\n#train_df['Haversine_dist'] = train_df['Haversine_dist'].round(3)\n#train_df['bearing_dist'] = train_df['bearing_dist'].round(3)\n#train_df['Manhattan_dist'] = train_df['Manhattan_dist'].round(3)\n#train_df['trip_duration_mins'] = train_df['trip_duration_mins'].round(3)\n#train_df['trip_duration_hours'] = train_df['trip_duration_hours'].round(3)\n", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "63deac89a111deea356dd188bb0e2b2025f5e1ca", "_cell_guid": "ec091776-c8c6-43be-ab00-49f258c544eb"}, "outputs": [], "execution_count": null, "source": "print (train_df.isnull().values.any())\nprint (test_df.isnull().values.any())", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "d68eabada907d90e12b2aaf26efcba27d32bb33a", "_cell_guid": "e4e03880-157d-43e9-9db8-280adf2821ed"}, "outputs": [], "execution_count": null, "source": "print(train_df.head())\nprint(test_df.head())", "cell_type": "code"}, {"metadata": {"_uuid": "55bf4afa9e63635bef28daf7a403c01a7d3ee252", "_cell_guid": "c8ff5983-6ed9-4050-bfd2-5cbdf1ded5cb"}, "outputs": [], "execution_count": null, "source": "", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "7c43e92c80c4ebf299a78b32b269251b5414c43a", "_cell_guid": "fc28448e-175c-464b-9b6f-1fda666e9a37"}, "outputs": [], "execution_count": null, "source": "b_train = train_df.drop(['pickup_datetime','dropoff_datetime','dropoff_hour', 'dropoff_month', 'dropoff_day', 'trip_duration', 'trip_duration_mins', 'trip_duration_hours'], 1)\nb_label = train_df['trip_duration']\nprint(b_train.head())\nprint(b_label.head())\n\ntest = test_df\ntest = test.drop(['pickup_datetime','id'], 1)\nprint(test.head())", "cell_type": "code"}, {"metadata": {"_uuid": "7e24b0ffaaf7842110e4c926480125df66a8cc97"}, "outputs": [], "execution_count": null, "source": "**Cross Validation** \n\nAdapted from [HERE](https://www.kaggle.com/jeru666/stacked-regressions-top-4-on-leaderboard)", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "898ec196e06d2bd9fe8b9c1c4a59f7afdf3fbe8a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#Validation function\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(b_train)\n    rmse= np.sqrt(-cross_val_score(model, b_train, b_label, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)", "cell_type": "code"}, {"metadata": {"_uuid": "b299d17e3b54ea9400247a226cc984671eb09c42"}, "outputs": [], "execution_count": null, "source": "**Modeling**\n\n* LASSO\n\n", "cell_type": "markdown"}, {"metadata": {"trusted": true, "_uuid": "737a88f89a29b9bddc9dbf06551040d7462bfa7e"}, "outputs": [], "execution_count": null, "source": "from sklearn.linear_model import Lasso\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\n\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n#lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\nlasso = Lasso(alpha =0.01, random_state=1)", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "d1ed041d90617a5ecd5326dd03d03f9fe234301b", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#lasso.predict()  ", "cell_type": "code"}, {"metadata": {"trusted": true, "_uuid": "4bea6a414e9be357f040521cad19a7a5328888f9"}, "outputs": [], "execution_count": null, "source": "#score = rmsle_cv(lasso)\n#print(\"\\nLasso score: {:.4f} (+/-{:.4f})\\n\".format(score.mean(), score.std()))\n#print('DONE!!')", "cell_type": "code"}, {"metadata": {"_uuid": "84c532212447c68179ab8ba59d7c5ee837a9ee8d"}, "outputs": [], "execution_count": null, "source": "", "cell_type": "markdown"}, {"metadata": {"_uuid": "5efbb14e376ebb17370bd7c900c44194dd0dd0dd", "_cell_guid": "e6781c56-ca51-46ae-9131-0a9fe028cac8"}, "outputs": [], "execution_count": null, "source": "**Gradient Boosting Regressor** ", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_uuid": "13c089933bce832227185da1d64dc239576424bb", "_cell_guid": "be93034b-9150-4940-95bc-b9f64ce3f6a4", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Setting up and training Gradient Boosting Regressor ---\n\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nGBR = GradientBoostingRegressor(n_estimators=50, learning_rate=0.01, max_depth=5, random_state=0, loss='ls')\nGBR.fit(b_train, b_label)\n\nprint (GBR)\n", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "e02f092c938a74ff9a16cb169a9411973c5629d6", "_cell_guid": "52320e05-7983-4dec-9a13-377dfc6f08f7", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- List of important features for Gradient Boosting Regressor ---\n\nfeatures_list = b_train.columns.values\nfeature_importance = GBR.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nprint(sorted_idx)\n", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "e1284566b2899f5d39837190ab29b1da71ac0fbf", "_cell_guid": "f013d0e1-6cfd-46b6-914b-80cf177e6c7c", "collapsed": true}, "outputs": [], "execution_count": null, "source": "\nplt.figure(figsize=(15, 15))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()\n", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "1f24294dc581f28ac3be4f43d81694a4927db268", "_cell_guid": "29526b3d-3fe6-4a48-bf68-243a6d29b521", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Predicting Gradient boost result for test data ---\ny_GBR = GBR.predict(test)", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "64b670b8f65f39d57f383dc1497894cbb07d36f2", "_cell_guid": "5c502cd1-9869-4df5-bbfe-b6431fd4f12a", "collapsed": true}, "outputs": [], "execution_count": null, "source": "\nfinal = pd.DataFrame()\nfinal['id'] = test_df['id']\nfinal['trip_duration'] = y_GBR\nfinal.to_csv('Gradient_Boost_1.csv', index=False)\nprint('DONE!!')\n", "cell_type": "code"}, {"metadata": {"_uuid": "c7f7a9b3efa83e3253bc2a8b2360a63888f94a97", "_cell_guid": "747964cc-1b4e-467c-9bbb-854d49b5a6db"}, "outputs": [], "execution_count": null, "source": "**Adaptive Boosting** (Ada Boost gave me a **VERY** bad score on the LB, you can try and see it for yourself!!)", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_uuid": "b357d0a2e1873c9366c67db82cdffb9f0f134886", "_cell_guid": "e603173e-5e31-49c6-b82a-393b0e6637a7", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Setting up and training Ada boost ---\n'''\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\n\nAda_R = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators = 300, random_state = np.random.RandomState(1))\n\nAda_R.fit(b_train, b_label)\n\nprint (Ada_R)\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "17fe2dbc1fffafba02822d2cc4cca9fdcd2f9310", "_cell_guid": "0fa410f1-6372-4efe-8c39-83cd69a123fd", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- List of important features for Ada Boost ---\n'''\nfeatures_list = b_train.columns.values\nfeature_importance = Ada_R.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nprint(sorted_idx)\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "ec404e8ffd8ab65050f1b44b76de689b60519f7d", "_cell_guid": "e149179c-c931-4dff-ab57-c1696ed5bb57", "collapsed": true}, "outputs": [], "execution_count": null, "source": "'''\nplt.figure(figsize=(15, 15))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "33d8a5848d2cc38ced4b2c5913ace1c05dad890d", "_cell_guid": "3cb8d98b-ef4a-4f12-a6a8-4b95e3c45063", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Predicting Ada boost result for test data ---\n#y_Ada = Ada_R.predict(test)", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "f9165f6847fa186503594caa56ced5456cea33ab", "_cell_guid": "553c92c3-e68d-4500-b2b9-8e90c096c44e", "collapsed": true}, "outputs": [], "execution_count": null, "source": "'''\nfinal = pd.DataFrame()\nfinal['id'] = test_df['id']\nfinal['trip_duration'] = y_Ada\nfinal.to_csv('Ada_Boost_1.csv', index=False)\nprint('DONE!!')\n'''", "cell_type": "code"}, {"metadata": {"_uuid": "c2ac8cacb175ac9a991df4401b365dfa808da9f8", "_cell_guid": "7269d644-cf27-4f55-ac5c-8cb08de67a91"}, "outputs": [], "execution_count": null, "source": "**Random Forest Regressor** (Random Forest performed a lot better !!!)", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_uuid": "7a2ad1f6f247d90d2833ce62c41016977b642abf", "_cell_guid": "d26575ee-cd01-429f-a289-c40220c59311", "collapsed": true}, "outputs": [], "execution_count": null, "source": "from sklearn.ensemble import RandomForestRegressor  \n'''\nRF = RandomForestRegressor()\nRF.fit(b_train, b_label)\n\nprint(RF)\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "eced60c7cffb2bd42bfecca854501a288bc8ce62", "_cell_guid": "da677f66-8839-404e-8686-b84c6c8bba11", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- List of important features ---\n'''\nfeatures_list = b_train.columns.values\nfeature_importance = RF.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nprint(sorted_idx)\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "620df49fc73240b1b3ce373c5af5b221b23feb83", "_cell_guid": "ec694332-7f08-49bd-82eb-f2842ddb0b81", "collapsed": true}, "outputs": [], "execution_count": null, "source": "'''\nplt.figure(figsize=(15, 15))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "f4f13829f384a38f529a7f3a96d98709f380b43a", "_cell_guid": "e9b4b47d-4ff0-4079-b644-6a7c62ac897d", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#--- Predicting for the test data ---\n##test_df = test_df.drop('pickup_datetime', 1)\n## = test_df.drop('id', 1)\n'''\nprint(test.head())\n\nY_pred = RF.predict(test)\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "fb8df3c0aa72117f004c72e1444cf1b324de3f91", "_cell_guid": "b8c486ac-3883-49f1-a484-f3e8302bd323", "collapsed": true}, "outputs": [], "execution_count": null, "source": "'''\nfinal = pd.DataFrame()\nfinal['id'] = test_df['id']\nfinal['trip_duration'] = Y_pred\nfinal.to_csv('RF_1.csv', index=False)\nprint('DONE!!')\n'''", "cell_type": "code"}, {"metadata": {"trusted": false, "_uuid": "eb0c2f21c4b6860eec4dfd9f15d66475f0c585fb", "_cell_guid": "e9039b21-d711-464e-8a74-e8f33c5a8a2b", "collapsed": true}, "outputs": [], "execution_count": null, "source": "#print(final.head())", "cell_type": "code"}, {"metadata": {"_uuid": "1796f7d0664ece3b617fe0b5a8a36cc3c63245a9", "_cell_guid": "6d4bdc42-b5e5-4af7-9f57-7e4771789ea0"}, "outputs": [], "execution_count": null, "source": "Random Forest with Cross Validation", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_uuid": "3fded4ed81ae6aa67477159320bfaad1325e5d38", "_cell_guid": "76ca4199-9f4c-461c-b9df-e69c70eccf85", "collapsed": true}, "outputs": [], "execution_count": null, "source": "'''\nfrom sklearn.ensemble import RandomForestRegressor  \nfrom sklearn.cross_validation import KFold\nfrom sklearn.metrics import r2_score   \n\nsample_size = locations_1.shape[0]\n\nmax_estimators_options=[7]   \n\nprint(\"lets start cross validation\")\n\ntest_results=[]\n\ncv = KFold(sample_size, n_folds=5,shuffle=True, random_state=123)\nresult_r2=np.empty([cv.n_folds,len(max_estimators_options)],dtype=float)\nCV_stacked=[]\n\n#--- target columns to remove \ncols = [ 'dropoff_month', 'dropoff_day', 'dropoff_hour', 'trip_duration', 'trip_duration_mins', 'trip_duration_hours']\nx_train = train_df.drop(cols, 1)\n\n#--- assign target column to separate variable---\nlabels = train_df[\"trip_duration\"].copy()\n\ncount=0\nfor alp in max_estimators_options:\n    params = {'n_estimators':400, 'max_depth': 7, 'min_samples_split':50,\"max_features\":75,\n          'random_state':0,\"verbose\":1, 'n_jobs' : -1 }\n    model=RandomForestRegressor(**params)\n    result=[]\n    actual=[]\n    pred_CV=[]\n\n    for traincv, testcv in cv: \n        X_train = x_train.iloc[traincv]            #--- all independent variables\n        labels_train = labels.iloc[traincv]        #--- dependent variable -> trip_duration\n        \n        X_CV = x_train.iloc[testcv]\n        labels_test= labels.iloc[testcv]\n\n        test_data = test_df.copy()\n        \n        final_pred = model.fit(X_train, labels_train).predict(X_CV)\n        val_score = r2_score(labels_test,final_pred)\n        \n        actual+=labels_test.tolist()\n        pred_CV+=final_pred.tolist()\n        \n        test_pred = model.predict(test_data)\n        test_results.append(test_pred)\n        #val_score =r2_score(data_set.ix[testcv,\"y\"],final_pred)\n        #print(val_score)\n        result.append(val_score)\n    result_r2[:,count]=result\n    stacked_CV = r2_score(actual, pred_CV)\n    CV_stacked.append(stacked_CV)\n    print(count)\n    print(result)\n    count=count+1\n\nmean = result_r2.mean(axis=0)\nstd = result_r2.std(axis=0)\n###fine best estimator size\nprint(mean)\nprint(std)\nprint(CV_stacked)\n'''", "cell_type": "code"}, {"metadata": {"_uuid": "90b7f48d44812c934b245e7efa9b1c4d1f083321", "_cell_guid": "8bc9be0f-5d94-4a96-88bc-0328ae93c962"}, "outputs": [], "execution_count": null, "source": "Normally distributing the output variable using log transformation", "cell_type": "markdown"}, {"metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "228f97a93a92f7bb44f22a22023c9b9ca162232b", "_cell_guid": "6fe6b0e1-f176-4324-8728-3858199ff7c7", "collapsed": true}, "outputs": [], "execution_count": null, "source": "plt.hist(np.log(train_df['trip_duration']+25), bins = 25)\n\n", "cell_type": "code"}, {"metadata": {"_uuid": "c03d7ba17ad0090a561fd78f5a0912f95b95d329", "_cell_guid": "77ca0112-cc57-471e-ba0c-86ad64c2925a"}, "outputs": [], "execution_count": null, "source": "**WORK STILL IN PROGRESS\n\n**MANY MORE MODELS WILL BE BUILT AND TUNED**\n\nSTAY TUNED!!!**", "cell_type": "markdown"}], "nbformat": 4, "nbformat_minor": 1}