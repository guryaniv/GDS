{"cells":[{"metadata":{"_uuid":"cf926608d0921132f7369f04482709f0875dcc9d"},"cell_type":"markdown","source":"I use these:\n- [Based on Starter Kernel](https://www.kaggle.com/michaelapers/lstm-starter-notebook)\n- [LSTM with Attention](https://www.kaggle.com/suicaokhoailang/lstm-with-attention-baseline-0-989-lb)\n- [AUC Metric](https://github.com/keras-team/keras/issues/3230#issuecomment-292535661) and [Callback](https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Let's load in some basics and make sure our files are all here\nimport numpy as np\nimport pandas as pd\nimport os\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6af6c7c118b929064fe375ad37495007c5ee622f"},"cell_type":"markdown","source":"## Load and EDA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\nsample_submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1af04552eed6d0505deb35d1bdf10a72b4d092f2"},"cell_type":"code","source":"print(train.columns)\nsample_submission.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a1c076d7f3174afadb3d1de3c3d10c2ae8e590"},"cell_type":"code","source":"cols = [\"vid_id\", \"start_time_seconds_youtube_clip\", \"end_time_seconds_youtube_clip\",\n        \"audio_embedding\", \"is_turkey\"]\nprint(train.shape)\nprint(test.shape)\ntrain[train['is_turkey']==1][cols].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dead92efa224b26251940bb0fb0540daa03c5375"},"cell_type":"code","source":"\"is_turkey rate is \" + str(train[train['is_turkey']==1].shape[0] / train.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4acf2c1fdb041b24307abe418a50c47a3ce5b619"},"cell_type":"code","source":"print(train['audio_embedding'].head())\n\n#see the possible list lengths of the first dimension\nprint(\"train's audio_embedding can have this many frames: \"+ str(train['audio_embedding'].apply(lambda x: len(x)).unique())) \nprint(\"test's audio_embedding can have this many frames: \"+ str(test['audio_embedding'].apply(lambda x: len(x)).unique())) \n\n#see the possible list lengths of the first element\nprint(\"each frame can have this many features: \"+str(train['audio_embedding'].apply(lambda x: len(x[0])).unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aa681afa8cc2cb10eaa65331a889ea3f89ce868"},"cell_type":"code","source":"sns.countplot(train['audio_embedding'].apply(lambda x: len(x)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5463c4c951cd48b60df350e36a9a12cd6f747df"},"cell_type":"code","source":"# train[\"time_seconds\"] = train[\"end_time_seconds_youtube_clip\"] - train[\"start_time_seconds_youtube_clip\"]\n# test[\"time_seconds\"] = test[\"end_time_seconds_youtube_clip\"] - test[\"start_time_seconds_youtube_clip\"]\n# sns.countplot(train[\"time_seconds\"])\n# plt.ylim(0,100)\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcf94d153e8ba5dde5ab0d31a21b569c2c83cd22"},"cell_type":"markdown","source":"## Modeling"},{"metadata":{"trusted":true,"_uuid":"19fbc34b8927f8c6a3c1dea4fabb02df5fb0caf9"},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout, Input\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1627381eccc35dd6164ae07512bcea30a76de91d"},"cell_type":"markdown","source":"### Prepare"},{"metadata":{"trusted":true,"_uuid":"fb9abfd615a378579fc8fcf0884b30b23afd70d9","scrolled":false},"cell_type":"code","source":"#split the training data to have a validation set\ntrain_train, train_val = train_test_split(train, test_size=0.2, random_state=42, stratify=train[\"is_turkey\"])\nxtrain = [k for k in train_train['audio_embedding']]\nytrain = train_train['is_turkey'].values\n\nxval = [k for k in train_val['audio_embedding']]\nyval = train_val['is_turkey'].values\n\n# Pad the audio features so that all are \"10 seconds\" long\nx_train = pad_sequences(xtrain, maxlen=10)\nx_val = pad_sequences(xval, maxlen=10)\n\ny_train = np.asarray(ytrain)\ny_val = np.asarray(yval)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6712dcd9f05cb03d5196e6f1b68b0a5db2567571"},"cell_type":"markdown","source":"### AUC Metric and Callback"},{"metadata":{"trusted":true,"_uuid":"1bf879b61031d1ea3bcf4452719b27e1322e6011"},"cell_type":"code","source":"## https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nimport tensorflow as tf\nfrom keras import backend as K\nclass roc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = roc_auc_score(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return\n    \n    \n## https://github.com/keras-team/keras/issues/3230#issuecomment-292535661\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# AUC for a binary classifier\ndef auc(y_true, y_pred):   \n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# PFA, prob false alert for binary classifier\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # N = total number of negative labels\n    N = K.sum(1 - y_true)\n    # FP = total number of false alerts, alerts from the negative class labels\n    FP = K.sum(y_pred - y_pred * y_true)    \n    return FP/N\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# P_TA prob true alerts for binary classifier\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # P = total number of positive labels\n    P = K.sum(y_true)\n    # TP = total number of correct alerts, alerts from the positive class labels\n    TP = K.sum(y_pred * y_true)    \n    return TP/P","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea75247d9619cd6da6ff324f28448c2870f67aa2"},"cell_type":"markdown","source":"### Attention"},{"metadata":{"trusted":true,"_uuid":"87b6902555e59956f5e40c30abfd9592cdd314e8"},"cell_type":"code","source":"## https://www.kaggle.com/suicaokhoailang/lstm-with-attention-baseline-0-989-lb/notebook\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\n\n# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cdb246fc25cdb8100cf621bceb4decf08c03a94"},"cell_type":"markdown","source":"### Build and Train Model"},{"metadata":{"trusted":true,"_uuid":"561a14aaa5a6ffd994662c785a6c9ae692d21630"},"cell_type":"code","source":"#Define a basic LSTM model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(256, dropout=0.3, recurrent_dropout=0.3, return_sequences=True, input_shape=(10, 128))))\nmodel.add(Bidirectional(LSTM(128, return_sequences=True)))\nmodel.add(Attention(10))\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n#maybe there is something better to use, but let's use binary_crossentropy\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=[\"accuracy\", auc])\n\n# Callback\nes = EarlyStopping(monitor='val_auc', min_delta=0, patience=5, verbose=0, mode='max')\nroc_cb = roc_callback(training_data=(x_train, y_train),validation_data=(x_val, y_val))\n\n#fit on a portion of the training data, and validate on the rest\nhistory = model.fit(x_train, y_train,\n                    validation_data=(x_val, y_val),\n                    batch_size=256,\n                    epochs=20,\n                    verbose=2,\n                    callbacks=[es, roc_cb])\n\n# Evaluate\nscore, acc, auc = model.evaluate(x_val, y_val, batch_size=256, verbose=0)\nprint('Validation AUC:', auc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1979d4f2a2069914c5a6fc92ae2e1d97ca6d0fba"},"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.lineplot(range(1, len(history.history['auc'])+1), history.history['auc'], label='Train AUC')\nsns.lineplot(range(1, len(history.history['auc'])+1), history.history['val_auc'], label='Test AUC')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ccea8c9e87c8e3a2575c9ebaecc8d9fb79d556a"},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true,"_uuid":"be275510fb4eb8a8ad1a4270d3f6786f310172d4"},"cell_type":"code","source":"df_val = pd.DataFrame({'vid_id':train_val['vid_id'].values,\n                       'is_turkey':[x for y in model.predict(x_val) for x in y],\n                       'start_time': train_val['start_time_seconds_youtube_clip'].values})\ndf_val.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18925f61242eb3deeefc421e91099ab166b52e23"},"cell_type":"code","source":"plt.figure(figsize=(6,4))\nsns.distplot(df_val[\"is_turkey\"], bins=20, kde=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5db6e478b7acf0290a7b1b6b3ac9a8d81585484e"},"cell_type":"code","source":"df_val[(df_val[\"is_turkey\"]>0.05) & (df_val[\"is_turkey\"]<0.95)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aac018a6eddfddcf04434c49d43bca759cd141a5"},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true,"_uuid":"d49025f0a75fc36da1f858237233280803e6056a"},"cell_type":"code","source":"test_data = [k for k in test['audio_embedding']]\nsubmission = model.predict(pad_sequences(test_data))\nsubmission = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':[x for y in submission for x in y]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"374b17df3212371cd7d43d5b0d130e2506da1173"},"cell_type":"code","source":"print(submission.head()) #check to see that it looks like the sample submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4f1308516d4107903af92b3c6d2dea7a027e7ad"},"cell_type":"code","source":"submission.to_csv('lstm_starter.csv', index=False) #drop the index so it matches the submission format.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f32fa5c59b2372e4a57ea7c397037470eb0e1b08"},"cell_type":"markdown","source":"---"},{"metadata":{"_uuid":"df78f42a2fd4be6af4a5a12052ecded2e264c43f"},"cell_type":"markdown","source":"## Don't call *her* turkey! (Just for fun)"},{"metadata":{"trusted":true,"_uuid":"120729a814cb5b17a77710d32cf2dfa0959acbdc"},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo(\"HvSsSQddil4\",start=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc2c2d1a0ac3a2338bd0e046c43e50663663b260"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}