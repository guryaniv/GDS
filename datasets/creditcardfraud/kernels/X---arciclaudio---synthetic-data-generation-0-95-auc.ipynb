{"cells":[{"metadata":{"_uuid":"3d6aade7b56766f2a8d4329972803de233362541","_cell_guid":"8ad4b702-b62a-4c61-80cf-ef11fef162de"},"cell_type":"markdown","source":"Hi guys, this is my first notebook on Kaggle. I hope you will find it interesting and I hope you will forgive my beginner mistakes. \n\nIn this notebook we are going to see the effect of synthetic data generation techniques to tackle the imbalanced problem.\n\nThe syntethic generation techniques we are going to use are: \n- SMOTE\n- SMOTE NN \n- SMOTE TOMEK\n- ADASYN \n\nthe opensource implementation of these techniques can be found in the imblearn library:\nhttp://contrib.scikit-learn.org/imbalanced-learn/stable/index.html\n\nThe techniques that we are going to use are: \n- Logistic Regression\n- Random Forest \n- Gradient Boosting \n\nIn the end we are going to tackle the problem of imbalanced dataset by adopting a reweihthing solution. \n\nSpoiler alert, the best obtained results are: \n- Gradient Boosting + Adasyn whith an AUC = 0.948922348202\n- Logistic Regression + Adasyn with an AUC = 0.946214132108\n\nLogistic Regression seems the model that perform better in each test. Probably becouse of the scarse amount of data. \n\nAdasyn seems the best synthetic data generation technique for this problem. \n\n"},{"metadata":{"_uuid":"7a642bea86f5f5f549a2692dfcc9d589b2d15ba5","_cell_guid":"c28abf14-d9e7-4c8b-a1d8-cafa4e0a0f47","trusted":true},"cell_type":"code","source":"# Imports\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.ensemble import RandomForestClassifier\nfrom imblearn.over_sampling import ADASYN \nfrom imblearn.combine import SMOTEENN \nfrom imblearn.combine import SMOTETomek \nfrom sklearn import ensemble\n\n\n# Load the dataset\ncredit_cards = pd.read_csv(\"../input/creditcard.csv\")\n\n# Devide labels and features\nlabels = credit_cards['Class']\nfeatures = credit_cards.drop('Class', axis=1)\n\n# Train-test split\nfeatures_train, features_test, labels_train, labels_test = train_test_split(features,\n                                                                            labels,\n                                                                            test_size=0.2,\n                                                                            random_state=1234)\n\nfraudolent_transactions_amount = len(labels_train [labels_train ==1])\ngenuine_transactions_amount = len(labels_train [labels_train ==0])\nratio = genuine_transactions_amount / fraudolent_transactions_amount\n\n#Check how much unbalanced is the train set\nprint('Number of fraudolent transaction = {}'.format(fraudolent_transactions_amount))\nprint('Number of genuine transaction = {}'.format(genuine_transactions_amount))\nprint('The ratio between genuine and fraudolent transactions is approximately {}:1'.format(round(ratio)))\n","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"35b23413a92a85959dfa8bed533136bf026a0619","_cell_guid":"571468f8-cb49-4bae-a7e4-e777f2fa5a77"},"cell_type":"markdown","source":"577 : 1 is quite a lot of imbalance. This means that we cannot use classical methods for evaluations. We have to use AUC as evaluation criteria. A classifier which predicts all transactions as genuine will have an accuracy of 99.9% but will be quite useless right? "},{"metadata":{"_uuid":"1f71509276182e26a8f1ea3dd663f3582961e4f4","_cell_guid":"afc5721d-0e90-4cd3-823b-4013e54317a7"},"cell_type":"markdown","source":"# Augmented Dataset Generation: "},{"metadata":{"_uuid":"8c1cf420666bb4fb9a9248e25bf412c92d9fe22a","_cell_guid":"0d34ca15-f037-4356-a270-e217349c3ee2","trusted":true},"cell_type":"code","source":"# Let's first instanciate the synthetic data generators\n\nsm = SMOTE(random_state=42)\nada = ADASYN(random_state=42)\nsmnn = SMOTEENN(random_state=42)\nsmt = SMOTETomek(random_state=42)\n\n# Generate the new datasets\nfeatures_train_sm, labels_train_sm = sm.fit_sample(features_train, labels_train)\nfeatures_train_ada, labels_train_ada = ada.fit_sample(features_train, labels_train)\nfeatures_train_smnn, labels_train_smnn = smnn.fit_sample(features_train, labels_train)\nfeatures_train_smt, labels_train_smt = smt.fit_sample(features_train, labels_train)\n\n#let's see if the classes are balanced now\nprint(len(labels_train_sm [labels_train_sm ==1]))\nprint(len(labels_train_sm [labels_train_sm ==0]))","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"4552dc837d77ba7915c0ede50553d6140f90365c","_cell_guid":"b7f6957d-d1ef-4d30-b8e3-365931cd7523"},"cell_type":"markdown","source":"Now that the dataset is again balanced we can start training our models: "},{"metadata":{"_uuid":"0b51a4667cda8be2a302435cff412c4f821aaec9","_cell_guid":"5756f6c1-c8c0-4b0c-b50b-93ec0c370d43"},"cell_type":"markdown","source":"## Logistic regression"},{"metadata":{"_uuid":"a89e1c7cd60da87f43d184c830c5ade229a3ade2","_cell_guid":"323d2b77-b639-48f8-8f7b-582a010fef13","trusted":true,"collapsed":true},"cell_type":"code","source":"#LOGISTIC REGRESSION  WITHOUT DATA AUGMENTATION\n\n#train Logistic Regression\nlr = LogisticRegression()\nlr.fit(features_train,labels_train)\n\n# predictions on test set\npredictions=lr.predict(features_test)\n\n#compute and print confusion matrix\ncm = confusion_matrix(labels_test,predictions)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\n\n#measure and print auc \nauc_res = auc(false_positive_rate, true_positive_rate)\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c676d533804443c594651479e537fb20cbb2c95","_cell_guid":"11f4a151-e47e-49ee-96e9-cbc63618c377","trusted":true,"collapsed":true},"cell_type":"code","source":"# Logistic Regression + SMOTE\nlr = LogisticRegression()\nlr.fit(features_train_sm,labels_train_sm)\n\n# predictions on test set\npredictions=lr.predict(features_test)\n\n#compute and print confusion matrix\ncm = confusion_matrix(labels_test,predictions)\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\n\n#measure and print auc \nauc_res = auc(false_positive_rate, true_positive_rate)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))\n\n# true negatives is C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"065a2347ffd2ab124c2b5374045d90ed710f9bee","_cell_guid":"c12860d5-39a1-474d-ace4-80e64b4ff0b9"},"cell_type":"markdown","source":"False positives (903) are genuine transactions classified as fraud."},{"metadata":{"_uuid":"1aae0f26a5cb5642e1b12e2af69e15335bdd6a0f","_cell_guid":"f90f2a96-ec27-4f57-895f-b11d89da441f","trusted":true,"collapsed":true},"cell_type":"code","source":"#LOGISTIC REGRESSION + SMOTE NN \n\n#train Logistic Regression\nlr = LogisticRegression()\nlr.fit(features_train_smnn,labels_train_smnn)\n\n# predictions on test set\npredictions=lr.predict(features_test)\n\n#compute and print confusion matrix\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\n\n#measure and print auc \nauc_res = auc(false_positive_rate, true_positive_rate)\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))\n# true negatives is C_{0,0}, false negatives is C_{1,0}, true positives is C_{1,1} and false positives is C_{0,1}.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f840f5d87c08383eb28008438a7d8db59cb9d9f4","_cell_guid":"3e281e31-3f6f-453d-afdf-2a3399843f23","trusted":true,"collapsed":true},"cell_type":"code","source":"#LOGISTIC REGRESSION + ADASYN\n\n#train Logistic Regression\nlr = LogisticRegression()\nlr.fit(features_train_ada,labels_train_ada)\n\n# predictions on test set\npredictions=lr.predict(features_test)\n\n#compute and print confusion matrix\ncm = confusion_matrix(labels_test,predictions)\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\n\n#measure and print auc \nauc_res = auc(false_positive_rate, true_positive_rate)\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd352244b8114519dbe0a8727a11b71a374cef87","_cell_guid":"7457f784-96fc-4675-8cd2-535fb4db6c88","trusted":true,"collapsed":true},"cell_type":"code","source":"# LOGISTIC REGRESSION + REWEIGHTING (and no data augmentation) \n\nlr = LogisticRegression()\n\nparam_grid = {\n    'class_weight': [None, {1:5, 0:1}, {1:10, 0:1}, {1:100, 0:1}, {1:700, 0:1},\n                     {1:1000, 0:1}, {1:10000, 0:1}, {1:100000, 0:1}]\n}\n\nCV_lr = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='roc_auc')\n\n\n#train logistic regression \n\n\nCV_lr.fit(features_train,labels_train)\n\nprint('Best parameters found by grid search are:', CV_lr.best_params_)\n\nbest_lr = CV_lr.best_estimator_\npredictions=best_lr.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3804d4364458c6df5c1178efb9ed070e9afa794","_cell_guid":"3977dbb2-e4a6-464b-845e-40032dc3abd0"},"cell_type":"markdown","source":"As you can see Logistic regression performed pretty good.\nUsing data augmentation techniques and reweighting boost the performances of logistic regression, from 0.81 to 0.95. "},{"metadata":{"_uuid":"df96326823e8933256dfdf374d49fb2394670d56","_cell_guid":"ea1a1092-de29-4a22-903e-264d9bfa3bb1"},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"_uuid":"e3f585dcda112251c2a877088d645061bada9b56","collapsed":true,"_cell_guid":"911e1206-204e-4e0d-aa2e-060f7f7a240a","trusted":true},"cell_type":"code","source":"#use random forest + SMOTE\n\n\n#train random forest\n\n\nrfc=RandomForestClassifier(n_jobs=2)\n\nparam_grid = {\n    'n_estimators': [10, 100, 1000],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='roc_auc')\n\n\n#train random forest\n\n\nCV_rfc.fit(features_train_sm,labels_train_sm)\n\nprint('Best parameters found by grid search are:', CV_rfc.best_params_)\n\nbest_rfc = CV_rfc.best_estimator_\n\npredictions=best_rfc.predict(features_test)\n\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c90e4899639c3e9e17f1d4eaaeae94b8cccae68","_cell_guid":"b20d0c9f-4932-4d18-bb13-f842d03fb6b1"},"cell_type":"markdown","source":"We notice that we have way less genuine transactions classified as fraud (903 vs 16) but on the other side more fraud transaction classified as genuine (11 vs 22)"},{"metadata":{"_uuid":"009cf0368093d333f93a7207804a784a04935231","collapsed":true,"_cell_guid":"44f0d50b-2639-4ab0-82e7-26635bdb7c29","trusted":true},"cell_type":"code","source":"#use random forest + ADASYN\n\n#train random forest\nrfc=RandomForestClassifier(n_jobs=2)\n\nparam_grid = {\n    'n_estimators': [10, 100, 1000],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='roc_auc')\n\n\n#train random forest\n\n\nCV_rfc.fit(features_train_ada,labels_train_ada)\n\nprint('Best parameters found by grid search are:', CV_rfc.best_params_)\n\nbest_rfc = CV_rfc.best_estimator_\n\npredictions=best_rfc.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98a282a48b923d76bfa0cf290519b86b9120f98a","collapsed":true,"_cell_guid":"8f1927b8-2fcd-4970-82f1-f0da7b856567","trusted":true},"cell_type":"code","source":"#use random forest + SMOTE NN \n\n#train random forest\nrfc=RandomForestClassifier(n_jobs=2)\n\nparam_grid = {\n    'n_estimators': [10, 100, 1000],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='roc_auc')\n\n\n#train random forest\n\n\nCV_rfc.fit(features_train_smnn,labels_train_smnn)\n\nprint('Best parameters found by grid search are:', CV_rfc.best_params_)\n\nbest_rfc = CV_rfc.best_estimator_\n\npredictions=best_rfc.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"435ad084bd3275fc42ead27a3677f98354348c97","collapsed":true,"_cell_guid":"97a25bee-2594-4e9d-9852-70b943e3e2d4","trusted":true},"cell_type":"code","source":"#use random forest + SMOTE TOMEK\n\n#train random forest\nrfc=RandomForestClassifier(n_jobs=2)\n\nparam_grid = {\n    'n_estimators': [10, 100, 1000],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='roc_auc')\n\n\n#train random forest\n\n\nCV_rfc.fit(features_train_smt,labels_train_smt)\n\nprint('Best parameters found by grid search are:', CV_rfc.best_params_)\n\nbest_rfc = CV_rfc.best_estimator_\n\npredictions=best_rfc.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53a159175155bf55987f992ad3c157d88e49fe7f","collapsed":true,"_cell_guid":"cd36c642-b473-490a-8584-5be5d60f64ba","trusted":true},"cell_type":"code","source":"#use random forest + reweighting\n\n#train random forest\nrfc=RandomForestClassifier(n_jobs=2, n_estimators = 1000, max_features = 'log2')\n\nparam_grid = {\n    'class_weight': [{1:3 , 0:1}, {1:5, 0:1}, {1:10, 0:1}]\n}\n\nCV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring='roc_auc')\n\n\n#train random forest\n\n\nCV_rfc.fit(features_train,labels_train)\n\nprint('Best parameters found by grid search are:', CV_rfc.best_params_)\n\nbest_rfc = CV_rfc.best_estimator_\n\npredictions=best_rfc.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud'] \nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dae0408d3ba99f48bb898ed42693f3020a56ddc7","_cell_guid":"372a8605-b77d-4aa9-9111-7ac34aa495be"},"cell_type":"markdown","source":"## Gradient Boosting"},{"metadata":{"_uuid":"a1b43d445a7da27941832955cf291174740d80e3","collapsed":true,"_cell_guid":"8b30a6c5-6b4b-4bcb-8834-802fcaae6e4d","trusted":true},"cell_type":"code","source":"#GRADIENT BOOSTING WITHOUT DATA AUGMENTATION\n\nparams = {'n_estimators': 1200, 'subsample': 0.5,\n          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\nclf = ensemble.GradientBoostingClassifier(**params)\n\nparam_grid = {\n    'learning_rate': [0.1, 0.01, 0.001],\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, scoring='roc_auc')\n\n#train\n\n\nCV_clf.fit(features_train,labels_train)\n\nprint('Best parameters found by grid search are:', CV_clf.best_params_)\n\nbest_clf = CV_clf.best_estimator_\n\npredictions=best_clf.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud']\nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39f90caf1232fe84a794e404a84e3c208d8f8ea9","collapsed":true,"_cell_guid":"d1139655-7f66-47c2-87a0-862b488e8700","trusted":true},"cell_type":"code","source":"#GRADIENT BOOSTING + ADASYN\n\nparams = {'n_estimators': 1200, 'subsample': 0.5,\n          'learning_rate': 0.01, 'min_samples_leaf': 1, 'random_state': 3}\nclf2 = ensemble.GradientBoostingClassifier(**params)\n\nparam_grid = {\n    'max_features': ['auto', 'sqrt', 'log2']\n}\n\nCV_clf2 = GridSearchCV(estimator=clf2, param_grid=param_grid, scoring='roc_auc')\n\n#train\n\n\nCV_clf2.fit(features_train_ada,labels_train_ada)\n\nprint('Best parameters found by grid search are:', CV_clf2.best_params_)\n\nbest_clf2 = CV_clf2.best_estimator_\n\npredictions=best_clf2.predict(features_test)\ncm = confusion_matrix(labels_test,predictions)\n\n\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(labels_test,predictions)\nroc_auc = auc(false_positive_rate, true_positive_rate)\n\n\ntarget_names = ['genuine', 'fraud']\nreport = classification_report_imbalanced(labels_test, predictions, target_names=target_names)\n\nprint('Confusion Matrix:')\nprint(cm)\nprint('Report:')\nprint(report)\nprint ('The obtained AUC is {}'.format(auc_res))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a04b8420ff550a8df5ffb5c99af70bb0abebe05","_cell_guid":"73328746-2b77-4374-b79c-18540f2038bc"},"cell_type":"markdown","source":"I am not goint to try Gradient boosting with Smote NN and Tomek because Adasyn seems to be the best. "},{"metadata":{"_uuid":"3c0a8303585e12b67e46fdca7aba1cc3a8ab1e6f","_cell_guid":"9fc5cdec-dd5f-4385-9e3a-48fcbff0c164"},"cell_type":"markdown","source":"# Conclusions\n\nFrom this experiments we learned that using a synthetic data generation technique increase drastically the performances of our learner. The reweighting technique seems to work for Logistic Regression and seems to have poor performances on Random Forest. This technique cannot be applied with Gradient Boosting apparently. \n\nThank you for reading and I hope you enjoied!"},{"metadata":{"_uuid":"d103fbbe8e44924def1d08e5d378ef4ae8082e65","collapsed":true,"_cell_guid":"379c2bdb-c4f7-4e32-b946-42fc3eb1a5a7","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"anaconda-cloud":{}},"nbformat":4,"nbformat_minor":1}