{"cells":[{"metadata":{"_uuid":"aff143129439ad734cb3561ff94c952835a0e8ac"},"cell_type":"markdown","source":"# Contents\n1. Load the training/test data\n2. Checking missing values\n3. Standardize the training/test data\n4. Train the model\n5. Predict the test data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import ElasticNet\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5cb50d117b6135fc92949d83168cef8b1edbfa5"},"cell_type":"markdown","source":"# **1. Load the training/test data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def read_data(file_name):\n    df = pd.read_csv(file_name)    \n    Y = df['target']\n    X = df.drop(columns=['target','id'])\n    return X, Y\n\n# load training data\nX_train, Y_train = read_data('../input/train.csv')\n\n# load testing data\nX_test = pd.read_csv('../input/test.csv').drop(columns=['id'])\n\nprint(X_train.shape, Y_train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c92181f6cb131b04ff20131c4c12918417309d2e"},"cell_type":"markdown","source":"Let's display some rows"},{"metadata":{"trusted":true,"_uuid":"5ea7d5b531a743c95d11a33d10f73e9e8fa31378"},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e658b426c7c9b00d1f3f232bd547ad1215fe984d"},"cell_type":"markdown","source":"And let's plot the target's frequency"},{"metadata":{"trusted":true,"_uuid":"082aed61d6a05d46f596ea46aa517b136f931876"},"cell_type":"code","source":"sns.countplot(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1cd657f24b7df4499dc040dbad5003ad2e633b3"},"cell_type":"markdown","source":"# 2. Checking missing values"},{"metadata":{"trusted":true,"_uuid":"46368f8f260d8be5c8b93980e1932d7b5c48618a"},"cell_type":"code","source":"X_train.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0aaaffb845d1ba9314c769792264507d8a291d3d"},"cell_type":"code","source":"X_test.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c1b08f46fcbe93374ddb6233e25a31dfca633e3"},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60a0ad75ccfd1622dcaf3d48fdc7264f8d2067cc"},"cell_type":"markdown","source":"As can be seen from above table, training examples are zero-centered (**mean**)  and have one standard deviation (**std**). In this case, there is no need to standardize the training data (Step 3 can be skipped somehow)."},{"metadata":{"_uuid":"fee23878f8e0d4e91f8f59eb319fc8ffcb11d826"},"cell_type":"markdown","source":"# 3. Standardize the training/test data"},{"metadata":{"trusted":true,"_uuid":"ec3d673c2abe2ffe0b42d6cafcab449f8dd78d1d"},"cell_type":"code","source":"sc = StandardScaler()\n\n# convert to numpy array\nX_train = X_train.values\nY_train = Y_train.values\nX_test = X_test.values\n\n# transform\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.fit_transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cce26afe8bce0559c37fe08b2704d76bacd47c5a"},"cell_type":"markdown","source":"Let's plot the training data distribution before/after scaling (only 2 rows)"},{"metadata":{"trusted":true,"_uuid":"2058b8e2332881a4e463eb50283e3c1394ad81fa"},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(6, 5))\n\nax1.set_title('Before Scaling')\nfor i in range(2):\n    sns.kdeplot(X_train[i], ax=ax1)\n\nax2.set_title('After Standard Scaler')\nfor i in range(2):\n    sns.kdeplot(X_train_scaled[i], ax=ax2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5fc7afa44da0695ca57372d6bcd249cfc5d11fb"},"cell_type":"markdown","source":"# 4. Train the model"},{"metadata":{"trusted":true,"_uuid":"54cffd54d40026f0182240abec2f2b0b1020164c"},"cell_type":"code","source":"best_parameters = { \n                    'alpha': 0.198, \n                    'l1_ratio': 0.3, \n                    'precompute': True, \n                    'selection': 'random', \n                    'tol': 0.001,\n                    'random_state': 19\n                }\n\nnet = ElasticNet(**best_parameters)\nnet.fit(X_train_scaled, Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13281b53ddba1e8ec78f956b64142d5e876a288e"},"cell_type":"markdown","source":"# 5. Predict the test data"},{"metadata":{"trusted":true,"_uuid":"8a47ae9e2424822e799085b00cc65992aaf97014"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = net.predict(X_test_scaled)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f44ccb1db297936dc52c21b3ca03d62a0f1bcaa"},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce8a1f1fc2ce704c90f81549cb8e10cd78ba419e"},"cell_type":"markdown","source":"## Please upvote if you like this kernel. Thank you :)"},{"metadata":{"_uuid":"9476bf3214025869ffee83117ed2a3420d167ab1"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}