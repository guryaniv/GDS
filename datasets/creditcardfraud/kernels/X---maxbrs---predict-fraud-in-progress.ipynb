{"cells":[{"metadata":{"_cell_guid":"70e88408-22df-42d4-bd9f-5c703db1093f","_uuid":"803c1b310909d8d3a5c2956d6649584db211beca"},"cell_type":"markdown","source":"## This kernel is still in progress ...\n## Feel free to tell me if you notice anything, and please come back when it will be finish !"},{"metadata":{"_cell_guid":"4714c78a-22a7-483c-8ab6-cc283a603f69","_uuid":"5908ff19fad58276be450d49fdcbf5cac3e9b1d2"},"cell_type":"markdown","source":"# Introduction"},{"metadata":{"_cell_guid":"9808866d-0e8f-43b5-8c45-eca1932618a9","_uuid":"1d1c673c1715bc708c64939cf104f34e169f747d"},"cell_type":"markdown","source":"In this kernel, I want to experiment some machine learning methods to build a model that would be able to classify fraud and non-fraud observations. It is a standars binary classification problem, but these classes are highly unequilibrated.\n\nTo do this analysis, I will experiment :\n- **Random Forest**\n- **Gradient Boosting**\n- **XGBoost**\n- **LightGBM**\n- **Adaboost**\n- **Neural Network** (Keras)\n\nAnd I will also try to combine these models to build :\n- **Bagging models**\n- **Stacking models**"},{"metadata":{"_cell_guid":"ab7e654d-a0f8-4902-9790-9aef110f9741","_uuid":"1c723079fa9ee7ca950352a773896a9ccbe1fa02"},"cell_type":"markdown","source":"**As I am still working on the improvement of this Kernel, feel free to tell me if you notice anything special !**"},{"metadata":{"_cell_guid":"0aa9e2ef-88fd-4302-8a80-4147e1ee5223","_uuid":"9a79100b2a53cf023ab54e2c7e372215d091b222"},"cell_type":"markdown","source":"# CREDIT CARD - FRAUD DETECTION"},{"metadata":{"collapsed":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport numpy as np\nimport pandas as pd\nfrom time import time\nimport datetime\nfrom math import sqrt\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\nfrom sklearn.preprocessing import StandardScaler, Imputer\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\nimport xgboost as xgb\nfrom xgboost import plot_importance\nimport lightgbm as lgb\nfrom keras.models import Sequential, load_model\nfrom keras.layers.core import Dense, Dropout\nfrom keras.optimizers import RMSprop\n\nt0 = time()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c787463-2b4f-480e-b2c2-b9a50c0771eb","_uuid":"94d0421a437cac002078c0a9a15c1a248e262c73"},"cell_type":"markdown","source":"# Load data"},{"metadata":{"collapsed":true,"_cell_guid":"2cc40cbf-e377-4036-875e-ce63501756f0","_uuid":"a303c095b55b799745207edb1b71c4143c95f84c","trusted":false},"cell_type":"code","source":"data = pd.read_csv('../input/creditcard.csv', sep=',', decimal='.')\ndata.info()\ndata.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1327885c-4dd6-47a4-aa54-a8d7c42fc40c","_uuid":"78f8ddd4cb67e6c0de8ce132e6d967113a83ea74"},"cell_type":"markdown","source":"## Preprocess data"},{"metadata":{"collapsed":true,"_cell_guid":"fc3c3665-2b01-4d93-a9e6-9b3163fc5e70","_uuid":"4261ca14321ed8119260f29b915c606e63f639d0","trusted":false},"cell_type":"code","source":"numericFeatures = ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\nscale_num = StandardScaler()\nscale_num.fit(data[numericFeatures])\ndata[numericFeatures] = scale_num.transform(data[numericFeatures])\ndata.head()\n\nplt.bar([0,1], height = data.Class.value_counts(), tick_label = ['No fraud','Fraud'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"27e1396b-2695-43f0-a9a9-68191fb2910b","_uuid":"b671f4aa7a851eb3095ca2043c5cc73577f3abb3"},"cell_type":"markdown","source":"## Create train & validation subsets"},{"metadata":{"collapsed":true,"_cell_guid":"1521ceb0-a2fd-43b7-bfce-76dee4118495","_uuid":"cac696f79b2d3fe54d00e3235d4f53bec3f3034f","trusted":false},"cell_type":"code","source":"y_data = data['Class']\nX_data = data.drop('Class', 1)\n\nX_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.33, random_state=29)\n\n# pickle.dump((X_train, X_val, y_train, y_val), open(obj_save_path+'train_val_df.p', 'wb'))\n#X_train, X_val, y_train, y_val = pickle.load(open(obj_save_path+'train_val_df.p', 'rb'))\nprint('Ready to start ML part !')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0a029804-a4d5-44d5-b58e-2811e99448eb","_uuid":"3b811d0e600d343043d3b798a546603de8e67510"},"cell_type":"markdown","source":"## I. Random Forest"},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"print('ML part. I : starting Random Forest !')\n\nmodel_rf = RandomForestClassifier(n_estimators=50,\n                                  max_depth=20,\n                                  min_samples_split=5,\n                                  min_samples_leaf=20,\n                                  bootstrap=True, oob_score=True, criterion='gini',\n                                  random_state=321, n_jobs=4, verbose=1)\n\nmodel_rf.fit(X_train, y_train)\n\n# pickle.dump(model_rf, open(obj_save_path+'model_rf.p', 'wb'))\n#model_rf = pickle.load(open(obj_save_path+'model_rf.p', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e938d389-8f92-4466-b3a8-b6d12e29b4c2","_uuid":"cb50fc0c1b8d7891157215c9a1a7632f8f4798c1","trusted":false},"cell_type":"code","source":"def plot_imp_rf(model_rf, X):\n    importances = model_rf.feature_importances_\n    std = np.std([tree.feature_importances_ for tree in model_rf.estimators_],\n                 axis=0)\n    indices = np.argsort(importances)[::-1]\n    names = X.columns[indices]\n    # Print the feature ranking\n    print(\"Feature ranking:\")\n    for f in range(X.shape[1]):\n        print(str(f+1)+'. feature '+str(names[f])+' ('+str(importances[indices[f]])+')')\n    # Plot the feature importances of the forest\n    plt.figure(figsize=(10, 5))\n    plt.title(\"Feature importances\")\n    plt.bar(range(X.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n    plt.xticks(range(X.shape[1]), names, rotation=80)\n    plt.xlim([-1, X.shape[1]])\n    plt.show()\n\nplot_imp_rf(model_rf, X_train)\n# oob_error = 1 - model_rf.oob_score_","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"05354941-be28-4adb-8ab1-29fac3afab4c","_uuid":"9c69566211f4b269baf8d8b933de3fc118fea14d","trusted":false},"cell_type":"code","source":"def verif_valid(model, X_val, y_val):\n    if type(model) == Sequential:\n        X_val = np.array(X_val)\n    reality = y_val\n    predictions = model.predict(X_val)\n    if type(model) == lgb.basic.Booster:\n        for i in range(len(predictions)):\n            if predictions[i] >= 0.5:  # threshold = 0.5\n               predictions[i] = 1\n            else:\n               predictions[i] = 0\n    if len(predictions.shape) == 2:\n        predictions = predictions[:, 0]\n    print('Matrice de confusion :')\n    print(confusion_matrix(reality, predictions))\n    print('Métriques de précision associées :')\n    print(classification_report(reality, predictions))\n    print('Score AUC :')\n    print(roc_auc_score(reality, predictions))\n\nverif_valid(model_rf, X_val, y_val)\n\nprint('ML part. I : Random Forest, done !')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e04ba587-b781-4704-8ec2-a08d7a9af394","_uuid":"db6164420a7ec6554a141535dec3482409abef49"},"cell_type":"markdown","source":"## II. GRADIENT BOOSTING"},{"metadata":{"collapsed":true,"_cell_guid":"9934b3ef-ebab-4847-ae55-3b9846c03e22","_uuid":"094f5c442ce00db88f0723b9711a2aa121dc596b","trusted":false},"cell_type":"code","source":"print('ML part. II : starting Gradient Boosting !')\n\nmodel_gradb = GradientBoostingClassifier(loss='deviance',\n                                        learning_rate=0.2,\n                                        n_estimators=100,\n                                        subsample=0.9,\n                                        #min_samples_leaf=10,\n                                        max_depth=6,\n                                        random_state=321, verbose=0)\n\nmodel_gradb.fit(X_train, y_train)\n\n# pickle.dump(model_gradb, open(obj_save_path+'model_gradb.p', 'wb'))\n#model_gradb = pickle.load(open(obj_save_path+'model_gradb.p', 'rb'))\n\nverif_valid(model_gradb, X_val, y_val)\n\nprint('ML part. II : Gradient Boosting, done !')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"780052c4-1506-410b-b49c-5da5df6ec89c","_uuid":"e86ae2502de66204cbcd06a734cf95b856229893"},"cell_type":"markdown","source":"## III. XGBoost"},{"metadata":{"collapsed":true,"_cell_guid":"5513b371-de0d-454f-9aa5-0f38d755406d","_uuid":"8b076075999ed52f31192dd17bfdc41d64eba11a","trusted":false},"cell_type":"code","source":"print('ML part. III : starting XGBoost !')\n\nmodel_xgb = xgb.XGBClassifier(base_score=0.5,\n                              subsample=0.8,\n                              max_delta_step=2,\n                              max_depth=7,\n                              min_child_weight=3,\n                              learning_rate=0.1,\n                              n_estimators=580,\n                              objective='binary:logistic',\n                              #booster='gbtree',\n                              colsample_bytree=0.85,\n                              gamma=0,\n                              reg_alpha=0,\n                              reg_lambda=1,\n                              scale_pos_weight=1,\n                              seed=321, silent=0)\n\nmodel_xgb.fit(X_train, y_train)\n\nprint(model_xgb)\n\n# pickle.dump(model_xgb, open(obj_save_path+'model_xgb.p', 'wb'))\n#model_xgb = pickle.load(open(obj_save_path+'model_xgb.p', 'rb'))\n\nplot_importance(model_xgb)\nplt.show()\n\nverif_valid(model_xgb, X_val, y_val)\n\nprint('ML part. III : XGBoost, done !')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"443a9f6f-ba3a-4af9-8629-8434a42e70db","_uuid":"1dfeaaa95931693b4562f325d0b5604834d746f8"},"cell_type":"markdown","source":"## IV. LightGBM"},{"metadata":{"_kg_hide-input":false,"collapsed":true,"_cell_guid":"7470f4ea-31b3-4549-87d6-63d828391004","_kg_hide-output":false,"_uuid":"088f77ce42ac82eb887aeb55839c4e32dd1ed847","trusted":false},"cell_type":"code","source":"print('ML part. IV : starting LightGBM !')\n\nd_train = lgb.Dataset(X_train, label=y_train)\nparams = {}\nparams['learning_rate'] = 0.1\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'binary'\nparams['metric'] = 'binary_logloss'\nparams['sub_feature'] = 0.5\nparams['num_leaves'] = 10\nparams['min_data'] = 50\nparams['max_depth'] = 10\nmodel_lgbm = lgb.train(params, d_train, 500)\n\n# pickle.dump(model_lgbm, open(obj_save_path+'model_lgbm.p', 'wb'))\n#model_lgbm = pickle.load(open(obj_save_path+'model_lgbm.p', 'rb'))\n\nverif_valid(model_lgbm, X_val, y_val)\n\nprint('ML part. IV : LightGBM, done !')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f82a4843-d175-4150-8696-e27dd3b09e23","_uuid":"2db380dcf5a4a034adb7933db6a5eb385a9d2f6a"},"cell_type":"markdown","source":"## V. ADABOOST"},{"metadata":{"collapsed":true,"_cell_guid":"5e0bc28c-6bcb-4b78-a86c-c22c4e506645","_uuid":"b8610c13afd12ec90afe7a615eab7eb4451b91f6","trusted":false},"cell_type":"code","source":"print('ML part. V : starting Adaboost !')\n\nmodel_adab = AdaBoostClassifier(#base_estimator=RandomForestClassifier(),\n                               n_estimators=300,\n                               learning_rate=0.28,\n                               #loss='linear',\n                               random_state=321)\n\nmodel_adab.fit(X_train, y_train)\n\n# pickle.dump(model_adab, open(obj_save_path+'model_adab.p', 'wb'))\n#model_adab = pickle.load(open(obj_save_path+'model_adab.p', 'rb'))\n\nverif_valid(model_adab, X_val, y_val)\n\nprint('ML part. V : Adaboost, done !')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c4305f81-1177-4feb-9eea-dc79222f230c","_uuid":"af76bbc5748dccc4a59af4522be72f300030beb7","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}