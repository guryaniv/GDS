{"cells":[{"metadata":{"_cell_guid":"808f988c-1f41-4f7d-8793-c2026c82b4d1","_uuid":"e705a25a301e51beba73d58c0d382009df875761","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"69a946d1-e6ba-49aa-ba1a-f2c518473150","_uuid":"10a565a4db1618f6284f08c3b62192eca1433aa0"},"cell_type":"markdown","source":"First we import some datasets of interest","outputs":[],"execution_count":null},{"metadata":{"_uuid":"b0fb0901d2490632a2824dc05805c4f210115bc1","_cell_guid":"4a7dc0a7-ca01-4190-91d4-ccb4fe370e49","collapsed":true,"trusted":true},"cell_type":"code","source":"#the seed information\ndf_seeds = pd.read_csv('../input/NCAATourneySeeds.csv')\n\n#tour information\ndf_tour = pd.read_csv('../input/NCAATourneyCompactResults.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e454a77e-f49c-4d9d-892c-1123d8454bc2","_uuid":"527abe962805346c8c8f6f16fdf5dd2597236dff"},"cell_type":"markdown","source":"Now we separate the winners from the losers and organize our dataset","outputs":[],"execution_count":null},{"metadata":{"_uuid":"7091f2c2a2ed6c5d8a146a3ac51c298a5a2a283e","_cell_guid":"4ec6229b-7494-4f18-a0a0-d8e5370c5f46","collapsed":true,"trusted":true},"cell_type":"code","source":"df_seeds['seed_int'] = df_seeds['Seed'].apply( lambda x : int(x[1:3]) )\n\ndf_winseeds = df_seeds.loc[:, ['TeamID', 'Season', 'seed_int']].rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\ndf_lossseeds = df_seeds.loc[:, ['TeamID', 'Season', 'seed_int']].rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\ndf_dummy = pd.merge(left=df_tour, right=df_winseeds, how='left', on=['Season', 'WTeamID'])\ndf_concat = pd.merge(left=df_dummy, right=df_lossseeds, on=['Season', 'LTeamID'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0e40d3d-7779-4667-8678-a96395355b9f","_uuid":"3bb822c49b897ac8d62058b7c2ea5c72ad9e0236"},"cell_type":"markdown","source":"Now we match the detailed results to the merge dataset above","outputs":[],"execution_count":null},{"metadata":{"_uuid":"03a96523f7d9a19dd29272952152fe6b0fa48f50","_cell_guid":"9aac33f3-1676-4ecb-b5d9-f164cf51e941","collapsed":true,"trusted":true},"cell_type":"code","source":"df_concat['DiffSeed'] = df_concat[['LSeed', 'WSeed']].apply(lambda x : 0 if x[0] == x[1] else 1, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e28cb983-7c48-46cd-8dc4-1dfe8dba3578","_uuid":"da5ff40a0948b76cd38dcc5e6f4b586a34956f08"},"cell_type":"markdown","source":"Here we get our submission info","outputs":[],"execution_count":null},{"metadata":{"_uuid":"f75b6b8769bf465778bd886288db760dfccc1cb8","_cell_guid":"d4981782-e062-451b-8d1e-0eae753283c6","collapsed":true,"trusted":true},"cell_type":"code","source":"#prepares sample submission\ndf_sample_sub = pd.read_csv('../input/SampleSubmissionStage1.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12bb1ee9fef8960fc1889d6e0819befcb1551cd4","_cell_guid":"6e5c767d-e38a-4780-88cf-6121001b17c4","collapsed":true,"trusted":true},"cell_type":"code","source":"df_sample_sub['Season'] = df_sample_sub['ID'].apply(lambda x : int(x.split('_')[0]) )\ndf_sample_sub['TeamID1'] = df_sample_sub['ID'].apply(lambda x : int(x.split('_')[1]) )\ndf_sample_sub['TeamID2'] = df_sample_sub['ID'].apply(lambda x : int(x.split('_')[2]) )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50ca7908-c5ec-4225-9290-db44a432948f","_uuid":"5e3ac254a7959225599e5ce254ed13a1eb128d8d"},"cell_type":"markdown","source":"# Training Data Creation","outputs":[],"execution_count":null},{"metadata":{"_uuid":"e05bb9aac2a0c46bc823be004888c1ad4d8232b2","_cell_guid":"1aefba0e-f65c-4538-bfd4-24bbdc5d7b62","collapsed":true,"trusted":true},"cell_type":"code","source":"winners = df_concat.rename( columns = { 'WTeamID' : 'TeamID1', \n                                                       'LTeamID' : 'TeamID2',\n                                                      'WScore' : 'Team1_Score',\n                                                      'LScore' : 'Team2_Score'}).drop(['WSeed', 'LSeed', 'WLoc'], axis = 1)\nwinners['Result'] = 1.0\n\nlosers = df_concat.rename( columns = { 'WTeamID' : 'TeamID2', \n                                                       'LTeamID' : 'TeamID1',\n                                                      'WScore' : 'Team2_Score',\n                                                      'LScore' : 'Team1_Score'}).drop(['WSeed', 'LSeed', 'WLoc'], axis = 1)\n\nlosers['Result'] = 0.0\n\ntrain = pd.concat( [winners, losers], axis = 0).reset_index(drop = True)\n\ntrain['Score_Ratio'] = train['Team1_Score'] / train['Team2_Score']\ntrain['Score_Total'] = train['Team1_Score'] + train['Team2_Score']\ntrain['Score_Pct'] = train['Team1_Score'] / train['Score_Total']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cd02010a-f89a-4f74-8f7b-2ac9fd5faebc","_uuid":"d7ddc45574af7aef6c253368700b598f8f2d01dc"},"cell_type":"markdown","source":"We will only consider years relevant to our test submission","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b9854119-287d-4886-9eab-7ddb3c43b4d8","_uuid":"d9d25150440215fb7d2c3be529dc191e74f3dcd2","trusted":true},"cell_type":"code","source":"years = [2014, 2015, 2016, 2017]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8181e004-87c6-4233-a607-1ae409a88e43","_uuid":"17d0b4d22e0fc24f4b7ff047d77b2e6e32c9043e"},"cell_type":"markdown","source":"Now lets just look at TeamID2, or just the second team info.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"51c899714907a95837d521a7fb58a1a9c998c45f","_cell_guid":"6ab2055b-692b-4359-82c2-5c8569a3593b","collapsed":true,"trusted":true},"cell_type":"code","source":"train_test_inner = pd.merge( train.loc[ train['Season'].isin(years), : ].reset_index(drop = True), \n         df_sample_sub.drop(['ID', 'Pred'], axis = 1), \n         on = ['Season', 'TeamID1', 'TeamID2'], how = 'inner' )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8765baf2-14bd-41b3-97ad-3f61589471c0","_uuid":"24a2c86b65d10e8b89dc440f0ab9010f41e498b5","trusted":true},"cell_type":"code","source":"train_test_inner.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d949fd36-41e5-49a3-baca-9c413dda8ead","_uuid":"bc53738a6bb663f2cfbdca37cb89b39a28502ef9"},"cell_type":"markdown","source":"From the inner join, we will create data per team id to estimate the parameters we are missing that are independent of the year.  Essentially, we are trying to estimate the average behavior of the team across the year.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"e9229cea-e197-4175-af81-a8c73559fa85","_uuid":"3d1d6ebcc2c00491a326277d01ee1843b28ba041","trusted":true},"cell_type":"code","source":"team1d_num_ot = train_test_inner.groupby(['Season', 'TeamID1'])['NumOT'].median().reset_index()\\\n.set_index('Season').rename(columns = {'NumOT' : 'NumOT1'})\nteam2d_num_ot = train_test_inner.groupby(['Season', 'TeamID2'])['NumOT'].median().reset_index()\\\n.set_index('Season').rename(columns = {'NumOT' : 'NumOT2'})\n\nnum_ot = team1d_num_ot.join(team2d_num_ot).reset_index()\n\n#sum the number of ot calls and subtract by one to prevent overcounting\nnum_ot['NumOT'] = num_ot[['NumOT1', 'NumOT2']].apply(lambda x : round( x.sum() ), axis = 1 )\n\nnum_ot.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6bfe5a2e-64c9-4182-ab95-9df6b26652ee","_uuid":"6ba1de202839605950e4f6d4100ca0b162a41caf"},"cell_type":"markdown","source":"Here we look at the comparable statistics.  For the TeamID2 column, we would consider the inverse of the ratio, and 1 minus the score attempt percentage.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a9b820c4-6ff1-4855-90f1-283517d046eb","_uuid":"c0d0a6c93209d22a3e809c77507340e97c1c0a11","trusted":true},"cell_type":"code","source":"def geo_mean( x ):\n    return np.exp( np.mean(np.log(x)) )\n\ndef harm_mean( x ):\n    return np.mean( x ** -1.0 ) ** -1.0\n\nteam1d_score_spread = train_test_inner.groupby(['Season', 'TeamID1'])[['Score_Ratio', 'Score_Pct']]\\\n.agg({ 'Score_Ratio': geo_mean, 'Score_Pct' : harm_mean}).reset_index()\\\n.set_index('Season').rename(columns = {'Score_Ratio' : 'Score_Ratio1', 'Score_Pct' : 'Score_Pct1'})\nteam2d_score_spread = train_test_inner.groupby(['Season', 'TeamID2'])[['Score_Ratio', 'Score_Pct']]\\\n.agg({ 'Score_Ratio': geo_mean, 'Score_Pct' : harm_mean}).reset_index()\\\n.set_index('Season').rename(columns = {'Score_Ratio' : 'Score_Ratio2', 'Score_Pct' : 'Score_Pct2'})\n\nscore_spread = team1d_score_spread.join(team2d_score_spread).reset_index()\n\n#geometric mean of score ratio of team 1 and inverse of team 2\nscore_spread['Score_Ratio'] = score_spread[['Score_Ratio1', 'Score_Ratio2']].apply(lambda x : ( x[0] * ( x[1] ** -1.0) ), axis = 1 ) ** 0.5\n\n#harmonic mean of score pct\nscore_spread['Score_Pct'] = score_spread[['Score_Pct1', 'Score_Pct2']].apply(lambda x : 0.5*( x[0] ** -1.0 ) + 0.5*( 1.0 - x[1] ) ** -1.0, axis = 1 ) ** -1.0\n\nscore_spread.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9acddd0a-ce83-4cb2-b5ec-5ea8f63b7a12","_uuid":"5950ad4cf87dc9cf1fe4ed3e5270931414369c13"},"cell_type":"markdown","source":"Now lets create a model just solely based on the inner group and predict those probabilities. \n\nWe will get the teams with the missing result.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"ffcb3fd4442a70c521095136e3093319eb3e4fa8","_cell_guid":"2ba53742-9354-41bd-82a4-9a29f4420b76","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train = train_test_inner.loc[:, ['Season', 'NumOT', 'Score_Ratio', 'Score_Pct']]\ntrain_labels = train_test_inner['Result']\n\ntrain_test_outer = pd.merge( train.loc[ train['Season'].isin(years), : ].reset_index(drop = True), \n         df_sample_sub.drop(['ID', 'Pred'], axis = 1), \n         on = ['Season', 'TeamID1', 'TeamID2'], how = 'outer' )\n\ntrain_test_outer = train_test_outer.loc[ train_test_outer['Result'].isnull(), \n                                        ['TeamID1', 'TeamID2', 'Season']]\n\ntrain_test_missing = pd.merge( pd.merge( score_spread.loc[:, ['TeamID1', 'TeamID2', 'Season', 'Score_Ratio', 'Score_Pct']], \n                   train_test_outer, on = ['TeamID1', 'TeamID2', 'Season']),\n         num_ot.loc[:, ['TeamID1', 'TeamID2', 'Season', 'NumOT']],\n         on = ['TeamID1', 'TeamID2', 'Season'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a2d4441-4a06-4dc6-bd08-73ffdec35005","_uuid":"d60c8973fe87097d57580a47864a56918e6f864f"},"cell_type":"markdown","source":"We scale our data for our logistic regression, and make sure our categorical variables are properly processed.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"95268c5c-1da0-4ed3-a30f-eb5c31efc64e","_uuid":"523d27436cd4593ade32cd26bbdee7004e713009","trusted":true,"collapsed":true},"cell_type":"code","source":"X_test = train_test_missing.loc[:, ['Season', 'NumOT', 'Score_Ratio', 'Score_Pct']]\n\nn = X_train.shape[0]\n\ntrain_test_merge = pd.concat( [X_train, X_test], axis = 0 ).reset_index(drop = True)\n\ntrain_test_merge = pd.concat( [pd.get_dummies( train_test_merge['Season'].astype(object) ), \n            train_test_merge.drop('Season', axis = 1) ], axis = 1 )\n\ntrain_test_merge = pd.concat( [pd.get_dummies( train_test_merge['NumOT'].astype(object) ), \n            train_test_merge.drop('NumOT', axis = 1) ], axis = 1 )\n\nX_train = train_test_merge.loc[:(n - 1), :].reset_index(drop = True)\nX_test = train_test_merge.loc[n:, :].reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea2411e0e759d42b0a16e1d0b4c53a14807ed6ad","_cell_guid":"041c02d8-d033-4a81-90eb-72fbb9546002","collapsed":true,"trusted":true},"cell_type":"code","source":"x_max = X_train.max()\nx_min = X_train.min()\n\nX_train = ( X_train - x_min ) / ( x_max - x_min + 1e-14)\nX_test = ( X_test - x_min ) / ( x_max - x_min + 1e-14)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e181cb99-419f-4ae3-9f4a-d2efacf51523","_uuid":"6ed274ee9b7e457f4d90d9ed34e4db5ed6590b7a","trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\n\nlog_clf = LogisticRegressionCV(cv = 5)\n\nlog_clf.fit( X_train, train_labels )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1eac4a2f-2adb-4024-b27a-7bb190eb0218","_uuid":"e555bc243a54de4bb2328a1950433e7b270840cf"},"cell_type":"markdown","source":"Here we store our probabilities","outputs":[],"execution_count":null},{"metadata":{"_uuid":"c4fb1aa4d082b150308eb6c05da52936c282929a","_cell_guid":"9240a9a2-125f-4080-8312-9cef6ef01f36","collapsed":true,"trusted":true},"cell_type":"code","source":"train_test_inner['Pred1'] = log_clf.predict_proba(X_train)[:,1]\ntrain_test_missing['Pred1'] = log_clf.predict_proba(X_test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1ce6decf-87cd-430f-b0ba-03866c37f11d","_uuid":"853dc8d62462cae05129941346cfb72ce27fadd1"},"cell_type":"markdown","source":"We merge our predictions","outputs":[],"execution_count":null},{"metadata":{"_uuid":"1d18855f0809102f5977f8e56662360571678d3b","_cell_guid":"cb3bd03c-c657-4373-9149-bbac48f01bb4","collapsed":true,"trusted":true},"cell_type":"code","source":"sub = pd.merge(df_sample_sub, \n                         pd.concat( [train_test_missing.loc[:, ['Season', 'TeamID1', 'TeamID2', 'Pred1']],\n                                     train_test_inner.loc[:, ['Season', 'TeamID1', 'TeamID2', 'Pred1']] ],\n                                   axis = 0).reset_index(drop = True),\n                  on = ['Season', 'TeamID1', 'TeamID2'], how = 'outer')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37984e41-9e15-4f7e-b220-82592ad7d723","_uuid":"9f667dbe45586396c8695673d0c3378da0f11186"},"cell_type":"markdown","source":"We get the 'average' probability of success for each team","outputs":[],"execution_count":null},{"metadata":{"_uuid":"8931f14c50ce5e7ff46dc20b64522279f93b5112","_cell_guid":"fcadfca6-7b2b-4d59-b50c-ae86739cf95e","collapsed":true,"trusted":true},"cell_type":"code","source":"team1_probs = sub.groupby('TeamID1')['Pred1'].apply(lambda x : (x ** -1.0).mean() ** -1.0 ).fillna(0.5).to_dict()\nteam2_probs = sub.groupby('TeamID2')['Pred1'].apply(lambda x : (x ** -1.0).mean() ** -1.0 ).fillna(0.5).to_dict()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"20d14f70-8fd2-4728-a95f-b85cf06d06fd","_uuid":"d4cf47906b76f7f1c09841d7856a4a5188c647e3"},"cell_type":"markdown","source":"Any missing value for the prediciton will be imputed with the product of the probabilities calculated above.  We assume these are independent events.","outputs":[],"execution_count":null},{"metadata":{"_uuid":"0dbb8fe571e51bc18f640d89cdfacb9aa25bfa09","_cell_guid":"c7ebdbb5-037f-49e2-8f3d-46785536e3cf","collapsed":true,"trusted":false},"cell_type":"code","source":"sub['Pred'] = sub[['TeamID1', 'TeamID2','Pred1']]\\\n.apply(lambda x : team1_probs.get(x[0]) * ( 1 - team2_probs.get(x[1]) ) if np.isnan(x[2]) else x[2], \n       axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05aa8d73fa65a02705d318d9c97be24b923e6ee7","_cell_guid":"f484187d-4272-4a36-9252-a7a8143a11de","collapsed":true,"trusted":false},"cell_type":"code","source":"sub[['ID', 'Pred']].to_csv('sub.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb17eff1-5946-4438-8d91-ce5176572cd7","_uuid":"7e7bfaecf446551a3552bdb145c459a9e5bf69c1","trusted":false,"collapsed":true},"cell_type":"code","source":"sub[['ID', 'Pred']].head(20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50bf94c114b6d27d9bd33815f4c33ec52c1f7bfa","_cell_guid":"dfb18170-66f1-4004-8ec9-ba52c18dcde4","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}