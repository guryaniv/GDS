{"cells":[{"metadata":{"_uuid":"81d13b6fa3108e6531f8c4d21bf468cce49620ed"},"cell_type":"markdown","source":"I wanted to learn how to apply baseline models in python so I skipped EDA and feature engineering parts in this kernel. Before starting this practice, I would like to say that I refered to the following kernel.  \n[samratp kernel](http://www.kaggle.com/samratp/santander-value-prediction-xgb-and-lightgbm)\n"},{"metadata":{"_uuid":"31f409bdb6761e66b46e97fc31b92807c9e86e3e"},"cell_type":"markdown","source":"# Simple step for applying baseline models\n1. Load libraries\n2. Load data\n3. Overview on data\n4. Check for missing value\n5. Check if all the values in a given row/column are 0\n6. Drop the zero-column in Training data \n7. Build data set\n8. Compare several baseline models"},{"metadata":{"_uuid":"524dd2d805081fb410971438067e6dcc977bd4f1"},"cell_type":"markdown","source":"## Load libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\n\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cb7009783869630a83088afea8d0adf756ec800"},"cell_type":"markdown","source":"## Load data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')  # train dataframe\ntest_df  = pd.read_csv('../input/test.csv')   # test dataframe\ntrain_df.head(n=10)\n#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74be0c6d343fd42a43476e474f21057511d85d5c"},"cell_type":"markdown","source":"##  Overview on data\n\nFirst of all, check the dimension of tarining/tesst data set, "},{"metadata":{"trusted":true,"_uuid":"e960492a1dda99c0295e3221cf2d5cd80f18c2fb"},"cell_type":"code","source":"# training set\nprint (\"Training set:\")\nn_data  = len(train_df)\nn_features = train_df.shape[1]\nprint (\"Number of Records: {}\".format(n_data))\nprint (\"Number of Features: {}\".format(n_features))\n\n# test set\nprint (\"\\nTest set:\")\nn_data  = len(test_df)\nn_features = test_df.shape[1]\nprint (\"Number of Records: {}\".format(n_data))\nprint (\"Number of Features: {}\".format(n_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc5929db829d30689bd899dc69e60fcb12e64e97"},"cell_type":"code","source":"train_df.info()\n#test_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b50768f64fc230a1f92d73f5ce764b5a9228e49"},"cell_type":"markdown","source":"## Check for missing value\nCheck if there are any Null values in training data and test data. "},{"metadata":{"trusted":true,"_uuid":"a0f227bf6ce21ac2102035ae738c493a9e3574de"},"cell_type":"code","source":"#### Check if there are any NULL values in training Data\nprint(\"Total Training Features with NaN Values = \" + str(train_df.columns[train_df.isnull().sum() != 0].size))\nif (train_df.columns[train_df.isnull().sum() != 0].size):\n    print(\"Features with NaN => {}\".format(list(train_df.columns[train_df.isnull().sum() != 0])))\n    train_df[train_df.columns[train_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ee21c0a984a6226b23a495085a1088f700f1dfb"},"cell_type":"code","source":"#### Check if there are any NULL values in test Data\nprint(\"Total Test Features with NaN Values = \" + str(test_df.columns[test_df.isnull().sum() != 0].size))\nif (test_df.columns[test_df.isnull().sum() != 0].size):\n    print(\"Features with NaN => {}\".format(list(test_df.columns[test_df.isnull().sum() != 0])))\n    test_df[test_df.columns[test_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c2e888092a08f3c26e77083386bc481ce00816"},"cell_type":"markdown","source":"## Check if all the values in a given row/column are 0\n"},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"trusted":true,"scrolled":true,"_uuid":"988b29df1ddc0012780ae3081d0a13cc1b569799"},"cell_type":"code","source":"#Example\n##step 1) Select multiple columns\nnewdf = train_df[train_df.columns[25:30]]\nnewdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6067af560796d5dad0ac9b4e7b3c1e82700b3dd5"},"cell_type":"code","source":"##step 2) Check if all the values in each row/column are 0 \n#newdf != 0\n(newdf != 0).any(axis=0)\n# column 'd5308d8bc' has only 0 values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"cadba439b74ab65f97e971ac831078c270b6a483"},"cell_type":"code","source":"##step 3) Double check the column'd5308d8bc' in raw data(train_df)\ntotal = train_df['d5308d8bc'].sum()\nprint(total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7263ad7b39c257fe6da1b849356d73620e0c9bb2"},"cell_type":"code","source":"##step 4) Drop the columns where all values are zero \nnewdf.loc[:, (newdf != 0).any(axis=0)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52407caa2dd0322db196cd85c03e4cc82e087b34"},"cell_type":"markdown","source":"## Drop the zero-column(constant feature) in data"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"89a49dec81ab35fc984ff2b63269f8d7c3c48afb"},"cell_type":"code","source":"# 1) training data\ntrain_df = train_df.loc[:, (train_df != 0).any(axis=0)]\n#train_df\n# 256 columns are dropped\n\n# 1) test data\ntest_df = test_df.loc[:, (test_df != 0).any(axis=0)]\n#test_df\n# 1 column is dropped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fb703a52703d82eae45f66968d484a4fbde0712"},"cell_type":"code","source":"print(\"Train set size: {}\".format(train_df.shape))\nprint(\"Test set size: {}\".format(test_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"407ce2ec67e9e0da8cef32efc404a71c673fe5b4"},"cell_type":"markdown","source":"## Build the data set"},{"metadata":{"trusted":true,"_uuid":"5d16e531b7105513a4d9c458a52fba57988358cc"},"cell_type":"code","source":"#step 1) set x and y\n#a) x in train data\n## axis = 1 means a row\nX_train = train_df.drop([\"ID\", \"target\"], axis=1)\n\n#b) y in train data\n# #np.log1p :  log(1 + x)\nY_train = np.log1p(train_df[\"target\"].values)\n#X_train.head()\n#Y_train\n\n#c) x in test data\nX_test = test_df.drop([\"ID\"], axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5287cf0afcf6bf9e999e309f520cd85ef6e95f33"},"cell_type":"code","source":"# step 2) split train_df \nx_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7525de032bf3eaa6a882437dbcd03a8b2a7bd729"},"cell_type":"markdown","source":"# Modeling "},{"metadata":{"_uuid":"4346e3a2aaa252f736593f839c860098ac1bbb5a"},"cell_type":"markdown","source":"## Light GBM"},{"metadata":{"trusted":true,"_uuid":"1ec2c1f4d5bfcfd08bbfaac277d88ee23a9da987"},"cell_type":"code","source":"# step 1) set lgb function\n## meaning of expm1\n#lgb function \ndef run_lgb(train_x, train_y, valid_x, valid_y, test_x):\n    params = {\n        \"boosting_type\":'gbdt',\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\",\n        \"num_leaves\" : 40,\n        \"learning_rate\" : 0.005,\n        \"bagging_fraction\" : 0.7,\n        \"feature_fraction\" : 0.5,\n        \"bagging_frequency\" : 5,\n        \"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"random_seed\": 42\n    }\n    \n    lgtrain = lgb.Dataset(train_x, label=train_y)\n    lgval = lgb.Dataset(valid_x, label=valid_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 5000, \n                      valid_sets=[lgval], \n                      early_stopping_rounds=100, \n                      verbose_eval=50, \n                      evals_result=evals_result)\n    \n    pred_test_y = np.expm1(model.predict(test_x, num_iteration=model.best_iteration))\n    return pred_test_y, model, evals_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c12c8a75fba05dbd82ca7988dbed2b3c74d9492"},"cell_type":"code","source":"# step 2) Training LGB\npred_test, model, evals_result = run_lgb(x_train, y_train, x_valid, y_valid, X_test)\nprint(\"LightGBM Training Completed...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2617aee4a9a7daedeaf0599515b9242fe056b18a"},"cell_type":"code","source":"# step 3) feature importance\nprint(\"Features Importance...\")\ngain = model.feature_importance('gain')\nfeatureimp = pd.DataFrame({'feature':model.feature_name(), \n                   'split':model.feature_importance('split'), \n                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\nprint(featureimp[:15])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b34202797087f43645e7a08d5e98459f3c1fa33"},"cell_type":"markdown","source":"# XGB modeling"},{"metadata":{"trusted":true,"_uuid":"819176ec9140f269af0acb5f3dbb0f555216fa91"},"cell_type":"code","source":"# step 1) set XGB function \ndef run_xgb(train_x, train_y, valid_x, valid_y, test_x):\n    params = {'objective': 'reg:linear', \n          'eval_metric': 'rmse',\n          'eta': 0.005,\n          'max_depth': 10, \n          'subsample': 0.6, \n          'colsample_bytree': 0.5,\n          'alpha':0,\n          'random_state': 42, \n          'silent': True}\n    \n    tr_data = xgb.DMatrix(train_x, train_y)\n    va_data = xgb.DMatrix(valid_x, valid_y)\n    \n    watchlist = [(tr_data, 'train'), (va_data, 'valid')]\n    model_xgb = xgb.train(params, tr_data, 2000, watchlist, maximize=False, early_stopping_rounds = 10, verbose_eval=100)\n    \n    dtest = xgb.DMatrix(test_x)\n    xgb_pred_y = np.expm1(model_xgb.predict(dtest, ntree_limit=model_xgb.best_ntree_limit))\n    \n    return xgb_pred_y, model_xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f20bde44951520a714d4ba06439a750e9ceaef85"},"cell_type":"code","source":"# step 2) Training XGB\npred_test_xgb, model_xgb = run_xgb(x_train, y_train, x_valid, y_valid, X_test)\nprint(\"XGB Training Completed...\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58df1b8ef2ca34dbf5b4ad4d99118bc7fff31bf3"},"cell_type":"markdown","source":"# combine prediction and submit a file"},{"metadata":{"trusted":true,"_uuid":"6196d49137c32d85833d6111df4aa3bb4c19402a"},"cell_type":"code","source":"# combine the predictions from two above models and submit it to Kaggle competition\nsub = pd.read_csv('../input/sample_submission.csv')\n\nsub_lgb = pd.DataFrame()\nsub_lgb[\"target\"] = pred_test\n#sub_lgb\n\nsub_xgb = pd.DataFrame()\nsub_xgb[\"target\"] = pred_test_xgb\n#sub_xgb\n\nsub[\"target\"] = (sub_lgb[\"target\"] + sub_xgb[\"target\"])/2\n\nprint(sub.head())\nsub.to_csv('sub_lgb_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"762db8c0e56ded4b8067038a96ca87362c888e89"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"c713173b48e86da3962eeef1114b8be06332e4a3"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}