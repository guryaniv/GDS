{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import Dense, Dropout, LeakyReLU\nfrom tensorflow.keras.initializers import TruncatedNormal, RandomUniform\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"383c362ba810081ada1c1ddfd3507b7a72b8dc5d"},"cell_type":"code","source":"seed = 4\ndef reset_seed(s=seed):\n    np.random.seed(s)\n    tf.set_random_seed(s)\nreset_seed()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65252d4ba3af06fa35fc8688772dfef7cfb228e6","scrolled":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', index_col='ID_code')\ntest = pd.read_csv('../input/test.csv', index_col='ID_code')\n\ntarget = train[['target']]\ntrain.drop('target', axis=1, inplace=True)\n\nfeats = train.columns\n\ndisplay(train.head())\ndisplay(test.head())\ndisplay(target.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e517f1a4348d3aa2183bc2065aa1e3c7c0a18f5c"},"cell_type":"code","source":"trn = {'x': train, 'y': target}\ntst = {'x': test}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba1a5d170c40af82187fca4c985b66cd79c2fce5"},"cell_type":"code","source":"scaler = StandardScaler()\ntrn['x'] = scaler.fit_transform(trn['x'])\ntst['x'] = scaler.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb297ab4d3bececa1550e7f37f9baa9198a6465"},"cell_type":"code","source":"def roc_auc_score_wrapper(y_true, y_pred):\n    check = np.sum(y_true)\n    if check == 0 or check == len(y_true):\n        return 0.5\n    return roc_auc_score(y_true, y_pred)\n\ndef auc(y_true, y_pred):\n    return tf.py_func(roc_auc_score_wrapper, (y_true, y_pred), tf.double)\n\n# def auc(y_true, y_pred):\n#     return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"def get_model():\n    model = tf.keras.Sequential([\n        Dense(200, kernel_initializer=RandomUniform(seed=seed), activation=LeakyReLU(), input_dim=len(feats)),\n        Dropout(0.5),\n        Dense(150, kernel_initializer=RandomUniform(seed=seed), activation=LeakyReLU()),\n        Dropout(0.5),\n        Dense(100, kernel_initializer=RandomUniform(seed=seed), activation=LeakyReLU()),\n        Dropout(0.5),\n        Dense(50, kernel_initializer=RandomUniform(seed=seed), activation=LeakyReLU()),\n        Dropout(0.5),\n        Dense(1, kernel_initializer=RandomUniform(seed=seed), activation='sigmoid')\n    ])\n\n    opt = tf.keras.optimizers.SGD(lr=0.01)\n    model.compile(optimizer=opt, \n                  loss='binary_crossentropy',\n                  metrics=[\"accuracy\", auc])\n    \n    params = {\n        'epochs': 50, \n        'batch_size': 128, \n        'class_weight': compute_class_weight('balanced', np.unique(target.values), target.values[:,0])\n    }\n    \n    return model, params\n\nm, params = get_model()\nm.summary()\nfor k in params:\n    print(k, ': ', params[k])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"0b481ea8da295c306a4c29924dd05fafb32bff02"},"cell_type":"code","source":"reset_seed()\n\nclf, params = get_model()\nhistory = clf.fit(\n    trn['x'], trn['y'],\n    **params\n).history\n\npred = clf.predict(tst['x'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cf9267767ff28d1ad5ffd4d5f5eb97cbf59de24"},"cell_type":"code","source":"sns.set()\nplt.figure(figsize=(25, 8))\nmetrics = ['auc', 'acc', 'loss']\nfor i in range(len(metrics)):\n    m = metrics[i]\n    epochs = np.array(range(len(history[m])))\n\n    plt.subplot(1,len(metrics),i+1)\n    plt.title(metrics[i])\n\n    sns.lineplot(epochs, history[m], label='Train')\n\n    plt.xticks(list(epochs[::5]) + [epochs[-1]+1])\n    #plt.yticks(np.arange(0,1.0001,0.1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7b0725cfc68a93f10f171b190657bf5652c8338"},"cell_type":"code","source":"df = pd.DataFrame({'ID_code': test.index, 'target': pred[:,0]})\ndf.to_csv('submission.csv', index=False)\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}