{"cells": [{"metadata": {"_uuid": "3e8951a23f8b07332479bd6219dbf3203a2d6cd6", "_cell_guid": "c2a0c7d9-3dda-4418-b264-afed440621e3"}, "cell_type": "markdown", "source": ["# Import common APIs for ML/DL"]}, {"metadata": {"_uuid": "141a56039542d497e59f7dadd73f50a15850798d", "_cell_guid": "b358b873-9b33-41f7-9a3e-ada3684d5e04", "collapsed": true}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\\\n", "    ,fbeta_score,classification_report,confusion_matrix,precision_recall_curve,roc_auc_score\\\n", "    ,roc_curve"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "32655b9433324617c3c9991d1246939d661ee837", "_cell_guid": "95e6369e-dfb4-4027-bd19-7564fafed3c9"}, "cell_type": "markdown", "source": ["# Data preprocessing"]}, {"metadata": {"_uuid": "14ec7aa1afd0b5c44a2ed4d509d2e6f1ee2c1f0a", "_cell_guid": "e3d92d5c-833c-4f60-8b35-5224ef3a1bc4", "collapsed": true}, "source": ["df_full = pd.read_csv('../input/creditcard.csv')\n", "df_full.head()"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "d8deeefb280446db38a866109ec605b5861f9724", "_cell_guid": "0f0dc7a6-c0db-42f0-8e24-fba0724513bc"}, "cell_type": "markdown", "source": ["The features are mostly the results of PCA, and the numbers are very easy to process. I don't think the time really matters so I will drop that column later."]}, {"metadata": {"_uuid": "db1a53796286fc1249e13493498b29c918fe242f", "_cell_guid": "defc8a6e-fe8b-450a-b0fe-baa546f4fa6d", "collapsed": true}, "source": ["df_full.Class.value_counts() ##\u53ef\u4ee5\u770b\u5230positive\u6bd4\u4f8b\u8d85\u7d1a\u4f4e\u7d04\u83ab0.2%\uff0c\u76f4\u63a5\u8dd1DL\u6703\u6709\u5075\u6e2c\u4e0d\u5230positive\u5168\u90e8\u731cnegative\u7684\u5371\u96aa"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "b9e87278cd40848e87ccd37b706cd2d48157b969", "_cell_guid": "31bff80d-fe39-4f1d-a7ed-414e892b2a10"}, "cell_type": "markdown", "source": ["The positive(fraud:1) samples are rare in our datasets. So later we would do stratified sampling to avoid the result that the model gave 0 all the time."]}, {"metadata": {"_uuid": "5aa8ba64ae9a149bf54f62fdf78854738cfd5f41", "_cell_guid": "3e206e01-3f8a-47f7-a279-42567c0454ba", "collapsed": true}, "source": ["df_full.sort_values(by='Class', ascending=False, inplace=True) #easier for stratified sampling\n", "df_full.drop('Time', axis=1,  inplace = True)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "b6022e84615dc8b98d872acc2cdd4a45eabfecfe", "_cell_guid": "2bd7777a-559a-4e4b-81ca-ec74517a4693", "collapsed": true}, "source": ["df_full.head()"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "b1730fe48a333bc9b957e1782e338153e74ce52d", "_cell_guid": "c8ee16d1-ade1-4832-9151-f5c03a91d6b5"}, "cell_type": "markdown", "source": ["## Stratified Sampling: balance the ratio of label 0 and 1 datasets"]}, {"metadata": {"_uuid": "e1b9158a44f39a3ecb5e11ac4d6df71fa90d6b23", "_cell_guid": "2a2cc118-4ede-48fe-a71a-f70a085a40be", "collapsed": true}, "source": ["df_sample = df_full.iloc[:3000,:]\n", "df_sample.Class.value_counts()"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "f1ab600f0670799ce777d57336d7b5f62300844d", "_cell_guid": "5bc99880-2f57-47c5-9b6d-b15af6ca7708", "collapsed": true}, "source": ["feature = np.array(df_sample.values[:,0:29])\n", "label = np.array(df_sample.values[:,-1])"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "a7b80145585e7fd18d8fadf982cb5096eee930c3", "_cell_guid": "bb80f164-75fb-4c96-b1c4-bfb8145283ad"}, "cell_type": "markdown", "source": ["## Shuffle and split the data into train and test sets"]}, {"metadata": {"_uuid": "9f1e0ed3f666e2ce5940a85bfbac8c014da94468", "_cell_guid": "e858f592-43aa-4bb6-8757-816d39cbd571", "collapsed": true}, "source": ["from sklearn.utils import shuffle\n", "\n", "shuffle_df = shuffle(df_sample, random_state=42)\n", "\n", "df_train = shuffle_df[0:2400]\n", "df_test = shuffle_df[2400:]"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "2696322163cdf46c850ccffc151ce3feea0196fc", "_cell_guid": "d40b2fc2-3804-4143-888c-a75100e8f009", "collapsed": true}, "source": ["train_feature = np.array(df_train.values[:,0:29])\n", "train_label = np.array(df_train.values[:,-1])\n", "test_feature = np.array(df_test.values[:,0:29])\n", "test_label = np.array(df_test.values[:,-1])"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "04a22be190cab363e11a60224cb46084d29aab4a", "_cell_guid": "1abb72b5-8fcf-4887-afeb-f362e19f2d0a", "collapsed": true}, "source": ["train_feature.shape"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "197f6e1ca83116a6ec5c773d3d852b081d92e3d9", "_cell_guid": "c4b7935f-4675-4265-b3a6-32590199ee93", "collapsed": true}, "source": ["train_label.shape"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "7f0000ae56dd34138d68a6d3125a5784b1035ea1", "_cell_guid": "0dc93c0e-8842-4eff-a674-e4914a515146"}, "cell_type": "markdown", "source": ["## Standardize the features for speeding up deep learning (MinMaxScaler)"]}, {"metadata": {"_uuid": "0b295111b5549796bdcfc326b790ef5a93a60657", "_cell_guid": "f8e6dc78-50b6-4089-8899-e7f3e9e007df", "collapsed": true}, "source": ["from sklearn.preprocessing import MinMaxScaler\n", "\n", "scaler = MinMaxScaler()\n", "\n", "scaler.fit(train_feature)\n", "train_feature_trans = scaler.transform(train_feature)\n", "test_feature_trans = scaler.transform(test_feature)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "4c45b1e8df70477c73342234d06122171c11e4df", "_cell_guid": "0759120a-925f-4a6e-a758-be6f0e04b28a"}, "cell_type": "markdown", "source": ["# Run the deep learning model: using keras MLP"]}, {"metadata": {"_uuid": "41c22028b6d174d0c8f92464aad2eb5a5da9f4a8", "_cell_guid": "3f410ebe-9565-4a28-b96f-56a6bd1b1430", "collapsed": true}, "source": ["######################### \u5efa\u7acb\u6a21\u578b\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import Dropout\n", "\n", "import matplotlib.pyplot as plt \n", "def show_train_history(train_history,train,validation):\n", "    plt.plot(train_history.history[train])\n", "    plt.plot(train_history.history[validation])\n", "    plt.title('Train History')\n", "    plt.ylabel(train)\n", "    plt.xlabel('Epoch')\n", "    plt.legend(['train', 'validation'], loc='best')\n", "    plt.show()\n", "\n", "model = Sequential() #\u4e00\u5c64\u4e00\u5c64\u5230\u5e95\uff0c\u6309\u9806\u5e8f\n", "\n", "#\u8f38\u5165\u5c64\uff08\u96b1\u85cf\u5c641\uff09\n", "model.add(Dense(units=200, \n", "                input_dim=29, \n", "                kernel_initializer='uniform', \n", "                activation='relu'))\n", "model.add(Dropout(0.5))\n", "\n", "#\u96b1\u85cf\u5c642\uff0c\u4e0d\u7528\u5bebinput_dim\uff0c\u56e0\u70ba\u5c31\u662f\u524d\u4e00\u5c64\u7684units\n", "model.add(Dense(units=200,  \n", "                kernel_initializer='uniform', \n", "                activation='relu'))\n", "model.add(Dropout(0.5))\n", "\n", "#\u8f38\u51fa\u5c64\n", "model.add(Dense(units=1, #\u8f38\u51fa\u4e00\u500b\u6578\u5b57 \n", "                kernel_initializer='uniform',\n", "                activation='sigmoid'))\n", "\n", "print(model.summary()) #\u53ef\u4ee5\u6e05\u695a\u770b\u5230model\u9084\u6709\u53c3\u6578\u6578\u91cf\n", "\n", "model.compile(loss='binary_crossentropy',   #\u4e8c\u5143\u7528binary\n", "              optimizer='adam', metrics=['accuracy'])\n", "\n", "train_history = model.fit(x=train_feature_trans, y=train_label,  #\u4e0a\u9762\u591a\u5206\u5272\u4e00\u6b65\u5728keras\u662f\u5167\u5efa\u7684\n", "                          validation_split=0.8, epochs=200, \n", "                          batch_size=500, verbose=2) #verbose=2\u8868\u793a\u986f\u793a\u8a13\u7df4\u904e\u7a0b\n", "\n", "######################### \u8a13\u7df4\u904e\u7a0b\u8996\u89ba\u5316\n", "show_train_history(train_history,'acc','val_acc')\n", "show_train_history(train_history,'loss','val_loss')\n", "\n", "\n", "######################### \u5be6\u969b\u6e2c\u9a57\u5f97\u5206\n", "scores = model.evaluate(test_feature_trans, test_label)\n", "print('\\n')\n", "print('accuracy=',scores[1])\n", "\n", "######################### \u7d00\u9304\u6a21\u578b\u9810\u6e2c\u60c5\u5f62\uff08\u7b54\u6848\u5377\uff09\n", "prediction = model.predict_classes(test_feature_trans)\n", "\n", "#\u5132\u5b58\u8a13\u7df4\u7d50\u679c\n", "#model.save_weights(\"Keras_CreditCardFraud_MLP.h5\")\n", "#print('model saved to disk')"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "bd88de24edede6c4cf07a63528f562a94a7b030c", "_cell_guid": "6a86cec1-e114-4e11-9df9-8c1242a29fa5"}, "cell_type": "markdown", "source": ["# Check out test result (and see if the predictions are all 0 or not? )"]}, {"metadata": {"_uuid": "944a60861d35d7948cdf535c399e3b021269c662", "_cell_guid": "db893543-79ba-4531-bb32-64fda47cd722", "collapsed": true}, "source": ["df_ans = pd.DataFrame({'Real Class' :test_label})\n", "df_ans['Prediction'] = prediction"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "8478394fd68b386c41e420f3db9ad6608cc85768", "_cell_guid": "177da773-2f8b-4183-b15d-e1e40433423d", "collapsed": true}, "source": ["df_ans[ df_ans['Real Class'] != df_ans['Prediction'] ]"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "a79ec09fd63fc9baab601e9f9aba2d37de119c18", "_cell_guid": "e7399876-26b5-4c66-b804-31f408d36727", "collapsed": true}, "source": ["df_ans['Prediction'].value_counts() #\u5206\u5c64\u4e4b\u5f8c\uff0c0\u548c1\u53c3\u534a\uff0c\u662f\u597d\u73fe\u8c61"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "22db6165fe7ddac0d516178948b58d6c1bb3be52", "_cell_guid": "505a8296-0af8-4cdd-96e1-769cbf82b4a5", "collapsed": true}, "source": ["df_ans['Real Class'].value_counts()"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "4f5a68aad0652e247240614aa091b9464241ac33", "_cell_guid": "cf24dae7-ea76-42d4-984c-09fa9d12ca36", "collapsed": true}, "source": ["import seaborn as sns\n", "%matplotlib inline\n", "\n", "cols = ['Real_Class_1','Real_Class_0']  #Gold standard\n", "rows = ['Prediction_1','Prediction_0'] #diagnostic tool (our prediction)\n", "\n", "B1P1 = len(df_ans[(df_ans['Prediction'] == df_ans['Real Class']) & (df_ans['Real Class'] == 1)])\n", "B1P0 = len(df_ans[(df_ans['Prediction'] != df_ans['Real Class']) & (df_ans['Real Class'] == 1)])\n", "B0P1 = len(df_ans[(df_ans['Prediction'] != df_ans['Real Class']) & (df_ans['Real Class'] == 0)])\n", "B0P0 = len(df_ans[(df_ans['Prediction'] == df_ans['Real Class']) & (df_ans['Real Class'] == 0)])\n", "\n", "conf = np.array([[B1P1,B0P1],[B1P0,B0P0]])\n", "df_cm = pd.DataFrame(conf, columns = [i for i in cols], index = [i for i in rows])\n", "\n", "f, ax= plt.subplots(figsize = (5, 5))\n", "sns.heatmap(df_cm, annot=True, ax=ax, fmt='d') \n", "ax.xaxis.set_ticks_position('top') #Making x label be on top is common in textbooks.\n", "\n", "print('total test case number: ', np.sum(conf))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "3bd53dcd257f17c911bc3a1889b580d8fe9b323a", "_cell_guid": "71568ea4-f5cb-4f63-a624-4d0fdb41204a", "collapsed": true}, "source": ["def model_efficacy(conf):\n", "    total_num = np.sum(conf)\n", "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n", "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n", "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n", "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n", "    \n", "    print('total_num: ',total_num)\n", "    print('G1P1: ',conf[0][0]) #G = gold standard; P = prediction\n", "    print('G0P1: ',conf[0][1])\n", "    print('G1P0: ',conf[1][0])\n", "    print('G0P0: ',conf[1][1])\n", "    print('##########################')\n", "    print('sensitivity: ',sen)\n", "    print('specificity: ',spe)\n", "    print('false_positive_rate: ',false_positive_rate)\n", "    print('false_negative_rate: ',false_negative_rate)\n", "    \n", "    return total_num, sen, spe, false_positive_rate, false_negative_rate\n", "\n", "model_efficacy(conf)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "de3acdc4f62579414210f7c613344fdbe203e343", "_cell_guid": "5a0976ba-5681-4c08-b778-a76837f36d80"}, "cell_type": "markdown", "source": ["# Exam generalization ability with whole data (lots of 0 label data)"]}, {"metadata": {"_uuid": "1b2f392794d861854afb516a1b2da205a5f64099", "_cell_guid": "d1ee5d73-9456-4a04-9bce-214f2542a82e", "collapsed": true}, "source": ["df_sample2 = df_full.iloc[:,:] #\u7531\u65bc\u90fd\u662flabel=0\uff0c\u5c31\u4e0dshuffle\u4e86\n", "\n", "feature2 = np.array(df_sample2.values[:,0:29])\n", "label2 = np.array(df_sample2.values[:,-1])\n", "\n", "feature2_trans = scaler.transform(feature2) #using the same scaler as above\n", "\n", "######################### \u5be6\u969b\u6e2c\u9a57\u5f97\u5206\n", "scores = model.evaluate(feature2_trans, label2)\n", "print('\\n')\n", "print('accuracy=',scores[1])\n", "\n", "######################### \u7d00\u9304\u6a21\u578b\u9810\u6e2c\u60c5\u5f62\uff08\u7b54\u6848\u5377\uff09\n", "prediction2 = model.predict_classes(feature2_trans)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "0efecce83fcd1c6f5bdbbb0ec587106fd3d2109b", "_cell_guid": "49d146f7-73fc-4bdb-9e62-2b380bc6c53e", "collapsed": true}, "source": ["prediction2_list = prediction2.reshape(-1).astype(int)\n", "label2_list = label2.astype(int)\n", "\n", "print(classification_report(label2_list, prediction2_list))\n", "print(confusion_matrix(label2_list, prediction2_list))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "090f830d0c896bf548381c62f23340a1aaf42acc", "_cell_guid": "8139632e-ce17-4825-a627-48ed94e45bfd", "collapsed": true}, "source": ["conf = confusion_matrix(label2_list, prediction2_list)\n", "f, ax= plt.subplots(figsize = (5, 5))\n", "sns.heatmap(conf, annot=True, ax=ax, fmt='d') \n", "ax.xaxis.set_ticks_position('top') #Making x label be on top is common in textbooks."], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "0d8ea075d36a13e612c2df8a5a310f1d268657c2", "_cell_guid": "2a7331ef-9f7f-419a-8fc0-ff1ed8d832ef", "collapsed": true}, "source": ["def model_efficacy(conf):\n", "    total_num = np.sum(conf)\n", "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n", "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n", "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n", "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n", "    \n", "    print('total_num: ',total_num)\n", "    print('G1P1: ',conf[0][0]) #G = gold standard; P = prediction\n", "    print('G0P1: ',conf[0][1])\n", "    print('G1P0: ',conf[1][0])\n", "    print('G0P0: ',conf[1][1])\n", "    print('##########################')\n", "    print('sensitivity: ',sen)\n", "    print('specificity: ',spe)\n", "    print('false_positive_rate: ',false_positive_rate)\n", "    print('false_negative_rate: ',false_negative_rate)\n", "    \n", "    return total_num, sen, spe, false_positive_rate, false_negative_rate\n", "\n", "model_efficacy(conf)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "c6e806ac210310a3389ec58f2d7497b0cc27bfc3", "_cell_guid": "808b8490-e834-4a4a-aa55-e781ae9901db"}, "cell_type": "markdown", "source": ["# Conclusion"]}, {"metadata": {"_uuid": "0c0478af168471fc6261583d3a3428471ab930ee", "_cell_guid": "eadcc396-45a3-4b56-9351-0a28e6737bc5"}, "cell_type": "markdown", "source": ["Total number of the data is about 285,000 / Fraud data: 492 / Prediction of fraud data: 3500 <br/>\n", "We can detect about 7 times of true fraud data as fraud candidates, and leave other 98.7% of normal data. <br/>\n", "It's a very easy model and the result is acceptable(false positive rate didn't go wild high). <br/>\n", "The false positive rate maybe lowered by more complicated model.<br/>\n", "Stratified sampling is the most important step for learning the model in this case.<br/>"]}, {"metadata": {"_uuid": "aa78a864df2d9ab18f2657662873b8a084cea0ec", "_cell_guid": "f7567bc0-4ec2-41a8-afac-a062d18dcf2c"}, "cell_type": "markdown", "source": ["# Try ensemble models, however, the results aren't good as MLP"]}, {"metadata": {"_uuid": "6390bcbeb50289161d01cd04f2637b5fa7c32e35", "_cell_guid": "11dab93d-1fe0-457c-bb1f-13ecd03403c7", "collapsed": true}, "source": ["df_sample2 = df_full.iloc[:,:] #\u7531\u65bc\u90fd\u662flabel=0\uff0c\u5c31\u4e0dshuffle\u4e86\n", "\n", "feature2 = np.array(df_sample2.values[:,0:29])\n", "label2 = np.array(df_sample2.values[:,-1])\n", "\n", "feature2_trans = scaler.transform(feature2)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "8ef906bb773b73e296a44d03fa2032a6f6fe3962", "_cell_guid": "f4b80db1-497f-4ae9-9ca1-2cc420fd2ddb"}, "cell_type": "markdown", "source": ["## AdaBoostClassifier"]}, {"metadata": {"_uuid": "7bd308e3f715721b7a489177880e2a828ad3c708", "_cell_guid": "91ff8f36-770b-4010-b05d-2a5534b2abc2", "collapsed": true}, "source": ["from sklearn import datasets,cross_validation,ensemble\n", "\n", "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n", "                                              test_size=0.25, random_state=0,stratify=train_label)\n", "clf=ensemble.AdaBoostClassifier()\n", "clf.fit(X_train,y_train)\n", "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n", "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "048d557419c127d17c2a26ff01a2298a9b8bdf42", "_cell_guid": "f49d2822-258f-4c46-8c79-4132656d8f18", "collapsed": true}, "source": ["print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "ca07ba0b245cc8b356d2181f37fb881e881def80", "_cell_guid": "36eaae86-4c15-4a09-ad64-7be72c858d27", "collapsed": true}, "source": ["prediction2 = clf.predict(feature2_trans)\n", "prediction2_list = prediction2.reshape(-1).astype(int)\n", "label2_list = label2.astype(int)\n", "\n", "print(classification_report(label2_list, prediction2_list))\n", "print(confusion_matrix(label2_list, prediction2_list))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "26fcb8d9dee60bfac1c268845143babd9daceb3c", "_cell_guid": "d26fb039-c53b-4862-a6eb-9791bb0ef75d", "collapsed": true}, "source": ["def model_efficacy(conf):\n", "    total_num = np.sum(conf)\n", "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n", "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n", "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n", "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n", "    \n", "    print('total_num: ',total_num)\n", "    print('G1P1: ',conf[0][0]) #G = gold standard; P = prediction\n", "    print('G0P1: ',conf[0][1])\n", "    print('G1P0: ',conf[1][0])\n", "    print('G0P0: ',conf[1][1])\n", "    print('##########################')\n", "    print('sensitivity: ',sen)\n", "    print('specificity: ',spe)\n", "    print('false_positive_rate: ',false_positive_rate)\n", "    print('false_negative_rate: ',false_negative_rate)\n", "    \n", "    return total_num, sen, spe, false_positive_rate, false_negative_rate\n", "\n", "conf = confusion_matrix(label2_list, prediction2_list)\n", "model_efficacy(conf)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "8d639c31cb6d68df705bb9c708663bf23611db01", "_cell_guid": "bff2f8e0-eb81-48a8-b27f-0981fc80bde2"}, "cell_type": "markdown", "source": ["## GradientBoostingClassifier"]}, {"metadata": {"_uuid": "5285b4911a2b695f09a13e40636b2ff8c5b44253", "_cell_guid": "c58c61b0-a822-4007-9d74-bc75af3ce51e", "collapsed": true}, "source": ["from sklearn import datasets,cross_validation,ensemble\n", "\n", "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n", "                                              test_size=0.25, random_state=0,stratify=train_label)\n", "clf=ensemble.GradientBoostingClassifier()\n", "clf.fit(X_train,y_train)\n", "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n", "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "215f5278d1130478991aba1c815c522cb9fa11a6", "_cell_guid": "bb08faf2-5502-4050-b52f-bc6f12ad14b7", "collapsed": true}, "source": ["print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "cf421a74ecbcac642556b142857ad92677bf841c", "_cell_guid": "04fd3d6a-d60d-4ee7-9e32-819e0c4dea34", "collapsed": true}, "source": ["prediction2 = clf.predict(feature2_trans)\n", "prediction2_list = prediction2.reshape(-1).astype(int)\n", "label2_list = label2.astype(int)\n", "\n", "print(classification_report(label2_list, prediction2_list))\n", "print(confusion_matrix(label2_list, prediction2_list))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "77a6bb4a584d6cbb76461e429b1e652b384e6675", "_cell_guid": "aa0f3fda-06f4-4518-bc28-22820936c51d", "collapsed": true}, "source": ["def model_efficacy(conf):\n", "    total_num = np.sum(conf)\n", "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n", "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n", "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n", "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n", "    \n", "    print('total_num: ',total_num)\n", "    print('G1P1: ',conf[0][0]) #G = gold standard; P = prediction\n", "    print('G0P1: ',conf[0][1])\n", "    print('G1P0: ',conf[1][0])\n", "    print('G0P0: ',conf[1][1])\n", "    print('##########################')\n", "    print('sensitivity: ',sen)\n", "    print('specificity: ',spe)\n", "    print('false_positive_rate: ',false_positive_rate)\n", "    print('false_negative_rate: ',false_negative_rate)\n", "    \n", "    return total_num, sen, spe, false_positive_rate, false_negative_rate\n", "\n", "conf = confusion_matrix(label2_list, prediction2_list)\n", "model_efficacy(conf)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "6c894b50315d305e1448f65e1a6770e7b035bfd1", "_cell_guid": "ebbed932-82b0-4206-86e5-5d25c8dd92ad"}, "cell_type": "markdown", "source": ["## RandomForestClassifier"]}, {"metadata": {"_uuid": "855147a72b7a4a62cc60de3a01cb890ffa14dc67", "_cell_guid": "fcda96cc-0ae0-46a7-a3cc-c90ffedd4c1a", "collapsed": true}, "source": ["from sklearn import datasets,cross_validation,ensemble\n", "\n", "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n", "                                              test_size=0.25, random_state=0,stratify=train_label)\n", "clf=ensemble.RandomForestClassifier()\n", "clf.fit(X_train,y_train)\n", "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n", "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "18667040daf581c45c7ef6caff808779c2c13117", "_cell_guid": "fd110371-ea45-409d-8217-69a7f7cbd45a", "collapsed": true}, "source": ["print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "269b1f3b89e60179f0c1379614a6e14e29055e9f", "_cell_guid": "0b287e2e-5e41-48f8-a312-caf3d6c4def5", "collapsed": true}, "source": ["prediction2 = clf.predict(feature2_trans)\n", "prediction2_list = prediction2.reshape(-1).astype(int)\n", "label2_list = label2.astype(int)\n", "\n", "print(classification_report(label2_list, prediction2_list))\n", "print(confusion_matrix(label2_list, prediction2_list))"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "83f1ce9423360aebae1cda4f906880096972e609", "_cell_guid": "f7d7fe32-2386-4b3d-a017-fe91a1dfb03d", "collapsed": true}, "source": ["def model_efficacy(conf):\n", "    total_num = np.sum(conf)\n", "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n", "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n", "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n", "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n", "    \n", "    print('total_num: ',total_num)\n", "    print('G1P1: ',conf[0][0]) #G = gold standard; P = prediction\n", "    print('G0P1: ',conf[0][1])\n", "    print('G1P0: ',conf[1][0])\n", "    print('G0P0: ',conf[1][1])\n", "    print('##########################')\n", "    print('sensitivity: ',sen)\n", "    print('specificity: ',spe)\n", "    print('false_positive_rate: ',false_positive_rate)\n", "    print('false_negative_rate: ',false_negative_rate)\n", "    \n", "    return total_num, sen, spe, false_positive_rate, false_negative_rate\n", "\n", "conf = confusion_matrix(label2_list, prediction2_list)\n", "model_efficacy(conf)"], "cell_type": "code", "outputs": [], "execution_count": null}, {"metadata": {"_uuid": "6babc79458eb409d018e282d5fce0e14f756c2cc", "_cell_guid": "28e2e208-7690-4d5a-b674-0d5aa5f40a96", "collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}], "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}