{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6f9b6ac6-3f48-f963-75df-21d037e13bd6"
      },
      "source": [
        "A first try(for me) at stacking, with scikit and xgb. seems to be working well enough! \n",
        "\n",
        "let me know the thoughts!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f37a5a61-e1e0-a3d6-57d0-7f6dd7ac9487"
      },
      "outputs": [],
      "source": [
        "import os,sys,time,random,math,time\n",
        "import tarfile, zipfile\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.cross_validation import train_test_split, StratifiedShuffleSplit\n",
        "from sklearn.linear_model import LinearRegression,Ridge\n",
        "\n",
        "from sklearn import decomposition, datasets, ensemble\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, average_precision_score, accuracy_score, mean_absolute_error\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "datadir=\"../input/\"\n",
        "print(check_output([\"ls\", datadir]).decode(\"utf8\"))\n",
        "\n",
        "%matplotlib inline  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8cd6160-54d7-8cba-99f1-da89842d2912"
      },
      "outputs": [],
      "source": [
        "def loadData(datadir,filename):\n",
        "    # Load the wholesale customers dataset\n",
        "    #data = pd.read_csv(filename)\n",
        "    data = ''\n",
        "    print (\"loading: \"+datadir+filename)\n",
        "    try:\n",
        "        if zipfile.is_zipfile(datadir+filename):\n",
        "            z = zipfile.ZipFile(datadir+filename)\n",
        "            filename = z.open(filename[:-4])\n",
        "        else:\n",
        "            filename=datadir+filename\n",
        "        data = pd.read_csv(filename, parse_dates=True)  \n",
        "        print (\"Dataset has {} samples with {} features each.\".format(*data.shape))\n",
        "    except Exception as e:\n",
        "        print (\"Dataset could not be loaded. Is the dataset missing?\")\n",
        "        print(e)\n",
        "    return data\n",
        "\n",
        "def writeData(data,filename):\n",
        "    # Load the wholesale customers dataset\n",
        "    try:\n",
        "        data.to_csv(filename, index=False)\n",
        "    except Exception as e:\n",
        "        print (\"Dataset could not be written.\")\n",
        "        print(e)\n",
        "    verify=[]\n",
        "    try:\n",
        "        with open(filename, 'r') as f:\n",
        "            for line in f:\n",
        "                verify.append(line)\n",
        "        f.closed\n",
        "        return verify[:5]\n",
        "    except IOError:\n",
        "        sys.std\n",
        "        \n",
        "def LabelEncoder(data):\n",
        "    # lifted in parts from:\n",
        "    #https://www.kaggle.com/mmueller/allstate-claims-severity/yet-another-xgb-starter/code\n",
        "    features = data.columns\n",
        "    cats = [feat for feat in features if 'cat' in feat]\n",
        "    for feat in cats:\n",
        "        data[feat] = pd.factorize(data[feat], sort=True)[0]\n",
        "    return data\n",
        "\n",
        "# XGB!\n",
        "\n",
        "def xgbfit(X_train,y_train):\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    \n",
        "\n",
        "    xgb_params = {\n",
        "        'seed': 0,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'silent': 1,\n",
        "        'subsample': 0.7,\n",
        "        'learning_rate': 0.075,\n",
        "        'objective': 'reg:linear',\n",
        "        'max_depth': 6,\n",
        "        'num_parallel_tree': 1,\n",
        "        'min_child_weight': 1,\n",
        "        'eval_metric': 'mae',\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "    res = xgb.cv(xgb_params, dtrain, num_boost_round=750, nfold=4, seed=42, stratified=False,\n",
        "                 early_stopping_rounds=15, verbose_eval=100, show_stdv=True, maximize=False)\n",
        "    print(\"fit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "\n",
        "    best_nrounds = res.shape[0] - 1\n",
        "    cv_mean = res.iloc[-1, 0]\n",
        "    cv_std = res.iloc[-1, 1]\n",
        "    print('CV-Mean: {0}+{1}'.format(cv_mean, cv_std))\n",
        "    # XGB Train!\n",
        "    start_time = time.time()\n",
        "    gbdt = xgb.train(xgb_params, dtrain, best_nrounds)\n",
        "    print(\"Train time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "    return gbdt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "97e0a37a-bc6d-3211-3fbc-3be69f1ad7ca"
      },
      "outputs": [],
      "source": [
        "data = loadData(datadir,'train.csv')\n",
        "display(data.info())\n",
        "display(data.head(5))\n",
        "\n",
        "test_data= loadData(datadir,'test.csv') \n",
        "display(test_data.info())\n",
        "display(test_data.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7aff6688-a717-2fa5-62ed-6d23cc7e039e"
      },
      "source": [
        "Pre-proccessing\n",
        "---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad62fb7f-9860-e268-2761-21a3eea9dc1e"
      },
      "outputs": [],
      "source": [
        "# combine the two frames so we can encode the labels!\n",
        "test_data['loss']=0\n",
        "\n",
        "lengthofData=len(data)\n",
        "lengthoftest_data=len(test_data)\n",
        "\n",
        "print(\"data:\",lengthofData)\n",
        "print(\"test:\",lengthoftest_data)\n",
        "\n",
        "combineddata=pd.concat([data,test_data])\n",
        "lengthofcombined=len(combineddata)\n",
        "print(\"combined:\",lengthofcombined)\n",
        "\n",
        "# the categorical data that we need in a number format\n",
        "combineddata=LabelEncoder(combineddata)\n",
        "\n",
        "# time to split the data back apart!\n",
        "data=combineddata.iloc[:lengthofData].copy()\n",
        "test_data=combineddata.iloc[lengthofData:].copy()\n",
        "test_data.drop(['loss'],1,inplace=True) # didn't have this column before, make it go away!\n",
        "\n",
        "\n",
        "x_test = test_data.copy()\n",
        "x_test.drop(['id'],1,inplace=True)\n",
        "\n",
        "# we don't want the ID columns in X, and of course not loss either\n",
        "x=data.drop(['id','loss'],1)\n",
        "# loss is our label\n",
        "y=data['loss']\n",
        "\n",
        "#minmax scaler\n",
        "scaler= MinMaxScaler() \n",
        "x = scaler.fit_transform(x)\n",
        "x_test_data = scaler.fit_transform(x_test)\n",
        "\n",
        "#display(x[:5])\n",
        "#display(y.head(5))\n",
        "\n",
        "print(\"Pre-Processing done\")\n",
        "print(\"data:\",len(x))\n",
        "print(\"labels:\",len(y))\n",
        "print(\"test:\",len(x_test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e1ec6bf-6afb-8a5f-40fe-72d9a1adea13"
      },
      "source": [
        "Stacking, Layer 1\n",
        "-----------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e57821a8-7d7c-961c-c70c-9f984c1ce56d"
      },
      "outputs": [],
      "source": [
        "# OK let's actually do some ML\n",
        "regrList=[] # a list of regressions to use\n",
        "#regrList.append(LinearRegression())\n",
        "regrList.append(ExtraTreesRegressor())\n",
        "regrList.append(Ridge())\n",
        "    \n",
        "regrList.append(RandomForestRegressor(n_estimators=10,\n",
        "                                      #criterion = 'mae',\n",
        "                                      n_jobs =-1, \n",
        "                                      random_state=42))\n",
        "print(\"number of scikitlearn regressors to use:\",len(regrList))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6e5d5b8-96d9-54c9-dfa0-8fe9a65a82f0"
      },
      "source": [
        "Split the data into k-folds(divisions). train the regressors on each combination of k-1 folds, and then predict on the held-out fold. Preserve the prediction of each regressor for the next layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "41847d2c-c981-92f3-2059-0d1894f1decc"
      },
      "outputs": [],
      "source": [
        "#prepare the fold divisions\n",
        "\n",
        "data_size=x.shape[0]\n",
        "print(\"size of train data:\",data_size)\n",
        "folds=[]\n",
        "num_folds=5\n",
        "fold_start=0\n",
        "for k in range(num_folds-1):\n",
        "    fold_end=int(((data_size/num_folds)*(k+1)))\n",
        "    folds.append((fold_start,fold_end))\n",
        "    fold_start=fold_end\n",
        "folds.append((fold_start,data_size))\n",
        "print(\"folds at:\",folds)\n",
        "print(\"fold size:\", (data_size/num_folds))\n",
        "print(\"train size:\",(data_size/num_folds)*(num_folds-1))\n",
        "\n",
        "count=0\n",
        "for i in folds:\n",
        "    count+=i[1]-i[0]\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09d3809c-6b74-ec93-e485-c72611a990cc"
      },
      "outputs": [],
      "source": [
        "x_layer2=[]\n",
        "start_time0 = time.time()\n",
        "\n",
        "for fold_start,fold_end in folds:\n",
        "    print(\"Fold:\",fold_start,\"to\",fold_end,\"of\",data_size)\n",
        "    start_time1 = time.time()\n",
        "    fold_result=[]\n",
        "    \n",
        "    X_test = x[fold_start:fold_end].copy()\n",
        "    y_test = y[fold_start:fold_end].copy()\n",
        "    X_train=np.concatenate((x[:fold_start], x[fold_end:]), axis=0)\n",
        "    y_train=np.concatenate((y[:fold_start], y[fold_end:]), axis=0)\n",
        "    print(\"\\nfolding! len test {}, len train {}\".format(len(X_test),len(X_train)))\n",
        "    \n",
        "    for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
        "        start_time = time.time()\n",
        "        regrList[i].fit(X_train,y_train)\n",
        "        print(\"\\nfit time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "\n",
        "        start_time = time.time()\n",
        "        print(regrList[i])\n",
        "        curr_predict=regrList[i].predict(X_test)\n",
        "        if fold_result == []:\n",
        "            fold_result = np.array(curr_predict.copy())\n",
        "        else:\n",
        "            fold_result = np.column_stack((fold_result,curr_predict))\n",
        "        \n",
        "        print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "        #show some stats on that last regressions run    \n",
        "        print(\"Mean abs error: {:.2f}\".format(np.mean(abs(curr_predict - y_test))))\n",
        "        print(\"Score: {:.2f}\".format(regrList[i].score(X_test, y_test)))\n",
        "    \n",
        "    #XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
        "    #dtest = xgb.DMatrix(X_test)\n",
        "    #gbdt=xgbfit(X_train,y_train)\n",
        "\n",
        "    # now do a prediction and spit out a score(MAE) that means something\n",
        "    #start_time = time.time()\n",
        "    #curr_predict=gbdt.predict(dtest)\n",
        "    #fold_result = np.column_stack((fold_result,curr_predict))  \n",
        "    #print(\"XGB Mean abs error: {:.2f}\".format(np.mean(abs(curr_predict - y_test))))\n",
        "    #print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "    \n",
        "    if x_layer2 == []:\n",
        "        x_layer2=fold_result\n",
        "    else:\n",
        "        x_layer2=np.append(x_layer2,fold_result,axis=0)\n",
        "        \n",
        "    print(\"--layer2 length:\",len(x_layer2))\n",
        "    print(\"--layer2 shape:\",np.shape(x_layer2))\n",
        "    print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   \n",
        "print(\"Full run time:{}s\".format(round((time.time()-start_time0), 3) ))   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ebb6558b-a6a4-b08e-c513-296db5f2bd24"
      },
      "source": [
        "train layer 2\n",
        "-------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b088b0fa-2d0f-1f28-5606-eae4fe9ec08f"
      },
      "outputs": [],
      "source": [
        "print(len(x_layer2))\n",
        "print(len(y))\n",
        "\n",
        "#  train/validation split\n",
        "X_layer2_train, X_layer2_validation, y_layer2_train, y_layer2_validation = train_test_split( x_layer2,\n",
        "                                                                                y,\n",
        "                                                                                test_size=0.25,\n",
        "                                                                                random_state=42)\n",
        "layer2_regr=LinearRegression()\n",
        "\n",
        "layer2_regr.fit(X_layer2_train,y_layer2_train)\n",
        "\n",
        "layer2_predict=layer2_regr.predict(X_layer2_validation)\n",
        "\n",
        "#show some stats on that last regressions run    \n",
        "print(\"Mean abs error: {:.2f}\".format(np.mean(abs(layer2_predict - y_layer2_validation))))\n",
        "print(\"Score: {:.2f}\".format(layer2_regr.score(X_layer2_validation, y_layer2_validation)))\n",
        "\n",
        "\n",
        "#with LinearReg: Mean abs error: 1238.52"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "50eea161-66b6-a7ca-331b-f0f7b96998b6"
      },
      "outputs": [],
      "source": [
        "# The XGB version of layer 2\n",
        "print(len(x_layer2))\n",
        "print(len(y))\n",
        "\n",
        "#  train/validation split\n",
        "X_layer2_train, X_layer2_validation, y_layer2_train, y_layer2_validation = train_test_split( x_layer2,\n",
        "                                                                                y,\n",
        "                                                                                test_size=0.25,\n",
        "                                                                                random_state=42)\n",
        "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
        "dtest = xgb.DMatrix(X_layer2_validation)\n",
        "#layer2_gbdt=xgbfit(X_layer2_train,y_layer2_train)\n",
        "\n",
        "# now do a prediction and spit out a score(MAE) that means something\n",
        "start_time = time.time()\n",
        "#print(\"XGB Mean abs error: {:.2f}\".format(np.mean(abs(layer2_gbdt.predict(dtest) - y_layer2_validation))))\n",
        "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "#with LinearReg: XGB Mean abs error: 1205.77"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d68e95da-f8d3-e17a-acbf-c82d762ea286"
      },
      "source": [
        "Predict layer 1 on test\n",
        "-----------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dad5cb1c-42e3-59b6-1c0f-247b80886d4e"
      },
      "outputs": [],
      "source": [
        "x_layer2_test = []\n",
        "start_time1 = time.time()\n",
        "for i in range(len(regrList)): # for each of the regressions we use, fit/predict the data\n",
        "    start_time = time.time()\n",
        "    print(regrList[i])\n",
        "    curr_predict=regrList[i].predict(x_test_data)\n",
        "    print(\"predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "    \n",
        "    if x_layer2_test == []:\n",
        "        x_layer2_test = np.array(curr_predict.copy())\n",
        "    else:\n",
        "        x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
        "    print(curr_predict)\n",
        "\n",
        "#XGB -- it doesn't fit the pattern of scikit, so do it seperatly\n",
        "dtest = xgb.DMatrix(x_test_data)\n",
        "# now do a prediction and spit out a score(MAE) that means something\n",
        "start_time = time.time()\n",
        "#curr_predict=gbdt.predict(dtest)\n",
        "#x_layer2_test = np.column_stack((x_layer2_test,curr_predict))\n",
        "#print(\"Mean abs error: {:.2f}\".format(np.mean(abs(cache[i+1] - y_test))))\n",
        "print(\"XGB predict time:{}s\".format(round((time.time()-start_time), 3) ))\n",
        "\n",
        "print(\"Fold run time:{}s\".format(round((time.time()-start_time1), 3) ))   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5f61966-8e94-54bb-3e96-1fc76356ed2f"
      },
      "outputs": [],
      "source": [
        "# some problems noted---fact finding below!\n",
        "display(\"size of original test data:\",len(x_test_data))\n",
        "display(\"Test shape:\",np.shape(x_layer2_test))\n",
        "display(\"train shape:\",np.shape(x_layer2))\n",
        "\n",
        "print(\"sample of layer2 test:\\n\",x_layer2_test[:4])\n",
        "\n",
        "print(\"x_layer2_test mean:\",x_layer2_test.mean( axis=0))\n",
        "print(\"x_layer2 mean:\",x_layer2.mean(axis=0))\n",
        "train_layer2_col0_mean=x_layer2.mean(axis=0)[0]\n",
        "\n",
        "print(\"x_layer2_test std:\",x_layer2_test.std( axis=0)) \n",
        "print(\"x_layer2 std:\",x_layer2.std(axis=0))\n",
        "\n",
        "# notice that column 0(linregresion) has a significantly higher mean and std\n",
        "# here's a hack to not fix that for now! \n",
        "\n",
        "# check which row in column 0 are significantly far from the mean\n",
        "problem_column=x_layer2_test.T[0]\n",
        "outliers=[]\n",
        "for i in range(len(problem_column)):\n",
        "    if problem_column[i]>30000:\n",
        "        outliers.append((i,problem_column[i]))\n",
        "print(\"num outliers:\",len(outliers))\n",
        "\n",
        "#for each problem child, set them to the average value from the train set, to null the affect some\n",
        "for o in outliers:\n",
        "    problem_column[o[0]]=train_layer2_col0_mean\n",
        "    \n",
        "print(problem_column[o[0]])\n",
        "\n",
        "#check outliers again\n",
        "problem_column=x_layer2_test.T[0]\n",
        "outliers=[]\n",
        "for i in range(len(problem_column)):\n",
        "    if problem_column[i]>30000:\n",
        "        outliers.append((i,problem_column[i]))\n",
        "print(\"num outliers:\",len(outliers))\n",
        "\n",
        "print(x_layer2_test.T[0][o[0]]) # verify that the change made it all the way to the original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "955778bb-5c2f-be97-b660-46585824f5f0"
      },
      "source": [
        "Predict Layer 2\n",
        "---------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1dd418a-429d-fe24-4887-7960127f623c"
      },
      "outputs": [],
      "source": [
        "test_data['loss']=layer2_regr.predict(x_layer2_test)\n",
        "\n",
        "result=test_data[['id','loss',]]\n",
        "output_fname=\"result_submission_stack.csv\"\n",
        "display(writeData(result,output_fname))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99dfb5d6-4bee-1062-ebd1-2338d4c63631"
      },
      "outputs": [],
      "source": [
        "#the XGB version:\n",
        "\n",
        "dtest = xgb.DMatrix(x_layer2_test)\n",
        "#test_data['loss']=layer2_gbdt.predict(dtest)\n",
        "\n",
        "result=test_data[['id','loss',]]\n",
        "output_fname=\"result_submission_stack_xgb.csv\"\n",
        "display(writeData(result,output_fname))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c51ff678-ad95-0f95-6c2c-abb0af307232"
      },
      "outputs": [],
      "source": [
        "#let's have a look at the std of the result, as a cross check\n",
        "print(\"result std:\",result.std(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ba82c66-b8f0-5d01-7634-2635e8e47384"
      },
      "source": [
        "EOF\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}