{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "file_extension": ".py", "version": "3.6.3", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "cells": [{"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["import time\n", "\n", "import pandas as pd\n", "import numpy as np\n", "\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Flatten\n", "from keras.layers import Conv2D, MaxPooling2D\n", "from keras.optimizers import Adam\n", "from keras.callbacks import TensorBoard\n", "\n", "from sklearn.model_selection import train_test_split"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def get_images(df):\n", "    '''Create 2-channel 'images'. Return normalised images.'''\n", "    \n", "    im1 = df.band_1.apply(np.array).apply(lambda x: x.reshape(75, 75)).tolist()\n", "    im2 = df.band_2.apply(np.array).apply(lambda x: x.reshape(75, 75)).tolist()\n", "    \n", "    im1 = np.array(im1)\n", "    im2 = np.array(im2)\n", "\n", "    images = np.stack([im1, im2], axis=3)\n", "    \n", "    # normalise images.\n", "    im_min = images.min(axis=(0, 1), keepdims=True)\n", "    im_max = images.max(axis=(0, 1), keepdims=True)\n", "    images = (images - im_min) / (im_max - im_min)\n", "    \n", "    return images"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def create_model():\n", "    '''Create and return a keras model.'''\n", "    \n", "    model = Sequential()\n", "    \n", "    # input: 75x75 images with 2 channels \n", "    \n", "    # this applies 16 convolution filters of size 3x3 each.\n", "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(75, 75, 2)))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "    model.add(Dropout(0.5))\n", "\n", "    model.add(Conv2D(32, (3, 3), activation='relu'))\n", "    model.add(MaxPooling2D(pool_size=(2, 2)))\n", "    model.add(Dropout(0.5))\n", "\n", "    model.add(Flatten())\n", "    model.add(Dense(64, activation='relu'))\n", "    model.add(Dropout(0.5))\n", "    model.add(Dense(1, activation='sigmoid'))\n", "    \n", "    tensorboard = TensorBoard(log_dir='./logs/{}'.format(time.time()), batch_size=32)\n", "\n", "    return model, [tensorboard]"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["train = pd.read_json('../input/train.json')\n", "X = get_images(train)\n", "y = train.is_iceberg.values\n", "\n", "train = None\n", "\n", "X, Xt, y, yt = train_test_split(X, y, test_size=0.25)"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["model, callbacks = create_model()\n", "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n", "model.fit(X, y, validation_data=(Xt, yt), batch_size=32, epochs=5, callbacks=callbacks)"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["model.save('model.h5')"], "outputs": []}, {"metadata": {}, "execution_count": null, "cell_type": "code", "source": ["# create a submission\n", "\n", "test = pd.read_json('../input/test.json')\n", "X = get_images(test)\n", "# make predictions\n", "predictions = model.predict_proba(X)\n", "submission = pd.DataFrame({'id': test['id'], 'is_iceberg': predictions[:, 0]})\n", "submission.to_csv('submission.csv', index=False)"], "outputs": []}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "source": [], "outputs": []}], "nbformat": 4}