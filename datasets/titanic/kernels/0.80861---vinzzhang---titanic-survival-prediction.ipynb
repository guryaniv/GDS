{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"210dd6fdf1be52834d11434a90f4c6232ce1cb77"},"cell_type":"markdown","source":"# Loading data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"tt_train =  pd.read_csv(\"../input/train.csv\")\ntt_test =  pd.read_csv(\"../input/test.csv\")\ntt = tt_train.append(tt_test, ignore_index = True, sort = True)\ntt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"487d5af930394cdd699ef217031d424dae5e0bf2"},"cell_type":"code","source":"tt.info()\ntt.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4ec5200884536e261a9ac149866afefc69822fd"},"cell_type":"markdown","source":"* Age: 263 missing values \n\n* Cabin: 1014 missing values \n\n* Embarked: 2 missing values\n* Fare: 1 missing values"},{"metadata":{"_uuid":"0a773e45851a67caafb5c1ff1071e1c910986cb6"},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true,"_uuid":"820c1ccaeafa3741dde066c9a2f107b6fd6b1f01"},"cell_type":"code","source":"# def predictAge(tt):\n#     num_tt = tt[['Age','Fare', 'Parch', 'SibSp', 'Pclass']]\n#     haveAge = num_tt.loc[num_tt['Age'].notnull(),:].copy()\n#     dontHaveAge = num_tt.loc[num_tt['Age'].isnull(),:].copy()\n#     y = haveAge.iloc[:, 0]\n#     X = haveAge.iloc[:, 1:]\n#     rfr = RandomForestRegressor(random_state=1, n_estimators=2000, n_jobs=-1)\n#     rfr.fit(X, y)\n#     y_pred = rfr.predict(dontHaveAge.iloc[:, 1:])\n#     tt.loc[tt['Age'].isnull(), 'Age' ] = y_pred \n#     tt = tt\n#     return tt, rfr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a903a1a87cb09277f13edf659d507a7f862768e0"},"cell_type":"markdown","source":"# Handling missing value"},{"metadata":{"trusted":true,"_uuid":"9816de881a2317a55cd852c50e357e29967672b6"},"cell_type":"code","source":"tt['Fare'] = tt['Fare'].fillna(tt['Fare'].mean())\ntt['Embarked'] = tt['Embarked'].fillna(tt['Embarked'].mode()[0])\ntt['Cabin'] = tt['Cabin'].fillna('U') # U: unknown\n# tt, rfr = predictAge(tt) # Filling missing value Age by random forest regressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a81678b343e9cc297d85ef8d81058906d830cc61"},"cell_type":"markdown","source":"# Etract new features"},{"metadata":{"trusted":true,"_uuid":"23ffd5228ecf730a0261ce3aa47287c509973ee4","scrolled":false},"cell_type":"code","source":"tt['Deck'] = tt['Cabin'].apply(lambda x:x[0]) # Extract Deck by the first letter of Cabin\ntt['DeckKnown'] = tt['Deck'].apply(lambda x: 1 if x == 'U' else 0)\n\ntt['Title'] = tt['Name'].str.extract('([A-Za-z]+)\\.', expand=False) # Split name and extract titles as title group function\n\n## Impute Age by filling the median age of same title people. RF model didn't perform a better in predicting age\nmedianAge = tt.groupby('Title')['Age'].median()\nageDict = medianAge.to_dict()\ntitles = medianAge.index.tolist()\nfor title in titles:\n    fillAge = medianAge[title]\n    tt.loc[(tt['Age'].isnull()) & (tt['Title'] == title), 'Age'] = fillAge\n\ntitle = (tt['Title'].value_counts() < 10) # Set titles whose count is lower than 10 as \"Rare\"\ntt['Title'] = tt['Title'].apply(lambda x: 'Rare' if title.loc[x] == True else x)\n\ntt['FamilySize'] = tt['SibSp'] + tt['Parch'] + 1 # Summary the number of family members for each people\ntt['FamilySize'] = tt['FamilySize'].apply(lambda x: 'Single' if x == 1 else ('Normal' if 1<x<4 else 'Large')) # Category family size by 1, 1-3, over 3\n\ntt[\"AgeGroup\"]=pd.cut(tt[\"Age\"],range(0,90,15)) # Category Age by groups, especially for child group with age lower than 12\n\ntt['FareGroup'] = pd.qcut(tt['Fare'], 4) # Category Fare by quantile groups\n\n# tt.loc[tt['Age']<=16, 'Person'] ='child' # Category Age_Sex by child, man and woman\n# tt.loc[(tt['Age']>16) & (tt['Sex']=='female'), 'Person'] = 'adult_woman'\n# tt.loc[(tt['Age']>16) & (tt['Sex']=='male'), 'Person'] = 'adult_man'\n\n# Marked people with same surname\n# Since people in the same family tend to survive or die together\ntt['Surname'] = tt['Name'].apply(lambda x : x.split(',')[1].split('.')[1].strip())\ncountMap= tt['Surname'].value_counts().to_dict()\ntt['Surname'] = tt['Surname'].map(countMap)\ntt.loc[tt['Surname'] > 1,'alone_NoSameSurname_members'] = 1\ntt.loc[tt['Surname'] == 1,'alone_NoSameSurname_members'] = 0 # alone\n\n# Marked people who has same ticket as ShareTicket condition\n# Since people who have same ticket knowing each others (friends, family and other relationships) tend to survive or die together\nticketMap = tt['Ticket'].value_counts().to_dict()\ntt['TicketCount'] = tt['Ticket'].map(ticketMap)\ntt.loc[tt['TicketCount'] > 1,'ShareTicket'] = 1\ntt.loc[tt['TicketCount'] == 1,'ShareTicket'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44f603a03fe110d997325e5ffa37fa1d905cf950"},"cell_type":"markdown","source":"# Visualization: Relastions between features and survival"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"8c7d0317b0f857abd58e5f9b5601827f62c934b2"},"cell_type":"code","source":"features = [\"Sex\",\"Pclass\",\"DeckKnown\",\"Embarked\",\"ShareTicket\",\"Title\",\"alone_NoSameSurname_members\",\"FamilySize\",\"AgeGroup\",\"FareGroup\"]\n\npltDict={}\nfor f in features:\n    temp=tt.groupby([\"Survived\",f]).size()\n    pltDict[f]=pd.concat([temp[0],temp[1]],axis=1,sort=False).fillna(0)\n\nfor f in features:\n    N = len(pltDict[f][0])\n    ind = np.arange(N)    # the x locations for the groups\n    width = 0.5       # the width of the bars: can also be len(x) sequence\n    survived_num = pltDict[f][1]\n    not_survived_num = pltDict[f][0]\n\n    plt.bar(ind, not_survived_num, width, label=\"Not survived\")\n    plt.bar(ind, survived_num, width, bottom = not_survived_num, label = \"Survived\")\n    plt.xticks(ind, pltDict[f].index.values, rotation = 60)\n    plt.ylabel(\"Number of people\")\n    plt.title(f)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e380ecdd910e0f9c31225080e2c0e246778efba"},"cell_type":"markdown","source":"# One-hot encoding for categorical variable"},{"metadata":{"trusted":true,"_uuid":"923dbd0388e56a37b70be3ce2534418cafa351a4"},"cell_type":"code","source":"dummies_Embarked = pd.get_dummies(tt['Embarked'], prefix= 'Embarked')\ndummies_Sex = pd.get_dummies(tt['Sex'], prefix= 'Sex')\ndummies_Title = pd.get_dummies(tt['Title'], prefix= 'Title')\n# dummies_Person = pd.get_dummies(tt['Person'], prefix= 'Person')\ndummies_FamilySize = pd.get_dummies(tt['FamilySize'], prefix= 'FamilySize')\ndummies_AgeGroup = pd.get_dummies(tt['AgeGroup'], prefix= 'AgeGroup')\ndummies_FareGroup = pd.get_dummies(tt['FareGroup'], prefix= 'FareGroup')\n\nPassengerId = tt.loc[891:,'PassengerId']\ntt = tt.drop(['Name','PassengerId','Surname','Age','Fare','Ticket','Cabin','Embarked','Sex','FareGroup','AgeGroup','SibSp','Parch','TicketCount','Deck','FamilySize','Title'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7243e3623471bf0ccf9e6d70c38b9bcd13f3b9cc"},"cell_type":"code","source":"tt = pd.concat([tt, dummies_AgeGroup, dummies_FareGroup, dummies_Embarked, dummies_Sex, dummies_Title, dummies_FamilySize],axis=1)\ntt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a510e8cd865a32dd3eff9566d23fa963c057aaec"},"cell_type":"markdown","source":"# Base Modeling & Evaluation"},{"metadata":{"trusted":true,"_uuid":"3165c49bf4276bf07bff55d94f1d6799afec4131"},"cell_type":"code","source":"# Drop Survived to split series easily \nsurvived = tt['Survived']\ntt = tt.drop(['Survived'], axis = 1)\n# Normalization\ntt = tt.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x))) \ntt['Survived'] = survived","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad4bac5c4bb6a49934991fd28e9beffba8488ae1"},"cell_type":"code","source":"# Split X_train, X_test, y_train\nx_train = tt.iloc[0:891, :-1]\ny_train = tt.iloc[0:891, -1]\nx_test = tt.iloc[891: , :-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33fcb9520c75635241ad20b4e0dc22cb7ff91b78","collapsed":true},"cell_type":"markdown","source":"## Model comparison: Logistic Regression, SVM, Naive Bayes, Decision Tree, Random Forest"},{"metadata":{"trusted":true,"_uuid":"610611a48c7d0edf41cb83474d23067605de5a05"},"cell_type":"code","source":"# # Logistic Regression\n# lg = LogisticRegression()\n# lg.fit(x_train, y_train.values.ravel())\n# y_pred = lg.predict(x_test)\n# lg = lg.score(x_train, y_train)\n\n# # Support Vector Machines\n# svc = SVC(gamma = 'auto')\n# svc.fit(x_train, y_train.values.ravel())\n# y_pred = svc.predict(x_test)\n# svc = svc.score(x_train, y_train)\n\n# # Gaussian Naive Bayes\n# gaussian = GaussianNB()\n# gaussian.fit(x_train, y_train.values.ravel())\n# y_pred = gaussian.predict(x_test)\n# gaussian = gaussian.score(x_train, y_train)\n\n# # Decision Tree\n# decision_tree = DecisionTreeClassifier()\n# decision_tree.fit(x_train, y_train.values.ravel())\n# y_pred = decision_tree.predict(x_test)\n# dt = decision_tree.score(x_train, y_train)\n\n# # Random Forest\n# random_forest = RandomForestClassifier(n_estimators=100)\n# random_forest.fit(x_train, y_train.values.ravel())\n# y_sub = random_forest.predict(x_test)\n# rf = random_forest.score(x_train, y_train)\n\n# # Model comparison\n# models = pd.DataFrame({\n#     'Model': ['Support Vector Machines', 'Logistic Regression', 'Random Forest', 'Naive Bayes', 'Decision Tree'],\n#     'Score': [svc, lg, rf, gaussian, dt]})\n# models.sort_values(by='Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff6aa442f15982f0bdd4db1a0893c03760f37fd"},"cell_type":"code","source":"# svc = SVC() # rbf kernel\n# parameter_grid = {\n#                  'C': [0.001,0.01,0.1,1,10],\n#                  'gamma': [0.1,0.01,0.001],\n#                  }\n# cross_validation = StratifiedKFold(n_splits=5)\n# grid_search = GridSearchCV(svc,\n#                            param_grid=parameter_grid,\n#                            cv=cross_validation,\n#                            iid=True)\n# grid_search.fit(x_train, y_train)\n# print('Best score: {}'.format(grid_search.best_score_))\n# print('Best parameters: {}'.format(grid_search.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d83c7029ba8ca92ef5da9c3f7103db9cab486ca"},"cell_type":"code","source":"# rf = RandomForestClassifier(max_features='sqrt')\n# parameter_grid = {\n#                  'max_depth' : [4,5,6,7,8],\n#                  'n_estimators': [100,150,200,250,400],\n#                  'criterion': ['gini','entropy'],\n#                  }\n# cross_validation = StratifiedKFold(n_splits=5)\n# grid_search = GridSearchCV(rf,\n#                            param_grid=parameter_grid,\n#                            cv=cross_validation,\n#                            iid=True)\n# grid_search.fit(x_train, y_train)\n# print('Best score: {}'.format(grid_search.best_score_))\n# print('Best parameters: {}'.format(grid_search.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"463f9a5aaae331728e9edd2563e063dfbe8f3b13"},"cell_type":"code","source":"# gbdt = GradientBoostingClassifier(n_estimators=200, learning_rate = 0.1)\n# parameter_grid = {\n#                  'n_estimators': [100,150,200,300],\n#                  'learning_rate': [0.01, 0.1, 1],\n#                  'subsample': [0.6, 0.7, 0.8],\n#                  'max_depth' : [4,5,6,7,8],\n#                  }\n# cross_validation = StratifiedKFold(n_splits=5)\n# grid_search = GridSearchCV(gbdt,\n#                            param_grid=parameter_grid,\n#                            cv=cross_validation,\n#                            iid=True)\n# grid_search.fit(x_train, y_train)\n# print('Best score: {}'.format(grid_search.best_score_))\n# print('Best parameters: {}'.format(grid_search.best_params_))\n\n# # Best score: 0.8372615039281706\n# # Best parameters: {'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.6}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a51baf147476d787b288279d0ebc567b9833fe3b"},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=150, max_depth=7, criterion='gini')\nrf.fit(x_train, y_train)\ny_sub = rf.predict(x_test)\n\n# gbdt = GradientBoostingClassifier(n_estimators=300, learning_rate=0.01, subsample=0.6, max_depth=5)\n# y_sub = voting.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94c8c52479eabd2ad553939b5a4f3ffb9530ac44"},"cell_type":"code","source":"# Submission\nsubmission = pd.DataFrame({\n        \"PassengerId\": PassengerId,\n        \"Survived\": y_sub.astype(int)\n    })\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0530594c7589b598074dcebb5dbb35db2c501514"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bde1ec017d3cc3201724e138995292b936d72185"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}