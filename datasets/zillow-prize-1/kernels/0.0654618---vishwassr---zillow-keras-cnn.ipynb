{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"149163e1ff6491174d165f0822087fd21c381a0e"},"cell_type":"code","source":"from datetime import datetime\nimport numpy as np\nimport numpy as numpy\nimport pandas as pd\nimport pylab\nimport calendar\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nfrom scipy.stats import kendalltau\nimport warnings\nimport matplotlib.pyplot as plt\nimport pandas","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dd6790a2600c2beb4b42e4819d4d29b90bbca53"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, LSTM, GRU, Conv1D,MaxPooling1D\nfrom keras.layers import Dropout, BatchNormalization, Flatten\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a298f75072c1a886dff82bd30716a06ca930feb1"},"cell_type":"code","source":"#################\n##  READ DATA  ##\n#################\n\n# Load train, Prop and sample\nprint('Loading train, prop and sample data')\ntrain = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\nprop = pd.read_csv('../input/properties_2016.csv')\nsample = pd.read_csv('../input/sample_submission.csv')\n \nprint('Fitting Label Encoder on properties')\nfor c in prop.columns:\n    prop[c]=prop[c].fillna(-1)\n    if prop[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(prop[c].values))\n        prop[c] = lbl.transform(list(prop[c].values))\n        \n#Create df_train and x_train y_train from that\nprint('Creating training set:')\ndf_train = train.merge(prop, how='left', on='parcelid')\n\n###########################################################","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"15f5a8ee7b2d40236e9a9fe334bafd0424cb2290"},"cell_type":"code","source":"###########################################################\ndf_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\ndf_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\ndf_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\ndf_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"1040f7fd14e11160558c36ee541effad74d98085"},"cell_type":"code","source":"###########################################\n\nprint('Fill  NA/NaN values using suitable method' )\n#df_train.fillna(df_train.mean(),inplace = True)\ndf_train.fillna(-1.0)\n\n#df_train =df_train[ df_train.logerror > -0.4005 ]\n#df_train=df_train[ df_train.logerror < 0.412 ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbb6ab8b6fb49c2a3401f1aa27ed8d317ccc7596"},"cell_type":"code","source":"print('Create x_train and y_train from df_train' )\nx_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\ny_train = df_train[\"logerror\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91126c87869e538cf79f3741e2930c35ca0d741f"},"cell_type":"code","source":"y_mean = np.mean(y_train)\nprint(x_train.shape, y_train.shape)\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n# Create df_test and test set\nprint('Creating df_test  :')\nsample['parcelid'] = sample['ParcelId']\n\nprint(\"Merge Sample with property data :\")\ndf_test = sample.merge(prop, on='parcelid', how='left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5d759976baa09d6561e1914bb701000336e96de5"},"cell_type":"code","source":"\n########################\ndf_test[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\ndf_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\ndf_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\ndf_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"292bc85d8237d76a297e6b0e0ec20eee454e1e89"},"cell_type":"code","source":"\n#################################\n\n\nx_test = df_test[train_columns]\n\nprint('Shape of x_test:', x_test.shape)\nprint(\"Preparing x_test:\")\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n  \n#print(\"Bind x_test to float32:\")\n#x_test = x_test.values.astype(np.float32, copy=False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a4e22d66e0ded96fe80b1e6fb533cf69204cee56"},"cell_type":"code","source":"###################\n##  PREPROCESS  ##\n###################\n\n\n#############################Imputer##################\n\nfrom sklearn.preprocessing import Imputer\nimputer= Imputer()\nimputer.fit(x_train.iloc[:, :])\nx_train = imputer.transform(x_train.iloc[:, :])\nimputer.fit(x_test.iloc[:, :])\nx_test = imputer.transform(x_test.iloc[:, :])\n\n#########################Standard Scalar##############\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\n################################################\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a99f576801e306d7fa4ab90cbbf2c84b4a8f2e78"},"cell_type":"code","source":"print(\"x_train shape:\",x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca8566338e5222f4d90fae9491f51fa4099060ed"},"cell_type":"code","source":"###################\n##  RUN NETWORK  ##\n###################\n\ncount = 8\nlen_x=int(x_train.shape[1])\nprint(\"len_x is:\",len_x)\n\n## The model- Uses a few dense layers on top of LSTM and CNN layers. \n\nmodel = Sequential()\nmodel.add(Conv1D(filters=20, kernel_size=10 ,strides=10,     \n                  input_shape = (len_x,1), kernel_initializer= 'uniform',      \n                  activation= 'relu'))\nmodel.add(MaxPooling1D(pool_size=2, strides=10, padding='same'))\nmodel.add(Dropout(.17))\nmodel.add(LSTM(units = 150 , kernel_initializer = 'normal', activation = 'softmax',return_sequences=True))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(.4))\nmodel.add(Dense(units = 150 , kernel_initializer = 'normal', activation = 'relu'))\n\nmodel.add(BatchNormalization())\nmodel.add(Dropout(.32))\nmodel.add(Dense(units = 75, kernel_initializer = 'normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(.22))\nmodel.add(Dense(units = 25, kernel_initializer = 'normal', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(.22))\nmodel.add(Flatten())\nmodel.add(Dense(1, kernel_initializer='normal'))\nmodel.compile(loss='mean_absolute_error', optimizer='rmsprop')\n\nmodel.summary()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14b1bec0d9e918d3ec2da7f2b14a6830b7e8097a"},"cell_type":"code","source":"print(len(x_train), len(y_train))\nx = np.array(x_train)\nx = np.expand_dims(x, axis=2)\ny = np.array(y_train)\n#y = y.reshape(y_train.shape[0],)\nprint(x.shape,y.shape)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"efd175136f0a718ce841d253c3b519906a017aa9"},"cell_type":"code","source":"\n\nmodel.fit(x,y, batch_size = 128, epochs = 20, verbose=1)\n\nprint(\"x_test.shape:\",x_test.shape)\nx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n\n\n#######################################################################################\n\nprint( \"\\nPreparing results for write :\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a197ddf6df640a268faf5a4bafdedc2d92f86d6"},"cell_type":"code","source":"y_pred_ann = model.predict(x_test)\nprint(y_pred_ann.shape)\ny_pred = y_pred_ann.flatten()\nprint(y_pred.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b61d824b6d9bbd1175f42f16305ce54ea35b168b"},"cell_type":"code","source":"#####################\n##  WRITE RESULTS  ##\n#####################\n\n#y_pred = y_pred_ann.flatten()\n\n#output = pd.DataFrame({'ParcelId': properties['parcelid'].astype(np.int32),\noutput = pd.DataFrame({'ParcelId': prop['parcelid'].astype(np.int32),\n        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n# set col 'ParceID' to first col\ncols = output.columns.tolist()\ncols = cols[-1:] + cols[:-1]\noutput = output[cols]\n\nprint( \"\\nWriting results to disk:\" )\noutput.to_csv('Output_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n\nprint( \"\\nFinished!\" )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"82eb2dc8bacd8f7beb1aa05e19dc61193d0314c7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":1}