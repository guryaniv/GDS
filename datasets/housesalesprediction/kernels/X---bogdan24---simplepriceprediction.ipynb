{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom math import sqrt\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"house = pd.read_csv(\"../input/kc_house_data.csv\")\nprice = house['price'] # y of the data for linear regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0eb9d542c9ad0946648c6d2f81456c4c3fadc22"},"cell_type":"code","source":"house.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"145ec220f4de07e7319940c11d406d310d09b3de"},"cell_type":"markdown","source":"# Feature analysis and transformation"},{"metadata":{"trusted":true,"_uuid":"181528b4118d17bd4f9fc9e11e00d1752ebcb5ca"},"cell_type":"code","source":"house['date'] = pd.to_datetime(house['date'])#transforming date column to datetype\nhouse['year'] = house['date'].dt.year #extracting year \nhouse['month'] = house['date'].dt.month #month\nhouse['day'] = house['date'].dt.day #day\nhouse['yr_renovated'] = house['yr_renovated'].apply(lambda x: 2018 - x if x != 0 else 0)#analysing how old is a renovation\nhouse['yr_built'] = np.abs(house['yr_built'] - 2018) #analysing how old is a building\nhouse = pd.concat([house, pd.get_dummies(house['zipcode'])], axis=1); # creating dummies from zipcode\n\nhouse = house.drop('date', axis = 1)\nhouse = house.drop('zipcode', axis = 1)\nhouse = house.drop('id', axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67bfeb750b79e423bb51d3134aa7955db7b257c2"},"cell_type":"code","source":"# visualising houses on the map with indication of house price\nhouse.plot(kind=\"scatter\", x=\"long\", y=\"lat\", alpha=0.4, figsize=(16,8), c=price,\n           cmap=plt.get_cmap(\"jet\"), colorbar=True, sharex=False)\n# As we can see most of the houses are cheaper than 300 thousands and most of the expensive houses are \n#located near the water (water is mainly white spacec on the graph)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33add028701e4fbfaa38f8cada0b474465276c5d"},"cell_type":"code","source":"#visualizationg of price corresponging to sqrt_living with indication of condiditon of the property\nplt.figure(figsize = (12,8))\ng = sns.FacetGrid(data=house, hue='condition',size= 5, aspect=2)\ng.map(plt.scatter, \"sqft_living\", \"price\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e74b1afa8f5f0e245a834914e7c248153c0b4c5d"},"cell_type":"code","source":"#creating correlation matrix to know the relation between target feature and other features\nfeatures = ['price','sqft_living','grade','sqft_above','sqft_living15', 'bathrooms','view','sqft_basement',\n            'bedrooms', 'lat', 'waterfront', 'floors', 'sqft_lot', 'sqft_lot15','yr_renovated','yr_built',\n            'condition', 'year','long', 'day', 'month']\nf, ax = plt.subplots(figsize=(20, 15))\nplt.title('Correlation Matrix',fontsize=25)\nsns.heatmap(house[features].corr(), linewidths=0.25, vmax=1.0, square=True, cmap=\"RdBu_r\", linecolor='k', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ccba5b2bf53c5f20f9a6e6f75e142a750e7af7"},"cell_type":"code","source":"house = house.drop('price', axis = 1)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(house, price, test_size = 0.2, random_state=49)\nprint(\"Linear regression datasets\")\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e7e9339661671ecfb3d1a940667438237d27112"},"cell_type":"markdown","source":"# Linear regression"},{"metadata":{"trusted":true,"_uuid":"8b3d4ca046b71cc4e1c1716604f927d662b7614c"},"cell_type":"code","source":"from sklearn import linear_model\nlinear = linear_model.LinearRegression()\nlinear.fit(X_train, y_train)\npredictions = linear.predict(X_test)\n# The mean squared error\nprint(\"MSE test: %.2f\"% mean_squared_error(y_test, predictions))\nprint(\"MSE train: %.2f\"% mean_squared_error(y_train, linear.predict(X_train)))\n# The root mean squared error\nprint(\"RMSE: %.2f\"% sqrt(mean_squared_error(y_test, predictions)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a26f317a79790794b9e700e53a9a09fa2a69e8a8"},"cell_type":"code","source":"# to visualize easier I will take features \ntrain_score = [67931066834.67, 62306584063.49, 61471318688.55, 61331972036.77, 61062544452.85, 57063428453.64,\n               57063428453.64, 56474065847.59, 48498227841.03, 46620127163.50, 46471326069.48, 46450188074.47, \n               46346785423.06, 46175074862.26, 41929732178.36, 41609035250.42, 41422672632.55, 41210098136.32, \n               40699278920.83, 40694987157.64, 25994480772.17]\ntest_score = [70035987663.86,  64466114800.02, 63394337312.83, 63346196234.39, 62906940485.03, 57520064549.14,\n              57520064549.14, 57147409666.80, 48670558382.01, 44954342653.28, 44870210542.26, 44664863538.50,\n              44802783588.71, 44445870879.89, 40142222536.94, 39705475435.78, 39456722730.82, 39327197095.20,\n              38930511620.08, 38903082114.59, 24585784318.73]\nnumber_of_features = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 16, 17, 18, 19, 90]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ecd893bb48d064c54d182837d4821d34d58d96a"},"cell_type":"code","source":"plt.figure(figsize=(16, 5))\nplt.plot(number_of_features, train_score)\nplt.plot(number_of_features, test_score)\nplt.xlim([0, 20])\nplt.ylim([38000000000, 71000000000])\nplt.rcParams['font.size'] = 12\nplt.title('Train Test Error')\nplt.xlabel('Number of features')\nplt.ylabel('MSE')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69767f66e9450e7051bcaee01cf9d6d2f90e44ea"},"cell_type":"markdown","source":"# Polynomial regression"},{"metadata":{"trusted":true,"_uuid":"fbed69e8c25e4883805599bd68c6941cd8301907"},"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(2)\nX_poly = poly.fit_transform(house)\n\nX_train_poly, X_test_poly, y_train_poly, y_test_poly = train_test_split(X_poly, price, test_size=0.2, random_state=49)\n\nmodel = linear_model.LinearRegression()\nmodel.fit(X_train_poly, y_train_poly)\npredictions_poly = model.predict(X_test_poly)\n# The mean squared error\nprint(\"MSE: %.2f\"% mean_squared_error(y_test_poly, predictions_poly))\n# The root mean squared error\nprint(\"RMSE: %.2f\"% sqrt(mean_squared_error(y_test_poly, predictions_poly)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test_poly, predictions_poly))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caea759c1d7c082b28673a05f64be2bd416bac04"},"cell_type":"markdown","source":"# Random forest"},{"metadata":{"trusted":true,"_uuid":"2d787caf4d7e48465092b1e420f51fe45a9ade11"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_model = RandomForestRegressor(n_estimators=500)\nrf_model.fit(X_train, y_train)\npredictions_rf = rf_model.predict(X_test)\n# The mean squared error\nprint(\"MSE: %.2f\"% mean_squared_error(y_test, predictions_rf))\n# The root mean squared error\nprint(\"RMSE: %.2f\"% sqrt(mean_squared_error(y_test, predictions_rf)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, predictions_rf))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b424af94857ee8f5d61a68ded3bbf2278a135d1c"},"cell_type":"markdown","source":"# XGBoost"},{"metadata":{"trusted":true,"_uuid":"31317bdab9e0148c58de7cdf2f0374ce348aa497"},"cell_type":"code","source":"from xgboost import XGBRegressor\nxgb = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,colsample_bytree=1, max_depth=7)\nxgb.fit(X_train, y_train)\npredictions_xgboost = xgb.predict(X_test)\n# The mean squared error\nprint(\"MSE: %.2f\"% mean_squared_error(y_test, predictions_xgboost))\n# The root mean squared error\nprint(\"RMSE: %.2f\"% sqrt(mean_squared_error(y_test, predictions_xgboost)))\n# Explained variance score: 1 is perfect prediction\nprint('Variance score: %.2f' % r2_score(y_test, predictions_xgboost))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3257675da350c1800d997337852b6762fe324f5f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}