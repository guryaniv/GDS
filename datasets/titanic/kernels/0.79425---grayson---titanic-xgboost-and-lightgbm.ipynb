{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.impute import SimpleImputer # missing data imputing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score\nimport matplotlib.pyplot as plt\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# read train and test data\ndata_train = pd.read_csv('../input/train.csv')\ndata_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"582c057bc92a664c07aacbaaaea8b1987ee002e3"},"cell_type":"markdown","source":"# A glance at the data"},{"metadata":{"trusted":true,"_uuid":"4001b6b177845a442b52749d913fdfc9af713174"},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cecc34117c0ef1e33b361e851a6690c8993daa7"},"cell_type":"code","source":"data_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a94773a6d5d277521bc882992bd5a5d85e5b574"},"cell_type":"code","source":"# check column datatypes\ndata_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efe933d9e2446d969130876d347e69577f87d5ca"},"cell_type":"markdown","source":"# Data processing"},{"metadata":{"_uuid":"99f5a356a741e54ea6afa29a600748e74ba052df"},"cell_type":"markdown","source":"## Handle missing values"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"264b35f8cd702d24bd7a608479c8902ad56ea8a4"},"cell_type":"code","source":"# check for missing values\nprint(\"Missing Values in data_train: \", data_train.isnull().sum(), sep = \"\\n\")\nprint()\nprint(\"Missing Values in data_test: \", data_test.isnull().sum(), sep = \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"febf14fb223dcc90020b2712bb6d710559d66908"},"cell_type":"code","source":"# check age distribution in both datasets\nplt.subplot(1, 2, 1)\ndata_train.Age.hist()\nplt.xlabel('Age (data_train)')\nplt.ylabel('# of passengers')\n\nplt.subplot(1, 2, 2)\ndata_test.Age.hist()\nplt.xlabel('Age (data_test)')\nplt.ylabel('# of passengers')\n\n# Ages are continuously distributed with a single mode. Filling the missing values\n# with the most frequent value is appropriate.\n\n# fill missing values for Age with the most frequent value\nimp_age = SimpleImputer(missing_values = np.nan, strategy='most_frequent')\n\n# for data_train\nimp_age.fit(data_train[['Age']])\ndata_train['Age'] = imp_age.transform(data_train[['Age']])\n\n# for data_test\nimp_age.fit(data_test[['Age']])\ndata_test['Age'] = imp_age.transform(data_test[['Age']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f77110fe49a3814e541f234a15f5fbe92774c8"},"cell_type":"code","source":"# check cabin info in both datasets\nprint(\"Cabin values in data_train: \", data_train.Cabin.unique().size)\nprint()\nprint(\"Cabin values in data_test: \", data_test.Cabin.unique().size)\n\n# Cabin has many discrete values. Adding a new discrete value \"Unknown\" to this\n# category will not have significant impact.\n\n# fill missing values for Cabin with \"Unknown\"\ndata_train.Cabin.fillna(\"Unknown\", inplace = True)\ndata_test.Cabin.fillna(\"Unknown\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc3669a4efc756713e6992876f83c15b73ed6070"},"cell_type":"code","source":"# check embark info in data_train\nprint(data_train.Embarked.value_counts())\n\n# Only 3 categories found in this column. Missing values are filled by the\n# most frequent value.\ndata_train.Embarked.fillna(\"S\", inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8011799e807d1336fde1b9b525c88643133a8900"},"cell_type":"code","source":"# check fair info in data_test\ndata_test.Fare.hist()\nplt.xlabel('Fare (data_test)')\nplt.ylabel('# of passengers')\n\n# A large amount of passangers didn't pay their fare.\n# The missing values in the Fare column are filled by 0.\ndata_test.Fare.fillna(0, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66e229bfa87c5c245b11cd0c89e28e3fe23d9ad0","scrolled":true},"cell_type":"code","source":"# Check the missing values again after imputing\nprint(\"Missing Values in data_train: \", data_train.isnull().sum(), sep = \"\\n\")\nprint()\nprint(\"Missing Values in data_test: \", data_test.isnull().sum(), sep = \"\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bc6c3aeaf36a9c76da8fbb62f896f547c8198a3"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"_uuid":"7b9993eb660222af0bc1bb709e0b3cd551c34327"},"cell_type":"markdown","source":"## Pclass and Survive"},{"metadata":{"trusted":true,"_uuid":"5f49c02cf1bf1207ab652ebe0eed2218f9dd5798"},"cell_type":"code","source":"# visulize the relationship between pclass and survive\npclass_survive_crosstbl = pd.crosstab(data_train.Pclass, data_train.Survived)\n\n# print(pclass_survive_crosstbl)\n\npassanger_num_pclass = pclass_survive_crosstbl.sum(axis = 1)\n\n# calculate survivor rate for each pclass\npclass_survive_crosstbl = pclass_survive_crosstbl.divide(passanger_num_pclass, axis = 0).round(2)\n\npclass_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('pclass (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d0da0d0a8eeb8e888aee9cf30f221adf707090d"},"cell_type":"markdown","source":"## Title and Survive"},{"metadata":{"trusted":true,"_uuid":"eaf04a60ecf9e2364391c75e99edb83c215edcbb"},"cell_type":"code","source":"# extract titles for the passengers\ntitle_train = data_train.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\ntitle_test = data_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\nprint(title_train.unique())\nprint()\nprint(title_test.unique())\nprint()\n\n# merge the titles by social status\ntitle_to_replace = {'Mrs': 'Ordinary_female', 'Miss': 'Ordinary_female', \n                    'Mme': 'Ordinary_female', 'Ms': 'Ordinary_female', \n                    'Mlle': 'Ordinary_female', 'Mr': 'Ordinary_male', \n                    'Master': 'Ordinary_male', 'Capt': 'Official', \n                    'Major': 'Official', 'Dr': 'Official', \n                    'Col': 'Official', 'Rev': 'Official', \n                    'Don': 'Noble_male', 'Jonkheer': 'Noble_male', \n                    'Sir': 'Noble_male', 'Dona': 'Noble_female', \n                    'Lady': 'Noble_female', 'Countess': 'Noble_female'}\n# add title column in data_train\ndata_train['Title'] = title_train.map(title_to_replace)\ndata_test['Title'] = title_test.map(title_to_replace)\n\n# check if the Tile column matches the Name column\nprint(data_train[['Name', 'Title']].head())\nprint()\nprint(data_test[['Name', 'Title']].head())\n\n# remove the Name column\ndata_train = data_train.drop('Name', axis = 1)\ndata_test = data_test.drop('Name', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3d4b87ee0e7a226fa8744c33bf8ef82137f8232b"},"cell_type":"code","source":"# visulize the relationship between Title and survive\ntitle_survive_crosstbl = pd.crosstab(data_train.Title, data_train.Survived)\n\n# print(title_survive_crosstbl)\n\npassanger_num_title = title_survive_crosstbl.sum(axis = 1)\n\n# calculate survivor rate for each title\ntitle_survive_crosstbl = title_survive_crosstbl.divide(passanger_num_title, axis = 0).round(2)\n\ntitle_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Title (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4db931b7884556ad01c08bb502384cfe2743544a"},"cell_type":"markdown","source":"## Sex and Survive"},{"metadata":{"trusted":true,"_uuid":"22dac5965de325ba8eb787b705837ede60971cf4"},"cell_type":"code","source":"# visulize the relationship between sex and survive\nsex_survive_crosstbl = pd.crosstab(data_train.Sex, data_train.Survived)\n\n# print(sex_survive_crosstbl)\n# calculate survivor rate for each sex\nsex_survive_crosstbl = sex_survive_crosstbl.divide(sex_survive_crosstbl.sum(axis = 1), axis = 0)\n\nsex_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Sex (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92cd5d24c7efa6673f350597bded943bb346cfa2"},"cell_type":"markdown","source":"## Sex and Survive"},{"metadata":{"trusted":true,"_uuid":"bd24bc35fb5847c31dbeab981fafe57fb3a5deab"},"cell_type":"code","source":"# Segment the Age column\nage_qcut_train = pd.cut(data_train.Age, [0, 20, 40, 60, 80])\nage_qcut_test = pd.cut(data_test.Age, [0, 20, 40, 60, 80])\n\n# encode the age bins for data_train\nle = LabelEncoder()\nle.fit(age_qcut_train)\ndata_train['Age_bins'] = le.transform(age_qcut_train)\n\n# for data_test\ndata_test['Age_bins'] = le.transform(age_qcut_test)\n\n # visulize the relationship between age and survive\nage_survive_crosstbl = pd.crosstab(data_train.Age_bins, data_train.Survived)\n# print(age_survive_crosstbl)\n# calculate survivor rate for each age\nage_survive_crosstbl = age_survive_crosstbl.divide(age_survive_crosstbl.sum(axis = 1), axis = 0)\nage_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Age_bins (data_train)')\nplt.ylabel('Survival Rate')\nplt.xticks(np.arange(0, 4), ('0~20', '20~40', '40~60', '60~80'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a42e0346948529eceee0344c386c0ea8c88b720"},"cell_type":"markdown","source":"## Family Size and Survive"},{"metadata":{"trusted":true,"_uuid":"ad2b5a250ca76014786bd1bac60444a734728649"},"cell_type":"code","source":"# create new family size column by combining SibSp and Parch column\ndata_train['famsz'] = data_train.SibSp + data_train.Parch + 1\ndata_test['famsz'] = data_test.SibSp + data_test.Parch + 1\n\n# visulize the relationship between famsz and survive\nfamsz_survive_crosstbl = pd.crosstab(data_train.famsz, data_train.Survived)\n\n# print(famsz_survive_crosstbl)\n# calculate survivor rate for each famsz\nfamsz_survive_crosstbl = famsz_survive_crosstbl.divide(famsz_survive_crosstbl.sum(axis = 1), axis = 0)\n\nfamsz_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Family Size (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f3d9b137c83de842e254a3f89549803e1dd2543"},"cell_type":"markdown","source":"## Fare and Survive"},{"metadata":{"trusted":true,"_uuid":"ec3af877f496afe3453f4e452c7c607e2d771aac"},"cell_type":"code","source":"# calculate fare/person\ndata_train['FarePP'] = data_train['Fare'] / data_train['famsz']\ndata_test['FarePP'] = data_test['Fare'] / data_test['famsz']\n\n# Segment the FarePP column\nfarepp_qcut_train = pd.cut(data_train.FarePP, [0, 5, 10, 20, 30, 600], include_lowest = True)\nfarepp_qcut_test = pd.cut(data_test.FarePP, [0, 5, 10, 20, 30, 600], include_lowest = True)\n\nfarepp_qcut_train.value_counts()\n# encode the farepp bins for data_train\nle = LabelEncoder()\nle.fit(farepp_qcut_train)\ndata_train['FarePP_bins'] = le.transform(farepp_qcut_train)\n\n# for data_test\ndata_test['FarePP_bins'] = le.transform(farepp_qcut_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8ee394e5a61619f4cae1f519576f3c48676372b9"},"cell_type":"code","source":"# visulize the relationship between farepp and survive\nfarepp_survive_crosstbl = pd.crosstab(data_train.FarePP_bins, data_train.Survived)\n\n# print(farepp_survive_crosstbl)\n# calculate survivor rate for each farepp\nfarepp_survive_crosstbl = farepp_survive_crosstbl.divide(farepp_survive_crosstbl.sum(axis = 1), axis = 0)\n\nfarepp_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('FarePP_bins (data_train)')\nplt.ylabel('Survival Rate')\nplt.xticks(np.arange(0, 5), ('0~5', '5~10', '10~20', '20~30', '30~600'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8db8023b2b5cd08f007ed00cf14e9ca6fb807d99"},"cell_type":"markdown","source":"## Deck and Survive"},{"metadata":{"trusted":true,"_uuid":"bfb7fb9450d622c5697bd7243f1f4126696333f9"},"cell_type":"code","source":"# Extract Deck info from the Cabin column\ndata_train['Deck'] = data_train.Cabin.str.slice(0,1)\ndata_test['Deck'] = data_test.Cabin.str.slice(0,1)\n\n# visulize the relationship between deck and survive\ndeck_survive_crosstbl = pd.crosstab(data_train.Deck, data_train.Survived)\n\n# calculate survivor rate for each deck\ndeck_survive_crosstbl = deck_survive_crosstbl.divide(deck_survive_crosstbl.sum(axis = 1), axis = 0)\n\ndeck_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Deck (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5f5b5515c914f8db189885a6014216a6ca9434c"},"cell_type":"markdown","source":"## Embark and Survive"},{"metadata":{"trusted":true,"_uuid":"03e42aaf0862231548d63878d4b8521b65368cc3"},"cell_type":"code","source":"# visulize the relationship between embark and survive\nembark_survive_crosstbl = pd.crosstab(data_train.Embarked, data_train.Survived)\n\n# calculate survivor rate for each embark\nembark_survive_crosstbl = embark_survive_crosstbl.divide(embark_survive_crosstbl.sum(axis = 1), axis = 0)\n\nembark_survive_crosstbl.plot(kind = \"bar\", stacked = True)\nplt.xlabel('Embark (data_train)')\nplt.ylabel('Survival Rate')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e88f221fd062f1d6e93291ee6cd4be261de3ee6"},"cell_type":"markdown","source":"## Drop non-informative or redundant columns"},{"metadata":{"trusted":true,"_uuid":"39a262aa70759b6cc058e4b7ebe2a78cb46ec6bb"},"cell_type":"code","source":"# drop non-informative or redundant columns\nPassengerId_train = data_train.PassengerId\nPassengerId_test = data_test.PassengerId\n\ndata_train = data_train.drop(['PassengerId', 'Age', 'Ticket', 'Fare', 'Cabin', 'FarePP'], axis = 1)\ndata_test = data_test.drop(['PassengerId', 'Age', 'Ticket', 'Fare', 'Cabin', 'FarePP'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78369e673d8454a947c7cb05694c0119303d9314"},"cell_type":"code","source":"# check processed data (train)\ndata_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a27d70127a256570b016f91487da73f2acd20798"},"cell_type":"code","source":"# check processed data (test)\ndata_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ec038270bac3ed769d373ff49b88e7612587c1"},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{"trusted":true,"_uuid":"3f536e896dc14cc448649ad97d53a98a79a02825"},"cell_type":"code","source":"# one hot encoding for Pclass\nPclass_one_hot_train = pd.get_dummies(data_train['Pclass'], prefix='Pclass')\nPclass_one_hot_test = pd.get_dummies(data_test['Pclass'], prefix='Pclass')\n\n# one hot encoding for Sex\nSex_one_hot_train = pd.get_dummies(data_train['Sex'], prefix='Sex')\nSex_one_hot_test = pd.get_dummies(data_test['Sex'], prefix='Sex')\n\n# one hot encoding for SibSp\nSibSp_one_hot_train = pd.get_dummies(data_train['SibSp'], prefix='SibSp')\nSibSp_one_hot_test = pd.get_dummies(data_test['SibSp'], prefix='SibSp')\n\n# one hot encoding for Parch\nParch_one_hot_train = pd.get_dummies(data_train['Parch'], prefix='Parch')\nParch_one_hot_test = pd.get_dummies(data_test['Parch'], prefix='Parch')\n\n# one hot encoding for Embarked\nEmbarked_one_hot_train = pd.get_dummies(data_train['Embarked'], prefix='Embarked')\nEmbarked_one_hot_test = pd.get_dummies(data_test['Embarked'], prefix='Embarked')\n\n# one hot encoding for Title\nTitle_one_hot_train = pd.get_dummies(data_train['Title'], prefix='Title')\nTitle_one_hot_test = pd.get_dummies(data_test['Title'], prefix='Title')\n\n# one hot encoding for Age_bins\nAge_bins_one_hot_train = pd.get_dummies(data_train['Age_bins'], prefix='Age_bins')\nAge_bins_one_hot_test = pd.get_dummies(data_test['Age_bins'], prefix='Age_bins')\n\n# one hot encoding for famsz\nfamsz_one_hot_train = pd.get_dummies(data_train['famsz'], prefix='famsz')\nfamsz_one_hot_test = pd.get_dummies(data_test['famsz'], prefix='famsz')\n\n# one hot encoding for FarePP_bins\nFarePP_bins_one_hot_train = pd.get_dummies(data_train['FarePP_bins'], prefix='FarePP_bins')\nFarePP_bins_one_hot_test = pd.get_dummies(data_test['FarePP_bins'], prefix='FarePP_bins')\n\n# one hot encoding for Deck\nDeck_one_hot_train = pd.get_dummies(data_train['Deck'], prefix='Deck')\nDeck_one_hot_test = pd.get_dummies(data_test['Deck'], prefix='Deck')\n\n# join the data frames\n# for data_train\none_hot_train = pd.concat([Pclass_one_hot_train, Sex_one_hot_train, SibSp_one_hot_train,\n                           Parch_one_hot_train, Embarked_one_hot_train, Title_one_hot_train,\n                           Age_bins_one_hot_train, famsz_one_hot_train, FarePP_bins_one_hot_train,\n                          Deck_one_hot_train, data_train.Survived], axis = 1, sort = False)\n\n# for data_test\none_hot_test = pd.concat([Pclass_one_hot_test, Sex_one_hot_test, SibSp_one_hot_test,\n                           Parch_one_hot_test, Embarked_one_hot_test, Title_one_hot_test,\n                           Age_bins_one_hot_test, famsz_one_hot_test, FarePP_bins_one_hot_test,\n                          Deck_one_hot_test], axis = 1, sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b54f6b08507d142523ee80aa010e77e2acabc032"},"cell_type":"code","source":"# check if the columns are same between one_hot_train and one_hot_test\nset(list(one_hot_train)) ^ set(list(one_hot_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0457c4ad5d9c51e90174e0cab49ef858d704f620","scrolled":true},"cell_type":"code","source":"# check the one hot encoded data (train)\n# no Deck_T  & Title_Noble_male in data_test\none_hot_train = one_hot_train.drop('Deck_T', axis = 1)\none_hot_train = one_hot_train.drop('Title_Noble_male', axis = 1)\n\nprint(one_hot_train.shape)\none_hot_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"461a0b05b7ec876270028a77e7df6a9e730ec1e9","scrolled":false},"cell_type":"code","source":"# check the one hot encoded data (test)\n# no Parch_9 in the data_train\none_hot_test = one_hot_test.drop('Parch_9', axis = 1)\n\nprint(one_hot_test.shape)\none_hot_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53cf89ece91aa4e1d857e098ffad1e4680c8fc04"},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true,"_uuid":"5c63ce6390634d5672cec35ebfd3016142efb2fa"},"cell_type":"code","source":"# split data_train\ny = one_hot_train.Survived\nX = one_hot_train.drop('Survived', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2da0161169ce38bc998e1169f498f0b4f04ac0d0"},"cell_type":"markdown","source":"## XGBoost and Parameter Tuning"},{"metadata":{"trusted":true,"_uuid":"28ced44461ba019742c6643967c04d0d0cbf27c0"},"cell_type":"code","source":"# xgboost parameter tuning (RandomizedSearchCV)\n\nparams_xgb = {'min_child_weight': range(5,10),\n           'gamma': [i/10.0 for i in range(0,10, 2)],\n           'subsample': [i/10.0 for i in range(5, 10)],\n           'colsample_bytree': [i/10.0 for i in range(5, 10)],\n           'max_depth': range(5,10),\n           'n_estimators': [400, 600, 1000, 1500],\n           'learning_rate': [0.1, 0.01, 0.001]}\n\nmy_xgb = xgb.XGBClassifier(silent = 1, nthread = 1)\n\n# split train for parameter tuning\nskf = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 12)\n\n# tuning with random search\nrandom_search_xgb = RandomizedSearchCV(my_xgb, param_distributions = params_xgb,\n                                   n_iter = 10,\n                                   scoring = 'accuracy', n_jobs = 4,\n                                   cv = skf.split(X_train,y_train),\n                                   verbose = False, random_state = 12)\n\n# predict with tuned xgboost\nrandom_search_xgb.fit(X_train, y_train)\npredictions_xgb = random_search_xgb.predict(X_test)\n\n# accuracy check\naccuracy_xgb = accuracy_score(y_test, predictions_xgb)\n\nprecision_xgb = precision_score(y_test, predictions_xgb)\n\nprint('Accuracy (xgb): ', accuracy_xgb)\nprint('Precision (xgb): ', precision_xgb)\nprint('Best Parameters (xgb): ', random_search_xgb.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd288827e812504b5f73ba5a85bb4e764b26826c"},"cell_type":"markdown","source":"## LightGBM and Parameter Tuning"},{"metadata":{"trusted":true,"_uuid":"d249310331370bc065565db57047ccde3acb591b"},"cell_type":"code","source":"# lgbm parameter tuning (RandomizedSearchCV)\n\nparams_lgbm = {'max_depth' : range(5,10),\n               'num_leaves': [2**i for i in range(5, 10)],\n               'max_bin': [100, 300, 500],\n               'subsample_for_bin': [50, 100, 200],\n               'min_child_weight': range(5,10),\n               'min_child_samples': range(5,10),\n               'min_split_gain': [i/10.0 for i in range(0, 10)],\n               'colsample_bytree': [i/10.0 for i in range(5, 10)],\n               'n_estimators': [400, 600, 1000, 1500],\n               'subsample': [i/10.0 for i in range(5, 10)]}\n\nmy_lgbm = lgb.LGBMClassifier(boosting_type = 'dart', objective = 'binary', nthread = 1,\n                             learning_rate = 0.01, scale_pos_weight = 1.1,\n                             num_class = 1, metric = 'accuracy')\n\nrandom_search_lgbm = RandomizedSearchCV(my_lgbm, param_distributions = params_lgbm,\n                                   n_iter = 10,\n                                   scoring = 'accuracy', n_jobs = 4,\n                                   cv = skf.split(X_train,y_train),\n                                   verbose = False, random_state = 12)\n\n# predict with tuned lgbm\nrandom_search_lgbm.fit(X_train, y_train)\npredictions_lgbm = random_search_lgbm.predict(X_test)\n\n# classification_report(y_test, predictions)\naccuracy_lgbm = accuracy_score(y_test, predictions_lgbm)\nprecision_lgbm = precision_score(y_test, predictions_lgbm)\n\nprint('Accuracy: ', accuracy_lgbm)\nprint('Precision: ', precision_lgbm)\nprint('Best Parameters (lgbm): ', random_search_lgbm.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89bb3acefa839c74c091b3939c4fe6166c709053"},"cell_type":"markdown","source":"## Final Prediction"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"565fc992fbc12a936a2bc6f1fb2e3ab23ac03b72"},"cell_type":"code","source":"# make prediction for data_test\npredictions_xgb_test = random_search_xgb.predict(one_hot_test)\n\npredictions_xgb_test_df = pd.DataFrame({'PassengerId': PassengerId_test,\n                                         'Survived': predictions_xgb_test})\n\n# write the results\npredictions_xgb_test_df.to_csv('titanic_submission.csv', sep=',', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}