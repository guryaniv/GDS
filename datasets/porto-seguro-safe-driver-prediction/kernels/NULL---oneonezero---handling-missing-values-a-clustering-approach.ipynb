{"cells": [{"metadata": {"_cell_guid": "4a697c33-4596-47a1-9ffd-7e99b180c724", "_uuid": "cb634975920667213fcfcd5916aea4b760063139"}, "cell_type": "markdown", "source": ["I wanted to show you an idea I had about how to handle missing values. We'll use the porto seguro training data to see, how the idea works."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5c19625b-9f85-4811-8b12-a09d26189717", "_uuid": "786441f3e5d6f680c858145ca2d4654c6910b3b3"}, "source": ["import pandas as pd\n", "from sklearn.cluster import MiniBatchKMeans\n", "\n", "X = pd.read_csv(\"../input/train.csv\", na_values = -1)\n", "X.drop([\"id\", \"target\"], axis = 1, inplace = True)\n", "\n", "na_count = X.isnull().sum()\n", "na_columns = list(na_count[na_count>0].index.values)\n", "\n", "print(\"columns with missing values:\")\n", "print(na_columns)\n", "\n", "na_count.plot(kind = \"bar\")\n"]}, {"metadata": {"_cell_guid": "c1a99a4b-682b-41bb-b8d4-728f8c811061", "_uuid": "1e6651f327702df2c01e0dbcf31cd4a3d26be587"}, "cell_type": "markdown", "source": ["As you can see, there are some features with a lot of missing values. So how do we handle them? Normally, I would replace nominal values with the median of the not-missing values and categorical/binary features with the most common value of the not-missing values. Below I try something more..."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "aa2e7bc7-f9e8-4b85-892d-793823b98970", "_uuid": "a28d6fb195e724f2b6f492dc6a0d24d10b3f168f"}, "source": ["#create df only with columns with no missing values\n", "X_no_missing = X.drop(na_columns, axis = 1)\n", " \n", "#one hot encoding of categorical features\n", "cat_columns_no_missing = list(filter(lambda x: x.endswith(\"cat\"),\n", "                                     X_no_missing.columns.values))\n", "X_no_missing_oh = pd.get_dummies(X_no_missing, columns = cat_columns_no_missing)   "]}, {"metadata": {"_cell_guid": "097f37ed-e71e-43c5-b495-a289c5c0369b", "_uuid": "62ede25e4bcaf2db7a237602ebd3d3bfb2120f8a"}, "cell_type": "markdown", "source": ["So I drop all columns that contain missing values and then I use KMeans on the remaining columns to cluster the samples."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "36ef098b-acb0-442c-96f7-f2775de2c41e", "_uuid": "a725d65a9fd2d10df53b899da5ad3eaae4aa19d7"}, "source": ["#train kmeans\n", "kmeans = MiniBatchKMeans(n_clusters = 15, random_state = 0, batch_size = 2000)\n", "kmeans.fit(X_no_missing_oh)\n", "print(\"Clustersize: \\n\")\n", "print(pd.Series(kmeans.labels_).value_counts())\n", "\n", "#store cluster labels in df\n", "X[\"cluster\"] = kmeans.labels_"]}, {"metadata": {"_cell_guid": "ddc0c719-a720-409c-a4ce-59bca052a535", "_uuid": "246a343777d544ecd38668284a6d442bc4ce154d"}, "cell_type": "markdown", "source": ["We see that all clusters have approximately the same size. As a next step we loop over all columns containing missing values. For each column we drop the missing values and use the rest to calculate a replacement value. This would be the most common label for categorical/binary features and the median for nominal features. "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "fa3e7e0d-fbcd-4634-9488-97d152474834", "_uuid": "b4e1b8232dc99634df5a507fe13c20d5bc1e9455"}, "source": ["#for columns with missing values, drop missing values and find median or most common value - per cluster\n", "Values_replace_missing = pd.DataFrame()\n", "\n", "for i in na_columns:\n", "    clean_df = X[[\"cluster\", i]].dropna()\n", "    if i.endswith(\"cat\"):\n", "        Values_replace_missing[i] = clean_df.groupby([\"cluster\"]).agg(lambda x:x.value_counts().index.values[0])\n", "    else:\n", "        Values_replace_missing[i] = clean_df.groupby([\"cluster\"]).median() \n", "\n", "print(Values_replace_missing)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["As you can see, different clusters have different replacement values. This is especially prominent for \"ps_car_05_cat\". Now we have to replace the missing values with the ones we calculated above. "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "40bec42e-31b0-44a5-afc0-f6ec85dd6eea", "_uuid": "3d8467cd1f141bf87a9715f73eb83f5ee8567bf3"}, "source": ["    #replace missing values with median or most common value in the same cluster\n", "    for cl, cat in ((x, y) for x in range(15) for y in na_columns):\n", "        X.loc[(X[\"cluster\"] == cl) & pd.isnull(X[cat]), cat] = Values_replace_missing.loc[cl, cat]\n", "    \n", "    #print remaining missing values (should be zero)\n", "    print(\"\\n remaining missing values: \" + str(X.isnull().sum().sum()))"]}, {"metadata": {"collapsed": true, "_cell_guid": "9dede6d6-309d-465b-9f6f-0c1583a1d441", "_uuid": "135ec22982c57106038bcc7f2f733a958ff9969d"}, "cell_type": "markdown", "source": ["I have not tested the impact of this approach on the prediction quality but maybe this is interesting for you, too. So what do you think: does this approach make sense?"]}], "metadata": {"language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1, "nbformat": 4}