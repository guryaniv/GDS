{"cells":[{"metadata":{"_uuid":"6f06de1b48e35853f80eb1f3384baae8f8536b3c"},"cell_type":"markdown","source":"<h1><center><font size=\"6\">Santander EDA, PCA and Light GBM Classification Model</font></center></h1>\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg/640px-Another_new_Santander_bank_-_geograph.org.uk_-_1710962.jpg\"></img>\n\n<br>\n<b>\nIn this challenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data they have available to solve this problem. \nThe data is anonimyzed, each row containing 200 numerical values identified just with a number.</b>\n\n<b>Inspired by Jiwei Liu's Kernel. I added Data Augmentation Segment to my kernel</b>\n\n<pre>\n<a id='0'><b>Content</b></a>\n- <a href='#1'><b>Import the Data</b></a>\n- <a href='#11'><b>Data Exploration</b></a>  \n- <a href='#2'><b>Check for the missing values</b></a>  \n- <a href='#3'><b>Visualizing the Satendar Customer Transactions Data</b></a>   \n - <a href='#31'><b>Check for Class Imbalance</b></a>   \n - <a href='#32'><b>Distribution of Mean and Standard Deviation</b></a>   \n - <a href='#33'><b>Distribution of Skewness</b></a>   \n - <a href='#34'><b>Distribution of Kurtosis</b></a>   \n- <a href='#4'><b>Principal Component Analysis</b></a>\n - <a href='#41'><b>Kernel PCA</b></a>\n- <a href = \"#16\"><b>Data Augmentation</b></a>\n- <a href='#6'><b>Build the Light GBM Model</b></a></pre>"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport matplotlib\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold,KFold\nimport warnings\nfrom six.moves import urllib\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nplt.style.use('seaborn')\nfrom scipy.stats import norm, skew","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d150ae0e24acf7d0107ec64ccea13d9745ce45fc"},"cell_type":"markdown","source":"<a id=1><pre><b>Import the Data</b></pre></a>"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Load the Data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e711ea5576a8672fce378ede726be247aa789ef1"},"cell_type":"markdown","source":"<a id=11><pre><b>Data Exploration</b></pre></a>"},{"metadata":{"_uuid":"0ad0660223a680a8cc777c7526258759fface7a6","trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"217907a226a7e9425b4445805cde80c5de4feaca","trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90ca407e625a961a635fde6a21c9f524f024d654","trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"089309dd0b32db21b44152f4bb15b2c7765dfd87","trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3548150c4ae4ccd847d84baea5cba641f4fdc0bb"},"cell_type":"markdown","source":"<a id=2><b><pre>Check for the Missing Values.</pre></b></a> "},{"metadata":{"_uuid":"906ec8c811e2d415d47c7f67d8ac23bed0d8699b","trusted":true},"cell_type":"code","source":"#Check for Missing Values after Concatination\n\nobs = train.isnull().sum().sort_values(ascending = False)\npercent = round(train.isnull().sum().sort_values(ascending = False)/len(train)*100, 2)\npd.concat([obs, percent], axis = 1,keys= ['Number of Observations', 'Percent'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfe81109ea380b1210a3a6d50547058a4ee0e9b5"},"cell_type":"markdown","source":"<pre>There are no missing values in the dataset</pre>"},{"metadata":{"_uuid":"8d28011134ff59dc25080e743e028bb487b8c366"},"cell_type":"markdown","source":"<pre><a id = 3><b>Visualizing the Satendar Customer Transactions Data</b></a></pre>"},{"metadata":{"_uuid":"6abbb24cafc26afb4c6f8c52ab6b0353e2698f2e"},"cell_type":"markdown","source":"<pre><a id = 31 ><b>Check for Class Imbalance</b></a></pre>"},{"metadata":{"_uuid":"ada8973ebb427bbf9934a911095c1338b9036b35","trusted":true},"cell_type":"code","source":"target = train['target']\ntrain = train.drop([\"ID_code\", \"target\"], axis=1)\nsns.set_style('whitegrid')\nsns.countplot(target)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bcb709f47ab634bd7ebaa7a9f0574d571e2b30e"},"cell_type":"markdown","source":"<pre><a id = 32 ><b>Distribution of Mean and Standard Deviation</b></a></pre>\n\n<pre>EDA Reference : https://www.kaggle.com/gpreda/santander-eda-and-prediction</pre>"},{"metadata":{"_uuid":"60077579a9b2e2b92119d2cebbf29c301c3ee279","scrolled":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train and test set\")\nsns.distplot(train[features].mean(axis=1),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='test')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5f90ed3f3e3a6c21fd21e7891dd131a981e1f24"},"cell_type":"markdown","source":"<pre>Let's check the distribution of the mean of values per columns in the train and test datasets.</pre>"},{"metadata":{"_uuid":"4589fe2bb6b38c8f490057b6c2734aa1c8cf57a5","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train[features].mean(axis=0),color=\"black\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"red\", kde=True,bins=120, label='test')\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17a1f1bd380a50f59f2293071f1fd1cb85d4cace"},"cell_type":"markdown","source":"<pre>Distribution for Standard Deviation</pre>"},{"metadata":{"_uuid":"1119bbd9854b60c53eff0f5c024df241cf99a4ff","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of std values per rows in the train and test set\")\nsns.distplot(train[features].std(axis=1),color=\"blue\",kde=True,bins=120, label='train')\nsns.distplot(test[features].std(axis=1),color=\"green\", kde=True,bins=120, label='test')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e23ffd37c255be7b01aab8ef6b25d0bd4d2563f"},"cell_type":"markdown","source":"<pre>Let's check the distribution of the standard deviation of values per columns in the train and test datasets.</pre>"},{"metadata":{"_uuid":"734b96fd6a8aba302513797962498c906e299653","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train and test set\")\nsns.distplot(train[features].mean(axis=0),color=\"blue\", kde=True,bins=120, label='train')\nsns.distplot(test[features].mean(axis=0),color=\"green\", kde=True,bins=120, label='test')\nplt.legend();plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1200ca154b1928043b67fb114d7d0eb93bfbd7e7"},"cell_type":"markdown","source":"<pre>Let's check now the distribution of the mean value per row in the train dataset, grouped by value of target</pre>"},{"metadata":{"_uuid":"802622e99a858e7e1be8a56a0dcb32c217769736","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per row in the train set\")\nsns.distplot(t0[features].mean(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].mean(axis=1),color=\"green\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bae148d9255104a14c07b0075dbe67084039ada9"},"cell_type":"markdown","source":"<pre>Let's check now the distribution of the mean values per columns in the train and test datasets.</pre>"},{"metadata":{"_uuid":"5778c9b5a5b82264a02907471c98aba55e753cf9","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of mean values per column in the train set\")\nsns.distplot(t0[features].mean(axis=0),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].mean(axis=0),color=\"green\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfe2e017dbe64a93c707785b77a2f018c55d2a92"},"cell_type":"markdown","source":"<pre>Let's check now the distribution of the standard deviation  per row in the train dataset, grouped by value of target</pre>"},{"metadata":{"_uuid":"03d83a9f09460a7e0e64de7cff618fb903511eb5","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of standard deviation values per row in the train set\")\nsns.distplot(t0[features].std(axis=1),color=\"blue\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].std(axis=1),color=\"red\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0796b8aa04186d551ae3d92d28e18a548dc09e51"},"cell_type":"markdown","source":"<pre>Let's check now the distribution of standard deviation per columns in the train and test datasets.</pre>"},{"metadata":{"_uuid":"8fe584abb584e77e654eb6c768b42eeafda6b784","trusted":true},"cell_type":"code","source":"t0 = train.loc[target  == 0]\nt1 = train.loc[target  == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of standard deviation values per column in the train set\")\nsns.distplot(t0[features].std(axis=0),color=\"blue\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].std(axis=0),color=\"red\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61fb22a8fdac069232e1584d97e02ca6348c7eea"},"cell_type":"markdown","source":"<pre><a id = 33 ><b>Distribution of Skewness</b></a></pre>\n\n<pre>Let's see now the distribution of skewness on rows in train separated for values of target 0 and 1. We found the distribution is left skewed</pre>"},{"metadata":{"_uuid":"a353fcf6b2ce7db7d6c693a2761bc8ac0e005309","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per row in the train set\")\nsns.distplot(t0[features].skew(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].skew(axis=1),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a0d204c325a9b78ff5b242e3b23043645040499"},"cell_type":"markdown","source":"<pre>Let's see now the distribution of skewness on columns in train separated for values of target 0 and 1.</pre>"},{"metadata":{"_uuid":"e47c1c00db66e3f43c65efad776bd2bcbea8117d","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of skew values per column in the train set\")\nsns.distplot(t0[features].skew(axis=0),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].skew(axis=0),color=\"blue\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52dc95b188e82d5e55503348b8db57abfb385ca2"},"cell_type":"markdown","source":"<pre><a id = 34 ><b>Distribution of Kurtosis</b></a></pre>"},{"metadata":{"_uuid":"b3d635fc2ccd5d0ad662413ccff46e062a01a13c"},"cell_type":"markdown","source":"<pre>Let's see now the distribution of kurtosis on rows in train separated for values of target 0 and 1. We found the distribution to be Leptokurtic</pre>"},{"metadata":{"_uuid":"a0785f3344f18166d838b50ecfb05901ad2180c8","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of kurtosis values per row in the train set\")\nsns.distplot(t0[features].kurtosis(axis=1),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].kurtosis(axis=1),color=\"green\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"736f0bde864b3bf327be491a0d820593415aa3f5"},"cell_type":"markdown","source":"<pre>Let's see now the distribution of kurtosis on columns in train separated for values of target 0 and 1.</pre>"},{"metadata":{"_uuid":"8b72cdd5a6f9b1db419fdd35e44974e219a9d376","trusted":true},"cell_type":"code","source":"t0 = train.loc[target == 0]\nt1 = train.loc[target == 1]\nplt.figure(figsize=(16,6))\nplt.title(\"Distribution of kurtosis values per column in the train set\")\nsns.distplot(t0[features].kurtosis(axis=0),color=\"red\", kde=True,bins=120, label='target = 0')\nsns.distplot(t1[features].kurtosis(axis=0),color=\"green\", kde=True,bins=120, label='target = 1')\nplt.legend(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"374e9be094d1adaf17888cb16aea2f10093edd9e"},"cell_type":"markdown","source":"<a id=4><pre><b>Principal Component Analysis to check Dimentionality Reduction<b></pre></a>"},{"metadata":{"_uuid":"0af73d37cc75d3685fcb5f8c2702ad8758070b94","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ntrain_scaled = scaler.fit_transform(train)         \nPCA_train_x = PCA(2).fit_transform(train_scaled)\nplt.scatter(PCA_train_x[:, 0], PCA_train_x[:, 1], c=target, cmap=\"copper_r\")\nplt.axis('off')\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2482fcb3497bcc3b7fe7f27256e408ff98324de2"},"cell_type":"markdown","source":"<pre><a id = 41><b>Kernel PCA (Since the Graph above doesn't represent meaningful analysis)</b></a></pre>"},{"metadata":{"_uuid":"9206e909ab4be625c94811af6bd0b676f626de22","trusted":true},"cell_type":"code","source":"from sklearn.decomposition import KernelPCA\n\nlin_pca = KernelPCA(n_components = 2, kernel=\"linear\", fit_inverse_transform=True)\nrbf_pca = KernelPCA(n_components = 2, kernel=\"rbf\", gamma=0.0433, fit_inverse_transform=True)\nsig_pca = KernelPCA(n_components = 2, kernel=\"sigmoid\", gamma=0.001, coef0=1, fit_inverse_transform=True)\n\n\nplt.figure(figsize=(11, 4))\nfor subplot, pca, title in ((131, lin_pca, \"Linear kernel\"), (132, rbf_pca, \"RBF kernel, $\\gamma=0.04$\"), \n                            (133, sig_pca, \"Sigmoid kernel, $\\gamma=10^{-3}, r=1$\")):\n       \n    PCA_train_x = PCA(2).fit_transform(train_scaled)\n    plt.subplot(subplot)\n    plt.title(title, fontsize=14)\n    plt.scatter(PCA_train_x[:, 0], PCA_train_x[:, 1], c=target, cmap=\"nipy_spectral_r\")\n    plt.xlabel(\"$z_1$\", fontsize=18)\n    if subplot == 131:\n        plt.ylabel(\"$z_2$\", fontsize=18, rotation=0)\n    plt.grid(True)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b7a96339294daeedba94abaee4fbe6f16e69f2e"},"cell_type":"markdown","source":"<pre>Since PCA hasn't been useful, I decided to proceed with the existing dataset</pre>"},{"metadata":{"_uuid":"96861473dd6cb2de3377a47684ece1714e1ab072"},"cell_type":"markdown","source":"<pre><a id = 16><b>Data Augmentation</b></a></pre>"},{"metadata":{"trusted":true,"_uuid":"dfd26c446ff80f323791fbdbbbf158d355ee7267"},"cell_type":"code","source":"def augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a37f046be743d0086a2fc6094d78d7b9cab78055"},"cell_type":"markdown","source":"<pre><a id = 6><b>Build the Light GBM Model</b></a></pre>"},{"metadata":{"_uuid":"d418b9c44ef2f96b02db44d70aacbca61fe0952f","trusted":true},"cell_type":"code","source":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.335,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.041,\n    'learning_rate': 0.0083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': -1\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc22f099688ce4928a44f1c68cd16d6b8473e207","trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b4f1d5f4aef4730673a8a6bbb2e828c2f92e2a5","trusted":true},"cell_type":"code","source":"num_folds = 11\nfeatures = [c for c in train.columns if c not in ['ID_code', 'target']]\n\nfolds = KFold(n_splits=num_folds, random_state=2319)\noof = np.zeros(len(train))\ngetVal = np.zeros(len(train))\npredictions = np.zeros(len(target))\nfeature_importance_df = pd.DataFrame()\n\nprint('Light GBM Model')\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n    \n    X_train, y_train = train.iloc[trn_idx][features], target.iloc[trn_idx]\n    X_valid, y_valid = train.iloc[val_idx][features], target.iloc[val_idx]\n    \n    X_tr, y_tr = augment(X_train.values, y_train.values)\n    X_tr = pd.DataFrame(X_tr)\n    \n    print(\"Fold idx:{}\".format(fold_ + 1))\n    trn_data = lgb.Dataset(X_tr, label=y_tr)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    \n    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    getVal[val_idx]+= clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration) / folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9dc76139cb15edf957be0a8400e6de33c14e655"},"cell_type":"code","source":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(14,26))\nsns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"137cf3c3924422e1a15ac63f4e259b86db86c2c5","trusted":true},"cell_type":"code","source":"num_sub = 26\nprint('Saving the Submission File')\nsub = pd.DataFrame({\"ID_code\": test.ID_code.values})\nsub[\"target\"] = predictions\nsub.to_csv('submission{}.csv'.format(num_sub), index=False)\ngetValue = pd.DataFrame(getVal)\ngetValue.to_csv(\"Validation_kfold.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}