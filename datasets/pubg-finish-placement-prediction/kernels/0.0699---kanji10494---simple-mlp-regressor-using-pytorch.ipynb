{"cells":[{"metadata":{"_uuid":"43e6e0e563cc21093b917935db99104d232ce9cb"},"cell_type":"markdown","source":"# Build Simple MLP Regressor using PyTorch"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"130f6d97ac1dc13b863ce185b84a42dea9c2c6b0"},"cell_type":"markdown","source":"Train data consists of 26 columns and more than 4 million rows.\n\nThis time, we use all variable except ids to predict winPlacePerc."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train_V2.csv\")\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0ed7f4e5162b999dad4742c9990a80c6be03dc5"},"cell_type":"code","source":"#device setting\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0046b0e60103372ced229620034c3813f3887940"},"cell_type":"code","source":"#defining utility class\n#by defining this, you only have to write \"for loop\" to load minibatch data\nclass DataLoader(object):\n    def __init__(self, x, y, batch_size=128, shuffle=True):\n        self.x = x\n        self.y = y\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.start_idx = 0\n        self.data_size = x.shape[0]\n        if self.shuffle:\n            self.reset()\n    \n    def reset(self):\n        self.x, self.y = shuffle(self.x, self.y)\n    \n    def __iter__(self):\n        return self\n    \n    def __next__(self):\n        if self.start_idx >= self.data_size:\n            if self.shuffle:\n                self.reset()\n            self.start_idx = 0\n            raise StopIteration\n    \n        batch_x = self.x[self.start_idx:self.start_idx+self.batch_size]\n        batch_y = self.y[self.start_idx:self.start_idx+self.batch_size]\n\n        batch_x = torch.tensor(batch_x, dtype=torch.float, device=device)\n        batch_y = torch.tensor(batch_y, dtype=torch.float, device=device)\n\n        self.start_idx += self.batch_size\n\n        return (batch_x,batch_y)\n\n#defining MLP model\n#generally out_dim is more than 1, but this model only allows 1.\nclass MLP(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim=1):\n        super(MLP, self).__init__()\n        \n        assert out_dim==1, 'out_dim must be 1'\n        \n        self.in_dim = in_dim\n        self.hidden_dim = hidden_dim\n        self.out_dim = out_dim\n        self.linear1 = nn.Linear(self.in_dim, self.hidden_dim)\n        self.linear2 = nn.Linear(self.hidden_dim, self.out_dim)\n    \n    def forward(self, x):\n        x = torch.tanh(self.linear1(x))\n        x = torch.sigmoid(self.linear2(x))\n        x = x.squeeze(1)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbfcd6b2714108f06e0f077ca74a71202af9de4c"},"cell_type":"code","source":"#data formatting\ny = train.winPlacePerc\nx = train.drop(['Id', 'groupId', 'matchId', 'matchType', 'winPlacePerc'], axis=1)\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2)\n\n# pd.DataFrame to np.ndarray\nx_train = x_train.values\ny_train = y_train.values\nx_valid = x_valid.values\ny_valid = y_valid.values\nassert isinstance(x_train, np.ndarray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fde98fbe15694cadd022a8cb62d964243a152ce"},"cell_type":"code","source":"#instantiate model\nmlp = MLP(x_train.shape[1], 200, 1).to(device)\noptimizer = optim.Adam(mlp.parameters())\ntrain_dataloader = DataLoader(x_train, y_train, batch_size=4000)\nvalid_dataloader = DataLoader(x_valid, y_valid, batch_size=4000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2681f0ab2d3746b83cdc7f6a400649e112b33f5a"},"cell_type":"code","source":"#this model learns to minimize MAE\ndef mae_loss(y_pred, y_true):\n    mae = torch.abs(y_true - y_pred).mean()\n    return mae","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a5d9f8e4fc19163547c54957505864eb64d88fb","scrolled":false},"cell_type":"code","source":"#training phase\nepochs = 20\n#to plot loss curve after training\nvalid_losses = []\n\nfor epoch in range(epochs):\n    start_time = time.time()\n    mlp.train()\n    num_batch = train_dataloader.data_size // train_dataloader.batch_size + 1\n    \n    for batch_id, (batch_x, batch_y) in enumerate(train_dataloader):\n        \n        y_pred = mlp(batch_x)\n\n        loss = mae_loss(y_pred, batch_y)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        elapsed_time = time.time() - start_time\n        elapsed_min = int(elapsed_time / 60)\n        elapsed_sec = elapsed_time - 60 * elapsed_min\n\n        print('\\rEpoch:{} Batch:{}/{} Loss:{:.4f} Time:{}m{:.2f}s'.format(epoch + 1, batch_id, \n                                                                          num_batch, loss.item(),\n                                                                          elapsed_min, elapsed_sec), end='')\n    print()\n    mlp.eval()\n    valid_loss = 0\n    best_loss = np.inf\n    num_batch = valid_dataloader.data_size // valid_dataloader.batch_size + 1\n    \n    for batch_id, (batch_x, batch_y) in enumerate(valid_dataloader):\n    \n        y_pred = mlp(batch_x)\n        loss = mae_loss(y_pred, batch_y)\n        valid_loss += loss.item()\n    \n    valid_loss /= num_batch\n    valid_losses.append(valid_loss)\n    \n    #save model when validation loss is minimum\n    if valid_loss < best_loss:\n        best_loss = valid_loss\n        torch.save(mlp.state_dict(), 'mlp.model')  \n    \n    print('Valid Loss:{:.4f}'.format(valid_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c40c5a19c4ac7d8ef81dfe804311b38ed178b761"},"cell_type":"code","source":"#plot validation loss curve, this may help to notice overfitting\nplt.figure(figsize=(16,5))\nplt.ylim(0,max(valid_losses)+0.02)\nplt.plot(valid_losses)\nprint('minimum validation loss is {:.4f}'.format(min(valid_losses)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d69a757bd9a1ade2db103b7f0c48ff7dbe0419f"},"cell_type":"markdown","source":"Let's submit prediction by this model."},{"metadata":{"trusted":true,"_uuid":"5b368898a3a10a3b71c95c48b5e853c856f0e6b6"},"cell_type":"code","source":"#load the best model\nmlp.load_state_dict(torch.load('mlp.model'))\n\ntest = pd.read_csv('../input/test_V2.csv')\n#data formatting\nx_test = test.drop(['Id', 'groupId', 'matchId', 'matchType'],axis=1)\nx_test = torch.tensor(x_test.values,dtype=torch.float,device=device)\n\n#predict\ny_pred = mlp(x_test)\ny_pred = y_pred.data.cpu().numpy()\n\n#format to csv file\ny_pred = pd.DataFrame(y_pred,columns=['winPlacePerc'])\ny_pred['Id'] = test['Id']\ny_pred = y_pred[['Id', 'winPlacePerc']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b368898a3a10a3b71c95c48b5e853c856f0e6b6"},"cell_type":"code","source":"y_pred.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fab1c91b8f8ee0c27cec15322de916b3978ab0d5"},"cell_type":"code","source":"!head submission.csv","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}