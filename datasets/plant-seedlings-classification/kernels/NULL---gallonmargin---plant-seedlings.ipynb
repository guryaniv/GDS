{"cells": [{"execution_count": null, "metadata": {"_cell_guid": "b7aee221-a97f-4b1f-8c00-4a5e43fa3ca9", "_uuid": "752b2fa19147063c016636c65d8fa6c8ab324dab", "collapsed": true}, "cell_type": "code", "source": ["%matplotlib inline\n", "\n", "import matplotlib.pyplot as plt\n", "import tensorflow as tf\n", "import pandas as pd \n", "import numpy as np \n", "import skimage\n", "import scipy as sp\n", "import time\n", "import cv2\n", "import os\n", "\n", "\n", "from subprocess import check_output\n", "from sklearn.feature_extraction.image import grid_to_graph\n", "from sklearn.cluster import AgglomerativeClustering\n", "from sklearn.utils.testing import SkipTest\n", "from sklearn.utils.fixes import sp_version\n", "from skimage import transform\n", "from tensorflow import keras\n", "from scipy import misc\n", "from PIL import Image, ImageOps\n", "from glob import glob"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "a782f2f6-3c7f-4882-9ee6-0e8ee8fd1ad2", "_uuid": "758553d5639bf3fd288028dede32122469bdb9be", "collapsed": true}, "cell_type": "code", "source": ["CLASSES = check_output([\"ls\",\"../input/train\"]).decode(\"utf8\").strip().split(\"\\n\")\n", "NUM_CLASSES = len(CLASSES)"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "5a1d972b-2664-4347-9e11-e84350481c1b", "_uuid": "fb48f59920dd77478ac8b98cde4f2e31b2b156b4", "collapsed": true}, "cell_type": "code", "source": ["data_dir = '../input/'\n", "train_dat = os.path.join(data_dir, 'train')\n", "test_dat = os.path.join(data_dir, 'test')\n", "sample_dat = pd.read_csv(os.path.join(data_dir,'sample_submission.csv'))"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "7ff4bc2a-c40c-4ccc-a012-a707267dab39", "_uuid": "0315a6d7d7f59b57b36beaa5cce5d195bff65a57", "collapsed": true}, "cell_type": "code", "source": ["dir_list = []\n", "for c in CLASSES:\n", "    files = check_output([\"ls\", \"../input/train/%s\" % c]).decode(\"utf8\").strip().split(\"\\n\")\n", "    dir_list.append(files)\n", "\n", "df = pd.DataFrame({\"n_images\": [len(x) for x in dir_list]},\n", "                  index=CLASSES).sort_values(['n_images'],\n", "                                             ascending=False,\n", "                                             kind='mergesort')"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "08b725de-b19b-4edd-8d01-83f7aca3daa6", "_uuid": "b33e2ac2a71fc6d726ed23002770462eba76ef1a", "collapsed": true}, "cell_type": "code", "source": ["train = []\n", "for category_id, category in enumerate(CLASSES):\n", "    for file in os.listdir(os.path.join(train_dat,category)):\n", "        train.append(['train/{}/{}'.format(category,file),category_id,category])\n", "train = pd.DataFrame(train,columns=['file','category_id','category'])"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "f489f1d8-fa4e-41e1-9b15-d8fbdeefeebb", "_uuid": "09c82c4cf70ecd8b7cec1c1db41ae6ba1f4c045f", "collapsed": true}, "cell_type": "code", "source": ["images = {}\n", "for class_folder_name in os.listdir(train_dat):\n", "    class_folder_path = os.path.join(train_dat, class_folder_name)\n", "    class_label = class_folder_name\n", "    images[class_label] = []\n", "    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n", "        image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n", "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n", "        images[class_label].append(image_bgr)"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "a0782a4a-b9bc-4300-85f5-c0aa2a81c167", "_uuid": "d8dd6a94772c034c1f2aa604ddfaabce74715128"}, "cell_type": "code", "source": ["for key,value in images.items():\n", "    print(\"{0} -> {1}\".format(key,len(value)))\n", "num_cats = len(images)\n", "classes = [ctype for ctype in images]"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "c1b25627-5b07-40e7-a951-15542e8a33cd", "_uuid": "c4b3b355518954659794f82323b2580a77096493"}, "cell_type": "code", "source": ["def plot_for_class(label):\n", "    nb_rows = 3\n", "    nb_cols = 3\n", "    fig, axs = plt.subplots(nb_rows, nb_cols, figsize=(6,6))\n", "    \n", "    n = 0\n", "    for i in range(0, nb_rows):\n", "        for j in range(0,nb_cols):\n", "            axs[i, j].xaxis.set_ticklabels([])\n", "            axs[i, j].yaxis.set_ticklabels([])\n", "            axs[i, j].imshow(images[label][n])\n", "            n += 1"], "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "10ec2d9a-b49a-423b-806e-c544eca70d56", "_uuid": "01890d616c5696f985a24e9cb1d4a64be6f569ce", "collapsed": true}, "cell_type": "code", "source": ["def create_mask_for_plant(image):\n", "    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n", "    \n", "    sensitivity = 35\n", "    lower_hsv = np.array([60 - sensitivity, 100, 50])\n", "    upper_hsv = np.array([60 + sensitivity, 255, 255])\n", "    \n", "    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n", "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n", "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n", "    \n", "    return mask\n", "\n", "def segment_plant(image):\n", "    mask = create_mask_for_plant(image)\n", "    output = cv2.bitwise_and(image, image, mask = mask)\n", "    return output\n", "\n", "def sharpen_image(image):\n", "    image_blurred = cv2.GaussianBlur(image, (0,0) ,3)\n", "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n", "    return image_sharp\n", "\n", "def deskew(image):\n", "    m = cv2.moments(image)\n", "    if abs(m['mu02']) < 1e-2:\n", "        return image.copy()\n", "    skew = m['mu11']/m['mu02']\n", "    M = np.float32([[1,skew,-0.5*SZ*skew], [0,1,0]])\n", "    image = cv2.warpAffine(img, M, (SZ,SZ), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n", "    return img"], "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["def find_contours(mask_image):\n", "    return cv2.findContours(mask_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n", "\n", "def calculate_largest_contour_area(contours):\n", "    if len(contours) == 0:\n", "        return 0\n", "    c = max(contours, key=cv2.contourArea)\n", "    return cv2.contourArea(c)\n", "\n", "def calculate_contours_area(contours, min_contour_area = 250):\n", "    area = 0\n", "    for c in contours:\n", "        c_area = cv2.contourArea(c)\n", "        if c_area >= min_contour_area:\n", "            area += c_area\n", "    return area"], "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["areas = []\n", "largest_contour_area = []\n", "labels = []\n", "nb_of_contours = []\n", "\n", "for classes in images.keys():\n", "    for image in images[classes]:\n", "        mask = create_mask_for_plant(image)\n", "        contours = find_contours(mask)\n", "        \n", "        area = calculate_contours_area(contours)\n", "        largest_area = calculate_largest_contour_area(contours)\n", "        \n", "        areas.append(area)\n", "        nb_of_contours.append(len(contours))\n", "        largest_contour_area.append(largest_area)\n", "        labels.append(classes)"], "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": ["features_df = pd.DataFrame()\n", "features_df[\"label\"] = labels\n", "features_df[\"area\"] = areas\n", "features_df[\"largest_area\"] = largest_contour_area\n", "features_df[\"number_of_components\"] = nb_of_contours"], "outputs": []}, {"execution_count": null, "metadata": {}, "cell_type": "code", "source": ["features_df.groupby(\"label\").describe()"], "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3"}}, "nbformat_minor": 1, "nbformat": 4}