{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import *\nfrom collections import Counter\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsub = pd.read_csv('../input/sample_submission.csv').rename(columns={'Predicted': 'Predicted2'})\notrain = datasets.fetch_20newsgroups(subset='train')\notrain = pd.DataFrame({'Id': otrain['filenames'], 'text': otrain['data'], 'target': otrain['target']})\notrain['Id'] = otrain['Id'].map(lambda x: x.split('/')[-1])\notest = datasets.fetch_20newsgroups(subset='test')\notest = pd.DataFrame({'Id': otest['filenames'], 'text': otest['data'], 'target': otest['target']})\notest['Id'] = otest['Id'].map(lambda x: x.split('/')[-1])\ntrain.shape, otrain.shape, test.shape, otest.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11860b0ddae90a027703a05f7fd93e741748827e","trusted":false},"cell_type":"code","source":"otrain_ = []\nfor i in range(len(otrain)):\n    t = str(otrain['text'][i]).replace('\\n', '\\n ')\n    for j in range(0, len(t), 300):\n        otrain_.append([otrain['Id'][i] + '_' + str(int(j/300)).zfill(3), t[j: j+300], otrain['target'][i]])\notrain = pd.DataFrame(otrain_, columns=['Id', 'text', 'target'])\notest_ = []\nfor i in range(len(otest)):\n    t = str(otest['text'][i]).replace('\\n', '\\n ')\n    for j in range(0, len(t), 300):\n        otest_.append([otest['Id'][i] + '_' + str(int(j/300)).zfill(3), t[j: j+300], otest['target'][i]])\notest = pd.DataFrame(otest_, columns=['Id', 'text', 'target'])\notrain = pd.concat((otrain, otest)).reset_index(drop=True)\nlen(otrain), len(train) + len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cafa87990fdc83ab94569709d504d470bb2310c8"},"cell_type":"code","source":"train_d = {}\npattern = {}\ntrain_d[0] = Counter(' '.join(otrain['text'].astype(str).values))\npattern[0] = ''.join([c for c, v in train_d[0].most_common(100)])\nprint(0, repr(pattern[0]))\n\nfor i in range(1,5):\n    train_d[i] = train[train['difficulty']==i].copy()\n    train_d[i] = Counter(' '.join(train_d[i]['ciphertext'].astype(str).values))\n    pattern[i] = ''.join([c for c, v in train_d[i].most_common(100)])\n    print(i, repr(pattern[i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c4b358fb739d5b9705f960aed5ff7b875dff511","trusted":false},"cell_type":"code","source":"def SubEnc(s, level):\n    s = str(s)\n    for i in range(level,0, -1):\n        s1 = pattern[i]\n        s2 = pattern[i-1]\n        SubEnc_ = str.maketrans(s1, s2)\n        s = s.translate(SubEnc_)\n    return s","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb11b8b0e2077b0f0d79220c347ef5a22fc01e89","trusted":false},"cell_type":"code","source":"for i in range(1,5):\n    train['ciphertext'] = train.apply(lambda r: SubEnc(r['ciphertext'], i) if r['difficulty'] == i else r['ciphertext'], axis=1)\n    test['ciphertext'] = test.apply(lambda r: SubEnc(r['ciphertext'], i) if r['difficulty'] == i else r['ciphertext'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8fcd5ad944437e7cbbb1b605a8b0e8642249f04","trusted":false},"cell_type":"code","source":"train_d1 = train[train['difficulty']==1].copy()\ntrain_d1['len'] = train_d1['ciphertext'].map(len)\ntrain_d1[train_d1['len']==224].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dfdbef3d364c795df4d341e014e0e85e6b5467e","trusted":false},"cell_type":"code","source":"otrain['len'] = otrain['text'].map(len)\notrain[((otrain['text'].str.contains('not provided a service for the co')) & (otrain['target']==18))].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"37d5adda249950956ef5696b8886973405020349"},"cell_type":"code","source":"#Use a word dictionary to fine tune the mappings\nspelling_dict = Counter(' '.join(otrain['text'].astype(str).values).split(' '))\n#[w for w in train_d1[train_d1['len']==224]['ciphertext'].values[0].split(' ') if w not in spelling_dict]\n#set([w for w in otrain[((otrain['text'].str.contains('not provided a service for the co')) & (otrain['target']==18))]['text'].values[0].split(' ')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d518ec7d2ea5f426b8ca8ae35b204dea8d6cdf19","trusted":false},"cell_type":"code","source":"results = []\nfor d in range(1,5):\n    train_d = train[train['difficulty']==d].reset_index(drop=True)\n    test_d = test[test['difficulty']==d].reset_index(drop=True)\n    tfidf = feature_extraction.text.TfidfVectorizer(analyzer = 'char_wb', ngram_range=(1, 7), lowercase=False) \n    tfidf.fit(pd.concat((train_d['ciphertext'], test_d['ciphertext'])))\n    trainf = tfidf.transform(train_d['ciphertext'])\n    testf = tfidf.transform(test_d['ciphertext'])\n    clf = linear_model.LogisticRegression(tol=0.001, C=10.0, random_state=0, solver='sag', max_iter=90, multi_class='auto', n_jobs=-1)\n    clf.fit(trainf, train_d['target'])\n    print(d, metrics.accuracy_score(train_d['target'], clf.predict(trainf)))\n    test_d['Predicted'] = clf.predict(testf)\n    results.append(test_d)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea22d8e11098af085768074236ccc50c44dc9f5d","trusted":false},"cell_type":"code","source":"test = pd.concat(results)\nsub = pd.merge(sub,test, how='left', on=['Id'])\nsub[['Id','Predicted']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"beed4d89c7d569891bfdb1b3879e1621453f84d3"},"cell_type":"code","source":"for i in range(1,5):\n    print(i, repr(SubEnc('V8g{9827\\\f$A${?^*?}$$v7\u0010*.yig$w9.8}', i)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}