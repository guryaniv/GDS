{"cells":[{"metadata":{"_cell_guid":"9d4426fc-abb8-422d-9722-3314dd2af7a7","_uuid":"4ccb138ab7fc232e384bf56c3449c6e3529ad7f2"},"cell_type":"markdown","source":"<h1>Welcome to my exploration of Credit Card fraud!</h1>\n\nIn this kernel I will do some explorations trying to understand the fraud transaction patterns and them I will implement some models of machine learning.<br>\n\nI will implement technique an technique called SMOTE, supervised models, semi supervised learning algorithms and a deep learning model."},{"metadata":{"_cell_guid":"8273d335-3adf-448e-ab80-17b147c31187","_uuid":"a981865961fc75753c653c3f681ab49222492a65"},"cell_type":"markdown","source":"*English is not my first language, consider if you find language mistakes* <br>\n"},{"metadata":{"_cell_guid":"7ebc9631-71d3-45bd-95df-0880c2254365","_uuid":"0e1564cf054ef74dd12a28d3c1badd694c82fe3e"},"cell_type":"markdown","source":"<h2>Introduction to Dataset</h2>\n\nThe datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\nGiven the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n\nThe dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection. More details on current and past projects on related topics are available on http://mlg.ulb.ac.be/BruFence and http://mlg.ulb.ac.be/ARTML\n\nPlease cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015"},{"metadata":{"_uuid":"0061bfdd1f27ca8a06fcb7aceb8ebb3bc9151f82"},"cell_type":"markdown","source":"## OBJECTIVE\n\nI will explore the data distribuition as this is almost all numerical features that was standrized.\n\nI will use this Kernel to implement some models of machine learning as Study to practical to me. This is the main objective.\n\n\n# Please, if you think that I can do anything in a better way, I will be very greatful for your feedback."},{"metadata":{"_cell_guid":"a42c9966-0ce2-4bc6-ae01-15f097f0aad2","_uuid":"1088412396ca645640aa2813a139d6ad51242e4c"},"cell_type":"markdown","source":"<h2>Let's start importing the librarys and looking the data</h2>"},{"metadata":{"_cell_guid":"315d90fc-06e1-4f99-987b-30837586526a","_uuid":"bf775109c304a96f3b7f1661016d3c075a61344b","trusted":true},"cell_type":"code","source":"import pandas as pd #To hand with data \nimport numpy as np #To math \nimport seaborn as sns #to visualization\nimport matplotlib.pyplot as plt # to plot the graphs\nimport matplotlib.gridspec as gridspec # to do the grid of plots","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5ed2e58-2c04-45b9-8b64-a5fd9a211d51","_uuid":"f1c7b54c4dc02147ce064826491c8b678f13a358","trusted":true},"cell_type":"code","source":"#loading the data\ndf_credit = pd.read_csv(\"../input/creditcard.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d102b02e-6bcf-412c-9eef-fb6aecace766","_uuid":"90de510bdbadedd87abdc59575b62a396b1c1e8b","trusted":true},"cell_type":"code","source":"#looking the how data looks\ndf_credit.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddd5b399-18a1-4f81-873b-b97d2be23f67","_uuid":"56f1c343acf06abb567c5909521334e5adc57308","trusted":true},"cell_type":"code","source":"#looking the type and searching for null values\ndf_credit.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6c26e0db-71da-413b-85e9-5618851fe465","_uuid":"8566d352da4e500f1a64e14e660adfe9cea2910f","trusted":true},"cell_type":"code","source":"# The data is stardarized, I will explore them later\n#For now I will look the \"normal\" columns\ndf_credit[[\"Time\",\"Amount\",\"Class\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08736ed3-7bb7-42e6-b9f3-ead80381b96c","_uuid":"06030ed2623c7f97254aecdb39c8e86011b44b5f"},"cell_type":"markdown","source":"<h2>Firstly, I will explore through 3 different columns:</h2>\n- Time\n- Amount\n- Class"},{"metadata":{"_cell_guid":"b3220b5c-f3db-4553-9a76-ccb1347d5291","_uuid":"af843d503f5b3f0e1b049d973ec060cee4db52d9","trusted":true},"cell_type":"code","source":"#Lets start looking the difference by Normal and Fraud transactions\nprint(\"Distribuition of Normal(0) and Frauds(1): \")\nprint(df_credit[\"Class\"].value_counts())\n\nplt.figure(figsize=(7,5))\nsns.countplot(df_credit['Class'])\nplt.title(\"Class Count\", fontsize=18)\nplt.xlabel(\"Is fraud?\", fontsize=15)\nplt.ylabel(\"Count\", fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f795ba35-6d76-4cdb-a328-8032f955196d","_uuid":"f8977ab9fd2d8c6a21ef3d6a54dced776733776b"},"cell_type":"markdown","source":"We have a clearly imbalanced data.<br>\nIt's very common when treating of frauds... <br>\n\n<b>First</b> I will do some explore through the Time and Amount. <br>\n<b>Second</b> I will explore the V's Features, that are PCA's "},{"metadata":{"_uuid":"1bfeb2f6bb9db6c977e7541c86c1d56616f5c227"},"cell_type":"markdown","source":"## Time Features and some Feature Engineering\nAs our Time feature are in seconds we will transform it ot minutes and hours to get a better understand of the patterns"},{"metadata":{"trusted":true,"_uuid":"e7c0e7464c10ba7c24c3bdc2738e2dab895b758d"},"cell_type":"code","source":"timedelta = pd.to_timedelta(df_credit['Time'], unit='s')\ndf_credit['Time_min'] = (timedelta.dt.components.minutes).astype(int)\ndf_credit['Time_hour'] = (timedelta.dt.components.hours).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9fa298be-50da-4951-833b-b5b5e402dea6","_uuid":"6fd743122a71a772111d9dde1ac4626750b649ab","trusted":true},"cell_type":"code","source":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(df_credit[df_credit['Class'] == 0][\"Time_hour\"], \n             color='g')\nsns.distplot(df_credit[df_credit['Class'] == 1][\"Time_hour\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by Hours', fontsize=17)\nplt.xlim([-1,25])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75ea931d6404085e3559105c3f73cbffeaa38fcc"},"cell_type":"code","source":"#Exploring the distribuition by Class types throught hours and minutes\nplt.figure(figsize=(12,5))\nsns.distplot(df_credit[df_credit['Class'] == 0][\"Time_min\"], \n             color='g')\nsns.distplot(df_credit[df_credit['Class'] == 1][\"Time_min\"], \n             color='r')\nplt.title('Fraud x Normal Transactions by minutes', fontsize=17)\nplt.xlim([-1,61])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5624ce945c36eab036d95c502d23a114e31eef7a"},"cell_type":"markdown","source":"- Interesting distribuition, but don't sounds like a clear pattern of action"},{"metadata":{"_uuid":"9c5da3d67e39d5497c9e5b6f01a208ec34834a84"},"cell_type":"markdown","source":"## Looking the statistics of our Amount class frauds and normal transactions"},{"metadata":{"_cell_guid":"3f34ae04-e6f2-4656-b1ef-478cbd9ce2e9","_uuid":"b2eb4184ab7ef23938c81e260b7005a573b73199","trusted":true},"cell_type":"code","source":"#To clearly the data of frauds and no frauds\ndf_fraud = df_credit[df_credit['Class'] == 1]\ndf_normal = df_credit[df_credit['Class'] == 0]\n\nprint(\"Fraud transaction statistics\")\nprint(df_fraud[\"Amount\"].describe())\nprint(\"\\nNormal transaction statistics\")\nprint(df_normal[\"Amount\"].describe())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0c390092-2b5f-4c62-9e18-3ade988b6577","_uuid":"e19d8b4fde11143c3292a069535038f0c732b2e1"},"cell_type":"markdown","source":"Interesting. <br>\nUsing this informations I will filter the values to look for Amount by Class <br>\nI will filter the \"normal\" amounts by 3.000"},{"metadata":{"trusted":true,"_uuid":"555ec77171ffaeabeee44dc43565fc343595ecde"},"cell_type":"code","source":"#Feature engineering to a better visualization of the values\ndf_credit['Amount_log'] = np.log(df_credit.Amount + 0.01)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d9da4785-93e8-4a7d-acdc-8b5721e90532","_uuid":"7a5cf2296c7e3a37cda31d2b150c8cdcc5b5ba01","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,6))\n#I will explore the Amount by Class and see the distribuition of Amount transactions\nplt.subplot(121)\nax = sns.boxplot(x =\"Class\",y=\"Amount\",\n                 data=df_credit)\nax.set_title(\"Class x Amount\", fontsize=20)\nax.set_xlabel(\"Is Fraud?\", fontsize=16)\nax.set_ylabel(\"Amount(US)\", fontsize = 16)\n\nplt.subplot(122)\nax1 = sns.boxplot(x =\"Class\",y=\"Amount_log\", data=df_credit)\nax1.set_title(\"Class x Amount\", fontsize=20)\nax1.set_xlabel(\"Is Fraud?\", fontsize=16)\nax1.set_ylabel(\"Amount(Log)\", fontsize = 16)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.8)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fd6c3b927ac84be54fcb4ba3fc927d060fe6c3b"},"cell_type":"markdown","source":"We can see a slightly difference in log amount of our two Classes. <br>\nThe IQR of fraudulent transactions are higher than normal transactions, but normal transactions have highest values"},{"metadata":{"_uuid":"2866cbe93b06ceefc04748f81ac1918ecd477c3f"},"cell_type":"markdown","source":"### Looking a scatter plot of the Time_min distribuition by Amount"},{"metadata":{"_cell_guid":"c736e49c-15fc-4215-85e0-fccd8cb26b8c","_uuid":"240895d266c51d0aa29b6d903f5facebc53cc459","trusted":true},"cell_type":"code","source":"#Looking the Amount and time distribuition of FRAUD transactions\nax = sns.lmplot(y=\"Amount\", x=\"Time_min\", fit_reg=False,aspect=1.8,\n                data=df_credit, hue='Class')\nplt.title(\"Amounts by Minutes of Frauds and Normal Transactions\",fontsize=16)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3cb7168a1ac0512e676851ad73acdbf83fc2ee9"},"cell_type":"markdown","source":"### Looking a scatter plot of the Time_hour distribuition by Amount"},{"metadata":{"_cell_guid":"9a527a7b-d837-4d04-be9d-7808304f5306","_uuid":"940ac54a36233b2d0fae60eda1618c899b40ed5f","trusted":true},"cell_type":"code","source":"ax = sns.lmplot(y=\"Amount\", x=\"Time_hour\", fit_reg=False,aspect=1.8,\n                data=df_credit, hue='Class')\nplt.title(\"Amounts by Hour of Frauds and Normal Transactions\", fontsize=16)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"72bdaa56-f8c2-4002-ab88-93a916942985","_uuid":"83e8171418539dc0f1baf341d1e40a06d024cf0e"},"cell_type":"markdown","source":"<h2>I will use boxplot to search differents distribuitions: </h2>\n- We are searching for features that diverges from normal distribuition"},{"metadata":{"_cell_guid":"85d2a3c7-1673-436c-98f5-b298d1e1fd01","_uuid":"1cf561af23615f8a5a1815a30841ed3a381f7616","scrolled":false,"trusted":true},"cell_type":"code","source":"#Looking the V's features\ncolumns = df_credit.iloc[:,1:29].columns\n\nfrauds = df_credit.Class == 1\nnormals = df_credit.Class == 0\n\ngrid = gridspec.GridSpec(14, 2)\nplt.figure(figsize=(15,20*4))\n\nfor n, col in enumerate(df_credit[columns]):\n    ax = plt.subplot(grid[n])\n    sns.distplot(df_credit[col][frauds], bins = 50, color='g') #Will receive the \"semi-salmon\" violin\n    sns.distplot(df_credit[col][normals], bins = 50, color='r') #Will receive the \"ocean\" color\n    ax.set_ylabel('Density')\n    ax.set_title(str(col))\n    ax.set_xlabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"940811609dadad6120bd469b3bd5749c746fef9f"},"cell_type":"markdown","source":"We can see a interesting different distribuition in some of our features like V4, V9, V16, V17 and a lot more.  <br>\nNow let's take a look on time distribuition"},{"metadata":{"_uuid":"f10dc0eb4fc87a83bdfaff69f05d891ef7a753ad"},"cell_type":"markdown","source":"  ## Diference in time"},{"metadata":{"trusted":true,"_uuid":"40acff28e6f451b4951fc350721c48bb814f4557"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77f8e91fce7e276d294101cefc2868c3d872e49d"},"cell_type":"markdown","source":"## Feature selections"},{"metadata":{"_cell_guid":"059645e4-56a8-474f-8211-bae661dd3b31","_uuid":"9b558ff7c01aca62cbef47ff9a11fe496a642c65","trusted":true},"cell_type":"code","source":"#I will select the variables where fraud class have a interesting behavior and might can help us predict\n\ndf_credit = df_credit[[\"Time_hour\",\"Time_min\",\"V2\",\"V3\",\"V4\",\"V9\",\"V10\",\"V11\",\"V12\",\"V14\",\"V16\",\"V17\",\"V18\",\"V19\",\"V27\",\"Amount\",\"Class\"]]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a7a06c828b0091fa897f2cabb37085fd9c7db68"},"cell_type":"markdown","source":"## Some Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"3c3e1a2a1d82ff05f4a3dfde2ea9fa2eda88c9f7"},"cell_type":"code","source":"df_credit.Amount = np.log(df_credit.Amount + 0.001)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4f6f7871-6749-40b2-a143-b2c711a1d687","_uuid":"67eb863cb3a7cf51b2f88e6a3134f4bb16c97322","trusted":true},"cell_type":"code","source":"#Looking the final df\ndf_credit.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8030913f-8791-4191-b0f0-113b0279cd24","_uuid":"457bd7b63f6436b850d3bb08dd9b5cd07ca0ce74","trusted":true},"cell_type":"code","source":"colormap = plt.cm.Greens\n\nplt.figure(figsize=(14,12))\n\nsns.heatmap(df_credit.corr(),linewidths=0.1,vmax=1.0, \n            square=True, cmap = colormap, linecolor='white', annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abec3a5e851cfd368f767cbd5322048951b52342","collapsed":true},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"_cell_guid":"a359ba0d-ee52-4c27-a8da-2f4fd4af1686","_uuid":"be39107b6bd667eed64c66ca21dd7060030832a5","trusted":true},"cell_type":"code","source":"from imblearn.pipeline import make_pipeline as make_pipeline_imb # To do our transformation in a unique time\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.pipeline import make_pipeline\nfrom imblearn.metrics import classification_report_imbalanced\n\nfrom sklearn.model_selection import train_test_split\nfrom collections import Counter\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.metrics import precision_score, recall_score, fbeta_score, confusion_matrix, precision_recall_curve, accuracy_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70d2acba0f36910bcea354dcad557db01dd529c0"},"cell_type":"code","source":"X = df_credit.drop([\"Class\"], axis=1).values #Setting the X to do the split\ny = df_credit[\"Class\"].values # transforming the values in array","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e3d1d0e-82ea-4f88-85bd-71350092c432","_uuid":"eca22f092acc6bfc0012eaef482c60e0b794084d","trusted":true},"cell_type":"code","source":"# the function that we will use to better evaluate the model\ndef print_results(headline, true_value, pred):\n    print(headline)\n    print(\"accuracy: {}\".format(accuracy_score(true_value, pred)))\n    print(\"precision: {}\".format(precision_score(true_value, pred)))\n    print(\"recall: {}\".format(recall_score(true_value, pred)))\n    print(\"f2: {}\".format(fbeta_score(true_value, pred, beta=2)))\n\n# splitting data into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.20)\n\nclassifier = RandomForestClassifier\n\n# build model with SMOTE imblearn\nsmote_pipeline = make_pipeline_imb(SMOTE(random_state=4), \\\n                                   classifier(random_state=42))\n\nsmote_model = smote_pipeline.fit(X_train, y_train)\nsmote_prediction = smote_model.predict(X_test)\n\n#Showing the diference before and after the transformation used\nprint(\"normal data distribution: {}\".format(Counter(y)))\nX_smote, y_smote = SMOTE().fit_sample(X, y)\nprint(\"SMOTE data distribution: {}\".format(Counter(y_smote)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb77e89a2a627b6ba3214e6097f44b90825495c3"},"cell_type":"markdown","source":"## Evaluating the model SMOTE + Random Forest"},{"metadata":{"_cell_guid":"b59e7374-c2e3-463e-9282-b2a8618b0bba","_uuid":"e7fbae91fd27f70444187aeffdf6b28900b8d7d9","trusted":true},"cell_type":"code","source":"print(\"Confusion Matrix: \")\nprint(confusion_matrix(y_test, smote_prediction))\n\nprint('\\nSMOTE Pipeline Score {}'.format(smote_pipeline.score(X_test, y_test)))\n\nprint_results(\"\\nSMOTE + RandomForest classification\", y_test, smote_prediction)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9349261d-9aa6-475c-8e91-08d3d131c8ef","_uuid":"6597b929123cd9484899aae93dd8205733050153","trusted":true},"cell_type":"code","source":"# Compute predicted probabilities: y_pred_prob\ny_pred_prob = smote_pipeline.predict_proba(X_test)[:,1]\n\n# Generate precision recall curve values: precision, recall, thresholds\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot(precision, recall)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"65704d49-e64a-48e3-90f2-e815b970c0fe","_uuid":"a0e228da0e4961f6c8c81e223310949e36a03547","collapsed":true},"cell_type":"markdown","source":"# This ROC Curve is a overfitted curve, how can I fix this problem and get a correct "},{"metadata":{"trusted":true,"_uuid":"c1d92d6ef3bd9ce6ca2353c46cebadf0b138c0b6"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.cross_validation import KFold, cross_val_score\nfrom sklearn.grid_search import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d42aa55f72f6af5f217291a3396629b61e60f2cb"},"cell_type":"code","source":"#params of the model\nparam_grid = {\"max_depth\": [3,5, None],\n              \"n_estimators\":[3,5,10],\n              \"max_features\": [5,6,7,8]}\n\n# Creating the classifier\nmodel = RandomForestClassifier(max_features=3, max_depth=2 ,n_estimators=10, random_state=3, criterion='entropy', n_jobs=1, verbose=1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27aeab7ea786aa0984556c080f290ecdf4cd82cc","scrolled":false,"_kg_hide-output":true},"cell_type":"code","source":"grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='recall')\ngrid_search.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18b923f5e8887824e8a756a780322eb191c26bd6"},"cell_type":"code","source":"print(grid_search.best_score_)\nprint(grid_search.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08366cf459d4a64a237ad6569475fddf288d6c68"},"cell_type":"code","source":"# Running the fit\nrf = RandomForestClassifier(max_depth=5, max_features = 7, n_estimators = 10)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98cc43256d3c18f65184461ba946ff53d747c12b"},"cell_type":"code","source":"# Printing the Training Score\nprint(\"Training score data: \")\nprint(rf.score(X_train, y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31601b54a2bb41e3ea7771a84f3b4246c0f073c5"},"cell_type":"code","source":"#Testing the model \n#Predicting by X_test\ny_pred = rf.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint_results(\"RF classification\", y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5c7f703380f3fb6fd2009a5b9a28fa7afa40b5e"},"cell_type":"markdown","source":"## Feature importance plot"},{"metadata":{"trusted":true,"_uuid":"9e00f2c43f74d5dc315cea3c50a659db53577f0c"},"cell_type":"code","source":"features = [\"Time_min\", 'Time_hours',\"V2\",\"V3\",\"V4\",\"V9\",\"V10\",\"V11\",\"V12\",\"V14\",\"V16\",\"V17\",\"V18\",\"V19\",\"V27\",\"Amount\"]\n\n# Credits to Gabriel Preda\n# https://www.kaggle.com/gpreda/credit-card-fraud-detection-predictive-models\nplt.figure(figsize = (9,5))\n\nfeat_import = pd.DataFrame({'Feature': features, 'Feature importance': rf.feature_importances_})\nfeat_import = feat_import.sort_values(by='Feature importance',ascending=False)\n\ng = sns.barplot(x='Feature',y='Feature importance',data=feat_import)\ng.set_xticklabels(g.get_xticklabels(),rotation=90)\ng.set_title('Features importance - Random Forest',fontsize=20)\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af8ff7ca605b950ae23befd6a9c4951c6c7c3ed2"},"cell_type":"markdown","source":"The top 4 feature are V17, V14, V12, V10 corresponds to 75% of total. \n\nAlso the f2 score that is the median of recall and precision are on a considerably value"},{"metadata":{"_uuid":"5ba3059d6bd461704ccbcb844c127c62820bafe4"},"cell_type":"markdown","source":"## ROC CURVE - Random Forest"},{"metadata":{"trusted":true,"_uuid":"9f73198cf5d3098187fe53e309f6ae3a3ba8197b"},"cell_type":"code","source":"#Predicting proba\ny_pred_prob = rf.predict_proba(X_test)[:,1]\n\n# Generate precision recall curve values: precision, recall, thresholds\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot(precision, recall)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7ce1bd11c6fb90646ade401146de8514577f057"},"cell_type":"code","source":"results = cross_val_score(rf,X_train, y_train, cv=10, scoring='recall')\nresults","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b74333d678e1615fba83f6ffcf8d22229ab5b9db"},"cell_type":"markdown","source":"## Modelling Logistic Regression with Hyper Parameters"},{"metadata":{"trusted":true,"_uuid":"706a2362ed34fee51188fa84b53c245bee2517a5","scrolled":false},"cell_type":"code","source":"param_grid = {'C': [0.01, 0.1, 1, 10],\n             'penalty':['l1', 'l2']}\n\nlogreg = LogisticRegression(random_state=2)\n\ngrid_search_lr = GridSearchCV(logreg, param_grid=param_grid, scoring='recall', cv=5)\n\ngrid_search_lr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c928f9d7f73c74def33abe7df3cb943e9e358b46"},"cell_type":"code","source":"# The best recall obtained\nprint(grid_search_lr.best_score_)\n#Best parameter on trainning set\nprint(grid_search_lr.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c191c97819f2ec6341a8d7f73ba51b44e92a716"},"cell_type":"markdown","source":"### Setting the best parameters as parameters of our model"},{"metadata":{"trusted":true,"_uuid":"bdf9c84c574653bb1b089cce6cf137b5434f3ae8"},"cell_type":"code","source":"# Creating the model \nlogreg = LogisticRegression(C=10, penalty='l2',random_state=2)\n\n#Fiting the model\nlogreg.fit(X_train, y_train)\n           \n# Printing the Training Score\nprint(\"Cross Validation of X and y Train: \")\nprint(cross_val_score(logreg,X_train, y_train, cv=5, scoring='recall'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7677137a08bfe32d134f5fb3da88c7a7451ab06e","scrolled":true},"cell_type":"code","source":"# Predicting with the best params\ny_pred = logreg.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\nprint(\"\")\nprint_results(\"LogReg classification\", y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4710aca5074708f6f0dd29d347638c653740914"},"cell_type":"markdown","source":"70% of accuracy is not too bad, but we found a high vale on the Random Forest Model"},{"metadata":{"_uuid":"ca734b7b568210f64dcf77212ccf7d63095631a1"},"cell_type":"markdown","source":"## Precision Recall Curve of Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"dead578c8ce660b1d1456a942df41519d32dec86"},"cell_type":"code","source":"#Predicting proba\ny_pred_prob = logreg.predict_proba(X_test)[:,1]\n\n# Generate precision recall curve values: precision, recall, thresholds\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n\n# Plot ROC curve\nplt.plot(precision, recall)\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision Recall Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0821e09d3588a76c6c2b6b2179b028486ef179f7"},"cell_type":"markdown","source":"# CONCLUSION: \nThe highest values of Normal transactions are 25691.16 while of Fraudulent transactions are just 2125.87. <br>\nThe average value of normal transactions are small(USD 88.29) than fraudulent transactions that is USD 122.21\n\n\nWe got the best score when we use the SMOTE (OverSampling)  + RandomForest, that performed a f2 score of 0.8669~ \n\nThis is a considerably difference by the second best model that is 0.8252 that uses just RandomForests with some Hyper Parameters.\n\nThe worst model was Logreg where I used GridSearchCV to get the Best params to fit and predict where the recall was ~0.6666 and f2 ~0.70.\n\n\n"},{"metadata":{"_uuid":"f69975947bb3b497623d82a3f15baa776df815e8"},"cell_type":"markdown","source":"## Please if you have any feedback or suggestion to improve my models, let me know! "},{"metadata":{"_uuid":"e95b38a00d44be9d4fdb83f453a7b60da07b997e"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}