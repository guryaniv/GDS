{"metadata": {"language_info": {"name": "python", "pygments_lexer": "ipython2", "version": "2.7.13", "codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "0f9d6921e5ffb6d3d35400bc5abb79d693c7abe5"}, "source": ["# Credit card Fraud detection"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "238aeb14d5be950288ab3c6fec8561a5341f564c"}, "source": ["The datasets contains transactions made by credit cards in September 2013 by european cardholders.\n", "This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "97d74da9c0906b6e122857a1a17b0baef070a60c"}, "source": ["It contains only numerical input variables which are the result of a PCA transformation."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "68f118061c39c305e4790583e5cab2d4cbb3eeba"}, "source": ["### Goal : Classify whether it is a fraud transaction or not."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "97f6852149a004c96e0c0aa96bcec179d5185775"}, "source": "The following steps will be taken: \n\n 1. EDA\n 2. fit logistic regression with all features given\n 3. analyze the result\n 4. resampling to fix skewness in dataset\n 5. compare two results and conclusion", "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "1777ab4fc6fa366c23bcefee43baea00ec2f38a2", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": "import pandas as pd\nimport numpy as np\nfrom __future__ import division\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f77a9b49a8f4da89a452953cb78dccacc0229150"}, "source": ["# Loading the data"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "35c2d1a1f0f630ee593a4992febc25dd617fc6e6", "_execution_state": "idle", "scrolled": false}, "execution_count": null, "source": "df = pd.read_csv('../input/creditcard.csv')\ndf.describe()", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "2e8d50c3f877932232b2194bef677daaf093abf0", "_execution_state": "idle", "scrolled": true}, "execution_count": null, "source": ["# It is true that in data description, all variables are the result of PCA transformation\n", "df.head()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "e2c135de76707b6c516faa42b72f598a2562b0d6"}, "source": ["# Explore to Data"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "90486f63b2e86bca3cc95793c38c61b7aafb1b46", "_execution_state": "idle"}, "execution_count": null, "source": ["# checking null value in dataset\n", "df.isnull().sum()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "aee1987a77bda8e6b4b9d6a96490220ef706fcad", "_execution_state": "idle"}, "execution_count": null, "source": ["# number of label \"1\" in whole dataset.\n", "sum(df['Class']==1)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "ad7bfd70a6cbc10d655f9a73cbd57c3a128d5289", "_execution_state": "idle"}, "execution_count": null, "source": ["# visualize\n", "count_classes = pd.value_counts(df['Class'], sort = True)\n", "count_classes.plot(kind='bar')\n", "plt.title(\"Fraud class histogram\")\n", "plt.xlabel(\"Class\")\n", "plt.ylabel(\"Frequency\")"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "e232447a00df45502c6dcc3ab187b6f9955cea5f", "_execution_state": "idle"}, "execution_count": null, "source": ["492/284807 * 100"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "138139fe92b70fff0921671dc73261026ebd5801"}, "source": ["The dataset obviously skewed.\n", "\n", "consist of 0.17% fraudulent transaction in dataset. "], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "c1c1feb09734e6af6e8712756eb3c5d587a45589", "_execution_state": "idle", "scrolled": false}, "execution_count": null, "source": ["# plot correlation heatmap \n", "corr = df.corr()\n", "sns.heatmap(corr, vmin=0, vmax=1)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "021ad9d7fc71a82c17089d661d1ab5abb53a93a4"}, "source": ["'Time' column is about the time when each transaction occured.\n", "As you can see in correlation between data, I couldn't find any significant clue."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "61caf9597279d3a53b49d8bdebd322b424e1a9f4", "_execution_state": "idle"}, "execution_count": null, "source": ["# make data frame easy to see, change order of columns and drop Time column.\n", "col = df.columns.values\n", "col = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n", "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19',\n", "       'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n", "       'Amount', 'Class']\n", "\n", "# assign new column order to data frame\n", "df = df.reindex(columns=col)\n", "df.head()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "5aebbb690dfbaa8abf20781d2f4e2847ccc71f89", "_execution_state": "idle", "scrolled": false}, "execution_count": null, "source": ["# plot histogram for all variables\n", "import matplotlib.gridspec as gridspec\n", "\n", "features = df.iloc[:,:29].columns\n", "plt.figure(figsize=(15,30*4))\n", "gs = gridspec.GridSpec(30, 1)\n", "for i, col in enumerate(df[features]):\n", "    ax = plt.subplot(gs[i])\n", "    sns.distplot(df[col][df.Class==0], bins=100)\n", "    sns.distplot(df[col][df.Class==1], bins=100, color='r')\n", "    ax.set_xlabel('')\n", "    ax.set_title(col)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f806e73b266fd9015f5988cff875eebfd5f009f1"}, "source": ["most of data distributed centered around 0."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "0b80725dae2a492d8a9406924f456a0799c69cea"}, "source": ["**note**\n", "df.hist() plots histogram for all data but column order isn't preserved unless you change name of column."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "42bf47f82fe1d60c06a9a98be9b23b86b783a4ad"}, "source": ["#### I wonder how standardization affect logistic regression result. Do I have to standardize features everytime? no exception?\n", "\n", "To figure out I will test 2 cases ->\n", " * Test1 : fit logistic regression with NOT Standardized 'Amount' feature.\n", " * Test2 : fit logistic regression with Standardized 'Amount' feature."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "40fecbe427499aa99da356bd04faf3887054d99d"}, "source": ["## Test 1"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "63d8d33a6d2158a95b008609e3de7178af69ce08", "_execution_state": "idle"}, "execution_count": null, "source": ["# copy data frame for testing\n", "df_test = df\n", "df_test.head()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6af7cb0499d10341af2f89e25a2dceaa9ae87750", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["X = df_test.loc[:, df_test.columns != 'Class']\n", "y = df_test.loc[:, df_test.columns == 'Class']"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "8b47ff2d101934ae9f475261a304f805005fde90", "_execution_state": "idle", "scrolled": true}, "execution_count": null, "source": ["# divide data\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n", "\n", "# choose Logistic regression to classify whether it is fraudulent transaction or not.\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "lr = LogisticRegression()\n", "lr.fit(X_train, y_train.values.ravel())\n", "y_pred = lr.predict(X_test)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6733c7916027c3739fee4e84a97171a42d206cda", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["# confusion matrix\n", "from sklearn.metrics import confusion_matrix\n", "import itertools\n", "\n", "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n", "    \"\"\"\n", "    This function prints and plots the confusion matrix.\n", "    Normalization can be applied by setting `normalize=True`.\n", "    \"\"\"\n", "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n", "    plt.title(title)\n", "    plt.colorbar()\n", "    tick_marks = np.arange(len(classes))\n", "    plt.xticks(tick_marks, classes, rotation=15)\n", "    plt.yticks(tick_marks, classes, rotation=15)\n", "\n", "    if normalize:\n", "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n", "        #print(\"Normalized confusion matrix\")\n", "    \n", "        #print(cm)\n", "    thresh = cm.max() / 2.\n", "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n", "        plt.text(j, i, cm[i, j],\n", "                 horizontalalignment=\"center\",\n", "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n", "\n", "    plt.tight_layout()\n", "    plt.ylabel('True label')\n", "    plt.xlabel('Predicted label')"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6d4c7040b4358f42b541f69ad3540a32b600fcec", "_execution_state": "idle", "scrolled": false}, "execution_count": null, "source": ["# Compute confusion matrix\n", "class_set = [0, 1]\n", "cnf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n", "np.set_printoptions(precision=2)\n", "print (\"        Confusion matrix not standardized\")\n", "\n", "# Plot non-standardized confusion matrix\n", "plot_confusion_matrix(cm=cnf_matrix, classes=class_set)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "e585bcb42c749244bb1f10667dff03058a20c40e", "_execution_state": "idle", "scrolled": true}, "execution_count": null, "source": ["# calculate Precision, Recall and F1-score.\n", "\n", "# Precision rate = TP / TP + FP\n", "# Recall rate = TP / TP + FN\n", "\n", "precision = cnf_matrix[1,1] / (cnf_matrix[1,1] + cnf_matrix[0,1])\n", "recall = cnf_matrix[1,1] / (cnf_matrix[1,1] + cnf_matrix[1,0])\n", "\n", "print (\"Not standardized\\n\")\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Precision : %.4f\" %precision)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Recall : %.4f\" %recall)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"F1-Score : %.4f\" % ((precision*recall*2)/(precision+recall)))"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "a9751076b6abbd595c4e88968b3a66f6603f37c1"}, "source": ["## Test 2"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "abdcd4617e29fd9ec2dd535cfc58e278a970cfc7", "_execution_state": "idle"}, "execution_count": null, "source": ["# standardize\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "df_test['Amount_rescale'] = StandardScaler().fit_transform(df_test['Amount'].values.reshape(-1, 1))\n", "df_test.drop('Amount', axis=1, inplace=True)\n", "df_test.head()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "01081f0457d3422ddcd20a784598344ebe91e8cf", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["X_std = df_test.loc[:, df_test.columns != 'Class']\n", "y_std = df_test.loc[:, df_test.columns == 'Class']"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "e9c527f61e09b950292895daa8e421952e0507db", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["# divide data\n", "X_train_std, X_test_std, y_train_std, y_test_std = train_test_split(X_std, y_std, test_size=0.3, random_state=0)\n", "\n", "# train and predict\n", "lr_std = LogisticRegression()\n", "lr_std.fit(X_train_std, y_train_std.values.ravel())\n", "y_pred_std = lr_std.predict(X_test_std)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "eb1ae7fa54b11e1176329167f499d4d806817907", "_execution_state": "idle"}, "execution_count": null, "source": ["# Compute confusion matrix\n", "cnf_matrix_std = confusion_matrix(y_true=y_test_std, y_pred=y_pred_std)\n", "np.set_printoptions(precision=2)\n", "print (\"        Confusion matrix standardized\")\n", "\n", "# Plot standardized confusion matrix\n", "plot_confusion_matrix(cm=cnf_matrix_std, classes=class_set)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "a9b5c6626581582cc200d18d4450dace7b4b50c7", "_execution_state": "idle"}, "execution_count": null, "source": ["# calculate Precision, Recall and F1-score.\n", "# overwrite variables\n", "precision = cnf_matrix_std[1,1] / (cnf_matrix_std[1,1] + cnf_matrix_std[0,1])\n", "recall = cnf_matrix_std[1,1] / (cnf_matrix_std[1,1] + cnf_matrix_std[1,0])\n", "\n", "print (\"Standardized\\n\")\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Precision : %.4f\" %precision)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Recall : %.4f\" %recall)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"F1-Score : %.4f\" % ((precision*recall*2)/(precision+recall)))"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f66cfc4df4420b33f1eab50b2ec468f426517599"}, "source": ["#### I don't see any difference between test1 result and test2 result."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "b2d2790259920963d74da4d6b7d37b8243276fa3"}, "source": ["#### but standardization is important for regularization to work properly, we need to ensure that all our features are on comparable scales.\n", "so I will standardize feature."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "6b3841e825f8b921fad35845c641b7e55343e0ae", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["df = df_test"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "b0dc40c2ecc45f7068a7450ec0757be30a1b904d"}, "source": ["# Handle skewed data"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "6b8b2e9d4c87cf420a787df52dd7d1975b030227"}, "source": ["we can not collect more data, so we should solve skewed data problem by Oversampling/Undersampling."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "67df0850f0770b27fc4de9ac514b0e5be71fe95b"}, "source": ["Let's try undersampling. Main idea of undersampling is drop some of labeled samples at random to give a balanced dataset of 50% sample. we have 492 of fraudulent transactions. to make 50 / 50 ratio, choose normal transactions randomly and then concatenate 492 of fraudulent transactions and 492 of normal transactions."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "2f6a3cb81fc18a0f23e89c85ee11e8d87ed050a6", "_execution_state": "idle"}, "execution_count": null, "source": ["# get fraudulent transaction indices\n", "len_fraud = len(df[df['Class']==1])\n", "indices_fraud = np.array(df[df['Class']==1].index)\n", "\n", "# get normal transaction indices\n", "indices_normal = np.array(df[df['Class']==0].index)\n", "indices_normal = np.random.choice(indices_normal, len_fraud, replace=False)\n", "\n", "# make a undersampled dataframe\n", "undersample_indices = np.concatenate([indices_normal, indices_fraud])\n", "under_df = df.iloc[undersample_indices, :]\n", "\n", "# reindexing\n", "under_df.index = range(0, 984)\n", "under_df.shape"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "7d45e50fa1c992490b720ccb04708099e065906e"}, "source": ["fit undersampled data to logistic regression model"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "c5f9b4dfdef0e0e3ce4a6d731373886dbfd33f58", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["# shuffle rows in dataframe\n", "under_df = under_df.sample(frac=1).reset_index(drop=True)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "8f09a7580eca167ad8143b3d9ef29ebd854eb6f0", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["# divide data\n", "under_X = under_df.loc[:, under_df.columns.values != 'Class']\n", "under_y = under_df.loc[:, under_df.columns.values == 'Class']"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "453e4d83e7daab83000665d454bd77788153eace", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["X_train_und, X_test_und, y_train_und, y_test_und = train_test_split(under_X, under_y, test_size=0.3, random_state=0)\n", "\n", "lr_und = LogisticRegression()\n", "lr_und.fit(X_train_und, y_train_und.values.ravel())\n", "y_pred_und = lr_und.predict(X_test_und)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f35c704dea12975413a7212da9d1acfc327a276c", "_execution_state": "idle"}, "execution_count": null, "source": ["cnf_matrix_und = confusion_matrix(y_true=y_test_und, y_pred=y_pred_und)\n", "np.set_printoptions(precision=2)\n", "print (\"Confusion matrix undersampled\")\n", "\n", "plot_confusion_matrix(cm=cnf_matrix_und, classes=class_set)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "f99124056f26c0dd1e20f100d46b59ed9f6e06fc", "_execution_state": "idle"}, "execution_count": null, "source": ["# calculate Precision, Recall and F1-score.\n", "# overwrite variables\n", "precision = cnf_matrix_und[1,1] / (cnf_matrix_und[1,1] + cnf_matrix_und[0,1])\n", "recall = cnf_matrix_und[1,1] / (cnf_matrix_und[1,1] + cnf_matrix_und[1,0])\n", "\n", "\n", "print (\"Undersampled\\n\")\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Precision : %.4f\" %precision)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Recall : %.4f\" %recall)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"F1-Score : %.4f\" % ((precision*recall*2)/(precision+recall)))"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "8e2e535fb87f0941387d7e22b2789d2bcad12544"}, "source": ["#### test whole dataset with the model that we've fitted undersampled dataset."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "da2047f019bc78eda9c9f31f74d3575a84e5d8b9", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["# to test whole dataset, reset X and y\n", "X = df.loc[:, df.columns.values != 'Class']\n", "y = df.loc[:, df.columns.values == 'Class']"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "9fecaf09da67e4f139036528ce57fff1587aeb6d", "_execution_state": "idle"}, "execution_count": null, "source": ["# first fit model, compute confusion matrix and then plot ROC, AUC curve\n", "from sklearn.metrics import roc_curve, auc\n", "\n", "# the model we will use is 'lr_und'\n", "# train with undersampled data\n", "lr_und = LogisticRegression()\n", "lr_und.fit(X_train_und, y_train_und.values.ravel())\n", "\n", "# test whole dataset\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)\n", "y_pred = lr_und.predict(X_test)\n", "\n", "#compute confusion matrix\n", "cnf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n", "plot_confusion_matrix(cnf_matrix, classes=class_set, title='Final Confusion matrix')\n", "plt.show()\n"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "5bffa00d1a0da96aa2a12b6bb51c40f2b01a659c", "_execution_state": "idle"}, "execution_count": null, "source": "# calculate Precision, Recall and F1-score.\n# overwrite variables\nprecision = cnf_matrix[1,1] / (cnf_matrix[1,1] + cnf_matrix[0,1])\nrecall = cnf_matrix[1,1] / (cnf_matrix[1,1] + cnf_matrix[1,0])\n\n\nprint (\"fit whole data into model \\n\")\nprint (\"------------------------------------------------------------------------\")\nprint (\"Precision : %.4f\" %precision)\nprint (\"------------------------------------------------------------------------\")\nprint (\"Recall : %.4f\" %recall)\nprint (\"------------------------------------------------------------------------\")\nprint (\"F1-Score : %.4f\" % ((precision*recall*2)/(precision+recall)))", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "c20d5c0467ea9cdff7c0359175cf8a70b74c5e7a"}, "source": ["very low Precision rate."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "790ae7543987a904e8b4f0adbead3ea8063d1718"}, "source": "## Compare two ROC, AUC result", "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "c06e53418a5fca4ae33ab327177eca91c4a16bfd"}, "source": ["plot ROC, AUC of whole dataset first"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "b95087b40ee5bc5cdf9bff2759720b8bec1dcd00", "_execution_state": "idle"}, "execution_count": null, "source": ["# plot ROC, AUC\n", "# below code is use undersampled model and plot whole dataset.\n", "y_pred_score = lr_und.fit(X_train_und, y_train_und.values.ravel()).decision_function(X_test)\n", "\n", "fpr, tpr, thresholds = roc_curve(y_test.values.ravel(), y_pred_score)\n", "roc_auc = auc(fpr, tpr)\n", "\n", "# plot\n", "plt.plot(fpr, tpr, 'darkorange', label='AUC = %0.2f'% roc_auc)\n", "plt.plot([0,1],[0,1],'--', color='navy')\n", "plt.xlim([-0.05,1.0])\n", "plt.ylim([0.0,1.05])\n", "plt.title('Receiver Operating Characteristic')\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')\n", "plt.legend(loc='lower right')\n", "plt.show()\n"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "e0a98396f878b20fcb71dae0d19f40bafc3d0f81"}, "source": ["now plot ROC, AUC of udersampled dataset"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "b70f64b085f9651d7c751d95acda83c4270019c8", "_execution_state": "idle"}, "execution_count": null, "source": ["# plot ROC, AUC\n", "# below code is use undersampled model and plot whole dataset.\n", "y_pred_score_und = lr_und.fit(X_train_und, y_train_und.values.ravel()).decision_function(X_test_und)\n", "\n", "fpr_und, tpr_und, thresholds_und = roc_curve(y_test_und.values.ravel(), y_pred_score_und)\n", "roc_auc_und = auc(fpr_und, tpr_und)\n", "\n", "# plot\n", "plt.plot(fpr_und, tpr_und, 'darkorange', label='AUC = %.2f'% roc_auc_und)\n", "plt.plot([0,1],[0,1],'--', color='navy')\n", "plt.xlim([-0.05,1.0])\n", "plt.ylim([0.0,1.05])\n", "plt.title('Receiver Operating Characteristic')\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')\n", "plt.legend(loc='lower right')\n", "plt.show()\n"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "b1c22e2914641695a7890855f8a424f9f0177c28"}, "source": ["## K-fold"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "c57480ac4be0aed3dd961139e5dbe76cc184f394"}, "source": ["use K-fold cross validation to find best parameter C."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "496aae4f8c17ab40d2ffa2e564720df0aad551b5", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["from sklearn.model_selection import KFold, cross_val_score\n", "from sklearn.metrics import recall_score"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "28ace254f207c3006dd73fa7651143ec077ecbeb", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["under_X = under_df.loc[:, under_df.columns.values != 'Class']\n", "under_y = under_df.loc[:, under_df.columns.values == 'Class']"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "9a3534c52366b64277f39df4d64e08d87a53bada", "_execution_state": "idle", "scrolled": false}, "execution_count": null, "source": "kf = KFold(n_splits=7)\nc_params = [0.001, 0.01, 0.1, 1, 10.0, 100.0, 1000.0]\nresults = []\n\nfor c_param in c_params:\n    print ('--------------------------------------------------')\n    print ('C parameter: ', c_param)\n    print ('--------------------------------------------------')\n    print ('')\n    \n    recall_accs = []\n    \n    for k, (train, test) in enumerate(kf.split(under_X, under_y)):\n        # use L2 penalization\n        lr_kf = LogisticRegression(C = c_param, penalty='l2')\n        lr_kf.fit(under_X.iloc[train], under_y.iloc[train].values.ravel())\n        y_pred_under = lr_kf.predict(under_X.iloc[test].values)\n        \n        # compute Recall rate because our goal is find fraudulent transactions. We should minimize TN which missclassify \n        # transactions which are actually fraudulent transaction but predict as normal transaction.    \n        recall_acc = recall_score(under_y.iloc[test].values.ravel(), y_pred_under)\n        recall_accs.append(recall_acc)\n        print ('Iteration: ',k+1 ,'recall score = ', recall_acc)\n    \n     # The mean value of those recall scores is the metric we want to save and get hold of.\n    results.append(np.mean(recall_accs))\n    \n    print ('')\n    print ('Mean recall score ', np.mean(recall_accs))\n    print ('')\n    \n    best_c = max(results)\n    \n    # Finally, we can check which C parameter is the best amongst the chosen.\n    \n    print ('Best mean recall score is', best_c)\n    print ('')\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "6b435a0dc63ffc40d94bf6d088c73b4890d7c894", "_execution_state": "idle"}, "execution_count": null, "source": "# kaggle can't understand zip function.\nprint (c_params, results)\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "b25c0ed7b1593a7af04c7d0894c1f3aca75678d5"}, "source": ["best C parameter is 0.001"], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "5b8b8448ae89fcca656ef68d3ce5d4cedf0be517"}, "source": ["### Let's fit model again with best C parameter 0.001 and see what will change."], "execution_count": null, "cell_type": "markdown"}, {"outputs": [], "metadata": {"_uuid": "25c08716546da6a0b26773c5cfb0f9860007a93d", "_execution_state": "idle", "collapsed": true}, "execution_count": null, "source": ["X_train_und, X_test_und, y_train_und, y_test_und = train_test_split(under_X, under_y, test_size=0.3, random_state=0)\n", "\n", "lr_c = LogisticRegression(C=best_c)\n", "lr_c.fit(X_train_und, y_train_und.values.ravel())\n", "y_pred_c = lr_c.predict(X_test_und)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "99eeb86d963040acb36f43b090b4ae9d16717b87", "_execution_state": "idle"}, "execution_count": null, "source": ["cnf_matrix_c = confusion_matrix(y_true=y_test_und, y_pred=y_pred_c)\n", "np.set_printoptions(precision=2)\n", "print (\"Confusion matrix with best C parameter\")\n", "\n", "plot_confusion_matrix(cm=cnf_matrix_c, classes=class_set)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_uuid": "755409cdd2a218913c4b9439d975f15d7a4bb777", "_execution_state": "idle"}, "execution_count": null, "source": ["precision = cnf_matrix_c[1,1] / (cnf_matrix_c[1,1] + cnf_matrix_c[0,1])\n", "recall = cnf_matrix_c[1,1] / (cnf_matrix_c[1,1] + cnf_matrix_c[1,0])\n", "\n", "\n", "print (\"result fit model with best C\")\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Precision : %.4f\" %precision)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"Recall : %.4f\" %recall)\n", "print (\"------------------------------------------------------------------------\")\n", "print (\"F1-Score : %.4f\" % ((precision*recall*2)/(precision+recall)))"], "cell_type": "code"}], "nbformat_minor": 2, "nbformat": 4}