{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python"}}, "cells": [{"metadata": {"_uuid": "0bca9739b82d5d51e1229243e03ea1b6db35c17e", "_cell_guid": "d3b04218-0413-4e6c-8751-5d8a404d73a9"}, "source": ["* Forked from **Jeremy Howard**'s NB-LR kernel: https://www.kaggle.com/jhoward/nb-svm-baseline-0-06-lb\n", "\n", "## Introduction\n", "\n", "This kernel shows how to use NBSVM (Naive Bayes - Support Vector Machine) to create a strong baseline for the [Toxic Comment Classification Challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) competition. NBSVM was introduced by Sida Wang and Chris Manning in the paper [Baselines and Bigrams: Simple, Good Sentiment and Topic Classi\ufb01cation](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf). In this kernel, we use sklearn's logistic regression, rather than SVM, although in practice the two are nearly identical (sklearn uses the liblinear library behind the scenes).\n"], "cell_type": "markdown"}, {"metadata": {"_uuid": "cca038ca9424a3f66e10262fc9129de807b5f855", "collapsed": true, "_cell_guid": "ef06cd19-66b6-46bc-bf45-184e12d3f7d4"}, "source": ["import pandas as pd, numpy as np\n", "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n", "from sklearn.feature_extraction.text import CountVectorizer"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "f70ebe669fcf6b434c595cf6fb7a76120bf7809c", "collapsed": true, "_cell_guid": "a494f561-0c2f-4a38-8973-6b60c22da357"}, "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "subm = pd.read_csv('../input/sample_submission.csv')"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "2c18461316f17d1d323b1959c8eb4e5448e8a44e", "_cell_guid": "3996a226-e1ca-4aa8-b39f-6524d4dadb07"}, "source": ["## Looking at the data\n", "\n", "The training data contains a row per comment, with an id, the text of the comment, and 6 different labels that we'll try to predict."], "cell_type": "markdown"}, {"metadata": {"_uuid": "5f5269c56ea6ded273881b0d4dcdb6af83a3e089", "collapsed": true, "scrolled": true, "_cell_guid": "5ddb337b-c9b2-4fec-9652-cb26769dc3c6"}, "source": ["train.head()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "004d2e823056e98afc5adaac433b7afbfe93b82d", "_cell_guid": "b3b071fb-7a2c-4195-9817-b01983d11c0e"}, "source": ["Here's a couple of examples of comments, one toxic, and one with no labels."], "cell_type": "markdown"}, {"metadata": {"_uuid": "1ba9522a65227881a3a55aefaee9de93c4cfd792", "collapsed": true, "_cell_guid": "d57f0b31-c09b-4305-a0b0-0b864e944fd1"}, "source": ["train['comment_text'][0]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "b0d70e9d745411ea6228c95c5f19bd3a2ca6dd55", "collapsed": true, "scrolled": true, "_cell_guid": "9caf5da3-33bb-422d-81c4-fef20fbda1a8"}, "source": ["train['comment_text'][2]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "5c4c716de98a4b1c2ecc0e516e67813b4fc1473e", "_cell_guid": "2ea37597-02f7-43cf-ad16-a3d50aac1aba"}, "source": ["The length of the comments varies a lot."], "cell_type": "markdown"}, {"metadata": {"_uuid": "9c1a3f81397199fa250a2b642edc7fbc5f9f504e", "collapsed": true, "_cell_guid": "fd3fe158-4d7f-4b30-ac15-42605240ea4f"}, "source": ["lens = train.comment_text.str.len()\n", "lens.mean(), lens.std(), lens.max()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "eb68f1c83a5ad11e652ca5f2150993a06d43edb4", "collapsed": true, "_cell_guid": "d2e55012-4736-425f-84f3-c148ac1f4852"}, "source": ["lens.hist();"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "0151ab55887071aed82d297acb2c6545ed964c2b", "_cell_guid": "b8515824-b2dd-4c95-bbf9-dc74c80355db"}, "source": ["We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."], "cell_type": "markdown"}, {"metadata": {"_uuid": "4ba6ef86c82f073bf411785d971a694348c3efa9", "collapsed": true, "_cell_guid": "c66f79d1-1d9f-4d94-82c1-8026af198f2a"}, "source": ["label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n", "train['none'] = 1-train[label_cols].max(axis=1)\n", "train.describe()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "8d9f66a506ea3ea1ba643dec16ec750cebc0191a", "collapsed": true, "scrolled": true, "_cell_guid": "68962905-15fc-483e-909e-eb1e58e0098c"}, "source": ["train[label_cols].max(axis=1).describe()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "b7b0d391248f929a026b16fc38936b7fc0176351", "collapsed": true, "_cell_guid": "9f6316e3-7e29-431b-abef-73acf4a08637"}, "source": ["len(train),len(test)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "bfdcf59624717b37ca4ffc0c99d2c28a2d419b06", "_cell_guid": "1b221e62-e23f-422a-939d-6747edf2d613"}, "source": ["There are a few empty comments that we need to get rid of, otherwise sklearn will complain."], "cell_type": "markdown"}, {"metadata": {"_uuid": "1e1229f403225f1889c7a7b4fc9be90fda818af5", "collapsed": true, "_cell_guid": "fdba531c-7ef2-4967-88e2-fc2b04f6f2ef"}, "source": ["COMMENT = 'comment_text'\n", "train[COMMENT].fillna(\"unknown\", inplace=True)\n", "test[COMMENT].fillna(\"unknown\", inplace=True)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "6f5dccdadc19b491c7b77737e1cfd885e4b93905", "collapsed": true, "_cell_guid": "dc15b813-6f92-46ee-b775-b681d9f5e832"}, "source": ["df = pd.concat([train['comment_text'], test['comment_text']], axis=0)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "f2e77e8e6df5e29b620c7a2a0add1438c35af932", "_cell_guid": "480780f1-00c0-4f9a-81e5-fc1932516a80"}, "source": ["## Building the model\n", "\n", "We'll start by creating a *bag of words* representation, as a *term document matrix*. We'll use ngrams, as suggested in the NBSVM paper."], "cell_type": "markdown"}, {"metadata": {"_uuid": "6bc08d6ac10871f09ac81adaa92930007d30fcf8", "collapsed": true, "_cell_guid": "26952eec-a7fb-4469-af5b-78bf35de5b0e"}, "source": ["n = train.shape[0]\n", "vec = CountVectorizer(ngram_range=(1,2),min_df=3, max_df=0.97,max_features = 60000) # could also try adding stop word removals, stemming, not lowercasing!\n", "\n", "vec.fit(df.values)\n", "trn_term_doc = vec.transform(train[COMMENT])\n", "test_term_doc = vec.transform(test[COMMENT])\n", "\n", "# trn_term_doc = vec.fit_transform(train[COMMENT])\n", "# test_term_doc = vec.transform(test[COMMENT])"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "85c13f3ba3d86a42cb9640016efce7ffd13ea3cc", "_cell_guid": "b9eb802a-160c-4781-9782-ab67dcdcb17c"}, "source": ["Here's the basic naive bayes feature equation:"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8b277f01cecd575ed4fcae2e630c0dd8ce979793", "collapsed": true, "_cell_guid": "45fc6070-ba13-455b-9274-5c2611e2809c"}, "source": ["def pr(y_i, y):\n", "    p = x[y==y_i].sum(0)\n", "    return (p+1) / ((y==y_i).sum()+1)"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "8e165fbbcf3e4b22b4ee23dc4f9b3366613f6546", "_cell_guid": "12341e9e-ab19-44a1-9f10-20718238f85e"}, "source": ["We *binarize* the features as discussed in the NBSVM paper."], "cell_type": "markdown"}, {"metadata": {"_uuid": "926eaa2e40e588f4ef2b86e0a28f8e575c9ed5f4", "collapsed": true, "_cell_guid": "2299d24b-5515-4d37-92d9-e7f6b16a290a"}, "source": ["x=trn_term_doc.sign()\n", "test_x = test_term_doc.sign()"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "d8b56c17c4a5fba190395acbe1f024d20f2382b5", "_cell_guid": "92760538-b2df-4568-9b92-f0e7e27114d1"}, "source": ["Fit a model for one dependent at a time:"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8652ab2f5f84e77fa395252be9b60be1e44fd583", "collapsed": true, "_cell_guid": "b756c889-a383-4952-9ee9-eca79fd3454f"}, "source": ["def get_mdl(y):\n", "    y = y.values\n", "    r = np.log(pr(1,y) / pr(0,y))\n", "#     m = LogisticRegression(C=0.1, dual=True) # ORIG\n", "    m = LogisticRegressionCV(Cs=5)\n", "    x_nb = x.multiply(r)\n", "    return m.fit(x_nb, y), r"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "0fa103b5406aabdc36ea9ef21612d343e4982fc4", "collapsed": true, "_cell_guid": "33fd5f8c-adfc-45a1-9fde-1769a0993e76"}, "source": ["preds = np.zeros((len(test), len(label_cols)))"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "dfff4b395bad89158d49d6da3878607f284257eb", "collapsed": true, "_cell_guid": "9f2dd982-9542-4d37-be77-087c293e3c99"}, "source": ["for i, j in enumerate(label_cols):\n", "    print('fit', j)\n", "    m,r = get_mdl(train[j])\n", "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]"], "outputs": [], "execution_count": null, "cell_type": "code"}, {"metadata": {"_uuid": "6f2b640da9c9cf88a08526ce8ce9a33c6bdc3bd5", "_cell_guid": "c3f79dcf-a1db-4f81-9429-2c772d10ac76"}, "source": ["And finally, create the submission file."], "cell_type": "markdown"}, {"metadata": {"_uuid": "5dd033a93e6cf32cdbdaa0a8b05cd8d27de2b21d", "collapsed": true, "_cell_guid": "bc6a4575-fbbb-47ea-81ac-91fa702dc194"}, "source": ["submid = pd.DataFrame({'id': subm[\"id\"]})\n", "submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n", "submission.to_csv('submission.csv', index=False)"], "outputs": [], "execution_count": null, "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1}