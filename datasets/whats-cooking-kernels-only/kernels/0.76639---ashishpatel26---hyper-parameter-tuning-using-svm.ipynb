{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n% matplotlib inline\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom pprint import pprint\n\npd.set_option('display.max_columns', None)\npd.set_option('display.max_row', None)\n\nimport re\nfrom nltk.stem import WordNetLemmatizer\n\n# Grid search for optimal parameters of the model\nfrom sklearn.model_selection import GridSearchCV\n\n# Model modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nfrom sklearn.neural_network import MLPClassifier\n\n# modules for # estimate\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import cross_validation\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# modules for encoding features\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\n\n# Modules for dividing a data set\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\nfrom gensim.models import word2vec\nfrom contextlib import contextmanager\n\nimport gc\nimport time\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8a137e237a1ec55f447d6c3a8a68520e330ef3b","collapsed":true},"cell_type":"code","source":"@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Dataset Preparation\nprint (\"Read Dataset ... \")\ndef read_dataset(path):\n    return json.load(open(path)) \ntrain = read_dataset('../input/train.json')\ntest = read_dataset('../input/test.json')\ndef read():\n    train = read_dataset('../input/train.json')\n    test = read_dataset('../input/test.json')\n    return train,test\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a8651cccd73dd6c1ee648330b8c0a58bc123c69"},"cell_type":"code","source":"def analysis():\n    train = pd.read_json(\"../input/train.json\")\n    test = pd.read_json(\"../input/test.json\")\n    print(\"Train shape:\", train.shape)\n    print(\"Test shape:\", test.shape)\n    df = train.copy()\n    print(df.shape)\n    df.head(2)\n    df.count()\n    df.isnull().sum()\n    print('Cuisine is {}.'.format(len(df.cuisine.value_counts())))\n    df.cuisine.value_counts()\n    # cuisine type visualization\n    plt.style.use('ggplot')\n    df.cuisine.value_counts().plot(kind = 'bar',title='Cuisine Types',figsize=(20,5),legend=True,fontsize=12)\n    plt.ylabel(\"Number of Recipes\", fontsize=12)\n    return plt.show()\n\nanalysis()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d0bb71269ca12dac4a961f9bb03debc56eee34f","collapsed":true},"cell_type":"code","source":"#prepare text data for traina and test\ndef generate_text(data):\n    print(\"prepare text data for Train and Test....\")\n    text_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n    return text_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a18882ac286ab186923405ad43aeda9b1977ab11"},"cell_type":"code","source":"# count the word frequency for text data\ntfidf = TfidfVectorizer(binary=True)\ndef tfidf_features(text, flag):\n    print (\"TF-IDF on text data ... \")\n    if flag == \"train\":\n        x = tfidf.fit_transform(text)\n    else:\n        x = tfidf.transform(text)\n    x = x.astype('float16')\n    print()\n    return x ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2be85cd70800b702a68876a5763ead0fcb328aed"},"cell_type":"code","source":"lb = LabelEncoder()\n# Label Encoding - Target \ndef label_encoding(target):\n    print (\"Label Encode the Target Variable ... \")\n    y = lb.fit_transform(target)\n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"233f8be11a9ad10c74286f974d9fa0993590d38e"},"cell_type":"code","source":"# Model Training \ndef data_model(X,y,X_test):\n    print (\"Train the model ... \")\n#     classifier = SVC(C=200, # penalty parameter, setting it to a larger value \n#                      kernel='rbf', # kernel type, rbf working fine here\n#                      degree=5, # default value, not tuned yet\n#                      gamma=1, # kernel coefficient, not tuned yet\n#                      coef0=1, # change to 1 from default value of 0.0\n#                      shrinking=True, # using shrinking heuristics\n#                      tol=0.001, # stopping criterion tolerance \n#                      probability=False, # no need to enable probability estimates\n#                      cache_size=200, # 200 MB cache size\n#                      class_weight=None, # all classes are treated equally \n#                      verbose=True, # print the logs \n#                      max_iter=-1, # no limit, let it run\n#                      decision_function_shape=None, # will use one vs rest explicitly \n#                      random_state=None)\n    \n    Cs = [100,200,300]\n    gammas = [0.001, 0.01, 0.1, 1]\n    param_grid = {'C': Cs, 'gamma' : gammas}\n    grid_search = GridSearchCV(SVC(C=200, # penalty parameter, setting it to a larger value \n                     kernel='rbf', # kernel type, rbf working fine here\n                     degree=5, # default value, not tuned yet\n                     gamma=1, # kernel coefficient, not tuned yet\n                     coef0=1, # change to 1 from default value of 0.0\n                     shrinking=True, # using shrinking heuristics\n                     tol=0.001, # stopping criterion tolerance \n                     probability=False, # no need to enable probability estimates\n                     cache_size=200, # 200 MB cache size\n                     class_weight=None, # all classes are treated equally \n                     verbose=True, # print the logs \n                     max_iter=-1, # no limit, let it run\n                     decision_function_shape=None, # will use one vs rest explicitly \n                     random_state=None), param_grid, cv=3)\n    grid_search.fit(X, y)\n#     grid_search.best_params_\n    model = OneVsRestClassifier(grid_search, n_jobs=4)\n    model.fit(X, y)\n    print(\"This Model Accuracy is :\", model.score(X,y))\n    # Predictions \n    print (\"Predict on test data... \")\n    y_test = model.predict(X_test)\n    y_pred = lb.inverse_transform(y_test)\n    return (y_pred, y_test)\n\ndef submission(test, y_pred):\n    # Submission\n    print (\"Generate Submission File ... \")\n    test_id = [doc['id'] for doc in test]\n    sub = pd.DataFrame({'id': test_id, 'cuisine': y_pred}, columns=['id', 'cuisine'])\n    sub.to_csv('Submission.csv', index=False)\n    return sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99e1b5aa1c7ed0dde021b19875f7416cc8c2a745"},"cell_type":"code","source":"def main(debug = False):\n    with timer(\"Process Read Data..\"):\n        analysis()\n        train, test = read()\n#         train = load_data(\"../input/train.json\")\n#         test = load_data(\"../input/test.json\")\n        print(\"Full Report of Train Data......\")\n        print(\"Report Completed...\")\n        gc.collect()\n    with timer(\"Process of prepare text data for Train and Test....\"):\n        print(\"Start Data preparation...\")\n        train_text = generate_text(train)\n        test_text = generate_text(test)\n        target = [doc['cuisine'] for doc in train]\n        print(\"Data Preparation Completed...\")\n        gc.collect()\n    with timer(\"Process of TFIDF for train_text and test_text\"):\n        print(\"Start TFIDF...\")\n        X = tfidf_features(train_text, flag=\"train\")\n        X_test = tfidf_features(test_text, flag=\"test\")\n        print(\"TFIDF Completed...\")\n        gc.collect()\n    with timer(\"Process Label Encoding\"):\n        print(\"Start Label Encoding...\")\n        y = label_encoding(target=target)\n        print(\"Label Encoding Completed...\")\n        gc.collect()\n    with timer(\"Run SVM Training\"):\n        print(\"Start Model Training...\")\n        y_pred, y_test = data_model(X,y,X_test)\n        print(\"Model Training Completed...\")\n        gc.collect()\n    with timer(\"Final Submission\"):\n        print(\"Start file Submission...\")\n        sub = submission(test,y_pred)\n        sub.head(20)\n        print(\"Run Compeleted.\")\n\nif __name__ == \"__main__\":\n    with timer(\"Full model run\"):\n        main(debug= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c47aa8d122e4de14dc234ecc16de5d6933e4726"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}