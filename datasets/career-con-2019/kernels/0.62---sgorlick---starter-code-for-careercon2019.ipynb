{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.utils import check_array\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler,QuantileTransformer\nfrom sklearn.base import BaseEstimator,TransformerMixin,RegressorMixin\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nfrom scipy.stats import skew,kurtosis","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"train = pd.read_csv('../input/X_train.csv',index_col=1)\ntrain.drop('row_id',axis=1,inplace=True)\ntest = pd.read_csv('../input/X_test.csv',index_col=1)\ntest.drop('row_id',axis=1,inplace=True)\ntarget =  pd.read_csv('../input/y_train.csv')\nsub = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36dd99adbf39c2c709583be0d0cba6a4cc64e86c"},"cell_type":"code","source":"def fe_step0 (actual):\n    \n    # https://www.mathworks.com/help/aeroblks/quaternionnorm.html\n    # https://www.mathworks.com/help/aeroblks/quaternionmodulus.html\n    # https://www.mathworks.com/help/aeroblks/quaternionnormalize.html\n        \n    actual['norm_quat'] = (actual['orientation_X']**2 + actual['orientation_Y']**2 + actual['orientation_Z']**2 + actual['orientation_W']**2)\n    actual['mod_quat'] = (actual['norm_quat'])**0.5\n    actual['norm_X'] = actual['orientation_X'] / actual['mod_quat']\n    actual['norm_Y'] = actual['orientation_Y'] / actual['mod_quat']\n    actual['norm_Z'] = actual['orientation_Z'] / actual['mod_quat']\n    actual['norm_W'] = actual['orientation_W'] / actual['mod_quat']\n    \n    return actual\n\n# https://stackoverflow.com/questions/53033620/how-to-convert-euler-angles-to-quaternions-and-get-the-same-euler-angles-back-fr?rq=1\ndef quaternion_to_euler(x, y, z, w):\n    import math\n    t0 = +2.0 * (w * x + y * z)\n    t1 = +1.0 - 2.0 * (x * x + y * y)\n    X = math.atan2(t0, t1)\n\n    t2 = +2.0 * (w * y - z * x)\n    t2 = +1.0 if t2 > +1.0 else t2\n    t2 = -1.0 if t2 < -1.0 else t2\n    Y = math.asin(t2)\n\n    t3 = +2.0 * (w * z + x * y)\n    t4 = +1.0 - 2.0 * (y * y + z * z)\n    Z = math.atan2(t3, t4)\n\n    return X, Y, Z\n\ndef fe_step1 (actual):\n    \"\"\"Quaternions to Euler Angles\"\"\"\n    \n    x, y, z, w = actual['norm_X'].tolist(), actual['norm_Y'].tolist(), actual['norm_Z'].tolist(), actual['norm_W'].tolist()\n    nx, ny, nz = [], [], []\n    for i in range(len(x)):\n        xx, yy, zz = quaternion_to_euler(x[i], y[i], z[i], w[i])\n        nx.append(xx)\n        ny.append(yy)\n        nz.append(zz)\n    \n    actual['euler_x'] = nx\n    actual['euler_y'] = ny\n    actual['euler_z'] = nz\n    return actual\n\n\ntrain = fe_step0(train)\ntest = fe_step0(test)\n\ntrain = fe_step1(train)\ntest = fe_step1(test)\n\n\ndef extra_feats(data):\n    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n    return data\n\ntrain = extra_feats(train)\ntest = extra_feats(test)\n\nfor i in range(1,train.shape[1]):\n    train=pd.concat([train,train.iloc[:,i].diff().fillna(0)],axis=1)\n    test=pd.concat([test,test.iloc[:,i].diff().fillna(0)],axis=1)\n    \n    \ntrain.columns=list(range(train.shape[1]))\ntest.columns=list(range(test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1846775f72cc5a843e6f17267d5699378a05f0b","scrolled":false},"cell_type":"code","source":"train_pivot=pd.pivot_table(data=train,index=train.index,columns=train.columns[0])\ntest_pivot=pd.pivot_table(data=test,index=test.index,columns=train.columns[0])\n\ntrain_stats=[]\nfor i in np.linspace(0,128*(train.shape[1]-2),train.shape[1]-1).astype(int):\n    train_stats.append( np.mean(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( np.median(train_pivot.iloc[:,i:i+128],axis=1) )\n    train_stats.append( np.sum(train_pivot.iloc[:,i:i+128],axis=1).values )    \n    train_stats.append( np.max(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( np.min(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( np.max(train_pivot.iloc[:,i:i+128],axis=1).values - np.min(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( (np.max(train_pivot.iloc[:,i:i+128],axis=1).values / np.min(train_pivot.iloc[:,i:i+128],axis=1)).fillna(0).values )\n    train_stats.append( np.std(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( np.var(train_pivot.iloc[:,i:i+128],axis=1).values )\n    train_stats.append( skew(train_pivot.iloc[:,i:i+128],axis=1) )\n    train_stats.append( kurtosis(train_pivot.iloc[:,i:i+128],axis=1) )\ntrain_pivot=pd.concat([train_pivot,pd.DataFrame(train_stats).T],axis=1)\n\ntest_stats=[]\nfor i in np.linspace(0,128*(test.shape[1]-2),test.shape[1]-1).astype(int):\n    test_stats.append( np.mean(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( np.median(test_pivot.iloc[:,i:i+128],axis=1) )\n    test_stats.append( np.sum(test_pivot.iloc[:,i:i+128],axis=1).values )    \n    test_stats.append( np.max(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( np.min(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( np.max(test_pivot.iloc[:,i:i+128],axis=1).values - np.min(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( (np.max(test_pivot.iloc[:,i:i+128],axis=1).values / np.min(test_pivot.iloc[:,i:i+128],axis=1)).fillna(0).values )\n    test_stats.append( np.std(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( np.var(test_pivot.iloc[:,i:i+128],axis=1).values )\n    test_stats.append( skew(test_pivot.iloc[:,i:i+128],axis=1) )\n    test_stats.append( kurtosis(test_pivot.iloc[:,i:i+128],axis=1) )\ntest_pivot=pd.concat([test_pivot,pd.DataFrame(test_stats).T],axis=1)\n\n\ntrain_pivot.columns=list(range(train_pivot.shape[1]))\ntest_pivot.columns=list(range(test_pivot.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6cfebf9803d64beaa42dd66a45e0d0408ed9a10"},"cell_type":"code","source":"target_working = target['surface'].map({\n    'concrete':0,\n    'soft_pvc':1,\n    'wood':2,\n    'tiled':3,\n    'fine_concrete':4,\n    'hard_tiles_large_space':5,\n    'soft_tiles':6,\n    'carpet':7,\n    'hard_tiles':8,\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4dab2f17de0bf6d5f1bf04a46273af8b9f12310"},"cell_type":"code","source":"train_pivot=check_array(np.where(train_pivot== np.inf,0,train_pivot))\ntest_pivot=check_array(np.where(test_pivot== np.inf,0,test_pivot))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a126a2b0bea14768c7dba958ed72b44aab0e97"},"cell_type":"code","source":"class LGBClassifierCV(BaseEstimator,RegressorMixin) :\n    def __init__(self,fit_params=None,n_splits=3) :#,feature_name=feature_name) :\n        self.fit_params = fit_params\n        self.n_splits = n_splits\n        #self.feature_name = feature_name\n    def fit(self,X,y) : \n        print('begin fit . . .')\n        self.oof_preds = np.zeros((X.shape[0],target['group_id'].nunique())) \n        self.M = []\n        #X = np.where(X == np.inf,0,X)\n        X = check_array(X,force_all_finite ='allow-nan')\n        y = y.values\n        folds = StratifiedKFold(n_splits= self.n_splits, shuffle=True,random_state=1600)\n        M_fit=0\n        M_cv=0\n        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n            dtrain = lgb.Dataset(data=X[train_idx,:], \n                                 label=y[train_idx], \n                                 #feature_name=self.feature_name,\n                                 #categorical_feature=['col'],\n                                 )\n            dvalid = lgb.Dataset(data=X[valid_idx,:], \n                                 label=y[valid_idx], \n                                 #feature_name=self.feature_name,\n                                 #categorical_feature=['col'],\n                                 )\n            m = lgb.train(\n                train_set=dtrain,\n                valid_sets=[dtrain, dvalid],\n                params=self.fit_params,\n                num_boost_round=100000,\n                early_stopping_rounds=100,\n                verbose_eval=False\n            )\n            self.M.append(m)\n            self.oof_preds[valid_idx,:] = m.predict(X[valid_idx,:])\n            print(n_fold, accuracy_score(y[valid_idx],np.argmax(self.oof_preds[valid_idx,:],axis=1)))\n        print('final', accuracy_score(y,np.argmax(self.oof_preds,axis=1)))\n        return self\n    @property\n    def cv_scores_(self):\n        return self.oof_preds\n    def predict(self,X) :\n        sub_preds=np.zeros((X.shape[0],target['group_id'].nunique()))\n        #X = np.where(X == np.inf,0,X)\n        X = check_array(X,force_all_finite ='allow-nan')\n        for m in self.M :\n            sub_preds=np.add(sub_preds,m.predict(X)/5)\n        return sub_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"38206070011aff80066027719e96c41e10278325"},"cell_type":"code","source":"fit_params = {\n\n    'num_leaves': 18,\n    'min_data_in_leaf': 40,\n    'objective': 'multiclass',\n    'metric': 'multi_error',\n    'max_depth': 8,\n    'learning_rate': 0.01,\n    \"boosting\": \"gbdt\",\n    \"bagging_freq\": 5,\n    \"bagging_fraction\": 0.812667,\n    \"bagging_seed\": 11,\n    \"verbosity\": -1,\n    'reg_alpha': 0.2,\n    'reg_lambda': 0,\n    \"num_class\": target['group_id'].nunique(),\n    'nthread': -1\n}\n\nM=make_pipeline(QuantileTransformer(output_distribution='normal'),StandardScaler(),MinMaxScaler(),LGBClassifierCV(fit_params=fit_params) )\n#M=make_pipeline(StandardScaler(),LGBClassifierCV(fit_params=fit_params) )\ntarget\nM.fit(train_pivot,target['group_id'])#target_working)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"75379fe4b1e4ec07541f7bad3eb6141629ca6ac3"},"cell_type":"code","source":"for i in range(target['group_id'].nunique()) :\n    print(i,np.where(target['group_id'] == i,1,0).sum(),np.round(np.where(np.argmax(M.named_steps['lgbclassifiercv'].cv_scores_,axis=1)[target['group_id'] == i]==i,1,0).mean(),2) )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"411f4d9cb51bed40edaaf1704a4adb2d8c57f4a0"},"cell_type":"code","source":"oof_preds_grp_to_label=pd.Series(np.argmax(M.named_steps['lgbclassifiercv'].cv_scores_,axis=1)).map({a:b for a,b in target.loc[:,['group_id','surface']].drop_duplicates().values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"34d6a3f1e850ac6b76d00050eb008441c51688f5"},"cell_type":"code","source":"oof_preds_grp_to_label_map = oof_preds_grp_to_label.map({\n    'concrete':0,\n    'soft_pvc':1,\n    'wood':2,\n    'tiled':3,\n    'fine_concrete':4,\n    'hard_tiles_large_space':5,\n    'soft_tiles':6,\n    'carpet':7,\n    'hard_tiles':8,\n})\n\nfor i in range(target_working.nunique()) :\n    print(i,np.where(target_working == i,1,0).sum(),np.round(np.where(oof_preds_grp_to_label_map[target_working == i]==i,1,0).mean(),2) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a33b66391076d1f138ec7c08216cbcc5c864f84"},"cell_type":"code","source":"sub_preds=pd.Series(np.argmax(M.predict(test_pivot),axis=1)).map({a:b for a,b in target.loc[:,['group_id','surface']].drop_duplicates().values})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b588755a83943d05ae9b92ea8941da0358607408"},"cell_type":"code","source":"sub['surface']=sub_preds.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ce1d026b5d5ff4ffe67096bccb0febace7a0e88"},"cell_type":"code","source":"sub.to_csv('submittal.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}