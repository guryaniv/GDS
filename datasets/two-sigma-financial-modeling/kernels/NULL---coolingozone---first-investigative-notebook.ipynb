{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c73847c6-da86-6911-92b0-a24011bde994"
      },
      "source": [
        "This is my first notebook at Kaggle, it is really to get myself started on something."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4e24c2b-b700-f5b2-8f15-5240a1877d60"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "88f53b1f-cfd9-e86d-edf9-2dfe4141e91d"
      },
      "source": [
        "To load Kaggle enivornment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da75fe2b-a641-3532-d56e-3ec212117822"
      },
      "outputs": [],
      "source": [
        "import kagglegym\n",
        "# Create environment\n",
        "env = kagglegym.make()\n",
        "# Get first observation\n",
        "observation = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c50706e-e465-6fa6-55c0-11ec0fec846d"
      },
      "outputs": [],
      "source": [
        "with pd.HDFStore('../input/train.h5') as train:\n",
        "    df = train.get('train')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "681de0d9-e2fd-ea55-75c7-3e8a09179c12"
      },
      "source": [
        "Read in the value from train.h5 ile."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bdd498db-0641-bc70-adc7-101880817b90"
      },
      "source": [
        "Lets take a look at the data to have a feel of what we are actually having on hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "835c0c89-ed8d-5893-bd21-55f689bbcbba"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "df.head()\n",
        "\n",
        "#newdata=df.ix[:,2:110]\n",
        "#newdata=newdata.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8982d04e-e3e7-e66b-ab88-81706e9b44f6"
      },
      "source": [
        "Lets look at the column list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f36e3918-e268-3ce6-a1ad-474e661d619d"
      },
      "outputs": [],
      "source": [
        "for col in df.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f3c373b8-5e22-2c21-663f-da4d7c582eb7"
      },
      "source": [
        "get rid of rows with NAN in any column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a9f0b731-bdc5-9ebf-c2a0-4a31f023960a"
      },
      "outputs": [],
      "source": [
        "newdata=df.dropna()\n",
        "print(newdata.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "420122d2-ce1e-64e5-455e-8899a6cf7c05"
      },
      "source": [
        "observe the value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cee7024e-48b1-46dc-4e5d-b2e9ac4c6e81"
      },
      "outputs": [],
      "source": [
        "newdata[\"y\"].hist(bins=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a41c0f65-bdd3-b770-761c-30bec549633e"
      },
      "source": [
        "observe another column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "edc54d11-2dad-42b1-9c99-2e3d9301fd9c"
      },
      "outputs": [],
      "source": [
        "\n",
        "newdata[\"fundamental_11\"].hist(bins=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ff7e11b-cc15-b0ea-a9e3-97d6721a5c0e"
      },
      "source": [
        "all seem to be zero mean, that would mean that the data had went through some scaling pre-process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6cfbba5-07c4-b3ec-3b03-12a1be4626e6"
      },
      "outputs": [],
      "source": [
        "newdata[\"fundamental_12\"].hist(bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff7036b5-be39-d2db-7122-23ce9f6792ea"
      },
      "outputs": [],
      "source": [
        "print(newdata.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80945b02-d904-a7d3-c30e-eb984600d42a"
      },
      "outputs": [],
      "source": [
        "\n",
        "moments = df[['id', 'y']].groupby('id').agg([np.mean, np.std, stats.kurtosis, stats.skew]).reset_index()\n",
        "moments.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f2075bb-aef4-c343-6918-70fae9983aaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "moments = df[['timestamp','id']].groupby('id').agg([np.mean, np.std, stats.kurtosis, stats.skew]).reset_index()\n",
        "moments.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba3b2bfd-08a8-7982-b8b7-9bc1b8b6e531"
      },
      "outputs": [],
      "source": [
        "nansum = df.isnull().sum()/len(df)\n",
        "print(nansum)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6edbd87c-5aba-eb66-e0e5-826381467fbf"
      },
      "outputs": [],
      "source": [
        "print(nansum.shape)\n",
        "plt.bar(np.arange(0,len(nansum),1),nansum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "151a4ffc-41e9-430b-6941-ad6da66e2890"
      },
      "source": [
        "**\n",
        "\n",
        "would continue to add more code or explaination.\n",
        "------------------------------------------------\n",
        "\n",
        "**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34a87e78-f22d-330a-cfa0-09f2d5bcb278"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math\n",
        "FEATURE_SIZE=108   #total number of features also is the number of input to the network\n",
        "batch_size=32 \n",
        "LEARNING_RATE=0.01\n",
        "hidden1_units=FEATURE_SIZE\n",
        "hidden2_units=32\n",
        "d = tf.placeholder(tf.float32, shape=(batch_size,FEATURE_SIZE))                                              \n",
        "y = tf.placeholder(tf.float32, shape=(batch_size,1))\n",
        "#hidden layer 1 that interface with the input\n",
        "with tf.name_scope('hidden1'):\n",
        "    weights = tf.Variable(tf.truncated_normal([FEATURE_SIZE, hidden1_units],\n",
        "                        stddev=1.0 / math.sqrt(float(FEATURE_SIZE))),name='weights')\n",
        "    biases = tf.Variable(tf.zeros([hidden1_units]),name='biases')\n",
        "    hidden1 = tf.nn.relu(tf.matmul(d, weights) + biases)\n",
        "#hidden layer 2 \n",
        "with tf.name_scope('hidden2'):\n",
        "    weights = tf.Variable(tf.truncated_normal([FEATURE_SIZE, hidden2_units],\n",
        "                        stddev=1.0 / math.sqrt(float(FEATURE_SIZE))),name='weights')\n",
        "    biases = tf.Variable(tf.zeros([hidden2_units]),name='biases')\n",
        "    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
        "#softmax output\n",
        "with tf.name_scope('softmax_linear'):\n",
        "    weights = tf.Variable(tf.truncated_normal([hidden2_units, 1],\n",
        "                            stddev=1.0 / math.sqrt(float(hidden2_units))),name='weights')\n",
        "    biases = tf.Variable(tf.zeros([1]),name='biases')\n",
        "    logits = tf.matmul(hidden2, weights) + biases    \n",
        "\n",
        "#y = tf.to_int64(y)\n",
        "#cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y, name='xentropy')\n",
        "#loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8f0cab1-8423-9b4c-33df-c120a02f5ee1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}