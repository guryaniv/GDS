{"cells":[{"metadata":{"trusted":true,"_uuid":"a41d96b9aa0cae38d7ff8c8ef1dcf040c74c9794","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"915c77182dd69cbd940d41c39414638620449b97"},"cell_type":"markdown","source":"This notebook shows how to build and run Google sentencepiece package and tokenize the encoded text."},{"metadata":{"_uuid":"6b85f02f8fd8182963b58a8c820605694a4c1bb3"},"cell_type":"markdown","source":"# build sentencepiece\n\nNote: Internet must be enabled in kernel environment's settings for this step.\n\nDownload sentencepiece's source code and build the package."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1dc10e61d3009af38e0b6d463991be8a00bb7559","_kg_hide-output":true},"cell_type":"code","source":"%%bash -e\nif ! [[ -f ./spm_train ]]; then\n  wget https://github.com/google/sentencepiece/archive/v0.1.8.zip\n  echo '8799f4983608897e8eb3370385eda149180d309c7276db939f955d6507d53846  v0.1.8.zip' | sha256sum -c\n  unzip v0.1.8.zip\n  conda install -y cmake pkg-config\n  export SENTENCEPIECE_HOME=$(pwd)/sentencepiece\n  export PKG_CONFIG_PATH=${SENTENCEPIECE_HOME}/lib/pkgconfig\n  (cd sentencepiece-0.1.8 && mkdir -p build)\n  (cd sentencepiece-0.1.8/build && cmake -DCMAKE_INSTALL_PREFIX=${SENTENCEPIECE_HOME} ..  && make -j4 && make install)\n  (cd sentencepiece-0.1.8/python && python setup.py install)\n  rm -rf sentencepiece-0.1.8 v0.1.8.zip\nfi","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9337492b2e6f60530ddb6705710b7f3be11cf035"},"cell_type":"markdown","source":"# Prepare input"},{"metadata":{"trusted":true,"_uuid":"bdaa75781919358ce4046730951f83d94967d0d6"},"cell_type":"code","source":"def read_train_text(filename='../input/train.csv'):\n    return pd.read_csv(filename)\n\ndef write_cipher_text(texts, filename='spm_train.txt'):\n    with open(filename, 'w',encoding='utf-8') as f:\n        for text in texts:\n            f.write(text + \"\\n\")\n\ntrain_df = read_train_text()\ntest_df = read_train_text(filename='../input/test.csv')\nciphertexts = list(train_df.ciphertext.values) + list(test_df.ciphertext.values)\nwrite_cipher_text(ciphertexts)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfb5d3ab6e20aec73438f291c3f0950830631c8d"},"cell_type":"markdown","source":"# Train SentencePieceModel"},{"metadata":{"trusted":true,"_uuid":"e623cfc266fcc6ea57584e11c90f2129a3a4d386"},"cell_type":"code","source":"import sentencepiece as spm\nspm.SentencePieceTrainer.Train(\n        '--input=' + os.path.join('spm_train.txt') +\n        ' --model_prefix=train --vocab_size=1000')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e4b2b54ee288c4a35b9c10bd3e5640a10ff83f2"},"cell_type":"code","source":"def encode_ciphertext(ciphertext):\n    sp = spm.SentencePieceProcessor()\n    sp.Load('train.model')\n    encodedtext = []\n    for text in ciphertext:\n        encodedtext.append(sp.encode_as_ids(text))\n    return encodedtext\n\ntrain_encoded = encode_ciphertext(train_df.ciphertext)\ntest_encoded = encode_ciphertext(test_df.ciphertext)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Train Random Forest Model"},{"metadata":{"trusted":true,"_uuid":"65c6dd4d0d6bb43b855735928c38d150a2d9c867"},"cell_type":"code","source":"from collections import defaultdict, Counter\n\nword_counter = defaultdict(int)\nfor text in train_encoded + test_encoded:\n    counter = Counter(text)\n    for l,c in counter.items():\n        word_counter[l] += c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7671680be1f1e45f8fbf63e32a4df26cdb833391"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee2f7b89ab105fa6d68d94ad5255a0c5c03a8743"},"cell_type":"code","source":"def build_df(word_counter, df, encodedtext):\n    keys = list(word_counter.keys())    \n    rows = []\n    for rowid, row in df.iterrows():\n        counter = Counter(encodedtext[rowid])\n        entry = [counter.get(k, 0) for k in keys]\n        entry += [row['difficulty']]\n        if 'target' in row:\n            entry += [row['target']]\n        rows.append(entry)\n    return pd.DataFrame(rows)\n\ntrain = build_df(word_counter, train_df, train_encoded)\ntest = build_df(word_counter, test_df, test_encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f276debbfc234465d135728eaac69c9d3d19d8b6"},"cell_type":"code","source":"X = train.iloc[:, :-1]\nY = train.iloc[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b83ffcdc528f68f67e6705e1fd25fc918fabadf"},"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nacc = np.sum(y_pred == y_test) / len(y_test)\nprint(acc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bedfa27966328a28323f3a5dcc7eecee963d43c"},"cell_type":"markdown","source":"# Make submission"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"544dc12d119a9f75f89b9123c1161a3ff52afcfa"},"cell_type":"code","source":"rf.fit(X, Y)\ny_pred = rf.predict(test)\nsubmission = pd.DataFrame(test_df.Id, columns=['Id'])\nsubmission['Predicted'] = y_pred\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cb3f58a2985fe6a082b902be5db7217764f29e8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}