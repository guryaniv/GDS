{"cells":[{"metadata":{"_cell_guid":"a54ac529-9f01-4c9b-9db8-efbec06adaa2","_uuid":"349e8834482e322d1e2bb697a95dc6cb4a8a2f75","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.cross_validation import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0afdd27a-b10b-4ae5-ad56-e3dd382300fd","_uuid":"a718cdc5018272ecb490a813fe7ece460886988b","trusted":true},"cell_type":"code","source":"def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"a068185c-208b-47fd-8067-58b32de620b0","_uuid":"9a5241b8118973e9973a56ab346e8bcd0a3f8f63","trusted":true},"cell_type":"code","source":"print(\"Loading data...\")\ntrain = pd.read_table(\"../input/train.tsv\")\ntest = pd.read_table(\"../input/test.tsv\")\nprint(train.shape)\nprint(test.shape)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"93c4397f-668c-4f1a-83e7-5d7781602a22","_uuid":"9917a942904b6943feb8230860e3c193cf827579","trusted":true},"cell_type":"code","source":"#HANDLE MISSING VALUES\nprint(\"Handling missing values...\")\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8d559a40-0498-4a0c-b3e4-248f64dcf6b7","_uuid":"6a7af50cb2b2dd21b07323fa1a009938291d0269","trusted":true},"cell_type":"code","source":"#train.head(3)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"eec4bd91-2e73-4109-aca4-59e2ab531960","scrolled":true,"_uuid":"78e7990c273f44c5b782d5a7107764134f8c5afd","trusted":true},"cell_type":"code","source":"#PROCESS CATEGORICAL DATA\nprint(\"Handling categorical variables...\")\nle = LabelEncoder()\n\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le\n\ntrain.head(3)","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"2e08f2b1-e381-4554-b744-dd7686731969","_uuid":"462fe9b04899ba1c42adb9f075955e9073c171d6","trusted":true},"cell_type":"code","source":"#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n\nprint(\"   Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\nprint(\"   Transforming text to seq...\")\n\ntrain[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\ntest[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\ntrain[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\ntrain.head(3)","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"267c33ac-c9a2-4eb8-bed4-b7ebf17a8a7a","_uuid":"a9460468ca8b99bbe248621785f6590c76f6c232","trusted":true},"cell_type":"code","source":"max_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                  , np.max(test.seq_item_description.apply(lambda x: len(x)))])\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"2151ef93-0f84-41f7-afa5-d4d2aab6be1e","_uuid":"7d2cb64a48b54fa455fd49de04cf49bc5927a11d","trusted":true},"cell_type":"code","source":"train.seq_name.apply(lambda x: len(x)).hist()","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"698e12d2-5528-4e7e-90c8-757a20a8be79","_uuid":"f22ea453c253fc219e1e811671dff6146064ef4d","trusted":true},"cell_type":"code","source":"train.seq_item_description.apply(lambda x: len(x)).hist()","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"30f9b560-3864-4334-a707-56cd2f454fa1","_uuid":"439011d161b90cc5e24be1d233d41bd299a96cda","trusted":true},"cell_type":"code","source":"MAX_NAME_SEQ = 10\nMAX_ITEM_DESC_SEQ = 75\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())\n                  , np.max(train.seq_item_description.max())\n                  , np.max(test.seq_item_description.max())])+2\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"2b7e6caa-3b34-4b88-9be1-230348afe151","_uuid":"4cc7e087c64075ab692dbe37cc5b4e0607c35ab7","trusted":true},"cell_type":"code","source":"train[\"target\"] = np.log(train.price+1)\ntarget_scaler = MinMaxScaler(feature_range=(-1, 1))\ntrain[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\npd.DataFrame(train.target).hist()","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"82349e24-bf6b-4f60-afa5-0777416d2d4a","_uuid":"c2829ebc26abcaed6293a23189b15f59deba8a56","trusted":true},"cell_type":"code","source":"dtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)","execution_count":13,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"634c4d4e-4560-4d1f-88a9-44b366566371","_uuid":"aab79dd4dddbead59eb164ec32f750c9d7feee40","trusted":true},"cell_type":"code","source":"#KERAS DATA DEFINITION\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef get_keras_data(dataset):\n    X = {\n        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n        ,'brand_name': np.array(dataset.brand_name)\n        ,'category_name': np.array(dataset.category_name)\n        ,'item_condition': np.array(dataset.item_condition_id)\n        ,'num_vars': np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"b2f83248-f5e4-487c-8862-62d7f748b306","_uuid":"e58569ca95d4f3dd4d7d7f6bbf1de6c94936dd82","trusted":true},"cell_type":"code","source":"#KERAS MODEL DEFINITION\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\ndef get_model():\n    #params\n    dr_r = 0.1\n    \n    #Inputs\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #Embeddings layers\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layer\n    rnn_layer1 = GRU(16) (emb_item_desc)\n    rnn_layer2 = GRU(8) (emb_name)\n    \n    #main layer\n    main_l = concatenate([\n        Flatten() (emb_brand_name)\n        , Flatten() (emb_category_name)\n        , Flatten() (emb_item_condition)\n        , rnn_layer1\n        , rnn_layer2\n        , num_vars\n    ])\n    main_l = Dropout(dr_r) (Dense(128) (main_l))\n    main_l = Dropout(dr_r) (Dense(64) (main_l))\n    \n    #output\n    output = Dense(1, activation=\"linear\") (main_l)\n    \n    #model\n    model = Model([name, item_desc, brand_name\n                   , category_name, item_condition, num_vars], output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n    \n    return model\n\n    \nmodel = get_model()\nmodel.summary()    ","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a1b5e977e11fc84fba95f0b05327d046cdec31a"},"cell_type":"code","source":"#FITTING THE MODEL\nBATCH_SIZE = 20000\nepochs = 5\n\nmodel = get_model()\nmodel.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n          , validation_data=(X_valid, dvalid.target)\n          , verbose=1)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e6347a4d3845d4e376945bc546195bc14496add"},"cell_type":"code","source":"#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\nval_preds = model.predict(X_valid)\nval_preds = target_scaler.inverse_transform(val_preds)\nval_preds = np.exp(val_preds)+1\n\n#mean_absolute_error, mean_squared_log_error\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds[:,0]\nv_rmsle = rmsle(y_true, y_pred)\nprint(\" RMSLE error on dev test: \"+str(v_rmsle))","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"65731396-883a-4e69-8b89-d2dea4a8534b","_uuid":"93e632e1e067778ccda2b0388b631c0e34204bd4","trusted":true},"cell_type":"code","source":"#CREATE PREDICTIONS\npreds = model.predict(X_test, batch_size=BATCH_SIZE)\npreds = target_scaler.inverse_transform(preds)\npreds = np.exp(preds)-1\n\nsubmission = test[[\"test_id\"]]\nsubmission[\"price\"] = preds","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"6e626082-b577-480e-a238-8832940abeae","_uuid":"fc2eee7d84c2084fd7764e95a19fadf4a864d15c","trusted":true},"cell_type":"code","source":"submission.to_csv(\"./myNNsubmission4.csv\", index=False)\nsubmission.price.hist()","execution_count":19,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"14be63a9-d40c-4152-b098-860e12dde409","_uuid":"932f9701d2d6aea4060ef430261a196dbed690d7","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}