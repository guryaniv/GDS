{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5db7df34-4e6f-6576-9ba1-798538f85093"
      },
      "source": [
        "Line to line copy paste from notebook at \n",
        "https://www.kaggle.com/tobikaggle/leaf-classification/nn-through-keras-copied-mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c5c26ea-5c36-9735-fd71-61ff535d7dfe"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation\n",
        "from keras.utils.np_utils import to_categorical\n",
        "#from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7a7e4854-6c4e-65bc-d5a1-af6109eb6d4a"
      },
      "outputs": [],
      "source": [
        "## Read data from the CSV file\n",
        "data = pd.read_csv('../input/train.csv')\n",
        "parent_data = data.copy()\n",
        "ID = data.pop('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca172cc1-417f-e506-ef28-9ce4cdbf23c0"
      },
      "outputs": [],
      "source": [
        "## Since the labels are textual, so we encode them categorically\n",
        "y = data.pop('species')\n",
        "y = LabelEncoder().fit(y).transform(y)\n",
        "## We will be working with categorical crossentropy function\n",
        "## It is required to further convert the labels into \"one-hot\" representation\n",
        "y_cat = to_categorical(y)\n",
        "\n",
        "## Most of the learning algorithms are prone to feature scaling\n",
        "## Standardising the data to give zero mean =)\n",
        "X = StandardScaler().fit(data).transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ebc3f41-5692-5e45-1ceb-435424d0fb76"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(250, input_dim=192,  init='uniform', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(150, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(99, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics = [\"accuracy\"])\n",
        "history = model.fit(X, y_cat, batch_size=64, nb_epoch=250, verbose=0, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93d0be6e-47ce-8d6e-b726-a1f51daac957"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "## Plotting the loss with the number of iterations\n",
        "plt.semilogy(history.history['loss'])\n",
        "plt.semilogy(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b0acbe9b-5737-f0fa-3421-ff7126a60324"
      },
      "outputs": [],
      "source": [
        "## Plotting the error with the number of iterations\n",
        "## With each iteration the error reduces smoothly\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98c2c895-d19d-c7ce-2c1c-a9d318489f44"
      },
      "outputs": [],
      "source": [
        "## read test file\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "index = test.pop('id')\n",
        "test = StandardScaler().fit(test).transform(test)\n",
        "yPred = model.predict_proba(test)\n",
        "\n",
        "## Converting the test predictions in a dataframe as depicted by sample submission\n",
        "yPred = pd.DataFrame(yPred,index=index,columns=sort(parent_data.species.unique()))\n",
        "\n",
        "fp = open('submission_nn_kernel.csv','w')\n",
        "fp.write(yPred.to_csv())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b00ea799-62ea-b88a-7f2d-c942db00ca96"
      },
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \".\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79dd7d85-630b-9093-7f80-af2514f545ef"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}