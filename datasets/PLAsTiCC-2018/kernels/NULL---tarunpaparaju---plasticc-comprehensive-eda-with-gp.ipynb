{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data_df = pd.read_csv('../input/training_set.csv')\ntrain_metadata_df = pd.read_csv('../input/training_set_metadata.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b7457c0417f37b3687e8cb81599b0824bc7dad3"},"cell_type":"markdown","source":"**Simple Feature Engineering**"},{"metadata":{"trusted":true,"_uuid":"b7dc3ae1e5f799f27d10d01d6cd30f2256941f48"},"cell_type":"code","source":"train_data_df['flux_ratio_sq'] = np.power(train_data_df['flux'] / train_data_df['flux_err'], 2.0)\ntrain_data_df['flux_by_flux_ratio_sq'] = train_data_df['flux'] * train_data_df['flux_ratio_sq']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"829c2a013125ca4858b2d9878c7d39388d534380"},"cell_type":"markdown","source":"**Extracting all features from the train meta data and features like minimum, maximum, mean, median, skew etc from the time-series data (train data)**"},{"metadata":{"trusted":true,"_uuid":"9bdcd8e322e570695626babc5739b8c2843070b8"},"cell_type":"code","source":"data_features = train_data_df.columns[1:]\nmetadata_features = train_metadata_df.columns[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75f546b19b246e53155d2471aec9497443a4d018"},"cell_type":"code","source":"groupObjects = train_data_df.groupby('object_id')[data_features]\n\nprint(\"Add constant object features\")\nfeatures = train_metadata_df.drop(['target'], axis=1)\n\nprint(\"Add sum of mutable object features\")\nfeatures = pd.merge(features, groupObjects.agg('sum'), how='right', on='object_id', suffixes=['', '_sum'])\n\nprint(\"Add mean of mutable object features\")\nfeatures = pd.merge(features, groupObjects.agg('mean'), how='right', on='object_id', suffixes=['', '_mean'])\n\nprint(\"Add median of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg('median'), how='right', on='object_id', suffixes=['', '_median'])\n\nprint(\"Add minimum of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg('min'), how='right', on='object_id', suffixes=['', '_min'])\n\nprint(\"Add maximum of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg('max'), how='right', on='object_id', suffixes=['', '_max'])\n\nprint(\"Add range of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg(lambda x: max(x) - min(x)), how='right', on='object_id', suffixes=['', '_range'])\n\nprint(\"Add standard deviation of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg('std'), how='right', on='object_id', suffixes=['', '_stddev'])\n\nprint(\"Add skew of mutable features\")\nfeatures = pd.merge(features, groupObjects.agg('skew'), how='right', on='object_id', suffixes=['', '_skew'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5df85c42ad9ac0ef06f44e1dedf02729c028f7b"},"cell_type":"code","source":"features = features.fillna(features.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"874bc271dfc6b5061de92cb01ef6d805413d1f0e"},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b9e243fd039ddcfe057453b7de9cd15bc54c767"},"cell_type":"code","source":"features = features.drop('object_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0e729526f711fdf55690c3a88936e26c2c3774e"},"cell_type":"code","source":"targets = train_metadata_df.target.map({6:0, 15:1, 16:2, 42:3, 52:4, 53:5, 62:6, 64:7, 65:8, 67:9, 88:10, 90:11, 92:12, 95:13})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd5276d4583656e9ed1bfadc7900e79839f252c7"},"cell_type":"code","source":"targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"444e4284bbf687140d18c3e3207404d28d28ec6b"},"cell_type":"code","source":"features['target'] = targets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64b8dc12df3c26e3b456541754214390626dbcab"},"cell_type":"markdown","source":"**Engineer new features using Genetic Programming with the gplearn library.**"},{"metadata":{"trusted":true,"_uuid":"569632c3b4300a7d7b440ed3e584c82fefe89633"},"cell_type":"code","source":"import gplearn\nfrom gplearn.genetic import SymbolicTransformer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6b5144c6bbc1c51a96e848e35a537acc2280278"},"cell_type":"code","source":"import keras \nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca0197e40d7817ceb035c7b9513af7eb62f33004"},"cell_type":"code","source":"function_set = ['add', 'sub', 'mul', 'div',\n                'sqrt', 'log', 'abs', 'neg', 'inv',\n                'max', 'min']\n\ngp = SymbolicTransformer(generations=100, population_size=2000,\n                         hall_of_fame=100, n_components=10,\n                         function_set=function_set,\n                         parsimony_coefficient=0.0005,\n                         max_samples=0.9, verbose=1,\n                         random_state=0, n_jobs=3)\n\ngp.fit(features.drop('target', axis=1).values, targets.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c11c3a76923f9638c9bbab875a6bb8f436290831"},"cell_type":"code","source":"engineered_features = gp._programs\n\nfor i in range(len(engineered_features)):\n    for engineered_feature in engineered_features[i]:\n        if engineered_feature != None:\n            print(engineered_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4c57fb89daaaced4b6509fc4276be1159233e2e"},"cell_type":"code","source":"new_features = pd.DataFrame(gp.transform(features.drop('target', axis=1).values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6575c9b2731059c154cca90887833190c67d224"},"cell_type":"code","source":"features = pd.concat([features, new_features], axis=1, join_axes=[features.index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"012174c6093422d199f31ef32ef30599668ee5b8"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5d212fda15d494c3b8ca81e1df386f031f25470"},"cell_type":"markdown","source":"**Visualize the probability distributions of each feature for different astronomical source types using seaborn**"},{"metadata":{"trusted":true,"_uuid":"5142c7f16359ee5c7dc823bf46a3af19c71e14b6"},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"724ea959d636e35c965d0273926f8660168a648f"},"cell_type":"code","source":"sns.set(style=\"darkgrid\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3247ee718effb478035d408640da91b7aa869849"},"cell_type":"markdown","source":"**Original features**"},{"metadata":{"trusted":true,"_uuid":"1e4adc66b17848b1af06b0401856c305c191c779"},"cell_type":"code","source":"columns = features.columns\n\nfor column in columns[:-10]:\n    sns.pairplot(x_vars=column, y_vars=column, hue='target', diag_kind='kde', data=features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57f1ea6710bb14522ba69f53da5c687ce65759ee"},"cell_type":"markdown","source":"**Engineered features**"},{"metadata":{"trusted":true,"_uuid":"b5615ecfd6c75b84d40fc1363677b70c6ad89025"},"cell_type":"code","source":"for column in columns[-10:]:\n    sns.pairplot(x_vars=column, y_vars=column, hue='target', diag_kind='kde', data=features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d45ad84fb7f146906f6d6a8b3b8e68711e80174d"},"cell_type":"markdown","source":"**The features for which the data distributions for different classes are very different from each other are most likely the more \"important\" features. This \"difference\" between distribution can be measured using Kullback-Leibler Divergence (a distribution similarity metric)**"},{"metadata":{"trusted":true,"_uuid":"bc52ffa052bbb319e7327d6a2249df95d9e98cd7"},"cell_type":"code","source":"# sns_plot = sns.pairplot(data=features, hue='target', diag_kind='kde')\n# sns_plot.savefig('plasticc_visualizations.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7f2ea667272556740a5a6412b9b05f20c5d8791"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}