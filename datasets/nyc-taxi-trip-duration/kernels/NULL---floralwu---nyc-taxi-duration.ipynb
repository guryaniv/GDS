{"nbformat_minor": 1, "cells": [{"cell_type": "code", "outputs": [], "source": ["# Importing the libraries\n", "import numpy as np \n", "import pandas as pd \n", "import matplotlib.pyplot as plt\n", "import datetime as dt\n", "from datetime import datetime, timedelta,date\n", "from sklearn.model_selection import train_test_split  \n", "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n", "import time"], "execution_count": null, "metadata": {"_cell_guid": "0c31ed7b-e8f9-4cc2-a65c-a571d0491c57", "_execution_state": "idle", "collapsed": true, "_uuid": "2c4f71619a7f1c6b3e5094ec5b52985f5b3d9a6d"}}, {"cell_type": "code", "outputs": [], "source": ["# Importing the dataset\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "execution_count": null, "metadata": {"_cell_guid": "2c57f228-ecb8-4f10-9e33-7296f46960ef", "_execution_state": "idle", "collapsed": true, "_uuid": "e54e7803002010ecb949823b9306705cfb64fc78"}}, {"cell_type": "code", "outputs": [], "source": ["# First of all, take a look at the imported data\n", "print(\"train as a pd DataFrame\")\n", "print(train.info())\n", "print(train.head())\n", "print(\"test as a pd DataFrame\")\n", "print(test.info())\n", "print(test.head())"], "execution_count": null, "metadata": {"_cell_guid": "49963966-26b9-4de6-9399-8b698e838a2e", "_execution_state": "idle", "_uuid": "53e1184cc99baafad84fcb51c138773e10274a6a"}}, {"cell_type": "markdown", "source": ["Before fitting the data to the machine learning models, we need perform data pre-processing. According to the problem statement, the dependent variable is trip_duration. From that test dataset, we konw tha the independent variables are: all the attributets in the test dataset but id, becaus id cannot have any logical contribution to the duration. However, the id can be used to check if the train and test over laping with the train dataset.\n", "\n", "So the pre-processing will includ the following stepes::\n", "1. Missing data: There is no null cell for all attributes. So there is no need to take care of missing data;\n", "2. Need to check colu mn id, to see if there is any overlapping ids in train and test data set;\n", "3. Outlier: Need to chedk if the trip_duration has outliers;\n", "4. Spetial data type: \n", "     4.1The pickup_datetime, and dropoff_datetime are of the type of datetime,need transform to date, weekday, hour, min, and check if holiday;\n", "    4.2 store_and_fwd_flag is categorical, need to be encoded."], "metadata": {"_cell_guid": "3b972112-ce9e-4589-b0f3-49081c75b560", "_uuid": "652d69272f40d623f00143af6dd9012c3ed5167f"}}, {"cell_type": "code", "outputs": [], "source": [" #  check  column id, to see if there is any overlapping ids in train and test data set;\n", "train_id = set(train['id'].values)\n", "test_id = set(test['id'].values)\n", "overlap_id = train_id.intersection(test_id)\n", "print(\"Number of overlaping id in the train and test datasets : \", len(overlap_id))"], "execution_count": null, "metadata": {"_cell_guid": "3e249dd9-2a61-41b5-8041-8ba1ff46bb35", "_execution_state": "idle", "_uuid": "c9a3fdc02524977ca3cde9bfd10415a304865559"}}, {"cell_type": "markdown", "source": ["So there is no overlaping ids in train and test datasets. But we need to check if the trip_duration has outliers, and clean the outliers if any.\n", " "], "metadata": {"_cell_guid": "5cf5967f-3878-4bbb-b35f-a09adb253d3a", "_uuid": "dceb421c4149e243253723866d22a39f95bbb931"}}, {"cell_type": "code", "outputs": [], "source": ["y = train['trip_duration'] \n", "print(\"Longest trip_duration = {}  minutes: \" .format( np.max(y.values)//60))\n", "print(\"Smallest trip_duration = {} minutes: \".format(np.min(y.values)//60))\n", "print(\"Average trip_duration = {} minutes\".format( np.mean(y.values)//60))"], "execution_count": null, "metadata": {"_cell_guid": "34b873d5-ca64-454e-9180-d0341dc3730f", "_execution_state": "idle", "_uuid": "4fbc3cb98d4af5950380b51fcb74cd7af6c762ab"}}, {"cell_type": "markdown", "source": ["The trip_duration of 8771 and 0 min should be outliers. "], "metadata": {"_cell_guid": "fc5e20d9-1936-48f3-94d6-e174c97b6a34", "_uuid": "a85fa8cf6f9509cc442cb11846e829a1b543c6c3"}}, {"cell_type": "code", "outputs": [], "source": ["#visalize the trip_duration \n", "f = plt.figure(figsize=(8,6))\n", "#plt.scatter(range(len(y)), np.sort(y.values), alpha=0.5)\n", "plt.scatter(range(len(y)) ,  y , alpha=0.5)\n", "plt.xlabel('Index')\n", "plt.ylabel('Trip duration in minutes')\n", "plt.show()"], "execution_count": null, "metadata": {"_cell_guid": "66c009cf-72d1-469b-932d-a6d6214f5b79", "_execution_state": "idle", "_uuid": "b370f8701f8a280d4862f96c4a72fb7e84264800"}}, {"cell_type": "markdown", "source": ["The plot shows that there are 4 outliers that have extreamly high values..\n", "According to the law of large numbers, trip_duration followsnormal distribution. We identify outsiders as those out of (mean - 2*sigma, mean + 2*sigma), and exclude the outliers."], "metadata": {"_cell_guid": "a27615be-f12d-42a9-8e56-02c944bb6365", "_uuid": "8ccfa990d28215f1969af07e3feb4840528e84a6"}}, {"cell_type": "code", "outputs": [], "source": ["#exulding outliers\n", "P = np.percentile(y, [0.5, 99.5])\n", "train= train[(train['trip_duration'] > P[0]) & (train['trip_duration']< P[1])]\n", "# redefine y\n", "y = train['trip_duration']"], "execution_count": null, "metadata": {"_cell_guid": "9a70746d-f4e4-46d2-9384-877e961cf57f", "_execution_state": "idle", "collapsed": true, "_uuid": "199efe592c1ae05ebc89dbb1d6767584981cef93"}}, {"cell_type": "code", "outputs": [], "source": ["#visalize the improved trip_duration \n", "f = plt.figure(figsize=(8,6))\n", "#plt.scatter(range(len(y)), np.sort(y.values), alpha=0.5)\n", "plt.scatter(range(len(y)) ,  y , alpha=0.5)\n", "plt.xlabel('Index')\n", "plt.ylabel('Trip duration in minutes')\n", "plt.show()"], "execution_count": null, "metadata": {"_cell_guid": "facbf3c3-5df5-4dd4-9049-d32badd69c5e", "_execution_state": "idle", "_uuid": "8952c9c75752b10a5b91e47b30b0db91c45cd45f"}}, {"cell_type": "code", "outputs": [], "source": ["#visaulize the distribution of y \n", "f = plt.figure(figsize=(8,6))\n", "plt.hist(y/60)\n", "plt.xlabel('Trip duration in minutes')\n", "plt.ylabel('Frequency')\n", "plt.show()"], "execution_count": null, "metadata": {"_cell_guid": "c015d3dc-7f7b-4b95-b1d2-16491773e3f0", "_execution_state": "idle", "_uuid": "e8bebf863fd6d6a5827940c79649298585116d66"}}, {"cell_type": "markdown", "source": ["The graph looks resonable."], "metadata": {"_cell_guid": "f9a32554-c244-4e17-a934-9d7cd7e4b8f6", "_uuid": "9755beeadf0fb3fe27bec3a0ed295a3ea3b5259a"}}, {"cell_type": "code", "outputs": [], "source": ["# data preprocessing on trainning dataset\n", "# takeing care of  datetime type\n", "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n", "train['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'])\n", "\n", "train['pickup_day'] = train['pickup_datetime'].dt.day\n", "train['pickup_month'] = train['pickup_datetime'].dt.month\n", "train['pickup_weekday'] = train['pickup_datetime'].dt.weekday\n", "train['pickup_hour'] = train['pickup_datetime'].dt.hour\n", "\n", "train['drop_day'] = train['dropoff_datetime'].dt.day\n", "train['drop_month'] = train['dropoff_datetime'].dt.month\n", "train['drop_weekday'] = train['dropoff_datetime'].dt.weekday\n", "train['drop_hour'] = train['dropoff_datetime'].dt.hour\n", "\n", "# finding out holidays\n", "cal = calendar()\n", "holidays = cal.holidays(start=train['pickup_datetime'].min(), end=train['pickup_datetime'].max())\n", "#df = pd.DataFrame()\n", "train['holiday'] = train['pickup_datetime'].astype('datetime64[ns]').isin(holidays)\n", " \n", "#construct training dataset as in testing dataset\n", "\n", "train1 = train\n", "#train = train1\n", "# First of all, take a look at the imported data\n", "print(\"train1 as a pd DataFrame\")\n", "print(train.info())\n", "\n", "train1 = train1.drop('pickup_datetime',axis =1)\n", "train1 = train1.drop('dropoff_datetime',axis =1)\n", "train1 = train1.drop('trip_duration',axis  =1)\n", "train1 = train1.drop('drop_day',axis  =1)\n", "train1 = train1.drop('drop_month',axis  =1)\n", "train1 = train1.drop('drop_weekday',axis  =1)\n", "train1 = train1.drop('drop_hour',axis  =1)\n", "print(\"train1 after dropping columns\")\n", "print(train1.info())\n", "\n", "#Encoding categorical data\n", "from sklearn.preprocessing import LabelEncoder\n", "train1 = train1.values\n", "labelencoder_X = LabelEncoder()\n", "\n", "train1[:,7] = labelencoder_X.fit_transform(train1[:,7])\n", "train1[:,12] = labelencoder_X.fit_transform(train1[:,12])\n", "#set up X_traian  \n", "X = train1\n", "y = y.values"], "execution_count": null, "metadata": {"_cell_guid": "5a2591c5-5acd-429f-95a7-756d2eb4cd99", "_execution_state": "idle", "_uuid": "6252ef6df8d32df8c9d6331d804b9849e8d41445"}}, {"cell_type": "code", "outputs": [], "source": ["# Splitting the dataset into the Training set and Test set\n", "# this is for the purpose of evaluating the performance, not for the required predetion \n", "from sklearn.cross_validation import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n", "X_train_id = X_train[:,0]\n", "X_test_id = X_test[:,0]\n", "X_train = X_train[:,1:]\n", "X_test = X_test[:,1:]\n"], "execution_count": null, "metadata": {"_cell_guid": "ddb39a53-6576-4ef1-9bb6-245bc5994e6a", "_execution_state": "idle", "_uuid": "e850b40cc99281bacd5b4e55e5ad4097184db120"}}, {"cell_type": "code", "outputs": [], "source": ["# Feature Scaling\n", "from sklearn.preprocessing import StandardScaler\n", "sc_X = StandardScaler()\n", "X_train = sc_X.fit_transform(X_train)\n", "X_test = sc_X.transform(X_test)"], "execution_count": null, "metadata": {"_cell_guid": "8f08c0f4-feb1-4302-8b37-0c7506083e26", "_execution_state": "idle", "_uuid": "31af6a63a79cad530bfcd3ef83d94ce8b875b8cb"}}, {"cell_type": "code", "outputs": [], "source": ["# Fitting Multiple Linear Regression \n", "from sklearn.linear_model import LinearRegression# Predicting the Test set results\n", " \n", "regressor = LinearRegression()\n", "regressor.fit(X_train, y_train)"], "execution_count": null, "metadata": {"_cell_guid": "6ee1649d-5575-40f5-9957-58d7db0f0911", "_execution_state": "idle", "_uuid": "ee50fdb484aaf452f440f790819d39574560c007"}}, {"cell_type": "code", "outputs": [], "source": ["# Predicting the Test set results (this X_test is part of the train data, for performance evaluation popose)\n", "y_pred = regressor.predict(X_test) \n", "print (y_pred)\n", "print (y_test)"], "execution_count": null, "metadata": {"_cell_guid": "78c631ef-d9a4-4a74-8287-873ecb820387", "_execution_state": "idle", "_uuid": "cd5c1e6f961851a5dfa4d84e45e046bf0fb0863f"}}, {"cell_type": "code", "outputs": [], "source": ["#result = pd.concat(comp, ignore_index=True)\n", "result = pd.DataFrame({'id':X_test_id,'y_test':y_test,'y_pred':y_pred})"], "execution_count": null, "metadata": {"collapsed": true}}, {"cell_type": "code", "outputs": [], "source": ["# Evaluating the model performance\n", "import statsmodels.formula.api as sm\n", "X = X[:,1:]\n", "X = sc_X.fit_transform(X)\n", "X = np.append(arr = np.ones((1444013, 1)).astype(int), values = X, axis = 1)\n", "X_opt = X[:, [ 1, 2, 3, 4, 5,6,7,8,9,10,11,12]]\n", "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n", "regressor_OLS.summary()"], "execution_count": null, "metadata": {"_cell_guid": "c962cbfa-9233-4894-87c3-e5409d4da6d4", "_uuid": "75c2c611998a113d77cfb8a03444b7c637d029c2"}}, {"cell_type": "code", "outputs": [], "source": [], "execution_count": null, "metadata": {"collapsed": true}}, {"cell_type": "markdown", "source": ["The smallest eigenvalue is      0. This might indicate that there are strong multicollinearity problems or that the design matrix is singular. The result shows that multiple linear regress is not a good model for this data. "], "metadata": {"_cell_guid": "9f1c5da8-f4ea-462c-a26d-a9de3136e9c1", "_uuid": "41f33fe00623a0d9bf2d4027f6896916a75d5f80"}}], "nbformat": 4, "metadata": {"language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.6.1", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}