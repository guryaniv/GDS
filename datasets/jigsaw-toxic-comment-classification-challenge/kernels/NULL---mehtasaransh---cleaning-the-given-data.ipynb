{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "outputs": [], "metadata": {"_uuid": "3653f3dff3b656f0dc05eb27d1f9b929da36127f", "_cell_guid": "fbb06c7b-4dd8-4ae0-b225-10fe6d7fa36e", "collapsed": true}}, {"cell_type": "code", "source": ["import re\n", "import string\n", "import os"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "39e2f6e6b5b76e764f0f0cb4cb787617baf8436e", "_cell_guid": "357f6d2e-51e6-405b-ac94-132ff249da86", "collapsed": true}}, {"cell_type": "code", "source": ["trainPath = \"../input/train.csv\"\n", "testPath = \"../input/test.csv\""], "execution_count": null, "outputs": [], "metadata": {"_uuid": "459ef28243c6d91fc03709f58b7df85ab3702c36", "_cell_guid": "fcf19a0a-9dfe-493f-ba73-c31074ceff30", "collapsed": true}}, {"cell_type": "markdown", "source": ["Here I am just cleaning the text of both train and test datasets. Making it free from any kind of punctuations like !, ==, #, ? etc"], "metadata": {"_uuid": "2bf9c3e3618e71bbb993b4094563cf7d3c83ee5e", "_cell_guid": "16e6c57e-5923-4f98-9fb3-b4233fd0e533"}}, {"cell_type": "code", "source": ["df = pd.read_csv(trainPath)\n", "df.head()"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "bd63ef114294086393c9f524003a4dcec55984fe", "_cell_guid": "342ec454-6f54-439f-a4a1-8cdef07f6ee0", "collapsed": true}}, {"cell_type": "markdown", "source": ["# we will make translation table (or dictionary) to remove punctions,\n", "# we ll map each punctuation to None, so translation will remove it whenever it finds it\n", "# specificaaly remove punctuations\n", "# we can also use the regex, re.sub(re.sub('[^a-zA-Z]+', '', sen))"], "metadata": {"_uuid": "0cc11d3b3175d3fb70a6df7b264406c42060c6cf", "_cell_guid": "9291c18b-8e11-47a9-b8d6-3f16777d3249"}}, {"cell_type": "code", "source": ["totalContentCleaned = []\n", "punctDict = {}\n", "for punct in string.punctuation:\n", "    punctDict[punct] = None\n", "transString = str.maketrans(punctDict)\n", "# since we intent to remove any punctuation with ''\n", "for sen in df['comment_text']:\n", "    \n", "    #cleanedString = re.sub('[^a-zA-Z]+', '', sen)\n", "    \n", "    p = sen.translate(transString)\n", "    totalContentCleaned.append(p)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "0cd2a7cf3e51848bcad08bf038ec04df846150b6", "_cell_guid": "89f021a2-c77a-43f1-a24f-0cce16c78860", "collapsed": true}}, {"cell_type": "code", "source": ["totalContentCleaned[:5]"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "e6801f6725c07412e03ba1b6a989e7a267a600c9", "_cell_guid": "68d94259-c31a-4bd7-b314-81db4afd0471", "collapsed": true}}, {"cell_type": "code", "source": ["df['comment_text'] = totalContentCleaned\n", "# we can save the file to csv if we want in local machine\n", "#df.to_csv(os.path.join(os.path.abspath('data'), 'train_cleaned.csv'), index = False)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "7bfbe284cfa5b0af3038e6cbee5b842dd57826a6", "_cell_guid": "ebbb326b-7780-449e-906b-2682745461bd", "collapsed": true}}, {"cell_type": "code", "source": ["df2 = pd.read_csv(testPath)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "91ce4f55bca48e3a33cdef16dda8f9f7a0d9b999", "_cell_guid": "4483ec47-c35f-4782-903c-2191916a5224", "collapsed": true}}, {"cell_type": "code", "source": ["df2.head()"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "697d92f7370f8a4e2ee8c81f9f5202ef83ec530a", "_cell_guid": "2030fd09-eeb5-4e63-97b8-efdbfa0dd067", "collapsed": true}}, {"cell_type": "code", "source": ["totalContentCleaned = []\n", "for sen in df2['comment_text']:\n", "    \n", "    #cleanedString = re.sub('[^a-zA-Z]+', '', sen)\n", "    sen = str(sen)\n", "    p = sen.translate(transString)\n", "    totalContentCleaned.append(p)\n", "df2['comment_text'] = totalContentCleaned"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "e9b409d1d39a229373d0aa1964c4dbe7262430f7", "_cell_guid": "15f53142-df7c-4628-bc91-c3c8afa852e1", "collapsed": true}}, {"cell_type": "code", "source": ["df2.head()\n", "#df2.to_csv(os.path.join(os.path.abspath('data'), 'test_cleaned.csv'), index = False)"], "execution_count": null, "outputs": [], "metadata": {"_uuid": "1d453de363f53c539eeda9429452c6940788d75d", "_cell_guid": "decca1a1-0e49-4902-8940-020a6e279239", "collapsed": true}}, {"cell_type": "markdown", "source": ["# Thus we have done cleaning for both the files"], "metadata": {"_uuid": "173ef91c775484e09563581c7e14d4083208daad", "_cell_guid": "86f103b4-079d-4bb2-b61f-7dcefbb9b56b"}}, {"cell_type": "code", "source": [], "execution_count": null, "outputs": [], "metadata": {"_uuid": "811ea0d276089776cfacaf0bf80be40e0f537ea1", "_cell_guid": "15e14a37-19e4-4dc4-893d-46477f113bdb", "collapsed": true}}], "metadata": {"language_info": {"nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}