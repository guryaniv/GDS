{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d939a075-c4f4-6f17-db08-e3be8fd3b4fa"
      },
      "source": [
        "The problem of Native Bayesian algorithm is : all features must be relatively independent. Originally, I directly use bayesian algorithm to classify leaves. the code and result as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f6e3f6b2-30b0-6e0e-ffb8-64210dc7ad39"
      },
      "outputs": [],
      "source": [
        "# apply bayesian model for calculating the probability of sample\n",
        "def BayesClassify0(testData,dicSubsetMean,dicSubsetVar,dicSubsetPbi):\n",
        "\tdicTestDataBayes = {}\n",
        "\tn = np.shape(testData)[1]\n",
        "\t#\n",
        "\tfor key in dicSubsetMean.keys():\n",
        "\t\tdataMean = dicSubsetMean[key][0]\n",
        "\t\tdataVar = dicSubsetVar[key][0]\n",
        "\t\tPBi = dicSubsetPbi[key]\n",
        "\t\ttestData = testData[0]\n",
        "\t\tPABi = [0]\n",
        "\t\tfor j in range(n):\n",
        "\t\t\tif dataVar[0,j]==0:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tPAjBi = np.exp(-pow((testData[0,j]-dataMean[0,j]),2)/(2*dataVar[0,j]))/np.sqrt(2*3.1415*dataVar[0,j])\n",
        "\t\t\tif PAjBi>0:\n",
        "\t\t\t\tPABi.append(math.log(PAjBi,2))\n",
        "\t\tPBiA = sum(PABi) + PBi\n",
        "\t\tdicTestDataBayes[key] = PBiA\n",
        "\t#\n",
        "\tsortPBiA = sorted(dicTestDataBayes.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
        "\treturn sortPBiA[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca91baed-5f88-9a79-5647-a23c1f0b110a"
      },
      "source": [
        "Total test samples:49 \tavgErrCount:38 \tavgErrRate:0.789116\n",
        "\n",
        "the above result is bad, I think the reason is that some original features are locally relevant.\n",
        "so I allpy PCA to make features irrelevant, and the run bayesian algorithm again.\n",
        "the code and results as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e0403c0-359e-ea9d-ba39-b058341ae897"
      },
      "outputs": [],
      "source": [
        "# PCA\n",
        "def pca(dataSet,topNfeat=9999):\n",
        "\tmeanVals = np.mean(dataSet,axis=0)\n",
        "\tdataRemoved = dataSet-meanVals\n",
        "\tcovMat = np.cov(dataRemoved,rowvar=0)\n",
        "\t#\n",
        "\teigVals,eigVects = np.linalg.eig(np.mat(covMat))\n",
        "\teigValInd = np.argsort(eigVals)\n",
        "\teigValInd = eigValInd[:-(topNfeat+1):-1]\n",
        "\tredEigVecs = eigVects[:,eigValInd]\n",
        "\t#\n",
        "\treduceSet = dataRemoved*redEigVecs\n",
        "\treturn reduceSet,eigVals,redEigVecs\n",
        "\n",
        "def contribution(eigVals,tops):\n",
        "\ttotal = sum(eigVals)\n",
        "\tfor i in range(tops):\n",
        "\t\tconYi = eigVals[i]/total\n",
        "\t\tprint \"No.\",i+1,\" contribution rate:\",conYi\n",
        "\tsconYi = sum(eigVals[:i+1])/total\n",
        "\tprint \"the top \",i+1,\" contribution rate:\",sconYi,\"\\n\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73f49697-eed8-4c7d-9c29-effc7048d107"
      },
      "source": [
        "No. 1  contribution rate: 0.149800041582\n",
        "\n",
        "No. 2  contribution rate: 0.101889003956\n",
        "\n",
        "No. 3  contribution rate: 0.0867181502113\n",
        "\n",
        "... ...\n",
        "\n",
        "No. 88  contribution rate: 0.000521767479293\n",
        "\n",
        "No. 89  contribution rate: 0.000508699929438\n",
        "\n",
        "No. 90  contribution rate: 0.000505613673714\n",
        "\n",
        "the top  90  contribution rate: 0.99146981703\n",
        "\n",
        "Total test samples:49 \tavgErrCount:6 \tavgErrRate:0.123810\n",
        "\n",
        "\n",
        "\n",
        "The result is greatly improved, but still not good enough."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}