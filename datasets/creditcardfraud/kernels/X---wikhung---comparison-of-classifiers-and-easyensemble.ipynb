{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "68107d86-d728-627e-b6e3-4d59bc207590"
      },
      "source": [
        "# 11-10-2016\n",
        "\n",
        "In this script, I examined the performance of three classifiers (Logistic Regression, RandomForest, & AdaBoost) and an undersampling method on this highly unbalanced dataset. The undersampling technique, [EasyEnsemble][1] proposed by Liu, Wu, and Zhou (2008), samples a subset of the negative cases to create a balanced dataset. A classifier is then trained on this reduced dataset and generate predictions for the test set. This procedure is repeated multiple times and the test predicitions are aggregated.\n",
        "\n",
        "Without doing any hyperparameter tuning, I find the undersampling technique provided little to no improvement. I think this is due to the fact that most classifiers are able to do a decent job with any modifications. This result is consistent with the ones reported by Liu et al. (2008). \n",
        "\n",
        "\n",
        "  [1]: http://ieeexplore.ieee.org/document/4717268/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e524d6f8-016d-a047-a64d-68bd504c6e84"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42be3142-085a-e62d-a722-234bf9ecfdfd"
      },
      "outputs": [],
      "source": [
        "random.seed(2016)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91ecf377-dc49-3928-8f20-f2a40b0a17fe"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/creditcard.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4e95bc51-ee11-34e9-7e8c-2327e2a84741"
      },
      "source": [
        "I dropped the purchase time and normalized the purchase amount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9152e237-14c2-9d88-4497-0570dc50eb10"
      },
      "outputs": [],
      "source": [
        "# Normalize the purchase amount\n",
        "df['normAmount'] = StandardScaler().fit_transform(df['Amount'].as_matrix())\n",
        "df = df.drop(['Time', 'Amount'], axis = 1) #Drop the time and amount columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fb026c5-7db2-6dcc-fb57-ce213536b229"
      },
      "outputs": [],
      "source": [
        "df['Class'].describe() # 0.173% of positive cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e086e534-a562-33b0-f7c6-bcaa1e9e55ec"
      },
      "outputs": [],
      "source": [
        "# Save the features and target\n",
        "features = [col for col in df.columns if col not in ['Class']]\n",
        "target = 'Class'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "097ce988-2f8b-d876-72c9-4a001670500c"
      },
      "outputs": [],
      "source": [
        "n_fold = 5\n",
        "test_size = 0.1\n",
        "n_iterations = 40\n",
        "# Set up a Stratified Kfold splits\n",
        "sss = StratifiedShuffleSplit(n_fold, test_size = test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b553545d-0ed8-8681-421d-28c94cb0cd2d"
      },
      "source": [
        "This function implements the EasyEnsemble algorithm described by Liu et al. (2008) and return the average predicted probability for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5482d557-34f6-3d27-cda7-e14d094d1670"
      },
      "outputs": [],
      "source": [
        "def EasyEnsemble(train_df, test_df, features, target, clf, n_iterations):\n",
        "    num_pos = np.sum(train_df[target])\n",
        "    neg_train_df = train_df[train_df[target] == 0]\n",
        "    pos_train_df = train_df[train_df[target] == 1]\n",
        "\n",
        "    test_predictions = np.empty((test_df.shape[0], n_iterations))\n",
        "    train_predictions = np.empty((test_df.shape[0], n_iterations))\n",
        "    \n",
        "    for i in range(n_iterations):\n",
        "        classifier = clf()\n",
        "        # Sample the same number of negative cases as positive cases\n",
        "        neg_sample = neg_train_df.sample(num_pos, random_state = i)\n",
        "        subset = neg_sample.append(pos_train_df)\n",
        "        \n",
        "        # Fit the classifier to the balanced dataset\n",
        "        classifier.fit(subset[features], np.ravel(subset[target]))\n",
        "        prediction = classifier.predict_proba(test_df[features])[:,1]\n",
        "        test_predictions[:, i] = prediction\n",
        "    \n",
        "    # Average all the test predictions\n",
        "    ensemble_predictions = np.mean(test_predictions, axis = 1)\n",
        "    \n",
        "    return(ensemble_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb5d4e54-1746-cdcc-6411-f034d3e2d845"
      },
      "source": [
        "Since there is so little positive cases in the dataset, I find it necessary to do KFold cross validation to get more consistent results. I also used the stratified KFold to make sure the train and test set have approximately same proportion of positive cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bed36a43-109a-a9ca-e671-4e448270996f"
      },
      "outputs": [],
      "source": [
        "def KFoldPrediction(df, features, target, kSplit, clf, ensemble = False, n_iterations = 0):\n",
        "    mean_tpr = 0.0\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    \n",
        "    mean_recall = 0.0\n",
        "    mean_precision = np.linspace(0, 1, 100)\n",
        "    \n",
        "    mean_precision_score = 0.0\n",
        "    \n",
        "    # Loop through the CV indexes\n",
        "    for i, (train_index, test_index) in enumerate(kSplit.split(df[features], df[target])):\n",
        "        \n",
        "        classifier = clf()\n",
        "        train_df, test_df = df.iloc[train_index], df.iloc[test_index]\n",
        "        \n",
        "        # For ensemble method, call the EasyEnsemble function\n",
        "        if not ensemble:\n",
        "            classifier.fit(train_df[features], np.ravel(train_df[target]))\n",
        "            proba = classifier.predict_proba(test_df[features])[:, 1]\n",
        "        else:\n",
        "            proba = EasyEnsemble(train_df, test_df, features, target, clf, n_iterations)\n",
        "            \n",
        "        # Get the FPR, TPR \n",
        "        fpr, tpr, thresholds = roc_curve(test_df[target], proba)\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "        mean_tpr[0] = 0.0\n",
        "        \n",
        "        # Get the precision and recall\n",
        "        precision, recall, thresholds = precision_recall_curve(test_df['Class'], proba)\n",
        "        mean_recall += np.interp(mean_precision, precision, recall)\n",
        "\n",
        "        mean_precision_score += average_precision_score(test_df[target], proba)\n",
        "    \n",
        "    nfold = sss.get_n_splits(df[features], df[target])\n",
        "    \n",
        "    # Average the totals for TPR, recall, precision score\n",
        "    mean_tpr /= nfold\n",
        "    mean_recall /= nfold\n",
        "    mean_precision_score /= nfold\n",
        "    \n",
        "    return(mean_fpr, mean_tpr, mean_precision, mean_recall, mean_precision_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a8b6b632-d5dd-ede5-d1fb-65a04a53db0d"
      },
      "source": [
        "# Graph all the ROC and Precision-Recall Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6eb6f0ab-b475-79bb-168e-46e47d7974a6"
      },
      "outputs": [],
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "classifiers = {'Logistic Regression': LogisticRegression,\n",
        "               'Random Forest': RandomForestClassifier,\n",
        "               'AdaBoost': AdaBoostClassifier,\n",
        "               'Ensemble_Random Forest': RandomForestClassifier,}\n",
        "\n",
        "# Not the most elegant implementation, need to rewrite this when I have time\n",
        "for key in classifiers:\n",
        "    if str.split(key, '_')[0] == 'Ensemble':\n",
        "            fpr, tpr, precision, recall, precision_score = KFoldPrediction(df, features, target, sss, classifiers[key], True, n_iterations)\n",
        "    else:\n",
        "        fpr, tpr, precision, recall, precision_score = KFoldPrediction(df, features, target, sss, classifiers[key])\n",
        "    \n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    # Graph ROC Curve\n",
        "    plt.figure(1)\n",
        "    plt.plot(fpr, tpr,\n",
        "             label='%s ROC (area = %0.2f)' % (key, roc_auc))\n",
        "    plt.legend(loc=4, fontsize = 8)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylim([-0.05, 1.05])\n",
        "    \n",
        "    # Graph Precision-Recall Curve\n",
        "    plt.figure(2)\n",
        "    plt.plot(recall, precision,\n",
        "             label='%s Precision (area = %0.2f)' % (key, precision_score))\n",
        "    plt.legend(loc=3, fontsize = 8)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylim([-0.05, 1.05])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "df376f18-8aec-03f8-837a-1ddb153e0df2"
      },
      "source": [
        "As you can see above, the undersampling technique (EasyEnsemble) did not result in substantial improvement in classification. In fact, comparing to the original classifier (Random Forest), the undersampling technique seems to result in a degradation of classification performance. It will be interesting to see if this result holds for other classifiers or ensemble method."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}