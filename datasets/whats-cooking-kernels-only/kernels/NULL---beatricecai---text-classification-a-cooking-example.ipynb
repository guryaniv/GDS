{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\nimport re\nimport unidecode\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder\nfrom tqdm import tqdm\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77800b2c1040ac7afcc1cb2a835818c2edb65ca3"},"cell_type":"code","source":"train['num_ingredients'] = train['ingredients'].apply(len)\ntrain = train[train['num_ingredients'] > 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c0ffbdcd44355fe3f58b062500d3072f808e9d"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fb7e325c4a200a481727b60c9809882936f5065"},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients_text = ' '.join(ingredients)\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', ' ')\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) <= 2: continue\n        if '’' in word: continue\n        word = lemmatizer.lemmatize(word)\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n\nfor ingredient, expected in [\n    ('Eggs', 'egg'),\n    ('all-purpose flour', 'all purpose flour'),\n    ('purée', 'purée'),\n    ('1% low-fat milk', 'low fat milk'),\n    ('half & half', 'half half'),\n    ('safetida (powder)', 'safetida (powder)')\n]:\n    actual = preprocess([ingredient])\n    assert actual == expected, f'\"{expected}\" is excpected but got \"{actual}\"'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7a2ef4a4b399152eefb4ea1f0d0dbbc6a02b8c0"},"cell_type":"code","source":"train['x'] = train['ingredients'].progress_apply(preprocess)\ntest['x'] = test['ingredients'].progress_apply(preprocess)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bdc32a4d5bf17ac8d4cef9e66381648f8ba7594c"},"cell_type":"code","source":"vectorizer = make_pipeline(\n    TfidfVectorizer(sublinear_tf=True),\n    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n)\n\nx_train = vectorizer.fit_transform(train['x'].values)\nx_train.sort_indices()\nx_test = vectorizer.transform(test['x'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01556a58c9ffc1d1a6dac9fddeeb3f58e0da2510"},"cell_type":"code","source":"type(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"430a1de2e3fd3bb84254cd6829155ee5a3cb853b"},"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(train['cuisine'].values)\ndict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1105175ca6d62b8e4e66599c279ca8701c53f96f"},"cell_type":"code","source":"estimator = SVC(\n    C=50,\n    kernel='rbf',\n    gamma=1.4,\n    coef0=1,\n    cache_size=500,\n)\nclassifier = OneVsRestClassifier(estimator, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f0023355d4ee5ecbbe5eb6a3f6a8c75570e6795"},"cell_type":"code","source":"%%time\nclassifier.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43a2017488225bfbb9402771ddb036a8bd343fdb"},"cell_type":"code","source":"y_pred = label_encoder.inverse_transform(classifier.predict(x_train))\ny_true = label_encoder.inverse_transform(y_train)\n\nprint(f'accuracy score on train data: {accuracy_score(y_true, y_pred)}')\n\ndef report2dict(cr):\n    rows = []\n    for row in cr.split(\"\\n\"):\n        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n        if len(parsed_row) > 0: rows.append(parsed_row)\n    measures = rows[0]\n    classes = defaultdict(dict)\n    for row in rows[1:]:\n        class_label = row[0]\n        for j, m in enumerate(measures):\n            classes[class_label][m.strip()] = float(row[j + 1].strip())\n    return classes\nreport = classification_report(y_true, y_pred)\npd.DataFrame(report2dict(report)).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64b0ecbea68fffe235166255e189050ecd445f19"},"cell_type":"code","source":"y_pred = label_encoder.inverse_transform(classifier.predict(x_test))\ntest['cuisine'] = y_pred\ntest[['id', 'cuisine']].to_csv('submission.csv', index=False)\ntest[['id', 'cuisine']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fba28d7e1e2caaf1e30c448176dfd878e9dad7d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}