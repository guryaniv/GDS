{"cells":[{"metadata":{"_cell_guid":"bae464c6-580b-414f-9d74-31532e233f5f","_uuid":"659dbf4767592d9d907a1dbc6a251c2b2229a6db"},"cell_type":"markdown","source":"# Toxic Comment Classification Challenge\n### Identify and classify toxic online comments"},{"metadata":{"_cell_guid":"81ce0b6b-e6e4-45ef-84a6-c10ee9509287","_uuid":"7989ea5c6a08fdf6597920888072059d01337f6c"},"cell_type":"markdown","source":"<img src='https://storage.googleapis.com/kaggle-media/competitions/jigsaw/003-avatar.png' height=150 width=150/>\nDiscussing things you care about can be difficult. The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n\nThe [Conversation AI](https://conversationai.github.io/) team, a research initiative founded by [Jigsaw](https://jigsaw.google.com/) and Google (both a part of Alphabet) are working on tools to help improve online conversation. One area of focus is the study of negative online behaviors, like toxic comments (i.e. comments that are rude, disrespectful or otherwise likely to make someone leave a discussion). So far they’ve built a range of publicly available models served through the [Perspective API](https://perspectiveapi.com/), including toxicity. But the current models still make errors, and they don’t allow users to select which types of toxicity they’re interested in finding (e.g. some platforms may be fine with profanity, but not with other types of toxic content).\n\nIn this competition, you’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s [current models](https://github.com/conversationai/unintended-ml-bias-analysis). You’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n\nDisclaimer: the dataset for this competition contains text that may be considered profane, vulgar, or offensive."},{"metadata":{"_cell_guid":"12086c8d-4c88-45ef-a080-c36420a88332","_uuid":"20c2ff561f6afd0975d808abad11a2b7a5876819"},"cell_type":"markdown","source":"## Lets load the neccesary packages\n___\nThe libraries below will be used to load and explore the toxic comment data challenge data\n<img src='https://media.giphy.com/media/12Q9qZRnnab0T6/giphy.gif' height=100 />\n\n**File descriptions**  \n*train.csv* - the training set, contains comments with their binary labels  \n*test.csv* - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.  \n*sample_submission.csv* - a sample submission file in the correct format"},{"metadata":{"_cell_guid":"ef67fbd8-6bb9-47b0-a2e8-582acefb1b36","_uuid":"51fd462e843e4fd83c1be9ff83506deffb8d8a22","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # for visuals\nimport matplotlib.pyplot as plt # for plots\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2f165ad9-7c17-4505-b6d5-1f6c818c0d98","_uuid":"4c085b14a288f4664622147c8325564e7a417328"},"cell_type":"markdown","source":"## Loading Data\n___\nLoading training, testing and sample submission datasets"},{"metadata":{"_cell_guid":"c9d25d75-8a4e-4860-b1a7-cc17e8741129","collapsed":true,"_uuid":"9e759610163c77d69dae8a8864f7f6605dc2fda0","trusted":false},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50276fa3-e870-4dbb-901c-b286b96daddc","_uuid":"4388dc270c3187861ff7a9b1a80851b8f6b341bc"},"cell_type":"markdown","source":"## Exploratoring Data\n___\n> Errors using inadequate data are much less than those using no data at all.   \n> by **Charles Babbage**\n"},{"metadata":{"_cell_guid":"fa2a3846-b48b-4cf6-97dc-9c3682e78a49","_uuid":"bbf5311737cb786f11925dff7d4d0d204d301cf2","trusted":false,"collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c66b92e2-ec3b-4840-a841-1d4e1daab60d","_uuid":"06b6dde10ebf9b4a03492887d4531727f24c06b5","trusted":false,"collapsed":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"348ca6f5-8c95-4763-845f-637dd57ca673","_uuid":"186b9918b4bcc5659a4b5269c6bdbe4d97810f8b"},"cell_type":"markdown","source":"## Dataset Overview\n___\nThe dataset has \n* About 160 000 of records \n* 7 columns excluding id column\n* lets get started with statistical analysis"},{"metadata":{"_cell_guid":"066b4f9f-d42b-465f-93b7-03167f4acffd","_uuid":"17ae0318e3d388df8e11e17965d1e1c3788ec401"},"cell_type":"markdown","source":"### Checking Data types\n___\nIt is important to know what type of data you are working on just to be sure, even though we know this dataset"},{"metadata":{"_cell_guid":"aca33977-3498-480f-aa11-beb8c0a5357a","_uuid":"74a5146b0be68fc8b0d8a40c9190063774f96395","trusted":false,"collapsed":true},"cell_type":"code","source":"train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bb0f892d-6b9b-4445-84ca-62f188bfd223","_uuid":"4e12be61f85e36a3c3db9684821c6ddc5a0a67e0"},"cell_type":"markdown","source":"### Checking Missing Values\n___\nThe data does not contain the missing values, but I will check it in later stage to verify, finding the missing values in text might be challenge sometimes."},{"metadata":{"_cell_guid":"533c92e3-510c-49cd-9be0-470f5f3b7076","_uuid":"c78b705b431f5ef456a298e68b99630b444486a9","trusted":false,"collapsed":true},"cell_type":"code","source":"train.isnull().any()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4daa986d-606d-442f-b1b1-0129858dd8f7","_uuid":"f4cb1ae7214a24e3eb2e81a525ba726dc21c35d7"},"cell_type":"markdown","source":"### Statistical Overview of Labels\n___\nOur labels for datasets are as follows \n* 'toxic'  \n* 'severe_toxic'  \n* 'obscene'  \n* 'threat'  \n* 'insult'  \n* 'identity_hate'  "},{"metadata":{"_cell_guid":"b15c46e8-50be-4adb-86b3-81d2973ca688","_uuid":"d93b5a5b7cd001544feadcd6e2d8d8fc627908bd","trusted":false,"collapsed":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"379d5ad3-620d-480a-8e16-20cb8b3f55d9","_uuid":"053ae4d83bce9bea5e3d1f3a10c6395ecbdf5d3d"},"cell_type":"markdown","source":"### Lets plot the results for sake of graphically understanding"},{"metadata":{"_cell_guid":"1cf26775-d98f-47fc-a4a5-0f2a62d3b3f8","_uuid":"40a1b88663f79102dcb985b8b08c4bdc53fc534a","trusted":false,"collapsed":true},"cell_type":"code","source":"train.describe().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dad34677-90d5-4578-a652-033b0a1aa509","_uuid":"93b6962315812f91029252445415eaec568cc9a9"},"cell_type":"markdown","source":"### Visualizing data on pairplor graph\n___\nPlot pairwise relationship in a datasets"},{"metadata":{"_cell_guid":"891de15d-3996-4d4e-a6a9-6c6c1d8f95e6","_uuid":"13b7a28579bd9d2d938e5a4dccb80acf4a2e2149","trusted":false,"collapsed":true},"cell_type":"code","source":"sns.pairplot(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c94a7ca8f6c31edfb3786b005d2d60d829d3e219","_cell_guid":"73176ce3-972d-4de6-9a55-f8abb9c74fce"},"cell_type":"markdown","source":"### The diagonal plots are as follows  with the numbers that reflets the bar graphs\n___\n"},{"metadata":{"_uuid":"bd9534d49758109d5b5f27246aea5db91776d1e7","_cell_guid":"828ba286-888e-4a97-9026-d7e6c7afab08"},"cell_type":"markdown","source":"#### Displaying the numbers first****"},{"metadata":{"_uuid":"465b8f2390045d0755745c1269242aaf14928dfb","_cell_guid":"c99a0c9e-d544-4e71-9ffc-5ce460827433","trusted":false,"collapsed":true},"cell_type":"code","source":"print(train.obscene.value_counts())\nprint(train.threat.value_counts())\nprint(train.insult.value_counts())\nprint(train.identity_hate.value_counts())\nprint(train.toxic.value_counts())\nprint(train.severe_toxic.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3554bbf3648550f4639740f178206e8db4930eeb","_cell_guid":"fa6cec92-5c0c-4d5f-a91f-37b84bb2b67b"},"cell_type":"markdown","source":"The following are simplified version of diagonal from top left to bottom right"},{"metadata":{"_uuid":"084ab3d94b449cd72edde6f8fa8b173eb8e4997d","_cell_guid":"21662673-1c8c-40af-b8e1-1ac750940193","trusted":false,"collapsed":true},"cell_type":"code","source":"fig, plots = plt.subplots(2,3,figsize=(18,12))\nplot1, plot2, plot3, plot4, plot5, plot6 = plots.flatten()\nsns.countplot(train['obscene'], palette= 'deep', ax = plot1)\nsns.countplot(train['threat'], palette= 'muted', ax = plot2)\nsns.countplot(train['insult'], palette = 'pastel', ax = plot3)\nsns.countplot(train['identity_hate'], palette = 'dark', ax = plot4)\nsns.countplot(train['toxic'], palette= 'colorblind', ax = plot5)\nsns.countplot(train['severe_toxic'], palette= 'bright', ax = plot6)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2c3a04c0-c227-41e7-a12d-487a0b2d3000","_uuid":"aa0742157babb89322ff25d89390bad27d15f386"},"cell_type":"markdown","source":"# Let's do Text clearning a bit\n___\n\nThe informal text to formal systax was obtained from the notebook below:  \nhttps://www.kaggle.com/gakngm/some-predictions-for-toxic-comments  \nTitled: **Some predictions for Toxic Comments**  by  [Gael Kngm](https://www.kaggle.com/gakngm)   \nGood start at Gael  \n\n"},{"metadata":{"_cell_guid":"70bb9cb7-f1eb-44ef-b631-666cd733dbb8","collapsed":true,"_uuid":"70c844c33972104cca8075fc4e5511b34085ecde","trusted":false},"cell_type":"code","source":"structured_patterns = [\n (r'won\\'t', 'will not'),\n (r'can\\'t', 'cannot'),\n (r'i\\'m', 'i am'),\n (r'ain\\'t', 'is not'),\n (r'(\\w+)\\'ll', '\\g<1> will'),\n (r'(\\w+)n\\'t', '\\g<1> not'),\n (r'(\\w+)\\'ve', '\\g<1> have'),\n (r'(\\w+)\\'s', '\\g<1> is'),\n (r'(\\w+)\\'re', '\\g<1> are'),\n (r'(\\w+)\\'d', '\\g<1> would')\n]\n\nclass RegexpReplacer(object):\n    def __init__(self, patterns=structured_patterns):\n         self.patterns = [(re.compile(regex), repl) for (regex, repl) in\n         patterns]\n            \n    def replace(self, text):\n        s = text\n        for (pattern, repl) in self.patterns:\n             s = re.sub(pattern, repl, s)\n        return s\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adfc9c0dfcc301a4700af7d74125deeb6045d96f","_cell_guid":"bbf6b5fb-3906-4379-9853-a72022ba92b1"},"cell_type":"markdown","source":"### Removing symbols in the text \n___\nExample:  \n*     **from** hello, i need two$   \n*     **to** hello i need two  "},{"metadata":{"_cell_guid":"2bda9a32-4b40-4f95-b06f-dc345150ff04","collapsed":true,"_uuid":"5c264c6c961f6d8e99ed0d4fac8799811e15c4f7","trusted":false},"cell_type":"code","source":"import re\ndef strip_symbols(text):\n    return ' '.join(re.compile(r'\\W+', re.UNICODE).split(text))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0e42f99f-9d60-4b51-8e2f-1241457b0d3b","_uuid":"110dbed3be857292e5dd9766fbe6c362f2165d78"},"cell_type":"markdown","source":"### Convert the text to lower\n___\nStandardizing the text to all lower cases and replaing new line spaces by spaces to avoid creating new words from test"},{"metadata":{"_cell_guid":"0b54d991-a757-430c-94ec-e63602b6f1bd","collapsed":true,"_uuid":"a8e78b98364afda7098bd44b26fb5b46be6b0874","trusted":false},"cell_type":"code","source":"train.comment_text = train.comment_text.str.lower()\ntrain.comment_text = train.comment_text.str.replace('\\n',' ')\nreplacer = RegexpReplacer()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90ef4076625987f201f927831dd110c364383eb5","_cell_guid":"3f422079-26bf-4ac6-b49f-eddbca314323"},"cell_type":"markdown","source":"#### Removing symbols and converting text from informal to formal text\n___\nExample:   \n    **from** :  I Can't do it    \n    **to** : i cannot do it "},{"metadata":{"_cell_guid":"6c0eb2d2-df74-4e7b-b945-970099d9897d","_uuid":"cee53eb579ec4f299935e8dd405b069dfb878ee2","trusted":false,"collapsed":true},"cell_type":"code","source":"train.comment_text = train.comment_text.apply(lambda x:replacer.replace(x))\ntrain.comment_text = train.comment_text.apply(lambda x:strip_symbols(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc56d311e669a914ddc3968560783c6d56c14293","_cell_guid":"1a7f3a58-878c-4778-ae67-a143f4116b5d"},"cell_type":"markdown","source":"## Display the clean text \n___\nDisplaying the first few rows of the data "},{"metadata":{"_cell_guid":"5d86f652-2b59-426c-9935-9a69251bf195","_uuid":"cc76772d5dec59ef1d465f5f52ee12cea91c7e69","trusted":false,"collapsed":true},"cell_type":"code","source":"train.comment_text.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bae346832a474956dee0066d0adc04bb229584c","_cell_guid":"111470bd-0c6e-46b7-9fe3-77b1d33392d3"},"cell_type":"markdown","source":"## Wordclouds for clean dataset \n___\n**Lets define word clouds first:**    \nWordclouds - an image composed of words used in a particular text or subject, in which the size of each word indicates its frequency or importance.   \n**Warning**  \n    please note that some words are toxic since the dataset contain toxic comments \n"},{"metadata":{"_cell_guid":"b451cb0d-b489-44c5-a87c-9179cfee771f","_uuid":"18d71b8897c41d171ed357c48dfe91cc4a7c3558","trusted":false,"collapsed":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(width=1440, height=1080).generate(\" \".join(train.comment_text.astype(str)))\nplt.figure(figsize=(20, 15))\nplt.imshow(wordcloud)\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"065238be-8b60-482f-9db4-525964c67e1c","_uuid":"d165cd59b6d486889e6f04011a15badf8e29b1cf"},"cell_type":"markdown","source":"# Machine Learning\n___\n<img src='http://www.princeton.edu/~samory/samoryDraw1.jpg' height=250 width=600/>\nLoad neccesary packages to make predictions and model fitting\n\nYou are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n\n* toxic\n* severe_toxic\n* obscene\n* threat\n* insult\n* identity_hate  \nYou must create a model which predicts a probability of each type of toxicity for each comment.\n"},{"metadata":{"_uuid":"71bd715b8e590282b6be40c34273560e42e88773","_cell_guid":"33271be9-6d66-4424-872f-318cb22bdd18"},"cell_type":"markdown","source":"## Load Machine leaning Packages \n___\n* Loading Bernouli Naive Bayes, Since its better with text for sample notebook, can be improved later to move to tensorflow and Keras with algorithms like RNN, LSTM and GRU  \n* This notebook will be updated soon, but now it uses the TF-IDF and CountVectorizer\n*  One versus Rest Classifier for fitting multiple labels "},{"metadata":{"_cell_guid":"69f96c32-8adc-4714-a248-e171924dd9fa","collapsed":true,"_uuid":"a743a4ce322ebe773909c3f9d2e91e60d539fa04","trusted":false},"cell_type":"code","source":"from sklearn.naive_bayes import BernoulliNB\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1baa43f42a3cc0b28b545668bc1897f455eeb170","_cell_guid":"2c33ad47-0003-4287-8e25-9c139fd8a389"},"cell_type":"markdown","source":"## Stop words removal\n___\nRemoving english stopwords from text to have more meaningful words to eliminate noise and fitting the training dataset to the model "},{"metadata":{"_cell_guid":"77ef61fb-9ffe-4cbc-b73a-89b7590f4815","_uuid":"59f1afc93ad29480bf8a67b990f9e073f38f2fd2","trusted":false,"collapsed":true},"cell_type":"code","source":"vectorizer = CountVectorizer(stop_words='english')\nX = vectorizer.fit_transform(train.comment_text)\ny = train.loc[:,'toxic':'identity_hate']\nclf = BernoulliNB()\nmodel = OneVsRestClassifier(clf)\nmodel.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e034a32ae022b31587a61b23ad77e692f9921ce6","_cell_guid":"f55e7120-f58e-490e-91d0-c209c370e6ac"},"cell_type":"markdown","source":"## Testing Dataset\n___\nWe will apply all the steps we have done in training dataset for only text comment_text column, since the test dataset has only comment_text column The target results are probabilities all the class labels per text given to the model"},{"metadata":{"_uuid":"5430589f80981020928e54c74ab8c8ec2f16d318","_cell_guid":"ae714c53-3944-4f54-bd44-655642ff0aa3","trusted":false,"collapsed":true},"cell_type":"code","source":"## display the first few records for test dataset\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"135c6ca538870fccc47babe6cf53e2afb6e66228","_cell_guid":"2d2cfe0c-74b3-4468-819d-7574b5391848"},"cell_type":"markdown","source":"#### Converting to lower and removing new line spaces"},{"metadata":{"_cell_guid":"4e02d6a2-dc67-448c-b3cc-94c38ad49df5","collapsed":true,"_uuid":"07b748e2c5697053be67a86b1400574756140c8d","trusted":false},"cell_type":"code","source":"test.comment_text = test.comment_text.str.lower()\ntest.comment_text = test.comment_text.str.replace('\\n',' ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdd78e3677fc7b8012af2d623aa9eed481b136d5","_cell_guid":"06847490-7433-4f32-a1d9-93592d3e3899"},"cell_type":"markdown","source":"## Check dimensions\n___\nwe need to check the size of the test dataset, later we will make sure the dimension should be the same as training dataset"},{"metadata":{"_cell_guid":"2f795935-5ba9-407b-8f10-1db8961e28b0","_uuid":"31342618c54d6c8d4f78fa3448ce3d28a7314e2e","trusted":false,"collapsed":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79cd0f4a-fa98-4d08-a460-ba0444c3302e","collapsed":true,"_uuid":"56e9c29173486a3e1869addb6147f55e13565b61"},"cell_type":"markdown","source":"### Removing symbols and converting informal text to formal"},{"metadata":{"_cell_guid":"a973bdd8-eb1f-455b-9b90-70ad4e9d1cf1","collapsed":true,"_uuid":"3a987df61a2cb8f38af0c0ae987ea71b0a449361","trusted":false},"cell_type":"code","source":"test.comment_text = test.comment_text.apply(lambda x:replacer.replace(x))\ntest.comment_text = test.comment_text.apply(lambda x:strip_symbols(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4a2a79e76fe257250adc24f70ebad8a02981574","_cell_guid":"54d2f2b8-05f2-482c-97fe-831bd7faf2c4"},"cell_type":"markdown","source":"## Making train and test to have same dimensions\n* To make sure the dimension are the same, vectorizer will use .tranform(text) since previously it used .fit_transform(), \n* Let's print the dimension of X_test and X_train to show they have the same dimensions"},{"metadata":{"_cell_guid":"ca4e4a5e-e2bb-421d-9e3e-e1a9eae52ef8","collapsed":true,"_uuid":"d14aeb07714c191cf86619367d1f0eec88e28ce6","trusted":false},"cell_type":"code","source":"X_test = vectorizer.transform(test.comment_text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f821dde1fa566ae23b55b46ee0df249c38277ca","_cell_guid":"cdff379f-db60-4918-bffa-3ba9f2d6dbfb","trusted":false,"collapsed":true},"cell_type":"code","source":"## remenber we have to make sure that the columns are the same not the rows \nprint(\"X train shape : \",X.shape )\nprint(\"X test shape : \",X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c5c48f7d4927ee07c11fbe13ad40ea55c1885a5","_cell_guid":"b61fb83b-24eb-45ba-b40f-06b14da36c57"},"cell_type":"markdown","source":"# Predictions \n___\nLets predicts probabilities for test dataset\n<img src='https://media-exp2.licdn.com/mpr/mpr/AAEAAQAAAAAAAAliAAAAJGJhNWZmYWM2LTVjMjAtNDkwNS05MzJiLWE4MzAxNmVjNzliZQ.png'>"},{"metadata":{"_cell_guid":"2f01b0ca-84ed-4bf6-be28-0c250620a4f4","collapsed":true,"_uuid":"6bb2eeca65180ea55e328272c8c8cd2be68c8627","trusted":false},"cell_type":"code","source":"probs = model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b09c7c2b9e1850e1fb0243050572b42a8ae47809","_cell_guid":"4505773c-1817-4b10-a196-808389c02f55"},"cell_type":"markdown","source":"## Replacing sample probabilities\n___\nThe below submission frame data is overwritten using model prediction probabilites"},{"metadata":{"_cell_guid":"f603a1b2-6b28-4ceb-982e-de5be6205827","collapsed":true,"_uuid":"20cd5431863d2d8ec2d068e021a412906763d5d6","trusted":false},"cell_type":"code","source":"submission.loc[:,'toxic':'identity_hate'] = probs","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"467fe5d9afab5a04772c4bca7f9f9f04d3312c1a","_cell_guid":"324d28b7-6903-40c8-b8a1-e9b629e076eb"},"cell_type":"markdown","source":"## Identity hate probabilities  \n* Identity_hate with 3000 points of probabilities greater than 0.5 and less than 0.2 "},{"metadata":{"_cell_guid":"9c0267cc-d675-4da9-b6ec-a1bb6729b93e","_uuid":"569547378ab6c72c133dfeae52d12046dd43f7e0","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nplt.subplot(1,2,1)\nsns.violinplot(x = 'toxic', y = 'insult', data = train[0:50000])\nplt.subplot(1,2,2)\nsns.distplot(submission[submission['identity_hate'] > 0.5]['identity_hate'][0:3000], color = 'green')\nsns.distplot(submission[submission['identity_hate'] < 0.2 ]['identity_hate'][0:3000], color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"da6d798f-746e-4dbb-83ad-27c81173d35c","collapsed":true,"_uuid":"4df5f94a0e1a262f32f34037df164bd6bbe20196","trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92223a784ac83cf25324acbf207512dd58c343a9","_cell_guid":"c6e4f3d9-94db-462c-b5e6-a2de701e88af"},"cell_type":"markdown","source":"## ROC Curve"},{"metadata":{"_uuid":"a0ed4e003df1c7a25e50fe8a8da8f0bc2a396254","_cell_guid":"0cb9c552-0c86-4752-b171-633ab907b84f","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr, tpr, thresholds = roc_curve(model.predict(X_test)[:,1], model.predict_proba(X_test)[:,1])\nbernouli = roc_auc_score(model.predict(X_test)[:,1], model.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Bernouli Naive Bayes (area = %0.2f)' % bernouli)\nplt.plot([0,1], [0,1],label='Base Rate' 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fc84123f-c1ae-4710-9698-9285f97e7b86","collapsed":true,"_uuid":"1eee5be39e82d3a52b17d93bd3fb6f2e7631562b"},"cell_type":"markdown","source":"## Both negative and positive comments are welcome"},{"metadata":{"_uuid":"06d7ff59e3f7a104abda07fd6620331f5dd25a94","collapsed":true,"_cell_guid":"e9074c5b-3a02-4e51-8b8b-14dfb225a981","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}