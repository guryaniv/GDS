{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**1. Introduction**\n\nFinding good sets of parameter for algorithms such as xgboost or lightgbm can be daunting. In essence there are three options to tune parameter:\n\n**a) Random search:** Randomly set parameters, obtain results (e.g. AUC), pick the parameter set which delivers the best result after x iterations\n\n**b) Grid search: **Define a range of parameter values, iterate stepwise over the range for each parameter, obtain results (e.g. AUC), pick the parameter set which delivers the best result after all iterations\n\n**c) Bayesian optimization:** Define a acquisition function which represents the probability of improvement at step x and stepwise iterate to improve the parameter set. Unlike the former two approaches, Bayesian optimization aims at using information from previous rounds to update the parameter set. In a sense there is “reinforcement” with respect to learning on the choice of parameters. \nFor further reading, see: [http://krasserm.github.io/2018/03/21/bayesian-optimization/](http://)\n\nIn what follows I present a simple random parameter search routine for lightgbm. I use data from the Kaggle Santander competition ([https://www.kaggle.com/c/santander-customer-transaction-prediction](http://)).\n\n**2. Concept**\n\n**i)** Set a threshold for the evaluation metric (AUC in this case)\n\n**ii) **Randomly choose a set of parameter \n\n**iii)** Obtain AUC by cross-validation \n\n**iv)** If CV AUC is greater or equal to threshold AUC: use parameter set to obtain predictions, else continue\n\n**3. Kernel**\n\nLet’s start and first load some packages:\n"},{"metadata":{"trusted":true,"_uuid":"887913b0f13e52be38e689825ee55bb7c7d737e0"},"cell_type":"code","source":"import lightgbm as lgb\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import preprocessing\nimport random, json, os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f7af8d46f4ccbacd026f4141ceb6e414ba2a0fd"},"cell_type":"markdown","source":"Here I set some parameter. The first (*minauc*) is the minimal required AUC to make a prediction. The remaining parameter are the maximal bossting rounds (*maxrounds*), the number of random parameter draws for cross-validation (*cvrounds*), the early stopping rule (*estop*) and the CV-folds (*fol*).\n\n**Note:** The values are set rather low here, so that the routine can finish in a reasonable period of time. To obtain good results you may use higher values."},{"metadata":{"trusted":true,"_uuid":"2fdea465a0d981d13b99e0fb12788f6d85c42ae2"},"cell_type":"code","source":"# Min. cross validated AUC reqired to obtain/save model predictions\nminauc = 0.85\n# Max. rounds (of lgb model)\n# This value can be high because there is early stopping\nmaxrounds = 25000\n# Number of parameter trys by cross validation\n# (these are not the \"folds\")\ncvrounds = 2\n# Early stopping rounds\nestop = 1000\n# CV folds\nfol = 5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98d72aed8ac9c65af2aaa34fa41cfe9bf0aa6f0d"},"cell_type":"markdown","source":"Load the data:"},{"metadata":{"trusted":true,"_uuid":"e716550f562a7d0d61ad77f1c035899c550c8bf6"},"cell_type":"code","source":"# Load data for training \nmydata = pd.read_csv('../input/train.csv', sep=',')\nmydata = mydata.drop('ID_code', 1)\n# Load prediction data\npreddata = pd.read_csv('../input/test.csv', sep=',')\npredids = preddata[['ID_code']] \niddf = preddata[['ID_code']] \npreddata = preddata.drop('ID_code', 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"462c080c0d073f749617fbab11665a4bd695547b"},"cell_type":"markdown","source":"Preprocessing:"},{"metadata":{"trusted":true,"_uuid":"922a0c8574325a6620d18ea4bcdce20a683b65bf"},"cell_type":"code","source":"# Test train split\ndf_train, df_test = train_test_split(mydata, test_size=0.3, random_state=76)\n# Same random state to make sure rows merge\ny_train = df_train['target']\ny_test = df_test['target']\nX_train = df_train.drop('target', 1)\nX_test = df_test.drop('target', 1)\n\n# Scale data\nscaler = preprocessing.StandardScaler()\nscaled_df = scaler.fit_transform(X_train)\nX_train = pd.DataFrame(scaled_df)\nscaled_df = scaler.fit_transform(X_test)\nX_test = pd.DataFrame(scaled_df)\nscaled_df = scaler.fit_transform(preddata)\npreddata = pd.DataFrame(scaled_df)\n\n# Create dataset for lightgbm input\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3835f7148bbc8b08c329b81652e5393bba4c7fd5"},"cell_type":"markdown","source":"Next I start a loop in which a set of parameters is chosen randomly in each step. The current set of patameters is stored in *params* and is passed on to the *lgb.cv* model, from which the AUC is obtained (*curauc*). \n\nIf the CV AUC is sufficiently large, predictions are obtained and stored. Also the current set of parameter is stored to the hard drive as a txt file. \n\nFinally, for each round in which predictions are obtained, predictions are averaged over all rounds (for which CV AUC >= min. AUC), and the predictions are saved as csv file, which later can be used for submission."},{"metadata":{"trusted":true,"_uuid":"3ca1c7eaa89a3483c0a144efa5aba1f5e4900622"},"cell_type":"code","source":"for i in range(0,cvrounds):\n    params = {\n        'boost_from_average' : False,\n        'objective' :'binary',\n        'learning_rate' : random.uniform(0.002, 0.003),\n        'num_leaves' : random.randint(20, 26), \n        'feature_fraction': random.uniform(0.05, 0.16), \n        'bagging_fraction': random.uniform(0.2, 0.4), \n        'bagging_freq': random.randint(3, 5), \n        'max_bin' : random.randint(250, 260), \n        'scale_pos_weight' : random.randint(1, 3),  \n        'boosting_type' : 'gbdt',\n        'metric': 'auc',\n        'num_threads' : 4,\n        'tree_learner': 'serial', #neu\n        'boost_from_average':'false',#neu\n        'min_split_gain': random.uniform(0.15, 0.3),\n        'min_child_weight': random.uniform(0.01, 0.2),\n        'min_child_samples': random.randint(3, 6)\n    }\n    print(params)\n    # Cross validation of parameter\n    cv_results = lgb.cv(params, lgb_train, num_boost_round=maxrounds, nfold=fol, early_stopping_rounds=estop, metrics='auc')\n\n    cvlist = cv_results['auc-mean']\n    curauc = max(cvlist)\n    curaucpos = cvlist.index(max(cvlist))\n    curparams = params\n    print(\"Current CV-AUC is %s (steps: %s)\" %(curauc,curaucpos))\n\n    if curauc >= minauc:\n        # Train model with current parameters\n        gbm = lgb.train(curparams, lgb_train, num_boost_round=maxrounds, valid_sets=lgb_eval, early_stopping_rounds=estop)\n        # Predict (to get the AUC on test)\n        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n        auc = roc_auc_score(y_test, y_pred)\n        print(\"Round: %s, Test AUC: %s\" %(i, round(auc, 5)))\n\n        # Get AUC as string to lable output file\n        aucstring = str(auc)\n        aucstring = aucstring.replace(\".\", \"\")\n        # Write params to HDD\n        params = {'params': params}\n        with open(\"params\"+str(aucstring)+\".txt\", 'w') as file:\n            file.write(json.dumps(params)) \n        \n        # Predict on submission data\n        y_pred = gbm.predict(preddata, num_iteration=gbm.best_iteration)\n        y_pred = y_pred.tolist()\n        \n        # Append dataframe with current predictions\n        preddf = pd.DataFrame({'pred':y_pred})\n        iddf = pd.concat([iddf, preddf], axis=1)\n                \n        # Updated submission file with new predictions (averaged)\n        submission = pd.DataFrame({'ID_code': iddf['ID_code']})\n        iddf_temp = iddf.drop('ID_code', 1)\n        submission['target'] = iddf_temp.mean(axis=1)\n        # Submission file contains average propensity scores\n        submission.to_csv(\"submission.csv\", sep=',', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}