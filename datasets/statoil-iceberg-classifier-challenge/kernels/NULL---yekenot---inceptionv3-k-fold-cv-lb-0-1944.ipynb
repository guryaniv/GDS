{"cells": [{"source": ["import numpy as np\n", "np.random.seed(42)\n", "import pandas as pd\n", "\n", "import cv2\n", "from sklearn.model_selection import KFold\n", "\n", "from keras.models import Model\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.optimizers import Adam\n", "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"], "cell_type": "code", "metadata": {"_uuid": "629df8d24e72716fd68f4979e5b399c627155b28", "_cell_guid": "78048ae2-6848-4868-89f0-2cdb99a72856"}, "outputs": [], "execution_count": 22}, {"source": ["# Load data\n", "train = pd.read_json(\"../input/train.json\")\n", "test = pd.read_json(\"../input/test.json\")"], "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 23}, {"source": ["# Train data\n", "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_1']])\n", "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train['band_2']])\n", "\n", "X_train = np.concatenate([x_band1[:, :, :, np.newaxis],\n", "                          x_band2[:, :, :, np.newaxis],\n", "                          ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n", "\n", "target_train=train['is_iceberg']\n", "\n", "del train"], "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 24}, {"source": ["# Test data\n", "x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n", "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n", "\n", "X_test = np.concatenate([x_band1[:, :, :, np.newaxis],\n", "                         x_band2[:, :, :, np.newaxis],\n", "                         ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n", "\n", "id_test = test['id'].values\n", "\n", "del test; del x_band1; del x_band2"], "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 25}, {"source": ["# Define CNN Model Architecture (Kaggle can't access the weights file)\n", "img_height = 224\n", "img_width = 224\n", "img_channels = 3\n", "img_dim = (img_height, img_width, img_channels)\n", "\n", "def inceptionv3(img_dim=img_dim):\n", "    input_tensor = Input(shape=img_dim)\n", "    base_model = InceptionV3(include_top=False,\n", "                   weights='imagenet',\n", "                   input_shape=img_dim)\n", "    bn = BatchNormalization()(input_tensor)\n", "    x = base_model(bn)\n", "    x = GlobalAveragePooling2D()(x)\n", "    x = Dropout(0.5)(x)\n", "    output = Dense(1, activation='sigmoid')(x)\n", "    model = Model(input_tensor, output)\n", "    \n", "    return model\n", "\n", "model = inceptionv3()\n", "model.summary()"], "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 26}, {"source": ["# Train Model and predict\n", "def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n", "        \n", "    train_scores = []; valid_scores = []\n", "    preds_test = np.zeros(len(test), dtype = np.float)\n", "\n", "    i = 1\n", "\n", "    for train_index, test_index in kf.split(x):\n", "        x_train = x[train_index]; x_valid = x[test_index]\n", "        y_train = y[train_index]; y_valid = y[test_index]\n", "\n", "        def augment(src, choice):\n", "            if choice == 0:\n", "                # Rotate 90\n", "                src = np.rot90(src, 1)\n", "            if choice == 1:\n", "                # flip vertically\n", "                src = np.flipud(src)\n", "            if choice == 2:\n", "                # Rotate 180\n", "                src = np.rot90(src, 2)\n", "            if choice == 3:\n", "                # flip horizontally\n", "                src = np.fliplr(src)\n", "            if choice == 4:\n", "                # Rotate 90 counter-clockwise\n", "                src = np.rot90(src, 3)\n", "            if choice == 5:\n", "                # Rotate 180 and flip horizontally\n", "                src = np.rot90(src, 2)\n", "                src = np.fliplr(src)\n", "            return src\n", "\n", "        def train_generator():\n", "            while True:\n", "                for start in range(0, len(x_train), batch_size):\n", "                    x_batch = []\n", "                    end = min(start + batch_size, len(x_train))\n", "                    y_batch = y_train[start:end]\n", "                    for img in x_train[start:end]:\n", "                        new_img = cv2.resize(img, img_size)\n", "                        new_img = augment(new_img, np.random.randint(6))\n", "                        x_batch.append(new_img)\n", "                    x_batch = np.array(x_batch, np.float32) / 255.\n", "                    y_batch = np.array(y_batch, np.uint8)\n", "                    yield x_batch, y_batch\n", "\n", "        def valid_generator():\n", "            while True:\n", "                for start in range(0, len(x_valid), batch_size):\n", "                    x_batch = []\n", "                    end = min(start + batch_size, len(x_valid))\n", "                    y_batch = y_valid[start:end]\n", "                    for img in x_valid[start:end]:\n", "                        new_img = cv2.resize(img, img_size)\n", "                        x_batch.append(new_img)\n", "                    x_batch = np.array(x_batch, np.float32) / 255.\n", "                    y_batch = np.array(y_batch, np.uint8)\n", "                    yield x_batch, y_batch\n", "\n", "        def test_generator():\n", "            while True:\n", "                for start in range(0, len(test), n_fold):\n", "                    x_batch = []\n", "                    end = min(start + n_fold, len(test))\n", "                    for img in test[start:end]:\n", "                        new_img = cv2.resize(img, img_size)\n", "                        x_batch.append(new_img)\n", "                    x_batch = np.array(x_batch, np.float32) / 255.\n", "                    yield x_batch\n", "                    \n", "        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n", "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n", "                               verbose=1, min_lr=1e-7),\n", "             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n", "                             save_best_only=True, save_weights_only=True, mode='auto')]\n", "\n", "        train_steps = len(x_train) / batch_size\n", "        valid_steps = len(x_valid) / batch_size\n", "        test_steps = len(test) / n_fold\n", "        \n", "        model = model\n", "\n", "        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics = ['accuracy'])\n", "\n", "        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n", "                            callbacks=callbacks, validation_data=valid_generator(), \n", "                            validation_steps=valid_steps)\n", "\n", "        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n", "\n", "        \n", "        print('----------------------------------------')\n", "        print('Running train evaluation on fold {}'.format(i))\n", "        train_score = model.evaluate_generator(train_generator(), steps=train_steps)        \n", "        print('Running validation evaluation on fold {}'.format(i))\n", "        valid_score = model.evaluate_generator(valid_generator(), steps=valid_steps)\n", "        print('----------------------------------------')   \n", "        \n", "        print('Train loss: {:0.5f}\\n Train acc: {:0.5f} for fold {}'.format(train_score[0],\n", "                                                                            train_score[1], i))\n", "        print('Valid loss: {:0.5f}\\n Valid acc: {:0.5f} for fold {}'.format(valid_score[0],\n", "                                                                            valid_score[1], i))\n", "        print('----------------------------------------')\n", "\n", "        train_scores.append(train_score[1])\n", "        valid_scores.append(valid_score[1])\n", "        print('Avg Train Acc: {:0.5f}\\nAvg Valid Acc: {:0.5f} after {} folds'.format\n", "              (np.mean(train_scores), np.mean(valid_scores), i))\n", "        print('----------------------------------------')\n", "        \n", "        print('Running test predictions with fold {}'.format(i))        \n", "        preds_test_fold = model.predict_generator(generator=test_generator(),\n", "                                              steps=test_steps, verbose=1)[:, -1]\n", "\n", "        preds_test += preds_test_fold\n", "\n", "        print('\\n\\n')\n", "\n", "        i += 1\n", "\n", "        if i <= n_fold:\n", "            print('Now beginning training for fold {}\\n\\n'.format(i))\n", "        else:\n", "            print('Finished training!')\n", "\n", "    preds_test /= n_fold\n", "\n", "    return preds_test"], "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "execution_count": 27}, {"source": ["batch_size = 6\n", "epochs = 50\n", "n_fold = 3\n", "img_size = (img_height, img_width)\n", "kf = KFold(n_splits=n_fold, shuffle=True)\n", "\n", "prediction = train_model(model, batch_size, epochs, img_size, X_train, \n", "                                target_train, X_test, n_fold, kf)\n", "\n", "submit = pd.DataFrame({'id': id_test, 'is_iceberg': prediction.reshape((prediction.shape[0]))})\n", "submit.to_csv('./submission.csv', index=False)"], "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 28}], "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "nbformat": 4}