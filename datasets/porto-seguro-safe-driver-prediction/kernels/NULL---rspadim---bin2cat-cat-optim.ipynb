{"cells": [{"source": ["Read data"], "cell_type": "markdown", "metadata": {"_uuid": "c65a3b0cb7c02913453e9bab9f157a369664660c", "_cell_guid": "c206b3ba-3b96-4ee8-8e1d-bac72cf59721"}}, {"outputs": [], "execution_count": null, "source": ["import pandas as pd\n", "print(\"reading files...\")\n", "train  =pd.read_csv(\"../input/train.csv\")\n", "predict=pd.read_csv(\"../input/test.csv\")\n", "bin_cols = [col for col in train.columns if '_bin' in col]\n", "print(\"done :)\")"], "cell_type": "code", "metadata": {"_uuid": "a91a60132385d6bd2226f49744311d7c74e728dc", "collapsed": true, "_cell_guid": "182415be-a332-4363-81d0-aca3c5a92c7b"}}, {"source": ["convert bins to categorical"], "cell_type": "markdown", "metadata": {"_uuid": "910d94a3e44959989e9aad5fe3ab0e47adf91eeb", "_cell_guid": "84a3abfb-b727-4cab-9d25-8d6078a83691"}}, {"outputs": [], "execution_count": null, "source": ["# from https://www.kaggle.com/rspadim/convert-binary-to-categorical/notebook\n", "\n", "import warnings\n", "import numpy as np\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "class BinToCat(BaseEstimator, TransformerMixin):\n", "    def __init__(self):\n", "        pass\n", "    def fit(self, X, y=None, **kwargs):\n", "        cols=X.columns\n", "        if(len(cols)>64):\n", "            warnings.warn(\"Caution, more than 64 bin columns, 2**64 can overflow int64\")\n", "        for i in cols:\n", "            unique_vals=X[i].unique()\n", "            if(len(unique_vals)>2):\n", "                raise Exception(\"Column \"+i+\" have more than 2 values, is it binary? values: \"+str(unique_vals))\n", "            if not (0 in unique_vals and 1 in unique_vals):\n", "                raise Exception(\"Column \"+i+\" have values different from 0/1, is it binary? values: \"+str(unique_vals))\n", "        self.scale=np.array([1<<i for i in range(np.shape(X)[1])])\n", "        \n", "    def transform(self, X):\n", "        return np.sum(self.scale*X,axis=1)\n", "        "], "cell_type": "code", "metadata": {"_uuid": "5738284a130de686d50b03125af31917f82a714d", "collapsed": true, "_cell_guid": "81157029-2e51-4e46-b42f-4378608ec6f9"}}, {"outputs": [], "execution_count": null, "source": ["a=BinToCat()\n", "a.fit(train[bin_cols])\n", "train['bins']  =a.transform(train[bin_cols])\n", "predict['bins']=a.transform(predict[bin_cols])\n"], "cell_type": "code", "metadata": {"_uuid": "06435e3b3c49036641f8a7307e5a43bdc64988d4", "collapsed": true, "_cell_guid": "dc53bdd5-8f5f-439d-aea6-d2e383961970"}}, {"source": ["Reorder function - it return the series and a dictionary to replace the predict dataset"], "cell_type": "markdown", "metadata": {"_uuid": "e45257e9d015c96ce0d71d049ae91e2d363831b9", "_cell_guid": "58c2b487-9b67-469f-8b33-a7aebfb7948e"}}, {"outputs": [], "execution_count": null, "source": ["# from https://www.kaggle.com/rspadim/categorical-optimization-tree-and-logistic\n", "import time\n", "import numpy as np\n", "from math import factorial\n", "from itertools import permutations\n", "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n", "from sklearn.metrics import roc_auc_score,log_loss,mean_absolute_error,mean_squared_error,r2_score\n", "from xgboost import XGBClassifier\n", "\n", "\n", "def getModel(classifier=True,tree_seed=19870425):\n", "    ## tests with xgb\n", "    #return XGBClassifier(max_depth=10000,\n", "    #                     learning_rate=0.1,\n", "    #                     n_estimators=10000, \n", "    #                     silent=True, \n", "    #                     objective='binary:logistic', \n", "    #                     booster='gbtree', \n", "    #                     n_jobs=1, \n", "    #                     nthread=None, \n", "    #                     gamma=0, \n", "    #                     min_child_weight=1, \n", "    #                     max_delta_step=0, \n", "    #                     subsample=1, \n", "    #                     colsample_bytree=1, \n", "    #                     colsample_bylevel=1, \n", "    #                     reg_alpha=0, \n", "    #                     reg_lambda=1, \n", "    #                     scale_pos_weight=1, \n", "    #                     base_score=0.5, \n", "    #                     random_state=tree_seed, \n", "    #                     seed=tree_seed, \n", "    #                     missing=None)\n", "    \n", "    \n", "    if(classifier):\n", "        return DecisionTreeClassifier(max_depth=None,presort=True,criterion='entropy',class_weight='balanced',random_state=tree_seed)\n", "    return DecisionTreeRegressor(max_depth=None,presort=True,random_state=tree_seed)\n", "\n", "def getMetric(model):\n", "    ## tests with xgb\n", "    #print(type(model))\n", "    #print(vars(model))\n", "    #print(model._Booster.get_dump())\n", "    #__die\n", "    #if(type(model)==DecisionTreeClassifier):\n", "    #    return model.tree_.max_depth\n", "    #return 0\n", "    return model.tree_.max_depth\n", "\n", "# small black magic\n", "def reorderCategorical(df,feature_col,target_col,classifier=True,\n", "                                 max_iterations=721,verbose=False,random_permutation=None,\n", "                                 tree_seed=19870425,random_seed=19870425):\n", "    #time it\n", "    start     = time.time()\n", "    values    =df[feature_col].sort_values().unique() #nd array, since df[col] is a series\n", "    len_values=len(values)\n", "\n", "    #min dictionary (l<=>l)\n", "    optimized=False\n", "    default_dict={l:l for l in values}\n", "    min_dict    ={l:l for l in values}\n", "    if(len_values<3):\n", "        if(verbose):\n", "            print(feature_col,': uniques=',len_values,', values=',values)\n", "            print('\\t\\tLESS THAN 3 UNIQUE VALUES, Time spent (seconds):',time.time() - start)\n", "        return df[feature_col],min_dict\n", "    \n", "    #Current Values\n", "    model=getModel(classifier,tree_seed)\n", "    model.fit(df[feature_col].values.reshape(-1,1),df[target_col])\n", "    min_depth_count=getMetric(model)\n", "    if(verbose):\n", "        print(feature_col,': uniques=',len_values,', depth=',min_depth_count,', values=',values)\n", "        if(classifier):\n", "            print('\\t\\tROC_AUC/LogLoss: ',\n", "                      roc_auc_score(df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n", "                      log_loss(     df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1]))\n", "        else:\n", "            print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                      mean_absolute_error(df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n", "                      mean_squared_error( df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]),'/',\n", "                      r2_score(           df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]))\n", "    if(min_depth_count==1):\n", "        if(verbose):\n", "            print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n", "        return df[feature_col],min_dict\n", "    \n", "    #Naive order by count\n", "    if(classifier):\n", "        first_try=df[df[target_col]==0].groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n", "    else:\n", "        #maybe a median/mean order? for example, target_col>mean(target) ?\n", "        first_try=df.groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n", "    l,values_dict=0,{}\n", "    for i in first_try.index:\n", "        values_dict[values[l]]=i\n", "        l+=1\n", "    \n", "    model=getModel(classifier,tree_seed)\n", "    model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n", "    # better than l<=>l ?\n", "    if(min_depth_count>getMetric(model)):\n", "        optimized=True\n", "        if(verbose):\n", "            print('\\tNaive order by count: from ',min_depth_count,' to ',getMetric(model),', dict:',min_dict)\n", "            if(classifier):\n", "                print('\\t\\tROC_AUC/LogLoss: ',\n", "                          roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                          log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "            else:\n", "                print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                          mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                          mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n", "                          r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "        min_depth_count,min_dict=getMetric(model),values_dict\n", "        if(min_depth_count==1):\n", "            if(verbose):\n", "                print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n", "            return df[feature_col].replace(values_dict),values_dict\n", "    elif(verbose):\n", "        print('\\t\\t=[ No optimization using naive order by Count')\n", "    \n", "    # Search Space:\n", "    # maybe random_permutatition isn't the best method... \n", "    #     if len(permutations)~=factorial(len_values) < max_iterations, we can use permutatition (real brute force)\n", "    if(random_permutation==None):\n", "        random_permutation=False\n", "        if(factorial(len_values)>max_iterations):\n", "            random_permutation=True\n", "            if(verbose):\n", "                print('\\t\\tToo big search space, using RANDOM SAMPLING')\n", "        elif(verbose):\n", "            print('\\t\\tmax_iterations (',max_iterations,') >Factorial(length) (',factorial(len_values),'), USING PERMUTATION')\n", "    \n", "    # TODO: maybe we can do better with GA ?!\n", "    if(random_permutation):\n", "        # random permutation ( good lucky =] )\n", "        np.random.seed(random_seed)\n", "        space=range(max_iterations)\n", "    else:\n", "        # default itertools permutation\n", "        space=permutations(values)\n", "\n", "    count=0\n", "    for perm in space:\n", "        if(count>max_iterations):\n", "            break\n", "        # random permutation\n", "        if(random_permutation):\n", "            perm=np.random.permutation(values)\n", "        \n", "        values_dict={values[i]:perm[i] for i in range(0,len_values)}\n", "        model=getModel(classifier,tree_seed)\n", "        model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n", "        if(min_depth_count>getMetric(model)):\n", "            optimized=True\n", "            if(verbose):\n", "                print('\\t',count,'/',max_iterations,'NEW!!! from',min_depth_count,' to ',getMetric(model),' dict:',values_dict)\n", "                if(classifier):\n", "                    print('\\t\\tROC_AUC/LogLoss: ',\n", "                              roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                              log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "                else:\n", "                    print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                              mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                              mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n", "                              r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "            min_depth_count,min_dict=getMetric(model),values_dict\n", "            if(min_depth_count==1):\n", "                print('\\t\\tDEPTH=1')\n", "                break\n", "        count+=1\n", "    if(verbose):\n", "        print('\\t\\tTime spent (seconds):',time.time() - start)\n", "    if(not optimized):\n", "        return df[feature_col],default_dict\n", "    return df[feature_col].replace(values_dict),values_dict\n"], "cell_type": "code", "metadata": {"_uuid": "c5f62300c9cd996e3687e0218155e25e24ac9289", "collapsed": true, "_cell_guid": "86452d0c-290e-4ef2-a9c0-d4025ad9ceea"}}, {"source": ["Let's work! BRUTE FORCE IT!"], "cell_type": "markdown", "metadata": {"_uuid": "d89e3e7ccf4fb31e38eba56c4cd00380fbf967ed", "_cell_guid": "f0f6e3ad-1cca-43ce-b00f-d372905688b2"}}, {"outputs": [], "execution_count": null, "source": ["# SINGLE THREAD\n", "_,values_dict=reorderCategorical(train,'bins','target',verbose=True,max_iterations=100)\n", "train['bins_reordered']  =train['bins'].replace(values_dict)\n", "predict['bins_reordered']=predict['bins'].replace(values_dict)\n", "print('Nice job! =]')"], "cell_type": "code", "metadata": {"_uuid": "b1cffc8a187092f477de756616cc65297fd0e752", "collapsed": true, "scrolled": true, "_cell_guid": "793f85fd-f38b-46c6-9537-8ae9ef9aa32b"}}, {"source": ["THANKS KAGGLE COMPUTERS!"], "cell_type": "markdown", "metadata": {"_uuid": "18cbd2fed12c095c09272d9c2c1471a1e781c6e5", "_cell_guid": "dd1268bd-6a44-4707-b217-8285c18eb259"}}, {"outputs": [], "execution_count": null, "source": ["train.to_csv(  'train.bin2cat-reordered.csv',index=False)\n", "predict.to_csv('test.bin2cat-reordered.csv',index=False)"], "cell_type": "code", "metadata": {"_uuid": "08668c62c0a9bb0e60546e87e1d5263eb188f7a5", "collapsed": true, "_cell_guid": "a2f0fdfa-86b1-4261-99cb-9aa3cb1693d5"}}, {"outputs": [], "execution_count": null, "source": ["from sklearn import tree\n", "from graphviz import Source\n", "import matplotlib.pyplot as plt"], "cell_type": "code", "metadata": {"_uuid": "96d1f883bd352ad741467784212d3258373305e2", "collapsed": true, "_cell_guid": "21459b9e-d3cb-43cd-aa35-53810b9b0c57"}}, {"outputs": [], "execution_count": null, "source": ["#output tree using binaries:)\n", "model=DecisionTreeClassifier(criterion='gini',class_weight='balanced',max_depth=None)\n", "# dataset 1\n", "model.fit(train[bin_cols],train['target'])\n", "y_hat1=model.predict_proba(train[bin_cols])[:,1]\n", "loss1 =log_loss(train['target'],y_hat1)\n", "print('    depth:  ',model.tree_.max_depth)\n", "print('    logloss:',loss1)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["#plot tree :)\n", "Source( tree.export_graphviz(model, out_file=None))"], "cell_type": "code", "metadata": {"_uuid": "8476c258ae02b064188882aaed081ac4734fe331", "collapsed": true, "_cell_guid": "34625ea6-e52a-4729-9506-2e17e412de2e"}}, {"outputs": [], "execution_count": null, "source": ["model.fit(train['bins_reordered'].reshape(-1,1),train['target'])\n", "y_hat1=model.predict_proba(train['bins_reordered'].reshape(-1,1))[:,1]\n", "loss1 =log_loss(train['target'],y_hat1)\n", "print('    depth:  ',model.tree_.max_depth)\n", "print('    logloss:',loss1)"], "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [], "execution_count": null, "source": ["#plot tree :)\n", "Source( tree.export_graphviz(model, out_file=None))"], "cell_type": "code", "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1}