{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential,load_model,Model\nfrom keras.optimizers import *\nfrom keras.utils import to_categorical\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nsess = tf.Session()\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nK.tensorflow_backend._get_available_gpus()\nK.set_session(sess)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"xtrain = pd.read_csv('../input/X_train.csv')\nytrain = pd.read_csv('../input/y_train.csv')\ntest=pd.read_csv(\"../input/X_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2be341a2e26f22365d8ea8cac8e2f33d0328a6dd"},"cell_type":"code","source":"### feature extraction of orientation, angular_velocity, linear_acceleration, velocity_to_acceleration and velocity_linear_acceleration\ndef feature_extraction(raw_frame):\n    raw_frame['orientation'] = raw_frame['orientation_X'] + raw_frame['orientation_Y'] + raw_frame['orientation_Z']+ raw_frame['orientation_W']\n    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n    raw_frame['velocity_linear_acceleration'] = raw_frame['linear_acceleration'] * raw_frame['angular_velocity']\n    return raw_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da090c42eaca5fd72a988b697b6a14f86e508d3"},"cell_type":"code","source":"xtrain = feature_extraction(xtrain)\ntest = feature_extraction(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123c9c83df733a4a1d77dd6a372fb9ffecca8acd"},"cell_type":"code","source":"### more feature extraction with mean, mode, std, variance, min, max and so on...\n\ndef feature_extraction_more(raw_frame):\n    frame = pd.DataFrame([])\n    for col in raw_frame.columns[3:]:\n        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()\n        frame[col + '_std'] = raw_frame.groupby(['series_id'])[col].std()\n        frame[col + '_var'] = raw_frame.groupby(['series_id'])[col].var()\n        frame[col + '_sem'] = raw_frame.groupby(['series_id'])[col].sem()\n        frame[col + '_max'] = raw_frame.groupby(['series_id'])[col].max()\n        frame[col + '_min'] = raw_frame.groupby(['series_id'])[col].min()\n        frame[col + '_max_to_min'] = frame[col + '_max'] / frame[col + '_min']\n        frame[col + '_max_minus_min'] = frame[col + '_max'] - frame[col + '_min']\n        frame[col + '_std_to_var'] = frame[col + '_std'] * frame[col + '_var']\n        frame[col + '_mean_abs_change'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        frame[col + '_abs_max'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fed61fdfe466dd3ec075258c87981fd546133cf7"},"cell_type":"code","source":"train_df = feature_extraction_more(xtrain)\ntest_df = feature_extraction_more(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d37efc43addaf24b30e26a16c34e70f938c9c120"},"cell_type":"code","source":"print(\"train shape\",train_df.shape)\nprint(\"test shape\", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05df3ef9578f5d2f167e4777d29d2939286c32d5"},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\n# Apply transform to both the training set and the test set.\ntrain_df = scaler.fit_transform(train_df)\ntest_df = scaler.fit_transform(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c0f9f9eccb75cf94d7957bcf4c341cbaf2dfcda"},"cell_type":"code","source":"### lable encoding \nle = preprocessing.LabelEncoder()\nle.fit(ytrain.surface)\nytrain['surface'] = le.transform(ytrain.surface)\ntrain_label = to_categorical(ytrain['surface'])\ntrain_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f798e6468abdf37cf1dc730156105618b6875d56"},"cell_type":"code","source":"train_x,val_x,train_y,val_y = train_test_split(train_df, train_label, test_size = 0.10, random_state=14)\ntrain_x.shape,val_x.shape,train_y.shape,val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf5124afe0010b4eafd32205578b44d2d824a009"},"cell_type":"code","source":"train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\nval_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], 1))\ntest_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"842aaef44a88062847b99f7009998650ed28d221"},"cell_type":"code","source":"train_x.shape,val_x.shape,test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"362249addb28dbd42528e72f6f63131576d5538f"},"cell_type":"code","source":"nb_features = train_df.shape[1]\nnb_out = train_label.shape[1]\nnb_features,nb_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a82972642c1a0699171f14a3f50f0f4577e77e4"},"cell_type":"code","source":"# https://www.kaggle.com/ist597/simple-keras-lstm-classifier-98-74\nmodel = Sequential()\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, input_shape=((nb_features), 1)))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(nb_out, activation='softmax'))\n\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aec2b3f4c227ee71ac992e0dae722370ae492bf7"},"cell_type":"code","source":"history = model.fit(train_x, train_y,\n                    batch_size=32,\n                    epochs=10,\n                    verbose=1,\n                    validation_data=(val_x, val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dfd5efcfad87835dda2dcb61833597312c4cf6f"},"cell_type":"code","source":"prediction = model.predict(test_df)\nprediction=np.argmax(prediction, axis=1) \nsubmission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = le.inverse_transform(prediction)\nsubmission.to_csv('lstm_38.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69d5f94bd355d132667cb133531ad10648fe4e76"},"cell_type":"code","source":"train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1]))\nval_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1]))\ntest_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1]))\ntrain_x.shape,val_x.shape,test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ed80edff2855d3d9776df06f61846ec455e507f"},"cell_type":"code","source":"## https://www.kaggle.com/kabure/titanic-eda-keras-nn-pipelines\n## Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(165, \n                activation='relu',  \n                input_dim = nb_features,\n                kernel_initializer='uniform'))\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(nb_out, activation='softmax'))\n\n#Visualizing the model\nmodel.summary()\n\nsgd = SGD(lr = 0.01, momentum = 0.9)\n\n# Compiling our model\nmodel.compile(optimizer = sgd, \n                   loss = 'categorical_crossentropy', \n                   metrics = ['accuracy'])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\nsave_best = ModelCheckpoint('cnn.hdf', save_best_only=True, \n                               monitor='val_loss', mode='min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1af563c2f0fe9cd13dfe85106da54fcd7ce32061"},"cell_type":"code","source":"history = model.fit(train_x, train_y,\n                    batch_size=32,\n                    epochs=50,\n                    verbose=1,\n                    validation_data=(val_x, val_y),callbacks=[early_stopping,save_best])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3196d0f40b7360d155641dca87ec54fe09a311a"},"cell_type":"code","source":"prediction = model.predict(test_df)\nprediction=np.argmax(prediction, axis=1) \nsubmission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = le.inverse_transform(prediction)\nsubmission.to_csv('cnn_74.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29a475b0a67880ec93e8b7f6425949847e718852"},"cell_type":"code","source":"train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\nval_x = np.reshape(val_x, (val_x.shape[0], val_x.shape[1], 1))\ntest_df = np.reshape(test_df, (test_df.shape[0], test_df.shape[1],1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb86bccfe0416b09b58a91e77dee577ad37ae6f1"},"cell_type":"code","source":"## Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(165,activation='relu',input_shape = (nb_features,1),kernel_initializer='uniform'))\nmodel.add(MaxPooling1D(pool_size=2))\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n#adding second hidden layer \nmodel.add(Dense(128,kernel_initializer='uniform',activation='relu'))\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\nmodel.add(GRU(64))\nmodel.add(Dropout(0.50))\nmodel.add(Dense(32,kernel_initializer='uniform',activation='relu'))\nmodel.add(Dropout(0.50))\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(nb_out, activation='softmax'))\n#Visualizing the model\nmodel.summary()\nsgd = SGD(lr = 0.01, momentum = 0.9)\n# Compiling our model\nmodel.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\nsave_best = ModelCheckpoint('cnn.hdf', save_best_only=True,monitor='val_loss', mode='min')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e3f14c4bbd2ef411d92e63d4b86397f1b263a24"},"cell_type":"code","source":"history = model.fit(train_x, train_y,\n                    batch_size=32,\n                    epochs=10,\n                    verbose=1,\n                    validation_data=(val_x, val_y),callbacks=[early_stopping,save_best])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"969384c9bfd2f2c974149de2f5982f5555186ea1"},"cell_type":"code","source":"prediction = model.predict(test_df)\nprediction=np.argmax(prediction, axis=1) \nsubmission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = le.inverse_transform(prediction)\nsubmission.to_csv('gru_33.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29c6426612838084f7f1ae79bbecd02ea5a22736"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}