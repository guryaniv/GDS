{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Imports\nimport pickle\nimport keras\n\nfrom pathlib import Path\nfrom subprocess import check_output\n\nfrom scipy import signal\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dffbdca22134f0926131e51e2e68b73140e056ea"},"cell_type":"code","source":"with open('../input/speech-recognition-data-processing/SavedTestDict.pickle', 'rb') as handle:\n    test_dict = pickle.load(handle)\nwith open('../input/speech-recognition-data-processing/SavedTestLabels.pickle', 'rb') as handle:\n    test_labels = pickle.load(handle)\nprint(\"loaded data.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc520830d201abfc8be6fe8d4f7ddead41ce735d"},"cell_type":"code","source":"train_audio_path = '../input/tensorflow-speech-recognition-challenge/train/audio'\ncontest_dict = {'yes': 0,\n                'no': 1,\n                'up': 2,\n                'down': 3,\n                'left': 4,\n                'right': 5,\n                'on': 6,\n                'off': 7,\n                'stop': 8,\n                'go': 9,\n                'unknown': 10,\n                'silence': 11\n               }\nanswer_dict = {0: 'yes',\n               1: 'no', \n               2: 'up', \n               3: 'down', \n               4: 'left',\n               5: 'right',\n               6: 'on',\n               7: 'off',\n               8: 'stop',\n               9: 'go',\n               10: 'unknown',\n               11: 'silence'\n              }\nprint(test_dict['test'][0], answer_dict[test_labels[test_dict['test'][0]]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bce851932975ececc6016798be26829a1d516cd"},"cell_type":"code","source":"def spectrogram(file, label):\n    if label == 11:\n        path = '../input/'\n    else:\n        path = train_audio_path + '/'\n        \n    eps=1e-10\n    sample_rate, samples = wavfile.read(path + file)\n    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n    \n    # silence can end up being empty files, in this case we can just return one second of zeros\n    if len(spectrogram.shape) < 2:\n        return np.zeros((71,129))\n    else:\n        return np.log(np.abs(spectrogram).T+eps)\n\ndef stft(file, label):\n    if label == 11:\n        path = '../input/'\n    else:\n        path = train_audio_path + '/'\n        \n    eps=1e-10\n    sample_rate, samples = wavfile.read(path + file)\n    frequencies, times, Zxx = signal.stft(samples, sample_rate, nperseg = sample_rate/50, noverlap = sample_rate/75)\n    \n    # silence can end up being empty files, in this case we can just return one second of zeros\n    if len(Zxx.shape) < 2:\n        return np.zeros((151,161))\n    else:\n        return np.log(np.abs(Zxx).T+eps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7c80c204bd9e941c999f75b4790bb76afeb0011"},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    # Generates data for Keras\n    def __init__(self, list_IDs, labels, batch_size=32, dim=(151,161), x1dim=(71,129), x2dim=(151,161), n_channels=1,\n                 n_classes=11, shuffle=True, input_type='wav', testing=False):\n        # Initialization\n        self.dim = dim\n        self.x1dim = x1dim\n        self.x2dim = x2dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.input_type = input_type\n        self.testing = testing\n        self.on_epoch_end()\n\n    def __len__(self):\n        # Denotes the number of batches per epoch\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        # Generate one batch of data\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        if self.input_type == 'all':\n            X1, X2, y = self.__data_generation(list_IDs_temp)\n            if self.testing:\n                return [X1,X2]\n            else:\n                return [X1,X2], [y]\n        else:\n            X, y = self.__data_generation(list_IDs_temp)\n            \n            return X, y\n\n    def on_epoch_end(self):\n        # Updates indexes after each epoch\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        # Generates data containing batch_size samples # X : (n_samples, *dim, n_channels)\n        # Initialization\n\n        if self.input_type == 'all':\n            X1 = np.empty((self.batch_size, *self.x1dim, self.n_channels))\n            X2 = np.empty((self.batch_size, *self.x2dim, self.n_channels))\n        else:\n            X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        y = np.empty((self.batch_size), dtype=int)\n\n        # Generate data  \n        if self.input_type == 'spectrogram':\n            for i, ID in enumerate(list_IDs_temp):\n                spect = spectrogram(ID, self.labels[ID])\n                padded = np.zeros((self.dim))\n                padded[:spect.shape[0], :spect.shape[1]] = spect\n                X[i,] = padded[:, :, np.newaxis]\n                y[i] = self.labels[ID]\n                \n            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n\n        elif self.input_type == 'stft':\n            for i, ID in enumerate(list_IDs_temp):\n                trans = stft(ID, self.labels[ID])\n                #last = ID, self.dim, spect.shape\n\n                padded = np.zeros((self.dim))\n                padded[:trans.shape[0], :trans.shape[1]] = trans\n                X[i,] = padded[:, :, np.newaxis]\n                y[i] = self.labels[ID]\n                \n            return X, keras.utils.to_categorical(y, num_classes=self.n_classes)\n        \n        elif self.input_type == 'all':\n        \n            for i, ID in enumerate(list_IDs_temp):\n                spect = spectrogram(ID, self.labels[ID])\n                padded = np.zeros((self.x1dim))\n                padded[:spect.shape[0], :spect.shape[1]] = spect\n                X1[i,] = padded[:, :, np.newaxis]        \n                y[i] = self.labels[ID]\n            for i, ID in enumerate(list_IDs_temp):\n                trans = stft(ID, self.labels[ID])\n                #last = ID, self.dim, spect.shape\n\n                padded = np.zeros((self.dim))\n                padded[:trans.shape[0], :trans.shape[1]] = trans\n                X2[i,] = padded[:, :, np.newaxis]\n                \n            return X1, X2, keras.utils.to_categorical(y, num_classes=self.n_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf1e20dc68ec5731d1128ef3a1264130fdee00b2"},"cell_type":"code","source":"from keras.models import load_model\n\nensemble_model = load_model('../input/ensemble-model/ensemble_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d58b9a9b72f4e653c38b0c20223734692ef33a3"},"cell_type":"code","source":"# Parameters\ntest_params = {'x1dim': (71,129),\n               'x2dim': (151,161),\n               'batch_size': 5,\n               'n_classes':12,\n               'n_channels': 1,\n               'shuffle': False,\n               'input_type': 'all'}\n\n# Generators\ntest_generator = DataGenerator(test_dict['test'], test_labels, **test_params)\n\nensemble_model.evaluate_generator(test_generator, steps=1367)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"006f6d9d51302a9f0f07940636f82da2b6103f4e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}