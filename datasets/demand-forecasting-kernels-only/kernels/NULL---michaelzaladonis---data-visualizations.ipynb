{"cells":[{"metadata":{"toc":true,"_uuid":"9fc5b6f93f3f0b7ebe0217e356d5893ea2ed767e"},"cell_type":"markdown","source":"<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Problem-Statement\" data-toc-modified-id=\"Problem-Statement-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Problem Statement</a></span></li><li><span><a href=\"#Prepare\" data-toc-modified-id=\"Prepare-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Prepare</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-libraries\" data-toc-modified-id=\"Load-libraries-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load libraries</a></span></li><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Load dataset</a></span></li></ul></li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descriptive-statistics\" data-toc-modified-id=\"Descriptive-statistics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Descriptive statistics</a></span></li><li><span><a href=\"#Data-visualizations\" data-toc-modified-id=\"Data-visualizations-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Data visualizations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sales\" data-toc-modified-id=\"Sales-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Sales</a></span></li><li><span><a href=\"#Stores\" data-toc-modified-id=\"Stores-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Stores</a></span></li><li><span><a href=\"#Items\" data-toc-modified-id=\"Items-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Items</a></span></li><li><span><a href=\"#Time-Series\" data-toc-modified-id=\"Time-Series-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Time Series</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluate-Models\" data-toc-modified-id=\"Evaluate-Models-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluate Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Split-out-validation-dataset\" data-toc-modified-id=\"Split-out-validation-dataset-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Split-out validation dataset</a></span></li><li><span><a href=\"#Naive-Approach\" data-toc-modified-id=\"Naive-Approach-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Naive Approach</a></span></li><li><span><a href=\"#Moving-Averages\" data-toc-modified-id=\"Moving-Averages-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Moving Averages</a></span></li><li><span><a href=\"#Logarithmic-Sales\" data-toc-modified-id=\"Logarithmic-Sales-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Logarithmic Sales</a></span></li><li><span><a href=\"#Moving-Averages-Log\" data-toc-modified-id=\"Moving-Averages-Log-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Moving Averages Log</a></span></li><li><span><a href=\"#Decompose-Log\" data-toc-modified-id=\"Decompose-Log-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Decompose Log</a></span></li></ul></div>"},{"metadata":{"_uuid":"0fec53b93412b156e3cf800f1908f792230d49f5"},"cell_type":"markdown","source":"## Introduction"},{"metadata":{"_uuid":"fcf50820e2dce9feb93fd695d4854b886c5890b5"},"cell_type":"markdown","source":"This dataset was obtained from a Kaggle challenge “Store Item Demand Forecasting Challenge.” In this challenge, they want you to predict predict 3 months of sales for 50 different items at 10 different stores.  The data we are provided with contains set 5 years of store-item sales data.\n\nKey factors about this dataset:\n- Number of rows: 913000\n- Only 3 columns: store, item and sales.\n- 50 items\n- 10 stores\n- Sales are given for each item, store and date (daily)\n- Time frame - 2013/01/01 to 2017/12/31\n- No missing data"},{"metadata":{"_uuid":"03d74fe232abbe347465a78b9892948da4a8a225"},"cell_type":"markdown","source":"## Problem Statement"},{"metadata":{"_uuid":"9e348a6415aa2b941bf563c51924b5830e344deb"},"cell_type":"markdown","source":"The goal of this assignment is to show time series analysis visualizations."},{"metadata":{"_uuid":"f29d11a9ce473b737e5374f933e348c7af6a2279"},"cell_type":"markdown","source":"##\tPrepare"},{"metadata":{"_uuid":"c7a951b825d67f750556deb513b350478a283d5a"},"cell_type":"markdown","source":"###\tLoad libraries"},{"metadata":{"trusted":true,"_uuid":"ae19c569bae5017abebd20f162118504a476a5ec","collapsed":true},"cell_type":"code","source":"import pandas as pd\nfrom pandas.tseries.holiday import *\nimport os\n\nimport datetime\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n%matplotlib inline\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, TimeSeriesSplit\nfrom sklearn.preprocessing import StandardScaler\n\nfrom itertools import *\nimport itertools\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom scipy.stats import norm\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#importing packages for the prediction of time-series data\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport statsmodels.api as sm\nimport statsmodels.tsa.api as smt\nimport statsmodels.formula.api as smf\nfrom statsmodels.tsa.stattools import acf  \nfrom statsmodels.tsa.stattools import pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee7e7f22fd5743830ae27c507a4574eff037a7d3"},"cell_type":"markdown","source":"###\tLoad dataset"},{"metadata":{"trusted":true,"_uuid":"6d468e5c438a5a10e74c1fe91f0a729e5a6ba96c","collapsed":true},"cell_type":"code","source":"# First let us load the datasets\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61594be6be5ab9ba9915e10e0b45d0e3ea2ce957"},"cell_type":"markdown","source":"Make a copy of the data for later use."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e2350ce209265f58403f700494361a57a16c6882"},"cell_type":"code","source":"train_org = train.copy()\ntest_org = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a4e246cd43b613d76d0c431104637b41b170837"},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"_uuid":"3239c68d97ba62b8ca04c9b41f7fac9aa589ce8c"},"cell_type":"markdown","source":"###\tDescriptive statistics"},{"metadata":{"trusted":true,"_uuid":"e50ac3a1d857da829699c39bbc5bd3dd4905c182","collapsed":true},"cell_type":"code","source":"train.columns, test.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e44f5f9701ee32c365bb913e3628ca777c6ea146"},"cell_type":"markdown","source":"The test dataset does not contain an ID column."},{"metadata":{"trusted":true,"_uuid":"64c51bce3100ef81cafc2171db6e65cab5bbc608","collapsed":true},"cell_type":"code","source":"train.dtypes, test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd2a9167a78c93fe48af73237038b1b0a2439c64","collapsed":true},"cell_type":"code","source":"test.shape, train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"deeadd7178486eeb61f8a4284575568a8b2a7ad7"},"cell_type":"markdown","source":"Copy date column as Datetime ."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"51909d65582b0f4261b3e4a929e1ae6802b3317d"},"cell_type":"code","source":"train['Datetime'] = pd.to_datetime(train.date)\ntest['Datetime'] = pd.to_datetime(test.date)\ntest_org['Datetime'] = pd.to_datetime(test_org.date)\ntrain_org['Datetime'] = pd.to_datetime(train_org.date)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1931d38bc2e5452631cd01000b55ada714d3fe62"},"cell_type":"markdown","source":"Resample data into daily, weekly, monthly, and quarterly to show sales for those time peroids."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"afee92a2aeb3cdc4179b2fab60b8af466ac03c84"},"cell_type":"code","source":"train.timestamp = pd.to_datetime(train.Datetime, format = '%d-%m-%Y %H:%M')\ntrain.index = train.timestamp\n\n#converting to daily mean\ndaily = train.resample('D').mean()\n\n#converting to weekly mean\nweekly = train.resample('W').mean()\n\n#converting to monthly mean\nmonthly = train.resample('M').mean()\n\n#converting to Quarter mean\nquarterly = train.resample('Q').mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"bcd8d236732ca4e70bbae719e106d4e7ebd17287","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77229206ec2f66738657e7eb76a15808c35e2686","collapsed":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d3de410d9b58e5794acee7dfeb1defae9672a61"},"cell_type":"markdown","source":"Sales during the 5 year period ranges from 0 to 231, with an average of 52.3.\n\nBreak time down into segments. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e28c01a6c71e471c48eef17ca9f2c08e0413185e"},"cell_type":"code","source":"for i in (test, train, test_org, train_org):\n    i['Year'] = i.Datetime.dt.year\n    i['Month'] = i.Datetime.dt.month\n    i['day'] = i.Datetime.dt.day\n    i[\"dow\"] = i.Datetime.dt.dayofweek\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa4a16adce9c6131110db151ebc91977fd3f11a8","collapsed":true},"cell_type":"code","source":"test.tail()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"3ff2de8bed5e65afa248bf73afa1d20c6ef529be","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cd4da6ffd396f6b32c1e5e52681a214e25b1035"},"cell_type":"markdown","source":"Identify which days are weekends. "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"856007dc170e3bd620906225b167065a54c08697"},"cell_type":"code","source":"temp = train['Datetime']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"39a272f31c657fe348c2dfc40bdbdd06bb7c50a2"},"cell_type":"code","source":"def applyer(row):\n    if row.dayofweek == 5 or row.dayofweek == 6:\n        return 1\n    else:\n        return 0\n    \ntemp2 = train.Datetime.apply(applyer)\ntrain['weekend'] = temp2","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"4a223bf42b0b5ed8abd269cf94d41def40cd654d","collapsed":true},"cell_type":"code","source":"train.head(3)\n            ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4281f10512e04d2af3526c2d80eef677e1edb526"},"cell_type":"markdown","source":"###\tData visualizations"},{"metadata":{"_uuid":"e14ae0467cb364f51e0ef4df47f4bf297edf638f"},"cell_type":"markdown","source":"#### Sales"},{"metadata":{"trusted":true,"_uuid":"5bedcab5260e26dc00f44d85b64efd2ef08aba98","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 10))\nax = sns.distplot(train['sales'], bins=5);\n\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Sales Distributions', fontsize=20)\nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c308cd7bc2da1a1430157b0bc5d697ec167c33ed","collapsed":true},"cell_type":"code","source":"# Sales distribution across the train data\nsales_df = train.copy(deep=True)\nsales_df['sales_bins'] = pd.cut(sales_df.sales, [0, 50, 100, 150, 200, 250])\n\n# Total number of data points\ntotal_points = pd.value_counts(sales_df.sales_bins).sum()\nprint('Sales bucket v/s Total percentage:')\ndisplay(pd.value_counts(sales_df.sales_bins).apply(lambda s: (s/total_points)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4cb7b06f1693401802115e23d8cb7384b13acff","collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(20, 10))\npd.value_counts(sales_df.sales_bins).plot(kind='bar', title='Sales distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c11bf70b186a51203b40b8352b0ad7ce416ac21","collapsed":true},"cell_type":"code","source":"weekDay = train.groupby('weekend')['sales'].sum()\n\ntotal_points = weekDay.sum()\nprint(\"Total\", total_points)\nweekDay.apply(lambda s: (s/total_points)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"344cdfd2e72c61290bc4e55aa14fc16fc41b6ddb","collapsed":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(20, 10))\nweekDay.index = ['Weekday', 'Weekend']\nax = sns.barplot(x=weekDay.index, y=weekDay.values, \n                label=\"Total\")\n\nax.set_xlabel(xlabel='Stores', fontsize=16)\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Total Sales: Weekday vs Weekend', fontsize=20)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"eaeeed1c1ee05560c1f983f2b7b3a7d299d90337","collapsed":true},"cell_type":"code","source":"by_weekday = train.groupby(train.index.dayofweek).mean()\n\nx = by_weekday['sales']\nf, ax = plt.subplots(figsize=(20, 10))\n\nx.index = ['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']\n\nax = sns.barplot(x=x.index, y=x.values, \n                label=\"Total\")\n\nax.set_xlabel(xlabel='Stores', fontsize=16)\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Mean Sales per Day of week', fontsize=20)\nplt.show();\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d3f662234df9b0f19b5bd3069c00f6218aa3cd5"},"cell_type":"markdown","source":"Saturday and Sunday have the highest sales and the weekend has 33% of the sales."},{"metadata":{"trusted":true,"_uuid":"803d6779bc48f23c93381581664793a46cd2bc2a","collapsed":true},"cell_type":"code","source":"by_month = train.groupby(train.index.month).mean()\n\nx = by_month['sales']\nf, ax = plt.subplots(figsize=(20, 14))\nx.index = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n\nax = sns.barplot(x=x.index, y=x.values, \n                label=\"Total\")\n\nax.set_xlabel(xlabel='Months', fontsize=16)\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Mean Sales per Month', fontsize=20)\nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bf2cbac4f2dc814d8e1808483136cb9569eeef9"},"cell_type":"markdown","source":"Sales peak in the summer months, although sales have a burst in November before dropping in December."},{"metadata":{"trusted":true,"_uuid":"1b20a43cffbb851d4a1b3a2403a93cf8a0a7ab28","collapsed":true},"cell_type":"code","source":"by_quarter = train.groupby(train.index.quarter).mean()\n\nx = by_quarter['sales']\nf, ax = plt.subplots(figsize=(20, 14))\nx.index = [\"Q!\", \"Q2\", \"Q3\", \"Q4\"]\n\nax = sns.barplot(x=x.index, y=x.values, \n                label=\"Total\")\n\nax.set_xlabel(xlabel='Quarter', fontsize=16)\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Mean Sales per Quarter', fontsize=20)\nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"238c83801624380bd6804646176d6ebb610ec8ac"},"cell_type":"code","source":"by_year = train.groupby(train.index.year).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"028e8c3144117b06764f4e85fadeb8680ca7fdde","collapsed":true},"cell_type":"code","source":"x = by_year[\"sales\"].pct_change()\nprint(\"Mean year on year change\", x.mean() * 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce030ad5b8de91c35c6dad81a3c3d4ae8222130","collapsed":true},"cell_type":"code","source":"x = by_year['sales']\nf, ax = plt.subplots(figsize=(20, 14))\nax = sns.barplot(x=x.index, y=x.values, \n                label=\"Total\")\n\nax.set_xlabel(xlabel='Years', fontsize=16)\nax.set_ylabel(ylabel='Sales', fontsize=16)\nax.set_title(label='Mean Sales per Year', fontsize=20)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef78df9fd7e05c352d0951617fdb83b0fe58c202"},"cell_type":"markdown","source":"#### Stores"},{"metadata":{"trusted":true,"_uuid":"114eafeb5da42af1e8e76db813ce245e50992122","collapsed":true},"cell_type":"code","source":"years =[2013,2014,2015,2016,2017]\nlength = len(years)\nimport itertools\n\nax = plt.figure(figsize=(20,20))\nax.set_facecolor(\"white\")\n\n\nfor i,j in itertools.zip_longest(years,range(length)):\n    \n    plt.subplot(3,2,j+1)\n    temp_1 = train[train.Year == i]\n    temp_1 = temp_1.groupby(['store', \"Year\"], as_index=False).agg({'sales': np.sum})  \n    temp_1 = temp_1.sort_values(['sales'],ascending=False).reset_index(drop=True)\n    it = temp_1.index\n\n    plt.title(i)\n    plt.subplots_adjust(hspace = .3)\n    sns.set_color_codes(\"pastel\")\n    ax = sns.barplot(x=\"sales\", y=it, data=temp_1, orient='h')\n    ax.set_xlabel(xlabel='Sales', fontsize=16)\n    ax.set_ylabel(ylabel='Store', fontsize=16)\n    ax.set_title(label='Top 10 Stores '+ str(i), fontsize=20)\n    ax.set_yticklabels(labels = temp_1['store'], fontsize=14)\n    \n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7609f9202db3554b2a4d2d7b0934e69997fb8a04","collapsed":true},"cell_type":"code","source":"data = train.groupby(['store']).agg({'sales': np.sum})\ndata.reset_index(level=0, inplace=True)\n# print(data)\ndata = pd.DataFrame(data.sort_values('sales',ascending=False).reset_index(drop=True))[0:10]\n\npublishers = data.index\nplt.figure(figsize=(20,10))\nax = sns.barplot(y = publishers , x = 'sales', data=data, orient='h')\nax.set_xlabel(xlabel='Total Sales', fontsize=16)\nax.set_ylabel(ylabel='Stores', fontsize=16)\nax.set_title(label='Top Stores', fontsize=20)\nax.set_yticklabels(labels = data['store'], fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"d6825230e055f3d9fd713460a91e2096a392f53d","collapsed":true},"cell_type":"code","source":"table = train.pivot_table('sales', index='store', columns='Year', aggfunc='sum')\n\npublishers = table.idxmax()\nsales = table.max()\nyears = table.columns.astype(int)\ndata = pd.concat([publishers, sales], axis=1)\ndata.columns = ['Store', 'Sales']\n\nplt.figure(figsize=(12,8))\nax = sns.pointplot(y = 'Sales', x = years, hue='Store', data=data, size=15)\nax.set_xlabel(xlabel='Year', fontsize=16)\nax.set_ylabel(ylabel='Store Sales Per Year', fontsize=16)\nax.set_title(label='Best Store - Sales Per Year', fontsize=20)\nax.set_xticklabels(labels = years, fontsize=12, rotation=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0368399b1861b3e9cb269bfca3224eb7300b3318"},"cell_type":"markdown","source":"Store 2 is the store with the most sales and it's year on year sales have increased for the past 5 years. "},{"metadata":{"_uuid":"0b05a4dd33fa71bb499edd1f7d3783ccda31f970"},"cell_type":"markdown","source":"#### Items"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"5d12254a1a09e83aaa4a30dc6c2eab8fbe1dcf36","collapsed":true},"cell_type":"code","source":"years =[2013,2014,2015,2016,2017]\nlength = len(years)\nimport itertools\n\nax = plt.figure(figsize=(20,20))\nax.set_facecolor(\"white\")\n\n# df_ts.groupby('store', \"month\").agg({'sales':{'Mean': np.mean, 'Sum': np.sum}})\n\n\n# print(temp_1)\n\nfor i,j in itertools.zip_longest(years,range(length)):\n    \n    plt.subplot(3,2,j+1)\n    temp_1 = train[train.Year == i].groupby(['item', \"Year\"], as_index=False).agg({'sales': np.sum})\n\n    temp_1 = temp_1[temp_1.Year == i]\n    temp_1 = temp_1.sort_values(['sales'],ascending=False).reset_index(drop=True)[0:10]\n    it = temp_1.index\n\n    plt.title(i)\n    plt.subplots_adjust(hspace = .3)\n    sns.set_color_codes(\"pastel\")\n    ax = sns.barplot(x=\"sales\", y= temp_1.index, data=temp_1, orient='h')\n    ax.set_xlabel(xlabel='Sales', fontsize=16)\n    ax.set_ylabel(ylabel='Item', fontsize=16)\n    ax.set_title(label='Top 10 Items '+ str(i), fontsize=20)\n    ax.set_yticklabels(labels = temp_1['item'], fontsize=14)\n    \n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"8cd3f8787a01857cde7cdd3365387d0018b5885e","collapsed":true},"cell_type":"code","source":"data = train.groupby(['item']).agg({'sales': np.sum})\ndata.reset_index(level=0, inplace=True)\n# print(data)\ndata = pd.DataFrame(data.sort_values('sales',ascending=False).reset_index(drop=True))[0:10]\npublishers = data.index\n\ncolors = sns.color_palette(\"spring\", len(data))\nplt.figure(figsize=(12,8))\nax = sns.barplot(y = publishers , x = 'sales', data=data, orient='h', palette=colors)\nax.set_xlabel(xlabel='Sales', fontsize=16)\nax.set_ylabel(ylabel='Item', fontsize=16)\nax.set_title(label='Top 10 Items', fontsize=20)\nax.set_yticklabels(labels = data['item'], fontsize=14)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"573a2b997d189587eb1a2fd8244e510dd62bdee6","collapsed":true},"cell_type":"code","source":"table = train.pivot_table('sales', index='item', columns='Year', aggfunc='sum')\n\npublishers = table.idxmax()\nsales = table.max()\nyears = table.columns.astype(int)\ndata = pd.concat([publishers, sales], axis=1)\ndata.columns = ['Item', 'Sales']\n\nplt.figure(figsize=(12,8))\nax = sns.pointplot(y = 'Sales', x = years, hue='Item', data=data, size=15)\nax.set_xlabel(xlabel='Year', fontsize=16)\nax.set_ylabel(ylabel='Item Sales Per Year', fontsize=16)\nax.set_title(label='Best Selling Item - Sales Per Year', fontsize=20)\nax.set_xticklabels(labels = years, fontsize=12, rotation=50)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25ffcf017a16846f4a728319a6f342dabedab57d"},"cell_type":"markdown","source":"Item 15 is the best selling item and it's year on year sales have increased for the past 5 years. "},{"metadata":{"_uuid":"182ee558df3c625b1c47159a609d24afb7e39822"},"cell_type":"markdown","source":"#### Time Series\n"},{"metadata":{"trusted":true,"_uuid":"d1742a2fd3409f192fe9fb655c3842a2f0be1ba5","collapsed":true},"cell_type":"code","source":"fig, axs = plt.subplots(4,1)\ndaily.sales.plot(figsize = (20,14), title = 'Daily', fontsize = 14, ax = axs[0])\nweekly.sales.plot(figsize = (20,14), title = 'Weekly', fontsize = 14, ax = axs[1])\nmonthly.sales.plot(figsize = (20,14), title = 'Monthly', fontsize = 14, ax = axs[2])\nquarterly.sales.plot(figsize = (20,14), title = 'Quarterly', fontsize = 14, ax = axs[3])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b0c55952fa21ec6636a9884569c704ff66443e1"},"cell_type":"markdown","source":"Use the mean daily sales to show in the future."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2dd1c857c293a53c5e11d95475b079cc7a9c1bba"},"cell_type":"code","source":"test.Timestamp = pd.to_datetime(test.Datetime,format='%d-%m-%Y %H:%M') \ntest.index = test.Timestamp \n\n# Converting to daily mean\ntest = test.resample('D').mean()\n\ntrain.Timestamp = pd.to_datetime(train.Datetime,format='%d-%m-%Y %H:%M') \ntrain.index = train.Timestamp\n\n# Converting to daily mean\ntrain = train.resample('D').mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937231caba8c09c0d4ddd2a75a1bbeddde9b5322"},"cell_type":"markdown","source":"## Evaluate Models"},{"metadata":{"_uuid":"e0658b7b9e685739fd40c35c4ee228c6b361655b"},"cell_type":"markdown","source":"### Split-out validation dataset"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a1ed6822091993eb54c8f0e7052ebf51ba349ab8"},"cell_type":"code","source":"# Splitting train and validation data\nTrain = train.ix['2013-01-01':'2016-12-30']\nvalid = train['2017-01-01':'2017-12-31']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caefc09cefe9976b29f1e027e046b706092aad11","collapsed":true},"cell_type":"code","source":"Train.sales.plot(figsize=(20,10), title= 'Daily Sales', fontsize=14, label='train')\nvalid.sales.plot(figsize=(20,10), title= 'Daily Sales', fontsize=14, label='valid')\nplt.xlabel(\"Datetime\")\nplt.ylabel(\"Sales\")\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8814d157f50d50376c540ff0bde891bf2171f067"},"cell_type":"markdown","source":"### Naive Approach"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"10621fc71246ed50b5ba20864c932ccb37575ac6","collapsed":true},"cell_type":"code","source":"dd = np.asarray(Train.sales)\ny_hat = valid.copy()\ny_hat['naive'] = dd[len(dd)-1]\nplt.figure(figsize = (20,10))\nplt.plot(Train.index, Train['sales'], label = 'Train')\nplt.plot(valid.index,valid['sales'], label='Valid')\nplt.plot(y_hat.index,y_hat['naive'], label='Naive Forecast')\nplt.legend(loc='best')\nplt.title(\"Naive Forecast\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62a6667b2194e9c996e037caaf08b73c14407e29","collapsed":true},"cell_type":"code","source":"#checking the accruacy with RMSE for Naive Approach\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nrms = sqrt(mean_squared_error(valid.sales, y_hat.naive))\nprint(rms)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5265db59a98433a7c0c5b63ac37f5aa210f9544e"},"cell_type":"markdown","source":"### Moving Averages"},{"metadata":{"trusted":true,"_uuid":"30321525cf76b07bf0e8686ea53904828d3d4580","collapsed":true},"cell_type":"code","source":"# Moving average of last 10 observations\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = Train['sales'].rolling(10).mean().iloc[-1] \nplt.figure(figsize=(15,5)) \nplt.plot(Train['sales'], label='Train')\nplt.plot(valid['sales'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 10 observations')\nplt.legend(loc='best')\nplt.show()\n\n#Moving average of last 20 observations\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = Train['sales'].rolling(20).mean().iloc[-1]\nplt.figure(figsize=(15,5))\nplt.plot(Train['sales'], label='Train')\nplt.plot(valid['sales'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 20 observations')\nplt.legend(loc='best')\nplt.show()\n\n#Moving average of last 50 observations\ny_hat_avg = valid.copy()\ny_hat_avg['moving_avg_forecast'] = Train['sales'].rolling(50).mean().iloc[-1]\nplt.figure(figsize=(15,5))\nplt.plot(Train['sales'], label='Train')\nplt.plot(valid['sales'], label='Valid')\nplt.plot(y_hat_avg['moving_avg_forecast'], label='Moving Average Forecast using 50 observations')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9adfbf5ff42e432c922969acb334a863bda27489"},"cell_type":"markdown","source":"### Seasonal Decompose"},{"metadata":{"trusted":true,"_uuid":"04693923576beae3ed5e61964195c482fb7355b7","collapsed":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndecomposition = seasonal_decompose(pd.DataFrame(Train[\"sales\"]), freq = 12)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\nfig, ax = plt.subplots(figsize=(20, 14))\n\nplt.subplot(411)\nplt.plot(Train[\"sales\"], label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0260bc46ddba0140cf36452e7b9f66e4eb548f04","collapsed":true},"cell_type":"code","source":"def test_stationarity(timeseries):\n    \n    #Determing rolling statistics\n    rolmean = timeseries.rolling(12).mean()\n    rolstd = timeseries.rolling(12).mean()\n    #Change window depending on time frame of data\n\n\n    #Plot rolling statistics:\n    plt.figure(figsize = (16,8))\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n    \ntest_stationarity(train[\"sales\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fafd664309951d2bfcbc238c82593ebaa234f47"},"cell_type":"markdown","source":"The test stats show that the data is stationary since the p-value is less than 0.05"},{"metadata":{"_uuid":"f0ffae5a15c0995d9a338244246b44674301e415"},"cell_type":"markdown","source":"### Logarithmic Sales"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d5870470a53c580e2e7ddfee7981fa1e448ce68"},"cell_type":"code","source":"Train[\"sales_log\"] = np.log(Train['sales'])\nvalid[\"sales_log\"]  = np.log(Train['sales'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d14a5fc7aa9698ce08db90f2ca086864d210be5","collapsed":true},"cell_type":"code","source":"Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f02cb608748188816c365a2c7ac4be1ed74113c5","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 10))\nax = sns.distplot(Train[\"sales_log\"]);\n\n# ax.set_xlabel(xlabel='Stores', fontsize=16)\nax.set_ylabel(ylabel='Log Sales', fontsize=16)\nax.set_title(label='Log Sales Distributions', fontsize=20)\n# ax.set_xticklabels(labels = years)\nplt.show();\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f46f13b00ee321bded05704e998c4f355abb9ef3"},"cell_type":"markdown","source":"### Moving Averages Log"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"c0a8f6adac417e3aef755c6ffb66770b91c20075","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 10))\n\nmoving_avg = Train[\"sales_log\"].rolling(12).mean()\nplt.plot(Train[\"sales_log\"])\nplt.plot(moving_avg, color = 'red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5fdb969df0d57bbac844ce971121e5cb1ea412a6"},"cell_type":"code","source":"train_log_moving_avg_diff = Train[\"sales_log\"] - moving_avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d6e9daa5d3d14fc38aa7477cfdb77bce52a17e59"},"cell_type":"code","source":"train_log_moving_avg_diff.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"a538f51ee368795d8aa55e681cb505a222157ddc","collapsed":true},"cell_type":"code","source":"test_stationarity(train_log_moving_avg_diff)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91545fdffc912b808e9b5850971122619b893a0d","collapsed":true},"cell_type":"code","source":"train_log_diff = Train[\"sales_log\"] - Train[\"sales_log\"].shift(1)\ntest_stationarity(train_log_diff.dropna())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc2a16f79d49ca82b335b60dcdf5586e74b66c59"},"cell_type":"markdown","source":"### Decompose Log"},{"metadata":{"trusted":true,"_uuid":"6ad22878334d81d21e4adff6388412f492d0000c","collapsed":true},"cell_type":"code","source":"from statsmodels.tsa.seasonal import seasonal_decompose\ntrain_log_decompose = seasonal_decompose(pd.DataFrame(Train[\"sales_log\"]), freq = 12)\n\ntrend = train_log_decompose.trend\nseasonal = train_log_decompose.seasonal\nresidual = train_log_decompose.resid\nfig, ax = plt.subplots(figsize=(20, 14))\n\nplt.subplot(411)\nplt.plot(Train[\"sales_log\"], label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31ab75a6df887498db6f261da12d8db7c654aace"},"cell_type":"markdown","source":"### Auto Correlation"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0007919a56628a630219616c72d803d47c183fc0"},"cell_type":"code","source":"from statsmodels.tsa.stattools import acf, pacf\nlag_acf = acf(train_log_diff.dropna(), nlags=25)\nlag_pacf = pacf(train_log_diff.dropna(), nlags=25, method='ols')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"641df74ca0a936601eaa8ea2a80c2b1f105256b0","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 14))\nplt.plot(lag_acf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Autocorrelation Function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aec5d34b5efb6c104ad211b4337fc5737497ccb2","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20, 14))\nplt.plot(lag_pacf)\nplt.axhline(y=0,linestyle='--',color='gray')\nplt.axhline(y=-1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.axhline(y=1.96/np.sqrt(len(train_log_diff.dropna())),linestyle='--',color='gray')\nplt.title('Partial Autocorrelation Function')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26e8dcff5304349cb0656273cb2f6b8bd95d6b90"},"cell_type":"markdown","source":"### Credits"},{"metadata":{"_uuid":"58312934cda34a39a9d532203d68d0afa401a081"},"cell_type":"markdown","source":"- https://www.datahubbs.com/towards-machine-learning-in-supply-chain-forecasting-part-2/\n- https://www.datahubbs.com/forecasting-with-seasonality\n- https://github.com/nishanthgampa/Time-Series-Analysis-on-Transportation-Data\n- https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3\n- http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016\n- https://www.quantstart.com/articles#time-series-analysis\n- https://machinelearningmastery.com/time-series-forecasting-supervised-learning/\n- https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ef813b5970893cab59cf6a080b44c13ca1277a5a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"notify_time":"5","toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":true,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"384px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}