{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<h1>** Free Sound  General Purpose Audio Tagging**</h1>\n\n**AIM : **To build a general-purpose automatic audio tagging system using a dataset of audio files covering a wide range of real-world environments. Sounds in the dataset include things like musical instruments, human sounds, domestic sounds, and animals from Freesound’s library\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#from pyAudioAnalysis import audioTrainTest as aT\n#from PyLyrics import *\nfrom wordcloud import WordCloud\nfrom os import path\nimport os\nfrom scipy.io.wavfile import read\nfrom collections import Counter\nimport librosa\nimport librosa.display\nimport IPython.display\nimport matplotlib.style as ms\nms.use('seaborn-muted')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be59935646bbf51d5b391af1c9a206b987478e1b"},"cell_type":"markdown","source":"<h1>**A. Load Dataset**</h1>"},{"metadata":{"trusted":true,"_uuid":"564c89d606ff27f8157123447f9240939128a409","collapsed":true},"cell_type":"code","source":"audio=pd.read_csv('../input/train.csv')\nsubmission=pd.read_csv('../input/sample_submission.csv')\n# Load list of all files from audio_train folder\nfiles_train = librosa.util.find_files('../input/audio_train//')\n# Load list of all files from audio_train folder\nfiles_test= librosa.util.find_files('../input/audio_test//')\n#y, sr = librosa.load(librosa.util.filename())\nfs, data = read('../input/audio_train/001ca53d.wav')\ndata_size = len(data)\n# we will use the size of the array\n# to determine the duration of the sound\nprint(fs)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a28080e04498a82d1bab89087881766cf5bf19d4"},"cell_type":"markdown","source":" <h1>** B.  Understand Data with Descriptive Stats**</h1>"},{"metadata":{"trusted":true,"_uuid":"11815cf5fa240686f717c3a0bb6b7eb6d2970a77","collapsed":true},"cell_type":"code","source":"print(audio.shape)\naudio=pd.DataFrame(audio)\nprint(audio.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1df54d6a5fc7fd5d1807857b135217ebe4a541f6","collapsed":true},"cell_type":"code","source":"wordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(audio.label))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud,interpolation='bilinear')\nplt.title(\"WordCloud for Different Types of Audio Samples\", fontsize=35)\nplt.axis(\"off\")\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1574a28ace74fa40e8dce09ff115b8be6d4ef5e5","collapsed":true},"cell_type":"code","source":"c = Counter(audio.label)\nprint(list(c))\nprint('\\nThe Audio samples count is {}.'.format(len(audio.label.value_counts())))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c293ac320a1cccb39bd757ef3d4a88206f0a2c0a"},"cell_type":"markdown","source":"<h3>Audio effects  and playback with **Librosa** and **IPython **</h3>"},{"metadata":{"trusted":true,"_uuid":"3e8eff4efc537f6e8b2cacc5e65eef1719544e6d","collapsed":true},"cell_type":"code","source":"# Play the  original audio\ny, sr = librosa.load('../input/audio_train//001ca53d.wav')\nIPython.display.Audio(data=y, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e781874d99dca83d89f7946aec16d4fdcb0c4520","collapsed":true},"cell_type":"code","source":"# Separating harmonic and percussive components\ny_h, y_p = librosa.effects.hpss(y)\n# Play the harmonic component\nIPython.display.Audio(data=y_h, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8ff26e35c02a54d5e51deb4dc5bf4f87252bdd5","collapsed":true},"cell_type":"code","source":"# Play the percussive component\nIPython.display.Audio(data=y_p, rate=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6394e6100041b99d5ac7556963ca9cd379780d7c","collapsed":true},"cell_type":"code","source":"#Plot the amplitude envelope of a waveform.\n#If y is monophonic, a filled curve is drawn between [-abs(y), abs(y)].\nplt.figure()\nplt.subplot(3, 1, 1)\nlibrosa.display.waveplot(y, sr=sr)\nplt.title('Monophonic')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebd942b3d7603ba5b20560fc0350bb0ba50a4e58"},"cell_type":"markdown","source":"<h1>Feature Extraction and Visualization</h1>\n. <H3> 1. **Mel-frequency cepstral coefficients (MFCCs): ** </H3>  Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an MFC. They are derived from a type of cepstral representation of the audio clip a nonlinear \"spectrum-of-a-spectrum\".\n<h3>2. **Melspectrogram:**</h3>An object of type MelSpectrogram represents an acoustic time-frequency representation of a sound: the power spectral density P(f, t).It is sampled into a number of points around equally spaced times ti and frequencies fj (on a Mel frequency scale).\n\n<h3>3.  **Chromatogram** :</h3>  A chromatogram is the visual output of the chromatograph. In the case of an optimal separation, different peaks or patterns on the chromatogram correspond to different components of the separated mixture."},{"metadata":{"trusted":true,"_uuid":"3abdaee39d44e5eb2f72a8ac392c6266e53f7f60","collapsed":true},"cell_type":"code","source":"# Visualize the MFCC series\nmfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(mfccs, x_axis='time')\nplt.colorbar()\nplt.title('MFCC')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe626b49562376cd4cc9221b7bf0d56916e3cb04","collapsed":true},"cell_type":"code","source":"#Generate mfccs from a time series\nlibrosa.feature.mfcc(y=y, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0a6dd1b1e705b6dc22e6a0d4bf7e00b4dc1e47a","collapsed":true},"cell_type":"code","source":"S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\nplt.figure(figsize=(10, 4))\nlibrosa.display.specshow(librosa.power_to_db(S,ref=np.max),y_axis='mel', fmax=8000,x_axis='time')\nplt.colorbar(format='%+2.0f dB')\nplt.title('Mel spectrogram')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5ee3883d60ec4222ef4dcb91cb2d7fc11329e60","collapsed":true},"cell_type":"code","source":"#Generate melspectrogram from a time series\nlibrosa.feature.melspectrogram(y=y, sr=sr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6218c7f3d9afc79cb9f05086722b0ae3e770b052","collapsed":true},"cell_type":"code","source":"#Compare a long-window STFT chromagram to the CQT chromagram\nchroma_stft = librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=12, n_fft=4096)\nchroma_cq = librosa.feature.chroma_cqt(y=y, sr=sr)\nplt.figure()\nplt.subplot(2,1,1)\nlibrosa.display.specshow(chroma_stft, y_axis='chroma')\nplt.title('chroma_stft')\nplt.colorbar()\nplt.subplot(2,1,2)\nlibrosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time')\nplt.title('chroma_cqt')\nplt.colorbar()\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8d6f9e2907497e7e6a9c766701516a7b869a8256"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}