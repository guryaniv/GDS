{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"INPUT_DIR = '../input'\n\nimport math\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nfrom tqdm import tqdm\n\n%matplotlib inline\n\n#to plot images\ndef plot_images_for_filenames(filenames, labels, rows=4):\n    imgs = [plt.imread(f'{INPUT_DIR}/train/{filename}') for filename in filenames]\n    \n    return plot_images(imgs, labels, rows)\n\ndef plot_images(imgs, labels, rows=4):\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(13, 8))\n\n    cols = len(imgs) // rows + 1\n\n    for i in range(len(imgs)):\n        subplot = figure.add_subplot(rows, cols, i + 1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(imgs[i] , cmap = 'gray')\n\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3bab85c22c316dbba3cf4311e108682a0204c72"},"cell_type":"code","source":"data_train = pd.read_csv(\"../input/train.csv\")\nprint(data_train.head())\n\nrand_rows = data_train.sample(frac = 1.0)[:25]\nimgs = list(rand_rows['Image'])\nprint(imgs)\nlabels = list(rand_rows['Id'])\n\nplot_images_for_filenames(imgs, labels)\n\nnum_categories = len(data_train['Id'].unique())\n     \nprint(f'Number of categories: {num_categories}')\n\nsize_buckets = Counter(data_train['Id'].value_counts().values)\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(size_buckets)), list(size_buckets.values())[::-1])\nplt.xticks(range(len(size_buckets)), list(size_buckets.keys())[::-1])\nplt.title(\"Num of categories by images in the training set\")\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ed528b0aa3520d3400776c199d8dcec8e492968"},"cell_type":"code","source":"print(data_train['Id'].value_counts().tail(10).keys())\n\n#ploting images with less no. of example\nless_image_eg = data_train['Id'].value_counts().tail(10).keys()\nprint(less_image_eg)\nfile_name_less = []\nlabel = []\nfor i in less_image_eg:\n    file_name_less.extend(data_train[data_train['Id'] == i]['Image'])\n    label.append(i)\nprint(np.asarray(label).shape)\nplot_images_for_filenames(file_name_less , label , rows = 3)\n\nAs we can't make the validation set because some images have less example due to this the validation set and train set will not be distributed properly so we will apply data argumentation\n\ndef is_grey_scale(img_path):\n    im = Image.open(img_path).convert('RGB')\n    w,h = im.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = im.getpixel((i,j))\n            if r != g != b: return False\n    return True\n\n#is_grey = [is_grey_scale(f'{INPUT_DIR}/train/{i}') for i in data_train['Image'].sample(frac=0.2)]\n#grey_perc = round(sum([i for i in is_grey]) / len([i for i in is_grey]) * 100, 2)\n#print(f\"% of grey images: {grey_perc}\")\n\nimg_sizes = Counter([Image.open(f'{INPUT_DIR}/train/{i}').size for i in data_train['Image']])\n\nsize, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(freq)), list(freq), align='center')\nplt.xticks(range(len(size)), list(size), rotation=70)\nplt.title(\"Image size frequencies (where freq > 1)\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"007d9c9bc18b97f4c5c195eac02c2b13bddab569"},"cell_type":"code","source":"from keras.preprocessing.image import (\n    random_rotation, random_shift, random_shear, random_zoom,\n    random_channel_shift, transform_matrix_offset_center, img_to_array)\n\nimg = Image.open(f'{INPUT_DIR}/train/ff38054f.jpg')\n\nimg_arr = img_to_array(img)\nprint(img_arr.shape)\n\nplt.imshow(img)\n\n#image rotation\nimgs = [\n    random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')*255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)\n\nimgs = [\n    random_shift(img_arr, wrg=0.1, hrg=0.3, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)\n\nimgs = [\n    random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)\n\nimgs = [\n    random_zoom(img_arr, zoom_range=(1.5, 0.7), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)\n\nimport random\n\ndef random_greyscale(img, p):\n    if random.random() < p:\n        return np.dot(img[...,:1], [0.299]).T\n    \n    return img\n\nimgs = [\n    random_greyscale(img_arr, 0.5) * 255\n    for _ in range(5)]\n\nplot_images(imgs, None, rows=1)\n\ndef augmentation_pipeline(img_arr):\n    img_arr = random_rotation(img_arr, 18, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_zoom(img_arr, zoom_range=(0.9, 2.0), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    #img_arr = random_greyscale(img_arr, 0.4)\n\n    return img_arr\n\nimgs = [augmentation_pipeline(img_arr) * 255 for _ in range(5)]\nplot_images(imgs, None, rows=1)\n\nprint(file_name_less)\nprint(label)\n\nprint(data_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ea7e61d71406386ad554f65b3df69621fabf93c"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom glob import glob\nfrom PIL import Image\nimport matplotlib.pylab as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_images = glob(\"../input/train/*jpg\")\ntest_images = glob(\"../input/test/*jpg\")\ndf = pd.read_csv(\"../input/train.csv\")\n\ndf[\"Image\"] = df[\"Image\"].map( lambda x : \"../input/train/\"+x)\nImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))\n\nSIZE = 64\n#image are imported with a resizing and a black and white conversion\ndef ImportImage( filename):\n    img = Image.open(filename).convert(\"LA\").resize( (SIZE,SIZE))\n    return np.array(img)[:,:,0]\naug_img = []\nfor img in file_name_less:\n    i = str(INPUT_DIR) + \"/train/\" + str(img)\n    aug_img.append(ImportImage(i))\nx_to_be_aug = np.asarray(aug_img)\n\nprint(x_to_be_aug)\n\ndef plotImages( images_arr, n_images=4):\n    fig, axes = plt.subplots(n_images, n_images, figsize=(12,12))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        if img.ndim != 2:\n            img = img.reshape( (SIZE,SIZE))\n        ax.imshow( img, cmap=\"Greys_r\")\n        ax.set_xticks(())\n        ax.set_yticks(())\n    plt.tight_layout()\n\nx_to_be_aug = x_to_be_aug.reshape( (-1,SIZE,SIZE,1))\nprint(x_to_be_aug.shape)\n\nimage_gen = ImageDataGenerator(\n    #featurewise_center=True,\n    #featurewise_std_normalization=True,\n    rescale=1./255,\n    rotation_range=15,\n    width_shift_range=.15,\n    height_shift_range=.15,\n    horizontal_flip=True)\n\n\n\nimage_gen.fit(x_to_be_aug, augment=True)\n\nprint(x_to_be_aug)\n\nnew_aug_img = []\nfor i in x_to_be_aug:\n    for _ in range(5):\n        img = augmentation_pipeline(i)\n        new_aug_img.append(img)\n\nnew_aug_img = np.asarray(new_aug_img)\nprint(new_aug_img.shape)\n\nprint(label)\n\nlabel_new = []\nfor i in label:\n    for _ in range(5):\n        label_new.append(i)\n        \n\nlabel_new = np.asarray(label_new)\nprint(label_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9cd84f428fedcdd3f014d3cfa6844a30b651393"},"cell_type":"code","source":"train_img = np.array([ImportImage( img) for img in train_images])\nx = train_img\n\nx = x.reshape( (-1,SIZE,SIZE,1))\ninput_shape = x[0].shape\nx_train = x.astype(\"float32\")\nprint(input_shape)\n\ndata = pd.read_csv(\"../input/train.csv\")\nprint(data[\"Id\"])\n\ny_train = data[\"Id\"]\nprint(y_train)\n\ny_train = np.asarray(y_train)\ny_train = np.concatenate((y_train , label_new) , axis = 0)\n\ny_train = np.reshape(y_train , (9900 , 1))\nprint(y_train.shape)\ny_train = pd.DataFrame(y_train)\ny_train = pd.get_dummies(y_train)\n\ny_train = np.asarray(y_train)\nprint(y_train.shape)\nprint(x_train.shape)\n\nx_train = np.concatenate((x_train , new_aug_img) , axis = 0)\nprint(x_train.shape)\n\nmodel = Sequential()\nmodel.add(Conv2D(48, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(48, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(48, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.33))\nmodel.add(Flatten())\nmodel.add(Dense(36, activation='relu'))\nmodel.add(Dropout(0.33))\nmodel.add(Dense(36, activation='relu'))\nmodel.add(Dense(4251, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.fit(x_train , y_train , batch_size = 128 , epochs = 10 , validation_split=0.2)\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0508e9373a601c5f0b80431a43fe6397739a90ac"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}