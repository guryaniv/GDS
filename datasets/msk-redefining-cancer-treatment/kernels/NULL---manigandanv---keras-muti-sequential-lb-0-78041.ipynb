{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"_cell_guid": "3de21bc8-c1e6-40d0-ba79-705289367705", "_execution_state": "idle", "_uuid": "5acb21da6f1c23e6a1657eeac066011c774426cd"}, "source": ["Keras multi sequential model i.e 14 models merged to main model to produce output"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "5601707e-fe0f-4220-99f8-f9d0b9025d2c", "_execution_state": "busy", "_uuid": "bcf5cd8c75a179306435200e3b7a8609d9760af2"}, "source": ["from sklearn import *\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.wrappers.scikit_learn import KerasClassifier\n", "from keras.utils import np_utils\n", "from keras.layers import Dropout,Merge\n", "from sklearn.preprocessing import LabelEncoder\n", "train = pd.read_csv(\"../input/training_variants\")\n", "test = pd.read_csv(\"../input/test_variants\")\n", "trainx = pd.read_csv(\"../input/training_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n", "testx = pd.read_csv(\"../input/test_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\n", "train = pd.merge(train, trainx, how='left', on='ID')\n", "y = train['Class'].values\n", "train = train.drop('Class', axis=1)\n", "test = pd.merge(test, testx, how='left', on='ID')\n", "pid = test['ID'].values\n", "all_data=np.concatenate((train,test),axis=0)\n", "all_data=pd.DataFrame(all_data)\n", "all_data.columns=['ID','Gene','Variation','Text']\n", "sent=all_data['Text']\n", "vect=TfidfVectorizer(stop_words='english')\n", "sent_vectors=vect.fit_transform(sent)\n", "svd=TruncatedSVD(200)\n", "sent_vectors1=svd.fit_transform(sent_vectors)\n", "sent_vectors2=svd.fit_transform(sent_vectors)\n", "sent_vectors3=svd.fit_transform(sent_vectors)\n", "sent_vectors4=svd.fit_transform(sent_vectors)\n", "sent_vectors5=svd.fit_transform(sent_vectors)\n", "sent_vectors6=svd.fit_transform(sent_vectors)\n", "sent_vectors7=svd.fit_transform(sent_vectors)\n", "sent_vectors8=svd.fit_transform(sent_vectors)\n", "sent_vectors9=svd.fit_transform(sent_vectors)\n", "sent_vectors10=svd.fit_transform(sent_vectors)\n", "sent_vectors11=svd.fit_transform(sent_vectors)\n", "sent_vectors12=svd.fit_transform(sent_vectors)\n", "sent_vectors13=svd.fit_transform(sent_vectors)\n", "sent_vectors14=svd.fit_transform(sent_vectors)\n", "def baseline_model():\n", "    model=Sequential()\n", "    model.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    model.add(Dropout(0.25))\n", "    lower_model=Sequential()\n", "    lower_model.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model.add(Dropout(0.25))\n", "    lower_model1=Sequential()\n", "    lower_model1.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model1.add(Dropout(0.25))\n", "    lower_model2=Sequential()\n", "    lower_model2.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model2.add(Dropout(0.25))\n", "    lower_model3=Sequential()\n", "    lower_model3.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model3.add(Dropout(0.25))\n", "    lower_model4=Sequential()\n", "    lower_model4.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model4.add(Dropout(0.25))\n", "    lower_model5=Sequential()\n", "    lower_model5.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model5.add(Dropout(0.25))\n", "    lower_model6=Sequential()\n", "    lower_model6.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model6.add(Dropout(0.25))\n", "    lower_model7=Sequential()\n", "    lower_model7.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model7.add(Dropout(0.25))\n", "    lower_model8=Sequential()\n", "    lower_model8.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model8.add(Dropout(0.25))\n", "    lower_model9=Sequential()\n", "    lower_model9.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model9.add(Dropout(0.25))\n", "    lower_model10=Sequential()\n", "    lower_model10.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model10.add(Dropout(0.25))\n", "    lower_model11=Sequential()\n", "    lower_model11.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model11.add(Dropout(0.25))\n", "    lower_model12=Sequential()\n", "    lower_model12.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n", "    lower_model12.add(Dropout(0.25))\n", "    merged_model=Merge([model,lower_model,lower_model1,lower_model2,lower_model3,lower_model4,lower_model5,lower_model6,lower_model7,lower_model8,lower_model9,lower_model10,lower_model11,lower_model12],mode='concat')\n", "    final_model=Sequential()\n", "    final_model.add(merged_model)\n", "    final_model.add(Dense(9,init='normal',activation='softmax'))\n", "    final_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n", "    return final_model\n", "encoder=LabelEncoder()\n", "encoder.fit(y)\n", "encoded_y=encoder.transform(y)\n", "dummy_y=np_utils.to_categorical(encoded_y)\n", "print(dummy_y.shape)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "submission = pd.read_csv('../input/stage2_sample_submission.csv')\n", "stage1_test = pd.read_csv('../input/test_variants')\n", "stage2_test = pd.read_csv('../input/stage2_test_variants.csv')\n", "stage1_solution = pd.read_csv('../input/stage1_solution_filtered.csv')\n", "\n", "stage1_solution = stage1_solution.merge(stage1_test, how = 'left', on = 'ID')\n", "\n", "stage2_test.merge(\n", "        stage1_solution.drop('ID', axis = 1), \n", "        how = 'left', \n", "        on = ['Gene', 'Variation'])\\\n", "    .drop(['Gene', 'Variation'], axis = 1)\\\n", "    .fillna(1)\\\n", "    .to_csv('submission.csv', index = False)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "7ccea308-bbac-4fd8-a972-fcb33d2f8a73", "_execution_state": "idle", "_uuid": "e58b682573faff0a67597ca9a8ccece63f4cd04c"}, "source": [], "cell_type": "code", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}