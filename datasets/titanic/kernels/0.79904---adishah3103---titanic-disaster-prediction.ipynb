{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport random as rnd\nimport xgboost as xgb\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Machine Learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.grid_search import GridSearchCV\n#parameters = {'min_samples_split':np.arange(2, 100), 'max_depth': np.arange(2,100), 'criterion':['gini', 'entropy']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a58e09529b0003bf01174b72ea796cbe4f3ead7"},"cell_type":"code","source":"#loading datasets\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e1dd73601f0e1a512f110dbfd0554e79298c4f3"},"cell_type":"code","source":"#analysing data\nprint(train_df.columns.values)\n\n#preview the data\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fbf1fd3d3c09c8601c2737a557bcf6623d53175"},"cell_type":"code","source":"#reviewing data\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"298bec6222e3513ac17e555f347ed2dea584f5c2"},"cell_type":"code","source":"#Analyzing by pivoting features\ntrain_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2bff4ec5fc7bae66e430410caf416275914161f"},"cell_type":"code","source":"#Analyzing by pivoting features\ntrain_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7f813db707c5a80ec44d662f949b4983db245b7"},"cell_type":"code","source":"#Analyzing by pivoting features\ntrain_df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6632a8d9d19e49bdcc776866fdcb191fa276c309"},"cell_type":"code","source":"#Analyzing by pivoting features\ntrain_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6eee736705ba67cda8b8bc96609aaa364904bd4"},"cell_type":"code","source":"#Dropping redundant features\ntrain_df = train_df.drop(['Ticket', 'Cabin'], axis=1)\ntest_df = test_df.drop(['Ticket', 'Cabin'], axis=1)\ncombine = [train_df, test_df]\nprint(test_df.shape)\nprint(train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09796f2f69a670cd8b8af5a802c9d650acc26201"},"cell_type":"code","source":"#creating title feature\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(train_df['Title'], train_df['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d73c76948ec558a8af4597c9413eec80bc8fa3b"},"cell_type":"code","source":"#We can replace many titles with a more common name or classify them as Rare\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntrain_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e060a4b061a59ca4df785f97f417fd4162f1297"},"cell_type":"code","source":"#Handling categorical data\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n\nfor dataset in combine:\n    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n\ntrain_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#We can now drop Name and passenger ID feature\ntrain_df = train_df.drop(['Name', 'PassengerId'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.shape, test_df.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62bf92cbdfadd38322c0e198749fa20e0e957a73"},"cell_type":"code","source":"#handling missing values in age\n\nguess_ages = np.zeros((2,3))\nguess_ages\n\nfor dataset in combine:\n    for i in range(0, 2):\n        for j in range(0, 3):\n            guess_df = dataset[(dataset['Sex'] == i) & \\\n                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n\n    \n            age_guess = guess_df.median()\n\n            # Convert random age float to nearest .5 age\n            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n            \n    for i in range(0, 2):\n        for j in range(0, 3):\n            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1),\\\n                    'Age'] = guess_ages[i,j]\n\n    dataset['Age'] = dataset['Age'].astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8276d9019330cb909f4a901144cb17865b6b272"},"cell_type":"code","source":"#ceating age bands and replacing with single value\ntrain_df['AgeBand'] = pd.cut(train_df['Age'], 5)\ntrain_df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(\n    by='AgeBand', ascending=True)\n\nfor dataset in combine:    \n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']\ntrain_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ae86a8d18a668354db75743daf9a47c4bd71b7d"},"cell_type":"code","source":"train_df = train_df.drop(['AgeBand'], axis=1)\ncombine = [train_df, test_df]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c39e223416cbc7a4c33cdbb04130f4e7129281bc"},"cell_type":"code","source":"#combining SibSp and Parch\nfor dataset in combine:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n\ntrain_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf02e025bbee2f3751d5212c15c2894500224b10"},"cell_type":"code","source":"#creating new feature IsAlone\nfor dataset in combine:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n\ntrain_df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4332e32d7b9bfc6b169a3243c7ec43da6f820ea8"},"cell_type":"code","source":"#dropping Parch,SibSp and FamilySize\ntrain_df = train_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ntest_df = test_df.drop(['Parch', 'SibSp', 'FamilySize'], axis=1)\ncombine = [train_df, test_df]\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"830facfd146975f1f77de8969855f8f779e59e93"},"cell_type":"code","source":"#Filling missing vlues in Embarked with the most occuring value \nfreq_port = train_df.Embarked.dropna().mode()[0]\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n    \ntrain_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n\nfor dataset in combine:\n    dataset['Age*Class'] = dataset.Age * dataset.Pclass\n\ntrain_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcc5de092f1781ceb10afec482c3c0540aafe8cf"},"cell_type":"code","source":"#handling categorial feature for Embarked\nfor dataset in combine:\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36a672dd5cb77cc683f9a4d8eddc7d2b63c6b6e3"},"cell_type":"code","source":"#missing value of fare in test dataset\ntest_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"583faa7ffbdcf20f0fb888dd871deeda3ba88f8f"},"cell_type":"code","source":"# creating a new Feature FareBand and assigning integer values t each category of fare\ntrain_df['FareBand'] = pd.qcut(train_df['Fare'], 4)\ntrain_df[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25b59b82d2a09da7d2b6fe545aa3b4095a73cf63"},"cell_type":"code","source":"for dataset in combine:\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n\ntrain_df = train_df.drop(['FareBand'], axis=1)\ncombine = [train_df, test_df]\n    \ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db471f5cc9bdf538f00244ea4fdc8c5fe94aafa4"},"cell_type":"code","source":"#Splitting into X_train, Y_train\n\nX_train = train_df.drop(\"Survived\", axis=1)\nY_train = train_df[\"Survived\"]\nX_test  = test_df.drop(\"PassengerId\", axis=1).copy()\nX_train.shape, Y_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cfa687bc2989a22ff8b663fd38a0252b48f4b60"},"cell_type":"code","source":"#Predicting the model\n\n#Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f13e3839eb6602f218151f247abdce62a261c5e8"},"cell_type":"code","source":"# SVM\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4b5adf41b83971ddc1f01b0caff41be54b2d2f1"},"cell_type":"code","source":"#KNN\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7536d72b7c562fb774718315af50d3f6b95912dd"},"cell_type":"code","source":"#Decision Tree\ndecision_tree = DecisionTreeClassifier()\n#grid = GridSearchCV(decision_tree, parameters,scoring='accuracy', cv=8)\n#grid.fit(X_train,Y_train)\n#print(grid.best_params_)\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree\n\n#Decision tree performs better as comapred to other models here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3c35ea1efc0650f6cdd1bac974e9ad56f8d1e42"},"cell_type":"code","source":"# Random Forest\n\n#random_forest = RandomForestClassifier(n_estimators=100)\n#random_forest.fit(X_train, Y_train)\n#Y_pred = random_forest.predict(X_test)\n#random_forest.score(X_train, Y_train)\n#acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n#acc_random_forest '''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51f52c056df688e8c03afbd59916b64a105591c5"},"cell_type":"code","source":"#XGBoost\nmodel1 = xgb.XGBClassifier()\ntrain_model1 = model1.fit(X_train, Y_train)\nY_pred  = train_model1.predict(X_test)\nprint(round(model1.score(X_train, Y_train) * 100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8261fb5fa7244fd54719b29e877c52bdeb1b1d29"},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": Y_pred\n    })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4eb87d188783f3c21c53c9b01e6618abeec0bd14"},"cell_type":"code","source":"submission.to_csv('final_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}