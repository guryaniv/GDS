{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b38403d-2919-bfd4-d630-9de8c31464d4"
      },
      "source": [
        "*The same issue as with Naive Bayes - can not classify 0*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e9f3d07e-d859-4694-269e-52f48f5e909f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from datetime import date\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy import interp\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7558513c-62f9-4007-3b6f-08ec349c2d54"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "df=pd.read_csv('../input/Combined_News_DJIA.csv')\n",
        "df['Combined']=df.iloc[:,2:27].apply(lambda row: ''.join(str(row.values)), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95ea4b8c-7b4e-0e69-162e-8d3a114ba8af"
      },
      "outputs": [],
      "source": [
        "#train data\n",
        "train=df.loc[(pd.to_datetime(df[\"Date\"]) <= date(2014,12,31)),['Label','Combined']]\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7622c8d0-f5b3-4ce3-a3b9-c4f3868266fd"
      },
      "outputs": [],
      "source": [
        "#test data\n",
        "test=df.loc[(pd.to_datetime(df[\"Date\"]) > date(2014,12,31)),['Label','Combined']]\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c7f3a78c-c4b7-0cf1-739a-83918b04041d"
      },
      "source": [
        "I run different classification models on the same data to compare the results. So I combine text processing, plotting and evaluation in specific functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f96b2026-e97e-146d-4cd5-2f9d36d66251"
      },
      "outputs": [],
      "source": [
        "#Text pre-processing\n",
        "\n",
        "def text_process(text):\n",
        "    \"\"\"\n",
        "    Takes in a string of text, then performs the following:\n",
        "    1. Tokenizes and removes punctuation\n",
        "    2. Removes  stopwords\n",
        "    3. Stems\n",
        "    4. Returns a list of the cleaned text\n",
        "    \"\"\"\n",
        "     \n",
        "    # tokenizing\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    text_processed=tokenizer.tokenize(text)\n",
        "    \n",
        "    # removing any stopwords\n",
        "    text_processed = [word.lower() for word in text_processed if word.lower() not in stopwords.words('english')]\n",
        "    \n",
        "    # steming\n",
        "    porter_stemmer = PorterStemmer()\n",
        "    \n",
        "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
        "    \n",
        "    try:\n",
        "        text_processed.remove('b')\n",
        "    except: \n",
        "        pass\n",
        "\n",
        "    return text_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22fb6320-7c1c-9f6f-e68c-c500993b60cc"
      },
      "outputs": [],
      "source": [
        "def ROCCurves (Actual, Predicted):\n",
        "    '''\n",
        "    Plot ROC curves for the multiclass problem\n",
        "    based on http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
        "    '''\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    n_classes=2\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(Actual.values, Predicted)\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Actual.ravel(), Predicted.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "    ##############################################################################\n",
        "    # Plot ROC curves for the multiclass problem\n",
        "\n",
        "    # Compute macro-average ROC curve and ROC area\n",
        "\n",
        "    # First aggregate all false positive rates\n",
        "\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    # Then interpolate all ROC curves at this points\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    # Finally average it and compute AUC\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure()\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label='micro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"micro\"]),\n",
        "         linewidth=2)\n",
        "\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "         label='macro-average ROC curve (area = {0:0.2f})'\n",
        "               ''.format(roc_auc[\"macro\"]),\n",
        "         linewidth=2)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                   ''.format(i, roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "    plt.legend(loc=\"lower right\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52d8f57b-f83e-3213-3391-9255ebe5f957"
      },
      "outputs": [],
      "source": [
        "def heatmap(data):\n",
        "  fig, ax = plt.subplots()\n",
        "  heatmap = sns.heatmap(data, cmap=plt.cm.Blues,annot=True, annot_kws={\"size\": 8})\n",
        "  # put the major ticks at the middle of each cell\n",
        "  # want a more natural, table-like display\n",
        "  ax.xaxis.tick_top()\n",
        "  # rotate the\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b0b5c903-5200-3850-de14-0567072ae0ea"
      },
      "outputs": [],
      "source": [
        "def plot_classification_report(classification_report):\n",
        "    lines = classification_report.split('\\n')\n",
        "    classes = []\n",
        "    plotMat = []\n",
        "    for line in lines[2 : (len(lines) - 3)]:\n",
        "        t = line.split()\n",
        "        classes.append(t[0])\n",
        "        v = [float(x) for x in t[1: len(t) - 1]]\n",
        "        plotMat.append(v)\n",
        "    aveTotal = lines[len(lines) - 1].split()\n",
        "    classes.append('avg/total')\n",
        "    vAveTotal = [float(x) for x in t[1:len(aveTotal) - 1]]\n",
        "    plotMat.append(vAveTotal)\n",
        "    df_classification_report = DataFrame(plotMat, index=classes,columns=['precision', 'recall', 'f1-score'])\n",
        "    heatmap(df_classification_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6bf28c99-6b75-a9f4-7738-e33e64f9d2dc"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(confusion_matrix,classes=['0','1']):\n",
        "    df_confusion_matrix = DataFrame(confusion_matrix, index=classes,columns=classes)\n",
        "    df_confusion_matrix\n",
        "    heatmap(df_confusion_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "00f98fe1-8a17-538c-79c9-701c1d270d2c"
      },
      "outputs": [],
      "source": [
        "def Evaluation (Actual, Predicted):\n",
        "    '''\n",
        "        Prints and plots\n",
        "        - classification report\n",
        "        - confusion matrix\n",
        "        - ROC-AUC\n",
        "    '''\n",
        "    print (classification_report(Actual,Predicted))\n",
        "    plot_classification_report(classification_report(Actual,Predicted))\n",
        "    print ('Confussion matrix:\\n', confusion_matrix(Actual,Predicted))\n",
        "    plot_confusion_matrix(confusion_matrix(Actual,Predicted))\n",
        "    print ('ROC-AUC: ' + str(roc_auc_score(Actual,Predicted)))\n",
        "    ROCCurves (Actual,Predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79e54595-a967-69e4-6bcc-8f59451fdd19"
      },
      "outputs": [],
      "source": [
        "#Creating a Data Pipeline for SVM classifier\n",
        "svm_pipeline = Pipeline([\n",
        "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
        "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
        "    ('classifier', SVC()),  # train on TF-IDF vectors w/ LogisticRegression classifier\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c6f11be-e08e-a1b1-89cf-e716be14295e"
      },
      "outputs": [],
      "source": [
        "svm_pipeline.fit(train['Combined'],train['Label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b28b7064-3707-2ff5-ba68-2661976700e3"
      },
      "outputs": [],
      "source": [
        "predictions = svm_pipeline.predict(test['Combined'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d4d7959-e3e9-7523-67c3-bc3e2961def5"
      },
      "outputs": [],
      "source": [
        "Evaluation (test[\"Label\"], predictions)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}