{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":true},"cell_type":"code","source":"INPUT_DIR = '../input'","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"7d03c24fa62cb44f8226b2e6c7fa55953cbce21d","_cell_guid":"8b578df7-1f44-4078-9752-876eb9cca5d0","collapsed":true,"trusted":true},"cell_type":"code","source":"import math\nfrom collections import Counter\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\n\nfrom tqdm import tqdm\n\n%matplotlib inline","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"c7c4e6ab6cf01d6bf05e6af583fc34a14b9c888f","_cell_guid":"264d8de4-c411-440b-ba14-988cb5169061","collapsed":true,"trusted":true},"cell_type":"code","source":"#to plot images\ndef plot_images_for_filenames(filenames, labels, rows=4):\n    imgs = [plt.imread(f'{INPUT_DIR}/train/{filename}') for filename in filenames]\n    \n    return plot_images(imgs, labels, rows)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"916fa293fa50c46c7bedd8e701a42a2d9474f8c0","_cell_guid":"482be394-8aa5-43b2-95c4-e3f3ba05ff65","collapsed":true,"trusted":true},"cell_type":"code","source":"def plot_images(imgs, labels, rows=4):\n    # Set figure to 13 inches x 8 inches\n    figure = plt.figure(figsize=(13, 8))\n\n    cols = len(imgs) // rows + 1\n\n    for i in range(len(imgs)):\n        subplot = figure.add_subplot(rows, cols, i + 1)\n        subplot.axis('Off')\n        if labels:\n            subplot.set_title(labels[i], fontsize=16)\n        plt.imshow(imgs[i] , cmap = 'gray')","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"9008134be1762498c9973d66c519551bd6b63384","_cell_guid":"a78205ef-5c11-43c9-969e-15bec3ad0605","collapsed":true,"trusted":true},"cell_type":"code","source":"np.random.seed(0)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"07b3e9db9d2eaef700a0694229bd1c97f4fd665a","_cell_guid":"9ac9ce3a-5ba8-4267-95b7-2a4600a4f50d","trusted":true},"cell_type":"code","source":"data_train = pd.read_csv(\"../input/train.csv\")\nprint(data_train.head())","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"81971ec31a022a7d0d91f20e8e4f9417678445c0","_cell_guid":"631fa731-acf4-4b22-9869-eba5e14714a6","trusted":true},"cell_type":"code","source":"rand_rows = data_train.sample(frac = 1.0)[:25]\nimgs = list(rand_rows['Image'])\nprint(imgs)\nlabels = list(rand_rows['Id'])\n\nplot_images_for_filenames(imgs, labels)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"95ebb2761d41582dff8383e939da76d720a30436","_cell_guid":"c53dba79-404b-458d-8dca-25c25f84ca08","trusted":true},"cell_type":"code","source":"num_categories = len(data_train['Id'].unique())\n     \nprint(f'Number of categories: {num_categories}')","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"ffa18ebc61713b63367d61eebe6e3cad4bd3ca36","_cell_guid":"5a7d4291-93fa-4a9c-aecd-3b98f6ba889f","collapsed":true,"trusted":true},"cell_type":"code","source":"size_buckets = Counter(data_train['Id'].value_counts().values)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"56065f852a07b21b0a6d1d3f42e37b0b78bb8a97","_cell_guid":"f95db211-0584-4685-b48a-ee09bc9cdd41","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\nplt.bar(range(len(size_buckets)), list(size_buckets.values())[::-1])\nplt.xticks(range(len(size_buckets)), list(size_buckets.keys())[::-1])\nplt.title(\"Num of categories by images in the training set\")\n\nplt.show()\n","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"ec00f1ded5b5feb01b97490b130882104cefeea4","_cell_guid":"9ad734bc-2b3a-49fd-88c9-a3b0b5071623","trusted":true},"cell_type":"code","source":"print(data_train['Id'].value_counts().tail(10).keys())","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"951e969d6410ef0f9b77bd34385002df45c25f17","_cell_guid":"89191a38-6e98-486f-a562-d6425345cc22","trusted":true},"cell_type":"code","source":"#ploting images with less no. of example\nless_image_eg = data_train['Id'].value_counts().tail(10).keys()\nprint(less_image_eg)\nfile_name_less = []\nlabel = []\nfor i in less_image_eg:\n    file_name_less.extend(data_train[data_train['Id'] == i]['Image'])\n    label.append(i)\nprint(np.asarray(label).shape)\nplot_images_for_filenames(file_name_less , label , rows = 3)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"bacfb5a1600e10d5476e34573edb04a3183b58f8","_cell_guid":"c7a33dda-7b4c-4f8d-b2d7-f76d73b1bfc1"},"cell_type":"markdown","source":"As we can't make the validation set because some images have less example due to this the validation set and train set will not be distributed properly so we will apply data argumentation"},{"metadata":{"_uuid":"e85f25a6d626abd154d7ae8f6f28eac0a8274661","_cell_guid":"e03349e9-646d-44db-83da-2e48785c191e","collapsed":true,"trusted":true},"cell_type":"code","source":"def is_grey_scale(img_path):\n    im = Image.open(img_path).convert('RGB')\n    w,h = im.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = im.getpixel((i,j))\n            if r != g != b: return False\n    return True","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"c5647f1ece84af28112baf09ef838895aa202f63","_cell_guid":"5cac6c1c-32ac-444f-bb8b-269ca505fd03","collapsed":true,"trusted":true},"cell_type":"code","source":"#is_grey = [is_grey_scale(f'{INPUT_DIR}/train/{i}') for i in data_train['Image'].sample(frac=0.2)]\n#grey_perc = round(sum([i for i in is_grey]) / len([i for i in is_grey]) * 100, 2)\n#print(f\"% of grey images: {grey_perc}\")","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"8d79e7099ee94b95ed05675579debbdb80866d72","_cell_guid":"b4ef97d0-8002-415c-a576-96d1f6d32d73","trusted":true},"cell_type":"code","source":"img_sizes = Counter([Image.open(f'{INPUT_DIR}/train/{i}').size for i in data_train['Image']])\n\nsize, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n\nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(freq)), list(freq), align='center')\nplt.xticks(range(len(size)), list(size), rotation=70)\nplt.title(\"Image size frequencies (where freq > 1)\")\n\nplt.show()","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"cacd0bbfd0330d05dfe664cf7bf64fb3201d2633","_cell_guid":"df906dc0-9d5f-4296-8c1c-b356e5361d5a","trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import (\n    random_rotation, random_shift, random_shear, random_zoom,\n    random_channel_shift, transform_matrix_offset_center, img_to_array)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"407b8a1efa519095a0286960b70c983c165fa7ee","_cell_guid":"5ada5f3d-12dc-4259-ad4d-aba436e816fd","collapsed":true,"trusted":true},"cell_type":"code","source":"img = Image.open(f'{INPUT_DIR}/train/ff38054f.jpg')","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"66a9c8be6d3d481a9df7c37ef46da014624a7e6a","_cell_guid":"e071966f-9c75-4cc7-bd15-300034fd4b89","trusted":true},"cell_type":"code","source":"img_arr = img_to_array(img)\nprint(img_arr.shape)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"9652e0260f80e2d7b370f4c87e4fca4934f22f02","_cell_guid":"e6e331d1-abba-4df7-af60-d56b2a063abe","trusted":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"39eedd85ed051ed4a35387d921bdc516f122da3f","_cell_guid":"4e7fcc39-8b33-4f5e-b59b-32071cd6d1ce","trusted":true},"cell_type":"code","source":"#image rotation\nimgs = [\n    random_rotation(img_arr, 30, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')*255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"18efe621f705e9e4533b9a283ae9edd747685cac","_cell_guid":"60c8892a-878f-4825-baa0-6615e347f6fa","trusted":true},"cell_type":"code","source":"imgs = [\n    random_shift(img_arr, wrg=0.1, hrg=0.3, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"2097808bbc983684ca6c4e1e0b37591700639507","_cell_guid":"da1bad39-d20e-4084-ac2d-873e87f7e83c","trusted":true},"cell_type":"code","source":"imgs = [\n    random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"8f7c53b7f60933e79173d763d87fa373763a49b7","_cell_guid":"269478f6-2333-4cea-8c7a-4293256799f8","trusted":true},"cell_type":"code","source":"imgs = [\n    random_zoom(img_arr, zoom_range=(1.5, 0.7), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n    for _ in range(5)]\nplot_images(imgs, None, rows=1)","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"5649884e409afc3bbdca833dd1d0e299452a7f77","_cell_guid":"315119e7-18af-48ea-a956-bd558dd47e9d","trusted":true},"cell_type":"code","source":"import random\n\ndef random_greyscale(img, p):\n    if random.random() < p:\n        return np.dot(img[...,:1], [0.299]).T\n    \n    return img\n\nimgs = [\n    random_greyscale(img_arr, 0.5) * 255\n    for _ in range(5)]\n\nplot_images(imgs, None, rows=1)","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"b028983eed0b0cc38ea86af98f25de21a0c565c9","_cell_guid":"fcb4bd2f-e3b3-4eab-9dde-051bf3b30e43","collapsed":true,"trusted":true},"cell_type":"code","source":"def augmentation_pipeline(img_arr):\n    img_arr = random_rotation(img_arr, 18, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    img_arr = random_zoom(img_arr, zoom_range=(0.9, 2.0), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n    #img_arr = random_greyscale(img_arr, 0.4)\n\n    return img_arr","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"a4f950870f3cec241d8f7a942a6b54c98b7404ac","_cell_guid":"6d63870d-ed7d-4806-8e27-af677a4797c1","trusted":true},"cell_type":"code","source":"imgs = [augmentation_pipeline(img_arr) * 255 for _ in range(5)]\nplot_images(imgs, None, rows=1)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"c627a5ef348cc516a05c6dc8f6aef51154cc154e","_cell_guid":"f8be7ef4-bd61-447c-93b8-fd062405042e","trusted":true},"cell_type":"code","source":"print(file_name_less)\nprint(label)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"09e623d8f7392843c20e09498265186284b530aa","_cell_guid":"effc9c1a-154d-4c4a-a6fb-e18c773afd53","trusted":true},"cell_type":"code","source":"print(data_train.shape)","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"64bbc8238d7931da0048a1989628450a535b4bf5","_cell_guid":"8f48b411-e50b-4328-a313-bf94ac3ab144","trusted":true},"cell_type":"code","source":"import scipy.misc\nfor i in file_name_less:\n    img = Image.open(f'{INPUT_DIR}/train/{i}')\n    img_arr = img_to_array(img)\n   # print(img_arr)\n    for j in range(5):\n        imgs = augmentation_pipeline(img_arr)*255\n        plot_images(imgs , None , rows = 4)\n        img_name = str(j) + \"_\" + str(i)\n        print(img_name)\n        scipy.misc.imsave('..input/train/{img_name}', image_array)\n        data_train['Id'].append(data_train['Id'][data_train['Image'] == i])\n        data_train['Image'].append(img_name)\n        train.append(imgs)","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"3f14a8a4404cfac080bbd08c1cdfa0043189a4a0","_cell_guid":"9e621fc8-866c-458a-8cc4-f6bc32494bf7","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom glob import glob\nfrom PIL import Image\nimport matplotlib.pylab as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"f7a6cc3832a75892240684f98f8c6a4bf9e8ee09","collapsed":true,"_cell_guid":"314f3694-6885-4b89-b252-e57c859a2f5c","trusted":true},"cell_type":"code","source":"train_images = glob(\"../input/train/*jpg\")\ntest_images = glob(\"../input/test/*jpg\")\ndf = pd.read_csv(\"../input/train.csv\")\n\ndf[\"Image\"] = df[\"Image\"].map( lambda x : \"../input/train/\"+x)\nImageToLabelDict = dict( zip( df[\"Image\"], df[\"Id\"]))","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"6fb9d617a66f05de2a4df9956d340bbfe9885a1c","collapsed":true,"_cell_guid":"fd226d4c-6d8a-4252-931d-de80c3bf0f39","trusted":true},"cell_type":"code","source":"SIZE = 64\n#image are imported with a resizing and a black and white conversion\ndef ImportImage( filename):\n    img = Image.open(filename).convert(\"LA\").resize( (SIZE,SIZE))\n    return np.array(img)[:,:,0]\naug_img = []\nfor img in file_name_less:\n    i = str(INPUT_DIR) + \"/train/\" + str(img)\n    aug_img.append(ImportImage(i))\nx_to_be_aug = np.asarray(aug_img)","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"e72c21d0664f976b650857b9717bf9cfcf85f879","_cell_guid":"0e619ca2-84dd-49f3-b1de-d5ce182cc082","trusted":true},"cell_type":"code","source":"print(x_to_be_aug)","execution_count":40,"outputs":[]},{"metadata":{"_uuid":"6b92ef52a226a44356eb160ef3592716e0a07eb1","collapsed":true,"_cell_guid":"c5509e9a-a9cc-416b-97e9-b0c6a2095900","trusted":true},"cell_type":"code","source":"def plotImages( images_arr, n_images=4):\n    fig, axes = plt.subplots(n_images, n_images, figsize=(12,12))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        if img.ndim != 2:\n            img = img.reshape( (SIZE,SIZE))\n        ax.imshow( img, cmap=\"Greys_r\")\n        ax.set_xticks(())\n        ax.set_yticks(())\n    plt.tight_layout()","execution_count":41,"outputs":[]},{"metadata":{"_uuid":"0d18b55e0c63d6e3df48a972ff22960b922d5ce9","_cell_guid":"86af5ec2-ba5f-4a1a-bf29-16f0b93e360b","trusted":true},"cell_type":"code","source":"x_to_be_aug = x_to_be_aug.reshape( (-1,SIZE,SIZE,1))\nprint(x_to_be_aug.shape)","execution_count":42,"outputs":[]},{"metadata":{"_uuid":"b7a2374abdb1f295fabdd70a965783dc04c6560a","collapsed":true,"_cell_guid":"f0c6891c-45da-4959-846e-9f37f3496411","trusted":true},"cell_type":"code","source":"image_gen = ImageDataGenerator(\n    #featurewise_center=True,\n    #featurewise_std_normalization=True,\n    rescale=1./255,\n    rotation_range=15,\n    width_shift_range=.15,\n    height_shift_range=.15,\n    horizontal_flip=True)\n\n","execution_count":43,"outputs":[]},{"metadata":{"_uuid":"57caae314d6945741cddb46f80d70cf25e1ff17e","_cell_guid":"d34b022a-984b-474f-b779-61be55f7bfc7","trusted":true},"cell_type":"code","source":"image_gen.fit(x_to_be_aug, augment=True)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"acfcdd95f83e4d1a7d3d9eaae3938589bfb53370","_cell_guid":"dd02407a-01ab-4ad3-abd9-b7d496c67385","trusted":true},"cell_type":"code","source":"print(x_to_be_aug)","execution_count":45,"outputs":[]},{"metadata":{"_uuid":"4851609f8036a98b68ea385f0b97c316fbec2e3e","_cell_guid":"af4d3928-ff53-4d52-8968-dedc72f94a47","trusted":true},"cell_type":"code","source":"new_aug_img = []\nfor i in x_to_be_aug:\n    for _ in range(5):\n        img = augmentation_pipeline(i)\n        new_aug_img.append(img)","execution_count":46,"outputs":[]},{"metadata":{"_uuid":"d38de2031b297f6b7b8fc039e6374545002cec18","_cell_guid":"54117fc8-43a8-4f0a-8d1e-e30af3e8216c","trusted":true},"cell_type":"code","source":"new_aug_img = np.asarray(new_aug_img)\nprint(new_aug_img.shape)","execution_count":47,"outputs":[]},{"metadata":{"_uuid":"92c5c9a40fceb68c961566e98faeec575f39220e","_cell_guid":"8b27c592-6ed1-4d00-8ac9-72d157973605","trusted":true},"cell_type":"code","source":"print(label)","execution_count":48,"outputs":[]},{"metadata":{"_uuid":"045c73cc3d3748a24793f76f28658b8f9194c046","collapsed":true,"_cell_guid":"dc066487-0241-4a30-8d6d-7d9e62407622","trusted":true},"cell_type":"code","source":"label_new = []\nfor i in label:\n    for _ in range(5):\n        label_new.append(i)\n        ","execution_count":49,"outputs":[]},{"metadata":{"_uuid":"a395598d054959704874819bc2ccd8ca3aa9d80a","_cell_guid":"301ac998-6763-4c11-8151-ababc41ab564","trusted":true},"cell_type":"code","source":"label_new = np.asarray(label_new)\nprint(label_new.shape)","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"13dbd2d4a67943c4ad0fc19c113b66ab303ebddd","collapsed":true,"_cell_guid":"7cbee880-c5e8-4cd5-9309-4aaa709e2e14","trusted":true},"cell_type":"code","source":"train_img = np.array([ImportImage( img) for img in train_images])\nx = train_img","execution_count":51,"outputs":[]},{"metadata":{"_uuid":"8ac0ba691a15f65dce7919278c2277e12693c046","_cell_guid":"ca730ee5-8418-4f00-ad2f-0f2808449833","trusted":true},"cell_type":"code","source":"x = x.reshape( (-1,SIZE,SIZE,1))\ninput_shape = x[0].shape\nx_train = x.astype(\"float32\")\nprint(input_shape)","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"fd4aa0da3ddaf809f7d2f1528e56b99058b4bea5","_cell_guid":"da7f5c74-c44f-4b12-ad70-7f2bba4d1f92","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/train.csv\")\nprint(data[\"Id\"])","execution_count":53,"outputs":[]},{"metadata":{"_uuid":"67cbc2c81064fd05d175bd2f9cc001fc56d39d9c","_cell_guid":"b2aca2c7-2d9c-4375-8061-e67ac0aa93ab","trusted":true},"cell_type":"code","source":"y_train = data[\"Id\"]\nprint(y_train)","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"f8e733af6701f00143083e197a14575805b388de","collapsed":true,"_cell_guid":"3dac29ce-d450-4492-832a-75ccd4c71c83","trusted":true},"cell_type":"code","source":"y_train = np.asarray(y_train)\ny_train = np.concatenate((y_train , label_new) , axis = 0)","execution_count":55,"outputs":[]},{"metadata":{"_uuid":"bb5541023b66d8af8f535fe56b937e62fe98622e","_cell_guid":"50fbb253-5e50-49d2-8cb8-9f49b692238e","trusted":true},"cell_type":"code","source":"y_train = np.reshape(y_train , (9900 , 1))\nprint(y_train.shape)\ny_train = pd.DataFrame(y_train)\ny_train = pd.get_dummies(y_train)","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"c338ff631cc7b3e2e69435ae4da81cb3456ebc3b","_cell_guid":"4a013185-ab4e-4ec9-aca1-bdce9fd71ba4","trusted":true},"cell_type":"code","source":"y_train = np.asarray(y_train)\nprint(y_train.shape)\nprint(x_train.shape)","execution_count":57,"outputs":[]},{"metadata":{"_uuid":"dfa120257af717a6dc09ab7ca09f3bf29370efcd","_cell_guid":"e52d77f2-ce2c-4c9b-92b0-fc53a0bb6907","trusted":true},"cell_type":"code","source":"x_train = np.concatenate((x_train , new_aug_img) , axis = 0)\nprint(x_train.shape)","execution_count":58,"outputs":[]},{"metadata":{"_uuid":"b0c744cb681f96ab1334512c9d522f01c156f170","_cell_guid":"d609490e-e71a-46d2-818a-0389de708aec","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(48, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=input_shape))\nmodel.add(Conv2D(48, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(48, (5, 5), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.33))\nmodel.add(Flatten())\nmodel.add(Dense(36, activation='relu'))\nmodel.add(Dropout(0.33))\nmodel.add(Dense(36, activation='relu'))\nmodel.add(Dense(4251, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adam(),\n              metrics=['accuracy'])\nmodel.fit(x_train , y_train , batch_size = 128 , epochs = 10 , validation_split=0.2)","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"5222fdb4100ed932ef40c214ce44c35955506d6e","_cell_guid":"bb16a4d9-4c20-4332-933a-64cdf88a2e6e","trusted":true},"cell_type":"code","source":"print(model.summary())","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f0c7f33d96a80274215c331bbf19bd22d7a953ba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}