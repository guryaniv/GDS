{"nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "663762d0acd501a442290010ddc25eaea219ff13", "_cell_guid": "ecf01439-91f9-40c2-90ca-cfc9fef897f9"}, "source": ["Based on [olivier's script](https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "dbd332f83c89108c4e641218f5c4e7b9cd325b80", "collapsed": true, "_cell_guid": "45ba73d4-6c4c-40bb-9390-7dfc956c555d"}, "execution_count": null, "source": ["MAX_ROUNDS = 400\n", "OPTIMIZE_ROUNDS = False\n", "LEARNING_RATE = 0.07\n", "EARLY_STOPPING_ROUNDS = 50  \n", "# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n", "#       I will get lots of information to make my own judgment.  You should probably\n", "#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."]}, {"cell_type": "markdown", "metadata": {"_uuid": "b277fe426336d65ac71f0e6ac96c7ee16d02074c", "_cell_guid": "7e199c98-16b0-45e7-a6d1-bdd9325c2631"}, "source": ["I recommend initially setting <code>MAX_ROUNDS</code> fairly high and using <code>OPTIMIZE_ROUNDS</code> to get an idea of the appropriate number of rounds (which, in my judgment, should be close to the maximum value of  <code>best_ntree_limit</code> among all folds, maybe even a bit higher if your model is adequately regularized...or alternatively, you could set <code>verbose=True</code> and look at the details to try to find a number of rounds that works well for all folds).  Then I would turn off <code>OPTIMIZE_ROUNDS</code> and set <code>MAX_ROUNDS</code> to the appropraite number of total rounds.  \n", "\n", "The problem with \"early stopping\" by choosing the best round for each fold is that it overfits to the validation data.    It's therefore liable not to produce the optimal model for predicting test data, and if it's used to produce validation data for stacking/ensembling with other models, it would cause this one to have too much weight in the ensemble.  Another possibility (and the default for XGBoost, it seems) is to use the round where the early stop actually happens (with the lag that verifies lack of improvement) rather than the best round.  That solves the overfitting problem (provided the lag is long enough), but so far it doesn't seem to have helped.  (I got a worse validation score with 20-round early stopping per fold than with a constant number of rounds for all folds, so the early stopping actually seemed to underfit.)\n"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "72171ee53e170096d37a18eef84682fa348ae5c4", "collapsed": true, "_cell_guid": "b7258128-55f9-4543-8611-5e0a6661837b"}, "execution_count": null, "source": ["import numpy as np\n", "import pandas as pd\n", "from xgboost import XGBClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold\n", "from sklearn.preprocessing import LabelEncoder\n", "from numba import jit\n", "import time\n", "import gc"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "154b078a7e86c0a5a328118a61d28e2581bb3b0a", "collapsed": true, "_cell_guid": "3d16f16e-12cc-4b41-b7bd-fa05ce44770c"}, "execution_count": null, "source": ["# Compute gini\n", "\n", "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n", "@jit\n", "def eval_gini(y_true, y_prob):\n", "    y_true = np.asarray(y_true)\n", "    y_true = y_true[np.argsort(y_prob)]\n", "    ntrue = 0\n", "    gini = 0\n", "    delta = 0\n", "    n = len(y_true)\n", "    for i in range(n-1, -1, -1):\n", "        y_i = y_true[i]\n", "        ntrue += y_i\n", "        gini += y_i * delta\n", "        delta += 1 - y_i\n", "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n", "    return gini"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "67a8ca9dead7110c776d7f75bb8963b3429617cb", "collapsed": true, "_cell_guid": "99b88ea4-a9af-45aa-9df0-86412d7264cf"}, "execution_count": null, "source": ["# Funcitons from olivier's kernel\n", "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n", "\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = -eval_gini(labels, preds)\n", "    return [('gini', gini_score)]\n", "\n", "\n", "def add_noise(series, noise_level):\n", "    return series * (1 + noise_level * np.random.randn(len(series)))\n", "\n", "\n", "def target_encode(trn_series=None,    # Revised to encode validation series\n", "                  val_series=None,\n", "                  tst_series=None,\n", "                  target=None,\n", "                  min_samples_leaf=1,\n", "                  smoothing=1,\n", "                  noise_level=0):\n", "    \"\"\"\n", "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n", "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n", "    trn_series : training categorical feature as a pd.Series\n", "    tst_series : test categorical feature as a pd.Series\n", "    target : target data as a pd.Series\n", "    min_samples_leaf (int) : minimum samples to take category average into account\n", "    smoothing (int) : smoothing effect to balance categorical average vs prior\n", "    \"\"\"\n", "    assert len(trn_series) == len(target)\n", "    assert trn_series.name == tst_series.name\n", "    temp = pd.concat([trn_series, target], axis=1)\n", "    # Compute target mean\n", "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n", "    # Compute smoothing\n", "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n", "    # Apply average function to all target data\n", "    prior = target.mean()\n", "    # The bigger the count the less full_avg is taken into account\n", "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n", "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n", "    # Apply averages to trn and tst series\n", "    ft_trn_series = pd.merge(\n", "        trn_series.to_frame(trn_series.name),\n", "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n", "        on=trn_series.name,\n", "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n", "    # pd.merge does not keep the index so restore it\n", "    ft_trn_series.index = trn_series.index\n", "    ft_val_series = pd.merge(\n", "        val_series.to_frame(val_series.name),\n", "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n", "        on=val_series.name,\n", "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n", "    # pd.merge does not keep the index so restore it\n", "    ft_val_series.index = val_series.index\n", "    ft_tst_series = pd.merge(\n", "        tst_series.to_frame(tst_series.name),\n", "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n", "        on=tst_series.name,\n", "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n", "    # pd.merge does not keep the index so restore it\n", "    ft_tst_series.index = tst_series.index\n", "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "07a5a5782894611e9006ae1b399b0b8fb8a0f06b", "collapsed": true, "_cell_guid": "52b50086-b405-4598-b11c-97887cdcce8e"}, "execution_count": null, "source": ["# Read data\n", "train_df = pd.read_csv('../input/train.csv', na_values=\"-1\") # .iloc[0:200,:]\n", "test_df = pd.read_csv('../input/test.csv', na_values=\"-1\")"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "2ac19052e2f2c14d79962af5e5a8ee3d54a28695", "collapsed": true, "_cell_guid": "b9e041d2-18fb-4a8a-8bb4-577e8993189b"}, "execution_count": null, "source": ["# from olivier\n", "train_features = [\n", "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n", "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n", "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n", "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n", "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n", "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n", "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n", "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n", "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n", "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n", "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n", "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n", "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n", "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n", "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n", "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n", "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n", "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n", "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n", "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n", "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n", "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n", "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n", "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n", "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n", "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n", "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n", "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n", "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n", "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n", "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n", "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n", "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n", "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n", "]\n", "# add combinations\n", "combs = [\n", "    ('ps_reg_01', 'ps_car_02_cat'),  \n", "    ('ps_reg_01', 'ps_car_04_cat'),\n", "]"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "da09aaf7c0c77a131c7d9d53feae512c8f9730c1", "collapsed": true, "_cell_guid": "d9a217fa-50f4-43a7-805b-d1c796a7ebf7"}, "execution_count": null, "source": ["# Process data\n", "id_test = test_df['id'].values\n", "id_train = train_df['id'].values\n", "y = train_df['target']\n", "\n", "start = time.time()\n", "for n_c, (f1, f2) in enumerate(combs):\n", "    name1 = f1 + \"_plus_\" + f2\n", "    print('current feature %60s %4d in %5.1f'\n", "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n", "    print('\\r' * 75, end='')\n", "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n", "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n", "    # Label Encode\n", "    lbl = LabelEncoder()\n", "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n", "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n", "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n", "\n", "    train_features.append(name1)\n", "    \n", "X = train_df[train_features]\n", "test_df = test_df[train_features]\n", "\n", "f_cats = [f for f in X.columns if \"_cat\" in f]\n"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "6255e3c12616b0279cef5c1bdec97751bb72d8b8", "collapsed": true, "_cell_guid": "1b36eb15-ee01-43a3-8766-27650f98158d"}, "execution_count": null, "source": ["y_valid_pred = 0*y\n", "y_test_pred = 0"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "6aa7ada2193c2e4b8a63eebda925cee5023b45b0", "collapsed": true, "_cell_guid": "7c6e4823-4e8c-4408-b961-576d469e9241"}, "execution_count": null, "source": ["# Set up folds\n", "K = 5\n", "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n", "np.random.seed(0)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "581c3f15f294378a0e2ac3305e9e3d375f664b21", "collapsed": true, "_cell_guid": "5d8108f3-e9e8-45d6-93b5-740eb7b4b10b"}, "execution_count": null, "source": ["# Set up classifier\n", "model = XGBClassifier(    \n", "                        n_estimators=MAX_ROUNDS,\n", "                        max_depth=4,\n", "                        objective=\"binary:logistic\",\n", "                        learning_rate=LEARNING_RATE, \n", "                        subsample=.8,\n", "                        min_child_weight=6,\n", "                        colsample_bytree=.8,\n", "                        scale_pos_weight=1.6,\n", "                        gamma=10,\n", "                        reg_alpha=8,\n", "                        reg_lambda=1.3,\n", "                     )"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "2b9ed96c98b705d3e4bf2a3d60323dfab4332674", "scrolled": true, "collapsed": true, "_cell_guid": "c4e48347-920f-4ba7-8b37-cfbaab4c3c00"}, "execution_count": null, "source": ["# Run CV\n", "\n", "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n", "    \n", "    # Create data for this fold\n", "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n", "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n", "    X_test = test_df.copy()\n", "    print( \"\\nFold \", i)\n", "    \n", "    # Enocode data\n", "    for f in f_cats:\n", "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n", "                                                        trn_series=X_train[f],\n", "                                                        val_series=X_valid[f],\n", "                                                        tst_series=X_test[f],\n", "                                                        target=y_train,\n", "                                                        min_samples_leaf=200,\n", "                                                        smoothing=10,\n", "                                                        noise_level=0\n", "                                                        )\n", "    # Run model for this fold\n", "    if OPTIMIZE_ROUNDS:\n", "        eval_set=[(X_valid,y_valid)]\n", "        fit_model = model.fit( X_train, y_train, \n", "                               eval_set=eval_set,\n", "                               eval_metric=gini_xgb,\n", "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n", "                               verbose=False\n", "                             )\n", "        print( \"  Best N trees = \", model.best_ntree_limit )\n", "        print( \"  Best gini = \", model.best_score )\n", "    else:\n", "        fit_model = model.fit( X_train, y_train )\n", "        \n", "    # Generate validation predictions for this fold\n", "    pred = fit_model.predict_proba(X_valid)[:,1]\n", "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n", "    y_valid_pred.iloc[test_index] = pred\n", "    \n", "    # Accumulate test set predictions\n", "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n", "    \n", "    del X_test, X_train, X_valid, y_train\n", "    \n", "y_test_pred /= K  # Average test set predictions\n", "\n", "print( \"\\nGini for full training set:\" )\n", "eval_gini(y, y_valid_pred)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "e61bf4e22c1c29c8358caeecb6e67d6658f2005d", "collapsed": true, "_cell_guid": "0e3dfd76-c566-4b8d-a460-b56e964d0772"}, "execution_count": null, "source": ["# Save validation predictions for stacking/ensembling\n", "val = pd.DataFrame()\n", "val['id'] = id_train\n", "val['target'] = y_valid_pred.values\n", "val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"]}, {"outputs": [], "cell_type": "code", "metadata": {"_uuid": "380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1", "collapsed": true, "_cell_guid": "f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5"}, "execution_count": null, "source": ["# Create submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = id_test\n", "sub['target'] = y_test_pred\n", "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "5401495c2c34ef736c761573c70d7e3b4efa3a5b", "_cell_guid": "77516718-78a9-4043-8b4b-0b04276e4345"}, "source": ["Notes:<br>\n", "version 16. Baseline best CV=.2832, LB=.282<br>\n", "version 15. Ntree optimization for baseline<br>\n", "version 21. Verbose version of baseline optimization<br>\n", "version 22. Baseline + per-fold early stopping after 20 rounds<br>\n", "version 23. Back to baseline.<br>\n", "version 24. Some parameter tuning.<br>\n", "version 25. Re-published to make it visible.<br>\n", "version 26. A little more tuning.<br>\n", "version 27: More tuning, get rid of upsampling (using  **<code>scale_pos_weight</code>** instead),<br>\n", "                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n", "                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n", "                    Set <code>OPTIMIZE_ROUNDS</code> and <code>verbose</code> temporarily<br>\n", "version 28: <code>MAX_ROUNDS=300</code> as a compromise<br>\n", "version 29: Substantively identical. (Turn off now-irrelevant <code>verbose</code>.)<br>\n", "version 30: Still substantively identical. Some visual cleanup.<br>\n", "version 35. More tuning. CV went up but LB sorts lower (still .283)<br>\n", "version 36. Identical (except turn off irrelevant <code>verbose</code>). Republished to make it visible.<br>\n", "versions 37-42. More tuning (gamma=10, alpha=8). LB .284 (\\*end zone dance\\*).<br>\n", "version 43. More tuning (min_child_weight=6).  LB score has considerably improved according to sort, but still .284"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true}, "execution_count": null, "source": []}], "metadata": {"language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "version": "3.6.3", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}