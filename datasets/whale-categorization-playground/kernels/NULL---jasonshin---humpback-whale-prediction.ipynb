{"nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "version": "3.6.4", "mimetype": "text/x-python"}}, "cells": [{"source": ["from collections import defaultdict\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "import pandas as pd\n", "import numpy as np\n", "import os\n", "import glob\n", "from sklearn.neighbors import NearestNeighbors\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.model_selection import train_test_split\n", "from keras import backend as K\n", "from keras.models import Model\n", "from keras.layers import Embedding, Flatten, Input, merge\n", "from keras.optimizers import Adam\n", "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n", "from keras.models import Model\n", "import glob\n", "import os\n", "from PIL import Image\n", "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n", "from keras import optimizers, losses, activations, models\n", "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n", "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n", "from keras.applications.resnet50 import ResNet50\n", "import pandas as pd\n", "import numpy as np\n", "import os\n", "import glob\n", "from sklearn.neighbors import NearestNeighbors\n", "import matplotlib.pyplot as plt\n", "import matplotlib.image as mpimg\n", "\n", "from sklearn.model_selection import train_test_split\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Convolution2D, MaxPooling2D, Flatten, Dropout\n", "from keras.losses import categorical_crossentropy\n", "from keras.optimizers import Adam\n", "from tqdm import tqdm"], "outputs": [], "metadata": {"_cell_guid": "60c25a40-ba1b-4b41-9e54-704125e07f34", "_uuid": "a6f154c5e53a700fbf626e69d73f80ed41266074", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["training_dir = '../input/train/'\n", "data = pd.read_csv('../input/train.csv')\n", "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n", "print('Checking training data head')\n", "print(train.head())\n", "print('Checking test data head')\n", "print(test.head())"], "outputs": [], "metadata": {"_cell_guid": "06d7e527-48ae-4fa2-9cbf-d20c6d38311f", "_uuid": "dfc428bdeb89ebf110c549f0661c23c522b21c63", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["sampleImageFile1 = train.Image[2]\n", "sampleImage = mpimg.imread(training_dir + sampleImageFile1)\n", "plt.imshow(sampleImage)\n", "plt.show()"], "outputs": [], "metadata": {"_cell_guid": "0b6b768b-fd75-4570-8518-2077d2f93b41", "_uuid": "6ac67882fe65c307e5b4a1dc792c1fbde6af0186", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["sampleImageFile2 = train.Image[89]\n", "sampleImage2 = mpimg.imread(training_dir + sampleImageFile2)\n", "plt.imshow(sampleImage2)"], "outputs": [], "metadata": {"_cell_guid": "7e6589ac-0289-4173-976f-ffe511227821", "_uuid": "2a3c40df923aa2ef1b2799e070aeebbfa0dd5af0", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["## Read training CSV\n", "\n", "1. Checking duplicate IDs"], "metadata": {"_cell_guid": "b311f2dc-4915-45f7-83fe-2228ae0c6682", "_uuid": "b9d3331cabf3aadab3f94a1403a198ba15d7fc06", "collapsed": true}, "cell_type": "markdown"}, {"source": ["vc = train.Id.value_counts().sort_values(ascending=False)\n", "vc[:50].plot(kind='bar')\n", "plt.show()"], "outputs": [], "metadata": {"_cell_guid": "d3dc1c72-6a67-48f8-a0ae-59f6e64a1ce2", "_uuid": "79725c45e2b9b7f7feffe3f6a890f8b2eca60c69", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# Train model"], "metadata": {"_cell_guid": "9954cf9c-e7b4-434b-8398-01019ce247ba", "_uuid": "82c1b5ab17f54fc633d5801dbbe4dd03cc6cc79b", "collapsed": true}, "cell_type": "markdown"}, {"source": ["# PARAMETERS\n", "# The parameters are not the final parameters and will be changed later.\n", "k_size = (4,4)\n", "drop_probability = 0.5\n", "hidden_size = 256\n", "batch_size = 64\n", "input_shape = (batch_size, 128, 128)\n", "pool_size = (2,2)\n", "learning_rate = 0.07\n", "num_of_epochs = 10\n", "num_of_classes = 4251"], "outputs": [], "metadata": {"_cell_guid": "69bb1219-28ad-45e4-ae9a-336790eac84b", "_uuid": "91d6f85da47d3578c08e96cd8df2a9cc89e85ff7", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# NETWORK\n", "model = Sequential()\n", "model.add(Convolution2D(32, kernel_size=k_size, activation=\"relu\", input_shape=input_shape))\n", "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n", "model.add(Convolution2D(64, kernel_size=k_size, activation=\"relu\"))\n", "model.add(MaxPooling2D(pool_size=pool_size, strides=(1,1)))\n", "model.add(Convolution2D(512, kernel_size=k_size, activation=\"relu\"))\n", "model.add(MaxPooling2D(pool_size=pool_size, strides=(2,2)))\n", "model.add(Flatten())\n", "model.add(Dense(1024, activation=\"relu\"))\n", "model.add(Dropout(0.25))\n", "model.add(Dense(512, activation=\"relu\"))\n", "model.add(Dense(32, activation=\"relu\"))\n", "model.add(Dropout(0.25))\n", "model.add(Dense(num_of_classes, activation=\"softmax\"))"], "outputs": [], "metadata": {"_cell_guid": "51f009f2-b074-4b5f-9b6f-a22ae4f3f142", "_uuid": "8a966516d4d07f908812d33a8510101f598c31f8", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# COST AND OPTIMIZER\n", "model.compile(loss=categorical_crossentropy,\n", "              optimizer=Adam(lr=0.01),\n", "              metrics=['accuracy'])"], "outputs": [], "metadata": {"_cell_guid": "89e1a8f5-a437-4518-894b-926b8cd3fc90", "_uuid": "30f3372ee3c92227500a575dd1cfcd2d4d6ef0e2", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# Data preparation and training"], "metadata": {"_cell_guid": "7558761d-d6d2-4949-a678-033744c5a93b", "_uuid": "8ed37157bbb3c2b20d3c27f44f8521e0fc6d4f9c"}, "cell_type": "markdown"}, {"source": ["def process(image):\n", "    # resize\n", "    image = np.resize(image, [128, 128])\n", "    \n", "    # convert to grayscale\n", "    if image.shape == 3:\n", "        image = np.dot([image[:,:,0],image[:,:,1],image[:,:,2]],[0.299,0.587,0.114])\n", "    \n", "    # return normalized\n", "    return image / 255\n", "    "], "outputs": [], "metadata": {"_cell_guid": "bf15ea61-4c12-42e0-a1c9-a1024383a4e3", "_uuid": "79b1591100e55d132902747bd591fc64a26ac4c0", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["# Convert target variable to a one hot coded value"], "metadata": {"_cell_guid": "a9e64efc-9acd-4108-87a0-db11a6f4c62c", "_uuid": "7fa77a96e3c4a4b260871b5557fd8e5cff3279d0"}, "cell_type": "markdown"}, {"source": ["x = []\n", "y = []"], "outputs": [], "metadata": {"_cell_guid": "49b6e159-5d4a-427d-b302-bec4a6fd4f8c", "_uuid": "7a64a341441ae6a0f3feae6eb7d6ad92ba6e64b3", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["for path in tqdm(train.Image):\n", "    image = mpimg.imread(training_dir + path)\n", "    image = process(image)\n", "    x.append(image)\n", "    \n", "    cod = 'Id_' + train[train.Image == path]['Id']\n", "    y.append(cod)\n"], "outputs": [], "metadata": {"_cell_guid": "94ecd7f0-687c-42c6-9de7-3f6f6fad623d", "_uuid": "9ae377c09d721dd480d5f02dd8e6aeca44453b1b", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["model.fit(np.array(x), np.array(y), batch_size=batch_size, epochs=num_of_epochs, verbose=1)"], "outputs": [], "metadata": {"_cell_guid": "6b7bba88-1a2c-4269-b19d-6f9389a9d76e", "_uuid": "aebac2454bc7a1e90e082b0042d979af2cef6bd9", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["test_preds = []\n", "test_file_names = []\n", "i = 1\n", "test_files = glob.glob(\"../input/test/*.jpg\")\n", "for fnames, imgs in data_generator(test_files, batch=32):\n", "    print(i * 32 / len(test_files) * 100)\n", "    i += 1\n", "    predicts = inference_model.predict(imgs)\n", "    predicts = predicts.tolist()\n", "    test_preds += predicts\n", "    test_file_names += fnames\n", "\n", "test_preds = np.array(test_preds)"], "outputs": [], "metadata": {"_cell_guid": "03b593cd-160f-4813-903c-4baf71470d3f", "_uuid": "10f48462e29a0dbfd3eabeee6f3a6b3baa902011", "collapsed": true}, "execution_count": null, "cell_type": "code"}]}