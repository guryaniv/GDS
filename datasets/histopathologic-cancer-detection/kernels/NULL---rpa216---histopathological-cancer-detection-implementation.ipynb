{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.layers import BatchNormalization\nfrom __future__ import absolute_import , division, print_function\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras import Sequential\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nimport itertools\n%matplotlib inline\nIMAGE_SIZE = 96\nIMAGE_CHANNELS = 3\nSAMPLE_SIZE = 50000","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3b37c3d24bb09e47955db9bdf6fcc669327e5c3"},"cell_type":"code","source":"print(len(os.listdir('../input/train')))\nprint(len(os.listdir('../input/test')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2e45a894652c40b84d4164f72ec133778be1d3d"},"cell_type":"markdown","source":"Let me read the data into a dataframe"},{"metadata":{"trusted":true,"_uuid":"4c0e671ec9a762afb29f03f8df49c8a44874a0de"},"cell_type":"code","source":"train_data  = pd.read_csv('../input/train_labels.csv')\nprint(train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb89852e4f0735a1054dfaf89f1449aa09feade6"},"cell_type":"code","source":"train_data['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d8d6d1930a07195e5bf02b7aff3ea0a48df8e2"},"cell_type":"code","source":"#Image location is available\nimport random\nIMAGE_LOCATION = '../input/train/'\n# #reading images\nfile = IMAGE_LOCATION + train_data['id'].iloc[1002] + '.tif'\nim = cv2.imread(file)\nprint(im.shape)\nplt.imshow(im)\nplt.show()\ndef draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n    categories = (df.groupby([col_name])[col_name].nunique()).index\n    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n                             figsize=(4*figure_cols,4*len(categories))) # adjust size here\n        # draw a number of images for each location\n    for i, cat in enumerate(categories):\n        sample = df[df[col_name]==cat].sample(figure_cols) # figure_cols is also the sample size\n        for j in range(0,figure_cols):\n            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n            im=cv2.imread(file)\n            print(im.shape)\n            ax[i, j].imshow(im, resample=True, cmap='gray')\n            ax[i, j].set_title(cat, fontsize=16)  \n    plt.tight_layout()\n    plt.show()\n\ndef get_me_data(IMAGE_LOCATION, train_data):\n    build_data = []\n    train_id = train_data['id'].tolist()\n    train_id = np.array(train_id)\n    random_values = np.random.choice(np.arange(len(train_id)), size=SAMPLE_SIZE)\n    train_id = train_id[random_values]\n    \n    for i in range(len(train_id)):\n        file = IMAGE_LOCATION + train_id[i] + '.tif'\n        build_data.append(cv2.imread(file))\n    return(build_data, random_values)\ntrain_images, random_values = get_me_data(IMAGE_LOCATION, train_data)\ntrain_label = train_data['label'].tolist()\ntrain_label = np.array(train_label)\ntrain_label = train_label[random_values]\n# train_\n# draw_category_images('label', 4, train_data, IMAGE_LOCATION)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de09441b51dc9ae875b9d6537c07911f2de05187"},"cell_type":"code","source":"\"\"\" get the test data\"\"\"\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_images, train_label, test_size = .35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b072b708c2eb7b27c9ba31ec4eaa772e7c8ab4a6"},"cell_type":"code","source":"(130908)/(130908+89117)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b96d67d6e777a4b2098eb63bdf0cb4e9dbd2bdde"},"cell_type":"code","source":"X_train = np.array(X_train)\nprint(X_train.shape)\nX_test = np.array(X_test)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fc539206923a4260d05c446ef62ef5fd760be1a"},"cell_type":"code","source":"#Building a simple Convolutional Neural Network classifier\n#Model\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.layers import Activation, Dropout, Flatten, Dense\nfrom keras import backend as K\n\nmodel = Sequential()\nmodel.add(Conv2D(64, (3, 3), input_shape=(96, 96, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(Dense(256, activation=\"relu\"))\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\nmodel.summary()\nmodel.fit(X_train, y_train, epochs=50, batch_size = 512, shuffle=True, validation_data=(X_test, y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f68206d001ae20ada415056efb8d1ab0a9ce9aee"},"cell_type":"code","source":"y_train[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62ea9d424e9c75e9edb3dfa89e1ba0205c3c4eeb","scrolled":true},"cell_type":"markdown","source":"##### random_samples = np.random.choice(np.arange(len(X_train)), )"},{"metadata":{"trusted":true,"_uuid":"36ba61d99fdab66de26ab2151ce7178adf2fbf82"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}