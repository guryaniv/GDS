{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "efd5feb5-8262-1b45-af15-0dd16116052b",
        "_active": false
      },
      "source": "The kernel is based on the Candidate Generation one with a few modifications and parts that have been rewritten to work a little bit better.",
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ceec3ade-181c-4059-e0f2-958a1f7629af",
        "_active": false
      },
      "source": "**Reading a CT Scan**\n-----------------\nThe input folder has three things, one is the sample_images folders which has the sample CT Scans. The `stage1_labels.csv` contains the cancer ground truth for the stage 1 training set images and `stage1_sample_submission.csv` shows the submission format for stage 1. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "53553842-54eb-d04d-1f5a-fd0c08472863",
        "_active": false
      },
      "outputs": [],
      "source": "import numpy as np # linear algebra\nimport pandas as pd # reading and processing of tables\nimport skimage, os\nfrom skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\nfrom skimage.measure import label,regionprops, perimeter\nfrom skimage.morphology import binary_dilation, binary_opening\nfrom skimage.filters import roberts, sobel\nfrom skimage import measure, feature\nfrom skimage.segmentation import clear_border\nfrom skimage.util.montage import montage2d\nfrom scipy import ndimage as ndi\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\nimport dicom\nimport scipy.misc\nCT_OFFSET = 1024\nZERO_VALUE = -2000",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "4e8bb7fb-0e42-f1f1-bd87-8ad1420f45db",
        "_active": false
      },
      "outputs": [],
      "source": "# we want to crop out the regions we dont need first\ndef _dsum(carr,  # type: np.ndarray\n          cax  # type: int\n          ):\n    # type: (np.ndarray, int) -> np.ndarray\n    return np.sum(carr, tuple(n for n in range(carr.ndim) if n is not cax))\n\ndef get_bbox(in_vol,\n             min_val=0):\n    # type: (np.ndarray, float) -> List[Tuple[int,int]]\n    ax_slice = []\n    for i in range(in_vol.ndim):\n        c_dim_sum = _dsum(in_vol > min_val, i)\n        wh_idx = np.where(c_dim_sum)[0]\n        c_sl = sorted(wh_idx)\n        if len(wh_idx) == 0:\n            ax_slice += [(0, 0)]\n        else:\n            ax_slice += [(c_sl[0], c_sl[-1] + 1)]\n    return ax_slice\n\ndef apply_bbox(in_vol,  # type: np.ndarray\n               bbox_list,  # type: List[Tuple[int,int]]\n               pad_values = False,\n               padding_mode = 'edge'\n               ):\n    return in_vol.__getitem__([slice(a, b, 1) for (a, b) in bbox_list])\n\ndef autocrop(in_vol,  # type: np.ndarray\n             min_val  # type: double\n             ):\n    return apply_bbox(in_vol, get_bbox(in_vol,\n                                       min_val=min_val))",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "13bdd5df-5f74-f085-e590-57c135ccd704",
        "_active": false
      },
      "source": "Each 3D CT Scan consists of many slices, whose number depends on the resolution of the scanner and each slice has a Instance Number associated with it which tells the index of the slice from the top. All the dicom files for a CT Scan are inside one folder having the CT Scan's name. Now we will read all the dicom slices for a scan and then stack them with respect to their Instance Number to get the 3D Lung CT Scanned Image.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_cell_guid": "f39d03ea-cbb7-0d39-e5dc-e4265b85a5d6",
        "_active": false
      },
      "outputs": [],
      "source": "image_tags_df = pd.read_csv('../input/stage1_labels.csv')\nimage_tags_df.sample(3)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bfe2dd1f-6061-b2dd-94a5-559a70d09f5b",
        "_active": false
      },
      "source": "Each CT Scan consists of multiple 2D slices which are provided in a DICOM format. At first, I will read the random dicom file of a CT Scan. After reading the image file, we will update the intensity values of -2000 with 0 because they are the pixels that fall outside of the scanner bounds.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "_cell_guid": "a4a6a3e0-5766-9421-5a9f-d9237773f860",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "# Read an image and the image path\ndef read_dicom_array(in_path):\n    # type: (str) -> Tuple[int, np.ndarray]\n    lung_dicom = dicom.read_file(in_path)\n    slice_array = lung_dicom.pixel_array\n    slice_array[slice_array == -2000] = 0\n    return int(lung_dicom.InstanceNumber), slice_array.astype(np.int16) - CT_OFFSET\n_, slice_arr = read_dicom_array('../input/sample_images/00cba091fa4ad62cc3200a657aeb957e/38c4ff5d36b5a6b6dc025435d62a143d.dcm')\n\nc_img_ax = plt.imshow(slice_arr, cmap=plt.cm.bone)\nplt.colorbar(c_img_ax)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_cell_guid": "740a14d6-edc1-cfbd-c31c-6a378a5d71be",
        "_active": false
      },
      "outputs": [],
      "source": "def read_ct_scan(folder_name):\n        # Read the slices from the dicom file\n        slices = [read_dicom_array(folder_name + filename) for filename in os.listdir(folder_name)]\n        \n        # Sort the dicom slices in their respective order\n        s_slices = sorted(slices, key = lambda x: x[0])\n        \n        # Get the pixel values for all the slices\n        slices = np.stack([data for pos, data in s_slices])\n        return slices",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_cell_guid": "9b923da3-6985-27f1-0cef-f8c6dd0434ad",
        "_active": false
      },
      "outputs": [],
      "source": "ct_scan = read_ct_scan('../input/sample_images/00cba091fa4ad62cc3200a657aeb957e/') \nprint('Scan Dimensions',ct_scan.shape)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8db1af50-854f-da03-3c03-7782b7fd39d9",
        "_active": false
      },
      "source": "To visualise the slices, we will have to plot them. `matplotlib` is used for plotting the slices. The `plot_ct_scan` function takes a 3D CT Scanned Image array  as input and plots equally spaced slices. The CT Scans are grayscale images i.e. the value of each pixel is a single sample, which means it carries only intensity information.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "43b4d7bc-66d8-b12a-47e4-d391e998f796",
        "_active": false
      },
      "outputs": [],
      "source": "def plot_ct_scan(scan):\n    \"\"\"\n    show all the slices the ct as a montage\n    \"\"\"\n    f, ax1 = plt.subplots(1,1, figsize=(12, 12))\n    ax1.imshow(montage2d(scan), cmap=plt.cm.bone) \n    ax1.axis('off')",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "_cell_guid": "0f3389c1-65b9-8af3-edc8-6aa38b1e6498",
        "_active": false
      },
      "outputs": [],
      "source": "plot_ct_scan(ct_scan)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4118db22-f1d7-304a-a58f-0f8aaca8311a",
        "_active": false
      },
      "source": "## Segmentation of Lungs\nAfter reading the CT Scan, the first step in preprocessing is the segmentation of lung structures because it is obvious that the regions of interests lies inside the lungs. It is visible that the lungs are the darker regions in the CT Scans. The bright region inside the lungs are the blood vessels or air. A threshold of (-400 HU) is used at all places because it was found in experiments that it works just fine. We segment lung structures from each slice of the CT Scan image and try not to loose the possible region of interests attached to the lung wall. There are some nodules which may be attached to the lung wall.\n\nI will first explain a common method using simple Image Processing and Morphological operations to segment the lungs and then will give references and summaries to good links of papers. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "_cell_guid": "3fc2eca2-e580-e66e-561b-d1812e829897",
        "_active": false
      },
      "outputs": [],
      "source": "def get_segmented_lungs(in_im, plot=False):\n    im = in_im.copy() # don't change the input\n    '''\n    This funtion segments the lungs from the given 2D slice.\n    '''\n    if plot == True:\n        f, plots = plt.subplots(3, 3, figsize=(10, 10))\n        plots = plots.flatten()\n    '''\n    Step 1: Convert into a binary image. \n    '''\n    binary = im < -400\n    if plot == True:\n        plots[0].axis('off')\n        plots[0].imshow(binary, cmap=plt.cm.bone) \n        plots[0].set_title('First Threshold')\n    '''\n    Step 2: Remove the blobs connected to the border of the image.\n    '''\n    cleared = clear_border(binary)\n    if plot == True:\n        plots[1].axis('off')\n        plots[1].imshow(cleared, cmap=plt.cm.bone) \n        plots[1].set_title('Remove Border')\n    '''\n    Step 3: Label the image.\n    '''\n    label_image = label(cleared)\n    if plot == True:\n        plots[2].axis('off')\n        plots[2].imshow(label_image, cmap=plt.cm.gist_earth)\n        plots[2].set_title('Label Components')\n    '''\n    Step 4: Keep the labels with 2 largest areas.\n    '''\n    areas = [r.area for r in regionprops(label_image)]\n    areas.sort()\n    if len(areas) > 2:\n        for region in regionprops(label_image):\n            if region.area < areas[-2]:\n                for coordinates in region.coords:                \n                       label_image[coordinates[0], coordinates[1]] = 0\n    binary = label_image > 0\n    if plot == True:\n        plots[3].axis('off')\n        plots[3].imshow(binary, cmap=plt.cm.bone) \n        plots[3].set_title('Keep Biggest 2')\n    '''\n    Step 5: Erosion operation with a disk of radius 2. This operation is \n    seperate the lung nodules attached to the blood vessels.\n    '''\n    selem = disk(2)\n    binary = binary_erosion(binary, selem)\n    if plot == True:\n        plots[4].axis('off')\n        plots[4].imshow(binary, cmap=plt.cm.bone)\n        plots[4].set_title('Erosion')\n    '''\n    Step 6: Closure operation with a disk of radius 10. This operation is \n    to keep nodules attached to the lung wall.\n    '''\n    selem = disk(10)\n    binary = binary_closing(binary, selem)\n    if plot == True:\n        plots[5].axis('off')\n        plots[5].imshow(binary, cmap=plt.cm.bone) \n        plots[5].set_title('Close Image')\n    '''\n    Step 7: Fill in the small holes inside the binary mask of lungs.\n    '''\n    edges = roberts(binary)\n    binary = ndi.binary_fill_holes(edges)\n    if plot == True:\n        plots[6].axis('off')\n        plots[6].imshow(binary, cmap=plt.cm.bone) \n        plots[6].set_title('Fill holes')\n    '''\n    Step 8: Superimpose the binary mask on the input image.\n    '''\n    get_high_vals = (binary == 0)\n    im[get_high_vals] = ZERO_VALUE # minimum value\n    if plot == True:\n        plots[7].axis('off')\n        plots[7].imshow(im, cmap=plt.cm.bone) \n        plots[7].set_title('Binary Masked Input')\n        \n    return im",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8d027175-ccd6-aa1d-ca26-fa70857ea9aa",
        "_active": false
      },
      "source": "The `get_segmented_lungs` function segments a 2D slice of the CT Scan. I have outputted the slice after all steps for better visualisation and understanding of the code and applied operations.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "_cell_guid": "0b95efee-2a29-f0c6-3728-4f4425123573",
        "_active": false
      },
      "outputs": [],
      "source": "get_segmented_lungs(ct_scan[71], True)",
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ffb87321-c5fc-c04d-2559-b2b2b27d9066",
        "_active": false
      },
      "source": "Now, I will segment the whole CT Scan slice by slice and show some slices of the CT Scan.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "_cell_guid": "b3048b12-2ee0-d144-a742-014998bb0458",
        "_active": false
      },
      "outputs": [],
      "source": "def segment_lung_from_ct_scan(ct_scan):\n    return np.stack([get_segmented_lungs(c_slice) for c_slice in ct_scan], 0)",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "_cell_guid": "75f42d28-320f-eeb9-5347-9049e8dcf85c",
        "_active": false
      },
      "outputs": [],
      "source": "segmented_ct_scan = segment_lung_from_ct_scan(ct_scan)\nplot_ct_scan(segmented_ct_scan)",
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "bfc20b76-1499-fa3a-35ee-01f8606176ac",
        "_active": false,
        "collapsed": false
      },
      "source": "# Super Pixel Generation\nHere we generate superpixels for the regions the lungs",
      "execution_count": 15,
      "cell_type": "markdown",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "c8d7b26e-ddb6-3a72-2103-dcf72f817766",
        "_active": false,
        "collapsed": false
      },
      "source": "# Renormalize Image\nmean_val = ct_proj[n_ct_img>ZERO_VALUE].mean()\nsd_val = ct_proj[n_ct_img>ZERO_VALUE].std()\nprint(mean_val, sd_val)\nn_ct_img = (ct_proj-mean_val)/(3*sd_val)\nn_ct_img = (n_ct_img+0.1).clip(0,1)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8, 4))\nax1.imshow(n_ct_img, vmin = 0, vmax = 1, cmap = 'bone')\nax1.set_title('Rescaled Image')\n_ = ax2.hist(n_ct_img.flatten(), np.linspace(0,1,30))\nax2.set_title('Histogram')",
      "execution_count": 56,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "3581465f-384a-3202-f183-b2af46e103f9",
        "_active": false,
        "collapsed": false
      },
      "source": "from skimage.segmentation import slic\nfrom skimage.segmentation import mark_boundaries\nct_proj = segmented_ct_scan[74]\nfig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (15, 10))\n\nct_segs = slic(n_ct_img, \n               n_segments = 200, \n               compactness = 0.02)\n\nax1.imshow(ct_proj, cmap = 'bone')\nax1.set_title('CT Image')\n\nct_segs[ct_proj==ZERO_VALUE] = 0\nax2.imshow(ct_segs, cmap = plt.cm.RdBu)\nax2.set_title('Segmented Image')\n\nax3.imshow(mark_boundaries(n_ct_img, ct_segs))\nax3.set_title('Visible Boundaries')",
      "execution_count": 57,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "cf04775a-d5c2-8289-9ff9-f1d8633d1536",
        "_active": false,
        "collapsed": false
      },
      "source": "## Calculate the entire stack Superpixels\nHere we calculate the superpixels for the entire stack, we then reorder it so it is easier to see in the colormaps",
      "execution_count": null,
      "cell_type": "markdown",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "dd628778-dd18-286f-565f-a7e41958e4fd",
        "_active": false,
        "collapsed": false
      },
      "source": "norm_lung_stack = (segmented_ct_scan-mean_val)/(3*sd_val)\nnorm_lung_stack = (norm_lung_stack+0.1).clip(0,1)\n\nnl_segs = slic(norm_lung_stack, \n               n_segments = 200, \n               compactness = 0.1,\n              multichannel = False) # otherwise it assumes a color image\n\nnl_segs[segmented_ct_scan==ZERO_VALUE] = 0 # remove unneeded segments\n# reorder segments\nnl_segs_new = np.zeros_like(nl_segs)\nfor i_new, i_old in enumerate(sorted(np.unique(nl_segs))):\n    if i_new>0:\n        nl_segs_new[nl_segs==i_old] = i_new",
      "execution_count": 70,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "busy"
    },
    {
      "metadata": {
        "_cell_guid": "24ea9f63-3c6e-4281-ff55-8a60f49ac403",
        "_active": true,
        "collapsed": false
      },
      "source": "fig, (ax1, ax2) = plt.subplots(2,1, figsize = (15, 25))\n\nax1.imshow(montage2d(nl_segs_new), cmap = plt.cm.rainbow)\nax1.set_title('Segmented Image')\n\nax2.imshow(mark_boundaries(montage2d(norm_lung_stack), \n                           montage2d(nl_segs_new).astype(nl_segs_new.dtype)))\nax2.set_title('Visible Boundaries')",
      "execution_count": 66,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "busy"
    },
    {
      "metadata": {
        "_cell_guid": "d217d9cd-ddaa-0695-c980-60b26f2b2bbf",
        "_active": false,
        "collapsed": false
      },
      "source": "Skip slices to get a better overview",
      "execution_count": null,
      "cell_type": "markdown",
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1c0cfaa7-6bcf-f2a3-551e-da3e6b6ac14c",
        "_active": false,
        "collapsed": false
      },
      "source": "fig, (ax1, ax2) = plt.subplots(2,1, figsize = (15, 25))\n\nax1.imshow(montage2d(nl_segs_new[::4]), cmap = plt.cm.rainbow, interpolation = 'none')\nax1.set_title('Segmented Image')\n\nax2.imshow(mark_boundaries(montage2d(norm_lung_stack[::4]), \n                           montage2d(nl_segs_new[::4]).astype(nl_segs_new.dtype)),\n          interpolation = 'none')\nax2.set_title('Visible Boundaries')",
      "execution_count": 69,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "10c687a9-2eec-9cb3-94e9-48717e1d99f2",
        "_active": false
      },
      "source": "Nodule Candidate/Region of Interest Generation\n---------------------------\nAfter segmenting the lung structures from the CT Scanned images, our task is to find the candidate regions with nodules since the search space is very large. Also, whole image cant be classified directly using 3D CNNs due to limit on computation, we need to find possible regions of cancer and then classify them. It was found in experiments that all the region of interests have intensity >  -400 HU. So, we used this threshold to filter the darker regions. This reduces the number of candidates by a large number and preserves all the important regions with high recall. We then classify all the candidate points to reduce the False Positives.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d890715-8444-a56a-5c23-9dbe8a2353a6",
        "_active": false
      },
      "outputs": [],
      "source": "segmented_ct_scan[segmented_ct_scan < -400] = ZERO_VALUE\nplot_ct_scan(autocrop(segmented_ct_scan, ZERO_VALUE))"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8d8e510b-f23d-aeab-3fb0-76f14037942a",
        "_active": false
      },
      "source": "After filtering, there are still lot of noise because of blood vessels. Thus we further remove the two largest connected component.",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8d7c6201-1143-ec15-79da-a4d30f74d2da",
        "_active": false
      },
      "outputs": [],
      "source": "selem = ball(2)\nbinary = binary_closing(segmented_ct_scan, selem)\n\nlabel_scan = label(binary)\n\nareas = [r.area for r in regionprops(label_scan)]\nareas.sort()\n\nfor r in regionprops(label_scan):\n    max_x, max_y, max_z = 0, 0, 0\n    min_x, min_y, min_z = label_scan.shape # use the shape instead of hard-coded values\n    \n    for c in r.coords:\n        max_z = max(c[0], max_z)\n        max_y = max(c[1], max_y)\n        max_x = max(c[2], max_x)\n        \n        min_z = min(c[0], min_z)\n        min_y = min(c[1], min_y)\n        min_x = min(c[2], min_x)\n    if (min_z == max_z or min_y == max_y or min_x == max_x or r.area > areas[-3]):\n        for c in r.coords:\n            segmented_ct_scan[c[0], c[1], c[2]] = 0\n    else:\n        index = (max((max_x - min_x), (max_y - min_y), (max_z - min_z))) / (min((max_x - min_x), (max_y - min_y) , (max_z - min_z)))"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "baa73057-81b1-803d-6cd6-5fbb1661df07",
        "_active": false
      },
      "source": "The `plot_3d` function plots the 3D numpy array of CT Scans. ",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a639882e-626d-75a6-d3b6-103fc06e6f9f",
        "_active": false
      },
      "outputs": [],
      "source": "def plot_3d(image, threshold):\n    # Position the scan upright, \n    # so the head of the patient would be at the top facing the camera\n    p = image.transpose(2,1,0)\n    p = p[:,:,::-1]\n    \n    verts, faces = measure.marching_cubes(p, threshold)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n    mesh = Poly3DCollection(verts[faces], alpha=0.1)\n    face_color = [0.5, 0.5, 1]\n    mesh.set_facecolor(face_color)\n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n\n    plt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09b89a89-5cdf-993e-8d4d-5d0b78ef3363",
        "_active": false
      },
      "outputs": [],
      "source": "plot_3d(autocrop(segmented_ct_scan, -400), -400)"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6882870-ab01-033b-50ca-5ae1eb936218",
        "_active": false
      },
      "source": "### Show the individual components one at a time",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40cdf467-18c8-8e40-ed39-3ae1060e6ac8",
        "_active": false
      },
      "outputs": [],
      "source": "cbase_image = autocrop(segmented_ct_scan, -400)\ncur_labels = label(base_image>-400)\nmax_comp = np.max(cur_labels)\ncomp_by_size = reversed(np.argsort([0]+[np.sum(cur_labels==i) for i in range(1, max_comp+1)]))\nprint('Components Found:', max_comp)\nfig_count = 0\nfor i in comp_by_size:\n    c_bbox = get_bbox(cur_labels==i)  \n    print('Component:', i, c_bbox)\n    cur_obj = apply_bbox(base_image, c_bbox)\n    if (cur_obj.shape[0]>4) & (cur_obj.shape[1]>4)  & (cur_obj.shape[2]>4):\n        print(i, cur_obj.min(), cur_obj.max())\n        plot_3d(cur_obj, np.median([ cur_obj.min(), -400,  cur_obj.max()]))\n        fig_count +=1\n    if fig_count>3: # maximum figure count\n        break"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d879e9c-e6fc-e584-7e6c-e4c7f23a9475",
        "_active": false
      },
      "source": "\n**Please upvote or leave a comment, if you liked the tutorial.**",
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a71487e3-ce5c-9542-e248-356368807287",
        "_active": false
      },
      "outputs": [],
      "source": null
    }
  ]
}