{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73120d09-2d1d-8bc5-17f6-5d5f69ff8fa5"
      },
      "source": [
        "**Exploratory Data Analysis of  Sberbank Russian Housing Market**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "752a0d0d-2d95-3090-2c9e-5ecf55f85679"
      },
      "source": [
        "**In this exploration notebook, try to explore the  dataset which will help us build our models / features.\n",
        "Let us start with importing the necessary modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "44f0501f-6ca8-66a1-19f4-181a8e799405"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing\n",
        "import xgboost as xgb\n",
        "color = sns.color_palette()\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb5f1d0e-2c1e-c3de-e9e8-45b78fcb0629"
      },
      "source": [
        "Importing Train file data and explore the data set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9e9b84a-e1df-81e5-0324-ba66cea0c9d0"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8a39c6ef-9ffc-130a-5929-fac87b0d23bf"
      },
      "outputs": [],
      "source": [
        "train_df.head()# Checking head of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f71a8ffe-003c-3d36-8741-287b17bffbba"
      },
      "source": [
        "**Look at summary of numerical fields by using describe() function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a0dc5a8-6cad-23f8-0433-8deb3d8ce39c"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a71dd00b-5211-ad56-6ebc-1fbd3e0c6335"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_df[train_df.dtypes[(train_df.dtypes==\"float64\")|(train_df.dtypes==\"int64\")]\n",
        "                        .index.values].hist(figsize=[11,11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "33409a34-784a-de2d-2d5f-bfba43cdaa68"
      },
      "source": [
        "**Distribution analysis**\n",
        "\n",
        "Plotting the histogram of Credit_Amount using the following commands\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f23b6c9b-e130-0a77-5af0-e0297dd7b48e"
      },
      "outputs": [],
      "source": [
        "train_df['max_floor'].hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27f69370-f8a9-8afd-fe32-921929c764ad"
      },
      "outputs": [],
      "source": [
        "train_df['price_doc'].hist(bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff2582f6-552c-f028-7a82-576bc666cc5a"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(range(train_df.shape[0]), np.sort(train_df.price_doc.values))\n",
        "plt.xlabel('index', fontsize=12)\n",
        "plt.ylabel('price', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "25e3e9a4-ed79-7897-84a6-27a64d4edf2f"
      },
      "source": [
        "Looks okay to me. Also since the metric is RMSLE, I think it is okay to have it as such. However if needed, one can truncate the high values.\n",
        "We can now bin the 'price_doc' and plot it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0f30a063-f4ad-0a68-dd22-07083cffc50c"
      },
      "source": [
        "This looks much better than previous one\n",
        "Now let us see how the median housing price change with time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f06d2433-5b53-f9b0-d7da-3bb7234ba6a1"
      },
      "outputs": [],
      "source": [
        "train_df['yearmonth'] = train_df['timestamp'].apply(lambda x: x[:4]+x[5:7])\n",
        "grouped_df = train_df.groupby('yearmonth')['price_doc'].aggregate(np.median).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3f749c7-c7d6-6f5b-52c5-2313bf44aecc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.barplot(grouped_df.yearmonth.values, grouped_df.price_doc.values, alpha=0.8, color=color[2])\n",
        "plt.ylabel('Median Price', fontsize=12)\n",
        "plt.xlabel('Year Month', fontsize=12)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f11fd76-d525-e1c4-c608-2f60758b1f0d"
      },
      "source": [
        "It seems some median price value increase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dfce223c-4fb7-4b45-b3b8-7d3b59a17689"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "dtype_df = train_df.dtypes.reset_index()\n",
        "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
        "dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7045cd1a-1307-6be8-60b8-806e793291ca"
      },
      "source": [
        "Now  explore the number of missing values in each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1834762c-9bee-0520-30b2-76726bc6e24b"
      },
      "outputs": [],
      "source": [
        "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
        "missing_df.columns = ['column_name', 'missing_count']\n",
        "missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
        "ind = np.arange(missing_df.shape[0])\n",
        "width = 0.9\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "rects = ax.barh(ind, missing_df.missing_count.values, color='y')\n",
        "ax.set_yticks(ind)\n",
        "ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')\n",
        "ax.set_xlabel(\"Count of missing values\")\n",
        "ax.set_title(\"Number of missing values in each column\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c6ed800-47f5-25bb-54c8-f0dd715ac9dd"
      },
      "source": [
        "There are 292 variables, let us build a basic xgboost model and then explore only the important variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "61c0fea1-2a48-012d-b606-fd00089fef06"
      },
      "outputs": [],
      "source": [
        "for f in train_df.columns:\n",
        "    if train_df[f].dtype=='object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(train_df[f].values)) \n",
        "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
        "        \n",
        "train_y = train_df.price_doc.values\n",
        "train_X = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "\n",
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 8,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "dtrain = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns.values)\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100)\n",
        "\n",
        "# plot the important features #\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f91ce7c4-d37c-41c3-ad90-c1f3169d53ab"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}