{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport cv2\nfrom tqdm import tqdm\nfrom time import time\nfrom collections import Counter\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D\nfrom keras.callbacks import TensorBoard, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\ndataset_base_path = \"../input\"\ntrain_data_path = os.path.join(dataset_base_path, 'train')\ntest_data_path = os.path.join(dataset_base_path, 'test')\nTENSORBOARD_LOGS_PATH = './tensorboard_logs'\nIMAGE_SIZE = 50\nimport shutil\n# shutil.rmtree(\"cat_dogs_checkpoints\")\nos.listdir(\".\")\n# !df -h\nos.mkdir(\"cat_dogs_checkpoints\")\n# os.mkdir(\"TENSORBOARD_LOGS_PATH\")\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d88f5ac0a9f5755ed80ab2c5c3648c6508860b80"},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = TENSORBOARD_LOGS_PATH# Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 6006 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"# Load data\n# df = pd.read_csv('../input/sampleSubmission.csv')\ntrain_images = os.listdir(train_data_path)\ntest_images = os.listdir(test_data_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"064403548fc01b975be6ba2e1dff0608ae092c55","_kg_hide-input":true},"cell_type":"code","source":"# Prepare train data\ndef prepare_train_data(train_images_names):\n    train_images = list()\n    train_labels = list()\n    for image_name in tqdm(train_images_names):\n        image = cv2.imread(os.path.join(train_data_path, image_name))\n        try:\n            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n        except:\n            print(image_name)\n            continue\n        label = 1 if image_name.split(\".\")[0] == \"cat\" else 0\n        train_images.append(image)\n        train_labels.append(label)\n    train_images = np.stack(train_images)\n    train_labels = np.stack(train_labels)\n    np.save(\"train_images.npy\", train_images)\n    np.save(\"train_labels.npy\", train_labels)\n    return train_images, train_labels\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7195245a67795ba717d034b58a9c0040550a4679"},"cell_type":"code","source":"# Prepare test data\ndef prepare_test_data(test_images_names):\n    test_images = list()\n    test_labels = list()\n    for image_name in tqdm(test_images_names):\n        image = cv2.imread(os.path.join(test_data_path, image_name))\n        try:\n            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n        except:\n            print(image_name)\n            continue\n        image_num = image_name.split(\".\")[0]\n        test_images.append(image)\n        test_labels.append(image_num)\n    test_images = np.stack(test_images)\n    test_image_id = np.stack(test_labels)\n    np.save(\"test_images.npy\", test_images)\n    np.save(\"test_image_id.npy\", test_image_id)\n    return test_images, test_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68edffe32f6ec5b4322a911d0f7f123866b5b7d6"},"cell_type":"code","source":"prepare_train_data(train_images)\nprepare_test_data(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e90e242f82e86ad197f6fbe51e14517ddcc3b8c"},"cell_type":"code","source":"dataset_images = np.load('train_images.npy')\ndataset_labels = np.load('train_labels.npy')\n# np.random.shuffle(train_dataset)\n# Generate random indexes for train / val / test split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b31962a683d242bb67f6e43557fbb9747de2953e"},"cell_type":"code","source":"print(dataset_images.shape)\ndataset_images = dataset_images / 255.0\ndataset_image_orig = dataset_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68097f5bb9e1b8f349a927412e7942bf735f14d3"},"cell_type":"code","source":"NUM_TRAIN_DATA = 21000\nX_train = dataset_images[:NUM_TRAIN_DATA, :] # 21000 training samples \nX_val = dataset_images[NUM_TRAIN_DATA:NUM_TRAIN_DATA + 2000, :] # 4000 val samples\nX_test = dataset_images[NUM_TRAIN_DATA + 2000:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5575a8ac0daede542bf063dd848ec62437f6da0b"},"cell_type":"code","source":"Y_train, Y_val, Y_test = dataset_labels[:NUM_TRAIN_DATA], dataset_labels[NUM_TRAIN_DATA:NUM_TRAIN_DATA + 2000], dataset_labels[NUM_TRAIN_DATA + 2000:]\nY_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d93ff2a71cf357c21df9d1d39d670d0b095cfa6"},"cell_type":"code","source":"def show_images_horizontally(images, labels=[], lookup_label=None,\n                            figsize=(15, 7)):\n\n    import matplotlib.pyplot as plt\n    from matplotlib.pyplot import figure, imshow, axis\n    print(labels[0])\n    fig = figure(figsize=figsize)\n    for i in range(images.shape[0]):\n        fig.add_subplot(1, images.shape[0], i + 1)\n        if lookup_label:\n            plt.title(lookup_label[labels[i]])\n        imshow(images[i], cmap='Greys_r')\n        axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a105b717bff0c6df87ef1d9bbef3f6ed05f502f"},"cell_type":"code","source":"show_images_horizontally(X_val[:5], Y_val[:5], lookup_label={1:\"cat\", 0:\"dog\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ed8e59cb7b82394b20ac76c2d4ed84d3504eb8"},"cell_type":"code","source":"model = Sequential()\n# Add model layers\nmodel.add(Conv2D(64, (3,3), strides=(1,1),  padding='same', activation='relu', input_shape=(50, 50, 3), name=\"block1_conv1\"))\nmodel.add(Conv2D(64, (3,3), strides=(1,1),  padding='same', activation='relu', name=\"block1_conv2\"))\nmodel.add(MaxPool2D((2,2), padding='same', name='max_pooling1'))\nmodel.add(Conv2D(128, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block2_conv1\"))\nmodel.add(Conv2D(128, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block2_conv2\"))\nmodel.add(MaxPool2D((2,2), padding='same', name='max_pooling2'))\nmodel.add(Conv2D(256, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block3_conv1\"))\nmodel.add(Conv2D(256, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block3_conv2\"))\nmodel.add(Conv2D(256, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block3_conv3\"))\nmodel.add(MaxPool2D((2,2), padding='same', name='max_pooling3'))\nmodel.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block4_conv1\"))\nmodel.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block4_conv2\"))\nmodel.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block4_conv3\"))\n# model.add(MaxPool2D((2,2), padding='same', name='max_pooling4'))\n# model.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block5_conv1\"))\n# model.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block5_conv2\"))\n# model.add(Conv2D(512, (3,3), strides=(1,1),  padding='same', activation='relu',name=\"block5_conv3\"))\n# model.add(MaxPool2D((2,2), padding='same', name='max_pooling5')) We might not need this max pool\nmodel.add(Flatten(name=\"Flatten\"))\nmodel.add(Dense(128, activation='relu', name=\"fc1\"))\nmodel.add(Dense(128, activation='relu', name=\"fc2\"))\nmodel.add(Dense(1, activation='sigmoid', name=\"predictions\"))\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e08b0d9fce2039776a65940ccbc420e83ad1d978"},"cell_type":"code","source":"# tensorboard = TensorBoard(log_dir=TENSORBOARD_LOGS_PATH + \"/{}\".format(time()))\nfile_path = 'cat_dogs_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nmodel.compile(optimizer=optimizers.Adamax(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=100, callbacks=[checkpoint], batch_size=32, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a1c9315847bee4791cef64e91dc8f1bc779e290"},"cell_type":"code","source":"model = load_model('cat_dogs_checkpoints/weights-improvement-50-0.88.hdf5')\n# !cp cat_dogs_checkpoints/weights-improvement-37-0.88.hdf5 .\n# !ls cat_dogs_checkpoints","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"065106b34cf43b7f2a6e33a3e817d9fc96f95b69"},"cell_type":"code","source":"!ls\nres = model.predict(X_test)\nres_squeezed = np.squeeze(res)\ny_pred = (res_squeezed > 0.5) * 1\nsum(Y_test == y_pred) / Y_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab04a522de3afc503b6162792139d669d5565d33"},"cell_type":"code","source":"test_images_sub = np.load('test_images.npy')\ntest_images_id = np.load('test_image_id.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d94ad34b14d3b11c6b161aa023ba0dff17d6f791"},"cell_type":"code","source":"# test_images_sub.shape\nres = model.predict(test_images_sub)\nres_squeezed = np.squeeze(res)\ny_pred = (res_squeezed > 0.5) * 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"895671a3f58355e5fc3e53128b36e61f65a11f5f"},"cell_type":"code","source":"import csv\nwith open('submissions.csv', 'w') as writeFile:\n    writer = csv.writer(writeFile)\n    writer.writerow([\"id\", \"label\"])\n    for i, result in enumerate(y_pred): \n        writer.writerow([test_images_id[i], result])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a06b2dbe9531a50b0e3cee3522e0501e55911f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}