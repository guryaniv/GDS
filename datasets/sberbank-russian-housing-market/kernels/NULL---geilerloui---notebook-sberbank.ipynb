{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0912b1b4-2472-436a-59c1-e726fa41e208"
      },
      "source": [
        "Introduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f54a207-296c-be48-33f8-bc833de1ed4c"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "df_macro = pd.read_csv('../input/macro.csv', parse_dates=['timestamp'])\n",
        "df_train = pd.read_csv('../input/train.csv', parse_dates=['timestamp'])\n",
        "df_test = pd.read_csv('../input/test.csv', parse_dates=['timestamp'])\n",
        "df_sample_submission = pd.read_csv('../input/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1dbd3d02-1332-1cfc-ed11-0f79c99ac0e4"
      },
      "outputs": [],
      "source": [
        "weak_model_train = df_train.dropna(axis=1)\n",
        "weak_model_macro = df_macro.dropna(axis=1)\n",
        "weak_model_test = df_test.dropna(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1acb0ccb-5b14-479b-cc50-bf6631283b95"
      },
      "outputs": [],
      "source": [
        "i1 = set(weak_model_train.columns)\n",
        "i2 = set(weak_model_test.columns)\n",
        "\n",
        "# new set with element in i1 but not in i2\n",
        "i1.difference(i2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "709c859f-6f77-b8dc-548a-b19da9c25e64"
      },
      "outputs": [],
      "source": [
        "i2.difference(i1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "43e2cfbe-4fdf-6de0-c013-7ce1f97959a9"
      },
      "outputs": [],
      "source": [
        "weak_model_test = weak_model_test.drop(['floor',\n",
        "                                          'kitch_sq',\n",
        "                                          'material',\n",
        "                                          'max_floor',\n",
        "                                          'num_room'],\n",
        "                                        axis=1)\n",
        "weak_model_train = weak_model_train.drop(['green_part_2000',\n",
        "                                        'product_type'],\n",
        "                                      axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1511254-4ae6-6fff-9b16-7521609f75c6"
      },
      "outputs": [],
      "source": [
        "weak_model_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc3b77b2-8dd7-67bf-5a44-767591d1d2e4"
      },
      "outputs": [],
      "source": [
        "weak_model_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45ed046e-9347-0c2c-cc59-80ead910ece6"
      },
      "outputs": [],
      "source": [
        "weak_model_union = weak_model_train.merge(weak_model_macro, left_on='timestamp', right_on='timestamp', how='inner')\n",
        "\n",
        "# We remove id and timestamp\n",
        "weak_model_union = weak_model_union.drop(['id', 'timestamp'], axis=1)\n",
        "\n",
        "# We only keep continuous predictors\n",
        "weak_model_union = weak_model_union.select_dtypes([np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70155caf-4559-c0db-606f-b2cc0d6e4e86"
      },
      "outputs": [],
      "source": [
        "weak_model_test = weak_model_test.merge(weak_model_macro, left_on='timestamp', right_on='timestamp', how='inner')\n",
        "\n",
        "# We remove id and timestamp\n",
        "weak_model_test = weak_model_test.drop(['id', 'timestamp'], axis=1)\n",
        "\n",
        "# We only keep continuous predictors\n",
        "weak_model_test = weak_model_test.select_dtypes([np.number])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34dbfc7b-1297-b113-51f8-fa0d55cd1afb"
      },
      "outputs": [],
      "source": [
        "index_unions = set(weak_model_union.columns)\n",
        "index_test = set(weak_model_test.columns)\n",
        "\n",
        "# new set with element in index_unions but not in index_test\n",
        "index_unions.difference(index_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "411c2eb9-2de5-9b68-612a-9029bac8f672"
      },
      "outputs": [],
      "source": [
        "weak_model_union.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4bba3bc3-287d-9e07-57a7-19eabc7e4e88"
      },
      "outputs": [],
      "source": [
        "weak_model_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0b2373d-8a63-ecb6-1a9c-d6b68c7db704"
      },
      "outputs": [],
      "source": [
        "# Machine learning - metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import cross_validation, metrics #Additional scklearn functions\n",
        "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
        "\n",
        "# Machine learning - algorithms\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "# Machine learning - preprocessing\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "61c77d42-adbb-c59e-bab1-6dfa78b2df6b"
      },
      "outputs": [],
      "source": [
        "X = weak_model_union.drop('price_doc', axis=1).values\n",
        "Y = weak_model_union['price_doc'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3876cc2-1141-1169-b018-102b65902ecf"
      },
      "outputs": [],
      "source": [
        "# Normalization\n",
        "std_scale = preprocessing.StandardScaler().fit(X)\n",
        "X = std_scale.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c19e198-b22e-78ef-c857-3ec82cd982e3"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - An object to be used as a cross-validation generator.\n",
        "          - An iterable yielding train/test splits.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : integer, optional\n",
        "        Number of jobs to run in parallel (default 1).\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c758c16-76c5-e70d-6058-2562e5f85579"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "title = \"Learning Curves (GBR)\"\n",
        "cv = 5\n",
        "estimator = GradientBoostingRegressor()\n",
        "plot_learning_curve(estimator, title, X, Y, ylim=(0.7, 1.01), cv=cv)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cce59928-4ead-3e5c-a158-9a55b33aa657"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\n",
        "X, Y, test_size = 0.33, random_state = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dd38e77f-bda2-bebf-ffbe-222221ae102b"
      },
      "outputs": [],
      "source": [
        "gbr = GradientBoostingRegressor()\n",
        "gbr.fit(X_train, Y_train)\n",
        "pred_train = gbr.predict(X_train)\n",
        "pred_test = gbr.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "47233efe-310d-7e94-d50e-9c01be60d4ec"
      },
      "outputs": [],
      "source": [
        "print(\"Fit a model X_train, and calculate RMSLE with Y_train:\",\n",
        "      RMSLE(gbr.predict(X_train), Y_train))\n",
        "print(\"Fit a model X_train, and calculate RMSLE with X_test, Y_test:\",\n",
        "      RMSLE(gbr.predict(X_test), Y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f39bffe-bd3a-9191-38ae-cbb4bbfa0d85"
      },
      "outputs": [],
      "source": [
        "# Root Mean Squared Logarithmic Error\n",
        "def RMSLE(predictions, a):\n",
        "    return np.sqrt( (1/a.shape[0]) * np.square(np.sum([np.log(predictions+1), - np.log(a+1)])) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b122112e-2747-e033-e625-4e677ae1a916"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.cross_validation import KFold, train_test_split\n",
        "\n",
        "rng = np.random.RandomState(31337)\n",
        "kf = KFold(Y.shape[0], n_folds=10, shuffle=True, random_state=rng)\n",
        "err = []\n",
        "\n",
        "for train_index, test_index in kf:\n",
        "    xgb_model = xgb.XGBRegressor().fit(X[train_index], Y[train_index])\n",
        "    predictions = xgb_model.predict(X[test_index])\n",
        "    actuals = Y[test_index]\n",
        "    err.append(RMSLE(predictions, actuals))\n",
        "\n",
        "print(\"xgboost results, mean: {}, std: {}\".format(np.mean(err), np.std(err)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f806d52a-ddc7-e64f-bf6c-4cf2e09c1149"
      },
      "source": [
        "xgb_model = xgb.XGBRegressor()\n",
        "\n",
        "param_grid = {'max_depth' : [4],\n",
        "              'n_estimators': [50, 100]\n",
        "              }\n",
        "\n",
        "grid_search = GridSearchCV(xgb_model,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=kf,\n",
        "                           verbose=1)\n",
        "\n",
        "grid_search.fit(X, Y)\n",
        "grid_search.best_score_, grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2b5447f-de46-487b-dedc-72b005ab973d"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "608eb59d-4f6d-d5b6-9bbd-c6a8c2fdd067"
      },
      "source": [
        "# Predict on test set then write on CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c03d25fc-7536-2403-6717-53561e9d4e55"
      },
      "outputs": [],
      "source": [
        "X_validation = weak_model_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "591b628f-5dbe-a4ac-7708-3bce04e835f3"
      },
      "outputs": [],
      "source": [
        "xgb_model = xgb.XGBRegressor().fit(X, Y)\n",
        "predictions_validation = xgb_model.predict(X_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e074a6e-2151-62cd-6ab2-857188aa024a"
      },
      "outputs": [],
      "source": [
        "result_csv = pd.DataFrame({'id':df_test.id.values , 'price_doc': predictions_validation})\n",
        "result_csv.to_csv('result.csv', index = False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}