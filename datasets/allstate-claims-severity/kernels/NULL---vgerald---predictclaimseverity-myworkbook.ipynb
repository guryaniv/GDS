{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "629c66cd-51d6-837d-13b8-319d9b8c159a"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4bae191-17e8-43cd-1ee2-6ab852f01916"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "33d1f2fe-5969-f534-f56d-b8237fffb55c"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"../input/train.csv\", nrows=2000)\n",
        "test = pd.read_csv(\"../input/test.csv\", nrows=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c03097f-d286-ba19-598f-fbdb4c7d8359"
      },
      "outputs": [],
      "source": [
        "print(\"Train Shape --> \", train.shape)\n",
        "print(\"Test  Shape --> \", test.shape)\n",
        "print(\"Training data sample: \\n\",train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05c7399e-1cc4-463d-6e32-796f9c163ef0"
      },
      "outputs": [],
      "source": [
        "print(\"Number of missing values\",train.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "612298cf-948d-fe05-9359-d0a8fbe99aea"
      },
      "outputs": [],
      "source": [
        "print(\"Training data types -->\",tuple(train.columns.to_series().groupby(train.dtypes).groups))\n",
        "print(\"Training data types -->\",tuple(test.columns.to_series().groupby(test.dtypes).groups))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "37aad336-2b33-fda7-99f3-34a67caedf3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "def convertcat2cont(df):\n",
        "    print(\"Before -->\",tuple(df.columns.to_series().groupby(df.dtypes).groups))\n",
        "    for cf1 in catFeatureslist:\n",
        "        le = LabelEncoder()\n",
        "        le.fit(df[cf1].unique())\n",
        "        df[cf1] = le.transform(df[cf1])\n",
        "    print(\"After -->\",tuple(df.columns.to_series().groupby(df.dtypes).groups))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9ead724-7704-b7a1-065c-ab9d438b5ae7"
      },
      "outputs": [],
      "source": [
        "# Understanding categorical and continuous features\n",
        "catCount = sum(str(x).isalpha() for x in train.iloc[1,:])\n",
        "print(\"Number of categories features: \",catCount)\n",
        "contCount = sum(not str(x).isalpha() for x in train.iloc[1,:])\n",
        "print(\"Number of Continuous features: \",contCount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a45ddba9-0adc-bd34-10bc-48e203c3fc74"
      },
      "outputs": [],
      "source": [
        "catFeatureslist = []\n",
        "contFeatureslist = []\n",
        "for colName,x in train.iloc[1,:].iteritems():\n",
        "\tif(str(x).isalpha()):\n",
        "\t\tcatFeatureslist.append(colName)\n",
        "\telse:\n",
        "\t\tcontFeatureslist.append(colName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "523d0956-4fba-ffc2-93ff-164183e978b6"
      },
      "outputs": [],
      "source": [
        "print(\"Number of categories features: \",len(catFeatureslist))\n",
        "print(\"Number of Continuous features: \",len(contFeatureslist))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b61557ce-d3fe-851b-6491-7cabd9e61f90"
      },
      "outputs": [],
      "source": [
        "# Box plots for continuous features\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "#plt.figure(figsize=(13,9))\n",
        "sns.boxplot(train[contFeatureslist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1168a1c-bc36-21e8-c143-5e70bcf0cfff"
      },
      "outputs": [],
      "source": [
        "# Correlation between continuous features\n",
        "correlationMatrix = train[contFeatureslist].corr().abs()\n",
        "plt.subplots(figsize=(12, 8))\n",
        "sns.heatmap(correlationMatrix,annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e6c3d37-02b6-12fe-6713-fb7b349c1d6c"
      },
      "outputs": [],
      "source": [
        "# Mask unimportant features (less than 0.5)\n",
        "sns.heatmap(correlationMatrix, mask=correlationMatrix < .5, cbar=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c37ade59-4110-939f-5f5f-87fea26a7d8c"
      },
      "outputs": [],
      "source": [
        "# Analysis of loss feature\n",
        "\n",
        "#plt.figure(figsize=(12,8))\n",
        "sns.distplot(train[\"loss\"])\n",
        "sns.boxplot(train[\"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9d990b8-7e6f-b1b9-e23b-feefc902fd53"
      },
      "outputs": [],
      "source": [
        "# use log to remove the skewness\n",
        "#plt.figure(figsize=(12,8))\n",
        "sns.distplot(np.log1p(train[\"loss\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1eab5b21-6c29-c783-fb9c-443e82727552"
      },
      "outputs": [],
      "source": [
        "# Unique categorical values per each category\n",
        "print(train[catFeatureslist].apply(pd.Series.nunique))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb61208c-202f-6997-68d5-07342cef978b"
      },
      "outputs": [],
      "source": [
        "#Analysis of categorical features with levels between 5-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2e79fdb-d009-85c3-0ac3-abf800d834f8"
      },
      "outputs": [],
      "source": [
        "filterG5_10 = list((train[catFeatureslist].apply(pd.Series.nunique) > 5) & \n",
        "                (train[catFeatureslist].apply(pd.Series.nunique) < 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "875f5a2b-6b42-2bbd-860d-b4af58b60d54"
      },
      "outputs": [],
      "source": [
        "catFeaturesG5_10List = [i for (i, v) in zip(catFeatureslist, filterG5_10) if v]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ad8c0a55-0060-8da8-676f-012308299262"
      },
      "outputs": [],
      "source": [
        "len(catFeaturesG5_10List)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af06ede3-56e4-558d-e52e-e64f0d7d02ab"
      },
      "outputs": [],
      "source": [
        "ncol = 2\n",
        "nrow = 4\n",
        "try:\n",
        "    for rowIndex in range(nrow):\n",
        "        f,axList = plt.subplots(nrows=1,ncols=ncol,sharey=True) #,figsize=(13, 9))\n",
        "        features = catFeaturesG5_10List[rowIndex*ncol:ncol*(rowIndex+1)]\n",
        "        \n",
        "        for axIndex in range(len(axList)):\n",
        "            sns.boxplot(x=features[axIndex], y=\"loss\", data=train, ax=axList[axIndex])\n",
        "                        \n",
        "            # With original scale it is hard to visualize because of outliers\n",
        "            axList[axIndex].set(yscale=\"log\")\n",
        "            axList[axIndex].set(xlabel=features[axIndex], ylabel='log loss')\n",
        "except IndexError:\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3b748bc-186d-8457-b904-a56eb8555b59"
      },
      "outputs": [],
      "source": [
        "#convert categorical variables to continuous\n",
        "convertcat2cont(train)\n",
        "convertcat2cont(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8d488b2a-82d0-0dde-be35-35d7a2e0beaf"
      },
      "outputs": [],
      "source": [
        "#Correlation between categorical variables\n",
        "filterG2 = list((train[catFeatureslist].apply(pd.Series.nunique) == 2))\n",
        "catFeaturesG2List = [i for (i, v) in zip(catFeatureslist, filterG2) if v]\n",
        "catFeaturesG2List.append(\"loss\")\n",
        "\n",
        "corrCatMatrix = train[catFeaturesG2List].corr().abs()\n",
        "\n",
        "s = corrCatMatrix.unstack()\n",
        "sortedSeries= s.order(kind=\"quicksort\",ascending=False)\n",
        "\n",
        "print(\"Top 5 most correlated categorical feature pairs: \\n\")\n",
        "print(sortedSeries[sortedSeries != 1.0][0:9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e74f380b-ae5c-b7f6-197c-bf4a315f3446"
      },
      "outputs": [],
      "source": [
        "print(\"train --> \", train.shape)\n",
        "X_train = train.drop(['id','loss'], axis=1)\n",
        "y_train = train['loss']\n",
        "print(\"X features -->\", X_train.shape)\n",
        "print(\"y feature --->\", y_train.shape)\n",
        "\n",
        "print(\"test --> \", test.shape)\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "# predict y_test\n",
        "print(\"X features -->\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "522f3beb-9bea-9bfa-8aa3-7143bf5119bb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor(n_estimators=50, random_state=3)\n",
        "def doRFR(X_train,y_train,X_test):\n",
        "    rfr.fit(X_train,y_train)\n",
        "    print(\"Accuracy on training set: {:.3f}\".format(rfr.score(X_train, y_train)))\n",
        "    y_predrfr = rfr.predict(X_test)\n",
        "    print(\"RandomForestRegressor\")\n",
        "    print(y_predrfr[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69c1e486-5dc6-7933-13c5-21210adbfcad"
      },
      "outputs": [],
      "source": [
        "# any object or category will make the analysis fail\n",
        "print(tuple(X_train.columns.to_series().groupby(X_train.dtypes).groups))\n",
        "print(tuple(X_test.columns.to_series().groupby(X_test.dtypes).groups))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4d183aa-6cbf-b86b-0f93-b3449a17b3b1"
      },
      "outputs": [],
      "source": [
        "y_pred = doRFR(X_train,y_train,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c32509cf-309b-c7e7-1335-30dcd5861346"
      },
      "outputs": [],
      "source": [
        "preds = pd.DataFrame({\"id\": test['id'],\"loss\": y_pred})\n",
        "preds.head(5)\n",
        "preds.to_csv('AllStateClaimsSeverity_yyyymmdd.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e300c8b7-8a11-8698-73a1-2235f9bc89ef"
      },
      "outputs": [],
      "source": [
        "print(check_output([\"ls\"]).decode(\"utf8\"))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}