{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport warnings\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"088d828a8f18048282e0aaae6744d919067ff8d4"},"cell_type":"markdown","source":"Application train and application test are the two main files here! Train has the *TARGET* variable which has the defaulted (1) or not defaulted (0) outcome. Each row in these files is a loan.\n\nWe will focus on these files first in this kernel!"},{"metadata":{"trusted":true,"_uuid":"dab212fbf980eaf2486718b5075bfa92e29660a9"},"cell_type":"code","source":"# read in application train and application test files\napp_train = pd.read_csv('../input/application_train.csv')\napp_test = pd.read_csv('../input/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cba7b12e761b76ffd9db3dcc1373c86dceac948"},"cell_type":"code","source":"# How many rows and columns are there? train has the extra TARGET variable over test!\nprint(app_train.shape)\nprint(app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfd0bd44fa9872aeff47b19e525cbb22f6bd045d"},"cell_type":"code","source":"# What are the column types?\nplt.figure(figsize = (10,6))\nax = app_train.dtypes.value_counts().plot(kind = 'bar', rot = 0)\nax.set_title('Count of Column Data Types')\nax.set_xlabel('Data Type')\nax.set_yticks([])\nax.grid(False)\n\n# each rectangle is a bar\nrects = ax.patches\n\n# Make some labels.\nlabels = app_train.dtypes.value_counts().tolist()\n\n# loop through each rectangle and put label\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width() / 2, height - 5, label,\n            ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7abc175c3c1a519de532c2afbbabdb19379ae38"},"cell_type":"code","source":"# define a function to get the missing values\ndef missing_check(df):\n    '''Given a dataframe this determines the missing values and plots them'''\n    missing_df = df.isnull().sum().reset_index()\n    missing_df.columns = ['variable', 'missing_values']\n    missing_df['Perc_Missing'] = missing_df['missing_values']*100/len(df)\n    missing_df.sort_values('Perc_Missing', ascending = False, inplace = True)\n    missing_df = missing_df.loc[missing_df['Perc_Missing']>0, :]\n    if len(missing_df) == 0:\n        return \"No columns with missing values\"\n    else:\n        missing_df['Perc_total'] = 100\n        return missing_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"705694f6fe1d029786e15eaa6a070f39c4f47f1c"},"cell_type":"code","source":"# visualize the top most columns with missing entries\nabc = missing_check(app_train).reset_index(drop = True)\n\nplt.figure(figsize = (10, 10))\nplt.barh(abc.loc[:15, 'variable'], abc.loc[:15, 'Perc_total'], label = \"Total rows\")\nplt.barh(abc.loc[:15,'variable'], abc.loc[:15,'Perc_Missing'], label = \"Missing rows\")\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8854d40256aa90f8b1804537bd05e1cd3774b8eb"},"cell_type":"markdown","source":"We see many columns with greater than 60% missing values. We will have to figure out a strategy to impute these or remove these columns!"},{"metadata":{"trusted":true,"_uuid":"2dc3aa9ed1750ecc27feadcee088c4f100e8cb6a"},"cell_type":"code","source":"abc['Column_Type'] = abc['variable'].map(lambda x: app_train[x].dtype)\nabc.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a71ddf4d672d4a21aace6f130d1b7fe728e85f3"},"cell_type":"markdown","source":"So what type of columns have the most missing values?"},{"metadata":{"trusted":true,"_uuid":"e5ff93d1e2fa80970c4719646a5fb56796e2f5e4"},"cell_type":"code","source":"plt.figure(figsize = (10,6))\nplt.style.use('seaborn-darkgrid')\nax = abc['Column_Type'].value_counts().plot(kind = 'bar')\nax.grid(False)\nax.set_title('Column Type count with missing values')\nax.set_xlabel('Column Type')\nax.set_ylabel('Count of columns')\nax.set_yticks([])\n\nrects = ax.patches\nlabels = abc['Column_Type'].value_counts().tolist()\n\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    width = rect.get_width()\n    ax.text(rect.get_x() + width/2, height - 3, label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caae199d2bbceec8bdcb6261be6c8f814d60c733"},"cell_type":"markdown","source":"The 'NA' values in the *object* column type would get their own column with 0,1 when encoded. The *float* type columns can be easily imputed using a median/mean strategy!!"},{"metadata":{"_uuid":"a593f0158ea5a19e7957d5b7962232d8697d6635"},"cell_type":"markdown","source":"### Categorical Variable Encoding"},{"metadata":{"_uuid":"68b1a5868fa2d0a3f7c5779073ad86c07eb9847a"},"cell_type":"markdown","source":"There are around 16 categorical variables in our test and train dataframe, lets encode these! \n1. Label encode would assign a numerical value to each level of the variable, \n2. hot encoding creates a new column with 1,0 values for each level!"},{"metadata":{"trusted":true,"_uuid":"c8e234d3facea3daf503c1dca8d370a75d873d0c"},"cell_type":"code","source":"# First lets select the object type columns from app_train\nobj_cols = app_train.select_dtypes('object').columns.tolist()\nprint(obj_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23e7dc7424727fc8c91dcaf114323ea2fe91dedd"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ncount_le = 0\n\nfor col in obj_cols:\n    if len(app_train[col].unique()) <= 2:\n        le.fit(app_train[col])\n        app_train[col] = le.transform(app_train[col])\n        app_test[col] = le.transform(app_test[col])\n        \n        count_le += 1\n        \nprint(\"Columns with label encoding:\", count_le)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc1aa3bd5f2fd8e74f1e8b7b7b026eead50b3065"},"cell_type":"markdown","source":"Looking at the **app_train** and **app_test** datasets again, we find that 3 object type variables in each have been converted to a 0-1 encoding. Lets do one hot encoding for other variables!"},{"metadata":{"trusted":true,"_uuid":"321fab1f905bf45d419ff4d886273537f8a2cc36"},"cell_type":"code","source":"# get_dummies takes all categorical variables and creates a new column for each level\napp_train_encoded = pd.get_dummies(app_train)\napp_test_encoded = pd.get_dummies(app_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1bb913e8a3f636ab58c096258ee5dd824f6fcf1c"},"cell_type":"code","source":"print(app_train_encoded.shape)\nprint(app_test_encoded.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60545ce2fcd31f954f1edf749c97686f58a770fc"},"cell_type":"markdown","source":"Once we do the encoding, we see that the number of columns has increased significantly and that the number of columns in test and train datsets is not equal! **This is because the levels in the catgorical variables are not the same!**"},{"metadata":{"trusted":true,"_uuid":"40b675dc6de8aecc6f2adb9b0eb14cf1a4c88c7c"},"cell_type":"code","source":"# align the dataframes - This removes the target variable too, so lets store it separately\ntrain_labels = app_train_encoded['TARGET']\n\napp_train_encoded, app_test_encoded = app_train_encoded.align(app_test_encoded,\n                                                             join = 'inner',\n                                                             axis = 1)\n\nprint(app_train_encoded.shape)\nprint(app_test_encoded.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ede57047aea5daa5276a9d18ee2f622a4e912f46"},"cell_type":"markdown","source":"Aligning the two dataframes has made the columns in train dataframe, same as that of the test dataframe! The shape output tells us as much! Note that now the **app_train_encoded** dataframe doesnt have the TARGET variable which is now in the **train_labels** variable.\n\nOne thing to note is that when we encode a categorical variable, **the NA values go into a column of their own**. This can help us if all NA values secretly mean something that we would otherwise not capture if we impute these values! Anyway, we have no robust method to impute categorical variables!"},{"metadata":{"_uuid":"6081b242099c79ceb4fb42c39fd63af119163303"},"cell_type":"markdown","source":"## Variable Correlations\nOnce we have modified our dataframe into a suitable shape, next we need to look into variable correlations to make sense of what variables are most important to us from the prediction aspect!"},{"metadata":{"trusted":true,"_uuid":"19662fe386fb6f676d1ea63e2bc8e047e403c980"},"cell_type":"code","source":"# attach train_labels to the app_train_encoded\napp_train_encoded['TARGET'] = train_labels\n\n# correlations\ncorrelations = app_train_encoded.corr()['TARGET']\ntop_5_positive = correlations.sort_values(ascending = False)[:5]\ntop_5_negative = correlations.sort_values(ascending = True)[:5]\n\nprint(top_5_positive)\nprint(top_5_negative)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf01d5b448670bb9265d5e7bfdf67b44a291be42"},"cell_type":"markdown","source":"*EXT_SOURCE_3, EXT_SOURCE_2* and *EXT_SOURCE_1* are the most negatively correlated with *TARGET* and *DAYS_BIRTH* is positively correlated! \n\n**Since *DAYS_BIRTH* is all negative values, it tells us that as people get younger, they probably default more than older people!**"},{"metadata":{"trusted":true,"_uuid":"0c24e1dc60f012cbe5f520f9dfed2aa7092ecb60"},"cell_type":"code","source":"# What does the DAYS_BIRTH variable look like? This is the difference between the loan\n# application date and birthdate of the applicant\nplt.figure(figsize = (10,6))\napp_train_encoded['DAYS_BIRTH'].plot.hist(bins = 25, edgecolor = 'k', rot = 0)\nplt.title('DAYS_BIRTH Histogram')\nplt.xlabel('DAYS_BIRTH')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26147d86a7209495b21dc7d6c2aa2c77f8caf8ab"},"cell_type":"code","source":"# Lets convert this to positive values so that it makes more sense\napp_train_encoded['DAYS_BIRTH'] = abs(app_train_encoded['DAYS_BIRTH'])\napp_test_encoded['DAYS_BIRTH'] = abs(app_test_encoded['DAYS_BIRTH'])\n\nplt.figure(figsize = (10,6))\napp_train_encoded['DAYS_BIRTH'].plot.hist(bins = 25, edgecolor = 'k', rot = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcc641f3961f6eafc28652eb6be2b8ed6e9b61a9"},"cell_type":"markdown","source":"And now we see that the correlation has become negative! **As age increases -> default rate goes down!**"},{"metadata":{"trusted":true,"_uuid":"338adc44bdf60fe6f49bcb4f2b03c11f39597660"},"cell_type":"code","source":"app_train_encoded['DAYS_BIRTH'].corr(app_train_encoded['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a0d4605cc2d1fec8e76c2aaf56cf9f7c4ee4718"},"cell_type":"code","source":"# age versus the outcome variable\nplt.figure(figsize = (10, 8))\n\nsns.kdeplot(app_train_encoded.loc[app_train_encoded['TARGET'] == 0, 'DAYS_BIRTH'],\n           label = \"TARGET = 0\")\nsns.kdeplot(app_train_encoded.loc[app_train_encoded['TARGET'] == 1, 'DAYS_BIRTH'],\n           label = \"TARGET = 1\")\nplt.title('DAYS_BIRTH vs TARGET')\nplt.xlabel('DAYS_BIRTH')\nplt.ylabel('Density')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64d32e84fcdd52c54b15005aacafb10791f23e27"},"cell_type":"markdown","source":"On to the **EXT_SOURCE** variables!"},{"metadata":{"trusted":true,"_uuid":"8f8b9292ea76d2fcf96bfe3c60778612f01174d4"},"cell_type":"code","source":"correl = app_train_encoded[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET']].corr()\n\nplt.figure(figsize = (10,6))\nsns.heatmap(correl, cmap = plt.cm.RdYlBu_r, annot = True, vmin = -0.6, vmax = 0.8)\nplt.yticks(rotation = 'horizontal')\nplt.title('Correlation Heatmap')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb55954508ab1a07faf50ad3a942489bd144f8c6"},"cell_type":"markdown","source":"We see that the *EXT_SOURCE* variables are more correlated with each other than with the *TARGET* variable in an absolute sense!"},{"metadata":{"_uuid":"f8fc8a019866375285b9354115eb34b87e196da9"},"cell_type":"markdown","source":"### Missing value imputations\nNow that we have seen what variables are most correlated with our TARGET, we move on to imputing the missing values! Lets use the median strategy and mean strategy and compare the results!\n\nA critical element to note here is that the while imputing,** we have to make sure that we treat the test data as unseen, which means that for all columns with missing data we need to calculate the mean/median on the training data and use the same mean/median while imputing values in the test data!**"},{"metadata":{"trusted":true,"_uuid":"ede1f379fd19119c6375774a36cd619bc8116372"},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\nimputer = Imputer(strategy = 'median')\n\nif 'TARGET' in app_train_encoded:\n    app_train_encoded.drop(columns = ['TARGET'], inplace = True)\n    \n\n# we need to remove the SK_ID_CURR variable before we do the scaling since these do not \n# have to be scaled\ntrain_id = app_train_encoded['SK_ID_CURR']\ntest_id = app_test_encoded['SK_ID_CURR']\n\n# Fit on train data and then transform test data as well!\napp_train_encoded.drop(columns = ['SK_ID_CURR'], inplace = True)\napp_test_encoded.drop(columns = ['SK_ID_CURR'], inplace = True)\n\n# get column names from the dataframe since imputer converts these to matrices\nfeatures = app_train_encoded.columns.tolist()\n\n# impute the missing values\napp_train_enc_imput_med = imputer.fit_transform(app_train_encoded)\napp_test_enc_imput_med = imputer.transform(app_test_encoded)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b24a2c6e273c7ebd57c90cc1f1a26f87bdd4a4d"},"cell_type":"markdown","source":"### Min max scaling of variables\nBefore we fit our models, it is critical to scale our variable ranges! This makes it easier for us to interpret the coefficients of models such as **Logistic Regression** to be proxies for variable importance! Generally, I have also seen model performance improvements with this!\n\nMinMaxScaling for a `feature_range = (0,1)` essentially does -\n\n[MinMaxScaling](https://drive.google.com/open?id=1l53oXLJFybxqK8HuRjwUADKPYQJjyf3S)\n\nIn our train and test data, although we do not expect, the min and max values for the same column can be very different. For this reason, we use the (min, max) values from the train data and use the same for scaling the test data. This ensures that columns across dataframes are scaled appropriately!\n\nFor instance, suppose a column in training data values  - `[4,5,6]`.  Then, min max scaling would change these values to - `[0, 0.5, 1]`. Now, lets suppose the same column in the test data has the values - `[9,10,15]`, then the min max scaling on the test data would change these to - `[0, 1/6 , 1]`. **For a model that uses these values to predict the outcome essentially a value of 6 becomes the same as 15 which is wrong.**"},{"metadata":{"trusted":true,"_uuid":"702d903ad3b342b2ecb8fdb935d59b90a0b4e962"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0,1))\n\napp_train_enc_imput_med = scaler.fit_transform(app_train_enc_imput_med)\napp_test_enc_imput_med = scaler.transform(app_test_enc_imput_med)\n\nprint(\"Test data:\", app_test_enc_imput_med.shape)\nprint(\"Train data shape:\", app_train_enc_imput_med.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0bba899a52ac54b84977e937bf9de07716a7525"},"cell_type":"markdown","source":"### Logistic Regression Model"},{"metadata":{"trusted":true,"_uuid":"22349feee2ada347414ebcfbc45496fcedd34201"},"cell_type":"code","source":"# Lets break our train data into training and validation datasets - 0.7 and 0.3\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(app_train_enc_imput_med, \n                                                   train_labels,\n                                                   test_size = 0.3,\n                                                   random_state = 2)\n\nprint(\"Train data shape:\", X_train.shape)\nprint(\"Test data shape:\", X_test.shape)\nprint(\"train labels shape:\", y_train.shape)\nprint(\"test labels shape:\", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8cbb0c89131be63a5a5d4c913a63f181e9bac7d"},"cell_type":"code","source":"# Fit the model on training data!\nfrom sklearn.linear_model import LogisticRegression\n\n# Logistic regression model\nlog_reg = LogisticRegression(C =  0.0001)\n\nlog_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c6768331c56fa3710343faf01ff52782e6fe720"},"cell_type":"markdown","source":"### Get variable importance using the test data"},{"metadata":{"trusted":true,"_uuid":"b7e6ef01d527472090b823156832e56a6fe357bf"},"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(log_reg, random_state = 2).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = features)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6da81fa2dfc65ccb79dee09d5b57f8649f6d0e72"},"cell_type":"markdown","source":"### What are the coefficients like?\nCorrelations told us that *EXT_SOURCE* variables and *DAYS_BIRTH* should be the most important variables! Lets see if the coefficients match this hypothesis! **Since our numerical variables are in the 0,1 range, the coefficients can be directly compared to assess impact of a variable on the *TARGET***"},{"metadata":{"trusted":true,"_uuid":"6aae7bc3d55fc745f1b30d1236c272c1cc4f4a24"},"cell_type":"code","source":"log_reg_coeff = pd.Series(log_reg.coef_.tolist()[0], index = features).sort_values()\nprint(\"Top 5 negative:\\n\",log_reg_coeff[:5])\nprint(\"\\nTop 5 positive:\\n\",log_reg_coeff[-5:])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9b336ea77020ef6929493de35b264ee05fb9cc7"},"cell_type":"markdown","source":"**What leads to less default** - \n1. Higher values on the *EXT_SOURCE* variables- Are these credit ratings?\n2. Female loan applicants - Nice!\n3. Older people in general!\n4. Whether applicant provided cell phone number!\n\n**What leads to more default** -\n1. People with *OCCUPATION* as Laborer are more likely to default.\n2. Male loan applicants!\n3. Working people (Salaried) are more likely to default!\n4. If applicant's permanent address does not match contact address\n5. If applicant's permanent address does not match work address."},{"metadata":{"_uuid":"efc93f006dad2ca9ec3310ba188b863841b3f911"},"cell_type":"markdown","source":"Let's now predict default values in the test set that we created. We will use the `predict_proba` function and get the probabilities of getting a 1 (Default)"},{"metadata":{"trusted":true,"_uuid":"38a8d0f6c8640d2e3eacd7ce3259468e7986ca4c"},"cell_type":"code","source":"# predict the probability of each class in the test data and extract the probability for\n# class = 1\nlog_predictions = log_reg.predict_proba(X_test)[:,1]\nlog_predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e45844f6ab664e240a32dcb85b15a72e30384572"},"cell_type":"markdown","source":"The **log_predictions** variable holds the predicted probabilities for default = 1 for the test data!"},{"metadata":{"trusted":true,"_uuid":"149d14a5f0be829ec231c0036d9c7c2d30fd1a8e"},"cell_type":"code","source":"# Whats the baseline accuracy for this problem\ny_test.value_counts()/len(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59c979cf703591b23e516fc99b5a6afaf0528fdd"},"cell_type":"markdown","source":"We have an imbalanced class problem here since the proportion of defaulters is just 8.07% while non-defaulters are the majority with a proportion of 91.93%. **For this reason, any model that just predicts no-default for all the test rows would get an accuracy of 91.93%** - however, this is not an informative model since we want to identify with some accuracy, the people who will default.\n\nFor such problems the **Area Under the Receiver Operating Characteristic curve (AUC ROC)** is the metric of choice! For intuition, a model with an aucroc score of 0.5 is no good and its effectiveness increases the further the area goes upwards of 0.5!"},{"metadata":{"trusted":true,"_uuid":"c79141b47c5466ee12a3bf5da662b968f71ddade"},"cell_type":"code","source":"# lets calculate the AUCROC metric\nfrom sklearn import metrics\nlogit_accuracy = metrics.roc_auc_score(y_test, log_predictions)\nprint(\"Logistic Regression Accuracy: {0:.2f}\".format(logit_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d23996f1a25b3b0497fad6864a354d2d3003a7a"},"cell_type":"markdown","source":"### Cross Validation\nThe above *roc_auc_score* could be due to a chance selection of a good test set. Let's use cross validation to check if model performs in a stable manner."},{"metadata":{"trusted":true,"_uuid":"0173d9e3dab71f76ec09c3ff231df2a1acecdec4"},"cell_type":"code","source":"# 10 fold cross validation setup\nfrom sklearn.model_selection import StratifiedKFold\nkfold = StratifiedKFold(n_splits = 10, random_state = 2).split(X = app_train_enc_imput_med,\n                                                               y = train_labels)\n\naccuracies = []\n\n# train the logistic regression model on each and get auc-roc scores\nfor train, holdout in kfold:\n    log_reg.fit(app_train_enc_imput_med[train,:], train_labels[train])\n    predictions = log_reg.predict_proba(app_train_enc_imput_med[holdout,:])[:,1]\n    accuracy = metrics.roc_auc_score(train_labels[holdout], predictions)\n    accuracies.append(accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a6667901bccebecfe9596cec04d40baeb559fd"},"cell_type":"code","source":"# Scatter plot of the accuracies achieved through cross validation\nplt.figure(figsize = (6, 6))\nplt.scatter(range(1,11), accuracies)\nplt.title('ROC AUC score with Cross Validation')\nplt.xlabel('Fold Number')\nplt.ylabel('Area under the ROC curve')\n\n# draw a line for the mean auc-roc score\nplt.axhline(y = np.mean(accuracies), color = 'red', linewidth = 1)\nplt.text(x = 6, y = 0.695, \n         s = \"Average Accuracy:{0:.3f}\".format(np.mean(accuracies)),\n        color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8310aa2ae4c2c182cd824c71d5dbed8fd8a06b84"},"cell_type":"markdown","source":"### Random Forest Classifier\nLet's also try the random Forest Classifier here.** A random forest classifier would make a lot of decision trees on different variables of the dataset and try to aggregate the predictions from all those trees into a single prediction. **\n\nThis works because with a lot of different algorithms that are usually uncorrelated with each other, we get a reduction in variance of the prediction - which is to say that all the trees won't get the same prediction wrong and this usually leads to improved performance!"},{"metadata":{"trusted":true,"_uuid":"cc18e000583d08b3b7b39095bf3669d80464bfa4"},"cell_type":"code","source":"# train the random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(n_estimators = 100,\n                                 n_jobs = 1,\n                                 random_state = 2)\n\n# 5 fold cross validation\nkfold = StratifiedKFold(n_splits = 5, random_state = 2).split(X = app_train_enc_imput_med,\n                                                              y = train_labels)\n\n# Calculate the auc-roc scores for each train, holdout score\naccuracies = []\nfor train, holdout in kfold:\n    rf_model.fit(app_train_enc_imput_med[train, :], train_labels[train])\n    predictions = rf_model.predict_proba(app_train_enc_imput_med[holdout, :])[:,1]\n    accuracies.append(metrics.roc_auc_score(train_labels[holdout], predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7f69e97790fe400b0a8b0285f4287983d2f0018"},"cell_type":"code","source":"# Lets draw a scatter plot of the AUC-ROC scores for each fold!\nplt.figure(figsize = (6,6))\nplt.scatter(range(1,6), accuracies)\nplt.title('Cross Validation AUC-ROC with Random Forest')\nplt.xlabel('Fold Number')\nplt.ylabel('ROC-AUC Score')\n\nplt.axhline(y = np.mean(accuracies), color = 'red', linewidth = 1)\nplt.text(x = 3.5, y = 0.715,\n         s = \"Avg AUC-ROC score:{0:.2f}\".format(np.mean(accuracies)),\n        color = 'red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae9da66dc932026c29d5f2f8ea7450b182f39cee"},"cell_type":"markdown","source":"**Using a randomForest Model we get an auc-roc score of 0.710 on average**. This is an improvement over the previous logistic regression model which gave a score of 0.68!"},{"metadata":{"_uuid":"daf72b06b803168fdf8c4c055ca2282d76ffae34"},"cell_type":"markdown","source":"### Auxilliary Data - \nThere is a host of auxilliary data provided in this competition. Let's try to merge that with our `app_train_enc_input_med` to see whether it brings improvements in accuracy! We will do this in the next notebook. \n\nLet's write out our outputs from this notebook to a csv file and we can pick it up from there in the next notebook!"},{"metadata":{"trusted":true,"_uuid":"0eecea276cbe5d11e966c7ff64963090d04c5d93"},"cell_type":"code","source":"# convert the test and train matrices to a dataframe\napp_train_part1 = pd.DataFrame(app_train_enc_imput_med,\n                              columns = features)\n\napp_test_part1 = pd.DataFrame(app_test_enc_imput_med,\n                              columns = features)\n\n# Append the SK_ID_CURR variable\napp_train_part1 = pd.concat([app_train_part1, train_id], axis = 1)\napp_test_part1 = pd.concat([app_test_part1, test_id], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13bac05deed37d0868a8c794fa5d9997cfef4012"},"cell_type":"code","source":"# write to a csv file\napp_train_part1.to_csv(\"app_train_part1.csv\", index = False)\napp_test_part1.to_csv(\"app_test_part1.csv\", index = False)\ntrain_labels.to_csv(\"train_labels.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc2c0774bbbeee0ea2080a324b0acba16d972a84"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}