{"cells": [{"metadata": {"_uuid": "c88c132dac3908aa10d39ca408da3eea29decf76", "slideshow": {"slide_type": "slide"}, "_cell_guid": "556a42c3-1263-446e-8c1e-65cd1901f611"}, "cell_type": "markdown", "source": ["# Deep Learning Bootcamp November 2017, GPU Computing for Data Scientists\n", "\n", "#### Shlomo Kashani \n", "\n", "\n", "## 69-PyTorch-Kaggle-porto-driver\n", "\n", "Web: https://www.meetup.com/Tel-Aviv-Deep-Learning-Bootcamp/events/241762893/\n", "\n", "Notebooks: <a href=\"https://github.com/QuantScientist/Data-Science-PyCUDA-GPU\"> On GitHub</a>\n", "\n", "*Shlomo Kashani*\n", "\n", "\n", "### Data\n", "- Download from Kaggle\n", "\n", "### Epochs\n", "I set epochs=500 because in Kaggle this runs on a CPU, change to 5000 for better results on a GPU"]}, {"metadata": {"_uuid": "00f69110481df8e5dc2f6b22f85ed57252defeeb", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "f2a22c11-4867-4706-b45e-e3b26f37bf38"}, "cell_type": "markdown", "source": ["# PyTorch Imports\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "641a00a35bed67714404fbb76c835907f067a87f", "slideshow": {"slide_type": "-"}, "collapsed": true, "_cell_guid": "3c437ee6-22a3-4826-9cb5-2a48ee95471d"}, "source": ["% reset -f\n", "import torch\n", "import sys\n", "import torch\n", "from torch.utils.data.dataset import Dataset\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torch import nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.autograd import Variable\n", "\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n", "\n", "print('__Python VERSION:', sys.version)\n", "print('__pyTorch VERSION:', torch.__version__)\n", "\n", "import numpy\n", "import numpy as np\n", "\n", "use_cuda = torch.cuda.is_available()\n", "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n", "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n", "Tensor = FloatTensor\n", "\n", "import pandas\n", "import pandas as pd\n", "\n", "import logging\n", "handler=logging.basicConfig(level=logging.INFO)\n", "lgr = logging.getLogger(__name__)\n", "%matplotlib inline\n", "\n", "# !pip install psutil\n", "import psutil\n", "import os\n", "def cpuStats():\n", "        print(sys.version)\n", "        print(psutil.cpu_percent())\n", "        print(psutil.virtual_memory())  # physical memory usage\n", "        pid = os.getpid()\n", "        py = psutil.Process(pid)\n", "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n", "        print('memory GB:', memoryUse)\n", "\n", "cpuStats()"], "outputs": []}, {"metadata": {"_uuid": "68215cb0cc4621aa263706009ab028b2dc7a6eb2", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "fb941080-db5e-4a5b-a777-9eeb8a617234"}, "cell_type": "markdown", "source": ["#  Global params"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "6c6507ce66c8fa3dbd7d37fce6c4ff2d379ead39", "collapsed": true, "_cell_guid": "b8dfa887-cf7b-4caa-bf6a-ec3534ab2067"}, "source": ["# fix seed\n", "seed=17*19\n", "np.random.seed(seed)\n", "torch.manual_seed(seed)\n", "if use_cuda:\n", "    torch.cuda.manual_seed(seed)    \n", "# ! dir    "], "outputs": []}, {"metadata": {"_uuid": "8cb0c2510660f94ddaa1a405f94b4d434dc5a0bd", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "426a5a63-32a5-4ad3-88e0-0ebe08774d16"}, "cell_type": "markdown", "source": ["\n", "#  View the Data"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "013281b3b441e2f21927f2c89837cbbfb23def6a", "collapsed": true, "_cell_guid": "40a56f8e-7e3d-493a-ad91-8b549dabbb8a"}, "source": ["import gc; gc.enable()\n", "# !pip install xgboost\n", "import xgboost as xgb\n", "# http://www.lfd.uci.edu/~gohlke/pythonlibs/#xgboost\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn import *\n", "import sklearn\n", "\n", "# Data params\n", "TARGET_VAR= 'target'\n", "BASE_FOLDER = '../input/'\n", "\n", "# Read in our input data\n", "df_train = pd.read_csv(BASE_FOLDER + '/train.csv')\n", "df_test = pd.read_csv(BASE_FOLDER + '/test.csv')\n", "# This prints out (rows, columns) in each dataframe\n", "print('Train shape:', df_train.shape)\n", "print('Test shape:', df_test.shape)\n", "\n", "print('Columns:', df_train.columns)\n", "\n", "y_train = df_train['target'].values\n", "id_train = df_train['id'].values\n", "id_test = df_test['id'].values\n", "df_train.head()"], "outputs": []}, {"metadata": {"_uuid": "1446cf549e1f3b5247763bbe1c67b076ab2fc57b", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "78c7c4bc-2a85-4a24-a9c1-dfd15a5a9036"}, "cell_type": "markdown", "source": ["#  Train / Validation / Test Split"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "4f4b3bb860aa2fefda962b02db898a90d6f81766", "collapsed": true, "_cell_guid": "961fe1a3-4c06-4353-91f4-6b551bdfe7e7"}, "source": ["x_train = df_train.drop(['target', 'id'], axis=1)\n", "x_test = df_test.drop(['id'], axis=1)\n", "\n", "# Take a random 20% of the dataset as validation data\n", "trainX, valX, trainY, valY = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)\n", "print('Train samples: {} Validation samples: {}'.format(len(trainX), len(valX)))\n", "\n", "N_FEATURES=trainX.shape[1]"], "outputs": []}, {"metadata": {"_uuid": "83e367e376ac2e04c9431ba15f7bc0fbf5c2ba56", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "9e4d1d88-94a9-4723-a80e-ac477654579d"}, "cell_type": "markdown", "source": ["#  From Numpy to PyTorch GPU tensors"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "aaa1cb6a0b3bc888a9314997f88f03c171257667", "collapsed": true, "_cell_guid": "441ae82a-ca40-4bd6-b9fc-5aa62d10ce3a"}, "source": ["use_cuda = torch.cuda.is_available()\n", "# use_cuda = False\n", "\n", "\n", "# Convert the np arrays into the correct dimention and type\n", "# Note that BCEloss requires Float in X as well as in y\n", "def XnumpyToTensor(x_data_np):\n", "    x_data_np = np.array(x_data_np, dtype=np.float32)        \n", "    print(x_data_np.shape)\n", "    print(type(x_data_np))\n", "\n", "    if use_cuda:\n", "        lgr.info (\"Using the GPU\")    \n", "        X_tensor = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n", "    else:\n", "        lgr.info (\"Using the CPU\")\n", "        X_tensor = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n", "    \n", "    print(type(X_tensor.data)) # should be 'torch.cuda.FloatTensor'            \n", "    print((X_tensor.data.shape)) # torch.Size([108405, 29])\n", "    return X_tensor\n", "\n", "\n", "# Convert the np arrays into the correct dimention and type\n", "# Note that BCEloss requires Float in X as well as in y\n", "def YnumpyToTensor(y_data_np):    \n", "    y_data_np=y_data_np.reshape((y_data_np.shape[0],1)) # Must be reshaped for PyTorch!\n", "    print(y_data_np.shape)\n", "    print(type(y_data_np))\n", "\n", "    if use_cuda:\n", "        lgr.info (\"Using the GPU\")            \n", "    #     Y = Variable(torch.from_numpy(y_data_np).type(torch.LongTensor).cuda())\n", "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor).cuda()  # BCEloss requires Float        \n", "    else:\n", "        lgr.info (\"Using the CPU\")        \n", "    #     Y = Variable(torch.squeeze (torch.from_numpy(y_data_np).type(torch.LongTensor)))  #         \n", "        Y_tensor = Variable(torch.from_numpy(y_data_np)).type(torch.FloatTensor)  # BCEloss requires Float        \n", "\n", "    print(type(Y_tensor.data)) # should be 'torch.cuda.FloatTensor'\n", "    print(y_data_np.shape)\n", "    print(type(y_data_np))    \n", "    return Y_tensor"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "915c7a22b4b02a7e66c6005221ca0612ca365e2e", "collapsed": true, "_cell_guid": "033868d8-e25f-4a03-a921-ff44c12fb569"}, "source": ["# class ConvRes(nn.Module):\n", "#     def __init__(self, insize, outsize):\n", "#         super(ConvRes, self).__init__()\n", "#         drate = .3\n", "#         self.math = nn.Sequential(\n", "#             nn.BatchNorm1d(insize),            \n", "#             torch.nn.Conv1d(insize, outsize, kernel_size=2, padding=2),\n", "#             nn.PReLU(),\n", "#         )\n", "#     def forward(self, x):\n", "#         return self.math(x)\n", "\n", "# class ConvCNN(nn.Module):\n", "#     def __init__(self, insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n", "#         super(ConvCNN, self).__init__()\n", "#         self.avg = avg\n", "#         self.math = torch.nn.Sequential(\n", "#             torch.nn.Conv1d(insize, outsize, kernel_size=kernel_size, padding=padding),\n", "#             torch.nn.BatchNorm1d(outsize),\n", "#             torch.nn.LeakyReLU(),\n", "#             torch.nn.MaxPool1d(pool),\n", "#         )        \n", "#     def forward(self, x):\n", "#         x = self.math(x)        \n", "#         return x\n", "\n", "# class SimpleNet(nn.Module):\n", "#     def __init__(self):\n", "#         super(SimpleNet, self).__init__()        \n", "\n", "#         self.cnn1 = ConvCNN(N_FEATURES, 64, kernel_size=7, pool=4, avg=False)\n", "#         self.cnn2 = ConvCNN(64, 64, kernel_size=5, pool=2, avg=True)\n", "#         self.cnn3 = ConvCNN(64, 32, kernel_size=5, pool=2, avg=True)\n", "#         self.res1 = ConvRes(32, 64)\n", "\n", "#         self.features = nn.Sequential(\n", "#             self.cnn1,\n", "# #             self.cnn2,\n", "# #             self.cnn3,\n", "# #             self.res1,\n", "#         )\n", "\n", "#         self.classifier = torch.nn.Sequential(\n", "#             nn.Linear(1024, 1),\n", "#         )\n", "#         self.sig = nn.Sigmoid()\n", "\n", "#     def forward(self, x):\n", "#         x = self.features(x)\n", "#         x = x.view(x.size(0), -1)\n", "#         x = self.classifier(x)\n", "#         x = self.sig(x)\n", "#         return x\n", "    \n", "    \n", "X_tensor_train= XnumpyToTensor(trainX) # default order is NBC for a 3d tensor, but we have a 2d tensor\n", "X_shape=X_tensor_train.data.size()\n", "\n", "\n", "n_mult_factor=9\n", "n_input= trainX.shape[1]\n", "n_hidden= n_input * n_mult_factor\n", "n_output=1\n", "n_input_rows=trainX.shape[0]\n", "n_cnn_kernel=7\n", "n_padding=4\n", "n_max_pool1d=2\n", "\n", "DEBUG_ON=True\n", "def debug(msg, x):\n", "    if DEBUG_ON:\n", "        print (msg + ', (size():' + str (x.size()))\n", "    \n", "class CNNNumerAI(nn.Module):    \n", "    def __init__(self, n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding,n_max_pool1d):\n", "        super(CNNNumerAI, self).__init__()    \n", "        self.n_input=n_input\n", "        self.n_hidden=n_hidden\n", "        self.n_output= n_output \n", "        self.n_cnn_kernel=n_cnn_kernel\n", "        self.n_mult_factor=n_mult_factor\n", "        self.n_padding=n_padding\n", "        self.n_max_pool1d=n_max_pool1d\n", "        self.n_l1=int((n_mult_factor * self.n_input) * (n_padding + 1) / n_max_pool1d)\n", "                    \n", "        self.features = nn.Sequential(  \n", "            torch.nn.Conv1d(self.n_input, self.n_hidden,kernel_size=(self.n_cnn_kernel,), stride=(1,), padding=(self.n_padding,)),                                             \n", "            torch.nn.LeakyReLU(),            \n", "            torch.nn.MaxPool1d(kernel_size=self.n_max_pool1d),\n", "                                    \n", "        )                        \n", "                \n", "        linear4=torch.nn.Linear(int(self.n_hidden), 1)\n", "        torch.nn.init.xavier_uniform(linear4.weight)        \n", "        \n", "        self.classifier = torch.nn.Sequential\n", "                                 (\n", "                                    linear4\n", "                                  )                                 \n", "        self.sig=nn.Sigmoid()\n", "                \n", "        \n", "    def forward(self, x):\n", "        varSize=x.data.shape[0] # must be calculated here in forward() since its is a dynamic size                          \n", "        # for CNN  \n", "        x=x.contiguous() \n", "        x = x.view(varSize,self.n_input,1)\n", "        debug('after view',x)   \n", "        x=self.features(x)\n", "        debug('after CNN',x)           \n", "        x = x.view(varSize,int(self.n_hidden)) \n", "        debug('after 2nd view',x)                  \n", "        x=self.classifier(x)   \n", "        debug('after self.out',x)   \n", "        x=self.sig(x)\n", "        return x\n", "\n", "net = CNNNumerAI(n_input, n_hidden, n_output,n_cnn_kernel, n_mult_factor, n_padding, n_max_pool1d)    \n", "print(net)\n", "\n", "if use_cuda:\n", "    net=net.cuda() \n", "b = net(X_tensor_train)\n", "\n", "print ('(b.size():' + str (b.size()))    \n", "\n", "LR = 0.005\n", "\n", "optimizer = torch.optim.Adam(net.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\n", "loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n", "\n", "if use_cuda:\n", "    lgr.info (\"Using the GPU\")    \n", "    net.cuda()\n", "    loss_func.cuda()\n", "#     cudnn.benchmark = True\n", "\n", "lgr.info (optimizer)\n", "lgr.info (loss_func)"], "outputs": []}, {"metadata": {"_uuid": "5924485871c7b4a5433bfb54fedff46c7e23abed", "_cell_guid": "82efda03-9e61-4901-8f8d-97bf4a36b9da"}, "cell_type": "markdown", "source": ["# Training set"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "f9057e5181309d3c1e7340c70fbe750d87f10af2", "collapsed": true, "_cell_guid": "658daa90-6dda-44f1-b858-9a1de7f47c47"}, "source": ["from __future__ import division\n", "\n", "import time\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "import matplotlib.pyplot as plt\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n", "\n", "# for windows\n", "torch.backends.cudnn.enabled=False\n", "\n", "start_time = time.time()    \n", "epochs=1500 # change to 5000 for better results\n", "div_factor=100\n", "all_losses = []\n", "loss_arr =[]\n", "DEBUG_ON=False\n", "\n", "print (net)\n", "\n", "X_tensor_train= XnumpyToTensor(trainX)\n", "Y_tensor_train= YnumpyToTensor(trainY)\n", "print(type(X_tensor_train.data), type(Y_tensor_train.data)) # should be 'torch.cuda.FloatTensor'\n", "\n", "# CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.\n", "# X_tensor_train=X_tensor_train.contiguous()\n", "# Y_tensor_train=Y_tensor_train.contiguous()\n", "                \n", "# From here onwards, we must only use PyTorch Tensors\n", "for step in range(epochs):    \n", "    out = net(X_tensor_train)                 # input x and predict based on x\n", "    cost = loss_func(out, Y_tensor_train)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n", "\n", "    optimizer.zero_grad()   # clear gradients for next train\n", "    cost.backward()         # backpropagation, compute gradients\n", "    optimizer.step()        # apply gradients\n", "                   \n", "        \n", "    if step % div_factor == 0:        \n", "        loss = cost.data[0]\n", "        all_losses.append(loss)\n", "        print(step, cost.data.cpu().numpy())\n", "        # RuntimeError: can't convert CUDA tensor to numpy (it doesn't support GPU arrays). \n", "        # Use .cpu() to move the tensor to host memory first.        \n", "        prediction = (net(X_tensor_train).data).float() # probabilities         \n", "#         prediction = (net(X_tensor).data > 0.5).float() # zero or one\n", "#         print (\"Pred:\" + str (prediction)) # Pred:Variable containing: 0 or 1\n", "#         pred_y = prediction.data.numpy().squeeze()            \n", "        pred_y = prediction.cpu().numpy().squeeze()\n", "        target_y = Y_tensor_train.cpu().data.numpy()\n", "                        \n", "        tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\n", "        print ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n", "        \n", "        loss_arr.append(cost.cpu().data.numpy()[0])\n", "                \n", "end_time = time.time()\n", "print ('{} {:6.3f} seconds'.format('GPU:', end_time-start_time))\n", "\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "plt.plot(all_losses)\n", "plt.show()\n", "\n", "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n", "roc_auc = auc(false_positive_rate, true_positive_rate)\n", "\n", "plt.title('GINI:' + str(2*roc_auc_score(target_y,pred_y ) - 1))\n", "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n", "plt.legend(loc='lower right')\n", "plt.plot([0, 1], [0, 1], 'r--')\n", "plt.xlim([-0.1, 1.2])\n", "plt.ylim([-0.1, 1.2])\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')\n", "plt.show()\n"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "0ab3b7d76fe6a7961f11a3b67537bf210f502732", "collapsed": true, "_cell_guid": "65efa106-b2fd-490a-bd07-b5aaa276e760"}, "source": ["net.eval()\n", "# Validation data\n", "print (valX.shape)\n", "print (valY.shape)\n", "\n", "X_tensor_val= XnumpyToTensor(valX)\n", "Y_tensor_val= YnumpyToTensor(valY)\n", "\n", "\n", "print(type(X_tensor_val.data), type(Y_tensor_val.data)) # should be 'torch.cuda.FloatTensor'\n", "\n", "predicted_val = (net(X_tensor_val).data).float() # probabilities \n", "# predicted_val = (net(X_tensor_val).data > 0.5).float() # zero or one\n", "pred_y = predicted_val.cpu().numpy()\n", "target_y = Y_tensor_val.cpu().data.numpy()                \n", "\n", "print (type(pred_y))\n", "print (type(target_y))\n", "\n", "\n", "print ('\\n')\n", "tu = (log_loss(target_y, pred_y),roc_auc_score(target_y,pred_y ), 2*roc_auc_score(target_y,pred_y ) - 1)\n", "print ('LOG_LOSS={}, ROC_AUC={}, GINI={}'.format(*tu))  \n", "        \n", "false_positive_rate, true_positive_rate, thresholds = roc_curve(target_y,pred_y)\n", "roc_auc = auc(false_positive_rate, true_positive_rate)\n", "\n", "plt.title('GINI=' + str(2*roc_auc_score(target_y,pred_y ) - 1))\n", "plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.6f' % roc_auc)\n", "plt.legend(loc='lower right')\n", "plt.plot([0, 1], [0, 1], 'r--')\n", "plt.xlim([-0.1, 1.2])\n", "plt.ylim([-0.1, 1.2])\n", "plt.ylabel('True Positive Rate')\n", "plt.xlabel('False Positive Rate')\n", "plt.show()\n", "\n", "# print (pred_y)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a4fae8b85d5470eabe18894a5f92b05f15a3abec", "slideshow": {"slide_type": "slide"}, "collapsed": true, "_cell_guid": "374999bf-3efe-4c64-91d8-4397e02d9363"}, "source": ["# Submission"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "2d965577d79bc18da96e37f60c7ab5c8366bf0a3", "collapsed": true, "_cell_guid": "550b1ed8-b9bd-492f-8659-e0e31ff8a8cf"}, "source": ["# X_df_test = pd.read_csv(BASE_FOLDER + '/test.csv')\n", "# print('Test shape:', X_df_test.shape)\n", "# print('Columns:', X_df_test.columns)\n", "# id_test = X_df_test['id'].values\n", "# X_df_test=X_df_test.apply(lambda x: pandas.to_numeric(x, errors='ignore'))\n", "\n", "\n", "# print (X_df_test.shape)\n", "# columns = ['id', 'target']\n", "# df_pred=pd.DataFrame(data=np.zeros((0,len(columns))), columns=columns)\n", "\n", "\n", "# for index, row in X_df_test.iterrows():\n", "#     rwo_no_id=row.drop('id')    \n", "# #     print (rwo_no_id.values)    \n", "#     x_data_np = np.array(rwo_no_id.values, dtype=np.float32)        \n", "#     if use_cuda:\n", "#         X_tensor_test = Variable(torch.from_numpy(x_data_np).cuda()) # Note the conversion for pytorch    \n", "#     else:\n", "#         X_tensor_test = Variable(torch.from_numpy(x_data_np)) # Note the conversion for pytorch\n", "                    \n", "#     X_tensor_test=X_tensor_test.view(1, trainX.shape[1]) # does not work with 1d tensors            \n", "#     predicted_val = (net(X_tensor_test).data).float() # probabilities     \n", "#     p_test =   predicted_val.cpu().numpy().item() # otherwise we get an array, we need a single float\n", "    \n", "#     df_pred = df_pred.append({'id':row['id'], 'target':p_test},ignore_index=True)\n", "# #     df_pred = df_pred.append({'id':row['id'].astype(int), 'probability':p_test},ignore_index=True)\n", "\n", "# df_pred.head(5)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "74026ada9da4f2f650347f6dd2f3ddb2a659dcdc", "collapsed": true, "_cell_guid": "1e7cb91b-92e5-4be0-b6a5-0dff8742fa67"}, "source": ["# df_pred.id=df_pred.id.astype(int)\n", "\n", "# def savePred(df_pred, loss):\n", "# #     csv_path = 'pred/p_{}_{}_{}.csv'.format(loss, name, (str(time.time())))\n", "#     csv_path = 'pred/pred_{}_{}.csv'.format(loss, (str(time.time())))\n", "#     df_pred.to_csv(csv_path, columns=('id', 'target'), index=None)\n", "#     print (csv_path)\n", "    \n", "# savePred (df_pred, str(2*roc_auc_score(target_y,pred_y ) - 1))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "563253e9bcb548c417b519f1fcde92eafbe8274b", "collapsed": true, "_cell_guid": "b701d421-10a8-46c0-83a0-fb87a9787d0e"}, "source": [], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "be87f3dc85f6c4cc8c17e137326c7370ec38fe19", "collapsed": true, "_cell_guid": "d6bb0ef6-4ade-4df6-99fc-721b95080430"}, "source": [], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "48da4017ccbde49ce469ec49b275637636dc4856", "collapsed": true, "_cell_guid": "63ac94b1-1ffd-4f8d-8831-7ac949dfb6d9"}, "source": [], "outputs": []}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3"}, "livereveal": {"controls": "true", "start_slideshow_at": "selected", "progress": "true", "scroll": "true", "history": "true", "mouseWheel": "true", "overview": "true"}, "anaconda-cloud": {}, "celltoolbar": "Slideshow"}}