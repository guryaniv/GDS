{"cells":[{"metadata":{"_uuid":"6b8bd0a4963deefb968a6504cf1ea47b92f70257"},"cell_type":"markdown","source":"# What's Cooking with bidirectional GRU in Pytorch"},{"metadata":{"_uuid":"06a6f89aa13349712bcc7ce3f5d676b9bd8374a7"},"cell_type":"markdown","source":"> This code uses only Pytorch, but is heavily inspired by fast.ai."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torch.utils.data\nimport collections\nfrom scipy.spatial import KDTree\nfrom tqdm import tqdm_notebook\nimport pdb\n\nfrom pathlib import Path\npath = Path(\"../input\")\nlist(path.iterdir())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"015dd083e271f12ba87d69e035a8878e5f1994f0"},"cell_type":"code","source":"#Make sure GPU is on \ntorch.cuda.device_count()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Read in training data\nfullDF = pd.read_json(path/\"train.json\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"560f30774d523420d6987c8b23d9273d944d7ca7"},"cell_type":"code","source":"#Create a list of all unique ingredients\nvocab = list({s for l in fullDF.ingredients for s in l})\nstoi = collections.defaultdict(lambda: len(vocab),{s:i for i,s in enumerate(vocab)})\npadIdx = len(vocab)+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"837367caf0f10ad9e830b980fb3f321c03c46a49"},"cell_type":"code","source":"#Set cuisine type as a categorical column\nfullDF.cuisine = fullDF.cuisine.astype(\"category\")\n\n#Create new column, to be passed to the model, which contains an array of ingredients by position in the vocab array\nfullDF[\"x\"] = fullDF.ingredients.apply(lambda l: np.array([stoi[s] for s in l]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8760829b2ac2b1095d856d1b6f0ea35a366dfa33"},"cell_type":"code","source":"nCuisines = len(fullDF.cuisine.cat.categories)\n#Dictionary which converts cuisine index to string value\nitosCuisine = {i:c for i,c in enumerate(fullDF.cuisine.cat.categories)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d16dbef5e88a6575a3e65fa064eaceac8fb95850"},"cell_type":"code","source":"#Our processed dataframe\nfullDF.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"707620bfb3c5f108fc390abba8f4cbee87c0e392"},"cell_type":"code","source":"#Extremely basic dataset class\nclass RecipeDataset(torch.utils.data.Dataset):\n    def __init__(self,x,y):\n        self.x, self.y = x,y\n        \n    def __len__(self): return len(self.x)\n    \n    def __getitem__(self,idx): return self.x[idx], self.y[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b615dcbb8ca21c31bdec7eb56b1ae648ff67d5d1"},"cell_type":"code","source":"#Split train/valid sets\nnp.random.seed(5342)\nvalDF = fullDF.sample(frac=0.15,replace=False)\ntrainDF = fullDF[~fullDF.index.isin(valDF.index)]\nassert len(valDF) + len(trainDF) == len(fullDF)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3878c8ced42b8b48b29cb8d249670d296dc6e108"},"cell_type":"code","source":"#Create three different datasets. fullDS contains all rows in training data\nfullDS = RecipeDataset(fullDF.x.values,fullDF.cuisine.cat.codes.values)\ntrainDS = RecipeDataset(trainDF.x.values,trainDF.cuisine.cat.codes.values)\nvalDS = RecipeDataset(valDF.x.values,valDF.cuisine.cat.codes.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f45b03a8f101ed2269f3fdba80de9c79333914d7"},"cell_type":"code","source":"#Custom collate function which takes a batch of samples and embeds them in a tensor (sequence length,batch size), padded out to the max ingredient list length of the batch\ndef collate(samples):\n    bs = len(samples)\n    maxLen = max(len(s[0]) for s in samples)\n    out = torch.zeros(maxLen,bs,dtype=torch.long) + padIdx\n    for i,s in enumerate(samples):\n        out[:len(s[0]),i] = torch.tensor(s[0],dtype=torch.long)\n    return out.cuda(), torch.tensor([s[1] for s in samples],dtype=torch.long).cuda()\n\n#Create the dataloaders\nbs = 64\ntrainDL = torch.utils.data.DataLoader(trainDS,bs,shuffle=True,collate_fn=collate)\nvalDL = torch.utils.data.DataLoader(valDS,bs,collate_fn=collate)\nfullDL = torch.utils.data.DataLoader(fullDS,bs,collate_fn=collate,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"469b8b49f528fea5e5060ad7677a093ab52247c4"},"cell_type":"code","source":"#copied from https://github.com/fastai/fastai/blob/master/fastai/layers.py#L116, implements He initialization for the embedding layer\ndef trunc_normal_(x:torch.tensor, mean:float=0., std:float=1.) -> torch.tensor:\n    \"Truncated normal initialization.\"\n    # From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12\n    return x.normal_().fmod_(2).mul_(std).add_(mean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8efe249bac821665d7011d6987c9b65e8a3f970a"},"cell_type":"markdown","source":"This is the class for the model. The first layer is an embedding matrix, which maps each ingredient to a vector. Next is the GRU, which encodes the list of ingredients. The last timestep of output from the GRU is then put through a linear layer, which outputs a vector of size nCuisines. Dropout is added at each layer. \n\nThe approach is to use a large number of parameters, while also utilizing large amounts of regularization, specifically dropout and weight decay. "},{"metadata":{"trusted":true,"_uuid":"76547533234c85da48f0da6cd5914637b1ff00ad"},"cell_type":"code","source":"class CuisineNet(torch.nn.Module):\n    def __init__(self,nIngred,embSize,hiddenSize,nCuisines):\n        super().__init__()\n        self.hiddenSize = hiddenSize\n        self.ingredEmb = torch.nn.Embedding(nIngred,embSize,padding_idx = padIdx)\n        self.embDropout = torch.nn.Dropout(0.5)\n        with torch.no_grad(): trunc_normal_(self.ingredEmb.weight, std=0.01) # Use He initilization on the embedding layer\n        self.ingredEnc = torch.nn.GRU(embSize,hiddenSize,2,dropout=0.90,bidirectional=True)\n        self.encDropout = torch.nn.Dropout(0.5)\n        self.out = torch.nn.Linear(hiddenSize*2,nCuisines)\n        \n    def forward(self,inp):\n        sl, bs = inp.size()\n        inp = self.embDropout(self.ingredEmb(inp))\n        enc,h = self.ingredEnc(inp,torch.zeros(4,bs,self.hiddenSize).cuda())\n        #Since we are using a bidrectional GRU, we need to concat the forward state to the backward state, then pass it to the output layer\n        return self.out(self.encDropout(torch.cat([h[-2],h[-1]],dim=1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e84bf772810b7ec4dfa11bd0efd193ab46d2c3b8","scrolled":true},"cell_type":"code","source":"#initialize the model. The number of embeddings it two larger than the vocab size, since we need embeddings for padding and unknown. The embedding dimension is 100, and the \n#hidden size of the GRU is 400 (since it is bidrectional, we end up with an output of size 800).\nmodel = CuisineNet(len(vocab)+2,100,400,nCuisines).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c31d56a7c605f61a022b10c4cb8c8f516d50990"},"cell_type":"code","source":"#Grab a batch from the dataloader, and pass it through the model to make sure the output shape is correct\nx,y = next(iter(trainDL))\nmodel(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62fcabe561fbfd1240680a6abc2faba896d8ad1a"},"cell_type":"code","source":"#function to calculate the average accuracy of a batch\ndef batchAccuracy(preds,target):\n    preds = torch.softmax(preds,dim=1)\n    preds = torch.argmax(preds,dim=1)\n    o = (preds == target).sum().item()\n    return o / len(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c7e6d0c80a6be4045418aa86517e635b3d59b0e"},"cell_type":"code","source":"#fit function\ndef learn(model,epochs,lr,trainDL,valDL=None):\n    lossFn = torch.nn.functional.cross_entropy\n    optimizer = torch.optim.Adam(model.parameters(),lr=lr,amsgrad=True,weight_decay=5e-4)\n\n    for e in tqdm_notebook(range(epochs)):\n        model.train()\n        with tqdm_notebook(iter(trainDL),leave=False) as t:\n            bloss, n = 0.0,0\n            for x,y in t:\n                pred = model(x)\n                loss = lossFn(pred,y)\n                bloss += loss.item()\n                n += 1\n                t.set_postfix({\"loss\": bloss / n})\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            print(f\"Epoch {e+1} Training Set Loss: {bloss / n}\")\n        if valDL is not None:\n            model.eval()\n            with torch.no_grad():\n                loss,accuracy,n =0.0,0.0,0\n                for x,y in tqdm_notebook(iter(valDL),leave=False):\n                    pred = model(x)\n                    loss += lossFn(pred,y)\n                    accuracy += batchAccuracy(pred,y)\n                    n += 1\n                print(f\"Validation Set Loss: {loss / n}, Accuracy: {accuracy / n}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"a4e912f0f19939940f441ad03d84412116e81609"},"cell_type":"code","source":"#For some reason tqdm progress bars don't display correctly in the kernel (bar is missing).\n\n#The model is trained for 18 epochs, lowering the learning rate every 6 epochs\nlearn(model,6,1e-3,fullDL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed32ccb79d793b69a8f470bcdf997a980d97188a"},"cell_type":"code","source":"learn(model,6,1e-4,fullDL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72c8970501a75f454aca042a525ea9eb9620ba8d"},"cell_type":"code","source":"learn(model,6,1e-5,fullDL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01cc72161b2969d7943f2fe5f30747a0a6591abe"},"cell_type":"code","source":"torch.save(model.state_dict(),\"model.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10c7a70e67ecd23246a490d390c227123b1d6ac4"},"cell_type":"code","source":"testDF = pd.read_json(path/\"test.json\")\ntestDF[\"x\"] = testDF.ingredients.apply(lambda l: np.array([stoi[s] for s in l]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"8c20f904e4057792e074a97038f6d7da530ecdbc"},"cell_type":"code","source":"testDS = RecipeDataset(testDF.x.values,testDF.id.values)\ntestDL = torch.utils.data.DataLoader(testDS,bs,collate_fn=collate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a450e36a773a8b30ce20aa314b68144f98be003"},"cell_type":"code","source":"def testModel():\n    o = []\n    model.eval()\n    with torch.no_grad():\n        for x,ids in tqdm_notebook(iter(testDL),leave=False):\n            preds = model(x)\n            preds = torch.softmax(preds,dim=1)\n            preds = torch.argmax(preds,dim=1)\n            for c,id in zip(preds,ids): o.append([id.item(),itosCuisine[c.item()]])\n    return pd.DataFrame(o,columns=[\"id\",\"cuisine\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"922cf07b5e05a992ebfc6000490dc8f9094267ed"},"cell_type":"code","source":"t = testModel()\nt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dfba1d44da342a841c0f613434f77978a0c1173"},"cell_type":"code","source":"t.to_csv(\"out.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}