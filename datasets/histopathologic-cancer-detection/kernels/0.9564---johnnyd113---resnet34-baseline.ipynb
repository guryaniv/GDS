{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"In this kernel I will use the Fastai library which is built on top of pytorch. The notebook follows a similar workflow followed in lessons 1 and 2 of the <a href='https://course.fast.ai/'>Practical Deep Learning for Coders, v3</a> course taught by Jermey Howard. I used to use Keras for deep learning but found fastai to give better results, and use fewer lines of code. \n\nI also used some code from Gunther's <a href='https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169'> [fastai v1] Densenet169</a> kernel so you should check that one out as well. I commented the code I used from that kernel."},{"metadata":{"_uuid":"2c744a0bd39bbe06f7651acc628ac8823e4ad7ff"},"cell_type":"markdown","source":"Be sure to turn the kernel GPU on and select Internet connected in the settings on the bottom right. Without the internet connection it will give you an error loading the pytorch pretrained model."},{"metadata":{"trusted":true,"_uuid":"30ed0df917b8ab1f6dac882d1f770db56b256652"},"cell_type":"code","source":"#Imports\nfrom fastai.vision import *\nfrom sklearn.metrics import roc_auc_score\nnp.random.seed(11)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"505a250931bad54de65284c0f5b1aad9f0f7c08c"},"cell_type":"code","source":"bs = 1024  #Sets batch size\npath = Path('../input/') #Sets path to data\nsz = 96 #Pixel size of images (96, 96)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be09428cab3db4800937cc405aded1e23e76d1dd"},"cell_type":"code","source":"#Read in the data\ndf = pd.read_csv(path/'train_labels.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90af06fc8a966d806da056823af2f769e5c7a9b"},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4ee5093893d44b15fe0ca1588724d9ff358e349"},"cell_type":"code","source":"#Check percentage images with label=1\ndf.iloc[:,1].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f0d217d49dca70097dd61135e3f8a20daa6ed7d"},"cell_type":"markdown","source":"About 40% of our data is positive."},{"metadata":{"trusted":true,"_uuid":"c513a86f69fc9eb5503a03fb565615c683dc09e6"},"cell_type":"code","source":"#Take a sample\ndf = df.sample(n=25000, random_state=11)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6a1298f8b5555502f144c844087e6b8e0458957"},"cell_type":"markdown","source":"There is no need to train on all 200000+ samples for a baseline. Taking a sample lets us train and test ideas quicker"},{"metadata":{"trusted":true,"_uuid":"b8e5cdebaec37f88db6d4711d76a83cf977545e9"},"cell_type":"code","source":"#Data tranformation function\ntfms = get_transforms(flip_vert=True,max_warp=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13cee949ceba55781febe4d8873940e0e3e720e4"},"cell_type":"markdown","source":"We can set flip_vert=True because the histopathic images are top down images so its okay to flip the image in any direction. The default flip_vert value is false in fastai. We also set warp=0 because none of the images in the data are warped."},{"metadata":{"trusted":true,"_uuid":"7a0d8fb40c429771e3fd7416341a2ff0bb400d6d"},"cell_type":"code","source":"#Read the data in from the dataframe\ndata = (ImageDataBunch.from_df(path,           #Path the data is stored in\n                               df=df,          #Dataframe with image filenames and labels\n                               folder='train', #Folder contatining train+validation images\n                               suffix='.tif',  #Suffix of the image names\n                               ds_tfms=tfms,   #Apply the defined transformations\n                               size=sz,        #Set the image pixel size (96, 96)\n                               bs=bs,          #Set the batch size (1024)\n                               test='test',    #Set the folder contatining test images\n                               num_workers=0)  #Need to assign num_workers when running in kernel\n                               .normalize())   #Normalize the data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"283238febfb3b47eca91620011b69ccd8d457eb2"},"cell_type":"markdown","source":"The .normalize() should get the mean and standard deviation from the training data and apply the same mean subtraction and standard deviation  division to the train, validation, and test data. The validation data is by default set to 20% of the training data."},{"metadata":{"trusted":true,"_uuid":"b0266ff95e55ed4d3ae2bb3f5f43a56d1b18c673"},"cell_type":"code","source":"#Display a few images\ndata.show_batch(rows=3, figsize=(7,5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da5a95e232e86ef4765a2daa2bf4195f02b52f38"},"cell_type":"markdown","source":"Images are displayed with their label."},{"metadata":{"trusted":true,"_uuid":"f622f8b24ead61172fa9cb96545f5e280361118b"},"cell_type":"code","source":"#https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169\n#Define auc metric to track while training\ndef auc_score(y_pred,y_true,tens=True):\n    score=roc_auc_score(y_true,torch.sigmoid(y_pred)[:,1])\n    if tens:\n        score=tensor(score)\n    else:\n        score=score\n    return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82beb09ea82c8af337145a24ca55038c6d7e3de9"},"cell_type":"code","source":"#Create our cnn\nlearn = create_cnn(data, models.resnet34, metrics=auc_score,path='.')\n#Need to assign model path when running in kernel","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70971690591c2655f7e3abafedd46de1115d4c61"},"cell_type":"markdown","source":"This creates our ResNet34 model with pretrained weights. This creates a learner that will have ResNet34 architecture, use the DataBunch we created earlier, and track auc score at the end of each epoch. \n\nFastai fit_one_cycle implements cyclical learning rates from Smith's paper<a href='https://arxiv.org/abs/1506.01186'>\nCyclical Learning Rates for Training Neural Networks</a>. As descibed in the paper 'this method lets the learning rate cyclically vary between reasonable boundary values. Training with cyclical learning rates instead of fixed values achieves improved classification accuracy without a need to tune and often in fewer iterations.' \n"},{"metadata":{"trusted":true,"_uuid":"f15a6c08c7deba6bb4c100fb0a5ca6d7625b914b"},"cell_type":"code","source":"lr = 3e-3 #Assign learning rate\n\n#This trains our added layers for two epochs with ResNet layers frozen\nlearn.fit_one_cycle(3, lr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43121b9a6fabca12fc77b3d4b1d33f3025f76acd"},"cell_type":"markdown","source":"In the lectures learn.lr_find() was used to find a learning rate before any training. The kernel was running really slow so I removed it. Learning rates between 1e-3 to 3e-3 tend to work pretty well for the first round of training. Next I plot the learning rate to get a better understand of what fit_one_cycle() is doing."},{"metadata":{"trusted":true,"_uuid":"a53445d413517c7f82b8e591e55aa62710ccee2a"},"cell_type":"code","source":"#Plot the learning rates to see the change over iterations\nlearn.recorder.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"460b1806be85f93f621b3e126b1f8aa56cd53f84"},"cell_type":"markdown","source":"Now with the added dense layers trained with reasonable parameters, we can unfreeze the earlier layers of the ResNet model and fine tune them for our task. \n\nWe will also set a range of learning rates. We want the earlier layers of our model to have lower learning rates than the later layers. This is because the earlier layers find general features like a line/edge which we do not want to disrupt. "},{"metadata":{"trusted":true,"_uuid":"181c71072a38830dc7b7f688ce1868f6c515f735"},"cell_type":"code","source":"#Unfreezes all layers\nlearn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1e5f939f87a52fb2314e62fc636951fea384afd"},"cell_type":"markdown","source":"First we implement the learning rate finder. You can do this before training the first layers of the model, but I chose not to in this notebook because it was taking to long in the kernel."},{"metadata":{"trusted":true,"_uuid":"c3c20918e20c5a7f677d0d034d2848bf183aaf0d"},"cell_type":"code","source":"#Find optimal learning rate\nlearn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59fe93f6528605ecddb06cb8e8581abbe16aa14d"},"cell_type":"code","source":"#Observe learning rate increase through every iteration\nlearn.recorder.plot_lr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e720ced92e4b3e58e55e23f3764ff60b93b0ff9b"},"cell_type":"code","source":"#Observe the loss as we increase learning rate\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6738fb020e8ca8565a858e136d792c3f21f318d"},"cell_type":"markdown","source":"A general rule of thumb mentioned in one of the lectures to set the learning rates after unfreezing the layers is to:\n\n1) Set the first learning rate at a rate where we still see the steepest drop in loss in the plot above. Sometimes thats not very clear so you want to atleast make sure its 10X smaller than the learning rate where the loss starts to increase.\n\n2) Set the second learning rate (used for the later dense layers) to 1/5 or 1/10 of our starting learning rate we initially used to train the model."},{"metadata":{"trusted":true,"_uuid":"dde2d74f22270009340cc299b3be671428750018"},"cell_type":"code","source":"learn.fit_one_cycle(5, max_lr=slice(5e-4, lr/5))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c828c0c4161a9698c91d90cf969f99ea4f68377a"},"cell_type":"markdown","source":"With less than 10% of the data we are able to quickly build a model with a high AUC. Our validation score is still getting better so the model can be trained for more epochs."},{"metadata":{"_uuid":"fc57f1c741ceb6161d380f41126e121f55ff3165"},"cell_type":"markdown","source":"There are plenty of steps to take from here:\n\n1. Plot the images the model predicted wrong with high confidence\n\n2. Try different data augmentations with the get_transforms() function.\n\n3. Try different learning rates and training for more epochs\n\n4. Use more data\n\n5. Try a more complex model\n\n6. Predict with test time augmentation"},{"metadata":{"_uuid":"58585f1355af0a09337ed8bf7bc7851ebbe3232f"},"cell_type":"markdown","source":"Submission code was used from <a href='https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169'> [fastai v1] Densenet169</a>. That kernel also shows you how to implement test time augmentation which can increase your LB score."},{"metadata":{"trusted":true,"_uuid":"7067ffe003bc3a9cc626e85d5c3c290ccd4a3669"},"cell_type":"code","source":"preds_test,y_test=learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3f1fbfcc171cddfd9c669f2494fe6092dbe0100"},"cell_type":"code","source":"sub=pd.read_csv(path/'sample_submission.csv').set_index('id')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3624c30275a66b18cb3b937116c87f85e6333d87"},"cell_type":"code","source":"#https://www.kaggle.com/guntherthepenguin/fastai-v1-densenet169\nclean_fname=np.vectorize(lambda fname: str(fname).split('/')[-1].split('.')[0])\nfname_cleaned=clean_fname(data.test_ds.items)\nfname_cleaned=fname_cleaned.astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"558e1aa11092e0f837d1ac29a5db02bb5d491f7c"},"cell_type":"code","source":"sub.loc[fname_cleaned,'label']=to_np(preds_test[:,1])\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"060ce748258d140dd8ce5fb7c217ab7a70e989e7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}