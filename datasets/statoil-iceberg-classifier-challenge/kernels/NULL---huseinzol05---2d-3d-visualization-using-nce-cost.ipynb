{"cells": [{"outputs": [], "metadata": {"_cell_guid": "c8fce719-3599-43fc-bb00-22094f973975", "_uuid": "ad2662b89d27ca32edade97f1167447d88f3f102"}, "cell_type": "code", "source": ["import numpy as np\n", "import tensorflow as tf\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import plotly.offline as py\n", "py.init_notebook_mode(connected = True)\n", "import plotly.graph_objs as go\n", "import seaborn as sns\n", "sns.set()"], "execution_count": 1}, {"source": ["This notebook will show you how to use deep convolutional neural network with Noise-contrastive estimation.\n", "\n", "The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.\n", "\n", "You can read more about [NCE cost function here](http://proceedings.mlr.press/v9/gutmann10a/gutmann10a.pdf)"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["df = pd.read_json('../input/train.json')\n", "df.inc_angle = df.inc_angle.replace('na', 0)\n", "df.inc_angle = df.inc_angle.astype(float).fillna(0.0)"], "execution_count": 2}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n", "x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n", "X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n", "                          , x_band2[:, :, :, np.newaxis]\n", "                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\n", "X_angle_train = np.array(df.inc_angle)\n", "y_train = np.array(df[\"is_iceberg\"])"], "execution_count": 3}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["# just take 200 dataset to do visualization\n", "# we assume this 200 able to generalize the whole dataset\n", "# if not enough, increase the number\n", "X_train = X_train[:500]\n", "y_train = y_train[:500].reshape((-1, 1))\n", "X_angle_train = X_angle_train[:500].reshape((-1, 1))\n", "learning_rate = 0.001\n", "boundary = [-1, 1]\n", "batch_size = 20\n", "dimension_size = 300\n", "epoch = 30"], "execution_count": 4}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["class Model:\n", "\n", "    def __init__(self, vocabulary_size):\n", "        self.X = tf.placeholder('float', [None, 75, 75, 3])\n", "        self.X_angle = tf.placeholder('float', (None, 1))\n", "        self.Y = tf.placeholder('float', [None, 1])\n", "\n", "        def conv_layer(x, conv, out_shape, name, stride = 1):\n", "            w = tf.Variable(tf.truncated_normal([conv, conv, int(x.shape[3]), out_shape]), name = name + '_w')\n", "            b = tf.Variable(tf.truncated_normal([out_shape], stddev = 0.01), name = name + '_b')\n", "            return tf.nn.conv2d(x, w, [1, stride, stride, 1], padding = 'SAME') + b\n", "\n", "        def pooling(x, k = 2, stride = 2):\n", "            return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, stride, stride, 1], padding = 'SAME')\n", "\n", "        with tf.name_scope(\"conv5-16\"):\n", "            conv1 = tf.nn.sigmoid(conv_layer(self.X, 5, 16, '16'))\n", "\n", "        with tf.name_scope(\"maxpool-1\"):\n", "            pooling1 = pooling(conv1)\n", "            \n", "        with tf.name_scope(\"conv5-32\"):\n", "            conv2 = tf.nn.sigmoid(conv_layer(pooling1, 5, 32, '32'))\n", "    \n", "        with tf.name_scope(\"maxpool-2\"):\n", "            pooling2 = pooling(conv2)\n", "\n", "        with tf.name_scope(\"conv5-64\"):\n", "            conv3 = tf.nn.sigmoid(conv_layer(pooling2, 5, 64, '64'))\n", "\n", "        with tf.name_scope(\"maxpool-3\"):\n", "            pooling3 = pooling(conv3)\n", "\n", "        with tf.name_scope(\"conv5-128\"):\n", "            conv4 = tf.nn.sigmoid(conv_layer(pooling3, 5, 128, '128'))\n", "\n", "        with tf.name_scope(\"maxpool-4\"):\n", "            pooling4 = pooling(conv4)\n", "            \n", "        with tf.name_scope(\"conv5-256\"):\n", "            conv5 = tf.nn.sigmoid(conv_layer(pooling4, 5, 256, '256'))\n", "\n", "        with tf.name_scope(\"maxpool-5\"):\n", "            pooling5 = pooling(conv5)\n", "\n", "        output_shape = int(pooling5.shape[1]) * int(pooling5.shape[2]) * int(pooling5.shape[3])\n", "        pooling5 = tf.reshape(pooling5, [-1, output_shape])\n", "        pooling5 = tf.concat([pooling5, self.X_angle], axis = 1)\n", "        embeddings = tf.Variable(tf.random_uniform([output_shape + 1, dimension_size], boundary[0], boundary[1]))\n", "        embeddings = tf.matmul(pooling5, embeddings)\n", "        nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, dimension_size], stddev = 1.0 / np.sqrt(dimension_size)))\n", "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n", "        self.loss = tf.reduce_mean(tf.nn.nce_loss(weights = nce_weights, biases = nce_biases, labels = self.Y,\n", "                                                  inputs = embeddings, num_sampled = batch_size, num_classes = vocabulary_size))\n", "\n", "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n", "        norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims = True))\n", "        self.normalized_embeddings = embeddings / norm"], "execution_count": 5}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["sess = tf.InteractiveSession()\n", "model = Model(X_train.shape[0])\n", "sess.run(tf.global_variables_initializer())\n", "for i in range(epoch):\n", "    total_loss = 0\n", "    for k in range(0, (X_train.shape[0] // batch_size) * batch_size, batch_size):\n", "        loss, _ = sess.run([model.loss, model.optimizer], feed_dict = {model.X: X_train[k: k + batch_size, :, :, :], \n", "                                                                       model.X_angle: X_angle_train[k: k + batch_size, :],\n", "                                                                       model.Y: y_train[k: k + batch_size, :]})\n", "    total_loss += loss\n", "    print('epoch: ', i, 'avg loss: ', total_loss / (X_train.shape[0] // batch_size))"], "execution_count": 6}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": ["vector_out = sess.run(model.normalized_embeddings, feed_dict = {model.X: X_train, model.X_angle: X_angle_train})"], "execution_count": 7}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["from sklearn.manifold import TSNE\n", "embed_2d = TSNE(n_components = 2).fit_transform(vector_out)\n", "embed_3d = TSNE(n_components = 3).fit_transform(vector_out)"], "execution_count": 8}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["plt.figure(figsize=(8, 5))\n", "label = ['ship', 'ice']\n", "colors = sns.color_palette(n_colors = len(label))\n", "y_train_reshape = y_train.reshape([-1])\n", "for no, _ in enumerate(np.unique(y_train_reshape)):\n", "    plt.scatter(embed_2d[y_train_reshape == no, 0], embed_2d[y_train_reshape == no, 1], c = colors[no], label = label[no])\n", "plt.legend()\n", "plt.show()"], "execution_count": 11}, {"outputs": [], "metadata": {}, "cell_type": "code", "source": ["data_graph = []\n", "from ast import literal_eval\n", "# i love these colors, dont judge me\n", "colors = ['rgb(0,31,63)', 'rgb(255,133,27)']\n", "for no, _ in enumerate(np.unique(y_train_reshape)):\n", "    graph = go.Scatter3d(\n", "    x = embed_3d[y_train_reshape == no, 0],\n", "    y = embed_3d[y_train_reshape == no, 1],\n", "    z = embed_3d[y_train_reshape == no, 2],\n", "    name = label[no],\n", "    mode = 'markers',\n", "    marker = dict(\n", "        size = 12,\n", "        line = dict(\n", "            color = '#%02x%02x%02x' % literal_eval(colors[no][3:]),\n", "            width = 0.5\n", "            ),\n", "        opacity = 0.5\n", "        )\n", "    )\n", "    data_graph.append(graph)\n", "    \n", "layout = go.Layout(\n", "    scene = dict(\n", "        camera = dict(\n", "            eye = dict(\n", "            x = 0.7,\n", "            y = 0.7,\n", "            z = 0.7\n", "            )\n", "        )\n", "    ),\n", "    margin = dict(\n", "        l = 0,\n", "        r = 0,\n", "        b = 0,\n", "        t = 0\n", "    )\n", ")\n", "fig = go.Figure(data = data_graph, layout = layout)\n", "py.iplot(fig, filename = '3d-scatter')"], "execution_count": 14}, {"source": ["Tada! It is beautiful! scattered neatly! I can say, this one is very hard to classify with perfect score"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "metadata": {"collapsed": true}, "cell_type": "code", "source": [], "execution_count": null}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "version": "3.6.3", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python"}}}