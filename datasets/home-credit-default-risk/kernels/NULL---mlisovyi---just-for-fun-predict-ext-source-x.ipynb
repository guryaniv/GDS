{"cells":[{"metadata":{"_uuid":"e44e5ca4e44464ffdcce0e840c543577bd6569bf"},"cell_type":"markdown","source":"# Regression model to predict missing EXT_SOURCE_x values\nThe goal is to build a regression model to predict `EXT_SOURCE_x` values based on other features (as the external scoring agencies might have done to get those numbers)."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n#set a fun plot style\n#plt.xkcd()\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport lightgbm as lgb\n\nimport os\nPATH = \"../input/\"\nprint(os.listdir(PATH))","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"0ed4d74b3e586cc5b1be41bf67756e370b86186a"},"cell_type":"markdown","source":"## Read in the data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"application_train = pd.read_csv(PATH+'application_train.csv')","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"5fb1ac77952823a894bede3dc852b942bf6ee4a7"},"cell_type":"markdown","source":"## Drop several less useful columns"},{"metadata":{"trusted":true,"_uuid":"170d685eee2e20f41824e19342d55426963a53dc","collapsed":true},"cell_type":"code","source":"cols_2drop = [f_ \n              for f_ in application_train.columns \n              if 'FLAG_DOCUMENT' in f_ \n              or 'AVG' in f_\n              or 'MODE' in f_\n              or 'MEDI' in f_]\ncols_2drop += ['SK_ID_CURR', 'TARGET']","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dc6b91ace65ae540ab2c59afc691fd8767b1606","collapsed":true},"cell_type":"code","source":"y=application_train['TARGET']\napplication_train.drop(cols_2drop, axis=1, inplace=True)","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"6d5bca8a942f037df055bcc021f936a7b485e585"},"cell_type":"markdown","source":"## Ordered/binary category encoding\nLightGBM can handle categorical features internally, however, we can add ordering for those features, where it is applicable and to simple 0/1 encoding for binary N/Y features"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1a91dc362e45c1452f390d93d0ce858cd923813"},"cell_type":"code","source":"encoding = {'NAME_CONTRACT_TYPE': {'Cash loans': 1, 'Revolving loans': 0},\n            'FLAG_OWN_CAR': {'N': 0, 'Y': 1},\n            'FLAG_OWN_REALTY': {'N': 0, 'Y': 1},\n            'CODE_GENDER': {'M':0, 'F':1, 'XNA':np.nan},\n            'NAME_EDUCATION_TYPE': {'Lower secondary': 0,\n                                    'Secondary / secondary special': 1,\n                                    'Incomplete higher': 2,\n                                    'Higher education': 3,\n                                    'Academic degree': 4}\n           }","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9bf5a8b1a91f439d95bc174d1ccc7c69c8817ccc"},"cell_type":"code","source":"for c_, map_ in encoding.items():\n    application_train[c_] = application_train[c_].replace(map_)","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"71c27fc3a7ab4c86fc560344d94b621228104ee8"},"cell_type":"markdown","source":"## Convert 'object' types into 'category'"},{"metadata":{"trusted":true,"_uuid":"e4bb4f28e8b5b3501bc831dbd14428175966ed32","collapsed":true},"cell_type":"code","source":"cat_cols = application_train.select_dtypes(include='object')","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53723cec91b69ab468249cd6f00d98aeeb6fcf06","collapsed":true},"cell_type":"code","source":"for c in cat_cols.columns:\n    application_train[c] = application_train[c].astype('category')","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"17896c93d14cf94768076a8f10ab58498466bb61"},"cell_type":"markdown","source":"Just for info, let's look at the classes in the remaining categories"},{"metadata":{"trusted":true,"_uuid":"fb320737908a8966d188eb0cde632f3757d65318","collapsed":true},"cell_type":"code","source":"for c in cat_cols.columns:\n    print('======== {} =========='.format(c))\n    print(cat_cols[c].value_counts())","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"20b4333f9532045e68d3ea0fb4a27126097d10ae"},"cell_type":"markdown","source":"## Look at the missing values"},{"metadata":{"trusted":true,"_uuid":"c06ff70307ea0c909d9488f528dab543e1e7835d","collapsed":true},"cell_type":"code","source":"# replace DAYS_EMPLOYED == 365243\napplication_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"62e4ded65a763634012e6e14fd69d63988b547cc"},"cell_type":"code","source":"null_train = application_train.isnull()","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb3a1f4840e97105bc6a9a43fc1cc5e7c47d4070","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(18,20))\nsns.heatmap(null_train.T)#.iloc[:100000,:]","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"1082e78608a2cb15c0e95dbc97598d2520227a73"},"cell_type":"markdown","source":"### Closer look on EXT_SOURCE missing values"},{"metadata":{"trusted":true,"_uuid":"e8b2a0f9043b73f5dd692bb54e732696a9687637","collapsed":true},"cell_type":"code","source":"cols_ext = ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']\n\nplt.figure(figsize=(18,6))\nsns.heatmap(null_train.loc[:,cols_ext].T)","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"2a5cf8e4b93742981510b9fe346dc5b46c8e1c83"},"cell_type":"markdown","source":"Clearly, `EXT_SOURCE_2` has very small number of missing values, while `EXT_SOURCE_3` has a larger fraction, and `EXT_SOURCE_1` are missing even more often."},{"metadata":{"_uuid":"7cb5de178ea5e51bb17848388cc28e82054cae90"},"cell_type":"markdown","source":"## What do EXT_SOURCE values correlate with"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"23155cf161b1007aa2fff01876fd141423887db7"},"cell_type":"code","source":"corr_train = application_train.corr()","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecbb184606fd38eb2cc44741841362cd038f23a0","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(6,10))\nsns.heatmap(corr_train[[f_ for f_ in application_train.columns if \"EXT_\" in f_]], cmap='BrBG', vmin=-1, vmax=1)\nplt.savefig('ext_source_corr.png')","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"bf17fb7c56402dfcbb2fe5244a20f882823ee2e1"},"cell_type":"markdown","source":"`EXT_SOURCE_2` is clearly strongly correlated with the applicant age."},{"metadata":{"_uuid":"4c81411dd18ee176c8496451040f0bfcd73756c0"},"cell_type":"markdown","source":"## Define a function for classifier fitting"},{"metadata":{"trusted":true,"_uuid":"2b3da1e93b4c97417477ec4361419df39c4325d2","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfolds = KFold(n_splits= 5, shuffle=True, random_state=101)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2c2a9d7deef493f8a8a234812f2af00cbdfea1dd"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\ndef train_model(X_, y_, folds_):\n    \n    score = 0\n    feat_imp  = np.zeros(X_.shape[1])\n    oof_preds = np.zeros(X_.shape[0])\n    \n    for n_fold, (trn_idx, val_idx) in enumerate(folds_.split(X_, y_)):\n        X_train, y_train = X_.iloc[trn_idx], y_.iloc[trn_idx]\n        X_val, y_val     = X_.iloc[val_idx], y_.iloc[val_idx]\n    \n        clf = lgb.LGBMClassifier(learning_rate=0.05,\n                         num_leaves=10,\n                         max_depth=-1, n_estimators=5000,\n                         colsample_bytree=0.9, subsample=0.9,\n                         reg_alpha=0.1, reg_lambda=0.1,\n                         metric='None',\n                         random_state=314, min_child_samples=100,\n                         silent=True, n_jobs=4)\n        # lightgbm training parameters for early stoping\n        fit_params_={\"early_stopping_rounds\":50, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_val,y_val)],\n            'eval_names': ['valid'],\n            'verbose': 500,\n            'categorical_feature': 'auto'}\n        _ = clf.fit(X_train, y_train, **fit_params_)\n        #\n        feat_imp += clf.booster_.feature_importance('gain') / folds_.n_splits\n        oof_preds[val_idx] = clf.predict_proba(X_val)[:, 1]\n        \n    score = roc_auc_score(y_, oof_preds)\n    print('The final OOF score: {}'.format(score))\n    \n    feat_imp = pd.Series(feat_imp, index=application_train.columns)\n    feat_imp.nlargest(10).plot(kind='barh', figsize=(8,10))\n    \n    return  score","execution_count":51,"outputs":[]},{"metadata":{"_uuid":"45388897849efebb8523138021d1dd28448bc0b3"},"cell_type":"markdown","source":"## Do a basic modelbefore EXT_SOURCE imputation was done"},{"metadata":{"trusted":true,"_uuid":"b381c0101548caf86e658336a4ef2c16baa03973","collapsed":true},"cell_type":"code","source":"score_orig = train_model(application_train, y, folds)","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"077f571d694f0b446b0c2b84991bf91071d84ce0"},"cell_type":"markdown","source":"# Model fitting for imputation\nWe will use LightGBM regression model - LightGBM allows to build very sophysticated models with a very short training time."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"deadf3b3119f5e49677f6e08fe4b492e828b2aa0"},"cell_type":"code","source":"def run_imputer(df, y_name='EXT_SOURCE_1', fobj='mse'):\n    \n    print('Impute {}'.format(y_name))\n    \n    notnans = df[y_name].notnull()\n    nans = df[y_name].isnull()\n    idx_nans = nans.nonzero()[0]\n    \n    if nans.sum() == 0:\n        print('Nothin to impute. Do not run the LightGBMImputer')\n        return\n    \n    train = df[notnans]\n    test = df[nans]\n    \n    from sklearn.model_selection import train_test_split\n    X_train, X_val, y_train, y_val = train_test_split(train.drop(cols_ext, axis=1), train[y_name], test_size=0.20, random_state=314)\n    print('Training size = {}'.format(train.shape))\n    print('Test size = {}'.format(test.shape))\n    \n    # lightgbm training parameters for early stoping\n    fit_params={\"early_stopping_rounds\":50, \n            \"eval_metric\" : ['mae', 'mse'], \n            \"eval_set\" : [(X_val,y_val)],\n            'eval_names': ['valid'],\n            'verbose': 500,\n            'categorical_feature': 'auto'}\n    \n    #n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n    clf1 = lgb.LGBMRegressor(objective=fobj, learning_rate=0.1,\n                         num_leaves=10,\n                         max_depth=-1, n_estimators=5000,\n                         colsample_bytree=0.9, subsample=0.9,\n                         reg_alpha=0.1, reg_lambda=0.1,\n                         random_state=314, min_child_samples=100,\n                         silent=True, n_jobs=4)\n    clf1.fit(X_train, y_train, **fit_params)\n    \n    df[y_name][nans.nonzero()[0]] = clf1.predict(test.drop(cols_ext, axis=1))","execution_count":43,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10f73db93a347e74d3025fa67891e2c589d673d6","collapsed":true},"cell_type":"code","source":"for c in cols_ext:\n    run_imputer(application_train, y_name=c)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"b8af9e2ff9ca6f6bb59b7380bc65c99a5063f4c7"},"cell_type":"markdown","source":"## Train again using imputed EXT_SOURCE data\nThis allows us to avoid overtraining and we do not need to optimise the number of trees"},{"metadata":{"trusted":true,"_uuid":"e6b0475f9d1a7d4c2ab1d34c3294258ce6c4222e","collapsed":true},"cell_type":"code","source":"score_imp = train_model(application_train, y, folds)","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b07dbe8a5e4127a347c9982ca06f7767a701dbc","collapsed":true},"cell_type":"code","source":"print('Final comparison of ROC AUC scores: original = {}, with imputation = {:2f}'.format(score_orig, score_imp))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83272a6ccf734a4b8b262022c0b326ad8c611bc1"},"cell_type":"markdown","source":"As an outcome, precision of the classifier does not depend much on the advanced imputer and if anything gets even a bit worse"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}