{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29da0e9e-da0e-902f-4df0-d7a606442792"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import tensorflow as tf\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85e5aefa-30b6-e47a-fc86-c9367aaead60"
      },
      "outputs": [],
      "source": [
        "def get_im_cv2(path):\n",
        "    img = cv2.imread(path)\n",
        "    resized = cv2.resize(img, (32, 32), cv2.INTER_LINEAR)\n",
        "    return resized\n",
        "\n",
        "def get_im_tf(path, img_rows, img_cols, color_type=1):\n",
        "    img = tf.read_file(path)\n",
        "    # Load as grayscale\n",
        "    if color_type == 1:\n",
        "        img = tf.image.decode_jpeg(img, channels=1)\n",
        "    elif color_type == 3:\n",
        "        img = tf.image.decode_jpeg(img, channels=0)\n",
        "    # Reduce size\n",
        "    resized = tf.image.resize_images(img, (32,32), method= 0,align_corners=False)\n",
        "    return resized\n",
        "\n",
        "\n",
        "def load_train(img_rows, img_cols, color_type=1):\n",
        "    x_train = []\n",
        "    x_train_id = []\n",
        "    y_train = []\n",
        "    #start_time = time.time()\n",
        "\n",
        "    print('Read train images')\n",
        "    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
        "    for fld in folders:\n",
        "        index = folders.index(fld)\n",
        "        print('Load folder {} (Index: {})'.format(fld, index))\n",
        "        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            flbase = os.path.basename(fl)\n",
        "            img = get_im_cv2(fl)\n",
        "            x_train.append(img)\n",
        "            x_train_id.append(flbase)\n",
        "            y_train.append(index)\n",
        "\n",
        "    #print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
        "    return x_train, y_train, x_train_id\n",
        "\n",
        "\n",
        "def load_test():\n",
        "    path = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n",
        "    files = sorted(glob.glob(path))\n",
        "\n",
        "    X_test = []\n",
        "    X_test_id = []\n",
        "    for fl in files:\n",
        "        flbase = os.path.basename(fl)\n",
        "        img = get_im_cv2(fl)\n",
        "        X_test.append(img)\n",
        "        X_test_id.append(flbase)\n",
        "\n",
        "    return X_test, X_test_id\n",
        "\n",
        "def to_categorical(y, nb_classes=None):\n",
        "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
        "    E.g. for use with categorical_crossentropy.\n",
        "    # Arguments\n",
        "        y: class vector to be converted into a matrix\n",
        "            (integers from 0 to nb_classes).\n",
        "        nb_classes: total number of classes.\n",
        "    # Returns\n",
        "        A binary matrix representation of the input.\n",
        "    \"\"\"\n",
        "    y = np.array(y, dtype='int').ravel()\n",
        "    if not nb_classes:\n",
        "        nb_classes = np.max(y) + 1\n",
        "    n = y.shape[0]\n",
        "    categorical = np.zeros((n, nb_classes))\n",
        "    categorical[np.arange(n), y] = 1\n",
        "    return categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f6b9069-1e0c-2339-b1a7-6e65c27c42e0"
      },
      "outputs": [],
      "source": [
        "train_data, train_target, train_id = load_train(32,32,1)\n",
        "test_data, test_id = load_test()\n",
        "\n",
        "\n",
        "x_train = np.array(train_data, dtype=np.uint8)\n",
        "y_train = np.array(train_target, dtype=np.uint8)\n",
        "#x_train = x_train.transpose((0, 1, 2))\n",
        "\n",
        "x_test = np.array(test_data, dtype=np.uint8)\n",
        "#x_test = x_test.transpose((0, 3, 1, 2))\n",
        "\n",
        "# Normalizing the data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "#x_train.reshape()\n",
        "print(y_train.shape)\n",
        "print('X_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34e3fb2f-1e90-a168-39e4-a452e5c6611e"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 200000\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "# Network Parameters\n",
        "n_width = 32 # Fishes data input (img shape: 28*28)\n",
        "n_height=32\n",
        "n_classes = 8 # Fishes total classes (0-9 digits)\n",
        "dropout = 0.75 # Dropout, probability to keep units\n",
        "\n",
        "\n",
        "# tf Graph input\n",
        "images_batch = tf.placeholder(tf.float32, [None,n_width,n_height,3])\n",
        "labels_batch = tf.placeholder(tf.float32, [None, n_classes])\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "print(y_train.shape)\n",
        "keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26ee5aee-d0e4-2fa9-2740-7914f7fa350e"
      },
      "outputs": [],
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    # MaxPool2D wrapper\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='VALID')\n",
        "\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    # Reshape input picture\n",
        "    print(\"Pablo0\")\n",
        "    #x = tf.reshape(x, shape=[-1, 32, 32, 3])\n",
        "    \n",
        "    print(\"Pablo1\")\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "89c7245a-61ff-5b60-6639-58f35dcdc46b"
      },
      "outputs": [],
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([1024, n_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
        "}\n",
        "\n",
        "# Construct model\n",
        "pred = conv_net(images_batch, weights, biases, keep_prob)\n",
        "\n",
        "# Define loss and optimizer\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=labels_batch))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "print(\"prediction\")\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(labels_batch, 1))\n",
        "print(\"prediction\")\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a427728e-8177-ba44-1401-9d6bb72c467d"
      },
      "outputs": [],
      "source": [
        "# Launch the graph\n",
        "with tf.Session() as sess: \n",
        "    sess.run(init) \n",
        "    for _ in range(1000):  \n",
        "              \n",
        "            indices = np.random.choice(3777, batch_size)\n",
        "            print(indices.size)\n",
        "            X_batch, Y_batch = x_train[indices], y_train[indices]\n",
        "            print(X_batch.size)\n",
        "            print(Y_batch)\n",
        "            sess.run(optimizer, feed_dict={images_batch: X_batch, labels_batch: Y_batch,\n",
        "                                       keep_prob: dropout})\n",
        "            \n",
        "            print(Y_batch.size)               \n",
        "            if step % display_step == 0:\n",
        "            # Calculate batch loss and accuracy\n",
        "               loss, acc = sess.run([cost, accuracy], feed_dict={images_batch: X_batch,\n",
        "                                                              labels_batch: Y_batch,\n",
        "                                                              keep_prob: 1.})     \n",
        "            print(acc+ \" \")  \n",
        "            step += 1\n",
        "    \n",
        "    print(\"Optimization Finished!\")\n",
        "            \n",
        " \n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}