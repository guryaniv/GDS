{"cells":[{"metadata":{"_uuid":"1f4ca439e4cdb0a9d47d42cacb7a975a985102ec"},"cell_type":"markdown","source":"# Blurriness-aware Cropping Augmentation with openCV\n\nAs Heng CherKeng's [discussion](https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/65556), the dataset contains somewhat amount of blurry images. \nThe `BlurAwareCrop` class defined in this notebook is a module which takes PIL image as input, measures the blurriness of image, and apply random cropping with given probability on image, **only when** they are determined a sharp image. This module utilizes openCV for measuring the sharpness of image. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom torchvision import transforms\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b792ffa7fdc7f3be2c1155125f1be9da266f551a"},"cell_type":"code","source":"class BlurAwareCrop():\n    def __init__(self, prob=0.7, blur_thres=200, min_crop=70, return_size=101):\n        self.prob = prob\n        self.blur_thres = blur_thres\n        self.min_crop = min_crop\n        self.return_size = return_size\n        self.tr = None\n    \n    # reference: https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n    def sharp_measure(self, img_pil):\n        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n        return cv2.Laplacian(img_cv, cv2.CV_64F).var()\n    \n    def __call__(self, img):\n        '''\n        if given image has RGB mode(salt image), compute the sharpness of image using cv and setup transforms to be applied\n        otherwise, if mask is given, just applies same transform again.\n        '''\n        if img.mode == 'RGB':\n            if self.sharp_measure(img) > self.blur_thres and np.random.rand() < self.prob:\n                crop_size = np.random.randint(self.min_crop, self.return_size)\n                self.tr = transforms.Compose([\n                    transforms.RandomCrop(crop_size),\n                    transforms.Resize(self.return_size)\n                ])\n            else:\n                self.tr = transforms.Compose([])\n        return self.tr(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a66bfbc3f8401f409d25bbef49a376b39d67bf2"},"cell_type":"code","source":"tr = BlurAwareCrop()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e58f7f94f8c7c55383fff64bb7f928c7ef2ee3aa"},"cell_type":"code","source":"fnames = pd.read_csv('../input/train.csv', usecols=['id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d58e64c748a38be35282377e06832b14f9fb5af"},"cell_type":"code","source":"def show_example(index):\n    img = Image.open(f'../input/train/images/{fnames.id[index]}.png')\n    mask = Image.open(f'../input/train/masks/{fnames.id[index]}.png')\n    sharpness = tr.sharp_measure(img)\n    print(f\"image sharpness: {sharpness}\")\n    if sharpness > tr.blur_thres:\n        print(f\"image is sharp enough, cropping is applied with probability {tr.prob}\")\n    else:\n        print(\"image is blurry, cropping will not applied\")\n    \n    plt.figure(figsize=(16, 9))\n    \n    plt.subplot(141)\n    plt.title('image before transform')\n    plt.imshow(img)\n    \n    plt.subplot(142)\n    plt.title('mask before transform')\n    plt.imshow(mask)\n\n    plt.subplot(143)\n    plt.title('image after transform')\n    plt.imshow(tr(img))\n    \n    plt.subplot(144)\n    plt.title('mask after transform')\n    plt.imshow(tr(mask))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f44f32e78090389e94fb774c237db775da62d7a"},"cell_type":"markdown","source":"## Example: blurry image. transform will not applied"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"daecb40c81cfa9fdea7288b9f2ea84fbf74a50d9"},"cell_type":"code","source":"show_example(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f958536babcdef6dad2c1f80ce027bcc73ef565f"},"cell_type":"markdown","source":"## Example: sharp image. transform will applied according to given probability"},{"metadata":{"trusted":true,"_uuid":"b0118ea88afce61fe0205a57d779d64d82ce9a4e"},"cell_type":"code","source":"show_example(19)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b115badff9089ede6faedb0c94cce6081eda968"},"cell_type":"markdown","source":"You can use this module chained with other torchvision transforms, using `torchvision.transforms.Compose`.\nI think this module's native that sets up transforms when image is given, and just re-use it when mask is given would be problematic when multiprocessing is used for data loader(with `num_workers` argument), but not tested it myself. I would be grateful if someone contributes to this kernel by testing that, or suggest better way of making augmentations on image and mask syncronized.\n"},{"metadata":{"trusted":true,"_uuid":"7ca7293a3c549df372e93d40fcb35262ba0c0757"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}