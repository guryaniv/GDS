{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/test\"))\n#!unzip ../input/test/\n# Any results you write to the current directory are saved as output.\n!pip install pyspark","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom pyspark.sql import SparkSession,SQLContext\nfrom pyspark import SparkFiles\nfrom pyspark.ml.feature import VectorAssembler\nimport pyspark\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nsc = pyspark.SparkContext('local[*]')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0d4e1c50490188d5e7dee1f6a809dcc02aee53c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4ec20bc91999873b274808cf77187a6d50e4e1"},"cell_type":"code","source":"sqlCtx = SQLContext(sc)\ndf = sqlCtx.read.csv('../input/train/train.csv',header=True,inferSchema='True')\ndf_test = sqlCtx.read.csv('../input/test/test.csv',header=True,inferSchema='True')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c342a0216b6e135aefc9006352f99fbc6b2dfa92"},"cell_type":"code","source":"spark = SparkSession.builder.appName(\"pet_adoption\").getOrCreate()\n##pandas frame is easier to read\ndf_pd = pd.read_csv('../input/train/train.csv')\ninput_cols = [a for a,b in df.dtypes if b=='int']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"603f0b670a77862c24a0ee00319fc8ff5f2d3f5b"},"cell_type":"code","source":"indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in [\"AdoptionSpeed\"]]\npipeline = Pipeline(stages=indexers)\ndf = pipeline.fit(df).transform(df)\ndf_test = pipeline.fit(df_test).transform(df_test)\n\nfeature = VectorAssembler(inputCols=input_cols,outputCol=\"features\")\nfeature_vector= feature.transform(df)\n\nfeature_vector_test= feature.transform(df_test)\n(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)\nfrom pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"AdoptionSpeed_index\", featuresCol=\"features\")\nlrModel = lr.fit(trainingData)\nlr_prediction = lrModel.transform(testData)\n#lr_prediction.select(\"prediction\", \"Survived\", \"features\").show()\n#evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\nevaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\nlr_accuracy = evaluator.evaluate(lr_prediction)\nprint(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\nprint(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))\n#lr_prediction.show()\nlr_prediction = lrModel.transform(feature_vector_test)\npredictions = [int(elem['prediction']) for elem in lr_prediction.select('prediction').collect()]\npredictions_ids = [elem['PetID'] for elem in lr_prediction.select('PetID').collect()]\ndf_new = pd.DataFrame()\ndf_new['PetID'] = predictions_ids\ndf_new['AdoptionSpeed'] = predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64dd0bd68d01d77fa768734280377450afd609b6"},"cell_type":"code","source":"df_new.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e195ff736bbe9c25b9ba2c4d3153c1768354ee9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a938e1a86f09cee8168f8f158ba326d53be67ec"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}