{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["[<img src='https://lh3.googleusercontent.com/-tNe1vwwd_w4/VZ_m9E44C7I/AAAAAAAAABM/5yqhpSyYcCUzwHi-ti13MwovCb_AUD_zgCJkCGAYYCw/w256-h86-n-no/Submarineering.png'>](https://twitter.com/submarineering?lang=en)\n"], "metadata": {"_cell_guid": "711ac61a-75c9-4c77-9ac2-97255573ad6a", "_uuid": "7728d8b02ab95d25ebe4ba280fc73163775fbcbc"}}, {"cell_type": "markdown", "source": ["**The main purpose of this Notebook is to apply image processing technics in order to provide some additional engineering features to help on the improvement of the classifier accuracy. ** \n", "\n", "I highly recommend to read and see some examples about image processing : \n", "\n", "http://scikit-image.org/\n", "\n", "And my Notebooks  '**Submarineering.Size matters**', '**Submarineering.Objects solation**' :\n", "\n", "https://www.kaggle.com/submarineering/submarineering-size-matters\n", "\n", "https://www.kaggle.com/submarineering/submarineering-objects-isolation-0-75-lb\n", "\n", "What can you learn? \n", "\n", "-An easy way to compare graphically the influency of differents attributes, and plot a 3d surface from the images using Plotly. \n", "\n", "-Undertanding  that the cleaning of data is fundamental for the classifier, as the learning process is automatic, unnecessary data will confuse to the algorithm. \n", "\n", "-Doesn't  matter which classifier or different algorithm you are going to use. This is always important.\n", "\n", "-In this case I am focusing on the isolation of the object and calculate his volume . \n", "\n", "-The info provides by the water is irrelevant.\n", "\n", "-**As a bonus, at the end, I explain how to generate useful features as result of the morphological analysis. ** \n", "\n"], "metadata": {"_cell_guid": "69a85df1-ce44-4679-b76c-b3241e525d44", "_uuid": "8b4eadf79a7fd43fed307bba176ac46d52be0014"}}, {"cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "from scipy.ndimage import gaussian_filter\n", "from skimage import img_as_float\n", "from skimage.morphology import reconstruction\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "train = pd.read_json('../input/train.json')\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "81234c3b-deea-416a-97fe-852964adcfc7", "_uuid": "028037b2200fb14e57e2c152c3382f3b57227c06"}}, {"cell_type": "code", "source": ["# load the training dataset.\n", "train = pd.read_json('../input/train.json')"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "bcbf68e7-c44b-42f4-a6f5-39e0664e084c", "_uuid": "500bf40db576b4bb3d9b41811cda4e22ca97f872", "collapsed": true}}, {"cell_type": "code", "source": ["# Isolation function.\n", "def iso(arr):\n", "    image = img_as_float(np.reshape(np.array(arr), [75,75]))\n", "    image = gaussian_filter(image,2.5)\n", "    seed = np.copy(image)\n", "    seed[1:-1, 1:-1] = image.min()\n", "    mask = image \n", "    dilated = reconstruction(seed, mask, method='dilation')\n", "    return image-dilated\n"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "5a7bc5cb-8752-4fe2-8a9b-369731694847", "_uuid": "9f78bcc284e2a7af05da81c3e77f3f8fc4de8f01", "collapsed": true}}, {"cell_type": "code", "source": ["# Plotting to compare\n", "arr = train.band_1[12]\n", "dilated = iso(arr)\n", "fig, (ax0, ax1) = plt.subplots(nrows=1,\n", "                                    ncols=2,\n", "                                    figsize=(16, 5),\n", "                                    sharex=True,\n", "                                    sharey=True)\n", "\n", "ax0.imshow(np.reshape(np.array(arr), [75,75]))\n", "ax0.set_title('original image')\n", "ax0.axis('off')\n", "ax0.set_adjustable('box-forced')\n", "\n", "ax1.imshow(dilated, cmap='gray')\n", "ax1.set_title('dilated')\n", "ax1.axis('off')\n", "ax1.set_adjustable('box-forced')\n"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "740093b9-3565-4e31-9650-baa981142781", "_uuid": "b5e157cea4c6d91cca8a6fa2865ff2ebe203cf11"}}, {"cell_type": "code", "source": ["# Plotting to compare\n", "arr = train.band_1[8]\n", "dilated = iso(arr)\n", "fig, (ax0, ax1) = plt.subplots(nrows=1,\n", "                                    ncols=2,\n", "                                    figsize=(16, 5),\n", "                                    sharex=True,\n", "                                    sharey=True)\n", "\n", "ax0.imshow(np.reshape(np.array(arr), [75,75]))\n", "ax0.set_title('original image')\n", "ax0.axis('off')\n", "ax0.set_adjustable('box-forced')\n", "\n", "ax1.imshow(dilated, cmap='gray')\n", "ax1.set_title('dilated')\n", "ax1.axis('off')\n", "ax1.set_adjustable('box-forced')"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "3572994a-2a71-4f5a-87ac-cfbddad43cad", "_uuid": "652d2104044b51d7c961d3e5908ff4dd11dc4177"}}, {"cell_type": "code", "source": ["# Feature engineering iso1 and iso2.\n", "train['iso1'] = train.iloc[:, 0].apply(iso)\n", "train['iso2'] = train.iloc[:, 1].apply(iso)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "c3f7bd43-7679-4275-b2d4-136df9ffd288", "_uuid": "e3a963100299144eed87044c5858490e37cea17e", "collapsed": true}}, {"cell_type": "code", "source": ["import plotly.offline as py\n", "import plotly.graph_objs as go\n", "py.init_notebook_mode(connected=True)\n", "img = train.iso1[12]+train.iso2[12]\n", "data = [\n", "    go.Surface(\n", "        z=img\n", "    )\n", "]\n", "layout = go.Layout(\n", "    title='Iceberg to 3D Surface',\n", "    autosize=False,\n", "    width=500,\n", "    height=500,\n", "    margin=dict(\n", "        l=65,\n", "        r=50,\n", "        b=65,\n", "        t=90\n", "    )\n", ")\n", "fig = go.Figure(data=data, layout=layout)\n", "py.iplot(fig)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "52279ddc-4446-4ffd-8f55-7ee5a6019c93", "_uuid": "9b19ecdc369632c4169c27a892ddced3277d4b22"}}, {"cell_type": "code", "source": ["img = train.iso1[8] + train.iso2[8]\n", "data = [\n", "    go.Surface(\n", "        z= img\n", "    )\n", "]\n", "layout = go.Layout(\n", "    title='Ship to 3D Surface',\n", "    autosize=False,\n", "    width=500,\n", "    height=500,\n", "    margin=dict(\n", "        l=65,\n", "        r=50,\n", "        b=65,\n", "        t=90\n", "    )\n", ")\n", "fig = go.Figure(data=data, layout=layout)\n", "py.iplot(fig)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "0be6904f-9091-4488-be1c-2bb8f8f011b6", "_uuid": "ff7ef12339b2661f6c4a563a587108ade19246db"}}, {"cell_type": "code", "source": ["#Adding up every pixel value is equivalent to the volumen under the surface. \n", "def volume(arr):\n", "    return np.sum(arr)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "356a1097-4c06-4c46-89d9-70636f440e77", "_uuid": "8b0e135d6f9fa57a69d0eac110d01cfc3733a5a8", "collapsed": true}}, {"cell_type": "code", "source": ["train['vol'] = (train.iloc[:, 0] + train.iloc[:, 1]).apply(volume)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "835bf290-6b1d-4c64-bfa2-2a280c3afc20", "_uuid": "bf037d43c44b5d5730fa8501b9ba29b41b4a7562", "collapsed": true}}, {"cell_type": "code", "source": ["# Additional features from the morphological analysis and how is working on discrimination.\n", "train[train.is_iceberg==1]['iso1'].apply(np.max).plot(alpha=0.4)\n", "train[train.is_iceberg==0]['iso1'].apply(np.max).plot(alpha=0.4)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "2447bfc3-fe66-485a-8473-54cc33337f10", "_uuid": "71da26a553335a733e704318a2e4501f4edf9619"}}, {"cell_type": "code", "source": ["# Additional features from the morphological analysis and how is working on discrimination.\n", "train[train.is_iceberg==1]['iso2'].apply(np.max).plot(alpha=0.4)\n", "train[train.is_iceberg==0]['iso2'].apply(np.max).plot(alpha=0.4)"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "bdbfab28-2061-4cbd-9da1-68101c0fe769", "_uuid": "18d0973aec21eee2a6bb0485b77c761b9605cbd2"}}, {"cell_type": "code", "source": ["# Volume. Additional features from the morphological analysis and how is working on discrimination.\n", "train[train.is_iceberg==1]['vol'].plot(alpha=0.4)\n", "train[train.is_iceberg==0]['vol'].plot(alpha=0.4)\n"], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "b87f5ea4-5de8-427a-a635-fedfcaf0a75e", "_uuid": "94843253060132124c28180151fb9998b8105a02"}}, {"cell_type": "markdown", "source": ["**NOTE :** It looks like images with incidence angles having less than or equal to 4 decimal are the naturally captured images, and those with greater precision are machine generated, as 'brassmonkey' describes very well. \n", "In the data description of the competition is also refered as : \n", "\"Please note that we have included machine-generated images in the test set to prevent hand labeling. They are excluded in scoring.\"\n", "This is an important point to be in mind. \n"], "metadata": {"_cell_guid": "d17b866a-bbba-4bbe-b9e2-94eeccea20ce", "_uuid": "37a42184bd4d1ef5c044d1b3dca4001486fd09b8"}}, {"cell_type": "markdown", "source": ["**Conclusion.** As described in my Notebooks  **'Submarineering.Size matters** and **'Submarineering.Objects isolation**'', that I highly recommed :\n", "\n", "https://www.kaggle.com/submarineering/submarineering-size-matters \n", "\n", "https://www.kaggle.com/submarineering/submarineering-objects-isolation-0-75-lb\n", "\n", "the size can be used from multiple points of view.  Also the shape of the object to detect can give us a rich information about his class. Additional features can be obtain from these morphological properties, like the** Volume** ,that it clearly can help to the classification too.\n", "\n", "These features could be improved :\n", "\n", "-They can be categorized in order to help on the accuracy of the Classifier.\n", "\n", "I hope these lines be useful for your. **Please vote up**.\n"], "metadata": {"_cell_guid": "d6b2c63d-ebf9-4a8a-800c-df1c60460ba0", "_uuid": "862ea76e28185247232cb9761a2692e4c4562028"}}, {"cell_type": "code", "source": [], "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "1ff5b000-a53a-417c-8a2f-2beddb49dd0e", "_uuid": "7464ce7fd76b64a7f0275c89da6dd85bb6a3add8", "collapsed": true}}], "nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}