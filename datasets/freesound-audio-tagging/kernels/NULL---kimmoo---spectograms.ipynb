{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import librosa\nimport librosa.display\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea5a5cafcc8541aa0df62d732884aa318e86215f","collapsed":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"227b0ca4b7fda1b590060d2e04416fcf10ab9ae3","collapsed":true},"cell_type":"code","source":"data_path = '../input/'\ntrain_root = '../input/audio_train/'\ntest_root = '../input/audio_test/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6657e9bbec5b695b506373f6ebef9d97dbdcdd0"},"cell_type":"markdown","source":"# Why spectograms?\n\nSpectograms of sounds turn out to be quite useful for training 2d convolutional networks.  My current enseble in the Freesound competition includes models trained with spectogram data achieving accuracy scores between 60% and 70%. The results I get are a little bit better when I use models which have been pretrained on Imagenet.  If you'd like to try it, here's how to create spectograms: "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"49e68ac350a0d7a8acb0ca15f187d2988b4e08cc"},"cell_type":"code","source":"def to_log_S(fname, PATH):\n    y, sr = librosa.load(os.path.join(PATH, fname))\n    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n    log_S = librosa.amplitude_to_db(S, ref=np.max)\n    return log_S","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d4e03870e002ef0f1df88ff524cd0504b15f222"},"cell_type":"code","source":"to_log_S('65b299e9.wav', train_root)[:10, :4]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62ee321828559743167b0e2848853bd8dbe3951"},"cell_type":"markdown","source":"Instead of mean=[0.485, 0.456, 0.406] and std=[0.229, 0.224, 0.225]) as described in https://pytorch.org/docs/master/torchvision/models.html, I use the mean of the mean and the mean of the std, since I've got only 1 channel."},{"metadata":{"trusted":true,"_uuid":"55ae04c5630f770995c83a3fc70377b13053917e","collapsed":true},"cell_type":"code","source":"mean = (0.485+0.456+0.406)/3\nstd = (0.229+0.224+0.225)/3\nmean, std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e142cb5aa0a3ae438a0d8813a098fd2899d17fe"},"cell_type":"code","source":"def normalize(x):\n    x = -x/80\n    x = (x-mean)/std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54203bc639558095b6a06f80cbb31f59fc93e13b"},"cell_type":"markdown","source":"Here's how to visualize a spectogram:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"94f8bc65d6dfc67b1d50303f25bb0317dc299267"},"cell_type":"code","source":"def display_spectogram(log_S):\n    sr = 22050\n    plt.figure(figsize=(12,4))\n    librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n    plt.title('mel power spectrogram')\n    plt.colorbar(format='%+02.0f dB')\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57daee88467f61cd6731b7ce87cc06580b39a315"},"cell_type":"code","source":"display_spectogram(to_log_S('65b299e9.wav', train_root)[:10, :4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed1d9a30c18e8f043bdfe797ba6a1704a6afba77","collapsed":true},"cell_type":"code","source":"display_spectogram(to_log_S('65b299e9.wav', train_root))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}