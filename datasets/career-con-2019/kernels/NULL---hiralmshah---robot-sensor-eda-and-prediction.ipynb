{"cells":[{"metadata":{"_uuid":"70ac848abee33372f1fc984cff22a2666a1510f0"},"cell_type":"markdown","source":"## Introduction:\nRobots are smart… by design. To fully understand and properly navigate a task, however, they need input about their environment.\nIn this competition, you’ll help robots recognize the floor surface they’re standing on using data collected from Inertial Measurement Units (IMU sensors).\n\n## About Data: \nCareerCon has collected IMU sensor data while driving a small mobile robot over different floor surfaces on the university premises. \n\n## Objective:\nThe task is to predict which one of the nine floor types (carpet, tiles, concrete) the robot is on using sensor data such as acceleration and velocity. Succeed and you'll help improve the navigation of robots without assistance across many different surfaces, so they won’t fall down on the job.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport plotly.offline as py \nfrom plotly.offline import init_notebook_mode, iplot\npy.init_notebook_mode(connected=True) # this code, allow us to work with offline plotly version\nimport plotly.graph_objs as go # it's like \"plt\" of matplot\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e34f69dc39da43668ef2b31a5bc78a2f00e2c90","scrolled":true},"cell_type":"code","source":"X_train = pd.read_csv('../input/X_train.csv')\nX_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"y_train = pd.read_csv('../input/y_train.csv')\ny_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14178c56eab309c63986cdcd7de1d2576957433d"},"cell_type":"code","source":"X_test = pd.read_csv('../input/X_test.csv')\nX_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87344a081dfe0608e015f37140004a9103b1b9e7"},"cell_type":"markdown","source":"# Descriptive Statistics"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1a77ddf0c56e91c8faef884dcd6b16e5c606dc62"},"cell_type":"code","source":"print('Size of Train Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(X_train.shape[0], X_train.shape[1]))\n\nprint('\\nSize of Test Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(X_test.shape[0], X_test.shape[1]))\n\nprint('\\nSize of Target Data')\nprint('Number of samples are: {0}\\nNumber of features are: {1}'.format(y_train.shape[0], y_train.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e9946fb562f644bd6bafa8b881e09c686afb4b2"},"cell_type":"markdown","source":"## Train Data Description"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c7bcd5aea9bd259d6ccb60a17460365a7c57f1a4"},"cell_type":"code","source":"X_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c997188cebfe04de0f2287ef379b8cd396a16f3"},"cell_type":"markdown","source":"## Target surface type and their sample count"},{"metadata":{"trusted":true,"_uuid":"5b86605f9b26e4d5236fd3e3c6d94937dbe60960","_kg_hide-input":true},"cell_type":"code","source":"target_data = y_train['surface'].value_counts().reset_index().rename(columns = {'index' : 'target'})\ntarget_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"786a55a2d8d52fcba3db36c115e9170d16984131","_kg_hide-input":true},"cell_type":"code","source":"#sns.countplot(y='surface',data = y_train)\ntrace0 = go.Bar(\n    x = y_train['surface'].value_counts().index,\n    y = y_train['surface'].value_counts().values\n    )\n\ntrace1 = go.Pie(\n    labels = y_train['surface'].value_counts().index,\n    values = y_train['surface'].value_counts().values,\n    domain = {'x':[0.55,1]})\n\ndata = [trace0, trace1]\nlayout = go.Layout(\n    title = 'Frequency Distribution for surface/target data',\n    xaxis = dict(domain = [0,.50]))\n\nfig = go.Figure(data = data, layout = layout)\npy.iplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa07370c418b5e5814179617658eb74c71651349"},"cell_type":"markdown","source":"## Preprocessing data\n\n### Is there any missing data?"},{"metadata":{"trusted":true,"_uuid":"3829dec760a69f4e1d283afc906688998ec79458","_kg_hide-input":true},"cell_type":"code","source":"X_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4ccf370c0f1a0df7b629fb2c819854ebf8114de"},"cell_type":"markdown","source":"#### Observation: No missing data"},{"metadata":{"_uuid":"f03510dd8267322c693dbfd27e11364ddd0ef7b7"},"cell_type":"markdown","source":"### Is there any duplicate data?"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8f708a49fcae5e7efe5147628a4d5d830b73435b"},"cell_type":"code","source":"X_train['is_duplicate'] = X_train.duplicated()\nX_train['is_duplicate'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f59513c7a1c24e1c9f22ff7d85824f4e658cf4b7"},"cell_type":"markdown","source":"#### Observation: There is no duplicate data"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"19f19ac2a9e52a64951ed175861146797c7f1deb"},"cell_type":"code","source":"X_train = X_train.drop(['is_duplicate'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1be64fe4734c0b66a6471aaa2c006d9ac3719570"},"cell_type":"markdown","source":"### Sorting based on series_id and measurement_number"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9f5c8d51dd737aa3c00bbacc3b03263986b30355"},"cell_type":"code","source":"X_train_sort = X_train.sort_values(by = ['series_id', 'measurement_number'], ascending = True)\nX_train_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8053877048a866406c120f73017ede5d0b77f3cf"},"cell_type":"markdown","source":"### Min_Max value of each feature"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6b37d58fa592fbaef7a3e872a60956341936f156"},"cell_type":"code","source":"def min_max_values(col):\n    top = X_train[col].idxmax()\n    top_obs = pd.DataFrame(X_train.loc[top])\n    \n    bottom = X_train[col].idxmin()\n    bot_obs = pd.DataFrame(X_train.loc[bottom])\n    \n    min_max_obs = pd.concat([top_obs, bot_obs], axis = 1)\n    \n    return min_max_obs","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0fd80ab76ab5d4f55efc3cb158564dcff0e44ea6"},"cell_type":"code","source":"min_max_values('series_id')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60618761456f01add7c20df75f9ffed60b7ac051"},"cell_type":"markdown","source":"### Correlation Matrix"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"812d5dcceee65b7b49a783dfc128e8a9f0b07ce3"},"cell_type":"code","source":"corr = X_train.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"209d7feaec5a2b84e716bc3712cbdc80f76ec512"},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize = (15,6))\n\nhm = sns.heatmap(corr,\n                ax = ax,\n                cmap = 'coolwarm',\n                annot = True,\n                fmt = '.2f',\n                linewidths = 0.05)\nfig.subplots_adjust(top=0.93)\nfig.suptitle('Orientation, Angular_velocity and Linear_accelaration Correlation Heatmap', \n              fontsize=14, \n              fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7935de051893834499a8819bfb0cb1cdae573c1"},"cell_type":"markdown","source":"**Observation:**\n*     orientation_X and orientation_W are strongly correlated\n*     orientation_Y and orientation_Z are strongly correlated\n*     linear_accelaration_Y and linear_accelaration_Z also has positive correlation\n*     angular_velocity_Y and angular_velocity_Z has negative correlation"},{"metadata":{"_uuid":"136694c6c89addd415d471e922b0f7396ab5400a"},"cell_type":"markdown","source":"### Box plot of angular_velocity, orientation and linear_accelaration data"},{"metadata":{"trusted":true,"_uuid":"37eca2bbd6ca4cca4085c876b44357ab3fd9ecfd","_kg_hide-input":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15,15))\nax = fig.add_subplot(311)\nax.set_title('Distribution of Orientation_X,Y,Z,W',\n             fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,3:7].boxplot()\nax = fig.add_subplot(312)\nax.set_title('Distribution of Angular_Velocity_X,Y,Z',fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,7:10].boxplot()\nax = fig.add_subplot(313)\nax.set_title('Distribution of linear_accelaration_X,Y,Z',fontsize=14, \n             fontweight='bold')\nX_train.iloc[:,10:13].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6853d35ad43c26185526284091006b1174bfb27"},"cell_type":"markdown","source":"**Observation**: There are many outliers in angular_velocity and linear accelaration data"},{"metadata":{"_uuid":"3b88953c5803cb1e8019a6569be204b1e14f4c13"},"cell_type":"markdown","source":"### Histogram plot for all features"},{"metadata":{"trusted":true,"_uuid":"bf1014b7cfabbe6af7d4a9ac0614ac4913cbf48e","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i, col in enumerate(X_train.columns[3:]):\n    ax = plt.subplot(3, 4, i + 1)\n    sns.distplot(X_train[col], bins=100, label='train')\n    sns.distplot(X_test[col], bins=100, label='test')\n    ax.legend()   ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df9abf210f80212a27b47eaca351d38b8ae61fed"},"cell_type":"markdown","source":"### Observation:\n*    Angular velocity are normally distributed infect they are symmetrical data distribution\n*    linear_accelaration are normally distributed/symmetrical distribution but average value is slightly negative for linear_accelaration_Z\n*    X,Y,Z,W orientation data are not symmetrical or bell shaped distributed. \n*         X,Y orientation data are distributed un-even between 1 to -1.\n*         Z,W orientation data are distributed un-even between 1.5 to -1.5"},{"metadata":{"_uuid":"2c65c139f8b8feba981b855d72ea5764c3f95e7b"},"cell_type":"markdown","source":"### Feature distribution for each target value (surface)"},{"metadata":{"trusted":true,"_uuid":"d228c9af3602cade9773376aa48f24a6845160fb","_kg_hide-input":true},"cell_type":"code","source":"df = X_train.merge(y_train, on = 'series_id', how = 'inner')\ntargets = (y_train['surface'].value_counts()).index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adbe30df3646cc7d76edd93e5dd066227708387a","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(26, 16))\nfor i,col in enumerate(df.columns[3:13]):\n    ax = plt.subplot(3,4,i+1)\n    ax = plt.title(col)\n    for surface in targets:\n        surface_feature = df[df['surface'] == surface]\n        sns.kdeplot(surface_feature[col], label = surface)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25b717e812d494e40f153423501b929aa74d4b23"},"cell_type":"markdown","source":"**Observation:**\n\n*     even though 'hard tile' data count is less, orientation_X,Y,Z,W for hard tile surface is at pick.\n*     for orientation_X these data range is approx 0.5 to 1.0, \n*     for orientation_Y these data range is approx -1.0 to -0.5\n*     for orientation_Z these data range is approx -0.12 to -0.8\n*     for orientation_W these data range is approx 0.07 to 0.12 \n*     for angular velocity and linear accelaration data, there is a symmetry around mean in terms of data distribution.\n    "},{"metadata":{"_uuid":"9d15e8141ac2e531545aa88da31c409d290e735a"},"cell_type":"markdown","source":"## Model\n\nOur goal is to identify 'which surface' it might be based on previous input features. More precisely it is a 'Classification' Problem.\nLogistic Regression is a first choice here.\n\n### Types of Logistic Regression:\n**Binary Logistic Regression:** The target variable has only two possible outcomes such as Spam or Not Spam, Cancer or No Cancer.\n**Multinomial Logistic Regression:** The target variable has three or more nominal categories such as in this problem type of surface.\n**Ordinal Logistic Regression:** the target variable has three or more ordinal categories such as restaurant or product rating from 1 to 5.\n\n### Selecting Feature\n\nWe will select appropriate features for the model. for that we will drop less important columns.\nFor this model our data has to be numeric. for that we will transform target data to numerical using LabelEncoding."},{"metadata":{"_uuid":"b65e10a6dc0774109438622bf11874dc10c15973"},"cell_type":"markdown","source":"### Spliting data\n\nTo understand model performance, dividing the dataset into a training set and a test set is a good strategy.\n\nLet's split dataset by using function train_test_split(). You need to pass 3 parameters features, target, and test_set size. Additionally, you can use random_state to select records randomly."},{"metadata":{"trusted":true,"_uuid":"965e9fb95964ae2cd843b20428ab5c86d643cc25","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nholdout = X_test # from now on we will refer to this\n               # dataframe as the holdout data\n    \nY = df[['surface']]\nfeatures = [c for c in df.columns if c not in ['surface','group_id']]\nX = df[features]\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.025, random_state = 0)\nX_train1, y_train1 = X_train, y_train\nX_test1, y_test1 = X_test, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"282c1566fa0c73d4f4b5d4a0ae3d2cdd99b0a5ba"},"cell_type":"code","source":"X_train.shape,X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b3ea7d07d452d9f9545f9bd87276533018b0293","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\nmodel = logreg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1be2ea6f1e2834657cb7f97542b0a7bc351cfd48","_kg_hide-input":true},"cell_type":"code","source":"from sklearn import metrics\ny_pred=logreg.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4ec3527a4d15777706c69d51e8ac6d7c41d4e25"},"cell_type":"markdown","source":"**Conclusion**: \nAccuracy score is very law. Logistic regression here not giving good result, \nso lets another model for our classification problem. Lets use Random forest classifier.\n\n**Random Forest Classifier**\nA random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default)."},{"metadata":{"trusted":true,"_uuid":"ba3f5f5f681f50435f1c5980992e78e2a01a26f3","_kg_hide-input":true},"cell_type":"code","source":"model1 = RandomForestClassifier(n_estimators=50, random_state=0).fit(X_train1, y_train1)\ny_pred = model1.predict(X_test1)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d21251fa9c7a2f5bd075c855cfb7342462b61a4f"},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9eaab341e88c04435fbc2480c3f417b5f321f49e"},"cell_type":"markdown","source":"**Conclusion:**\n    Accuracy score is 99%. which is really good.\n    \n  **Feature Importance**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a0056a9c1493426fbea30c5ac771c2112675ed6e"},"cell_type":"code","source":"feature_importances = pd.DataFrame(lr.feature_importances_, index = X_train.columns, columns = ['importance'])\nfeature_importances = feature_importances.sort_values('importance' , ascending = False)\nfeature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a42e4e45000baa5c4722561ec3a19eb3092d8630","_kg_hide-input":true},"cell_type":"code","source":"colors = ['grey'] * 6 + ['green'] * 5\ntrace1 = go.Bar(x = feature_importances.importance[:11][::-1],\n               y = [x.title()+\"  \" for x in feature_importances.index[:11][::-1]],\n               name = 'feature importnace (relative)',\n               marker = dict(color = colors, opacity=0.4), orientation = 'h')\n\ndata = [trace1]\n\nlayout = go.Layout(\n    margin=dict(l=400), width = 1000,\n    xaxis=dict(range=(0.0,0.15)),\n    title='Relative Feature Importance (Which Features are more important to make predictions ?)',\n    barmode='group',\n    bargap=0.25\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e2a6a8b99149fecc3474b8a06c755a220d7e79f"},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true,"_uuid":"06ef22c598dddbe5ada9e8d5c31f90f1583ebd46"},"cell_type":"markdown","source":"Thanks for stopping by. Please upvote if you like my kernel. \nStay Tuned for further Analaysis and Predictive models"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}