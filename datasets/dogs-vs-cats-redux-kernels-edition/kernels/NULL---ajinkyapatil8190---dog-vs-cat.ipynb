{"cells":[{"metadata":{"_uuid":"9679447ca4fd1d07e64e60663e51b81c844fd9de"},"cell_type":"markdown","source":"Dog Vs Cat an Image classifier.\nFull run through of raw images to classification with Convolutional Neural Network¶\nIn this notebook I am going to be running through taking raw images that have been labeled for us already, and then feeding them through a convolutional neural network for classification.\n\nThe images are either of dog(s) or cat(s).\n\nOnce you have downloaded and extracted the data from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data, you're ready to begin."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom random import shuffle\nimport cv2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom tqdm import tqdm\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"TRAIN_DIR = \"../input/train\" #Reading in the training directory.\n#TEST_DIR = \"../input/test\"\nIMG_SIZE = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc6e71977be0ce729595f740338dd989b3a16f39"},"cell_type":"markdown","source":"Now, the first order of business is to convert the images and labels to array information that we can pass through our network. To do this, we'll need a helper function to convert the image name to an array.\n\nOur images are labeled like \"cat.1\" or \"dog.3\" and so on, so we can just split out the dog/cat, and then convert to an array like so:\n"},{"metadata":{"trusted":true,"_uuid":"8fbb439600980e70c8d79a5f9653a78141266248"},"cell_type":"code","source":"def get_label(img):                      #Function to get the label of the image, is it a cat or a dog.\n    word_label = img.split('.')[0] \n    if word_label == 'cat' : return [1,0]\n    elif word_label == 'dog' : return [0,1]     #Return the respective label.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a62495fb70d9a634219f1668db151db5ec7e9fc"},"cell_type":"markdown","source":"Now, I build another function to fully process the training images and their labels into arrays and return the array:\n\n"},{"metadata":{"trusted":true,"_uuid":"7c91d5b27723f27561effbd1829db92c534728f2"},"cell_type":"code","source":"def create_train_data():                  #Function for creation of the training data\n    train_data = []\n    for img in (os.listdir(TRAIN_DIR)):        #For each image repeat.\n        label = get_label(img)                 #Get the image label.\n        path = os.path.join(TRAIN_DIR,img)\n        img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE),(IMG_SIZE,IMG_SIZE))  #Resizing the image\n        train_data.append([np.array(img),np.array(label)])\n    shuffle(train_data)\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48cb2dd38a9bd26e6fccb5599ea1c0a34154d883"},"cell_type":"markdown","source":"Here we call the create train data function to load all the images in the array."},{"metadata":{"trusted":true,"_uuid":"43781f7039337e98894158d4f4180d318c1f5ef3"},"cell_type":"code","source":"train_data = create_train_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ff4932c03bbbc31439a4016e249e517357373e7"},"cell_type":"code","source":"print(len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f129b3e0e5ddf3eb32e29331b47a701dfb16aab"},"cell_type":"markdown","source":"Next, we're ready to define our neural network:"},{"metadata":{"trusted":true,"_uuid":"3864539938bcb1c9bfff3a21a309b1683542615c"},"cell_type":"code","source":"import tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\n\nconvnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n\nconvnet = conv_2d(convnet, 32, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 32, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 32, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = conv_2d(convnet, 64, 2,activation='relu')\nconvnet = max_pool_2d(convnet, 2)\n\nconvnet = fully_connected(convnet, 1024,activation='relu')\nconvnet = dropout(convnet, 0.8)\n\nconvnet = fully_connected(convnet,2,activation='softmax')\nconvnet = regression(convnet,optimizer = 'adam', loss='categorical_crossentropy',name='conv_NN')\n\nmodel = tflearn.DNN(convnet)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a57324a7eea48a435c21ff33a15febc1f319a282"},"cell_type":"markdown","source":"Now, let's split out training and validation data, we use 24.500 images for training and 500 images for validation.\n\n"},{"metadata":{"trusted":true,"_uuid":"68fce7f9b3eca83084d8d759137590762c44bad9"},"cell_type":"code","source":"train = train_data[:-500]\ntest = train_data[-500:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e1676fbec616ef1361fd0e5e2afa2613559ff4d"},"cell_type":"markdown","source":"Now, the training data and testing data are both labeled datasets. The training data is what we'll fit the neural network with, and the test data is what we're going to use to validate the results. The test data will be \"out of sample,\" meaning the testing data will only be used to test the accuracy of the network, not to train it.\n\n\nNext, I am going to create our data arrays. For some reason, typical numpy logic like:\n\narray[:,0] and array[:,1] did NOT work for me here. Not sure what I'm doing wrong, so I do this instead to separate my features and labels:"},{"metadata":{"trusted":true,"_uuid":"9ebb9235d60607270d8e2a26a360f3e86959dd7a"},"cell_type":"code","source":"X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE,1) \nY = [i[1] for i in train]\n\ntest_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE,1) \ntest_y = [i[1] for i in test]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eca3fd2156d392ff86638165bc25576b0cdcb4de"},"cell_type":"markdown","source":"Now we fit for 5 epochs:\n\n"},{"metadata":{"trusted":true,"_uuid":"32d43e3c709bdac0b2d73a83887bbed09f522988"},"cell_type":"code","source":"model.fit(X,Y, n_epoch= 5,validation_set=(test_x,test_y),snapshot_step=500,show_metric=True,run_id='ConvNN')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45c06227ad21e01d0d41935a50b2d2c4ff77048d"},"cell_type":"markdown","source":"Here, I check the results by loading some images and printing their predictions."},{"metadata":{"trusted":true,"_uuid":"d1bc80caf3d92f9a6c93b780495723dd62e27168"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig = plt.figure()\n\nfor num, data in enumerate(test[:12]):\n    img_num = data[1]\n    img_data = data[0]\n    \n    y = fig.add_subplot(3,4,num+1)\n    orig = img_data\n    data = img_data.reshape(IMG_SIZE, IMG_SIZE,1)\n    \n    model_out = model.predict([data])[0]\n    \n    if( np.argmax(model_out) == 1):\n        str_label = 'Dog'\n    else:\n        str_label = 'Cat'\n    \n    y.imshow(orig,cmap='gray')\n    plt.title(str_label)\n    y.axes.get_xaxis().set_visible(False)\n    y.axes.get_yaxis().set_visible(False)\nplt.show()\n    \n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}