{"cells":[{"metadata":{"_uuid":"b4eb69b3f154f2e9c928a31d8d639efacf549fa5"},"cell_type":"markdown","source":"**Hi there!**\n\nHere you'll find a super simple implementation of the MNIST digit recognition using CNN.\nOf course, [Yassine's kernel](http://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6) was of a great help for me, as a beginner.\n\nFeel free to fork this notebook, or upvote it if you find it helpful :)"},{"metadata":{"trusted":true,"_uuid":"3e29f500c11d4e2fe5ec53be3e888143d3d2fc87"},"cell_type":"code","source":"#importing libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, MaxPool2D\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import confusion_matrix\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c71618d0500ae5c51f38efbf24840e55c56321c2"},"cell_type":"code","source":"#reading data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"763f6c1cda549c6678efa5db8578703a80f97385"},"cell_type":"code","source":"#train data x and y\nx_train = train.drop(labels = [\"label\"], axis = 1)\ny_train = train[\"label\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5648056b6a0536baca9256f092404075d974da1b"},"cell_type":"code","source":"#normalizing and reshaping data\nx_train = x_train / 255.0 #pixel values vary between 0 and 255\ntest = test / 255.0\nx_train = x_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0894ca5bddbffd127ffc34ff4343f3aead88afce"},"cell_type":"code","source":"#one hot encoding for y\ny_train = to_categorical(y_train)\n#train test split\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e32c7328d04f2538796d358ba58d9f3249e78d20"},"cell_type":"code","source":"#defining the model\nmodel = Sequential()\n# 2 conv2d layers\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4)) \n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten()) #flattening the data into a 1D vector, before the fully connected layers\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dense(10, activation = 'softmax'))\n\n\n#optimizing the model: using Adam omptimizer\noptim=Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n#compiling the model\nmodel.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n#training the model\nmodel.fit(X_train, Y_train, epochs=10, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66fae5efd6aa8e58e946a0f53c34660eb4fe5ff0"},"cell_type":"code","source":"# Predicting the values from the validation dataset\nY_pred = model.predict(X_val)\n# converting one hot vectors to actual values \nY_pred = np.argmax(Y_pred,axis = 1) \nY_true = np.argmax(Y_val,axis = 1) \n# computing the confusion matrix\ncm = confusion_matrix(Y_true, Y_pred) \n\n#plotting the confusion matrix\nplt.imshow(cm)\nplt.title('confusion matrix')\nplt.colorbar()\ntick_marks = np.arange(10)\nplt.xticks(tick_marks, range(10), rotation=45)\nplt.yticks(tick_marks, range(10))\n\nthresh = cm.max() / 2.\nfor i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, cm[i, j],\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] > thresh else \"black\")\n\nplt.tight_layout()\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a5b495a57ca2512cf0243aa1766609f07085547"},"cell_type":"code","source":"#evaluating the model: 0.9926 accuracy\nloss_and_metrics = model.evaluate(X_val, Y_val, batch_size=128)\nloss_and_metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4cf293d8c76a004e351ba21fe91aed60afafb6a"},"cell_type":"code","source":"#predicting on the test set\ny_pred = model.predict(test, batch_size = 128)\npred = np.argmax(y_pred,axis = 1)\n\npred = pd.Series(pred,name=\"Label\")\n#preparing submission\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}