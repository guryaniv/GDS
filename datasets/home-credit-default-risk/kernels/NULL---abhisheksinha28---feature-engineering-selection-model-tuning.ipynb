{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import sys\n\ndef return_size(df):\n    \"\"\"Return size of dataframe in gigabytes\"\"\"\n    return round(sys.getsizeof(df) / 1e9, 2)\n\ndef convert_types(df):\n    print(f'Original size of data: {return_size(df)} gb.')\n    for c in df:\n        if df[c].dtype == 'object':\n            df[c] = df[c].astype('category')\n    print(f'New size of data: {return_size(df)} gb.')\n    return df\n# matplotlib and seaborn for plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Suppress warnings from pandas\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nplt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"2976c1b75c38de5bf1e8d39f099e677f030cdac0"},"cell_type":"code","source":"train = pd.read_csv('../input/application_train.csv').replace({365243: np.nan})\ntest = pd.read_csv('../input/application_test.csv').replace({365243: np.nan})\nbureau = pd.read_csv('../input/bureau.csv').replace({365243: np.nan})\nbureau_balance = pd.read_csv('../input/bureau_balance.csv').replace({365243: np.nan})\n\ntest['TARGET'] = np.nan\ndata = train.append(test, ignore_index=True, sort=True)\n\ndata = convert_types(data)\nbureau = convert_types(bureau)\nbureau_balance = convert_types(bureau_balance)\n\nimport gc\ngc.enable()\ndel train, test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11cfb25c0454a1c9dbebefb80aba603d179779bb"},"cell_type":"code","source":"def kde_target(var_name,df):\n    corr = df['TARGET'].corr(df[var_name])\n    sns.kdeplot(df.ix[df['TARGET']==0, var_name], label = 'target ==0')\n    sns.kdeplot(df.ix[df['TARGET']==1, var_name], label= 'target ==1')\n    plt.xlabel(var_name); plt.ylabel('Density'); plt.title('%s Distribution' % var_name)\n    plt.legend();\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c29165e010b3a36a698d44dd88197d4318a0fa15"},"cell_type":"code","source":"def agg_numeric(df, group_var, df_name):\n    \n    \n    \n    # Remove id variables other than grouping variable\n    for col in df:\n        if col != group_var and 'SK_ID' in col:\n            df = df.drop(columns = col)\n            \n    group_ids = df[group_var]\n    numeric_df = df.select_dtypes('number')\n    numeric_df[group_var] = group_ids\n\n    # Group by the specified variable and calculate the statistics\n    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n\n    # Need to create new column names\n    columns = [group_var]\n\n    # Iterate through the variables names\n    for var in agg.columns.levels[0]:\n        # Skip the grouping variable\n        if var != group_var:\n            # Iterate through the stat names\n            for stat in agg.columns.levels[1][:-1]:\n                # Make a new column name for the variable and stat\n                columns.append('%s_%s_%s' % (df_name, var, stat))\n\n    agg.columns = columns\n    _, idx = np.unique(agg,axis=1,return_index=True)\n    agg= agg.iloc[:,idx]\n    \n    return agg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c5c25ca5ba354e1dcde73302aa70f680a11459e"},"cell_type":"code","source":"def target_corrs(df):\n    corrs = []\n    for col in df :\n        print(col)\n        if col!= 'TARGET':\n            corr = df['TARGET'].corr(df[col])\n            corrs.append((col,corr))\n    corrs = sorted(corrs, key = lambda x: abs(x[1]), reverse = True)\n    return corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dddca460e4c93c28267157a1c57229494be9353"},"cell_type":"code","source":"def agg_categorical(df,group_var,df_name) :\n    categorical = pd.get_dummies(df.select_dtypes('category'))\n    categorical[group_var] = df[group_var]\n    categorical = categorical.groupby(group_var).agg(['sum','count','mean'])\n    \n    column_names = []\n    \n    for var in categorical.columns.levels[0]:\n        # Iterate through the stats in level 1\n        for stat in ['sum','count','mean']:\n            # Make a new column name\n            column_names.append('%s_%s_%s' % (df_name, var, stat))\n    \n    categorical.columns = column_names\n    \n    _,idx = np.unique(categorical, axis=1, return_index=True)\n    categorical = categorical.iloc[:,idx]\n    return categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3375191d43d208319c3200d0b8de6c6bece9548a"},"cell_type":"code","source":"import gc\n\ndef agg_child(df,parent_var,df_name):\n    df_agg = agg_numeric(df,parent_var,df_name)\n    df_cat = agg_categorical(df,parent_var,df_name)\n    df_combined = df_agg.merge(df_cat,on=parent_var, how='outer')\n    \n    _,idx = np.unique(df_combined,axis=1,return_index=True)\n    df_combined = df_combined.iloc[:,idx]\n    \n    gc.enable()\n    del df_agg,df_cat\n    gc.collect()\n    \n    return df_combined","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee1ff9765bdff51f850ec2d8a00308ca86c7696f"},"cell_type":"code","source":"def agg_grandchild(df, parent_df,parent_var, grandparent_var, df_name):\n    parent_df = parent_df[[parent_var,grandparent_var]].copy().set_index(parent_var)\n    df_agg = agg_numeric(df,parent_var,'%s_LOAN' % df_name)\n    df_agg = df_agg.merge(parent_df, on = parent_var, how = 'left')\n    df_agg_client = agg_numeric(df_agg,grandparent_var,'%s_CLIENT' %df_name)\n    if any(df.dtypes == 'category'):\n    \n        # Aggregate the categorical variables at the parent level\n        df_agg_cat = agg_categorical(df, parent_var, '%s_LOAN' % df_name)\n        df_agg_cat = df_agg_cat.merge(parent_df,\n                                      on = parent_var, how = 'left')\n\n        # Aggregate the categorical variables at the grandparent level\n        df_agg_cat_client = agg_numeric(df_agg_cat, grandparent_var, '%s_CLIENT' % df_name)\n        df_info = df_agg_client.merge(df_agg_cat_client, on = grandparent_var, how = 'outer')\n        \n        gc.enable()\n        del df_agg, df_agg_client, df_agg_cat, df_agg_cat_client\n        gc.collect()\n        \n    else:\n        df_info =df_agg_client.copy()\n        gc.enable()\n        del df_agg_client,df_agg\n        gc.collect()\n        \n    _, idx = np.unique(df_info, axis=1, return_index =True)\n    df_info = df_info.iloc[:,idx]\n    return df_info\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3bc99cf6ad4a56997c2d6ab557d44e69099ac6d"},"cell_type":"code","source":"data['LOAN_RATE'] = data['AMT_ANNUITY'] / data['AMT_CREDIT'] \ndata['CREDIT_INCOME_RATIO'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\ndata['EMPLOYED_BIRTH_RATIO'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\ndata['EXT_SOURCE_SUM'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].sum(axis = 1)\ndata['EXT_SOURCE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\ndata['AMT_REQ_SUM'] = data[[x for x in data.columns if 'AMT_REQ_' in x]].sum(axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8973abff008dfa84af881418d254126c92b67d0a"},"cell_type":"code","source":"bureau['LOAN_RATE'] = bureau['AMT_ANNUITY'] / bureau['AMT_CREDIT_SUM']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27d95be0990172d5a5df7ebdec678650ba3fb359"},"cell_type":"code","source":"bureau_info = agg_child(bureau, 'SK_ID_CURR', 'BUREAU')\nbureau_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bebd5d0a043a6e6643b499a08f1db0385035bfa"},"cell_type":"code","source":"bureau_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fb9a71e518b6d22d58bc9ba9f1dfe1c0a3739bc"},"cell_type":"code","source":"bureau_balance['PAST_DUE'] = bureau_balance['STATUS'].isin(['1', '2', '3', '4', '5'])\nbureau_balance['ON_TIME'] = bureau_balance['STATUS'] == '0'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e0b3d6045ad68981ff7e5ba5d4313425f894248"},"cell_type":"code","source":"bureau_balance_info = agg_grandchild(bureau_balance, bureau, 'SK_ID_BUREAU', 'SK_ID_CURR', 'BB')\ndel bureau_balance, bureau\nbureau_balance_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"717c7e74875bc0cec5d10b8c3285dad718e74021"},"cell_type":"code","source":"bureau_balance_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"831a95e470b0d1384d70b7fd6789273efb9a257f"},"cell_type":"code","source":"data = data.set_index('SK_ID_CURR')\ndata = data.merge(bureau_info, on = 'SK_ID_CURR', how = 'left')\ndel bureau_info\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa693d5b486fa0567459eb6e7470607784f98e1e"},"cell_type":"code","source":"data = data.merge(bureau_balance_info, on = 'SK_ID_CURR', how = 'left')\ndel bureau_balance_info\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"728940a879dfe88bd37c8e12f3c04f5a044c3b1e"},"cell_type":"code","source":"previous = pd.read_csv('../input/previous_application.csv').replace({365243: np.nan})\nprevious = convert_types(previous)\nprevious['LOAN_RATE'] = previous['AMT_ANNUITY'] / previous['AMT_CREDIT']\nprevious[\"AMT_DIFFERENCE\"] = previous['AMT_CREDIT'] - previous['AMT_APPLICATION']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8788dcb0c88d5207fecb55143c0a5818d184d1f3"},"cell_type":"code","source":"previous_info = agg_child(previous, 'SK_ID_CURR', 'PREVIOUS')\nprevious_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fdb4b420279b76bfe2f4de7c7bcffeaa576a4d2"},"cell_type":"code","source":"data = data.merge(previous_info, on = 'SK_ID_CURR', how = 'left')\ndel previous_info\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96e5f03cf1832ce0db9cfab445c777813373f617"},"cell_type":"code","source":"installments = pd.read_csv('../input/installments_payments.csv').replace({365243: np.nan})\ninstallments = convert_types(installments)\ninstallments['LATE'] = installments['DAYS_ENTRY_PAYMENT'] > installments['DAYS_INSTALMENT']\ninstallments['LOW_PAYMENT'] = installments['AMT_PAYMENT'] < installments['AMT_INSTALMENT']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86425b27a9dd6812bf08b046175e3f79df7ad6c5"},"cell_type":"code","source":"installments_info = agg_grandchild(installments,previous,'SK_ID_PREV', 'SK_ID_CURR', 'IN')\ndel installments\ninstallments_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4fc33c143141aafbdccab856e785469a5daab3a"},"cell_type":"code","source":"data = data.merge(installments_info, on = 'SK_ID_CURR', how = 'left')\ndel installments_info\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7716ae881c8bffdd120bdf3954a3433bd46c7fe1"},"cell_type":"code","source":"cash = pd.read_csv('../input/POS_CASH_balance.csv').replace({365243: np.nan})\ncash = convert_types(cash)\ncash['LATE_PAYMENT'] = cash['SK_DPD'] > 0.0\ncash['INSTALLMENTS_PAID'] = cash['CNT_INSTALMENT'] - cash['CNT_INSTALMENT_FUTURE']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ac84cb25c1c38739c87eda33310e2871bea3ea5"},"cell_type":"code","source":"cash_info = agg_grandchild(cash, previous, 'SK_ID_PREV', 'SK_ID_CURR', 'CASH')\ndel cash\ncash_info.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"102f92d3016830c3ebc0bebc387795a8eea55e48"},"cell_type":"code","source":"data = data.merge(cash_info, on='SK_ID_CURR', how='left')\ndel cash_info\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"348c11b688c513c82af99cbf437c0c0f75121836"},"cell_type":"code","source":"credit = pd.read_csv('../input/credit_card_balance.csv').replace({365243: np.nan})\ncredit = convert_types(credit)\ncredit['OVER_LIMIT'] = credit['AMT_BALANCE'] > credit['AMT_CREDIT_LIMIT_ACTUAL']\ncredit['BALANCE_CLEARED'] = credit['AMT_BALANCE'] == 0.0\ncredit['LOW_PAYMENT'] = credit['AMT_PAYMENT_CURRENT'] < credit['AMT_INST_MIN_REGULARITY']\ncredit['LATE'] = credit['SK_DPD'] > 0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa5fbf3ab9cdcf00d6735217274611ff3cb3f44b"},"cell_type":"code","source":"credit_info = agg_grandchild(credit, previous, 'SK_ID_PREV', 'SK_ID_CURR', 'CC')\ndel credit, previous\ncredit_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d3a0d6b363e4f731cb2c72ca5861ae3a5aae916"},"cell_type":"code","source":"gc.collect()\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4eaf771d28c51a302cc6395b873890d10ea020c0"},"cell_type":"code","source":"\ndata = data.merge(credit_info, on = 'SK_ID_CURR', how = 'left')\ndel credit_info\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e862982f1b3a4e0734565419ed605f59ce5bcacc"},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e4a27b0ff37f9521006f8bb15aab68394d94c78"},"cell_type":"code","source":"print('After manual feature engineering, there are {} features.'.format(data.shape[1] - 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c334d57ea769a1b3549f49f33a9d2027327eaf"},"cell_type":"code","source":"gc.enable()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"461804cd251624f50fc7f31995bfe2de735a6095"},"cell_type":"code","source":"print(f'Final size of data {return_size(data)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8000dedd5d4a7f0dfa23e6e26d23ebf6fee9dbcd"},"cell_type":"code","source":"#data.to_csv('clean_manual_features.csv', chunksize = 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd954d891864df6d846c6b38bbccaf8a6b3f5d78"},"cell_type":"code","source":"data.reset_index(inplace = True)\ntrain, test = data[data['TARGET'].notnull()].copy(), data[data['TARGET'].isnull()].copy()\ngc.enable()\ndel data\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b36e5f8f1dc25ef48e8fd15d6693313cd86f8d56"},"cell_type":"code","source":"train_labels = np.array(train.pop('TARGET')).reshape((-1, ))\n\ntest_ids = list(test.pop('SK_ID_CURR'))\ntest = test.drop(columns = ['TARGET'])\ntrain = train.drop(columns = ['SK_ID_CURR'])\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bb23255986edf91fbefa62d7a333c9da984b5f6"},"cell_type":"code","source":"train_df = train[:1000]\ntest_df = test[:1000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5dd94ed76ad1bcf0c947c70748df9c0a765df97"},"cell_type":"code","source":"train = pd.get_dummies(train)\ntest = pd.get_dummies(test)\n\n# Match the columns in the dataframes\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\ntrain_df = pd.get_dummies(train_df)\ntest_df = pd.get_dummies(test_df)\n\n# Match the columns in the dataframes\ntrain_df, test_df = train_df.align(test_df, join = 'inner', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07603d2b6cd6caeb2ab20aeac82e737bf7faf528"},"cell_type":"code","source":"cols_with_id = [x for x in train_df.columns if 'SK_ID_CURR' in x]\ncols_with_bureau_id = [x for x in train_df.columns if 'SK_ID_BUREAU' in x]\ncols_with_previous_id = [x for x in train_df.columns if 'SK_ID_PREV' in x]\nprint('There are %d columns that contain SK_ID_CURR' % len(cols_with_id))\nprint('There are %d columns that contain SK_ID_BUREAU' % len(cols_with_bureau_id))\nprint('There are %d columns that contain SK_ID_PREV' % len(cols_with_previous_id))\n\ntrain = train.drop(columns = cols_with_id)\ntest = test.drop(columns = cols_with_id)\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffc60f870398e96b8bfdee9310d194d58fbb648b"},"cell_type":"code","source":"threshold = 0.9\n\n# Absolute value correlation matrix\ncorr_matrix = train_df.corr().abs()\ncorr_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a80a94b1b553bddc0dd6dd2e4e2b41a45b9aa27"},"cell_type":"code","source":"upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84b98384f4bb2e033463795e923bc4935bd0b267"},"cell_type":"code","source":"to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acb4917da29f97eafd007f849964d4713b757106"},"cell_type":"code","source":"train = train.drop(columns = to_drop)\ntest = test.drop(columns = to_drop)\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"445f964d4ea3d224b06e444a35ebfb28ac236ab4"},"cell_type":"code","source":"train_missing = (train.isnull().sum() / len(train)).sort_values(ascending = False)\ntrain_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2fb3d9818df389b53c38f80ede006cd37080609"},"cell_type":"code","source":"test_missing = (test.isnull().sum() / len(test)).sort_values(ascending = False)\ntest_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24cd938c3aba9c8fc70c94d170f802a788a7200a"},"cell_type":"code","source":"train_missing = train_missing.index[train_missing > 0.75]\ntest_missing = test_missing.index[test_missing > 0.75]\n\nall_missing = list(set(set(train_missing) | set(test_missing)))\nprint('There are %d columns with more than 75%% missing values' % len(all_missing))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31eb8d9505a93428d4a4c9c4f6cdab4b5f8eaf6b"},"cell_type":"code","source":"#train_labels = train[\"TARGET\"]\n#train_ids = train['SK_ID_CURR']\n#test_ids = test['SK_ID_CURR']\n\ntrain = pd.get_dummies(train.drop(columns = all_missing))\ntest = pd.get_dummies(test.drop(columns = all_missing))\n\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\nprint('Training set full shape: ', train.shape)\nprint('Testing set full shape: ' , test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9b4ee8d72c00899c40af40884f6ccca077f8b00"},"cell_type":"code","source":"import lightgbm as lgb\nfeature_importances = np.zeros(train.shape[1])\n\n# Create the model with several hyperparameters\nmodel = lgb.LGBMClassifier(objective='binary', boosting_type = 'goss', n_estimators = 10000, class_weight = 'balanced')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d45c5be4f19fe60ba84786867cef00e3c695249"},"cell_type":"code","source":"train1 = pd.read_csv('../input/application_train.csv')\ntest1 = pd.read_csv('../input/application_test.csv')\ntrain_labels = train1[\"TARGET\"]\ntrain_ids = train1['SK_ID_CURR']\ntest_ids = test1['SK_ID_CURR']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9316061192e3879dffecc2d61a2376478c5bbdbd"},"cell_type":"code","source":"del train1 , test1\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df9d51de0eefc430bdc0d80010a6d734bfb2633"},"cell_type":"code","source":"for i in range(2):\n    \n    # Split into training and validation set\n    train_features, valid_features, train_y, valid_y = train_test_split(train, train_labels, test_size = 0.25, random_state = i)\n    \n    # Train using early stopping\n    model.fit(train_features, train_y, early_stopping_rounds=100, eval_set = [(valid_features, valid_y)], \n              eval_metric = 'auc', verbose = 200)\n    \n    # Record the feature importances\n    feature_importances += model.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61718b279703c84e69b2635d7f3cc5e1c2b4da1f"},"cell_type":"code","source":"feature_importances = feature_importances / 2\nfeature_importances = pd.DataFrame({'feature': list(train.columns), 'importance': feature_importances}).sort_values('importance', ascending = False)\n\nfeature_importances.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e46ef075c7a3139d4a925ac74179d30193377c57"},"cell_type":"code","source":"zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])\nprint('There are %d features with 0.0 importance' % len(zero_features))\nfeature_importances.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abf9fe42c6a9cbe71459fbc9585f08f4595e7b7b"},"cell_type":"code","source":"train = train.drop(columns = zero_features)\ntest = test.drop(columns = zero_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e97229173b3f8ef99b59889c5fde64cf849c8cf9"},"cell_type":"code","source":"def plot_feature_importances(df, n = 15, threshold = None):\n    \"\"\"\n    Plots n most important features. Also plots the cumulative importance if\n    threshold is specified and prints the number of features needed to reach threshold cumulative importance.\n    Intended for use with any tree-based feature importances. \n    \n    Parameters\n    --------\n    df : dataframe\n        Dataframe of feature importances. Columns must be \"feature\" and \"importance\"\n    \n    n : int, default = 15\n        Number of most important features to plot\n    \n    threshold : float, default = None\n        Threshold for cumulative importance plot. If not provided, no plot is made\n        \n    Return\n    --------\n    df : dataframe\n        Dataframe ordered by feature importances with a normalized column (sums to 1)\n        and a cumulative importance column\n    \n    Note\n    --------\n        * Normalization in this case means sums to 1. \n        * Cumulative importance is calculated by summing features from most to least important\n    \n    \"\"\"\n    \n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n    df['cumulative_importance'] = np.cumsum(df['importance_normalized'])\n    \n    plt.rcParams['font.size'] = 12\n    \n    # Bar plot of n most important features\n    df.loc[:n, :].plot.barh(y = 'importance_normalized', \n                            x = 'feature', color = 'blue', edgecolor = 'k', figsize = (12, 8),\n                            legend = False)\n\n    plt.xlabel('Normalized Importance', size = 18); plt.ylabel(''); \n    plt.title(f'Top {n} Most Important Features', size = 18)\n    plt.gca().invert_yaxis()\n    \n    if threshold:\n        # Cumulative importance plot\n        plt.figure(figsize = (8, 6))\n        plt.plot(list(range(len(df))), df['cumulative_importance'], 'b-')\n        plt.xlabel('Number of Features', size = 16); plt.ylabel('Cumulative Importance', size = 16); \n        plt.title('Cumulative Feature Importance', size = 18);\n        \n        # Number of features needed for threshold cumulative importance\n        importance_index = np.min(np.where(df['cumulative_importance'] > threshold))\n        \n        # Add vertical line to plot\n        plt.vlines(importance_index + 1, ymin = 0, ymax = 1.2, linestyles = '--', colors = 'red')\n        plt.show();\n        \n        print('{} features required for {:.0f}% of cumulative importance.'.format(importance_index + 1, 100 * threshold))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99d0fe76b8b1b3962951e8bc8afbcec445792f9b"},"cell_type":"code","source":"plot_feature_importances(feature_importances, n=15, threshold = 0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26773d9c1ce37a1ba3a733e17d41cebb8691e4eb"},"cell_type":"code","source":"train['TARGET'] = train_labels\ntrain['SK_ID_CURR'] = train_ids\ntest['SK_ID_CURR'] = test_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"915fa3ae011e09b9f797aebc1480c72a509ebd87"},"cell_type":"code","source":"features = train\n\n# Sample 16000 rows (10000 for training, 6000 for testing)\nfeatures = features.sample(n = 16000, random_state = 42)\n\n# Only numeric features\nfeatures = features.select_dtypes('number')\n\n# Extract the labels\nlabels = np.array(features['TARGET'].astype(np.int32)).reshape((-1, ))\nfeatures = features.drop(columns = ['TARGET', 'SK_ID_CURR'])\n\n# Split into training and testing data\ntrain_features, test_features, trainlabels, testlabels = train_test_split(features, labels, test_size = 6000, random_state = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fb7255b9bd0d156b5b6046d73de6ca50e403588"},"cell_type":"code","source":"print(\"Training features shape: \", train_features.shape)\nprint(\"Testing features shape: \", test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08f0854f9c7871f5b759d757bf3e4073e3240a8a"},"cell_type":"code","source":"train_set = lgb.Dataset(data = train_features, label = trainlabels)\ntest_set = lgb.Dataset(data = test_features, label = testlabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce87f6ff71795dc8c66a01436ea16560dfbaca26"},"cell_type":"code","source":"default_params = model.get_params()\n\nN_FOLDS = 5\nMAX_EVALS = 5\n# Remove the number of estimators because we set this to 10000 in the cv call\ndel default_params['n_estimators']\n\n# Cross validation with early stopping\ncv_results = lgb.cv(default_params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, \n                    metrics = 'auc', nfold = N_FOLDS, seed = 42)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23c7e279dda87cb2db3bb6203ecf88aa3a429a61"},"cell_type":"code","source":"print('The maximum validation ROC AUC was: {:.5f} with a standard deviation of {:.5f}.'.format(cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('The optimal number of boosting rounds (estimators) was {}.'.format(len(cv_results['auc-mean'])))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab628373657ce4cb3b66b8bdda5963e708d62c12"},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nmodel.n_estimators = len(cv_results['auc-mean'])\n\n# Train and make predicions with model\nmodel.fit(train_features, trainlabels)\npreds = model.predict_proba(test_features)[:, 1]\nbaseline_auc = roc_auc_score(testlabels, preds)\n\nprint('The baseline model scores {:.5f} ROC AUC on the test set.'.format(baseline_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9592cad7602fcf451a916e7300a7c8098002863"},"cell_type":"code","source":"def objective(hyperparameters, iteration):\n    \"\"\"Objective function for grid and random search. Returns\n       the cross validation score from a set of hyperparameters.\"\"\"\n    \n    # Number of estimators will be found using early stopping\n    if 'n_estimators' in hyperparameters.keys():\n        del hyperparameters['n_estimators']\n    \n     # Perform n_folds cross validation\n    cv_results = lgb.cv(hyperparameters, train_set, num_boost_round = 10000, nfold = N_FOLDS, \n                        early_stopping_rounds = 100, metrics = 'auc', seed = 42)\n    \n    # results to retun\n    score = cv_results['auc-mean'][-1]\n    estimators = len(cv_results['auc-mean'])\n    hyperparameters['n_estimators'] = estimators \n    \n    return [score, hyperparameters, iteration]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54ac4b72bfa605606bda9f5eaf3576967dc8a984"},"cell_type":"code","source":"score, params, iteration = objective(default_params, 1)\n\nprint('The cross-validation ROC AUC was {:.5f}.'.format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ad40208fff62225ccb2a4a8a28f61725ed6c36e"},"cell_type":"code","source":"# Create a default model\nmodel = lgb.LGBMModel()\nmodel.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e93a289a7bcc6f0d330748cc5e097d9fefe78d66"},"cell_type":"code","source":"param_grid = {\n    'boosting_type': ['gbdt', 'goss', 'dart'],\n    'num_leaves': list(range(20, 150)),\n    'learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 1000)),\n    'subsample_for_bin': list(range(20000, 300000, 20000)),\n    'min_child_samples': list(range(20, 500, 5)),\n    'reg_alpha': list(np.linspace(0, 1)),\n    'reg_lambda': list(np.linspace(0, 1)),\n    'colsample_bytree': list(np.linspace(0.6, 1, 10)),\n    'subsample': list(np.linspace(0.5, 1, 100)),\n    'is_unbalance': [True, False]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f6ebd26fdf1cd370bb899cd29475a8e02b77871"},"cell_type":"code","source":"import random\n\nrandom.seed(50)\n\n# Randomly sample a boosting type\nboosting_type = random.sample(param_grid['boosting_type'], 1)[0]\n\n# Set subsample depending on boosting type\nsubsample = 1.0 if boosting_type == 'goss' else random.sample(param_grid['subsample'], 1)[0]\n\nprint('Boosting type: ', boosting_type)\nprint('Subsample ratio: ', subsample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06db4039f26dd04adcabba72db0e02b426fd5765"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Learning rate histogram\nplt.hist(param_grid['learning_rate'], bins = 20, color = 'r', edgecolor = 'k');\nplt.xlabel('Learning Rate', size = 14); plt.ylabel('Count', size = 14); plt.title('Learning Rate Distribution', size = 18);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbaf933b2489d786b414cba8d9cf0757bd53c96f"},"cell_type":"code","source":"random_results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n                              index = list(range(MAX_EVALS)))\n\ngrid_results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n                              index = list(range(MAX_EVALS)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fd330508cefedb98106a2c99fd8c4925fddadda"},"cell_type":"code","source":"import itertools\n\ndef grid_search(param_grid, max_evals = MAX_EVALS):\n    \"\"\"Grid search algorithm (with limit on max evals)\"\"\"\n    \n    # Dataframe to store results\n    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n                              index = list(range(MAX_EVALS)))\n    \n    # https://codereview.stackexchange.com/questions/171173/list-all-possible-permutations-from-a-python-dictionary-of-lists\n    keys, values = zip(*param_grid.items())\n    \n    i = 0\n    \n    # Iterate through every possible combination of hyperparameters\n    for v in itertools.product(*values):\n        \n        # Create a hyperparameter dictionary\n        hyperparameters = dict(zip(keys, v))\n        \n        # Set the subsample ratio accounting for boosting type\n        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n        \n        # Evalute the hyperparameters\n        eval_results = objective(hyperparameters, i)\n        \n        results.loc[i, :] = eval_results\n        \n        i += 1\n        \n        # Normally would not limit iterations\n        if i > MAX_EVALS:\n            break\n        # Sort with best score on top\n    results.sort_values('score', ascending = False, inplace = True)\n    results.reset_index(inplace = True)\n    \n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88233a90fbd52b1e391597f342322852d2094402"},"cell_type":"code","source":"''''\ngrid_results = grid_search(param_grid)\n\nprint('The best validation score was {:.5f}'.format(grid_results.loc[0, 'score']))\nprint('\\nThe best hyperparameters were:')\ngrid_results = grid_results.drop(columns='index')\ngrid_results.to_csv('grid_results.csv', header= ['score', 'hyperparameters', 'iteration'] )\nimport pprint\npprint.pprint(grid_results.loc[0, 'params'])\n''''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9762370a4c89559e6f110146d7026f3a3ef88dff"},"cell_type":"code","source":"''''\ngrid_search_params = grid_results.loc[0, 'params']\n\n# Create, train, test model\nmodel = lgb.LGBMClassifier(**grid_search_params, random_state=42)\nmodel.fit(train_features, trainlabels)\n\npreds = model.predict_proba(test_features)[:, 1]\n\nprint('The best model from grid search scores {:.5f} ROC AUC on the test set.'.format(roc_auc_score(testlabels, preds)))\n''''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3a7a647b454c1b454789bea2ba516be11e521f8"},"cell_type":"code","source":"random.seed(50)\n\n# Randomly sample from dictionary\nrandom_params = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n# Deal with subsample ratio\nrandom_params['subsample'] = 1.0 if random_params['boosting_type'] == 'goss' else random_params['subsample']\n\nrandom_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bf23bb0857b39a384de57fccd3b16ac5295fab5"},"cell_type":"code","source":"def random_search(param_grid, max_evals = MAX_EVALS):\n    \"\"\"Random search for hyperparameter optimization\"\"\"\n    \n    # Dataframe for results\n    results = pd.DataFrame(columns = ['score', 'params', 'iteration'],\n                                  index = list(range(MAX_EVALS)))\n    \n    # Keep searching until reach max evaluations\n    for i in range(MAX_EVALS):\n        \n        # Choose random hyperparameters\n        hyperparameters = {k: random.sample(v, 1)[0] for k, v in param_grid.items()}\n        hyperparameters['subsample'] = 1.0 if hyperparameters['boosting_type'] == 'goss' else hyperparameters['subsample']\n\n        # Evaluate randomly selected hyperparameters\n        eval_results = objective(hyperparameters, i)\n        \n        results.loc[i, :] = eval_results\n    \n    # Sort with best score on top\n    results.sort_values('score', ascending = False, inplace = True)\n    results.reset_index(inplace = True)\n    return results ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54f3904f63bc7519795ad17270c9b79ee3600c77"},"cell_type":"code","source":"random_results = random_search(param_grid)\n\nprint('The best validation score was {:.5f}'.format(random_results.loc[0, 'score']))\nprint('\\nThe best hyperparameters were:')\n\nimport pprint\npprint.pprint(random_results.loc[0, 'params'])\nrandom_results = random_results.drop(columns='index')\nrandom_results.to_csv('random_results.csv', header= ['score', 'hyperparameters', 'iteration'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcdd5fa619029551931c00e4f9d4ed39f7698d75"},"cell_type":"code","source":"random_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e58bceeaf9ebc3d0ecf269cedaeaf305096b01b"},"cell_type":"code","source":"def evaluate(results, name):\n    \"\"\"Evaluate model on test data using hyperparameters in results\n       Return dataframe of hyperparameters\"\"\"\n        \n    # Sort with best values on top\n    results = results.sort_values('score', ascending = False).reset_index(drop = True)\n    \n    # Print out cross validation high score\n    print('The highest cross validation score from {} was {:.5f} found on iteration {}.'.format(name, results.loc[0, 'score'], results.loc[0, 'iteration']))\n    \n    # Use best hyperparameters to create a model\n    hyperparameters = results.loc[0, 'params']\n    model = lgb.LGBMClassifier(**hyperparameters)\n    \n    # Train and make predictions\n    model.fit(train_features, trainlabels)\n    preds = model.predict_proba(test_features)[:, 1]\n    \n    print('ROC AUC from {} on test data = {:.5f}.'.format(name, roc_auc_score(testlabels, preds)))\n    \n    # Create dataframe of hyperparameters\n    hyp_df = pd.DataFrame(columns = list(results.loc[0, 'params'].keys()))\n\n    # Iterate through each set of hyperparameters that were evaluated\n    for i, hyp in enumerate(results['params']):\n        hyp_df = hyp_df.append(pd.DataFrame(hyp, index = [0]), \n                               ignore_index = True)\n        \n    # Put the iteration and score in the hyperparameter dataframe\n    hyp_df['iteration'] = results['iteration']\n    hyp_df['score'] = results['score']\n    \n    return hyp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acafb7844bc5914a395915b947f33675fdc27448"},"cell_type":"code","source":"random_hyp = evaluate(random_results, name = 'random search')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95d909d586f79086491af7cd16f0f5fa4f38538d"},"cell_type":"code","source":"test_ids = test['SK_ID_CURR']\ntrain_labels = np.array(train['TARGET'].astype(np.int32)).reshape((-1, ))\n\ntrain = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\ntest = test.drop(columns = ['SK_ID_CURR'])\n\nprint('Training shape: ', train.shape)\nprint('Testing shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b11e1c49526954d6bf6a486e5edee21fbd53388e"},"cell_type":"code","source":"train_set = lgb.Dataset(train, label = train_labels)\n\nhyperparameters = dict(**random_results.loc[0, 'params'])\ndel hyperparameters['n_estimators']\n\n# Cross validation with n_folds and early stopping\ncv_results = lgb.cv(hyperparameters, train_set,\n                    num_boost_round = 10000, early_stopping_rounds = 100, \n                    metrics = 'auc', nfold = N_FOLDS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf8544fb111c7471f19f6b422161006351eec572"},"cell_type":"code","source":"print('The cross validation score on the full dataset = {:.5f} with std: {:.5f}.'.format(\n    cv_results['auc-mean'][-1], cv_results['auc-stdv'][-1]))\nprint('Number of estimators = {}.'.format(len(cv_results['auc-mean'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e0d68ed98a5d744864ea0c0cd48aaa16c4022b6"},"cell_type":"code","source":"# Train the model with the optimal number of estimators from early stopping\nmodel = lgb.LGBMClassifier(n_estimators = len(cv_results['auc-mean']), **hyperparameters)\nmodel.fit(train, train_labels)\n                        \n# Predictions on the test data\npreds = model.predict_proba(test)[:, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5557111cb6bbd434b1a4e46cd0b9aa7f02622c96"},"cell_type":"code","source":"submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': preds})\nsubmission.to_csv('submission_simple_features_random.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}