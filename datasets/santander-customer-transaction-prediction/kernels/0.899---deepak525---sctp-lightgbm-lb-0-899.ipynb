{"cells":[{"metadata":{"_uuid":"b70e7191db83d8a2d8a74fe9bce2debdc1c8805b"},"cell_type":"markdown","source":"<div style=\"background: linear-gradient(to bottom, #200122, #6f0000); border: 2px; box-radius: 20px\"><h1 style=\"color: white; text-align: center\"><br> <center>Santander Customer Transaction Prediction<center><br></h1></div>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport time\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nimport xgboost as xgb\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bf6551b89dc3d1fceff2447f3613e86bb7d0e24"},"cell_type":"markdown","source":"## **Load the Data**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\nprint('Rows: ',train_df.shape[0],'Columns: ',train_df.shape[1])\ntrain_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c901079a56654ba15563c68ae14eaa05512d1ed"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8db0af93eacfd36483ee6f0036ed35036fda768d"},"cell_type":"markdown","source":"- The Dataset containing 200 numeric feature variables from var_0 to var_199 and a target value."},{"metadata":{"trusted":true,"_uuid":"be2e967ae1697a682ae1255789a06c8d454ccde8"},"cell_type":"code","source":"train_df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"211d4bf841496d7963c5b97686bc9e0adb1df0d1"},"cell_type":"code","source":"sns.countplot(train_df['target'])\nsns.set_style('whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d12cc1731a79301837b58290e971aae7d9a8fa0c"},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true,"_uuid":"1a563c4719cb9fb2af6d32da8438269e79a508d2"},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7603d088b5fd0a17eafeaf09b2dcedf98b9b21e2"},"cell_type":"code","source":"X_test = test_df.drop('ID_code',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"452338807d00a95d91d14b05818d5a8aa0b1ce9d"},"cell_type":"code","source":"X = train_df.drop(['ID_code','target'],axis=1)\ny = train_df['target']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e627fd9846a197dc00ad68fbb5bff14fb64eee41"},"cell_type":"markdown","source":"## **LGBM**"},{"metadata":{"trusted":true,"_uuid":"f321308b2ed87c229a9af3f8a4c3f72bb6e87c72"},"cell_type":"code","source":"n_fold = 5\nfolds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfdb7e71cf95169214e6c13880779d1c24b2a256"},"cell_type":"code","source":"params = {'num_leaves': 8,\n         'min_data_in_leaf': 42,\n         'objective': 'binary',\n         'max_depth': 16,\n         'learning_rate': 0.0123,\n         'boosting': 'gbdt',\n         'bagging_freq': 5,\n         'bagging_fraction': 0.8,\n         'feature_fraction': 0.8201,\n         'bagging_seed': 11,\n         'reg_alpha': 1.728910519108444,\n         'reg_lambda': 4.9847051755586085,\n         'random_state': 42,\n         'metric': 'auc',\n         'verbosity': -1,\n         'subsample': 0.81,\n         'min_gain_to_split': 0.01077313523861969,\n         'min_child_weight': 19.428902804238373,\n         'num_threads': 4}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83f3d6004bfc2f0202ef3a6c49424249ef55856b"},"cell_type":"code","source":"prediction = np.zeros(len(X_test))\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n    print('Fold', fold_n, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    train_data = lgb.Dataset(X_train, label=y_train)\n    valid_data = lgb.Dataset(X_valid, label=y_valid)\n        \n    model = lgb.train(params,train_data,num_boost_round=20000,\n                    valid_sets = [train_data, valid_data],verbose_eval=300,early_stopping_rounds = 200)\n            \n    #y_pred_valid = model.predict(X_valid)\n    prediction += model.predict(X_test, num_iteration=model.best_iteration)/5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b500006f608746f34cdf6cd9a6e7d4c364cdc25"},"cell_type":"markdown","source":"## **CatBoost Classifier**"},{"metadata":{"trusted":true,"_uuid":"e89758706ee463561d411b104ae112568e461f14"},"cell_type":"code","source":"from catboost import CatBoostClassifier,Pool\nprediction1 = np.zeros(len(X_test))\nm = CatBoostClassifier(loss_function=\"Logloss\",eval_metric=\"AUC\",\n                       boosting_type = 'Ordered')\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n    print('Fold', fold_n, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n\n    train_data = Pool(X_train, label=y_train)\n    valid_data = Pool(X_valid, label=y_valid)\n\n    model1 = m.fit(train_data,eval_set=valid_data,use_best_model=True,verbose=300)\n    \n    prediction1 += model1.predict(X_test)/5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"432e5c906499eb79f993c1987d0ddc49b7a58ddf"},"cell_type":"markdown","source":"## **XGBoost**"},{"metadata":{"trusted":true,"_uuid":"e4b28db1ee18888f40c48e1326c341bf624059ad"},"cell_type":"code","source":"mod = xgb.XGBClassifier(max_depth=4,n_estimators=999999, colsample_bytree=0.7,subsample = 0.7, \n                              min_child_weight = 50, eval_metric = \"auc\",gamma = 5,alpha = 0,\n                               booster = \"gbtree\",colsample_bylevel = 0.7, learning_rate=0.1,\n                              objective='binary:logistic', n_jobs=-1)\n\nprediction2 = np.zeros(len(X_test))\nfor fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n    print('Fold', fold_n, 'started at', time.ctime())\n    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n    \n    #evallist = [(valid_data, 'eval'), (train_data, 'train')]\n    model2 = mod.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],verbose=200, eval_metric='auc',\n                        early_stopping_rounds=200)\n    \n    prediction2 += model2.predict(X_test, ntree_limit=model2.best_ntree_limit)/5","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f3765c9c5b18c97708f45afafbf1594064a5822"},"cell_type":"markdown","source":"## **Submission**"},{"metadata":{"trusted":true,"_uuid":"d0614be72aea0ca75853675c148e9a7ddcb644cc"},"cell_type":"code","source":"prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf6ec8873127ac4ee14a52fda304ea8c16d2ab30"},"cell_type":"code","source":"sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\nsub[\"target\"] = prediction\nsub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"451f137f84dce71cc0caf9d4da4a498f278bd07a"},"cell_type":"code","source":"sub[\"target\"] = prediction1\nsub.to_csv(\"submission1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5609d5ff3d1166960beaef6f14d7c2d36249c382"},"cell_type":"code","source":"sub[\"target\"] = (prediction + prediction1)/2\nsub.to_csv(\"submission2.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96e1c95d8481967df1632c08a91b437aab7bdbf1"},"cell_type":"code","source":"sub[\"target\"] = prediction2\nsub.to_csv(\"submission3.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b4bdeb02d65774c79c206ec81720cf4840301df"},"cell_type":"code","source":"sub[\"target\"] = (prediction + prediction2)/2 \nsub.to_csv(\"submission4.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0945a088bf730a88fc51fbab4100c80330ae8190"},"cell_type":"code","source":"sub[\"target\"] = (prediction + prediction1 + prediction2)/3 \nsub.to_csv(\"submission5.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}