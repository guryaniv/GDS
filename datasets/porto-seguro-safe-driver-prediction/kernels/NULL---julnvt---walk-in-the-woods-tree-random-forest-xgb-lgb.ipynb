{"metadata": {"language_info": {"version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "cells": [{"source": ["This kernel provides examples of Python implementation of tree-based algorithms. The Porto Seguro's dataset is a good case study to begin with, as it is a binary classification problem (0/1), both the number of observations and features are not too large nor too small (training is quite fast) and we have to deal with missing values and imbalanced target variable.\n", "\n", "We start by building a single decision tree, where maximum depth is chosen via cross validation (either via cross_val_score or GridSearchCV). This technique does not lead to good out-of-sample performance. We then try Random Forest algorithm to increase robustness, but only a small improvement was achieved. Stronger Gini score is found using gradient boosting, such as XGBoost and Light GBM. While XGBoost allows us to post our highest score (0.276) on the leaderboard, Light GBM provides very similar performance on the test set with much less training time than XGBoost.\n", "\n", "Some parts of the code have been sourced from multiple kernels of this competition."], "metadata": {"_cell_guid": "2c26a6fe-2713-4ec0-83db-5d49c2590949", "_uuid": "7bb0241d2a00847857a6488eec2760d456c4d843"}, "cell_type": "markdown"}, {"outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "0ad7e78a-3bd5-43ba-8257-beb50b0b2539", "_uuid": "f3c0bf7d83ea55e4c457077248b5fb660b01cc5c"}, "cell_type": "code", "execution_count": 4}, {"outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import graphviz\n", "\n", "import gc\n", "\n", "from sklearn.cross_validation import train_test_split\n", "from sklearn.model_selection import StratifiedKFold\n", "\n", "from sklearn import tree\n", "from sklearn.ensemble import RandomForestClassifier\n", "import xgboost as xgb\n", "import lightgbm as lgb\n", "\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import roc_curve\n", "from sklearn.metrics import make_scorer"], "metadata": {"_cell_guid": "1f996537-37aa-4769-9623-95b37373d2c5", "collapsed": true, "_uuid": "1e313603f23e24221fda3b8a103c45342ffb03c1"}, "cell_type": "code", "execution_count": 2}, {"outputs": [], "source": ["rawdata_train = pd.read_csv(\"../input/train.csv\", sep = ',',na_values = -1)\n", "rawdata_test = pd.read_csv(\"../input/test.csv\", sep = ',',na_values = -1)"], "metadata": {"_cell_guid": "7d4e2782-28f1-46b0-a1ac-07c4e4d97ead", "collapsed": true, "_uuid": "c011b51243673b2c7e1649c8ddc82c0f20a22c76"}, "cell_type": "code", "execution_count": 5}, {"source": ["**Fix missing values**\n", "\n", "First, we visualize which features have this issue. Those with too many missing values are dropped. The others have their missing entries replaced by the mode value"], "metadata": {"_cell_guid": "8c8c926f-b9de-4fdf-b0f7-2d202a24e0f5", "_uuid": "144ec8bfbc17be8f50418d5120d6922c5e15eef1"}, "cell_type": "markdown"}, {"outputs": [], "source": ["def describe_missing_values(df):\n", "    na_percent = {}\n", "    N = df.shape[0]\n", "    for column in df:\n", "        na_percent[column] = df[column].isnull().sum() * 100 / N\n", "\n", "    na_percent = dict(filter(lambda x: x[1] != 0, na_percent.items()))\n", "    plt.bar(range(len(na_percent)), na_percent.values())\n", "    plt.ylabel('Percent')\n", "    plt.xticks(range(len(na_percent)), na_percent.keys(), rotation='vertical')\n", "    plt.show()"], "metadata": {"_cell_guid": "6f4f0e45-b86d-47cb-b4ff-a137c67ff8c1", "collapsed": true, "_uuid": "a09323d43e8392bbbb681e5ac9124f8263c54fee"}, "cell_type": "code", "execution_count": 7}, {"outputs": [], "source": ["print(\"Missing values for train set\")\n", "describe_missing_values(rawdata_train)\n", "print(\"Missing values for test set\")\n", "describe_missing_values(rawdata_test)"], "metadata": {"_cell_guid": "eba3c2e8-40bb-48c1-bd25-0066a6c6d0f3", "_uuid": "8c543176774e310eb93d928611f7e7a98f83605c"}, "cell_type": "code", "execution_count": 8}, {"outputs": [], "source": ["X = rawdata_train.drop({'target','id','ps_car_03_cat','ps_car_05_cat'},axis=1)\n", "Y = rawdata_train['target']\n", "X_test = rawdata_test.drop({'id','ps_car_03_cat','ps_car_05_cat'},axis=1)\n", "\n", "cat_cols = [col for col in X.columns if 'cat' in col]\n", "bin_cols = [col for col in X.columns if 'bin' in col]\n", "con_cols = [col for col in X.columns if col not in bin_cols + cat_cols]\n", "\n", "for col in cat_cols:\n", "    X[col].fillna(value=X[col].mode()[0], inplace=True)\n", "    X_test[col].fillna(value=X_test[col].mode()[0], inplace=True)\n", "    \n", "for col in bin_cols:\n", "    X[col].fillna(value=X[col].mode()[0], inplace=True)\n", "    X_test[col].fillna(value=X_test[col].mode()[0], inplace=True)\n", "    \n", "for col in con_cols:\n", "    X[col].fillna(value=X[col].mean(), inplace=True)\n", "    X_test[col].fillna(value=X_test[col].mean(), inplace=True)"], "metadata": {"_cell_guid": "aeb9980d-b1a5-4228-ba4f-2c7b01859218", "collapsed": true, "_uuid": "67d022c269e45ec8d3b90e9c5e831c8c7aaba90f"}, "cell_type": "code", "execution_count": 10}, {"source": ["**Defining Gini scoring metric**\n", "\n", "As the submissions are evaluated using the Normalized Gini Coefficient, we create a scoring function, which will be fed into the algorithms."], "metadata": {"_cell_guid": "e3848068-9c4e-4240-9e80-d6c46d62adb0", "_uuid": "53eb159438002e3247bc81fb4c761f7e7b0acc1c"}, "cell_type": "markdown"}, {"outputs": [], "source": ["def gini(actual, pred):\n", "    assert (len(actual) == len(pred))\n", "    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n", "    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n", "    totalLosses = all[:, 0].sum()\n", "    giniSum = all[:, 0].cumsum().sum() / totalLosses\n", "\n", "    giniSum -= (len(actual) + 1) / 2.\n", "    return giniSum / len(actual)\n", "\n", "\n", "def gini_normalized_score(actual, pred):\n", "    return gini(actual, pred) / gini(actual, actual)\n", "\n", "score_gini = make_scorer(gini_normalized_score, greater_is_better=True, needs_threshold = True)"], "metadata": {"_cell_guid": "b00fbd06-769d-4b56-aecc-dbedebd09978", "collapsed": true, "_uuid": "63bc50765ea61c8b3006e2883c8f747cfbc933d3"}, "cell_type": "code", "execution_count": 12}, {"source": ["**Single Classification Tree**\n", "\n", "We choose the tree depth via cross validation. One can use either cross_val_score (it requires to manually code a loop over the depth possibilities) or GridSearchCV do all the work for you. In both cases, we see that strongest gini score is achieved with 8 as max depth."], "metadata": {"_cell_guid": "3104e467-98d4-4094-9cbd-859559fa6a6b", "_uuid": "c9f6d0281096312ae805cda8df46b9145200e4c4"}, "cell_type": "markdown"}, {"outputs": [], "source": ["depth_gini = []\n", "for i in range(3,15):\n", "    clf = tree.DecisionTreeClassifier(max_depth=i)\n", "    # Perform 5-fold cross validation\n", "    scores_gini = cross_val_score(clf, X, Y, cv=5, scoring = score_gini)\n", "    depth_gini.append((i,scores_gini.mean()))\n", "plt.plot(*zip(*depth_gini))\n", "plt.xlabel('tree depth')\n", "plt.ylabel('cv gini score')\n", "plt.show()"], "metadata": {"_cell_guid": "6064e2e0-1227-4677-9a6d-c7cea9b2af39", "_uuid": "802ff4986415d850f1eb422dee365848a4b5aa6e"}, "cell_type": "code", "execution_count": 19}, {"outputs": [], "source": ["parameters = {'max_depth': np.arange(3,15)}\n", "clf = GridSearchCV(estimator = tree.DecisionTreeClassifier(), param_grid = parameters, scoring = score_gini, cv = 5)\n", "clf.fit(X, Y)\n", "print(\"Best parameters set found on development set:\")\n", "print()\n", "print(clf.best_estimator_)\n", "print()\n", "print(\"Grid scores on development set:\")\n", "print()\n", "for params, mean_score, scores in clf.grid_scores_:\n", "    print(\"%0.3f (+/-%0.03f) for %r\"\n", "            % (mean_score, scores.std() / 2, params))\n", "print()"], "metadata": {"_cell_guid": "60465a1a-0af6-4c25-9532-3237f7babc80", "_uuid": "08d92a310c8ff4113a24311003f955bb9e5fd3b3"}, "cell_type": "code", "execution_count": 20}, {"outputs": [], "source": ["clf = tree.DecisionTreeClassifier(max_depth=8)\n", "clf = clf.fit(X,Y)\n", "Y_pred_clf = clf.predict(X)\n", "Y_pred_proba_clf = clf.predict_proba(X)\n", "Y_pred_clf = clf.predict(X)"], "metadata": {"_cell_guid": "04134285-3939-4760-85ae-5a9d3d388d1e", "collapsed": true, "_uuid": "41153709468abb76bf37350df1c75065fe4a43c6"}, "cell_type": "code", "execution_count": 24}, {"source": ["Graphviz allows to visualize the tree."], "metadata": {"_cell_guid": "c57cb936-9b17-4bae-a63c-22d47d8db532", "_uuid": "0493f4851a741c84726d537d02eaa5d4346ebf50"}, "cell_type": "markdown"}, {"outputs": [], "source": ["dot_data = tree.export_graphviz(clf,out_file=None)\n", "graph = graphviz.Source(dot_data)\n", "graph"], "metadata": {"_cell_guid": "81838dc0-7bef-4cea-a26d-002b920349ee", "_uuid": "1abe6ee8909cebd3225c1b680f483433f12d8284"}, "cell_type": "code", "execution_count": 25}, {"source": ["**Random Forest**\n", "\n", "We use the same approach to choose max depth of a Random Forest Classifier."], "metadata": {"_cell_guid": "3b154613-649d-4330-93e2-d72eefd0e038", "_uuid": "ac07711355fb9302cb15a71b276e2e99dd7e8dc3"}, "cell_type": "markdown"}, {"outputs": [], "source": ["depth_gini = []\n", "for i in range(3,15):\n", "    rf = RandomForestClassifier(max_depth=i)\n", "    # Perform 5-fold cross validation\n", "    scores_gini = cross_val_score(rf, X, Y, cv=5, scoring = score_gini)\n", "    depth_gini.append((i,scores_gini.mean()))\n", "plt.plot(*zip(*depth_gini))\n", "plt.xlabel('tree depth')\n", "plt.ylabel('cv gini score')\n", "plt.show()"], "metadata": {"_cell_guid": "5686a11c-404c-4a7e-a0cf-b0128d42002e", "_uuid": "fbe4d5e23215b42ca41bacee56eb30e51b0a44ce"}, "cell_type": "code", "execution_count": 26}, {"outputs": [], "source": ["rf = RandomForestClassifier(max_depth=8)\n", "rf = rf.fit(X,Y)\n", "Y_pred_rf = rf.predict(X)\n", "Y_pred_proba_rf = rf.predict_proba(X)\n", "Y_pred_rf = rf.predict(X)"], "metadata": {"_cell_guid": "5511dba0-6488-4c3a-a064-8d3b05bf741b", "collapsed": true, "_uuid": "19161a6a0a6a5acadc99cfa2aa1c89f1bdea9f95"}, "cell_type": "code", "execution_count": 28}, {"source": ["It may be useful to plot feature importance resulting from the training of Random Forest."], "metadata": {"_cell_guid": "7bdeb980-18ef-4be5-b111-d1d4d9ad9618", "_uuid": "c2edb4f929d3033fd3342358859ac79b7c639cf3"}, "cell_type": "markdown"}, {"outputs": [], "source": ["importances = rf.feature_importances_\n", "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n", "             axis=0)\n", "indices = np.argsort(importances)[::-1]\n", "\n", "# Print the feature ranking\n", "print(\"Feature ranking:\")\n", "\n", "for f in range(X.shape[1]):\n", "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n", "\n", "# Plot the feature importances of the forest\n", "plt.figure()\n", "plt.title(\"Feature importances\")\n", "plt.bar(range(X.shape[1]), importances[indices],\n", "       color=\"r\", yerr=std[indices], align=\"center\")\n", "plt.xticks(range(X.shape[1]), indices)\n", "plt.xlim([-1, X.shape[1]])\n", "plt.show()"], "metadata": {"_cell_guid": "923cbe38-97cb-455f-9c7b-cc2c5542839a", "_uuid": "0eaf79b10b2e004027a9f59d261dc26666223a43"}, "cell_type": "code", "execution_count": 29}, {"source": ["**Comparison of Single Classification Tree and Random Forest**\n", "\n", "An easy method to compare performance of these two models is to plot the ROC curve, and calculate the AUC. We find that Random Forest achieves slightly higher AUC than a single decision tree."], "metadata": {"_cell_guid": "1aca1f59-b398-4787-bb0d-8a8ca7a117a2", "_uuid": "cc591808c271d3b1c8508c849eccfd6f13e83ad6"}, "cell_type": "markdown"}, {"outputs": [], "source": ["confusion_matrix(Y,Y_pred_clf)"], "metadata": {"_cell_guid": "40f5fe6b-9968-419a-b1f4-c03f0b90ef1d", "_uuid": "cf9b022488f7e231b12a159a437e430be9df7cbe"}, "cell_type": "code", "execution_count": 31}, {"outputs": [], "source": ["fpr_clf, tpr_clf, thresholds_clf = roc_curve(Y,Y_pred_proba_clf[:,1],pos_label = 1)\n", "fpr_rf, tpr_rf, thresholds_rf = roc_curve(Y,Y_pred_proba_rf[:,1],pos_label = 1)\n", "plt.plot(fpr_clf,tpr_clf)\n", "plt.plot(fpr_rf,tpr_rf)\n", "plt.xlabel('false positive rate')\n", "plt.ylabel('true positive rate')\n", "plt.show()\n", "auc_clf = np.trapz(tpr_clf,fpr_clf)\n", "auc_rf = np.trapz(tpr_rf,fpr_rf)\n", "print(auc_clf)\n", "print(auc_rf)"], "metadata": {"_cell_guid": "f19252e2-cd86-4d88-84ff-71ef95f85e2d", "_uuid": "eee6020d0c5dec12cd8bbe1350bd3139569ea7c8"}, "cell_type": "code", "execution_count": 33}, {"source": ["**XGBoost**\n", "\n", "Single Classification Tree and Random Forest delivered poor prediction performance so far. We now try XGBoost and Light GBM. We increase the gini score from 0.24 with previous algorithms to 0.275. XGBoost takes longer to train."], "metadata": {"_cell_guid": "4936540d-b6a3-4e67-abaa-d2176d25846d", "_uuid": "ca265bd65162cc8717c0fe1244ce56f30f379a78"}, "cell_type": "markdown"}, {"outputs": [], "source": ["X = rawdata_train.drop({'target','id'},axis=1)\n", "Y = rawdata_train['target']\n", "X_test = rawdata_test"], "metadata": {"_cell_guid": "1a18a0d2-eb4f-4342-b3c7-dd4d4943a001", "collapsed": true, "_uuid": "1304a59b1eabec63987415bb2e9a6a2f796f7c82"}, "cell_type": "code", "execution_count": 34}, {"outputs": [], "source": ["# Create an XGBoost-compatible metric from Gini\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized_score(labels, preds)\n", "    return [('gini', gini_score)]"], "metadata": {"_cell_guid": "05678495-7546-4d5f-808e-bd5e07bbc576", "collapsed": true, "_uuid": "a8dc593a496b378eec10825da5c5b931cbe0e837"}, "cell_type": "code", "execution_count": 35}, {"outputs": [], "source": ["params = {'eta': 0.2,\n", "          'max_depth': 4,\n", "          'objective': 'binary:logistic',\n", "          'eval_metric': 'auc',\n", "          'silent': True}\n", "\n", "features = X.columns\n", "submission = X_test['id'].to_frame()\n", "submission['target']=0\n", "\n", "kfold = 3\n", "skf = StratifiedKFold(n_splits=kfold)\n", "for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n", "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n", "    X_train, X_valid = X.loc[train_index], X.loc[test_index]\n", "    Y_train, Y_valid = Y.loc[train_index], Y.loc[test_index]\n", "    d_train = xgb.DMatrix(X_train, Y_train) \n", "    d_valid = xgb.DMatrix(X_valid, Y_valid) \n", "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n", "    xgb_model = xgb.train(params, d_train, 1000, watchlist, early_stopping_rounds=100, \n", "                        feval=gini_xgb, maximize=True, verbose_eval=100)\n", "    submission['target'] += xgb_model.predict(xgb.DMatrix(X_test[features]), \n", "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n", "gc.collect()\n", "submission.head(2)"], "metadata": {"_cell_guid": "a6d17499-fea1-4bfe-9250-641d6ad4d4f6", "collapsed": true, "_uuid": "9d6f3e728960eae69368c9ce0b1e8121ebf5be89"}, "cell_type": "code", "execution_count": null}, {"source": ["GridSearchCV also works with XGBoost."], "metadata": {"_cell_guid": "8ec9164d-8d7f-46b4-a921-34937ca388eb", "_uuid": "f9c414a08eb06d3dd60846a391cd572e54562266"}, "cell_type": "markdown"}, {"outputs": [], "source": ["parameters = {'max_depth': np.arange(3,7),\n", "            'learning_rate': [0.2],\n", "             'n_estimators': [20,100]}\n", "\n", "clf = GridSearchCV(estimator = xgb.XGBClassifier(silent=True), param_grid = parameters, scoring = score_gini, cv = 3, verbose = 10, n_jobs = -1)\n", "clf.fit(X, Y)"], "metadata": {"_cell_guid": "d907429a-f4af-4431-94f0-ff5af7036187", "collapsed": true, "_uuid": "272dabda2c9ab43ebef7f0a147570ce6b817f838"}, "cell_type": "code", "execution_count": null}, {"source": ["**Light GBM**"], "metadata": {"_cell_guid": "2103ef3c-b3b1-4438-aef1-5582a57d3a65", "_uuid": "9748f756e0e17b8b293f4da785920b244fd640bf"}, "cell_type": "markdown"}, {"outputs": [], "source": ["def gini_lgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized_score(labels, preds)\n", "    return [('gini', gini_score, True)]"], "metadata": {"_cell_guid": "a88ab4f5-4a88-47ae-8426-a324ccbf9014", "collapsed": true, "_uuid": "fe4154015817ed292535b7709e278b419e3d3d50"}, "cell_type": "code", "execution_count": 36}, {"outputs": [], "source": ["params = {'learning_rate' : 0.2, 'max_depth':6, 'max_bin':10,  'objective': 'binary', \n", "        'metric': 'auc'}\n", "\n", "features = X.columns\n", "submission = X_test['id'].to_frame()\n", "submission['target']=0\n", "\n", "kfold = 5\n", "skf = StratifiedKFold(n_splits=kfold)\n", "for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n", "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n", "    X_train, X_valid = X.loc[train_index], X.loc[test_index]\n", "    Y_train, Y_valid = Y.loc[train_index], Y.loc[test_index]\n", "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=Y_train), 400, \n", "                  lgb.Dataset(X_valid, label=Y_valid), verbose_eval=100, \n", "                  feval=gini_lgb, early_stopping_rounds=50)\n", "    submission['target'] += lgb_model.predict(X_test[features], \n", "                        num_iteration=lgb_model.best_iteration) / (kfold)\n", "gc.collect()\n", "submission.head(2)"], "metadata": {"_cell_guid": "0857a9b5-012a-4709-9206-08caccae314f", "_uuid": "4da1239ebf0a53084be94aa7aa6f04e06dd43815"}, "cell_type": "code", "execution_count": 38}, {"source": ["**Submit predictions**"], "metadata": {"_cell_guid": "83b223b6-0bd2-4c7f-ac47-1ef6a7f0db9d", "_uuid": "9b22f27b46ff27fd7da140ef39815a25456eeac4"}, "cell_type": "markdown"}, {"outputs": [], "source": ["submission.to_csv(\"./submission.csv\", index=False, float_format='%.5f')"], "metadata": {"_cell_guid": "a96743da-891f-4e8d-b6c8-89f2803f7532", "collapsed": true, "_uuid": "6ef7bbdabb1eeaef6cd058bc70fc218962222710"}, "cell_type": "code", "execution_count": 39}], "nbformat_minor": 1}