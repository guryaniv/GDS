{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "ef25ae18c01b92601c3222ad9d23a86957e95782", "_cell_guid": "12b97784-1dee-48c4-b831-56c696c88f78"}, "source": ["Based on the1owl's [kernel](https://www.kaggle.com/the1owl/forza-baseline-lightgbm-example)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "dbd332f83c89108c4e641218f5c4e7b9cd325b80", "_cell_guid": "45ba73d4-6c4c-40bb-9390-7dfc956c555d", "collapsed": true}, "outputs": [], "source": ["MAX_ROUNDS = 1200\n", "OPTIMIZE_ROUNDS = False\n", "LEARNING_RATE = 0.024"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b277fe426336d65ac71f0e6ac96c7ee16d02074c", "_cell_guid": "7e199c98-16b0-45e7-a6d1-bdd9325c2631"}, "source": ["I recommend initially setting <code>MAX_ROUNDS</code> fairly high and using <code>OPTIMIZE_ROUNDS</code> to get an idea of the appropriate number of rounds (which, in my judgment, should be close to the maximum value of <code>best_iteration</code> among all folds, maybe even a bit higher if your model is adequately regularized...or alternatively, you can look at the detailed output from the boosting rounds and choose a value that seems like it would work OK for all folds).  Then I would turn off <code>OPTIMIZE_ROUNDS</code> and set <code>MAX_ROUNDS</code> to the appropraite number of total rounds.  The problem with \"early stopping\" by choosing the best round for each fold is that it overfits to the validation data.    It's therefore liable not to produce the optimal model for predicting test data, and if it's used to produce validation predictions for stacking/ensembling with other models, it would cause this one to have too much weight in the ensemble."]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "72171ee53e170096d37a18eef84682fa348ae5c4", "_cell_guid": "b7258128-55f9-4543-8611-5e0a6661837b", "collapsed": true}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from catboost import CatBoostClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import KFold\n", "from numba import jit\n", "from sklearn import *\n", "import lightgbm as lgb\n", "from multiprocessing import *"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "154b078a7e86c0a5a328118a61d28e2581bb3b0a", "_cell_guid": "3d16f16e-12cc-4b41-b7bd-fa05ce44770c", "collapsed": true}, "outputs": [], "source": ["# Compute gini\n", "\n", "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n", "@jit\n", "def eval_gini(y_true, y_prob):\n", "    y_true = np.asarray(y_true)\n", "    y_true = y_true[np.argsort(y_prob)]\n", "    ntrue = 0\n", "    gini = 0\n", "    delta = 0\n", "    n = len(y_true)\n", "    for i in range(n-1, -1, -1):\n", "        y_i = y_true[i]\n", "        ntrue += y_i\n", "        gini += y_i * delta\n", "        delta += 1 - y_i\n", "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n", "    return gini"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "affb627af275ad7aa0c5c85dd826ee140370eb3e", "_cell_guid": "7f8f84f9-aa46-43d6-8d78-619ef9a7dcce", "collapsed": true}, "outputs": [], "source": ["def transform_df(df):\n", "    df = pd.DataFrame(df)\n", "    dcol = [c for c in df.columns if c not in ['id','target']]\n", "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n", "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n", "    for c in dcol:\n", "        if '_bin' not in c: #standard arithmetic\n", "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n", "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n", "    for c in one_hot:\n", "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n", "            for val in one_hot[c]:\n", "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n", "    return df\n", "\n", "def multi_transform(df):\n", "    p = Pool(cpu_count())\n", "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n", "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n", "    p.close(); p.join()\n", "    return df\n", "\n", "def gini_lgb(preds, dtrain):\n", "    y = list(dtrain.get_label())\n", "    score = eval_gini(y, preds) / eval_gini(y, y)\n", "    return 'gini', score, True\n", "\n"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "07a5a5782894611e9006ae1b399b0b8fb8a0f06b", "_cell_guid": "52b50086-b405-4598-b11c-97887cdcce8e", "collapsed": true}, "outputs": [], "source": ["# Read data\n", "train_df = pd.read_csv('../input/train.csv') # .iloc[0:200,:]\n", "test_df = pd.read_csv('../input/test.csv')"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "6255e3c12616b0279cef5c1bdec97751bb72d8b8", "_cell_guid": "1b36eb15-ee01-43a3-8766-27650f98158d", "collapsed": true}, "outputs": [], "source": ["# Process data\n", "col = [c for c in train_df.columns if c not in ['id','target']]\n", "col = [c for c in col if not c.startswith('ps_calc_')]\n", "\n", "id_test = test_df['id'].values\n", "id_train = train_df['id'].values\n", "\n", "y = train_df['target']\n", "X = train_df[col]\n", "y_valid_pred = 0*y\n", "X_test = test_df.drop(['id'], axis=1)\n", "y_test_pred = 0"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "6aa7ada2193c2e4b8a63eebda925cee5023b45b0", "_cell_guid": "7c6e4823-4e8c-4408-b961-576d469e9241", "collapsed": true}, "outputs": [], "source": ["# Set up folds\n", "K = 5\n", "kf = KFold(n_splits = K, random_state = 1, shuffle = True)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "581c3f15f294378a0e2ac3305e9e3d375f664b21", "_cell_guid": "5d8108f3-e9e8-45d6-93b5-740eb7b4b10b", "collapsed": true}, "outputs": [], "source": ["# Set up classifier\n", "params = {\n", "    'learning_rate': LEARNING_RATE, \n", "    'max_depth': 4, \n", "    'lambda_l1': 16.7,\n", "    'boosting': 'gbdt', \n", "    'objective': 'binary', \n", "    'metric': 'auc',\n", "    'feature_fraction': .7,\n", "    'is_training_metric': False, \n", "    'seed': 99\n", "}"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "2b9ed96c98b705d3e4bf2a3d60323dfab4332674", "scrolled": false, "_cell_guid": "c4e48347-920f-4ba7-8b37-cfbaab4c3c00", "collapsed": true}, "outputs": [], "source": ["# Run CV\n", "\n", "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n", "    \n", "    # Create data for this fold\n", "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index].copy()\n", "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n", "    test = test_df.copy()[col]\n", "    print( \"\\nFold \", i)\n", "\n", "    # Transform data for this fold\n", "    one_hot = {c: list(X_train[c].unique()) for c in X_train.columns}\n", "    X_train = X_train.replace(-1, np.NaN)  # Get rid of -1 while computing summary stats\n", "    d_median = X_train.median(axis=0)\n", "    d_mean = X_train.mean(axis=0)\n", "    X_train = X_train.fillna(-1)  # Restore -1 for missing values\n", "\n", "    X_train = multi_transform(X_train)\n", "    X_valid = multi_transform(X_valid)\n", "    test = multi_transform(test)\n", "\n", "    # Run model for this fold\n", "    if OPTIMIZE_ROUNDS:\n", "        fit_model = lgb.train( \n", "                               params, \n", "                               lgb.Dataset(X_train, label=y_train), \n", "                               MAX_ROUNDS, \n", "                               lgb.Dataset(X_valid, label=y_valid), \n", "                               verbose_eval=50, \n", "                               feval=gini_lgb, \n", "                               early_stopping_rounds=200 \n", "                             )\n", "        print( \" Best iteration = \", fit_model.best_iteration )\n", "        pred = fit_model.predict(X_valid, num_iteration=fit_model.best_iteration)\n", "        test_pred = fit_model.predict(test[col], num_iteration=fit_model.best_iteration)\n", "    else:\n", "        fit_model = lgb.train( \n", "                               params, \n", "                               lgb.Dataset(X_train, label=y_train), \n", "                               MAX_ROUNDS, \n", "                               verbose_eval=50 \n", "                             )\n", "        pred = fit_model.predict(X_valid)\n", "        test_pred = fit_model.predict(test)\n", "\n", "    # Save validation predictions for this fold\n", "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n", "    y_valid_pred.iloc[test_index] = (np.exp(pred) - 1.0).clip(0,1)\n", "    \n", "    # Accumulate test set predictions\n", "    y_test_pred += (np.exp(test_pred) - 1.0).clip(0,1)\n", "    \n", "y_test_pred /= K  # Average test set predictions\n", "\n", "print( \"\\nGini for full training set:\" )\n", "eval_gini(y, y_valid_pred)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e61bf4e22c1c29c8358caeecb6e67d6658f2005d", "_cell_guid": "0e3dfd76-c566-4b8d-a460-b56e964d0772", "collapsed": true}, "outputs": [], "source": ["# Save validation predictions for stacking/ensembling\n", "val = pd.DataFrame()\n", "val['id'] = id_train\n", "val['target'] = y_valid_pred.values\n", "val.to_csv('lgb_valid.csv', float_format='%.6f', index=False)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1", "_cell_guid": "f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5", "collapsed": true}, "outputs": [], "source": ["# Create submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = id_test\n", "sub['target'] = y_test_pred\n", "sub.to_csv('lgb_submit.csv', float_format='%.6f', index=False)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "18b6d7a7385825ed07623911b64ca30008983e13", "_cell_guid": "aa79af82-15f2-4d12-aef9-4048034742ce"}, "source": ["version 8:  Resubmitting identical run because version 7 seems to have become invisible<br>\n", "versions 9,10 (substantively identical): Set <code>lambda_l1=16.7</code>, sorted LB score improved but still reported as .282<br>\n", "version 11: With <code>OPTIMIZE_ROUNDS</code>, negate gini score so LightGBM will minimize. <code>is_higher_better</code> not working.<br>\n", "version 12: Un-negate gini score and set <code>is_higher_better</code> again. Maybe I misunderstood.<br>\n", "version 14: Set <code>MAX_ROUNDS=1400</code> for prediction run.<br>\n", "versions 15-21: Set <code>feature_fraction</code>. LB score goes up but still reported as .282"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "539c2db7c30cecbb9f37dc006b1b81fedd349b87", "_cell_guid": "ca9594fa-57ce-4393-9b1c-3383310e83a3", "collapsed": true}, "outputs": [], "source": []}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}