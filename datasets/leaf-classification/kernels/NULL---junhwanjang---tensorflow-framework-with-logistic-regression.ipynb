{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "50bb3efc-a45e-4952-562f-56755d2a473a"
      },
      "source": [
        "# The Idea\n",
        "\n",
        "This notebook is created mainly to provide a framework to use Tensorflow for building a logistic regression model with the pre-extracted features. You have a room to improve the results by including more features and trying different algorithms.\n",
        "\n",
        "**Step 1:** Define paramaters for the model, read source data, and create train / test data array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "01b742cb-803f-ee2a-89a5-7288ea5ff76f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Define paramaters for the model\n",
        "learning_rate = 0.01\n",
        "batch_size = 33\n",
        "n_epochs = 100\n",
        "\n",
        "# Step 1.1: Read in data\n",
        "train_df = pd.read_csv('../input/train.csv') \n",
        "test_df  = pd.read_csv('../input/test.csv') \n",
        "\n",
        "# Step 1.2: create train and test data array\n",
        "train_data  = train_df.loc[:,'margin1':'texture64']\n",
        "test_data   = test_df.loc[:,'margin1':'texture64']\n",
        "target_data = pd.get_dummies(train_df.species)\n",
        "\n",
        "X_train = train_data.as_matrix()\n",
        "X_test  = test_data.as_matrix()\n",
        "y_train = target_data.as_matrix()\n",
        "\n",
        "num_train = X_train.shape[0]\n",
        "num_test  = X_test.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ace9033-887e-2996-00f7-4250067368c3"
      },
      "source": [
        "**Step 2:** Create placeholders for features and labels. Each image is represented with 1x192 tensor and there are 99 classes for each image and each lable is one hot vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1a9a9e2-0ebb-e903-1d74-6f9db4a2450b"
      },
      "outputs": [],
      "source": [
        "X = tf.placeholder(tf.float32, [None, 192], name='X_placeholder') \n",
        "Y = tf.placeholder(tf.float32, [None, 99], name='Y_placeholder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cdcd447b-48b5-576a-a03a-ba417b157a5b"
      },
      "source": [
        "**Step 3:** Create weights and bias\n",
        "* w is initialized to random variables with mean of 0, stddev of 0.01\n",
        "* b is initialized to 0\n",
        "* shape of w depends on the dimension of X and Y so that Y = tf.matmul(X, w)\n",
        "* shape of b depends on Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1e48f8d-871c-a8cc-52e4-35f38d493cd0"
      },
      "outputs": [],
      "source": [
        "w = tf.Variable(tf.random_normal(shape=[192, 99], stddev=0.01), name='weights')\n",
        "b = tf.Variable(tf.zeros([1, 99]), name=\"bias\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "934fb27c-ba7a-1371-2830-2a64ad1bc692"
      },
      "source": [
        "**Step 4:** Build model that returns the logits. This logits will be later passed through softmax layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0bbd2a1-81d0-3d1f-2ae2-6034da0c90f7"
      },
      "outputs": [],
      "source": [
        "logits = tf.matmul(X, w) + b "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "83d68f71-01ab-b60b-6888-e720afd35f52"
      },
      "source": [
        "**Step 5:** Define log loss function. Let's use cross entropy of softmax of logits as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2977fdc-df74-4f75-5f0c-18a5440b60cf"
      },
      "outputs": [],
      "source": [
        "y = tf.nn.softmax(logits)\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y), reduction_indices=[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4c8d191e-ea39-28da-802b-40beae7c6745"
      },
      "source": [
        "**Step 6:** Define training operation using Adam optimizer with learning rate of 0.01 to minimize loss and apply a trained model to test dataset.\n",
        "\n",
        "**Note:** Because the number of features, 192, is relatively large considering the number of data points, 990, I used Adam optimizer instead of gradient descent optimizer. It turns out Adam optimizer outperforms gradient descent optimizer! Feel free to test it by replacing tf.train.AdamOptimizer by tf.train.GradientDescentOptimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aea24b92-a5f3-dc42-b9bd-f85c9edb3b31"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    # to visualize using TensorBoard\n",
        "    #writer = tf.summary.FileWriter('./graph/leaf_lr', sess.graph)\n",
        "\n",
        "    start_time = time.time()\n",
        "    sess.run(tf.global_variables_initializer())\t\n",
        "    n_batches = int(num_train/batch_size)\n",
        "\n",
        "    for i in range(n_epochs): # train the model n_epochs times\n",
        "\n",
        "        # shuffle X, y\n",
        "        X_train, y_train = shuffle(X_train, y_train)\n",
        "        total_loss   = 0\n",
        "\n",
        "        for j in range(n_batches):\n",
        "            X_batch, Y_batch = X_train[j*batch_size:(j+1)*batch_size], y_train[j*batch_size:(j+1)*batch_size]\n",
        "            _, loss_batch = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch}) \n",
        "            total_loss += loss_batch\n",
        "\n",
        "        print('Average loss epoch {0}: {1}'.format(i, total_loss/n_batches))\n",
        "\n",
        "    print('Total time: {0} seconds'.format(time.time() - start_time))\n",
        "\n",
        "    print('Optimization Finished!') # should be around 0.35 after 25 epochs\n",
        "\n",
        "    # test the model\n",
        "    logits_test = sess.run(logits, feed_dict={X: X_test}) \n",
        "    Y_pred = sess.run(tf.nn.softmax(logits_test))\n",
        "\n",
        "    #writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "839b3a5f-1c31-08f9-f208-88c183fe0695"
      },
      "source": [
        "**Step 7:** Write to the submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "92f664ea-273a-e791-ccd9-26b5c4dba1a6"
      },
      "outputs": [],
      "source": [
        "sample_submission  = pd.read_csv('../input/sample_submission.csv')\n",
        "col_idx = list(sample_submission)[1:]\n",
        "row_idx = sample_submission.id.values\n",
        "\n",
        "submission = pd.DataFrame(data=Y_pred, index=row_idx, columns=col_idx)\n",
        "print(submission.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "39a68bff-5fbe-5492-9e7f-f8d0959e47a6"
      },
      "source": [
        "Though Tensowflow site has great tutorials, I wanted to provide a simple framework to use Tensorflow for building a loss function, selecting a optimizer, training the model, and finally testing the model. To me, Tensorflow is very flexible to experiment different optimizers and loss functions and I hope you find the same!\n",
        "\n",
        "## Thank you for reading!"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}