{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from os import listdir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6c8f32e4c5e2ac13052912798001ca45eebcee6","collapsed":true},"cell_type":"code","source":"listdir('../input/train')[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8171f169545a222376dcb9df5e9f3eacb52c5e2"},"cell_type":"markdown","source":"# Acknowledgements"},{"metadata":{"_uuid":"bf05c0092be153859611147e4017ca6d672636a3"},"cell_type":"markdown","source":"Inspiration is obtained from **fujisan** kernel found [here](https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98)"},{"metadata":{"_uuid":"387a48c9e6f261c8e7a634c0a34b2a594fa16fcb"},"cell_type":"markdown","source":"# Step One : Load libraries"},{"metadata":{"trusted":true,"_uuid":"b3ab78e53ef76dd3b7cf26ef6f7432145f3f83a2","collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nfrom os import listdir\nfrom glob import glob\nimport itertools\nimport fnmatch\nimport random\nfrom PIL import Image\nimport zlib\nimport itertools\nimport csv\nfrom tqdm import tqdm\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport cv2\nimport skimage\nfrom skimage import transform\nfrom skimage.transform import resize\nimport scipy\nfrom scipy.misc import imresize, imread\nfrom scipy import misc\nimport keras\nfrom keras import backend as K\nfrom keras import models, layers, optimizers\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.models import Model, Sequential, model_from_json\nfrom keras.layers import Dense, Dropout, Input, Activation, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D, Lambda, AveragePooling2D\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nimport sklearn\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, learning_curve, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, make_scorer, accuracy_score\nfrom sklearn.utils import class_weight\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1703775e4c6a04993dc2bb5d8437dfc9807b33a"},"cell_type":"markdown","source":"# Step 2 Read the Files"},{"metadata":{"trusted":true,"_uuid":"a5e5f647967a54011883e5da9327d778e8b3a732","collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport math\nfrom glob import glob\nimport os\n\nmaster = pd.read_csv(\"../input/train_labels.csv\")\nmaster.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43c67933bb2087ee377fc7bddafc5ef11da93ef1","collapsed":true},"cell_type":"code","source":"img_path = \"../input/train/\"\n\ny = []\nfile_paths = []\nfor i in range(len(master)):\n    file_paths.append( img_path + str(master.iloc[i][0]) +'.jpg' )\n    y.append(master.iloc[i][1])\ny = np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd8532f790f9ab924c8000d018b84641e90e4a0","collapsed":true},"cell_type":"code","source":"file_paths[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0cebb84b8b7f05db012c3b8cd6b869e8ccbf67c","collapsed":true},"cell_type":"code","source":"y[:10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f94a4abffdd1574ed6416e38abc7136ebf168514"},"cell_type":"markdown","source":"# Step Three : Plot the Data"},{"metadata":{"trusted":true,"_uuid":"9309892e6768db0ed4f3e689c664d33f84e3c88b","collapsed":true},"cell_type":"code","source":"image = cv2.imread(file_paths[0])\nplt.figure(figsize=(16,16))\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bff3efd755ed527efa156fb058554175b2080da"},"cell_type":"markdown","source":"# Step Four : Read the Data into Arrays"},{"metadata":{"trusted":true,"_uuid":"02c8140ee35372a97d8ea0ab8adc472efea69954","collapsed":true},"cell_type":"code","source":"imageSize =256\nfrom tqdm import tqdm\ndef get_data(file_paths):\n    \"\"\"\n    Load the data and labels from the given folder.\n    \"\"\"\n    X = []\n    for image_filename in tqdm(file_paths):\n        img_file = cv2.imread(image_filename)\n        if img_file is not None:\n            img_file = skimage.transform.resize(img_file, (imageSize, imageSize, 3))\n            img_arr = np.asarray(img_file)\n            X.append(img_arr)\n                           \n    X = np.asarray(X)\n    return X\n\nX_train = get_data(file_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db09be52ab7ef876a8a6deab197c2fe485f3dfeb","collapsed":true},"cell_type":"code","source":"type(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4a3308e42ead816d2fd580d0f2896bde9d46dbd","collapsed":true},"cell_type":"code","source":"X_train = X_train / 255\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80cdde1052de1ce197e71bfd88d8f3a8ac47f134"},"cell_type":"markdown","source":"# Split into Train and Validation Data"},{"metadata":{"trusted":true,"_uuid":"54a809750dac58fc0eafab787533892a7edd1898","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a22d59570f42340ca1fdc673215ca80ce170b6b6","collapsed":true},"cell_type":"markdown","source":"# Build the Convolutional Network"},{"metadata":{"trusted":true,"_uuid":"17fbbbb20a1f18bf27e098762959104496ebf52c","collapsed":true},"cell_type":"code","source":"pretrained_model_1 = VGG16(include_top=False, input_shape=(imageSize, imageSize, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"290a8a5a366a8aeb3f252d0654abf71d2fc18d22","collapsed":true},"cell_type":"code","source":"base_model = pretrained_model_1 # Topless\noptimizer1 = keras.optimizers.Adam()\n# Add top layer\nx = base_model.output\nx = Conv2D(256, kernel_size = (3,3), padding = 'valid')(x)\nx = Flatten()(x)\nx = Dropout(0.75)(x)\npredictions = Dense(1, activation='sigmoid')(x)\nmodel = Model(inputs=base_model.input, outputs=predictions)\n# Train top layer\nfor layer in base_model.layers:\n    layer.trainable = False\nmodel.compile(loss='binary_crossentropy', \n              optimizer=optimizer1, \n              metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5751edd413eb091e658828dd6f7f6d1e281fa84","collapsed":true},"cell_type":"code","source":"history = model.fit(X_train,y_train, \n                        epochs=10, \n                        batch_size = 32,\n                        validation_data=(X_test,y_test), \n                        verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c03c615a46585b4fad7d0e724dc4bf0849af71c3","collapsed":true},"cell_type":"code","source":"del X_train\ndel y_train\ndel X_test\ndel y_test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64b4585d9dd4916ee9a0ba29ee9cc87238f8163b","collapsed":true},"cell_type":"code","source":"import gc \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7e42ea554e83850a3ae57064b41231437ba40272"},"cell_type":"markdown","source":"# Prepare the Test Data"},{"metadata":{"trusted":true,"_uuid":"67a2f06c18463c74206b013f73eef73c273cb9d0","collapsed":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nimg_path = \"../input/test/\"\n\ntest_names = []\nfile_paths2 = []\n\nfor i in range(len(sample_submission)):\n    test_names.append(sample_submission.iloc[i][0])\n    file_paths2.append( img_path + str(int(sample_submission.iloc[i][0])) +'.jpg' )\n    \ntest_names = np.array(test_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa0d590a1482cba0af4de7da239de383d87a4075","collapsed":true},"cell_type":"code","source":"file_paths2[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc171bd62151ddca005ff9975b1c56f785a636e6","collapsed":true},"cell_type":"code","source":"X_test2 = get_data(file_paths2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9b0f6d780ae93156e95c301e60b18107e0213c75"},"cell_type":"code","source":"X_test2 = X_test2 / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a66d5b95502a28d43b67b90a1f743ebdf9f47c97"},"cell_type":"code","source":"y_pred = model.predict(X_test2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"035b61c3de8932bf70f2a0fa1c3db1b66fd8bfc9","collapsed":true},"cell_type":"code","source":"y_pred[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f50963356651710271a25ffc87d6facca2fb8a44","collapsed":true},"cell_type":"code","source":"type(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31dd3d03c706b1bd80b38b7efcfbc516a2bc2cf3","collapsed":true},"cell_type":"code","source":"y_pred[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5099e1d656311959ed2c4f7281a2e1db2e2866a9"},"cell_type":"code","source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"872acab82bd7e32bd0d794d5d7bd5a7755900399","collapsed":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69e9e14def66571ee34d8f57ad8b912407ef9def","collapsed":true},"cell_type":"code","source":"for i, name in enumerate(test_names):\n    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = y_pred[i]\n\nsample_submission.to_csv(\"submit.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c5da676311a9b7d68596d6cee48521a306d00768"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}