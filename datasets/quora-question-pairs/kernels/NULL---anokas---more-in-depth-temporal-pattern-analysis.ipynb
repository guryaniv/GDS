{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "936adb50-0332-1adc-79ba-0d1d8a22eb98"
      },
      "source": [
        "Here's a quick attempt at exploring why the train set average response rate could be so different to that observed in the Public LB\n",
        "\n",
        "If we make the assumption that there's an underlying temporal pattern to the data, and use the qid values as a proxy for it (higher qid value implies more recent question), then re-sorting the train set by increasing qid and plotting the sliding window of mean response rate should show us some pattern.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "83f9757a-d270-8155-af97-9c4941cdffc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv( \"../input/train.csv\")\n",
        "\n",
        "df[\"qmax\"]      = df.apply( lambda row: max(row[\"qid1\"], row[\"qid2\"]), axis=1 )\n",
        "df              = df.sort_values(by=[\"qmax\"], ascending=True)\n",
        "df[\"dupe_rate\"] = df.is_duplicate.rolling(window=500, min_periods=500).mean()\n",
        "df[\"timeline\"]  = np.arange(df.shape[0]) / float(df.shape[0])\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "#df.plot(x=\"timeline\", y=\"dupe_rate\", kind=\"line\")\n",
        "plt.plot(df['timeline'],)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ec29b0de-4357-3efc-ec59-af471196508e"
      },
      "source": [
        "The above pattern, and the ~16.5% LB response rate reported by others, imply that the Public LB (and possibly Private LB) are potentially sourced from more recent data than the training set.\n",
        "\n",
        "If this holds, then we could also use this concept to more appropriately construct validation data splits and training data sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c6cd72d-4bc8-fe77-b337-fcffe26e8c9f"
      },
      "outputs": [],
      "source": [
        "df[\"dupe_rate_2\"] = df.is_duplicate.rolling(window=25000, min_periods=500).mean()\n",
        "plt.figure(figsize=(20, 20))\n",
        "df.plot(x=\"timeline\", y=\"dupe_rate_2\", kind=\"line\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5215f00c-7cc5-4f0b-9a69-7e0b56f8334a"
      },
      "outputs": [],
      "source": [
        "plt.hist(df['dupe_rate_2'].dropna(), bins=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "660ba5c4-0815-2e83-b3fc-b301227cb22c"
      },
      "outputs": [],
      "source": [
        "df['dupe_rate_grad'] = df['dupe_rate_2'].diff(5000)\n",
        "df.plot(x=\"timeline\", y=\"dupe_rate_grad\", kind=\"line\")"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}