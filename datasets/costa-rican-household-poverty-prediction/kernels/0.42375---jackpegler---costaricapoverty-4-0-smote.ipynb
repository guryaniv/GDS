{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\nfrom imblearn.over_sampling import SMOTE\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae38c059eeaeca4b849ca34e438b89ef5d658ffc"},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"trusted":true,"_uuid":"6bdd8ca0964338d5aabe5959dd18f51441082789"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\nprint(\"Shape of training set: {}\".format(train.shape))\nprint(\"Shape of training set: {}\".format(test.shape))\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b163e7df40b97b272c828b075bf5d8a6b88a645"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"bc45ed8a46e87510821b6b8081fbb5460f043552"},"cell_type":"code","source":"# get dependency from the square\ntrain['dependency'] = train['SQBdependency'].apply(lambda x: np.sqrt(x))\ntrain['dependency'].describe()\n\n# get dependency from the square\ntest['dependency'] = test['SQBdependency'].apply(lambda x: np.sqrt(x))\ntest['dependency'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66dd68cc4b04b4235c07dd7f13a4be4396144fd2"},"cell_type":"code","source":"## Filter out for ONLY heads of household in TRAINING DATA\n#train = train[train['parentesco1']==1]\n\n# Check no duplicates\nprint(\"Head of house: {}\".format(train.shape[0]))\nprint(\"Number of unique house IDs: {}\".format(len(train['idhogar'].unique())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82af41f5dd2e880fd550af0bdea4c6e0e7e03136"},"cell_type":"code","source":"# drop a SQUARE columns the we won't use\nkeep_cols = [col for col in train.columns if col[:3] != 'SQB']\nkeep_cols = [item for item in keep_cols if item != 'agesq']\nkeep_cols\n\ntrain = train[keep_cols]\ntest = test[keep_cols[0:-1]]\n\nprint(\"Columns in Training set: {}\".format(train.shape[1]))\nprint(\"Columns in Test set: {}\".format(test.shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f821f88524b5a16283e994ba9d0af06a70ea6a23"},"cell_type":"markdown","source":"### Create some new columns & Change others"},{"metadata":{"trusted":true,"_uuid":"e936481332cce4fe5b66bde7d20ca699b262f8c1"},"cell_type":"code","source":"# children per adult\ntrain['child_per_adult'] = train['hogar_nin'] / train['hogar_adul']\ntest['child_per_adult'] = test['hogar_nin'] / test['hogar_adul']\n\n# rooms per person\ntrain['room_per_person'] = train['rooms'] / train['tamviv']\ntest['room_per_person'] = test['rooms'] / test['tamviv']\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d3a1c41971838829816f7d8ba026507753042c0"},"cell_type":"code","source":"#walls and roof bad\ntrain.loc[(train['epared1'] == 1) & (train['etecho1'] == 1), 'bad_walls_roof'] = 1\ntest.loc[(test['epared1'] == 1) & (test['etecho1'] == 1), 'bad_walls_roof'] = 1\n\n#bad walls, roof and floor\ntrain.loc[(train['bad_walls_roof'] == 1) & (train['eviv1'] == 1), 'bad_walls_roof_floor'] = 1\ntest.loc[(test['bad_walls_roof'] == 1) & (test['eviv1'] == 1), 'bad_walls_roof_floor'] = 1\n\n# no electricity or water inside\ntrain.loc[(train['abastaguadentro'] != 1) & (train['noelec'] == 1), 'no_elec_or_water'] = 1\ntest.loc[(test['abastaguadentro'] != 1) & (test['noelec'] == 1), 'no_elec_or_water'] = 1\n\n#has bathroom and fridge\ntrain.loc[(train['v14a'] == 1) & (train['refrig'] == 1), 'bath_and_fridge'] = 1\ntest.loc[(test['v14a'] == 1) & (test['refrig'] == 1), 'bath_and_fridge'] = 1\n\n#has computer and TV\ntrain.loc[(train['computer'] == 1) & (train['television'] == 1), 'pc_and_tv'] = 1\ntest.loc[(test['computer'] == 1) & (test['television'] == 1), 'pc_and_tv'] = 1\n\n\ntrain['bad_walls_roof'] = train['bad_walls_roof'].fillna(0)\ntrain['bad_walls_roof_floor'] = train['bad_walls_roof_floor'].fillna(0)\ntrain['no_elec_or_water'] = train['no_elec_or_water'].fillna(0)\ntrain['bath_and_fridge'] = train['bath_and_fridge'].fillna(0)\ntrain['pc_and_tv'] = train['pc_and_tv'].fillna(0)\n\ntest['pc_and_tv'] = test['pc_and_tv'].fillna(0)\ntest['bath_and_fridge'] = test['bath_and_fridge'].fillna(0)\ntest['bad_walls_roof'] = test['bad_walls_roof'].fillna(0)\ntest['bad_walls_roof_floor'] = test['bad_walls_roof_floor'].fillna(0)\ntest['no_elec_or_water'] = test['no_elec_or_water'].fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08fa4f77ad5aa258cb334e2c8fc7fab6ff417d9f"},"cell_type":"code","source":"### Reworked my original handling of this feature based on https://www.kaggle.com/skooch/xgboost\n# fill \"no\"s for education with 0s\ntrain.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\ntrain.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\ntest.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\ntest.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n\n# if education is \"yes\" and person is head of household, fill with escolari\ntrain.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\ntrain.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n\ntest.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\ntest.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n\n# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\ntrain.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\ntrain.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n\ntest.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\ntest.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n\n# convert to int for our models\ntrain['edjefe'] = train['edjefe'].astype(\"int\")\ntrain['edjefa'] = train['edjefa'].astype(\"int\")\ntest['edjefe'] = test['edjefe'].astype(\"int\")\ntest['edjefa'] = test['edjefa'].astype(\"int\")\n\n# create feature with max education of either head of household\ntrain['HoH_EduMax'] = np.max(train[['edjefa','edjefe']], axis=1)\ntest['HoH_EduMax'] = np.max(test[['edjefa','edjefe']], axis=1)\n\n# fill some nas\ntrain['v2a1']=train['v2a1'].fillna(-1)\ntest['v2a1']=test['v2a1'].fillna(-1)\n\ntrain['qmobilephone']=train['qmobilephone'].fillna(0)\ntest['qmobilephone']=test['qmobilephone'].fillna(0)\n\ntest['v18q1']=test['v18q1'].fillna(0)\ntrain['v18q1']=train['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2241a3ad5beef04158251c219ab158515cd351b9"},"cell_type":"code","source":"# remove columns we identifed as should be null\ntrain = train[train.meaneduc.isnull() == False]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eca1b9ffa8b2dd30f650352b8ef29ef3ae6f3d98"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1217f444099d5ff9a755c6b936e250797fd4af78"},"cell_type":"code","source":"### ONLY want to scale numerical columns\nNUMERICAL_COLUMNS = ['v2a1','hacdor','hacapo','rooms', 'bedrooms', 'overcrowding', 'dependency', 'meaneduc','v18q1','r4h1','r4h2','r4h3','r4m1','r4m2','r4m3','r4t1','r4t2','r4t3','hogar_adul','hogar_nin','hogar_mayor','hogar_total','room_per_person','HoH_EduMax', 'age', 'child_per_adult', 'qmobilephone']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a19b1cc0cdbc89b4d56de639a60b6cc62c4ac45"},"cell_type":"code","source":"len(NUMERICAL_COLUMNS)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e57c21b8853c8932b367ed429f1e944b11350d5"},"cell_type":"markdown","source":"#### Reverse the OHE into Categorical variables ######\n"},{"metadata":{"trusted":true,"_uuid":"b72e3f1588e9fd70029a4e6a7e1fec99c061ee23"},"cell_type":"code","source":"## define the categories\n\nWALL = ['paredblolad','paredzocalo','paredpreb','pareddes','paredmad','paredzinc','paredfibras','paredother']\n\nFLOOR = ['pisomoscer','pisocemento','pisoother','pisonatur','pisonotiene','pisomadera']\n\nROOF = ['techozinc','techoentrepiso','techocane','techootro']\n\nWATER =['abastaguadentro','abastaguafuera','abastaguano']\n\nELEC = ['public','planpri','noelec','coopele']\n\nTOILET = ['sanitario1','sanitario2','sanitario3','sanitario5','sanitario6']\n\nCOOK = ['energcocinar1','energcocinar2','energcocinar3','energcocinar4']\n\nRUBBISH = ['elimbasu1','elimbasu2','elimbasu3','elimbasu4','elimbasu5','elimbasu6']\n\nWALL_QLTY = ['epared1', 'epared1','epared3']\n\nROOF_QLTY = ['etecho1','etecho2','etecho3']\n\nFLOOR_QLTY = ['eviv1','eviv2','eviv3']\n\nSEX = ['male', 'female']\n\nCIVIL = ['estadocivil1','estadocivil2','estadocivil3','estadocivil4','estadocivil5','estadocivil6','estadocivil7']\n\nH_OWNER = ['tipovivi1','tipovivi2','tipovivi3','tipovivi4','tipovivi5']\n\nREGION = ['lugar1','lugar2','lugar3','lugar4','lugar5','lugar6']\n\nAREA = ['area1', 'area2']\n\n\nALL_LISTS = [AREA, REGION, H_OWNER, CIVIL, SEX, FLOOR_QLTY, ROOF_QLTY, WALL_QLTY, RUBBISH, COOK, TOILET, ELEC, WATER, ROOF, FLOOR, WALL]\nLIST_NAMES = ['AREA', 'REGION', 'H_OWNER', 'CIVIL', 'SEX', 'FLOOR_QLTY', 'ROOF_QLTY', 'WALL_QLTY', 'RUBBISH', 'COOK', 'TOILET', 'ELEC', 'WATER', 'ROOF', 'FLOOR', 'WALL']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f9cb853bc723cc08d3438c931456ae8e14728c"},"cell_type":"code","source":"## function to change to cat variables and delete OHE columns\ndef OHE_to_cat(df, lists_of_cols, names):\n    \n    for cols, name in zip(lists_of_cols, names):\n        df[name] = (df[cols] == 1).idxmax(1)\n        df[name] = df[name].apply(lambda x: cols.index(x))\n        \n        df = df.drop(columns=cols)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a99f904fef52012bc603d215dd0bdfee6980fe1d"},"cell_type":"code","source":"## Apply to train and test sets\ntrain = OHE_to_cat(train, ALL_LISTS, LIST_NAMES)\ntest = OHE_to_cat(test, ALL_LISTS, LIST_NAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11575e03c8f712e641f6fa0dcbe3da4f0b44f50a"},"cell_type":"code","source":"REPEAT_COLS = ['v18q','tamhog', 'tamviv', 'rez_esc','hhsize','parentesco1',\n               'parentesco2','parentesco3','parentesco4','parentesco5','parentesco6','parentesco7',\n               'parentesco8','parentesco9','parentesco10','parentesco11', 'parentesco12',\n                'idhogar','mobilephone', 'edjefa', 'edjefe', 'escolari', 'instlevel1',\n              'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7',\n              'instlevel8', 'instlevel9']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5274cc23a9b617dd341ba88af66a15d6c37b3195"},"cell_type":"code","source":"train = train.drop(columns=REPEAT_COLS)\ntrain = train.drop(columns=['Id']) # will handle Id in TEST set differently\n\ntest = test.drop(columns=REPEAT_COLS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77b09e57532142d6a0fd6b1e72e026f3acbfa723"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d254fc21e978ee178678ad9a9dbfc174056c257"},"cell_type":"markdown","source":"## Balancing"},{"metadata":{"trusted":true,"_uuid":"3addc43c37acac6b7d139f7a81adfeebe5d3af01"},"cell_type":"code","source":"y_train = train[\"Target\"]\ntrain.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38d74faa9bb6f9f02cbf159ff593b7599508fb35"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85bd6546b9507d06dacd3ecb909e5fab501c87e8"},"cell_type":"code","source":"\"\"\"\nAdapted this strategy to undersample ONLY the class-4\n\"\"\"\ncount_class_4, count_class_2, count_class_3, count_class_1 = train.Target.value_counts()\n# Divide by class\ntrain_class_1 = train[train['Target'] == 1]\ntrain_class_2 = train[train['Target'] == 2]\ntrain_class_3 = train[train['Target'] == 3]\ntrain_class_4 = train[train['Target'] == 4]\n\ntrain_class_1_under = train_class_1.sample(count_class_1, random_state=99)\ntrain_class_2_under = train_class_2.sample(round(count_class_2), random_state=99)\ntrain_class_3_under = train_class_3.sample(round(count_class_3), random_state=99)\ntrain_class_4_under = train_class_4.sample(round(count_class_4*.25), random_state=99)\n\n\ntrain = pd.concat([train_class_1_under, train_class_2_under, train_class_3_under, train_class_4_under], axis=0)\ntrain.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adff2fb3807d6122c735210245f64b96bdbf08c9"},"cell_type":"code","source":"y_train = train['Target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"722c606752b67d5563805f4ca4186185d1694f21"},"cell_type":"code","source":"train_cols = train.columns\nsm = SMOTE(random_state=2)\ntrain_res, y_train_res = sm.fit_sample(train, y_train.ravel())\ntrain_res = pd.DataFrame(train_res, columns=train_cols)\ntrain_res.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b22d56511654d30b9711dee247a3549fc2facee"},"cell_type":"code","source":"X_train = train_res.drop(['Target'], axis = 1) \n\ny_train = y_train_res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2eb9234097fc99788c3aa7bfd33a89e665abed6"},"cell_type":"code","source":"print(\"Final Train Shape: {}\".format(X_train.shape))\nprint(\"Final TEST Shape: {}\".format(test.shape))\nprint(\"Extra column is Id which will be handled later\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"927d24dcfb070a8fc5ee6c48184d74166dc67264"},"cell_type":"markdown","source":"## Train, Dev split"},{"metadata":{"trusted":true,"_uuid":"1a36e012db6d103ac2c250a85f9c14197c284b5d"},"cell_type":"code","source":"X_train, X_dev, y_train, y_dev = train_test_split(X_train,y_train,test_size = 0.2,random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73a06200682ecc2eb8b081f3efc0ad77781cb040"},"cell_type":"markdown","source":"## Scaling"},{"metadata":{"trusted":true,"_uuid":"592885e7d6d2161504e4d1823fda5da32739cb3f"},"cell_type":"code","source":"sc_X = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab74d076e3e525b91304a257d5baf7ff2a664396"},"cell_type":"code","source":"## Only Scaling the Numerical Columns not Binary\nX_train_bin = X_train.drop(NUMERICAL_COLUMNS, axis = 1) \nX_dev_bin = X_dev.drop(NUMERICAL_COLUMNS, axis = 1) \n\nX_train = X_train[NUMERICAL_COLUMNS]\nX_dev = X_dev[NUMERICAL_COLUMNS] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2de763c5e468b4425732f370ca12f33caad405c"},"cell_type":"code","source":"### fit to training and transform traing and tes\nX_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\nX_dev2= pd.DataFrame(sc_X.transform(X_dev))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c61daf8a8b1a461423d7c907a645b357b9b5ba3e"},"cell_type":"code","source":"#scaler returns numpy array and lose index and columns names which we don't want!\nX_train2.columns = X_train.columns.values\nX_dev2.columns = X_dev.columns.values\n\nX_train2.index = X_train.index.values\nX_dev2.index = X_dev.index.values\n\n# combine the numerical and categorical values\nX_train = pd.concat([X_train2, X_train_bin],axis=1, sort=False)\nX_dev = pd.concat([X_dev2,X_dev_bin],axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05c0d0ba21e8e119071ebe2dd4f89d890e9d7cf5"},"cell_type":"code","source":"# check shape\nprint(X_train.shape)\nprint(X_dev.shape)\nprint(y_train.shape)\nprint(y_dev.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d173be9bdadb10d62593ac1b9d560cf208de8ea"},"cell_type":"code","source":"X_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"033468a456833bbf5709bbfb3b7c03f8a433956f"},"cell_type":"markdown","source":"## MODEL DEVELOPMENT"},{"metadata":{"trusted":true,"_uuid":"c31eba59208f53eed453f291ec8e4bf2e3f9a3d8"},"cell_type":"code","source":"random_forest = RandomForestClassifier(n_estimators=400)\n\ny_train = pd.DataFrame(y_train)\nrandom_forest.fit(X_train, y_train.values.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41894a752af712d5250abf5eb48e536afd08ad15"},"cell_type":"code","source":"### Get metrics for Dev set\ny_pred = random_forest.predict(X_dev)\n\nprint(\"Accuracy:\")\nprint(round(random_forest.score(X_dev, y_dev), 3))\n\n\n# of predicted +ve, how many correct\nprint(\"Precision score:\")\nprint(round(precision_score(y_dev, y_pred, average='macro'), 3))\n\n\n# of all actual +ve how many did we get\nprint(\"Recall score:\")\nprint(round(recall_score(y_dev, y_pred, average='macro'), 3))\n\n# f1 combines\nprint(\"Global F1 score:\")\nprint(round(f1_score(y_dev, y_pred, average='macro'), 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9c60c00d4b394942c386a559cbcf28fd38019b7","scrolled":true},"cell_type":"code","source":"cm = confusion_matrix(y_dev, y_pred.round())\ndf_cm = pd.DataFrame(cm, index = (1,2,3,4), columns=(1,2,3,4))\nplt.figure(figsize = (10,7))\nsns.set(font_scale=1.4)\nsns.heatmap(df_cm, annot = True, fmt='g')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nprint('Test Data Accuracy: %0.4f' % accuracy_score(y_dev, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2721f054b4bed9138d9089411f013093a245ab04"},"cell_type":"markdown","source":"## Improve model"},{"metadata":{"trusted":true,"_uuid":"0dac22c99a2b6479bef5f0b819953d65ad5c392a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cd49529e72afc85e9bab42573984e56b4cd6057"},"cell_type":"markdown","source":"## Test"},{"metadata":{"trusted":true,"_uuid":"930a11a21c143e34cfe4ef21999fafaef848214c"},"cell_type":"code","source":"print(test.shape)\nprint(X_train.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2da35e2ffc645fcec1afc4a5908a690bc24199c"},"cell_type":"code","source":"test_id = test['Id']\ntest = test.drop(columns=['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2221eb453fc237b3504e06e3f38ebdea0bef0d7"},"cell_type":"code","source":"# would be important to check that these are records where there its not HoH; not that can do much..\n# and 31 on 29k isn't bad\ntest['meaneduc']=test['meaneduc'].fillna(-1)\n\ntest_bin = test.drop(NUMERICAL_COLUMNS, axis = 1) \ntest = test[NUMERICAL_COLUMNS]\ntest.describe()\n\n# some inf and nan on child_per_adult\ntest['child_per_adult'] = test['child_per_adult'].replace([np.inf, -np.inf], np.nan)\ntest['child_per_adult'] = test['child_per_adult'].fillna(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb1c25798dae6b624eb555e7493f0220b9c020e"},"cell_type":"code","source":"# Scale\ntest2 = pd.DataFrame(sc_X.transform(test))\n\n#scaler returns numpy array and lose index and columns names which we don't want!\ntest2.columns = test.columns.values\ntest2.index = test.index.values\n\n# combine the numerical and categorical values\ntest = pd.concat([test2, test_bin],axis=1, sort=False)\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"617468137eaa8ae61a5a640ddc9951f02c3d4596"},"cell_type":"code","source":"# predict values\ntest_pred = random_forest.predict(test)\ntest_pred = pd.DataFrame(test_pred)\n\nmy_preds = pd.concat([test_id, test_pred],axis=1, sort=False)\nmy_preds.columns = ['Id', 'Target']\nmy_preds.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"713f0b41ce223bc12a4bbdb8496176898c8aac32"},"cell_type":"code","source":"my_preds.to_csv('190128_g_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"596cb2c39730df9d258a8929f9897c400c68183e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}