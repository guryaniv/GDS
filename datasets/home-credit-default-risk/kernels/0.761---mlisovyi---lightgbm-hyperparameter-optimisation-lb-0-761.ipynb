{"cells":[{"metadata":{"_uuid":"e44e5ca4e44464ffdcce0e840c543577bd6569bf"},"cell_type":"markdown","source":"# Basic end-to-end training of a LightGBM model\n\nFeatures that are illustrated in this kernel:\n- data reading with **memory footprint reduction**\n- a bit of feature engineering adding **estimated credit length, which boosts AUC ROC by 0.015 on PLB and by 0.035 in local CV**\n- categorical feature encoding using **one-hot-encoding (OHE)**\n-  internal **category weighting** by _**LightGBM**_ was tuned and no need of resampling is shown\n- **gradient-boosted decision trees** using _**LightGBM**_ package\n- **early stopping** in _**LightGBM**_ model training to avoid overtraining\n- **learning rate decay** in _**LightGBM**_ model training to improve convergence to the minimum\n- **hyperparameter optimisation** of the model using random search in cross validation\n- submission preparation\n**The main goal is to provide an example of how those features can be used. High ROC AUC score is not the purpose here**\nThis kernel inherited ideas and SW solutions from other public kernels and in such cases I will post direct references to the original product, that that you can get some additional insights from the source."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \nplt.xkcd()\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nPATH = \"../input/\"\nprint(os.listdir(PATH))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ed4d74b3e586cc5b1be41bf67756e370b86186a"},"cell_type":"markdown","source":"## Read in the data reducing memory pattern for variables.\nThe implementation was copied over from [this kernel](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"259665371981ab1eeae11333963b96b6099fd9e0"},"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\n\ndef import_data(file):\n    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n    df = reduce_mem_usage(df)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"application_train = import_data(PATH+'application_train.csv')\napplication_test = import_data(PATH+'application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83d85f866b03c50ff1962917db4dd9d149ef6243"},"cell_type":"markdown","source":"The following 2 cells with cleaning criteria were inherited from [this kernel](https://www.kaggle.com/kingychiu/home-credit-eda-distributions-and-outliers)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a258ddefe97be5807054b3742fb8ab1f18ac62aa"},"cell_type":"code","source":"application_train = application_train[application_train['AMT_INCOME_TOTAL'] != 1.170000e+08]\napplication_train = application_train[application_train['AMT_REQ_CREDIT_BUREAU_QRT'] != 261]\napplication_train = application_train[application_train['OBS_30_CNT_SOCIAL_CIRCLE'] < 300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a56b73ffe90bdab9015d385d68567cf03617bdf","collapsed":true},"cell_type":"code","source":"application_train['DAYS_EMPLOYED'] = (application_train['DAYS_EMPLOYED'].apply(lambda x: x if x != 365243 else np.nan))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fb1ac77952823a894bede3dc852b942bf6ee4a7"},"cell_type":"markdown","source":"## Additional numerical features\nThe credit length feature idea is due [@oskird](https://www.kaggle.com/sz8416) implemented [here in the corresponding kernel](https://www.kaggle.com/sz8416/eda-baseline-model-using-application)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3b5d60b0df693c67fbb18f68f9123e0b2b3ae7e0"},"cell_type":"code","source":"def feat_ext_source(df):\n    x1 = df['EXT_SOURCE_1'].fillna(-1) + 1e-1\n    x2 = df['EXT_SOURCE_2'].fillna(-1) + 1e-1\n    x3 = df['EXT_SOURCE_3'].fillna(-1) + 1e-1\n    \n    df['EXT_SOURCE_1over2_NAminus1_Add0.1'] = x1/x2\n    df['EXT_SOURCE_2over1_NAminus1_Add0.1'] = x2/x1\n    df['EXT_SOURCE_1over3_NAminus1_Add0.1'] = x1/x3\n    df['EXT_SOURCE_3over1_NAminus1_Add0.1'] = x3/x1\n    df['EXT_SOURCE_2over3_NAminus1_Add0.1'] = x2/x3\n    df['EXT_SOURCE_3over2_NAminus1_Add0.1'] = x3/x2\n    \n    df['EXT_SOURCE_na1_2'] = (df['EXT_SOURCE_1'].isnull()) * (df['EXT_SOURCE_2'].fillna(0))\n    df['EXT_SOURCE_na1_3'] = (df['EXT_SOURCE_1'].isnull()) * (df['EXT_SOURCE_3'].fillna(0))\n    df['EXT_SOURCE_na2_1'] = (df['EXT_SOURCE_2'].isnull()) * (df['EXT_SOURCE_1'].fillna(0))\n    df['EXT_SOURCE_na2_3'] = (df['EXT_SOURCE_2'].isnull()) * (df['EXT_SOURCE_3'].fillna(0))\n    df['EXT_SOURCE_na3_1'] = (df['EXT_SOURCE_3'].isnull()) * (df['EXT_SOURCE_1'].fillna(0))\n    df['EXT_SOURCE_na3_2'] = (df['EXT_SOURCE_3'].isnull()) * (df['EXT_SOURCE_2'].fillna(0))\n    \n    df['CREDIT_LENGTH'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aa46a91e767414557d54b0fa9d79bfc013812289"},"cell_type":"code","source":"application_train = feat_ext_source(application_train)\napplication_test  = feat_ext_source(application_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87bce4fc7ddd06b3778cd5c0bcf99bcde57ce0ab"},"cell_type":"markdown","source":"## Categorical encoding\nThe function was taken from [this kernel](https://www.kaggle.com/sz8416/simple-intro-eda-baseline-model-with-gridsearch). It allows to do OneHotEncoding (OHE) keeping only those columns that are common to train and test samples. OHE is performed using `pd.get_dummies`, which allows to convert categorical features, while keeping numerical untouched"},{"metadata":{"trusted":true,"_uuid":"f4114dfe218a34a532275add442cb92a0414b3a4","collapsed":true},"cell_type":"code","source":"# use this if you want to convert categorical features to dummies(default)\ndef cat_to_dummy(train, test):\n    train_d = pd.get_dummies(train, drop_first=False)\n    test_d = pd.get_dummies(test, drop_first=False)\n    # make sure that the number of features in train and test should be same\n    for i in train_d.columns:\n        if i not in test_d.columns:\n            if i!='TARGET':\n                train_d = train_d.drop(i, axis=1)\n    for j in test_d.columns:\n        if j not in train_d.columns:\n            if j!='TARGET':\n                test_d = test_d.drop(i, axis=1)\n    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(train.memory_usage().sum() / 1024**2, \n                                                                            train_d.memory_usage().sum() / 1024**2))\n    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(test.memory_usage().sum() / 1024**2, \n                                                                            test_d.memory_usage().sum() / 1024**2))\n    return train_d, test_d\n\napplication_train_ohe, application_test_ohe = cat_to_dummy(application_train, application_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4bf82dab5971e542c488ed1e96fc5f9fa75b6e87"},"cell_type":"code","source":"# use this if you want to convert categorical features to dummies(default)\ndef cat_to_int(train, test):\n    mem_orig_train = train.memory_usage().sum() / 1024**2\n    mem_orig_test  = test .memory_usage().sum() / 1024**2\n    categorical_feats = [ f for f in train.columns if train[f].dtype == 'object' or train[f].dtype.name == 'category' ]\n    print('---------------------')\n    print(categorical_feats)\n    for f_ in categorical_feats:\n        train[f_], indexer = pd.factorize(train[f_])\n        test[f_] = indexer.get_indexer(test[f_])\n    print('Memory usage of train increases from {:.2f} to {:.2f} MB'.format(mem_orig_train, \n                                                                            train.memory_usage().sum() / 1024**2))\n    print('Memory usage of test increases from {:.2f} to {:.2f} MB'.format(mem_orig_test, \n                                                                            test.memory_usage().sum() / 1024**2))\n    return categorical_feats, train, test\n\n#categorical_feats, application_train_ohe, application_test_ohe = cat_to_int(application_train, application_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7faf1adde941f470349ca125e4fdcc71ea55330f"},"cell_type":"markdown","source":"Use this instead if you want to make use of the internal categorical feature treatment in lightgbm."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"41e810b51a69e157ef4e07f21e93615e6ab81069"},"cell_type":"code","source":"#application_train_ohe, application_test_ohe = (application_train, application_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfa35f60c92ae01d6de9c82ef52ffc1a0c00350d"},"cell_type":"markdown","source":"## Deal with category imbalance\nUse a standard library (`imblearn`) to to random undersampling on the dominating category. Use if if you want to repeat the HP optimisation"},{"metadata":{"trusted":true,"_uuid":"f62e64bf4e4d4329a0c4216651b287cea8f3100d","collapsed":true},"cell_type":"code","source":"\n#from imblearn.under_sampling import RandomUnderSampler\n#rus = RandomUnderSampler(random_state=314)\n#X_rus, y_rus = rus.fit_sample(application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1).fillna(-1), \n#                              application_train_ohe['TARGET'])\n\n# You can use the full sample and do sample weighting in lightgbm using `is_unbalance` OR `scale_pos_weight` argument\n# But it makes the code to run 8x..10x slower, which is ok for the run with pre-optimised parametersm but is too slow for HP optimisation\nX_rus, y_rus = (application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1),\n                application_train_ohe['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"077f571d694f0b446b0c2b84991bf91071d84ce0"},"cell_type":"markdown","source":"# Model fitting with HyperParameter optimisation\nWe will use LightGBM classifier - LightGBM allows to build very sophysticated models with a very short training time.\n### Split the full sample into train/test (80/20)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c9053167195838284544e5d717c1c68b27b46fb"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.20, random_state=314, stratify=y_rus)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08cb13d0caa3713665f843db8a83de6744210f83"},"cell_type":"markdown","source":"### Prepare learning rate shrinkage"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a746df8c0f27948f76f476b7329bf11449d25f38"},"cell_type":"code","source":"def learning_rate_010_decay_power_099(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_010_decay_power_0995(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_005_decay_power_099(current_iter):\n    base_learning_rate = 0.05\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8af9e2ff9ca6f6bb59b7380bc65c99a5063f4c7"},"cell_type":"markdown","source":"### Use test subset for early stopping criterion \nThis allows us to avoid overtraining and we do not need to optimise the number of trees"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f565eef3d14a6d8ade0602823dcd316ad2829117"},"cell_type":"code","source":"import lightgbm as lgb\nfit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_test,y_test)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edcf7716984b1f0ed56d4d325d0ddee2efe7c017"},"cell_type":"markdown","source":"### Set up HyperParameter search\nWe use random search, which is more flexible and more efficient than a grid search"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8a1c436c90043f3ade05d149f4714ccf5bbf15aa"},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparam_test ={'num_leaves': sp_randint(6, 50), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bb7998f3db77da6fc23737bbf8d80a260391f24","collapsed":true},"cell_type":"code","source":"#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 100\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=314,\n    verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ab1e4e2b4726f0d1864ec085c1929a2c4d3dba1"},"cell_type":"markdown","source":"Run this cell, to do HP optimisation. To save time `opt_parameters` was directly hardcoded below."},{"metadata":{"trusted":true,"_uuid":"1d6c7e208287046714f376085cb3745da63ad7e1","collapsed":true},"cell_type":"code","source":"#gs.fit(X_train, y_train, **fit_params)\n#print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"684c01b827d63be6cb3e8a97eb942f8ece5201e5"},"cell_type":"code","source":"opt_parameters = {'colsample_bytree': 0.9234, 'min_child_samples': 399, 'min_child_weight': 0.1, 'num_leaves': 13, 'reg_alpha': 2, 'reg_lambda': 5, 'subsample': 0.855}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ec17e1e5fec8b04a1602f4524486848deda39a9"},"cell_type":"markdown","source":"## Tune the weights of unbalanced classes\nFollowing discussion in [this comment](https://www.kaggle.com/mlisovyi/modular-good-fun-with-ligthgbm/comments#337494), there was a small tuning of the disbalanced sample weight:\n"},{"metadata":{"trusted":true,"_uuid":"01da6dd7dd86c2d62fd4858765ffe5a45c7e9f7b","collapsed":true},"cell_type":"code","source":"clf_sw = lgb.LGBMClassifier(**clf.get_params())\n#set optimal parameters\nclf_sw.set_params(**opt_parameters)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"920796edc3cce8d8d5bd72bfb34be0e611c5336c","collapsed":true},"cell_type":"code","source":"gs_sample_weight = GridSearchCV(estimator=clf_sw, \n                                param_grid={'scale_pos_weight':[1,2,6,12]},\n                                scoring='roc_auc',\n                                cv=5,\n                                refit=True,\n                                verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f91033d82c3cccd7fb6a6dbe1bd99cdf77e01d07","collapsed":true},"cell_type":"code","source":"gs_sample_weight.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(gs_sample_weight.best_score_, gs_sample_weight.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83272a6ccf734a4b8b262022c0b326ad8c611bc1"},"cell_type":"markdown","source":"As an outcome, precision of the classifier does not depend much on the internal class weighting, but `weight=1` still turns out to give slightly better performance that weighted scenarios."},{"metadata":{"_uuid":"a4362d5fd50f429e8157996c4a20da5ef1069711"},"cell_type":"markdown","source":"### Look at the performance of the top-5 parameter choices\n(the list is inverted)"},{"metadata":{"trusted":true,"_uuid":"d292f90f371aa3f9c614a694fdd4b64fe0476845","collapsed":true},"cell_type":"code","source":"#print(\"Valid+-Std     Train  :   Parameters\")\n#for i in np.argsort(gs.cv_results_['mean_test_score'])[-5:]:\n#    print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs.cv_results_['params'][i], \n#                                    gs.cv_results_['mean_test_score'][i], \n#                                    gs.cv_results_['mean_train_score'][i],\n#                                    gs.cv_results_['std_test_score'][i]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac81e2ddb8deeabc0c4d555d0ae66c4b88c1d82","collapsed":true},"cell_type":"code","source":"print(\"Valid+-Std     Train  :   Parameters\")\nfor i in np.argsort(gs_sample_weight.cv_results_['mean_test_score'])[-5:]:\n    print('{1:.3f}+-{3:.3f}     {2:.3f}   :  {0}'.format(gs_sample_weight.cv_results_['params'][i], \n                                    gs_sample_weight.cv_results_['mean_test_score'][i], \n                                    gs_sample_weight.cv_results_['mean_train_score'][i],\n                                    gs_sample_weight.cv_results_['std_test_score'][i]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af7d792fa3b44bbf11bec995032c95bfacf12ee2"},"cell_type":"markdown","source":"## Build the final model\nWe do training with the 0.8 subset of the dataset and 0.2 subset for early stopping. We use the tuned parameter values but a smaller learning rate to allow smoother convergence to the minimum"},{"metadata":{"trusted":true,"_uuid":"53bb37030e953d3e5d332e5886997de9925109e0","scrolled":true,"collapsed":true},"cell_type":"code","source":"#Configure from the HP optimisation\n#clf_final = lgb.LGBMClassifier(**gs.best_estimator_.get_params())\n\n#Configure locally from hardcoded values\nclf_final = lgb.LGBMClassifier(**clf.get_params())\n#set optimal parameters\nclf_final.set_params(**opt_parameters)\n\n#Train the final model with learning rate decay\nclf_final.fit(X_train, y_train, **fit_params, callbacks=[lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_0995)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d7b27535ec0dfdfe5ae599d3120d714487de4ec"},"cell_type":"markdown","source":"### Plot feature importance"},{"metadata":{"trusted":true,"_uuid":"f92343b2289eeac9ff3006bb8efcf8591ad89f2b","collapsed":true},"cell_type":"code","source":"feat_imp = pd.Series(clf_final.feature_importances_, index=application_train_ohe.drop(['SK_ID_CURR', 'TARGET'], axis=1).columns)\nfeat_imp.nlargest(20).plot(kind='barh', figsize=(8,10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b6ab3bf6034170547105ab835b65503e9f5e3f7"},"cell_type":"markdown","source":"# Predict on the submission test sample"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"377aa88c83f9821fd9f1e7147b78584fbfaa9bb3"},"cell_type":"code","source":"probabilities = clf_final.predict_proba(application_test_ohe.drop(['SK_ID_CURR'], axis=1))\nsubmission = pd.DataFrame({\n    'SK_ID_CURR': application_test_ohe['SK_ID_CURR'],\n    'TARGET':     [ row[1] for row in probabilities]\n})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cb372267b91470fb7579a5fe38f77e6cd8e48a0c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"455cd9159b8edac43d16c7d5f0634cd1e1e9f581"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6e823d094ef5b460a2a95b27d08beee82d6366f5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}