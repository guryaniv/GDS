{"nbformat": 4, "metadata": {"language_info": {"name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import matplotlib.gridspec as gridspec\n", "import seaborn as sns\n", "from sklearn.model_selection import train_test_split, learning_curve\n", "from sklearn.metrics import average_precision_score, f1_score,confusion_matrix\n", "from sklearn import manifold\n", "from xgboost.sklearn import XGBClassifier\n", "from xgboost import plot_importance, to_graphviz\n", "import lightgbm as lgb \n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.cluster import DBSCAN\n", "from sklearn.linear_model import LogisticRegression\n", "import warnings\n", "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n", "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n", "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n", "warnings.filterwarnings(\"ignore\", category=UserWarning)\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "#from subprocess import check_output\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "metadata": {"_cell_guid": "a746de41-abf1-4d86-b92a-c286eba26f32", "_uuid": "543736a46d10891722afec37cf3e9ce20a2bb7a4", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["df = pd.read_csv('../input/PS_20174392719_1491204439457_log.csv')\n", "#df = pd.read_csv('./input/PS_20174392719_1491204439457_log.csv.zip',compression='zip')\n", "\n", "df = df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n", "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})\n"], "execution_count": null, "metadata": {"_cell_guid": "649559ac-1feb-45b7-8009-f3e979cadefe", "_uuid": "8f45775bcae9742c51a51dc4835db7e78c265780", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["df[:1]"], "execution_count": null, "metadata": {"_cell_guid": "c66d860d-4a77-4cff-90c2-3afbf83c0477", "_uuid": "69ad69bc8ffda4af7062e734aaeb1abf9c75ecfa", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["df.describe()"], "execution_count": null, "metadata": {"_cell_guid": "595a34c6-8ad6-4672-8512-1cda54e0f295", "_uuid": "04202908fa2c2861ad8a3aad65fbaf2d7c3ad9bd", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["df.groupby('type')['isFraud','isFlaggedFraud'].sum()"], "execution_count": null, "metadata": {"_cell_guid": "1e9673ba-1d27-40a9-b43b-3568c0359565", "_uuid": "21acda3cd5da4f4d2ea8d4eef4ae4ec539bd4554", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["df.groupby('type')['amount'].mean()"], "execution_count": null, "metadata": {"_cell_guid": "f0e53a28-cac7-467f-9e85-f92b7ee1d69b", "_uuid": "99a5aedb08b9c4999983df65b5848911fc045720", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# Start Feature extraction\n", "# Merchant flag for source and dist\n", "# Trans tye for fraud trans type\n", "data = df.copy()\n", "# add source and target type\n", "data['OrigC']=data['nameOrig'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n", "data['DestC']=data['nameDest'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n", "data['TRANSFER']=data['type'].apply(lambda x: 1 if x=='TRANSFER' else 0)\n", "data['CASH_OUT']=data['type'].apply(lambda x: 1 if x=='CASH_OUT' else 0)\n", "\n", "#"], "execution_count": null, "metadata": {"_cell_guid": "5b7827bc-78f6-4d71-aa65-73b4954acaac", "_uuid": "87aaf7f30b1b5dc0a99832a15bd40472f930ef13", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["# Trans Amount from Loan ? killed features from  Arjun Joshua\n", "data['OrigAmntErr']=(abs(data.oldBalanceOrig-data.newBalanceOrig)-data.amount)*data['OrigC']\n", "data['DestAmntErr']=(abs(data.oldBalanceDest-data.oldBalanceDest)-data.amount)*data['DestC']"], "execution_count": null, "metadata": {"_cell_guid": "4b3ffe36-166b-4254-8b11-485275f1c482", "_uuid": "a221d4f511d6a9d19cd7630ec90a0fbd57050ba3", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["def Fplot(DF,catlist):\n", "    nf = DF.shape[1]\n", "    frdf=DF[catlist][DF.isFraud == 1]\n", "    cldf=DF[catlist][DF.isFraud == 0]\n", "    sns.set(font_scale=1)\n", "    for i, cn in enumerate(catlist):\n", "        if cn != 'isFraud':\n", "            plt.figure(figsize=(12,nf*8))\n", "            gs = gridspec.GridSpec(nf*2, 1)\n", "            ax = plt.subplot(gs[i])\n", "            ax.set_title(str(cn)+'(Fraud-Red/Normal-Green)')\n", "            sns.distplot(frdf[cn], bins=50, color='Red', hist=True)\n", "            ax = plt.subplot(gs[i+1])\n", "            sns.distplot(cldf[cn], bins=50, color='Green', hist=True)\n", "            DF[[cn,'isFraud']].boxplot(by='isFraud', vert=False,figsize=(12,5))\n", "            plt.show()\n", "    "], "execution_count": null, "metadata": {"_kg_hide-input": false, "_cell_guid": "0d977742-2306-4d81-a9ec-ae008f771f0f", "_uuid": "832b5a078da2d746d99d2bfde485c55499141aeb", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["dt=data.sample(n=500000)\n", "flist=['step', u'amount','oldBalanceOrig',\n", "       'newBalanceOrig', 'oldBalanceDest', 'newBalanceDest',\n", "       'isFlaggedFraud', 'OrigC', 'DestC', 'TRANSFER',\n", "       'CASH_OUT', 'OrigAmntErr', 'DestAmntErr']\n", "Fplot(dt,flist)"], "execution_count": null, "metadata": {"_cell_guid": "c02e69cf-fcb2-4f4c-bc17-192e59a11423", "_uuid": "71b8c3859e2c7559ee649b25d8a01d1520bd5512", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["# drop list \n", "droplist=['isFlaggedFraud','OrigC','type','nameDest','nameOrig']"], "execution_count": null, "metadata": {"_cell_guid": "54a1d848-e910-487c-b2a2-e9e3a6bdb5d8", "_uuid": "3db676796af45b34f435a76667a67ec9c4a22469", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["#print XGBoost result\n", "def presult(clf,x_test,y_test, plotimp=1):\n", "    y_prob=clf.predict_proba(x_test)\n", "    y_pred=clf.predict(x_test)\n", "    print ('AUPRC :', (average_precision_score(y_test, y_prob[:, 1])))\n", "    print ('F1 - macro :',(f1_score(y_test,y_pred,average='macro')))\n", "    print  ('Confusion_matrix : ')\n", "    print (confusion_matrix(y_test,y_pred))\n", "    sns.set(font_scale=1.5)\n", "    #sns.heatmap(confusion_matrix(testY,y_pred), annot=True,annot_kws={\"size\": 15},fmt='10g')\n", "    #plt.show()\n", "    if plotimp==1:\n", "        plot_importance(clf)\n", "        plt.show()"], "execution_count": null, "metadata": {"_cell_guid": "1d6008d2-f838-4848-ad06-e1e23226095e", "_uuid": "8bad3abd8e3745968505298da0385a5c0c9b6b89", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["#Train/Test Split"], "execution_count": null, "metadata": {"_cell_guid": "43aab066-5256-4fe4-a78b-1c7758c8e379", "_uuid": "eb8a216ef0303ef74a977587643d3f423073141e", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["MLData=data.drop(labels=droplist,axis=1)\n", "X=MLData.drop('isFraud',axis=1)\n", "Y=MLData.isFraud\n"], "execution_count": null, "metadata": {"_cell_guid": "23e58068-dbda-4c03-b429-acf681e0473e", "_uuid": "495e86b2a57266325898ca1dcbe89cf9013cb10a", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3,random_state=42)"], "execution_count": null, "metadata": {"_cell_guid": "f16102b6-8592-4eb1-8874-0e68b2b9de09", "_uuid": "611b3ed2e23f6be7bdcd0bace7a25db5b74ad48b", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["print ('trainX.step.min,max,count', trainX.step.min(),trainX.step.max(),trainX.step.count())\n", "print ('testX.step.min,max,count',testX.step.min(),testX.step.max(),testX.step.count())\n", "print ('y=1 total, train, test',sum(Y),sum(trainY),sum(testY))"], "execution_count": null, "metadata": {"_cell_guid": "a98f42db-f49b-462b-8c46-5ac925d11db3", "_uuid": "27c4a741d93061df5a60d8b89c6ba208fdeb142e", "collapsed": false}}, {"cell_type": "markdown", "source": ["DateTime based feature \"step\" have same value in train and test data. Below i use shuffle=False  to not know the future when learning"], "metadata": {"_cell_guid": "cb2dc527-4aef-4302-b9aa-74d2604fe873", "_uuid": "4fea00ea29ab9c93da236e8eb1be9abab462a318"}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3,random_state=42, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "f2a2cf6a-5505-4fc5-9ce5-40e0bde64fd1", "_uuid": "3a3c8d9a7181a57ffdfa5b07a547aea334f3e211", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["print ('trainX.step.min,max,count', trainX.step.min(),trainX.step.max(),trainX.step.count())\n", "print ('testX.step.min,max,count',testX.step.min(),testX.step.max(),testX.step.count())\n", "print ('y=1 total, train, test',sum(Y),sum(trainY),sum(testY))"], "execution_count": null, "metadata": {"_cell_guid": "52e8c3e0-addd-4a07-bddf-ea8045ab9082", "_uuid": "94ef2f4724127a1b414a4da529687a99a8c03572", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "#Base metrics \n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "print ('Test')\n", "presult(clf,testX,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "b9f64d00-bca1-4b0d-97e5-04dcd393915b", "_uuid": "bc4a04435f62e2be62cbf7514ff31b66ae35cc37", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["#add DestC to drop list\n", "droplist=['isFlaggedFraud','OrigC','type','nameDest','nameOrig','DestC']"], "execution_count": null, "metadata": {"_cell_guid": "bdf7656c-e403-406a-ba94-77800e461a59", "_uuid": "795a04a1c68080cbb2dcf1bfabedfd6afcc08a67", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# Check series transaction for same client\n", "dt=data.copy()\n", "dt = dt.sort_values(['step'])\n", "print (sum(dt.groupby('nameOrig')['step'].count()>1)) #9298 \u00b10.2% \n", "# Only \u00b110 000 transaction for same client. Impossible create client profile features :-( \n", "#=> We can drop Trans type WO Fraud case\n", "\n", "\n"], "execution_count": null, "metadata": {"_cell_guid": "e62ee885-01d8-47c9-8a48-18748e28f1c9", "_uuid": "b39506091d95510854eb3b5a8faf4d5605681fc7", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["# drop Trans type WO Fraud\n", "MLData=data.copy()\n", "#only TRANSFER and CASH_OUT\n", "MLData=MLData.loc[(MLData.TRANSFER+MLData.CASH_OUT)>0]\n", "MLData.drop(droplist,axis=1,inplace=True)\n", "#add CASH_OUT to drop list\n", "MLData=MLData.drop(['CASH_OUT'],axis=1)\n", "X=MLData.drop('isFraud',axis=1)\n", "Y=MLData.isFraud\n", "trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "230c35e1-5605-4d04-8d66-629dd9ca858f", "_uuid": "debf719454edb7151d42fc1721600afaa1aa23b1", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics only for CASH OUT and transfer in train\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "presult(clf,testX,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "00a52ef0-a7da-4b8b-9ffb-945468e54ff1", "_uuid": "7f4edabf0edc1b165b6eebc69ea92feddeb6df80", "collapsed": false}}, {"cell_type": "markdown", "source": ["DestAmntErr - drop candidate"], "metadata": {"_cell_guid": "8b570b28-a854-4921-b26a-103628384869", "_uuid": "6e2c140bed916406fc81166403cc4118caa28310", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["# modify step to hours in day. \n", "X['step24']=X.step%24"], "execution_count": null, "metadata": {"_cell_guid": "fc273d34-67bd-456e-91d0-9f5012eaae67", "_uuid": "075032dd88a8efbd8cc7e4dc8d6b2c0c831b6800", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["X.step24.describe()"], "execution_count": null, "metadata": {"_cell_guid": "092856e3-bdd9-4dbf-af63-52ec72db4887", "_uuid": "fd182cef69a9d6d5037e60ed6538b6f781a9242b", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "4d830a1f-d469-47c5-a2f7-3fcc7206cfd3", "_uuid": "470073a6aa43e02784cd49e43a8470d5d75dc4bd", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics step in hour(s)\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "presult(clf,testX,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "32e376d8-00f9-4798-a2d6-439b2ccb0954", "_uuid": "b1e8729d055a50ba0180f784da0bf16ce8b4eb43", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["#  drop DestAmntErr and update newBalanceDest\n", "X.loc[(X.DestAmntErr != 0) & (X.newBalanceDest == 0),'newBalanceDest'] = -1\n", "X=X.drop('DestAmntErr',axis=1)\n", "MLData.loc[(MLData.DestAmntErr != 0) & (MLData.newBalanceDest == 0),'newBalanceDest'] = -1\n", "MLData=MLData.drop('DestAmntErr',axis=1)"], "execution_count": null, "metadata": {"_cell_guid": "ea73af23-5457-4530-b018-dccce3f0d4ad", "_uuid": "50eeffbe865b1814e180c58832f277a8639094b7", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["X.newBalanceDest.describe()"], "execution_count": null, "metadata": {"_cell_guid": "395360c8-2e4f-4ae5-9eda-7f33b0bb3bb6", "_uuid": "3fc217699688913f474eeb7fbe6e4b9fea5a5662", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "b444b47b-f6f6-4a50-8b68-047ee6bfe0d0", "_uuid": "323ca679fd2592f03ed04df355246c08fd8465cf", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics step in hour(s)\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "presult(clf,testX,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "f721f6a9-8686-4fdd-9b61-15aadbe17f8d", "_uuid": "3c16df99a2faa77892ad4b8371cc4f589875e8c2", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "#LGBMClassifier\n", "# metrics for 0.3 test size\n", "clf = lgb.LGBMClassifier(n_estimators=100,max_depth=3, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "presult(clf,testX,testY,0)"], "execution_count": null, "metadata": {"collapsed": false}}, {"cell_type": "markdown", "source": ["It perfect but makes impossible improve the ML model \n", "\n", "Try 0.5 test size"], "metadata": {"_cell_guid": "3844a143-26a1-42cc-9e9c-397334e2d180", "_uuid": "36885999f46bb11c8c5e6dabcb70cdfc0410ad35", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.5, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "99257db6-cb3e-4631-bef0-3ef44a2122c2", "_uuid": "00bf051351b4d730dcc85c596a9920e81b03eca3", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics for 0.5 test size\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX, trainY)\n", "presult(clf,testX,testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "ad18f2a8-c081-44a4-bca0-172717c85b2e", "_uuid": "759c578efd0156c57a716e24f84e748246d91cea", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["#ok try next step"], "execution_count": null, "metadata": {"_cell_guid": "d8b98220-28e1-4f58-9ea0-289e53ba4458", "_uuid": "e5aece3777eb5c435c236c30c8b7f2468edc35de", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["#in first scale data. Theory - result do not change for random forest (XGB)"], "execution_count": null, "metadata": {"_cell_guid": "aea9a88c-8ea4-468b-aee0-b6afc3488589", "_uuid": "15d955362a145e708a2cb96934077829f6bf963a", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "scaler = StandardScaler()\n", "scaler.fit(trainX)\n", "# metrics for 0.5 test size\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(scaler.transform(trainX), trainY)\n", "presult(clf,scaler.transform(testX),testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "873c9768-715a-44ac-9d5c-58a60117b247", "_uuid": "5ae815049fb2c5e04d052ed91965092e55d7826b", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "#LGBMClassifier\n", "scaler = StandardScaler()\n", "scaler.fit(trainX)\n", "# metrics for 0.3 test size\n", "clf = lgb.LGBMClassifier(n_estimators=100,max_depth=3, n_jobs = 4, random_state=42)\n", "clf.fit(scaler.transform(trainX), trainY)\n", "presult(clf,scaler.transform(testX),testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "abd8d78a-c5a5-4b8f-9f59-1cee820dfdd9", "_uuid": "5daff8abf49f125d496727da75f49bfb91cfb8e3", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["# in practice we give best result for same time"], "execution_count": null, "metadata": {"_cell_guid": "448aed3d-000f-4097-82b6-97862701248f", "_uuid": "9a37fd06c21a2185530ef28f2e1cb9473274f483", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["# nex step - add synt feature  "], "execution_count": null, "metadata": {"_cell_guid": "b84282ce-d4f5-437c-bdaf-0c8c937dbf14", "_uuid": "f6b41f4ed2e219cef50d370f5b5ee3727decae69", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["MLData.corr().isFraud"], "execution_count": null, "metadata": {"_cell_guid": "d978819c-83a5-4b93-b7fe-c19e94816fa7", "_uuid": "3a5194d73360b1d2d164e46001dc326293081fc4", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["Ldrop=['oldBalanceDest','newBalanceDest']"], "execution_count": null, "metadata": {"_cell_guid": "2995bb8b-68cb-44db-8746-743949a9c99a", "_uuid": "282b099d813dda5e37ff53862f905bf5227866e1", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["#try add linear probalitics to feature\n", "scaler = StandardScaler()\n", "scaler.fit(X.drop(Ldrop,axis=1))\n", "lr = LogisticRegression(class_weight='balanced', C=0.5, random_state=33)\n", "lr.fit(scaler.transform(trainX.drop(Ldrop,axis=1)),trainY)\n", "trainX1=pd.DataFrame(scaler.transform(trainX.drop(Ldrop,axis=1)))\n", "trainX1['lsynt']=lr.predict_log_proba(trainX1).T[1].reshape(-1,1)\n", "testX1=pd.DataFrame(scaler.transform(testX.drop(Ldrop,axis=1)))\n", "testX1['lsynt']=lr.predict_log_proba(testX1).T[1].reshape(-1,1)\n", "y_pred=lr.predict(scaler.transform(testX.drop(Ldrop,axis=1)))\n", "print  ('Confusion_matrix : ')\n", "print (confusion_matrix(testY,y_pred))"], "execution_count": null, "metadata": {"_cell_guid": "260983fd-3175-401b-92d2-784dc539ff32", "scrolled": true, "_uuid": "35f11f87cb9cf8d60edf77c01ffa2d6e777e71b9", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics for lsynt feature and  0.5 test size\n", "# Data already scaled\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX1, trainY)\n", "presult(clf,testX1,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "35942a0f-4beb-4e77-bb9f-40f9cf0677fa", "_uuid": "c59b7a560e80953db87616c8474259816f58d991", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "#LGBMClassifier\n", "# metrics for 0.3 test size\n", "clf = lgb.LGBMClassifier(n_estimators=100,max_depth=3, n_jobs = 4, random_state=42)\n", "clf.fit(trainX1, trainY)\n", "presult(clf,testX1,testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "f914967e-16ec-4f2e-92b6-f256492a94bb", "_uuid": "fc0da593c98b6f21b494bae815221793f112db7b", "collapsed": false}}, {"cell_type": "markdown", "source": ["Best result for XGB, but not for LGB. Try for 0.3 "], "metadata": {"_cell_guid": "73e8aea5-0dc0-493f-933c-c6721ebe2ead", "_uuid": "2ea78f3059f34706cf3ff8f53cf564aee587eac7", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["trainX, testX, trainY, testY = train_test_split(X, Y, test_size = 0.3, shuffle=False)"], "execution_count": null, "metadata": {"_cell_guid": "66b5ccb8-4432-4c82-8e57-8307487ccea2", "_uuid": "5f86d66a282dd9fad24c6533aca63cb5f1f97542", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["#try add linear probalitics to feature\n", "scaler = StandardScaler()\n", "scaler.fit(X.drop(Ldrop,axis=1))\n", "lr = LogisticRegression(class_weight='balanced', C=0.5, random_state=33)\n", "lr.fit(scaler.transform(trainX.drop(Ldrop,axis=1)),trainY)\n", "trainX1=pd.DataFrame(scaler.transform(trainX.drop(Ldrop,axis=1)))\n", "trainX1['lsynt']=lr.predict_log_proba(trainX1).T[1].reshape(-1,1)\n", "testX1=pd.DataFrame(scaler.transform(testX.drop(Ldrop,axis=1)))\n", "testX1['lsynt']=lr.predict_log_proba(testX1).T[1].reshape(-1,1)\n", "y_pred=lr.predict(scaler.transform(testX.drop(Ldrop,axis=1)))\n", "print  ('Confusion_matrix : ')\n", "print (confusion_matrix(testY,y_pred))"], "execution_count": null, "metadata": {"_cell_guid": "267c54ea-7710-4984-be25-4daebe4ec0b3", "_uuid": "389bab569cf4530936d01f6a9e6b562801577c92", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "# metrics for lsynt feature and  0.3 test size\n", "# Data already scaled\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(trainX1, trainY)\n", "presult(clf,testX1,testY,1)"], "execution_count": null, "metadata": {"_cell_guid": "2207c830-d2d4-4743-b891-ef1c0514b182", "_uuid": "86a31fb22a56d60db226d07409780a7d3e0a64a8", "collapsed": false}}, {"outputs": [], "cell_type": "code", "source": ["# not so good. Try only Scaler"], "execution_count": null, "metadata": {"_cell_guid": "620ba143-3896-4c64-8a57-b09b5fa3cbed", "_uuid": "081eb0b984156d15c42d36433743aca97b192631", "collapsed": true}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "scaler = StandardScaler()\n", "scaler.fit(trainX)\n", "# metrics for 0.3 test size\n", "weights = (Y == 0).sum() / (1.0 * (Y == 1).sum())\n", "clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n", "clf.fit(scaler.transform(trainX), trainY)\n", "presult(clf,scaler.transform(testX),testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "2041c008-04db-4b90-95c2-0aebf917d748", "_uuid": "4e4a4bae0bfd8bfef95f595a9eb42bccb8f0efe8", "collapsed": false}}, {"cell_type": "markdown", "source": ["#### IF FN (Fraud) cost >= FP cost * 10  we win , else we loose "], "metadata": {"_cell_guid": "0567c621-848e-4dbc-a9bc-32fff3309963", "_uuid": "2506e41c2222d2a91a478c9f8d30d9db039b81cf"}}, {"outputs": [], "cell_type": "code", "source": ["%%time\n", "#LGBMClassifier\n", "scaler = StandardScaler()\n", "scaler.fit(trainX)\n", "# metrics for 0.3 test size\n", "clf = lgb.LGBMClassifier(n_estimators=100,max_depth=3, n_jobs = 4, random_state=42)\n", "clf.fit(scaler.transform(trainX), trainY)\n", "presult(clf,scaler.transform(testX),testY,0)"], "execution_count": null, "metadata": {"_cell_guid": "c7e41135-9061-44c1-bb0c-fa4f95cad6e1", "_uuid": "8a53e326bd39e322399fb5d4181460084136099b", "collapsed": false}}, {"cell_type": "markdown", "source": ["## Conclusion"], "metadata": {"_cell_guid": "31e9c950-066c-44bf-9173-2d812d251235", "_uuid": "b1e1197741f3ecaa1473caae1bf6b67f93a8c7f8"}}, {"cell_type": "markdown", "source": ["\n", "1. I think it's not the right decision to use the mixed sample in time series data. We guess the past based on the knowledge of the future.\n", "2. You should always look at Confusion_matrix in classification problems. Especially in problems of binary classification. My leading synthetic metric for an unbalanced sample is f1-macro\n", "3. For problems of fraud analysis, it is desirable to know the cost of False Positive and False Negative. For example, FP = 1USD and FN = 10USD. This will allow more accurate estimate if the FP and FN are significant\n", "4. I think that the OrigAmntErr, which allows for so precise identification of fraud, is an error of the genius algorithm and will be corrected in the next iterations. The real problems of search for fraud have significantly more noisy data with a worse quality solution\n", "5. Detecting fraud detection is not normal behavior. Normality can be determined on a general background (the amount is more than), but this will probably not be enough. We need a customer profile. For client profile, you need the event geography by the connection's IP address or the city of the transaction execution by the client. You need to connect to the network even without an operation. In the current dataset, unfortunately, the client profile does not have the ability to allocate. There is also no possibility to determine the geography of the operation.\n", "6. LightGBM  demonstrated a higher computational speed than XGBoost with a comparable quality\n", "7. The synthetic frature  the probability of belonging to a class from a linear model does not allow improving the result when the basic characteristics give good quality\n", "\n", "#### Thanks to Edgar Alonso Lopez-Rojas for posting this dataset.\n", "#### Thanks to Arjun Joshua for killing features\n", "#### Thanks to Arjun Joshua and Net for perfect data vizualization. These perfect notebooks really help me.\n", "\n"], "metadata": {"_cell_guid": "5f1aee64-11c1-4a8f-a099-a38eb594babe", "_uuid": "bffa96fb6e0b92eb4df8753c11139ee0224f0a60"}}]}