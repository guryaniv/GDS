{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# **DATA**"},{"metadata":{"trusted":true,"_uuid":"f9b26a841901cb7f8ed913217ce43329a62ae9d7"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef read_data():\n    df = pd.read_csv(\"../input/train.csv\")\n    print (\"Shape of base training File = \", df.shape)\n    # Remove missing values and duplicates from training data\n    df.drop_duplicates(inplace=True)\n    df.dropna(inplace=True)\n    print(\"Shape of base training data after cleaning = \", df.shape)\n    return df\n\ndf = read_data()\ndf_train, df_test = train_test_split(df, test_size = 0.02)\nprint (\"\\n\\n\", df_train.head(10))\nprint (\"\\nTrain Shape : \", df_train.shape)\nprint (\"Test Shape : \", df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50feb3fd4c43521d722c9eb41ce855626bd4c500"},"cell_type":"markdown","source":"## A Liitle bit - **EDA**"},{"metadata":{"trusted":true,"_uuid":"29a91a304a49e4bdae469a8884782fc863a016e6"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef eda(data):\n    dup_check = data['is_duplicate'].value_counts()\n    plt.bar(dup_check.index, dup_check.values)\n    plt.ylabel('Number of Queries')\n    plt.xlabel('Is Duplicate')\n    plt.title('Data Distribution', fontsize = 18)\n    plt.show()\n    \n    print(\"\\nAbove Graph Features :  [Is Not Duplicate | Is Duplicate]\\n\")\n    print(\"Above Graph Indices  : \", dup_check.index)\n    print(\"\\nAbove Graph Values   : \", dup_check.values)\n\neda(df_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bc698b4958eb3a08c4d74af5ce6525baa75df6d"},"cell_type":"markdown","source":"# **Preparing Bag of Words**"},{"metadata":{"trusted":true,"_uuid":"feb9b12298006a818160ba80c314a6f0deaf17f9"},"cell_type":"code","source":"import re\nimport gensim\nfrom gensim import corpora\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b51a50eff5039116db71b101e7c1f69c55887de"},"cell_type":"code","source":"words = re.compile(r\"\\w+\",re.I)\nstopword = stopwords.words('english')\nstemmer = PorterStemmer()\n\n# Cleaning and tokenizing the queries.\ndef tokenize_questions(df):\n    question_1_tokenized = []\n    question_2_tokenized = []\n\n    for q in df.question1.tolist():\n        question_1_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) \n                                     if i not in stopword])\n\n    for q in df.question2.tolist():\n        question_2_tokenized.append([stemmer.stem(i.lower()) for i in words.findall(q) \n                                     if i not in stopword])\n\n    df[\"Question_1_tok\"] = question_1_tokenized\n    df[\"Question_2_tok\"] = question_2_tokenized\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19a6c13f2caf3504b29525a0b2a4e359c611136b"},"cell_type":"markdown","source":"### Tokenize"},{"metadata":{"trusted":true,"_uuid":"e171c2576ff1422d1e809c79cfc81be19461d453"},"cell_type":"code","source":"df_train = tokenize_questions(df_train)\ndf_test = tokenize_questions(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c88ad59bb1f6456a1335811209b612144f30621d"},"cell_type":"code","source":"df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16002ee334e71685d1bccac3f50b07a1ed7ac2d1"},"cell_type":"code","source":"df_test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"730b4247e8eaf1a7a578a5d6393f303b73a4a082"},"cell_type":"markdown","source":"### Preparing Dictionary"},{"metadata":{"trusted":true,"_uuid":"59c72cd0397a0aad9267a45393d747ee65335ee4"},"cell_type":"code","source":"def train_dictionary(df):\n    \n    questions_tokenized = df.Question_1_tok.tolist() + df.Question_2_tok.tolist()\n    \n    dictionary = corpora.Dictionary(questions_tokenized)\n    dictionary.filter_extremes(no_below=5)\n    dictionary.compactify()\n    \n    return dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9730dec6367a9087970a1ba654cb4475afd0925"},"cell_type":"code","source":"dictionary = train_dictionary(df_train)\nprint (\"No of words in the dictionary = %s\" %len(dictionary.token2id))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95437129b4b7c5c4f0b7588322704fb80aacdc3b"},"cell_type":"code","source":"print(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"475b26222c3559c6b13ef5d3cb8adcd58692fef4"},"cell_type":"markdown","source":"### Preparing vectors and BOW"},{"metadata":{"trusted":true,"_uuid":"ddc6694dc5bf2921a98fd55753f41ba1c730d848"},"cell_type":"code","source":"def get_vectors(df, dictionary):\n    \n    question1_vec = [dictionary.doc2bow(text) for text in df.Question_1_tok.tolist()]\n    question2_vec = [dictionary.doc2bow(text) for text in df.Question_2_tok.tolist()]\n    \n    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n    \n    return question1_csc.transpose(),question2_csc.transpose()\n\n\nq1_csc, q2_csc = get_vectors(df_train, dictionary)\n\nprint (q1_csc.shape)\nprint (q2_csc.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9cce1a560b9a2a686f17cf061c7fdfc17dcf745"},"cell_type":"code","source":"q1_csc_test, q2_csc_test = get_vectors(df_test, dictionary)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba2583e52649bb23bc36081f79fb076b3bd05fce"},"cell_type":"markdown","source":"# **Preparing ML Model using Similarity Measures**"},{"metadata":{"_uuid":"3e4a16e5cefb2cd6a19ddaaa74b7d02704a2fe5e"},"cell_type":"markdown","source":"### Similarity Measure"},{"metadata":{"trusted":true,"_uuid":"d2f64061b516ae80b74f356bab38747e45f3c05e"},"cell_type":"code","source":"'''\nSimilarity Measures:\n    Cosine Similarity\n    Manhattan Distance\n    Euclidean Distance\n'''\n\nfrom sklearn.metrics.pairwise import cosine_similarity as cs\nfrom sklearn.metrics.pairwise import manhattan_distances as md\nfrom sklearn.metrics.pairwise import euclidean_distances as ed\n\n\ndef get_similarity_values(q1_csc, q2_csc):\n    cosine_sim = []\n    manhattan_dis = []\n    eucledian_dis = []\n        \n    for i,j in zip(q1_csc, q2_csc):\n        sim = cs(i,j)\n        cosine_sim.append(sim[0][0])\n        sim = md(i,j)\n        manhattan_dis.append(sim[0][0])\n        sim = ed(i,j)\n        eucledian_dis.append(sim[0][0])\n        \n    return cosine_sim, manhattan_dis, eucledian_dis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4e616879856c944474f8a3fcb6843d82b929ec1"},"cell_type":"code","source":"cosine_sim, manhattan_dis, eucledian_dis = get_similarity_values(q1_csc, q2_csc)\ny_pred_cos, y_pred_man, y_pred_euc = get_similarity_values(q1_csc_test, q2_csc_test)\n\nprint (\"cosine_sim sample= \\n\", cosine_sim[0:5])\nprint (\"\\nmanhattan_dis sample = \\n\", manhattan_dis[0:5])\nprint (\"\\neucledian_dis sample = \\n\", eucledian_dis[0:5])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff950ca2148b06bf638faca80f9d5f351699d185"},"cell_type":"markdown","source":"### ML Model"},{"metadata":{"trusted":true,"_uuid":"28b17814ca38b2cebfaf6c9e3a96d8de1bfe98d5"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nxtrain = pd.DataFrame({\"cosine\" : cosine_sim, \"manhattan\" : manhattan_dis,\n                        \"eucledian\" : eucledian_dis})\nytrain = df_train.is_duplicate\n\nxtest = pd.DataFrame({\"cosine\" : y_pred_cos, \"manhattan\" : y_pred_man,\n                       \"eucledian\" : y_pred_euc})\nytest = df_test.is_duplicate\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77b14f62428e7c402de2a2f694dde9a300fb91fe"},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(xtrain, ytrain)\nrf_predicted = rf.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f4e0dc508b6c5f2c34328133cb1fb44a0503c6c"},"cell_type":"code","source":"logist = LogisticRegression(random_state=0)\nlogist.fit(xtrain, ytrain)\nlogist_predicted = logist.predict(xtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d00378a7e05ec213ae769f68538998eb736db91e"},"cell_type":"code","source":"from sklearn.metrics import log_loss\n\ndef calculate_logloss(y_true, y_pred):\n    loss_cal = log_loss(y_true, y_pred)\n    return loss_cal","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c08bd3b05d2e52c64f746be22f9ec7f3b15a99ca"},"cell_type":"markdown","source":"# Result Time"},{"metadata":{"trusted":true,"_uuid":"afb014fb68d083fef78d3a61da651a9f2479e016"},"cell_type":"code","source":"logloss_rf = calculate_logloss(ytest, rf_predicted)\nlog_loss_logist = calculate_logloss(ytest, logist_predicted)\nprint (\"Log loss value using Random Forest is = %f\" %logloss_rf)\nprint (\"Log loss value using Logistic Regression is = %f\" %log_loss_logist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f553d1e7772af575e9daf986f665bfd14e468656"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntest_acc_rf = accuracy_score(ytest, rf_predicted) * 100\ntest_acc_logist = accuracy_score(ytest, logist_predicted) * 100\nprint (\"Accuracy of Random Forest Model : \", test_acc_rf)\nprint (\"Accuracy of Logistic Regression Model : \", test_acc_logist)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}