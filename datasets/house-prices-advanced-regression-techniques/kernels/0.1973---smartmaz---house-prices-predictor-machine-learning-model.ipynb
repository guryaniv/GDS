{"cells":[{"metadata":{"_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86","_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nI will build and continually improve a model to predict housing prices as you work through each tutorial.  "},{"metadata":{"_uuid":"1c728098629e1301643443b1341556a15c089b2b","_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","trusted":true},"cell_type":"code","source":"import pandas as pd\n\n# save filepath to variable for easier access\nmain_file_path = '../input/train.csv'\n# read the data and store data in DataFrame titled train\ntrain = pd.read_csv(main_file_path)\n# print a summary of the data\nprint(train.describe())","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"7affcceb174235c811094e5f704d85cd114d50b7","_cell_guid":"109bb61b-e0a9-435b-929a-ee42ed2433c7"},"cell_type":"markdown","source":"**Selecting a Single Column**\nI can pull out any variable (or column) with dot-notation. This single column is stored in a Series, which is broadly like a DataFrame with only a single column of data. Here's an example:"},{"metadata":{"_uuid":"340e4e80cbb08b67fb8cc1a65be5c05de8ce0203","_cell_guid":"2b17c234-6264-4d1c-8948-e990d53e456c","trusted":true},"cell_type":"code","source":"# store the series of prices separately as melbourne_price_data.\nhouse_price_data = train.SalePrice\n# the head command returns the top few lines of data.\nprint(house_price_data.head())","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"514f8e20b8471d835e7db96ff438812d5fef1586","_cell_guid":"db9bbe85-a1fa-49a2-8bbd-a2093c33ce1d"},"cell_type":"markdown","source":"**Selecting Multiple Columns**\nYou can select multiple columns from a DataFrame by providing a list of column names inside brackets. Remember, each item in that list should be a string (with quotes)."},{"metadata":{"_uuid":"cd40ce04c78f870069ecbb8ff51136c5c9cbfa2a","_cell_guid":"0ce86242-f652-413e-ad9b-e9d018d3c5ba","trusted":false,"collapsed":true},"cell_type":"code","source":"columns_of_interest = ['LotArea', 'MiscVal']\ntwo_columns_of_data = train[columns_of_interest]\ntwo_columns_of_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0bcd9faf2e477e1e747788956bc2bd90c3e464ea","_cell_guid":"f288cf58-2cb0-4fe8-93e8-e2e210317ea0"},"cell_type":"markdown","source":"**Choosing the Prediction Target**\nYou have the code to load your data, and you know how to index it. You are ready to choose which column you want to predict. This column is called the prediction target. There is a convention that the prediction target is referred to as y. Here is an example doing that with the example data."},{"metadata":{"collapsed":true,"_uuid":"15d31ae9a7e64da97da912fc722efc9ad60d1af5","_cell_guid":"7c8e3884-03b9-4927-a757-65d0b71e205d","trusted":true},"cell_type":"code","source":"y = train.SalePrice","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"14a36cbff445f70c618b921e09ce5b238b9a92e5","_cell_guid":"134edcf4-ae03-4dab-b4ac-73ff76f97afb"},"cell_type":"markdown","source":"**Choosing Predictors**\nNext we select the predictors. Sometimes, you will want to use all of the variables except the target..\n\nIt's possible to model with non-numeric variables, but we'll start with a narrower set of numeric variables. In the example data, the predictors will be chosen as:"},{"metadata":{"collapsed":true,"_uuid":"40a957279fe8eb221e3d437dd253ce75d1daa6ba","_cell_guid":"4013cee1-0e8f-4b42-a466-5a3409756fe3","trusted":true},"cell_type":"code","source":"train_predictors = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\nX = train[train_predictors]","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"511001c66d985844fe8621ae5e347e8da7c6e71b","_cell_guid":"d7c8e24b-2579-47db-93a0-d8ac1279afff"},"cell_type":"markdown","source":"**Building Your Model**\nYou will use the scikit-learn library to create your models. When coding, this library is written as sklearn, as you will see in the sample code. Scikit-learn is easily the most popular library for modeling the types of data typically stored in DataFrames.\n\nThe steps to building and using a model are:\n\nDefine: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\nFit: Capture patterns from provided data. This is the heart of modeling.\nPredict: Just what it sounds like\nEvaluate: Determine how accurate the model's predictions are.\nHere is the example for defining and fitting the model."},{"metadata":{"_uuid":"538bd06b198a21326087777c6f7cc39d8881b3dc","_cell_guid":"342ec30f-861e-4de3-81a3-cb5e2a5ff096","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n# Define model\ntrain_model = DecisionTreeRegressor()\n\n# Fit model\ntrain_model.fit(X, y)\n\nprint(\"Making predictions for the following 5 houses:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(train_model.predict(X.head()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b837ffb87b7e9006f41105b5c504b2b2d6e8934","_cell_guid":"6d92c14c-53ad-4c48-a475-d644bf3dab1f"},"cell_type":"markdown","source":"The calculation of mean absolute error in the train data is"},{"metadata":{"_uuid":"a0bab9e79d59a8694f7841b9294dbae26978ae74","_cell_guid":"3dcc5266-1e22-4036-9d2a-4c839eff76df","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\npredicted_home_prices = train_model.predict(X)\nmean_absolute_error(y, predicted_home_prices)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbbe91cd48d48188b3185a4582b3844fb0e25a8d","_cell_guid":"06e20b77-e9a9-4380-944d-3712d61516c9"},"cell_type":"markdown","source":"The scikit-learn library has a function train_test_split to break up the data into two pieces, so the code to get a validation score looks like this:"},{"metadata":{"_uuid":"61af3283dfb0ce0e90619a464b8244fc347d3bf9","_cell_guid":"d86b74df-67c0-4eb3-8dfa-ae73fa380b63","trusted":false,"collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n# Define model\ntrain_model = DecisionTreeRegressor()\n# Fit model\ntrain_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = train_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c1336027ea617e6e93d1e02295f33af8acef549","_cell_guid":"795827ec-91e4-4522-a67f-fc29495cfca2"},"cell_type":"markdown","source":"There are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes. But the max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area.\n\nWe can use a utility function to help compare MAE scores from different values for max_leaf_nodes:"},{"metadata":{"collapsed":true,"_uuid":"6bb4bf674e2cdb07c1fb8f1c57727b66b96df014","_cell_guid":"c710ffb2-c80e-4267-b4b4-ba0707128b0c","trusted":false},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39c09a0f34536c7652477d5cf976239f9083f592","_cell_guid":"00edf971-1d6a-4276-b204-ff80c2f70c0d"},"cell_type":"markdown","source":"The data is loaded into train_X, val_X, train_y and val_y using the code you've already seen (and which you've already written).\n\nWe can use a for-loop to compare the accuracy of models built with different values for max_leaf_nodes."},{"metadata":{"_uuid":"34d42bda04cf15d44c123a6110ff5f297ceed996","_cell_guid":"75ba340a-12d2-490a-bf0a-b037533bdcfb","trusted":false,"collapsed":true},"cell_type":"code","source":"# compare MAE with differing values of max_leaf_nodes\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9338a3018f56fd3fba0b00d0384fa9ca77dc2765","_cell_guid":"13c6af0a-ed0d-4147-ae16-f8eb15bd1354"},"cell_type":"markdown","source":"Decision trees leave you with a difficult decision. A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.\n\nEven today's most sophisticated modeling techniques face this tension between underfitting and overfitting. But, many models have clever ideas that can lead to better performance. We'll look at the random forest as an example.\n\nThe random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters.\n\nWe build a RandomForest similarly to how we built a decision tree in scikit-learn."},{"metadata":{"_uuid":"fbcc791a28c2cc61ba933271858313da68f68c32","_cell_guid":"c6924eee-5dee-4e86-b86a-23a416e433d3","trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)\nmelb_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, melb_preds))","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"6682bad4e042fc4061e3b65db13526add9e2280d"},"cell_type":"markdown","source":"We're doing very minimal data set up here so we can focus on how to submit modeling results to competitions. Other tutorials will teach you how build great models. So the model in this example will be fairly simple. We'll start with the code to read data, select predictors, and fit a model."},{"metadata":{"trusted":true,"_uuid":"461aadae03cd1c42ffbdc5b988c48538470c4668"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Read the data\ntrain = pd.read_csv('../input/train.csv')\n\n# pull data into target (y) and predictors (X)\ntrain_y = train.SalePrice\npredictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n\n# Create training predictors data\ntrain_X = train[predictor_cols]\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"fac094ef6da75342c0d9aa301ad455a1607895e6","_cell_guid":"dcb4da62-f31c-49fe-8dd6-b171d9b9ca9d"},"cell_type":"markdown","source":"In addition to your training data, there will be test data. This is frequently stored in a file with the title test.csv. This data won't include a column with your target (y), because that is what we'll have to predict and submit. Here is sample code to do that."},{"metadata":{"_uuid":"742a7a8c3dad6779adf4d5b1478f8b65b9e3e3d5","_cell_guid":"53c43a75-ab2e-4a73-8e74-7920f572b9b7","trusted":true},"cell_type":"code","source":"# Read the test data\ntest = pd.read_csv('../input/test.csv')\n# Treat the test data in the same way as training data. In this case, pull same columns.\ntest_X = test[train_predictors]\n# Use the model to make predictions\npredicted_prices = forest_model.predict(test_X)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"3c629cc0f4dda401210843d0e160ce22e975d236","_cell_guid":"00de7691-1b28-44dd-8b53-aa4dba45b929"},"cell_type":"markdown","source":"Prepare Submission File We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the housing data is the string 'Id'). The prediction column will use the name of the target field.\n\nWe will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."},{"metadata":{"collapsed":true,"_uuid":"8c83bc4aef72f5919d103e9d6877ed32da606f3f","_cell_guid":"40b35b41-380f-4979-b4a4-6efcaa2b011f","trusted":true},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":18,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}