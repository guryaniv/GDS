{"cells":[{"metadata":{"_uuid":"7f65d1be836f1d7b45ba6376592fe89ac041e118"},"cell_type":"markdown","source":"Checking FastAI"},{"metadata":{"trusted":true,"_uuid":"d828756c025a611ca9bb11bfe81673a41b62f3a1"},"cell_type":"code","source":"from __future__ import print_function, division\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\ntry:\n    from itertools import  ifilterfalse\nexcept ImportError: # py3k\n    from itertools import  filterfalse\n\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = gt_sorted.sum()\n    intersection = gts - gt_sorted.float().cumsum(0)\n    union = gts + (1 - gt_sorted).float().cumsum(0)\n    jaccard = 1. - intersection / union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\n\ndef iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n    \"\"\"\n    IoU for foreground class\n    binary: 1 foreground, 0 background\n    \"\"\"\n    if not per_image:\n        preds, labels = (preds,), (labels,)\n    ious = []\n    for pred, label in zip(preds, labels):\n        intersection = ((label == 1) & (pred == 1)).sum()\n        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n        if not union:\n            iou = EMPTY\n        else:\n            iou = float(intersection) / union\n        ious.append(iou)\n    iou = mean(ious)    # mean accross images if per_image\n    return 100 * iou\n\n\ndef iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n    \"\"\"\n    Array of IoU for each (non ignored) class\n    \"\"\"\n    if not per_image:\n        preds, labels = (preds,), (labels,)\n    ious = []\n    for pred, label in zip(preds, labels):\n        iou = []    \n        for i in range(C):\n            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n                intersection = ((label == i) & (pred == i)).sum()\n                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n                if not union:\n                    iou.append(EMPTY)\n                else:\n                    iou.append(float(intersection) / union)\n        ious.append(iou)\n    ious = map(mean, zip(*ious)) # mean accross images if per_image\n    return 100 * np.array(ious)\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2. * labels.float() - 1.\n    errors = (1. - logits * Variable(signs))\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.elu(errors_sorted) +1, Variable(grad))\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\n\nclass StableBCELoss(torch.nn.modules.Module):\n    def __init__(self):\n         super(StableBCELoss, self).__init__()\n    def forward(self, input, target):\n         neg_abs = - input.abs()\n         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n         return loss.mean()\n\n\ndef binary_xloss(logits, labels, ignore=None):\n    \"\"\"\n    Binary Cross entropy loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      ignore: void class id\n    \"\"\"\n    logits, labels = flatten_binary_scores(logits, labels, ignore)\n    loss = StableBCELoss()(logits, Variable(labels.float()))\n    return loss\n\n\n# --------------------------- MULTICLASS LOSSES ---------------------------\n\n\ndef lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n      only_present: average only on classes present in ground truth\n      per_image: compute the loss per image instead of per batch\n      ignore: void class labels\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n                          for prob, lab in zip(probas, labels))\n    else:\n        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n    return loss\n\n\ndef lovasz_softmax_flat(probas, labels, only_present=False):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n      only_present: average only on classes present in ground truth\n    \"\"\"\n    C = probas.size(1)\n    losses = []\n    for c in range(C):\n        fg = (labels == c).float() # foreground for class c\n        if only_present and fg.sum() == 0:\n            continue\n        errors = (Variable(fg) - probas[:, c]).abs()\n        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n        perm = perm.data\n        fg_sorted = fg[perm]\n        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n    return mean(losses)\n\n\ndef flatten_probas(probas, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch\n    \"\"\"\n    B, C, H, W = probas.size()\n    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n    labels = labels.view(-1)\n    if ignore is None:\n        return probas, labels\n    valid = (labels != ignore)\n    vprobas = probas[valid.nonzero().squeeze()]\n    vlabels = labels[valid]\n    return vprobas, vlabels\n\ndef xloss(logits, labels, ignore=None):\n    \"\"\"\n    Cross entropy loss\n    \"\"\"\n    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n\n\n# --------------------------- HELPER FUNCTIONS ---------------------------\n\ndef mean(l, ignore_nan=False, empty=0):\n    \"\"\"\n    nanmean compatible with generators.\n    \"\"\"\n    l = iter(l)\n    if ignore_nan:\n        l = ifilterfalse(np.isnan, l)\n    try:\n        n = 1\n        acc = next(l)\n    except StopIteration:\n        if empty == 'raise':\n            raise ValueError('Empty mean')\n        return empty\n    for n, v in enumerate(l, 2):\n        acc += v\n    if n == 1:\n        return acc\n    return acc / n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from fastai.conv_learner import *\nfrom fastai.dataset import *\nimport matplotlib.pyplot as plt\nfrom concurrent.futures import ThreadPoolExecutor\nfrom PIL import Image\nimport os\n\nfrom pathlib import Path\nimport json\ntorch.cuda.set_device(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6e82a2e0941998d2847472970fb7132c51f2f927"},"cell_type":"code","source":"MASKS_FN = 'train.csv'\nTRAIN_DN = Path('train/images/')\nMASKS_DN = Path('train/masks/')\nTEST = Path('test/images/')\n\nPATH = Path('/kaggle/input/tgs-salt-identification-challenge/')\nPATH128 = Path('/tmp/128/')\nTMP = Path('/tmp/')\nMODEL = Path('/tmp/model/')\nPRETRAINED = Path('/kaggle/input/fork-of-is-there-salt-resnet34/model/resnet34_issalt.h5')\nseg = pd.read_csv(PATH/MASKS_FN).set_index('id')\nseg.head()\n\nsz = 128\nbs = 64\nnw = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6824f72889f33be34225e34e5fde611aa83581d3"},"cell_type":"code","source":"ls /kaggle/input/is-there-salt-resnet34/models/res","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2efaff04aee64496476bc08d9b789f9b6adcebc5"},"cell_type":"code","source":"train_names_png = [TRAIN_DN/f for f in os.listdir(PATH/TRAIN_DN)]\ntrain_names = list(seg.index.values)\nmasks_names_png = [MASKS_DN/f for f in os.listdir(PATH/MASKS_DN)]\ntest_names_png = [TEST/f for f in os.listdir(PATH/TEST)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11ef51b9f2cffb829b0ca536a4888c29fd91a2c2"},"cell_type":"code","source":"train_names_png[0], masks_names_png[0], test_names_png[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfab303c8731a742e89943fbd437a2eb236da718"},"cell_type":"code","source":"TMP.mkdir(exist_ok=True)\nPATH128.mkdir(exist_ok=True)\n(PATH128/'train').mkdir(exist_ok=True)\n(PATH128/'test').mkdir(exist_ok=True)\n(PATH128/MASKS_DN).mkdir(exist_ok=True)\n(PATH128/TRAIN_DN).mkdir(exist_ok=True)\n(PATH128/TEST).mkdir(exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f30b170531378aabaac3f287de91c183bc9aa6f6"},"cell_type":"code","source":"def resize_mask(fn, sz=128):\n    Image.open(PATH/fn).resize((sz,sz)).save(PATH128/fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96df55671ab50b185a0aa5d88d63f5df59af7eeb"},"cell_type":"code","source":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, train_names_png)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6b91f5fad57138c184ce8729cee1aa106ab6fde"},"cell_type":"code","source":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, masks_names_png)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca17761c5ce64ab86f3aec5fd1602c56e0a03a1b"},"cell_type":"code","source":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, test_names_png)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02549724eba9bfd9158615ec506aa76ee277b5de"},"cell_type":"code","source":"def show_img(im, figsize=None, ax=None, alpha=None):\n    if not ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im, alpha=alpha)\n    ax.set_axis_off()\n    return ax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"759e613ac5fe48b2a58ca6c6666d37fca451e13e"},"cell_type":"code","source":"show_img(open_image(str(PATH128/train_names_png[0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9595ec1ad84464a91f0f9b4dc6bfbd037d3fd007"},"cell_type":"code","source":"class CustomDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n        \n    def get_x(self, i): \n        return open_image(os.path.join(self.path,self.fnames[i]))\n    def get_y(self, i): \n        return open_image(os.path.join(self.path,self.y[i]))\n    def get_c(self): return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caea8da0830a0381725b5e97dd47b884bcd92584"},"cell_type":"code","source":"class TestFilesDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        self.th = 1\n        super().__init__(fnames, transform, path)        \n    def get_x(self, i): \n        return np.fliplr(open_image(os.path.join(self.path, self.fnames[i])))\n    def get_y(self, i): \n        return np.fliplr(open_image(os.path.join(self.path,self.y[i])))\n    def get_c(self): return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f768c2898bdfd40e3a53afc651637bb44a85b6f0"},"cell_type":"code","source":"def IoU_np(pred, targs, thres=0):\n    pred = (pred>thres)\n    intersection = (pred*targs).sum()\n    return intersection / ((pred+targs).sum() - intersection + 1.0)\n\ndef IoU(pred, targs, thres=0):\n    pred = (pred>thres).float()\n    intersection = (pred*targs).sum()\n    return intersection / ((pred+targs).sum() - intersection + 1.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5486a9a3ea3da3d9f7cd143379e018c873f4426"},"cell_type":"code","source":"def get_base(f, cut):\n    layers = cut_model(f(True), cut)\n    return nn.Sequential(*layers)\n\ndef load_pretrained(model, path):\n    weights = torch.load(PRETRAINED, map_location=lambda storage, loc: storage)\n    model.load_state_dict(weights, strict=False)\n            \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b98307f5de2097fcc65f35d8c5e8efd8639db75"},"cell_type":"code","source":"class SaveFeatures():\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2497917b98bf5f12f634c2967f1e522084a47865"},"cell_type":"code","source":"class UnetBlock(nn.Module):\n    def __init__(self, up_in, x_in, n_out):\n        super().__init__()\n        up_out = x_out = n_out//2\n        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n        self.bn = nn.BatchNorm2d(n_out)\n        \n    def forward(self, up_p, x_p):\n        up_p = self.tr_conv(up_p)\n        x_p = self.x_conv(x_p)\n        cat_p = torch.cat([up_p,x_p], dim=1)\n        return self.bn(F.relu(cat_p))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dc14f581071d422e4507e4bddf2a71bd07a15ec"},"cell_type":"code","source":"class Unet34(nn.Module):\n    def __init__(self, rn):\n        super().__init__()\n        self.rn = rn\n        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n        self.up1 = UnetBlock(512,256,256)\n        self.up2 = UnetBlock(256,128,256)\n        self.up3 = UnetBlock(256,64,256)\n        self.up4 = UnetBlock(256,64,256)\n#         self.conv1 = nn.Conv2d(512, 256, kernel_size=3, bias=False, stride=1, padding=1)\n#         self.bn1 = nn.BatchNorm2d(256)\n#         self.conv2 = nn.Conv2d(256, 512, kernel_size=1, bias=False, stride=1, padding=0)\n#         self.bn2 = nn.BatchNorm2d(512)\n        self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n                             nn.Conv2d(512,256,1),\n                             nn.ReLU(inplace=True),\n                             nn.Conv2d(256, 512,1),\n                             nn.Sigmoid()\n                               )\n        self.sSE = nn.Sequential(nn.Conv2d(512,512,1),\n                             nn.Sigmoid())\n        \n        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n        \n    def forward(self,x):\n        x = F.dropout(F.relu(self.rn(x)),0.3)\n        x = torch.addcmul(x * self.cSE(x), 1, x, self.sSE(x))\n\n#         x = F.leaky_relu(self.bn2(self.conv2(x)))\n        \n        x1 = self.up1(x, self.sfs[3].features)\n        x2 = self.up2(x1, self.sfs[2].features)\n        x = self.up3(x2, self.sfs[1].features)\n        x = self.up4(x, self.sfs[0].features)\n        x = self.up5(x)\n        x = torch.cat((x,\n                       F.interpolate((x2),scale_factor=8,mode='bilinear',align_corners=True),\n                       F.interpolate((x1),scale_factor=16,mode='bilinear', align_corners=True)\n                      ),1)\n        return F.dropout(x[:,0],0.3)\n    \n    def close(self):\n        for sf in self.sfs: sf.remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5be5af896119b1a37822a2cb726172ee68750343"},"cell_type":"code","source":"class UnetModel():\n    def __init__(self,model,name='unet'):\n        self.model,self.name = model,name\n\n    def get_layer_groups(self, precompute):\n        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n        return lgs + [children(self.model)[1:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9e0836898390d2491865647e3cac1d5d3379bfc"},"cell_type":"code","source":"x_names = [f'{x}.png' for x in train_names]\nx_names_path = np.array([str(TRAIN_DN/x) for x in x_names])\ny_names = [x for x in x_names]\ny_names_path = np.array([str(MASKS_DN/x) for x in x_names])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"202db080324939ec9864033147c153d4b6a6962d"},"cell_type":"code","source":"class RandomRotate2(CoordTransform):\n    \"\"\" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    \"\"\"\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode = self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57bb76bbbc816c878398ed1fed490802d697b5f2"},"cell_type":"code","source":"aug_tfms = [RandomRotate2(4, tfm_y=TfmType.CLASS),\n            RandomFlip(tfm_y=TfmType.CLASS),\n            RandomStretch(0.2,tfm_y=TfmType.CLASS),\n            RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]\ntfms = tfms_from_model(resnet34, sz=sz, pad=0, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n\ndef get_data(val_idxs):\n    ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names_path, y_names_path)\n    datasets = ImageData.get_ds(CustomDataset, (trn_x,trn_y), (val_x,val_y), tfms, (test_x, test_x), path=PATH128)\n    return ImageData(PATH128, datasets, bs=32, num_workers=nw, classes=None)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0e9d2bf7e9765c0c1c7f72e63b065c3e16a7744"},"cell_type":"code","source":"f = resnet34\ncut,lr_cut = model_meta[f]\n\ndef get_learner(md):\n    m_base = load_pretrained(get_base(f, cut),PRETRAINED)\n    m = to_gpu(Unet34(m_base))\n    models = UnetModel(m)\n    learn = ConvLearner(md, models, tmp_name=TMP, models_name=MODEL)\n    learn.opt_fn=optim.Adam\n    learn.crit = nn.BCEWithLogitsLoss()\n    learn.metrics=[accuracy_thresh(0.5), IoU]\n    learn.clip = 0.25\n    return learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc03c1362c5a67ca85aa2f414d55543b06ea659"},"cell_type":"code","source":"n_folds = 5\nval_size = 4000//n_folds\nactual_its = []\nlr=3e-3\nwd=1e-7\nlrs = np.array([lr/100,lr/10,lr/3])\ntest_x = np.array(test_names_png)\n\nout=np.zeros((18000,sz,sz))\nalpha = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a557302752cb359dbe6021a3fbe36a40c66c68fe"},"cell_type":"markdown","source":"# UNET"},{"metadata":{"trusted":true,"_uuid":"4aabcb9cd67529b0b7cacc7ce7823053fe497aab"},"cell_type":"code","source":"for i in [0,1,2]:\n    #fold i\n    print(f'Fold{i}------------------------------------')\n    val_idxs=list(range(i*val_size, (i+1)*val_size))\n    md = get_data(val_idxs)\n    \n    #learner\n    learn = get_learner(md)\n    learn.freeze_to(1)\n    print(f'fit (lrs, wd): {lrs, wd}')\n    learn.fit(lrs, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best1')\n    print('unfreezing')\n    learn.unfreeze()\n#     learn.fit(lrs/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9))\n    learn.load('best1')\n    learn.crit = lovasz_hinge\n    learn.fit(lrs/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best2')\n    learn.load('best2')\n    print(f'computing test set: {i}')\n    p = learn.predict(is_test=True)\n    learn.save(f'{i}-model')\n    print('Computing optimal threshold')\n    preds, targs = learn.predict_with_targs()\n    IoUs=[]\n    for a in np.arange(0, 1, 0.1):\n        IoUs.append(IoU_np(preds, targs, a))\n    IoU_max = np.array(IoUs).argmax()\n    print(f'optimal Threshold: {IoU_max/10.0}')\n    alpha+=IoU_max/10.0\n    print('TTA')\n    md.test_dl.dataset = TestFilesDataset(test_x,test_x,tfms[1],PATH128)\n    p_f = learn.predict(is_test=True)\n    p_f = p_f[:,:,::-1]\n    out = (p+p_f)/2\n    actual_its.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1373a6c9379874e22fa0a2f4ed48bfb0ba1688bf"},"cell_type":"code","source":"print(f'Last Iteration group [0,1,2]: {i} ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c6938b72d5e8597c7e7842fc943e73f69bcea94"},"cell_type":"code","source":"for i in [3,4]:\n    #fold i\n    print(f'Fold{i}------------------------------------')\n    val_idxs=list(range(i*val_size, (i+1)*val_size))\n    md = get_data(val_idxs)\n    \n    #learner\n    learn = get_learner(md)\n    learn.freeze_to(1)\n    print(f'fit (lrs, wd): {lrs, wd}')\n    learn.fit(lrs, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best1')\n    print('unfreezing')\n    learn.unfreeze()\n#     learn.fit(lrs/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9))\n    learn.load('best1')\n    learn.crit = lovasz_hinge\n    learn.fit(lrs/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best2')\n    learn.load('best2')\n    print(f'computing test set: {i}')\n    p = learn.predict(is_test=True)\n    learn.save(f'{i}-model')\n    print('Computing optimal threshold')\n    preds, targs = learn.predict_with_targs()\n    IoUs=[]\n    for a in np.arange(0, 1, 0.1):\n        IoUs.append(IoU_np(preds, targs, a))\n    IoU_max = np.array(IoUs).argmax()\n    print(f'optimal Threshold: {IoU_max/10.0}')\n    alpha+=IoU_max/10.0\n    print('TTA')\n    md.test_dl.dataset = TestFilesDataset(test_x,test_x,tfms[1],PATH128)\n    p_f = learn.predict(is_test=True)\n    p_f = p_f[:,:,::-1]\n    out = (p+p_f)/2\n    actual_its.append(i)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d41ad6a4a5d7dbe0212d7a930d6e2c824a15594"},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true,"_uuid":"683b5852bc88b0be3a94ce104abad44aa4bc8d6a"},"cell_type":"code","source":"print(f'Last Iteration group [3,4]: {i} ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce638ec54f8f3be305468af20a9dc0936b32d01b"},"cell_type":"code","source":"print(actual_its)\nout = out/n_folds\nalpha = alpha/n_folds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe7b4823b16c35e1155453dd988ee9659a14390"},"cell_type":"code","source":"fig, axes = plt.subplots(12, 6, figsize=(12, 40))\nfor i,ax in enumerate(axes.flat):\n    ax = show_img(Image.open(PATH128/test_names_png[i+30]), ax=ax)\n    show_img(out[i+30]>alpha, ax=ax, alpha=0.2)\nplt.tight_layout(pad=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0dcec07f05bcab7b2aa86083c81238c7d7f730e"},"cell_type":"code","source":"def rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fffc228be274920ee8074a11a54cd313f59ac930"},"cell_type":"code","source":"tmp_list = []\nname_list = []\nfor i in range(18000):\n    img = cv2.resize(out[i,:,:], dsize=(101,101), interpolation = cv2.INTER_CUBIC)\n    tmp_list.append(rle_encode(img>alpha))\n    name_list.append(test_names_png[i].name[0:-4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53fd158c259425ffcbc51253f5196c9cfc6a4b54"},"cell_type":"code","source":"sub = pd.DataFrame(list(zip(name_list, tmp_list)), columns = ['id', 'rle_mask'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c289e8bc9442e25c34621ca4e6b3318a2173d6ba"},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}