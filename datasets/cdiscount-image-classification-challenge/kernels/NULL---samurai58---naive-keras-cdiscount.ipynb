{"metadata": {"language_info": {"name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"source": ["This notebook is just a (very) small improvement over most common baseline.\n", "\n", "It loads a few images from train and resize it to 8x8 pixels to generate a 64 (8 x 8) feature vector.\n", "\n", "Then, it uses KNN to find the most similar image on test set.\n", "\n", "Unfortunatelly, due to limitations on Kernel, only a few test images are classified."], "metadata": {"_cell_guid": "077c0bd7-bc31-4528-a747-6b0c6e66ebe4", "_uuid": "de87e4b1b18f48d3672221485a6577293ec10926"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "7d7afe89-0c7e-43cb-9ba6-0e93db30b4bd", "_uuid": "99b9a425db0c128d80fda1ecc9b42f952a77c93c"}, "source": ["import numpy as np\n", "import pandas as pd\n", "import io\n", "import bson\n", "import cv2\n", "import matplotlib.pyplot as plt\n", "from tqdm import tqdm_notebook\n", "import concurrent.futures\n", "from multiprocessing import cpu_count"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "ea4565d0-2922-4d0d-b7c5-f970cbdf1cc1", "_uuid": "25a8edf7b1bf5b9d0726b3ede0c796717ab720ab"}, "source": ["num_images = 200000\n", "im_size = 16\n", "num_cpus = cpu_count()\n", "num_cpus"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "82f5d889-b14d-4cb7-86b0-5bd726304d8b", "_uuid": "4a5081a65e4d22316b7306cddd80332712b21b0d"}, "source": ["def imread(buf):\n", "    return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_ANYCOLOR)\n", "\n", "def img2feat(im):\n", "    x = cv2.resize(im, (im_size, im_size), interpolation=cv2.INTER_AREA)\n", "    return np.float32(x) / 255\n", "\n", "X = np.empty((num_images, im_size, im_size, 3), dtype=np.float32)\n", "y = []\n", "\n", "def load_image(pic, target, bar):\n", "    picture = imread(pic)\n", "    x = img2feat(picture)\n", "    bar.update()\n", "    \n", "    return x, target\n", "\n", "bar = tqdm_notebook(total=num_images)\n", "with open('../input/train.bson', 'rb') as f, \\\n", "        concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n", "\n", "    data = bson.decode_file_iter(f)\n", "    delayed_load = []\n", "\n", "    i = 0\n", "    try:\n", "        for c, d in enumerate(data):\n", "            target = d['category_id']\n", "            for e, pic in enumerate(d['imgs']):\n", "                delayed_load.append(executor.submit(load_image, pic['picture'], target, bar))\n", "                \n", "                i = i + 1\n", "\n", "                if i >= num_images:\n", "                    raise IndexError()\n", "\n", "    except IndexError:\n", "        pass;\n", "    \n", "    for i, future in enumerate(concurrent.futures.as_completed(delayed_load)):\n", "        x, target = future.result()\n", "        \n", "        X[i] = x\n", "        y.append(target)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "5cfda60d-d8c8-481c-833b-85f170564cc6", "_uuid": "39c439b021cfe966165d78d29486f97ea9b84c5b"}, "source": ["X.shape, len(y)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "b5166a88-3ab9-4c8e-b4ad-134362a17845", "_uuid": "f5f630b612437a897f216c657530f18f8e9b4f96"}, "source": ["y1= pd.Series(y)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "7e266d56-303e-42a8-8279-e6a5dbc3115f", "_uuid": "175f3b982eb641ff17fb790c872ef80db1d923d9"}, "source": ["y1"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "3fd80f61-ca6d-48d3-909b-d605ff206686", "_uuid": "fd00d573b02fcd88409cdf437bcc313e03208b64"}, "source": ["y1.value_counts()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "1529bff1-855b-4361-b49a-a162f73d143f", "_uuid": "ce2ab3b93006f2944aca5e79504b0f59abdc5b04"}, "source": ["y1.value_counts().index[:499].tolist()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "39f4b991-794c-452b-acaa-6ad7b46a968c", "_uuid": "f23014097dc697cbb369585290885d2a1757ebba"}, "source": ["len(y1.value_counts().index[:499].tolist())"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "87058b8f-6f8c-44cd-b0f1-fdd60ba58d84", "_uuid": "3e4320c510ef1928c19cd60e3b3ddd2219cdf010"}, "source": ["set(y1.value_counts().index[:499].tolist())"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "a533d0d8-d20a-439a-b580-49384e290527", "_uuid": "bfe944c0684733afc68b35fbbaad708cb9540789"}, "source": ["len(set(y1.value_counts().index[:499].tolist()))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "c3d22179-af06-45e8-9904-6b4353b051ad", "_uuid": "0843cca57a70b00822cf04a007c8bdfe96f9145a"}, "source": ["y2 = set(y1.value_counts().index[:499].tolist())"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "8a3e53eb-0eee-4c85-b648-63b837be6296", "_uuid": "9c12475f57bbf4c5fc534271b725c0442e885406"}, "source": ["y1.isin(y2)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "8a1665d1-4ffb-4c91-8ad5-736b3cddb48b", "_uuid": "e0d1699481d90793c0eee77f409a91427062a071"}, "source": ["y3 = y1.isin(y2)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "9dfb3bca-0768-4324-8f5e-31a482a57086", "_uuid": "702208233c60a16844dd3b055152c2cffea91f82"}, "source": ["~y3"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "1a58ef3d-2066-412b-857c-84bb76820b3e", "_uuid": "8f72ecaf4deb9dfd9cb57c6fa60f24191743edd7"}, "source": ["y1[~y3] = -1"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "33c1650b-6bcc-4b2f-a114-a2d2401ff471", "_uuid": "93972c2056e2cb17f765e7728d84a7687fb99c65"}, "source": ["y1"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "5dff47bc-7971-4c51-9a88-9638101cd07d", "_uuid": "a2931f755fb0ba816bfeb413e72c5a7d13501b2f"}, "source": ["y3.mean()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "34c9bf08-9f89-461f-b74f-1f24291a5829", "_uuid": "56969c620e60a3e55f0684b412fe1f6b7590ba01"}, "source": ["y = pd.Series(y)\n", "\n", "num_classes = 500  # This will reduce the max accuracy to about 0.75\n", "\n", "# Now we must find the most `num_classes-1` frequent classes\n", "# (there will be an aditional 'other' class)\n", "valid_targets = set(y.value_counts().index[:num_classes-1].tolist())\n", "valid_y = y.isin(valid_targets)\n", "\n", "# Set other classes to -1\n", "y[~valid_y] = -1\n", "\n", "max_acc = valid_y.mean()\n", "print(max_acc)"], "cell_type": "code"}, {"source": ["Note that the max accuracy reported above is greater than ~0.75 reported [here](http://https://www.kaggle.com/bguberfain/naive-statistics) due to smaller train set."], "metadata": {"_cell_guid": "2951efcb-a616-48c8-ad20-6c2bf2317a19", "_uuid": "f49981818f17dcfc127b0e4cb6b28f7bf3003c42"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "7543f03c-1eb4-483c-bdb2-2b04a3758b97", "_uuid": "bb34e3f26c81f39a2ed4f3f8cc4fa03301b85fcd"}, "source": ["y, rev_labels = pd.factorize(y)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "b032166d-24ee-42ae-bbe3-444e8141ba53", "_uuid": "c0adfc41acc8a560e92bd849ae2967422f622267"}, "source": ["y"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "d1557e85-32d2-42a7-90da-a75b0c0e4878", "_uuid": "676e13013955cee9db034e38a9d759c703baa3f8"}, "source": ["rev_labels"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "3c137f38-d10d-49e7-a9e5-b1628d2e0567", "_uuid": "1975ac67714c59998a9c8e587c7fd5554fd7597b"}, "source": ["# Now we categorize the dataframe\n", "y, rev_labels = pd.factorize(y)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "8755a82d-ed9b-4587-8d90-1a17cd95e51b", "_uuid": "2d3d34806c1f50b6ecaf5e63fbed89a4f5be3b4f"}, "source": ["num_classes=500"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "e6368858-f2ce-4426-85af-89219c651a06", "_uuid": "96da9277c9c7fed8cb871a3c434be783c9eb10f1"}, "source": ["# Train a simple NN\n", "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n", "from keras.models import Sequential\n", "from keras.optimizers import Adam\n", "\n", "model = Sequential()\n", "model.add(Conv2D(16, 3, activation='relu', padding='same', input_shape=X.shape[1:]))\n", "model.add(Conv2D(16, 3, activation='relu', padding='same'))\n", "model.add(MaxPooling2D(2))\n", "model.add(Conv2D(32, 3, activation='relu', padding='same'))\n", "model.add(Conv2D(32, 3, activation='relu', padding='same'))\n", "model.add(MaxPooling2D(2))\n", "model.add(Flatten())\n", "model.add(Dense(num_classes, activation='relu'))\n", "model.add(Dense(num_classes, activation='softmax'))\n", "\n", "\n", "opt = Adam(lr=0.01)\n", "\n", "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n", "\n", "model.summary()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"scrolled": true, "_cell_guid": "663b6abe-c16e-445a-b55e-6895087dc321", "_uuid": "7683eaaa3211bdf9a17ca675bf6af5b1dd1ccd24"}, "source": ["hist = model.fit(X, y, validation_split=0.1, epochs=2)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "e36e69f3-841d-4c73-986f-9570efc2d4e5", "_uuid": "e5ddbdd8b3b6be3937992264306ac580b83230b5"}, "source": ["hist.history"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "da934b31-efeb-48b9-b9fc-2474aa2c4470", "_uuid": "c8d10d15e06318953ceafc26ec03349c88a041c2"}, "source": ["# list all data in history\n", "print(hist.history.keys())\n", "# summarize history for accuracy\n", "plt.plot(hist.history['acc'])\n", "plt.plot(hist.history['val_acc'])\n", "plt.title('model accuracy')\n", "plt.ylabel('accuracy')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()\n", "# summarize history for loss\n", "plt.plot(hist.history['loss'])\n", "plt.plot(hist.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "8980a025-38b1-4f1b-8860-ee413631c434", "_uuid": "290914eec155b2c14ae06309436235063c844339", "_kg_hide-input": true, "_kg_hide-output": true}, "source": ["model.save_weights('cdiscount_model.h5')  #You can download this model and run whole test localy"], "cell_type": "code"}, {"source": ["Now we evaluate the test set using the previous trained model."], "metadata": {"_cell_guid": "4b990f20-cb25-4be0-92bc-df033ada90ad", "_uuid": "3dcc4c6c6261ac47970b5d0e33eaa0b9066a3cb9"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "4425bdc4-dd25-40c8-a26e-fe2eb11d3398", "_uuid": "5811926ec436c8820ccaa468fc2ac6a09dfbd3bc"}, "source": ["submission = pd.read_csv('../input/sample_submission.csv', index_col='_id')\n", "\n", "most_frequent_guess = 1000018296\n", "submission['category_id'] = most_frequent_guess # Most frequent guess"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "f7465e07-cc74-4371-9cc1-3639641f4110", "_uuid": "bc6ce0ae1620a9ac5a481d0a7e4a0f0e25510fd1"}, "source": ["num_images_test = 800000  # We only have time for a few test images..\n", "\n", "bar = tqdm_notebook(total=num_images_test * 2)\n", "with open('../input/test.bson', 'rb') as f, \\\n", "         concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n", "\n", "    data = bson.decode_file_iter(f)\n", "\n", "    future_load = []\n", "    \n", "    for i,d in enumerate(data):\n", "        if i >= num_images_test:\n", "            break\n", "        future_load.append(executor.submit(load_image, d['imgs'][0]['picture'], d['_id'], bar))\n", "\n", "    print(\"Starting future processing\")\n", "    for future in concurrent.futures.as_completed(future_load):\n", "        x, _id = future.result()\n", "        \n", "        y_cat = rev_labels[np.argmax(model.predict(x[None])[0])]\n", "        if y_cat == -1:\n", "            y_cat = most_frequent_guess\n", "\n", "        bar.update()\n", "        submission.loc[_id, 'category_id'] = y_cat\n", "print('Finished')"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "dd34386c-f28a-42d7-a3be-f09126fd61c7", "_uuid": "f806114fc478e841392589d4f7e2f0b828b20311", "_kg_hide-input": true, "_kg_hide-output": true}, "source": ["submission.to_csv('new_submission.csv.gz', compression='gzip')"], "cell_type": "code"}], "nbformat_minor": 1, "nbformat": 4}