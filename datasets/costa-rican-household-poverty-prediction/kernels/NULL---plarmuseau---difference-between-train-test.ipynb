{"cells":[{"metadata":{"_uuid":"79e200d968f5a51d337a0fc12df8d68fedececb6"},"cell_type":"markdown","source":"# anyone suggestion what explains that difference"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nimport plotly.plotly as py\nfrom plotly import tools\nfrom datetime import date\nimport pandas as pd\nimport numpy as np \nimport plotly.figure_factory as ff\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random \nimport warnings\nimport operator\nwarnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n## list of features to be used\nfeatures = [c for c in train.columns if c not in ['Id', 'Target']]\n\n## target variable \ntarget = train['Target'].values\ntarget_index = {1:0, 2:1, 3:2, 4:3}\ntarget = np.array([target_index[c] for c in target])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2d0fc5b25aff17ff48c796a698767fcbc37970b"},"cell_type":"code","source":"def label_encoding(col):\n    le = LabelEncoder()\n    le.fit(list(train[col].values) + list(test[col].values))\n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))\n\nnum_cols = train._get_numeric_data().columns \ncat_cols = list(set(features) - set(num_cols))\nfor col in cat_cols:\n    label_encoding(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c7e3533cda1572914b6f476ba0ad6cb326253d2"},"cell_type":"code","source":"totaal=train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e883b8e80a177256c40182a03a2eb91102ed495"},"cell_type":"markdown","source":"# SVD reveals a difference between test and train\n## with such a lack of overlap its impossible to forecast test accurately"},{"metadata":{"trusted":true,"_uuid":"f327e100e9abaa4301cc0d8477a650e3f72c2a7f"},"cell_type":"code","source":"from sklearn.decomposition import TruncatedSVD\ntotaal=(train.append(test)).fillna(0)\ntotaal=totaal.drop(['Id','Target'],axis=1)  #.reset_index()\ntemp=totaal.iloc[:,1:135].divide(totaal['rooms'],axis=0)\ntotaal=(totaal.T.append(temp.T)).T\ntotaal=totaal.join(temp, lsuffix='', rsuffix='persons')\nsvd = TruncatedSVD(n_components=140, n_iter=7, random_state=42)\ne_=svd.fit_transform(totaal)\n#A_,e1_,e_,s_=robustSVD(e_,100)\nNew_features =  e_[:len(train)]\nTest_features= e_[-len(test):]\npd.DataFrame(New_features).plot.scatter(x=0,y=1,c=train['Target']+1)\npd.DataFrame(np.concatenate((Test_features,New_features))).plot.scatter(x=0,y=1,c=[1 for x in range(len(test))]+[2 for x in range(len(train))],colormap='viridis')    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74298867ef84776e4a8a29432fe061cf847a7abe"},"cell_type":"code","source":"def cohen_effect_size(X, y):\n    \"\"\"Calculates the Cohen effect size of each feature.\n    \n        Parameters\n        ----------\n        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n            Training vector, where n_samples in the number of samples and\n            n_features is the number of features.\n        y : array-like, shape = [n_samples]\n            Target vector relative to X\n        Returns\n        -------\n        cohen_effect_size : array, shape = [n_features,]\n            The set of Cohen effect values.\n        Notes\n        -----\n        Based on https://github.com/AllenDowney/CompStats/blob/master/effect_size.ipynb\n    \"\"\"\n    print(X.shape,y.shape,y.mean())\n    medi=y.mean()\n    group1, group2 = X[y<medi], X[y>=medi]\n    diff = group1.mean() - group2.mean()\n    var1, var2 = group1.var(), group2.var()\n    n1, n2 = group1.shape[0], group2.shape[0]\n    pooled_var = (n1 * var1 + n2 * var2) / (n1 + n2)\n    d = diff / np.sqrt(pooled_var)\n    return d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f5639fb42f3cc972619c6fbf2de4a315c7f4751"},"cell_type":"code","source":"excluded_feats = ['ID','Id','Target'] #['SK_ID_CURR']\n\nfeatures = [f_ for f_ in train.drop('Target',axis=1).columns if f_ not in excluded_feats]\nprint('Number of features %d' % len(features),train.shape,target.shape)\n#effect_sizes = cohen_effect_size(Xtrain[:len(ytrain)], ytrain)\neffect_sizes = cohen_effect_size(train.drop('Target',axis=1)[:len(target)],pd.DataFrame(train).reset_index().set_index('index')['Target'])\neffect_sizes.reindex(effect_sizes.abs().sort_values(ascending=False).nlargest(50).index)[::-1].plot.barh(figsize=(6, 10));\nprint('Features with the 30 largest effect sizes')\nsignificant_features2 = [f for f in features if np.abs(effect_sizes.loc[f]) > 0.1]\nprint('Significant features %d: %s' % (len(significant_features2), significant_features2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9954fd76624af968c4695dbc9d44b397682327d7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}