{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport shutil\nprint(os.listdir(\"../input\"))\n\noriginal_dataset_dir = \"../input/train/\"\nbase_dir = \"../input/\"\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#define some directories to be used for data subsets and outputs \n\ntrain_dir = '../input/train'\ntest_dir = \"../input/test\"\ntemp_dir = '.'\noutput_dir = '.'\nimage_shape = (150,150,3) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"857e9405abcbc98dbcea9114b383000673576972"},"cell_type":"code","source":"##useful libraries \nimport os \nimport matplotlib.pyplot as plt \nfrom scipy.ndimage import imread\nfrom scipy.misc import imsave \nimport numpy as np  \nimport time\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88a014e3b12f1f171951c9dbf4672332fd88eff8"},"cell_type":"code","source":"##visualize a cat image and its shape from training directory \nrandom_cat_path = os.path.join(train_dir,'cat.25.jpg')\nrandom_cat_show = plt.imread(random_cat_path)\nplt.imshow(random_cat_show)\nrandom_cat_show.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc8966d4e16a055bac2ab9da810254326c705e45"},"cell_type":"code","source":"## visualize a dog image and shape from training directory \nrandom_dog_path = os.path.join(train_dir, 'dog.10.jpg')\nrandom_dog_show = plt.imread(random_dog_path)\nplt.imshow(random_dog_show)\nrandom_dog_show.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75dd935b649224aa3c3bc4d0056decbf881ef492"},"cell_type":"code","source":"##useful keras helper functions to pre-process images into the defined image_shape \nfrom keras.preprocessing import image\n\ndef loadAndResizeImage(img, w, h):\n    return image.load_img(img, target_size = (w,h))\n\n#random example with cat \n\nimg = os.path.join(train_dir, 'dog.2000.jpg')\nw = image_shape[0]\nh = image_shape[1]\nresized_image = loadAndResizeImage(img, w, h)\nplt.imshow(resized_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc2334e1d42e505dd7c1c4b3e7f0c54f918e55b1"},"cell_type":"code","source":"def normalizedArrayfromImagePath(image_path, image_shape):\n    \n    \"\"\"\n    takes image path, uses loadAndResizeImage function and converts PIL image to array and returns it\n    arguments image_path - path to a specific image \n    image_shape - tuple of size 3 with elements representing width, heigh, channels\n    \"\"\"\n    \n    _img = loadAndResizeImage(image_path, image_shape[0], image_shape[1])\n    _normalizedArray = image.img_to_array(_img)/ 255 \n    return(_normalizedArray)\n\ndef loadResizedNormalizedImages(basepath, path_array, img_shape):\n    \"\"\"\n    arguments - \n        basepath - directory where images are contained\n        path_array - # of images needed \n        img_shape - used to calculate the size of the array returned - tuple of size 3 \n    \"\"\"\n    images = np.empty((len(path_array), img_shape[0], img_shape[1], img_shape[2]), dtype = np.float32)\n    for i in range(len(path_array)):\n        image_path = os.path.join(basepath, path_array[i])\n        images[i] = normalizedArrayfromImagePath(image_path, img_shape)\n    return images \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60498159ad44a6f5a83f0c1504dedaefbd9691d3"},"cell_type":"code","source":"\n\ntrain_ex = 1000 \n_train_dir_list = os.listdir(train_dir)\ntrain_x = _train_dir_list[:train_ex]\nlen(train_x)\n\ntrain_images_X = loadResizedNormalizedImages(train_dir, train_x, image_shape)\ntrain_images_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a893ccc739d14bf61fb47d9580987f1b3826338f","scrolled":true},"cell_type":"code","source":"validation_ex = 100 \nvalidation_x = _train_dir_list[train_ex:train_ex + validation_ex]\nlen(validation_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2be6c036492ea6b1d5268207eeb232dafc0447dc"},"cell_type":"code","source":"validation_images_X = loadResizedNormalizedImages(train_dir, validation_x, image_shape)\nvalidation_images_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4321ec1a3c4b6eb4f72e82930d67b406f326498a"},"cell_type":"code","source":"def getYlabel(img):\n    \"\"\"\n    get the y label 'cat' or 'dog' for given image path \n    \n    \"\"\"\n    if 'cat' in img:\n        return 0\n    else:\n        return 1\n    \ndef getYlabelAsArray(X):\n    Y = np.empty(len(X))\n    for i in range (len(X)):\n        Y[i] = getYlabel(X[i])\n    return Y\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93a0b24fe48ec4a7a723785ecbcc0d89b2e8cce3"},"cell_type":"code","source":"train_y = getYlabelAsArray(train_x)\nvalidation_y = getYlabelAsArray(validation_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b117b97a6649060a3573ab404dae9ee8b9bb5b"},"cell_type":"code","source":"## we will use InceptionV3 as transfer learn mechanism\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cda4ff64b7ad1fdc46ecdb0613c114886cb7575b"},"cell_type":"code","source":"base_model = InceptionV3(weights = \"imagenet\", include_top = False)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation = \"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation = \"relu\")(x)\nx = Dropout(0.5)(x)\nx = Dense(32, activation = \"relu\")(x)\npredictions = Dense(1, activation = \"sigmoid\")(x)\n\nmodel= Model(inputs= base_model.input, output = predictions)\nfor layer in base_model.layers:\n    layer.trainable = False \nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a8093cff0bc423447d5398f3fdfbb6dd3d04512"},"cell_type":"code","source":"model.fit(x = train_images_X, y = train_y, batch_size = 16, epochs = 6, verbose =1,validation_data = (validation_images_X, validation_y))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97e746259285f659702565d33cc67467973c351d"},"cell_type":"code","source":"model.save(os.path.join(output_dir,'model.h5'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a7eac99ed23e1f883449e596f38f2dcbaee8320"},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model(os.path.join(output_dir, 'model.h5'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6d815bf1121a0d4db8b087d9209bcff86001c0d"},"cell_type":"code","source":"##time to test generalization over some other training images. We choose the last 300 training images \n\nevaluate_ex = 300 \n_evaluate_dir_list = os.listdir(train_dir)\nevaluate_x = _evaluate_dir_list[-evaluate_ex:]\nlen(evaluate_x)\n\nevaluate_images_X = loadResizedNormalizedImages(train_dir, evaluate_x, image_shape)\nevaluate_y = getYlabelAsArray(evaluate_x)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f46bb43e5ca612f62bb8b206d293b8fa85a2d5ac"},"cell_type":"code","source":"model.evaluate(x = evaluate_images_X, y = evaluate_y, batch_size = 10, verbose =1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cff5c67bb648567d9716848741fe02b97d9e42dd"},"cell_type":"code","source":"##test_dir = \"../input/test\"\n\"\"\"\n\"\"\"\ntest_ex = len(os.listdir(test_dir))\n_test_dir_list = os.listdir(test_dir)\ntest_x = _test_dir_list[:]\n\ntest_images_X = loadResizedNormalizedImages(test_dir, test_x, image_shape)\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"598e317f3281e5191bbc87c3e2f67f6876f7e63a"},"cell_type":"code","source":"test_images_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da7504f67b84faebc9c1b7f3b43f8cd633932cd1"},"cell_type":"code","source":"test_y = model.predict(test_images_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15cf9dadced6db9c84102cc279397773b2840300"},"cell_type":"code","source":"test_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12bed9aacc6c63466217d71ef0cbe33b26b5d7ef"},"cell_type":"code","source":"import numpy as np\n##predarray = np.asarray(Bin)\nimport csv\n\ncsvfile = os.path.join(output_dir, 'newAlgo.csv')\n\nwith open(csvfile, \"w\") as output:\n    writer = csv.writer(output, lineterminator='\\n')\n    for val in test_y:\n        writer.writerow(val) \n        \nimport pandas \ndf = pandas.read_csv('newAlgo.csv')\nprint(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7843edfaa959cd4cc0d4342b4bd038de0dd36415"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}