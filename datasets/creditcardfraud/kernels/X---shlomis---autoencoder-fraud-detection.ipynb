{"nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "c8d10e6a04088741386efcb03aaf219d1e6230d0", "_cell_guid": "57e30eba-fb3a-42ee-972f-a795a10d4f8c"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn.preprocessing import StandardScaler\n", "from keras.layers import Input, Dense\n", "from keras.models import Model\n", "import matplotlib.pyplot as plt\n", "\n", "data = pd.read_csv('../input/creditcard.csv')\n", "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n", "data = data.drop(['Time','Amount'],axis=1)\n", "\n", "data = data[data.Class != 1]\n", "X = data.loc[:, data.columns != 'Class']\n", "\n", "encodingDim = 8\n", "inputShape = X.shape[1]\n", "inputData = Input(shape=(inputShape,))\n", "\n", "X = X.as_matrix()\n", "\n", "encoded = Dense(encodingDim, activation='relu')(inputData)\n", "encoded = Dense(int(encodingDim/2), activation='relu')(encoded)\n", "encoded = Dense(int(encodingDim/4), activation='relu')(encoded)\n", "\n", "decoded = Dense(int(encodingDim/4), activation='relu')(encoded)\n", "decoded = Dense(int(encodingDim/2), activation='relu')(decoded)\n", "decoded = Dense(inputShape, activation='sigmoid')(decoded)\n", "\n", "autoencoder = Model(inputData, decoded)\n", "encoder = Model(inputData, encoded)\n", "encodedInput = Input(shape=(encodingDim,))\n", "decoderLayer = autoencoder.layers[-1]\n", "decoder = Model(encodedInput, decoderLayer(encodedInput))\n", "\n", "autoencoder.summary()\n", "\n", "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n", "history = autoencoder.fit(X, X,\n", "                epochs=50,\n", "                batch_size=10,\n", "                validation_split=0.33)\n", "\n", "print(history.history.keys())\n", "# summarize history for loss\n", "plt.plot(history.history['loss'])\n", "plt.plot(history.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'test'], loc='upper left')\n", "plt.show()\n", "\n", "\n", "\n", "\n"], "execution_count": 1}], "nbformat": 4}