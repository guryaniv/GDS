{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n#Before we start, let's import some packages and determine the available patients.\n\n%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom as dicom\nimport os\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\n\nfrom skimage import measure, morphology\nfrom mpl_toolkits.mplot3d.art3d import Poly3DCollection\n\n# Some constants \nINPUT_FOLDER = '../input/sample_images/'\npatients = os.listdir(INPUT_FOLDER)\npatients.sort()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"# Load the scans in given folder path\ndef load_scan(path):\n    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    try:\n        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n    except:\n        slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        \n    return slices\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6503a45787e5d639e4365d104ae453d035f73345","collapsed":true,"_cell_guid":"7f086498-ffc0-4b3a-a94a-644e1507df02","trusted":false},"cell_type":"code","source":"def get_pixels_hu(slices):\n    image = np.stack([s.pixel_array for s in slices])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 0\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    for slice_number in range(len(slices)):\n        \n        intercept = slices[slice_number].RescaleIntercept\n        slope = slices[slice_number].RescaleSlope\n        \n        if slope != 1:\n            image[slice_number] = slope * image[slice_number].astype(np.float64)\n            image[slice_number] = image[slice_number].astype(np.int16)\n            \n        image[slice_number] += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd2a867fa00296ef7a7bb68842345d1e5fd28adb","scrolled":true,"_cell_guid":"433898c7-8f69-450c-9ea0-da8445c742ec","trusted":false,"collapsed":true},"cell_type":"code","source":"first_patient = load_scan(INPUT_FOLDER + patients[0])\nfirst_patient_pixels = get_pixels_hu(first_patient)\nplt.hist(first_patient_pixels.flatten(), bins=80, color='c')\nplt.xlabel(\"Hounsfield Units (HU)\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Show some slice in the middle\nplt.imshow(first_patient_pixels[80], cmap=plt.cm.gray)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9123f456265de79c3677e643e89fb0acfb68aadc","collapsed":true,"_cell_guid":"7f740eb5-f2f6-49a4-a6ed-62d5b6fcf357","trusted":false},"cell_type":"code","source":"def resample(image, scan, new_spacing=[1,1,1]):\n    # Determine current pixel spacing\n    spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32)\n\n    resize_factor = spacing / new_spacing\n    new_real_shape = image.shape * resize_factor\n    new_shape = np.round(new_real_shape)\n    real_resize_factor = new_shape / image.shape\n    new_spacing = spacing / real_resize_factor\n    \n    image = scipy.ndimage.interpolation.zoom(image, real_resize_factor, mode='nearest')\n    \n    return image, new_spacing\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"954210992c4a9ee1df9066b4c2ae53c98395ec7a","scrolled":true,"_cell_guid":"6df44a86-af95-4856-b8d8-d2cf44207b9a","trusted":false,"collapsed":true},"cell_type":"code","source":"pix_resampled, spacing = resample(first_patient_pixels, first_patient, [1,1,1])\nprint(\"Shape before resampling\\t\", first_patient_pixels.shape)\nprint(\"Shape after resampling\\t\", pix_resampled.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5826acb4eabeaf368a5eeace1e244d66f7560e1c","collapsed":true,"_cell_guid":"d5dc16a2-fcf6-4f46-884e-de66da8c8f25","trusted":false},"cell_type":"code","source":"def plot_3d(image, threshold=-300):\n    \n    # Position the scan upright, \n    # so the head of the patient would be at the top facing the camera\n    p = image.transpose(2,1,0)\n    \n    verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold)\n\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111, projection='3d')\n\n    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n    mesh = Poly3DCollection(verts[faces], alpha=0.70)\n    face_color = [0.45, 0.45, 0.75]\n    mesh.set_facecolor(face_color)\n    ax.add_collection3d(mesh)\n\n    ax.set_xlim(0, p.shape[0])\n    ax.set_ylim(0, p.shape[1])\n    ax.set_zlim(0, p.shape[2])\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b24706c4c5fa4e67189a765e173862cd933a2d4","scrolled":true,"_cell_guid":"e8e23002-f2ac-44d2-8e8f-7073553a5035","trusted":false,"collapsed":true},"cell_type":"code","source":"plot_3d(pix_resampled, 400)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc9d0e9105d3c104003adbb2b50f86d4c58a139d","collapsed":true,"_cell_guid":"44d4d693-b87f-48e7-9723-60d3c01a516f","trusted":false},"cell_type":"code","source":"def largest_label_volume(im, bg=-1):\n    vals, counts = np.unique(im, return_counts=True)\n\n    counts = counts[vals != bg]\n    vals = vals[vals != bg]\n\n    if len(counts) > 0:\n        return vals[np.argmax(counts)]\n    else:\n        return None\n\ndef segment_lung_mask(image, fill_lung_structures=True):\n    \n    # not actually binary, but 1 and 2. \n    # 0 is treated as background, which we do not want\n    binary_image = np.array(image > -320, dtype=np.int8)+1\n    labels = measure.label(binary_image)\n    \n    # Pick the pixel in the very corner to determine which label is air.\n    #   Improvement: Pick multiple background labels from around the patient\n    #   More resistant to \"trays\" on which the patient lays cutting the air \n    #   around the person in half\n    background_label = labels[0,0,0]\n    \n    #Fill the air around the person\n    binary_image[background_label == labels] = 2\n    \n    \n    # Method of filling the lung structures (that is superior to something like \n    # morphological closing)\n    if fill_lung_structures:\n        # For every slice we determine the largest solid structure\n        for i, axial_slice in enumerate(binary_image):\n            axial_slice = axial_slice - 1\n            labeling = measure.label(axial_slice)\n            l_max = largest_label_volume(labeling, bg=0)\n            \n            if l_max is not None: #This slice contains some lung\n                binary_image[i][labeling != l_max] = 1\n\n    \n    binary_image -= 1 #Make the image actual binary\n    binary_image = 1-binary_image # Invert it, lungs are now 1\n    \n    # Remove other air pockets insided body\n    labels = measure.label(binary_image, background=0)\n    l_max = largest_label_volume(labels, bg=0)\n    if l_max is not None: # There are air pockets\n        binary_image[labels != l_max] = 0\n \n    return binary_image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70199372f22d7f89fcd4fed4e7b185f1eff06e1c","collapsed":true,"_cell_guid":"64c34dee-dd34-4646-b72c-e293676c2944","trusted":false},"cell_type":"code","source":"segmented_lungs = segment_lung_mask(pix_resampled, False)\nsegmented_lungs_fill = segment_lung_mask(pix_resampled, True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"808d7718230cdde34ccfa3973e9a0de74c29fdd2","_cell_guid":"9e8045e6-6510-4677-987a-f697cbd1020d","trusted":false,"collapsed":true},"cell_type":"code","source":"plot_3d(segmented_lungs, 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937c72bb3fc19038ed8858070ded4b167b0f82af","_cell_guid":"278d5a67-5df0-4759-9bcd-d250979bec50","trusted":false,"collapsed":true},"cell_type":"code","source":"plot_3d(segmented_lungs_fill - segmented_lungs, 0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a0bac0b804c026821e22f56c6cf9cc0350d639c","collapsed":true,"_cell_guid":"b8b8b415-66e2-428b-9886-57baa0403253","trusted":false},"cell_type":"code","source":"MIN_BOUND = -1000.0\nMAX_BOUND = 400.0\n    \ndef normalize(image):\n    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n    image[image>1] = 1.\n    image[image<0] = 0.\n    return image","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5cf3ee88bd0bf2149387abc6b31229a6a51b808","collapsed":true,"_cell_guid":"681f62d8-e09d-4773-a5da-68e9b10f4de6","trusted":false},"cell_type":"code","source":"PIXEL_MEAN = 0.25\n\ndef zero_center(image):\n    image = image - PIXEL_MEAN\n    return image","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}