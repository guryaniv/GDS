{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebb37c764ec4d0d9ee6d898bb2af3ae2344e1e70"},"cell_type":"code","source":"import gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33dcd5e5af2cd06c46bddbcdb0562c5e9195c6e1"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9098dbaf685149fef82166737cdc5e41f1f36c04"},"cell_type":"code","source":"import glob\nimport math\nfrom functools import partial\nfrom multiprocessing import Pool","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tqdm\nfrom skimage.morphology import label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88c35b2b1d04e24b55c127f462d0d28ee1cf4260"},"cell_type":"code","source":"import torch.utils.model_zoo as model_zoo\nimport torch.nn as nn\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78164b672292514e1f0a007727ec4e31dd69bfb5"},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a796ed0267851ebf819162957ba7993b93e98c7a"},"cell_type":"code","source":"len(os.listdir(\"../input/airbus-ship-detection/test_v2\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f6cde9a7422f4e1d147e28418a83db7bd9fd2b7"},"cell_type":"code","source":"def predict_batch_classifier(images, model):\n\n    images = np.array(images)\n    images = torch.from_numpy(images)\n    images = images.to(DEVICE)\n    images = images.float() / 255\n    images = images.permute(0, 3, 1, 2)\n    images = normalize(images)\n    output = model(images)\n    probs = torch.sigmoid(output)\n    return probs.data.cpu().numpy().squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a73a45993cc177b1b0d080524754764aad7b639"},"cell_type":"code","source":"def batch_iterate(cases, batch_size):\n\n    full, remainder = divmod(len(cases), batch_size)\n\n    for k in range(full):\n        yield cases[k * batch_size : (k + 1) * batch_size]\n\n    if remainder:\n        yield cases[-remainder:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e0b64f7a91ad62962ed9bd1d5f53c7f9e835cd9"},"cell_type":"code","source":"def load_single_image(image_file):\n\n    image = cv2.imread(image_file, cv2.IMREAD_COLOR)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"233d8eb1070f1154e73e904d60f78796af9cbd1b"},"cell_type":"code","source":"def resize_image(image, size):\n    return cv2.resize(image, (size, size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edb0fa9cb80482f88071fdef8f3616031278a39c"},"cell_type":"code","source":"IMAGES_SOURCE = \"../input/airbus-ship-detection/test_v2/\"\n\nCLASSIFIER_IMAGE_SIZE = 384\nCLASSIFIER_BATCH_SIZE = 64\nUNET_IMAGE_SIZE = 512\nUNET_BATCH_SIZE = 16\nCLASSIFIER_THRESHOLD = 0.8\nUNET_THRESHOLD = 0.5\nORIGINAL_IMAGE_SIZE = 768\n\nN_THREADS = 4\n\nDEVICE = \"cuda\"\nDTYPE = np.float32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99f901e53789c0cd714056bf2a638c1359bcdaf8"},"cell_type":"code","source":"def conv3x3(in_planes, out_planes, stride=1):\n    \"\"\"3x3 convolution with padding\"\"\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a50738e5f4fc83387d73835aacb44cc50318616"},"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(BasicBlock, self).__init__()\n        self.conv1 = conv3x3(inplanes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n        self.stride = stride\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out += residual\n        out = self.relu(out)\n\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"075c85868c164c79b4901e999f7a254c58c8c0a0"},"cell_type":"code","source":"class ResNet(nn.Module):\n\n    def __init__(self, block, layers, num_classes=1000, layer2_stride=2):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n                               bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=layer2_stride)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"064f04d7c8bf19e3bc0f07ccb42085c181c03593"},"cell_type":"code","source":"def resnet18(pretrained=False, **kwargs):\n    \"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50f4e13d2f2eb8c991ff0da71be6e978c56e934d"},"cell_type":"code","source":"class SupervisedClassificationModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        self.network = resnet18(num_classes=1000, pretrained=False, layer2_stride=4)\n        self.non_empty_conv = nn.Conv2d(512, 1, kernel_size=1, padding=0)\n        self.pool = nn.AdaptiveMaxPool2d(1)\n\n    def forward(self, x):\n\n        x = self.network.conv1(x)\n        x = self.network.bn1(x)\n        x = self.network.relu(x)\n        x = self.network.maxpool(x)\n\n        x = self.network.layer1(x)\n        x = self.network.layer2(x)\n        x = self.network.layer3(x)\n        x = self.network.layer4(x)\n\n        non_empty_logits_raw = self.non_empty_conv(x)\n        non_empty_logits = self.pool(non_empty_logits_raw).squeeze(-1).squeeze(-1)\n\n        return non_empty_logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bdfab9edaf8f70e62040a716285d2c6a99e44b3","scrolled":false},"cell_type":"code","source":"model = SupervisedClassificationModel().to(DEVICE)\nstate_dict = torch.load(\n    \"../input/airbusspeedprize/final_model.pth\",\n    map_location=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n)\nmodel.load_state_dict(state_dict)\nmodel = model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e8246283f4bbaacfce49e2f9e9ff1665cdce99c"},"cell_type":"code","source":"class TorchBatchNormalizer():\n\n    def __init__(self, device, dtype):\n\n        mean = np.reshape([0.485, 0.456, 0.406], (1, 3, 1, 1))\n        std = np.reshape([0.229, 0.224, 0.225], (1, 3, 1, 1))\n\n        self.mean = torch.from_numpy(mean.astype(dtype)).to(device)\n        self.std = torch.from_numpy(std.astype(dtype)).to(device)\n\n    def __call__(self, images):\n        return (images - self.mean) / self.std","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54013054b9a6c7cd0441e50c596e84507acfe606"},"cell_type":"code","source":"def extract_id(case):\n    basename = os.path.basename(case)\n    id, ext = os.path.splitext(basename)\n    return id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4da801f84af4ac256354bd4ac1bb4be4b5ec9046"},"cell_type":"code","source":"normalize = TorchBatchNormalizer(DEVICE, DTYPE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4518fa2d8422d3982d64a64c2ac611d471ae368e"},"cell_type":"code","source":"cases = glob.glob(os.path.join(IMAGES_SOURCE, \"*.jpg\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2093197c1e7da802e745c2eefbc6f9b0a066d4aa"},"cell_type":"code","source":"len(cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d764566ef310924683557015bf1ad03dcc7a3ba"},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96ad96b28b4f440ddf93eb39f799e7c5eb02a9c5"},"cell_type":"code","source":"total_time = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"34716d68dc49e7e6658bb8112014dd387da7d0e3"},"cell_type":"code","source":"classifier_probs = []\n\nresize = partial(resize_image, size=CLASSIFIER_IMAGE_SIZE)\n\ntotal_time_classifier = 0\ncurrent_start = time.time()\n\nwith Pool(N_THREADS) as pool:\n\n    batch_iterator = batch_iterate(cases, CLASSIFIER_BATCH_SIZE)\n    cases_batch = next(batch_iterator)\n    total_time_classifier += (time.time() - current_start)\n    images_batch = [load_single_image(im) for im in cases_batch]\n    current_start = time.time()\n    future_result = pool.map_async(resize, images_batch)\n\n    with torch.no_grad():\n        for n, cases_batch in enumerate(tqdm.tqdm_notebook(\n            list(batch_iterator),\n            desc=\"Predicting\", ncols=70)):\n\n            images = future_result.get()    \n            total_time_classifier += (time.time() - current_start)\n            images_batch = [load_single_image(im) for im in cases_batch]\n            current_start = time.time()\n            future_result = pool.map_async(resize, images_batch)\n\n            probs = predict_batch_classifier(images, model)\n            classifier_probs.extend(probs)\n\n        # process the last batch\n        images = future_result.get()\n        probs = predict_batch_classifier(images, model)\n        classifier_probs.extend(probs)\n        \n        total_time_classifier += (time.time() - current_start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48cf45e645dac8aed74c3d4f354e20277c00d36b"},"cell_type":"code","source":"print(total_time_classifier / 60)\ntotal_time += total_time_classifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d41a89d3893f84935c5b8e17a2d52f5f0cf3dfd"},"cell_type":"code","source":"model = model.to(\"cpu\")\ntorch.cuda.empty_cache()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb2f5c81cd7c09e8432e8a872060b9f78ef576b7"},"cell_type":"code","source":"current_start = time.time()\n\nnon_empty = np.array(classifier_probs) > CLASSIFIER_THRESHOLD\nnon_empty_cases = np.array(cases)[non_empty]\nempty_cases = np.array(cases)[~non_empty]\n\ntotal_time += time.time() - current_start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"294b1118abb749aca438ba0f18f5aaa104287a9d"},"cell_type":"code","source":"len(non_empty_cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10773ae64fbe3bc6f6dc698a8e27e0ee69018c17"},"cell_type":"code","source":"class DecoderBlockV2(nn.Module):\n    def __init__(self, in_channels, middle_channels, out_channels, is_deconv=True):\n        super(DecoderBlockV2, self).__init__()\n        self.in_channels = in_channels\n\n        if is_deconv:\n            \"\"\"\n                Paramaters for Deconvolution were chosen to avoid artifacts, following\n                link https://distill.pub/2016/deconv-checkerboard/\n            \"\"\"\n\n            self.block = nn.Sequential(\n                ConvRelu(in_channels, middle_channels),\n                nn.ConvTranspose2d(middle_channels, out_channels, kernel_size=4, stride=2,\n                                   padding=1),\n                nn.ReLU(inplace=True)\n            )\n        else:\n            self.block = nn.Sequential(\n                ConvRelu(in_channels, middle_channels),\n                nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n                ConvRelu(middle_channels, out_channels),\n            )\n\n    def forward(self, x):\n        x = self.block(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee06f87538d812ad190f6907aadc3b110da11744"},"cell_type":"code","source":"class ConvRelu(nn.Module):\n    def __init__(self, in_, out):\n        super().__init__()\n        self.conv = conv3x3(in_, out)\n        self.activation = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.activation(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a06557cf62b077b15a8c6f60e585bb01eb4aaee7"},"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, num_classes=1, num_filters=32, pretrained=True, is_deconv=False):\n        \"\"\"\n        :param num_classes:\n        :param num_filters:\n        :param pretrained:\n            False - no pre-trained network is used\n            True  - encoder is pre-trained with resnet34\n        :is_deconv:\n            False: bilinear interpolation is used in decoder\n            True: deconvolution is used in decoder\n        \"\"\"\n        super().__init__()\n        self.num_classes = num_classes\n\n        self.pool = nn.MaxPool2d(2, 2)\n\n        self.encoder = resnet18()\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Sequential(self.encoder.conv1,\n                                   self.encoder.bn1,\n                                   self.encoder.relu)\n\n\n        self.conv2 = self.encoder.layer1\n        self.conv3 = self.encoder.layer2\n        self.conv4 = self.encoder.layer3\n        self.conv5 = self.encoder.layer4\n\n        self.dec5 = DecoderBlockV2(512, 256, 256, is_deconv)\n        self.dec4 = DecoderBlockV2(512, 256, 128, is_deconv)\n        self.dec3 = DecoderBlockV2(256, 128, 64, is_deconv)\n        self.dec2 = DecoderBlockV2(128, 64, 32, is_deconv)\n        self.dec1 = DecoderBlockV2(96, 64, 32, is_deconv)\n        self.final = nn.Conv2d(32 , 1, kernel_size=1)\n        \n    def forward(self, x):\n        conv1 = self.conv1(x)\n        conv2 = self.conv2(self.pool(conv1))\n        conv3 = self.conv3(conv2)\n        conv4 = self.conv4(conv3)\n        conv5 = self.conv5(conv4)\n        \n        dec5 = self.dec5(conv5)\n        dec4 = self.dec4(torch.cat([dec5, conv4], 1))\n        dec3 = self.dec3(torch.cat([dec4, conv3], 1))\n        dec2 = self.dec2(torch.cat([dec3, conv2], 1))\n        dec1 = self.dec1(torch.cat([dec2, conv1], 1))\n        \n        output = self.final(dec1)\n        return F.interpolate(output, size=(ORIGINAL_IMAGE_SIZE, ORIGINAL_IMAGE_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d7e0d1e83058c79b5070863e8007616c543631e"},"cell_type":"code","source":"model = UNet().to(DEVICE)\nstate_dict = torch.load(\n    \"../input/airbusspeedprize/resnet18_104_0.4799_added2.pth\",\n    map_location=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n)\nmodel.load_state_dict(state_dict[\"state_dict\"])\nmodel = model.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11524689f603d13e7bffed080d93e5418c22f4e7"},"cell_type":"code","source":"def predict_batch_unet(images, model):\n\n    images = np.array(images)\n    images = torch.from_numpy(images)\n    images = images.to(DEVICE)\n    images = images.float() / 255\n    images = images.permute(0, 3, 1, 2)\n    output = model(images)\n    probs = torch.sigmoid(output)\n    predictions = probs > UNET_THRESHOLD\n    return predictions.data.cpu().numpy().squeeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c99f083d0bff6362b1129440897b53b1c5a3f42","scrolled":false},"cell_type":"code","source":"unet_predictions = []\n\nresize = partial(resize, size=UNET_IMAGE_SIZE)\n\ntotal_time_unet = 0\ncurrent_start = time.time()\n\nwith Pool(N_THREADS) as pool:\n\n    batch_iterator = batch_iterate(non_empty_cases, UNET_BATCH_SIZE)\n    cases_batch = next(batch_iterator)\n    total_time_unet += (time.time() - current_start)\n    images_batch = [load_single_image(im) for im in cases_batch]\n    current_start = time.time()\n    future_result = pool.map_async(resize, images_batch)\n\n    with torch.no_grad():\n        for n, cases_batch in enumerate(tqdm.tqdm_notebook(\n            list(batch_iterator),\n            desc=\"Predicting\", ncols=70)):\n\n            images = future_result.get()\n            total_time_unet += (time.time() - current_start)\n            images_batch = [load_single_image(im) for im in cases_batch]\n            current_start = time.time()\n            future_result = pool.map_async(resize, images_batch)\n\n            preds = predict_batch_unet(images, model)\n            unet_predictions.extend(preds)\n\n        # process the last batch\n        images = future_result.get()\n        preds = predict_batch_unet(images, model)\n        unet_predictions.extend(preds)\n        \n        total_time_unet += (time.time() - current_start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d8ace4ed0cd52b4226814189645408a34421de5"},"cell_type":"code","source":"print(total_time_unet / 60)\ntotal_time += total_time_unet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de259d4b8851af1541780bfa66bfddb53d51081b"},"cell_type":"code","source":"def rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.ravel()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return \" \".join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04b03b98ce203f316ab4fa2f9ea76261b8a1eb5d"},"cell_type":"code","source":"def multi_rle_encode(img):\n    labels, n_labels = label(img, return_num=True)\n    ships = [(labels == k) for k in range(1, n_labels + 1)]\n    return [rle_encode(s) for s in ships if s.sum() >= 60]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42107e3354e182227bc8d07c5efa82bcceac4785"},"cell_type":"code","source":"current_start = time.time()\n\nids, rles = [], []\n\nfor case in empty_cases:\n    ids.append(extract_id(case) + \".jpg\")\n    rles.append(\"\")\n    \nfor case, mask in zip(non_empty_cases, unet_predictions):\n    id = extract_id(case) + \".jpg\"\n    case_rles = multi_rle_encode(mask)\n    \n    if case_rles:\n        rles.extend(case_rles)\n        ids.extend([id] * len(case_rles))\n    else:\n        ids.append(id)\n        rles.append(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25ae94d791e6741b6c4b3e9e1327cfb16e24065d"},"cell_type":"code","source":"len(empty_cases) + len(non_empty_cases)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d43b32812b96acb1a937e64850b68712c518954"},"cell_type":"code","source":"submission = pd.DataFrame({\"ImageId\": ids, \"EncodedPixels\": rles})\nsubmission.to_csv(\"submission.csv\", index=False)\n\ntotal_time += time.time() - current_start","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03398fc40d892b6a5fb77ddb7b151e8578b29aa7"},"cell_type":"code","source":"submission.ImageId.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdffc3c499f5a2761a507b387599a5e40a514d91"},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5360385a373fac96cf3ea8319463330fc460c75e"},"cell_type":"code","source":"print(\"Total time {:.2f} minutes:\".format(total_time / 60))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}