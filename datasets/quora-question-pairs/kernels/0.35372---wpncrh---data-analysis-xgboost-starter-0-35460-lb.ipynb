{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9c355c2c-044d-2b87-e1cf-a6732fb9e802"
      },
      "source": [
        "# Identifying Duplicate Questions\n",
        "\n",
        "\"Welcome to the Quora Question Pairs competition! Here, our goal is to identify which questions asked on [Quora](https://www.quora.com/), a quasi-forum website with over 100 million visitors a month, are duplicates of questions that have already been asked. This could be useful, for example, to instantly provide answers to questions that have already been answered. We are tasked with predicting whether a pair of questions are duplicates or not, and submitting a binary prediction against the logloss metric.\" - Anokas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9f5b5bf-b8a8-a88a-a16c-7666be39bd7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "pal = sns.color_palette()\n",
        "\n",
        "print('# File sizes')\n",
        "for f in os.listdir('../input'):\n",
        "    if 'zip' not in f:\n",
        "        print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ac4cab6-214b-957b-bb2a-01f7e8d5ed2b"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "63f4375e-a885-4994-4293-fe279ff0f94c"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc1375af-72bd-6983-ccea-2287cd2015f4"
      },
      "outputs": [],
      "source": [
        "small_train=df_train.sample(50000)\n",
        "small_test=df_test.sample(50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2704bf6-9256-d37d-d284-aa957694d3f4"
      },
      "outputs": [],
      "source": [
        "small_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "68e0a285-995b-ecb2-fde7-3486c982912b"
      },
      "outputs": [],
      "source": [
        "print('Duplicate pairs in small train: {}%'.format(round(small_train['is_duplicate'].mean()*100, 2)))\n",
        "print('Duplicate pairs in full df_train: {}%'.format(round(df_train['is_duplicate'].mean()*100, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "656b602a-e321-6ee4-682a-e76959bccc19"
      },
      "source": [
        "# Initial Feature Analysis\n",
        "\n",
        "Before we create a model, we should take a look at how powerful some features are. I will start off with the word share feature from the benchmark model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ef13480a-2522-2d1f-cf8a-56670e0856ab"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "def word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
        "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
        "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
        "    return R\n",
        "\n",
        "train_word_match = df_train.apply(word_match_share, axis=1, raw=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "24ce20d7-2c37-9833-dfdb-b4aac6b37e96"
      },
      "source": [
        "## TF-IDF\n",
        "\n",
        "I'm now going to try to improve this feature, by using something called TF-IDF (term-frequency-inverse-document-frequency). This means that we weigh the terms by how **uncommon** they are, meaning that we care more about rare words existing in both questions than common one. This makes sense, as for example we care more about whether the word \"exercise\" appears in both than the word \"and\" - as uncommon words will be more indicative of the content.\n",
        "\n",
        "You may want to look into using sklearn's [TfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) to compute weights if you are implementing this yourself, but as I am too lazy to read the documentation I will write a version in pure python with a few changes which I believe should help the score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99d8e8e1-e2fd-25c6-137d-4492b850e1b5"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# If a word appears only once, we ignore it completely (likely a typo)\n",
        "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
        "def get_weight(count, eps=1000, min_count=2):\n",
        "    if count < min_count:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1 / (count + eps)\n",
        "\n",
        "eps = 5000\n",
        "words = (\" \".join(train_qs)).lower().split()\n",
        "counts = Counter(words)\n",
        "weights = {word: get_weight(count) for word, count in counts.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d791c6b1-9860-7c3b-2b96-0767e607d6dc"
      },
      "outputs": [],
      "source": [
        "print('Most common words and weights: \\n')\n",
        "print(sorted(weights.items(), key=lambda x: x[1] if x[1] > 0 else 9999)[:10])\n",
        "print('\\nLeast common words and weights: ')\n",
        "(sorted(weights.items(), key=lambda x: x[1], reverse=True)[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2c8f2e86-f96b-5d36-e2f1-5f4c4c903e26"
      },
      "outputs": [],
      "source": [
        "def tfidf_word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    \n",
        "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
        "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
        "    \n",
        "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
        "    return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "157fd891-0b63-22df-4129-e4267cb55ff0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "tfidf_train_word_match = df_train.apply(tfidf_word_match_share, axis=1, raw=True)\n",
        "plt.hist(tfidf_train_word_match[df_train['is_duplicate'] == 0].fillna(0), bins=20, normed=True, label='Not Duplicate')\n",
        "plt.hist(tfidf_train_word_match[df_train['is_duplicate'] == 1].fillna(0), bins=20, normed=True, alpha=0.7, label='Duplicate')\n",
        "plt.legend()\n",
        "plt.title('Label distribution over tfidf_word_match_share', fontsize=15)\n",
        "plt.xlabel('word_match_share', fontsize=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1814b89-b895-f442-0ba2-b4e2fc6b6288"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "print('Original AUC:', roc_auc_score(df_train['is_duplicate'], train_word_match))\n",
        "print('   TFIDF AUC:', roc_auc_score(df_train['is_duplicate'], tfidf_train_word_match.fillna(0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "232aece4-2175-85b6-9700-ca7eaa08f7b5"
      },
      "source": [
        "# Length of questions difference - Nowak Feature\n",
        "\n",
        "Does the length of question 1 and question 2 make them more likely to be related? I find the difference in word count btw q1 and q2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f33ad6d9-d21c-570c-b960-4ec0c0a001f1"
      },
      "outputs": [],
      "source": [
        "train_q1s = pd.Series(df_train['question1'].tolist()).astype(str)\n",
        "train_q2s = pd.Series(df_train['question2'].tolist()).astype(str)\n",
        "\n",
        "#df_train['question2'].tolist()).astype(str)\n",
        "#test_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)\n",
        "\n",
        "train_q1_words = train_q1s.apply(lambda x: len(x.split(' ')))\n",
        "train_q2_words = train_q1s.apply(lambda x: len(x.split(' ')))\n",
        "train_word_count_diff=train_q1_words-train_q2_words\n",
        "\n",
        "test_q1s = pd.Series(df_test['question1'].tolist()).astype(str)\n",
        "test_q2s = pd.Series(df_test['question2'].tolist()).astype(str)\n",
        "\n",
        "#df_train['question2'].tolist()).astype(str)\n",
        "#test_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)\n",
        "\n",
        "test_q1_words = test_q1s.apply(lambda x: len(x.split(' ')))\n",
        "test_q2_words = test_q2s.apply(lambda x: len(x.split(' ')))\n",
        "\n",
        "#dist_test = test_qs.apply(lambda x: len(x.split(' ')))\n",
        "test_word_count_diff=test_q1_words-test_q2_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "28b46d9f-82fe-c37e-010c-a3e115687d41"
      },
      "source": [
        "## Rebalancing the Data\n",
        "\"However, before I do this, I would like to rebalance the data that XGBoost receives, since we have 37% positive class in our training data, and only 17% in the test data. By re-balancing the data so our training set has 17% positives, we can ensure that XGBoost outputs probabilities that will better match the data on the leaderboard, and should get a better score (since LogLoss looks at the probabilities themselves and not just the order of the predictions like AUC)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0589da36-d092-c951-f3cd-68df3fd91c7a"
      },
      "outputs": [],
      "source": [
        "# First we create our training and testing data\n",
        "x_train = pd.DataFrame()\n",
        "x_test = pd.DataFrame()\n",
        "x_train['word_match'] = train_word_match\n",
        "x_train['tfidf_word_match'] = tfidf_train_word_match\n",
        "x_train['word_count_diff']=train_word_count_diff\n",
        "x_test['word_match'] = df_test.apply(word_match_share, axis=1, raw=True)\n",
        "x_test['tfidf_word_match'] = df_test.apply(tfidf_word_match_share, axis=1, raw=True)\n",
        "x_test['word_count_diff']=train_word_count_diff\n",
        "\n",
        "y_train = df_train['is_duplicate'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5ccae7db-46e1-cf74-fdd8-4d4758bf460f"
      },
      "outputs": [],
      "source": [
        "pos_train = x_train[y_train == 1]\n",
        "neg_train = x_train[y_train == 0]\n",
        "\n",
        "# Now we oversample the negative class\n",
        "# There is likely a much more elegant way to do this...\n",
        "p = 0.165\n",
        "scale = ((len(pos_train) / (len(pos_train) + len(neg_train))) / p) - 1\n",
        "while scale > 1:\n",
        "    neg_train = pd.concat([neg_train, neg_train])\n",
        "    scale -=1\n",
        "neg_train = pd.concat([neg_train, neg_train[:int(scale * len(neg_train))]])\n",
        "print(len(pos_train) / (len(pos_train) + len(neg_train)))\n",
        "\n",
        "x_train = pd.concat([pos_train, neg_train])\n",
        "y_train = (np.zeros(len(pos_train)) + 1).tolist() + np.zeros(len(neg_train)).tolist()\n",
        "del pos_train, neg_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20684b12-fd83-bad6-b00b-77c51dd14c32"
      },
      "outputs": [],
      "source": [
        "# Finally, we split some of the data off for validation\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=4242)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9df47145-da6a-ad51-7bfb-1b588c4bab06"
      },
      "source": [
        "## XGBoost\n",
        "\n",
        "Now we can finally run XGBoost on our data, in order to see the score on the leaderboard!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5f9f7fc-5ec4-fc9f-7fc0-608f5f25e7c6"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Set our parameters for xgboost\n",
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eval_metric'] = 'logloss'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "11616998-a057-45e0-ac3c-d129e5cfec36"
      },
      "outputs": [],
      "source": [
        "d_test = xgb.DMatrix(x_test)\n",
        "p_test = bst.predict(d_test)\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['test_id'] = df_test['test_id']\n",
        "sub['is_duplicate'] = p_test\n",
        "sub.to_csv('simple_xgb.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4b74fd4a-5e89-27e1-5ddd-f170bc370697"
      },
      "source": [
        "**0.35460** on the leaderboard - a good first score!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9160f65-420f-0413-9504-2330d8c661cd"
      },
      "outputs": [],
      "source": [
        "df_test"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}