{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "700e3e8f-2972-5c83-9e55-b48f7a927274"
      },
      "source": [
        "# first neural network test-split the data\n",
        "# obtain the results to ann\n",
        "# the code must be improved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc99ba69-0c52-3434-ba07-21968eac9dc9"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "789ed47c-c8ab-7058-4839-ddc1c0b74bc0"
      },
      "outputs": [],
      "source": [
        "prop_df = pd.read_csv(\"../input/properties_2016.csv\")\n",
        "train_df = pd.read_csv(\"../input/train_2016.csv\")\n",
        "data= pd.merge(left=train_df,right=prop_df, left_on='parcelid', right_on='parcelid') # merge target and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5a9b3b3-8f4e-29a7-b54a-5dc4d283e327"
      },
      "outputs": [],
      "source": [
        "# split the dataset (train and test)\n",
        "train=data.sample(frac=0.4,random_state=200)\n",
        "test=data.drop(train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45030457-2a58-c5c6-8412-a3220459fd61"
      },
      "outputs": [],
      "source": [
        "# geting the name of variables\n",
        "strings = list(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db0e3f9e-b1b3-f39f-dd6e-41bca13dd939"
      },
      "outputs": [],
      "source": [
        "# dataset: features to be excluded \n",
        "invalid = ['parecelid', 'logerror', 'transactiondate','propertycountylandusecode','propertyzoningdesc','taxdelinquencyflag',\n",
        "               'hashottuborspa','fireplaceflag','latitude','longitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75ab11c1-df04-e792-b264-c7f9743f0e10"
      },
      "outputs": [],
      "source": [
        "# exlucluding features\n",
        "Nomes = list(filter(lambda x: not any(s in x.lower() for s in invalid),strings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75d09e85-7fc2-a2e8-39f1-cef6f5a9bcd3"
      },
      "outputs": [],
      "source": [
        "#s plit the dataset in train and target and replace NaNs by zero\n",
        "train_x=train[Nomes]\n",
        "train_x[np.isnan(train_x)] = 0\n",
        "train_y=train[['logerror']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23bcfac4-dd5a-7a0e-94a2-472220573b60"
      },
      "outputs": [],
      "source": [
        "# normatization of dataset\n",
        "train_y=(train_y-train_y.min())/(train_y.max()-train_y.min())\n",
        "train_x=(train_x-train_x.min())/(train_x.max()-train_x.min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d420211a-5001-770f-f280-d01aaabd5ad4"
      },
      "outputs": [],
      "source": [
        "#create neural net regressor\n",
        "# activation : {'identity', 'logistic', 'tanh', 'relu'},\n",
        "reg = MLPRegressor(hidden_layer_sizes=(100,),activation='logistic',solver=\"lbfgs\",max_iter=10000)\n",
        "reg.fit(train_x,train_y)\n",
        " \n",
        "#test prediction\n",
        "test_x=train_x\n",
        "predict=reg.predict(test_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "905742bc-c80d-aad0-8363-c729c9433946"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(train_y,predict)\n",
        "plt.xlabel(\"y_train\")\n",
        "plt.ylabel(\"y_calc\")\n",
        "plt.xlim((0,1))\n",
        "plt.ylim((0,1))\n",
        "plt.title(\"my first ANN approx\")\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}