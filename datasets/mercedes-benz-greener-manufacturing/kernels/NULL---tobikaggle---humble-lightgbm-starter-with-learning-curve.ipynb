{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "303e2a34-94c6-ce38-0d3c-0575333cf2e6"
      },
      "source": [
        "**Example for LightGBM**, see https://github.com/Microsoft/LightGBM  \n",
        "very fast, run time is around 2 seconds locally (old 2012 CPU)   \n",
        "and 16 seconds Kaggle cloud (without grid search at the end),     \n",
        "includes learning curve, parameter importance plot, grid search and parameter tuning  \n",
        "\n",
        "Full code for copy-paste in local python editor here:  \n",
        "https://www.kaggle.com/tobikaggle/humble-lightgbm-starter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "276a448d-9693-d6a8-f128-75528d3ef9a4"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# LightGBM regression example\n",
        "# __author__ = \"DDgg\"\n",
        "# https://www.kaggle.com/c/mercedes-benz-greener-manufacturing\n",
        "# -----------------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9533aa90-607b-4138-619a-addd80ed4e6b"
      },
      "outputs": [],
      "source": [
        "# PCA -------------------------------------------------------------------------\n",
        "# add to see skewness\n",
        "# -----------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8a36d04-20a5-e765-7998-6e08378256ef"
      },
      "outputs": [],
      "source": [
        "# data imnport \n",
        "# fork of forks from https://www.kaggle.com/jaybob20/starter-xgboost\n",
        "# Any results you write to the current directory are saved as output.\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "#pca_3D_plot(test)\n",
        "\n",
        "for c in train.columns:\n",
        "    if train[c].dtype == 'object':\n",
        "        lbl = LabelEncoder() \n",
        "        lbl.fit(list(train[c].values) + list(test[c].values)) \n",
        "        train[c] = lbl.transform(list(train[c].values))\n",
        "        test[c] =  lbl.transform(list(test[c].values))\n",
        "        \n",
        "y_train = train[\"y\"]\n",
        "y_mean = np.mean(y_train)\n",
        "train.drop('y', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a0605670-ee2b-047f-21ce-0403c1cb0d4c"
      },
      "outputs": [],
      "source": [
        "# split into training and validation set\n",
        "# the data has a number of outliers, so the validation size needs\n",
        "# to be large enough plus cross-validation is needed\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        train, y_train, test_size=0.2, random_state=12345)\n",
        "\n",
        "# create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_valid = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
        "\n",
        "# to record eval results for plotting\n",
        "evals_result = {} \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "461c4b33-9382-db5d-3e0c-35346b267492"
      },
      "outputs": [],
      "source": [
        "# The rmse of prediction is: 7.75675312274\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'task': 'train',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'metric': {'l2'},\n",
        "    'num_leaves': 20,\n",
        "    'learning_rate': 0.05,\n",
        "    'feature_fraction': 0.9,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'min_data_in_leaf':4,\n",
        "     #'min_sum_hessian_in_leaf': 5,\n",
        "    'verbose':10\n",
        "}\n",
        "\n",
        "print('Start training...')\n",
        "\n",
        "# train\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=200,\n",
        "                valid_sets=[lgb_train, lgb_valid],\n",
        "                evals_result=evals_result,\n",
        "                verbose_eval=10,\n",
        "                early_stopping_rounds=50)\n",
        "\n",
        "# print('\\nSave model...')\n",
        "# save model to file\n",
        "# gbm.save_model('model.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "59e279d9-6aa4-99ab-a298-16c074b374c9"
      },
      "outputs": [],
      "source": [
        "print('Start predicting...')\n",
        "# predict\n",
        "y_pred = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# eval rmse\n",
        "print('\\nThe rmse of prediction is:', mean_squared_error(y_valid, y_pred) ** 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06d079d1-1ea3-4010-d925-f2f3e03ea7b4"
      },
      "outputs": [],
      "source": [
        "# print feature names\n",
        "print('\\nFeature names:', gbm.feature_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "20605ac7-757e-e981-788e-005b64d51428"
      },
      "outputs": [],
      "source": [
        "print('\\nCalculate feature importances...')\n",
        "\n",
        "# feature importances\n",
        "print('Feature importances:', list(gbm.feature_importance()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a908d647-ba89-6294-7683-b47ebfe0a9c4"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------\n",
        "print('Plot metrics during training...')\n",
        "ax = lgb.plot_metric(evals_result, metric='l2')\n",
        "plt.show()\n",
        "# -------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7f99ab7-d46d-5633-0244-51005734aee0"
      },
      "outputs": [],
      "source": [
        "print('Plot feature importances...')\n",
        "ax = lgb.plot_importance(gbm, max_num_features=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9903944a-0884-592e-d1b3-7b49428bc6f5"
      },
      "outputs": [],
      "source": [
        "print('\\nPredicting test set...')\n",
        "y_pred = gbm.predict(test, num_iteration=gbm.best_iteration)\n",
        "\n",
        "# y_pred = model.predict(dtest)\n",
        "output = pd.DataFrame({'id': test['ID'], 'y': y_pred})\n",
        "output.to_csv('submit-lightgbm.csv', index=False)\n",
        "\n",
        "print(\"Finished.\")\n",
        "# -----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d62e1d4-9da3-11bd-6fef-855c42d1154e"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Grid search example // uncomment block if needed\n",
        "# The parameters estimated here need to be fed into the upper code\n",
        "# can also be rearranged for demo purposes only\n",
        "# once this part is executed the ipython notebook has to be rerun\n",
        "# in external pyton editor the code section can be executed alone\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "estimator = lgb.LGBMRegressor()\n",
        "\n",
        "# get possible parameters\n",
        "estimator.get_params().keys()\n",
        "\n",
        "# fill parameters ad libitum\n",
        "param_grid = {\n",
        "'num_leaves': [20, 30],    \n",
        "'learning_rate': [0.01, 0.1],\n",
        "#     'n_estimators': [],\n",
        "#     'colsample_bytree' :[],\n",
        "#     'min_split_gain' :[],\n",
        "#     'subsample_for_bin' :[],\n",
        "#     'max_depth' :[],\n",
        "#     'subsample' :[], \n",
        "#     'reg_alpha' :[], \n",
        "#     'max_drop' :[], \n",
        "#     'gaussian_eta' :[], \n",
        "#     'drop_rate' :[], \n",
        "#     'silent' :[], \n",
        "#     'boosting_type' :[], \n",
        "#     'min_child_weight' :[], \n",
        "#     'skip_drop' :[], \n",
        "#     'learning_rate' :[], \n",
        "#     'fair_c' :[], \n",
        "#     'seed' :[], \n",
        "#     'poisson_max_delta_step' :[], \n",
        "#     'subsample_freq' :[], \n",
        "#     'max_bin' :[], \n",
        "#     'n_estimators' :[], \n",
        "#     'nthread' :[], \n",
        "#     'min_child_samples' :[], \n",
        "#     'huber_delta' :[], \n",
        "#     'use_missing' :[], \n",
        "#     'uniform_drop' :[], \n",
        "#     'reg_lambda' :[], \n",
        "#     'xgboost_dart_mode' :[], \n",
        "#     'objective'\n",
        "}\n",
        "\n",
        "\n",
        "gbm = GridSearchCV(estimator, param_grid)\n",
        "\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# list them\n",
        "print('Best parameters found by grid search are:', gbm.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}