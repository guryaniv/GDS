{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2776f027-17c3-cc4f-85eb-819f97285960"
      },
      "source": [
        "Its my last take on Quora\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca0f1a00-5e22-80e9-fb7b-ef66940c8c5e"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "# timing function\n",
        "import time   \n",
        "start = time.clock() #_________________ measure efficiency timing\n",
        "\n",
        "\n",
        "train=pd.read_csv('../input/train.csv')[:20000].fillna(\"\")\n",
        "\n",
        "def cleanup(x):\n",
        "    # Pad punctuation with spaces on both sides\n",
        "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
        "        x = x.replace(char, ' ' + char + ' ')\n",
        "    return x\n",
        "\n",
        "\n",
        "def edit_distance(s1, s2):\n",
        "    m=len(s1)+1\n",
        "    n=len(s2)+1\n",
        "\n",
        "    tbl = {}\n",
        "    for i in range(m): tbl[i,0]=i\n",
        "    for j in range(n): tbl[0,j]=j\n",
        "    for i in range(1, m):\n",
        "        for j in range(1, n):\n",
        "            cost = 0 if s1[i-1] == s2[j-1] else 1\n",
        "            tbl[i,j] = min(tbl[i, j-1]+1, tbl[i-1, j]+1, tbl[i-1, j-1]+cost)\n",
        "\n",
        "    return tbl[i,j]\n",
        "\n",
        "def leve3(string_1, string_2):\n",
        "    len_1 = len(ngrams_split(string_1,3)) + 1\n",
        "    len_2 = len(ngrams_split(string_2,3)) + 1\n",
        "    d=[0]\n",
        "    if len_1>3 and len_2>3:\n",
        "        d = [0] * (len_1 * len_2)\n",
        "\n",
        "        for i in range(len_1):\n",
        "            d[i] = i\n",
        "        for j in range(len_2):\n",
        "            d[j * len_1] = j\n",
        "\n",
        "        for j in range(1, len_2):\n",
        "            for i in range(1, len_1):\n",
        "                if string_1[i - 3] == string_2[j - 3]:\n",
        "                    d[i + j * len_1] = d[i - 1 + (j - 1) * len_1]\n",
        "                else:\n",
        "                    d[i + j * len_1] = min(\n",
        "                       d[i - 1 + j * len_1] + 1,        # deletion\n",
        "                       d[i + (j - 1) * len_1] + 1,      # insertion\n",
        "                       d[i - 1 + (j - 1) * len_1] + 1,  # substitution\n",
        "                    )\n",
        "\n",
        "    return d[-1]\n",
        "\n",
        "questions = train['question1'].tolist() + train['question2'].tolist()\n",
        "train=cleanup(train)\n",
        "print(train.head())\n",
        "end = time.clock()\n",
        "print('open:',end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7d97d2c-d047-2228-30dc-12112a1de2e9"
      },
      "outputs": [],
      "source": [
        "import nltk #language functions\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity,euclidean_distances,laplacian_kernel,sigmoid_kernel,polynomial_kernel,rbf_kernel\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import scipy\n",
        "\n",
        "def ngram(lst):\n",
        "    woorden=nltk.word_tokenize(lst.lower())\n",
        "    gra_ret=[]\n",
        "    for woo in woorden:\n",
        "        zip_lst=list(woo)\n",
        "        grams=zip(zip_lst, zip_lst[1:], zip_lst[2:])\n",
        "        trigram=[]\n",
        "        for gr in grams:\n",
        "            trigram.append(''.join(gr))    \n",
        "        gra_ret+=trigram\n",
        "\n",
        "    return ' '.join(gra_ret)\n",
        "\n",
        "def intersecting(a, b):\n",
        "    return ' '.join(list(set(a.split()) & set(b.split())))\n",
        "\n",
        "def differencing(a, b):\n",
        "    return ' '.join(list(set(a.split()) ^ set(b.split())))\n",
        "\n",
        "\n",
        "def get_fea(df_fea):\n",
        "    print('3gramming')\n",
        "    df_fea['q13g'] = df_fea['question1'].apply(lambda x: ngram(x))\n",
        "    df_fea['q23g'] = df_fea['question2'].apply(lambda x: ngram(x))        \n",
        "    df_fea['inte'] = df_fea[['q13g','q23g']].apply(lambda x: intersecting(*x), axis=1)\n",
        "    df_fea['diffe'] = df_fea[['q13g','q23g']].apply(lambda x: differencing(*x), axis=1)    \n",
        "    df_fea['q1di'] = df_fea[['q13g','diffe']].apply(lambda x: intersecting(*x), axis=1)    \n",
        "    df_fea['q2di'] = df_fea[['q23g','diffe']].apply(lambda x: intersecting(*x), axis=1)        \n",
        "        \n",
        "    return df_fea.fillna(0.0)\n",
        "    \n",
        "df_train = get_fea(train)\n",
        "#print(df_train)\n",
        "end = time.clock()\n",
        "print('gramming:',len(df_train)*1.0/(end-start))\n",
        "\n",
        "questions = train['q13g'].tolist() + train['q23g'].tolist()\n",
        "tfidf = TfidfVectorizer( ngram_range=(2, 3))\n",
        "tfidf.fit_transform(questions)\n",
        "\n",
        "print(tfidf)\n",
        "\n",
        "def get_feaT(df_feaT):\n",
        "    question1_tfidf = tfidf.transform(df_feaT.q13g.tolist())\n",
        "    print('Q1')    \n",
        "    question2_tfidf = tfidf.transform(df_feaT.q23g.tolist())    \n",
        "    print('Q2')        \n",
        "    questionI_tfidf = tfidf.transform(df_feaT.inte.tolist())    \n",
        "    questionD_tfidf = tfidf.transform(df_feaT.diffe.tolist()) \n",
        "    questionQ1D_tfidf = tfidf.transform(df_feaT.q1di.tolist())    \n",
        "    questionQ2D_tfidf = tfidf.transform(df_feaT.q2di.tolist())  \n",
        "\n",
        "    print('sum mean len....')\n",
        "    df_feaT['tfidfSum1'] = scipy.sparse.csr_matrix(question1_tfidf).sum(axis=1)\n",
        "    df_feaT['tfidfSum2'] = scipy.sparse.csr_matrix(question2_tfidf).sum(axis=1)\n",
        "    df_feaT['tfidfSumI'] = scipy.sparse.csr_matrix(questionI_tfidf).sum(axis=1)   \n",
        "    df_feaT['tfidfSumD'] = scipy.sparse.csr_matrix(questionD_tfidf).sum(axis=1)\n",
        "    df_feaT['tfidfSum1D'] = scipy.sparse.csr_matrix(questionQ1D_tfidf).sum(axis=1)     \n",
        "    df_feaT['tfidfSum2D'] = scipy.sparse.csr_matrix(questionQ2D_tfidf).sum(axis=1)    \n",
        "    \n",
        "    df_feaT['tfidfMean1'] = scipy.sparse.csr_matrix(question1_tfidf).mean(axis=1)\n",
        "    df_feaT['tfidfMean2'] = scipy.sparse.csr_matrix(question2_tfidf).mean(axis=1)\n",
        "    df_feaT['tfidfMeanI'] = scipy.sparse.csr_matrix(questionI_tfidf).mean(axis=1)    \n",
        "    df_feaT['tfidfMeanD'] = scipy.sparse.csr_matrix(questionD_tfidf).mean(axis=1)    \n",
        "    df_feaT['tfidfMean1D'] = scipy.sparse.csr_matrix(questionQ1D_tfidf).mean(axis=1)    \n",
        "    df_feaT['tfidfMean2D'] = scipy.sparse.csr_matrix(questionQ2D_tfidf).mean(axis=1)    \n",
        "    \n",
        "    df_feaT['tfidfLen1'] = (question1_tfidf != 0).sum(axis = 1)\n",
        "    df_feaT['tfidfLen2'] = (question2_tfidf != 0).sum(axis = 1)\n",
        "    df_feaT['tfidfLenI'] = (questionI_tfidf != 0).sum(axis = 1)\n",
        "    df_feaT['tfidfLenD'] = (questionD_tfidf != 0).sum(axis = 1)\n",
        "    df_feaT['tfidfLen1D'] = (questionQ1D_tfidf != 0).sum(axis = 1)\n",
        "    df_feaT['tfidfLen2D'] = (questionQ2D_tfidf != 0).sum(axis = 1)\n",
        "    \n",
        "    #(question1_tfidf.getrow())*(question1_tfidf.getrow())\n",
        "    print('simil')    \n",
        "    df_feaT['sim12'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*question2_tfidf.getrow(i).T).toarray()[0][0])    \n",
        "    df_feaT['sim1I'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionI_tfidf.getrow(i).T).toarray()[0][0] )      \n",
        "    df_feaT['sim1D'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionD_tfidf.getrow(i).T).toarray()[0][0]  )      \n",
        "    df_feaT['sim2I'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionI_tfidf.getrow(i).T).toarray()[0][0]  )      \n",
        "    df_feaT['sim2D'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionD_tfidf.getrow(i).T).toarray()[0][0]  )          \n",
        "    df_feaT['sim11D'] = df_feaT['id'].apply(lambda i: (question1_tfidf.getrow(i)*questionQ1D_tfidf.getrow(i).T).toarray()[0][0] )       \n",
        "    df_feaT['sim22D'] = df_feaT['id'].apply(lambda i: (question2_tfidf.getrow(i)*questionQ2D_tfidf.getrow(i).T).toarray()[0][0] )           \n",
        "    \n",
        "    #df_feaT['cos12'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),question2_tfidf.getrow(i))[0][0]) \n",
        "    #df_feaT['cos1I'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionI_tfidf.getrow(i))[0][0])      \n",
        "    #df_feaT['cos1D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n",
        "    print('similD')      \n",
        "    #df_feaT['cos2I'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionI_tfidf.getrow(i))[0][0])      \n",
        "    #df_feaT['cos2D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])          \n",
        "    #df_feaT['cos11D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question1_tfidf.getrow(i),questionQ1D_tfidf.getrow(i))[0][0])      \n",
        "    #df_feaT['cos22D'] = df_feaT['id'].apply(lambda i: cosine_similarity(question2_tfidf.getrow(i),questionQ2D_tfidf.getrow(i))[0][0])      \n",
        "    print('eucl') \n",
        "    df_feaT['euc12'] = df_feaT['id'].apply(lambda i: euclidean_distances(question1_tfidf.getrow(i),question2_tfidf.getrow(i))[0][0]) \n",
        "    df_feaT['euc1D'] = df_feaT['id'].apply(lambda i: euclidean_distances(question1_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n",
        "    df_feaT['euc2D'] = df_feaT['id'].apply(lambda i: euclidean_distances(question2_tfidf.getrow(i),questionD_tfidf.getrow(i))[0][0])         \n",
        "    print('svd')     \n",
        "    svd = TruncatedSVD(n_components=20, n_iter=30, random_state=42)\n",
        "    tempi=pd.DataFrame(svd.fit_transform(questionI_tfidf))\n",
        "    tempi.rename(columns=lambda x: str(x)+'_i', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_feaT=df_feaT.join(tempi,how='inner')\n",
        "    print('tempi',tempi.shape)\n",
        "    \n",
        "    svd = TruncatedSVD(n_components=20, n_iter=30, random_state=42)\n",
        "    tempd=pd.DataFrame(svd.fit_transform(questionD_tfidf))\n",
        "    tempd.rename(columns=lambda x: str(x)+'_d', inplace=True) #nog eens zoeken omcolumns te renamen\n",
        "    df_feaT=df_feaT.join(tempd,how='inner')\n",
        "    print('tempd',tempd.shape)\n",
        "    \n",
        "    return df_feaT\n",
        "\n",
        "df_train = get_feaT(df_train)\n",
        "end = time.clock()\n",
        "print('tfidf-sim:',len(df_train)*1.0/(end-start))\n",
        "\n",
        "print(df_train.head(10))\n",
        "\n",
        "y=train['is_duplicate']        \n",
        "feats = df_train.columns.values.tolist()\n",
        "feats=[x for x in feats if x not in ['question1','question2','q13g','q23g','inte','diffe','q1di','q2di','id','qid1','qid2','is_duplicate']]\n",
        "print(\"features\",feats)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "faa29386-22a3-0ae9-0332-a72d8a175b3b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "import scipy\n",
        "import xgboost as xgb\n",
        "import difflib\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(df_train[feats], y, test_size=0.1, random_state=0)\n",
        "#XGBoost model\n",
        "params = {\"objective\":\"binary:logistic\",'eval_metric':'logloss',\"max_depth\":7}\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "bst = xgb.train(params, d_train, 2000, watchlist, early_stopping_rounds=200,verbose_eval=25) #change to higher #s\n",
        "print('training done')\n",
        "\n",
        "print(\"log loss for training data set\",log_loss(y, bst.predict(xgb.DMatrix(df_train[feats]))))\n",
        "#Predicting for test data set\n",
        "sub = pd.DataFrame() # Submission data frame\n",
        "sub['test_id'] = []\n",
        "sub['is_duplicate'] = []\n",
        "header=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14748d2a-6e47-958a-4539-c63277af35c2"
      },
      "outputs": [],
      "source": [
        "sub = pd.DataFrame() # Submission data frame\n",
        "sub['test_id'] = []\n",
        "sub['is_duplicate'] = []\n",
        "header=['test_id','question1','question2','id','qid1','qid2','is_duplicate']\n",
        "test=pd.read_csv('../input/test.csv')[:10000].fillna(\"\")\n",
        "test.columns=['id','question1','question2']\n",
        "\n",
        "print(\"cleaning test\")\n",
        "df_test=cleanup(test)\n",
        "print('cleaned',df_test.head())\n",
        "df_test = get_fea(df_test)\n",
        "df_test = get_feaT(df_test)\n",
        "print('engineered',df_test.head())\n",
        "\n",
        "sub=pd.DataFrame({'test_id':df_test['id'], 'is_duplicate':bst.predict(xgb.DMatrix(df_test[feats]))})\n",
        "print(sub.head())\n",
        "\n",
        "sub.to_csv('../quora_submission_svd_xgb.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}