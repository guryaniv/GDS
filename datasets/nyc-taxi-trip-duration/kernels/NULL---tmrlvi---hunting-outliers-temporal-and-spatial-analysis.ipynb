{"cells": [{"metadata": {"_uuid": "9562cf556dbae6ebfaa59f30e9f02e70a9d77379", "collapsed": false, "_cell_guid": "8229b857-4828-4469-951b-4e200158287d", "_execution_state": "idle"}, "outputs": [], "source": "There are many irregularities in the data that we must hunt down in order to improve the prediction. In the following notebook you'll find an analysis of the features that contain most information about the rides - the dates and times of pickup and dropoff, and their location.\nThis analysis emphasize how easy it is to notice some phenomena given the right visualization tool.", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "707e145bdcb57df4a5ab3bb35685c2395b38606c", "_cell_guid": "f52749dc-6574-4ac8-bf1e-e22ecba2213c", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["%pylab inline\n", "import os\n", "import pandas as pd\n", "import seaborn as sns\n", "from haversine import AVG_EARTH_RADIUS"], "execution_count": 1}, {"metadata": {"_uuid": "1652e43083a2719653ff278cbe49fb451d8a01d0", "_cell_guid": "e7ee60b1-2883-4d7a-8557-a5eba2a4858e"}, "outputs": [], "cell_type": "markdown", "source": ["# Loading Data"], "execution_count": null}, {"metadata": {"_uuid": "d0af2e5bdbfb1c791c380f6494b89abfe6c25fc2", "collapsed": true, "_cell_guid": "8f3334a7-7c7c-4adb-b22d-510131f493bd", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": "train = pd.read_csv(\"../input/train.csv\", index_col=0)", "execution_count": 2}, {"metadata": {"_uuid": "1f9a7d2d3a52b1965a73cdfd124659c03ec5dc03", "_cell_guid": "56445355-5c7d-47d3-b27c-d8b7f50abe6f"}, "outputs": [], "cell_type": "markdown", "source": ["In the next bit, we just loat and transform the data a bit. The main new feature I present is the geodesic distance, in kilometers (sorry, I'm metric) using the [haversine](https://en.wikipedia.org/wiki/Haversine_formula) formula\n", "$$\n", "d\\left(x,y\\right) = 2 \\cdot r \\cdot \\arcsin \\left( \\sqrt{ \\sin^2 \\left( \\frac{x_{\\text{lat}} - y_{\\text{lat}}}{2} \\right)  + \\cos\\left(x_{\\text{lat}}\\right)\\cos\\left(y_{\\text{lat}}\\right)\\sin^2 \\left( \\frac{x_{\\text{long}} - y_{\\text{long}}}{2} \\right)}\\right)\n", "$$\n", "\n", "This is done so the values I get later would make more sense."], "execution_count": null}, {"metadata": {"_uuid": "83e5b56fe34918a9adb718c4b901fc44d6293feb", "_cell_guid": "196c33c8-6cab-48ff-84ff-c0ad456c2111", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["train = train.assign(\n", "    pickup_datetime = pd.to_datetime(train.pickup_datetime),\n", "    dropoff_datetime = pd.to_datetime(train.dropoff_datetime),\n", "    vendor_id = train.vendor_id.astype(\"category\"),\n", "    store_and_fwd_flag = train.store_and_fwd_flag.astype(\"category\"),\n", "    passenger_count = train.passenger_count.astype(\"category\", ordered=True),\n", "    dlat = (train.pickup_latitude - train.dropoff_latitude) * pi/180,\n", "    dlong = (train.pickup_longitude - train.dropoff_longitude) * pi/180\n", ").assign(\n", "    euclidean_distance = lambda df: (2* AVG_EARTH_RADIUS*\n", "                                     arcsin(sqrt(square(sin(df.dlat/2)) + \n", "                                            cos(df.pickup_latitude * pi/180) * \n", "                                            cos(df.dropoff_latitude * pi/180) * \n", "                                            square(sin(df.dlong/2)))))\n", ")"], "execution_count": 3}, {"metadata": {"_uuid": "d61c3dadc864db8f97177a3c07256ecdb94af497", "_cell_guid": "0fe91e1d-4572-4239-9982-f2979d1d55ea"}, "outputs": [], "cell_type": "markdown", "source": ["# Initial Cleaning and Summary\n", "\n", "Early plotting reveals blatent outliers, that we want to get rid off for now. Seeing as Manhatten circumference is less than 60km, and that 500,000 seconds is more than five days, I'm pretty certain these values are mistake."], "execution_count": null}, {"metadata": {"_uuid": "f16aef47c51b70b1f2cbcd56df2a9c1ca65fc7b5", "collapsed": true, "_cell_guid": "504a5638-1121-4c75-a34c-4e02afa42a0a", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": "train = train[\n    (train.trip_duration < 500000) &\n    (train.euclidean_distance < 125)\n].copy()", "execution_count": 4}, {"metadata": {"_uuid": "1296172e51e3c9ad85f1dff60d9f62838388862b", "_cell_guid": "c00d1599-a10d-4789-9615-b3594f0774f8", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": "def summary(df, sample_size = None):\n    if sample_size is None or sample_size > len(df):\n        sample_size = len(df)\n    sample = np.random.choice(df.index, size=sample_size, replace=False)\n    fig, axes = plt.subplots(3,3, figsize=(12,12))\n    axes = np.reshape(axes, -1)\n    for index, field in enumerate(['vendor_id', 'passenger_count', 'pickup_longitude', 'pickup_latitude',\n                                   'dropoff_longitude', 'dropoff_latitude', 'trip_duration', 'store_and_fwd_flag',\n                                   'euclidean_distance']):\n        data = df.loc[sample, field]\n        if isinstance(data.dtype, pd.core.dtypes.dtypes.CategoricalDtype):\n            sns.countplot(x=field, data=df.loc[sample, [field]], ax=axes[index])\n        else:\n            sns.violinplot(data=df.loc[sample, [field]], ax=axes[index])\n        axes[index].set_title(field)\n\nsummary(train, 10000)", "execution_count": 5}, {"metadata": {"_uuid": "9649f3d9a4f387d857a66075c01c6576b1169fcf", "_cell_guid": "0589138d-d93f-4c9d-aec8-b2b0759004f8"}, "outputs": [], "cell_type": "markdown", "source": ["From a quick glance at the `trip duration` and `euclidean distance`, it seems some of the data is still a bit off. This might be worth exploring. Lets look at it a little deeper."], "execution_count": null}, {"metadata": {"_uuid": "8a4fad04c1c0e01ca92a58acce90430360f0f9c7", "_cell_guid": "b74a95ac-26f6-4c90-bfb5-6aa5fa12e5f8", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["fig, axes = subplots(1, 2, figsize=(15,5))\n", "train.euclidean_distance.hist(bins=100, ax=axes[0])\n", "axes[0].set_yscale(\"log\")\n", "axes[0].set_title(\"Distance Historgram\")\n", "\n", "train.trip_duration.hist(bins=100, ax=axes[1])\n", "axes[1].set_yscale(\"log\")\n", "_ = axes[1].set_title(\"Trip Duration Historgram\")"], "execution_count": 6}, {"metadata": {"_uuid": "7eece50998151ad0c0721061ef4962f53444a295", "_cell_guid": "f6444baf-939f-45cf-86cd-1a584c0a47d4"}, "outputs": [], "cell_type": "markdown", "source": ["# Exploring Temporal Fields"], "execution_count": null}, {"metadata": {"_uuid": "ec069ec9cebc09346477ddff2f077a7c825704a5", "_cell_guid": "738ab2db-9f9c-4daf-9755-dfdc9062402c"}, "outputs": [], "cell_type": "markdown", "source": ["Ok, so I can't say anything new about the distance. Howver, the `trip duration` variable is very odd. Recall that the `trip duration` is calculated by `dropoff_datetime - pickup_datetime`. Maybe we can visualize it in a smarter way? Let's try to visualize all the average speed throught the week."], "execution_count": null}, {"metadata": {"_uuid": "d24f741be12c3b8706b82f80ee1c8fe64c8f971a", "_cell_guid": "8e18681e-7a13-484c-b61e-ffaf2f29046a", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["DAY_NAME = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n", "\n", "def weekday_hour_table(df, func):\n", "    \"\"\"\n", "    df - the dataframe to summaries\n", "    func - function for calculating the values for each pair of pickup-dropoff times\n", "    \"\"\"\n", "    df = df.groupby(\n", "        [\n", "            df.pickup_datetime.apply(lambda dt: (dt.weekday(), dt.hour)),\n", "            df.dropoff_datetime.apply(lambda dt: (dt.weekday(), dt.hour)),\n", "        ]\n", "    ).apply(func).unstack()\n", "    df.index = [\"%s %d\" % (DAY_NAME[day], hour) for day, hour in df.index]\n", "    df.columns = [\"%s %d\" % (DAY_NAME[day], hour) for day, hour in df.columns]\n", "    return df\n", "\n", "def median_of_average_ride_speed(group):\n", "    return (group.euclidean_distance / group.trip_duration).median()\n", "\n", "traffic_by_day = weekday_hour_table(train, median_of_average_ride_speed)\n", "figsize(15,15)\n", "ax = sns.heatmap(log(traffic_by_day+1e-7), xticklabels=2, yticklabels=2)\n", "_= xticks(rotation=90)"], "execution_count": 7}, {"metadata": {"_uuid": "dcb1dde5a4accd7b1fc74f748be713d1ee86d927", "_cell_guid": "d4bb1c03-20ad-48dc-aa58-24335feb1381"}, "outputs": [], "cell_type": "markdown", "source": ["Whoa. There is something regularly strange there. We see two phenomena. the first is each day at midnight, many rides are closed (dropoff marked). The second is \"ghost rides\", rides that take 20-23 hours. Remember the histogram? They probably match the increase in frequency of longer rides.\n", "\n", "Let's try to figure out what it is all about. Seems it would be easy to begin with the midnight ends. Technically, we'd plot a summary of all the restricted dataset, but I like to jump to the end."], "execution_count": null}, {"metadata": {"_uuid": "c3c4b766674fbb0dfd471c536e63a6a096dc2509", "_cell_guid": "589cf4e5-ea0e-4ae7-9b7f-0b6fa2a1e9e8", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["figsize(15,5)\n", "df = train[\n", "    (train.dropoff_datetime.dt.hour == 0) &\n", "    (train.dropoff_datetime.dt.minute == 0) &\n", "    (train.dropoff_datetime.dt.second == 0)\n", "]\n", "sample = np.random.choice(df.index, size=min(10000, len(df)), replace=False)\n", "_ = sns.stripplot(y=\"trip_duration\", x=\"vendor_id\", data=df.loc[sample].copy(), jitter=True)"], "execution_count": 8}, {"metadata": {"_uuid": "7bbe2dfb48a09d5e2f7e1f107da5e9f3ca6f2a14", "_cell_guid": "fa623415-d27d-44ef-9c60-11ff65acd2dc"}, "outputs": [], "cell_type": "markdown", "source": ["So, we can blame `vendor_id` 2 in all this mess. I wonder how the heatmap looks without them?"], "execution_count": null}, {"metadata": {"_uuid": "1516c0ef7a5950c5730f0969a29dac343689c1b4", "_cell_guid": "af158ba1-ff31-4d12-bd1a-64ba52c4950d", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["traffic_by_day = weekday_hour_table(train[train.vendor_id == 1], median_of_average_ride_speed)\n", "figsize(15,10)\n", "ax = sns.heatmap(log(traffic_by_day+1e-7), xticklabels=2, yticklabels=2)\n", "_= xticks(rotation=90)"], "execution_count": 9}, {"metadata": {"_uuid": "a14b5a60abc7c393fb4bf723851dc8d4bc052fa0", "_cell_guid": "dc5072c8-bafe-4059-8ea2-c4f75828df8b"}, "outputs": [], "cell_type": "markdown", "source": ["Much cleaner. Those with a sharp eye will notice an outlier there (recall that light color means really slow ride). We'll deal with it later. "], "execution_count": null}, {"metadata": {"_uuid": "9c72e33ef73737369be2694fd42e1f292cff202f", "_cell_guid": "5edb02fa-2a43-49d2-b542-7d24f517016c"}, "outputs": [], "cell_type": "markdown", "source": ["# Exploring Spatial Fields"], "execution_count": null}, {"metadata": {"_uuid": "d63199e660465003008ed62650c3289428a111e5", "_cell_guid": "97abdf0a-43b3-43f2-acc0-7708542c6634"}, "outputs": [], "cell_type": "markdown", "source": ["We'll begin by removing the outliers (so we can trust the durations. At least those that are far from zero."], "execution_count": null}, {"metadata": {"_uuid": "b7fba654e2e6f1e718da0cc10fc9fa3d17d6d1ba", "_cell_guid": "89eaaec4-95f5-4442-81b8-4ab65acf951d", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["outliers = (\n", "    ((\n", "        (train.vendor_id == 2) &\n", "        (train.dropoff_datetime.dt.hour == 0) &\n", "        (train.dropoff_datetime.dt.minute == 0) &\n", "        (train.dropoff_datetime.dt.second == 0)\n", "    ) |\n", "    (\n", "        train.trip_duration > 40000\n", "    ) | \n", "    (\n", "        train.euclidean_distance == 0\n", "    ))\n", ")\n", "train = train[~outliers].copy()"], "execution_count": 10}, {"metadata": {"_uuid": "0d2497384f0b0dd528f2349cfa6130216074d4cc", "_cell_guid": "ef1ac8e1-0013-4cfa-81b7-72d5fd8e9d5f", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["fig, axes = subplots(1, 2, figsize=(15,5))\n", "train.euclidean_distance.hist(bins=100, ax=axes[0])\n", "(train[\"euclidean_distance\"] / (train[\"trip_duration\"]/3600)).hist(bins=200, ax=axes[0])\n", "axes[0].set_yscale(\"log\")\n", "axes[0].set_title(\"KM Per Hour Historgram\")\n", "\n", "((train[\"trip_duration\"]/3600) / train[\"euclidean_distance\"]).hist(bins=200, ax=axes[1])\n", "axes[1].set_yscale(\"log\")\n", "_ = axes[1].set_title(\"Hour Per KM Historgram\")"], "execution_count": 11}, {"metadata": {"_uuid": "45dd2446cf8bb681563218c73993aec621fd2361", "_cell_guid": "fab13803-d792-4ca3-80c1-c4679d151ffc"}, "outputs": [], "cell_type": "markdown", "source": ["Okay. Some of the speeds are really not reasonable. 8000 kmph? I mean, come on! (Or 800 hours for one km? Makes no sense). In general, the hour per kilometer figure is strange. So many rides that take more than an two hours per kilometer? Why don't people just walk?"], "execution_count": null}, {"metadata": {"_uuid": "d1904dfba86b3381e03fe1c4e521ab4fcfb12b08", "_cell_guid": "9f00fa6e-b98d-4341-9aad-b6c95927deb4", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["too_fast = ((train[\"euclidean_distance\"] / (train[\"trip_duration\"]/3600)) > 300)\n", "too_slow = ((train[\"euclidean_distance\"] / (train[\"trip_duration\"]/3600)) < 0.5)\n", "# Removing some outliers to make the plot clearer\n", "not_too_far = (train[\"pickup_latitude\"] > 40) &  (train[\"pickup_longitude\"] > -76)\n", "\n", "#Plotting\n", "with_speed = train[(too_fast | too_slow) & not_too_far].copy()\n", "with_speed[\"fast\"] = too_fast\n", "_ = sns.lmplot(x='pickup_longitude', y='pickup_latitude', hue=\"fast\", markers='.', size=10, \n", "               fit_reg=False, data=with_speed)"], "execution_count": 12}, {"metadata": {"_uuid": "190fdbe2e30790af1ec7e44e2e51e5d3f2dea8e5", "_cell_guid": "3ed96ab8-3f77-4b3d-97b1-ac5e748cb71c"}, "outputs": [], "cell_type": "markdown", "source": ["A close examination (plotting on real map, i.e. with gmaps module) reveals that most of the points are valid. (Long Island, Philadelphia and other areas. Although, there is one point in the middle of the ocean.) Many of the rides are one very short distances, and it seems it was a mistake in entering the time of the location of the ride.\n", "\n", "For now, I haven't found a cause of the mistake, so I'm goning to treat everyting as an outlier. At least let's clean it up."], "execution_count": null}, {"metadata": {"_uuid": "4a574a89c020137588870147bd7155ff1b043491", "collapsed": true, "_cell_guid": "016b9022-04f2-42f0-8a4a-62a7bede8788", "_execution_state": "idle"}, "outputs": [], "cell_type": "code", "source": ["train = train[~too_fast & ~too_slow].copy()"], "execution_count": 13}], "nbformat_minor": 2, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.5.2"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}