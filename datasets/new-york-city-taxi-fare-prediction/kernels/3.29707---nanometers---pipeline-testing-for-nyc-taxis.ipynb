{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport dask.dataframe as dd\nfrom tqdm import tqdm\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nTRAIN_PATH = '../input/train.csv'\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1467458dd082b469a73d1100219479d508b52a5"},"cell_type":"code","source":"%%time\n# Counting the number of rows in dataframe\n\n# Same method but more 'pythonic'\nimport subprocess\n\ndef file_len(fname):\n    p = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE, \n                                              stderr=subprocess.PIPE)\n    result, err = p.communicate()\n    if p.returncode != 0:\n        raise IOError(err)\n    return int(result.strip().split()[0])+1\n\nn_rows = file_len(TRAIN_PATH)\nprint (f'Exact number of rows: {n_rows}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6358b9bc419169a7ede548ede48f7ea0bfe64de9"},"cell_type":"code","source":"# Set columns to most suitable type to optimize for memory usage\ntraintypes = {'fare_amount': 'float32',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'uint8'}\n\ncols = list(traintypes.keys())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31afb2f1cb07ff25b876a6e9a1b345fcb6ea9e01"},"cell_type":"markdown","source":"# batching\n%%time\ndf_list = [] # list to hold the batch dataframe\n\nfor df_chunk in tqdm(pd.read_csv(TRAIN_PATH, usecols=cols, dtype=traintypes, chunksize=chunksize)):\n     \n    # Neat trick from https://www.kaggle.com/btyuhas/bayesian-optimization-with-xgboost\n    # Using parse_dates would be much slower!\n    df_chunk['pickup_datetime'] = df_chunk['pickup_datetime'].str.slice(0, 16)\n    df_chunk['pickup_datetime'] = pd.to_datetime(df_chunk['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n    \n    # Can process each chunk of dataframe here\n    # clean_data(), feature_engineer(),fit()\n    \n    # Alternatively, append the chunk to list and merge all\n    df_list.append(df_chunk) \n   \n   # Merge all dataframes into one dataframe\ntrain_df = pd.concat(df_list)\n\n# Delete the dataframe list to release memory\ndel df_list\n\n# See what we have loaded\ntrain_df.info()"},{"metadata":{"trusted":true,"_uuid":"40a9667ddd5d8757ae9ea554fc8858c59ac92881"},"cell_type":"code","source":"%%time\n\n# using panda read_csv to read the entire file in one shot\n# df = pd.read_csv(TRAIN_PATH, usecols=cols, dtype=traintypes)\ntrain = pd.read_csv(TRAIN_PATH, usecols=cols, dtype=traintypes, nrows = 5000000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cddcbc76c37694571562857b05fe340d33020e4"},"cell_type":"code","source":"# df.head()\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29a7771377e27f8db746ece6ef75e64e52cc684b"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"add82e9fefba94ddfe6c67a636d2b31818e7cdf7"},"cell_type":"code","source":"# Can see above that there is somehow an entry with 208? passengers. A plane? Haha. Also, somehow a negative fare. \n# Let's get rid of entries with negative fares and passengers that are too large.\nprint(\"old size: %d\" % len(train))\ntrain = train[train.fare_amount >=0]\nprint(\"New size: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0652a7ae8f6e7d2971ebe5f074fbafc7e3ed0cf"},"cell_type":"code","source":"# check missing data\ntrain.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45273f91e78e521341fc96fc4cdf4abf465afe41"},"cell_type":"code","source":"# Delete the null lat/long entries.\nprint(\"old size: %d\" % len(train))\ntrain = train.dropna(how='any', axis=0)\nprint(\"New size after dropping missing value: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf784530f432dace0566a89e5147c8aa4c98cd77"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\n\nplt.style.use('seaborn-whitegrid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9c8515d1831d1bd0a21ab818c0da964f5150247"},"cell_type":"code","source":"# checking for passenger count greater than 7\ntrain[train.passenger_count >7].passenger_count.hist(bins=10, figsize = (16,8))\nplt.xlabel(\"Passenger Count\")\nplt.ylabel(\"Frequency\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a777e0cd2881060d5e61f8bd4a80b059a4306c6"},"cell_type":"code","source":"# Plotting boxplots for <= 7 passengers.\nplt.figure(figsize= (16,8))\nsns.boxplot(x = train[train.passenger_count< 8].passenger_count, y = train.fare_amount)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f85849e1eb8cadfd766338233739a2bbbe894595"},"cell_type":"code","source":"# Looking at correlation of fare_amount and passenger_count - wondering why there are 0 passengers for entries\ntrain[train.passenger_count <7][['fare_amount','passenger_count']].corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afc04b9ac7c87cc96bc66396da4db3faa0550e49"},"cell_type":"code","source":"# Time to look over test file\ntest = pd.read_csv(\"../input/test.csv\")\nprint(\"shape of test data\", test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f602162be25f5dc3b398e474cf46e9a0f14d2da0"},"cell_type":"code","source":"test.isnull().sum()\n# No null data - how nice of our test set\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ba0b9305b16211a8702cdd87540a3fc1277802"},"cell_type":"code","source":"# Test set min/max dropoffs and pickups\nmin(test.pickup_longitude.min(),test.dropoff_longitude.min()), \\\nmax(test.pickup_longitude.max(),test.dropoff_longitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86916c37aafdc0aa2699fafde957628e978a2d07"},"cell_type":"code","source":"min(test.pickup_latitude.min(),test.dropoff_latitude.min()), \\\nmax(test.pickup_latitude.max(),test.dropoff_latitude.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cc02a5b89739d6c18f8c23242520a581193e576"},"cell_type":"code","source":"# this function will also be used with the test set below\ndef select_within_test_boundary(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ac0e2a2f90a51574f626dbec3148dc2be8f17a0"},"cell_type":"code","source":"BB = (-74.5, -72.8, 40.5, 41.8)\nprint('Old size: %d' % len(train))\ntrain = train[select_within_test_boundary(train, BB)]\nprint('New size: %d' % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b932cac6e9d74b74846493e20fb651d512f6403a"},"cell_type":"code","source":"# Going through time features\ndef prepare_time_features(df):\n    df['pickup_datetime'] = df['pickup_datetime'].str.slice(0, 16)\n    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n    df['hour_of_day'] = df.pickup_datetime.dt.hour\n#     df['week'] = df.pickup_datetime.dt.week\n    df['month'] = df.pickup_datetime.dt.month\n    df[\"year\"] = df.pickup_datetime.dt.year\n#     df['day_of_year'] = df.pickup_datetime.dt.dayofyear\n#     df['week_of_year'] = df.pickup_datetime.dt.weekofyear\n    df[\"weekday\"] = df.pickup_datetime.dt.weekday\n#     df[\"quarter\"] = df.pickup_datetime.dt.quarter\n#     df[\"day_of_month\"] = df.pickup_datetime.dt.day\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3cc22489e6b5e6dba3af1a22ef448de24bef4586"},"cell_type":"code","source":"train = prepare_time_features(train)\ntest = prepare_time_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8378addde48d8a3dfe512c79481e32673bd9a9cb"},"cell_type":"code","source":"# calculate distance between two latitude, longitude points haversine (spherical) formula \n# Returns distance in miles\ndef distance(lat1, lon1, lat2, lon2):\n    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))   # 2*R*asin...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d184e7daa56805289bd9b777a5c8aea12214d38"},"cell_type":"code","source":"train['distance_miles'] = distance(train.pickup_latitude, train.pickup_longitude, \\\n                                      train.dropoff_latitude, train.dropoff_longitude)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5a05f90b3fa4692bd99cd06a36876dbe4ca477"},"cell_type":"code","source":"test['distance_miles'] = distance(test.pickup_latitude, test.pickup_longitude, \\\n                                      test.dropoff_latitude, test.dropoff_longitude)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e6d807a53605dd26675e42427c9ee010cad77a5"},"cell_type":"code","source":"# Airport distances for NYC\ndef transform(data):\n    # Distances to nearby airports, \n    jfk = (-73.7781, 40.6413)\n    ewr = (-74.1745, 40.6895)\n    lgr = (-73.8740, 40.7769)\n\n    data['pickup_distance_to_jfk'] = distance(jfk[1], jfk[0],\n                                         data['pickup_latitude'], data['pickup_longitude'])\n    data['dropoff_distance_to_jfk'] = distance(jfk[1], jfk[0],\n                                           data['dropoff_latitude'], data['dropoff_longitude'])\n    data['pickup_distance_to_ewr'] = distance(ewr[1], ewr[0], \n                                          data['pickup_latitude'], data['pickup_longitude'])\n    data['dropoff_distance_to_ewr'] = distance(ewr[1], ewr[0],\n                                           data['dropoff_latitude'], data['dropoff_longitude'])\n    data['pickup_distance_to_lgr'] = distance(lgr[1], lgr[0],\n                                          data['pickup_latitude'], data['pickup_longitude'])\n    data['dropoff_distance_to_lgr'] = distance(lgr[1], lgr[0],\n                                           data['dropoff_latitude'], data['dropoff_longitude'])\n    \n    return data\n\ntrain = transform(train)\ntest = transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b2b73e8ceaa36c60f90b65009a7c563996810e8"},"cell_type":"code","source":"# train[(train['distance_miles']==0)&(train['fare_amount']==0)]\n# Deleting the distances & fares equal to 0.\nprint(\"old size: %d\" % len(train))\ntrain = train.drop(index= train[(train['distance_miles']==0)&(train['fare_amount']==0)].index, axis=0)\nprint(\"New size: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b1c679971e97e177446879ec989f72c8809b2c3"},"cell_type":"code","source":"# How many with $0 fares but distances > 0\ntrain[train['fare_amount']==0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"477f92b33c047025ebc7a45cc406d80793cd003f"},"cell_type":"code","source":"print(\"old size: %d\" % len(train))\ntrain = train.drop(index= train[train['fare_amount']==0].index, axis=0)\nprint(\"New size: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51367259d6aa12e04c509abbd0998f3d23d8f8a7"},"cell_type":"code","source":"# Initial costs, so these aren't typical\ntrain[train['fare_amount'] < 2.5].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b59bfd1e606827b2b7617e5c6e412d761e9a0ebb"},"cell_type":"code","source":"print(\"old size: %d\" % len(train))\ntrain = train.drop(index= train[train['fare_amount'] < 2.5].index, axis=0)\nprint(\"New size: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e102c7177750711295e20ccb70c550aedb98b4a0"},"cell_type":"code","source":"# Deleting all remaining cases greater than 7 passengers\nprint(\"old size: %d\" % len(train))\ntrain = train.drop(index= train[train.passenger_count >= 7].index, axis=0)\nprint(\"New size: %d\" % len(train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a874d1403a06c2b5e7bf4ce708da75675fb6b330"},"cell_type":"code","source":"# What's distribution of distances that are covered now?\npd.cut(train['distance_miles'],np.linspace(0, 70, num = 8)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c34df305480be6af18c1e26b4ecbc73e300e8cc4"},"cell_type":"code","source":"# Now the test cases\npd.cut(test['distance_miles'],np.linspace(0, 70, num = 8)).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d21e6c127529fad8a51acce3d844540c192bc624"},"cell_type":"code","source":"# Starting to get to the data set to train/test split\ntrain.columns\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d354ad91a6c982c5f88b7df2ef206000269f42"},"cell_type":"code","source":"# create copy of the data set\ndf_train = train.drop(columns= ['pickup_datetime'], axis= 1).copy()\ndf_test = test.drop(columns= ['key','pickup_datetime'], axis= 1).copy()\nprint(df_train.shape)\nprint(df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e54065433860aeee961a6e78ede79e708b5a6cfb"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(df_train.drop('fare_amount', axis=1),\n                                                    df_train['fare_amount'], test_size=0.2, random_state = 42)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"895ea74c228c8a5a6cd0420b153c4edd6f655b5f"},"cell_type":"code","source":"import xgboost as xgb\nparams = {\n    'max_depth': 7,\n    'gamma' :0,\n    'eta':.03, \n    'subsample': 1,\n    'colsample_bytree': 0.9, \n    'objective':'reg:linear',\n    'eval_metric':'rmse',\n    'silent': 0\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eb7d7e0405913193c2af133feeb9f72ae81e04c"},"cell_type":"code","source":"def XGBmodel(X_train,X_test,y_train,y_test,params):\n    matrix_train = xgb.DMatrix(X_train,label=y_train)\n    matrix_test = xgb.DMatrix(X_test,label=y_test)\n    model=xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=10,evals=[(matrix_test,'test')])\n    return model\n\nmodel = XGBmodel(X_train,X_test,y_train,y_test,params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c5d200ecc0964c14f6a8722ecfecb75456bb3c"},"cell_type":"code","source":"prediction = model.predict(xgb.DMatrix(df_test), ntree_limit = model.best_ntree_limit).tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b19158f83301811522a348522bdb8e3f44cae48d"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\nholdout = pd.DataFrame({'key': test['key'], 'fare_amount': prediction})\nholdout.to_csv('xgb_with4mtrainedrows.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"433c6b200383144887370c237e0f10a9f938683e"},"cell_type":"code","source":"# del df\n# testdata = pd.read_csv('../input/test.csv')\n# testdata.head()\n# traindata = pd.read_csv('../input/train.csv')\n# traindata.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# from sklearn.ensemble import RandomForestRegressor\n# from sklearn.pipeline import make_pipeline\n# from sklearn.impute import SimpleImputer\n# my_pipeline = make_pipeline(SimpleImputer(), RandomForestRegressor())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dac114516c8dbdfc66ac7ee3e903812e439314d"},"cell_type":"code","source":"#my_pipeline.fit(train_X, train_y)\n# predictions = my_pipeline.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b28fa652869adadcd91b0ac20b20b15e80245a6"},"cell_type":"code","source":"#predictions","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}