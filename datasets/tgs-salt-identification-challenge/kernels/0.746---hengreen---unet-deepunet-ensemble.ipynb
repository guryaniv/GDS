{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51000e12ba27c6a235ebff6e203ddab8cb60cf2b"},"cell_type":"code","source":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9563d915d7019e46ea7370087ee7666257304dc8"},"cell_type":"code","source":"# Set some parameters\nimg_size_ori = 101\nimg_size_target = 101\nim_width = 101\nim_height = 101\nim_chan = 1\nbasicpath = '../input/'\npath_train = basicpath + 'train/'\npath_test = basicpath + 'test/'\n\npath_train_images = path_train + 'images/'\npath_train_masks = path_train + 'masks/'\npath_test_images = path_test + 'images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"700fb9ff8bfa4c50c8ae3f0184123fe2dc17eed3"},"cell_type":"code","source":"# Loading of training/testing ids and depths\n\ntrain_df = pd.read_csv(\"../input/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71224c5d3e6f8c0b447f46f13199b86c4ec5889e"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(\"../input/train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e6de0ae9e05aaee622e48097f51962324ca35a0"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(\"../input/train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6d2dc3c6b6222cf7a9f5edffc0e45cc14e42f72"},"cell_type":"markdown","source":"# Calculating the salt coverage and salt coverage classes"},{"metadata":{"_uuid":"6e18f73cb0a7fe7f13c8548471381203f4386dcc"},"cell_type":"markdown","source":" #### Counting the number of salt pixels in the masks and dividing them by the image size. Also create 11 coverage classes, -0.1 having no salt at all to 1.0 being salt only. Plotting the distribution of coverages and coverage classes, and the class against the raw coverage."},{"metadata":{"trusted":true,"_uuid":"430568d0b7917dd8a901b3bac328ee80237c3983"},"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38d1c0932315a35bb49bc7728d34c105bcb3630f"},"cell_type":"code","source":"def cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d19bdf77e4ffe5ed7071f97b35436ed75c6b199","scrolled":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47edf2fbe6eed2d8e5bd6f116f6203c37eec02b2"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0])\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5d10c4d8c01374dfaa8b8fec8bcb571942df0c5"},"cell_type":"code","source":"# Create train/validation split stratified by salt coverage\n\nids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"336e75f4b45dfb47afe117c82e4ae08bf3947fd9"},"cell_type":"code","source":"depth_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"881d101e07efceb71643ee4979a912927a78363f"},"cell_type":"code","source":"ACTIVATION = \"relu\"\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    if activation == True:\n        x = Activation(ACTIVATION)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16):\n    x = Activation(ACTIVATION)(blockInput)\n    x = BatchNormalization()(x)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21561ee7472c5723477014a77777bfa6d876de9c"},"cell_type":"code","source":"# DeepUnet model\ndef build_DeepUnet_model(inputs):\n    # 101 -> 50\n    down0 = Conv2D(64, (3, 3), padding='same')(inputs)\n    down0 = BatchNormalization()(down0) #\n    down0 = Activation('relu')(down0)\n    down0 = Conv2D(32, (3, 3), padding='same')(down0)\n    down0 = BatchNormalization()(down0) #\n    down0 = Activation('relu')(down0)\n    plus_0 = Conv2D(32, (2, 2), padding='same')(down0)\n    down0 = Add()([down0,inputs]) #\n    down0 = MaxPooling2D((2, 2), strides=(2, 2))(down0)\n    down0 = Dropout(0.25)(down0) #\n    down0 = Activation('relu')(down0)\n\n    # 50 -> 25\n\n    down1 = Conv2D(64, (3, 3), padding='same')(down0)\n    down1 = BatchNormalization()(down1) #\n    down1 = Activation('relu')(down1)\n    down1 = Conv2D(32, (3, 3), padding='same')(down1)\n    down1 = BatchNormalization()(down1) #\n    plus_1 = concatenate([down1, down0], axis=3)\n    down1 = Add()([down1, down0]) #\n    down1= MaxPooling2D((2, 2), strides=(2, 2))(down1)\n    down1 = Dropout(0.5)(down1) #\n    down1 = Activation('relu')(down1)\n    \n\n    # 25 -> 12\n\n    down2 = Conv2D(64, (3, 3), padding='same')(down1)\n    down2 = BatchNormalization()(down2) #\n    down2 = Activation('relu')(down2)\n    down2 = Conv2D(32, (2, 2), padding='same')(down2)\n    down2 = BatchNormalization()(down2) #\n    plus_2 = concatenate([down2, down1], axis=3)\n    down2 = Add()([down2, down1]) #\n    down2 = MaxPooling2D((2, 2), strides=(2, 2))(down2)\n    down2 = Dropout(0.5)(down2) #\n    down2 = Activation('relu')(down2)\n\n    # 12 -> 6\n\n    down3 = Conv2D(64, (3, 3), padding='same')(down2)\n    down3 = BatchNormalization()(down3) #\n    down3 = Activation('relu')(down3)\n    down3 = Conv2D(32, (2, 2), padding='same')(down3)\n    down3 = BatchNormalization()(down3) #\n    plus_3 = concatenate([down3, down2], axis=3)\n    down3 = Add()([down3,down2]) #\n    down3 = MaxPooling2D((2, 2), strides=(2, 2))(down3)\n    down3 = Dropout(0.5)(down3) #\n    down3 = Activation('relu')(down3)\n\n    # 6 - > 12\n    up4 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"same\")(down3)\n\n    # 12 -> 25\n\n    up3 = concatenate([up4, plus_3], axis=3)\n    up3 = Dropout(0.5)(up3) #\n    up3 = Conv2D(64, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3) #\n    up3 = Activation('relu')(up3)\n    up3 = Conv2D(32, (3, 3), padding='same')(up3)\n    up3 = BatchNormalization()(up3) #\n    #up3 = concatenate([up3, up4], axis=3)\n    up3 = Add()([up3,up4]) #\n    up3 = Activation('relu')(up3)\n    up3 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"valid\")(up3)\n\n    # 25 -> 50\n\n    up2 = concatenate([up3, plus_2], axis=3)\n    up2 = Dropout(0.5)(up2) #\n    up2 = Conv2D(64, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2) #\n    up2 = Activation('relu')(up2)\n    up2 = Conv2D(32, (3, 3), padding='same')(up2)\n    up2 = BatchNormalization()(up2) #\n    #up2 = concatenate([up2, up3], axis=3)\n    up2 = Add()([up2,up3]) #\n    up2 = Activation('relu')(up2)\n    up2 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"same\")(up3)\n\n    # 50 -> 101\n\n    up1 = concatenate([up2, plus_1], axis=3)\n    up1 = Dropout(0.5)(up1) #\n    up1 = Conv2D(64, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1) #\n    up1 = Activation('relu')(up1)\n    up1 = Conv2D(32, (3, 3), padding='same')(up1)\n    up1 = BatchNormalization()(up1) #\n    #up1 = concatenate([up1, up2], axis=3)\n    up1 = Add()([up1,up2]) #\n    up1 = Activation('relu')(up1)\n    up1 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding=\"valid\")(up1)\n\n    up1 = Dropout(0.25)(up1) #\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(up1)\n    model = Model(input_layer, output_layer)\n    return model   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fc4ba52d363e11e7753b0fa77ebea36fda2961c"},"cell_type":"code","source":"# Build Unet model\ndef build_Unet_model(input_layer, start_neurons, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = Activation(ACTIVATION)(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = Activation(ACTIVATION)(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = Activation(ACTIVATION)(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = Activation(ACTIVATION)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = Activation(ACTIVATION)(convm)\n    \n    # 6 -> 12\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(DropoutRatio)(uconv4)\n    \n    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = residual_block(uconv4,start_neurons * 8)\n    uconv4 = Activation(ACTIVATION)(uconv4)\n    \n    # 12 -> 25\n    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])    \n    uconv3 = Dropout(DropoutRatio)(uconv3)\n    \n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = residual_block(uconv3,start_neurons * 4)\n    uconv3 = Activation(ACTIVATION)(uconv3)\n\n    # 25 -> 50\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n        \n    uconv2 = Dropout(DropoutRatio)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = residual_block(uconv2,start_neurons * 2)\n    uconv2 = Activation(ACTIVATION)(uconv2)\n    \n    # 50 -> 101\n    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    \n    uconv1 = Dropout(DropoutRatio)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = residual_block(uconv1,start_neurons * 1)\n    uconv1 = Activation(ACTIVATION)(uconv1)\n    \n    uconv1 = Dropout(DropoutRatio/2)(uconv1)\n    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    model = Model(input_layer, output_layer)\n    return model #output_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a74b9d7fe5feb8407493f656c038a68be1237d82"},"cell_type":"code","source":"iou_thresholds = np.array([0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95])\n\ndef iou(img_true, img_pred):\n    i = np.sum((img_true*img_pred) >0)\n    u = np.sum((img_true + img_pred) >0)\n    if u == 0:\n        return u\n    return i/u\n\ndef iou_metric(imgs_true, imgs_pred):\n    num_images = len(imgs_true)\n    scores = np.zeros(num_images)\n    \n    for i in range(num_images):\n        if imgs_true[i].sum() == imgs_pred[i].sum() == 0:\n            scores[i] = 1\n        else:\n            scores[i] = (iou_thresholds <= iou(imgs_true[i], imgs_pred[i])).mean()\n            \n    return scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"234f47d2afe9a0bb3ddd309d796364ca865a95c5"},"cell_type":"code","source":"#Data augmentation\nx_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\nprint(x_train.shape)\nprint(y_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daf3d23be22e3fafd034e57569dac1c73bfec392"},"cell_type":"code","source":"def compile_and_train(model, epochs,batch_size,model_name): \n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n    early_stopping = EarlyStopping(monitor='val_acc', mode = 'max',patience=20, verbose=1)\n    model_checkpoint = ModelCheckpoint(\"./\" + model_name + \"_best.model\",monitor='val_acc', \n                                   mode = 'max', save_best_only=True, verbose=1)\n    #model_checkpoint = ModelCheckpoint(\"./\" + model_name + \"_best.h5\",monitor='val_acc', \n    #                               mode = 'max', save_weights_only=True, save_best_only=True, period=1, verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode = 'max',factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n\n    #checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1)\n    #tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n    #history = model.fit(x=x_train, y=y_train, batch_size=32, epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n    history = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr], \n                    verbose=1)\n    return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"099bd57b1c7b7355835f6c3792bfa26e6bcdbb0b"},"cell_type":"code","source":"input_layer = Input((img_size_target, img_size_target, 1))\nUnet_model = build_Unet_model(input_layer, 16,0.5)\n\nhistory_unet = compile_and_train(Unet_model, 200, 32,\"Unet\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8600766defa08c78beb21be007612fa093078d6b"},"cell_type":"code","source":"input_layer = Input((img_size_target, img_size_target, 1))\nDeepUnet_model = build_DeepUnet_model(input_layer)\nhistory_deepunet = compile_and_train(DeepUnet_model, 50, 32,\"DeepUnet\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db5bcee145d2e72b949629dac6d3e2103c996d45"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# summarize history for loss\nplt.plot(history_unet.history['acc'][1:])\nplt.plot(history_unet.history['val_acc'][1:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73a052a7f3fac137a8ac8c27aa9e36a24ef2cccb"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# summarize history for loss\nplt.plot(history_deepunet.history['acc'][1:])\nplt.plot(history_deepunet.history['val_acc'][1:])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train','Validation'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13620727b5ed9ec7ee0fbb1c91316999eb85fdbd"},"cell_type":"code","source":"fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history_unet.epoch, history_unet.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history_unet.epoch, history_unet.history[\"val_loss\"], label=\"Validation loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3368b9ad5f0a03d64ec884f4f5db4160a1d287b4"},"cell_type":"code","source":"fig, (ax_loss, ax_acc) = plt.subplots(1, 2, figsize=(15,5))\nax_loss.plot(history_deepunet.epoch, history_deepunet.history[\"loss\"], label=\"Train loss\")\nax_loss.plot(history_deepunet.epoch, history_deepunet.history[\"val_loss\"], label=\"Validation loss\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d75a9b1a985f319d6f09decb11d2c3d98fbd1529"},"cell_type":"code","source":"def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n    preds_test += np.array([ np.fliplr(a) for a in model.predict(np.array([np.fliplr(x) for x in x_test])).reshape(-1, img_size_target, img_size_target)])\n    return preds_test/2.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffa58c1221e50876afe31c839c800a64a23065c5"},"cell_type":"code","source":"preds_valid = predict_result(DeepUnet_model,x_valid,img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4217f7d7fe327a7a56e682560bb4fe77bf84b17"},"cell_type":"code","source":"def filter_image(img):\n    if img.sum() < 100:\n        return np.zeros(img.shape)\n    else:\n        return img\n\n## Scoring for last model\nthresholds = np.linspace(0.3, 0.7, 31)\nious = np.array([iou_metric(y_valid.reshape((-1, img_size_target, img_size_target)), [filter_image(img) for img in preds_valid > threshold]) for threshold in tqdm_notebook(thresholds)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8190f45c32e4cac9da2cd5bc3cce0a86c6819e3a"},"cell_type":"code","source":"threshold_best_index = np.argmax(ious) \niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f96318b2c88c179f2a73ca54a88ecd30b21a1f3"},"cell_type":"code","source":"def rle_encode(im):\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b9a0d2995f1b1d1146d137d1b4d9a121302470e"},"cell_type":"code","source":"import gc\n\ndel x_train, x_valid, y_train, y_valid, preds_valid\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6952d6acd0eb522deab65ff6977fd2462fac862"},"cell_type":"code","source":"x_test = np.array([(np.array(load_img(\"../input/test/images/{}.png\".format(idx), grayscale = True))) / 255 for idx in tqdm_notebook(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)\n\n#preds_test = predict_result(model,x_test,img_size_target)\npreds_test_unet = predict_result(Unet_model,x_test,img_size_target)\npreds_test_deepunet = predict_result(DeepUnet_model,x_test,img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad445f0466270900021d78c58508d1ca0ab1f360"},"cell_type":"code","source":"preds_test_unet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4c8c5081ba23edcb22279c0ddd03146366e6181"},"cell_type":"code","source":"preds_test_deepunet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67dcca87fdd7ed69d0a978ab2c971d86912d0ffe"},"cell_type":"code","source":"# take the average of the models - ensemble\npreds_test  = np.mean([preds_test_unet, preds_test_deepunet], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee0fab70c49933cd262bc66844eda1cf8e9bcbea"},"cell_type":"code","source":"preds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ecaae6e9f616ef44fd5629e9fcbaca7eca0cfd1"},"cell_type":"code","source":"import time\nt1 = time.time()\npred_dict = {idx: rle_encode(filter_image(preds_test[i] > threshold_best)) for i, idx in enumerate(tqdm_notebook(test_df.index.values))}\nt2 = time.time()\n\nprint(f\"Usedtime = {t2-t1} s\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f1cb741e01983d7263c3a5afc1a9deaed9b6923"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"617fcd557804b642363c7d775977dde661f87d32"},"cell_type":"code","source":"sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4e2663631bd982e5653515e3fcfe079184cd132"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}