{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca08da4c-7acd-3cd0-e4ad-b94124bfdadb"
      },
      "source": [
        "# Conducting a Regression Analysis to Predict 'Survival to 65 years' \n",
        "In the following notebook, I have used data from the 'indicator.csv' file, specifically world development indicator data on India to predict the 'Survival to 65 years (% of cohort)' feature (taken as average of 'Survival to age 65, female (% of cohort)' and 'Survival to age 65, male (% of cohort)' features. To extract the relevant data, I performed some sieving by hand and some on python. \n",
        "\n",
        "I ended up extracted the following features of interest: Birth rate, crude (per 1,000 people);\tCO2 emissions;\tDeath rate, crude (per 1,000 people);\tFertility rate, total (births per woman);\tFinal consumption expenditure;\tGDP per capita;\tGross domestic income;\tGross national expenditure;\tHousehold final consumption expenditure;\tMortality rate, adult, female (per 1,000 female adults);\tMortality rate, adult, male (per 1,000 male adults);\tNet bilateral aid flows from DAC donors;\tPopulation, total;  Year\n",
        "\n",
        "I found that 'Survival to 65 years' could be effectively predicted given the above features using a DecisionTreeRegression classifier. As it turned out, the data proved very tenable to my analysis - I ended up with a very high r2_score, something I found quite strange! I speculate that a similar analysis on data from other countries and regions would likely produce similar results. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1cfb40bd-3334-2087-f3b4-f15691309ab8"
      },
      "outputs": [],
      "source": [
        "# Much of the code on this page is inspired by code I came across through the udacity nanodegree on machine learning...\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "%matplotlib inline\n",
        "\n",
        "try:\n",
        "    data = pd.read_csv(\"newKaggleFile.csv\")\n",
        "    print \"dataset loaded...\"\n",
        "except:\n",
        "    print \"The dataset could not be loaded...\"\n",
        "\n",
        "data = data[np.isfinite(data['Birth rate, crude (per 1,000 people)'])]\n",
        "survival = data['Survival to age 65 (% of cohort)']\n",
        "\n",
        "features = data.drop(['Survival to age 65, male (% of cohort)', 'Survival to age 65, female (% of cohort)', 'Survival to age 65 (% of cohort)'], axis = 1)\n",
        "\n",
        "print \"Number of datapoints: {}\\nNumber of variables per datapoint: {}\".format(*data.shape)\n",
        "\n",
        "display(data[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3400fb6c-5c21-e369-3d31-d9c12ef9370f"
      },
      "outputs": [],
      "source": [
        "# Statistics of Dataset\n",
        "\n",
        "# Survival to 65 through the years\n",
        "lowestSurvival = np.min(survival)\n",
        "highestSurvival = np.max(survival)\n",
        "meanSurvival = np.mean(survival)\n",
        "medianSurvival = np.median(survival)\n",
        "stdDevSurvival = np.std(survival)\n",
        "\n",
        "\n",
        "print \"Survival to 65\"\n",
        "print \"Minimum:\", lowestSurvival\n",
        "print \"Maximum:\", highestSurvival\n",
        "print \"Mean:\", meanSurvival\n",
        "print \"Median\", medianSurvival\n",
        "print \"Standard deviation\", stdDevSurvival"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e67b8661-c579-5f96-d6e0-33e244893e20"
      },
      "source": [
        "### Analyzing economic and non-economic features\n",
        "In the absence of information as to which features can be used to predict 'Survival to 65 years', I resorted to analyzing economic and non economic features separately, and finally the entire feature space ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a86a90f-dc53-81e9-3d86-86c9f40ea678"
      },
      "outputs": [],
      "source": [
        "economicfeatures = features.drop(['Birth rate, crude (per 1,000 people)', 'CO2 emissions', 'Death rate, crude (per 1,000 people)', 'Fertility rate, total (births per woman)', 'Mortality rate, adult, female (per 1,000 female adults)', 'Population, total', 'Mortality rate, adult, male (per 1,000 male adults)'], axis = 1)\n",
        "noneconomicfeatures = features.drop(['Final consumption expenditure', 'GDP per capita', 'Gross domestic income', 'Gross national expenditure', 'Household final consumption expenditure', 'Net bilateral aid flows from DAC donors'], axis = 1) \n",
        "display(economicfeatures[:5])\n",
        "display(noneconomicfeatures[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6286ad57-93c7-9939-e55c-2630f9736bc6"
      },
      "source": [
        "### Preparing the data\n",
        "The following code splits the data into training and testing points for the regression model analysis. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "220e6838-5d05-d6a4-9000-097b31ea8989"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split \n",
        "# Divide data into training and testing sets\n",
        "X_train_noneconomic, X_test_noneconomic, y_train_noneconomic, y_test_noneconomic = train_test_split(noneconomicfeatures, survival, test_size = 0.2, random_state = 2)\n",
        "X_train_economic,X_test_economic, y_train_economic, y_test_economic = train_test_split(economicfeatures, survival, test_size = 0.2, random_state = 2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, survival, test_size = 0.2, random_state = 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b698deb-584b-1a98-43ee-d20ab861604b"
      },
      "source": [
        "### Principle Component Analysis\n",
        "There are a large number of features in the features dataset. I suspected that there are underlying latent features driving the economic and the non-economic features respectively. I sought to find them using PCA. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d95899a6-64d4-2ddc-6a82-e662e6201dc5"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Find PCA transformed data (non-economic features) \n",
        "pca_noneconomic = PCA(n_components = 3)\n",
        "pca_noneconomic.fit(X_train_noneconomic)\n",
        "\n",
        "X_train_noneconomic_pca = pca_noneconomic.transform(X_train_noneconomic)\n",
        "X_test_noneconomic_pca = pca_noneconomic.transform(X_test_noneconomic)\n",
        "\n",
        "# Find PCA transformed data (economic features)\n",
        "pca_economic = PCA(n_components = 3)\n",
        "pca_economic.fit(X_train_economic)\n",
        "\n",
        "X_train_economic_pca = pca_economic.transform(X_train_economic)\n",
        "X_test_economic_pca = pca_economic.transform(X_test_economic)\n",
        "\n",
        "# Find PCA transformed data (economic & non-economic features)\n",
        "pca = PCA(n_components = 5)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0480cc01-5503-7c85-7eb9-b23c18ca9aa5"
      },
      "source": [
        "### Building a metric for guaging the model efficacy..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f3f3335-5939-3f08-9379-372c4d6f9733"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "def performance_metric(y_true, y_predict):\n",
        "    return r2_score(y_true, y_predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "49efdf89-d0cf-6849-d303-e722a641158b"
      },
      "source": [
        "### Implementing the Decision Tree Regression model on the data\n",
        "I found that the entirety of the data (economic + non-economic features) yielded the best r2_score. In the remainder of the analysis, I used the entirety of the data to build my final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "07600853-4220-6fae-0fa5-c9f5e2d93219"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Testing DecisionTreeRegressor on data \n",
        "\n",
        "# Economic feature set\n",
        "reg_economic = DecisionTreeRegressor()\n",
        "reg_economic.fit(X_train_economic_pca, y_train_economic)\n",
        "y_pred_economic = reg_economic.predict(X_test_economic_pca)\n",
        "print 'Decision Tree Regressor r2_score on Economic data is:', performance_metric(y_test_economic, y_pred_economic)\n",
        "\n",
        "# Non-economic feature set\n",
        "reg_noneconomic = DecisionTreeRegressor()\n",
        "reg_noneconomic.fit(X_train_noneconomic_pca, y_train_noneconomic)\n",
        "y_pred_noneconomic = reg_economic.predict(X_test_noneconomic_pca)\n",
        "print 'Decision Tree Regressor r2_score on Non-economic data is:', performance_metric(y_test_noneconomic, y_pred_noneconomic)\n",
        "\n",
        "# (Economic + non-economic) feature set\n",
        "reg_ = DecisionTreeRegressor()\n",
        "reg_.fit(X_train_pca, y_train)\n",
        "y_pred_ = reg_.predict(X_test_pca)\n",
        "print 'Decision Tree Regressor r2_score on (Economic + non-economic) data is:', performance_metric(y_test, y_pred_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b0f772f-618f-702d-40da-da10df14d465"
      },
      "source": [
        "### Optimizing the Decision Tree Regression classifier parameters on the data\n",
        "Oddly enough, I found that optimizing the Decision Tree classifier parameters did not yield appreciably better results. Am I not optimizing the correct parameters?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "55ab8443-03cc-f744-0d12-eecfe14ef472"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.cross_validation import ShuffleSplit\n",
        "def fit_model(X, y):\n",
        "    # Setting parameters for GridSearchCV \n",
        "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 2)\n",
        "    regressor = DecisionTreeRegressor()\n",
        "    params = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'splitter': ['best', 'random']}\n",
        "    scoring_func = make_scorer(performance_metric)\n",
        "    \n",
        "    # Create GridSearch object\n",
        "    grid = GridSearchCV(regressor, params, cv = cv_sets, scoring = scoring_func)\n",
        "    \n",
        "    # Fit GridSearch object to the data\n",
        "    grid = grid.fit(X, y)\n",
        "    \n",
        "    # Return best estimator using inbuilt method\n",
        "    return grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "abc17912-5e1e-3c0c-7963-7f508a30deee"
      },
      "outputs": [],
      "source": [
        "optimalReg = fit_model(X_train_pca, y_train)\n",
        "y_pred_optimal = optimalReg.predict(X_test_pca)\n",
        "print 'The r2_score of the optimal classifier is:', performance_metric(y_test, y_pred_optimal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59ed1b6c-b23d-e956-5565-2f496796b2d9"
      },
      "source": [
        "### Conclusion\n",
        "So there you have it. The decision tree classifier model performed surprisingly well on the data in predicting 'Survival to 65 years'. As mentioned in the introduction, I believe similar analyses on data from other countries too shall yield similarly strong results.  "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}