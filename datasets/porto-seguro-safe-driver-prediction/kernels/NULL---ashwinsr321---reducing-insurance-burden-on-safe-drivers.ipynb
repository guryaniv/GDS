{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"_cell_guid": "e253461f-6c06-4f13-ab7e-15358f9e7aff", "_uuid": "20544d5f036cbf8e616c9ca951d771f34cf4172d"}, "source": ["# Porto Seguro\u2019s Safe Driver Prediction\n", "\n", "## Overview of the Kaggle competition :\n", "Nothing ruins the thrill of buying a brand new car more quickly than seeing your new insurance bill. The sting\u2019s even more painful when you know you\u2019re a good driver. It doesn\u2019t seem fair that you have to pay so much if you\u2019ve been cautious on the road for years.\n", "\n", "Porto Seguro, one of Brazil\u2019s largest auto and homeowner insurance companies, completely agrees. Inaccuracies in car insurance company\u2019s claim predictions raise the cost of insurance for good drivers and reduce the price for bad ones.\n", "\n", "In this competition, you\u2019re challenged to build a model that predicts the probability that a driver will initiate an auto insurance claim in the next year. While Porto Seguro has used machine learning for the past 20 years, they\u2019re looking to Kaggle\u2019s machine learning community to explore new, more powerful methods. A more accurate prediction will allow them to further tailor their prices, and hopefully make auto insurance coverage more accessible to more drivers.\n", "\n", "\n", "### Importing Packages"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "3606a469-1d32-4eba-8c7e-8f4dd1a49cd2", "_uuid": "5a10c9a5d73a086e1d4e107a90ba696d6555108e"}, "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt; plt.rcdefaults()\n", "import numpy as np\n", "import matplotlib as mpl\n", "import seaborn as sns\n", "from collections import Counter\n", "import missingno as msno\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn import datasets\n", "from sklearn import metrics\n", "from sklearn.ensemble import ExtraTreesClassifier\n", "from xgboost import XGBClassifier"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "473edc92-5a99-4d43-b674-ca9552fdb401", "_uuid": "5e9fa725c56c72c915d2832a31d42fe0bd79991d"}, "source": ["### Loading & Analysing Data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "cc0d3a13-73d9-4ffa-8fde-70bcb8fc1da1", "_uuid": "0577dc7bc90b279ac3595afd09df99ab8462de56"}, "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "ac8e6b91-3a03-46a4-8601-78340a496aa4", "_uuid": "5abe5d734ffb44e324081d786d0cdafec15e0912"}, "source": ["#### Visualising the Data :"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "e18ea85d-f2b9-4524-96fa-887ace539d2c", "_uuid": "1411a0772a42497661e089487f139664bbf50dcc"}, "source": ["train.head()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e2607995-791b-4d2e-ae92-475a4cf8ecad", "_uuid": "51fdd470d4ad4e4694a5e12d9f5f097edac67b08"}, "source": ["#### Data Discription :\n", "Each row is a client and they are independent. 595,212 unique clients are present in test set while 892,816 are present in the test set. \n", "\n", "The data consists of 57 input features, one target variable and a client ID. The target is 1 if the customer has filed a claim and 0 if not. In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., ind, reg, car, calc). \"Ind\" is related to individual or driver, \"reg\" is related to region, \"car\" is related to car itself and \"calc\" is an calculated feature. In addition, feature names include the postfix bin to indicate binary features and cat to indicate categorical features. Features without these designations are either continuous or ordinal. Values of -1 indicate that the feature was missing from the observation. 17 of the 57 features are binary, 14 are categorical & the others are either continuous or ordinal."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "99bc9e80-fb46-4c30-9620-e60f826f5d05", "_uuid": "d8500f5c3e97239040099433dfe69db2633fb9ca"}, "source": ["print(\"Total number of input features : \", (train.shape[1] - 2)) # id and target are not features, hence -2\n", "print(\"Number of users in train : \", train.shape[0])\n", "print(\"Number of users in test : \", test.shape[0])"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5046c35e-524c-4fa4-a46c-672c6c64a749", "_uuid": "02867ebcae684adddf785e5655ed543a201834ee"}, "source": ["#### Memory usage by Train and Test data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "afe401f0-fc9e-483a-ad3a-9d4e031d76bd", "_uuid": "776e483438a7e3876a94e48301dcfc6b6010609b"}, "source": ["train.info(memory_usage='deep', verbose=False)\n", "test.info(memory_usage='deep', verbose=False)"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "4eefec64-93f6-49a6-957a-27333baa3cb3", "_uuid": "4c69c3a42e00401074738823bc584c3287bb3e16"}, "source": ["#### Analysing Missing Data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "3a3fa749-db5a-4996-ad31-e92eea819924", "_uuid": "0d27b70794b141f2fdf779d2d6343fa339bd0ca3"}, "source": ["print(\"Total NaN in train data : \", train.isnull().sum().sum())\n", "print(\"Total NaN in test data : \", test.isnull().sum().sum())"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "8821bea2-287a-42ea-b459-634d9dd5c01e", "_uuid": "c5bcd3281006bf64aec6e5ab2b4f2fe40920f5f6"}, "source": ["There are no NaNs in either test or train data. But values of -1 indicate that the feature was missing from the observation."], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "c6e00552-24d6-4ef3-8a98-7a79cc25961c", "_uuid": "3967fad1948c89944a27b1a02c22a5e5f29fb6e0"}, "source": ["train_missing_count = (train == -1).sum()\n", "plt.rcParams['figure.figsize'] = (15,8)\n", "train_missing_count.plot.bar()\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "6b49795e-9ae3-4f6c-998b-dd9e5a438f61", "_uuid": "979db2403e2837a8cab7f0927c81ef062fe00a73"}, "source": ["The missing data in training data is as below: \n", "\n", "ps_ind_02_cat        216\n", "ps_ind_04_cat         83\n", "ps_ind_05_cat       5809\n", "ps_reg_03         107772\n", "ps_car_01_cat        107\n", "ps_car_02_cat          5\n", "ps_car_03_cat     411231\n", "ps_car_05_cat     266551\n", "ps_car_07_cat      11489\n", "ps_car_09_cat        569\n", "ps_car_11              5\n", "ps_car_12              1\n", "ps_car_14          42620\n", "\n", "The data is mainly missing from ps_car_05_cat, ps_car_03_cat, ps_reg_03"], "cell_type": "raw"}, {"execution_count": null, "metadata": {"_cell_guid": "585311d4-7d15-465d-b0dd-faae87169707", "_uuid": "ef0ceba36e67c867c50ed533ef328e5647c050b6"}, "source": ["test_missing_count = (test == -1).sum()\n", "test_missing_count.plot.bar()\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "842846d0-9db3-4baf-8c8a-f04fdc487523", "_uuid": "628b8edf84a9ee8cab05ca22f88e1e8de648f7a7"}, "source": ["The missing data in test data is as below: \n", "\n", "ps_ind_02_cat        307\n", "ps_ind_04_cat        145\n", "ps_ind_05_cat       8710\n", "ps_reg_03         161684\n", "ps_car_01_cat        160\n", "ps_car_02_cat          5\n", "ps_car_03_cat     616911\n", "ps_car_05_cat     400359\n", "ps_car_07_cat      17331\n", "ps_car_09_cat        877\n", "ps_car_11              1\n", "ps_car_14          63805"], "cell_type": "raw"}, {"metadata": {"_cell_guid": "08a4d115-da84-4602-982c-374a37e162fb", "_uuid": "1b5adf367285f102d52d77b37b2d8393dbb4c37e"}, "source": ["#### Heatmap of Missing Data :"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "0e1b568b-70f1-4c1f-98cf-7cb680d31daa", "_uuid": "fe82bec82b67da9ab409e95f6ccdd509a2791308"}, "source": ["required_columns = ['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_reg_03', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_05_cat', 'ps_car_07_cat', 'ps_car_09_cat', 'ps_car_11', 'ps_car_14']\n", "train_temp = train.copy()\n", "train_temp = pd.DataFrame(train_temp, columns=required_columns)\n", "train_temp = train_temp.replace(-1, np.NaN)\n", "msno.matrix(df=train_temp, figsize=(20, 15))\n", "msno.heatmap(train_temp,figsize=(20,15))\n", "del train_temp"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "204e1aee-d20e-48bc-b5b2-345830ac4af5", "_uuid": "43bae82a6ab619f745152d918de33b88060c793f"}, "source": ["#### Closer view at training data :\n"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "cb198fd1-b51e-450d-95be-d9858c7a4eaf", "_uuid": "1597753467f4d6f967acc3b6f89fbd100c0a3fd2"}, "source": ["train_statistics = train.iloc[:,2:].describe()\n", "train_statistics"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "63bce0c6-d82f-4339-99c9-985fb00d2883", "_uuid": "5a107707be977bfbda8ca2add0e4b68b88550bb9"}, "source": ["#### Analysing Target Variable"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "a8710364-34df-4721-bfbd-3da3931b0dff", "_uuid": "ed17e75677bc73ac04fee164252461043edab3e2"}, "source": ["print(train['target'].sum(), \"people claimed insurance and\",train.shape[0] - train['target'].sum(), \"did not claim imsurance\")\n", "print(((train['target'].sum()*100.0)/train.shape[0]), \"% of the people claimed insurance and\",(((train.shape[0] - train['target'].sum())*100.0)/train.shape[0]), \"did not claim imsurance\")\n", "\n", "\n", "objects = ('Claimed', 'Not Claimed')\n", "y_pos = np.arange(len(objects))\n", "performance = [train['target'].sum(), train.shape[0] - train['target'].sum()]\n", "plt.bar(y_pos, performance, align='center', alpha=0.5)\n", "plt.xticks(y_pos, objects)\n", "plt.ylabel('claim #')\n", "plt.title('Claimed vs Not Claimed')\n", "plt.show()\n", "\n", "objects = ('Claimed', 'Not Claimed')\n", "colors = ['red', 'yellowgreen']\n", "sizes = [(train['target'].sum()*100.0)/train.shape[0], ((train.shape[0] - train['target'].sum())*100.0)/train.shape[0]]\n", "explode = (0.1, 0)  # explode 1st slice\n", "plt.pie(sizes, explode=explode, labels=objects, colors=colors,\n", "        autopct='%1.1f%%', shadow=True, startangle=140)\n", "plt.axis('equal')\n", "plt.show()\n"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "30fa4384-f46c-4665-8e40-e50df71368f5", "_uuid": "6ce950852564d9f9df9d66010a81bd7d143a26e2"}, "source": ["21694 people claimed insurance and 573518 did not claim imsurance.\n", "\n", "3.64% of the people claimed insurance and 96.35% did not claim imsurance.\n", "\n", "## Analysing each feature\n", "\n", "### Binary Features :"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"scrolled": true, "_cell_guid": "d6eb02d8-e600-4932-a47c-d4e93597f5db", "_uuid": "0c047e8916318df910c1424893f0cb8007fd1832"}, "source": ["unique_counter = Counter()\n", "for col in train.columns:\n", "    unique_counter[col] = len(np.sort(train[col].unique()))\n", "binary_columns = [ col for col , val in unique_counter.items() if(val==2)]\n", "binary_column_sum = []\n", "for col in binary_columns:\n", "    binary_column_sum.append(train[col].sum())\n", "#List of binary columns\n", "binary_columns"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "66f6d37e-9f9b-4b10-8da6-090d4a671066", "_uuid": "ae769694ac51d86050959bde0662b3224c58b6b0"}, "source": ["# data to plot\n", "n_groups = len(binary_columns)\n", "one_cols = binary_column_sum\n", "zero_cols = train.shape[0] - np.asarray(binary_column_sum)\n", " \n", "# create plot\n", "plt.rcParams['figure.figsize'] = (15,8)\n", "fig, ax = plt.subplots()\n", "index = np.arange(n_groups)\n", "bar_width = 0.3\n", "opacity = 0.8\n", " \n", "rects1 = plt.bar(index, one_cols, bar_width,\n", "                 alpha=opacity,\n", "                 color='g',\n", "                 label='1')\n", " \n", "rects2 = plt.bar(index + bar_width, zero_cols, bar_width,\n", "                 alpha=opacity,\n", "                 color='b',\n", "                 label='0')\n", "\n", "plt.ylabel('#', fontsize=14)\n", "plt.title('Binary Features', fontsize=20)\n", "plt.xticks(index + bar_width/2, binary_columns, rotation='vertical', fontsize=12)\n", "plt.legend()\n", " \n", "plt.tight_layout()\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "078c07a0-4a39-414d-8246-6e869deb3912", "_uuid": "9a418994a9ddb920def2b23fc104d7f861bd2086"}, "source": ["#### Catagorical and other Features\n", "\n", "Histogram of train data viewing the distribution of data:"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "77fc5dc8-c16d-4c30-8cd1-a235c583986c", "_uuid": "9f852524671da3a32cce074e1711820de3f7bf61"}, "source": ["# Univariate Histograms\n", "columns_multi = [x for x in list(train.columns) if x not in binary_columns]\n", "columns_multi.remove('id')\n", "columns_multi\n", "plt.rcParams['figure.figsize'] = (15,40)\n", "names = columns_multi\n", "train.hist(layout = (10,4), column = columns_multi)\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "6da6feca-5ed7-42c8-942a-32ee97cfd658", "_uuid": "03265abc52071670779ea49ceb5c516664216078"}, "source": ["names = columns_multi\n", "train.plot(kind='density', subplots=True, layout=(15,4), sharex=False)\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "61f5d62e-47e7-4324-a817-407d521731a6", "_uuid": "02098976e51b3797a815810b001f31aa830b2666"}, "source": ["## Correction of Train Data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "b18bf479-6aca-48f6-9962-b1d214db1d05", "_uuid": "a3bca6e4c7ad468c94efba4b8c878f09152a8be5"}, "source": ["# Correction Matrix Plot\n", "names = train.columns\n", "correlations = train.corr()\n", "# plot correlation matrix\n", "plt.rcParams['figure.figsize'] = (15,12)\n", "fig = plt.figure()\n", "ax = fig.add_subplot(111)\n", "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n", "fig.colorbar(cax)\n", "ticks = np.arange(0,59,1)\n", "ax.set_xticks(ticks)\n", "ax.set_yticks(ticks)\n", "ax.set_xticklabels(names, rotation=90)\n", "ax.set_yticklabels(names)\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e62f3d2b-ae8e-48f0-8c4e-956a598597e2", "_uuid": "0d7172daedbdf7d58ddbc86de8c9f8bd98f55e34"}, "source": ["## Discovering Feature Importances :\n", "\n", "Three methods are used\n", "- Random Forest Classifier\n", "- Extra Trees Classifier\n", "- XGBoost"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"_cell_guid": "7e236c23-d0a8-4203-a94c-f48b9a7fc10d", "_uuid": "dad9ba359986ef82c057d9ec0661bc290b7ad243"}, "source": ["# Create a random forest classifier\n", "clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n", "# Train the classifier\n", "clf.fit(train.iloc[:,2:], train.iloc[:,1])\n", "\n", "# Plot the gini importance of each feature\n", "feature_importances = sorted(zip(clf.feature_importances_, list(train.columns)[2:]), reverse=True)\n", "objects = (list(zip(*feature_importances))[1])\n", "y_pos = np.arange(len(objects))\n", "performance = np.array(list(zip(*feature_importances))[0])\n", "plt.bar(y_pos, performance, align='center', alpha=0.5)\n", "plt.xticks(y_pos, objects, rotation='vertical')\n", "plt.ylabel('Importance')\n", "plt.title('Feature Importances using Random forest')\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "0f982ccc-c80b-4373-a7da-513a94aa2d72", "_uuid": "7024eb542453af176522e90257980cb8067e5590"}, "source": ["# Feature Importance\n", "# fit an Extra Trees model to the data\n", "model = ExtraTreesClassifier()\n", "model.fit(train.iloc[:,2:], train.iloc[:,1])\n", "\n", "\n", "# Plot the gini importance of each feature\n", "feature_importances = sorted(zip(model.feature_importances_, list(train.columns)[2:]), reverse=True)\n", "objects = (list(zip(*feature_importances))[1])\n", "y_pos = np.arange(len(objects))\n", "performance = np.array(list(zip(*feature_importances))[0])\n", "plt.bar(y_pos, performance, align='center', alpha=0.5)\n", "plt.xticks(y_pos, objects, rotation='vertical')\n", "plt.ylabel('Importance')\n", "plt.title('Feature Importances using Extra Trees Classifier')\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"_cell_guid": "5e8e2cf3-1b18-42fc-852c-ae902f9fdaa5", "_uuid": "cb2598277af7b6b321373172996cfd3521854ed8"}, "source": ["X = train.iloc[:,2:]\n", "y = train.iloc[:,1]\n", "# fit model to training data\n", "model = XGBClassifier()\n", "model.fit(X, y)\n", "# plot\n", "feature_importances = sorted(zip(model.feature_importances_, list(train.columns)[2:]), reverse=True)\n", "objects = (list(zip(*feature_importances))[1])\n", "y_pos = np.arange(len(objects))\n", "performance = np.array(list(zip(*feature_importances))[0])\n", "plt.bar(y_pos, performance, align='center', alpha=0.5)\n", "plt.xticks(y_pos, objects, rotation='vertical')\n", "plt.ylabel('Importance')\n", "plt.title('Feature Importances using XGBoost')\n", "plt.show()"], "cell_type": "code", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}