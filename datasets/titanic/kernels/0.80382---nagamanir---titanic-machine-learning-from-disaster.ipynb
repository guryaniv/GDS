{"nbformat": 4, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "version": "3.6.4", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1, "cells": [{"source": ["I am a begineer in datascience and machine learning. This is my first kernel submitted.\n", "\n", "Taken references from the below kernels for building the model\n", "https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling   \n", "https://www.kaggle.com/startupsci/titanic-data-science-solutions  \n", "https://www.kaggle.com/longyin2/titanic-machine-learning-from-disaster-0-842\n", "\n", "Please review and let me know how can I improve the accuracy. Thanks\n", "\n", "Extracted the title from Name as used it as features as mentioned in the above kernels. The accuracy significantely improved.\n", "Edited for - Both train and test set are considered for calculating the mean for Age.\n", "\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "0c72a3bb-6f1a-4289-9813-408e4e374fc0", "_uuid": "a22141883e4162328cd7cdaf666a5f9d7fb47a9a"}}, {"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "## Visulization\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "8403b3f7-ee1f-4ec2-8180-e7747ae2bdfb", "_uuid": "527ec847cf5214ddca32fa257e680af2ed134837"}, "cell_type": "code", "outputs": [], "execution_count": 1}, {"source": ["## Load the training and test dataset\n", "input_df = pd.read_csv(\"../input/train.csv\")\n", "test_df = pd.read_csv(\"../input/test.csv\")\n", "\n", "data_df = input_df.append(test_df) #Entire dataset\n", "\n", "# display the first 5 records of input data set\n", "input_df.head()\n"], "metadata": {"_cell_guid": "9754f714-5591-4d19-8f14-e541ee83e803", "_uuid": "71c12ddca161d9e30ea4273c7bf180fce686a377"}, "cell_type": "code", "outputs": [], "execution_count": 2}, {"source": ["**Implementation** : **Data Exploration**        \n", "an investigation of the dataset  below will determine how many people survived or not survived from each category and will also tell us the percentage of the people that are survived.\n", "\n", "Total number of passengers in the input data - 891    \n", "no of passengers survived -- 342       \n", "no of passenger not survived - 549\n", "\n", "Percentage of people survived - 38%   \n", "Female passengers survived most.  \n", "Most passengers in 1st class are survived   "], "cell_type": "markdown", "metadata": {"_cell_guid": "1e46595f-e2d1-455c-9d07-6668dec59e50", "_uuid": "e0e146607b0c53f5d01637100253375208b8d2b7"}}, {"source": ["input_df.describe()"], "metadata": {"_cell_guid": "605af220-d05c-4b6c-b3df-ec9c62a878ce", "_uuid": "61d4589e7ad3a2c22122c527aa04ad4a342be3c8"}, "cell_type": "code", "outputs": [], "execution_count": 3}, {"source": ["n_survived = len(input_df[input_df['Survived'] == 1])\n", "not_survived = len(input_df[input_df['Survived'] == 0])\n", "print (\"Total number of passengers survived: {}\".format(n_survived))\n", "print (\"Total number of passengers survived: {}\".format(not_survived))\n"], "metadata": {"_cell_guid": "4ede21c8-f8f7-4278-a2e5-3cbac61dcbae", "_uuid": "1794d7c3b20716ce6e988e42c0d94912c7fae64e"}, "cell_type": "code", "outputs": [], "execution_count": 4}, {"source": ["sns.countplot(x='Survived', hue=\"Sex\", data=input_df)"], "metadata": {"_cell_guid": "9413a551-95a6-4b52-a8c2-a43c0afeab39", "_uuid": "2b8c7e4b5e3ae950708a6a14cbd2b6233a7d9e4a"}, "cell_type": "code", "outputs": [], "execution_count": 5}, {"source": ["sns.countplot(x='Survived', hue='Pclass', data=input_df)"], "metadata": {"_cell_guid": "13ed708b-24e1-4309-80ab-528cf258d178", "_uuid": "db07956598b44fe1ff21d640052f2e6dd86a50a3"}, "cell_type": "code", "outputs": [], "execution_count": 6}, {"source": ["## Visulizing distributions of Age and Fare\n", "fig, axes = plt.subplots(1,2, figsize=(10,4))\n", "axes[0].hist(input_df['Fare'], bins=20)\n", "#axes[1].hist(input_df['Age'])\n", "\n", "input_df['Age'].hist(axes=axes[1], bins=15, density=True)\n", "input_df['Age'].plot(kind='density', color='green')"], "metadata": {"_cell_guid": "ab89a06c-6c8e-43ff-940d-b5268b8836e8", "_uuid": "d90ea73c90181ccef327be5d68f36eab7337dece"}, "cell_type": "code", "outputs": [], "execution_count": 7}, {"source": ["**Featureset Exploration**    \n", "Age - Continuous         \n", "Pclass - Categorical  ( 1- Upper, 2 - Middle, 3-Lower)       \n", "PassengerId - Sequence of the passenger ID. Continuous         \n", "Sex - Categorical ( Male, Female)       \n", "Name - Unique name of the passenger         \n", "Sibsp - No of siblings/spouses aboard. Numerical, Continuous          \n", "Parch - No of parents/Childern aboard. Numerical, Continuous          \n", "Fare - Continuous             \n", "Embarked - Categorical (C, Q, S)             \n", "Cabin - Alphanumeric number             \n", "Ticket - Unique value             \n", "Survived - Categorical ( 0 - No, 1 - Yes)               "], "cell_type": "markdown", "metadata": {"_cell_guid": "7c095ebb-f021-478c-a82f-8d5670b6df94", "_uuid": "43459e5695b13f6e232caf94760be7507f672043"}}, {"source": ["**Preparing the Data** -- Data Preprocessing               \n", "**Missing Values**       \n", "For this dataset, we can see there are missing values present for Age, Embarked and Cabin. While 20% of the data has missing values for Age, very large proportion of the data has values missed for Cabin. So considering this, the column Cabin can be dropped instead of filling the data.    \n", "For the Age, the missing values can be replaced with some form of imputation like th mean of the Age.\n", "For Embarked, only 2 values are missing and can be filled in with the most Embarked category.\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "478a25ce-d1db-4e8c-9b77-5831e43f5914", "_uuid": "c699846b0c2c4e20d921dc2dbbe4a75d822a84dd"}}, {"source": ["input_df.info()\n", "print (\"---------------------------------------------\")\n", "test_df.info()"], "metadata": {"_cell_guid": "e3dfed82-99e9-4270-84c6-19db49e94dee", "_uuid": "6f7aa5fb73d7d241da740085cace6dc909578b24"}, "cell_type": "code", "outputs": [], "execution_count": 8}, {"source": ["sns.countplot(input_df['Embarked'])"], "metadata": {"_cell_guid": "ee51dab8-6e1a-4dfe-8e76-6bbc85dd106c", "_uuid": "8547eb657d60170d704e2a6b95bcfc440f47dc27"}, "cell_type": "code", "outputs": [], "execution_count": 9}, {"source": ["Extracting the Title from the Name column"], "cell_type": "markdown", "metadata": {"_cell_guid": "35d61b53-60f6-4e0a-b317-662599fc7ec2", "_uuid": "b4cc072cddba6ce2988fdedd16b22fb946e23e21"}}, {"source": ["def Name_Title_Code(x):\n", "    if x == 'Mr.':\n", "        return 1\n", "    if (x == 'Mrs.') or (x=='Ms.') or (x=='Lady.') or (x == 'Mlle.') or (x =='Mme'):\n", "        return 2\n", "    if x == 'Miss':\n", "        return 3\n", "    if x == 'Rev.':\n", "        return 4\n", "    return 5\n", "\n", "print (input_df['Name'].head())\n", "print ('--------------------------------------')\n", "input_df['Name_Title'] = input_df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n", "print (input_df['Name_Title'].head())\n", "\n", "input_df['Name_Title'] = input_df['Name_Title'].apply(Name_Title_Code)\n", "print (input_df['Name_Title'].head())\n", "\n", "print ('----------Test data.........')\n", "test_df['Name_Title'] = test_df['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n", "print (test_df['Name_Title'].head())\n", "\n", "test_df['Name_Title'] = test_df['Name_Title'].apply(Name_Title_Code)\n", "print (test_df['Name_Title'].head())"], "metadata": {"_cell_guid": "16da04bb-3132-4196-a287-07d793d37bc9", "_uuid": "c6a31053b70e86de2bfbceb9743324b5136a45f7"}, "cell_type": "code", "outputs": [], "execution_count": 10}, {"source": ["Filling the missing data for Age - One way is we can fill in with the  mean age of all the passengers or we can check the correlation of Age with other features like pclass and populate the mean age based on the pclass.\n", "\n", "For Embarked - we can fill in with the Most Embarked station - 'S'"], "cell_type": "markdown", "metadata": {"_cell_guid": "cfc47078-acc9-4d22-b4c1-872367467408", "_uuid": "0776a27b4834d801b6d8febc895910cbbf81fd70"}}, {"source": ["#mean_age = input_df['Age'].mean()\n", "def impute_age(cols):\n", "    age = cols[0]\n", "    pclass = cols[1]\n", "    if pd.isnull(age):\n", "        return data_df.groupby('Pclass').median()['Age'][pclass]   \n", "    else:\n", "        return age\n", "\n", "def impute_embarked(embarked):\n", "    if pd.isnull(embarked):\n", "        return 'S'\n", "    else:\n", "        return embarked\n", "        \n", "input_df['Age'] = input_df[['Age', 'Pclass']].apply(impute_age, axis=1)\n", "test_df['Age'] = test_df[['Age', 'Pclass']].apply(impute_age, axis=1)\n", "input_df['Embarked'] = input_df['Embarked'].apply(impute_embarked)\n", "test_df['Embarked'] = test_df['Embarked'].apply(impute_embarked)\n", "\n", "### filling the missing value for the Fare in the test dataset\n", "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"], "metadata": {"_cell_guid": "b2669edf-4ab8-4b8c-ace4-cb948f73c460", "_uuid": "416b3eea68cc5865635bd8fbffa168314c3cee12", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": 11}, {"source": ["## Verifying the data after the missing values are filled in for Age and Embarked\n", "input_df.info()\n", "print (\"----------------------------------------------\")\n", "test_df.info()"], "metadata": {"_cell_guid": "61df4714-b73f-480e-9017-c702a2b3d5a1", "_uuid": "641afdbfea555584398788b59d9083a1ca13ad17"}, "cell_type": "code", "outputs": [], "execution_count": 12}, {"source": ["**Transforming skewed continuous features**\n", "Age and Fare are two continuous features in the dataset. "], "cell_type": "markdown", "metadata": {"_cell_guid": "a2ecacf2-35be-4a1e-aa8b-b9b5b6f57215", "_uuid": "9dd114484bcbc0db60b476152617c3b3c0ce6b0d"}}, {"source": ["## seperate out the target\n", "target_df = input_df['Survived']\n", "features_raw = input_df.drop('Survived', axis=1)"], "metadata": {"_cell_guid": "1cff8253-d609-42b4-8e72-c90e044dc6a5", "_uuid": "350fd568a09a9656b4a018389893ca81c61da3f7", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": 13}, {"source": ["# Log-transform the skewed features\n", "skewed = ['Age', 'Fare']\n", "features_log_transformed = pd.DataFrame(data = features_raw)\n", "features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))\n", "\n", "## applying the log transformation to the test data\n", "test_df_log_transformed = pd.DataFrame(data=test_df)\n", "test_df_log_transformed[skewed] = test_df[skewed].apply(lambda x: np.log(x+1))\n", "\n", "# Visualize the new log distributions\n", "fig, axes = plt.subplots(1,2, figsize=(10,4))\n", "axes[0].hist(features_log_transformed['Fare'], bins=30)\n", "axes[0].set_title(\"Fare: Feature Distribution\")\n", "axes[0].set_xlabel(\"Fare\")\n", "axes[0].set_ylabel(\"No of records\")\n", "axes[1].hist(input_df['Age'], bins=25)\n", "axes[1].set_title(\"Age: Feature Distribution\")\n", "axes[1].set_xlabel(\"Age\")\n", "axes[1].set_ylabel(\"No of records\")\n", "\n", "fig.tight_layout()"], "metadata": {"_cell_guid": "e7c42a48-0460-4dc8-a345-c8bcdf5b243c", "_uuid": "af5cba541c20d0d9068c4e71e2d926d738afd89b"}, "cell_type": "code", "outputs": [], "execution_count": 14}, {"source": ["## Adding the family feature\n", "features_log_transformed['Family'] = features_log_transformed['SibSp'] +  features_log_transformed['Parch']\n", "\n", "test_df_log_transformed['Family'] =  test_df_log_transformed['SibSp'] +  test_df_log_transformed['Parch']\n", "\n", "features_log_transformed.head()"], "metadata": {}, "cell_type": "code", "outputs": [], "execution_count": 25}, {"source": ["**Normalizing Numerical Features**\n", "Applying a scaling/normalization ensures that each feature is treated equally when applying the learning algorithm."], "cell_type": "markdown", "metadata": {"_cell_guid": "fe0bac10-3405-4777-a66e-bb4629ed665c", "_uuid": "c7dd95a1c503b29974a221d703a2e691e188ecec"}}, {"source": ["from sklearn.preprocessing import MinMaxScaler\n", "scaler = MinMaxScaler()\n", "#numerical = ['Age', 'Fare', 'SibSp', 'Parch']\n", "\n", "numerical = ['Age', 'Fare', 'Family']\n", "\n", "features_normalized = pd.DataFrame(data=features_log_transformed)\n", "features_normalized[numerical] = scaler.fit_transform(features_log_transformed[numerical])\n", "\n", "print (features_normalized.head(5))\n", "\n", "## Normalizing test data set\n", "test_features_normalized = pd.DataFrame(data=test_df_log_transformed)\n", "test_features_normalized[numerical] = scaler.fit_transform(test_df_log_transformed[numerical])"], "metadata": {"_cell_guid": "1e4c38ae-2016-4498-92fe-6c2b7ed3522d", "_uuid": "739062a7e96b5433c35533057dc8f6c1281a9d05"}, "cell_type": "code", "outputs": [], "execution_count": 26}, {"source": ["**Data Preprocssing - Converting the categorical values**    \n", "Using one hot encoding scheme the categorical values for Sex, Embarked  can be converted to numberical values."], "cell_type": "markdown", "metadata": {"_cell_guid": "7f1fca76-7441-40f2-af65-e693639c0794", "_uuid": "3234f05438dae800a59a3eefbd9351dfeb26e3a9"}}, {"source": ["## one hot coding for the categorical values. SEX, EMBARKED\n", "## Before that lets drop the columns that are not required for the algorithm \n", "## Cabin, Name, PassengerId, TicketId\n", "\n", "features_final = features_normalized.drop(['Cabin', 'PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch'], axis=1)\n", "test_df_final = test_features_normalized.drop(['Cabin', 'PassengerId', 'Name', 'Ticket', 'SibSp', 'Parch'], axis=1)\n", "\n", "#features_final['Sex'].replace(['male', 'female'], [0,1], inplace=True)\n", "#test_df_final['Sex'].replace(['male', 'female'], [0,1], inplace = True)\n", "\n", "input_train_one_hot_encoded = pd.get_dummies(features_final)\n", "print (input_train_one_hot_encoded.head())\n", "\n", "### one hot encoding for test dataset\n", "test_df_one_hot_encoded = pd.get_dummies(test_df_final)\n"], "metadata": {"_cell_guid": "011a5ce9-fbc1-47e6-967b-347467e7c2f4", "_uuid": "0ca6bd672311e74f8e394d9b9e0bc59fc88d4542"}, "cell_type": "code", "outputs": [], "execution_count": 27}, {"source": ["input_train_one_hot_encoded.isnull().any()  ## to check if any column has null or nan values"], "metadata": {"_cell_guid": "74de4099-0c6c-4f15-ba58-36d97152da91", "_uuid": "7d4fb961b46e74468ba38211adf9eb3f0359fdf8"}, "cell_type": "code", "outputs": [], "execution_count": 17}, {"source": ["**Splitting data into Training and Testing data sets. \n", "80% of the input data will be used for training and 20% for testing.\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "de3d59ee-462e-4c3f-a48e-17f2b030ac31", "_uuid": "6f4ee397e862bf95c53621e7159bd696fbea8fd5"}}, {"source": ["from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(input_train_one_hot_encoded, \n", "                                                    target_df, test_size=0.20, random_state=42)\n", "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n", "\n", "print (\"Training set has {} samples\".format(X_train.shape[0]))\n", "print (\"Testing set has {} samples\".format(X_test.shape[0]))"], "metadata": {"_cell_guid": "cc2f933f-8162-4596-8145-a91d16b68aba", "_uuid": "852c1e9d133b20a872d996ba5e2a3e1d87d6e414"}, "cell_type": "code", "outputs": [], "execution_count": 28}, {"source": ["**Model application - Logistic Classificatioin******"], "cell_type": "markdown", "metadata": {"_cell_guid": "3d5ba552-a935-418b-9ab6-4d52c6c9e676", "_uuid": "af86d660e872f6c61dacda231e45a069d920065b"}}, {"source": ["## Logistic classification\n", "from sklearn import linear_model\n", "from sklearn.metrics import accuracy_score, fbeta_score\n", "\n", "clf_A = linear_model.LogisticRegression()\n", "clf_A.fit(X_train, y_train)\n", "pred = clf_A.predict(X_test)\n", "accuracy = accuracy_score(pred, y_test)\n", "f_score = fbeta_score(y_test, pred, beta=0.5)\n", "\n", "print (\"Accuracy score of logistic classification: {}\".format(accuracy))\n", "print (\"f_score of logistic classification: {}\".format(f_score))"], "metadata": {"_cell_guid": "e9c499c7-9ad1-4f3d-a2b5-55a9bd1d7114", "_uuid": "176dbb3e5614d33b8133006521883bf795de3f44"}, "cell_type": "code", "outputs": [], "execution_count": 29}, {"source": ["## Adaboost Classifier\n", "from sklearn.ensemble import AdaBoostClassifier\n", "clf_B = AdaBoostClassifier(random_state = 100)\n", "clf_B.fit(X_train, y_train)\n", "pred_1 = clf_B.predict(X_test)\n", "accuracy_1 = accuracy_score(pred_1, y_test)\n", "f_score_1 = fbeta_score(y_test, pred_1, beta=0.5)\n", "\n", "print (\"Accuracy score of AdaBoost classification: {}\".format(accuracy_1))\n", "print (\"f_score of AdaBoost classification: {}\".format(f_score_1))\n"], "metadata": {"_cell_guid": "6638774c-b5f5-4113-a23b-9c772840c4a0", "_uuid": "7e7884438f4c3029c386cacb500f9f575d0042ee"}, "cell_type": "code", "outputs": [], "execution_count": 30}, {"source": ["## Support Vector machine\n", "from sklearn import svm\n", "clf_C = svm.SVC(random_state = 100)\n", "clf_C.fit(X_train, y_train)\n", "pred_2 = clf_C.predict(X_test)\n", "accuracy_2 = accuracy_score(pred_2, y_test)\n", "f_score_2 = fbeta_score(y_test, pred_2, beta=0.5)\n", "\n", "print (\"Accuracy score of SVM classification: {}\".format(accuracy_2))\n", "print (\"f_score of SVM classification: {}\".format(f_score_2))"], "metadata": {"_cell_guid": "ad76ec64-83f7-441f-b42a-0bcbc90acf80", "_uuid": "5d018dcef949e6bfa4eb7ba356f453e6c0d44e8c"}, "cell_type": "code", "outputs": [], "execution_count": 21}, {"source": ["## Implementaion & Model tuning of RandomForest Classifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n", "\n", "clf_r = RandomForestClassifier(random_state = 100)\n", "## Parameters list to fine tune\n", "#parameters = {'criterion': ['gini', 'entropy'], 'n_estimators': [10, 20],\n", " #            'min_samples_split': [10, 15]}\n", "parameters = {'criterion': ['gini', 'entropy'], 'n_estimators': [50,100,400,700,1000],\n", "             'min_samples_split': [2, 4, 10,12,16], }\n", "scorer = make_scorer(fbeta_score, beta=0.5)\n", "\n", "# Perform grid search on the classifier \n", "grid_obj = GridSearchCV(clf_r, param_grid=parameters, scoring= scorer)\n", "grid_fit = grid_obj.fit(X_train, y_train)\n", "\n", "# best estimator\n", "best_clf_r = grid_fit.best_estimator_\n", "best_predictions = best_clf_r.predict(X_test)\n", "\n", "print(grid_fit.best_score_)\n", "print(grid_fit.best_params_) \n", "\n", "##Optimized model\n", "print (\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n", "print (\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"], "metadata": {"_cell_guid": "fff22a03-66ce-4f84-a489-972ff600a3e4", "_uuid": "e458c9407a8d47cc7f027a2f7fad43ddaab79566"}, "cell_type": "code", "outputs": [], "execution_count": 31}, {"source": ["## Implementaion - Model tuning of AdaBoost Classifier\n", "'''\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n", "\n", "clf = AdaBoostClassifier(random_state = 100)\n", "## Parameters list to fine tune\n", "parameters = {'learning_rate': [0.1,0.2, 0.3, 0.4, 0.5], 'n_estimators': [600, 800,1000]}\n", "scorer = make_scorer(fbeta_score, beta=0.5)\n", "\n", "# Perform grid search on the classifier \n", "grid_obj = GridSearchCV(clf, param_grid=parameters, scoring= scorer)\n", "grid_fit = grid_obj.fit(X_train, y_train)\n", "\n", "# best estimator\n", "best_clf = grid_fit.best_estimator_\n", "best_predictions = best_clf.predict(X_test)\n", "\n", "##Optimized model\n", "print (\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n", "print (\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n", "'''"], "metadata": {"_cell_guid": "9279f2df-da7f-4e2a-b95d-72445f28b089", "_uuid": "194cde367ab0ba085006bb84a4fe284a681befe9"}, "cell_type": "code", "outputs": [], "execution_count": 23}, {"source": ["Since accuracy and F-score is high when used the RandomForestClassifier, submitting the predictions on the test data set using this model."], "cell_type": "markdown", "metadata": {"_cell_guid": "5820f57f-f48f-4654-adfe-e9e6cbb21c4e", "_uuid": "b78245187f61abeea2a5718a895e7ad7ba432829"}}, {"source": ["test_pred = best_clf_r.predict(test_df_one_hot_encoded)\n", "\n", "submission = pd.DataFrame({\n", "           \"PassengerId\": test_df[\"PassengerId\"],\n", "           \"Survived\": test_pred\n", "           })\n", "\n", "submission.to_csv('submission.csv', index=False)"], "metadata": {"_cell_guid": "e147df52-137c-4750-8947-088ae14a7b7a", "_uuid": "c84220ae8fc8d15d51a229308b4c6b6f291643ca", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": 33}, {"source": [], "metadata": {"_cell_guid": "d1ef8525-70f1-4c22-b85f-ce63f815e144", "_uuid": "e47c9471dc0786d0219e5f74cee58336fddef99a", "collapsed": true}, "cell_type": "code", "outputs": [], "execution_count": null}]}