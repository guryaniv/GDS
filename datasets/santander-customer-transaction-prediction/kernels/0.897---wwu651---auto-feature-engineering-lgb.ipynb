{"cells":[{"metadata":{"_uuid":"ef78d260d5fb1a064dbe93d907a0a335519ecf48"},"cell_type":"markdown","source":"# Load Data & Overview"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set()\n\nimport lightgbm as lgb\nimport xgboost as xgb\n\n# sklearn tools for model training and assesment\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\nfrom sklearn.metrics import roc_curve, auc, accuracy_score,roc_auc_score\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.base import clone\n\nimport gc\nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d25444a0432a384afbc2bde297ff034618becb78"},"cell_type":"code","source":"train=pd.read_csv('../input/train.csv')\ntest=pd.read_csv('../input/test.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"755871385e1a9fc3b2f5f3ce08900ca3712f9d61"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# EDA"},{"metadata":{"_uuid":"25b9598b2b3926f05688c66d1b299a4b75b7f2ca"},"cell_type":"markdown","source":"## The Target"},{"metadata":{"trusted":true,"_uuid":"f0070c774021680cc8d05b3ed01e6966a4eee160"},"cell_type":"code","source":"sns.countplot(train['target'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"540143ff6ff32849fae9a1e5636743cfd87cfbe8"},"cell_type":"markdown","source":"The target is imbalance, and we will use AUC as the metric according to the requirement.  I tried SMOTE over sampling before but didn't help."},{"metadata":{"trusted":true,"_uuid":"d2383d4ea9a659c175d3547b178a3626ea9fb77a"},"cell_type":"code","source":"# Checking missing values\nprint(train.isnull().values.any())\nprint(test.isnull().values.any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f16ad3eb7a13db67be263696807d4d482f97a423","scrolled":true},"cell_type":"code","source":"# Features that have high correlations with the target\nfeatures=[]\ncor=[]\nfor feature in train.iloc[:,2:].columns:\n    if (train['target'].corr(train[feature])>0.05)|(train['target'].corr(train[feature])<-0.05):\n        features.append(feature)\n        cor.append(train['target'].corr(train[feature]))\n\ndf_corr=pd.DataFrame({'Features': features,'Correlations':cor}).sort_values(by='Correlations').set_index('Features')\n\ndf_corr.plot(kind='barh',figsize=(10,8))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fe75d48ae7637ce870f679564b6e6d85f1735fa"},"cell_type":"code","source":"# Feature with high skewness\nfeaturesSkew=[]\nskewness=[]\n\nfor feature in train.iloc[:,2:].columns:\n    if (train[feature].skew()>=0.5) | (train[feature].skew()<=-0.5) :\n        featuresSkew.append(feature)\n        skewness.append(train[feature].skew())\n\ndf_skew=pd.DataFrame({'Features':featuresSkew,'Skewness':skewness})\ndf_skew","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9668527454b1d33d2f4e686be7db33121efd9d8b"},"cell_type":"markdown","source":"There is no transformation needed."},{"metadata":{"_uuid":"8d60e6d7d496630229d0ada9ba41a19ce4d58fc4"},"cell_type":"markdown","source":"# Feature Engineering"},{"metadata":{"trusted":true,"_uuid":"b6036dd0336b70c2319bef31aeae3c1e13489470"},"cell_type":"code","source":"import featuretools as ft\nes = ft.EntitySet(id='Santander')\n\nes.entity_from_dataframe(dataframe=train[features],\n                         entity_id='train',\n                         make_index = True,\n                         index='index')\n\nfm, feat= ft.dfs(entityset=es, \n                 target_entity='train',\n                 trans_primitives=['multiply_numeric','add_numeric'],\n                 max_depth=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78153f8a2462ce8a04bdf1e442b7b8478d563422"},"cell_type":"code","source":"train=pd.concat((train,fm.iloc[:,len(features):]),axis=1)\n# release some memory\ndel fm\ngc.collect()\nfm=pd.DataFrame()\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a90bb0cb4d0cb7a24d34aa7e07d64e0e7cb3820"},"cell_type":"code","source":"es.entity_from_dataframe(dataframe=test[features],\n                         entity_id='test',\n                         make_index = True,\n                         index='index')\n\nfm_test, feat= ft.dfs(entityset=es, \n                 target_entity='test',\n                 trans_primitives=['multiply_numeric','add_numeric'],\n                 max_depth=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"990eee4b07dec294516143428211799ba6366a2b"},"cell_type":"code","source":"test=pd.concat((test,fm_test.iloc[:,len(features):]),axis=1)\n# release some memory\ndel fm_test\ngc.collect()\nfm_test=pd.DataFrame()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f2a461595d246b94be64af5a6bdd68ff81a64de"},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true,"_uuid":"c98b3b0cb868cc5bd40fda9a8ca23775af7c5889"},"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nrandom_state = 123\nkfold = StratifiedKFold(n_splits=12,shuffle=False,random_state=random_state)\npred_val = np.zeros(len(train))\nfeature_base=train.columns.tolist()[2:202]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec57327316890bab86ce762fa07ef84cd00352bf"},"cell_type":"code","source":"# Parameters are from https://www.kaggle.com/jesucristo/santander-magic-lgb\nparam = {\n        'bagging_freq': 5,\n        'bagging_fraction': 0.38,\n        'boost_from_average':'false',\n        'boost': 'gbdt',\n        'feature_fraction': 0.045,\n        'learning_rate': 0.01,\n        'max_depth': -1,  \n        'metric':'auc',\n        'min_data_in_leaf': 80,\n        'min_sum_hessian_in_leaf': 10.0,\n        'num_leaves': 13,\n        'num_threads': 8,\n        'tree_learner': 'serial',\n        'objective': 'binary', \n        'verbosity': 1\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8972773ca76641c2cce2d9ec09c8a7f8272532cd","scrolled":false},"cell_type":"code","source":"# Baseline model: LightGBM with no feature engineering and tunning.\nfor foldIdx, (trn_idx, val_idx) in enumerate(kfold.split(train.loc[:,feature_base], train['target'])):\n    print(\"Fold {}\".format(foldIdx))\n    lgbm_base=lgb.LGBMClassifier(n_estimators=100000,random_state=random_state,**param)\n    lgbm_base.fit(train.iloc[trn_idx][feature_base],train['target'][trn_idx],\n                  eval_set=[(train.iloc[trn_idx][feature_base],train['target'][trn_idx]),(train.iloc[val_idx][feature_base],train['target'][val_idx])],\n                  early_stopping_rounds = 5000,\n                  verbose=2000)\n    pred_val[val_idx] = lgbm_base.predict_proba(train.loc[val_idx,feature_base], num_iteration=lgbm_base.best_iteration_)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2457194592d8a353a5b1b970a455781e717d965"},"cell_type":"code","source":"# Evaluation\nprint('AUC score: %.5f' % roc_auc_score(train['target'],pred_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fa03f30d85401a213280a99c4d16d0d5521b5b7"},"cell_type":"code","source":"# Split X and y\nX_train=train.iloc[:,2:]\ny_train=train['target']\nX_test=test.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be5a1a182f0768fedfac59d32906d5e8c1003e53"},"cell_type":"code","source":"# Feature selection with LightGBM for all features\nlgbm_sel=lgb.LGBMClassifier(n_estimators=lgbm_base.best_iteration_,\n                        random_state=random_state,\n                        **param)\n\nembeded_lgb_selector = SelectFromModel(lgbm_sel, threshold='1.25*median')\nembeded_lgb_selector.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46993816271ea90290440e4f676937d522d63754"},"cell_type":"code","source":"embeded_lgb_support = embeded_lgb_selector.get_support()\nembeded_lgb_feature = X_train.loc[:,embeded_lgb_support].columns.tolist()\nprint(str(len(embeded_lgb_feature)), 'selected features')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7e3919d41be36b5a7524ceebf1086f02a69f2622"},"cell_type":"code","source":"# Fit the lightGBM with embeded_lgb_feature\npred_val = np.zeros(len(train))\npred_test = np.zeros(len(test))\nfor foldIdx, (trn_idx, val_idx) in enumerate(kfold.split(X_train.loc[:,embeded_lgb_feature], y_train)):\n    print(\"Fold {}\".format(foldIdx))\n    lgbm=lgb.LGBMClassifier(n_estimators=100000,random_state=random_state,**param)\n    lgbm.fit(X_train.iloc[trn_idx][embeded_lgb_feature],y_train[trn_idx],\n                  eval_set=[(X_train.iloc[trn_idx][embeded_lgb_feature],y_train[trn_idx]),(X_train.iloc[val_idx][embeded_lgb_feature],y_train[val_idx])],\n                  early_stopping_rounds = 5000,\n                  verbose=2000)\n    pred_val[val_idx] = lgbm.predict_proba(X_train.loc[val_idx,embeded_lgb_feature], num_iteration=lgbm.best_iteration_)[:,1]\n    pred_test += lgbm.predict_proba(X_test[embeded_lgb_feature],num_iteration=lgbm.best_iteration_)[:,1] / kfold.n_splits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e190b35749ccfded2f26cb738c56bfdfa3c98888"},"cell_type":"code","source":"# Evaluation\nprint('AUC score: %.5f' % roc_auc_score(y_train,pred_val))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61bb14e7423b572c2ee3da8b92ad62ecd752136c"},"cell_type":"markdown","source":"The AUC score is not better with more features and the model tended to overfit. I will explore more ideas on 1)feature engineering, 2)feature selection and 3)ensemble modeling. "},{"metadata":{"trusted":true,"_uuid":"fb24ac14ec5e4fcaa4e35b6a9d689001a6cc5a3f"},"cell_type":"code","source":"# Submission\nsubmission = pd.DataFrame({'ID_code': test.ID_code.values,\n                           'target':pred_test})\nsubmission.to_csv(\"LGBM_V1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e96c1e45579056ed5cdd1ed14b21721100462bed"},"cell_type":"markdown","source":"# Reference\n\n[What is the acceptable range of skewness and kurtosis for normal distribution of data?](https://codeburst.io/2-important-statistics-terms-you-need-to-know-in-data-science-skewness-and-kurtosis-388fef94eeaa)\n\n[Auto feature engineering with feature tool](https://docs.featuretools.com/loading_data/using_entitysets.html)\n\n[Auto feature engineering Kaggle case](https://www.kaggle.com/willkoehrsen/featuretools-for-good)\n\n[How to choose metrics for imbalance dataset](https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba)\n\n[Santander Magic LGB](https://www.kaggle.com/jesucristo/santander-magic-lgb)\n\n[6 Ways for Feature Selection](https://www.kaggle.com/sz8416/6-ways-for-feature-selection)\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}