{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom keras.preprocessing.image import ImageDataGenerator\n#================================\n# import the necessary packages\n#from keras.models import Sequential\n#from keras.layers.normalization import BatchNormalization\n#from keras.layers.convolutional import Conv2D\n#from keras.layers.convolutional import MaxPooling2D\n#from keras.layers.core import Activation\n#from keras.layers.core import Flatten\n#from keras.layers.core import Dropout\n#from keras.layers.core import Dense\n#from keras import backend as K\n\n#================================\n\nimport matplotlib\n#matplotlib.use(\"Agg\")\n \n# import the necessary packages\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import img_to_array\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.model_selection import train_test_split\n#from pyimagesearch.smallervggnet import SmallerVGGNet\nimport matplotlib.pyplot as plt\n#from imutils import paths\nimport numpy as np\n#import argparse\nimport random\nimport pickle\nimport cv2\nimport os\n\nfrom PIL import Image\nfrom collections import Counter\n\nfrom keras.preprocessing.image import ImageDataGenerator\n#from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n\nfrom tensorflow.python.keras.applications import ResNet50, InceptionResNetV2\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D,BatchNormalization, MaxPooling2D\nfrom keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.layers.convolutional import Conv2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.python.keras.layers.core import Activation, Dropout\nfrom tensorflow.python.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nimport sklearn.preprocessing\nimport sklearn.model_selection\nimport sklearn.metrics\nimport sklearn.linear_model\nimport sklearn.naive_bayes\nimport sklearn.tree\nimport sklearn.ensemble\n\nfrom tqdm import tqdm\n\nfrom os.path import join, exists, expanduser","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"517c7199f827cfa700f34c3a8d567c8c617d202a"},"cell_type":"code","source":"cache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    os.makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20f16c5baf9b994b07a1039b64af830ca5769b6b"},"cell_type":"code","source":"nepochs = 36\n#nsamples = 1200\nimg_size=256\nnclass=28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"086e32bc4e3c83dcda9ef1bd0e56b4d8d87bbd38"},"cell_type":"code","source":"train = pd.read_csv(\"../input/human-protein-atlas-image-classification/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3315ea9ff23206fe16de0ed72b97240e237ad5c3"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"247fe437f26e35bd0ef4d05b1dcd3c9715ccfb37"},"cell_type":"code","source":"train['Labels'] = train['Target'].map(lambda x: [int(y) for y in x.split(' ')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"124fe4a88f6bc83e1328d9cd907342b13818d1f6"},"cell_type":"code","source":"for i in range(nclass):\n    train[i] = train['Labels'].map(lambda x: int(i in x))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58e7f018ea853a60176fb48b6ef012dd6507ce91"},"cell_type":"code","source":"counts = train[list(range(nclass))].sum().sort_values(ascending=False)\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f612f3c144b5e547d4e1b9b1edc628a80ef0e59f"},"cell_type":"code","source":"temp = pd.DataFrame()\n\nfor i in range(nclass):\n    l = min(counts[i],50)\n    if i == 0:\n        temp = train[train[i]>0][:l]\n    else:\n        temp = temp.append(train[train[i]>0][:l]).drop_duplicates(subset='Id')\ntrain = temp\ncounts = train[list(range(nclass))].sum().sort_values(ascending=False)\ncounts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"631fa76ad14d87bf69d84b480b4a2bea4932ce3e"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8b9f914fbcd17a77aec91f02ed5497242d61905"},"cell_type":"code","source":"def read_img(train_test,img_id,size):\n    img_r = Image.open('../input/human-protein-atlas-image-classification/'+train_test+'/'+img_id+'_red.png').resize((size,size))\n    img_g = Image.open('../input/human-protein-atlas-image-classification/'+train_test+'/'+img_id+'_green.png').resize((size,size))\n    img_b = Image.open('../input/human-protein-atlas-image-classification/'+train_test+'/'+img_id+'_blue.png').resize((size,size))\n    return preprocess_input(np.expand_dims(np.stack([img_r,img_g,img_b],-1).copy(), axis=0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f06cb938c614bc7e179693f85a3ca0bd4b2e36d"},"cell_type":"code","source":"x_trains = np.zeros((len(train), img_size, img_size, 3), dtype='float32')\nfor i, img_id in tqdm(enumerate(train['Id'])):\n    x_trains[i]  = read_img('train',img_id, img_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa0085172ba46065971ba0d7e0210bf3366dadd4"},"cell_type":"code","source":"y_trains = train[list(range(nclass))].values ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e3347e47430957f0d71c6a8d921372268dbdbe"},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e632a3bb47e51caf2bbf6c49caec90c50495ea3"},"cell_type":"code","source":"if False:\n    resnet_weights_path = '../input/keras-pretrained-models/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    os.system(\"cp ../input/keras-pretrained-models/inception_resnet_v2* ~/.keras/models/\")\n    model = Sequential()\n    model.add(InceptionResNetV2(include_top=False, pooling='avg', \n                                weights=resnet_weights_path, input_shape = (img_size, img_size, 3)))\n#    for i in range(20):\n#        model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n#        model.add(BatchNormalization(axis=-1))\n#    model.add(GlobalAveragePooling2D())\n#    model.add(Dropout(0.25))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.25))\n#    model.add(Dense(128, activation='relu'))\n#    model.add(Dropout(0.25))\n#    model.add(Dense(64, activation='relu'))\n    model.add(Dense(nclass, activation='softmax'))\n    init_lr=0.001\n    opt = Adam(lr=init_lr, decay=init_lr / nepochs)\n\n    # Say not to train first layer (ResNet) model. It is already trained\n    model.layers[0].trainable = False\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b54ed91e2a2121bf64a8c39fd7ee452629caa46b"},"cell_type":"code","source":"if True:\n    resnet_weights_path = '../input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    os.system(\"cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/\")\n    model = Sequential()\n    model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path, input_shape = (img_size, img_size, 3)))\n    model.add(Dense(512, activation='relu'))\n    model.add(Dropout(0.25))\n    model.add(Dense(256, activation='relu'))\n    model.add(Dropout(0.25))\n#    model.add(Dense(128, activation='relu'))\n#    model.add(Dropout(0.25))\n#    model.add(Dense(64, activation='relu'))\n    model.add(Dense(nclass, activation='softmax'))\n    init_lr=0.001\n    opt = Adam(lr=init_lr, decay=init_lr / nepochs)\n\n    # Say not to train first layer (ResNet) model. It is already trained\n    model.layers[0].trainable = False\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f61fb337ca120a34caff969351ce2bc5a9a30378"},"cell_type":"code","source":"batch_size=32\ncv_num=10\nkfold=sklearn.model_selection.KFold(cv_num,shuffle=True,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c8e403a2d1fbe8e2db57d53332c7e07e44c2538"},"cell_type":"code","source":"histories=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02144a62051a7882e131513b4b0736859ec54698","scrolled":false},"cell_type":"code","source":"if True:\n    datagen = ImageDataGenerator(\n        samplewise_std_normalization=False,\n        rotation_range=360,\n        width_shift_range=0,\n        height_shift_range=0,\n        zoom_range = 0.2,\n        featurewise_center = False,\n        samplewise_center = False,\n        horizontal_flip=True,\n        vertical_flip=True)\n    \n    for i,(train_index,valid_index) in enumerate(kfold.split(y_trains)):\n        #x_train = x_trains[train_index]\n        #y_train = y_trains[train_index]\n        #x_valid = x_trains[valid_index]\n        #y_valid = y_trains[valid_index]\n        \n# fits the model on batches with real-time data augmentation:\n        histories.append(model.fit_generator(datagen.flow(x_trains[train_index], y_trains[train_index], batch_size=batch_size),\n                    steps_per_epoch=len(x_trains[train_index]) // batch_size, \n                    validation_data=datagen.flow(x_trains[valid_index], y_trains[valid_index], batch_size=batch_size),\n                    validation_steps=len(y_trains[valid_index])//batch_size,\n   #                 callbacks=[EarlyStopping()],\n                    epochs=nepochs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f968e2790c5cfe069cf00b2457fb2c9333db867"},"cell_type":"code","source":"fig, arr = plt.subplots(cv_num,2,figsize=(8,40), sharex=True, sharey='col')\nfor i in range(cv_num):\n    arr[i][0].plot(histories[i].history['acc'])\n    arr[i][0].plot(histories[i].history['val_acc'])\n    arr[i][0].set_title(str(i)+' accuracy')\n    arr[i][0].legend(['train','test'],loc='upper left')\n\n    arr[i][1].plot(histories[i].history['loss'])\n    arr[i][1].plot(histories[i].history['val_loss'])\n    arr[i][1].set_title(str(i)+' loss')\n    arr[i][1].legend(['train','test'],loc='upper left')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"497ea6962c4d735f22ea77c0014a7d405ea66bdc"},"cell_type":"code","source":"submit = pd.read_csv('../input/human-protein-atlas-image-classification/sample_submission.csv')\n\ny_preds_labels = []\nfor i, img_id in tqdm(enumerate(submit['Id'])):\n    y_pred = model.predict(read_img('test',img_id, img_size))\n    c = np.arange(nclass)[y_pred[0] >= 0.5]\n    label = ' '.join(str(cc) for cc in c)\n    y_preds_labels.append(label)\n\nsubmit['Predicted'] = y_preds_labels\nsubmit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}