{"cells":[{"metadata":{"_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199","_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nYou will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n\nThe data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n\nCome to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n\n# Write Your Code Below\n\n"},{"metadata":{"_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"1c728098629e1301643443b1341556a15c089b2b","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nmain_file_path = '../input/train.csv'\ndata = pd.read_csv(main_file_path)\nprint('hello world')\nprint(data.describe())\nprint (data.columns)\nmelbourne_price_data = data.SalePrice\nmelbourne_price_data.head()\ncolumns_of_interest = [\"LotArea\", \"PoolArea\"]\ntwo_columns_of_data = data[columns_of_interest]\nprint(two_columns_of_data.head())\nprint(two_columns_of_data.describe())\n\n\n","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"929a10d15a2414f57cf94855027331ae82dfa247"},"cell_type":"code","source":"y = data.SalePrice\ndata_predictors = [\"LotArea\", \"YearBuilt\", \"1stFlrSF\", \"2ndFlrSF\", \"FullBath\", \"BedroomAbvGr\", \"TotRmsAbvGrd\" ]\nX = data[data_predictors]\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmy_data_model = DecisionTreeRegressor()\nmy_data_model.fit(X,y)\nprint(\"Making predictions for the following 5 houses:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(my_data_model.predict(X.head()))\n\nfrom sklearn.metrics import mean_absolute_error\nPredicted_prices = my_data_model.predict(X)\nprint(mean_absolute_error(y, Predicted_prices))","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2883555f85b21faca7b6e514755afff3938671da"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n# Define model\n#print(X.shape, train_X.shape)\nmelbourne_model = DecisionTreeRegressor()\n# Fit model\nmelbourne_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = melbourne_model.predict(val_X)\nprint(\"mean_abs_err= %f\" %mean_absolute_error(val_y, val_predictions))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e13c3b8f8f99dccdefbdd0da8a02531b12705c22"},"cell_type":"code","source":"\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\n# compare MAE with differing values of max_leaf_nodes\nfor max_leaf_nodes in [5, 25, 50, 100, 250, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3c9e62ad2d9f91face9102694de861ad230991b"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)\nmelb_preds = forest_model.predict(val_X)\nprint(melb_preds)\nprint(mean_absolute_error(val_y, melb_preds))","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1221425fbf44e4a8765e1fd6980798af064eb50"},"cell_type":"code","source":"# Read the test data\ntest = pd.read_csv('../input/test.csv')\n# Treat the test data in the same way as training data. In this case, pull same columns.\ntest_X = test[data_predictors]\n# Use the model to make predictions\npredicted_prices = forest_model.predict(test_X)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)\n\nmy_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\n\n","execution_count":28,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}