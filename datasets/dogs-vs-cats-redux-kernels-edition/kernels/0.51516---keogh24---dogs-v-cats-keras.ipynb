{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2, random\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n# print(os.listdir(\"../input\"))\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caef5b38cff62092c3b3d549575414f8930e9c61"},"cell_type":"code","source":"np.random.seed(1339)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12f0bef1cfe9ea85ddbf729c6bf8c60698bbfb0a"},"cell_type":"code","source":"img = cv2.imread('../input/train/dog.3.jpg')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69ad3259d890f565dd4f8c6f4e5846791057bfb2"},"cell_type":"markdown","source":"## Prep data\nbased on https://www.kaggle.com/jeffd23/catdognet-keras-convnet-starter"},{"metadata":{"trusted":true,"_uuid":"f7f67dad96dd0aa3cdc9febd00333dcc1a277d7a"},"cell_type":"code","source":"TRAIN_DIR = '../input/train/'\nTEST_DIR = '../input/test/'\n\nROWS = 100\nCOLS = 100\nCHANNELS = 3\n\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntrain_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\ntrain_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n\ntest_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n\n# slice datasets for memory efficiency on Kaggle Kernels, delete if using full dataset\n# train_images = train_dogs[:5000] + train_cats[:5000]\nrandom.shuffle(train_images)\n# test_images =  test_images[:100]\n\ndef read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n\n\ndef prep_data(images):\n    count = len(images)\n    data = np.ndarray((count, ROWS, COLS, CHANNELS), dtype=np.float32)\n\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        image = image / 255\n        data[i] = image\n        if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a22d77068d3bb3e0cb40f9296f1eb763e083280d"},"cell_type":"code","source":"len(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce95137cecdfcbbd839c901bc8402c4537627c47"},"cell_type":"code","source":"len(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"733f0f6936902651ca3a504a72869b2e2cf68565"},"cell_type":"code","source":"train = prep_data(train_images)\ntest = prep_data(test_images)\n\nprint(\"Train shape: {}\".format(train.shape))\nprint(\"Test shape: {}\".format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74dd65075d9eb7b43a16557ea04ee5223a26a192"},"cell_type":"code","source":"labels = []\nfor i in train_images:\n    if 'dog' in i:\n        labels.append(1)\n    else:\n        labels.append(0)\nlabels = np.asarray(labels).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec35b4fdcd9d6179da592f7026db0005de9fdb91"},"cell_type":"code","source":"train_images[1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2703e5b0f838e2dba5592bb1b1c363e6c9f5879"},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true,"_uuid":"5d505e1c37ebea3bc3b572f4663aa08f61207a5e"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(ROWS, COLS, CHANNELS)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(Conv2D(256, (3, 3), activation='relu'))\n# model.add(Conv2D(256, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(1024, activation='relu'))\n# model.add(Dense(1000, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c23d03bc17c875846c21040e844e6df13044bde"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a537b2cf376dda9d37870a101544f32c1db817cc"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n             optimizer='rmsprop',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e54dc71a0390807e1d5c92cd05bff1504e3c971"},"cell_type":"code","source":"history = model.fit(train, labels, validation_split=0.2, epochs=20, batch_size=200, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98e65a3c07193562a45adb4051d7d7d37d3832ff"},"cell_type":"code","source":"history_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\nepochs = range(1, len(loss_values) + 1)\nplt.plot(epochs, loss_values, 'bo', label='Training loss')\nplt.plot(epochs, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b17071bbb56274d48ec15d2ac290c5aa5430e1c1"},"cell_type":"code","source":"acc_values = history_dict['acc']\nval_acc_values = history_dict['val_acc']\nplt.plot(epochs, acc_values, 'bo', label='Training acc')\nplt.plot(epochs, val_acc_values, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88210adea1fc8c943501a7db2bdb959948fe3c5f"},"cell_type":"code","source":"predictions = model.predict(test, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87d35b3a620e47e2d696cb08e70add991e445389"},"cell_type":"code","source":"for i in range(0,10):\n    if predictions[i, 0] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n\n    plt.imshow(test[i])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c60f54fc069068417284508d690fa02dff12094"},"cell_type":"code","source":"# model.save('dogs-v-cats-v01.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52e0f2cdc1016a7d2de71550f8e4da0fd437d9ff"},"cell_type":"code","source":"test_images[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d734121d6c0e2c3baf213cafe4d3f1f17846368a"},"cell_type":"code","source":"predictions[0, 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a02c13a16131f5884bcf2c67f4c7e558fc15c25f"},"cell_type":"code","source":"import csv\n\nwith open('results01.csv', 'w') as csvfile:\n    writer = csv.writer(csvfile, delimiter=',',\n                        quotechar='|', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow(['id', 'label'])\n    for i, path in enumerate(test_images):\n        basename = os.path.basename(path)\n        name = os.path.splitext(basename)[0]\n        writer.writerow([name, predictions[i, 0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dd2de498e4b723d1ba011f1638d5141b11c2e43"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcaf1354a4f95ca845bf012240524dd28091684a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"716264361d293a1812dc4f2362d9c926ce64bf0e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a566f1873c39d4c73f7b575c9509bc4482db24c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e6f8b310864eec18478a33c4a8f320cfab9780b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1d07a71fb8ea2eca485308c2bf3db619c721f86"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19aeeaedcfce4b971a9451c627caa87f7c15132c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}