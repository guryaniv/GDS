{"cells":[{"metadata":{"_uuid":"0e45310aa62f5040d1435325cc66108ecefe3ed8"},"cell_type":"markdown","source":"# Finding ships in satellite images, using U-Net model\n\nHere I compare predicitions with different changes to the training data.\n\nReferences\n* https://arxiv.org/pdf/1505.04597.pdf\n* https://github.com/jakeret/tf_unet\n* https://www.kaggle.com/kmader/baseline-u-net-model-part-1"},{"metadata":{"trusted":true,"_uuid":"7271ae326dda79e2757561ab812675c1972c39a0","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pandas as pd\nimport os\nBOAT_LOCATIONS = pd.read_csv(os.path.join('../input', 'train_ship_segmentations_v2.csv'))\n\nTOP_50_SHIP_IMGS = [\n    'a81100305.jpg', '08216b410.jpg', 'ebc35d891.jpg', 'e44e2c614.jpg',\n    '3105c0420.jpg', 'a0d96b1b8.jpg', '79bb365b9.jpg', 'd26e81921.jpg',\n    'c28f4836c.jpg', '554616297.jpg', 'd008303a2.jpg', '567ab6c4f.jpg',\n    'f073dd78b.jpg', 'bd4f94cbc.jpg', '73122cca0.jpg', '392424e94.jpg',\n    '6fc3838b3.jpg', '26f128c0c.jpg', '398e139de.jpg', '1762993f7.jpg',\n    '9b2754ced.jpg', 'eac759ca6.jpg', '34a097ff2.jpg', '0fd84d04a.jpg',\n    '6928ac085.jpg', '0235db857.jpg', 'b178a4c2f.jpg', '2296fb360.jpg',\n    '5b190f4ae.jpg', '3975f9d0b.jpg', '6a76c5aee.jpg', '52554d6ee.jpg',\n    '3c678278d.jpg', '5bd280cc1.jpg', 'd00965b66.jpg', 'f6e008b23.jpg',\n    '7e5705d1f.jpg', '8157ad66f.jpg', 'edec35a72.jpg', '9b7785d98.jpg',\n    '4830cb243.jpg', '43f6fce62.jpg', '99d10330c.jpg', '278e44498.jpg',\n    '9d7a2fa1b.jpg', 'bcd16b011.jpg', '5d0018daf.jpg', '0334e61a7.jpg',\n    'eeafd580e.jpg', 'ccfb18b6c.jpg']\n\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list):\n    '''Take the individual ship masks and create a single mask array for all ships'''\n    all_masks = np.zeros((768, 768), dtype = np.int16)\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)\n\n\nimport os\nfrom skimage.io import imread\nimport numpy as np\ndef get_img_and_label(img_dir, img_file, masks=BOAT_LOCATIONS):\n    raw_img = imread(os.path.join(img_dir, img_file))\n    c_img = np.stack([raw_img], 0)/255.0\n\n    rle_list = masks.query('ImageId==\"' + img_file + '\"')['EncodedPixels']  # pd.Series, 1 line of RLE per boat\n    raw_img = masks_as_image(rle_list)\n    lb_img = np.stack([raw_img], 0)\n\n    return c_img, lb_img\n\ndef create_gen_1_img():\n    img_dir = '../input/train_v2'\n    while True:\n        img_file = 'ccfb18b6c.jpg'\n        yield get_img_and_label(img_dir, img_file)\n\ndef create_gen_top_50_ships():\n    return create_gen_from_file_list(TOP_50_SHIP_IMGS)\n    \ndef create_gen_from_file_list(filelist):\n    img_dir = '../input/train_v2'\n    i = -1\n    while True:\n        i = (i + 1) % len(filelist)\n        img_file = filelist[i]\n        yield get_img_and_label(img_dir, img_file)\n    \n#test generator by plotting an image + label    \n#import matplotlib.pyplot as plt\n#g = create_gen_top_50_ships()\n#for i in range(4):\n#    (x, y) = next(g)\n#    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n#    ax1.imshow(x[0, :, :, 0:3])\n#    ax2.imshow(y[0, :, :, 0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"301a5d939c566d1487a049bb2554d09b592b18b1","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"BATCH_SIZE = 1  #4\nEDGE_CROP = 16\nNB_EPOCHS = 2  #5\nGAUSSIAN_NOISE = 0.1\nUPSAMPLE_MODE = 'SIMPLE'\n# downsampling inside the network\nNET_SCALING = None\n# downsampling in preprocessing\nIMG_SCALING = None  #(1, 1)\n# number of validation images to use\nVALID_IMG_COUNT = 400  \n# maximum number of steps_per_epoch in training\nMAX_TRAIN_STEPS = 20  #200\nAUGMENT_BRIGHTNESS = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c826bd059a97f34ef3549a393d140dd1451d657","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage.segmentation import mark_boundaries\nfrom skimage.util.montage import montage2d as montage\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nship_dir = '../input'\ntrain_image_dir = os.path.join(ship_dir, 'train_v2')\ntest_image_dir = os.path.join(ship_dir, 'test_v2')\nimport gc; gc.enable() # memory is tight\n\nfrom skimage.morphology import label\ndef multi_rle_encode(img):\n    labels = label(img[:, :, 0])\n    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\ndef masks_as_image(in_mask_list):\n    # Take the individual ship masks and create a single mask array for all ships\n    all_masks = np.zeros((768, 768), dtype = np.int16)\n    #if isinstance(in_mask_list, list):\n    for mask in in_mask_list:\n        if isinstance(mask, str):\n            all_masks += rle_decode(mask)\n    return np.expand_dims(all_masks, -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ca7119188fbb4c6540d9df55f5833b55435287e","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"masks = pd.read_csv(os.path.join('../input/',\n                                 'train_ship_segmentations_v2.csv'))\nprint(masks.shape[0], 'masks found')\nprint(masks['ImageId'].value_counts().shape[0])\nmasks.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0081fd6f387abd7c05eb35f29575a2ee6ddc2236","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nrle_0 = masks.query('ImageId==\"00021ddc3.jpg\"')['EncodedPixels']\nimg_0 = masks_as_image(rle_0)\nax1.imshow(img_0[:, :, 0])\nax1.set_title('Image$_0$')\nrle_1 = multi_rle_encode(img_0)\nimg_1 = masks_as_image(rle_1)\nax2.imshow(img_1[:, :, 0])\nax2.set_title('Image$_1$')\nprint('Check Decoding->Encoding',\n      'RLE_0:', len(rle_0), '->',\n      'RLE_1:', len(rle_1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4f008bf6898518fd371de013418f936edaa09f8","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\nunique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\nunique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\nunique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n# some files are too small/corrupt\nunique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n                                                               os.stat(os.path.join(train_image_dir, \n                                                                                    c_img_id)).st_size/1024)\nunique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\nunique_img_ids['file_size_kb'].hist()\nmasks.drop(['ships'], axis=1, inplace=True)\nunique_img_ids.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"871720221ac25f7f9408bfe01aeb4ccb95edbd1f","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_ids, valid_ids = train_test_split(unique_img_ids, \n                 test_size = 0.3, \n                 stratify = unique_img_ids['ships'])\ntrain_df = pd.merge(masks, train_ids)\nvalid_df = pd.merge(masks, valid_ids)\nprint(train_df.shape[0], 'training masks')\nprint(valid_df.shape[0], 'validation masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2612fa47c7e9fdcaa7aa720c4e15fc86fd65d69a","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"train_df['ships'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf0bb261eda957cb0a12a330260e1390c57c8c9","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\ndef sample_ships(in_df, base_rep_val=1500):\n    if in_df['ships'].values[0]==0:\n        return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n    else:\n        return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n    \nbalanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\nbalanced_train_df['ships'].hist(bins=np.arange(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6181ac51577e5636995e38a9e29311cf47f513ca","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def make_image_gen(in_df, batch_size = BATCH_SIZE):\n    all_batches = list(in_df.groupby('ImageId'))\n    out_rgb = []\n    out_mask = []\n    while True:\n        np.random.shuffle(all_batches)\n        for c_img_id, c_masks in all_batches:\n            rgb_path = os.path.join(train_image_dir, c_img_id)\n            c_img = imread(rgb_path)\n            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n            if IMG_SCALING is not None:\n                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n            out_rgb += [c_img]\n            out_mask += [c_mask]\n            if len(out_rgb)>=batch_size:\n                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n                out_rgb, out_mask=[], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1983738da75b031f2bec8ba36db01c095e7c5d59","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_gen = make_image_gen(balanced_train_df)\ntrain_x, train_y = next(train_gen)\nprint('x', train_x.shape, train_x.min(), train_x.max())\nprint('y', train_y.shape, train_y.min(), train_y.max())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4396cd28ddd2e4c8076fcb165e9b61e3baeeeb7","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\nbatch_rgb = montage_rgb(train_x)\nbatch_seg = montage(train_y[:, :, :, 0])\nax1.imshow(batch_rgb)\nax1.set_title('Images')\nax2.imshow(batch_seg)\nax2.set_title('Segmentations')\nax3.imshow(mark_boundaries(batch_rgb, \n                           batch_seg.astype(int)))\nax3.set_title('Outlined Ships')\nfig.savefig('overview.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30cb02a2a7103a9d66e90f701991199de1e5b73e","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\nprint(valid_x.shape, valid_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 15, \n                  width_shift_range = 0.1, \n                  height_shift_range = 0.1, \n                  shear_range = 0.01,\n                  zoom_range = [0.9, 1.25],  \n                  horizontal_flip = True, \n                  vertical_flip = True,\n                  fill_mode = 'reflect',\n                  data_format = 'channels_last')\n# brightness can be problematic since it seems to change the labels differently from the images \nif AUGMENT_BRIGHTNESS:\n    dg_args[' brightness_range'] = [0.5, 1.5]\nimage_gen = ImageDataGenerator(**dg_args)\n\nif AUGMENT_BRIGHTNESS:\n    dg_args.pop('brightness_range')\nlabel_gen = ImageDataGenerator(**dg_args)\n\ndef create_aug_gen(in_gen, seed = None):\n    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n    for in_x, in_y in in_gen:\n        seed = np.random.choice(range(9999))\n        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n        g_x = image_gen.flow(255*in_x, \n                             batch_size = in_x.shape[0], \n                             seed = seed, \n                             shuffle=True)\n        g_y = label_gen.flow(in_y, \n                             batch_size = in_x.shape[0], \n                             seed = seed, \n                             shuffle=True)\n\n        yield next(g_x)/255.0, next(g_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6122ccb9e58bfac6fa5e11c86121e78d9e5151b1","scrolled":false,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cur_gen = create_aug_gen(train_gen)\nt_x, t_y = next(cur_gen)\nprint('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\nprint('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n# only keep first 9 samples to examine in detail\nt_x = t_x[:9]\nt_y = t_y[:9]\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\nax1.imshow(montage_rgb(t_x), cmap='gray')\nax1.set_title('images')\nax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\nax2.set_title('ships')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33300c4f03b6600da7b418f775d11d7ebf76a35a","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2687377309d3cbbab1197f4eccd2b50ab996f5a6","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"from keras import models, layers\n# Build U-Net model\ndef upsample_conv(filters, kernel_size, strides, padding):\n    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\ndef upsample_simple(filters, kernel_size, strides, padding):\n    return layers.UpSampling2D(strides)\n\nif UPSAMPLE_MODE=='DECONV':\n    upsample=upsample_conv\nelse:\n    upsample=upsample_simple\n\ninput_shape = (768, 768, 3)  # t_x.shape[1:]\nprint('input_shape ' + str(type(input_shape)) + '\\n' + str(input_shape))\n\ninput_img = layers.Input(input_shape, name = 'RGB_Input')\npp_in_layer = input_img\nif NET_SCALING is not None:\n    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n    \npp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\npp_in_layer = layers.BatchNormalization()(pp_in_layer)\n\nc1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (pp_in_layer)\nc1 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = layers.MaxPooling2D((2, 2)) (c1)\n\nc2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = layers.MaxPooling2D((2, 2)) (c2)\n\nc3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = layers.MaxPooling2D((2, 2)) (c3)\n\nc4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = layers.MaxPooling2D(pool_size=(2, 2)) (c4)\n\n\nc5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = layers.Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = upsample(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = layers.concatenate([u6, c4])\nc6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = layers.Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = upsample(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = layers.concatenate([u7, c3])\nc7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = layers.Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = upsample(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = layers.concatenate([u8, c2])\nc8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = layers.Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = upsample(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = layers.concatenate([u9, c1], axis=3)\nc9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = layers.Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\nd = layers.Conv2D(1, (1, 1), activation='sigmoid') (c9)\nd = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\nd = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\nif NET_SCALING is not None:\n    d = layers.UpSampling2D(NET_SCALING)(d)\n\nseg_model = models.Model(inputs=[input_img], outputs=[d])\nseg_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1678069aa8013510264ba898291c6ae2dce88a76","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"import keras.backend as K\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\ndef dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\ndef dice_p_bce(in_gt, in_pred):\n    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\ndef true_positive_rate(y_true, y_pred):\n    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n\nseg_model.compile(optimizer=Adam(1e-4, decay=1e-6), \n                  loss=dice_p_bce, \n                  metrics=[dice_coef, 'binary_accuracy', true_positive_rate])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7282d18de3aff1cee12ff89b7d511a391702814f","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('seg_model')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n                             save_best_only=True, mode='max', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n                                   patience=3, \n                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\nearly = EarlyStopping(monitor=\"val_dice_coef\", \n                      mode=\"max\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b67d808c0b8c7e28bff41e6d3858ff6f09dd626","scrolled":false,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"# balanced_train_df.shape[0]=11000,  11000 rows x 7 columns\nNB_EPOCHS = 3\nMAX_TRAIN_STEPS = 20\nstep_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n\naug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n\nprint('step_count=' + str(step_count))\nprint('balanced_train_df ' + str(type(balanced_train_df)) + '\\n' + str(balanced_train_df.head()))\n\nloss_history = [seg_model.fit_generator(aug_gen, \n                       steps_per_epoch=step_count, \n                       epochs=NB_EPOCHS, \n                       validation_data=(valid_x, valid_y),\n                       callbacks=callbacks_list,\n                       workers=1 # the generator is not very thread safe\n                       )]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a168c8b1af446b800f6129104906003ededd61c4","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"def show_loss(loss_history):\n    epich = np.cumsum(np.concatenate(\n        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n    _ = ax1.plot(epich,\n                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n                 'b-',\n                 epich, np.concatenate(\n            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n    ax1.legend(['Training', 'Validation'])\n    ax1.set_title('Loss')\n\n    _ = ax2.plot(epich, np.concatenate(\n        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n                     epich, np.concatenate(\n            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n                     'r-')\n    ax2.legend(['Training', 'Validation'])\n    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n    \n    _ = ax3.plot(epich, np.concatenate(\n        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n                     epich, np.concatenate(\n            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n                     'r-')\n    ax3.legend(['Training', 'Validation'])\n    ax3.set_title('Binary Accuracy (%)')\n    \n    _ = ax4.plot(epich, np.concatenate(\n        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n                     epich, np.concatenate(\n            [mh.history['val_dice_coef'] for mh in loss_history]),\n                     'r-')\n    ax4.legend(['Training', 'Validation'])\n    ax4.set_title('DICE')\n\nshow_loss(loss_history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce1167e9f09200f537e61f93f486168a13be1711","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"seg_model.load_weights(weight_path)  # not sure why to 'save'\nseg_model.save('seg_model.h5')  # not sure why to 'save'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"275b411dc97a350aacaba46c8562efcf2658b1a7","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pred_y = seg_model.predict(valid_x)\nprint(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69141c3af95ce8a76eaf257c02752e5ceb60a5a8"},"cell_type":"markdown","source":"# Ship Predictions after Round 1 of Training"},{"metadata":{"trusted":true,"_uuid":"6a4fd2ca0cf47ba069a314356bf74c7b531c56ac"},"cell_type":"code","source":"#fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n#ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))  # histogram of image coverage, comparing 400 predictions\n#ax.set_xlim(0, 1)\n#ax.set_yscale('log', nonposy='clip')\n\n#1\nfig, mxs = plt.subplots(10, 10, figsize = (20, 20))\ni = 0\nfor ax_list in mxs:\n    for ax in ax_list:\n        ax.imshow(pred_y[i, :, :, 0], vmin = 0, vmax = 1)\n        i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e2d6d59a91d99bb8efe3d8498b6e0d8c21dee51"},"cell_type":"code","source":"# train more\naug_gen = create_aug_gen(make_image_gen(balanced_train_df))\nloss_history = [seg_model.fit_generator(aug_gen, \n                       steps_per_epoch=step_count, \n                       epochs=NB_EPOCHS, \n                       validation_data=(valid_x, valid_y),\n                       callbacks=callbacks_list,\n                       workers=1 # the generator is not very thread safe\n                       )]\nseg_model.load_weights(weight_path)  # not sure why to 'save'\nseg_model.save('seg_model.h5')  # not sure why to 'save'\npred_y = seg_model.predict(valid_x)\nprint(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fd754514e0c5121132ca2c567be1fe74d4f0f8e"},"cell_type":"markdown","source":"# After Round 2 of Training"},{"metadata":{"trusted":true,"_uuid":"0b07a210985668578e1c8973a452dfba94e68274"},"cell_type":"code","source":"#2\nfig, mxs = plt.subplots(10, 10, figsize = (20, 20))\ni = 0\nfor ax_list in mxs:\n    for ax in ax_list:\n        ax.imshow(pred_y[i, :, :, 0], vmin = 0, vmax = 1)\n        i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af5d15548ade1c49acf398020b28caa8d172f293"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}