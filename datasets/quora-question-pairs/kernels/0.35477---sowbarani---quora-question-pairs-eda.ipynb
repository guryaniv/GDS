{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "402f6aed-475f-d967-6343-bf09e281d95c"
      },
      "source": [
        "Quora question Pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ea454caf-4755-81f9-9214-1dedfff36949"
      },
      "source": [
        "To check the question is duplicate or not ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c3ca9b0d-8051-8b6a-17d6-518b6ae70598"
      },
      "source": [
        "Importing the modules which are needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49f8e7c3-9a8f-8d0e-9f80-736510811e59"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize, ngrams\n",
        "from sklearn import ensemble\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import log_loss\n",
        "import xgboost as xgb\n",
        "\n",
        "eng_stopwords = set(stopwords.words('english'))\n",
        "color = sns.color_palette()\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b8f37375-0778-0d66-a8ae-266bba7e0212"
      },
      "source": [
        "Reading the both input files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "638b3afa-34a1-8bb4-f6db-52df1c5f109a"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "test_df = pd.read_csv(\"../input/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c5a31b70-1658-a156-5f88-484652bd8629"
      },
      "source": [
        "checking the number of row and columns present in the input file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b673e64c-3f89-276d-9968-651e2a13ebd7"
      },
      "outputs": [],
      "source": [
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "36acc92d-9c9e-b71b-b3c8-9f09d1a7cc08"
      },
      "source": [
        "Understand the data from the given input files "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dfe5c30c-d14b-d5e3-bdf2-d55654e46809"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2cdc21d0-e3cc-e9e9-ab49-e8bad4c0f0f6"
      },
      "outputs": [],
      "source": [
        "test_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a2cf71d4-5deb-07e8-4762-5c8431615a8e"
      },
      "source": [
        "checking the values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f7bb197-dbbf-0535-4f61-727c8a680560"
      },
      "outputs": [],
      "source": [
        "train_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b0cd0065-4087-7c7f-46eb-a44057346f84"
      },
      "outputs": [],
      "source": [
        "test_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7b7d2c2c-d5dc-9069-7b51-99ef800324ce"
      },
      "source": [
        "**Fields in both input files are :**\n",
        "1) Train dataframe\n",
        "id,qid1,qid2,question1,question2,is_duplicate\n",
        "\n",
        "id - It has set question pair numbers\n",
        "\n",
        "qid1,qid2 - has unique id numbers respective to the question1,question2 columns\n",
        "\n",
        "is_duplicate - it has zero , if the question1 and question2 has the same meaning then set 1 else 0\n",
        "\n",
        "\n",
        "2) Test data \n",
        "test_id,question1,question2\n",
        "\n",
        "test_id - it has set question pair numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1526fb73-902e-1ac9-1b77-00355e0027bd"
      },
      "outputs": [],
      "source": [
        "dup = train_df['is_duplicate'].value_counts()\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.barplot(dup.index,dup.values,color=color[3])\n",
        "plt.ylabel(\"No of Occurences\",fontsize=14)\n",
        "plt.xlabel(\"Duplicate\",fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5cef0481-e60b-1487-1fa8-b3e97f8488d5"
      },
      "outputs": [],
      "source": [
        "dup\n",
        "dup/dup.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "29e12ed5-402b-cbd7-a3e1-1cd38f32b763"
      },
      "source": [
        "combining the question1 and question2 column as a single column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "56282e2d-5e4e-9cf4-b923-902e7a1f8ec0"
      },
      "outputs": [],
      "source": [
        "question_df=pd.DataFrame(pd.concat([train_df['question1'],train_df['question2']]))\n",
        "question_df.columns=[\"questions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b9d2aa4-9fac-b569-aa5f-18f83618fa30"
      },
      "outputs": [],
      "source": [
        "question_df = pd.DataFrame(pd.concat([train_df['question1'], train_df['question2']]))\n",
        "question_df.columns = [\"questions\"]\n",
        "question_df[\"No_of_Words\"] = question_df[\"questions\"].apply(lambda x : len(str(x).split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86eb4ca3-23a8-235e-55a4-ad1335e5a7fd"
      },
      "outputs": [],
      "source": [
        "count =question_df['No_of_Words'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(count.index, count.values, alpha=0.6, color=color[3])\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Number of words in the question Column', fontsize=12)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f16afc1-2917-d3c2-1a66-121db5122488"
      },
      "source": [
        "Checking the character in question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2504d662-b54a-5acd-04e3-1e8f3d388c6e"
      },
      "outputs": [],
      "source": [
        "question_df[\"no_of_characters\"]=question_df[\"questions\"].apply(lambda x : len(str(x)))\n",
        "count = question_df['no_of_characters'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(50,8))\n",
        "sns.barplot(count.index,count.values,alpha=0.6,color=color[3])\n",
        "plt.ylabel('Number of occurences',fontsize=12)\n",
        "plt.xlabel('Number of characters',fontsize=12)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4370ba90-ac21-8106-fb9f-2cde861eada6"
      },
      "source": [
        "Getting common words from question1 and question2 in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d562c37-7ebc-57e1-1ef6-edd6701d04d4"
      },
      "outputs": [],
      "source": [
        "def get_unigrams(que):\n",
        "    return [word for word in word_tokenize(que.lower()) if word not in eng_stopwords]\n",
        "\n",
        "def get_common_unigrams(row):\n",
        "    return len( set(row[\"unigrams_ques1\"]).intersection(set(row[\"unigrams_ques2\"])) )\n",
        "\n",
        "def get_common_unigram_ratio(row):\n",
        "    return float(row[\"unigrams_common_count\"]) / max(len( set(row[\"unigrams_ques1\"]).union(set(row[\"unigrams_ques2\"])) ),1)\n",
        "\n",
        "train_df[\"unigrams_ques1\"] = train_df['question1'].apply(lambda x: get_unigrams(str(x)))\n",
        "train_df[\"unigrams_ques2\"] = train_df['question2'].apply(lambda x: get_unigrams(str(x)))\n",
        "train_df[\"unigrams_common_count\"] = train_df.apply(lambda row: get_common_unigrams(row),axis=1)\n",
        "train_df[\"unigrams_common_ratio\"] = train_df.apply(lambda row: get_common_unigram_ratio(row), axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8f5939f1-340d-9da6-bca3-f012fa4342a1"
      },
      "outputs": [],
      "source": [
        "count = train_df['unigrams_common_count'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(count.index, count.values, alpha=0.8)\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Common unigrams count', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8f98b32-fd6d-d80e-b387-9b3cd596985d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"is_duplicate\", y=\"unigrams_common_count\", data=train_df, palette=\"muted\")\n",
        "plt.xlabel('Is duplicate', fontsize=12)\n",
        "plt.ylabel('Common unigrams count', fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "623c875d-6e33-acaf-67af-69467ea0f515"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"is_duplicate\", y=\"unigrams_common_ratio\", data=train_df, palette=\"muted\")\n",
        "plt.xlabel('Is duplicate', fontsize=12)\n",
        "plt.ylabel('Common unigrams ratio', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce9883d8-2449-306f-db3f-97d36b32b440"
      },
      "source": [
        "using Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f69993a-c331-757a-b297-78ccc9e4bdea"
      },
      "outputs": [],
      "source": [
        "def get_bigrams(que):\n",
        "    return [word for word in word_tokenize(que.lower()) if word not in eng_stopwords]\n",
        "\n",
        "def get_common_bigrams(row):\n",
        "    return len( set(row[\"bigrams_ques1\"]).intersection(set(row[\"bigrams_ques2\"])) )\n",
        "\n",
        "def get_common_bigram_ratio(row):\n",
        "    return float(row[\"bigrams_common_count\"]) / max(len( set(row[\"bigrams_ques1\"]).union(set(row[\"bigrams_ques2\"])) ),1)\n",
        "\n",
        "train_df[\"bigrams_ques1\"] = train_df['unigrams_ques1'].apply(lambda x: get_unigrams(str(x)))\n",
        "train_df[\"bigrams_ques2\"] = train_df['unigrams_ques2'].apply(lambda x: get_unigrams(str(x)))\n",
        "train_df[\"bigrams_common_count\"] = train_df.apply(lambda row: get_common_unigrams(row),axis=1)\n",
        "train_df[\"bigrams_common_ratio\"] = train_df.apply(lambda row: get_common_unigram_ratio(row), axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "260e4f9c-b8cb-92ec-dfb3-01a541237409"
      },
      "outputs": [],
      "source": [
        "count = train_df['bigrams_common_count'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(count.index, count.values, alpha=0.8)\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Common bigrams count', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c40a4565-6ce2-aab5-7068-a0d7d2aa4280"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"is_duplicate\", y=\"bigrams_common_count\", data=train_df, palette=\"muted\")\n",
        "plt.xlabel('Is duplicate', fontsize=12)\n",
        "plt.ylabel('Common bigrams count', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "24f7fc6c-f4bf-3aa2-48bc-ffc849cf1b35"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.violinplot(x=\"is_duplicate\", y=\"bigrams_common_ratio\", data=train_df, palette=\"muted\")\n",
        "plt.xlabel('Is duplicate', fontsize=12)\n",
        "plt.ylabel('Common bigrams ratio', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab0cf1c3-a1af-eab3-799d-fd13b9a07949"
      },
      "outputs": [],
      "source": [
        "def feature_extraction(row):\n",
        "    que1 = str(row['question1'])\n",
        "    que2 = str(row['question2'])\n",
        "    out_list = []\n",
        "    # get unigram features #\n",
        "    unigrams_que1 = [word for word in que1.lower().split() if word not in eng_stopwords]\n",
        "    unigrams_que2 = [word for word in que2.lower().split() if word not in eng_stopwords]\n",
        "    common_unigrams_len = len(set(unigrams_que1).intersection(set(unigrams_que2)))\n",
        "    common_unigrams_ratio = float(common_unigrams_len) / max(len(set(unigrams_que1).union(set(unigrams_que2))),1)\n",
        "    out_list.extend([common_unigrams_len, common_unigrams_ratio])\n",
        "\n",
        "    # get bigram features #\n",
        "    bigrams_que1 = [i for i in ngrams(unigrams_que1, 2)]\n",
        "    bigrams_que2 = [i for i in ngrams(unigrams_que2, 2)]\n",
        "    common_bigrams_len = len(set(bigrams_que1).intersection(set(bigrams_que2)))\n",
        "    common_bigrams_ratio = float(common_bigrams_len) / max(len(set(bigrams_que1).union(set(bigrams_que2))),1)\n",
        "    out_list.extend([common_bigrams_len, common_bigrams_ratio])\n",
        "\n",
        "    # get trigram features #\n",
        "    trigrams_que1 = [i for i in ngrams(unigrams_que1, 3)]\n",
        "    trigrams_que2 = [i for i in ngrams(unigrams_que2, 3)]\n",
        "    common_trigrams_len = len(set(trigrams_que1).intersection(set(trigrams_que2)))\n",
        "    common_trigrams_ratio = float(common_trigrams_len) / max(len(set(trigrams_que1).union(set(trigrams_que2))),1)\n",
        "    out_list.extend([common_trigrams_len, common_trigrams_ratio])\n",
        "    return out_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f385f7b4-acf7-9312-e0e5-508050e75ab2"
      },
      "outputs": [],
      "source": [
        "def runXGB(train_X, train_y, test_X, test_y=None, feature_names=None, seed_val=0):\n",
        "        params = {}\n",
        "        params[\"objective\"] = \"binary:logistic\"\n",
        "        params['eval_metric'] = 'logloss'\n",
        "        params[\"eta\"] = 0.02\n",
        "        params[\"subsample\"] = 0.7\n",
        "        params[\"min_child_weight\"] = 1\n",
        "        params[\"colsample_bytree\"] = 0.7\n",
        "        params[\"max_depth\"] = 4\n",
        "        params[\"silent\"] = 1\n",
        "        params[\"seed\"] = seed_val\n",
        "        num_rounds = 300 \n",
        "        plst = list(params.items())\n",
        "        xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "\n",
        "        if test_y is not None:\n",
        "                xgtest = xgb.DMatrix(test_X, label=test_y)\n",
        "                watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
        "                model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
        "        else:\n",
        "                xgtest = xgb.DMatrix(test_X)\n",
        "                model = xgb.train(plst, xgtrain, num_rounds)\n",
        "                \n",
        "        pred_test_y = model.predict(xgtest)\n",
        "\n",
        "        loss = 1\n",
        "        if test_y is not None:\n",
        "                loss = log_loss(test_y, pred_test_y)\n",
        "                return pred_test_y, loss, model\n",
        "        else:\n",
        "            return pred_test_y, loss, model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a900c8f3-001c-f330-dfaa-8cb2b7c6fc94"
      },
      "source": [
        "Thanks to [SRK Notebook][1]\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/sudalairajkumar/quora-question-pairs/simple-exploration-notebook-quora-ques-pair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "209265b5-99f2-911b-c4a0-c66164523e06"
      },
      "outputs": [],
      "source": [
        "train_X = np.vstack( np.array(train_df.apply(lambda row: feature_extraction(row), axis=1)) ) \n",
        "test_X = np.vstack( np.array(test_df.apply(lambda row: feature_extraction(row), axis=1)) )\n",
        "train_y = np.array(train_df[\"is_duplicate\"])\n",
        "test_id = np.array(test_df[\"test_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f91ac40-7402-ae4e-ac1e-7154e5e45617"
      },
      "outputs": [],
      "source": [
        "train_X_dup = train_X[train_y==1]\n",
        "train_X_non_dup = train_X[train_y==0]\n",
        "\n",
        "train_X = np.vstack([train_X_non_dup, train_X_dup, train_X_non_dup, train_X_non_dup])\n",
        "train_y = np.array([0]*train_X_non_dup.shape[0] + [1]*train_X_dup.shape[0] + [0]*train_X_non_dup.shape[0] + [0]*train_X_non_dup.shape[0])\n",
        "del train_X_dup\n",
        "del train_X_non_dup\n",
        "print(\"Mean target rate : \",train_y.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f28aa8f3-331b-00b9-8673-1a101b4b74d6"
      },
      "outputs": [],
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=2016)\n",
        "for dev_index, val_index in kf.split(range(train_X.shape[0])):\n",
        "    dev_X, val_X = train_X[dev_index,:], train_X[val_index,:]\n",
        "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
        "    preds, lloss, model = runXGB(dev_X, dev_y, val_X, val_y)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab815362-7f46-e124-0670-2e4190c91696"
      },
      "outputs": [],
      "source": [
        "xgtest = xgb.DMatrix(test_X)\n",
        "preds = model.predict(xgtest)\n",
        "\n",
        "out_df = pd.DataFrame({\"test_id\":test_id, \"is_duplicate\":preds})\n",
        "out_df.to_csv(\"xgb_starter.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}