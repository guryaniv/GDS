{"nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}}, "cells": [{"execution_count": null, "source": "In this Scripts, I will be training XGboost on my Random Forest Implementations and feature engineering I did.", "cell_type": "markdown", "metadata": {"_execution_state": "idle", "_cell_guid": "db4af5ad-80b4-4c8f-8d83-84a57afd8bad", "_uuid": "844f50c237d48873b5e33e2224f5f699bb211769", "collapsed": false}, "outputs": []}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "c1c0721d-0b8f-4e35-9f56-e0d0d10b4f3c", "_uuid": "ea80cf451fcd619d39b298e6a99171c1a8b21eb2"}, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."}, {"execution_count": null, "source": "data = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\nprint(\"Done 1\")\n\ndata_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "b63f6d8f-4648-477a-ac63-54fdf8fb0dc5", "_uuid": "b111bd7dcba73fb9add3470a1a42fb6c3bb94e37", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "pd.set_option('display.max_columns', 500) #This is a very handy tool for large column datasets\ndata.head()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "53796451-b599-4561-9ca0-37630799f48e", "_uuid": "ffdd6b2e848b5ac420f4052796a78ce36e286c92", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "data_type = data.dtypes.reset_index() #Reset index gives an index to the dataframe\ndata_type.columns=[\"columns\", \"data_type\"]\ndata_type.head()\n\ndata_type.groupby('data_type').aggregate('count').reset_index()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "2d2644c4-d7ae-4e6b-abe5-9008dfec1f9c", "_uuid": "d292c462800c9aaa9b931b8ddc5d2f77cd1af34b", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "def isNullCount(data):\n    \"\"\"\n    Function to always compute the nullcount of a dataset\n    \n    Input: Dataframe of Dataset\n    Output: Dataframe of columns and number of nulls, A List of Null_columns\n    \n    \"\"\"\n    data_null = data.isnull().sum().reset_index()\n    data_null.columns = [\"column\", \"null_count\"]\n    null_column = data_null[data_null['null_count'] > 0]['column'].tolist()\n    return data_null, null_column\n\ndata_null, null_column = isNullCount(data)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "5f6a8345-abff-428c-acb6-b121556f8e40", "_uuid": "1da15d6752bd41cb6d11bab48a3d16c939e89da7", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "data_null_6000 = data_null[data_null[\"null_count\"] > 6000]\n#Drop the columns of data_null_6000 from main data\nnull_6000_list = data_null_6000.column.values\n\nnull_list = data_null.column.tolist()\n\n#make a copy of the data befor going forward\ndata_copy = data.copy()\n\ndata_copy_notnull = data_copy.drop([null for null in null_6000_list], axis=1)\n\nnew_data = data_copy_notnull.copy()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "697f0ce9-e5a5-45c5-9fc6-270b8b4986d0", "_uuid": "ac79a03550fb59b3fa8149993d5a5e9b856fcb61", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "color = sns.diverging_palette\nfig, ax = plt.subplots(figsize=(7,5))\nax.scatter(range(new_data.shape[0]), new_data.price_doc, alpha=0.2)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "afefd073-e519-4589-9657-9f71ae12b395", "_uuid": "e2d01ecb33d23bb8606d49c6e128bac74f3a5a9c", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(new_data, test_size=0.2, random_state=42)\nlen(train_set)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "2688be03-d591-4646-a176-d9d085be881b", "_uuid": "8ce83c586d0e5d28e8c445d3cc626cbe4184495a", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### Training Data after removing Null Values >6000", "cell_type": "markdown", "metadata": {"_execution_state": "idle", "_cell_guid": "9defb615-7d8c-4c44-9c1c-51e596ff2959", "_uuid": "e8ce35f125b3a74a9e144b34a240f5ce0edf2356", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "prep_train = train_set.drop(['price_doc', 'timestamp'], axis=1)\ny_label = train_set['price_doc'].copy()\n\ndata_type = prep_train.dtypes.reset_index() #Reset index gives an index to the dataframe\ndata_type.columns=[\"columns\", \"data_type\"]\ndata_type.head()\n\ndata_type.groupby('data_type').aggregate('count').reset_index()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "555360da-6540-465a-b242-3388f0343a35", "_uuid": "6b8282ed219aab51e0c7636c37d26eb7af00d286", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "#Let's get the columns with numeric values\nprep_train_num = prep_train.select_dtypes(include=[\"int64\", \"float64\"])\n\n#Column with object values\nprep_train_obj = prep_train.select_dtypes(include=[\"object\"])", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "3a83f8a1-75a1-495b-bd86-58c3aaa11e46", "_uuid": "d8adcf5e00756cca93450e70c330f26a20a340e2", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "from sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.pipeline import TransformerMixin\nfrom sklearn.base import BaseEstimator\n\nnum_attributes = list(prep_train_num)\ncat_attributes = list(prep_train_obj)\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import Imputer\n\nclass NewLabelBinarizer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        arrayed = np.array([])\n        for i in range(X.shape[1]):\n            col = X[:, i].reshape(-1, 1)\n            binarizer = LabelBinarizer().fit_transform(col)\n            arrayed = np.hstack([arrayed, binarizer]) if arrayed.size else binarizer\n        return arrayed\n    def fit_transform(self, X, y=None):\n        return self.fit(X, y).transform(X)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "12908048-d7c6-4f85-9e92-d3bb487ce2bc", "_uuid": "99fb24e1b708b2558268bab7a79e723ac84efa1b", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "class DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values\n    def fit_transform(self, X, y=None):\n        return self.fit(X,y).transform(X)\n\nnum_pipeline = Pipeline([\n        ('selector', DataFrameSelector(num_attributes)),\n        ('imputer', Imputer(strategy=\"median\"))\n    ])\n\ncat_pipeline = Pipeline([\n        ('selector', DataFrameSelector(cat_attributes)),\n        ('binarizer', NewLabelBinarizer())\n        #('cat_binarizer', MultiColumnLabelEncoder())\n    ])\n    \nfull_pipeline = FeatureUnion(transformer_list=[\n        ('num_pipeline', num_pipeline),\n        ('cat_pipeline', cat_pipeline)\n    ])", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "8c1c80e0-e3da-43d8-9da8-bbc639e7e7d3", "_uuid": "55ff47dbdbcf1699d66c2a2c34e98c4e5fc2d8b3", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "final_prep = full_pipeline.fit_transform(prep_train)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "c979bbed-a3e5-4263-938f-7cd65c1098aa", "_uuid": "2fa8ac7446f9ee27dee6d52e8ec3781f437c75b3", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "final_prep.shape", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "c06943ac-3c36-4cd1-a24e-8e4435dc71a6", "_uuid": "5e1f959404bed25f245e165d122c3578a4ccd252", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "#Make RLSME Scorer\ndef rmsle(predicted, actual):\n    return np.sqrt(np.square(np.log(predicted + 1) - np.log(actual + 1)).mean())\n\nfrom sklearn.metrics import make_scorer\nscorer = make_scorer(rmsle, greater_is_better=False)\n\n#Train some model on the data\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Score_mean\", scores.mean())\n    print(\"Score_std\", scores.std())", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "478c0af0-ace0-4ae6-845a-46274090d1d4", "_uuid": "3b12c526bd90f6cd5ee771433f4b1f470f06470e", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "from sklearn.model_selection import cross_val_score\nimport xgboost as xgb\n\nmodel1 = xgb.XGBRegressor()\nscores = cross_val_score(model1, final_prep, y_label, scoring=scorer, cv=10)\ndisplay_scores(-scores)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "05fd50b4-c1d5-4b5e-8c3e-3b3ecd7cecab", "_uuid": "69d8e3a40c6e2cdaffb4a30b756dd0aed7acf8ad", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "data_test = data_test.drop([null for null in null_6000_list], axis=1)\n\ndata_test.isnull().values.any()", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "3e3b72f2-d56b-4802-afbb-828634d5693f", "_uuid": "47cee1002b22b3f2db39a7daae7e84383bcf1c5f", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "median = data_test.median()\n\ntest_prep = data_test.fillna(data_test.median())\ntest_prep = test_prep.fillna(method='pad')", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "529273ec-3108-45dc-a4df-2908e3c6ed87", "_uuid": "4904945b0aa13104e5387d2b996bb780ae912edb", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "prep_test = test_prep.drop('timestamp', axis=1)\nfinal_test = full_pipeline.fit_transform(prep_test)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "a5a2437e-51a3-464a-8d43-accb092b9fd2", "_uuid": "463371481020300d4239dc784c45c226e48b595f", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "final_prep.shape, final_test.shape", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "7dbec6dc-63aa-4edf-b573-f881de09fccf", "_uuid": "1b0312ce932f489ec627b4803376695739a48bcc", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "train_model1 = model1.fit(final_prep, y_label)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "3a356c24-8425-4891-9be5-e55c09b02950", "_uuid": "c1d3e89759e8273a52fec79c05817b5df00d519d", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "pred1 = train_model1.predict(final_test)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "e1874890-7467-4ebd-8939-74b01c298979", "_uuid": "84db7b583808d29d3253a8c8ed1e12e63bf68101", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "sub = pd.DataFrame(data= {'id': prep_test['id'].ravel()})\nsub['price_doc'] = pred1\nsub.to_csv(\"submission.csv\", index = False, header = True)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "99501934-8654-4c94-80c3-fec579cd741c", "_uuid": "128bf88f633ab25dff43eda188af44c540f01d2e", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### This notebooks scored me 0.337 which is far more better than the 0.358 gotten with the same random Forest Implementation", "cell_type": "markdown", "metadata": {"trusted": false, "_execution_state": "idle", "_cell_guid": "364b9049-56c2-467e-bb92-b657a6f5a2b2", "_uuid": "5537b88e24ff0a769a1c24b6c3b3621dffa2491d", "collapsed": false}, "outputs": []}], "nbformat_minor": 0}