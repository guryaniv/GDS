{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\nimport os \nimport random\nimport math\nimport numpy as np\nimport pandas as pd\nimport pydicom\n\nfrom skimage import io\nfrom skimage import measure\nfrom skimage import transform, exposure\nfrom skimage.transform import resize\n\nfrom tqdm import tqdm\nfrom scipy import ndimage\n\nimport keras\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential, load_model, Model\nfrom keras import layers\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, UpSampling2D, Conv2DTranspose, concatenate, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.layers import Activation, Dropout, Flatten, Dense, Lambda\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import backend as K\nfrom keras import optimizers, regularizers\nfrom keras import applications","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50a081f1719b85ef3e4892e6b330a19968471b39"},"cell_type":"markdown","source":"# Run time parameters"},{"metadata":{"trusted":true,"_uuid":"3f4a1779d72e7c6ac441ad8e5e63f2fdf6624192","scrolled":true},"cell_type":"code","source":"os.listdir('../input/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c71b014ccace05e9e65a788eb2cf3e0b9737057e"},"cell_type":"code","source":"LEARNING_RATE = 3e-4\nDO = 0.5\nFRAC = 1                                                                   # FRACtion of input to be used for training\nTRAIN_VAL_SPLIT = 0.965                                                    # Proportion of Training to Validation set\nEPOCH = 4\n\nIMG_SIZE = 256\nN_CHANNEL = 3\nBATCH_SIZE = 32\nTHRESHOLD = 0.5                                                           # probability threshold for prediction \nRANDOM_STATE = 1\n\nTAKE_INPUTS_PREV_RUN = True\nDATA_INPUT_DIR = '/kaggle/input/rsna-pneumonia-detection-challenge/'      # path containing inputs\nPREV_RUN_INPUT_DIR = '/kaggle/input/rsna-pk2-tutorial-epoch-16-to-20/'    # path containing weights and training scores from previous run, to be imported manually\nOUTPUT_DIR = '/kaggle/working'                                            # path to store weights and training scores from this run","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46a3ed34d30623fc99e1ac817f1d6f94d57f376f"},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"trusted":true,"_uuid":"a34aef3d2f19c6734c41ce27fac95cc523294e1a"},"cell_type":"code","source":"# function to read annotn file and put it into a dataframe\ndef read_annotn(file_path=''):\n    annotn = pd.read_csv(file_path)\n    annotn = annotn.reset_index(drop=True)\n    return annotn\n\n# function to (1) sample input (2) split the input into train val \ndef get_train_val_df(frac=FRAC, train_val_split=TRAIN_VAL_SPLIT, random_state=RANDOM_STATE, file_path='../input/stage_2_train_labels.csv'):\n    df_annotn = read_annotn(file_path=file_path)\n    df_id_label = df_annotn.fillna(0)\n    df_id_label = df_id_label.sample(frac=frac, random_state=RANDOM_STATE)\n    train_sample = round(train_val_split*df_id_label.shape[0])\n    df_train = df_id_label[:train_sample]\n    df_val = df_id_label[train_sample:]\n    return df_train,df_val\n\n# loss function for training\ndef dice_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n\n# metrics function for training\ndef dice_coef_loss(y_true, y_pred):\n    return -dice_coef(y_true, y_pred)\n\ndef dice_bce_loss(y_true, y_pred):\n    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * dice_coef_loss(y_true, y_pred)\n\ndef mean_iou(y_true, y_pred):\n    y_pred = tf.round(y_pred)\n    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n    smooth = tf.ones(tf.shape(intersect))\n    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n\n# function to put training scores into a dataframe\ndef update_df_score(df, history):\n    for i in range(EPOCH): \n        df = df.append( { 'epoch' : i,\n                         'train_loss' : history.history['loss'][i], \n                         'val_loss' : history.history['val_loss'][i], \n                         'train_accuracy' : history.history['acc'][i], \n                         'val_accuracy' : history.history['val_acc'][i],\n                         'train_dice_coef' : history.history['dice_coef'][i], \n                         'val_dice_coef' : history.history['val_dice_coef'][i],\n                         'train_mean_iou' : history.history['mean_iou'][i], \n                         'val_mean_iou' : history.history['val_mean_iou'][i]} , ignore_index=True)\n    return df\n\n# function to convert mask to list of x,y,w,h\ndef convert_mask_to_xywh (mask, threshold=THRESHOLD):\n    component = mask[:, :, 0] > THRESHOLD\n    component = measure.label(component)\n    xywh_list = []\n    for region in measure.regionprops(component):\n        y, x, y2, x2 = region.bbox\n        height = y2 - y\n        width = x2 - x\n        xywh_list.append([x, y, width, height])\n    return xywh_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f748e8ab463600e8cb0421b92f66326f31c098e"},"cell_type":"markdown","source":"# Generator class"},{"metadata":{"trusted":true,"_uuid":"48830678cd80cabab19c99f5a0a87a16e0d52c05"},"cell_type":"code","source":"# generator class for generating batches of (1) image  and mask array for training and validation (2) image array for prediction \nclass datagen(keras.utils.Sequence):\n    def __init__(self, df_X_y, im_size=IMG_SIZE, batch_size=32, predict=False, augment=True):\n        self.im_size = im_size\n        self.df_X_y = df_X_y\n        self.batch_size = batch_size\n        self.predict = predict\n        self.augment = augment\n        \n    def __len__(self):\n        return int(math.ceil(self.df_X_y.shape[0] / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch = self.df_X_y[idx * self.batch_size:(idx + 1) * self.batch_size]\n        X = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, N_CHANNEL))\n        if self.predict:\n            for i, row in enumerate(batch.iterrows()):\n                patientId = row[1]['patientId']\n                dcm_file = DATA_INPUT_DIR + '/stage_2_test_images/%s' %patientId\n                dcm_data = pydicom.read_file(dcm_file)\n                img =  dcm_data.pixel_array\n                img = exposure.equalize_hist(img)\n                img = resize(img, (IMG_SIZE, IMG_SIZE), mode='reflect')\n                img = img - img.mean()\n                img = img / img.std()\n                img = np.expand_dims(img, -1) if N_CHANNEL == 1 else np.stack((img,)*3, axis=-1)            \n                X[i,] = img\n            return np.array(X), batch['patientId']\n        else:\n            masks = np.zeros((self.batch_size, IMG_SIZE, IMG_SIZE, N_CHANNEL))\n            for i, row in enumerate(batch.iterrows()):\n                patientId = row[1]['patientId']\n                dcm_file = DATA_INPUT_DIR + '/stage_2_train_images/%s.dcm' %patientId \n                dcm_data = pydicom.read_file(dcm_file)\n                img =  dcm_data.pixel_array\n                img = exposure.equalize_hist(img)\n                img = resize(img, (IMG_SIZE, IMG_SIZE), mode='reflect')\n                img = img - img.mean()\n                img = img / img.std()\n                img = np.expand_dims(img, -1) if N_CHANNEL == 1 else np.stack((img,)*3, axis=-1)\n                msk = np.zeros(dcm_data.pixel_array.shape)\n                for key, (_, x, y, width, height, _) in self.df_X_y.loc[self.df_X_y['patientId'] == patientId].iterrows():\n                    x, y, w, h = (int(x), int(y), int(width), int(height))\n                    msk[y:y+h, x:x+w] = 1 \n                msk = resize(msk, (IMG_SIZE, IMG_SIZE), mode='reflect') > THRESHOLD\n                msk = np.expand_dims(msk, -1) if N_CHANNEL == 1 else np.stack((msk,)*3, axis=-1)\n                if self.augment and random.random() > 0.5:\n                    img = np.fliplr(img)\n                    msk = np.fliplr(msk)\n                    angle = random.random()*15\n                    img = ndimage.rotate(img, angle, reshape=False, order=1)\n                    msk = ndimage.rotate(msk, angle, reshape=False, order=1)\n                masks[i,] = msk\n                X[i,] = img\n            return np.array(X), np.array(masks)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b3c4fd330dd03dcb074c05f21469aa5a662420d"},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true,"_uuid":"4b62658fe16f484e940bf612f8a0adcd4eb8eeee"},"cell_type":"code","source":"def get_unet_IR_DO(LR=LEARNING_RATE, DO=DO):\n    from keras.applications.inception_resnet_v2 import InceptionResNetV2\n    img_input = Input( (IMG_SIZE, IMG_SIZE, N_CHANNEL))\n\n    IR_model = InceptionResNetV2(weights='imagenet', input_tensor=img_input, include_top=False)\n    conv1 = IR_model.get_layer(index=3).output \n    conv1 = keras.layers.UpSampling2D(2)(conv1)\n    conv1 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((2, 0), (2, 0))))(conv1) \n    \n    conv2 = IR_model.get_layer(index=9).output \n    conv2 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((3, 0), (3, 0))))(conv2) \n    \n    conv3 = IR_model.get_layer(index=16).output \n    conv3 = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((4, 0), (4, 0))))(conv3) \n    \n    conv3a = IR_model.get_layer(index=266).output\n    conv3a = keras.layers.Lambda(lambda x:  keras.backend.spatial_2d_padding(x, padding=((3, 0), (3, 0))))(conv3a) \n\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block4_conv1\")(conv3a)\n    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block4_conv2\")(conv4)\n    conv4 = Dropout(DO)(conv4)\n    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(conv4)\n\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block5_conv1\")(pool4)\n    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block5_conv2\")(conv5)\n    conv5 = Dropout(DO)(conv5)\n    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(conv5)\n\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block6_conv1\")(pool5)\n    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block6_conv2\")(conv6)\n    conv6 = Dropout(DO)(conv6)\n    pool6 = MaxPooling2D((2, 2), strides=(2, 2), name='block6_pool')(conv6)\n\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block7_conv1\")(pool6)\n    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block7_conv2\")(conv7)\n    conv7 = Dropout(DO)(conv7)\n\n    up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv7), conv6], axis=3)\n    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n\n    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up9)\n\n    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv9), conv4], axis=3)\n    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n\n    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n\n    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n\n    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n\n    conv13 = Conv2D(3, (1, 1))(conv13)\n    conv13 = Activation(\"sigmoid\")(conv13)\n    model = Model(img_input, conv13)\n    Adam = optimizers.Adam(lr=LR)\n    model.compile(optimizer=Adam, loss=dice_bce_loss, metrics=['accuracy', dice_coef, mean_iou])\n    model.name = 'unet+IR'\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ddcf8f602153f418726a8dfdde9fc311529d3ec"},"cell_type":"markdown","source":"# Train"},{"metadata":{"trusted":true,"_uuid":"439a351fa26fa48f7a67607b771d6ab053ad0014"},"cell_type":"code","source":"# Build training and validation generator\ndf_train, df_val = get_train_val_df(frac=FRAC, train_val_split=TRAIN_VAL_SPLIT, random_state=RANDOM_STATE, \n                                    file_path=os.path.join(DATA_INPUT_DIR, 'stage_2_train_labels.csv'))\nprint(df_train.shape, df_val.shape)\ntraining_generator = datagen(df_train, batch_size=BATCH_SIZE, augment=True, predict=False)\n\nvalidation_generator = datagen(df_val, batch_size=BATCH_SIZE, augment=True, predict=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21084194bf71e4633a91723a5174f79ec4b13d35"},"cell_type":"code","source":"# setup model\nmodel = get_unet_IR_DO()\nif TAKE_INPUTS_PREV_RUN:\n    model.load_weights(os.path.join(PREV_RUN_INPUT_DIR, 'weights.hdf5'))\nmodel_checkpoint = ModelCheckpoint(os.path.join(OUTPUT_DIR, 'weights.hdf5'), monitor='loss', verbose=1, save_best_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b024245357e6d8bcb1e84a883e88e3cec4e8dfc","scrolled":false},"cell_type":"code","source":"if TAKE_INPUTS_PREV_RUN:\n     df_score = pd.read_csv(os.path.join(PREV_RUN_INPUT_DIR, 'df_score.csv'))\nelse:\n     df_score = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss', \n                                      'train_dice_coef', 'val_dice_coef',\n                                      'train_mean_iou', 'val_mean_iou',\n                                      'train_accuracy', 'val_accuracy'\n                                     ])\nhistory = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=EPOCH, callbacks=[model_checkpoint])\ndf_score = update_df_score(df_score, history)\ndf_score.to_csv(os.path.join(OUTPUT_DIR, 'df_score.csv'), index=False)\ndf_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8382c091b707ba928c38368a64b7db43c7ea66be"},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(30,7))\ndf_score.plot(y=['train_loss', 'val_loss'], ax=axes[0], linewidth=3)\ndf_score.plot(y=['train_dice_coef', 'val_dice_coef'], ax=axes[1], linewidth=3)\ndf_score.plot(y=['train_mean_iou', 'val_mean_iou'], ax=axes[2], linewidth=3)\ndf_score.plot(y=['train_accuracy', 'val_accuracy'], ax=axes[3], linewidth=3)\n\nfor i in range(4):\n    axes[i].grid()\n    axes[i].set_xticks(np.arange(df_score.shape[0]))\n    axes[i].set_xlabel('epoch')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52edab29b6774dfbb2a6d5e491fe95ae45d15839"},"cell_type":"code","source":"# visualize results - print true and predicted boxes on a batch (#32) of images \nf, ax = plt.subplots(4, 8, figsize=(20,15))\nax = ax.ravel()\n\nfor images, masks in training_generator:\n    preds = model.predict(images)\n    for i, (image, mask, pred) in enumerate(zip(images, masks, preds)):\n        ax[i].imshow(image[:, :, 0])\n        \n        # print true mask\n        xywh_list = convert_mask_to_xywh(mask)\n        for (x, y, w, h) in xywh_list:\n            ax[i].add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='b',facecolor='none'))\n        \n        # print predicted mask\n        xywh_list = convert_mask_to_xywh(pred)\n        for (x, y, w, h) in xywh_list:\n            ax[i].add_patch(patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r',facecolor='none'))\n            \n    plt.show()\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67d876694ad05851352eb53bc9ab91827363818c"},"cell_type":"markdown","source":"# Prediction & Submission"},{"metadata":{"trusted":true,"_uuid":"8c29441d9d9abed286c07987d5dbbe50e8e154c4"},"cell_type":"code","source":"# Build prediction generator\ndf_pred = pd.DataFrame(data=os.listdir(DATA_INPUT_DIR + '/stage_2_test_images'), columns=['patientId'])\npred_generator = datagen(df_pred, batch_size=BATCH_SIZE, predict=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c47ee7b87e52b5da6bbe0f9cb5c3aa7ae45cb6b"},"cell_type":"code","source":"# loop through pred generator and (1) resize (2) convert mask to x,y,w,h (3) put it in a dict for submission\nsubmission_dict = {}\nfor imgs, patientIds in tqdm(pred_generator):\n    preds = model.predict(imgs)\n    for pred, patientId in zip(preds, patientIds):\n        pred = resize(pred, (1024, 1024), mode='reflect')\n        xywh_list = convert_mask_to_xywh(pred) \n        predictionString = ''\n        for (x, y, w, h) in xywh_list:\n            conf = np.mean(pred[y:y+h, x:x+w])\n            predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(w) + ' ' + str(h) + ' '\n        patientId = patientId.split('.')[0]\n        submission_dict[patientId] = predictionString","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"518a80f7892f5830416f7990a3b2d8d69efa121b"},"cell_type":"code","source":"sub = pd.DataFrame.from_dict(submission_dict,orient='index')\nsub.index.names = ['patientId']\nsub.columns = ['PredictionString']\nsub.to_csv(os.path.join(OUTPUT_DIR, 'submission.csv')) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"908284959ffd706cb7ba514e8c2f77899c156e67"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}