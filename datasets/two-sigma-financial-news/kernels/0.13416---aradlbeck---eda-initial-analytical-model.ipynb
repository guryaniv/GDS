{"cells":[{"metadata":{"_uuid":"5ffb21374c7cf4b98e7239045ef9bf312effee25"},"cell_type":"markdown","source":"# Analytical Model\nWe are starting here with the analytical block and some exploring with the market data set\n\nWe will:\n1. explore some features that we can create from the market data\n1. find a way to train a model day-by-day\n1. ???\n1. profit\n"},{"metadata":{"trusted":true,"_uuid":"c20fa6deeac9d374c98774abd90bdc76b023ee63","scrolled":false},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\n\n# returns the training data DataFrames as a tuple of:\n(market_train_df, news_train_df) = env.get_training_data()\n\n# size of total data\nprint(\"Market Train Size: \", market_train_df.shape)\nprint(\"News Train Size: \", news_train_df.shape)\n\n# we only care about the market data here\nmarket_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fad909ccc1f5b9f4de60792b701bf06742fced05"},"cell_type":"markdown","source":"## Exploration\nFor now lets just use one asset tag and explore its feature and target relation"},{"metadata":{"trusted":true,"_uuid":"f0d689459a1846ea19187f1061d06de5089e9464"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# find unique asset codes\nuAssestCode = pd.unique(market_train_df.assetCode)\nprint(\"Unique asset codes: \", len(uAssestCode))\nprint(uAssestCode[0])\n\n# grab information for uAssestCode[0]\ndf = market_train_df[market_train_df.assetCode == uAssestCode[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"098954b3c2a529671e1b35622f16b8f6c7be378e"},"cell_type":"code","source":"# rough stock chart\nfig, ax = plt.subplots()\nax.plot(df.time,\n        df.close,\n        color='blue')\nax.plot(df.time,\n        df.open,\n        color='red')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('close')\nax.set_title('plotting ' + uAssestCode[0])\nax.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"697ffc4e1aa12e0ec5db05fe4e2b45a91db63723"},"cell_type":"markdown","source":"**Target**\n\nreturnsOpenNextMktres10\n\nLets plot the target and seperate it into two classes:\n* positive gain ( > 0)\n* no or negative gain (<= 0)\n\nThis will make feature exploration easier"},{"metadata":{"trusted":true,"_uuid":"f8726f343e312e0da523f66520fc492411aad12a"},"cell_type":"code","source":"# target value\nfig, ax = plt.subplots()\nax.plot(df.time, \n        df.returnsOpenNextMktres10,\n        color='green')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('plotting: ' + uAssestCode[0])\nax.legend(loc='lower right')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b032a700535802847d9ec0e620eadd32ccbc6af"},"cell_type":"code","source":"# seperate out the label\nyo = df['returnsOpenNextMktres10']\n\n# create a class based decision\ny = np.zeros(yo.shape[0])\ny[yo > 0] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee7a47cd99f81e4acf26a5fbd4980272adc2cac1"},"cell_type":"markdown","source":"**Features**\n\nRaw:\n* volume\n* open\n* close\n\nDSP based:\n* These will have to come later (based on obs)?\n\nMarket based:\n* gain = close - open\n* gpv = gain / volume\n"},{"metadata":{"trusted":true,"_uuid":"c7dcb0babfcf0ae1499b2cec97e9a247a90ceca2"},"cell_type":"code","source":"# volume\nfill = np.linspace(1.0, df.volume.shape[0], num=df.volume.shape[0])\n\nv     = df.volume\nvol2  = np.power(df.volume, 1/2)\n\nfig, ax = plt.subplots()\nax.scatter(v, \n        vol2, \n        c=y)\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('volume')\nax.set_title('plotting ' + uAssestCode[0])\nax.legend(loc='lower right')\n\n# lets try to break this up into bins\n# and look at the bins lined up with the target\nvbins, ved = np.histogram(v, bins=20)\nnpv = np.array(v)\nnpy = np.array(y)\nymean   = np.zeros(ved.shape[0] - 1)\nvolumeb = np.zeros(v.shape[0])\n\nfor i in range(1, ved.shape[0] - 1):\n    meets_range = npy[np.logical_and(ved[i] < npv, npv < ved[i+1])]    \n    if(meets_range.size == 0):\n        # it is empty\n        ymean[i] = 0\n    else:\n        ymean[i] = meets_range.mean()\n    volumeb[np.logical_and(ved[i] < npv, npv < ved[i+1])] = i\nfill = np.linspace(1.0, ymean.shape[0], num=ymean.shape[0])\n\n# bar\nfig, ax = plt.subplots()\nax.bar(fill, ymean)\nax.grid()\nax.set_xlabel('bins')\nax.set_ylabel('y mean')\nax.set_title('plotting ' + uAssestCode[0])\n\n# this looks good! as bins","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"689daedfad156176de388f048dafdc2a51674480"},"cell_type":"code","source":"# gain\n# features to test\ngain  = df.close - df.open\ngain2 = np.power(gain, 2)\ngainb = np.zeros(gain.shape[0])\ngainb[gain > 0] = 1\n\n# plot\nfig, ax = plt.subplots()\nax.scatter(gain, \n           gainb, \n           c=y)\nax.grid()\nax.set_xlabel('close')\nax.set_ylabel('open')\nax.set_title('plotting: ' + uAssestCode[0])\n\n# this looks good!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c13c45c31ba1f908908c130dbf1741435760d9a0"},"cell_type":"code","source":"# gpv\ngpv  = (df.close - df.open) / df.volume\ngpv2 = np.power(gpv, 2)\nfill = np.linspace(1.0, gpv.shape[0], num=gpv.shape[0])\n\nfig, ax = plt.subplots()\nax.scatter(gpv2, \n           gpv, \n           c=y)\nax.grid()\nax.set_xlabel('fill')\nax.set_ylabel('gpv')\nax.set_title('plotting ' + uAssestCode[0])\nax.legend(loc='lower right')\n\n# this looks ok, lets not use this as a feature for now","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01b046e708f1608c4c5ee17038ddf760e82e3127"},"cell_type":"markdown","source":"**Model**\n\nSVM"},{"metadata":{"trusted":true,"_uuid":"08e335d939f0c9344310b3a773091e23a6793b23"},"cell_type":"code","source":"# we will create our features in a data frame\n#Xdict = {1: gain, 2: gainb, 3: volumeb}\nXdict = {2: gainb, 3: volumeb}\nX     = pd.DataFrame(Xdict)\n\n# print some info\nprint(type(X))\nprint(X.dtypes)\nX.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e14d2cc3f8e8cd49a6016addb4a7728973b3f10"},"cell_type":"code","source":"# reference:\n#    https://stackabuse.com/implementing-svm-and-kernel-svm-with-pythons-scikit-learn/ \n# time to train initial prediction model\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn import svm\n \n# scale y to be max [-1,1] to represent confidence \ny       = np.zeros(yo.shape[0])\n#y_scale = minmax_scale(list(yo), feature_range=(-1, 1), axis=0, copy=True)\ny[yo >  1e-6] = 1\ny[yo < -1e-6] = -1\n\n# split up data set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)\n\n# implement SVM regression\nclf = svm.LinearSVC()\n#clf = svm.SVR(C=0.7, kernel='rbf')\n#clf = svm.SVC(C=0.7)\nclf.fit(X_train, y_train) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b87c5d536bceddf5c2d5fe052bd7a7bb55e47414"},"cell_type":"code","source":"y_scale = minmax_scale(list(yo), feature_range=(-1, 1), axis=0, copy=True)\n\n# plot pred and truth\nx = np.linspace(1.0, y_scale.shape[0], num=y_scale.shape[0])\n\n# predicted\nfig, ax = plt.subplots()\nax.plot(x, yo, color='green')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('ya: ' + uAssestCode[0])\n\n# predicted\nfig, ax = plt.subplots()\nax.plot(x, y_scale, color='green')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('scale: ' + uAssestCode[0])\n\n# predicted\nfig, ax = plt.subplots()\nax.plot(x, y, color='green')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('y: ' + uAssestCode[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd70e7cb24723f92988030210fe3ec1edfd2a32d","scrolled":false},"cell_type":"code","source":"# test and analysis\nimport numpy as np\ny_pred = clf.predict(X_test)\n\n# plot pred and truth\nx = np.linspace(1.0, y_pred.shape[0], num=y_pred.shape[0])\n\n# predicted\nfig, ax = plt.subplots()\nax.plot(x, y_pred, color='green')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('predicted: ' + uAssestCode[0])\nprint('y_pred mean: ', np.mean(y_pred))\n\n# actual\nfig, ax = plt.subplots()\nax.plot(x, y_test, color='blue')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('actual: ' + uAssestCode[0])\nprint('y_test mean: ', np.mean(y_test))\n\n# squared error\ny_test = np.array(y_test)\nsq_err = 1/2 * np.power((y_test - y_pred), 2)\n#\nfig, ax = plt.subplots()\nax.plot(x, sq_err, color='red')\nax.grid()\nax.set_xlabel('time')\nax.set_ylabel('target')\nax.set_title('Squared Error: ' + uAssestCode[0])\nprint('sq_err mean: ', np.mean(sq_err))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8397d9cf7314324a4a4eae27c550e80eed45183"},"cell_type":"markdown","source":"## Feature Function"},{"metadata":{"trusted":true,"_uuid":"b6c247ee17db08aafde63dcc97944360e3fbf0d9"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef analysis_get_features(market_data, byday=False, trainInfo=None):\n    # for full training set feature creation\n    if(not byday):\n        # assign uids to each asset \n        uAssestCode = pd.unique(market_data.assetCode)    \n        uidList     = np.linspace(1.0, uAssestCode.shape[0], num=uAssestCode.shape[0])\n\n        # feature 0 - map from assetCode to uid    \n        uidMap = {}\n        for A, B in zip(uAssestCode, uidList):\n            uidMap[A] = B\n\n        aUID = np.zeros(market_data.shape[0])\n        for i, item in enumerate(market_data.assetCode):\n            aUID[i] = uidMap[item]\n\n        # feature 1, 2 - gain, gainb    \n        gain  = market_data.close - market_data.open    \n        gainb = np.zeros(gain.shape[0])\n        # classify\n        gainb[gain > 0] = 1\n\n        # feature 3 - volumeb\n        v   = market_data.volume\n        npv = np.array(v)    \n        vbins, ved = np.histogram(v, bins=20)\n        volumeb    = np.zeros(v.shape[0])\n\n        # create classes for bins\n        for i in range(1, ved.shape[0] - 1): \n            volumeb[np.logical_and(ved[i] < npv, npv < ved[i+1])] = i\n\n        # features to dataframe\n        #Xdict = {1: aUID, 2: gain, 3: gainb, 4: volumeb}\n        Xdict = {1: gain, 2: gainb, 3: volumeb}\n        X     = pd.DataFrame(Xdict)\n        \n        # save off training information\n        trainInfo = (uidList, uidMap, ved)\n        \n    # for one off feature creation\n    else:                \n        # feature 0\n        auid = np.zeros(market_data.assetCode.shape[0])\n        for i, assetCode in enumerate(market_data.assetCode):\n            # look for uid\n            if assetCode in trainInfo[1]:\n                uid = trainInfo[1][assetCode]\n            else:\n                # if its a new asset code create a new uid\n                newUID = trainInfo[0].max() + 1\n                np.append(trainInfo[0], newUID)\n                \n                # update dict\n                trainInfo[1][assetCode] = newUID\n                uid = newUID\n                \n            # set uid\n            auid[i] = uid\n        \n        # feature 1, 2 - gain, gainb\n        gain  = market_data.close - market_data.open    \n        gainb = np.zeros(gain.shape[0])\n        # classify\n        gainb[gain > 0] = 1\n        \n        # feature 3 - volumeb\n        v   = market_data.volume\n        npv = np.array(v)    \n        # TODO consider using the same bin alignment as the training data\n        # it may be better to leave it as-is; it would be proportionate\n        # ved = trainInfo[2][i]\n        vbins, ved = np.histogram(v, bins=20)\n        volumeb    = np.zeros(v.shape[0])\n\n        # create classes for bins\n        for i in range(1, ved.shape[0] - 1): \n            volumeb[np.logical_and(ved[i] < npv, npv < ved[i+1])] = i\n                \n        # features to dataframe\n        #Xdict = {1: auid, 2: gain, 3: gainb, 4: volumeb}\n        Xdict = {1: gain, 2: gainb, 3: volumeb}\n        X     = pd.DataFrame(Xdict)\n    \n    return X, trainInfo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb32d11b9c3c1012611612a5f0f86465a9a4d44"},"cell_type":"code","source":"# debug \n# subset = market_train_df.head()\nfeatures, trainInfo = analysis_get_features(market_train_df)\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b64109445918e8a591ce3d103aee1e669dd5fc63"},"cell_type":"markdown","source":"## Training Function"},{"metadata":{"trusted":true,"_uuid":"7a0ed2795e78c2f79ebd89e5f0267e651f8e1052"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import minmax_scale\nfrom sklearn import svm\n\ndef analysis_train(features, target):\n    # scale y to be max [-1,1] to represent confidence \n    y       = np.zeros(target.shape[0])\n    #y_scale = minmax_scale(list(target), feature_range=(-1, 1), axis=0, copy=True)\n    y[target >  1e-3] = 1\n    y[target < -1e-3] = -1\n\n    # implement SVM regression\n    clf = svm.LinearSVC()\n    #clf = svm.SVR(C=0.9, kernel='rbf')  \n    #clf = svm.SVR(kernel='linear', C=1e3)   \n    #clf = svm.SVC(gamma='auto')\n    clf.fit(features, y)\n    \n    return clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abcc7332a2424a62f73de33dfceb9e0622e80f84"},"cell_type":"code","source":"trainedModel = analysis_train(features, market_train_df['returnsOpenNextMktres10'])\nprint(trainedModel)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"840aa03b49d675953f080e4069f79f435282bb43"},"cell_type":"markdown","source":"# Daily Values\n* While there are more prediction day(s) and `predict` was called successfully since the last yield, yields a tuple of:\n    * `market_observations_df`: DataFrame with market observations for the next prediction day.\n    * `news_observations_df`: DataFrame with news observations for the next prediction day.\n    * `predictions_template_df`: DataFrame with `assetCode` and `confidenceValue` columns, prefilled with `confidenceValue = 0`, to be filled in and passed back to the `predict` function.\n* If `predict` has not been called since the last yield, yields `None`."},{"metadata":{"trusted":true,"_uuid":"02dd761e6bbf44892b667eb14e29ecc0ddd92d75"},"cell_type":"code","source":"# You can only iterate through a result from `get_prediction_days()` once\n# so be careful not to lose it once you start iterating.\n#days = env.get_prediction_days()\n#(market_obs_df, news_obs_df, predictions_template_df) = next(days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"140aee54dc838549f87f041a97c7a809ee4e0f6f"},"cell_type":"code","source":"# debug\n#p = analysis_predict(market_obs_df, predictions_template_df, trainInfo, trainedModel)\n\n# info\n#print(\"market_obs_df size: \", market_obs_df.shape)\n#market_obs_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b02d43dec4b881564cd43ff6239c7aa97d94a7af"},"cell_type":"code","source":"#news_obs_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e44e11095c1ea215b91883cfc7917d108fd2aa11"},"cell_type":"code","source":"#p.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5233f1b22f5ddac08adb50bbaa6444a0da4a24bc"},"cell_type":"code","source":"#predictions_template_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8b181c3e0e6a10a3287ab78932ce6b19a5f8a95"},"cell_type":"markdown","source":"## Prediction Function"},{"metadata":{"trusted":true,"_uuid":"0b9ab3f3d9978f60e49a3c3ec4256e49ac21cdca"},"cell_type":"code","source":"def analysis_predict(market_obs, predictions, trainInfo, trainedModel):    \n    features, trainInfo = analysis_get_features(market_obs, True, trainInfo)\n    p       = trainedModel.predict(features)\n    #p_scale = minmax_scale(list(p), feature_range=(-1, 1), axis=0, copy=True)\n    #p_class = np.ones(p_scale.shape[0]) * -1\n    #p_class[p_scale > 0] = 1\n    p_class = p\n    \n    # set\n    predictions.confidenceValue = p_class","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8056b881707072c379ad2e89b9c59c3c041a2ab7"},"cell_type":"markdown","source":"## Main Loop\nLet's loop through all the days and make our random predictions.  The `days` generator (returned from `get_prediction_days`) will simply stop returning values once you've reached the end."},{"metadata":{"trusted":true,"_uuid":"1bd50bb1532e95d1bfbf515d2724cbd3d57f695f"},"cell_type":"code","source":"days = env.get_prediction_days()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef60bc52a8a228e5a2ce18e4bd416f1f1f25aeae"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    analysis_predict(market_obs_df, predictions_template_df, trainInfo, trainedModel)\n    env.predict(predictions_template_df)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bea40ae32a2346a2cb58ccc364e84a86cb86932b"},"cell_type":"code","source":"predictions_template_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c8fbcca87c7f6abc53e86408417bf12ce21bb7f"},"cell_type":"markdown","source":"## **`write_submission_file`** function\n\nWrites your predictions to a CSV file (`submission.csv`) in the current working directory."},{"metadata":{"trusted":true,"_uuid":"2c8ed34ffb2c47c6e124530ec798c0b4eb01ddd5"},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d38aa8a67cad3f0c105db7e764ec9b805db39ceb"},"cell_type":"code","source":"# We've got a submission file!\nimport os\nprint([filename for filename in os.listdir('.') if '.csv' in filename])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f464f37885ffa763a2592e2867d74685f75be506"},"cell_type":"markdown","source":"As indicated by the helper message, calling `write_submission_file` on its own does **not** make a submission to the competition.  It merely tells the module to write the `submission.csv` file as part of the Kernel's output.  To make a submission to the competition, you'll have to **Commit** your Kernel and find the generated `submission.csv` file in that Kernel Version's Output tab (note this is _outside_ of the Kernel Editor), then click \"Submit to Competition\".  When we re-run your Kernel during Stage Two, we will run the Kernel Version (generated when you hit \"Commit\") linked to your chosen Submission."},{"metadata":{"trusted":true,"_uuid":"ffd584a58c2656675e26d82efcd34dca31d4f5a3"},"cell_type":"code","source":"# lets check out that CSV file\nimport pandas as pd\nfrom datetime import datetime\nimport csv\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\nheaders = ['time', 'assetCode', 'confidenceValue']\ndf_in  = pd.read_csv('submission.csv',names=headers)\n\nprint(df_in)\n\ncode = df_in.assetCode[3]\ndf   = df_in[df_in.assetCode == code]           \n\ny = np.array(df['confidenceValue'], dtype=float)\nx = np.linspace(1.0, y.shape[0], num=y.shape[0])\n\n# plot\nplt.plot(x,y)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e3a267ea3149403c49ff59515a1a669ca2d1f9f"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}