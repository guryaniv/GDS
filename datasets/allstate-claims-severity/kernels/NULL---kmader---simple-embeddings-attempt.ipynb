{"nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "1204b5c9b3e912c72dc6ad9561bf0af36d3d5d51", "_cell_guid": "663eb8be-b6df-478d-830b-bdbc767a6857"}, "source": ["# Overview\n", "The goal of this notebook is to make a simple neural network which uses embeddings for all of the categorical variables and fully connected layers for the continuous ones (after a batch normalization step). The idea is to see how well just having a simple formula for embeddings works on complicated datasets."]}, {"cell_type": "code", "source": ["import os\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import keras\n", "from keras.layers import Embedding, Dense, Input, MaxPooling1D, concatenate, Flatten, Dropout, BatchNormalization\n", "from keras.models import Model"], "metadata": {"collapsed": true, "_uuid": "547d64ad5e01739133d7d1876ca42ae408d19d13", "_cell_guid": "7ce2d1c3-6d8a-48f7-b010-f648bb921c5a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["base_path = os.path.join('..', 'input')\n", "train_path = os.path.join(base_path, 'train.csv')\n", "test_path = os.path.join(base_path, 'test.csv')\n", "train_df = pd.read_csv(train_path)\n", "train_df.sample(3)"], "metadata": {"collapsed": true, "_uuid": "4499e2b0b4f1e408bb67adb16c2c0da389fc2dea", "_cell_guid": "37bd9a89-52b1-4800-8160-38c51597a0db"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.preprocessing import LabelEncoder\n", "cat_cols = [x for x in train_df.columns if 'cat' in x]\n", "cont_cols = [x for x in train_df.columns if 'cont' in x]\n", "le_encoders = {x: LabelEncoder() for x in cat_cols}\n", "le_cols = {k: v.fit_transform(train_df[k]) for k,v in le_encoders.items()}\n", "y_col = 'loss'"], "metadata": {"collapsed": true, "_uuid": "06a1343abdc2d2ffe8c910ff13fe609b6c14a470", "_cell_guid": "3d15adc4-62ea-40bd-8a64-01efe6070484"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["all_emb_chan, all_inputs = [], []\n", "for k,v in le_cols.items():\n", "    in_val = Input(shape = (1,), name = k)\n", "    all_emb_chan +=[Flatten()(Embedding(v.max()+1, (v.max()+1)//2)(in_val))]\n", "    all_inputs += [in_val]\n", "concat_layer = concatenate(all_emb_chan)\n", "norm_concat_emb = BatchNormalization()(concat_layer)\n", "feature_layer = Dense(16)(Dropout(0.5)(norm_concat_emb))\n", "\n", "cont_input = Input(shape = (len(cont_cols),), name = 'continuous')\n", "bn_cont = BatchNormalization()(cont_input)\n", "cont_feature_layer = Dense(16)(Dropout(0.5)(bn_cont))\n", "full_concat_layer = concatenate([feature_layer, cont_feature_layer])\n", "full_reduction = Dense(16)(full_concat_layer)\n", "\n", "out_layer = Dense(1, activation = 'tanh')(full_reduction)\n", "full_model = Model(inputs = all_inputs+[cont_input], outputs = [out_layer], name = 'FullModel')\n", "full_model.compile(optimizer = 'adam', loss = 'mae')\n", "print('Using a model with:', full_model.count_params(), 'parameters, in', len(full_model.layers), 'layers')"], "metadata": {"collapsed": true, "_uuid": "48fdfdbb09c366e442aa2175bdb99c672f1e369a", "_cell_guid": "6cd262e6-bc2f-46ed-922e-d0c42a437805"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["y_vec = train_df[y_col].copy().values\n", "loss_mean, loss_std = y_vec.mean(), 3*y_vec.std()\n", "y_vec -= loss_mean\n", "y_vec /= loss_std\n", "train_df['loss_norm'] = y_vec.clip(-1,1)"], "metadata": {"collapsed": true, "_uuid": "31df6e1f383d24a7070c12c5e3a200bfdd345a86", "_cell_guid": "00bedcdc-d7ad-4796-a7a2-3a6eb563f7e4"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "t_split_df, v_split_df = train_test_split(train_df, \n", "                 test_size = 0.2,\n", "                 stratify = pd.qcut(train_df['loss'], 10),\n", "                                         random_state = 2017)\n", "print(t_split_df.shape, v_split_df.shape)"], "metadata": {"collapsed": true, "_uuid": "d210e349c6193a7bf6a6db4f4fec6a0d646e2585", "_cell_guid": "09004ba0-bc9c-40c1-a9b0-079c0b48114d"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def gen_samples(in_df, batch_size = None, loss_name = 'loss_norm'):\n", "    while True:\n", "        out_df = in_df if batch_size is None else in_df.sample(batch_size)\n", "        feed_dict = {c_name: le_encoders[c_name].transform(out_df[c_name].values) for c_name in cat_cols}\n", "        feed_dict['continuous'] = out_df[cont_cols].values\n", "        yield feed_dict, out_df[loss_name].values"], "metadata": {"collapsed": true, "_uuid": "dcc7c50fa339e41a37d184602ba4ffff79452a3f", "_cell_guid": "acb7e243-2380-47a0-8445-0e7ae0b3d096"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["loss_history = []"], "metadata": {"collapsed": true, "_uuid": "70f2f38d2908897292f73a2e746b5e8dd7b3f22b", "_cell_guid": "6c8b4850-6c67-4493-9a21-73f7f8b53b5d"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["for i in range(10):\n", "    loss_history += [full_model.fit_generator(gen_samples(t_split_df, 32), \n", "                         steps_per_epoch = 500,\n", "                         epochs = 1,\n", "                         validation_data = next(gen_samples(v_split_df))\n", "                         )]"], "metadata": {"collapsed": true, "_uuid": "c0f3e0a2f7212a38f25c4ead52d6bfbc745ce004", "_cell_guid": "5760cb04-f701-49e1-aeb3-ebca9f3896c4"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["valid_vars, valid_loss = next(gen_samples(v_split_df, loss_name = 'loss'))\n", "pred_loss = full_model.predict(valid_vars).ravel()*loss_std+loss_mean"], "metadata": {"collapsed": true, "_uuid": "064b550524f7f4755939f472c48a8368b5c99361", "_cell_guid": "3ae2fd0f-e680-4a93-8c98-61ed89f7e6d9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["fig, ax1 = plt.subplots(1,1)\n", "ax1.hist(valid_loss-pred_loss)\n", "ax1.set_title('Loss Error: MAE-%2.2f' % (np.mean(np.abs(valid_loss-pred_loss))))\n", "ax1.set_xlabel('Actual - Predicted Loss')"], "metadata": {"collapsed": true, "_uuid": "0c559c4fd8f2e19478894aacf84613658c2afd40", "_cell_guid": "17299d26-6e59-4aac-a7eb-883d23379c58"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["print('Using a model with:', full_model.count_params(), 'parameters')"], "metadata": {"collapsed": true, "_uuid": "a61ef47aa2b85b66730851c8605ee34b18773e57", "_cell_guid": "197101ef-0bc7-4e68-848c-5fd045d119a1"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["test_df = pd.read_csv(test_path)\n", "test_vars, test_id = next(gen_samples(test_df, loss_name = 'id'))\n", "pred_test_loss = full_model.predict(test_vars, verbose = 1).ravel()*loss_std+loss_mean"], "metadata": {"collapsed": true, "_uuid": "f6fc8faa3894b29d5b45ee0c0d4ebb87e41ecc6b", "_cell_guid": "ebad9506-8c4b-4fe0-932d-9b9f02395aa2"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "d58658fb6ae26f4c2ebdb5fa1b787920328f3fd7", "_cell_guid": "0050354d-48ae-4d72-a149-15dfeeccc0a8"}, "source": ["# Out of scope\n", "great, the test dataset has labels we don't see in the training"]}, {"cell_type": "code", "source": [], "metadata": {"collapsed": true, "_uuid": "6536f8b9328ba8d030dbd3d3e1ea7b39a2b11479", "_cell_guid": "89562300-fb2b-4e66-b8b1-1e04c6298966"}, "execution_count": null, "outputs": []}], "metadata": {"language_info": {"file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1}