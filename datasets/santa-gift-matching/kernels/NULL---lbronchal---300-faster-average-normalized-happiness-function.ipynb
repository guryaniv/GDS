{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python"}}, "cells": [{"metadata": {"_uuid": "60a2cddb5047a327188737aa4efde2d30f904203", "_cell_guid": "8801e2e5-920b-470e-82fa-d796ccb37771"}, "source": ["## Summary\n", "This is not a typical machine learning problem, but it's a very interesting optimization one. The possibility to evaluate fast the solutions it's going to be very important. The following implementation of the **Average Normalized Happiness** function was originally provided by organizers [here](https://www.kaggle.com/wendykan/average-normalized-happiness-demo) but with small changes it can run in almost **70% less time** \n", "\n", "update:\n", "\n", "I have added a more extended analysis of the time execution comparison and changed the name of the kernel. The original one was confusing: \"70% Faster Average Normalized Happiness Function\". The optimized script takes 70% less time to execute than the original one, but that means it is about 300% faster."], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "a8ae2537afe8afc1760f1eb6ecc039477cb1fee1", "_cell_guid": "fd0fc0cc-293d-45eb-9a1c-6febcc9395d9"}, "execution_count": null, "source": ["import numpy as np \n", "import pandas as pd "], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "36cf3c5bdc58383f33a34266e3e7df782da4d5a6", "_cell_guid": "d68c1540-ca0e-48c3-be94-3166f6f5ea9d"}, "execution_count": null, "source": ["gift_pref = pd.read_csv('../input/child_wishlist.csv',header=None).drop(0, 1).values\n", "child_pref = pd.read_csv('../input/gift_goodkids.csv',header=None).drop(0, 1).values\n", "random_sub = pd.read_csv('../input/sample_submission_random.csv').values.tolist()"], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "4337dc50ea46092fc443f80d8ade4fb55386db1c", "_cell_guid": "dabb9ad7-fdc7-4551-972e-23a8708d1d87"}, "source": ["The original function from [here](https://www.kaggle.com/wendykan/average-normalized-happiness-demo):"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "f75cd99829c6c74c9cd6a8194dd490a8509e4311", "_cell_guid": "2f3e98e4-c849-4342-9da2-c138ac927658"}, "execution_count": null, "source": ["# https://www.kaggle.com/wendykan/average-normalized-happiness-demo\n", "\n", "from collections import Counter\n", "\n", "n_children = 1000000 # n children to give\n", "n_gift_type = 1000 # n types of gifts available\n", "n_gift_quantity = 1000 # each type of gifts are limited to this quantity\n", "n_gift_pref = 10 # number of gifts a child ranks\n", "n_child_pref = 1000 # number of children a gift ranks\n", "twins = int(0.004 * n_children)    # 0.4% of all population, rounded to the closest even number\n", "ratio_gift_happiness = 2\n", "ratio_child_happiness = 2\n", "\n", "\n", "def avg_normalized_happiness(pred, child_pref, gift_pref):\n", "    \n", "    # check if number of each gift exceeds n_gift_quantity\n", "    gift_counts = Counter(elem[1] for elem in pred)\n", "    for count in gift_counts.values():\n", "        assert count <= n_gift_quantity\n", "                \n", "    # check if twins have the same gift\n", "    for t1 in range(0,twins,2):\n", "        twin1 = pred[t1]\n", "        twin2 = pred[t1+1]\n", "        assert twin1[1] == twin2[1]\n", "    \n", "    max_child_happiness = n_gift_pref * ratio_child_happiness\n", "    max_gift_happiness = n_child_pref * ratio_gift_happiness\n", "    total_child_happiness = 0\n", "    total_gift_happiness = np.zeros(n_gift_type)\n", "    \n", "    for row in pred:\n", "        child_id = row[0]\n", "        gift_id = row[1]\n", "        \n", "        # check if child_id and gift_id exist\n", "        assert child_id < n_children\n", "        assert gift_id < n_gift_type\n", "        assert child_id >= 0 \n", "        assert gift_id >= 0\n", "        child_happiness = (n_gift_pref - np.where(gift_pref[child_id]==gift_id)[0]) * ratio_child_happiness\n", "        if not child_happiness:\n", "            child_happiness = -1\n", "\n", "        gift_happiness = ( n_child_pref - np.where(child_pref[gift_id]==child_id)[0]) * ratio_gift_happiness\n", "        if not gift_happiness:\n", "            gift_happiness = -1\n", "\n", "        total_child_happiness += child_happiness\n", "        total_gift_happiness[gift_id] += gift_happiness\n", "    \n", "    # print(max_child_happiness, max_gift_happiness \n", "    print('normalized child happiness=',float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) , \\\n", "        ', normalized gift happiness',np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity))\n", "    return float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) + np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity)\n"], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "8cdb68cb4228e1de5814fd1725d2254e0ba497ee", "_cell_guid": "726a5644-88d9-424e-b8d3-b89f0ee4355f"}, "source": ["Some changes using [numba](https://numba.pydata.org/):"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "01de223a0c5ba0051d4a6326ac615c718e91ee04", "_cell_guid": "1210a000-7688-47c4-8aa2-8d1f459aa2f8"}, "execution_count": null, "source": ["from numba import jit\n", "\n", "@jit(nopython=True)\n", "def avg_normalized_happiness_fast(pred, child_pref, gift_pref):\n", "    \n", "    n_children = 1000000 # n children to give\n", "    n_gift_type = 1000 # n types of gifts available\n", "    n_gift_quantity = 1000 # each type of gifts are limited to this quantity\n", "    n_gift_pref = 10 # number of gifts a child ranks\n", "    n_child_pref = 1000 # number of children a gift ranks\n", "    twins = int(0.004 * n_children)    # 0.4% of all population, rounded to the closest even number\n", "    ratio_gift_happiness = 2\n", "    ratio_child_happiness = 2\n", "\n", "    # check if number of each gift exceeds n_gift_quantity\n", "    tmp_dict = np.zeros(n_gift_quantity, dtype=np.uint16)\n", "    for i in np.arange(len(pred)):\n", "        tmp_dict[pred[i][1]] += 1\n", "    for count in np.arange(n_gift_quantity):\n", "        assert count <= n_gift_quantity    \n", "                \n", "    # check if twins have the same gift\n", "    for t1 in np.arange(0,twins,2):\n", "        twin1 = pred[t1]\n", "        twin2 = pred[t1+1]\n", "        assert twin1[1] == twin2[1]\n", "    \n", "    max_child_happiness = n_gift_pref * ratio_child_happiness\n", "    max_gift_happiness = n_child_pref * ratio_gift_happiness\n", "    total_child_happiness = 0\n", "    total_gift_happiness = np.zeros(n_gift_type, dtype=np.float32)\n", "\n", "    for i in np.arange(len(pred)):\n", "        row = pred[i]\n", "        child_id = row[0]\n", "        gift_id = row[1]\n", "        \n", "        # check if child_id and gift_id exist\n", "        assert child_id < n_children\n", "        assert gift_id < n_gift_type\n", "        assert child_id >= 0 \n", "        assert gift_id >= 0\n", "        \n", "        child_happiness = (n_gift_pref - np.where(gift_pref[child_id]==gift_id)[0]) * ratio_child_happiness\n", "        if (len(child_happiness) == 0):\n", "            tmp_child_happiness = -1\n", "        else:\n", "            tmp_child_happiness = child_happiness[0]\n", "\n", "        gift_happiness = ( n_child_pref - np.where(child_pref[gift_id]==child_id)[0]) * ratio_gift_happiness\n", "        if (len(gift_happiness) == 0):\n", "            tmp_gift_happiness = -1\n", "        else:\n", "            tmp_gift_happiness = gift_happiness[0]\n", "            \n", "        total_child_happiness += tmp_child_happiness    \n", "        total_gift_happiness[gift_id] += tmp_gift_happiness    \n", "        \n", "    # print(max_child_happiness, max_gift_happiness  \n", "    print('normalized child happiness=',float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) , \\\n", "        ', normalized gift happiness',np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity))\n", "    return float(total_child_happiness)/(float(n_children)*float(max_child_happiness)) + np.mean(total_gift_happiness) / float(max_gift_happiness*n_gift_quantity)\n", "            "], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "2da2c14f625247be1f2f5a3e19b8e03a311b63a2", "_cell_guid": "ebdeb54b-0d8f-4e5b-9016-bf5b9f13ee64"}, "source": ["Let's compare performance:"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "feceefbc02344721e7aa6a70fea62e50d640a194", "_cell_guid": "ba0ec542-5e15-4cf7-8ec4-b28a0eb9b601"}, "execution_count": null, "source": ["time_original = %timeit -r 10 -o avg_normalized_happiness(random_sub, child_pref, gift_pref)"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "bff4187582a4c58f64dabffa95bb11c4bea520a0", "_cell_guid": "cd087fba-8920-462f-a511-e7e632b7c690"}, "execution_count": null, "source": ["time_fast = %timeit -r 10 -o avg_normalized_happiness_fast(np.array(random_sub), child_pref, gift_pref)"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "793ea1a61f46f06b9297e37e0f0c2d88a6703299", "_cell_guid": "81c6a2c9-8e31-4c11-841b-a372429e8fe4"}, "execution_count": null, "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "time_result = pd.DataFrame({'time_original': time_original.all_runs,\n", "                            'time_fast': time_fast.all_runs})\n", "time_result.describe()"], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "e8afc3c05d9518f9feb518131862cd7842f23a53", "_cell_guid": "87d216b8-0287-472d-a927-f58eaa2f3010"}, "source": ["The original version takes 20.53 seconds in mean, while the optimized one with numba takes about 6.45 seconds in mean. That's 14.08 seconds less, almost 70% less time (68.58%). That means that the optimized script is more than 300% faster (100/31.42  = 3.18)"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "5cb0ca633121614f84179fca6d9803cc36a5d979", "_cell_guid": "537e25a3-61b9-4ecb-be17-42177e7120f2"}, "execution_count": null, "source": ["time_result.plot.box(figsize=(12,10))\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "8f866273f406a00a3c7a87b238e34c07ac07d28e", "_cell_guid": "5ad6ccec-236a-421c-9db4-d028ac91b4a3"}, "execution_count": null, "source": ["time_result.plot(figsize=(12,10))\n", "plt.show()"], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "3a0b0cf94f02840497a680df1dfbc15a31126042", "_cell_guid": "9d5c8d72-5184-466a-a3b0-3211adf12e90"}, "source": ["The new function is faster, but I'm sure there is still room for more improvement. \n", "Although both functions produce almost the same result, there is a small deifference because of float representation:"], "cell_type": "markdown"}, {"metadata": {"collapsed": true, "_uuid": "143a1ec9f69c4f6ee2a33bbbb6537da2cf3f551a", "_cell_guid": "e797b6f9-ea21-4800-81b5-31b66312830d"}, "execution_count": null, "source": ["avg_normalized_happiness(np.array(random_sub), child_pref, gift_pref)"], "cell_type": "code", "outputs": []}, {"metadata": {"collapsed": true, "_uuid": "4954245645e9b737c3151962a67ee133f9328fba", "_cell_guid": "6756bb39-a086-479c-bab3-d99b10a1850d"}, "execution_count": null, "source": ["avg_normalized_happiness_fast(np.array(random_sub), child_pref, gift_pref)"], "cell_type": "code", "outputs": []}, {"metadata": {"_uuid": "cfc0188d7897fcd8193382f4dad89be638f5c353", "_cell_guid": "071b980a-e2d5-40f9-9728-e38bad1d6824"}, "source": ["## Conclusion\n", "With small changes, we have built an more than **300% faster Average Normalized Happiness function** with the [numba](https://numba.pydata.org/) package, and it is possible to even get better performance. Other alternatives could be to use [cython](http://cython.org/) and even better, in case of not using python,  to use C++ with CUDA support."], "cell_type": "markdown"}], "nbformat_minor": 1, "nbformat": 4}