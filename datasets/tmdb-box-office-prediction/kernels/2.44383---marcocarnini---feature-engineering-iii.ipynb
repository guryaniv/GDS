{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Importing data"},{"metadata":{"trusted":true,"_uuid":"0fef33abfcfe08f564c34dd35e686535061c5528"},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"../input/train.csv\")\nprint(df.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85f7eff9ff634ebf5938007e5da492c8c422e835"},"cell_type":"markdown","source":"The input variables currenly unused:\n\n* **id**                      \n* ~~**belongs_to_collection**~~\n* ~~**budget**~~                  \n* **genres**                  \n* ~~**homepage**~~                 \n* **imdb_id**                  \n* ~~**original_language**~~        \n* **original_title**           \n* **overview**                 \n* ~~**popularity**~~             \n* ~~**poster_path**~~             \n* **production_companies**    \n* **production_countries**     \n* ~~**release_date**~~            \n* ~~**runtime**~~                \n* **spoken_languages**        \n* ~~**status**~~                   \n* **tagline**                  \n* **title**                   \n* **Keywords**                \n* **cast**                     \n* **crew**                    \n* ~~**revenue**~~                 \n\nThe metric to be used is **RMLSE**:"},{"metadata":{"trusted":true,"_uuid":"84c13e7444f22a8bb7bc4bb89d86d86aa7bda349"},"cell_type":"code","source":"from sklearn.metrics.scorer import make_scorer\n\ndef rmlse(y, y0):\n    assert len(y) == len(y0)\n    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(np.clip(y0, 0, None)), 2)))\n\nrmsle_scorer = make_scorer(rmlse, greater_is_better=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7effcb2f8e26b1e3d1cdfca1e8eca5d786357dac"},"cell_type":"markdown","source":"# Adding variables"},{"metadata":{"trusted":true,"_uuid":"67ac3ef04cb336461e3f8e9eacaf3f5d0f2e46a1"},"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"../input/train.csv\")\nprint(df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98089ceae550b32cfd0dc79d392d13ce5ff5063c"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea524c4566022f6424c344b45e6b20d6a4ac51f1"},"cell_type":"markdown","source":"## Genres"},{"metadata":{"trusted":true,"_uuid":"2965bc587517882ff5a8f7fa30340ef456ea0f21"},"cell_type":"code","source":"print(df.genres)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b98ea70e91aafe8f2443c36337b29c404e4112dc"},"cell_type":"code","source":"import numpy as np\n\nallgenres = set([i[\"name\"] for j in df.genres[df.genres.notnull()] for i in eval(j)])\nd = {i: np.zeros(df.shape[0], dtype=int) for i in allgenres}\nd[\"Missing\"] = np.zeros(df.shape[0], dtype=int)\ngenres_matrix = pd.DataFrame(d)\n\ngenres_matrix[\"Missing\"][pd.isnull(df.genres)] = 1.0\nfor j,i in enumerate(pd.notnull(df.genres)):\n    if i:\n        for k in eval(df.genres[j]):\n            genres_matrix.loc[j, k[\"name\"]] += 1\ngenres_matrix[\"genres_number\"] = genres_matrix.apply(sum, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82398257687d2552fdf71837cfb6f391c47d04dd"},"cell_type":"code","source":"print(set(genres_matrix.genres_number))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11fb3d9023e289f2e2390b6a305bf6f5c32de101"},"cell_type":"markdown","source":"## Production companies"},{"metadata":{"trusted":true,"_uuid":"33afe9dd13a0d5e006b12d25ebe26d527b1bee2c"},"cell_type":"code","source":"print(df.production_companies[0:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26c38d06c368aeacfa9d9e82104c8f8b3fd0b0a3"},"cell_type":"code","source":"allcompanies = set([i[\"name\"] for j in df.production_companies[df.production_companies.notnull()] for i in eval(j)])\nd = {i: np.zeros(df.shape[0], dtype=int) for i in allcompanies}\nd[\"Missing\"] = np.zeros(df.shape[0], dtype=int)\ncompanies_matrix = pd.DataFrame(d)\n\ncompanies_matrix[\"Missing\"][pd.isnull(df.production_companies)] = 1.0\nfor j,i in enumerate(pd.notnull(df.production_companies)):\n    if i:\n        for k in eval(df.production_companies[j]):\n            companies_matrix.loc[j, k[\"name\"]] += 1\ncompanies_matrix[\"companies_number\"] = companies_matrix.sum(axis=1)-companies_matrix.Missing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1321a2081ee588d0d60ad489ce17d0952123efa2"},"cell_type":"markdown","source":"# Model\n\n## Select train and test"},{"metadata":{"trusted":true,"_uuid":"b636726e6b8dd6ae7f3c73c76091db703db9b661"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"../input/train.csv\")\ntrain = pd.DataFrame(df[[\"budget\", \"popularity\", \"runtime\", \"status\", \"original_language\"]])\ntrain = pd.get_dummies(train)\ntest = pd.read_csv(\"../input/test.csv\")\ndfte = pd.DataFrame(test[[\"budget\", \"popularity\", \"runtime\", \"status\", \"original_language\"]])\ndfte = pd.get_dummies(dfte)\nmissing_columns = set(dfte.columns) - set(train.columns)\nfor _ in missing_columns:\n    train[_] = 0\nmissing_columns = set(train.columns) - set(dfte.columns)\nfor _ in missing_columns:\n    dfte[_] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fc9b905db5e21d9383344b4a3d9dfb838965014"},"cell_type":"markdown","source":"## Features"},{"metadata":{"trusted":true,"_uuid":"a42d7d0b07269e714ff4c033cf2543c88fe27215"},"cell_type":"code","source":"train.loc[1335, \"runtime\"] = 130.0\ntrain.loc[2302, \"runtime\"] = 90.0\ntrain[\"homepage_missing\"] = np.array(df.homepage.isna(), dtype=int)\ntrain[\"belongs_to_collection_missing\"] = np.array(df.belongs_to_collection.isna(), dtype=int)\ntrain[\"release_day\"] = [int(i.split(\"/\")[1]) for i in df.release_date]\ntrain[\"release_month\"] = [int(i.split(\"/\")[0]) for i in df.release_date]\ntrain[\"release_year\"] = [int(i.split(\"/\")[2]) for i in df.release_date]\ntrain[\"release_year\"] = [2000+i if i < 18 else 1900+i for i in train.release_year]\n\ntrain[\"poster_length\"] = 0\ntrain.loc[df.poster_path.notnull(), \"poster_length\"] = [len(i) for i in df.poster_path[df.poster_path.notnull()]]\n\nlabel = df[\"revenue\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f19be63ae0bea0061260a9b9b76b503879259006"},"cell_type":"code","source":"train[\"contains_com\"] = 0\ntrain[\"contains_uk\"] = 0\ntrain[\"contains_fr\"] = 0\ntrain[\"contains_de\"] = 0\ntrain[\"contains_net\"] = 0\ntrain[\"contains_kr\"] = 0\ntrain[\"contains_disney\"] = 0\ntrain[\"contains_sony\"] = 0\ntrain[\"contains_warnerbros\"] = 0\ntrain[\"contains_indexhtml\"] = 0\ntrain[\"contains_movie\"] = 0\ntrain[\"contains_wikipedia\"] = 0\ntrain[\"count_slash\"] = 0\n\ntrain.loc[df.homepage.notnull(), \"contains_com\"] = [1 if ((i != \"\") & (\".com\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_uk\"] = [1 if ((i != \"\") & (\".uk\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_fr\"] = [1 if ((i != \"\") & (\".fr\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_de\"] = [1 if ((i != \"\") & (\".de\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_net\"] = [1 if ((i != \"\") & (\".net\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_kr\"] = [1 if ((i != \"\") & (\".kr\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_disney\"] = [1 if ((i != \"\") & (\"disney\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_sony\"] = [1 if ((i != \"\") & (\"sony\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_warnerbros\"] = [1 if ((i != \"\") & (\"warnerbros\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_indexhtml\"] = [1 if ((i != \"\") & (\"index.html\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_movie\"] = [1 if ((i != \"\") & (\"movie\" in i.lower())) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"contains_wikipedia\"] = [1 if ((i != \"\") & (\"wikipedia\" in i)) else 0 for i in df.homepage[df.homepage.notnull()]]\ntrain.loc[df.homepage.notnull(), \"count_slash\"] = [len(i.split(\"/\")) for i in df.homepage[df.homepage.notnull()]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6a5f8c17989073a57f80b63ae590c2319e54c23","scrolled":true},"cell_type":"code","source":"import numpy as np\n\nd = {i: np.zeros(df.shape[0], dtype=int) for i in allgenres}\nd[\"Missing\"] = np.zeros(df.shape[0], dtype=int)\ngenres_matrix = pd.DataFrame(d)\n\ngenres_matrix[\"Missing\"][pd.isnull(df.genres)] = 1.0\nfor j,i in enumerate(pd.notnull(df.genres)):\n    if i:\n        for k in eval(df.genres[j]):\n            genres_matrix.loc[j, k[\"name\"]] += 1\ngenres_matrix[\"genres_number\"] = genres_matrix.sum(axis=1)-genres_matrix.Missing\nprint(genres_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8570c758f767ca1604277dc57494acbcd1b5b559"},"cell_type":"code","source":"allcompanies = set([i[\"name\"] for j in df.production_companies[df.production_companies.notnull()] for i in eval(j)])\nd = {i: np.zeros(train.shape[0], dtype=int) for i in allcompanies}\nd[\"Missing\"] = np.zeros(train.shape[0], dtype=int)\ncompanies_matrix = pd.DataFrame(d)\n\ncompanies_matrix[\"Missing\"][pd.isnull(df.production_companies)] = 1.0\nfor j,i in enumerate(pd.notnull(df.production_companies)):\n    if i:\n        for k in eval(df.production_companies[j]):\n            companies_matrix.loc[j, k[\"name\"]] += 1\ncompanies_matrix[\"companies_number\"] = companies_matrix.sum(axis=1)-companies_matrix.Missing\nprint(companies_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"105e832d974dabb89c7d754019586c5daa0835b9"},"cell_type":"code","source":"train[\"row\"] = np.linspace(0, train.shape[0], train.shape[0], dtype=int)\ngenres_matrix[\"row\"]= np.linspace(0, train.shape[0], train.shape[0], dtype=int)\ncompanies_matrix[\"row\"]= np.linspace(0, train.shape[0], train.shape[0], dtype=int)\ntrain = pd.concat([train, genres_matrix, companies_matrix], axis=1, join=\"inner\")\ntrain.drop([\"row\"], axis = 1, inplace=False)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff1b83395ce78325031bf918e7244d77d59f8d41"},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true,"_uuid":"64041b47f9b3abf73a88549de8417cd7c4f6e65a"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\nmodel  = RandomForestRegressor(n_estimators=100, random_state=2019)\nscores_randomforest = cross_val_score(model, train, label, cv=10, scoring=rmsle_scorer)\nprint(-np.mean(scores_randomforest), \"+/-\" ,np.std(scores_randomforest))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d32e9ddc7c359b454c9eaf7d36a1787711be6b47"},"cell_type":"markdown","source":"Train on the full train set:"},{"metadata":{"trusted":true,"_uuid":"2da0ed576b93a5aaadc78583a8999a6549df36ed"},"cell_type":"code","source":"model  = RandomForestRegressor(n_estimators=100)\nmodel.fit(train, label)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae59d77d3dc79357958751479a3fe38c8896edb9"},"cell_type":"markdown","source":"Prepare the test set:"},{"metadata":{"trusted":true,"_uuid":"5a26ff035d6c674970aceb7d826897ac04a0c81e"},"cell_type":"code","source":"dfte[\"homepage_missing\"] = np.array(test.homepage.isna(), dtype=int)\ndfte[\"belongs_to_collection_missing\"] = np.array(test.belongs_to_collection.isna(), dtype=int)\ndfte.loc[243, \"runtime\"] = 93.0\ndfte.loc[1489, \"runtime\"] = 91.0\ndfte.loc[1632, \"runtime\"] = 100.0\ndfte.loc[3817, \"runtime\"] = 90.0\n\ntest.loc[828, \"release_date\"] = \"03/30/2001\"\ndfte[\"release_day\"] = [int(i.split(\"/\")[1]) for i in test.release_date]\ndfte[\"release_month\"] = [int(i.split(\"/\")[0]) for i in test.release_date]\ndfte[\"release_year\"] = [int(i.split(\"/\")[2]) for i in test.release_date]\ndfte[\"release_year\"] = [2000+i if i < 18 else 1900+i for i in dfte.release_year]\n\ndfte[\"poster_length\"] = 0\ndfte.loc[test.poster_path.notnull(), \"poster_length\"] = [len(i) for i in test.poster_path[test.poster_path.notnull()]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e97e8e5b210b7b4b26fcc593a10424d28406bcf"},"cell_type":"code","source":"dfte[\"contains_com\"] = 0\ndfte[\"contains_uk\"] = 0\ndfte[\"contains_fr\"] = 0\ndfte[\"contains_de\"] = 0\ndfte[\"contains_net\"] = 0\ndfte[\"contains_kr\"] = 0\ndfte[\"contains_disney\"] = 0\ndfte[\"contains_sony\"] = 0\ndfte[\"contains_warnerbros\"] = 0\ndfte[\"contains_indexhtml\"] = 0\ndfte[\"contains_movie\"] = 0\ndfte[\"contains_wikipedia\"] = 0\ndfte[\"count_slash\"] = 0\n\ndfte.loc[test.homepage.notnull(), \"contains_com\"] = [1 if ((i != \"\") & (\".com\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_uk\"] = [1 if ((i != \"\") & (\".uk\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_fr\"] = [1 if ((i != \"\") & (\".fr\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_de\"] = [1 if ((i != \"\") & (\".de\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_net\"] = [1 if ((i != \"\") & (\".net\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_kr\"] = [1 if ((i != \"\") & (\".kr\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_disney\"] = [1 if ((i != \"\") & (\"disney\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_sony\"] = [1 if ((i != \"\") & (\"sony\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_warnerbros\"] = [1 if ((i != \"\") & (\"warnerbros\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_indexhtml\"] = [1 if ((i != \"\") & (\"index.html\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_movie\"] = [1 if ((i != \"\") & (\"movie\" in i.lower())) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"contains_wikipedia\"] = [1 if ((i != \"\") & (\"wikipedia\" in i)) else 0 for i in test.homepage[test.homepage.notnull()]]\ndfte.loc[test.homepage.notnull(), \"count_slash\"] = [len(i.split(\"/\")) for i in test.homepage[test.homepage.notnull()]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c380c7952e5a16ab5f4ba6c3666c941ec1cb1243"},"cell_type":"code","source":"import numpy as np\n\nd = {i: np.zeros(test.shape[0], dtype=int) for i in allgenres}\nd[\"Missing\"] = np.zeros(test.shape[0], dtype=int)\ngenres_matrix = pd.DataFrame(d)\n\ngenres_matrix[\"Missing\"][pd.isnull(test.genres)] = 1.0\nfor j,i in enumerate(pd.notnull(test.genres)):\n    if i:\n        for k in eval(test.genres[j]):\n            genres_matrix.loc[j, k[\"name\"]] += 1\ngenres_matrix[\"genres_number\"] = genres_matrix.sum(axis=1)-genres_matrix.Missing\nprint(genres_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d36cb1f9bee2bb9573f356e9cd3f6e99b9c3933e"},"cell_type":"code","source":"d1 = {i: np.zeros(test.shape[0], dtype=int) for i in allcompanies}\nd1[\"Missing\"] = np.zeros(test.shape[0], dtype=int)\ncompanies_matrix = pd.DataFrame(d1)\n\ncompanies_matrix[\"Missing\"][pd.isnull(test.production_companies)] = 1.0\nfor j,i in enumerate(pd.notnull(test.production_companies)):\n    if i:\n        for k in eval(test.production_companies[j]):\n            if (k[\"name\"] in d1.keys()):\n                companies_matrix.loc[j, k[\"name\"]] += 1\ncompanies_matrix[\"companies_number\"] = companies_matrix.sum(axis=1)-companies_matrix.Missing\nprint(companies_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85630f2148e9818367aeaa04aeb19bcc600e565a"},"cell_type":"code","source":"dfte[\"row\"] = np.linspace(0, dfte.shape[0], dfte.shape[0], dtype=int)\ngenres_matrix[\"row\"]= np.linspace(0, dfte.shape[0], dfte.shape[0], dtype=int)\ncompanies_matrix[\"row\"]= np.linspace(0, dfte.shape[0], dfte.shape[0], dtype=int)\ndfte = pd.concat([dfte, genres_matrix, companies_matrix], axis=1, join=\"inner\")\ndfte.drop([\"row\"], axis = 1, inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a4f97d6a5116e8f9b2c75f33e81f9462f8c6703"},"cell_type":"markdown","source":"## Prepare submission"},{"metadata":{"trusted":true,"_uuid":"4a7212be487cb329274058356649fa53f239012b"},"cell_type":"code","source":"predictions = model.predict(dfte)\npredictions = np.clip(predictions, 0, None)\nsubmission = pd.DataFrame({\n    \"id\" : test.id,\n    \"revenue\": predictions\n})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}