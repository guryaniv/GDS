{"cells": [{"cell_type": "markdown", "source": ["This is a basic LogisticRegression model trained using the data from https://www.kaggle.com/eoveson/convai-datasets-baseline-models\n", "\n", "The baseline model in that kernal is tuned a little to get the data for this kernal This kernal scored 0.044 in the LB"], "metadata": {}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.pipeline import Pipeline\n", "from scipy import sparse\n", "# set stopwords\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"collapsed": true, "_cell_guid": "eb9acbb1-40db-4a60-9c00-7e1134408cb1", "_uuid": "7e97dad72af19207237cb816bc898ca5818f4389"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train = pd.read_csv('../input/dataset/train_with_convai.csv')\n", "test = pd.read_csv('../input/dataset/test_with_convai.csv')\n"], "metadata": {"collapsed": true, "_cell_guid": "bb967e03-d30b-46ec-b9d2-c0f5d4c0ee68", "_uuid": "97b399586c43626b73bc77b50e58b952d86ea8da"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["feats_to_concat = ['comment_text', 'toxic_level', 'attack', 'aggression']\n", "# combining test and train\n", "alldata = pd.concat([train[feats_to_concat], test[feats_to_concat]], axis=0)\n", "alldata.comment_text.fillna('unknown', inplace=True)"], "metadata": {"collapsed": true, "_cell_guid": "1eebb207-607e-4985-908e-9848888808b1", "_uuid": "3e90295dde0dd25158ea9e3464165aa8ea62fd1c"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["vect_words = TfidfVectorizer(max_features=50000, analyzer='word', ngram_range=(1, 1))\n", "vect_chars = TfidfVectorizer(max_features=20000, analyzer='char', ngram_range=(1, 3))"], "metadata": {"collapsed": true, "_cell_guid": "88a8e609-b287-4a7e-b72d-5dcac6f4a55f", "_uuid": "741273ee4b5122a37d978708ba29e16879e5b33f"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["all_words = vect_words.fit_transform(alldata.comment_text)\n", "all_chars = vect_chars.fit_transform(alldata.comment_text)"], "metadata": {"collapsed": true, "_cell_guid": "6db22032-8e99-4848-8978-be7c68a1e936", "_uuid": "cf10b99072cef22bf87ee92c9aa51f035a26e893"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train_new = train\n", "test_new = test"], "metadata": {"collapsed": true, "_cell_guid": "8f42e0d7-5938-4bb0-beb7-7ddf9f85685d", "_uuid": "d074b6b6c5271f462c129c534980c5a0d287599f"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train_words = all_words[:len(train_new)]\n", "test_words = all_words[len(train_new):]\n", "\n", "train_chars = all_chars[:len(train_new)]\n", "test_chars = all_chars[len(train_new):]"], "metadata": {"collapsed": true, "_cell_guid": "c068c9bb-bf28-4342-aa71-e575c6d93788", "_uuid": "09975f14757c51e19876dab638a39671dfd555e4"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["feats = ['toxic_level', 'attack']\n", "# make sparse matrix with needed data for train and test\n", "train_feats = sparse.hstack([train_words, train_chars, alldata[feats][:len(train_new)]])\n", "test_feats = sparse.hstack([test_words, test_chars, alldata[feats][len(train_new):]])"], "metadata": {"collapsed": true, "_cell_guid": "5d55e152-e1cb-4cf0-aa41-e3eec5850b3a", "_uuid": "0338f2d0b8f09c751f97afebf1cf8e77d8a10fe3"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n", "\n", "only_col = ['toxic']\n", "\n", "preds = np.zeros((test_new.shape[0], len(col)))\n", "\n", "for i, j in enumerate(col):\n", "    print('===Fit '+j)\n", "    \n", "    model = LogisticRegression(C=4.0, solver='sag')\n", "    print('Fitting model')\n", "    model.fit(train_feats, train_new[j])\n", "      \n", "    print('Predicting on test')\n", "    preds[:,i] = model.predict_proba(test_feats)[:,1]"], "metadata": {"collapsed": true, "_cell_guid": "350aad79-ee6f-44bc-9d85-4e9652956bd3", "_uuid": "da2082c68a367369fac28ddc09eec2e5b6c718bb", "scrolled": false}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["subm = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n", "\n", "submid = pd.DataFrame({'id': subm[\"id\"]})\n", "submission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\n", "submission.to_csv('feat_lr_2cols.csv', index=False)"], "metadata": {"collapsed": true, "_cell_guid": "9d84b909-d93b-4778-b432-701f65a73d3c", "_uuid": "3605ca797e6d5e4d05ac2c63d70766c23d2a8cf1"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": [], "metadata": {"collapsed": true, "_cell_guid": "6d350714-1262-4f91-af11-a7f95750ec84", "_uuid": "be385cfe2683246d05dc872d7b09cb4608b73337"}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3", "version": "3.6.3", "name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}}, "nbformat_minor": 1}