{"metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "name": "python", "version": "3.6.1", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"metadata": {"_uuid": "e627faf53120efa07880ee1725dd90e190aa6cdc", "_cell_guid": "4d3aa338-daf0-4e37-bb84-a71e1081241b"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n"]}, {"metadata": {"_uuid": "08a541d8982dd5aa01fffedb4e64c35845d44665", "_cell_guid": "4f6daedb-e4a8-41cb-bfb2-121a1062ff5a"}, "cell_type": "markdown", "source": ["In my previous kernel for this dataset, I performed exploratory data analysis and built a basic logistic regression model to get a first glimpse of what is the best approach to detect the anomalies. We saw that using a simple supervised classification model without applying upsampling/downsampling of the majority class (recall dataset is imbalanced), the AUCPR was really low. Thus, we need to find another strategy.\n", "Recall we saw that for both non-fraudulent and fraudlent classes, features followed Gaussian distributions. For example, for V4, the non-fraudulent class followed a Gaussian distribution with small variance compared to the fraudulent class. "]}, {"metadata": {"_uuid": "34f117424f4a3b5a296ecf0bbdc978b62d7e7003", "_cell_guid": "ba7e310e-9e9c-48b8-a5f2-aaaae0fa408e"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["df = pd.read_csv('../input/creditcard.csv')\n", "import matplotlib.gridspec as gridspec\n", "features=['V17','V14', 'V11', 'V4', 'V15', 'V13']\n", "nplots=np.size(features)\n", "plt.figure(figsize=(15,4*nplots))\n", "gs = gridspec.GridSpec(nplots,1)\n", "for i, feat in enumerate(features):\n", "    ax = plt.subplot(gs[i])\n", "    sns.distplot(df[feat][df.Class==1], bins=30)\n", "    sns.distplot(df[feat][df.Class==0],bins=30)\n", "    ax.legend(['fraudulent', 'non-fraudulent'],loc='best')\n", "    ax.set_xlabel('')\n", "    ax.set_title('Distribution of feature: ' + feat)\n"]}, {"metadata": {"_uuid": "47e5a40d7b129639d7306dcc1132bb55c924b06c", "collapsed": true, "_cell_guid": "e0f0a1fe-94c5-40ce-8545-e3cba73ae309"}, "cell_type": "markdown", "source": ["Now let's evaluate the scatterplots between two features (i.e. V14 and V17, V11 and V4, etc...). We are trying to find what kind of Gaussian distributions we have (i.e. evaluate the covariances) so that we can estimate a Gaussian Mixture Model (GMM) using the Expectation-Maximization algorithm in order to represent the the non-fraudulent class. Finally, detect the fraudulent samples by evaluating their probabilities (i.e. below a threshold).\n"]}, {"metadata": {"_uuid": "5bce4ea156f5204e4361c1cf256707a8c0fefa01", "_cell_guid": "76411889-05b1-4ca1-876b-89b5baf2bcd4"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["sns.pairplot(df[df.Class==1], vars=['V14', 'V17'], kind='reg', hue='Class')\n"]}, {"metadata": {"_uuid": "65f4b27c4fe8cb22d718eb8387839048c4544884", "_cell_guid": "c34ddb20-d661-433d-90ba-67d24e9fc2c8"}, "cell_type": "markdown", "source": ["Now we will train a simple Gaussian mixture model using V14 and V17. \n", "We will create a dataset with only non-fraudulent transactions and a dataset with fraudulent ones\n", "Then we will plit non-fraudulent data in 90% for training GMM and 10% for cross-validation and testing\n", "Then we will split the fraudulent data in 50% for cross-validation (to find the probability threshold) and 50% for testing."]}, {"metadata": {"_uuid": "807ea0b2d5e378b78454953c77acff913072d1a8", "_cell_guid": "9cd2cd36-fb78-40af-8d3b-aef1b8777cea"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["from sklearn.model_selection import train_test_split\n", "from matplotlib.colors import LogNorm\n", "from sklearn import mixture\n", "\n", "df_0=df[df.Class==0]    #Dataset with non-fraudulent only\n", "df_1=df[df.Class==1]    #Dataset with fraudulent only\n", "df_0=df_0[['V14', 'V17','Class']]    #Select two most correlated features for now\n", "df_1=df_1[['V14', 'V17', 'Class']]\n", "\n", "#Split non-fraudulent data in 90% for training GMM and 10% for cross-validation and testing\n", "X_train, X_test, y_train, y_test = train_test_split(df_0.drop(['Class'],axis=1), df_0['Class'] , test_size=0.1, random_state=0)\n", "#Split the fraudulent data in 50% for cross-validation and 50% for testing\n", "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_1.drop(['Class'],axis=1), df_1['Class'] , test_size=0.5, random_state=0)\n", "\n", "\n", "# Fit a Gaussian Mixture Model with the two components 'V14' and 'V17'\n", "clf = mixture.GaussianMixture()\n", "clf.fit(X_train)\n", "\n", "# display predicted scores by the model as a contour plot\n", "x = np.linspace(-18, 10)\n", "y = np.linspace(-17, 9.)\n", "X, Y = np.meshgrid(x, y)\n", "XX = np.array([X.ravel(), Y.ravel()]).T\n", "Z = -clf.score_samples(XX)\n", "Z = Z.reshape(X.shape)\n", "CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=1000.0), levels=np.logspace(0, 3, 10))\n", "CB = plt.colorbar(CS, shrink=0.8, extend='both')\n", "plt.scatter(X_train['V14'].values,X_train['V17'].values, 0.8)\n", "plt.title('Negative log-likelihood traine using GMM')\n", "plt.axis('tight')\n", "plt.show()"]}, {"metadata": {"_uuid": "2e74d65cbb4869ffb789d70acbb0f12e619f346a", "_cell_guid": "e9cae2d8-3092-4971-b475-ae7c4ea95902"}, "cell_type": "markdown", "source": ["Now that the GMM is fit, let's find the probabilities of the test set. After we find those probabilities, if the probability is below a threshold we will say it is a fraudulent transaction (that is because our GMM is based on non-fraudulent transactions). Low probability means that is not probable that a given transaction is non-fraudulent."]}, {"metadata": {"_uuid": "2364f938312331c1760479802714e98e221e8704", "_cell_guid": "0465014c-4ce8-4b79-8362-37114eb367f3"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["######### Cross-validation step to select best threshold T still to be done ####\n", "#  KFold=...\n", "#################################################################################\n", "from sklearn.metrics import average_precision_score\n", "from sklearn.metrics import precision_recall_curve\n", "y_test_proba = clf.score_samples(np.vstack([X_test, X_test_1]))\n", "plt.plot(y_test_proba)\n", "plt.title('Predicted probabilities for test dataset')"]}, {"metadata": {"_uuid": "088e4fecafa7ed003ae99a94fbefbfbc339e1874", "_cell_guid": "e6d18a71-f92a-4d1f-9d62-917b47553213"}, "cell_type": "markdown", "source": ["We can see on the plot above that there are some pics of low probability. Those are probably outliers.\n", "To make it correctly, we should find the threshold T by doing crossvalidation. \n", "Now, just to have a first impresion of how this works compared to the Logistic classifier from prevous sections, we will define a fixed threshold and evaluate the performance."]}, {"metadata": {"_uuid": "88544ce27c71553b2d605d53ead0e4537d0ab445", "_cell_guid": "9815b8e4-0e45-4c38-8546-fb5b07e85f43"}, "outputs": [], "cell_type": "code", "execution_count": null, "source": ["from sklearn.metrics import classification_report\n", "from sklearn.metrics import average_precision_score\n", "from sklearn.metrics import precision_recall_curve\n", "T=-40\n", "y_test_proba[y_test_proba>=T]=0\n", "y_test_proba[y_test_proba<T]=1\n", "\n", "y_test_orig=np.hstack([y_test, y_test_1])\n", "print('Classification report')\n", "print(classification_report(y_test_orig, y_test_proba))\n", "print('Test AUCPR = ' + str(average_precision_score(y_test_orig, y_test_proba)))\n", "\n", "\n", "\n", "precision, recall, _ = precision_recall_curve(y_test_orig, y_test_proba)\n", "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n", "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n", "plt.xlabel('Recall')\n", "plt.ylabel('Precision')\n", "plt.ylim([0.0, 1.05])\n", "plt.xlim([0.0, 1.0])\n", "plt.title('2-class Precision-Recall curve: AUC={0:0.2f}'.format( average_precision_score(y_test_orig, y_test_proba)))\n"]}, {"metadata": {"_uuid": "d9e66df5fc1522add1c09c40bb72c278cd9b3eae", "_cell_guid": "cb4961ca-1441-4481-a4dd-9731645bf87d"}, "cell_type": "markdown", "source": ["Note that we have gone from an AUCPR of 0.47 using Logistic classifier to an AUCPR of 0.67.\n", "This will probably be improved more if we optimize the threshold T using cross-validation\n", "and we use more features, not just 'V14' and 'V17'.\n", "I will do this in soon... Keep "]}], "nbformat_minor": 1}