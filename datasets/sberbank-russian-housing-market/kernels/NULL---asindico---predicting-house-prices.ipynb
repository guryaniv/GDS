{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0ac88558-a464-8201-9bb4-47ed9783a636"
      },
      "source": [
        "## Preditcting House Prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "919f3c60-364f-aff9-9324-ed5a5723bc0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import model_selection, preprocessing\n",
        "\n",
        "train_df = pd.read_csv(\"../input/train.csv\")\n",
        "macro = pd.read_csv(\"../input/macro.csv\")\n",
        "\n",
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14f60c00-ad6e-4b4b-a8bc-702908441bea"
      },
      "outputs": [],
      "source": [
        "def _revrt(X,m=None):\n",
        "    \"\"\"\n",
        "    Inverse of forrt. Equivalent to Munro (1976) REVRT routine.\n",
        "    \"\"\"\n",
        "    if m is None:\n",
        "        m = len(X)\n",
        "    i = int(m // 2+1)\n",
        "    y = X[:i] + np.r_[0,X[i:],0]*1j\n",
        "    return np.fft.irfft(y)*m\n",
        "\n",
        "from statsmodels.nonparametric import kdetools\n",
        "\n",
        "# replace the implementation with new method.\n",
        "kdetools.revrt = _revrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1bbaa32-9521-ff5f-a984-a0d574d596b9"
      },
      "outputs": [],
      "source": [
        "train_df['price_doc'].describe()\n",
        "prices  =train_df['price_doc']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b9626ea-62dc-12a4-a8e1-fb62424b6826"
      },
      "outputs": [],
      "source": [
        "f,axarray = plt.subplots(1,2)\n",
        "f.set_size_inches(13,10)\n",
        "axarray[0].set_title(\"price\")\n",
        "sns.distplot(train_df.price_doc.values, bins=50, kde=False,ax =axarray[0] )\n",
        "lprices = np.log(prices)\n",
        "axarray[1].set_title(\"price log\")\n",
        "sns.distplot(lprices, bins=50, kde=False,ax = axarray[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a986fec0-4cce-5c51-7298-e645446768f1"
      },
      "source": [
        "full_sq: total area in square meters, including loggias, balconies and other non-residential areas\n",
        "\n",
        "life_sq: living area in square meters, excluding loggias, balconies and other non-residential areas\n",
        "\n",
        "floor: for apartments, floor of the building\n",
        "\n",
        "max_floor: number of floors in the building\n",
        "\n",
        "material: wall material\n",
        "\n",
        "build_year: year built\n",
        "\n",
        "num_room: number of living rooms\n",
        "\n",
        "kitch_sq: kitchen area\n",
        "\n",
        "state: apartment condition\n",
        "\n",
        "product_type: owner-occupier purchase or investment\n",
        "\n",
        "sub_area: name of the district"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "82dcc12a-c55a-2643-f6c6-3eec6da0c793"
      },
      "source": [
        "### Number of Rooms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ba4a6d68-b24e-1eb4-debc-cacf109f4ba9"
      },
      "source": [
        "We have only 68% of values for the number of rooms. In order to get reasonable values for the missing data we can exploit the full_sq field information.\n",
        "\n",
        "full_sq is defined as the total area in square meters, including loggias, balconies and other non-residential areas. We have such information for the whole dataset.\n",
        "\n",
        "The Idea is that the number of rooms is directly related to the total are in square meters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6b8228c7-650c-2afa-ffc5-b9733bb60094"
      },
      "outputs": [],
      "source": [
        "print (len(train_df[train_df['num_room']>0])/float(len(train_df)))\n",
        "print (train_df[train_df['num_room']>0]['num_room'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f868b499-b7c0-1d50-1887-c6faef96e8a3"
      },
      "source": [
        "such relationship is confirmed  by the following correlation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "35412d97-b740-c227-6591-f6af61c517c3"
      },
      "outputs": [],
      "source": [
        "nrsq = train_df[train_df['num_room']>0][['full_sq','num_room']]\n",
        "nrsq.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9d7115f3-f46f-79be-9032-997d5fb80e1b"
      },
      "outputs": [],
      "source": [
        "f,axarray = plt.subplots(1,2)\n",
        "f.set_size_inches(13,8)\n",
        "sns.distplot(train_df['full_sq'], bins=50, kde=False,ax =axarray[0])\n",
        "lsq = np.log(train_df['full_sq']+0.0001)\n",
        "train_df['full_sq']=lsq\n",
        "sns.distplot(lsq, bins=50, kde=False,ax=axarray[1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c6eaa720-1454-4432-d262-a19d09aff11c"
      },
      "source": [
        "Since we have full_sq for all data we can use it to predict the missing number of rooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49bfa68f-251b-1372-87ab-8b946320b1d9"
      },
      "outputs": [],
      "source": [
        "print (len(train_df[train_df['full_sq']>=0])/float(len(train_df)))\n",
        "print (train_df[train_df['full_sq']>=0]['full_sq'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aadeaac2-dea7-6902-77b4-e5a4a7df68d6"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "nr = train_df[train_df['num_room']>0]['full_sq']\n",
        "nrp = train_df[train_df['num_room']>0]['num_room']\n",
        "X_train, X_test, y_train, y_test = train_test_split(nr, nrp, test_size=0.3, random_state=42)\n",
        "\n",
        "room_pred = DecisionTreeRegressor()\n",
        "room_pred.fit(X_train[:, None],y_train)\n",
        "pred = room_pred.predict(X_test[:, None])\n",
        "print (r2_score(y_test.astype(int),pred.astype(int)))\n",
        "\n",
        "fsqnr = np.array(train_df[['full_sq','num_room']])\n",
        "nr = [int(np.round(room_pred.predict(np.array([el[0]]).reshape(1, -1)))) if math.isnan(el[1]) else el[1] for el in fsqnr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6a3afc2-6bc8-6a4f-f3e1-28dd23473e13"
      },
      "outputs": [],
      "source": [
        "train_df['num_room'] = nr\n",
        "nf = pd.DataFrame(pd.Series(nr),columns=[\"num_room\"])\n",
        "nf = pd.concat([nf,pd.DataFrame(train_df['full_sq'],columns=[\"full_sq\"])],axis=1)\n",
        "nf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb238611-7e8d-fb7f-9cb5-f71a3bcc6a62"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.concat([nf,prices],axis=1),size = 3.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1cc8177a-facd-220f-89a0-bd399f969343"
      },
      "source": [
        "### Floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0fb23fc-87e3-74cf-5d75-d6ef918896ba"
      },
      "outputs": [],
      "source": [
        "print (len(train_df[train_df['floor']>=-10])/float(len(train_df)))\n",
        "print (train_df[train_df['floor']>=-10]['floor'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1a513761-1412-cb41-00f7-79e9074ae0ed"
      },
      "outputs": [],
      "source": [
        "fl = [5 if math.isnan(fl) else fl for fl in train_df['floor']]\n",
        "train_df['floor']=fl\n",
        "print (len(train_df[train_df['floor']>=0])/float(len(train_df)))\n",
        "nf = pd.concat([nf,pd.DataFrame(fl,columns=[\"floor\"])],axis=1)\n",
        "nf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88160ebb-2709-feb3-b0fc-aad6c94d254f"
      },
      "outputs": [],
      "source": [
        "f,axarray = plt.subplots(1,2)\n",
        "f.set_size_inches(13,8)\n",
        "sns.distplot(train_df['floor'], bins=50, kde=False,ax=axarray[0])\n",
        "plt.xlabel('floor', fontsize=12)\n",
        "\n",
        "train_df['floor'] = np.log(train_df['floor']+0.1)\n",
        "nf['floor'] = train_df['floor']\n",
        "sns.distplot(train_df['floor'], bins=50, kde=False,ax= axarray[1])\n",
        "plt.xlabel('floor log', fontsize=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ee54e2fc-cf8f-847e-4505-82aca6876a5e"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.concat([nf,prices],axis=1),size = 2.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41f103cc-a7b2-f579-f17f-d8c80d7d0a79"
      },
      "source": [
        "### Max Floor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2a84822a-722e-d831-aa97-56c21245e591"
      },
      "outputs": [],
      "source": [
        "print (len(train_df[train_df['max_floor']>=0])/float(len(train_df)))\n",
        "print (train_df[train_df['max_floor']>=0]['max_floor'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80664c9a-48b7-5bac-041d-68d87671c116"
      },
      "outputs": [],
      "source": [
        "maxff = train_df[train_df['max_floor']>=0][['floor','max_floor']]\n",
        "maxff.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "743ef736-7c4e-6717-6ba3-67e320304437"
      },
      "outputs": [],
      "source": [
        "fl = train_df[train_df['max_floor']>=0]['floor']\n",
        "mf = train_df[train_df['max_floor']>=0]['max_floor']\n",
        "X_train, X_test, y_train, y_test = train_test_split(fl, mf, test_size=0.3, random_state=42)\n",
        "\n",
        "max_floor_pred= DecisionTreeRegressor()\n",
        "max_floor_pred.fit(X_train[:, None],y_train)\n",
        "pred = max_floor_pred.predict(X_test[:, None])\n",
        "print (r2_score(y_test,pred))\n",
        "\n",
        "flmf = np.array(train_df[['floor','max_floor']])\n",
        "mf = [int(np.round(max_floor_pred.predict(np.array([el[0]]).reshape(1, -1)))) if math.isnan(el[1]) else el[1] for el in flmf]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8feb5662-885b-984a-df8a-013b7d3f47d9"
      },
      "outputs": [],
      "source": [
        "nf = pd.concat([nf,pd.DataFrame(mf,columns=[\"max_floor\"])],axis=1)\n",
        "nf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "38d68367-4fdc-0d04-1730-da0882062acb"
      },
      "outputs": [],
      "source": [
        "tf = nf[['full_sq','floor','max_floor']]\n",
        "sns.pairplot(pd.concat([tf,prices],axis=1),size = 2.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a995d410-0c3a-d652-dd7f-f4fd3127d8e5"
      },
      "source": [
        "### Life SQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b05564be-9dfa-55c8-8bc9-d93393349371"
      },
      "outputs": [],
      "source": [
        "print (len(train_df[train_df['life_sq']>=0])/float(len(train_df)))\n",
        "print (train_df[train_df['life_sq']>=0]['life_sq'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "261aff69-2d72-c19a-8b2c-843c831d2473"
      },
      "outputs": [],
      "source": [
        "maxff = train_df[train_df['num_room']>=0][['life_sq','num_room']]\n",
        "maxff.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d68969f7-a7ba-913a-7417-25f9b546e939"
      },
      "outputs": [],
      "source": [
        "nr = train_df[(train_df.num_room>=0) & (train_df.life_sq>=0)]['num_room']\n",
        "ls = train_df[(train_df.num_room>=0) & (train_df.life_sq>=0)]['life_sq']\n",
        "X_train, X_test, y_train, y_test = train_test_split(nr, ls, test_size=0.3, random_state=42)\n",
        "\n",
        "life_sq_pred= DecisionTreeRegressor()\n",
        "life_sq_pred.fit(X_train[:, None],y_train)\n",
        "pred = life_sq_pred.predict(X_test[:, None])\n",
        "print (r2_score(y_test,pred))\n",
        "\n",
        "nrls = np.array(train_df[['num_room','life_sq']])\n",
        "lsq = [int(np.round(life_sq_pred.predict(np.array(   [el[0]]   ).reshape(1, -1)))) if math.isnan(el[1]) else el[1] for el in nrls]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27b230e1-a652-6654-e1af-d9bc47319fbc"
      },
      "outputs": [],
      "source": [
        "nf = pd.concat([nf,pd.DataFrame(lsq,columns=[\"life_sq\"])],axis=1)\n",
        "lsq = np.log(nf['life_sq']+0.0001)\n",
        "nf['life_sq'] = lsq\n",
        "nf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "07dd7173-db70-4a49-2867-f42fff661441"
      },
      "source": [
        "### Sub Area and Product Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de5d4a09-6a20-baa8-4bfb-7e31f5097bc7"
      },
      "outputs": [],
      "source": [
        "\n",
        "psm = train_df['price_doc']/(train_df['full_sq']+1).astype(float)\n",
        "psm = psm / np.max(psm)\n",
        "train_df['psm'] = psm\n",
        "\n",
        "sa = train_df['sub_area']\n",
        "sap = train_df[['sub_area','psm']]\n",
        "\n",
        "area_psm =  sap.groupby('sub_area').mean()\n",
        "\n",
        "print (pd.DataFrame(area_psm['psm']).head())\n",
        "nf['sap'] = train_df['sub_area'].apply(lambda x: area_psm['psm'][x])\n",
        "print (nf['sap'].isnull().sum())\n",
        "\n",
        "sa = pd.Series(sa)\n",
        "#print sa.unique()\n",
        "sad = pd.get_dummies(sa)\n",
        "sad.shape\n",
        "\n",
        "pt = train_df['product_type']\n",
        "pt = pd.Series(pt)\n",
        "ptd = pd.get_dummies(pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "720adc52-ee54-421b-0abf-99584bb40c58"
      },
      "source": [
        "### Time Stamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3381566-b5fb-d9c5-a551-7d17b7b3dd69"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "years = [int(re.split(r'^([0-9]*)-',ts)[1]) for ts in train_df['timestamp']]\n",
        "years = pd.Series(years).astype(int)\n",
        "print (years.value_counts())\n",
        "print (years.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65a19581-e5b8-d32f-cf16-39533ddb9a9a"
      },
      "outputs": [],
      "source": [
        "yp = pd.concat([years,prices],axis=1)\n",
        "yp.columns = ['years','prices']\n",
        "grouped = yp.groupby('years')\n",
        "grouped.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "286acda9-4750-adae-f667-7f9c6b673a81"
      },
      "outputs": [],
      "source": [
        "nf = pd.concat([nf,pd.get_dummies(years)],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f9a01bcb-641f-2523-5f4d-a1234c30211e"
      },
      "outputs": [],
      "source": [
        "nf = pd.concat([nf,pd.DataFrame(train_df['timestamp'])],axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "63018d84-5b6c-8242-86b7-1681bf3bc715"
      },
      "source": [
        "### Transportation PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18abac96-f79c-ae4a-b36f-ecd2d935f189"
      },
      "outputs": [],
      "source": [
        "tpt = train_df.filter(regex='^(?=.*metro)(?!.*ID_).*|^(?=.*road)(?!.*ID_).*')\n",
        "tpt = tpt.select_dtypes(include=['number'])\n",
        "tpt = np.log(tpt)\n",
        "from sklearn.decomposition import PCA\n",
        "tf = tpt\n",
        "print (tf.head())\n",
        "tf = tf.select_dtypes(include=['number']).dropna(axis=1, how='any')\n",
        "tf[np.isinf(tf)] = 0\n",
        "#print(np.isnan(tf).sum())\n",
        "print(np.isinf(tf).sum())\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(tf)\n",
        "reduced_data = pca.transform(tf)\n",
        "tpt_reduced_data = pd.DataFrame(reduced_data,columns=['tpt_pca1','tpt_pca2','tpt_pca3'])\n",
        "print (np.isnan(tpt_reduced_data).sum())\n",
        "tmp = pd.concat([tpt_reduced_data,prices],axis=1)\n",
        "print (tmp.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1fa930c5-c5ff-5a14-9808-b3bbd661c8a0"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.concat([tpt_reduced_data,prices],axis=1),size = 2.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "60001d51-8c7e-5fd3-ef09-fec2e34d405f"
      },
      "source": [
        "### School PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5709d9f-fd68-f153-40cf-5a44173719e5"
      },
      "outputs": [],
      "source": [
        "tpt = train_df.filter(regex='^(?=.*school)(?!.*ID_).*')\n",
        "tpt = tpt.select_dtypes(include=['number'])\n",
        "#tpt = np.log(tpt)\n",
        "tpt = tpt.drop('preschool_quota',axis=1)\n",
        "from sklearn.decomposition import PCA\n",
        "tf = tpt\n",
        "print (tf.head())\n",
        "tf = tf.select_dtypes(include=['number']).dropna(axis=1, how='any')\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(tf)\n",
        "reduced_data = pca.transform(tf)\n",
        "sch_reduced_data = pd.DataFrame(reduced_data,columns=['sch_pca1','sch_pca2','sch_pca3'])\n",
        "tmp = pd.concat([sch_reduced_data,prices],axis=1)\n",
        "print (tmp.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a44ce838-cad8-4042-c3e5-a91093aca4f5"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.concat([sch_reduced_data,prices],axis=1),size = 2.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e96e43a6-3b06-9ced-1c46-74ee85595fe4"
      },
      "source": [
        "### Green"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02963f48-f8ae-45f2-b19e-07a07236fc7e"
      },
      "outputs": [],
      "source": [
        "tpt = train_df.filter(regex='^(?=.*green)(?!.*ID_).*')\n",
        "tpt = tpt.select_dtypes(include=['number'])\n",
        "from sklearn.decomposition import PCA\n",
        "tf = tpt\n",
        "print (tf.head())\n",
        "tf = tf.select_dtypes(include=['number']).dropna(axis=1, how='any')\n",
        "tf[np.isinf(tf)] = 0\n",
        "pca = PCA(n_components=3)\n",
        "pca.fit(tf)\n",
        "reduced_data = pca.transform(tf)\n",
        "green_reduced_data = pd.DataFrame(reduced_data,columns=['gr_pca1','gr_pca2','gr_pca3'])\n",
        "tmp = pd.concat([tpt_reduced_data,prices],axis=1)\n",
        "print (tmp.corr())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a021849e-25fe-d262-fc8a-0ec110b01531"
      },
      "outputs": [],
      "source": [
        "nnf = pd.concat([nf,ptd],axis=1)\n",
        "nnf = pd.concat([nnf,tpt_reduced_data],axis=1)\n",
        "nnf = pd.concat([nnf,sch_reduced_data],axis=1)\n",
        "nnf = pd.concat([nnf,green_reduced_data],axis=1)\n",
        "nnf = pd.concat([nnf,train_df['raion_popul']],axis=1)\n",
        "nnf = nnf.drop('timestamp',axis=1)\n",
        "nnf['num_room'] = nnf['num_room'].astype('int')\n",
        "nnf['floor'] = nnf['floor'].astype('int')\n",
        "nnf['max_floor'] = nnf['max_floor'].astype('int')\n",
        "nnf['full_sq']=nf['full_sq']/np.max(nf['full_sq'])\n",
        "nnf['life_sq']=nf['full_sq']/np.max(nf['life_sq'])\n",
        "nnf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22fbe7c2-84ee-1da2-ed39-87ebe404a6ba"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6401c1fd-6c9a-ce85-fb09-7cc4f962901b"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(nnf,prices,test_size=0.2,random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8817f812-4ef2-fdbc-e6a4-1c2aa9491d6d"
      },
      "source": [
        "## Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "782822b5-3f7a-12fb-b647-3586370a1de1"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def rmsle(a,p):\n",
        "    tm =0\n",
        "    for idx,el in enumerate(a):\n",
        "        tm = tm+(math.log(p[idx]+1)-math.log(el+1))**2\n",
        "    tm = tm /len(a)\n",
        "    return math.sqrt(tm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b86e34b-6e3f-0b3b-aefb-9329cde65606"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def performance_metric(y_true, y_predict):\n",
        "    score = r2_score(y_true,y_predict)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "613803de-d497-6ff9-20f7-c0da43a11388"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn import grid_search\n",
        "from sklearn.cross_validation import ShuffleSplit\n",
        "\n",
        "def fit_model(X, y):\n",
        "    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n",
        "    params = {'max_depth': (1,20),'n_estimators':(1,50)}\n",
        "    scoring_fnc = make_scorer(score_func= performance_metric)\n",
        "    regressor = RandomForestRegressor()\n",
        "    grid =  grid_search.GridSearchCV(regressor,params,cv=cv_sets,scoring = scoring_fnc);\n",
        "    grid = grid.fit(X, y)\n",
        "    return grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a50bf50-f54b-ede3-cd09-514777579847"
      },
      "outputs": [],
      "source": [
        "#model =  regressor = linear_model.LinearRegression().fit(X_train,y_train)\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#model = Pipeline([(\"scale\", preprocessing.StandardScaler()),\n",
        "#               (\"rf\", RandomForestRegressor(n_estimators=100, n_jobs=-1, verbose=2))])\n",
        "#model.fit(X_train,y_train)\n",
        "model = fit_model(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51fe0290-467c-e7c7-ddc3-69f620c8deb5"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "#pred = pred - pred*0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1878ec58-2288-6409-26e2-4410476cb8d9"
      },
      "outputs": [],
      "source": [
        "print (model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a8635e7c-89f0-17df-a21d-471c18a1fee0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#e_y_test = np.exp(y_test)\n",
        "#e_pred = np.exp(pred)\n",
        "print (rmsle(y_test,pred))\n",
        "#print math.sqrt(mean_squared_error(y_test,pred))\n",
        "#print prices.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7cc793c3-d05c-fc20-f85a-db99a16780dc"
      },
      "source": [
        "### Features Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "450653a7-1a03-2fd1-2f8a-9fc244d45a39"
      },
      "outputs": [],
      "source": [
        "importances = model.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(nnf.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c19adc6d-fa9b-1278-7ce9-341503b5afc9"
      },
      "outputs": [],
      "source": [
        "nnf.columns[indices-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4efd1522-41fd-ba02-9f82-fba958f07d94"
      },
      "outputs": [],
      "source": [
        "topf = nnf.columns[indices-1][0:10]\n",
        "top_df = nnf[topf]\n",
        "top_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2f0be8f-ddfa-6a0a-fce0-534da34610d7"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(top_df,prices,test_size=0.2,random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16a27d6c-7651-cbbd-744c-545306c8371a"
      },
      "outputs": [],
      "source": [
        "model = fit_model(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c980bc0-e5c9-b138-c8c8-cfc3b221c485"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(X_test)\n",
        "print (rmsle(y_test,pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90853266-3690-d3f9-1f56-acc380455900"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}