{"cells":[{"metadata":{"_uuid":"fe34081443335d414429896725f74ab9de8f2a50"},"cell_type":"raw","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n#Seed the notebool\nimport random\nrandom.seed(113)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv',nrows =2000000 )\ntest_set = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ec286da58aa8a3d7ec39891674e3baeb137ccb8"},"cell_type":"code","source":"df = df.round(2)\ndf = df.reindex(np.random.permutation(df.index))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc641b202957c98b8c9afe20f9d14dcf79c43711","collapsed":true},"cell_type":"code","source":"def distance(lat1, lon1, lat2, lon2):\n    distance = np.abs(lat2 - lat1) + np.abs(lon2 - lon1)\n    return distance\n'''    p = 0.017453292519943295 # Pi/180\n    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n    return 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...'''\n#features from basic linear model kernel\ndef add_travel_vector_features(df):\n    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n    \n\njfk=(-73.7900, 40.6437)\nlgr=(-73.8733, 40.7746)\newr=(-74.1843, 40.6924)\n\n# add new column to dataframe with distance in km\ndf['distance_km'] = distance(df.pickup_latitude, df.pickup_longitude, \\\n                                   df.dropoff_latitude, df.dropoff_longitude)\n\ntest_set['distance_km'] = distance(test_set.pickup_latitude, test_set.pickup_longitude, \\\n                                   test_set.dropoff_latitude, test_set.dropoff_longitude)\n#JFK\n# add new column to dataframe with distance in km\ndf['jfkpickup_distance_km'] = distance(df.pickup_latitude, df.pickup_longitude, \\\n                                   jfk[1], jfk[0])\n\ntest_set['jfkpickup_distance_km'] = distance(test_set.pickup_latitude, test_set.pickup_longitude, \\\n                                   jfk[1], jfk[0])\n\n#La Guardia\n# add new column to dataframe with distance in km\ndf['lgrpickup_distance_km'] = distance(df.pickup_latitude, df.pickup_longitude, \\\n                                   lgr[1], lgr[0])\n\ntest_set['lgrpickup_distance_km'] = distance(test_set.pickup_latitude, test_set.pickup_longitude, \\\n                                   lgr[1], lgr[0])\n\n#La Guardia\n# add new column to dataframe with distance in km\ndf['ewrpickup_distance_km'] = distance(df.pickup_latitude, df.pickup_longitude, \\\n                                   ewr[1], ewr[0])\n\ntest_set['ewrpickup_distance_km'] = distance(test_set.pickup_latitude, test_set.pickup_longitude, \\\n                                   ewr[1], ewr[0])\n#DRop off distance\n# add new column to dataframe with distance in km\ndf['jfkdropoff_distance_km'] = distance(df.dropoff_latitude, df.dropoff_longitude, \\\n                                   jfk[1], jfk[0])\n\ntest_set['jfkdropoff_distance_km'] = distance(test_set.dropoff_latitude, test_set.dropoff_longitude, \\\n                                   jfk[1], jfk[0])\n\n#DRop off distance\n# add new column to dataframe with distance in km\ndf['lgrdropoff_distance_km'] = distance(df.dropoff_latitude, df.dropoff_longitude, \\\n                                   lgr[1], lgr[0])\n\ntest_set['lgrdropoff_distance_km'] = distance(test_set.dropoff_latitude, test_set.dropoff_longitude, \\\n                                   lgr[1], lgr[0])\n\n#DRop off distance\n# add new column to dataframe with distance in km\ndf['ewrdropoff_distance_km'] = distance(df.dropoff_latitude, df.dropoff_longitude, \\\n                                   ewr[1], ewr[0])\n\ntest_set['ewrdropoff_distance_km'] = distance(test_set.dropoff_latitude, test_set.dropoff_longitude, \\\n                                   ewr[1], ewr[0])\nadd_travel_vector_features(df)\nadd_travel_vector_features(test_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b3316fd09be3d67ad8fd57df543d60622798f25","scrolled":true,"collapsed":true},"cell_type":"code","source":"BB = (-75, -73, 40, 41.5)\n\n# this function will be used with the test set below\ndef select_within_boundingbox(df, BB):\n    return (df.pickup_longitude >= BB[0]) & (df.pickup_longitude <= BB[1]) & \\\n           (df.pickup_latitude >= BB[2]) & (df.pickup_latitude <= BB[3]) & \\\n           (df.dropoff_longitude >= BB[0]) & (df.dropoff_longitude <= BB[1]) & \\\n           (df.dropoff_latitude >= BB[2]) & (df.dropoff_latitude <= BB[3])\n           \n\nprint('Old size: %d' % len(df))\ndf = df[select_within_boundingbox(df, BB)]\ndf = df[(df.passenger_count > 0) & (df.passenger_count <= 8)]\ndf = df[(df.fare_amount>0) & (df.fare_amount<=250)]\n#test_set = test_set[select_within_boundingbox(test_set, BB)]\nprint('New size: %d' % len(df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a157d94c5ceb88365f94e6390d71134a231b1154","collapsed":true},"cell_type":"code","source":"def add_datetime_info(dataset):\n    #Convert to datetime format\n    dataset['pickup_datetime'] = pd.to_datetime(dataset['pickup_datetime'])\n    \n    dataset['hour'] = dataset.pickup_datetime.dt.hour\n    dataset['day'] = dataset.pickup_datetime.dt.day\n    dataset['month'] = dataset.pickup_datetime.dt.month\n    dataset['weekday'] = dataset.pickup_datetime.dt.weekday\n    dataset['year'] = dataset.pickup_datetime.dt.year\n    \n    return dataset\n\ndf = add_datetime_info(df)\ntest_set = add_datetime_info(test_set)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd3a9835ac39bf1e16427feb4826aab413bb5ac","collapsed":true},"cell_type":"code","source":"df['year'].hist()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c64b9bc74fd05e9ec73ba3933551238ca84e3a78","collapsed":true},"cell_type":"code","source":"test_set['year'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03dcc12972481c35e74369508f35f00e96fa3b01","collapsed":true},"cell_type":"code","source":"airport_long = [-73.79,-73.87,-74.18]\nairport_lat = [40.64,40.77,40.69]\nprint(df['dropoff_longitude'].describe())\n'''jfk=(-73.79, 40.64)\nlgr=(-73.87, 40.77)\newr=(-74.18, 40.69)\nairportList=[jfk,lgr,ewr]\ndef checkAirport(df):\n    val = 0\n    if (df['dropoff_longitude'] in airport_long) and (df['dropoff_latitude'] in airport_lat):\n        val= 1\n    else:\n        val = 0\n    return val\ndf['is_airport'] = df.apply(checkAirport,axis=1) \ndf['is_airport'].value_counts()  '''        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"24887cca2517a5fc2b0b8cc9712d550bf9361b80"},"cell_type":"code","source":"#df['is_night'] = np.where((((df['hour']>=20) & (df['hour']<=23)) | ((df['hour']>=0) & (df['hour']<6))),1,0) \n#df['is_airport'] = np.where((((df['dropoff_longitude']>=73.77) & (df['dropoff_longitude']<=73.78)) | ((df['dropoff_latitude']>=40.63) & (df['dropoff_latitude']<=40.64))),1,0) \n#df['is_surge']= np.where((((df['hour']>=16) & (df['hour']<20)) & ((df['weekday']!=5) & (df['weekday']!=6))),1,0)\n#df['is_BeforeRaise']= np.where(((df['year']>=2012) & (df['month']>=8)),0,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"965d8a2bd0b2fdf7526c136266b82ab436d07e38","scrolled":true,"collapsed":true},"cell_type":"code","source":"cor_frame = df.corr()\ncor_frame.sort_values('fare_amount',axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc0d3b7041ce76a09dd2f0396b238109898d2a2e","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain = df.drop(['key','fare_amount','pickup_datetime'],axis=1)#'hour','day','month','weekday','lgrpickup_distance_km',\ntest = df['fare_amount']\nX_train, X_test, y_train, y_test = train_test_split(train, test, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e12f28224f78900779cbcb8448f25056332f08e2","scrolled":true,"collapsed":true},"cell_type":"code","source":"'''from sklearn import preprocessing\nscaler = preprocessing.StandardScaler().fit(X_train)\nX_train_transformed = scaler.transform(X_train)\nX_test_transformed = scaler.transform(X_test)'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"656bb25c00752c899289184784dcb3eefbd581b8","scrolled":true,"collapsed":true},"cell_type":"code","source":"'''from xgboost import XGBRegressor\nregressor = XGBRegressor(max_depth =40, learning_rate=0.20, n_estimators=200,early_stopping_rounds=20)\nregressor.fit(X_train, y_train)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"bf14c42a8f5a747197934ddb575e1ea531845551","collapsed":true},"cell_type":"code","source":"import xgboost as xgb\nfrom bayes_opt import BayesianOptimization\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test)\nparams = {'eval_metric': 'rmse',\n              'max_depth': 30,\n              'subsample': 0.8,\n              'eta': 0.1,\n              'gamma': 1,\n              'colsample_bytree': 1}\ndef xgb_evaluate(max_depth, gamma, colsample_bytree):\n    \n    # Used around 1000 boosting rounds in the full model\n    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n    \n    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]\n'''xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 7), \n                                             'gamma': (0, 1),\n                                             'colsample_bytree': (0.3, 0.9)})\n# Use the expected improvement acquisition function to handle negative numbers\n# Optimally needs quite a few more initiation points and number of iterations\nxgb_bo.maximize(init_points=3, n_iter=5, acq='ei')\n\nparams = xgb_bo.res['max']['max_params']\nparams['max_depth'] = int(params['max_depth'])'''\n# Train a new model with the best parameters from the search\nmodel2 = xgb.train(params, dtrain, num_boost_round=200)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6d2bce3c67fef3b1effe128638beb45e8bb092d","collapsed":true},"cell_type":"code","source":"import pickle \n#pickle.dump(regressor, open(\"xgbregressor\", 'wb'))\n \n# some time later...\n \n# load the model from disk\n#regressor = pickle.load(open(\"xgbregressor\", 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36abb33dee9e42f66f7eb763d3b88c7f15eaede8","collapsed":true},"cell_type":"code","source":"predictions = model2.predict(dtest)\npredictions_train = model2.predict(dtrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d9d20f9f34c705ce1f880e1e33b5cc1c575b22d","scrolled":false,"collapsed":true},"cell_type":"code","source":"import math\nfrom sklearn.metrics import mean_squared_error\n\nrmse = math.sqrt(mean_squared_error(y_test,predictions))\nrmse_train = math.sqrt(mean_squared_error(y_train,predictions_train))\n\nprint(rmse)\nprint(rmse_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e79baac4fdb962115f65fff4b894af3243d7fb","collapsed":true},"cell_type":"code","source":"'''from keras import Sequential\nfrom keras import layers\nfrom keras.layers import Dense,Dropout\nfrom keras.callbacks import ModelCheckpoint,  ReduceLROnPlateau\nfrom keras import optimizers\nfrom keras.regularizers import l2\n\nneuralNetwork = Sequential()\nneuralNetwork.add(Dense(units=2056,input_shape=(14,),activation='relu',kernel_regularizer = l2(1e-2)))\nneuralNetwork.add(Dropout(0.5))\nneuralNetwork.add(Dense(units=10,activation='relu',kernel_regularizer = l2(1e-2)))\nneuralNetwork.add(Dropout(0.5))\nneuralNetwork.add(Dense(units=1,activation='relu',kernel_regularizer = l2(1e-2)))\n\nneuralNetwork.compile(optimizer='Adam', \n           loss='mean_squared_error')\n\nfilepath = './model_weights/weights-improvement-10M.hdf5'\nbest_callback = ModelCheckpoint(filepath, \n                                save_best_only=True)\n\n#lr_sched = ReduceLROnPlateau(monitor='loss', factor = 0.2, patience = 10, verbose = 1)\n\nhistory = neuralNetwork.fit(X_train1, y_train, \n          epochs=20,\n          verbose=0,\n          batch_size=2048)\n\ny_pred = neuralNetwork.predict(X_test1)\nrmse = math.sqrt(mean_squared_error(y_test,y_pred))\n\nprint(rmse)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08786dace2a4d66b44e50bfa315046383a7223a4","scrolled":false,"collapsed":true},"cell_type":"code","source":"\n#test_set['is_night'] = np.where((((test_set['hour']>=20) & (test_set['hour']<=23)) | ((test_set['hour']>=0) & (test_set['hour']<6))),1,0) \n#test_set['is_airport'] = np.where((((test_set['dropoff_longitude']>=73.77) & (test_set['dropoff_longitude']<=73.78)) | ((test_set['dropoff_latitude']>=40.63) & (test_set['dropoff_latitude']<=40.64))),1,0) \n#test_set['is_surge']= np.where((((test_set['hour']>=16) & (test_set['hour']<20)) & ((test_set['weekday']!=5) & (test_set['weekday']!=6))),1,0)\n#test_set['is_BeforeRaise']= np.where(((test_set['year']>=2012) & (test_set['month']>=8)),1,0)\n\ntest_set_features = test_set.drop(['key','pickup_datetime'],axis=1)#'hour','day','month','weekday','lgrpickup_distance_km',\n\ntest_set_key = test_set['key']\ndtest_1 = xgb.DMatrix(test_set_features)\n\ny_pred_reg = model2.predict(dtest_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd0325d4a7472beb076cac9a76cf76d9fd919623","collapsed":true},"cell_type":"code","source":"'''test_set_features = test_set_features.drop(['year'],axis=1)#'abs_diff_longitude', 'abs_diff_latitude',\ny_pred_neuralNet = neuralNetwork.predict(test_set_features)\ny_pred_neuralNet = y_pred_neuralNet.reshape(9914,)\ny_pred_final = (y_pred_reg+y_pred_neuralNet)/2'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a47a9a3c5b81d123610c61c8fa550c28915f604","scrolled":true,"collapsed":true},"cell_type":"code","source":"#Putting everything together in a .csv file\nsubmission = pd.DataFrame(\n    {'key': test_set_key, 'fare_amount': y_pred_reg},\n    columns = ['key', 'fare_amount'])\nsubmission = submission.round({'fare_amount':2})\nsubmission.to_csv('submission_combo.csv', index = False)\nprint(submission.head())\nprint(\"Submitted\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e201ae5cb78d14dbe7ad568db08b5809185b13","scrolled":false,"collapsed":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2cc1a159d0d7515cf98f21319446deeb2dd0f13d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}