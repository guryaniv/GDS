{"cells":[{"metadata":{"_uuid":"2c17cbe4291aa59af66132221cfb9c644c5d2878"},"cell_type":"markdown","source":"# Human Protein Atlas Image Classification\nReference:  \n- https://www.kaggle.com/allunia/protein-atlas-exploration-and-baseline\n- https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n- https://www.kaggle.com/allunia/uncover-target-correlations-with-bernoulli-mixture"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport os\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\n\nsns.set()\n\nmatplotlib.style.use('fivethirtyeight')\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9637d5b6ba50e86161d45517411c064fb7ef4a87"},"cell_type":"code","source":"## data analysis","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path = \"../input\"\nmetadata='train.csv'\nimage_train_path = os.path.join(path, 'train')\nimage_test_path = os.path.join(path, 'test')\n\ntrain_data = pd.read_csv( os.path.join( path, metadata) )\n\nprint(train_data.head())\nprint('Total: ', len(train_data))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10f337a9dde2ddd490ef467f0a5cd08c54507f9c"},"cell_type":"code","source":"idx_to_class = {\n    0:  \"Nucleoplasm\",  \n    1:  \"Nuclear membrane\",   \n    2:  \"Nucleoli\",   \n    3:  \"Nucleoli fibrillar center\",   \n    4:  \"Nuclear speckles\",\n    5:  \"Nuclear bodies\",   \n    6:  \"Endoplasmic reticulum\",   \n    7:  \"Golgi apparatus\",   \n    8:  \"Peroxisomes\",   \n    9:  \"Endosomes\",   \n    10:  \"Lysosomes\",   \n    11:  \"Intermediate filaments\",   \n    12:  \"Actin filaments\",   \n    13:  \"Focal adhesion sites\",   \n    14:  \"Microtubules\",   \n    15:  \"Microtubule ends\",   \n    16:  \"Cytokinetic bridge\",   \n    17:  \"Mitotic spindle\",   \n    18:  \"Microtubule organizing center\",   \n    19:  \"Centrosome\",   \n    20:  \"Lipid droplets\",   \n    21:  \"Plasma membrane\",   \n    22:  \"Cell junctions\",   \n    23:  \"Mitochondria\",   \n    24:  \"Aggresome\",   \n    25:  \"Cytosol\",   \n    26:  \"Cytoplasmic bodies\",   \n    27:  \"Rods & rings\"\n}\n\nclass_to_idx = dict((v,k) for k,v in idx_to_class.items())\n\ndef fill_targets(row):\n    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n    for num in row.Target:\n        name = idx_to_class[int(num)]\n        row.loc[name] = 1\n    return row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d74b248b2ea53b9082d6c9b2f11e65dda4becb57"},"cell_type":"code","source":"\nfor key in idx_to_class.keys():\n    train_data[idx_to_class[key]] = 0\n    \ntrain_data = train_data.apply(fill_targets, axis=1)\ntrain_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f338795cbd6be4a85811830ea44725ad1955ca1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cdf0d4d0b05c77a127ac2f4ff92b5c9b3ff089a"},"cell_type":"code","source":"\ntarget_counts = train_data.drop([\"Id\", \"Target\"],axis=1).sum(axis=0).sort_values(ascending=False)\nplt.figure(figsize=(15,15))\nsns.barplot(y=target_counts.index.values, x=target_counts.values, order=target_counts.index)\nplt.show()\n\nprint(target_counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e62644140227e05182add639bad1e968d779018"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54e78711bf2954265b780f631b995dbf0665b608"},"cell_type":"code","source":"## load dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67179213370a7d05c25aa35314421ee72f79d762"},"cell_type":"code","source":"path = \"../input\"\nmetadata='train.csv'\nimage_train_path = os.path.join(path, 'train')\nimage_test_path = os.path.join(path, 'test')\n\ntrain_data = pd.read_csv( os.path.join( path, metadata) )\n\nprint(train_data.head())\nprint('Total: ', len(train_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c23941c99be034683b7646f62828550fbfc15682"},"cell_type":"code","source":"def fill_targets(row):\n    target = np.array(row.Target.split(\" \")).astype(np.int)\n    p = np.zeros( 28 )\n    p[target] = 1 #1/len(target)\n    row.Target = p\n    return row\n\ntrain_data = train_data.apply(fill_targets, axis=1)\ntrain_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2b98733dc8318e9a45eabd46cd0af7d9dfea97d"},"cell_type":"code","source":"# https://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n\ndef open_grby(path, id): #a function that reads GRBY image\n    suffs = ['green', 'red', 'blue','yellow']\n    cvflag = cv2.IMREAD_GRAYSCALE\n    img = [cv2.imread(os.path.join( path, '{}_{}.png'.format(id, suff) ), cvflag).astype(np.float32)/255 \n           for suff in suffs ]\n    return np.stack(img, axis=-1)\n\ndef grby2rgb( image ):\n    return np.stack( ( image[:,:,0], image[:,:,1]/2 + image[:,:,3]/2, image[:,:,2]/2 + image[:,:,3]/2  ), axis=-1 )\n\n\nindex = 0\nimage_id = train_data['Id'][index]\nprob = train_data['Target'][index]\nimage_grby = open_grby( image_train_path, image_id )\n\nprint(image_grby.shape)\nprint(prob)\n\nips = np.where( prob>0 )[0]\nprint( [ '{}:{}'.format( idx_to_class[ip], prob[ip]) for ip in ips  ]  )\n\nplt.figure( figsize=(22,8) )\nplt.subplot(151)\nplt.imshow( grby2rgb(image_grby) )\nplt.axis('off')\nplt.title('image grby (grb)')\nfor i,v in enumerate(['green', 'red', 'blue','yellow']):\n    plt.subplot(1,5,i+2)\n    plt.imshow( image_grby[:,:,i] )\n    plt.axis('off')\n    plt.title('image grby ({}-channel)'.format( v[0] ) )\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ac6698c348a145d09f5a8eb979213ae321d06fd"},"cell_type":"code","source":"matplotlib.rcParams['font.size'] = 9\nmatplotlib.rcParams['figure.figsize'] = (12,19)\n\nnumRows = 9; numCols = 5\n\nplt.figure()\nfor k in range(numRows*numCols):\n    index = np.random.randint( len(train_data) )\n    image_id = train_data['Id'][index]\n    prob = train_data['Target'][index]\n    image_grby = open_grby( image_train_path, image_id )    \n    plt.subplot(numRows,numCols,k+1); \n    plt.imshow( grby2rgb( image_grby )  )\n    plt.title( '{} ...'.format( image_id[:3] ) ); \n    plt.axis('off')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b21d499ff90fa84bc5029d3f9de05f9e6cc56145"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd30075a1291868875c20c33fc38e87a6d591e4e"},"cell_type":"code","source":"\ndef open_grby( path, id): \n    '''a function that reads GRBY image'''\n    suffs = ['green', 'red', 'blue','yellow']\n    cvflag = cv2.IMREAD_GRAYSCALE    \n    img = [cv2.imread(os.path.join( path, '{}_{}.png'.format(id, suff) ), cvflag).astype(np.float32)/255 \n           for suff in suffs ]\n    return np.stack(img, axis=-1)\n\ndef make_dataset( path, metadata, train=True):\n    '''load file patch for disk\n    '''\n    data = pd.read_csv( os.path.join( path, metadata) )\n    if train:\n        def fill_targets(row):\n            target = np.array(row.Target.split(\" \")).astype(np.int)\n            p = np.zeros( 28 )\n            p[target] = 1 #1/len(target)\n            row.Target = p\n            return row\n        data = data.apply(fill_targets, axis=1)\n    return data\n\ndef grby2rgb( image ):\n    return np.stack( ( image[:,:,0], image[:,:,1]/2 + image[:,:,3]/2, image[:,:,2]/2 + image[:,:,3]/2  ), axis=-1 )\n\nclass ATLASProvide( object ):\n    '''Provide for ATLAS dataset\n    '''\n    @classmethod\n    def create(\n        cls, \n        path,\n        train=True,\n        folders_images='train',\n        metadata='train.csv',\n        ):\n        '''\n        Factory function that create an instance of ATLASProvide and load the data form disk.\n        '''\n        provide = cls(path, train, folders_images, metadata )\n        return provide\n    \n    def __init__(self,\n        path,        \n        train=True,\n        folders_images='train',\n        metadata='train.csv',\n        ):\n        super(ATLASProvide, self).__init__( )        \n        self.path     = os.path.expanduser( path )\n        self.folders_images  = folders_images\n        self.metadata        = metadata\n        self.data            = []\n        self.train           = train\n        \n        self.data = make_dataset( self.path, self.metadata, self.train )\n        \n    def __len__(self):\n        return len(self.data)\n        \n    def getname(self, i):\n        #check index\n        if i<0 and i>len(self.data): raise ValueError('Index outside range');\n        self.index = i;\n        return self.data['Id'][i]        \n\n    def __getitem__(self, i):                \n        #check index\n        if i<0 and i>len(self.data): raise ValueError('Index outside range');\n        self.index = i        \n        if self.train:           \n            image_id = self.data['Id'][i]\n            prob = self.data['Target'][i]\n            image_grby = open_grby(  os.path.join(self.path, self.folders_images ), image_id )\n            return image_id, grby2rgb(image_grby), prob\n        else:\n            image_id = self.data['Id'][i]\n            image_grby = open_grby( os.path.join(self.path, self.folders_images ) , image_id )\n            return image_id, grby2rgb(image_grby), 0\n\n        \n        \npath = \"../input\"\nmetadata='train.csv' # train.csv, sample_submission.csv\nfolders_images='train' #train, test\ntrain=True #True, False\ndataset = ATLASProvide.create(path=path, train=train, folders_images=folders_images, metadata=metadata )\niD,image, prob = dataset[ np.random.randint( len(dataset) ) ]\n\nprint( len(dataset) )     \nprint( iD )\nprint( prob )\n\nplt.figure( figsize=(8,8) )\nplt.imshow( image )\nplt.axis('off')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"798bb7b3d10de675b9ee0757f8c383928bab1b6c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c828a047dfec8caa4da29ba3cc952eef5403817"},"cell_type":"code","source":"!ls ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8691413a17236b543f8f4e4945d1ce3d71a1e105"},"cell_type":"code","source":"# dataloader \n\ntrain = 'train'\nvalidation = 'train'\ntest  = 'train'\n\nclass ATLASDataset(object):\n    '''\n    Management for Human Protein Atlas dataset\n    '''\n    def __init__(self, \n        path,   \n        train=True,\n        folders_images='train',\n        metadata = 'train.csv',\n        ext='png',\n        transform=None,\n        count=None, \n        num_channels=3,\n        ):\n        \"\"\"Initialization       \n        \"\"\"            \n           \n        self.data = ATLASProvide.create( \n                path, \n                train,\n                folders_images, \n                metadata,\n                )\n        \n        self.transform = transform  \n        self.count = count if count is not None else len(self.data)   \n        self.num_channels = num_channels\n\n    def __len__(self):\n        return self.count\n    \n    def getname(self, idx):\n        idx = idx % len(self.data)\n        return self.data.getname(idx)\n\n    def __getitem__(self, idx):   \n        idx = idx % len(self.data)\n        iD, image, prob = self.data[idx]\n                \n        #obj = ObjectImageTransform( image )\n        #if self.transform: \n        #    obj = self.transform( obj )\n        #image = obj.to_value()\n        \n        return iD, image, prob \n    \n\npath = \"../input\"\nmetadata='train.csv' # train.csv, sample_submission.csv\nfolders_images='train' #train, test\ntrain=True #True, False\ndataset = ATLASDataset(path=path, train=train, folders_images=folders_images, metadata=metadata )\niD,image, prob = dataset[ np.random.randint( len(dataset) )  ]\n\nprint( len(dataset) )     \nprint( iD )\nprint( prob )\n\nplt.figure( figsize=(8,8) )\nplt.imshow( image )\nplt.axis('off')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b0b1ee8ed1eef7a8ea1bb54e8f611872d5b555f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68f541149239e007dbd35a70fd4d834341266c44"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8811a645f75f61362f85a98ea2cd4e9f817b08f0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}