{"nbformat_minor": 1, "cells": [{"source": ["***Getting some issue with sparse matrix and input to TensorFlow*** \n", "In this notebook I tried to use tfidf features and a simple neural network with tensorflow "], "cell_type": "markdown", "metadata": {"_cell_guid": "ed6e29b2-a035-46ec-a37c-f87364378ece", "_uuid": "5b42154f4351550140bbaa437753f14be0d46a5f"}}, {"metadata": {"_cell_guid": "3e451bd6-f8db-4c76-b12c-7630ad223dbb", "_uuid": "a2ee98ffa2671706cec6a569a1f30c8935111ab1", "collapsed": true}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import tensorflow as tf\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.feature_extraction.text import TfidfTransformer\n", "from sklearn.externals import joblib\n", "from sklearn.model_selection import train_test_split"], "cell_type": "code", "execution_count": 1}, {"metadata": {"_cell_guid": "5666ccf3-0fcb-4868-b0c7-1923cd713f84", "_uuid": "8686e874e9a257fc9237da1566f3a1ac370f4309", "collapsed": true}, "outputs": [], "source": ["# Loading datasets\n", "train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")\n", "submission = pd.read_csv(\"../input/sample_submission.csv\")"], "cell_type": "code", "execution_count": 2}, {"metadata": {"_cell_guid": "57d59955-4069-4d48-90c8-e15d856fcf3f", "_uuid": "e5dd634894192950737243729bf42b56c7e98154"}, "outputs": [], "source": ["train.head()"], "cell_type": "code", "execution_count": 3}, {"metadata": {"_cell_guid": "d384bb54-2aba-4f22-a1c2-f882069ef440", "_uuid": "d105f3c9b451c8e3b7aa3e0b6419318435ae43ad", "scrolled": true, "collapsed": true}, "outputs": [], "source": ["# print \"before\",test.shape\n", "test[\"comment_text\"].fillna(\"fillanything\").values\n", "# print \"after\", test.shape\n", "\n", "train_comment, test_comment = train[\"comment_text\"], test[\"comment_text\"]\n", "allcomment = pd.concat([train_comment,test_comment])\n", "# allcomment = allcomment[\"comment_text\"].fillna(\"fillanything\").values # filling if any value is left blank"], "cell_type": "code", "execution_count": 4}, {"metadata": {"_cell_guid": "567efc1e-057c-421c-a7e3-746db25ef7a7", "_uuid": "4500ff41f3c475aceee3d0e46f7f3c0d09f14d53"}, "outputs": [], "source": ["col = np.array(train.columns)\n", "y_lable = train[col[2:]].astype(np.int32)           # ground truth\n", "print (y_lable.shape[1])"], "cell_type": "code", "execution_count": 5}, {"metadata": {"_cell_guid": "69bd2084-40f4-4c8c-998d-90be418c116f", "_uuid": "63fff41be65b97737f30e10a8d5b2bc8f56c7907", "scrolled": true}, "outputs": [], "source": ["vectorizer = TfidfVectorizer(stop_words='english', lowercase = True, strip_accents='unicode', ngram_range=(1,3), encoding = 'utf-8', decode_error = 'strict', max_features = 1000)\n", "vectorizer.fit_transform(allcomment)\n", "# Once done save it into pickle format\n", "# joblib.dump(vectorizing_all_comment, \"comment_1000.pkl\")\n", "# vectorizing_all_comment = joblib.load(\"comment_1000.pkl\")"], "cell_type": "code", "execution_count": 6}, {"metadata": {"_cell_guid": "5a473478-a8ff-4b0e-a942-64ae8a605b35", "_uuid": "aae865e58eafc488d9bb0c5cde2ffcc99acc44db", "collapsed": true}, "outputs": [], "source": ["trainVectFeatures = vectorizer.transform(train[\"comment_text\"])\n", "testVectFeatures = vectorizer.transform(test[\"comment_text\"])"], "cell_type": "code", "execution_count": 7}, {"metadata": {"collapsed": true}, "outputs": [], "source": ["from scipy.sparse import csr_matrix\n", "trainVectFeatures = trainVectFeatures.todense()"], "cell_type": "code", "execution_count": 8}, {"metadata": {"_cell_guid": "ba787cfd-0f35-40cf-ade0-aeb82a9376cf", "_uuid": "650e3f89689a4dfda40540d1a79f7ab5199dd50d", "collapsed": true}, "outputs": [], "source": ["#trainVectFeatures= joblib.load(\"trainVectFeatures1000.pkl\").astype(np.int64)\n", "# joblib.load( \"testVectFeatures1000.pkl\").astype(np.int64)"], "cell_type": "code", "execution_count": null}, {"metadata": {"_cell_guid": "bb86866c-f923-4bed-b311-15102f5f5f77", "_uuid": "bf2815d5d14397fe441405eb5266919aaad8811a", "collapsed": true}, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(trainVectFeatures, y_lable, test_size=0.2, random_state=42)"], "cell_type": "code", "execution_count": 9}, {"source": ["# Creating 1 hidden layer neural network"], "cell_type": "markdown", "metadata": {"_cell_guid": "e6364655-d514-4d58-96a3-2654dd55bff0", "_uuid": "db0961b90569a737dbf009972cebe5671400b69f"}}, {"metadata": {"_cell_guid": "76a4cd7a-f65f-401a-bf21-efdd73b12012", "_uuid": "035894b44decc7e3497087fdc422ba25134ee11d", "collapsed": true}, "outputs": [], "source": ["input_size = trainVectFeatures.shape[1]\n", "output_size = y_train.shape[1] # 6\n", "hidden_unit1 = 1100\n", "\n", "X_input = tf.placeholder(tf.float32, [None, input_size] ) # input 1000 \n", "y_output = tf.placeholder(tf.float32, [None, output_size] )  # y=6 \n", "\n", "w1 = tf.Variable(tf.random_normal([input_size, hidden_unit1]), name = \"Weights_1\") #Initaliazing weight_1\n", "b1 = tf.Variable(tf.random_normal([hidden_unit1]), name = \"Bias_1\")\n", "\n", "w2 = tf.Variable(tf.random_normal([hidden_unit1, output_size]),  name = \"Weights_2\") #Initaliazing weight_2\n", "b2 = tf.Variable(tf.random_normal([output_size]), name = \"Bias_2\")"], "cell_type": "code", "execution_count": 10}, {"metadata": {"_cell_guid": "28477ceb-b954-4d79-98c7-f7e894962f6f", "_uuid": "22fb03cd1e8be6510a4c0eefb7f62026b1cd3209"}, "outputs": [], "source": ["hidden_layer = tf.nn.sigmoid(tf.matmul(X_input, w1)+b1) \n", "output_layer = tf.nn.sigmoid(tf.matmul(hidden_layer, w2) + b2)\n", "\n", "losses = tf.losses.mean_squared_error(y_train, output_layer)\n", "optimizer = tf.train.GradientDescentOptimizer(0.09).minimize(losses)\n", "\n", "init = tf.global_variables_initializer()\n", "sess = tf.InteractiveSession() \n", "sess.run(tf.global_variables_initializer())\n", "\n", "step_size = 100\n", "for step in range(step_size):  \n", "    a,b,c,d = sess.run([hidden_layer,output_layer,losses,optimizer], feed_dict={X_input:X_train,y_output:y_train})\n", "\n", "    if step%20==0:\n", "        print (\"losses after per 20 iteration: \",c)\n", "\n", "correct_prediction = tf.equal(tf.argmax(output_layer,1), tf.argmax(y_output,1))\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n", "\n"], "cell_type": "code", "execution_count": 12}, {"metadata": {}, "outputs": [], "source": ["print (\"Accuracy on the model: \",accuracy.eval(feed_dict={X_input:X_train, y_output:y_train}))"], "cell_type": "code", "execution_count": 13}, {"metadata": {"_cell_guid": "5f44c381-a988-42d6-b1ef-5821930bbd66", "_uuid": "6b69cf9e23b9a8a5d8651c8d1d20a0a5d7de2aaf", "collapsed": true}, "outputs": [], "source": [], "cell_type": "code", "execution_count": null}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"version": "3.6.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}}}}