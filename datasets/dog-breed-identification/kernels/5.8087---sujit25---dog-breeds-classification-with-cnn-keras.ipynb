{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom os import listdir\nfrom os.path import basename,join,exists\nimport os\nprint(listdir(\"../input\"))\nimport threading\nfrom queue import Queue\nfrom math import floor\nimport time\nimport pickle\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"df = pd.read_csv('../input/sample_submission.csv')\ntrain_dir_path = \"../input/train\"\ntest_dir_path = \"../input/test\"\n#pickled_dir_path  = \"../output/pickled_Data\"\nlabels_df = pd.read_csv('../input/labels.csv')\ndog_breeds = list(df.columns[1:])\nprint(len(dog_breeds))\nprint(dog_breeds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6098db8e4d7ddc93df9fbc9d6497baef49f3e801","collapsed":true},"cell_type":"code","source":"train_img_fpaths = [ join(train_dir_path, f) for f in listdir(train_dir_path)]\ntest_img_fpaths = [join(test_dir_path, f) for f in listdir(test_dir_path)]\nprint(len(train_img_fpaths))\nprint(len(test_img_fpaths))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58bcd5d6a2118b5a3cea5c84ec37571fa21ba69b","collapsed":true},"cell_type":"code","source":"def dog_breed_from_id(dog_id):\n    #labels_df = pd.read_csv('../input/labels.csv')\n    return labels_df[labels_df['id'] ==dog_id]['breed'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb76349dd3eeefe06360740a6d6ec0b5388641e6","collapsed":true},"cell_type":"code","source":"import cv2 as cv\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c16cccefbe3ffa886bf6f83b465bde1635651f5","collapsed":true},"cell_type":"code","source":"# variables \nIMG_HEIGHT = 150\nIMG_WIDTH = 150\nIMG_CHANNELS = 3\nBATCH_SIZE = 1000\nlock = threading.Lock()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1f055c5c6c2dc2c007c0ac498550d512c4244ecc"},"cell_type":"code","source":"def img_to_array(img_path):   \n    img_array = cv.imread(img_path)\n    img_array = cv.resize(img_array, (IMG_HEIGHT, IMG_WIDTH))\n    img_array = img_array.reshape(-1,IMG_HEIGHT,IMG_WIDTH, IMG_CHANNELS)\n    return img_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc7b7e685bbe0b103a4a3eaeedaec962fe249365","collapsed":true},"cell_type":"code","source":"# initialize queue which is threadsafe \ndef initialize_queue():\n    queue =Queue()\n    return queue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a42b29fd5d8df0c903679dc636e0d866bd01cf24"},"cell_type":"code","source":"# get list of image ids from names of test images\ndef get_test_image_ids():\n    return [basename(fpath).split('.')[0] for fpath in test_img_fpaths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64f447aca7bea745f4444f81e34ef139fb0c2b74","collapsed":true},"cell_type":"code","source":"# converts image files to numpy array and based on train/test, return train array and labels,\ndef get_data(is_train):\n    # 1 batch per thread and last thread with remaining images\n    img_fpaths = train_img_fpaths if is_train else test_img_fpaths\n    num_threads = floor(len(img_fpaths)/BATCH_SIZE)\n    print(\"num of threads:\", num_threads + 1)\n    img_array = None\n    queue = initialize_queue()\n    results = []          # results from multiple threads\n    print(\"getting training data....\") if is_train else print(\"getting testing data....\")\n    \n    # load queue with data for each task\n    for batch_index in range(num_threads + 1):\n        if batch_index == num_threads:\n            file_batch = img_fpaths[(batch_index*BATCH_SIZE):]\n        else:\n            file_batch = img_fpaths[(batch_index*BATCH_SIZE) : (batch_index + 1)*BATCH_SIZE]\n        queue.put(file_batch)\n    \n    # iterate over loop to create threads\n    for thread_index in range(num_threads+1):\n        thread = threading.Thread(target = get_train_data_parallely, args=(queue, results)) if is_train else threading.Thread(target =get_testing_data_parallely, args =(queue, results))    \n        thread.start()\n        print(\"{} started\".format(thread.name))\n       # worker_threads.append(thread)\n        \n    # when queue in empty\n    queue.join()\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5738a2bea158ef8f8bdf880fa3c7670b0e38980","collapsed":true},"cell_type":"code","source":"# convert training data into list of tuples\n# this subroutine represents a task for child thread to collect training data\ndef get_train_data_parallely(queue, results):\n    result = []\n    while not queue.empty():\n        fpaths = queue.get()\n        for f_path in fpaths:\n            img_array = img_to_array(f_path)\n            # train_img_array = img_array if train_img_array is None else np.vstack((train_img_array, img_array))\n            img_name = basename(f_path)\n            img_id = img_name.split('.')[0]\n            dog_breed = dog_breed_from_id(img_id)\n            #train_labels.append(dog_breed)\n            results.append((img_array, dog_breed))\n            \n    # append arr,labels for current task to results\n    print(\"{} finished\".format(threading.currentThread().getName()))\n    # signal for task has been done\n    queue.task_done()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cafe3280ff1a83135b0b1922c1374cea62b0051e","collapsed":true},"cell_type":"code","source":"# worker job for converting test imgs to array\ndef get_testing_data_parallely(queue, results):\n    while not queue.empty():\n        file_batch = queue.get()\n        for f_path in file_batch:        \n            img_name = basename(f_path)\n            img_id = img_name.split('.')[0]\n            results.append((img_id, img_to_array(f_path)))\n    print(\"{} finished\".format(threading.currentThread().getName()))\n    queue.task_done()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32ee84979d6990fe6139247310555303555bfb77","scrolled":false,"collapsed":true},"cell_type":"code","source":"# method for getting training data\ndef get_training_data():\n    train_results = get_data(is_train = True)\n    train_labels = []\n    img_arrays= []\n    for u_index in range(len(train_results)):\n        img_arr, identified_breed = train_results[u_index]\n        img_arrays.append(img_arr)\n        train_labels.append(identified_breed)\n    train_arr = np.array(img_arrays).reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n    train_arr = train_arr/255\n    train_labels = one_hot_encode_labels(train_labels)\n    return train_arr,train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f1e663f373aa1ec0f23cba45ef974e68def66fe8"},"cell_type":"code","source":"# method for getting testing arr\ndef get_testing_data():\n    results = get_data(is_train = False)\n    test_img_ids = []\n    test_img_list = []\n    for test_result in results:\n        img_id, img_arr = test_result\n        test_img_list.append(img_arr)\n        test_img_ids.append(img_id)\n    test_img_arr = np.array(test_img_list).reshape(-1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n    test_img_arr = test_img_arr/255\n    return test_img_arr, test_img_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"22fa7ae953f78d33b2b4798bec2d9d4b00ab79b7"},"cell_type":"code","source":"def save_obj_to_disk(fname, obj):\n    print(\"saving \"+ fname +\" to filesystem\")\n    if  exists(fname):\n        print(fname + \"already exists\") \n    with open(fname, 'wb') as f:\n        pickle.dump(obj, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b46cbdeb0037b857ec41a779366f0cd771545c0e","collapsed":true},"cell_type":"code","source":"def load_obj_from_disk(fname):\n    if exists(fname):\n        print(\"loading \"+fname + \" from filesystem\")\n        obj = None\n        with open(fname, 'rb') as f:\n            obj = pickle.load(f)\n        return obj\n    else:\n        print(fname + \"doesnt not exists\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94689997aba3c0a76a054c2644d60971e2f2ad88","collapsed":true},"cell_type":"code","source":"def load_train_test_data(load_train=False, load_test=False, one_hot_encode=False):\n    train_arr = None\n    train_labels = None\n    test_arr = None\n    \n    # check if training data and labels exists already as pickled file\n    if load_train:\n        if exists(\"train_data.pickle\") and exists(\"train_labels.pickle\"):\n            train_arr = load_obj_from_disk(\"train_data.pickle\")\n            train_labels = load_obj_from_disk(\"train_labels.pickle\")\n            if one_hot_encode:\n                train_labels = one_hot_encode_labels(train_labels)\n        else:\n            # create training_data and save it to filesystem\n            train_arr, train_labels = get_data(is_train= True)\n            if not exists(\"train_data.pickle\"):\n                save_obj_to_disk(\"train_data.pickle\", train_data)\n            if not exists(\"train_labels.pickle\"):\n                save_obj_to_disk(\"train_labels.pickle\", train_labels)\n        print(\" train array shape : {}, train array labels: {}\".format(train_data.shape,len(train_labels)))\n        \n    # check if testing data and labels exists already as pickled file\n    if load_test:\n        if exists(\"test_data.pickle\"):\n            test_arr = load_obj_from_disk(\"test_data.pickle\")\n        else:\n            # create test_data and save it to filesystem\n            test_arr = get_data(is_train= False)\n            save_obj_to_disk(\"test_data.pickle\", test_arr)\n        print(\" test array shape : {}\".format(test_arr.shape))\n    return train_arr, train_labels, test_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"acca546637834880440388d904555cdc2006b785"},"cell_type":"code","source":"# method for onehot encoding labels of train_arr\ndef one_hot_encode_labels(label_arr):\n    from sklearn.preprocessing import LabelEncoder ,OneHotEncoder\n    labelEncoder = LabelEncoder()\n    integer_encoded = labelEncoder.fit_transform(np.array(label_arr))\n    integer_encoded = integer_encoded.reshape(-1,1)\n    onehotEncoder = OneHotEncoder()\n    onehot_encoded_arr = onehotEncoder.fit_transform(integer_encoded).toarray()\n    return onehot_encoded_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be449887b7d8ba9f9778c03bf4ad54e2bff5b1ff","collapsed":true},"cell_type":"code","source":"x, y =get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f01a2b6b2e086dd7b44dac15e99265b3f05ba66c"},"cell_type":"code","source":"train_x, valdn_x, train_y, valdn_y = train_test_split(x,y,test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59556f42676c9a12338e2aa74655f8b46ed15abe","collapsed":true},"cell_type":"code","source":"test_x, test_img_ids = get_testing_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ea978f1c898090500eb4c36b276405592f13c30","collapsed":true},"cell_type":"code","source":"print(train_x.shape)\nprint(train_y.shape)\nprint(valdn_x.shape)\nprint(valdn_y.shape)\nprint(test_x.shape)\nprint(len(test_img_ids))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"659fd8492fe15451e521c030cff7f0e5ec59961d","collapsed":true},"cell_type":"code","source":"# import required packages\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5fd6ed73aeb66a653810f582574b2117542d15b6"},"cell_type":"code","source":"# CNN model\nmodel = Sequential()\n\n# -----------------------------------------------------------------------------------\n# conv 1\nmodel.add(Conv2D(16, (3,3), input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)))       # input -N,150,150,3, output- N,148,148,16\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n# max pool 1\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))                                   #input- N,148,148,16, output- N, 74,74,16\n\n# -----------------------------------------------------------------------------------\n# # conv 2\nmodel.add(Conv2D(32, (3,3)))                                                         #input- N,74,74,16 output - N, 72,72,16\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.5))\n\n# max pool 2\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))                                 #input - N,72,72,16, output- N,36,36,16\n# -----------------------------------------------------------------------------------\n\n# conv 3\nmodel.add(Conv2D(48, (3,3)))                                                       #input - N,36,36,16, output- N,34,34,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.7))\n\n# max pool 3\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))                                #input- N,34,34,32, output- N,17,17,32\n# -----------------------------------------------------------------------------------\n\n# # conv 4\nmodel.add(Conv2D(64, (3,3)))                                                     #input- N,17,17,32, output- N,15,15,32\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Activation('relu'))\n#model.add(Dropout(0.7))\n# max pool 4\nmodel.add(MaxPooling2D(pool_size=(2,2),strides=2))                              #input- N,15,15,32, output- N,7,7,32\n\n# flatten\nmodel.add(Flatten())                                                            # output- 1568\n\n# fc layer 1\nmodel.add(Dense(1024, activation='relu'))                                  \n\n# fc layer 2\nmodel.add(Dense(512, activation='relu'))\n\n# fc layer 3\nmodel.add(Dense(256, activation='relu'))\n\n# fc layer 4\nmodel.add(Dense(120, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfadef0004c484415660f40499bc2e7549bf5723","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8bb3b45e9b7ec4bdcfa74ab003fd07bff3a0112c"},"cell_type":"code","source":"# compile model for with softmax cross entropy and adam optimizer, set accuracy as parameter to evaluate\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1575e46888536132b9548f6f7e448e547e209a3c","collapsed":true},"cell_type":"code","source":"# train model on training data\nmodel_hist = model.fit(train_x, train_y, batch_size=64, nb_epoch=100, verbose=1, validation_data=(valdn_x, valdn_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e872bc8b28692ed635f1047ab6ba9a846e179017","collapsed":true},"cell_type":"code","source":"predictions = model.predict(test_x, batch_size=32, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caaa74d3c9226485c923e64d2fbb5d55e63c60a3","collapsed":true},"cell_type":"code","source":"print(predictions.shape)\nprint(len(dog_breeds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c628627f62345fe1c8c7a4f2379db5f03fa2770","collapsed":true},"cell_type":"code","source":"import pandas as pd\nsubmission_res = pd.DataFrame(data= predictions, index =test_img_ids, columns= dog_breeds)\nsubmission_res.index.name = 'id'\nsubmission_res.to_csv('submission.csv', encoding='utf-8', index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb3fd827d6d129fd1a8b95ed51cfac23616e8798","collapsed":true},"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(model_hist.history['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a30b60745c9d516d0fa635f769650e5ee6dc6d0b","collapsed":true},"cell_type":"code","source":"# summarize history for loss\nplt.plot(model_hist.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}