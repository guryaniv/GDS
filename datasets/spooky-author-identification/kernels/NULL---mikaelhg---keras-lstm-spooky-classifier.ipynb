{"nbformat_minor": 1, "cells": [{"execution_count": null, "cell_type": "code", "metadata": {"_uuid": "fcdd50d0287ef09de79d8c479161d5aa0eb53cf6", "_cell_guid": "89e6ac61-d437-493f-acf6-d36e14c6d403"}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["NUM_WORDS = 10000\n", "N = 128\n", "MAX_LEN = 50\n", "NUM_CLASSES = 3"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["from keras.layers import Embedding, LSTM, Dense, Flatten\n", "from keras.models import Sequential\n", "\n", "model = Sequential()\n", "model.add(Embedding(NUM_WORDS, N, input_length=MAX_LEN))\n", "model.add(LSTM(N, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n", "model.add(Flatten())\n", "model.add(Dense(NUM_CLASSES, activation='softmax'))\n", "\n", "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "model.summary()"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "train.sample(10)"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.preprocessing.sequence import pad_sequences\n", "from keras.preprocessing.text import Tokenizer\n", "from sklearn import preprocessing\n", "\n", "X = train['text']\n", "Y = train['author']\n", "\n", "tokenizer = Tokenizer(num_words=NUM_WORDS)\n", "tokenizer.fit_on_texts(X)\n", "\n", "train_x = tokenizer.texts_to_sequences(X)\n", "train_x = pad_sequences(train_x, maxlen=MAX_LEN)\n", "\n", "lb = preprocessing.LabelBinarizer()\n", "lb.fit(Y)\n", "\n", "train_y = lb.transform(Y)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["model.fit(train_x, train_y, validation_split=0.2, batch_size=1024, epochs=8, verbose=2)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["score = model.evaluate(train_x, train_y, batch_size=1024, verbose=2)\n", "print(score)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["p = model.predict(pad_sequences(tokenizer.texts_to_sequences(test['text']), maxlen=MAX_LEN),\n", "                  batch_size=1024)\n", "\n", "for i in range(10):\n", "    row = p[i]\n", "    print(TX[i])\n", "    for j in range(len(lb.classes_)):\n", "        print('{0:>5} {1:02.2f}'.format(lb.classes_[j], row[j]))\n", "    print()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["import pickle, h5py\n", "model.save('spooky_model.hdf5')\n", "with open('tokenizer.pickle', 'wb') as f:\n", "    pickle.dump(tokenizer, f)\n", "with open('binarizer.pickle', 'wb') as f:\n", "    pickle.dump(lb, f)"]}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}}