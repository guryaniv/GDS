{"cells":[{"metadata":{"_uuid":"3d7ff0f55d73bdf321e790575ef09eb0c27ae94b"},"cell_type":"markdown","source":"### This is an adaptation of the Coursera code (originally built with tensorflow), on this one i used Keras to make the model part simpler, maybe it can help people that are new to deep learning or anyone else that want to use Keras on this competition.\n\n#### Notes: \n* [Link for a tensorflow version](https://www.kaggle.com/dimitreoliveira/tensorflow-dnn-coursera-ml-course-code)\n* [Link for a more complete version on Github](https://github.com/dimitreOliveira/NewYorkCityTaxiFare)\n* I'm not using \"passenger count\" because it something that is not supposed to really matter in this case.\n* I've created two features derived from \"hour\" (night and late night), according to some research i did it's added an additional value if it's a business day (mon ~ fri), and it's night, also there's another added value if it's dawn.\n* I'm binning latitudes and longitudes to make it easier to work with.\n* Even tough deep learning is robust enough to deal with noisy data, i'm removing outliers (it may save some memory).\n* Currently i'm using both Euclidean and Manhattan distances, it may be a bit redundant, but they have a different meaning and i'm still not sure of witch one is better(if you have some insights about this please let me know)"},{"metadata":{"_uuid":"202e10c43907e5fdc7264a2c328aa0a53ed73a10"},"cell_type":"markdown","source":"### Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom keras import optimizers\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2f2e006756ff46df570d539cc3976520d530cb6"},"cell_type":"markdown","source":"## Data clean\n### Here i'm removing some outliers, and noisy data.\n* Lats and lons that do not belong to New York.\n* Negative fare.\n* Fare greater than 250 (this seems to be noisy data).\n* Rides that begin and end in the same location."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"716e84668e42e06342b58423ea1f64a319d05f62"},"cell_type":"code","source":"def clean(df):\n    # Delimiter lats and lons to NY only\n    df = df[(-76 <= df['pickup_longitude']) & (df['pickup_longitude'] <= -72)]\n    df = df[(-76 <= df['dropoff_longitude']) & (df['dropoff_longitude'] <= -72)]\n    df = df[(38 <= df['pickup_latitude']) & (df['pickup_latitude'] <= 42)]\n    df = df[(38 <= df['dropoff_latitude']) & (df['dropoff_latitude'] <= 42)]\n    # Remove possible outliers\n    df = df[(0 < df['fare_amount']) & (df['fare_amount'] <= 250)]\n    # Remove inconsistent values\n    df = df[(df['dropoff_longitude'] != df['pickup_longitude'])]\n    df = df[(df['dropoff_latitude'] != df['pickup_latitude'])]\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12bb5164c954464788a0b26afb62d13f8a5f868c"},"cell_type":"markdown","source":"## Feature engineering\n*  Now i'll do some feature engineering and process the data, i'm basically creating 3 kinds of features.\n    *  **Time features**\n        * Year, Month, Day, Hour, Weekday\n        * Night (between 16h and 20h, from monday to friday)\n        * Late night (between 20h and and 6h)\n    * **Coordinate features**\n        * Latitude difference (difference from pickup and dropout latitudes)\n        * Longitude difference (difference from pickup and dropout longitudes)\n    * **Distances features**\n        * Euclidean (Euclidean distance from pickup and dropout)\n        * Manhattan (Manhattan distance from pickup and dropout)\n        * Manhattan distances from pickup location and downtown, JFK, EWR and LGR airports (see if the ride started at one of these locations).\n        * Manhattan distances from dropout location and downtown, JFK, EWR and LGR airports (see if the ride ended at one of these locations)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"def late_night (row):\n    if (row['hour'] <= 6) or (row['hour'] >= 20):\n        return 1\n    else:\n        return 0\n\n\ndef night (row):\n    if ((row['hour'] <= 20) and (row['hour'] >= 16)) and (row['weekday'] < 5):\n        return 1\n    else:\n        return 0\n    \n    \ndef manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n\n\ndef add_time_features(df):\n    df['pickup_datetime'] =  pd.to_datetime(df['pickup_datetime'], format='%Y-%m-%d %H:%M:%S %Z')\n    df['year'] = df['pickup_datetime'].apply(lambda x: x.year)\n    df['month'] = df['pickup_datetime'].apply(lambda x: x.month)\n    df['day'] = df['pickup_datetime'].apply(lambda x: x.day)\n    df['hour'] = df['pickup_datetime'].apply(lambda x: x.hour)\n    df['weekday'] = df['pickup_datetime'].apply(lambda x: x.weekday())\n    df['pickup_datetime'] =  df['pickup_datetime'].apply(lambda x: str(x))\n    df['night'] = df.apply (lambda x: night(x), axis=1)\n    df['late_night'] = df.apply (lambda x: late_night(x), axis=1)\n    # Drop 'pickup_datetime' as we won't need it anymore\n    df = df.drop('pickup_datetime', axis=1)\n    \n    return df\n\n\ndef add_coordinate_features(df):\n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    # Add new features\n    df['latdiff'] = (lat1 - lat2)\n    df['londiff'] = (lon1 - lon2)\n\n    return df\n\n\ndef add_distances_features(df):\n    # Add distances from airpot and downtown\n    ny = (-74.0063889, 40.7141667)\n    jfk = (-73.7822222222, 40.6441666667)\n    ewr = (-74.175, 40.69)\n    lgr = (-73.87, 40.77)\n    \n    lat1 = df['pickup_latitude']\n    lat2 = df['dropoff_latitude']\n    lon1 = df['pickup_longitude']\n    lon2 = df['dropoff_longitude']\n    \n    df['euclidean'] = (df['latdiff'] ** 2 + df['londiff'] ** 2) ** 0.5\n    df['manhattan'] = manhattan(lat1, lon1, lat2, lon2)\n    \n    df['downtown_pickup_distance'] = manhattan(ny[1], ny[0], lat1, lon1)\n    df['downtown_dropoff_distance'] = manhattan(ny[1], ny[0], lat2, lon2)\n    df['jfk_pickup_distance'] = manhattan(jfk[1], jfk[0], lat1, lon1)\n    df['jfk_dropoff_distance'] = manhattan(jfk[1], jfk[0], lat2, lon2)\n    df['ewr_pickup_distance'] = manhattan(ewr[1], ewr[0], lat1, lon1)\n    df['ewr_dropoff_distance'] = manhattan(ewr[1], ewr[0], lat2, lon2)\n    df['lgr_pickup_distance'] = manhattan(lgr[1], lgr[0], lat1, lon1)\n    df['lgr_dropoff_distance'] = manhattan(lgr[1], lgr[0], lat2, lon2)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a098dcf43d5c5f8bbe1dbd6e89f797160f8173d5"},"cell_type":"markdown","source":"### Auxiliar functions"},{"metadata":{"trusted":true,"_uuid":"646281e5cb269122cfe005191271d57bdcf42a96","collapsed":true},"cell_type":"code","source":"def output_submission(raw_test, prediction, id_column, prediction_column, file_name):\n    df = pd.DataFrame(prediction, columns=[prediction_column])\n    df[id_column] = raw_test[id_column]\n    df[[id_column, prediction_column]].to_csv((file_name), index=False)\n    print('Output complete')\n    \n    \ndef plot_loss_accuracy(history):\n    plt.figure(figsize=(20,10))\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper right')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f26c4a260b408ffbd1e881d205eb7145a1e37ce"},"cell_type":"markdown","source":"### Parameters"},{"metadata":{"trusted":true,"_uuid":"a67bbf9dc5b0caab8d964837c072b229b6224a5a","collapsed":true},"cell_type":"code","source":"TRAIN_PATH = '../input/train.csv'\nTEST_PATH = '../input/test.csv'\nSUBMISSION_NAME = 'submission.csv'\n\n# Model parameters\nBATCH_SIZE = 256\nEPOCHS = 50\nLEARNING_RATE = 0.001\nDATASET_SIZE = 6000000","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6e4c15bf38a9f2606d0fb2f65f152eaee7912df"},"cell_type":"markdown","source":"### Load data"},{"metadata":{"trusted":true,"_uuid":"99506a559b162562260d3e347558249c0ed85b7f","collapsed":true},"cell_type":"code","source":"# Load values in a more compact form\ndatatypes = {'key': 'str', \n              'fare_amount': 'float32',\n              'pickup_datetime': 'str', \n              'pickup_longitude': 'float32',\n              'pickup_latitude': 'float32',\n              'dropoff_longitude': 'float32',\n              'dropoff_latitude': 'float32',\n              'passenger_count': 'uint8'}\n\n# Only a fraction of the whole data\ntrain = pd.read_csv(TRAIN_PATH, nrows=DATASET_SIZE, dtype=datatypes, usecols=[1,2,3,4,5,6])\ntest = pd.read_csv(TEST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f7c8d4f7d38887e62deb95d0c5be74975ab22f0"},"cell_type":"markdown","source":"#### Clean and process data"},{"metadata":{"trusted":true,"_uuid":"061247c80aa6f3a443a59bd7736de33985cd1a7b","collapsed":true},"cell_type":"code","source":"train = clean(train)\n\ntrain = add_time_features(train)\ntest = add_time_features(test)\n\nadd_coordinate_features(train)\nadd_coordinate_features(test)\n\ntrain = add_distances_features(train)\ntest = add_distances_features(test)\n\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b06b6025ec3822623a120c06170e74161f0f7262","collapsed":true},"cell_type":"code","source":"# Drop unwanted columns\ndropped_columns = ['pickup_longitude', 'pickup_latitude', \n                   'dropoff_longitude', 'dropoff_latitude']\ntrain_clean = train.drop(dropped_columns, axis=1)\ntest_clean = test.drop(dropped_columns + ['key', 'passenger_count'], axis=1)\n\n# peek data\ntrain_clean.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"736872d7fb45a0b3e7532db4da69da29ac4761fd"},"cell_type":"markdown","source":"#### Split data in train and validation (90% ~ 10%)"},{"metadata":{"trusted":true,"_uuid":"ea58d88d113808dc224e176db2bc37f6c93e08db","collapsed":true},"cell_type":"code","source":"train_df, validation_df = train_test_split(train_clean, test_size=0.10, random_state=1)\n\n# Get labels\ntrain_labels = train_df['fare_amount'].values\nvalidation_labels = validation_df['fare_amount'].values\ntrain_df = train_df.drop(['fare_amount'], axis=1)\nvalidation_df = validation_df.drop(['fare_amount'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9500aaf4067e9c953d045421f767e8a536a0efad","collapsed":true},"cell_type":"code","source":"# Scale data\n# Note: im doing this here with sklearn scaler but, on the Coursera code the scaling is done with Dataflow and Tensorflow\nscaler = preprocessing.MinMaxScaler()\ntrain_df_scaled = scaler.fit_transform(train_df)\nvalidation_df_scaled = scaler.transform(validation_df)\ntest_scaled = scaler.transform(test_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ccc5e6695f687e26444532b1c53849e894222ad"},"cell_type":"markdown","source":"### Model"},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"8dd2826039f92c6d46fde06c9c030ff76bb5933f","scrolled":false,"collapsed":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(256, activation='relu', input_dim=train_df_scaled.shape[1], activity_regularizer=regularizers.l1(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(8, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1))\n\nadam = optimizers.adam(lr=LEARNING_RATE)\nmodel.compile(loss='mse', optimizer=adam, metrics=['mae'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfe2b169b769e5e887523c4b5b00b8320599ffb3"},"cell_type":"markdown","source":"### Model parameters"},{"metadata":{"trusted":true,"_uuid":"b8ba37654ff52b8d7d615090ba5fa60c85f322cf","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Dataset size: %s' % DATASET_SIZE)\nprint('Epochs: %s' % EPOCHS)\nprint('Learning rate: %s' % LEARNING_RATE)\nprint('Batch size: %s' % BATCH_SIZE)\nprint('Input dimension: %s' % train_df_scaled.shape[1])\nprint('Features used: %s' % train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25f481043932ddb2e57a0b7199bcb42d4a11c44e","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14ddb39832ed9661b987abaed3a3a0d4397a1fe2"},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true,"_uuid":"e0d16fe6d7fcc97e819e2c1168c38565ef34267e","collapsed":true},"cell_type":"code","source":"history = model.fit(x=train_df_scaled, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, \n                    verbose=1, validation_data=(validation_df_scaled, validation_labels), \n                    shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"034ee7cc55876cb8fbb4d030b988074b68ff5c97"},"cell_type":"markdown","source":"### Plot metrics"},{"metadata":{"trusted":true,"_uuid":"bba904fee24ae03e106a55e77ba6e43943c35b9a","collapsed":true},"cell_type":"code","source":"plot_loss_accuracy(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb1f3931f926c01a966f17940fc134f1800ca39c","collapsed":true},"cell_type":"code","source":"# Make prediction\nprediction = model.predict(test_scaled, batch_size=128, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faca9351377875f0dbfc36306c5470d3e95e313c","collapsed":true},"cell_type":"code","source":"# output prediction\noutput_submission(test, prediction, 'key', 'fare_amount', SUBMISSION_NAME)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}