{"cells":[{"metadata":{"_uuid":"30e304a9d2243b94a01b668d7ad8ebb219e00bf8"},"cell_type":"markdown","source":"# This notebook is made to expolain how to reduce size of big CSV data and make processing faster"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport glob\nlistBigCSV = glob.glob(\"../input/NGS*csv\")\nimport os\nimport tqdm\nimport gc\nimport feather\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22679cb22cbe349c2e2ae8aeb2d2cbb30544a902"},"cell_type":"markdown","source":"## Downcasting for smaller dataset\nLet's load the first dataset.\nWe can us C engine to load faster those big files and take pandas function memory_usage to see what we gain. \nA conversion from bytes to megabytes is needed. So a division by 1024 ** 2 is need."},{"metadata":{"trusted":true,"_uuid":"40ddcc860974234dd3147f7d57b3659716472cd3"},"cell_type":"code","source":"def memory(df):\n    if isinstance(df,pd.DataFrame):\n        value = df.memory_usage(deep=True).sum() / 1024 ** 2\n    else: # we assume if not a df it's a series\n        value = df.memory_usage(deep=True) / 1024 ** 2\n    return value, \"{:03.2f} MB\".format(value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a73578b0bafe6363c1051372e45f6b630d14ef74"},"cell_type":"code","source":"df = pd.read_csv(listBigCSV[2], engine='c')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"754e1a465650e174cae09d06b73fed6697eecc96"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3188a201153df5e710bbc7803714c30645c527a"},"cell_type":"markdown","source":"What kind of types do we have ?"},{"metadata":{"trusted":true,"_uuid":"ab1e16f3f10898fb4142704b3df92fe7f4c63c9b"},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33c15dba66c0f9bb69ea48ad13ab8457c8e3db4b"},"cell_type":"markdown","source":"We can select int64 and make them matching both uint8 which takes 1 byte or uint16 (2 bytes).\nSelecting them and applying a smaller types gives:"},{"metadata":{"trusted":true,"_uuid":"67ddf4a9b6a4d7f9afbff086d72eeadd124d1bfc"},"cell_type":"code","source":"dfIntSelection = df.select_dtypes(include=['int'])\ndfConverted2int = dfIntSelection.apply(pd.to_numeric,downcast='unsigned')\nmemInt, memIntTxt=  memory(dfIntSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2int)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"636be56766a125ee4918d89bbbce7cbd5a7e92fc"},"cell_type":"code","source":"dfConverted2int.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fee0b5f78e3ae7451e988bbb8b90d58cf9268a6e"},"cell_type":"markdown","source":"A gain of 400% is observed. Wich really good !\nInteger might also be seen as category. It may be intersting if a convertion to a category is a better choice."},{"metadata":{"trusted":true,"_uuid":"d0a7231f7b903cc957cf77173b93bf1471fbdec5"},"cell_type":"code","source":"dfIntSelection = df.select_dtypes(include=['int'])\ndfConverted2int = dfIntSelection.astype('category')\nmemInt, memIntTxt=  memory(dfIntSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2int)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2c6833072d86e5f8401f653a885b2c342b4292b"},"cell_type":"markdown","source":"We gain 600%  ! We can apply this methods on float too and downcast them to float."},{"metadata":{"trusted":true,"_uuid":"c721b2c1370b5d8ea10877cea2665790f383ca39"},"cell_type":"code","source":"dfFloatSelection = df.select_dtypes(include=['float'])\ndfConverted2float = dfFloatSelection.apply(pd.to_numeric,downcast='float')\nmemInt, memIntTxt=  memory(dfFloatSelection)\nmemIntDownCast, memIntDownCastTxt = memory(dfConverted2float)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc892a1f6a6860eebf2b33265ad92c7695026cd1"},"cell_type":"markdown","source":"Again, the gain is about 200% !"},{"metadata":{"_uuid":"acc3d00d21d910a14d3e17b95733bf99654e8b27"},"cell_type":"markdown","source":"There is two types left: Time and Event.\nFirst can be converted to date time. The second might be a category. "},{"metadata":{"trusted":true,"_uuid":"88033b84a63bcaa83b5801e25844987e6d8d4447"},"cell_type":"code","source":"dfTime = df.Time \ndate_format = '%Y-%m-%d %H:%M:%S.%f'\ndfTime = pd.to_datetime(dfTime,format=date_format)\n\nmem, memTxt = memory(dfTime)\nmemConv, memConvTxt = memory(dfTime)\n\nprint(memTxt)\nprint(memConvTxt)\nprint('Gain: ', mem/memConv *100.0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"212156e1a2d931381d953ff09803792465228c09"},"cell_type":"markdown","source":"We gain more than 1000% converting it."},{"metadata":{"trusted":true,"_uuid":"dc0de7188b2d27b3f28bb26390f7fcb43bc70581"},"cell_type":"markdown","source":"# Do we need to do a special function for this ?\nPandas provides a way to give data types upfront while reading csv file. So we can use it. "},{"metadata":{"trusted":true,"_uuid":"969114c8e6a7ef71ebc8be3e846394f3ce8b2050"},"cell_type":"code","source":"dtypes = df.drop('Time',axis=1).dtypes\n\ndtypes_col = dtypes.index\ndtypes_type = [i.name for i in dtypes.values]\n\ncolumn_types = dict(zip(dtypes_col, dtypes_type))\npreview = first2pairs = {key:value for key,value in list(column_types.items())[:10]}\nimport pprint\npp = pp = pprint.PrettyPrinter(indent=4)\npp.pprint(preview)\ndfDownCast =pd.read_csv(listBigCSV[2],dtype=column_types,parse_dates=['Time'], infer_datetime_format=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"_uuid":"ac31555e23cde0f28d2496070157100a77fe5fc6"},"cell_type":"code","source":"dfDownCast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99f16ad3b5744d35c750ca13aa869aa58f855f5"},"cell_type":"code","source":"memInt, memIntTxt=  memory(df)\nmemIntDownCast, memIntDownCastTxt = memory(dfDownCast)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"378b0cfbfdad95b3afd75511e6070d4448857bbd"},"cell_type":"code","source":"dfDownCast.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dd09edaf807cddc43688bc7bdff4a3ff09fa89a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79967c93bf1abf53069cf2233e7e79decebf63af"},"cell_type":"code","source":"def downCast(df):\n    date_format = '%Y-%m-%d %H:%M:%S.%f'\n    converted_obj = df.select_dtypes(include=['int']).astype('category')\n    df[converted_obj.columns] = converted_obj\n    converted_obj = df.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='float')\n    df[converted_obj.columns] = converted_obj\n    if 'Time' in df:\n        df.Time = pd.to_datetime(df.Time,format=date_format)\n    if 'Event' in df:\n        df.Event = df.Event.astype('category')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27be18ab8e475edb1406435249eda8a7b46fd115"},"cell_type":"code","source":"dfDown = df.copy()\ndfDown = downCast(dfDown)\n\nmemInt, memIntTxt=  memory(df)\nmemIntDownCast, memIntDownCastTxt = memory(dfDown)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b6c484ba6231431af3b78b68cd2c2dd939b1ad6"},"cell_type":"markdown","source":"270% of space gain is really important. Now we can save it as pkl for the next time. And do that for every big dataset."},{"metadata":{"trusted":true,"_uuid":"6bb9f513e1c9bb314415eb400dcedfa533ab8d99"},"cell_type":"code","source":"for csvFile in listBigCSV:\n    dataframe = pd.read_csv(csvFile, engine='c')\n    dataframe = downCast(dataframe)\n    dataframe.to_pickle(os.path.basename(csvFile[:-4]+'.pkl'))\n    del dataframe","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.path.basename('../input/NGS-2016-reg-wk7-12.pkl')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"845ded703e17f2009c900f0fa491182aa2a28b09"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"965ddd1efc7cfd93813702319bebeae79262b580"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dfbf03fdd9f91a484d12a8bb79053bfd571f534"},"cell_type":"code","source":"def downCast(df):\n    date_format = '%Y-%m-%d %H:%M:%S.%f'\n    converted_obj = df.select_dtypes(include=['int']).astype('category')\n    df[converted_obj.columns] = converted_obj\n    converted_obj = df.select_dtypes(include=['float']).apply(pd.to_numeric,downcast='float')\n    df[converted_obj.columns] = converted_obj\n    if 'Time' in df:\n        df.Time = pd.to_datetime(df.Time,format=date_format)\n    if 'Event' in df:\n        df.Event = df.Event.astype('category')\n    return df\n\ndfDown = df.copy()\nconverted_obj = dfDown.select_dtypes(include=['float']).dropna(how='all').astype(np.float32)\ndfDown[converted_obj.columns] = converted_obj\n\ndfDown = dfDown[~dfDown['GSISID'].isna()]\ndfDown.Season_Year = dfDown.Season_Year.astype('int32')\ndfDown.PlayID = dfDown.PlayID.astype('int32')\ndfDown.GSISID = dfDown.GSISID.astype('int32')\ndfDown.GameKey = dfDown.GameKey.astype('int32') #7610563 7610563\ndfDown.Event = dfDown.Event.astype('category') #7610563 7610563\ndate_format = '%Y-%m-%d %H:%M:%S.%f'\ndfDown.Time = pd.to_datetime(df.Time,format=date_format)\n\nmemInt, memIntTxt=  memory(df)\nmemIntDownCast, memIntDownCastTxt = memory(dfDown)\n\nprint(memIntTxt)\nprint(memIntDownCastTxt)\nprint('Gain: ', memInt/memIntDownCast *100.0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d970cc6640a0cb4dcaa40ec920a06dd10aa9ceef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7183ddcca64b5e07dd9de6fa10a464ef038e402d"},"cell_type":"code","source":"df_list = []\nfor i in tqdm.tqdm(listBigCSV):\n    dfDown =  pd.read_csv(i, engine='c')\n    converted_obj = dfDown.select_dtypes(include=['float']).dropna(how='all').astype(np.float32)\n    dfDown[converted_obj.columns] = converted_obj\n    dfDown = dfDown[~dfDown['GSISID'].isna()]\n    dfDown.Season_Year = dfDown.Season_Year.astype('int32')\n    dfDown.PlayID = dfDown.PlayID.astype('int32')\n    dfDown.GSISID = dfDown.GSISID.astype('int32')\n    dfDown.GameKey = dfDown.GameKey.astype('int32') #7610563 7610563\n    dfDown.Event = dfDown.Event.astype('category') #7610563 7610563\n    date_format = '%Y-%m-%d %H:%M:%S.%f'\n    dfDown.Time = pd.to_datetime(dfDown.Time,format=date_format)\n    df_list.append(dfDown)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7178a48a773da76fe276b6d7c9ce8b0e8149261b"},"cell_type":"code","source":"# Merge all dataframes into one dataframe\nngs = pd.concat(df_list)\n\n# Delete the dataframe list to release memory\ndel df_list\ngc.collect()\n\n# Convert Time to datetime\n# ngs['Time'] = pd.to_datetime(ngs['Time'], format='%Y-%m-%d %H:%M:%S')\n\n# See what we have loaded\nngs.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3c6e3b5a32f959417f460c7074c0947a998d5f7"},"cell_type":"code","source":"ngs.Event = ngs.Event.astype('category')\nngs.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fcc7d0ee919dc826e713ffbabb6cc5cad50a61f"},"cell_type":"code","source":"ngs.Time = ngs.Time.astype('datetime64[ms]')\nngs.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f52e60aee5a0b4d7d74a6f7dec6f6f008ab1a978"},"cell_type":"code","source":"def calculate_speeds_2(df, dt=None, SI=False):\n    data_selected = df[['Time', 'x','y']]\n    if SI==True:\n        data_selected.x = data_selected.x / 1.0936132983\n        data_selected.y = data_selected.y / 1.0936132983\n    # Might have used shift pd function ?\n    data_selected_diff = data_selected.diff()\n    if dt==None:\n        # Time is now a timedelta and need to be converted\n        #data_selected_diff.Time = data_selected_diff.Time.apply(lambda x: (x.total_seconds()))\n        data_selected_diff['Speed'] = np.sqrt(data_selected_diff.x **2 + data_selected_diff.y **2).astype(np.float64) / data_selected_diff.Time.values.astype(np.float64)\n    else:\n        # Need to be sure about the time step...\n        data_selected_diff['Speed'] = (data_selected_diff.x **2 + data_selected_diff.y **2).astype(np.float64).apply(np.sqrt) / dt\n    #data_selected_diff.rename(columns={'Time':'TimeDelta'}, inplace=True)\n    #return data_selected_diff\n    df['TimeDelta'] = data_selected_diff.Time\n    df['Speed'] = data_selected_diff.Speed\n    return df[1:]\n\ndef get_speed_2(df):\n    df_with_speed = df.copy()\n    date_format = '%Y-%m-%d %H:%M:%S.%f'\n    sortBy = ['Season_Year', 'GameKey', 'PlayID', 'GSISID', 'Time']\n    df_with_speed.Time = pd.to_datetime(df_with_speed.Time, format =date_format)\n    df_with_speed.sort_values(sortBy, inplace=True)\n    df_with_speed = calculate_speeds_2(df_with_speed, SI=True)\n    cut_speed=100 / 9.58 # World record 9,857232 m/s for NFL\n    df_with_speed = remove_wrong_values(df_with_speed, cutspeed=cut_speed)\n    return df_with_speed\n\ndef remove_wrong_values(df, tested_columns=['Season_Year', 'GameKey', 'PlayID', 'GSISID', 'TimeDelta'], cutspeed=None):\n    dump = df.copy()\n    colums = dump.columns\n    mask = []\n    for col in tested_columns:\n        dump['shift_'+col] = dump[col].shift(-1)\n        mask.append(\"( dump['shift_\"+col+\"'] == dump['\"+col+\"'])\")\n    mask =eval(\" & \".join(mask))\n    # Keep results where next rows is equally space\n    dump = dump[mask]\n    dump = dump[colums]\n    if cutspeed!=None:\n        dump = dump[dump.Speed < cutspeed]\n    return dump","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}