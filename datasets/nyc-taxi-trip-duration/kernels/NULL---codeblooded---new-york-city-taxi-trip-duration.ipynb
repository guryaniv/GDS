{"nbformat_minor": 0, "nbformat": 4, "cells": [{"source": "## Introduction\nIn this competition, we are challenged to build a model that predicts the total ride duration of taxi trips in New York City. The primary dataset is one released by the NYC Taxi and Limousine Commission, which includes pickup time, geo-coordinates, number of passengers, and several other variables.\n\nWith this simple notebook we try to\n \n - Explore the dataset\n - Extract features\n - Build Baseline model\n\n", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "c1bce6da4606aff453dce0df662d67f036333d54", "collapsed": false, "_cell_guid": "4cea5369-ce64-44f4-8755-77cdd7a648d4"}, "outputs": [], "cell_type": "markdown"}, {"source": "%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import timedelta\nimport datetime as dt\n# from geopy.distance import vincenty, great_circle\nfrom haversine import haversine\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "3e7eace53021a688d91d5939f52569716f998397", "_cell_guid": "963845e4-1e0b-43cb-8f96-3a6cc3c65c45", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "## Data understanding", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "0f6f1d4ec879b0990c1ebbee539c8526482f33a6", "collapsed": false, "_cell_guid": "c9a9f52c-521f-4f1e-899a-3bdbb4ed9cad"}, "outputs": [], "cell_type": "markdown"}, {"source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsample_submission = pd.read_csv('../input/sample_submission.csv')", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "4b38084abfec19c85c6cdab171603ce918cce80d", "collapsed": false, "_cell_guid": "b01447cc-9e19-4099-bf5c-7f4a20f86392", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "Let's check the data files! According the data description we should find the following columns:\n\n - **id** - a unique identifier for each trip\n - **vendor_id** - a code indicating the provider associated with the trip record\n - **pickup_datetime** - date and time when the meter was engaged\n - **dropoff_datetime** - date and time when the meter was disengaged\n - **passenger_count** - the number of passengers in the vehicle (driver entered value)\n - **pickup_longitude** - the longitude where the meter was engaged\n - **pickup_latitude** - the latitude where the meter was engaged\n - **dropoff_longitude** - the longitude where the meter was disengaged\n - **dropoff_latitude** - the latitude where the meter was disengaged\n - **store_and_fwd_flag** - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server (Y=store and forward; N=not a store and forward trip)\n - **trip_duration** - duration of the trip in seconds\n\nObviously dropoff_datetime and trip_duration are only available for the train set.", "execution_count": null, "metadata": {"_execution_state": "busy", "_uuid": "e7a3414ce68fdb6b9ece942f4b73eafe3d4f2db4", "collapsed": false, "_cell_guid": "6058bd5d-b215-44d7-9f58-276a8fe608d2"}, "outputs": [], "cell_type": "markdown"}, {"source": "print('We have {} training rows and {} test rows.'.format(train.shape[0], test.shape[0]))\nprint('We have {} training columns and {} test columns.'.format(train.shape[1], test.shape[1]))\ntrain.head(2)", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "d3771b390ded751970c7f6b48832dcfd5b828631", "collapsed": false, "_cell_guid": "3422f365-f64b-465a-a6fa-2f8baac7354b", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "7580e7dda4f9221049258b4a11b9afeb921406da", "collapsed": false, "_cell_guid": "1b9eb3dc-7f16-4ad5-a39a-7c5811f4270d", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "## Sanity check", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "04e2f7531b77679aaeedd35bbf004c17cb1afcb6", "collapsed": false, "_cell_guid": "d0a81a6e-7cd2-4056-9500-38aa5834ecb1"}, "outputs": [], "cell_type": "markdown"}, {"source": "print('Id is unique.') if train.id.nunique() == train.shape[0] else print('oops')\nprint('Train and test sets are distinct.') if len(np.intersect1d(train.id.values, test.id.values))== 0 else print('oops')\nprint('We do not need to worry about missing values.') if train.count().min() == train.shape[0] and test.count().min() == test.shape[0] else print('oops')\nprint('The store_and_fwd_flag has only two values {}.'.format(str(set(train.store_and_fwd_flag.unique()) | set(test.store_and_fwd_flag.unique()))))", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "5c52bcaced95822e9524686626058144fb822e03", "collapsed": false, "_cell_guid": "65039a11-9b9c-4033-bb77-58e97ab012e9", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)\ntrain['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\ntest['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')\n", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "351937722ec85070faa0ea76a677076683594b92", "collapsed": false, "_cell_guid": "4a8d4f81-a77e-4372-9cfa-3213135f8aa4", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "train['check_trip_duration'] = (train['dropoff_datetime'] - train['pickup_datetime']).map(lambda x: x.total_seconds())\nduration_difference = train[np.abs(train['check_trip_duration'].values  - train['trip_duration'].values) > 1]\nprint('Trip_duration and datetimes are ok.') if len(duration_difference[['pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration']]) == 0 else print('Ooops.')", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "096083acbca6ff5bfa36e6fec4ccdeff141f5dfa", "collapsed": false, "_cell_guid": "3e482fcb-b538-4169-9dc1-ed98b584f0fc", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "## Feature Extraction\nLet's calculate the distance (km) between pickup and dropoff points. Currently Haversine is used, geopy has another heuristics (vincenty() or great_circle()) if you prefer.\nThe cabs are not flying and we are in New York so we could check the Manhattan (L1) distance too :) ", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "133b47114e62d6e9cd355a5a20f1f77dfbd2d540", "collapsed": false, "_cell_guid": "b994b964-debb-455e-9efb-35874a8b79ca"}, "outputs": [], "cell_type": "markdown"}, {"source": "def haversine_array(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371  # in km\n    # calculate haversine\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\ndef dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n    a = haversine_array(lat1, lng1, lat1, lng2)\n    b = haversine_array(lat1, lng1, lat2, lng1)\n    return a + b\n\n\ntrain.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\ntrain.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\ntest.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\ntest.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "ba82f706ad4c9fde07915ece0f378102829acd76", "collapsed": false, "_cell_guid": "c5e348ce-b673-437a-b6a9-b951f895cb84", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "Add datetime features.", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "ff2948fb0669423ffd72090e2187c435ca0f2664", "collapsed": false, "_cell_guid": "681f5c2d-c816-4f60-b7ae-1eddb1e22b1f"}, "outputs": [], "cell_type": "markdown"}, {"source": "train.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntrain.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_day'] = train['pickup_datetime'].dt.day\ntrain.loc[:, 'pickup_month'] = train['pickup_datetime'].dt.month\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).map(lambda x: x.total_seconds())\n\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_day'] = test['pickup_datetime'].dt.day\ntest.loc[:, 'pickup_month'] = test['pickup_datetime'].dt.month\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).map(lambda x: x.total_seconds())", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "9e4ad49c8df2763e7a231c22a38b6f4f89a43803", "collapsed": false, "_cell_guid": "1fde4f97-db7d-4299-9d6c-cc514fae37c8", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "train.loc[:, 'average_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\n# train.loc[:, 'average_speed_v'] = 1000 * train['distance_vincenty'] / train[trip_duration]\n# train.loc[:, 'average_speed_gc'] = 1000 * train['distance_great_circle'] / train[trip_duration]\ntrain.loc[:, 'average_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "f7634a2eb0a383f68b62e60d4f8541e117c344bb", "collapsed": false, "_cell_guid": "b065fea1-36fc-4172-957d-0cf5aeea60f0", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "fig, ax = plt.subplots(ncols=3, sharey=True)\nax[0].plot(train.groupby('pickup_hour').mean()['average_speed_h'], 'bo-', alpha=0.5)\nax[1].plot(train.groupby('pickup_weekday').mean()['average_speed_h'], 'go-',  alpha=0.5)\nax[2].plot(train.groupby('pickup_day').mean()['average_speed_h'], 'ro',  alpha=0.5)\nax[0].set_xlabel('hour')\nax[1].set_xlabel('weekday')\nax[2].set_xlabel('day')\nax[0].set_ylabel('average speed')\nfig.suptitle('Rush hour average traffic speed')\nplt.show()", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "28f07978a82cbcff92ae7bc16ce4e49b3beef1a6", "collapsed": false, "_cell_guid": "3d44edfe-7c41-4f40-8f41-771a18d19f6f", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "## Modeling\nFirst let's check the train test split. It helps to decide our validation strategy.", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "90a892e8c7546f8578e58840d333051a12904701", "collapsed": false, "_cell_guid": "fb168c85-d45e-485c-80b3-f8312e5eb1cb"}, "outputs": [], "cell_type": "markdown"}, {"source": "plt.plot(train.groupby('pickup_date').count()[['id']], 'o-', label='train')\nplt.plot(test.groupby('pickup_date').count()[['id']], 'o-', label='test')\nplt.title('Train and test period complete overlap.')\nplt.legend(loc=0)\nplt.ylabel('number of records')\nplt.show()", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "97485b36f58f5ab565030fccd09d95ace84df25e", "collapsed": false, "_cell_guid": "0359bf71-15a4-4baa-aa8b-5f4ab93c4a2c", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\nax[0].plot(train['pickup_latitude'].values, train['pickup_longitude'].values, 'b.',\n           label='train', alpha=0.1)\nax[1].plot(test['pickup_latitude'].values, test['pickup_longitude'].values, 'g.',\n           label='train', alpha=0.1)\nfig.suptitle('Train and test area complete overlap.')\nax[0].legend(loc=0)\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[1].legend(loc=0)\nplt.xlim([40.5, 41])\nplt.ylim([-74.5, -73.5])\nplt.show()\n", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "4c1a6bc96a1c89591248c2ab385c405f8b3b4a10", "collapsed": false, "_cell_guid": "7f5ca1d6-a4e7-451e-bc37-a4b3d86b67ce", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "Add a few average traffic speed feature. Note that if the train/test split would be time based then we could not use as much temporal features. In this competition we do not need to predict the future.", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "78a8718f83ca0a39f71782ca19f1370216441866", "collapsed": false, "_cell_guid": "4d7155fb-712f-4375-8a94-dbf99ad1363b"}, "outputs": [], "cell_type": "markdown"}, {"source": "for gby_col in ['pickup_hour', 'pickup_day', 'pickup_date', 'pickup_weekday']:\n    gby = train.groupby(gby_col).mean()[['average_speed_h', 'average_speed_m']]\n    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n    test = pd.merge(test, gby, how='left', left_on=gby_col, right_index=True)", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "ec8fab7f992ad219dbcc7f26eb349b5fc401cb36", "collapsed": false, "_cell_guid": "dae778cc-9bc0-4ce8-b741-eea105c90de4", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "train['trip_duration'].describe()\n", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "bb47556c603362b7c6a674df06c03199406e3144", "collapsed": false, "_cell_guid": "d0d5a059-6c46-49da-b02e-f63818530bf4", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "We can see that the max trip_duration is ~ 1000 hours. Fortunately the evaluation metric is RMSLE and not RMSE . Outliers will cause less trouble. We could logtransform our target label and use RMSE during training.", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "c8df5a172e1f7e94f32362bf00eb6292cb9a9ecb", "collapsed": false, "_cell_guid": "0a66dd82-f05c-4345-b9de-3d3462a2a666"}, "outputs": [], "cell_type": "markdown"}, {"source": "feature_names = list(train.columns)\ndo_not_use_for_training = ['id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration',\n                           'check_trip_duration', 'pickup_date', 'average_speed_h', 'average_speed_m']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nprint(feature_names)\ntrain[feature_names].count()\n\ny = np.log(train['trip_duration'].values + 1)\nplt.hist(y, bins=100)\nplt.xlabel('log(trip_duration)')\nplt.ylabel('number of train records')\nplt.show()", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "06b96f6c26f9ff746a7ec33957a271663f068ed5", "collapsed": false, "_cell_guid": "05de35e8-ef1f-47f9-b45a-34052fbba065", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\ndtrain = xgb.DMatrix(Xtr, label=ytr)\ndvalid = xgb.DMatrix(Xv, label=yv)\ndtest = xgb.DMatrix(test[feature_names].values)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "d0b202b2ac59d5db5dbb34eef71597c0b2906cd6", "collapsed": false, "_cell_guid": "07c65e11-2b79-447e-b8c1-f40cf228322d", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "xgb_pars = {'min_child_weight': 10, 'eta': 0.2, 'colsample_bytree': 0.5, 'max_depth': 10,\n            'subsample': 0.95, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "2ed83f5725aceaf8d7a5855d273a8f8d3a200543", "collapsed": false, "_cell_guid": "00790795-2654-48ed-af00-8bbf4ebfe23f", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "model = xgb.train(xgb_pars, dtrain, 400, watchlist, early_stopping_rounds=50,\n                  maximize=False, verbose_eval=50)", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "e196a75edbce65a00e2e56cd6e0464c49ac22d50", "collapsed": false, "_cell_guid": "82bdf391-0394-4dc3-bf89-0ff7a91574fd", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "ypred = model.predict(dvalid)\nplt.scatter(ypred, yv, alpha=0.1)\nplt.xlabel('log(prediction)')\nplt.ylabel('log(ground truth)')\nplt.show()\n\nplt.scatter(np.exp(ypred), np.exp(yv), alpha=0.1)\nplt.xlabel('prediction')\nplt.ylabel('ground truth')\nplt.show()", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "c1beacedee75e5823383897573d71fa20c28049c", "collapsed": false, "_cell_guid": "08e78125-5837-41cb-bd0a-58cbf814c31e", "trusted": false}, "outputs": [], "cell_type": "code"}, {"source": "Let's try our first submission.", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "73695e4c1f464998b8c444dff4b91732366a5ad8", "collapsed": false, "_cell_guid": "85870431-7fc5-41c5-ab96-a633bd83a16b"}, "outputs": [], "cell_type": "markdown"}, {"source": "ytest = model.predict(dtest)\nprint((test.shape, ytest.shape))\ntest['trip_duration'] = np.exp(ytest)\ntest[['id', 'trip_duration']].to_csv('first_submission.csv', index=False)", "execution_count": null, "metadata": {"_execution_state": "idle", "_uuid": "bd89e8c38aadd146dca953dfa5131c8cbbbe4ca3", "collapsed": false, "_cell_guid": "3c32d9c2-db22-444a-ab12-32918dd2797a", "trusted": false}, "outputs": [], "cell_type": "code"}], "metadata": {"language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}}