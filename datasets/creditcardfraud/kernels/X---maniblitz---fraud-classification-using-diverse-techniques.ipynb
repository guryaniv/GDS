{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # Import for model plotting\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import classification_report\nfrom matplotlib.ticker import PercentFormatter\nimport hdbscan\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/creditcard.csv')\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cc7ddc29d49c71d51eeb27921616ea167388315"},"cell_type":"markdown","source":"# Dataset evaluation\n\nFor the purpose of this analysis, I decided to go for a simple Kmeans clustering along with an HDBSCAN clustering to define the data that are classified as fraud and those thare aren't. To do so, we must first understand the general idea behind the dataset and identify the particularities of the dataset.\n\n## Negative and positive values\n\nWe first classify the values by positive and negative to see what percentage of each category represent:\n"},{"metadata":{"trusted":true,"_uuid":"7c1dccf96964de4108a0ea868daf3c2c4bef92dd"},"cell_type":"code","source":"classification = data['Class'].value_counts()\nprint(classification)\nN = 2\ny_values = classification.values\nx_values = [0,1]\nind = np.arange(N)\nplt.bar(x_values,y_values)\nplt.xticks(ind, ('0','1'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bcb2673b91fa0445b26a647b7440233795053a0"},"cell_type":"markdown","source":"## Data points distribution\n\nWe want to know what is the general distribution of the different features. To do so, we will simply associate the different values present in the features table, flatten the whole set and compute a frequency plot. "},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"_uuid":"b01c2916647e37dd3c98d84bd38cc02c09fa36bf"},"cell_type":"code","source":"value_plot = []\ncols_names = ['V'+str(i) for i in range(1,29)]\nn_bins = 1000\n\nvalues_set = data.iloc[:, 1:29].values\nvalues = np.array(values_set).flatten()\n\n\nplt.hist(values,bins=n_bins)\nplt.xlim(-5, 5)\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38a8183830778aa11c1ef645150c0fe35106ebe3"},"cell_type":"markdown","source":"## Model configuration\n\nNow that our distribution is proposed and displayed, we need to define both our Kmeans and HDBScan models. The advantage that we have with kmeans is the fact that the number of classes is already defined. One disadvantage of HDBScan is the fact that the number of classes will be automatically defined through density and linkage analysis, meaning that it may result in more classes that expected.\n\n### KMEANS model"},{"metadata":{"trusted":true,"_uuid":"dfa79f21837ad8d2510a54cca8af760320836b19"},"cell_type":"code","source":"number_cluster = 2    # We have a fixed number of clusters\nrandom_state = 23     # We define a seed for our random state for result reproduction\n\ndef kmeans_evaluation(values_set,number_clusters=2,random_state=23,n_init=100,number_iterations = 10000,tol=0.00001):\n    y_pred = KMeans(n_clusters=number_clusters, verbose=2, random_state=random_state,max_iter=number_iterations,tol = tol).fit_predict(values_set)\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e73b577b2ccbb8cb8ea7e21f4b278c4b37c49df4"},"cell_type":"code","source":"def acc(y_def,y_pred):\n    classification_result = classification_report(y_def, y_pred)\n    return classification_result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6055f2259b30ff24d64df9c7a7759cc3a7839666"},"cell_type":"code","source":"result = acc(data.iloc[:,-1].values,kmeans_evaluation(values_set))\nprint('\\nThe accuracy provided by kmeans =====> \\n'+str(result))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64c8f96fe77789127a951561e5c68b4ba1cfc243"},"cell_type":"markdown","source":"We discover that our kmeans model provides very poor results with a classification of 47.37%. This is really low accuracy, meaning that the model cannot be used for classification purposes. Now we try another unsupervised classification algorithm that is more complex than kmeans and uses linkage and density to increase the quality of the classification.\n\n### HDBSCAN model"},{"metadata":{"trusted":true,"_uuid":"0a324809a3d2703effdf09ca335215bcd70d9049"},"cell_type":"code","source":"def hdbscan_evaluation(values_set,number_clusters=2,random_state=23,n_init=100,number_iterations = 10000,tol=0.00001):\n    y_pred = hdbscan.HDBSCAN().fit(values_set)\n    return y_pred.labels_\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b576c5bff62cc2f78726f335b293d7c0ba290cc0"},"cell_type":"code","source":"#result = acc(data.iloc[:,-1].values,hdbscan_evaluation(values_set))\n#print('\\nThe accuracy provided by kmeans =====> '+str(result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60ee989d2747e297c91da531d4a94205269e1d40"},"cell_type":"markdown","source":"Our accuracy provided by HDBSCAN is not better than the accuracy provided by kmeans. In effect, for this type of exercise, having a predefined number of labels helps for the clustering. Not all elements can be classified using a similarity of patterns such as distance. In this case, we need to see what is the mathematical or even non linear relationship between the different elements analyzed to see what is their influence in the determination of fraud. This is why we go for the next set of models that will be linear regression and logistic regression. Before doing so, we need to define a kfold cross validation that will be used throughout the system for results consistency and statistical validity.\n\n### Kfold cross validation\n\n"},{"metadata":{"trusted":true,"_uuid":"e63842e52f1283dd14a021325cda824735037e97"},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n# We decide to define 5 folds as we have a small size dataset\n\nn_folds = 5\nkf = KFold(n_splits=n_folds)\nfolds = kf.split(values_set)\n\n# Hence we defined our separation for training and testing. This will be used for training and testing\n# It will be applied for the training and testing for supervised training","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23682a9beb20f8a0e78b752f95e1f6b29d6f4258"},"cell_type":"markdown","source":"### Linear classification model"},{"metadata":{"trusted":true,"_uuid":"b1674a7080dbba9bf1f953ba12f9cf6df153caf3"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\ndef linear_reg_model(values_set,labels,test_set,test_labels):\n    regr = LinearRegression()\n    # Train the model using the training sets\n    regr.fit(values_set, labels)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(test_set)\n    y_pred[y_pred<=0.5] = 0\n    y_pred[y_pred>0.5] = 1\n    \n    return y_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca9a4e6490987807899518941f77ee08672dfa14"},"cell_type":"code","source":"labels_set = data.iloc[:,-1].values\naccuracies = []\nfor train_index, test_index in folds:\n    X_train, X_test = values_set[train_index], values_set[test_index]\n    y_train, y_test = labels_set[train_index], labels_set[test_index]\n    result = acc(y_test,linear_reg_model(X_train,y_train,X_test,y_test))\n    accuracies.append(result)\nfor accuracy in accuracies:   \n    print(accuracy)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e92d4453a7dd5dd8abd837d19d35fe777b3aac3"},"cell_type":"code","source":"values_set[:5]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dfff823397b4f1474f72024efb799969da7446f9"},"cell_type":"markdown","source":"Setting our threshold to 0.5, we have a training accuracy of 99.89%. For the testing, we have the highest accuracy recorded at 99.91%, hence setting a record in term of classification performance. Now that our linear classification has been set, we can go ahead and work with another classification method called logistic regression. This is another regression problem that define the probabilistic capacity of each entity using a sigmoid function. For this one, we will also implement an ROC curve to determine what threshold provide the best separation for the true positive and true negative values.\n\n### Logistic regression"},{"metadata":{"trusted":true,"_uuid":"5e836a42bc5e2f34dbf693538fa6a9a79dd31363"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve\n\ndef logistic_reg_model(x_train,x_test,y_train,y_test,iterations,tolerance):\n    rt_lm = LogisticRegression(solver='lbfgs',verbose=2, max_iter=iterations,tol = tolerance)\n    rt_lm.fit(X_train, y_train)\n    y_pred = rt_lm.predict_proba(X_test)[:,1]\n    fpr_rt_lm, tpr_rt_lm, threshold = roc_curve(y_test, y_pred)\n    \n    i = np.arange(len(tpr_rt_lm)) \n    roc = pd.DataFrame({'tf' : pd.Series(tpr_rt_lm-(1-fpr_rt_lm), index=i), 'threshold' : pd.Series(threshold, index=i)})\n    roc_t = roc.ix[(roc.tf-0).abs().argsort()[:1]]\n\n    optimal_threshold = list(roc_t['threshold'])[0]\n    \n    y_pred[y_pred<=optimal_threshold] = 0\n    y_pred[y_pred>optimal_threshold] = 1\n    \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.plot(fpr_rt_lm, tpr_rt_lm, label='Logistic Regression')\n    plt.xlabel('False positive rate')\n    plt.ylabel('True positive rate')\n    plt.title('ROC curve')\n    plt.legend(loc='best')\n    plt.show()\n    \n    return optimal_threshold, y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02470dda733af989fc04c477aabb3b5d53433280"},"cell_type":"code","source":"n_folds = 5\nkf = KFold(n_splits=n_folds)\nlr_folds = kf.split(values_set)\niterations = 1000\ntolerance = 0.01\n\naccuracies = []\nthresholds = []\nfor train_index, test_index in lr_folds:\n    X_train, X_test = values_set[train_index], values_set[test_index]\n    y_train, y_test = labels_set[train_index], labels_set[test_index]\n    threshold, model_pred = logistic_reg_model(X_train,X_test,y_train,y_test,iterations,tolerance)\n    result = acc(y_test,model_pred)\n    accuracies.append(result)\n    thresholds.append(threshold)\n    \nfor accuracy in accuracies:\n    print(accuracy)\nprint(thresholds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae4d010938345c14e3d212c7d4ea31b1526ece98"},"cell_type":"markdown","source":"For our logistic regression, we concluded with a threshold close from 0.001 with a median accuracy of 91.5%. This result proves that we can use logistic regression and end up with satisfying results. Now that we are done with out linear models, we want to define classifiers using Neural Networks, CNN and Reinforcement Networks. They will be for most of them pretty simple and used for simple binary classification. The framework used is Keras. It offers the possibility to work on the GPU but we will focuss on working strictly with the CPU.\n\n### Simple Neural Network"},{"metadata":{"trusted":true,"_uuid":"9f5db227c33dc672a6c5e2ca4d0da97eff1b841c"},"cell_type":"code","source":"# Important Keras Imports\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom sklearn.utils import class_weight\n\n# We define our hyperparameters that will be used in the different models\n\nlearning_rate = 0.000025\nbatch_size = 32\nepochs = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77874f543a254d17ad65f27398f3eafba815b280"},"cell_type":"code","source":"# In this part we define our simple neural network model\n# We decided to go for a really simple model for a start\n\ndef defineNNModel(training_data,testing_data,validation_data,training_label,testing_label,validation_label,num_classes = 2,\n               training_sample=0):\n    \n    # input image dimensions\n    img_x, img_y = 7, 4\n    \n    class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(training_label),\n                                                 training_label)\n    \n    x_train = training_data.reshape(training_data.shape[0], img_x, img_y, 1)\n    x_test = testing_data.reshape(testing_data.shape[0], img_x, img_y, 1)\n    x_validation = validation_data.reshape(validation_data.shape[0], img_x, img_y, 1)\n    \n    y_train = keras.utils.to_categorical(training_label, num_classes)\n    y_test = keras.utils.to_categorical(testing_label, num_classes)\n    y_validation = keras.utils.to_categorical(validation_label, num_classes)\n    \n    model = Sequential()\n    model.add(Flatten())\n    model.add(Dense(500,input_dim=28,activation=\"sigmoid\"))\n    model.add(Dense(1000,activation='relu'))\n    model.add(Dense(100,activation='sigmoid'))\n    model.add(Dense(2,activation='softmax'))\n    \n    model.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.SGD(lr=learning_rate),\n              metrics=['acc'])\n    \n    # Our model will use mean squared error for the estimation of loss, along with a Stochastic Gradient Descent for optimization\n    # The metric we want to gather is the accuracy, reason why we define it.\n    \n    history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(x_validation, y_validation),\n              class_weight=class_weights)\n    \n    # Plot training & validation accuracy values\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(\"NN_model_accuracy\"+str(training_sample)+'.png')\n    plt.show()\n    \n    \n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(\"NN_model_loss\"+str(training_sample)+'.png')\n    plt.show()\n    \n    print(model.summary())\n    \n    score = model.evaluate(x_test, y_test, verbose=1)\n    y_pred = model.predict_classes(x_test)\n    report = acc(testing_label,y_pred)\n    \n    return score[1], score[0], report\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92e151a7b063b92d85d37df222a348397fbaeebb"},"cell_type":"code","source":"training_cycle = 0\naccuracies_NN = []\nlosses_NN = []\n\nfor train_index, test_index in kf.split(values_set):\n    \n    print('\\n==========  TRAINING CYCLE #'+str(training_cycle)+' ==========\\n')\n    \n    data_train, data_test = values_set[train_index], values_set[test_index]\n    label_train, label_test = labels_set[train_index], labels_set[test_index]\n    \n    # We need to define the validation data and validation labels of our data train and label train\n    # We decide to take the last 100 elements of the training data as our validation data\n    \n    data_validation = data_train[-50000:]\n    label_validation = label_train[-50000:]\n    \n    # We go for our NN model\n    accuracy_nn, loss_nn, report = defineNNModel(data_train,data_test,data_validation,label_train,label_test,label_validation,training_sample=training_cycle)\n    accuracies_NN.append(accuracy_nn)\n    losses_NN.append(loss_nn)\n    print(report)\n    \n    training_cycle+=1   # We update the training iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43bbfbb8ef7cded1d51e371b7bda5490e9b6ac2d"},"cell_type":"markdown","source":"### Convolutional Neural Network\n\nAny array of size N can be converted into a matrix of size NxP representing an image format. This is what we will use for the training of our convolutional neural network. The result provided should be either close or better than the one provided by the simple neural network. We will use a kernel size of 2x2 and a stride of 1"},{"metadata":{"trusted":true,"_uuid":"13c182721cd83a98b21ca8d9c0ff74b17a4b7537"},"cell_type":"code","source":"def defineCNNModel(training_data,testing_data,validation_data,training_label,testing_label,validation_label,num_classes = 2,\n                training_sample=0):\n    \n    # input image dimensions\n    img_x, img_y = 7, 4\n    \n    # reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n    # because the MNIST is greyscale, we only have a single channel - RGB colour images would have 3\n    x_train = training_data.reshape(training_data.shape[0], img_x, img_y, 1)\n    x_test = testing_data.reshape(testing_data.shape[0], img_x, img_y, 1)\n    x_validation = validation_data.reshape(validation_data.shape[0], img_x, img_y, 1)\n    input_shape = (img_x, img_y, 1)\n    \n    y_train = keras.utils.to_categorical(training_label, num_classes)\n    y_test = keras.utils.to_categorical(testing_label, num_classes)\n    y_validation = keras.utils.to_categorical(validation_label, num_classes)\n    \n    class_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(training_label),\n                                                 training_label)\n    \n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(2, 2),input_shape=input_shape))\n    # We first define a convolutional layer with 32 output vectors. The kernel size is set to be 2 by 2\n    # The input shape is the same as out image data.\n    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    # pooling is used in convolutional neural networks to make the detection of certain features \n    # in the input invariant to scale and orientation changes\n    \n    model.add(Conv2D(32, kernel_size=(3, 3),input_shape=input_shape))\n    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Flatten())\n    # We flatten our output to enter the fully connected layer\n    model.add(Dense(100,activation='sigmoid'))\n    model.add(Dense(20,activation='tanh'))\n    \n    model.add(Dense(num_classes, activation='softmax'))\n    # Softmax classification, or output layer, which is the size of the number of our classes \n    \n    model.compile(loss=keras.losses.mean_squared_error,\n              optimizer=keras.optimizers.SGD(lr=learning_rate),\n              metrics=['acc'])\n    \n    # Our model will use mean squared error for the estimation of loss, along with a Stochastic Gradient Descent for optimization\n    # The metric we want to gather is the accuracy, reason why we define it.\n    \n    history = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1,\n          validation_data=(x_validation, y_validation),\n          class_weight=class_weights)\n    \n    # Plot training & validation accuracy values\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(\"CNN_model_accuracy\"+str(training_sample)+'.png')\n    plt.show()\n    \n    # Plot training & validation loss values\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(\"CNN_model_loss\"+str(training_sample)+'.png')\n    plt.show()\n    \n    print(model.summary())\n    \n    score = model.evaluate(x_test, y_test, verbose=1)\n    y_pred = model.predict_classes(x_test)\n    report = acc(testing_label,y_pred)\n    \n    return score[1], score[0], report\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b52c7dc34e581c5b11ec1b34594f659f16a5716a"},"cell_type":"code","source":"training_cycle = 0\naccuracies_CNN = []\nlosses_CNN = []\n\nfor train_index, test_index in kf.split(values_set):\n    \n    print('\\n==========  TRAINING CYCLE #'+str(training_cycle)+' ==========\\n')\n    \n    data_train, data_test = values_set[train_index], values_set[test_index]\n    label_train, label_test = labels_set[train_index], labels_set[test_index]\n    \n    # We need to define the validation data and validation labels of our data train and label train\n    # We decide to take the last 100 elements of the training data as our validation data\n    \n    data_validation = data_train[-50000:]\n    label_validation = label_train[-50000:]\n    \n    # Now we simply apply our different models and gather their information\n    \n    # We start with the CNN model\n    accuracy, loss, report = defineCNNModel(data_train,data_test,data_validation,label_train,label_test,label_validation,training_sample=training_cycle)\n    accuracies_CNN.append(accuracy)\n    losses_CNN.append(loss)\n    print(report)\n    \n    training_cycle+=1   # We update the training iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1db33cae0913f34f903eecbe0bba57e4bdf1e0a"},"cell_type":"code","source":"accuracies_CNN_mean = np.mean(accuracies_CNN)\naccuracies_NN_mean = np.mean(accuracies_NN)\n\nprint(\"CNN Accuracy : \"+str(accuracies_CNN_mean)+\"\\nNN Accuracy : \"+str(accuracies_NN_mean))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}