{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization\n#from keras.layers.advanced_activations import LeakyReLU\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import optimizers\nfrom keras.models import load_model\nimport gc, sys\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"665af58850ceb1b3bad239913e1aff69442b1521"},"cell_type":"code","source":"def feature_engineering(is_train=True):\n    # When this function is used for the training data, load train_V2.csv :\n    if is_train: \n        print(\"processing train_V2.csv\")\n        df = pd.read_csv('../input/train_V2.csv')\n        \n        # Only take the samples with matches that have more than 1 player \n        # there are matches with no players or just one player ( those samples could affect our model badly) \n        df = df[df['maxPlace'] > 1]\n    \n    # When this function is used for the test data, load test_V2.csv :\n    else:\n        print(\"processing test_V2.csv\")\n        df = pd.read_csv('../input/test_V2.csv')\n        \n    # Make a new feature indecating the total distance a player cut :\n    df['totalDistance'] = df['rideDistance'] + df[\"walkDistance\"] + df[\"swimDistance\"]\n          \n\n    # Process the 'rankPoints' feature by replacing any value of (-1) to be (0) :\n    df['rankPoints'] = np.where(df['rankPoints'] <= 0 ,0 , df['rankPoints'])                                \n    \n\n    target = 'winPlacePerc'\n    # Get a list of the features to be used\n    features = list(df.columns)\n    \n    # Remove some features from the features list :\n    features.remove(\"Id\")\n    features.remove(\"matchId\")\n    features.remove(\"groupId\")\n    features.remove(\"matchDuration\")\n    features.remove(\"matchType\")\n    \n    y = None\n    \n    # If we are processing the training data, process the target\n    # (group the data by the match and the group then take the mean of the target) \n    if is_train: \n        y = np.array(df.groupby(['matchId','groupId'])[target].agg('mean'), dtype=np.float64)\n        # Remove the target from the features list :\n        features.remove(target)\n    \n    # Make new features indicating the mean of the features ( grouped by match and group ) :\n    print(\"get group mean feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('mean')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    \n    # If we are processing the training data let df_out = the grouped  'matchId' and 'groupId'\n    if is_train: df_out = agg.reset_index()[['matchId','groupId']]\n    # If we are processing the test data let df_out = 'matchId' and 'groupId' without grouping \n    else: df_out = df[['matchId','groupId']]\n    \n    # Merge agg and agg_rank (that we got before) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the max value of the features for each group ( grouped by match )\n    print(\"get group max feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('max')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the minimum value of the features for each group ( grouped by match )\n    print(\"get group min feature\")\n    agg = df.groupby(['matchId','groupId'])[features].agg('min')\n    # Put the new features into a rank form ( max value will have the highest rank)\n    agg_rank = agg.groupby('matchId')[features].rank(pct=True).reset_index()\n    \n    # Merge the new (agg and agg_rank) with df_out :\n    df_out = df_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId', 'groupId'])\n    df_out = df_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the number of players in each group ( grouped by match )\n    print(\"get group size feature\")\n    agg = df.groupby(['matchId','groupId']).size().reset_index(name='group_size')\n     \n    # Merge the group_size feature with df_out :\n    df_out = df_out.merge(agg, how='left', on=['matchId', 'groupId'])\n    \n    # Make new features indicating the mean value of each features for each match :\n    print(\"get match mean feature\")\n    agg = df.groupby(['matchId'])[features].agg('mean').reset_index()\n    \n    # Merge the new agg with df_out :\n    df_out = df_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n    \n    # Make new features indicating the number of groups in each match :\n    print(\"get match size feature\")\n    agg = df.groupby(['matchId']).size().reset_index(name='match_size')\n    \n    # Merge the match_size feature with df_out :\n    df_out = df_out.merge(agg, how='left', on=['matchId'])\n    \n    # Drop matchId and groupId\n    df_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n    \n    # X is the output dataset (without the target) and y is the target :\n    X = np.array(df_out, dtype=np.float64)\n    \n    \n    del df, df_out, agg, agg_rank\n    gc.collect()\n\n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84c4f0bcb2f5962c19338b852492f4fe01b28c55"},"cell_type":"code","source":"%%time\n# Process the training data :\nX, y = feature_engineering(True)\n# Scale the data to be in the range (-1 , 1)\nscaler = preprocessing.MinMaxScaler(feature_range=(-1, 1), copy=False).fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a647474b4597c7bbe04cf3d8ad1c3c1d2347c1e"},"cell_type":"code","source":"print(\"X\", X.shape, X.max(), X.min())\nscaler.transform(X)\nprint(\"X\", X.shape, X.max(), X.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11b9c19cd04890e490bc925ca8cfd6165fcf29fb"},"cell_type":"code","source":"y = y * 2 - 1\nprint(\"y\", y.shape, y.max(), y.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21f3f9098476487bc62000efb53f5e69e18a71e4"},"cell_type":"code","source":"#Let's build a model\nmodel = Sequential()\nmodel.add(Dense(X.shape[1], input_dim=X.shape[1], activation='relu'))\n#model.add(LeakyReLU(0.1))\n#model.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\n#model.add(LeakyReLU(0.1))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128, activation='relu'))\n#model.add(LeakyReLU(0.1))\n#model.add(BatchNormalization())\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(0.1))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1, activation='linear'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b618a56f185180deb6ff799217e63488e2c3ce3d"},"cell_type":"code","source":"optimizer = optimizers.Adam(lr=0.01, epsilon=1e-8, decay=1e-4, amsgrad=False)\n\nmodel.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n\ncheckpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \ncheckpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bc520eefada5d2cda94fab75e0285c62e2052c8"},"cell_type":"code","source":"history = model.fit(x=X, y=y, batch_size=1000,\n             epochs=20, verbose=1, callbacks=callbacks_list,\n             validation_split=0.2, validation_data=None, shuffle=True,\n             class_weight=None, sample_weight=None, initial_epoch=0,\n             steps_per_epoch=None, validation_steps=None)\n\ndel X, y\n#gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71078d6b03176ae95bae8e86c804c0dc7d4cb9e7"},"cell_type":"code","source":"# Plot training & validation loss values\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot training & validation mae values\nplt.plot(history.history['mean_absolute_error'])\nplt.plot(history.history['val_mean_absolute_error'])\nplt.title('Mean Absolute Error')\nplt.ylabel('Mean absolute error')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09f2ab3466082bb4c879a188d48bffb783f590c2"},"cell_type":"code","source":"#Processing test data\nX, _ = feature_engineering(False)\nscaler.transform(X)\nprint(\"x_test\", X.shape, X.max(), X.min())\nnp.clip(X, out=X, a_min=-1, a_max=1)\nprint(\"x_test\", X.shape, X.max(), X.min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a93f4a3b7fac6ee6e3e46378a3f1e56c6733e278"},"cell_type":"code","source":"%%time\npred = model.predict(X)\ndel X\npred = pred.reshape(-1)\npred = (pred + 1) / 2\n\n# pred = (pred + 1) / 2\ndf_test = pd.read_csv('../input/test_V2.csv')\n\n\nprint(\"Correcting winPlacePerc\")\nfor i in range(len(df_test)):\n    winPlacePerc = pred[i]\n    maxPlace = int(df_test.iloc[i]['maxPlace'])\n    if maxPlace == 0:\n        winPlacePerc = 0.0\n    elif maxPlace == 1:\n        winPlacePerc = 1.0\n    else:\n        gap = 1.0 / (maxPlace - 1)\n        winPlacePerc = round(winPlacePerc / gap) * gap\n    \n    if winPlacePerc < 0: winPlacePerc = 0.0\n    if winPlacePerc > 1: winPlacePerc = 1.0    \n    pred[i] = winPlacePerc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9b574d253bbd9099b513044c24dd058dea38d4c"},"cell_type":"code","source":"df_test['winPlacePerc'] = pred\nsubmission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}