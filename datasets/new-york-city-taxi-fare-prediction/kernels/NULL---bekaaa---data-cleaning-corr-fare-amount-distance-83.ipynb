{"cells":[{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1340e91d6a7f014cc07aeb3d526f7758486bffc9"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport geopy.distance\nimport dask.dataframe as dd\nfrom dask.multiprocessing import get","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acef2b6bf56baa04a08d23a57a7285d5f4517dc7"},"cell_type":"code","source":"! ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"f095f8211fffcaa78715624426c8b687adbf99c0"},"cell_type":"code","source":"%%time\ndata = pd.read_csv('../input/train.csv', nrows=int(2e7))\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bc2e35d714240afed06aa3bcad3d14f29a34732"},"cell_type":"markdown","source":"## Drop NA"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"7cf756e4f0fa1ece459e52323a426c3c308f119f"},"cell_type":"code","source":"data.dropna(inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14238c6ed3ba4ca0fb97ed15fdb581d15f805b20"},"cell_type":"markdown","source":"# Cleaning : "},{"metadata":{"_uuid":"73c9ef56acc3c499ae15af0206d997da14f5746c"},"cell_type":"markdown","source":"## Latitudes, longitudes and distance"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"cc27a92d8bf54d761dad2cb6a8e8699a76448e61"},"cell_type":"code","source":"# drop data with lat/lon outside of newyork range\n# range are calculated through this link : https://www.mapdevelopers.com/geocode_bounding_box.php\n\nny_lat_min =  40.477399\nny_lat_max = 40.917577\nny_lon_max = -73.700272\nny_lon_min =  -74.259090\n#--------------------------------------------\nindices_to_drop = data[(data.pickup_latitude < ny_lat_min) | (data.pickup_latitude > ny_lat_max) |\n                      (data.dropoff_latitude < ny_lat_min) | (data.dropoff_latitude > ny_lat_max)|\n                      (data.pickup_longitude < ny_lon_min) | (data.pickup_longitude > ny_lon_max) |\n                      (data.dropoff_longitude < ny_lon_min) | (data.dropoff_longitude > ny_lon_max)].index\nprint (len(indices_to_drop))\n#----------------------------------------------\ndata.drop(index=indices_to_drop, inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"342b98750b015d6afa261dbe89d380a5f3c5dfe4"},"cell_type":"code","source":"%%time\n# Compute Distance using geopy.. [6 cores/ 6 partitions and 20M rows takes ~ 25 minutes]\ncols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude']\nddata = dd.from_pandas(data[cols], npartitions=4)\n\ndef compute_distance(lat1, lon1, lat2, lon2):\n    return round(geopy.distance.distance((lat1,lon1), (lat2, lon2)).km,2)\n\ndata['distance'] = ddata.map_partitions(lambda df: df.apply((lambda row: compute_distance(*row)), axis=1))\\\n    .compute(get=get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9ab49658440e8b92d08fcd697103a56b51f4f010"},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a8d3feb416ffa3f0092178f1c082827c437459c9"},"cell_type":"code","source":"%%time\n#data.to_hdf('./data/v2/sample_dist_2M.hdf', key='sample_dist_2M')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07966e5fbe76810810608f40657687e0f6f621dc"},"cell_type":"markdown","source":"## Passengers count"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"1d6b1ccb5747d43acc64426dcf0ca9f76e178b72"},"cell_type":"code","source":"# for a normal taxi the maximum number of passenger would be 4 or 5,\n# maybe for a larger cap with two large backseats it would be 7. \n# I'll drop any columns with passenger larger than 7 or lower than 1 ( so obvious.)\n\nindices_to_drop = data[(data.passenger_count < 1) | (data.passenger_count > 7)].index\nprint (len(indices_to_drop))\n#-----------------------------------\ndata.drop(index=indices_to_drop, inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"67b42df8007b752b939ad0eb730a46cd458e36ca"},"cell_type":"code","source":"# drop outliers also\nQ1 = data.passenger_count.quantile(q=.25)\nQ3 = data.passenger_count.quantile(q=.75)\nIQR = Q3 - Q1\nlower = Q1 - 1.5 * IQR\nupper = Q3 + 1.5 * IQR\nprint('Q1 = {}, Q3 = {}, IQR = {},\\nlower limit = {}, upper limit = {}'\\\n     .format(Q1,Q3,IQR,lower,upper))\n#--------------------\n# But instead i'll drop > .05% and < .95% so I keep as many rows as possible.\nlower = data.passenger_count.quantile(.05)\nupper = data.passenger_count.quantile(.95)\nprint('.05 quantile = {}, .95 quantile = {}'.format(lower, upper))\n#-----------\nindices_to_drop = data[(data.passenger_count < lower)|(data.passenger_count > upper)].index\nprint('number of indices to drop : ', len(indices_to_drop))\n#------------\ndata.drop(index=indices_to_drop, inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77fe457bb8d6384b0f129f353e97d4abc2ff2a2c"},"cell_type":"markdown","source":"## Fare Amount"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2890ee682ac97af73057a0341723bae208c82d60"},"cell_type":"code","source":"# first delete all negative/zero fare_amount as they won't be real\nindices_to_drop = data[data.fare_amount <= 0].index\nprint (len(indices_to_drop))\n#---------------------\ndata.drop(index=indices_to_drop, inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"758b3c4d529e451f979d52f169bb6339f8dcd9bd"},"cell_type":"code","source":"# drop fare_amount outliers also\nQ1 = data.fare_amount.quantile(q=.25)\nQ3 = data.fare_amount.quantile(q=.75)\nIQR = Q3 - Q1\nlower = Q1 - 1.5 * IQR\nupper = Q3 + 1.5 * IQR\nprint('Q1 = {}, Q3 = {}, IQR = {},\\nlower limit = {}, upper limit = {}'\\\n     .format(Q1,Q3,IQR,lower,upper))\n#----------------------\n# and here also i'll drop .05 and .95\nlower = data.fare_amount.quantile(.05)\nupper = data.fare_amount.quantile(.95)\nprint('.05 quantile = {}, .95 quantile = {}'.format(lower, upper))\n#--------------\nindices_to_drop = data[(data.fare_amount < lower)|(data.fare_amount > upper)].index\nprint('number of rows to drop : ', len(indices_to_drop))\n#--------------------------\ndata.drop(index=indices_to_drop, inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"901ad06ee529ff8257e435d4318c7c7f901cbc34"},"cell_type":"markdown","source":"--------------------"},{"metadata":{"_uuid":"f55948de8133263a0843eb9f3c70c01d1eb9e4c9"},"cell_type":"markdown","source":"## Date and Time"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"12758e3655dce8920d00fb7ab93bbe2606435348"},"cell_type":"code","source":"%%time\n\nyear = data.pickup_datetime.apply(lambda d: d[:4])\nmonth = data.pickup_datetime.apply(lambda d: d[5:7])\nhour = data.pickup_datetime.apply(lambda d: d[11:13])\n\nyear = year.astype(int)\nmonth = month.astype(int)\nhour = hour.astype(int)\n\ndata['year'] = year\ndata['month'] = month\ndata['hour'] = hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"2fbb92cdf136c579426cee10609c337bf81b45b9"},"cell_type":"code","source":"data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"20e8bfc52168343ab332f6f1b1903dac375139ed"},"cell_type":"code","source":"%%time\n#data.to_hdf('./data/v2/sample_dist_2M_ready.hdf', key='sample_dist_2M_ready')\n#or\n#data = pd.read_hdf('./data/v2/sample_dist_2M_ready.hdf')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ca225a64ced590a006be22e09551e3c19834ede"},"cell_type":"markdown","source":"------------"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"ccef937d251c0a668fcd07854737e0242ea17358"},"cell_type":"code","source":"data.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8063934f7cac1de4cfca13cd6115b73327253cc7"},"cell_type":"markdown","source":"Looking at the correlation here, we find that : \n1. there is a big correlation between fare_amount and distance.\n2. passenger_count has 0 correlation and that makes sense as the number of passenger doesn't count in fare_amount.\n3. both longitudes have a small corr that maybe usefull.\n4. on the other hand the two latitudes have no correlation.\n5. Month and hour have no high corr with any other columns.\n6. Year has a little corr with fare_amount and it make sense as prices changes over years.\n\n---------\n\nFor further work I recommend keeping only the columns :\n    ( fare_amount, pickup_longitude, dropoff_longitude, distance, year)\n\n\n-----------------\n\nOne last thing, I'd like to point that I reduced the 20M rows to 17,250,037."},{"metadata":{"_uuid":"d59ef22813a923013215561a2e543be1fef661a4"},"cell_type":"markdown","source":"----------"},{"metadata":{"_uuid":"cadc583867f1b75989ecfaf2ab846950fc5e7c07"},"cell_type":"markdown","source":"# Keeping relevant columns for the Model :"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"47de47b12668bba053b3eab78aa578609dbde955"},"cell_type":"code","source":"cols_to_keep = ['fare_amount', 'pickup_longitude', 'dropoff_longitude', 'distance', 'year']\n\ndata = data[cols_to_keep]\n\ndata.rename(columns={'fare_amount':'target',\n            'pickup_longitude':'pickup',\n            'dropoff_longitude':'dropoff'}, inplace=True)\nprint(data.shape)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c82a2fcb9d466c57aca7ae671cb46f40a2ca1d47"},"cell_type":"markdown","source":"# Standarization and Normalization"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"db0b242a6d19a75f1c88c360121fc3313a36f3ba"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"3919d03cfd3dc54a0c8d825449322991e3b199f7"},"cell_type":"code","source":"%%time\nscaler = MinMaxScaler()\nscaled_data = data.copy()\ncols = ['pickup', 'dropoff', 'distance', 'year']\nscaled_data[cols] = scaler.fit_transform(data[cols])\n\n#scaled_data.target = np.log1p(data.target) # remember to convert the results using np.expm1()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"e999895b422e704171c6337354110583875e9c59"},"cell_type":"code","source":"scaled_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"925ba91e4fc3ec4bdc0a8a99c8fedbb7dbf39104"},"cell_type":"code","source":"%%time\n#scaled_data.to_hdf('./data/v2/ready_scaled_20M.hdf', 'ready_scaled_20M')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"4e922c0e0b7634763e554ac8fbb50667ab5e5ca2"},"cell_type":"code","source":"scaled_data.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"937126a98f44f945b0902ea266713cdc6cc769ae"},"cell_type":"markdown","source":"-----"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"820723b345d16f83c2a9ec40f2bc54d6d9b73386"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":1}