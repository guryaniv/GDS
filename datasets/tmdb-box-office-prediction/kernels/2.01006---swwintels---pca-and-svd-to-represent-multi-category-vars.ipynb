{"cells":[{"metadata":{"_uuid":"b2d3c255b2ec63f1299b9afbd198fa49acfa4f3b"},"cell_type":"markdown","source":"This notebook follows a similar approach, and steals with pride from the follow notebooks:\n* https://www.kaggle.com/zero92/stacking-xgb-lgbm-cat-authorized-variable. Thanks B H for the model set-up\n* https://www.kaggle.com/shubhammank/tmdb-eda. Thanks Shubham for the data cleaning functions\n\nThe real novel thing I'm doing is to  create multi-hot encodings for the genres, keywords, crew and cast using PCA (where number of unique categories is limited) or SVD with sparse matrices\n\nI hope this helps others improve their models. Please steal back with pride :)"},{"metadata":{"trusted":true,"_uuid":"f13586e4c24c7f8d3652c14432bbd016070a5ed0"},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8429380bc79b306dcc667f1932f84992429790f"},"cell_type":"code","source":"from fastai.tabular import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\nimport time\n\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport ast\n\nfrom sklearn.metrics import mean_squared_error\n\nimport seaborn as sns\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98601b93ce4fca286f34d18be346cce3c8f5fef3"},"cell_type":"code","source":"PATH = \"../input/tmdb-box-office-prediction/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17bce5d527c09428f38f16f33450bb28b091c07f"},"cell_type":"code","source":"train = pd.read_csv(f'{PATH}train.csv', parse_dates=['release_date'])\ntest = pd.read_csv(f'{PATH}test.csv', parse_dates=['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4594ddf86480885edc32cf14bf36c090297259"},"cell_type":"code","source":"train_votes = pd.read_csv('../input/tmdb-prediction-votes/trainRatingTotalVotes.csv')\ntest_votes = pd.read_csv('../input/tmdb-prediction-votes/testRatingTotalVotes.csv')\ntrain = pd.merge(train, train_votes, how='left', on=['imdb_id'])\ntest = pd.merge(test, test_votes, how='left', on=['imdb_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a184bdcb61172659f50e0387e5388aa8da56d355"},"cell_type":"code","source":"dict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ntrain = text_to_dict(train)\ntest = text_to_dict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d64e5a354bb647f869a04c717fd33a670f38bbdd"},"cell_type":"code","source":"def build_category_list(x, field, feature):\n    regex = re.compile('[^0-9a-zA-Z_]')\n    category_list = \"\"\n    \n    \n    for d in x:\n        new_category = regex.sub('', d[field].lower().replace(\" \",\"_\"))\n        \n        # Exception for cast: keep only 0 and 1 to limit nb of values\n        #        if feature == 'cast' and d['order'] > 1:\n        #            pass\n        #        else:\n        category_list += new_category + \",\"\n    return category_list.strip().strip(\",\").split(\",\")\n\n\ntarget_fields = {'belongs_to_collection': 'name', 'genres': 'name',\n                 'production_countries': 'iso_3166_1', 'production_companies': 'name',\n                 'spoken_languages': 'iso_639_1', 'Keywords': 'name', 'cast': 'name'\n                }\n\nfor k,v in target_fields.items():\n    train[k] = train[k].apply(lambda x: build_category_list(x, v, k))\n    test[k] = test[k].apply(lambda x: build_category_list(x, v, k))\n    \n    \ntarget_fields = {'cast':{'field':'name', 'role_field':'order', 'role_values':[0,1,2]}}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9184a0d8a2f4fe14152890f4b482468dfefcdc4c"},"cell_type":"code","source":"train.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1542,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8dd88e31bc8b5ea01d9610e16d0247ab7a75a5e4"},"cell_type":"code","source":"test.loc[test['id'] == 3889,'budget'] = 15000000       # Colossal\ntest.loc[test['id'] == 6733,'budget'] = 5000000        # The Big Sick\ntest.loc[test['id'] == 3197,'budget'] = 8000000        # High-Rise\ntest.loc[test['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\ntest.loc[test['id'] == 5704,'budget'] = 4300000        # French Connection II\ntest.loc[test['id'] == 6109,'budget'] = 281756         # Dogtooth\ntest.loc[test['id'] == 7242,'budget'] = 10000000       # Addams Family Values\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0435dad2b3ca86aae1b1e081f1f7b692a7f3547"},"cell_type":"code","source":"power_six = train.id[train.budget > 1000][train.revenue < 100]\n\nfor k in power_six :\n    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"321eb27e6967b3ccce9b8d6249ff20d928903e7a"},"cell_type":"code","source":"def multi_hot_encode(df, column_name, mlb=MultiLabelBinarizer()):\n    encoded = pd.DataFrame(mlb.fit_transform(df[column_name]))\n    encoded.columns = [f'{column_name}_{i}'.format(i) for i in mlb.classes_]\n    return mlb, encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec8c75c83fc443b81f6c158d1f21a4cc15991f0b"},"cell_type":"code","source":"def conv_column_to_SVD(df, column_name, size=10, sparse_mlb=MultiLabelBinarizer(sparse_output=True)):\n    #sparse_mlb = MultiLabelBinarizer(sparse_output=True)\n    sparse_matrix = sparse_mlb.fit_transform(df[column_name])\n    sparse_SVD = TruncatedSVD(size)\n    sparse_TSVD = pd.DataFrame(sparse_SVD.fit_transform(sparse_matrix))\n    sparse_TSVD.columns = [f'{column_name}_{i}' for i in range(size)]\n    return sparse_mlb, sparse_TSVD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8900bceb6d4e1425884ad7828b792303361b1687"},"cell_type":"code","source":"genre_mlb, genre_encoded = multi_hot_encode(train,'genres')\ncast_sparse_mlb, cast_TSVD = conv_column_to_SVD(train, 'cast', 10)\nkeywords_sparse_mlb, keywords_TSVD = conv_column_to_SVD(train, 'Keywords', 10)\nlanguages_mlb, languages_TSVD = conv_column_to_SVD(train, 'spoken_languages', 5)\nprodcomp_mlb, prodcomp_TSVD = conv_column_to_SVD(train, 'production_companies', 5)\nprodcountries_mlb, prodcountries_TSVD = conv_column_to_SVD(train, 'production_countries', 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd749f3b56b559df5332ff72463600c413885083"},"cell_type":"code","source":"_,test_genre= multi_hot_encode(test,'genres',genre_mlb)\n_,test_cast = conv_column_to_SVD(test, 'cast', 10)\n_,test_keywords = conv_column_to_SVD(test, 'Keywords', 10)\n_,test_languages = conv_column_to_SVD(test, 'spoken_languages', 5)\n_,test_prodcomp = conv_column_to_SVD(test, 'production_companies', 5)\n_,test_prodcountries = conv_column_to_SVD(test, 'production_countries', 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b918b8b905f66d32e4f07a65d55cf78424f1952f"},"cell_type":"code","source":"train = train.join(genre_encoded)\ntrain = train.join(cast_TSVD)\ntrain = train.join(keywords_TSVD)\ntrain = train.join(languages_TSVD)\ntrain = train.join(prodcomp_TSVD)\ntrain = train.join(prodcountries_TSVD)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5a6c50423ec8a818875725e88f5fe8749293594"},"cell_type":"code","source":"test = test.join(test_genre)\ntest = test.join(test_cast)\ntest = test.join(test_keywords)\ntest = test.join(test_languages)\ntest = test.join(test_prodcomp)\ntest = test.join(test_prodcountries)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cba9a03e798c10ac87f9efc5bec81c36fc11949"},"cell_type":"code","source":"add_datepart(train, 'release_date')\nadd_datepart(test, 'release_date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"324e1d6bc2f6b40d85631435be79947c85d70f9d"},"cell_type":"code","source":"cats_to_drop=['id','title','genres', 'cast', 'crew','Keywords','spoken_languages','production_companies','production_countries','homepage', 'belongs_to_collection','poster_path','imdb_id','original_language', 'original_title', 'overview','tagline','status']\ntrain = train.drop(cats_to_drop, axis=1)\ntrain = train.drop('genres_tv_movie', axis=1)\ntest = test.drop(cats_to_drop,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83ac85220dbdcda3ede3a9e24271545467348996"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffb3ab81c4b43fde82ff46f8b8c51b03588e1077"},"cell_type":"code","source":"train[\"revenue\"]=np.log(train[\"revenue\"]).astype('float')\ntrain[\"budget\"]=np.log(train[\"budget\"]+0.1).astype('float')\ntest[\"budget\"]=np.log(test[\"budget\"]+0.1).astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27bd8905aad2772ac36a454004c6e4bb0a3f3277"},"cell_type":"code","source":"train.loc[train[\"runtime\"].isnull(),\"runtime\"]=train[\"runtime\"].mode()[0]\ntrain.loc[train[\"rating\"].isnull(),\"rating\"]=train[\"rating\"].mode()[0]\ntrain.loc[train[\"totalVotes\"].isnull(),\"totalVotes\"]=train[\"totalVotes\"].mode()[0]\n\ntest.loc[test[\"runtime\"].isnull(),\"runtime\"]=train[\"runtime\"].mode()[0]\ntest.loc[test[\"rating\"].isnull(),\"rating\"]=train[\"runtime\"].mode()[0]\ntest.loc[test[\"totalVotes\"].isnull(),\"totalVotes\"]=train[\"totalVotes\"].mode()[0]\n\ntest.loc[test[\"release_Year\"].isnull(),\"release_Year\"]=train[\"release_Year\"].mode()[0]\ntest.loc[test[\"release_Month\"].isnull(),\"release_Month\"]=train[\"release_Month\"].mode()[0]\ntest.loc[test[\"release_Week\"].isnull(),\"release_Week\"]=train[\"release_Week\"].mode()[0]\ntest.loc[test[\"release_Day\"].isnull(),\"release_Day\"]=train[\"release_Day\"].mode()[0]\ntest.loc[test[\"release_Dayofweek\"].isnull(),\"release_Dayofweek\"]=train[\"release_Dayofweek\"].mode()[0]\ntest.loc[test[\"release_Dayofyear\"].isnull(),\"release_Dayofyear\"]=train[\"release_Dayofyear\"].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"120dca18ac8bee001ed62785713ceed705906224"},"cell_type":"code","source":"X = train.drop(['revenue'], axis=1)\ny = train['revenue']\nX_test = test\nn_fold = 5\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\nrepeated_folds = RepeatedStratifiedKFold(n_splits=10, n_repeats=20, random_state=42)\n\n# scaler = StandardScaler()\n# X_train = scaler.fit_transform(X_train)\n# X_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad4a31228b5a04e7795cf2e91d268769bf64eb4d"},"cell_type":"code","source":"def train_model(X, X_test, y, params, folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n    oof = np.zeros(len(X))\n    prediction = np.zeros(len(X_test))\n    scores = []\n    feature_importance = pd.DataFrame()\n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        print('Fold', fold_n, 'started at', time.ctime())\n        X_train, X_valid = X.loc[train_index], X.loc[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        \n        if model_type == 'lgb':\n            train_data = lgb.Dataset(X_train, label=y_train)\n            valid_data = lgb.Dataset(X_valid, label=y_valid)\n            \n            model = lgb.train(params,\n                    train_data,\n                    num_boost_round=20000,\n                    valid_sets = [train_data, valid_data],\n                    verbose_eval=1000,\n                    early_stopping_rounds = 200)\n            \n            y_pred_valid = model.predict(X_valid)\n            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n            \n        if model_type == 'xgb':\n            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_train.columns)\n\n            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n        \n        if model_type == 'sklearn':\n            model = model\n            model.fit(X_train, y_train)\n            y_pred_valid = model.predict_proba(X_valid).reshape(-1,)\n            score = mean_squared_error(y_valid, y_pred_valid)\n            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n            # print('')\n            \n            y_pred = model.predict_proba(X_test)[:, 1]\n            \n        if model_type == 'glm':\n            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n            model_results = model.fit()\n            model_results.predict(X_test)\n            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n            score = mean_squared_error(y_valid, y_pred_valid)\n            \n            y_pred = model_results.predict(X_test)\n            \n        if model_type == 'cat':\n            model = CatBoostClassifier(iterations=20000, learning_rate=0.1, loss_function='Logloss',  eval_metric='AUC', **params)\n            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n\n            y_pred_valid = model.predict_proba(X_valid)\n            y_pred = model.predict_proba(X_test)\n            \n        oof[valid_index] = y_pred_valid.reshape(-1,)\n        scores.append(mean_squared_error(y_valid, y_pred_valid))\n\n        if averaging == 'usual':\n            prediction += y_pred\n        elif averaging == 'rank':\n            prediction += pd.Series(y_pred).rank().values  \n        \n        if model_type == 'lgb':\n            # feature importance\n            fold_importance = pd.DataFrame()\n            fold_importance[\"feature\"] = X.columns\n            fold_importance[\"importance\"] = model.feature_importance()\n            fold_importance[\"fold\"] = fold_n + 1\n            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n\n    prediction /= n_fold\n    \n    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n    \n    if model_type == 'lgb':\n        feature_importance[\"importance\"] /= n_fold\n        if plot_feature_importance:\n            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n                by=\"importance\", ascending=False)[:50].index\n\n            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n\n            plt.figure(figsize=(16, 12));\n            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n            plt.title('LGB Features (avg over folds)');\n        \n            return oof, prediction, feature_importance\n        return oof, prediction, scores\n    \n    else:\n        return oof, prediction, scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d30c1c0fbcbde398a303d01ef03097979e46f55b"},"cell_type":"code","source":"params = {'num_leaves': 16,\n         'min_data_in_leaf': 2,\n         'objective': 'regression',\n         'max_depth': 20,\n         'learning_rate': 0.008,\n         'boosting': 'gbdt',\n         'bagging_freq': 5,\n         'feature_fraction': 0.82,\n         'bagging_seed': 11,\n         'reg_alpha': 1.7,\n         'reg_lambda': 6,\n         'random_state': 42,\n         'metric': 'mse',\n         'verbosity': -1,\n         'subsample': 0.81,\n         'min_gain_to_split': 0.01,\n         'min_child_weight': 10,\n         'num_threads': 8}\noof_lgb, prediction_lgb, scores = train_model(X, X_test, y, params=params, folds=folds, model_type='lgb', plot_feature_importance=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd4009543db0da38b500ccb18c5fcda4740001e3"},"cell_type":"code","source":"xgb_params = {'eta': 0.1, 'max_depth': 3, 'subsample': 0.9, 'colsample_bytree': 0.9, \n          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 8}\noof_xgb, prediction_xgb, scores = train_model(X, X_test, y, params=xgb_params, folds=folds, model_type='xgb')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08724efeb323b47d8df4da6e98558559460bf235"},"cell_type":"code","source":"sns.distplot(prediction_lgb, hist=False) # blue\nsns.distplot(prediction_xgb, hist=False) # orange\nsns.distplot(train['revenue'], hist=False) #green","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d88129d9255a4f9440899d793ad719e309ffd02"},"cell_type":"code","source":"train['revenue'].mean()/((prediction_lgb+prediction_xgb)/2).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfb8445f05810bd216bd97f2c70bb6efa08d56ff"},"cell_type":"code","source":"submission = pd.read_csv(f'{PATH}sample_submission.csv')\nsubmission['revenue'] = np.exp(0.50*(prediction_lgb+prediction_xgb))\nsubmission.to_csv(f'submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"867b0ac61002e6f4dfa9bb115d769db891d54f75"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}