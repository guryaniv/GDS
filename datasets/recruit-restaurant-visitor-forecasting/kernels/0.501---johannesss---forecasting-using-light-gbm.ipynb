{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "version": "3.6.4", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}}, "cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.metrics import mean_squared_error\n", "from sklearn.utils import shuffle\n", "from sklearn import model_selection\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "from subprocess import check_output\n", "from sklearn.model_selection import train_test_split\n", "import lightgbm as lgb\n", "from sklearn import preprocessing"], "metadata": {"_cell_guid": "eb7eb04d-42c7-4971-a6d2-79f482ce0f25", "_uuid": "0a3131f5b1e272426033b62d82d40be37bf52e65", "collapsed": true}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["data = {\n", "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n", "    'as': pd.read_csv('../input/air_store_info.csv'),\n", "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n", "    'ar': pd.read_csv('../input/air_reserve.csv'),\n", "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id': pd.read_csv('../input/store_id_relation.csv'),\n", "    'tes': pd.read_csv('../input/sample_submission.csv'),\n", "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n", "    }\n", "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n", "data['hr'].drop('hpg_store_id',  axis=1, inplace=True)\n", "data['ar'] = data['ar'].append(data['hr'])\n", "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n", "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n", "test_id = data['tes']['id']\n", "data['tes'].drop('id', axis=1, inplace=True)\n", "print ('Data loaded - number visits: ' + str(data['tra'].shape[0]))"], "metadata": {"_cell_guid": "750dab05-4563-4f05-874f-53eda6e9d6b0", "_uuid": "df069fc9a7396acba16d2cbb5c8742ca9941adc5"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Create single data set with all relevant base data:\n", "data['tra']['visit_datetime'] = pd.to_datetime(data['tra']['visit_date'])\n", "data['tra']['dow']     = data['tra']['visit_datetime'].dt.dayofweek\n", "data['ar']['res_visit_datetime'] = pd.to_datetime(data['ar']['visit_datetime'])\n", "data['ar']['reserve_datetime']   = pd.to_datetime(data['ar']['reserve_datetime'])\n", "data['ar']['visit_date']         = data['ar']['res_visit_datetime'].dt.date\n", "data['ar']['reserve_diff'] = data['ar'].apply(lambda r: (r['res_visit_datetime']\n", "                                                         - r['reserve_datetime']).days, \n", "                                        axis=1)\n", "data['ar'].drop('visit_datetime',  axis=1, inplace=True)\n", "data['ar'].drop('reserve_datetime',  axis=1, inplace=True)\n", "data['ar'].drop('res_visit_datetime',  axis=1, inplace=True)\n", "avg_reserv = data['ar'].groupby(['air_store_id','visit_date'], \n", "                                as_index=False).mean().reset_index()\n", "data['ar'] = data['ar'].groupby(['air_store_id','visit_date'], \n", "                                as_index=False).sum().reset_index()\n", "data['ar'] = data['ar'].drop(['reserve_diff'],axis=1)\n", "data['ar'] = data['ar'].drop(['index'],axis=1)\n", "data['ar']['reserve_diff'] = avg_reserv['reserve_diff']  \n", "data['ar']['visit_date'] = data['ar']['visit_date'].astype(str)    \n", "\n", "data['tes']['visit_datetime'] = pd.to_datetime(data['tes']['visit_date'])\n", "data['tes']['dow']     = data['tes']['visit_datetime'].dt.dayofweek\n", "\n", "prep_df = pd.merge(data['tra'], data['ar'],  how='left', on=['air_store_id', 'visit_date'])\n", "prep_df = pd.merge(prep_df,     data['as'],  how='inner', on='air_store_id')\n", "prep_df = pd.merge(prep_df,     data['hol'], how='left',  on='visit_date')\n", "print ('Data merged - number visits in train: ' + str(prep_df.shape[0]))\n", "predict_data = pd.merge(data['tes'],  data['ar'],   how='left', on=['air_store_id', 'visit_date'])\n", "predict_data = pd.merge(predict_data, data['as'],   how='inner', on='air_store_id')\n", "predict_data = pd.merge(predict_data, data['hol'],  how='left', on='visit_date')\n", "print ('Data merged - number visits in test: ' + str(predict_data.shape[0]))"], "metadata": {"_cell_guid": "13033c0f-d4fc-4e43-8126-efc11a71e0f6", "_uuid": "492e59e2738e1c5db6a7fa81371daa1fdcc01753"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].min().rename(\n", "    columns={'visitors': 'min_visitors'})\n", "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n", "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].mean().rename(\n", "    columns={'visitors': 'mean_visitors'})\n", "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n", "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].median().rename(\n", "    columns={'visitors': 'median_visitors'})\n", "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n", "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].max().rename(\n", "    columns={'visitors': 'max_visitors'})\n", "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n", "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n", "tmp = data['tra'].groupby(['air_store_id', 'dow'], as_index=False)['visitors'].count().rename(\n", "    columns={'visitors': 'count_observations'})\n", "prep_df = pd.merge(prep_df, tmp, how='left', on=['air_store_id', 'dow'])\n", "predict_data = pd.merge(predict_data, tmp, how='left', on=['air_store_id', 'dow'])\n", "\n", "prep_df.drop('dow',  axis=1, inplace=True)\n", "predict_data.drop('dow',  axis=1, inplace=True)\n", "print(predict_data.shape)\n", "print(prep_df.shape)"], "metadata": {"_cell_guid": "74bf4d7d-8b9d-4d40-af81-0458339cbf8b", "_uuid": "e4e009dc9b75ab7d9ab20f158319e418005b0f44"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["# Encode fields:\n", "prep_df['month'] = prep_df['visit_datetime'].dt.month\n", "prep_df['day']   = prep_df['visit_datetime'].dt.day\n", "prep_df.drop('visit_datetime',      axis=1, inplace=True)   \n", "predict_data['month'] = predict_data['visit_datetime'].dt.month\n", "predict_data['day']   = predict_data['visit_datetime'].dt.day\n", "predict_data.drop('visit_datetime', axis=1, inplace=True)\n", "prep_df.fillna(-1, inplace=True)\n", "predict_data.fillna(-1, inplace=True)\n", "\n", "# Encode labels of categorical columns:\n", "cat_features = [col for col in ['air_genre_name', 'air_area_name', 'day_of_week']]\n", "for column in cat_features:\n", "    temp_prep = pd.get_dummies(pd.Series(prep_df[column]))\n", "    prep_df = pd.concat([prep_df,temp_prep],axis=1)\n", "    prep_df = prep_df.drop([column],axis=1)\n", "    temp_predict = pd.get_dummies(pd.Series(predict_data[column]))\n", "    predict_data = pd.concat([predict_data,temp_predict],axis=1)\n", "    predict_data = predict_data.drop([column],axis=1)\n", "    for missing_col in temp_prep:     # Make sure the columns of train and test are identical\n", "        if missing_col not in predict_data.columns:\n", "            predict_data[missing_col] = 0\n", "    for missing_col in temp_predict:     # Make sure the columns of train and test are identical\n", "        if missing_col not in prep_df.columns:\n", "            prep_df[missing_col] = 0        \n", "    \n", "prep_df['visitors'] = np.log1p(prep_df['visitors'])\n", "print('Done')"], "metadata": {"_cell_guid": "75456b4f-afe0-41d3-9576-088871eb2b80", "_uuid": "8251d594c4d3a507bdb36c5429bf08648721ad57"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["#prep_df = prep_df[prep_df['visit_date'] >= '2016-06-29']\n", "#prep_df = prep_df.drop(['reserve_visitors'],axis=1)\n", "#prep_df = prep_df.drop(['reserve_diff'],axis=1)\n", "#prep_df = prep_df.drop(['latitude'],axis=1)\n", "#prep_df = prep_df.drop(['longitude'],axis=1)\n", "#predict_data = predict_data.drop(['reserve_visitors'],axis=1)\n", "#predict_data = predict_data.drop(['reserve_diff'],axis=1)\n", "#predict_data = predict_data.drop(['latitude'],axis=1)\n", "#predict_data = predict_data.drop(['longitude'],axis=1)                        \n", "#prep_df.head()"], "metadata": {"_cell_guid": "bf7fcff5-a20e-4ffc-8f68-93f7bfdd2c47", "_uuid": "cdf9509f4cad4b1b759d77376d7e9e78b60a6275", "collapsed": true}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["prep_df.drop(['visit_date'], axis=1, inplace=True)\n", "label_enc = preprocessing.LabelEncoder()\n", "label_enc.fit(prep_df['air_store_id'])\n", "prep_df['air_store_id'] = label_enc.transform(prep_df['air_store_id'])\n", "prep_cols = prep_df.columns\n", "\n", "predict_data.drop(['visit_date'], axis=1, inplace=True)  \n", "predict_data['air_store_id'] = label_enc.transform(predict_data['air_store_id'])\n", " \n", "X_train = prep_df.drop(['visitors'], axis=1)\n", "y_train = prep_df['visitors'].values    \n", "X_test = predict_data.drop(['visitors'], axis=1)\n", "# Submissions are evaluated using RMSLE:\n", "def RMSLE(y, pred):\n", "    return mean_squared_error(y, pred)**0.5"], "metadata": {"_cell_guid": "a59a6680-18a5-4109-a008-14cb976595d4", "_uuid": "0110301907bfea1240e6093d489c348f1535ecd2", "collapsed": true}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["print(X_train.shape)\n", "print(y_train.shape)\n", "print(X_test.shape)"], "metadata": {"_cell_guid": "d045d27a-1650-4e87-bf68-25b345cb5e2d", "_uuid": "42c743c969af57b449ad4b56d88cb6b140eed5e4"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["lgb_params1 = {}\n", "lgb_params1['application'] = 'regression'\n", "lgb_params1['boosting'] = 'gbdt'\n", "lgb_params1['learning_rate'] = 0.015\n", "lgb_params1['num_leaves'] = 32\n", "lgb_params1['min_sum_hessian_in_leaf'] = 2e-2\n", "lgb_params1['min_gain_to_split'] = 0\n", "lgb_params1['bagging_fraction'] = 0.9\n", "lgb_params1['feature_fraction'] = 0.9\n", "lgb_params1['num_threads'] = 8\n", "lgb_params1['metric'] = 'rmse'\n", "\n", "lgb_params2 = {}\n", "lgb_params2['application'] = 'regression'\n", "lgb_params2['boosting'] = 'gbdt'\n", "lgb_params2['learning_rate'] = 0.02\n", "lgb_params2['lambda_l1'] = 0.2\n", "lgb_params2['num_leaves'] = 16\n", "lgb_params2['min_gain_to_split'] = 0\n", "lgb_params2['bagging_fraction'] = 0.8\n", "lgb_params2['feature_fraction'] = 0.8\n", "lgb_params2['num_threads'] = 4\n", "lgb_params2['metric'] = 'rmse'\n", "\n", "lgb_params3 = {}\n", "lgb_params3['application'] = 'regression'\n", "lgb_params3['boosting'] = 'gbdt'\n", "lgb_params3['learning_rate'] = 0.022\n", "lgb_params3['num_leaves'] = 32\n", "lgb_params2['lambda_l2'] = 0.3\n", "lgb_params3['bagging_freq'] = 8\n", "lgb_params3['min_gain_to_split'] = 0\n", "lgb_params3['bagging_fraction'] = 0.8\n", "lgb_params3['feature_fraction'] = 0.8\n", "lgb_params3['num_threads'] = 4\n", "lgb_params3['metric'] = 'rmse'\n", "\n", "def do_train(X_train, X_valid, lgb_params):\n", "    X_t = X_train.drop(['visitors'], axis=1)\n", "    y_t = X_train['visitors'].values\n", "    d_train = lgb.Dataset(X_t, y_t)\n", "    X_v = X_valid.drop(['visitors'], axis=1)\n", "    y_v = X_valid['visitors'].values\n", "    d_valid = lgb.Dataset(X_v, y_v)\n", "    watchlist = [d_train, d_valid]\n", "    lgb_model = lgb.train(lgb_params, train_set=d_train, num_boost_round=15000, \n", "                          valid_sets=watchlist, verbose_eval=100)\n", "    test_pred = lgb_model.predict(X_v)\n", "    rmsle = RMSLE(y_v, test_pred)\n", "    return rmsle, lgb_model\n", "\n", "X_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=74, shuffle=True)\n", "rmsle, lgb_model1 = do_train(X_train, X_valid, lgb_params1)\n", "test_pred1 = np.expm1(lgb_model1.predict(X_test))\n", "print('Test RMSLE: %.3f' % rmsle)\n", "    \n", "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=2121, shuffle=True)\n", "rmsle, lgb_model2 = do_train(X_train, X_valid, lgb_params2)\n", "test_pred2 = np.expm1(lgb_model2.predict(X_test))\n", "print('Test RMSLE: %.3f' % rmsle)   \n", "\n", "X_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=4, shuffle=True)\n", "rmsle, lgb_model3 = do_train(X_train, X_valid, lgb_params3)\n", "test_pred3 = np.expm1(lgb_model3.predict(X_test))\n", "print('Test RMSLE: %.3f' % rmsle)   \n", "\n", "X_train, X_valid = train_test_split(prep_df, test_size=0.3, random_state=19, shuffle=True)\n", "rmsle, lgb_model4 = do_train(X_train, X_valid, lgb_params1)\n", "test_pred4 = np.expm1(lgb_model4.predict(X_test))\n", "print('Test RMSLE: %.3f' % rmsle)  \n", "\n", "test_pred = (test_pred1 + test_pred2 + test_pred3 + test_pred4) / 4\n", "result = pd.DataFrame({\"id\": test_id, \"visitors\": test_pred})   \n", "result.to_csv('LGB_sub.csv', index=False)\n", "print('Done')"], "metadata": {"_cell_guid": "4bae1e9b-63e1-4533-b12f-473b53598d99", "_uuid": "e1da1944b9aa89094124bd24ac0a3403891f1b2f"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["#prep_df = shuffle(prep_df, random_state=74)\n", "#X_train, X_valid = train_test_split(prep_df, test_size=0.2, random_state=74, shuffle=False)\n", "#\n", "#X_t = X_train.drop(['visitors'], axis=1)\n", "#y_t = X_train['visitors'].values\n", "#d_train = lgb.Dataset(X_t, y_t)\n", "#\n", "#X_v = X_valid.drop(['visitors'], axis=1)\n", "#y_v = X_valid['visitors'].values\n", "#d_valid = lgb.Dataset(X_v, y_v)\n", "#watchlist = [d_train, d_valid]\n", "#\n", "#params = {}\n", "#params['application'] = 'regression'\n", "#params['boosting'] = 'gbdt'\n", "#params['learning_rate'] = 0.015\n", "#params['num_leaves'] = 32\n", "#params['min_sum_hessian_in_leaf'] = 2e-2\n", "#params['min_gain_to_split'] = 0\n", "#params['bagging_fraction'] = 0.9\n", "#params['feature_fraction'] = 0.9\n", "#params['num_threads'] = 8\n", "#params['metric'] = 'rmse'\n", "#\n", "#lgb_model = lgb.train(params, train_set=d_train, num_boost_round=50000, \n", "#                       valid_sets=watchlist, verbose_eval=100)\n", "#\n", "#test_pred = lgb_model.predict(X_v)\n", "#rmsle = RMSLE(y_v, test_pred)\n", "#print('Test RMSLE: %.3f' % rmsle)"], "metadata": {"_cell_guid": "cd3af536-c427-4af2-ba3c-9b4d3cc2ef85", "_uuid": "cddfbecbd3f530e0226d4c107543dd85b27c2fd0", "collapsed": true}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["#predict_data.drop(['visitors'], axis=1, inplace=True)\n", "#test_pred = np.expm1(lgb_model.predict(predict_data))\n", "#result = pd.DataFrame({\"id\": test_id, \"visitors\": test_pred})\n", "#    \n", "#result.to_csv('LGB_sub.csv', index=False)\n", "#print('Done')"], "metadata": {"_cell_guid": "a43137ed-a9d5-449a-8460-7c31014e8354", "_uuid": "4f1b01e0431437a2691137212a45b86232da5d01", "collapsed": true}}], "nbformat": 4, "nbformat_minor": 1}