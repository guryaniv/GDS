{"cells": [{"metadata": {"_cell_guid": "d20d05fd-8125-46a9-8337-1937aadbf7e4", "_uuid": "4f2b29a02ebca1cfd6f269abd09e54387fa404f9", "scrolled": true}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"_cell_guid": "31d02cc6-c4a0-46cd-b23c-35fc32dfeaff", "_uuid": "1737926de45d37cc589252971c99cd4f7bf660c1", "collapsed": true}, "source": ["train = pd.read_csv('../input/train.csv')\n", "valid  = pd.read_csv('../input/test.csv')"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {"_cell_guid": "4657c2f8-7079-4673-9abb-b95b526569fc", "_uuid": "ee3bc8a2f2cf6d398084b1cc17ddf1ca2ad1e442"}, "source": ["print(\"Shape of Train Data : \", train.shape)\n", "print(\"Shape of Validation Data : \",  valid.shape)"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"_cell_guid": "35cb6808-986d-41ba-88d2-f9f40d5320c9", "_uuid": "b19e5d86b24e8c4547572c1991b624d9a1f3649e"}, "source": ["print(\"Data Type in the Training Data : \")\n", "print(train.dtypes)\n", "print(valid.dtypes)"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"_cell_guid": "458b16e5-31ab-4717-9124-8f9c586d1a9b", "_uuid": "01183d04be55a4cad3fa3d2aa6d610054f9c62a3", "scrolled": true}, "source": ["print('Summary Statistics:')\n", "for col in train.columns:\n", "    print('Distinct Values, min and, max of : ',col, train[col].nunique(), min(train[col]), max(train[col]))"], "cell_type": "code", "outputs": [], "execution_count": 5}, {"metadata": {"_cell_guid": "8abb4c3e-60b2-4293-bde8-6b03054778c7", "_uuid": "ca65d08993f3d380b51868f4d3d94c1b884e9d58"}, "source": ["print('Distribution of Events : ')\n", "dfOut = train['target'].value_counts().reset_index()\n", "dfOut.columns = ['target', 'event']\n", "dfOut['eventRate'] = dfOut['event']/sum(dfOut['event'])\n", "print(dfOut)"], "cell_type": "code", "outputs": [], "execution_count": 6}, {"metadata": {"_cell_guid": "bb932d5d-5018-43e6-9019-b83de4cec5af", "_uuid": "820787db6ed202232b9366e8de18ef2f629aed11", "scrolled": true}, "source": ["print(' --- Risk Table (Different Approach) --- ')\n", "for col in train.columns:\n", "    if(col not in ['id','target','ps_reg_03','ps_car_12','ps_car_13','ps_car_14','ps_car_15']):\n", "        print(\"Feature : \", col)\n", "        dfOut = train.groupby(col)['target'].agg({'sum' : 'sum', 'count' : 'count'}).reset_index()\n", "        dfOut['eventOdd'] = dfOut['sum']/dfOut['count'] * 100\n", "        dfOut[col + '_eventRate']= dfOut['sum']/sum(dfOut['sum']) * 100\n", "        dfOut.sort_values(col + '_eventRate', ascending = False, inplace = True)\n", "        dfOut.drop(['sum','count','eventOdd'], axis = 1, inplace = True)\n", "        train = pd.merge(train, dfOut, on = col, how = 'inner')\n", "        train.drop(col, axis = 1, inplace = True)\n", "\n", "pd.set_option('display.max_columns',None)       \n", "print(train.head())\n"], "cell_type": "code", "outputs": [], "execution_count": 7}, {"metadata": {"_cell_guid": "9c80c93f-72c8-4a7c-91a1-b875cf14cbc7", "_uuid": "29ef07ba3952c0e79a59e9441f7716a7042f277e"}, "source": ["print('--- XGBoost ---')\n", "import random\n", "from xgboost import XGBRegressor\n", "\n", "train['randomNumber'] = [random.uniform(0,1) for x in range(train.shape[0])]\n", "\n", "dfTrain = train.query('randomNumber<=.7')\n", "dfTest  = train.query('randomNumber>.7')\n", "\n", "print('--- Distribuion of Event in Train and Test Datasets')\n", "print('--- Train ---\\n', dfTrain['target'].value_counts())\n", "print('--- Test ---\\n', dfTest['target'].value_counts())\n", "\n", "colsToKeep = [x for x in train.columns if x not in ('id','target','randomNumber')]\n", "xTrain = dfTrain[colsToKeep].apply(lambda x: x).values\n", "yTrain = dfTrain['target'].values\n", "xTest  = dfTest[colsToKeep].apply(lambda x: x).values\n", "yTest  = dfTest['target'].values\n", "\n", "reg = XGBRegressor()\n", "reg.fit(xTrain, yTrain)\n", "yPred = reg.predict(xTest)\n", "\n", "from sklearn.metrics import log_loss, accuracy_score\n", "print('Log Loss:\\n', log_loss(yTest, yPred))\n"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {"_cell_guid": "743cedbd-8cd1-4f57-8e67-d25f3f25dabe", "_uuid": "c5bc00e0d174d37b9d3715dcd99819442b4f4332"}, "source": ["print('--- Model Validation ---')\n", "xValid = valid.drop(['id'], axis = 1).values\n", "\n", "yOut = reg.predict(xValid)\n", "\n", "outDf = pd.DataFrame()\n", "outDf['id'] = valid['id']\n", "outDf['target'] = yOut\n", "\n", "outDf.to_csv('100_test.csv', index = False)"], "cell_type": "code", "outputs": [], "execution_count": 9}, {"metadata": {"_cell_guid": "d9e358ea-6d7e-47bb-a60f-211e9c4049a1", "_uuid": "78e2e31e7d6ee99e2fd408b67b14374b16d515bf", "collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}], "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4}