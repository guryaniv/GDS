{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "version": "3.6.4", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python"}}, "cells": [{"metadata": {"_cell_guid": "677912b7-2ec7-4a7d-bab4-5568de233e47", "_uuid": "03644a330d3da78a3b89fb58b2115e456a5420a1"}, "cell_type": "markdown", "source": ["# Keras cnn + GloVe + Dropout + Early Stopping = [0.048 LB]\n", "\n", "#### 2 Jan 2018\n", "***"]}, {"metadata": {"_cell_guid": "582fe746-5914-4b94-8b0b-ba603fc604cd", "_uuid": "3e03184d38dfa0b4d3f39de3f4bfe54b44e05dc6"}, "cell_type": "markdown", "source": ["## **Summary**"]}, {"metadata": {"_cell_guid": "67537a49-3915-4151-b01a-ef36b79192d8", "_uuid": "8508bac4219f877514c72c0a6599e4533eb3ba44"}, "cell_type": "markdown", "source": ["This model, nicknamed the_Detoxinator, uses pretrained Glove 840B with Adam optimizer and a learning rate of 0.0001. The model implements early stopping using a stratified validation set (25% of training set). Training was done on a GPU (Crestle). If I remember correctly, training did not take more than 30 minutes.\n", "\n", "Please note that this script is written to run locally, not in the Kaggle kernel environment. \n", "\n", "\n", "#### **The CNN architecture is as follows:**"]}, {"metadata": {"_cell_guid": "f0eca2e0-d55b-4cc2-84cc-51c6c2254ebd", "collapsed": true, "_uuid": "4ce391d1c940e7542dea352f3c3a72638e6cd875"}, "cell_type": "markdown", "source": ["model = Sequential()<br>\n", "e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=500,trainable=False)<br>\n", "model.add(e)<br>\n", "model.add(Conv1D(128, 3, activation='relu'))<br>\n", "model.add(MaxPooling1D(3))<br>\n", "model.add(Dropout(0.2))<br>\n", "model.add(Conv1D(64, 3, activation='relu'))<br>\n", "model.add(MaxPooling1D(3))<br>\n", "model.add(Dropout(0.2))<br>\n", "model.add(Conv1D(64, 3, activation='relu'))<br>\n", "model.add(Dropout(0.2))<br>\n", "model.add(Flatten())<br>\n", "model.add(Dense(1, activation='sigmoid'))<br>"]}, {"metadata": {"_cell_guid": "588893d5-e47b-4bde-a835-b171ecc0542e", "_uuid": "79a7469c0b3d6daea3fc856a9c9d331930ec205d"}, "cell_type": "markdown", "source": ["![](http://)The public LB score was 0.048. I found that this score could be improved to 0.046 by averaging the predictions of this cnn model with the predictions generated by another logistic regression model that I created. The following kernel explains how to easily do this:\n", "\n", "https://www.kaggle.com/jhoward/minimal-lstm-nb-svm-baseline-ensemble-lb-0-044\n", "\n", "Using a weighted average (0.6 x cnn_model + 0.4 x logistic_regression_model) further improved the public LB score to 0.045.\n", "***"]}, {"metadata": {"_cell_guid": "2c09a73b-225c-4cb3-b6e5-8360cfe27bef", "_uuid": "461c683283c62f10be20c61a56dfdadc4e38c392"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "from sklearn.model_selection import train_test_split\n", "\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.preprocessing.sequence import pad_sequences\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import Flatten\n", "from keras.layers import Embedding\n", "from keras.optimizers import Adam\n", "from keras.layers import BatchNormalization, Flatten, Conv1D, MaxPooling1D\n", "from keras.layers import Dropout\n", "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n", "\n", "# Don't Show Warning Messages\n", "import warnings\n", "warnings.filterwarnings('ignore')"]}, {"metadata": {"_cell_guid": "8ff1b6f1-2e72-4eec-954e-017ced59dce5", "_uuid": "2baebccd3836f4bda9b03ac3ea85b2fd511e73c8"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# read in the data\n", "\n", "#df_train = pd.read_csv('train.csv.zip')\n", "#df_test = pd.read_csv('test.csv.zip')\n", "\n", "df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')\n", "\n", "print(df_train.shape)\n", "print(df_test.shape)"]}, {"metadata": {"_cell_guid": "20b9b3aa-110b-4c59-9970-1732e87017fa", "collapsed": true, "_uuid": "c4392f8fc9f88c5daef65e66d233b72093de8a9c"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# combine the train and test sets for encoding and padding\n", "\n", "train_len = len(df_train)\n", "df_combined =  pd.concat(objs=[df_train, df_test], axis=0).reset_index(drop=True)\n", "\n", "print(df_combined.shape)"]}, {"metadata": {"_cell_guid": "0b23211a-fb43-4fe3-a855-86317a7937ce", "collapsed": true, "_uuid": "f5b22283efd3faef27316ea3c65867f688427817"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# define text data\n", "docs_combined = df_combined['comment_text'].astype(str)\n", "\n", "# initialize the tokenizer\n", "t = Tokenizer()\n", "t.fit_on_texts(docs_combined)\n", "vocab_size = len(t.word_index) + 1\n", "\n", "# integer encode the text data\n", "encoded_docs = t.texts_to_sequences(docs_combined)\n", "\n", "# pad the vectors to create uniform length\n", "padded_docs_combined = pad_sequences(encoded_docs, maxlen=500, padding='post')"]}, {"metadata": {"_cell_guid": "210f64cb-5e3c-4e08-90ad-dbbb23b90df8", "collapsed": true, "_uuid": "410ce48a5a51e8ecb2e75bf9ecf9c2473e0b4cdc"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# seperate the train and test sets\n", "\n", "df_train_padded = padded_docs_combined[:train_len]\n", "df_test_padded = padded_docs_combined[train_len:]\n", "\n", "print(df_train_padded.shape)\n", "print(df_test_padded.shape)"]}, {"metadata": {"_cell_guid": "27d6f8a3-415d-460c-8f6a-d21ec5219d21", "_uuid": "9ff0edb62e63e13339031f4f9b17c9558bb9cf2d"}, "cell_type": "markdown", "source": ["### **Load the GloVe embeddings**"]}, {"metadata": {"_cell_guid": "8239f3a1-3e27-44b6-8e92-ca8e8a43ecb3", "_uuid": "a4182a93db8d378f0b214f62735b2f013e8114e3"}, "cell_type": "markdown", "source": ["The code for processing the Glove embeddings is taken from this excellent blog post:\n", "\n", "https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n", "\n", "I made some minor changes to suit glove840B and to fix a \"could not convert string to float\" error."]}, {"metadata": {"_cell_guid": "c1ddb595-c6dd-4a10-812e-9528f0489fab", "collapsed": true, "_uuid": "3c7fca0da64ff99701ff9d30223e598046c1ce05"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# load the glove840B embedding into memory after downloading and unzippping\n", "\n", "embeddings_index = dict()\n", "f = open('glove.840B.300d.txt')\n", "\n", "for line in f:\n", "    # Note: use split(' ') instead of split() if you get an error.\n", "\tvalues = line.split(' ')\n", "\tword = values[0]\n", "\tcoefs = np.asarray(values[1:], dtype='float32')\n", "\tembeddings_index[word] = coefs\n", "f.close()\n", "\n", "print('Loaded %s word vectors.' % len(embeddings_index))\n", "\n", "# create a weight matrix\n", "embedding_matrix = np.zeros((vocab_size, 300))\n", "for word, i in t.word_index.items():\n", "\tembedding_vector = embeddings_index.get(word)\n", "\tif embedding_vector is not None:\n", "\t\tembedding_matrix[i] = embedding_vector"]}, {"metadata": {"_cell_guid": "58dfc4cc-01ee-489a-808b-3ff3120125b8", "_uuid": "855ccac09de4f92e853cae879089e209e5b57201"}, "cell_type": "markdown", "source": ["### **Define X and y**"]}, {"metadata": {"_cell_guid": "9d242e26-e9a0-4ae3-a47c-97a41e638343", "collapsed": true, "_uuid": "086e9e087dc425b4ff79564680bb47ac55569776"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["X = df_train_padded\n", "X_test = df_test_padded\n", "\n", "# target columns\n", "y_toxic = df_train['toxic']\n", "y_severe_toxic = df_train['severe_toxic']\n", "y_obscene = df_train['obscene']\n", "y_threat = df_train['threat']\n", "y_insult = df_train['insult']\n", "y_identity_hate = df_train['identity_hate']"]}, {"metadata": {"_cell_guid": "b50dbcce-d6a2-4561-932d-8220b18e89f4", "_uuid": "774dd49341c23f367e3d4c1e08894bd129fd852b"}, "cell_type": "markdown", "source": ["### **Train and generate predictions for each of the 6 target columns:**"]}, {"metadata": {"_cell_guid": "6d9218a9-de6e-4df9-b667-c394c2bd8495", "collapsed": true, "_uuid": "8d94984e6a3508f9f781007c17be6ad950fa501e"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# create a list of the target columns\n", "target_cols = [y_toxic,y_severe_toxic,y_obscene,y_threat,y_insult,y_identity_hate]\n", "\n", "preds = []\n", "\n", "for col in target_cols:\n", "    \n", "    print('\\n')\n", "    \n", "    # set the value of y\n", "    y = col\n", "    \n", "    # create a stratified split\n", "    X_train, X_eval, y_train ,y_eval = train_test_split(X, y,test_size=0.25,shuffle=True,\n", "                                                    random_state=5,stratify=y)\n", "\n", "    # cnn model\n", "    model = Sequential()\n", "    e = Embedding(vocab_size, 300, weights=[embedding_matrix], \n", "                  input_length=500, trainable=False)\n", "    model.add(e)\n", "    model.add(Conv1D(128, 3, activation='relu'))\n", "    model.add(MaxPooling1D(3))\n", "    model.add(Dropout(0.2))\n", "    model.add(Conv1D(64, 3, activation='relu'))\n", "    model.add(MaxPooling1D(3))\n", "    model.add(Dropout(0.2))\n", "    model.add(Conv1D(64, 3, activation='relu'))\n", "    model.add(Dropout(0.2))\n", "    model.add(Flatten())\n", "    model.add(Dense(1, activation='sigmoid'))\n", "\n", "\n", "    # compile the model\n", "    Adam_opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n", "    model.compile(optimizer=Adam_opt, loss='binary_crossentropy', metrics=['acc'])\n", "\n", "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n", "    save_best = ModelCheckpoint('toxic.hdf', save_best_only=True, \n", "                               monitor='val_loss', mode='min')\n", "\n", "    history = model.fit(X_train, y_train, validation_data=(X_eval, y_eval),\n", "                        epochs=100, verbose=1,callbacks=[early_stopping,save_best])\n", "\n", "    \n", "    # make a prediction on y (target column)\n", "    model.load_weights(filepath = 'toxic.hdf')\n", "    predictions = model.predict(X_test)\n", "    y_preds = predictions[:,0]\n", "    \n", "    # append the prediction to a python list\n", "    preds.append(y_preds)\n"]}, {"metadata": {"_cell_guid": "ce2b8fc7-dc8c-438b-ab91-6723abad0007", "_uuid": "60ed543d945f6ba0ea9f4db52f5aa68d6769d69a"}, "cell_type": "markdown", "source": ["### **Create a submission file**"]}, {"metadata": {"_cell_guid": "1cce236f-c2a8-4a49-af46-e3f757d2a96b", "collapsed": true, "_uuid": "34d25b09fe313b0d94aabb0849929512e5c7f803"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_results = pd.DataFrame({'id':df_test.id,\n", "                            'toxic':preds[0],\n", "                           'severe_toxic':preds[1],\n", "                           'obscene':preds[2],\n", "                           'threat':preds[3],\n", "                           'insult':preds[4],\n", "                           'identity_hate':preds[5]}).set_index('id')\n", "\n", "# Pandas automatically sorts the columns alphabetically by column name.\n", "# Therefore, we need to re-order the columns to match the sample submission file.\n", "df_results = df_results[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n", "\n", "# create a submission csv file\n", "df_results.to_csv('kaggle_submission.csv', \n", "                  columns=['toxic','severe_toxic','obscene','threat','insult','identity_hate']) "]}, {"metadata": {"_cell_guid": "400a186c-1b13-4680-8416-a061e4672258", "_uuid": "f7a3b6cf0c539d64d92ea2741c9ed069b6cc73cb"}, "cell_type": "markdown", "source": ["***\n", "### **Resources**\n"]}, {"metadata": {"_cell_guid": "21843050-dee8-46f5-8410-40fd99f1404c", "_uuid": "b187960941b6c7be32720261a987fcc489953d1b"}, "cell_type": "markdown", "source": ["These are a few cnn and nlp resources I found helpful:\n", "\n", "- What are word embeddings?<br>\n", "https://www.youtube.com/watch?v=Eku_pbZ3-Mw\n", "\n", "\n", "- Blog post with a simple example explaining how to use pre trained embeddings:<br>https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n", "\n", "\n", "- Online cnn course:<br>\n", "https://www.coursera.org/learn/convolutional-neural-networks<br>\n", "This course can be taken for free. \n", "\n", "\n", "- Lesson 5 notes from the fast.ai course:<br>\n", "http://wiki.fast.ai/index.php/Lesson_5_Notes\n", "\n", "\n", "- GloVe: Global Vectors for Word Representation<br>\n", "Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014.<br>\n", "https://nlp.stanford.edu/projects/glove/\n", "\n", "\n", "- Machine learning with text<br>\n", "https://www.youtube.com/watch?v=ZiKMIuYidY0\n", "\n", "\n", "- NLTK Tutorial series<br>\n", "https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/"]}, {"metadata": {"_cell_guid": "490b224a-22db-4135-bf9f-3f65886c2994", "_uuid": "9939b4da27ecece2944fb217e19a8520c65c2ddc"}, "cell_type": "markdown", "source": ["***\n", "This competition is a great learning experience. Thank you to all who have been commenting and publishing.\n", "\n", "Happy new year!"]}, {"metadata": {"_cell_guid": "98c3d980-6862-4e7f-99a8-134a48fcc99f", "collapsed": true, "_uuid": "562e4ee4a08ea5f3b47d157cd6443e4a51b0b05c"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": []}], "nbformat_minor": 1, "nbformat": 4}