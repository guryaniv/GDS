{"metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "e9c20dc3-4e0f-4853-af09-c1d38f4f50e5", "_uuid": "ecf02f60179b0a22b2ad63246b62e3eacc0d77da"}, "source": [">\"Ent\u00e3o voc\u00ea n\u00e3o se lembra de um mundo sem rob\u00f4s.  Houve um tempo quando a humanidade enfrentou o universo sozinha e sem amigo. Agora ela tem criaturas para ajud\u00e1-la; criaturas mais fortes que si mesma, mais confi\u00e1veis,  mais \u00fateis e absolutamente devotas. A humanidade n\u00e3o mais est\u00e1 sozinha. Voc\u00ea j\u00e1 pensou nisso desta forma?\" <br>\n", "I, Robot - Issac Asimov, 1950\n", "\n", "\n", "# Uma breve hist\u00f3ria dos algoritmos que aprendem\n", "\n", "<br><br>\n", "**Bem-vindos ao Laborat\u00f3rio Introdut\u00f3rio de Machine Learning!**\n", "<br><br>\n", "\n", "Esse \u00e9 um dos livros que vamos  usar como refer\u00eancia [Python Machine Learning - Second Edition,\n", "Raschka & Mirjalili, September-2017](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition)\n", "\n", "\n", "O primeiro passo para iniciar nossos estudos  \u00e9 compreender que **Machine Learning (ML)** \u00e9 um sub-campo de pesquisa da **Intelelig\u00eancia Artificial (IA)** e,  portanto, n\u00e3o \u00e9 necessariamente seu sin\u00f4nimo como erroneamente sugerem alguns desavisados por ai.  ** Deep Learning (DL)** \u00e9 um dos t\u00f3picos de **Redes Neurais (NN's)** que por sua vez s\u00e3o uma das sub-\u00e1reas de **ML**.  N\u00e3o cometa o erro de confundir indistintamente Deep Learning com Machine Learning.\n", "![](https://blogs.nvidia.com/wp-content/uploads/2016/07/Deep_Learning_Icons_R5_PNG.jpg.png)\n", "\n", "\n", "\n", "# Peceptron\n", "Algoritmos de aprendizagem n\u00e3o s\u00e3o um tema novo.  A defini\u00e7\u00e3o de neur\u00f4nio artificial, o **perceptron**, foi estabelecida no final da d\u00e9cada de 50 (The Perceptron: A Perceiving and Recognizing Automaton, F. Rosenblatt, Cornell Aeronautical Laboratory, 1957) e pode ser resumida na fun\u00e7\u00e3o abaixo:\n", "\n", "![](https://www.dropbox.com/s/s0uvoloszvkg83x/00-Perceptron.jpg?dl=1)\n", "\n", "De forma simplificada, a sa\u00edda de um neur\u00f4nio artificial \u00e9 igual a soma do produto das entradas ***x*** pelos pesos ***w*** aplicados a cada entrada.   As entradas ***x*** de um neur\u00f4nio artificial equivalem aos dentritos de um neur\u00f4nio biol\u00f3gico e a soma **$\\sum_{j=0}^m x_{j}w_{j}$** \u00e9 o est\u00edmulo resultante no ax\u00f4nio, definido por um limiar interno do neur\u00f4nio (**threshold**) que vai determinar a sua \"sensibilidade\" ou quando ser\u00e1 ativado ou n\u00e3o. Em ML preferencialmente utilizaremos a nota\u00e7\u00e3o matricial  **$w^Tx$** onde o produto \u00e9 dado pela transposta de *w* por *x*. A utiliza\u00e7\u00e3o de matrizes permite maior efici\u00eancia computacional e simplifica\u00e7\u00e3o dos c\u00f3digos de ML. \n", "\n", "<br><BR>\n", "Aqui temos a representa\u00e7\u00e3o gr\u00e1fica do perceptron:\n", "\n", "![](https://www.dropbox.com/s/yxvrkm7kk1r991e/01-Perceptron.jpg?dl=1)"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "22040ec2-d174-4010-bb6c-5df66f5bf8bd", "_uuid": "bd1a899f2ca43537a082c6914b680037529c1cd5"}, "source": ["![](https://www.sololearn.com/avatars/b2b6905b-4e53-412a-bcb8-22bfef2bcec5.jpg)\n", "\n", "# Quando as m\u00e1quinas aprendem...\n", "\n", "A aprendizagem se traduz em encontrar pesos que aplicados aos valores de entrada resultem em um determinado valor de sa\u00edda esperado.  Ainda analisando o gr\u00e1fico do perceptron acima, vale notar que por quest\u00f5es de conven\u00e7\u00e3o e c\u00e1lculo a entrada **$x_{0} $** \u00e9 fixada com o valor ***1*** e seu o peso **$w_{0} $**  \u00e9 chamado de **bias**.   Em uma rede neural de apenas uma entrada ter\u00edamos a seguinte equa\u00e7\u00e3o equivalente z =  $w_{0}$ + $w_{1}x_{1}$.  Se voltarmos \u00e0s aulas de matem\u00e1tica fundamental veremos que essa \u00e9 exatamente uma **equa\u00e7\u00e3o reduzida da reta **, onde $w_{0}$ define a \"altura\" da reta e  $w_{1}$ define sua inclina\u00e7\u00e3o no gr\u00e1fico.   \n", "\n", "![](https://www.dropbox.com/s/cdai4n28jp5m5wp/simple_regression.png?dl=1)\n", "\n", "\n", "O que os algoritmos de ML fazem \u00e9 buscar de forma autom\u00e1tica a equa\u00e7\u00e3o que melhor representa o conjunto verdade (**y**) para um conjunto de observa\u00e7\u00f5es ou amostras de entradas.  Uma forma de encontrar a melhor equa\u00e7\u00e3o \u00e9 atrav\u00e9s do c\u00e1lculo sucessivo da diferen\u00e7a entre os valores gerados pela equa\u00e7\u00e3o \"aprendida\" (**\u0177**) e os valores reais observados (**y**). Essa diferen\u00e7a chamamos de **Erro** ou **Perda**. As fun\u00e7\u00f5es de perda  ou **loss functions** s\u00e3o um importante elemento na constru\u00e7\u00e3o de algoritmos inteligentes. Em outras palavras, podemos afirmar que a aprendizagem de m\u00e1quina \u00e9 essencialmente uma tarefa de otimiza\u00e7\u00e3o de fun\u00e7\u00f5es.  Atualmente os principais frameworks de ML implementam diversos algoritmos de otimiza\u00e7\u00e3o, sendo o Gradiente Descendente Estoc\u00e1stico ([SGD](http://ruder.io/optimizing-gradient-descent)) um dos mais populares.\n", "\n", "O processo de ajustar pesos atrav\u00e9s de algoritmos de otimiza\u00e7\u00e3o de fun\u00e7\u00e3o \u00e9 denominado **fit (treino)**, e cada rodada de ajustes \u00e9 chamada de **Epoch (\u00c9poca)**. O ajuste geralmente \u00e9 feito usando um determinado n\u00famero de amostras por vez que chamamos de **Batch (Lote)** .\n", "\n", "No gr\u00e1fico acima temos um problema onde os valores de solu\u00e7\u00e3o podem ser linearmente correlacionadas com as amostras de entrada. Neste caso um algoritmo de ** Regress\u00e3o ** poderia ser aplicado, mas existem varios tipos de algoritmos de ML e cada um vai funcionar melhor em determinados cen\u00e1rios.  Da\u00ed o teorema  **No Free Lunch**  em Machine Learning de David H. Wolpert, que nos recorda de que nenhum algoritmo de ML \u00e9 universalmente melhor que todos os outros em todos cen\u00e1rios (The Lack of A Priori Distinctions Between Learning Algorithms, Wolpert and David H, 1996).\n", "\n", "\n", "\n", "# Rolling in the Deep\n", "\n", "As redes profundas conhecidas como Deep Learning(DL) ganharam maior destaque a partir de 2012 com a vit\u00f3ria de um time universit\u00e1rio canadense em uma competi\u00e7\u00e3o de classifica\u00e7\u00e3o de Imagens, a [ImageNet](http://www.image-net.org/).\n", "\n", "Mas a vit\u00f3ria deste time canadense est\u00e1 intimamente relacionada com avan\u00e7os da d\u00e9cada de 80, sendo um de seus expoentes o cientista de computa\u00e7\u00e3o e psicologia cognitiva **Geoffrey Hinton** da Universidade de Toronto. Hinton \u00e9 conhecido por temas como **Propaga\u00e7\u00e3o Reversa (Backpropagation)**, **M\u00e1quina de Boltzman (Boltzmann Machine** e **Deep Learning**. \n", "\n", "Embora o termo Deep Learning j\u00e1 havia sido aplicado a redes neurais artificiais por Igor Aizenberg em 2000,  foi uma plublica\u00e7\u00e3o de Geoffrey Hinton e Ruslan Salakhutdinov em 2006 que chamou mais aten\u00e7\u00e3o ao mostrar como redes neurais poderiam ser pr\u00e9-treinadas uma camada por vez, e ent\u00e3o fazer ajustes finos por meio de Backpropagation.  Esse avan\u00e7o contribuiu fortemente para a viabilidade das redes DL como hoje conhecemos.\n", "\n", "Em 2012, Hinton e seus dois alunos Alex Krizhevsky e Ilya Sutskever entraram na competi\u00e7\u00e3o ImageNet e ao fazerem uso de redes densas convolucionais (CNN's) e t\u00e9cnicas avan\u00e7adas para reduzir overfitting (ajuste excessivo aos dados de treino que resulta em baixa generaliza\u00e7\u00e3o) conseguiram atingir um incr\u00edvel patamar de erro de 16% contra os 25% alcan\u00e7ados at\u00e9 ent\u00e3o com algoritmos classificadores existentes. Hinton e seus alunos criaram uma empresa que seria adquirida posteriormente pelo Google.\n", "\n", "Abaixo o gr\u00e1fico da arquitetura de sua rede **[AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)** . Esta rede foi treinada por cerca de 5 a 6 dias usando um dataset de 15 milh\u00f5es de imagens classificadas com cerca de 22.000 classes. A equipe da AlexNet al\u00e9m da arquitetura inovadora utilizou duas placas de video GTX 580 (GPU) para poder suportar a alta demanda de processamento desse tipo de rede. O poder de manipula\u00e7\u00e3o de matrizes de uma GPU \u00e9 muito bemvindo com algoritmos de ML j\u00e1 que no final das contas toda informa\u00e7\u00e3o e aprendizagem resultam em matrizes de dados e pesos.\n", "\n", "\n", "![](https://image.slidesharecdn.com/dlcvd2l4imagenet-160802094728/95/deep-learning-for-computer-vision-imagenet-challenge-upc-2016-7-638.jpg?cb=1470131387)\n", "\n", "Nos anos seguintes empresas como Nvidia, Google, Microsoft, Baidu, Amazon, IBM, Ubber, Facebook e Tesla  entrariam de forma ainda mais agressiva na corrida tecnol\u00f3gica por plataformas de intelig\u00eancia artificial mudando o n\u00edvel do jogo para uma aposta de trilh\u00f5es de d\u00f3lares,  e criando com o apoio das diversas comunidades de c\u00f3digo aberto os frameworks poderosos que est\u00e3o hoje ao alcance de alguns cliques. Abaixo algum dos principais frameworks da atualidade:\n", "\n", "![](https://www.dropbox.com/s/lv9ooa3ur8pxc33/deep-learning-developer-frameworks-407.png?dl=1)"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "6d21cbbf-95b9-4e29-bdc7-26df3ca0dfce", "_uuid": "adff681816b86fee2a4d3d647c12af834c37a2ba"}, "source": ["# O que \u00e9 Machine Learning?\n", "<br>\n", "A seguir vamos come\u00e7ar a entender um pouco mais sobre como funciona os principais tipos de algoritmos de ML,  quais s\u00e3o as estrat\u00e9gias de treino e etapas para constru\u00e7\u00e3o destes algor\u00edtimos.\n", "\n", "Ent\u00e3o, uma pergunta importante a fazer \u00e9: o que \u00e9 um algor\u00edtimo de aprendizagem de m\u00e1quina? Uma boa defini\u00e7\u00e3o , emprestada de [*Deep Learning*](http://www.deeplearningbook.org) (Goodfellow-et-al-2016) ,  seria ***\"um algor\u00edtmo de aprendizagem de m\u00e1quina \u00e9 um algor\u00edtmo capaz de aprender com os dados\"* **.\n", "\n", "Ok, mas o que significa aprender? Tom Mitchell em seu livro* Machine Learning* (McGraw-Hill, New York. 97) nos ajuda com uma defini\u00e7\u00e3o bem sucinta: *** \u201cUm programa de computador \u00e9 dito aprender de uma experi\u00eancia E em respeito a alguma classe de tarefa T e medida de performance P, se sua performance em tarefas T, como medido por P, melhora com a experi\u00eancia E\".*** \n", "\n", "Todavia n\u00e3o podemos esquecer que Machine Learning \u00e9 um campo em constru\u00e7\u00e3o e muitos dos conceitos que hoje consideramos  verdade ser\u00e3o descartados nos pr\u00f3ximos anos. O pr\u00f3prio[ Geoffrey Hinton em entrevista com Andrew NG](https://www.youtube.com/watch?v=-eyhCTvrEtE) (outro nome bastante conhecido da galera de ML) diz *\"Meu conselho \u00e9 que leia alguma literatura (*de ML*) mas n\u00e3o leia demais... alguns dizem que voc\u00ea deveria passar v\u00e1rios anos lendo a literatura e s\u00f3 ent\u00e3o come\u00e7ar a trabalhar em suas pr\u00f3prias id\u00e9ias e isso pode ser verdade para alguns pesquisadores, mas para pesquisadores criativos eu penso que o que voc\u00ea quer \u00e9 estudar uma parte da literatura e, ent\u00e3o, notar o que todos est\u00e3o fazendo errado... aquilo que voc\u00ea sente que n\u00e3o est\u00e1 correto, e ao contr\u00e1rio imaginar um jeito de fazer certo... e quando os outros disserem que n\u00e3o serve, apenas continue... tenho um bom princ\u00edpio para ajudar as pessoas a continuarem que \u00e9: ou suas intui\u00e7\u00f5es s\u00e3o boas ou n\u00e3o, se s\u00e3o boas voc\u00ea deveria seguir-las e ao final ter\u00e1 sucesso, se n\u00e3o s\u00e3o boas n\u00e3o importa o que voc\u00ea fa\u00e7a... voc\u00ea deveria confiar nas suas intui\u00e7\u00f5es n\u00e3o h\u00e1 raz\u00e3o para n\u00e3o faz\u00ea-lo...\"* (tradu\u00e7\u00e3o livre)\n", "\n", "\n", "Portanto, a seguir veremos tr\u00eas grandes grupos de algoritimos de ML, mas utilize essa divis\u00e3o apenas como ferramenta de compreens\u00e3o j\u00e1 que alguns algoritmos atuais extravasam essas classifica\u00e7\u00f5es.\n", "\n", "\n", "# Os tr\u00eas tipos de Machine Learning\n", "\n", "Os algoritmos de Machine Learning podem ser agrupados em tr\u00eas tipos principais:\n", "\n", "\n", "![](https://www.dropbox.com/s/btluyzv2e08djan/02-MLTipos.jpg?dl=1)\n", "\n", "## Supervised Learning\n", "O principal objetivo na **aprendizagem supervisionada** \u00e9 \"aprender\" um modelo com base nos dados de treino rotulados que seja capaz fazer predi\u00e7\u00f5es a respeito de dados novos ou de dados futuros. \n", "\n", "Quando os valores esperados s\u00e3o discretos, como por exemplo um algoritmo capaz de reconhecer se uma imagem \u00e9 de um gato ou cachorro, dizemos que se trata de uma **Tarefa de Classifica\u00e7\u00e3o** ou seja buscamos um modelo classificador.  Classifica\u00e7\u00e3o \u00e9 uma subcategoria da aprendizagem supervisionada na qual o foco \u00e9 prever r\u00f3tulos categ\u00f3ricos de novas inst\u00e2ncias baseado nas observa\u00e7\u00f5es do passado.\n", "\n", "A predi\u00e7\u00e3o de  valores cont\u00ednuos, como por exemplo o pre\u00e7o de venda de um im\u00f3vel, \u00e9 tratada por outra subcategoria de aprendizagem supervisionada a **Regress\u00e3o**.  \n", "\n", "\n", "## Reinforcement Learning\n", "Outro tipo de aprendizagem de m\u00e1quina \u00e9 o aprendizado por refor\u00e7o. Em **reinforcement learning** o objetivo \u00e9 desenvolver um **agente** que melhora sua performance baseado em sucessivas intera\u00e7\u00f5es com o ambiente.  Diferentemente das fun\u00e7\u00f5es de perda (loss functions) das t\u00e9cnicas supervisioanadas, aqui o feedback \u00e9 dado por um sistema de recompensas que pune ou premia certos resultados (**reward function**) com base em certos estados do ambiente.\n", "\n", "Um exemplo popular desta arquitetura de aprendizagem \u00e9 uma Engine de Xadrez. Nela o agente decide uma s\u00e9rie de movimentos de acordo com o estado do tabuleiro, a recompensa pode ser definida com base em diversos resultados como sobrepor uma pe\u00e7a inimiga ou tomar sua rainha, ou mesmo a vit\u00f3ria ou derrota final.\n", "\n", "\n", "\n", "\n", "## Unsupervised Learning\n", "Na aprendizagem n\u00e3o supervisionada lidamos com dados n\u00e3o r\u00f3tulados ou com informa\u00e7\u00e3o cuja estrutura n\u00e3o \u00e9 exatamente conhecida.   \n", "\n", "Ao usarmos  t\u00e9cnicas de aprendizagem n\u00e3o supervisionada somos capazes de explorar a estrutura de nossas amostras e extrair informa\u00e7\u00e3o significativa de como essas amostras se relacionam.  Uma das aplica\u00e7\u00f5es pr\u00e1ticas deste tipo de aprendizagem \u00e9 a segmenta\u00e7\u00e3o (**clustering**) de clientes de acordo com suas prefer\u00eancias ou quaisquer outras caracter\u00edsticas que tenhamos \u00e0 disposi\u00e7\u00e3o. \n", "\n", "Outro campo de aplica\u00e7\u00e3o da aprendizagem n\u00e3o supervisionada \u00e9 redu\u00e7\u00e3o de dimensionalidade de dados. A redu\u00e7\u00e3o de dimensionalidade permite eliminar ru\u00eddos e  comprimir informa\u00e7\u00e3o resultando em economia de processamento e armazenamento de dados. "], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "a59f9d08-6aee-4165-baa6-2ddfa9346d79", "_uuid": "a219f277dbabeea4e3da3a879e6c2446a5e0e0e3"}, "source": ["# Botando a m\u00e3o na massa!\n", "\n", "Agora que vimos em linhas gerais o que s\u00e3o algor\u00edtmos de ML, vamos come\u00e7ar com o primeiro passo no desenvolvimento de um sistema de ML:   A prepara\u00e7\u00e3o e explora\u00e7\u00e3o de dados ou **exploratory data analysis (EDA)** termo tamb\u00e9m emprestado do campo de estat\u00edstica.  \n", "\n", "Nos exemplos vou usar um famoso dataset chamado Iris que possui 150 amostras de 3 tipos de flores e os tamanhos de suas p\u00e9talas.  Em ML essas caracter\u00edsticas ou dados de entrada denominamos **features**.\n", "\n", "*Voc\u00ea deve executar cada c\u00e9lula de c\u00f3digo . Use Ctrl + Enter para executar e Shift + Enter para criar uma nova c\u00e9lula*\n", "\n", "## 1 - Bibliotecas "], "cell_type": "markdown"}, {"source": ["#Usamos import para importar as bibliotecas e pacotes que vamos utilizar\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt # library for draring charts\n", "\n", "# A tag '%' \u00e9 uma magic cell que permite alterar o comportamento de uma c\u00e9lula de um notebook\n", "# a magic cell abaixo permite exibir automaticamente os graficos criados com matplotlib \n", "%matplotlib inline\n", "\n", "# Exibe a vers\u00e3o das biblioteca. Em alguns casos \u00e9 importante em que vers\u00e3o est\u00e1 trabalhando\n", "print(\"Numpy Version {}\".format(np.__version__))\n", "print(\"Pandas Version {}\".format(pd.__version__))"], "metadata": {"_cell_guid": "3b7d9c6c-12aa-41b4-953c-cbef8810029b", "_uuid": "5de0e1e74b4ee6b4f300fabcbbb109c82083143c", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "0eed9cc0-2888-46f2-a5e4-86a016637de1", "_uuid": "88185240749e454cca2cd636fc9c6a88a5198227"}, "source": ["## 2 - Caminho do Dataset"], "cell_type": "markdown"}, {"source": ["'''\n", "O dataset que vamos usar foi adicionado automaticamente pelo Kaggle na parte superior \n", "deste notebook na \u00e1rea \"Input Files\". L\u00e1 \u00e9 poss\u00edvel adicionar qualquer dataset p\u00fablico \n", "do Kaggle com o bot\u00e3o \"Add a Data Source\" ou o seu pr\u00f3prio com \"Upload a Dataset\"\n", "\n", "Os dataset adicionados ser\u00e3o postos no caminho \"../input\".\n", "Abaixo executamos o comando linux ls atrav\u00e9s do python para listar os arquivos desta pasta:\n", "'''\n", "\n", "from subprocess import check_outpu\n", "print('Arquivos Iris:')\n", "print(check_output([\"ls\", \"../input/iris\"]).decode(\"utf8\"))"], "metadata": {"_cell_guid": "8d6c3d95-8a72-43ba-b42e-a1f7b1d24072", "_uuid": "1ac38464d1588421a7b2db1f3f3d290a27c1500d", "_kg_hide-output": false, "collapsed": true, "_kg_hide-input": false}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "08b39ae4-1338-45dd-a0be-d2d50c647fae", "_uuid": "4744c41851afcb76ae5dbacc7f254cac02db8b0f"}, "source": ["## 3 - Carregando o Dataset"], "cell_type": "markdown"}, {"source": ["# Existem v\u00e1rias formas de se carregar um dataset para uso em ML as duas mais comuns:\n", "# usar a biblioteca numpy ou carregar um data frame do pandas como abaixo\n", "df_iris = pd.read_csv('../input/iris/Iris.csv')"], "metadata": {"_cell_guid": "668ab5a8-6bf3-460c-9752-3884ce911bbe", "_uuid": "becdadf42dde8a7ce06bbe24a96c75aee321c005", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["# Exibe as primeiras 5 linhas do dataframe\n", "df_iris.head(5)"], "metadata": {"_cell_guid": "166b2060-a74d-49a7-bd28-9c3b4e260ca8", "_uuid": "3074786f42f081c0570bf094b5349cfa76037896", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "134bea85-22c3-4b00-91fc-ed64661364cc", "_uuid": "f2bb120e5624ffbb39a21f25dc25b3a92c5021aa"}, "source": ["## 4 - Explorando os dados com gr\u00e1ficos do matplotlib\n", "\n", "No dataset Iris temos na coluna Species os tipos das flores que vamos analisar. Para isso precisamos transformar as classes de flores em n\u00fameros, para podermos seguir com as an\u00e1lise"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "39bec785-3f85-4291-b366-9071d83d5b45", "_uuid": "8dbdfeb0a42bbf94cb047a5e0feacb7ae2638d39"}, "source": ["**Exibindo a distribui\u00e7\u00e3o das classes**"], "cell_type": "markdown"}, {"source": ["# Verificamos os valores \u00fanicos para as esp\u00e9cies\n", "print(df_iris['Species'].unique())\n", "\n", "# Adicionamos uma nova coluna no data frame e mapeamos com um valor n\u00famerico por classe\n", "df_iris['y'] = df_iris['Species'].map({'Iris-setosa': 1, 'Iris-versicolor': 2, 'Iris-virginica' : 3})\n", "\n", "#plt.scatter(x,y, c=color)\n", "plt.xlabel('Sepal Length Cm')\n", "plt.ylabel('Petal Length Cm')\n", "plt.scatter(df_iris['SepalLengthCm'],df_iris['PetalLengthCm'], c=df_iris['y'])\n", "plt.show()"], "metadata": {"_cell_guid": "50dd38b5-517e-4cd9-90c1-095d43f1ab5c", "_uuid": "ce82bc08306759116599b056bcec4e82f42983e2", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "7a14520e-9736-43cc-a00a-7cc6677b7db4", "_uuid": "133d1553976102f155e19ef0ab88c409734b3382"}, "source": ["Observando o gr\u00e1fico acima podemos verificar que com apenas duas features do dataset \u00e9 poss\u00edvel separar as classes com uma amostra como de exce\u00e7\u00e3o.  Esse tipo de feature \u00e9 muito \u00fatil para construirmos nossos modelos de aprendizagem."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e2b61d08-95bb-40ad-984e-c226e1f1f6e1", "_uuid": "71ec0edcfe30ba10198f769333934c2fd37bef1b"}, "source": ["**Usando fun\u00e7\u00f5es plot e hist do matplotlib para compreender melhor os dados:**"], "cell_type": "markdown"}, {"source": ["# Nesse grafico podemos ver que nosso dataset \u00e9 bastante balanceado\n", "plt.title('Histograma das Classes - Cada Classe tem 50 ocorr\u00eancias')\n", "plt.hist(df_iris['y'])\n", "plt.show()\n", " \n", "plt.title('Histograma da Propriedade Sepal Length\\n Maior n\u00famero de amostras com valor entre 5 e 7 cm')\n", "plt.hist(df_iris['SepalLengthCm'], bins=6)\n", "plt.show()"], "metadata": {"_cell_guid": "9774c342-0200-4527-8984-cb6bcf41fbe4", "_uuid": "6190ec7b0a5afa94bb7f7cc9d11a38c8c235ca7a", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["plt.figure(figsize=(15,10))\n", "plt.title('Exibindo as medidas por amostras')\n", "plt.plot ( df_iris['SepalLengthCm'], c='blue', ) \n", "plt.plot ( df_iris['SepalWidthCm'], c= 'red')\n", "plt.plot ( df_iris['PetalLengthCm'], c= 'green')\n", "plt.plot ( df_iris['PetalWidthCm'], c= 'yellow')\n", "plt.show()"], "metadata": {"_cell_guid": "aa7f6cd1-b23a-411b-a949-fd37163bc8e9", "_uuid": "136177e252e6a8803f7ce7b302e8c9a499abee8b", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "053fce27-5c1f-4216-96b1-296b051a8fe7", "_uuid": "6862058fd499459657c45a7c41b7732b253921bc"}, "source": ["##  5 - Selecionando um algoritmo de ML\n", "Este \u00e9 um Dataset bem pequeno, por\u00e9m bastante balanceado pois temos 50 amostras de cada classe poss\u00edvel.  Vimos que as duas features  SepalLengthCm e PetalLengthCm sozinhas praticamente conseguem definir a separa\u00e7\u00e3o das tr\u00eas classes mas queremos um classificador que fa\u00e7a o maior acerto poss\u00edvel. Ent\u00e3o vamos usar as 4 features que dispomos, nesse caso \u00e9 importante notar que o **campo Id ** ser\u00e1 descartado para an\u00e1lises.  Vamos usar a biblioteca sckit-learn muito \u00fatil para prepara\u00e7\u00e3o de dados e tamb\u00e9m para implementa\u00e7\u00e3o de algoritmos que n\u00e3o envolvam redes neurais.\n", "\n", "Pelas caracter\u00edsticas desse dataset poder\u00edamos ter um bom resultado mesmo usando algoritmos lineares, mas para que voc\u00ea possa verificar o poder de uma rede neural, vamos utilizar 3 neur\u00f4nios de sa\u00edda (um para cada tipo de flor) com 4 entradas cada (uma para cada feature), em algor\u00edtmos de classifica\u00e7\u00e3o o n\u00famero de sa\u00eddas deve ser igual ao n\u00famero de classes quando tivermos mais que duas classes.  \n", "\n", "N\u00e3o se preocupe se n\u00e3o entender alguma parte do c\u00f3digo, vamos explorar todos detalhes nos pr\u00f3ximos Labs, o objetivo aqui \u00e9 voc\u00ea ver uma solu\u00e7\u00e3o completa usando Keras e TensorFlow."], "cell_type": "markdown"}, {"source": ["#veja que ao importar o keras que \u00e9 um wrapper, o TensorFlow ser\u00e1 exibido como backend\n", "from sklearn.model_selection import train_test_split\n", "from keras.models import Sequential\n", "from keras.layers.core import Dense, Activation\n", "from keras.optimizers import SGD\n", "from keras.utils import np_utils"], "metadata": {"_cell_guid": "5ab8f9f6-1d50-4349-9682-0a78bf917427", "_uuid": "ff9782560b819cc7e0019f975ced9ded9ba07a69", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "e77ec279-25d0-4b58-8b5d-5b424a154e0f", "_uuid": "102b151d344b62798f8ce5e8bd985fa99c962752"}, "source": ["## 6 - Feature Engineering \n", "\n", "Nesta fase temos a sele\u00e7\u00e3o das features que v\u00e3o compor nosso Modelo, e seu ajuste para que sejam compat\u00edvel com o formato de entrada do tipo de algor\u00edtm selecionado.  Nossa coluna Y, por exemplo cont\u00e9m valores de 1 a 3, esses valores ser\u00e3o transformados para 0 a 2 e convertidos em tr\u00eas colunas no formato** One-Hot**, que estudaremos nos pr\u00f3ximos labs. Al\u00e9m disso em muitos casos vamos normalizar os valores de entrada antes de aplicar a uma rede neural ou qualquer outro tipo de algoritmo de ML."], "cell_type": "markdown"}, {"source": ["#N\u00famero de classes poss\u00edveis\n", "n_classes = len(df_iris['Species'].unique()) # 3 classes\n", "\n", "#Fazemos slice do Dataframe e as convertemos em matrizes do NumPy\n", "x_full = np.array(df_iris.iloc[:, 1:5].values) # selecionamos as colunas de features e todas linhas\n", "y_full = np.array(df_iris.iloc[:, 6].values) # selecionamos todas linhas mas apenas a coluna 'y' \n", "\n", "# Para algor\u00edtimos de classifica\u00e7\u00e3o com mais de duas classes temos que usar one-hot\n", "# aqui uso uma simples subtra\u00e7\u00e3o para alterar os valores de todas a linhas y\n", "y_full = np_utils.to_categorical(y_full - 1, n_classes) \n", "\n", "print(\"Vericamos se as matrizes de entrada possuem o formato correto\")\n", "print(\"x_full.shape ={}    y_full.shape ={}\".format(x_full.shape, y_full.shape))"], "metadata": {"_cell_guid": "7fa2bfb2-c80e-4dbe-a7c3-e0eeed8b5abd", "_uuid": "d5f22767cfb9017d2e8ca21d4bf8a27ea2874c90", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "31fab741-8f16-46aa-b23b-c59c6c9b4916", "_uuid": "a82aeaafb6b2d7189c0ebe4489589b940121eeef"}, "source": ["## 7 - Split do dataset em treino e valida\u00e7\u00e3o"], "cell_type": "markdown"}, {"source": ["seed = 42 # aqui ficamos o seed rand\u00f4mico, para garantir a reprodu\u00e7\u00e3o de resultados\n", "\n", "# A separa\u00e7\u00e3o do dataset \u00e9 uma t\u00e9cnica muito importante para maior efici\u00eancia\n", "# da valida\u00e7\u00e3o da efic\u00e1cia de um modelo e veremos em maior detalhe nos pr\u00f3ximos labs. \n", "X_train, X_val, y_train, y_val = train_test_split(x_full, y_full,\n", "                                                test_size=0.2, random_state=seed)\n", "\n", "# A classe train_test_split faz o embaralhamento dos dados antes\n", "print(\"Novamente validamos os formatos do split:\")\n", "print(X_train.shape, y_train.shape)\n", "print(X_val.shape, y_val.shape)"], "metadata": {"_cell_guid": "4617dc7b-fef8-4088-a072-2a6bf9d58af9", "_uuid": "116ba880aa00fac1840df107fa19fefcf3de62ab", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "a558d1a8-e2ff-4a83-965a-3c2142af4c0f", "_uuid": "462e3e4f585bd536164f2dc0faac375df460aee8"}, "source": ["## 8 - Definindo o Modelo para nossa Rede Neural"], "cell_type": "markdown"}, {"source": ["# Fixamor o seed permite reproduzir o mesmo resultado e \u00e9 muito importante \n", "#com algumas estrat\u00e9gias de valida\u00e7\u00e3o de treino\n", "np.random.seed(seed) \n", "\n", "#Cada implementa\u00e7\u00e3o de um algor\u00edtimo de ML chamamos de modelo\n", "model = Sequential()\n", "model.add(Dense(n_classes, input_shape=(4,)))\n", "model.add(Activation('softmax')) # vamos usar um ativa\u00e7\u00e3o de threshold conhecida como softmax\n", "model.summary()\n"], "metadata": {"_cell_guid": "ca8199df-a145-4e44-9852-e2c16f44bedf", "_uuid": "2a984442cb7a96bd4711f5e9ad8dfaa753845d1e", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "33e1e6af-14b5-445b-af6c-0000406d08e9", "_uuid": "bb415711369af975c5b4856a603b89bae51fe89b"}, "source": ["Se olharmos acima notamos a exist\u00eancia de 15 par\u00e2metros trein\u00e1veis. Cada um dos tr\u00eas neur\u00f4nios possuem 4 entradas, uma para cada feature, portanto teremos 4 x 3  = 12, ou seja 12 pesos que devem ser treinados. E de onde vem os 15?  \n", "\n", "Lembra que para cada neur\u00f4nio vamos ter uma entrada $x_{0}$ igual a 1 e um peso peso $w_{0}$ que ser\u00e1 o **bias**?   Ent\u00e3o como temos 3 neur\u00f4nios teremos 3 biases a serem treinados. Dai 12 pesos + 3 biases, resultando em 15 par\u00e2metros trein\u00e1veis."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "8de1489d-4d99-458d-9675-706b007f842b", "_uuid": "4f814ddcb923ad53b9318fb703cb0946fb3b7846"}, "source": ["## 9 - Compilando e Treinando nosso Modelo (Finalmente!!)"], "cell_type": "markdown"}, {"source": ["import timeit\n", "\n", "n_epoch = 500 # N\u00famero de \u00c9pocas\n", "batch_size = 10 #tamanho do Batch (quantidade de amostras por lote de treino)\n", "\n", "#Aqui vamos usar o Gradiente Descendente Estoc\u00e1stico, que \u00e9 um tipo de otimizador\n", "sgd = SGD(lr= 0.1) # lr \u00e9 o Learning Rate conceito que vamos ver nos pr\u00f3ximos labs.\n", "\n", "#Todo modelo precisa ser compilado, veja que no par\u00e2metro loss informamos a fun\u00e7\u00e3o de erro\n", "model.compile(optimizer=sgd, loss='categorical_crossentropy') \n", "\n", "#Inicia contagem do tempo\n", "start = timeit.default_timer()\n", "\n", "# Aqui fazemos o fit do modelo e salvamos o resultado de cada epoca em history\n", "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epoch,verbose=0) \n", "\n", "#Inicia contagem do tempo\n", "elapsed = timeit.default_timer() - start\n", "\n", "print(\"Rede Treinada em {} \u00e9pocas durante {:.4f} segundos\".format(n_epoch, elapsed))"], "metadata": {"_cell_guid": "66ab352b-e584-460e-ac35-22242b61a7dd", "_uuid": "1fdbb011bf6cbfa62d63703b90c368fd90e5ef1e", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "45c37822-556d-4593-a15b-14d21b61fab2", "_uuid": "0164ed11a70db538dbd0d3bd40fe19f5a2ba817c"}, "source": ["## 10 - Avaliando o qu\u00e3o inteligente \u00e9 nosso algor\u00edtimo"], "cell_type": "markdown"}, {"source": ["train_loss = model.evaluate(X_train, y_train, verbose=0)\n", "val_loss = model.evaluate(X_val, y_val, verbose=0)\n", "\n", "print('Perda no Treino: {:.4f}%'.format(train_loss))\n", "print('Perda na Valida\u00e7\u00e3o: {:.4f}%'.format(val_loss))"], "metadata": {"_cell_guid": "6d01c39c-be39-444a-819a-ac1c2f9ece5c", "_uuid": "890e9912573e11576699dd1ed44fba4a52f634c3", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "b3006d12-8b2a-48c5-a1a7-16c77dc6f40c", "_uuid": "383c47dd1c254283d91d395c1c1f7b6d52331fbe"}, "source": ["Uau!!! Um excelente resultado com cerca de 5 segundos de treino e uma rede de somente 3 neur\u00f4nios e um m\u00ednimo ajuste de **hiperpar\u00e2metro**, o **Learning Rate** (LR=0.1). \n", "\n", "Uma perda de 0.077% siginifica que na valida\u00e7\u00e3o essa foi nossa margem de erro. \n", "\n", "Hiperpar\u00e2metros ser\u00e3o tema para um pr\u00f3ximo lab. Fiquem a vontade para fazer Fork desse Kernel e testar valores diferentes para n\u00famero de \u00e9pocas, batch size e tipo de otimizador.  "], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "7d391804-5ad3-4862-ac1a-6bd0a1084259", "_uuid": "fce00b6bf7d44230168a1a6bb5e5f6d3eb24fc56"}, "source": ["** Matrix de Confus\u00e3o** \n", "\n", "Esta \u00e9 uma outra forma de visualizar a acur\u00e1cia de uma rede, geralmente aplicamos somente no dataset de valida\u00e7\u00e3o.\n", "Aqui apliquei nos dois para poder exibir onde nosso algoritmo errou."], "cell_type": "markdown"}, {"source": ["y_hat_train = model.predict_classes(X_train)\n", "pd.crosstab(y_hat_train, np.argmax(y_train, axis=1))"], "metadata": {"_cell_guid": "10763f0b-de86-48bf-8f2a-57f0d334a870", "_uuid": "70f22a551dcbe502e3d3b1e4b12c0ed6de05f655", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["y_hat_val = model.predict_classes(X_val)\n", "pd.crosstab(y_hat_val, np.argmax(y_val, axis=1))"], "metadata": {"_cell_guid": "9f844bab-6495-409b-a828-e3e2910350c9", "_uuid": "97b413a3aebcd4e10e83b2d2f5c07eac73657fcf", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "dc3abad2-a075-4c54-a915-2238e5613cc7", "_uuid": "95f422209b27d49d931a7e81562bdcebb17a0ff1"}, "source": ["Se olharmos as duas matrizes de confus\u00e3o veremos que nosso modelo errou apenas 3 amostras das 150. Um \u00f3timo feito para uma rede de penas uma camada densa de 3 neur\u00f4nios."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "364abd4c-b777-4428-b12b-f933b4570d4a", "_uuid": "9d5b4c5a42516db7ceaea03c750a86f240b6dba7"}, "source": ["## 11 - Verificando a curva de aprendizagem de sua rede\n", "\u00c9 poss\u00edvel verificar que a partir da \u00e9poca 300 n\u00e3o h\u00e1 grande melhoria (diminui\u00e7\u00e3o do erro)"], "cell_type": "markdown"}, {"source": ["# a impress\u00e3o dos valores de perda a cada \u00e9poca de treinamento\n", "# permite ter valiosos insights sobre como seu modelo se comporta durante o treinamento\n", "plt.figure()\n", "plt.plot(history.history['loss'])\n", "plt.show()"], "metadata": {"_cell_guid": "600211d0-24bd-4952-ad34-c3fbcf3d4214", "_uuid": "5aea86729bdf8af4ef5002764ac3cdf421620cb8", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "4f47816b-49a8-4f11-9ea5-1ef0c553e6e3", "_uuid": "61f1dfc72ed385a8e6d25d0c9fb30efe43053704"}, "source": ["## Tarefas do Lab\n", "\n", "Crie um fork deste notebook em sua conta (assim voc\u00ea trabalha em sua pr\u00f3pria c\u00f3pia), e nos quadros abaixo escreva c\u00f3digo para carregar o dataset  **House Sales in King County** (kc_house_data.csv) que j\u00e1 est\u00e1 copiado na pasta **../input/housesalesprediction** .  Crie uma abaixo de cada tarefa solicitada e selecione o tipo Code na parte superior da c\u00e9lula. Alguns blocos eu j\u00e1 deixei as c\u00e9lulas criadas.\n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e5cb005a-3d2a-41b3-b087-065bece8279d", "_uuid": "9bcb0d95a0e511f2d50c206a3b48f172560744ff"}, "source": ["### 1 - Carregar o Dataset House Sales de King County"], "cell_type": "markdown"}, {"source": ["import numpy as np \n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "from subprocess import check_output \n", "print('Arquivo House Sales:')\n", "print(check_output([\"ls\", \"../input/housesalesprediction\"]).decode(\"utf8\"))"], "metadata": {"_cell_guid": "1a879fa8-53bf-4cdd-9b0c-056ee60d244a", "_uuid": "6f925b6f5bff3b5357e214823ee0d73203817d0d", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"source": ["#Usando pandas crie um dataframe para armazenar o dataset House Sales\n", "#df_house = pd.read_csv...\n", "df_house = pd.read_csv('../input/housesalesprediction/kc_house_data.csv')"], "metadata": {"_cell_guid": "f551a2d5-8603-472e-842a-74ed4ec00ed7", "_uuid": "a55666ece632d9e0b24f5609e104d0df3b632682", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "f38993f6-3131-4113-9921-81f0571ce2fb", "_uuid": "44a73dd42341518d9fe4ff3d43745552a9850f8b"}, "source": ["### 2 - Exibir as 20 primeiras linhas e as \u00faltimas 5 do data frame df_house"], "cell_type": "markdown"}, {"source": ["#df_house.head(20)\n", "pd.concat([df_house.head(20), df_house.tail(5)])"], "metadata": {"_cell_guid": "f78c774b-52ca-434d-bd0a-be348bd2481b", "_uuid": "863edc2e51463d31e64443b6f99cdfc9040caf48"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "9c7e80ac-eb0c-4b92-9b58-8c2c35c46f52", "_uuid": "e4a781de3c99d499cd976a827633c91f8b285ef6"}, "source": ["### 3 - Adicione uma nova coluna no dataframe com o nome 'yearsale' (o campo date possui a data da venda)"], "cell_type": "markdown"}, {"source": ["df_house['yearsale'] = pd.to_datetime(df_house['date']).dt.year"], "metadata": {"_cell_guid": "66cf2c8e-313e-4d74-a431-a2738fb10d17", "_uuid": "f5f412e4c53bbe11b67f5136db1caed46fe62f53", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "43d8e5be-cb51-45da-a49f-8a4cfb903c1e", "_uuid": "a8b2095abae571a3e39b9efa94645560979aeb42"}, "source": ["### 4 - Criar um gr\u00e1fico que relacione o ano de cosntru\u00e7\u00e3o (yr_built) com o valor da venda (price)\n", "Aqui \u00e9 poss\u00edvel utilizar a fun\u00e7\u00e3o plot ou scatter, veja qual funciona melhor."], "cell_type": "markdown"}, {"source": ["\n", "plt.scatter(df_house['yr_built'],df_house['price'])\n", "plt.show()\n"], "metadata": {"_cell_guid": "7af68ab5-af4d-46ce-a068-2f7cce256936", "_uuid": "580e19a95618b803d4dac815c2b8c3f7226c4ed7", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "94a74408-a60b-434a-b199-95ca4e89a9ac", "_uuid": "34947ff1940dbb158271b62985475aedc0e179c5"}, "source": ["### 5 - Mostrar o histograma de distribui\u00e7\u00e3o das vendas de acordo com o local (zipcode), pre\u00e7o de venda (price) e tamanho das casas (sqft_living)"], "cell_type": "markdown"}, {"source": ["plt.title('Histograma')\n", "plt.hist(df_house['zipcode'] + df_house['price'])\n", "plt.show()\n", "\n", "plt.title('Histograma')\n", "plt.hist(df_house['price'] + df_house['sqft_living'])\n", "plt.show()"], "metadata": {"_cell_guid": "4d57ffad-142e-4d99-a2cf-a45fc329097a", "_uuid": "dd8bd08b798c0e1f97a742a14549dc136365d5a9", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "2186a790-4454-42f7-a550-c9a80f56541b", "_uuid": "e70997d98ef472905dba09848a54c1c3fed0f44c", "collapsed": true}, "source": ["\n", "### 6 - Avaliando de forma geral o conte\u00fado deste dataset qual ou quais colunas voc\u00ea acredita que tenha maior impacto sobre o valor da venda do im\u00f3vel?  Correlacione essas colunas com a coluna price. Plote gr\u00e1ficos que justifiquem sua resposta."], "cell_type": "markdown"}, {"source": ["df_house.corr()\n"], "metadata": {"_cell_guid": "e679adb3-e9e3-462e-94ce-a179b2421af5", "_uuid": "6e60708643dcd4c8fee286b7c25ad3b3b1d0ca6d"}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "ca1702ae-246c-4809-b3ed-0b0aad2784f9", "_uuid": "0af99625cc78c7b9a91a3b4f4ece858e0a8e2ad2", "collapsed": true}, "source": ["### 7 - Em ML recorremos ao conceito estat\u00edstico *Outlier*. Dada uma s\u00e9rie de dados uma amostra que possua um valor muito destoante do restante \u00e9 considerado um *outlier*.   Em algumas an\u00e1lises reconhecer outliers pode ser de grande ajuda para entender a natureza dos dados a serem explorados.  Como voc\u00ea faria para identificar a exist\u00eancia de outliers ao verificarmos o valor das vendas deste dataset?  Dica tente usar gr\u00e1ficos scatter e hist.  "], "cell_type": "markdown"}, {"source": [], "metadata": {"_cell_guid": "bb081b8a-612f-45d3-ad12-ac94e798b2ce", "_uuid": "60cdf8ac474dc0b623e904c0e2d35c21bb65598a", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "21793bcd-e055-43ec-bb24-7660836276e0", "_uuid": "9079e398a98364e06e1d446aa4cb883c101ed936"}, "source": ["### 8 - Usando Python e NumPy calcule o valor m\u00e9dio do square feet (pode utilizar a coluna sqft_living para o c\u00e1lculo) e crie um gr\u00e1fico para exibir todas as amostras cujo valor do square feet de venda seja maior que o valor m\u00e9dio."], "cell_type": "markdown"}, {"source": [], "metadata": {"_cell_guid": "08421456-e32d-4a66-ad08-a5196af05f90", "_uuid": "fe1758103e7657fcd99ff80674ee10ca2369b248", "collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code"}, {"metadata": {"_cell_guid": "bf7bc6ff-215c-4c69-a840-38c517ea947c", "_uuid": "529d079719954ca12dc4575d2b35b4db0b2aec34"}, "source": [], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "1a7cd8e8-366c-41a5-962c-d8f3d421270b", "_uuid": "a4c65152d0c0bc252add40d99e5350e2ffedb82e"}, "source": [], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "a90425a1-667b-48b1-ac4c-cfb70f2a3275", "_uuid": "0f3f25a1c2e6aec9141df9b86b77a28c3c1e44c7"}, "source": [], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "be16178b-0763-4e5a-884e-9054bd229ed1", "_uuid": "48b768481690874073541cae39e540bc2ad51f3b"}, "source": [], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "2e063052-e001-401f-a111-5836f7b0ab3a", "_uuid": "38c0f67a4915f489e3a08a654d670a63f9ed3380"}, "source": [], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e6b714c1-3208-407c-9ff7-a338078e7e9b", "_uuid": "4d5d423f6984850f1fb184bfc789f10f50edeed7"}, "source": [], "cell_type": "markdown"}], "nbformat_minor": 1}