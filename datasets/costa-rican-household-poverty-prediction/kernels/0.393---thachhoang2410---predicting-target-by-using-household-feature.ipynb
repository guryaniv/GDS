{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom tqdm import tqdm\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4acff5bed421bf7e16107152d3df9c210019325"},"cell_type":"code","source":"# fill NaN values of v2a1 = 0 when house_house_status = 0\ntrain['v2a1'][train['tipovivi1']==1] = 0\ntest['v2a1'][test['tipovivi1']==1] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42c5cf204d3024194e1d6ef73c4b866134414bda"},"cell_type":"code","source":"# fill NaN values of v2a1 = 0 when house_house_status = 0\ntrain['v18q1'][train['v18q']==0] = 0\ntest['v18q1'][test['v18q']==0] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee595be9345778668ef153acf6e8b653677ae979","collapsed":true},"cell_type":"code","source":"train['eviv1'] = np.logical_and(np.array(train['eviv1']), np.logical_not(np.array(train['pisonotiene'])))*1\ntest['eviv1'] = np.logical_and(np.array(test['eviv1']), np.logical_not(np.array(test['pisonotiene'])))*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"395468b7650ebbd4fefba6b84f0b5c73e0a4d278","collapsed":true},"cell_type":"code","source":"train = train.replace('no', 0)\ntrain = train.replace('yes', 1)\ntest = test.replace('no', 0)\ntest = test.replace('yes', 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a118a37c667af5962c8cf7b49a231c0c3607362"},"cell_type":"code","source":"print(\"Training shape: \", train.shape)\nprint(\"Training info: \")\ntrain.info()\nprint(\"\\n-----------------------------------------\\n\")\nprint(\"Test shape: \", test.shape)\nprint(\"Test info: \")\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72ebcc0d5e8e423eadaee8ca1ba7f7ac611a6878"},"cell_type":"code","source":"print(\"Test/Train raito: \", test.shape[0]/float(train.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b96217760db6034921cb8dd1706d0dbbaa2d3c95"},"cell_type":"markdown","source":"**Analyzing columns... **"},{"metadata":{"_uuid":"c987ef58c12d2be53e35341322d55ab4573fab77"},"cell_type":"markdown","source":"**Check r4t3, tamhog and hhsize are they the same?**\n"},{"metadata":{"trusted":true,"_uuid":"c031a997302832f99e058b5af398b1a73fc6469e"},"cell_type":"code","source":"train[['r4t3', 'tamhog', 'hhsize', 'tamviv']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"878132034c121935935dbd6db2ccd4461df1fefb"},"cell_type":"code","source":"print(\"Data type of columns:\")\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"scrolled":true,"_uuid":"4926c7b85abdeff5f85d459b468708aa8e44379c"},"cell_type":"code","source":"print(\"Check NaN values in Train set:\")\nisnull = train.isnull().sum().reset_index()\n#isnull[isnull>0]\nisnull.columns = ['Feature', 'Total_null']\ntotal_null = isnull[isnull['Total_null']>0]\ntotal_null","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true,"_uuid":"c27bd67a51dc4328ea7d4c481df2d43206d1b2ef"},"cell_type":"code","source":"print(\"Check NaN values in Test set:\")\nisnull = test.isnull().sum().reset_index()\n#isnull[isnull>0]\nisnull.columns = ['Feature', 'Total_null']\ntotal_null = isnull[isnull['Total_null']>0]\ntotal_null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3ca56931bdf110b9b44a188c0c3b80d46292a0c"},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c0e7ad93a503ab0501304420d737d280f142bb2"},"cell_type":"markdown","source":"**Predicting null monthly rent values for household**"},{"metadata":{"trusted":true,"_uuid":"4f114c6da6feff889deb18541461dce0c4ee307c"},"cell_type":"code","source":"\"\"\"\nfeature_used = ['hacdor', 'rooms', 'hacapo', 'v14a', 'refrig', 'tamhog', 'paredblolad', 'paredzocalo',\n                'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras' ,'paredother' ,'pisomoscer',\n                'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera', 'techozinc', \n                'techoentrepiso', 'techocane', 'techootro', 'cielorazo', 'abastaguadentro', 'abastaguafuera',\n                'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', 'sanitario3',\n                'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4',\n                'elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6', 'epared1', 'epared2',\n                'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3']\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bed54b4cfc13916d38c9891cc4d385537c778dd","collapsed":true},"cell_type":"code","source":"feature_used = ['cielorazo', 'v18q1', 'computer', 'television', 'qmobilephone', 'refrig', 'bedrooms', 'hacdor', 'overcrowding', 'rooms', \n                'hacapo', 'v14a','paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother', 'paredblolad', 'paredzocalo',\n               'abastaguadentro', 'abastaguafuera', 'abastaguano', 'public', 'planpri', 'noelec', 'coopele', 'sanitario1', 'sanitario2', \n                'sanitario3', 'sanitario5', 'sanitario6', 'energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4', 'elimbasu1', \n                'elimbasu2', 'elimbasu3', 'elimbasu4','elimbasu5', 'elimbasu6', 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', \n               'pisomadera', 'techozinc', 'techoentrepiso', 'techocane', 'techootro', 'eviv1', 'eviv2', 'eviv3', 'pisonotiene', 'pisomoscer', \n                'pisocemento', 'pisoother', 'pisonatur', 'pisomadera', 'lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6',\n               'area1', 'area2', 'tipovivi1', 'tipovivi2', 'tipovivi3', 'tipovivi4', 'tipovivi5']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d860429fdf0c55ef33621f34fc0b8de293a81c17"},"cell_type":"code","source":"train_groupby = train.groupby(['idhogar']).mean().reset_index()\ntest_groupby = test.groupby(['idhogar']).mean().reset_index()\n\ntest_missing_rent = test_groupby[test_groupby['v2a1'].isnull()]\ntest_rent = test_groupby[~test_groupby['v2a1'].isnull()]\n\ntrain_missing_rent = train_groupby[train_groupby['v2a1'].isnull()]\ntrain_rent = train_groupby[~train_groupby['v2a1'].isnull()]\n\ntemp_frame = [train_rent, test_rent]\nrent_training = pd.concat(temp_frame)\n\ntemp_frame = [train_missing_rent, test_missing_rent]\nrent_test = pd.concat(temp_frame)\n\nX = rent_training[feature_used]\nY = rent_training[['v2a1']]\n\nX_test = rent_test[feature_used]\nidhogar_test = rent_test['idhogar']\n\n# normalize data\nfrom sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler()\nmin_max_scaler.fit(X)\nmin_max_scaler.fit(X_test)\nX_scale = min_max_scaler.transform(X)\n\n\n# train on linear regression model\n# split train/test set\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nnp.random.seed(0)\nX_train, X_val, Y_train, Y_val = train_test_split(X_scale, Y, test_size=0.1, random_state=0)\n\nmodel = LinearRegression().fit(X_train, Y_train)\nprint(\"Training score: \", model.score(X_train, Y_train))\nprint(\"Validation score: \", model.score(X_val, Y_val))\n\n# predict rent for missing values\nidhogar_test_df = pd.DataFrame(idhogar_test, columns=['idhogar'])\nidhogar_test_df = idhogar_test_df.reset_index().drop(columns=['index'])\n\nrent_predict = model.predict(X_test)\nrent_predict_df = pd.DataFrame(rent_predict, columns=['v2a1'])\ntest_result_predict = pd.concat([idhogar_test_df, rent_predict_df], axis=1, join='inner')\n\n# merge predicting values with original train/test dataframe\ntemp_train = pd.merge(train, test_result_predict, on=['idhogar', 'idhogar'], how='left')\ntemp_train['v2a1_x'].fillna(temp_train['v2a1_y'], inplace=True)\ntemp_train = temp_train.drop(columns='v2a1_y')\ntemp_train = temp_train.rename(index=str, columns={'v2a1_x':'v2a1'})\n\ntemp_test = pd.merge(test, test_result_predict, on=['idhogar', 'idhogar'], how='left')\ntemp_test['v2a1_x'].fillna(temp_test['v2a1_y'], inplace=True)\ntemp_test = temp_test.drop(columns='v2a1_y')\ntemp_test = temp_test.rename(index=str, columns={'v2a1_x':'v2a1'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e92eb802eeb6fa7585056363065496f41b24d8eb","collapsed":true},"cell_type":"code","source":"# store the original data\noriginal_train = train\noriginal_test = test\n\n# set train/test data to the new one which using predicting monthly rent values\ntrain = temp_train\ntest = temp_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24a1ddd14b387324c19ca2f2599d9dabe156ee6a"},"cell_type":"code","source":"print(\"Check NaN values in Train set:\")\nisnull = train.isnull().sum().reset_index()\n#isnull[isnull>0]\nisnull.columns = ['Feature', 'Total_null']\ntotal_null = isnull[isnull['Total_null']>0]\ntotal_null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"150423b49a98271c6b0377439dbbd719061bf268"},"cell_type":"code","source":"print(\"Check NaN values in Test set:\")\nisnull = test.isnull().sum().reset_index()\n#isnull[isnull>0]\nisnull.columns = ['Feature', 'Total_null']\ntotal_null = isnull[isnull['Total_null']>0]\ntotal_null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06485ff3cb2dbb2b64020cfc031b07cbbb41d824"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73628cac524248c2dc54861b486d417f1f8fa357"},"cell_type":"markdown","source":"**Analyzing a given household members**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"81cec5eb2eacbaa27294f0a155331665f67de6d2"},"cell_type":"code","source":"temp_train = train[['Id', 'idhogar', 'r4h3', 'r4m3', 'r4t3']]\ntemp_train.columns=['Id','idhogar','Total_male','Total_female', 'Total_person']\ntemp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"8835b6d4e3e8456b4307abc7de80e1c49a4eee44"},"cell_type":"code","source":"train.loc[train['idhogar'] == '2b58d945f']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eff97e3fa3db7cb0725b4c2bce417f06941ecaaa"},"cell_type":"markdown","source":"**NOTE:**\n- Because the target is the same for all members in a household. The row indicates information of the person. To combine the information from each member in the household, I separate the features of the household (which are the same for all members) and the individual features (different from each member). And then, I combine those features to denote the final feature for the given household.\n\n**To Do: **\n- Garther row by household\n- Concatenate features\n- Train on single-layer neural network"},{"metadata":{"trusted":true,"_uuid":"cb14e4dd968a9d72bf7ed49bbe35ad58ec3370e3","collapsed":true},"cell_type":"code","source":"# replace all NaN value to -1\n#train.fillna(-1, inplace=True)\n#test.fillna(-1, inplace=True)\ntrain = train.fillna(train.mean())\ntest = test.fillna(test.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d17f42005727d463b382b2494f5aca627150a193","collapsed":true},"cell_type":"code","source":"train = train.replace('no', 0)\ntrain = train.replace('yes', 1)\ntest = test.replace('no', 0)\ntest = test.replace('yes', 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"120b4a936c410502c043bf0fe41ae0839497d3a7"},"cell_type":"markdown","source":"**Add other features...**"},{"metadata":{"trusted":true,"_uuid":"7afba17ba9cc43202ab2069e1bee92fba6664ea8","collapsed":true},"cell_type":"code","source":"def extract_features(df):\n    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n    df['rent_to_bedrooms'] = df['v2a1']/df['bedrooms']\n    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n    df['tamhog_to_bedrooms'] = df['tamhog']/df['bedrooms']\n    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n    df['r4t3_to_bedrooms'] = df['r4t3']/df['bedrooms']\n    df['rent_to_r4t3'] = df['v2a1']/df['r4t3']\n    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1'])\n    df['hhsize_to_rooms'] = df['hhsize']/df['rooms']\n    df['hhsize_to_bedrooms'] = df['hhsize']/df['bedrooms']\n    df['rent_to_hhsize'] = df['v2a1']/df['hhsize']\n    df['qmobilephone_to_r4t3'] = df['qmobilephone']/df['r4t3']\n    df['qmobilephone_to_v18q1'] = df['qmobilephone']/df['v18q1']\n    \nextract_features(train)\nextract_features(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c18cc5b7421c3c5a32d3192cb3f2231b421e3dac"},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d7ca7f52ed664ef3971efdb70c67318b90375a8"},"cell_type":"markdown","source":"**Using information from the household: combine individual in household**"},{"metadata":{"_uuid":"679dfc5744a8616e18d927d24a91bb6f8a1be259"},"cell_type":"markdown","source":"List features of individual: \n- dis, =1 if disable person\n- male, =1 if male\n- female, =1 if female\n- estadocivil1, =1 if less than 10 years old\n- estadocivil2, =1 if free or coupled uunion\n- estadocivil3, =1 if married\n- estadocivil4, =1 if divorced\n- estadocivil5, =1 if separated\n- estadocivil6, =1 if widow/er\n- estadocivil7, =1 if single\n- parentesco1, =1 if household head\n- parentesco2, =1 if spouse/partner\n- parentesco3, =1 if son/doughter\n- parentesco4, =1 if stepson/doughter\n- parentesco5, =1 if son/doughter in law\n- parentesco6, =1 if grandson/doughter\n- parentesco7, =1 if mother/father\n- parentesco8, =1 if father/mother in law\n- parentesco9, =1 if brother/sister\n-parentesco10, =1 if brother/sister in law\n- parentesco11, =1 if other family member\n- parentesco12, =1 if other non family member\n- meaneduc,average years of education for adults (18+)\n- instlevel1, =1 no level of education\n- instlevel2, =1 incomplete primary\n- instlevel3, =1 complete primary\n- instlevel4, =1 incomplete academic secondary level\n- instlevel5, =1 complete academic secondary level\n- instlevel6, =1 incomplete technical secondary level\n- instlevel7, =1 complete technical secondary level\n- instlevel8, =1 undergraduate and higher education\n- instlevel9, =1 postgraduate higher education\n- age, Age in years\n\n\n"},{"metadata":{"trusted":true,"_uuid":"363861396fd76da6a3224e3b8b281ee5a7dadb0f","collapsed":true},"cell_type":"code","source":"individual_features = ['idhogar','dis', 'male', 'female', 'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', \n                       'estadocivil5', 'estadocivil6', 'estadocivil7', 'parentesco1', 'parentesco2', 'parentesco3', \n                       'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', \n                       'parentesco10', 'parentesco11', 'parentesco12', 'meaneduc', 'instlevel1', 'instlevel2', \n                       'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', \n                       'instlevel9', 'age']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0e1629ce98cd91f21ec0d81ffc9c4c7e4fb0c9d"},"cell_type":"markdown","source":"Scale train and test set"},{"metadata":{"trusted":true,"_uuid":"0cd12cad170196c0f596fce998c808ceb64c978f","collapsed":true},"cell_type":"code","source":"from sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n\n# get list features which will be scaled\nlist_features = list(set(list(train)) - set(['Id', 'idhogar', 'Target']))\n\n# create a temp set\nscaled_train = train.copy()\nscaled_test = test.copy()\n\n# fit scaler\nscaled_train[list_features] = min_max_scaler.fit_transform(train[list_features])\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\nscaled_test[list_features] = min_max_scaler.fit_transform(test[list_features])\n\n# transform\n#scaled_train[list_features] = min_max_scaler.transform(train[list_features])\n#scaled_test[list_features] = min_max_scaler.transform(test[list_features])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1f3cd75b88e6c11055d3f00c0750d70e8e9290ff"},"cell_type":"code","source":"scaled_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac970a18d9a5ff798aaa0770bec0819e43d0597e"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04fcdd37eaaaacc68c883bd8d203dbcd809bf29e","collapsed":true},"cell_type":"markdown","source":"**Remove(SQBXXX and agesq) out of the training and test set **\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"151d0d179217c64cc8006d7c8a518783e562dbd0"},"cell_type":"code","source":"#scaled_train = scaled_train.drop(columns=['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq'])\n#scaled_test = scaled_test.drop(columns=['SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned', 'agesq'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3dcfe2b6d31172093c48930673d15f2160bc594d"},"cell_type":"markdown","source":"**Get data of head household**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9fb298a462ea20f286d03e256bf7921f15dc668e","collapsed":true},"cell_type":"code","source":"head_household_train = scaled_train[scaled_train['parentesco1']==1]\nhead_household_test = scaled_test[scaled_test['parentesco1']==1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96647842edbbb04d177656cfcf7e4ebee753f732"},"cell_type":"markdown","source":"\"**Get data of not head household**"},{"metadata":{"trusted":true,"_uuid":"174ee7496df25320afe4d01f56e80536cc0a3f8d","collapsed":true},"cell_type":"code","source":"member_household_train = scaled_train[scaled_train['parentesco1']!=1][individual_features]\nmember_household_test = scaled_test[scaled_test['parentesco1']!=1][individual_features]\n#member_household_train = scaled_train[scaled_train['parentesco1']!=1].drop(columns=['Id', 'Target'])\n#member_household_test = scaled_test[scaled_test['parentesco1']!=1].drop(columns=['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"50250b4f6e4d98a38f78309c4f85514c5324ed4c","collapsed":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"def concatenate_features(head_household, member_household):\n    \"\"\"\n    inputs are the dataframe\n    \"\"\"    \n    list_idhogar = []\n    features = -np.ones((head_household.shape[0], (head_household.shape[1]-2)+(member_household.shape[1]-1)*12))\n    for i in tqdm(range(len(head_household))):\n        idhogar = head_household.iloc[i]['idhogar']\n        members = member_household[member_household['idhogar']==idhogar].sort_values(by=['age'])\n        members = members.drop(columns=['idhogar'])\n        list_idhogar.append(idhogar)\n        temp_head_household = head_household[head_household['idhogar']==idhogar].drop(columns=['idhogar', 'Id'])\n        current_index = temp_head_household.shape[1]\n        features[i][:current_index] = np.array(temp_head_household)\n        for j in range(len(members)):\n            next_index = current_index + members.shape[1]\n            features[i][current_index:next_index] = np.array(members.iloc[j])\n            current_index = next_index\n    return (features, list_idhogar)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf99f15bdb6c77e99d3237ba55420c57c8f6e642","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"train_target = head_household_train['Target']\nhead_household_train = head_household_train.drop(columns='Target')\ntrain_features, train_idhogar = concatenate_features(head_household_train, member_household_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"734bbd86fd6a12ad23a228e8b186dbf83f6791e4","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"test_features, test_idhogar = concatenate_features(head_household_test, member_household_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9f9b79d8903bed652e3902e73991936c7617e067"},"cell_type":"code","source":"Y_train = np.array(train_target)\nX_train = train_features\nX_test = test_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3b8065bb1749d84f1edb33f67e073248360d520"},"cell_type":"markdown","source":"**Training**"},{"metadata":{"_uuid":"b91414ae0c6f96cb00aa7429363cd969636fb01c"},"cell_type":"markdown","source":"Preprocessing"},{"metadata":{"_uuid":"f350f4523891d11bc0bcf362c233e7849f60dfc9"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"6cfb70ce4c539485d714f75e0f539c7506734b77","_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"\"\"\"\nfrom sklearn import preprocessing\nmin_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\nmin_max_scaler.fit(train_features)\nmin_max_scaler.fit(test_features)\nX_train = min_max_scaler.transform(train_features)\nX_test = min_max_scaler.transform(test_features)\n\nprint(\"X_train shape: \", X_train.shape)\nprint(\"Y_train shape: \", Y_train.shape)\nprint(\"X_test shape: \", X_test.shape)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b204298cff87afd5d15e39a26f8fa8a8f3e4f25b","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# calculate class weigths because of imbalanced classes\nfrom sklearn.utils import class_weight\n\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(Y_train.flatten()), Y_train.flatten())\ndict_class_weights = dict(enumerate(class_weights))\nprint(\"Class weights: \", dict_class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"044dffa0d69dc8b7c314957d80eacde3ca1db032","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Transform Y_train to multi-class matrix\nY_train = np.array(Y_train, dtype=int)\nlb = preprocessing.LabelBinarizer()\nlb.fit(Y_train)\nprint(\"Class: \", lb.classes_)\nY_train = lb.transform(Y_train)\nprint(Y_train[0:4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5df0f26bc847b4fa734563beeadc0477e848eaf"},"cell_type":"code","source":"# import library\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1160835b1db6a332386b913d477176dc7f42bffd","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# second model:\n# constructing model\nnp.random.seed(0)\nmodel_neuron = Sequential()\n#model.add(Dense(output_dim=2048, input_shape=(X_train.shape[1],),\n#               W_regularizer=l2(1.0), activation='relu'))\n#model.add(Dense(output_dim=512,activation='relu'))\n#model.add(Dropout(.3))\n#model.add(Dense(output_dim=256,activation='relu',input_shape=(X_train.shape[1],)))\n#model.add(Dense(output_dim=128,activation='relu',input_shape=(X_train.shape[1],)))\n#model.add(Dense(output_dim=64,activation='relu',input_shape=(X_train.shape[1],), W_regularizer=l2(1.0)))\nmodel_neuron.add(Dense(output_dim=4, input_shape=(X_train.shape[1],), W_regularizer=l2(1.0)))\nmodel_neuron.add(Activation('softmax'))\nmodel_neuron.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-5), metrics=['accuracy'])\nprint(model_neuron.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bfdb7a3c3770fdd9ceae213289ba5db08ebb153","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"history = model_neuron.fit(X_train, Y_train, nb_epoch=200, batch_size=32, validation_split=0.1, callbacks=[EarlyStopping(patience=10)], class_weight=dict_class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9209b725788919fa3935fe3e8ec50f4bd1f65025"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d9d01887775e75dc04734b5e542fcf47a39d3fd"},"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f4b527219f77dcb79708b579312913d6bac7a18","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ny = [np.argmax(i)+1 for i in Y_train]\nY_predict = model_neuron.predict(X_train)\nclass_predict = [np.argmax(i)+1 for i in Y_predict]\nconfusion_matrix(y, class_predict, labels=[1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85eadc66be5a9f2947eb51507d3e7c059a1b9d70"},"cell_type":"markdown","source":"**Try to use linear regression**"},{"metadata":{"trusted":true,"_uuid":"275088de370e8fb3a68212092943d2959feffe1a","collapsed":true},"cell_type":"code","source":"# split train/test set\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"494c19924cd64554963ae707264506cf968994bc","collapsed":true},"cell_type":"code","source":"temp_class_weights = {}\nfor (class_, weight) in dict_class_weights.items():\n    temp_class_weights[class_+1] = weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47a47ff42b0509820049bb5cc4ff2054b8f4a193"},"cell_type":"code","source":"# train on SVM\nnp.random.seed(1)\nX = X_train\nY = y\nX_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.1, random_state=0)\nmodel = SVC(kernel='linear', C=1, class_weight=temp_class_weights).fit(X_train, Y_train)\nprint(\"Training score: \", model.score(X_train, Y_train))\nprint(\"Validation score: \", model.score(X_val, Y_val))\nfrom sklearn.metrics import f1_score\ny_pred = model.predict(X_train)\nprint(\"F1 score training: \", f1_score(Y_train, y_pred, average='macro'))\ny_pred = model.predict(X_val)\nprint(\"F1 score validation: \", f1_score(Y_val, y_pred, average='macro'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d63df6b8d7227e8def3b3b0ed30993560609a5f1"},"cell_type":"code","source":"class_predict = model.predict(X_train)\nconfusion_matrix(Y_train, class_predict, labels=[1,2,3,4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e80707032996d57bf434515ca0c8bc9ebf5498f","collapsed":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"temp_test = test[['Id', 'idhogar', 'parentesco1']]\n#temp_test = temp_test[temp_test['parentesco1']==1]\ntemp_test_matrix = temp_test.as_matrix()\nclass_predict = model.predict(X_test)\ntest_id = []\npredict_target = []\nfor row_index in temp_test_matrix:\n    try:\n        idhogar_index = test_idhogar.index(row_index[1])\n        predict_target.append(class_predict[idhogar_index])\n    except ValueError:\n        predict_target.append(4)\n    test_id.append(row_index[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f34f46d551fb9a6d46ddd7294e50f55ec955b8b7","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"print(sum(np.array(class_predict)==1))\nprint(sum(np.array(class_predict)==2))\nprint(sum(np.array(class_predict)==3))\nprint(sum(np.array(class_predict)==4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3d06b9f8b3b38c7e811d96a951c65461eb3bd7f3"},"cell_type":"code","source":"# transfer prediction\nsub = pd.DataFrame({'Id':test_id,'Target':predict_target})\noutput = sub[['Id','Target']]\noutput.to_csv(\"output_linear.csv\",index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80422542d27f2dd8a8ef24cf38291399a509774b"},"cell_type":"code","source":"output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c6bf03030d808a3dad1f7b16580042b91a3625c5"},"cell_type":"markdown","source":"**Comeback soon....**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4faaa67bcc8503daa44c5ec34c0b6e62f8933dbb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}