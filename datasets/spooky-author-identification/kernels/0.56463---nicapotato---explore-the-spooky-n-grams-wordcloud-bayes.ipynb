{"cells": [{"cell_type": "markdown", "source": ["## Spooky Spooky Exploration\n", "\n", "An analysis revolving around Intelligibility\n", "\n", "By Nick Brooks"], "metadata": {"_cell_guid": "b235f198-4449-4236-8a3a-ad3e06fa0620", "_uuid": "3af1bd2c28670291d94009198da27e8988568481"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "c4ab602c-7323-4f03-ae3e-f4b5a316d56e", "_uuid": "842a12ccf02b42343cc9b4fb9c2e749f0bd19498"}, "execution_count": null, "source": ["# Packages\n", "import os\n", "import numpy as np\n", "import pandas as pd\n", "import nltk\n", "import random\n", "\n", "# Pre-Processing\n", "import string\n", "from nltk.tokenize import RegexpTokenizer\n", "from nltk.corpus import stopwords\n", "import re\n", "from nltk.stem import PorterStemmer\n", "from nltk.stem.lancaster import LancasterStemmer\n", "from nltk.stem.porter import *\n", "\n", "# Sentiment Analysis\n", "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n", "from nltk.sentiment.util import *\n", "import matplotlib.pyplot as plt\n", "\n", "# Visualization\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "from subprocess import check_output\n", "from wordcloud import WordCloud, STOPWORDS\n", "import seaborn as sns\n", "\n", "# N- Grams\n", "from nltk.util import ngrams\n", "from collections import Counter\n", "\n", "# Topic Modeling\n", "from nltk import WordNetLemmatizer\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.decomposition import NMF, LatentDirichletAllocation\n", "\n", "# Word 2 Vec\n", "from gensim.models import Word2Vec\n", "from sklearn.decomposition import PCA\n", "\n", "# Models\n", "import datetime\n", "from nltk import naivebayes\n", "\n", "import warnings\n", "warnings.filterwarnings(\"ignore\")"]}, {"cell_type": "markdown", "source": ["## Goal:\n", "\n", "Attempt to understand the themes and style of each author using statistical methods, instead of reading the books like a normal person..\n", "\n", "\n", "## Introduction:\n", "\n", "This dataset is comprised of authors who mostly lived in the 19ths century. Earliest of the bunch, Mary Shelley is most famous for her work Frankenstein. Her Gothic Horror style refers to the architectural setting of her stories, which is an iconic style of the medieval era. I can easily imagine a dark stone castle in the night being confronted by a angry mob of villagers with torches and pitchforks! Through this environment, Shelley also explores the contemporary themes of the role of the individual in a secular government, carrying Locke and Rousseau\u2019s burden into the world of fiction.\n", "Although Edgar Allan Poe is also known of residing in the realm of Gothic Horror, his writing is perhaps more centered around an urban setting. Furthermore, while Shelley resided in England and Europe, Poe was a Bostonian who was orphaned at an early age, and lacked the funds and parental guidance of Shelley.\n", "H.P Lovecraft, our final member of the Spooky club, also lived his life in the American Northeast. Similar to Poe, he also struggled to support himself as an author, and his health took a serious toll because of it. Lovecraft's early work is said to be influenced by Poe\u2019s Macabre style. However, in the end, Lovecraft\u2019s obsession with Astronomy led him to center his stories in a cosmic setting, exploring themes of human insignificance amongst ancient gods and prophecies. Do you hear its Call?\n", "\n", "So what?\n", "This brief introduction of the author\u2019s artistic style indicate that there is a lot of overlap in terms of the setting and influence between these three authors. It would be interesting to test the integrity of this hypothesis by analysing the unsupervised technique of word vector of themes such as: Astronomy, Medieval Ages, Gods, Nihilism, Life. \n"], "metadata": {"collapsed": true, "_cell_guid": "54c86000-6374-42c1-a4b0-17cc5b08290b", "_uuid": "cf7694dddbc7355629b4a3d8553726e372375770"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3d059977-9bbc-4794-aebc-609a34735aa6", "_uuid": "de362e8c1dea8258261277b0f92249b305f8b92a"}, "execution_count": null, "source": ["import sys\n", "sys.version"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "ab0ae274-f457-4bf7-8581-73fb35bdb8cc", "_uuid": "552b09b60a5122bda8b9b8e73d7794c99ed51bca"}, "execution_count": null, "source": ["# Read Data\n", "df = pd.read_csv(\"../input/train.csv\", index_col=\"id\")\n", "test = pd.read_csv(\"../input/test.csv\", index_col=\"id\")"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "1d065f08-a75c-4de9-8a2e-b26fbb5a6735", "_uuid": "f4ace0d9496ffe6e64852080c1da2447668a9578", "scrolled": false}, "execution_count": null, "source": ["pd.set_option('max_colwidth', 500)\n", "df.text= df.text.astype(str)\n", "df.author = pd.Categorical(df.author)\n", "df.iloc[:20,:]"]}, {"cell_type": "markdown", "source": ["## First look at sentence samples:\n", "Wow, these sentences sure are Spooky. Except for the last of the bunch, where Lovecraft comments on the mature look of a chinless child. From these samples so far, the writing style definitely seems drawn out and convoluted. Something a modern like me is not completely accustomed to..\n"], "metadata": {"_cell_guid": "52f22aab-d8fe-4e9c-976c-fc6cea1aa7f6", "_uuid": "a9cbdee43f030d8a53c53f0b9f8c6b3b758451da"}}, {"cell_type": "markdown", "source": ["## Pre-Processing\n", "\n", "- Lexicon Processing and Normalization\n", "- Lowercasing and Removing Punctuation\n", "- Tokenization\n", "- Removing Stopwords\n"], "metadata": {"_cell_guid": "76083173-14b1-498d-b35d-5a241ac27576", "_uuid": "0ef77c7861dd2c3ead6c40c3d51ece36ec263b4a"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "cdafd8bc-c4bd-40a5-84c8-afa17e3af70d", "_uuid": "15cb312aff83cff4b04d4dc8b90f829177ce620b"}, "execution_count": null, "source": ["from nltk.stem.lancaster import LancasterStemmer\n", "from nltk.stem.porter import *\n", "#ps = LancasterStemmer()\n", "ps = PorterStemmer()\n", "\n", "tokenizer = RegexpTokenizer(r'\\w+')\n", "stop_words = set(stopwords.words('english'))\n", "\n", "def preprocessing(data):\n", "    txt = data.str.lower().str.cat(sep=' ') #1\n", "    words = tokenizer.tokenize(txt) #2\n", "    words = [w for w in words if not w in stop_words] #3\n", "    #ords = [ps.stem(w) for w in words] #4\n", "    return words\n", "\n", "def wordfreqviz(text, x):\n", "    word_dist = nltk.FreqDist(text)\n", "    top_N = x\n", "    rslt = pd.DataFrame(word_dist.most_common(top_N),\n", "                    columns=['Word', 'Frequency']).set_index('Word')\n", "    matplotlib.style.use('ggplot')\n", "    rslt.plot.bar(rot=0)\n", "\n", "def wordfreq(text, x):\n", "    word_dist = nltk.FreqDist(text)\n", "    top_N = x\n", "    rslt = pd.DataFrame(word_dist.most_common(top_N),\n", "                    columns=['Word', 'Frequency']).set_index('Word')\n", "    print(rslt)"]}, {"cell_type": "markdown", "source": ["## Sentiment Analysis\n", "\n", "I am hoping to get an idea of the general mood of each author. Understanding the mood could potentially point to the most \u201cmacabre\u201d of them all."], "metadata": {"_cell_guid": "c1c72d5d-6bc4-4fc5-a527-93e4a8611942", "_uuid": "9b39978b4590034c829449020f53eb497c41ec78"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "b5c87308-2f2e-4aa7-9cd9-4e4fe92a6072", "_uuid": "db9b29a603c93f9036a157483fdb2f932aa03a39"}, "execution_count": null, "source": ["# Pre-Processing\n", "SIA = SentimentIntensityAnalyzer()\n", "\n", "# Applying Model, Variable Creation\n", "sentiment = df.copy()\n", "sentiment['polarity_score']=sentiment.text.apply(lambda x:SIA.polarity_scores(x)['compound'])\n", "sentiment['neutral_score']=sentiment.text.apply(lambda x:SIA.polarity_scores(x)['neu'])\n", "sentiment['negative_score']=sentiment.text.apply(lambda x:SIA.polarity_scores(x)['neg'])\n", "sentiment['positive_score']=sentiment.text.apply(lambda x:SIA.polarity_scores(x)['pos'])\n", "sentiment['sentiment']=''\n", "sentiment.loc[sentiment.polarity_score>0,'sentiment']='POSITIVE'\n", "sentiment.loc[sentiment.polarity_score==0,'sentiment']='NEUTRAL'\n", "sentiment.loc[sentiment.polarity_score<0,'sentiment']='NEGATIVE'\n", "\n", "# Normalize for Size\n", "auth_sent= sentiment.groupby(['author','sentiment'])[['text']].count().reset_index()\n", "for x in ['EAP','HPL','MWS']:\n", "    auth_sent.text[auth_sent.author == x] = (auth_sent.text[auth_sent.author == x]/\\\n", "        auth_sent[auth_sent.author ==x].text.sum())*100"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "a36ff893-ddc0-4e65-a1d2-54518e340c36", "_uuid": "66782e1424b2cee2f7eacbd7a2e81e700c94f7a5", "scrolled": false}, "execution_count": null, "source": ["ax= sns.barplot(x='sentiment', y='text',hue='author',data=auth_sent)\n", "ax.set(xlabel='Author', ylabel='Sentiment Percentage')\n", "ax.figure.suptitle(\"Author by Sentiment\", fontsize = 24)\n", "plt.show()"]}, {"cell_type": "markdown", "source": ["After normalizing for sentence size by author, I am surprised to find that Lovecraft is the most negative writer, and that Shelley is the most polarized, with the least amount of neutral sentences. This suggests a high volatility between sentences, an author not afraid of taking her readers through a rollercoaster of emotions.\n", "\n", "After reading each author\u2019s wikipedia page, I was really expecting Poe to top the negativity chart, since his writing seemed centered around bleak city streets. Now that I think about it, there isn\u2019t anything too cheerful about the evil space squids, Cthulhu.\n"], "metadata": {"_cell_guid": "e0ca602a-c760-433d-915f-ed44a7c0184c", "_uuid": "517f0ba2c85978013449d180b18b172e69f0ffd4"}}, {"cell_type": "markdown", "source": ["## WordCloud\n", "\n", "Word clouds are great at shedding light on the author\u2019s prefered language."], "metadata": {"_cell_guid": "188c6547-56b0-4e74-89b9-97370a2b94cf", "_uuid": "c904f64b10cb610d45ac3f03c5f06ac7696a0c90"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "c551dc2b-c50f-46c9-ad91-730d5b824845", "_uuid": "b59430083d5a79bc5017aeb3cca52028859b7e9a"}, "execution_count": null, "source": ["# Function\n", "def cloud(text, title):\n", "    # Setting figure parameters\n", "    mpl.rcParams['figure.figsize']=(10.0,10.0)    #(6.0,4.0)\n", "    #mpl.rcParams['font.size']=12                #10 \n", "    mpl.rcParams['savefig.dpi']=100             #72 \n", "    mpl.rcParams['figure.subplot.bottom']=.1 \n", "    \n", "    # Processing Text\n", "    stopwords = set(STOPWORDS) # Redundant\n", "    wordcloud = WordCloud(width=1400, height=800,\n", "                          background_color='black',\n", "                          #stopwords=stopwords,\n", "                         ).generate(\" \".join(text))\n", "    \n", "    # Output Visualization\n", "    plt.figure(figsize=(20,10), facecolor='k')\n", "    plt.imshow(wordcloud)\n", "    plt.axis('off')\n", "    plt.tight_layout(pad=0)\n", "    plt.title(title, fontsize=50,color='y')\n", "    #plt.imshow(plt.recolor( colormap= 'Pastel1_r' , random_state=17), alpha=0.98)\n", "    #fig.savefig(\"wordcloud.png\", dpi=900)"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3cea0578-e18d-4a88-955d-c567b098f26e", "_uuid": "30c03ee1f4f73282fdb2027fe000eab6190750bf"}, "execution_count": null, "source": ["x = \"EAP\"\n", "print(cloud(df[df.author == x]['text'].values,x))"]}, {"cell_type": "markdown", "source": ["This word cloud brings to light some of the propositional words, as well as some simple vocabulary. Unfortunately, the most defining characteristics of Poe do not emerge."], "metadata": {"collapsed": true, "_cell_guid": "d86b97ee-0382-468c-8dbd-01dca86aa328", "_uuid": "91af219a3e8f6ed160aece3024dc5785f999cabc"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "314b18ae-28d6-4fe9-b79e-1ac78345cb6c", "_uuid": "5be78bc8d8cf45e7a1db0467d45d1cf461803c53"}, "execution_count": null, "source": ["x = \"HPL\"\n", "print(cloud(df[df.author == x]['text'].values,x))"]}, {"cell_type": "markdown", "source": ["\"Seemed\", \"Thing\", \"Old\", \"Night\" are words I would expect in the Lovecraft mythos."], "metadata": {"_cell_guid": "83bb2d99-ac26-49b7-b4e2-4a7174426006", "_uuid": "352543fc2916e0aaca333c6a3e59b0e0ce4f6d48"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "019b2a1c-4cc1-47ef-8cd3-02753bbe0320", "_uuid": "b5282d3a8a76a61c49ea78cc45b5f09cbcc911e4"}, "execution_count": null, "source": ["x = \"MWS\"\n", "print(cloud(df[df.author == x]['text'].values,x))"]}, {"cell_type": "markdown", "source": ["My suspicions that Shelley would focus on existential themes is correct. \u201cLife\u201d, \u201cheart\u201d, \u201clove\u201d, \u201csoul\u201d, \u201cdeath\u201d seem right out of Frankenstein. Unfortunately, the dataset does not indicate the novels included."], "metadata": {"_cell_guid": "d2b36d52-77b4-48ee-a38d-11d0c037791d", "_uuid": "1168a46c4834fab3860c2c14c1348f42d611f86a"}}, {"cell_type": "markdown", "source": ["## N Grams\n", "\n", "Another tool leveraging statistical frequency.. N-Grams! This method finds the most common sequence of words by N length. While the word cloud has a sequence length of 1, N-Grams may provide insight into the prose of the author."], "metadata": {"_cell_guid": "9c690025-fc1f-41ec-bbbc-3f90f91c7f61", "_uuid": "3243d4e9c0382d6b5f47aad865a949363fd62f36"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "5a2063bc-c993-4e27-88bd-eb3dce2e8f44", "_uuid": "dee5c78b6d9a37b6f482755186daf19096fba855"}, "execution_count": null, "source": ["## Helper Functions\n", "def get_ngrams(text, n):\n", "    n_grams = ngrams((text), n)\n", "    return [ ' '.join(grams) for grams in n_grams]\n", "\n", "def gramfreq(text,n,num):\n", "    # Extracting bigrams\n", "    result = get_ngrams(text,n)\n", "    # Counting bigrams\n", "    result_count = Counter(result)\n", "    # Converting to the result to a data frame\n", "    df = pd.DataFrame.from_dict(result_count, orient='index')\n", "    df = df.rename(columns={'index':'words', 0:'frequency'}) # Renaming index column name\n", "    return df.sort_values([\"frequency\"],ascending=[0])[:num]\n", "\n", "def gram_table(x, gram, length):\n", "    out = pd.DataFrame(index=None)\n", "    for i in gram:\n", "        table = pd.DataFrame(gramfreq(preprocessing(df[df.author == x]['text']),i,length).reset_index())\n", "        table.columns = [\"{}-Gram\".format(i),\"Occurence\"]\n", "        out = pd.concat([out, table], axis=1)\n", "    return out"]}, {"cell_type": "markdown", "source": ["#### Edgar Allan Poe\n", "\n", "Mr. Crab? (#13 on 2-Gram), did a Spongebob text sample get sneaked in here? Interestingly, 2-Grams has a few French words such as \u201cL\u2019etoile\u201d, and \u201cEspanaye\u201d. Other than that, \u201cha ha\u201d also stands out, since I was under the impression that this was unique to millennial texting.\n", "\n", "In terms of 3-Grams, this sequence length gives a good idea of some of the major characters and locations.\n", "\n", "Finally, 4-Grams also give insight in some strange sayings, like \u201cugh ugh ugh ugh\u201d, and \u201cmille mille mille mille\u201d which is just four times \u201cthousand\u201d in French."], "metadata": {"_cell_guid": "1a4ec41c-1a78-40ca-9467-3d646f021746", "_uuid": "92ef90814705aa1b69352933fe093433443beee4"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "9ea53e31-bd4f-450a-af6f-8f42168a60e2", "_uuid": "63768f82a9116c13ca99df8f23454396ced8d528"}, "execution_count": null, "source": ["gram_table(x=\"EAP\", gram=[1,2,3,4], length=20)"]}, {"cell_type": "markdown", "source": ["#### HP Lovecraft\n", "\n", "\u201cHeh heh heh heh..\u201d said the old women small furry. Lovecraft\u2019s N-Grams could have its own Card Against Humanities edition. His N-Grams give a good amount of insight on his characters and iconic objects, such as the necronomicon, and a slew of characters with strange, ominous features.\n"], "metadata": {"_cell_guid": "e2cbdde5-0cbf-4fa8-a341-11f58b64a560", "_uuid": "046bfb3851ba4db650e23cb3d18ee4b4dc4faf9e"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "145a1d4e-c749-4670-8899-0d2f23bbe9a4", "_uuid": "879929b630acc24ecfd138156b96c62ed6b1ed8a"}, "execution_count": null, "source": ["gram_table(x=\"HPL\", gram=[1,2,3,4], length=20)"]}, {"cell_type": "markdown", "source": ["#### Mary Shelley\n", "\n", "The theme of life and mortality is not evident in much of the higher N-Grams. It is interesting to note that the occurrences of 3 and 4 Grams are very low, suggesting that Shelley does not make use of drawn out phrases. \n"], "metadata": {"_cell_guid": "9380b72b-e73f-4c9d-b50b-791a218efad8", "_uuid": "939ed47fdbf2231810ebd725e7cb82cc172826e0"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "78924925-6a59-4fb4-ab5f-5dbf0ca020a7", "_uuid": "978cf1a70a0f3433b303decd69c356ea98fcc18b"}, "execution_count": null, "source": ["gram_table(x=\"MWS\", gram=[1,2,3,4], length=20)"]}, {"cell_type": "markdown", "source": ["#### N-Gram conclusion\n", "\n", "Within this genre of horror, there seems to be a strange interest in \u201cold man\u201d.\n"], "metadata": {"_cell_guid": "f7ff4ce4-8915-413e-be91-eb5d4690a044", "_uuid": "d7afc336023201b39a5a17ef25a993f6fef61eb3"}}, {"cell_type": "markdown", "source": ["## Unsupervised Learning/ Topic Modeling\n", "\n", "My next goal is to try to use more advanced methods to extract some of the themes, or topics within each author. "], "metadata": {"_cell_guid": "0d56e60f-f1dc-40dc-932e-a43806e5c97d", "_uuid": "8be50b2d5a7390438cfb306d637dbffbbedfd9c9"}}, {"cell_type": "markdown", "source": ["## Latent Dirichlet Allocation\n", "*Full Credit goes to Anisotropic! Check out his amazing notebook*. I was very impressed by his analysis and wanted to see if topics could be applied within each author.\n", "\n", "https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial\n", "\n", "The LDA model uses probability to output the top words of each cluster."], "metadata": {"_cell_guid": "8e512765-0bc9-47c3-8f9c-3abbb999e56b", "_uuid": "e14096a48f34bf015472f5a5630fefa674a07611"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "c12501fd-307c-419e-aea7-dc42b7583f2d", "_uuid": "b6a73c6395554794f37f1e786297566a75bbf2d5"}, "execution_count": null, "source": ["lemm = WordNetLemmatizer()\n", "class LemmaCountVectorizer(CountVectorizer):\n", "    def build_analyzer(self):\n", "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n", "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))\n", "    \n", "# Define helper function to print top words\n", "def print_top_words(model, feature_names, n_top_words):\n", "    for index, topic in enumerate(model.components_):\n", "        message = \"\\nTopic #{}:\".format(index)\n", "        message += \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1 :-1]])\n", "        print(message)\n", "        print(\"=\"*70)\n", "    \n", "def LDA(data):\n", "    # Storing the entire training text in a list\n", "    text = list(data.values)\n", "    # Calling our overwritten Count vectorizer\n", "    tf_vectorizer = LemmaCountVectorizer(max_df=0.95, min_df=2,\n", "                                              stop_words='english',\n", "                                              decode_error='ignore')\n", "    tf = tf_vectorizer.fit_transform(text)\n", "\n", "\n", "    lda = LatentDirichletAllocation(n_topics=6, max_iter=5,\n", "                                    learning_method = 'online',\n", "                                    learning_offset = 50.,\n", "                                    random_state = 0)\n", "\n", "    lda.fit(tf)\n", "\n", "    n_top_words = 10\n", "    print(\"\\nTopics in LDA model: \")\n", "    tf_feature_names = tf_vectorizer.get_feature_names()\n", "    print_top_words(lda, tf_feature_names, n_top_words)"]}, {"cell_type": "markdown", "source": ["#### Edgar Allan Poe"], "metadata": {"_cell_guid": "e3a891b4-48f2-458e-954f-13f656f21e0e", "_uuid": "029f1af5dac5f3e4a7b1e3351b3b49f580c91625"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "b9cab8f0-a31c-409d-befa-ac68d30fc0a9", "_uuid": "80a2a49c7c8f698361e802df7740e8a248e8e0b9", "scrolled": false}, "execution_count": null, "source": ["x = \"EAP\"\n", "LDA(df.text[df.author==x])"]}, {"cell_type": "markdown", "source": ["To me, topic #1 seems the most interesting since it suggest some kind of existential theme.\n", "\n", "\n", "#### Mary Shelley"], "metadata": {"_cell_guid": "7a00cf96-7c7f-4d13-bb1b-963311209e0c", "_uuid": "2b9e1b3213b04df3e93146c735b228316f6f7d11"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "b392c596-9268-4fce-99e9-9bfffcdc3361", "_uuid": "5d7c1cb20303fb2239abc34ff673dfd8abc00a87"}, "execution_count": null, "source": ["x = \"MWS\"\n", "LDA(df.text[df.author==x])"]}, {"cell_type": "markdown", "source": ["Words such as \"Love\", \"Life\", \"Hope\" reinforce the observations made from the N-Grams and my prior assumptions about Shelley's themes.\n", "\n", "#### HP Lovecraft"], "metadata": {"_cell_guid": "87f7ef27-e88b-4bca-b750-9c108a10828f", "_uuid": "d4c345039ff48775def2ca76fa08a40b0bea3218"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "c1cb347f-ec82-4845-816d-414bca84a676", "_uuid": "39ccea1ba25abbeb909e63d6cf9c4b2f17675ecf"}, "execution_count": null, "source": ["x = \"HPL\"\n", "LDA(df.text[df.author==x])"]}, {"cell_type": "markdown", "source": ["Mostly setting centric topics.\n", "\n", "## Word 2 Vec"], "metadata": {"_cell_guid": "c8b66ef1-512f-4ec1-9efb-be84700e2d40", "_uuid": "d6ad3d60bbba678539dd149e94e1ffb29257914d"}}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "00896219-a0c6-4f1f-818e-e1081a61b912", "_uuid": "1b26a720e02a94592f599e726397488871ecb45d"}, "execution_count": null, "source": ["def model_prep(df_in):\n", "    df_in['tokenized'] = df_in.text.astype(str).str.lower() # turn into lower case text\n", "    df_in['tokenized'] = df_in.apply(lambda row: tokenizer.tokenize(row['tokenized']), axis=1) # apply tokenize to each row\n", "    df_in['tokenized'] = df_in['tokenized'].apply(lambda x: [w for w in x if not w in stop_words]) # remove stopwords from each row\n", "    #df_in['tokenized'] = df_in['tokenized'].apply(lambda x: [ps.stem(w) for w in x]) # apply stemming to each row\n", "    return df_in\n", "\n", "def w2vec(data,yrange):\n", "    wvec = model_prep(data)\n", "    model = Word2Vec(data.tokenized, min_count=1, max_vocab_size=250)\n", "    # model.save('model.bin')\n", "    # new_model = Word2Vec.load('model.bin')\n", "    \n", "    # summarize the loaded model\n", "    print(model)\n", "\n", "    X = model[model.wv.vocab]\n", "    pca = PCA(n_components=2)\n", "    result = pca.fit_transform(X)\n", "    # create a scatter plot of the projection\n", "    plt.rcParams[\"figure.figsize\"] = [16,9]\n", "\n", "    plt.scatter(result[:, 0], result[:, 1])\n", "    words = list(model.wv.vocab)\n", "    for i, word in enumerate(words):\n", "        plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n", "\n", "    plt.ylim(yrange)   \n", "\n", "    plt.show()\n", "    \n"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "cb9d2fc8-67a7-4ee1-bc8e-c3323afc05a6", "_uuid": "8fed81866ac35a0927d7e6497a9276a96400afbf"}, "execution_count": null, "source": ["x = \"MWS\"\n", "w2vec(df[df.author==x],[-.015,.015])"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "871d5b86-4c75-4ad9-8260-139268f1de96", "_uuid": "0993150e511fe799d3bc5de8c2f1608becb5ae43"}, "execution_count": null, "source": ["x = \"EAP\"\n", "print(\"\\n\",x)\n", "w2vec(df[df.author==x],[-.014,.014])"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "e6109094-7d4d-4123-bd54-d905dacb144c", "_uuid": "6a18839681d52d110689173ced59dc54cdc24c57"}, "execution_count": null, "source": ["x = \"HPL\"\n", "print(\"\\n\",x)\n", "w2vec(df[df.author==x],[-.015,.015])"]}, {"cell_type": "markdown", "source": ["## Naive Bayes\n", "\n", "Generative Models based off Bayes' Rule and Conditional Probabilities"], "metadata": {"_cell_guid": "a69a139c-4a2c-4461-b51c-078f94bcad56", "_uuid": "8e5b0caf01a45f03dac9672a70191ba35f2ba15c"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "26d1e80b-7207-440f-a572-5466d2bca125", "_uuid": "4462e2f97ca67da00052bc36fe7c154eb992f542"}, "execution_count": null, "source": ["print(\"Train Vocabulary Size: {}\".format(len(nltk.FreqDist(preprocessing(df['text'])))))\n", "print(\"Train Size: {}\".format(len(df)))\n", "print(\"Test Vocabulary Size: {}\".format(len(nltk.FreqDist(preprocessing(test['text'])))))\n", "print(\"Test Size: {}\".format(len(test)))"]}, {"outputs": [], "cell_type": "code", "metadata": {"_kg_hide-input": true, "collapsed": true, "_cell_guid": "9660e866-bc2b-4b5f-963e-e93df0767dd9", "_uuid": "e57d52545c638712d6406e91449c4c969b92cc94"}, "execution_count": null, "source": ["# Number of features\n", "all_words = nltk.FreqDist(preprocessing(df['text'])) # Calculate word occurence from whole block of text\n", "word_features = list(all_words.keys())[:20000] \n", "# Number of columns (can't exceed vocab, only shrink it) from largest to smallest\n", "\n", "# Helper Functions\n", "# for each review, records which uniqeue words out of the whole text body are present\n", "def find_features(document):\n", "    words = set(document)\n", "    features = {}\n", "    for w in word_features:\n", "        features[w] = (w in words)\n", "\n", "    return features\n", "\n", "# Function to create model features\n", "def model_prep(state, df_in):\n", "    df_in['tokenized'] = df_in.text.astype(str).str.lower() # turn into lower case text\n", "    df_in['tokenized'] = df_in.apply(lambda row: tokenizer.tokenize(row['tokenized']), axis=1) # apply tokenize to each row\n", "    df_in['tokenized'] = df_in['tokenized'].apply(lambda x: [w for w in x if not w in stop_words]) # remove stopwords from each row\n", "    df_in['tokenized'] = df_in['tokenized'].apply(lambda x: [ps.stem(w) for w in x]) # apply stemming to each row\n", "    if state == \"Train\":\n", "        print(\"{} Word Features: {}\".format(state, len(word_features)))\n", "        print(\"All Possible words in {} set: {}\".format(state, len(all_words)))\n", "        # Bag of Words with Label\n", "        featuresets = [(find_features(text), LABEL) for (text, LABEL) in list(zip(df_in.tokenized, (df_in.author)))]\n", "        print(\"Train Set Size: {}\".format(len(featuresets)))\n", "        print(\"Train Set Ready\")\n", "        return featuresets, word_features\n", "    else:\n", "        # Bag of Words without Labels\n", "        featuresets = [(find_features(text)) for (text) in list(df_in.tokenized)]\n", "        print(\"Submission Set Size: {}\".format(len(featuresets)))\n", "        print(\"Submission Set Ready\")\n", "        return featuresets"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "3424fc5d-ffe3-4edc-a2aa-a95a18675895", "_uuid": "dee64c1bb0e2749fe79e391c01fb10800afa30e9"}, "execution_count": null, "source": ["trainset, word_features= model_prep(\"Train\", df_in=df)"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "98a04513-135c-4b00-ac3f-de051c99464b", "_uuid": "221740d62977040f27bcc2ed8fa2a0f13eb211f9"}, "execution_count": null, "source": ["submissionset = model_prep(\"Test\", df_in=test)"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "6a77c12b-a159-49d7-a8f0-40f9cc0f4828", "_uuid": "b959d48d96d79c67065e392c1769a6be0ae0599f"}, "execution_count": null, "source": ["training_set = trainset[:15000]\n", "testing_set = trainset[15000:]\n", "del trainset"]}, {"cell_type": "markdown", "source": ["## Execute Model"], "metadata": {"_cell_guid": "9dc700aa-e99a-488a-84e4-b2764e55f0c4", "_uuid": "427611725ecbd379945c27f56c61566ebbe61d9a"}}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "5c454544-f85b-48bb-bbf5-a979d59e28dd", "_uuid": "8bdd9d0da10f0fb58fdb89c94c58e9ecb32a9c24"}, "execution_count": null, "source": ["start = time.time()\n", "classifier = nltk.NaiveBayesClassifier.train(training_set)\n", "# Posterior = prior_occurence * likelihood / evidence\n", "end = time.time()\n", "print(\"Model took %0.2f seconds to train\"%(end - start))"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "07ffb111-974c-4721-84f7-08f909ac9532", "_uuid": "dc3b9f47047bdd5cb260db2a2e1033c9fc44a61f"}, "execution_count": null, "source": ["# Edgar Allan Poe [EAP], Mary Shelley[MWS], and HP Lovecraft[HPL]"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "210517b5-cb9f-47b4-862c-cda1cc72918d", "_uuid": "6164ec398cd40b72c75fc2f119d48b0ff7967a10", "scrolled": false}, "execution_count": null, "source": ["print(\"Classifier Test Accuracy:\",(nltk.classify.accuracy(classifier, testing_set))*100)\n", "print(classifier.show_most_informative_features(40))"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "efc5bcb1-9da7-484c-a9b9-9a6e56124671", "_uuid": "f7e169ad81739f7f1deb3d7521e856eab547564b"}, "execution_count": null, "source": ["classifier.labels()"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "8ed6f754-712c-4b2b-a2f5-fd6c04c621f9", "_uuid": "43411648ea57864bff445d0cb693e3d83694682c"}, "execution_count": null, "source": ["labels = classifier.labels()\n", "submission = pd.DataFrame(columns=labels)\n", "for x in submissionset:\n", "    dist = classifier.prob_classify(x)\n", "    submission= submission.append({labels[0]:dist.prob(labels[0]),\n", "                                   labels[1]:dist.prob(labels[1]),\n", "                                   labels[2]:dist.prob(labels[2])},ignore_index=True)\n", "submission[\"id\"] = test.index\n", "submission= submission[[\"id\", \"EAP\",\"HPL\",\"MWS\"]]"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "7b63af9a-3621-4f34-bc31-0f33e2dee308", "_uuid": "e83955381a202243f7fc0b58d7a5483828f52108"}, "execution_count": null, "source": ["submission.head()"]}, {"outputs": [], "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "631ae152-2f33-4a59-83a1-8b670cbf6a04", "_uuid": "14f99d06c0d6387f049980a29d3d80b384dcc538"}, "execution_count": null, "source": ["submission.to_csv(\"naive_spooky.csv\", index=False)"]}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1}