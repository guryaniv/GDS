{"cells": [{"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "39d17f96-4842-412a-ac5d-78d8140bf0a0", "_uuid": "08e48b15d299cee47d867887485ba08958312379"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "import seaborn as sns\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "import re\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from collections import Counter\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from nltk.stem.porter import *\n", "from string import punctuation\n", "import copy\n", "import itertools\n", "\n", "import sklearn.ensemble\n", "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import accuracy_score, log_loss\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "39d773d4-6961-4a94-990f-a0398f1b33ec", "_uuid": "36330fb49a3bac4d0ac63e25fc0f4ed42fb28d60"}, "cell_type": "code", "source": ["train_data = pd.read_csv(\"../input/train.csv\")\n", "test_data = pd.read_csv(\"../input/test.csv\")\n", "head_count = 2\n", "stops = set(stopwords.words(\"english\"))\n", "accuracy_lst = list()\n", "logloss_lst = list()"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "3ec4ad58-caa9-44d7-abe2-daa5e6a3e92c", "_uuid": "76b12a2258d72b0c7c2e44456d3163e3ca39c8df"}, "cell_type": "code", "source": ["auth_vc = train_data['author'].value_counts()\n", "train_data['author_lbl'] = train_data['author'].map({\n", "    'EAP': 1,\n", "    'MWS': 2,\n", "    'HPL': 3\n", "})"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "05d14bbf-204d-4731-a5e3-e993cb967fbe", "_uuid": "924ee9fcdfb284bd5dc577a255392eeaf53c9968"}, "cell_type": "code", "source": ["def tokenize(text):\n", "    word_tokens = nltk.word_tokenize(text)\n", "    word_tokens = [w for w in word_tokens if not w in stops]\n", "    word_tokens = list(map(str.lower, word_tokens))\n", "    return word_tokens\n", "\n", "def get_bag_of_words(row):\n", "    return Counter(row['tokens'])\n", "\n", "def total_punctuations(row):\n", "    return len([p for p in row['tokens'] if p in list(punctuation)])\n", "                   \n", "def total_stopwords(row):\n", "    return len([p for p in row['tokens'] if p in stops])\n", "\n", "def get_random_idx(df):\n", "    return np.random.choice(df.index.values)"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "9a9d0936-79fb-4e98-858a-d053371cbeff", "_uuid": "4e867c302c25b5ef666dddf71858147053024fda"}, "cell_type": "code", "source": ["def generate_text_features(df):\n", "    df['n_words']               = df.apply(lambda row: len(row['text']), axis=1)\n", "    df['tokens']                = df.apply(lambda row: tokenize(row['text']), axis=1)\n", "    df['n_tokens']              = df['tokens'].map(len)\n", "    df['bow']                   = df.apply(lambda row: get_bag_of_words(row), axis=1)\n", "    df['n_puncts']              = df.apply(lambda row: total_punctuations(row), axis=1)\n", "    df['#,']                    = df.apply(lambda row: row['bow'][','], axis=1)\n", "    df['#;']                    = df.apply(lambda row: row['bow'][';'], axis=1)\n", "    return df"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "1eaeec96-7062-4c0d-9d37-d82e371fa5bd", "_uuid": "2db146dbfa772ee0075f3960cf5357ef7952cf38"}, "cell_type": "code", "source": ["train_data = generate_text_features(train_data)"]}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "fe5c033d-a6dc-4c5d-93e2-7d3277deacd1", "_uuid": "53706d0b2f5b2e93f90db67658f48db3873e03a2"}, "cell_type": "code", "source": ["punctuation"]}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "deabe2a2-6a3f-440e-a4bd-fce4bbe62540", "_uuid": "a7f438afc4082b7f139393b78af6b922f66ecc24"}, "cell_type": "code", "source": ["features = ['n_puncts', '#;']\n", "X = train_data[features]\n", "\n", "y = train_data['author_lbl']\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n", "clf = RandomForestClassifier(random_state=0)\n", "clf = clf.fit(X_train, y_train)\n", "\n", "y_proba = clf.predict_proba(X_test)\n", "log_loss_score = log_loss(y_test, y_proba)\n", "logloss_lst.append(\"{:>5.3f}\".format(log_loss_score))\n", "\n", "y_predict = clf.predict(X_test)\n", "predict_df = pd.DataFrame({'actual': y_test.ravel(), 'predicts': y_predict})\n", "predict_df['score'] = predict_df.apply(lambda x: 1 if x['actual'] == x['predicts'] else 0, axis=1)\n", "accuracy = predict_df['score'].sum() / len(predict_df)\n", "accuracy = accuracy * 100\n", "accuracy_lst.append(\"{:>5.3f}\".format(accuracy))\n", "\n", "print(\"Logloss \", \", \".join(logloss_lst))\n", "print(\"Accuracy \", \", \".join(accuracy_lst))"]}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "06b641e6-8212-48cc-aae1-8d46d74bc94d", "_uuid": "4d9d7dc76a8c7078817c2502b44325e9e5303452"}, "cell_type": "code", "source": []}], "nbformat_minor": 1, "metadata": {"language_info": {"file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.3", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}