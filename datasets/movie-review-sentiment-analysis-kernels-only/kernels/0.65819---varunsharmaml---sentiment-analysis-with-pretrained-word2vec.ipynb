{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Dense, Input, LSTM, GRU, Conv1D, MaxPooling1D, Concatenate\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.initializers import glorot_uniform\n\nfrom sklearn.preprocessing import OneHotEncoder\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"787c5686ac8a2b6198b0cd745d14b7ae1abd4fed"},"cell_type":"code","source":"train = pd.read_csv(\"../input/movie-review-sentiment-analysis-kernels-only/train.tsv\", sep=\"\\t\")\ntest = pd.read_csv(\"../input/movie-review-sentiment-analysis-kernels-only/test.tsv\", sep=\"\\t\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1ba2deaabb4758e7cd9179f70dad8b0115b1e17","collapsed":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caef432116994c8cfedc6d349b3b9188c796877e","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8edd4902fe459a6038cd80082939f81ca88f1a3","collapsed":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"70fe7cd6a59ef6fe30f7fa73fc6cf65d6a50cdf0"},"cell_type":"code","source":"import string\ntr = str.maketrans(string.punctuation, \" \"*32)\ndef modify_phrase(ph, tr):\n    ph = ph.lower()\n    return ph.translate(tr).strip()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a88ab3db2f819838154b0fd4f9965491ce522cd9","collapsed":true},"cell_type":"code","source":"modify_phrase(\"Hey there! I am here, using whatsapp!!...\", tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6e0a6892f975f1817a06e36cfc45c708f7b44581"},"cell_type":"code","source":"import io\n\ndef load_vectors(fname):\n    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n    vocab_size, dim = map(int, fin.readline().split())\n    word_to_vec_map = {}\n    words = set()\n    for line in fin:\n        tokens = line.rstrip().split(' ')\n        words.add(tokens[0])\n        word_to_vec_map[tokens[0]] = np.array(tokens[1:], dtype=np.float64)\n    i = 1\n    words_to_index = {}\n    index_to_words = {}\n    for w in sorted(words):\n        words_to_index[w] = i\n        index_to_words[i] = w\n        i = i + 1\n    return word_to_vec_map, words_to_index, index_to_words, vocab_size, dim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"549d89cfe5597cd578893dfd8421c8967118f35a","collapsed":true},"cell_type":"code","source":"word_to_vec_map, word_to_index, index_to_words, vocab_size, dim= load_vectors('../input/fasttext-wikinews/wiki-news-300d-1M.vec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49954e77ce699d42833132fd031dcbb7585d3ff8","collapsed":true},"cell_type":"code","source":"train['Phrase'] = train.apply(lambda row: modify_phrase(row.Phrase, tr), axis=1)\ntest['Phrase'] = test.apply(lambda row: modify_phrase(row.Phrase, tr), axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d7a140033379f89020f82f33a1db7e9acb1cce81"},"cell_type":"code","source":"X = np.array(train.Phrase)\nY = np.array(train.Sentiment)\nX_test = np.array(test.Phrase)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb4e8c9704d11d8a40cee84fbb1a27659bf72d12","collapsed":true},"cell_type":"code","source":"X.shape, Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46ad1ad1edf8e94a1d746a123c1bd05fa5c46b64","collapsed":true},"cell_type":"code","source":"encode = OneHotEncoder(sparse=False)\nY = encode.fit_transform(np.reshape(Y, (Y.shape[0], 1)))\nY.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"773a58e4163b6e5c95f6995e84f7491e08e30498"},"cell_type":"code","source":"maxLen = 60          #maximum length of sentences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"148da638d55607105ef402ada27575b22095d206"},"cell_type":"code","source":"def sentences_to_indices(X, word_to_index, maxLen):\n    m = X.shape[0]                                   # number of training examples\n    \n    X_indices = np.zeros((m, maxLen))\n    \n    for i in range(m):\n        sentence_words = X[i].lower().strip().split()\n        j = 0\n        for w in sentence_words:\n            if w not in word_to_index:\n                w = \"person\"        #mostly names are not present in vocabulary\n            X_indices[i, j] = word_to_index[w]\n            j = j + 1\n    \n    return X_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"80d2ec379d4d826f8ad5d4a069ee0eb86650dcc2"},"cell_type":"code","source":"X_vec = sentences_to_indices(X, word_to_index, maxLen)\nX_test_vec = sentences_to_indices(X_test, word_to_index, maxLen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5dbf0c48046c96ad5847ea024b0a3f82025d27de"},"cell_type":"code","source":"def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n    vocab_len = len(word_to_index) + 1\n    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]\n    \n    emb_matrix = np.zeros((vocab_len, emb_dim))\n    \n    for word, index in word_to_index.items():\n        emb_matrix[index, :] = word_to_vec_map[word]\n\n    embedding_layer = Embedding(input_dim = vocab_len, output_dim = emb_dim, trainable = False) \n\n    embedding_layer.build((None,))\n    embedding_layer.set_weights([emb_matrix])\n    \n    return embedding_layer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d1715cc6c97b8c48c0e18f4dbe305972e6c89fc3"},"cell_type":"code","source":"def movie_review_analysis(input_shape, word_to_vec_map, word_to_index):\n    sentence_indices = Input(shape=input_shape, dtype='int32')\n    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n    \n    embeddings = embedding_layer(sentence_indices)   \n    \n    X1 = Conv1D(128, 3)(embeddings)\n    X2 = Conv1D(128, 3)(embeddings)\n    X1 = MaxPooling1D(pool_size=4)(X1)\n    X2 = MaxPooling1D(pool_size=5)(X2)\n    X = Concatenate(axis=1)([X1, X2])\n    \n    X = GRU(units=128, dropout=0.4, return_sequences=True)(X)\n    X = LSTM(units=128, dropout=0.3)(X)\n    \n    X = Dense(units = 32, activation=\"relu\")(X)\n    X = Dense(units=5, activation='softmax')(X)\n    \n    model = Model(inputs=sentence_indices, outputs=X)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31ac24595a27faa23f9ea78e82b14c514da6499c","collapsed":true},"cell_type":"code","source":"model = movie_review_analysis((maxLen,), word_to_vec_map, word_to_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"50ca8c104b49466b2d6c7fa695952a6a95fdcbda"},"cell_type":"code","source":"model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e363d9842f06b505dbf284d47bb5e25670d118f","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43a1be6bd01b8ee0c27f360e97da3cc102a6a02c","collapsed":true},"cell_type":"code","source":"track = model.fit(X_vec, Y, batch_size=128, epochs=9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18998a4e24609d86cc2f08597e1883e8a3e80ef7","collapsed":true},"cell_type":"code","source":"plt.plot(track.history['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be47a64d50dd506cde85dc626142295dab10f962","collapsed":true},"cell_type":"code","source":"plt.plot(track.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd7633380106be54f13d0dcdb73eeb4f87b91d7d","collapsed":true},"cell_type":"code","source":"preds = model.predict(X_test_vec, batch_size=128, verbose=1)\npreds = preds.argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"97a84dddeb36ab885b7a9f6a07d57097af2fbc97"},"cell_type":"code","source":"submit = pd.read_csv(\"../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv\")\nsubmit[\"Sentiment\"] = preds\nsubmit.to_csv(\"submitNow.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"56be8c8862003906a902d43fec8e1f0dd53a020d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}