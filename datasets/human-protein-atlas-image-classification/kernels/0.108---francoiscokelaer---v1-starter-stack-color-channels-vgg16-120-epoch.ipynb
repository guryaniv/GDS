{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0bd943f1f7b984381a63e7ec06d3cf8c740c589"},"cell_type":"code","source":"weightpath = 'vvg16-4channels-80epochs-batch64'\ndatapath = 'human-protein-atlas-image-classification'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9109dc3ddb9abece0a5b27dd45f8a5f21b0675e2"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nimport pandas as pd\nimport numpy as np\nimport keras\nfrom keras.preprocessing.image import *\nfrom keras.layers import Input,Dense, Dropout, Flatten, Add\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Activation\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras import optimizers\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":" ## IO : load csv / subsample for saving memory\n"},{"metadata":{"trusted":true,"_uuid":"e52085b988297b2612a1e29fdc4eaedfcc5a0dc7"},"cell_type":"code","source":"train_df = pd.read_csv('../input/{}/train.csv'.format(datapath))\n#train_df = pd.read_csv('../input/train.csv')\ntrain_df.head()\nprint(train_df.shape)\nprint(\"set size is {}\".format(train_df.size))\n#the train dataset is reduced in order to save memory\ntrain_df_subset = train_df.sample(frac=0.5, random_state=2)\ntrain_df_subset = train_df_subset.reset_index(drop=True)\n\nprint(\"Subsample subset size is {}\".format(train_df_subset.size))\ntrain_df_subset['target_list'] = train_df_subset['Target'].map(lambda x: [int(a) for a in x.split(' ')])\nprint(train_df_subset.head())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8e1cc9f37cc6eb8983a8f6a42b11604b22b9283"},"cell_type":"code","source":"# create a categorical vector\nfrom itertools import chain\nfrom collections import Counter\nall_labels = list(chain.from_iterable(train_df_subset['target_list'].values))\nc_val = Counter(all_labels)\nprint(c_val)\nn_keys = c_val.keys()\nprint(n_keys)\nmax_idx = max(n_keys)\ntrain_df_subset['target_categorial'] = train_df_subset['target_list'].map(lambda ck: [i in ck for i in range(max_idx+1)])\ntrain_df_subset.sample(3)\nprint(train_df_subset.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d0581e1c7054abd08cf28250254492fd5603ac0"},"cell_type":"markdown","source":"## Class num to label"},{"metadata":{"trusted":true,"_uuid":"7f32ebfb3d65b8de9a25488daabe3827e64bfb5f"},"cell_type":"code","source":"name_label_dict = {\n0:  \"Nucleoplasm\", \n1:  \"Nuclear membrane\",   \n2:  \"Nucleoli\",   \n3:  \"Nucleoli fibrillar center\" ,  \n4:  \"Nuclear speckles\"   ,\n5:  \"Nuclear bodies\"   ,\n6:  \"Endoplasmic reticulum\",   \n7:  \"Golgi apparatus\"   ,\n8:  \"Peroxisomes\"   ,\n9:  \"Endosomes\"   ,\n10:  \"Lysosomes\"   ,\n11:  \"Intermediate filaments\",   \n12:  \"Actin filaments\"   ,\n13:  \"Focal adhesion sites\",   \n14:  \"Microtubules\"   ,\n15:  \"Microtubule ends\",   \n16:  \"Cytokinetic bridge\",   \n17:  \"Mitotic spindle\"   ,\n18:  \"Microtubule organizing center\" ,  \n19:  \"Centrosome\"   ,\n20:  \"Lipid droplets\",   \n21:  \"Plasma membrane\",   \n22:  \"Cell junctions\"  , \n23:  \"Mitochondria\"   ,\n24:  \"Aggresome\"   ,\n25:  \"Cytosol\",\n26:  \"Cytoplasmic bodies\",   \n27:  \"Rods & rings\" \n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2997fbc307e2f4d87a89cdd9ce5f956bbf03cf9c"},"cell_type":"markdown","source":"## Class repartition"},{"metadata":{"trusted":true,"_uuid":"ef69fd5de2084068750f8aca6f9c0f9c03de973c"},"cell_type":"code","source":"from itertools import chain\nfrom collections import Counter\n\nall_labels = list(chain.from_iterable(train_df_subset['target_list'].values))\nc_val = Counter(all_labels)\nn_keys = c_val.keys()\nmax_idx = max(n_keys)\nfig, ax1 = plt.subplots(1,1, figsize = (10, 5))\nax1.bar(n_keys, [c_val[k] for k in n_keys])\nax1.set_xticks(range(max_idx+1))\nax1.set_xticklabels([name_label_dict[k] for k in range(max_idx+1)], rotation=90)\nfor k,v in c_val.items():\n    print(name_label_dict[k], 'count:', v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"963bf9674acb597c80f9657619c1ea8353254763"},"cell_type":"code","source":"# out_df_list = []\n# for k,v in c_val.items():\n#     if v<500:\n#         keep_rows = train_df_subset['target_list'].map(lambda x: k in x)\n#         out_df_list += [train_df_subset[keep_rows].sample(500, replace=True)]   \n# train_df_subset = pd.concat(out_df_list, ignore_index=True)\n# print(train_df_subset.shape)\n# train_df_subset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4459247200c88957e8778d48f3b672c11236db3e"},"cell_type":"code","source":"print(\"Subsample subset size is {}\".format(train_df_subset.size))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a63dbf9e507521a1acac5423775496021989571"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"edfbb9545a463f7bc51f2f16c9145af4c6ae0f85"},"cell_type":"markdown","source":"## Image Loading and Processing"},{"metadata":{"trusted":true,"_uuid":"8d5b120538fadcb30680a64418f261a00f7fcfd1"},"cell_type":"code","source":"def loadAndStackImageData(df, datatype = 'train', resolution=128):\n    colors =  ('green','blue','yellow','red')\n    df[\"images\"] = [ ((np.stack( (img_to_array(load_img(\"../input/{}/{}/{}_{}.png\".format(datapath,datatype, idx, color),\n                                                               color_mode=\"grayscale\",\n                                                               target_size=(resolution,resolution)))\n                                                                  for color in colors), axis=-1)).reshape(128,128,4))/255.\n                                                                     for idx in tqdm_notebook(df.Id)]\n# def loadAndStackImageData(df, datatype = 'train', resolution=128):\n#     colors =  ('green','blue','yellow','red')\n#     df[\"images\"] = [ ((np.stack( (img_to_array(load_img(\"../input/{}/{}_{}.png\".format(datatype, idx, color),\n#                                                                color_mode=\"grayscale\",\n#                                                                target_size=(resolution,resolution)))\n#                                                                   for color in colors), axis=-1)).reshape(128,128,4))/255.\n#                                                                       for idx in tqdm_notebook(df.Id)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f1a9ae2007424dfe2bd675d5ab200c404af5bee"},"cell_type":"code","source":"# loadAndStackImageData(train_df_subset,'train', resolution=128)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"092c2fc5979d350d83f5dfdd777b631eaa797cd6"},"cell_type":"markdown","source":"## Data exploration : overlay image layers"},{"metadata":{"trusted":true,"_uuid":"ab04a91572d7a8f16cf42e5f585f5211afeedb38"},"cell_type":"code","source":"# #colors =  ('green','blue','yellow','red')\n# fig, axs = plt.subplots(4,15,figsize=(15,4))\n# for i in range(60):\n#     x1 = train_df_subset['images'][i][:,:,0]\n#     x2 = train_df_subset['images'][i][:,:,1]\n#     x3 = train_df_subset['images'][i][:,:,2]\n#     x4 = train_df_subset['images'][i][:,:,3]\n#     ax = axs[int(i/15), i % 15]\n#     ax.imshow(x1,alpha=0.5)\n#     ax.imshow(x2, alpha=0.5)\n#     ax.imshow(x3, alpha=0.5)\n#     ax.imshow(x4, alpha=0.5)\n#     ax.axis('off')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c677bfc86f467d018c97c69bb8ffc11bd192224f"},"cell_type":"markdown","source":"## Define VGG16 like model"},{"metadata":{"trusted":true,"_uuid":"f641be1438ed7492c8750da380e4cf7b6beed13b"},"cell_type":"code","source":"def vgg16like(num_classes, BATCH_NORM = None):\n\n    input_layer = Input((128, 128, 4))\n    \n    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(input_layer)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n    \n    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(256, (3, 3), padding='same', name='block3_conv4')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block4_conv4')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Conv2D(512, (3, 3), padding='same', name='block5_conv4')(x)\n    x = BatchNormalization()(x)if BATCH_NORM else None\n    x = Activation('relu')(x)\n\n    x = Flatten()(x)\n\n    x = Dense(4096)(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x = Dense(4096, name='fc2')(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('relu')(x)\n    x = Dropout(0.5)(x)\n\n    x = Dense(num_classes)(x)\n    x = BatchNormalization()(x) if BATCH_NORM else None\n    x = Activation('sigmoid')(x)\n    \n    model = Model(inputs=input_layer, outputs=x)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6351b7fd25e378ab962a2e76a047a971f876fd18"},"cell_type":"markdown","source":"# Training part"},{"metadata":{"trusted":true,"_uuid":"d2c933224355c275a5a3033d7f68b3bd3005612e"},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n# train_df, valid_df = train_test_split(train_df_subset, \n#                  test_size = 0.3)\n# print(train_df.shape[0], 'training masks')\n# print(valid_df.shape[0], 'validation masks')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc2d3a8eea99e6e6b946114ce972c445ac8fe622"},"cell_type":"code","source":"model = vgg16like(max_idx+1, BATCH_NORM = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f221669f4ba9669225cc5ec3d04ee07674dea2f"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e525d04ca94bb998942d22cede4855d1c7431a8"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94de0308d4d9f16696afe730dfb4aef37b53112e"},"cell_type":"code","source":"# x_train = np.array(train_df['images'].tolist())\n# y_train = np.array(train_df['target_categorial'].tolist())\n# x_valid = np.array(valid_df['images'].tolist())\n# y_valid = np.array(valid_df['target_categorial'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a661318493e9f96cb6c7a7dbddb19aa3bf06604"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cff8726e75093d6fdce91ea5cde636ff1376e559","scrolled":false},"cell_type":"code","source":"# checkpointer = ModelCheckpoint('VGG16_4channels_80epochs_batch64.model', verbose=2, save_best_only=True)\n# early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=1, factor=0.1)\n\n# history = model.fit(x_train,y_train,batch_size=64,epochs=80,\n#                     verbose=1,\n#                     callbacks=[checkpointer, early_stopping, reduce_lr],\n#                     validation_data=(x_valid,y_valid))\nmodel.load_weights('../input/{}/VGG16_4channels_80epochs_batch64.model'.format(weightpath))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15602bd744bd4ddcc1ee17ce4335ede7f205f9af"},"cell_type":"markdown","source":"## Prediction part"},{"metadata":{"_uuid":"5c2a6eb54aa6afcfc9dc5950270e5e8ed5693cdf"},"cell_type":"markdown","source":"### format test data"},{"metadata":{"trusted":true,"_uuid":"e6d662f84d0b3991777ebf2b00e172734b4ee075"},"cell_type":"code","source":"test_df = pd.read_csv('../input/{}/sample_submission.csv'.format(datapath))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e0d47d5d2437201e869ba22665a5963a9630283"},"cell_type":"code","source":"loadAndStackImageData(test_df,'test',resolution=128)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26daa3acff9895723875c8b39a5ba33af414ddfc"},"cell_type":"markdown","source":"### Predict results"},{"metadata":{"trusted":true,"_uuid":"5ae2950c474f7543dd83ffacefc7f68b7e597e16"},"cell_type":"code","source":"x_test = np.array(test_df['images'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"629013a8b92b34dd7c587990c2abd6cba634cca7"},"cell_type":"code","source":"y_test = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbdad26853f916d50d98dde3ac4542ca66bf71af"},"cell_type":"code","source":"prediction = [ (np.arange(28)[y_test[row]>=0.3]) for row in range(y_test.shape[0])] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91bb7860eccb4dcb5c7c57f666234ab7ded88363"},"cell_type":"code","source":"prediction = list(map(lambda x: x.tolist(), prediction))\nprediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7a111f5ee3c8bf459e3afeaa113ee35ecb6426b"},"cell_type":"code","source":"#results = [if not idx: ' ' else : ' '.join(str(prt))  for idx in prediction for prt in idx]\nresults = []\nfor idx in prediction:\n    print(idx)\n    if not idx:\n        print('.isempty')\n        results.append('0')\n    else:\n        concat = \"\"\n        for elt in idx:\n            concat+=str(elt)\n            concat+=' '\n        concat = concat.strip()\n        results.append(concat)\nresults \n# for idx in prediction: \n#     if not idx:\n#         results.append('0')\n#     else:\n#         res = \"\"\n#         for prt in idx:\n#             res+= str(prt)\n#         results.append(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf899ad5bdcf65037ca40497008f3e12ebf5c125"},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ea109efffae072e8a86f4555b6661a2bb1283c5"},"cell_type":"code","source":"submission = pd.read_csv('../input/{}/sample_submission.csv'.format(datapath))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"218b1ed477f89edabb9e4b63fb842fda65ab6532"},"cell_type":"code","source":"submission['Predicted'] = results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dd60aafa3e3253a96c3cfe26f5c3f670b3b49f2"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81b6fb44d28fd911432745179835654c3e2d44ca"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}