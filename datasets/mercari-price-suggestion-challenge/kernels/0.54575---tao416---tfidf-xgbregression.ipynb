{"cells":[{"metadata":{"collapsed":true,"_cell_guid":"973513d1-fa41-402c-8c3e-eaffaa175cdb","_uuid":"f93c41e6a99468f268f9a4a4b65fcdf7b8ad96c8","trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"eb3a84c6-2d51-49d6-86fb-f82a2b377ccf","_uuid":"a25d3cfcce6984dfd432aeafe80fe54c321407da","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\n%matplotlib inline\nimport seaborn as sb","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"75d38574-8efc-4ed9-a703-da9739ff16f1","_uuid":"ad9c409b60a0d22306716300111c15c161dac4d5","trusted":false},"cell_type":"code","source":"train = pd.read_table('../input/train.tsv', engine='c')\ntest = pd.read_table('../input/test.tsv', engine='c')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"485c91ad-a828-4f44-b7e5-ec2311a5d9b0","_uuid":"7d220be3c3b06f669edd4d8c22d689881655724e","trusted":false},"cell_type":"code","source":"train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"aa410478-be32-47e1-be94-b892d7678905","_uuid":"0f78bf3c8b55e41f2fca0fcf8ce7fc166724b1c1","trusted":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7a54e92f-2e72-4614-93ef-d707d600f22d","_uuid":"5109c59f3ca2db6772a6d339f7cbbf9585bd46f2","trusted":false},"cell_type":"code","source":"# Plot the histogram of the price\nbin_values = np.arange(start=0, stop=200, step=1)\ntrain.hist(column='price',bins=bin_values, figsize=[14,6])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a81ebf95-8969-4fc1-9917-a38dd02465c8","_uuid":"32d2061e162e11e230d85258727fdd91c26da63d","trusted":false},"cell_type":"code","source":"# Show the first ten brand_name\ntrain.brand_name.value_counts().loc[lambda x: x.index != ''][:10]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e9c3d13e-6e98-41eb-81b5-5cc2b130d381","_uuid":"36e6ce90ea11025df5eae03c3023f2deb05de04a","trusted":false},"cell_type":"code","source":"import time\nstart = time.time()\nplt.hist(train.price, bins=300,range=(0,250), normed=False)\nplt.show()\nend = time.time()\nprint(\"Time is %f\" %(end-start))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fa32d5f8-f88f-4b24-ae37-8653e6a1938d","_uuid":"7f7ecd3e3cf219127b6c70ee60068dc489be1f2b","trusted":false},"cell_type":"code","source":"plt.hist(np.log(train.price), bins=300, range=(0,6), normed=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"566faff9-bc5d-4258-9ce3-55d1da29ff23","_uuid":"ea83cecfb23f67f0bfffb8874a92cc7db10df101"},"cell_type":"markdown","source":"**Data Engineering**","outputs":[],"execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"95f5e931-c304-4445-bc24-aa45ce59492f","_uuid":"9a30717f307aa21aaa1b8d4c9609bcba9ffd4d7b","trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nimport scipy\n\ntrain[\"category_name\"] = train[\"category_name\"].fillna(\"Other\")\ntrain[\"brand_name\"] = train[\"brand_name\"].fillna(\"unknown\")\ntest[\"category_name\"] = test[\"category_name\"].fillna(\"Other\")\ntest[\"brand_name\"] = test[\"brand_name\"].fillna(\"unknown\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5410eec9-3106-4350-b178-5e3c463b3f57","_uuid":"95ba5ca643046ef8ef562d7ba13fbf30d94ac52e","trusted":false},"cell_type":"code","source":"# Split the category and lable them\ndef cat_split(row):\n    try:\n        text = row\n        txt1, txt2, txt3 = text.split('/')\n        return txt1, txt2, txt3\n    except:\n        return np.nan, np.nan, np.nan\n\n\ntrain[\"cat_1\"], train[\"cat_2\"], train[\"cat_3\"] = zip(*train.category_name.apply(lambda val: cat_split(val)))\ntest[\"cat_1\"], test[\"cat_2\"], test[\"cat_3\"] = zip(*test.category_name.apply(lambda val: cat_split(val)))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"29d75db8-477e-43dc-88f1-84aba2350f69","_uuid":"9b3fe7bf872fa774609557409095daf62b7b5afd","trusted":false},"cell_type":"code","source":"train.cat_1.value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"ce21b8b2-a876-4f31-bb00-b365e3aa16ee","_uuid":"e6fa38a088abedb65d58e2969720c51a122c5cd5","trusted":false},"cell_type":"code","source":"# making dictionaries for different categories \nkeys = train.cat_1.unique().tolist() + test.cat_1.unique().tolist()\nkeys = list(set(keys)) # use set() to get the unique key\nvalues = range(0,keys.__len__())\ncat1_dict = dict(zip(keys, values))\ncat1_dict\n\nkeys2 = train.cat_2.unique().tolist() + test.cat_2.unique().tolist()\nkeys2 = list(set(keys2))\nvalues2 = list(range(keys2.__len__()))\ncat2_dict = dict(zip(keys2, values2))\n\nkeys3 = train.cat_3.unique().tolist() + test.cat_3.unique().tolist()\nkeys3 = list(set(keys3))\nvalues3 = list(range(keys3.__len__()))\ncat3_dict = dict(zip(keys3, values3))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f988f4c8-fc5c-4056-bd1a-aca050099c64","_uuid":"470078a8328ebd39c9be4bbdc97a50c7ded7c34b","trusted":false},"cell_type":"code","source":"# code the categories\ndef cat_lable(row):\n    txt1 = row['cat_1']\n    txt2 = row['cat_2']\n    txt3 = row['cat_3']\n    return cat1_dict[txt1], cat2_dict[txt2], cat3_dict[txt3]\n\ntrain[\"cat_1_label\"], train[\"cat_2_label\"], train[\"cat_3_lable\"] \\\n= zip(*train.apply(lambda val: cat_lable(val), axis =1))\n# zip(*) means unzip\n\ntest[\"cat_1_label\"], test[\"cat_2_label\"], test[\"cat_3_lable\"] \\\n= zip(*test.apply(lambda val: cat_lable(val), axis =1))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"48ceee36-0e88-407d-854c-878735551440","_uuid":"17953349d5263483e75f55b8fb27f2b4119c54ac","trusted":false},"cell_type":"code","source":"def if_catname(row):\n    \"\"\"function to give if brand name is there or not\"\"\"\n    if row == row:\n        return 1\n    else:\n        return 0\n    \ntrain['if_cat'] = train.category_name.apply(lambda row : if_catname(row))\ntest['if_cat'] = test.category_name.apply(lambda row : if_catname(row))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"355f378d-5fbb-4d21-99a4-f6393efd4533","_uuid":"86d96e1f5b043646803e2af7ae8b61fe535af081","trusted":false},"cell_type":"code","source":"# brand name related features \ndef if_brand(row):\n    \"\"\"function to give if brand name is there or not\"\"\"\n    if row == row:\n        return 1\n    else:\n        return 0\n    \ntrain['if_brand'] = train.brand_name.apply(lambda row : if_brand(row))\ntest['if_brand'] = test.brand_name.apply(lambda row : if_brand(row))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d592c7f5-e254-4ce4-a433-470b9521e6d4","_uuid":"3d47a7b937407623f153a662ed7b8efbea91825e","trusted":false},"cell_type":"code","source":"# makinfg brand name dict features \nkeys = train.brand_name.dropna().unique()\nvalues = list(range(keys.__len__()))\nbrand_dict = dict(zip(keys, values))\n\ndef brand_label(row):\n    \"\"\"function to assign brand label\"\"\"\n    try:\n        return brand_dict[row]\n    except:\n        return np.nan\n\ntrain['brand_label'] = train.brand_name.apply(lambda row: brand_label(row))\ntest['brand_label'] = test.brand_name.apply(lambda row: brand_label(row))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b9e96563-f3c9-4f9b-be3c-232a2d87b761","_uuid":"7fc92d84e4961ced5c46a23ca1b0ee32a006ea08","trusted":false},"cell_type":"code","source":"def if_description(row):\n    \"\"\"function to say if description is present or not\"\"\"\n    if row == 'No description yet':\n        a = 0\n    else:\n        a = 1\n    return a\n\ntrain['is_description'] = train.item_description.apply(lambda row : if_description(row))\ntest['is_description'] = test.item_description.apply(lambda row : if_description(row))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e8b84d3e-d680-499a-a486-71857283c2c8","_uuid":"1008526feea5458ab8abb554c837007073466a90","trusted":false},"cell_type":"code","source":"print(train.shape[0])\ntrain = train.loc[train.item_description == train.item_description]\ntest = test.loc[test.item_description == test.item_description]\ntrain = train.loc[train.name == train.name]\ntest = test.loc[test.name == test.name]\nprint(train.shape[0])\nprint(\"Dropped records where item description was nan\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d33a28f9-367b-453b-bebd-d3086b0e7036","_uuid":"88066adf0097b1ec28dcd6f15d37597a144073ed","trusted":false},"cell_type":"code","source":"import pandas as pd  #pandas for using dataframe and reading csv \nimport numpy as np   #numpy for vector operations and basic maths \nimport urllib        #for url stuff\nimport re            #for processing regular expressions\nimport datetime      #for datetime operations\nimport calendar      #for calendar for datetime operations\nimport time          #to get the system time\nimport scipy         #for other dependancies\nfrom sklearn.cluster import KMeans # for doing K-means clustering\nfrom haversine import haversine # for calculating haversine distance\nimport math          #for basic maths operations\nimport seaborn as sns #for making plots\nimport matplotlib.pyplot as plt # for plotting\nimport os                # for os commands\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nimport xgboost as xgb\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn import ensemble, metrics, model_selection, naive_bayes","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f30ef892-0886-400d-b021-dc9750e399b9","_uuid":"6e46411df283222dd22d8d97525f7616164200a9","trusted":false},"cell_type":"code","source":"tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1,1))\nfull_tfidf = tfidf_vec.fit_transform(train['item_description'].values.tolist() + test['item_description'].values.tolist())\ntrain_tfidf = tfidf_vec.transform(train['item_description'].values.tolist())\ntest_tfidf = tfidf_vec.transform(test['item_description'].values.tolist())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e116ff69-a96e-4d57-9fc3-7ba1fe032a55","_uuid":"0d3f8db7c7606b6a06ad7b132a52eb35d2de5e21","trusted":false},"cell_type":"code","source":"n_comp = 50\nsvd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\nsvd_obj.fit(full_tfidf)\ntrain_svd = pd.DataFrame(svd_obj.transform(train_tfidf))\ntest_svd = pd.DataFrame(svd_obj.transform(test_tfidf))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5781af07-d37e-4416-8955-6647b9266348","_uuid":"5db71a1e159823dee28f76c9c9467ecc4b01bfda","trusted":false},"cell_type":"code","source":"train_svd.columns = ['svd_item_'+str(i) for i in range(n_comp)]\ntest_svd.columns = ['svd_item_'+str(i) for i in range(n_comp)]\ntrain_df = pd.concat([train, train_svd], axis=1)\ntest_df = pd.concat([test, test_svd], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fdd4b454-a46d-4cde-8bc3-49627c54f88f","_uuid":"ea40c1a6e29eb26e5ec5305cb925ef6cd24a94b1","trusted":false},"cell_type":"code","source":"pd.set_option('display.max_columns',100)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4a11116c-200b-450f-b80a-91dcba122973","_uuid":"6c3a84a6d5fb5c24ca3d28ae65014866252819eb","trusted":false},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"collapsed":true,"_cell_guid":"d5fbe9ee-7461-4801-9cb0-0a681f0d4371","_uuid":"7dfc6b11b6715a6ed7140781f95065eebd7c66be","trusted":false},"cell_type":"code","source":"train_df.fillna(0, inplace=True)\ntest_df.fillna(0, inplace=True)\nprint(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4a3e6b4a-019f-4427-9e0f-1621f02a17b8","_uuid":"bd0561b8a54226eb6a76272cb6f5543be697025b","trusted":false},"cell_type":"code","source":"train = train_df.copy()\ntest = test_df.copy()\nprint(\"Difference of features in train and test are {}\".format(np.setdiff1d(train.columns, test.columns)))\nprint(\"\")\ndo_not_use_for_training = ['cat_1','test_id','cat_2','cat_3','train_id','name', 'category_name', 'brand_name', 'price', 'item_description']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\nprint(\"We will be using following features for training {}.\".format(feature_names))\nprint(\"\")\nprint(\"Total number of features are {}.\".format(len(feature_names)))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2ab2d302-5659-4d30-a6c8-cbca3e5a52fa","_uuid":"08fe265809c9d6ccd5475b12061fb1e1dbb56975","trusted":false},"cell_type":"code","source":"y = np.log(train['price'].values + 1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7fd99640-4a91-4a4c-83e9-e39c93accb05","_uuid":"23a111272834b9124a62221091f5ff33e2d792e8","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\ndtrain = xgb.DMatrix(Xtr, label=ytr)\ndvalid = xgb.DMatrix(Xv, label=yv)\ndtest = xgb.DMatrix(test[feature_names].values)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9c7c8bfa-8511-440d-a8d6-bd3f8e777db3","_uuid":"f283ce5c681cf2ec9a636677d57bbee531246641","trusted":false},"cell_type":"code","source":"xgb_par = {'min_child_weight': 20, 'eta': 0.05, 'colsample_bytree': 0.5, 'max_depth': 15,\n            'subsample': 0.9, 'lambda': 2.0, 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}\nmodel_1 = xgb.train(xgb_par, dtrain, 500, watchlist, early_stopping_rounds=50, maximize=False, verbose_eval=50)\nprint('Modeling RMSLE %.5f' % model_1.best_score)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6d2c05f4-f81b-4662-affe-5fdeae4bf839","_uuid":"854a4df824da324102e916f05af649ef8bc2af76","trusted":false},"cell_type":"code","source":"pred = model_1.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"203b7401-d26d-44cb-bfce-00086d9f7b19","_uuid":"484fa5646e45fff98d6998eb699450099cc91367","trusted":false},"cell_type":"code","source":"test['price'] = np.expm1(pred)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"037cff94-d9af-45cb-bddf-ee69866cd511","_uuid":"f5da8541b5876a6ce8b63a3480ae59dc60684ea9","trusted":false},"cell_type":"code","source":"test[[\"test_id\", \"price\"]].to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}