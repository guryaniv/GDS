{"cells":[{"metadata":{"_uuid":"9852b94d02df147084e4f8c79cca4c652e034bcc"},"cell_type":"markdown","source":"**Deep Neural Network inspired from InceptionV3 model. (+99% Accuracy)**\n\nIntroduction: \n\nThis is a deep neural network model inspired InceptionV3 model. InceptionV3 model is sequential deep convolution neural network model trained for the ImageNet Large Visual Recognition Challenge which achived a top-5 error rate of 3.46%. I modified the original inception V3 model to reduce the complexicity and removed few layers which bought down the number of parameters to train. \n\nI used another MNIST 60K dataset http://yann.lecun.com/exdb/mnist/) and removed the test dataset enteries which are in the train dataset of MNIST. Overall I trained the model with around 77K images. \n\nI also used data agumentation to create more data using the existing dataset of 77K which involves in the operations like Rotation, Zooming, width shifting and height shiffting.  \n\nOverall I achieved 99% when I trained with combination of all the datasets. I hope the accuracy is good enough for the model and beyond it may consider as overfit model. \n\nThis notebook consist of 4 sections. \n*     1) Data Pre processing.\n*     2) InceptionV3 inspired Model creation.\n*     3) Data Augumentation.\n*     4) Results and Predictions. \n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6bd20888578a3d6598a3b9352dfc4769d1978cf8"},"cell_type":"markdown","source":"Loading required libraries. \n\nModel was written with Keras API which is running Tensorflow as a Backend. \nImageDataGenerator was used to to manuplate existing data and create new data. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\nfrom keras.models import Model\nfrom keras import layers\nfrom keras import backend as K\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a05f226fa8632829c40e6267c90227e29a57827"},"cell_type":"code","source":"#defaults: \n# To use additional dataset. \nUSE60KDATASET = True ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb106ba546a8abeef35d2ed3ccb44a15aac89ef2"},"cell_type":"markdown","source":"Importing data from CSV. "},{"metadata":{"trusted":true,"_uuid":"51bc801e46e01280e516f1447d6b410c332be4e5"},"cell_type":"code","source":"train_df_1 = pd.read_csv('../input/digit-recognizer/train.csv')\ntest_df = pd.read_csv('../input/digit-recognizer/test.csv')\ntrain_df_2 = pd.read_csv('../input/mnist-in-csv/mnist_train.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bff6e7e68ad74e79e1896527aed55ff2549f17e"},"cell_type":"code","source":"train_df_1.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c9a5e214f486fb115d1165d110be986503a58dd"},"cell_type":"code","source":"train_df_2.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69c393379278af0deaafc8a9345db82c80c63d96"},"cell_type":"markdown","source":"Column labels of both the datasets doesn't match. To concatinate both the datasets column labels has to be same. So Changing the column labels of the train_df_2 to make it same as train_df_1."},{"metadata":{"trusted":true,"_uuid":"b9d8669d0c4f609c2931e1d565fe425246e21f01"},"cell_type":"code","source":"\ntrain_df_2.columns = train_df_1.columns\nif USE60KDATASET:\n    train_df = pd.concat([train_df_1,train_df_2])\nelse:\n    train_df = train_df_1 \n\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aea3c1c17830fe4ff01540b2c4a0ceb2fd3ba0c2"},"cell_type":"markdown","source":"Check data for any null values"},{"metadata":{"trusted":true,"_uuid":"14fdb8ff226df60f7420842e287a53382e244125"},"cell_type":"code","source":"train_df.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"a676a6532a452230e10c378c4d7b2b1e64811536"},"cell_type":"code","source":"test_df.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09f8f62516ac4d83c7cee1d88169acac6fda6aca"},"cell_type":"markdown","source":"There is no null values in the dataset. "},{"metadata":{"_uuid":"2859c3dd882f503ba0bde85daab613127930d1ab"},"cell_type":"markdown","source":"60K dataset contains some data which is present in test set. So removing the entries from the train set. "},{"metadata":{"trusted":true,"_uuid":"27f8c5abcb16a089bdc7bcd29316bdda36835861"},"cell_type":"code","source":"leftjoin = pd.merge(train_df, test_df, how='left',indicator=True)\ntrain_df = leftjoin[leftjoin['_merge'] == 'left_only'].drop(columns=['_merge'])\n\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"274c88598e08f99e1b1f2066d162629cfbf68684"},"cell_type":"markdown","source":"Extracting train labels and image data from dataset. "},{"metadata":{"trusted":true,"_uuid":"b51ca0622271567400f3df8026fadf109a171e54"},"cell_type":"code","source":"train_label = train_df.iloc[:,0].reset_index().iloc[:,1:]\ntrain_in = train_df.iloc[:,1:].reset_index().iloc[:,1:]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f738f3d315290d66b2bf15e79553066616325b4"},"cell_type":"markdown","source":"Normalization of data to 0 to 1 from 0 to 255. "},{"metadata":{"trusted":true,"_uuid":"6328b640842e9050925acb529c178c7fa6db9972"},"cell_type":"code","source":"train_in = train_in/255\ntest_in = test_df/255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e034ad41323c2bff445bb7265d00751faee22d37"},"cell_type":"markdown","source":"Reshaping the image array from  784 to 28X28 "},{"metadata":{"trusted":true,"_uuid":"bc2a12d6c0b40ac964c71c0c662d22fe48bed45c"},"cell_type":"code","source":"train_in = np.asarray([x.reshape(28,28,1)for x in train_in.values])\ntest_in = np.asarray([x.reshape(28,28,1)for x in test_in.values])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e537d7217aef7c34d73eb496ad97cd1281be8181"},"cell_type":"markdown","source":"One-Hot encoding the train labels"},{"metadata":{"trusted":true,"_uuid":"16f67fe76ad83bf279a47ac527f867002bc2b206"},"cell_type":"code","source":"labels_flat = train_label.label.ravel()\n\nlabels_one_hot_test = np.zeros((labels_flat.shape[0], 10))\nhh = (np.arange(labels_flat.shape[0])*10 + labels_flat.ravel()).astype(int)\n\nlabels_one_hot_test.flat[hh] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27b0e49bca9a85ef2f98bd1a0a77aa870c92d679"},"cell_type":"markdown","source":"Model Creation\n\nUtility function to apply convolution and batch normalization. "},{"metadata":{"trusted":true,"_uuid":"4c90783816d52efd36b0110ca5aec6e9765b78bd"},"cell_type":"code","source":"if K.image_data_format() == 'channels_first':\n    channel_axis = 1\nelse:\n    channel_axis = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"118ab11f441fc76660ff123645075ca810de85dc"},"cell_type":"code","source":"def conv2d_bn(x,\n              filters,\n              num_row,\n              num_col,\n              padding='same',\n              strides=(1, 1),\n              name=None):\n    \"\"\"Utility function to apply conv + BN.\n\n    # Arguments\n        x: input tensor.\n        filters: filters in `Conv2D`.\n        num_row: height of the convolution kernel.\n        num_col: width of the convolution kernel.\n        padding: padding mode in `Conv2D`.\n        strides: strides in `Conv2D`.\n        name: name of the ops; will become `name + '_conv'`\n            for the convolution and `name + '_bn'` for the\n            batch norm layer.\n\n    # Returns\n        Output tensor after applying `Conv2D` and `BatchNormalization`.\n    \"\"\"\n    if name is not None:\n        bn_name = name + '_bn'\n        conv_name = name + '_conv'\n    else:\n        bn_name = None\n        conv_name = None\n    if K.image_data_format() == 'channels_first':\n        bn_axis = 1\n    else:\n        bn_axis = 3\n    x = layers.Conv2D(\n        filters, (num_row, num_col),\n        strides=strides,\n        padding=padding,\n        use_bias=False,\n        name=conv_name)(x)\n    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n    x = layers.Activation('relu', name=name)(x)\n    return x\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52c647f7a0de06a98b7f437912df266ac76ac0d4"},"cell_type":"markdown","source":"Inception V3 Model:\n\nIntial V3 Model: \n![Original](https://github.com/harshaneigapula/Reduced-InceptionV3-model/blob/master/Original.png?raw=true)\n\nModifed V3 Model: \n\nTo decrease the complexcity of the model, removed some of the loops in the model. Which results as below:  \n\n![After](https://github.com/harshaneigapula/Reduced-InceptionV3-model/blob/master/After.jpg?raw=true)"},{"metadata":{"trusted":true,"_uuid":"a0d3b5e586a37066a8ef3326ba5840c3d1ff3cb2"},"cell_type":"code","source":"input_tensor = layers.Input(shape=(28,28,1))\n\nx = conv2d_bn(input_tensor, 4, 3, 3, strides=(1, 1), padding='valid')\nx = conv2d_bn(x, 4, 3, 3, padding='valid')\nx = conv2d_bn(x, 8, 3, 3, padding='valid')\nx = layers.MaxPooling2D((3, 3), strides=(1, 1))(x)\n\nx = conv2d_bn(x, 12, 1, 1, padding='valid')\nx = conv2d_bn(x, 32, 3, 3, padding='valid')\nx = layers.MaxPooling2D((3, 3), strides=(1, 1))(x)\n\n\nbranch1x1 = conv2d_bn(x, 8, 1, 1,padding='valid')   # 1,1\n\nbranch5x5 = conv2d_bn(x, 6, 1, 1,padding='valid') # 1,1\nbranch5x5 = conv2d_bn(branch5x5, 8, 5, 5) # 5,5 \n\nbranch3x3dbl = conv2d_bn(x, 8, 1, 1,padding='valid') # 1,1\nbranch3x3dbl = conv2d_bn(branch3x3dbl, 12, 3, 3)\nbranch3x3dbl = conv2d_bn(branch3x3dbl, 12, 3, 3)\n\nbranch_pool = layers.AveragePooling2D((3, 3),  strides=(1, 1),  padding='same')(x)\nbranch_pool = conv2d_bn(branch_pool, 4, 1, 1)\nx = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis,name='mixed0')\n\n\nbranch3x3 = conv2d_bn(x, 32, 3, 3, strides=(2, 2), padding='valid')\n\nbranch3x3dbl = conv2d_bn(x, 8, 1, 1)\nbranch3x3dbl = conv2d_bn(branch3x3dbl, 12, 3, 3)\nbranch3x3dbl = conv2d_bn(\n    branch3x3dbl, 12, 3, 3, strides=(2, 2), padding='valid')\n\nbranch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\nx = layers.concatenate(\n    [branch3x3, branch3x3dbl, branch_pool],\n    axis=channel_axis,\n    name='mixed1')\n\n\nbranch1x1 = conv2d_bn(x, 32, 1, 1,padding='valid') # 1 1\n\nbranch7x7 = conv2d_bn(x, 16, 1, 1,padding='valid') # 1 1\nbranch7x7 = conv2d_bn(branch7x7, 16, 1, 7)\nbranch7x7 = conv2d_bn(branch7x7, 32, 7, 1)\n\nbranch7x7dbl = conv2d_bn(x, 16, 1, 1,padding='valid') # 1 1\nbranch7x7dbl = conv2d_bn(branch7x7dbl, 16, 7, 1)\nbranch7x7dbl = conv2d_bn(branch7x7dbl, 16, 1, 7)\nbranch7x7dbl = conv2d_bn(branch7x7dbl, 16, 7, 1)\nbranch7x7dbl = conv2d_bn(branch7x7dbl, 32, 1, 7)\n\nbranch_pool = layers.AveragePooling2D((3, 3),\n                                      strides=(1, 1 ),\n                                      padding='same')(x)\nbranch_pool = conv2d_bn(branch_pool, 32, 1, 1,padding='valid') # 1 1\nx = layers.concatenate(\n    [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n    axis=channel_axis,\n    name='mixed2')\n\n\nbranch3x3 = conv2d_bn(x, 32, 1, 1,padding='valid') # 1 1\nbranch3x3 = conv2d_bn(branch3x3, 64, 3, 3,\n                      strides=(2, 2), padding='valid')\n\nbranch7x7x3 = conv2d_bn(x, 32, 1, 1,padding='valid') # 1 1\nbranch7x7x3 = conv2d_bn(branch7x7x3, 32, 1, 7)\nbranch7x7x3 = conv2d_bn(branch7x7x3, 32, 7, 1)\nbranch7x7x3 = conv2d_bn(\n    branch7x7x3, 32, 3, 3, strides=(2, 2), padding='valid')\n\nbranch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2),padding='valid')(x) # strides 2 2\nx = layers.concatenate(\n    [branch3x3, branch7x7x3, branch_pool],\n    axis=channel_axis,\n    name='mixed3')\n\n\n\nbranch1x1 = conv2d_bn(x, 32, 1, 1,padding='valid',name='validcheck') # 1 1\n\nbranch3x3 = conv2d_bn(x, 32, 1, 1,padding='valid')\nbranch3x3_1 = conv2d_bn(branch3x3, 32, 1, 3)\nbranch3x3_2 = conv2d_bn(branch3x3, 32, 3, 1)\nbranch3x3 = layers.concatenate(\n    [branch3x3_1, branch3x3_2],\n    axis=channel_axis,\n    name='mixed4')\n\nbranch3x3dbl = conv2d_bn(x, 32, 1, 1,padding='valid')\nbranch3x3dbl = conv2d_bn(branch3x3dbl, 32, 3, 3)\nbranch3x3dbl_1 = conv2d_bn(branch3x3dbl, 32, 1, 3)\nbranch3x3dbl_2 = conv2d_bn(branch3x3dbl, 32, 3, 1)\nbranch3x3dbl = layers.concatenate(\n    [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n\nbranch_pool = layers.AveragePooling2D(\n    (3, 3), strides=(1, 1), padding='same')(x)\nbranch_pool = conv2d_bn(branch_pool, 32, 1, 1,padding='valid') # 1 1 \nx = layers.concatenate(\n    [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n    axis=channel_axis,\n    name='mixed5')\n        \n      \nx = layers.AveragePooling2D(\n    (3, 3), strides=(1, 1), padding='valid')(x)\nx = layers.Dropout(0.01)(x)\nx = layers.GlobalAveragePooling2D(name='avg_pool')(x)\nx = layers.Dense(64, activation = \"relu\")(x)\nx = layers.Dense(10, activation='softmax', name='predictions')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f08c341125392c99c76aa56e361f94be4168f1e"},"cell_type":"code","source":"model = Model(input_tensor, x)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cae8745484e5cdc6782035a054588502b40707e2"},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74305a049b2adb874ceb83e875e4404bfce8ce1e"},"cell_type":"markdown","source":"Fiting the training set to the model. \n\nHere I am using epochs = 5, for better accuracy change it to 10 or more. "},{"metadata":{"trusted":true,"_uuid":"81393e37f80a11b3b62d2715d37fc0ed184ae2dd"},"cell_type":"code","source":"modelfit = model.fit(x=train_in, y=labels_one_hot_test, batch_size=100, epochs=5, verbose=1, callbacks=None, validation_split=0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10d84584266cd98cbde6991847f0920cb7853137"},"cell_type":"markdown","source":"**Data Augumentation: **\n\nCreating new examples can be done through data augementation by rotating the image or by zooming the image. ImageDataGenerator which is available in keras.preprocessing.image used here to perform the data augemenation. Rotation, Zoom, width shift and height shift are enabled. \n\nAfter defining the parameters and generating the new examples these new examples are again fitted to the model "},{"metadata":{"trusted":true,"_uuid":"0a361948e5e40862e2087c42c6dd301ae442bf4a"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.15, # Randomly zoom image \n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccf40b9c9502405d25eb82d7d729a77951060471"},"cell_type":"code","source":"datagen.fit(train_in)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f2ef30deebe8d1e8445e1be16f14ca86228166e"},"cell_type":"code","source":"modelfitwithdatagen = model.fit_generator(datagen.flow(train_in,labels_one_hot_test, batch_size=100),\n                              epochs = 5, validation_data = None,\n                              verbose = 1, steps_per_epoch=779)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4417c4f7144f2e28ed3403bdac40ae3b664609e0"},"cell_type":"markdown","source":"**Predictions and submissions**\n\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3b03ac253d42bc655dbddb8dbb5a5ba4400dc434"},"cell_type":"code","source":"pred = model.predict(test_in)\n\npred_val = np.argmax(pred,axis=1)\n\nresults = pd.Series(pred_val,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b9d0f446ac0f7c9794c7e0d1db75103649612d71"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,pred_val.shape[0]+1),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"Results.csv\",index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6db7ea997e361d0ebd1111aa3c244b1a273aaf64"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}