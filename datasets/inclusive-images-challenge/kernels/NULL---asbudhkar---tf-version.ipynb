{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\nimport sklearn\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57944049096f900aa5b4865ad029a8ad51310d02","scrolled":false},"cell_type":"code","source":"images_dir_name = '../input/stage_1_test_images/stage_1_test_images'\n#print(os.listdir(\"../input/stage_1_test_images/stage_1_test_images\"))\ninput_dir = '../input/'\n# retrieve all the labels and store those into a collection\nclasses_trainable = pd.read_csv(input_dir+'classes-trainable.csv')\nprint(classes_trainable)\nall_labels = classes_trainable['label_code']\nprint ('The number of unique labels is {}'.format(len(all_labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ebe5078c726fb8f75e7a981a6976fc4ffc537ae"},"cell_type":"code","source":"# retrieve all the labels and store those into a collection\nclasses_trainable = pd.read_csv(input_dir+'classes-trainable.csv')\nall_labels = classes_trainable['label_code']\nprint(all_labels)\nprint ('The number of unique labels is {}'.format(len(all_labels)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43a0fd9df77ce15c6a311e3f09931492535c9ce9"},"cell_type":"code","source":"# set the number of labels which will be used as an output layer size for a model\nnum_labels = len(all_labels)\n\n# build the index dictionary based on the labels collection\nlabels_index = {label:idx for idx, label in enumerate(all_labels)}\nprint(labels_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87ba8e384d6390d8bf2d078d69c58e6bd3ab1ed5"},"cell_type":"code","source":"# retrieve the list of train images (in our case we'll be using the test images just to get the model up and running)\n# this will be changed to the train data set in the future.\ntrain_image_names = [img_name[:-4] for img_name in os.listdir(images_dir_name)]\n#print (train_image_names)\nprint (\"number of training images is {}\".format(len(train_image_names)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb22044a28981b9653686f8a706351773dc0479b","scrolled":false},"cell_type":"code","source":"# retrieve the list of train labels (machine labels for now; need to work on replacing the machine labels with human ones if available)\n# for now I'll be using tuning labels\nlabels = pd.read_csv('../input/tuning_labels.csv')\nprint(labels)\n#print(labels)\nlabels.head()\n#print(labels.head)\ntrain_images = []\ntrain_labels_raw = []\nfor index, row in labels.iterrows():\n    #print(str(index)+row[0])\n    train_images.append(row[0])\n    labels_raw = row[1].split(' ')\n    train_labels_raw.append([labels_index[label] for label in labels_raw])\n    #print(labels_raw.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33572db9e83d0ee3ca0caea4e9d0b362c1a83bb2"},"cell_type":"code","source":"# do the multi-hot encoding\ndef multi_hot_encode(x, num_classes):\n    encoded = []\n    for labels in x:\n        labels_encoded = np.zeros(num_classes)\n        \n        for item in labels:\n            labels_encoded[item] = 1\n            \n        encoded.append(labels_encoded)\n        \n    encoded = np.array(encoded)\n    \n    return encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"655b44008e344c4c8202e2cbd97b71ebe83bffe8"},"cell_type":"code","source":"train_labels = multi_hot_encode(train_labels_raw, num_labels)\nprint (train_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af6cda8a8f3213048e60eba06ae0685a15132c18"},"cell_type":"code","source":"from sklearn.utils import shuffle\n#import tensorflow as tf\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7a41383bf2b3c1cbd5bdceb0849d9c2987d4231"},"cell_type":"code","source":"# define the normalization logic for an image data\ndef normalize(x):\n    return (x.astype(float) - 128)/128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34f0a41bd9fb4391c426c0fe9e6df9963be65bea"},"cell_type":"code","source":"# define the dimensions of the processed image\nx_dim = 100\ny_dim = 100\nn_channels = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7968e74ecd286d18354b9837785b47245949371b"},"cell_type":"code","source":"# define scaling for logic for an image data\ndef scale(x):\n    return cv2.resize(x, (x_dim, y_dim))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae0af0c699100f4b288437e35d0b650ee74c1120"},"cell_type":"code","source":"# read and pre-process image\ndef preprocess(image_name):\n    #print(\"IMAGE NAME\")\n    img = cv2.imread(image_name)\n    img1=plt.imshow(img)\n    print(img)\n    scaled = scale(img)\n    normalized = normalize(scaled)\n    \n    return np.array(normalized)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"746f4bb6b03d5538156e6a98707a60208597b9e7"},"cell_type":"code","source":"# prepare the collection of labels\ndef get_labels(image_name):\n    labels = []\n    \n    # todo implement\n    \n    return labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6ea3127c5d3a8cb5224bf5660046dbc20391880"},"cell_type":"code","source":"# build the generator for training\ndef generator(samples, sample_labels, batch_size=32):\n    num_samples = len(samples)\n    \n    while 1: # Loop forever so the generator never terminates\n        sklearn.utils.shuffle(samples, sample_labels)\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            batch_labels = sample_labels[offset:offset+batch_size]\n\n            images = []\n            labels = []\n\n            for i, batch_sample in enumerate(batch_samples):\n                #if((images_dir_name+'/'+batch_sample)!='None')\n                #print(\"--------------------\")\n                #print(images_dir_name+'/'+batch_sample+'.jpg')\n                image = preprocess(images_dir_name+'/'+batch_sample+'.jpg')\n\n                # this will be needed later once get the real data\n                #image_labels = get_labels(batch_sample)\n\n                images.append(image)\n                labels.append(batch_labels[i])\n\n            X_train = np.array(images)\n            y_train = np.array(labels)\n            #yield sklearn.utils.shuffle(X_train, y_train)\n            return X_train,y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a49141e589ecbbd5b51462923ea838c16b5901e0"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nXtrain, Xvalid, ytrain, yvalid = train_test_split(train_images, train_labels, test_size=0.1)\n#print(Xtrain)\n#print(ytrain)\nXtrain,ytrain=generator(Xtrain,ytrain,batch_size=32)\n#print(Xtrain)\n#print(Xtrain.shape)\n#print(ytrain.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c6b8cf1fce96e072179dfabce150dc6da8b0069","scrolled":true},"cell_type":"code","source":"x = tf.placeholder(\"float\", [None,30000])\n\nW = tf.Variable(tf.zeros([30000,8000]))\nb = tf.Variable(tf.zeros([8000]))\nW1 = tf.Variable(tf.zeros([8000,7178]))\nb1 = tf.Variable(tf.zeros([7178]))                       \ny = tf.nn.relu(tf.matmul(x,W) + b)\n#y2 = tf.nn.relu(tf.matmul(y,W2) + b)\ny1 = tf.nn.sigmoid(tf.matmul(y,W1) + b1)\ny1_ = tf.placeholder(\"float\", [None,7178])\n\n#cross_entropy = -tf.reduce_sum(y1_*tf.log(y1))\ncross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y1,labels=y1_)\ntrain_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n\ninit = tf.initialize_all_variables()\n\nsess = tf.Session()\nsess.run(init)\nsaver = tf.train.Saver([W,b,W1,b1])\n#Train our modelSS\nprint(\"----\")\niter = 10\n#correct_prediction=tf.equal(tf.argmax(y1,1), tf.argmax(y1_,1))\ncorrect_prediction=tf.equal(tf.round(y1), y1_)\nreq_list=[correct_prediction, train_step]\nfor i in range(iter):\n  #print(i)\n  Xtrain=np.reshape(Xtrain,(32,30000))\n  #batch_xs, batch_ys = Xtrain.train.next_batch(100)\n  list=sess.run(req_list, feed_dict={x: Xtrain, y1_: ytrain})\n  correct_prediction, train_step=list\n  print(correct_prediction.shape)\n  saver.save(sess,\"./tenIrisSave/saveOne\")\n  \n#Evaluationg our model:\n#correct_prediction=tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\nsaver.restore(sess, \"./tenIrisSave/saveOne\")\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\nprint (\"Accuracy: \", sess.run(accuracy, feed_dict={x: Xtrain, y1_: ytrain}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1418aed843edbf66e6bcfb02d2085824a1ec0b7a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1afc25e5b9b7a378f513c4e86c9efc608e9fb612"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913dde24b7bd7d00f4b1a0835e487d69bf744569"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}