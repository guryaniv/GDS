{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "064bbf4d-c858-1ad6-36ae-9cd334b09d83"
      },
      "source": [
        "About Overfitting\n",
        "-----------------\n",
        "\n",
        "this note is used to check the cumulative R value from  https://www.kaggle.com/sudalairajkumar/two-sigma-financial-modeling/am-i-over-fitting.\n",
        "\n",
        "(1)And it works well in detecting my bad performance of mycode (use four variables ,this model behaves well in the last half of train set with a public score 0.017265299516796905 but in test set with -0.0350178.https://www.kaggle.com/richardmore/two-sigma-financial-modeling/model1-5/run/506392)\n",
        "and it seems that the overfitting is a type of time overfitting( works extremely well in very few timestamp, and give a higher magnitude prediction)\n",
        "\n",
        " (2)And the below zero phenomenon of many model including ridge1 from https://www.kaggle.com/ymcdull/two-sigma-financial-modeling/ridge-lb-0-0100659/\n",
        " in early timestamp may be the low volatility in the early timestamp\n",
        "\n",
        "(3) Most of our model just give a very low magnitude prediction compared with the actual value .(about 1/50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "face6fa6-36ae-934f-17e5-f08fbd5b0621"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary packages \n",
        "import kagglegym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "018e401e-3666-f9ae-39c8-804e4fea7950"
      },
      "outputs": [],
      "source": [
        "# Read the full data set stored as HDF5 file\n",
        "full_df = pd.read_hdf('../input/train.h5')\n",
        "# A custom function to compute the R score\n",
        "def get_reward(y_true, y_fit):\n",
        "    R2 = 1 - np.sum((y_true - y_fit)**2) / np.sum((y_true - np.mean(y_true))**2)\n",
        "    R = np.sign(R2) * math.sqrt(abs(R2))\n",
        "    return(R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eaab9fc2-8f42-4cfd-218f-38c703dcb736"
      },
      "outputs": [],
      "source": [
        "# Some pre-processing as seen from most of the public scripts.\n",
        "# The \"environment\" is our interface for code competitions\n",
        "env = kagglegym.make()\n",
        "\n",
        "# We get our initial observation by calling \"reset\"\n",
        "observation = env.reset()\n",
        "target_var = 'y'\n",
        "\n",
        "# Get the train dataframe\n",
        "train = observation.train\n",
        "mean_values = train.median(axis=0)\n",
        "train.fillna(mean_values, inplace=True)\n",
        "\n",
        "# Observed with histograns:\n",
        "low_y_cut = -0.086093\n",
        "high_y_cut = 0.093497\n",
        "\n",
        "y_is_above_cut = (train.y > high_y_cut)\n",
        "y_is_below_cut = (train.y < low_y_cut)\n",
        "y_is_within_cut = (~y_is_above_cut & ~y_is_below_cut)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "512c1515-747d-1500-4a9a-3e00a478c2a4"
      },
      "outputs": [],
      "source": [
        "### https://www.kaggle.com/ymcdull/two-sigma-financial-modeling/ridge-lb-0-0100659/run/545100\n",
        "# The \"environment\" is our interface for code competitions\n",
        "env = kagglegym.make()\n",
        "\n",
        "# We get our initial observation by calling \"reset\"\n",
        "observation = env.reset()\n",
        "\n",
        "# cols_to_use for ridge model\n",
        "#cols_to_use = ['technical_30', 'technical_20', 'fundamental_11']\n",
        "cols_to_use = ['technical_20']\n",
        "\n",
        "# model build\n",
        "model = Ridge()\n",
        "model.fit(np.array(train.loc[y_is_within_cut, cols_to_use].values), train.loc[y_is_within_cut, target_var])\n",
        "\n",
        "# getting the y mean dict for averaging\n",
        "ymean_dict = dict(train.groupby([\"id\"])[\"y\"].mean())\n",
        "\n",
        "# weighted average of model & mean\n",
        "def get_weighted_y(series):\n",
        "    id, y = series[\"id\"], series[\"y\"]\n",
        "    return 0.95 * y + 0.05 * ymean_dict[id] if id in ymean_dict else y\n",
        "\n",
        "y_actual_list = []\n",
        "y_pred_list = []\n",
        "r1_overall_reward_list = []\n",
        "ts_list = []\n",
        "r1_lms = [] # mean squares between pred_y and acctual_y on each timestamp \n",
        "r1_lms_pre = [] # mean predicted return on each timestamp\n",
        "r1_lms_acc = [] # mean acctual return on each timestamp\n",
        "while True:\n",
        "    timestamp = observation.features[\"timestamp\"][0]\n",
        "    actual_y = list(full_df[full_df[\"timestamp\"] == timestamp][\"y\"].values)\n",
        "    observation.features.fillna(mean_values, inplace=True)\n",
        "    test_x = np.array(observation.features[cols_to_use].values)\n",
        "    observation.target.y = model.predict(test_x).clip(low_y_cut, high_y_cut)\n",
        "    \n",
        "    ## weighted y using average value\n",
        "    observation.target.y = observation.target.apply(get_weighted_y, axis = 1)\n",
        "    target = observation.target\n",
        "    observation, reward, done, info = env.step(target)\n",
        "    \n",
        "    if timestamp % 100 == 0:\n",
        "        print(\"Timestamp #{}\".format(timestamp))\n",
        "    \n",
        "    pred_y = list(target.y.values)\n",
        "    y_actual_list.extend(actual_y)\n",
        "    y_pred_list.extend(pred_y)\n",
        "    r1_lms.append(np.average( (np.array(actual_y)-np.array(pred_y) )**2))\n",
        "    tmp = np.average( np.abs(np.array(actual_y))  ) \n",
        "    r1_lms_acc.append(  tmp  )\n",
        "    tmp = np.average( np.abs( np.array(pred_y)  )   ) \n",
        "    r1_lms_pre.append(  tmp )\n",
        "    \n",
        "    \n",
        "    overall_reward = get_reward(np.array(y_actual_list), np.array(y_pred_list))\n",
        "    r1_overall_reward_list.append(overall_reward)\n",
        "    ts_list.append(timestamp)\n",
        "    if done:\n",
        "        break\n",
        "    \n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "640afe23-3c63-4fd7-0ac9-e50ac0cb3374"
      },
      "outputs": [],
      "source": [
        "plt.plot(ts_list,r1_lms)\n",
        "plt.title(\"mean square between pred_y and acctual_y on each timestamp\")\n",
        "plt.show()\n",
        "plt.plot(ts_list,r1_lms_acc)\n",
        "plt.title(\"mean absolute value of acctual_y on each timestamp\")\n",
        "plt.show()\n",
        "plt.plot(ts_list,r1_lms_pre)\n",
        "plt.title(\"mean absolute value of pred_y on each timestamp\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2f3464d8-48b7-ebb9-66ed-46460fecc463"
      },
      "source": [
        "it seems that our ridge model have a similar shape with the actual but the magnitude is too small compared with the actual . Most of the predicted values are around Zero. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "963e1f1e-e79d-b229-43b9-a0967bddb96c"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 6))\n",
        "plt.plot(ts_list, r1_overall_reward_list, c='blue')\n",
        "plt.plot(ts_list, [0]*len(ts_list), c='red')\n",
        "plt.title(\"Cumulative R value change for Univariate Ridge (technical_20)\")\n",
        "plt.ylim([-0.04,0.04])\n",
        "plt.xlim([850, 1850])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9bc8d11e-254b-f019-a119-a5de99c7e9b7"
      },
      "source": [
        "my code, which perform good in local test but worse in the public LB. can this method shed some light on why this model is overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e035dec-feb2-3f11-91ac-170ca45c9719"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model as lm\n",
        "cols_to_use = ['technical_30', 'technical_20', 'technical_40', 'technical_19']\n",
        "# Get first observation\n",
        "env = kagglegym.make()\n",
        "observation = env.reset()\n",
        "train = observation.train\n",
        "mean_values = train.mean(axis=0)\n",
        "train.fillna(mean_values, inplace=True)\n",
        "\n",
        "model = lm.LinearRegression()\n",
        "model.fit(np.array(train[cols_to_use]), train.y.values)\n",
        "\n",
        "y_pred_list = []\n",
        "mycode_overall_reward_list = []\n",
        "y_actual_list = []\n",
        "mycode_lms = []\n",
        "mycode_lms_acc = []\n",
        "mycode_lms_pre = []\n",
        "\n",
        "while True:\n",
        "    # code for the statistics\n",
        "    timestamp = observation.features[\"timestamp\"][0]\n",
        "    actual_y = list(full_df[full_df[\"timestamp\"] == timestamp][\"y\"].values)\n",
        "    \n",
        "    observation.features.fillna(mean_values, inplace=True)\n",
        "    test_x = np.array(observation.features[cols_to_use])\n",
        "    observation.target.y = model.predict(test_x)\n",
        "    target = observation.target\n",
        "    if timestamp % 100 == 0:\n",
        "        print(\"Timestamp #{}\".format(timestamp))\n",
        "    # code for the statistics    \n",
        "    pred_y = list(target.y.values)    \n",
        "    y_pred_list.extend(pred_y)\n",
        "    y_actual_list.extend(actual_y)\n",
        "    mycode_lms.append(np.average( (np.array(actual_y)-np.array(pred_y) )**2))\n",
        "    \n",
        "    tmp = np.average( np.abs(np.array(actual_y))  ) \n",
        "    mycode_lms_acc.append(  tmp  )\n",
        "    tmp = np.average( np.abs( np.array(pred_y)  )   ) \n",
        "    mycode_lms_pre.append(  tmp )\n",
        "    \n",
        "    overall_reward = get_reward(np.array(y_actual_list), np.array(y_pred_list))\n",
        "    mycode_overall_reward_list.append(overall_reward)\n",
        "    \n",
        "    observation, reward, done, info = env.step(target)\n",
        "    if done:\n",
        "        break\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4007886-eb05-3a78-8d29-767481e07b45"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.plot(ts_list,np.array(mycode_lms_acc)/50+0.001,color=\"y\",label=\"transformed acutal\")\n",
        "plt.plot(ts_list,mycode_lms_pre,label=\"mycode\",color='r')\n",
        "plt.plot(ts_list,r1_lms_pre,label=\"r1\",color='g')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title(\"the magnitude of pred_y from r1 model, pred_y from mycode,transformed actual_y on each timestamp\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "289fc597-bbb7-714d-e18f-acaa53d3954a"
      },
      "source": [
        "it seems that the the magnitude of r1 is smaller than mycode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2de3c637-5dd2-60dc-2954-0a980f5042e4"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(ts_list, mycode_overall_reward_list, c='green', label='mycode')\n",
        "ax.plot(ts_list, r1_overall_reward_list, c='blue', label='ridge-1')\n",
        "ax.plot(ts_list, [0]*len(ts_list), c='red', label='zero line')\n",
        "ax.legend(loc='lower right')\n",
        "ax.set_ylim([-0.04,0.04])\n",
        "ax.set_xlim([850, 1850])\n",
        "plt.title(\"Cumulative R value change for ridge1 and mycode\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8284e17a-b805-97dd-a6ee-e84d2f729c0d"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "----------\n",
        "\n",
        "\n",
        "this code behaves well in the last half of train set with a public score 0.017265299516796905 but in test set with -0.0350178. and it seems this cumulative R value do a good job in differentiating the overfitting problem.\n",
        "\n",
        "But what's wrong about my code? It ends with a scores  0.01726, which should be sightly improvement but in public LB -0.035. From this figure just above, the performance of my code is so volatile , even in cumulative R curve. Note that  around timestamp 1580, there is a big positive R and follows a big negative R. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60eec15b-092b-3b4f-c633-cde3aad28909"
      },
      "outputs": [],
      "source": [
        "# just for get the statistics....\n",
        "observation = env.reset()\n",
        "y_actual_list = []\n",
        "cumu_average_return = []\n",
        "cumu_std_return = []\n",
        "average_return = []\n",
        "std_return = [] \n",
        "\n",
        "while True:\n",
        "    # code for the statistics\n",
        "    timestamp = observation.features[\"timestamp\"][0]\n",
        "    actual_y = list(full_df[full_df[\"timestamp\"] == timestamp][\"y\"].values)\n",
        "    target = observation.target\n",
        "    if timestamp % 100 == 0:\n",
        "        print(\"Timestamp #{}\".format(timestamp))\n",
        "    # code for the statistics    \n",
        "    y_actual_list.extend(actual_y)\n",
        "    average_return.append(np.average(actual_y))\n",
        "    std_return .append(np.std(actual_y))\n",
        "    cumu_average_return.append(np.average(y_actual_list))\n",
        "    cumu_std_return.append(np.std(y_actual_list))\n",
        "    observation, reward, done, info = env.step(target)\n",
        "    if done:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc923443-a9bf-061e-890e-b7438f7215e3"
      },
      "outputs": [],
      "source": [
        "plt.plot(ts_list, average_return, c='red', label='average_rtn')\n",
        "plt.show()\n",
        "plt.plot(ts_list, std_return, c='yellow', label='average_rtn')\n",
        "plt.show()\n",
        "plt.plot(ts_list, cumu_average_return, c='red', label='average_rtn')\n",
        "plt.show()\n",
        "plt.plot(ts_list, cumu_std_return, c='yellow', label='average_rtn')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca4b46a2-6231-6233-bd4a-e741e99a1ecd"
      },
      "source": [
        "from the fig above , we know that the std is lower in the early stage, so according to the R formula, the R will be lower.  this may be a reason why the early cumulative R curve of many model is below zero.\n",
        "\n",
        "Here, my code didn't work well in the cumulative curve but ends with a good score. This is so called overfitting, but from the cumulative curve, we can know that this overfitting is a type of time overfitting. \n",
        "Maybe my code(use four variables) behaves extremely well in special time  but poor in other timestamp. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2ca630f9-c868-15cf-2feb-fdb9c1499255"
      },
      "source": [
        "how about define another evaluation measure?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c127dc9a-d089-b0e6-fc68-3f84d682f09a"
      },
      "outputs": [],
      "source": [
        "\n",
        "r1_lms_sqrt =[np.sqrt(i) for i in r1_lms] \n",
        "mycode_lms_sqrt =[np.sqrt(i) for i in mycode_lms] \n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "ax.plot(ts_list, mycode_lms_sqrt, c='green', label='mycode')\n",
        "ax.plot(ts_list, r1_lms_sqrt, c='blue', label='ridge-1')\n",
        "plt.title(\"the new  for ridge1 and mycode\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4896c9e2-49e3-71f1-052d-bdedbaea87cb"
      },
      "source": [
        "these two curve are overlapping..... This may be why we use R measure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "810cb2b3-27db-55ec-bed4-cc914d605cd7"
      },
      "outputs": [],
      "source": [
        "plt.plot(ts_list,mycode_lms_pre)\n",
        "plt.show()\n",
        "plt.plot(ts_list,mycode_lms_acc)\n",
        "plt.show()\n",
        "plt.plot(ts_list,r1_lms_pre)\n",
        "plt.show()\n",
        "plt.plot(ts_list,r1_lms_acc)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}