{"cells":[{"metadata":{"_uuid":"70d2764d37a848371095624eb8f4233c6239ede1"},"cell_type":"markdown","source":"# Exploring and Preprocessing the input images\n\nThis kernel intends to explore the image dataset, and preprocess them to be 224x224 to match ImageNet, and make it compatible with most architectures in Keras or Tensorflow. The resulting data will be:\n* `X_train`: 25361x224x224x3\n* `X_test`: 7960x224x224x3\n* `y_train`: 25361x5005"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport math\nimport psutil\nimport multiprocessing\n\nimport numpy as np # linear algebra\nfrom PIL import Image\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9d36f20119e79921ac19f483fa5a59abeb4af95"},"cell_type":"markdown","source":"## Exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"label_df = pd.read_csv('../input/train.csv')\nsubmission_df = pd.read_csv('../input/sample_submission.csv')\nlabel_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c9e5b61f7515d0a7366c3e36d66dc25a01c674b"},"cell_type":"code","source":"label_df['Id'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a375a7e3ee8e463fedd668170230c8459cd0a4"},"cell_type":"code","source":"# Display the most frequent ID (without counting new_whale)\nlabel_df['Id'].value_counts()[1:16].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"1ace90356946feaf6e2a8111308c94a81250c813"},"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'Image']\n        image_id = df.loc[i,'Id']\n        img = cv2.imread(f'../input/train/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d9dc344f755ded8606fe51ec497b215d83535d0"},"cell_type":"markdown","source":"The width of the image seem to be bigger than the height. We will have to pad the images, then resize them to 224x224x3"},{"metadata":{"_uuid":"8613b9ad48bd627b30acbc0715ba12f7d2aeb197"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"_uuid":"457582b8522fd04739b57ed3cd81585133a46076"},"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef pad_and_resize_cv(image_path, dataset, desired_size=224):\n    img = cv2.imread(f'../input/{dataset}/{image_path}')\n    \n    pad_width = get_pad_width(img, max(img.shape))\n    padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n    \n    resized = cv2.resize(padded, (desired_size,)*2).astype('uint8')\n    \n    return resized\n\ndef pad_and_resize_pil(image_path, dataset, desired_size=224):\n    '''Experimental'''\n    im = Image.open(f'../input/{dataset}/{image_path}')\n    \n    old_size = im.size\n    ratio = float(desired_size)/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    resized = im.resize(new_size)\n    im_array = np.asarray(resized)\n    \n    pad_width = get_pad_width(im_array, desired_size)\n    padded = np.pad(im_array, pad_width=pad_width, mode='constant', constant_values=0)\n    \n    return padded\n\n\ndef pad_and_resize(image_path, dataset, desired_size=224, mode='cv'):\n    if mode =='pil':\n        return pad_and_resize_pil(image_path, dataset, desired_size)\n    else:\n        return pad_and_resize_cv(image_path, dataset, desired_size)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9b73391f5bab9ebc649108027dae892de02534d"},"cell_type":"markdown","source":"### Padding process and resizing with OpenCV"},{"metadata":{"trusted":true,"_uuid":"d836765ab3393ba9a23712efea6d195e2ce61353"},"cell_type":"code","source":"img = cv2.imread(f'../input/train/{label_df.loc[0,\"Image\"]}')\n\npad_width = get_pad_width(img, max(img.shape))\npadded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\nresized = cv2.resize(padded, (224,224))\nplt.imshow(resized)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed582c5a2b3cab7807f430e6dcc3a62c961edaba"},"cell_type":"markdown","source":"## Pad and resize all the images"},{"metadata":{"trusted":true,"_uuid":"6f9420096df3a58964e7d4acbb6d39714b1c63a8"},"cell_type":"code","source":"target_dummies = pd.get_dummies(label_df['Id'])\ntrain_label = target_dummies.columns.values\ny_train = target_dummies.values\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee4b66e3521a47e5212d78cc66732e4959b25bd1"},"cell_type":"code","source":"def process_dataset(dataset):\n    resized_imgs = []\n    \n    if dataset == 'train':\n        dataset_names = label_df[\"Image\"]\n    else:\n        dataset_names = submission_df['Image']\n\n    for image_path in dataset_names:\n        resized_imgs.append(pad_and_resize(image_path, dataset))\n\n    X = np.stack(resized_imgs)\n    return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"586bb58b4240b7eb92987b3145b2ee6b71b90cd6"},"cell_type":"code","source":"start_time = time.time()\n\nwith multiprocessing.Pool(1) as pool: \n    X_train, X_test = pool.map(process_dataset, [\"train\", \"test\"])\n    \nprint(f\"Images loaded in {time.time() - start_time:.2f} sec\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}