{"cells":[{"metadata":{"_uuid":"254506426a86515795e8d4553aadd8cb54ac3bd2"},"cell_type":"markdown","source":"# Data preparetion. Spet by step\n-   Simple Dataset\n-  Splitting data into train and validation part\n- Using augmentation for images\n- Adding mask\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport glob\nimport os.path as osp\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10089c168702cf48dfaabdf4fdbbd9bd94e87ad2"},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils import data as D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7820adac84631993c90a534416ee426644175339"},"cell_type":"code","source":"# Tutorail for torch version:\ntorch.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bcb144fd2277715aca75dc1e8df813947459fd27"},"cell_type":"markdown","source":"## Dataset: basic structure\nSo go to official [web documantation](https://pytorch.org/docs/stable/data.html). And see 3 main class: Dataset,  Sampler and DataLoader.\n- Dataset:\n    - An abstract class representing a Dataset.\n    - All other datasets should subclass it. All subclasses should override __len__, that provides the size of the dataset, and __getitem__, supporting integer indexing in range from 0 to len(self) exclusive.\n- Sampler:\n    - Base class for all Samplers.\n    - Every Sampler subclass has to provide an __iter__ method, providing a way to iterate over indices of dataset elements, and a __len__ method that returns the length of the returned iterators.\n- DataLoader:\n    - Combines a dataset and a sampler, and provides single- or multi-process iterators over the dataset."},{"metadata":{"trusted":true,"_uuid":"ea733b76bd84b7d8118276899e5edf173617df9d"},"cell_type":"markdown","source":"### 1.  Simple Dataset:"},{"metadata":{"trusted":true,"_uuid":"5e2c1021243a7c979ca874ec5c1a7e8bbfeebd78"},"cell_type":"code","source":"path = '../input/train/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2290b19e967d999c7bad3557e1e118550f303694"},"cell_type":"code","source":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4065f82afd939906cebc26ebf9ad862bdf0c124"},"cell_type":"code","source":"# Simple dataset. Only save path to image and load it and transform to tensor when call __getitem__.\nairimg = AirbusDS(path)\n# total images in set\nprint(airimg.len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa5ef932da763294f32c4a5f8dce75b31851828e"},"cell_type":"code","source":"# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# functions to show an image\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some images\ndataiter = iter(loader)\nimages = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,8))\nimshow(torchvision.utils.make_grid(images))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39f002d1c6b123378e87359775e74d37635f2ad4"},"cell_type":"markdown","source":"### 2. Splitting data into train and validation part\nUse random split as example. For this aim create 2 Subset"},{"metadata":{"trusted":true,"_uuid":"3a0ba2c9137b43caafadc7e17c18333b818608b3"},"cell_type":"code","source":"train_len = int(0.7*airimg.len)\nvalid_len = airimg.len - train_len\ntrain, valid = D.random_split(airimg, lengths=[train_len, valid_len])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d846c8c56d91bb44d7bec354336ff025c0fbf97a"},"cell_type":"code","source":"# check lens of subset\nlen(train), len(valid)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e41be212f0bc5ff4ac7c1611770c2d805213a9ce"},"cell_type":"markdown","source":"### 3. Using augmentation for images"},{"metadata":{"trusted":true,"_uuid":"2c09677e984fcf690b9b9692f2104f68442a2466"},"cell_type":"code","source":"# https://github.com/albu/albumentations\nfrom albumentations import (ToFloat, \n    CLAHE, RandomRotate90, Transpose, ShiftScaleRotate, Blur, OpticalDistortion, \n    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n    Flip, OneOf, Compose\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a7e0354193da459fc46900df6ed6523257042c4"},"cell_type":"code","source":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root, aug = False):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.aug = aug\n        if self.aug:\n            self.transform = OneOf([\n                                CLAHE(clip_limit=2),\n                                IAASharpen(),\n                                RandomRotate90(),\n                                IAAEmboss(),\n                                Transpose(),\n                                RandomContrast(),\n                                RandomBrightness(),\n                            ], p=0.3)\n        else:\n            self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        if self.aug:\n            data = {\"image\": np.array(image)}\n            image = self.transform(**data)['image']\n            images = np.transpose(image, (2, 0, 1))\n            return images\n        else:\n            return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a878b81066b321c6f5a89657e1ab063b10b3fc39"},"cell_type":"code","source":"airimg = AirbusDS(path, aug=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f17c6dce8af440f1bf813117e4cd048c94f217d"},"cell_type":"code","source":"# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# get some images\ndataiter = iter(loader)\nimages = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,8))\nimshow(torchvision.utils.make_grid(images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4812906e2a31bcdeecff3ab1b0a70944b6caca93"},"cell_type":"markdown","source":"### 4. Adding masks"},{"metadata":{"trusted":true,"_uuid":"3a9ce9b6c31340c19ca9148aa4cdc3358042fcb6"},"cell_type":"code","source":"# based on https://www.kaggle.com/inversion/run-length-decoding-quick-start\nmasks = pd.read_csv('../input/train_ship_segmentations.csv')\nmasks.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f07aec83c16e130d95a1614831398455d012493e"},"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfba6ef065e6001c612f5f8909570066edbbedc7"},"cell_type":"code","source":"class AirbusDS(D.Dataset):\n    \"\"\"\n    A customized data loader.\n    \"\"\"\n    def __init__(self, root, aug = False, mode='train'):\n        \"\"\" Intialize the dataset\n        \"\"\"\n        self.filenames = []\n        self.root = root\n        self.aug = aug\n        self.mode = 'test'\n        if mode == 'train':\n            self.mode = 'train'\n            self.masks = pd.read_csv('../input/train_ship_segmentations.csv').fillna(-1)\n        if self.aug:\n            self.transform = OneOf([\n                                RandomRotate90(),\n                                Transpose(),\n                                Flip(),\n                            ], p=0.3)\n        else:\n            self.transform = transforms.ToTensor()\n        filenames = glob.glob(osp.join(path, '*.jpg'))\n        for fn in filenames:\n            self.filenames.append(fn)\n        self.len = len(self.filenames)\n        \n    # You must override __getitem__ and __len__\n    def get_mask(self, ImageId):\n        img_masks = self.masks.loc[self.masks['ImageId'] == ImageId, 'EncodedPixels'].tolist()\n\n        # Take the individual ship masks and create a single mask array for all ships\n        all_masks = np.zeros((768, 768))\n        if img_masks == [-1]:\n            return all_masks\n        for mask in img_masks:\n            all_masks += rle_decode(mask)\n        return all_masks\n    \n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.open(self.filenames[index])\n        ImageId = self.filenames[index].split('/')[-1]\n        if self.mode == 'train':\n            mask = self.get_mask(ImageId)\n        if self.aug:\n            if self.mode == 'train':\n                data = {\"image\": np.array(image), \"mask\": mask}\n            else:\n                data = {\"image\": np.array(image)}\n            transformed = self.transform(**data)\n            image = transformed['image']/255\n            image = np.transpose(image, (2, 0, 1))\n            if self.mode == 'train':\n                return image, transformed['mask'][np.newaxis,:,:] \n            else:\n                return image\n        else:\n            if self.mode == 'train':\n                return self.transform(image), mask[np.newaxis,:,:] \n            return self.transform(image)\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cef601e3807d8e0d101b138324daa03d8a7e4a8"},"cell_type":"code","source":"airimg = AirbusDS(path, aug=True, mode='train')\n# Use the torch dataloader to iterate through the dataset\nloader = D.DataLoader(airimg, batch_size=24, shuffle=False, num_workers=0)\n\n# get some images\ndataiter = iter(loader)\nimages, masks = dataiter.next()\n\n# show images\nplt.figure(figsize=(16,16))\nplt.subplot(211)\nimshow(torchvision.utils.make_grid(images))\nplt.subplot(212)\nimshow(torchvision.utils.make_grid(masks))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bc990abb3cbb4ee6e1ade437e455895b022699d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}