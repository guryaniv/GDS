{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3da45999-ae91-e3f9-16b4-142d295e0b86"
      },
      "source": [
        "#Introduction:\n",
        "Beginner Notebook with step by step documentation. The goal is to transition from just online courses to real world problems.\n",
        "\n",
        "#Remarks:\n",
        "* I have no educational background in CS\n",
        "* Feel free to contribute for a better learning experience\n",
        "* Good luck everyone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ed1a4479-e495-83bc-ab91-eefe77dac10e"
      },
      "source": [
        "#Step 1: Import all the things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff8dd54a-0769-d995-278d-8fbf47ea59ec"
      },
      "outputs": [],
      "source": [
        "import numpy as np #linAlgebra\n",
        "import pandas as pd #dataFrames ans data manipulation\n",
        "import sklearn as sk # basic ML; Models will come directly from sklearn \n",
        "import matplotlib as mpl #basic import for dataviz\n",
        "import matplotlib.pyplot as plt #convenient way to use pyplot \n",
        "import seaborn as sns #extended dataviz\n",
        "from datetime import datetime #conerting the string date to a normal date format\n",
        "\n",
        "%matplotlib inline\n",
        "#more things will come while I reach the different steps \n",
        "\n",
        "#Good idea from SKS to not let my notebook explode\n",
        "pd.options.display.max_columns = 999"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7d085a77-ee6b-e003-929e-9b6877e7849e"
      },
      "source": [
        "#Step 2: get a first idea about the dataset\n",
        "I will use SRKSimple Exploration Notebook - Zillow Prize as a string point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "41d1e469-c2a2-a318-b6bb-799a7abc79d8"
      },
      "outputs": [],
      "source": [
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce4d3d38-8bf6-5953-a4fb-16462f5b9d25"
      },
      "source": [
        "##Import all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8551ef3a-7cb2-f645-21c5-7240afc4593e"
      },
      "outputs": [],
      "source": [
        "#properties_2016_df = pd.read_csv(\"../input/properties_2016.csv\")\n",
        "#sample_submission_df = pd.read_csv(\"../input/sample_submission.csv\")\n",
        "train_2016_df = pd.read_csv(\"../input/train_2016.csv\", parse_dates = [\"transactiondate\"])\n",
        "#Datadictionary is a file where the different datapoints are described\n",
        "#Got an error when importing the first two files. I think it has something to do with the memory. Ill just start with the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d18f276-672e-6387-6239-8b153a2c6282"
      },
      "outputs": [],
      "source": [
        "train_2016_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29246019-239e-6949-e616-42785a869a02"
      },
      "outputs": [],
      "source": [
        "train_2016_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1157dec5-038d-2d2e-93b9-e38a4648373b"
      },
      "source": [
        "##What do we see:\n",
        "1. The parcelid is a unique(? we'll see) ID for a certain object\n",
        "2. The logerror is the target variable for this competition. It is defined as followed: logerror= log(Zestimate) - log(SalesPrice)\n",
        "3. The transactiondate is obviously the date of this transaction\n",
        "\n",
        "## Now let us explore the dataset in three major bullets:\n",
        "###Bullet 1: parcelid\n",
        "* How many parcelid's do we have (hint 90811 rows)\n",
        "* Is the parcelid a unique value ? If not, how often are parcel id's been \"traded\"\n",
        "\n",
        "###Bullet 2: logerror\n",
        "* Whats the range of the logerror\n",
        "* Are there any outliers\n",
        "* How is the distribution among the logerror\n",
        "\n",
        "###Bullet 3: transactiondate\n",
        "* How many Transaction have been made in certain time periods\n",
        "* How is the distribution of the logerror among the different time periods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "144f1869-fcfc-d7fb-8a91-da34d98d8a58"
      },
      "source": [
        "##Bullet 1: parcelid\n",
        "###Answers:\n",
        "* How many parcelid's do we have (hint 90811 rows)\n",
        "1. 90811 parcelid's in the training set\n",
        "* Is the parcelid a unique value ? If not, how often are parcel id's been \"traded\"\n",
        "1. Most of them are unique, 127 are listed 2 times and only 1 is listed three times. We'll investigate it later when we have an understand of all the different files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2bef64b8-9bde-f9ba-4ea0-cfe6c53a780f"
      },
      "outputs": [],
      "source": [
        "parcelid_duplicates = train_2016_df.groupby(\"parcelid\").size().reset_index().rename(columns={0:'count'})\n",
        "parcelid_duplicates[\"count\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "318922e2-3594-f980-c34b-edb8c6da48fd"
      },
      "source": [
        "##Bullet 2: logerror\n",
        "###Answers:\n",
        "* Whats the range of the logerror\n",
        "1. -4.605 -4.737\n",
        "* Are there any outliers\n",
        "1. yes the min max value, I will cut everything what is bigger than 6 sigma \n",
        "* How is the distribution among the logerror\n",
        "1. pretty much normal distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cce0d191-4f68-067a-7ec3-b74f1d7b34d4"
      },
      "outputs": [],
      "source": [
        "print(train_2016_df[\"logerror\"].max())\n",
        "print(train_2016_df[\"logerror\"].min())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "910e06e8-3e3e-2248-1072-f7f60ca6a4bd"
      },
      "outputs": [],
      "source": [
        "train_2016_df_sorted = train_2016_df.sort_values(by = \"logerror\")\n",
        "train_2016_df_sorted.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e804f0ae-8785-d076-56a1-4ecb8063e698"
      },
      "outputs": [],
      "source": [
        "train_2016_df_sorted.tail(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7686eb7f-2ca0-ed31-62c8-8fb95a370d31"
      },
      "outputs": [],
      "source": [
        "#sorted scatterplot\n",
        "x = range(train_2016_df_sorted.shape[0])\n",
        "y = train_2016_df_sorted[\"logerror\"]\n",
        "plt.scatter(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c228e809-1f06-dbae-d3fe-27af1668cf9f"
      },
      "outputs": [],
      "source": [
        "logerror_duplicates = train_2016_df.groupby(\"logerror\").size().reset_index().rename(columns={0:'count'})\n",
        "#print(logerror_duplicates[\"count\"].value_counts(bins = 20))\n",
        "x = logerror_duplicates[\"logerror\"]\n",
        "y = logerror_duplicates[\"count\"]\n",
        "plt.hist(logerror_duplicates[\"logerror\"], bins = 20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2950097a-a7fa-1161-3eff-dfdaaf7bb646"
      },
      "source": [
        "###Bullet 3: transactiondate\n",
        "###Answers:\n",
        "* How many Transaction have been made in certain time periods\n",
        "* How is the distribution of the logerror among the different time periods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a9768d09-12c6-b172-600a-6af480f5fcfa"
      },
      "source": [
        "Before Starting I need to change the transactiondate from string to datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f0a8100-c8b1-5bea-f39b-ebdfc0d21d91"
      },
      "outputs": [],
      "source": [
        "train_2016_df[\"transactiondate\"].iloc[2].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "221e61cc-52c3-e61f-cdf0-681c42dd1ce1"
      },
      "outputs": [],
      "source": [
        "x = train_2016_df[\"transactiondate\"]\n",
        "y = train_2016_df[\"logerror\"]\n",
        "plt.scatter(x,y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9693035a-8350-1e16-6001-2b786788d223"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}