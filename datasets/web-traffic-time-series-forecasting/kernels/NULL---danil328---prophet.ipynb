{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"trusted": true, "_uuid": "cff98cd4cfcff6ae891a23ae1018f2c3f95936a3", "_cell_guid": "5dc09cd8-3788-4389-927f-caf4b0158ce2"}, "execution_count": null, "cell_type": "code", "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nfrom fbprophet import Prophet\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "8c3ce9995f24962a889f13bb89415c580878f357", "_cell_guid": "21f58d52-edb1-4a86-9e22-163770e4c7e1"}, "execution_count": null, "cell_type": "code", "source": "train_1 = pd.read_csv('../input/train_1.csv')\ntrain_1.head()", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "bff83c132c57d7e64b6cb70014dbad364952f6c8", "_cell_guid": "d798023f-8ee8-4536-8f1d-daca51e8b0cf"}, "execution_count": null, "cell_type": "code", "source": "train_1.fillna(0, inplace=True)\npage=pd.DataFrame(train_1[train_1.columns[0]])\ntrain_1=train_1.drop(train_1.columns[0], axis=1)\ntrain_1.columns=range(len(train_1.columns))\ntrain_1=train_1.transpose()  \ntrain_1.columns=[page[page.columns[0]]]    \ntrain_1=train_1.convert_objects(convert_numeric=True)\ntrain_1.head()", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "e4ec03b9a9417a95a9139a6807a934a2ad5850c8", "collapsed": true, "_cell_guid": "7c5bba59-1b04-474e-836a-6a2f45988cd9"}, "execution_count": null, "cell_type": "code", "source": "df=pd.DataFrame(train_1[train_1.columns[0]])\ndf.insert(loc=1, column='visits', value=train_1[train_1.columns[1]])  #number columns \ny=df[-60:] \ny=y.visits.values\ndf=df[:-60]\n\ncount=0\nfor i in df.visits:\n    if i == 0:\n        count=count+1\n        \ndf=df[count:]\ndf.visits.replace(to_replace=0,value=df.visits.mean(),inplace=True)\ndf['visits'] = np.log(df['visits'])\ndf.columns = [\"ds\", \"y\"]", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "21928dc85e7ad5ad54f271c74822103dd8a9dcf6", "collapsed": true, "_cell_guid": "4d99a662-dab1-4e69-bd4f-372689eaee2d"}, "execution_count": null, "cell_type": "code", "source": "articles = pd.DataFrame({\n  'holiday': 'publish',\n  'ds': pd.to_datetime(['2014-09-27', '2014-10-05', '2014-10-14', '2014-10-26', '2014-11-9',\n                        '2014-11-18', '2014-11-30', '2014-12-17', '2014-12-29', '2015-01-06',\n                        '2015-01-20', '2015-02-02', '2015-02-16', '2015-03-23', '2015-04-08',\n                        '2015-05-04', '2015-05-17', '2015-06-09', '2015-07-02', '2015-07-13',\n                        '2015-08-17', '2015-09-14', '2015-10-26', '2015-12-07', '2015-12-30',\n                        '2016-01-26', '2016-04-06', '2016-05-16', '2016-06-15', '2016-08-23',\n                        '2016-08-29', '2016-09-06', '2016-11-21', '2016-12-19', '2016-12-31',\n                        '2017-01-01', '2017-01-17', '2017-02-06', '2017-02-21']),\n  'lower_window': 0,\n  'upper_window': 3,\n})", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "4c5c317e3e4a0f9676ed6806374385d2a83ccada", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": "m = Prophet(holidays=articles,changepoint_prior_scale=0.01,weekly_seasonality=True,yearly_seasonality=True).fit(df)\nfuture = m.make_future_dataframe(periods=60)\nforecast = m.predict(future)\n\nforecast[\"Sessions\"] = np.exp(forecast.yhat).round()\nforecast[\"Sessions_lower\"] = np.exp(forecast.yhat_lower).round()\nforecast[\"Sessions_upper\"] = np.exp(forecast.yhat_upper).round()\nforecast[(forecast.ds > \"3-5-2017\") &(forecast.ds < \"4-1-2017\")][[\"ds\", \"yhat\", \"Sessions_lower\",\"Sessions\", \"Sessions_upper\"]]\n\nforecast[\"Projected_Sessions\"] = np.exp(forecast.yhat).round()\nforecast[\"Projected_Sessions_lower\"] = np.exp(forecast.yhat_lower).round()\nforecast[\"Projected_Sessions_upper\"] = np.exp(forecast.yhat_upper).round()", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "23b3cf6363dac63b52bc21dcb435f91d83a39c9b", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": "final_proj = forecast[(forecast.ds > \"2016-11-01\") &(forecast.ds < \"2017-03-02\")][[\"ds\", \"Projected_Sessions_lower\",\"Projected_Sessions\", \"Projected_Sessions_upper\"]]\nm.plot(forecast);\n\ndef getsmape(pred,target):\n    smape=0\n    for i in range(len(pred)):\n        smape=smape+(abs(target[i]-pred[i])/((abs(target[i])+abs(pred[i]))/2))\n    smape=smape*100/len(pred)\n    return smape\n\nx=final_proj.Projected_Sessions\nx=x.values\nx=x*0.8  #0.8 it's well\nsmape=getsmape(x,y)\nprint (smape)", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}