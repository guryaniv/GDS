{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a026762affc903bfbde120e5709200e6d6b0584"},"cell_type":"code","source":"# show first 5 lines in train.csv\nDATA_DIR = \"../input/\"\ntrain = pd.read_csv(DATA_DIR + \"train.csv\")\ntest = pd.read_csv(DATA_DIR + \"test.csv\")\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba56b90cb61ed81bc36a8f6d8bf69f5dc02ffd24"},"cell_type":"code","source":"print(train.shape)\nprint(\"The number of traning examples(data points) = %i \" % train.shape[0])\nprint(\"The number of features we have = %i \" % train.shape[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1754f2768b0f4246a1b671bd997ac42d1ee363e"},"cell_type":"code","source":"import seaborn as sns\n\nimport matplotlib.pyplot as plt\n\ncorr = train.corr()\nf, ax = plt.subplots(figsize=(25, 25))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# sns.palplot(sns.diverging_palette(220, 10, n=10))\n\nsns.heatmap(corr, cmap=cmap, center=0, square=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efdd1c0333354059526979550a11cb7d83ae0aed"},"cell_type":"code","source":"# Drop unneccesary columns\ntrain.drop(['Id'], inplace=True, axis=1)\ntrain.drop(['Soil_Type15', 'Soil_Type7'], inplace=True, axis=1)\ntest.drop(['Soil_Type15', 'Soil_Type7'], inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06aebf1dacf077e820e4b791121263a21ad21beb"},"cell_type":"code","source":"# train.head()\ntrain['HorizontalHydrology_HorizontalFire'] = (train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Fire_Points'])\ntrain['Neg_HorizontalHydrology_HorizontalFire'] = (train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Fire_Points'])\ntrain['HorizontalHydrology_HorizontalRoadways'] = (train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Roadways'])\ntrain['Neg_HorizontalHydrology_HorizontalRoadways'] = (train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Roadways'])\ntrain['HorizontalFire_Points_HorizontalRoadways'] = (train['Horizontal_Distance_To_Fire_Points']+train['Horizontal_Distance_To_Roadways'])\ntrain['Neg_HorizontalFire_Points_HorizontalRoadways'] = (train['Horizontal_Distance_To_Fire_Points']-train['Horizontal_Distance_To_Roadways'])\n\ntrain['Neg_Elevation_Vertical'] = train['Elevation']-train['Vertical_Distance_To_Hydrology']\ntrain['Elevation_Vertical'] = train['Elevation']+train['Vertical_Distance_To_Hydrology']\n\ntrain['mean_hillshade'] =  (train['Hillshade_9am']  + train['Hillshade_Noon'] + train['Hillshade_3pm'] ) / 3\n\ntrain['Mean_HorizontalHydrology_HorizontalFire'] = (train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Fire_Points'])/2\ntrain['Mean_HorizontalHydrology_HorizontalRoadways'] = (train['Horizontal_Distance_To_Hydrology']+train['Horizontal_Distance_To_Roadways'])/2\ntrain['Mean_HorizontalFire_Points_HorizontalRoadways'] = (train['Horizontal_Distance_To_Fire_Points']+train['Horizontal_Distance_To_Roadways'])/2\n\ntrain['MeanNeg_Mean_HorizontalHydrology_HorizontalFire'] = (train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Fire_Points'])/2\ntrain['MeanNeg_HorizontalHydrology_HorizontalRoadways'] = (train['Horizontal_Distance_To_Hydrology']-train['Horizontal_Distance_To_Roadways'])/2\ntrain['MeanNeg_HorizontalFire_Points_HorizontalRoadways'] = (train['Horizontal_Distance_To_Fire_Points']-train['Horizontal_Distance_To_Roadways'])/2\n\ntrain['Slope2'] = np.sqrt(train['Horizontal_Distance_To_Hydrology']**2+train['Vertical_Distance_To_Hydrology']**2)\ntrain['Mean_Fire_Hydrology_Roadways']=(train['Horizontal_Distance_To_Fire_Points'] + train['Horizontal_Distance_To_Hydrology'] + train['Horizontal_Distance_To_Roadways']) / 3\ntrain['Mean_Fire_Hyd']=(train['Horizontal_Distance_To_Fire_Points'] + train['Horizontal_Distance_To_Hydrology']) / 2 \n\ntrain[\"Vertical_Distance_To_Hydrology\"] = abs(train['Vertical_Distance_To_Hydrology'])\n\ntrain['Neg_EHyd'] = train.Elevation-train.Horizontal_Distance_To_Hydrology*0.2\n\n\ntest['HorizontalHydrology_HorizontalFire'] = (test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Fire_Points'])\ntest['Neg_HorizontalHydrology_HorizontalFire'] = (test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Fire_Points'])\ntest['HorizontalHydrology_HorizontalRoadways'] = (test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Roadways'])\ntest['Neg_HorizontalHydrology_HorizontalRoadways'] = (test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Roadways'])\ntest['HorizontalFire_Points_HorizontalRoadways'] = (test['Horizontal_Distance_To_Fire_Points']+test['Horizontal_Distance_To_Roadways'])\ntest['Neg_HorizontalFire_Points_HorizontalRoadways'] = (test['Horizontal_Distance_To_Fire_Points']-test['Horizontal_Distance_To_Roadways'])\n\ntest['Neg_Elevation_Vertical'] = test['Elevation']-test['Vertical_Distance_To_Hydrology']\ntest['Elevation_Vertical'] = test['Elevation'] + test['Vertical_Distance_To_Hydrology']\n\ntest['mean_hillshade'] = (test['Hillshade_9am']  + test['Hillshade_Noon']  + test['Hillshade_3pm'] ) / 3\n\ntest['Mean_HorizontalHydrology_HorizontalFire'] = (test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Fire_Points'])/2\ntest['Mean_HorizontalHydrology_HorizontalRoadways'] = (test['Horizontal_Distance_To_Hydrology']+test['Horizontal_Distance_To_Roadways'])/2\ntest['Mean_HorizontalFire_Points_HorizontalRoadways'] = (test['Horizontal_Distance_To_Fire_Points']+test['Horizontal_Distance_To_Roadways'])/2\n\ntest['MeanNeg_Mean_HorizontalHydrology_HorizontalFire'] = (test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Fire_Points'])/2\ntest['MeanNeg_HorizontalHydrology_HorizontalRoadways'] = (test['Horizontal_Distance_To_Hydrology']-test['Horizontal_Distance_To_Roadways'])/2\ntest['MeanNeg_HorizontalFire_Points_HorizontalRoadways'] = (test['Horizontal_Distance_To_Fire_Points']-test['Horizontal_Distance_To_Roadways'])/2\n\ntest['Slope2'] = np.sqrt(test['Horizontal_Distance_To_Hydrology']**2+test['Vertical_Distance_To_Hydrology']**2)\ntest['Mean_Fire_Hydrology_Roadways']=(test['Horizontal_Distance_To_Fire_Points'] + test['Horizontal_Distance_To_Hydrology'] + test['Horizontal_Distance_To_Roadways']) / 3 \ntest['Mean_Fire_Hyd']=(test['Horizontal_Distance_To_Fire_Points'] + test['Horizontal_Distance_To_Hydrology']) / 2\n\n\ntest['Vertical_Distance_To_Hydrology'] = abs(test[\"Vertical_Distance_To_Hydrology\"])\n\ntest['Neg_EHyd'] = test.Elevation-test.Horizontal_Distance_To_Hydrology*0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4a0927519eda567c40055474af8994f9d4609e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx = train.drop(['Cover_Type'], axis=1)\ny = train['Cover_Type']\n\nX_train, X_test, y_train, y_test = train_test_split(x.values, y.values, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44b85078d07dbf5001a2de87c74504b3983dc454"},"cell_type":"code","source":"from sklearn import datasets\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\n\nclf = ExtraTreesClassifier()\nclf.fit(X_train, y_train)\n\nz = clf.feature_importances_\n\ndf = pd.DataFrame()\nprint(len(z), X_train.shape[1])\n\ndf[\"values\"] = z\ndf[\"column\"] = list(x.columns.values)\n\ndf.sort_values(by=\"values\", ascending=False, inplace=True)\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ba626dd7a4b3625fbed9ce9117365453690ffb2"},"cell_type":"code","source":"# Preprocessing: Normalization and dimension reduction\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn import decomposition\n\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c4bbe7a3c33b2eee26f03b3237e871ab29c31a6"},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nfrom xgboost import XGBClassifier\n\nclf = ExtraTreesClassifier(n_estimators=950, random_state=0)\nclf.fit(X_train, y_train)\n\nprint('Accuracy of classifier on training set: {:.2f}'.format(clf.score(X_train, y_train) * 100))\nprint('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X_test, y_test) * 100))\n\n# Uncomment the below code for gridSearchCV\n# n_estimators = np.linspace(start = 600 , stop = 1000, num = 8, dtype= int )\n# n_estimators = [500, 550, 600, 650, 700, 750, 800 , 850, 900, 950]\n\n# param_grid = {'n_estimators': n_estimators}\n# grid = GridSearchCV(clf, param_grid =param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n# grid.fit(x_train, y_train)\n\n# print(\"The best parameters are %s with a score of %0.0f\" % (grid.best_params_, grid.best_score_ * 100 ))\n# print( \"Best estimator accuracy on test set {:.2f} \".format(grid.best_estimator_.score(x_test, y_test) * 100 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d321fb0449c3f8d4fadfbcf324f3727a960d71d"},"cell_type":"code","source":"idx = test['Id']\ntest.drop(['Id'], inplace=True, axis=1)\n\ntest = scaler.transform(test)\n\npredictions = clf.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad1989e6ff6dca65df63f2679c69905afe25d874"},"cell_type":"code","source":"out = pd.DataFrame()\nout['Id'] = idx\nout['Cover_Type'] = predictions\nout.to_csv('my_submission.csv', index=False)\n\nout.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35d48ee48f20cc8dbfd424c1805e2fc9f8bb9883"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}