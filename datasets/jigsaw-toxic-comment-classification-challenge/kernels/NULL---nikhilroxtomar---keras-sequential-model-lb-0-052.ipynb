{"metadata": {"language_info": {"version": "3.6.4", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"metadata": {"_uuid": "f5e86b7bf4f117737ae32952c22d6ada16b45b5c", "_cell_guid": "d493a15b-c3f8-4fc8-b6f6-b244262cc9cc"}, "source": ["**Perform the necessary imports**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "68cb2423a6f01d469434af0430887b537efcfb51", "_cell_guid": "5e3d88fb-79b6-4876-aa4f-700ee70b6a97"}, "outputs": [], "execution_count": null, "source": ["import numpy as np\n", "import pandas as pd\n", "from keras.preprocessing import text, sequence\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Activation\n", "from keras.layers import Embedding\n", "from keras.layers import Conv1D, GlobalMaxPooling1D\n", "from sklearn.model_selection import train_test_split"], "cell_type": "code"}, {"metadata": {"_uuid": "36fe75d8b240981c941a1f0c67831acbb5b5b944", "_cell_guid": "de245cc0-77b6-41e1-95eb-a1c262a67d13"}, "source": ["**Necessary global variables**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "2b0d3e0df7b39c957a5aa82929828c6d38ed045c", "collapsed": true, "_cell_guid": "9ee07ff6-a9f6-43e6-acd5-0c0b6991434c"}, "outputs": [], "execution_count": null, "source": ["list_of_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n", "max_features = 20000\n", "max_text_length = 400\n", "embedding_dims = 50\n", "filters = 250\n", "kernel_size = 3\n", "hidden_dims = 250\n", "batch_size = 128\n", "epochs = 1"], "cell_type": "code"}, {"metadata": {"_uuid": "f7c54e5252d6eaa902043414368ecf077a7122c4", "_cell_guid": "297811ae-23ee-471a-b3c1-a39afda0603b"}, "source": ["**Quick peek into the data**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "c7ce7a4f881105d1d64fe22b9197311e057696e3", "_cell_guid": "d30f5899-23a4-42a1-aa44-bb0f4e075104"}, "outputs": [], "execution_count": null, "source": ["train_df = pd.read_csv('../input/train.csv')\n", "print(train_df.head())"], "cell_type": "code"}, {"metadata": {"_uuid": "4cae0fb90301fc9a5ed4005b498261eb939c213e", "_cell_guid": "672807f9-6ce2-47d1-9a1c-80fe07576b09"}, "source": ["**Printing using 'iloc' just for fun**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "25e62320d15cacbc201714c861591c18d2acc220", "_cell_guid": "2b90735a-eb0a-4ee3-9545-2233f2fdee02"}, "outputs": [], "execution_count": null, "source": ["print(train_df.iloc[0, -7])\n", "print(train_df.iloc[0, 1])"], "cell_type": "code"}, {"metadata": {"_uuid": "d107221dc682c12682832224bfe5cc6fd10462a9", "_cell_guid": "858757df-0cb8-4187-8c3d-1172ba673af4"}, "source": ["**Checking if  NaNs exist in the training data**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8a9fcc9505de340c9f0a157b2c9aef37851e7b91", "_cell_guid": "3a1ffb98-08b4-4363-b19f-d4b4ed6c808a"}, "outputs": [], "execution_count": null, "source": ["print(np.where(pd.isnull(train_df)))"], "cell_type": "code"}, {"metadata": {"_uuid": "6e3afb7d148fcba97b16dfa69898ede9d83edf01", "_cell_guid": "752260bc-592e-40c1-8d4a-728873fdbe47"}, "source": ["**Apparently no NaNs in the training set!**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "0a76a762fce842e1d254d84d44af56cd6d33333e", "_cell_guid": "4b1145e3-caa3-474d-b471-0fa37f402801"}, "source": ["**Converting pandas series to a numpy array using .values**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "aaa6ccda53c3facedcd6f92e5e5f7408c6a28efc", "_cell_guid": "a74097c1-ba58-45c1-ae57-551496a96994"}, "outputs": [], "execution_count": null, "source": ["x = train_df['comment_text'].values\n", "print(x)"], "cell_type": "code"}, {"metadata": {"_uuid": "bb2b3f733ffee73d9504542814ceda82282f7007", "_cell_guid": "8263e42d-a76b-4e3b-bfb1-c42fe366f7bb"}, "outputs": [], "execution_count": null, "source": ["print(\"properties of x\")\n", "print(\"type : {}, dimensions : {}, shape : {}, total no. of elements : {}, data type of each element: {}, size of each element {} bytes\".format(type(x), x.ndim, x.shape, x.size, x.dtype, x.itemsize))"], "cell_type": "code"}, {"metadata": {"_uuid": "7abe952d6a9b178edadc0751795649842c4ff042", "_cell_guid": "88890c4f-bfd1-47f4-bc69-30435001c6f5"}, "source": ["**Getting the labels**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "7b65845c54b983d2602e68f1e0438b9c712dc300", "_cell_guid": "706f8df5-41b1-4a75-9d20-864b5cf3d791"}, "outputs": [], "execution_count": null, "source": ["y = train_df[list_of_classes].values\n", "print(y)"], "cell_type": "code"}, {"metadata": {"_uuid": "5fc08696b61be737b0b1f16b412abed4c5a2abb9", "_cell_guid": "1a7180e9-0756-4f58-bb57-d37dde2bd528"}, "outputs": [], "execution_count": null, "source": ["print(\"properties of y\")\n", "print(\"type : {}, dimensions : {}, shape : {}, total no. of elements : {}, data type of each element: {}, size of each element {} bytes\".format(type(y), y.ndim, y.shape, y.size, y.dtype, y.itemsize))"], "cell_type": "code"}, {"metadata": {"_uuid": "b8ba64cd620fc3453bce297105fcdb8d6fb8e306", "_cell_guid": "af34631e-ff2c-4cf3-bee5-0b5a9bdb0db9"}, "source": ["**Keras makes our life easy. Using Tokenizer to get a list of sequence and then padding it form a 2D numpy array **"], "cell_type": "markdown"}, {"metadata": {"_uuid": "e8ed34f540de09e56dcd95bc0e509d4a406eb8a8", "_cell_guid": "55cf2aa3-b53e-4f4e-b9f1-f4043f04120d"}, "outputs": [], "execution_count": null, "source": ["x_tokenizer = text.Tokenizer(num_words=max_features)\n", "print(x_tokenizer)\n", "x_tokenizer.fit_on_texts(list(x))\n", "print(x_tokenizer)\n", "x_tokenized = x_tokenizer.texts_to_sequences(x) #list of lists(containing numbers), so basically a list of sequences, not a numpy array\n", "#pad_sequences:transform a list of num_samples sequences (lists of scalars) into a 2D Numpy array of shape \n", "x_train_val = sequence.pad_sequences(x_tokenized, maxlen=max_text_length)"], "cell_type": "code"}, {"metadata": {"_uuid": "6ad16f7b64b4cd930ba3d2837937d9ad9548bb84", "_cell_guid": "758e64cc-2646-45bf-b9e1-ace946e8174b"}, "outputs": [], "execution_count": null, "source": ["print(\"properties of x_train_val\")\n", "print(\"type : {}, dimensions : {}, shape : {}, total no. of elements : {}, data type of each element: {}, size of each element {} bytes\".format(type(x_train_val), x_train_val.ndim, x_train_val.shape, x_train_val.size, x_train_val.dtype, x_train_val.itemsize))"], "cell_type": "code"}, {"metadata": {"_uuid": "d68eea53d70a1701ba939991fdeb9976c8df05c4", "_cell_guid": "cd3693ba-3872-4e07-96f9-99087ae5bd70"}, "source": ["**90% of the data is used for training and the rest for validation**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "4bdd0b3298393be4f5150c725569dadb789fb3b4", "collapsed": true, "_cell_guid": "d84418e1-95e7-4024-b494-825e00ce8172"}, "outputs": [], "execution_count": null, "source": ["x_train, x_val, y_train, y_val = train_test_split(x_train_val, y, test_size=0.1, random_state=1)"], "cell_type": "code"}, {"metadata": {"_uuid": "2848de4a72693329cdd114c3e2b0d5fe2e5c4cd3", "_cell_guid": "a044595d-de8f-4d4d-b547-5c1fee4e4e4f"}, "source": ["**Start building the model**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "56417e8ca623249048c89be6ba75b18209abb6da", "_cell_guid": "c66cbdb4-9c9d-4120-aed9-023f2d5c1659"}, "outputs": [], "execution_count": null, "source": ["print('Build model...')\n", "model = Sequential()\n", "\n", "# we start off with an efficient embedding layer which maps\n", "# our vocab indices into embedding_dims dimensions\n", "model.add(Embedding(max_features,\n", "                    embedding_dims,\n", "                    input_length=max_text_length))\n", "model.add(Dropout(0.2))\n", "\n", "# we add a Convolution1D, which will learn filters\n", "# word group filters of size filter_length:\n", "model.add(Conv1D(filters,\n", "                 kernel_size,\n", "                 padding='valid',\n", "                 activation='relu',\n", "                 strides=1))\n", "# we use max pooling:\n", "model.add(GlobalMaxPooling1D())\n", "\n", "# We add a vanilla hidden layer:\n", "model.add(Dense(hidden_dims))\n", "model.add(Dropout(0.2))\n", "model.add(Activation('relu'))\n", "\n", "# We project onto 6 output layers, and squash it with a sigmoid:\n", "model.add(Dense(6))\n", "model.add(Activation('sigmoid'))\n", "\n", "model.compile(loss='binary_crossentropy',\n", "              optimizer='adam',\n", "              metrics=['accuracy'])\n", "\n", "model.summary()"], "cell_type": "code"}, {"metadata": {"_uuid": "b2aabd44e7161e983ddea65a6489fb9b18e187e9", "_cell_guid": "67a54a4c-f08a-490c-ae9f-e7a13c7e41e1"}, "source": ["**Begin training**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "297008f72969696c9031cbdfa7eb2ed964a2069a", "_cell_guid": "5ce38563-9ce9-4c5c-b084-350a5a74bc0b"}, "outputs": [], "execution_count": null, "source": ["model.fit(x_train, y_train,\n", "          batch_size=batch_size,\n", "          epochs=epochs,\n", "validation_data=(x_val, y_val))"], "cell_type": "code"}, {"metadata": {"_uuid": "f03aed757872dac28edd054ccf956d9249ade471", "_cell_guid": "1fbbc91d-73fd-4ed4-8c66-9fbdec9485d9"}, "source": ["**Good job! 98% accuracy on the validation set. Scope for improvement exists!**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "3592c6fa0c6100d8847db8ab7c53a9b85d6a48b1", "_cell_guid": "cb35da05-2661-42d2-be40-6656eda6ff71"}, "source": ["**Quick peek into the test set**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "038b1acf1b88e71ef0b5cd29070fd9bfa90c9c95", "_cell_guid": "f99b26ea-0ee9-4ea6-aa71-8e4e3a3d5cda"}, "outputs": [], "execution_count": null, "source": ["test_df = pd.read_csv('../input/test.csv')\n", "print(test_df.head())"], "cell_type": "code"}, {"metadata": {"_uuid": "1b903303556d9efa8716153b453f5c19860c00e3", "_cell_guid": "96fe1fc4-cbc6-45df-98f9-79fa8fa9326f"}, "source": ["**Checking if  NaNs exist in the test data**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "441dab5b1c9a842943d6d0f37537ae79b12e5868", "_cell_guid": "4ee9acc5-131f-4aee-b42d-7dba412338ee"}, "outputs": [], "execution_count": null, "source": ["print(np.where(pd.isnull(test_df)))"], "cell_type": "code"}, {"metadata": {"_uuid": "17003afb11c9a45651e950a999410d40dad13e10", "_cell_guid": "219da36e-9c01-4cc5-bb37-b60dcf828e1d"}, "source": ["**Hmmm**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "fac1694d92d39700287ea83c2f56aa1d38eb5315", "_cell_guid": "0b578f37-57ea-4163-9544-7f98c51e5c43"}, "outputs": [], "execution_count": null, "source": ["test_df.iloc[52300, 1]"], "cell_type": "code"}, {"metadata": {"_uuid": "1d8461f41d14fe71577fa337d0666232181d5b9c", "_cell_guid": "0bb52e9e-209c-44a3-b798-e03498a8fc54"}, "source": ["**Fill the NaN field**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8ab3002d00c86fda5802a7546d722b62fc3bcfc2", "_cell_guid": "f940ba4b-0381-4662-8c2d-ad2c4684dd14"}, "outputs": [], "execution_count": null, "source": ["x_test = test_df['comment_text'].fillna('comment_missing').values\n", "print(x_test)"], "cell_type": "code"}, {"metadata": {"_uuid": "f3b50a49e1a5dbf25ce0cb182db3da60a9db85d9", "_cell_guid": "3072aca7-6fd9-4da3-8561-730b9b6b1706"}, "source": ["**Tokenizing and padding similar to what we did before to training data**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "6c2b27f7d2c0c1f6158b52b965479f1e257a3afc", "_cell_guid": "67e8eb4e-7457-4649-9513-411794e55ada"}, "outputs": [], "execution_count": null, "source": ["x_test_tokenized = x_tokenizer.texts_to_sequences(x_test)\n", "x_testing = sequence.pad_sequences(x_test_tokenized, maxlen=max_text_length)"], "cell_type": "code"}, {"metadata": {"_uuid": "cadb4f9b8a646599eca8d107a2416214b49442ee", "_cell_guid": "5ca42dea-b68c-4e31-a3f9-99e415ddc3be"}, "source": ["**Time to predict!**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "d323d8503236d4cf01a3253f6639445ec9735ee9", "_cell_guid": "d1cc833e-46f4-46bf-bbe0-0a39ef80ff5d"}, "outputs": [], "execution_count": null, "source": ["y_testing = model.predict(x_testing, verbose = 1)"], "cell_type": "code"}, {"metadata": {"_uuid": "e3ec631b8e942bb6a3dd843f40d42241f1373308", "_cell_guid": "e25db199-5b05-455f-8e87-b2fd4b7265a0"}, "source": ["**Submit predictions!**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "d87c22acba7dda6524eba4b7fdc6c915b8301174", "collapsed": true, "_cell_guid": "612d0744-ec1c-40bc-bed6-5028f9936ac6"}, "outputs": [], "execution_count": null, "source": ["sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n", "sample_submission[list_of_classes] = y_testing\n", "sample_submission.to_csv(\"toxic_comment_classification.csv\", index=False)"], "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1}