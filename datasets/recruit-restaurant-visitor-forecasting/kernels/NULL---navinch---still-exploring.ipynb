{"cells": [{"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "45aaf873-4fd6-4411-8218-77fa16c785a8", "_uuid": "00cb987589cece4b5aab4280adb579b739951edb"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "\n", "%matplotlib inline\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "244e387a-4e25-4ad8-9048-705e97557edd", "collapsed": true, "_uuid": "7be5af55f8997f716c1f9ed349a5f5233f9b569c"}, "source": ["ar = pd.read_csv('../input/air_reserve.csv')\n", "asi = pd.read_csv('../input/air_store_info.csv')\n", "avd = pd.read_csv('../input/air_visit_data.csv')\n", "di = pd.read_csv('../input/date_info.csv')\n", "hr = pd.read_csv('../input/hpg_reserve.csv')\n", "hsi = pd.read_csv('../input/hpg_store_info.csv')\n", "sid = pd.read_csv('../input/store_id_relation.csv')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "1b826f99-fa66-420e-8b51-98d8bf9cf764", "collapsed": true, "_uuid": "2a218d10cfca5f920a94c02731889d01808a21e6"}, "source": ["#air_8093d0b565e9dbdf hpg_874415e6e7ccfe13"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "08f09c13-9634-478d-b0a4-64a291611096", "collapsed": true, "_uuid": "0d06e327d7df264fdbd4a8f77bc9aa453b6b2886"}, "source": ["store = avd[avd['air_store_id'] == 'air_8093d0b565e9dbdf']\n", "store = store.merge(di, left_on='visit_date', right_on='calendar_date')\n", "store.drop(['calendar_date', 'day_of_week', 'air_store_id'], axis=1, inplace=True)\n", "store.set_index('visit_date', inplace=True)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["store.head()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_cell_guid": "b6413ac4-97ec-4d33-a4a7-8ac6eefc7def", "collapsed": true, "_uuid": "65d23dbd3fa2f2f066ebc2838c3e421f8e7e70de"}, "source": ["def rmsle(y, y_pred):\n", "    assert len(y) == len(y_pred)\n", "    to_sum = [(math.log(pred + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n", "    return (sum(to_sum) * (1.0/len(y))) ** 0.5"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["import math\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import LSTM\n", "from sklearn.preprocessing import MinMaxScaler\n", "from sklearn.metrics import mean_squared_error\n", "# convert an array of values into a dataset matrix\n", "def create_dataset(dataset, look_back=1):\n", "    dataX, dataY = [], []\n", "    for i in range(len(dataset)-look_back-1):\n", "        a = dataset[i:(i+look_back), 0]\n", "        dataX.append(a)\n", "        dataY.append(dataset[i + look_back, 0])\n", "    return np.array(dataX), np.array(dataY)\n", "# fix random seed for reproducibility\n", "np.random.seed(7)\n", "# load the dataset\n", "dataset = store['visitors'].values\n", "dataset = dataset.astype('int32')\n", "# normalize the dataset\n", "scaler = MinMaxScaler(feature_range=(0, 1))\n", "dataset = scaler.fit_transform(dataset.reshape(-1, 1))\n", "# split into train and test sets\n", "train_size = int(len(dataset) * 0.8)\n", "test_size = len(dataset) - train_size\n", "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n", "# reshape into X=t and Y=t+1\n", "look_back = 7\n", "trainX, trainY = create_dataset(train, look_back)\n", "testX, testY = create_dataset(test, look_back)\n", "# reshape input to be [samples, time steps, features]\n", "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n", "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n", "# create and fit the LSTM network\n", "model = Sequential()\n", "model.add(LSTM(100, input_shape=(1, look_back)))\n", "model.add(Dense(7))\n", "model.add(Dense(1))\n", "model.compile(loss='mean_squared_error', optimizer='adam')\n", "model.fit(trainX, trainY, epochs=15, batch_size=1, verbose=2)\n", "# make predictions\n", "trainPredict = model.predict(trainX)\n", "testPredict = model.predict(testX)\n", "# invert predictions\n", "trainPredict = scaler.inverse_transform(trainPredict)\n", "trainY = scaler.inverse_transform([trainY])\n", "testPredict = scaler.inverse_transform(testPredict)\n", "testY = scaler.inverse_transform([testY])\n", "# calculate root mean squared error\n", "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n", "print('Train Score: %.2f RMSE' % (trainScore))\n", "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n", "print('Test Score: %.2f RMSE' % (testScore))\n", "# shift train predictions for plotting\n", "trainPredictPlot = np.empty_like(dataset)\n", "trainPredictPlot[:, :] = np.nan\n", "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n", "# shift test predictions for plotting\n", "testPredictPlot = np.empty_like(dataset)\n", "testPredictPlot[:, :] = np.nan\n", "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n", "# plot baseline and predictions\n", "plt.plot(scaler.inverse_transform(dataset))\n", "plt.plot(trainPredictPlot)\n", "plt.plot(testPredictPlot)\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["ratios = [x/y for x,y in zip(testPredict, testY)]"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["plt.plot(ratios[0])\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["ones = [x for x in ratios[0] if (x>0.6) & (x<1.3)]\n", "len(ones)/len(ratios[0])"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["rmsle(testY.T, testPredict)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": []}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": []}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1}