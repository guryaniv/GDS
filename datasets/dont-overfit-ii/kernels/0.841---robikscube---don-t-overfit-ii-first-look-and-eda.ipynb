{"cells":[{"metadata":{"_uuid":"903c1d057528f23bd85af533ca91fa1f1aa894ec"},"cell_type":"markdown","source":"# First Look of the Don't Overfit II Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport random\nimport os, sys\n\nimport warnings\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\n!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read in datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nss = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9a016f87540ec0649c7104059b8b138f3c271d5"},"cell_type":"code","source":"print('Train shape {}'.format(train.shape))\nprint('Test shape {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b03a7fd5bd23bbe243b5e7d2741d712676b9914"},"cell_type":"code","source":"train.groupby('target').count()['id'].plot(kind='barh', title='Target Distribution', figsize=(15, 5))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ec9b821d98ad28ca4842f4614f7766a49a05b15"},"cell_type":"markdown","source":"## 64-36 split of target in training set - will that hold true for test set?"},{"metadata":{"trusted":true,"_uuid":"c8175a42091b334fe09ca55373bc4176df4f758e"},"cell_type":"code","source":"train['target'].mean() * 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc088afaeb6943ddb8132dab4b387288cb9d1fec"},"cell_type":"markdown","source":"# Plot distribution of features in train vs test\n- Picked 5 random features\n- There are a lot of features (300)"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"2da11499b88c2b262edd73b309ce177533a70e12"},"cell_type":"code","source":"random.seed(5)\nfor x in range(0, 5):\n    random_feature = random.randint(1,299)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15 ,3))\n    train[str(random_feature)].plot(kind='hist', ax=ax1, bins=20, title='Feature {}: Train set'.format(random_feature))\n    test[str(random_feature)].plot(kind='hist', ax=ax2, bins=20, title='Feature {}: Test set'.format(random_feature))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf66ec58caad00cac664b2ddeb70e51f769609c1"},"cell_type":"markdown","source":"# See correlation between first 4 features and target"},{"metadata":{"trusted":true,"_uuid":"cc347535aac353316c1f088374535652bdee9b43"},"cell_type":"code","source":"sns.pairplot(train, vars=['target', '0','1','2','3','4'], hue='target')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b016f3be69ea4e2ed373994c8d570e501dd520a6"},"cell_type":"markdown","source":"# Walkthrough of SKlearn Classification Algs (Not worrying about overfitting yet)\n- Lets not worry about overfitting yet and try out some classification algs"},{"metadata":{"trusted":true,"_uuid":"0307baecf38667ed592da0909fd3e25e20ebb0b0"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\n\ntrain_X = train.drop(['id','target'], axis=1).as_matrix()\ntrain_y = train['target'].values\ntest_X = test.drop(['id'], axis=1).as_matrix()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f1975810af567ee106288299bae45f75a0f877e"},"cell_type":"markdown","source":"## KNeighborsClassifier - Public LB 0.549"},{"metadata":{"trusted":true,"_uuid":"c03d1b0e20bcf02c6bf595e648b89d4757ec6848"},"cell_type":"code","source":"clf = KNeighborsClassifier(n_neighbors=5)\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_KNeighborsClassifier.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"384ed104bb23dafe5f8f30a80fa3b91114ab9df7"},"cell_type":"markdown","source":"## DecisionTreeClassifier - Public LB 0.558"},{"metadata":{"trusted":true,"_uuid":"a647461b04cd648b3a82c500af4c5277590abcde"},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(train_X, train_y)\n# Delete the old prediction\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_DecisionTreeClassifier.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13914c6ca634142d434720488883fe0b5b8fb47c"},"cell_type":"markdown","source":"## RandomForestClassifier - Public LB 0.574"},{"metadata":{"trusted":true,"_uuid":"0a9adca451077b791b1dbc7fd66dd8cd2df40b86"},"cell_type":"code","source":"clf = RandomForestClassifier()\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_RandomForestClassifier.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04f7a4b7f7d0ee81f9d0e91c2aa3beac9aca072f"},"cell_type":"markdown","source":"## AdaBoostClassifier - Public LB 0.638"},{"metadata":{"trusted":true,"_uuid":"a46cb95641f0fc5689a42a594b5a3726ad35717f"},"cell_type":"code","source":"clf = AdaBoostClassifier()\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_AdaBoostClassifier.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"719e842be690bab0894d32fe2db169f34f66505f"},"cell_type":"markdown","source":"## Naive Bayes - Public LB 0.611"},{"metadata":{"trusted":true,"_uuid":"be57664af4a3e1817b195456ca71b563f7417372"},"cell_type":"code","source":"clf = GaussianNB()\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_GaussianNB.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56526ca9760217abd6a8b39cf99ee12544d9c820"},"cell_type":"markdown","source":"## XGBoost - Public LB ???"},{"metadata":{"trusted":true,"_uuid":"71afa59a555a9d5c6d7260ce360141bd9826d86c"},"cell_type":"code","source":"import xgboost as xgb\nclf = xgb.XGBClassifier()\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_XGBClassifier.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58ab455117ee4829f443bdb146ac399da66ae6b0"},"cell_type":"markdown","source":"## Logistic Regression - Public LB ???"},{"metadata":{"trusted":true,"_uuid":"6f66f001c965e0d8bc30467f9f91d015f3c70bf7"},"cell_type":"code","source":"clf = LogisticRegression(class_weight='balanced', penalty='l1', C=1.0, solver='liblinear')\nclf.fit(train_X, train_y)\ntest['target'] = clf.predict(test_X)\ntest[['id','target']].to_csv('submission_LogisticRegression.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d20cd54d8702fa5a785d8901f7d1610039b1302"},"cell_type":"markdown","source":"# Cross Validation\nNow lets use some cross validation techniques to validate our scores for each model type. Cross validation allows us to train multiple models on the training data by splitting differently each time it trains the model."},{"metadata":{"trusted":true,"_uuid":"d696b40bd0f63b9734b64b132e02c638a1a6757a"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import ShuffleSplit\n\nfor model_type in [KNeighborsClassifier, DecisionTreeClassifier, RandomForestClassifier,\n                   AdaBoostClassifier, xgb.XGBClassifier, LogisticRegression]:\n    clf = model_type()\n    kfold = KFold(n_splits=5, shuffle=True)\n    cv = ShuffleSplit(n_splits=100, test_size=0.3, random_state=0)\n    scores = cross_val_score(clf, train_X, train_y, cv=cv, scoring='roc_auc')\n    print(\"Print {} Accuracy: {} (+/- {})\".format(model_type.__name__, scores.mean(), scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29743f2ac154b7346e2236535c62bb67ac465f06"},"cell_type":"markdown","source":"# Parameter Tuning using RandomizedSearchCV\n- Next we want to do some parameter tuning on our best model."},{"metadata":{"trusted":true,"_uuid":"5ab6c77606073fb36a70d531e193135f26331beb"},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\n\nclf = LogisticRegression(class_weight='balanced', solver='liblinear')\n\n# Search through these optino\npenalty = ['l1', 'l2']\nC = uniform(loc=0, scale=4)\nhyperparameters = dict(C=C, penalty=penalty)\n\nrand_cv = RandomizedSearchCV(clf, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1, scoring='roc_auc')\nbest_model = rand_cv.fit(train_X, train_y)\n\nprint('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_model.best_estimator_.get_params()['C'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"372ecdd1bf6523a2fc6e76db328675472cc22f93"},"cell_type":"code","source":"cv_results = pd.DataFrame()\ncv_results['params'] = best_model.cv_results_['params']\ncv_results['mean_test_score'] = best_model.cv_results_['mean_test_score']\ncv_results['std_test_score'] = best_model.cv_results_['std_test_score']\ncv_results['rank_test_score'] = best_model.cv_results_['rank_test_score']\ncv_results = pd.concat([cv_results.drop('params', axis=1), pd.DataFrame(cv_results['params'].tolist())], axis=1)\ncv_results.sort_values('rank_test_score').head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c5eb3180521d275a5a1e80520b85dcdd75192e4"},"cell_type":"code","source":"cv_results['penalty_color'] = cv_results.apply(lambda x: 1 if x['penalty'] == 'l1' else 0, axis=1)\ncv_results[['mean_test_score','C']].plot.scatter(x='mean_test_score', y='C', c=cv_results['penalty_color'], colormap='viridis')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91681641ff74851b05fdb27b9b9a40c9645fb358"},"cell_type":"markdown","source":"## Focused Gridsearch\n- Use only l1\n- Smaller C values"},{"metadata":{"trusted":true,"_uuid":"9e7a3b820fe49768d5639efde29f432635214b3b"},"cell_type":"code","source":"# Search through these optino\nC = [0.001, 0.01, 0.02, 0.05, 0.1, 0.12, 0.13, 0.15, 0.16, 0.17, 0.178, 0.179, 0.175, 0.2, 0.3]\nhyperparameters = dict(C=C)\n\nclf = LogisticRegression(solver='liblinear', class_weight='balanced', penalty='l1')\nrand_cv = RandomizedSearchCV(clf, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1, scoring='roc_auc')\nbest_model = rand_cv.fit(train_X, train_y)\n\nprint('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\nprint('Best C:', best_model.best_estimator_.get_params()['C'])\nprint('Best Score: {}'.format(best_model.best_score_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb4802c1c2b0f6861a2659d7bda1956a2a7376e2"},"cell_type":"code","source":"test['target'] = best_model.predict(test_X)\ntest[['id','target']].to_csv('submission_LogisticRegression_randomCV.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97e121e764cda321c63decb136979d8bea5eb9be"},"cell_type":"code","source":"# Use predict proba\ntest['target'] = best_model.predict_proba(test_X)[:,1]\ntest[['id','target']].to_csv('submission_LogisticRegression_randomCV_proba.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e123f789baab9fdb8ed1a250f37a75d9830b32c6"},"cell_type":"markdown","source":"# XGBClassifier with RandomizedSearchCV"},{"metadata":{"trusted":true,"_uuid":"657192c92bad28f60861761ed6f5d165e0eb1045"},"cell_type":"code","source":"clf = xgb.XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic')\n# A parameter grid for XGBoost\nparams = {\n        'min_child_weight': [1, 5, 10],\n        'gamma': [0.5, 1, 1.5, 2, 5],\n        'subsample': [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.6, 0.8, 1.0],\n        'max_depth': [3, 4, 5]\n        }\nrand_cv = RandomizedSearchCV(clf, params, random_state=1, n_iter=20, cv=5, verbose=0, n_jobs=-1, scoring='roc_auc')\nbest_model = rand_cv.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03583f34dec370f56d428a77831b7d6ba3f8b507"},"cell_type":"code","source":"best_model.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1af03de07a7ef493e66bb5175bd9a8a1c6e9e7d7"},"cell_type":"code","source":"test['target'] = best_model.predict(test_X)\ntest[['id','target']].to_csv('submission_XGBClassifier_randomCV.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column\n\n# Use predict proba\ntest['target'] = best_model.predict_proba(test_X)[:,1]\ntest[['id','target']].to_csv('submission_XGBClassifier_randomCV_proba.csv', index=False)\ntest = test.drop('target', axis=1) # drop the target column","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad9b11480bd91187d2369e9339f6f992d3f14ea5"},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"0188c60b20878f07a56aed1241944ed283a219bb"},"cell_type":"code","source":"clf = LogisticRegression(class_weight='balanced', penalty='l1', C=0.01, solver='liblinear').fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d51060542036d84e2849579ba97930b6a22e5c9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}