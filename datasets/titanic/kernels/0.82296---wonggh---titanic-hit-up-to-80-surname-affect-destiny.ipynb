{"cells":[{"metadata":{"trusted":true,"_uuid":"e174a1e4251e8a8fe22b514bd0e18dae87fc0f45"},"cell_type":"code","source":"#Trying to follow the concept of these 2 article, and more\n#https://towardsdatascience.com/predicting-the-survival-of-titanic-passengers-30870ccc7e8\n#https://www.kaggle.com/mohamedtimor/titanic-dataset\n\nimport numpy as np\nimport pandas as pd \n\n# data visualization\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom matplotlib import style\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23db5eec0fa2d58181ff8c6d3455053bd7b1f18c"},"cell_type":"code","source":"#get data\ntrain_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n\n#merge train & test data to perform data exploration and transformation \ndf = pd.concat([train_df, test_df] , sort = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64fab8255daab0492fee957435f53b19bd18cc52"},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Data Exploration/Analysis\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea4f5576302f58b169d9fe0e5e69789cb51ce82a"},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f7a79bd3590087ab0438bd34884777be47f941"},"cell_type":"code","source":"df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c4ff4308517d8e29caec58cb6db9e55d3eb9d68"},"cell_type":"code","source":"#check in details what data actuall missing\ntotal = df.isnull().sum().sort_values(ascending=False)\npercent_1 = df.isnull().sum()/df.isnull().count()*100\npercent_2 = (round(percent_1, 1)).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\ndisplay(missing_data.head(5))\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"51e531f1a696a8b5b1d7a9f89f9f0b9a740bc80b"},"cell_type":"code","source":"# Check the correlation for the current numeric feature set.\nprint(df[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr())\nsns.heatmap(df[['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']].corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb56e929e3795c5b9669d6f2e280178c93d5b25"},"cell_type":"code","source":"df.columns.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1cfccff0ca7c2e7d9d18d5a876eb2a19326b6de"},"cell_type":"markdown","source":"# 1. Age and Sex:\n"},{"metadata":{"trusted":true,"_uuid":"d84c409b4ccd3905832542fe82bb5b5f27ad7315"},"cell_type":"code","source":"#Train set evaluate\nsurvived = 'survived'\nnot_survived = 'not survived'\nfig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\nwomen = train_df[train_df['Sex']=='female']\nmen = train_df[train_df['Sex']=='male']\nax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\nax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\nax.legend()\nax.set_title('Female')\nax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\nax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\nax.legend()\n_ = ax.set_title('Male')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c340a114e3b431c5b086118f205fd734c9515e33"},"cell_type":"markdown","source":"# 3. Embarked, Pclass and Sex:"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"09a47d2928065035700ad0cd48e0c83392245870"},"cell_type":"code","source":"FacetGrid = sns.FacetGrid(train_df, row='Embarked', size=4.5, aspect=1.6)\nFacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\nFacetGrid.add_legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"faeaca21c7ac4ad3ee16914de5b2994587e9faed"},"cell_type":"markdown","source":"# 4. Pclass:\n"},{"metadata":{"trusted":true,"_uuid":"95f100aa6453e8b33d1066d8c46e66478baa96d3"},"cell_type":"code","source":"sns.barplot(x='Pclass', y='Survived', data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e975294e32cd3d97b820cda50ca0fb457172e261"},"cell_type":"code","source":"grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a59ba7b79d183db9f79f89a39db53e4cc79a0026"},"cell_type":"markdown","source":"# 5. SibSp and Parch:"},{"metadata":{"trusted":true,"_uuid":"6a65acb249e4daf19e471b5db4fc50e4df0041dd"},"cell_type":"code","source":"train_df['relatives'] = train_df['SibSp'] + train_df['Parch']\naxes = sns.factorplot('relatives','Survived', \n                      data=train_df, aspect = 2.5, )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f7602f9d29cebd165b94e6f1861e78780c5319c"},"cell_type":"markdown","source":"# 6. Title"},{"metadata":{"trusted":true,"_uuid":"726e8e691ec3aa056aad7121f8500bf123727d0e"},"cell_type":"code","source":"titles = set()\nfor name in df['Name']:\n    titles.add(name.split(',')[1].split('.')[0].strip())\nprint(titles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbd4a7f269a8ac1e7977ff05fd7a4848fd0a9a89"},"cell_type":"code","source":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Dona\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6df8c09b40e641a918aa176b1251822c90aa235"},"cell_type":"markdown","source":"# 7. Sur name - this quite interesting, does name affect your destiny??"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9769fff7094bc0d5adf6ebc7883db52e813e00ba"},"cell_type":"code","source":"#sur checking\nsur = set()\nfor name in df['Name']:\n    sur.add(name.split(' ')[0].replace(' ','').replace(',','').lower())\nprint(sur)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53f417c399a39c8efd81745087ed27b262d551f5"},"cell_type":"markdown","source":"# Data Preprocessing\n"},{"metadata":{"_uuid":"ad75b6a30d09c8103367a4d16a70fb78a5675f20"},"cell_type":"markdown","source":"## Title"},{"metadata":{"trusted":true,"_uuid":"591310e17e7e909d9bcd883012122db324b7a745"},"cell_type":"code","source":"def get_titles():\n    # we extract the title from each name\n    df['Title'] = df['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated title\n    # we map each title\n    df['Title'] = df.Title.map(Title_Dictionary)\n    return df\n\ndf = get_titles()\n\ndf['Title'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b289b3065c8545481b262006f57dfe25204bcd2"},"cell_type":"markdown","source":"# Sur name"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3945ccced525ffb6c08ac8d42c6889b15eba934b"},"cell_type":"code","source":"def get_sur():\n    df['sur'] = df['Name'].map(lambda name:name.split(' ')[0].replace(' ','').replace(',','').lower())\n    return df\n\ndf = get_sur()\ndf['sur'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"816ac7e74ec3c9f084e53dc2a6630403143932d7"},"cell_type":"markdown","source":"# Missing Data: - Age (263), Cabin (1014), Embarked (2), Fare(1)\n"},{"metadata":{"_uuid":"fb553830560443a4702a81bd65419048494d5ff3"},"cell_type":"markdown","source":"## Age: (263)"},{"metadata":{"trusted":true,"_uuid":"7642180714e907339f9ce1268c735c8188c63a39"},"cell_type":"code","source":"print(\"Train- Missing Age\")\nprint(train_df.iloc[:891].Age.isnull().sum())\n\nprint(\"Test- Missing Age\")\nprint(test_df.iloc[:891].Age.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb5583f77f54ad9a0b5d9ed890f65a6308ef8cad"},"cell_type":"code","source":"grouped_train = df.groupby(['Sex','Pclass','Title'])\ngrouped_median_train = grouped_train.median()\ngrouped_median_train = grouped_median_train.reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\ngrouped_median_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ffbb8d597e898d11cbdf147709b133d2a2bc9dc"},"cell_type":"code","source":"def fill_age(row):\n    condition = (\n        (grouped_median_train['Sex'] == row['Sex']) & \n        (grouped_median_train['Title'] == row['Title']) & \n        (grouped_median_train['Pclass'] == row['Pclass'])\n    ) \n    return grouped_median_train[condition]['Age'].values[0]\n\n\ndef process_age():\n    global df\n    # a function that fills the missing values of the Age variable\n    df['Age'] = df.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis=1)\n    return df\n\ndf = process_age()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6aed265027401e28fbcb1b1ab9f6668607e0325"},"cell_type":"markdown","source":"### dummies for title"},{"metadata":{"trusted":true,"_uuid":"205de0e546638da3d86542796826c343e3a5f05b","scrolled":true},"cell_type":"code","source":"#make dummies for title \ndef process_names():\n    global df\n    # we clean the Name variable\n    df.drop('Name', axis=1, inplace=True)\n    \n    # encoding in dummy variable\n    titles_dummies = pd.get_dummies(df['Title'], prefix='Title')\n    df = pd.concat([df, titles_dummies], axis=1)\n    \n    # removing the title variable\n    df.drop('Title', axis=1, inplace=True)\n    \n    return df\n\ndf = process_names()\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b62f8c0112866672bb89e376714915172840993"},"cell_type":"markdown","source":"# dummies for sur name"},{"metadata":{"trusted":true,"_uuid":"39818b0005a93012e7ba95b93b414c2ee5c81ba6"},"cell_type":"code","source":"#make dummies for sur \ndef process_sur():\n    global df\n    \n    # encoding in dummy variable\n    sur_dummies = pd.get_dummies(df['sur'], prefix='sur')\n    df = pd.concat([df, sur_dummies], axis=1)\n    \n    # removing the title variable\n    df.drop('sur', axis=1, inplace=True)\n    \n    return df\n\ndf = process_sur()\ndf.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5114171593e2ffa47c76df5fb95a46ff98c9d2cd"},"cell_type":"markdown","source":"# Cabin: (1014)\n\n### First thought, we have to delete the ‘Cabin’ variable but then I found something interesting. A cabin number looks like ‘C123’ and the letter refers to the deck. Therefore we’re going to extract these and create a new feature, that contains a persons deck. Afterwords we will convert the feature into a numeric variable. The missing values will be converted to zero. In the picture below you can see the actual decks of the titanic, ranging from A to G."},{"metadata":{"trusted":true,"_uuid":"a126a9990753283cd210d5c110d1c78f441a7efa"},"cell_type":"code","source":"print(\"Train- Missing Cabin\")\nprint(train_df.iloc[:891].Cabin.isnull().sum())\n\nprint(\"Test- Missing Cabin\")\nprint(test_df.iloc[:891].Cabin.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa6e7cf610400222e61ba66d3f2c2b3410d9beef"},"cell_type":"code","source":"train_cabin, test_cabin = set(), set()\n\nfor c in df.iloc[:891]['Cabin']:\n    try:\n        train_cabin.add(c[0])\n    except:\n        train_cabin.add('U') # replaces NaN values with U (for Unknow)\n        \nfor c in df.iloc[891:]['Cabin']:\n    try:\n        test_cabin.add(c[0])\n    except:\n        test_cabin.add('U') \n\nprint(\"train_cabin -> \" +str(train_cabin))\n\nprint(\"test_cabin -> \" +str(test_cabin))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12017b2590c8d6b96f6305c2549f80c34e6fb027"},"cell_type":"code","source":"#don't have any cabin letter in the test set that is not present in the train set.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cab6ef19973a658e8ba7f553bbadd369d047c459"},"cell_type":"code","source":"def process_cabin():\n    global df    \n    # replacing missing cabins with U (for Uknown)\n    df.Cabin.fillna('U', inplace=True)\n    \n    # mapping each Cabin value with the cabin letter\n    df['Cabin'] = df['Cabin'].map(lambda c: c[0])\n    \n    # dummy encoding ...\n    cabin_dummies = pd.get_dummies(df['Cabin'], prefix='Cabin')    \n    df = pd.concat([df, cabin_dummies], axis=1)\n\n    df.drop('Cabin', axis=1, inplace=True)\n    return df\n\ndf = process_cabin()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c30292a1ee2a7db743ccc592576717a898c74529"},"cell_type":"markdown","source":"# Embarked: (2)"},{"metadata":{"trusted":true,"_uuid":"bacd9fca5cc45c5e05af91581b6259be03527248"},"cell_type":"code","source":"df['Embarked'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daf543099cc6af4b6b0d634c5a4cee3bb92fbb76"},"cell_type":"code","source":"common_value = 'S'\ndf['Embarked'] = df['Embarked'].fillna(common_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fbefaab89244e6a007364d0a8e10668aaf4d78b9"},"cell_type":"code","source":"def process_embarked():\n    global df\n    # two missing embarked values - filling them with the most frequent one in the train  set(S)\n    df.Embarked.fillna('S', inplace=True)\n    # dummy encoding \n    embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked')\n    df = pd.concat([df, embarked_dummies], axis=1)\n    df.drop('Embarked', axis=1, inplace=True)\n    return df\n\ndf = process_embarked()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e09fedd4126131321c64b8e8076d6203f6bf402f"},"cell_type":"markdown","source":"# Fare: (1)"},{"metadata":{"trusted":true,"_uuid":"15cb90880d9d626621a0403a88659c43b354e09a"},"cell_type":"code","source":"df['Fare'] = df['Fare'].fillna(df.Fare.mean())\ndf['Fare'] = df['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d420b607cbfb0cb8774dcfb385206f6ea9e35f8"},"cell_type":"markdown","source":"# ~Missing value settled~\n"},{"metadata":{"_uuid":"1cff5d3134e2ebba6d6181bf59ab44678393f5d3"},"cell_type":"markdown","source":"# Sex:"},{"metadata":{"trusted":true,"_uuid":"a76c19b830fddab6766cacbe52739279198a58fd"},"cell_type":"code","source":"def process_sex():\n    global df\n    # mapping string values to numerical one \n    df['Sex'] = df['Sex'].map({'male':1, 'female':0})\n    return df\n\ndf = process_sex()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd4e114c2f40ecf5600b7dae6f9334bb6cf84e68"},"cell_type":"markdown","source":"# Pclass"},{"metadata":{"trusted":true,"_uuid":"3d16aedbdcca0900f0deb5d03338f93a7deb1dd5"},"cell_type":"code","source":"def process_pclass():\n    \n    global df\n    # encoding into 3 categories:\n    pclass_dummies = pd.get_dummies(df['Pclass'], prefix=\"Pclass\")\n    \n    # adding dummy variable\n    df = pd.concat([df, pclass_dummies],axis=1)\n    \n    # removing \"Pclass\"\n    df.drop('Pclass',axis=1,inplace=True)\n    return df\n\ncombined = process_pclass()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"04ccc36a3bfec42577a813826155e0a041a24279"},"cell_type":"markdown","source":"# Ticket:\ncheck how many variance of ticket in dataset"},{"metadata":{"trusted":true,"_uuid":"d6263c40be425cc687566fe41fa6d13a032bef94"},"cell_type":"code","source":"def cleanTicket(ticket):\n    ticket = ticket.replace('.', '')\n    ticket = ticket.replace('/', '')\n    ticket = ticket.split()\n    ticket = map(lambda t : t.strip(), ticket)\n    ticket = list(filter(lambda t : not t.isdigit(), ticket))\n    if len(ticket) > 0:\n        return ticket[0]\n    else: \n        return 'XXX'\n\ntickets = set()\nfor t in df['Ticket']:\n    tickets.add(cleanTicket(t))\n    \nprint(len(tickets))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f05632251a0d96e0f489fdb833c20fe1545f60b"},"cell_type":"code","source":"def process_ticket():\n    \n    global df\n    \n    # a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n    def cleanTicket(ticket):\n        ticket = ticket.replace('.','')\n        ticket = ticket.replace('/','')\n        ticket = ticket.split()\n        ticket = map(lambda t : t.strip(), ticket)\n        ticket = list(filter(lambda t : not t.isdigit(), ticket))\n        \n        if len(ticket) > 0:\n            return ticket[0]\n        else: \n            return 'XXX'\n    \n\n    # Extracting dummy variables from tickets:\n\n    df['Ticket'] = df['Ticket'].map(cleanTicket)\n    tickets_dummies = pd.get_dummies(df['Ticket'], prefix='Ticket')\n    df = pd.concat([df, tickets_dummies], axis=1)\n    df.drop('Ticket', inplace=True, axis=1)\n    return df\n\ndf = process_ticket()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c0d0d3ad8c3ec4a973a90c8e1d09a45a1f74bc0"},"cell_type":"code","source":"df.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85b6d931176028fb07d061ee088921cc18022d46"},"cell_type":"markdown","source":"# Family:\nFamilySize : the total number of relatives including the passenger (him/her)self.\n\nSigleton : a boolean variable that describes families of size = 1 \\n\n\nSmallFamily : a boolean variable that describes families of 2 <= size <= 4 \\n\n\nLargeFamily : a boolean variable that describes families of 5 < size"},{"metadata":{"trusted":true,"_uuid":"f493fd1d26b211b000c554d8210e706984d5f78e"},"cell_type":"code","source":"def process_family():\n    \n    global df\n    # introducing a new feature : the size of families (including the passenger)\n    df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n\n    # introducing other features based on the family size\n    df['Singleton'] = df['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n    df['SmallFamily'] = df['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0)\n    df['LargeFamily'] = df['FamilySize'].map(lambda s: 1 if 5 <= s else 0)\n    return df\n\ndf = process_family()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18ec9bf3022e98f64731a7eca4d8b5ddcdd6e7ed"},"cell_type":"code","source":"def process_parch():\n    global df\n    \n    # dummy encoding \n    parch_dummies = pd.get_dummies(df['Parch'], prefix='Parch')\n    df = pd.concat([df, parch_dummies], axis=1)\n    df.drop('Parch', axis=1, inplace=True)\n    return df\n\ndf = process_parch()\n\ndef process_SibSp():\n    global df\n    \n    # dummy encoding \n    SibSp_dummies = pd.get_dummies(df['SibSp'], prefix='SibSp')\n    df = pd.concat([df, SibSp_dummies], axis=1)\n    df.drop('SibSp', axis=1, inplace=True)\n    return df\n\ndf = process_SibSp()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb4c4da720b1475eeb44c664d5bd79729b2e2e2f"},"cell_type":"markdown","source":"# Creating Categories:\n\n## Age:"},{"metadata":{"trusted":true,"_uuid":"edffeedc1a977937cf95eb88cec41246b0759229"},"cell_type":"code","source":"df['Age'] = df['Age'].astype(int)\ndf.loc[ df['Age'] <= 11, 'Age'] = 0\ndf.loc[(df['Age'] > 11) & (df['Age'] <= 18), 'Age'] = 1\ndf.loc[(df['Age'] > 18) & (df['Age'] <= 22), 'Age'] = 2\ndf.loc[(df['Age'] > 22) & (df['Age'] <= 27), 'Age'] = 3\ndf.loc[(df['Age'] > 27) & (df['Age'] <= 33), 'Age'] = 4\ndf.loc[(df['Age'] > 33) & (df['Age'] <= 40), 'Age'] = 5\ndf.loc[(df['Age'] > 40) & (df['Age'] <= 66), 'Age'] = 6\ndf.loc[ df['Age'] > 66, 'Age'] = 6\n\n# let's see how it's distributed \ndf['Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c54cd9f6ff08ed9bee94ba4c365b3a9b0fd9b09"},"cell_type":"code","source":"def process_age():\n    global df\n    \n    # dummy encoding \n    embarked_dummies = pd.get_dummies(df['Age'], prefix='Age')\n    df = pd.concat([df, embarked_dummies], axis=1)\n    df.drop('Age', axis=1, inplace=True)\n    return df\n\ndf = process_age()\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5075e0db0bbf7a74d1a1113f5e117d9215736ee4"},"cell_type":"markdown","source":"# Fare:"},{"metadata":{"trusted":true,"_uuid":"6598b2a0a0c85282454d4082ced426193820f14e"},"cell_type":"code","source":"df['Fare'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29e3d2f4addb58fd16216a3ac8377f4e0bf7a9e1"},"cell_type":"code","source":"df.loc[ df['Fare'] <= 7.91, 'Fare'] = 0\ndf.loc[(df['Fare'] > 7.91) & (df['Fare'] <= 14.454), 'Fare'] = 1\ndf.loc[(df['Fare'] > 14.454) & (df['Fare'] <= 31), 'Fare']   = 2\ndf.loc[(df['Fare'] > 31) & (df['Fare'] <= 99), 'Fare']   = 3\ndf.loc[(df['Fare'] > 99) & (df['Fare'] <= 250), 'Fare']   = 4\ndf.loc[ df['Fare'] > 250, 'Fare'] = 5\ndf['Fare'] = df['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50e16985e65269788c2b80584f27f8e41eb3b694"},"cell_type":"code","source":"def process_fare():\n    global df\n    \n    # dummy encoding \n    embarked_dummies = pd.get_dummies(df['Fare'], prefix='Fare')\n    df = pd.concat([df, embarked_dummies], axis=1)\n    df.drop('Fare', axis=1, inplace=True)\n    return df\n\ndf = process_fare()\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73666f7bf708196a59069b32d5a2ec8bdddcc611"},"cell_type":"markdown","source":"# Done data preprocessing\n"},{"metadata":{"trusted":true,"_uuid":"fa444b46357e659597254342aa68818ae0ff107f"},"cell_type":"code","source":"print(df.sample(3))\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44827db5a2eb1068814b4a85b2f250228bf61d80"},"cell_type":"markdown","source":"# Building Machine Learning Models"},{"metadata":{"trusted":true,"_uuid":"26846d2f3051c4bcba9318151ea777046c1fbf96"},"cell_type":"code","source":"df.drop(['PassengerId'], 1, inplace=True)\nfeature_train_df = df.iloc[:891].copy()\ndf.drop(['Survived'], 1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"311bc27155c3c98c7f53a0131f984cade5aab1dd"},"cell_type":"code","source":"def recover_train_test_target():\n    global df\n    \n    passengerId = test_df['PassengerId']\n    targets = pd.read_csv('../input/train.csv', usecols=['Survived'])['Survived'].values\n    train = df.iloc[:891]\n    test = df.iloc[891:]\n    \n    return train, test, targets,passengerId\n\ntrain, test, targets, passengerId= recover_train_test_target()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6caeb5d8c447257d821809e701ceecaa3b8279d4"},"cell_type":"markdown","source":"## Feature selection - done in local computer with 10methods, select the best"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"cb13cb375adfdfb6768048ff5fa9a57d595a6b77"},"cell_type":"code","source":"param = ['Sex',\n 'Title_Master',\n 'Title_Miss',\n 'Title_Mr',\n 'Title_Mrs',\n 'Title_Officer',\n 'Title_Royalty',\n 'sur_abbott',\n 'sur_ahlin',\n 'sur_aks',\n 'sur_albimona',\n 'sur_ali',\n 'sur_allison',\n 'sur_andersen-jensen',\n 'sur_anderson',\n 'sur_andrew',\n 'sur_andrews',\n 'sur_angle',\n 'sur_appleton',\n 'sur_arnold-franchi',\n 'sur_artagaveytia',\n 'sur_asplund',\n 'sur_attalah',\n 'sur_ayoub',\n 'sur_backstrom',\n 'sur_baclini',\n 'sur_bailey',\n 'sur_banfield',\n 'sur_barah',\n 'sur_barbara',\n 'sur_barber',\n 'sur_barkworth',\n 'sur_bateman',\n 'sur_baumann',\n 'sur_baxter',\n 'sur_beane',\n 'sur_becker',\n 'sur_beckwith',\n 'sur_beesley',\n 'sur_behr',\n 'sur_berriman',\n 'sur_bidois',\n 'sur_bing',\n 'sur_bishop',\n 'sur_bjornstrom-steffansson',\n 'sur_blackwell',\n 'sur_blank',\n 'sur_bonnell',\n 'sur_boulos',\n 'sur_bourke',\n 'sur_bracken',\n 'sur_bradley',\n 'sur_braund',\n 'sur_brewe',\n 'sur_brown',\n 'sur_bryhl',\n 'sur_buss',\n 'sur_butler',\n 'sur_butt',\n 'sur_byles',\n 'sur_bystrom',\n 'sur_cacic',\n 'sur_cairns',\n 'sur_calderhead',\n 'sur_caldwell',\n 'sur_calic',\n 'sur_cameron',\n 'sur_campbell',\n 'sur_canavan',\n 'sur_caram',\n 'sur_carbines',\n 'sur_cardeza',\n 'sur_carlsson',\n 'sur_carr',\n 'sur_carrau',\n 'sur_cavendish',\n 'sur_chaffee',\n 'sur_chambers',\n 'sur_chapman',\n 'sur_chip',\n 'sur_christy',\n 'sur_clarke',\n 'sur_cleaver',\n 'sur_clifford',\n 'sur_cohen',\n 'sur_coleff',\n 'sur_collander',\n 'sur_colley',\n 'sur_connolly',\n 'sur_coutts',\n 'sur_crosby',\n 'sur_cunningham',\n 'sur_dahl',\n 'sur_dahlberg',\n 'sur_daly',\n 'sur_danbom',\n 'sur_daniel',\n 'sur_davidson',\n 'sur_davis',\n 'sur_davison',\n 'sur_de',\n 'sur_dean',\n 'sur_del',\n 'sur_devaney',\n 'sur_dick',\n 'sur_dodge',\n 'sur_doling',\n 'sur_dorking',\n 'sur_douglas',\n 'sur_dowdell',\n 'sur_downton',\n 'sur_drew',\n 'sur_duff',\n 'sur_duran',\n 'sur_eitemiller',\n 'sur_elias',\n 'sur_emanuel',\n 'sur_fahlstrom',\n 'sur_farthing',\n 'sur_faunthorpe',\n 'sur_flynn',\n 'sur_foo',\n 'sur_ford',\n 'sur_foreman',\n 'sur_fortune',\n 'sur_fox',\n 'sur_frauenthal',\n 'sur_frolicher-stehli',\n 'sur_frost',\n 'sur_fry',\n 'sur_funk',\n 'sur_futrelle',\n 'sur_fynney',\n 'sur_gale',\n 'sur_garside',\n 'sur_gaskell',\n 'sur_gavey',\n 'sur_gee',\n 'sur_giglio',\n 'sur_giles',\n 'sur_gill',\n 'sur_gillespie',\n 'sur_gilnagh',\n 'sur_givard',\n 'sur_glynn',\n 'sur_goldenberg',\n 'sur_goldschmidt',\n 'sur_goldsmith',\n 'sur_goodwin',\n 'sur_greenfield',\n 'sur_guggenheim',\n 'sur_gustafsson',\n 'sur_haas',\n 'sur_hagland',\n 'sur_hakkarainen',\n 'sur_hale',\n 'sur_hamalainen',\n 'sur_hansen',\n 'sur_harder',\n 'sur_harknett',\n 'sur_harper',\n 'sur_harrington',\n 'sur_harris',\n 'sur_harrison',\n 'sur_hart',\n 'sur_hassab',\n 'sur_hassan',\n 'sur_hawksford',\n 'sur_hays',\n 'sur_healy',\n 'sur_hedman',\n 'sur_hegarty',\n 'sur_heikkinen',\n 'sur_heininen',\n 'sur_henry',\n 'sur_herman',\n 'sur_hewlett',\n 'sur_hickman',\n 'sur_hirvonen',\n 'sur_hocking',\n 'sur_hold',\n 'sur_homer',\n 'sur_honkanen',\n 'sur_hood',\n 'sur_hosono',\n 'sur_hoyt',\n 'sur_hunt',\n 'sur_ilett',\n 'sur_ilmakangas',\n 'sur_isham',\n 'sur_jalsevac',\n 'sur_jansson',\n 'sur_jarvis',\n 'sur_jenkin',\n 'sur_jensen',\n 'sur_jermyn',\n 'sur_johannesen-bratthammer',\n 'sur_johansson',\n 'sur_johnson',\n 'sur_johnston',\n 'sur_jonsson',\n 'sur_jussila',\n 'sur_kallio',\n 'sur_karun',\n 'sur_kelly',\n 'sur_kent',\n 'sur_kimball',\n 'sur_kink-heilmann',\n 'sur_kirkland',\n 'sur_klaber',\n 'sur_knight',\n 'sur_kvillner',\n 'sur_lahtinen',\n 'sur_laitinen',\n 'sur_lam',\n 'sur_landergren',\n 'sur_lang',\n 'sur_larsson',\n 'sur_leader',\n 'sur_leeni',\n 'sur_lefebre',\n 'sur_lehmann',\n 'sur_leitch',\n 'sur_lemore',\n 'sur_lesurer',\n 'sur_levy',\n 'sur_lewy',\n 'sur_leyson',\n 'sur_lindahl',\n 'sur_lindblom',\n 'sur_lindqvist',\n 'sur_lobb',\n 'sur_long',\n 'sur_louch',\n 'sur_lulic',\n 'sur_mack',\n 'sur_madigan',\n 'sur_madsen',\n 'sur_mamee',\n 'sur_mangan',\n 'sur_mannion',\n 'sur_marechal',\n 'sur_marvin',\n 'sur_masselmani',\n 'sur_matthews',\n 'sur_mccarthy',\n 'sur_mccormack',\n 'sur_mccoy',\n 'sur_mcdermott',\n 'sur_mcevoy',\n 'sur_mcgough',\n 'sur_mcgovern',\n 'sur_mcgowan',\n 'sur_mckane',\n 'sur_meanwell',\n 'sur_meek',\n 'sur_mellinger',\n 'sur_mellors',\n 'sur_meyer',\n 'sur_millet',\n 'sur_minahan',\n 'sur_mockler',\n 'sur_moen',\n 'sur_molson',\n 'sur_montvila',\n 'sur_moor',\n 'sur_moraweck',\n 'sur_morley',\n 'sur_moss',\n 'sur_moubarek',\n 'sur_moussa',\n 'sur_mudd',\n 'sur_mullens',\n 'sur_murphy',\n 'sur_najib',\n 'sur_nakid',\n 'sur_nasser',\n 'sur_natsch',\n 'sur_newell',\n 'sur_nicholls',\n 'sur_nicholson',\n 'sur_nicola-yarred',\n 'sur_nilsson',\n 'sur_niskanen',\n 'sur_norman',\n 'sur_nye',\n 'sur_nysten',\n \"sur_o'driscoll\",\n \"sur_o'dwyer\",\n \"sur_o'leary\",\n \"sur_o'sullivan\",\n 'sur_ohman',\n 'sur_olsen',\n 'sur_olsson',\n 'sur_oreskovic',\n 'sur_osman',\n 'sur_ostby',\n 'sur_otter',\n 'sur_padro',\n 'sur_pain',\n 'sur_palsson',\n 'sur_panula',\n 'sur_parkes',\n 'sur_parr',\n 'sur_parrish',\n 'sur_partner',\n 'sur_pears',\n 'sur_penasco',\n 'sur_pengelly',\n 'sur_pernot',\n 'sur_persson',\n 'sur_peter',\n 'sur_peters',\n 'sur_petranec',\n 'sur_petroff',\n 'sur_pettersson',\n 'sur_peuchen',\n 'sur_phillips',\n 'sur_pickard',\n 'sur_pinsky',\n 'sur_ponesell',\n 'sur_porter',\n 'sur_quick',\n 'sur_reeves',\n 'sur_reuchlin',\n 'sur_reynaldo',\n 'sur_rice',\n 'sur_richard',\n 'sur_richards',\n 'sur_ridsdale',\n 'sur_ringhini',\n 'sur_robbins',\n 'sur_robins',\n 'sur_roebling',\n 'sur_romaine',\n 'sur_rood',\n 'sur_rosblom',\n 'sur_ross',\n 'sur_rothes',\n 'sur_rothschild',\n 'sur_rugg',\n 'sur_ryan',\n 'sur_ryerson',\n 'sur_saad',\n 'sur_saalfeld',\n 'sur_sage',\n 'sur_salkjelsvik',\n 'sur_sandstrom',\n 'sur_sedgwick',\n 'sur_seward',\n 'sur_sharp',\n 'sur_sheerlinck',\n 'sur_shelley',\n 'sur_silven',\n 'sur_silverthorne',\n 'sur_silvey',\n 'sur_simonius-blumer',\n 'sur_sinkkonen',\n 'sur_sjoblom',\n 'sur_skoog',\n 'sur_slayter',\n 'sur_slemen',\n 'sur_sloper',\n 'sur_smart',\n 'sur_smith',\n 'sur_sobey',\n 'sur_soholt',\n 'sur_stahelin-maeglin',\n 'sur_stanley',\n 'sur_stead',\n 'sur_stewart',\n 'sur_strandberg',\n 'sur_stranden',\n 'sur_strom',\n 'sur_sunderland',\n 'sur_sundman',\n 'sur_sutton',\n 'sur_taussig',\n 'sur_taylor',\n 'sur_thayer',\n 'sur_thomas',\n 'sur_thorne',\n 'sur_tobin',\n 'sur_toomey',\n 'sur_tornquist',\n 'sur_touma',\n 'sur_troupiansky',\n 'sur_trout',\n 'sur_troutt',\n 'sur_turja',\n 'sur_turkula',\n 'sur_turpin',\n 'sur_uruchurtu',\n 'sur_van',\n 'sur_vander',\n 'sur_vestrom',\n 'sur_walker',\n 'sur_watson',\n 'sur_watt',\n 'sur_weir',\n 'sur_weisz',\n 'sur_wells',\n 'sur_west',\n 'sur_white',\n 'sur_wick',\n 'sur_widener',\n 'sur_wilhelms',\n 'sur_williams',\n 'sur_williams-lambert',\n 'sur_woolner',\n 'sur_wright',\n 'sur_yasbeck',\n 'sur_yrois',\n 'sur_zabour',\n 'Cabin_B',\n 'Cabin_D',\n 'Cabin_E',\n 'Cabin_F',\n 'Cabin_G',\n 'Cabin_T',\n 'Cabin_U',\n 'Embarked_C',\n 'Embarked_Q',\n 'Embarked_S',\n 'Pclass_1',\n 'Pclass_2',\n 'Pclass_3',\n 'Ticket_A4',\n 'Ticket_A5',\n 'Ticket_C',\n 'Ticket_CA',\n 'Ticket_CASOTON',\n 'Ticket_FC',\n 'Ticket_FCC',\n 'Ticket_LINE',\n 'Ticket_PC',\n 'Ticket_PP',\n 'Ticket_SC',\n 'Ticket_SCOW',\n 'Ticket_SCParis',\n 'Ticket_SOC',\n 'Ticket_SOP',\n 'Ticket_SOPP',\n 'Ticket_STONO',\n 'Ticket_SWPP',\n 'Ticket_WC',\n 'Ticket_WEP',\n 'Ticket_XXX',\n 'FamilySize',\n 'Singleton',\n 'SmallFamily',\n 'LargeFamily',\n 'Parch_0',\n 'Parch_1',\n 'Parch_2',\n 'Parch_3',\n 'Parch_4',\n 'Parch_5',\n 'Parch_6',\n 'SibSp_0',\n 'SibSp_1',\n 'SibSp_2',\n 'SibSp_3',\n 'SibSp_4',\n 'SibSp_5',\n 'SibSp_8',\n 'Age_0',\n 'Age_1',\n 'Age_2',\n 'Age_4',\n 'Age_5',\n 'Age_6',\n 'Fare_0',\n 'Fare_1',\n 'Fare_2',\n 'Fare_3',\n 'Fare_4',\n 'Fare_5']\n\ntrain = train[param]\ntest = test[param]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84d308b8cbbc94d2df6b1e9e2c2c37f42354a2d8"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nss = StandardScaler()\ntrain_scale= pd.DataFrame(ss.fit_transform(train), columns=test.columns)\ntest_scale = pd.DataFrame(ss.fit_transform(test), columns=test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb2a6f153ab6fd2d2575f8e4f0b6ff14524e61d8"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\ndef svc_param_selection(X, y, nfolds):\n    Cs = [0.001, 0.01, 0.1, 1, 10]\n    gammas = [0.001, 0.01, 0.1, 1]\n    kernel =[\"linear\",\"rbf\"]\n    param_grid = {'C': Cs, 'gamma' : gammas,'kernel':kernel}\n    grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid, cv=nfolds)\n    grid_search.fit(X, y)\n    grid_search.best_params_\n    return grid_search.best_params_\n\nparam = svc_param_selection(train_scale,targets,10)\ndisplay(param)\n\n#take times to run, use back local given param","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23e744b6408c81e61e1b401cdfb6e6ae37255e7c"},"cell_type":"code","source":"from sklearn import svm\nfrom sklearn.svm import SVC\n\nsvc = SVC(C=10,gamma=0.001,kernel='rbf')\nsvc.fit(train_scale, targets)\npred = svc.predict(test_scale).astype(int)\n\nprint(round(svc.score(train_scale, targets) * 100, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de4924f368a858226b7c09148651c85df0cd5ed5","_kg_hide-output":true,"_kg_hide-input":false},"cell_type":"code","source":"#Save result into df, csv\npassengerId = test_df['PassengerId']\nnew_df = pd.DataFrame(columns=['PassengerId','Survived'])\nnew_df['PassengerId'] = passengerId\nnew_df['Survived'] = pred\n\nnew_df.to_csv(\"submition.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ca211538805b44e513234916b79f424e336ecf9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}