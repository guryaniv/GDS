{"cells":[{"metadata":{"_uuid":"dd4adf2dd94ae02b1d2e3559e17603095b971856"},"cell_type":"markdown","source":"Okay, let's just follow the tutorial I guess."},{"metadata":{"collapsed":true,"_uuid":"1c728098629e1301643443b1341556a15c089b2b","_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nmain_file_path = '../input/house-prices-advanced-regression-techniques/train.csv' # this is the path to the Iowa data that you will use\niowa_df = pd.read_csv(main_file_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea443f01712ee353060ad9606b5195204aef6cba"},"cell_type":"markdown","source":"Let's see the shape of the data:"},{"metadata":{"_uuid":"704e07440d7d4ef7ad3cf25c0a966c000bb8eeef","_cell_guid":"895df7f1-dab8-4c54-ab7e-9a865146deac","trusted":true,"collapsed":true},"cell_type":"code","source":"iowa_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7334a07cd8e602f3be340783872ab31d5def0277"},"cell_type":"markdown","source":"And some info too:"},{"metadata":{"trusted":true,"_uuid":"2037bde5906d2229c7ccb4c413546a77e9ca6ce2","collapsed":true},"cell_type":"code","source":"iowa_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bc1754cca2df203a3b6bde92fd7188398f32aa5f"},"cell_type":"markdown","source":"Since there's so many columns, it might be nice to see a list of them:"},{"metadata":{"trusted":true,"_uuid":"dc8cc3783d793425b26ad2b7a0624e925e716cc4","collapsed":true},"cell_type":"code","source":"iowa_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7877e0f7a5b56c0ca78e51cb35eaf93730be37f8"},"cell_type":"markdown","source":"Yeah, just as expected, a bunch of columns. There's a way of making our analysis more focused by selecting only a few columns. For instance:"},{"metadata":{"trusted":true,"_uuid":"2f3b0937e9eee9af66bd511c9d5ccce9c8cb4323","collapsed":true},"cell_type":"code","source":"iowa_df[['Id', 'LotConfig', 'SalePrice']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7c44b18852435282f39f465f356d0f3d832a2c5"},"cell_type":"markdown","source":"Okay, let's see what might be cool to use on use analysis.\n\n(Yeah, still following the tutorial)"},{"metadata":{"trusted":true,"_uuid":"5ccdd8094996e9d77ee74a29d521f32de877046e","collapsed":true},"cell_type":"code","source":"\nreduced_iowa_df = iowa_df[['LotArea', 'YearBuilt',\n                           '1stFlrSF', '2ndFlrSF',\n                           'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']]\nreduced_iowa_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09741a804541034250999663522ce8f13de01bb0"},"cell_type":"markdown","source":"Now is time for sime Machine Learning it seems. First, let's define the Prediction Target:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e03e024dd96636e76cdff7d7ba8393f1d8600e4b"},"cell_type":"code","source":"y = iowa_df.SalePrice","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8528ed16b7782342ff86e5617a64233a60e7b395"},"cell_type":"markdown","source":"And we need the predictors too, which will be used to guess the target:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b82cca3a503318da272a51922e3f13d030b7e0da"},"cell_type":"code","source":"X = reduced_iowa_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75b9d6fa93448af48bc199afcd09208bb6872f4d"},"cell_type":"markdown","source":"And now, the training!"},{"metadata":{"trusted":true,"_uuid":"ae46d741a6178e18cac801a6e14d5e5dd60292fa","collapsed":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\niowa_model = DecisionTreeRegressor()\niowa_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc031c705efa41dbab00e88e3d472d0258bb849d"},"cell_type":"markdown","source":"And it is done it seems!\n\nStill following the guide, we'll test the model with the dataframe used in it's training, just to get the feeling I guess."},{"metadata":{"trusted":true,"_uuid":"73288d318a654ec9d5f4418d22835ab04018342d","collapsed":true},"cell_type":"code","source":"print('Predicting the price for the following houses:')\nprint(X.head())\nprint('And using the model we just obtained, we have:')\nprint(iowa_model.predict(X.head()))\nprint('And if you are curious, here we have the real values:')\nprint(list(y.head()))\nprint(\"Yeah... seems pretty good! But of course, if it wasn't, I guess we would have a problem...\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"734452f881bf89f0fac781558309ac7e6f3691e7"},"cell_type":"markdown","source":"Given the expected value, we can check the error in some predictions using mean_absolute_error, a pretty convenient function:"},{"metadata":{"trusted":true,"_uuid":"1dfb96e4ccab84d020d52c4ec1e08704764b3c8c","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nmean_absolute_error(y, iowa_model.predict(X))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5da3be85c0cd3b1f973b4e3d964dd3f9e7acd195"},"cell_type":"markdown","source":"Welp, that doesn't seems so bad. Still, we are using the training data to check for errors, so something small is about the expected. Now the tutorial teaches us about the train_test_split function, that takes our training dataframe and breaks it into other dataframes, so that we can test the model without having skewed results.\n\nSeems fairly simple:"},{"metadata":{"trusted":true,"_uuid":"deb4fb2bbb6e78746a015e1e3ef194f41cf762e1","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, validation_X, train_y, validation_y = train_test_split(X, y, random_state = 0)\niowa_model = DecisionTreeRegressor()\niowa_model.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcec07c66d259d7940e5cc133e5806dceb5ed740"},"cell_type":"markdown","source":"And now, testing the model on data external to our sample, we have:"},{"metadata":{"trusted":true,"_uuid":"c71b97f2e506b562f7056fc144bfdf0c91933e67","collapsed":true},"cell_type":"code","source":"print(mean_absolute_error(validation_y, iowa_model.predict(validation_X)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0eda9132e74b3a40665dd0f6d40d023f7d4b2a68"},"cell_type":"markdown","source":"Dang, that's a lot bigger!\n\nYou know, maybe we can use the same model -- that is, the DecisionTreeRegression -- but get better results. For that, controlling the number of leaves of our tree might help! \n\nTo do so, we can make a nice little function that tests various leaf numbers and computes the model error for each:"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"809db249d97291b362f05d0f736ecd008d0714d7"},"cell_type":"code","source":"def get_maximum_average_error( maximum_number_of_leaves,\n                             predictors_training,\n                             predictors_validation,\n                             target_training,\n                            target_validation):\n    model = DecisionTreeRegressor(max_leaf_nodes = maximum_number_of_leaves,\n                                          random_state = 0)\n    model.fit(predictors_training, target_training)\n    predicted_values = model.predict(predictors_validation)\n    return mean_absolute_error(target_validation, predicted_values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"679013f43cf8d633491e7ed37fbc89bda03704eb"},"cell_type":"markdown","source":"Now, let's put this function to work:"},{"metadata":{"trusted":true,"_uuid":"044e13a07b5504ebb3a4542e553dcda2c9b0032f","collapsed":true},"cell_type":"code","source":"for maximum_leaves in [5, 50, 500, 5000, 50000, 500000]:\n    current_maximum_average_error = get_maximum_average_error(maximum_leaves,\n                                                             train_X,\n                                                             validation_X,\n                                                             train_y,\n                                                             validation_y)\n    print('For %d maximum number of leaves, \\t \\t we have a Mean Absolute Error for %d' %(maximum_leaves, current_maximum_average_error))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3d9967fa61ea44c0f676449082479a5cff7211ba"},"cell_type":"markdown","source":"Interesting: for about 50 leaves, we have the best model, that is, the model with least error. For less than that the results aren't that good, and for more we kinda of stagnate on 33382 as the Mean Absolute Error.\n\nThe next step is making a better analysis: to do so, the tutorial teaches us other type of model, which will give us better predictions than the Decision Tree.\nThis model is the Random Forest, that apparently is obtained by making a bunch of different Decision Trees and averaging them (hence the name, random forest).\nApparently it is pretty simple to use this model:"},{"metadata":{"trusted":true,"_uuid":"c2982643318681439c00b791795f6ac8373e3f33","collapsed":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\ntrain_X, validation_X, train_y, validation_y = train_test_split(X, y, random_state = 0)\niowa_model_with_random_forest = RandomForestRegressor()\niowa_model_with_random_forest.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e9904bb0d9067bb2198bd7671af620634ec1dcd","collapsed":true},"cell_type":"code","source":"mean_absolute_error(validation_y, iowa_model_with_random_forest.predict(validation_X) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"878a593de0bace05d0dc021c365cb126e475f5ef"},"cell_type":"markdown","source":"Hey, that's pretty good actually, given that our best bets with the Decision Tree had about 28k as error, and we got that with some testing on the number of leaves. Here it wasn't even needed!\n\nAnyway, the tutorial ends about here: the only thing left is to create a submission file, and then make the submission. Ok, let's try to do it.\n\nFirst, I'll change things up so that the RandomForest is trained on the entire train.csv, instead of a portion of it from the train_test_split():"},{"metadata":{"trusted":true,"_uuid":"37c80ce39405ab78844c31572d8314a32caa1347","collapsed":true},"cell_type":"code","source":"X = reduced_iowa_df\ny = iowa_df.SalePrice\niowa_model = RandomForestRegressor()\niowa_model.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2517045411e763abf13525d3a74861448093f274"},"cell_type":"markdown","source":"Now let's try to predict some prices based on the test.csv data:"},{"metadata":{"trusted":true,"_uuid":"e8772d5f911f81bf01daaa1b140ed1433e5a6bd8","collapsed":true},"cell_type":"code","source":"iowa_df_test = pd.read_csv('../input/house-prices-advanced-regression-techniques/test.csv')\nX_test = iowa_df_test[['LotArea', 'YearBuilt',\n                           '1stFlrSF', '2ndFlrSF',\n                           'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']]\npredicted_prices = iowa_model.predict(X_test)\n\nprint('And here are the predicted prices:')\nprint(predicted_prices)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5c576fbba2f8f5b3a4b1996fe495c76265007b4"},"cell_type":"markdown","source":"...or at least some of them, it seems. About 1.5k values is a pretty big quantity, anyway.\n\nNow, to the csv file. Seems fairly simple to create:"},{"metadata":{"trusted":true,"_uuid":"2702d4a5dfd22d0899a06e47f0c8dd6c3df382b8","collapsed":true},"cell_type":"code","source":"submission = pd.DataFrame({'Id': iowa_df_test.Id,\n                           'SalePrice': predicted_prices})\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ff676d98b991231b7c6a51ef79167555ef9b471e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}