{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7e678d1-6107-d11d-78ff-98b18ab6b670"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "## Load Data\n",
        "\n",
        "data = pd.read_csv(\"../input/loan.csv\", low_memory=False)\n",
        "\n",
        "#data.info()\n",
        "#data.shape\n",
        "\n",
        "## Clean data.\n",
        "\n",
        "clean_data = data.dropna(thresh=len(data),axis=1)\n",
        "#clean_data.shape\n",
        "list(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9201ffdd-3c9c-1bf5-9678-d63a7ac0b905"
      },
      "outputs": [],
      "source": [
        "#clean_data.loan_status.str.contains(\"Fully Paid\").astype(int)\n",
        "\n",
        "#clean_data.loan_status[clean_data.loan_status.str.contains(\"Fully Paid\") == True] = 1\n",
        "#clean_data.loan_status[clean_data.loan_status.str.contains(\"Fully Paid\") == False] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dbe712f4-b81e-87b9-2a08-152388f34c29"
      },
      "outputs": [],
      "source": [
        "## Remove data that does not meet the credit policy.\n",
        "clean_data = clean_data[clean_data.loan_status.str.contains(\"Does not meet the credit policy\") == False]\n",
        "\n",
        "#clean_data.loan_status[clean_data.loan_status.str.contains(\"Fully Paid\")].astype(int)\n",
        "clean_data.loan_status[clean_data.loan_status.str.contains(\"Fully Paid\") == True] = 1\n",
        "clean_data.loan_status[clean_data.loan_status.str.contains(\"Fully Paid\") == False] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e5d142c-83d8-25e2-0f67-c2c929c6fb73"
      },
      "outputs": [],
      "source": [
        "clean_data.loan_status.unique()\n",
        "\n",
        "clean_data.shape\n",
        "\n",
        "clean_data_orig = clean_data.copy()\n",
        "\n",
        "list(clean_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6ef84882-774e-3437-fc93-60084462656b"
      },
      "outputs": [],
      "source": [
        "## Split Data\n",
        "ratio = 0.7\n",
        "msk = np.random.rand(len(clean_data)) < ratio\n",
        "train_data = clean_data[msk]\n",
        "test_data = clean_data[~msk]\n",
        "\n",
        "## Use loan status as label for loan defaulters\n",
        "y_label['loan_status'] = clean_data['loan_status'][msk]\n",
        "y_test_label['loan_status'] = clean_data['loan_status'][~msk]\n",
        "\n",
        "train_data = train_data.select_dtypes(exclude=[np.object])\n",
        "test_data = test_data.select_dtypes(exclude=[np.object])\n",
        "\n",
        "\n",
        "len(train_data)\n",
        "len(test_data)\n",
        "\n",
        "#train_data['loan_amnt'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32e5a9a7-b49d-e5de-a5c4-c96ec51192e3"
      },
      "outputs": [],
      "source": [
        "##Vizualization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#train_data.plot()\n",
        "\n",
        "#plt.figure(); train_data.plot(); plt.legend(loc='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62771dec-06dc-7f63-d458-0982774cb18b"
      },
      "outputs": [],
      "source": [
        "#y_label[y_label.str.contains(\"Does not\") == True].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a32cba30-799c-442f-822c-eec14f09bc63"
      },
      "outputs": [],
      "source": [
        "list(train_data)\n",
        "\n",
        "#train_data.drop('id', axis=1, inplace=True)\n",
        "#train_data.drop('member_id', axis=1, inplace=True)\n",
        "train_data.drop('funded_amnt_inv', axis=1, inplace=True)\n",
        "#train_data.drop('url', axis=1, inplace=True)\n",
        "#train_data.drop('loan_status', axis=1, inplace=True)\n",
        "#train_data.drop('application_type', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "#test_data.drop('id', axis=1, inplace=True)\n",
        "#test_data.drop('member_id', axis=1, inplace=True)\n",
        "test_data.drop('funded_amnt_inv', axis=1, inplace=True)\n",
        "#test_data.drop('url', axis=1, inplace=True)\n",
        "#test_data.drop('loan_status', axis=1, inplace=True)\n",
        "#test_data.drop('application_type', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70edb1ad-7103-39c5-40fc-a483ba303824"
      },
      "outputs": [],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e186be1-25fe-45c3-5936-6fc80c5d4b17"
      },
      "outputs": [],
      "source": [
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6115d97c-1e23-0bfc-3472-31c064660eec"
      },
      "outputs": [],
      "source": [
        "unique, counts = np.unique(msk, return_counts=True)\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa2d7843-cc55-b93c-d73e-8bfb01cb7c86"
      },
      "outputs": [],
      "source": [
        "y_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b636c4df-3b68-4275-0f09-b7b0a3afd48a"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(train_data, y_label)\n",
        "Y_pred = logreg.predict(test_data)\n",
        "acc_log = round(logreg.score(train_data, y_label) * 100, 2)\n",
        "acc_log\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f12eafd-9f0d-3478-beac-b08b017c45f8"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8006411d-2ceb-6e48-b6d7-87e6c6d75134"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def get_series_ids(x):\n",
        "    '''Function returns a pandas series consisting of ids, \n",
        "       corresponding to objects in input pandas series x\n",
        "       Example: \n",
        "       get_series_ids(pd.Series(['a','a','b','b','c'])) \n",
        "       returns Series([0,0,1,1,2], dtype=int)'''\n",
        "\n",
        "    values = np.unique(x)\n",
        "    values2nums = dict(zip(values,range(len(values))))\n",
        "    return x.replace(values2nums)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d4ba3ae-f14c-4a7c-bdbb-3f6cb02a4ea0"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a62e339-7689-2793-f5b7-fef850aaf522"
      },
      "outputs": [],
      "source": [
        "x = tf.placeholder(tf.float32, shape=[len(train_data), None])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 2])\n",
        "\n",
        "W = tf.Variable(tf.zeros([len(train_data),2]))\n",
        "b = tf.Variable(tf.zeros([2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af0451c9-409d-57d7-fe49-7bb3cb7e6ad1"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "training_epochs = 25\n",
        "batch_size = 100\n",
        "display_step = 1\n",
        "\n",
        "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
        "\n",
        "# Minimize error using cross entropy\n",
        "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
        "# Gradient Descent\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    # Training cycle\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = len(train_data)\n",
        "        # Loop over all batches\n",
        "        for i in range(total_batch):\n",
        "            batch_xs = train_data\n",
        "            batch_ys = y_label\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
        "                                                          y: batch_ys})\n",
        "            # Compute average loss\n",
        "            avg_cost += c / total_batch\n",
        "        # Display logs per epoch step\n",
        "        if (epoch+1) % display_step == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "\n",
        "    # Test model\n",
        "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "    # Calculate accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "print(\"Accuracy:\", accuracy.eval({x: test_data, y: y_test_labels}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba1a58d4-ab9f-4fb0-33fa-e2a0eb2d5d9c"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}