{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "7ddd0764-1f6b-4f72-b3d4-692f829e99c1", "_uuid": "fad0cc2d3b352084b07bb30e4091379bf163f5c9"}, "outputs": [], "cell_type": "code", "source": ["\"\"\"\n", "References or inspired by\n", "1. https://www.kaggle.com/sudosudoohio/stratified-kfold-xgboost-eda-tutorial-0-281?scriptVersionId=1579846\n", "2. https://www.kaggle.com/youhanlee/eda-stratifiedshufflesplit-xgboost-for-starter?scriptVersionId=1583200\n", "\"\"\"\n", "import pandas as pd\n", "import numpy as np\n", "import warnings\n", "import matplotlib.pyplot as plt   \n", "import seaborn as sns             # not used\n", "\n", "from sklearn import preprocessing \n", "from sklearn.model_selection import StratifiedKFold\n", "import xgboost as xgb\n", "\n", "%matplotlib inline\n", "warnings.filterwarnings('ignore')"]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "581eab18-3129-4600-ab99-3a255b37e5e4", "_uuid": "b45b5378a8c326e3a12b1c56939c17efd46bbf7b"}, "outputs": [], "cell_type": "code", "source": ["# common gini metric for the gradient boost\n", "# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n", "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n", "    assert( len(actual) == len(pred) )\n", "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n", "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n", "    totalLosses = all[:,0].sum()\n", "    giniSum = all[:,0].cumsum().sum() / totalLosses\n", "    \n", "    giniSum -= (len(actual) + 1) / 2.\n", "    return giniSum / len(actual)\n", " \n", "def gini_normalized(a, p):\n", "    return gini(a, p) / gini(a, a)\n", "\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized(labels, preds)\n", "    return 'gini', gini_score"]}, {"execution_count": null, "metadata": {"_cell_guid": "260c3530-ce62-4a4a-bafe-e375446dc482", "_uuid": "e970d64f273cf88399005f3693db6114691d77fc"}, "outputs": [], "cell_type": "code", "source": ["# train and test data\n", "train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")\n", "train.head(10)\n", "test.head(10)"]}, {"execution_count": null, "metadata": {"_cell_guid": "10928ad1-7e12-40b5-97d5-076b89ec74de", "_uuid": "c0291b678326726ec9245add654091c37fc693eb"}, "outputs": [], "cell_type": "code", "source": ["# pre-processing, null data\n", "train_null = train.isnull().values.any()\n", "print(train_null)\n", "\n", "# features and drop related columns \n", "features = train.drop(['id','target'], axis=1).values\n", "targets = train.target.values\n", "drop_columns = train.columns[train.columns.str.startswith('ps_calc_')]\n", "train = train.drop(drop_columns, axis=1)  \n", "test = test.drop(drop_columns, axis=1)  "]}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "2e27086c-2e83-4aeb-a4df-ccbb4c949f4a", "_uuid": "90b8f32639454e347e157571e9cc23c1273b28c6"}, "outputs": [], "cell_type": "code", "source": ["# model setting\n", "kfold = 5\n", "skf = StratifiedKFold(n_splits=kfold, random_state=99)\n", "params = {\n", "    'min_child_weight': 10.0,\n", "    'objective': 'binary:logistic',\n", "    'max_depth': 7,\n", "    'max_delta_step': 1.8,\n", "    'colsample_bytree': 0.4,\n", "    'subsample': 0.8,\n", "    'eta': 0.025,\n", "    'gamma': 0.65,\n", "    'num_boost_round' : 700\n", "    }\n", "\n", "X = train.drop(['id', 'target'], axis=1).values\n", "y = train.target.values\n", "test_id = test.id.values\n", "test = test.drop('id', axis=1)"]}, {"execution_count": null, "metadata": {"_cell_guid": "c9ef1da6-a3bb-435d-a258-fcd0ca739886", "_uuid": "bc3cd0c6f8f7e95f515576d6aac3a063c6de8683"}, "outputs": [], "cell_type": "code", "source": ["# submission preparation\n", "sub = pd.DataFrame()\n", "sub['id'] = test_id\n", "sub['target'] = np.zeros_like(test_id)\n", "\n", "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n", "    print('[Fold %d/%d]' % (i + 1, kfold))\n", "    X_train, X_valid = X[train_index], X[test_index]\n", "    y_train, y_valid = y[train_index], y[test_index]\n", "    \n", "    # Convert our data into XGBoost format\n", "    d_train = xgb.DMatrix(X_train, y_train)\n", "    d_valid = xgb.DMatrix(X_valid, y_valid)\n", "    d_test = xgb.DMatrix(test.values)\n", "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n", "\n", "    # Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n", "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n", "    mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)\n", "\n", "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n", "    # Predict on our test data\n", "    p_test = mdl.predict(d_test)\n", "    sub['target'] += p_test/kfold"]}, {"execution_count": null, "metadata": {}, "outputs": [], "cell_type": "code", "source": ["# csv file\n", "sub.to_csv('StratifiedKFold.csv', index=False)"]}], "nbformat_minor": 1, "nbformat": 4}