{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python"}}, "cells": [{"metadata": {"_uuid": "e8b9d462c34fef928aff006d7bb43aa110d989e1", "collapsed": true, "_cell_guid": "71ce8f60-3770-4225-b88c-28b7b61020a0"}, "cell_type": "code", "outputs": [], "execution_count": null, "source": ["import time\n", "start_time = time.time()\n", "\n", "import pandas as pd \n", "import numpy as np\n", "\n", "from scipy.sparse import csr_matrix, hstack\n", "\n", "from sklearn.linear_model import Ridge\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "\n", "def replaceMissing(dataset):\n", "    dataset['category_name'].fillna(value='MV99', inplace=True)\n", "    dataset['brand_name'].fillna(value='MV99', inplace=True)\n", "    dataset['item_description'].fillna(value='MV99', inplace=True)\n", "    \n", "def createCategories(dataset):\n", "    cat_lists = dataset['category_name'].apply(lambda x: x.split('/'))\n", "    cat_df = pd.DataFrame(cat_lists.tolist(), columns=['category1','category2','category3','category4','category5'])\n", "    ds = pd.concat([dataset, cat_df], axis=1)\n", "    return ds\n", "\n", "def cleanCategories(ds1, ds2, minCount): \n", "    for var in ['category1','category2','category3','category4','category5']:\n", "        \n", "        ds1[var].fillna(value='MV99', inplace=True)\n", "        ds2[var].fillna(value='MV99', inplace=True)\n", "        \n", "        keep = ds1[var].value_counts()[\n", "            (ds1[var].value_counts() > minCount) & (ds2[var].value_counts() > minCount)\n", "        ].index.tolist()\n", "        \n", "        ds1[var] = ds1[var].apply(lambda x: x if x in keep else 'SV01')\n", "        ds2[var] = ds2[var].apply(lambda x: x if x in keep else 'SV01')\n", "        \n", "def cleanBrands(ds1, ds2, minCount):   \n", "    keepBrands = ds1['brand_name'].value_counts()[\n", "        (ds1['brand_name'].value_counts() > minCount) & (ds2['brand_name'].value_counts() > minCount)\n", "    ].index.tolist() \n", "    \n", "    ds1['brand'] = ds1['brand_name'].apply(lambda x: x if x in keepBrands else 'SV01')\n", "    ds2['brand'] = ds2['brand_name'].apply(lambda x: x if x in keepBrands else 'SV01')\n", "    \n", "train = pd.read_csv('../input/train.tsv',sep='\\t')\n", "test = pd.read_csv(\"../input/test.tsv\", sep='\\t')\n", "\n", "print(\"{} second to finish import\".format(time.time() - start_time))\n", "\n", "full = [train,test]\n", "\n", "submission = test['test_id']\n", "\n", "full2 = []\n", "\n", "for df in full:\n", "    replaceMissing(df)\n", "    df2 = createCategories(df)\n", "    full2.append(df2)\n", "    \n", "train2 = full2[0]\n", "test2 = full2[1]\n", "\n", "cleanCategories(train2, test2, 10)\n", "cleanBrands(train2, test2, 10)\n", "\n", "print(\"{} seconds to finish cleaning data\".format(time.time() - start_time))\n", "\n", "nrow_train = train.shape[0]\n", "\n", "traintest = pd.concat([train2.drop(['train_id','price'], axis=1), test2.drop(['test_id'], axis=1)])\n", "\n", "lb = LabelBinarizer(sparse_output=True)\n", "\n", "X_c1 = lb.fit_transform(traintest['category1'])\n", "X_c2 = lb.fit_transform(traintest['category2'])\n", "X_c3 = lb.fit_transform(traintest['category3'])\n", "X_c4 = lb.fit_transform(traintest['category4'])\n", "X_c5 = lb.fit_transform(traintest['category5'])\n", "X_brand = lb.fit_transform(traintest['brand'])\n", "\n", "print(\"{} seconds to finish LabelBinerizer\".format(time.time()-start_time))\n", "\n", "tv = TfidfVectorizer(max_features=50000, ngram_range=(1,3), stop_words='english')\n", "X_description = tv.fit_transform(traintest['item_description'])\n", "\n", "X_dummies = csr_matrix(pd.get_dummies(traintest[['item_condition_id', 'shipping']],sparse=True).values)\n", "\n", "sparse_merge = hstack((X_dummies,X_description,X_brand,X_c1,X_c2,X_c3,X_c4,X_c5)).tocsr()\n", "\n", "print(\"{} seconds to finish Sparse Merge\".format(time.time()-start_time))\n", "\n", "X = sparse_merge[:nrow_train]\n", "X_test = sparse_merge[nrow_train:]\n", "\n", "y = np.log1p(train['price'])\n", "end_time = time.time()\n", "print(\"Data Processing took {} seconds\".format(end_time - start_time))"]}, {"metadata": {"_uuid": "0d4f833235e25b38ccd548f7a4b9cb48df21c28b", "collapsed": true, "_cell_guid": "993c6761-340c-4275-8d77-f47d91e62deb"}, "cell_type": "code", "outputs": [], "execution_count": null, "source": ["model = Ridge(alpha=1, solver='sag', fit_intercept=True, random_state=111)\n", "model.fit(X,y)\n", "preds = np.expm1(model.predict(X_test))\n"]}, {"metadata": {"_uuid": "2c5d8a40191636aa799216b65e8956d6d0be8a88", "collapsed": true, "_cell_guid": "caa909d7-3729-45c6-8a18-36971a8bbbe4"}, "cell_type": "code", "outputs": [], "execution_count": null, "source": ["submission = pd.concat([test['test_id'],pd.DataFrame(preds, columns=['price'])],axis=1)\n", "submission.to_csv(\"submission_simple_ridge_1.csv\", index=False)"]}, {"metadata": {"_uuid": "a3a225067dff214e8f79c0144a001928baeeae7d", "collapsed": true, "_cell_guid": "a63bb649-acb5-4e94-b054-87efb688486c"}, "cell_type": "code", "outputs": [], "execution_count": null, "source": []}], "nbformat": 4, "nbformat_minor": 1}