{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eb93dea8-a1de-3b81-deab-1261e8ed89a8"
      },
      "source": [
        "imho we are doing a kind of internal organisational 'timemanagement'  where people are monitored...\n",
        "anyone has an explanation  how R2 are related with LB score ?\n",
        "\n",
        "btw: the better we are clustering the R2 the less efficient we become iMHO."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "149e94b4-3c85-737f-6f9e-9d5531e19f72"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# read datasets\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "test['y'] = 102  # to make append possible\n",
        "print\n",
        "y_train = train[\"y\"]\n",
        "totaal= train.append(test)\n",
        "#yx0_train = totaal[['y','X0']]\n",
        "#print(yx0_train.groupby('X0').mean().sort('y'))\n",
        "#temp=yx0_train.groupby('X0').mean().sort('y')\n",
        "#templ=temp.index\n",
        "#print(templ)\n",
        "#totaal['X0'].replace(to_replace=templ, value=[x for x in range(0,len(templ))], inplace=True, method='pad', axis=1)\n",
        "print(totaal.head())\n",
        "# process columns, apply LabelEncoder to categorical features\n",
        "for c in totaal.columns:\n",
        "    if totaal[c].dtype == 'object':\n",
        "        tempt = totaal[['y',c]]\n",
        "        temp=tempt.groupby(c).mean().sort('y')\n",
        "        templ=temp.index\n",
        "        print(templ)\n",
        "        aant=len(templ)\n",
        "        train[c].replace(to_replace=templ, value=[x/aant for x in range(0,aant)], inplace=True, method='pad', axis=1)\n",
        "        test[c].replace(to_replace=templ, value=[x/aant for x in range(0,aant)], inplace=True, method='pad', axis=1)\n",
        "         #test[c] = lbl.transform(list(test[c].values))\n",
        "\n",
        "# shape  \n",
        "print(train.head())\n",
        "print(test.head())\n",
        "print('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n",
        "\n",
        "\n",
        "##Add decomposed components: PCA / ICA etc.\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation,FactorAnalysis,MiniBatchDictionaryLearning\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "n_comp = 2\n",
        "#nmf\n",
        "nmf = NMF(n_components=n_comp, random_state=1,          alpha=.1, l1_ratio=.5)\n",
        "nmf_results_train=nmf.fit_transform(train.drop(['y'], axis=1))#,y=y_train)  #R2 +Y 0.44 #R2-Y 0.44\n",
        "nmf_results_test=nmf.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "\n",
        "#lda\n",
        "lda = LatentDirichletAllocation(n_topics=n_comp, max_iter=5,                                learning_method='online',                                learning_offset=50.,                                random_state=0).fit(train.drop([\"y\"], axis=1),y_train)\n",
        "lda_results_train = lda.fit_transform(train.drop([\"y\"], axis=1),y_train ) #R2 +Y 0.40\n",
        "lda_results_test = lda.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "# tSVD\n",
        "tsvd = TruncatedSVD(n_components=n_comp, random_state=42)\n",
        "tsvd_results_train = tsvd.fit_transform(train.drop(['y'], axis=1) ) #,y=y_train) #R2 +Y=0.47\n",
        "tsvd_results_test = tsvd.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=n_comp, random_state=42)\n",
        "pca2_results_train = pca.fit_transform(train.drop(['y'], axis=1))#,y=y_train) #R2 +Y 0.467\n",
        "pca2_results_test = pca.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "# ICA\n",
        "ica = FastICA(n_components=n_comp, random_state=42)\n",
        "ica2_results_train = ica.fit_transform(train.drop(['y'], axis=1) ) #,y=y_train) #R2+y=0.439\n",
        "ica2_results_test = ica.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "#FA\n",
        "fa =FactorAnalysis(n_components=n_comp)\n",
        "fa2_results_train = fa.fit_transform(train.drop([\"y\"], axis=1)) #,y=y_train) #R2 +y 0.412\n",
        "fa2_results_test = fa.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "#MDB\n",
        "mdb=MiniBatchDictionaryLearning(n_components=n_comp, alpha=0.1,n_iter=50, batch_size=3,random_state=42)\n",
        "mdb_results_train = mdb.fit_transform(train.drop(['y'], axis=1)) #,y=y_train) #R2 +y 0.469\n",
        "mdb_results_test = mdb.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "#mbk\n",
        "mbk=MiniBatchKMeans(n_clusters=n_comp, tol=1e-3, batch_size=20,max_iter=50, random_state=42)\n",
        "mbk_results_train = mbk.fit_transform(train.drop(['y'], axis=1)) #,y=y_train) #R2 +y 0.437\n",
        "mbk_results_test = mbk.transform(test.drop(['y'], axis=1))\n",
        "\n",
        "# Append decomposition components to datasets\n",
        "for i in range(1, n_comp+1):\n",
        "    train['mbk_' + str(i)] = mbk_results_train[:,i-1]\n",
        "    test['mbk_' + str(i)] = mbk_results_test[:, i-1]\n",
        "    \n",
        "    train['mdb_' + str(i)] = mdb_results_train[:,i-1]\n",
        "    test['mdb_' + str(i)] = mdb_results_test[:, i-1]\n",
        "     \n",
        "    train['fa_' + str(i)] = fa2_results_train[:,i-1]\n",
        "    test['fa_' + str(i)] = fa2_results_test[:, i-1]\n",
        "    \n",
        "    train['pca_' + str(i)] = pca2_results_train[:,i-1]\n",
        "    test['pca_' + str(i)] = pca2_results_test[:, i-1]\n",
        "    \n",
        "    train['ica_' + str(i)] = ica2_results_train[:,i-1]\n",
        "    test['ica_' + str(i)] = ica2_results_test[:, i-1]\n",
        "    \n",
        "    train['tsvd_' + str(i)] = tsvd_results_train[:,i-1]\n",
        "    test['tsvd_' + str(i)] = tsvd_results_test[:, i-1]\n",
        "\n",
        "    train['lda_' + str(i)] = lda_results_train[:,i-1]\n",
        "    test['lda_' + str(i)] = lda_results_test[:, i-1]    \n",
        "\n",
        "    train['nmf_' + str(i)] = nmf_results_train[:,i-1]\n",
        "    test['nmf_' + str(i)] = nmf_results_test[:, i-1]        \n",
        "    \n",
        "\n",
        "\n",
        "print('Shape with PCA train: {}\\nShape test: {}'.format(train.shape, test.shape))\n",
        "\n",
        "y_mean = np.mean(y_train)\n",
        "\n",
        "print(test.head())\n",
        "\n",
        "### Regressor\n",
        "import xgboost as xgb\n",
        "\n",
        "# prepare dict of params for xgboost to run with\n",
        "xgb_params = {\n",
        "    'n_trees': 500, \n",
        "    'eta': 0.0025,\n",
        "    'max_depth': 4,\n",
        "    'subsample': 0.95,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'base_score': y_mean, # base prediction = mean(target)\n",
        "    'silent': 1\n",
        "}\n",
        "\n",
        "\n",
        "# form DMatrices for Xgboost training\n",
        "dtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\n",
        "dtest = xgb.DMatrix(test.drop('y', axis=1))\n",
        "\n",
        "\n",
        "num_boost_rounds = 1500\n",
        "# train model\n",
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n",
        "fig, ax = plt.subplots(figsize=(12,15))\n",
        "xgb.plot_importance(model, height=0.8, ax=ax, max_num_features=30)\n",
        "plt.show()\n",
        "\n",
        "# check f2-score (to get higher score - increase num_boost_round in previous cell)\n",
        "from sklearn.metrics import r2_score\n",
        "print(r2_score(model.predict(dtrain), dtrain.get_label()))\n",
        "\n",
        "# make predictions and save results\n",
        "y_pred = model.predict(dtest)\n",
        "output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(output.y.values, bins=50, kde=False)\n",
        "plt.xlabel('Predicted AVG Time on Test platform', fontsize=12)\n",
        "plt.show()\n",
        "    \n",
        "output.to_csv('submission_baseLine.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}