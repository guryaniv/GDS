{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3b9e9b4f-378f-3c5d-429e-98a4cb2725af"
      },
      "source": [
        "In each competition I find myself in a need for a feature reference. It's just what you look at when you wonder how important is feature \"xyz\", is it meaningful to scale it, etc. This is the goal of this script. \n",
        "\n",
        "ATTENTION: To acutally see the final version click on \"You are viewing the last successful run of this script. Click here to see the current version with an error.\" The warning is shown, because the script is creating 3 graphics for each feature, or more than"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "96d42123-81ea-c04c-136e-c56ef3529176"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.stats as stats\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "sns.set(color_codes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2400e2d4-2465-437d-bf0f-60b64d2d15a5"
      },
      "outputs": [],
      "source": [
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
        "    df = train.get(\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c285760a-1085-e153-ac68-fb450a6c1c10"
      },
      "outputs": [],
      "source": [
        "print('Dataframe shape:', df.shape)\n",
        "print('Columns', df.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d074e670-41b3-b3bf-aa04-a08b826a98fe"
      },
      "outputs": [],
      "source": [
        "print('Ids (each id represents a different stock, e.g. Apple, Google, etc.) count:', len(df['id'].unique()))\n",
        "print('Time frames count:', len(df['timestamp'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f6577cc3-09af-61ae-24c5-7526b15b0978"
      },
      "source": [
        "If you multiply timestamps and id, you get 1424x1813 =  2,581,712. But we only have 1,710,756 samples of data => At each time frame you have some variable count of ids (stocks) X, where X<=1424. Let's look at how much ids one will find at each time frame:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "80b3f8c7-41b6-b07e-84a7-b004df58e91e"
      },
      "outputs": [],
      "source": [
        "id_count = [len(df[df['timestamp'] == i]['id'].unique()) for i in range(1813)]\n",
        "plt.figure(figsize=(9,3))\n",
        "plt.xlabel('Timestamp index')\n",
        "plt.ylabel('Unique IDs for the timestamp')\n",
        "plt.plot(range(1813), id_count,'.b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "80be77af-cb76-c607-c5e5-7bb5916f6a0b"
      },
      "source": [
        "That's a bit strange. The number of IDs for each timestamp is increasing over time...  You can also observe a pattern of time periodicity... There is already a script about that: https://www.kaggle.com/chaseos/two-sigma-financial-modeling/understanding-id-and-timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d85fc52d-81e1-83a6-bf23-22f236efc48a"
      },
      "outputs": [],
      "source": [
        "features = [feature for feature in df.columns.values if not feature in ['id', 'timestamp']]\n",
        "for feature in features:\n",
        "    values = df[feature].values\n",
        "    nan_count = np.count_nonzero(np.isnan(values))\n",
        "    values = sorted(values[~np.isnan(values)])\n",
        "    print('NaN count:', nan_count, 'Unique count:', len(np.unique(values)))\n",
        "    print('Max:', np.max(values), 'Min:', np.min(values))\n",
        "    print('Median', np.median(values), 'Mean:', np.mean(values), 'Std:', np.std(values))\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.title('Values '+feature)\n",
        "    plt.plot(values,'.b')\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.title('Percentiles 1,5,10...95,99 '+feature)\n",
        "    percentiles = [1] + list(range(5,100,5)) +[99]\n",
        "    plt.plot(percentiles, np.percentile(values, percentiles),'.b')\n",
        "    plt.show()\n",
        "    \n",
        "    fit = stats.norm.pdf(values, np.mean(values), np.std(values))  #this is a fitting indeed\n",
        "    plt.title('Distribution Values '+feature)\n",
        "    plt.plot(values,fit,'-g')\n",
        "    plt.hist(values,normed=True, bins=10)      #use this to draw histogram of your data\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae649c7e-40f3-d6da-fb53-c482af7904a6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}