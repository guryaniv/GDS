{"nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.4", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "cells": [{"source": ["**This project is to build a machine learning model to automatically classify boat and iceberg in satallite images.**\n", "\n", "**Part I, Image processing/denoising, backscattering signal extraction, data scaling.**\n", "\n", "**Part II, deep learning (transfer learning with multiple inputs and data augmentation).**"], "cell_type": "markdown", "metadata": {"_cell_guid": "98f63571-2dc1-4be5-b02a-222a610288d9", "_uuid": "868b6abd09f93bc88546c2dcd888b777120baf91"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "3d9bd703-a6ee-47f5-8fb0-d3608c96d0c3", "_uuid": "f6528733be9c63de5fedd610c81d2c03314b4206"}, "source": ["#Import libraries.\n", "import numpy as np \n", "import pandas as pd \n", "import cv2\n", "from skimage import restoration, filters, img_as_ubyte\n", "\n", "from sklearn.preprocessing import scale, StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import log_loss\n", "\n", "from scipy.stats import mode\n", "from scipy.ndimage.filters import uniform_filter\n", "from scipy.ndimage.measurements import variance\n", "\n", "from keras import applications, regularizers\n", "from keras.models import Sequential, Model\n", "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, SeparableConv2D, Add, Average\n", "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, concatenate\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.optimizers import Adam, SGD, Nadam\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.layers.merge import Concatenate\n", "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n", "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n", "from keras.applications.xception import Xception\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.applications.resnet50 import ResNet50\n", "from keras.applications.vgg19 import VGG19\n", "from keras.applications.vgg16 import VGG16\n", "from keras import backend as K\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"source": [" **Part I: Image processing and signal extraction**"], "cell_type": "markdown", "metadata": {"_cell_guid": "abfdbe28-69af-4e22-a09c-ba3d3643e272", "_uuid": "c0c7738893ebf1b9807e307d03e01652e1debd66"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "95962dd3-e1d4-4fce-85cb-8cb1759f89a0", "_uuid": "09c66bf6fc7b085ef6a0c97c2aab9b0203834914"}, "source": ["#Define a function to plot the radar signals as images.\n", "def img_plot(img_arr, ax, title):\n", "    ax.imshow(img_arr)\n", "    ax.axis('off')\n", "    ax.grid('off')\n", "    if title == 1:\n", "        ax.set_title('Iceberg')\n", "    elif title == 0:\n", "        ax.set_title('Boat')"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "41f4fd06-705c-4890-9254-99152f3fada4", "_uuid": "fa64a4e6f3ccfd6ce1fdbb94496867917f8d6316"}, "source": ["# Create the Lee filter function.\n", "def lee_filter(img, size):\n", "    img_mean = uniform_filter(img, (size, size))\n", "    img_sqr_mean = uniform_filter(img**2, (size, size))\n", "    img_variance = img_sqr_mean - img_mean**2\n", "\n", "    overall_variance = variance(img)\n", "\n", "    img_weights = img_variance**2 / (img_variance**2 + overall_variance**2)\n", "    img_output = img_mean + img_weights * (img - img_mean)\n", "    return img_output"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "a273d56a-5809-4c98-bae2-ea080394a4c1", "_uuid": "5b3089a5550d525ba347abfe679ffa3209c99ab2"}, "source": ["#Now, define a funciton to use the Lee filter, denoise_nl_means and bilateral functions sequentially to remove noise.\n", "#The filter parameters are defined in the function. \n", "def noise_removal(signal, img_h=75, img_w=75):\n", "    #Convert the signal array to 2d array/image\n", "    #Apply three filters sequentially to remove noise\n", "    image = signal\n", "    if len(signal.shape) == 1:\n", "        image = signal.reshape(img_h, img_w)\n", "    lee = lee_filter(image, 5)\n", "    final_image = restoration.denoise_nl_means(lee, patch_size=5, patch_distance=10, h=2, \n", "                                               multichannel=False, fast_mode=True)\n", "    return(final_image)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "1ea4e55a-c414-4df0-9584-2c9a2661c598", "_uuid": "55d70a468501282e694bb246706377cfb6c7edf0"}, "source": ["# Read the training dataset.\n", "data_df = pd.read_json('../input/statoil-iceberg-classifier-challenge/train.json')"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5494e966-a3c4-45a3-bceb-f6a915b56741", "_uuid": "cd060d4a32dd3de00424dd31c36bf2bb2d55a107"}, "source": ["# Remove noise and save the images in new columns, ch1 and ch2. \n", "# Add another new column, ch3, which is the sum of band1 and band2 data.\n", "# This step is time consuming!!\n", "data_df = pd.concat([data_df, pd.DataFrame(columns = ['band3'], dtype='object')])\n", "for row in range(0,len(data_df)):\n", "    arr1 = np.array(data_df.loc[row,'band_1'])\n", "    arr2 = np.array(data_df.loc[row,'band_2'])\n", "    data_df.at[row,'band3'] = noise_removal(arr1 + arr2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6523ae58-6188-4396-abca-12be25835615", "_uuid": "98d05a506e2142f3841216e8f04b8fb92c7976db"}, "source": ["#plot the raw data in 2-D images\n", "fig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\n", "for d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n", "    raw1 = np.array(data_df.loc[d, 'band_1']).reshape(75,75)\n", "    title = data_df.loc[d, 'is_iceberg']\n", "    img_plot(raw1, ax, title)\n", "\n", "plt.tight_layout(pad=-1.2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fdb919fe-6ffa-46fd-aa4d-bdac47df637e", "_uuid": "77b2da60b3c95f4a22ced0132c563ff3110cf8b8"}, "source": ["#plot the denoised \"band3\" images.\n", "fig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\n", "for d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n", "    ch3 = data_df.loc[d, 'band3']\n", "    title = data_df.loc[d, 'is_iceberg']\n", "    img_plot(ch3, ax, title)\n", "\n", "plt.tight_layout(pad=-1.2)"]}, {"source": ["Some images contain more than one object. It would be better to remove the contaminating objects which are mostly like near the edges of the images."], "cell_type": "markdown", "metadata": {"_cell_guid": "f68894e7-b0fc-4f60-9064-fd17e102ed94", "_uuid": "402bd6dbe9eecb0aff27c866a2137a6f89a67673"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "2c494074-7162-4eac-8b17-2e2c84c324af", "_uuid": "bf301c0824c5f3bb4ddd705cc136d05a33c51e7d"}, "source": ["#Define a function to get the centroid of a contour.\n", "#The centroid can be used to determined if a contour is too close to the edges of the image.\n", "def get_center(contour):\n", "    M = cv2.moments(contour)\n", "    if M[\"m00\"] != 0:\n", "        cX, cY = int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]) \n", "    else:\n", "        cX, cY = 0, 0 \n", "    return(cX, cY)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "f006eb91-d8fc-41da-b137-5e831a08f54d", "_uuid": "2c986ca1cfe3c4c2a89f7ba85ed2b53f94cbfc30"}, "source": ["#Define a function to list and remove all contours that are too close to the edges of the image.\n", "#If all contours are close to the edges (no central object), no contour will be removed.\n", "def get_central_cnts(cnts_lst):\n", "    edge_lst = []\n", "    central_lst = []\n", "    for c in cnts_lst:\n", "        cX, cY = get_center(c)\n", "        if cX < 15 or cX > 60 or cY < 15 or cY > 60:\n", "            edge_lst.append(c)\n", "        else:\n", "            central_lst.append(c)\n", "    \n", "    #If there is no central object, do not remove any object near the edges.\n", "    if (len(edge_lst) == len(cnts_lst)) and (len(central_lst) == 0):\n", "        edge_lst = []\n", "        central_lst = cnts_lst\n", "    \n", "    return(central_lst, edge_lst)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "b94a405a-2b07-4f51-9761-13bbc65e65b9", "_uuid": "19857eef64aeb4efa85161d38cd764feeae1cc62"}, "source": ["#Define a function to find contours and create masks.\n", "def cnt_to_mask(binary_image):\n", "    #Find contours in the binary image.\n", "    _, cnts, _ = cv2.findContours(binary_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n", "    if len(cnts) == 0:\n", "        print('No contour is found!')\n", "    \n", "    #Create a mask and draw the contours on the mask to record the background coordinates.\n", "    mask_bg = np.zeros((75,75), dtype='uint8')\n", "    for c in cnts:\n", "        cv2.drawContours(mask_bg, [c], -1, 1, -1)\n", "    \n", "    #Remove the contours that are too close to the edges.\n", "    cnts_clean, cnts_edge = get_central_cnts(cnts)\n", "    \n", "    #Create a mask and draw the cleaned contours on the mask to record the foreground coordinates.\n", "    mask_fg = np.zeros((75,75), dtype='uint8')\n", "    for c in cnts_clean:\n", "        cv2.drawContours(mask_fg, [c], -1, 1, -1)\n", "    \n", "    #Create a mask and draw the edge contours on the mask to record the edge coordinates.\n", "    mask_eg = np.zeros((75,75), dtype='uint8')\n", "    for c in cnts_edge:\n", "        cv2.drawContours(mask_eg, [c], -1, 1, -1)\n", "   \n", "    return(mask_bg, mask_fg, mask_eg) "]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "a7bca7cb-f1e2-40df-b809-9e19073d4e43", "_uuid": "328604496aa56af533799e89b54e0f9b62a81219"}, "source": ["# Define a function to generate binary images and create masks.\n", "def get_mask(input_img, cutoff = filters.threshold_triangle):\n", "    #Calculate the threshold and create the binary image.\n", "    thresh = cutoff(input_img, nbins=256)   \n", "    binary_img = input_img > thresh\n", "    \n", "    #Get the masks\n", "    mask_bg, mask_fg, mask_eg = cnt_to_mask(img_as_ubyte(binary_img)) \n", "      \n", "    #If any foreground contour touches the edge, the threshold probably didn't precisely cut out the object.\n", "    #Modify the threshold, and recreate the binary image and masks.\n", "    if sum(mask_fg[0,:]) > 1 or sum(mask_fg[74,:]) > 1 or sum(mask_fg[:,0]) > 1 or sum(mask_fg[74,:]) > 1:\n", "        fg_coord = np.where(mask_fg.flatten() == 1)\n", "        fg_mean = np.mean(np.take(input_img.flatten(), fg_coord[0]))\n", "        fg_max = np.max(np.take(input_img.flatten(), fg_coord[0]))\n", "        thresh_new = thresh + (fg_max - fg_mean) / 3\n", "        binary_img_new = input_img > thresh_new\n", "        mask_bg, mask_fg, mask_eg = cnt_to_mask(img_as_ubyte(binary_img_new)) \n", "    \n", "    return(mask_bg, mask_fg, mask_eg)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "14d9e61a-92cd-40bf-b553-e37804a0140b", "_uuid": "253043c83e9fcb3e3a24ad5ea8e6df4d91d92a4d"}, "source": ["#Check if the masks can be properly created.\n", "fig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\n", "for d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n", "    mask_bg, mask_fg, mask_eg = get_mask(np.array(data_df.loc[d, 'band3']))\n", "    final = cv2.bitwise_and(data_df.loc[d, 'band3'], data_df.loc[d, 'band3'], mask=mask_fg)\n", "    title = data_df.loc[d, 'is_iceberg']\n", "    img_plot(final, ax, title)\n", "\n", "plt.tight_layout(pad=-1.2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "571cc247-0694-42a6-ad93-5a4a49808126", "_uuid": "f60508c3975a8ff991686704affac589fc1e8881"}, "source": ["#Replace the objects on the edges with mean background signal. \n", "#Save the cleaned images in new columns, band1_cl and band2_cl.\n", "data_df = pd.concat([data_df, pd.DataFrame(columns = ['band1_cl','band2_cl'], dtype='object')])\n", "for r in range(0,len(data_df)):\n", "    mask_bg, _, mask_eg = get_mask(np.array(data_df.loc[r,'band3']))    \n", "    coord_bg = np.where(mask_bg.flatten() == 0)\n", "    bg1 = np.mean(np.take(np.array(data_df.at[r,'band_1']), coord_bg[0]))\n", "    bg2 = np.mean(np.take(np.array(data_df.at[r,'band_2']), coord_bg[0]))\n", "    if np.sum(mask_eg) > 0:\n", "        coord_eg = np.where(mask_eg.flatten() == 1)\n", "        \n", "        band1 = np.array(data_df.at[r,'band_1'])\n", "        np.put(band1, coord_eg, bg1)\n", "        data_df.at[r,'band1_cl'] = band1.reshape(75,75)\n", "        \n", "        band2 = np.array(data_df.at[r,'band_2'])\n", "        np.put(band2, coord_eg, bg2)\n", "        data_df.at[r,'band2_cl'] = band2.reshape(75,75)\n", "    \n", "    else:\n", "        data_df.at[r,'band1_cl'] = np.array(data_df.at[r,'band_1']).reshape(75,75)\n", "        data_df.at[r,'band2_cl'] = np.array(data_df.at[r,'band_2']).reshape(75,75)  "]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "34ce06dd-0ec7-4a1a-b065-38b739fe11ea", "_uuid": "817e9f38fe024d96f3c5fbe376d5b40f1f9a1ab3"}, "source": ["#Check if the images are cleaned.\n", "fig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\n", "for d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n", "    image = data_df.at[d,'band1_cl']\n", "    title = data_df.loc[d, 'is_iceberg']\n", "    img_plot(image, ax, title)\n", "\n", "plt.tight_layout(pad=-1.2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "7ea5639b-3851-47db-8e65-018b1b659ea2", "_uuid": "e505ccb8ecc22bcc28b82c884d83ca6176ce9281"}, "source": ["# Now do noise_removal again using the cleaned images, and save the new images in new columns ch1-ch3.\n", "data_df = pd.concat([data_df, pd.DataFrame(columns = ['ch1','ch2','ch3'], dtype='object')])\n", "for row in range(0,len(data_df)):\n", "    arr1 = data_df.loc[row,'band1_cl']\n", "    arr2 = data_df.loc[row,'band2_cl']\n", "    data_df.at[row,'ch1'] = noise_removal(arr1)\n", "    data_df.at[row,'ch2'] = noise_removal(arr2)\n", "    data_df.at[row,'ch3'] = noise_removal(arr1 + arr2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "24fbf4bf-9a05-415f-823e-cb5b309570af", "_uuid": "9b1e25368614b28b0a66ba5f600aa2639bd483fd"}, "source": ["#plot the denoised clean ch3 images.\n", "fig, axes = plt.subplots(nrows=2, ncols=6, sharex=False, sharey=False, figsize=(12,5))\n", "for d, ax in zip([55,26,1369,1126,65,142,8,31,41,44,93,63], axes.flat):\n", "    ch3 = data_df.loc[d, 'ch3']\n", "    title = data_df.loc[d, 'is_iceberg']\n", "    img_plot(ch3, ax, title)\n", "\n", "plt.tight_layout(pad=-1.2)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "5273d368-6b49-48f2-bad1-6a35333db527", "_uuid": "2ab6e45aa084f10abc53f2d9f2b17faa0281035c"}, "source": ["#Create new masks using the newly denoised images.\n", "#Extract background and object backscattering values.\n", "#Put the values in new columns, eng1 and eng2.\n", "data_df = pd.concat([data_df, pd.DataFrame(columns = ['eng1','eng2'], dtype='float')])\n", "for r in range(0,len(data_df)):\n", "    #Create masks\n", "    mask_bg, mask_fg, _ = get_mask(data_df.loc[r,'ch3'],cutoff = filters.threshold_otsu)\n", "\n", "    #Extract backscattering signals from objects.\n", "    coord_bg = np.where(mask_bg.flatten() == 0)\n", "    coord_fg = np.where(mask_fg.flatten() == 1)\n", "    bg1 = np.mean(np.take(np.array(data_df.at[r,'band1_cl']), coord_bg[0]))\n", "    bg2 = np.mean(np.take(np.array(data_df.at[r,'band2_cl']), coord_bg[0]))\n", "    sig1 = np.take(data_df.at[r,'band1_cl'], coord_fg[0])\n", "    sig2 = np.take(data_df.at[r,'band2_cl'], coord_fg[0])\n", "    data_df.at[r,'eng1'] = np.mean(sig1) - bg1\n", "    data_df.at[r,'eng2'] = np.mean(sig2) - bg2"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "cbe32bc7-6b49-43bf-b507-de41f1ccd9e4", "_uuid": "f3fa71d565ec6c0cbafda45647b5886f00c90f56"}, "source": ["#Standardize the energy values.\n", "data_df['eng1_std'] = (data_df['eng1'] - data_df['eng1'].mean()) / data_df['eng1'].std()\n", "data_df['eng2_std'] = (data_df['eng2'] - data_df['eng2'].mean()) / data_df['eng2'].std()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "aee5d3ab-b42b-47ed-a241-bc1aaeb06678", "_uuid": "023e076a3057ef4fa277a51dbc78ada1978de10c"}, "source": ["#Pair plot the energy values to see whether they can be used for classification.\n", "g = sns.PairGrid(data=data_df, \n", "                 hue='is_iceberg', #Variables in data for different colors.\n", "                 hue_order=None, \n", "                 palette='husl', \n", "                 hue_kws={\"marker\": [\"+\", \"x\"]}, \n", "                 vars=['eng1_std','eng2_std'], #list of columns to use, otherwise use all columns\n", "                 diag_sharey=True, \n", "                 size=3, #each facet\n", "                 aspect=1, \n", "                 despine=True, \n", "                 dropna=True)\n", "    \n", "g = g.map_diag(plt.hist, edgecolor=\"black\", linewidth=0.5)\n", "g = g.map_offdiag(plt.scatter, linewidth=0.5, s=50)  \n", "g = g.add_legend()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5c1c4c62-60f7-4503-8e48-61db34ae41b8", "_uuid": "9f57cf8b912193cb0d9dd8c5d7dfc72b4d9031ce"}, "source": ["#plot a heatmap to check the multicollinearity.\n", "cmap = sns.diverging_palette(150, 10, n=9, s=90, l=50, center='light', as_cmap=True)\n", "fig, ax = plt.subplots(figsize=(4,4))\n", "sns.heatmap(data_df[['eng1_std','eng2_std']].corr(), vmin=-1, vmax=1, cmap=cmap, annot=True, square=True, ax=ax, cbar_kws={'shrink':0.7})"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "8a03410e-4562-4df9-b239-617c4b485c91", "_uuid": "2b5e5e7002eb604dab8ab68cb200a4345994d34d"}, "source": ["# Scale the images and put them in new columns.\n", "# In this case, I chose to scale them to [-1, 1].\n", "data_df = pd.concat([data_df, pd.DataFrame(columns = ['scale_111','scale_112','scale_113',\n", "                                                      'scale_b1','scale_b2','scale_b3'], dtype='object')])\n", "for row in range(0,len(data_df)):\n", "    arr1 = data_df.loc[row,'band1_cl']\n", "    arr2 = data_df.loc[row,'band2_cl']\n", "    arr3 = data_df.loc[row,'ch3']\n", "    arr_b1 = np.array(data_df.loc[row,'band_1']).reshape(75,75)\n", "    arr_b2 = np.array(data_df.loc[row,'band_2']).reshape(75,75)\n", "    arr_b3 = data_df.loc[row,'band3']\n", "    \n", "#     # Rescale the image data to 0 to 1.\n", "#     data_df.at[row,'n011'] = (arr1 - np.min(arr1))/(np.max(arr1)-np.min(arr1))\n", "#     data_df.at[row,'n012'] = (arr2 - np.min(arr2))/(np.max(arr2)-np.min(arr2))\n", "#     data_df.at[row,'n013'] = (arr3 - np.min(arr3))/(np.max(arr3)-np.min(arr3))\n", "#     data_df.at[row,'n014'] = (arr4 - np.min(arr4))/(np.max(arr4)-np.min(arr4))\n", "#     data_df.at[row,'n015'] = (arr5 - np.min(arr5))/(np.max(arr5)-np.min(arr5))\n", "    \n", "    # Rescale the image data to -1 to 1.\n", "    data_df.at[row,'scale_111'] = 2*(arr1 - np.min(arr1))/(np.max(arr1)-np.min(arr1))-1\n", "    data_df.at[row,'scale_112'] = 2*(arr2 - np.min(arr2))/(np.max(arr2)-np.min(arr2))-1\n", "    data_df.at[row,'scale_113'] = 2*(arr3 - np.min(arr3))/(np.max(arr3)-np.min(arr3))-1    \n", "    data_df.at[row,'scale_b1'] = 2*(arr_b1 - np.min(arr_b1))/(np.max(arr_b1)-np.min(arr_b1))-1\n", "    data_df.at[row,'scale_b2'] = 2*(arr_b2 - np.min(arr_b2))/(np.max(arr_b2)-np.min(arr_b2))-1  \n", "    data_df.at[row,'scale_b3'] = 2*(arr_b3 - np.min(arr_b3))/(np.max(arr_b3)-np.min(arr_b3))-1"]}, {"source": ["**Part II: Model training**"], "cell_type": "markdown", "metadata": {"_cell_guid": "0d541be0-ee55-4275-8464-004fca3f5ee9", "_uuid": "fe3a5e6c092288e2fee87f08813ad7de6a250b94"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c387ac2a-c0a3-4eb6-8265-b3e88910d40b", "_uuid": "1f5979a86785a1d9981132653dde4f2006491bec"}, "source": ["# Prepare the arrays.\n", "arr_111 = np.stack(data_df['scale_111'], axis=0)\n", "arr_112 = np.stack(data_df['scale_112'], axis=0)\n", "arr_113 = np.stack(data_df['scale_113'], axis=0)\n", "arr_b1 = np.stack(data_df['scale_b1'], axis=0)\n", "arr_b2 = np.stack(data_df['scale_b2'], axis=0)\n", "arr_b3 = np.stack(data_df['scale_b3'], axis=0)\n", "data_img = np.concatenate([arr_b1[:,:,:,np.newaxis], arr_b2[:,:,:,np.newaxis], arr_b3[:,:,:,np.newaxis]], axis=3)\n", "print(data_img.shape)\n", "data_y = np.array(data_df['is_iceberg'].astype(int))\n", "print(data_y.shape)\n", "data_feat = np.array(data_df[['eng1_std','eng2_std']].astype(float))\n", "print(data_feat.shape)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "59d29292-bd72-4d6c-95ba-203f8efe96c0", "_uuid": "dc6e83ce7404ce043f9c69399830c6ffc1f060a5"}, "source": ["# Data split into the training and test sets\n", "img_train, img_test, feat_train, feat_test, y_train, y_test = train_test_split(data_img, \n", "                                                                               data_feat,\n", "                                                                               data_y, \n", "                                                                               random_state=4, \n", "                                                                               test_size=0.25)\n", "print(img_train.shape, feat_train.shape, img_test.shape, feat_test.shape)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "1b0a6bda-21bc-49de-9f74-cdfb9e02849a", "_uuid": "ee3b469d6c7a0d3de32bff6856641fb2506bbf8d"}, "source": ["input_shape = (75, 75, 3)"]}, {"source": ["Transfer learning using VGG16, 2 inputs."], "cell_type": "markdown", "metadata": {"_cell_guid": "f8151636-f5a8-4ec8-a1e6-3f87c21a528f", "_uuid": "d115618f12966373fbf094c35876ebd9c77876d6"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "6d370d51-c562-40c6-b90e-e4f3732eea6d", "_uuid": "066c82dbcc14389f431d6a2658cfa4926b7e73cb"}, "source": ["# Define data augmentation parameters\n", "datagen_train = ImageDataGenerator(rotation_range=40.,\n", "                                   shear_range=0.,\n", "                                   zoom_range=0.,\n", "                                   width_shift_range=0.1,\n", "                                   height_shift_range=0.1,\n", "                                   vertical_flip=True,\n", "                                   horizontal_flip=True,\n", "                                   samplewise_center=False,\n", "                                   samplewise_std_normalization=False,\n", "                                   fill_mode='nearest')\n", "\n", "datagen_test = ImageDataGenerator(rotation_range=20.,\n", "                                  vertical_flip=True,\n", "                                  horizontal_flip=True,\n", "                                  samplewise_center=False,\n", "                                  samplewise_std_normalization=False)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "0858231c-8070-44ad-97f4-f15587400092", "_uuid": "aa669dbed4dc557c676247f8a06bea13531d8a9f"}, "source": ["#Define a function to make a customized data generator, combining image and non-image data.\n", "def combo_gen(gen1, gen2):\n", "    while True:\n", "        set1 = gen1.next()\n", "        set2 = gen2.next()\n", "        yield [set2[0], set2[1]], set1[1]"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "fa8c8c81-8953-4fac-abb9-59b637aa526d", "_uuid": "69436d4f9d7e762997900b44334927f5b67ad00d"}, "source": ["# Define the VGG16-derived transfer learing model.\n", "def vgg16_model_2input():\n", "    base_model = VGG16(weights=None, input_shape=input_shape, include_top=False, classes=1)\n", "    base_model.load_weights('../input/vgg16wgts/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n", "    # Fix the lower-level 7 layer (no training). \n", "    for layer in base_model.layers[0:7]:\n", "        layer.trainable = False     \n", "    for layer in base_model.layers[7:]:\n", "        layer.trainable = True   \n", "    x = base_model.get_layer('block5_pool').output\n", "    x = Flatten()(x)\n", "    # Add a second input.\n", "    eng_input = Input(shape=(2,), name=\"energy\")\n", "    combined = concatenate([x, eng_input])    \n", "    combined = Dense(512, activation='relu', name='fc1')(combined)\n", "    combined = Dropout(0.3)(combined)\n", "    combined = Dense(128, activation='relu', name='fc2')(combined)\n", "    combined = Dropout(0.3)(combined)\n", "    predictions = Dense(1, activation='sigmoid')(combined)    \n", "    combined_model = Model(inputs=[base_model.input, eng_input], outputs=predictions)\n", "    sgd = SGD(lr=0.001, decay=0.001/1000, momentum=0.9, nesterov=True)\n", "#     nadam = Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n", "#     adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n", "#     The Adam and Nadam optimizers didn't work! \n", "    combined_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n", "    return(combined_model)"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "44cbe1b6-a3e4-4ba3-94f8-cde130f676f4", "_uuid": "65e6f86aa1d872d420253e422f538eb7e4b302f7"}, "source": ["# Create data generators for both image and non-image data.\n", "batch_size = 8\n", "train_gen1 = datagen_train.flow(img_train, y_train, shuffle=False, seed=1, batch_size=batch_size)\n", "train_gen2 = datagen_train.flow(img_train, feat_train, shuffle=False, seed=1, batch_size=batch_size)\n", "test_gen1 = datagen_test.flow(img_test, y_test, shuffle=False, seed=1, batch_size=batch_size)\n", "test_gen2 = datagen_test.flow(img_test, feat_test, shuffle=False, seed=1, batch_size=batch_size)\n", "# Create customized data generators with 2 inputs.\n", "train_combo_gen = combo_gen(train_gen1, train_gen2)\n", "test_combo_gen = combo_gen(test_gen1, test_gen2)\n", "# Set up callbacks parameters. These are commonly used.\n", "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n", "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n", "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=1, epsilon=1e-4, mode='min')"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "22986a63-d3db-40d5-b524-eecb0b58149d", "scrolled": false, "_uuid": "f142dd24e1854c407f0d83ebe00e85a3f86870fb"}, "source": ["model_vgg16_2input = vgg16_model_2input()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "59f1b9ff-428f-453c-bd43-42787fe46bb5", "_uuid": "5bb73ee44328d3cf7d8e5b8dfc1e456d1f4da5c1"}, "source": ["model_vgg16_2input.fit_generator(train_combo_gen, \n", "                                 epochs=50,\n", "                                 steps_per_epoch=img_train.shape[0] // 8.0,\n", "                                 verbose=1,\n", "                                 callbacks=[earlyStopping, mcp_save, reduce_lr_loss],\n", "                                 validation_data=test_combo_gen,\n", "                                 validation_steps=img_test.shape[0] // 8.0\n", "                                 )"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0a01aacb-8d8d-4338-88b6-5636fff9f49c", "_uuid": "09a1b33beccc5278d1b25e552b7feb02e028a842"}, "source": ["model_vgg16_2input.load_weights('.mdl_wts.hdf5')\n", "print('Training scores')\n", "print(model_vgg16_2input.evaluate([img_train,feat_train], y_train))\n", "print('Testing scores')\n", "print(model_vgg16_2input.evaluate([img_test,feat_test], y_test))"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "34a0e31e-aed5-4809-9264-bf250d949b17", "_uuid": "6e559603f27b1daa44d76b40e4b28b2eca0acda6"}, "source": ["del model_vgg16_2input\n", "K.clear_session()"]}, {"execution_count": null, "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "5331b07f-9003-484d-afb8-80dd7c6c523d", "_uuid": "501c0fb4898967c0d0b831476726b46e9852e1b6"}, "source": []}]}