{"cells": [{"metadata": {"_uuid": "6abeb4f979897743dac46e2ed0ef55d6c2a49de5", "_cell_guid": "cafef477-0c56-4e61-88d7-0f4cd93f2aea"}, "source": ["This kernel is made by taking reference from Lisa's kernel and using external data \n", "available at https://github.com/rwsproat/text-normalization-data (the link is also mentioned\n", "under discussion tab).\n"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8d0cd9618d70d2ca5d5f9f2d77bdc093875d5bc8", "_cell_guid": "2c9bfde7-71ac-48b9-8e81-cb67da48b948"}, "source": ["Since the external data is very large and took long time to run, here is the dictionary.npy generated from https://github.com/rwsproat/text-normalization-data \n", "\n", "(The ouput simply generated from this dictionary is also attached.)\n", "\n", "Hope this can save you time and help with research."], "cell_type": "markdown"}, {"metadata": {"_uuid": "2bff020a3a280162d674d6ce4ceb28f028fd7b67", "collapsed": true, "_cell_guid": "832eaa23-fa05-475f-9d09-7aa6db6e4ef3"}, "source": ["**How to use:**\n", "   - **download and unzip en_norm_dict.npy (may take 2 min)**\n", "   - **load the dictionary into python using the following code:**\n", "    "], "cell_type": "markdown"}, {"source": ["dict = np.load('en_norm_dict.npy').item()\n"], "metadata": {"_uuid": "78c586a8925a50291709ab92b8e72afafbb22c66", "collapsed": true, "_cell_guid": "ca592b86-3cd7-4cbd-8c63-9a553e7b2eb5"}, "outputs": [], "execution_count": null, "cell_type": "code"}, {"source": ["# # This Python 3 environment comes with many helpful analytics libraries installed\n", "# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# # For example, here's several helpful packages to load in \n", "# '''\n", "# This kernel is made by taking reference from Lisa's kernel and using external data \n", "# available at https://github.com/rwsproat/text-normalization-data (the link is also mentioned\n", "# under discussion tab).\n", "\n", "# You can add other functions along with this to improve your score.\n", "\n", "# Note: The external dataset is huge and it will take a little more time to run.\n", "# '''\n", "# import numpy as np # linear algebra\n", "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "# import operator\n", "# import glob\n", "# import os\n", "# import gc\n", "# # Input data files are available in the \"../input/\" directory.\n", "# # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "# from subprocess import check_output\n", "# print(check_output([\"ls\", \"/Users/SONGZIZHEN/Desktop/kaggle/english_normalization\"]).decode(\"utf8\"))\n", "\n", "# # Any results you write to the current directory are saved as output.\n", "\n", "\n", "\n", "\n", "# INPUT_PATH = \"/Users/SONGZIZHEN/Desktop/kaggle/english_normalization\"\n", "# SUBM_PATH = INPUT_PATH\n", "# DATA_INPUT_PATH = \"/Users/SONGZIZHEN/Desktop/kaggle/english_normalization/en_with_types\"\n", "# print(glob.glob(INPUT_PATH + '*'))\n", "# symbols = ['km', 'km2', 'km\u00b2', 'mm', 'Hz', 'mi', 'cm', 'ft', 'm', 'kg', 'm3', 'MB', 'm2', 'mg', 'yd', 'ha']\n", "\n", "\n", "# print('Train start...')\n", "# train = open(INPUT_PATH + \"/en_train.csv\")\n", "# line = train.readline()\n", "# res = dict()\n", "# total = 0\n", "# not_same = 0\n", "# while 1:\n", "#     line = train.readline().strip()\n", "#     if line == '':\n", "#         break\n", "#     total += 1\n", "#     pos = line.find('\",\"')\n", "#     text = line[pos + 2:]\n", "#     if text[:3] == '\",\"':\n", "#         continue\n", "#     text = text[1:-1]\n", "#     arr = text.split('\",\"')\n", "#     if arr[0] != arr[1]:\n", "#         not_same += 1\n", "#     if arr[0] not in res:\n", "#         res[arr[0]] = dict()\n", "#         res[arr[0]][arr[1]] = 1\n", "#     else:\n", "#         if arr[1] in res[arr[0]]:\n", "#             res[arr[0]][arr[1]] += 1\n", "#         else:\n", "#             res[arr[0]][arr[1]] = 1\n", "\n", "# train.close()\n", "# print('Total: {} Have diff value: {}'.format(total, not_same))\n", "\n", "\n", "# files = os.listdir(DATA_INPUT_PATH)\n", "# for file in files:\n", "#     train = open(os.path.join(DATA_INPUT_PATH, file))\n", "#     while 1:\n", "#         line = train.readline().strip()\n", "#         if line == '':\n", "#             break\n", "#         total += 1\n", "#         pos = line.find('\\t')\n", "#         text = line[pos + 1:]\n", "#         if text[:3] == '':\n", "#             continue\n", "#         arr = text.split('\\t')\n", "#         if arr[0] == '<eos>':\n", "#             continue\n", "#         if arr[1] != '<self>':\n", "#             not_same += 1\n", "\n", "#         if arr[1] == '<self>' or arr[1] == 'sil':\n", "#             arr[1] = arr[0]\n", "\n", "#         if arr[1] == '<self>' or arr[1] == 'sil':\n", "#             arr[1] = arr[0]\n", "\n", "#         if arr[0] not in res:\n", "#             res[arr[0]] = dict()\n", "#             res[arr[0]][arr[1]] = 1\n", "#         else:\n", "#             if arr[1] in res[arr[0]]:\n", "#                 res[arr[0]][arr[1]] += 1\n", "#             else:\n", "#                 res[arr[0]][arr[1]] = 1\n", "#     train.close()\n", "#     print(file + ':\\tTotal: {} Have diff value: {}'.format(total, not_same))\n", "#     gc.collect()\n", "\n", "\n", "# total = 0\n", "# changes = 0\n", "# out = open(SUBM_PATH + '/sub_text_v1.csv', \"w\")\n", "# out.write('\"id\",\"after\"\\n')\n", "# test = open(INPUT_PATH + \"/en_test_2.csv\")\n", "# line = test.readline().strip()\n", "\n", "# while 1:\n", "#     line = test.readline().strip()\n", "#     if line == '':\n", "#         break\n", "\n", "#     pos = line.find(',')\n", "#     i1 = line[:pos]\n", "#     line = line[pos + 1:]\n", "\n", "#     pos = line.find(',')\n", "#     i2 = line[:pos]\n", "#     line = line[pos + 1:]\n", "\n", "#     line = line[1:-1]\n", "#     out.write('\"' + i1 + '_' + i2 + '\",')\n", "#     if line in res:\n", "#         srtd = sorted(res[line].items(), key=operator.itemgetter(1), reverse=True)\n", "#         out.write('\"' + srtd[0][0] + '\"')\n", "#         changes += 1\n", "#     elif any(str.isdigit(c) for c in line) and any(s in line for s in symbols):\n", "#         l = line.split(' ')\n", "#         if l[0] in res:\n", "#             srtd = sorted(res[l[0]].items(), key=operator.itemgetter(1), reverse=True)\n", "#             num = srtd[0][0]\n", "#             if l[1] == 'km': sy = 'kilometers'\n", "#             elif l[1] == 'km2' or l[1] == 'km\u00b2': sy = 'square kilometers'\n", "#             elif l[1] == 'mm': sy = 'millimeters'\n", "#             elif l[1] == 'Hz': sy = 'hertz'\n", "#             elif l[1] == 'mi': sy = 'miles'\n", "#             elif l[1] == 'cm': sy = 'centimeters'\n", "#             elif l[1] == 'm': sy = 'meters'\n", "#             elif l[1] == 'ft': sy = 'feet'\n", "#             elif l[1] == 'kg': sy = 'kilograms'\n", "#             elif l[1] == 'm3': sy = 'cubic meters'\n", "#             elif l[1] == 'MB': sy = 'centimeters'\n", "#             elif l[1] == 'm2': sy = 'square meters'\n", "#             elif l[1] == 'mg': sy = 'milligrams'\n", "#             elif l[1] == 'yd': sy = 'yards'\n", "#             elif l[1] == 'ha': sy = 'hectares'\n", "#             else: sy = ''\n", "#             out.write('\"' + num + \" \" + sy + '\"')\n", "#             changes += 1\n", "#     else:\n", "#         out.write('\"' + line + '\"')\n", "\n", "#     out.write('\\n')\n", "#     total += 1\n", "\n", "# print('Total: {} Changed: {}'.format(total, changes))\n", "# test.close()\n", "# out.close()\n"], "metadata": {"_uuid": "b900e37cd3a6ea36d950a3f2e880f0fdeb147c56", "collapsed": true, "_cell_guid": "1a7c0155-8777-4ea0-9109-6ccd423cbbdf"}, "outputs": [], "execution_count": null, "cell_type": "code"}], "metadata": {"language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1, "nbformat": 4}