{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c8a79fb4-ec84-cf68-f9e6-04ade62d6eed"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def warn(*args, **kwargs): pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cross_validation import StratifiedShuffleSplit\n",
        "\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "\n",
        "def preprocess(train,test):\n",
        "    trainlb=LabelEncoder().fit(train['species']).transform(train['species'])\n",
        "    classes=list(LabelEncoder().fit(train['species']).classes_)\n",
        "    testid=test['id']\n",
        "    trainid=train['id']\n",
        "    return(train[list(train.columns.values)[2:]],\\\n",
        "           test[list(train.columns.values)[2:]],trainlb,trainid,testid,classes)\n",
        "train,test,trainlb,trainid,testid,classes=preprocess(train,test)\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2680342-fc58-1922-a416-0ae9e472e610"
      },
      "outputs": [],
      "source": [
        "sss = StratifiedShuffleSplit(trainlb, test_size=.1, random_state=23)\n",
        "\n",
        "for train_index, test_index in sss:\n",
        "    tr=train_index\n",
        "    te=test_index\n",
        "\n",
        "xtr, xte = train.ix[train_index], train.ix[test_index]\n",
        "ytr, yte = trainlb[train_index], trainlb[test_index]\n",
        "trid, teid = trainid[train_index], trainid[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8de0d186-a8d2-0008-afc5-4b26042b6b32"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "def resize_img(img,size):\n",
        "    if img.size[0]>img.size[1]:\n",
        "        return img.resize((size, int(img.size[1]/img.size[0]*size)))\n",
        "    else:\n",
        "        return img.resize((int(img.size[0]/img.size[1]*size), size))\n",
        "    \n",
        "def resizeimg(img,size):\n",
        "    x=np.repeat(0,size**2).reshape(size,size,1)\n",
        "    temp = resize_img(img, size=size)\n",
        "    temp=img_to_array(temp)\n",
        "    w=temp.shape[1]\n",
        "    h=temp.shape[0]\n",
        "    h1=int((size-h)/2)\n",
        "    w1=int((size-w)/2)\n",
        "    x[h1:(h1+h),w1:(w1+w),:]=temp\n",
        "    return(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc7452ef-5d64-2755-a8b8-0eba55dff62a"
      },
      "outputs": [],
      "source": [
        "def loaddata(trid,teid,size):\n",
        "    xtr=np.repeat(0,len(trid)*size*size).reshape(len(trid),size,size,1)\n",
        "    xte=np.repeat(0,len(teid)*size*size).reshape(len(teid),size,size,1)\n",
        "    for i in range(len(trid)):\n",
        "        img=load_img('../input/images/'+'%d'%trid[i]+'.jpg',grayscale=True)\n",
        "        xtr[i,:,:,:]=resizeimg(img,size)\n",
        "    for i in range(len(teid)):\n",
        "        img=load_img('../input/images/'+'%d'%trid[i]+'.jpg',grayscale=True)\n",
        "        xte[i,:,:,:]=resizeimg(img,size)\n",
        "    return(xtr,xte)\n",
        "size=96\n",
        "xtr,xte=loaddata(trid.values.ravel(),teid.values.ravel(),size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9de6bcf0-5aaf-6745-fece-968fdc2494fa"
      },
      "outputs": [],
      "source": [
        "xtrs=np.around(xtr/255)\n",
        "xtes=np.around(xte/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5198dc2-2cdc-0035-9046-af87ca864be0"
      },
      "outputs": [],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "ytrc = to_categorical(ytr)\n",
        "ytec = to_categorical(yte)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e869ab0-0206-8744-2d2a-dcb5d96cc91a"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, merge\n",
        "\n",
        "ipt=Input(shape=(size,size,1),name='image')\n",
        "\n",
        "c1=Convolution2D(8,5,5,input_shape=(size,size,1),border_mode='same')(ipt)\n",
        "c1=(Activation('relu'))(c1)\n",
        "p1=(MaxPooling2D(pool_size=(2,2),strides=(2,2)))(c1)\n",
        "\n",
        "c2=Convolution2D(32,5,5,input_shape=(size,size,1),border_mode='same')(p1)\n",
        "c2=(Activation('relu'))(c2)\n",
        "p2=(MaxPooling2D(pool_size=(2,2),strides=(2,2)))(c2)\n",
        "\n",
        "f1=Flatten()(p2)\n",
        "fc1=Dense(128,activation='relu')(f1)\n",
        "fc1=Dropout(.5)(fc1)\n",
        "\n",
        "out=Dense(99,activation='softmax')(fc1)\n",
        "model=Model(input=[ipt],output=out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36f1b8d7-a0b3-710a-d5b1-8cbc1a3d8384"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
        "\n",
        "# A little hacky piece of code to get access to the indices of the images\n",
        "# the data augmenter is working with.\n",
        "class ImageDataGenerator2(ImageDataGenerator):\n",
        "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
        "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
        "        return NumpyArrayIterator2(\n",
        "            X, y, self,\n",
        "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
        "            dim_ordering=self.dim_ordering,\n",
        "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
        "\n",
        "\n",
        "class NumpyArrayIterator2(NumpyArrayIterator):\n",
        "    def next(self):\n",
        "        # for python 2.x.\n",
        "        # Keeps under lock only the mechanism which advances\n",
        "        # the indexing of each batch\n",
        "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
        "        with self.lock:\n",
        "            # We changed index_array to self.index_array\n",
        "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "        # The transformation of images is not under thread lock so it can be done in parallel\n",
        "        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n",
        "        for i, j in enumerate(self.index_array):\n",
        "            x = self.X[j]\n",
        "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
        "            x = self.image_data_generator.standardize(x)\n",
        "            batch_x[i] = x\n",
        "        if self.save_to_dir:\n",
        "            for i in range(current_batch_size):\n",
        "                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
        "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
        "                                                                  index=current_index + i,\n",
        "                                                                  hash=np.random.randint(1e4),\n",
        "                                                                  format=self.save_format)\n",
        "                img.save(os.path.join(self.save_to_dir, fname))\n",
        "        if self.y is None:\n",
        "            return batch_x\n",
        "        batch_y = self.y[self.index_array]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "print('Creating Data Augmenter...')\n",
        "imgen = ImageDataGenerator2(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "imgen_train = imgen.flow(xtr, ytrc, seed=0)\n",
        "print('Finished making data augmenter...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1361d9f9-5b16-d9f2-3d6f-2d4f68156044"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def combined_generator(imgen, length):\n",
        "    \"\"\"\n",
        "    A generator to train our keras neural network. It\n",
        "    takes the image augmenter generator and the array\n",
        "    of the pre-extracted features.\n",
        "    It yields a minibatch and will run indefinitely\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        for i in range(length):\n",
        "            # Get the image batch and labels\n",
        "            batch_img, batch_y = next(imgen)\n",
        "            # This is where that change to the source code we\n",
        "            # made will come in handy. We can now access the indicies\n",
        "            # of the images that imgen gave us.\n",
        "            yield [batch_img], batch_y\n",
        "\n",
        "# autosave best Model\n",
        "best_model_file = \"leafnet.h5\"\n",
        "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "print('Training model...')\n",
        "history = model.fit_generator(combined_generator(imgen_train, xtr.shape[0]),\n",
        "                              samples_per_epoch=xtr.shape[0],\n",
        "                              nb_epoch=5,\n",
        "                              validation_data=([xte], ytec),\n",
        "                              nb_val_samples=xte.shape[0],\n",
        "                              verbose=0,\n",
        "                              callbacks=[best_model])\n",
        "\n",
        "print('Loading the best model...')\n",
        "model = load_model(best_model_file)\n",
        "print('Best Model loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d271437e-d191-d0b4-ad5d-7d0415e90f7f"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f1d76ca-47e1-5127-8745-8c577d5ecbb2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# If you want to use Theano, all you need to change\n",
        "# is the dim ordering whenever you are dealing with\n",
        "# the image array. Instead of\n",
        "# (samples, rows, cols, channels) it should be\n",
        "# (samples, channels, rows, cols)\n",
        "\n",
        "# Keras stuff\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# A large amount of the data loading code is based on najeebkhan's kernel\n",
        "# Check it out at https://www.kaggle.com/najeebkhan/leaf-classification/neural-network-through-keras\n",
        "root = '../input'\n",
        "np.random.seed(2016)\n",
        "split_random_state = 7\n",
        "split = .9\n",
        "\n",
        "\n",
        "def load_numeric_training(standardize=True):\n",
        "    \"\"\"\n",
        "    Loads the pre-extracted features for the training data\n",
        "    and returns a tuple of the image ids, the data, and the labels\n",
        "    \"\"\"\n",
        "    # Read data from the CSV file\n",
        "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
        "    ID = data.pop('id')\n",
        "\n",
        "    # Since the labels are textual, so we encode them categorically\n",
        "    y = data.pop('species')\n",
        "    y = LabelEncoder().fit(y).transform(y)\n",
        "    # standardize the data by setting the mean to 0 and std to 1\n",
        "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
        "\n",
        "    return ID, X, y\n",
        "\n",
        "\n",
        "def load_numeric_test(standardize=True):\n",
        "    \"\"\"\n",
        "    Loads the pre-extracted features for the test data\n",
        "    and returns a tuple of the image ids, the data\n",
        "    \"\"\"\n",
        "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n",
        "    ID = test.pop('id')\n",
        "    # standardize the data by setting the mean to 0 and std to 1\n",
        "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
        "    return ID, test\n",
        "\n",
        "\n",
        "def resize_img(img, max_dim=96):\n",
        "    \"\"\"\n",
        "    Resize the image to so the maximum side is of size max_dim\n",
        "    Returns a new image of the right size\n",
        "    \"\"\"\n",
        "    # Get the axis with the larger dimension\n",
        "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
        "    # Scale both axes so the image's largest dimension is max_dim\n",
        "    scale = max_dim / float(img.size[max_ax])\n",
        "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
        "\n",
        "\n",
        "def load_image_data(ids, max_dim=96, center=True):\n",
        "    \"\"\"\n",
        "    Takes as input an array of image ids and loads the images as numpy\n",
        "    arrays with the images resized so the longest side is max-dim length.\n",
        "    If center is True, then will place the image in the center of\n",
        "    the output array, otherwise it will be placed at the top-left corner.\n",
        "    \"\"\"\n",
        "    # Initialize the output array\n",
        "    # NOTE: Theano users comment line below and\n",
        "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
        "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n",
        "    for i, idee in enumerate(ids):\n",
        "        # Turn the image into an array\n",
        "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
        "        x = img_to_array(x)\n",
        "        # Get the corners of the bounding box for the image\n",
        "        # NOTE: Theano users comment the two lines below and\n",
        "        length = x.shape[0]\n",
        "        width = x.shape[1]\n",
        "        # length = x.shape[1] # uncomment this\n",
        "        # width = x.shape[2] # uncomment this\n",
        "        if center:\n",
        "            h1 = int((max_dim - length) / 2)\n",
        "            h2 = h1 + length\n",
        "            w1 = int((max_dim - width) / 2)\n",
        "            w2 = w1 + width\n",
        "        else:\n",
        "            h1, w1 = 0, 0\n",
        "            h2, w2 = (length, width)\n",
        "        # Insert into image matrix\n",
        "        # NOTE: Theano users comment line below and\n",
        "        X[i, h1:h2, w1:w2, 0:1] = x\n",
        "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n",
        "    # Scale the array values so they are between 0 and 1\n",
        "    return np.around(X / 255.0)\n",
        "\n",
        "\n",
        "def load_train_data(split=split, random_state=None):\n",
        "    \"\"\"\n",
        "    Loads the pre-extracted feature and image training data and\n",
        "    splits them into training and cross-validation.\n",
        "    Returns one tuple for the training data and one for the validation\n",
        "    data. Each tuple is in the order pre-extracted features, images,\n",
        "    and labels.\n",
        "    \"\"\"\n",
        "    # Load the pre-extracted features\n",
        "    ID, X_num_tr, y = load_numeric_training()\n",
        "    # Load the image data\n",
        "    X_img_tr = load_image_data(ID)\n",
        "    # Split them into validation and cross-validation\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
        "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
        "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
        "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
        "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
        "\n",
        "\n",
        "def load_test_data():\n",
        "    \"\"\"\n",
        "    Loads the pre-extracted feature and image test data.\n",
        "    Returns a tuple in the order ids, pre-extracted features,\n",
        "    and images.\n",
        "    \"\"\"\n",
        "    # Load the pre-extracted features\n",
        "    ID, X_num_te = load_numeric_test()\n",
        "    # Load the image data\n",
        "    X_img_te = load_image_data(ID)\n",
        "    return ID, X_num_te, X_img_te\n",
        "\n",
        "print('Loading the training data...')\n",
        "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
        "y_tr_cat = to_categorical(y_tr)\n",
        "y_val_cat = to_categorical(y_val)\n",
        "print('Training data loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2b4514f8-dbd5-fe0a-d482-b54770356c1f"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
        "\n",
        "# A little hacky piece of code to get access to the indices of the images\n",
        "# the data augmenter is working with.\n",
        "class ImageDataGenerator2(ImageDataGenerator):\n",
        "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
        "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
        "        return NumpyArrayIterator2(\n",
        "            X, y, self,\n",
        "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
        "            dim_ordering=self.dim_ordering,\n",
        "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
        "\n",
        "\n",
        "class NumpyArrayIterator2(NumpyArrayIterator):\n",
        "    def next(self):\n",
        "        # for python 2.x.\n",
        "        # Keeps under lock only the mechanism which advances\n",
        "        # the indexing of each batch\n",
        "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
        "        with self.lock:\n",
        "            # We changed index_array to self.index_array\n",
        "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
        "        # The transformation of images is not under thread lock so it can be done in parallel\n",
        "        batch_x = np.zeros(tuple([current_batch_size] + list(self.X.shape)[1:]))\n",
        "        for i, j in enumerate(self.index_array):\n",
        "            x = self.X[j]\n",
        "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
        "            x = self.image_data_generator.standardize(x)\n",
        "            batch_x[i] = x\n",
        "        if self.save_to_dir:\n",
        "            for i in range(current_batch_size):\n",
        "                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
        "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
        "                                                                  index=current_index + i,\n",
        "                                                                  hash=np.random.randint(1e4),\n",
        "                                                                  format=self.save_format)\n",
        "                img.save(os.path.join(self.save_to_dir, fname))\n",
        "        if self.y is None:\n",
        "            return batch_x\n",
        "        batch_y = self.y[self.index_array]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "print('Creating Data Augmenter...')\n",
        "imgen = ImageDataGenerator2(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest')\n",
        "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
        "print('Finished making data augmenter...')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4548bcf1-3fe9-3f87-fb4a-7a343d5a98fb"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def combined_generator(imgen, X):\n",
        "    \"\"\"\n",
        "    A generator to train our keras neural network. It\n",
        "    takes the image augmenter generator and the array\n",
        "    of the pre-extracted features.\n",
        "    It yields a minibatch and will run indefinitely\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        for i in range(X.shape[0]):\n",
        "            # Get the image batch and labels\n",
        "            batch_img, batch_y = next(imgen)\n",
        "            # This is where that change to the source code we\n",
        "            # made will come in handy. We can now access the indicies\n",
        "            # of the images that imgen gave us.\n",
        "            x = X[imgen.index_array]\n",
        "            yield [batch_img], batch_y\n",
        "\n",
        "# autosave best Model\n",
        "best_model_file = \"leafnet.h5\"\n",
        "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "print('Training model...')\n",
        "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
        "                              samples_per_epoch=X_num_tr.shape[0],\n",
        "                              nb_epoch=5,\n",
        "                              validation_data=([X_img_val], y_val_cat),\n",
        "                              nb_val_samples=X_num_val.shape[0],\n",
        "                              verbose=0,\n",
        "                              callbacks=[best_model])\n",
        "\n",
        "print('Loading the best model...')\n",
        "model = load_model(best_model_file)\n",
        "print('Best Model loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ebd00dff-425b-3dc7-9f26-13460b87d031"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "def combined_generator(imgen, X):\n",
        "    \"\"\"\n",
        "    A generator to train our keras neural network. It\n",
        "    takes the image augmenter generator and the array\n",
        "    of the pre-extracted features.\n",
        "    It yields a minibatch and will run indefinitely\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        for i in range(X.shape[0]):\n",
        "            # Get the image batch and labels\n",
        "            batch_img, batch_y = next(imgen)\n",
        "            # This is where that change to the source code we\n",
        "            # made will come in handy. We can now access the indicies\n",
        "            # of the images that imgen gave us.\n",
        "            x = X[imgen.index_array]\n",
        "            yield [batch_img], batch_y\n",
        "\n",
        "# autosave best Model\n",
        "best_model_file = \"leafnet.h5\"\n",
        "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "print('Training model...')\n",
        "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
        "                              samples_per_epoch=X_num_tr.shape[0],\n",
        "                              nb_epoch=5,\n",
        "                              validation_data=([xte], ytec),\n",
        "                              nb_val_samples=X_num_val.shape[0],\n",
        "                              verbose=0,\n",
        "                              callbacks=[best_model])\n",
        "\n",
        "print('Loading the best model...')\n",
        "model = load_model(best_model_file)\n",
        "print('Best Model loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e008acdf-862e-6d8b-3dd3-38539d3f3336"
      },
      "outputs": [],
      "source": [
        "xtr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b426698-e409-bf17-cfeb-7f19eece5978"
      },
      "outputs": [],
      "source": [
        "xte.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8750b3c0-9b6e-4ae0-5629-ebcbb60e71cd"
      },
      "outputs": [],
      "source": [
        "X_num_tr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d98a991e-d6fa-c307-7aae-e9460f73ee08"
      },
      "outputs": [],
      "source": [
        "X_img_tr.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "550eb4f3-0673-d1d1-3f86-1440f80e2699"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(xtr[0,:,:,0])\n",
        "plt.show()\n",
        "plt.imshow(X_img_tr[0,:,:,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "074c94fc-077e-e44c-ef45-a472d2fc7403"
      },
      "outputs": [],
      "source": [
        "X_img_tr[0,50,50,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4fa91e25-1976-2438-1531-b45e3582fe38"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}