{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"Hi Kagglers ! \n\nThis is a notebook to test what you can do in a few minutes with h2o's migthy GBM. I also included some basic grid search and early stopping to make the model more competitive. There is no CV in this kernel, I simply used a train/validation split framework. Unfortunately h2o does not allow you to correct for stratification when splitting (to my knowledge), so I rather used sklearn splitting function. \n\nA neat feature is that you can keep an eye on the scoring history along the training with scoring_history() function on many metrics of interest, not only AUC ROC.\n\nFeel free to comment, fork and upvote, happy kaggling, Cheers!\n"},{"metadata":{"_uuid":"e8291062be900495f0c3943501050c6b7f9a57c4"},"cell_type":"markdown","source":"# Contents\n1. [Start h2o and load the data](#step1)\n2. [Define a grid and train](#step2)\n3. [Best model](#step3)\n4. [Submission](#step4)\n"},{"metadata":{"_uuid":"7bbcaea6dc24eb2ae51368c1157700d2a26df9c7"},"cell_type":"markdown","source":"## Start h2o and load the data  <a name=\"step1\"></a>\n\nStart the h2o cluster and load train, validation and test datasets as h2oFrames. \n\nTrain/Validation split is done with sklearn function, to correct for stratification on the target column."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.grid.grid_search import H2OGridSearch\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport os, gc\nprint(os.listdir(\"../input\"))\n\nh2o.init()\n\ntrain_df = pd.read_csv(\"../input/train.csv\")\nvalid_rate = .15\ntrain_df, valid_df, tr_y, va_y = train_test_split(train_df, train_df['target'], stratify = train_df['target'], test_size=valid_rate, random_state = 42)\n\ntrain = h2o.H2OFrame(train_df)\nvalid = h2o.H2OFrame(valid_df)\ntest = h2o.import_file(\"../input/test.csv\")\n\nimport gc\ndel train_df, valid_df, tr_y, va_y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"288fffa0d416d5b6b6a027fa5dd5fa95c5da3b9c"},"cell_type":"code","source":"y = 'target'\nx = train.columns[2:]\ntrain[y] = train[y].asfactor()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cd443324648a3f3a8cce7c552ea0bc26e23b986"},"cell_type":"markdown","source":"## Define a grid and train  <a name=\"step2\"></a>\n\nWith the RandomDiscrete strategy you test *n_models*, with parameters randomly chosen from the grid. \n\n2500 trees should be enough here to reach the early stopping *AUC* criteria on the validation frame."},{"metadata":{"trusted":true,"_uuid":"422e7334d758e45497f14563b17dc06640d18d2b"},"cell_type":"code","source":"# CHANGE THIS PARAMETER to test as many models as you wish\nn_models = 8\ngrid_params = {\n    'max_depth': [2, 3],\n    'col_sample_rate': [.6, .7],\n    'learn_rate': [.09, .1],\n    'learn_rate_annealing': [1],\n    'min_rows': [110, 90],\n    'sample_rate': [.7]\n}\n\ngbm_grid = H2OGridSearch(model=h2o.estimators.H2OGradientBoostingEstimator,\n                grid_id='gbm_grid', \n                hyper_params=grid_params,\n                search_criteria={'strategy': 'RandomDiscrete', 'max_models': n_models})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"79066c8a75101497e6bad4b34fc7e8ec37ab99f4"},"cell_type":"code","source":"gbm_grid.train(x=x, y=y, training_frame=train, validation_frame=valid,\n            distribution='bernoulli',\n            ntrees=2500,\n            score_tree_interval = 20,\n            stopping_rounds = 4,\n            stopping_metric = \"AUC\",\n            stopping_tolerance = 1e-4,\n            seed = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58bd5965789381d53002332f166ada1445dea632"},"cell_type":"markdown","source":"## Best model  <a name=\"step3\"></a>\n\nNow sort the models of the grid from decreasing order on the *auc* criteria, and keep the first. You can check what are the parameters that were used to reach the best score. A detailed history on the different metrics is informative, especially for the *AUC* of the Precision Recall curve since target column is not balanced. "},{"metadata":{"trusted":true,"_uuid":"e1d33aae21cc9f4f776294fc31a9389f4e140808"},"cell_type":"code","source":"\ngridperf = gbm_grid.get_grid(sort_by='auc', decreasing=True)\nbest_model = gridperf.models[0]\nfor par in grid_params:\n    if par in best_model.params:\n        print('par: ' + par); print(best_model.params[par])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d450680226c61f8df61cebfe3e7a92d73f3d13c"},"cell_type":"code","source":"best_model.scoring_history()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"394d1d810731a7438c398c3d29ec95fa535f0ead"},"cell_type":"code","source":"history = pd.DataFrame(best_model.scoring_history())\nhistory.plot(x='number_of_trees', y = ['validation_auc', 'validation_pr_auc'])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"138804bbd7dd014975f2cce47fb12e2e6866a04f"},"cell_type":"markdown","source":"## Submission  <a name=\"step4\"></a>\n\nHere's your submission csv that should get you a LB score around .897 ! "},{"metadata":{"trusted":true,"_uuid":"8050e503d3becb72bdbbab1cbbe24db2540ae863"},"cell_type":"code","source":"preds = best_model.predict(test)\nsubmission = pd.read_csv('../input/sample_submission.csv')\nsubmission['target'] = preds['p1'].as_data_frame()\nsubmission.to_csv('gbm_submission.csv', index = False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}