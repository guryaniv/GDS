{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dfcd3eed-f542-496f-2f6c-5e365c9ca09f"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b93799a9-e8b2-3384-61cd-9e7f366574c8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv')\n",
        "df_test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "87f2b3fa-44d9-b446-4edf-3ae0fbef15d1"
      },
      "outputs": [],
      "source": [
        "print(df_train.info())\n",
        "print(df_test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3e7e8f0e-e992-9c90-f511-538687fa6098"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "def WordMatch(row):\n",
        "    q1 = set(str(row['question1']).split())\n",
        "    q2 = set(str(row['question2']).split())\n",
        "    a = len(q1.union(q2).difference(stops))\n",
        "    if (a == 0):\n",
        "        return 0\n",
        "    else:\n",
        "        return (len(q1.intersection(q2).difference(stops)) + .0) / a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ac4b3500-c7b5-6387-d71f-a3d5c290cb43"
      },
      "outputs": [],
      "source": [
        "#\u0427\u0438\u0441\u0442\u043a\u0430\n",
        "df_train.question1 = df_train.question1.map(lambda x : str(x).lower())\n",
        "df_train.question2 = df_train.question2.map(lambda x : str(x).lower())\n",
        "df_train.is_duplicate = df_train.is_duplicate.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "342f7da9-0813-f13b-b978-5149f75519a5"
      },
      "outputs": [],
      "source": [
        "df_train['WordMatch'] = df_train.apply(WordMatch, axis=1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "84880ccf-42b7-ddd4-3b31-4f49fd4829d4"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_train[df_train['is_duplicate']==0].WordMatch, kde=False)\n",
        "sns.distplot(df_train[df_train['is_duplicate']==1].WordMatch, kde=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eea45b4d-8a2b-ad29-4688-d79ca18705e1"
      },
      "outputs": [],
      "source": [
        "train_qs = pd.Series(df_train['question1'].tolist() + df_train['question2'].tolist()).astype(str)\n",
        "test_qs = pd.Series(df_test['question1'].tolist() + df_test['question2'].tolist()).astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b38d6f1-a1b1-83a4-c8d8-aa5cfdf0e6c4"
      },
      "outputs": [],
      "source": [
        "# \u0421\u0447\u0438\u0442\u0430\u0435\u043c \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u0435\u043c\u043e\u0441\u0442\u044c \u0441\u043b\u043e\u0432\n",
        "\n",
        "def get_weight(count, eps=10000, min_count=2):\n",
        "    if count < min_count:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1 / (count + eps)\n",
        "    \n",
        "words = (\" \".join(train_qs)).lower().split()\n",
        "counts = Counter(words)\n",
        "weights = {word: get_weight(count) for word, count in counts.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64809f16-830e-3a06-6ae2-a1fabc09dd6f"
      },
      "outputs": [],
      "source": [
        "def tfidf(row):\n",
        "    q1 =  set(str(row['question1']).split()).difference(stops)\n",
        "    q2 =  set(str(row['question2']).split()).difference(stops)\n",
        "    \n",
        "    if len(q1) == 0 or len(q2) == 0:        \n",
        "        return 0\n",
        "    inter = q1.intersection(q2)\n",
        "    \n",
        "    shared_weights = [2 * weights.get(w, 0) for w in inter]\n",
        "    total_weights = [weights.get(w, 0) for w in q1] + [weights.get(w, 0) for w in q2]\n",
        "    \n",
        "    R = np.sum(shared_weights) / (np.sum(total_weights) + 0.01)\n",
        "    return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "daf01bb8-c149-8950-08b5-457abc448af8"
      },
      "outputs": [],
      "source": [
        "df_train['tfidf'] = df_train.apply(tfidf, axis=1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2921fde4-d4eb-a22e-1153-fd61b7e39273"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df_train[df_train['is_duplicate']==0].tfidf, kde=False)\n",
        "sns.distplot(df_train[df_train['is_duplicate']==1].tfidf, kde=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ce52d4af-02c7-28f5-cc56-f81e875d1ddb"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "# \u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n",
        "params = {}\n",
        "params['objective'] = 'binary:logistic'\n",
        "params['eval_metric'] = 'logloss'\n",
        "params['eta'] = 0.02\n",
        "params['max_depth'] = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2792d90c-1e53-d282-f4b7-98cf316802d7"
      },
      "outputs": [],
      "source": [
        "df_test['tfidf'] = df_test.apply(tfidf, axis=1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5dbce4b2-4d13-1639-4988-4982b09e4189"
      },
      "outputs": [],
      "source": [
        "df_test['WordMatch'] = df_test.apply(WordMatch, axis=1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f7d3eaa-6e7e-714b-ac9c-9842d697dc8a"
      },
      "outputs": [],
      "source": [
        "x_train = df_train.drop(['question1', 'question2', 'qid1', 'qid2', 'is_duplicate', 'id'], axis=1).values\n",
        "y_train = df_train.is_duplicate.values\n",
        "x_test = df_test.drop(['question1', 'question2', 'test_id'], axis=1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32163cb4-8d6c-6b39-fa9c-1e252612161e"
      },
      "outputs": [],
      "source": [
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "watchlist = [(d_train, 'train')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52c3ab35-9b55-543c-589d-ca12720720c2"
      },
      "outputs": [],
      "source": [
        "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2dc1001-6838-8c86-7999-e62ca788db5a"
      },
      "outputs": [],
      "source": [
        "d_test = xgb.DMatrix(x_test)\n",
        "y_test = bst.predict(d_test)\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['test_id'] = df_test['test_id']\n",
        "sub['is_duplicate'] = y_test\n",
        "sub.to_csv('sub.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93b52fc0-a1a1-0b37-4305-532394e95d07"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8156d5ec-127a-2361-730e-a00d0d0eecef"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "39dfa8bd-da7c-9005-e8ac-2678d8d967e2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51e72535-28d6-4b71-43a6-a31ad3a6b544"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4994a279-aea5-f993-c21f-8306bcb20408"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}