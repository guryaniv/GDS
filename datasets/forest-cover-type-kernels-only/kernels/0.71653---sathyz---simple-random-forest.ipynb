{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ac3553ccfa9831625e3a44d9f3f82e95e844fda"},"cell_type":"markdown","source":"Demo for how to use sklearn pipelines on pandas dataframe with different transformations i.e we use StandardScaler for all numeric columns and MinMax scaler for columns where we have index values from 0 - 255."},{"metadata":{"trusted":true,"_uuid":"69f7c817e74a0ed220ebb1b871c33b59c5daa591"},"cell_type":"code","source":"from sklearn.pipeline import make_union, make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Binarizer, FunctionTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\n\ndef get_numeric_columns(df):\n    numerical_columns = [\"Elevation\", \"Aspect\", \"Slope\", \n                     \"Horizontal_Distance_To_Hydrology\",\n                     \"Vertical_Distance_To_Hydrology\",\n                     \"Horizontal_Distance_To_Roadways\",\n                     \"Horizontal_Distance_To_Fire_Points\",]\n    return df[numerical_columns]\n\ndef get_index_columns(df):\n    index_columns = [\"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\",]\n    return df[index_columns]\n\ndef get_bools_columns(df):\n    bool_columns = [ col for col in df.columns \n                        if col.startswith(\"Soil_Type\") \n                            or col.startswith(\"Wilderness_Area\") ]\n    return df[bool_columns]\n\ntransformations = [\n    make_pipeline(FunctionTransformer(get_numeric_columns, validate=False), StandardScaler()),\n    make_pipeline(FunctionTransformer(get_index_columns, validate=False), MinMaxScaler()),\n    make_pipeline(FunctionTransformer(get_bools_columns, validate=False), Binarizer()),\n]\n\ntransformer = make_union(*transformations)\nmodel = RandomForestClassifier()\n\npipeline = Pipeline([('transformations', transformer), ('rf', model)])\n\nys = train_df.Cover_Type.values - 1 # 0 base coding \npipeline.fit(train_df, ys)\ny_pred = pipeline.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f019c5b191c45c80bb946aa38a7c0422cb5a03d8"},"cell_type":"code","source":"def save_submission(test_df, y_pred, filename):\n    series = pd.Series(y_pred + 1, index=test_df.Id, name=\"Cover_Type\")\n    series.to_csv(filename, header=True)\n\nsave_submission(test_df, y_pred, \"submission.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}