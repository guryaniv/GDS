{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "53e4ddd2-cf7d-e4ec-7a84-4f6fbc33c8c6"
      },
      "source": [
        "**Just a starter code with Xgboost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f884cd51-7170-9a57-1220-ef93c1e462b7"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.width', 500)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.notebook_repr_html', True)\n",
        "\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5cd142a8-1b36-6c15-e704-ee3945f93d44"
      },
      "outputs": [],
      "source": [
        "# Reading and Formatting data\n",
        "trainData = pd.read_csv('../input/train.csv')\n",
        "testData = pd.read_csv('../input/test.csv')\n",
        "print ((trainData.shape, testData.shape))\n",
        "y = trainData['loss']\n",
        "trainData.drop('loss', axis =1, inplace = True)\n",
        "print (trainData.shape)\n",
        "# Log makes the distribution more gaussian. From the discussion forums, shift of 200\n",
        "# seems to be giving the best results\n",
        "y = np.log(y.add(200)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7010f2e7-2c74-2fb0-7fad-db0dd1ae79bb"
      },
      "outputs": [],
      "source": [
        "trainData = trainData.append(testData)\n",
        "print (trainData.shape)\n",
        "trainData.head()\n",
        "trainData.drop('id', axis=1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "77a68edf-e5da-e92d-b41d-2da07803d000"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labCatEncode = LabelEncoder()\n",
        "trainData.ix[:,0:116] = trainData.ix[:,0:116].apply(labCatEncode.fit_transform)\n",
        "train = trainData.iloc[:188318]\n",
        "test = trainData.iloc[188318:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf8b8522-0770-e65c-cf67-d1e9a57d4f86"
      },
      "outputs": [],
      "source": [
        "# Params for xgboost : Shamelessly copied from the user Tilii's kernel\n",
        "params = {}\n",
        "params['booster'] = 'gbtree'\n",
        "params['objective'] = \"reg:linear\"\n",
        "params['eval_metric'] = 'mae'\n",
        "params['eta'] = 0.1\n",
        "params['gamma'] = 0.5290\n",
        "params['min_child_weight'] = 4.2922\n",
        "params['colsample_bytree'] = 0.3085\n",
        "params['subsample'] = 0.9930\n",
        "params['max_depth'] = 7\n",
        "params['max_delta_step'] = 0\n",
        "params['silent'] = 1\n",
        "params['random_state'] = 1001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c7f1c80-d05e-1d42-dbe3-92d3068757b7"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "Xtrain,Xval,ytrain,yval = train_test_split(train.values, y.values, test_size  = 0.3)\n",
        "dTrain = xgb.DMatrix(Xtrain, label=ytrain)\n",
        "dVal = xgb.DMatrix(Xval, label=yval)\n",
        "dTest = xgb.DMatrix(test.values)\n",
        "watchlist = [(dTrain, 'train'), (dVal, 'eval')]\n",
        "clf = xgb.train(params,dTrain,1000,watchlist,early_stopping_rounds=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32a7cfe5-fdb6-7693-218b-ce25df583111"
      },
      "outputs": [],
      "source": [
        "Pred = pd.DataFrame()\n",
        "Pred['id'] = testData['id']\n",
        "Pred['loss'] = np.exp(clf.predict(dTest))\n",
        "Pred['loss']  = Pred['loss'].add(-200)\n",
        "Pred.to_csv('XGB_Starter.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}