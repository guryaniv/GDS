{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "056ff353273e0845a64b92eb2d2322134aa1852a", "_cell_guid": "22b5ecdf-73f3-45dd-b400-780b58b35d1b"}, "execution_count": null, "outputs": [], "source": ["##import necessary packages\n", "import numpy as np # linear algebra\n", "import scipy as sp \n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib\n", "import seaborn as sns \n", "import nltk\n", "from nltk.corpus import stopwords\n", "import wordcloud\n", "from wordcloud import WordCloud, STOPWORDS\n", "from matplotlib import pyplot as plt\n", "##read in the data file an display \n", "df_spooky_author=pd.read_csv('../input/train.csv')\n", "df_spooky_author\n", "\n", "sentence_list=df_spooky_author['text'].values.tolist()\n", "author_list=df_spooky_author['author'].values.tolist()\n", "\n", "sentence_list\n", "author_list\n", "\n", "\n", "combined_list=[list(author_list) for author_list in zip(author_list, sentence_list)]\n", "\n", "tokenized_list=[]\n", "\n", "for authors,sentence in combined_list:\n", "    tokenized_list.append([authors,nltk.word_tokenize(sentence)])\n", "\n", "tokenized_list\n", "\n", "##make individual authorwise list of words after removing stop words.\n", "##This is to prepare the data for wordcloud\n", "stop = set(stopwords.words('english'))    \n", "\n", "tokenized_stop_words_list=[]\n", "\n", "\n", "for author,sentence in tokenized_list:\n", "    tokenized_stop_words_list_temp=[]   \n", "    for word in sentence:\n", "        if not word in stop:\n", "            tokenized_stop_words_list_temp.append(word)\n", "    tokenized_stop_words_list.append([author,tokenized_stop_words_list_temp])        \n", "            \n", "tokenized_stop_words_list\n", "\n", "tokenized_words_EAP=[]\n", "tokenized_words_MWS=[]\n", "tokenized_words_HPL=[]\n", "\n", "for author,sentence in tokenized_stop_words_list:\n", "    if author=='EAP':\n", "        for words in sentence:\n", "            tokenized_words_EAP.append(words)\n", "    if author=='MWS':\n", "        for words in sentence:\n", "            tokenized_words_MWS.append(words)\n", "    if author=='HPL':\n", "        for words in sentence:\n", "            tokenized_words_HPL.append(words)\n", "            \n", "##word cloud for HPLovenCraft            \n", "plt.figure(figsize=(30,30))\n", "wc = WordCloud(background_color=\"black\", max_words=10000, \n", "               stopwords=stop, max_font_size= 40)\n", "wc.generate(\" \".join(tokenized_words_HPL))\n", "##plt.title(\"HP Lovecraft (Cthulhu-Squidy)\", fontsize=16)\n", "plt.imshow(wc.recolor( colormap= 'Pastel1_r' , random_state=17), alpha=0.98)\n", "plt.axis('off')\n"], "cell_type": "code"}]}