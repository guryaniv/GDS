{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "version": "3.6.1", "pygments_lexer": "ipython3", "file_extension": ".py"}}, "nbformat": 4, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "0cdb254b1c06a16e96f56229d79857dcba03136d", "_cell_guid": "bb2d269f-a72b-4d95-b5b9-aec2e48e20d3"}, "source": ["The purpose of this notebook is to create a benchmark code. It consists of creating the Multi Log Loss score function which would be used later for more complicated algorithms and checking it using simple benchmarks.\n", "I used an even 1/9 probability benchmark between all the classes and Bayesian probability.\n", "I've also checked how strong is the overfitting for using all the training data rather than using cross validation."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "39094815e8f3153d4a79facdc0f0c6b89798d017", "_cell_guid": "f8d9b7c8-6fa8-4806-8da3-a41b1352077f"}, "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3581607e4645d42ae94e06462846f0a1504c5cc6", "_cell_guid": "0144a905-ff0a-407c-a3f5-a32e9a031ca9"}, "source": ["# Reading train\n", "train_X = pd.read_csv(\n", "    '../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, \n", "    names=[\"ID\",\"Text\"])\n", "train_y = pd.DataFrame.from_csv(\"../input/training_variants\")\n", "print('Train Text')\n", "print(train_X.head())\n", "print(\"train classes\")\n", "print(train_y.head())\n", "print(\"train classes probability\")\n", "train_y.Class.value_counts(normalize=True)\n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f73a312f32d4e4431b1c68a7f11213fd4af5a969", "_cell_guid": "b53c17d6-2fd4-480b-8a88-897bbae4b8bb", "collapsed": true}, "source": ["def multi_log_loss(y_true: np.array, y_pred: np.array):  # score function for CV\n", "    # Handle all zeroes\n", "    all_zeros = np.all(y_pred == 0, axis=1)\n", "    y_pred[all_zeros] = 1/9\n", "    # Normalise sum of row probabilities to one\n", "    row_sums = np.sum(y_pred, axis=1)\n", "    y_pred /= row_sums.reshape((-1, 1))\n", "    # Calculate score\n", "    n_rows = y_true.size\n", "    y_true = y_true - 1  # classes start from 1 where columns start from zero\n", "    score_sum = 0\n", "    for i in range(y_true.size):\n", "        score_sum -= np.log(y_pred[i, y_true[i]])\n", "    score = score_sum / n_rows\n", "    return score\n", "        "]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "296854e46b009b167620247a47179fe23ade68b7", "_cell_guid": "3468499d-13e2-4fad-9dab-7c6b1db95096"}, "source": ["# Gives every class 1/9 probability\n", "predictions = np.repeat(1/9, train_y.size*9).reshape(train_y.size,9)\n", "benchmark_blind = multi_log_loss(train_y.Class.values, predictions)\n", "print(\"The score for equal probability per each class is:\")\n", "benchmark_blind"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c54ccd3970537ee18525dc3c76833f109456cbec", "_cell_guid": "d2987373-b98e-41b9-93f4-df1cfd6822d3", "collapsed": true}, "source": ["def class_probability_list(train_y_series):\n", "    class_probability_series = train_y_series.value_counts(normalize=True)\n", "    probability_list = []\n", "    for i in range(1, 10):\n", "        probability_list.append(class_probability_series.at[i])\n", "    return probability_list"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "285e8f1bc766eb03bf93b3e27b160f45c4142506", "_cell_guid": "0d92869c-7d86-4f2f-8cd8-dce6241fac0f"}, "source": ["# Gives every class its precentange - Overfitting full train (Bayesian)\n", "predictions = np.repeat(\n", "    [class_probability_list(train_y.Class)], train_y.size, axis=0)\n", "benchmark_probability_blind = multi_log_loss(train_y.Class.values, predictions)\n", "print(\"The score for Bayesian probabilities using the whole train is:\")\n", "print(benchmark_probability_blind)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d4b3fc6663433dc8bcbf95fdaa1c885b83fbf610", "_cell_guid": "b487f67f-c245-4ea0-a283-e12548be5f1f"}, "source": ["# Bayesian - without overfitting\n", "# Generate stratified cv\n", "from sklearn.model_selection import KFold\n", "\n", "benchmark_probability_blind_no_overfit = []\n", "\n", "n_cv = 4\n", "skf = KFold(n_splits=n_cv, shuffle=True, random_state=1)\n", "for indices_train, indices_test in skf.split(X=train_X.values):\n", "    predictions = class_probability_list(train_y.iloc[indices_train].Class)\n", "    predictions = np.repeat([predictions], indices_test.size, axis=0)\n", "    benchmark_probability_blind_no_overfit.append(\n", "        multi_log_loss(train_y.iloc[indices_test].Class.values, predictions))\n", "print(\"The score for Bayesian probabilities with Kfold is:\")\n", "print(np.mean(benchmark_probability_blind_no_overfit))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["print(\"Gene exploration\")\n", "train_y.Gene.value_counts(normalize=True)\n"]}], "nbformat_minor": 1}