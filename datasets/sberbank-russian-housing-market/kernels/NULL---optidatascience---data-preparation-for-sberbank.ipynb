{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b401ada4-911c-2ef0-0f87-6bb71a5326cb"
      },
      "source": [
        "Introduction\n",
        "------------\n",
        "\n",
        "This notebook aims to introduce a standard way of\n",
        "\n",
        "  1. loading the data into python notebook\n",
        "  2. Visual and identify issues\n",
        "  3. Pre-process the data e.g., variable transformation, normalization and etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a20c78ae-30d3-9c65-8b15-d33c206ac1bf"
      },
      "outputs": [],
      "source": [
        "## Load packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import normalize\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "from ggplot import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d70274cd-0b27-9fd7-0ea3-3a77144c4683"
      },
      "outputs": [],
      "source": [
        "## Load data into Python\n",
        "\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "da91ea54-d3bd-f2b0-9d30-cefc75c61a62"
      },
      "source": [
        "Step 1: Take a peak\n",
        "-------------------\n",
        "\n",
        "Now take a peak at what's in the data. This including how many rows and columns and what are they."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8017ca14-f6d4-e84b-3e1d-a9f28b5c76ab"
      },
      "outputs": [],
      "source": [
        "print(train.columns)\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e81fc6f2-600f-4998-e939-69a37c3890e4"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3b4a76a9-39b2-1553-9c86-0ea6d4a62d18"
      },
      "outputs": [],
      "source": [
        "## Describe the output field\n",
        "print(train['price_doc'].describe())\n",
        "sns.distplot(train['price_doc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5b990626-1a4a-cf21-8c20-01c18202525e"
      },
      "source": [
        "The dependent variable is skewed (as expected for dollars). The easiest would be to take a log tranformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "90dceefb-7fcd-a7db-add7-55d50fd3f34f"
      },
      "outputs": [],
      "source": [
        "train['LogAmt']=np.log(train.price_doc+0.5)\n",
        "print(train['LogAmt'].describe())\n",
        "sns.distplot(train['LogAmt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "537fa12d-471b-31d9-05f6-09845190c5d7"
      },
      "source": [
        "** Note the two small bars between 13 and 14, and 14 and 15. We will need to dig into that and see that happens there **."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d29ef4dd-b3a8-5a1b-b427-c01bde91cca8"
      },
      "outputs": [],
      "source": [
        "## Merge data into one dataset to prepare compare between train and test\n",
        "train_1 = train.copy()\n",
        "train_1['Source']='Train'\n",
        "test_1 = test.copy()\n",
        "test_1['Source']='Test'\n",
        "alldata = pd.concat([train_1, test_1])\n",
        "print(alldata.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1a53f033-4e78-e8dc-d7b8-8b500853f0ef"
      },
      "source": [
        "Most fields are numeric, and a few of them are object. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9804020-9916-0b5f-d2dc-f4d6442b40d5"
      },
      "outputs": [],
      "source": [
        "## Numerical and Categorical data types\n",
        "alldata_dtype=alldata.dtypes\n",
        "display_nvar = len(alldata.columns)\n",
        "alldata_dtype_dict = alldata_dtype.to_dict()\n",
        "alldata.dtypes.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "54996cc7-f435-217c-5f3e-e7962d117913"
      },
      "source": [
        "Step 2: Data Visualization\u00b6\n",
        "---------------------------\n",
        "\n",
        "**Variable Description**\n",
        "\n",
        "I wrote this function with intension to compare train/test data and check if some variable is illy behaved. It is modified a little to fit this dataset to compared between normal/fraud subset.\n",
        "\n",
        "It can be applied to both numeric and object data types:\n",
        "\n",
        "  1. When the data type is object, it will output the value count of each categories\n",
        "  2. When the data type is numeric, it will output the quantiles\n",
        "  3. It also seeks any missing values in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "102d09d5-3354-7530-97e6-ff4819e18542"
      },
      "outputs": [],
      "source": [
        "def var_desc(dt):\n",
        "    print('--------------------------------------------')\n",
        "    for c in alldata.columns:\n",
        "        if alldata[c].dtype==dt:\n",
        "            t1 = alldata[alldata.Source=='Train'][c]\n",
        "            t2 = alldata[alldata.Source=='Test'][c]\n",
        "            if dt==\"object\":\n",
        "                f1 = t1[pd.isnull(t1)==False].value_counts()\n",
        "                f2 = t2[pd.isnull(t2)==False].value_counts()\n",
        "            else:\n",
        "                f1 = t1[pd.isnull(t1)==False].describe()\n",
        "                f2 = t2[pd.isnull(t2)==False].describe()\n",
        "            m1 = t1.isnull().value_counts()\n",
        "            m2 = t2.isnull().value_counts()\n",
        "            f = pd.concat([f1, f2], axis=1)\n",
        "            m = pd.concat([m1, m2], axis=1)\n",
        "            f.columns=['Train','Test']\n",
        "            m.columns=['Train','Test']\n",
        "            print(dt+' - '+c)\n",
        "            print('UniqValue - ',len(t1.value_counts()),len(t2.value_counts()))\n",
        "            print(f.sort_values(by='Train',ascending=False))\n",
        "            print()\n",
        "\n",
        "            m_print=m[m.index==True]\n",
        "            if len(m_print)>0:\n",
        "                print('missing - '+c)\n",
        "                print(m_print)\n",
        "            else:\n",
        "                print('NO Missing values - '+c)\n",
        "            if dt!=\"object\":\n",
        "                if len(t1.value_counts())<=10:\n",
        "                    c1 = t1.value_counts()\n",
        "                    c2 = t2.value_counts()\n",
        "                    c = pd.concat([c1, c2], axis=1)\n",
        "                    f.columns=['Train','Test']\n",
        "                    print(c)\n",
        "            print('--------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9fda7818-ae1e-2d19-ceb9-c03003977099"
      },
      "outputs": [],
      "source": [
        "var_desc('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "21e6d16f-12d5-3874-7ca2-5db416fc798c"
      },
      "outputs": [],
      "source": [
        "var_desc('float64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f88a1e2-59ad-b55d-3bde-1902b6744e44"
      },
      "outputs": [],
      "source": [
        "var_desc('object')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f435b05-172a-b794-2438-9ccde2397aad"
      },
      "source": [
        "Correlation\n",
        "-----------\n",
        "\n",
        "Correlation is useful to find peers of input field so we are aware when building models, either to transform them (principal component) or remove one of the two.\n",
        "\n",
        "The first plot below the overall correlation matrix and there are blocks of variables that are highly correlated\n",
        "\n",
        "The second plot shows the highly correlated variables with response. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6676ec60-8fbe-703d-49f3-318e655552a9"
      },
      "outputs": [],
      "source": [
        "## Correlation\n",
        "corrmat = train.corr()\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(corrmat, vmax=.8, square=True,xticklabels=False,yticklabels=False,cbar=False);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aefdcb6b-5faa-4eb9-578b-31f08cebaf43"
      },
      "outputs": [],
      "source": [
        "# Top 20 correlated variables\n",
        "corrmat = train.corr()\n",
        "k = 20 #number of variables for heatmap\n",
        "cols = corrmat.nlargest(k, 'price_doc')['price_doc'].index\n",
        "cm = np.corrcoef(train[cols].values.T)\n",
        "f, ax = plt.subplots(figsize=(12, 12))\n",
        "sns.set(font_scale=1.25)\n",
        "hm = sns.heatmap(cm, cbar=False, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bf0aa3e3-52a2-6c31-196d-dacfe754016a"
      },
      "source": [
        "Detailed Look\n",
        "-------------\n",
        "\n",
        "Let's take a detailed look of the variables with response variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7c75ddd-f016-dbf5-5714-32a5a355b4a7"
      },
      "outputs": [],
      "source": [
        "dt = 'object'\n",
        "sel_col = train.columns[train.dtypes==dt]\n",
        "sel_col = [t for t in sel_col if t not in ['Id','timestamp','LogAmt']] \n",
        "\n",
        "for sc in sel_col:\n",
        "    data_1  = pd.concat([train[sc], train.LogAmt], axis=1)\n",
        "    data_2  = pd.melt(data_1,id_vars='LogAmt')\n",
        "    data_2  = data_2[pd.isnull(data_2.value)==False]\n",
        "    p = ggplot(data_2, aes(x='value',y='LogAmt')) + geom_boxplot(alpha=0.5,) + theme(plot_margin = dict(right = 1, top=0.5), axis_title_x=sc)\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5fb4ac3a-cee6-a612-7737-4e5130c12b38"
      },
      "outputs": [],
      "source": [
        "dt = 'int64'\n",
        "sel_col = train.columns[train.dtypes==dt]\n",
        "sel_col = [t for t in sel_col if t not in ['Id','timestamp','LogAmt']] \n",
        "\n",
        "for sc in sel_col:\n",
        "    data_1  = pd.concat([train[sc], train.LogAmt], axis=1)\n",
        "    data_2  = pd.melt(data_1,id_vars='LogAmt')\n",
        "    data_2  = data_2[pd.isnull(data_2.value)==False]\n",
        "    p = ggplot(data_2, aes(x='value',y='LogAmt')) + geom_point(alpha=0.5) + theme(plot_margin = dict(right = 1, top=0.5), axis_title_x=sc)\n",
        "    print(p)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}