{"cells":[{"metadata":{"_uuid":"8903ec077031cf0874bc09c3697d3134e6458094"},"cell_type":"markdown","source":"In this challenge we are given a dataset that contains a cuisine type, an ID number and a list of ingredients. This is only my second time attempting any machine learning, and my first time trying to create a pipeline that can understand text data. I learned a ton during this challenge, and welcome any feedback on how I can improve in the future!"},{"metadata":{"_uuid":"83b60fcb62e1034021155cdc42d3ae0cbb7a4b4e"},"cell_type":"markdown","source":"First we just have to input all of the necessary python modules to complete this challenge:"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Math and DataFrame stuff\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#basic computer stuff\nimport os\nprint(os.listdir(\"../input\"))\n\n#plotting stuff\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\n\n# machine learning\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a08ffc026bcb4658a0fdaf0ab3fdfdab23982085"},"cell_type":"markdown","source":"I read in both the test and train data sets using pandas"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train_df = pd.read_json('../input/train.json')\ntest_df = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cf2cb0d4684dba7b4221ed55b10bb6fef7e2962"},"cell_type":"markdown","source":"To get a better understanding of the datasets I print the column names"},{"metadata":{"trusted":true,"_uuid":"4ed0ac6e5f07ed3b193020cdcb773a34863f31f3"},"cell_type":"code","source":"print(train_df.columns.values)\nprint(test_df.columns.values)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17b8fcbe0568ed5c92c9bff89fb04a99801680e8"},"cell_type":"markdown","source":"So the training dataset contains the cuisne, but the test dataset only contains the id number and ingredients."},{"metadata":{"_uuid":"a0e5383bded02f3b89a75daf5fd676a655932d08"},"cell_type":"markdown","source":"I also check out the first 10 lines of the dataframe"},{"metadata":{"trusted":true,"_uuid":"dac1ea41938d143b83b3e581463ca040e24be538"},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3057a63a9326b34d2094216bd80edce8e42299c"},"cell_type":"markdown","source":"The ingredients for each recipie are recorded in a list. This will be hard for us to understand and program around, so I am going to simply get rid of the list using the pandas function DataFrameName.apply.(','.join) where DataFrameName is whatever your dataframe is called. "},{"metadata":{"trusted":true,"_uuid":"e9c93d82878a5b1d82b25c8436fe6c0da92956bb","collapsed":true},"cell_type":"code","source":"train_df['ingredients'] = train_df['ingredients'].apply(', '.join)\ntest_df['ingredients'] = test_df['ingredients'].apply(', '.join)\ncombine = [train_df,test_df]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47a77b1441b02336d73f885f224d4d09526d606f"},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3820621f2ca964c64e1e0832a01d8cfdca2c6d3d"},"cell_type":"code","source":"test_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f9cf02fc6be4af7ab5fcf95ab29eeed6e356b21"},"cell_type":"markdown","source":"What is the distribution of cuisines? Lets plot it and find out:\n"},{"metadata":{"trusted":true,"_uuid":"83a8b8de68a663230b5bf48a6487e1c3f2944d69"},"cell_type":"code","source":"sns.countplot(y = 'cuisine',data = train_df)\nsns.set(rc = {'figure.figsize' : (8,5)})\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ce7506eb286a56475fe4ed20668ca069735bea1"},"cell_type":"markdown","source":"So clearly italian and mexican dominate the distributions. That most likely means we'll be seeing a lot of garlic and oil!"},{"metadata":{"_uuid":"4e99be7b45feca66fafa7c12cb6d37ba8c69e9c0"},"cell_type":"markdown","source":"I really want the machine learning program to understand the individual ingredients, not the list for the entire recipie. So I can write a simple for loop that seperates the ingredients. I will change this to a lambda function when I use it in the CountVectorizor from sklearn, but I always check that my for loop does what I want it to before I commit it to a lambda function. This helps me debug my code more easily. "},{"metadata":{"trusted":true,"_uuid":"151738cc6eab8ee2e7cc74af4cc5b53f9dcaba41","collapsed":true},"cell_type":"code","source":"common_ing = []\nfor x in np.arange(len(train_df['cuisine'])):\n    for i in train_df['ingredients'][x].split(','):\n        common_ing.append(i.strip())\ncommon_ing = pd.DataFrame(common_ing, columns=['common_ing'])\n          ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"916d2314d6be9ca449c6c699b5ad93a6467c7fbb"},"cell_type":"markdown","source":"What are the 10 most common ingredients??"},{"metadata":{"trusted":true,"_uuid":"fd26fbe218aa0b9b3437343a473ef0cd5cdd09ea"},"cell_type":"code","source":"common_ing['common_ing'].value_counts().head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d97c38cb9bff2f424564a5771eecf13d639f4b24"},"cell_type":"markdown","source":"Yay! I was totally right about the garlic and olive oil! :)"},{"metadata":{"_uuid":"a275bf0aa6892256c744d5da0aac59059a26d59d"},"cell_type":"markdown","source":"So that worked! I now have a dataframe called 'common_ing' with all of the ingredients in the train_df dataframe. I feel confident turning this into a lambda function."},{"metadata":{"_uuid":"3bf247ea3e48c5160b2f899c8263fdb5def570fb"},"cell_type":"markdown","source":"Here I start followint the \"[Working With Text Data](http://http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html )\" tutorial on sklearn, and follow it pretty consistently"},{"metadata":{"_uuid":"9c32b3a9cf799a1bb5ec2d7c9f66a3940ab7e861"},"cell_type":"markdown","source":"From what I can understand, CountVectorizor builds a dictionary and the index value of a word in the vocabulary is linked to its frequency. If someone can better explain this to me in laymans terms it would be much appreciated!!"},{"metadata":{"trusted":true,"_uuid":"2ae9b90810abe89ab5452708c8d153212baaab26"},"cell_type":"code","source":"count_vec = CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)\nX_train_counts = count_vec.fit_transform(train_df['ingredients']) \nX_train_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5128c2b05e2917af76e2a8c350679d33ea2d9586"},"cell_type":"markdown","source":"TfidTransformer divides the number of occurrences of each word in a document by the total number of words in the document. This is supposed to be better for longer documents where the count of a particular word is not as insightful as the frequency."},{"metadata":{"trusted":true,"_uuid":"b3c07f8bab0ced467c887fb1a0da8613c883647c"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\ntf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\nX_train_tf = tf_transformer.transform(X_train_counts)\nX_train_tf.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad24a71e279bf3f6c636a6b370fb206ce55141c1"},"cell_type":"markdown","source":"We can create two different pipelines- one with a TfidTransformer, and one without- and compare them to see what works best. We will be using a support vector machine (SVM) which is supposed to be one of the best for text. "},{"metadata":{"trusted":true,"_uuid":"4bdc00524ae0c7301f68879df49e219a53a22156","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\n\ntext_clf = Pipeline([('vect', CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\ntext_tdif_clf = Pipeline([('vect', CountVectorizer(tokenizer=lambda x: [i.strip() for i in x.split(',')], lowercase=False)),('tfidf', TfidfTransformer()),('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None)),])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2586dbf45316c3d0894924c756bf42d2caa70c91"},"cell_type":"code","source":"text_tdif_clf.fit(train_df['ingredients'], train_df['cuisine']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"871d001cc899f0507c3b391be39ec73a6c196ea6"},"cell_type":"code","source":"predicted = text_tdif_clf.predict(train_df['ingredients'])\nnp.mean(predicted == train_df['cuisine'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b127a92275b2a40630950122fea058c0af97ad58"},"cell_type":"markdown","source":"Including Tfid we have a prediction rate of 72%- not the best! Lets see where it got confused."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3ca0852a9f7dd62dcfe82825a00b8e8d7f57cf31"},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d0c0fad4b6c39491c4c7e40cd285887909c619e"},"cell_type":"code","source":"print(metrics.classification_report(train_df['cuisine'],predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c890a6145f872e879ece71c2c60186e05b423d7f","collapsed":true},"cell_type":"code","source":"cm = metrics.confusion_matrix(train_df['cuisine'],predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc373de089a54f8288b425ff0e4990b636478722"},"cell_type":"code","source":"cm.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"70af2a15c61af8a07cb01c1c7045d189762e1de5"},"cell_type":"code","source":"legend = ['brazilian','british','cajun_creole','chinese','filipino','french','greek','indian','irish','italian','jamaican','japanese','korean','mexican','moroccan','russian','southern_us','spanish','thai','vietnamese']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e22200f9d55c43fb05bd27ce6dc06b3ca2f8a31","collapsed":true},"cell_type":"code","source":"df_cm = pd.DataFrame(cm,index = legend,columns=legend)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"477359058d58ab18013bbd618fc8a7c562a53c4a"},"cell_type":"code","source":"plt.figure\nsns.set(font_scale= 1.4,rc = {'figure.figsize' : (15,15)})\nsns.heatmap(df_cm,annot = True, linewidths=.5,fmt = 'd',cmap = 'viridis',cbar = False).set_title('Confusion Matrix With Tdif')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac6d71843551f68b36a4cd62245bebd6c50348ab"},"cell_type":"markdown","source":"The pipeline got most confused between italian, french, and southern us cooking.  Now lets try without Tfid to see if the prediction rate gets better or worse:"},{"metadata":{"trusted":true,"_uuid":"a34320ae39d74746d74a2437d9e4e012f6d23a12"},"cell_type":"code","source":"text_clf.fit(train_df['ingredients'], train_df['cuisine']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49db65a219c59affc60a9b140b6519001404577e"},"cell_type":"code","source":"predicted = text_clf.predict(train_df['ingredients'])\nnp.mean(predicted == train_df['cuisine'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d986eb50df2c5b1ccbf3f23242a85d1c883c8e98"},"cell_type":"markdown","source":"Without Tfid we went from 72% to 79%! In this case it seems count is more important than frequency."},{"metadata":{"trusted":true,"_uuid":"c220deac73547d8bc385c3839d8b38db28022e62"},"cell_type":"code","source":"print(metrics.classification_report(train_df['cuisine'],predicted))\ncm = metrics.confusion_matrix(train_df['cuisine'],predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1349e2e79f0d423dc1ce863689ea1ab5297c5384"},"cell_type":"code","source":"df_cm = pd.DataFrame(cm,index = legend,columns=legend)\nplt.figure\nsns.set(font_scale= 1.4,rc = {'figure.figsize' : (15,15)})\nsns.heatmap(df_cm,annot = True, linewidths=.5,fmt = 'd',cmap = 'viridis',cbar = False).set_title('Confusion Matrix Without Tdif')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"243563702dde34d1173dd689cd56eaeaccb7189c"},"cell_type":"markdown","source":"Just using CountVectorizor actually worked better than Tfid! We obtained an accuracy of 79% with most of the confusion *still*  happening between French, Italian and Southern US- but the confusion was less with CountVectorizor alone. "},{"metadata":{"_uuid":"03b883875a1a20603db6d04cd998559a609b725a"},"cell_type":"markdown","source":"Lets submit this guy!"},{"metadata":{"trusted":true,"_uuid":"935f20576d157c7fa24aa4d4c5895335cceff236"},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8587c5db5b96b1835cab8aacd73be2897de4ee8b"},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"807e1a25b03bacae0bcc3c6e6bb2ed3c49283e9d"},"cell_type":"code","source":"final_predicted = text_clf.predict(test_df['ingredients'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"820289aa8e43d35f10b053868cb182e14ad60bd9"},"cell_type":"code","source":"predictions = pd.DataFrame({'cuisine' : final_predicted , 'id' : test_df.id })\npredictions = predictions[[ 'id' , 'cuisine']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"aeee58f07f97526a35ade05372437f8d7c7cc4a3"},"cell_type":"code","source":"predictions.to_csv('submit.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"887ccbf65c437813eb600408fed0e6cfbe117d12"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}