{"nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"file_extension": ".py", "version": "3.6.1", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "name": "python"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "a9756699-a2b6-466d-9dcb-6571ade88a10", "_uuid": "b9baa78c9f65c83046735cca56316a4be45548ca"}, "source": ["# Predict the effect of Genetic Variants"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b652344e-5bd9-448c-9228-ca305a39763b", "scrolled": true, "_uuid": "4938eb971329bec4456ef309748e108aa1408b66"}, "source": ["from __future__ import print_function\n", "import os\n", "import re\n", "import tqdm\n", "import string\n", "import pandas as pd\n", "import numpy as np\n", "import keras"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "319c54c9-9098-4255-8a38-fb43c5fb0c92", "_uuid": "2e414af1ab1cad412b0ae147d2e761991b804ec6"}, "source": ["## 1. Loading Data"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "98f3fc6b-f4ba-4dd0-a420-8e7890214818", "_uuid": "96b4c6d0d507e955ae1041173f535a41a230c4ea", "collapsed": true}, "source": ["\"\"\" Read Data \"\"\"\n", "train_variant = pd.read_csv(\"../input/training_variants\")\n", "test_variant = pd.read_csv(\"../input/test_variants\")\n", "train_text = pd.read_csv(\"../input/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "test_text = pd.read_csv(\"../input/test_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "train = pd.merge(train_variant, train_text, how='left', on='ID')\n", "train_y = train['Class'].values\n", "train_x = train.drop('Class', axis=1)\n", "train_size=len(train_x)\n", "print('Number of training variants: %d' % (train_size))\n", "# number of train data : 3321\n", "\n", "test_x = pd.merge(test_variant, test_text, how='left', on='ID')\n", "test_size=len(test_x)\n", "print('Number of test variants: %d' % (test_size))\n", "# number of test data : 5668\n", "\n", "test_index = test_x['ID'].values\n", "all_data = np.concatenate((train_x, test_x), axis=0)\n", "all_data = pd.DataFrame(all_data)\n", "all_data.columns = [\"ID\", \"Gene\", \"Variation\", \"Text\"]"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "13260601-e4d0-43c9-aeb6-2863df477b58", "_uuid": "a2aede52f84aa393a522b93c9c394c392ac49d35", "collapsed": true}, "source": ["all_data.head()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ed2a23f8-e172-438c-8c4b-32b35a3ecc0d", "_uuid": "a9242f1fe200966fbc4cc9022c5b6ddc8e7df169"}, "source": ["## 2. Data Preprocessing"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "292274da-92f2-4463-9ffb-ebb2c36ea128", "_uuid": "cf5322354069733966c979519918448fadc51662", "collapsed": true}, "source": ["from nltk.corpus import stopwords\n", "from gensim.models.doc2vec import LabeledSentence\n", "from gensim import utils\n", "\n", "def constructLabeledSentences(data):\n", "    sentences=[]\n", "    for index, row in data.iteritems():\n", "        sentences.append(LabeledSentence(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n", "    return sentences\n", "\n", "def textClean(text):\n", "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n", "    text = text.lower().split()\n", "    stops = set(stopwords.words(\"english\"))\n", "    text = [w for w in text if not w in stops]    \n", "    text = \" \".join(text)\n", "    return(text)\n", "    \n", "def cleanup(text):\n", "    text = textClean(text)\n", "    text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n", "    return text\n", "\n", "allText = all_data['Text'].apply(cleanup)\n", "sentences = constructLabeledSentences(allText)\n", "allText.head()"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1ab275e7-e570-47e2-b483-a59b0681d4f2", "_uuid": "ad6986f93de0fe2cc37733cc61941c5143e1b39e", "collapsed": true}, "source": ["sentences[0]"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "63aadc95-4f87-4d08-baf6-dcebcd665fcd", "_uuid": "d51160c62c9fbc07eb41cdade5e7a96d014fc5d0"}, "source": ["## 3. Data Preparation and Features Extraction"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "4a602cec-b0cc-4f8a-a0f8-3b4a82b48106", "_uuid": "0c3baa21e0fef1182b1118ac02b6ff051e109509"}, "source": ["### 3.1 Text Featurizer using Doc2Vec"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "283da025-c57f-4545-b2ce-220b4ba18a4d", "_uuid": "205cb39aaa6f719467dfbf99f60f251c88b16572"}, "source": ["Training Doc2Vec with your data or import a saved file"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1f38824f-8ca8-485c-8765-e346a57bb22b", "_uuid": "93ecb3bb2b6fd292be89150288e2bb23a83ee45f", "collapsed": true}, "source": ["from gensim.models import Doc2Vec\n", "\n", "Text_INPUT_DIM=300\n", "\n", "\n", "text_model=None\n", "filename='docEmbeddings_5_clean.d2v'\n", "if os.path.isfile(filename):\n", "    text_model = Doc2Vec.load(filename)\n", "else:\n", "    text_model = Doc2Vec(min_count=1, window=5, size=Text_INPUT_DIM, sample=1e-4, negative=5, workers=4, iter=5,seed=1)\n", "    text_model.build_vocab(sentences)\n", "    text_model.train(sentences, total_examples=text_model.corpus_count, epochs=text_model.iter)\n", "    text_model.save(filename)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "73c44c70-cf30-4968-856c-fc65be5d845e", "_uuid": "25135f43005aa3a66134c9ff0ddcc4a7ff979865"}, "source": ["Featurize text for your training and testing dataset "]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6d65ba25-fbe0-4367-a18a-bdf4cc6be86f", "_uuid": "064f7923bb368007f060875757249e53c1660f7d", "collapsed": true}, "source": ["text_train_arrays = np.zeros((train_size, Text_INPUT_DIM))\n", "text_test_arrays = np.zeros((test_size, Text_INPUT_DIM))\n", "\n", "for i in range(train_size):\n", "    text_train_arrays[i] = text_model.docvecs['Text_'+str(i)]\n", "\n", "j=0\n", "for i in range(train_size,train_size+test_size):\n", "    text_test_arrays[j] = text_model.docvecs['Text_'+str(i)]\n", "    j=j+1\n", "    \n", "print(text_train_arrays[0][:50])"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "229c16b1-4438-45bb-ae99-e0b6fe65cde0", "_uuid": "278e8bec4a9e518afdacdb332cb8af23b570e263"}, "source": ["### 3.2 Gene and Varation Featurizer"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "eaa75363-2286-411c-8283-813fa029c856", "_uuid": "90b8c5929286f149ee9bebd1e30e38802488db19", "collapsed": true}, "source": ["from sklearn.decomposition import TruncatedSVD\n", "Gene_INPUT_DIM=25\n", "\n", "svd = TruncatedSVD(n_components=25, n_iter=Gene_INPUT_DIM, random_state=12)\n", "\n", "one_hot_gene = pd.get_dummies(all_data['Gene'])\n", "truncated_one_hot_gene = svd.fit_transform(one_hot_gene.values)\n", "\n", "one_hot_variation = pd.get_dummies(all_data['Variation'])\n", "truncated_one_hot_variation = svd.fit_transform(one_hot_variation.values)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ef8b6405-f0a5-4342-a33c-b80e5e044499", "_uuid": "199d43e9ad05ffc24a57a11c3ce27f59418c1c1b"}, "source": ["### 3.3 Output class encoding"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b4e685ad-9c31-496e-a26d-198692d3a9a4", "_uuid": "20da3e29b16a2dde8cc0137b7c35f462d60c67c0", "collapsed": true}, "source": ["from keras.utils import np_utils\n", "from sklearn.preprocessing import LabelEncoder\n", "\n", "label_encoder = LabelEncoder()\n", "label_encoder.fit(train_y)\n", "encoded_y = np_utils.to_categorical((label_encoder.transform(train_y)))\n", "print(encoded_y[0])"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "7e2d3ba3-49f8-482a-877f-4c16238cb4f3", "_uuid": "d95579f225751abefd30f647c2eec093b1a57222"}, "source": ["### 3.4 Merge Input features"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "5cd6d1f5-badb-48b1-92cb-64e493e714ea", "_uuid": "ac40039fbf0d39e58c81a3f440dd694cc8ab4550", "collapsed": true}, "source": ["train_set=np.hstack((truncated_one_hot_gene[:train_size],truncated_one_hot_variation[:train_size],text_train_arrays))\n", "test_set=np.hstack((truncated_one_hot_gene[train_size:],truncated_one_hot_variation[train_size:],text_test_arrays))\n", "print(train_set[0][:50])"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "1c66c381-54e4-483f-bfde-6124a66e0bd4", "_uuid": "2e26f6093d9ebef57b5fa8bdfda66a66ba15983d"}, "source": ["## 4. Define Keras Model"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "82ab5b69-e6f4-44f2-8a9e-906a87401c25", "_uuid": "fbcb45c2cca64a332b855cdaf9ce2e28b648cf21", "collapsed": true}, "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\n", "from keras.optimizers import SGD\n", "\n", "def baseline_model():\n", "    model = Sequential()\n", "    model.add(Dense(256, input_dim=Text_INPUT_DIM+Gene_INPUT_DIM*2, init='normal', activation='relu'))\n", "    model.add(Dropout(0.3))\n", "    model.add(Dense(256, init='normal', activation='relu'))\n", "    model.add(Dropout(0.5))\n", "    model.add(Dense(80, init='normal', activation='relu'))\n", "    model.add(Dense(9, init='normal', activation=\"softmax\"))\n", "    \n", "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)  \n", "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n", "    return model"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "385a3b2e-0b43-4ee4-9187-d6bf854fe4e0", "_uuid": "6381b9ceda6d8f3658b3684de5d02a1cec7156a1", "collapsed": true}, "source": ["model = baseline_model()\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d94d4c73-d984-4cbb-a897-6033aef67d29", "_uuid": "269aedf9edf459f5b1bf345ba95fa76c1f8e311c"}, "source": ["## 5. Training and Evaluating the Model"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ee8497d6-f5f3-4f39-87bb-eb153414034e", "_uuid": "8cf64923acb9c7c59d56a252e6db45b04e817231"}, "source": ["Create estimator for training the model"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "de730abf-b9c4-4f5c-9922-f10ad981a610", "_uuid": "2a0f0dc61103b801692eac5466280e0cccaa2e85", "collapsed": true}, "source": ["estimator=model.fit(train_set, encoded_y, validation_split=0.2, epochs=10, batch_size=64)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5a88edeb-1124-4c6e-ba2c-59719c0a301d", "_uuid": "877df2d233917344a86f23564faf71a6c0cf1a30"}, "source": ["Final model accuracy"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1e797aac-b5cd-4c20-a8a0-7bcaf6301547", "_uuid": "c0aec09666568ded24f24c5d34d03f4491886ba1", "collapsed": true}, "source": ["print(\"Training accuracy: %.2f%% / Validation accuracy: %.2f%%\" % (100*estimator.history['acc'][-1], 100*estimator.history['val_acc'][-1]))"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "4da93fc4-4719-467f-bd80-a065aef665e3", "_uuid": "c8a8e3c1d2559e6274f77db982db1e3c2b15fb02", "collapsed": true}, "source": ["import matplotlib.pyplot as plt\n", "\n", "# summarize history for accuracy\n", "plt.plot(estimator.history['acc'])\n", "plt.plot(estimator.history['val_acc'])\n", "plt.title('model accuracy')\n", "plt.ylabel('accuracy')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()\n", "\n", "# summarize history for loss\n", "plt.plot(estimator.history['loss'])\n", "plt.plot(estimator.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "a7b46e18-029f-47e4-9802-1453d190a524", "_uuid": "0accd1038dcfcbfd0f29f3bd479ed81d635f8552"}, "source": ["## 6. Make Predictions"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "dfa83b58-67e0-4e6d-8711-93d20cd6a6b7", "scrolled": true, "_uuid": "15b70b02e6b19e15c7b6e2f7aa5260ed325bad40", "collapsed": true}, "source": ["y_pred = model.predict_proba(test_set)"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "27c6b1bb-9387-46d9-b87b-d2af9f596b3d", "_uuid": "cb64cac79204a5147a874b24f80845957c8a93a9"}, "source": ["Make Submission File"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "59390174-876c-4cb1-a025-c9603529a1ac", "_uuid": "b55bf061cae62b0584799e688881fc3b3f2ef72f", "collapsed": true}, "source": ["submission = pd.DataFrame(y_pred)\n", "submission['id'] = test_index\n", "submission.columns = ['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9', 'id']\n", "submission.to_csv(\"submission_all.csv\",index=False)\n", "submission.head()"]}, {"cell_type": "markdown", "metadata": {"_cell_guid": "71e138c5-c6d8-4c98-a02d-90976c3a350e", "_uuid": "167d860b8e1b6421dd6f27ee7be53d182826ba0a"}, "source": ["## 7. Layers Visualization"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "0a59161d-3e83-46ff-99a8-e31d1b6e00c0", "_uuid": "74ea2a720108ba3333893e2dc589c2490d715586", "collapsed": true}, "source": ["from keras import backend as K\n", "import seaborn as sns\n", "\n", "layer_of_interest=0\n", "intermediate_tensor_function = K.function([model.layers[0].input],[model.layers[layer_of_interest].output])\n", "intermediate_tensor = intermediate_tensor_function([train_set[0,:].reshape(1,-1)])[0]\n"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "af42651d-8762-445b-9dd3-fc0667b86151", "_uuid": "7f2deddfa2219d7c1c3413a525e9d7e5370a14e7", "collapsed": true}, "source": ["import matplotlib\n", "colors = list(matplotlib.colors.cnames)\n", "\n", "intermediates = []\n", "color_intermediates = []\n", "for i in range(len(train_set)):\n", "    output_class = np.argmax(encoded_y[i,:])\n", "    intermediate_tensor = intermediate_tensor_function([train_set[i,:].reshape(1,-1)])[0]\n", "    intermediates.append(intermediate_tensor[0])\n", "    color_intermediates.append(colors[output_class])"]}, {"execution_count": null, "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "963df144-08a6-41d2-87f8-2bec298e4b04", "_uuid": "5b318b359560ee328611156410dc260e6d49c1ac", "collapsed": true}, "source": ["from sklearn.manifold import TSNE\n", "tsne = TSNE(n_components=2, random_state=0)\n", "intermediates_tsne = tsne.fit_transform(intermediates)\n", "plt.figure(figsize=(8, 8))\n", "plt.scatter(x = intermediates_tsne[:,0], y=intermediates_tsne[:,1], color=color_intermediates)\n", "plt.show()"]}], "nbformat": 4}