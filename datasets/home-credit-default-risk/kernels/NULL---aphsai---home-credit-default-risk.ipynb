{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"#Imports\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.preprocessing import LabelEncoder\n\nimport os\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"#Get a list of file names\nprint(os.listdir('../input/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a30a3639d6153c49a44a4784b39a7f18fde69c9","collapsed":true},"cell_type":"code","source":"#Initialize training data\ntrain = pd.read_csv('../input/application_train.csv')\ntrain.set_index('SK_ID_CURR', inplace=True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1a190c7936eeb2c311b6474d577e376e32b6035","collapsed":true},"cell_type":"code","source":"#Initialize testing data\ntest = pd.read_csv('../input/application_test.csv')\ntest.set_index('SK_ID_CURR', inplace=True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7f47c83a587fe0c940944128bbd0b1846514d1a","collapsed":true},"cell_type":"code","source":"#The first thing I like to do is look at the state of the data, examining missing values and the like.\ndef gen_missing_values(df):\n    missing_values = df.isnull().sum()\n    missing_values_percentages = (100 * df.isnull().sum() / len(df)).round(1)\n    missing_values_table = pd.concat([missing_values, missing_values_percentages], axis = 1)\n    missing_values_table = missing_values_table.rename(columns = {0: 'Missing Values', 1: 'Percentage'})\n    missing_values_table.sort_values('Missing Values', ascending=False, inplace=True)\n    return missing_values_table\n\nmissing_values = gen_missing_values(train)\nmissing_values.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ddafb244bf96c5991134e5ebcb6eb7e815b3340","collapsed":true},"cell_type":"code","source":"#I'll probably have to figure out some way to impute this data later, but for now I'll leave it.\n#I imagine dealing with non-decimal values is a more pressing concern.\n#The debate comes into play with label encoding vs. one-hot encoding and I chose to employ the safest approach which is to label encode all binary columns while \n#one-hot encoding all non-binary columns.\n\ndef adjust_for_labels(df): \n    le = LabelEncoder()\n    for col in df:\n        if df[col].dtype == 'object':\n            dropped_df = df.dropna(subset=[col])\n            if len(list(dropped_df[col].unique())) <= 2:\n                le.fit(dropped_df[col])\n                dropped_df[col] = le.transform(dropped_df[col])\n                df.update(dropped_df[col])\n    return df\n\ntrain = adjust_for_labels(train)   \ntest = adjust_for_labels(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7c4bf58ab30eaf5f5d933fa7a3d6b4e4d4bd38f","collapsed":true},"cell_type":"code","source":"#One hot-encoding\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)\n\n#Let's also check the shape of the training and testing data as the features in both these sets must be the same.\nprint('Testing shape: ', test.shape)\nprint('Training shape: ', train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2dcb77a1b400d4105bbadd0c037621a3bf5683a","collapsed":true},"cell_type":"code","source":"#As we can see, the one-hot encoding has most likely created more columns in the training data rather than the testing data (due to the larger amount of data,\n#hence higher potential for a larger diversity of categorical labels)\n\n#This is the extra column in the training data we need to save before we align the dataframes to each other\ntrain_labels = train['TARGET']\n\ntrain, test = train.align(test, join=\"inner\", axis=1)\n\n#Add this column back in\ntrain[\"TARGET\"] = train_labels\n\n#Let's check the shape again\nprint('Testing shape: ', test.shape)\nprint('Training shape: ', train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3353dc5c8214d021d3638f4078bb632b695fc37c","collapsed":true},"cell_type":"code","source":"#Nice.\n#The next thing on the list is to identify outliers inside the data, and for this, I'm going to use the z-score, and set an artbitrary \n#threshold value of 3 std. deviations to locate potential problem columns, and just take a look at how the data plays out on those.\n\ndef compute_potential_anomalies(df): \n    anomaly_table = df.dropna()\n    for col in anomaly_table:\n        std = anomaly_table[col].std()\n        anomaly_table.apply(lambda x: (x > 3 * std), axis=1)\n    return anomaly_table\n\nanomalies = compute_potential_anomalies(train)\nanomalies.head()\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b46698d52ef23896e3444d510ba5bd8ed91f1a67"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}