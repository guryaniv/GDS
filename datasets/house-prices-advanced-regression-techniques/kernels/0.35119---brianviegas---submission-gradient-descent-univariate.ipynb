{"cells":[{"metadata":{"_uuid":"6ca52328c473508a297daa89ee5937c7b2af104a"},"cell_type":"markdown","source":"Based on the poor initial results of Gradient Descent algorithm using only GrLivArea without log transformation and outliers removal, this submission was performed considering the use of these techniques.\n\n* Learning rate (alpha) = 0.03\n* Number of iterations = 1000\n* Random initial theta values \n* Score = 0.35119"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom scipy.stats import skew\npd.options.mode.chained_assignment = None  # default='warn'\n\n\n#######################  LINEAR REGRESSION ###########################\ndef predict(theta, x_test):\n    if len(x_test.shape) < 2:\n        x_test = x_test.reshape(-1,1)\n        x_test = np.insert(x_test, 0, 1, 1)\n    return np.dot(x_test, theta) \n\n######################### GRADIENT DESCENT ALGORITHM ####################\ndef compute_cost(features, values, theta):\n    m = len(values)\n    sum_of_square_errors = np.square(np.dot(features, theta) - values).sum()\n    cost = sum_of_square_errors / (2*m)\n    return cost\n\ndef gradient_descent(features, values, alpha, num_iterations):\n    if len(features.shape) < 2:\n        features = features.reshape(-1,1)\n        features = np.insert(features, 0, 1, 1)    \n    theta = abs(np.random.normal(0,0.00002, size = features[0].shape))\n    m = len(values)\n    cost_history = []\n    for i in range(num_iterations):\n        predict_values = np.dot(features, theta)\n        theta = theta - (alpha / m * np.dot((predict_values - values), features))\n        cost_theta = compute_cost(features, values, theta)\n        cost_history.append(cost_theta)\n    return theta, pd.Series(cost_history)\n\n########################## END OF GRADIENT DESCENT ALGORITHM #######################\n    \n##########################\n# Input train data\nfile_path = '../input/train.csv' \ntrain_data = pd.read_csv(file_path)\n# Input test data\ntest_data = pd.read_csv('../input/test.csv')\n\n# Removing GrLivArea > 4000 square feet area and eletrical input from train data\ntrain_data = train_data.drop(train_data.loc[train_data['Electrical'].isnull()].index)\ntrain_data = train_data[train_data.GrLivArea < 4000]\n\n# Log Transformation of GrLivArea and SalePrice\ntrain_data['GrLivArea'] = np.log(train_data['GrLivArea'])\ntest_data['GrLivArea'] = np.log(test_data['GrLivArea'])\ntrain_data['SalePrice'] = np.log(train_data['SalePrice'])\n\n# Spliting features and values from train data\ntrain_test_data = train_data['SalePrice']\ntrain_data = train_data.drop(['SalePrice'], axis = 1)\n\n# Formats train_x and test_x\ntrain_x = np.array(train_data['GrLivArea'])\ntest_x = np.array(test_data['GrLivArea'])\n\n# Process the gradient descent\nprint(\"Starting regression\")\ntheta_gradient_descent, cost_history = gradient_descent(train_x, train_test_data, 0.03, 1000)\npredictions = predict(theta_gradient_descent, test_x)\n#Transform the predictions\npredictions = np.exp(predictions)\nsubmission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predictions})\nsubmission.to_csv('submission_multi_gradient_uni_final.csv', index=False)\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}