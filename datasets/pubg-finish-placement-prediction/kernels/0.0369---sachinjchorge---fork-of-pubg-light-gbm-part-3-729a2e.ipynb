{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport datetime as dt\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"145a722040379a0dcdc0fe9955b8715fe012cb9c"},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df\nprint('function created')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"inittime = dt.datetime.now()\nprint(\"Capturing train database...\")\ndf_train = pd.read_csv(\"../input/train_V2.csv\")\nprint(\"Train Database captured in \", dt.datetime.now()- inittime, \" secs\" )\ndf_train= reduce_mem_usage(df_train)\n\ninittime = dt.datetime.now()\nprint(\"Capturing Test database...\")\ndf_test = pd.read_csv(\"../input/test_V2.csv\")\nprint(\"Test Database captured in \", dt.datetime.now()- inittime, \" secs\" )\ndf_test= reduce_mem_usage(df_test)\n\nprint(\"Train data set :\\n\",df_train.head())\nprint(\"Test data set :\\n\", df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d544f24d7912baeba4a54de1a71b94ef7455a96f","_kg_hide-output":false},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e127a196fb38c2e3e5e13794d256a85d81515dbf"},"cell_type":"code","source":"df_train.loc[df_train['winPlacePerc'].isna()==True, 'winPlacePerc']= 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54522e341e3ce6085749ea7d139a0595edd303ef"},"cell_type":"code","source":"df_train['matchType'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1614007d6e2c569f6019063e4433203ce65175af"},"cell_type":"code","source":"df_test['winPlacePerc']= 0.0\ndf_train['Type']= 'Train'\ndf_test['Type']= 'Test'\nprint(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91d23b0359c2a86c6528d473dff505f9dabe013"},"cell_type":"code","source":"df= pd.concat([df_train, df_test], ignore_index=True)\ndel df_train\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff00867eefca4ca7fcac463011acb7f657f500f3"},"cell_type":"code","source":"df= reduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b137d2464d248289fab779ad477b057ac7143f7"},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d1434e1a814c41f65a9a0eefe08a82d9b86240c"},"cell_type":"code","source":"# Counrtesy from kernel rejasupotaro/effective-feature-engineering\ndef min_by_team(df,df_Group, features):\n    print(\"Working on Min by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].min()\n    print(\"Features : Min Created in \", dt.datetime.now()- inittime)\n    return df.merge(agg, suffixes=['', '_min'], how='left', on=['matchId', 'groupId'])\n\n\ndef max_by_team(df,df_Group, features):\n    print(\"Working on Max by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].max()\n    print(\"Features : MAX Created in \", dt.datetime.now()- inittime)\n    return df.merge(agg, suffixes=['', '_max'], how='left', on=['matchId', 'groupId'])\n\ndef sum_by_team(df,df_Group, features):\n    print(\"Working on Sum by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].sum()\n    print(\"Features : SUM Created in \", dt.datetime.now()- inittime)\n    return df.merge(agg, suffixes=['', '_sum'], how='left', on=['matchId', 'groupId'])\n\ndef median_by_team(df,df_Group, features):\n    print(\"Working on Median by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].median()\n    print(\"Features : MEDIAN Created in \", dt.datetime.now()- inittime)\n    return df.merge(agg, suffixes=['', '_median'], how='left', on=['matchId', 'groupId'])\n\ndef mean_by_team(df,df_Group, features):\n    print(\"Working on Mean by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].mean()\n    print(\"Features : MEAN Created in \", dt.datetime.now()- inittime)\n    return df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n\ndef rank_by_team(df,df_Group, features):\n    print(\"Working on Rank by Team features...\")\n    inittime = dt.datetime.now()\n    agg = df_Group[features].mean()\n    print(\"Means Created\")\n    agg1 = agg.groupby('matchId')[features].rank(pct=True)\n    print(\"Features : RANK Created in \", dt.datetime.now()- inittime)\n    df= df.merge(agg, suffixes=['', '_mean'], how='left', on=['matchId', 'groupId'])\n    return df.merge(agg1, suffixes=['', '_mean_rank'], how='left', on=['matchId', 'groupId'])\nprint(\"Functions created\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd9ad5bd2caa20d96e98fb1a7484d996471f6f43"},"cell_type":"code","source":"#df= df.set_index(['Id', 'groupId', 'matchId','Type'])\n\n\nY_Column = 'winPlacePerc'\n\nColumnList = ['assists', 'boosts', 'damageDealt', 'DBNOs',\n       'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'maxPlace', 'numGroups', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']\n\n\ndf['headshotKills_over_kills'] = df['headshotKills'] / df['kills']\ndf['headshotKills_over_kills'].fillna(0, inplace=True)\ndf['headshotKills_over_kills'].replace(np.inf, 0, inplace=True)\n\ndf['killPlace_over_maxPlace'] = df['killPlace'] / df['maxPlace']\ndf['killPlace_over_maxPlace'].fillna(0, inplace=True)\ndf['killPlace_over_maxPlace'].replace(np.inf, 0, inplace=True)\n\ndf['walkDistance_over_heals'] = df['walkDistance'] / df['heals']\ndf['walkDistance_over_heals'].fillna(0, inplace=True)\ndf['walkDistance_over_heals'].replace(np.inf, 0, inplace=True)\n\ndf['walkDistance_over_kills'] = df['walkDistance'] / df['kills']\ndf['walkDistance_over_kills'].fillna(0, inplace=True)\ndf['walkDistance_over_kills'].replace(np.inf, 0, inplace=True)\n\ndf= reduce_mem_usage(df)\n\ncols_to_drop = ['Id', 'groupId', 'matchId', 'winPlacePerc','Type','matchType']\nfeatures = [col for col in ColumnList if col not in cols_to_drop]\ndf_Group = df.groupby(['matchId','groupId'])\n\n#df= min_by_team(df,df_Group,features)\ndf= reduce_mem_usage(df)\n#df= max_by_team(df,df_Group,features)\n#df= reduce_mem_usage(df)\n#df= sum_by_team(df,df_Group,features)\n#df= reduce_mem_usage(df)\ndf= median_by_team(df,df_Group,features)\ndf= reduce_mem_usage(df)\n#df= mean_by_team(df,df_Group,features)\ndf= rank_by_team(df,df_Group,features)\ndf= reduce_mem_usage(df)\nprint(\"New variables created\")\n\nfor colname in ColumnList:\n    df[colname+ '_1']= df[colname]/ (max(df[colname])- min(df[colname]))\n    df= df.drop(columns= [colname])\n    df= reduce_mem_usage(df)\n\n    #df[colname]= df[colname]**0.5\n    print(colname,'_1',' created')\ndf['totalDistance'] = df['rideDistance_1'] + df['walkDistance_1'] + df['swimDistance_1']\nprint(\"New variables created : totalDistance\")\n\ndf['kills_assists'] = (df['kills_1'] + df['assists_1'])\nprint(\"New variables created : kills_assists\")\n\ndf['healthitems'] = df['heals_1'] + df['boosts_1']\nprint(\"New variables created : healthitems\")\n\ndf['kills_']= df['kills_1'] + df['longestKill_1']+ df['killStreaks_1']\nprint(\"New variables created : kills_\")\n\ndf['killtypes']= df['headshotKills_1'] + df['roadKills_1']+ df['teamKills_1']+ df['vehicleDestroys_1']\nprint(\"New variables created : killtypes\")\n\ndf['Others']= df['damageDealt_1'] + df['DBNOs_1']+ df['revives_1'] + df['weaponsAcquired_1']\nprint(\"New variables created : Others\")\n\ndf['Points_'] = df['killPoints_1'] + df['winPoints_1']\nprint(\"New variables created : Points_\")\ndf= reduce_mem_usage(df)\n#df_Group1 = df.groupby(by = ['matchId'])\n#df_Group2 = df.groupby(by = ['groupId'])\n\n#def Create_Rank_Columns(db,dbGroup, NewColName, colName):\n#    starttime= dt.datetime.now()\n#    db[NewColName]= dbGroup[colName].rank(ascending= False)\n#    print(NewColName, \" created in time :\", dt.datetime.now()-starttime )\n#    return db\n\n#df= Create_Rank_Columns(df,df_Group1,'Rank_Points1','Points_')\n#df= Create_Rank_Columns(df,df_Group1,'Rank_kills1','kills_')\n#df= Create_Rank_Columns(df,df_Group1,'Rank_killassist1','kills_assists')\n#df= Create_Rank_Columns(df,df_Group1,'Rank_killtypes1','killtypes')\n#df= Create_Rank_Columns(df,df_Group1,'Rank_healthitems1','healthitems')\n\n#df= Create_Rank_Columns(df,df_Group2,'Rank_Points2','Points_')\n#df= Create_Rank_Columns(df,df_Group2,'Rank_kills2','kills_')\n#df= Create_Rank_Columns(df,df_Group2,'Rank_killassist2','kills_assists')\n#df= Create_Rank_Columns(df,df_Group2,'Rank_killtypes2','killtypes')\n#df= Create_Rank_Columns(df,df_Group2,'Rank_healthitems2','healthitems')\n\n#df['Rank1']= (df['Rank_Points1']+ df['Rank_kills1'] + df['Rank_killassist1']+ df['Rank_killtypes1']+ df['Rank_healthitems1'])/5\n#df['Rank2']= (df['Rank_Points2']+ df['Rank_kills2'] + df['Rank_killassist2']+ df['Rank_killtypes2']+ df['Rank_healthitems2'])/5\n\n#df= df.drop(columns = ColumnList)\nprint(df.columns)\n\nColumnList = df.columns.tolist()\nprint(ColumnList)\nColumnList.remove('Id')\nColumnList.remove('groupId')\nColumnList.remove('matchId')\nColumnList.remove('Type')\nColumnList.remove('winPlacePerc')\nColumnList.remove('matchType')\n\ndf= reduce_mem_usage(df)\n\ndf_Train = df[df['Type']== 'Train']\ndf_Test = df[df['Type']== 'Test']\nprint(\"Train and Test Data sets created\")\n\ndf_Train= df_Train.set_index(['Id', 'groupId', 'matchId','Type'])\ndf_Test= df_Test.set_index(['Id', 'groupId', 'matchId','Type'])\nprint(\"Indexes set\")\n\nX_Train = df_Train[ColumnList]\nY_Train = df_Train[Y_Column]\n\nX_test = df_Test[ColumnList]\n\nprint(X_Train.shape, Y_Train.shape, X_test.shape)\ndel df, df_Train, df_Test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf1c6b0648180d80b0da8ae93a8f51b7466765dd"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64bb3b1d686c3e03bc4aa9742722b2cdc073d324"},"cell_type":"code","source":"X_Train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed96a4173b1249dbb469a037ad16be080f86c513"},"cell_type":"code","source":"%%time\n# For tuning parameters\nstarttime = dt.datetime.now()\nd_train1 = lgb.Dataset(X_Train, label=Y_Train.values)\nparams = {}\nparams['learning_rate'] = 0.09\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = 'mae'\nparams['sub_feature'] = 0.8\nparams['num_leaves'] = 1000\nparams['min_data'] = 1\nparams['max_depth'] = 400\nparams['min_gain_to_split']= 0.0000001\nclf1 = lgb.train(params, d_train1, 1000)\nprint(\"Model created in \", dt.datetime.now()- starttime)\n#y_pred=clf1.predict(X_Train.head(1000))\ny_pred=clf1.predict(X_test)\n\nprint(y_pred)\n#[0.2522337  0.82816766 0.52467091 ... 0.40437544 0.70938478 0.22089762]\n#CPU times: user 11 s, sys: 432 ms, total: 11.4 s\n#Wall time: 3 s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4331e4ccb4c0aa47c45ff1fe5f18d7e6a77e358a"},"cell_type":"code","source":"# Restore some columns\ndel X_Train\nX_test = X_test.reset_index()\nX_test[\"winPlacePerc\"] = y_pred\nX_test = X_test[['Id',\"winPlacePerc\"]]\ndf_test = df_test[['Id','groupId']]\ndf_test= df_test.merge(X_test, on = ['Id'])\ndel X_test\ndf_test[\"winPlacePerc\"]= df_test[\"winPlacePerc\"].clip(lower = 0.0, upper= 1.0)\nprint(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27397f229b3eaaea804ae609bab58222b44f04dd"},"cell_type":"code","source":"df_test[['Id',\"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}