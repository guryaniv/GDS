{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c13b7f5-9318-4874-7a64-b0e0ee1a69b5"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stops = set(stopwords.words(\"english\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ed830bda-5b1f-d869-d759-9f1dcf13d8ac"
      },
      "outputs": [],
      "source": [
        "## Training set\n",
        "train_df = pd.read_csv('../input/train.csv', nrows=1000)\n",
        "\n",
        "## Test Set\",\n",
        "test_df = pd.read_csv('../input/test.csv', nrows=1000)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1e1f839-a6c4-c1bb-2fc6-5e8ddf528af2"
      },
      "outputs": [],
      "source": [
        "def word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
        "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
        "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
        "    return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "193aa9db-156d-fda8-545b-811c222357a8"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "# If a word appears only once, we ignore it completely (likely a typo)\n",
        "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
        "\n",
        "def get_weight(count, eps=10000, min_count=2):\n",
        "    if count < min_count:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1 / (count + eps)\n",
        "\n",
        "eps = 5000 \n",
        "train_qs = pd.Series(train_df['question1'].tolist() + train_df['question2'].tolist()).astype(str)\n",
        "words = (\" \".join(train_qs)).lower().split()\n",
        "counts = Counter(words)\n",
        "weights = {word: get_weight(count) for word, count in counts.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8796293e-6a23-00c0-aff1-c03161c62294"
      },
      "outputs": [],
      "source": [
        "def tfidf_word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    \n",
        "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
        "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
        "    \n",
        "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
        "    return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0369a399-2119-526e-92f9-a5c996d79d81"
      },
      "outputs": [],
      "source": [
        "def stop_ratio(question):\n",
        "    q = set(question)\n",
        "    if len(q) == 0:\n",
        "        return 0\n",
        "    qwords = q.difference(stops)\n",
        "    qstops = q.intersection(stops)\n",
        "    return len(qstops) / len(q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23755709-876d-5375-2600-9fbb425b89a7"
      },
      "outputs": [],
      "source": [
        "def uniq1_ratio(row):\n",
        "    uniq_1 = set(row[\"question1\"].lower().replace(\" \",\"\"))\n",
        "    uniq_2 = set(row[\"question2\"].lower().replace(\" \",\"\"))\n",
        "    return len(uniq_1) / len(uniq_1 | uniq_2)\n",
        "\n",
        "def uniq2_ratio(row):\n",
        "    uniq_1 = set(row[\"question1\"].lower().replace(\" \",\"\"))\n",
        "    uniq_2 = set(row[\"question2\"].lower().replace(\" \",\"\"))\n",
        "    return len(uniq_2) / len(uniq_1 | uniq_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93395a87-f27d-c6c0-dca0-f946be5e44c0"
      },
      "outputs": [],
      "source": [
        "def create_features(df):\n",
        "    df[\"question1\"].fillna(\"\", inplace=True)\n",
        "    df[\"question2\"].fillna(\"\", inplace=True)\n",
        "\n",
        "    df[\"question1\"] = df[\"question1\"].apply(str)\n",
        "    df[\"question2\"] = df[\"question2\"].apply(str)\n",
        "    \n",
        "    print(\"len\")\n",
        "    df[\"q1_len\"] = df[\"question1\"].apply(len)\n",
        "    df[\"q2_len\"] = df[\"question1\"].apply(len)\n",
        "    df[\"diff_len\"] = abs(df[\"q1_len\"] - df[\"q2_len\"])\n",
        "    \n",
        "    print(\"len word\")\n",
        "    df[\"q1_len_word\"] = df[\"question1\"].apply(lambda x: len(x.split()))\n",
        "    df[\"q2_len_word\"] = df[\"question1\"].apply(lambda x: len(x.split()))\n",
        "    df[\"diff_len_word\"] = abs(df[\"q1_len_word\"] - df[\"q2_len_word\"])\n",
        "    \n",
        "    print(\"avg len word\")\n",
        "    df['q1_avg_len_word'] = df['q1_len'] / df['q1_len_word']\n",
        "    df['q2_avg_len_word'] = df['q2_len'] / df['q2_len_word']\n",
        "    df['diff_avg_len_word'] = abs(df['q1_avg_len_word'] - df['q2_avg_len_word'])\n",
        "    \n",
        "    print(\"unique char\")\n",
        "    df[\"q1_n_uniquechar\"] = df[\"question1\"].apply(lambda x: len(\"\".join(set(x.replace(\" \",\"\")))))\n",
        "    df[\"q2_n_uniquechar\"] = df[\"question2\"].apply(lambda x: len(\"\".join(set(x.replace(\" \",\"\")))))\n",
        "    df[\"diff_n_uniquechar\"] = abs(df[\"q1_n_uniquechar\"] - df[\"q2_n_uniquechar\"])\n",
        "\n",
        "    print(\"W word\")\n",
        "    df[\"q1_how\"]   = df[\"question1\"].apply(lambda x : \"how\"   in x.lower())\n",
        "    df[\"q1_who\"]   = df[\"question1\"].apply(lambda x : \"who\"   in x.lower())\n",
        "    df[\"q1_why\"]   = df[\"question1\"].apply(lambda x : \"why\"   in x.lower())\n",
        "    df[\"q1_what\"]  = df[\"question1\"].apply(lambda x : \"what\"  in x.lower())\n",
        "    df[\"q1_where\"] = df[\"question1\"].apply(lambda x : \"where\" in x.lower())\n",
        "    df[\"q1_which\"] = df[\"question1\"].apply(lambda x : \"which\" in x.lower())\n",
        "\n",
        "    df[\"q2_how\"]   = df[\"question2\"].apply(lambda x : \"how\"   in x.lower())\n",
        "    df[\"q2_who\"]   = df[\"question2\"].apply(lambda x : \"who\"   in x.lower())\n",
        "    df[\"q2_why\"]   = df[\"question2\"].apply(lambda x : \"why\"   in x.lower())\n",
        "    df[\"q2_what\"]  = df[\"question2\"].apply(lambda x : \"what\"  in x.lower())\n",
        "    df[\"q2_where\"] = df[\"question2\"].apply(lambda x : \"where\" in x.lower())\n",
        "    df[\"q2_which\"] = df[\"question2\"].apply(lambda x : \"which\" in x.lower())\n",
        "    \n",
        "    df[\"q1q2_how\"]   = df[\"q1_how\"]   == df[\"q2_how\"]\n",
        "    df[\"q1q2_who\"]   = df[\"q1_who\"]   == df[\"q2_who\"]\n",
        "    df[\"q1q2_why\"]   = df[\"q1_why\"]   == df[\"q2_why\"]\n",
        "    df[\"q1q2_what\"]  = df[\"q1_what\"]  == df[\"q2_what\"]\n",
        "    df[\"q1q2_where\"] = df[\"q1_where\"] == df[\"q2_where\"]\n",
        "    df[\"q1q2_which\"] = df[\"q1_which\"] == df[\"q2_which\"]\n",
        "    \n",
        "    print(\"stop ratio\")\n",
        "    df[\"q1_stop_ratio\"] = df[\"question1\"].apply(stop_ratio)\n",
        "    df[\"q2_stop_ratio\"] = df[\"question2\"].apply(stop_ratio)\n",
        "    df[\"diff_stop_ratio\"] = abs(df[\"q1_stop_ratio\"] - df[\"q2_stop_ratio\"])\n",
        "\n",
        "    print(\"math\")\n",
        "    df[\"q1_math\"] = df[\"question1\"].apply(lambda x: '[math]' in x)\n",
        "    df[\"q2_math\"] = df[\"question2\"].apply(lambda x: '[math]' in x)\n",
        "    df[\"q1q2_math\"] = df[\"q1_math\"] == df[\"q2_math\"]\n",
        "    \n",
        "    print(\"nqmark\")\n",
        "    df[\"q1_nqmark\"] = df[\"question1\"].apply(lambda x: x.count('?'))\n",
        "    df[\"q2_nqmark\"] = df[\"question2\"].apply(lambda x: x.count('?'))\n",
        "    df[\"diff_nqmark\"] = abs(df[\"q1_nqmark\"] - df[\"q2_nqmark\"])\n",
        "    \n",
        "    print(\"nperiod\")\n",
        "    df[\"q1_nperiod\"] = df[\"question1\"].apply(lambda x: x.count('.'))\n",
        "    df[\"q2_nperiod\"] = df[\"question2\"].apply(lambda x: x.count('.'))\n",
        "    df[\"diff_nperiod\"] = abs(df[\"q1_nperiod\"] - df[\"q2_nperiod\"])\n",
        "\n",
        "    print(\"capitalfirst\")\n",
        "    df[\"q1_capitalfirst\"] = df[\"question1\"].apply(lambda x: x[0].isupper() if len(x) > 0 else False)\n",
        "    df[\"q2_capitalfirst\"] = df[\"question2\"].apply(lambda x: x[0].isupper() if len(x) > 0 else False)\n",
        "    df[\"q1q2_capitalfirst\"] = df[\"q1_capitalfirst\"] == df[\"q2_capitalfirst\"]\n",
        "\n",
        "    print(\"has capital\")\n",
        "    df[\"q1_has_capital\"] = df[\"question1\"].apply(lambda x: any([l.isupper() for l in x]))\n",
        "    df[\"q2_has_capital\"] = df[\"question2\"].apply(lambda x: any([l.isupper() for l in x]))\n",
        "    df[\"q1q2_has_capital\"] = df[\"q1_has_capital\"] == df[\"q2_has_capital\"]\n",
        "\n",
        "    print(\"n capitals\")\n",
        "    df[\"q1_n_capitals\"] = df[\"question1\"].apply(lambda x: sum([1 for c in x if c.isupper()]))\n",
        "    df[\"q2_n_capitals\"] = df[\"question2\"].apply(lambda x: sum([1 for c in x if c.isupper()]))\n",
        "    df[\"diff_n_capitals\"] = abs(df[\"q1_n_capitals\"] - df[\"q2_n_capitals\"])\n",
        "    \n",
        "    print(\"is identical\")\n",
        "    df[\"is_identical\"] = (df[\"question1\"].apply(lambda x: x.lower()) == df[\"question2\"].apply(lambda x: x.lower()))    \n",
        "\n",
        "    print(\"unique ratio\")\n",
        "    df[\"q1_unique_ratio\"] = df.apply(uniq1_ratio ,axis=1)\n",
        "    df[\"q2_unique_ratio\"] = df.apply(uniq2_ratio ,axis=1)\n",
        "\n",
        "    #df[\"similarity_prob\"] = df.apply(lambda row: SequenceMatcher(None, row[\"question1\"],row[\"question2\"]).ratio(),axis=1)\n",
        "    \n",
        "    print(\"text prop\")\n",
        "    df[\"q1_isalnum\"]   =  df[\"question1\"].apply(lambda x: x.isalnum())\n",
        "    df[\"q1_isalpha\"]   =  df[\"question1\"].apply(lambda x: x.isalpha())\n",
        "    df[\"q1_isdecimal\"] =  df[\"question1\"].apply(lambda x: x.isdecimal())\n",
        "    df[\"q1_isdigit\"]   =  df[\"question1\"].apply(lambda x: x.isdigit())\n",
        "    df[\"q1_islower\"]   =  df[\"question1\"].apply(lambda x: x.islower())\n",
        "    df[\"q1_isnumeric\"] =  df[\"question1\"].apply(lambda x: x.isnumeric())\n",
        "    df[\"q1_isspace\"]   =  df[\"question1\"].apply(lambda x: x.isspace())\n",
        "    df[\"q1_isupper\"]   =  df[\"question1\"].apply(lambda x: x.isupper())\n",
        "    \n",
        "    df[\"q2_isalnum\"]   =  df[\"question2\"].apply(lambda x: x.isalnum())\n",
        "    df[\"q2_isalpha\"]   =  df[\"question2\"].apply(lambda x: x.isalpha())\n",
        "    df[\"q2_isdecimal\"] =  df[\"question2\"].apply(lambda x: x.isdecimal())\n",
        "    df[\"q2_isdigit\"]   =  df[\"question2\"].apply(lambda x: x.isdigit())\n",
        "    df[\"q2_islower\"]   =  df[\"question2\"].apply(lambda x: x.islower())\n",
        "    df[\"q2_isnumeric\"] =  df[\"question2\"].apply(lambda x: x.isnumeric())\n",
        "    df[\"q2_isspace\"]   =  df[\"question2\"].apply(lambda x: x.isspace())\n",
        "    df[\"q2_isupper\"]   =  df[\"question2\"].apply(lambda x: x.isupper())\n",
        "    \n",
        "    df[\"q1q2_isalnum\"]   = df[\"q1_isalnum\"]   == df[\"q2_isalnum\"]\n",
        "    df[\"q1q2_isalpha\"]   = df[\"q1_isalpha\"]   == df[\"q2_isalpha\"]\n",
        "    df[\"q1q2_isdecimal\"] = df[\"q1_isdecimal\"] == df[\"q2_isdecimal\"]\n",
        "    df[\"q1q2_isdigit\"]   = df[\"q1_isdigit\"]   == df[\"q2_isdigit\"]\n",
        "    df[\"q1q2_islower\"]   = df[\"q1_islower\"]   == df[\"q2_islower\"]\n",
        "    df[\"q1q2_isnumeric\"] = df[\"q1_isnumeric\"] == df[\"q2_isnumeric\"]\n",
        "    df[\"q1q2_isspace\"]   = df[\"q1_isspace\"]   == df[\"q2_isspace\"]\n",
        "    df[\"q1q2_isupper\"]   = df[\"q1_isupper\"]   == df[\"q2_isupper\"]\n",
        "    \n",
        "    print(\"word share\")\n",
        "    df[\"word_match_share\"] = df.apply(lambda row: word_match_share(row), axis=1)\n",
        "    df[\"tfidf_word_match_share\"] = df.apply(lambda row: tfidf_word_match_share(row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "926d83c5-4740-bdb4-1251-976bf7b5cb3f"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.hist(train_df[train_df[\"is_duplicate\"]==0][\"tfidf_word_match_share\"],bins=100,range=(0,1),alpha=0.5,normed=True)\n",
        "plt.hist(train_df[train_df[\"is_duplicate\"]==1][\"tfidf_word_match_share\"],bins=100,range=(0,1),alpha=0.5,normed=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dec76cfc-8f32-6dfe-bc54-e487e311fe2a"
      },
      "outputs": [],
      "source": [
        "# bag of letter sequences (chars)\n",
        "BagOfWordsExtractor = CountVectorizer(max_df=0.999, min_df=1000, max_features=300, \n",
        "                                      analyzer='char', ngram_range=(1,2),\n",
        "                                      binary=True, lowercase=True)\n",
        "\n",
        "BagOfWordsExtractor.fit(train_qs.unique())\n",
        "\n",
        "trainQuestion1_BOW_rep = BagOfWordsExtractor.transform(train_df.ix[:,'question1'])\n",
        "trainQuestion2_BOW_rep = BagOfWordsExtractor.transform(train_df.ix[:,'question2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff5f0a19-8a69-95b0-f886-851c26531cc8"
      },
      "outputs": [],
      "source": [
        "X = (trainQuestion1_BOW_rep + trainQuestion2_BOW_rep).astype(int)/2.\n",
        "print(X[0].todense())\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4348611f-5e31-a7ff-348b-3b4d8cd2c53c"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Merge, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d1af746-e125-5e27-9976-6eb50cbc06bf"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(X.shape[1], input_dim=X.shape[1]))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam')\n",
        "\n",
        "history = model.fit(X.toarray(),train_df.is_duplicate.values,\n",
        "                    batch_size=1,\n",
        "                    epochs=20,\n",
        "                    validation_split=0.2)\n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}