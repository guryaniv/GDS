{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7bb19dd-a984-d55e-7b69-98dea421945e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import gc\n",
        "from sklearn.linear_model import ElasticNetCV, LassoLarsCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from sklearn.utils import check_array\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "from sklearn.decomposition import PCA, FastICA\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import r2_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4d97bd8d-6191-d698-d889-686a8d605d5e"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train_2016.csv')\n",
        "prop = pd.read_csv('../input/properties_2016.csv')\n",
        "sample = pd.read_csv('../input/sample_submission.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d1788e8-c4ba-e901-ed3d-b10773f739a9"
      },
      "outputs": [],
      "source": [
        "for c, dtype in zip(prop.columns, prop.dtypes):\n",
        "\tif dtype == np.float64:\n",
        "\t\tprop[c] = prop[c].astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "df_train = train.merge(prop, how='left', on='parcelid')\n",
        "\n",
        "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode', 'basementsqft', 'buildingclasstypeid', 'finishedsquarefeet13', 'storytypeid'], axis=1)\n",
        "y_train = df_train['logerror'].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_columns = x_train.columns\n",
        "\n",
        "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
        "    x_train[c] = (x_train[c] == True)\n",
        "    \n",
        "    \n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "#clean data \n",
        "x_train = x_train.fillna(0.0)\n",
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c7564b4-19e1-3d48-2a07-1d4936588df0"
      },
      "outputs": [],
      "source": [
        "n_comp = 12\n",
        "\n",
        "# tSVD\n",
        "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
        "tsvd_results_train = tsvd.fit_transform(x_train)\n",
        "\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=n_comp, random_state=420)\n",
        "pca2_results_train = pca.fit_transform(x_train)\n",
        "\n",
        "\n",
        "# ICA\n",
        "ica = FastICA(n_components=n_comp, random_state=420)\n",
        "ica2_results_train = ica.fit_transform(x_train)\n",
        "\n",
        "\n",
        "# GRP\n",
        "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
        "grp_results_train = grp.fit_transform(x_train)\n",
        "\n",
        "# SRP\n",
        "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
        "srp_results_train = srp.fit_transform(x_train)\n",
        "\n",
        "# Append decomposition components to datasets\n",
        "for i in range(1, n_comp + 1):\n",
        "    x_train['pca_' + str(i)] = pca2_results_train[:, i - 1]\n",
        "    #test['pca_' + str(i)] = pca2_results_test[:, i - 1]\n",
        "\n",
        "    x_train['ica_' + str(i)] = ica2_results_train[:, i - 1]\n",
        "    #test['ica_' + str(i)] = ica2_results_test[:, i - 1]\n",
        "\n",
        "    x_train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
        "    #test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n",
        "\n",
        "    x_train['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
        "    #test['grp_' + str(i)] = grp_results_test[:, i - 1]\n",
        "\n",
        "    x_train['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
        "    #test['srp_' + str(i)] = srp_results_test[:, i - 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3bb7486a-eb37-73bd-2625-78365359c464"
      },
      "outputs": [],
      "source": [
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "03e5cc6a-d872-49ff-53e3-f7fe58a04f47"
      },
      "outputs": [],
      "source": [
        "split = 80000\n",
        "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
        "\n",
        "print('building data matrix...')\n",
        "\n",
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
        "\n",
        "\n",
        "print('training ...')\n",
        "params = {}\n",
        "params['eta'] = 0.02\n",
        "params['objective'] = 'reg:linear'\n",
        "params['eval_metric'] = ['rmse', 'logloss']\n",
        "params['max_depth'] = 9\n",
        "params['silent'] = 1\n",
        "params['subsample'] = 0.7\n",
        "params['colsample_bytree'] = 0.7\n",
        "\n",
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "\n",
        "cv_output = xgb.cv(params, d_train, num_boost_round=3000, early_stopping_rounds=20,\n",
        "    verbose_eval=50, show_stdv=False)\n",
        "\n",
        "num_boost_rounds = len(cv_output)\n",
        "\n",
        "clf = xgb.train(params, d_train, num_boost_round= num_boost_rounds)\n",
        "\n",
        "del d_train, d_valid\n",
        "\n",
        "print('Building test set ...')\n",
        "\n",
        "sample['parcelid'] = sample['ParcelId']\n",
        "df_test = sample.merge(prop, on='parcelid', how='left')\n",
        "\n",
        "del prop; gc.collect()\n",
        "\n",
        "x_test = df_test[train_columns]\n",
        "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
        "    x_test[c] = (x_test[c] == True)\n",
        "\n",
        "del df_test, sample; gc.collect()\n",
        "\n",
        "d_test = xgb.DMatrix(x_test)\n",
        "\n",
        "del x_test; gc.collect()\n",
        "\n",
        "print('Predicting on test ...')\n",
        "\n",
        "p_test = clf.predict(d_test)\n",
        "\n",
        "del d_test; gc.collect()\n",
        "\n",
        "result = pd.read_csv('../input/sample_submission.csv')\n",
        "\n",
        "for c in result.columns[result.columns != 'ParcelId']:\n",
        "    result[c] = p_test\n",
        "\n",
        "print('writing csv output ...')\n",
        "result.to_csv('predictions.csv', index=False, float_format='%.4f') # Thanks to @inversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "079ea6f2-598f-89b1-3541-8ed65cd3f7e7"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}