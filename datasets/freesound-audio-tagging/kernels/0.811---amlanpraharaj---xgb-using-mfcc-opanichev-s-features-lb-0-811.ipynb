{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport librosa\n#from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\nfrom scipy.stats import skew\nSAMPLE_RATE = 44100\n\n#from sklearn.model_selection import KFold, RepeatedKFold\nfrom tqdm import tqdm, tqdm_pandas\n\ntqdm.pandas()\nimport scipy\ndata_path = '../input/'\nss = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":false},"cell_type":"code","source":"#loading data\naudio_train_files = os.listdir('../input/audio_train')\naudio_test_files = os.listdir('../input/audio_test')\n\ntrain = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98ec03e6-ff01-4acb-92af-ddae08839162","_uuid":"3007f57b4346ef16effdd1fdb2e134fc3521da81","collapsed":true,"trusted":false},"cell_type":"code","source":"#function from EDA kernel: https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis\ndef clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name\n\n#returns mfcc features with mean and standard deviation along time\ndef get_mfcc(name, path):\n    b, _ = librosa.core.load(path + name, sr = SAMPLE_RATE)\n    assert _ == SAMPLE_RATE\n    try:\n        ft1 = librosa.feature.mfcc(b, sr = SAMPLE_RATE, n_mfcc=20)\n        ft2 = librosa.feature.zero_crossing_rate(b)[0]\n        ft3 = librosa.feature.spectral_rolloff(b)[0]\n        ft4 = librosa.feature.spectral_centroid(b)[0]\n        ft5 = librosa.feature.spectral_contrast(b)[0]\n        ft6 = librosa.feature.spectral_bandwidth(b)[0]\n        ft1_trunc = np.hstack((np.mean(ft1, axis=1), np.std(ft1, axis=1), skew(ft1, axis = 1), np.max(ft1, axis = 1), np.min(ft1, axis = 1)))\n        ft2_trunc = np.hstack((np.mean(ft2), np.std(ft2), skew(ft2), np.max(ft2), np.min(ft2)))\n        ft3_trunc = np.hstack((np.mean(ft3), np.std(ft3), skew(ft3), np.max(ft3), np.min(ft3)))\n        ft4_trunc = np.hstack((np.mean(ft4), np.std(ft4), skew(ft4), np.max(ft4), np.min(ft4)))\n        ft5_trunc = np.hstack((np.mean(ft5), np.std(ft5), skew(ft5), np.max(ft5), np.min(ft5)))\n        ft6_trunc = np.hstack((np.mean(ft6), np.std(ft6), skew(ft6), np.max(ft6), np.m(ft6)))\n        return pd.Series(np.hstack((ft1_trunc, ft2_trunc, ft3_trunc, ft4_trunc, ft5_trunc, ft6_trunc)))\n    except:\n        print('bad file')\n        return pd.Series([0]*125)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"764f6a4d-9f5b-4977-a80f-7c99d0cd15e5","_uuid":"0a7b3047cec100da83d79f593d3c01e3379559fa","collapsed":true,"trusted":false},"cell_type":"code","source":"#preparing data\ntrain_data = pd.DataFrame()\ntrain_data['fname'] = train['fname']\ntest_data = pd.DataFrame()\ntest_data['fname'] = audio_test_files\n\ntrain_data = train_data['fname'].progress_apply(get_mfcc, path='../input/audio_train/')\nprint('done loading train mfcc')\ntest_data = test_data['fname'].progress_apply(get_mfcc, path='../input/audio_test/')\nprint('done loading test mfcc')\n\ntrain_data['fname'] = train['fname']\ntest_data['fname'] = audio_test_files\ntrain_data['label'] = train['label']\ntest_data['label'] = np.zeros((len(audio_test_files)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"082273ba-fca1-46d5-9370-26350e427e96","_uuid":"364dc66fb3dcb899fcb14ce9b2841bb7b7786765","collapsed":true,"trusted":false},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"71f29be4-fb8e-4ea8-874e-e448db2e6cab","_uuid":"e89ca5ec15004b3a4d06bc849a2790fa1d1b6258","collapsed":true,"trusted":false},"cell_type":"code","source":"#Features from LightGBM baseline kernel: https://www.kaggle.com/opanichev/lightgbm-baseline\n# MAPk from https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\ndef apk(actual, predicted, k=10):\n    \"\"\"\n    Computes the average precision at k.\n    This function computes the average prescision at k between two lists of\n    items.\n    Parameters\n    ----------\n    actual : list\n             A list of elements that are to be predicted (order doesn't matter)\n    predicted : list\n                A list of predicted elements (order does matter)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The average precision at k over the input lists\n    \"\"\"\n    if len(predicted)>k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i,p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits / (i+1.0)\n\n    if not actual:\n        return 0.0\n\n    return score / min(len(actual), k)\n\ndef mapk(actual, predicted, k=10):\n    \"\"\"\n    Computes the mean average precision at k.\n    This function computes the mean average prescision at k between two lists\n    of lists of items.\n    Parameters\n    ----------\n    actual : list\n             A list of lists of elements that are to be predicted \n             (order doesn't matter in the lists)\n    predicted : list\n                A list of lists of predicted elements\n                (order matters in the lists)\n    k : int, optional\n        The maximum number of predicted elements\n    Returns\n    -------\n    score : double\n            The mean average precision at k over the input lists\n    \"\"\"\n    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n\n\ndef extract_features(files, path):\n    features = {}\n\n    cnt = 0\n    for f in tqdm(files):\n        features[f] = {}\n\n        fs, data = scipy.io.wavfile.read(os.path.join(path, f))\n\n        abs_data = np.abs(data)\n        diff_data = np.diff(data)\n\n        def calc_part_features(data, n=2, prefix=''):\n            f_i = 1\n            for i in range(0, len(data), len(data)//n):\n                features[f]['{}mean_{}_{}'.format(prefix, f_i, n)] = np.mean(data[i:i + len(data)//n])\n                features[f]['{}std_{}_{}'.format(prefix, f_i, n)] = np.std(data[i:i + len(data)//n])\n                features[f]['{}min_{}_{}'.format(prefix, f_i, n)] = np.min(data[i:i + len(data)//n])\n                features[f]['{}max_{}_{}'.format(prefix, f_i, n)] = np.max(data[i:i + len(data)//n])\n\n        features[f]['len'] = len(data)\n        if features[f]['len'] > 0:\n            n = 1\n            calc_part_features(data, n=n)\n            calc_part_features(abs_data, n=n, prefix='abs_')\n            calc_part_features(diff_data, n=n, prefix='diff_')\n\n            n = 2\n            calc_part_features(data, n=n)\n            calc_part_features(abs_data, n=n, prefix='abs_')\n            calc_part_features(diff_data, n=n, prefix='diff_')\n\n            n = 3\n            calc_part_features(data, n=n)\n            calc_part_features(abs_data, n=n, prefix='abs_')\n            calc_part_features(diff_data, n=n, prefix='diff_')\n\n\n        cnt += 1\n\n        # if cnt >= 1000:\n        #     break\n\n    features = pd.DataFrame(features).T.reset_index()\n    features.rename(columns={'index': 'fname'}, inplace=True)\n    \n    return features\n\npath = os.path.join(data_path, 'audio_train')\ntrain_files = train.fname.values\ntrain_features = extract_features(train_files, path)\n\npath = os.path.join(data_path, 'audio_test')\ntest_files = ss.fname.values\ntest_features = extract_features(test_files, path)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"58e74ba2-ad9c-446d-934e-02dc6a116fbf","_uuid":"1ed3a7f20f8b92529d2dd3ce636c344c60825c44","collapsed":true,"trusted":false},"cell_type":"code","source":"train_data = train_data.merge(train_features, on='fname', how='left')\ntest_data = test_data.merge(test_features, on='fname', how='left')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ce971a7-b73a-4719-b50d-967b40da77eb","_uuid":"f61a3992c82e01d0b1c63af1cfe2d8b7dcaa3ba0","collapsed":true,"trusted":false},"cell_type":"code","source":"#Functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\n# Construct features set\nX = train_data.drop(['label', 'fname'], axis=1)\nfeature_names = list(X.columns)\nX = X.values\nlabels = np.sort(np.unique(train_data.label.values))\nnum_class = len(labels)\nc2i = {}\ni2c = {}\nfor i, c in enumerate(labels):\n    c2i[c] = i\n    i2c[i] = c\ny = np.array([c2i[x] for x in train_data.label.values])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98a0d2b0-c474-48c9-ac38-ce986f44950e","_uuid":"bda6a2934e3d8369b3ceab67c728b1b149f0f217","collapsed":true,"trusted":false},"cell_type":"code","source":"#fitting xgboost on the dataset\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10, shuffle = True)\nclf = XGBClassifier(max_depth=5, learning_rate=0.05, n_estimators=3000,\n                    n_jobs=-1, random_state=0, reg_alpha=0.2, \n                    colsample_bylevel=0.9, colsample_bytree=0.9)\nclf.fit(X_train, y_train)\nprint(accuracy_score(clf.predict(X_val), y_val))\n#more functions from LightGBM baseline: https://www.kaggle.com/opanichev/lightgbm-baseline\ndef proba2labels(preds, i2c, k=3):\n    ans = []\n    ids = []\n    for p in preds:\n        idx = np.argsort(p)[::-1]\n        ids.append([i for i in idx[:k]])\n        ans.append(' '.join([i2c[i] for i in idx[:k]]))\n\n    return ans, ids","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ab6e3a6a-458b-4f2b-9109-6d2821f85320","_uuid":"124c03cd99787dfb2c2bde67fe0e48824bd9fafa","collapsed":true,"trusted":false},"cell_type":"code","source":"#fitting on the entire data\n\nclf.fit(X, y)\nstr_preds, _ = proba2labels(clf.predict_proba(test_data.drop(['label', 'fname'], axis = 1).values), i2c, k=3)\n# Prepare submission\nsubm = pd.DataFrame()\nsubm['fname'] = audio_test_files\nsubm['label'] = str_preds\nsubm.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64328b80-d5b9-427b-a485-aa086dac2179","_uuid":"90ed554c868c7ba00c1e936b1e5d942dad0b3a9c","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}