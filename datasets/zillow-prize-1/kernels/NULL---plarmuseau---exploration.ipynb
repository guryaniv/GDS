{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.1", "mimetype": "text/x-python"}}, "cells": [{"metadata": {"_cell_guid": "7352f94b-b636-41c7-96d2-715f95842e2a", "_uuid": "3908d8c205853aac84133ddde4851d3487c8cc81"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"]}, {"metadata": {"_cell_guid": "c4ea28d4-baca-4571-9157-f919b46bdbde", "_uuid": "2b24f75ba4e11175340be89adba3fd782a0b126a"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from sklearn.preprocessing import LabelEncoder\n", "\n", "properties = pd.read_csv(\"../input/properties_2016.csv\")\n", "\n", "for c in properties.columns:\n", "    properties[c]=properties[c].fillna(-1)\n", "    if properties[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(properties[c].values))\n", "        properties[c] = lbl.transform(list(properties[c].values))\n", "        \n", "properties.describe().T"]}, {"metadata": {"_cell_guid": "3df1e8b2-109f-4ceb-9cbc-cf257ffcd6af", "_uuid": "cf470c10f203b3c004af58c27a965f8dcf1bbe73"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["train = pd.read_csv(\"../input/train_2016_v2.csv\")\n", "import matplotlib.pyplot as plt\n", "plt.hist(train['logerror'],200)\n", "plt.title(\"Histogram of logerror\")\n", "plt.xlabel(\"Value\")\n", "plt.ylabel(\"Frequency\")\n", "plt.show()\n", "train=pd.merge(train, properties, on='parcelid', how='left')"]}, {"metadata": {"_cell_guid": "19d1ae0d-e295-45da-9b07-513910239c3f", "collapsed": true, "_uuid": "938b9bdf4f47315036d52158c8c86bc807476eb9"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["def dddraw(X_reduced,name):\n", "    import matplotlib.pyplot as plt\n", "    from mpl_toolkits.mplot3d import Axes3D\n", "    # To getter a better understanding of interaction of the dimensions\n", "    # plot the first three PCA dimensions\n", "    fig = plt.figure(1, figsize=(8, 6))\n", "    ax = Axes3D(fig, elev=-150, azim=110)\n", "    ax.scatter(X_reduced[:, 0], X_reduced[:, 1], X_reduced[:, 2], c=Y,cmap=plt.cm.Paired)\n", "    titel=\"First three directions of \"+name \n", "    ax.set_title(titel)\n", "    ax.set_xlabel(\"1st eigenvector\")\n", "    ax.w_xaxis.set_ticklabels([])\n", "    ax.set_ylabel(\"2nd eigenvector\")\n", "    ax.w_yaxis.set_ticklabels([])\n", "    ax.set_zlabel(\"3rd eigenvector\")\n", "    ax.w_zaxis.set_ticklabels([])\n", "\n", "    plt.show()"]}, {"metadata": {"_cell_guid": "4b877912-a16d-4b8c-93ab-aa3ced911d98", "_uuid": "f4866cf3b6614e45eb84c55e42f9d94604646d9c"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from collections import Counter\n", "def todrop_col(df,tohold):\n", "    # use todrop_col(dataframe,['listtohold'])\n", "    # Categorical features\n", "    df.replace([np.inf, -np.inf], np.nan).fillna(value=-1)\n", "    \n", "    cat_cols = []\n", "    for c in df.columns:\n", "        if df[c].dtype == 'object':\n", "            cat_cols.append(c)\n", "    #print('Categorical columns:', cat_cols)\n", "    \n", "    \n", "    # Constant columns\n", "    cols = df.columns.values    \n", "    const_cols = []\n", "    for c in cols:   \n", "        if len(df[c].unique()) == 1:\n", "            const_cols.append(c)\n", "    #print('Constant cols:', const_cols)\n", "    \n", "    \n", "    # Dublicate features\n", "    d = {}; done = []\n", "    cols = df.columns.values\n", "    for c in cols:\n", "        d[c]=[]\n", "    for i in range(len(cols)):\n", "        if i not in done:\n", "            for j in range(i+1, len(cols)):\n", "                if all(df[cols[i]] == df[cols[j]]):\n", "                    done.append(j)\n", "                    d[cols[i]].append(cols[j])\n", "    dub_cols = []\n", "    for k in d.keys():\n", "        if len(d[k]) > 0: \n", "            # print k, d[k]\n", "            dub_cols += d[k]        \n", "    #print('Dublicates:', dub_cols)\n", "    \n", "    kolom=list(set(dub_cols+const_cols+cat_cols))\n", "    kolom=[k for k in kolom if k not in tohold]\n", "    \n", "    return kolom\n", "\n", "tohold=[]\n", "print(todrop_col(train,tohold))\n", "#print(todrop_col(properties,tohold))"]}, {"metadata": {"_cell_guid": "8cc1066b-18a7-4048-8c7f-8a7505f1a505", "scrolled": false, "_uuid": "3893d1feae3b08b8efd0f42368c777c436faf134"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from sklearn.decomposition import PCA, FastICA,SparsePCA,NMF, LatentDirichletAllocation,FactorAnalysis\n", "from sklearn.random_projection import GaussianRandomProjection,SparseRandomProjection\n", "from sklearn.cluster import KMeans,Birch\n", "import statsmodels.formula.api as sm\n", "from scipy import linalg\n", "from sklearn import preprocessing\n", "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n", "def rmsle(y_predicted, y_real):\n", "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n", "def procenterror(y_predicted, y_real):\n", "     return ( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ).round()\n", "\n", "n_col=50\n", "X=train.drop(['logerror','assessmentyear', 'transactiondate'],axis=1)\n", "def rmsle(y_predicted, y_real):\n", "    return np.sqrt(np.mean(np.power(np.log1p(y_predicted)-np.log1p(y_real), 2)))\n", "def procenterror(y_predicted, y_real):\n", "     return np.round( np.mean(np.abs(y_predicted-y_real) )/ np.mean(y_real) *100 ,1)\n", "\n", "    \n", "Y=train['logerror'].fillna(value=0)\n", "X=X.fillna(value=0)  #nasty NaN\n", "scaler = MinMaxScaler()\n", "scaler.fit(X)\n", "X=scaler.transform(X)\n", "#poly = PolynomialFeatures(2)\n", "#X=poly.fit_transform(X)\n", "\n", "\n", "names = [\n", "         'PCA',\n", "         'FastICA',\n", "         'Gauss',\n", "         'KMeans',\n", "         'SparsePCA',\n", "         'SparseRP',\n", "         'Birch',\n", "         'NMF',    \n", "         'LatentDietrich',    \n", "        ]\n", "\n", "classifiers = [\n", "    \n", "    PCA(n_components=n_col),\n", "    FastICA(n_components=n_col),\n", "    GaussianRandomProjection(n_components=3),\n", "    KMeans(n_clusters=n_col),\n", "    SparsePCA(n_components=n_col),\n", "    SparseRandomProjection(n_components=n_col, dense_output=True),\n", "    Birch(branching_factor=10, n_clusters=7, threshold=0.5),\n", "    NMF(n_components=n_col),    \n", "    #LatentDirichletAllocation(n_topics=n_col),\n", "    \n", "]\n", "correction= [1,1,0,0,0,0,0,0,0]\n", "\n", "temp=zip(names,classifiers,correction)\n", "print(temp)\n", "\n", "for name, clf,correct in temp:\n", "    Xr=clf.fit_transform(X,Y)\n", "    dddraw(Xr,name)\n", "    res = sm.OLS(Y,Xr).fit()\n", "    print(res.summary())  # show OLS regression\n", "    #print(res.predict(Xr).round()+correct)  #show OLS prediction\n", "    #print('Ypredict',res.predict(Xr).round()+correct)  #show OLS prediction\n", "    \n", "    print('Ypredict',res.predict(Xr).round()+correct*Y.mean())  #show OLS prediction\n", "    print(name,'%error',procenterror(res.predict(Xr)+correct*Y.mean(),Y),'rmsle',rmsle(res.predict(Xr)+correct*Y.mean(),Y)) #\n", "    \n", "    \n", "    "]}, {"metadata": {"_cell_guid": "7a3e2b59-1b0d-4223-a9a7-864cf0958eee", "_uuid": "31fbc314851641fb82ddf76c7c4978e600e661b4"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["from sklearn.linear_model import OrthogonalMatchingPursuit,RANSACRegressor,LogisticRegression,ElasticNetCV,HuberRegressor, Ridge, Lasso,LassoCV,Lars,BayesianRidge,SGDClassifier,LogisticRegressionCV,RidgeClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.preprocessing import MinMaxScaler,PolynomialFeatures\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}\n", "\n", "X=train.drop(['fireplaceflag', 'taxdelinquencyflag', 'propertycountylandusecode', 'propertyzoningdesc', 'assessmentyear', 'transactiondate', 'hashottuborspa'],axis=1)\n", "Y=np.round(train['logerror'].fillna(value=0)*2)\n", "\n", "X=X.replace([np.inf, -np.inf], np.nan).fillna(value=0)\n", "scaler = MinMaxScaler()\n", "scaler.fit(X)\n", "X=scaler.transform(X)\n", "#poly = PolynomialFeatures(2)\n", "#X=poly.fit_transform(X)\n", "\n", "\n", "names = [\n", "         #677% 'ElasticNet',\n", "         #timeout 'SVC',\n", "         #98.61% 'kSVC',\n", "         'KNN',\n", "         'DecisionTree',\n", "         #'RandomForestClassifier',\n", "         #'GridSearchCV',\n", "         #400%error 'HuberRegressor',\n", "         #683% 'Ridge',\n", "         #511% 'Lasso',\n", "         #683% 'LassoCV',\n", "         #681% 'Lars',\n", "         'BayesianRidge',\n", "         #415% 'SGDClassifier',\n", "         #410%'RidgeClassifier',\n", "         #406% 'LogisticRegression',\n", "         #684% 'OrthogonalMatchingPursuit',\n", "         #'RANSACRegressor',\n", "         ]\n", "\n", "classifiers = [\n", "    #ElasticNetCV(cv=10, random_state=0),\n", "    #SVC(),\n", "    #SVC(kernel = 'rbf', random_state = 0),\n", "    KNeighborsClassifier(n_neighbors = 1),\n", "    DecisionTreeClassifier(),\n", "    #RandomForestClassifier(n_estimators = 200),\n", "    #GridSearchCV(SVC(),param_grid, refit = True, verbose = 1),\n", "    #error HuberRegressor(fit_intercept=True, alpha=0.0, max_iter=100,epsilon=2.95),\n", "    #Ridge(fit_intercept=True, alpha=0.0, random_state=0, normalize=True),\n", "    #Lasso(alpha=0.05),\n", "    #LassoCV(),\n", "    #Lars(n_nonzero_coefs=10),\n", "    BayesianRidge(),\n", "    #SGDClassifier(),\n", "    #RidgeClassifier(),\n", "    #LogisticRegression(),\n", "    # OrthogonalMatchingPursuit(),\n", "    #RANSACRegressor(),\n", "]\n", "correction= [0,0,0,0,0,0,0,0,0,0,0,0]\n", "\n", "temp=zip(names,classifiers,correction)\n", "print(temp)\n", "\n", "for name, clf,correct in temp:\n", "    regr=clf.fit(X,Y)\n", "    #print( name,'% errors', abs(regr.predict(X)+correct-Y).sum()/(Y.sum())*100)\n", "    print(name,'%error',procenterror(regr.predict(X),Y),'rmsle',rmsle(regr.predict(X),Y))\n", "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,f1_score, precision_score, recall_score\n", "\n", "    # Confusion Matrix\n", "    print(name,'Confusion Matrix')\n", "    print(confusion_matrix(Y, np.round(regr.predict(X) ) ) )\n", "    print('--'*40)\n", "\n", "    # Classification Report\n", "    print('Classification Report')\n", "    print(classification_report(Y,np.round( regr.predict(X) ) ))\n", "\n", "    # Accuracy\n", "    print('--'*40)\n", "    logreg_accuracy = round(accuracy_score(Y, np.round( regr.predict(X) ) ) * 100,2)\n", "    print('Accuracy', logreg_accuracy,'%')"]}], "nbformat_minor": 1, "nbformat": 4}