{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.layers import Dense, SimpleRNN, GRU, LSTM, Embedding # Import layers from Keras\nfrom keras.models import Sequential\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"### Reading the data"},{"metadata":{"trusted":true,"_uuid":"2566129bba9da26ef5388b229f7c828b9d455e07"},"cell_type":"code","source":"raw_data = pd.read_csv('../input/train.csv', encoding='latin-1') # Read the data as a DataFrame using Pandas\nraw_test_data = pd.read_csv('../input/test.csv', encoding='latin-1')\n\nprint(raw_data.shape) # Print the dimensions of train DataFrame\nprint(raw_data.columns) # Print the column names of the DataFrame\nprint('\\n')\nraw_data.head(5) # Print the top few records","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61c6013266bae6149cafa2caf878d1fb9fc99cf2"},"cell_type":"markdown","source":"### Check the labels and their frequencies"},{"metadata":{"trusted":true,"_uuid":"8e01f3f59e473f5d105a5218f7a3ffca641ec873"},"cell_type":"code","source":"# Print the unique classes and their counts/frequencies\nclasses = np.unique(raw_data['target'], return_counts=True) # np.unique returns a tuple with class names and counts\nprint(classes[0]) #Print the list of unique classes\nprint(classes[1]) #Print the list of frequencies of the above classes02155","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ad5620f0da2e87ffb1b1d4d4ab4c87134da7d2c"},"cell_type":"markdown","source":"### Converting unstructured text to structured numeric form\n\n**This includes:**\n\n1. Tokenizing\n2. Converting sequence of words to sequence of word indeces\n3. Converting varing length sequences to fixed length sequences through padding"},{"metadata":{"trusted":true,"_uuid":"c58bbe20a99f70d8ad81d81e98fdf2342cc2d09f"},"cell_type":"code","source":"max_num_words = 10000\nseq_len = 150\nembedding_size = 100\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\ntokenizer = Tokenizer(num_words=max_num_words) #Tokenizer is used to tokenize text\ntokenizer.fit_on_texts(raw_data.question_text) #Fit this to our corpus\n\nx_train = tokenizer.texts_to_sequences(raw_data.question_text) #'text to sequences converts the text to a list of indices\nx_train = pad_sequences(x_train, maxlen=150) #pad_sequences makes every sequence a fixed size list by padding with 0s \n\n\nx_test = tokenizer.texts_to_sequences(raw_test_data.question_text) \nx_test = pad_sequences(x_test, maxlen=150)\n\nx_train.shape, x_test.shape # Check the dimensions of x_train and x_test  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65f2456dc6ec886bb8bae5750ce0dc69464543e9"},"cell_type":"markdown","source":"### Prepare the target vectors for the network"},{"metadata":{"trusted":true,"_uuid":"76eae9026223f5be381528d0e99ae4e94edba72f"},"cell_type":"code","source":"unique_labels = list(raw_data.target.unique())\nprint(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"245192ec2b969e64a28b606834a16039351f6c46"},"cell_type":"markdown","source":"### Building and training an LSTM model\n"},{"metadata":{"trusted":true,"_uuid":"e9c33726a751c68afa80b26e5f232b154566348c"},"cell_type":"code","source":"# Building an LSTM model\nmodel = Sequential() # Call Sequential to initialize a network\nmodel.add(Embedding(input_dim = max_num_words, \n                    input_length = seq_len, \n                    output_dim = embedding_size)) # Add an embedding layer which represents each unique token as a vector\nmodel.add(LSTM(10, return_sequences=False)) # Add an LSTM layer ( will not return output at each step)\nmodel.add(Dense(1, activation='sigmoid')) # Add an ouput layer. Since classification, 3 nodes for 3 classes.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"088098b1bf44a707e09bea934735d35373c41c46"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"831d016ca3559e20e197f760aa03697e35b701f7"},"cell_type":"code","source":"from keras.optimizers import Adam\nadam = Adam(lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"501cd24c11474e00ec2fa0a8fdd745180403745d"},"cell_type":"code","source":"# Mention the optimizer, Loss function and metrics to be computed\nmodel.compile(optimizer=adam,                  # 'Adam' is a variant of gradient descent technique\n              loss='binary_crossentropy', # categorical_crossentropy for multi-class classification\n              metrics=['accuracy'])            # These metrics are computed for evaluating and stored in history\ny_train = raw_data['target']\nmodel.fit(x_train, y_train, epochs=1, validation_split=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3875a1017abcb55f7379e270b4121804e59edb63"},"cell_type":"code","source":"preds = model.predict(x_test)\npred_test_y = (preds>0.35).astype(int)\n\n# Read the submission file\nsubmission=pd.read_csv(\"../input/sample_submission.csv\")\n\n# Fill the is_pass variable with the predictions\nsubmission['prediction']= pd.DataFrame(pred_test_y)\n\n# Converting the submission file to csv format\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90b4b0e413f527f8a6d3f6f024034ad4c899c94"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}