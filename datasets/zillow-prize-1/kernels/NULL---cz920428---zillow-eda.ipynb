{"nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.1", "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"outputs": [], "metadata": {"_uuid": "d37442c355641fb116ca076ed8adeba878b18f9f", "_cell_guid": "19260745-dec3-4870-af2c-222979dfc927", "trusted": true, "_execution_state": "idle"}, "cell_type": "code", "execution_count": null, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."}, {"outputs": [], "metadata": {"_uuid": "fc8a949a6aa80e13af7b606b6f05cc600b3b00e2", "_cell_guid": "80393984-032b-44af-87c0-7c0b81fd5840", "trusted": true}, "cell_type": "code", "execution_count": null, "source": "#Read data into notebook\n#parcelid, logerror, transactiondate\ntrain = pd.read_csv('../input/train_2016_v2.csv')\n#this file has many features of the property and parcelid \nall_2016 = pd.read_csv('../input/properties_2016.csv') "}, {"outputs": [], "metadata": {"_uuid": "27e88402b9ed2939392749144b48ed37674062bc", "_cell_guid": "4f579c09-6278-4e35-a487-980eb609cb8e", "trusted": true}, "cell_type": "code", "execution_count": null, "source": "train.head()"}, {"outputs": [], "metadata": {"_uuid": "b83665b8065cb033090324f4a58e79c1c5695505", "_cell_guid": "df540b74-b4e1-4781-8037-ef17c906e5c7", "trusted": true}, "cell_type": "code", "execution_count": null, "source": "all_2016.head()\nall_2016.shape"}, {"outputs": [], "metadata": {"_uuid": "96e1035bb2a1376c4ed415b7f46bc06c7c1e7993", "_cell_guid": "1e6c3ae1-13ca-41f6-894b-cad4b99e4301", "trusted": true}, "cell_type": "code", "execution_count": null, "source": "#Analyze train first\ntrain['transactiondate'] = pd.to_datetime(train['transactiondate'])\ntrain['TransactionMonth'] = train['transactiondate'].dt.strftime('%b')\ncount = train['TransactionMonth'].value_counts()\nimport seaborn as sns\nsns.barplot(count.index, count.values, order=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug',\n                                              'Sep','Oct','Nov','Dec'])\n#More transactions during summer. Dataset contains all transactions prior to Oct 15 2016 and \n#some transactions after Oct 15 2016. So there is less transactions in Oct, Nov and Dec. \n#Need to consider Seasonality when making predication. Jan, Feb lower transaction volumns"}, {"outputs": [], "metadata": {"trusted": true, "_uuid": "74aa53ed67fd07809f8389f08e48219bf8ef5434"}, "cell_type": "code", "execution_count": null, "source": "#Analyze the logerror \nimport matplotlib.pyplot as plt\nplt.hist(train['logerror'],np.linspace(-0.5, 0.5, 100), alpha=0.7)"}, {"outputs": [], "metadata": {"trusted": true, "_uuid": "0abc5e81cc40a67c818c75593fc6bf55c86b9443"}, "cell_type": "code", "execution_count": null, "source": "#mean absolute log error with time \n#During winter time, the mean of absolute logerror is larger than summer time. \nmean = abs(train['logerror']).groupby(train['TransactionMonth']).mean()\nsns.stripplot(x=pd.Series(mean.index), y=pd.Series(mean.values), order = ['Jan','Feb','Mar',\n                                                                          'Apr','May','Jun',\n                                                                          'Jul','Aug','Sep',\n                                                                          'Oct','Nov','Dec'],\n             size=10)"}, {"outputs": [], "metadata": {"_uuid": "0a7f4741c8aebe098a53a348af7726f913c73eff"}, "cell_type": "markdown", "execution_count": null, "source": "Start Analyzing on properties file \n<newline> \nStep 1: Check null values "}, {"outputs": [], "metadata": {"trusted": true, "_uuid": "6534c5fc3a7faa61e15535c36a4422a579836514"}, "cell_type": "code", "execution_count": null, "source": "null_value = all_2016.isnull().sum().reset_index()\nnull_value.columns = ['feature','CountNA']\nnull_value = null_value.sort_values('CountNA', ascending=False)\nfig, ax = plt.subplots()\nfig.set_size_inches(11, 15)\ngraph = sns.barplot(x='CountNA',y='feature',data=null_value, ax=ax)\ngraph.set(xlabel='Count of NA values', ylabel='Features')\n"}, {"outputs": [], "metadata": {"_uuid": "1a5111c7038112b763b081f7a6d939b37a67d95d"}, "cell_type": "markdown", "execution_count": null, "source": ""}], "nbformat": 4}