{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aa83a87c-e33b-bda5-1a85-559ced626450"
      },
      "outputs": [],
      "source": [
        "import os, cv2, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88b26f94-9fb8-50dd-d0f0-d29bf0845d8b"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '../input/train/'\n",
        "TEST_DIR  = '../input/test/'\n",
        "\n",
        "ROWS = 32\n",
        "COLS = 32\n",
        "CHANNELS = 1\n",
        "\n",
        "train_images = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
        "test_images =  [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
        "\n",
        "def read_image(file_path):\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "def prep_data(images):\n",
        "    count = len(images)\n",
        "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype = np.uint8)\n",
        "\n",
        "    for i, image_file in enumerate(images):\n",
        "        image = read_image(image_file)\n",
        "        data[i] = image.T\n",
        "        if i % 1000 == 0: print('Processed {} of {}'.format(i, count))\n",
        "    \n",
        "    return data\n",
        "\n",
        "train = prep_data(train_images)\n",
        "test = prep_data(test_images)\n",
        "\n",
        "print(\"Train shape: {}\".format(train.shape))\n",
        "print(\"Test shape: {}\".format(test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "014c77b5-be30-550c-dad8-e13ff9b64315"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "\n",
        "for i in train_images:\n",
        "    if 'dog' in i:\n",
        "        labels.append(1)\n",
        "    else:\n",
        "        labels.append(0)\n",
        "\n",
        "sns.countplot(labels)\n",
        "sns.plt.title('Cats and Dogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b14f0c68-8f8b-5b00-32ca-61b1c6b52422"
      },
      "outputs": [],
      "source": [
        "import os, cv2, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#%env KERAS_BACKEND = theano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23a10e71-db30-53b9-16e8-8b18156c8613"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "\n",
        "for i in train_images:\n",
        "    if 'dog' in i:\n",
        "        labels.append(1)\n",
        "    else:\n",
        "        labels.append(0)\n",
        "\n",
        "train = train.reshape(-1, 32,32,1)\n",
        "test = test.reshape(-1, 32,32,1)\n",
        "\n",
        "X_train = train.astype('float32')\n",
        "X_test = test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "Y_train = labels\n",
        "\n",
        "X_valid = X_train[:5000, :, :, :]\n",
        "Y_valid =   Y_train[:5000]\n",
        "X_train = X_train[5001:25000, :, :, :]\n",
        "Y_train  = Y_train[5001:25000]\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "441d2e5b-18b7-5a67-159a-846ea0d99a61"
      },
      "outputs": [],
      "source": [
        "TRAIN_DIR = '../input/train/'\n",
        "TEST_DIR  = '../input/test/'\n",
        "\n",
        "ROWS = 32\n",
        "COLS = 32\n",
        "CHANNELS = 1\n",
        "\n",
        "train_images = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\n",
        "test_images =  [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
        "\n",
        "def read_image(file_path):\n",
        "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    return cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "def prep_data(images):\n",
        "    count = len(images)\n",
        "    data = np.ndarray((count, CHANNELS, ROWS, COLS), dtype=np.uint8)\n",
        "\n",
        "    for i, image_file in enumerate(images):\n",
        "        image = read_image(image_file)\n",
        "        data[i] = image.T\n",
        "        if i % 2500 == 0: print('Processed {} of {}'.format(i, count))\n",
        "    \n",
        "    return data\n",
        "\n",
        "train = prep_data(train_images)\n",
        "test = prep_data(test_images)\n",
        "\n",
        "print(\"Train shape: {}\".format(train.shape))\n",
        "print(\"Test shape: {}\".format(test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "76be1556-ec70-1707-65f9-938a1350f462"
      },
      "outputs": [],
      "source": [
        "def CatDog():\n",
        "    \n",
        "    #Neural network model object\n",
        "    model = Sequential()\n",
        "    \n",
        "    #First convolution\n",
        "    model.add(Convolution2D(\n",
        "        16, 3, 3,\n",
        "        border_mode = 'same',\n",
        "        input_shape = (ROWS, COLS, CHANNELS),\n",
        "        activation = 'relu'\n",
        "    ))\n",
        "    \n",
        "    #First dimensionality reduction\n",
        "    model.add(\n",
        "        MaxPooling2D( pool_size = (2, 2) )\n",
        "    )\n",
        "    \n",
        "    #Second convolution\n",
        "    model.add(Convolution2D(\n",
        "        32, 3, 3,\n",
        "        border_mode = 'same',\n",
        "        activation = 'relu'\n",
        "    ))\n",
        "    \n",
        "    #Second dimensionality reduction\n",
        "    model.add(\n",
        "        MaxPooling2D( pool_size = (2, 2) )\n",
        "    )\n",
        "    \n",
        "    #Dimensionality reduction to single array\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    #Dense layers - linear model on flattened array\n",
        "    model.add(Dense(100, activation = 'relu'))\n",
        "    \n",
        "    #Prevent overfitting by randomly setting some model coeffecients to zero\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #More dense layers\n",
        "    model.add(Dense(100, activation = 'relu'))\n",
        "    \n",
        "    #More overfitting prevention\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    #Last dense layer\n",
        "    model.add(Dense(1))\n",
        "    \n",
        "    #Add output to model\n",
        "    model.add(Activation('sigmoid'))\n",
        "    \n",
        "    #Compile model and return\n",
        "    model.compile(\n",
        "        loss = 'binary_crossentropy',\n",
        "        optimizer = 'adam',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = CatDog()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e8b7570-3aa6-364f-fe1f-78730e47a9ca"
      },
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    Y_train,\n",
        "    batch_size = 128,\n",
        "    nb_epoch = 8,\n",
        "    verbose = 1,\n",
        "    validation_data = (X_valid, Y_valid)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1785669-4128-d69b-5e0e-e8be90bf3b10"
      },
      "outputs": [],
      "source": [
        "submission = model.predict_proba(X_test, verbose = 1)\n",
        "\n",
        "test_id = range(1, 12501)\n",
        "\n",
        "predictions_df = pd.DataFrame({\n",
        "    'id': test_id,\n",
        "    'label': submission[:, 0]\n",
        "})\n",
        "\n",
        "predictions_df.to_csv(\"submission.csv\", index = False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}