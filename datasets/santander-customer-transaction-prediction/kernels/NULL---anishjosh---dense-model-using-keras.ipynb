{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, BatchNormalization\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping\n% matplotlib inline\nfrom tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras.layers import Conv1D,MaxPooling1D,LSTM\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92f9a3bd2715f824cf9abee1f6e860de0e6f8b56"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntarget = pd.read_csv('../input/sample_submission.csv')\n\n\nX = train.iloc[:,2:].values\ny = train.iloc[:,1].values\ntest = test.iloc[:,1:].values\n\nscaler = StandardScaler()\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 3017)\n\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n\ndim_x_train = X_train_scaled.reshape(X_train_scaled.shape[0],X_train_scaled.shape[1],1)\ndim_x_test = X_test_scaled.reshape(X_test_scaled.shape[0],X_test_scaled.shape[1],1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dad39cd624f2f451fbb1dbe5c21fb324643a937","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cmodel = Sequential()\ncmodel.add(Conv1D(100,(1),input_shape=(200,1),activation=\"relu\"))\n# cmodel.add(Conv1D(100,(3),activation=\"relu\"))\ncmodel.add(BatchNormalization())\ncmodel.add(Dense(700,activation=\"relu\"))\ncmodel.add(BatchNormalization())\ncmodel.add(Dense(100,activation=\"relu\"))\n# cmodel.add(Dense(2,activation=\"relu\"))\n\ncmodel.add(Flatten())\ncmodel.add(Dense(1,activation=\"sigmoid\"))\noptimizer = Nadam(1e-6)\nes = EarlyStopping(patience=15, verbose=1)\ncmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\nhistory = cmodel.fit(dim_x_train, y_train, batch_size=512, epochs=50, validation_split=0.12, verbose=1, callbacks=[es])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cce8e50aa831a51b90e52288635337b608afefb6"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Dense(400, input_dim=200))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(400))\nmodel.add(Activation(\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(Dense(100))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(50))\nmodel.add(Activation(\"relu\"))\n\nmodel.add(Dense(1, activation = 'sigmoid'))\n\noptimizer = Nadam(1e-5)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n\nes = EarlyStopping(patience=10, verbose=1)\nhistory = model.fit(X_train_scaled, y_train, batch_size=256, epochs=18, validation_split=0.2, verbose=2, callbacks=[es])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c1f1ce0d763dfd30620eef2e20409fd56be139f"},"cell_type":"code","source":"testd = pd.read_csv('../input/test.csv')\npred_test = testd.iloc[:,1:]\n\nac = scaler.transform(pred_test)\nac_cnn = ac.reshape(pred_test.shape[0],pred_test.shape[1],1)\npredictions = cmodel.predict_classes(ac_cnn)\n\nans = pd.DataFrame(predictions)\nans = ans[0]\ntest = pd.read_csv('../input/test.csv')\ntest_id = test[\"ID_code\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a06a467dfff9d7fda757976f96e776d5f5865664"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['ID_code'] = test_id\nsub['target'] = ans\nsub.to_csv('submission_mcn5.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6cf87efdc0ee4759b90f50df6943f55688e0c98"},"cell_type":"code","source":"test_result = pd.read_csv('../working/submission_mcn5.csv')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5287e64de3f8ceed0fa5ab75ee8639ac28f3f0c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3183a36078282c1d9c7fbe7c3165aa54a2bb646f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}