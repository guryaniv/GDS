{"cells": [{"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "2282e0e6-bed3-4375-5b9b-05c80fe29f27", "_uuid": "e1f3635fe12d8b2454a90e8644b494d817c6d38e"}, "source": "use Keras pre-trained VGG16\n---------------------------\nthis is my first notebook. \n\npre-trained VGG16 is quickly and good performance.\n\nI learned from official Keras blog tutorial \n[Building powerful image classification models using very little data][1]\n\n\n  [1]: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "fdca4192-cf9d-1f5f-7e8f-30ae5e468db4", "_uuid": "867de32f2c7aa9ac25601fc940006294e33daca1"}, "source": "## resize train data and test data ##", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "aab06a15-51b8-13e2-172a-b3e62aa3738a", "_uuid": "c1ebca0bdc0b5bbc4f293bc4b53a80c721595d1a"}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import numpy as np\n", "import pandas as pd\n", "import cv2\n", "import math\n", "from glob import glob\n", "import os\n", "\n", "master = pd.read_csv(\"../input/train_labels.csv\")\n", "master.head()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "e68a78fc-8470-e081-27ad-eca99e6fdd1f", "_uuid": "7123c5327c0b72f3b3775fbb986c8808691ed912"}, "source": "img_path = \"../input/train/\"\n\ny = []\nfile_paths = []\nfor i in range(len(master)):\n    file_paths.append( img_path + str(i+1) +'.jpg' )\n    y.append(master.iloc[i][1])\ny = np.array(y)\ny[:10]", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "34636940-b7b8-64f6-6ca7-1ad97081ea7b", "_uuid": "786578085deb6df7474ef431cac853b5b2f2cb85"}, "source": ["#image reseize & centering & crop \n", "\n", "def centering_image(img):\n", "    size = [256,256]\n", "    \n", "    img_size = img.shape[:2]\n", "    \n", "    # centering\n", "    row = (size[1] - img_size[0]) // 2\n", "    col = (size[0] - img_size[1]) // 2\n", "    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n", "    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n", "\n", "    return resized\n", "\n", "\n", "x = []\n", "for i, file_path in enumerate(file_paths):\n", "    #read image\n", "    img = cv2.imread(file_path)\n", "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "\n", "    #resize\n", "    if(img.shape[0] > img.shape[1]):\n", "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n", "    else:\n", "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n", "\n", "    #centering\n", "    img = centering_image(cv2.resize(img, dsize=tile_size))\n", "    \n", "    #out put 224*224px \n", "    img = img[16:240, 16:240]\n", "    x.append(img)\n", "\n", "x = np.array(x)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "1f371b5e-579e-cd78-51f3-bad30c864a85", "_uuid": "e6bcd11e76d06e0f626d7e6817e5b41e407d2820"}, "source": "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nimg_path = \"../input/test/\"\n\ntest_names = []\nfile_paths = []\n\nfor i in range(len(sample_submission)):\n    test_names.append(sample_submission.iloc[i][0])\n    file_paths.append( img_path + str(int(sample_submission.iloc[i][0])) +'.jpg' )\n    \ntest_names = np.array(test_names)", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "8f849642-855e-63b0-26e8-107724628353", "_uuid": "a46292d10d3b4191bf17ecdcd17dca9012c297c6"}, "source": "test_images = []\nfor file_path in file_paths:\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    test_images.append(img)\n    \n    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n\ntest_images = np.array(test_images)", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b", "_uuid": "5e8137287ac14c52c93a0ada9505f011bf8a2406"}, "source": "save numpy array.\n\nUsually I separate code, data format and CNN.", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "54ee247b-1228-bfb2-46c0-0b08e3455375", "_uuid": "1856bed9e5c82d812aa5b70362757ef7788f5089"}, "source": "#np.savez('224.npz', x=x, y=y, test_images=test_images, test_names=test_names)", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "2880329f-76a5-b385-a3ba-609820535f34", "_uuid": "14c05681d068cff130218a64b8d712b6643a642d"}, "source": "## split train data and validation data  ##", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "aea9535d-9baa-214c-afd1-1595ae44cb0f", "_uuid": "1175eff0000655ea4f3a88db9f517d5d1e186658"}, "source": ["data_num = len(y)\n", "random_index = np.random.permutation(data_num)\n", "\n", "x_shuffle = []\n", "y_shuffle = []\n", "for i in range(data_num):\n", "    x_shuffle.append(x[random_index[i]])\n", "    y_shuffle.append(y[random_index[i]])\n", "    \n", "x = np.array(x_shuffle) \n", "y = np.array(y_shuffle)"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "3aa4f607-c45c-c738-3b99-ced4f3fa5a28", "_uuid": "2b0b9ffc7af2d6b6b753c3a7b26aa4fe0645f442"}, "source": "val_split_num = round(0.2*len(y))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "8b6caf1c-bc20-63cb-52a3-33dc71c5529d", "_uuid": "a200f1690c3a42c93ec45aaa0ba17159f9d58dc7"}, "source": "# normalization\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "9fa975c5-3996-8f40-65c0-a49c09ec26ae", "_uuid": "e2fbcc308baa0f9077da8335d86414795424ac46"}, "source": "use Keras pre-trained VGG16\n---------------------------\n\nbut kaggle karnel is not run", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "18861ee9-b81b-27ef-3846-0d04aafd3560", "_uuid": "c3435513a0394d37bdaaf66e65253af4e7cda3be"}, "source": ["from keras.models import Sequential, Model, load_model\n", "from keras import applications\n", "from keras import optimizers\n", "from keras.layers import Dropout, Flatten, Dense\n", "\n", "img_rows, img_cols, img_channel = 224, 224, 3\n", "\n", "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "a7b158cf-ed3e-6ebc-868f-acddcce92344", "_uuid": "0d9538b15c6e98a46fc40cbb5e93e8e56a1c0b80"}, "source": ["add_model = Sequential()\n", "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n", "add_model.add(Dense(256, activation='relu'))\n", "add_model.add(Dense(1, activation='sigmoid'))\n", "\n", "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n", "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n", "              metrics=['accuracy'])\n", "\n", "model.summary()"], "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "ecf8491d-cbba-505d-e5d8-fecaae32e35e", "_uuid": "43116cb710a13f336ca8316289b3ba5f43ebdfc9"}, "source": "from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nbatch_size = 32\nepochs = 50\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] // batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]\n)", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "e0e5efc6-cf1a-32fb-5b2e-d1ea2b244a5d", "_uuid": "1f9902f6e3abd8002d4839195b14b735c95f7e98"}, "source": "## predict test data ##", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "8c3ac15d-fb29-2531-cbe5-f763c35623a5", "_uuid": "4f6ca7411686df49ade418f9cc95eb3133a7d2ca"}, "source": "test_images = test_images.astype('float32')\ntest_images /= 255", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "7740ecc9-98c6-c62b-f71e-69d8c34ed451", "_uuid": "ecc8a7f8ef827ee7054bb54e0acd5aed0e9c1e75"}, "source": "predictions = model.predict(test_images)", "outputs": []}, {"execution_count": null, "cell_type": "code", "metadata": {"trusted": false, "_cell_guid": "a90d25c4-6587-a574-27db-5af5e9ff17d3", "_uuid": "1e23fcb11f110d5e168ec04d7bf8cdc2d3685446"}, "source": "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n\nfor i, name in enumerate(test_names):\n    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = predictions[i]\n\nsample_submission.to_csv(\"submit.csv\", index=False)", "outputs": []}, {"execution_count": null, "cell_type": "markdown", "metadata": {"_cell_guid": "3d36278d-01ef-c87b-3710-bf3820562913", "_uuid": "d5216261177f57a0c1ac2445143d8ba86e9b8cf7"}, "source": "What to do next?\n----------------\n\nI will try pre-trained ResNet, fine tune ResNet.\n\nThis idea seems to be helpful.\n\n[Dogs vs. Cats Redux Playground Competition, 3rd Place Interview][1]\n\n\n  [1]: http://blog.kaggle.com/2017/04/20/dogs-vs-cats-redux-playground-competition-3rd-place-interview-marco-lugo/", "outputs": []}], "nbformat": 4, "metadata": {"_change_revision": 0, "_is_fork": false, "language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 0}