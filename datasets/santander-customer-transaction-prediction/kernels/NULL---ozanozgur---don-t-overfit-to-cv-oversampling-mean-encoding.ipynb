{"cells":[{"metadata":{"_uuid":"8f0409f88b204e7697c30651f0ae843aa468dd1c"},"cell_type":"markdown","source":"**This is a random search tool function for various models with additional functionality.**\n\nAdded functionality:\n\n1- Processing CV data in each fold, separately (No overfitting to CV.)\n\n2- Preprocessing fold data separately (Separate data into train,valid, then process data based on y_train (oversampling doesn't overfit this way))\n\n3- Training a model multiple times with the same parameters(different folds) then averaging predictions. (CV score will be closer to LB score.)\n\n**Why did I add these functionalities?**\n- Don't overfit to CV while using oversampling. (You will see the real result without a surprise in submission.)\n- Don't overfit to CV while using mean encoding.\n- Oversampling all data before training causes overfitting in CV. Your CV result improves, but LB drops. When you don't change your validation data\nin folds, you will not overfit to CV.\n- Mean encoding requires using targets of other examples to encode that example. So, when you encode training set in CV fold, you can't use validation targets.\nA separate function that has no access to y_valid prevents  accidentally leaking targets and overfitting. You need to think less.\n\nI tried oversampling using SMOTE, mean encoding and binning. They didn't improve my CV score, but this code will be useful in other competitions.\nColumns to bin and encode are determined randomly in this code.\n\nMean encoding code from:\n[https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study](http://https://www.kaggle.com/vprokopev/mean-likelihood-encodings-a-comprehensive-study)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import KBinsDiscretizer\n\nimport os\nprint(os.listdir(\"../input\"))\n\ntrain_data = pd.read_csv('../input/train.csv')\ny_train = train_data.target\ntest_data = pd.read_csv('../input/test.csv')\ntest_IDs = test_data.ID_code\n\ntrain_data.drop(['ID_code', 'target'], axis = 1, inplace = True)\ntest_data.drop(['ID_code'], axis = 1, inplace = True)\n\nimport warnings  \nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41413c9a1f42518052140b507924216e2e875d65"},"cell_type":"code","source":"#Target encoding function\ndef mean_encode(train_data, test_data, columns, target_col, reg_method=None,\n                alpha=0, add_random=False, rmean=0, rstd=0.1, folds=1):\n    length_train = len(train_data)\n    '''Returns a DataFrame with encoded columns'''\n    encoded_cols = []\n    target_mean_global = train_data[target_col].mean()\n    for col in columns:\n        # Getting means for test data\n        nrows_cat = train_data.groupby(col)[target_col].count()\n        target_means_cats = train_data.groupby(col)[target_col].mean()\n        target_means_cats_adj = (target_means_cats*nrows_cat + \n                                 target_mean_global*alpha)/(nrows_cat+alpha)\n        # Mapping means to test data\n        encoded_col_test = test_data[col].map(target_means_cats_adj)\n        # Getting a train encodings\n        if reg_method == 'expanding_mean':\n            train_data_shuffled = train_data.sample(frac=1, random_state=1)\n            cumsum = train_data_shuffled.groupby(col)[target_col].cumsum() - train_data_shuffled[target_col]\n            cumcnt = train_data_shuffled.groupby(col).cumcount()\n            encoded_col_train = cumsum/(cumcnt)\n            encoded_col_train.fillna(target_mean_global, inplace=True)\n            if add_random:\n                encoded_col_train = encoded_col_train + normal(loc=rmean, scale=rstd, \n                                                               size=(encoded_col_train.shape[0]))\n        elif (reg_method == 'k_fold') and (folds > 1):\n            kfold = StratifiedKFold(n_splits = folds, shuffle=True, random_state=1).split(train_data[target_col].values, train_data[target_col])\n            parts = []\n            for tr_in, val_ind in kfold:\n                                # divide data\n                    \n                \n                df_for_estimation, df_estimated = train_data.iloc[tr_in], train_data.iloc[val_ind]\n                # getting means on data for estimation (all folds except estimated)\n                nrows_cat = df_for_estimation.groupby(col)[target_col].count()\n                target_means_cats = df_for_estimation.groupby(col)[target_col].mean()\n                target_means_cats_adj = (target_means_cats*nrows_cat + \n                                         target_mean_global*alpha)/(nrows_cat+alpha)\n                # Mapping means to estimated fold\n                encoded_col_train_part = df_estimated[col].map(target_means_cats_adj)\n                if add_random:\n                    encoded_col_train_part = encoded_col_train_part + normal(loc=rmean, scale=rstd, \n                                                                             size=(encoded_col_train_part.shape[0]))\n                # Saving estimated encodings for a fold\n                parts.append(encoded_col_train_part)\n            encoded_col_train = pd.concat(parts, axis=0)\n            encoded_col_train.fillna(target_mean_global, inplace=True)\n        else:\n            encoded_col_train = train_data[col].map(target_means_cats_adj)\n            if add_random:\n                encoded_col_train = encoded_col_train + normal(loc=rmean, scale=rstd, \n                                                               size=(encoded_col_train.shape[0]))\n\n        # Saving the column with means\n        encoded_col = pd.concat([encoded_col_train, encoded_col_test], axis=0)\n        encoded_col[encoded_col.isnull()] = target_mean_global\n        encoded_cols.append(pd.DataFrame({'mean_'+target_col+'_'+col:encoded_col}))\n    all_encoded = pd.concat(encoded_cols, axis=1)\n    #Modified to reindex\n    all_encoded = all_encoded.reset_index()\n    return (all_encoded.iloc[:length_train].reset_index(drop = True), \n            all_encoded.iloc[length_train:].reset_index(drop = True)\n           )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def RandomSearchModel(model, param_grid, num_runs = 1, random_state = None, n_folds = 2, process_fold = None, fold_data = None):\n        #You must use random state 99999 to preprocess fold data.\n        predictions_total = np.zeros(len(test_data))\n        preds_train_total = np.zeros(len(train_data))\n        \n        #Separate model parameters from CV parameters\n        cv_param_keys = ['has_eval_set', 'early_stopping', 'verbose']\n        \n        #Select random parameters from grid\n        param = dict()\n        for key in param_grid:\n            param[key] = np.random.choice(param_grid[key])\n        \n        #Separate model parameters from CV parameters\n        cv_params = dict()\n        for cv_param in cv_param_keys:\n            if not cv_param in list(param.keys()):\n                print(\"CV parameter [{}] is required.\".format(cv_param))\n            cv_params[cv_param] = param[cv_param]\n            param.pop(cv_param, None)\n\n        print(\"parameters: {}\".format(param))\n        \n        ### MULTIPLE RUNS ##############################################\n        for i_run in range(num_runs):\n            print('###> Run {}/{} <##################################'.format(i_run+1, num_runs))\n            folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n                \n            cv_scores = []\n            best_score = 0\n            preds_train = np.zeros(len(train_data))\n            predictions = np.zeros(len(test_data))\n            \n            for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data.values, y_train.values)):\n                clf = model(**param)\n                \n                train_fold_x = None\n                train_fold_y = None\n                \n                print(\"Fold {}\".format(fold_))\n                \n                #Pass preprocessed fold data (oversampled or etc.)\n                if fold_data == None:\n                    train_fold_x = train_data.iloc[trn_idx]\n                    train_fold_y = y_train.iloc[trn_idx].values.ravel()\n                else:\n                    #If there is a preprocessed data, use it\n                    train_fold_x = fold_data[fold_][0]\n                    train_fold_y = fold_data[fold_][1]\n                    #May also add test,valid data\n                \n                valid_fold_x = train_data.iloc[val_idx]\n                valid_fold_y = y_train.iloc[val_idx].values.ravel().copy()\n                \n                X_test_fold = None\n                #Pass a function to process each fold data\n                if process_fold != None:\n                    train_fold_x, train_fold_y, valid_fold_x, X_test_fold = process_fold(train_fold_x, train_fold_y, valid_fold_x, test_data)\n                    print(X_test_fold.shape)\n                else:\n                    X_test_fold = test_data\n                    \n                if cv_params['has_eval_set']:\n                    clf.fit(train_fold_x, train_fold_y, eval_set = [(valid_fold_x, valid_fold_y)], early_stopping_rounds = cv_params['early_stopping'], verbose = cv_params['verbose'])\n                else:\n                    clf.fit(train_fold_x, train_fold_y)\n                    print(\"Warning: Early stopping was not used! (Set [has_eval_set=1] if model allows.)\")\n\n                preds_train[val_idx] = clf.predict_proba(valid_fold_x)[:,1]\n                \n                score_fold = roc_auc_score(valid_fold_y, preds_train[val_idx])\n                score_fold = np.abs(score_fold - 0.5) + 0.5\n\n                cv_scores.append(score_fold)\n                print('fold score: {}'.format(score_fold))\n\n                # / folds.n_splits\n                predictions += clf.predict_proba(X_test_fold)[:,1] / folds.n_splits\n            \n            predictions_total += predictions / num_runs\n            preds_train_total += preds_train / num_runs\n            \n        overall_cv_score = roc_auc_score(y_train, preds_train_total)\n        overall_cv_score = np.abs(overall_cv_score - 0.5) + 0.5\n        \n        return [overall_cv_score, param, cv_scores, predictions_total, preds_train_total]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f366db3d5f5137d565216672da4e5561ee52ac39"},"cell_type":"code","source":"#This function processes data at each fold, without using validation targets. Then we don't get false hopes by overfitting to CV.\ndef process_fold(train_fold_x, train_fold_y, valid_fold_x, X_test):\n    #You can do whatever you want in this function and you won't overfit in CV results. => No bad surprise in submissions.\n    #The reason for that is we don't have access to validation data target. Overfitting to CV results from making decisions based on\n    #Validation set targets.\n    \n    #Things you can do here:\n    # - Target encoding\n    # - Binning\n    # - Oversampling (preprocessing fold data is faster for that)\n    # - Other FE\n    \n    #This didn't improve CV score, but you won't get false hopes by overfitting to CV.\n    \"\"\"cols_to_bin = np.random.choice(train_fold_x.columns, 10) #I chose these randomly, just to show that function works\n    cols_to_encode = cols_to_bin\n    \n    print('Binning {} columns. (Replace)...'.format(len(cols_to_bin)))\n    for col in cols_to_bin:\n        est = KBinsDiscretizer(n_bins=25, encode='ordinal', strategy='quantile') #Can try different things\n        est.fit(train_fold_x[col].values.reshape((-1,1)))\n        # You may also fit to pd.concat([train_fold_x, valid_fold_x, X_test]) but I'm not sure which one works better\n\n        train_fold_x[col] = est.transform(train_fold_x[col].values.reshape((-1,1)))\n        valid_fold_x[col] = est.transform(valid_fold_x[col].values.reshape((-1,1)))\n        X_test[col] = est.transform(X_test[col].values.reshape((-1,1)))\n    \n    #Cascaded mean encoding (This part is a little bit crappy, but I didn't have time to fix)\n    #By encoding all columns this way, you can obtain a feature with 0.89 auc on its own without a model. But it didn't contribute to overall CV.\n    \n    print('Target encoding {} columns. (Add columns)...'.format(len(cols_to_encode)))\n    num_valid = len(valid_fold_x)\n    for col in cols_to_encode:\n        train_fold_x['target'] = train_fold_y\n        train_encoded, test_encoded = mean_encode(train_fold_x, pd.concat([valid_fold_x, X_test], axis = 0), [col], 'target', reg_method='k_fold',\n                alpha=1, add_random=False, rmean=0, rstd=0.1, folds=4)\n        train_fold_x.drop('target', axis = 1, inplace = True)\n        \n        train_encoded.drop('index', axis = 1, inplace = True)\n        test_encoded.drop('index', axis = 1, inplace = True)\n        \n        train_fold_x.reset_index(drop = True, inplace = True)\n        valid_fold_x.reset_index(drop = True, inplace = True)\n        X_test.reset_index(drop = True, inplace = True)\n        \n        valid_encoded = test_encoded.iloc[:num_valid].reset_index(drop = True)\n        test_encoded = test_encoded.iloc[num_valid:].reset_index(drop = True)\n    \n        train_fold_x = pd.concat([train_encoded, train_fold_x], axis = 1).reset_index(drop = True)\n        valid_fold_x =  pd.concat([valid_encoded, valid_fold_x], axis = 1).reset_index(drop = True)\n        X_test =  pd.concat([test_encoded, X_test], axis = 1).reset_index(drop = True)\n    \n    print('Fold processing done.')\"\"\"\n    #Goes back into training\n    return [train_fold_x, train_fold_y, valid_fold_x, X_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97bba4f0cc0f1e05c300d513b02f5da9b5d45930"},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\n\n#This function processes fold data before starting training.\n#This way you avoid the overhead of processing at each fold/run.\ndef preprocess_folds(random_state, n_folds, X_train, y_train):\n    cols = X_train.columns\n    # Oversample data fold by fold (More memory consumption, but faster)\n    folds = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n    fold_data = []\n    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train.values, y_train.values)):\n        print(\"Fold: {}\".format(fold_))\n        train_fold_x = X_train.iloc[trn_idx]\n        train_fold_y = y_train.iloc[trn_idx].values.ravel()\n\n        num_negative = len(train_fold_y[train_fold_y == 0])\n        print(\"Oversampling...\")\n        train_fold_x, train_fold_y = SMOTE(sampling_strategy = {0: num_negative, 1:int(num_negative * 0.3)}).fit_resample(train_fold_x, train_fold_y)\n        print('target=0 : {}'.format(len(train_fold_y[train_fold_y == 0])))\n        print('target=1 : {}'.format(len(train_fold_y[train_fold_y == 1])))\n        print(\"Oversampling done.\")\n\n        fold_data.append([pd.DataFrame(train_fold_x, columns = cols), pd.Series(train_fold_y)])\n    \n    return fold_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23d50aec3dc0bab9c38ce48abd2a8452838b47b5"},"cell_type":"code","source":"#Oversample training sets in each fold. This way we won't overfit to CV.\nn_folds = 5\nrandom_state = 99999\n\nfold_data = preprocess_folds(random_state = random_state,\n                             n_folds = n_folds,\n                             X_train = train_data,\n                             y_train = y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d27225b4bf1915979913de7b072e660df32bf122"},"cell_type":"code","source":"import lightgbm as lgb\n#Random search gives its best results faster than bayesian search. Good for trying new things.\n#But bayesian search performs better after many trials.\n\nparam_grid = dict(\n         objective =  ['binary'],\n         learning_rate = np.logspace(-3, -1, num=50, base=10.0),\n         feature_fraction = np.logspace(-2, -1, num=50, base=10.0),\n         num_leaves = np.arange(10,30,20),\n         min_data_in_leaf = np.arange(30,150,50),\n         bagging_fraction = [0.35, 0.32, 0.33, 0.37, 0.38, 0.39],\n         bagging_freq = np.arange(3, 30, 27),\n         max_depth = [-1],\n         boosting_type = ['gbdt'],\n         metric = ['auc'],\n         min_sum_hessian_in_leaf = np.logspace(-4, 2, num=50, base=10.0),\n         n_jobs = [-1],\n         tree_learner = ['serial'],\n         boost_from_average = [False],\n         num_round = [30000],\n         verbose_eval = [1000],\n    \n        #CV parameters\n        verbose = [1],\n        has_eval_set = [True],\n        early_stopping = [3000]\n)\n\ncv_results = []\n\nfor i in range(1): #Increase this as much as you want\n    #You can train model with different folds num_runs times and average predictions and results (CV score will be closer to LB score)\n    #Note that you must set random_state to None while doing this.\n    \n    #In each call to RandomSearchModel, random parameters from parameter grid is selected.\n    #You can provide preprocessed fold data [(fold1_train, fold1_y_train), (fold2_train, fold2_y_train) ...] Use this for oversampling.\n    [cv_score, param, fold_scores, predictions_total, preds_train_total] = RandomSearchModel(lgb.LGBMClassifier,\n                                                                         param_grid,\n                                                                         num_runs = 1,\n                                                                         random_state = random_state,\n                                                                         n_folds = n_folds,\n                                                                         process_fold = process_fold,\n                                                                         fold_data = fold_data\n                                                                        )\n    cv_results.append((cv_score, param, predictions_total))\n\ncv_results_df = pd.DataFrame(cv_results, columns = ['cv_score', 'parameters', 'predictions_total'])\ncv_results_df.sort_values(by = 'cv_score', inplace = True)\ndisplay(cv_results_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"700d78704a2a7b5163536c02d667362abb1c74ac"},"cell_type":"code","source":"\"\"\"my_submission = pd.DataFrame({'ID_code': test_IDs, 'target': cv_results_df.iloc[0].predictions_total})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b921ad17976142d45b961f6a94607383b42cdaf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}