{"cells":[{"metadata":{"_cell_guid":"7d5a9d52-a4a9-400c-a0bb-ac971eda730f","_uuid":"a784b02d5cb53410e15856dbb43e82e808ec5d36","collapsed":true,"trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"05870475-256d-41ce-8fb5-0f7a61bdf47f","_uuid":"9dc95d99910872c75ce24f05abf97c8f50ba9314","trusted":true},"cell_type":"code","source":"# open dataset\ndf = pd.read_csv('../input/train.csv')\ndf.shape","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"fe3f98e6-c971-478d-9596-9e6d9b29d194","_uuid":"f4fa9a9c2b1f5714cec5afe43d399b9328268e62","trusted":true},"cell_type":"code","source":"df.head()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"f6b6dafb-8c10-4a22-b1f4-218af2dfcbde","_uuid":"71f51e8f250194b1682fab57fa55f48deff3f856","trusted":true},"cell_type":"code","source":"# open url\ni = 0\nprint('id', df['id'][i])\nprint('url:', df['url'][i])\nprint('landmark id:', df['landmark_id'][i])\nurli=df['url'][i]","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"5d726b82-34bb-4d8e-9bba-a010fd098d22","_uuid":"8a948378f0b027fff70a13a9c0a2e844cce73a56","collapsed":true,"trusted":true},"cell_type":"code","source":"import theano\nfrom theano import tensor as T\nfrom theano.tensor.nnet import conv2d\n\nimport numpy\n\nrng = numpy.random.RandomState(23455)\n\n# instantiate 4D tensor for input\ninput = T.tensor4(name='input')\n\n# initialize shared variable for weights.\nw_shp = (2, 3, 9, 9)\nw_bound = numpy.sqrt(3 * 9 * 9)\nW = theano.shared( numpy.asarray(\n            rng.uniform(\n                low=-1.0 / w_bound,\n                high=1.0 / w_bound,\n                size=w_shp),\n            dtype=input.dtype), name ='W')\n\n# initialize shared variable for bias (1D tensor) with random values\n# IMPORTANT: biases are usually initialized to zero. However in this\n# particular application, we simply apply the convolutional layer to\n# an image without learning the parameters. We therefore initialize\n# them to random values to \"simulate\" learning.\nb_shp = (2,)\nb = theano.shared(numpy.asarray(\n            rng.uniform(low=-.5, high=.5, size=b_shp),\n            dtype=input.dtype), name ='b')\n\n# build symbolic expression that computes the convolution of input with filters in w\nconv_out = conv2d(input, W)\n\n# build symbolic expression to add bias and apply activation function, i.e. produce neural net layer output\n# A few words on ``dimshuffle`` :\n#   ``dimshuffle`` is a powerful tool in reshaping a tensor;\n#   what it allows you to do is to shuffle dimension around\n#   but also to insert new ones along which the tensor will be\n#   broadcastable;\n#   dimshuffle('x', 2, 'x', 0, 1)\n#   This will work on 3d tensors with no broadcastable\n#   dimensions. The first dimension will be broadcastable,\n#   then we will have the third dimension of the input tensor as\n#   the second of the resulting tensor, etc. If the tensor has\n#   shape (20, 30, 40), the resulting tensor will have dimensions\n#   (1, 40, 1, 20, 30). (AxBxC tensor is mapped to 1xCx1xAxB tensor)\n#   More examples:\n#    dimshuffle('x') -> make a 0d (scalar) into a 1d vector\n#    dimshuffle(0, 1) -> identity\n#    dimshuffle(1, 0) -> inverts the first and second dimensions\n#    dimshuffle('x', 0) -> make a row out of a 1d vector (N to 1xN)\n#    dimshuffle(0, 'x') -> make a column out of a 1d vector (N to Nx1)\n#    dimshuffle(2, 0, 1) -> AxBxC to CxAxB\n#    dimshuffle(0, 'x', 1) -> AxB to Ax1xB\n#    dimshuffle(1, 'x', 0) -> AxB to Bx1xA\noutput = T.nnet.sigmoid(conv_out + b.dimshuffle('x', 0, 'x', 'x'))\n\n# create theano function to compute filtered images\nf = theano.function([input], output)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"09e8a740-7dcd-42b3-9d0e-420627bbcba2","_uuid":"bfc4be1560ffea7ebe9a13d0ddf9b5594630ffec","trusted":true},"cell_type":"code","source":"import numpy\nimport pylab\nfrom PIL import Image\nfrom urllib.request import urlretrieve\nimport requests\nfrom io import BytesIO\n\n# open random image of dimensions 639x516\nurli='http://static.panoramio.com/photos/original/70761397.jpg'\nprint(urli)\n\nsize = 256, 256\nresponse = requests.get(urli)\nimg = Image.open(BytesIO(response.content))\n\nimg.thumbnail(size, Image.ANTIALIAS)\nimg.show()\n#img = Image.open(open(urli))\n# dimensions are (height, width, channel)\nimg = numpy.asarray(img, dtype='float64') / 256.\n\n# put image in 4D tensor of shape (1, 3, height, width)\nimg_ = img.transpose(2, 0, 1).reshape(1, 3, 256,191)\nfiltered_img = f(img_)\n\n# plot original image and first and second components of output\npylab.subplot(1, 3, 1); pylab.axis('off'); pylab.imshow(img)\npylab.gray();\n# recall that the convOp output (filtered image) is actually a \"minibatch\",\n# of size 1 here, so we take index 0 in the first dimension:\npylab.subplot(1, 3, 2); pylab.axis('off'); pylab.imshow(filtered_img[0, 0, :, :])\npylab.subplot(1, 3, 3); pylab.axis('off'); pylab.imshow(filtered_img[0, 1, :, :])\npylab.show()","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"b0df50b9029e1b130b975a59bd9d6f31753a8b98"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"collapsed":true,"trusted":true,"_uuid":"0590f05d2d717cda1cd6188264d9257eec0fdd21"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"13bbb08f-cc2f-4073-b587-b832c59cb3a2","_uuid":"19cded9ec9a3a31b1c0a681ccc270f9d0dd30255"},"cell_type":"markdown","source":"![](https://pbs.twimg.com/media/DZ1yZP9X4AAYP07.png:large)\n\n![](http://static.panoramio.com/photos/original/70761397.jpg)\n\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}