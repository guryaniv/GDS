{"cells":[{"metadata":{"_cell_guid":"adcae640-633f-4f69-887a-fcd75c7bec64","_uuid":"de8254bcb759f641c0aa21caf6b72297f2746a38"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# 1. Introduction\n\nIn this kernel, I am illustrating a basic methodology to obtain a 3D tensor of frequencies using Fast Fourier Transforms (FFT). My lectures on the subject are a bit outdated, so I defer to [Wikipedia](https://en.wikipedia.org/wiki/Fast_Fourier_transform) for a better explanation of the matter:\n\n> A fast Fourier transform (FFT) is an algorithm that samples a signal over a period of time (or space) and divides it into its frequency components.[1](https://en.wikipedia.org/wiki/Fast_Fourier_transform#cite_note-1) These components are single sinusoidal oscillations at distinct frequencies each with their own amplitude and phase. \n\nThere is a lot that can be refined in the final output. First, it can be reduced to a 2D tensor by dropping the imaginary part of the frequency domain. Second, in order to have a fixed shape, I padded the end of the tensor with 0s. An alternative method that has the advantage to be cheaper computationally would be to limit the size of the audio file. Third, to simplify the problem of the tensor size, I did not use any overlap when computing the spectrum of the signal.\n\nI hope this may be useful for you if you intended to go through frequencies. If you have any comments, I would be happy to here them!\n\n## 1.1 Acknowledgements\nGiving credit where credit is due, since I never used audio data before this competition, I used [@Zafar's Kernel](https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data) to quickstart this one. I had trouble selecting among the various options I could use to apply the FFT on data, and I finally opted for scipy's spectrogram thanks to [@Lathwal's kernel](https://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis).\n\n## 1.2 Importing Datas"},{"metadata":{"_cell_guid":"f6e6adda-3296-4b57-88d2-4331ba26216c","_uuid":"2d70a0ec0240a07bb64f509ee0632de396a30675","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain.head()","execution_count":108,"outputs":[]},{"metadata":{"_cell_guid":"0742d3dc-694f-412c-a7f2-8021d76f7beb","_uuid":"c82910d34ac4e6e5ad1d9a5c47259ebfe72dd500"},"cell_type":"markdown","source":"# 2. FFT on a Single File\n## 2.1 Getting the Audio Signal for a Single File\nIn this section, my aim is to build basis understanding of applying a FFT to an audio signal. First, let us try one of the audio file."},{"metadata":{"_cell_guid":"b42ab7f8-35d7-4c95-89b8-8a5768ce443a","_uuid":"b2d00d074fdd12e14b1fbc36e7480c39f84add3c","trusted":true},"cell_type":"code","source":"import IPython.display as ipd  # To play sound in the notebook\nfname = '../input/audio_train/' + '001ca53d.wav'\nipd.Audio(fname)","execution_count":109,"outputs":[]},{"metadata":{"_uuid":"108035aa0c17144179108851bec2434c7a22ab15"},"cell_type":"markdown","source":"Now, let us import the audio file as a np array."},{"metadata":{"_cell_guid":"5563205a-fa38-41d2-9fd4-5346ada7d803","_uuid":"3a7fe2be3a64c10ae72592c551efa92e88e95a86","trusted":true},"cell_type":"code","source":"from scipy.io import wavfile\nrate, data = wavfile.read(fname)\nprint(\"Sampling (frame) rate = \", rate)\nprint(\"Total samples (frames) = \", data.shape)\nprint(data)","execution_count":110,"outputs":[]},{"metadata":{"_uuid":"5b490bb14f6f9b7ebf2c19c53e482e6c7860317f"},"cell_type":"markdown","source":"A final step is to normalize data. A quick look at the [data description](https://www.kaggle.com/c/freesound-audio-tagging/data) reveals that all audio files are encoded as \"uncompressed PCM 16 bit\". After a research on internet, it seems that we may normalize the signal with the following formula:\n$$ \\frac{x}{2^{16}} * 2 $$\nI have to admit here that my knowledge of data encoding for audio file is limited, so if anyone is more knowledgeable on the matter than me, any comment (either confirmation or a correct normalization method) would be appreciated."},{"metadata":{"_cell_guid":"0ebee648-1137-4bbf-a91d-f44f73398b6c","_uuid":"f8bfbbcf4398de848e3e8959b5ec621f3da57321","trusted":true},"cell_type":"code","source":"data = np.array([(e/2**16.0)*2 for e in data]) #16 bits tracks, normalization\nplt.plot(data)","execution_count":111,"outputs":[]},{"metadata":{"_uuid":"e972fa85547f226c99a9c8afa4d14db9197e65b5"},"cell_type":"markdown","source":"## 2.2 Retrieving the Frequency Domain\nFrom this point, we can now use Scipy's signal module to retrieve frequencies. In this case, I opted for the retrieval of the full transform as a complex number rather than the energy level alone. The reason is that I suspect that it provides more information. \n\nHowever, I am not sure of this, and provided that the dataset is small, it might be inneficient to increase the feature space this way. Whatever, if you feel that having the complex values for frequencies may help you, there you go: "},{"metadata":{"_cell_guid":"768f1728-ad41-4687-8d20-d951264a2873","_uuid":"156117d9eb491f6ffaf5949f4681212b807ef44c","trusted":true},"cell_type":"code","source":"from scipy import signal\n#data\nfreqs, times, specs = signal.spectrogram(data,\n                                         fs=rate,\n                                         window=\"boxcar\",\n                                        nperseg=13230,\n                                        noverlap=0,\n                                        detrend=False,\n                                        mode = 'complex')\n\nplt.plot(freqs,np.absolute(specs[:,0]))","execution_count":112,"outputs":[]},{"metadata":{"_cell_guid":"9b6daf35-1333-4cb5-8aac-5d7ecbc3b33b","_uuid":"419edcd501814b7d53c32345862345df4c0cd7fb","collapsed":true},"cell_type":"markdown","source":"## 2.3 Obtaining a 3D Tensor on a Single File\nBased on the above work, let us create a 3D tensor for a single audio file. Ultimately, I would like to have a tensor with a fixed shape that is not dependent of the audio file so it can be processed in Keras.\n\nHere, we know that the sampling rate is fixed (44.1kHz) and that audio files vary in length from 0.3 to 30 seconds. I am using this information and the fact that the resulting frequencies of an FFT are fixed to define ex ante the shape of the input tensor for my neural network.\n\nThe first dimension of the tensor will be dictated by the number frames used to compute the spectrum of the signal. Here, I made the choice to use a fixed number of frame per segment. In this case, I opted for the number of frame of the smallest audio file (0.3 seconds, i.e. 13230 frames). This results in $13230/2+1=6615$ bins of frequencies, which is our first dimension size.\n\nFor the second dimension, it is simply the ratio of the largest number of frame over the number of frames per segment. In this case, this results to 100.\n\nFinally, the third dimension has size 2, one for the real part of the frequency domain, one for the imaginary part. This dimension could be omitted if necessary by taking the magnitude."},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"37f714a2a183b231ee9cbffaa19477f913871742"},"cell_type":"code","source":"RATE = 44100                                                     #44.1 kHz\nMAX_FRAME = int(RATE * 30)                                       #Max frame = 44.1 kHz * 30 seconds\nMIN_FRAME = int(RATE * 0.3)                                      #Min frame = 44.1 kHz * 0.3 seconds\nNORM_FACTOR = 1.0/2**16.0                                        # Used later to normalize audio signal\n \nMAX_INPUT = int(MAX_FRAME / MIN_FRAME)                           #Size of the second dimension\nFREQUENCY_BINS = int(MIN_FRAME / 2) + 1                          #Size of the first dimension\n\n#Input of the NN\nnn_input = np.zeros((FREQUENCY_BINS,\n                    MAX_INPUT,\n                    2))\n\nfreqs, times, specs = signal.spectrogram(data,                          #Signal               \n                                         fs=RATE,                       #Sampling rate\n                                         window=\"boxcar\",               #Rectangular segments\n                                         nperseg=MIN_FRAME,             #Number of frames per segments\n                                         noverlap=0,                    #No overlap\n                                         detrend=False,\n                                         mode = 'complex')              #Retrieve complex numbers\n\n#Fill the first component of the 3rd dimension with real part\nnn_input[:,:specs.shape[1],0] = np.real(specs)\n#Fill the first component of the 3rd dimension with imaginary part\nnn_input[:,:specs.shape[1],1] = np.imag(specs)\n\n#Display output for a small part of the tensor\nnn_input[:3,:3,:]","execution_count":113,"outputs":[]},{"metadata":{"_uuid":"cbf30cb06c792e4dbf5a25ef95280183af9435fe"},"cell_type":"markdown","source":"# 3. Useful Functions\n\nI provide here some function to reproduce the above work (see description in their respective \\__docstring__)\n\n## 3.1 Single Audio File Pre-Processing"},{"metadata":{"trusted":true,"_uuid":"e9b13f2a58145dbfa0361bfffc695d3beeb4c5da"},"cell_type":"code","source":"from scipy.io import wavfile\n\nRATE = 44100\n \nMAX_INPUT = int(MAX_FRAME / MIN_FRAME)\nFREQUENCY_BINS = int(MIN_FRAME / 2) + 1\n\nMAX_FRAME = int(RATE * 30)\nMIN_FRAME = int(RATE * 0.3)\nNORM_FACTOR = 1.0/2**16.0\n\ndef make_tensor(fname):\n    \"\"\"\n    Brief\n    -----\n    Creates a 3D tensor from an audio file\n    \n    Params\n    ------\n    fname: name of the file to pre-process\n    \n    Returns\n    -------\n    A 3D tensor of the audio file as an np.array\n    \"\"\"\n    rate, data = wavfile.read(fname)\n    data = np.array([(e*NORM_FACTOR)*2 for e in data])\n    output = nn_input = np.zeros((FREQUENCY_BINS,\n                                  MAX_INPUT,\n                                  2))\n    freqs, times, specs = signal.spectrogram(data,                                         \n                                         fs=RATE,\n                                         window=\"boxcar\",\n                                         nperseg=MIN_FRAME,\n                                         noverlap=0,\n                                         detrend=False,\n                                         mode = 'complex')\n    output[:,:specs.shape[1],0] = np.real(specs)\n    output[:,:specs.shape[1],1] = np.imag(specs)\n    return output\n    \nmake_tensor(fname)[1:5,1:5,:]\n    \n    ","execution_count":114,"outputs":[]},{"metadata":{"_uuid":"a09dea95b4d6cb53d461ae39155bcc68289edb19"},"cell_type":"markdown","source":"## 3.2 Pre-Process a List of File (or a Directory)\n"},{"metadata":{"trusted":true,"_uuid":"7d26f5a923077c877ccfc689b28f4df88e5a6482"},"cell_type":"code","source":"import os\n\ndef make_input_data(audio_dir, fnames=None):\n    \"\"\"\n    Brief\n    -----\n    Pre-process a list of file or a full directory.\n    \n    Params\n    ------\n    audio_dir: str\n        Directory where files are stored\n    fnames: str or None\n        List of filenames to preprocess. If None: pre-process the full directory.\n    \n    Returns\n    -------\n    A 4D tensor (last dimension refers to observations) as an np.array\n    \"\"\"\n    if fnames is None:\n        fnames = os.listdir(AUDIO_DIR)\n    else:\n        fnames = [fname + '.wav' for fname in fnames]\n    output = np.zeros((FREQUENCY_BINS,MAX_INPUT,2,len(fnames)))\n    i = 0\n    for fname in fnames:\n        full_path = os.path.join(audio_dir,fname)\n        \n        output[:,:,:,i] = make_tensor(full_path)\n        i+1\n    return output\n\n\n#Example\nAUDIO_DIR = '../input/audio_train/'\nfnames = ['00044347','001ca53d']\nmake_input_data(AUDIO_DIR,fnames)\n\n#This takes too long to run\n#make_input_data(AUDIO_DIR)\n\n\n","execution_count":115,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}