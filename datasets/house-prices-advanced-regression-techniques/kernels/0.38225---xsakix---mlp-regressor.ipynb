{"cells":[{"metadata":{"_uuid":"30cd7dea1aaf093c57d4374872c24a6bab87dd62"},"cell_type":"markdown","source":"# Using MLPRegressor\n\nI tuned it locally. The results anyway don't look promising...\n\nYour submission scored 0.38225, which is not an improvement of your best score. Keep trying!\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import os\nimport sys\nimport warnings\n\nfrom sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error\n\nif not sys.warnoptions:\n    warnings.simplefilter(\"ignore\")\n\nimport numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the currentd directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Loading data\n\nLoading data from train and test file. Test file provides only input data and I'll predict the prices via using a model."},{"metadata":{"trusted":true,"_uuid":"c7710fd6794dec5b3e2d4f892ba96fe5e4e5c86a","scrolled":false},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\ndef get_cat_cols(df):\n    return [col for col in df.columns if df[col].dtype == 'object']\n\n\ny = np.log1p(train_data.SalePrice)\n# test is meant for predictions and doesn't contain any price data. I need to provide it.\ncand_train_predictors = train_data.drop(['Id', 'SalePrice'], axis=1)\ncand_test_predictors = test_data.drop(['Id'], axis=1)\n\ncat_cols = get_cat_cols(cand_train_predictors)\n\ncand_train_predictors[cat_cols] = cand_train_predictors[cat_cols].fillna('NotAvailable')\ncand_test_predictors[cat_cols] = cand_test_predictors[cat_cols].fillna('NotAvailable')\n\nencoders = {}\n\nfor col in cat_cols:\n    encoders[col] = LabelEncoder()\n    val = cand_train_predictors[col].tolist()\n    val.extend(cand_test_predictors[col].tolist())\n    encoders[col].fit(val)\n    cand_train_predictors[col] = encoders[col].transform(cand_train_predictors[col]) + 1\n    cand_test_predictors[col] = encoders[col].transform(cand_test_predictors[col]) + 1\n\n# for column in cand_train_predictors.columns:\n#     cand_train_predictors[column].value_counts().sort_index().plot(kind=\"bar\",legend=column,figsize = (24,8))\n#     plt.show()\n\ncorr_matrix = cand_train_predictors.corr().abs()\n# with pd.option_context('display.max_rows',None, 'display.max_columns',None):\n#     print(corr_matrix.head())\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\ncols_to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\nprint('Highly correlated features(will be droped):', cols_to_drop)\n\ncand_train_predictors = cand_train_predictors.drop(cols_to_drop, axis=1)\ncand_test_predictors = cand_test_predictors.drop(cols_to_drop, axis=1)\n\nprint(cand_train_predictors.shape)\nprint(cand_test_predictors.shape)\n\ntrain_set, test_set = cand_train_predictors.align(cand_test_predictors, join='left', axis=1)\ntrain_set = np.log1p(train_set)\ntest_set = np.log1p(test_set)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67dc78ee8fba5234edc887db95d1a98349b1bd69"},"cell_type":"markdown","source":"# Model\n\nUsing a pipeline to process input features:\n1.  Features are imputed for missing values.\n2. Scaled for outliers, etc with RobusScaler\n3. Selected via feature importance computed via Lasso regression done viac cross validation\n"},{"metadata":{"trusted":true,"_uuid":"43223e82e92087e8b54fd93a672903cef3a72eff","scrolled":true},"cell_type":"code","source":"params = {}\ntrain_set.fillna('NaN', inplace=True)\n\nscore_results = []\nkfold = KFold(n_splits=10, random_state=1)\nimputer = Imputer(axis=1, strategy='mean')\nscaler = RobustScaler(with_centering=False, with_scaling=True, quantile_range=(20.0, 80.0))\nselect = SelectFromModel(LassoCV(cv=kfold, random_state=1), threshold='0.5*median')\nregressor = MLPRegressor(random_state=1,\n                         activation='logistic',\n                         solver='sgd',\n                         learning_rate='adaptive',\n                         learning_rate_init=0.013000000000000001,\n                         early_stopping=True,\n                         hidden_layer_sizes=(140, 140),\n                         max_iter=10000,\n                         momentum=0.9697272727272728\n                         )\n\npipe = make_pipeline(imputer, scaler, select, regressor)\nmy_model = GridSearchCV(pipe,\n                        params,\n                        cv=kfold,\n                        scoring='neg_mean_squared_log_error',\n                        verbose=10,\n                        n_jobs=2,\n                        error_score=-1000.)\n\nmy_model.fit(train_set, y)\nprint(-1 * my_model.score(train_set, y))\nprint(my_model.best_params_)\n\ntrain_pred = my_model.predict(train_set)\nprint('rmsle: ', np.sqrt(mean_squared_log_error(y, train_pred)))\nprint('rmse: ', np.sqrt(mean_squared_error(train_data.SalePrice, np.expm1(train_pred))))\nprint('mae: ', mean_absolute_error(train_data.SalePrice, np.expm1(train_pred)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3cf6c092db3490cbd4a89f2a64e3f207b7a9104"},"cell_type":"markdown","source":"# Predicting and submitting\n\nNow it's time to predict from test."},{"metadata":{"trusted":true,"_uuid":"69ea892736f99cab64240a61912cac54900b5949"},"cell_type":"code","source":"#based on mae this model has worse results, but it will produce better results in the submission\ntest_set.fillna('NaN',inplace=True)\npredicted_prices = np.expm1(my_model.predict(test_set))\nprint(predicted_prices[:5])\n\n# print(len(predicted_prices))\n# print(len(test_data.Id))\n\nmy_submission = pd.DataFrame({'Id': test_data.Id, 'SalePrice': predicted_prices})\nmy_submission.Id = my_submission.Id.astype(int)\n# print(my_submission.Id)\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}