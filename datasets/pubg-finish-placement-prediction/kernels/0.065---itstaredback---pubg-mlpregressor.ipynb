{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\nfrom scipy import stats","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e94994928dd0aa1cac1c48bfc7a322dbdd466bfe"},"cell_type":"markdown","source":"Let's define a function to read a given file and clean up the data in a unified manner"},{"metadata":{"trusted":true,"_uuid":"f712bdede182c0c18683e54ca1872b32313a1d1c"},"cell_type":"code","source":"def cleanFeatures(df):\n    #drop columns that likely don't affect the outcome of the match, the y values, and the dummy values (matchType)\n    droppedColumns = df.drop(columns=['Id', 'groupId', 'matchId', 'winPlacePerc', 'matchType'], errors='ignore')\n\n    #get the dummy values for the matchType\n    matchTypeDummies = pd.get_dummies(columns=list(df['matchType']), data=df['matchType'].values)\n\n    #standardize everything else from 0-1\n    mms = MinMaxScaler()\n    scaledDroppedColumns = mms.fit_transform(droppedColumns)\n\n    #create one input tensor\n    scaledDroppedColumnsDf = pd.DataFrame(data=scaledDroppedColumns, columns=list(droppedColumns))\n    X = pd.concat([scaledDroppedColumnsDf, matchTypeDummies], axis=1)\n    \n    return X\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6323c31d9e8e88f3de228a3ab38077b95311649"},"cell_type":"code","source":"#read in the CSV file\nallColumns = pd.read_csv(\"../input/train_V2.csv\")\nX = cleanFeatures(allColumns)\n\n#replace empty win percentages (the labels) with 0.0\nallColumns['winPlacePerc'] = allColumns['winPlacePerc'].fillna(0.0)\n#remove any other NaN rows as they will just cause problems in the NN\nallColumns.dropna()\n\n#get just the labels for win percentage\ny = allColumns['winPlacePerc'].values\n\n#split the data at an 80/20 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d30675af7faad369b2328312642ebe9105d07a8c"},"cell_type":"code","source":"#create a heat map to see if there are any features that are highly correlated\nf,ax = plt.subplots(figsize=(20, 20))\nsns.heatmap(allColumns.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cf5c2fde3e79f6628558f719d4ebc1b57006c43"},"cell_type":"markdown","source":"The higher the number, the more correlated two features are to each other.  As can be seen, the diagonal shows that every feature is exactly correlated to itself. \n\nAs can be expected, the number of \"winPoints\" correlates very highly to the number of \"killPoints\": more kills means more wins. \nThe high correlation from \"numGroups\" to \"maxPlace\" is a side effect of the way the data was collected. \n\nThe -1.0 correlations are between \"rankPoints\", \"killPoints\", and \"winPoints\".  All three of these features are related to an ELO type ranking system for players, but it appears that \"rankPoints\" is being deprecated and can likely be discounted. The deprecation could be the reason that \"rankPoints\" has such a negative correlation. \n\nFrom a strict \"winPlacePerc\" correlation, it appears that the \"walkDistance\" has the most relation to whether a player wins the match, whereas \"killPlace\" (the rank for number of players killed) has very little correlation to whether a player wins. The further a player walks (searching for new items, getting to the center of the battleground) the more they are likely to win. "},{"metadata":{"_uuid":"b8e334810ed803adb79b40c7d78bf21134cc40d7"},"cell_type":"markdown","source":"The first time through this data set involved creating a Keras fully connected neural network involving 6 layers of between 64 and 1024 nodes.  There was to be dropout (due to the high number of input points) and batch normalization leading to a final Mean Squared Error output. Unfortunately, running fitting even once showed that the validation set was only around 2.8% correct.  That is unusable and frankly a waste of time to pursue further.   Even dropping the model to one layer with only a handful of nodes continued to build to around 2.8% correct.  \n\nIn the end, Occam's Razor wins: back to the drawing board to see if there is anything easier to use and significantly more correct. "},{"metadata":{"_uuid":"e0d8d5b457fa1d6d44b26f0f8ecb0d07225e8c53"},"cell_type":"markdown","source":"After some searching, the scikit learn pre-made neural networks: the Multi-Layer Perceptron Regressor (MLPRegressor - http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor) was determined to likely solve the issues at hand. \n\nThe MLPRegressor has a number of parameters related to how it processes input data.  To ensure that the best network was used, a grid search of parameters was performed (elsewhere) to find the best network creations.  The grid of parameters is as follows:\n* Hidden Layers\n    * 10\n    * 100\n    * 200\n* Activation\n    * Logistic\n    * RELU\n* Optimizer\n    * Adam\n    * SGD\n* Alpha (L2 Penalty)\n    * 0.0001\n    * 0.01\n* Batch Size\n    * 128\n    * 256\n* Learning Rate Classifier (Learning rate schedule for weight updates)\n    * Constant\n    * Inverse Scaling: \"gradually decreases the learning rate learning_rate_ at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)\"\n    * Adaptive: \"keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.\"\n* Initial Learning Rate\n    * 0.001\n    * 0.005\n* powerT: \"The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’\"\n    * 0.5\n    * 0.9\n* Momentum\n    * 0.5\n    * 0.9\n\nNotes are from the MLPRegressor man page\n"},{"metadata":{"_uuid":"7d87b60b5ea8e03d79c98670541923349d920b0c"},"cell_type":"markdown","source":"After a lengthy search for the most correct network, the network hyper parameters chosen are:\n\n* Activation function: RELU\n* Alpha: 0.0001\n* Batch Size: 256\n* Hidden Layers: 200\n* Learning Rate Classifier: Constant\n* Intial Learning Rate: 0.001\n* Momentum: 0.9\n* Optimizer: Adam\n* PowerT: 0.5\n\nThis network showed about a 92.9% score for the input data, which is noted as significantly higher than the 2.8% from the custom built network.  \n\nInterestingly enough, another set of hyper parameters showed an extremely close score to the chosen network, about 92.7%, where every hyper parameter was the same except that the Batch Size was 128 and the number of Hidden Layers was 100; both roughly half of the respective values for the chosen network.  These two numbers more correlate to the logical layout of the network rather than the weights and biases of the other hyper parameters and likely interact more closely. "},{"metadata":{"_uuid":"1f4566c036cc35c218c6543ac682488e22f0de23"},"cell_type":"markdown","source":"Now we use the hyper parameters found to create an MLPRegressor network"},{"metadata":{"trusted":true,"_uuid":"da51c4d3fa73de5c814a53dec3c4a7f9672ae13c"},"cell_type":"code","source":"K.clear_session()\n\nmodel = MLPRegressor(\n    hidden_layer_sizes=(200,), \n    activation=\"relu\", \n    solver=\"adam\", \n    alpha=0.0001, \n    batch_size=256, \n    learning_rate=\"constant\", \n    learning_rate_init=0.001, \n    power_t=0.5, \n    momentum=0.9, \n    verbose=1, \n    early_stopping=True) # allow the model to stop early when it is no longer progressing\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4eeba51db5d60ca214aa30330bd2e95ed32892d"},"cell_type":"code","source":"print(\"Score for test split data: \" + str(model.score(X_test, y_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c49517ab1e376a7d1ec574146546ee4b0681c1b"},"cell_type":"markdown","source":"Now the actual test data should be read in, and transformed in the same manner as the training data. "},{"metadata":{"trusted":true,"_uuid":"2d97361c43690f4029e06d383a87021c4e10e2bc"},"cell_type":"code","source":"testColumns = pd.read_csv('../input/test_V2.csv') \ntestFeatures = cleanFeatures(testColumns)\n\ntestFeatures.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef6b2972284d4323fc804aeeadbc1d697e7b4ea7"},"cell_type":"markdown","source":"As can be seen here (https://datascience.stackexchange.com/questions/31957/mlpregressor-output-range) there are some nuances to the MLPRegressor that may cause the output of the network to be outside of the expected range of 0-1.  To counteract these error values, manually setting the \"out_activation_\" value on the model to \"relu\" before predicting the test output sets the minimum value on the output.  "},{"metadata":{"trusted":true,"_uuid":"db846c68ba6a273b5086d062192a5b72a37ef429","scrolled":true},"cell_type":"code","source":"model.out_activation_ = 'relu'\nplacementPredictions = model.predict(testFeatures)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6e0a929115545cc101f79cb370184a5ece509dd"},"cell_type":"markdown","source":"However, there are still output nodes that are above a 1.0 valuation.  Clean up the output valuations. "},{"metadata":{"trusted":true,"_uuid":"11a303c7e6137a48b1d26f9192e3f21be1b60855"},"cell_type":"code","source":"#to assume that above 1.00 is a win, just set those to 1.00\nplacementPredictions[placementPredictions > 1.0] = 1.0\n\nstats.describe(placementPredictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b59019aa01d31c65d0893be65d68bfa6f42fc79"},"cell_type":"markdown","source":"Now that the predictions have been cast, read the sample submission and write the placement values"},{"metadata":{"trusted":true,"_uuid":"b48ee5d32ae1ad6fb562c8d56c2c0b66aff1ae04"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission_V2.csv')\nsubmission['winPlacePerc'] = placementPredictions\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e6c1780726742933c691f3b6bbadeed4bb8a16a1"},"cell_type":"markdown","source":"Create the submission.csv"},{"metadata":{"trusted":true,"_uuid":"7e8c4f798bc74b1bf1127795fdf2150c32d64809"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"414b199c508608476d6cd7ec08a7ff19b2b8f4dd"},"cell_type":"markdown","source":"Fin"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}