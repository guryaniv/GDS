{"cells":[{"metadata":{"_uuid":"d8f0954479f207e45ac4a5306fb9f8d0a80b212c"},"cell_type":"markdown","source":"**Digit Classification on MNIST Dataset using Keras**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"In this example, I've trained a Convolution Neural Network from scratch on the MNIST Dataset\nThis notebook is inspired by the book **Deep Learning with Python** written by Keras author Francois Chollet.\n\nWe'll be using Keras, a simple-to-use deep learning library in Python. Let us start by importing the required libraries."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cae4b5dfa194850bb27375d6bdf5d40cb7b6978","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import  train_test_split\nfrom keras.datasets import mnist\nfrom keras import models\nfrom keras import layers\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83b5d4d719917cce30b1512af4e49ba5eed79202"},"cell_type":"markdown","source":"Now when that's underway, let us **import the data**."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fef8155b57716cb2c9eb8c6090dc621f14f90fc1"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"251fb219550dc2d58ed586d9fa6beb6a04c5d2a6"},"cell_type":"markdown","source":"We've created two dataframes, *train* and *test* to store the training and testing data respectively. Now let's extract the features and labels out of the training data. \n\n*Note: the 'test' dataframe is left unchanged here.* "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"508b7dbe8951ca81f49f21e635703a973650b841"},"cell_type":"code","source":"y_train = train['label']\nX_train = train.drop(labels = ['label'], axis = 1)\ndel train","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddb62188c8baa59ca11dc24727391860dfb4cec4"},"cell_type":"markdown","source":"Thus, *X_train* and *y_train* contain training data and labels respectively, and *test* contains test data."},{"metadata":{"trusted":true,"_uuid":"848a4980833326c8113e19c896d4cb65b0f02fbb","collapsed":true},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c0f4b378eb996e4bb7edc6f99ff96faa57041a5","collapsed":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc5b171db56dcff814fc6bdf701a272d7b806042"},"cell_type":"markdown","source":"**Preprocessing the data**\n\nAt present, each data value contains a pixel of range 0 to 255. We normalize them by so that each pixel value is between 0 and 1.\n\nNext, we reshape them so that the linear array of (Size, 784) can be made to a shape of (Size, 28, 28, 1). This is the shape that will be required by our ConvNet. The general form is (Size, height, width, no. of channels).\n\n*Note: This operation is applied to both training and testing data.*"},{"metadata":{"trusted":true,"_uuid":"f43cebd62a2bc9ba6098bde29f58334fab0ecacc","collapsed":true},"cell_type":"code","source":"X_train = X_train/255.0\nX_train = X_train.values.reshape(-1, 28, 28, 1)\n\ntest = test/255.0\ntest = test.values.reshape(-1, 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4c273c7577f25a594b07f1835c867c9ee368c11"},"cell_type":"markdown","source":"Now let's come to the labels. First, take a look at them before we do anything."},{"metadata":{"trusted":true,"_uuid":"ea6a7da45f7c72a751b44047638adb3d330fad38","collapsed":true},"cell_type":"code","source":"y_train[9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b93e21717c56e0e78d118cafe2bff45c785a7f55","collapsed":true},"cell_type":"code","source":"g = sns.countplot(y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b74da978c7000a355ac5318c9c7d22fe8a80df3"},"cell_type":"markdown","source":"Presently *y_train* contains the actual digit (from 0 through 9). We need to transform it into a more computer friendly form. We do this by **One-Hot Encoding**."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"326df963e6cd91a3fab725f12802c019cea4fbbb"},"cell_type":"code","source":"y_train = to_categorical(y_train, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bd889db935dc3e7a99e2cc130389e65ded88fd8","collapsed":true},"cell_type":"code","source":"y_train[9]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aae8e08989a2fa7fb71631898552cfcad6e890fc"},"cell_type":"markdown","source":"See, *y_train[9]* now stores [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] instead of just 3. That is, an array of 10, where all are 0 expect the label, which is 1.\n\nNow, let's crave the validaton set out of out training data. This is the data that our model evaluates on after each cycle of training. We use the Scikit Lean function ***train_test_split*** for this."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2f54d1dbcfbe98251b399d52a55ef03e03024819"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa1a19854492b9bd6355308ca39b6ba53b9a7761"},"cell_type":"markdown","source":"**Building the Model. **\n\nOur model consists of 3 Pairs of Conv2D-MaxPool layers and 2 Dense layers. Dropout is also used to fight overfitting."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"606cf31770c364342343afb07e17c1e2bfc286cf"},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(128, activation = 'relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation = 'softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4d0762439cddd0dd2752fe57fabca0f16513a726"},"cell_type":"markdown","source":"This is what the model actually looks like."},{"metadata":{"trusted":true,"_uuid":"ac6fe146542dbd3ee60db4b67e9df52b91d17573","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"11175eb026efe1499254b15e8887212a6de5097e"},"cell_type":"code","source":"model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b48ed64e890182048064f753be378f566fbd24d"},"cell_type":"markdown","source":"Since this is a multiclass classification problem, we use loss as *categorial_crossentropy*.\n\nNow, **training the model**."},{"metadata":{"trusted":true,"_uuid":"d3faf730b320f5eef5b53466a4e78680f309b65c","collapsed":true},"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs = 20, batch_size = 128, validation_data = (X_val, y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5aee5db90573c3552dbbc5f0c6683ed3b459a061"},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nacc = history.history['acc']\nval_acc = history.history['val_acc']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe79a23b906b9c5cba842d3a3777f1ded40457c1"},"cell_type":"markdown","source":"**Plotting** the training vs validation loss and accuracy, and checking how our model performed."},{"metadata":{"trusted":true,"_uuid":"046fe1c4d89fd5629a0bb40dd90257a1142902b0","collapsed":true},"cell_type":"code","source":"epochs = range(1, 21)\n\nplt.plot(epochs, loss, 'ko', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'k', label = 'Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7df39a6d955f9b2de90c48eaccd35dcf56a89ce8","collapsed":true},"cell_type":"code","source":"plt.plot(epochs, acc, 'yo', label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'y', label = 'Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f504f9c49ac60b73a7e24608524f43aa1016d4b6"},"cell_type":"markdown","source":"As you can see, our accuracy on validation set is above 99%. Let's see how well this model can do on test set."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b07a5ace19567a7fad95fd5a933b60455e81f3a2"},"cell_type":"code","source":"results = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07738db40a4e5c71700db5d3e305c243d680f2a8"},"cell_type":"markdown","source":"Presently, *results* contains One-Hot Vectors. We convert them back to digits by picking out the maximum index of the vector."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"09aa77b4d491d7fcf8a52dada12687cc578cbf85"},"cell_type":"code","source":"results = np.argmax(results, axis = 1)\nresults = pd.Series(results, name = 'Label')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42dbef3122354289850b480aa85965f541b67d75"},"cell_type":"markdown","source":"Let's take a look at what our *results* look like."},{"metadata":{"trusted":true,"_uuid":"0d1f28ddb82241535a4637fd13964fc550e35702","collapsed":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4edfba2b0223edb040f31b9f8c7708a720e2e05"},"cell_type":"markdown","source":"Makng a *submission.csv* file containing our results."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8623164ab7e3fb192d314ab06f1b6bdfc1042394"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1, 28001), name = 'ImageId'), results], axis = 1)\nsubmission.to_csv(\"MNIST_Dataset_Submissions.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"837007f0315f29f42121086d389fb0df2ddbcbc4"},"cell_type":"markdown","source":"This is my first public kernel on Kaggle. Hope you enjoyed it. \n\nAny comments and suggestions are welcome :)\n\nCheckout this repository for a slightly modified version of the above kernel: https://github.com/raahatg21/Digit-Recognition-MNIST-Dataset-with-Keras/blob/master/MNIST_9914.ipynb\n\nThanks for reading\n\n*Raahat Gupta*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}