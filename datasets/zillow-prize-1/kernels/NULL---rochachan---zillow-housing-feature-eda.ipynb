{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c29c6b2a-00a8-7f8b-3dcd-26d457bbcab8"
      },
      "source": [
        "## Zillow Housing--Feature EDA\n",
        "\n",
        "There's already some excellent kernel in python, you can have a reference.    \n",
        "\n",
        "[Missing Values & Multicollinearity--vivek][1]  \n",
        "  \n",
        "[Simple Exploration Notebook - SRK][2]\n",
        "\n",
        "**my object**  \n",
        " To have easy and quick roadmap to what i have done to playing the data.\n",
        "\n",
        "  [1]: https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity\n",
        "  [2]: https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c8984a7-1e7f-3d39-31e1-3c2f288f04c0"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25792a8f-8ba3-8231-3f5c-579bcde7d315"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "color = sns.color_palette()\n",
        "from matplotlib import pyplot as plt\n",
        "pd.set_option(\"display.max_columns\",100)\n",
        "plt.style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "64713f56-b229-89e5-438f-91f3e97026d9"
      },
      "source": [
        "# Reading In Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bea62c44-967e-2170-7474-4ac834c7309e"
      },
      "outputs": [],
      "source": [
        "## read in the property data and merge with trainId\n",
        "train = pd.read_csv('../input/train_2016.csv', parse_dates=[\"transactiondate\"])\n",
        "properties = pd.read_csv('../input/properties_2016.csv')\n",
        "merged = pd.merge(train,properties,on=\"parcelid\",how=\"left\")\n",
        "del properties\n",
        "merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fb52c08c-405d-9b98-efaa-6422162efcf8"
      },
      "source": [
        "# Shape and size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cf388c39-3677-a039-1b58-e203e8435e97"
      },
      "outputs": [],
      "source": [
        "## find no error predict\n",
        "merged_no_err = merged[merged.logerror ==0]\n",
        "merged_err = merged[merged.logerror !=0]\n",
        "\n",
        "## calculate rows\n",
        "total_row = merged.shape[0]\n",
        "no_err_row = merged_no_err.shape[0]\n",
        "err_row = merged_err.shape[0]\n",
        "print(\"total row is: {:d}\".format(total_row))\n",
        "print(\"no error row is: {:d}\".format(no_err_row))\n",
        "print(\"error row is: {:d}\".format(err_row))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b856ccb7-0518-2cb7-d5fc-d61bc65b8dd6"
      },
      "source": [
        "# missing data analysis  \n",
        "\n",
        "---  \n",
        "From the beginning of EDA , we should know what's happening in our missing data? Is there some logic problem? Or some doable cleaning and wrangling. We should not abandon the missing feature or samples immediately.  \n",
        "For example, the missing correlation map, we can using a dict mapping to fill the na when the cor <1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52ecbf63-5658-cea8-d681-db08d5d52d47"
      },
      "outputs": [],
      "source": [
        "## select the column with missing value\n",
        "missingValueColumns = merged.columns[merged.isnull().any()].tolist()\n",
        "\n",
        "## plot missing value\n",
        "(merged[missingValueColumns].isnull().sum()/total_row).sort_values().plot.barh(figsize=(10,16))\n",
        "msno.heatmap(merged[missingValueColumns],figsize=(20,20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6c01bce3-d947-25dc-c8b9-dbf0328bfdf2"
      },
      "source": [
        "# Object anaylsis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d0ee93fd-9b9f-08d5-0384-f8790a3ce84c"
      },
      "source": [
        "Do some modification of some outlier, we can have a look at the beautiful distribution of our logerror."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75bc3cb7-8ce9-39c6-8675-3489a42f75a6"
      },
      "outputs": [],
      "source": [
        "ulimit = np.percentile(merged.logerror.values, 99)\n",
        "llimit = np.percentile(merged.logerror.values, 1)\n",
        "merged['logerror'].ix[merged['logerror']>ulimit] = ulimit\n",
        "merged['logerror'].ix[merged['logerror']<llimit] = llimit\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.distplot(merged.logerror.values, bins=50, kde=False)\n",
        "plt.xlabel('logerror', fontsize=12)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bd98e30f-6520-fe30-a247-d9eee5da42ef"
      },
      "source": [
        "From the fig, we see about 30k samples contribute 80% error, so may be we can focus on samples have bad prediction.\n",
        "And our threshold is [-inf, -0.05] U [0.05, inf].  \n",
        "Maybe in the future we can analysis the model from postive error and negative error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a86055d8-e60f-f632-6b7c-07d95242fdcd"
      },
      "outputs": [],
      "source": [
        "## calculate cdf \n",
        "(abs(merged_err.logerror).sort_values().cumsum()/abs(merged_err.logerror).sum())\\\n",
        ".sort_values(ascending=False).reset_index(drop=True).plot.line(title=\"cdf error of feature\")\n",
        "\n",
        "## choose the 80% error of samplews\n",
        "per8_merged = merged_err[\\\n",
        "                         ((abs(merged_err.logerror).sort_values().cumsum()\\\n",
        "                           /abs(merged_err.logerror).sum())\\\n",
        "                          >0.2).sort_index()]\n",
        "\n",
        "## split the data\n",
        "pos_err = per8_merged[per8_merged.logerror > 0]\n",
        "neg_err = per8_merged[per8_merged.logerror < 0]\n",
        "\n",
        "print(\"The threshold is [-inf,-0.05] | [0.05,inf]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ba4d280c-b8ab-ebdb-6359-9c2165b85929"
      },
      "outputs": [],
      "source": [
        "var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99f1496a-5e49-766e-18d6-98ed23eddaf4"
      },
      "outputs": [],
      "source": [
        "col_name = merged.columns.tolist()\n",
        "col_name = col_name[:5]\n",
        "for var in col_name:\n",
        "    merged[var].value_counts().sort_index().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a39add4d-0075-91c0-1265-779643df60f1"
      },
      "source": [
        "### That's just the begining.  Stay tunes. "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}