{"metadata": {"language_info": {"name": "python", "version": "3.6.3", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "cells": [{"cell_type": "code", "metadata": {"_uuid": "75e6911afd7b417609ff8ac53766a94cea39f0aa", "_cell_guid": "41976c26-426e-4683-88e1-60e6ff07716a"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "43a3526eed032f5ed89b380b4bbca29e95cf9793", "scrolled": true, "_cell_guid": "e7c597ce-9878-4874-88e8-a55b87610103"}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import confusion_matrix\n", "\n", "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n", "from keras.optimizers import Adam\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.callbacks import LearningRateScheduler\n", "\n", "\n", "train_file = \"../input/train.csv\"\n", "test_file = \"../input/test.csv\"\n", "output_file = \"submission.csv\"\n", "\n", "raw_data = np.loadtxt(train_file, skiprows=1, dtype='int', delimiter=',')\n", "x_train, x_val, y_train, y_val = train_test_split(raw_data[:,1:], raw_data[:,0], test_size=0.1)\n", "\n", "plt.imshow(x_train[0].reshape(28,28), cmap='gray')\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "565d4daf68221b54b7fb9e460414ca69625d2d29", "collapsed": true, "_cell_guid": "e3ee77d4-da5c-48cd-ae9a-322581b6fb8d"}, "source": ["x_train = x_train.reshape(-1, 28, 28, 1)\n", "x_val = x_val.reshape(-1, 28, 28, 1)\n", "\n", "x_train = x_train.astype(\"float32\")/255.\n", "x_val = x_val.astype(\"float32\")/255.\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "059e367ddf325ccc9edc69bc757059a2e71ff49f", "collapsed": true, "_cell_guid": "5a548533-c372-455a-ab3e-474e6c3e43df"}, "source": ["y_train = to_categorical(y_train)\n", "y_val = to_categorical(y_val)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "ecb07857ea6b66f143bbaf764577ded2791e4f03", "_cell_guid": "fb168fed-0882-4437-b8a6-7ad88fd5c791"}, "source": ["print(y_train[0])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "b3fab7bc2443965653c374c6218937fb6ae746ae", "_cell_guid": "ac40477b-586d-44ef-8c86-0c34fa9445d8"}, "source": ["model = Sequential()\n", "\n", "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n", "                 input_shape = (28, 28, 1)))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n", "model.add(BatchNormalization())\n", "model.add(MaxPool2D(strides=(2,2)))\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n", "model.add(BatchNormalization())\n", "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n", "model.add(BatchNormalization())\n", "model.add(MaxPool2D(strides=(2,2)))\n", "model.add(Dropout(0.25))\n", "\n", "model.add(Flatten())\n", "model.add(Dense(512, activation='relu'))\n", "model.add(Dropout(0.25))\n", "model.add(Dense(1024, activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(10, activation='softmax'))\n", "\n", "\n", "datagen = ImageDataGenerator(zoom_range = 0.1,\n", "                            height_shift_range = 0.1,\n", "                            width_shift_range = 0.1,\n", "                            rotation_range = 10)\n", "\n", "\n", "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])\n", "\n", "\n", "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n", "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n", "                           steps_per_epoch=500,\n", "                           epochs= 20,\n", "                           verbose=2,\n", "                           validation_data=(x_val[:400,:], y_val[:400,:]),\n", "                           callbacks=[annealer])\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_uuid": "dfb0f04544d6302af801ee094c4b8560bcc7514c", "_cell_guid": "dc763fe7-83c5-4ebc-9f1f-a1b2479e844c"}, "source": ["mnist_testset = np.loadtxt(test_file, skiprows=1, dtype='int', delimiter=',')\n", "x_test = mnist_testset.astype(\"float32\")\n", "x_test = x_test.reshape(-1, 28, 28, 1)/255.\n", "\n", "y_hat = model.predict(x_test, batch_size=64)\n", "y_pred = np.argmax(y_hat,axis=1)\n", "\n", "\n", "with open(output_file, 'w') as f :\n", "    f.write('ImageId,Label\\n')\n", "    for i in range(len(y_pred)) :\n", "        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))\n", "\n", "print(\"Done\")"], "execution_count": null, "outputs": []}], "nbformat_minor": 1, "nbformat": 4}