{"cells":[{"metadata":{"_cell_guid":"25b1e1db-8bc5-7029-f719-91da523bd121","_uuid":"bde6dc7acb47f87a08eefc4a7f7a88ec2195a4fb"},"cell_type":"markdown","source":"## Introduction ##\n\nThis kernel is forked from Sina's elgant work: [Titanic best working Classifier][1] with family/group survival feature extracted from the data. The family/group information is extracted from name, fare and ticket number through close examing of the data and insparation I got from reading the discussions on the competition. I believe it is the first time this feature has been used as a prediction feature (or at least I have not browsed all the kernels to see it being used :-)). This new feature improved the score by ~1.5% and put the score to be 0.81818. I believe this feature can be used in other models to improve the prediction accuracy as well.\n\n  [1]: https://www.kaggle.com/sinakhorami/titanic-best-working-classifier?scriptVersionId=560373"},{"metadata":{"_cell_guid":"2ce68358-02ec-556d-ba88-e773a50bc18b","_uuid":"e4183dfadf752d5a87c362e6d1251b2dcb6c2b37","trusted":false,"collapsed":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport re as re\n\ntrain = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\nfull_data = [train, test]\n\nprint (train.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e25e7d50b28d19c5578dd2a8c3b181095703300","trusted":false,"collapsed":true},"cell_type":"code","source":"print(len(train))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9595646-65c9-6fc4-395f-0befc4d122ce","_uuid":"5bdcb4ae1ad461a60ce80b51849b363e1ad18019"},"cell_type":"markdown","source":"# Feature Engineering #"},{"metadata":{"_cell_guid":"9b4c278b-aaca-e92c-ba77-b9b48379d1f1","_uuid":"2b76e3eb81519f0c52081e8eab0fd223b56baac7"},"cell_type":"markdown","source":"## 1. Pclass ##\nthere is no missing value on this feature and already a numerical value. so let's check it's impact on our train set."},{"metadata":{"_cell_guid":"4680d950-cf7d-a6ae-e813-535e2247d88e","_uuid":"e9b74bedc8dc91b38ce43408fe60e2dff3920faf","trusted":false,"collapsed":true},"cell_type":"code","source":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e70f81c-d4e2-1823-f0ba-a7c9b46984ff","_uuid":"51a1209dc0f803834e951646c837a38217a74f87"},"cell_type":"markdown","source":"## 2. Sex ##"},{"metadata":{"_cell_guid":"6729681d-7915-1631-78d2-ddf3c35a424c","_uuid":"ff90c89fdf8351331d431163d8de7c0861b297d0","trusted":false,"collapsed":true},"cell_type":"code","source":"print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7c58b7ee-d6a1-0cc9-2346-81c47846a54a","_uuid":"fb807ec520d999227e8d287fe52486cb407e2780"},"cell_type":"markdown","source":"## 3. SibSp and Parch ##\nWith the number of siblings/spouse and the number of children/parents we can create new feature called Family Size."},{"metadata":{"_cell_guid":"1a537f10-7cec-d0b7-8a34-fa9975655190","_uuid":"9e85e6f03f4e296e329fb044b6a2671cbf55c85d","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\nprint (train[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e4861d3e-10db-1a23-8728-44e4d5251844","_uuid":"c0fffbaa1abd65de31ed2f8601e5c3db28d815f2"},"cell_type":"markdown","source":"it seems has a good effect on our prediction but let's go further and categorize people to check whether they are alone in this ship or not."},{"metadata":{"_cell_guid":"8c35e945-c928-e3bc-bd9c-d6ddb287e4c9","_uuid":"02a35757da1f59c896dc4cbadf4e76f60a224fcb","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\nprint (train[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2780ca4e-7923-b845-0b6b-5f68a45f6b93","_uuid":"59e50ee5a0b175ffa5963406c22023949b7fcf54"},"cell_type":"markdown","source":"good! the impact is considerable."},{"metadata":{"_cell_guid":"8aa419c0-6614-7efc-7797-97f4a5158b19","_uuid":"26e051873df13aa1d61ed4debbce8cfabfeae41a"},"cell_type":"markdown","source":"## 4. Embarked ##\nthe embarked feature has some missing value. and we try to fill those with the most occurred value ( 'S' )."},{"metadata":{"_cell_guid":"0e70e9af-d7cc-8c40-b7d4-2643889c376d","_uuid":"1ab3775b7b25cc3c49102e492770b8544327ded6","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\nprint (train[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e08c9ee8-d6d1-99b7-38bd-f0042c18a5d9","_uuid":"35ed9241587442e065198a8d57e5afed5e1ab06c"},"cell_type":"markdown","source":"## 5. Fare ##\nFare also has some missing value and we will replace it with the median. then we categorize it into 4 ranges."},{"metadata":{"_cell_guid":"a21335bd-4e8d-66e8-e6a5-5d2173b72d3b","_uuid":"88ccfa38c0186e4f8664f306af0bf26fa3fef377","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)\nprint (train[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec8d1b22-a95f-9f16-77ab-7b60d2103852","_uuid":"ad890584a4ddc57abf4855e21e3e99b7c56cf1c1"},"cell_type":"markdown","source":"## 6. Age ##\nwe have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).\nthen we categorize age into 5 range."},{"metadata":{"_cell_guid":"b90c2870-ce5d-ae0e-a33d-59e35445500e","_uuid":"47f85ca83a5f478afbf17d839380bbb39ec0abc7","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    age_avg \t   = dataset['Age'].mean()\n    age_std \t   = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    \n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\n    \ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)\n\nprint (train[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd25ec3f-b601-c1cc-d701-991fac1621f9","_uuid":"335df3bdf094997131245f0bec9fbfa4b326e97e"},"cell_type":"markdown","source":"## 7. Name ##\nAnother way of getting the title"},{"metadata":{"_cell_guid":"ad042f43-bfe0-ded0-4171-379d8caaa749","_uuid":"4886916827c3240685277f88c7d2e2897f07b23a","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Title'] = [x[1].split(\".\")[0].strip(\" \") for x in dataset['Name'].str.split(\",\")]\n\nprint(pd.crosstab(train['Title'], train['Sex']))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca5fff8c-7a0d-6c18-2173-b8df6293c50a","_uuid":"b817e282a391fcefc3311ec6365a46b86a1aa6cb"},"cell_type":"markdown","source":" so we have titles. let's categorize it and check the title impact on survival rate."},{"metadata":{"_cell_guid":"8357238b-98fe-632a-acd5-33674a6132ce","_uuid":"27e6677968dc730cff2cbef79decad9bf7050fc8","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n\nprint (train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8a5b0876-6cd9-43de-8e9d-372a949b165d","_uuid":"84e9e30fbc7c9fe5356e2f4afa50a0b60ebb8795"},"cell_type":"markdown","source":"# Extracting family information"},{"metadata":{"_cell_guid":"18ea6b78-4158-4d23-9b7f-229c71885d0f","_uuid":"36e359795c41f96a8de3a1cabb9125430ea444a5"},"cell_type":"markdown","source":"First we can use last name to divide the passengers into families. And if you closely examin the data, same family are paying the same fare for the tickets. This suggests the fare is for the family. We can use both last name and fare to grout passengers into families in case different families with the same last name. "},{"metadata":{"_cell_guid":"eaa36709-397b-4b07-811c-ff6ed0b267f8","_uuid":"d0f7b8f713daa292f6aaa9b57422e3742381bff6","trusted":false,"collapsed":true},"cell_type":"code","source":"train_size = len(train)\ntest_size = len(test)\n\nall_df = train.append(test)\nall_df = all_df[list(train.columns)]\n\nall_df.set_index(['PassengerId'], inplace=True) ## This is to make sure of a unique index for both train & test\n\n## Processing family information\nall_df['Last name'] = all_df['Name'].apply(lambda x: str.split(x, \",\")[0])\nall_df['Fare'].fillna(all_df['Fare'].mean(), inplace=True)\n\n# The Fare is actually for the whole family\nfare_df = all_df.loc[all_df['FamilySize']>1, [\"Last name\", \"Fare\", \"FamilySize\"]].iloc[:train_size]\nfare_diff = (((fare_df.groupby(['Last name', 'FamilySize']).max() \n - fare_df.groupby(['Last name', 'FamilySize']).min())!=0).sum()/train_size * 100)\nprint((\"Percentage of families with different fares is: %.1f\" %(fare_diff.values[0])) + '%')\n# The data shows only 1.7% has a different fare value between family memebers. It's some type of anomaly\n# Will use last name and fare to group passengers into families\n# First would like to show there is value in doing this\ntrain_temp_df = all_df.iloc[:train_size]\nfamily_df_grpby = train_temp_df[train_temp_df['FamilySize']>1][\n    ['Last name', 'Fare', 'FamilySize', 'Survived']].groupby(['Last name', 'Fare'])\nfamily_df = pd.DataFrame(data=family_df_grpby.size(), columns=['Size in train'])\nfamily_df['Survived total'] = family_df_grpby['Survived'].sum().astype(int)\nfamily_df['FamilySize'] = family_df_grpby['FamilySize'].mean().astype(int)\n#family_df = family_df[family_df['FamilySize']==8]\nprint(\"Whole family survived: %.1f\" \n      %(100*len(family_df[family_df['Size in train']==family_df['Survived total'] ])/len(family_df))+'%') \nprint(\"Whole family perished: %.1f\" \n      %(100*len(family_df[family_df['Survived total'] == 0])/len(family_df))+'%') \n## Majority family either all perished or all survived, this means we can use this as one feature to \n## predict survival\n\n# Now let's do the feature extraction\n# Intialize all 'Family survival', meaning there is no information on if any family members survived. \n# This number can be tuned I guess but I will use it to start with.\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame()\nall_df['Family survival'] = 0.5\nfor grp, grp_df in all_df[['Survived','Name', 'Last name', 'Fare', \n                           'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last name', 'Fare']):\n    if (len(grp_df) != 1):\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        is_partial_age = (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n        grp_partial_age += is_partial_age\n        \n        sibsp_df = grp_df.loc[grp_df['SibSp']!=0, ['Age']]\n        #print(sibsp_df.info())\n        sibsp_age_diff = sibsp_df.max() - sibsp_df.min()\n        grp_age_diff_df = grp_age_diff_df.append(sibsp_age_diff, ignore_index=True)\n\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n\n\n        for PassID, row in grp_df.iterrows():\n            ## Find out if any family memebers survived or not\n            smax = grp_df.drop(PassID)['Survived'].max()\n            smin = grp_df.drop(PassID)['Survived'].min()\n\n            ## If any family memebers survived, put this feature as 1\n            if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n            ## Otherwise if any family memebers perished, put this feature as 0\n            elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\n\nprint(\"Number of passenger with family survival information: \" \n      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\n\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint(grp_age_diff_df.describe())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"be6a8e96-9a4d-4e75-a15b-baefd4ae4a3d","_uuid":"299eefe2b9b99fc04fae8c6ea8b896df5ed3bcff"},"cell_type":"markdown","source":"# Extracting group information"},{"metadata":{"_cell_guid":"cf0739d8-c45b-4c25-b0bb-ad001cb25837","_uuid":"df6388bbb9bd9645fd2b8e0609ea094ce3fec8b8"},"cell_type":"markdown","source":"In addtional to family, if you examin the data closely, you will see there are groups of people with same ticket number, and they pay the same fare. This suggests group of friends are travelling together. One will think these friends will help each other and will survive or perish at the same time. We will explore this informtion here."},{"metadata":{"_cell_guid":"bd75f4b8-975d-4e92-8adc-fc6b067de99f","_uuid":"ebee067543095fcef1e5f252ace944171a5fa1be","trusted":false,"collapsed":true},"cell_type":"code","source":"# First find out how many such groups exists that are not families and what is the chance of \n# passengers within the same group survive or perish together\ntrain_temp_df = all_df.iloc[:train_size]\nticket_grpby = train_temp_df.groupby('Ticket')\nticket_df = pd.DataFrame(data=ticket_grpby.size(), columns=['Size in train'])\nticket_df['Survived total'] = ticket_grpby['Survived'].sum().astype(int)\nticket_df['Not family'] = ticket_grpby['Last name'].unique().apply(len)\n#ticket_df['Pclass'] = ticket_grpby['Pclass'].median()\nticket_df = ticket_df[(ticket_df['Size in train'] > 1) & (ticket_df['Not family']>1)]\nprint('Number of groups in training set that is not family: '+ str(len(ticket_df)))\n#print(\"Groups in Pclass 2/3: \" + str(len(ticket_df[ticket_df['Pclass']!=1])))\nprint((\"Whole group perished: %.1f\" %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==0]))) + '%')\nprint((\"Whole group survived: %.1f\" \n       %(100/len(ticket_df)*len(ticket_df[ticket_df['Survived total']==ticket_df['Size in train']]))) + '%')\n\n## Looking at the output, one can see ~76% of group members stay together. So let's extract this feature.\n## We will overload the 'Family survival' column instead of creating a seperate feature.\ngrp_partial_age = 0\ngrp_partial_cabin = 0\ngrp_age_diff_df = pd.DataFrame(columns=['Age diff'])\nticket_grpby = all_df.groupby('Ticket')\nfor _, grp_df in ticket_grpby:\n    if (len(grp_df) > 1):\n        grp_missing_age = len(grp_df[grp_df['Age'].isnull()])\n        grp_partial_age += (grp_missing_age != 0) & (grp_missing_age != len(grp_df))\n\n        grp_age_diff_df = grp_age_diff_df.append(pd.DataFrame(data=[grp_df['Age'].max() \n                                                                    - grp_df['Age'].min()]\n                                                              , columns=['Age diff']))\n\n\n        grp_missing_cabin = len(grp_df[grp_df['Cabin'].isnull()])\n        grp_partial_cabin += (grp_missing_cabin != 0) & (grp_missing_cabin != len(grp_df))\n        for PassID, row in grp_df.iterrows():\n            if (row['Family survival']==0)|(row['Family survival']==0.5):\n                smax = grp_df.drop(PassID)['Survived'].max()\n                smin = grp_df.drop(PassID)['Survived'].min()\n                if (smax==1.0): all_df.loc[PassID, 'Family survival'] = 1\n                elif (smin==0.0): all_df.loc[PassID, 'Family survival'] = 0\nprint('partial age group: ' + str(grp_partial_age))\nprint('partial cabin group: ' + str(grp_partial_cabin))\nprint(\"Number of passenger with family/group survival information: \" \n      +str(all_df[all_df['Family survival']!=0.5].shape[0]))\ntrain['Family survival'] = (all_df.iloc[:train_size]['Family survival'].values).astype(float)\ntest['Family survival'] = (all_df.iloc[train_size:]['Family survival'].values).astype(float)\nprint(grp_age_diff_df.describe())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac64652c-b566-44de-a398-3c83f702bb18","_uuid":"80148e37ea64f36eacbff10de7c4dbecc4fd1986"},"cell_type":"markdown","source":"Good, we can see 546 passengers have a family/group survival information. That's a sizable chunk out of the total numbers of passengers. Hopefully it will improve our prediction accuracy"},{"metadata":{"_cell_guid":"68fa2057-e27a-e252-0d1b-869c00a303ba","_uuid":"e1b330a1855baead6af2c14ebc40cd54b146f3e1"},"cell_type":"markdown","source":"# Data Cleaning #\ngreat! now let's clean our data and map our features into numerical values."},{"metadata":{"_cell_guid":"2502bb70-ce6f-2497-7331-7d1f80521470","_uuid":"7dab8cc063a209f843a947d5476a9c257e530897","trusted":false,"collapsed":true},"cell_type":"code","source":"for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age']                           = 4\n\n# Feature Selection\ndrop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp',\\\n                 'Parch', 'FamilySize']\ntrain = train.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\ntest  = test.drop(drop_elements, axis = 1)\n\nprint (train.head(10))\n\ntrain = train.values\ntest  = test.values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8aaaf2bc-e282-79cc-008a-e2e801b51b07","_uuid":"69e8f0c6230d270355bdd1d504e35103b64d1f26"},"cell_type":"markdown","source":"good! now we have a clean dataset and ready to predict. let's find which classifier works better on this dataset. "},{"metadata":{"_cell_guid":"23b55b45-572b-7276-32e7-8f7a0dcfd25e","_uuid":"49c5e7101a6eac085d73f7b8b525ec72025a5e54"},"cell_type":"markdown","source":"# Classifier Comparison #"},{"metadata":{"_cell_guid":"31ded30a-8de4-6507-e7f7-5805a0f1eaf1","_uuid":"a1be9e966c3e841e7c28784593bdb1c0478e1bdb","trusted":false,"collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n\tAdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog \t = pd.DataFrame(columns=log_cols)\n\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\nX = train[0::, 1::]\ny = train[0::, 0]\n\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n\tX_train, X_test = X[train_index], X[test_index]\n\ty_train, y_test = y[train_index], y[test_index]\n\t\n\tfor clf in classifiers:\n\t\tname = clf.__class__.__name__\n\t\tclf.fit(X_train, y_train)\n\t\ttrain_predictions = clf.predict(X_test)\n\t\tacc = accuracy_score(y_test, train_predictions)\n\t\tif name in acc_dict:\n\t\t\tacc_dict[name] += acc\n\t\telse:\n\t\t\tacc_dict[name] = acc\n\nfor clf in acc_dict:\n\tacc_dict[clf] = acc_dict[clf] / 10.0\n\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n\tlog = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"438585cf-b7ad-73ba-49aa-87688ff21233","_uuid":"6cd52741b92c26366a144d811f64d70c76a5cb0b"},"cell_type":"markdown","source":"# Prediction #\nAfter adding this new feature, it looks like GradientBoostingClassifier or LogisticRegression are better. Nonetheless, we will keep using SVC to see the impact of this new feature."},{"metadata":{"_cell_guid":"24967b57-732b-7180-bfd5-005beff75974","_uuid":"4da9974a1b3b82cbcf29830d90c2b07f1fe4e536","collapsed":true,"trusted":false},"cell_type":"code","source":"candidate_classifier = SVC()\ncandidate_classifier.fit(train[0::, 1::], train[0::, 0])\nresult = candidate_classifier.predict(test)\nresult_df = pd.DataFrame(columns=['PassengerId', 'Survived'], \n                         data=np.array([range(892, 1310), result]).T.astype(int))\nresult_df.to_csv(\"prediction.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"81c3fcd3-5a4c-4668-a299-72748448c3e6","_uuid":"dae8259c046a42286a06217aa1653043e68443b3","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.3","nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"_is_fork":false,"_change_revision":0,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}