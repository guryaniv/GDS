{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport pickle\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#loading the csv data with pandas dataframe\n#then convert it to pickle file\n#which is faster to get input\n\nOriginalData = pd.read_csv('../input/train.csv')\n\nlabel = np.array(OriginalData.iloc[:,0].values)\nOriginalData = np.array(OriginalData.iloc[:,1:785].values)\n\nOriginalTestData = pd.read_csv('../input/test.csv')\nOriginalTestData = np.array(OriginalTestData.iloc[:,0:784].values)\n\n\nf = open(\"train.pickle\",\"wb\")\nf.write(pickle.dumps(OriginalData))\nf.close\n\nf = open(\"trainLabel.pickle\",\"wb\")\nf.write(pickle.dumps(label))\nf.close\n\nf = open(\"test.pickle\",\"wb\")\nf.write(pickle.dumps(OriginalTestData))\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6687ce26867e307e1ca38477495833e5e2dc92e3"},"cell_type":"code","source":"#load the training data of Kaggle from pickle file\n\ntrain_data = pickle.loads(open('train.pickle',\"rb\").read())\ntrain_label = pickle.loads(open('trainLabel.pickle',\"rb\").read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3de31d13e9e7d982ebb3b55491193a7bd9dd538d"},"cell_type":"code","source":"#modules need to import\n\nimport matplotlib.pyplot as plt\nimport keras\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense, Dropout, Activation,Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7258bb2637ff9f7890982f1d7c5ae21d52550f46"},"cell_type":"code","source":"#function to display the digit in image form with its label\ndef digit_plot(data,label):\n    \n    fig = plt.figure()\n    plt.imshow(data[0], cmap = 'binary')\n    plt.title(\"class {}\".format(label))\n    plt.xticks(())\n    plt.yticks(())\n    \n    fig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3604426c493b6fbc7f9c2cb925eddffbbd4f5003"},"cell_type":"code","source":"#setting the model training parameters\n#and preprocess the training data\n\ntrain_x,test_x,train_y,test_y = train_test_split(train_data,train_label,test_size = 0.3,random_state = 1)\nnb_classes = 10\ninput_shape = (28,28,1)\nbatch_size = 1024\nepochs = 20\n\ntrain_x = train_x.astype('float64') / 255\ntest_x = test_x.astype('float64') / 255\n\ntrain_x = train_x.reshape(-1,28,28,1)\ntest_x = test_x.reshape(-1,28,28,1)\n\ntrain_y_1 = np_utils.to_categorical(train_y,nb_classes)\ntest_y_1 = np_utils.to_categorical(test_y,nb_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"984ab91f814b812d20a08013d85e4d0fb54ec9e9"},"cell_type":"code","source":"#CNN model building function\n#Using Conv2D, MaxPooling, Dropout, and Flattern\n#before output, the activation method -> relu\n#until output, activation method->softmax\n#Using RMSporp optimizer \n\ndef model_build():\n    model = Sequential()\n    model.add(Conv2D(32,kernel_size=(3,3),padding = 'same',activation='relu',\n                input_shape = input_shape))\n    model.add(Conv2D(64,kernel_size=(3,3),padding = 'same',activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.3))\n    model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.4))\n    model.add(Flatten())\n    model.add(Dense(128,activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(nb_classes,activation='softmax'))\n\n    model.compile(loss=keras.losses.categorical_crossentropy,\n             optimizer=keras.optimizers.RMSprop(),\n             metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5403b0ef23db4534ee890090f935dde25e5b861"},"cell_type":"code","source":"#Data Augmentation function\n#which is used to expand the dataset by add data variability(rotation, zoom ...)\ndef DataAugmentation(data):\n    \n    ExpandData = ImageDataGenerator(rotation_range = 10,\n                                   width_shift_range = 0.1,\n                                   height_shift_range = 0.1,\n                                   zoom_range = 0.1,\n                                   )\n    ExpandData.fit(data)\n    \n    return ExpandData","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e19ec665305788e40feca14da91e57f20cc5818"},"cell_type":"code","source":"#generate expandign data\n#build model, train model and save model\nDataExpand = DataAugmentation(train_x)\nmodel = model_build()\nhistory = model.fit_generator(DataExpand.flow(train_x,train_y_1,batch_size=batch_size),\n                              epochs=epochs,verbose=1,validation_data=(test_x,test_y_1),\n                             steps_per_epoch=train_x.shape[0]//batch_size)\nmodel.save('digital_recognizer.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f76b7801a44d1ecfbed99c1c53451ce21ddb0619"},"cell_type":"code","source":"#Using test data to validate model\nscore = model.evaluate(test_x,test_y_1,verbose=0)\nprint(\"Test loss:{}\",format(score[0]))\nprint(\"Test accuracy:{}\",format(score[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b676a1fadd2ede5edabac2eae3d52c0734461ca2"},"cell_type":"code","source":"#plot the training and validation result\n\nfig = plt.figure()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.legend(['training','validation'],loc='lower right')\nplt.plot()\n\nfig = plt.figure()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','validation'],loc='lower right')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e92aad403518d4c255a9f19a7dd2a7581a3e41c"},"cell_type":"code","source":"#training the model by all the kaggle train data\n#After you finish tuning the model paramter\nfinal_train_data = train_data.reshape(-1,28,28,1)\nfinal_train_data = final_train_data.astype('float64')/255\nfinal_train_label = np_utils.to_categorical(train_label,nb_classes)\n\nDataExpand = DataAugmentation(final_train_data)\nmodel = model_build()\nmodel.fit_generator(DataExpand.flow(final_train_data,final_train_label,batch_size=batch_size),\n                   epochs=30,verbose=1,steps_per_epoch=final_train_data.shape[0]//batch_size)\n\nmodel.save('final_model.h5')\n\n\nscore = model.evaluate(test_x,test_y_1,verbose=2)\nprint('validation loss:{}',format(score[0]))\nprint('validation accuracy:{}',format(score[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38d57acd26c0300d0e792e8f39fe457781e31f0c"},"cell_type":"code","source":"#import the module for model loading\nfrom keras.models import load_model ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"978609f5f429696959aa373eac6b4290986214d8"},"cell_type":"code","source":"#Loading the model which was already trained\n#Loading the test data of kaggle\n#Output the prediction result to submission.csv\ncurrent_model = load_model('final_model.h5')\ntest_data = pickle.loads(open(\"test.pickle\",\"rb\").read())\n\ntest_data = test_data.reshape(-1,28,28,1)\n\nprediction = current_model.predict(test_data,verbose=2)\nprediction = np.round(prediction)\nprediction = prediction.argmax(1)\n\n#Checking some results from prediction\n#with digit_plot function\nfor index,currentData in enumerate(test_data[0:20]):\n    currentData = currentData.reshape(1,28,28)\n    digit_plot(currentData,prediction[index])\n\n\n\nids = np.arange(0,prediction.shape[0],1)\noutput = pd.DataFrame({'ImageId':ids,\"Label\":prediction})\noutput.to_csv(\"submission.csv\",index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}