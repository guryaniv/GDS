{"cells":[{"metadata":{"_cell_guid":"0c37fb27-ed14-4064-bbc0-5d95e4d090bc","_uuid":"d467f4b1b8acc6d6c349e408c0d42f571223f641"},"cell_type":"markdown","source":"# 2018 ML March Madness Challenge\n--------"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nfrom random import randint\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\nfrom sklearn.preprocessing import normalize\n\nmassey_path = \"../input/mens-machine-learning-competition-2018/\"\nold_data_path = \"../input/supplemental-march-madness-data/\"","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"## Massey Challenge Data"},{"metadata":{"_cell_guid":"1e32cbdf-a80f-4dfa-812a-3ff6c8a90f38","_uuid":"32e78cdae2794f8928145c92a03d566f54969d71","collapsed":true,"trusted":true},"cell_type":"code","source":"tourney_games = pd.read_csv(massey_path + \"NCAATourneyCompactResults.csv\")\ntourney_seeds = pd.read_csv(massey_path + \"NCAATourneySeeds.csv\")\nrankings = pd.read_csv(massey_path + \"MasseyOrdinals.csv\") \nteams = pd.read_csv(massey_path + \"Teams.csv\")\nteam_names = dict(zip(list(teams[\"TeamID\"]), list(teams[\"TeamName\"])))\nteam_conf = pd.read_csv(massey_path + \"TeamConferences.csv\")\nteam_coaches = pd.read_csv(massey_path + \"TeamCoaches.csv\")\nteam_cities = pd.read_csv(massey_path + \"Cities.csv\")\nreg_season_stats = pd.read_csv(massey_path + \"RegularSeasonDetailedResults.csv\")\nreg_season_wins = pd.read_csv(massey_path + \"RegularSeasonCompactResults.csv\")","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"cf8a2166-9079-45b8-97af-bf1b8e904e2a","_uuid":"ee807d8eb09603ba8e06b4e692d2380eb7091334"},"cell_type":"markdown","source":"## Independently Collected Data"},{"metadata":{"_cell_guid":"fe6fe921-57b1-402e-abcd-92e4d8759571","_uuid":"9a12b4a7ed84ba80f3a23f084e614bec53e73e37","collapsed":true,"trusted":true},"cell_type":"code","source":"#AP POLLS\nap_polls = pd.read_csv(old_data_path + \"ap_polls.csv\")\nteam_spellings = pd.read_csv(massey_path + \"TeamSpellings.csv\", encoding='latin1')\n\n#Add team ID to ap_polls\nteam_ids = []\nfor i, row in ap_polls.iterrows():\n    school_name = row[\"School\"].lower()\n    school_id = team_spellings.loc[team_spellings[\"TeamNameSpelling\"] == school_name]\n    school_id = int(school_id.iloc[0][\"TeamID\"])\n    team_ids.append(school_id)\nap_polls[\"TeamID\"] = team_ids\n\n#COACH TOURNAMENT APPEARANCES\ncoach_tourney_appearances = pd.read_csv(old_data_path + \"coach_tourney_appearances.csv\")\ncoach_appearances = {row[\"CoachName\"]: row[\"TourneyAppearances\"] for _, row in coach_tourney_appearances.iterrows()}\n\n#GAME LOCATION DISTANCES\ngame_distances = pd.read_csv(old_data_path + \"GameDistances.csv\")\ntournament_distance_matrix = pd.read_csv(old_data_path + \"TournamentDistanceMatrix.csv\")","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"9fdfbc2e-69bf-4dab-a298-4278e1676e32","_uuid":"e9adf71ea42872bb149f4e9744788d52791a6155"},"cell_type":"markdown","source":"## Feature Extraction Methods"},{"metadata":{"_cell_guid":"dbf6684c-95be-4c34-ba17-4f5e7839aada","_uuid":"66c28b67b8d70f1bbea072bed448798285850c17","collapsed":true,"trusted":true},"cell_type":"code","source":"#Feature Config\nfeatures = {\n    'round': 1,\n    'seed': 1,\n    'coach': 1,\n    'distance': 1,\n    'last': 1,\n    'rpi': 1,\n    'pom': 1,\n    'reb': 1,\n    'fga': 1,\n    'fgpct': 1,\n    'ftpct': 1\n}\nnum_features = 2 * len([1 for (k, v) in features.items() if (k != 'round' and v)]) + features['round']\n\n#Filename for saving\ndef gen_unique_name():\n    name = ''\n    if features['round']: name += 'Rnd'\n    if features['seed']: name += 'S'\n    if features['coach']: name += 'C'\n    if features['distance']: name += 'D'\n    if features['last']: name += 'L'\n    if features['rpi']: name += 'Rpi'\n    if features['pom']: name += 'P'\n    if features['reb']: name += 'Reb'\n    if features['fga']: name += 'Fga'\n    if features['fgpct']: name += 'Fgp'\n    if features['ftpct']: name += 'Ft'\n    return name\nfeature_filename = gen_unique_name()","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"5c027af4-faff-4b4c-b2c7-c33c80318978","_uuid":"5f16c0ea89652f9a27cc7a0813aaea61a725edd4","collapsed":true,"scrolled":false,"trusted":true},"cell_type":"code","source":"#Returns the tournament round of the game in question\ndef find_round(day_num):\n    #Return -1 if feature is not used\n    if not features['round']:\n        return -1\n    \n    #Play in games\n    if day_num in [134, 135]:\n        return 0\n    #First Round\n    elif day_num in [136, 137]:\n        return 1\n    #Round of 32\n    elif day_num in [138, 139]:\n        return 2\n    #Sweet Sixteen\n    elif day_num in [143, 144]:\n        return 3\n    #Elite Eight\n    elif day_num in [145, 146]:\n        return 4\n    #Final Four\n    elif day_num == 152:\n        return 5\n    #Champtionship\n    elif day_num == 154:\n        return 6\n\n#Seed comes in the form W00a\n#Where W is the region, 00 is the seed, and a indicates if it was play in game\ndef find_seed(year, team_id):\n    #Return -1 if feature is not used\n    if not features['seed']:\n        return -1\n    \n    seed = tourney_seeds.loc[(tourney_seeds[\"Season\"] == year) & (tourney_seeds[\"TeamID\"] == team_id)]\n    seed = seed.iloc[0][\"Seed\"]\n    if len(seed) > 3: #Play-in\n        seed = seed[:-1]\n    seed = seed[1:]\n    return int(seed)\n \n#Return the RPI and POM ranking for the team if the data is available\n#If RPI and POM are not available, return the AP Polls rank\n#If AP Poll rank is not available either, return the default value\ndef get_rankings(year, team_id):\n    #Change rank to -1 if feature is not used\n    def override(ranks):\n        if not features['rpi']:\n            ranks[0] = -1\n        if not features['pom']:\n            ranks[1] = -1\n        return ranks\n    \n    default_rank = 55 #Average RPI/POM rank for teams not in top 25 AP polls\n    \n    #Extract rank from Massey dataset or my personal dataset depending on rank type\n    def rank_by_type (name):\n        #Massey\n        if name != \"AP\":\n            rank = rankings.loc[(rankings[\"SystemName\"] == name) & (rankings[\"TeamID\"] == team_id) \n                                & (rankings[\"Season\"] == year) & (rankings[\"RankingDayNum\"] == 133)]\n            return rank.iloc[0][\"OrdinalRank\"]\n        #AP Polls\n        else:\n            rank = ap_polls.loc[(ap_polls[\"TeamID\"] == team_id) & (ap_polls[\"Year\"] == year)]\n            if not rank.empty:\n                return rank.iloc[0][\"Rank\"]\n            return None\n        \n    #If data is available, get RPI/POM\n    if year > 2002:\n        rpi_rank = rank_by_type(\"RPI\")\n        pom_rank = rank_by_type(\"POM\")\n        return override((rpi_rank, pom_rank))\n    #Otherwise check AP\n    else:\n        ap_rank = rank_by_type(\"AP\")\n        if ap_rank:\n            return override((ap_rank, ap_rank))\n        return override((default_rank, default_rank))\n\n#Return the number of years a coach has been in the tournament\n#Uses global variable \"coach_appearances\"\ndef coach_experience(year, team_id):\n    #Return -1 if feature is not used\n    if not features['coach']:\n        return -1\n    \n    if year == 2018:\n        days = 77\n    else:\n        days = 154\n        \n    coach = team_coaches.loc[(team_coaches[\"TeamID\"] == team_id) & (team_coaches[\"Season\"] == year)\n                                & (team_coaches[\"LastDayNum\"] == days)]\n    coach = coach.iloc[0][\"CoachName\"]\n    \n    if coach not in coach_appearances:\n        coach_appearances[coach] = 1\n        return 0\n    \n    coach_appearances[coach] += 1\n    return (coach_appearances[coach] - 1)\n\n#Regular season statistics leading up to the tournament\n#Returns average rebounds, field goal attempts, field goal percentage, and free throw percentage\n#If the data is unavailable, return average\ndefault_win_values = (36.8, 57.0, 46.6, 70.5)\ndefault_lose_values = (36.0, 56.2, 45.9, 70.2)\ndef get_stats(year, team_id, win=None):\n    #Change rank to -1 if feature is not used\n    def override(ranks):\n        if not features['reb']:\n            ranks[0] = -1\n        if not features['fga']:\n            ranks[1] = -1\n        if not features['fgpct']:\n            ranks[2] = -1\n        if not features['ftpct']:\n            ranks[3] = -1\n        return ranks\n    \n    #Data unavailable, return averages\n    if year < 2003:\n        if win == \"w\":\n            return override(default_win_values)\n        else:\n            return override(default_lose_values)\n    \n    #Regular season games\n    team_stats = reg_season_stats.loc[((reg_season_stats[\"Season\"] == year) \n                         & ((reg_season_stats[\"WTeamID\"] == team_id) | (reg_season_stats[\"LTeamID\"] == team_id)))]\n    \n    games = len(team_stats)\n    rebounds = np.zeros(games)\n    fga = np.zeros(games)\n    fgm = np.zeros(games)\n    fta = np.zeros(games)\n    ftm = np.zeros(games)\n    for i, (_, row) in enumerate(team_stats.iterrows()):\n        if row[\"WTeamID\"] == team_id:\n            t = \"W\"\n        else:\n            t = \"L\"\n        rebounds[i] = row[t+\"OR\"] + row[t+\"DR\"]\n        fga[i] = row[t+\"FGA\"]\n        fgm[i] = row[t+\"FGM\"]\n        fta[i] = row[t+\"FTA\"]\n        ftm[i] = row[t+\"FTM\"]\n    fg_pct = np.array([100*(fgm[i]/float(fga[i])) if fga[i] != 0 else 0 for i in range(games)])\n    ft_pct = np.array([100*(ftm[i]/float(fta[i])) if fta[i] != 0 else 0 for i in range(games)])\n    \n    rebounds = np.mean(rebounds)\n    fga = np.mean(fga)\n    fg_pct = np.mean(fg_pct)\n    ft_pct = np.mean(ft_pct)\n    \n    return override((rebounds, fga, fg_pct, ft_pct))\n\n#Returns the distance from the team's hometown to the location of play\ndefault_win_distance = 1050\ndefault_lose_distance = 1150\ndef find_distance (year, day_num, team_id, win=None):\n    #Return -1 if feature is not used\n    if not features['distance']:\n        return -1\n    \n    if year < 2010:\n        if win == \"w\":\n            return default_win_distance\n        return default_lose_distance\n    \n    distance = game_distances.loc[(game_distances[\"Season\"] == year) & (game_distances[\"DayNum\"] == day_num)\n                                 & (game_distances[win.upper()+\"TeamID\"] == team_id)]\n    return distance.iloc[0][win.upper()+\"TeamDistance\"]\n\n#Returns the number of the last 10 games the team has won\ndef last_ten (year, team_id):\n    #Return -1 if feature is not used\n    if not features['last']:\n        return -1\n    \n    games = reg_season_stats.loc[((reg_season_stats[\"Season\"] == year) \n                         & ((reg_season_stats[\"WTeamID\"] == team_id) | (reg_season_stats[\"LTeamID\"] == team_id)))]\n    last = games[-10:]\n    wins = len([0 for _, row in last.iterrows() if row[\"WTeamID\"] == team_id])\n    return wins\n\n\n#Normalizes scores as a probablility distribution for the labels\ndifferentials = {\n    11: 7,\n    10: 7,\n    9: 6.5,\n    8: 6,\n    7: 5.5,\n    6: 5,\n    5: 4.2,\n    4: 3.4,\n    3: 2.6,\n    2: 1.8,\n    1: 0.8\n}\ndef normalize_scores (score1, score2):\n    if (score1 - score2) >= 12:\n        return np.array([1.0, 0.0])\n    diff = score1 - score2\n    score2 += differentials[diff]\n    scores = np.array([score1, score2])\n    return np.exp(scores) / sum(np.exp(scores))\n","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"ecd7a8ac-3695-48a6-a423-9428af61c425","_uuid":"238da042cd21159fcbe50cf99b38d6e59a110f14"},"cell_type":"markdown","source":"## Training Data Aggregation"},{"metadata":{"_cell_guid":"9fb1eb45-96d9-439d-bad9-dbcf2d2dfb6d","_uuid":"9715b283a2f7f19cc58b00248fe4253f487b6dd2","collapsed":true,"trusted":true},"cell_type":"code","source":"sizeA = 1136\nsizeB = 448\nsizeC = 533\nnum_features = 21\nnum_outputs = 2\n\ntraining1985 = None\ntraining2003 = None\ntraining2010 = None\n\ndef shuffle_data (x, y):\n    group = np.array(list(zip(x, y)))\n    np.random.shuffle(group)\n    x = np.array([i[0] for i in group])\n    y = np.array([i[1] for i in group])\n    return (x, y)\n    \ndef gather_data():\n    training1985x = np.zeros((sizeA, num_features))\n    training2003x = np.zeros((sizeB, num_features))\n    training2010x = np.zeros((sizeC, num_features))\n    training1985y = np.zeros((sizeA, num_outputs))\n    training2003y = np.zeros((sizeB, num_outputs))\n    training2010y = np.zeros((sizeC, num_outputs))\n    global training1985, training2003, training2010\n\n    ai, bi, ci = 0, 0, 0\n    for i, row in tourney_games.iterrows():\n        year = row[\"Season\"]\n        day_num = row[\"DayNum\"]\n        w_team = row[\"WTeamID\"]\n        l_team = row[\"LTeamID\"]\n        w_score = row[\"WScore\"]\n        l_score = row[\"LScore\"]\n            \n        rnd = find_round(day_num)\n\n        w_seed = find_seed(year, w_team)\n        l_seed = find_seed(year, l_team)\n\n        w_coach = coach_experience(year, w_team)\n        l_coach = coach_experience(year, l_team)\n\n        w_rpi, w_pom = get_rankings(year, w_team)\n        l_rpi, l_pom = get_rankings(year, l_team)\n\n        w_distance = find_distance(year, day_num, w_team, \"w\")\n        l_distance = find_distance(year, day_num, l_team, \"l\")\n\n        w_last = last_ten(year, w_team)\n        l_last = last_ten(year, l_team)\n\n        w_reb, w_fga, w_fgpct, w_ftpct = get_stats(year, w_team, \"w\")\n        l_reb, l_fga, l_fgpct, l_ftpct = get_stats(year, l_team, \"l\")\n\n        win_prob = normalize_scores(w_score, l_score)\n\n        if randint(0, 1) == 0:\n            examp = np.array([i for i in [rnd, w_seed, w_coach, w_distance, w_last, w_rpi, w_pom, w_reb, w_fga, w_fgpct, w_ftpct,\n                                  l_seed, l_coach, l_distance, l_last, l_rpi, l_pom, l_reb, l_fga, l_fgpct, l_ftpct]\n                             if i != -1])\n            label = win_prob\n        else:\n            examp = np.array([i for i in [rnd, l_seed, l_coach, l_distance, l_last, l_rpi, l_pom, l_reb, l_fga, l_fgpct, l_ftpct,\n                                 w_seed, w_coach, w_distance, w_last, w_rpi, w_pom, w_reb, w_fga, w_fgpct, w_ftpct]\n                              if i != -1])\n            label = np.array([win_prob[1], win_prob[0]])\n            \n        if year < 2003:\n            training1985x[ai] = examp\n            training1985y[ai] = label\n            ai += 1\n        elif year < 2010:\n            training2003x[bi] = examp\n            training2003y[bi] = label\n            bi += 1\n        else:\n            training2010x[ci] = examp\n            training2010y[ci] = label\n            ci += 1\n\n    training1985x = normalize(training1985x)\n    training2003x = normalize(training2003x)\n    training2010x = normalize(training2010x)\n    \n    x1985, y1985 = shuffle_data(training1985x, training1985y)\n    x2003, y2003 = shuffle_data(training2003x, training2003y)\n    x2010, y2010 = shuffle_data(training2010x, training2010y)\n    \n    np.save('x1985_{}.npy'.format(feature_filename), x1985)\n    np.save('y1985_{}.npy'.format(feature_filename), y1985)\n    np.save('x2003_{}.npy'.format(feature_filename), x2003)\n    np.save('y2003_{}.npy'.format(feature_filename), y2003)\n    np.save('x2010_{}.npy'.format(feature_filename), x2010)\n    np.save('y2010_{}.npy'.format(feature_filename), y2010)","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"220d7d8b-dd53-4368-951c-1212cdfcc33a","_uuid":"7656d56d1f785d171a229f774e6e42b7687a74c0","collapsed":true,"trusted":true},"cell_type":"code","source":"gather_data()","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"db26a5c5-d6c0-489e-99b4-0fdfdcaa4d44","_uuid":"f0608649494ceee5a66b1a140b035d28925d692e"},"cell_type":"markdown","source":"## Split into Train and Test Sets"},{"metadata":{"_cell_guid":"8ce0d132-4921-45cc-9847-e5a818c148d7","_uuid":"7c63c584d080afba7a55e3259f8afdf12b951140","collapsed":true,"trusted":true},"cell_type":"code","source":"x1985 = np.load('x1985_{}.npy'.format(feature_filename))\ny1985 = np.load('y1985_{}.npy'.format(feature_filename))\nx2003 = np.load('x2003_{}.npy'.format(feature_filename))\ny2003 = np.load('y2003_{}.npy'.format(feature_filename))\nx2010 = np.load('x2010_{}.npy'.format(feature_filename))\ny2010 = np.load('y2010_{}.npy'.format(feature_filename))\n\ntraining_data = {1985: (x1985[:-15], y1985[:-15]), 2003: (x2003[:-15], y2003[:-15]), 2010: (x2010[:-120], y2010[:-120])}\ntraining_data[2000] = (np.concatenate((x2003[:-15], x2010[:-120])), np.concatenate((y2003[:-15], y2010[:-120])))\nx_test = np.concatenate((x1985[-15:], x2003[-15:], x2010[-120:]))\ny_test = np.concatenate((y1985[-15:], y2003[-15:], y2010[-120:]))\ntest = (x_test, y_test)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"65135521-ba03-4a1d-a376-1f252410ebeb","_uuid":"85f46aff572e4d433a36a5601636c2b6eb4b2aaf"},"cell_type":"markdown","source":"## Training Feed Forward Network\n#### First trained on dataset with all features mentioned above except regular season statistics or the distance from a team's home field\n#### Then trained on dataset with statistics but without the distances\n#### Finally trained on dataset where all the information is available"},{"metadata":{"_cell_guid":"fe1bde78-151e-4f69-b838-786503fca359","_uuid":"f46062aaf9c53f0c45e077289d9f6407eed9bdeb","trusted":true},"cell_type":"code","source":"n_in = num_features\nn_out = num_outputs\nn_hid = 64\nbatch_size = 16\n\ndef get_batch(year):\n    training = training_data[year]\n    size = training[0].shape[0]\n        \n    x, y = training\n    seed = randint(0, size - batch_size)\n    \n    return x[seed : seed+batch_size], y[seed : seed + batch_size]\n    \n\nx = tf.placeholder(tf.float32, shape=[None, n_in])\ny_ = tf.placeholder(tf.float32, shape=[None, n_out])\nlr = tf.placeholder(tf.float32)\n\nw1 = tf.Variable(tf.truncated_normal(shape=[n_in, n_hid]))\nw2 = tf.Variable(tf.truncated_normal(shape=[n_hid, n_out]))\nb1 = tf.Variable(tf.ones(n_hid))\nb2 = tf.Variable(tf.ones(n_out))\n\nh1 = tf.nn.relu(tf.matmul(x, w1) + b1)\ny = tf.matmul(h1, w2) + b2\n\nloss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\ntrain_step = tf.train.AdamOptimizer(lr).minimize(loss)\n\ncorrect_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n\nparams = {\n    1985: {\n        \"epoch_len\": 1000, \n        \"num_epochs\": 10, \n        \"learning_rate\": 0.001\n    },\n    2003: {\n        \"epoch_len\": 500, \n        \"num_epochs\": 5, \n        \"learning_rate\": 0.001\n    },\n    2010: {\n        \"epoch_len\": 500, \n        \"num_epochs\": 10, \n        \"learning_rate\": 0.001\n    },\n    2000: {\n        \"epoch_len\": 1000,\n        \"num_epochs\": 10,\n        \"learning_rate\": 0.0005\n    }\n}\n\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\n    \nfor year in [1985, 2003, 2010]:\n    for i in range(params[year][\"num_epochs\"]):\n        for _ in range(params[year][\"epoch_len\"]):\n            learning_rate = params[year][\"learning_rate\"]\n            examp, label = get_batch(year)\n                \n            _ = sess.run([train_step], feed_dict={ x: examp, y_: label, lr: learning_rate })\n        loss_val, acc = sess.run([loss, accuracy], feed_dict={x: training_data[year][0],\n                                                              y_: training_data[year][1], lr: learning_rate})\n        print (\"Epoch: {}, Loss: {}, Accuracy: {}\".format(i, loss_val, acc))\n            \n    loss_val, acc = sess.run([loss, accuracy], feed_dict={x: test[0], y_: test[1], lr: learning_rate})\n    print(\"Test Results:\\t Loss: {}, Accuracy:{}\".format(loss_val, acc))\n","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"b152ecb0-0367-4960-91b5-8851ff52167c","_uuid":"d9b2182646489fd50705fcfe4fe71a98f34ac9a3"},"cell_type":"markdown","source":"## 2018 Prediction"},{"metadata":{"_cell_guid":"9f3a0210-9546-4e17-878e-40dbe3c9a79c","_uuid":"ee25d32d8bc5971d4b83b0671db8148ace87fffe","collapsed":true,"trusted":true},"cell_type":"code","source":"tournament_cities = [\"\", \"\", \"\", \"\", \"Pittsburgh PN\", \"Detroit MI\", \"Dallas TX\", \"San Diego CA\", \"San Diego CA\",\n    \"Dallas TX\", \"Detroit MI\", \"Pittsburgh PN\", \"Wichita KS\", \"Pittsburgh PN\", \"Detroit MI\", \"San Diego CA\",\n    \"San Diego CA\", \"Detroit MI\", \"Pittsburgh PN\", \"Wichita KS\", \"Charlotte NC\", \"Nashville TN\", \"Dallas TX\", \n    \"Boise iD\", \"Boise iD\", \"Dallas TX\", \"Nashville TN\", \"Charlotte NC\", \"Nashville TN\", \"Charlotte NC\", \"Wichita KS\", \n    \"Boise iD\", \"Boise iD\", \"Wichita KS\", \"Charlotte NC\", \"Nashville TN\", \"Pittsburgh PN\", \"Detroit MI\", \"Dallas TX\",\n    \"San Diego CA\", \"Wichita KS\", \"Pittsburgh PN\", \"Detroit MI\", \"San Diego CA\", \"Charlotte NC\", \"Nashville TN\",\n    \"Dallas TX\", \"Boise iD\", \"Nashville TN\", \"Charlotte NC\", \"Wichita KS\", \"Boise iD\", \"Boston MA\", \"Boston MA\", \"Omaha NE\",\n    \"Omaha NE\", \"Atlanta GA\", \"Atlanta GA\", \"Los Angelos CA\", \"Los Angelos CA\", \"Boston MA\", \"Omaha NE\", \"Atlanta GA\",\n    \"Los Angelos CA\", \"San Antonio TX\", \"San Antonio TX\", \"San Antonio TX\"]","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"edccd5f6-d6e8-4001-a5f5-013bda36069a","_uuid":"8d16685a0c65ba0b494f40938572eca073f5e743","scrolled":true,"trusted":true},"cell_type":"code","source":"tourney_slots = pd.read_csv(massey_path + \"NCAATourneySlots.csv\")\nseeds = pd.read_csv(massey_path + \"NCAATourneySeeds.csv\")\n\nyear = 2018\n\ntourney_slots = tourney_slots.loc[tourney_slots[\"Season\"] == year]\ntourney_slots[\"City\"] = tournament_cities\nseeds = seeds.loc[seeds[\"Season\"] == year]\n\n#Play in games\ngame1 = seeds.loc[seeds[\"Seed\"] == \"W11a\"]\nseeds.at[game1.index[0], \"Seed\"] = \"W11\"\ngame2 = seeds.loc[seeds[\"Seed\"] == \"W16b\"]\nseeds.at[game2.index[0], \"Seed\"] = \"W16\"\ngame3 = seeds.loc[seeds[\"Seed\"] == \"X11b\"]\nseeds.at[game3.index[0], \"Seed\"] = \"X11\"\ngame4 = seeds.loc[seeds[\"Seed\"] == \"Z16b\"]\nseeds.at[game4.index[0], \"Seed\"] = \"Z16\"\n\nrounds = [1, 2, 3, 4, 5, 6]\nslots = None\nwinners = {}\nfor r in rounds:\n    slots = tourney_slots.loc[tourney_slots[\"Slot\"].str.startswith(\"R{}\".format(r))]\n    print(\"ROUND {}\".format(r))\n    for _, row in slots.iterrows():\n        slot = row[\"Slot\"]\n        s_seed = row[\"StrongSeed\"]\n        w_seed = row[\"WeakSeed\"]\n        city = row[\"City\"]\n        \n        if slot not in winners:\n            winners[slot] = {}\n        \n        if r == 1:\n            s_team = seeds.loc[seeds[\"Seed\"] == s_seed]\n            w_team = seeds.loc[seeds[\"Seed\"] == w_seed]\n            s_team = s_team.iloc[0][\"TeamID\"]\n            w_team = w_team.iloc[0][\"TeamID\"]\n\n            s_name = team_names[s_team]\n            w_name = team_names[w_team]\n\n            s_seed_num = find_seed(year, s_team)\n            w_seed_num = find_seed(year, w_team)\n\n            s_coach = coach_experience(year, s_team)\n            w_coach = coach_experience(year, w_team)\n\n            s_rpi, s_pom = get_rankings(year, s_team)\n            w_rpi, w_pom = get_rankings(year, w_team)\n\n            s_distance = tournament_distance_matrix.loc[(tournament_distance_matrix[\"TeamID\"] == s_team)]\n            w_distance = tournament_distance_matrix.loc[(tournament_distance_matrix[\"TeamID\"] == w_team)]\n            s_distance = s_distance.iloc[0][city]\n            w_distance = w_distance.iloc[0][city]\n\n            s_last = last_ten(year, s_team)\n            w_last = last_ten(year, w_team)\n\n            s_reb, s_fga, s_fgpct, s_ftpct = get_stats(year, s_team)\n            w_reb, w_fga, w_fgpct, w_ftpct = get_stats(year, w_team)\n\n            game = np.array([[i for i in [r, s_seed_num, s_coach, s_distance, s_last, s_rpi, s_pom, s_reb, s_fga, s_fgpct, s_ftpct,\n                                     w_seed_num, w_coach, w_distance, w_last, w_rpi, w_pom, w_reb, w_fga, w_fgpct, w_ftpct]\n                             if i != -1]])\n        \n        else:\n            s_name = winners[s_seed][0]\n            w_name = winners[w_seed][0]\n            s_stuff = winners[s_seed][1]\n            w_stuff = winners[w_seed][1]\n            \n            game = np.array([[r] + s_stuff + w_stuff])\n\n        print(s_name)\n        print(w_name)\n        \n        result = sess.run([y], feed_dict={x: game})\n        result = result[0][0]\n        \n        if result[0] > result[1]:\n            print(\"\\t\", s_name)\n            winners[slot] = (s_name, [s_seed_num, s_coach, s_distance, s_last, s_rpi, s_pom, s_reb, s_fga, s_fgpct, s_ftpct])\n        else:\n            winners[slot] = (w_name, [w_seed_num, w_coach, w_distance, w_last, w_rpi, w_pom, w_reb, w_fga, w_fgpct, w_ftpct])\n            print(\"\\t\", w_name)\n        print()\n        \n","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"295016cd-2924-4242-82c7-c58e064ac392","_uuid":"588757129d5c143deafe4fd1813334b0fb4a1792","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}