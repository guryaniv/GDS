{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport glob\nimport matplotlib.pyplot \nimport cv2\nprint(os.listdir(\"../input\"))\nfrom keras.utils import to_categorical\nfrom keras.models import load_model\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"training_img = []\nlabel= []\n\nfor dir_path in glob.glob(\"../input/train/*\"):\n    image_label = dir_path.split(\"/\")[-1]\n    for image_path in glob.glob(os.path.join(dir_path,\"*.png\")):\n        #image= load_img(image_path)\n        #image = img_to_array(image)\n        #image = cv2.resize(image,(64,64))\n        image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n        image = cv2.resize(image,(64,64))\n        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n        training_img.append(image)\n        label.append(image_label)\ntraining_img=np.array(training_img)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7ed1f10a-625e-45a5-9237-2c86f5d03bf4","_uuid":"bc8079640f74b77ee794b80d813f23abb85b4820","collapsed":true,"trusted":true},"cell_type":"code","source":"\nlabel_to_id = {v:k for k,v in enumerate(np.unique(label))}\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"11188889-a999-43ba-949f-88e496917a18","_uuid":"452f1bd43adef5c785984db9011e62d7d9511b94","collapsed":true,"trusted":true},"cell_type":"code","source":"id_to_label = {v:k for k,v in label_to_id.items()}","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"77066ea0-c52c-4d13-a5bb-e7047b63a4bf","_uuid":"287149d8cf1426ba1555db60233320a65eb8fc75","trusted":true},"cell_type":"code","source":"id_to_label","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad9c1849-58da-422a-9b63-582d74b57541","_uuid":"26961b995f202a689ac3ff84500f886f70de4fac","collapsed":true,"trusted":true},"cell_type":"code","source":"training_label_id = np.array([label_to_id[x] for x in label])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e3112654-aab9-403e-b4af-38c6d8d9f804","_uuid":"9ffe33b372f74274429704edc1396a0fc1f1f2bf","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"Y = np.array(training_label_id)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47dc7ecb-3b67-4cc7-a3af-7cd8bc2e3c88","_uuid":"503b4b24bdcc929c316e1fdde1db86fbb20bc6ee","collapsed":true,"trusted":true},"cell_type":"code","source":"Y = to_categorical(Y,num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e42f483f-d6ae-4910-82e2-0003680443ce","_uuid":"13fa0e062a0562eda28fffc6952cf85ab1cd6537","trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers.core import Dense,Dropout,Activation\nfrom keras.layers import Conv2D\nfrom keras.layers.pooling import AveragePooling2D,GlobalAveragePooling2D\nfrom keras.layers import Input,Concatenate\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.regularizers import l2\nfrom keras.optimizers import RMSprop,Adamax\nimport keras.backend as K\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e62f7026-d960-4d0a-8bed-0ffc5cd1621e","_uuid":"89000d3c457f6dcad5b49a5959516f2f9f710fbd","trusted":true,"collapsed":true},"cell_type":"code","source":"def conv_layer(x,concat_axis,nb_filter,dropout_rate=None,weight_decay=1E-4):\n    x = BatchNormalization(axis=concat_axis,\n                          gamma_regularizer=l2(weight_decay),\n                          beta_regularizer=l2(weight_decay))(x)\n    x = Activation('relu')(x)\n    x = Conv2D(nb_filter,(3,3),padding='same',kernel_regularizer=l2(weight_decay),use_bias=False)(x)\n    if dropout_rate:\n        x = Dropout(dropout_rate)(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e8bb9de9-0bba-4430-8f6e-9e3eebe769da","_uuid":"5cbea0633a2f6a9f0ebd0973233e095acf5be174","trusted":true,"collapsed":true},"cell_type":"code","source":"def transition_layer(x,concat_axis,nb_filter,dropout_rate=None,weight_decay=1E-4):\n    x = BatchNormalization(axis=concat_axis,\n                          gamma_regularizer=l2(weight_decay),\n                          beta_regularizer=l2(weight_decay))(x)\n    x = Activation('relu')(x)\n    x = Conv2D(nb_filter,(1,1),padding='same',kernel_regularizer=l2(weight_decay),use_bias=False)(x)\n    if dropout_rate:\n        x = Dropout(dropout_rate)(x)\n    x = AveragePooling2D((2,2),strides=(2,2))(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0260e3f3-980a-4758-98f3-70dad59457aa","_uuid":"118de22fdbe3e6d59a2c18a2a6f6e0b006bf7667","collapsed":true,"trusted":true},"cell_type":"code","source":"def denseblock(x,concat_axis,nb_filter,nb_layers,growth_rate,dropout_rate=None,weight_decay=1E-4):\n    list_features = [x]\n    for i in range(nb_layers):\n        x = conv_layer(x,concat_axis,growth_rate,dropout_rate=None,weight_decay=1E-4)\n        list_features.append(x)\n        x = Concatenate(axis=concat_axis)(list_features)\n        nb_filter += growth_rate\n    return x,nb_filter","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d6473f4-498f-4eaf-8328-2ac00631364b","_uuid":"f6ab700a136f95899436731680143466f5be4bf3","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"def Densenet(nb_classes,img_dim,depth,nb_dense_block,nb_filter,growth_rate,\n             dropout_rate=None,weight_decay=1E-4):\n    if K.image_dim_ordering() == \"th\":\n        concat_axis = 1\n    elif K.image_dim_ordering() == \"tf\":\n        concat_axis = -1\n        \n    model_input = Input(shape=img_dim)\n    \n    assert (depth-4)%3  == 0 , \"Depth must be 4*N +3\"\n    \n    nb_layers = int((depth-4 )/ 3) \n    \n    x = Conv2D(nb_filter,(3,3),padding='same',use_bias=False,\n               kernel_regularizer=l2(weight_decay))(model_input)\n    \n    for block_id in range(nb_dense_block-1):\n        \n        x,nb_filter = denseblock(x,concat_axis,nb_filter,nb_layers,growth_rate,\n                                 dropout_rate=None,weight_decay=1E-4)\n        x = transition_layer(x,concat_axis,nb_filter,dropout_rate=None,weight_decay=1E-4)\n        \n    x = BatchNormalization(axis=concat_axis,\n                          gamma_regularizer=l2(weight_decay),\n                          beta_regularizer=l2(weight_decay))(x)\n    \n    x = Activation('relu')(x)\n    \n    x = GlobalAveragePooling2D(data_format=K.image_data_format())(x)\n    \n    x = Dense(nb_classes,activation='softmax',kernel_regularizer=l2(weight_decay),\n                            bias_regularizer=l2(weight_decay))(x)\n    densenet = Model(inputs=[model_input], outputs=[x], name=\"DenseNet\")\n    \n    return densenet\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eb0b82a4-e259-43ae-af92-c7cabf9c3918","_uuid":"95dd08312f172846e60a430cc6a7f912e704791a","trusted":true,"collapsed":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(training_img, Y, test_size = 0.05)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d0d67c8a-4aea-445c-91b4-68b8bec1e795","_uuid":"a3f4d5d297f16fa6e05b6e88bfada143ba673cef","trusted":true},"cell_type":"code","source":" model =         Densenet(nb_classes=12,\n                          img_dim=(64,64,3),\n                          depth = 34,\n                          nb_dense_block = 6,\n                          growth_rate=12,\n                          nb_filter=32,\n                          dropout_rate=0.25,\n                          weight_decay=1E-4)\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ae93be75-0275-4aea-99f4-1383f9e7df1c","_uuid":"7fca0350acf02afbc82549de6ad089dc97cab03b","trusted":true,"collapsed":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer = Adamax(),\n              metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5013d652-f6c9-4788-b0b8-21dc4715f971","_uuid":"b27189607d3e5cb6b33102d864a46776a102d9ef","trusted":true},"cell_type":"code","source":"model_filepath = 'model.h5'\nannealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\nlr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=1e-5, patience=2, verbose=1)\nmsave = ModelCheckpoint(model_filepath, save_best_only=True)\n#aug = ImageDataGenerator(rotation_range=180, width_shift_range=0.1, \\\n #   height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n  #  horizontal_flip=True, fill_mode=\"nearest\")\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c7ae2353-92b9-4a51-97d8-54ddf9308c38","_uuid":"7ec47607de25ff74ecd2c2695209288d22e9fb1d","trusted":true,"scrolled":true},"cell_type":"code","source":"model.fit(X_train ,Y_train, batch_size=64,\n               validation_data = (X_test,Y_test),\n               epochs = 30,\n               callbacks=[lr_reduce,annealer,msave],\n               verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c31a9d56-baab-4b61-9b2e-d9b8457419a8","_uuid":"d39e17fcc45ee061f08c1b3a1e24b09052126df3","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f752c098-166e-4df3-b427-d3ee38bba7f7","_uuid":"e1469cc3ff645052a6e8afa673a8371720311675","collapsed":true,"trusted":true},"cell_type":"code","source":"data = []\nfilenames = []\nimages = os.listdir(\"../input/test/\")\nfor imageFileName in images:\n        imageFullPath = os.path.join(\"../input/test/\", imageFileName)\n        img = load_img(imageFullPath)\n        arr = img_to_array(img) \n        arr = cv2.resize(arr, (64,64)) \n        data.append(arr)\n        filenames.append(imageFileName)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"99d0f62b-8467-4fe5-8362-79ecef896b24","_uuid":"a2e27478a1662d87dc15b835f1fbd9eb77e13bb8","trusted":true,"collapsed":true},"cell_type":"code","source":"test = np.array(data)\ntest_x = test.reshape(test.shape[0],64,64,3)\n\nmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc0e999c-d04b-486e-992e-cb2dc99e1b94","_uuid":"c6a2b763f410b936af63b3ca16a38d06dde58b2c","trusted":true,"collapsed":true},"cell_type":"code","source":"yFit = model.predict(test_x, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9322e875-400a-464d-bfd9-281a7f56cdfe","_uuid":"3e50b1c01be5b6f5b9478a9a74e9b755c55f3ebc","trusted":true,"collapsed":true},"cell_type":"code","source":"print(type(yFit)) \nprint(type(filenames)) ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34f04701-da6e-40ec-9757-564b288aa699","_uuid":"ba2bad13d506d68bd766d0ff14c23ea32f7415e5","trusted":true,"collapsed":true},"cell_type":"code","source":"import csv  \nwith open('output.csv', 'w', newline='') as csvfile:\n    fieldnames = ['file', 'species']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for index, file in enumerate(filenames):\n        classesProbs = yFit[index]\n        maxIdx = 0\n        maxProb = 0;\n        for idx in range(0,11):\n            if(classesProbs[idx] > maxProb):\n                maxIdx = idx\n                maxProb = classesProbs[idx]\n        writer.writerow({'file': file, 'species': id_to_label[maxIdx]})\nprint(\"Writing complete\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c8802833-6650-4383-89d7-b7a86b576131","_uuid":"5e29dcddf4a13ea4c43d521fda05b67fb90aa397","trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13f8b191eca3143f393045e27beb80453787f85b","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ac4076ece5802c86b91e6527aba529e501435504"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}