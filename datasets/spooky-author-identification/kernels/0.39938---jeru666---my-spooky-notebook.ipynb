{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.3", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "aee09a0f202507c9fae503758c411cee28c39bc5", "_cell_guid": "e7e8c5dd-6ae8-450a-82c2-b9061681d88b"}, "source": ["## Sneak peek into the data"], "cell_type": "markdown"}, {"metadata": {"_uuid": "7d0bbc8108a5087e358905407f52be396cec8fa6", "_cell_guid": "6ffa00a7-d833-4d26-96ca-8609003b21a6", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["glove_file = '../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt'"], "cell_type": "code"}, {"metadata": {"_uuid": "b0853e96fa195b8cf452dc5a7e4c8d97e0549cb5", "_cell_guid": "8f06437b-aed2-4f3b-8ee8-9623bbc0cbac", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["import numpy as np # linear algebra\n", "import pandas as pd# data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "df_train = pd.read_csv('../input/spooky-author-identification/train.csv')\n", "df_test = pd.read_csv('../input/spooky-author-identification/test.csv')\n", "df_sample = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n", "\n", "#df.dropna(axis=0)\n", "#df.set_index('id', inplace = True)\n", "\n", "df_sample.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "55d3b16ac4c718394c0722b525db498f7754e3b9", "_cell_guid": "b474d8fc-8a88-4a58-8ec1-396fba9d33be", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["df_test.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "3615eb91fbd93b7eaee74c18a0c928f54f0f23cb", "_cell_guid": "98b9dcac-3d5a-4944-a6ab-1f90ccda8e32", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["print(df_train.shape)\n", "print(df_test.shape)"], "cell_type": "code"}, {"metadata": {"_uuid": "47d31e5db08a001aca8c443ab534a9fc8f17fe30", "_cell_guid": "5087c98c-c938-4d4c-8fc5-da71685d7f16"}, "source": ["## NLP modelling!"], "cell_type": "markdown"}, {"metadata": {"_uuid": "7f2d0df15b768853113ba7c465c35ee1704b8cc0", "_cell_guid": "8302859a-db73-4561-aa17-69e067fb6982", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["import re\n", "from nltk.corpus import stopwords\n", "\n", "stopWords = set(stopwords.words('english'))"], "cell_type": "code"}, {"metadata": {"_uuid": "2ae890379177816f591b51a62b0e00dfedd17f7a", "_cell_guid": "0ac19c57-49c4-47ea-bd13-fa744887233e", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["len(df_train.columns)"], "cell_type": "code"}, {"metadata": {"_uuid": "ae918bef7291db2dc0bd89ffdc124875d80597c2", "_cell_guid": "c9237834-cb78-40e6-9f10-0d648e1f1861"}, "source": ["## Feature Engineering"], "cell_type": "markdown"}, {"metadata": {"_uuid": "419af00aa6e1b4247c2f82da258d61d96a4f992e", "_cell_guid": "ac3ec91d-c545-45a2-84fe-9e3e2839fa06", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#creating a function to encapsulate preprocessing, to mkae it easy to replicate on  submission data\n", "def processing(df):\n", "    #lowering and removing punctuation\n", "    df['processed'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]','', x.lower()))\n", "    \n", "    #numerical feature engineering\n", "    #total length of sentence\n", "    df['length'] = df['processed'].apply(lambda x: len(x))\n", "    \n", "    #get number of words\n", "    df['words'] = df['processed'].apply(lambda x: len(x.split(' ')))\n", "    \n", "    df['words_not_stopword'] = df['processed'].apply(lambda x: len([t for t in x.split(' ') if t not in stopWords]))\n", "    \n", "    # number of unique words\n", "    df[\"num_unique_words\"] = df[\"text\"].apply(lambda x: len(set(str(x).split())))\n", "    \n", "    # number of characters\n", "    df[\"num_chars\"] = df[\"text\"].apply(lambda x: len(str(x)))\n", "    \n", "    # nmber of punctuations\n", "    #df[\"num_punctuations\"] = df[\"text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n", "    \n", "    # number of upper case \n", "    df[\"num_words_upper\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n", "    \n", "    #number of titles characters\n", "    df[\"num_words_title\"] = df[\"text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n", "    \n", "    #get the average word length\n", "    df['avg_word_length'] = df['processed'].apply(lambda x: np.mean([len(t) for t in x.split(' ') if t not in stopWords]) if len([len(t) for t in x.split(' ') if t not in stopWords]) > 0 else 0)\n", "    \n", "    #get number of commas\n", "    df['commas'] = df['text'].apply(lambda x: x.count(','))\n", "\n", "    return(df)\n", "\n", "df_train = processing(df_train)\n", "\n", "df_train.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "bd8fe58935a2d6b7f37c8463292371773d538cb4", "_cell_guid": "29ace5cc-5cb6-48ef-a5ee-a3591dc2fc39"}, "source": ["## Pipelining"], "cell_type": "markdown"}, {"metadata": {"_uuid": "5b1efa096eec5cf3ea4d93687f057f793153baaf", "_cell_guid": "0aef98e7-be50-4567-9f57-84d253e0a288", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["df_train.columns"], "cell_type": "code"}, {"metadata": {"_uuid": "0274417d3ee78c298ab962b2f38323e1f4aff318", "_cell_guid": "77924c24-1796-4a0e-b932-f8f1dacc1fab", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "\n", "features= [c for c in df_train.columns.values if c  not in ['id','text','author']]\n", "numeric_features= [c for c in df_train.columns.values if c  not in ['id','text','author','processed']]\n", "target = 'author'\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train[target], test_size=0.40, random_state=42)\n", "X_train.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "bce70f7ea9cf41352c56a1263eb1d0ec0f858f31", "_cell_guid": "1df7d25f-7c8a-49db-8bf0-383b7d4472d9", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.base import BaseEstimator, TransformerMixin\n", "\n", "class TextSelector(BaseEstimator, TransformerMixin):\n", "    \"\"\"\n", "    Transformer to select a single column from the data frame to perform additional transformations on\n", "    Use on text columns in the data\n", "    \"\"\"\n", "    def __init__(self, key):\n", "        self.key = key\n", "\n", "    def fit(self, X, y=None):\n", "        return self\n", "\n", "    def transform(self, X):\n", "        return X[self.key]\n", "    \n", "class NumberSelector(BaseEstimator, TransformerMixin):\n", "    \"\"\"\n", "    Transformer to select a single column from the data frame to perform additional transformations on\n", "    Use on numeric columns in the data\n", "    \"\"\"\n", "    def __init__(self, key):\n", "        self.key = key\n", "\n", "    def fit(self, X, y=None):\n", "        return self\n", "\n", "    def transform(self, X):\n", "        return X[[self.key]]"], "cell_type": "code"}, {"metadata": {"_uuid": "f1772595dc088a1895e0b2800faf7d24ac133d3e", "_cell_guid": "aeed9aa7-a20d-459a-80bb-74705e24fdd9", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.pipeline import Pipeline\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "\n", "text = Pipeline([\n", "                ('selector', TextSelector(key='processed')),\n", "                ('tfidf', TfidfVectorizer( stop_words='english'))\n", "            ])\n", "\n", "text.fit_transform(X_train)"], "cell_type": "code"}, {"metadata": {"_uuid": "3468644c8b12fefb9852664700380c8e6790e932", "_cell_guid": "5c727563-838b-4102-8cc1-6e5cfc798c7c", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "\n", "length =  Pipeline([\n", "                ('selector', NumberSelector(key='length')),\n", "                ('standard', StandardScaler())\n", "            ])\n", "\n", "words =  Pipeline([\n", "                ('selector', NumberSelector(key='words')),\n", "                ('standard', StandardScaler())\n", "            ])\n", "\n", "words_not_stopword =  Pipeline([\n", "                ('selector', NumberSelector(key='words_not_stopword')),\n", "                ('standard', StandardScaler())\n", "            ])\n", "\n", "num_unique_words =  Pipeline([\n", "                ('selector', NumberSelector(key='num_unique_words')),\n", "                ('standard', StandardScaler()),\n", "            ])\n", "\n", "num_chars =  Pipeline([\n", "                ('selector', NumberSelector(key='num_chars')),\n", "                ('standard', StandardScaler()),\n", "            ])\n", "\n", "num_words_upper =  Pipeline([\n", "                ('selector', NumberSelector(key='num_words_upper')),\n", "                ('standard', StandardScaler()),\n", "            ])\n", "\n", "num_words_title =  Pipeline([\n", "                ('selector', NumberSelector(key='num_words_title')),\n", "                ('standard', StandardScaler()),\n", "            ])\n", "\n", "avg_word_length =  Pipeline([\n", "                ('selector', NumberSelector(key='avg_word_length')),\n", "                ('standard', StandardScaler())\n", "            ])\n", "\n", "commas =  Pipeline([\n", "                ('selector', NumberSelector(key='commas')),\n", "                ('standard', StandardScaler()),\n", "            ])"], "cell_type": "code"}, {"metadata": {"_uuid": "d8176c34d69d54bd411453f44ff732b87f3624f0", "_cell_guid": "e25f5313-dbb6-4c25-b12c-79c8f56d5f09", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.pipeline import FeatureUnion\n", "\n", "feats = FeatureUnion([('text', text), \n", "                      ('length', length),\n", "                      ('words', words),\n", "                      ('num_unique_words', num_unique_words),\n", "                      ('num_chars', num_chars),\n", "                      ('num_words_upper', num_words_upper),\n", "                      ('num_words_title', num_words_title),\n", "                      ('words_not_stopword', words_not_stopword),\n", "                      ('avg_word_length', avg_word_length),\n", "                      ('commas', commas)])\n", "\n", "feature_processing = Pipeline([('feats', feats)])\n", "feature_processing.fit_transform(X_train)"], "cell_type": "code"}, {"metadata": {"_uuid": "412ca6e0fe546c01464c0c89f9d01400f5ba0fbd", "_cell_guid": "e566019a-90f2-40f0-8485-7cf2d01e71c0"}, "source": ["## Random Forest"], "cell_type": "markdown"}, {"metadata": {"_uuid": "d632511136985b0bdc651a68995ba350f7bf2e17", "_cell_guid": "01815a9e-14c6-4480-98af-7a371b0a19b4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "pipeline = Pipeline([\n", "    ('features',feats),\n", "    ('classifier', RandomForestClassifier(random_state = 42)),\n", "])\n", "\n", "pipeline.fit(X_train, y_train)\n", "\n", "preds = pipeline.predict(X_test)\n", "np.mean(preds == y_test)\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "90e66c8d8e87948eb16e946c469447e524ec68ba", "_cell_guid": "b62a82d0-82ee-4aa8-83f5-512c3058d3e1"}, "source": ["## Gradient Boosting Classifier"], "cell_type": "markdown"}, {"metadata": {"_uuid": "1790458ae610077230892bd95031fabaa2f2777c", "_cell_guid": "cb2dc7fa-7871-42a7-88ef-5b2dabc7469d", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "\n", "gbpipeline = Pipeline([\n", "    ('features',feats),\n", "    ('gbclassifier', GradientBoostingClassifier(random_state = 42)),\n", "])\n", "\n", "gbpipeline.fit(X_train, y_train)\n", "\n", "preds = gbpipeline.predict(X_test)\n", "np.mean(preds == y_test)\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "cf3161449c5cc64dff54a5371e4d5eee8f7ad468", "_cell_guid": "584f742a-7b7f-4f09-9045-4ac78dcdd0c1"}, "source": ["## Crossvalidation"], "cell_type": "markdown"}, {"metadata": {"_uuid": "a112c5da6f8c4a196393e0f59cff3033ace38453", "_cell_guid": "82cdbcd7-c9ae-42d4-90a8-e3d07a7776a5", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["# pipeline.get_params().keys()"], "cell_type": "code"}, {"metadata": {"_uuid": "235d7311916469d15d786fb8ca9f114bc358e17e", "_cell_guid": "3b63a58a-5ae6-4f7f-afa5-00acbfa7187c", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["# gbpipeline.get_params().keys()"], "cell_type": "code"}, {"metadata": {"_uuid": "2f208433ea909774975a9f250749142340e03ee3", "_cell_guid": "7bfd8575-046b-41f8-a626-582e78846ffb", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "hyperparameters = { 'features__text__tfidf__max_df': [0.9],\n", "                    'features__text__tfidf__ngram_range': [(1,1)],\n", "                   'classifier__max_depth': [160, 170, 180],\n", "                    'classifier__min_samples_leaf': [4]\n", "                  }\n", "clf = GridSearchCV(pipeline, hyperparameters, cv=5)\n", " \n", "# Fit and tune model\n", "clf.fit(X_train, y_train)\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "c28d3eef26f38233d175cc8b495c8d2eec0cb7b8", "_cell_guid": "5aa40c34-621a-44ad-b94c-4b157261601d", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "from sklearn.model_selection import GridSearchCV\n", "\n", "gbhyperparameters = { 'features__text__tfidf__max_df': [0.9],\n", "                      'features__text__tfidf__ngram_range': [(1,1)],\n", "                      'gbclassifier__n_estimators': [50, 100, 150],\n", "                      'gbclassifier__min_samples_split': [2, 3], \n", "                      'gbclassifier__min_samples_leaf' : [2, 4]\n", "                  }\n", "gbclf = GridSearchCV(gbpipeline, gbhyperparameters, cv=5)\n", " \n", "# Fit and tune model\n", "gbclf.fit(X_train, y_train)\n", "'''\n"], "cell_type": "code"}, {"metadata": {"_uuid": "cc85edb90e22325bdf5613ccebe9038f639a5279", "_cell_guid": "9e9e5c71-fc10-4741-9bbc-f4bcdc21da66"}, "source": ["**Seeing the best parameters**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "02086f8ff06597181b0bc0cde87c696612d04675", "_cell_guid": "16b6befb-d9ee-4c79-aead-35a9c5987a61", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#clf.best_params_"], "cell_type": "code"}, {"metadata": {"_uuid": "0399ad841b660838c2cb69c73a7a60c0738aa961", "_cell_guid": "a765e7a0-f13f-4293-ac86-90b0cc9ac8e7", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["# gbclf.best_params_"], "cell_type": "code"}, {"metadata": {"_uuid": "324aa2dfd0814296985f49523ba5720a21db43bc", "_cell_guid": "e690bc0a-da81-4dff-bea8-8df17ef2ea6c", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "#refitting on entire training data using best settings\n", "clf.refit\n", "\n", "preds = clf.predict(X_test)\n", "probs = clf.predict_proba(X_test)\n", "\n", "np.mean(preds == y_test)\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "f19de79864d919083e795ac5bb434c5da78a85dc", "_cell_guid": "b957d029-15a3-4595-967b-6a3379679e85", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "#refitting on entire training data using best settings\n", "gbclf.refit\n", "\n", "preds = gbclf.predict(X_test)\n", "probs = gbclf.predict_proba(X_test)\n", "\n", "np.mean(preds == y_test)\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "926f727687c1b7e37a078d7a7fba4b62516d0223", "_cell_guid": "3d089063-1c05-4813-810a-d83686773b5e"}, "source": ["## Submission File"], "cell_type": "markdown"}, {"metadata": {"_uuid": "da262bccc3e6aeb88b78bbc4295c863a76eb1eab", "_cell_guid": "9233469f-68c1-4cd6-a2ba-1bed56970958", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "submission = pd.read_csv('../input/test.csv')\n", "\n", "#preprocessing\n", "submission = processing(submission)\n", "predictions = clf.predict_proba(submission)\n", "\n", "preds = pd.DataFrame(data=predictions, columns = clf.best_estimator_.named_steps['classifier'].classes_)\n", "\n", "#generating a submission file\n", "result = pd.concat([submission[['id']], preds], axis=1)\n", "#result.set_index('id', inplace = True)\n", "result.head()\n", "'''\n"], "cell_type": "code"}, {"metadata": {"_uuid": "8d8daaea5a7c0645e49e196c345bf14b4624ec16", "_cell_guid": "c78fa4ab-510a-43fe-b787-1318464132f4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#result.to_csv('random_forest.csv', index=False)"], "cell_type": "code"}, {"metadata": {"_uuid": "0c1d35626735b726a242a4ce5ee904e7dbe4e4b8", "_cell_guid": "71efb200-caa2-4bb4-8ae4-3b163b23eb40", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["''' \n", "submission = pd.read_csv('../input/test.csv')\n", "\n", "#preprocessing\n", "submission = processing(submission)\n", "predictions = gbclf.predict_proba(submission)\n", "\n", "preds = pd.DataFrame(data=predictions, columns = gbclf.best_estimator_.named_steps['classifier'].classes_)\n", "\n", "#generating a submission file\n", "result = pd.concat([submission[['id']], preds], axis=1)\n", "#result.set_index('id', inplace = True)\n", "result.head()\n", "\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "0f9fd1d5a3cc3d79bedc7574723236b7972a1c16", "_cell_guid": "6d58408a-adc2-457c-ac81-433b8b7dab29", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["# result.to_csv('gradient_boost.csv', index=False)"], "cell_type": "code"}, {"metadata": {"_uuid": "46065c58910c8c9b239b756176827ec22988de62", "_cell_guid": "2d708afd-a188-4a73-865f-9c2ee006ea9c"}, "source": ["## Naive Bayes"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8a2322ae13152059097517a9a96b69ed1d55dc00", "_cell_guid": "5ba85a30-bdd0-4896-aa02-1cea24fc1758", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["\n", "train_corpus = []\n", "for i in range(len(df_train)):\n", "    review = re.sub('[^a-zA-Z0-9]', ' ', df_train['text'][i])\n", "    review = review.lower()\n", "    review = review.split()\n", "    review = [word for word in review if not word in set(stopwords.words('english'))]\n", "    review = ' '.join(review)\n", "    train_corpus.append(review)\n", "\n", "test_corpus = []\n", "for i in range(len(df_test)):\n", "    review = re.sub('[^a-zA-Z0-9]', ' ', df_test['text'][i])\n", "    review = review.lower()\n", "    review = review.split()\n", "    review = [word for word in review if not word in set(stopwords.words('english'))]\n", "    review = ' '.join(review)\n", "    test_corpus.append(review)\n", "    \n", "X_Train = np.array(train_corpus)\n", "X_Test = np.array(test_corpus)\n", "y = df_train.iloc[:, 2].values    \n", "\n", "\n", "\n"], "cell_type": "code"}, {"metadata": {"_uuid": "89353c2ecce4465c3aa711ade4c9e7f008b83226", "_cell_guid": "ea9af525-75db-4988-bdb9-717752655f59"}, "source": ["## Stemming\n", "\n", "Replacing similar words like ran, run and running as the same word."], "cell_type": "markdown"}, {"metadata": {"_uuid": "51ff4ead1f45aaaf69def206194f9c462dbda550", "_cell_guid": "0e1d6277-71aa-492f-bf01-18f3b10bd830", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "import nltk.stem as stm # Import stem class from nltk\n", "    import re\n", "    stemmer = stm.PorterStemmer()\n", "\n", "    # Crazy one-liner code here...\n", "    # Explanation above...\n", "    df_train.text = df_train.text.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n", "    df_test.text = df_test.text.apply(lambda text: \" \".join([stemmer.stem(word) for word in text.split(\" \")]))\n", "'''"], "cell_type": "code"}, {"metadata": {"_uuid": "1b9f22ee8b75c1b4a0eed766e29294618526807b", "_cell_guid": "a6e0b463-dbee-4111-a7f8-db832750d01a", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["'''\n", "X_Train = pd.DataFrame(X_Train)\n", "X_Train.columns = ['text']\n", "\n", "X_Train.head()\n", "''' "], "cell_type": "code"}, {"metadata": {"_uuid": "75612ee79db90359a014f6b767d878bdc3ed4207", "_cell_guid": "ebfe3265-9edf-4976-86da-25136141df1f", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#''' \n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "\n", "classifier = Pipeline([('vect', CountVectorizer()),\n", "                      ('tfidf', TfidfTransformer()),\n", "                      ('clf', MultinomialNB()),\n", "                       #('clf', GradientBoostingClassifier(random_state = 42))\n", "])\n", "\n", "classifier.fit(X_Train, y)\n", "#'''"], "cell_type": "code"}, {"metadata": {"_uuid": "55cf1e3679cd98aea5df6f1f44020551ab4b3f73", "_cell_guid": "bb89ccac-f6a2-4f9a-bd99-48d7609f0366", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#'''\n", "from sklearn.model_selection import GridSearchCV\n", "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n", "              'tfidf__use_idf': (True, False),\n", "              'clf__alpha': (0.05, 1.0)\n", "              #'clf__min_samples_split': [2, 3]\n", "}\n", "\n", "gs_clf = GridSearchCV(classifier, parameters)\n", "gs_clf.fit(X_Train, y)\n", "#'''"], "cell_type": "code"}, {"metadata": {"_uuid": "26c5d9d5a7a37239b95ce0a04edf0e8d0ff3a297", "_cell_guid": "187e69f3-c689-462a-bb10-1a0e1b806bc1", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["gs_clf.best_params_"], "cell_type": "code"}, {"metadata": {"_uuid": "7e9bd432a4057eba5949def533380aff7b7156fe", "_cell_guid": "e60e6f11-af0a-4b03-9854-4179e06bd7e4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#'''\n", "\n", "\n", "gs_clf.refit\n", "\n", "\n", "\n", "# Predicting the Test set results\n", "y_pred_proba = gs_clf.predict_proba(X_Test)\n", "\n", "tdf = pd.DataFrame(y_pred_proba)\n", "tdf.columns = ['EAP', 'HPL', 'MWS']\n", "\n", "submission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n", "result = pd.concat([submission[['id']], tdf], axis=1)\n", "result.head()\n", "\n", "result.to_csv('naive_bayes_old.csv', index=False)\n", "#'''"], "cell_type": "code"}, {"metadata": {"_uuid": "f28281dd30befde2a2cad367a7e527c0743dcb0a", "_cell_guid": "3ff329de-3d54-4466-b99a-b8b699371949"}, "source": ["## NLP"], "cell_type": "markdown"}, {"metadata": {"_uuid": "8bad5ff9c847d274e16a873b7c370a6b29f3e043", "_cell_guid": "901b518f-662f-4240-bca8-cf1dd7457ed5", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["import xgboost as xgb\n", "from tqdm import tqdm\n", "from sklearn.svm import SVC\n", "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.naive_bayes import MultinomialNB\n", "\n", "from nltk.corpus import stopwords\n", "stop_words = stopwords.words('english')"], "cell_type": "code"}, {"metadata": {"_uuid": "4adcf613d37632f8fb1df1ef93f06ccb20a4d108", "_cell_guid": "ec61cf8a-f449-45e8-afab-719e3e087a2e", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["df_train.head()\n"], "cell_type": "code"}, {"metadata": {"_uuid": "626860d1383f98be4be723ceeb5ecd882bc041ac", "_cell_guid": "5a057d67-e3ef-4599-b4a8-2471664fb38f", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["df_test.head()"], "cell_type": "code"}, {"metadata": {"_uuid": "633f0dcf3c493d2a79decb4286145b596cca5b63", "_cell_guid": "91345a25-e22b-47bf-8536-8f48ca38d168", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["def multiclass_logloss(actual, predicted, eps=1e-15):\n", "    \"\"\"Multi class version of Logarithmic Loss metric.\n", "    :param actual: Array containing the actual target classes\n", "    :param predicted: Matrix with class predictions, one probability per class\n", "    \"\"\"\n", "    # Convert 'actual' to a binary array if it's not already:\n", "    if len(actual.shape) == 1:\n", "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n", "        for i, val in enumerate(actual):\n", "            actual2[i, val] = 1\n", "        actual = actual2\n", "\n", "    clip = np.clip(predicted, eps, 1 - eps)\n", "    rows = actual.shape[0]\n", "    vsota = np.sum(actual * np.log(clip))\n", "    return -1.0 / rows * vsota"], "cell_type": "code"}, {"metadata": {"_uuid": "fbc5cdbed611c77c167343b2e66d25087f5c3b0c", "_cell_guid": "6e333ac8-ac0b-4250-84ca-b32403a34409", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["lbl_enc = preprocessing.LabelEncoder()\n", "y = lbl_enc.fit_transform(df_train.author.values)\n", "y"], "cell_type": "code"}, {"metadata": {"_uuid": "f91a900a8f7c742594ad48b8aa30e4432d3093b6", "_cell_guid": "c19761a9-62a7-45b6-bde3-95fa03a4eda4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["xtrain, xvalid, ytrain, yvalid = train_test_split(df_train.text.values, y, \n", "                                                  stratify = y, \n", "                                                  random_state = 42, \n", "                                                  test_size = 0.1, shuffle = True)"], "cell_type": "code"}, {"metadata": {"_uuid": "f564c1ccd1ee4caac592cc48af8236e360ac2de0", "_cell_guid": "05f4534f-d6a6-4c2a-a6bd-ca90974c2d6e", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["type(xvalid)"], "cell_type": "code"}, {"metadata": {"_uuid": "0424099e621fc6dcf29f7083a0a3d8685db94aa4", "_cell_guid": "d2c8394c-37e8-45c0-adc6-7228b99f1f7c", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["type(xtrain)"], "cell_type": "code"}, {"metadata": {"_uuid": "ab8da977c736be40e9cbae629c2934919e0148d3", "_cell_guid": "8f6fee09-432c-41af-8a24-20bc420700c4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["xtrain"], "cell_type": "code"}, {"metadata": {"_uuid": "a0dfad651cad9236a2c7f20f8349417caf39cb19", "_cell_guid": "a653d50b-6fb1-4974-908d-b6341622e543", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["print('Train and output {} & {}'.format( xtrain.shape, ytrain.shape))"], "cell_type": "code"}, {"metadata": {"_uuid": "b7cb0d843cfb3b63a1cf5d4f467a3927c570682b", "_cell_guid": "f3975a91-45e3-4db8-864d-d1d4df7cfe93", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["print('Validation and output {} & {}'.format( xvalid.shape, yvalid.shape))"], "cell_type": "code"}, {"metadata": {"_uuid": "77c4f29ab349ce56c6261c7b3975426b03eb14ae", "_cell_guid": "c92e2cf8-12a4-4284-b12a-3beba4e5196f"}, "source": ["## **TF-IDF followed by Logistic Regression**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "73e9a270b27fd9fd5d6d5a9963e70de18ad5702b", "_cell_guid": "9256a331-9eaa-471d-847e-f8acb344c0b6", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["tfv = TfidfVectorizer(min_df=3,  max_features=None, \n", "            strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}',\n", "            ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1,\n", "            stop_words = 'english')\n", "\n", "tfv"], "cell_type": "code"}, {"metadata": {"_uuid": "96c56d452beb5132e23f14154b3c7d68277b4cce", "_cell_guid": "90aacca0-ae9d-4773-9d79-f5c9c6f72627", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["tfv.fit(list(xtrain) + list(xvalid))\n", "xtrain_tfv =  tfv.transform(xtrain) \n", "xvalid_tfv = tfv.transform(xvalid)\n", "\n", "xvalid_tfv.shape"], "cell_type": "code"}, {"metadata": {"_uuid": "c29474577e46f56cc3b54e7299011dafa45565e2", "_cell_guid": "b56db9d3-5697-4bdc-8404-d172a0a478ca", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["clf = LogisticRegression(C=1.0)\n", "clf.fit(xtrain_tfv, ytrain)\n", "predictions = clf.predict_proba(xvalid_tfv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "483bdf95efbc1d6e5fe289e2a0842b14bb9a90ab", "_cell_guid": "3f1606ec-4eb7-44c0-8a11-2135e8209a62", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_predictions = clf.predict_proba(xvalid_tfv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "46a6f334afae2ca1f9b5661642013301e0422eeb", "_cell_guid": "0c255edf-f7b7-4948-887a-43e732d1d48a", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_tfv =  tfv.transform(df_test['text']) "], "cell_type": "code"}, {"metadata": {"_uuid": "2615ef95a2bafc52f7c6577783e70495f2b561f4", "_cell_guid": "104d44dc-8077-40ac-8be1-31f45f40bc73", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_predictions = clf.predict_proba(test_tfv)\n", "test_predictions.shape"], "cell_type": "code"}, {"metadata": {"_uuid": "2e70fa63046da4ef6cf3a2971750a8d494bf922f", "_cell_guid": "a1725664-b6e0-4981-9ace-fb2fdec9df71", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["tdf = pd.DataFrame(test_predictions)\n", "tdf.columns = ['EAP', 'HPL', 'MWS']\n", "\n", "submission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n", "result = pd.concat([submission[['id']], tdf], axis=1)\n", "result.head()\n", "\n", "result.to_csv('naive_tf_idf.csv', index=False)"], "cell_type": "code"}, {"metadata": {"_uuid": "ea5915f7cf444537261c4fe4d54a229532cbf066", "_cell_guid": "94ab12b1-d87c-4e46-b18b-e5aa5bafd96a"}, "source": ["## **Count Vectorizer**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "d2bfcfb484ddfeb03624b30a50bbdc04ae6cb6f6", "_cell_guid": "b34f6e64-b7dd-487a-a81c-08eb1c683fc9", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["ctv = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',\n", "            ngram_range=(1, 3), stop_words = 'english')\n", "\n", "# Fitting Count Vectorizer to both training and test sets (semi-supervised learning)\n", "ctv.fit(list(xtrain) + list(xvalid))\n", "xtrain_ctv =  ctv.transform(xtrain) \n", "xvalid_ctv = ctv.transform(xvalid)\n"], "cell_type": "code"}, {"metadata": {"_uuid": "a4de355381ce884c25c87a9e983a903fa929f414", "_cell_guid": "d34c53e5-a324-40d2-a9a7-8cade61be4d4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["clf = LogisticRegression(C=1.0)\n", "clf.fit(xtrain_ctv, ytrain)\n", "predictions = clf.predict_proba(xvalid_ctv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "97c0bc9cb6ab5bfb147cdd75cf74411716977df3", "_cell_guid": "4d8c3655-b1ac-493d-99f8-bcc5862cce65", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_predictions = clf.predict_proba(xvalid_ctv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "5d9f580dbf7adac0e2ae47d156dc8a40c695e97d", "_cell_guid": "9a7cb920-56c9-470c-86d5-3d363635f31f", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_ctv =  ctv.transform(df_test['text']) "], "cell_type": "code"}, {"metadata": {"_uuid": "b33d26d45ec55305c0180222528721226ec6e946", "_cell_guid": "adda992d-e2ab-4097-89e5-868df9e09f28", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["test_predictions = clf.predict_proba(test_ctv)\n", "test_predictions.shape"], "cell_type": "code"}, {"metadata": {"_uuid": "f34a186f09213f67dceba372f5f1e7bfa393d7ae", "_cell_guid": "50919fc5-bea4-4cef-9187-e22932141bbf", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["tdf = pd.DataFrame(test_predictions)\n", "tdf.columns = ['EAP', 'HPL', 'MWS']\n", "\n", "submission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n", "result = pd.concat([submission[['id']], tdf], axis=1)\n", "result.head()\n", "\n", "result.to_csv('naive_ctv.csv', index=False)"], "cell_type": "code"}, {"metadata": {"_uuid": "ad0243ce83919130a5b1e0cedf6ab9e5b0e70e12", "_cell_guid": "5e2b03e5-c91a-459d-b712-93bf58efff42"}, "source": ["## **Naive Bayes 2 **\n", "\n", "### **NB on tf-idf**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "ffedc207a0d684fe9b41af2ab73a4f03144a7a34", "_cell_guid": "d8a65269-97e4-4e8e-a900-9e0b99f36455", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["clf = MultinomialNB()\n", "clf.fit(xtrain_tfv, ytrain)\n", "predictions = clf.predict_proba(xvalid_tfv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "d40847949361738407ef8ef244d987a3bda06d82", "_cell_guid": "f310c232-c2f9-49b8-9241-726ec881b1e3"}, "source": ["### **NB on count vectorizer**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "6b653b0e70be05c92740bcbe0341cbf2db736b31", "_cell_guid": "8e075241-01b4-4821-a0cf-9d4cca5973db", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["clf = MultinomialNB()\n", "clf.fit(xtrain_ctv, ytrain)\n", "predictions = clf.predict_proba(xvalid_ctv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "a99d26be65a90da41bbefc01c884dcd895d5fc44", "_cell_guid": "2e6f9fd8-bd76-4acf-b11d-e3b8ed60e950", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "\n", "classifier = Pipeline([('vect', CountVectorizer()),\n", "                      ('tfidf', TfidfTransformer()),\n", "                      ('clf', MultinomialNB()),\n", "                       #('clf', GradientBoostingClassifier(random_state = 42))\n", "])\n", "\n", "classifier.fit(xvalid, yvalid)\n", "\n"], "cell_type": "code"}, {"metadata": {"_uuid": "4b4c19414b5215b2f2a3e3df3502de1efd27def5", "_cell_guid": "9c37a0d8-5e2b-4e0a-92dc-fe330230e204", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from sklearn.model_selection import GridSearchCV\n", "\n", "parameters = {'vect__ngram_range': [(1, 1)],\n", "              'tfidf__use_idf': [True],\n", "              'clf__alpha': ( 0.05, 0.01)\n", "              #'clf__min_samples_split': [2, 3]\n", "             }               \n", "\n", "\n", "'''parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n", "              'tfidf__use_idf': (True, False),\n", "              'clf__alpha': (0.5, 1.0)\n", "              #'clf__min_samples_split': [2, 3]\n", "             } '''\n", "\n", "gs_clf = GridSearchCV(classifier, parameters)\n", "gs_clf.fit(xtrain, ytrain)"], "cell_type": "code"}, {"metadata": {"_uuid": "02ef15089131b6085e9db83613b5e64de7a22845", "_cell_guid": "42c70cf2-92f0-4961-8586-b277e13430e2", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["gs_clf.best_params_"], "cell_type": "code"}, {"metadata": {"_uuid": "ace2b8109e8b09c1cd6a5b3473e0718c7b0a3e51", "_cell_guid": "306f3125-6473-45ed-9231-3fc7ae8476a4", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["\n", "\n", "gs_clf.refit\n", "\n", "gs_clf.fit(xtrain, ytrain)\n", "\n", "# Predicting the validation set results\n", "y_pred_valid = gs_clf.predict_proba(xvalid)\n", "\n", "#predictions = clf.predict_proba(xvalid_ctv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(y_pred_valid, predictions))\n", "\n", "y_pred_valid_f1 = gs_clf.predict(xvalid)\n", "\n", "from sklearn.metrics import classification_report\n", "print (classification_report(yvalid, y_pred_valid_f1))\n", "\n", "# Predicting the Test set results\n", "y_pred_proba = gs_clf.predict_proba(X_Test)\n", "\n", "tdf = pd.DataFrame(y_pred_proba)\n", "tdf.columns = ['EAP', 'HPL', 'MWS']\n", "\n", "submission = pd.read_csv('../input/spooky-author-identification/sample_submission.csv')\n", "result = pd.concat([submission[['id']], tdf], axis=1)\n", "result.head()\n", "\n", "result.to_csv('naive_bayes__2.csv', index=False)"], "cell_type": "code"}, {"metadata": {"_uuid": "4a4f0e1264b6e9dc49a5d6ba95e3df9b2a29fa88", "_cell_guid": "a49e2df4-40de-4b62-8ffb-ee7379b2e5a8"}, "source": ["### **Word Vectors**"], "cell_type": "markdown"}, {"metadata": {"_uuid": "74cdd0b86a127342dee5c9981c30e855032dd75d", "_cell_guid": "976a2c0a-0066-4901-8f91-d164b8f94fab", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["from nltk import word_tokenize\n", "\n", "embeddings_index = {}\n", "f = open(glove_file)\n", "for line in tqdm(f):\n", "    values = line.split()\n", "    word = values[0]\n", "    coefs = np.asarray(values[1:], dtype='float32')\n", "    embeddings_index[word] = coefs\n", "f.close()\n", "\n", "print('Found %s word vectors.' % len(embeddings_index))"], "cell_type": "code"}, {"metadata": {"_uuid": "4990ee20dce3788152700ed92531372f7deab726", "_cell_guid": "c002aee1-e4a0-4e85-9e62-bd521739b899", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["# this function creates a normalized vector for the whole sentence\n", "def sent2vec(s):\n", "    #words = str(s).lower().decode('utf-8')\n", "    words = str(s).lower()\n", "    words = word_tokenize(words)\n", "    words = [w for w in words if not w in stop_words]\n", "    words = [w for w in words if w.isalpha()]\n", "    M = []\n", "    for w in words:\n", "        try:\n", "            M.append(embeddings_index[w])\n", "        except:\n", "            continue\n", "    M = np.array(M)\n", "    v = M.sum(axis=0)\n", "    if type(v) != np.ndarray:\n", "        return np.zeros(300)\n", "    return v / np.sqrt((v ** 2).sum())"], "cell_type": "code"}, {"metadata": {"_uuid": "b9a6265b16af35bc5dd4bab343777919806c3656", "_cell_guid": "526e620c-ebf3-40a9-a64e-bddbead46b83", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["xtrain_glove = [sent2vec(x) for x in tqdm(xtrain)]\n", "xvalid_glove = [sent2vec(x) for x in tqdm(xvalid)]\n", "\n", "type(xtrain_glove)\n", "len(xvalid_glove[1])\n", "xvalid_glove[0].shape"], "cell_type": "code"}, {"metadata": {"_uuid": "e8a61d9b5c4a3d3787ef4285360b696c1e737f91", "_cell_guid": "638c4c0c-85c9-4be5-a742-afac0fcc6a5c", "collapsed": true}, "execution_count": null, "outputs": [], "source": [], "cell_type": "code"}, {"metadata": {"_uuid": "e8ef0ba4339e09e5fbbe2f24470d396df65437be", "_cell_guid": "e9a13c4d-95f1-42bd-a226-ca3f7065e16d", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["xtrain_glove1 = np.array(xtrain_glove)\n", "xvalid_glove1 = np.array(xvalid_glove)\n", "\n", "xvalid_glove1.shape\n", "\n", "xvalid_glove1.reshape(1, -1)\n", "xvalid_glove1.shape"], "cell_type": "code"}, {"metadata": {"_uuid": "2937147ece40c070f5cce58a6c348f47ed1e8811", "_cell_guid": "182079f4-7835-4627-8807-96874f1b75d3", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["xtrain_glove.shape"], "cell_type": "code"}, {"metadata": {"_uuid": "a35d54ae461f1c3f8a01173012c7350f5ab55ebc", "_cell_guid": "4ab39d35-5d8b-41e0-9bef-db67b7516371", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["#clf = xgb.XGBClassifier(nthread=10, silent=False)\n", "clf = MultinomialNB()\n", "\n", "#clf.fit(xtrain_glove[0], ytrain)\n", "#predictions = clf.predict_proba(xvalid_glove[0])\n", "\n", "clf.fit(xtrain_glove1, ytrain)\n", "predictions = clf.predict_proba(xvalid_glove1)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "3add749f80b119a6730b036467ef9ba29ef035c1", "_cell_guid": "5c004a9a-f0f5-4579-8849-0d9f82a2c01f", "collapsed": true}, "execution_count": null, "outputs": [], "source": ["\n", "clf.fit(xtrain_ctv, ytrain)\n", "predictions = clf.predict_proba(xvalid_ctv)\n", "\n", "print (\"logloss: %0.3f \" % multiclass_logloss(yvalid, predictions))"], "cell_type": "code"}, {"metadata": {"_uuid": "38a6a88508a05c5df1129b5df607dc7b798d692a", "_cell_guid": "66b6300d-db4b-4e20-a2c3-2cfe8f411fee", "collapsed": true}, "execution_count": null, "outputs": [], "source": [], "cell_type": "code"}, {"metadata": {"_uuid": "44df0d9c23135729594450e5059961b5bf630280", "_cell_guid": "fc0a4e07-ecef-4121-97cd-3e10a9faffe3", "collapsed": true}, "execution_count": null, "outputs": [], "source": [], "cell_type": "code"}], "nbformat": 4}