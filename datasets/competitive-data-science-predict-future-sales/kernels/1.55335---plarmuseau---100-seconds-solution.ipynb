{"cells":[{"metadata":{"_cell_guid":"953275d8-c751-4a44-a2c7-903211676e87","_uuid":"504ae0070a0402f176f0f9764124607d7b644263"},"cell_type":"markdown","source":"Read data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\n\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\n\nimport os\nprint(os.listdir(\"../input\"))\n# Import all of them \nsales=pd.read_csv(\"../input/sales_train.csv\")\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nitem_cat=pd.read_csv(\"../input/item_categories.csv\")\nitem=pd.read_csv(\"../input/items.csv\")\nsub=pd.read_csv(\"../input/sample_submission.csv\")\nshops=pd.read_csv(\"../input/shops.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\nshops.describe().T","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"f3a03178-4d66-4bec-8e10-9878a3b6cb5a","_uuid":"6ceb76aaea661140711e1073f369ba24aad0f4db","collapsed":true,"trusted":true},"cell_type":"code","source":"N_SESSIONS = 34","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"e5ce6d19-ddca-49ce-a511-4117299845de","_uuid":"422c9136b5c853e2ffd04350907c03a90fc4efa2","trusted":true},"cell_type":"code","source":"# Now we convert the raw sales data to monthly sales, broken out by item & shop\nsales_piv= sales.pivot_table(index=['item_id','shop_id'], columns='date_block_num',values='item_cnt_day',aggfunc=np.sum,fill_value=0).reset_index()\nsales_piv.head()","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"c1493abe-5edc-4d6e-bfcf-cf8d56944f14","_uuid":"6c5bc4d56b74cee2079f01f3b3a39682210ebaac","trusted":true},"cell_type":"code","source":"# Merge the monthly sales data to the test data\nTest=pd.merge(test, item, how='inner', on='item_id')\nTest = pd.merge(Test, sales_piv, on=['item_id','shop_id'], how='left').fillna(0)\n#add category\nTestcat=Test['item_category_id']\nTest = Test.drop(labels=['ID', 'shop_id', 'item_id','item_name','item_category_id'], axis=1).T\n# times series ARIMA\nTtrain=Test.append(Test.diff(1).dropna())\nTtrain=Ttrain.append(pd.rolling_mean(Test,12)).dropna()\n\n\nTtrain=Ttrain.T\n#cluster in 9 groups\nfrom sklearn.cluster import KMeans\nclu=KMeans(n_clusters=9)\nTtrain['clu']=clu.fit_predict(Ttrain)\nTtrain['cat']=Testcat\n\nTtrain","execution_count":63,"outputs":[]},{"metadata":{"_cell_guid":"c74b6aff-83a4-4503-8aad-4c3d14d83282","_uuid":"d7ee3e6e3fced5dc3a090d5870465b9c71ab3aa7","collapsed":true,"trusted":true},"cell_type":"code","source":"ALPHA = 0.5\nBETA = 0.0\n\ndef create_filtered_prediction(train_ts, alpha, beta):\n    train_time_filtered_ts = np.zeros((train_ts.shape[0], N_SESSIONS), dtype=np.float)\n    train_time_filtered_ts[0, :] = train_ts[0, :N_SESSIONS]\n    train_memontum_ts = np.zeros((train_ts.shape[0], N_SESSIONS), dtype=np.float)\n    prediction_ts = np.zeros((train_ts.shape[0], N_SESSIONS+1), dtype=np.float)\n    for i in range(1, N_SESSIONS):\n        train_time_filtered_ts[:, i] = (1-alpha) * (train_time_filtered_ts[:, i-1] + \\\n                                                    train_memontum_ts[:, i-1]) + alpha * train_ts[:, i]\n        train_memontum_ts[:, i] = (1-beta) * train_memontum_ts[:, i-1] + \\\n                                  beta * (train_time_filtered_ts[:, i] - train_time_filtered_ts[:, i-1])\n        prediction_ts[:, i+1] = train_time_filtered_ts[:, i] + train_memontum_ts[:, i]\n    return prediction_ts\n\n#predictions = create_filtered_prediction(Ttrain.values, ALPHA, BETA)","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"bc7df068-1317-45c1-8009-b4d76d5d0fc4","_uuid":"974f48b0090b5fe582f54be58cc2ecce0ac10226","trusted":true},"cell_type":"code","source":"N_SESSIONS=32\nmonth=33\ndef rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())\nprint(Ttrain.shape)\nyo=Ttrain.iloc[:,month]\nyo.colomns=[month,'di','ma']\n#print(yo)\nfor Ai in range(28,29,1):\n    for Bi in range(59,61,1):\n        BETA=Bi/100\n        ALPHA=Ai/100\n        p= create_filtered_prediction(Ttrain.values, ALPHA, BETA)\n        print(p[:,N_SESSIONS])\n        error = rmse(yo[month], p[:,N_SESSIONS])\n        print('alpha %d beta %d month %d - Error %.2f' % (Ai,Bi,N_SESSIONS, error) )\n          \n#predictions","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84693eacc78b5bdcfad778f212e3fc4a5ff67ced"},"cell_type":"code","source":"        N_SESSIONS=33\n        p= create_filtered_prediction(Ttrain.values, 0.27, 0.63)\n        print(p[:,33])\n        error = rmse(yo[month], p[:,33])\n        print('alpha %d beta %d month %d - Error %.2f' % (Ai,Bi,33, error) )\n        N_SESSIONS=33\n        p= create_filtered_prediction(Ttrain.values, 0.5, 0.0)\n        print(p[:,33])\n        error = rmse(yo[month], p[:,33])\n        print('alpha %d beta %d month %d - Error %.2f' % (Ai,Bi,33, error) )","execution_count":66,"outputs":[]},{"metadata":{"_cell_guid":"4bfbe69b-667b-488e-b68b-5d4791be579b","_uuid":"0688debcec78b20d69d26f9d2fcb246a0bb3b517","collapsed":true,"trusted":true},"cell_type":"code","source":"sub[\"item_cnt_month\"] = np.clip(p[:, N_SESSIONS], 0, 20)\nsub.to_csv(\"submitalpha25bet057.csv\",index=False)\n                  #.format(ALPHA))","execution_count":68,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}