{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"97ff7f5e-de74-4a7c-b034-bcf1432480f2","_uuid":"2dd003abe546efb14933e446b6854697ac10dfca"},"cell_type":"markdown","source":"## Create training and test sets"},{"metadata":{"_cell_guid":"deb3ac11-c600-48dc-b9d7-2b31d802caab","_uuid":"6ed50a5c0665dc88ac7a6d0c8f4f9c57187fd2e6","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# First we create a dataframe with the raw sales data, which we'll reformat later\nDATA = '../input/'\nsales = pd.read_csv(DATA+'sales_train.csv', parse_dates=['date'], infer_datetime_format=True, dayfirst=True)\nsales.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e64d8618-78fd-41cf-8361-c12f35ee75db","_uuid":"9069d629e7479bdae511d9f7303762b8fa85a2c1","trusted":true,"collapsed":true},"cell_type":"code","source":"# Let's also get the test data\ntest = pd.read_csv(DATA+'test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d55fc349-4a95-4d4a-8aaf-827d57bce777","_uuid":"6b3e74f88c77bf2e0eb76f00482fce1cf70b3b64","trusted":true,"collapsed":true},"cell_type":"code","source":"# Now we convert the raw sales data to monthly sales, broken out by item & shop\n# This placeholder dataframe will be used later to create the actual training set\ndf = sales.groupby([sales.date.apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).sum().reset_index()\ndf = df[['date','item_id','shop_id','item_cnt_day']]\ndf = df.pivot_table(index=['item_id','shop_id'], columns='date',values='item_cnt_day',fill_value=0).reset_index()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"910d25e3-8401-4815-8248-043d44139e13","_uuid":"8983b18b147317811bd7d1ceeec0b1502caab8ce","trusted":true,"collapsed":true},"cell_type":"code","source":"# Merge the monthly sales data to the test data\n# This placeholder dataframe now looks similar in format to our training data\ndf_test = pd.merge(test, df, on=['item_id','shop_id'], how='left')\ndf_test = df_test.fillna(0)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2565c11e-6b3a-4268-becd-5cab11fee861","_uuid":"303707b5b9d2c54fc771ecaae2117ce1b33d067c","scrolled":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"# Remove the categorical data from our test data, we're not using it\ndf_test = df_test.drop(labels=['ID', 'shop_id', 'item_id'], axis=1)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fde5595e-0cf6-4620-87e2-6031ba8ea68d","_uuid":"005d1e880ce7bea66471a7fb0e67d051cc133550","trusted":true,"collapsed":true},"cell_type":"code","source":"# Now we finally create the actual training set\n# Let's use the '2015-10' sales column as the target to predict\nTARGET = '2015-10'\ny_train = df_test[TARGET]\nX_train = df_test.drop(labels=[TARGET], axis=1)\n\nprint(y_train.shape)\nprint(X_train.shape)\nX_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fe54e321-f3d2-4217-a396-4416285ff1ff","_uuid":"846ff06038a2cf228b383d3c3c75989ae3a726be","trusted":true,"collapsed":true},"cell_type":"code","source":"# To make the training set friendly for keras, we convert it to a numpy matrix\n# X_train = X_train.as_matrix()\n# X_train = X_train.reshape((214200, 33, 1))\n\n# y_train = y_train.as_matrix()\n# y_train = y_train.reshape(214200, 1)\n\nprint(y_train.shape)\nprint(X_train.shape)\n\n# X_train[:1]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d7e744b1-4707-4df7-b8b4-4c2b92b0856b","_uuid":"2214c539e1f1348b9fb5e903df514434c0e4191e","trusted":true,"collapsed":true},"cell_type":"code","source":"# Lastly we create the test set by converting the test data to a numpy matrix\n# We drop the first month so that our trained LSTM can output predictions beyond the known time range\nX_test = df_test.drop(labels=['2013-01'],axis=1)\n# X_test = X_test.as_matrix()\n# X_test = X_test.reshape((214200, 33, 1))\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e8ac0b5c-09f3-4bf1-8ceb-8f54fb81f9a3","_uuid":"2c9ac0c8f0f2ba3bf312c5fc6224facce415402e"},"cell_type":"markdown","source":"## Build and Train the model"},{"metadata":{"_cell_guid":"d59a768d-c77d-44b4-9d48-14a752962b91","_uuid":"512b649b54d56cad4651e57083735121808bc459","trusted":true,"collapsed":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6c3898a6-e583-4426-a2bd-27b40e33f0c5","_uuid":"37595bce4deffcd88c38c5eef6e0678a5eadbef8","trusted":true,"collapsed":true},"cell_type":"code","source":"model=LGBMRegressor(\n        n_estimators=200,\n        learning_rate=0.03,\n        num_leaves=32,\n        colsample_bytree=0.9497036,\n        subsample=0.8715623,\n        max_depth=8,\n        reg_alpha=0.04,\n        reg_lambda=0.073,\n        min_split_gain=0.0222415,\n        min_child_weight=40)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"08d56185-5f4e-44d0-8802-8eddac643569","_uuid":"51b1a7acdbd3ceb2fef16d24385778ed1d68e4ed","trusted":true,"collapsed":true},"cell_type":"code","source":"print('Training time, it is...')\nmodel.fit(X_train, y_train,\n          \n         )","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4e4c11ad-2a76-4ced-bfff-a24e8ba5ab5c","_uuid":"272b8e352e7c606b1cc3da4f1b12dd2b1c0e4f62"},"cell_type":"markdown","source":"## Get test set predictions and Create submission"},{"metadata":{"_cell_guid":"71f93b2d-f548-4362-a04d-0f5923eabd06","_uuid":"b801abe918b33a85f55f040235c94dbbadb8d045","collapsed":true,"trusted":true},"cell_type":"code","source":"# Get the test set predictions and clip values to the specified range\ny_pred = model.predict(X_test).clip(0., 20.)\n\n# Create the submission file and submit!\npreds = pd.DataFrame(y_pred, columns=['item_cnt_month'])\npreds.to_csv('submission.csv',index_label='ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6eeed9ca595753c75fee93a07e5fcd9ae000450a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}