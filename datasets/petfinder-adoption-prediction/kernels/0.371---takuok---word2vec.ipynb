{"cells":[{"metadata":{"_uuid":"eee90a36c89d605197d052ca5911977f01afface"},"cell_type":"markdown","source":"## Based almost entirealy on Abishek's and Bluefool's kernels. For no ther reason than to annoy them. No original contribution whatsoever. Peter Hurford also did some stuff, but it's not worth even trolling. You are welcome. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\n\nimport scipy as sp\nimport pandas as pd\nimport numpy as np\n\nfrom functools import partial\nfrom math import sqrt\n\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\n\nfrom collections import Counter\nfrom os.path import join\n\nimport nltk\nimport string\nfrom gensim.models import word2vec\nfrom tqdm import tqdm\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom nltk.corpus import stopwords\n\nimport lightgbm as lgb\nnp.random.seed(369)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6c8bf111a00c2cc08de860ac6fca8deb14e3904"},"cell_type":"code","source":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99c49163eddbcc3f376888d039238585714f8c4"},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29e3f3de63719f040e3b7445f4803b4f590b2590"},"cell_type":"code","source":"def rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aa3e9d25751e8e8b138f99b9f63dab57c6a35f8"},"cell_type":"code","source":"def get_sentiment(ids, path):\n    dic = {\n        \"doc_sent_mag\": [],\n        \"doc_sent_score\": []\n    }\n    for pet in ids:\n        try:\n            with open(path + pet + '.json', 'r') as f:\n                sentiment = json.load(f)\n            dic[\"doc_sent_mag\"].append(sentiment['documentSentiment']['magnitude'])\n            dic[\"doc_sent_score\"].append(sentiment['documentSentiment']['score'])\n        except FileNotFoundError:\n            dic[\"doc_sent_mag\"].append(np.nan)\n            dic[\"doc_sent_score\"].append(np.nan)\n    return dic\n\ndef get_meta(ids, path, n):\n    dic = {\n        \"vertex_xs\": [],\n        \"vertex_ys\": [],\n        \"bounding_confidences\": [],\n        \"bounding_importance_fracs\": [],\n        \"dominant_blues\": [],\n        \"dominant_greens\": [],\n        \"dominant_reds\": [],\n        \"dominant_pixel_fracs\": [],\n        \"dominant_scores\": [],\n        \"mean_red\": [],\n        \"mean_blue\": [],\n        \"mean_green\": [],\n        \"label_descriptions\": [],\n        \"label_scores\": []\n    }\n    for pet in ids:\n        try:\n            with open(path+ pet + '-{}.json'.format(str(n)), 'r') as f:\n                data = json.load(f)\n            dic[\"vertex_xs\"].append(data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['x'])\n            dic[\"vertex_ys\"].append(data['cropHintsAnnotation']['cropHints'][0]['boundingPoly']['vertices'][2]['y'])\n            dic[\"bounding_confidences\"].append(data['cropHintsAnnotation']['cropHints'][0]['confidence'])\n            dic[\"bounding_importance_fracs\"].append(data['cropHintsAnnotation']['cropHints'][0].get('importanceFraction', -1))\n            try:\n                dic[\"dominant_blues\"].append(data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['blue'])\n            except:\n                dic[\"dominant_blues\"].append(0)\n            try:\n                dic[\"dominant_greens\"].append(data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['green'])\n            except:\n                dic[\"dominant_greens\"].append(0)\n            try:\n                dic[\"dominant_reds\"].append(data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['color']['red'])\n            except:\n                dic[\"dominant_reds\"].append(0)\n            dic[\"dominant_pixel_fracs\"].append(data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['pixelFraction'])\n            dic[\"dominant_scores\"].append(data['imagePropertiesAnnotation']['dominantColors']['colors'][0]['score'])\n            \"\"\"r, g, b = 0, 0, 0\n            for i, color in enumerate(data['imagePropertiesAnnotation']['dominantColors']['colors']):\n                try:\n                    r += data['imagePropertiesAnnotation']['dominantColors']['colors'][i]['color']['red']\n                except:\n                    b += 0\n                try:\n                    g += data['imagePropertiesAnnotation']['dominantColors']['colors'][i]['color']['green']\n                except:\n                    b += 0\n                try:\n                    b += data['imagePropertiesAnnotation']['dominantColors']['colors'][i]['color']['blue']\n                except:\n                    b += 0\n            dic[\"mean_red\"].append(r / i)\n            dic[\"mean_blue\"].append(b / i)\n            dic[\"mean_green\"].append(g / i)\"\"\"\n            if data.get('labelAnnotations'):\n                dic[\"label_descriptions\"].append(data['labelAnnotations'][0]['description'])\n                dic[\"label_scores\"].append(data['labelAnnotations'][0]['score'])\n            else:\n                dic[\"label_descriptions\"].append('nothing')\n                dic[\"label_scores\"].append(np.nan)\n        except FileNotFoundError:\n            dic[\"vertex_xs\"].append(np.nan)\n            dic[\"vertex_ys\"].append(np.nan)\n            dic[\"bounding_confidences\"].append(np.nan)\n            dic[\"bounding_importance_fracs\"].append(np.nan)\n            dic[\"dominant_blues\"].append(np.nan)\n            dic[\"dominant_greens\"].append(np.nan)\n            dic[\"dominant_reds\"].append(np.nan)\n            dic[\"dominant_pixel_fracs\"].append(np.nan)\n            dic[\"dominant_scores\"].append(np.nan)\n            #dic[\"mean_red\"].append(np.nan)\n            #dic[\"mean_blue\"].append(np.nan)\n            #dic[\"mean_green\"].append(np.nan)\n            dic[\"label_descriptions\"].append('nothing')\n            dic[\"label_scores\"].append(np.nan)\n    return dic\n\ndef replace_nan(train, test, replace_dic):\n    for col, value in replace_dic.items():\n        train[col] = train[col].replace(value, np.nan)\n        test[col] = test[col].replace(value, np.nan)\n    return train, test\n\ndef get_color(x):\n    result = [0 for i in range(7)]\n    for i in range(1, 8):\n        if i in list(x.values):\n            result[i-1] = 1\n    return pd.Series(result)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\ntrain = pd.read_csv(\"../input/train/train.csv\")\ntest = pd.read_csv(\"../input/test/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"303f70b66aef2d613e62c0ce4b1a403ad5d0a94c"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4aa5f57d313f96b24ae7f7ba36b477969dd0a20"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"948169f40e748c7ec45402f269e7cbb8af40983f"},"cell_type":"code","source":"fe_input_path = \"../input/\"\nn_meta = 1\ntarget = train['AdoptionSpeed']\ntrain_id = train['PetID']\ntest_id = test['PetID']\ntrain.drop(['AdoptionSpeed', 'PetID'], axis=1, inplace=True)\ntest.drop(['PetID'], axis=1, inplace=True)\n\ncolor_result_col = [\"color{}\".format(i) for i in range(1, 8)]\ncolor_pick_col = [\"Color1\", \"Color2\", \"Color3\"]\ntrain_color = pd.DataFrame(train[color_pick_col].apply(get_color, axis=1).values, columns=color_result_col)\ntest_color = pd.DataFrame(test[color_pick_col].apply(get_color, axis=1).values, columns=color_result_col)\n\ntrain = pd.concat((train, train_color), axis=1)\ntest = pd.concat((test, test_color), axis=1)\n\ntrain.drop(color_pick_col, axis=1, inplace=True)\ntest.drop(color_pick_col, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4436a13aeded76a3e5651a9774d839f57caa529a"},"cell_type":"code","source":"%%time\ndic = get_sentiment(train_id, join(fe_input_path, 'train_sentiment/'))\ntrain.loc[:, 'doc_sent_mag'] = dic[\"doc_sent_mag\"]\ntrain.loc[:, 'doc_sent_score'] = dic[\"doc_sent_score\"]\n\ndic = get_sentiment(test_id, join(fe_input_path, 'test_sentiment/'))\ntest.loc[:, 'doc_sent_mag'] = dic[\"doc_sent_mag\"]\ntest.loc[:, 'doc_sent_score'] = dic[\"doc_sent_score\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c0aa0f4106521cc5f356e8871cc9c07e73d0f44"},"cell_type":"code","source":"for i in range(1, n_meta+1):\n    dic = get_meta(train_id, join(fe_input_path,  'train_metadata/'), i)\n    train.loc[:, 'vertex_x_{}'.format(str(i))] = dic[\"vertex_xs\"]\n    train.loc[:, 'vertex_y_{}'.format(str(i))] = dic[\"vertex_ys\"]\n    train.loc[:, 'bounding_confidence_{}'.format(str(i))] = dic[\"bounding_confidences\"]\n    train.loc[:, 'bounding_importance_{}'.format(str(i))] = dic[\"bounding_importance_fracs\"]\n    train.loc[:, 'dominant_blue_{}'.format(str(i))] = dic[\"dominant_blues\"]\n    train.loc[:, 'dominant_green_{}'.format(str(i))] = dic[\"dominant_greens\"]\n    train.loc[:, 'dominant_red_{}'.format(str(i))] = dic[\"dominant_reds\"]\n    train.loc[:, 'dominant_pixel_frac_{}'.format(str(i))] = dic[\"dominant_pixel_fracs\"]\n    train.loc[:, 'dominant_score_{}'.format(str(i))] = dic[\"dominant_scores\"]\n    train.loc[:, 'label_description_{}'.format(str(i))] = dic[\"label_descriptions\"]\n    train.loc[:, 'label_score_{}'.format(str(i))] = dic[\"label_scores\"]\n\n    dic = get_meta(test_id, join(fe_input_path,  'test_metadata/'), i)\n    test.loc[:, 'vertex_x_{}'.format(str(i))] = dic[\"vertex_xs\"]\n    test.loc[:, 'vertex_y_{}'.format(str(i))] = dic[\"vertex_ys\"]\n    test.loc[:, 'bounding_confidence_{}'.format(str(i))] = dic[\"bounding_confidences\"]\n    test.loc[:, 'bounding_importance_{}'.format(str(i))] = dic[\"bounding_importance_fracs\"]\n    test.loc[:, 'dominant_blue_{}'.format(str(i))] = dic[\"dominant_blues\"]\n    test.loc[:, 'dominant_green_{}'.format(str(i))] = dic[\"dominant_greens\"]\n    test.loc[:, 'dominant_red_{}'.format(str(i))] = dic[\"dominant_reds\"]\n    test.loc[:, 'dominant_pixel_frac_{}'.format(str(i))] = dic[\"dominant_pixel_fracs\"]\n    test.loc[:, 'dominant_score_{}'.format(str(i))] = dic[\"dominant_scores\"]\n    test.loc[:, 'label_description_{}'.format(str(i))] = dic[\"label_descriptions\"]\n    test.loc[:, 'label_score_{}'.format(str(i))] = dic[\"label_scores\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e55e37a6b66c19033b61741f68291a2ac94fe0b7"},"cell_type":"code","source":"eng_stopwords = set(stopwords.words(\"english\"))\nremove_punctuation_map = dict((ord(char), ' ') for char in string.punctuation)\n#stemmer = nltk.stem.snowball.SnowballStemmer('english')\nstemmer = nltk.stem.porter.PorterStemmer()\n\ndef stem_tokens(tokens):\n    lst = [stemmer.stem(item) for item in tokens]\n    return ' '.join(lst)\n\ndef get_textfeats(df, col, flag=True):\n    df[col] = df[col].fillna('none').astype(str)\n    df[col] = df[col].str.lower()\n    df[col] = df[col].apply(lambda x: stem_tokens(nltk.word_tokenize(x.translate(remove_punctuation_map))))\n    \n    return df\n\ndef load_text(train, test):\n    train = get_textfeats(train, \"Description\")\n    test = get_textfeats(test, \"Description\")\n    train_desc = train['Description'].values\n    test_desc = test['Description'].values\n\n    train_corpus = [text_to_word_sequence(text) for text in tqdm(train_desc)]\n    test_corpus = [text_to_word_sequence(text) for text in tqdm(test_desc)]\n    \n    return train_corpus, test_corpus\n\ndef get_result(corpus, model):\n    result = []\n    for text in corpus:\n        n_skip = 0\n        for n_w, word in enumerate(text):\n            try:\n                vec_ = model.wv[word]\n            except:\n                n_skip += 1\n                continue\n            if n_w == 0:\n                vec = vec_\n            else:\n                vec = vec + vec_\n        vec = vec / (n_w - n_skip + 1)\n        result.append(vec)\n        \n    return result\n\ntrain_corpus, test_corpus = load_text(train, test)\nmodel = word2vec.Word2Vec(train_corpus+test_corpus, size=200, window=10, max_vocab_size=50000, seed=0)\ntrain_result = get_result(train_corpus, model)\ntest_result = get_result(test_corpus, model)\n\nw2v_cols = [\"wv{}\".format(i) for i in range(1, 201)]\ntrain_result = pd.DataFrame(train_result)\ntrain_result.columns = w2v_cols\ntest_result = pd.DataFrame(test_result)\ntest_result.columns = w2v_cols\n\ntrain = pd.concat((train, train_result), axis=1)\ntest = pd.concat((test, test_result), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb93d39a1d814bbdb4477f9f5dbdc45dc6a525fa","scrolled":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"674d96bab68425baae154d8d95dc2e4f43ee19ae"},"cell_type":"code","source":"%%time\ntrain.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)\ntest.drop(['Name', 'RescuerID', 'Description'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"570c602f74cd85a689acacb24621468d7bc4e9a7"},"cell_type":"code","source":"replace_dic = {\n    \"Gender\": 3,\n    \"MaturitySize\": 0,\n    \"FurLength\": 0,\n    \"MaturitySize\": 0,\n    \"Vaccinated\": 3,\n    \"Dewormed\": 3,\n    \"Sterilized\": 3,\n    \"Health\": 0\n}\ntrain, test = replace_nan(train, test, replace_dic)\ncat_cols = ['Type', 'Breed1', 'Breed2', 'Gender', 'MaturitySize', \n            'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health',\n            'State', 'label_description_1']\ntrain.loc[:, cat_cols] = train[cat_cols].astype('category')\ntest.loc[:, cat_cols] = test[cat_cols].astype('category')\nprint(train.shape)\nprint(test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5f7f965a23fc83f5fbd0331d64468b204a48fab"},"cell_type":"code","source":"def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n    fold_splits = kf.split(train, target)\n    cv_scores = []\n    qwk_scores = []\n    pred_full_test = 0\n    pred_train = np.zeros((train.shape[0], 5))\n    all_coefficients = np.zeros((5, 4))\n    feature_importance_df = pd.DataFrame()\n    i = 1\n    for dev_index, val_index in fold_splits:\n        print('Started ' + label + ' fold ' + str(i) + '/5')\n        if isinstance(train, pd.DataFrame):\n            dev_X, val_X = train.iloc[dev_index], train.iloc[val_index]\n            dev_y, val_y = target[dev_index], target[val_index]\n        else:\n            dev_X, val_X = train[dev_index], train[val_index]\n            dev_y, val_y = target[dev_index], target[val_index]\n        params2 = params.copy()\n        pred_val_y, pred_test_y, importances, coefficients, qwk = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n        pred_full_test = pred_full_test + pred_test_y\n        pred_train[val_index] = pred_val_y\n        all_coefficients[i-1, :] = coefficients\n        if eval_fn is not None:\n            cv_score = eval_fn(val_y, pred_val_y)\n            cv_scores.append(cv_score)\n            qwk_scores.append(qwk)\n            print(label + ' cv score {}: RMSE {} QWK {}'.format(i, cv_score, qwk))\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df['feature'] = train.columns.values\n        fold_importance_df['importance'] = importances\n        fold_importance_df['fold'] = i\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)        \n        i += 1\n    print('{} cv RMSE scores : {}'.format(label, cv_scores))\n    print('{} cv mean RMSE score : {}'.format(label, np.mean(cv_scores)))\n    print('{} cv std RMSE score : {}'.format(label, np.mean(cv_scores)))\n    print('{} cv QWK scores : {}'.format(label, qwk_scores))\n    print('{} cv mean QWK score : {}'.format(label, np.mean(qwk_scores)))\n    print('{} cv std QWK score : {}'.format(label, np.std(qwk_scores)))\n    pred_full_test = pred_full_test / 5.0\n    results = {'label': label,\n               'train': pred_train, 'test': pred_full_test,\n                'cv': cv_scores, 'qwk': qwk_scores,\n               'importance': feature_importance_df,\n               'coefficients': all_coefficients}\n    return results\n\nparams = {'application': 'regression',\n          'boosting': 'gbdt',\n          'metric': 'rmse',\n          'num_leaves': 80,\n          'max_depth': 9,\n          'learning_rate': 0.01,\n          'bagging_fraction': 0.85,\n          'feature_fraction': 0.8,\n          'min_split_gain': 0.01,\n          'min_child_samples': 150,\n          'min_child_weight': 0.1,\n          'verbosity': -1,\n          'data_random_seed': 3,\n          'early_stop': 100,\n          'verbose_eval': 100,\n          'num_rounds': 10000}\n\ndef runLGB(train_X, train_y, test_X, test_y, test_X2, params):\n    print('Prep LGB')\n    d_train = lgb.Dataset(train_X, label=train_y)\n    d_valid = lgb.Dataset(test_X, label=test_y)\n    watchlist = [d_train, d_valid]\n    print('Train LGB')\n    num_rounds = params.pop('num_rounds')\n    verbose_eval = params.pop('verbose_eval')\n    early_stop = None\n    if params.get('early_stop'):\n        early_stop = params.pop('early_stop')\n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n    print('Predict 1/2')\n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    optR = OptimizedRounder()\n    optR.fit(pred_test_y, test_y)\n    coefficients = optR.coefficients()\n    pred_test_y_k = optR.predict(pred_test_y, coefficients)\n    print(\"Valid Counts = \", Counter(test_y))\n    print(\"Predicted Counts = \", Counter(pred_test_y_k))\n    print(\"Coefficients = \", coefficients)\n    qwk = quadratic_weighted_kappa(test_y, pred_test_y_k)\n    print(\"QWK = \", qwk)\n    print('Predict 2/2')\n    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n    return pred_test_y.reshape(-1, 1), pred_test_y2.reshape(-1, 1), model.feature_importance(), coefficients, qwk\n\nresults = run_cv_model(train, test, target, runLGB, params, rmse, 'lgb')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"98066147b196b8fb4a374cc058e88d6fa5fb7e5a"},"cell_type":"code","source":"imports = results['importance'].groupby('feature')['feature', 'importance'].mean().reset_index()\nimports.sort_values('importance', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f5cd15c1e86ee594e457e9d5cc305c750f4b68a9"},"cell_type":"code","source":"optR = OptimizedRounder()\ncoefficients_ = np.mean(results['coefficients'], axis=0)\nprint(coefficients_)\ntrain_predictions = [r[0] for r in results['train']]\ntrain_predictions = optR.predict(train_predictions, coefficients_).astype(int)\nCounter(train_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb665c871358ce885df2d9a67e210e1f110acc77"},"cell_type":"code","source":"optR = OptimizedRounder()\ntest_predictions = [r[0] for r in results['test']]\ntest_predictions = optR.predict(test_predictions, coefficients_).astype(int)\nCounter(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3bfb85656371f812c304aff3c982e00ab94fdac"},"cell_type":"code","source":"pd.DataFrame(sk_cmatrix(target, train_predictions), index=list(range(5)), columns=list(range(5)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6a51364bb4b337d28ebc249234a4a9c8b285f707"},"cell_type":"code","source":"quadratic_weighted_kappa(target, train_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1782242261e638e3762946663b3bb55e90528093"},"cell_type":"code","source":"rmse(target, [r[0] for r in results['train']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c3846700ea868e7a2b9992a582104a7a5ff8a2c"},"cell_type":"code","source":"submission = pd.DataFrame({'PetID': test_id, 'AdoptionSpeed': test_predictions})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1712f6b02c1f3ac821789c02c88f516cb629b44e"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}