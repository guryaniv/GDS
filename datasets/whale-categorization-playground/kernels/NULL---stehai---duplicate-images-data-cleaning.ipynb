{"cells":[{"metadata":{"_uuid":"fafc9b15b6d81065d4079d6b16e61b2607c3c1e6"},"cell_type":"markdown","source":"**While exploring the data I found that there are 778 duplicate images.**<br>\n**There are 3 types of data errors regarding duplicate images:**<br>\n**1) The same image with the corresponding Id appears multiple time.**<br>\n**2) The same image appears with a known whale Id and as \"new_whale\".**<br>\n**3) The same image appears with different Ids (ambiguous classified).**<br>\n\nThe following code shows a data cleaning approach to fix the duplicate images issue."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport collections\nimport imagehash\nfrom os import path as os_path\n\nTRAIN_IMG_PATH = r\"../input/train\"\n###############################################################################\n# misc functions\n\ndef plot_images(path, imgs):\n    assert(isinstance(imgs, collections.Iterable))\n    imgs_list = list(imgs)\n    nrows = len(imgs_list)\n    if (nrows % 2 != 0):\n        nrows = nrows + 1 \n\n    plt.figure(figsize=(18, 6*nrows/2))\n    for i, img_file in enumerate(imgs_list):\n        with Image.open(os_path.join(path, img_file)) as img:\n            ax = plt.subplot(nrows/2, 2, i+1)\n            ax.set_title(\"#{}: '{}'\".format(i+1, img_file))\n            ax.imshow(img)\n        \n    plt.show()\n\n\n###############################################################################\n# load data\n\ndef getImageMetaData(file_path):\n    with Image.open(file_path) as img:\n        img_hash = imagehash.phash(img)\n        return img.size, img.mode, img_hash\n\ndef get_train_input():\n    train_input = pd.read_csv(r\"../input/train.csv\")\n    \n    m = train_input.Image.apply(lambda x: getImageMetaData(os_path.join(TRAIN_IMG_PATH, x)))\n    train_input[\"Hash\"] = [str(i[2]) for i in m]\n    train_input[\"Shape\"] = [i[0] for i in m]\n    train_input[\"Mode\"] = [str(i[1]) for i in m]\n    train_input[\"Length\"] = train_input[\"Shape\"].apply(lambda x: x[0]*x[1])\n    train_input[\"Ratio\"] = train_input[\"Shape\"].apply(lambda x: x[0]/x[1])\n    train_input[\"New_Whale\"] = train_input.Id == \"new_whale\"\n    \n    return train_input\n\ntrain_input = get_train_input()\n\n###############################################################################\n# data cleaning duplicate images\n\n# determine duplicate images using the hash\n\nt = train_input.Hash.value_counts()\nt = t[t > 1]\nduplicates_df = pd.DataFrame(t)\n\n# get the Ids of the duplicate images\nduplicates_df[\"Ids\"] =list(map(\n            lambda x: set(train_input.Id[train_input.Hash==x].values), \n            t.index))\nduplicates_df[\"Ids_count\"] = duplicates_df.Ids.apply(lambda x: len(x))\nduplicates_df[\"Ids_contain_new_whale\"] = duplicates_df.Ids.apply(lambda x: \"new_whale\" in x)\n\nprint(duplicates_df.head(20))\n\n###\n# There are 3 types of data errors regarding duplicate images:\n#\n# 1) The same image with the corresponding Id appears multiple time.\n# 2) The same image appears with an Id and as \"new_whale\".\n# 3) The same image appears with different Ids (ambiguous classified). \n#\n\n# Fix error type 1: The same image with the corresponding Id appears multiple time.\n\ntrain_input.drop_duplicates([\"Hash\", \"Id\"], inplace = True)\n\n# Fix error type 2: The same image appears with an Id and as \"new_whale\".\n# => delete the \"new_whale\" entry\n\ndrop_hash = duplicates_df.loc[(duplicates_df.Ids_count>1) & (duplicates_df.Ids_contain_new_whale==True)].index\ntrain_input.drop(train_input.index[(train_input.Hash.isin(drop_hash) & (train_input.Id==\"new_whale\"))], inplace=True)\n\n# Fix error type 3: The same image appears with different Ids (ambiguous classified).\n# => delete all of them\n\ndrop_hash = duplicates_df.loc[(duplicates_df.Ids_count>1) & ((duplicates_df.Ids_count - duplicates_df.Ids_contain_new_whale)>1)].index\n\n#print(\"Ambiguous classified images:\")\n#for i in drop_hash:\n#    plot_images(TRAIN_IMG_PATH, \n#                train_input[train_input.Hash==i].Image)\n\ntrain_input.drop(train_input.index[train_input.Hash.isin(drop_hash)], inplace=True)\n\n# check if there are still duplicate images\nassert(np.sum(train_input.Hash.value_counts()>1) == 0)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}