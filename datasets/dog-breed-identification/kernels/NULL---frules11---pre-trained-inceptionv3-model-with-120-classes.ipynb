{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport tensorflow as tf\nimport os\nimport cv2\nfrom tqdm import tqdm\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed30af1bae7aa72469a7b757f26f8c4eedbd5aac"},"cell_type":"code","source":"def get_y_map():\n    df = pd.read_csv(\"../input/labels.csv\")\n    \n    y_map = {}\n    \n    for i, el in enumerate(df[\"breed\"].unique().tolist()):\n        y_map[el] = i\n        \n    return y_map\n\ndef data_loader():\n    df = pd.read_csv(\"../input/labels.csv\")\n    img_dir = \"../input/train\"\n    \n    x_data = []\n    y_data = []\n    \n    y_map = get_y_map()\n    \n    for d in tqdm(df.values):\n        x_data.append(cv2.resize(cv2.imread(os.path.join(img_dir, d[0]+\".jpg\")),(299, 299)))\n        y_data.append(y_map[d[1]])\n        \n    return np.array(x_data), np.array(y_data), len(y_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f6ac366c88f49ce28753c2f7d182aec96815bcc"},"cell_type":"code","source":"x_data, y_data, num_classes = data_loader()\ny_data_cat = tf.keras.utils.to_categorical(y_data, num_classes=120)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aaa91a0b178a22d24241c6ccde5639bdef006f9a"},"cell_type":"code","source":"model = tf.keras.applications.inception_v3.InceptionV3(weights=\"imagenet\")\n\nx = tf.keras.layers.Dense(120, activation=\"softmax\")(model.layers[-2].output)\n\nmodel = tf.keras.models.Model(model.inputs, x)\n\nmodel.summary()\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.000025), metrics=[\"acc\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2f9a2669d4b1a026acc3cded70316e5a63bba2d"},"cell_type":"code","source":"history = model.fit(x_data, y_data_cat, batch_size=64, epochs=5, validation_split=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c3d76f36b2166c6e1d74c91d8c87960327d0514"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}