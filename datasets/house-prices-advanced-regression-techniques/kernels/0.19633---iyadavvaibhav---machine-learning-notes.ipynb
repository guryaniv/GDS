{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Machine Learning - Notes\nHere it begins the next step in data analytics. I hope you are excited too..! Let crack it on..\n\n## Table of Contents\n- [Selecting and filtering](# Selecting and Filtering)\n- [Predicting](#predicting)\n- [Bias Variance Trade Off](#Bias Variance Trade Off)\n\n## Selecting and Filtering\n\nColumns can be seen using **dot** notation.\n`my_data.columns`\n\n**Sample** data can be seen using dot and paran\n`my_data.head()`\n\n### Selecting\nSingle column, dot\n`my_data.col1`\n\nMultiple columns, **select SQL** example, dot and array\n`my_data.[['col1', 'col2']]`\n\nDetails of data,  dot and paran\n`my_data.describe()`\n"},{"metadata":{"_uuid":"f595fbb7704f7653d70d56de1bb33bb9b1b4537b"},"cell_type":"markdown","source":"## Predicting \n*Prediction target is reffered to as* **y** and data as **x**\n\nThe steps to building and using a model are:\n\n* Define: What type of model will it be? A decision tree? Some other type of model? Some other parameters of the model type are specified too.\n* Fit: Capture patterns from provided data. This is the heart of modeling.\n* Predict: Just what it sounds like\n* Evaluate: Determine how accurate the model's predictions are.\n\n### Linear Regression\nIt is a line that passes as close to observations as possible. y predicted vs y can give us errors. \n\ny can be some column, say sale price\n\nX can be columns which are characteristics, like area, floors, pool, parking, park facing etc.\n\nWe need to divide our data into set of training and testing data.\n\n[Refer workbook](https://www.kaggle.com/iyadavvaibhav/machine-learning-linear-regression)\n\n#### Define Model\nWe can define model\n`my_model = DecisionTreeRegressor()`\n\n#### Fit Model\nThen we need to fit model\n`my_model.fit(X, y)`\n\n#### Predict Values\nWe can predict using following code\n`my_model.predict(X.head())`\n\n**Conclusion**\nWe have built a decision tree model that can predict the prices of houses based on their characteristics."},{"metadata":{"_uuid":"59ecb596819c14f4fa25cd13cabe4ac7edc9f885"},"cell_type":"markdown","source":"\n## Model Validation\nHow good is model?\nWe can do this by predicting values for training data but it is not good.\nOne common way is *Mean Absolute Error* aslo called **MAE**. \n\n*error = actual - predicted*\n\nwe take abolute values of it and the find average. In english we say:\n*On average, our predicitons are off by about X*\n\n### Computing Error\nThis can be calculated usung **metrics** class from sklearn.\n\n`from sklearn import metrics`\n\n**Predicting using train data and validation data**\nWe can use train_test_split to divide our data into two subsets.\n\n`print('MAE',metrics.mean_absolute_error(y_test,predictions))`\n\n### Summary\nThe entire process can be summarized as following:\n1. Take the data\n2. Split into training and testing set\n3. Train a linear model from sklearn\n4. Fit the model\n5. look at `intercept_` and `coef_` to learn about the model\n6. Predict the values from the model\n7. Analyze the residuals and errors of the model\n\n## Bias Variance Trade Off\nFundamental topic of understanding model performance.\n\nIt is  point where we just add noise by adding model complexity.  If we make model more and more complex to make our line touch all the X values. It reduces the training error but might increase the test error.\n\nModel after bias trade-off point begins to **overfit**.\n\nSometime training data may not be very scattered and we predict well while otherwise it might be scattered with outliers where we will have to find a bias trade off point.\n\nIf we plot 'model complexity' vs 'perdiction error' for test sample then the point at which graph is lowest is can be treated as bias trade off."},{"metadata":{"trusted":true,"_uuid":"87145a029bb0984570e01b9f4f40aa92994ca70b"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\npredicted_home_prices = my_model.predict(X)\nmean_absolute_error(y, predicted_home_prices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8b20f0cf391c6cedb102353f94000ce10246ba4"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n# Define model\nmy_model = DecisionTreeRegressor()\n# Fit model\nmy_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = my_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c39ed8f1031131893a557ce0f694a47ea074b5dc"},"cell_type":"markdown","source":"**Conclusion** now we can calculate the quality of our model by using MAE. Next is comparing models.\n\n# Depth of Decesion Tree\nThe depth of decision and number of leaves play a mojor role in determining the accuracy of the mode. We can compare MAE with number of leaves to find best fit of our mode.\n\nModels can suffer from either:\n* **Overfitting:** capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n* **Underfitting:** failing to capture relevant patterns, again leading to less accurate predictions.\nWe use validation data, which isn't used in model training, to measure a candidate model's accuracy.\n\nLet's compare MAE with number of leaves.\n\n\n"},{"metadata":{"trusted":true,"_uuid":"0f3612a311e913cf0db68427e5fa1575b16db122"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\n# compare MAE with differing values of max_leaf_nodes\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c9ef7453d9eac09f61ee42aa830f7cfc41f413d"},"cell_type":"markdown","source":"**Conclusion:** Here we see that with 50 leaf nodes we get lowest MAE and it is sweetest spot for our data.\nNext, we see advance ML model.\n\n# Random Forest\nThe random forest uses many trees, and it makes a prediction by averaging the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters.\n"},{"metadata":{"trusted":true,"_uuid":"4fb4e41ed78f19944342ec5e17f79b879fc6dc02"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)\nmelb_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, melb_preds))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"caef691e96c01f0c68c77cb81b09a42ee6680375"},"cell_type":"markdown","source":"**Conclusion:** One of the best features of Random Forest models is that they generally work reasonably even without tuning.\n\n# Competition"},{"metadata":{"trusted":true,"_uuid":"e4027e09cfd7998be9a2e28db478318d0bbde48e"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Read the data\ntrain = pd.read_csv('../input/train.csv')\n\n# pull data into target (y) and predictors (X)\ntrain_y = train.SalePrice\npredictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n\n# Create training predictors data\ntrain_X = train[predictor_cols]\n\nmy_model = RandomForestRegressor()\nmy_model.fit(train_X, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"846d32718725a5b9b5058d509d7f30f6b81c9056"},"cell_type":"code","source":"# Read the test data\ntest = pd.read_csv('../input/test.csv')\n# Treat the test data in the same way as training data. In this case, pull same columns.\ntest_X = test[predictor_cols]\n# Use the model to make predictions\npredicted_prices = my_model.predict(test_X)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66d4e77521c1f5f4f94484b3d40c218b76dbe566"},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}