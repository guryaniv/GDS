{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Fast.ai/Pytorch Starter\n\nAlthough most people (including me) seem to be doing much better with Boosting Trees, I think it is worth the time to explore a Neural Network solution to the  Home Credit Default Risk competition. Besides, a Kaggle competition is always a good opportunity to test what one is currently learning. I did two \"cool\"  things in this kernel:\n\n* Categorical Embeddings.\n* Custom loss functions with different weights for each class to try to manage the imbalance in `TARGET`. \n\nI had to tweak the fast.ai library a little bit, but all things considered, it is extraordinary how little code you actually have to write to get some model going. \n\n## Load Data\n\nTo aggregate the various tables available in the competition I followed the next heuristic:\n\n* If the variable was continuous, I aggregated it using its mean. \n* If the variable was categorical, I aggregated it using its mode. If I were to one-hot-encode the variables and aggregate them using their mean, there wouldn't be categorical variables (besides the one in the main table) for which to create categorical embeddings. \n\nThe mode computation is very, very slow, so I did it all of this in another Kaggle kernel.\n\n## Imports\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from fastai.imports import *\nfrom fastai.structured import *\nfrom fastai.column_data import *\nfrom torch.nn import functional as F\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","execution_count":1,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"7aa0ba8ec01c80e92841ecd2bc70d3ccd3b89c7e","_kg_hide-output":false},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n# Define custom loss function to account for two ouput nodes\ndef roc_auc_own(y_score, y_true):\n    y_score = np.exp(y_score[:,1])\n    return roc_auc_score(y_true, y_score)\ndef proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    \"\"\" proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n    Parameters:\n    -----------\n    df: The data frame you wish to process.\n    y_fld: The name of the response variable\n    skip_flds: A list of fields that dropped from df.\n    ignore_flds: A list of fields that are ignored during processing.\n    do_scale: Standardizes each column in df. Takes Boolean Values(True,False)\n    na_dict: a dictionary of na columns to add. Na columns are also added if there\n        are any missing values.\n    preproc_fn: A function that gets applied to df.\n    max_n_cat: The maximum number of categories to break into dummy values, instead\n        of integer codes.\n    subset: Takes a random subset of size subset from df.\n    mapper: If do_scale is set as True, the mapper variable\n        calculates the values used for scaling of variables during training time (mean and standard deviation).\n    Returns:\n    --------\n    [x, y, nas, mapper(optional)]:\n        x: x is the transformed version of df. x will not have the response variable\n            and is entirely numeric.\n        y: y is the response variable\n        nas: returns a dictionary of which nas it created, and the associated median.\n        mapper: A DataFrameMapper which stores the mean and standard deviation of the corresponding continuous\n        variables which is then used for scaling of during test-time.\n    Examples:\n    ---------\n    >>> df = pd.DataFrame({'col1' : [1, 2, 3], 'col2' : ['a', 'b', 'a']})\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    note the type of col2 is string\n    >>> train_cats(df)\n    >>> df\n       col1 col2\n    0     1    a\n    1     2    b\n    2     3    a\n    now the type of col2 is category { a : 1, b : 2}\n    >>> x, y, nas = proc_df(df, 'col1')\n    >>> x\n       col2\n    0     1\n    1     2\n    2     1\n    >>> data = DataFrame(pet=[\"cat\", \"dog\", \"dog\", \"fish\", \"cat\", \"dog\", \"cat\", \"fish\"],\n                 children=[4., 6, 3, 3, 2, 3, 5, 4],\n                 salary=[90, 24, 44, 27, 32, 59, 36, 27])\n    >>> mapper = DataFrameMapper([(:pet, LabelBinarizer()),\n                          ([:children], StandardScaler())])\n    >>>round(fit_transform!(mapper, copy(data)), 2)\n    8x4 Array{Float64,2}:\n    1.0  0.0  0.0   0.21\n    0.0  1.0  0.0   1.88\n    0.0  1.0  0.0  -0.63\n    0.0  0.0  1.0  -0.63\n    1.0  0.0  0.0  -1.46\n    0.0  1.0  0.0  -0.63\n    1.0  0.0  0.0   1.04\n    0.0  0.0  1.0   0.21\n    \"\"\"\n    if not ignore_flds: ignore_flds=[]\n    if not skip_flds: skip_flds=[]\n    if subset: df = get_sample(df,subset)\n    ignored_flds = df.loc[:, ignore_flds]\n    df.drop(ignore_flds, axis=1, inplace=True)\n    df = df.copy()\n    if preproc_fn: preproc_fn(df)\n    if y_fld is None: y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]): df[y_fld] = df[y_fld].cat.codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds, axis=1, inplace=True)\n\n    if na_dict is None: na_dict = {}\n    else: na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for n,c in df.items(): na_dict = fix_missing(df, c, n, na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n    if do_scale: mapper = scale_vars(df, mapper)\n    for n,c in df.items(): numericalize(df, c, n, max_n_cat)\n    df = pd.get_dummies(df, dummy_na=True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df, y, na_dict]\n    if do_scale: res = res + [mapper]\n    return res","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2df01493fae9666b612557581c89be3205269ea5","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"df_train = pd.read_feather('../input/home-credit-data-processing-for-neural-networks/tables_merged_train')\ndf_test = pd.read_feather('../input/home-credit-data-processing-for-neural-networks/tables_merged_test')","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"04867915d576cb3cbb34a0853de8e1d5bcaa7699"},"cell_type":"markdown","source":"## What type of variables do we have?"},{"metadata":{"trusted":true,"_uuid":"166e9ec0956507959d1afc7f4ac09a1c0fb5dc37","_kg_hide-input":true},"cell_type":"code","source":"df_train.dtypes.value_counts()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8f0d01f815d3800cb90227322c6385d84acddee3"},"cell_type":"code","source":"cat_vars = [col for col in df_train if df_train[col].dtype.name != 'float64' and df_train[col].dtype.name != 'float32' and len(df_train[col].unique()) < 150]\ncat_vars.remove('TARGET')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a2de280e875125d1b0865bd3431d468907a323f","collapsed":true},"cell_type":"code","source":"cat_sz = [(c, len(df_train[c].unique())+1) for c in cat_vars]","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"469514a8d5cbd798e67556c4711259caf53940bb"},"cell_type":"markdown","source":"Which variables are we going to treat as categorical?"},{"metadata":{"trusted":true,"_uuid":"69081617002e7c700ed74812063f4a2866dc327c","_kg_hide-input":true},"cell_type":"code","source":"cat_vars","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"d80db730bd8830942a96c8bfd63075aa5722a8e5"},"cell_type":"markdown","source":"## Pre-processing \n\nThe fast.ai library handles NA values for us. For categorical variables, missing variables are encoded as a level within the categories of their own; in this case, with a zero. For continuous variables, if a given variable has missing variables, we create an extra dummy variable recording which of the observations were missing and, in the original given variable, we impute the missing values with the median. \n\nThus, the algorithm will be able to encode missingness in any way it chooses. Also, we will normalize continuous variables for ease of optimization. "},{"metadata":{"trusted":true,"_uuid":"779e5c3c88e180c0e9fd1a54906d9bfe6b63bfdb"},"cell_type":"code","source":"# Train validation-split\ny = np.array(df_train['TARGET'])\ndf_train.drop('TARGET', axis = 1, inplace=True)\ndf_to_nn_train, df_to_nn_valid, y_train, y_valid = train_test_split(df_train, y, test_size=0.33, random_state=23, stratify = y)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"06c407c84bf75b4c661c6b5b845e5540b9b48f44"},"cell_type":"code","source":"def preprocess_fast_ai(df_to_nn_train, df_to_nn_valid, cat_vars):\n    # Declare categorical variables\n    for v in cat_vars: df_to_nn_train[v] = df_to_nn_train[v].astype('category').cat.as_ordered()\n    apply_cats(df_to_nn_valid, df_to_nn_train)\n\n    # Deal with missingness and put everything as numbers\n    df, _, nas, mapper = proc_df(df_to_nn_train, do_scale=True, skip_flds=['SK_ID_CURR'])\n    df_valid, _, nas, mapper = proc_df(df_to_nn_valid, do_scale=True, na_dict=nas, mapper=mapper, skip_flds=['SK_ID_CURR'])\n    return df, df_valid","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85bb24bdb20e05ac1d448575a0008c22842863d6"},"cell_type":"code","source":"%time df, df_valid = preprocess_fast_ai(df_to_nn_train, df_to_nn_valid, cat_vars)","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"352852dd63bf9f25842626900130f205bc113e1e"},"cell_type":"markdown","source":"The embedding sizes we are going to use for each category:"},{"metadata":{"trusted":true,"_uuid":"f11f979d1ae30817a9000a2a8a8a564557ffda70","collapsed":true},"cell_type":"code","source":"emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz]","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"47483c8ca3797c77cccc4b4f8382c303bbc3826e"},"cell_type":"markdown","source":"## PyTorch/Fast.ai\n\nDefine the data loader:"},{"metadata":{"trusted":true,"_uuid":"77b4b6e7e60be736f4355b34de3a7b460b83a1a3","collapsed":true},"cell_type":"code","source":"md  = ColumnarModelData.from_data_frames('', trn_df = df, val_df = df_valid, \n                                         trn_y = y_train.astype('int'), val_y = y_valid.astype('int'), \n                                         cat_flds=cat_vars, bs=512, is_reg= False)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"ef952815b0c2874e6e6957f80967fca90f758918"},"cell_type":"markdown","source":"There's no easy way of using the fast.ai library (that I know) to predict structured data in a classification problem. Besides, the fast.ai package that Kaggle is running is not the same as the source code in GitHub. Thus, I read a little bit of the code and tweaked it to create the model that we are going to use."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"881c7933b477f474655be4f55474b82644f605f2"},"cell_type":"code","source":"class MixedInputModel(nn.Module):\n    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n                 y_range=None, use_bn=False, is_reg=True, is_multi=False):\n        super().__init__()\n        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n        for emb in self.embs: emb_init(emb)\n        n_emb = sum(e.embedding_dim for e in self.embs)\n        self.n_emb, self.n_cont= n_emb, n_cont\n        szs = [n_emb + n_cont] + szs\n        self.lins = nn.ModuleList([\n            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n        self.bns = nn.ModuleList([\n            nn.BatchNorm1d(sz) for sz in szs[1:]])\n        for o in self.lins: kaiming_normal(o.weight.data)\n        self.outp = nn.Linear(szs[-1], out_sz)\n        kaiming_normal(self.outp.weight.data)\n\n        self.emb_drop = nn.Dropout(emb_drop)\n        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n        self.bn = nn.BatchNorm1d(n_cont)\n        self.use_bn,self.y_range = use_bn,y_range\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def forward(self, x_cat, x_cont):\n        x = []\n        for i,e in enumerate(self.embs):\n            x.append(e(x_cat[:,i]))\n        x = torch.cat(x, 1)\n        x = self.emb_drop(x)\n        x2 = self.bn(x_cont)\n        x = torch.cat([x, x2], 1)\n        for l,d,b in zip(self.lins, self.drops, self.bns):\n            x = F.relu(l(x))\n            if self.use_bn: x = b(x)\n            x = d(x)\n        x = self.outp(x)\n        x = F.log_softmax(x)\n        return x","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"320f477b11d99be017d56a4301689727683d2849"},"cell_type":"markdown","source":"Besides the embedding, 3 fully connected layers:"},{"metadata":{"trusted":true,"_uuid":"d2dcee58a192073da17e32b9c2c720e537f3707e","collapsed":true},"cell_type":"code","source":"# Define Model\nm = MixedInputModel(emb_szs, n_cont = len(df.columns)-len(cat_vars),\n                   emb_drop = 0.05, out_sz = 2, szs = [500, 250, 250], drops = [0.1, 0.1, 0.1], \n                   y_range = None, use_bn = False, is_reg = False, is_multi = False)\nbm = BasicModel(m.cuda(), 'binary_classifier')","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"22a9cbd77fb51a5cbf5d2f91636bfc99e2b119e8"},"cell_type":"markdown","source":"We define our learner's loss function:"},{"metadata":{"trusted":true,"_uuid":"31f94b39a811234109d125f657dcd9398f110dd2","collapsed":true},"cell_type":"code","source":"# Define Learner\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n        self.crit = F.nll_loss\n# Instantiate learner\nlearn = StructuredLearner(md, bm)","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"c49ca38c946afe68f802167b5c24920339212fd1"},"cell_type":"markdown","source":"Now, let's do some fitting:"},{"metadata":{"trusted":true,"_uuid":"4d6337fb7e894784c84944404d3d8ff9691632e6"},"cell_type":"code","source":"learn.lr_find(1e-4, 1)\nlearn.sched.plot(100)","execution_count":36,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91a3873b7965b1a3d19b22bdae48ff2ab1e56f83"},"cell_type":"code","source":"lr = 1e-1\nlearn.fit(lr, 3, metrics=[roc_auc_own])","execution_count":37,"outputs":[]},{"metadata":{"_uuid":"8d226d83cb6a9babb83cefb42a553844a202d4e2"},"cell_type":"markdown","source":"## Let's Understand our predictions"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4b097a07e382c94d9db0861902031757203946ae"},"cell_type":"code","source":"# predictions \nlogpreds = learn.predict() # final output log_softmax\npreds = np.exp(logpreds[:,1])","execution_count":21,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7c317acb447d7c0e97deef936b78fff8ee390ad9","collapsed":true},"cell_type":"code","source":"logpreds_valid = learn.predict(is_test = False)\npreds_valid = np.exp(logpreds_valid[:,1])\npreds_binary = (preds_valid >= 0.5).astype(np.int)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_valid, preds_binary)\nplot_confusion_matrix(cm, [0, 1])","execution_count":22,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0ca6d78bb18d475c3a4d40f1b2487e6489bbfdf8","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_valid,\n                            preds_binary,\n                            target_names= ['0', '1']))","execution_count":23,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f8c3f362948422c8b15acf311f0460d831284cce","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfalse_positive_rate, true_positive_rate, threshold = roc_curve(y_valid,\n                                                               preds_valid)\n# Plot ROC curve\nplt.title(\"Receiver Operating Characteristic\")\nplt.plot(false_positive_rate, true_positive_rate)\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.show()","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"d826e0fa94aec217ef0efb4bbbe307f1db15427d"},"cell_type":"markdown","source":"Although our AUC is not that bad, our predictions are extremely naive. They are driven by the huge imbalance in the dataset. This can be seen by the confusion matrix: we are hardly predicting for any of the observations the `1` class. This results in a lousy recall. We need our model to learn better what indentifies the people who belong to the `1` class."},{"metadata":{"_uuid":"2a9a5549da281f03d925bd2f4de4a97fac9e58e5"},"cell_type":"markdown","source":"## Tackling the imbalance problem\n\nSeems we've exhausted what this model can learn, as the changes from `val_loss` and `roc` have hit decreasing returns and our predictions aren't that intelligent. Let's try to correct for the imbalance in `TARGET`."},{"metadata":{"trusted":true,"_uuid":"eca09374b0c59aa8872c01bd78892827ecc0d91a","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"class ColumnarDataset(Dataset):\n    def __init__(self, cats, conts, y, is_reg, is_multi):\n        n = len(cats[0]) if cats else len(conts[0])\n        self.cats  = np.stack(cats,  1).astype(np.int64)   if cats  else np.zeros((n,1))\n        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n        self.y     = np.zeros((n,1))                       if y is None else y\n        if is_reg:\n            self.y =  self.y[:,None]\n        self.is_reg = is_reg\n        self.is_multi = is_multi\n\n    def __len__(self): return len(self.y)\n\n    def __getitem__(self, idx):\n        return [self.cats[idx], self.conts[idx], self.y[idx]]\n\n    @classmethod\n    def from_data_frames(cls, df_cat, df_cont, y=None, is_reg=True, is_multi=False):\n        cat_cols = [c.values for n,c in df_cat.items()]\n        cont_cols = [c.values for n,c in df_cont.items()]\n        return cls(cat_cols, cont_cols, y, is_reg, is_multi)\n\n    @classmethod\n    def from_data_frame(cls, df, cat_flds, y=None, is_reg=False, is_multi=False):\n        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg, is_multi)\n\nclass ColumnarModelData(ModelData):\n    def __init__(self, path, trn_ds, val_ds, bs, test_ds=None, shuffle=True):\n        test_dl = DataLoader(test_ds, bs, shuffle=False, num_workers=1) if test_ds is not None else None\n        super().__init__(path, DataLoader(trn_ds, bs, shuffle=shuffle, num_workers=1),\n            DataLoader(val_ds, bs*2, shuffle=False, num_workers=1), test_dl)\n    @classmethod\n    def from_data_frames(cls, path, trn_df, trn_y, cat_flds, bs, val_df = None, val_y = None,  is_reg = False, is_multi = False, test_df=None):\n        trn_ds  = ColumnarDataset.from_data_frame(trn_df,  cat_flds, trn_y, is_reg, is_multi)\n        val_ds  = ColumnarDataset.from_data_frame(val_df,  cat_flds, val_y, is_reg, is_multi) if val_df is not None else None\n        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, None,  is_reg, is_multi) if test_df is not None else None\n        return cls(path, trn_ds, val_ds, bs, test_ds=test_ds)\n    \n    @classmethod\n    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, is_multi=False, test_df=None):\n        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, is_multi, test_df=test_df)","execution_count":64,"outputs":[]},{"metadata":{"_uuid":"7b07fdbf92ac786c84a80df38d85683eb27af10b"},"cell_type":"markdown","source":"Our model is having trouble identifying the people with class `1`. The main problem is that there is hardly any of them in the dataset. Let's change that by oversampling with replacement these people and creating and augmented dataset such that they appear the same number of times as the people with class `0`. "},{"metadata":{"trusted":true,"_uuid":"6c3aa4a543db9d103921cbfe7106f1a75b4f4635"},"cell_type":"code","source":"train_ids = df_train['SK_ID_CURR']\ntest_ids = df_test['SK_ID_CURR']\n%time train_df, test_df = preprocess_fast_ai(df_train, df_test, cat_vars)","execution_count":65,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c53c79d1c19af16da0c03c53c033675fb54345d"},"cell_type":"code","source":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler()\ndf_resampled, y_resampled = ros.fit_sample(df, y_train)\ndf_resampled = pd.DataFrame(df_resampled, columns = df.columns)\ny_valid.mean(), y_resampled.mean()","execution_count":66,"outputs":[]},{"metadata":{"_uuid":"3c2c3e971a0711a651d40d28107edf56128219ac"},"cell_type":"markdown","source":"Let's redefine the data loader with the new observations added. Given that our training stops being representative of our validation, let's do some heavy dropout regularization. "},{"metadata":{"trusted":true,"_uuid":"7d2fc52f8cc28e0546307757e18553d77e6c6457","collapsed":true},"cell_type":"code","source":"md  = ColumnarModelData.from_data_frames('', trn_df = df_resampled, \n                                         val_df = df_valid, trn_y = y_resampled.astype('int'),\n                                         val_y = y_valid.astype('int'), cat_flds=cat_vars, bs=1024, is_reg = False,\n                                         test_df = test_df)\n# Define Learner\nclass StructuredLearner(Learner):\n    def __init__(self, data, models, **kwargs):\n        super().__init__(data, models, **kwargs)\n        self.crit = F.nll_loss\nm = MixedInputModel(emb_szs, n_cont = len(df.columns)-len(cat_vars),\n                   emb_drop = 0.4, out_sz = 2, szs = [1000, 500], \n                   drops = [0.6, 0.6],y_range = None, use_bn = False, is_reg = False)\nbm = BasicModel(m.cuda(), 'binary_classifier')\n# Instantiate learner\nlearn = StructuredLearner(md, bm)","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8f571bb07f81ae3c7b5424e43e3f4082997c914"},"cell_type":"code","source":"learn.lr_find(1e-2, 2)\nlearn.sched.plot(100)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56f53f10cb551df98273aa692ad14b979089c6be"},"cell_type":"code","source":"lr = 0.1\nlearn.fit(lr, 3, metrics=[roc_auc_own])","execution_count":69,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"528a68e85a9c1aee12bfb511565174a76bc975fc"},"cell_type":"code","source":"learn.fit(lr, 2, metrics=[roc_auc_own], cycle_len=1, cycle_mult=2)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd672224ab84db6fe72ce915a26e5244eb07c56b"},"cell_type":"code","source":"logpreds = learn.predict()\npreds = np.exp(logpreds[:,1])\n\nlogpreds_valid = learn.predict(is_test = False)\npreds_valid = np.exp(logpreds_valid[:,1])\npreds_binary = (preds_valid >= 0.5).astype(np.int)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_valid, preds_binary)\nplot_confusion_matrix(cm, [0, 1])","execution_count":71,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14ee5485b6289e2db8306742da4e349b44d44496"},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_valid,\n                            preds_binary,\n                            target_names= ['0', '1']))\n\nfrom sklearn.metrics import roc_curve\nfalse_positive_rate, true_positive_rate, threshold = roc_curve(y_valid,\n                                                               preds_valid)","execution_count":72,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d99375b0fbe566cd612c5fb21847fe6188e5129d"},"cell_type":"code","source":"# Plot ROC curve\nplt.title(\"Receiver Operating Characteristic\")\nplt.plot(false_positive_rate, true_positive_rate)\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlabel(\"False Positive Rate\")\nplt.show()","execution_count":73,"outputs":[]},{"metadata":{"_uuid":"a0863440197ef1b2bb2d20ecb679fd14891c4405"},"cell_type":"markdown","source":" Even though we are regularizing heavily, the model is still overfitting and the ROC has improved a little bit. Let's try to take this model to the leaderboard."},{"metadata":{"trusted":true,"_uuid":"790d19547028745d8280e643771e498c21e5d063","collapsed":true},"cell_type":"code","source":"logpreds = learn.predict(True)\npreds = np.exp(logpreds[:,1])\n\nsubmission = pd.DataFrame({'SK_ID_CURR': df_test['SK_ID_CURR'],\n              'TARGET': preds})\nsubmission.to_csv('submission.csv', index=False, float_format='%.8f')","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"733e7a15f860cf0c168e8ff57fd56d9683844832"},"cell_type":"markdown","source":"Get embeddings"},{"metadata":{"trusted":true,"_uuid":"742bd6df9792c59e9beef9822404596cd43b4fcc"},"cell_type":"code","source":"m=learn.model \nm.cuda()","execution_count":87,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c99a14f592bff885bcc472662d38c4fa4e87623d"},"cell_type":"code","source":"def get_embeddings(embs, dataframe, ids, cat_vars):\n    embeddings = np.concatenate([to_np(embs[i](V(dataframe[cat_vars[i]]))) for i in range(len(embs))], axis = 1)\n    embedding_columns = [\"embedding_\"+str(i) for i in range(embeddings.shape[1])]\n    embedding_df = pd.DataFrame(embeddings, columns=embedding_columns)\n    embedding_df = pd.concat([embedding_df, ids], axis = 1)\n    return embedding_df","execution_count":91,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dfcfd11eee7ff4c8659fddadfc0e861694373ac"},"cell_type":"code","source":"train_embeddings = get_embeddings(m.embs, train_df, train_ids, cat_vars)\ntest_embeddings = get_embeddings(m.embs, test_df, test_ids, cat_vars)\ntrain_embeddings.to_csv('train_embeddings.csv', index=False)\ntest_embeddings.to_csv('test_embeddings.csv', index=False)","execution_count":93,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}