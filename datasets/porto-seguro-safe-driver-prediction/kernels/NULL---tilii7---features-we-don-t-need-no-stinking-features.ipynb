{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "nbconvert_exporter": "python"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "2a347db6-b6ae-443f-ab26-5a98fe6e29f7", "_uuid": "6ff52a2937a3fc9aae74700af978afd45d23f306"}, "source": ["There has been an ongoing discussion about the feature usefulness (or lack thereof) - see [__here__](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/41487). We also have many feature importance plots to choose from that have been provided by other Kagglers. A tried and true approach to this is [__recursive feature elimination__](https://en.wikipedia.org/wiki/Feature_selection), where we remove N features (1 <= N < total features) at a time and see how it affects our predictions. If the score goes up we toss those features, or keep them if the score gets worse. Here I use sklearn's [__recursive feature elimination wrapped with cross-validation__](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html) because in my experience it provides a very unbiased estimate of feature importance. Random Forest classifier is used primarily for speed, but you can substitute in there any tree-based method that provides information about feature importance either through a coef attribute or through a feature_importances attribute. \n", "\n", "Sorry about the click-baiting title - the inspiration was [__this famous line__](https://www.youtube.com/watch?v=XT8hE7_8BCY) that just came to me as I was thinking about feature elimination."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "865a0d4b-2b56-459d-aeed-49acbbfd2c99", "collapsed": true, "_uuid": "07d9343742caa492d8fff3acaa0d078eeb09b43d"}, "source": ["__author__ = 'Tilii: https://kaggle.com/tilii7'\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from datetime import datetime\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.feature_selection import RFECV\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import roc_auc_score\n", "\n", "def timer(start_time=None):\n", "    if not start_time:\n", "        start_time = datetime.now()\n", "        return start_time\n", "    elif start_time:\n", "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n", "        print('\\n Time taken: %i minutes and %s seconds.' % (tmin, round(tsec, 2)))\n", "\n", "train = pd.read_csv('../input/train.csv', dtype={'id': np.int32, 'target': np.int8})\n", "X = train.drop(['id', 'target'], axis=1).values\n", "y = train['target'].values\n", "test = pd.read_csv('../input/test.csv', dtype={'id': np.int32})\n", "X_test = test.drop(['id'], axis=1).values\n", "\n", "all_features = [x for x in train.drop(['id', 'target'], axis=1).columns]"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "0327b561-7381-4f79-abec-0ab3a1a64204", "_uuid": "73b351369b0ea8944821f57f5f907a80b544697a"}, "source": ["Here we define Random Forest classifier and RFECV parameters. To test the features properly, it is probably a good idea to change n_estimators to 200 and max_depth=20 (or remove max_depth). It will take longer, on the order of 2 hours, if you choose to do so.\n", "\n", "Yet another important parameter is **step**, which specifies how many features are removed at a time. Setting it to 2-5 usually works well, but set it to 1 if you want to be thorough.\n", "\n", "Note that I am specifying n_jobs=4 because Kaggle provides 4 CPUs per job. You may wish to set that to -1 so that all CPUs on your system are used. Also, the whole countdown will go 5 times because we are doing 5-fold cross-validation."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "4245ced6-a637-4903-a086-7a71dd69e1c2", "collapsed": true, "_uuid": "48648ba686a8ff80698993048691f667d9dcb8f7"}, "source": ["folds = 5\n", "step = 2\n", "\n", "rfc = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=10, n_jobs=4)\n", "\n", "rfecv = RFECV(\n", "              estimator=rfc,\n", "              step=step,\n", "              cv=StratifiedKFold(\n", "                                 n_splits=folds,\n", "                                 shuffle=False,\n", "                                 random_state=1001).split(X,y),\n", "              scoring='roc_auc',\n", "              n_jobs=1,\n", "              verbose=2)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "186fe1bb-25a2-4487-bd27-169761d7a89d", "_uuid": "d424556c8150801a60ef56ebfeea38733df99f44"}, "source": ["We estimate the feature importance and time the whole process."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "c12279b7-a664-41d1-ba34-bca868f9bed6", "collapsed": true, "_uuid": "16178992b0c526626fe960d4021cefd318e4c5fe"}, "source": ["starttime = timer(None)\n", "start_time = timer(None)\n", "rfecv.fit(X, y)\n", "timer(start_time)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "ba7b2eb7-23db-4ef1-9873-c243bcba2608", "_uuid": "6b8b96261671a6bea8d7f5fdb94fb605cbee1c64"}, "source": ["Let's summarize the output."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "37c554b4-eb51-4555-8d30-c3e2a51b6b30", "collapsed": true, "_uuid": "a3d4c70f27e8d457b66c1e716c0d39f83204be68"}, "source": ["print('\\n Optimal number of features: %d' % rfecv.n_features_)\n", "sel_features = [f for f, s in zip(all_features, rfecv.support_) if s]\n", "print('\\n The selected features are {}:'.format(sel_features))"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e4af9fa6-cb3b-42ce-a952-06c059656f1b", "_uuid": "73133184dd479f6884207f86bc86dc425b6bbdea"}, "source": ["Plot number of features vs. CV scores."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "0bc57c13-37a7-412b-a2c7-bd42989ecc37", "collapsed": true, "_uuid": "73aba053a4b43188dc46a2f3f53a6082f19c74e8"}, "source": ["plt.figure(figsize=(12, 9))\n", "plt.xlabel('Number of features tested x 2')\n", "plt.ylabel('Cross-validation score (AUC)')\n", "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n", "plt.savefig('Porto-RFECV-01.png', dpi=150)\n", "plt.show()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "d473901c-8ca6-4c5d-9b0a-97df35ccd0a7", "_uuid": "d463321a26b18b4277cb53882db87508a7b5cea0"}, "source": ["Save sorted feature rankings."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "e6d821dc-f799-4fb8-a2fc-f1e81d0e59fb", "collapsed": true, "_uuid": "c7122eaaa29e73b098c35658519a6c64ed9b5059"}, "source": ["ranking = pd.DataFrame({'Features': all_features})\n", "ranking['Rank'] = np.asarray(rfecv.ranking_)\n", "ranking.sort_values('Rank', inplace=True)\n", "ranking.to_csv('Porto-RFECV-ranking-01.csv', index=False)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "0c04d25d-fe9a-4d94-8e4d-1333e1e91df0", "_uuid": "42d90aae82fc7574423684018de0998e8c092a9d"}, "source": ["Make a prediction. This is only a proof-of-principle as the prediction will likely be poor until more optimal parameters are used above."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "92fc4377-5006-4ab3-8fcb-4cb113e695c5", "collapsed": true, "_uuid": "134f960272cc6469b9a207ec92e866173d52258b"}, "source": ["score = round((np.max(rfecv.grid_scores_) * 2 - 1), 5)\n", "test['target'] = rfecv.predict_proba(X_test)[:,1]\n", "test = test[['id', 'target']]\n", "now = datetime.now()\n", "sub_file = 'submission_5fold-RFECV-RandomForest-01_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n", "print(\"\\n Writing submission file: %s\" % sub_file)\n", "test.to_csv(sub_file, index=False)\n", "timer(starttime)"], "execution_count": null, "cell_type": "code", "outputs": []}]}