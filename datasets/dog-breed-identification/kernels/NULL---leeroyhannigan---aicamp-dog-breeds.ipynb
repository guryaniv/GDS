{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd         #read in csv data\nimport numpy as np \nimport tqdm as tqdm         # graphical representation of progress\nimport cv2 as cv            # Open images\nimport matplotlib.pyplot as plt    # Plot graphs\nimport matplotlib.image as mpimg\n\nfrom keras.layers import Activation, Convolution2D, Flatten, Dense, Dropout\nfrom keras.models import Model, Sequential\nfrom keras.applications import InceptionV3, ResNet50, Xception, VGG16\nfrom keras.optimizers import SGD, RMSprop\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score\n\nfrom numpy.random import seed","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#make directory to put weights\nfrom pathlib import Path\nimport os\n# mkdir -p ~/.keras/models\ncache_dir = Path.home() / '.keras'\nif not cache_dir.exists():\n    os.makedirs(cache_dir)\nmodels_dir = cache_dir / 'models'\nif not models_dir.exists():\n    os.makedirs(models_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06a374cd20f2695de7b176e1af8316aaacd9fd89","collapsed":true},"cell_type":"code","source":"!cp  ../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b8869ca867df3c7ecf61730c23cb99637d620b49"},"cell_type":"code","source":"%matplotlib inline\nseed(seed=1982)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb11b56f2ef65642fb7ed2275c4024f240cde225"},"cell_type":"code","source":"#Create Path\nPATH = '../input/dog-breed-identification/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e60f6502859d10143db10e4a5002142967f2a76","collapsed":true},"cell_type":"code","source":"#Get labels and sample submissions\ntrain_df = pd.read_csv(PATH + 'labels.csv')\ntest_df = pd.read_csv(PATH+'sample_submission.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"43e28a84bb7cc072c197d4a068d75c08f821bd71"},"cell_type":"code","source":"#Declare Variables\nNUM_CLASSES = 16\nIMG_HEIGHT=250\nIMG_WIDTH = 250\n#array for resized images\nimages =[]\n#array for labels\nclasses=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7528dedb719aef4bbb138244cdea2d95a0b16456"},"cell_type":"code","source":"#select 16 breeds\nselected_breeds = list(train_df.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n#Array of images that match our 16 breeds\nsub_df_train =  train_df[train_df.breed.isin(selected_breeds)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25d674bd19f97951953148ca61ffd5101b720a4b","collapsed":true},"cell_type":"code","source":"#Create array of breeds\ntargets = pd.Series(sub_df_train.breed)\ntargets.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b9ab2bbe34176ea16f3f0b27dc1cc8ca513f89b","collapsed":true},"cell_type":"code","source":"#get_dummies changes label strings to numerical vale\none_hot = pd.get_dummies(targets, sparse=True)\none_hot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"814b50444daaf4db408eb1d400b167c3d292b845","collapsed":true},"cell_type":"code","source":"#assign onehot numerical values to numpy array\none_hot_labels = np.asarray(one_hot)\nprint((one_hot_labels[:5]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fe9461eca36355b3d934101d8f09e62985f4df5","collapsed":true},"cell_type":"code","source":"#Get Images, resize and assign to images array\nfor f, breeds in tqdm.tqdm(sub_df_train.values):\n    img= cv.imread('../input/dog-breed-identification/train/{}.jpg'.format(f))        \n    images.append(cv.resize(img, (IMG_HEIGHT,IMG_WIDTH)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8730483f119810cea050dbe1cfd2de3602906b5c","collapsed":true},"cell_type":"code","source":"#assign images and labes to numpy arrays\nclasses = one_hot_labels\nX = np.asarray(images, dtype=np.float32)\nY = np.asarray(classes, dtype=np.uint8)\n\nprint(X.shape)\nprint(Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"89bdd843849488f41b755d0d4332485301f304a3"},"cell_type":"code","source":"#train test split takes train and test data and labels. in this case 70% train, 30% test\nX_train, X_val, y_train, y_val = train_test_split(X,Y, test_size=0.3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3140b0eee0a1a858413a2926ab016ed02b590853"},"cell_type":"code","source":"#declare model\nstarting_model = InceptionV3(include_top=False\n                             ,weights='imagenet'\n                             , input_shape=(IMG_HEIGHT,IMG_WIDTH,3),\n                             classes=NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"51b49bc75f8bde48a4a105835bb944775c420331"},"cell_type":"code","source":"#Add our own layers to the fully connected layer\nmodel = starting_model.output\nmodel = Flatten()(model)\nmodel = Dense(1024, activation='relu')(model)\nmodel = Dropout(0.5)(model)\nmodel = Dense(1024, activation='relu')(model)\n\npredictions = Dense(NUM_CLASSES, activation='softmax')(model)\n\nfinal_model = Model(inputs=[starting_model.input], outputs=[predictions])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"33b107bf14dd7ada6252c69bc591a37514d91bfb"},"cell_type":"code","source":"#compile with grid classifer\nfinal_model.compile(SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ecc7663a23f5688d88ad59c26093644a8b94be5"},"cell_type":"code","source":"#get dataframes\ntrain_datagen = ImageDataGenerator(rescale=1. / 255)\nvalid_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow(X_train, y_train, batch_size=32)\nvalid_generator = valid_datagen.flow(X_val, y_val, batch_size = 32)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fd86e5ffd0109ddb1c64d12355c71717d87e9be8"},"cell_type":"code","source":"#fit model\nfinal_model.fit_generator(train_generator, epochs=30, validation_data=valid_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c1c42f1738dd9b2b238840e6a28f52a53abcdc4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}