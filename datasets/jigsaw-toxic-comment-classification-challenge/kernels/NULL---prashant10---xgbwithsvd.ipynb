{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import pandas as pd\n", "import numpy as np\n", "import re\n", "import nltk\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.metrics import log_loss\n", "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n", "from sklearn import svm\n", "from sklearn.ensemble import RandomForestClassifier\n", "import xgboost as xgb\n", "from sklearn.decomposition import TruncatedSVD\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_cell_guid": "e5825421-3048-4e87-a859-a2248bb93a9a", "_uuid": "fbc088d4976520309d25ad1cb12357202841373f"}}, {"cell_type": "code", "execution_count": null, "source": ["train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")\n", "sampleSubmission = pd.read_csv(\"../input/sample_submission.csv\")"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "6b3055c3-8a40-42fa-9666-462528bb5486", "_uuid": "bd012f975667e886ba1d61eb483fda2e4e691d9d"}}, {"cell_type": "code", "execution_count": null, "source": ["col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n", "trainTxt = train['comment_text']\n", "testTxt = test['comment_text']\n", "trainTxt = trainTxt.fillna(\"unknown\")\n", "testTxt = testTxt.fillna(\"unknown\")"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "179cc113-bfc6-4311-ac49-0dd1f61f6a04", "_uuid": "9c2ca37258371081c246c45267a5c2e8d260f17f"}}, {"cell_type": "code", "execution_count": null, "source": ["combinedTxt = pd.concat([trainTxt,testTxt],axis=0)"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "7e0d90bc-6d41-49cd-b7aa-ab8e0cbdf403", "_uuid": "3cc5948454c3876cae9a22d10f7994d1e9add79b"}}, {"cell_type": "code", "execution_count": null, "source": ["vect = TfidfVectorizer(decode_error='ignore',use_idf=True,smooth_idf=True,min_df=10,ngram_range=(1,3),lowercase=True,\n", "                      stop_words='english')"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "9ab12926-8938-47cb-8c70-710d86f04174", "_uuid": "d075dccbc903590cb08439c4179849f2e2e595a0"}}, {"cell_type": "code", "execution_count": null, "source": ["combinedDtm = vect.fit_transform(combinedTxt) #fit on combine\n", "trainDtm = combinedDtm[:train.shape[0]]\n", "testDtm = vect.transform(testTxt) #transform only test"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "21434a80-de63-44b1-8304-5ea9ff3a658c", "_uuid": "0864159d1607202dbd4d04ab8b56d10191530fdb"}}, {"cell_type": "code", "execution_count": null, "source": ["svd = TruncatedSVD(n_components=50, n_iter=10, random_state=42)\n", "trainDtmSvd = svd.fit_transform(trainDtm)\n", "testDtmSvd = svd.transform(testDtm)"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "11f147b6-f6b7-427b-884e-666e7a74802f", "_uuid": "06dcaa0649eb1a8ba3cf12312ce92d60832b7cea"}}, {"cell_type": "code", "execution_count": null, "source": ["#call fit on every single col value \n", "#normal lr\n", "loss = []\n", "lrpreds = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    lr = LogisticRegression(C=4)\n", "    lr.fit(trainDtm,train[j]) #train[j] is each type of comment\n", "    lrpreds[:,i] = lr.predict_proba(testDtm)[:,1]\n", "    train_preds = lr.predict_proba(trainDtm)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {"_cell_guid": "53f0a61a-94a3-4b93-a893-aef2aa3f1a6a", "_uuid": "50ec5df1aaf7ec596cfa0301f7e561d23f1ce821"}}, {"cell_type": "code", "execution_count": null, "source": ["#lr with Svd\n", "loss = []\n", "lrpredssvd = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    lr = LogisticRegression(C=4)\n", "    lr.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n", "    lrpredssvd[:,i] = lr.predict_proba(testDtmSvd)[:,1]\n", "    train_preds = lr.predict_proba(trainDtmSvd)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {"_cell_guid": "990ca1e0-6198-4de9-8ddb-033b2fc2b4e3", "_uuid": "0655f6fe1c731835134b1be0c58cd0855cf1affe"}}, {"cell_type": "code", "execution_count": null, "source": ["#call fit on every single col value \n", "#normal rf\n", "loss = []\n", "rfpreds = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    rf = RandomForestClassifier(max_depth=10, random_state=123)\n", "    rf.fit(trainDtm,train[j]) #train[j] is each type of comment\n", "    rfpreds[:,i] = rf.predict_proba(testDtm)[:,1]\n", "    train_preds = rf.predict_proba(trainDtm)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["#rf with svd\n", "loss = []\n", "rfpredssvd = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    rf = RandomForestClassifier(max_depth=2, random_state=0)\n", "    rf.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n", "    rfpredssvd[:,i] = rf.predict_proba(testDtmSvd)[:,1]\n", "    train_preds = rf.predict_proba(trainDtmSvd)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {}}, {"cell_type": "code", "execution_count": null, "source": ["#normal xgb\n", "loss = []\n", "xgbpreds = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    xg = xgb.XGBClassifier(max_depth=5, n_estimators=100, colsample_bytree=0.8, \n", "                        subsample=0.8, nthread=10, learning_rate=0.1)\n", "    xg.fit(trainDtm,train[j]) #train[j] is each type of comment\n", "    xgbpreds[:,i] = xg.predict_proba(testDtm)[:,1]\n", "    train_preds = xg.predict_proba(trainDtm)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "991b3f0c-95fe-495b-a174-b6473df903db", "_uuid": "fa682526efb6be6b587ac4d237e41d48adf18f3a"}}, {"cell_type": "code", "execution_count": null, "source": ["#xgb with svd\n", "loss = []\n", "xgbpredssvd = np.zeros((test.shape[0],len(col)))\n", "for i,j in enumerate(col):\n", "    xg = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n", "                        subsample=0.8, nthread=10, learning_rate=0.1)\n", "    xg.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n", "    xgbpredssvd[:,i] = xg.predict_proba(testDtmSvd)[:,1]\n", "    train_preds = xg.predict_proba(trainDtmSvd)[:,1]\n", "    loss.append(log_loss(train[j],train_preds))\n", "np.mean(loss)"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "6fbb7523-9d92-4e19-86af-f10247a06b5b", "_uuid": "b274c44dd3e61b42684d91f36d38809668cd664e"}}, {"cell_type": "code", "execution_count": null, "source": ["# predsMix = 0.6*lrpreds+0.3*xgbpreds+0.1*nbpreds\n", "predsMix = rfpredssvd\n", "predsDf = pd.DataFrame(predsMix,columns = col)\n", "subid = pd.DataFrame({'id':sampleSubmission['id']})\n", "finalPreds = pd.concat([subid,predsDf],axis=1)\n", "finalPreds.to_csv(\"xgbSVDwithLR.csv\",index=False)"], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "7223d4a0-2bfa-4316-85d6-8f3a6162901e", "_uuid": "221cc9df76de73fa95f797dae07a5604c89ad6c9"}}, {"cell_type": "code", "execution_count": null, "source": [], "outputs": [], "metadata": {"collapsed": true, "_cell_guid": "a78c0695-480c-475e-8bc8-daef670ff9c5", "_uuid": "3cb33203358ac9723a1520030e6a3405d2458f47"}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"pygments_lexer": "ipython3", "version": "3.6.3", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python"}}}