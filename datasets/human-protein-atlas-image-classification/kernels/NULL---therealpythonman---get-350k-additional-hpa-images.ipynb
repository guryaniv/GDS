{"cells":[{"metadata":{"_uuid":"9545c1ca1cc10a2cba8f28bf5140e7c934c317c7"},"cell_type":"markdown","source":"**TL;DR: Download up to 70328 additional labeled fluorescent microscopy samples with these 5 images per sample:**\n![](https://i.imgur.com/FEgtFjr.png)"},{"metadata":{"_uuid":"b84f89dc02f2594fa70a6ebe6216294e5f7f31f3"},"cell_type":"markdown","source":"**You can download the segmentation masks [here](https://www.kaggle.com/therealpythonman/hpa-segmentation-masks) (4GB, full size PNG) and 264k intensity images [here](https://www.kaggle.com/therealpythonman/hpa-intensities-512x512) (8GB JPEG, rescaled to 512x512). Please consider downloading from there as crawling HPA again and again might impact their traffic a bit.**"},{"metadata":{"_uuid":"c8638b2759c6e9f8c2f7026dd5c35db97e87ea4e"},"cell_type":"markdown","source":"When visiting sites of the [Human Protein Atlas](https://www.proteinatlas.org/ENSG00000120159-CAAP1/cell#human), you might also have noticed these buttons that segment the cells in the image and show much more detailed intensity information of the four RGBY channels:\n![](https://i.imgur.com/0ZNjsgQ.gif)"},{"metadata":{"_uuid":"223180899a4c681f6cdb3422baf1f7d135031cbd"},"cell_type":"markdown","source":"While [HPA's download page](https://www.proteinatlas.org/about/download) mentions downloadable data and [this thread](https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/69984) offers some code to download the RGBY images, we have not found a way to download the segmentation masks and the intensity images. After observing the network traffic with HPA, we developed the following script to download the extra 70k labeled samples as well as their segmentation maps and intensity images:"},{"metadata":{"_uuid":"48b17e5ed71eb1a72532c17268b7a2d591ee0015"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"0d25eb7c0a5819643a64a37cb15988532b1e8e0f"},"cell_type":"code","source":"# Download all data from the Human Protein Atlas in XML format\n!wget https://www.proteinatlas.org/download/proteinatlas.xml.gz ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78740cf44e963caabdd8c14351664725b28fb6d8"},"cell_type":"code","source":"# There is more (temporary) space\n!mv proteinatlas.xml.gz /","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54d2eae851a242a261875cb88240f582f33d4231"},"cell_type":"code","source":"# Unzip it\n!gzip -d /proteinatlas.xml.gz","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"import xml.etree.ElementTree as etree\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom skimage import io\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import defaultdict\n\nPROTEINATLAS_XML_PATH = \"/proteinatlas.xml\"\nTRAIN_EXTRA_PATH = \"train_extra.csv\"\n\ncounter = 0\npbar = tqdm(total=70328)\ndata = []\nother_labels = defaultdict(int)\n\n# There are more labels in the extra training data than there are in the official training data\nname_to_label_dict = {'nucleoplasm': 0, 'nuclear membrane': 1, 'nucleoli': 2, 'nucleoli fibrillar center': 3,\n                      'nuclear speckles': 4, 'nuclear bodies': 5, 'endoplasmic reticulum': 6, 'golgi apparatus': 7,\n                      'peroxisomes': 8, 'endosomes': 9, 'lysosomes': 10, 'intermediate filaments': 11,\n                      'actin filaments': 12, 'focal adhesion sites': 13, 'microtubules': 14, 'microtubule ends': 15,\n                      'cytokinetic bridge': 16, 'mitotic spindle': 17, 'microtubule organizing center': 18,\n                      'centrosome': 19, 'lipid droplets': 20, 'plasma membrane': 21, 'cell junctions': 22,\n                      'mitochondria': 23, 'aggresome': 24, 'cytosol': 25, 'cytoplasmic bodies': 26,\n                      'rods & rings': 27, 'midbody': [16, 12], 'midbody ring': [16, 12], 'cleavage furrow': 16, 'vesicles': [8, 9, 10, 20]}\n\n# Iterate over the XML file (since parsing it in one run might blow up the memory)\nfor event, elem in etree.iterparse(PROTEINATLAS_XML_PATH, events=('start', 'end', 'start-ns', 'end-ns')):\n    if event == 'start':\n        if elem.tag == \"data\" and len({\"location\", \"assayImage\"} - set([c.tag for c in elem.getchildren()])) == 0:\n            labels = []\n            assay_image = None\n            for c in elem.getchildren():\n                if c.tag == 'assayImage':\n                    assay_image = c\n                if c.tag == 'location':\n                    if c.text in name_to_label_dict:\n                        label = name_to_label_dict[c.text]\n                        if type(label) is int:\n                           labels.append(label)\n                        else:\n                            for l in label:\n                                labels.append(l)\n                    else:\n                        other_labels[c.text] += 1\n            if not labels:\n                # Let's ignore images that do not have labels\n                continue\n            for image in assay_image.getchildren():\n                if len(image.getchildren()) < 4 or image.getchildren()[-1].text is None:\n                    continue\n                image_url = image.getchildren()[-1].text\n                assert \"blue_red_green\" in image_url\n                for channel, color, object_ in zip(image.getchildren()[:-1], [\"blue\", \"red\", \"green\"], [\"nucleus\", \"microtubules\", \"antibody\"]):\n                    assert channel.text == object_\n                    assert channel.attrib[\"color\"] == color\n\n                # \"https://v18.proteinatlas.org/images/4109/24_H11_1_blue_red_green_yellow.jpg\" -> \"4109/24_H11_1\"\n                data.append([\"/\".join(image_url.split(\"/\")[-2:]).replace(\"_blue_red_green.jpg\", \"\"), \" \".join(str(x) for x in sorted(labels, reverse=True))])\n                counter += 1\n                pbar.update()\n        # This is necessary to free up memory\n        elem.clear()\nprint(counter)\n# Samples are also labeled with 'nucleus', which can not be translated into official labels\nprint(other_labels)\n\ndf = pd.DataFrame(data=data, columns=[\"Id\", \"Target\"])\ndf.to_csv(TRAIN_EXTRA_PATH, index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58ce6e4a5abc14a9f195319c3f785a870824f844"},"cell_type":"code","source":"hpa_base = \"https://v18.proteinatlas.org/images\"\ntitles = [\"RGBY\", \"Segmentation\", \"Intensity Green\", \"Intensity Blue\", \"Intensity Red\", \"Intensity Yellow\"]\nurls = [\"/{}_blue_red_green_yellow.jpg\", \"_cell_segmentation/{}_segmentation.png\", \"/{}_green_lut.jpg\", \"/{}_blue_lut.jpg\", \"/{}_red_lut.jpg\", \"/{}_yellow_lut.jpg\"]\n_, axes = plt.subplots(nrows=1, ncols=len(urls), figsize=(5 * len(urls), 5))\nfor index, (title, url) in enumerate(zip(titles, urls)):\n    image = io.imread(hpa_base + url.format(df.loc[0, \"Id\"]))\n    axes[index].imshow(image)\n    axes[index].set_title(title)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fcc1e17fde7450e66d353a300d146cf164fa4ea"},"cell_type":"markdown","source":"We hope this might help the one or other.  \nHappy hacking!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}