{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport torch\nfrom torch import nn\nfrom torch import utils\nfrom torch.utils.data import DataLoader\nimport numpy as np\nimport json\nfrom torch.autograd import Variable\nimport matplotlib.pyplot as plt\nimport csv\n\n#Custom weight init\ndef initi(m):\n    if isinstance(m,nn.Linear):\n        nn.init.xavier_uniform(m.weight.data)\n        \n\n#Simple json load\nwith open('../input/train.json') as f:\n    train = json.load(f)\n        \nwith open('../input/test.json') as f:\n    test = json.load(f)\n    \nprint ('imported')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48a08e7edc7f1f8eaf3f827169584eca4fe1b23d","collapsed":true},"cell_type":"code","source":"#Randomise the arrangment of the training set in case it is biased\n# i.e: Starts with all italian recepies, then mexican, etc. \n# It's useful because we split into training and validation sets later in the code\nfrom random import shuffle\nshuffle(train)\n\nxx=[d['ingredients'] for d in train]\nyy=[d['cuisine'] for d in train]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3b0dc0a28de9bda4c7ce62c28600b047e118cae"},"cell_type":"code","source":"#Converting into One Hot Vector:\n# representation of array like [0,0,0,0,1,0,0...0] \n#  where 1 rerpresents the existance of an ingredient out of the entire ingredient list\n\n#Make the list of ingredients\nword_list=set()\nfor x in xx:\n    word_list|=set(tuple(x))\nword_list=list(word_list)\n#Make the list of cuisines \n\ncat_list=list(set(yy))\n            \n'''\nThe more an ingredient is showing up in a single category, the bigger it's weight is\nThe more an ingredient is showing up in multiple categories, the smaller it's weight is\nLets start with only second term.\n\ning_recep_count=[]\nfor ing in word_list:\n    cuis_list=[]\n    for recep in train:\n        if ing in recep['ingredients']:\n            if recep['cuisine'] not in cuis_list:\n                cuis_list.append(recep['cuisine'])\n    ing_recep_count.append(len(cuis_list))\n#This just doesn't work :(\n'''\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d4b0843d3fb335c10a35a1b3419b0a535473bf5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e8d72159eb6567cc2e74535701918fdfa527dd1","collapsed":true},"cell_type":"code","source":"#new_word_list=[ing for ing in word_list if ing_recep_count[word_list.index(ing)]!=20]\n#print (len (new_word_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2a4e01821af01f7eb83a5eb8b5d5ee25d16d858"},"cell_type":"code","source":"#Make the one hot vector\nnewx=[]\nfor num,rec in enumerate(xx):\n    newx.append(np.zeros(len(word_list)))\n    for ing in rec:\n        if ing in word_list:\n            ing_location=word_list.index(ing)\n            #newx[num][ing_location]=1/(ing_recep_count[ing_location])\n            newx[num][ing_location]=1\nnewx=np.array(newx)\n\n\n#Convert the cuisines to numerical representation\nnewy2=[]\nfor num,rec in enumerate(yy):\n    newy2.append(cat_list.index(rec))\nnewy2=np.array(newy2)\n\nprint ('First 3 recepies of one hot vectors')\nprint (newx[0:5])\n\nprint ('First 5 cuisines in numerical')\nprint (newy2[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66c83a12e287050437273c505669d82b30ff9c2c"},"cell_type":"code","source":"def stats(prevloss):\n    train_loss_history.append(loss.data[0])\n    #How does it look in our validation set?\n    valpred=model(txval)\n    valloss=loss_fn(valpred,tyval)\n    val_loss_history.append(valloss.data[0])\n    actualy=tyval.cpu().data.numpy()\n    predy=valpred.cpu().data.numpy()\n    val_accuracy=(np.argmax(predy,axis=1)==actualy).sum()/len(predy)\n    val_accuracy_history.append(val_accuracy)\n    if t%10==0:\n        print ('Iteration # %s'%t)\n        print ('Current valdiation loss')\n        print (round(valloss.data[0],2))\n        print ('Previous validation loss')\n        print (round(prevloss,2))\n        print ('Validation accuracy: {} %'.format(round(100*val_accuracy,3)))    \n    '''if prevloss<valloss.data[0]:\n        if steps_back<2:\n            steps_back+=1\n            print ('loss increasing')\n            print (steps_back)\n        else:\n            print ('im breaking!')\n            #break\n    else:\n        steps_back=0\n    '''\n    #if np.abs(prevloss-valloss.data[0])<0.000001:\n    #    print ('breaking beacuse {} and {} are very similar'.format(round(prevloss,6),round(valloss.data[0],6)))\n    #    break\n    prevloss=valloss.data[0]\n    return (prevloss)\n\n    #Save validation loss\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb0d06770353308f93ed543e1d0931230aebf362"},"cell_type":"code","source":"dtype = torch.cuda.FloatTensor\nSPLIT = 0.8\n#Splitting into training and validation sets with SPLIT amount\ntv=int(np.ceil(len(newx)*SPLIT))\nxtrain=newx[0:tv]\nytrain=newy2[0:tv]\nxval=newx[tv:]\nyval=newy2[tv:]\n\n'''\nxtrain=newx\nytrain=newy2\n'''\n\n#Convert to tensors and variables\ntxval=Variable(torch.from_numpy(xval.astype(float)).float()).type(dtype)\ntyval=Variable(torch.from_numpy(yval.astype(float)).long()).cuda()\ntx=Variable(torch.from_numpy(xtrain.astype(float)).float()).type(dtype)\nty=Variable(torch.from_numpy(ytrain.astype(float)).long()).cuda()\n#tx=Variable(loader_train.__iter__().next()[0]).type(dtype)\n#tx=tx.cuda()\nprint (tx.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed47ae5d0224f4c977abfb874fe5aac1907ae1a6"},"cell_type":"code","source":"batch_size=50\n\n#Our \"deep\" model\nmodel= nn.Sequential(\n    nn.Linear(6714,20),\n    nn.LeakyReLU(),\n)\nmodel.cuda()\nmodel.zero_grad()\nmodel.apply(initi)\n\n#The loss\nloss_fn=nn.CrossEntropyLoss()\nprint ('built new model')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0821f3224ce18029693a557cbd2b88239d48c115"},"cell_type":"code","source":"lr=1e-4\n#The optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=lr,betas=(0.9,0.99))\n#optimizer = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99,\n#                                eps=1e-08, weight_decay=0.000001, momentum=0, centered=False)\noptimizer.zero_grad()\nprint ('made new optimizer')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6ea24ab9c4b588ff03ea87bd98afa9d03f9e612f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"36cf9b411da934cc94af6b4cd8e3b30b82cdfcf4"},"cell_type":"code","source":"epochs=170\nitt=0\ntrain_loss_history=[]\nval_loss_history=[]\nval_accuracy_history=[]\nprevloss=90\nsteps_back=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee7b0a1326f71be558a2dcf70e55dfd59b7b924f","scrolled":false},"cell_type":"code","source":"for t in range(epochs):\n    itt=0   \n    for curr in range(batch_size,len(tx),batch_size):\n        #Split\n        x=tx[itt:curr]\n        y=ty[itt:curr]\n\n        #Predict\n        pred=model(x)\n\n        #How well we predicted\n        loss=loss_fn(pred,y)\n\n        optimizer.zero_grad()\n        #What should we do next to be better\n        loss.backward()\n\n        #Try to be better next time\n        optimizer.step()\n        itt+=batch_size\n        \n    prevloss=stats(prevloss)\n\n    #Save train loss\n\n\nprint ('Trained!')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c50091156ece2f6884411277f07765aafe54acbb","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f765ac1e0fdb79769565aa947086722f1c48f05e"},"cell_type":"code","source":"curcurr=range(len(val_loss_history))\nplt.plot(curcurr,train_loss_history,'.r',label='Train loss')\nplt.plot(curcurr,val_loss_history,'+b',label='Validation loss')\nplt.plot(curcurr,val_accuracy_history,'*g',label='Validation accuracy')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f388e349e5727ac74bd160b608272ccb634de059","collapsed":true},"cell_type":"code","source":"#Load test set\nxx=[d['ingredients'] for d in test]\n\n#One hot that boi\ntestx=[]\nfor num,rec in enumerate(xx):\n    testx.append(np.zeros(len(word_list)))\n    for ing in rec:\n        if ing in word_list:\n            testx[num][word_list.index(ing)]=1\ntestx=np.array(testx)\n\n#Make tensor and predict\ntestx=torch.from_numpy(testx.astype(float)).float()\ntestx=Variable(testx).type(dtype)\npred=model(testx)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f37c3d961e5709821404de7166f3831483239610","collapsed":true},"cell_type":"code","source":"results1=pred.data.cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ff6d8c894bef2aea26884949de4a132b184faae"},"cell_type":"code","source":"#Convert to format\nanswers=[]\nfor num,val in enumerate(test):\n    answers.append(str(val['id'])+','+cat_list[int(np.argmax(results1[num]))])\n\nanswers.insert(0,'id,cuisine')\nprint ('predicted!')\nprint (answers[17])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85554aaf3a9020e85b18e382d0d226dfe5bebcc8","collapsed":true},"cell_type":"code","source":"np.savetxt(\"one_layer_1000_epoch.csv\", answers, delimiter=\",\", fmt='%s')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}