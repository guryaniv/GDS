{"cells":[{"metadata":{"_uuid":"e840879c007f7768c08c519e6b0ab7bbf25e4f19"},"cell_type":"markdown","source":"# Plant Seedlings Classification\nChallenge is to differentiate a weed from a crop seedling"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Import all general libraries\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nimport glob\n\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ba6dc1e8dad936e96f0fec304e847b6a398592"},"cell_type":"code","source":"#This function will return all training image paths and corrosponding lebels were collected in Series object\n\ndef train_impath():\n    impaths = [f for f in glob.glob(\"../input/train/*\")]\n    label = pd.Series(impaths).str.split('/').apply(lambda x:x[-1])\n\n    imagePaths = []\n    for lab in label:\n        imp = [f for f in glob.glob(\"../input/train/\"+lab+\"/*.png\")]\n        imagePaths.extend(imp)\n    imagePaths = pd.Series(imagePaths)\n    labels = pd.Series(imagePaths).str.split('/').apply(lambda x:x[3])\n    labels = pd.Series(labels)\n    return labels, imagePaths","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"284b8fce60770b5cea389cac007e832ec1988603"},"cell_type":"code","source":"impaths = [f for f in glob.glob(\"../input/train/*\")]\npd.Series(impaths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cea34301428a55a83e03b72b46751b3b4d1ba55f"},"cell_type":"code","source":"#This function will return all training image paths were collected in Series object\n#No labels. we will find them. thats our challenge\ndef test_impath():\n    labels = pd.read_csv('../input/sample_submission.csv')\n    lab = labels.iloc[:,0].tolist()\n\n    data_dir = []\n    for l in lab:\n        t_dir = \"../input/test/\"+l\n        data_dir.append(t_dir)\n    return data_dir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e80783ca7fd649c8ee1b061f5b35b9557361f2e5"},"cell_type":"code","source":"#Calling both functions above and get lebels for training data set and training and test image PATHS\n#Note: we will encode all the labels later by using onehot encoding\nlabels, train_impaths = train_impath()\ntest_impaths = test_impath()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"290245a6092b9577a27486210642c6968e83d86f"},"cell_type":"code","source":"#Now all image paths and lebels are taken. Using keras preprocessing tools we are going to read all images in those paths\n#This function will read image and return them as ndarray(). Before return images will be normalized by deviding 255. Normalaizing will help to reduce the number value and will save computational cost\n#image load by using keras model\nfrom keras.preprocessing import image\ndef im_read(impaths):\n    df = []\n    for path_ in impaths:\n        img = image.load_img(path=path_,target_size=(224,224,3))\n        img = image.img_to_array(img)\n        df.append(img)\n    return np.array(df, dtype=float)/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8db8a7ec52e1a8f5eef612da595a052e3812f18e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29e55c339a7571760dad64c21fd7a9db475a2269"},"cell_type":"code","source":"#Calling keras image read function and load train and test iamges\nX = im_read(train_impaths)\nX_ts = im_read(test_impaths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1cafc132514a486368efc6af7a25e62316ad75f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4a7b056358ba965619766e5c5300950e21bfa38"},"cell_type":"code","source":"#Sample image show\nplt.imshow(X[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd544058e817b93cdc0a1250741df764878b34f5"},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{"trusted":true,"_uuid":"387cb31ef7a44500fe3570654d75e4c1bf602f80"},"cell_type":"code","source":"#labels were loaded few cells before and were mentioned that we need to encode them by using onehot encoding\n#All the lebels need to be encoded as a matrix/ndarray. For instance if label is '1' and total number of calss is 3. '1' need to be encoded as [1,0,0] for the first image/observation as lebeled '1'\n#Sklearn OneHotEncoder and LebelEncoder is a very good tools to encode labels\n#In this problem we are using LabelEncoder\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nle = LabelEncoder()\n\nlabels_encod = labels.value_counts().index.sort_values()\n\nle = le.fit(labels_encod)\nlabels = le.transform(labels)\nlabels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe59554d08a8fe90cc601d213f073dd3e6551d5f"},"cell_type":"code","source":"#All the lebels are converted in numberse. Now we need to do oneHot encoding which will convert them as ndarray\nfrom keras.utils import to_categorical as tc\nY = tc(labels,num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2abb786128b3a61ff44449d5d59ea997db2fb0f"},"cell_type":"code","source":"#Model has been designed using transfer learning approach. VGG16 model was used and layers from input to 'fc2' were take and a custom layer was added as it requires to fit our problem.\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import decode_predictions\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\n\ninput_ = Input(shape=(224, 224, 3))\n\nmodel = VGG16(input_tensor=input_)\nmodel.summary()\n\nnumber_of_class=12\nvgg16_fc2 = model.get_layer('fc2').output\nMy_out_layer = Dense(number_of_class, activation='softmax',name = 'custome_layer1')(vgg16_fc2)\n\nMy_model = Model(input_,My_out_layer)\nMy_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1a8a67c97e04bf260cbae201786f071b44cf843"},"cell_type":"code","source":"#All VGG16 layers are set as non-trainable and only custom layer will be open to train\nfor layer in My_model.layers[:-1]:\n    layer.trainable = False\nMy_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71ef2409dc60e0c868b3ee747ce3bc70ee184541"},"cell_type":"code","source":"#SGD optimization was used as a suitable optimization technique for this proble.\nfrom keras import optimizers\nopt = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\nMy_model.compile(optimizer = opt , loss = 'mse', metrics=['mae','accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"670d944549a189b8dc6c51ff7d2df32927da1319"},"cell_type":"code","source":"#Fit model: Here all the input parameter(images) will be fit with there corresponding labels\nMy_model.fit(X, Y, epochs=1, batch_size=30,validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50b96af4681995d45a271725d1fc0fcb2da07f24"},"cell_type":"code","source":"#Predict labels from test images. It will return an array of float values for each test image. That array will contain probability for each catagory\nY_ts = My_model.predict(X_ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d8241b52b96cf1558c34fa1294cb05922bdb99b"},"cell_type":"code","source":"# select the indix with the maximum probability which will be assigned as the label for each of the images\nresults = np.argmax(Y_ts,axis = 1)\n\nresults = le.inverse_transform(results)\nresults = pd.Series(results, name='species')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a314f8103096a90113909fa746df6ceb2ee4d0c7"},"cell_type":"code","source":"labels = pd.read_csv('../input/sample_submission.csv')\nlab = labels.iloc[:,0].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c48aa907cfee7fe5d93282245addc5c3062fcd13"},"cell_type":"code","source":"file = pd.Series(lab,name=\"file\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9857a828bf6cf86949efeeec32b06f837089ec8e"},"cell_type":"code","source":"sub = pd.concat([pd.DataFrame(file),pd.DataFrame(results)],axis=1, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa6b0c3713a586efa06b2c7804b8ab6ffdcc2237"},"cell_type":"code","source":"sub.to_csv('sub11.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}