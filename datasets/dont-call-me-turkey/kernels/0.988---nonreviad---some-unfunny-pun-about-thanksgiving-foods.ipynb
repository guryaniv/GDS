{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n# No, really, that's it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"555891975036558cfd78328b032dcab9c417f114"},"cell_type":"code","source":"# Could've been done with keras' pad_sequences, but why do it the simple way? Life's too short\ndef normalise_and_pad(sequence):\n    ret = np.pad(np.array(sequence) / 255.0, ((0, 10-len(sequence)),(0,0)), 'wrap')\n    return ret","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df82bc38aace0ddd7eae40ec0e8135ad67b72ae0"},"cell_type":"code","source":"df = pd.read_json('../input/train.json')\nx_train = np.asarray([normalise_and_pad(x) for x in df['audio_embedding']])\ny_train = df['is_turkey'].values\n\n# Split the data into 60% training, 20% cross-validation, 20% test\nx_train, x_crossvalidation, y_train, y_crossvalidation = train_test_split(x_train, y_train, test_size=0.2)\nx_crossvalidation, x_test, y_crossvalidation, y_test = train_test_split(x_crossvalidation, y_crossvalidation, test_size=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34ff881c931b4a56abca6e7ba713e014aea50eda"},"cell_type":"code","source":"def cnn_model():\n    dropout = 0.2\n\n    activation = keras.activations.elu\n\n    input_layer = keras.layers.Input(shape=(10,128))\n    conv_1 = keras.layers.Conv1D(256, 1, activation=activation, padding='causal')(input_layer)\n    maxpool_1 = keras.layers.MaxPool1D()(conv_1)\n    \n    conv_2 = keras.layers.Conv1D(512, 3, activation=activation, padding='causal')(maxpool_1)\n    maxpool_2 = keras.layers.MaxPool1D()(conv_2)\n\n    conv_3 = keras.layers.Conv1D(1024, 1, activation=activation, padding='causal')(maxpool_2)\n    maxpool_3 = keras.layers.MaxPool1D()(conv_3)\n\n    flattened = keras.layers.Flatten()(maxpool_3) \n    fc1 = keras.layers.Dense(256, activation=activation)(flattened)\n    fc1 = keras.layers.Dropout(rate=dropout)(fc1)\n\n    fc2 = keras.layers.Dense(128, activation=activation)(fc1)\n    fc2 = keras.layers.Dropout(rate=dropout)(fc2)\n\n    dense_out = keras.layers.Dense(1, activation='sigmoid')(fc2)\n    model = keras.models.Model(input_layer, dense_out)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6684ddc094b404d1522caa5927100c987a978413","scrolled":false},"cell_type":"code","source":"def try_model(model, batch_size=64, epochs=40):\n    checkpointer = keras.callbacks.ModelCheckpoint(filepath='./weights.hdf5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n\n    model.fit(x_train, y_train, epochs=epochs, callbacks=[checkpointer], batch_size=batch_size, validation_data=(x_crossvalidation, y_crossvalidation))\n    model.load_weights('./weights.hdf5')\n    _, train_acc = model.evaluate(x_train, y_train)\n    _, cv_acc = model.evaluate(x_crossvalidation, y_crossvalidation)\n    _, test_acc = model.evaluate(x_test, y_test)\n    print (\"Training         accuracy is {}%\".format(train_acc * 100))\n    print (\"Cross-validation accuracy is {}%\".format(cv_acc * 100))\n    print (\"Hold-out test    accuracy is {}%\".format(test_acc * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41113c049e9d39b3535ff2e5365292eaf5495e8d"},"cell_type":"code","source":"def gru_model():\n    dropout = 0.2\n    input_layer = keras.layers.Input(shape=(10,128))\n    gru_out = keras.layers.Bidirectional(keras.layers.GRU(128, dropout=dropout, recurrent_dropout=dropout))(input_layer)\n    dense_out = keras.layers.Dense(1, activation='sigmoid')(gru_out)\n    model = keras.models.Model(input_layer, dense_out)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bf8dd64ade92e8bcd5d109c6f3ab19fff63b87c"},"cell_type":"code","source":"def lstm_model():\n    dropout = 0.2\n    input_layer = keras.layers.Input(shape=(10,128))\n    lstm_out = keras.layers.LSTM(128, dropout=dropout, recurrent_dropout=dropout)(input_layer)\n    dense_out = keras.layers.Dense(1, activation='sigmoid')(lstm_out)\n    model = keras.models.Model(input_layer, dense_out)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9f6515b674b502dcd580f143df33ef03fd230f9"},"cell_type":"code","source":"def blend_models(models, x):\n    ys = np.zeros((x.shape[0],1))\n    for model in models:\n        ys += model.predict(x)\n    ys /= len(models)\n    return ys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b1bd9a0629ed5f80a5d147e2f6f2dfaf929e9bd"},"cell_type":"code","source":"# let's try out some stuff\ncranberry_neural_network = cnn_model() # forced pun, I know\ntry_model(cranberry_neural_network, batch_size=512, epochs=100) # how good is it anyway?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"c17ccd1fadf48be4f44874cf66f3c3278f0db665"},"cell_type":"code","source":"gobbling_recurrent_unit = gru_model() # less of a pun, more of a WTF\ntry_model(gobbling_recurrent_unit, batch_size=512, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b22e375b7fc897f6fc546830ee1f0c602e90205a"},"cell_type":"code","source":"long_short_turkey_memory = lstm_model()\ntry_model(long_short_turkey_memory, batch_size=512, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ad59ec900c25e5cb7ce38c035db6f8c2bb8db9c"},"cell_type":"code","source":"def test_blend(models):\n    y1 = blend_models(models, x_train)\n    y2 = blend_models(models, x_crossvalidation)\n    y3 = blend_models(models, x_test)\n    print (\"Blended train accuracy            {}%\".format(roc_auc_score(y_train, y1) * 100))\n    print (\"Blended cross-validation accuracy {}%\".format(roc_auc_score(y_crossvalidation, y2) * 100))\n    print (\"Blended test accuracy             {}%\".format(roc_auc_score(y_test, y3) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"069a24aa23407021e32fe38ed2a76f594dc82bfa"},"cell_type":"code","source":"all_models = [cranberry_neural_network, gobbling_recurrent_unit, long_short_turkey_memory]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab1a54a06f53534d3321d175dac03ab06b9efb3d"},"cell_type":"code","source":"test_blend(all_models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81ff9f923c735f142a9ca1d6a6d988e02526cada"},"cell_type":"code","source":"df_test = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6373231c747516e146e6333bad098be2f87760bc"},"cell_type":"code","source":"x_submission = np.asarray([normalise_and_pad(x) for x in df_test['audio_embedding']])\ny_pred = blend_models(all_models, x_submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9a4c3e79384800d140fae628c87261569df932a"},"cell_type":"code","source":"df_out = pd.DataFrame({'vid_id':df_test['vid_id'],'is_turkey':[x[0] for x in y_pred]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ed3e85442b6bf84b459e45de49be3be84f29dfa"},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}