{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def read_data(path):\n    data=pd.read_csv(path)\n    print(data.shape)\n    print(data.head())\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"795ecde123a3bab1a0423192e73fba92bead1e56"},"cell_type":"code","source":"application_train=read_data(\"../input/application_train.csv\")\nPOS_CASH_balance=read_data(\"../input/POS_CASH_balance.csv\")\nbureau_balance=read_data(\"../input/bureau_balance.csv\")\nprevious_application=read_data(\"../input/previous_application.csv\")\ninstallments_payments=read_data(\"../input/installments_payments.csv\")\ncredit_card_balance=read_data(\"../input/credit_card_balance.csv\")\nsample_submission=read_data(\"../input/sample_submission.csv\")\napplication_test=read_data(\"../input/application_test.csv\")\nbureau=read_data(\"../input/bureau.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5e7a19b5906bf2363df31fff448b7ab25aea652"},"cell_type":"code","source":"application_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8680cab76fa966ea4b02c6da407a79118b9c3b54"},"cell_type":"code","source":"application_train['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15f124ab7c6b00811b1775c2fe6947ce7f046cc7"},"cell_type":"code","source":"#More Negative then positive values,so F1 will be a better measure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2273bfe8c700b77a74ccdaaadd9779bb5b9b8ef"},"cell_type":"code","source":"application_train['TARGET'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f652d33f8b5ef03e1abac1b5ab2df960cb3c63f4"},"cell_type":"code","source":"((application_train.isnull().sum().sort_values(ascending=False).head(10))/len(application_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f03adbbc446b3997b8f7210c03bafb73fec316a"},"cell_type":"code","source":"def null_percent(df):\n    df_null_count=df.isnull().sum().sort_values(ascending=False)\n    df_percent=(100 * df.isnull().sum() / len(df)).sort_values(ascending=False)\n    mis_val_table = pd.concat([df_null_count, df_percent], axis=1)\n    mis_val_table.rename(columns = {0 : 'Missing_Values', 1 : '% of Total Values'},inplace=True)\n    return mis_val_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53d96261e492911ca664168c4870042c04bdb3bb"},"cell_type":"code","source":"null_detail=null_percent(application_train)\nnull_detail[null_detail.Missing_Values>0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"262da1cd81a2472a107536be622b695dbb16c4ce"},"cell_type":"markdown","source":"When it comes time to build our machine learning models,\nwe will have to fill in these missing values (known as imputation). \nIn later work, we will use models such as XGBoost that can handle\nmissing values with no need for imputation. Another option would be to\ndrop columns with a high percentage of missing values, although it is \nimpossible to know ahead of time if these columns will be helpful to \nour model. Therefore, we will keep all of the columns for now."},{"metadata":{"trusted":true,"_uuid":"25268f2e8a4922f3d57ff156cfb01835f04ee91b"},"cell_type":"code","source":"application_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4ad63701ea3d8b46b1c2f004481f602e9a21d1b"},"cell_type":"code","source":"application_train.select_dtypes('object').apply(pd.Series.nunique, axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7e1a651936c9ac6eec25cde0e6106ded353739fb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}