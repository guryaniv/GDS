{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b76f41dc-eac5-89dc-48f1-0ca4fb5a7c71"
      },
      "outputs": [],
      "source": [
        "\n",
        "del testimport numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import itertools \n",
        "import csv\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from gensim.models import word2vec\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "sns.set_context(\"paper\")\n",
        "%matplotlib inline\n",
        "\n",
        "RES_DIR = \"../input/\"\n",
        "# Load train data (skips the content column)\n",
        "def load_train_data():\n",
        "    categories = ['cooking', 'robotics', 'travel', 'crypto', 'diy', 'biology']\n",
        "    train_data = []\n",
        "    for cat in categories:\n",
        "        data = pd.read_csv(\"{}{}.csv\".format(RES_DIR, cat), usecols=['id', 'title', 'tags','content'])\n",
        "        data['category'] = cat\n",
        "        train_data.append(data)\n",
        "    \n",
        "    return pd.concat(train_data)\n",
        "data = load_train_data()\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "data=data.sample(3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bb34c73c-dcba-aad3-43ae-39c252ee2ae5"
      },
      "outputs": [],
      "source": [
        "uri_re = r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\u00ab\u00bb\u201c\u201d\u2018\u2019]))'\n",
        "\n",
        "def stripTagsAndUris(x):\n",
        "    if x:\n",
        "        # BeautifulSoup on content\n",
        "        soup = BeautifulSoup(x, \"html.parser\")\n",
        "        # Stripping all <code> tags with their content if any\n",
        "        if soup.code:\n",
        "            soup.code.decompose()\n",
        "        # Get all the text out of the html\n",
        "        text =  soup.get_text()\n",
        "        # Returning text stripping out all uris\n",
        "        return re.sub(uri_re, \"\", text)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# This could take a while\n",
        "data[\"title\"] = data[\"title\"].map(stripTagsAndUris)\n",
        "data[\"content\"] = data[\"content\"].map(stripTagsAndUris)\n",
        "import string\n",
        "print(data.head())\n",
        "\n",
        "def removePunctuation(x):\n",
        "    # Lowercasing all words\n",
        "    x = x.lower()\n",
        "    # Removing non ASCII chars\n",
        "    #x = re.sub(r'[^\\x00-\\x7f]',r' ',x)\n",
        "    # Removing (replacing with empty spaces actually) all the punctuations\n",
        "    return re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n",
        "\n",
        "# point questionmarks etc\n",
        "data[\"title\"] = data[\"title\"].map(removePunctuation)\n",
        "data[\"content\"] = data[\"content\"].map(removePunctuation)\n",
        "#data = clean_dataframe(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8bfda00f-6c8d-67ba-b03f-4632d550354b"
      },
      "outputs": [],
      "source": [
        "from gensim.parsing import PorterStemmer\n",
        "global_stemmer = PorterStemmer()\n",
        " \n",
        "class StemmingHelper(object):\n",
        "    \"\"\"\n",
        "    Class to aid the stemming process - from word to stemmed form,\n",
        "    and vice versa.\n",
        "    The 'original' form of a stemmed word will be returned as the\n",
        "    form in which its been used the most number of times in the text.\n",
        "    \"\"\"\n",
        " \n",
        "    #This reverse lookup will remember the original forms of the stemmed\n",
        "    #words\n",
        "    word_lookup = {}\n",
        " \n",
        "    @classmethod\n",
        "    def stem(cls, word):\n",
        "        \"\"\"\n",
        "        Stems a word and updates the reverse lookup.\n",
        "        \"\"\"\n",
        " \n",
        "        #Stem the word\n",
        "        stemmed = global_stemmer.stem(word)\n",
        " \n",
        "        #Update the word lookup\n",
        "        if stemmed not in cls.word_lookup:\n",
        "            cls.word_lookup[stemmed] = {}\n",
        "        cls.word_lookup[stemmed][word] = (\n",
        "            cls.word_lookup[stemmed].get(word, 0) + 1)\n",
        " \n",
        "        return stemmed\n",
        " \n",
        "    @classmethod\n",
        "    def original_form(cls, word):\n",
        "        \"\"\"\n",
        "        Returns original form of a word given the stemmed version,\n",
        "        as stored in the word lookup.\n",
        "        \"\"\"\n",
        " \n",
        "        if word in cls.word_lookup:\n",
        "            return max(cls.word_lookup[word].keys(),\n",
        "                       key=lambda x: cls.word_lookup[word][x])\n",
        "        else:\n",
        "            return word\n",
        "        \n",
        "#data['title']=data['title'].replace('?',' ?')\n",
        "data.head(5)# Summary about tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "97e65fb7-23b1-3bc4-a877-5892418cd7d0"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "\n",
        "data['tot']=data['title']+' '+data['content']\n",
        "#create sklearn pipeline, fit all, and predit test data\n",
        "clf = Pipeline([('v',TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words = 'english')), \n",
        "                ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), \n",
        "                ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), \n",
        "                ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))])\n",
        "clf.fit(data['tot'], data['tags'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "646459aa-4ba6-9805-24d8-5e4d8f9e6452"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "test['tags'] = ''\n",
        "test['category'] = 'physics'\n",
        "\n",
        "data=test.sample(3000)\n",
        "data[\"title\"] = data[\"title\"].map(removePunctuation)\n",
        "data[\"content\"] = data[\"content\"].map(removePunctuation)\n",
        "data['tot']=data['title']+' '+data['content']\n",
        "t_labels = clf.predict(data['tot'])\n",
        "print(t_labels)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}