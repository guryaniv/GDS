{"cells":[{"metadata":{"_uuid":"ca7529b0cb9fbf0f33906aa88c8491e2b68c569d"},"cell_type":"markdown","source":"This is my first kernel, I still got a lot to learn and hope this helps. You also might want to check this kernel here since I too learned from him.\nhttps://www.kaggle.com/darshanadiga/time-series-data-exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom math import sqrt\nimport sys\nfrom scipy import spatial","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d7a1e5e6c61ebb269c20c77298195497fadbe8ab"},"cell_type":"code","source":"df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3b070e2647ed7342a86f23ef808dc01617a8875"},"cell_type":"markdown","source":"After we load the data, we now plot the store based on the item sales"},{"metadata":{"trusted":true,"_uuid":"3eb96f824847a69f9d6317e110709c7c0a767049"},"cell_type":"code","source":"sales_across_store_df = df.copy()\nsales_across_store_df = pd.pivot_table(sales_across_store_df, index='store', \n                                       values=['sales','date'], columns='item', aggfunc=np.mean)\nsales_across_store_df['avg_sale'] = sales_across_store_df.apply(lambda r: r.mean(), axis=1)\n\nsales_store_data = go.Scatter(\n    y = sales_across_store_df.avg_sale.values,\n    mode='markers',\n    marker=dict(\n        size = sales_across_store_df.avg_sale.values,\n        color = sales_across_store_df.avg_sale.values,\n        colorscale='Viridis',\n        showscale=True\n    ),\n    text = sales_across_store_df.index.values\n)\ndata = [sales_store_data]\n\nsales_store_layout = go.Layout(\n    autosize= True,\n    title= 'Scatter plot of avg sales per store',\n    hovermode= 'closest',\n    xaxis= dict(\n        title= 'Stores',\n        ticklen= 10,\n        zeroline= False,\n        gridwidth= 1,\n    ),\n    yaxis=dict(\n        title= 'Avg Sales',\n        ticklen= 10,\n        zeroline= False,\n        gridwidth= 1,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=sales_store_layout)\npy.iplot(fig,filename='scatter_sales_store')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"446d54e6b23c93f8dc3d4c73015b709034f8e870"},"cell_type":"code","source":"store_clusters = []\nstore_clusters.append([2, 3, 4, 8, 9, 10])\nstore_clusters.append([1])\nstore_clusters.append([5, 6, 7])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55db0072c6065c722a7000b01b2051b6d327dc69"},"cell_type":"markdown","source":"As we can see, in terms of average sales, store 2, 3, 4, 8, 9, and 10 seems to be in  one cluster while 5, 6, and 7 in another cluster and store 1 in also another cluster. So we have 3 clusters. The following code will dig down to more detail into peritem. (index in the picture starts from 0)"},{"metadata":{"trusted":true,"_uuid":"b81f255659a09270ab20211caecb63881a178769"},"cell_type":"code","source":"sales_across_item_df = df.copy()\nsales_across_item_df = pd.pivot_table(sales_across_item_df, index='store', \n                                       values=['sales','date'], columns='item', aggfunc=np.mean)\nsales_across_item_df.loc[11] = sales_across_item_df.apply(lambda r: r.mean(), axis=0)\navg_sales_per_item_across_stores_df = pd.DataFrame(data=[[i+1,a] for i,a in enumerate(sales_across_item_df.loc[11:].values[0])], columns=['item', 'avg_sale'])\n\n# Scatter plot of average sales per item\nsales_item_data = go.Bar(\n    x=[i for i in range(0, 50)],\n    y=avg_sales_per_item_across_stores_df.avg_sale.values,\n    marker=dict(\n        color=avg_sales_per_item_across_stores_df.avg_sale.values,\n        colorscale='Blackbody',\n        showscale=True\n    ),\n    text = avg_sales_per_item_across_stores_df.item.values\n)\ndata = [sales_item_data]\n\nsales_item_layout = go.Layout(\n    autosize= True,\n    title= 'Scatter plot of avg sales per item',\n    hovermode= 'closest',\n    xaxis= dict(\n        title= 'Items',\n        ticklen= 55,\n        zeroline= False,\n        gridwidth= 1,\n    ),\n    yaxis=dict(\n        title= 'Avg Sales',\n        ticklen= 10,\n        zeroline= False,\n        gridwidth= 1,\n    ),\n    showlegend= False\n)\nfig = go.Figure(data=data, layout=sales_item_layout)\npy.iplot(fig,filename='scatter_sales_item')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"228bfb1205fd8892830c9381f6e291d4fae966d2"},"cell_type":"markdown","source":"Now we see that items sales are vary among others, some have very high sales while the other don't. Now we will plot per item per store"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e46bfb4377e27636ac4f8d104bfe615d6b00d13a"},"cell_type":"code","source":"def plot_sales(item_ids, store_ids):\n    stores_items_df = df.copy()    \n    multi_store_item_ts_data = []\n    for st,it in zip(store_ids, item_ids):\n        flt = stores_items_df[stores_items_df.store == st]\n        flt = flt[flt.item == it]\n        multi_store_item_ts_data.append(go.Scatter(x=flt.date, y=flt.sales, name = \"Store:\" + str(st) + \",Item:\" + str(it)))\n    py.iplot(multi_store_item_ts_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e23c92af3589a3f1edd7c60ba971211598b178b1"},"cell_type":"code","source":"plot_sales([1], [1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b30212c3b33f8a00854d975de050cfa039af0dd"},"cell_type":"markdown","source":"That sales plot really shows us that there is seasonal pattern in it."},{"metadata":{"trusted":true,"_uuid":"e43157f3d48e4c4f1b3fb83ebd23939bd834b94c"},"cell_type":"code","source":"plot_sales([1 for _ in range(10)], [x+1 for x in range(10)])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cc35aaaccebff8b556bc4f417226957db7cabc1"},"cell_type":"markdown","source":"Those are plots on item 1 in all stores. They seem to follow the same pattern."},{"metadata":{"trusted":true,"_uuid":"31e22c4f9308a4465c797fda510ef9a70239a8cd"},"cell_type":"code","source":"for store_cluster in store_clusters:\n    plot_sales([1 for _ in range(len(store_cluster))], store_cluster)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cdae21cad5644d98eeb3b04e644568b1b696c55"},"cell_type":"markdown","source":"Well I don't think split the data in to cluster based on the store make any difference. So next I will item on item in the same and different store."},{"metadata":{"trusted":true,"_uuid":"720cfbf6c74b2acd03a53c05f312f0ff8426a703"},"cell_type":"code","source":"plot_sales([1, 1, 15, 15, 42, 42], [2, 7, 2, 7, 2, 7])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83616038b32906c44fa588a0499440314b476bd9"},"cell_type":"markdown","source":"Now we see each of the sales data react differently to the seasonal pattern. So next I will try to cluster them for each item per store using K means."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"46f47f34de31c20d979062c4be28adb09338e6f9"},"cell_type":"code","source":"def euclid_dist(t1, t2):\n    return np.sqrt(((t1-t2)**2).sum(axis = 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c6c8cd692d31a268334307e910633d1f0d489ac4"},"cell_type":"code","source":"def init_centroids(data, num_clust):\n    centroids = np.zeros([num_clust, data.shape[1]]) \n    centroids[0,:] = data[np.random.randint(0, data.shape[0], 1)]\n\n    for i in range(1, num_clust):\n        D2 = np.min([np.linalg.norm(data - c, axis = 1)**2 for c in centroids[0:i, :]], axis = 0) \n        probs = D2/D2.sum()\n        cumprobs = probs.cumsum()\n        ind = np.where(cumprobs >= np.random.random())[0][0]\n        centroids[i, :] = np.expand_dims(data[ind], axis = 0)\n\n    return centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6a600e69a595fb2221acfe36229f37f8d38c37f0"},"cell_type":"code","source":"def calc_centroids(data, centroids):\n    dist = np.zeros([data.shape[0], centroids.shape[0]])\n\n    for idx, centroid in enumerate(centroids):\n        dist[:, idx] = euclid_dist(centroid, data)\n\n    return np.array(dist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c044f411702d909fefcb408146c491e4362f5e76"},"cell_type":"code","source":"def closest_centroids(data, centroids): \n    dist = calc_centroids(data, centroids) \n    return np.argmin(dist, axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"750cc027aa88399961603a3e6f90a4335b5ac063"},"cell_type":"code","source":"def move_centroids(data, closest, centroids):\n    k = centroids.shape[0]\n    new_centroids = np.array([data[closest == c].mean(axis = 0) for c in np.unique(closest)])\n\n    if k - new_centroids.shape[0] > 0:\n        print(\"adding {} centroid(s)\".format(k - new_centroids.shape[0]))\n        additional_centroids = data[np.random.randint(0, data.shape[0], k - new_centroids.shape[0])] \n        new_centroids = np.append(new_centroids, additional_centroids, axis = 0)\n\n    return new_centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"83a6273b32647118cc4788901b41feba80a8ceec"},"cell_type":"code","source":"def k_means(data, num_clust, num_iter): \n    centroids = init_centroids(data, num_clust)\n    last_centroids = centroids\n\n    for n in range(num_iter):\n        closest = closest_centroids(data, centroids)\n        centroids = move_centroids(data, closest, centroids)\n        if not np.any(last_centroids != centroids):\n            break\n        last_centroids = centroids\n\n    return centroids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"abb0c8c5dcc67ce99c097c0b205593bf9708a7a9"},"cell_type":"code","source":"def cosine_similarity(t1, t2):\n    return 1 - spatial.distance.cosine(t1, t2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f858438c1b558d2c763f492e68055ae2e10589ff"},"cell_type":"code","source":"store_ids = [s for s in range(1, 11)]\nitem_ids = [i for i in range(1, 51)]\n\nmulti_store_item_df = df.copy()\nseries_sales = []\n\nfor it in item_ids:\n#     sales = []\n    for st in store_ids:\n        flt = multi_store_item_df[multi_store_item_df.store == st]\n        flt = flt[flt.item == it]\n        series_sales.append(list(flt.sales.values))\n    \nseries_sales = np.reshape(series_sales, (len(series_sales), len(series_sales[0])))\nseries_sales.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bacdcc99acb3c36b9778dd75c8c6590ee10c4d46"},"cell_type":"code","source":"num_cluster = 25\ncentroids = k_means(series_sales, num_cluster, 100)\n\nsales_clusters = [[] for _ in range(num_cluster)]\nfor i in range(len(series_sales)):\n    clostest_dist = 0\n    clust = 0\n    for c in range(num_cluster):\n        dist = cosine_similarity(centroids[c], series_sales[i])\n        if dist > clostest_dist:\n            clostest_dist = dist\n            clust = c\n    sales_clusters[clust].append({\n        'store': (i%10) + 1,\n        'item': int(i/10) + 1\n    })\n\nfor sales_cluster in sales_clusters:\n    print(len(sales_cluster))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91788905bd3c88c815bb2ac6f64286bba61612df"},"cell_type":"markdown","source":"I tried to make 10 cluster and see the number of member on each cluster"},{"metadata":{"trusted":true,"_uuid":"332ef00018bcc9b96b75e6defc322b0c2d91c882"},"cell_type":"code","source":"item_ids = []\nstore_ids = []\nfor sales_dict in sales_clusters[5]:\n    item_ids.append(sales_dict['item'])\n    store_ids.append(sales_dict['store'])\nplot_sales(item_ids, store_ids)\n\nitem_ids = []\nstore_ids = []    \nfor sales_dict in sales_clusters[10]:\n    item_ids.append(sales_dict['item'])\n    store_ids.append(sales_dict['store'])\nplot_sales(item_ids, store_ids)\n\nitem_ids = []\nstore_ids = []\nfor sales_dict in sales_clusters[15]:\n    item_ids.append(sales_dict['item'])\n    store_ids.append(sales_dict['store'])\nplot_sales(item_ids, store_ids)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4706b160202c4521a53f5dcf5835e7227e4e825"},"cell_type":"markdown","source":"The member of the same cluster seems to have the very similiar pattern"},{"metadata":{"_uuid":"427cbac444ff1d2cbe48d4b592d7c42357baa86d"},"cell_type":"markdown","source":"I think maybe if we use these clusters to train the model, it might help to improve the accuracy. Hope this helps, thank you."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a97f2f23c6d6f1a830c6a560decb5eb583a9c383"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dc1c42cb6dec20216c2c2bd775770d425306d623"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}