{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"version": "3.6.3", "file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "6722396d-ca08-4ce3-acf7-3b6d95fe87c3", "_uuid": "dba11730637a1c3e0b4098b2e96b79bc53f92878"}, "cell_type": "markdown", "source": ["<h2> Doc2Vec </h2>"]}, {"execution_count": null, "cell_type": "code", "source": ["from __future__ import print_function\n", "import os\n", "import re\n", "import tqdm\n", "import string\n", "import pandas as pd\n", "import numpy as np\n", "import keras\n", "from keras.layers import Flatten"], "metadata": {"_cell_guid": "d041c197-2d35-4578-aca6-921394995dc5", "_uuid": "5a62f2412375e52cf23e4ca6db7bfda6febf8f55"}, "outputs": []}, {"metadata": {"_cell_guid": "51da132a-5061-4dcb-94e9-e9b5f538b7fc", "_uuid": "6daac9c62f00d56532ea67af5e378983eea4e6bb"}, "cell_type": "markdown", "source": ["<h4> Load Data </h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["#train data\n", "df_train_txt = pd.read_csv('../input/training_text', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "df_train_var = pd.read_csv('../input/training_variants')\n", "#test data\n", "df_test_txt = pd.read_csv('../input/test_text', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "df_test_var = pd.read_csv('../input/test_variants')"], "metadata": {"_cell_guid": "49d84664-7e35-418c-b4ed-e8d73a04429c", "_uuid": "729ac7e390e6c88ccb25ab2a3420a5597f747760"}, "outputs": []}, {"metadata": {"_cell_guid": "ebc171d5-418e-4019-9898-10e56387a2f0", "_uuid": "efeea4fb36737a2a30d09102a6ea0f5858def28e"}, "cell_type": "markdown", "source": ["<h4>Performing EDA.</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["train = df_train_var.merge(df_train_txt, how=\"inner\", left_on=\"ID\", right_on=\"ID\")\n", "train.head()"], "metadata": {"_cell_guid": "9d1fde8a-d14b-4e5d-9115-2a92a7a25726", "_uuid": "87ff911fbf7de15eb1e9bd99e71f4c7180912da3"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["test_x = df_test_var.merge(df_test_txt, how=\"inner\", left_on=\"ID\", right_on=\"ID\")\n", "test_x.head()"], "metadata": {"_cell_guid": "b2e73a0a-7d51-489a-8613-2f52f58013fe", "_uuid": "ee2fe4951a88f48f89162d6742826c52cf323f4d"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["train_y = train['Class'].values\n", "train_x = train.drop('Class', axis=1)\n", "train_size=len(train_x)\n", "print('Number of training variants: %d' % (train_size))"], "metadata": {"_cell_guid": "675173fc-ac6e-4071-8e68-96ecdbb047fa", "_uuid": "d99afd2c3d6ca1b3b4a29c06ae42b2fd0f9e2660"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["test_size=len(test_x)\n", "print('Number of test variants: %d' % (test_size))\n", "# number of test data : 5668"], "metadata": {"_cell_guid": "3484dace-a2fb-468d-bfb1-012242aa3d1b", "_uuid": "b8aa28ad743d9aa55afcc4c4ec5dca538edd5b0a"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["test_index = test_x['ID'].values\n", "all_data = np.concatenate((train_x, test_x), axis=0)\n", "all_data = pd.DataFrame(all_data)\n", "all_data.columns = [\"ID\", \"Gene\", \"Variation\", \"Text\"]"], "metadata": {"_cell_guid": "d652661f-38ae-4c61-bf0c-d843dd3ebcde", "_uuid": "6996446dfad3fd31f0028c1e41e954c0351993ec", "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["all_data.head()"], "metadata": {"_cell_guid": "97364678-16f5-4a07-8d27-9dbae65d9054", "_uuid": "2e82fd1da67a960707cdae19e0986db8d7a92302"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["from nltk.corpus import stopwords\n", "from gensim.models.doc2vec import LabeledSentence\n", "from gensim import utils"], "metadata": {"_cell_guid": "4933ab25-2147-4a24-9c14-be64b2d5dfad", "_uuid": "41a42ef182c66c40a3365c0bfbd9b6267b5c5001", "collapsed": true}, "outputs": []}, {"metadata": {"_cell_guid": "aecb44a5-3f9d-462e-ab3c-4c96c49dea4f", "_uuid": "2bb94d492131bc18051c4727ada5fa089fc5347b"}, "cell_type": "markdown", "source": ["<h4>Clean up Text and construct Labeled Setnetences.</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["def constructLabeledSentences(data):\n", "    sentences=[]\n", "    for index, row in data.iteritems():\n", "        sentences.append(LabeledSentence(utils.to_unicode(row).split(), ['Text' + '_%s' % str(index)]))\n", "    return sentences\n", "\n", "def textClean(text):\n", "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n", "    text = text.lower().split()\n", "    stops = set(stopwords.words(\"english\"))\n", "    text = [w for w in text if not w in stops]    \n", "    text = \" \".join(text)\n", "    return(text)\n", "    \n", "def cleanup(text):\n", "    text = textClean(text)\n", "    text= text.translate(str.maketrans(\"\",\"\", string.punctuation))\n", "    return text\n", "\n", "allText = all_data['Text'].apply(cleanup)\n", "sentences = constructLabeledSentences(allText)\n", "allText.head()"], "metadata": {"_cell_guid": "d29a3cec-3500-4049-85c9-b478b55b51a9", "_uuid": "8b9877251a3fe1fc0346b379b1e77c403e626f10"}, "outputs": []}, {"metadata": {"_cell_guid": "34e62d98-6049-4920-9e00-6d540a3afbfc", "_uuid": "b9b779ea72a563834a6ec948ef385a06a86513c8"}, "cell_type": "markdown", "source": ["<h4>Training Doc2Vec with your data or import a saved file</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["from gensim.models import Doc2Vec"], "metadata": {"_cell_guid": "9c3b7a7f-76a7-44db-9375-c13310feabbf", "_uuid": "6333c9da240d956623b0ae94a13887e0df393ae1", "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["Text_INPUT_DIM=300\n", "\n", "\n", "text_model=None\n", "filename='docEmbeddings_5_clean.d2v'\n", "if os.path.isfile(filename):\n", "    text_model = Doc2Vec.load(filename)\n", "else:\n", "    text_model = Doc2Vec(min_count=1, window=5, size=Text_INPUT_DIM, sample=1e-4, negative=5, workers=4, iter=5,seed=1)\n", "    text_model.build_vocab(sentences)\n", "    text_model.train(sentences, total_examples=text_model.corpus_count, epochs=text_model.iter)\n", "    text_model.save(filename)"], "metadata": {"_cell_guid": "5df9faf3-aeec-4fba-945f-47fa98f7aedc", "_uuid": "4b0f5a390125b4062ac0e99621699727c9891f5e"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["text_train_arrays = np.zeros((train_size, Text_INPUT_DIM))\n", "text_test_arrays = np.zeros((test_size, Text_INPUT_DIM))\n", "\n", "for i in range(train_size):\n", "    text_train_arrays[i] = text_model.docvecs['Text_'+str(i)]\n", "\n", "j=0\n", "for i in range(train_size,train_size+test_size):\n", "    text_test_arrays[j] = text_model.docvecs['Text_'+str(i)]\n", "    j=j+1"], "metadata": {"_cell_guid": "91ea6ce8-8e22-41fd-aea8-fa5cab96e538", "_uuid": "b33742fb3e191f59b991028ee803e1d97a18c41a", "collapsed": true}, "outputs": []}, {"metadata": {"_cell_guid": "4bced941-898c-4ff0-9b3b-4df79880ac43", "_uuid": "171191481f3d01176def235e8798296c82faf174"}, "cell_type": "markdown", "source": ["<h4> Gene and Variation Featurizer.</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.decomposition import TruncatedSVD\n", "Gene_INPUT_DIM=25\n", "\n", "#Gene and Variation Featurizer.\n", "svd = TruncatedSVD(n_components=25, n_iter=Gene_INPUT_DIM, random_state=12)\n", "\n", "one_hot_gene = pd.get_dummies(all_data['Gene'])\n", "truncated_one_hot_gene = svd.fit_transform(one_hot_gene.values)\n", "\n", "one_hot_variation = pd.get_dummies(all_data['Variation'])\n", "truncated_one_hot_variation = svd.fit_transform(one_hot_variation.values)"], "metadata": {"_cell_guid": "3896b3c5-bf88-48f3-ad00-6eb4313dff0f", "_uuid": "0ee1bb71130c4e9d9290c1c5d8b37e87581aab9d", "collapsed": true}, "outputs": []}, {"metadata": {"_cell_guid": "f1106d6d-0dc9-4b4c-9db4-9e66788182e5", "_uuid": "bb6d8faf7e8f46c2135e8b648ffc391c895e9a4a"}, "cell_type": "markdown", "source": ["<h4> One hot vector encoding of classes</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["from keras.utils import np_utils\n", "from sklearn.preprocessing import LabelEncoder\n", "\n", "#One hot vector encoding of classes\n", "label_encoder = LabelEncoder()\n", "label_encoder.fit(train_y)\n", "encoded_y = np_utils.to_categorical((label_encoder.transform(train_y)))"], "metadata": {"_cell_guid": "1736ca2c-59ed-41bc-b9fd-025d33b253c2", "_uuid": "ecb109665ff2aefaa929f5db7e734b6a03b4953d", "collapsed": true}, "outputs": []}, {"metadata": {"_cell_guid": "26e9770d-251c-4348-862a-3845b0e744f8", "_uuid": "3a4ef97cbff7a094dee387d3958a60398b41af5f"}, "cell_type": "markdown", "source": ["<h4> Merge Input Features</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["##Considering all features, i.e. Gene, Variation and Text.\n", "\n", "#Merge Input Features\n", "train_set=np.hstack((truncated_one_hot_gene[:train_size],truncated_one_hot_variation[:train_size],text_train_arrays))\n", "test_set=np.hstack((truncated_one_hot_gene[train_size:],truncated_one_hot_variation[train_size:],text_test_arrays))\n"], "metadata": {"_cell_guid": "6b8605f2-0c66-431a-bde0-1d9b0bb4e37e", "_uuid": "5196060aba1fa4bdef525abda701e3d05226ca52", "collapsed": true}, "outputs": []}, {"metadata": {"_cell_guid": "a1dc3907-8485-4101-b25e-df24d7d92285", "_uuid": "f43dc60ac763ceb3b034d54b2658cd44b7f41db4"}, "cell_type": "markdown", "source": ["\n", "<h4>Defining a base sequential model</h4>"]}, {"execution_count": null, "cell_type": "code", "source": ["train_set = np.reshape(train_set, (train_set.shape[0],1,train_set.shape[1]))"], "metadata": {"_cell_guid": "35f4b77e-791d-40bc-b666-19077b56cf9e", "_uuid": "fee84b665ef8a2b72b15dea77095ab92562fadf2", "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["train_set.shape"], "metadata": {"_cell_guid": "15f211e1-eaf1-4c55-af57-2514467c706e", "_uuid": "91072e20b110f3c9dcf3d6f3456f6f7e9e273291"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\n", "from keras.optimizers import SGD, Adam, RMSprop, Adamax\n", "\n", "def baseline_model(r,c):\n", "    #----------------Old Start-----------------   \n", "    #     model = Sequential()\n", "    #     model.add(Dense(256, input_dim=Text_INPUT_DIM+Gene_INPUT_DIM*2, init='normal', activation='relu'))\n", "    #     model.add(Dropout(0.1))\n", "    #     model.add(Dense(256, init='normal', activation='relu'))\n", "    #     model.add(Dropout(0.08))\n", "    #     model.add(Dense(80, init='normal', activation='relu'))\n", "    #     model.add(Dense(9, init='normal', activation=\"softmax\"))\n", "    #     adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n", "    #     model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n", "    #     return model \n", "    #----------------Old end-----------------\n", "\n", "    #------------------------------Modified Start--------------------------\n", "    lstm_out = 350\n", "    model = Sequential()\n", "    model.add(LSTM(lstm_out,return_sequences=True, dropout=0.6, input_shape=(1, c)))\n", "#     model.add(LSTM(lstm_out,return_sequences=True, dropout=0.6, input_shape=(1, c)))\n", "    model.add(Dropout(1.8))\n", "    model.add(Dense(10, init='normal', activation='relu'))\n", "    model.add(Dense(10, init='normal', activation='relu'))\n", "#     model.add(Dropout(0.08))\n", "#     model.add(Flatten())\n", "    \n", "    model.add(Dense(9, init='normal', activation=\"softmax\"))\n", "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n", "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n", "    return model \n", "    #------------------------------Modified End--------------------------\n", "##sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)  \n", "\n", "##rms = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n", "##adamax = Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n", "\n", "# '''\n", "# model = Sequential()\n", "# model.add(Embedding(2000, 128, input_length = X.shape[1]))\n", "# model.add(LSTM(lstm_out, recurrent_dropout=0.2, dropout=0.2))\n", "# model.add(Dense(9,activation='softmax'))\n", "# model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['categorical_crossentropy'])\n", "# '''\n"], "metadata": {"_cell_guid": "6951e214-113a-467c-bd24-5ab7324467d3", "_uuid": "5b17e04beae4133685a7508ba5de8c02734e4792", "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["# model = baseline_model(train_set.shape[1],train_set.shape[2])\n", "model = baseline_model(train_set.shape[0],train_set.shape[2])\n", "model.summary()"], "metadata": {"_cell_guid": "befa0adc-36e9-41fc-995c-09f3c624acd5", "_uuid": "c223f74962d4c245a8532f8b495143c507fe4e65", "scrolled": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["encoded_y.shape"], "metadata": {"_cell_guid": "cab28b4a-b7de-433e-9312-d515f3c583f7", "_uuid": "dc22e63b343717c6c1b451c0965b751e0d2734d7"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["encoded_y = np.reshape(encoded_y, (encoded_y.shape[0],1,encoded_y.shape[1]))"], "metadata": {"_cell_guid": "fc7ce7f1-22ee-47ca-a41b-d77146e3b932", "_uuid": "d48ff466e48a7ddd36b22000f74ba546db2ff154", "collapsed": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["# train_set = np.reshape(train_set, (train_set.shape[0], 1, train_set.shape[1]))\n", "# X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n", "train_set.shape\n", "estimator=model.fit(train_set, encoded_y, validation_split=0.2, epochs=2, batch_size=32)"], "metadata": {"_cell_guid": "6dd12c91-3f19-4bd7-86fd-fbdaca54d6c8", "_uuid": "62a9fc414db43f91eaa3d0c24d84f5daf2e42344", "scrolled": true}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "\n", "# summarize history for accuracy\n", "plt.plot(estimator.history['acc'])\n", "plt.plot(estimator.history['val_acc'])\n", "plt.title('model accuracy')\n", "plt.ylabel('accuracy')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()\n", "\n", "# summarize history for loss\n", "plt.plot(estimator.history['loss'])\n", "plt.plot(estimator.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'valid'], loc='upper left')\n", "plt.show()"], "metadata": {"_cell_guid": "1bc3c29f-f06e-4f4c-8c30-ab1633d2f18c", "_uuid": "6fa32d071c1fd2eef14e94e00c2117dc1ebe27d9"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["print(\"Training accuracy: %.2f%% / Validation accuracy: %.2f%%\" % (100*estimator.history['acc'][-1], 100*estimator.history['val_acc'][-1]))"], "metadata": {"_cell_guid": "fa47adfa-521b-4589-a669-733a22c5cc34", "_uuid": "d7900fdc331428eec1995c1f22ea5ed213543887"}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": [], "metadata": {"collapsed": true, "_uuid": "9f048ca064bc24e0d377b235cb4b2ed6f8be23d0", "_cell_guid": "2a8b2ab5-c475-4727-835f-18ab1a15d7f0"}, "outputs": []}]}