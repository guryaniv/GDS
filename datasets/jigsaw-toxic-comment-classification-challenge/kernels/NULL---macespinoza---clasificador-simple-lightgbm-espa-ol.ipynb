{"cells":[{"metadata":{"_uuid":"b07a4942933ebb664a8d453fad10992f0eb8d868"},"cell_type":"markdown","source":"## **LightGBM **\n\nVamos a aprender un poco de LightGBM en su cladificador de varias columnas"},{"metadata":{"_uuid":"58a01f885779e67fca37a240c2ac90919e92b1c2"},"cell_type":"markdown","source":"Cargamos las librerias necesarias para el proceso"},{"metadata":{"_uuid":"7b45fad7d6be1e5af62de32b78509b5b3570c6cb","_cell_guid":"30c803e7-2c9a-4ba7-8c3b-e77f2e6de655","trusted":true},"cell_type":"code","source":"# loading libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport lightgbm as lgbm\nimport re\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a897acda21fb77e423d8b72d3baa99cc90e027ca","_cell_guid":"1693cead-2647-4782-bd3d-ad22b131e632","trusted":true},"cell_type":"markdown","source":"Cargamos los datos de entrenamiento y test"},{"metadata":{"_uuid":"fca51e8e7e06f73e94d7a340fa5f29242c7f4b07","_cell_guid":"283df181-415b-4e44-8c0e-0b2a773f7666","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"508237686f6d2a78d6429c03e2e324afc01545d8"},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dea97a76a46a07343ce7319cdf5fa15401bfe260","_cell_guid":"42b4ee0f-c64b-4efb-8ea9-f5f682e27e4c","trusted":true},"cell_type":"code","source":"# visualizacion repida de datos\ntrain.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af70032abf4c45fe9e2d25524244416377538f2f"},"cell_type":"code","source":"test.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b846078e39e425739133581c841ea5c56f6dd9e7","_cell_guid":"2bd80b6c-1b35-4a39-bc03-850cb63b65bc","trusted":true},"cell_type":"code","source":"# taking comment from train and test and making a single dataframe\n# Tomar comentarios del set de entrenamiento y prueba y hacer un único marco de datos.\ntrain_ = train['comment_text']\ntest_ = test['comment_text']\n\nalldata = pd.concat([train_, test_], axis=0)\n\nalldata = pd.DataFrame(alldata)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2860dad7b862dc92b2124d6690471d166c255ca3","_cell_guid":"e8d54542-4e96-4721-8903-df52c50d4c2c","trusted":true},"cell_type":"code","source":"# imputando a los valores perdidos\nalldata.comment_text.fillna('blllllllllllllllllllllllaaaaaaaaaaaaaaaahhhhhhhh...!!!', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"927195e00936bc8f1e98dcc5d3a42f226809ccb9","_cell_guid":"61ec74f3-67d5-400b-b184-268d21c5a4dc","trusted":true},"cell_type":"code","source":"# function to clean the comment\n# adapted from a kaggle kernal, can't find its link now\n\n# función para limpiar el comentario\n# adaptado de un núcleo de Kaggle, https://www.kaggle.com/currie32/the-importance-of-cleaning-text\ndef cleanData(text):\n    txt = str(text)\n    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n    text = re.sub(r\"what's\", \"\", text)\n    text = re.sub(r\"What's\", \"\", text)\n    text = re.sub(r\"\\'s\", \" \", text)\n    text = re.sub(r\"\\'ve\", \" have \", text)\n    text = re.sub(r\"can't\", \"cannot \", text)\n    text = re.sub(r\"n't\", \" not \", text)\n    text = re.sub(r\"I'm\", \"I am\", text)\n    text = re.sub(r\" m \", \" am \", text)\n    text = re.sub(r\"\\'re\", \" are \", text)\n    text = re.sub(r\"\\'d\", \" would \", text)\n    text = re.sub(r\"\\'ll\", \" will \", text)\n    text = re.sub(r\"60k\", \" 60000 \", text)\n    text = re.sub(r\" e g \", \" eg \", text)\n    text = re.sub(r\" b g \", \" bg \", text)\n    text = re.sub(r\"\\0s\", \"0\", text)\n    text = re.sub(r\" 9 11 \", \"911\", text)\n    text = re.sub(r\"e-mail\", \"email\", text)\n    text = re.sub(r\"\\s{2,}\", \" \", text)\n    text = re.sub(r\"quikly\", \"quickly\", text)\n    text = re.sub(r\" usa \", \" America \", text)\n    text = re.sub(r\" USA \", \" America \", text)\n    text = re.sub(r\" u s \", \" America \", text)\n    text = re.sub(r\" uk \", \" England \", text)\n    text = re.sub(r\" UK \", \" England \", text)\n    text = re.sub(r\"india\", \"India\", text)\n    text = re.sub(r\" dms \", \"direct messages \", text)  \n    text = re.sub(r\"actived\", \"active\", text)\n    text = re.sub(r\"kms\", \" kilometers \", text)\n    text = re.sub(r\"KMs\", \" kilometers \", text)\n    text = re.sub(r\"\\0rs \", \" rs \", text) \n    text = re.sub(r\"calender\", \"calendar\", text)\n    text = re.sub(r\"ios\", \"operating system\", text)\n    text = re.sub(r\"bestfriend\", \"best friend\", text)\n    text = re.sub(r\"dna\", \"DNA\", text)\n    text = re.sub(r\"III\", \"3\", text) \n    text = re.sub(r\"Find\", \"find\", text) \n\n    return txt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"084d52177dcf35a1daa076198fb2879d2d5781ed","_cell_guid":"62be3ce0-80f4-4f1c-9104-cf005b420942","trusted":true},"cell_type":"code","source":"# definimos un CountVectorizer como matriz de confusion\ncountvec = CountVectorizer(max_features = 1500, ngram_range=(1, 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4108962d874b65068d2a8953081777653fd2fded","_cell_guid":"c9187ce5-72eb-44fc-a307-e68b13c58e5c","trusted":true},"cell_type":"code","source":"# Ejecutamos el metodo de limpieza de datos\nalldata['comment_text'] = alldata['comment_text'].map(lambda x: cleanData(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"074b9fa83bbf4867f8f48e6ce464d370d5799c68","_cell_guid":"b3ac7403-66c6-44f8-a543-e772c97f0888","trusted":true},"cell_type":"code","source":"# transformar los datos de texto utilizando CountVectorizer\ncountvecdata = countvec.fit_transform(alldata['comment_text'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c8d7c86080ae668435fa162763f3b9f4d4a3d643","_cell_guid":"0d79b678-9c39-4e95-b285-33d3529ded30","trusted":true},"cell_type":"code","source":"# convertir los datos a una matriz\ncountvec_df = pd.DataFrame(countvecdata.todense()) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65804a71ce62be7dabbb8081b85414d6c1572106","_cell_guid":"e37b03f4-b6ff-4141-b456-6ded075282fa","trusted":true},"cell_type":"code","source":"# añadiendo encabezados de columna\ncountvec_df.columns = ['col' + str(x) for x in countvec_df.columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4efc83f0792ab1c5dc8e62da2ca8741c90fe67e3","_cell_guid":"a2d86617-64d4-47b5-9233-40043f11b638","trusted":true},"cell_type":"code","source":"# Cortar los datos para entrenar y probar.\ncountvec_df_train = countvecdata[:len(train_)] \ncountvec_df_test = countvecdata[len(train_):]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58ea257bf30a34b8491efbff74fc8f13d0bd05d9","_cell_guid":"ec39e24b-4fa6-4c89-ab2a-8770f81f48d4","trusted":true},"cell_type":"code","source":"# convertimos en float32\ncountvec_df_train_ = countvec_df_train.astype('float32')\ncountvec_df_test_ = countvec_df_test.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d42af71d336f2db9e01e14a7ae9b961f54016bb","_cell_guid":"2236d4c8-113c-4658-b1d9-4d045b6cc171","trusted":true},"cell_type":"code","source":"# haciendo lista y marcador de posición\ncol = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\npreds = np.zeros((test.shape[0], len(col)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f829f7b79853ded1e577068c4137609de245573e","_cell_guid":"3126fef5-a2dd-4dba-b496-3aaa5576f87c","trusted":true},"cell_type":"code","source":"# parametros para el clasificador LightGBMClassifier\nparams = {\n    'objective' :'binary',\n    'learning_rate' : 0.02,\n    'num_leaves' : 76,\n    'feature_fraction': 0.64, \n    'bagging_fraction': 0.8, \n    'bagging_freq':1,\n    'boosting_type' : 'gbdt',\n    'metric': 'binary_logloss'\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b58b362da4f514e2ab7db3e18441513feb8f280","_cell_guid":"eff30697-514d-4513-896f-28a7f033e923","trusted":true},"cell_type":"code","source":"# hacemos predicción para cada columna\n# adaptado de kaggle kernel https://www.kaggle.com/yekenot/toxic-regression/code\n\nfor i, j in enumerate(col):\n    print('columna de ajuste : '+j)\n    # creamos los set de entrenamiento y validacion\n    X_train, X_valid, Y_train, Y_valid = train_test_split(countvec_df_train_,  train[j], random_state=7, test_size=0.33)\n    \n    # modelamos el dataset lgbm para entrenamiento y validacion\n    d_train = lgbm.Dataset(X_train, Y_train)\n    d_valid = lgbm.Dataset(X_valid, Y_valid)\n    \n    # entrenamiento con parada temprana\n    bst = lgbm.train(params, d_train, 5000, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=100)\n    \n    # Realizamos la prediccion para cada columna\n    print('prediciendo para :' +j)\n    preds[:,i] = bst.predict(countvec_df_test_)\n\nprint('Entrenamiento terminado')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b67fc816a4ab91d27a3c7531e8b25a5b23a96bb4","_cell_guid":"534a1b7f-4129-4ac1-8dc6-0a6b02a601ee","trusted":true},"cell_type":"code","source":"# visualizamos  los resultados!!\nsubm = pd.read_csv('../input/sample_submission.csv')\nsubmid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = col)], axis=1)\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f486a6074912432a4d295c68b916f1f7beae593","_cell_guid":"aff84c4e-bd99-4fc5-82b8-cd38f6cb961d","trusted":true},"cell_type":"code","source":"submission.to_csv('submission_001.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0097ac78313ebb3b67fd10a036f4e2bba71921fe"},"cell_type":"markdown","source":"Disclaimer: Este documento es una traduccion del original: https://www.kaggle.com/sreeram004/simple-lightgbm-classifier , sin fines de copia."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}