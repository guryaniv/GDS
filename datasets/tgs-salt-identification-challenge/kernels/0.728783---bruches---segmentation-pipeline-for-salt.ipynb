{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"177591766ed5b73533d821167eff282361beed44"},"cell_type":"markdown","source":"# Tool for image segmentation\n\nIn this kernel I use a library [segmantation pipeline](https://github.com/petrochenko-pavel-a/segmentation_training_pipeline) for image segmentation just in few lines.\n\nWith minimal settings I was able to achieve over 0.70 scores for this task.\n\nLet's start with installation of all required modules."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"!pip install segmentation_pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16d006070274c73549227ebbbb6bd52d257a48c1"},"cell_type":"code","source":"!pip uninstall -y imgaug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd54349fea21c25045024e78fd398b4719e16f9d"},"cell_type":"code","source":"!pip install git+https://github.com/aleju/imgaug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1989df80cbdcffa6329d62593266173a585a1381"},"cell_type":"code","source":"!pip install shapely","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33e6a1d37ee7ca3e3eb69f43cbe31d4680764d2a"},"cell_type":"markdown","source":"Now we need to create our custom dataset:"},{"metadata":{"trusted":true,"_uuid":"91747e3a4d27db69733ceb55c6562ec88a45e131"},"cell_type":"code","source":"from segmentation_pipeline.impl.datasets import PredictionItem\nimport os\nfrom segmentation_pipeline.impl import rle\nimport imageio\nimport pandas as pd\n\nclass SegmentationRLE:\n\n    def __init__(self,path,imgPath):\n        self.data=pd.read_csv(path);\n        self.values=self.data.values;\n        self.imgPath=imgPath;\n        self.ship_groups=self.data.groupby('id');\n        self.masks=self.ship_groups['id'];\n        self.ids=list(self.ship_groups.groups.keys())\n        pass\n    \n    def __len__(self):\n        return len(self.masks)\n\n\n    def __getitem__(self, item):\n        pixels=self.ship_groups.get_group(self.ids[item])[\"rle_mask\"]\n        return PredictionItem(self.ids[item] + '.png', imageio.imread(os.path.join(self.imgPath,self.ids[item]+'.png')),\n                              rle.masks_as_image(pixels, shape=(101,101)) > 0.5)\n    \n    def isPositive(self, item):\n        pixels=self.ship_groups.get_group(self.ids[item])[\"rle_mask\"]\n        for mask in pixels:\n            if isinstance(mask, str):\n                return True;\n        return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"385a186df11f77b092ba28350bf1ca77be2acf2a"},"cell_type":"code","source":"CSV_PATH = '../input/train.csv'\nIMG_PATH = '../input/train/images/'\ndataset = SegmentationRLE(CSV_PATH, IMG_PATH)\nprint(dataset[0].x.shape)\nprint(dataset[1].y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa73f9387a91f77e2effb661db0ef9e3ffb8bb72"},"cell_type":"markdown","source":"The main thing is our configuration file, where we define all needed things.\n\nIn this example I used `DeepLabV3` with `mobilenetv2` backbone.\n\nOptimizer was `Adam`, batch size is 4, callbacks are `EarlyStopping` and `ReduceLROnPlateau`.\n\nAs loss I used composite loss: `binary_crossentropy + dice_loss`"},{"metadata":{"trusted":true,"_uuid":"74f3165afc29d1861548a79c343170d9aae1a949"},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/BruchesLena/DataSets/master/salt.yaml","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"530fa80f8899e1601c955ef3e44d7ae0dabd8292"},"cell_type":"markdown","source":"And now we are ready to start the training:"},{"metadata":{"trusted":true,"_uuid":"226bb233b99f950f033bf39e8b162d0fb4b25348"},"cell_type":"code","source":"from segmentation_pipeline.impl.datasets import PredictionItem\nimport segmentation_pipeline.impl.datasets\nfrom segmentation_pipeline import segmentation\nfrom segmentation_pipeline.impl.datasets import  SimplePNGMaskDataSet\n\nsegmentation_pipeline.impl.datasets.AUGMENTER_QUEUE_LIMIT=1\ncfg = segmentation.parse(\"salt.yaml\")\ncfg.verbose = 2\ncfg.fit(dataset)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c717bda8cbe77a82edf3562e08a22fb247167aa"},"cell_type":"markdown","source":"Let's define the fold with the best validation accuracy:"},{"metadata":{"trusted":true,"_uuid":"07330d2f88b336dd6a710ab5b49c599cbc9692ad"},"cell_type":"code","source":"import numpy as np\n\nval_accs = []\nfor i in range(5):\n  metric_file = 'metrics/metrics-'+str(i)+'.0.csv'\n  metrics = pd.read_csv(metric_file)\n  acc = list(metrics['val_binary_accuracy'])\n  val_accs.append(acc[-5])\nbest_fold = np.argmax(np.array(val_accs))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3119dba25478ce5b6b46e165a3842a97d631924"},"cell_type":"markdown","source":"Let's create 2 submission files.\n\nThe first one will be the submission for the best fold metrics."},{"metadata":{"trusted":true,"_uuid":"ccadf74dc2a099c394e43373c04b940ad6297600"},"cell_type":"code","source":"from segmentation_pipeline import  segmentation\nfrom segmentation_pipeline.impl.rle import rle_encode\nfrom skimage.morphology import remove_small_objects, remove_small_holes\nimport pandas as pd\n\n#this is our callback which is called for every image\ndef onPredict(file_name, img, data):\n    threshold = 0.25\n    predictions = data[\"pred\"]\n    imgs = data[\"images\"]\n    post_img = remove_small_holes(remove_small_objects(img.arr > threshold))\n    rle = rle_encode(post_img)\n    predictions.append(rle)\n    imgs.append(file_name[:file_name.index(\".\")])\n    pass\n\npredictions = []\nimages = []\ncfg.predict_in_directory(\"../input/test/images/\", best_fold, 0, onPredict, {\"pred\": predictions, \"images\": images})\n\ndf = pd.DataFrame.from_dict({'id': images, 'rle_mask': predictions})\ndf.to_csv('submission_best_fold.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9907c6d785451d407b5fcaee693c2daf599ee5a9"},"cell_type":"markdown","source":"The second submission will be the ensemble across all folds:\n"},{"metadata":{"trusted":true,"_uuid":"b181e08696a6d6e65f9884ff26e225c9c6851797"},"cell_type":"code","source":"from segmentation_pipeline import  segmentation\nfrom segmentation_pipeline.impl.rle import rle_encode\nfrom skimage.morphology import remove_small_objects, remove_small_holes\nimport pandas as pd\n\ndef onPredict(file_name, img, data):\n    threshold = 0.25\n    predictions = data[\"pred\"]\n    imgs = data[\"images\"]\n    post_img = remove_small_holes(remove_small_objects(img.arr > threshold))\n    rle = rle_encode(post_img)\n    predictions.append(rle)\n    imgs.append(file_name[:file_name.index(\".\")])\n    pass\n\npredictions = []\nimages = []\ncfg.predict_in_directory(\"../input/test/images/\", [0,1,2,3,4], 0, onPredict, {\"pred\": predictions, \"images\": images})\n\ndf = pd.DataFrame.from_dict({'id': images, 'rle_mask': predictions})\ndf.to_csv('submission_all.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}