{"cells":[{"metadata":{"_uuid":"cf0510b6138321268b476718f90da38e668475d5"},"cell_type":"markdown","source":"## Performing dog/cat classification using pre-trained Keras MobileNet and ResNet50\n\nFirst of all importing libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport cv2\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.mobilenet import MobileNet\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import optimizers\n\nimg_size = 128 # image height and width\ntrain_size = None # number of samples for training\ntest_size = None # number of samples for testing","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e938f025f0a4dde9c759eb48c8da0ab5c491294"},"cell_type":"markdown","source":"## Loading images and labels"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"files_paths = glob.glob('../input/train/*.jpg') # list of image files\nfiles_labels = [[1, 0] if 'dog' in f else [0, 1] for f in files_paths] # labels\n\nprint(len(files_paths), len(files_labels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc095d0940b0520bd90ecc64964435631c099a1a"},"cell_type":"code","source":"def files_2_img_array(files_list): \n    '''Takes list of image files paths and return np array of images'''\n    imgs = []\n    for i in files_list:\n        img = cv2.imread(i)\n        img = cv2.resize(img, (img_size, img_size))\n#         img = np.true_divide(img, 255, dtype=np.float64)\n#         img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        imgs.append(img)\n    return np.array(imgs)\n\nx = files_2_img_array(files_paths)\ny = np.array(files_labels)\nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f53637756553c0a236b45a23eb46cbac09c117ba"},"cell_type":"markdown","source":"## Plotting some samples"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"ef44c3bac3a897658eb865890c8ec0df7c93a1dd"},"cell_type":"code","source":"n = 4\nfig, axs = plt.subplots(nrows=n, ncols=n, sharex=True, sharey=True, figsize=(10, 10))\nfor i in range(n**2):\n    ax = axs[i // n, i % n]\n    ax.imshow(x[i])\n    ax.set_title('label: %s, idx: %s' % (str(y[i]), str(i)))\n    ax.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c71f71c06404017616d37605b75106c3c676f8e4"},"cell_type":"markdown","source":"## Performing some basic image augmentation"},{"metadata":{"trusted":true,"_uuid":"94795b1aa1e0dc58010e3dc698555d30c9a37dcd"},"cell_type":"code","source":"x_flipped = np.array([np.fliplr(img) for img in x]) # performing flipping \nx = np.concatenate([x, x_flipped])\ny = np.concatenate([y, y])\n\ndel x_flipped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"453587127a65f6626d47d012279b0eeccd6c7df3"},"cell_type":"code","source":"plt.imshow(x[100])\nplt.axis('off')\nplt.show()\n\nplt.imshow(x[25100])\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9e45142e4f262b30970e60dde2a17fddc9a7be5"},"cell_type":"markdown","source":"## Splitting data for train and test sets"},{"metadata":{"trusted":true,"_uuid":"b83313dea14756668d2cdf991cad95f914e09e81"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\nif train_size:\n    x_train = x_train[:train_size]\n    y_train = y_train[:train_size]\nif test_size:\n    x_test = x_test[:test_size]\n    y_test = y_test[:test_size]\n\nprint(x_train.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32ab53ef275353796018900c3c0fff71494e13f4"},"cell_type":"markdown","source":"## Building MobileNet model\n\nPre-trained MobileNet + some dense layers."},{"metadata":{"trusted":true,"_uuid":"2cdbb597eef4605627243d288f9d0c87f5246a32"},"cell_type":"code","source":"mobile_net_model= MobileNet(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\nmobile_net_model.trainable = False\n\nmodel = Sequential()\nmodel.add(mobile_net_model)\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(2, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d82a93ffc758355d1e4d6a7cefa78e70c253f3a8"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97478eba09e26390dacf561f20cfba1658be3551"},"cell_type":"markdown","source":"## Training model"},{"metadata":{"trusted":true,"_uuid":"a950bfd5fd7aabe69fbeeefafb39b5b326f2a063"},"cell_type":"code","source":"history = model.fit(\n    x_train,\n    y_train,\n    epochs=15,\n    batch_size=100,\n    validation_data=(x_test, y_test),\n    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4db279ef55196e98169cf83af70ae119125686bd"},"cell_type":"markdown","source":"## Plotting training history"},{"metadata":{"trusted":true,"_uuid":"159d76c9310a32642ef12edef3b72700d839519b"},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebf33dfd41fb622ba4f6ba2be6011973fefad67e"},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14912cbf559eaf6ddabd691380b672c6c6fa3191"},"cell_type":"markdown","source":"## Loading submission files"},{"metadata":{"trusted":true,"_uuid":"c149675d237540a7047f18b4c6cca9ee48dc1abf"},"cell_type":"code","source":"test_files_paths = glob.glob('../input/test/*.jpg')\nxx = files_2_img_array(test_files_paths)\nxx.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"99b91258f609129cc168a8f52483f4b74acdad2f"},"cell_type":"markdown","source":"## Performing prediction"},{"metadata":{"trusted":true,"_uuid":"ae03fb85a8fe1e1090eddba3b3a0cee09694033b"},"cell_type":"code","source":"predictions = model.predict(xx)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecbe7dced91c7f7a4ce3c1d7777f733eb23c4d09"},"cell_type":"markdown","source":"## Generating submission file"},{"metadata":{"trusted":true,"_uuid":"f83e9fd012c9ed76c34acd43431c840bcd842f49"},"cell_type":"code","source":"sub_ids = [i.split('/')[3].split('.')[0] for i in test_files_paths]\nsub_labels = [i[0] for i in predictions]\n\nsubmission_df = pd.DataFrame({'id': sub_ids, 'label': sub_labels})\nsubmission_df.to_csv('output_mobilenet.csv', index = False)\n\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25f6941b13655b6ffcfa762e985005e0ac6b209f"},"cell_type":"markdown","source":"## Building ResNet model"},{"metadata":{"trusted":true,"_uuid":"fe5e709113bcf7a5fe11719967c0e816ceba10bf"},"cell_type":"code","source":"res_net_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\nres_net_model.trainable = False\n\nmodel = Sequential()\nmodel.add(res_net_model)\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(2, activation='softmax'))\nmodel.summary()\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=optimizers.Adam(),\n              metrics=['acc'])\n\nhistory = model.fit(\n    x_train,\n    y_train,\n    epochs=15,\n    batch_size=100,\n    validation_data=(x_test, y_test),\n    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02b2675371f54461465137aca491f90de7e8cc39"},"cell_type":"markdown","source":"## Plotting training history"},{"metadata":{"trusted":true,"_uuid":"1da818c644278488198544b38b27f8004771a752"},"cell_type":"code","source":"plt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f673f0aca8b630ac9d308f6d547bf5fe8f651c1"},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9b58afbe21ad1c925b37411a19bf23884764dd1"},"cell_type":"markdown","source":"## Generating submission file"},{"metadata":{"trusted":true,"_uuid":"99f2e93f20ea1adf5e1b1e8d15980d77c7ca1344"},"cell_type":"code","source":"predictions = model.predict(xx)\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95dfb441507d4ea300b3d94dca61187ab90f9877"},"cell_type":"code","source":"sub_labels = [i[0] for i in predictions]\n\nsubmission_df = pd.DataFrame({'id': sub_ids, 'label': sub_labels})\nsubmission_df.to_csv('output_resnet.csv', index = False)\n\nsubmission_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}