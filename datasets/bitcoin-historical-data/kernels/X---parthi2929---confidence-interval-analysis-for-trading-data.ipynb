{"cells":[{"metadata":{"_uuid":"a943032f4e2fbf2bbcb7f85dd2544d8856d43731"},"cell_type":"markdown","source":"# Confidence Interval Analysis\n\nThis is just an attempt to analyze CI as taught briefly in Udacity's Intro to Statistics Course. (Lesson 41: Flash Card Example) [here](https://youtu.be/L8qboNrDod0)\n\n## Collecting raw trade data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nbtc=pd.read_csv(\"../input/bitstampUSD_1-min_data_2012-01-01_to_2018-11-11.csv\")  #importing csv file \nbtc.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7ab886b68ad4b39b5887896b03e4be651623074"},"cell_type":"markdown","source":"## Cleanup the data\n\n1. Convert time stamp\n2. Convert to hourly data\n3. Take the desired window of timeframe for further analysis[](http://)"},{"metadata":{"trusted":true,"_uuid":"e9cadb985e4e84a691e67d0b5138522e987e2c13"},"cell_type":"code","source":"btc = btc.dropna()  # remove NaN they do not help\nbtc[\"Timestamp\"]=pd.to_datetime(btc[\"Timestamp\"],unit=\"s\") \n\nhour=btc[\"Timestamp\"]==btc[\"Timestamp\"].dt.floor(\"H\")  # there are over 3 million entries in the dataframe\ndf=btc[hour]                                    # to make the dataset more simple i only take daily values\n\ndf = df[(df['Timestamp'] > '2017-06-20 00:00:00') & (df['Timestamp'] <= '2017-07-23 00:00:00')]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"481bf8a53ff4507a3453fce20fd22e53a6d1df1b"},"cell_type":"markdown","source":"## Calculate $\\Delta$T\n\nEach $\\Delta_t$ at\"t\"th moment can be defined as b\n\n$$\n\\Delta_t = \\dfrac{X_{t+1}  - X_t  }{X_t}\n$$"},{"metadata":{"trusted":true,"_uuid":"6c1ba194c45e096d2801a69a506e3174aead8031"},"cell_type":"code","source":"df['dX'] = (df['Weighted_Price'].shift(-1) - df['Weighted_Price'])/df['Weighted_Price'].shift(-1)\ndf['dX'] = df['dX'].shift(1)\n# df['dX'] = df['dX'].round(5)  # rounding to 3 decimal places for better frequency distribution later\ndf = df.dropna()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78f8e97bdae788bf4ffd8a4d9f6f9dfa39e9746d"},"cell_type":"markdown","source":"## Plot"},{"metadata":{"trusted":true,"_uuid":"565a47f2aa723ddbec68391d5957e8b2c7047df2"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig,axr = plt.subplots(2,1,figsize=(14,5))\n\nT = df.Timestamp\nX = df.Weighted_Price\ndX = df.dX\n\nax = axr[0]\nax.plot(T,X , color=\"green\", label=\"BTC/USD\")      # line plot for seeing the daily weighted price\nax.set_xlabel (\"Time\")\nax.set_ylabel(\"USD\")\n\nax = axr[1]\nax.plot(T,dX , color=\"green\", label=\"BTC/USD\")      # line plot for seeing the delta\nax.set_xlabel (\"Time\")\nax.set_ylabel(\"USD_Normalized_Delta\")\n\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3def534e14bd34080004779d2f2a60a98d5b7fda"},"cell_type":"markdown","source":"## Sampling Distribution of Delta X\n\nLet us analyze that, how it looks like to get an idea. Note, **this frequency is for a particular time  window**. If window changes, these could change. "},{"metadata":{"_uuid":"b8fa478e96059870c6bec829fb8d05bca99f5e37","trusted":true},"cell_type":"code","source":"# freq = df['dX'].value_counts()\nX = df['dX'].tolist()\n\nfig, ax = plt.subplots(1,1, figsize=(7,5))\n\nax.hist(X, bins=50)\n\nfrom matplotlib.ticker import FormatStrFormatter\nax.xaxis.set_major_formatter(FormatStrFormatter('%.4f'))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"030bfd8ac8526f8f4505c99b33e7681f5a882cda"},"cell_type":"markdown","source":"Strange. The delta differences follow a normal distribution. With the mean almost zero. Let us calculate the $\\overline{x}$ and $s$ precisely. "},{"metadata":{"trusted":true,"_uuid":"a85a65642a9c879fe9d89c604bea9ca9a5b227e8"},"cell_type":"code","source":"mean = sum(X)/len(X)\nvar = sum([ (i - mean)**2 for i in X ])/len(X)\nfrom math import sqrt\nsd = sqrt(var)\nmeanstr = str.format('{0:.6f}', mean) # this is a string to print in desired decimal places\nsdstr = str.format('{0:.6f}', sd)\nprint(meanstr, sdstr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27410305c12233fdc42b2856023dd327aa5022cb"},"cell_type":"markdown","source":"Note, the values we got are similar (not equal though ofcourse) to what Sebastian writes (Psst! that is in percentage)\n\n![Sebastian's value](https://i.postimg.cc/YqNHszPd/image.png)"},{"metadata":{"_uuid":"2fb3ffbdcb5784e96a125975dd76c9dfea335be9"},"cell_type":"markdown","source":"Thus, we are not only convinced of the values, but also that, we see, the normalized delta forming a normal distribution, we are convinced of taking confidence intervals which should hold good because the given distribution is already normal.  Let us take CI for our own values, like how Sebastian does and observe the outcome. \n\n$$\n\\overline{x} = 0.000042 \\ \\ \\ \\ s = 0.009951 \\ \\ \\ \\ n = 1 \\\\\nCI = \\overline{x} \\pm 1.96\\dfrac{s}{\\sqrt{n}} = ?\n$$"},{"metadata":{"trusted":true,"_uuid":"c83398784262b6087ddbf9a99ebfaff7ff372ea1"},"cell_type":"code","source":"n = 1 # because each sample set size is 1\nl_ci, h_ci = mean - 1.96*(sd/sqrt(n)), mean + 1.96*(sd/sqrt(n))\nround(l_ci,4), round(h_ci,4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28e2f0f32f2a7d799757424cff3d6815241fd970"},"cell_type":"markdown","source":"## Quiz: Outlier Frequency\n\nFor how many cases will we expect out measurement to fall outside the interval? "},{"metadata":{"trusted":true,"_uuid":"5bfd845dab9d9adc0892b6ea1de2387ad141eb85"},"cell_type":"code","source":"from IPython.display import HTML\nhtml = '<iframe width=\"418\" height=\"235\" src=\"https://www.youtube.com/embed/xku0dnLWkcI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\nHTML(html)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06ed8376a5ec5e8bd88bd3478fd87ea5a9e64b86"},"cell_type":"markdown","source":"This depends on our window. Our total sample sets could be counted, and as per confidence interval, about 5% of them are expected to fall outside the range. "},{"metadata":{"trusted":true,"_uuid":"3b2420552538f402087aa737e9357fae7987a68f"},"cell_type":"code","source":"total_samples = len(X)\nn_outliers = total_samples*0.05  # about 5% are expected to fall outside as per the distribution we saw earlier\nprint(total_samples, n_outliers, (n_outliers/total_samples)*100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1731b32f8a0010c95cdad49f75efb8d045f444d"},"cell_type":"markdown","source":"Thus out of 787 samples, we could expect about 40 samples to fall outside the range of CI in our given window. "},{"metadata":{"_uuid":"7912ef3f21ae631f62c640db5de28c09f161c14f"},"cell_type":"markdown","source":"## New Interval\n\nNow Sebastian takes the game to a new (significance) level. This time, instead of z = 1.96, we take z = 6.5, as you can see in normal distribution this is really a rare case. \n\n$$\n\\overline{x} = 0.000042 \\ \\ \\ \\ s = 0.009951 \\ \\ \\ \\ n = 1 \\\\\nCI = \\overline{x} \\pm 6.5\\dfrac{s}{\\sqrt{n}} = ?\n$$"},{"metadata":{"trusted":true,"_uuid":"f8a3d7c56b8a1d0e97002c7923428dba624081b9"},"cell_type":"code","source":"n = 1 # because each sample set size is 1\nl_ci, h_ci = mean - 6.5*(sd/sqrt(n)), mean + 6.5*(sd/sqrt(n))\nround(l_ci,4), round(h_ci,4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"524668f7d663ee7d3842756c56f54254c07ccfab"},"cell_type":"markdown","source":"This is also similar to values Sebastian got \n\n![Sebastian's values](https://i.postimg.cc/Z5sjJ0s1/image.png)"},{"metadata":{"trusted":true,"_uuid":"6b65a4344fc0d738ce6ca096bd67473eb471425f"},"cell_type":"markdown","source":"## Basic Indicator\n\nNow that we have the lower and upper limits, let us try constructing a simple indicator. If the delta is out of the lower range of CI, we will raise an alarm (to sell). Since our chosen window is not having a dramatic crash as Sebastian used, we shall use our previous outliers of 5% (that is 1.96).  "},{"metadata":{"trusted":true,"_uuid":"5cc74f38672b0961d0dc4dee2e2e6af2ed98ef59"},"cell_type":"code","source":"df['dI'] = 0\n# df.loc[df['dX'] > 0.0195, 'dI'] = 1   # using 5% significance as we do not have much of crash in our chosen window\ndf.loc[df['dX'] < -0.0195, 'dI'] = 1\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a76a4771b1bd673f6bcd04d9913a3e7cebe75a43"},"cell_type":"code","source":"fig,axr = plt.subplots(3,1,figsize=(14,5))\n\nT = df.Timestamp\nX = df.Weighted_Price\ndX = df.dX\ndI = df.dI\n\nax = axr[0]\nax.plot(T,X , color=\"green\", label=\"BTC/USD\")      # line plot for seeing the daily weighted price\nax.set_xlabel (\"Time\")\nax.set_ylabel(\"USD\")\n\nax = axr[1]\nax.plot(T,dX , color=\"green\", label=\"BTC/USD\")      # line plot for seeing the delta\nax.set_xlabel (\"Time\")\nax.set_ylabel(\"USD_Normalized_Delta\")\n\nax = axr[2]\nax.plot(T,dI , color=\"green\", label=\"BTC/USD\")      # line plot for seeing the delta\nax.set_xlabel (\"Time\")\nax.set_ylabel(\"Indicator\")\n\nplt.legend() \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34c4287852754693d0b914900c18f479a4f20e6f"},"cell_type":"markdown","source":"Depending on the **crash** level, one could choose the confidence level, and thus wider range. For eg, 1.96 gives many alarms as above, which may be useful to some, but others may prefer a wider interval to only indicate a bigger crash. They could simply choose a higher confidence level. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}