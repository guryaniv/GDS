{"cells":[{"metadata":{"_uuid":"eaf93cd0131d3cd168dfd1e8370465a0035de114"},"cell_type":"markdown","source":"# Ingredients -> NN -> cuisine\n## Test a neural network approach with keras.\n- Kaggle competition: [https://www.kaggle.com/c/whats-cooking-kernels-only](https://www.kaggle.com/c/whats-cooking-kernels-only)\n- View this notebook from Kaggle: [https://www.kaggle.com/bebaek/test-nn-cooking-bb](https://www.kaggle.com/bebaek/test-nn-cooking-bb)\n- Multi-class softmax categorization\n- Submission score: 0.79 (-0.03 from the top score )\n- Unzip datafiles first if they are zipped."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_json('../input/train.json')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dce065be6b5b4d8d148e3aae35213b801fb391a"},"cell_type":"code","source":"# shuffle and split data\nn_data = len(data.id)\nr_train = 1\nr_eval = 0\n\ndata = data.sample(frac=1).reset_index(drop=True)\ni_train = int(n_data*r_train)\ndata_train = data[:i_train]\ni_eval = int(n_data*(1-r_eval))\ndata_eval = data[i_eval:]\nprint('n_train, n_eval = {}, {}'.format(len(data_train), len(data_eval)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1aa4c2f1a6c933df9651cb3c11c95f9e073994b1"},"cell_type":"code","source":"# Build integer-based categorical data\n\n\"\"\"Brute-force vectorization. Replaced with Tokenizer API.\nimport keras\n\ndef get_unique_x(lofl):\n    x_all = set({})\n    for x in lofl:\n        x_all = x_all | set(x)\n    return np.array(list(x_all))\n\nget_unique_y = lambda l: np.array(list(set(l)))\n\ndef get_index(text, dic):\n#def get_index(text):\n    try:\n        return list(dic).index(text)\n    except:\n        return -1\n\n#v_get_index = np.vectorize(get_index, excluded=['dic'])\nv_get_index = np.vectorize(get_index)\nv_get_index.excluded.add(1)\n\n# get all x, y\nx_train_name = list(data_train.ingredients.values)\ny_train_name = list(data_train.cuisine.values)\nx_eval_name = list(data_eval.ingredients.values)\ny_eval_name = list(data_eval.cuisine.values)\n\n# compile x, y train\nx_dic = get_unique_x(x_train_name)\nprint('All ingredients:', x_dic)\ny_dic = get_unique_y(y_train_name)\nprint('All cuisines:', y_dic)\n\n# vectorize x train\nx_train = np.zeros((len(x_train_name), len(x_dic)))\nfor i, xi in enumerate(x_train):\n    xvi = v_get_index(x_train_name[i], x_dic)\n    mat = keras.utils.to_categorical(xvi, num_classes=len(x_dic))\n    x_train[i] = np.sum(mat, axis=0)\n    if i%1000 == 0:\n        print(i, xvi)\n        print('num of total, 0, 1: {}, {}, {}'.format(len(x_train[i]), len(x_train[i][x_train[i]==0]),\n                                                     len(x_train[i][x_train[i]==1])))\nprint('Shape x_train:', x_train.shape)\ninput_dim = x_train.shape[1]\n\n# vectorize y train\ny_train = keras.utils.to_categorical(v_get_index(y_train_name, y_dic), num_classes=len(y_dic))\nprint('Shape y_train:', y_train.shape)\noutput_dim = y_train.shape[1]\n\n# vectorize x eval\nx_eval = np.zeros((len(x_eval_name), len(x_dic)))\nfor i, xi in enumerate(x_eval):\n    xvi = v_get_index(x_eval_name[i], x_dic)\n    mat = keras.utils.to_categorical(xvi, num_classes=len(x_dic))\n    x_eval[i] = np.sum(mat, axis=0)\n    if i%1000 == 0:\n        print(i, xvi)\n        print('num of total, 0, 1: {}, {}, {}'.format(len(x_eval[i]), len(x_eval[i][x_eval[i]==0]),\n                                                     len(x_eval[i][x_eval[i]==1])))\nprint('Shape x_eval:', x_eval.shape)\n\n# vectorize y test\ny_eval = keras.utils.to_categorical(v_get_index(y_eval_name, y_dic), num_classes=len(y_dic))\nprint('Shape y_eval:', y_eval.shape)\n\"\"\"\n\nfrom keras.preprocessing.text import Tokenizer\n\n# get all x, y\nx_train_name = data_train.ingredients.values\ny_train_name = data_train.cuisine.values\nx_eval_name = data_eval.ingredients.values\ny_eval_name = data_eval.cuisine.values\n\n# vectorize train data\ntx = Tokenizer(filters='', split=None)\ntx.fit_on_texts(x_train_name)\nx_train = tx.texts_to_matrix(x_train_name)\nx_eval = tx.texts_to_matrix(x_eval_name)\ninput_dim = x_train.shape[1]\n\nty = Tokenizer(filters='', split=None)\nty.fit_on_texts(y_train_name)\ny_train = ty.texts_to_matrix(y_train_name)\ny_eval = ty.texts_to_matrix(y_eval_name)\noutput_dim = y_train.shape[1]\ny_inv = dict(map(reversed, ty.word_index.items()))\n\n# check\nprint('Shape x_train, x_eval =', x_train.shape, x_eval.shape)\nprint('Shape y_train, y_eval =', y_train.shape, y_eval.shape)\ni = 0\nprint('x_train_name[{}] = {}'.format(i, x_train_name[i]))\nprint('x_train[{}]: N_total = {}, N_0 = {}, N_1 = {}'.format(\n    i, len(x_train[i]), len(x_train[i][x_train[i]==0]), len(x_train[i][x_train[i]==1])))\nprint('y_train_name[{}] = {}'.format(i, y_train_name[i]))\nprint('y_train[{}]: N_total = {}, N_0 = {}, N_1 = {}'.format(\n    i, len(y_train[i]), len(y_train[i][y_train[i]==0]), len(y_train[i][y_train[i]==1])))\nprint('y_inv =', y_inv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a0f352b9776ba44569f9fa52019a7a825b5d9cb","scrolled":true},"cell_type":"code","source":"# Train\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=input_dim, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(output_dim, activation='softmax'))\n\nsgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=sgd,\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=40, batch_size=128)\nif r_eval > 0:\n    score = model.evaluate(x_eval, y_eval, batch_size=128)\n    print(model.metrics_names, '=', score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d661cf3937b8359da12ddcd5e63b8acc67b8d1d"},"cell_type":"code","source":"test = pd.read_json('../input/test.json')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"556cb91d497f502b73991eecd2056a37f19022a7","collapsed":true},"cell_type":"code","source":"# predict\nx_test = tx.texts_to_matrix(test.ingredients)\ny_test = model.predict(x_test)\ny_test_name = [y_inv[k] for k in np.argmax(y_test, axis=1)]\n\n# save\nout = pd.DataFrame({\n    'id': test.id,\n    'cuisine': y_test_name })\nout.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9611389ccec72cc735510cb824d3d978d7ed83d"},"cell_type":"code","source":"out.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"159cec4c484e3c3800c50ba16adeff9688ca00fb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}