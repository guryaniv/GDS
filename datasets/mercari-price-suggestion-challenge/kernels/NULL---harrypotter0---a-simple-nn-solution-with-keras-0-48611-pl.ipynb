{"cells":[{"metadata":{"_uuid":"e4561cb64722ffd7adb74a8800f89973bc3fe87a","_cell_guid":"f49a0842-1c3d-4bee-8b3e-3caf6111bb60","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.cross_validation import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"56874f4a359241631a1f1e4788da09e7b09182b8","collapsed":true,"_cell_guid":"17b85633-4dae-4a49-9573-5d5c3b1b9699","trusted":false},"cell_type":"code","source":"def rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n#Source: https://www.kaggle.com/marknagelberg/rmsle-function","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80cd3abaf2d32b2c8133719d9a7bbb977adf91cb","collapsed":true,"_cell_guid":"a76efe2c-34bb-458a-8611-1dcabda65b31","trusted":false},"cell_type":"code","source":"#LOAD DATA\nprint(\"Loading data...\")\ntrain = pd.read_table(\"../input/train.tsv\")\ntest = pd.read_table(\"../input/test.tsv\")\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"967a5f2b26862be11cdae8cb0fb7402fd486135c","collapsed":true,"_cell_guid":"4e506bee-5541-4879-aaea-159dee4416b8","trusted":false},"cell_type":"code","source":"#HANDLE MISSING VALUES\nprint(\"Handling missing values...\")\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1aa305c5227f3a4d6b5a5bdf6aa55fe55cf46548","collapsed":true,"_cell_guid":"39007c90-161e-4ef0-b0a5-fc16f04665b4","trusted":false},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cf9985161bcd94612b1359177e23124efd3410cb","collapsed":true,"_cell_guid":"204de9ca-7ea5-481b-9039-743bbab1084f","trusted":false},"cell_type":"code","source":"#PROCESS CATEGORICAL DATA\nprint(\"Handling categorical variables...\")\nle = LabelEncoder()\n\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le\n\ntrain.head(3)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff62bf6d3681b84510026bfa3514963513f2e8f2","collapsed":true,"_cell_guid":"b122ac7a-c203-463f-aa92-b843b039fce3","trusted":false},"cell_type":"code","source":"#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n\nprint(\"   Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\nprint(\"   Transforming text to seq...\")\n\ntrain[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\ntest[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\ntrain[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"335a3d95444a2602598aebbfa6de0a8a3f5a1814","collapsed":true,"_cell_guid":"9da5165e-0692-4c1a-a5e7-3fb1c6c1a4fd","trusted":false},"cell_type":"code","source":"#SEQUENCES VARIABLES ANALYSIS\nmax_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"32ffa5a96deaeb6214469a2594475f7b5a15bc92","collapsed":true,"_cell_guid":"3e87bf13-093e-42a3-bef9-ed10322944df","trusted":false},"cell_type":"code","source":"train.seq_name.apply(lambda x: len(x)).hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdfde374cbe6f2edc9c453f91ef90c757c8d8f06","collapsed":true,"_cell_guid":"09349ced-fcac-4406-8876-a00fc269218d","trusted":false},"cell_type":"code","source":"train.seq_item_description.apply(lambda x: len(x)).hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cae7d35e8b44e04df93c9f8084ec67ef40a1828","collapsed":true,"_cell_guid":"e1b9db3a-63de-4bd9-9bad-2db899176053","trusted":false},"cell_type":"code","source":"#EMBEDDINGS MAX VALUE\n#Base on the histograms, we select the next lengths\nMAX_NAME_SEQ = 10\nMAX_ITEM_DESC_SEQ = 75\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())\n                  , np.max(train.seq_item_description.max())\n                  , np.max(test.seq_item_description.max())])+2\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53474065f08e5d469e4a65bd272c0b316ae26b1e","collapsed":true,"_cell_guid":"cb88f6b3-44ab-4ab4-831a-6a3ebdd0e10d","trusted":false},"cell_type":"code","source":"#SCALE target variable\ntrain[\"target\"] = np.log(train.price+1)\ntarget_scaler = MinMaxScaler(feature_range=(-1, 1))\ntrain[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\npd.DataFrame(train.target).hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38f7f125582a88eba6410d93306df119e454db82","collapsed":true,"_cell_guid":"abf9cd11-efa2-4a2c-b844-cdf2fc23bbd8","trusted":false},"cell_type":"code","source":"#EXTRACT DEVELOPTMENT TEST\ndtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f876f24ae0e5a82bdf9b0568f796cce5e2fed2c","collapsed":true,"_cell_guid":"22f34be1-bd4a-4ad1-a931-62873816e8ee","trusted":false},"cell_type":"code","source":"#KERAS DATA DEFINITION\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef get_keras_data(dataset):\n    X = {\n        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n        ,'brand_name': np.array(dataset.brand_name)\n        ,'category_name': np.array(dataset.category_name)\n        ,'item_condition': np.array(dataset.item_condition_id)\n        ,'num_vars': np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8af261410908e6c713ca7de01c3c2c549debf779","collapsed":true,"_cell_guid":"79428c10-e754-4e0e-a8be-ecbe74ef55ff","trusted":false},"cell_type":"code","source":"#KERAS MODEL DEFINITION\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\ndef get_model():\n    #params\n    dr_r = 0.1\n    \n    #Inputs\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #Embeddings layers\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layer\n    rnn_layer1 = GRU(16) (emb_item_desc)\n    rnn_layer2 = GRU(8) (emb_name)\n    \n    #main layer\n    main_l = concatenate([\n        Flatten() (emb_brand_name)\n        , Flatten() (emb_category_name)\n        , Flatten() (emb_item_condition)\n        , rnn_layer1\n        , rnn_layer2\n        , num_vars\n    ])\n    main_l = Dropout(dr_r) (Dense(128) (main_l))\n    main_l = Dropout(dr_r) (Dense(64) (main_l))\n    \n    #output\n    output = Dense(1, activation=\"linear\") (main_l)\n    \n    #model\n    model = Model([name, item_desc, brand_name\n                   , category_name, item_condition, num_vars], output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n    \n    return model\n\n    \nmodel = get_model()\nmodel.summary()\n    \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fa44a0c7fcca9b0f0c15719be8ac38a2ee7cea8","collapsed":true,"_cell_guid":"b19fde2e-e454-48fd-b336-de0b15051fc8","trusted":false},"cell_type":"code","source":"#FITTING THE MODEL\nBATCH_SIZE = 20000\nepochs = 5\n\nmodel = get_model()\nmodel.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n          , validation_data=(X_valid, dvalid.target)\n          , verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5065d64200d6c4675901e727ddf87afc8136a0c3","collapsed":true,"_cell_guid":"0bfc00c9-37d7-4ebe-9f9c-2bf0661aef3c","trusted":false},"cell_type":"code","source":"#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\nval_preds = model.predict(X_valid)\nval_preds = target_scaler.inverse_transform(val_preds)\nval_preds = np.exp(val_preds)+1\n\n#mean_absolute_error, mean_squared_log_error\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds[:,0]\nv_rmsle = rmsle(y_true, y_pred)\nprint(\" RMSLE error on dev test: \"+str(v_rmsle))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59772da91cbcb781396138d860d7875a23accaa9","collapsed":true,"_cell_guid":"996256b1-8628-4a8a-9e75-2eae09fa7d6e","trusted":false},"cell_type":"code","source":"#CREATE PREDICTIONS\npreds = model.predict(X_test, batch_size=BATCH_SIZE)\npreds = target_scaler.inverse_transform(preds)\npreds = np.exp(preds)-1\n\nsubmission = test[[\"test_id\"]]\nsubmission[\"price\"] = preds","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"270683b6ea8391d536aa86deeb7d0b381a9006ba","collapsed":true,"_cell_guid":"8b76a6c9-fa82-4011-82ab-0384b8e2e5b4","trusted":false},"cell_type":"code","source":"submission.to_csv(\"./myNNsubmission.csv\", index=False)\nsubmission.price.hist()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0e07027d44dcda199db405c974a05276a3fb4ac","_cell_guid":"4f194864-1f59-4b94-871b-3b3ee6f01fd2"},"cell_type":"markdown","source":"This was just an example how nn can solve this problems. Potencial improvements of the kernel:\n    - Increase the embeddings factos\n    - Decrease the batch size\n    - Add Batch Normalization\n    - Try LSTM, Bidirectional RNN, stack RNN\n    - Try with more dense layers or more rnn outputs\n    -  etc. Or even try a new architecture!\n    \nAny comment will be welcome. Thanks!\n \n    "}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}