{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport math\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"def load_dataset():\n    train_set = pd.read_csv('../input/train.csv')\n    test_set  = pd.read_csv('../input/test.csv' )\n    \n    train_set_x      = train_set.drop(columns=['label'])\n    train_set_x_orig = np.array(train_set_x)\n    train_set_y_orig = np.array(train_set['label'][:])\n    \n    #train_set_x_final, train_set_y_final, dev_set_x_final, dev_set_y_final = train_test_split(train_set_x_flat, train_set_y_orig, test_size=0.1, random_state=42)\n    \n    test_set_x_orig = np.array(test_set)\n    \n    return train_set_x_orig, train_set_y_orig, test_set_x_orig","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"7451689d-51dd-4e61-90d4-7d6f4cc9e58f","_uuid":"6e29aaba6533d3e93d52cb05f034a38a01dfd87b","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train_orig, Y_train_orig, X_test_orig = load_dataset()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"3401f793-3c74-4073-9365-8b5c79da2c43","_uuid":"5e143bfe354387abf0c8c808118131c27cc25a34","trusted":true},"cell_type":"code","source":"print(X_train_orig.shape)\nprint(Y_train_orig.shape)\nprint(X_test_orig.shape)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"1a4a0b38-fb0c-4db6-9575-ecca0cce75c8","_uuid":"a7a1f4689923881e3cb066dd1cc67194b1785215","collapsed":true,"trusted":true},"cell_type":"code","source":"X_train, X_dev, Y_train, Y_dev = train_test_split(X_train_orig, Y_train_orig, test_size = 0.1, random_state=42)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"96318dbe-1528-4668-b8f9-017cf220ea56","_uuid":"0f3b50075dbfe5a405c84a88e3cf3a6d746df12b","collapsed":true,"trusted":true},"cell_type":"code","source":"def convert_to_one_hot(labels, C):\n    C = tf.constant(C, name = 'C')    \n    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n\n    sess = tf.Session()\n    one_hot = sess.run(one_hot_matrix)\n    sess.close()\n    \n    return one_hot","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"ada42b20-25a4-4b85-83c6-207e70bedbce","_uuid":"9535c8669349e2f5a6a24d43fe0125027e431551","collapsed":true,"trusted":true},"cell_type":"code","source":"Y_train = convert_to_one_hot(Y_train, 10)\n\nX_train = X_train.reshape(X_train.shape[0], -1).T\nX_train = X_train/255\n\nY_dev = convert_to_one_hot(Y_dev, 10)\n\nX_dev = X_dev.reshape(X_dev.shape[0], -1).T\nX_dev = X_dev/255\n\nX_test = X_test_orig.reshape(X_test_orig.shape[0], -1).T\nX_test = X_test/255","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"cf648534-3838-40a1-9ab7-237dfd96f8b6","_uuid":"0837f098f0a435d55af02792f9ca8ae908c1350c","trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(Y_train.shape)\nprint(X_dev.shape)\nprint(Y_dev.shape)\nprint(X_test .shape)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"52b9d23b-15c2-4f6e-8d3a-19775a7bc220","_uuid":"1b390645283548aa40a4da7c202219197a2bbd37","collapsed":true,"trusted":true},"cell_type":"code","source":"def create_placeholders(n_x, n_y):\n    X = tf.placeholder(tf.float32, shape=(n_x, None), name='X')\n    Y = tf.placeholder(tf.float32, shape=(n_y, None), name='Y')\n\n    return X, Y","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"2b136615-ba95-4e7e-8808-a2d229fbd1d1","_uuid":"d3ddf955b5111e31a3dc3066d42868d1b4eb447e","collapsed":true,"trusted":true},"cell_type":"code","source":"def initialize_parameters():\n    W1 = tf.get_variable('W1', [25, 784], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b1 = tf.get_variable('b1', [25,   1], initializer = tf.zeros_initializer())\n    W2 = tf.get_variable('W2', [12,  25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b2 = tf.get_variable('b2', [12,   1], initializer = tf.zeros_initializer())\n    W3 = tf.get_variable('W3', [10,  12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n    b3 = tf.get_variable('b3', [10,   1], initializer = tf.zeros_initializer())\n    \n    parameters = { 'W1' : W1,\n                   'b1' : b1,\n                   'W2' : W2,\n                   'b2' : b2,\n                   'W3' : W3,\n                   'b3' : b3 }\n    \n    return parameters","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"a9025540-66cc-4da2-9fb0-64f59ff8b7cc","_uuid":"c5bac7974584abbffbeaff88f8fd5e56853b2396","collapsed":true,"trusted":true},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    \n    W1 = parameters['W1'] \n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n\n    Z1 = tf.add(tf.matmul(W1, X), b1)\n    A1 = tf.nn.relu(Z1)\n    Z2 = tf.add(tf.matmul(W2, A1), b2)\n    A2 = tf.nn.relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)\n\n    return Z3","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"ef4e8dd4-fd51-40ea-bf69-996586c2b3e1","_uuid":"f2c50c699758de70720a0b309b1531a12c691551","collapsed":true,"trusted":true},"cell_type":"code","source":"def compute_cost(Z3, Y):\n    logits = tf.transpose(Z3)\n    labels = tf.transpose(Y)\n    \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels = labels))\n    \n    return cost","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"fb45068e-2ce8-4a74-a882-7f8c3d1a1606","_uuid":"d648d4000e3ba8977b29ffbb3ab78906295c1de6","collapsed":true,"trusted":true},"cell_type":"code","source":"def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    m = X.shape[1]\n    mini_batches = []\n    np.random.seed(seed)\n    \n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n\n    num_complete_minibatches = math.floor(m/mini_batch_size)\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"086ad09e-d4ef-4d2d-857b-9633658a27b8","_uuid":"efd76e1f6e1d5c1316c3ed4d8ffcfa2883937424","collapsed":true,"trusted":true},"cell_type":"code","source":"def model(X_train, Y_train, learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True):\n    ops.reset_default_graph()\n    (n_x, m) = X_train.shape\n    n_y = Y_train.shape[0]\n    costs = []\n    \n    X, Y = create_placeholders(n_x, n_y) \n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    cost = compute_cost(Z3, Y) \n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    \n    init = tf.global_variables_initializer()\n    \n    with tf.Session() as sess:\n        sess.run(init)\n        for epoch in range(num_epochs):\n            epoch_cost = 0\n            num_minibatches = int(m / minibatch_size)\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n            \n            for minibatch in minibatches:\n                (minibatch_X, minibatch_Y) = minibatch\n                \n                _, mini_batch_cost = sess.run([optimizer, cost], feed_dict = { X : minibatch_X, Y : minibatch_Y})\n                epoch_cost += mini_batch_cost / num_minibatches\n                \n            if print_cost == True and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n                plt.plot(np.squeeze(costs))\n        \n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        parameters = sess.run(parameters)\n        \n        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n\n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n        print (\"Test Accuracy:\", accuracy.eval({X: X_dev, Y: Y_dev}))\n        \n        return parameters","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"303785dd-66ff-4465-80bc-ca4bbd122bbe","_uuid":"c19f8c4ec5eece93c3ebf323b1489e2fff4e77ff","scrolled":true,"trusted":true},"cell_type":"code","source":"parameters = model(X_train, Y_train, num_epochs = 700)","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"c2d055c6-4067-4c0f-a649-2fa2fb54e1aa","_uuid":"148b69eafe3916e479d79a67f87e584b13f35d65","collapsed":true,"trusted":true},"cell_type":"code","source":"def forward_propagation_for_predict(X, parameters):\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3'] \n                                                           # Numpy Equivalents:\n    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n    \n    return Z3","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"e5498271-e039-483f-9465-48cd651d23bd","_uuid":"4151f26535e96cc17eefdea99d9bd43262ef7448","collapsed":true,"trusted":true},"cell_type":"code","source":"def predict(X, parameters):\n    \n    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n    \n    params = {\"W1\": W1,\n              \"b1\": b1,\n              \"W2\": W2,\n              \"b2\": b2,\n              \"W3\": W3,\n              \"b3\": b3}\n    \n    x = tf.placeholder(\"float\", [784, 1])\n    \n    z3 = forward_propagation_for_predict(x, params)\n    p = tf.argmax(z3)\n    \n    sess = tf.Session()\n    prediction = sess.run(p, feed_dict = {x: X})\n        \n    return prediction","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"12dda11b-f1c3-42e2-a355-4e754c62aa8b","_uuid":"ad8150e7904b4270113dbc8d8488fa8d98ec1834","collapsed":true,"trusted":true},"cell_type":"code","source":"train_set_verify = pd.read_csv('../input/train.csv' )\ntest_set_submit  = pd.read_csv('../input/test.csv'  )","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"8baf194d-81d2-4d41-b854-eadcbbbd4c37","_uuid":"9f5b050b99ee8f291073f9135a2182e222142715","collapsed":true,"trusted":true},"cell_type":"code","source":"index = 18\n\ntrain_set_test = train_set_verify.iloc[index]\ntrain_set_test = train_set_test.drop(['label'], axis=0)","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"8b81d1a3-fc2e-4b8e-bd05-e92bb0f58e4a","_uuid":"700dd6ae97ea12ca9497b305b2320fe811eb73c5","collapsed":true,"trusted":true},"cell_type":"code","source":"np_train_set_test = np.array(train_set_test)","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"8d249ffc-3f25-4e3d-9bcf-084a68e8508b","_uuid":"fd7e79e5ed736af3f1740d0c8adeab0d8bd21d45","collapsed":true,"trusted":true},"cell_type":"code","source":"np_train_set_test = np_train_set_test.reshape(np_train_set_test.shape[0], -1)\nnp_train_set_test = np_train_set_test/255","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"3e093e08-6579-4eee-8f59-12236efdf033","_uuid":"92f5659cac8bc9fd2d7f900b1b85ed3dbcaea73f","collapsed":true,"trusted":true},"cell_type":"code","source":"np_train_set_test.shape\nmy_image_prediction = predict(np_train_set_test, parameters)","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"99cd8af4-5254-4343-86eb-7d1107877204","_uuid":"4af35250a7332fc87ac48854925211e8706e99d3","scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"My algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))\nprint(\"Actual Value is: y = \" + str(train_set_verify.iloc[index][0]))","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"c3340687-2e48-4662-9bfe-bfc9a929db68","_uuid":"cb7a0c3c4a39c29266f93eedb63ba7d5794a0d8a","collapsed":true,"trusted":true},"cell_type":"code","source":"columns = ['ImageId', 'Label']\npredictions = pd.DataFrame(columns = columns)","execution_count":26,"outputs":[]},{"metadata":{"_cell_guid":"5ad4f66c-3e80-45a5-9335-19d6ea79812a","_uuid":"5bb8e15e31912ef6fb45fed09f0e194e4c5f9bc9","trusted":true},"cell_type":"code","source":"W1 = tf.convert_to_tensor(parameters[\"W1\"])\nb1 = tf.convert_to_tensor(parameters[\"b1\"])\nW2 = tf.convert_to_tensor(parameters[\"W2\"])\nb2 = tf.convert_to_tensor(parameters[\"b2\"])\nW3 = tf.convert_to_tensor(parameters[\"W3\"])\nb3 = tf.convert_to_tensor(parameters[\"b3\"])\n\nx = tf.placeholder(\"float\", [784, 1])\nZ1 = tf.add(tf.matmul(W1, x), b1) \nA1 = tf.nn.relu(Z1)               \nZ2 = tf.add(tf.matmul(W2, A1), b2)\nA2 = tf.nn.relu(Z2)               \nZ3 = tf.add(tf.matmul(W3, A2), b3)\np = tf.argmax(Z3)\nsess = tf.Session()\n\nfor index in range(X_test.shape[1]):\n    cur_test = X_test[:, index].reshape(X_test.shape[0], -1)\n    prediction = sess.run(p, feed_dict = { x : cur_test })\n    \n    if index % 4000 == 0:\n        print(index)\n    #print(\"My algorithm predicts: y = \" + str(np.squeeze(prediction))) \n\n    predictions = predictions.append({'ImageId' : index+1, 'Label' : str(np.squeeze(prediction))}, ignore_index=True)\n    \nsess.close()","execution_count":28,"outputs":[]},{"metadata":{"_cell_guid":"a665af2c-1b00-4bba-9c1f-3b245092c4e6","_uuid":"1317be2a5d712f0ef87a42d653326ad3e2569af5","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions = predictions.set_index('ImageId')","execution_count":29,"outputs":[]},{"metadata":{"_cell_guid":"fe10b444-8f77-4be0-a826-000e43da2c9f","_uuid":"5e83dbf40131a49dfda0792bcd6e93a36f1bb540","collapsed":true,"trusted":true},"cell_type":"code","source":"predictions.to_csv('MNIST_SUBMISSION.csv')","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"1a7b6f68-b2ce-4a71-a029-53cf917b9e79","_uuid":"8bb16facd43842f3f17c8b965ddad4ccc5bd13cc","trusted":true},"cell_type":"code","source":"predictions.head()","execution_count":31,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8260f669a18e83500f3edd9b49c70ef3e5feb130"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}