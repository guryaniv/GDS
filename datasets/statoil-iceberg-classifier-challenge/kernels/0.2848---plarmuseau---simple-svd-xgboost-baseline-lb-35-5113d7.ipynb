{"cells": [{"metadata": {"_cell_guid": "057b28f0-4682-4bce-a25f-9e07f478450f", "_uuid": "5aed6729ec2b6aaf3d0cdec5da3a24cd5508a175"}, "source": ["We aim to use svd to dimensionally reduce the images to just a few features (20 per image in this particular case), which works nicely as it turns out most of variance in the image is just noise. LB should be aroun ~0.35, but I've played a bit with xgb parameters and the crossvalidation improved, this suggest that perhaps you can get lower LB if you submit this notebook. "], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "08e02f57-9c97-487a-ab0d-b2afad161d53", "_uuid": "e6b43e7b7d786bc565deb7c52acd78d2885d9837", "collapsed": true}, "source": ["#load with pandas, manipulate with numpy, plot with matplotlib\n", "import numpy as np \n", "import pandas as pd \n", "import matplotlib.pyplot as plt\n", "\n", "#ML - we will classify using a naive xgb with stratified cross validation\n", "import xgboost as xgb\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.metrics import log_loss\n", "\n", "\n", "\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "232aecf4-a711-415c-8b23-d277824788c3", "_uuid": "027ce3e753ae41fbe6600369f6dd38047e1fdd59", "collapsed": true}, "source": ["#filenames\n", "inputFolder = \"../input/\"\n", "trainSet = 'train.json'\n", "testSet = 'test.json'\n", "subName = 'iceberg-svd-xgb-3fold.csv'\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "2d055ac8-6c5d-4bd3-8f93-c981379fe57a", "_uuid": "f52fbe147c7723767b3f03200c9746ba5abdaae5", "collapsed": true}, "source": ["#load data\n", "trainDF = pd.read_json(inputFolder+trainSet)\n", "testDF = pd.read_json(inputFolder+testSet)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "a2ff70e4-e630-419b-b6b3-9a8be46a7014", "_uuid": "7f08caa08f99b025488c086b4a610333e306d087", "collapsed": true}, "source": ["#get numpy arrays for train/test data, prob there is a more pythonic approach\n", "band1 = trainDF['band_1'].values\n", "im1 = np.zeros((len(band1),len(band1[0])))\n", "for j in range(len(band1)):\n", "    im1[j,:]=np.asarray(band1[j])\n", "    \n", "band2 = trainDF['band_2'].values\n", "im2 = np.zeros((len(band2),len(band2[0])))\n", "for j in range(len(band2)):\n", "    im2[j,:]=np.asarray(band2[j])\n", "    \n", "#get numpy array for test data\n", "band1test = testDF['band_1'].values\n", "im1test = np.zeros((len(band1test),len(band1test[0])))\n", "for j in range(len(band1test)):\n", "    im1test[j,:]=np.asarray(band1test[j])\n", "    \n", "band2test = testDF['band_2'].values\n", "im2test = np.zeros((len(band2test),len(band2test[0])))\n", "for j in range(len(band2test)):\n", "    im2test[j,:]=np.asarray(band2test[j])"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "eec13fca-3462-46e8-8f1e-c462f1c90d99", "_uuid": "78e22d6cc95e32ddbcbbf4d07dc7138b7b81e978", "collapsed": true}, "source": ["import cv2\n", "from skimage import filters\n", "from skimage import data, exposure\n", "\n", "U1,s1,V1 = np.linalg.svd(np.vstack((im1,im1test)),full_matrices = 0)\n", "U2,s2,V2 = np.linalg.svd(np.vstack((im2,im2test)),full_matrices = 0)\n", "#svd of the two bands\n", "Uh1,sh1,Vh1 = np.linalg.svd(exposure.equalize_hist(np.vstack((im1,im1test))),full_matrices = 0)\n", "Uh2,sh2,Vh2 = np.linalg.svd(exposure.equalize_hist(np.vstack((im2,im2test))),full_matrices = 0)\n", "print(Uh2.shape,Vh2.shape)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "28f0bea0-ad1e-4dac-be86-f76096aeab2f", "_uuid": "e8e87c37e83b9be919a0f98a8ccda59495466ee8", "collapsed": true}, "source": ["#original \n", "nmodes=20\n", "\n", "im1p=np.dot(U1[:,:nmodes],V1[:nmodes,])\n", "im2p=np.dot(U2[:,:nmodes],V2[:nmodes,])\n", "im1ph=np.dot(Uh1[:,:nmodes],Vh1[:nmodes,])\n", "im2ph=np.dot(Uh2[:,:nmodes],Vh2[:nmodes,])\n"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "8907b35b-6d4a-4b52-9c64-7ef47f604809", "_uuid": "8f769429220e7b3b4cb252da26dc75d308bf1404", "collapsed": true}, "source": ["\n", "nmodes = 20\n", "\n", "X = np.hstack((U1[:len(trainDF),:nmodes],U2[:len(trainDF),:nmodes]))\n", "X = np.hstack((X,Uh1[:len(trainDF),:nmodes]))\n", "X = np.hstack((X,Uh2[:len(trainDF),:nmodes]))\n", "X_test = np.hstack((U1[len(trainDF):,:nmodes],U2[len(trainDF):,:nmodes]))\n", "X_test = np.hstack((X_test,Uh1[len(trainDF):,:nmodes]))\n", "X_test = np.hstack((X_test,Uh2[len(trainDF):,:nmodes]))\n", "y = trainDF['is_iceberg'].values"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "a1569666-7286-43af-b31e-842c9dbb8795", "_uuid": "581325179817744f640cbad47b040c4dc282552a", "collapsed": true}, "source": ["#is there a native xgb way of doing it?\n", "def logloss_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    score = log_loss(labels, preds)\n", "    return 'logloss', score"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "db22c09b-3f05-4cab-b65c-98b96ef2a2c5", "_uuid": "b1f4522cbe45692088e1fe1d817f1db387cddaee", "collapsed": true}, "source": ["nfolds = 3;\n", "xgb_mdl=[None]*nfolds\n", "\n", "\n", "xgb_params = {\n", "        'objective': 'binary:logistic',\n", "        'n_estimators':1000,\n", "        'max_depth': 8,\n", "        'subsample': 0.9,\n", "        'colsample_bytree': 0.9 ,\n", "     #   'max_delta_step': 1,\n", "     #   'min_child_weight': 10,\n", "        'eta': 0.01,\n", "      #  'gamma': 0.5\n", "        }\n", "\n", "\n", "folds = list(StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=2016).split(X, y))\n", "\n", "d_test = xgb.DMatrix(X_test)\n", "\n", "preds = np.zeros((X_test.shape[0],nfolds))\n", "\n", "for j, (train_idx, valid_idx) in enumerate(folds):\n", "    X_train = X[train_idx]\n", "    y_train = y[train_idx]\n", "    \n", "    X_valid = X[valid_idx]\n", "    y_valid = y[valid_idx]\n", "    \n", "    d_train =  xgb.DMatrix(X_train,label=y_train)\n", "    d_valid =  xgb.DMatrix(X_valid,label=y_valid)\n", "    \n", "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n", "    \n", "    xgb_mdl[j]=xgb.train(\n", "            xgb_params, \n", "            d_train, \n", "            1600, watchlist, \n", "            early_stopping_rounds=70, \n", "            feval=logloss_xgb, \n", "            maximize=False, \n", "            verbose_eval=100)\n", "    preds[:,j] = xgb_mdl[j].predict(d_test)"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "source": ["import matplotlib.pyplot as plt\n", "y = trainDF['is_iceberg'].values\n", "pre = xgb_mdl[j].predict(xgb.DMatrix(X))\n", "plt.scatter(pre, y)\n", "plt.show()"], "cell_type": "code"}, {"outputs": [], "execution_count": null, "metadata": {"_cell_guid": "1fe79978-e5fa-4e5d-9192-9b309ae12e45", "_uuid": "ee960d6bb03549e9b7956715ebd3a670af600a8e", "collapsed": true}, "source": ["y_pred = np.mean(preds,axis=1)\n", "sub = pd.DataFrame()\n", "sub['id'] = testDF['id']\n", "sub['is_iceberg'] = y_pred\n", "sub.to_csv(subName, index=False)\n"], "cell_type": "code"}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.3", "mimetype": "text/x-python"}}}