{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt # date and time\nimport matplotlib.pyplot as plt # plotting tool\nimport seaborn as sns # plotting tool\nimport random  #random values generator\nfrom scipy.stats import ttest_ind ## statistical library\n# this part is to connect to the dataset of the competition, It is only accessible from \n# kaggle notebook\n\nfrom kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n## Setting the golabl figure size of all plots included in this report\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b04ee966666afe23dd16dd6319255ed7a1a9850","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"## Getting rid of the noisy warnings and side information when running plots \nimport warnings\nwarnings.filterwarnings('ignore')\n## setting the plot figure size\nplt.rcParams['figure.figsize'] = (20.0, 10.0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"markdown","source":"\n  **ABOUT THE DATA**\n        The Data comes from the Kaggle competition titled ( Two Sigma: Using News to Predict Stock Movements ) in this website : https://www.kaggle.com/c/two-sigma-financial-news\n        \n1.  Market data (2007 to present) provided by Intrinio - contains financial market information such as opening price, closing price, trading volume, calculated returns, etc\n2.  News data (2007 to present) Source: Thomson Reuters - contains information about news articles/alerts published about assets, such as article details, sentiment, and other commentary\n     \n\n    News data provided by Thomson Reuters. Copyright ©, Thomson Reuters, 2017. All Rights Reserved. Use, duplication, or sale of this service, or data contained herein, except as described in the Competition Rules, is strictly prohibited."},{"metadata":{"trusted":true,"_uuid":"c5b462a4f1e6381c53b64c1740aa087fbec76ce4"},"cell_type":"markdown","source":"## Data Overview\n\nIn this capstone project, I will explore the data, and try to answer three questions that will provide some insight about the data provided. \nFirst lets take a look at the Data :\n"},{"metadata":{"trusted":true,"_uuid":"017ae0bf662f196e8d74b225173d8ebbc2c1a98e","_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"## Showing the shape (number of ) of our 1st dataset, the market dataset\nprint(f'{market_train_df.shape[0]} samples and {market_train_df.shape[1]} features in the training market dataset.')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f8a7509eb79c747b1e9a422f8e312ee898c1562","_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"## Showing the first 5 rows of our dataset\nmarket_train_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7576fd07f05cc2bbfb387ed5e0b540214714a7b9","_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"## Showing the shape of our 2nd dataset, the news dataset\nprint(f'{news_train_df.shape[0]} samples and {news_train_df.shape[1]} features in the training news dataset.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b1e3595f3a8fe0a561146cb9aa98b8c08cdd425","_kg_hide-input":true},"cell_type":"code","source":"## Showing the last 5 rows of our dataset\nnews_train_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ecccfbf7176e5c2c090f2f11ead7c6ea50f4163b"},"cell_type":"markdown","source":"Having an overview of the data helps in the process of coming up with the exploratory questions necessery to have an idea of some of the trends or anomalies in the dataset.\n\nThe data is Big, with many rows on both tables and a hefty amount of columns or features. There are 4,072,956 samples and 16 features in the training market dataset and 9,328,750 samples and 35 features in the training news dataset. However, the questions will only involve one company at a time to minimize the data used."},{"metadata":{"_uuid":"0dc10b5ec03b6ed5446c8da7fe5412b2a1a3d315"},"cell_type":"markdown","source":"## First Question\n\nWhat is the distribution of the  daily change in price of Apple stock Over a period of time? What about a random company ?"},{"metadata":{"trusted":true,"_uuid":"f068108a7138cb458f335cc6e680ae74c9f41a48","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"# This part is to get the Apple stock rows from the original  market dataset\n\nasset1Code = 'AAPL.O'\nasset1_df = market_train_df[(market_train_df['assetCode'] == asset1Code) \n                            & (market_train_df['time'] < '2017-01-01')]\n# This part is to get a random stock rows from the original market dataset\nasset2Code = market_train_df['assetCode'][random.randint(0, market_train_df.shape[0])]\nasset2_df = market_train_df[(market_train_df['assetCode'] == f'{asset2Code}') \n                            & (market_train_df['time'] < '2017-01-01')]\n# This part is to get the Apple stock rows from the original  news dataset\nasset3Name = 'Apple Inc'\nasset3_df = news_train_df.loc[lambda df: df['assetName'] == asset3Name, :]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47f7ed60ce4098f4536a136d53ef658705309ac9"},"cell_type":"markdown","source":"### Apple stock Distribution"},{"metadata":{"trusted":true,"_uuid":"2cd85e3fec2e4e869453dbe5c6e6d17efad4d5da","_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"## This part is to plot a histogram that shows the distribution of returns in apple stock \nassets = tuple(asset1_df.loc[:,'returnsClosePrevRaw1'])\nsns.distplot(assets, hist=True, kde=True, \n             bins=int(180/5), color = 'darkblue', \n             hist_kws={'edgecolor':'black'},\n             kde_kws={'linewidth': 2, 'color':'k'})\nmeanreturn = asset1_df.loc[:,'returnsClosePrevRaw1'].values.mean()\nplt.axvline(meanreturn, \n            color='r',\n            linestyle='dashed',\n            linewidth=2)\nplt.xlabel('Apple returns at close time')\nplt.ylabel('Frequency')\nplt.title('Apple stock returns Frequency Distribution');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9de09fe259fb83d735698e40e493eee6f3a2296"},"cell_type":"markdown","source":"### The Random Stock Distribution"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d12c3e3558fbdc2eab604137eff7bbd9394a5448"},"cell_type":"code","source":"## This part is to plot a histogram that shows the distribution of returns in the random stock \nsns.distplot(asset2_df.loc[:,'returnsClosePrevRaw1'], hist=True, kde=True, \n             bins=int(180/5), color = 'burlywood', \n             hist_kws={'edgecolor':'white'},\n             kde_kws={'linewidth': 2, 'color':'k'});\nplt.axvline(asset2_df.loc[:,'returnsClosePrevRaw1'].mean(), \n            color='r', \n            linestyle='dashed', \n            linewidth=2)\nplt.xlabel(f'{asset2_df.assetName[0]} returns at close time')\nplt.ylabel('Frequency')\nplt.title(f'{asset2_df.assetName[0]} stock returns Frequency Distribution');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"151f5a19bcaf7491f1ca483e2a5387c596b9f7ee"},"cell_type":"markdown","source":"The histogram shows the returns at close time for Apple follows a normal distribution, this is what I expected but it is nice to see it. The mean of is actually around 0 (Does this mean stocks are a zero sum game ? ) \n\nFor any other random company the standard deviation and width of the normal distribution seems to be different from company to company,"},{"metadata":{"_uuid":"7aa0db3f5d809f9156bd079a62901b2319109aa2"},"cell_type":"markdown","source":"## Second Question \nis there a correlation between the number of negative sentiment news articles and the fluctuations of the stocks of apple?\n\n\nIn this part of answering the question we will use the scatterplot to see if there is a correlation between the negative sentiment level and the Apple Stock Returns Projected for 10 days and adjusted for market.\n"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7ecb25b4813143278cd68eacd15ecbbb2dea8765","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"## I will merge both data sets on the time column\n\nasset1_df['date'] = asset1_df['time'].dt.strftime(date_format='%Y-%m-%d')\nasset3_df['date'] = asset3_df['time'].dt.strftime(date_format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2669fa6e1ac7de8a0440f6132d8f8e7589e9a473","_kg_hide-input":true},"cell_type":"code","source":"## Taking only the negative sentiment rows and grouping it by the date variable to be able to merge the tabels together\n\nmeanSent = pd.DataFrame(asset3_df.groupby('date')['sentimentNegative'].mean())\n\nasset_merged = pd.merge(asset1_df, meanSent, on= 'date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8387201d4d22463efe6dfbf7c17ce6c1061e436b","scrolled":false,"_kg_hide-input":true},"cell_type":"code","source":"# plotting a scattor plot alongside a regression line that would show if there is a correlation\nsns.regplot(asset_merged.loc[:,'sentimentNegative'].values,\n            asset_merged.loc[:,'returnsOpenNextMktres10'].values, \n            line_kws={'color' : 'darkred'})\nplt.xlabel ('Negative Sentiment Level')\nplt.ylabel('Apple Stock Returns Projected')\nplt.title(f'{asset1_df.assetName[0]} stock returns Frequency Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0588ac07387499cbe0b007519384fe5c14395858"},"cell_type":"markdown","source":"From our resulted graph, the linear regression line is also added to the scatter plot, which shows there is no significant correlation between the negative sentiment and the returns of the stock. Maybe this is just the case of Apple Inc. given that their stock is not highly volatile with the news. \n\n"},{"metadata":{"_uuid":"739d43f7806ba97bfb28dec19b40d6a4ac1ee269"},"cell_type":"markdown","source":"## Third Question \nSince the previous assessment of the correlation between the sentiment of articles (The mean of the daily news sentiment value). Lets see if the mean of Apple inc stocks is statistically  different  based on the sentiment of articles (i.e. positive, negative)."},{"metadata":{"trusted":true,"_uuid":"3684df268de5ce246480e45dfa6f8e573e5a8f59","_kg_hide-input":true},"cell_type":"code","source":"## getting the positive and negative sentiment rows\nasset_negative = asset3_df.loc[lambda df: df.loc[:,'sentimentClass'] == -1, :]\n\nasset_positive =  asset3_df.loc[lambda df: df.loc[:,'sentimentClass'] == 1, :]\nmeanNeg = pd.DataFrame(asset_negative.groupby('date')['sentimentNegative'].mean())\nmeanPos = pd.DataFrame(asset_positive.groupby('date')['sentimentPositive'].mean())\nasset_merged_neg = pd.merge(asset1_df, meanNeg, on= 'date')\nasset_merged_pos = pd.merge(asset1_df, meanPos, on= 'date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58089dee8096bccfd9187623c0c453ff08ccfce9","_kg_hide-input":true,"scrolled":true},"cell_type":"code","source":"## Graphing a histogram to show the different distributions\nsns.distplot(asset_merged_neg.loc[:,'returnsOpenNextMktres10'], color=\"r\")\nsns.distplot(asset_merged_pos.loc[:,'returnsOpenNextMktres10'], color=\"g\")\n\nplt.xlabel ('returns values')\nplt.ylabel('Frequency')\nplt.title('Distribution of Returns of the opening of 10 days');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4006144fbce37243c85826c4850d96cd9b06b9f9","_kg_hide-input":true,"scrolled":false},"cell_type":"code","source":"## Applying a t-test on the \nprint(ttest_ind(asset_merged_pos.loc[:,'returnsOpenNextMktres10'], \n                asset_merged_neg.loc[:,'returnsOpenNextMktres10']))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"821f8fdfd44d5a738b20a76b569756fc6a95f6a1"},"cell_type":"markdown","source":"Given that the t-tes resutled in the values: \nT-statistic = 0.284\np-value = 0.77\n\n Usually: \n $$\\alpha = 0.05$$ \nSince our p-value is greater than our confidence interval, which means that the value lies withen the range of 97.5% and 2.5%. We can safely say that there is no significance difference in the mean of both distribution. "},{"metadata":{"_uuid":"2d0040d167ef6f1ef2f388317ac66f4d16c94f84"},"cell_type":"markdown","source":"## Extra \nI have found a way to plot a wordcloud that shows the words mostly associated with a certain feature. The below figure is showing the top words in headlines that were classified as  sentimentally negative "},{"metadata":{"trusted":true,"_uuid":"5c5413cd1dbb7b9d67d194227eed6be504be168d","_kg_hide-input":true},"cell_type":"code","source":"## this part is just a showcase of one of the ways to visulaize our data.\nfrom wordcloud import WordCloud, STOPWORDS \nstop = set(STOPWORDS)\ntext = ' '.join(asset_negative.loc[:,'headline'].str.lower().values)\nwordcloud = WordCloud(max_font_size=None, stopwords=stop, background_color='white',\n                      width=1200, height=1000).generate(text)\nplt.figure(figsize=(12, 8))\nplt.imshow(wordcloud)\nplt.title('Top  words in headlines classified as negative of Apple')\nplt.axis(\"off\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b77c66ce65417a0a64e5fe99f3311ee16852d01"},"cell_type":"markdown","source":"## Further Research\nThis is a huge dataset with many variables that may, or may not have any significant correlation with our target prediction. However, taking the adjustment effect of adding multiple variables, I believe that by using some of the supervised machine learning algorithms that test for multiple variables, such as neural networks. I would like to apply statistical analysis on the dataset using ANOVA or a similar technique to sutdy multivariable predictions.  I would also consider applying a form of factoring, Principle Component Aanalysis or BARRA factors, which are very useful in the case of financial analysis. "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}