{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport datetime\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# import libraries for visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Library for statistical operations\nimport scipy\nimport sklearn as sk\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import cross_val_predict, cross_val_score, KFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\nimport os\n# os.listdir(\"../input/\")\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_kg_hide-output":false,"collapsed":true,"_uuid":"a9641167b1a19479989a481336656860ee891dfa","_cell_guid":"8d116a89-1062-473e-b831-772b81f77244","_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Load data from spreadsheet to pandas dataframes\ntrain_data = pd.read_csv(\"../input/train.csv\", parse_dates = [1])\ntest_data = pd.read_csv(\"../input/test.csv\", parse_dates = [1])\n\n# Note that we are intentionally making a copy of the raw dataset as we'll be manipulating it\n# to make it appropriate for our ML algo code\nX_train = train_data.iloc[:, np.arange(dtype=int, start = 1, stop = 42, step = 1)].copy()\ny_train = train_data.iloc[:, [42]].copy()\nX_test = test_data.iloc[:, np.arange(dtype=int, start = 1, stop = 42, step = 1)].copy()\n\n# From the above view, we can see that \"Open Date\" is a date filed. We definitely cannot ue this field as an\n# index as this is not a time series data that we are operating on. At the same time we cannot even ignore\n# this field. One simple logic might say that how old a restaurant is might also be a factor influencing its\n# sustainability and hence revenue. But this is a mere guess.\n# In order to convert this field to a continuous field, we can take the difference of the date in dataset\n# with that of some seed date.\n\nseed = datetime.datetime(1990, 1, 1)\nX_train[\"Open Date\"] = X_train[\"Open Date\"].map(lambda d: pd.Timedelta(d - seed).days)\nX_test[\"Open Date\"] = X_test[\"Open Date\"].map(lambda d: pd.Timedelta(d - seed).days)","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"b71c577841f9f10004996bb562fbdb0575729ee4","_cell_guid":"2b611e83-0008-462b-afe8-bb4862408ac9","_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"models = []\nmodels.append((\"OLS\", linear_model.LinearRegression()))\n# models.append((\"SGD\", linear_model.SGDRegressor(loss='squared_loss', max_iter=1000)))","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"b174783ebcf957d9d9ec3cbc919c2781006a777c","_cell_guid":"b4345b94-2f95-4fb9-9f80-7fc9fa635d52"},"cell_type":"markdown","source":"### Converting categorical variables to dummy variables\nWe can see that there are three groups namely City, City Group and Type which are categorical/nominal. To be precise there are 34 cities, belonging to 2 different groups (big cities and other) and 3 different types (inline,  food court and drive through)\n\nWe are going to make use of a strategy called **[Label encoding](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder)**."},{"metadata":{"collapsed":true,"_uuid":"ecb47a98ddaf006addb74c09aa22bbf73ed6ab1c","_cell_guid":"f4e46cf3-cb43-4bfd-9c80-610457420035","trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ncolumns_to_encode = ['City', 'City Group', 'Type']\n\n# Iterating over all the common columns in train and test\nfor col in X_test.columns.values:\n    # Encoding only categorical variables\n    if X_test[col].dtypes=='object':\n        # Using whole data to form an exhaustive list of levels\n        data=X_train[col].append(X_test[col])\n        le.fit(data.values)\n        X_train[col]=le.transform(X_train[col])\n        X_test[col]=le.transform(X_test[col])","execution_count":4,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"ad78ead6544648ef6171f7323048c7b9dea2179c","_cell_guid":"1c130784-0a8e-48e3-b490-e234b5276183","trusted":true},"cell_type":"code","source":"X_train.describe()","execution_count":5,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"066293137aa8d247aa38c0e0fbe0698c20831052","_cell_guid":"716013ba-1024-46d4-bb0a-577811219ee2","trusted":true},"cell_type":"code","source":"# We'll create X_train_1, y_train_1 and X_test_1 to be used for this model which uses plain label encoding.\n\nX_train_1 = X_train.iloc[:].copy()\ny_train_1 = y_train.iloc[:].copy()\nX_test_1 = X_test.iloc[:].copy()\n\nX_scaler = StandardScaler()\ny_scaler = StandardScaler()\n\ndesign_matrix_columns = X_train.columns\nresponse_vector_columns = y_train.columns\n\nX_train_1 = pd.DataFrame(X_scaler.fit_transform(X_train_1), columns=design_matrix_columns)\ny_train_1 = pd.DataFrame(y_scaler.fit_transform(y_train_1), columns=response_vector_columns)\nX_test_1 = pd.DataFrame(X_scaler.fit_transform(X_test_1), columns=design_matrix_columns)\n\n# Now that we have converted all the columns to numerical fields, we can try and fit a linear model.\n\nfor model_name, model in models:\n    model.fit(X_train_1, y_train_1)\n    print(\"Model Name: {0}\\nModel Score: {1:.2f}%\".format(model_name, model.score(X_train_1, y_train_1) * 100))\n\n# Generate the submission file.\n#selected_model = models[0][1]\n#predicted_df = pd.DataFrame(\n#    y_scaler.inverse_transform(np.round(selected_model.predict(X_test))),\n#    columns=['Prediction']\n#)\n#predicted_df[\"Id\"] = predicted_df.index\n#predicted_df = predicted_df[['Id', 'Prediction']]\n#predicted_df\n#predicted_df.to_csv(\"../input/linear_regression_model1_submission.csv\", index=False)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"940f1e67228bbd9662d118f59954d44ce2854fd5","_cell_guid":"52f2fdfd-bd1a-4c7d-b434-97bdf4159183"},"cell_type":"markdown","source":"You can see that we aren't doing that well here. A score of 38.63% is way below par of what we would like to achive. In fact in the csv file generated, we can see a number of observations having  anegative value predicted as output.\n\nThe problem with label encoding is the implicit ordinality that it introduces in the feature. One might think that one hot encoding would be the right choice to solve this problem. But in that we have to be aware of the fact that the number of features that get added to the model might explode and quickly go out of control. Often people follow an approach where they go for one hot encoding followed by principal component analysis (PCA). But that is something that we'll take up in upcoming sections."},{"metadata":{"scrolled":false,"_uuid":"678589a8bea984d185c2845d9061043e38b35020","_cell_guid":"2d17bac5-1fa3-4cec-8075-94a38ade6353","trusted":true},"cell_type":"code","source":"X_train_2 = X_train.iloc[:].copy()\nX_test_2 = X_test.iloc[:].copy()\n\n# Perform one hot encoding on training and test data\none_hot_encoder = OneHotEncoder(dtype=np.int8, sparse=False)\ncolumns_to_encode = ['City', 'City Group', 'Type']\n\nfor col in columns_to_encode:\n    data = X_train_2[[col]].append(X_test_2[[col]])\n    one_hot_encoder.fit(data)\n    \n    temp = one_hot_encoder.transform(X_train_2[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_train_2.index.values)\n    X_train_2 = pd.concat([X_train_2, temp], axis = 1)\n    \n    temp = one_hot_encoder.transform(X_test_2[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_test_2.index.values)\n    X_test_2=pd.concat([X_test_2,temp],axis=1)\n\n# Evaluate model performance\nfor model_name, model in models:\n    model.fit(X_train_2, y_train)\n    print(\"Model Name: {0}\\nModel Score: {1:.2f}%\".format(model_name, model.score(X_train_2, y_train) * 100))\n\n#Generate the submission file.\n# selected_model = models[0][1]\n# predicted_df = pd.DataFrame(\n#    np.round(selected_model.predict(X_test_2)),\n#    columns=['Prediction']\n# )\n# predicted_df[\"Id\"] = predicted_df.index\n# predicted_df = predicted_df[['Id', 'Prediction']]\n# predicted_df.to_csv(\"../input/linear_regression_model2_submission.csv\", index=False)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"88a46100e76fe20dbe76a6ccce3589160a1ee6c3","_cell_guid":"1cb78df9-b11d-4f92-ac8a-ae5e4b7aed10"},"cell_type":"markdown","source":"You will notice that although the model has shown some improvement with respect to performance/accuracy on training data, it continues to perform poorly on test data. We'll continue to refine this to improve our model's accuracy. In the section below, wera re going to make use of MinMax scaler to scale the raining and test data."},{"metadata":{"scrolled":false,"_uuid":"09ad354ad5c065b20d367fef380c85727c70b520","_cell_guid":"45c9869e-e10e-40d7-8883-be82ddd81a45","trusted":true},"cell_type":"code","source":"X_train_3 = X_train.iloc[:].copy()\nX_test_3 = X_test.iloc[:].copy()\ny_train_3 = y_train.iloc[:].copy()\n\n# Perform one hot encoding on training and test data\none_hot_encoder = OneHotEncoder(dtype=np.int8, sparse=False)\ncolumns_to_encode = ['City', 'City Group', 'Type']\n\nfor col in columns_to_encode:\n    data = X_train_3[[col]].append(X_test_3[[col]])\n    one_hot_encoder.fit(data)\n    temp = one_hot_encoder.transform(X_train_3[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_train_3.index.values)\n    X_train_3 = pd.concat([X_train_3, temp], axis = 1)\n    X_train_3.drop([col], axis = 1, inplace = True)\n    \n    temp = one_hot_encoder.transform(X_test_3[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_test_3.index.values)\n    X_test_3 = pd.concat([X_test_3,temp],axis=1)\n    X_test_3.drop([col], axis = 1, inplace = True)\n\n# Perform MinMax scaling to scale each feature to a range between 0 and 1\nX_scaler = MinMaxScaler(feature_range=(0,1))\ny_scaler = MinMaxScaler(feature_range=(0,1))\n\ndesign_matrix_columns = X_train_3.columns\nresponse_vector_columns = y_train_3.columns\n\nX_train_3 = pd.DataFrame(X_scaler.fit_transform(X_train_3), columns=design_matrix_columns)\nX_test_3 = pd.DataFrame(X_scaler.fit_transform(X_test_3), columns=design_matrix_columns)\ny_train_3 = pd.DataFrame(y_scaler.fit_transform(y_train_3), columns=response_vector_columns)\n\n# Evaluate model performance\nfor model_name, model in models:\n    model.fit(X_train_3, y_train_3)\n    print(\"Model Name: {0}\\nModel Score: {1:.2f}%\".format(model_name, model.score(X_train_3, y_train_3) * 100))\n\n#Generate the submission file.\n# selected_model = models[0][1]\n# predicted_df = pd.DataFrame(\n#    y_scaler.inverse_transform(np.round(selected_model.predict(X_test_3))),\n#    columns=['Prediction']\n# )\n# predicted_df[\"Id\"] = predicted_df.index\n# predicted_df = predicted_df[['Id', 'Prediction']]\n# predicted_df.to_csv(\"../input/linear_regression_model3_submission.csv\", index=False)","execution_count":8,"outputs":[]},{"metadata":{"scrolled":true,"_uuid":"dad7758bf81af2d46bf430f1d940fb91bd1f454b","_cell_guid":"9a0b452f-b589-46b3-9835-d05a30bc5874","trusted":true},"cell_type":"code","source":"# Implementing feature selection\nX_train_4 = X_train.iloc[:].copy()\nX_test_4 = X_test.iloc[:].copy()\ny_train_4 = y_train.iloc[:].copy()\n\n# Perform one hot encoding on training and test data\none_hot_encoder = OneHotEncoder(dtype=np.int8, sparse=False)\ncolumns_to_encode = ['City', 'City Group', 'Type']\n\nfor col in columns_to_encode:\n    data = X_train_4[[col]].append(X_test_4[[col]])\n    one_hot_encoder.fit(data)\n    temp = one_hot_encoder.transform(X_train_4[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_train_4.index.values)\n    X_train_4 = pd.concat([X_train_4, temp], axis = 1)\n    X_train_4.drop([col], axis = 1, inplace = True)\n    \n    temp = one_hot_encoder.transform(X_test_4[[col]])\n    temp = pd.DataFrame(temp, columns=[(col + \"_\" + str(i)) for i in data[col].value_counts().index.values])\n    temp = temp.set_index(X_test_4.index.values)\n    X_test_4 = pd.concat([X_test_4,temp],axis=1)\n    X_test_4.drop([col], axis = 1, inplace = True)\n\n# Perform MinMax scaling to scale each feature to a range between 0 and 1\nX_scaler = MinMaxScaler(feature_range=(0,1))\ny_scaler = MinMaxScaler(feature_range=(0,1))\n\ndesign_matrix_columns = X_train_4.columns\nresponse_vector_columns = y_train_4.columns\n\nX_train_4 = pd.DataFrame(X_scaler.fit_transform(X_train_4), columns=design_matrix_columns)\nX_test_4 = pd.DataFrame(X_scaler.fit_transform(X_test_4), columns=design_matrix_columns)\ny_train_4 = pd.DataFrame(y_scaler.fit_transform(y_train_4), columns=response_vector_columns)\n\n# Evaluate model performance\nfor model_name, model in models:\n    rfe = RFE(estimator=model, n_features_to_select=95, step=1)\n    rfe.fit(X_train_4, y_train_4)\n    selected_columns = [i for i,j in zip(X_train_4.columns.values, rfe.support_) if j == True]\n    X_train_4 = X_train_4.loc[:, selected_columns]\n    model.fit(X_train_4, y_train_4)\n    print(\"Model Name: {0}\\nModel Score: {1:.2f}%\".format(model_name, model.score(X_train_4, y_train_4) * 100))\n#     print(\"RMSE: \", np.mean(cross_val_score(model, X=X_train_4, y=y_train, cv = 3)))\n\n#Generate the submission file.\n# selected_model = models[0][1]\n# predicted_df = pd.DataFrame(\n#    y_scaler.inverse_transform(np.round(selected_model.predict(X_test_4))),\n#    columns=['Prediction']\n# )\n# predicted_df[\"Id\"] = predicted_df.index\n# predicted_df = predicted_df[['Id', 'Prediction']]\n# predicted_df.to_csv(\"../input/linear_regression_model3_submission.csv\", index=False)","execution_count":9,"outputs":[]},{"metadata":{"scrolled":false,"_uuid":"fd270710ae8b3079fefd23f7eee4a8a6c6703991","_cell_guid":"7408b334-9442-4cb0-b283-ee0c59fcebe6","trusted":true},"cell_type":"code","source":"X_train_5 = X_train.iloc[:].copy()\nX_test_5 = X_test.iloc[:].copy()\ny_train_5 = y_train.iloc[:].copy()\n\ntotal_data = pd.concat([X_train_5, X_test_5])\n\ntotal_records = len(total_data.index)\n\n# Geting of missing values. We will make a simple assumption here. Any feature for which the overall percentage of 0's is more than 20% will be assumed to have zero impact on response variable.\n# So we will simple drop those columns from te training set. In order to do so, we'll consider the test set as well.\ndef null_percentage(column):return(np.round((len(total_data[column][total_data[column] == 0])/total_records) * 100, 2))\n\nfor column in total_data.columns.values:\n    threshold = null_percentage(column)\n    if threshold >= 20:\n        print(\" Dropping column {0} as percentage of values that are zero: {1}. Much higher that threshold of 20%\".format(column, threshold))\n        X_train_5.drop(columns=[column], inplace=True)\n        X_test_5.drop(columns=[column], inplace=True)\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()\nmodel.fit(X_train_5, y_train_5)\n\nprint(\"Score on training set: {0:.2f}\".format(model.score(X_train_5, y_train_5) * 100))\n\n#Generate the submission file.\npredicted_df = pd.DataFrame(\n   np.round(model.predict(X_test_5)),\n   columns=['Prediction']\n)\npredicted_df[\"Id\"] = predicted_df.index\npredicted_df = predicted_df[['Id', 'Prediction']]\npredicted_df.to_csv(\"../input/linear_regression_model5_submission.csv\", index=False)","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4d657640002cba913b499549376774a28e8114ce","_cell_guid":"ba968e4f-9a72-4811-b9b2-5377fae85d48"},"cell_type":"markdown","source":"The solution with simple decision tree performed pretty badly with actual test set (as evaluated by kaggle). Seeing the discussions on this topic, I think it makes sense to identify the outliers in data. Also, it is important to investigate the role that the fields from P1 to P37 playing to influence the revenue."},{"metadata":{"_uuid":"d57d603096179b6608c2def0c0564a40c1716a8d","_cell_guid":"ca1f2454-e385-44e2-b3c5-9bacf86b3416","trusted":true,"collapsed":true},"cell_type":"code","source":"# train_data.sort_index(by = [\"revenue\"])\n\n","execution_count":11,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3dd044e9e392cafa9f9da75ba6e9f6587acc398f","_cell_guid":"5a2410ef-3618-439d-92e2-91864aaabca8","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}