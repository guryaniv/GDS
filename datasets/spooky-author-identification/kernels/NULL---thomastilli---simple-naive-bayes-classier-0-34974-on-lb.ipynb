{"nbformat": 4, "cells": [{"cell_type": "code", "source": ["# Importing the libraries\n", "import numpy as np\n", "import pandas as pd\n"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": 3}, {"cell_type": "code", "source": ["# Input data files\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "submiss=pd.read_csv(\"../input/sample_submission.csv\")"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": 4}, {"cell_type": "markdown", "source": ["# Preprocessing\n", "I not do only a little preprocessing. I think to differentiate between the authors everything is important. Stop word removal makes things worser - I have tested that."], "metadata": {}}, {"cell_type": "code", "source": ["X_Train=train['text'].str.replace('[^a-zA-Z0-9]', ' ')\n", "y_train=train['author']\n", "X_Test=test['text'].str.replace('[^a-zA-Z0-9]', ' ')"], "outputs": [], "metadata": {"collapsed": true}, "execution_count": 9}, {"cell_type": "code", "source": ["## Multinomial Naive Bayes Classifier ##\n", "# Build pipeline\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.pipeline import Pipeline\n", "classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n", "                      ('tfidf', TfidfTransformer()),\n", "                      ('clf', MultinomialNB()),\n", "])\n", "\n", "# parameter tuning with grid search\n", "from sklearn.model_selection import GridSearchCV\n", "parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n", "              'vect__max_df': ( 0.7,0.8,0.9,1.0),\n", "              'vect__min_df': (1,2),    \n", "              'clf__alpha': ( 0.022,0.025, 0.028),\n", "}\n", "gs_clf = GridSearchCV(classifier, parameters,n_jobs=-1, verbose=1,cv=5)\n", "gs_clf.fit(X_Train, y_train)\n", "best_parameters = gs_clf.best_estimator_.get_params()\n", "for param_name in sorted(parameters.keys()):\n", "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n", "\n", "# Predicting the Test set results\n", "y_pred_proba = gs_clf.predict_proba(X_Test)\n"], "outputs": [], "metadata": {}, "execution_count": 10}, {"cell_type": "code", "source": ["y_pred_proba"], "outputs": [], "metadata": {}, "execution_count": 11}, {"cell_type": "code", "source": ["submiss['EAP']=y_pred_proba[:,0]\n", "submiss['HPL']=y_pred_proba[:,1]\n", "submiss['MWS']=y_pred_proba[:,2]\n", "submiss.to_csv(\"submission_nb_word.csv\",index=False)\n", "submiss.head(10)"], "outputs": [], "metadata": {}, "execution_count": 13}, {"cell_type": "markdown", "source": ["# Further exloration to be done:\n", "- try other classifiers\n", "- evaluate new features "], "metadata": {}}], "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "version": "3.6.3"}}}