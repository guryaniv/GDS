{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Get requirements\nimport numpy as np\nimport pandas as pd\nimport keras\nimport tensorflow as tf\nprint(\"We're using TF\", tf.__version__)\nimport keras\nprint(\"We are using Keras\", keras.__version__)\nnp.random.seed(1234)\n# Ok, get some stuff from Keras (model, layer, optimizers and ImageDataGenerator)\nfrom keras import models\nfrom keras import layers\nfrom keras.utils import to_categorical  #keras.utils.to_categorical(y, num_classes=None)\nimport keras.backend as K\nfrom keras.models import load_model\nimport h5py\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nimport  matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.cm as cm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9f061b0fe660850c32bc17c42dc1cf3d1452533","scrolled":true,"trusted":true},"cell_type":"code","source":"# Load data \norg_train = pd.read_csv('../input/train.csv')\norg_test_images = pd.read_csv('../input/test.csv')\norg_train.head() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1508adf1daf155d6085337ac986a8cdfe8c44821","trusted":true},"cell_type":"code","source":"org_train_labels = org_train[\"label\"]\n# Drop 'label' column\norg_train_images = org_train.drop(labels = [\"label\"],axis = 1) \nprint (org_train_labels.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad17f98ce5b711683496548366d73ddf0bf709b5","trusted":true},"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 28px, width = 28px , channels = 1)\norg_train_images = org_train_images.values.reshape(-1,28,28,1)\norg_test_images = org_test_images.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3d6f83a7d77c6d915b11996cb3247edd339be15","trusted":true},"cell_type":"code","source":"# Normalize from 0-255 to 0-1\norg_train_images = org_train_images.astype('float32') /255.0\norg_test_images = org_test_images.astype('float32') /255.0 \nprint (org_train_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ee612f143ec16641f7da09fc67499f35281c7b1","trusted":true},"cell_type":"code","source":"# Ok, lets look at our new data.\nfig = plt.figure(figsize=(10,10))\nfor i in range(6):\n    ax = fig.add_subplot(1, 6, i+1, xticks=[], yticks=[])\n    ax.imshow(org_train_images[i].reshape(28,28), cmap='gray')\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d859d35db54225b36a6e99b0ecad6160624e24ca","trusted":true},"cell_type":"code","source":"# Split the train and the validation set for the fitting, use stratify.\ndef getdata(random_state):\n    train_images,dev_images,train_labels,dev_labels=train_test_split(org_train_images,org_train_labels,test_size=0.1,random_state=random_state,stratify=org_train_labels)\n    train_labels = keras.utils.to_categorical(train_labels,10)\n    #test_labels = keras.utils.to_categorical(test_labels,10)\n    dev_labels = keras.utils.to_categorical(dev_labels,10)\n    return (train_images,dev_images,train_labels,dev_labels)\ntrain_images,dev_images,train_labels,dev_labels = getdata(12)\nprint (dev_images.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7231e4935d57f371d9f13310eef8ca5fcdc2f54a","trusted":true},"cell_type":"code","source":"# Ok lets do some training with data augumentation in Keras\n# Since neural networks are hungry for data Keras have a built in function to generate syntetic data on the fly!\nbatch_size=60\n# Realtime data augmentation:\ndatagen = ImageDataGenerator(\n    rotation_range=12,  # randomly rotate images in the range (degrees, 0 to 180)\n    shear_range=1, # shear this amount of degrees\n    zoom_range = 0.12, # Randomly zoom image \n    width_shift_range= 3/28,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range=3/28  # randomly shift images vertically (fraction of total height)\n    )\ndatagen.fit(train_images)\ntrain_images_batch, train_label_batch = datagen.flow(train_images, train_labels, batch_size=batch_size).next()\n\n# Ok, lets see how the images in the batch changed (shifted up/down, left/right and rotated/zoomed a bit in our case)\nplt.figure(figsize=(20,20))\nfor i in range(0, int(batch_size/2)):\n    plt.subplot(10,10,1+i, xticks=[], yticks=[])\n    plt.imshow(train_images_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n# show the plot\nprint ('Images showing the augumented images')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7348df58c5980294dc0f077bfffd6435714b3eb0","trusted":true},"cell_type":"code","source":"#Setup the callbacks list\ndef callback():  \n    callbacks_list = [keras.callbacks.EarlyStopping(\n                                  monitor='val_loss',\n                                  patience=25  # stops when this number of epochs does not improve\n                                  ),\n                  keras.callbacks.ModelCheckpoint(\n                                  filepath='my_model.h5',\n                                  verbose=1,\n                                  monitor='val_loss',\n                                  save_best_only=True  # save the model that is best\n                                  ),\n                 # keras.callbacks.LearningRateScheduler(lambda x: 1e-2 * 0.99 ** x),\n                 \n                  keras.callbacks.ReduceLROnPlateau(\n                                  monitor='val_loss',\n                                  factor=0.5,  # reduce learningrate with this factor ex: lr=0.01 --> lr=0.01*0.1=0.001\n                                  patience=3,  # nr of epochs without improvement in monitored loss ('val_loss') to trigger the decrease in lr\n                                  verbose=1,\n                                  min_lr=0.0001)\n                   \n                 \n                 \n    ]\n    return (callbacks_list)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5aab22ed90882da1f2518b10e6f8a848307e87ef","trusted":true},"cell_type":"code","source":"# Lets create the first network using SeparableConv2D  + LeakyRelu and SpatialDropOuts and GlobalAveragePooling\n# This is a test of SpatialDropout and Pooling \nfrom keras.layers.advanced_activations import LeakyReLU\n\nK.clear_session()\ncnn1=models.Sequential()\n# 28x28 \ncnn1.add(layers.SeparableConv2D(32,(3,3),padding='same',input_shape=(28,28,1))) \ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.2))\ncnn1.add(layers.SeparableConv2D(32,(3,3),padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.2))\ncnn1.add(layers.SeparableConv2D(32,(3,3),padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.2))\ncnn1.add(layers.MaxPooling2D((2,2),strides=(2,2)))\ncnn1.add(layers.SpatialDropout2D(0.3))\n\n# 14x14\ncnn1.add(layers.SeparableConv2D(64,(3,3),padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.1))\ncnn1.add(layers.SeparableConv2D(64,(3,3),padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.1))\ncnn1.add(layers.SeparableConv2D(64,(3,3),padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.1))\ncnn1.add(layers.MaxPooling2D((2,2)))\ncnn1.add(layers.SpatialDropout2D(0.3))\n\n# 7x7\ncnn1.add(layers.SeparableConv2D(128,(3,3),strides=1,padding=\"same\"))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(LeakyReLU(alpha=0.1))\ncnn1.add(layers.MaxPooling2D((2,2)))\ncnn1.add(layers.SpatialDropout2D(0.3))\n\n# 3x3\ncnn1.add(layers.SeparableConv2D(192,(3,3),padding=\"same\"))\n#cnn1.add(layers.BatchNormalization())\ncnn1.add(layers.GlobalAveragePooling2D())  # - No RELU before this layer\ncnn1.add(layers.Dense(256)) \ncnn1.add(LeakyReLU(alpha=0.1))\ncnn1.add(layers.BatchNormalization())\ncnn1.add(layers.Dropout(0.3))\ncnn1.add(layers.Dense(10,activation='softmax'))\nopt=optimizers.Nadam(lr=0.02, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n#opt=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999,  decay=0.0, amsgrad=False)  # optimizer=optimizers.RMSprop(lr=1e-4)\ncnn1.compile(optimizer=opt,    \n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\ncnn1.count_params()\ncnn1.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2485a78839ab03da4080188ed35b880133e55c57","trusted":true},"cell_type":"code","source":"# Fit the model on the batches generated by datagen.flow().\n# datagen.flow will generate unique images for every batch!\n# this will make the network train on \"new\" images!\nbs=60 # batch size\ncallbacks_list=callback() # Reset the callbacklist","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57065a8ac0c7cef126fa25d96559f65ffe1e816b","trusted":true},"cell_type":"code","source":"#Ok, lets train our first network!\ncnn1.fit_generator(datagen.flow(train_images, train_labels,batch_size=bs),\n                        steps_per_epoch=train_images.shape[0] // (bs),\n                        epochs=50,\n                        callbacks=callbacks_list,\n                        validation_data=(dev_images,dev_labels),\n                        validation_steps = dev_images.shape[0]// (bs),\n    \n                        #workers=8\n                        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3d9c7007a16dc61c1fef334cd1dd10c4e24d3a5","trusted":true},"cell_type":"code","source":"# Load best cnn1 model and checkit\ncnn1.load_weights('my_model.h5') # Load the best model and check it\ndev_loss, dev_acc = cnn1.evaluate(dev_images, dev_labels)\nprint('dev_acc:', dev_acc)\ncnn1.save_weights('cnn1_weights.h5')\ncnn1.save('cnn1_model.h5')\nos.remove ('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0ab70048b35089c24cf4519d3d50d77c8fc5431","trusted":true},"cell_type":"code","source":"#Print a classification Report\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nnp.set_printoptions(precision=3)\npred=cnn1.predict_classes(dev_images)\ntarget_names = [\"{}\".format(i) for i in range(10)]\nprint ('* Classification Report *')\nprint(classification_report(np.argmax(dev_labels,axis=1), pred, target_names=target_names,digits=3))\n#print (confusion_matrix(np.argmax(dev_labels,axis=1), pred,labels=[9,8,7,6,5,4,3,2,1,0]))\n\ncnf_matrix = confusion_matrix(np.argmax(dev_labels,axis=1), pred)\n\nimport seaborn as sns\nsns.heatmap(cnf_matrix, annot=True, fmt=\"d\")\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7903efba78e9252c23bfef71530c382b4693a582","scrolled":true,"trusted":true},"cell_type":"code","source":"# Plot some curves!  \n\ndef plot_curves(hist):\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(10,5))\n    history_dict=hist.history\n    loss_values=history_dict['loss']\n    val_loss_values=history_dict['val_loss']\n    epochs=range(1,len(loss_values)+1)\n    plt.plot(epochs,loss_values,'r',label='Training Loss') # r=red line, ro=red dot\n    plt.plot(epochs,val_loss_values,'b',label='Validation Loss') # b=blue line\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    plt.clf()\n    acc_values=history_dict['acc']\n    val_acc_values=history_dict['val_acc']\n    plt.figure(figsize=(10,5))\n    plt.plot(epochs,acc_values,'r',label='Training accuracy') \n    plt.plot(epochs,val_acc_values,'b',label='Validation accuracy') \n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.show()\n\n    plt.clf()\n    lr_values=history_dict['lr']\n    plt.figure(figsize=(10,5))\n    plt.plot(epochs,lr_values,'r',label='Learning Rate')\n    plt.title('Learning Rate')\n    plt.xlabel('Epochs')\n    plt.ylabel('Learning Rate')\n    plt.legend()\n    plt.show()\n    return\nplot_curves(cnn1.history)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"47b187b62756e912e1f09855d1a5b11dadac14e3","trusted":true},"cell_type":"code","source":"# Lets create the second network using SeparableConv2D with RELU and SpatialDropOuts and Flatten instead of GlobalAveragePooling\n\ntrain_images,dev_images,train_labels,dev_labels = getdata(14)\ncnn2=models.Sequential()\n# 28x28\ncnn2.add(layers.SeparableConv2D(32,(3,3),activation='relu',padding='same',input_shape=(28,28,1))) \ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.SeparableConv2D(32,(3,3),activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.SeparableConv2D(32,(3,3),strides=1, activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.MaxPooling2D((2,2)))\ncnn2.add(layers.SpatialDropout2D(0.3))\n# 14x14\ncnn2.add(layers.SeparableConv2D(64,(3,3),activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.SeparableConv2D(64,(3,3),activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.SeparableConv2D(128,(3,3),strides=1, activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.MaxPooling2D((2,2)))\ncnn2.add(layers.SpatialDropout2D(0.4))\n# 7x7\ncnn2.add(layers.SeparableConv2D(128,(3,3),activation='relu',padding=\"same\"))\ncnn2.add(layers.BatchNormalization())\ncnn2.add(layers.MaxPooling2D((2,2)))\ncnn2.add(layers.SpatialDropout2D(0.4))\n\ncnn2.add(layers.SeparableConv2D(512,(3,3),activation='relu'))\ncnn2.add(layers.BatchNormalization())\n\ncnn2.add(layers.Flatten())  # Konvertera 3D --> 1D\n#cnn2.add(layers.GlobalAveragePooling2D())  # - Istället för flatten https://github.com/keras-team/keras/issues/8470\n#cnn2.add(layers.Dropout(0.5))\ncnn2.add(layers.Dense(128,activation='relu')) \ncnn2.add(layers.Dense(10,activation='softmax'))\nopt=optimizers.Adam(lr=1e-2, beta_1=0.9, beta_2=0.999, decay=0.0)  # optimizer=optimizers.RMSprop(lr=1e-4)\ncnn2.compile(optimizer=opt,    \n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\ncnn2.summary()\ncnn2.count_params() # 3,5x in Size - should be better one could hope for!","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"577971019a39c19f70b591e3e0caad3e3b11b724","trusted":true},"cell_type":"code","source":"#  Lets train network CNN2 exactly the same way as CNN1\ncallbacks_list=callback() # Reset the callbacklist\ncnn2.fit_generator(datagen.flow(train_images, train_labels,batch_size=bs),\n                        steps_per_epoch=train_images.shape[0] // (bs),\n                        epochs=100,\n                        callbacks=callbacks_list,\n                        validation_data=(dev_images,dev_labels),\n                        validation_steps = dev_images.shape[0] // (bs),\n    \n                        #workers=8\n                        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"274e9de3ed0f879469d0988fa3ce1e3f077d3ca5","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9f14e748d121f1ba349f946567ea97a2103e9ef","trusted":true},"cell_type":"code","source":"# Load best cnn2 model and checkit\ncnn2.load_weights('my_model.h5') # Load the best model and check it\ndev_loss, dev_acc = cnn2.evaluate(dev_images, dev_labels)\nprint('dev_acc:', dev_acc)\ncnn2.save_weights('cnn2_weights.h5')\ncnn2.save('cnn2_model.h5')\nos.remove ('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"961451646c9ef8d1e350929140188c06b73586df"},"cell_type":"code","source":"plot_curves(cnn2.history)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"834b7f5828337eba4cb4ee7f46625e32e344d1ff","trusted":true},"cell_type":"code","source":"# Ok, lets go for a third one with a different optimizer\n# \ntrain_images,dev_images,train_labels,dev_labels = getdata(1564)\ncnn3=models.Sequential()\ncnn3.add(layers.SeparableConv2D(32,(3,3),activation='relu',padding='same',input_shape=(28,28,1))) # testa padding=\"same\"/\"valid\". Kolla noga på tabellen\ncnn3.add(layers.BatchNormalization())\n#cnn3.add(layers.MaxPooling2D((2,2)))\ncnn3.add(layers.SeparableConv2D(32,(3,3),activation='relu',padding=\"valid\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.SeparableConv2D(64,(3,3),strides=1, activation='relu',padding=\"same\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.MaxPooling2D((2,2)))\ncnn3.add(layers.SpatialDropout2D(0.4))\ncnn3.add(layers.SeparableConv2D(128,(3,3),activation='relu',padding=\"valid\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.SeparableConv2D(96,(3,3),activation='relu',padding=\"same\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.SeparableConv2D(64,(3,3),strides=1, activation='relu',padding=\"same\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.MaxPooling2D((2,2)))\ncnn3.add(layers.SpatialDropout2D(0.4))\ncnn3.add(layers.SeparableConv2D(256,(3,3),activation='relu',padding=\"valid\"))\ncnn3.add(layers.BatchNormalization())\ncnn3.add(layers.MaxPooling2D((2,2)))\ncnn3.add(layers.SpatialDropout2D(0.4))\n\ncnn3.add(layers.GlobalAveragePooling2D()) \n#cnn3.add(layers.Dropout(0.5))\ncnn3.add(layers.Dense(128,activation='relu')) \ncnn3.add(layers.Dense(10,activation='softmax'))\n#opt=optimizers.Adam(lr=1e-2, beta_1=0.9, beta_2=0.999, decay=0.001)  \nopt=optimizer=optimizers.RMSprop(lr=1e-3)\ncnn3.compile(optimizer=opt,    \n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\ncnn3.summary()\ncnn3.count_params()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebb09351287ab81dd20ecef6ee615b297fd241c0","trusted":true},"cell_type":"code","source":"#  Lets train network CNN3 exactly the same way as the others\ncallbacks_list=callback()# Reset the callbacklist\ncnn3.fit_generator(datagen.flow(train_images, train_labels,batch_size=bs),\n                        steps_per_epoch=train_images.shape[0] // (bs),\n                        epochs=50,\n                        callbacks=callbacks_list,\n                        validation_data=(dev_images,dev_labels),\n                        validation_steps = dev_images.shape[0] // (bs),\n    \n                        #workers=8\n                        )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3abed8569b0e9f7e490def21e2e2d93741fb076","trusted":true},"cell_type":"code","source":"# Load best cnn2 model and checkit\ncnn3.load_weights('my_model.h5') # Load the best model and check it\ndev_loss, dev_acc = cnn2.evaluate(dev_images, dev_labels)\nprint('dev_acc:', dev_acc)\ncnn3.save_weights('cnn3_weights.h5')\ncnn3.save('cnn3_model.h5')\nos.remove ('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1964443ed5af877bf6686af4272cb5f23b2c94fc","trusted":true},"cell_type":"code","source":"# First load the 3 best results from all models, see cnn3 code for how to use Keras to automatically save the best one\ncnn1.load_weights('cnn1_weights.h5')\ncnn2.load_weights('cnn2_weights.h5')\ncnn3.load_weights('cnn3_weights.h5')\n\nmodels=[cnn1,cnn2,cnn3]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf9bc9ac5bcf1cf00016ad071b20b1e2d5bebb5f","trusted":true},"cell_type":"code","source":"def ensemble(models, model_input):\n    # collect all the outputs from the networks\n    outputs = [model(model_input) for model in models] \n    # averaging outputs\n    outputsAvg = layers.Average()(outputs)    \n    modelEns = keras.models.Model(inputs=model_input,outputs=outputsAvg, name='ensemble')    \n    return modelEns\n  \ndef evaluate_error(model):\n    pred = model.predict(test_images, batch_size = 60)\n    pred = np.argmax(pred, axis=1)\n    pred = np.expand_dims(pred, axis=1) # make same sha\n    error = np.sum(np.not_equal(pred, test_labels)) / test_labels.shape[0]    \n    return error\n\n#All networks in the ensemble must have the same input shape (our case 28,28,1)\nmodel_input = keras.models.Input(shape=models[0].input_shape[1:])  \nmodelEns = ensemble(models, model_input)\n\n# We need to compile it - just to ignore a error when loading it :) \nmodelEns.compile(optimizer='Adam',\n                loss='categorical_crossentropy',\n                metrics=['accuracy'])\nmodelEns.summary()\nmodelEns.save(\"MyEnsemble.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a020cce3a79581bb2d47c0ac35a90a83bb808f6","trusted":true},"cell_type":"code","source":"# Ok, lets test this small ensemble model with our test data\nfrom keras.models import load_model\nmodelEns=keras.models.load_model(\"MyEnsemble.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01b0ac337a2fd69403728054fc535f5e1d383801","trusted":true},"cell_type":"code","source":"test_loss, test_acc = modelEns.evaluate(dev_images, dev_labels)\nprint('Ensemble test_acc:', test_acc)  # Compare this result to all the individual ones. \n# averageing is one type of ensemble ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5c34780235b04ca2328df582630d670949fba52","trusted":true},"cell_type":"code","source":"# predict results\nresults = modelEns.predict(org_test_images)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f16e40d95a254b2a4325c0cd4c5cf76db1930247","trusted":true},"cell_type":"code","source":"results = np.argmax(results,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"087523fb3b60e000b6fecd7a10f44c184309be16","trusted":true},"cell_type":"code","source":"results = pd.Series(results,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a67713c1a8babd2a9649519620fb0f052ce7fc0d","trusted":true},"cell_type":"code","source":"print (results.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ead3b495ccf5e353dc65aa65db8ddf0da76849f7","trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"test_labels.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7582cfb127c10076d0cd321134b15d8637f629b8","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}