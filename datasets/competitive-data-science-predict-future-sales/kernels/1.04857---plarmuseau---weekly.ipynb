{"cells":[{"metadata":{"_uuid":"8ccbc488817978f9e361bce3a02c205a7989daa2"},"cell_type":"markdown","source":"*weekly(version 11/11) 1.23901  >> price volume instead of counting\n* weekly(version 9/9) 1.08116\n* weekly(version 7/9) 1.08567\n* weekly(version 6/9) 1.27601\n* weekly(version 4/9) 1.24642\n* weekly(version 3/9) 1.08348\n* weekly(version 2/9) 1.06151\n* weekly(version 1/9) 1.04857\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n\nitems_df = pd.read_csv('../input/items.csv')\nshops_df = pd.read_csv('../input/shops.csv')\nicats_df = pd.read_csv('../input/item_categories.csv')\ntrain_df = pd.read_csv('../input/sales_train.csv')\nsmpsb_df = pd.read_csv('../input/sample_submission.csv')\ntest_df  = pd.read_csv('../input/test.csv')\n\n# Any results you write to the current directory are saved as output.\ntrain_df['date'] = pd.to_datetime(train_df.date,format=\"%d.%m.%Y\")\ntrain_df['week'] = ( train_df.date.values.astype('datetime64[W]'))\ntrain_df['volum'] = train_df['item_cnt_day']*train_df['item_price']\ntrain_df.head()","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"7c21431ea4f3d0abf99904b7fc672e7160c3493f"},"cell_type":"markdown","source":"# week sum of sales per shop and per item\nits not used here actually"},{"metadata":{"trusted":true,"_uuid":"38f60253a6579374b16bcf3615ad73ddb4e8e58f"},"cell_type":"code","source":"## Pivot by monht to wide format\np_df = train_df.pivot_table(index=['shop_id','item_id'], columns='week', values='item_cnt_day',aggfunc='sum').fillna(0.0)\npv_df = train_df.pivot_table(index=['shop_id','item_id'], columns='week', values='volum',aggfunc='sum').fillna(0.0)\np_df.head()","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"b6f3f2c6139d94b9cf3737b23148479c9b8e0d1a"},"cell_type":"markdown","source":"# deseasonalize sale per item per month\nappend sales per item_month to p_df"},{"metadata":{"trusted":true,"_uuid":"e7cbfd83151eed32b10b27b4ced917ce05b30366"},"cell_type":"code","source":"#diff = p_df.T.diff().dropna()\n#exp_12=p_df.T.ewm(span=12,adjust=False).mean()\n\n##   i_df = train_df.pivot_table(index=['item_id'], columns='date_block_num', values='item_cnt_day',aggfunc='sum').fillna(0.0)\n#i_df = train_df.pivot_table(index=['item_id'], columns='date_block_num', values='volum',aggfunc='sum').fillna(0.0)\ni_df = train_df.pivot_table(index=['item_id'], columns='week', values='item_cnt_day',aggfunc='sum').fillna(0.0)\n\nis_df=(i_df.T/i_df.T.max()).T\nis_df['imax']=i_df.T.max()\npis_df=pd.DataFrame()\npis_df['isom']=pv_df.sum(axis=1)\npis_df=pis_df.reset_index()\npis_df=pis_df.merge(is_df,how='left',left_on=[ \"item_id\"],right_on=[\"item_id\"])\n\npis_df.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"289b37e3ab72c7c83bc14941a2835f3352ac54c5"},"cell_type":"markdown","source":"# deseasonalize sales per shop per month\nappend sales per shop_month to p_df\n\nwhat we could do further is add a salesforecast for period 34 with ARIMA"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2f3109a6bd330d9533a6ce92d0f75e21eb21a55a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8abf907d3c1b4bde804903c920af70486278711"},"cell_type":"code","source":"s_df = train_df.pivot_table(index=['shop_id'], columns='week', values='item_cnt_day',aggfunc='sum').fillna(0.0)\n##       s_df = train_df.pivot_table(index=['shop_id'], columns='date_block_num', values='item_cnt_day',aggfunc='sum').fillna(0.0)\n#sv_df = train_df.pivot_table(index=['shop_id'], columns='date_block_num', values='volum',aggfunc='sum').fillna(0.0)\nss_df=(s_df.T/s_df.T.max()).T\n#ssv_df=(sv_df.T/sv_df.T.max()).T\nss_df['smax']=s_df.T.max()\n#ss_df['svmax']=sv_df.T.max()\n\npss_df=pd.DataFrame()\npss_df['ssom']=pv_df.sum(axis=1)\npss_df=pss_df.reset_index()\npss_df=pss_df.merge(ss_df,how='left',left_on=[ \"shop_id\"],right_on=[\"shop_id\"])\n#pss_df=pss_df.merge(ssv_df,how='left',left_on=[ \"shop_id\"],right_on=[\"shop_id\"])\npss_df.head()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a6b68016f932a71608d771b2b4c7ddd68c9ee3ae"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa842c18dfa72fd7870e1f50145ec166651167d2"},"cell_type":"markdown","source":"# cleanup\nmake abit orderly"},{"metadata":{"trusted":true,"_uuid":"686c75ef74be4ce66767a9df945e6fddc9cb685d"},"cell_type":"code","source":"train_cleaned_df=pis_df.merge(pss_df,how='inner',on=['shop_id','item_id'])\ntrain_cleaned_df.head()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94e3810493300137c36c3e59c8ea02dacac7d123"},"cell_type":"code","source":"kolom=train_cleaned_df.columns\nkolom=[  x  for x in kolom if x not in ['shop_id', 'item_id', 'isom','ssom','imax','smax','svmax'] ]\ntrain_cleaned_df=train_cleaned_df[['shop_id', 'item_id', 'isom','ssom','imax','smax'] + list(kolom)]\n#train_cleaned_df=train_cleaned_df[['shop_id', 'item_id', 'isom','ssom','imax','smax','svmax'] + list(kolom)]\ntrain_cleaned_df['shop_id']= train_cleaned_df.shop_id.astype('str')\ntrain_cleaned_df['item_id']= train_cleaned_df.item_id.astype('str')\ntrain_cleaned_df.shape","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"70863f5d8d601decf5bab3a561bf547da0022be4"},"cell_type":"markdown","source":"# training \nchecking forecast in scatter plot, looks excellent"},{"metadata":{"trusted":true,"_uuid":"9204fa466cb57fd63ee9a3647b19e983595b85c4"},"cell_type":"code","source":"import xgboost as xgb\nparam = {'max_depth':10, \n         'subsample':1,\n         'min_child_weight':0.5,\n         'eta':0.3, \n         'num_round':1000, \n         'seed':1,\n         'silent':0,\n         'eval_metric':'rmse'}\n\nprogress = dict()\nxgbtrain = xgb.DMatrix(train_cleaned_df.iloc[:, :].values, p_df.iloc[:, -5:].sum(axis=1).values)\nwatchlist  = [(xgbtrain,'train-rmse')]\n\nbst = xgb.train(param, xgbtrain)\npreds = bst.predict(xgb.DMatrix(train_cleaned_df.iloc[:,:].values))\nfrom sklearn.metrics import mean_squared_error \nrmse = np.sqrt(mean_squared_error(preds,p_df.iloc[:, -5:].sum(axis=1).values))\nprint(rmse)\n\nplt.scatter(preds, p_df.iloc[:, -5:].sum(axis=1).values, marker='.',s=1)\n","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"aed3798ba7939143b62722367faef5fe2493c4d8"},"cell_type":"markdown","source":"# try implement the knowledge to the testdata\nso the funny thing is we dont' forecast yet, we simply forecast october on the test data"},{"metadata":{"trusted":true,"_uuid":"d90faf6e3539ae592ef61c870d3e57ae67eca497"},"cell_type":"code","source":"apply_df = test_df\napply_df['shop_id']= apply_df.shop_id.astype('str')\napply_df['item_id']= apply_df.item_id.astype('str')\napply_df = test_df.merge(train_cleaned_df, how = \"left\", on = [\"shop_id\", \"item_id\"]).fillna(0.0)\napply_df.drop('ID',axis=1).head(),apply_df.drop('ID',axis=1).shape","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1500ee91578b7defadaaee834cc55c79cce855f9","collapsed":true},"cell_type":"code","source":"# Move to one month front\n#d = dict(zip(apply_df.columns[4:],list([-1,-1,])+list(np.array(list(apply_df.columns[6:])) )))\n\n#apply_df  = apply_df.rename(d, axis = 1)\n#preds = bst.predict(xgb.DMatrix(apply_df.iloc[:, (apply_df.columns != 'ID') & (apply_df.columns != -1)].values))\n\npreds = bst.predict(xgb.DMatrix(apply_df.drop('ID',axis=1).values))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8be15b6be507e19fdd32bc64feb0240a0e18cd52"},"cell_type":"code","source":"preds","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"preds=preds\n\n# Normalize prediction to [0-20]\npreds = list(map(lambda x: min(20,max(x,0)), list(preds)))\nsub_df = pd.DataFrame({'ID':apply_df.ID,'item_cnt_month': preds })\npd.DataFrame.hist(sub_df[sub_df['item_cnt_month']>1.7])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"abeddee3-9480-4346-9b64-2cb54f5286fb","_uuid":"fe1318f4b268c07fcf5d8076185b9eda2879873c","trusted":true},"cell_type":"code","source":"sub_df.to_csv('xg_boost4_cats.csv',index=False)","execution_count":35,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}