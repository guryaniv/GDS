{"cells": [{"metadata": {"_cell_guid": "80da469f-020f-425f-9f70-a66b16ba1aac", "_uuid": "45e8cd5f8a059cb838400f20d1513a0a3a0b3d8a"}, "source": ["### 0. Hello!\n", "\n", "My first visit to Kaggle was about a year ago, and set a goal to upload a posting like other competitive smart people on the board. This is my first posting. Finally achieved sth in 2017! Any comments will be appreciated! Thanks :)\n", "\n", "\n", "## 1. Introduction\n", "- Preprocessed data: Drop columns, Scaling numbers, Over-sampling\n", "- Logistic Regression, Decision Tree, Random Forest\n", "- Threshold change"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["import numpy as np\n", "import pandas as pd\n", "import pandas as pd\n", "import matplotlib as mpl\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import train_test_split\n", "%matplotlib inline"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def loadData(File):\n", "    data = pd.read_csv(File)\n", "    print(\"Top two records are: \\n\", data.head(2))\n", "    #print(\"Description: \\n\", data.describe())\n", "    return data\n", "data = loadData(\"../input/creditcard.csv\")"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def showColDist(colname, data):\n", "    data = pd.DataFrame(data)\n", "    return sns.countplot(x = colname, data = data )\n", "showColDist(\"Class\", data) # Showing high imbalance"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def dropCol(colname, axis):\n", "    return data.drop(colname, axis = axis)\n", "data = dropCol('Time', 1) # Firstly dropped Time, becasue"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def showDistplot(data):\n", "    return sns.distplot(data)\n", "showDistplot(data['Amount']) "], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def checkEachCol(data):\n", "    List_col = list(data.columns.values)\n", "    for i in List_col:\n", "        print(\"====>\",i,\"<====\")\n", "        print(data[i].describe())\n", "checkEachCol(data)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def letsNorm(col):\n", "    #from sklearn.preprocessing import StandardScaler\n", "    inp = col.values.reshape(-1,1)\n", "    scaler = StandardScaler()\n", "    scaledData = scaler.fit_transform(inp)\n", "    print(\"Newly normalized data : \\n\", scaler.fit_transform(inp),\"This will be added, too.\")\n", "    data['Normalied'] = scaledData\n", "    return data\n", "data = letsNorm(data[\"Amount\"])"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["data.head(2)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["data = dropCol('Amount', 1) \n", "data.head(2)"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["## 2-1. Loading and spliting data"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["def Xy_split(data):\n", "    y = data['Class']\n", "    List_col = list(data.columns.values)\n", "    print(List_col)\n", "    X_col = [x for x in List_col if x != \"Class\"]\n", "    print(X_col)\n", "    #print(X_col)\n", "    X = data.loc[:,X_col]\n", "    return X,y\n", "X, y = Xy_split(data)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["X.head(3)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y.head(3)"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"metadata": {}, "source": ["> ## 2-2. Over-sampling"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from imblearn.over_sampling import RandomOverSampler\n", "from collections import Counter"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["def randomOverSampling(X, y):\n", "    #from imblearn.over_sampling import RandomOverSampler\n", "    #from collections import Counter\n", "    ros = RandomOverSampler()\n", "    X_resampled, y_resampled = ros.fit_sample(X,y)\n", "    #print(sorted(Counter(y_resampled).items()))\n", "    return X_resampled, y_resampled"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["X_big = X.copy()\n", "y_big = y.copy()"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["X_res , y_res = randomOverSampling(X_big, y_big)\n", "print(\" The # of original data is \", len(X_big),\".\\n\",\"The # of the over-sampled one is \", len(X_res),\".\")"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["sns.countplot(y_res)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.25, random_state = 23)"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y_result = pd.DataFrame(y_test)\n", "y_result.rename(columns={0: 'y_test'}, inplace=True)\n", "y_result.head()"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["### 3-1. Linear Regression\n", "---\n", "\n", "####  `sklearn.linear_model.LinearRegression`\n", "---****"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.linear_model import LogisticRegression\n", "LogisticReg = LogisticRegression()\n", "LogisticReg.fit(X= X_train, y = y_train)\n", "LogisticReg.predict(X = X_test) \n", "y_pred_lr = LogisticReg.predict(X = X_test)\n", "print(y_pred_lr)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y_result[\"Logistic_reg\"] = y_pred_lr"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["LogisticReg.score(X=X_test,y=y_test)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y_result.head()"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 3-2. Evaluation : Confusion Matrix \n", "---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.metrics import confusion_matrix\n", "confusion_matrix(y_pred = LogisticReg.predict(X_test), y_true = y_test)\n", "# [[ true negative , false positive],\n", "# [false negative], [true positive]]\n", "#print(LogisticReg.score(X=X_test,y=y_test))"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["### 3-1. Decision Tree\n", "---\n", "\n", "#### `sklearn.tree.DecisionTreeClassifier`\n", "---**"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.tree import DecisionTreeClassifier\n", "class_weight = 'balanced'\n", "max_depth = 5\n", "# dt_model \n", "dt_model = DecisionTreeClassifier(class_weight = class_weight, max_depth = max_depth, criterion = 'entropy')"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["dt_model.fit(X_train,y_train)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["dt_model.predict(X_test)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["dt_model.score(X = X_test, y = y_test)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y_result['DecisionTree'] = dt_model.predict(X_test)"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["y_result.head(10)"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 3-2. Evaluation : Confusion Matrix \n", "* ---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["confusion_matrix(y_pred = dt_model.predict(X_test), y_true = y_test)"], "metadata": {"_kg_hide-input": true}, "cell_type": "code"}, {"metadata": {}, "source": ["### 4-1. Random Forest\n", "---\n", "\n", "#### `sklearn.ensemble.RandomForestClassifier`\n", "---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "n_estimators = [3,15,75]\n", "class_weight = 'balanced'\n", "max_depth = 5"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["# rf_model\n", "for i in n_estimators:\n", "    rf_model = RandomForestClassifier(n_estimators = i, class_weight = class_weight, max_depth = max_depth)\n", "    rf_model.fit(X_train, y_train)\n", "    rf_model.predict(X_test)\n", "    print(\"rf_model score with # est. {}:\".format(i), rf_model.score(X_test, y_test))\n", "    y_result['rf-{}'.format(i)] = rf_model.predict(X_test)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["rf_model = RandomForestClassifier(n_estimators = 15, class_weight = class_weight, max_depth = max_depth)"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["rf_model.fit(X_train, y_train)"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["rf_model.predict(X_test)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["rf_model.score(X = X_test, y = y_test)"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 4-2. Evaluation : Confusion Matrix \n", "* ---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["confusion_matrix(y_pred = rf_model.predict(X_test), y_true = y_test)"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 5-1. Reports: Over-sampled, balanced test data\n", "---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.metrics import classification_report\n", "\n", "print(\"Logistic Regression\\n\",classification_report(y_test, y_pred =LogisticReg.predict(X = X_test)))\n", "print(\"Decision Tree\\n\",classification_report(y_test, y_pred =dt_model.predict(X_test)))\n", "print(\"Random Forest 15 estimators\\n\",classification_report(y_test, y_pred =rf_model.predict(X_test)))"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 5-2. Reports: Original, imbalanced test data\n", "---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["X_original = X.copy()\n", "y_original = y.copy()\n", "X_tr, X_te, y_tr, y_te = train_test_split(X_original, y_original, test_size = 0.25, random_state = 23)"], "metadata": {"collapsed": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["sns.countplot(y_te)"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["print(\"Logistic Regression\\n\",classification_report(y_te, y_pred =LogisticReg.predict(X = X_te)))\n", "print(\"Decision Tree\\n\",classification_report(y_te, y_pred =dt_model.predict(X_te)))\n", "print(\"Random Forest 15 estimators\\n\",classification_report(y_te, y_pred =rf_model.predict(X_te)))"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["print(\"=====Score of each model=========\")\n", "print(\"Logistic Regression: \",LogisticReg.score(X = X_te, y = y_te))\n", "print(\"Decision Tree: \",dt_model.score(X = X_te, y = y_te))\n", "print(\"Random Forest:\",rf_model.score(X = X_te, y = y_te))"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 6. Changing thresholds\n", "---"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": ["from sklearn.metrics import accuracy_score\n", "thresholds = np.arange(0, 1, 0.1)\n", "accuracies_dt = []\n", "y_pred_prob = dt_model.predict_proba(X = X_te)\n", "for i in thresholds:\n", "    y_pred = y_pred_prob[:,1]>i\n", "    accuracies_dt.append(accuracy_score(y_pred = y_pred , y_true = y_te))\n", "accuracies_dt"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["plt.figure() \n", "plt.scatter(thresholds, accuracies_dt )\n", "plt.xlabel(\"Thresholds\", fontsize = 13, color = 'black')\n", "plt.ylabel(\"Accuracy score\", fontsize = 13, color = 'black')\n", "plt.ylim([0,1])\n", "plt.suptitle(\"Thresholds change, Decision Tree\", fontsize = 20, color = \"black\")\n"], "metadata": {"scrolled": true}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["thresholds = np.arange(0, 1, 0.1)\n", "accuracies_rf = []\n", "y_pred_prob = rf_model.predict_proba(X = X_te)\n", "for i in thresholds:\n", "    y_pred = y_pred_prob[:,1]>i\n", "    accuracies_rf.append(accuracy_score(y_pred = y_pred , y_true = y_te))\n", "accuracies_rf"], "metadata": {}, "cell_type": "code"}, {"outputs": [], "execution_count": null, "source": ["plt.figure() \n", "plt.scatter(thresholds, accuracies_rf )\n", "plt.xlabel(\"Thresholds\", fontsize = 13, color = 'black')\n", "plt.ylabel(\"Accuracy score\", fontsize = 13, color = 'black')\n", "plt.ylim([0,1])\n", "plt.suptitle(\"Thresholds change, Random Forest\", fontsize = 20, color = \"black\")"], "metadata": {}, "cell_type": "code"}, {"metadata": {}, "source": ["#### 7. Conclusion\n", "---"], "cell_type": "markdown"}, {"metadata": {}, "source": ["### Hm.... came out unexpected high scores, did I miss something...???"], "cell_type": "markdown"}, {"outputs": [], "execution_count": null, "source": [], "metadata": {"collapsed": true}, "cell_type": "code"}], "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 1, "nbformat": 4}