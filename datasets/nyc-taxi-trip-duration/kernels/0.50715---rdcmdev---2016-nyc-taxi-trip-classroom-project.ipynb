{"cells":[{"metadata":{"_uuid":"a056b3e6e57d5fef6d30228be33492c8dc4df35b","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Classroom Project\n\nTo build this notebook first was created individuals ones for each model, then used [Grid Search](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from [scikit-learn](http://scikit-learn.org/), to make exaustive search from models to find top1. So, this notebook compiles, just the top1 models."},{"metadata":{"slideshow":{"slide_type":"subslide"},"_uuid":"660ecbac4faedeb0a92f32813d3e51651e92aa69"},"cell_type":"markdown","source":"## Used Models\n   * Linear Regression\n   * Decision Tree \n   * Neural Networks"},{"metadata":{"slideshow":{"slide_type":"subslide"},"_uuid":"82951c3ffd3bc8253fcc463945f6579021d3abf9"},"cell_type":"markdown","source":"## Task\n\nBased on individual trip attributes, should be predict the duration of each trip in the test set."},{"metadata":{"slideshow":{"slide_type":"subslide"},"_uuid":"68d31cad725a13bff8e0a59067c3b47c6826e164"},"cell_type":"markdown","source":"## Dataset\n\nDataset is from [New York City Taxi Trip Duration](https://www.kaggle.com/c/nyc-taxi-trip-duration), a playground competition from Kaggle."},{"metadata":{"slideshow":{"slide_type":"subslide"},"_uuid":"c8351aff0c752ace04ad8d0432978c76e9fd052b"},"cell_type":"markdown","source":"## Data fields\n   * **id** - a unique identifier for each trip\n   * **vendor_id** - a code indicating the provider associated with the trip record\n   * **pickup_datetime** - date and time when the meter was engaged\n   *  **dropoff_datetime** - date and time when the meter was disengaged\n   * **passenger_count** - the number of passengers in the vehicle (driver entered value)\n   * **pickup_longitude** - the longitude where the meter was engaged\n   * **pickup_latitude** - the latitude where the meter was engaged\n   * **dropoff_longitude** - the longitude where the meter was disengaged\n   * **dropoff_latitude** - the latitude where the meter was disengaged\n   * **store_and_fwd_flag** - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n   * **trip_duration** - duration of the trip in seconds"},{"metadata":{"_uuid":"3e7ba525c3487bcd37dc7720f3fdac7a3b7158ff","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Import base Packages\n\nIt is common in Python community usage of alias, like:\n  * pandas as pd\n  * numpy as np"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"# used to work with dataframes(excels like tables)\nimport pandas as pd\n\n# used to work properly with numerical operations\nimport numpy as np\n\n# used to avoid deprecated messages\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"8ca5f00d2221a0896388b0dade7e71363192e916","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Show files in Kernel Virtual Machine\n\n## File descriptions\n* **train.csv** - the training set (contains 1458644 trip records)\n* **test.csv** - the testing set (contains 625134 trip records)\n* **sample_submission.csv** - a sample submission file in the correct format\n"},{"metadata":{"_uuid":"2f8d971c59e5d5ec9c07acad4b2bf1dd3cc5bc44","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"!ls ../input","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"c9a9c6bb5e3b7ea037239dbd68cf131a8dd14b22","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Load train dataset\n\nOther common alias, is *dataframe* as *df*"},{"metadata":{"_uuid":"fabebecd2a6eff21279a2597d50a3f84b525d2c5","scrolled":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_train.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"c93f94bc8879f77f9180974c30cad435158be0dd","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Create shortest variables to \"large\" string labels"},{"metadata":{"_uuid":"f65fae8125926594fae779845485d09a190e9ef2","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"plg, plt = 'pickup_longitude', 'pickup_latitude'\ndlg, dlt = 'dropoff_longitude', 'dropoff_latitude'\npdt, ddt = 'pickup_datetime', 'dropoff_datetime'","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"7d7652796fe5a90e832248d3727ebdf7a3e2194e","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Clean Train dataset\n\nBasically in this section all unecessary or \"unmeaningful\" data from dataset was removed."},{"metadata":{"_uuid":"d346a7026460cec115f4314896f6ac514cc4927d","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Remove missing values"},{"metadata":{"_uuid":"27b0fdf886bd70d98578207f61de427a158cbe45","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"df_train.dropna(inplace=True)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"5e91b975bc52a0c755fac2d597feca4d5bb73dab","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Remove outliers respect to *trip_duration* column\n\n[Here](https://www.kdnuggets.com/2017/02/removing-outliers-standard-deviation-python.html) is why data that has more than two, absolute, standard deviation from mean are considered outliers."},{"metadata":{"_uuid":"59585ad2fda1a47d483eadf5c416c26736b8391f","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"mean, std_deviation = np.mean(df_train['trip_duration']), np.std(df_train['trip_duration'])\ndf_train = df_train[df_train['trip_duration'] <= mean + 2 * std_deviation]\ndf_train = df_train[df_train['trip_duration'] >= mean - 2 * std_deviation]","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"195f3c0efdd4df775a4585ecb73da77b79996609","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Function to calculate distance from *pickup* to *dropoff*\n\nTo make this calculation, has to be used [Haversine Formula](https://en.wikipedia.org/wiki/Haversine_formula), instead [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance), because latitude and longitue are points in sphere and not in plain.\n\nThe implementation below to Haversine Formula it is from [Aaron D](https://stackoverflow.com/users/399704/aaron-d), on StackOverflow and is available [here](https://stackoverflow.com/questions/15736995/how-can-i-quickly-estimate-the-distance-between-two-latitude-longitude-points). To extend precision of this calculation was used double precision, from [numpy](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)."},{"metadata":{"_uuid":"592753e057ec26f91cb42909ca48b22f41d6f9b5","collapsed":true,"slideshow":{"slide_type":"subslide"},"trusted":false},"cell_type":"code","source":"from math import radians, cos, sin, asin, sqrt\n\ndef haversine(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points \n    on the earth (specified in decimal degrees)\n    \"\"\"\n    # convert decimal degrees to radians \n    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n    # haversine formula \n    dlon = lon2 - lon1 \n    dlat = lat2 - lat1 \n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a)) \n    # Radius of earth in kilometers is 6371\n    km = 6371* c\n    return km\n\ndef haversine_distance(x):\n    x1, y1 = np.float64(x[plg]), np.float64(x[plt])\n    x2, y2 = np.float64(x[dlg]), np.float64(x[dlt])    \n    return haversine(x1, y1, x2, y2)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"d763df033357e032600882320679068c1345774e","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Create column with calculated distance from *pickup* to *dropoff*"},{"metadata":{"_kg_hide-output":false,"_uuid":"7d68ce04333da013f30d33cd42de5d6a0079325e","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"%%time\ndf_train['distance'] = df_train[[plg, plt, dlg, dlt]].apply(haversine_distance, axis=1)\ndf_train.head()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"2ee79368e2e88613951fdae81cadbb625dc2a349","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Convert string to datetime\n\nColumns *pickup_datetime* and *dropoff_datetime* are strings that are in format of *datetime*, and contains information about date and time. But to get date and time from strings in this columns, first it has to be converted to *datetime*. Code below to that."},{"metadata":{"_uuid":"53f63646b649a2bf0fc6b0955a9c276b81318d3d","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from datetime import datetime\n\ndf_train[pdt] = df_train[pdt].apply(lambda x : datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\ndf_train[ddt] = df_train[ddt].apply(lambda x : datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"8dea7c2a9e1280a6d767f0cbf068298873e04443","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Create colums from *pickuptime*\n\nDate in format YEAR-MONTH-DAY HOUR:MINUTES:SECONDS, aka %Y-%m-%d %H:%M:%S, has no meaningful information to Machine Learning models. Because of that, some information has to be extracted from *pickup_time*, that are:\n* **month** - integer from 1 to 12, where january is 1, february is 2, and so on;\n* **weekDay** - integer from 0 to 5, where monday is 0, tuesday is 1, and so on;\n* **dayMonth** - integer from 0 to 30, where 0 is the first day of month.\n* **pickupTimeMinutes** - integer that contains time in minutes of *pickupTime*. Seconds are removed because will insert much specificty in dataset, that can be problematic to generalize."},{"metadata":{"_uuid":"9daa96051dcd9a33a224fbef8bc5010ee3c4cdd3","slideshow":{"slide_type":"subslide"},"trusted":false},"cell_type":"code","source":"df_train['month'] = df_train[pdt].apply(lambda x : x.month)\ndf_train['weekDay'] = df_train[pdt].apply(lambda x : x.weekday())\ndf_train['dayMonth'] = df_train[pdt].apply(lambda x : x.day)\ndf_train['pickupTimeMinutes'] = df_train[pdt].apply(lambda x : x.hour * 60.0 + x.minute)\ndf_train.head()","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"3dbdd1f72962b6ff003121e7edd239c9d92865b6","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Remove unecessary columns\n\nRemove columns that not will be used to train models"},{"metadata":{"_uuid":"7baaaa3f1c75db92f3df76cf77aa45aa8d22ed40","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"df_train.drop(['id', pdt, ddt, dlg, dlt, 'store_and_fwd_flag'], inplace=True, axis=1)\ndf_train.head()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"3772b12019b422638fd490f575e7815744a29d03","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Rearrange columns\n\nJust organize columns to put output as last column, and all attributes that has similiar information together, for example, latitude besides longitude."},{"metadata":{"_uuid":"97a5e2efbefaa88a9b2252e9238a07d424f67169","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"df_train = df_train[\n    [\n        plg, \n        plt, \n        'distance', \n        'month', \n        'dayMonth', \n        'weekDay', \n        'pickupTimeMinutes', \n        'passenger_count', \n        'vendor_id', \n        'trip_duration'\n    ]\n]\ndf_train.head()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"5663bce2762bc57e647fc5c048f3c21672c9e8bf","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Prepare data to train models"},{"metadata":{"_uuid":"34cd95bd5fa87139bc11d169698774d0a6ee2083","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Get train and test data\n\nTo separate dataset will be use holdout, that consists of split dataset in two parts, usually that division is 70% to train and 30% to test or 66% to train and 34% to test. But in this project was used 70/30 division. But this test set was named *val*(validation), because it is used to validate model, and test set used was Kaggle PrivateTest, that are contents of *test.csv* file. Just Kaggle knows this PrivateTest output, on file are just inputs os tests.\n\nAt this point, if all cells are execute properly, dataset will clean. So, last colum contains output, named *y*, and all others columns(attributes) contains input, named *X*. Yes, upper X! For some reason, Python community that works with Machine Learning use this pattern, upper case x to input, and lower case y to output."},{"metadata":{"_uuid":"cd5216739ac473aaac8238e6de2c49e4ce5118ef","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX, y = df_train.iloc[:, :-1], df_train.iloc[:, -1]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=4305)\nX_train.shape, y_train.shape, X_val.shape, y_val.shape","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"84d4e131cba4408aa7a162626cb8fc482a30b5e6","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Standardization input\n\nBrief explanation what is Normalization and Standardization:\n* **Normalization**: rescales the values into a range of [0,1]. This might be useful in some cases where all parameters need to have the same positive scale. However, the outliers from the data set are lost.\n* **Standardization**: rescales data to have a mean of 0 and standard deviation of 1 (unit variance).\n\nMore detailed description [here](http://sebastianraschka.com/Articles/2014_about_feature_scaling.html)."},{"metadata":{"_uuid":"b4c75f7ba83791695b7ff9cf1da236c3cb1c3721","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\n\nscaler = StandardScaler().fit(X_val)\nX_val = scaler.transform(X_val)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"b9df8799cab0b15e62ed16591b943c34ac223ab6","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Use KFold to Cross-Validation validation\n\n[Link](https://www.analyticsvidhya.com/blog/2018/05/improve-model-performance-cross-validation-in-python-r/) to explanation about why cross-validation method is import to evaluate performance of Machine Learn models, and how its work.\n\nThis dataset was separeted using k = 3, because validation of this models are just for study purpose, and not of extremelly guaranteed precision. Scientific reports and experiments recommend k = 10, to good model evaluation.\n\nFor guarantee that model will be good at generalization, dataset was shuffled to remove any data dependence."},{"metadata":{"_uuid":"363325f16e3df9c73a88ecf9fef53e2f01287860","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score\n\nkf = KFold(n_splits=3, shuffle=True, random_state=4305)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"63845eda2719127ba90d830a2b2514ae1a66bba4","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Create Models"},{"metadata":{"_uuid":"e1877fae2ca4fedbbc8d3088ea7e48b363d12e33","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"models = {}","execution_count":16,"outputs":[]},{"metadata":{"_uuid":"53b87dddc2d237dcb74d5f2992ddeac07a0d244b","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Create Neural Network Model"},{"metadata":{"_uuid":"3a8a01c4d38e9ce285b6894406d752e7c842840e","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\n\nmlp = MLPRegressor(\n    activation='relu',\n    alpha=0.0001, \n    batch_size='auto',\n    beta_1=0.9,\n    beta_2=0.999, \n    early_stopping=False, \n    epsilon=1e-08,\n    hidden_layer_sizes=(3, 3),\n    learning_rate='adaptive',\n    learning_rate_init=0.001, \n    max_iter=1000, \n    momentum=0.5,\n    nesterovs_momentum=True,\n    power_t=0.5,\n    random_state=None,\n    shuffle=True, \n    solver='adam',\n    tol=0.0001, \n    validation_fraction=0.1,\n    verbose=False, \n    warm_start=True\n)\n\nmodels['mlp'] = mlp","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"9fc772a23eedaf0c36f3857b87c2085767044788","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Create Decision Tree Model"},{"metadata":{"_uuid":"c2eb0e48515f99933755498c67a41b9ad475e423","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ndtree = DecisionTreeRegressor(\n    criterion='mse', \n    max_depth=17, \n    max_features=None,       \n    max_leaf_nodes=None,\n    min_impurity_decrease=0.0,  \n    min_impurity_split=None, \n    min_samples_leaf=1,      \n    min_samples_split=2,\n    min_weight_fraction_leaf=0.0,  \n    presort=False, \n    random_state=None,\n    splitter='best'\n)\n\nmodels['dtree'] = dtree","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"b20e9e098c946004dc33f1754df521e96c75782a","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Create Linear Regression Model"},{"metadata":{"_uuid":"d09e5eefa9341241d646e25bb0ec252e1709878f","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlreg = LinearRegression(\n    copy_X=True, \n    fit_intercept=True, \n    n_jobs=1, \n    normalize=False\n)\n\nmodels['lreg'] = lreg","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"67b61440a63d9ca325a06075d4915cc2d45fee73","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Show created models"},{"metadata":{"_uuid":"ab87c7a80f26de5bb4cd24c9c8ffa6936fb1d998","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"models","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"991bdf5fc931b972ad27e0bc2d10ad74a667cac8","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Create function to calculate error\n\nThis competitions evalution use RMSLE (Root Mean Square Logarithmic Error) function. That works like explained [here](https://www.kaggle.com/c/nyc-taxi-trip-duration#evaluation), and scikit-learn does not implement that like a scorer function. Because of that, this function has to be implemented. Thanks to [jpopham91](https://www.kaggle.com/jpopham91) at Kaggle,  it is already implemented in vectorized version, and is available [here](https://www.kaggle.com/jpopham91/rmlse-vectorized).\n\n\\begin{equation*}\n    \\epsilon = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\log(p_i + 1) - \\log(a_i+1))^2 }\n\\end{equation*}\n\nWhere:\n\n- $\\epsilon$ - is the RMSLE value (score);\n- $n$ - is the total number of observations in the (public/private) data set;\n- $p_{i}$ - is model prediction of trip duration;\n- $a_{i}$ - is the actual trip duration for $i$;\n- $log(x)$ - is the natural logarithm of $x$.\n"},{"metadata":{"_uuid":"7a959844793b542d55b8859bc85ceed2b5db65d3","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\ndef rmsle(y_true, y_pred):\n    assert len(y_true) == len(y_pred)\n    return np.sqrt(np.mean(np.square(np.subtract(np.log1p(y_true), np.log1p(y_pred)))))\n\nrmsle_scorer = make_scorer(rmsle, greater_is_better=False)","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"3ce0f8d22d1056e5e9da73d86b242505c8e1be19","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Train models"},{"metadata":{"_uuid":"e920561f19a5f56d1bfe16c5d458044ba9048998","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"%%time\nfor model in models.values():    \n    model.fit(X_train, y_train)","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"c451d96b58be03572bd19ac6b7613ff5d9608ff6","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Validate Models"},{"metadata":{"_uuid":"19025c41607d0dfc75a4dc07f53bb3e7b2ed3639","scrolled":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"for model_name, model in models.items():    \n    score = cross_val_score(model, X_val, y_val, cv=kf)\n    print(f'model name: {model_name} \\t score: {score} \\t mean_score: {np.mean(score)}')","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"da8d7ef2d3344307f793a2f1eff8738332611371","slideshow":{"slide_type":"slide"}},"cell_type":"markdown","source":"# Submit to Kaggle\n\nWill be generated files, one for each model trained, after that this notebook must be commited to be possible output files submission."},{"metadata":{"_uuid":"6f2ae87418d941f69f50d188e2e6bc5c920230eb","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Load test dataset\n\nTo test models Kaggle maintains a PrivateTest set, where isgiven to users just inputs, for them fill output and send to Kaggle evaluate model performance."},{"metadata":{"_uuid":"da4136cd43b4bc77b7854d9fd8c38bc6e372204e","slideshow":{"slide_type":"-"},"trusted":false},"cell_type":"code","source":"df_test = pd.read_csv('../input/test.csv')\ndf_test.head()","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"993e3850d7e983bf7f07693701f42c40bff6c5de","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Clean Test dataset"},{"metadata":{"_kg_hide-output":true,"_uuid":"958aabc2a89408a7d273c6cad63e69b4bbb0ce4f","slideshow":{"slide_type":"-"},"trusted":false},"cell_type":"code","source":"df_test['distance'] = df_test[[plg, plt, dlg, dlt]].apply(haversine_distance, axis=1)\ndf_test[pdt] = df_test[pdt].apply(lambda x : datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\ndf_test['month'] = df_test[pdt].apply(lambda x : x.month)\ndf_test['weekDay'] = df_test[pdt].apply(lambda x : x.weekday())\ndf_test['dayMonth'] = df_test[pdt].apply(lambda x : x.day)\ndf_test['pickupTimeMinutes'] = df_test[pdt].apply(lambda x : x.hour * 60.0 + x.minute)\ndf_test.drop(['pickup_datetime', dlg, dlt, 'store_and_fwd_flag'], inplace=True, axis=1)\ndf_test = df_test[['id', plg, plt, 'distance', 'month', 'dayMonth', 'weekDay', 'pickupTimeMinutes', 'passenger_count', 'vendor_id']]\ndf_test.head()","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"0d7ef8dcf379855b0edf8ed897796400f3441a96","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Get Test data"},{"metadata":{"_uuid":"4ea5e3cfc0e2d5daf92503d1d3d604f15bd57075","slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"X_id, X_test = df_test.iloc[:, 0], df_test.iloc[:, 1:]\nX_id.shape, X_test.shape","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"ee28ae6c9e9c14ddd1aa5d9160e7bbf7f9b3e74c","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Standardization input"},{"metadata":{"_uuid":"ab4200b5ef0165797e14ff5ed71805de13f545ec","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"scaler = StandardScaler().fit(X_test)\nX_test = scaler.transform(X_test)","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"cc2e775089ea834096b0844dcfaa9d80471e34b2","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Predict outputs\n\nMachine Learn models are programming/statistics/artificial intelligence tools to make prediction, because of that, process of a model generate an output is called prediction."},{"metadata":{"_uuid":"09a5a2fc60ae6ef689c957ebebcd4b7b8a8b4b3d","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"models_output = {}\nfor model_name, model in models.items():\n    models_output[model_name] = model.predict(X_test)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"804c4eb482c89a78220715cffed305c0dcb02302","slideshow":{"slide_type":"subslide"}},"cell_type":"markdown","source":"## Generate output file"},{"metadata":{"_uuid":"fc411da1fca06f5a39b547482bb372b64e341aeb","collapsed":true,"slideshow":{"slide_type":"fragment"},"trusted":false},"cell_type":"code","source":"for model_name, model_output in models_output.items():\n    df_output = pd.DataFrame({'id' : X_id, 'trip_duration': model_output})\n    df_output.to_csv(model_name + '.csv', index=False)","execution_count":29,"outputs":[]},{"metadata":{"slideshow":{"slide_type":"slide"},"_uuid":"24eaadd00c631a1c1f7f671b244c501b04f44dd2"},"cell_type":"markdown","source":"# Results"},{"metadata":{"slideshow":{"slide_type":"fragment"},"_uuid":"1abc0c1bea28d69bb48db919074d0ce87793aae8"},"cell_type":"markdown","source":"## Proposed Models\n\n| Model name            | Local score| Kaggle Public | Kaggle Private |\n|-----------------------|------------|---------------|----------------|\n| Decision Tree         | 0.61409    | 0.50989       | 0.50703        |\n| Linear Regression     | 0.49877    | 0.62139       | 0.62284        |\n| Multilayer Perceptron | 0.56493    | 0.53855       | 0.53848        |"},{"metadata":{"slideshow":{"slide_type":"fragment"},"_uuid":"da4db8789367a457e4f0fe0ac0b3906d2b4a1060"},"cell_type":"markdown","source":"## Kaggle\n\n| Team Name      | Public  | Private |\n|----------------|---------|---------|\n| L2F            | 0.28882 | 0.28976 |\n| Swimming       | 0.30566 | 0.30664 |\n| Tomohiko Itano | 0.30831 | 0.30942 |"}],"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"384px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}