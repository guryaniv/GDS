{"cells": [{"metadata": {"_cell_guid": "3759acc1-2b32-4262-a296-0b245fcf0d7d", "_uuid": "ccb964ee27038efd91d5c6bece25c38d7fe37165"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import math\n", "from scipy import stats\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "train = pd.read_json('../input/train.json')#C:\\Users\\jajy\\Documents\\fall\\ML\\project\\train_data\\processed\n", "train['inc_angle'] = pd.to_numeric(train['inc_angle'],errors='coerce')\n", "train.drop(['inc_angle'], axis = 1, inplace = True)\n", "#mean median max min\n", "\n", "\n", "maxi=[np.max(np.array(x)) for x in train['band_1']]\n", "mean=[np.mean(np.array(x)) for x in train['band_1']]\n", "       \n"]}, {"metadata": {"_cell_guid": "a52a6116-70e4-47d1-b93c-614ad08c8c47", "collapsed": true, "_uuid": "1e96cee46d7b63cea0c0148833933d56ed1146c3"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#preprocessing band1 \n", "for p in range(0,len(train)):\n", "    m=train['band_1'][p]\n", "    maximum=max(m)\n", "    bound=abs(maxi[p]-mean[p])\n", "    bound=math.ceil(0.35*bound)\n", "    for b in range(0,len(m)):\n", "        if (maximum-m[b])>bound:\n", "            train['band_1'][p][b]=0\n", "            \n"]}, {"metadata": {"_cell_guid": "82f19ab5-caad-47cb-a50e-b8f70018afdc", "collapsed": true, "_uuid": "b9290ffc66e7908ae5585bf2af1933bac7bc8bbb"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#preprocessing band2 \n", "for p in range(0,len(train)):\n", "    m=train['band_2'][p]\n", "\n", "    \n", "    bound=abs(maxi[p]-mean[p])\n", "    bound=math.ceil(0.35*bound)\n", "    for b in range(0,len(m)):\n", "        if train['band_1'][p][b]==0:\n", "            train['band_2'][p][b]=0"]}, {"metadata": {"_cell_guid": "4d7134e3-a049-42af-8aea-b33aa90ed2b3", "collapsed": true, "_uuid": "13fc1baace095f50c22c8a09cbae7919ac4ed7a6"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["def transform(df):\n", "    images = []\n", "    for i, row in df.iterrows():\n", "        band_1 = np.array(row['band_1']).reshape(75, 75)\n", "        band_2 = np.array(row['band_2']).reshape(75, 75)\n", "        images.append(np.dstack((band_1, band_2)))\n", "    return np.array(images)\n"]}, {"metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import scipy\n", "from scipy import ndimage\n", "def augment(images):\n", "    image_rot90 = []\n", "    image_rot180 = []\n", "    image_rot270 = []\n", "    image_mirror_lr = []\n", "    image_mirror_ud = []\n", "    for i in range(0,images.shape[0]):\n", "        band_1 = images[i,:,:,0]\n", "        band_2 = images[i,:,:,1]\n", "        \n", "        # rotate 90\n", "        #band_1_rot90 = np.rot90(band_1)\n", "        #band_2_rot90 = np.rot90(band_2)\n", "        band_1_rot90 = scipy.ndimage.rotate(band_1, 90)\n", "        band_2_rot90 = scipy.ndimage.rotate(band_2, 90)\n", "        image_rot90.append(np.dstack((band_1_rot90, band_2_rot90)))\n", "        \n", "        # rotate 180\n", "        #band_1_rot180 = np.rot90(band_1_rot90)\n", "        #band_2_rot180 = np.rot90(band_2_rot90)\n", "        band_1_rot180 = scipy.ndimage.rotate(band_1, 180)\n", "        band_2_rot180 = scipy.ndimage.rotate(band_2, 180)\n", "        image_rot180.append(np.dstack((band_1_rot180, band_2_rot180)))\n", "        \n", "        # rotate 270\n", "        #band_1_rot270 = np.rot90(band_1_rot180)\n", "        #band_2_rot270 = np.rot90(band_2_rot180)\n", "        band_1_rot270 = scipy.ndimage.rotate(band_1, 270)\n", "        band_2_rot270 = scipy.ndimage.rotate(band_2, 270)\n", "        image_rot270.append(np.dstack((band_1_rot270, band_2_rot270)))\n", "        \n", "        # mirror left-right\n", "        #band_1_mirror_lr = np.flip(band_1, 0)\n", "        #band_2_mirror_lr = np.flip(band_2, 0)\n", "        #image_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr)))\n", "        \n", "        # mirror up-down\n", "        #band_1_mirror_ud = np.flip(band_1, 1)\n", "        #band_2_mirror_ud = np.flip(band_2, 1)\n", "        #image_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud)))\n", "        \n", "    rot90 = np.array(image_rot90)\n", "    rot180 = np.array(image_rot180)\n", "    rot270 = np.array(image_rot270)\n", "    #mirrorlr = np.array(image_mirror_lr)\n", "    #mirrorud = np.array(image_mirror_ud)\n", "    images = np.concatenate((images, rot90, rot180, rot270)) #mirrorlr, mirrorud))\n", "    return images"]}, {"metadata": {"_cell_guid": "095fc20e-24cb-4489-850a-02b32bf51933", "collapsed": true, "_uuid": "1ee7fb236196a2c1dd291bab722e0b9250191817"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#nope\n", "def augment(images):\n", "    image_rot90 = []\n", "    image_rot180 = []\n", "    image_rot270 = []\n", "    image_mirror_lr = []\n", "    image_mirror_ud = []\n", "    for i in range(0,images.shape[0]):\n", "        band_1 = images[i,:,:,0]\n", "        band_2 = images[i,:,:,1]\n", "        \n", "        # rotate 90\n", "        band_1_rot90 = np.rot90(band_1)\n", "        band_2_rot90 = np.rot90(band_2)\n", "        image_rot90.append(np.dstack((band_1_rot90, band_2_rot90)))\n", "        \n", "        # rotate 180\n", "        band_1_rot180 = np.rot90(band_1_rot90)\n", "        band_2_rot180 = np.rot90(band_2_rot90)\n", "        image_rot180.append(np.dstack((band_1_rot180, band_2_rot180)))\n", "        \n", "        # rotate 270\n", "        band_1_rot270 = np.rot90(band_1_rot180)\n", "        band_2_rot270 = np.rot90(band_2_rot180)\n", "        image_rot270.append(np.dstack((band_1_rot270, band_2_rot270)))\n", "        \n", "        # mirror left-right\n", "        band_1_mirror_lr = np.flip(band_1, 0)\n", "        band_2_mirror_lr = np.flip(band_2, 0)\n", "        image_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr)))\n", "        \n", "        # mirror up-down\n", "        band_1_mirror_ud = np.flip(band_1, 1)\n", "        band_2_mirror_ud = np.flip(band_2, 1)\n", "        image_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud)))\n", "        \n", "    rot90 = np.array(image_rot90)\n", "    rot180 = np.array(image_rot180)\n", "    rot270 = np.array(image_rot270)\n", "    mirrorlr = np.array(image_mirror_lr)\n", "    mirrorud = np.array(image_mirror_ud)\n", "    images = np.concatenate((images, rot90, rot180, rot270, mirrorlr, mirrorud))\n", "    return images"]}, {"metadata": {"_cell_guid": "af2e55b5-de83-48ed-b7b0-85cd77abe3b2", "_uuid": "6f541f1239cfd8e6a5a79be59907d08733addf38"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "x = train['band_1'] #only band1\n", "#x = train['band_2'] #only band2\n", "#x = train.drop('is_iceberg',axis = 1) #band1 & band2\n", "y = train['is_iceberg']\n", "\n", "train_X = transform(train)\n", "train_y = np.array(train['is_iceberg'])\n", "train_X = augment(train_X)\n", "train_y = np.concatenate((train_y, train_y, train_y, train_y))#, train_y, train_y))\n", "xtrain, xtest, ytrain, ytest = train_test_split(train_X, train_y, test_size=0.25, train_size=0.75 )\n"]}, {"metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["xtrain.tolist()\n", "print(xtrain)"]}, {"metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["#SVM\n", "from sklearn.svm import LinearSVC\n", "svm_clf = LinearSVC(C=2.0)\n", "svm_clf.fit(xtrain,ytrain)\n", "predictions = svm_clf.predict(xtest)\n", "print(confusion_matrix(ytest, predictions))\n", "print(classification_report(ytest, predictions))\n", "print(accuracy_score(ytest, Predictions))\n", "#print(ytest)"]}, {"metadata": {"_cell_guid": "52234a16-0c1e-4e26-bb58-390029908531", "_uuid": "8e6fa02aef1dfb205281c03484e4df1a7323f7c0"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import keras as k\n", "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n", "model=k.models.Sequential()\n", "\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 2)))\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3),activation='relu'))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "#model.add(GlobalAveragePooling2D())\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3),activation='relu'))\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "\n", "#model.add(k.layers.convolutional.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n", "#model.add(k.layers.convolutional.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n", "#model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "\n", "model.add(k.layers.Dropout(0.25))\n", "\n", "model.add(k.layers.Flatten())\n", "\n", "#model.add(k.layers.Dense(128, activation='relu'))\n", "#model.add(k.layers.Dropout(0.2))\n", "\n", "model.add(k.layers.Dense(64, activation='relu'))\n", "model.add(k.layers.Dropout(0.3))\n", "\n", "model.add(k.layers.Dense(32, activation='relu'))\n", "model.add(k.layers.Dropout(0.5))\n", "\n", "model.add(k.layers.Dense(1, activation=\"sigmoid\"))\n", "\n", "model.compile(loss='binary_crossentropy', optimizer = k.optimizers.Nadam(lr=0.01), metrics=['accuracy'])\n", "model.summary()\n", "\n", "model.fit(xtrain, ytrain, batch_size=100, epochs=10, verbose=1)"]}, {"metadata": {"_cell_guid": "e2414dfa-3b73-476f-9bd3-6019151d54c5", "collapsed": true, "_uuid": "816b87cefa7c1a0601b2e61b50f735c8f339a8c2"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import keras as k\n", "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n", "model=k.models.Sequential()\n", "\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3),activation='relu', input_shape=(75, 75, 2)))\n", "model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3),activation='relu'))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "#model.add(GlobalAveragePooling2D())\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3),activation='relu'))\n", "model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3), activation='relu' ))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "\n", "model.add(k.layers.convolutional.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n", "model.add(k.layers.convolutional.Conv2D(256, kernel_size=(3, 3), activation='relu'))\n", "model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n", "\n", "model.add(k.layers.Dropout(0.25))\n", "\n", "model.add(k.layers.Flatten())\n", "\n", "model.add(k.layers.Dense(128, activation='relu'))\n", "model.add(k.layers.Dropout(0.2))\n", "\n", "model.add(k.layers.Dense(64, activation='relu'))\n", "model.add(k.layers.Dropout(0.3))\n", "\n", "model.add(k.layers.Dense(32, activation='relu'))\n", "model.add(k.layers.Dropout(0.5))\n", "\n", "model.add(k.layers.Dense(1, activation=\"sigmoid\"))\n", "\n", "model.compile(loss='binary_crossentropy', optimizer = k.optimizers.Nadam(lr=0.01), metrics=['accuracy'])\n", "model.summary()\n", "\n", "model.fit(xtrain, ytrain, batch_size=100, epochs=10, verbose=1)"]}, {"metadata": {}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}, {"metadata": {"scrolled": true, "_cell_guid": "95fb673f-c1cd-4a10-b57d-126b1491a7a0", "collapsed": true, "_kg_hide-output": false, "_uuid": "f8ea0282203b921efec967cf67ea33a93665324a"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["import sklearn\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "pred = model.predict(xtest)\n", "#print(ytest)\n", "predictions =[]\n", "for i in range(len(pred)):\n", "    predictions.append(pred[i][0])\n", "yt =[]\n", "for i in ytest:\n", "    yt.append(i)\n", "#print(predictions)\n", "print(classification_report(yt, predictions))"]}, {"metadata": {"_cell_guid": "8fd0e5c0-f0ce-4a13-9c74-4e97458654f7", "collapsed": true, "_uuid": "fe42bbfd3357d44956ff1b808383eea656fbf007"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["print(ytest)\n", "yt =[]\n", "for i in ytest:\n", "    yt.append(i)\n", "print(yt)"]}, {"metadata": {"_cell_guid": "20992781-87e7-427c-8ce5-08a2ded23d35", "collapsed": true, "_uuid": "0fb5af488f83ef1cc4e59bec88c402777b9639fd"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["print(classification_report(yt, predictions))"]}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.3"}}, "nbformat_minor": 1, "nbformat": 4}