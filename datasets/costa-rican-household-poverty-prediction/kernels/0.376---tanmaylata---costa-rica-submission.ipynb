{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#importing the dataset\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nsubmission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8ca3bb34b1812880729de44882172e6386314be"},"cell_type":"code","source":"#checking for null values\nmissing_values = train_df.isnull().sum().sort_values(ascending = False)\nmissing_values =(missing_values[missing_values > 0] / train_df.shape[0])\nprint(f'{missing_values *100} %')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d17af5976f3685e265f27ed275de08e4a8af0180"},"cell_type":"code","source":"#We need to take care of missing data\n#We will first check for v18q1\ntrain_df[['v18q','v18q1']].groupby(train_df['v18q'] == 0).count()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0123cfff31cbfc2b17f4aa2b2ba92441f74fe0ba"},"cell_type":"code","source":"#We can update the null values in v18q1 by 0\ntrain_df['v18q1'] = train_df['v18q1'].fillna(0)\ntest_df['v18q1'] = test_df['v18q1'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0428dc1c3fe257a65e6868492d9ebc3f805cd0d"},"cell_type":"code","source":"#Lets replace the missisng rez_esc values by 0\ntrain_df['rez_esc'] = train_df['rez_esc'].fillna(0)\ntest_df['rez_esc'] = test_df['rez_esc'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9609218e6eae7e2b7bf99d3bc8a8e7895d7c1e4e"},"cell_type":"code","source":"#We can finish off with the meaneduc and SQBmeaned label by imputing them with the median of the columns.\nmedian_meaneduc = train_df['meaneduc'].median()\nmedian_SQBmeaned = train_df['SQBmeaned'].median()\ntrain_df['meaneduc'] = train_df['meaneduc'].fillna(median_meaneduc)\ntrain_df['SQBmeaned'] = train_df['SQBmeaned'].fillna(median_SQBmeaned)\n\nmedian_meaneduc_test = test_df['meaneduc'].median()\nmedian_SQBmeaned_test = test_df['SQBmeaned'].median()\ntest_df['meaneduc'] = test_df['meaneduc'].fillna(median_meaneduc_test)\ntest_df['SQBmeaned'] = test_df['SQBmeaned'].fillna(median_SQBmeaned_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee2d981ebe604b9c359eba1a3c31aed95afe29a1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cfe20cad60ba9af979dbee928b33f66f4a5d49d"},"cell_type":"code","source":"#Check for households where The household population hs unequal target distribution\nall_equal = train_df.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nnot_equal = all_equal[all_equal != True]\nprint(len(not_equal))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dafc98d53f4143128bf5ec2fc3a5d0ef28d88b7"},"cell_type":"code","source":"#correcting the unqual households\nfor household in not_equal.index:\n    true_target = int(train_df[(train_df['idhogar'] == household) & (train_df['parentesco1'] == 1.0)]['Target'])\n    train_df.loc[train_df['idhogar'] == household, 'Target'] = true_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"780b09bca66596b781942d73eb516f2a032fe5fe"},"cell_type":"code","source":"#Replacing the values.\ntrain_house_paid = train_df.loc[train_df['v2a1'].isnull() & (train_df['tipovivi1'] == 1)]\ntrain_house_paid['v2a1'] = train_house_paid['v2a1'].fillna(0)\ntrain_df.update(train_house_paid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"934e1870a69e09c810db8229ed63b81f504f8f9e"},"cell_type":"code","source":"test_house_paid = test_df.loc[test_df['v2a1'].isnull() & (test_df['tipovivi1'] == 1)]\ntest_house_paid['v2a1'] = test_house_paid['v2a1'].fillna(0)\ntest_df.update(test_house_paid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"25c26cd803a342f8327b04e352efc52c2f151d29"},"cell_type":"code","source":"train_df.fillna(-1, inplace = True)\ntest_df.fillna(-1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9e879423941bba60d15b70278a77120aa65c1dd"},"cell_type":"code","source":"train_df['dependency'] = np.sqrt(train_df['SQBdependency'])\ntest_df['dependency'] = np.sqrt(test_df['SQBdependency'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af42a46f53b9b1e157e6d53664cb6b4fbaa64205"},"cell_type":"code","source":"def mapping(data):\n    if data == 'yes':\n        return 1\n    elif data == 'no':\n        return 0\n    else:\n        return data\ntrain_df['dependency'] = train_df['dependency'].apply(mapping).astype(float)\ntrain_df['edjefa'] = train_df['edjefa'].apply(mapping).astype(float)\ntrain_df['edjefe'] = train_df['edjefe'].apply(mapping).astype(float)\n\ntest_df['dependency'] = test_df['dependency'].apply(mapping).astype(float)\ntest_df['edjefa'] = test_df['edjefa'].apply(mapping).astype(float)\ntest_df['edjefe'] = test_df['edjefe'].apply(mapping).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8622bb7b16b6e2bcffef786392a308699442bfbf"},"cell_type":"code","source":"#converting into percentages\ntrain_df['males_above_12'] = train_df['r4h2']/train_df['r4h3']\ntrain_df['person_above_12'] = train_df['r4t2']/train_df['r4t3']\ntrain_df['size_to_person_ratio'] = train_df['tamhog']/train_df['tamviv']\n\ntest_df['males_above_12'] = test_df['r4h2']/test_df['r4h3']\ntest_df['person_above_12'] = test_df['r4t2']/test_df['r4t3']\ntest_df['size_to_person_ratio'] = test_df['tamhog']/test_df['tamviv']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67c93c6000a929c34d21b3c1e0994f0574fdf853"},"cell_type":"code","source":"train_df['males-above_12'] = train_df['males_above_12'].fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29baaf5e59fd53907227d2c512fda599dc4e4e80"},"cell_type":"code","source":"test_df['males-above_12'] = test_df['males_above_12'].fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3807771dc709ce49e2a3f91a0e5ed0f4e7a1d0dc"},"cell_type":"code","source":"train_df = train_df.fillna(0)\ntest_df = test_df.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc103721f1aafdedacc103ddc78b78d9066a581d"},"cell_type":"code","source":"#dropping the useless columns\ncols = ['Id','idhogar','SQBescolari','SQBage','SQBhogar_total','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency','SQBmeaned','agesq']\ntrain_df.drop(cols, axis = 1, inplace = True)\ntest_df.drop(cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb7a81097fbe818ac0502c230fb28ff1e2e6fbb7"},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b8eb123c6483f7f72aa1f1c54525f81d08beb4d"},"cell_type":"code","source":"#creating the matrics of features\ny = train_df.Target.values\ntrain_df.drop('Target', axis =1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ab47ad6bc6199343e549e57d397317cdb80c8ce"},"cell_type":"code","source":"X = train_df.iloc[:,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b2e1f490179fc0c5a7a1953fb13235703eb6647"},"cell_type":"code","source":" X_test = test_df.iloc[:,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c410653f40662cd8580782ffcb7fe2ce556bf43e"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as RFC\nclassifier = RFC(n_estimators =25 , random_state = 0)\nclassifier.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb5b4a342bff2630e77a3c28c1d7cd6e0964edc6"},"cell_type":"code","source":"# from xgboost import XGBClassifier as XGB\n# model = XGB()\n# model.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad8eff096c069085eef859d0d966ba2cf0514d06"},"cell_type":"code","source":"predictions = classifier.predict(X_test).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19d6b18b4c623e2fcf76aafe637bc85334dfd602"},"cell_type":"code","source":"submission = pd.DataFrame({\n    \"Id\" : submission['Id'],\n    \"Target\" : predictions\n})\nsubmission.to_csv('sample_submission.csv', index =False, encoding = 'utf-8')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}