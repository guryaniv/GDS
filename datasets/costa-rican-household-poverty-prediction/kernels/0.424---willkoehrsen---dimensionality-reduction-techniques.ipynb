{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom umap import UMAP\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.manifold import TSNE\n# Clearing up memory\nimport gc\n\n# Featuretools for automated feature engineering\nimport featuretools as ft\nimport featuretools.variable_types as vtypes\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import Imputer\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13dd09b5c29533bfe6e84ba2e8ffb2afcd8d6c77"},"cell_type":"code","source":"feature_matrix = pd.read_csv('../input/costa-rican-poverty-derived-data/ft_2000.csv')\nfeature_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ae44c82bf7ae8b5ea6815d7066fe49c53e7d4b19"},"cell_type":"code","source":"feature_matrix['SUM(ind.rez_esc / escolari)'] = feature_matrix['SUM(ind.rez_esc / escolari)'].astype(np.float32)\nfeature_matrix['SUM(ind.age / escolari)'] = feature_matrix['SUM(ind.age / escolari)'].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"72e05bfb48f589bc0c6e541dacd526db73f6cde9"},"cell_type":"code","source":"for col in feature_matrix:\n    if feature_matrix[col].dtype == 'object':\n        if col != 'idhogar':\n            feature_matrix[col] = feature_matrix[col].astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1504aa24f6a4b6090bbca1868b3b7c64b23766a"},"cell_type":"code","source":"feature_matrix.columns[np.where(feature_matrix.dtypes == 'object')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d548dfac93f85248d789326f2fed941b0a7b91d"},"cell_type":"code","source":"missing_threshold = 0.95\ncorrelation_threshold = 0.99\n\n\ntrain = feature_matrix[feature_matrix['Target'].notnull()]\ntest = feature_matrix[feature_matrix['Target'].isnull()]\n\ntrain_ids = list(train.pop('idhogar'))\ntest_ids = list(test.pop('idhogar'))\n\nfeature_matrix = feature_matrix.replace({np.inf: np.nan, -np.inf:np.nan})\nn_features_start = feature_matrix.shape[1]\nprint('Original shape: ', feature_matrix.shape)\n\n# Find missing and percentage\nmissing = pd.DataFrame(feature_matrix.isnull().sum())\nmissing['fraction'] = missing[0] / feature_matrix.shape[0]\nmissing.sort_values('fraction', ascending = False, inplace = True)\n\n# Missing above threshold\nmissing_cols = list(missing[missing['fraction'] > missing_threshold].index)\nn_missing_cols = len(missing_cols)\n\n# Remove missing columns\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in missing_cols]]\nprint('{} missing columns with threshold: {}.'.format(n_missing_cols, missing_threshold))\n\n# Zero variance\nunique_counts = pd.DataFrame(feature_matrix.nunique()).sort_values(0, ascending = True)\nzero_variance_cols = list(unique_counts[unique_counts[0] == 1].index)\nn_zero_variance_cols = len(zero_variance_cols)\n\n# Remove zero variance columns\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in zero_variance_cols]]\nprint('{} zero variance columns.'.format(n_zero_variance_cols))\n\n# Correlations\ncorr_matrix = feature_matrix.corr()\n\n# Extract the upper triangle of the correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n\n# Select the features with correlations above the threshold\n# Need to use the absolute value\nto_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n\nn_collinear = len(to_drop)\n\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in to_drop]]\nprint('{} collinear columns removed with correlation above {}.'.format(n_collinear,  correlation_threshold))\n\ntotal_removed = n_missing_cols + n_zero_variance_cols + n_collinear\n\nprint('Total columns removed: ', total_removed)\nprint('Shape after feature selection: {}.'.format(feature_matrix.shape))\n\n# Remove columns derived from the Target\ndrop_cols = []\nfor col in feature_matrix:\n    if col == 'Target':\n        pass\n    else:\n        if 'Target' in col:\n            drop_cols.append(col)\n\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in drop_cols]]    \n\n# Extract out training and testing data\ntrain = feature_matrix[feature_matrix['Target'].notnull()]\ntest = feature_matrix[feature_matrix['Target'].isnull()]\n\ntrain_ids = list(train.pop('idhogar'))\ntest_ids = list(test.pop('idhogar'))\n\ntrain_labels = np.array(train.pop('Target')).reshape((-1, ))\ntest = test.drop(columns = 'Target')\n\ntrain = train.replace({np.inf: np.nan, -np.inf: np.nan})\ntest = test.replace({np.inf: np.nan, -np.inf: np.nan})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa0daf71bec4eaa1c4ecb73a9d3665cdd1777032"},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nfeature_list = list(train.columns)\n\nimputer = SimpleImputer(strategy = 'median')\ntrain = imputer.fit_transform(train)\ntest = imputer.transform(test)\n\ntrain_df = pd.DataFrame(train, columns = feature_list)\ntest_df = pd.DataFrame(test, columns = feature_list)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad2e1bc9a085b158e9f6181bd5eba220434bcf35","collapsed":true},"cell_type":"code","source":"train_df = train_df.astype(np.float32)\ntest_df = test_df.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"62c0c94e95ed4e2fd37a560c9d73cb34ceb1b545"},"cell_type":"code","source":"from timeit import default_timer as timer\n\nn_components = 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"961c71e5bf9bc6faae5d271cad7d0ebd53dd228a","collapsed":true},"cell_type":"code","source":"umap = UMAP(n_components=n_components)\npca = PCA(n_components=n_components)\nica = FastICA(n_components=n_components)\ntsne = TSNE(n_components=n_components)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ece588d4a488ea48f7f11154e2244fe5c30464c"},"cell_type":"code","source":"for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n    \n    if name == 'umap':\n        start = timer()\n        reduction = method.fit_transform(train, train_labels)\n        test_reduction = method.transform(test)\n        end = timer()\n    \n    else:\n        start = timer()\n        reduction = method.fit_transform(train)\n        test_reduction = method.transform(test)\n        end = timer()\n        \n    print(f'Method: {name} {round(end - start, 2)} seconds elapsed.')\n    train_df['%s_c1' % name] = reduction[:, 0]\n    train_df['%s_c2' % name] = reduction[:, 1]\n    train_df['%s_c3' % name] = reduction[:, 2]\n    \n    test_df['%s_c1' % name] = test_reduction[:, 0]\n    test_df['%s_c2' % name] = test_reduction[:, 1]\n    test_df['%s_c3' % name] = test_reduction[:, 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"acddfd09765f5755743fe43c5f5f4801e4c4202a"},"cell_type":"code","source":"train_df['label'] = train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"406f77e845e04281ad917f7394163eacc31cbe3d"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\ncmap = plt.get_cmap('tab10', 4)\n\nfor method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n    fig = plt.figure(figsize = (8, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    p = ax.scatter(train_df['%s_c1' % name], train_df['%s_c2'  % name], train_df['%s_c3'  % name], c = train_df['label'].astype(int), cmap = cmap)\n    plt.title(f'{name.capitalize()}')\n    fig.colorbar(p, aspect = 4, ticks = [1, 2, 3, 4])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd636cf78c5faec5e397c15b2e816b1c9055db4a"},"cell_type":"code","source":"test_comp = pd.read_csv('../input/costa-rican-household-poverty-prediction/test.csv')\nsubmission_base = test_comp.loc[:, ['idhogar', 'Id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ba7af7e60b1519b047aa08fc0b79f4449ff42c2c"},"cell_type":"code","source":"def macro_f1_score(labels, predictions):\n    # Reshape the predictions as needed\n    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n    \n    metric_value = f1_score(labels, predictions, average = 'macro')\n    \n    # Return is name, value, is_higher_better\n    return 'macro_f1', metric_value, True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"911336fd8ae83e6c63958d3e95c16b99eb418456"},"cell_type":"code","source":"def model_gbm(features, labels, test_features, test_ids, nfolds = 5, return_preds = False):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n    \n    feature_names = list(features.columns)\n    \n    # Model with hyperparameters selected from previous work\n    model = lgb.LGBMClassifier(boosting_type = 'gbdt', n_estimators = 10000, max_depth = -1,\n                               learning_rate = 0.025, metric = 'None', min_child_samples = 30,\n                               reg_alpha = 0.35, reg_lambda = 0.6, num_leaves = 15, \n                               colsample_bytree = 0.85, objective = 'multiclass', \n                               class_weight = 'balanced', \n                               n_jobs = -1)\n    \n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n    predictions = pd.DataFrame()\n    importances = np.zeros(len(feature_names))\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    test_features = np.array(test_features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    \n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        # Dataframe for \n        fold_predictions = pd.DataFrame()\n        \n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds = 100, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 200)\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        \n        # Make predictions from the fold\n        fold_probabilitites = model.predict_proba(test_features)\n        \n        # Record each prediction for each class as a column\n        for j in range(4):\n            fold_predictions[(j + 1)] = fold_probabilitites[:, j]\n            \n        fold_predictions['idhogar'] = test_ids\n        fold_predictions['fold'] = (i+1)\n        predictions = predictions.append(fold_predictions)\n        \n        importances += model.feature_importances_ / nfolds    \n\n    feature_importances = pd.DataFrame({'feature': feature_names,\n                                        'importance': importances})\n    valid_scores = np.array(valid_scores)\n    print(f'{nfolds} cross validation score: {round(valid_scores.mean(), 5)} with std: {round(valid_scores.std(), 5)}.')\n    \n    # If we want to examine predictions don't average over folds\n    if return_preds:\n        predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n        predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n        return predictions, feature_importances\n    \n    # Average the predictions over folds\n    predictions = predictions.groupby('idhogar', as_index = False).mean()\n    \n    # Find the class and associated probability\n    predictions['Target'] = predictions[[1, 2, 3, 4]].idxmax(axis = 1)\n    predictions['confidence'] = predictions[[1, 2, 3, 4]].max(axis = 1)\n    predictions = predictions.drop(columns = ['fold'])\n    \n    # Merge with the base to have one prediction for each individual\n    submission = submission_base.merge(predictions[['idhogar', 'Target']], \n                                       on = 'idhogar', how = 'left').drop(columns = ['idhogar'])\n        \n    submission['Target'] = submission['Target'].fillna(4).astype(np.int8)\n    \n    # return the submission and feature importances\n    return submission, feature_importances, valid_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91092bb49f903f4ff425d009a387aac46b8310af"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"384adcd6ca4327fdbd96ec7c28ab9d8983c27065","collapsed":true},"cell_type":"code","source":"for col in train_df:\n    if 'Target' in col:\n        print(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4751d0e7d66050f30521853b633f5ed322b58659"},"cell_type":"code","source":"predictions, fi = model_gbm(train_df.drop(columns = 'label'), train_labels, \n                                   test_df, test_ids, return_preds = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c15e6524c3f315bab0a137dc85a20b6649430860"},"cell_type":"code","source":"fi.sort_values('importance').dropna().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b013e46c0612522f05a7ad7ff01ebd3e5aa319ca"},"cell_type":"code","source":"submission, fi, scores = model_gbm(train_df.drop(columns = 'label'), train_labels, \n                                   test_df, test_ids, return_preds = False)\n\nsubmission.to_csv('dimension_reduction.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36f0a25acc77267c47406a0cb5de1b1bd42343db"},"cell_type":"code","source":"fi.sort_values('importance').dropna().tail(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67ae09ed945b6edddb2b86d81ee44b1e97f26099"},"cell_type":"code","source":"scores.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd84a82e47f725a14caf0c6196d6c0ac42f8e8d4"},"cell_type":"code","source":"scores.std()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b458369ee1751db137b480f4430d02431f3f904f"},"cell_type":"markdown","source":"# Try without giving labels"},{"metadata":{"trusted":true,"_uuid":"e2031bd6fd42e355931c4fbd549e6fa30cd70c4f"},"cell_type":"code","source":"for method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n    start = timer()\n    reduction = method.fit_transform(train)\n    test_reduction = method.transform(test)\n    end = timer()\n    print(f'Method: {name} {round(end - start, 2)} seconds elapsed.')\n    train_df['%s_c1' % name] = reduction[:, 0]\n    train_df['%s_c2' % name] = reduction[:, 1]\n    train_df['%s_c3' % name] = reduction[:, 2]\n    \n    test_df['%s_c1' % name] = test_reduction[:, 0]\n    test_df['%s_c2' % name] = test_reduction[:, 1]\n    test_df['%s_c3' % name] = test_reduction[:, 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f966d20067761f271e71e82085293e731d396eb"},"cell_type":"code","source":"cmap = plt.get_cmap('tab10', 4)\n\nfor method, name in zip([umap, pca, ica], ['umap', 'pca', 'ica']):\n    fig = plt.figure(figsize = (8, 8))\n    ax = fig.add_subplot(111, projection='3d')\n    p = ax.scatter(train_df['%s_c1' % name], train_df['%s_c2'  % name], train_df['%s_c3'  % name], c = train_df['label'].astype(int), cmap = cmap)\n    plt.title(f'{name.capitalize()}')\n    fig.colorbar(p, aspect = 4, ticks = [1, 2, 3, 4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8d9454b2a707bc7d7dd011a3674e9c8b16789de"},"cell_type":"code","source":"submission, fi, scores = model_gbm(train_df.drop(columns = 'label'), train_labels, \n                                   test_df, test_ids, return_preds = False)\n\nsubmission.to_csv('dimension_reduction_nolabels.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7cac8fc5cd6e2bb5ce192716416886154d1a045"},"cell_type":"code","source":"fi.sort_values('importance').dropna().tail(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6b68269ea087c7678d57aaa0ccf64dee8ba99d85"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}