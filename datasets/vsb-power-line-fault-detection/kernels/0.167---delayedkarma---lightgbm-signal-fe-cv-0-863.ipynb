{"cells":[{"metadata":{"_uuid":"1c4dffdfb559f4a85b3662b83bc9a58e101ac171"},"cell_type":"markdown","source":"### Inspired by my own kernel (https://www.kaggle.com/delayedkarma/lightgbm-cv) and leo's https://www.kaggle.com/bluexleoxgreen/simple-feature-lightgbm-baseline"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\n\nimport random\nrandom.seed(42) # The answer\n \nimport os\nimport sys\nimport gc\nimport re\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm import tqdm\n\nimport lightgbm as lgb\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedKFold\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bfdb7071cfcde506f3b0c997c236267efc562ce"},"cell_type":"code","source":"meta_train = pd.read_csv('../input/metadata_train.csv')\nlen(meta_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f8c373c784a2d265c40ab03da5ea066a9551773"},"cell_type":"code","source":"meta_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0fcb9a5677eb0546d16ab1c4671b4785bf567ee"},"cell_type":"code","source":"%%time\nsubset_train = pq.read_pandas('../input/train.parquet', columns=[str(i) for i in range(len(meta_train))]).to_pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b410811f00351d5c26bf0b8d10608869e1f4aa5"},"cell_type":"code","source":"%%time\ntrain_length = 8712 \npositive_length = len(meta_train[meta_train['target']==1])\ntrain_df = pd.DataFrame()\nrow_index = 0\n\nfor i in range(train_length):\n    # downsampling\n    if meta_train.loc[i,'target'] == 1 or random.random() < positive_length / train_length:\n        subset_train_row = subset_train[str(i)]\n        train_df.loc[row_index, 'signal_min'] = np.min(subset_train_row)\n        train_df.loc[row_index, 'signal_max'] = np.max(subset_train_row)\n        train_df.loc[row_index, 'signal_mean'] = np.mean(subset_train_row)\n        train_df.loc[row_index, 'signal_mean_sq'] = np.mean(subset_train_row)**2\n        train_df.loc[row_index, 'signal_max_min_diff'] = np.subtract(np.max(subset_train_row),np.min(subset_train_row))\n#         train_df.loc[row_index, 'signal_median'] = np.median(subset_train_row)\n#         train_df.loc[row_index, 'signal_ptp'] = np.ptp(subset_train_row)\n        \n        train_df.loc[row_index, 'signal_id'] = i\n        row_index += 1\n        \nprint(\"positive length: \" + str(positive_length))\n\nprint(\"train length: \" + str(len(train_df)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48ff31e2df159076239f2ec5e9709b1bfabd3025"},"cell_type":"code","source":"train_df = pd.merge(train_df, meta_train, on='signal_id')\ntrain_df.to_csv(\"train.csv\", index=False)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f053ee8a0f2302debefac9ccf73cc68183968c6"},"cell_type":"code","source":"train_df.drop(['id_measurement'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c2454ede0cce661826326fee72f6fcf07a715cd"},"cell_type":"code","source":"x_train = train_df\ntarget = x_train['target']\ninput_target = x_train['target']\nx_train.drop('target', axis=1, inplace=True)\nx_train.drop('signal_id', axis=1, inplace=True)\nfeatures = x_train.columns\nparam = {'num_leaves': 80,\n         'min_data_in_leaf': 60, \n         'objective':'binary',\n         'max_depth': -1,\n         'learning_rate': 0.05,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.8,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.8 ,\n         \"bagging_seed\": 42,\n         \"metric\": 'auc',\n         \"lambda_l1\": 0.1,\n         \"verbosity\": -1}\nmax_iter=5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34d34a0f625d0d0c6120d52bbe5f9af88cf532a6"},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\noof = np.zeros(len(x_train))\nfeature_importance_df = pd.DataFrame()\nscore = [0 for _ in range(folds.n_splits)]\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, target.values)):\n    print(\"Fold No.{}\".format(fold_+1))\n    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n                           label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n                           label=target.iloc[val_idx])\n    num_round = 10000\n    clf = lgb.train(param,\n                    trn_data,\n                    num_round,\n                    valid_sets = [trn_data, val_data],\n                    verbose_eval=100,\n                    early_stopping_rounds = 200)\n    \n    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = features\n    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n    if fold_ == max_iter - 1: break\nif (folds.n_splits == max_iter):\n    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\nelse:\n     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e6a099db46983bc825c3d774e8ee697725ea4a2"},"cell_type":"code","source":"cols = (feature_importance_df[[\"feature\", \"importance\"]]\n        .groupby(\"feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:1000].index)\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n\nplt.figure(figsize=(10,10))\nsns.barplot(x=\"importance\",\n            y=\"feature\",\n            data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1d076cb1222959c7318da8b53baafc749230a04"},"cell_type":"code","source":" gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ddceba3adc3ca1b3d4ac788b23b64669d1641aa"},"cell_type":"code","source":"%%time\nmeta_test = pd.read_csv('../input/metadata_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30c2a23e0183f1214ac42a11e1ec8ad792ead919"},"cell_type":"code","source":"%%time\ntest_df = pd.DataFrame()\nrow_index = 0\nfor i in range(10):\n    subset_test = pq.read_pandas('../input/test.parquet', columns=[str(i*2000 + j + 8712) for j in range(2000)]).to_pandas()\n    for j in range(2000):\n        subset_test_row = subset_test[str(i*2000 + j + 8712)]\n        test_df.loc[row_index, 'signal_min'] = np.mean(subset_test_row)\n        test_df.loc[row_index, 'signal_max'] = np.max(subset_test_row)\n        test_df.loc[row_index, 'signal_mean'] = np.mean(subset_test_row)\n        test_df.loc[row_index, 'signal_mean_sq'] = np.mean(subset_test_row)**2\n        test_df.loc[row_index, 'signal_max_min_diff'] = np.subtract(np.max(subset_test_row),np.min(subset_test_row))\n#         test_df.loc[row_index, 'signal_median'] = np.median(subset_test_row)\n#         test_df.loc[row_index, 'signal_ptp'] = np.ptp(subset_test_row)\n        test_df.loc[row_index, 'signal_id'] = i*2000 + j + 8712\n        row_index += 1\nsubset_test = pq.read_pandas('../input/test.parquet', columns=[str(i + 28712) for i in range(337)]).to_pandas()\nfor i in tqdm(range(337)):\n    subset_test_row = subset_test[str(i + 28712)]\n    test_df.loc[row_index, 'signal_min'] = np.min(subset_test_row)\n    test_df.loc[row_index, 'signal_max'] = np.max(subset_test_row)\n    test_df.loc[row_index, 'signal_mean'] = np.mean(subset_test_row)\n    test_df.loc[row_index, 'signal_mean_sq'] = np.mean(subset_test_row)**2\n    test_df.loc[row_index, 'signal_max_min_diff'] = np.subtract(np.max(subset_test_row),np.min(subset_test_row))\n#     test_df.loc[row_index, 'signal_median'] = np.median(subset_test_row)\n#     test_df.loc[row_index, 'signal_ptp'] = np.ptp(subset_test_row)\n    test_df.loc[row_index, 'signal_id'] = i + 28712\n    row_index += 1\ntest_df = pd.merge(test_df, meta_test, on='signal_id')\ntest_df.to_csv(\"test.csv\", index=False)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf4aa06f4d69c4ed2446f70d26cd3c51b32189b9"},"cell_type":"code","source":"test_df.drop(['id_measurement'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e90f923755d9b1a259b0764d752aa84241f8966f"},"cell_type":"code","source":"x_test = test_df\nx_filename = x_test['signal_id']\nx_test = x_test.drop('signal_id', axis=1)\n\npredictions = clf.predict(x_test, num_iteration=clf.best_iteration)\n\nsub_df = pd.DataFrame({\"signal_id\":x_filename.values})\nsub_df[\"target\"] = pd.Series(predictions).round()\nsub_df['signal_id'] = sub_df['signal_id'].astype(np.int64)\nsub_df['target'] = sub_df['target'].astype(np.int64)\nsub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10d1b0d36a809627eda33e3c8ffc8504d534dbce"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}