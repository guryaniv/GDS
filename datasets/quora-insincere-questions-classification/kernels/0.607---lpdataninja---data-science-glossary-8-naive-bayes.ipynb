{"cells":[{"metadata":{"_uuid":"b727d07290a04d9de10463629ffb8a8ac66ca423"},"cell_type":"markdown","source":"# Naive Bayes\n- In this kernel you will learn how to use Naive Bayes to solve a Classification problem."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB,ComplementNB,BernoulliNB\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"faec1c3c0d18e5f0f31dbe648960eb16db5a444e"},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b0b213fd2d3d89d0625d940f9caee74853c621f"},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08bdbd4b9c6ed67e6121f29f8932a01a3b56f421"},"cell_type":"code","source":"train_data['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39c379859004a1649bd74bb6c554dc857a237322"},"cell_type":"code","source":"# train_data['num_words'] = train_data['question_text'].apply(lambda x: len(str(x).split()) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d68e94c503819e676bd70561652a90feb6a069a3"},"cell_type":"markdown","source":"## Basic Logistic Regression "},{"metadata":{"trusted":true,"_uuid":"b2b2263fdb5a83117541eb8acbd90cb803142b55"},"cell_type":"code","source":"train_text = train_data['question_text']\ntest_text = test_data['question_text']\ntrain_target = train_data['target']\nall_text = train_text.append(test_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6983ea53027ef4ab124f4da34ee80e18118552f"},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer()\ntfidf_vectorizer.fit(all_text)\n\ncount_vectorizer = CountVectorizer()\ncount_vectorizer.fit(all_text)\n\ntrain_text_features_cv = count_vectorizer.transform(train_text)\ntest_text_features_cv = count_vectorizer.transform(test_text)\n\ntrain_text_features_tf = tfidf_vectorizer.transform(train_text)\ntest_text_features_tf = tfidf_vectorizer.transform(test_text)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bba8d82a07bb52f2d259075edb871b70845e370"},"cell_type":"code","source":"kfold = KFold(n_splits = 5, shuffle = True, random_state = 2018)\ntest_preds = 0\noof_preds = np.zeros([train_data.shape[0],])\n\nfor i, (train_idx,valid_idx) in enumerate(kfold.split(train_data)):\n    x_train, x_valid = train_text_features_tf[train_idx,:], train_text_features_tf[valid_idx,:]\n    y_train, y_valid = train_target[train_idx], train_target[valid_idx]\n    classifier = LogisticRegression()\n    print('fitting.......')\n    classifier.fit(x_train,y_train)\n    print('predicting......')\n    print('\\n')\n    oof_preds[valid_idx] = classifier.predict_proba(x_valid)[:,1]\n    test_preds += 0.2*classifier.predict_proba(test_text_features_tf)[:,1]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c4b90edcfd241fb7ce8f850c3c6a8de3f70fbb2"},"cell_type":"code","source":"pred_train = (oof_preds > .25).astype(np.int)\nf1_score(train_target, pred_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b50e4525a3656fed96543b6f02c93f3ec005e25"},"cell_type":"code","source":"submission1 = pd.DataFrame.from_dict({'qid': test_data['qid']})\nsubmission1['prediction'] = (test_preds>0.25).astype(np.int)\n# submission1.to_csv('logistic_submission.csv', index=False)\nsubmission1['prediction'] = (test_preds>0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4462c1ffc281296eab3a09efd5338ba9e4bff5e5"},"cell_type":"markdown","source":"## Naive Bayes"},{"metadata":{"trusted":true,"_uuid":"1f057d1cbff17dc71d7019128d9e2c8d65b66a4f"},"cell_type":"code","source":"kfold = KFold(n_splits = 5, shuffle = True, random_state = 2018)\ntest_preds1 = 0\noof_preds1 = np.zeros([train_data.shape[0],])\n\ntest_preds2 = 0\noof_preds2 = np.zeros([train_data.shape[0],])\n\nfor i, (train_idx,valid_idx) in enumerate(kfold.split(train_data)):\n    x_train, x_valid = train_text_features_cv[train_idx,:], train_text_features_cv[valid_idx,:]\n    y_train, y_valid = train_target[train_idx], train_target[valid_idx]\n    classifier1 = MultinomialNB()\n    classifier2 = BernoulliNB()\n    print('fitting.......')\n    classifier1.fit(x_train,y_train)\n    classifier2.fit(x_train,y_train)\n    print('predicting......')\n    print('\\n')\n    oof_preds1[valid_idx] = classifier1.predict_proba(x_valid)[:,1]\n    test_preds1 += 0.2*classifier1.predict_proba(test_text_features_cv)[:,1]\n    oof_preds2[valid_idx] = classifier2.predict_proba(x_valid)[:,1]\n    test_preds2 += 0.2*classifier2.predict_proba(test_text_features_cv)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"613a25fa72b6c9b370c2372b02b37407184cccb0"},"cell_type":"code","source":"pred_train = (oof_preds1 > .3).astype(np.int)\nf1_score(train_target, pred_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e566157e37363cf544ee8ca10d77fcb164a5a176"},"cell_type":"code","source":"pred_train = (oof_preds2 > .3).astype(np.int)\nf1_score(train_target, pred_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dd1cf2f4d3a18eaf7ea524d914fa44014d7475a"},"cell_type":"code","source":"submission2 = pd.DataFrame.from_dict({'qid': test_data['qid']})\nsubmission3 = pd.DataFrame.from_dict({'qid': test_data['qid']})\n\nsubmission2['prediction'] = (test_preds1>0.3).astype(np.int)\n# submission2.to_csv('multinomial_submission.csv', index=False)\nsubmission2['prediction'] = (test_preds1>0.3)\n\nsubmission3['prediction'] = (test_preds2>0.3).astype(np.int)\n# submission3.to_csv('bernoulli_submission.csv', index=False)\nsubmission3['prediction'] = (test_preds2>0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3a20a12aec947dffaa5fc275b317d163bc2d042"},"cell_type":"code","source":"submission_final = pd.DataFrame.from_dict({'qid':test_data['qid']})\nsubmission_final['prediction'] = ((0.6*submission1['prediction'] + 0.2*submission2['prediction'] + 0.2*submission3['prediction'])>0.4).astype(np.int)\nsubmission_final.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}