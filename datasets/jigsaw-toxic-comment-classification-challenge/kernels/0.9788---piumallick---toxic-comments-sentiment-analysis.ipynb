{"cells":[{"metadata":{"_cell_guid":"11ddec6e-0ddc-47c8-aaf7-b4e1b2842f9c","_uuid":"2015e68a1623f7b2bb4d64126fa1cc0c104c41a8"},"cell_type":"markdown","source":" **                                                                     TOXIC Comments : Sentiment Analysis                                            **","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b3d2b42c-13f8-4548-82a7-3df2c5d3d572","_uuid":"685abcf982624602079ba6a30e6bd97c59f89991"},"cell_type":"markdown","source":"**Brief Introduction**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a1e045a2-e718-4810-a08d-a23eaa666651","_uuid":"54958b42b5eb9b8258e9f3ace7a01fb89570679f"},"cell_type":"markdown","source":"It is very easy to hurt someone's sentiment on social media or forums, specially when it is anonymous. \n\nThe aim of this project, launched by Jigsaw, is to protect the harrassment of the people with the use of the best algorithm to detect and classify toxic comments from the datasets provided by them.\n\nThe goal of this Notebook is :\n\n* to draw insight from the dataset provided by Jigsaw\n* and then benchmarking the most commonly used algorithm for Natural Language Processing","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"3741db21-acfc-405e-badf-f8a9eaf6100f","_uuid":"a515ed3835660b6ccc404a9a55af6b7f49d4d5b9","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import linear_model\nfrom sklearn.metrics import log_loss\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ef21ff3b-3956-4d60-be63-b75a509056fb","_uuid":"8a6754ee4246287a00a4fedbc8cc47eaaf8d5720","collapsed":true,"trusted":true},"cell_type":"code","source":"#NLP tools\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud\nstopwords = nltk.corpus.stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9274de93-58a7-4318-b1ce-b372c64859e1","_uuid":"9613880250f7bdfbdbe15dec764949f721bb86b3","collapsed":true,"trusted":true},"cell_type":"code","source":"#Plot and image tools\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom matplotlib import gridspec\nimport seaborn as sns\nsns.set_style(\"dark\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56a1726e-c6eb-4e09-b4e4-2655566eac3d","_uuid":"9017a84e035558238adac90ba5cc1dfc4bd8b801","collapsed":true,"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dce7c091-d564-4fd5-9687-9c165cae9f76","_uuid":"9839662ad65e8bfb3dbf746b1823faa01a666b62","collapsed":true,"trusted":true},"cell_type":"code","source":"#Loading the Data\ntrain = pd.read_csv('../input/train.csv', error_bad_lines=False).fillna(' ')\ntest = pd.read_csv('../input/test.csv', error_bad_lines=False).fillna(' ')\nsubm = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b0a33686-366c-485f-8f19-9c3d429b7f20","_uuid":"caa3c8ddd1919660615e7dc19ac152ede7166b54","collapsed":true,"trusted":true},"cell_type":"code","source":"#A quick look at our training dataset\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"88cc974c-b048-4546-9016-4432be071427","_uuid":"6306a2912c58b638fdaa4c23d3208cd1a93849ad","collapsed":true,"trusted":true},"cell_type":"code","source":"# the size of our training dataset\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5e4ae54-874d-4eb4-a9fb-663d0da918fd","_uuid":"cc9116933bd79770389ad61136b03faa7fa227d5"},"cell_type":"markdown","source":"So, from the above dataset we can see that there are 6 categories of undesirable comments:\n\n1. Toxic\n2. Severe Toxic\n3. Obscene\n4. Threat\n5. Insult \n6. Identity hate","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"5c5a179f-4bea-4fd9-bec2-ae4954e277e7","_uuid":"fa772b526d1c35e9c9a2aae479476b739d332737"},"cell_type":"markdown","source":"**Finding more information on the data**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ce037cfb-e008-4026-801d-e89004a0ec4e","_uuid":"7294e4b13db481ba5c326248b7990975aa857c2b"},"cell_type":"markdown","source":"Total number of toxic comments:","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"a867acfe-d1b0-4ed8-95c0-a586fad700ff","_uuid":"9e9a7d089534778ddbdc6ff33bf17b7bbc8d3731","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(ngram_range=(1, 2),\n                             max_df=0.5,\n                             min_df=4,\n                             max_features=1000)\nvector_space_model = vectorizer.fit_transform(train['comment_text'].values.astype('U').tolist()) # converting the dtype object to unicode string \nn_comments = vector_space_model.shape[0]\nprint('%d Total Comments' % n_comments)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"db3304ce-ccf6-4877-81bb-8e4364d9b7f0","_uuid":"7dee520285c10b9ef0be3d5edf3d5de816827e84","collapsed":true,"trusted":true},"cell_type":"code","source":"training_set_size = int(n_comments * 0.33)\nX = vector_space_model[:training_set_size,:]\nZ = vector_space_model[training_set_size:vector_space_model.shape[0]-1,:]\nprint('%d comments for the estimation of the parameters and %d for the evaluation' % \n      (X.shape[0], Z.shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"81a57d69-2a32-4022-8c05-ea7f9d2b6c3b","_uuid":"89a159d974924898ed299ce19a6b86d12ba064be","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\n\nX = X.toarray()\nY = train['toxic'][:training_set_size]\nmodel = linear_model.BayesianRidge(verbose=True)\nmodel.fit(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a2ac3750-6672-452a-b742-293b05c4bbc2","_uuid":"ef86fbb1708e729615a3320a071493fc0b3d14e0","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import binarize\nfrom sklearn.metrics import confusion_matrix\n\nground_truth = train['toxic'][training_set_size:vector_space_model.shape[0]-1]\nprediction = model.predict(Z)\nprediction = binarize(prediction.reshape(-1, 1), 0.5)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0169e20-ed5b-431e-abe5-efcbbb536196","_uuid":"15e5ae4466e5f4ad1a5b68cb00b9bfe2cc225454","collapsed":true,"trusted":true},"cell_type":"code","source":"toxic_ids = [i for i, c in enumerate(prediction) if c == 1]\ntoxic_ids","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1f5393e6-75a0-4377-9cb5-8c434d0b0771","_uuid":"6524e7c3df182db5c31edf3902f399705a6127f0"},"cell_type":"markdown","source":"**Checking for sample toxic comments**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f86cc914-3554-48c6-bfe0-a6befcb1dded","_uuid":"63468aaa8022a5728ad60ac0f8d55e82644313a2","collapsed":true,"trusted":true},"cell_type":"code","source":"comment_id = toxic_ids[0]\nprint('Content of the comment: \\n%s\\n' % train['comment_text'][training_set_size+comment_id])\nprint('Is this comment \"toxic\" according to the model?\\n%s' % str(model.predict(Z[comment_id,:]) >0.5))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b86fce88-0cb8-4e0f-8732-a16081151a36","_uuid":"f45f0ef472b22a53fb0e16ad2e6e7814425abe30","collapsed":true,"trusted":true},"cell_type":"code","source":"comment_id = toxic_ids[1]\nprint('Content of the comment: \\n%s\\n' % train['comment_text'][training_set_size+comment_id])\nprint('Is this comment \"toxic\" according to the model?\\n%s' % str(model.predict(Z[comment_id,:]) >0.5))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f42ecee2-2e02-4ac9-8df9-1c61fd7fadbe","_uuid":"4307bba067b4fe741a67f296270f3c2b9ee29d4e","collapsed":true,"trusted":true},"cell_type":"code","source":"comment_id = toxic_ids[2]\nprint('Content of the comment: \\n%s\\n' % train['comment_text'][training_set_size+comment_id])\nprint('Is this comment \"toxic\" according to the model?\\n%s' % str(model.predict(Z[comment_id,:]) >0.5))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"35866e1d-6f90-4ac4-9bc2-ad840484475a","_uuid":"c779af47ce363408e7d917ca62f4f23c7fa86d87"},"cell_type":"markdown","source":"**Working on Clean Comments**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"27f6e901-6a4c-47fa-bd3b-6c32e0722f68","_uuid":"3aed5211fc7291515f3bdf45592d5ddabee3ac72"},"cell_type":"markdown","source":"Now, we will create a new column for \"clean\" comments. These comments  correspond to none of the 6 categories as stated above.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"9c60eab3-1c0d-4417-b5f2-19fcd72c4020","_uuid":"8f78f45ce1b6031f0b29026db8022c8cc7512da1","collapsed":true,"trusted":true},"cell_type":"code","source":"rowsums=train.iloc[:,2:].sum(axis=1)\ntrain['clean']=(rowsums==0)\ntrain['clean'].sum()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb23a05c-331a-45dc-a6cc-eb3506452301","_uuid":"bdd74957c601b80a9b0748c46cad74888fbabade"},"cell_type":"markdown","source":"**Bar Charts : Showcasing the categories of toxic comments**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"98e9a64e-92a5-4642-bc7c-11477dd8c7d8","_uuid":"866cf8bd208ca25ee32f0f2ad34d96291d893542","collapsed":true,"trusted":true},"cell_type":"code","source":"colors_list = [\"brownish green\", \"pine green\", \"ugly purple\",\n               \"blood\", \"deep blue\", \"brown\", \"azure\"]\n\npalette= sns.xkcd_palette(colors_list)\n\nx=train.iloc[:,2:].sum()\n\nplt.figure(figsize=(9,6))\nax= sns.barplot(x.index, x.values,palette=palette)\nplt.title(\"Number per Class\")\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Type ')\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 10, label, \n            ha='center', va='bottom')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50e92e03-0c65-4c21-8441-78ada32a3854","_uuid":"3c7fb7311be9031404ef7db6d2e3189aad95be80"},"cell_type":"markdown","source":"We have more than 1.4 lakhs clean comments. And, we can see that we have a very unbalanced dataset. Even non-clean comments are not equally reparted. This might be an issue whilel training the learning algorithms. This also means that if we predict 'clean' for each comment, our result will not be so bad in term of accuracy.\n\n","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"69a99b43-1825-46a1-82f9-4f8d00239f06","_uuid":"2edc700498db93cedeff2ad3849fd1d93071cff8","collapsed":true,"trusted":true},"cell_type":"code","source":"# A list that contains all the text data\ncomment_text_list = train.apply(lambda row : nltk.word_tokenize( row['comment_text']),axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fa3d0b3f-004c-4d55-8e4b-50cdc2724b6e","_uuid":"fd4664a53fbc603e00246b61f562eb701396a819","collapsed":true,"trusted":true},"cell_type":"code","source":"comment_text_list.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5080a2b9-20e1-48aa-a18b-69146b0ec779","_uuid":"628948e5f14cbca378ae35a7d65c454d9cb8f086"},"cell_type":"markdown","source":"**Odd Comments : Containing a high rate of punctuation symbols or capital letters**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"83a9bcfa-c603-4b85-8088-64fc70eadf7e","_uuid":"53464c0fa120d456238e0aed7093e1f82a715610","collapsed":true,"trusted":true},"cell_type":"code","source":"#An odd comment contains a high rate of punctuation symbols or capital letters\nrate_punctuation=0.7\nrate_capital=0.7\ndef odd_comment(comment):\n    punctuation_count=0\n    capital_letter_count=0\n    total_letter_count=0\n    for token in comment:\n        if token in list(string.punctuation):\n            punctuation_count+=1\n        capital_letter_count+=sum(1 for c in token if c.isupper())\n        total_letter_count+=len(token)\n    return((punctuation_count/len(comment))>=rate_punctuation or \n           (capital_letter_count/total_letter_count)>rate_capital)\n\nodd=comment_text_list.apply(odd_comment)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"181a579c-c145-42eb-b630-17555c734c44","_uuid":"e7cf87a28c467e53e2070c1b6f929f67fc400f80","collapsed":true,"trusted":true},"cell_type":"code","source":"odd_ones=odd[odd==True]\nodd_comments=train.loc[list(odd_ones.index)]\nodd_comments[odd_comments.clean==False].count()/len(odd_comments)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"355efb61-d989-4772-a7df-f75690f65f9a","_uuid":"b70a95a6ec38be5d726e03baf5be0194009594d3"},"cell_type":"markdown","source":"Hence, we could see that more than 65% of the so-called odd comments are not clean. It seems to be an interesting feature to add to the dataset. So, we will have to train a model for these specific odd comments that cannot be treated the same way as the normal or the clean ones. ","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"f60e0afd-de33-4fbb-8e32-35117a017c9a","_uuid":"368315b7631a5c84e4df74ff6e617f99a14e26d7"},"cell_type":"markdown","source":"**Bar Charts : Showcasing the categories of toxic comments based on Odd Comments**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"7cc74517-6e36-4663-b1a9-8784b21fb7f6","_uuid":"9797e4f6bcd6eb5bd208ece4711120c74407b269","collapsed":true,"trusted":true},"cell_type":"code","source":"colors_list = [\"brownish green\", \"pine green\", \"ugly purple\",\n               \"blood\", \"deep blue\", \"brown\", \"azure\"]\n\npalette= sns.xkcd_palette(colors_list)\n\nx=odd_comments.iloc[:,2:].sum()\n\n\nplt.figure(figsize=(9,6))\nax= sns.barplot(x.index, x.values, alpha=0.8, palette=palette)\nplt.title(\"Number per category\")\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.xlabel('Type ', fontsize=12)\n\nrects = ax.patches\nlabels = x.values\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ea515fb2-3b34-435e-81d2-95f663802694","_uuid":"de8fd40a79893bb62ea044c1766616ceb4df8ccd","collapsed":true,"trusted":true},"cell_type":"code","source":"# A quick check for empty comments\nempty_comments=train[train.comment_text==\"\"]\nempty_comments","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e50e7001-e7bd-406f-b2c5-381134bd4584","_uuid":"5fef4926f22e91ce1cfc73d5275df41b3dca5d6a","collapsed":true,"trusted":true},"cell_type":"code","source":"# A quick check for duplicated comments\nduplicate=train.comment_text.duplicated()\nduplicate[duplicate==True]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"baeb10b6-cd42-48a0-99a1-90cf40f7c1e4","_uuid":"256e504e00f7d11f977e9ddb1c8b474410f2d100","collapsed":true,"trusted":true},"cell_type":"code","source":"# Storing each categories of non clean comments in specific arrays\ntoxic=train[train.toxic==1]['comment_text'].values\nsevere_toxic=train[train.severe_toxic==1]['comment_text'].values\nobscene=train[train.obscene==1]['comment_text'].values\nthreat=train[train.threat==1]['comment_text'].values\ninsult=train[train.insult==1]['comment_text'].values\nidentity_hate=train[train.identity_hate==1]['comment_text'].values","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"68f8e0c3-f5fb-4ea1-9644-ec3d78b8361e","_uuid":"24a873aefd7f2ae4ca0850cae94c31ab3ce3d856"},"cell_type":"markdown","source":"**Exploring toxic data from WordCloud Patterns**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"b0fb97d9-babf-45ac-a068-ca9c409bec58","_uuid":"18ba9295947bc5ff64f1204b9a027475d3091a1d"},"cell_type":"markdown","source":"Wordclouds are a quick way to see which words are dominant in a text. Now, we will see that which words are the most dominated in toxic labeled comments.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"0d1521c9-5804-4ad4-8912-fffe84889a19","_uuid":"f1855b6df5d145ef00e6b9b0f451a239346d9de2","collapsed":true,"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\nplt.figure(figsize=(16,13))\nwc = WordCloud(background_color=\"black\", max_words=500, stopwords=stopwords, max_font_size= 60)\nwc.generate(\" \".join(toxic))\nplt.title(\"Wordlcloud Toxic Comments\", fontsize=30)\nplt.imshow(wc.recolor( colormap= 'Set1' , random_state=1), alpha=0.98)\nplt.axis('off')\nplt.savefig('Toxic_wc.png')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fba6af3b-ab94-4baa-8d97-641b470f6ea6","_uuid":"bf6858e3b7282846ca5c8bc1653f5ee33ccfd8fc","collapsed":true},"cell_type":"markdown","source":"It's time for some text processing now.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"0a62df8f-4222-4b67-8401-22e2bb2a868c","_uuid":"35da3b1e4a229407c7f8e425f27af61c95ad0ca1"},"cell_type":"markdown","source":"**Lemmatization**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"ad5663ac-d9fc-4038-ae9e-f489e4c61b5f","_uuid":"ec84d91be89b790725d2d6d6e0c141f235503c79"},"cell_type":"markdown","source":"<b>Lemmatization </b>usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n\nFor example : Lemmatization(drank)=drink\n\nWe would also be replacing apostrophe words like \"won't\" ==> will not, \"can't\"==> cannot., etc.\n\nSo, it's time to start with the <b>toxic category</b> :","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"886aed21-ff96-4e9e-977d-7a15e4350edb","_uuid":"0c0d0f22d14c43b3f5154c94235758ea94c54b62","collapsed":true,"trusted":true},"cell_type":"code","source":"replacement_patterns = [\n (r'won\\'t', 'will not'),\n (r'can\\'t', 'cannot'),\n (r'i\\'m', 'i am'),\n (r'ain\\'t', 'is not'),\n (r'(\\w+)\\'ll', '\\g<1> will'),\n (r'(\\w+)n\\'t', '\\g<1> not'),\n (r'(\\w+)\\'ve', '\\g<1> have'),\n (r'(\\w+)\\'s', '\\g<1> is'),\n (r'(\\w+)\\'re', '\\g<1> are'),\n (r'(\\w+)\\'d', '\\g<1> would')\n]\nclass RegexpReplacer(object):\n    def __init__(self, patterns=replacement_patterns):\n         self.patterns = [(re.compile(regex), repl) for (regex, repl) in\n         patterns]\n     \n    def replace(self, text):\n        s = text\n        for (pattern, repl) in self.patterns:\n             s = re.sub(pattern, repl, s)\n        return s","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"98514487-7d29-45d6-9b0b-9e556c1bb0ad","_uuid":"6a441672954abff136d9d4afe650b3b360193fe6","collapsed":true,"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmer = WordNetLemmatizer()\nstopwords = nltk.corpus.stopwords.words('english')\nfrom nltk.tokenize import TweetTokenizer\n#from replacers import RegexpReplacer\nreplacer = RegexpReplacer()\ntokenizer=TweetTokenizer()\n\ndef comment_process(category):\n    category_processed=[]\n    for i in range(category.shape[0]):\n        comment_list=tokenizer.tokenize(replacer.replace(category[i]))\n        comment_list_cleaned= [word for word in comment_list if ( word.lower() not in stopwords \n                              and word.lower() not in list(string.punctuation) )]\n        comment_list_lemmed=[lemmer.lemmatize(word, 'v') for word in comment_list_cleaned]\n        category_processed.extend(list(comment_list_lemmed))\n    return category_processed","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"acd5228a-8d38-4329-8613-2796afe64c6b","_uuid":"f59a484ea62eeb54a43f01f240063bc9c1b8db6e","collapsed":true,"trusted":true},"cell_type":"code","source":"toxic1=comment_process(toxic)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad37d37a-5b15-4a8d-a998-1d387337b61b","_uuid":"698a2a00e34dbcdd8e32e91dbd449592a4e6dc62","collapsed":true,"trusted":true},"cell_type":"code","source":"fd=nltk.FreqDist(word for word in toxic1)\n\nx=[fd.most_common(150)[i][0] for i in range(99)]\ny=[fd.most_common(150)[i][1] for i in range(99)]\n\npalette= sns.light_palette(\"crimson\",100,reverse=True)\nplt.figure(figsize=(45,15))\nax= sns.barplot(x, y, alpha=0.8,palette=palette)\n\nplt.title(\"Occurences per word in Toxic comments 1\", fontsize=40)\nplt.ylabel('Occurrences', fontsize=30)\nplt.xlabel(' Word ', fontsize=30)\n\n# Adding the text labels\nrects = ax.patches\nlabels = y\nfor rect, label in zip(rects, labels):\n    height = rect.get_height()\n    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n    plt.xticks(rotation=60, fontsize=18)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4c5a087b-b025-43ef-be61-9843d2d4748b","_uuid":"ad96306815d20ec7db12dba418c13b26c0ec015b"},"cell_type":"markdown","source":"The bar chart/plot can be opened in a new tab/window for a bigger and better view.\n\nFrom the above plot, we could see that some of the toxic words have lots of occurences which do not have any existance  in the first wordcloud. \nHence, using the word cloud library on unprocessed data in the first place might be misleading. \n\nSo, it seems that we have some more work to do on the data processing part.","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"8b28ecec-1d6f-4f0f-b518-0e041506a500","_uuid":"1cdeb06b4455a3b754819926cc0bcb722ef1dbd1","collapsed":true,"trusted":true},"cell_type":"code","source":"def wordcloud_plot(category, name) : \n    plt.figure(figsize=(20,15))\n    wc = WordCloud(background_color=\"black\", max_words=500, min_font_size=6 \n                 , stopwords=stopwords, max_font_size= 60)\n    wc.generate(\" \".join(category))\n    plt.title(\"Twitter Wordlcloud \" + name +  \" Comments\", fontsize=30)\n    # plt.imshow(wc.recolor( colormap= 'Pastel1_r' , random_state=17), alpha=0.98)\n    plt.imshow(wc.recolor( colormap= 'Set1' , random_state=21), alpha=0.98)\n    plt.axis('off')\n    plt.savefig(name+'_wc.png')\n    return(True)\n\nwordcloud_plot(toxic1,'Toxic')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"37f2e415-8d84-40ab-a47d-97e37a7eb25b","_uuid":"602ba6de0e5eba2e9e5429837110d320f726c431","collapsed":true,"trusted":true},"cell_type":"code","source":"severe_toxic1=comment_process(severe_toxic)\nobscene1=comment_process(obscene)\nthreat1=comment_process(threat)\ninsult1=comment_process(insult)\nidentity_hate1=comment_process(identity_hate)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"21d7ef53-59e8-442e-96b6-094a4bf8bb7b","_uuid":"785319d0c4dcd3b4a5b11b9fe7618cb371592be6","collapsed":true,"trusted":true},"cell_type":"code","source":"wordcloud_plot(severe_toxic1,'Severe_toxic')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b59cc270-c990-41f5-8834-20022a3f20ea","_uuid":"6c575ccdc5630dcb251764f6f379787f97f00c51","collapsed":true,"trusted":true},"cell_type":"code","source":"wordcloud_plot(obscene1,'Obscene')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d24ec6cf-1c53-43d7-bc63-cc15485d96cb","_uuid":"af279c3b25eeb960b1b8f5706af96fc48e884ab2","collapsed":true,"trusted":true},"cell_type":"code","source":"wordcloud_plot(threat1,'Threat')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8ef78268-00e9-4633-8ee8-1784d19c1e0b","_uuid":"4509ad20eb3120dd0dc893db7a4bc7fe40a1d974","collapsed":true,"trusted":true},"cell_type":"code","source":"wordcloud_plot(insult1,'Insult')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"831c2a63-48df-4e68-8a34-d84edf404216","_uuid":"007dee45c81aa4b5be715047886d924550b9941e","collapsed":true,"trusted":true},"cell_type":"code","source":"wordcloud_plot(identity_hate1,'Identity_Hate')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"57d0722d-899a-4748-ac51-089178672735","_uuid":"89b8c5f41762ad0a198fa984a1fff23cc88d72c2"},"cell_type":"markdown","source":"**Conclusion from the above wordcloud patterns**","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"1289aadc-9304-4a4f-aa14-e5bb05d4321c","_uuid":"70e436ce1f5528871dc28a08b7c2b2f25c013a7d"},"cell_type":"markdown","source":"Some categories(Wordcloud patterns) share the same vocabulary in terms of richness and word frequency, like Insult and Toxic categories. And some others, like Identity and Hate category, use specific words more frequently. ","outputs":[],"execution_count":null},{"metadata":{"_cell_guid":"d0feb0b0-bbad-42a5-96b5-3c4d6823bf34","_uuid":"aad92940890cf634973552fc6ef52a8e887fbdf3","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fa2f3533-b812-4f37-bd95-0167520a6ec6","_uuid":"11d9dd51b66bb5d73178562d4f2343a87a34820a","collapsed":true,"trusted":true},"cell_type":"code","source":"class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\ntrain_text = train['comment_text']\ntest_text = test['comment_text']\nall_text = pd.concat([train_text, test_text])\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 1),\n    max_features=20000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(train_text)\ntest_word_features = word_vectorizer.transform(test_text)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    ngram_range=(1, 4),\n    max_features=20000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(train_text)\ntest_char_features = char_vectorizer.transform(test_text)\n\ntrain_features = hstack([train_char_features, train_word_features])\ntest_features = hstack([test_char_features, test_word_features])\n\nscores = []\nsubmission = pd.DataFrame.from_dict({'id': test['id']})\nfor class_name in class_names:\n    train_target = train[class_name]\n    classifier = LogisticRegression(solver='sag')\n\n    cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n    scores.append(cv_score)\n    print('CV score for class {} is {}'.format(class_name, cv_score))\n\n    classifier.fit(train_features, train_target)\n    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n\nprint('Total CV score is {}'.format(np.mean(scores)))\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cf103776-26d2-46c1-bf98-e1b1d0dc837e","_uuid":"be2d1c94ea0930c150793d398ae4c5d5f4669fca","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}