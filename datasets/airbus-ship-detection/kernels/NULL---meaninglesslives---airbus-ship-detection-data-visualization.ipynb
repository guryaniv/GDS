{"cells":[{"metadata":{"_uuid":"18c735c4a3e7d53bbcd82dfd676240301cb075e0"},"cell_type":"markdown","source":"**<h2>Introduction**"},{"metadata":{"_uuid":"d30127c5abec33501bff60055ab83187a546a5c6"},"cell_type":"markdown","source":"In this notebook, I try to explore the Airbus Ship Detection Challenge data and get some sense of what types of features may be useful. This is work in progress, so i will keep updating it. I hope you find this helpful. Happy Kaggling :-)"},{"metadata":{"trusted":true,"_uuid":"f926376d1380568f248346353c42fcf599e6c0e6","_kg_hide-input":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom skimage.feature import canny\nfrom skimage.filters import sobel,threshold_otsu, threshold_niblack,threshold_sauvola\nfrom skimage.segmentation import felzenszwalb, slic, quickshift, watershed\nfrom skimage.segmentation import mark_boundaries\nfrom scipy import signal\n\nimport cv2\nfrom PIL import Image\nimport pdb\nfrom tqdm import tqdm\nimport seaborn as sns\nimport os \nfrom glob import glob\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8d19639fac647b9933ba36071a63ea26a638416"},"cell_type":"markdown","source":"<h2> Setting paths"},{"metadata":{"trusted":true,"_uuid":"f1a78c7e479a65719964c9536298f82afb969ebf","_kg_hide-input":true},"cell_type":"code","source":"INPUT_PATH = '../input'\nDATA_PATH = INPUT_PATH\nTRAIN_DATA = os.path.join(DATA_PATH, \"train\")\nTRAIN_MASKS_DATA = os.path.join(DATA_PATH, \"train/masks\")\nTEST_DATA = os.path.join(DATA_PATH, \"test\")\ndf = pd.read_csv(DATA_PATH+'/train_ship_segmentations.csv')\npath_train = '../input/train/'\npath_test = '../input/test/'\ntrain_ids = df.ImageId.values\ndf = df.set_index('ImageId')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62f821d9d4a7bf8530d6478f2a14f35919f44cc9"},"cell_type":"markdown","source":"<h2> Some utility functions"},{"metadata":{"trusted":true,"_uuid":"b9447b5a9c6369010e3f949ec741def0687a139a","_kg_hide-input":true},"cell_type":"code","source":"def get_filename(image_id, image_type):\n    check_dir = False\n    if \"Train\" == image_type:\n        data_path = TRAIN_DATA\n    elif \"mask\" in image_type:\n        data_path = TRAIN_MASKS_DATA\n    elif \"Test\" in image_type:\n        data_path = TEST_DATA\n    else:\n        raise Exception(\"Image type '%s' is not recognized\" % image_type)\n\n    if check_dir and not os.path.exists(data_path):\n        os.makedirs(data_path)\n\n    return os.path.join(data_path, \"{}\".format(image_id))\n\ndef get_image_data(image_id, image_type, **kwargs):\n    img = _get_image_data_opencv(image_id, image_type, **kwargs)\n    img = img.astype('uint8')\n    return img\n\ndef _get_image_data_opencv(image_id, image_type, **kwargs):\n    fname = get_filename(image_id, image_type)\n    img = cv2.imread(fname)\n    assert img is not None, \"Failed to read image : %s, %s\" % (image_id, image_type)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img\n\n# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape=(768, 768)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n\n# https://github.com/ternaus/TernausNet/blob/master/Example.ipynb\ndef mask_overlay(image, mask):\n    \"\"\"\n    Helper function to visualize mask\n    \"\"\"\n    mask = mask.astype(np.uint8)\n    weighted_sum = cv2.addWeighted(mask, 0.75, image, 0.5, 0.)\n    img = image.copy()\n    ind = mask[:, :, 1] > 0    \n    img[ind] = weighted_sum[ind]    \n    return img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"338497fc51d3a8876a67ff056faaa9de1f2e61b7"},"cell_type":"markdown","source":"<h2>**Plotting Images**"},{"metadata":{"_uuid":"fb586a4d1e99e575880aafcb3a04c683e95253ba"},"cell_type":"markdown","source":"Lets plot some random images from training set and then few more images with the mask overlayed on top of it."},{"metadata":{"trusted":true,"_uuid":"12a555948195593dde1bfaf38c48946e1c046ae3","_kg_hide-input":true},"cell_type":"code","source":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\nif df.index.name == 'ImageId':\n    df = df.reset_index()\nif df.index.name != 'ImageId':\n    df = df.set_index('ImageId')\n    \n_train_ids = list(train_ids)\nnp.random.shuffle(_train_ids)\n# _train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\nalpha = 0.3\n\n# m = int(np.ceil(len(_train_ids) * 1.0 / n))\nm = int(np.ceil(nImg * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    j = 0\n    while j < n:\n        counter += 1\n        all_masks = np.zeros((768, 768))\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        image_id = _train_ids[counter]\n        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n            continue\n        else:\n            j += 1\n        img = get_image_data(image_id, 'Train')\n        \n        try:\n            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n            for mask in img_masks:\n                all_masks += rle_decode(mask)\n            all_masks = np.expand_dims(all_masks,axis=2)\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n            \n            img_masked = mask_overlay(img, all_masks)\n            \n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n\n        except Exception as e:\n            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n            all_masks = np.expand_dims(all_masks,axis=2)*255\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n            \n            img_masked = mask_overlay(img, all_masks)        \n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n#             pdb.set_trace()\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n\n        \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:],cmap='seismic')\n    plt.title(\"Training dataset\")\n    \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training dataset: Lighter Color depicts ship\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"047aa6fe7ae4fd071a44878d8386235563165096"},"cell_type":"markdown","source":"<h3>Plotting Ship Count"},{"metadata":{"trusted":true,"_uuid":"391141f3290c383db2ebfb6e136824d93ac6cad2"},"cell_type":"code","source":"df = df.reset_index()\ndf['ship_count'] = df.groupby('ImageId')['ImageId'].transform('count')\ndf.loc[df['EncodedPixels'].isnull().values,'ship_count'] = 0  #see infocusp's comment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4446af7ccc322df5a06b56ecfa0e6cb6fba08e1c"},"cell_type":"code","source":"sns.set_style(\"white\")\nsns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\nsns.distplot(df['ship_count'],kde=False)\nplt.title('Ship Count Distribution in Train Set')\n\nprint(df['ship_count'].describe())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9bb024c87ee036619a3215a00fbe9df69725daf"},"cell_type":"markdown","source":"<h2>**Plotting Images: Based on Ship Count**"},{"metadata":{"_uuid":"397b7202a0106ee3e944124d2371e560bcc60ac9"},"cell_type":"markdown","source":"Let's plot some images having different ship counts and try to see if we are able to glean any differences. This way, we can get some sense of what we're looking at. The images are 768 x 768 pixels each with the mask (in lighter color) overlayed on top of it. "},{"metadata":{"trusted":true,"_uuid":"463cde8d66d9270f1bb9ce37d2522865955dd6e9"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f97b4278913da6c803137209d7fbf872b5356aa6"},"cell_type":"markdown","source":"<h2> Training Set Images with Ship Count 0 i.e. no ship"},{"metadata":{"trusted":true,"_uuid":"5914bed1386a5c1ada8e131b26f0e7b1e1643f9c","_kg_hide-input":false},"cell_type":"code","source":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\nif df.index.name == 'ImageId':\n    df = df.reset_index()\nif df.index.name != 'ImageId':\n    df = df.set_index('ImageId')\n    \n_train_ids = list(train_ids)\n# _train_ids = list(train_ids[idx])\nnp.random.shuffle(_train_ids)\n# _train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\nalpha = 0.4\n\n# m = int(np.ceil(len(_train_ids) * 1.0 / n))\nm = int(np.ceil(nImg * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    j = 0\n    while j < n:\n        counter += 1\n\n        all_masks = np.zeros((768, 768))\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        image_id = _train_ids[counter]\n        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n            j += 1            \n        else:\n            continue\n        img = get_image_data(image_id, 'Train')\n        img = cv2.resize(img, dsize=tile_size)\n        img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n        complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n\n    \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image[ys:ye,:,:])\n    plt.title(\"Training Set Ship Count 0 i.e. no ship\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db0cda6094b801e15ea39a4fbd9defd471c0b18b"},"cell_type":"markdown","source":"<h2> Training Set Images with Ship Count between 1 to 5"},{"metadata":{"trusted":true,"_uuid":"d9d0e4e1615fa710d5ecf8b79a80a8c874e61e6f","_kg_hide-input":true},"cell_type":"code","source":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\nidx = np.ravel(np.where((df['ship_count']<6) ) )\nif df.index.name == 'ImageId':\n    df = df.reset_index()\n_train_ids = list(df.loc[idx,'ImageId'])\nif df.index.name != 'ImageId':\n    df = df.set_index('ImageId')\n\nnp.random.shuffle(_train_ids)\n\ntile_size = (256, 256)\nn = 8\nalpha = 0.4\n\nm = int(np.ceil(nImg * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    j = 0\n    while j < n:\n        counter += 1\n        all_masks = np.zeros((768, 768))\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        image_id = _train_ids[counter]\n        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n            continue\n        else:\n            j += 1\n        img = get_image_data(image_id, 'Train')\n        \n        try:\n            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n            for mask in img_masks:\n                all_masks += rle_decode(mask)\n            all_masks = np.expand_dims(all_masks,axis=2)\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n            \n            img_masked = mask_overlay(img, all_masks)\n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n\n        except Exception as e:\n            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n            all_masks = np.expand_dims(all_masks,axis=2)*255\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n        \n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n            img_masked = mask_overlay(img, all_masks)\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n    \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Ship Count 1 to 5\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4482ec8bee847dd75b53e0be48cff362e0117d1"},"cell_type":"markdown","source":"<h2> Training Set Images with Ship Count 5 to 10"},{"metadata":{"trusted":true,"_uuid":"66e5add359a991ac2659f836be305c8a7d8dadd9","_kg_hide-input":true},"cell_type":"code","source":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\nidx = np.ravel(np.where((df['ship_count']<11) & (df['ship_count']>5)) )\nif df.index.name == 'ImageId':\n    df = df.reset_index()\n_train_ids = list(df.loc[idx,'ImageId'])\nif df.index.name != 'ImageId':\n    df = df.set_index('ImageId')\n\nnp.random.shuffle(_train_ids)\n\ntile_size = (256, 256)\nn = 8\nalpha = 0.4\n\nm = int(np.ceil(nImg * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    j = 0\n    while j < n:\n        counter += 1\n        all_masks = np.zeros((768, 768))\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        image_id = _train_ids[counter]\n        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n            continue\n        else:\n            j += 1\n        img = get_image_data(image_id, 'Train')\n        \n        try:\n            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n            for mask in img_masks:\n                all_masks += rle_decode(mask)\n            all_masks = np.expand_dims(all_masks,axis=2)\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n            \n            img_masked = mask_overlay(img, all_masks)\n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n\n        except Exception as e:\n            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n            all_masks = np.expand_dims(all_masks,axis=2)*255\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n        \n            img_masked = mask_overlay(img, all_masks)\n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n    \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Ship Count 5 to 10\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f4e82596ddabec29b9c5a62bc6533e2b9adb28a"},"cell_type":"markdown","source":"<h2>Training Set Images with Ship Count greater than 10"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2977babea3db6b65cb3a3942e136e18a4873101f"},"cell_type":"code","source":"nImg = 32  #no. of images that you want to display\nnp.random.seed(42)\nidx = np.ravel(np.where((df['ship_count']>10) ) )\nif df.index.name == 'ImageId':\n    df = df.reset_index()\n_train_ids = list(df.loc[idx,'ImageId'])\nif df.index.name != 'ImageId':\n    df = df.set_index('ImageId')\n# _train_ids = list(train_ids[idx])\nnp.random.shuffle(_train_ids)\n# _train_ids = _train_ids[:nImg]\ntile_size = (256, 256)\nn = 8\nalpha = 0.4\n\nm = int(np.ceil(nImg * 1.0 / n))\ncomplete_image = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\ncomplete_image_masked = np.zeros((m*(tile_size[0]+2), n*(tile_size[1]+2), 3), dtype=np.uint8)\n\ncounter = 0\nfor i in range(m):\n    ys = i*(tile_size[1] + 2)\n    ye = ys + tile_size[1]\n    j = 0\n    while j < n:\n        counter += 1\n        all_masks = np.zeros((768, 768))\n        xs = j*(tile_size[0] + 2)\n        xe = xs + tile_size[0]\n        image_id = _train_ids[counter]\n        if str(df.loc[image_id,'EncodedPixels'])==str(np.nan):\n            continue\n        else:\n            j += 1\n        img = get_image_data(image_id, 'Train')\n        \n        try:\n            img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n            for mask in img_masks:\n                all_masks += rle_decode(mask)\n            all_masks = np.expand_dims(all_masks,axis=2)\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')*255\n            \n            img_masked = mask_overlay(img, all_masks)\n#             img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n            \n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n#             pdb.set_trace()\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n            \n#             pdb.set_trace()\n        except Exception as e:\n#             print(e,counter)\n            all_masks = rle_decode(df.loc[image_id,'EncodedPixels'])\n            all_masks = np.expand_dims(all_masks,axis=2)*255\n            all_masks = np.repeat(all_masks,3,axis=2).astype('uint8')\n        \n            img_masked =  cv2.addWeighted(img, alpha, all_masks, 1 - alpha,0)\n    #         img_masked = cv2.bitwise_and(img, img, mask=all_masks)\n\n            img = cv2.resize(img, dsize=tile_size)\n            img_masked = cv2.resize(img_masked, dsize=tile_size)\n\n            img = cv2.putText(img, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image[ys:ye, xs:xe, :] = img[:,:,:]\n#             pdb.set_trace()\n\n            img_masked = cv2.putText(img_masked, image_id, (5,img.shape[0] - 5), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), thickness=2)\n            complete_image_masked[ys:ye, xs:xe, :] = img_masked[:,:,:]\n    \nm = complete_image.shape[0] / (tile_size[0] + 2)\nk = 8\nn = int(np.ceil(m / k))\nfor i in range(n):\n    plt.figure(figsize=(20, 20))\n    ys = i*(tile_size[0] + 2)*k\n    ye = min((i+1)*(tile_size[0] + 2)*k, complete_image.shape[0])\n    plt.imshow(complete_image_masked[ys:ye,:,:])\n    plt.title(\"Training Set Ship Count greater than 10\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1b6e6add8ac352017f60b2e9bf401355b8977d94","collapsed":true},"cell_type":"code","source":"# takes too long.. have to optimize it\n# # _train_ids = list(df_train.loc[count_idx[0],'id']+'.png')\n\n# idx = np.ravel(np.where((df['ship_count']<6) & (df['ship_count']>1)) )\n# if df.index.name == 'ImageId':\n#     df = df.reset_index()\n# _train_ids1 = list(df.loc[idx,'ImageId'])\n\n# idx = np.ravel(np.where((df['ship_count']<11) & (df['ship_count']>5)) )\n# _train_ids2 = list(df.loc[idx,'ImageId'])\n\n# idx = np.ravel(np.where((df['ship_count']>10) ) )\n# _train_ids3 = list(df.loc[idx,'ImageId'])\n# df = df.set_index('ImageId')\n\n# # takes a long time...\n# # mask_count1 = np.zeros((768, 768,len(_train_ids1)), dtype=np.float32)\n# # for n, id_ in tqdm(enumerate(_train_ids1), total=len(_train_ids1)):\n# #     image_id = _train_ids1[n]\n# #     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n# #     all_masks = np.zeros((768, 768))\n# #     for mask in img_masks:\n# #         all_masks += rle_decode(mask)\n# #     mask_count1[:,:,n] = (all_masks>0).astype('uint8')\n\n# # mean_mask_count1 = mask_count1.mean(axis=2)\n# # del mask_count1\n\n# mask_count2 = np.zeros((768, 768,len(_train_ids2)), dtype=np.float32)\n# for n, id_ in tqdm(enumerate(_train_ids2), total=len(_train_ids2)):\n#     image_id = _train_ids2[n]\n#     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n#     all_masks = np.zeros((768, 768))\n#     for mask in img_masks:\n#         all_masks += rle_decode(mask)\n#     mask_count2[:,:,n] = (all_masks>0).astype('uint8')\n\n# mean_mask_count2 = mask_count2.mean(axis=2)\n# del mask_count2\n\n# mask_count3 = np.zeros((768, 768,len(_train_ids3)), dtype=np.float32)\n# for n, id_ in tqdm(enumerate(_train_ids3), total=len(_train_ids3)):\n#     image_id = _train_ids3[n]\n#     img_masks = df.loc[image_id,'EncodedPixels'].tolist()\n#     all_masks = np.zeros((768, 768))\n#     for mask in img_masks:\n#         all_masks += rle_decode(mask)\n#     mask_count3[:,:,n] = (all_masks>0).astype('uint8')\n\n# mean_mask_count3 = mask_count3.mean(axis=2)\n# del mask_count3\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0a03afddb7f102138cb09d3e6e79989d2a851f21","collapsed":true},"cell_type":"code","source":"# fig = plt.figure(1,figsize=(30,15))\n\n# # ax = fig.add_subplot(1,3,1)\n# # ax.imshow(mean_mask_count1)\n# # ax.set_title(\"Ship Location for Count: 0 to 5\")\n\n# ax = fig.add_subplot(1,2,1)\n# ax.imshow(mean_mask_count2)\n# ax.set_title(\"Ship Location for Count: 5 to 10\")\n\n# ax = fig.add_subplot(1,2,2)\n# ax.imshow(mean_mask_count3)\n# ax.set_title(\"Ship Location for Count: 5 to 10\")\n\n# plt.suptitle('Mean Masks for different s',y=0.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"730aaf122a1e26e85f339dcd48d5cbe02f072529"},"cell_type":"markdown","source":"**<h2>Transforming the Images**"},{"metadata":{"_uuid":"3fc5f26b5732e9fde19373693f6f9020553e991f"},"cell_type":"markdown","source":"Let's try to transform the images in some way to enhance the contrast between the ship and the background."},{"metadata":{"_uuid":"2cc9558e03b0da2a6893182d5e9b72e591964117"},"cell_type":"markdown","source":"<h3>**Smoothing the Image**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b1fbefd0c66cbfbf2609a05eff6dbcd8aa40af28"},"cell_type":"code","source":"from skimage.filters import gaussian,laplace","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"63604095e13f6121891daff222e589dfc6680a3f"},"cell_type":"code","source":"_train_ids = list(train_ids)\nfig = plt.figure(1,figsize=(15,15))\nfor i in range(9):\n    image_id = _train_ids[np.random.randint(0,len(_train_ids))]\n    ax = fig.add_subplot(3,3,i+1)\n    img = get_image_data(image_id, 'Train')\n    img = gaussian(img)\n    img = cv2.resize(img, dsize=tile_size)\n    ax.imshow(img)\n    ax.set_title('Smoothed Image')\n    \nplt.show()\nplt.suptitle('Smoothed Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"729250fbe0ba64e10df5318655e70147e5e1b39d","collapsed":true},"cell_type":"code","source":"from skimage.feature import canny\nfrom skimage.filters import scharr\nfrom skimage import exposure\nfrom skimage.color.adapt_rgb import adapt_rgb, each_channel, hsv_value","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9decd70b744e36866a42fbc91f876fddd4be22a5","collapsed":true},"cell_type":"code","source":"@adapt_rgb(hsv_value)\ndef canny_hsv(image):\n    return canny(image)\n\n@adapt_rgb(hsv_value)\ndef scharr_hsv(image):\n    return scharr(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a27a8ccc5cad45f7479b825b698e105c3c8062ab"},"cell_type":"markdown","source":"<h2> Extracting some useful features"},{"metadata":{"trusted":true,"_uuid":"c871dc640f824a9e6f971ce92a3cee094f03c9f4"},"cell_type":"code","source":"# simple features that can be easily extracted and used for training deep networks\n# these features may be used along with original image\nnp.random.seed(13)\n# random.seed(12)\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=1.2)  #adjust this to change vertical and horiz. spacings..\nnImg = 5  #no. of images to process\nj = 0\nfor _ in range(nImg):\n    q = j+1\n    image_id = _train_ids[np.random.randint(0,len(_train_ids))]\n    ax = fig.add_subplot(3,3,i+1)\n    img = get_image_data(image_id, 'Train')\n    \n#     # Contrast stretching\n    p2, p98 = np.percentile(img, (2, 98))\n    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n    \n    # Equalization\n    img_eq = exposure.equalize_hist(img)\n\n    # Adaptive Equalization\n    img_adapteq = exposure.equalize_adapthist(img)\n    \n    edge_scharr = scharr_hsv(img)\n    edge_canny = canny_hsv(img)\n\n    \n    plt.subplot(nImg,8,q*8-7)\n    plt.imshow(img, cmap='binary')\n    plt.title('Original Image')\n    \n    plt.subplot(nImg,8,q*8-6)\n    plt.imshow(img, cmap='binary')\n    plt.title('Image Mask')\n    \n    plt.subplot(nImg,8,q*8-5)    \n    plt.imshow(img_rescale, cmap='binary')\n    plt.title('Contrast stretching')\n    \n    plt.subplot(nImg,8,q*8-4)\n    plt.imshow(img_eq, cmap='binary')\n    plt.title('Equalization')\n    \n    plt.subplot(nImg,8,q*8-3)\n    plt.imshow(img_adapteq, cmap='binary')\n    plt.title('Adaptive Equalization')\n    \n    plt.subplot(nImg,8,q*8-2)\n    plt.imshow(edge_scharr, cmap='binary')\n    plt.title('Scharr Edge Magnitude')\n    \n    plt.subplot(nImg,8,q*8-1)\n    plt.imshow(edge_canny, cmap='binary')\n    plt.title('Canny features')\n    j = j + 1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2154b1c5e56d5459e8d52c5a4d46e874faeab315"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}