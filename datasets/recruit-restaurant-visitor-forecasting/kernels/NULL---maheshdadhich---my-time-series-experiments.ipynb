{"cells": [{"source": ["# Recruit Restaurant Visitor Forecasting\n", "\n", "**Note** - This is my first time series experiment and I will be using LSTM. Let me know improvement areas in comments and upvote if you find it useful.\n", "\n", "# Preamble \n", "In this competition we are given data from Hot Pepper Gourmet ( which is similar website to Yelp) and AirREGI ( a reservation control and cash register system) and we hare supposed to predict visitors forecasting. e are supposed to use the reservations, visits, and other information from these sites to forecast future restaurant visitor totals on a given date. The training data covers the dates from 2016 until April 2017. The test set covers the last week of April and May of 2017. The test set is split based on time (the public fold coming first, the private fold following the public) and covers a chosen subset of the air restaurants. Let's dive in the data and see what we are given with and lets see what can be done.. \n"], "metadata": {"_uuid": "fc0ddc665e3035f63c213b37c8848de0942254ad", "_cell_guid": "8e2ac554-9cb3-41d7-bbe7-b645711a3452"}, "cell_type": "markdown"}, {"outputs": [], "source": ["import pandas as pd  #pandas for using dataframe and reading csv \n", "import numpy as np   #numpy for vector operations and basic maths \n", "import urllib        #for url stuff\n", "import re            #for processing regular expressions\n", "import datetime      #for datetime operations\n", "import calendar      #for calendar for datetime operations\n", "import time          #to get the system time\n", "import scipy         #for other dependancies\n", "from sklearn.cluster import KMeans # for doing K-means clustering\n", "from haversine import haversine # for calculating haversine distance\n", "import math          #for basic maths operations\n", "import seaborn as sns #for making plots\n", "import matplotlib.pyplot as plt # for plotting\n", "import os                # for os commands\n", "import nltk\n", "from nltk.corpus import stopwords\n", "import string\n", "import xgboost as xgb\n", "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn import ensemble, metrics, model_selection, naive_bayes"], "metadata": {"collapsed": true, "_uuid": "ee5bb07031edeec0a4145e673daff192d29a8465", "_cell_guid": "075a9374-8b68-4511-9edb-a561bbf02023"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["air_reserve = pd.read_csv(\"../input/air_reserve.csv\")\n", "air_store = pd.read_csv(\"../input/air_store_info.csv\")\n", "air = air_reserve.merge(air_store, on = 'air_store_id', how = 'left')\n", "air_visit = pd.read_csv(\"../input/air_visit_data.csv\")\n", "air = air.merge(air_visit, on = 'air_store_id', how = 'left')\n", "date_info = pd.read_csv(\"../input/date_info.csv\")\n", "air = air.merge(date_info, left_on='visit_date', right_on = 'calendar_date', how = 'left')\n", "# air.head()"], "metadata": {"collapsed": true, "_uuid": "9c0dbc986a352e3aae951f2f3f3ece79a172def9", "_cell_guid": "3d175e9b-cc29-4928-a5c2-229e384dfe15"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["hpg_reserve = pd.read_csv(\"../input/hpg_reserve.csv\")\n", "store_id_rel = pd.read_csv(\"../input/store_id_relation.csv\")\n", "hpg_store_info = pd.read_csv(\"../input/hpg_store_info.csv\")\n", "hpg = hpg_reserve.merge(hpg_store_info, on = 'hpg_store_id', how = 'left')\n", "hpg = hpg.merge(store_id_rel, on = 'hpg_store_id', how = 'left')\n", "#train = hpg.merge(air, on = 'air_store_id', how = 'left')\n", "#train.head()\n", "hpg.head()"], "metadata": {"_uuid": "d601cbe39e6ef4bf2c1e93d5ba10664c0a0351be", "_cell_guid": "826359a4-80d8-47b3-952e-653f52d91c4c"}, "execution_count": null, "cell_type": "code"}, {"source": ["## Data preparation\n", "As of now I am using only air file to predict the outputs, in next versions I will include the hpg file as well. By looking at the data in air file we are given information that we have to prepared to be fed to LSTM. We have to predict visitors for given id and date. "], "metadata": {"_uuid": "4e7f073266ce493e63f72c928ed0d7beabfef3ba", "_cell_guid": "88ed39de-4b54-44ad-8a70-6c4fa1d55e35"}, "cell_type": "markdown"}, {"outputs": [], "source": ["air.head()\n"], "metadata": {"_uuid": "b7742192402b44b677df998392c61646d418b035", "_cell_guid": "da93cc2e-4631-48bc-a4e7-5a7f11870c69"}, "execution_count": null, "cell_type": "code"}, {"source": ["# Visualization of restaurants \n", "Showing restaurants of most famous genres..."], "metadata": {"_uuid": "5a7ac63da318338379ba2c58514bddb12632d466", "_cell_guid": "6912a5a6-9e25-404b-b836-392df6fa61b1"}, "cell_type": "markdown"}, {"outputs": [], "source": ["genre_summary = pd.DataFrame(air.groupby('air_genre_name')['air_genre_name'].count())\n", "genre_summary.reset_index(drop = True)\n", "genre_summary = genre_summary.sort_values('air_genre_name', ascending = False)"], "metadata": {"_uuid": "7ee7bad5f0f2fbb631432660f972402f02e8a9d2", "_cell_guid": "a79ebc89-df10-4e2b-afab-748d3d518c2d"}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["import folium\n", "def show_fmaps(train_data, path=1):\n", "    \"\"\"function to generate map and add the pick up and drop coordinates\n", "    1. Path = 1 : Join pickup (blue) and drop(red) using a straight line\n", "    \"\"\"\n", "    full_data = train_data\n", "    summary_full_data = pd.DataFrame(full_data.groupby('air_genre_name')['air_store_id'].count())\n", "    summary_full_data.reset_index(inplace = True)\n", "    summary_full_data = summary_full_data.loc[summary_full_data['air_store_id']>70000]\n", "    map_1 = folium.Map(location=[35.767937, 139.982155], zoom_start=10,tiles='OpenStreetMap') # manually added centre\n", "    new_df = train_data.loc[train_data['air_genre_name'].isin(summary_full_data.air_genre_name.tolist())].sample(50)\n", "    new_df.reset_index(inplace = True, drop = True)\n", "    for i in range(new_df.shape[0]):\n", "        pick_long = new_df.loc[new_df.index ==i]['longitude'].values[0]\n", "        pick_lat = new_df.loc[new_df.index ==i]['latitude'].values[0]\n", "        #dest_long = new_df.loc[new_df.index ==i]['dropoff_longitude'].values[0]\n", "        #dest_lat = new_df.loc[new_df.index ==i]['dropoff_latitude'].values[0]\n", "        folium.Marker([pick_lat, pick_long]).add_to(map_1)\n", "        #folium.Marker([dest_lat, dest_long]).add_to(map_1)\n", "    return map_1"], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}, {"outputs": [], "source": ["osm = show_fmaps(air, path=1)\n", "osm"], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["**To Be continued... **"], "metadata": {}, "cell_type": "markdown"}, {"outputs": [], "source": [], "metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code"}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1}