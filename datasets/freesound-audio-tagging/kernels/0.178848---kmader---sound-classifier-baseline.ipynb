{"cells":[{"metadata":{"trusted":true,"_uuid":"da47cf37ddf9463ee0320709018e229d1f2fa76c"},"cell_type":"code","source":"batch_size = 32\nBASE_FILTER_COUNT = 16\nmax_steps = 10\nSAMPLING_RATE = 8000 # [4000, 8000, 16000, 22000]\ninput_length = SAMPLING_RATE*2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d42696d24681de355e32c2964ce1b748b0855810"},"cell_type":"code","source":"%matplotlib inline  \nimport numpy as np\nimport pandas as pd\nfrom keras import optimizers, losses, activations, models\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n    concatenate\nfrom numpy import random\nimport librosa\nimport numpy as np\nimport glob\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abe27024d5ef9ee89394dcd01f4561cb3453845b"},"cell_type":"code","source":"def audio_norm(data):\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)/(max_data-min_data+0.0001)\n    return data-0.5\n\ndef load_audio_file(file_path, input_length=input_length):\n    data = librosa.core.load(file_path, sr=SAMPLING_RATE)[0] #, sr=16000\n    if len(data)>input_length:\n        max_offset = len(data)-input_length\n        offset = np.random.randint(max_offset)\n        data = data[offset:(input_length+offset)]\n    else:\n        if input_length > len(data):\n            max_offset = input_length - len(data)\n            offset = np.random.randint(max_offset)\n        else:\n            offset = 0\n        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n    data = audio_norm(data)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aff02f930ecbc461353c67a9032360b0ed4d9119"},"cell_type":"code","source":"train_files = glob.glob(\"../input/audio_train/audio_train/*.wav\")\ntest_files = glob.glob(\"../input/audio_test/audio_test/*.wav\")\ntrain_labels = pd.read_csv(\"../input/train.csv\")\nprint(len(train_files), 'training', len(test_files), 'testing')\ntrain_labels.groupby(['label']).size().plot.bar()\ntrain_labels.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac426a0c2779ff103228913c36133cce2575885e"},"cell_type":"code","source":"file_to_label = {\"../input/audio_train/audio_train/{}\".format(k):v \n                 for k,v in zip(train_labels['fname'].values,\n                                train_labels['label'].values)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2d724618d1f5cabfeb86298ba69972bd997432f"},"cell_type":"markdown","source":"## Show a test signal"},{"metadata":{"trusted":true,"_uuid":"2e35d019c6b5cd59cbee02fc8c747b82634b880f"},"cell_type":"code","source":"data_base = load_audio_file(train_files[0])\nfig = plt.figure(figsize=(14, 8))\nplt.title('Raw wave : %s ' % (file_to_label[train_files[0]]))\nplt.ylabel('Amplitude')\nplt.xlabel('Time (s)')\nplt.plot(np.linspace(0, input_length/SAMPLING_RATE, input_length), data_base)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d487e3962039ddb162c7520c7a8d9268d72f3fa"},"cell_type":"code","source":"list_labels = sorted(list(set(train_labels['label'].values)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d7d561634e45cf37e35f1052d88a8173078c85f"},"cell_type":"code","source":"label_to_int = {k:v for v,k in enumerate(list_labels)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cf61066f60862e9805abafb912519c69b2c120c"},"cell_type":"code","source":"int_to_label = {v:k for k,v in label_to_int.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33435463aad696a589dbdcd3d0b3c6cbcea51657"},"cell_type":"code","source":"file_to_int = {k:label_to_int[v] for k,v in file_to_label.items()}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c11230c47d8062447adc0eaad660c540fd6bbc98"},"cell_type":"code","source":"from keras import layers\ndef create_model(n_filt, act_name = 'relu'):\n    if act_name=='relu':\n        act_fun = activations.relu\n    elif act_name=='leakyrelu':\n        act_fun = layers.LeakyReLU(0.3)\n    nclass = len(list_labels)\n    inp = Input(shape=(input_length, 1))\n    img_1 = Convolution1D(n_filt, kernel_size=9, activation=act_fun, padding=\"valid\")(inp)\n    img_1 = Convolution1D(n_filt, kernel_size=9, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=16)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(n_filt*2, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(n_filt*2, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=4)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(n_filt*4, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(n_filt*4, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=4)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(n_filt*16, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(n_filt*16, kernel_size=3, activation=act_fun, padding=\"valid\")(img_1)\n    img_1 = GlobalMaxPool1D()(img_1)\n    img_1 = Dropout(rate=0.2)(img_1)\n\n    dense_1 = Dense(n_filt*16, activation=act_fun)(img_1)\n    dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n\n    model = models.Model(inputs=inp, outputs=dense_1)\n    opt = optimizers.Adam(lr=1e-4)\n    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9c0473b0e15b3abcf14497f9efe5a2dcec75bb0"},"cell_type":"code","source":"def chunker(seq, size):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af179b71cb47c613b7f3cf3416a5dd6877274d65"},"cell_type":"code","source":"def train_generator(raw_list_files, batch_size=batch_size):\n    while True:\n        list_files = np.random.permutation(raw_list_files)\n        for batch_files in chunker(list_files, size=batch_size):\n            batch_data = [load_audio_file(fpath) for fpath in batch_files]\n            batch_data = np.array(batch_data)[:,:,np.newaxis]\n            batch_labels = [file_to_int[fpath] for fpath in batch_files]\n            batch_labels = np.array(batch_labels)\n            yield batch_data, batch_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5538c2dd7139606c7744581700d2289e56da292e"},"cell_type":"code","source":"tr_files, val_files = train_test_split(train_files, test_size=0.1, random_state=2018)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6db9c353d822c0ec1f3b7c76d0a477f81b3eb0f"},"cell_type":"code","source":"%%time\n# test the generator\n_tx, _ty = next(train_generator(tr_files))\nprint(_tx.shape, _ty.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51940f25c24cc29a71ad2addb439344c8cd4d72c"},"cell_type":"code","source":"model = create_model(BASE_FILTER_COUNT, 'relu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b130ece37b2afb4950e22e1ab9cf030f3a578d66"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nweight_path=\"{}_weights.best.hdf5\".format('simple_sound_model')\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df0d6f9ed3d667c83ffbf9665023b36e3d26ede4"},"cell_type":"code","source":"model.fit_generator(train_generator(tr_files), \n                    steps_per_epoch=min(len(tr_files)//batch_size, max_steps), \n                    epochs=50,\n                    validation_data=train_generator(val_files), \n                    validation_steps=min(len(val_files)//batch_size, max_steps),\n                    callbacks=callbacks_list,\n                    use_multiprocessing=True,\n                    workers=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32e8642a50854e907ee36111fdd72eb0ecd07033"},"cell_type":"code","source":"model.save(\"baseline_cnn.h5\")","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"71787d953933838626f108c92d33d03f3a75d1d5"},"cell_type":"markdown","source":"# Run Predictions on Test Data"},{"metadata":{"trusted":true,"_uuid":"9bfc5f2e1d6aea9597f42263453ec21a1d6ca62d"},"cell_type":"code","source":"list_preds = []\nfor batch_files in tqdm(chunker(test_files, size=batch_size), total=len(test_files)//batch_size ):\n    batch_data = [load_audio_file(fpath) for fpath in batch_files]\n    batch_data = np.array(batch_data)[:,:,np.newaxis]\n    preds = model.predict(batch_data).tolist()\n    list_preds += preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"476baa0a3c3a453939272803c99412c258a0576e"},"cell_type":"code","source":"array_preds = np.array(list_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a295825bc41a9b21016317850297dafef143810"},"cell_type":"code","source":"list_labels = np.array(list_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc0d0ac8010a457e99bccdfa66a8f008c6c98701"},"cell_type":"code","source":"top_3 = list_labels[np.argsort(-array_preds, axis=1)[:, :3]] #https://www.kaggle.com/inversion/freesound-starter-kernel\npred_labels = [' '.join(list(x)) for x in top_3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8b5c9594cf2555a3633adf341951ab96e0d5ec6"},"cell_type":"code","source":"df = pd.DataFrame(test_files, columns=[\"fname\"])\ndf['label'] = pred_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d67a88f61bcdca1891bc571e48c0d97e95d089e"},"cell_type":"code","source":"df['fname'] = df.fname.apply(lambda x: x.split(\"/\")[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"032745a10fb024fa362569b9892ebc35e636afa7"},"cell_type":"code","source":"df.to_csv(\"baseline.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58275343c759c923c31f28a70104b64f614259b0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}