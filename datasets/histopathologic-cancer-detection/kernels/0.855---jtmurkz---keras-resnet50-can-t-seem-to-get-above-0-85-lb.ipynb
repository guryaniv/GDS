{"cells":[{"metadata":{"_uuid":"8ff2f9de1d43b7e2c6d7e8e910913a67ebb0d475"},"cell_type":"markdown","source":"# Histopathologic Cancer Detection\n\nThis is my entry for the Kaggle playground competition on cancer detection. This is my second machine learning project and was motivated by my completion of Course 4 of the Deeplearning.ai specialisation on Coursera. After many tries I can't seen to get above 0.85 AUC and I'm not sure why.\n\nAfter recieving some help from some very kind people on the discussions I am going to try the following things: Resize the image to either 196x196 or 244x244, use ensemble learning and try some different architectures.\n\n"},{"metadata":{"trusted":true,"_uuid":"e028ae38502c4a4459355d33e079d7689c6f96d0"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom glob import glob \nimport matplotlib.pyplot as plt\n\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nfrom keras_preprocessing.image import ImageDataGenerator\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.layers import Conv2D, MaxPool2D\n\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a167e8a535edd325007febe644dc3b5875e5ec70"},"cell_type":"markdown","source":"## Processing the data"},{"metadata":{"_uuid":"3889a45e5fd543405d51683e5953fb108ac6a500"},"cell_type":"markdown","source":"Now it's time to import the data.\nWhat I want to do is:\n\n1. Load and display some positive and negative test examples\n2. Split the train data into train and dev sets"},{"metadata":{"trusted":true,"_uuid":"350a0d71785d3aa17772d495a3d799080399f72f"},"cell_type":"code","source":"path = \"../input/\" \nlabels = pd.read_csv(path + 'train_labels.csv')\ntrain_path = path + 'train/'\ntest_path = path + 'test/'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d2ba183604216f4f58470837e474edbf72e5ed8"},"cell_type":"markdown","source":"Create a dataframe which contains every training examples path, id and label:"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"18b7b8e894af8283799d8b11ee5fe6693a4d5221"},"cell_type":"code","source":"df = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))})\ndf['id'] = df.path.map(lambda x: ((x.split(\"n\")[2].split('.')[0])[1:]))\ndf = df.merge(labels, on = \"id\")\ndf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b955187f2e82207066107721423275d5a2c4756e"},"cell_type":"markdown","source":"Choose 4 random positve and negative examples, find their respective path then display them in a subplot:"},{"metadata":{"trusted":true,"_uuid":"1af05b00ea18b0281b8db8f05c84b9aec3d2b891"},"cell_type":"code","source":"def readImage(path):\n    # OpenCV reads the image in bgr format by default\n    bgr_img = cv2.imread(path)\n    # We flip it to rgb for visualization purposes\n    b,g,r = cv2.split(bgr_img)\n    rgb_img = cv2.merge([r,g,b])\n    return rgb_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89ae9498a74f1919e42e62b6f4f0ba23e97aa217"},"cell_type":"code","source":"positive_indices = list(np.where(df[\"label\"] == True)[0])\nnegative_indices = list(np.where(df[\"label\"] == False)[0])\nrand_pos_inds = random.sample(positive_indices, 4)\nrand_neg_inds = random.sample(negative_indices, 4)\n\nfig, ax = plt.subplots(2,4, figsize=(20,8))\nfig.suptitle('Histopathologic scans of lymph node sections',fontsize=20, fontweight='bold')\n\nfor i in range(0, 4):\n    ax[0,i].imshow(readImage(df.iloc[rand_pos_inds[i],0]))\n    ax[0,i].set_title(\"Positive Example\", fontweight='bold')\n    \n    ax[1,i].imshow(readImage(df.iloc[rand_neg_inds[i],0]))\n    ax[1,i].set_title(\"Negative Example\", fontweight='bold')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6aec2347b757e81761ec94caa8d89f35ab96af0"},"cell_type":"markdown","source":"# Train/Validation Split and Loading the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 196\nBATCH_SIZE = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"342a29282f3e38c1856937b74acdc31982918118"},"cell_type":"code","source":"test_list = os.listdir(test_path)\ntrain_list = os.listdir(train_path)\nprint(\"There are \" + str(len(train_list)) + \" training examples.\")\nprint(\"There are \" + str(len(test_list)) + \" test examples.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34a98be4485e3edf5fb085eb9282ad337f81bec2"},"cell_type":"markdown","source":"Going to split 20% of the training set into a validation set."},{"metadata":{"trusted":true,"_uuid":"fdd11fc9d5cdf331ccad0ee0baec066af7f81429"},"cell_type":"code","source":"df['label'] = df['label'].astype(str)\ntrain, valid = train_test_split(df, test_size=0.2, stratify = df['label'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88c10cdf4e33a9b4d0fad96bf05eeb28b0675981"},"cell_type":"code","source":"def crop_centre(image, crop_length):\n    original_size = image.shape[0]\n    centre = original_size // 2\n    lower_bound = centre - crop_length // 2 \n    upper_bound = centre + crop_length // 2\n    image = image[(lower_bound):(upper_bound),(lower_bound):(upper_bound)]\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6bef8f94cbe078da658cd9f39af33a2ee79f79e"},"cell_type":"code","source":"\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                  vertical_flip = True,\n                                  horizontal_flip = True,\n                                  rotation_range=90,\n                                  zoom_range=0.2, \n                                  width_shift_range=0.1,\n                                  height_shift_range=0.1,\n                                  shear_range=0.05,\n                                  channel_shift_range=0.1)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"adaeaf8dd2872dcf29d0905f70a80bd6221370b6"},"cell_type":"code","source":"\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = train, \n                                                    directory = None,\n                                                    x_col = 'path', \n                                                    y_col = 'label',\n                                                    target_size = (IMG_SIZE,IMG_SIZE),\n                                                    class_mode = \"binary\",\n                                                    batch_size=BATCH_SIZE,\n                                                    seed = 110318,\n                                                    shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d1061fd15cdc493e2cf7a3e8cf2a0e87081ebcf"},"cell_type":"code","source":"valid_generator = test_datagen.flow_from_dataframe(dataframe = valid,\n                                                   directory = None,\n                                                   x_col = 'path',\n                                                   y_col = 'label',\n                                                   target_size = (IMG_SIZE,IMG_SIZE),\n                                                   class_mode = 'binary',\n                                                   batch_size = BATCH_SIZE,\n                                                   shuffle = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2823f65e4d1a782a2503abe67999ac3282e9ce7"},"cell_type":"markdown","source":"## Creating the model"},{"metadata":{"trusted":true,"_uuid":"ae37e0b06806be46190ea940f78c697ec8ea879a"},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\n\ndropout_fc = 0.5\n\nconv_base = ResNet50(weights = 'imagenet', include_top = False, input_shape = (IMG_SIZE,IMG_SIZE,3))\n\nmy_model = Sequential()\n\nmy_model.add(conv_base)\nmy_model.add(Flatten())\nmy_model.add(Dense(256, use_bias=False))\nmy_model.add(BatchNormalization())\nmy_model.add(Activation(\"relu\"))\nmy_model.add(Dropout(dropout_fc))\nmy_model.add(Dense(1, activation = \"sigmoid\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"fa05e6c5f7f0f6bb1ac6532ab8a85e21ffe5258b"},"cell_type":"code","source":"my_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3f35f658bfee3ae5c28a0ce7e02c5b3d7f6c0f2"},"cell_type":"code","source":"conv_base.Trainable=True\n\nset_trainable=False\nfor layer in conv_base.layers:\n    if layer.name == 'res5a_branch2a':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4758de74e465c8339643eb303cbf92814c1b37d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbaebaa508beb5c08fca58cfe81229c1994a2310"},"cell_type":"code","source":"from keras import optimizers\nmy_model.compile(optimizers.Adam(0.001), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98783d7eb0b33810c14573c21726e109f2dae67b"},"cell_type":"code","source":"train_step_size = train_generator.n // train_generator.batch_size\nvalid_step_size = valid_generator.n // valid_generator.batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ad56b34ecc891b4c7038b94d169011725dee9fc"},"cell_type":"code","source":"earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose=2, restore_best_weights=True)\nreduce = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = my_model.fit_generator(train_generator,\n                                     steps_per_epoch = train_step_size,\n                                     epochs = 13,\n                                     validation_data = valid_generator,\n                                     validation_steps = valid_step_size,\n                                     callbacks = [reduce, earlystopper],\n                                     verbose = 2)\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97f6cfd9d1eb8a2d0255b4567b008e72fe39574f"},"cell_type":"markdown","source":"# Analysis\nNow that our model has been trained, it is time to plot some training graphs to see how our accuracies and losses varied over epochs."},{"metadata":{"trusted":true,"_uuid":"a3c0d4e6d5d75a88caf81243fb872781404c79a3"},"cell_type":"code","source":"epochs = [i for i in range(1, len(history.history['loss'])+1)]\n\nplt.plot(epochs, history.history['loss'], color='blue', label=\"training_loss\")\nplt.plot(epochs, history.history['val_loss'], color='red', label=\"validation_loss\")\nplt.legend(loc='best')\nplt.title('training')\nplt.xlabel('epoch')\nplt.savefig(\"training.png\", bbox_inches='tight')\nplt.show()\n\nplt.plot(epochs, history.history['acc'], color='blue', label=\"training_accuracy\")\nplt.plot(epochs, history.history['val_acc'], color='red',label=\"validation_accuracy\")\nplt.legend(loc='best')\nplt.title('validation')\nplt.xlabel('epoch')\nplt.savefig(\"validation.png\", bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96c5c295e3cde7c625c2e0a5fda45e103cdd71df"},"cell_type":"markdown","source":"ROC Plot"},{"metadata":{"trusted":true,"_uuid":"8c348e99651e82a3a971f87d5ede9f2beb46aae1"},"cell_type":"code","source":"roc_validation_generator = ImageDataGenerator(rescale=1./255).flow_from_dataframe(valid,\n                                                                                  x_col = 'path',\n                                                                                  y_col = 'label',\n                                                                                  target_size = (IMG_SIZE,IMG_SIZE),\n                                                                                  class_mode = 'binary',\n                                                                                  batch_size = BATCH_SIZE,\n                                                                                  shuffle = False)\npredictions = my_model.predict_generator(roc_validation_generator, steps=len(roc_validation_generator), verbose=2)\nfalse_positive_rate, true_positive_rate, threshold = roc_curve(roc_validation_generator.classes, predictions)\narea_under_curve = auc(false_positive_rate, true_positive_rate)\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(false_positive_rate, true_positive_rate, label='AUC = {:.3f}'.format(area_under_curve))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.savefig('ROC_PLOT.png', bbox_inches='tight')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfc786845ee3bb7af1be804f9495637fadcbc2e5"},"cell_type":"markdown","source":"Confusion Matrix:"},{"metadata":{"trusted":true,"_uuid":"b97ca14759d26fbb1fda0afaf387dbc6aae0199c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3eaa72e5cba254cf43af52547233f43eb016fbc9"},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true,"_uuid":"5f39ab9a0d4e5840e7af853d7b1b0a2812a67932"},"cell_type":"markdown","source":"After 15+ tries of getting my model to make a decent prediction, i'm doing no better than on my first attempt when i got 67 percent. This suggests to me that im doing something wrong when it comes to predicting. As my train and val accuracies are not random. I'm going to try and predict a single test image and go from there."},{"metadata":{"trusted":true,"_uuid":"8fdc51bac85542400e47a382b232551d7a5b9f35"},"cell_type":"code","source":"testdf = pd.DataFrame({'path': glob(os.path.join(test_path, '*.tif'))})\ntestdf['id'] = testdf.path.map(lambda x: (x.split(\"/\")[3].split('.')[0]))\ntestdf.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b67eedd3c1b658814f75f0f1be7d1e24ec2213b0"},"cell_type":"code","source":"tta_datagen = ImageDataGenerator(rescale=1./255, #Normalise\n                                 vertical_flip = True,\n                                 horizontal_flip = True,\n                                 rotation_range=90,\n                                 zoom_range=0.2, \n                                 width_shift_range=0.1,\n                                 height_shift_range=0.1,\n                                 shear_range=0.05,\n                                 channel_shift_range=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 10\nsubmission = pd.DataFrame()\nfor index in range(0, len(testdf)):\n    data_frame = pd.DataFrame({'path': testdf.iloc[index,0]}, index=[index])\n    data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[3].split('.')[0])\n    img_path = data_frame.iloc[0,0]\n    test_img = cv2.imread(img_path)\n    test_img = cv2.resize(test_img,(IMG_SIZE,IMG_SIZE))\n    test_img = np.expand_dims(test_img, axis = 0)  \n    predictionsTTA = []\n    for i in range(0, tta_steps):\n        preds = my_model.predict_generator(train_datagen.flow(test_img, batch_size=1, shuffle=False), steps = 1)\n        predictionsTTA.append(preds)\n  \n    prediction_entry = np.array(np.mean(predictionsTTA, axis=0))\n    data_frame['label'] = prediction_entry\n    submission = pd.concat([submission, data_frame[['id', 'label']]])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4544440fde361922da366240c31f6bec42e62e52"},"cell_type":"code","source":"submission.set_index('id')\nsubmission.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67b4c89e80f6b3fd7ad2c720803ca043aeac8490"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8b5425a6f5481951f7c1ca98dd82ab70aa6bd65"},"cell_type":"markdown","source":"# References\nHeavily inspired by these kernels:\n\n1. [https://www.kaggle.com/qitvision/a-complete-ml-pipeline-fast-ai](http://)\n\n2. [https://www.kaggle.com/fadhli/starter-code-keras-resnet50-0-9275-lb](http://)\n\n3. [https://www.kaggle.com/gomezp/complete-beginner-s-guide-eda-keras-lb-0-93](http://)\n\n4. [https://www.kaggle.com/greg115/histopathologic-cancer-detector-lb-0-958](http://)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}