{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers\nfrom keras.preprocessing import image\nfrom keras.models import Sequential,Model\nfrom keras.layers import Dense,Flatten,Input\nfrom keras.optimizers import SGD,RMSprop,Adagrad,Adadelta,Adam,Adamax,Nadam\nfrom keras.losses import mean_squared_error\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras.applications.imagenet_utils import preprocess_input\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nfrom keras.models import load_model\nimport pickle\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom PIL import Image\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70179cc2d129a3183cb81f111e7e8925996faeef"},"cell_type":"code","source":"def add_snow(img,factor):                      #Function to add snow\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    brightness_coef=2.5\n    snow_point=factor\n    image_HLS[:,:,1][image_HLS[:,:,1]<snow_point]= image_HLS[:,:,1][image_HLS[:,:,1]<snow_point]*brightness_coef\n    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_brightness(img,factor):               #Function to change brightness\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,1]=image_HLS[:,:,1]*factor\n    image_HLS[:,:,1][image_HLS[:,:,1]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_saturation(img,factor):           #Function to change saturation\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,2]=image_HLS[:,:,2]*factor\n    image_HLS[:,:,2][image_HLS[:,:,2]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef add_hue(img,factor):                 #Function to change hue\n    image_HLS=cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n    image_HLS=np.array(image_HLS,dtype=np.float64)\n    image_HLS[:,:,0]=image_HLS[:,:,0]*factor\n    image_HLS[:,:,0][image_HLS[:,:,0]>255]  = 255\n    image_HLS=np.array(image_HLS,dtype=np.uint8)\n    image_RGB=cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB)\n    return image_RGB\n\ndef generate_random_lines(imshape,slant,drop_length):\n    drops=[]\n    for i in range(1500): ## If You want heavy rain, try increasing this\n        if slant<0:\n            x= np.random.randint(slant,imshape[1])\n        else:\n            x= np.random.randint(0,imshape[1]-slant)\n        y= np.random.randint(0,imshape[0]-drop_length)\n        drops.append((x,y))\n    return drops\n        \n    \ndef add_rain(image):\n    \n    imshape = image.shape\n    slant_extreme=10\n    slant= np.random.randint(-slant_extreme,slant_extreme) \n    drop_length=20\n    drop_width=2\n    drop_color=(200,200,200) ## a shade of gray\n    rain_drops= generate_random_lines(imshape,slant,drop_length)\n    \n    for rain_drop in rain_drops:\n        cv2.line(image,(rain_drop[0],rain_drop[1]),(rain_drop[0]+slant,rain_drop[1]+drop_length),drop_color,drop_width)\n    image= cv2.blur(image,(7,7)) ## rainy view are blurry\n    \n    brightness_coefficient = 0.7 ## rainy days are usually shady \n    image_HLS = cv2.cvtColor(image,cv2.COLOR_RGB2HLS) ## Conversion to HLS\n    image_HLS[:,:,1] = image_HLS[:,:,1]*brightness_coefficient ## scale pixel values down for channel 1(Lightness)\n    image_RGB = cv2.cvtColor(image_HLS,cv2.COLOR_HLS2RGB) ## Conversion to RGB\n    return image_RGB\n\ndef flip(img):                #Function to return mirror image\n    return np.fliplr(img)\n\ndef resize(image):                        #Function to resize the image\n    image=image.resize((img_height,img_width),Image.ANTIALIAS)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0caf109a509ba5047548b10948b664da075af5d2"},"cell_type":"code","source":"def prepareImages(data, m, dataset):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, 100, 100, 3))\n    count = 0\n    \n    for fig in data['Image']:\n        #load images into images of size 100x100x3\n        img = image.load_img(\"../input/humpback-whale-identification/\"+dataset+\"/\"+fig, target_size=(100, 100, 3))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        X_train[count] = x\n        if (count%500 == 0):\n            print(\"Processing image: \", count+1, \", \", fig)\n        count += 1\n    \n    return X_train\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data_dir='../input/humpback-whale-identification/train'\ntest_data_dir='../input/humpback-whale-identification/test'\nimg_height,img_width=100,100\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"753909f3934dd59f1fc6ceb703c422a7cb4898ae","scrolled":true},"cell_type":"code","source":"train=pd.read_csv(train_data_dir+'.csv')\ntrain_md=pd.get_dummies(train,columns=['Id'])\ntrain_md.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d322fdd4110e2ea82c6e8d861ec316d5b176d4f9"},"cell_type":"code","source":"\ntrain_md=train_md[train_md.Id_new_whale!=1]\ntrain_md.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"447693046a114a34430b179982ffaba8b575708d"},"cell_type":"code","source":"train_md.dropna()\ntrain_md.drop(['Id_new_whale'],axis=1,inplace=True)\ntrain_md.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7585e53159945ea9927415653dd5f4bc9b3ca6da"},"cell_type":"code","source":"\ny=train_md.drop(train_md.columns[0],axis=1)\nnames=list(y.columns.values)\ny=np.array(y)\nX=prepareImages(train_md,train_md.shape[0],\"train\")\nX/=255\nX_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.1,random_state=2)\nX_train=X\ny_train=y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20a0f615c80b2decc9504730f68ed706bc3b4880"},"cell_type":"code","source":"print(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"110cd9ecfc6c5a3522c0ca51f7e28cce3e3f51cf"},"cell_type":"code","source":"model=applications.vgg16.VGG16(include_top=False,weights='imagenet',input_shape=(100,100,3),pooling='avg')\nfor layer in model.layers[:-5]:\n    layer.trainable=False\nprint(model.output.shape)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"370ea58d6b9403bc691258e54ad6e367d0f754c4"},"cell_type":"code","source":"x=model.output\nx=Dense(5004,activation='softmax')(x)\nmodel_final=Model(inputs=model.input,outputs=x)\ndel X\ndel y\ngc.collect()\nprint(model_final.output.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"595943782b7f411eb540d7ce8751e1a78d7653a9"},"cell_type":"code","source":"model_final.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(),metrics=['acc'])\nmodel_final.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43432938989d4f29a08b42ce7ccc0d0c69ef998d"},"cell_type":"markdown","source":"def read_and_process_image(image_dir):          #Read Images from directory and processes them\n    X=[]\n    for image in image_dir:\n        X.append(cv2.resize(cv2.imread(train_data_dir+'/'+image,cv2.IMREAD_COLOR),(img_height,img_width),interpolation=cv2.INTER_AREA))\n        #print(image)\n    return X    "},{"metadata":{"trusted":true,"_uuid":"fdda5b9be19848716efcd4aa65fcfb6703194528"},"cell_type":"code","source":"history=model_final.fit(X_train,y_train,epochs=20,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eec754ed49ddc2f350c0d891f10c19fc818260a6"},"cell_type":"code","source":"del X_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4113e5e00aa82fb3c267780e3ad050d5f39d4364"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4303ed75cc150a66dbb402e8c2efaca2bc7f5ca5"},"cell_type":"code","source":"X_list=np.array(train['Image'])\nprint(X_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc8614dfe103067c2967be08f92fe031c0ff5d2e"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),50))\n    \n  \nX=np.array(X)\nX=X/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a6c358316434382e66ea216d48d60a5617f545"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),100))\n    \nX=X/255   \nX=np.array(X)\nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81e4f0bb4cb7ba69e5f09aa8073e65e73deaf0fb"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_snow(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),150))\n    \nX=X/255    \nX=np.array(X)\nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9377ceae4da82106ed40730b123b856f19044b85"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n\nX=np.array(X)\nX=X/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82ffdf682f7037fdc2ab7f2021453c65c3c55288"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),1.25))\n    \n\nX=np.array(X)\nX=X/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eca2ccab7192f747c1f04b6a2612e8705bb9c1b1"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_brightness(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),1.75))\n    \n \nX=np.array(X)\nX=X/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e24bb0e7c590cee28f08d15e9e32ae8c11d6aab4"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_saturation(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n\nX=np.array(X)\nX=X/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d778735831ee54c3aafae8bd796c14cdb2498943"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_saturation(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),1.5))\n    \n\nX=np.array(X)\nX=X/255  \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d5b87ca085874a31da51911e03c33ca40d28eb1"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_hue(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),0.5))\n    \n \nX=np.array(X)\nX=X/255   \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99e3089137064edbc8b567c03b15a8afce5d385"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_hue(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width)),1.5))\n    \n\nX=np.array(X)\nX=X/255    \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a832e32a19c21600a7e6c3852fa59d40650b7ed9"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(add_rain(cv2.resize(cv2.imread(train_data_dir+\"/\"+X_list[i]),(img_height,img_width))))\n    \n   \nX=np.array(X)\nX=X/255 \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87a5c31eeeac753b921c5b8b3b16535c6d8d9dc7"},"cell_type":"code","source":"X=[]\nfor i in range(y_train.shape[0]):\n   \n    X.append(resize(flip(cv2.imread(train_data_dir+\"/\"+X_list[i]))))\n    \n\nX=np.array(X)\nX=X/255    \nhistory=model_final.fit(X,y_train,epochs=16,verbose=1,batch_size=64,validation_data=(X_val,y_val))\ndel X\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f7d0ca2bc681d6be88d8f39705679cf54bc0524"},"cell_type":"markdown","source":"X_train=read_and_process_image(X_train)\nX_train=np.array(X_train)\nX_val=read_and_process_image(X_val)\nX_val=np.array(X_val)"},{"metadata":{"trusted":true,"_uuid":"0e2d1dabbb30f77d7c22d486d65c3b6416eaf2bd"},"cell_type":"markdown","source":"print(X_train.shape)\nprint(y_train.shape)"},{"metadata":{"trusted":true,"_uuid":"fad0b1bac8218973d2d35311d4c9e98fcb1e74b1"},"cell_type":"markdown","source":"#plt.imshow(X[0])"},{"metadata":{"trusted":true,"_uuid":"de0d64fafaca00db8be2ce801000c2a428dd53eb"},"cell_type":"markdown","source":"val_generator=val_datagen.flow(X_val,y_val)"},{"metadata":{"trusted":true,"_uuid":"6023ff4d7f355451b7301614e6f387f39684453b"},"cell_type":"markdown","source":"for j in tqdm(range(64)):\n    for i in range(15):\n        train_generator=train_datagen.flow(X_train[i*1000:(i+1)*1000],y_train[i*1000:(i+1)*1000])\n        history=model_final.fit_generator(train_generator,steps_per_epoch=1000//32,epochs=1,validation_data=val_generator,validation_steps=1000//32)\n        del train_generator\n        gc.collect()\n\n    train_generator=train_datagen.flow(X_train[15000:15697],y_train[15000:15697])\n    history=model_final.fit_generator(train_generator,steps_per_epoch=100//32,epochs=1,validation_data=val_generator,validation_steps=1000//32)\n    del train_generator\n    gc.collect()"},{"metadata":{"trusted":true,"_uuid":"2625649b06a23d381d6bfc5d09a3ba87c04b1dc0"},"cell_type":"code","source":"model_final.save_weights('model1weights.h5')\nmodel_final.save('model1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"433959a903bdebe93ca687ebcff6fc09822e5ad3"},"cell_type":"markdown","source":"X_test=X_train[:10,:,:,:]\nmodel_final=load_model('model1.h5')\nmodel_final.load_weights('model1weights.h5')"},{"metadata":{"trusted":true,"_uuid":"3a7a92f288df1b24c86ef61d553c87540d938636"},"cell_type":"markdown","source":"arr=model_final.predict(X_train)"},{"metadata":{"trusted":true,"_uuid":"d9138e051b2b1007c02b63412980ac9ac6de5993"},"cell_type":"markdown","source":"\nprint(names[np.argmax(arr[0])])"},{"metadata":{"trusted":true,"_uuid":"36cb7517434057e8924eca4003ec5a71eada2112"},"cell_type":"markdown","source":"print(np.max(arr[0]))"},{"metadata":{"trusted":true,"_uuid":"2984c3169d966cb7f263b330cc02b4435d440639"},"cell_type":"markdown","source":"print(names[np.argmax(arr[2])])\nprint(np.max(arr[2]))"},{"metadata":{"trusted":true,"_uuid":"ef2cc843a5c7442446e5f9b7d13f6da406d8f1b4"},"cell_type":"markdown","source":"train_tt=pd.get_dummies(train,columns=['Id'])\nX=train_tt['Image']\nX=np.array(X)"},{"metadata":{"trusted":true,"_uuid":"2c100c7ca7028569c815c3714d57a808b2742803"},"cell_type":"markdown","source":"print(X.shape)"},{"metadata":{"trusted":true,"_uuid":"59d060c4423b5a65f7eb15463dfb00ac0d9547fe"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6324aff96babd7c547389a6bd825216c4314c345"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99de6c2491a203c0ad347e5dd2eb514baa0a23f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}