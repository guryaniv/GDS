{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a65dfcc-a871-8d5a-cc0f-3166a00fee4d"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "# load data\n",
        "\n",
        "data_train = pd.read_json('../input/train.json')\n",
        "data_test = pd.read_json('../input/test.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c5237e9-6655-8b92-1df5-ed7b25557df8"
      },
      "outputs": [],
      "source": [
        "# cluster the training lat longs to find 10 centroids\n",
        "\n",
        "latlong_X = pd.DataFrame()\n",
        "latlong_X['latitude'] = data_train.latitude.values\n",
        "latlong_X['longitude'] = data_train.longitude.values\n",
        "from sklearn.cluster import KMeans\n",
        "latlong_kmeans = KMeans(n_clusters=10, random_state=1234).fit(latlong_X)\n",
        "kmeans_centroids = latlong_kmeans.cluster_centers_\n",
        "\n",
        "print(kmeans_centroids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d9c9fd8-0856-3e87-dcc8-634d3f8d1e19"
      },
      "outputs": [],
      "source": [
        "# spare matrix of features\n",
        "\n",
        "features = data_train['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
        "features_sub = data_test['features'].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "feat_cv = CountVectorizer(stop_words='english', max_features=200)\n",
        "features_sparse = feat_cv.fit_transform(features)\n",
        "features_sparse_sub = feat_cv.transform(features_sub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d333081-54fb-ea7e-048d-94f593faff90"
      },
      "outputs": [],
      "source": [
        "# data prep function\n",
        "def prep_input(X, kmeans_centroids):\n",
        "    \n",
        "    X['longlat'] = X['longitude'] * X['latitude']\n",
        "    X['price2'] = X['price'] ** 2\n",
        "    X['price3'] = X['price'] ** 3\n",
        "    X['bedrooms2'] = X['bedrooms'] ** 2\n",
        "    X['bedrooms3'] = X['bedrooms'] ** 3\n",
        "    X['bathrooms2'] = X['bathrooms'] ** 2\n",
        "    X['bathrooms3'] = X['bathrooms'] ** 3\n",
        "    X['bedrooms+bathrooms'] = X['bedrooms'] + X['bathrooms']\n",
        "    X['bedrooms*bathrooms'] = X['bedrooms'] * X['bathrooms']\n",
        "    X['bedrooms2+bathrooms2'] = X['bedrooms']**2 + X['bathrooms']**2\n",
        "    X['bedrooms2*bathrooms2'] = X['bedrooms']**2 * X['bathrooms']**2\n",
        "    X['bedrooms3+bathrooms3'] = X['bedrooms']**3 + X['bathrooms']**3\n",
        "    X['bedrooms3*bathrooms3'] = X['bedrooms']**3 * X['bathrooms']**3\n",
        "    X['priceperbed'] = X['price'] / np.maximum(X['bedrooms'],1)\n",
        "    X['priceperbath'] = X['price'] / np.maximum(X['bathrooms'],1)\n",
        "    X['priceperroom'] = X['price'] / np.maximum(X['bedrooms'] + X['bathrooms'],1)\n",
        "    \n",
        "    \n",
        "    X['centroid0'] = np.sqrt((kmeans_centroids[0][0] - X['latitude'])**2 + (kmeans_centroids[0][1] - X['longitude'])**2)\n",
        "    X['centroid1'] = np.sqrt((kmeans_centroids[1][0] - X['latitude'])**2 + (kmeans_centroids[1][1] - X['longitude'])**2)\n",
        "    X['centroid2'] = np.sqrt((kmeans_centroids[2][0] - X['latitude'])**2 + (kmeans_centroids[2][1] - X['longitude'])**2)\n",
        "    X['centroid3'] = np.sqrt((kmeans_centroids[3][0] - X['latitude'])**2 + (kmeans_centroids[3][1] - X['longitude'])**2)\n",
        "    X['centroid4'] = np.sqrt((kmeans_centroids[4][0] - X['latitude'])**2 + (kmeans_centroids[4][1] - X['longitude'])**2)\n",
        "    X['centroid5'] = np.sqrt((kmeans_centroids[5][0] - X['latitude'])**2 + (kmeans_centroids[5][1] - X['longitude'])**2)\n",
        "    X['centroid6'] = np.sqrt((kmeans_centroids[6][0] - X['latitude'])**2 + (kmeans_centroids[6][1] - X['longitude'])**2)\n",
        "    X['centroid7'] = np.sqrt((kmeans_centroids[7][0] - X['latitude'])**2 + (kmeans_centroids[7][1] - X['longitude'])**2)\n",
        "    X['centroid8'] = np.sqrt((kmeans_centroids[8][0] - X['latitude'])**2 + (kmeans_centroids[8][1] - X['longitude'])**2)\n",
        "    X['centroid9'] = np.sqrt((kmeans_centroids[9][0] - X['latitude'])**2 + (kmeans_centroids[9][1] - X['longitude'])**2)\n",
        "\n",
        "    X['num_features'] = X['features'].apply(len)   \n",
        "      \n",
        "    X = X.drop(['building_id','description','created','display_address','features','manager_id','photos','street_address'], 1)\n",
        "    \n",
        "    return X\n",
        "\n",
        "X = prep_input(data_train.drop('interest_level',1), kmeans_centroids)\n",
        "y = data_train['interest_level']\n",
        "X_sub = prep_input(data_test, kmeans_centroids)\n",
        "\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de339212-5d5a-8ec2-b620-c5cb5ebcecec"
      },
      "outputs": [],
      "source": [
        "# join sparse features into features\n",
        "\n",
        "from scipy import sparse\n",
        "columns = X.columns.values\n",
        "X = sparse.hstack([X, features_sparse]).tocsr()\n",
        "X_sub = sparse.hstack([X_sub, features_sparse_sub]).tocsr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78e18f68-b99c-8a1b-3f9e-aa0504eaaa05"
      },
      "outputs": [],
      "source": [
        "# split into train and test for local validation\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1ce3513-d9e0-c77f-6968-8810311c342a"
      },
      "outputs": [],
      "source": [
        "# fit model\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=1000, verbose=1, n_jobs=-1)\n",
        "rf = rf.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aff6b208-c88d-25ae-9161-63a57bc50ba2"
      },
      "outputs": [],
      "source": [
        "# print feature importances\n",
        "\n",
        "list(sorted(zip(rf.feature_importances_, list(columns) + list(feat_cv.get_feature_names())), reverse=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "13a025eb-c1c0-a0e9-5cf3-6cfeba13cd48"
      },
      "outputs": [],
      "source": [
        "# local validation using logloss\n",
        "\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "y_pred = rf.predict_proba(X_test)\n",
        "print('log_loss',log_loss(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3a020f3-915d-ba56-7b33-7d3794b37f19"
      },
      "outputs": [],
      "source": [
        "# re-fit model on all training data\n",
        "\n",
        "rf = rf.fit(X, y)\n",
        "y_sub = rf.predict_proba(X_sub)\n",
        "\n",
        "df =  pd.DataFrame(y_sub)\n",
        "df.columns = rf.classes_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17167450-1e87-1548-3b11-1fdeaafe2e64"
      },
      "outputs": [],
      "source": [
        "df[\"listing_id\"] = data_test.listing_id.values\n",
        "\n",
        "df.to_csv(\"sub1.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}