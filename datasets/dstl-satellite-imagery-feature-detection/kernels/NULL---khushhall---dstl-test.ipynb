{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "97bd7735-a2dd-a770-e9fe-fd2bf63508d8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import plot, show, subplot, specgram, imshow, savefig\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from shapely.wkt import loads as wkt_loads\n",
        "import tifffile as tiff\n",
        "import os\n",
        "import random\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import jaccard_similarity_score\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "import shapely.wkt\n",
        "import shapely.affinity\n",
        "from collections import defaultdict\n",
        "\n",
        "N_Cls = 1 #10\n",
        "N_ToPredict = 1000\n",
        "inDir = '../input'\n",
        "DF = pd.read_csv(inDir + '/train_wkt_v4.csv')\n",
        "GS = pd.read_csv(inDir + '/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
        "SB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n",
        "ISZ = 160\n",
        "smooth = 1e-12\n",
        "\n",
        "\n",
        "def _convert_coordinates_to_raster(coords, img_size, xymax):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    Xmax, Ymax = xymax\n",
        "    H, W = img_size\n",
        "    W1 = 1.0 * W * W / (W + 1)\n",
        "    H1 = 1.0 * H * H / (H + 1)\n",
        "    xf = W1 / Xmax\n",
        "    yf = H1 / Ymax\n",
        "    coords[:, 1] *= yf\n",
        "    coords[:, 0] *= xf\n",
        "    coords_int = np.round(coords).astype(np.int32)\n",
        "    return coords_int\n",
        "\n",
        "\n",
        "def _get_xmax_ymin(grid_sizes_panda, imageId):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n",
        "    return (xmax, ymin)\n",
        "\n",
        "\n",
        "def _get_polygon_list(wkt_list_pandas, imageId, cType):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
        "    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n",
        "    polygonList = None\n",
        "    if len(multipoly_def) > 0:\n",
        "        assert(len(multipoly_def) == 1)\n",
        "        polygonList = wkt_loads(multipoly_def.values[0])\n",
        "    return polygonList\n",
        "\n",
        "\n",
        "def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    perim_list = []\n",
        "    interior_list = []\n",
        "    if polygonList is None:\n",
        "        return None\n",
        "    for k in range(len(polygonList)):\n",
        "        poly = polygonList[k]\n",
        "        perim = np.array(list(poly.exterior.coords))\n",
        "        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n",
        "        perim_list.append(perim_c)\n",
        "        for pi in poly.interiors:\n",
        "            interior = np.array(list(pi.coords))\n",
        "            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n",
        "            interior_list.append(interior_c)\n",
        "    return perim_list, interior_list\n",
        "\n",
        "\n",
        "def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    img_mask = np.zeros(raster_img_size, np.uint8)\n",
        "    if contours is None:\n",
        "        return img_mask\n",
        "    perim_list, interior_list = contours\n",
        "    cv2.fillPoly(img_mask, perim_list, class_value)\n",
        "    cv2.fillPoly(img_mask, interior_list, 0)\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n",
        "    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n",
        "    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n",
        "    mask = _plot_mask_from_contours(raster_size, contours, 1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def M(image_id):\n",
        "    # __author__ = amaia\n",
        "    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n",
        "    filename = os.path.join(inDir, 'sixteen_band', '{}_M.tif'.format(image_id))\n",
        "    img = tiff.imread(filename)\n",
        "    img = np.rollaxis(img, 0, 3)\n",
        "    return img\n",
        "\n",
        "\n",
        "def stretch_n(bands, lower_percent=5, higher_percent=95):\n",
        "    out = np.zeros_like(bands)\n",
        "    n = bands.shape[2]\n",
        "    for i in range(n):\n",
        "        a = 0  # np.min(band)\n",
        "        b = 1  # np.max(band)\n",
        "        c = np.percentile(bands[:, :, i], lower_percent)\n",
        "        d = np.percentile(bands[:, :, i], higher_percent)\n",
        "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
        "        t[t < a] = a\n",
        "        t[t > b] = b\n",
        "        out[:, :, i] = t\n",
        "\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "\n",
        "def jaccard_coef(y_true, y_pred):\n",
        "    # __author__ = Vladimir Iglovikov\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def jaccard_coef_int(y_true, y_pred):\n",
        "    # __author__ = Vladimir Iglovikov\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def stick_all_train():\n",
        "    print(\"let's stick all imgs together\")\n",
        "    s = 835\n",
        "\n",
        "    x = np.zeros((5 * s, 5 * s, 8))\n",
        "    y = np.zeros((5 * s, 5 * s, N_Cls))\n",
        "\n",
        "    ids = sorted(DF.ImageId.unique())\n",
        "    print(len(ids))\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            id = ids[5 * i + j]\n",
        "\n",
        "            img = M(id)\n",
        "            img = stretch_n(img)\n",
        "            print(img.shape, id, np.amax(img), np.amin(img))\n",
        "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n",
        "            for z in range(N_Cls):\n",
        "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
        "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
        "\n",
        "    print(np.amax(y), np.amin(y))\n",
        "\n",
        "    #np.save('data_x_trn_%d' % N_Cls, x)\n",
        "    #np.save('data_y_trn_%d' % N_Cls, y)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def get_patches(img, msk, amt=10000, aug=True):\n",
        "    is2 = int(1.0 * ISZ)\n",
        "    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n",
        "\n",
        "    x, y = [], []\n",
        "\n",
        "    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n",
        "    for i in range(amt):\n",
        "        xc = random.randint(0, xm)\n",
        "        yc = random.randint(0, ym)\n",
        "\n",
        "        im = img[xc:xc + is2, yc:yc + is2]\n",
        "        ms = msk[xc:xc + is2, yc:yc + is2]\n",
        "\n",
        "        for j in range(N_Cls):\n",
        "            sm = np.sum(ms[:, :, j])\n",
        "            if 1.0 * sm / is2 ** 2 > tr[j]:\n",
        "                if aug:\n",
        "                    if random.uniform(0, 1) > 0.5:\n",
        "                        im = im[::-1]\n",
        "                        ms = ms[::-1]\n",
        "                    if random.uniform(0, 1) > 0.5:\n",
        "                        im = im[:, ::-1]\n",
        "                        ms = ms[:, ::-1]\n",
        "\n",
        "                x.append(im)\n",
        "                y.append(ms)\n",
        "\n",
        "    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n",
        "    print(x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def make_val(img, msk):\n",
        "    print(\"let's pick some samples for validation\")\n",
        "    #img = np.load('data_x_trn_%d.npy' % N_Cls)\n",
        "    #msk = np.load('data_y_trn_%d.npy' % N_Cls)\n",
        "    x, y = get_patches(img, msk, amt=3000)\n",
        "\n",
        "    #np.save('data_x_tmp_%d' % N_Cls, x)\n",
        "    #np.save('data_y_tmp_%d' % N_Cls, y)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def get_unet():\n",
        "    inputs = Input((8, ISZ, ISZ))\n",
        "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(inputs)\n",
        "    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv1)\n",
        "\n",
        "    #conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool1)\n",
        "    #conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv2)\n",
        "    #pool2 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv2)\n",
        "\n",
        "    #conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool2)\n",
        "    #conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv3)\n",
        "    #pool3 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv3)\n",
        "\n",
        "    #conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool3)\n",
        "    #conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv4)\n",
        "    #pool4 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv4)\n",
        "\n",
        "    #conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool4)\n",
        "    #conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv5)\n",
        "    conv5 = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool1)\n",
        "    conv5 = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv5)\n",
        "\n",
        "    #up6 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv5), conv4], mode='concat', concat_axis=1)\n",
        "    #conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up6)\n",
        "    #conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv6)\n",
        "\n",
        "    #up7 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv6), conv3], mode='concat', concat_axis=1)\n",
        "    #conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up7)\n",
        "    #conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv7)\n",
        "\n",
        "    #up8 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv7), conv2], mode='concat', concat_axis=1)\n",
        "    #conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up8)\n",
        "    #conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv8)\n",
        "\n",
        "    up9 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv5), conv1], mode='concat', concat_axis=1)\n",
        "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up9)\n",
        "    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv9)\n",
        "\n",
        "    conv10 = Convolution2D(N_Cls, 1, 1, activation='sigmoid', dim_ordering=\"th\")(conv9)\n",
        "\n",
        "    model = Model(input=inputs, output=conv10)\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def calc_jacc(model, img, msk):\n",
        "    #img = np.load('data_x_tmp_%d.npy' % N_Cls)\n",
        "    #msk = np.load('data_y_tmp_%d.npy' % N_Cls)\n",
        "\n",
        "    prd = model.predict(img, batch_size=4)\n",
        "    print(prd.shape, msk.shape)\n",
        "    avg, trs = [], []\n",
        "\n",
        "    for i in range(N_Cls):\n",
        "        t_msk = msk[:, i, :, :]\n",
        "        t_prd = prd[:, i, :, :]\n",
        "        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
        "        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
        "\n",
        "        m, b_tr = 0, 0\n",
        "        for j in range(10):\n",
        "            tr = j / 10.0\n",
        "            pred_binary_mask = t_prd > tr\n",
        "\n",
        "            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n",
        "            if jk > m:\n",
        "                m = jk\n",
        "                b_tr = tr\n",
        "        print(i, m, b_tr)\n",
        "        avg.append(m)\n",
        "        trs.append(b_tr)\n",
        "\n",
        "    score = sum(avg) / 10.0\n",
        "    return score, trs\n",
        "\n",
        "\n",
        "def mask_for_polygons(polygons, im_size):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "    img_mask = np.zeros(im_size, np.uint8)\n",
        "    if not polygons:\n",
        "        return img_mask\n",
        "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
        "    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n",
        "    interiors = [int_coords(pi.coords) for poly in polygons\n",
        "                 for pi in poly.interiors]\n",
        "    cv2.fillPoly(img_mask, exteriors, 1)\n",
        "    cv2.fillPoly(img_mask, interiors, 0)\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def mask_to_polygons(mask, epsilon=5, min_area=1.):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "\n",
        "    # first, find contours with cv2: it's much faster than shapely\n",
        "    image, contours, hierarchy = cv2.findContours(\n",
        "        ((mask == 1) * 255).astype(np.uint8),\n",
        "        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n",
        "    # create approximate contours to have reasonable submission size\n",
        "    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n",
        "                       for cnt in contours]\n",
        "    if not contours:\n",
        "        return MultiPolygon()\n",
        "    # now messy stuff to associate parent and child contours\n",
        "    cnt_children = defaultdict(list)\n",
        "    child_contours = set()\n",
        "    assert(hierarchy.shape[0] == 1)\n",
        "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
        "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
        "        if parent_idx != -1:\n",
        "            child_contours.add(idx)\n",
        "            cnt_children[parent_idx].append(approx_contours[idx])\n",
        "    # create actual polygons filtering by area (removes artifacts)\n",
        "    all_polygons = []\n",
        "    for idx, cnt in enumerate(approx_contours):\n",
        "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
        "            assert(cnt.shape[1] == 1)\n",
        "            poly = Polygon(\n",
        "                shell=cnt[:, 0, :],\n",
        "                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n",
        "                       if cv2.contourArea(c) >= min_area])\n",
        "            all_polygons.append(poly)\n",
        "    # approximating polygons might have created invalid ones, fix them\n",
        "    all_polygons = MultiPolygon(all_polygons)\n",
        "    if not all_polygons.is_valid:\n",
        "        all_polygons = all_polygons.buffer(0)\n",
        "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
        "        # need to keep it a Multi throughout\n",
        "        if all_polygons.type == 'Polygon':\n",
        "            all_polygons = MultiPolygon([all_polygons])\n",
        "    return all_polygons\n",
        "\n",
        "\n",
        "def get_scalers(im_size, x_max, y_min):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n",
        "    h, w = float(h), float(w)\n",
        "    w_ = 1.0 * w * (w / (w + 1))\n",
        "    h_ = 1.0 * h * (h / (h + 1))\n",
        "    return w_ / x_max, h_ / y_min\n",
        "\n",
        "def batch_generator(X, y, batch_size, shuffle):\n",
        "    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n",
        "    number_of_batches = np.ceil(X.shape[0]/batch_size)\n",
        "    counter = 0\n",
        "    sample_index = np.arange(X.shape[0])\n",
        "    if shuffle:\n",
        "        np.random.shuffle(sample_index)\n",
        "    while True:\n",
        "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
        "        X_batch = X[batch_index,:]\n",
        "        y_batch = y[batch_index]\n",
        "        counter += 1\n",
        "        yield X_batch, y_batch\n",
        "        if (counter == number_of_batches):\n",
        "            if shuffle:\n",
        "                np.random.shuffle(sample_index)\n",
        "            counter = 0\n",
        "\n",
        "def batch_generatorp(X, batch_size, shuffle):\n",
        "    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n",
        "    counter = 0\n",
        "    sample_index = np.arange(X.shape[0])\n",
        "    while True:\n",
        "        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n",
        "        X_batch = X[batch_index, :]\n",
        "        counter += 1\n",
        "        yield X_batch\n",
        "        if (counter == number_of_batches):\n",
        "            counter = 0\n",
        "\n",
        "def train_net(img, msk, x_val, y_val):\n",
        "    print(\"start train net\")\n",
        "    #x_val, y_val = np.load('data_x_tmp_%d.npy' % N_Cls), np.load('data_y_tmp_%d.npy' % N_Cls)\n",
        "    #img = np.load('data_x_trn_%d.npy' % N_Cls)\n",
        "    #msk = np.load('data_y_trn_%d.npy' % N_Cls)\n",
        "\n",
        "    print(\"get_patches {}, {}...\".format(img.shape, msk.shape))\n",
        "    x_trn, y_trn = get_patches(img, msk)\n",
        "\n",
        "    print(\"model...\")\n",
        "    model = get_unet()\n",
        "    #model.load_weights('weights/unet_10_jk0.7878')\n",
        "    model_checkpoint = ModelCheckpoint('weights_unet_tmp.hdf5', monitor='loss', save_best_only=True)\n",
        "    for i in range(1):\n",
        "        print(\"fit {}, {}...\".format(x_trn.shape, x_val.shape))\n",
        "        model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, verbose=1, shuffle=True,\n",
        "                  callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n",
        "        #model.fit_generator(generator=batch_generator(x_trn, y_trn, 64, False),\n",
        "        #                 nb_epoch=1, samples_per_epoch=x_trn.shape[0],\n",
        "        #                 callbacks=[model_checkpoint],\n",
        "        #                 validation_data=batch_generator(x_val, y_val, 64, False), nb_val_samples=x_val.shape[0], verbose=2\n",
        "        #                 )\n",
        "        del x_trn\n",
        "        del y_trn\n",
        "        x_trn, y_trn = get_patches(img, msk)\n",
        "        score, trs = calc_jacc(model, x_val, y_val)\n",
        "        print('val jk', score)\n",
        "        model.save_weights('weights_unet_10_jk%.4f' % score)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_id(id, model, trs):\n",
        "    img = M(id)\n",
        "    x = stretch_n(img)\n",
        "\n",
        "    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n",
        "    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n",
        "    cnv[:img.shape[0], :img.shape[1], :] = x\n",
        "\n",
        "    for i in range(0, 6):\n",
        "        line = []\n",
        "        for j in range(0, 6):\n",
        "            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n",
        "\n",
        "        x = 2 * np.transpose(line, (0, 3, 1, 2)) - 1\n",
        "        tmp = model.predict(x, batch_size=4)\n",
        "        #tmp = model.predict_generator(generator=batch_generatorp(x, 4, False), val_samples=x.shape[0])\n",
        "        for j in range(tmp.shape[0]):\n",
        "            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = tmp[j]\n",
        "\n",
        "    # trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n",
        "    for i in range(N_Cls):\n",
        "        prd[i] = prd[i] > trs[i]\n",
        "\n",
        "    return prd[:, :img.shape[0], :img.shape[1]]\n",
        "\n",
        "\n",
        "def predict_test(model, trs):\n",
        "    print(\"predict test\")\n",
        "    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n",
        "        msk = predict_id(id, model, trs)\n",
        "        np.save('msk_10_%s' % id, msk)\n",
        "        if i % 100 == 0: print(i, id)\n",
        "\n",
        "\n",
        "def make_submit(model, trs):\n",
        "    print(\"make submission file\")\n",
        "    df = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n",
        "    print(df.head())\n",
        "    for idx, row in df.iterrows():\n",
        "        id = row[0]\n",
        "        kls = row[1] - 1\n",
        "        if idx % 100 == 0: print(idx)\n",
        "        \n",
        "        if idx >= N_ToPredict:\n",
        "            continue\n",
        "        \n",
        "        if kls < N_Cls:\n",
        "            #print('Predicting {}, {}, {}, {}'.format(idx, id, kls, row))\n",
        "            try:\n",
        "                msk = predict_id(id, model, trs)[kls]\n",
        "                #np.save('msk_10_%s' % id, msk)\n",
        "                #msk = np.load('msk_10_%s.npy' % id)[kls]\n",
        "                pred_polygons = mask_to_polygons(msk)\n",
        "                #print('pred_polygons {}'.format(pred_polygons))\n",
        "                x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n",
        "                y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n",
        "\n",
        "                x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n",
        "\n",
        "                scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n",
        "                                                              origin=(0, 0, 0))\n",
        "\n",
        "                df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n",
        "                #print('Got pred: {}'.format(df.iloc[idx, 2]))\n",
        "            except:\n",
        "                print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "                raise\n",
        "    print(df.head())\n",
        "    df.to_csv('subm_1.csv', index=False)\n",
        "\n",
        "\n",
        "def check_predict(id='6120_2_3'):\n",
        "    model = get_unet()\n",
        "    #model.load_weights('weights/unet_10_jk0.7878')\n",
        "\n",
        "    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n",
        "    img = M(id)\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(131)\n",
        "    ax1.set_title('image ID:6120_2_3')\n",
        "    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n",
        "    ax2 = plt.subplot(132)\n",
        "    ax2.set_title('predict bldg pixels')\n",
        "    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n",
        "    ax3 = plt.subplot(133)\n",
        "    ax3.set_title('predict bldg polygones')\n",
        "    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n",
        "\n",
        "    plt.show()\n",
        "    #savefig('plot.png')\n",
        "    #plt.gcf().clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de83125c-f5e5-547a-1c43-c1cd0833cb97"
      },
      "outputs": [],
      "source": [
        "x, y = stick_all_train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "13b68910-9102-40f4-8a8b-b455b2904586"
      },
      "outputs": [],
      "source": [
        "x_val, y_val = make_val(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f208d38-e92d-4521-89f4-a6facf89a9f3"
      },
      "outputs": [],
      "source": [
        "model = train_net(x, y, x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7b25789-bcd2-a569-99b0-bd9b70c35d41"
      },
      "outputs": [],
      "source": [
        "# score, trs = calc_jacc(model, x_val, y_val)\n",
        "print (\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "063f66ff-d897-87d6-341b-99e76b687bde"
      },
      "outputs": [],
      "source": [
        "check_predict('6120_2_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53a11fd6-f7fb-d054-d64c-bac72b5bce8c"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}