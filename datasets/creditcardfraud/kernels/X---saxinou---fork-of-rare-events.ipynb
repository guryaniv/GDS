{"metadata": {"language_info": {"nbconvert_exporter": "python", "version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "cells": [{"metadata": {"_cell_guid": "54c18e24-da16-492f-8d26-1c33ac4b7747", "_uuid": "95e16514cfed4bc34f9be7cb0aa538cf4d74d07d"}, "cell_type": "markdown", "source": ["# **Rare event**\n", "\n", "Undersampling et Oversampling method with logistic regression\n"]}, {"metadata": {"_cell_guid": "3c7a0e37-3a3c-403b-a3d8-45f4d9e98af8", "_uuid": "72eecb0330fd9f9385e1811f1428203b247f74c5", "scrolled": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns # for intractve graphs\n", "\n", "from sklearn.preprocessing import MinMaxScaler # Pour centrer et r\u00e9duire les donn\u00e9es \n", "from imblearn.over_sampling import SMOTE # Algorithme SMOTE\n", "\n", "from sklearn import linear_model \n", "from sklearn import metrics\n", "from sklearn.metrics import recall_score\n", "from sklearn.metrics import precision_recall_curve\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Importation des donnees\n", "df = pd.read_table('../input/creditcard.csv', header=0, sep=',', engine='python')\n", "\n", "# Presentation de la base\n", "df.describe()  # Description de la base de donn\u00e9e\n", "df.shape       # Dimension de la base \n", "type(df)       # Le type de la bdd\n", "df.dtypes      # Affichage du type de chaque colonne\n", "print(df.columns.tolist()) # Affichage du nom des colonnes\n", "\n", "# Recuperation du nombre de fraude \n", "n0 = len(df[df[\"Class\"]==0]) \n", "n1 = len(df[df[\"Class\"]==1])\n", "print(\"n_fraudes = \",n1)\n", "print(\"n_ok = \",n0)\n", "sns.countplot(x='Class',data=df, palette='hls')\n", "# Check valeur nulle \n", "df.isnull().sum()\n", "# Checking for independence between features\n", "sns.heatmap(df.corr()) \n", "\n", "# Fr\u00e9quence relative de la variable cible\n", "my_tab = pd.crosstab(index=df['Class'],  # Make a crosstab\n", "                     columns=\"count\")      # Name the count column\n", "my_tab\n"]}, {"metadata": {"collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["sns.countplot(x='Class',data=df, palette='hls')"]}, {"metadata": {"_cell_guid": "2f6984dc-0a72-47d0-9b9c-7ee37fc8045e", "_uuid": "9f3ba929fd8911615b21c6ae6f0cfd50021d86f3"}, "cell_type": "markdown", "source": ["# Description des m\u00e9thodes : \n", "\n", "** Oversampling ** : la classe minoritaire est r\u00e9 \u00e9chantillonn\u00e9e de sorte que celle-ci soit \u00ab sur-repr\u00e9sent\u00e9es \u00bb en terme de fr\u00e9quence dans la base d\u2019apprentissage.\n", "\n", "** Undersampling ** : la classe majoritaire est r\u00e9\u00e9chantillonn\u00e9e de sorte que sa fr\u00e9quence dans la base d\u2019apprentissage soit la plus proche possible de la classe minoritaire."]}, {"metadata": {"_cell_guid": "e7b245f1-5806-467f-9025-6db34de02811", "_uuid": "955be21f62f047f4cc4069cd949d3a8dfc65eef5", "collapsed": true, "scrolled": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# On veut 50% de fraudes et 50% de non fraude par d\u00e9faut\n", "def undersampling(data,target,times=0.75):\n", "    # Echantillonnage sur les cibles\n", "    samp1 = df[df[target]==1].sample(frac=1, replace=True)\n", "    # Recuperation du nombre de cible s\u00e9lectionn\u00e9\n", "    n1 = samp1.shape[0]\n", "    # Petit calcul pour d\u00e9terminer le nombre de non cible \u00e0 s\u00e9lectionner\n", "    # new_n0 = int(n1*(1-pct_target)/pct_target)\n", "    facteur = times*2/0.5\n", "    # Echantillonnage sur les non-cibles\n", "    samp0 = df[df[target]==0].sample(n=int(samp1.shape[0]*facteur), replace=True)\n", "    # Concatenation des deux tables \n", "    samp = pd.concat([samp0,samp1])\n", "    \"\"\"\n", "    print(\"Distribution of class labels before resampling \\n\", pd.crosstab(index=data[target], columns=\"count\") )\n", "    print(\"Distribution of class labels after resampling \\n\", pd.crosstab(index=samp[target], columns=\"count\") )\n", "    \"\"\"\n", "    return(samp)\n", "\n", "# Construction de la base d'apprentissage\n", "# Exemple de lancement : \n", "df_over = undersampling(df,\"Class\",times=0.5)\n", "df_over.shape\n", "# df_over = undersampling(df,\"Class\",times=0.75)"]}, {"metadata": {"_cell_guid": "23d88542-ce3d-42f4-92d4-0e06262bb76b", "_uuid": "b06aec3487a393c2fd86e2389c63b5c0456ac9fe", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Pour l'oversampling, on ne garde qu'une partie des non fraudes\n", "# On d\u00e9termine le nombre de fraude par rapport \u00e0 la fraction restante\n", "def oversample(data,target,times = 0.75,frac_nontarget = 0.5):#times denote the normal data = times*fraud data\n", "    # Echantillonnage sur les non cibles\n", "    samp0 = data[data[target]==0].sample(frac=frac_nontarget, replace=True)\n", "    # Recuperation du nombre de cible s\u00e9lectionn\u00e9\n", "    facteur = times*2/0.5\n", "    # Echantillonnage sur les cibles\n", "    samp1 = data[data[target]==1].sample(n=int(samp0.shape[0]/facteur), replace=True)\n", "    # Concatenation des deux tables \n", "    samp = pd.concat([samp0,samp1])\n", "    \"\"\"\n", "    print(\"Distribution of class labels before resampling \\n\", pd.crosstab(index=data[target], columns=\"count\") )\n", "    print(\"Distribution of class labels after resampling \\n \", pd.crosstab(index=samp[target], columns=\"count\") )\n", "    \"\"\"\n", "    return(samp)\n", "\n", "# Times  = % de non fraude \n", "\n", "# Exemple de lancement : \n", "df_under = oversample(df,\"Class\",times = 0.75)\n", "df_under.shape"]}, {"metadata": {"_cell_guid": "92a60314-9f65-4286-962d-c3f8369c88c4", "_uuid": "a3eac4e9ec943c3e8fd8dd7dea9e18d5a56f0cde", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Preparation des donn\u00e9es : centrer et r\u00e9duire \n", "\"\"\"\n", "from sklearn.preprocessing import StandardScaler # for preprocessing the data\n", "df[\"Normalized Amount\"] = StandardScaler().fit_transform(df['Amount'].reshape(-1, 1))\n", "df.drop([\"Time\",\"Amount\"],axis=1,inplace=True)\n", "df.head()\n"]}, {"metadata": {"_cell_guid": "b23103e4-8ddf-4624-8eb2-1c637e98a3b2", "_uuid": "3c54f0f54c3313f19ade62f3ffced5d97139bdff", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "Preparation des donn\u00e9es : creation des bases d'apprentissage et  \n", "\"\"\"\n", "def dataprep(data, target, times, type_sample = \"over\"):\n", "    if \"under\" in type_sample: \n", "        print (\"Creation des bases undersampling\\n\")\n", "        data = undersampling(data,target,times=times)\n", "    else: \n", "        print (\"Creation des bases oversampling\\n\")\n", "        data = oversample(data,target,times=times)\n", "        \n", "    \"\"\" Target vs Design Matrix \"\"\" \n", "    y = data[target]\n", "    X = data.drop([target], axis=1)\n", "\n", "    \"\"\" Preparation de la base d'apprentissage et de validation \"\"\"\n", "    # On split a nouveau en une base de train et de test\n", "    print (\"\\nSplit en base train et validation \")\n", "    x_train, x_val, y_train, y_val = train_test_split(X,y,  test_size = .2, random_state=12)\n", "    \"\"\"\n", "    print(\"Dimension de la design matrix d'apprentissage \", x_train.shape)\n", "    print(\"R\u00e9partition des targets dans l'apprentissage \\n\", pd.crosstab(y_train, columns=\"count\") )\n", "    print(\"Dimension de la design matrix de validation \", x_val.shape)\n", "    print(\"R\u00e9partition des targets dans l'apprentissage \\n\", pd.crosstab(y_val, columns=\"count\") )\n", "    \"\"\"\n", "    return(x_train, x_val, y_train, y_val)\n", "\n", "x_train, x_val, y_train, y_val = dataprep(df, \"Class\", type_sample = \"over\",times=0.75)"]}, {"metadata": {"_cell_guid": "310e65b5-3f46-4ab0-ac3f-b49772ec8804", "_uuid": "c943be42f76c42d1bfd44f9642cc98274d237e7b", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["def model_accuracy(trained_model, features, targets):\n", "    accuracy_score = trained_model.score(features, targets)\n", "    return accuracy_score"]}, {"metadata": {"_cell_guid": "45299cba-4d27-4cf8-8482-459d4db17670", "_uuid": "6edf03794dc1c3f12bc12a7103455dc88bd61efa", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["## first make a model function for modeling with confusion matrix\n", "def model(model,features_train,features_test,labels_train,labels_test):\n", "\n", "    model.fit(features_train,labels_train.values.ravel())\n", "    pred=model.predict(features_test)\n", "    cnf_matrix=confusion_matrix(labels_test,pred)\n", "\n", "    print(\"\\nAUC ----------------------------------- \")\n", "    # Sur la base d'apprentissage\n", "    fpr, tpr, thresholds = metrics.roc_curve(labels_train, model.predict(features_train))\n", "    print(\"Train AUC : \", metrics.auc(fpr, tpr))\n", "    # Sur la base de validation\n", "    fpr, tpr, thresholds = metrics.roc_curve(labels_test, model.predict(features_test))\n", "    print(\"Validation AUC : \",metrics.auc(fpr, tpr))\n", "\n", "    print(\"Accuracy ------------------------------ \")\n", "    train_accuracy = model_accuracy(model, features_train, labels_train)\n", "    print (\"Train Accuracy : \", train_accuracy)\n", "    val_accuracy = model_accuracy(model, features_test, labels_test)\n", "    print (\"Validation Accuracy : \", val_accuracy)\n", "\n", "    print(\"Recall ------------------------------ \")\n", "    print(\"the recall for this model is :\",cnf_matrix[1,1]/(cnf_matrix[1,1]+cnf_matrix[1,0]))\n", "    fig= plt.figure(figsize=(6,3))# to plot the graph\n", "    \"\"\"\n", "    print(\"TP\",cnf_matrix[1,1,]) # no of fraud transaction which are predicted fraud\n", "    print(\"TN\",cnf_matrix[0,0]) # no. of normal transaction which are predited normal\n", "    print(\"FP\",cnf_matrix[0,1]) # no of normal transaction which are predicted fraud\n", "    print(\"FN\",cnf_matrix[1,0]) # no of fraud Transaction which are predicted normal\n", "    \"\"\"\n", "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n", "    plt.title(\"Confusion_matrix sur la base de test \")\n", "    plt.xlabel(\"Predicted_class\")\n", "    plt.ylabel(\"Real class\")\n", "    plt.show()\n", "    \"\"\"\n", "    print(\"\\n----------Classification Report------------------------------------\")\n", "    print(classification_report(labels_test,pred))\n", "    \"\"\"\n", "\n", "# Exemple de lancement : \n", "# model(linear_model.LogisticRegression(),x_train,x_val,y_train,y_val)"]}, {"metadata": {"_cell_guid": "126184cd-4ea2-485e-8b06-2073c05757e6", "_uuid": "397d04af27b008731f7ad49fbe0df4100a2c3471", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["# Driver g\u00e9n\u00e9rique pour lancer le mod\u00e8le\n", "def driver(data, target, typemodel, method_sample = \"over\", times = 0.75):\n", "    print (\"---------------------------------- \\n Lancement pour le mod\u00e8le avec \", times, \"\\n ---------------------------------- \")\n", "    print(\"\\n---------- Information concernant le split de la BDD  \\n \")\n", "    x_train, x_val, y_train, y_val = dataprep(data, target, type_sample = method_sample, times = times)\n", "    print(\"\\n---------- Information concernant le modele ---------- \\n \")\n", "    model(typemodel,x_train,x_val,y_train,y_val)\n", "\n", "typemodel = linear_model.LogisticRegression()\n", "driver(df, \"Class\", typemodel, method_sample = \"over\", times = 0.85)\n", "\"\"\"\n", "driver(df, \"Class\", typemodel, method_sample = \"over\", times = 0.75)\n", "driver(df, \"Class\", typemodel, method_sample = \"over\", times = 0.65)\n", "driver(df, \"Class\", typemodel, method_sample = \"over\", times = 0.50)\n", "\"\"\"\n"]}, {"metadata": {"_cell_guid": "70074c12-e759-4103-adfd-9c4de3c2503c", "_uuid": "3c3c68c96d69ab1b9064388d5f324c1f57ff2211"}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "ALGO SMOTE avec une r\u00e9gression logistique\n", "\"\"\"\n", "# Chargement des modules\n", "\n", "\"\"\"\n", "TO DO:\n", "- revoir le pgm \n", "\"\"\"\n", "LogReg = linear_model.LogisticRegression()\n", "\n", "# Lancement de l'algorithme SMOTE\n", "sm = SMOTE(random_state=42)\n", "\n", "\"\"\" Target vs Design Matrix \"\"\" \n", "y = df[\"Class\"]\n", "X = df.drop([\"Class\"], axis=1)\n", "\n", "x_res, y_res = sm.fit_sample(X, y)\n", "\n", "# Apprentissage r\u00e9gression logistique sur les donn\u00e9es SMOTE\n", "LogReg.fit(x_res, y_res)\n", "fpr, tpr, thresholds = metrics.roc_curve(y_res, LogReg.predict(x_res))\n", "print('Train Results\\n', metrics.auc(fpr, tpr),'\\n', recall_score(y_res, LogReg.predict(x_res)))\n", "\n", "# Pred sur la base de validation\n", "fpr, tpr, thresholds = metrics.roc_curve(y_val, LogReg.predict(x_val))\n", "print('\\nValidation Results\\n', metrics.auc(fpr, tpr),'\\n', recall_score(y_val, LogReg.predict(x_val)))\n", "\n", "# SUr la population\n", "fpr, tpr, thresholds = metrics.roc_curve(y, LogReg.predict(X))\n", "print('\\nBase Results\\n', metrics.auc(fpr, tpr),'\\n', recall_score(y, LogReg.predict(X)))"]}, {"metadata": {"_cell_guid": "586e4f97-15ce-4ff0-8443-4fb98979ea72", "_uuid": "c29b3c594b03801fc385b345e507ff3f4336d7b0", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "ALGO SMOTE - Comparaison des diff\u00e9rents algorithmes SMOTE \n", "- regular\n", "- borderline1 et 2\n", "- SVM\n", "\"\"\"\n", "LogReg = linear_model.LogisticRegression()\n", "\n", "# Definition des diff\u00e9rentes m\u00e9thodes \"kind\"\n", "kind = ['regular', 'borderline1', 'borderline2'] # 'svm' non execut\u00e9 car trop long\n", "\n", "print(\"Demarrage de l'analyse avec differentes m\u00e9thodes \", kind)\n", "# Comparaison des diff\u00e9rentes m\u00e9thodes\n", "for k in kind:\n", "    sm = SMOTE(random_state=42, kind=k)\n", "    x_res, y_res = sm.fit_sample(x_train, y_train)\n", "    LogReg.fit(x_res, y_res)\n", "    fpr_train, tpr_train, thresholds_train = metrics.roc_curve(y_res, LogReg.predict(x_res))\n", "    fpr_val, tpr_val, thresholds_val = metrics.roc_curve(y_val, LogReg.predict(x_val))\n", "    fpr_pop, tpr_pop, thresholds_pop = metrics.roc_curve(y, LogReg.predict(X))\n", "    print(\"R\u00e9sultat pour le mod\u00e8le %s -------------- \" % (k))\n", "    print(\"AUC sur la base d'apprentissage : %f\" % (metrics.auc(fpr_train, tpr_train)))\n", "    print(\"AUC sur la base de validation : %f\" % (metrics.auc(fpr_val, tpr_val)))\n", "    print(\"AUC sur la population : %f\" % (metrics.auc(fpr_pop, tpr_pop)))\n", "    \n", "    print(\"\\nRecall sur la base d'apprentissage\" , recall_score(y_res, LogReg.predict(x_res)))\n", "    print(\"Recall sur la base de validation \" , recall_score(y_val, LogReg.predict(x_val)))\n", "    print(\"Recall sur la population \" , recall_score(y, LogReg.predict(X)))\n", "    \n", "    confusion_matrix_train = confusion_matrix(y_res, LogReg.predict(x_res))\n", "    print(\"\\nMatrice de confusion sur la base de train : \\n\", confusion_matrix_train)\n", "    confusion_matrix_val = confusion_matrix(y_val, LogReg.predict(x_val))\n", "    print(\"Matrice de confusion sur la base de train : \\n\", confusion_matrix_val)\n", "    confusion_matrix_pop = confusion_matrix(y, LogReg.predict(X))\n", "    print(\"Matrice de confusion sur la base de train : \\n\", confusion_matrix_pop)\n", "    print(\"---------------------------------------------\\n\")\n"]}, {"metadata": {"_cell_guid": "3b576d92-60d6-478a-9ee2-ddaef0c2cceb", "_uuid": "602d710b3552772ec42b340a1c2f1177f5a492ff", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "ALGO SMOTE - Comparaison des diff\u00e9rents ratio \n", "- 'minority'\n", "- 'majority'\n", "- 'not minority'\n", "- 'all'\n", "- 'auto'\n", "\"\"\"\n", "from imblearn.over_sampling import SMOTE\n", "from sklearn import linear_model\n", "from sklearn.metrics import precision_recall_curve\n", "from sklearn.metrics import confusion_matrix\n", "from sklearn.metrics import classification_report\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.model_selection import train_test_split\n", "\n", "LogReg = linear_model.LogisticRegression()\n", "\n", "# Definition des diff\u00e9rentes m\u00e9thodes \"kind\"\n", "ratio = ['minority','not minority','all','auto'] \n", "\n", "print(\"Demarrage de l'analyse avec differentes m\u00e9thodes \", ratio)\n", "# Comparaison des diff\u00e9rentes m\u00e9thodes\n", "for r in ratio:\n", "    sm = SMOTE(random_state=42, ratio=r)\n", "    x_res, y_res = sm.fit_sample(x_train, y_train)\n", "    LogReg.fit(x_res, y_res)\n", "    fpr_train, tpr_train, thresholds_train = metrics.roc_curve(y_res, LogReg.predict(x_res))\n", "    fpr_val, tpr_val, thresholds_val = metrics.roc_curve(y_val, LogReg.predict(x_val))\n", "    fpr_pop, tpr_pop, thresholds_pop = metrics.roc_curve(y, LogReg.predict(X))\n", "    print(\"\\nR\u00e9sultat pour le mod\u00e8le %s -------------- \" % (r))\n", "    print(\"AUC sur la base d'apprentissage : %f\" % (metrics.auc(fpr_train, tpr_train)))\n", "    print(\"AUC sur la base de validation : %f\" % (metrics.auc(fpr_val, tpr_val)))\n", "    print(\"AUC sur la population : %f\" % (metrics.auc(fpr_pop, tpr_pop)))"]}, {"metadata": {"_cell_guid": "586381d7-c1de-4ba0-b378-e156e0271397", "_uuid": "2a6cad8e83dc3902c04000759f72d0129486858a", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}, {"metadata": {"_cell_guid": "a192d0bc-235f-4037-ab8c-5ccf3e6fab9e", "_uuid": "6331b1dc5af03f78e00b56397d5face8e3808a73", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}, {"metadata": {"_cell_guid": "8a90b224-6dc1-4db8-98fa-c75fed4d4723", "_uuid": "c8628a356bc7113abbc6d2e9fe6054138523e327", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": ["\"\"\"\n", "ADASYN\n", "\"\"\"\n", "X_res, y_res = method.fit_sample(X, y)\n", "X_resampled.append(X_res)\n", "y_resampled.append(y_res)\n", "LogReg.fit(X_resampled, y_resampled)\n", "fpr, tpr, thresholds = metrics.roc_curve(y_train_res, LogReg.predict(x_train_res))\n", "print(metrics.auc(fpr, tpr))\n"]}, {"metadata": {"_cell_guid": "c5681fb5-8c28-4e75-8ddc-fc0c1ff727c2", "_uuid": "274c4cf2d1ddaf585fedd7c7e3f10eebeb6c8d3a", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}, {"metadata": {"_cell_guid": "76a0ed84-e047-4118-8f76-656627e9763b", "_uuid": "e59c4042b924d67a5461901db541750be2eba499", "collapsed": true}, "outputs": [], "execution_count": null, "cell_type": "code", "source": []}], "nbformat_minor": 1}