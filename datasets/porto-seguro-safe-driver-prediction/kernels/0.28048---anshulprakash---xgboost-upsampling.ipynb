{"cells": [{"metadata": {"collapsed": true, "_cell_guid": "11a94a0f-51f3-4a15-8bad-eac68cc1027b", "_uuid": "25b75a696ea90285e26b08e748a386f0151321d0"}, "cell_type": "code", "outputs": [], "source": ["### IMPORTING REQUIRED PACKAGES\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "# machine learning modules\n", "import sklearn\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score\n", "from sklearn.utils import shuffle\n", "from sklearn.model_selection import StratifiedKFold\n", "import xgboost as xgb"], "execution_count": 1}, {"metadata": {"_cell_guid": "eeb4f5bb-aa18-4d69-8579-36d4cc46d6a5", "_uuid": "8ce8349460fae8dad550435669bf21cddbd4840e"}, "cell_type": "code", "outputs": [], "source": ["#### LOADING DATA ####\n", "\n", "train = pd.read_csv(\"../input/train.csv\", na_values='-1')\n", "test = pd.read_csv(\"../input/test.csv\", na_values='-1')\n", "print(train.shape)\n", "print(test.shape)"], "execution_count": 2}, {"metadata": {"_cell_guid": "ba1e77c3-8c92-4262-948d-0cff775fe85a", "_uuid": "9f3e0dc7f381342a8826de44f2e91b42efadc0ed"}, "cell_type": "code", "outputs": [], "source": ["desired_apriori=0.10\n", "\n", "# Get the indices per target value\n", "idx_0 = train[train.target == 0].index\n", "idx_1 = train[train.target == 1].index\n", "\n", "# Get original number of records per target value\n", "nb_0 = len(train.loc[idx_0])\n", "nb_1 = len(train.loc[idx_1])\n", "\n", "# Calculate the undersampling rate and resulting number of records with target=0\n", "undersampling_rate = ((1-desired_apriori)*nb_1)/(nb_0*desired_apriori)\n", "undersampled_nb_0 = int(undersampling_rate*nb_0)\n", "print('Rate to undersample records with target=0: {}'.format(undersampling_rate))\n", "print('Number of records with target=0 after undersampling: {}'.format(undersampled_nb_0))\n", "\n", "# Randomly select records with target=0 to get at the desired a priori\n", "undersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0)\n", "\n", "# Construct list with remaining indices\n", "idx_list = list(undersampled_idx) + list(idx_1)\n", "\n", "# Return undersample data frame\n", "train = train.loc[idx_list].reset_index(drop=True)"], "execution_count": 3}, {"metadata": {"collapsed": true, "_cell_guid": "05d14762-e422-4174-bdf0-ad645166d4be", "_uuid": "9c313467728e9d4d51eb5151e1f07c701c3b8961"}, "cell_type": "code", "outputs": [], "source": ["### DROPPING COLUMNS\n", "vars_to_drop = ['ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_reg_03', 'ps_car_03_cat', \n", "                'ps_car_05_cat','ps_car_14']\n", "train.drop(vars_to_drop, inplace=True, axis=1)\n", "test.drop(vars_to_drop, inplace=True, axis=1)\n", "print(train.shape)\n", "print(test.shape)"], "execution_count": null}, {"metadata": {"collapsed": true, "_cell_guid": "43480b9f-7532-4002-b9ac-92a6123f5774", "_uuid": "951f01037da557275ba30a78a34391d68d911e68"}, "cell_type": "code", "outputs": [], "source": ["unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n", "train = train.drop(unwanted, axis=1)  \n", "test = test.drop(unwanted, axis=1)  "], "execution_count": 4}, {"metadata": {"collapsed": true, "_cell_guid": "f01ea844-73db-4c31-9f9a-05c1763d86f6", "_uuid": "ec3564b47c06f574577512e9ff6ce7f50afb2678"}, "cell_type": "code", "outputs": [], "source": ["## Filling the missing data NAN with median of the column\n", "train_data_nato_median = pd.DataFrame()\n", "for column in train.columns:\n", "    train_data_nato_median[column] = train[column].fillna(train[column].median())\n", "\n", "train = train_data_nato_median.copy()\n", "\n", "## Filling the missing data NAN with mean of the column\n", "test_data_nato_median = pd.DataFrame()\n", "for column in test.columns:\n", "    test_data_nato_median[column] = test[column].fillna(test[column].median())\n", "    \n", "test = test_data_nato_median.copy()"], "execution_count": 5}, {"metadata": {"collapsed": true, "_cell_guid": "e1dc4a74-2089-4d45-aed6-61c79bc03cbb", "_uuid": "89833e9d7615668dc07a21ebe755536a8a9c0d7f"}, "cell_type": "code", "outputs": [], "source": ["## Identifying Categorical data\n", "column_names = train.columns\n", "categorical_column = column_names[column_names.str[10] == 'c']\n", "\n", "## Changing categorical columns to category data type\n", "def int_to_categorical(data):\n", "    \"\"\" \n", "    changing columns to catgorical data type\n", "    \"\"\"\n", "    for column in categorical_column:\n", "        data[column] =  data[column].astype('category')"], "execution_count": 6}, {"metadata": {"_cell_guid": "e82c7b21-3d12-4ab0-b268-688185a8459a", "_uuid": "9b0bcae90d70eeb894eec0c7b0fd46eea17f7b6d"}, "cell_type": "code", "outputs": [], "source": ["## Creating list of train and test data and converting columns of interest to categorical type\n", "datas = [train,test]\n", "\n", "for data in datas:\n", "    int_to_categorical(data)\n", "\n", "print(test.dtypes)"], "execution_count": 7}, {"metadata": {"collapsed": true, "_cell_guid": "1636d22f-d902-49aa-8ce3-13cb3c64a899", "_uuid": "e772439343903f994786bd78ce550fd87336af39"}, "cell_type": "code", "outputs": [], "source": ["### FUNCTION TO CREATE DUMMIES COLUMNS FOR CATEGORICAL VARIABLES\n", "def creating_dummies(data):\n", "    \"\"\"creating dummies columns categorical varibles\n", "    \"\"\"\n", "    for column in categorical_column:\n", "        dummies = pd.get_dummies(data[column],prefix=column)\n", "        data = pd.concat([data,dummies],axis =1)\n", "        ## dropping the original columns ##\n", "        data.drop([column],axis=1,inplace= True)"], "execution_count": 8}, {"metadata": {"_cell_guid": "57eb3a0d-f592-4b6f-9914-43f5b32702a5", "_uuid": "c59a0d5d315034b314f8447eb1906aa054722427"}, "cell_type": "code", "outputs": [], "source": ["### CREATING DUMMIES FOR CATEGORICAL VARIABLES  \n", "for column in categorical_column:\n", "        dummies = pd.get_dummies(train[column],prefix=column)\n", "        train = pd.concat([train,dummies],axis =1)\n", "        train.drop([column],axis=1,inplace= True)\n", "\n", "\n", "for column in categorical_column:\n", "        dummies = pd.get_dummies(test[column],prefix=column)\n", "        test = pd.concat([test,dummies],axis =1)\n", "        test.drop([column],axis=1,inplace= True)\n", "\n", "print(train.shape)\n", "print(test.shape)"], "execution_count": 9}, {"metadata": {"collapsed": true, "_cell_guid": "61abee78-e275-4987-b88d-bc34e26b9b42", "_uuid": "578e955aaa2cf8daf74fc4944b79fae7420b6c62"}, "cell_type": "code", "outputs": [], "source": ["# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n", "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n", "    assert( len(actual) == len(pred) )\n", "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n", "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n", "    totalLosses = all[:,0].sum()\n", "    giniSum = all[:,0].cumsum().sum() / totalLosses\n", "    \n", "    giniSum -= (len(actual) + 1) / 2.\n", "    return giniSum / len(actual)\n", " \n", "def gini_normalized(a, p):\n", "    return gini(a, p) / gini(a, a)\n", "\n", "def gini_xgb(preds, dtrain):\n", "    labels = dtrain.get_label()\n", "    gini_score = gini_normalized(labels, preds)\n", "    return 'gini', gini_score"], "execution_count": 10}, {"metadata": {"collapsed": true, "_cell_guid": "b2759710-b188-48f3-b7c5-b6e531df3311", "_uuid": "b9c165024268b46f6544fc0944b462258b715e3f"}, "cell_type": "code", "outputs": [], "source": ["# Stratified K Fold\n", "kfold = 3\n", "skf = StratifiedKFold(n_splits=kfold, random_state=42)"], "execution_count": 11}, {"metadata": {"collapsed": true, "_cell_guid": "7f4b3aa9-f2a7-4e71-bb3e-0159e25aa691", "_uuid": "f7de0dc8323c2cce6d4cdf2a9d85af31aba2e37f"}, "cell_type": "code", "outputs": [], "source": ["# Set parameters for XGBoost \n", "params = {\n", "    'min_child_weight': 10.0,\n", "    'objective': 'binary:logistic',\n", "    'max_depth': 7,\n", "    'max_delta_step': 1.8,\n", "    'colsample_bytree': 0.4,\n", "    'subsample': 0.8,\n", "    'eta': 0.025,\n", "    'gamma': 0.65,\n", "    'num_boost_round' : 700\n", "    }"], "execution_count": 12}, {"metadata": {"collapsed": true, "_cell_guid": "f3a853fa-d866-4d0f-b060-47d6ceab33c0", "_uuid": "c2226b310743fb1b928fbc4fd984fe658fd096ea"}, "cell_type": "code", "outputs": [], "source": ["#Define X and y\n", "X = train.drop(['id', 'target'], axis=1).values\n", "y = train.target.values\n", "test_id = test.id.values\n", "test = test.drop('id', axis=1).values"], "execution_count": 13}, {"metadata": {"collapsed": true, "_cell_guid": "03e80dba-b72e-40d0-a83b-124397fdbe22", "_uuid": "9bdf9b81b6486fdb635a77667f05a84f49d29bf0"}, "cell_type": "code", "outputs": [], "source": ["X = X[:,[142,135,150,14,138,143,139,141,136,61,151,11,179,146,140,86,175,147, 152,145,180,148,177,133,59,60,183,14,51,34,67,137,16,161,88,85,159,33,178,184,65,13,12,63,18,156,83,87]]\n", "test = test[:,[142,135,150,14,138,143,139,141,136,61,151,11,179,146,140,86,175,147, 152,145,180,148,177,133,59,60,183,14,51,34,67,137,16,161,88,85,159,33,178,184,65,13,12,63,18,156,83,87]]"], "execution_count": null}, {"metadata": {"collapsed": true, "_cell_guid": "db44a0e7-801f-4299-8929-a376422bcba0", "_uuid": "5b2e57aff250d2ca260ef92b34d0502c0c1425e6"}, "cell_type": "code", "outputs": [], "source": ["sub = pd.DataFrame()\n", "sub['id'] = test_id\n", "sub['target'] = np.zeros_like(test_id)"], "execution_count": 14}, {"metadata": {"_cell_guid": "f8f7ab1f-d0cf-47bb-ba15-18b698d6d09b", "_uuid": "e25e395948d99f6b6216b58fccb96dda878a0067"}, "cell_type": "code", "outputs": [], "source": ["for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n", "    print('[Fold %d/%d]' % (i + 1, kfold))\n", "    X_train, X_valid = X[train_index], X[test_index]\n", "    y_train, y_valid = y[train_index], y[test_index]\n", "    # Convert our data into XGBoost format\n", "    d_train = xgb.DMatrix(X_train, y_train)\n", "    d_valid = xgb.DMatrix(X_valid, y_valid)\n", "    d_test = xgb.DMatrix(test)\n", "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n", "\n", "    # Train the model! We pass in a max of 1,600 rounds (with early stopping after 70)\n", "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n", "    mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, feval=gini_xgb, maximize=True, verbose_eval=100)\n", "\n", "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n", "    # Predict on our test data\n", "    p_test = mdl.predict(d_test, ntree_limit=mdl.best_ntree_limit)\n", "    sub['target'] += p_test/kfold"], "execution_count": null}, {"metadata": {"collapsed": true, "_cell_guid": "3397163d-aa49-4bf0-95c8-66b19f48c19f", "_uuid": "a3212193c95046e5b67008af264f0adaff514151"}, "cell_type": "code", "outputs": [], "source": ["sub.to_csv('StratifiedKFold5.csv', index=False)"], "execution_count": null}, {"metadata": {"collapsed": true, "_cell_guid": "130daa0b-16cc-486f-a46a-416559172ec1", "_uuid": "afc78fdfc89fce80b5aa82bbff17fe8f2c84c3db"}, "cell_type": "code", "outputs": [], "source": ["from xgboost import plot_importance\n", "plot_importance(mdl)\n", "plt.show()"], "execution_count": null}], "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "nbconvert_exporter": "python", "name": "python"}}, "nbformat_minor": 1, "nbformat": 4}