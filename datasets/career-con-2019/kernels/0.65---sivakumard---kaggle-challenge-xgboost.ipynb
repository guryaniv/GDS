{"cells":[{"metadata":{"_uuid":"0c806027097e3b4e00f13e289acdc28126a18246"},"cell_type":"markdown","source":"I tried to use LGBM with GPU but even after strugging to install for more than 24 hrs, resulted in various errors, FindBoost, then error 2026 and I gave up. \n<br/>But bent upon using GPU as I invested in the laptop, so I installed XGBoost with gpu. It was so easy just followed the steps.\n<br/>This kerenl uses GPU but for CPU you can cnange the params 'tree_method':'gpu_hist' to 'hist' \n<br/>With default params it scores very well 0.65!\n<br/>Thanks to the feature engineering code here https://www.kaggle.com/jsaguiar/surface-recognition-baseline/notebook"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"d7b73292e7c6f85a8ecb4e3cbfb468718928f331"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split  \nfrom sklearn.model_selection import cross_val_score\n\nimport xgboost as xgb\nimport time\n\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0988856b56b2b0bcf61ff1e5cfdc89fb07da027"},"cell_type":"code","source":"from scipy.stats import norm\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/X_train.csv\")\ntest_df = pd.read_csv(\"../input/X_test.csv\")\ny = pd.read_csv(\"../input/y_train.csv\")\nsub = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddda0cfe3c53346cc3776ccc651a709187c8c0be"},"cell_type":"code","source":"def _kurtosis(x):\n    return kurtosis(x)\n\ndef CPT5(x):\n    den = len(x)*np.exp(np.std(x))\n    return sum(np.exp(x))/den\n\ndef skewness(x):\n    return skew(x)\n\ndef SSC(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1 \n    xn_i1 = x[0:len(x)-2]  # xn-1\n    ans = np.heaviside((xn-xn_i1)*(xn-xn_i2),0)\n    return sum(ans[1:]) \n\ndef wave_length(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1 \n    return sum(abs(xn_i2-xn))\n    \ndef norm_entropy(x):\n    tresh = 3\n    return sum(np.power(abs(x),tresh))\n\ndef SRAV(x):    \n    SRA = sum(np.sqrt(abs(x)))\n    return np.power(SRA/len(x),2)\n\ndef mean_abs(x):\n    return sum(abs(x))/len(x)\n\ndef zero_crossing(x):\n    x = np.array(x)\n    x = np.append(x[-1], x)\n    x = np.append(x,x[1])\n    xn = x[1:len(x)-1]\n    xn_i2 = x[2:len(x)]    # xn+1\n    return sum(np.heaviside(-xn*xn_i2,0))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51898308d9507b96ea5baa41be4c7312c2579316"},"cell_type":"code","source":"def feature_extraction(raw_frame):\n    frame = pd.DataFrame()\n    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n    \n    for col in raw_frame.columns[3:]:\n        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()        \n        frame[col + '_CPT5'] = raw_frame.groupby(['series_id'])[col].apply(CPT5) \n        frame[col + '_SSC'] = raw_frame.groupby(['series_id'])[col].apply(SSC) \n        frame[col + '_skewness'] = raw_frame.groupby(['series_id'])[col].apply(skewness)\n        frame[col + '_wave_lenght'] = raw_frame.groupby(['series_id'])[col].apply(wave_length)\n        frame[col + '_norm_entropy'] = raw_frame.groupby(['series_id'])[col].apply(norm_entropy)\n        frame[col + '_SRAV'] = raw_frame.groupby(['series_id'])[col].apply(SRAV)\n        frame[col + '_kurtosis'] = raw_frame.groupby(['series_id'])[col].apply(_kurtosis) \n        frame[col + '_mean_abs'] = raw_frame.groupby(['series_id'])[col].apply(mean_abs) \n        frame[col + '_zero_crossing'] = raw_frame.groupby(['series_id'])[col].apply(zero_crossing) \n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78611fc2e19e595dc83e82dbb2e057cb6a1bc723"},"cell_type":"code","source":"def missing_data(data):\n    total = data.isnull().sum()\n    percent = (data.isnull().sum()/data.isnull().count()*100)\n    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n    types = []\n    for col in data.columns:\n        dtype = str(data[col].dtype)\n        types.append(dtype)\n    tt['Types'] = types\n    return(np.transpose(tt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"106feb19c747ee585caf839fc943154f183b46f5"},"cell_type":"code","source":"def multiclass_accuracy(preds, train_data):\n    labels = train_data.get_label()\n    pred_class = np.argmax(preds.reshape(9, -1).T, axis=1)\n    return 'multi_accuracy', np.mean(labels == pred_class), True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a727538a038142dd3c0897c31bf8d48f8a4999de"},"cell_type":"code","source":"train_df=feature_extraction(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9bf5b18a1da43f41036183246bd0472e027a676"},"cell_type":"code","source":"test_df=feature_extraction(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e2d4149715a5ffd19eaae5b7d8b532124d83df2"},"cell_type":"code","source":"le = LabelEncoder()\ntarget = le.fit_transform(y['surface'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a75524331bb859fdef7336b5fa136ae1060467d"},"cell_type":"code","source":"# Create 0.75/0.25 train/test split\nX_train, X_test, y_train, y_test = train_test_split(train_df, target, test_size=0.25, train_size=0.75,\n                                                    random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ca43d0ef763df3a344e7fae0921c7c25c7412ae"},"cell_type":"code","source":"# Leave most parameters as default\nparam = {'objective': 'multi:softmax', # Specify multiclass classification\n         'num_class': 9, # Number of possible output classes\n         'tree_method': 'hist' # Use gpu_hist for GPU accelerated algorithm.\n         }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebef9bad11d499c3dc6695479aacacce3f1af0d3"},"cell_type":"code","source":"# Convert input data from numpy to XGBoost format\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndtest = xgb.DMatrix(X_test, label=y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed2d1beca0144a75ab8807d819144fe44c1c8e2b"},"cell_type":"code","source":"dtext_X = xgb.DMatrix(test_df)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"55d62035a46cc4af2c5ab76ca7fbdf3626a59573"},"cell_type":"code","source":"num_round = 500\ngpu_res = {} # Store accuracy result\ntmp = time.time()\n# Train model\nbst=xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=gpu_res)\nprint(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp))) #tried to time it aganst GPU ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52f83e48c112c11568fedc09a0f86c41b98ffc38"},"cell_type":"code","source":"predictions = bst.predict(dtext_X)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"082d200920ea0b8240f463175ee369dadd13e078"},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(predictions.astype(int))\nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1951db5caade8f04aedf6cf8dfad651582720050"},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3be0c1b37458053cbf48c0a01889f8360d733bd"},"cell_type":"code","source":"# Leave most parameters as default\nparam = {'objective': 'multi:softprob', # usieng Probilities for multiclass classification\n         'num_class': 9, # Number of possible output classes\n         'tree_method': 'gpu_hist' \n         }","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":false,"_uuid":"bfb18674dcba3a5efbc8f343cb8e5fa211dbfcef"},"cell_type":"code","source":"num_round = 500 \ngpu_res = {} # Store accuracy result\ntmp = time.time()\n# Train model\nbst=xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=gpu_res)\nprint(\"GPU Training Time: %s seconds\" % (str(time.time() - tmp))) #tried to time it aganst GPU ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c26bf7cafa745c4bd6a8a9128ef91f88abdedf9"},"cell_type":"code","source":"predictions = bst.predict(dtext_X)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eaf052e8b0010dfd60629c1cb8c5c4e5437b4e0"},"cell_type":"code","source":"predictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9723761fdbdba252623b5e8f056105147541205"},"cell_type":"code","source":"sub['surface'] = le.inverse_transform(predictions.argmax(axis=1))\nsub.to_csv('submission-xgb-prob.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}