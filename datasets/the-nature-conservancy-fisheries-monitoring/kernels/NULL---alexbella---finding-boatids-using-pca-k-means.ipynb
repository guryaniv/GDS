{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "47b81592-85e5-e1e1-e922-9002636e938f"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0cb9ace8-6040-a675-d739-ab87a8e4a3a1"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1ec77db7-e889-394a-4c09-7e1517ae5df2"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import RandomizedPCA\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b74a982a-e1d4-cc21-fe24-8c640db73326"
      },
      "outputs": [],
      "source": [
        "def get_im_cv2(path):\n",
        "    img = cv2.imread(path)\n",
        "    resized = cv2.resize(img, (32, 32), cv2.INTER_LINEAR)\n",
        "    return resized\n",
        "\n",
        "\n",
        "def load_train():\n",
        "    X_train = []\n",
        "    X_train_id = []\n",
        "    y_train = []\n",
        "    start_time = time.time()\n",
        "\n",
        "    print('Read train images')\n",
        "    folders = ['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']\n",
        "    for fld in folders:\n",
        "        index = folders.index(fld)\n",
        "        print('Load folder {} (Index: {})'.format(fld, index))\n",
        "        path = os.path.join('..', 'input', 'train', fld, '*.jpg')\n",
        "        files = glob.glob(path)\n",
        "        for fl in files:\n",
        "            flbase = os.path.basename(fl)\n",
        "            img = get_im_cv2(fl)\n",
        "            X_train.append(img)\n",
        "            X_train_id.append(fl)\n",
        "            y_train.append(index)\n",
        "\n",
        "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
        "    return X_train, y_train, X_train_id\n",
        "\n",
        "\n",
        "def read_and_normalize_train_data():\n",
        "    train_data, train_target, train_id = load_train()\n",
        "\n",
        "    print('Convert to numpy...')\n",
        "    train_data = np.array(train_data, dtype=np.uint8)\n",
        "    train_target = np.array(train_target, dtype=np.uint8)\n",
        "\n",
        "    print('Reshape...')\n",
        "    train_data = train_data.transpose((0, 3, 1, 2))\n",
        "\n",
        "    print('Convert to float...')\n",
        "    train_data = train_data.astype('float32')\n",
        "    train_data = train_data / 255\n",
        "    train_target = np_utils.to_categorical(train_target, 8)\n",
        "\n",
        "    print('Train shape:', train_data.shape)\n",
        "    print(train_data.shape[0], 'train samples')\n",
        "    return train_data, train_target, train_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "721440bb-af98-9e91-9ef2-8c9754942bdc"
      },
      "outputs": [],
      "source": [
        "train_x, train_y, train_id = read_and_normalize_train_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f41621c-6c34-25ee-59d9-7e05e13b8d75"
      },
      "outputs": [],
      "source": [
        "np_x = np.array(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "126d69d3-8824-58a7-146f-65a220487b8d"
      },
      "outputs": [],
      "source": [
        "data_final = np_x.reshape(3777, 3072)\n",
        "data_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d1d979b-408b-19cc-64d8-6f15a1c6f8cd"
      },
      "outputs": [],
      "source": [
        "n_components = 50\n",
        "pca = RandomizedPCA(n_components=n_components, whiten=True).fit(data_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9494a430-e15e-be66-fcf4-0bc1d1150a55"
      },
      "outputs": [],
      "source": [
        "x_train_pca = pca.transform(data_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7422ae08-10b3-4dc3-0af2-373f64137f6d"
      },
      "outputs": [],
      "source": [
        "n_boats = 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f968c33d-e798-fefa-3553-9070d9c805c1"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=n_boats, random_state=0).fit(x_train_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d8683c6-f099-5543-93d0-625ab380cf8c"
      },
      "outputs": [],
      "source": [
        "predicted_labels = kmeans.predict(x_train_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de6b5ac0-b806-95d6-0d8c-94d5d34888f7"
      },
      "outputs": [],
      "source": [
        "predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eed82ed9-8f3f-d61d-d33a-d3d79259284c"
      },
      "outputs": [],
      "source": [
        "# checking for redundant image file strings across the fish-folders\n",
        "len(np.unique(np.array(train_id))) == len(train_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d84f8938-cafe-90e9-1bbc-51294d6863e4"
      },
      "outputs": [],
      "source": [
        "# NDA doesn't allow images in public notebook.\n",
        "# Run this code in local notebook to see the clustering results. Spoiler: clusters look fine ;-)\n",
        "for cluster in range(0, kmeans.n_clusters):\n",
        "    cluster_counter = 0\n",
        "    cluster_predictions = predicted_labels == cluster\n",
        "    \n",
        "    _, ax = plt.subplots(2, 4, sharex='col', sharey='row', figsize=(10, 3))\n",
        "    plt.suptitle(\"Cluster No.{}\".format(cluster + 1, size=20))\n",
        "                 \n",
        "    for idx in range(0, len(cluster_predictions)):\n",
        "        if cluster_predictions[idx]:\n",
        "            img = mpimg.imread(train_id[idx])\n",
        "            ax[cluster_counter // 4, cluster_counter % 4].imshow(img)\n",
        "            cluster_counter += 1\n",
        "            if (cluster_counter == 8):\n",
        "                break\n",
        "                \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "966c05fd-87a7-36bf-4090-4e690530ec5d"
      },
      "source": [
        "Works pretty well, even without any tuning!\n",
        "\n",
        "TODO: tweak the amount of components for PCA and the amount of clusters in kMeans (= number of boats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ffb4cff8-8c9e-f6c6-4f6c-8b3f37752310"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}