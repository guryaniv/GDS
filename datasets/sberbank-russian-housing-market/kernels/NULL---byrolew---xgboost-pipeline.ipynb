{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2ae4d9e6-a98f-c6a4-134d-22745ba18b5f"
      },
      "source": [
        "Wzorowa\u0142am si\u0119 na https://www.kaggle.com/bguberfain/naive-xgb-lb-0-317. Niestety moje pr\u00f3by pogorszy\u0142y wynik zamiast polepszy\u0107, ale bardzo trudno by\u0142o sprawdza\u0107 poprawno\u015b\u0107 wyniku, gdy\u017c w walidacji krzy\u017cowej wyniki wychodzi\u0142y du\u017co gorsze, a przede wszystkim zupe\u0142nie inne ni\u017c p\u00f3\u017aniej na zbiorze testowym. Ma to zapewne zwi\u0105zek z charakterem danych (szereg czasowy) i faktem, \u017ce dane testowe pochodz\u0105 z p\u00f3\u017aniejszego okresu ni\u017c dane treningowe. Warto by\u0142oby budowa\u0107 zbi\u00f3r walidacyjnie w analogiczny spos\u00f3b. W stosunku do powy\u017cszego notebooka zdecydowa\u0142am si\u0119 zaimplementowa\u0107 ca\u0142y proces przetwarzania i modelowania danych jako pipeline, kt\u00f3ry jest du\u017co czytelniejszym i \u0142atwiejszym w p\u00f3\u017aniejszym utrzymaniu sposobem.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c06e864f-5639-8cf8-57f3-cb8977b53eab"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from scipy import sparse as sp\n",
        "from sklearn.pipeline import make_pipeline, make_union\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import Imputer, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import make_scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60da4661-4ebc-f730-3d35-fc286cf3f303"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('../input/train.csv')\n",
        "df_macro = pd.read_csv('../input/macro.csv')\n",
        "df_test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f892f3b0-84eb-a793-711c-047f40723767"
      },
      "outputs": [],
      "source": [
        "# Join with macro variables\n",
        "df_all = pd.concat([df_train, df_test])\n",
        "df = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "38247205-1c64-4318-2082-0df5dfcbc604"
      },
      "outputs": [],
      "source": [
        "# Change what we can to floats\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == int:\n",
        "        df[col] = df[col].astype(float).copy()\n",
        "    elif df[col].dtype != float:\n",
        "        df.loc[df[col].str.contains('^no$', na=False), col] = 0.0\n",
        "        df.loc[df[col].str.contains('^yes$', na=False), col] = 1.0\n",
        "        try:\n",
        "            df[col] = df[col].astype(float).copy()\n",
        "        except ValueError:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d61cab71-7379-93fc-fee5-26809d8a94a2"
      },
      "outputs": [],
      "source": [
        "# Change again to train and final test\n",
        "df_all = df[np.isfinite(df['price_doc'])]\n",
        "df_final_test = df[~ np.isfinite(df['price_doc'])]\n",
        "\n",
        "x_final = df_final_test.drop(['price_doc', 'id'], axis=1)\n",
        "y_final = df_final_test['price_doc']\n",
        "id_test = df_final_test['id']\n",
        "\n",
        "y_train = df_all['price_doc']\n",
        "x_train = df_all.drop(['price_doc', 'id'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f074b1b-ecf9-a5d9-fd50-15f55745aa12"
      },
      "outputs": [],
      "source": [
        "# Selector coumns by name or type\n",
        "class PandasSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, dtype=None, columns=None, inverse=False,\n",
        "                 return_vector=True):\n",
        "        self.dtype = dtype\n",
        "        self.columns = columns\n",
        "        self.inverse = inverse\n",
        "        self.return_vector = return_vector\n",
        "\n",
        "    def check_condition(self, x, col):\n",
        "        cond = (self.dtype is not None and x[col].dtype == self.dtype) or \\\n",
        "               (self.columns is not None and col in self.columns)\n",
        "        return self.inverse ^ cond\n",
        "\n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "\n",
        "    def _check_if_all_columns_present(self, x):\n",
        "        if not self.inverse and self.columns is not None:\n",
        "            missing_columns = set(self.columns) - set(x.columns)\n",
        "            if len(missing_columns) > 0:\n",
        "                missing_columns_ = ','.join(col for col in missing_columns)\n",
        "                raise KeyError('Keys are missing in the record: %s' %\n",
        "                               missing_columns_)\n",
        "\n",
        "    def transform(self, x):\n",
        "        # check if x is a pandas DataFrame\n",
        "        if not isinstance(x, pd.DataFrame):\n",
        "            raise KeyError('Input is not a pandas DataFrame')\n",
        "\n",
        "        selected_cols = []\n",
        "        for col in x.columns:\n",
        "            if self.check_condition(x, col):\n",
        "                selected_cols.append(col)\n",
        "\n",
        "        # if the column was selected and inversed = False make sure the column\n",
        "        # is in the DataFrame\n",
        "        self._check_if_all_columns_present(x)\n",
        "\n",
        "        # if only 1 column is returned return a vector instead of a dataframe\n",
        "        if len(selected_cols) == 1 and self.return_vector:\n",
        "            return np.array(x[selected_cols[0]])\n",
        "        else:\n",
        "            return np.array(x[selected_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52e68435-9ea1-1a65-8b3e-eac2ffad3167"
      },
      "outputs": [],
      "source": [
        "# Converter fron string to int (for one hot encoder)\n",
        "class StringConverter(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.map = {} # column : string : int\n",
        "    \n",
        "    def fit(self, X, *args):\n",
        "        for col in range(X.shape[1]):\n",
        "            self.map[col] = {}\n",
        "            idx = 1\n",
        "            for row in range(X.shape[0]):                \n",
        "                s = X[row, col]\n",
        "                if s not in self.map[col]:\n",
        "                    self.map[col][s] = idx\n",
        "                    idx += 1\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_int = np.zeros(shape=X.shape)\n",
        "        for col in range(X.shape[1]):\n",
        "            X_int[:, col] = np.array([self.map[col].get(s, 0) for s in X[:, col]])\n",
        "\n",
        "        return X_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7a4ef65-2237-3498-0f8c-31717930821f"
      },
      "outputs": [],
      "source": [
        "# Adds a column in sparse matrix (because of bug in xgboost)\n",
        "class AddDummy(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, *args):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return sp.hstack([X, sp.csr_matrix(np.ones((X.shape[0], 1)))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fcda22cc-0301-9c7f-6c85-2fbd5d1c9b38"
      },
      "outputs": [],
      "source": [
        "# Adds features based on date\n",
        "class DatesFeaturer(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.month_year_map = {}\n",
        "        self.week_year_map = {}\n",
        "    \n",
        "    def fit(self, df, *args):\n",
        "        month_year = pd.to_datetime(df.timestamp).dt.month + pd.to_datetime(df.timestamp).dt.year * 100\n",
        "        self.month_year_map = month_year.value_counts().to_dict()\n",
        "        week_year = pd.to_datetime(df.timestamp).dt.weekofyear + pd.to_datetime(df.timestamp).dt.year * 100\n",
        "        self.week_year_map = week_year.value_counts().to_dict()\n",
        "        return self\n",
        "    \n",
        "    def transform(self, df):\n",
        "        month_year = pd.to_datetime(df.timestamp).dt.month + pd.to_datetime(df.timestamp).dt.year * 100\n",
        "        week_year = pd.to_datetime(df.timestamp).dt.weekofyear + pd.to_datetime(df.timestamp).dt.year * 100\n",
        "        \n",
        "        new_df = pd.DataFrame({\n",
        "            'month_year_count': month_year.map(self.month_year_map),\n",
        "            'week_year_count': week_year.map(self.week_year_map),\n",
        "            'month': pd.to_datetime(df.timestamp).dt.month,\n",
        "            'dow': pd.to_datetime(df.timestamp).dt.dayofweek\n",
        "        })\n",
        "        \n",
        "        return np.array(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5df06cf3-80a6-0b47-bfff-231a2afd5bb7"
      },
      "outputs": [],
      "source": [
        "# Adds relative features\n",
        "class RelativeFeaturer(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def fit(self, df, *args):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, df):   \n",
        "        new_df = pd.DataFrame({\n",
        "            'rel_floor': df['floor'] / np.maximum(1.0, df['max_floor'].astype(float)),\n",
        "            'rel_kitch_sq': df['kitch_sq'] / np.minimum(1.0, df['full_sq'].astype(float)),\n",
        "        })\n",
        "        return np.array(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3ff36947-223e-25e3-5c8e-686b836e3513"
      },
      "outputs": [],
      "source": [
        "# Converts estimator to transform in order to ensemble many estimators\n",
        "class EstimatorToTransform(BaseEstimator, TransformerMixin):    \n",
        "    def __init__(self, estimator):\n",
        "        self.estimator = estimator\n",
        "    \n",
        "    def fit(self, X, *args):\n",
        "        self.estimator.fit(X, *args)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        pred = self.estimator.predict(X)\n",
        "        return pred.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30ac1ab2-defd-b434-7fa9-cf563b0e7cf9"
      },
      "outputs": [],
      "source": [
        "def rmsle_score(pred, true):\n",
        "    return (np.sum((np.log(1 + pred) - np.log(1 + true))**2) / len(pred))**0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a0b048c-7b2e-064e-db05-39507d62b350"
      },
      "outputs": [],
      "source": [
        "# Defining pipelines\n",
        "\n",
        "float_pipeline = make_pipeline(\n",
        "    PandasSelector(dtype=float),\n",
        ")\n",
        "\n",
        "eco_pipeline = make_pipeline(\n",
        "    PandasSelector(columns=['ecology'], return_vector=False),\n",
        "    StringConverter(),\n",
        "    OneHotEncoder(),\n",
        ")\n",
        "\n",
        "prod_pipeline = make_pipeline(\n",
        "    PandasSelector(columns=['product_type'], return_vector=False),\n",
        "    StringConverter(),\n",
        "    OneHotEncoder(),\n",
        ")\n",
        "\n",
        "sub_pipeline = make_pipeline(\n",
        "    PandasSelector(columns=['sub_area'], return_vector=False),\n",
        "    StringConverter(),\n",
        "    OneHotEncoder(),\n",
        ")\n",
        "\n",
        "dates_pipeline = make_pipeline(\n",
        "    DatesFeaturer(),\n",
        ")\n",
        "\n",
        "rel_pipeline = make_pipeline(\n",
        "    RelativeFeaturer(),\n",
        ")\n",
        "\n",
        "pipeline_ensemble = make_pipeline(\n",
        "    make_union(\n",
        "        EstimatorToTransform(\n",
        "            xgb.XGBRegressor(\n",
        "                n_estimators=500,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=5,\n",
        "                subsample=0.7,\n",
        "                colsample_bytree=0.7,\n",
        "                objective='reg:linear',\n",
        "            ),\n",
        "        ),\n",
        "        EstimatorToTransform(\n",
        "            xgb.XGBRegressor(\n",
        "                n_estimators=100,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                subsample=1,\n",
        "                colsample_bytree=1,\n",
        "                objective='reg:linear',\n",
        "            ),\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "final_pipeline = make_pipeline(\n",
        "    make_union(\n",
        "        rel_pipeline,\n",
        "        dates_pipeline,\n",
        "        float_pipeline,\n",
        "        eco_pipeline,\n",
        "        prod_pipeline,\n",
        "        sub_pipeline,\n",
        "    ),\n",
        "    AddDummy(),\n",
        "    Imputer(),\n",
        "    pipeline_ensemble,\n",
        "    LinearRegression(),\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d62ccd60-5fb9-ab2b-fa65-846464d8f2b6"
      },
      "outputs": [],
      "source": [
        "# Calculate cross-validate score\n",
        "\n",
        "cv_score = cross_val_score(\n",
        "        final_pipeline,\n",
        "        x_train,\n",
        "        y_train,\n",
        "        scoring=make_scorer(rmsle_score),\n",
        "        cv=3,\n",
        ")\n",
        "\n",
        "np.mean(cv_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86fcb679-ce46-6e87-c1f7-d5009b3c3c97"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Fitting model\n",
        "model = final_pipeline.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "21ac3629-3285-ce1f-9a51-0b9d0413a152"
      },
      "outputs": [],
      "source": [
        "pred_train = model.predict(x_train)\n",
        "print(rmsle_score(pred_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8191081-1c98-764c-c776-d64dab2f1a86"
      },
      "outputs": [],
      "source": [
        "# Predicting\n",
        "final_pred = model.predict(x_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34b2b0ae-2c2d-b313-a823-f4ab4c1d56bf"
      },
      "outputs": [],
      "source": [
        "# Creating final submission file\n",
        "df_sub = pd.DataFrame({'id': id_test.astype(int), 'price_doc': final_pred.astype(int)})\n",
        "df_sub.to_csv('sub.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}