{"cells":[{"metadata":{"_uuid":"42ce28948c8a0a22778a5ad1c80ff6f9a2dcc007"},"cell_type":"markdown","source":"Hi all,\nThis is my first kernel and is related to LightGBM for Santander value prediction challenge. \nI will be updating this kernel with more algorithms in the future.\n\nThanks"},{"metadata":{"_uuid":"f81e00f1a594d6927e8021ec1a541cc3cd637001"},"cell_type":"markdown","source":"### Importing required libraries"},{"metadata":{"trusted":true,"_uuid":"c9c5eaadc6367b19f3d2240cf2dc739139052120","collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib\nimport seaborn as sns\nimport plotly.plotly as py\n%matplotlib inline\nimport plotly\nimport sklearn\nimport pymongo\nimport json\nsklearn.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ce4510a7b001575dee222a9db9d0aa7485d02df5"},"cell_type":"code","source":"import itertools\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats import ks_2samp\nfrom sklearn.preprocessing import scale, MinMaxScaler\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn import manifold\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37a43841b25c726849fa6aa4228ac5b461eea46f"},"cell_type":"markdown","source":"### Importing Data and Overview"},{"metadata":{"trusted":true,"_uuid":"eeeab8c363dcabc662bdff4d3615c5242d085b39","collapsed":true},"cell_type":"code","source":"sample = pd.read_csv('../input/sample_submission.csv')\ntest_df = pd.read_csv('../input/test.csv')\ntrain_df = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6afce9116d59a190a7e0110a8775fb28808074d","collapsed":true},"cell_type":"code","source":"print (train_df.shape)\nprint (test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"93c3645012fd5f64180419eedb94e23faa6eff9d","collapsed":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3eac5f13f6fdad2595fc39c886227bcf9493a40","collapsed":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5049d46318c6718f9d64420c4218187cb47e174"},"cell_type":"markdown","source":"### We can see lot of zeroes in both the test and the train data. Checking features having 99% of data as zeroes."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"279ea5c68eae2b9febdc1b0ac7c7231ba821cd1f"},"cell_type":"code","source":"cols_and_zeroes = []\nfor col in train_df.columns:\n    no_of_zeroes = []\n    cols_dict = {}\n    aa = (train_df[col].value_counts())\n    for key, value in aa.iteritems():\n        if key==0:\n            per = int(value * 100 / 4459)\n            cols_dict[col] = int(per)\n            cols_and_zeroes.append(cols_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e28ee379a4948c12c962381d4e67f80804460a13"},"cell_type":"code","source":"l= []\nfor i in cols_and_zeroes:\n    for k,v in i.items():\n        if v>=98:\n            l.append(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fb5d9cf6ce9a8c5164a6efc25f2a2fba3989516","collapsed":true},"cell_type":"code","source":"print (len(l))\ntrain_df.drop(l, axis=1, inplace=True)\ntest_df.drop(l, axis=1, inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13b7071e1bfa57825d11b6f06df5f256ea7981cb","collapsed":true},"cell_type":"code","source":"train_df.shape\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bc2923e892ef7ff722d6f4a62ceb205ce222569"},"cell_type":"markdown","source":"### Columns removed with std dev of zero"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"90505e8e46130bf112b16887241834b51eabb64e"},"cell_type":"code","source":"cols_to_remove = []\nfor col in train_df.columns:\n    if col != 'ID':\n        if train_df[col].std() == 0:\n            cols_to_remove.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cd2083b23948d4cf6be5e240afe5ef8415d23456"},"cell_type":"code","source":"train_df.drop(cols_to_remove, axis=1, inplace=True)\ntest_df.drop(cols_to_remove, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4cd5f4e9822889ac2886bccf4276a8635be91643","collapsed":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e30723a1288b6cb8509a7204d8044a88fea4268","collapsed":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f462cc81872ae8f71dd38dd5c0bd9ebba02a3f0"},"cell_type":"markdown","source":"### Correlation Coefficient"},{"metadata":{"trusted":true,"_uuid":"f2d5fd1508f7a68a1088166da03198bbc62be2ad","collapsed":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"54aee9516e17830821e577726dcdd3fa26a879f9","collapsed":true},"cell_type":"code","source":"corrcoefficient = []\nfor i in range (2,2123):\n    cor = train_df.iloc[:,1].corr(train_df.iloc[:,i])\n    corrcoefficient.append(cor)\n    \nplt.hist(corrcoefficient, normed=True, bins=10)\nplt.xlabel('Correlation Coefficeint with target variable');\nplt.ylabel('Frequency');\nplt.title('Histogram of correlation coefficient of features with target variable');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91f05bdd468acfd2680524321b8638c3c9e37ffc"},"cell_type":"markdown","source":"### One can see that the correlation coefficient is low for all of the features with the target variable."},{"metadata":{"trusted":true,"_uuid":"9c0d674ebfa7f285293516159b81351614d71e52","collapsed":true},"cell_type":"code","source":"target = train_df.iloc[:,1]\nhis = plt.hist(target, normed=True, bins=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3acbe5f3893845c626f79b8dcb64465b71a00dff","collapsed":true},"cell_type":"code","source":"log_target = np.log(target)\nhis_log = plt.hist(log_target, normed=True, bins=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcddebf854973c7ddab71095737e20c066573ec4"},"cell_type":"markdown","source":"### Log of the target distribution shows better variation. Hence log of the target variable will be used as the target variable in ML algorithms"},{"metadata":{"_uuid":"a34786bfae236f1d93b0ae1897aa5186441130ae"},"cell_type":"markdown","source":"### Transform and Dimensionality Reduction (PCA)"},{"metadata":{"trusted":true,"_uuid":"db2152526947d7d92df0ef1ced81cb34f55d7083","collapsed":true},"cell_type":"code","source":"train=train_df.iloc[:,2:].values\ntest=test_df.iloc[:,1:].values\nprint('Shape of train: ',train.shape)\nprint('Shape of target: ',log_target.shape)\nprint('Shape of test: ',test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a49311790e1b7d09115e3f57a688e2c47d40143d"},"cell_type":"code","source":"def transform (dataframe):\n    from sklearn.preprocessing import StandardScaler\n    scaler = StandardScaler()\n    scaled_data = scaler.fit_transform(dataframe)\n    return pd.DataFrame(scaled_data)\n\ntrain = transform(train)\ntest = transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2909ca7032d6193713b5422120fdde290d54ad59"},"cell_type":"code","source":"def get_PCA(DATAFRAME,NUMBER_OF_COMPONENTS):\n    from sklearn.decomposition import PCA\n    pca = PCA(n_components=NUMBER_OF_COMPONENTS)\n    pca.fit(DATAFRAME)\n    DF_RETURN = pca.transform(DATAFRAME)\n    print (\"data frame shape: %f %f\" %DF_RETURN.shape)\n    #print pca.explained_variance_ratio_\n    zzz = pca.explained_variance_ratio_\n    plt.plot(zzz.cumsum())\n    plt.xlabel('Number of Components');\n    plt.ylabel('Cumulative Variance Ratio');\n    plt.title('PCA Variance ratio of first 1500 components');\n    return pd.DataFrame(DF_RETURN)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"b76769dda59c687cbeb6001c66af925a97e9ab86","collapsed":true},"cell_type":"code","source":"a = get_PCA(train,1500)\nb = get_PCA(test,1500)\nprint (log_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"351170af54a6e7b4da3253c2a0d5abf896c51e5f"},"cell_type":"markdown","source":"### From the above graph it is seen that 1500 components explains around 95% of the variance in the  training data"},{"metadata":{"trusted":true,"_uuid":"a273375924883e711e57333771790255380cc4c3","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#X_train, X_val, y_train, y_val = train_test_split(train, test, test_size=0.2, random_state=0)\nX_train, X_target, Y_train, Y_target = train_test_split(a, log_target, test_size=0.30, random_state=101)\n#Y_train, Y_test = train_test_split(test, test_size=0.20, random_state=101)\n\nprint (X_train.shape,Y_train.shape)\nprint (X_target.shape, Y_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2c83cadbd578a3ac3c724f20020167add3ec32f"},"cell_type":"markdown","source":"### Hyperparamter tuning for LightGBM using GridSearchCV "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"909f8d186275a8a8e687605876b3762cbf64db41"},"cell_type":"code","source":"'''# coding: utf-8\n# pylint: disable = invalid-name, C0111\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nprint('Start training...')\nimport timeit\nstart = timeit.default_timer()\n\n\n# other scikit-learn modules\nestimator = lgb.LGBMRegressor()\n\nparam_grid = {\n    'max_depth': [8,10,12,14],\n    'learning_rate': [0.001, 0.01, 0.1, 1],\n    'n_estimators': [20, 40, 60, 80],\n    'bagging_fraction' : [0.00001, 0.0001,0.001, 0.01, 0.1],\n    'num_leaves': [60, 90, 120, 150]\n}\n\ngbm = GridSearchCV(estimator, param_grid)\n\ngbm.fit(a, log_target)\n\nprint('Best parameters found by grid search are:', gbm.best_params_)\n\nstop = timeit.default_timer()\nprint stop - start'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de02a5012189638218812dd98e667e20bfa66ec9"},"cell_type":"markdown","source":"('Best parameters found by grid search are:', {'max_depth': 12}\n('Best parameters found by grid search are:', {'learning_rate': 0.1})\n('Best parameters found by grid search are:', {'n_estimators': 40})\n('Best parameters found by grid search are:', {'bagging_fraction': 1e-05})\n('Best parameters found by grid search are:', {'num_leaves': 90})"},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"a058cedd2b3c3e5303615e66dab670c34f077cf4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"828fcef5a2ec532eb7b7762bfbe865e116e1eef5"},"cell_type":"markdown","source":"### Machine Learning Algorithms - LightGBM"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c4c5d755ea262e326f3d19f5d8f4403db0312d0f"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import mean_squared_log_error,mean_squared_error\nimport lightgbm\n#lgbm = LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8092ceb7f3f9003921c234145e735a7081a5c9dc"},"cell_type":"code","source":"train_data=lightgbm.Dataset(X_train,Y_train)\nvalid_data = lightgbm.Dataset(X_target,Y_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37fe9ab383600136e34c43bb2c8829ae5a406fee","collapsed":true},"cell_type":"code","source":"params={'learning_rate':0.1,\n        'boosting_type':'gbdt',\n        'objective':'regression',\n        'metric':'rmse',\n        'sub_feature':0.5,\n        'num_leaves':90,\n        'feature_fraction': 0.5,\n        'bagging_fraction': 1e-05,\n        'min_data':50,\n        'max_depth':12,\n        'reg_alpha': 0.3, \n        'reg_lambda': 0.1, \n        'min_child_weight': 10, \n        'verbose': 1,\n        'nthread':5,\n        'max_bin':512,\n        'subsample_for_bin':200,\n        'min_split_gain':0.0001,\n        'min_child_samples':5\n       }\nlgbm = lightgbm.train(params,\n                 train_data,\n                 25000,\n                 valid_sets=valid_data,\n                 early_stopping_rounds= 80,\n                 verbose_eval= 10\n                 )\n\nprint( \" Best iteration = \", lgbm.best_iteration )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5aae79f05ce401e745144ae64d99ef998fd8bc0"},"cell_type":"markdown","source":"### LightGBM with CV"},{"metadata":{"trusted":true,"_uuid":"149bc27a1c76a6bc3fb25e57da7f8c7f30f76d2c","collapsed":true},"cell_type":"code","source":"Model_Summary = pd.DataFrame()\nmodel_name='lightgbm_rmse'\nRMSLE=np.sqrt(mean_squared_error(Y_target,lgbm.predict(X_target)))\nRMSLE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"034a2112e9045294f72caa7075c7fd77b98b4763","collapsed":true},"cell_type":"code","source":"cv_results = lightgbm.cv(params, train_data, num_boost_round=20, nfold=4, \n                    verbose_eval=10, early_stopping_rounds=80, stratified=False)\nprint (cv_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a3340d5a1cb2bf6ea2c31c8f7b4fef5c1cd3679","collapsed":true},"cell_type":"code","source":"print('Current parameters:\\n', params)\nprint('\\nBest num_boost_round:', len(cv_results['rmse-mean']))\nprint('Best CV score:', cv_results['rmse-mean'][-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b1d6feab6e186b7ec98db63e04ab2ac1b497aa1","collapsed":true},"cell_type":"code","source":"pred_lgbm=np.expm1(lgbm.predict(test))\nhistogram = plt.hist(pred_lgbm, normed=True, range = [1000000,3000000])\npred_lgbm.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d4a6806e92eaa58f7d4e7d13a2ab3f4ba660bcc0"},"cell_type":"code","source":"sub_1 = pd.DataFrame()\nsub_1['ID'] = test_df.iloc[:,0]\nsub_1['target'] = pred_lgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e5a11284274d2be266b32b16189221631102c8c4"},"cell_type":"code","source":"sub_1.to_csv('sub_1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07bdb4b3541e6cfe156c8da2548be1fb6cc60582"},"cell_type":"markdown","source":"## END"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}