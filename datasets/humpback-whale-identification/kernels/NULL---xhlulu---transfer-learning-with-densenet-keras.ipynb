{"cells":[{"metadata":{"_uuid":"70d2764d37a848371095624eb8f4233c6239ede1"},"cell_type":"markdown","source":"# CNN Starter with DenseNet in Keras\n\nThis a fork of the preprocessing phase, described here: https://www.kaggle.com/xhlulu/exploration-and-preprocessing-for-keras-224x224\n\nThe resulting files are:\n* `X_train`: 25361x224x224x3\n* `X_test`: 7960x224x224x3\n* `y_train`: 25361x5005\n\nUsing those files, I will show how to perform data augmentation and transfer learning."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nfrom PIL import Image, ImageOps\nimport math\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport time\nimport gc\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9d36f20119e79921ac19f483fa5a59abeb4af95"},"cell_type":"markdown","source":"## Exploration"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"label_df = pd.read_csv('../input/humpback-whale-identification/train.csv')\nsubmission_df = pd.read_csv('../input/humpback-whale-identification/sample_submission.csv')\nlabel_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c9e5b61f7515d0a7366c3e36d66dc25a01c674b"},"cell_type":"code","source":"label_df['Id'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10a375a7e3ee8e463fedd668170230c8459cd0a4"},"cell_type":"code","source":"# Display the most frequent ID (without counting new_whale)\nlabel_df['Id'].value_counts()[1:16].plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"1ace90356946feaf6e2a8111308c94a81250c813"},"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'Image']\n        image_id = df.loc[i,'Id']\n        img = cv2.imread(f'../input/humpback-whale-identification/train/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d9dc344f755ded8606fe51ec497b215d83535d0"},"cell_type":"markdown","source":"The width of the image seem to be bigger than the height. We will have to pad the images, then resize them to 224x224x3"},{"metadata":{"_uuid":"8613b9ad48bd627b30acbc0715ba12f7d2aeb197"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"_uuid":"457582b8522fd04739b57ed3cd81585133a46076"},"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\n\ndef pad_and_resize(image_path, dataset):\n    img = cv2.imread(f'../input/humpback-whale-identification/{dataset}/{image_path}')\n    pad_width = get_pad_width(img, max(img.shape))\n    padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n    resized = cv2.resize(padded, (224,224)).astype('uint8')\n    \n    return resized","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9b73391f5bab9ebc649108027dae892de02534d"},"cell_type":"markdown","source":"### Pad and resize with cv2"},{"metadata":{"trusted":true,"_uuid":"d836765ab3393ba9a23712efea6d195e2ce61353"},"cell_type":"code","source":"img = cv2.imread(f'../input/humpback-whale-identification/train/{label_df.loc[0,\"Image\"]}')\n\npad_width = get_pad_width(img, max(img.shape))\npadded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\nresized = cv2.resize(padded, (224,224))\nplt.imshow(resized)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fa74b1edbd9f108461e01d0ad36a0001fa7c7c4"},"cell_type":"markdown","source":"### Resizing"},{"metadata":{"trusted":true,"_uuid":"18b94f376cbf5cee48ce830661d03aea813f6f9d"},"cell_type":"code","source":"train_resized_imgs = []\ntest_resized_imgs = []\n\nfor image_path in label_df['Image']:\n    train_resized_imgs.append(pad_and_resize(image_path, 'train'))\n\nfor image_path in submission_df['Image']:\n    test_resized_imgs.append(pad_and_resize(image_path, 'test'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f9420096df3a58964e7d4acbb6d39714b1c63a8"},"cell_type":"code","source":"X_train = np.stack(train_resized_imgs)\nX_test = np.stack(test_resized_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3eaef7e446ea934ef0c34ffcaaefecda13b6bb23"},"cell_type":"code","source":"target_dummies = pd.get_dummies(label_df['Id'])\ntrain_label = target_dummies.columns.values\ny_train = target_dummies.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0d304d008a01128ff12d9dfa680b37dbc62b36b"},"cell_type":"code","source":"del train_resized_imgs, test_resized_imgs\n\ngc.collect()\ntime.sleep(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4893c8187b12f9de9d0689920b1354adeb304af9"},"cell_type":"markdown","source":"### Preprocess input the same way keras does"},{"metadata":{"trusted":true,"_uuid":"907e4112a660d41deca1270fa4e4544f79516c1d"},"cell_type":"code","source":"from tensorflow.keras.applications.densenet import preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c85735f2573bdf217286f5101c11f0e867415125"},"cell_type":"code","source":"X_train = preprocess_input(X_train)\nX_test = preprocess_input(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc0d90cf28765495a8a04e40a980691d6b642234"},"cell_type":"markdown","source":"## Prepare Data For Keras"},{"metadata":{"trusted":true,"_uuid":"9331c961fd17ec8836656eb269c7678bbf2df63f"},"cell_type":"code","source":"import json\n\nfrom tensorflow.keras import layers, Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\nfrom tensorflow.keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44e2e746653406d03d9f642ccb58eb6969af999f"},"cell_type":"code","source":"densenet = DenseNet121(\n    weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\nmodel = Sequential()\nmodel.add(densenet)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(5005, activation='softmax'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44e2e746653406d03d9f642ccb58eb6969af999f"},"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=64,\n    epochs=10,\n    callbacks=[checkpoint],\n    verbose=2,\n    validation_split=0.1\n)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"e055e0e1d18c1292c58a64d9cd9660f69dd98891"},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a50599afc1a80e6686c4ac676bed0d41bc35b1c9"},"cell_type":"code","source":"model.load_weights('model.h5')\nsubmission_df['Id'] = model.predict(X_test)\nsubmission_df.to_csv('submission.csv', index=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}