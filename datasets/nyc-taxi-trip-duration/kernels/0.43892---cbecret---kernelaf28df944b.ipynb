{"cells":[{"metadata":{"_uuid":"f98bdb6da14236cce79eaba01d34e7c089a07ad4"},"cell_type":"markdown","source":"# Exercice de Machine Learning pour le cours de Data Science\n## Hétic - Janvier 2019\n## Cyril Bécret"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Importation des librairies\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3f54def2e4fcfcea68d5a1ad088d33d6f78426e"},"cell_type":"markdown","source":"## 1. Chargement des données"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load datas\n\nTRAIN_PATH = os.path.join('..', 'input', 'train.csv')\n\ndf = pd.read_csv(TRAIN_PATH, index_col=0)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18d865a8d3ac35eb4349812cea8c157f5b61fdb2"},"cell_type":"markdown","source":"## 2. Exploration des données"},{"metadata":{"trusted":true,"_uuid":"1e1465fd3cfb0ab7237983496185373591062e39"},"cell_type":"code","source":"# Affichage des informations sur le dataset\n\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d66c50a56a57c1eeef727e74a5af84055d448b2"},"cell_type":"markdown","source":"Le dataset est composé de 1458644 enregistrements qui contiennent 10 colonnes.\n\nLes colonnes sont de 4 types différents :\n* INT pour ['vendor_id', 'passenger_count', 'trip_duration']\n* Datetime object pour ['pickup_datetime', 'dropoff_datetime'] au format __%Y-%m-%d %H:%M:%S__.\n* FLOAT pour ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'] qui correspondent à des coordonnées GPS.\n* BOOLEAN pour ['store_and_fwd_flag'] stockés par 'Y' et 'N'.\n"},{"metadata":{"trusted":true,"_uuid":"47504ad093cb75644c55bd954ec87f459f99b740"},"cell_type":"code","source":"# Affichage des valeurs de répartition du dataset\n\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccf500a2ec36f3814262415ddf6d5fe965f951a4"},"cell_type":"markdown","source":"## 3. Nettoyage des données"},{"metadata":{"trusted":true,"_uuid":"06d48b5b1b8c7c0012a9d2211cea0be86aea6043"},"cell_type":"code","source":"# Recherche de valeurs dupliquées\n\ndf.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64cbb51f05f03e1d3cac3a0048b9ce91159029fe"},"cell_type":"markdown","source":"Nous constatons que 7 valeurs sont dupliquées dans ce dataset. Nous pouvons les retirer afin de ne pas biaiser notre analyse."},{"metadata":{"trusted":true,"_uuid":"7514bc13b36ebc42677491a9dc605f09edffd652"},"cell_type":"code","source":"# Suppression des enregistrements dupliqués et vérification du nombre total\n\ndf_no_duplicates = df.drop_duplicates()\ndf_no_duplicates.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e77d51ddd5bf09a72690929ff74de81acd7f1c87"},"cell_type":"code","source":"# Recherche des valeurs manquantes\n\ndf_no_duplicates.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5430c7ad38db69ec53bce611d4b57b91602121e4"},"cell_type":"markdown","source":"Aucune valeur manquante dans ce dataset. Celui-ci a été bien préparé avant d'être proposé à la compétition !"},{"metadata":{"trusted":true,"_uuid":"e0e7a284de8e3facb2f2784b378d80fb1514bc17"},"cell_type":"code","source":"# Recherche d'éventuels outliers\n\nsns.boxplot(x=df_no_duplicates['trip_duration']).set_title(\"Boxplot de la durée des trajets\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb184d9d327938fdebe4a2c881768cfdc508cddf"},"cell_type":"markdown","source":"Seule la durée des trajets présentait des valeurs extrèmes. Les autres features vérifiées ne sont donc pas montrées ici.\n\nNous constatons 4 valeurs qui sortent du lot pour la durée des trajets. Analysons celles-ci plus en détail :"},{"metadata":{"trusted":true,"_uuid":"344fae84ae7e68c6236080b81fafe0a8391a4dfa"},"cell_type":"code","source":"# Affichage des 4 outliers dont la durée du trajet dépasse 100000\n\ndf_no_duplicates.loc[df_no_duplicates['trip_duration'] > 100000]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1421df012634d2a28ec0e89edc870d588ae37040"},"cell_type":"markdown","source":"Ces 4 enregistrements ont des valeurs extrèmes de durée de trajet (+27h ...). Elles seront donc retirées du dataset pour la suite de cette étude.\nEn regardant de plus près les dates de ces courses, nous observons qu'elles ont eu lieu en janvier et mars 2016, période pendant laquelle de violentes tempêtes de neige ont touché les USA. Ces retards sont peut être donc dû à des problèmes climatiques ? Ce n'est pas l'objet de notre étude de toute façon donc contentons nous de les retirer.\n( voir : https://www.lejdd.fr/International/USA/Snowzilla-la-tempete-de-neige-fait-19-victimes-aux-Etats-Unis-769749 )"},{"metadata":{"trusted":true,"_uuid":"1c19b6388bb405e458e82e9730924aecc567b4fd"},"cell_type":"code","source":"# Suppression des outliers\n\ndf_clean = df_no_duplicates.loc[df_no_duplicates['trip_duration'] < 100000]\ndf_clean.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6604a4bcac3686942b7af82563eadb2b674e034e"},"cell_type":"markdown","source":"## 4. Feature engineering\n\nNous allons créer plusieurs nouvelles features pour aider l'entrainement de notre modèle.\n\nCommençons par la distance entre les points d'arrivés et de départ qui seront **delta_longitude** et **delta_latitude** en calculant la valeur absolue de la différence entre ces coordonnées GPS.\n\nEnsuite, **delta_total** sera la distance euclidienne entre ces deux points."},{"metadata":{"trusted":true,"_uuid":"b0df869e04fceeabf7a9947e636095059482ce75"},"cell_type":"code","source":"# Création de features de distance entre le départ et l'arrivée pour la longitude et la latitude\n\ndf_enhanced = df_clean.copy()\n\ndf_enhanced[\"delta_longitude\"] = df_clean[\"pickup_longitude\"] - df_clean[\"dropoff_longitude\"]\ndf_enhanced[\"delta_latitude\"] = df_clean[\"pickup_latitude\"] - df_clean[\"dropoff_latitude\"]\ndf_enhanced[\"delta_total\"] = np.sqrt(np.square(df_enhanced[\"delta_longitude\"]) + np.square(df_enhanced[\"delta_latitude\"]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dda3e2663d061c9eb1fac950893203a66533bd87"},"cell_type":"markdown","source":"Analysons ensuite les datetimes fournies dans les données de départ. Nous utiliserons le pickup_datetime puisqu'il correspond à la donnée connue dans les courses à prédire.\n\nNous allons extraire l'heure de la journée et les minutes.\n\nNous prendrons ensuite le jour de la semaine sous forme d'entier.\n\nEnfin nous regarderons le numéro de la semaine, toujours sous forme d'entier ainsi que le mois."},{"metadata":{"trusted":true,"_uuid":"abf842715bad8f5fdae8fddc13c0ea61eafaa3a7"},"cell_type":"code","source":"# Création de features à partir des informations du pickup_datetime\n\ndf_enhanced[\"pickup_Timestamp\"] =  pd.to_datetime(df_clean[\"pickup_datetime\"], format='%Y/%m/%d')\ndf_enhanced[\"pickup_hour\"] = df_enhanced[\"pickup_Timestamp\"].dt.strftime('%-H').astype(int)\ndf_enhanced[\"pickup_minute\"] = df_enhanced[\"pickup_Timestamp\"].dt.strftime('%-M').astype(float)\ndf_enhanced[\"pickup_daynumber\"] = df_enhanced[\"pickup_Timestamp\"].dt.strftime('%w').astype(int)\ndf_enhanced[\"pickup_month\"] = df_enhanced[\"pickup_Timestamp\"].dt.strftime('%m').astype(int)\ndf_enhanced[\"pickup_weeknumber\"] = df_enhanced[\"pickup_Timestamp\"].dt.strftime('%U').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb4b79d78f151af908e22d00eca2f9efbe0d4488"},"cell_type":"code","source":"# Selection des features\n\ndf_features = df_enhanced[['vendor_id', 'passenger_count', 'pickup_hour', 'pickup_minute', 'pickup_daynumber', 'pickup_weeknumber', 'pickup_month', 'delta_longitude', 'delta_latitude', 'delta_total']]\n\ndf_target = np.log(df_enhanced['trip_duration'].values)\ndf_features.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdfa8bd658876d7955aeda85ff4c0244b5555130"},"cell_type":"markdown","source":"## 5. Entraînement du modèle"},{"metadata":{"trusted":true,"_uuid":"752f392badb05f4ca6b266f7e12288134940dde4"},"cell_type":"code","source":"# Découpage du dataset en données d'entrainement et en données de test\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(df_features, df_target, test_size=0.1, random_state=42)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30e9c41da1a8d3011a0007a5f9d099ff6d1d2420"},"cell_type":"code","source":"# Utilisation du modèle RandomForestRegressor\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf = RandomForestRegressor(n_estimators=500, min_samples_leaf=10, min_samples_split=30, max_depth=20, random_state=42, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Entrainement du modèle RandomForestRegressor\n\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vérification du RMSE de ce modèle\n\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\nrms = sqrt(mean_squared_error(y_test, rf.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rms","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88c7d0c21fa94f5becc1b59a5337560dffb3aa9d"},"cell_type":"markdown","source":"## 6. Prédictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Chargement du dataset de soumission\n\nTEST_PATH = os.path.join('..', 'input', 'test.csv')\ntest = pd.read_csv(TEST_PATH, index_col=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculs des nouvelles features sur ce nouveau dataset\n\ntest[\"delta_longitude\"] = test[\"pickup_longitude\"] - test[\"dropoff_longitude\"]\ntest[\"delta_latitude\"] = test[\"pickup_latitude\"] - test[\"dropoff_latitude\"]\ntest[\"delta_total\"] = np.sqrt(np.square(test[\"delta_longitude\"]) + np.square(test[\"delta_latitude\"]))\n\ntest[\"pickup_Timestamp\"] =  pd.to_datetime(test[\"pickup_datetime\"], format='%Y/%m/%d')\ntest[\"pickup_hour\"] = test[\"pickup_Timestamp\"].dt.strftime('%-H').astype(int)\ntest[\"pickup_minute\"] = test[\"pickup_Timestamp\"].dt.strftime('%-M').astype(float)\ntest[\"pickup_daynumber\"] = test[\"pickup_Timestamp\"].dt.strftime('%w').astype(int)\ntest[\"pickup_weeknumber\"] = test[\"pickup_Timestamp\"].dt.strftime('%U').astype(int)\ntest[\"pickup_month\"] = test[\"pickup_Timestamp\"].dt.strftime('%m').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prédictions de la durée des trajets du dataframe de test.\n\ntest_features = test[['vendor_id', 'passenger_count', 'pickup_hour', 'pickup_minute', 'pickup_daynumber', 'pickup_weeknumber', 'pickup_month', 'delta_longitude', 'delta_latitude', 'delta_total']]\n\ny_pred = np.exp(rf.predict(test_features))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d98336686b68ee8f94392c95d5beb1f802ae8198"},"cell_type":"markdown","source":"## 7. Soumission des prédictions"},{"metadata":{"trusted":true,"_uuid":"984d546c6d75ffbb7a762f0afa3d66da8ee3825b"},"cell_type":"code","source":"# Préparation de la soumission\n\nsubmission = pd.DataFrame({'id': test.index, 'trip_duration': y_pred})\n\nsubmission.to_csv('submission.csv', index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}