{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"The audiences and subjects columns in the news data are two of the more difficult features to work with. This notebook aims to explore these features, primarily by using embeddings to see how the terms relate to one another."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nnp.random.seed(13)\nfrom matplotlib import pyplot as plt\nimport itertools\nimport scipy\nimport sklearn.decomposition\nimport sklearn.manifold\nimport json\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d15984093d2fee60fa4fe1ad02f44b0f590e995"},"cell_type":"code","source":"EMBEDDING_SIZE = 8\nMIN_OCCURRENCES = 10","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d1aef3298b83622834aa0c0ed2d3eaff99e4c547"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"trusted":true,"_uuid":"dca108d9336ba3e19d07566e19d21caaa30d3d77"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a9c5f3bbf3fa97ace8302d4e4b32640a67ddaaa"},"cell_type":"code","source":"(market_data, news_data) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"133fd3215fd9258b8e10621245824c484f184f4e"},"cell_type":"markdown","source":"### Convert the audience and subject features to tuples\n\nThe audiences and subjects featurs are strings, to make the processing easier we will convert them to tuples"},{"metadata":{"trusted":true,"_uuid":"453e7f07319e69a2a02da4db90d1b0e2eef6959d"},"cell_type":"code","source":"%%time\nnews_data['subjects_tuples'] = news_data['subjects'].copy()\nsubjects_cats = news_data['subjects_tuples'].cat.categories\nsubjects_cats = [eval(c.replace(\"{\", \"(\").replace(\"}\", \")\")) for c in subjects_cats]\nnews_data['subjects_tuples'].cat.categories = subjects_cats\n\ndel subjects_cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5be28b12801842e3a267a4209bd7cd1d2e48fa"},"cell_type":"code","source":"news_data[['assetCodes', 'time', 'subjects', 'subjects_tuples']].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2025ea0426c846807492790c516f260404dabf77"},"cell_type":"code","source":"%%time\nnews_data['audiences_tuples'] = news_data['audiences'].copy()\naudiences_cats = news_data['audiences_tuples'].cat.categories\naudiences_cats = [eval(c.replace(\"{\", \"(\").replace(\"}\", \")\")) for c in audiences_cats]\nnews_data['audiences_tuples'].cat.categories = audiences_cats\n\ndel audiences_cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d243680e9009d3f724d1f203b8d6aeb75cd8d0e"},"cell_type":"code","source":"news_data[['assetCodes', 'time', 'audiences', 'audiences_tuples']].head(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4a0bea7392d567b0a4419c34e7c64f99b9f480f"},"cell_type":"markdown","source":"## Create Embeddings\n\nTo create the embedding, first we will create a multi-hot encoded array, and then use dimensionality reduction to obtain vectors of our desired size (EMBEDDING_SIZE). To perform the multi-hot encoding we will use the following function."},{"metadata":{"trusted":true,"_uuid":"553fe6bf30546afcec0c5eb3efdfedad98a437be"},"cell_type":"code","source":"def pd_categorical_to_dummies(series, min_occurrences=0):\n    \n    features_cats_evals = series.cat.categories\n    unique_features = list(set(itertools.chain(*features_cats_evals)))\n    \n    num_unique_features = len(unique_features)\n    \n    features_map = {k:v for v, k in enumerate(unique_features)}\n    features_cats_factorized = [[features_map[k] for k in l] for l in features_cats_evals]\n    \n    features_lengths = [\n        len(features_cats_factorized[i]) \n        for i in series.cat.codes\n    ]\n    \n    features_cats_rows = np.arange(series.shape[0]).repeat(features_lengths)\n    \n    features_cats_cols = np.array([\n        v for c in \n        series.cat.codes\n        for v in features_cats_factorized[c]\n    ])\n    \n    total_length = len(features_cats_cols)\n    \n    dummies = scipy.sparse.coo_matrix(\n        (np.ones(total_length, dtype=np.bool), (features_cats_rows, features_cats_cols)),\n        shape=(series.shape[0], num_unique_features),\n        dtype=np.bool\n    )\n    \n    dummies = dummies.tocsr()\n    \n    m = dummies.sum(axis=0).A[0] > min_occurrences\n    \n    dummies = dummies[:, m]\n    unique_features = [a for a, mm in zip(unique_features, m) if mm == 1]\n    \n    return dummies, unique_features","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ab659db8da9960fac9e1b99fe5acad88c2063c"},"cell_type":"markdown","source":"This is another helper function we will use later"},{"metadata":{"trusted":true,"_uuid":"bf5d22e1f8b7fd9f36038e5c06cea101bb240a98"},"cell_type":"code","source":"def get_similar(w, embeddings, features, max_features=10):\n    \n    i = features.index(w)\n    v = embeddings[i]\n    similarities = (embeddings @ v)\n    \n    ii = np.argsort(similarities)[::-1]\n    \n    similarities = similarities[ii[:max_features + 1]]\n    \n    similar_words = [features[j] for j in ii[:max_features + 1]]\n        \n    m = similarities > 1 - 1e-6\n        \n    assert w in np.array(similar_words)[m]\n    \n    similar_words.remove(w)\n    \n    return similar_words","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61bf83117cbacba6e4ab97d8972da1948da9b31b"},"cell_type":"markdown","source":"## Subject Embedding\n\nLets start by creating an embedding for the subjects"},{"metadata":{"trusted":true,"_uuid":"fbb07e61857dbf1b009f67cd5d5d7813752af710"},"cell_type":"code","source":"%%time\nsubject_dummies, subjects = pd_categorical_to_dummies(\n    news_data['subjects_tuples'],\n    MIN_OCCURRENCES\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaaa091ee4cf39721dcac60b341e13b4405f3ce5"},"cell_type":"code","source":"subject_dummies.shape, len(subjects)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bc86c226d25902ef1774f499e1bc7a65b2b509f"},"cell_type":"code","source":"svd_reducer = sklearn.decomposition.TruncatedSVD(\n    n_components=EMBEDDING_SIZE,\n    algorithm='randomized',\n    n_iter=5,\n    random_state=None,\n    tol=0.0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"482812b81cb2d2097bd1d3c8539b3495fb51ed1f"},"cell_type":"code","source":"%%time\nsvd_reducer.fit(subject_dummies.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"585d488b5c83b26135506a48a8aca781285b802c"},"cell_type":"code","source":"%%time\n_subject_embeddings = svd_reducer.transform(subject_dummies.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba764003cd990f114066b8b921e6d9fda388673b"},"cell_type":"code","source":"assert np.abs(_subject_embeddings.sum(axis=1)).min() != 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7318f9dfa26f8bc3438ec270926c62ff4678969"},"cell_type":"markdown","source":"Normalise the vectors"},{"metadata":{"trusted":true,"_uuid":"ae951b8eb57244fada842c00632819e13f9122a9"},"cell_type":"code","source":"subject_embeddings = _subject_embeddings/np.linalg.norm(_subject_embeddings, axis=1)[:, np.newaxis]\n# subject_embeddings[np.isnan(subject_embeddings)] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6480f180933ebad0fba779b179e9a5f7fd38f493"},"cell_type":"code","source":"assert np.isnan(subject_embeddings).sum() == 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9bbd5bf6c5a3e00cee559fa7210f2b8e7a3a039"},"cell_type":"markdown","source":"### Visualise\n\nNow we can use the vectors to see how subjects relate to one another. The first thing we will do is use TSNE to visualise the embedding.\n\nThere are two sources on the internet that describe what some of the subjects relate to:\n\n [s3.amazonaws.com/tr-liaison-documents/public/Reuters_News_Topics_External.xls](http://s3.amazonaws.com/tr-liaison-documents/public/Reuters_News_Topics_External.xls)\n\n https://liaison.reuters.com/tools/topic-codes\n \n Of the two the first, the spreadsheet, appears to be the more complete list."},{"metadata":{"trusted":true,"_uuid":"30868ea5348204e6b617f232ed9450a92bfbda58"},"cell_type":"code","source":"%%time\nsubject_tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(subject_embeddings)\nprint(subject_tsne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb44ac80dcf275293ed075f4f319e0e7e8d09451"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(subject_tsne[:, 0], subject_tsne[:, 1], s=1)\n\nfor i, txt in enumerate(subjects):\n    if i % 20 == 0:\n        ax.annotate(txt, (subject_tsne[i, 0], subject_tsne[i, 1]), fontsize=10)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"462301843f4e050a8a117fbfd5b52cba72da5b67"},"cell_type":"markdown","source":"Next we can use cosine similarity to find which subjects are similar to a given subject"},{"metadata":{"_uuid":"5a935e44ca988f8bf94c0fff22185725a8574dbe"},"cell_type":"markdown","source":"The FUND subject is related to other banking and fund subjects"},{"metadata":{"trusted":true,"_uuid":"4c499b231d3ed833f7846b452a8f886927fdf1f1"},"cell_type":"code","source":"\" \".join(get_similar(\"FUND\", subject_embeddings, subjects))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75d43ec15938a2143c37ba214ab31154ef74488c"},"cell_type":"markdown","source":"    FUND \tFunds\n    BANK \tBanks (TRBC)\n    PVE \t Private Equity Funds\n    BSVC \tBanking Services (TRBC)"},{"metadata":{"_uuid":"188e74b078240249bd191cb813dfa9f57526a149"},"cell_type":"markdown","source":"The GOLF subject is related to other sports and more general news"},{"metadata":{"trusted":true,"_uuid":"10d06ba426ebd357666b9ce08770bba15cc3edd0"},"cell_type":"code","source":"\" \".join(get_similar(\"GOLF\", subject_embeddings, subjects))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6c1dffd0e6f3c825fb20642aeaccf17cf553e45"},"cell_type":"markdown","source":"    GOLF \tGolf\n    PREV     Previews / Schedules / Diaries\n    GEN      General News\n    ODD \t Human Interest / Brights / Odd News\n    ICEH \tIce Hockey"},{"metadata":{"_uuid":"74f639b85e3be98b07f5d16833ee3cecb9300659"},"cell_type":"markdown","source":"The EPMICS subject is related to diseases and health issues"},{"metadata":{"trusted":true,"_uuid":"226e032f0cfa8abb4048ecbd3441766753704c35"},"cell_type":"code","source":"\" \".join(get_similar(\"EPMICS\", subject_embeddings, subjects))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"999a6c519471d5658ce0f2850ff39ced1489ff69"},"cell_type":"markdown","source":"    EPMICS   Epidemics\n    INFDIS   Infectious Diseases\n    WOMHEA   Women's Health\n    COMDIS   Communicable Diseases"},{"metadata":{"_uuid":"ab6d2cc9afaababccf28d8a94ea9990f502121a6"},"cell_type":"markdown","source":"The TWAVE subject is related to natural disasters"},{"metadata":{"trusted":true,"_uuid":"db1e020fd90880e3e995ebd4f1ac8659941ea087"},"cell_type":"code","source":"\" \".join(get_similar(\"TWAVE\", subject_embeddings, subjects))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b43bc4858e7bf36741a0f66fe29556a71f174125"},"cell_type":"markdown","source":"    TWAVE \tTsunami\n    WLDPWS    Wind Power? (WINPWR = Wind Farms)\n    QUAK \t Earthquakes\n    VIO \t  Civil Unrest\n    TRD       International Trade"},{"metadata":{"_uuid":"9863b23b690a93f7dbe948cc560eb367849076de"},"cell_type":"markdown","source":"The subjects embedding appears to have done a reasonable job at grouping similar terms together (based on a few examples).\n\nLets save the results."},{"metadata":{"trusted":true,"_uuid":"f388bd0c5bbcff8aa236d882fe725620b6d4603c"},"cell_type":"code","source":"with open(\"subjects.json\", \"w\") as f:\n    json.dump(subjects, f)\nnp.save(\"subject_embeddings.npy\", subject_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcc0b970c378be382d98e55b5225700a951048be"},"cell_type":"code","source":"if False:\n    del subject_dummies, subjects, subject_embeddings\ndel subject_tsne, _subject_embeddings, svd_reducer\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bdae02ab7278f4830317436d6bbc6f391a17f5c8"},"cell_type":"markdown","source":"### Audience Embedding\n\nNext we can perform the same steps on the audience data"},{"metadata":{"trusted":true,"_uuid":"078e10b5e1fbde48852befe35f37ee2984fcae67"},"cell_type":"code","source":"%%time\naudience_dummies, audiences = pd_categorical_to_dummies(\n    news_data['audiences_tuples'], \n    MIN_OCCURRENCES\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de17361e5e42170208022ca251d8a7256effc602"},"cell_type":"code","source":"audience_dummies.shape, len(audiences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b992bae0004f9f8fbbcf3c778fbff3825fe2cab"},"cell_type":"code","source":"svd_reducer = sklearn.decomposition.TruncatedSVD(\n    n_components=EMBEDDING_SIZE,\n    algorithm='randomized',\n    n_iter=5,\n    random_state=None,\n    tol=0.0\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f8198de2f680e21b5928b0ef3cc4c9800c3432c"},"cell_type":"code","source":"%%time\nsvd_reducer.fit(audience_dummies.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914a93c2dd80cc2595be7e365017853b216e54f7"},"cell_type":"code","source":"%%time\n_audience_embeddings = svd_reducer.transform(audience_dummies.T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"377ae406de6ecdffd35c0f775ed839a9d01d0336"},"cell_type":"code","source":"assert np.abs(_audience_embeddings.sum(axis=1)).min() != 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16d61034c2ff67ffb80d3454f87b5d446c0458ea"},"cell_type":"markdown","source":"Normalise the vectors"},{"metadata":{"trusted":true,"_uuid":"3275b48557c9cccdf6b0be19e4010df7b8b6683c"},"cell_type":"code","source":"audience_embeddings = _audience_embeddings/np.linalg.norm(_audience_embeddings, axis=1)[:, np.newaxis]\n# audience_embeddings[np.isnan(audience_embeddings)] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b516b68a5687730ddca686343553c03338baf5a"},"cell_type":"code","source":"assert np.isnan(audience_embeddings).sum() == 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53eb897eaf4529716c9420bd5d0aa5d25e4c2242"},"cell_type":"markdown","source":"### Visualise\n\nAs with the subjects embedding we can use TSNE to visualise the vectors.\n\nUnlike for the subjects, I have been unable to find any resources to describe what each of the audiences mean, which makes analysing the results harder."},{"metadata":{"trusted":true,"_uuid":"5e2e55b8c60624a6e40433390d9057ab30c10794"},"cell_type":"code","source":"audience_tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(audience_embeddings)\nprint(audience_tsne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0070c39b5d0a2e2e8c0d23e056022bb712bf26ec"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(audience_tsne[:, 0], audience_tsne[:, 1], s=1)\n\nfor i, txt in enumerate(audiences):\n    if i % 5 == 0:\n        ax.annotate(txt, (audience_tsne[i, 0], audience_tsne[i, 1]))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b50d55951ada7f9b19d2ebe22b3b8a1d03d81751"},"cell_type":"markdown","source":"Again, lets have a look at some similar terms for a selection of audiences"},{"metadata":{"trusted":true,"_uuid":"87a4e331f71c18dd99a94e84f2cb12595b2ee697"},"cell_type":"code","source":"\" \".join(get_similar(\"OIL\", audience_embeddings, audiences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"988eb25b1e11824f68276178abeb7b80c02eb6f5"},"cell_type":"code","source":"\" \".join(get_similar(\"MTL\", audience_embeddings, audiences))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5512423718a04e1200bbaf962da7b133c3ad0684"},"cell_type":"markdown","source":"    MTL    Metal\n    OIL    Oil"},{"metadata":{"trusted":true,"_uuid":"fda528c5285a4d2c510321be28d9ca9c04029298"},"cell_type":"code","source":"\" \".join(get_similar(\"NZP\", audience_embeddings, audiences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54bf21df93217654bcf842f98d35cce1380b9e4e"},"cell_type":"code","source":"\" \".join(get_similar(\"FN\", audience_embeddings, audiences))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36b6fef7b5f2709a18dc93c1cf649b7d8e7cfe37"},"cell_type":"markdown","source":"It is more difficult to tell how good the vectors are at grouping similar audiences compared with the subjects due to the lack of any information on what the abbreviations mean. However, looking at the results I would have expected to be able to see some more obvious patterns.\n\nLets save the audience embedding and see if we can use the subjects, which we have some confidence in, to get an understand of what some of the audience abbreviations mean."},{"metadata":{"trusted":true,"_uuid":"c89e2b48f18091ee721880469c8d8492909f596c"},"cell_type":"code","source":"with open(\"audiences.json\", \"w\") as f:\n    json.dump(audiences, f)\nnp.save(\"audience_embeddings.npy\", audience_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4bdc2e8518cc0dcc0d0a2f789a152e12e5407cc"},"cell_type":"code","source":"if False:\n    del audience_dummies, audiences\ndel audience_embeddings, audience_tsne, _audience_embeddings, svd_reducer\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a4742ee3a877b6ae19ae52b5c56997844273dfe"},"cell_type":"markdown","source":"## Audience Embedding using Subject Map\n\nThe embedding learnt for the audiences was not particularly encouraging. Since we have some confidence about the quality of the subjects data lets take a look at which subjects best describe each audience."},{"metadata":{"trusted":true,"_uuid":"d7f7550c9afa88cc287ccb5a59cafb80a7931d6b"},"cell_type":"code","source":"audience_subject_map = {}\nnum = 5\n\nglobal_subject_proportions = subject_dummies.sum(axis=0).A[0]/subject_dummies.shape[0]\n\nfor i in range(len(audiences)):\n    m = audience_dummies[:, i].A[:, 0]\n    a = audiences[i]\n    \n    c = subject_dummies[m].sum(axis=0).A[0]\n    p = c/subject_dummies[m].shape[0]\n    # s = np.abs(p - global_subject_proportions)\n    s = np.clip(p - global_subject_proportions, 0, np.inf)\n    \n    ii = np.argsort(s)[::-1][:num]\n    \n    subs = np.array(subjects)[ii].tolist()\n    cnts = c[ii]\n    \n    # print(a, subs)\n    \n    audience_subject_map[a] = subs\n    \n    #break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6bff7fad04ee7c8ae4088c3e96dc415c8d53b25b"},"cell_type":"code","source":"audience_subject_map['OIL']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff7423addb937073e48f428cee17b30e0f7c4df3"},"cell_type":"markdown","source":"The OIL audience appears to be related to energy subjects:\n\n    COM    Commodities\n    NRG    Energy Markets\n    ENR    Energy (Legacy)"},{"metadata":{"trusted":true,"_uuid":"34b2d102eb3e770e0984180ccb7c07e7d4c54cd8"},"cell_type":"code","source":"audience_subject_map['MTL'] # Metal??","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e59bc3a2e997af05f85f6b0e07354c77d2c20e7b"},"cell_type":"markdown","source":"It is less clear what the MTL audience is related to but assuming it is to do with metal the commodities subject is of note:\n  \n    COM    Commodities    \n    BLR    Content produced in Bangalore\n    FIN    Financials (Legacy)"},{"metadata":{"trusted":true,"_uuid":"1ebda24afc82490bec41461ce7df517aba3331c7"},"cell_type":"code","source":"audience_subject_map['FN'] # Finland ??","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8846675ec3ff7fd100685a797a4fd63570f04af0"},"cell_type":"markdown","source":"The FN audience seems to be related to European countries:\n\n    FI    Finland\n    NORD  Nordic States"},{"metadata":{"trusted":true,"_uuid":"1f3107347a197e85b0e8187fa89460fbfa9a04f3"},"cell_type":"code","source":"audience_subject_map['NZP'] # New Zealand ??","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eeb99017e38e1cdf721d5b07cb5e2242c0076a2"},"cell_type":"markdown","source":"The NZP appear to be related to New Zealand"},{"metadata":{"_uuid":"3fbed80afd7d71a3694eca6663d044020089b8bf"},"cell_type":"markdown","source":"There appears to be a strong pattern in which subjects best describe each audience, so let try and use the subject vectors to create an audience vector."},{"metadata":{"trusted":true,"_uuid":"b059a733fa8e29c185f8b3803f1df586abbbe8ff"},"cell_type":"code","source":"# subject_embeddings = np.load(\"subject_embeddings.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c92a5d63a7118e64c015dd5b84b32c6eb38b9bb4"},"cell_type":"code","source":"_audience_embeddings_using_sub = []\n\nfor i in range(len(audiences)):\n    a = audiences[i]\n    \n    subs = audience_subject_map[a]\n    \n    ii = [i for i, s in enumerate(subjects) if s in subs]\n    \n    e = subject_embeddings[ii].mean(axis=0)\n    \n    _audience_embeddings_using_sub.append(e)\n    \n_audience_embeddings_using_sub = np.array(_audience_embeddings_using_sub)\n\nprint(_audience_embeddings_using_sub.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7425485d447b2e4c029e061bd17085c76a105f5a"},"cell_type":"code","source":"audience_embeddings_using_sub = _audience_embeddings_using_sub/np.linalg.norm(_audience_embeddings_using_sub, axis=1)[:, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53805d7667b7700178bcdc6480359684dfcc8e81"},"cell_type":"code","source":"audience_using_sub_tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(\n    audience_embeddings_using_sub\n)\nprint(audience_using_sub_tsne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02982255581aaf0a9cd49df88a207688eb174948"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(audience_using_sub_tsne[:, 0], audience_using_sub_tsne[:, 1], s=1)\n\nfor i, txt in enumerate(audiences):\n    if i % 2 == 0:\n        ax.annotate(txt, (audience_using_sub_tsne[i, 0], audience_using_sub_tsne[i, 1]))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ca42b20064ef8170ac09429e3647254f862ae7f"},"cell_type":"code","source":"\" \".join(get_similar(\"OIL\", audience_embeddings_using_sub, audiences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13154e2f3a9534558779a9af90a781313865215e"},"cell_type":"code","source":"\" \".join(get_similar(\"MTL\", audience_embeddings_using_sub, audiences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9fc640f32eee25d8fb0c43053a6e3a343be518e"},"cell_type":"code","source":"\" \".join(get_similar(\"FN\", audience_embeddings_using_sub, audiences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b38ac255bda5c14744990cb2c81bf59b8655e1a"},"cell_type":"code","source":"\" \".join(get_similar(\"NZP\", audience_embeddings_using_sub, audiences))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfc79fa1ee1da9e3d1d80b9686f8d5376aa0fdb1"},"cell_type":"markdown","source":"Its still hard to tell if the audience vectors created using the subjects are any good.\n\nAgain, lets save the results"},{"metadata":{"trusted":true,"_uuid":"415da92a99b9c38b3e4298f6cb2ca5a6aed48a77"},"cell_type":"code","source":"with open(\"audience_subject_map.json\", \"w\") as f:\n    json.dump(audience_subject_map, f)\n    \nnp.save(\"audience_embeddings_using_sub.npy\", audience_embeddings_using_sub)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"718a9d742b12b5bc76d63358956d8d85219f7419"},"cell_type":"markdown","source":"## Word2Vec Skip-Gram Audience Embedding\n\nAnother method we can try, is to use the skip-gram word2vec model to learn the vectors."},{"metadata":{"trusted":true,"_uuid":"94f6865d7f63ec8a1f7dc03c101d12d2a1fe73db"},"cell_type":"code","source":"import gensim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b3584d02aa3aa5aa16f1338fc39fa7f7d12cc4"},"cell_type":"code","source":"model_audience = gensim.models.Word2Vec(\n    size=EMBEDDING_SIZE, #10,\n    window=99999,\n    sg=1,\n    hs=0,\n    min_count=MIN_OCCURRENCES,\n    workers=4,\n    compute_loss=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36910c13365c2620752102a6ce2e67de2ff58d63"},"cell_type":"code","source":"model_audience.build_vocab(news_data['audiences_tuples'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73bc1b6be2b43406bbbb2c996c9713584a65a599"},"cell_type":"code","source":"%%time\nmodel_audience.train(\n    sentences=news_data['audiences_tuples'],\n    epochs=1,\n    total_examples=news_data.shape[0],\n    compute_loss=True,   \n)\n\nmodel_audience.get_latest_training_loss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06799991da226beca2cacab4b109cb65e33601bb"},"cell_type":"code","source":"model_audience.wv.similar_by_word(\"OIL\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"011a04d41a8726d81eed3ea0f63e34265ea4ec47"},"cell_type":"code","source":"model_audience.wv.similar_by_word(\"MTL\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"851be0e572341a542f779b26c1281c0a44dd0412"},"cell_type":"code","source":"model_audience.wv.similar_by_word(\"NZP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2d56b6b5ea1f1dcc79ed28f243c5797d81e80d2"},"cell_type":"code","source":"%%time\naudience_word2vec_tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(\n    model_audience.wv.vectors_norm\n)\nprint(audience_word2vec_tsne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c490aa7b6d414909daebdec243ae4d6a5731f8b3"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(audience_word2vec_tsne[:, 0], audience_word2vec_tsne[:, 1], s=1)\n\nfor i, txt in enumerate(model_audience.wv.index2word):\n    if i % 2 == 0:\n        ax.annotate(txt, (audience_word2vec_tsne[i, 0], audience_word2vec_tsne[i, 1]))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3e0f0ed3b505656f7a95694bdb4eb64295c59c2"},"cell_type":"markdown","source":"As before, it is no clearer if these results are any better.\n\nAgain, we will save the results."},{"metadata":{"trusted":true,"_uuid":"a4b59791e315294b2b4de4676a1d413d2322154b"},"cell_type":"code","source":"with open(\"audience_skipgram.json\", \"w\") as f:\n    json.dump(model_audience.wv.index2word, f)\nnp.save(\"audience_skipgram_embeddings.npy\", model_audience.wv.vectors_norm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4537a14cdbe382cd5dcb6f9482012455b4af0c4c"},"cell_type":"markdown","source":"## Word2Vec Skip-Gram Subject Embedding\n\nFor completeness, lets learn vectors for the subjects using the skip-gram model.\n\nWARNING: this will take several minutes (~15mins)"},{"metadata":{"trusted":true,"_uuid":"73893f202182bcf70fac2fde058d42fd9e572fa0"},"cell_type":"code","source":"model_subject = gensim.models.Word2Vec(\n    size=EMBEDDING_SIZE, #10,\n    window=99999,\n    sg=1,\n    hs=0,\n    min_count=MIN_OCCURRENCES,\n    workers=4,\n    compute_loss=True\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9b98c108ce6604b318962e55635a422b5a72f2a"},"cell_type":"code","source":"model_subject.build_vocab(news_data['subjects_tuples'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3fb6cabcda8d021ef7cd6119ceb3908885f7a648"},"cell_type":"code","source":"%%time\nmodel_subject.train(\n    sentences=news_data['subjects_tuples'],\n    epochs=1,\n    total_examples=news_data.shape[0],\n    compute_loss=True,   \n)\n\nmodel_subject.get_latest_training_loss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a1ca109cbea19916266e5ca6d0ca6095b851ef9"},"cell_type":"code","source":"model_subject.wv.similar_by_word(\"FUND\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f0547de93295160d8cfcfced5f486879639bcde"},"cell_type":"code","source":"model_subject.wv.similar_by_word(\"EPMICS\")\n# COMDIS    Communicable Diseases\n# SL        Sierra Leone","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"435affefa49e8c8d93388acfeb10302a818d8cdc"},"cell_type":"code","source":"%%time\nsubjects_word2vec_tsne = sklearn.manifold.TSNE(n_components=2).fit_transform(model_subject.wv.vectors_norm)\nprint(subjects_word2vec_tsne.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac3b69865ae3260cc61bd900faffb72846253ac1"},"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n\nax.scatter(subjects_word2vec_tsne[:, 0], subjects_word2vec_tsne[:, 1], s=1)\n\nfor i, txt in enumerate(model_subject.wv.index2word):\n    if i % 20 == 0:\n        ax.annotate(txt, (subjects_word2vec_tsne[i, 0], subjects_word2vec_tsne[i, 1]))\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e40402c173635ce46c7c2834e408eaa3f3355e7f"},"cell_type":"markdown","source":"Again, we will save the results"},{"metadata":{"trusted":true,"_uuid":"4e363e14152e4f55f8731ef725ce86f24ca1e638"},"cell_type":"code","source":"with open(\"subjects_skipgram.json\", \"w\") as f:\n    json.dump(model_subject.wv.index2word, f)\nnp.save(\"subject_skipgram_embeddings.npy\", model_subject.wv.vectors_norm)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}