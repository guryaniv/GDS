{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a346c810-05f1-1eda-050b-275c6c3ace14"
      },
      "source": [
        "## Temporal corelations\n",
        "\n",
        "The idea of this notebook is to see how corelation between various features and target variable change over time.\n",
        "\n",
        "As has been observed in other EDA notebooks, there is very little corelation between given features and y variable.\n",
        "\n",
        "As pointed by Raddar here, distribution of features seem to vary quite a bit for many features with time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c84f66c-eb06-f9e6-be15-0bd68234644b"
      },
      "outputs": [],
      "source": [
        "import kagglegym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = 8, 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "07b152db-e4f9-6f1b-e9c2-23104dabf707"
      },
      "outputs": [],
      "source": [
        "train_all = pd.read_hdf('../input/train.h5')\n",
        "\n",
        "#Skipping alternate timestamps to be able to run this kernel\n",
        "\n",
        "#odd_timestamps = [t for t in  train_all.timestamp.unique() if t%2 !=0]\n",
        "#print(len(odd_timestamps))\n",
        "\n",
        "#train_all = train_all.loc[train_all.timestamp.isin(odd_timestamps)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f71563e-a939-b5d5-5c44-59753d941daa"
      },
      "outputs": [],
      "source": [
        "#Lets get all features and devide into derived, fundamental and technical categories\n",
        "feats = [col for col in train_all.columns if col not in ['id', 'timestamp', 'y']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "07432bc2-a049-e084-1dfe-5303f39de4f7"
      },
      "source": [
        "It would be good idea to do a box plot of all variables after clip them appropriately (as there are lot of very high values)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b56f2475-6768-3ce1-14fe-2f2acf98372d"
      },
      "outputs": [],
      "source": [
        "train_all[feats] = train_all[feats].clip(upper=5, lower=-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8e4c0e6f-639b-9515-7181-3226860411df"
      },
      "outputs": [],
      "source": [
        "train_all[feats].plot(kind='box')\n",
        "plt.ylim([-2,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d86fecf5-125c-43b0-07e5-45452f099490"
      },
      "source": [
        "All the features lie mostly within -2 to 2. So, clipping features at -2 and 2 could be a good idea for modeling purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4892921-7693-efad-e2c8-75d74e68bd84"
      },
      "outputs": [],
      "source": [
        "#Group by mean, median and 2 sigma. (Note! Many of the features are not normal, \n",
        "#hence 2 sigma  does not give complete picture but good for starters) \n",
        "#(No pun intended for sponsor of competition ;)\n",
        "\n",
        "train_all_mean = train_all.groupby('timestamp').apply(lambda x: x.mean())\n",
        "\n",
        "train_all_2stdp = train_all.groupby('timestamp').apply(lambda x: x.mean() + 2*x.std())\n",
        "\n",
        "train_all_2stdm = train_all.groupby('timestamp').apply(lambda x: x.mean() - 2*x.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8598c055-54f9-5442-fc0c-53353f603bd7"
      },
      "outputs": [],
      "source": [
        "tmp1 = pd.melt(train_all_mean, value_vars=feats, var_name='features1', value_name='mean')\n",
        "tmp2 = pd.melt(train_all_2stdp, value_vars=feats, var_name='features2', value_name='2_sigma_plus')\n",
        "tmp3 = pd.melt(train_all_2stdm, value_vars=feats, var_name='features3', value_name='2_sigma_minus')\n",
        "\n",
        "tmp = pd.concat([tmp1, tmp2, tmp3], axis=1)\n",
        "\n",
        "fg = sns.FacetGrid(data=tmp, col='features1', col_wrap=3, size=2.7)\n",
        "fg.map(plt.plot, 'mean', color='blue')\n",
        "fg.map(plt.plot, '2_sigma_plus', color='black')\n",
        "fg.map(plt.plot, '2_sigma_minus', color='black')\n",
        "#fg.map(plt.fill_between, 'mean', '2_sigma_minus', '2_sigma_plus', color='Purple', alpha=0.3)\n",
        "\n",
        "#plt.ylim([-4.5, 4.5])\n",
        "\n",
        "del tmp1, tmp2, tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2fcf4ac4-755e-281a-5cf3-e679d2b0f2b3"
      },
      "source": [
        "* As has been already been pointed out by raddar, variables that are stable (flat mean and variance) over time are more suitable for modeling.**\n",
        "\n",
        "* Removing(or modeling separately) two periods of high variance in y, can provide additional paramters for modeling \n",
        "\n",
        "\n",
        "Now, lets see how corelation with y changes for different variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c325702-6e11-0c02-ed28-c3e18749ae14"
      },
      "outputs": [],
      "source": [
        "#I had to impute missing data otherwise either it takes very long time or we get lot of NaN \n",
        "import time\n",
        "def get_corr(x):\n",
        "    s= time.time()\n",
        "    #for f in feats:\n",
        "    #    corr.append(np.corrcoef(x[f],x['y'],rowvar=0)[0,1])\n",
        "    corr = np.corrcoef(x.values.T)[-1,2:-1]\n",
        "    #print(time.time()- s)\n",
        "    return corr\n",
        "    \n",
        "train_all_imputed = train_all.fillna(0)\n",
        "train_all_corr = train_all_imputed.groupby('timestamp').apply(get_corr) #This will take some time\n",
        "train_all_corr = pd.DataFrame(np.vstack(train_all_corr), columns=feats)\n",
        "train_all_corr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "54901e39-f895-d537-a398-df76ba4a2daa"
      },
      "outputs": [],
      "source": [
        "tmp3 = pd.melt(train_all_corr, value_vars=feats, var_name='features3', value_name='corr')\n",
        "\n",
        "fg = sns.FacetGrid(data=tmp3, col='features3', col_wrap=3, size=2.8)\n",
        "fg.map(plt.plot, 'corr', color='blue').add_legend()\n",
        "del tmp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cc1c9812-d39a-da51-df61-66e3d0269d68"
      },
      "source": [
        "All the corelation coefficients are oscillating quite a lot. Almost all features show positive and negative corelations with high frequency, most likely because of high volatility of y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b70c7e49-6255-26c6-97ec-5e0deddd7903"
      },
      "outputs": [],
      "source": [
        "def get_corr2(x):\n",
        "    corr = np.corrcoef(x.values.T)[-1,2:-2]\n",
        "    return corr\n",
        "    \n",
        "    \n",
        "train_all_imputed['abs_y'] = abs(train_all_imputed['y'])\n",
        "train_all_corr2 = train_all_imputed.groupby('timestamp').apply(get_corr2) #This will take some time\n",
        "train_all_corr2 = pd.DataFrame(np.vstack(train_all_corr2), columns=feats)\n",
        "train_all_corr2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b0f58f6-b60c-5e02-50a2-99a9a1dc3e83"
      },
      "outputs": [],
      "source": [
        "tmp4 = pd.melt(train_all_corr2, value_vars=feats, var_name='features3', value_name='corr')\n",
        "\n",
        "fg = sns.FacetGrid(data=tmp4, col='features3', col_wrap=3, size=2.7)\n",
        "fg.map(plt.plot, 'corr', color='blue').add_legend()\n",
        "\n",
        "del tmp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e7cf6826-57eb-1e61-7afd-243b55a63936"
      },
      "source": [
        "** Many features are showing strong corelations with absolute values of y. **\n",
        "\n",
        "** Building separate models for absolute values of y and direction of y can be a good approach **\n",
        "\n",
        "Also, they seem to be varying over time.**\n",
        "\n",
        "Normalize everything and plot together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22016fdf-d1e1-fde5-be5f-676b23921807"
      },
      "outputs": [],
      "source": [
        "tmp1 = pd.melt(train_all_mean, value_vars=feats, var_name='features1', value_name='mean')\n",
        "tmp2 = pd.melt(train_all_2stdp, value_vars=feats, var_name='features2', value_name='2std')\n",
        "tmp3 = pd.melt(train_all_corr, value_vars=feats, var_name='features3', value_name='corr')\n",
        "tmp4 = pd.melt(train_all_corr2, value_vars=feats, var_name='features3', value_name='yabs_corr')\n",
        "\n",
        "tmp = pd.concat([tmp1, tmp2, tmp3, tmp4], axis=1)\n",
        "cols = ['mean', '2std', 'corr', 'yabs_corr']\n",
        "tmp[cols] = tmp[cols].apply(lambda x: (x - x.mean())/x.std())\n",
        "fg = sns.FacetGrid(data=tmp, col='features1', col_wrap=3, size=2.7)\n",
        "fg = fg.map(plt.plot, 'mean', color='red')\n",
        "fg = fg.map(plt.plot, 'corr', color='green', alpha=0.4)\n",
        "fg = fg.map(plt.plot, '2std', color='black')\n",
        "fg = fg.map(plt.plot, 'yabs_corr', color='purple', alpha=0.4)\n",
        "fg.add_legend()\n",
        "\n",
        "\n",
        "del tmp1, tmp2, tmp3, tmp4, tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e43660c2-f99f-2dd5-17f2-0c912ec319fe"
      },
      "source": [
        "**Many features have same trend as their correlation with absolute values of y. Some sort of temporal correction for features can improve lineal models **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a0ad130-7cf9-cacb-f292-4870a3caf4c6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}