{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom keras import Sequential\nfrom keras.layers import Dense, Dropout, ELU, Softmax\nfrom keras.utils import to_categorical\nfrom keras.callbacks import LearningRateScheduler\nfrom sklearn.model_selection import StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# set up dataset\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n# lets take a look...\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4c40dbb8d2969c599f0000b18c9b9a059d6536d","collapsed":true},"cell_type":"code","source":"# create train datasets\nX_train = train_df.drop(['Id', 'Cover_Type'], axis=1)\nY_train = train_df[['Cover_Type']].values\nY_train = Y_train.reshape(len(Y_train))\n\n# create test dataset and ID's\nX_test = test_df.drop(['Id'], axis=1)\nID_test = test_df['Id'].values\nID_test = ID_test.reshape(len(ID_test))\n\n# concatenate both together for feature engineering and normalisation\nX_all = pd.concat([X_train, X_test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"65766ee9d3ecc04893fce49703c39d769c0aa630"},"cell_type":"code","source":"# mean hillshade\ndef mean_hillshade(df):\n    df['mean_hillshade'] = (df['Hillshade_9am'] + df['Hillshade_Noon'] + df['Hillshade_3pm']) / 3\n    return df\n\n# calculate the distance to hydrology using pythagoras theorem\ndef distance_to_hydrology(df):\n    df['distance_to_hydrology'] = np.sqrt(np.power(df['Horizontal_Distance_To_Hydrology'], 2) + \\\n                                          np.power(df['Vertical_Distance_To_Hydrology'], 2))\n    return df\n\n# calculate diagnial distance down to sea level?\ndef diag_to_sealevl(df):\n    df['diag_to_sealevel'] = np.divide(df['Elevation'], np.cos(180-df['Slope']))\n    return df\n\n# calculate mean distance to features\ndef mean_dist_to_feature(df):\n    df['mean_dist_to_feature'] = (df['Horizontal_Distance_To_Hydrology'] + \\\n                                  df['Horizontal_Distance_To_Roadways'] + \\\n                                  df['Horizontal_Distance_To_Fire_Points']) / 3\n    return df\n\nX_all = mean_hillshade(X_all)\nX_all = distance_to_hydrology(X_all)\nX_all = diag_to_sealevl(X_all)\nX_all = mean_dist_to_feature(X_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c633d433522569af0897953f25ab0bdf11e843f9"},"cell_type":"code","source":"# normalise dataset\ndef normalise_df(df):\n    df_mean = df.mean()\n    df_std = df.std()    \n    df_norm = (df - df_mean) / (df_std)\n    return df_norm, df_mean, df_std\n\n# define columsn to normalise\ncols_non_onehot = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n                'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n                'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm', \n                'Horizontal_Distance_To_Fire_Points', 'mean_hillshade',\n                'distance_to_hydrology', 'diag_to_sealevel', 'mean_dist_to_feature']\n\nX_all_norm, df_mean, df_std = normalise_df(X_all[cols_non_onehot])\n\n# replace columns with normalised versions\nX_all = X_all.drop(cols_non_onehot, axis=1)\nX_all = pd.concat([X_all_norm, X_all], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"95bab9b093210c533259fb263e610579b5700e74"},"cell_type":"code","source":"# split back into test and train sets\nX_train = np.array(X_all[:len(X_train)])\nX_test = np.array(X_all[len(X_train):])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bebe6c2780e9f2d3ce6e9ab2cce3366a06c278b1","collapsed":true},"cell_type":"code","source":"# set up Kfolds\nn_splits = 3\nkfolds = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\nnum_classes = 7\nnum_features = X_train.shape[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b0f9c63d3218367efee2fd7d74afc2804c41c95f"},"cell_type":"code","source":"def build_model(ELU_alpha=1.0, dropout=0.3):\n    model = Sequential()\n\n    model.add(Dense(1024, input_shape=(num_features,)))\n    model.add(ELU(ELU_alpha))\n    if dropout:\n        model.add(Dropout(dropout))\n\n    model.add(Dense(1024))\n    model.add(ELU(ELU_alpha))\n\n    model.add(Dense(512))\n    model.add(ELU(ELU_alpha))\n\n    model.add(Dense(256))\n    model.add(ELU(ELU_alpha))\n    if dropout:\n        model.add(Dropout(dropout))\n        \n    model.add(Dense(num_classes))\n    model.add(Softmax())\n    \n    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3217d68955ebec76af6b0f56a8f25f195bbf3d4","scrolled":false},"cell_type":"code","source":"scores = []\nmodels = []\ncurrent_fold = 1\nfor train, test in kfolds.split(X_train, Y_train):\n    print('commencing fold {}'.format(current_fold))\n    # prepare data\n    print('  preparing data...')\n    Xt = X_train[train]\n    Yt = to_categorical(Y_train[train]-1)\n    Xv = X_train[test]\n    Yv = to_categorical(Y_train[test]-1)\n\n    # create, fit and test model\n    print('  building model...')\n    classifier = build_model()\n    print('  fitting model...')\n    classifier.fit(Xt, Yt, epochs=120, batch_size=512, verbose=False)\n    print('  evaluating model...')\n    score = classifier.evaluate(Xv, Yv, batch_size=1024, verbose=False)\n    scores.append(score[-1])\n    models.append(classifier)\n    print('  fold {} accuracy: {}'.format(current_fold, score[-1]*100))\n    current_fold += 1\n    \nprint('ensemble average accuracy: {} % (+/- {} %)'.format(np.mean(scores)*100, np.std(scores)*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d6a3ce42dcb8884656e6737f0b2e23f61be00fc","collapsed":true},"cell_type":"code","source":"print('testing ensemble accuracy on whole training set...')\ny_preds = []\nfor index, classifier in enumerate(models):\n    print('getting predictions from model {}...'.format(index+1))\n    y_onehot = classifier.predict(X_train, batch_size=1024)\n    y_pred = np.argmax(y_onehot, axis=1)\n    y_preds.append(y_pred)\n  \nprint('taking average and rounding...')\ny_pred = np.rint(np.mean(y_preds, axis=0)) + 1\ny_pred = y_pred.astype(int)\n\nprint('calcualting accuracy...')\nensemble_accuracy = accuracy_score(Y_train, y_pred)\n\nprint('ensemble accuracy: {} %'.format(ensemble_accuracy*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1939c08906fee8dbdd3cddb8f52f5ee403ad12b4","collapsed":true},"cell_type":"code","source":"y_preds = []\nfor index, classifier in enumerate(models):\n    print('getting predictions from model {}...'.format(index+1))\n    y_onehot = classifier.predict(X_test, batch_size=1024)\n    y_pred = np.argmax(y_onehot, axis=1)\n    y_preds.append(y_pred)\n\nprint('taking average and rounding...')\ny_pred = np.rint(np.mean(y_preds, axis=0)) + 1\ny_pred = y_pred.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c6abd952da75336ff3e82de38d9be07fdd4890e","collapsed":true},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['Id'] = ID_test\nsub['Cover_Type'] = y_pred\nsub.to_csv('my_submission.csv', index=False)\nprint('good luck!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}