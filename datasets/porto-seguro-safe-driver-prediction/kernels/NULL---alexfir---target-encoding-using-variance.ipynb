{"cells": [{"cell_type": "markdown", "metadata": {"_uuid": "2c08cf0ede8ce17ccc2b5fcfb2905a61bdabbde1", "_cell_guid": "522c1075-c5c5-4a64-bb9d-706d2e457b57"}, "source": ["This is slightly modified version of Oliver's notebook [Python target encoding for categorical features\n", "](https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features) that uses variance within category. As a result there is no need in additional tuning parameters \"min_samples_leaf\" and \"smoothing\", but this approach assumes normalitity.The formula for calculation is taken from the same paper (see formula 6) in [A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems by Daniele Micci-Barreca ](https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e1265cc5526a35811e2dfce90dfdebd5c386f015", "collapsed": true, "_cell_guid": "228b3cb2-b8bd-4484-af9a-46b64c2417e3"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "\n", "def add_noise(series, noise_level):\n", "    return series * (1 + noise_level * np.random.randn(len(series)))\n", "\n", "\n", "def target_encode(train_series=None,\n", "                  test_series=None,\n", "                  target=None,\n", "                  noise_level=0):\n", "    assert len(train_series) == len(target)\n", "    assert train_series.name == test_series.name\n", "\n", "    temp = pd.concat([train_series, target], axis=1)\n", "    # Compute target mean\n", "    aggregated_values = temp.groupby(by=train_series.name)[target.name].agg([\"mean\", \"count\", np.std])\n", "    total_std = np.std(target)\n", "    aggregated_values[\"std\"].fillna(total_std, inplace=True)\n", "\n", "    # Compute smoothing\n", "    smoothing_component = aggregated_values[\"count\"] * total_std ** 2\n", "    smoothing = smoothing_component / (aggregated_values[\"std\"] ** 2 + smoothing_component)\n", "\n", "    # Apply average function to all target data\n", "    mean_total = target.mean()\n", "    mean_values = mean_total * (1 - smoothing) + aggregated_values[\"mean\"] * smoothing\n", "\n", "    mean_values_dict = mean_values.rank(axis=0, method='first').to_dict()\n", "\n", "    train_columns = train_series.replace(mean_values_dict).fillna(mean_total)\n", "    test_columns = test_series.replace(mean_values_dict).fillna(mean_total)\n", "    \n", "    return add_noise(train_columns, noise_level), add_noise(test_columns, noise_level)\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "184ac78fd83e42102ccfde0307b31bbd92d0a595", "_cell_guid": "562c9068-b02f-4c64-be36-128754df107e"}, "source": ["### Testing with ps_car_11_cat"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "cf4f62d29a00eb971821592a7b4b77ac203facd8", "_cell_guid": "02726dea-c371-488e-84d3-8d54998e59c4"}, "source": ["# reading data\n", "trn_df = pd.read_csv(\"../input/train.csv\", index_col=0)\n", "sub_df = pd.read_csv(\"../input/test.csv\", index_col=0)\n", "\n", "# Target encode ps_car_11_cat\n", "trn, sub = target_encode(trn_df[\"ps_car_11_cat\"], \n", "                         sub_df[\"ps_car_11_cat\"], \n", "                         target=trn_df.target,\n", "                         noise_level=0.01)\n", "trn.head(10)"], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "c01f4d1c40913fd539eb99fa8415a840ac5931ef", "_cell_guid": "909b0a7a-2fde-42d4-826d-26ee307e25ea"}, "source": ["### Scatter plot of category values vs target encoding\n", "We see that the category values are not ordered\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": false, "_uuid": "f1892c3e00c89207c75e3ca4adb036ef0e852ded", "_cell_guid": "3ab7dddb-ce8e-4ba1-a9ba-c7dbcf61ac98"}, "source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "i=0\n", "for f in trn_df.columns:\n", "    if \"_cat\" in f:\n", "        trn, sub = target_encode(trn_df[f], \n", "                         sub_df[f], \n", "                         target=trn_df.target,\n", "                         noise_level=0)\n", "\n", "        plt.figure(i)\n", "        i+= 1\n", "        plt.scatter(trn_df[f], trn)\n", "        plt.xlabel(f + \" category values\")\n", "        "], "outputs": []}, {"cell_type": "markdown", "metadata": {"_uuid": "f2ef7ce0e9991f52745a11f7532782c975ae9577", "_cell_guid": "d687755e-92fd-4131-8e75-dbb65a9f21e3"}, "source": ["### Check AUC metric improvement after noisy encoding over 5 folds"]}, {"cell_type": "code", "execution_count": null, "metadata": {"_kg_hide-input": true, "_kg_hide-output": false, "_uuid": "08e2048bb660113bad3d67f764165beaa64188e9", "_cell_guid": "dccd829f-a816-4475-9c32-a6f140fb1b95"}, "source": ["from sklearn.metrics import roc_auc_score\n", "from sklearn.model_selection import StratifiedKFold\n", "\n", "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n", "f_cats = [f for f in trn_df.columns if \"_cat\" in f]\n", "print(\"%20s   %20s | %20s\" % (\"\", \"Raw Categories\", \"Encoded Categories\"))\n", "for f in f_cats:\n", "    print(\"%-20s : \" % f, end=\"\")\n", "    e_scores = []\n", "    f_scores = []\n", "    for trn_idx, val_idx in folds.split(trn_df.values, trn_df.target.values):\n", "        trn_f, trn_tgt = trn_df[f].iloc[trn_idx], trn_df.target.iloc[trn_idx]\n", "        val_f, val_tgt = trn_df[f].iloc[trn_idx], trn_df.target.iloc[trn_idx]\n", "        trn_tf, val_tf = target_encode(train_series=trn_f, \n", "                                       test_series=val_f, \n", "                                       target=trn_tgt,\n", "                                       noise_level=0.01)\n", "        f_scores.append(max(roc_auc_score(val_tgt, val_f), 1 - roc_auc_score(val_tgt, val_f)))\n", "        e_scores.append(roc_auc_score(val_tgt, val_tf))\n", "    print(\" %.6f + %.6f | %6f + %.6f\" \n", "          % (np.mean(f_scores), np.std(f_scores), np.mean(e_scores), np.std(e_scores)))"], "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python"}}, "nbformat_minor": 1, "nbformat": 4}