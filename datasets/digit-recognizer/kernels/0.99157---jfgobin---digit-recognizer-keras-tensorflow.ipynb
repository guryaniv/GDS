{"metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python"}}, "nbformat": 4, "cells": [{"cell_type": "code", "metadata": {"collapsed": true, "_uuid": "e7c251c0af661d5d2cb1d174bdfa1cdc8015f98a", "_cell_guid": "86770c8f-68b6-411b-b94a-ab0b272e617c"}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np\n", "import pandas as pd\n", "from keras.models import Sequential\n", "from keras.layers import Dense \n", "from keras.layers import Dropout\n", "from keras.layers import Flatten\n", "from keras.layers import Reshape\n", "from keras.layers.convolutional import Conv2D\n", "from keras.layers.convolutional import MaxPooling2D\n", "from keras.utils import np_utils\n", "from keras import backend as K\n", "from keras.optimizers import RMSprop\n", "from sklearn.model_selection import train_test_split\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "K.set_image_dim_ordering('th')\n", "\n", "# Set the random seed for reproducibility\n", "seed = 37\n", "np.random.seed(seed)\n", "\n", "# Read the datasets\n", "csv_train = pd.read_csv(\"../input/train.csv\")\n", "csv_test = pd.read_csv(\"../input/test.csv\")\n", "\n", "# Separate the data from the results in the training set\n", "y_train = csv_train.iloc[:,0]\n", "X_train = csv_train.iloc[:,1:]\n", "\n", "# Reshape the \"image\" part\n", "y_train = y_train.as_matrix()\n", "X_train = X_train.as_matrix().reshape(X_train.count()[0], 1, 28, 28)\n", "X_test = csv_test.as_matrix().reshape(csv_test.count()[0], 1, 28, 28)\n", "\n", "# Normalize the input\n", "X_mean = X_train.mean().astype(np.float32)\n", "X_sdev = X_train.std().astype(np.float32)\n", "\n", "X_train = (X_train - X_mean)/X_sdev\n", "X_test = (X_test - X_mean)/X_sdev\n", "\n", "# Convert the labels 0...9 to categoricals\n", "y_train = np_utils.to_categorical(y_train)\n", "\n", "# Create the model\n", "num_classes=10\n", "model = Sequential()\n", "model.add(Conv2D(32, (5, 5), input_shape=(1, 28, 28), activation='relu',\n", "          bias_initializer='RandomNormal'))\n", "model.add(MaxPooling2D(pool_size=(2, 2)))\n", "model.add(Conv2D(64, (5, 5), activation='relu'))\n", "model.add(MaxPooling2D(pool_size=(2, 2)))\n", "model.add(Flatten())\n", "model.add(Dense(256, activation='relu'))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(16, activation='relu'))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(num_classes, activation='softmax'))\n", "# Compile the model\n", "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "model.compile(optimizer=RMSprop(lr=0.001),\n", "              loss='categorical_crossentropy',\n", "              metrics=['accuracy'])\n", "# Partition the train set into training and validation\n", "x_train, x_val, y_train, y_val = train_test_split(X_train, y_train, \n", "                                                  test_size=0.1, random_state=83)\n", "# Fit the model\n", "history = model.fit(x_train, y_train,\n", "                    validation_data=(x_val, y_val), epochs=20,\n", "                    batch_size=128, verbose=0)\n", "history_dict = history.history\n", "# Plot the loss and accuracy values\n", "loss_values = history_dict['loss']\n", "val_loss_values = history_dict['val_loss']\n", "acc_values = history_dict['acc']\n", "val_acc_values = history_dict['val_acc']\n", "epochs = range(1, len(loss_values) + 1)\n", "# \"bo\" is for \"blue dot\"\n", "plt.plot(epochs, loss_values, 'bo')\n", "# b+ is for \"blue crosses\"\n", "plt.plot(epochs, val_loss_values, 'b+')\n", "plt.xlabel('Epochs')\n", "plt.ylabel('Loss')\n", "plt.show()\n", "plt.plot(epochs, acc_values, 'bo')\n", "plt.plot(epochs, val_acc_values, 'b+')\n", "plt.show()\n", "# And let's predict the labels\n", "y_pred = model.predict(X_test, batch_size=2000, \n", "                       verbose=1)\n", "\n", "# Move from categorical back to 0...9\n", "y_pred = np.argmax(y_pred, axis=1)\n", "to_submit = pd.DataFrame({'Label': y_pred})\n", "# Re-index to start at 1 instead of 0\n", "to_submit.index += 1\n", "to_submit.index.name = \"ImageId\"\n", "to_submit.to_csv('labelled.csv')"], "execution_count": null}, {"cell_type": "code", "metadata": {"collapsed": true, "_uuid": "10a6a9dfbd856915502f11992aa6dee47a10f57d", "_cell_guid": "69daebce-a355-4eb5-8c80-4a511a8c6ebc"}, "outputs": [], "source": [], "execution_count": null}], "nbformat_minor": 1}