{"cells":[{"metadata":{"_uuid":"afade040ee6236c90178cd712be51fd7a403d09f"},"cell_type":"markdown","source":"<h1>EDA with Data Visualization and Augmentation</h1>\nIn this **tutorial** we are going to explore the dataset searching for hidden patterns using** statistical** and **manual** methodes.\nWe are also going to see how we can perform **Clustering** to cluster images based on the label data we have and also will perform some **data augmentation** to be able to classify the images efficiently."},{"metadata":{"trusted":true,"_uuid":"cad23d48d6a0eb8d7bb907e890b4764a4492c071"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pydicom\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport seaborn as sns\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ec2a4940c84657084d74a8a8f9cb0c8a271dba4"},"cell_type":"markdown","source":"We will start by exploring the target classes we have in the dataset."},{"metadata":{"trusted":true,"_uuid":"d7f18eefcfb21deab984c313054b1e3e7db78b18","scrolled":true},"cell_type":"code","source":"\npatient_classes = pd.read_csv('../input/stage_2_detailed_class_info.csv')\npatient_classes.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a03d84858cbd3ff02283c97be343c8df31936dbe"},"cell_type":"markdown","source":"Before proceeding we need to know the number of target classes and its names."},{"metadata":{"trusted":true,"_uuid":"dcf5ba312afa3e93caad7b578064dbf6302ee994"},"cell_type":"code","source":"print(\"Number of classes in the dataset :: %i\" %  len(patient_classes[\"class\"].unique()))\nprint(\"Classes' names are :: %s\" % patient_classes[\"class\"].unique())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e438051ba7482296f540e44d8b7b1579bcfde66e"},"cell_type":"markdown","source":"To be able to decide which performance metric we may use, We need to know the number of data examples in eachclass to see if the data is skewed or not. If the data is skewe ( one class has much more data examples than other classes ) then we can't use accuracy because it yeald misleading results but we may use Precision, Recall or F-beta score according to the situation we have."},{"metadata":{"trusted":true,"_uuid":"a024826ed1715a2bec19df4865753b00f2624b2e","scrolled":true},"cell_type":"code","source":"class_count = patient_classes['class'].value_counts()\nclass_count.plot.bar( ec=\"orange\")\nprint(class_count)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8ada5c555bc85e8479fbe4d40dea1428a5cf8a3"},"cell_type":"markdown","source":"It seems that data is not skewed so we will proceed with accuracy as the performance metric for the algorithm.\nNow let's try to see how our train_labels data looks like."},{"metadata":{"trusted":true,"_uuid":"d1cfe122de5dc117ee2fe57ee816933e9c924a7a","scrolled":true},"cell_type":"code","source":"\ntrain_labels = pd.read_csv('../input/stage_2_train_labels.csv')\nprint(train_labels.iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0b2e21f88ac76e652c9ab193c14949951e1a07f"},"cell_type":"markdown","source":"From the above example we see that for every label we have a patient ID, and bounding boxes coordinates which are nulls for class 0 and have values for class 1"},{"metadata":{"_uuid":"97dcf93729c429c5fb7b33d2424920612324635d"},"cell_type":"markdown","source":"Input images are stored in DICOM format which stores description for every image in the dataset. Now let's see what we can benefit from this description."},{"metadata":{"trusted":true,"_uuid":"aa023b9d0f830685d3edc9a67e8140f0ad2f01d3"},"cell_type":"code","source":"\ndcm_file = '../input/stage_2_train_images/%s.dcm' % train_labels.patientId.tolist()[0]\ndcm_data = pydicom.read_file(dcm_file)\nprint(dcm_data)  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92dab8f89b39b97de4861866f03f759e0b9f72f1"},"cell_type":"markdown","source":"Most of the information doesn't seem to be useful except Age and Gender."},{"metadata":{"_uuid":"c0266a9b7f6fef5549ae83b0faa9e8117f70bede"},"cell_type":"markdown","source":"Now let's store all the destinct IDs into a dataframe for future usage."},{"metadata":{"trusted":true,"_uuid":"ea85977eaf242973f32deb5e55d575a5394051be"},"cell_type":"code","source":"patientIds = train_labels.drop_duplicates('patientId', keep = 'first').patientId.tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83a560ff9946a6421901a2b1014697759b240fcd"},"cell_type":"markdown","source":"We will now extract the PatientAge and PatientSex fields in the DICOM description for every destince ID in a seperate array for each one and then convert this to a dataframe to be able to use it later."},{"metadata":{"trusted":true,"_uuid":"7133adf259b122bbf98d2013f1ea8676c76d5277"},"cell_type":"code","source":"Sex = []\nAge = []\nfor patientId in patientIds:\n    dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId\n    dcm_data = pydicom.read_file(dcm_file)\n    Sex.append(dcm_data.PatientSex)\n    Age.append(int(dcm_data.PatientAge))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cec098246e60a5ea6ac7ecc9bf485967d6698423"},"cell_type":"code","source":"patientInfo = pd.DataFrame({'patientId': patientIds, 'patientSex': Sex, 'patientAge': Age})\npatientInfo.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1c4c9899d7d36cd8f7c7dde53c3508002e15e3b"},"cell_type":"markdown","source":"Let's now explore the data we collected in the dataframe and search for missing values."},{"metadata":{"trusted":true,"_uuid":"b7b9492a1750c666a9a8e292d4a285eef38475ba"},"cell_type":"code","source":"patientAge_count = patientInfo['patientAge'].value_counts().sum()\npatientSex_count = patientInfo['patientSex'].value_counts().sum()\npatient_count = patientInfo['patientId'].value_counts().sum()\n\nprint(\"total number of patientId :: %i\" % patient_count )\nprint(\"Total number of patients with Non null patientSex :: %i \" % patientSex_count )\nprint(\"Total number of patients with Non null patientAge :: %i \" %  patientAge_count )\nprint(\"Number of missing values to be imputed for the first field :: %i \" % (patient_count - patientSex_count) )\nprint(\"Number of missing values to be imputed for the second field :: %i \" % (patient_count - patientAge_count) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e672543b2d4e9e5d43eeff77a2e76f39eb911c60"},"cell_type":"code","source":"patientInfo = patientInfo.set_index('patientId').join(train_labels.set_index('patientId'))[['patientSex', 'patientAge', 'Target']]\npatientInfo.reset_index(inplace=True)\npatientInfo.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa2c641309b93040bece3a5201accbd584e21591"},"cell_type":"code","source":"patientInfo.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9998550f2894667e4f12d0b95651a7bde757ab9a"},"cell_type":"markdown","source":"**Exploring Age Feature**"},{"metadata":{"_uuid":"2e9b27f105ab495a435fb3563217b37fefbce33a"},"cell_type":"markdown","source":"We will explore the distinct age values in the dataset, Age greater than 90 years and also the frequency for each value using histgrams. Note: the oldest person on earth is 122 years old so any value more than this is probably an outlier."},{"metadata":{"trusted":true,"_uuid":"378b76beb027c9bdbd22e0de272faa68f4f53c1a","scrolled":true},"cell_type":"code","source":"\npatientInfo['patientAge'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6385185267d938585ffc3b8e3e9f80655787946"},"cell_type":"code","source":"\npatientInfo['patientAge'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5952fbef2ec95e9ed9a5ddad6f6a7367856ade16"},"cell_type":"code","source":"\npatientInfo[patientInfo['patientAge']>=90]['patientAge'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c30a162f8acb35998868f5c6788ae5b547341b4a"},"cell_type":"code","source":"patientInfo[patientInfo['patientAge']>=85]['patientAge'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2e0447a6220f7eceb3f9fd33118bcdb9368c284"},"cell_type":"markdown","source":"# Exploring Images \nWe will explore images from the dataset based on different age groups to see if there is a significant difference in the images to decide if we need further processing."},{"metadata":{"trusted":true,"_uuid":"58b3fca3a5ac0943cbfa72f1b5567b57b996421c"},"cell_type":"code","source":"\ndef draw_img(patient_id, title=None):\n    dcm_file = '../input/stage_2_train_images/%s.dcm' % patient_id\n    dcm_data = pydicom.read_file(dcm_file)\n    plt.imshow(dcm_data.pixel_array)\n    if title is not None:\n        plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47bf650526ee01df4884f4386936159b7829003d"},"cell_type":"code","source":"\npatients_greater_100 = patientInfo[patientInfo['patientAge']>=100]\npatients_less_5 = patientInfo[patientInfo['patientAge']<=5]\npatients_mid_age = patientInfo[(patientInfo['patientAge']>=30) & (patientInfo['patientAge']<= 50)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f649ed54dbc15a64a6edd3caa37283817d5d7504"},"cell_type":"code","source":"\ndef draw_grid(arr_patients, rows=5, columns=4, titles=None, figsize=(15, 15)):\n    fig=plt.figure(figsize=figsize)\n    for i in range(1, columns*rows + 1):\n        if(i <= len(arr_patients)):\n            fig.add_subplot(rows, columns, i)\n            if titles is None:\n                    draw_img(arr_patients[i - 1])\n            else:\n                    draw_img(arr_patients[i - 1], title=titles[i - 1])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3348e7388f5fcbf540fb0026eb2dd9667ffa36cf","scrolled":false},"cell_type":"code","source":"draw_grid(patients_mid_age['patientId'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ead04077be83e22db0bd906c89fc28308212be54"},"cell_type":"code","source":"draw_grid(patients_greater_100['patientId'].tolist(), 2, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee5c57324b8240a5ef0265fa3fb26b4f6781e175"},"cell_type":"code","source":"draw_grid(patients_less_5['patientId'].tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fd23312992644dc6a1ed737f43915a5e0892b98"},"cell_type":"code","source":"patientInfo['age_category'] = (patientInfo['patientAge'] // 10) * 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70fb16300b206c7d3d835a5372ff29fe8328ced9"},"cell_type":"code","source":"ax = sns.countplot(x=\"age_category\", hue=\"Target\", data=patientInfo)\nax.set_title('Disease per age category')\nax.legend(title='Disease')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"44c715b01c345b74e195d907229fc1c4b41382ed"},"cell_type":"markdown","source":"# Explore Gender\nWe will explore the images based on the ggender of the patient.\nFirst we need to see if the number of patients is the same for males and females."},{"metadata":{"trusted":true,"_uuid":"ed21ce505ee064d5eb64da0a42532f68bd2b6a89"},"cell_type":"code","source":"patientInfo['patientSex'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce3f692e67a619e10869f1cd25c63ac1a9223c0b"},"cell_type":"markdown","source":"Now we will try to see is there is a segnificant difference between the radiation images of males and females."},{"metadata":{"trusted":true,"_uuid":"16cea81b7f49665cbb2a8b68ec21c8f6848666fe"},"cell_type":"code","source":"\ndraw_grid(patientInfo[patientInfo['patientSex'] == 'M']['patientId'].tolist(), 3, 3, \n          titles=patientInfo[patientInfo['patientSex'] == 'M']['patientAge'].tolist(), figsize=(15, 15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7073e432a9d58756a4cfdb5d202558153fd63e7f"},"cell_type":"code","source":"\ndraw_grid(patientInfo[patientInfo['patientSex'] == 'F']['patientId'].tolist(), 3, 3, \n          titles=patientInfo[patientInfo['patientSex'] == 'F']['patientAge'].tolist(), figsize=(15, 15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"204de536ac0455fb1444140f282053b63a94c314"},"cell_type":"markdown","source":"I can see no difference between the images based on the gender of the patient only."},{"metadata":{"_uuid":"c19ac15ff393029b5e5635f32e98e44d5e7908ba"},"cell_type":"markdown","source":"Now let's try to explore the numbers in each class based on the gender."},{"metadata":{"trusted":true,"_uuid":"6b43da2a929905912a9ed1ec9f2593e013e592cc"},"cell_type":"code","source":"\nax = sns.countplot(x=\"patientSex\", hue=\"Target\", data=patientInfo)\nax.set_title('Disease per gender')\nax.legend(title='Disease')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4cacb0b24c50732247ae0cc55a80b199311dbbf"},"cell_type":"markdown","source":"# Age and Gender Exploration\nNow We will explore the age, gender and also the target classes. We will discover the data representation using histograms to see how the data looks like."},{"metadata":{"trusted":true,"_uuid":"dba18dcfbdddf32e5409d7dc476852c15dd09f36"},"cell_type":"code","source":"\nz = {'F': 1, 'M': 0}\npatientInfo['Sex'] = patientInfo['patientSex'].map(z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75cec06b0891f1e07547366d55b61b38e4bced45"},"cell_type":"code","source":"\nsns.pairplot(patientInfo[['Sex', 'age_category', 'Target']]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"841a4e086d19c3353a09c0d55b22b0d0fb65eb26"},"cell_type":"markdown","source":"It is very important to know the correlation between features and target variable to be able to decide if the feature is important to be used in the model or not. We will use correlation matrix and heat map to see this visually."},{"metadata":{"trusted":true,"_uuid":"b588af7862013c83772a7ef014f4d213a6e97d3e"},"cell_type":"code","source":"corr = patientInfo.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f98be002126ef6ad85ed554a8790f2d77b28751"},"cell_type":"code","source":"import seaborn as sns\n\n\nimport matplotlib.pyplot as plt\n\nf, ax = plt.subplots(figsize=(25, 25))\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\nsns.heatmap(corr, cmap=cmap, vmax= .3,vmin = - 0.3, center=0,\n            square=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e08d64ed64cfd8e3e13a6eabd44986db05e4297e"},"cell_type":"markdown","source":"We also have  to check if any label that is of the +ve class has Nulls in the bounding boxex data. Since only bounding boxes in the 0 class can have nulls since we will not draw anything."},{"metadata":{"trusted":true,"_uuid":"582f4de633195f3ff05ed550711671f4557317c4"},"cell_type":"code","source":"print(\"The number instances for the 0 class:: %i and for the 1 class = %i \" % (train_labels.Target.value_counts()[0], train_labels.Target.value_counts()[1]) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a3039efabe4ecfd85007cb7375d218bdcce6bd5"},"cell_type":"code","source":"train_ones = train_labels[train_labels.Target == 1]\ntrain_ones.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe4bf748965b23b9910f860148a35e051d0a398d"},"cell_type":"code","source":"print(\"The number of NaN values for bounding box dimentions columns for class 1 data = %s \" % train_ones.isna().sum() )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eca0e92ac243b18d2c59facb06ee895360e07cf0"},"cell_type":"markdown","source":"# Drawing bounding boxes on images\nWe will draw the bounding boxes on the images to see how disease looks like in the radiation images ."},{"metadata":{"trusted":true,"_uuid":"14a5e0fe337d376426e803b567c8cd76675ba51a"},"cell_type":"code","source":"\ntrain_labels.Target.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8d3c249f91521c653a38cd5ff7bd9a593f5a402"},"cell_type":"code","source":"\ntrain_labels.iloc[110]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a25b6f738eb731383be98a3e3090956e2bf5e94"},"cell_type":"code","source":"\n\nprint('all images:', train_labels.shape[0])\nprint('unique images:', np.unique(train_labels.patientId.tolist()).shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5c8c59125df075abe74bdd0af55d2f6e6028561"},"cell_type":"code","source":"\ndef draw_mult_rects(patientIds, rows=3, cols=3, figsize=(15, 15)):\n    \n    fig=plt.figure(figsize=figsize)\n    \n    for i in range(1, len(patientIds)+1):\n        fig.add_subplot(rows, cols, i)\n        records = train_labels[train_labels.patientId == patientIds[i-1]]\n        class_label = patient_classes[patient_classes.patientId == patientIds[i-1]]['class'].tolist()[0]\n        dcm_file = '../input/stage_2_train_images/%s.dcm' % patientIds[i-1]\n        dcm_data = pydicom.read_file(dcm_file)\n        plt.imshow(dcm_data.pixel_array)\n        plt.title(class_label)\n        for j in range(records.shape[0]):\n            record = records.iloc[j]                \n            x = record.x\n            y = record.y\n            width = record.width\n            height = record.height\n            if x is not None:\n                rect = patches.Rectangle((x,y),width,height,linewidth=1,edgecolor='r',facecolor='none')\n                plt.gca().add_patch(rect)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51a02d39bd7fa6c990e72a6ea71ff178f3a72dd2"},"cell_type":"code","source":"\ndraw_mult_rects(train_labels.patientId.unique()[:9])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1267b763b43364d6a7f0ff21e9d12389eb137f1a"},"cell_type":"markdown","source":"# Clustering\nWe have noticed a great difference in radiation images based on the Age and gender of the patient, So we will try to cluster images based on the differences in the features for each patient and examine the output histograms and draw an image for each cluster . We will explore the hestograms of each clustering procedure when changing the number of centroids of the clustering algorithm."},{"metadata":{"trusted":true,"_uuid":"16452688f3508179a958c88eee86a6986a72f51b"},"cell_type":"code","source":"patientId = patientInfo.patientId\ntmp_cluster = patientInfo.drop(['patientId', \"Target\", 'patientSex', 'age_category'], axis = 1)\ntmp_cluster['patientAge'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62f7eda0068bf3e4bc3fb749cee7a7ea634d6956"},"cell_type":"code","source":"from sklearn.cluster import KMeans\n\ndef kmeans(n, tmp_cluster) :\n    cluster = KMeans(n_clusters=n, max_iter=300, tol=0.0001, verbose=0, random_state = 0, n_jobs=-1).fit(tmp_cluster)\n    return cluster.labels_","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8797512480b902676ffed1b39b37a48043a06582"},"cell_type":"markdown","source":"Plotting the histogram of clustered data and also viewing an image from each cluster to see what we can be gathered in each cluster."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\ntmp_cluster_Id = pd.DataFrame()\nrows = 0\nfor i in range(2,10):\n    columns = 3\n    tmp_cluster[\"clusters\"] = kmeans(i, tmp_cluster)\n    n, bins, patches = plt.hist(tmp_cluster[\"clusters\"], facecolor='b')\n    tmp_cluster_Id = tmp_cluster.copy()\n    tmp_cluster_Id[\"patientId\"] = patientId\n    pics = ((tmp_cluster_Id.drop_duplicates('clusters', keep = 'first'))['patientId']).tolist()\n    \n    if( len( pics ) >= 3) :\n        rows = (((len(pics) - 3) / 3) + (len(pics) - 3) % 3) + 1\n    else : \n        columns = 2\n        rows = 1\n    draw_grid(pics, columns = columns, rows = int(rows) )\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01dab6d0ca217225f50eaa72427fa202bbb08958"},"cell_type":"markdown","source":"# Data Augmentation\nHere we will perform a very simple data augmentation. We will crop the edges of the images since we didn't need it. When trying this with our model it had significant effect on decreasing the variance."},{"metadata":{"trusted":true,"_uuid":"64f280caf549b9a883c702d7fafa9f6fc7d722d0"},"cell_type":"code","source":"import cv2\n\ndef remove_borders(img_data, threshold = 10):\n    img_data = img_data[:, np.max(img_data, axis=0) > threshold]\n    img_data = img_data[np.max(img_data, axis=1) > threshold]\n    img_data = cv2.resize(img_data, (1024, 1024))\n    return img_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51c0e6f72639d885d1e71d20b28b63634cc91a90"},"cell_type":"markdown","source":"Now we will see how the images look like after removing the boarders. I will show the same images as the above images to be able do see the differences."},{"metadata":{"trusted":true,"_uuid":"a529f72ef4ff97a56634cbb97c81c773dd22727d"},"cell_type":"code","source":"def read_one_img(patientId):\n    dcm_file = '../input/stage_2_train_images/%s.dcm' % patientId\n    dcm_data = pydicom.read_file(dcm_file)\n    img = dcm_data.pixel_array\n    img = remove_borders(img)\n    img = cv2.resize(img, (224, 224))\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"901d2f4118ee2e26f1f44664089216ab0f5d6774"},"cell_type":"code","source":"figure=plt.figure(figsize=(15,15))\n\nfor (i, j) in enumerate(pics) :\n    image = read_one_img(j)\n    image_pixels = remove_borders(image)\n    figure.add_subplot(3, 3, i+1)\n    plt.imshow(image_pixels)\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b521e559c636ecfae14b87097641dd4722853aac"},"cell_type":"markdown","source":"### Note : The data augmentation part is still in developpment since we can add many other things to it."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}