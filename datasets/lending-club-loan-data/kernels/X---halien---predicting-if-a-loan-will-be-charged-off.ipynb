{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["**In this simple kernel, I will attempt to predict whether customers will be \"Charged Off\" on a loan using Random Forests Classifier.**"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true, "_uuid": "15990fd27e7be23dcc3346b4b4c66424040590a9", "_cell_guid": "3201ed75-93a5-4f4f-843d-c99b544f2151"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["loan  = pd.read_csv(\"../input/loan.csv\")\n", "\n", "print(loan.head())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First let's see how much Nans are there per column"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["#determine nan percentage\n", "check_null = loan.isnull().sum().sort_values(ascending=False)/len(loan)\n", "\n", "#print all with 20% NaNs\n", "print(check_null[check_null > 0.2])\n"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["#loads of columns ... so let's remove these\n", "loan.drop(check_null[check_null > 0.2].index, axis=1, inplace=True)\n", "loan.dropna(axis=0, thresh=30,inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["After culling the NaN dominated columns, there are still a lot of features. Some will have useful info, others not. At this point I carefully weeded out any column that I think may be well useless. My main criteria is whether a feature is dominated by a single value (> 80%)\n", "1. id and member_id: somehow I don't think these will be useful, condidering all were unique\n", "2. Policy_cose: this is the same for all customers\n", "3. url: this is the webpage of the loan data. May come in handy at someother stage (maybe)\n", "4. zip_code and addr_state: I really don't think that the state and location of aperson will determine if they will repay a loan. Although, I could be wrong ....\n", "5. application_type: was >99% INDIVIDUAL\n", "6. 'pymnt_plan': 99.99% N\n", "7. emp_title: this could be useful. Possbly through NLP. \n", "8. acc_now_delinq: > 99% 0\n", "9. title: may be very useful. Requires NLP\n", "10. collections_12_mths_ex_med: ~98% 0\n", "11. collection_recovery_fee > 98% 0 "]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["#first let's remove some columns\n", "del_cols = ['id', 'member_id', 'policy_code', 'url', 'zip_code', 'addr_state',\n", "            'pymnt_plan','emp_title','application_type','acc_now_delinq','title',\n", "            'collections_12_mths_ex_med','collection_recovery_fee']"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["loan = loan.drop(del_cols,axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The point of this exercise is to predict if a loan will be \"Charged Off\". Let's see the breakdown of the target column: 'loan_status'"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print(loan['loan_status'].value_counts()/len(loan))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Yikes! Ok for now we will ignore \"Current\" customers. Note, we could use the model generated to predict whether a \"Current\" customers will be \"Charged Off\". "]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["loan = loan[loan['loan_status'] != 'Current']"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print(loan['loan_status'].value_counts()/len(loan))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The column 'emp_length' may be useful"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print(loan['emp_length'].unique())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's convert this to categorical data"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["loan['empl_exp'] = 'experienced'\n", "loan.loc[loan['emp_length'] == '< 1 year', 'empl_exp'] = 'inexp'\n", "\n", "loan.loc[loan['emp_length'] == '1 year', 'empl_exp'] = 'new'\n", "loan.loc[loan['emp_length'] == '2 years', 'empl_exp'] = 'new'            \n", "loan.loc[loan['emp_length'] == '3 years', 'empl_exp'] = 'new'\n", "\n", "loan.loc[loan['emp_length'] == '4 years', 'empl_exp'] = 'intermed'\n", "loan.loc[loan['emp_length'] == '5 years', 'empl_exp'] = 'intermed'\n", "loan.loc[loan['emp_length'] == '6 years', 'empl_exp'] = 'intermed'\n", "\n", "loan.loc[loan['emp_length'] == '7 years', 'empl_exp'] = 'seasoned'\n", "loan.loc[loan['emp_length'] == '8 years', 'empl_exp'] = 'seasoned'\n", "loan.loc[loan['emp_length'] == '9 years', 'empl_exp'] = 'seasoned'\n", "\n", "loan.loc[loan['emp_length'] == 'n/a', 'empl_exp'] = 'unknown'\n", "\n", "#delete the emp_length column \n", "loan = loan.drop('emp_length',axis=1)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["#remove all rows with nans\n", "loan.dropna(axis=0, how = 'any', inplace = True)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print(loan['loan_status'].value_counts()/len(loan))"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["#extract the target column and convert to Charged Off to 1 and the rest as 0\n", "mask = (loan.loan_status == 'Charged Off')\n", "loan['target'] = 0\n", "loan.loc[mask,'target'] = 1\n", "\n", "target = loan['target']\n", "loan = loan.drop(['loan_status','target'],axis=1)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["target.value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next step is to convert all categorical data to dummy numerical data. First let's seperate the categorical from number columns"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["loan_categorical = loan.select_dtypes(include=['object'], exclude=['float64','int64'])\n", "features = loan.select_dtypes(include=['float64','int64'])"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["#one-hot-encode the categorical variables and combine with the numercal values\n", "for col in list(loan_categorical):\n", "    dummy = pd.get_dummies(loan_categorical[col])\n", "    features = pd.concat([features,dummy],axis=1)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["#time to split and build models\n", "from sklearn.model_selection import train_test_split\n", "X_train, X_test, y_train, y_test = train_test_split(features,target)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The model we will build is Random Forest"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import precision_recall_curve,average_precision_score\n", "from sklearn.metrics import confusion_matrix, classification_report"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["RF = RandomForestClassifier(n_estimators=500)\n", "RF.fit(X_train, y_train)\n", "y_pred = RF.predict(X_test)\n", "print('Test score: {:.2f}'.format(RF.score(X_test, y_test)))\n", "print(\"Confusion matrix:\\n%s\" % confusion_matrix(y_test, y_pred))\n", "print(\"Classification report for Random Forest classifier %s:\\n%s\\n\"\n", "      % (RF, classification_report(y_test, y_pred)))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Nice! Carefully selecting features as well as some feature engineering paid off! 100% precision and 98% Recall for all \"Charged off\" loans! Since the dataset is skewed, let's have a llok at the Precision and Recall curve"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["precision, recall, thresholds = precision_recall_curve(y_test,RF.predict_proba(X_test)[:, 1])\n", "AUC = average_precision_score(y_test, RF.predict_proba(X_test)[:, 1])\n", "\n", "plt.plot(precision, recall, label='AUC: {:.2f} for {} Trees'.format(AUC, 500))\n", "close_default_rf = np.argmin(np.abs(thresholds - 0.5))\n", "plt.plot(precision[close_default_rf], recall[close_default_rf], 'o', c='k',\n", "         markersize=10, fillstyle=\"none\", mew=2)\n", "\n", "plt.ylabel('Recall')\n", "plt.xlabel('Precision')\n", "plt.title('Precision-Recall Curve Random Forest')\n", "plt.legend(loc='best')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Next: The next step? We can use this model to determine the probability any of the \"Current\" customers will be \"Charged Off\". "]}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.1"}}, "nbformat_minor": 1}