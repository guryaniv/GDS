{"cells":[{"metadata":{"_uuid":"deb3a587b05eb7af7fbf9d5b7fee3ae863597d9e"},"cell_type":"markdown","source":"# Costa-Rica Household Poverty Prediction"},{"metadata":{"trusted":true,"_uuid":"b19b55cd678539f182aa71b7d2b4ab79aa0a0edf"},"cell_type":"code","source":"#@author: Abhishek Kumar Gauraw\n# 1.1 Data manipulation modules\nimport pandas as pd        # R-like data manipulation\nimport numpy as np         # n-dimensional arrays\n\n# 1.2 For pltting\nimport matplotlib.pyplot as plt      # For base plotting\n# Seaborn is a library for making statistical graphics\n# in Python. It is built on top of matplotlib and \n#  numpy and pandas data structures.\nimport seaborn as sns                # Easier plotting\n\n# 1.3 Misc\nimport os\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be448fb150945e5a161974f45b9dee0a2702dd33"},"cell_type":"code","source":"############## Data Loading and Exploration ##################\n# 2.1 Read data file\ndata_test = pd.read_csv(\"../input/test.csv\")\ndata_train = pd.read_csv(\"../input/train.csv\")\n\n\n# 2.2 Explore data\nprint(\"Dimension of Test DataSet :\" ) \ndata_test.shape                         # dim()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f8f1c6f92f289eb3c99160ea3cc197998fc4ac8"},"cell_type":"code","source":"print(\"Dimension of Training DataSet :\")\ndata_train.shape                        # dim()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b06cc7296a73b3f98ee5b4ac4af653b45ded4cbf"},"cell_type":"code","source":"print(\"Columns of Test DataSet :\")              \ndata_test.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b170a56694f21cb64d0479c7fa64df5fb8b847a"},"cell_type":"code","source":"print(\"Columns of Training DataSet :\")\ndata_train.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36560cfd0cde8515e54a57fc888eae66228dc53a"},"cell_type":"code","source":"print(\"Gllimpse/Summary of Test DataSet :\")\ndata_test.describe()                      # summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9cdb9c348f716c6d811e931fe02d7f084a15ecc"},"cell_type":"code","source":"print(\"Gllimpse/Summmary of Training DataSet :\")\ndata_train.describe()                     # summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"021b2a43fb64170ce9a1ca1221a2fe2e3dd160e8"},"cell_type":"code","source":"print(\"First five records of Test DataSet :\")\ndata_test.head()                          # Top 5 records of test data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf2468e03fdd8c2f1a76561cfef32b5c80368f9a"},"cell_type":"code","source":"print(\"First five records of Training DataSet :\")\ndata_train.head()                          # Top 5 records of training data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9246012a281564ba9f5df6d60d1f3e270c8f016"},"cell_type":"code","source":"# Identifying and Removing columns not useful in analysis\nmissing_col_train = data_train.isnull().sum().sort_values(0, ascending = False)\nprint(\"Missing or Null Value column: \")\nmissing_col_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9403f21b16e95e672e941d7b49be6b76ed06de8"},"cell_type":"code","source":"# Looking at this columns rez_esc,v18q1 and v2al have many null/missing values\n## Hence we can remove these 3 columns to avoid any issue in modelling further\n\ndata_train.drop([\"rez_esc\",\n              \"v18q1\",\n              \"v2a1\",\n    ], axis=1, inplace=True)\n\ndel(missing_col_train)\n\nprint(\"Removed 3 columns\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f374281dd34eebb1736fa9b689d478d44dbb261"},"cell_type":"code","source":"## Remove these 3 columns from test data to avoid any issue in modelling further\n\ndata_test.drop([\"rez_esc\",\n              \"v18q1\",\n              \"v2a1\",\n    ], axis=1, inplace=True)\n\nprint(\"Removed 3 columns from Test data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"586e48f805d5ec91f898f80d5a6f71c34d92bbf5"},"cell_type":"code","source":"print(\"New Dimension of Training DataSet :\")\ndata_train.shape  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea05a045819edf649487f353eddd54fc288b9733"},"cell_type":"code","source":"#We can finish off with the meaneduc and SQBmeaned label by imputing them with the median of the columns.\nmedian_meaneduc = data_train['meaneduc'].median()\nmedian_SQBmeaned = data_train['SQBmeaned'].median()\ndata_train['meaneduc'] = data_train['meaneduc'].fillna(median_meaneduc)\ndata_train['SQBmeaned'] = data_train['SQBmeaned'].fillna(median_SQBmeaned)\n\nmedian_meaneduc_test = data_test['meaneduc'].median()\nmedian_SQBmeaned_test = data_test['SQBmeaned'].median()\ndata_test['meaneduc'] = data_test['meaneduc'].fillna(median_meaneduc_test)\ndata_test['SQBmeaned'] = data_test['SQBmeaned'].fillna(median_SQBmeaned_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d512909c843a324d06eca275d4fe7b97a462bdef"},"cell_type":"code","source":"data_train.loc[data_train['Target'].isin([1]),'target_des'] = \"Extereme Poverty\"         \ndata_train.loc[data_train['Target'].isin([2]),'target_des'] = \"Vulnerable\"         \ndata_train.loc[data_train['Target'].isin([3]),'target_des'] = \"Moderate Poverty\"         \ndata_train.loc[data_train['Target'].isin([4]),'target_des'] = \"NonVulnerable\"         \n\ndata_train['Target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf85d7a631927638dd15a90977bb27b59993b252"},"cell_type":"code","source":"#Target - the target is an ordinal variable indicating groups of income levels. \n## 1 = extreme poverty \n## 2 = moderate poverty \n## 3 = vulnerable households \n## 4 = non vulnerable households\n\n# Count Plot for Group of different Income levels\nincome_lvl_plot = sns.countplot(\"target_des\", data = data_train)\nincome_lvl_plot.set_title(\"Group of Income Levels at Cost Rica\")\nincome_lvl_plot.set_xticklabels(income_lvl_plot.get_xticklabels(), rotation=45)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f14afc11c786096212e2188f4e922a40091d539"},"cell_type":"code","source":"# Violin Plot to determine gender wise distribution along with poverty level \ngenderwise_total = data_train[[\"r4h3\", \"r4m3\"]].groupby(data_train[\"target_des\"]).sum()\nprint(genderwise_total)\ngender_plot = (sns.violinplot(data=genderwise_total,\n               split=True,         # If hue variable has two levels, draw half of a violin for each level.\n               inner=\"quartile\"    #  Options: “box”, “quartile”, “point”, “stick”, None \n               )\n        .set_xticklabels(['Male','Female'])    \n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"533bf7ffef0d5e0cb154aae534f197ac3c5f361b"},"cell_type":"code","source":"male_plot = (sns.violinplot( y=data_train[\"target_des\"], x=data_train[\"r4h3\"] )\n           .set(xlabel='Male', ylabel='Poverty level')  \n           )\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35466a1b7c04b555ae484a80a140698a5bebc087"},"cell_type":"code","source":"female_plot = (sns.violinplot( y=data_train[\"target_des\"], x=data_train[\"r4m3\"] )\n            .set(xlabel='Female', ylabel='Poverty level')\n            )\n\ndel(genderwise_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"401f1d61b173bf47d84151b2b40205f429db36dc"},"cell_type":"code","source":"\n# Education level of people from Costa-Rica\nEdu_level_total = data_train[[\"instlevel1\", \"instlevel2\", \"instlevel3\",\"instlevel4\", \"instlevel5\", \"instlevel6\",\"instlevel7\", \"instlevel8\", \"instlevel9\"]].groupby(data_train[\"target_des\"]).sum()\n\nprint(Edu_level_total)\nlabels = ['No level of education', 'Incomplete primary', 'Complete primary', 'Incomplete academic secondary level','Complete academic secondary level','Incomplete technical secondary level','Complete technical secondary level','Undergraduate and higher education','Postgraduate higher education']\nsns.set_style(\"whitegrid\")\n\nedu_lvl_plot = (\n   sns.violinplot(data=Edu_level_total,\n               split=True,         \n               inner=\"quartile\"     \n               )\n   .set(xlabel='Education Level', ylabel='Poverty level')\n        \n)\n\nedu_lvl_plot = (\n   sns.violinplot(data=Edu_level_total,\n               split=True,         \n               inner=\"quartile\"     \n               )\n    .set_xticklabels(labels,rotation=20)\n)\n\ndel(Edu_level_total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a881cf134f10c711dc79fd896e2b2e123724cf5a"},"cell_type":"code","source":"#Check for households where The household population has unequal target distribution\nall_equal = data_train.groupby('idhogar')['Target'].apply(lambda x: x.nunique() == 1)\nnot_equal = all_equal[all_equal != True]\nprint(len(not_equal))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37f7b8b615034c385a8e8bc97dfd9b4d6019d82e"},"cell_type":"code","source":"#correcting the unqual households\nfor household in not_equal.index:\n    true_target = int(data_train[(data_train['idhogar'] == household) & (data_train['parentesco1'] == 1.0)]['Target'])\n    data_train.loc[data_train['idhogar'] == household, 'Target'] = true_target","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2a45cf5c749a0e2b190192a51dee00e44826d77"},"cell_type":"code","source":"data_train.fillna(-1, inplace = True)\ndata_test.fillna(-1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4d585c628b1805cb8cfafc2887593e07896d6c5"},"cell_type":"code","source":"data_train['dependency'] = np.sqrt(data_train['SQBdependency'])\ndata_test['dependency'] = np.sqrt(data_test['SQBdependency'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"880cdfb3af57257c5bb7654f22c0551f9975039e"},"cell_type":"code","source":"def mapping(data):\n    if data == 'yes':\n        return 1\n    elif data == 'no':\n        return 0\n    else:\n        return data\ndata_train['dependency'] = data_train['dependency'].apply(mapping).astype(float)\ndata_train['edjefa'] = data_train['edjefa'].apply(mapping).astype(float)\ndata_train['edjefe'] = data_train['edjefe'].apply(mapping).astype(float)\n\ndata_test['dependency'] = data_test['dependency'].apply(mapping).astype(float)\ndata_test['edjefa'] = data_test['edjefa'].apply(mapping).astype(float)\ndata_test['edjefe'] = data_test['edjefe'].apply(mapping).astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37001f5992d39ef526cb22e7201193c99fd07fa9"},"cell_type":"code","source":"#converting into percentages\ndata_train['males_above_12'] = data_train['r4h2']/data_train['r4h3']\ndata_train['person_above_12'] = data_train['r4t2']/data_train['r4t3']\ndata_train['size_to_person_ratio'] = data_train['tamhog']/data_train['tamviv']\n\ndata_test['males_above_12'] = data_test['r4h2']/data_test['r4h3']\ndata_test['person_above_12'] = data_test['r4t2']/data_test['r4t3']\ndata_test['size_to_person_ratio'] = data_test['tamhog']/data_test['tamviv']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"952c2dcbc8b8644a657df02f9b71f1d553194d8c"},"cell_type":"code","source":"data_train['males-above_12'] = data_train['males_above_12'].fillna(0)\ndata_test['males-above_12'] = data_test['males_above_12'].fillna(0)\n\ndata_train = data_train.fillna(0)\ndata_test = data_test.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4af7c1e3ae0a8c6c3e06fba4c28608ac3647a4d9"},"cell_type":"code","source":"# Assigning ID to sub before dropping\nsubmission = data_test[['Id']]\n#dropping other useless columns\ncols = ['Id','idhogar','SQBescolari','SQBage','SQBhogar_total','SQBedjefe','SQBhogar_nin','SQBovercrowding','SQBdependency','SQBmeaned','agesq']\ndata_train.drop(cols, axis = 1, inplace = True)\ndata_test.drop(cols, axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"754f7bd14dc4c0689ecdaef290f1b565c7eafb7c"},"cell_type":"code","source":"# Feature Engineering\n#creating the matrics of features\ny = data_train.Target.values\ndata_train.drop('Target', axis =1, inplace = True)\ndata_train.drop('target_des', axis =1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61a899accfdccca5b2b1011530dc41d41370baac"},"cell_type":"code","source":"X = data_train.iloc[:,:].values\nX_test = data_test.iloc[:,:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7475bfa55a4c05464b55f1221fcf2e717ca14b6"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier as RFC\nclassifier = RFC(n_estimators =25 , random_state = 0)\nclassifier.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1f1b180ec2a55abcbab19a665e643d52012216a"},"cell_type":"code","source":"predict_result = classifier.predict(X_test).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"322fc4f16942502f9c7fea671400364228ae2423"},"cell_type":"code","source":"sub = pd.DataFrame({\n    \"Id\" : submission['Id'],\n    \"Target\" : predict_result\n})\nsub.to_csv('sample_submission.csv', index =False, encoding = 'utf-8')\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"004175da594c2986ad74ab0c9b7ded06acbf883f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}