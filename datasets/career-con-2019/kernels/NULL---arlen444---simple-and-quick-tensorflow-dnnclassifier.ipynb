{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"X_train = pd.read_csv(\"../input/X_train.csv\")\ny_train = pd.read_csv(\"../input/y_train.csv\")\nsub = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52bd9d31c7c8f83ebe58c5d6cf013fe4614eec90"},"cell_type":"code","source":"def flattenDataframe(df):\n    '''\n    'Flatten a dataframe\n    '''\n    df_new = pd.DataFrame([])\n    for col in df.columns[3:]:\n        df_new[col + '_mean'] = df.groupby(['series_id'])[col].mean()\n        df_new[col + '_std'] = df.groupby(['series_id'])[col].std()\n        df_new[col + '_var'] = df.groupby(['series_id'])[col].var()\n        df_new[col + '_sem'] = df.groupby(['series_id'])[col].sem()\n        df_new[col + '_max'] = df.groupby(['series_id'])[col].max()\n        df_new[col + '_min'] = df.groupby(['series_id'])[col].min()\n        df_new[col + '_max_to_min'] = df_new[col + '_max'] / df_new[col + '_min']\n        df_new[col + '_max_minus_min'] = df_new[col + '_max'] - df_new[col + '_min']\n        df_new[col + '_std_to_var'] = df_new[col + '_std'] * df_new[col + '_var']\n        df_new[col + '_mean_abs_change'] = df.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        df_new[col + '_abs_max'] = df.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n    return df_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7600ec917a5b30af41c6ea028d6f7746b95db7e1"},"cell_type":"code","source":"X_train_flat = flattenDataframe(X_train)\nX_train_flat.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16ce301f936bfa4d8c526b0d84d6ec85015fc0a7"},"cell_type":"markdown","source":"### Apply Standard Scaling to our train dataset\n\nWhen using Neural Network and Deep Learning based systems, it is usually a good idea to Standardize your data, let's run through it!"},{"metadata":{"trusted":true,"_uuid":"a4a1cc1e368db8fc3401d740bd3b5ece6bbeda8c"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train_flat)\nscaled_features = scaler.fit_transform(X_train_flat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29b0716ed67875354c5482ff03bb3437d3c25ffe"},"cell_type":"code","source":"X_train_new = pd.DataFrame(scaled_features,columns=X_train_flat.columns)\nX_train_new.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc7e7f8b4a374d879d359bbc117f20a2ff2b1a05"},"cell_type":"markdown","source":"### Create y_train_new dataset by encoding categorical data"},{"metadata":{"trusted":true,"_uuid":"51262eede42bb1e48377e4e5629959312b3ac858"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder = LabelEncoder()\ny_train_new=labelencoder.fit_transform(y_train['surface'])\ny_train_new=pd.Series(y_train_new)\nprint(labelencoder.classes_)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"227fd777c38b330be775e5ed2aaee80d23fb99a6"},"cell_type":"markdown","source":"### Flattening X_test and applying Standard Scaling to our dataset"},{"metadata":{"trusted":true,"_uuid":"e854917ac8c11ae6141db81309b001ae113ddbd3"},"cell_type":"code","source":"X_test = pd.read_csv(\"../input/X_test.csv\")\n\nX_test_flat= flattenDataframe(X_test)\nscaler.fit(X_test_flat)\nscaled_features_train = scaler.fit_transform(X_test_flat)\nX_test_new = pd.DataFrame(scaled_features_train,columns=X_test_flat.columns)\nX_test_new.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"109837f6587c1456d57a43054020c72fd8438882"},"cell_type":"markdown","source":"### Tensorflow"},{"metadata":{"trusted":true,"_uuid":"9aaf8d929b21fac796a2c4b7806110fbc35b6fed"},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dfe889e14bfdf770003e01847d8f34f49993b66"},"cell_type":"markdown","source":"### Create a list of feature column objects using tf.feature.numeric_column() "},{"metadata":{"trusted":true,"_uuid":"5e54e3896df99ea47f6dc7f639a827b1f7da8306"},"cell_type":"code","source":"feat_cols = []\nfor key in X_train_new.keys():\n    feat_cols.append(tf.feature_column.numeric_column(key=key))\nfeat_cols","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde63b46c266783f15fa3b615520076a0a84e7d7"},"cell_type":"markdown","source":"### Create an object called classifier which is a DNNClassifier from learn.\nSet it to have 9 classes and a [20,40,20] hidden unit layer structure:"},{"metadata":{"trusted":true,"_uuid":"04f2143581f6bf4233dd56aca50185a956f2ac4b"},"cell_type":"code","source":"steps=20000\nn=9\nLayers = [20,40,20]  \nclassifier = tf.estimator.DNNClassifier(\n                                        hidden_units=Layers,\n                                        n_classes=n,\n                                        feature_columns=feat_cols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"337a403408e56605258c418100dc1e6483c1c402"},"cell_type":"markdown","source":"### Now create a tf.estimator.pandas_input_fn that takes in your X_train, y_train, batch_size and set shuffle=True. "},{"metadata":{"trusted":true,"_uuid":"e160bafe450ed39af3b5bc690c408a461d4c311b"},"cell_type":"code","source":"input_func = tf.estimator.inputs.pandas_input_fn(x=X_train_new,\n                                                 y=y_train_new,\n                                                batch_size=10,num_epochs=500,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e2547a1292fe3a75de23d980d325e20e05515cc"},"cell_type":"markdown","source":"### Now train classifier to the input function "},{"metadata":{"trusted":true,"_uuid":"ef38808b603cf18e041c5b10c9d0b5b9b0070a0c"},"cell_type":"code","source":"classifier.train(input_fn=input_func,steps=steps)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a37e2f1667ff430eb348b1abd72419ef178cbd2"},"cell_type":"markdown","source":"### Use the predict method from the classifier model to create predictions from X_test "},{"metadata":{"trusted":true,"_uuid":"f33c9af91c5a4888911d10db2f6ba32f6e8a57f4"},"cell_type":"code","source":"pred_fn = tf.estimator.inputs.pandas_input_fn(\n      x=X_test_new,\n      batch_size=10,\n      num_epochs=1,\n      shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fea65c2cb3d25005d786858cd51317290d41c39"},"cell_type":"code","source":"note_predictions = list(classifier.predict(input_fn=pred_fn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8b4849267066b37fbc9cc6a6c4a38588b08878b"},"cell_type":"code","source":"final_preds  = []\nfor pred in note_predictions:\n    class_id=pred['class_ids'][0]\n    final_preds.append(class_id)\n    \nset(final_preds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62e58fc0b3e89a7a48572292e7abf627660f5ab8"},"cell_type":"markdown","source":"### Create a dataframe from our predictions "},{"metadata":{"trusted":true,"_uuid":"f42e36548ed069246bd6fe1e4254b8d0f9ba33e3"},"cell_type":"code","source":"df_pred= pd.DataFrame({'surface_code':final_preds})\ndf_pred.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01245a830fef3718189867b76a047c5d5d5d57c7"},"cell_type":"markdown","source":"### Decoding our surface_code and save the result to submission file"},{"metadata":{"trusted":true,"_uuid":"6b78851ba3de718ea9380e14f8882f0315fe9115"},"cell_type":"code","source":"df_pred['surface']=labelencoder.inverse_transform(df_pred['surface_code'])\nsub['surface'] = df_pred['surface']\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a661704871e42c0dfb9690e45b747f8cec4696c"},"cell_type":"code","source":"#train_eval_result = classifier.evaluate(input_fn=input_func)\n#print(\"Training set accuracy: {accuracy}\".format(**train_eval_result))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1f79e404a6b11a473754528eebcc9f6d8f15e75"},"cell_type":"markdown","source":"train_eval_result = classifier.evaluate(input_fn=input_func)\nprint(\"Training set accuracy: {accuracy}\".format(**train_eval_result))\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2019-03-19T17:57:11Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Finished evaluation at 2019-03-19-18:50:53\nINFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9007874, average_loss = 0.2592908, global_step = 20000, loss = 2.5929081\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: \n\n**Training set accuracy: 0.9007874131202698**"},{"metadata":{"trusted":true,"_uuid":"b40cb7a0b7edbe635dc064dce3e893b8d8535282"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}