{"metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py"}}, "cells": [{"metadata": {"_cell_guid": "390315bc-fecf-489c-bc29-407fbe668c0d", "_uuid": "ab034cbc2149bacffa3bd425178cb94d815fe406"}, "cell_type": "markdown", "source": ["Here we explore the text normalization data with a primary focus on dicks.  We demonstrate that you can never have enough dicks.  Over 30 dicks are erected in this kegel notebook.  The strength and capability of a dick is truly impressive because they are solid, inflexible, and fast to finish (look ups).  We will use dicks to find the g-spot (g for google).  Some dicks are very long -- over 10 million in length!  Whether you like long or short dicks... this notebook is for you! \n", "\n", "1. (1)  **READ THE TRAIN SHIT FILE**\n", "1. (2)  **FIGURE OUT WHAT'S DIFFERENT**\n", "1. (3)  **LOOK AT NOT SAME SHIT**\n", "1. (4)  **FIGURE OUT WHICH SHIT IS THE SAME**\n", "1. (5)  **BUILD SOME DICKS**\n", "1. (6)  **FUCKING MISSING SHIT**\n", "1. (7)  **LOOK AT THE FUCKING MISSING SHIT**\n", "1. (8)  **BUILD SOME MORE DICKS**\n", "1. (9)  **FIGURE OUT WHERE NOT SAME SHIT HAS DIFFERENT SHIT**\n", "1. (10)  **LOOK AT THAT SHIT**\n", "1. (11)  **LOOK AT THAT SHIT AGAIN BUT DIFFERENT**\n", "1. (12)  **FIND WHERE THE AFTER PARTY HAS CAPITAL LETTERS AND FIGURE OUT WTF**\n", "\n", "UPDATE! \n", "1. (13)  **OMG KEGEL, G-SPOT. WT\n", "\n", "\n", "1. (13)  **THROW AN ERROR**"]}, {"metadata": {"_cell_guid": "371661d6-7455-40a6-b68e-d51dc4ce2b78", "_uuid": "bd59c14c0d386e130c290a754e7174ea058f4b56"}, "cell_type": "code", "execution_count": null, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": []}, {"metadata": {"_cell_guid": "e6c0d68f-b16f-498e-b784-e4d9a637a187", "_uuid": "1b313b46af750b85f20c45c9359796681c4b81e1", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["import re, string, collections\n", "from fuzzywuzzy import fuzz\n", "from tqdm import tqdm\n", "from IPython.display import display\n"], "outputs": []}, {"metadata": {"_cell_guid": "57dbd9e7-507c-4952-9552-c5fbb0a6ad23", "_uuid": "0d0ad8fbf2f0cc34e3082835cdfe90c8138311ec"}, "cell_type": "markdown", "source": ["1. **READ THE TRAIN SHIT FILE**"]}, {"metadata": {"_cell_guid": "20df103c-9ad0-4361-a1db-e99eb4e54f95", "_uuid": "005127249e918318080fb183545ead30b0f3fa89"}, "cell_type": "code", "execution_count": null, "source": ["# Read en_train.csv  file.\n", "test_df = pd.read_csv(filepath_or_buffer=\"../input/en_test.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n", "train_df = pd.read_csv(filepath_or_buffer=\"../input/en_train.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n", "train_df.head()\n", "\n"], "outputs": []}, {"metadata": {"_cell_guid": "c9a2e89b-307e-4d4e-90e1-4065d4ba2eeb", "_uuid": "206b04817343b36877db2eff0cda7adff8cd6017", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["test_before = test_df['before'].tolist()\n", "train_after = train_df['after'].tolist()\n", "train_class = train_df['class'].tolist()\n", "test_idx = test_df.index.tolist()\n", "train_before = train_df['before'].tolist()\n", "train_idx = train_df.index.tolist()\n", "\n", "test_before_DICK = dict(zip(test_idx, test_before))\n", "train_idx_before_DICK = dict(zip(train_idx, train_before))\n", "train_idx_after_DICK = dict(zip(train_idx, train_after))\n", "\n", "\n", "test_before_str_only = [(x,y) for x,y in zip(test_idx, test_before) if type(y) == type(str())]\n", "test_before_str_only_idxs = [x[0] for x in test_before_str_only]\n", "\n", "train_before_str_only = [(x,y) for x,y in zip(train_idx, train_before) if type(y) == type(str())]\n", "train_before_str_only_idxs = [x[0] for x in train_before_str_only]"], "outputs": []}, {"metadata": {"_cell_guid": "34dd6db5-9f7b-43d1-a2b9-5cb6a161e108", "_uuid": "2cdb0f65c6f0df686a5fdcf5775433083d32c59d"}, "cell_type": "code", "execution_count": null, "source": ["#display(train_df[pd.isnull(train_df['after'])])\n", "#display(test_df[pd.isnull(test_df['before'])])\n", "trb_nan_idx = train_df[pd.isnull(train_df['before'])].index.tolist()\n", "\n", "train_df.loc[trb_nan_idx, 'before'] = ' '\n", "train_df.loc[trb_nan_idx, 'after'] = ' ' \n", "\n", "#train_df['before'] = train_df['before'].fillna(' ')\n", "#train_df['after'] = train_df['after'].fillna(' ')\n", "test_df['before'] = test_df['before'].fillna(' ')\n", "\n", "display(train_df[pd.isnull(train_df['before'])])"], "outputs": []}, {"metadata": {"_cell_guid": "761690ab-883c-402e-89c0-a0150a3a3df9", "_uuid": "ea2a785eb9684ffbde3e8f3e6d304fa17aee330d"}, "cell_type": "markdown", "source": ["(2)  **FIGURE OUT WHAT'S DIFFERENT**"]}, {"metadata": {"_cell_guid": "db244dd9-f295-422a-853f-75c248991213", "_uuid": "1e6031be57e0ac7cfaf3262a1a52f92f59d3c6aa"}, "cell_type": "code", "execution_count": null, "source": ["#np.array(train_df['before'])\n", "arr_after = np.array(train_df['after'])\n", "\n", "idx_not_same = list()\n", "for each_after, each_beforeiter in zip(tqdm(arr_after), train_df['before'].iteritems()):\n", "    if each_after != each_beforeiter[1]:\n", "        idx_not_same.append(each_beforeiter[0])\n", "\n", "print(str(len(idx_not_same)) + ' NOT SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_not_same) / len(train_df)) + ' %)')"], "outputs": []}, {"metadata": {"_cell_guid": "d8eb37cb-41bd-4c9e-be4f-6dbca450f11e", "_uuid": "5d6266f3323e142151d0e3756a2b7d261b3d1681"}, "cell_type": "code", "execution_count": null, "source": ["#thing = \n", "counter_notsame_class = collections.Counter(np.array(train_df.loc[idx_not_same, 'class']))\n", "display(pd.DataFrame([(i, str(counter_notsame_class[i] / len(idx_not_same) * 100.0)[:5] + ' %') for i, count in counter_notsame_class.most_common()], columns=['classy', '%_of_notsame']))\n", "#tkeys, tvalues = zip(*thing.items())\n", "\n", "display(train_df.loc[idx_not_same[:10]])"], "outputs": []}, {"metadata": {"_cell_guid": "bd3dff7f-86cf-4c21-92e3-38d565592378", "_uuid": "5aeb71d19704b14e80f8ba1d5fbd971ac6c9c074"}, "cell_type": "markdown", "source": ["(3)  **LOOK AT NOT SAME SHIT**"]}, {"metadata": {"_cell_guid": "c6dda98d-8d15-441f-ab2d-7d05ae74fed6", "_uuid": "56c21ff84e255d578c5e1ee2a41221c86c332cb9"}, "cell_type": "code", "execution_count": null, "source": ["for each_subdf in train_df.loc[idx_not_same].groupby(by=['class']):\n", "    display(each_subdf[1][:10])"], "outputs": []}, {"metadata": {"_cell_guid": "539ebd2c-f596-4c73-abe8-bfc09b0ccbc3", "_uuid": "c733a19d0e5f6544c36db036543e5524de5308fd"}, "cell_type": "markdown", "source": ["(4)  **FIGURE OUT WHICH SHIT IS THE SAME**"]}, {"metadata": {"_cell_guid": "b1b63844-9c37-4421-9389-cab16d2bf279", "_uuid": "ef9931e3ea586878bc04928f90b97756179f900b"}, "cell_type": "code", "execution_count": null, "source": ["idx_are_same = set(train_df.index) - set(idx_not_same)\n", "print(str(len(idx_are_same)) + ' ARE SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_are_same) / len(train_df)) + ' %)')"], "outputs": []}, {"metadata": {"_cell_guid": "52538678-2dc9-4317-8422-177d8b8a8fcc", "_uuid": "3a3e05487117e9b474fa6b382791ee98300b9a57"}, "cell_type": "markdown", "source": ["(5)  **BUILD SOME DICKS**"]}, {"metadata": {"_cell_guid": "4085412d-8ad7-4569-ab7a-9a83553ff9f0", "_uuid": "f95a18cc2b9cb9c093397c234e9b8013d2323971"}, "cell_type": "code", "execution_count": null, "source": ["# find rows where before is the same but after is different\n", "# find rows where after is the same but before is different\n", "# and class is different?\n", "#build a before dick\n", "train_df_idx = np.array(train_df.index)\n", "arr_before = np.array(train_df['before'])\n", "before_DICK = dict()\n", "for each_idx, each_before in zip(tqdm(train_df_idx), arr_before):\n", "    if each_before in before_DICK:\n", "        before_DICK[each_before].append(each_idx)\n", "    else:\n", "        before_DICK[each_before] = [each_idx]\n", "            \n"], "outputs": []}, {"metadata": {"_cell_guid": "2bf34f02-b1aa-40a0-ad34-e333ff3f8c20", "_uuid": "ec6826e893ff26ab9cad1b085e584a6e1f4093a9"}, "cell_type": "code", "execution_count": null, "source": ["# build a after dick\n", "after_DICK = dict()\n", "for each_idx, each_after in zip(tqdm(train_df_idx), arr_after):\n", "    if each_after in after_DICK:\n", "        after_DICK[each_after].append(each_idx)\n", "    else:\n", "        after_DICK[each_after] = [each_idx]"], "outputs": []}, {"metadata": {"_cell_guid": "179d017d-eaed-4deb-ab42-9635c01fbe50", "_uuid": "b6f97bf6b0206f1109bb365b3f56a6bf55fb8f99"}, "cell_type": "code", "execution_count": null, "source": ["# build a classy dick\n", "arr_class = np.array(train_df['class'])\n", "classy_DICK = dict()\n", "for each_idx, each_class in zip(tqdm(train_df_idx), arr_class):\n", "    if each_class in classy_DICK:\n", "        classy_DICK[each_class].append(each_idx)\n", "    else:\n", "        classy_DICK[each_class] = [each_idx]"], "outputs": []}, {"metadata": {"_cell_guid": "f8faf3fa-80cc-4f0a-bf05-1ec66fff3e6f", "_uuid": "5952c72a006ec0346dccdf738cdef07a9ea640ed"}, "cell_type": "markdown", "source": ["**DICKS ERECTION**"]}, {"metadata": {"_cell_guid": "ab221cd3-380f-4d7b-bd88-b57b27c35c81", "_uuid": "715704daece6aaccee1d3d5ddabf1c82a1f5147a"}, "cell_type": "code", "execution_count": null, "source": ["train_class = train_df['class'].tolist()\n", "tr_sentID = train_df['sentence_id'].tolist()\n", "t_sentID = test_df['sentence_id'].tolist()\n", "\n", "before_DICK = dict()\n", "after_DICK = dict()\n", "classy_DICK = dict()\n", "tr_sentID_DICK = dict()\n", "#t_sentID_DICK = dict()\n", "\n", "tr_ba_diff = list()\n", "\n", "for each_idx, each_before, each_after, each_class, each_tr_sID in zip(tqdm(train_idx), train_before, train_after, train_class, tr_sentID):\n", "    if each_before != each_after:\n", "        tr_ba_diff.append(each_idx)\n", "        \n", "    if each_before in before_DICK:\n", "        before_DICK[each_before].append(each_idx)\n", "    else:\n", "        before_DICK[each_before] = [each_idx]\n", "            \n", "    if each_after in after_DICK:\n", "        after_DICK[each_after].append(each_idx)\n", "    else:\n", "        after_DICK[each_after] = [each_idx]\n", "\n", "    if each_class in classy_DICK:\n", "        classy_DICK[each_class].append(each_idx)\n", "    else:\n", "        classy_DICK[each_class] = [each_idx] \n", "    \n", "    if each_tr_sID in tr_sentID_DICK:\n", "        tr_sentID_DICK[each_tr_sID].append(each_idx)\n", "    else:\n", "        tr_sentID_DICK[each_tr_sID] = [each_idx]\n", "print('i done')        "], "outputs": []}, {"metadata": {"_cell_guid": "16d78bda-6def-4cda-9006-77d2a800d8bc", "_uuid": "9f432ba36faf37c084e9ebe04268a4692126ec66"}, "cell_type": "markdown", "source": ["(6)  **FUCKING MISSING SHIT**"]}, {"metadata": {"_cell_guid": "0c7be710-bbfd-4fa0-9229-d1f7a9f4ebcf", "_uuid": "6b0e4422882e4225f0aff6a24c5943395f154c6e"}, "cell_type": "code", "execution_count": null, "source": ["print(len(before_DICK))\n", "print(len(after_DICK))\n", "print(len(classy_DICK))\n", "\n", "# fucking missing shit\n", "after_dick_nan_idxs = after_DICK.pop(np.nan, None)\n", "before_dick_nan_idxs = before_DICK.pop(np.nan, None)\n"], "outputs": []}, {"metadata": {"_cell_guid": "be6897d8-94b6-43ca-9751-416cb524e888", "_uuid": "b977cd537a67ca3e3258e5a9e7e57be5e423d857"}, "cell_type": "markdown", "source": ["(7)  **LOOK AT THE FUCKING MISSING SHIT... LOOK AT IT!!!**"]}, {"metadata": {"_cell_guid": "57922e2e-8210-42cb-a31d-f773bae8c89e", "_uuid": "166895d6ba3cbee962d84624b5cd70c955dd0088"}, "cell_type": "code", "execution_count": null, "source": ["for key,val in classy_DICK.items():\n", "    #classy_letters = classy_DICK.get('LETTERS')\n", "    display(train_df.loc[set(val).intersection(before_dick_nan_idxs)])"], "outputs": []}, {"metadata": {"_cell_guid": "6a766822-6536-4111-a6c2-9c39b803bdf0", "_uuid": "674b819332efff5b0a84197728df0578a9e3f408"}, "cell_type": "code", "execution_count": null, "source": ["for key,val in classy_DICK.items():\n", "    #classy_letters = classy_DICK.get('LETTERS')\n", "    display(train_df.loc[set(val).intersection(after_dick_nan_idxs)])"], "outputs": []}, {"metadata": {"_cell_guid": "113bfb63-97a0-429c-8529-a4228f633ed2", "_uuid": "94909b9af5a7dcc814a85c8601d9f709bf323b17"}, "cell_type": "markdown", "source": ["(8)  **BUILD SOME MORE DICKS**"]}, {"metadata": {"_cell_guid": "0dd7faba-f7fc-4d46-a4bf-36894a87f588", "_uuid": "232b21b01660135957b90807321d1340fbd4e34c", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["# build index to after dick\n", "idx_after_DICK = dict(zip(np.array(train_df.index), np.array(train_df['after'])))"], "outputs": []}, {"metadata": {"_cell_guid": "8b758e40-ae0a-49ca-8eef-971dc6666c2e", "_uuid": "727ef6da1609dac9b8c89b5d2a1524e034410787"}, "cell_type": "markdown", "source": ["(9)  **FIGURE OUT WHERE NOT SAME SHIT HAS DIFFERENT SHIT**"]}, {"metadata": {"_cell_guid": "47c2c883-c832-40e3-9fc8-b7fb9b590169", "_uuid": "e1f56f702159160f4ee04c498de8a8b44d3c54c0"}, "cell_type": "code", "execution_count": null, "source": ["# find rows where before is the same but after is different\n", "# find rows where after is the same but before is different\n", "# and class is different?\n", "before_with_different_after = list()\n", "most_common_after_of_before = list()\n", "with tqdm(total=len(before_DICK)) as pbar:\n", "    for key, value in before_DICK.items():\n", "        #unique_afters_of_before = train_df.loc[value, 'after'].unique() #slow as shit\n", "        get_that_shit = [idx_after_DICK.get(x) for x in value]\n", "        cafters, ccounts = zip(*collections.Counter(get_that_shit).most_common())\n", "        most_common_after_of_before.append((key, cafters[0])) #before, after\n", "        unique_afters_of_before = set(get_that_shit)\n", "        pbar.update()\n", "        if len(unique_afters_of_before) != 1:\n", "            before_with_different_after.append((key, value, unique_afters_of_before))\n", "\n", "print(len(before_with_different_after))"], "outputs": []}, {"metadata": {"_cell_guid": "5f609248-582e-40d6-8bbb-b0867f0bc87a", "_uuid": "97b0e54387b1a549b1761f5305f1bd7e7b87e5e5"}, "cell_type": "code", "execution_count": null, "source": ["# build me a quick DICK\n", "\n", "print(len(most_common_after_of_before))"], "outputs": []}, {"metadata": {"_cell_guid": "989abf3d-7478-4036-8432-2e241b51efe5", "_uuid": "d14a8516f06db390ace62783dd0812c8b7ab0bb3"}, "cell_type": "markdown", "source": ["(10)  **LOOK AT THAT SHIT**"]}, {"metadata": {"_cell_guid": "bf7d0872-741d-4227-9771-1e387409ed99", "_uuid": "d9ce4ae5a197fa4d487e7b1cc77bc4a0ada20673"}, "cell_type": "code", "execution_count": null, "source": ["pd.DataFrame(before_with_different_after[:10])"], "outputs": []}, {"metadata": {"_cell_guid": "41715e39-3ad4-47d0-8631-baa6255f00b5", "_uuid": "adf295f6ac0db7c8bf5bc13c124e3b28bcb12d06"}, "cell_type": "code", "execution_count": null, "source": ["the_before_diff_after, some_idxs, _ = zip(*before_with_different_after)\n", "list_after_idxs_not_matching = list()\n", "for each_before, each_listidxs in zip(tqdm(the_before_diff_after), some_idxs):\n", "    after_idxs_not_matching = list()\n", "    seen_afters = set()\n", "    for each_after in each_listidxs:\n", "        some_after = idx_after_DICK.get(each_after)\n", "        if (each_before != some_after) & (some_after not in seen_afters):\n", "            seen_afters.add(some_after)\n", "            after_idxs_not_matching.append(each_after)\n", "    list_after_idxs_not_matching.append(after_idxs_not_matching)"], "outputs": []}, {"metadata": {"_cell_guid": "f88a0ac3-c8bf-49fc-90e9-1ab6316a6f04", "_uuid": "60468a0a9d56a700b80602705812d36165fb7fef"}, "cell_type": "markdown", "source": ["(11)  **LOOK AT THAT SHIT AGAIN BUT DIFFERENT**"]}, {"metadata": {"_cell_guid": "06b58660-91ab-4910-b7bf-931a5d239ef0", "_uuid": "7fb042a87714b108f7e19f3a1297faa4f0b6f09c"}, "cell_type": "code", "execution_count": null, "source": ["print(sum([len(x) for x in list_after_idxs_not_matching]))\n", "keep_min = [min(x) for x in list_after_idxs_not_matching]\n", "#display(train_df.loc[keep_min[:10]])\n", "\n", "for key,val in classy_DICK.items():\n", "    #classy_letters = classy_DICK.get('LETTERS')\n", "    display(train_df.loc[set(val).intersection(keep_min)].sort_values(by=['before','after']))"], "outputs": []}, {"metadata": {"_cell_guid": "9922b29e-37eb-49af-90d3-8d49a7e828c3", "_uuid": "e8c67a97e17b4df58430e3cf6e2db89d0dfbe0eb"}, "cell_type": "markdown", "source": ["(12)  **FIND WHERE THE AFTER PARTY HAS CAPITAL LETTERS AND FIGURE OUT WTF**"]}, {"metadata": {"_cell_guid": "4f405946-a55e-4cfe-bde4-98df9a79d7ef", "_uuid": "7ff10dc8f628f0933a62aa289d5f68720f2ece86"}, "cell_type": "code", "execution_count": null, "source": ["mixedcase_after = list()\n", "allcaps_after = list()\n", "with tqdm(total=len(after_DICK)) as pbar:\n", "    for key, value in after_DICK.items():\n", "        if key.isupper():\n", "            allcaps_after.append((key, value))\n", "        elif key.lower() != key:\n", "            mixedcase_after.append((key, value))\n", "        pbar.update()\n", "print(len(allcaps_after))\n", "print(len(mixedcase_after))        "], "outputs": []}, {"metadata": {"_cell_guid": "79ff4d6b-39af-42ac-8210-270f46d1380d", "_uuid": "1d30d598105ea06f1315efd59634d10d91711432"}, "cell_type": "code", "execution_count": null, "source": ["test_df = pd.read_csv(filepath_or_buffer=\"../input/en_test.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n", "\n", "UNI_RANGES = [('CJK Ideographs Extension A', 13312, 19893, '3400', '4DB5'),\n", " ('CJK Ideographs', 19968, 40869, '4E00', '9FA5'),\n", " ('Hangul Syllables', 44032, 55203, 'AC00', 'D7A3'),\n", " ('Non-Private Use High Surrogates', 55296, 56191, 'D800', 'DB7F'),\n", " ('Private Use High Surrogates', 56192, 56319, 'DB80', 'DBFF'),\n", " ('Low Surrogates', 56320, 57343, 'DC00', 'DFFF'),\n", " ('The Private Use Area', 57344, 63743, 'E000', 'F8FF')]\n", "NAMED_RANGE = [(13312, 19893), (19968, 40869), (44032, 55203), (55296, 56191), (56192, 56319), (56320, 57343), (57344, 63743)]\n", "\n", "\n", "test_before = test_df['before'].tolist()\n", "train_after = train_df['after'].tolist()\n", "test_idx = test_df.index.tolist()\n", "train_before = train_df['before'].tolist()\n", "train_idx = train_df.index.tolist()\n", "\n", "\n", "test_before_DICK = dict(zip(test_idx, test_before))\n", "train_idx_before_DICK = dict(zip(train_idx, train_before))\n", "train_idx_after_DICK = dict(zip(train_idx, train_after))\n", "\n", "\n", "test_before_str_only = [(x,y) for x,y in zip(test_idx, test_before) if type(y) == type(str())]\n", "test_before_str_only_idxs = [x[0] for x in test_before_str_only]\n", "\n", "train_before_str_only = [(x,y) for x,y in zip(train_idx, train_before) if type(y) == type(str())]\n", "train_before_str_only_idxs = [x[0] for x in train_before_str_only]\n", "\n", "print(len(train_before_str_only))\n", "print(len(test_before_str_only))\n", "\n", "\n", "train_crazy = ''.join([x[1] for x in tqdm(train_before_str_only)])\n", "test_crazy = ''.join([x[1] for x in tqdm(test_before_str_only)])\n", "train_crazyset = set(train_crazy)\n", "test_crazyset = set(test_crazy)\n", "print(str(len(train_crazyset)))\n", "print(str(len(test_crazyset)))\n", "\n", "\n", "train_not_in_test = sorted(list(train_crazyset - test_crazyset))\n", "crazy_ords = [ord(x) for x in train_not_in_test]\n", "\n", "weird_ords = [y for y in crazy_ords if not any([True if (y <= x[1]) and (y >= x[0]) else False for x in NAMED_RANGE])]\n", "\n", "thingy = pd.DataFrame(weird_ords)\n", "thingy.plot()\n", "#display(pd.DataFrame(np.array(train_not_in_test[:1000]).reshape((50, 20))))\n", "\n", "\n", "len(weird_ords)\n", "display(pd.DataFrame(np.array([chr(x) for x in weird_ords + [34]*3]).reshape((20, 20))))\n", "\n", "\n", "t_alpha = [x for x in tqdm(test_before_str_only) if x[1].isalpha()]\n", "t_alnum = [x for x in tqdm(test_before_str_only) if x[1].isalnum() and not x[1].isalpha()]\n", "t_upper = [x for x in tqdm(test_before_str_only) if x[1].isupper()]\n", "t_lower = [x for x in tqdm(test_before_str_only) if x[1].islower()]\n", "t_numer = [x for x in tqdm(test_before_str_only) if x[1].isnumeric()]\n", "t_space_all = [x for x in tqdm(test_before_str_only) if x[1].isspace()]\n", "t_space_any = [x for x in tqdm(test_before_str_only) if any([y.isspace() for y in x[1]])]\n", "t_punct_all = [x for x in tqdm(test_before_str_only) if all([y in string.punctuation for y in x[1]])]\n", "#t_punct_any = [x for x in tqdm(test_before_str_only) if any([y in string.punctuation for y in x[1]])]\n", "t_punct_any = [x for x in tqdm(test_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n", "\n", "\n", "tr_alpha = [x for x in tqdm(train_before_str_only) if x[1].isalpha()]\n", "tr_alnum = [x for x in tqdm(train_before_str_only) if x[1].isalnum() and not x[1].isalpha()]\n", "tr_upper = [x for x in tqdm(train_before_str_only) if x[1].isupper()]\n", "tr_lower = [x for x in tqdm(train_before_str_only) if x[1].islower()]\n", "tr_numer = [x for x in tqdm(train_before_str_only) if x[1].isnumeric()]\n", "tr_space_all = [x for x in tqdm(train_before_str_only) if x[1].isspace()]\n", "tr_space_any = [x for x in tqdm(train_before_str_only) if any([y.isspace() for y in x[1]])]\n", "tr_punct_all = [x for x in tqdm(train_before_str_only) if all([y in string.punctuation for y in x[1]])]\n", "tr_punct_any = [x for x in tqdm(train_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n", "\n", "# FOR TEST\n", "thing = [len(x) for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any]]\n", "thing2 = list(zip(['t_alpha', 't_alnum', 't_upper', 't_lower', 't_numer', 't_space_all', 't_space_any', 't_punct_all', 't_punct_any'], thing))\n", "display(pd.DataFrame(thing2, columns=['type', 'howmany']))\n", "\n", "\n", "# FOR TRAIN\n", "thing = [len(x) for x in [tr_alpha, tr_alnum, tr_upper, tr_lower, tr_numer, tr_space_all, tr_space_any, tr_punct_all, tr_punct_any]]\n", "thing2 = list(zip(['tr_alpha', 'tr_alnum', 'tr_upper', 'tr_lower', 'tr_numer', 'tr_space_all', 'tr_space_any', 'tr_punct_all', 'tr_punct_any'], thing))\n", "display(pd.DataFrame(thing2, columns=['type', 'howmany']))\n", "\n", "\n", "thing = [[y[1] for y in x[:30]] for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any]]\n", "thing2 = pd.DataFrame(thing).T\n", "thing2.columns = ['t_alpha', 't_alnum', 't_upper', 't_lower', 't_numer', 't_space_all', 't_space_any', 't_punct_all', 't_punct_any']\n", "display(thing2)\n", "print(sum(thing))\n", "print(len(train_before_str_only))\n", "print(sum(thing))\n", "print(len(test_before_str_only))\n", "tr_punct_any = [x for x in tqdm(train_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n", "\n", "\n", "identified_test_idxs = [y[0] for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any] for y in x ]\n", "unique_ID_test_idxs = set(identified_test_idxs)\n", "print(len(unique_ID_test_idxs))\n", "\n", "mystery_test_idxs = set(test_before_str_only_idxs) - unique_ID_test_idxs\n", "print(len(mystery_test_idxs))\n", "\n", "mystery_test_before = [test_before_DICK[x] for x in list(mystery_test_idxs)]\n", "unique_mystery_test_before = list(set(mystery_test_before))\n", "print(len(unique_mystery_test_before))\n", "display(pd.DataFrame(unique_mystery_test_before))\n", "#display(pd.DataFrame(np.array(unique_mystery_test_before[:240]).reshape((30, 8))))\n", "\n", "# FOR TEST\n", "#thing = [(x,y) for x,y in t_alpha if not all([z in string.ascii_letters for z in y])]\n", "thing = [y for x,y in t_alpha if not all([z in string.ascii_letters for z in y])]\n", "print(len(thing))\n", "thing2 = list(set(thing))\n", "print(len(thing2))\n", "thing3 = [x for x in thing2 if len(x) == 1]\n", "print(len(thing3))\n", "\n", "#display(pd.DataFrame(np.array(thing2[:300]).reshape((30, 10))))\n", "display(pd.DataFrame(np.array(thing3[:400]).reshape((20, 20))))\n", "\n", "thing4 = pd.DataFrame(sorted([ord(x) for x in thing3]))\n", "\n", "thing4.hist()\n", "thing4.plot()\n", "\n", "\n", "\n", "#FOR TRAIN\n", "thing = [y for x,y in tr_alpha if not all([z in string.ascii_letters for z in y])]\n", "print(len(thing))\n", "thing2 = list(set(thing))\n", "print(len(thing2))\n", "thing3 = [x for x in thing2 if len(x) == 1]\n", "print(len(thing3))\n", "\n", "thing_b_a = [(y, train_idx_after_DICK[x]) for x,y in tr_alpha if (not all([z in string.ascii_letters for z in y])) and (len(y) == 1)]\n", "thing_b_a_unique = list(set(thing_b_a))\n", "#thing_b_a = list(zip(thing, thing_after))\n", "#display(pd.DataFrame(np.array(thing2[:300]).reshape((30, 10))))\n", "thingcols = ['b','a'] * 10\n", "display(pd.DataFrame(np.array(thing_b_a_unique[:200]).reshape((20, 20)), columns=thingcols))\n", "\n", "thing4 = pd.DataFrame(sorted([ord(x) for x in thing3]))\n", "thing4.hist()\n", "thing4.plot()\n", "\n", "\n", "#np.array(train_df['before'])\n", "arr_after = np.array(train_df['after'])\n", "\n", "idx_not_same = list()\n", "for each_after, each_beforeiter in zip(tqdm(arr_after), train_df['before'].iteritems()):\n", "    if each_after != each_beforeiter[1]:\n", "        idx_not_same.append(each_beforeiter[0])\n", "print(str(len(idx_not_same)) + ' NOT SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_not_same) / len(train_df)) + ' %)')\n", "\n", "idx_are_same = set(train_df.index) - set(idx_not_same)\n", "print(str(len(idx_are_same)) + ' ARE SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_are_same) / len(train_df)) + ' %)')\n", "\n"], "outputs": []}, {"metadata": {"_cell_guid": "07c6853c-43f8-4d4d-bd2b-d374cbf0d6a8", "_uuid": "5108e3c8dc2d0c828be76e4c0fbbdf66bae4478a", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["# what is the most common \"type\" of before giving multiple afters? \n", "#after_wards, after_wards_n = zip(*[(y, len(x.split(' '))) for x in tqdm(train_after) for y in x.split(' ')])\n", "#after_wards = [y for i in tqdm(range(len(train_after))) for y in train_after[i].split(' ')]\n", "after_wards = set()\n", "after_wards_n = list()\n", "for i in tqdm(range(len(train_after))):\n", "    spilt = train_after[i].split(' ')\n", "    after_wards_n.append(len(spilt))\n", "    after_wards.update(spilt)\n", "    #for x in spilt:\n", "        #after_wards.append(x)\n", "after_wards = list(after_wards)\n", "print(len(after_wards))\n", "print(after_wards[:10])\n", "#unique_after_wards = list(set(after_wards))\n", "#print(len(unique_after_wards))"], "outputs": []}, {"metadata": {"_cell_guid": "317ec54b-f007-430e-abd7-4de806ca94d8", "_uuid": "9ea1feb3acf9c67b86b60de36749c1bd69c09837", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["print(np.argmax(after_wards_n))\n", "print(max(after_wards_n))\n"], "outputs": []}, {"metadata": {"_cell_guid": "350cd629-5e7d-4835-a55c-d5a65b9cb57e", "_uuid": "1b181e5276fcafa39bdc0ef29d6df8d4c3910277", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["superlong = np.argmax(after_wards_n)\n", "display(train_df.loc[superlong])\n", "print(max(after_wards_n))\n", "print(len(train_df['before'].loc[superlong]))\n", "print(len(train_df['after'].loc[superlong]))\n", "print(train_idx_before_DICK[superlong])\n", "print(train_idx_after_DICK[superlong])"], "outputs": []}, {"metadata": {"_cell_guid": "7516b679-fbd2-427a-a947-06b94bfe56b2", "_uuid": "89ece6cfb0081e0881b9c813d0b5af951dadb4b2", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["#display(train_df.loc[list(range(superlong-10, superlong+10))])\n", "display(train_df.loc[tr_sentID_DICK[670765]])\n", "\n", "' '.join([train_idx_before_DICK[x] for x in tr_sentID_DICK[670765]])"], "outputs": []}, {"metadata": {"_cell_guid": "d489fcfc-19a0-4b00-b2a6-a45884c94ee2", "_uuid": "6cc098831c175e76fe814b73c8a67f17239ed4fb"}, "cell_type": "markdown", "source": ["(13)  **THROW AN ERROR**"]}, {"metadata": {"_cell_guid": "ea5d9053-06f6-45ac-8913-b4b7249b6c19", "_uuid": "f5d6f13db437dd392be01f6ac394518bfdac4334", "collapsed": true}, "cell_type": "code", "execution_count": null, "source": ["THROW AN ERROR"], "outputs": []}], "nbformat": 4, "nbformat_minor": 1}