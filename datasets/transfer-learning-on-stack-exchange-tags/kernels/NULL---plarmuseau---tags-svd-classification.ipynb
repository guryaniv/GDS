{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2a018561-c0aa-7efa-f9f0-95beb50e0d91"
      },
      "source": [
        "Ok , this is IMHO the fasted way to classify all documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "376a3953-871e-3a6e-85d6-fc16e243c4ad"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import itertools \n",
        "import csv\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_context(\"paper\")\n",
        "%matplotlib inline\n",
        "\n",
        "RES_DIR = \"../input/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9453439e-96e4-a5da-b9fc-f9a6af6dd25f"
      },
      "outputs": [],
      "source": [
        "# Load train data (skips the content column)\n",
        "def load_train_data():\n",
        "    categories = ['cooking', 'robotics', 'travel', 'crypto', 'diy', 'biology']\n",
        "    train_data = []\n",
        "    for cat in categories:\n",
        "        data = pd.read_csv(\"{}{}.csv\".format(RES_DIR, cat), usecols=['id', 'title', 'tags'])\n",
        "        data['category'] = cat\n",
        "        train_data.append(data)\n",
        "    \n",
        "    return pd.concat(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "47363d23-3ba7-f7d4-aacb-5dd8bebb6389"
      },
      "outputs": [],
      "source": [
        "train_data = load_train_data()\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "580f9f85-38d9-a29a-07e6-06d92d9bc197"
      },
      "outputs": [],
      "source": [
        "# Distribution of questions by category\n",
        "ax = train_data['category'].value_counts().plot(kind='bar')\n",
        "ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "df1c1d2f-f413-7611-c609-cf86d0da1f96"
      },
      "outputs": [],
      "source": [
        "# Summary about tags\n",
        "tag_lists = [t.strip().split() for t in train_data['tags'].values]\n",
        "tag_lists2 = [t.strip().split() for t in train_data['title'].values]\n",
        "all_tags = list(itertools.chain(*tag_lists,*tag_lists2))\n",
        "tag_list_size = np.array([len(x) for x in tag_lists])\n",
        "print(\"\"\"The corpus is composed by {} questions. Overall {} tags have been used, of which {} unique ones. \n",
        "Average number of tags per question {:.2f} (min={}, max={}, std={:.2f})\"\"\".format(\n",
        "    len(train_data),\n",
        "    len(all_tags), len(set(all_tags)),\n",
        "    tag_list_size.mean(), \n",
        "    min(tag_list_size), max(tag_list_size),\n",
        "    tag_list_size.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86cb0538-77ff-93d0-f7a3-550b4f45282c"
      },
      "outputs": [],
      "source": [
        "# Distribution of number of tags per question\n",
        "sns.distplot(tag_list_size, kde=False)\n",
        "sns.plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "392a42b7-287c-66af-d33d-eb65cb06dfc2"
      },
      "outputs": [],
      "source": [
        "# Utility function to return top occuring tags in the passed df\n",
        "def get_top_tags(df, n=None):\n",
        "    itag_lists = [t.strip().split() for t in df['tags'].values]\n",
        "    itag_lists2 = [t.strip().split() for t in df['title'].values]\n",
        "    tags = list(itertools.chain(*itag_lists,*itag_lists2))\n",
        "    top_tags = collections.Counter(list(tags)).most_common(n)\n",
        "    tags, count = zip(*top_tags)\n",
        "    return tags, count\n",
        "# Utility function to return top occuring tags in the passed df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36f713d3-ef34-58dc-0571-16b056ca2ba6"
      },
      "outputs": [],
      "source": [
        "# Created DataFrame indexed on tags\n",
        "tags_df = pd.DataFrame(index=set(itertools.chain(*tag_lists,*tag_lists2)))\n",
        "# For each category create a column and update the flag to tag count\n",
        "for i, (name, group) in enumerate(train_data.groupby('category')):\n",
        "    tags_df[name] = 0\n",
        "    tmp_index, count = get_top_tags(group)\n",
        "    tmp = pd.Series(count, index=tmp_index)\n",
        "    tags_df[name].update(tmp)\n",
        "# Number of categories for which a tag appeared at least 1 time\n",
        "tags_df['categories_appears'] = tags_df.apply(lambda x: x.astype(bool).sum(), axis=1)\n",
        "tags_df['categories_appears'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a813edd-89df-eb56-1892-c4623b31bbf6"
      },
      "outputs": [],
      "source": [
        "#import the test data\n",
        "test = pd.read_csv(\"../input/test.csv\")\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2fa116b-ba78-3dad-5341-e249bb36c98d"
      },
      "outputs": [],
      "source": [
        "# viewing the table of tags\n",
        "A=tags_df\n",
        "A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d80cbf66-e6ec-be73-45ec-43ab09db6b70"
      },
      "outputs": [],
      "source": [
        "#Solving the question with a Singular Value Decomposition, \n",
        "#this is the core function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "35112bb5-1642-4756-ca22-d6a3f0b9cbef"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import inv\n",
        "U,s,V=np.linalg.svd(A,full_matrices=False)\n",
        "# reconstruct\n",
        "S=np.diag(s)\n",
        "\n",
        "iS=inv(S)\n",
        "US=np.dot(U,iS)\n",
        "US\n",
        "# A fill up with US matrix\n",
        "US_df=pd.DataFrame(data=US, index=tags_df.index, columns=tags_df.columns)\n",
        "# with this simple math i know all the relations between all the tags and the documents\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "62fbc30d-32a1-d406-83df-faf9943747f9"
      },
      "outputs": [],
      "source": [
        "#learn how to use dataframes...  and yes the algorithm knows extreme tourism antarctica has something to do with travel...\n",
        "df1=US_df['extreme-tourism':'extreme-tourism':]\n",
        "df2=US_df['antarctica':'antarctica':]\n",
        "frames = [df1,df2]\n",
        "Qtemp=pd.concat(frames).sum()\n",
        "np.dot(Qtemp,V)/np.dot(np.abs(Qtemp),np.abs(V))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1777e418-e6e9-3aea-07ca-b828e2e3ca23"
      },
      "outputs": [],
      "source": [
        "columns = ['biology','cooking','crypto','diy','robotics','travel']\n",
        "#,'categories_appears']\n",
        "data = {'biology': [0],'cooking': [0],'crypto': [0],'diy': [0],'robotics': [0],'travel': [0],'categories_appears': [0]}\n",
        "newDF = pd.DataFrame(data, columns=columns,index = ['blanco'])\n",
        "#print(newDF)\n",
        "for xya in range(0,8926):\n",
        "    temptxt = test['title'][xya] + test['content'][xya]\n",
        "    tempspl = temptxt.strip().split() \n",
        "    Qtemp=newDF\n",
        "    for sword in tempspl:\n",
        "        if sword in US_df.index:\n",
        "            #print(US_df.loc[sword:sword,:])\n",
        "            Qtemp=Qtemp.append(US_df.loc[sword:sword,:])\n",
        "            #print(Qtemp)\n",
        "    simila=np.dot(Qtemp.sum(),V)/np.dot(np.abs(Qtemp.sum()),np.abs(V))\n",
        "    tempprnt=''\n",
        "    for xyb in range(0,5):\n",
        "        if simila[xyb]>0.89 or simila[xyb]==np.amax(simila[0:5]):\n",
        "            tempprnt+=columns[xyb]+' '\n",
        "    \n",
        "    print(test['id'][xya],',',tempprnt)\n",
        "\n",
        "    \n",
        "    \n",
        " "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}