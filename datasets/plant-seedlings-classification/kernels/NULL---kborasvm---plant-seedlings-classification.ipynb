{"cells":[{"metadata":{"_uuid":"b45dfc4d80db36179dafba17500f02bb86c851d5","_cell_guid":"73d64240-7fe7-4c08-8d85-4693c696f5d1","collapsed":true,"trusted":false},"cell_type":"code","source":"# Referred https://www.pyimagesearch.com/2017/NUM_CLASSES/11/image-classification-with-keras-and-deep-learning/\n# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n# https://machinelearningmastery.com/save-load-keras-deep-learning-models/\nfrom keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport random\nimport os\nimport sys\nimport cv2\nfrom keras.utils import to_categorical\nimport matplotlib\n\n# kaggle/python docker image: https://github.com/kaggle/docker-python\n# Input data files are available in the \"../input/\" directory.\nfrom subprocess import check_output\n#list the files in the input directory\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n#print(check_output([\"pwd\",\"\"]).decode(\"utf8\")) # returns /kaggle/working\n#classes = check_output([\"ls\", \"../input/train\"]).decode(\"utf8\") # returns 12 directories\n#print((classes))\ndef classes_to_int(label):\n    # label = classes.index(dir)\n    label = label.strip()\n    if label == \"Black-grass\":  return 0\n    if label == \"Charlock\":  return 1\n    if label == \"Cleavers\":  return 2\n    if label == \"Common Chickweed\":  return 3\n    if label == \"Common wheat\":  return 4\n    if label == \"Fat Hen\":  return 5\n    if label == \"Loose Silky-bent\": return 6\n    if label == \"Maize\":  return 7\n    if label == \"Scentless Mayweed\": return 8\n    if label == \"Shepherds Purse\": return 9\n    if label == \"Small-flowered Cranesbill\": return 10\n    if label == \"Sugar beet\": return 11\n    print(\"Invalid Label\", label)\n    return 12\n\ndef int_to_classes(i):\n    if i == 0: return \"Black-grass\"\n    elif i == 1: return \"Charlock\"\n    elif i == 2: return \"Cleavers\"\n    elif i == 3: return \"Common Chickweed\"\n    elif i == 4: return \"Common wheat\"\n    elif i == 5: return \"Fat Hen\"\n    elif i == 6: return \"Loose Silky-bent\"\n    elif i == 7: return \"Maize\"\n    elif i == 8: return \"Scentless Mayweed\"\n    elif i == 9: return \"Shepherds Purse\"\n    elif i == 10: return \"Small-flowered Cranesbill\"\n    elif i == 11: return \"Sugar beet\"\n    print(\"Invalid class \", i)\n    return \"Invalid Class\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0619332fc8a1dcb33f6b9640710b4ee216c7de7f","collapsed":true,"_cell_guid":"fe10533e-4f48-48ea-bd01-5f0f151066e0","trusted":false},"cell_type":"code","source":"#The Plant Seedlings Dataset contains images of approximately 960 unique plants belonging to\n# 12 species at several growth stages.\n# It comprises annotated RGB images with a physical resolution of roughly 10 pixels per mm.\nNUM_CLASSES = 12\n# we need images of same size so we convert them into the size\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\ninputShape = (WIDTH, HEIGHT, DEPTH)\n# initialize number of epochs to train for, initial learning rate and batch size\nEPOCHS = 15\nINIT_LR = 1e-3\nBS = 32","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98dcda1a7126da8bde0ae85eb9b9dd69cb1be002","collapsed":true,"_cell_guid":"d7b3c90b-aa73-4ce7-9c61-ab29c6549fc5","trusted":false},"cell_type":"code","source":"def readTrainData(trainDir):\n    data = []\n    labels = []\n    # loop over the input images\n    dirs = os.listdir(trainDir) \n    for dir in dirs:\n        absDirPath = os.path.join(os.path.sep,trainDir, dir)\n        images = os.listdir(absDirPath)\n        for imageFileName in images:\n            # load the image, pre-process it, and store it in the data list\n            imageFullPath = os.path.join(trainDir, dir, imageFileName)\n            #print(imageFullPath)\n            img = load_img(imageFullPath)\n            arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n            arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n            #print(arr.shape) \n            data.append(arr)\n            label = classes_to_int(dir)\n            labels.append(label)\n    return data, labels\n\ndef createModel():\n    model = Sequential()\n    # first set of CONV => RELU => POOL layers\n    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=inputShape))\n    # We then apply a ReLU activation function followed by 2×2 max-pooling in both \n    # the x and y direction with a stride of two. \n    #To visualize this operation, consider a sliding window that “slides” across \n    #the activation volume, taking the max operation over each region, while taking \n    #a step of two pixels in both the horizontal and vertical direction.\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    # second set of CONV => RELU => POOL layers\n    #This time we are learning 50 convolutional filters rather than the 20 convolutional\n    #filters as in the previous layer set. It’s common to see the number of CONV \n    #filters learned increase the deeper we go in the network architecture.\n    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    # first (and only) set of FC => RELU layers\n    # Flattening out the volume into a set of fully-connected layers\n    # Take the output of the preceding MaxPooling2D layer and flatten it into a single vector.\n    # This operation allows us to apply our dense/fully-connected layers.\n    # Fully-connected layer contains 500 nodes which is passed through another \n    # nonlinear ReLU activation.\n    model.add(Flatten())\n    model.add(Dense(500))\n    model.add(Activation(\"relu\"))\n    # softmax classifier\n    # Another fully-connected layer, but this one is special — the number of nodes is equal \n    # to the number of classes  (i.e., the classes we want to recognize).\n    # This Dense layer is then fed into our softmax classifier\n    # which will yield the probability for each class.\n    model.add(Dense(output_dim=12))\n    model.add(Activation(\"softmax\"))\n    # returns our fully constructed deep learning + Keras image classifier \n    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n    # use binary_crossentropy if there are two classes\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43560b3a9d15b1dd2027f02a70fa452da6f55d5c","_cell_guid":"262e6e75-86d0-4120-acdd-2bf7ab9689c0","collapsed":true,"trusted":false},"cell_type":"code","source":"random.seed(10)\nallLabels =  os.listdir(\"../input/train/\")  # list of subdirectories and files\nprint(\"Loading images...\")\nsys.stdout.flush()\nX, Y = readTrainData(\"/kaggle/working/../input/train/\")\n# scale the raw pixel intensities to the range [0, 1]\nX = np.array(X, dtype=\"float\") / 255.0\nY = np.array(Y)\n# convert the labels from integers to vectors\nY =  to_categorical(Y, num_classes=12)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db15e222cdd929fe6013f46ac3021cd67b8aecb9","_cell_guid":"7cda26cf-4e32-4d49-8602-27f260600257","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\"Parttition data into 75:25...\")\nsys.stdout.flush()\n# partition the data into training and testing splits using 75% training and 25% for validation\n(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"412aa9efb3e9fe06937e2888b62c74c630a40ca7","_cell_guid":"d4b7b4c5-2615-40ed-8fe4-7178d5698bb3","collapsed":true,"trusted":false},"cell_type":"code","source":"#construct the image generator for data augmentation\nprint(\"Generating images...\")\nsys.stdout.flush()\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n    horizontal_flip=True, fill_mode=\"nearest\")\n\n# initialize the model\nprint(\"compiling model...\")\nsys.stdout.flush()\nmodel = createModel()\n# train the network\nprint(\"training network...\")\nsys.stdout.flush()\nH = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \\\n    validation_data=(valX, valY), \\\n    steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)\n\n# save the model to disk\nprint(\"Saving model to disk\")\nsys.stdout.flush()\nmodel.save(\"/tmp/mymodel\")\n\n# set the matplotlib backend so figures can be saved in the background\n# plot the training loss and accuracy\nprint(\"Generating plots...\")\nsys.stdout.flush()\nmatplotlib.use(\"Agg\")\nmatplotlib.pyplot.style.use(\"ggplot\")\nmatplotlib.pyplot.figure()\nN = EPOCHS\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\nmatplotlib.pyplot.title(\"Training Loss and Accuracy on  crop classification\")\nmatplotlib.pyplot.xlabel(\"Epoch #\")\nmatplotlib.pyplot.ylabel(\"Loss/Accuracy\")\nmatplotlib.pyplot.legend(loc=\"lower left\")\nmatplotlib.pyplot.savefig(\"plot.png\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98f3d0faeb1fb47a710b35d2bd22f62e420a9912","collapsed":true,"_cell_guid":"9093b44b-2a8a-4202-bc45-adb0e2221f46","trusted":false},"cell_type":"code","source":"def readTestData(testDir):\n    data = []\n    filenames = []\n    # loop over the input images\n    images = os.listdir(testDir)\n    for imageFileName in images:\n        # load the image, pre-process it, and store it in the data list\n        imageFullPath = os.path.join(testDir, imageFileName)\n        #print(imageFullPath)\n        img = load_img(imageFullPath)\n        arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n        arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n        data.append(arr)\n        filenames.append(imageFileName)\n    return data, filenames","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"558f7c5411d6c9375f0380391f91ac929b930a9d","_cell_guid":"7e59efe7-4446-45fa-817b-5af82bc72de9","collapsed":true,"trusted":false},"cell_type":"code","source":"# read test data and find its classification\ntestX, filenames = readTestData(\"/kaggle/working/../input/test/\")\n# scale the raw pixel intensities to the range [0, 1]\ntestX = np.array(testX, dtype=\"float\") / 255.0\n\nfrom keras.models import load_model\nmymodel = load_model('/tmp/mymodel')\nyFit = mymodel.predict(testX, batch_size=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cfc9346e868b7c6eb7b69f800d8e0f109913d1b","_cell_guid":"967a11cb-09dd-4de6-9b14-6f565eb0e29b","collapsed":true,"trusted":false},"cell_type":"code","source":"#print(type(yFit)) # numpy.ndarray\n#print(type(filenames)) # list\n\nimport csv  \nwith open('output.csv', 'w', newline='') as csvfile:\n    fieldnames = ['file', 'species']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for index, file in enumerate(filenames):\n        classesProbs = yFit[index]\n        maxIdx = 0\n        maxProb = 0;\n        for idx in range(0,11):\n            if(classesProbs[idx] > maxProb):\n                maxIdx = idx\n                maxProb = classesProbs[idx]\n        writer.writerow({'file': file, 'species': int_to_classes(maxIdx)})\nprint(\"Writing complete\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","name":"python","nbconvert_exporter":"python"}},"nbformat":4,"nbformat_minor":1}