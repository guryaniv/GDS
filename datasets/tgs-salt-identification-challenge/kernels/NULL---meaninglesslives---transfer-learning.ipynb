{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bf46f72bcff130447533583f71bbb4259d26ed20"},"cell_type":"markdown","source":"This is a follow up of my [previous kernel](https://www.kaggle.com/meaninglesslives/simple-classifier-train/notebook) which tried to predict whether an image contains salt or not. In this kernel, I use Transfer learning (Xception Model) to improve the classifier validation accuracy to around 87%. Happy Kaggling :-)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import plot_model\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras import models\nfrom keras import layers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Reshape, concatenate, Conv2D, Flatten, MaxPooling2D\nfrom keras.layers import BatchNormalization, Dropout, GlobalMaxPooling2D\nfrom keras import optimizers\n\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"135a2e8e9a02e9bb4428f57501e4f7fbacc57ca2","_kg_hide-input":true},"cell_type":"code","source":"# Set some parameters\nim_width = 128\nim_height = 128\nborder = 5\nim_chan = 3 # Number of channels: first is original and second cumsum(axis=0)\nn_features = 1 # Number of extra features, like depth\npath_train = '../input/train/'\npath_test = '../input/test/'\ndf_depths = pd.read_csv('../input/depths.csv', index_col='id')\ntrain_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7a31dd51240379cf03bab39cbce1942a0123a2a","_kg_hide-input":true},"cell_type":"code","source":"# https://www.kaggle.com/bguberfain/unet-with-depth\n# Get and resize train images and masks\nX = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\ny = np.zeros((len(train_ids), ), dtype=np.float32)\nX_feat = np.zeros((len(train_ids), n_features), dtype=np.float32)\nprint('resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    \n    # Depth\n    X_feat[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    # Load X\n    img = load_img(path + '/images/' + id_, grayscale=True)    \n    x_img = img_to_array(img)\n\n    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)    \n\n\n    # Load Y\n    mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n    mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\n    # Save images\n    X[n, ..., 0] = x_img.squeeze() / 255\n    X[n, ..., 1] = x_img.squeeze() / 255\n    X[n, ..., 2] = x_img.squeeze() / 255\n\n    y[n] = 1 if np.sum(mask[:])>0 else 0\n#     y[n] = mask / 255\n\nprint('Pecentage of images with no salt in train set:', (np.sum(y)/y.shape[0])*100)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"4e2c2dbe0866d70940d75c15000511e28c940f2c","collapsed":true},"cell_type":"code","source":"i = 0\nj = 0\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\n# Visualizing the predicted outputs\nwhile True:\n    if y[i]==0:        \n        no_salt = X[i,:,:,:]\n        plt.subplot(1,6,j+1)\n        plt.imshow(no_salt)\n        plt.title('ID: '+ train_ids[i][:-4])\n        j = j + 1\n        if j>5:\n            break\n    i = i + 1\n\nplt.suptitle('Train set Images that have no salt', y=0.7, fontsize=30)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"53565d2a7263aa14237b75df9d687def02574917","collapsed":true},"cell_type":"code","source":"i = 0\nj = 0\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\n# Visualizing the predicted outputs\nwhile True:\n    if y[i]==1:        \n        with_salt = X[i,:,:,:]\n        plt.subplot(1,6,j+1)\n        plt.imshow(with_salt)\n        plt.title('ID: '+ train_ids[i][:-4])\n        j = j + 1\n        if j>5:\n            break\n    i = i + 1\n\nplt.suptitle('Train set Images that have salt', y=0.7, fontsize=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"756cbe7e5471c8cc84044d3ef9a424294f7b2ff7","collapsed":true},"cell_type":"code","source":"# uncomment to use the other models..\n# from keras.applications import VGG16\nfrom keras.applications import Xception\n# from keras.applications import MobileNet\n# from keras.applications import VGG19\n# conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(128, 128, 3))\nconv_base = Xception(weights='imagenet',include_top=False,input_shape=(128, 128, 3))\n# conv_base = MobileNet(weights='imagenet',include_top=False,input_shape=(128, 128, 3))\n# conv_base = VGG19(weights='imagenet',include_top=False,input_shape=(128, 128, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e7e037e41dd8ac261ac8bbba80314d6b5e9b9bce","_kg_hide-input":true},"cell_type":"code","source":"# Split train and valid\nX_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.15, random_state=42)\ncallbacks = [\n    EarlyStopping(patience=5, verbose=1),\n    ReduceLROnPlateau(patience=3, verbose=1),\n    ModelCheckpoint('model-tgs-salt-classifier.h5', verbose=1, save_best_only=True, save_weights_only=True)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49288b3b31e8ca514cc6e32455c0423537aa21e9","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"train_features = conv_base.predict(X_train)\nfeat_shape = np.array(train_features.shape)\nvalidation_features = conv_base.predict(X_valid)\n\ntrain_features = np.reshape(train_features, ( feat_shape[0],\n                                             feat_shape[1]* feat_shape[2]*feat_shape[3] ))\nvalidation_features = np.reshape(validation_features, (validation_features.shape[0],\n                                                       feat_shape[1]* feat_shape[2]* feat_shape[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"82d1eeefbbaf05732320bb0d24d4c61189610cb2","_kg_hide-output":false,"collapsed":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_dim=feat_shape[1]* feat_shape[2]*feat_shape[3]))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=optimizers.RMSprop(lr=2e-5),loss='binary_crossentropy',\n              metrics=['acc'])\nhistory = model.fit(train_features, y_train,epochs=30,batch_size=20,\n                    validation_data=(validation_features, y_valid),callbacks=callbacks)\n\n# model.fit_generator(gen_flow, validation_data=([X_valid, X_feat_valid], y_valid),\n#                     steps_per_epoch=len(X_train) / batch_size, epochs=30,callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50dfb96741a3006f6f06fa0ec7c1b02281a38c7d","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c9c6d0aaf95a70b180ea43b5d4007a1f902affc0","collapsed":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb3ea7789a3f4372fc96ce2844449b06fa566081","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.float32)\nX_feat_test = np.zeros((len(test_ids), n_features), dtype=np.float32)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    \n    # Load X\n    img = load_img(path + '/images/' + id_, grayscale=True)\n    x = img_to_array(img)\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n\n\n    # Save images\n    X_test[n, ..., 0] = x.squeeze() / 255\n    X_test[n, ..., 1] = x.squeeze() / 255\n    X_test[n, ..., 2] = x.squeeze() / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88a97ad775429e29c466f80baa5d9c10b63128f5","collapsed":true},"cell_type":"code","source":"# Predict on test data\ntest_features = conv_base.predict(X_test)\nfeat_shape = np.array(test_features.shape)\ntest_features = np.reshape(test_features, ( feat_shape[0],\n                                             feat_shape[1]* feat_shape[2]*feat_shape[3] ))\ntest_predictions = model.predict(test_features)\ntest_predictions = np.round(test_predictions)\n# 0.38 is fake, so predictions seem to be good..\nprint('Seems like',(sum(test_predictions)/test_predictions.shape[0])*100,'% images of test set have no salt..')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3655b9544004a1ae04c0ca97d41c7e69882be945","collapsed":true},"cell_type":"code","source":"i = 0\nj = 0\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\n# Visualizing the predicted outputs\nwhile True:\n    if test_predictions[i]==1:        \n        with_salt = X_test[i,:,:,:]\n        plt.subplot(1,6,j+1)\n        plt.imshow(with_salt)\n        plt.title('ID: '+ test_ids[i][:-4])\n        j = j + 1\n        if j>5:\n            break\n    i = i + 1\n\nplt.suptitle('Predicted Test set Images that may have salt', y=0.7, fontsize=30)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"90c36d2a8624b02600944ddfcc7c2056661f6490","collapsed":true},"cell_type":"code","source":"i = 0\nj = 0\nplt.figure(figsize=(30,15))\nplt.subplots_adjust(bottom=0.2, top=0.8, hspace=0.2)  #adjust this to change vertical and horiz. spacings..\n# Visualizing the predicted outputs\nwhile True:\n    if test_predictions[i]==0:        \n        no_salt = X_test[i,:,:,:]\n        plt.subplot(1,6,j+1)\n        plt.imshow(no_salt)\n        plt.title('ID: '+ test_ids[i][:-4])\n        j = j + 1\n        if j>5:\n            break\n    i = i + 1\n\nplt.suptitle('Predicted Test set Images that may not have salt', y=0.7, fontsize=30)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}