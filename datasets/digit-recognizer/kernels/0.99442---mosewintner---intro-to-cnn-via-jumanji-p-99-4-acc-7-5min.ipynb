{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["#### First attempt at building a CNN using MNIST digit recognition data\n", "\n", "Very grateful to other Kagglers, especially [Yassine Ghouzam](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6) for posting their kernels that taught me some super neat tricks!\n", "\n", "1. Explanation: Jumanji\n", "2. Preprocessing\n", "  - Load libraries\n", "  - Load and check data\n", "  - Reshape data into 2D images\n", "  - Normalize data\n", "  - Generate augmented images\n", "  - One-hot label encoding\n", "  - Training/validation split\n", "3. Tonight on CNN\n", "  - Define and compile model\n", "  - Define learning rate callback\n", "4. Evaluate CNN model\n", "  - Confusion matrix\n", "5. Submit predictions"], "metadata": {"_cell_guid": "4ec043a8-3755-440b-9ab8-19a2da77e360", "_uuid": "7d5f074373b7314b8edf9a3ad007d2c8bdc220eb"}}, {"cell_type": "markdown", "source": ["## 1. Jumanji\n", "\n", "You've probably seen the movie Jumanji, or at least heard of it. I just learned there's a remake in theaters right now!!\n", "\n", "<img src = \"http://cloud-3.steamusercontent.com/ugc/91602828075643624/F16C1BD022982E1C587B0DBEF8B85D897C7B0DC9/\">\n", "\n", "But did you play the board game released shortly thereafter? Each turn, players draw cards, but they're essentially unreadable. Here's an example.\n", "\n", "<img src=\"https://cf.geekdo-images.com/images/pic340327_md.jpg\", alt=\"Jumanji Card\", style=\"width: 250px;\">\n", "\n", "To read each card, one has to put it under a red piece of cellophane, after which one can clearly read the hidden blue text.\n", "\n", "I'm going to try to use this idea to explain convolution neural networks, so bear with me! The situations are similar: we have some information embedded in a 2D image and we need to filter some parts of the image out to get to the information.\n", "\n", "Imagine the Jumanji cards are more sophisticated: instead of solid red noise over the card, there are several overlapping gradients which obscure the text, and let's assume the situation is further complicated by the fact that we are colorblind and don't know what colors we'll need our filters to be! So we have several cards (digit images, in the case of MNIST), and there's some information we want to extract from each card, but we don't know what our filters should be in order to best decipher the information. If we can find the right filter(s), then they should work well for all the cards!\n", "\n", "This is like our situation: to train a CNN, instead of sticking each entire image under one big filter, one looks for several *local* filters, since often clues about the information are local in the image. As another example, if we're trying to classify photos of cats and dogs, we'd like different properties of the fur, eye shape, etc., a chance at being their own features capable of predictive power.\n", "\n", "It seems natural therefore to pick up clues by looking at different small areas of the card under different filters. This is what the first layer of a CNN does! It trains, via backpropagation, several local filters to decipher local information, i.e. local *features*. The collection of local filters makes up the first layer of our CNN, the convolution layer.\n", "\n", "After passing the image through this layer, we pass it through an activation layer (we'll use a ReLU activation, that is, the function $x\\to max(x,0)$) and a MaxPooling layer. The activation layer throws out sections of the filtered image which (at the current training stage) don't have good predictive power. The maxpool layer then picks out the strongest among neighboring local features; in our case, it simply picks out the greatest number in each 2x2 patch of features, therefore shrinking the 28x28 image to a 14x14 array of features\n", "\n", "Sometimes, if there is fear of overfitting the neural network to some training data, there is also included a Dropout layer, which randomly drops a portion of the data, i.e. zeros the outputs of several nodes. For some reason I can't get this to work for me in Keras.\n", "\n", "These groups of layers (Conv-Activation-MaxPooling-Dropout) are stacked, gradually merging local features into global features, until the image has been boiled down to a relatively small array of aspiring predictors.\n", "\n", "Then, having distilled the image into features, we unravel the 2D array into a 1D array, and pass everything through a fully connected (Dense) layer so that arbitrary linear combinations of these features may have the chance to be good predictors. Without the fully connected layer, disparate sections of each image have only weak means of informing one another about the content of the overall image, that is, only at the final maxpooling stage when they are compared as neighbors.\n", "\n", "And that's a crash course in convolutional neural networks, as I understand them! Please leave a comment if my intuition is wrong or incomplete, or if I've left out anything cool!"], "metadata": {"_cell_guid": "60eb3e38-4732-4e54-b6fc-77de42661d67", "_uuid": "a66f8c9ce0e9208077c7e61963dcdfd7ed7ca70e"}}, {"cell_type": "markdown", "source": ["### 2. Preprocessing"], "metadata": {"_cell_guid": "f1a4849a-9c6e-4878-9c17-be07f742e761", "_uuid": "1e974574cef4b3c62407680aecf1f6502e4ad718"}}, {"cell_type": "markdown", "source": ["##### Load libraries and set constants"], "metadata": {"_cell_guid": "40a98025-24df-4d5f-88ed-0e3646d0ae5d", "_uuid": "3d8a098aa5911def3f9daf92cf7587eb74f2b908"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "a2227901-ce93-42b3-ac0f-e40cd9252dc3", "_uuid": "baa299da2e0f97e202f941d146443ff8a406922d"}, "source": ["import os\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import confusion_matrix\n", "import itertools\n", "\n", "from keras.utils.np_utils import to_categorical\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n", "from keras.optimizers import Adam\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.callbacks import ReduceLROnPlateau\n", "\n", "sns.set(style='white')\n", "\n", "SEED = 323\n", "VAL_FRAC = 0.1\n", "EPOCHS = 20\n", "BATCH_SIZE = 128"]}, {"cell_type": "markdown", "source": ["##### Load data"], "metadata": {"_cell_guid": "fc15516f-9c39-4157-98ea-878591438742", "_uuid": "accd1c6fa7106f565370af1d2fc6a1282ba44caf"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "dc82b950-32e8-4468-b304-e534acc5ec8f", "_uuid": "8880e0705e50a73518ad3e5fff631f57523e6351"}, "source": ["if os.path.isfile('../input/train.csv') and os.path.isfile('../input/test.csv'):\n", "    train = pd.read_csv('../input/train.csv')\n", "    test = pd.read_csv('../input/test.csv')\n", "    print('train.csv loaded: train({0[0]},{0[1]})'.format(train.shape))\n", "    print('test.csv loaded: test({0[0]},{0[1]})'.format(test.shape))\n", "else:\n", "    print('Error: train.csv or test.csv not found in /input')\n", "    \n", "print('')\n", "print(train.info())\n", "print('')\n", "print(train.isnull().any().describe())\n", "print('')\n", "print(train['label'].value_counts())"]}, {"cell_type": "markdown", "source": ["Looks like the first column in our data contains the labels, i.e. the correct digits for each image. Let's split that column off and store it."], "metadata": {"_cell_guid": "e916c903-184f-4966-96ca-fb31f39f76ea", "_uuid": "31bbae562ecab1192cebf2d4b240f13ef2d51783"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "dd07cff0-320d-4440-88f9-01e609f7b98d", "_uuid": "187de1d6149bf1989fbf79e6014194761c5d4c09"}, "source": ["y_train = train['label']\n", "X_train = train.iloc[:,1:]\n", "\n", "print(y_train.shape, X_train.shape)\n", "del train"]}, {"cell_type": "markdown", "source": ["##### Reshape samples into 2D images"], "metadata": {"_cell_guid": "445d80d3-d702-45aa-8f71-069a4803e1c3", "_uuid": "f823e28985760bdfd9e583a8edab59247aeb734f"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "dff03dd0-d440-441f-aece-51c541ba6004", "_uuid": "f9948714c886fa179b3291a25558b852f32a221e"}, "source": ["X_train = X_train.values.reshape(-1,28,28,1)\n", "X_test = test.values.reshape(-1,28,28,1)\n", "\n", "print(X_train.shape, X_test.shape)"]}, {"cell_type": "markdown", "source": ["##### Normalize"], "metadata": {"_cell_guid": "2a0b95e9-40a8-4dce-8bbf-ac88d7bdb1cc", "_uuid": "4230fd933b6ad34865e77d7a1ff2cd4c48488b34"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "a74759fb-53f4-4da1-8d73-0d403ed2d894", "_uuid": "85008193068ec0ded98313f3170ee05f182851bc"}, "source": ["X_train = X_train.astype(np.float) # convert from int64 to float32\n", "X_test = X_test.astype(np.float)\n", "X_train = np.multiply(X_train, 1.0 / 255.0)\n", "X_test = np.multiply(X_test, 1.0 / 255.0)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "15ab1f81-6a4d-4170-84a6-4be4a2dcf34f", "_uuid": "2872e7b9b258354bf4f3418494c768162220446a"}, "source": ["#CHECK: plot some images\n", "plt.figure(figsize=(18,2))\n", "for i in range(12):\n", "    plt.subplot(2,12,1+i)\n", "    plt.xticks(())\n", "    plt.yticks(())\n", "    plt.imshow(X_train[i].reshape(28,28),cmap=matplotlib.cm.binary)"]}, {"cell_type": "markdown", "source": ["Interesting! I'm intrigued by the 1s in the first and third images. Seems to suggest we might make our algorithm more robust by generating new images from these via some subtle transformations. Keras has a method for this."], "metadata": {"_cell_guid": "4bf26233-fac8-42b7-b4d7-3d10b5917afa", "_uuid": "c1f438117d1b492b1a9ff20488987705f08c0cd7"}}, {"cell_type": "markdown", "source": ["##### Generate augmented images"], "metadata": {"_cell_guid": "76cd247d-e004-424c-873a-893004b71dcf", "_uuid": "2e2cc672a3e84e5bcb0f2d81f48c9313d4a71dd1"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "89910176-6845-4949-b811-c0e4cfd8a464", "_uuid": "3f9bb42962c29418fabe6a80c0c7f12f1b87beec"}, "source": ["idg = ImageDataGenerator(rotation_range=8.,\n", "    width_shift_range=0.1,\n", "    height_shift_range=0.1,\n", "    shear_range=np.pi/30., # 6 degrees\n", "    zoom_range=0.1)\n", "\n", "idg.fit(X_train)"]}, {"cell_type": "markdown", "source": ["##### One-hot encoding"], "metadata": {"_cell_guid": "7458fe3d-c4c2-42c6-aa1a-ec559d7bab0a", "_uuid": "475e7f2d53171d38261c3b18afd5f333361c04af"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "1d8c883e-c244-4336-b7c7-19cfa39f2fcf", "_uuid": "296826154c41c08501bb63a839d6987ab9f152f9"}, "source": ["y_train = to_categorical(y_train, num_classes = 10)"]}, {"cell_type": "markdown", "source": ["##### Training/validation split"], "metadata": {"_cell_guid": "3aa61aad-b2c6-4b0b-b794-ddef5788f781", "_uuid": "da3a35c829c067c6522561c679283ec23afd6c49"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "494f3473-38ba-4583-b5a8-077d0798cfda", "_uuid": "ad180cbb48786305aa962d52af0efb7a708125fe"}, "source": ["X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size = VAL_FRAC)"]}, {"cell_type": "markdown", "source": ["## 3. Tonight on CNN"], "metadata": {"_cell_guid": "9f1a437d-e4bc-464e-afc4-7b96172955ed", "_uuid": "5729b4f7881fde7a92c201e7dcd4a57772cfbf5f"}}, {"cell_type": "markdown", "source": ["Here's our model.\n", "\n", "Input ->\n", "\n", "Conv2D -> ReLU -> Conv2D -> ReLU -> MaxPooling2D ->\n", "\n", "Conv2D -> ReLU -> MaxPooling2D ->\n", "\n", "Flatten -> Dense -> Relu -> BatchNormalization -> Dense -> Relu -> Dense -> Softmax -> Output\n", "\n", "\n", "For some reason, I couldn't get the Dropout layer to work for me in Keras (I'll be making another attempt soon now that I've uploaded this kernel to Kaggle!) so I had to pare down the complexity of my model so I didn't need to regularize it quite so much. Regularization is an umbrella term for any of a variety of techniques used when problems are ill-posed or models are prone to overfitting. In the case of neural networks, typically there are far more weights being trained than might be necessary to capture the relevant features, so the model fits to noise. Adding regularization keeps the model simpler and less prone to overfitting."], "metadata": {"_cell_guid": "da072fbd-eecd-40b9-bd76-521ee0374244", "_uuid": "bf4c68e9ec50f1b365d21bfab9c94951ea4ca66a"}}, {"cell_type": "markdown", "source": ["##### Define and compile model"], "metadata": {"_cell_guid": "31f88e6f-31ee-4f35-bcee-8d921882dd5b", "_uuid": "3fef50b1fdcfe18f3ffb60ec97dff8dcb37be940"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "f9992571-c8c7-4931-beea-00b2ea816b51", "_uuid": "1c3290cc72ff4f10091aac2a369cbe1e5ca154bc"}, "source": ["model = Sequential()\n", "\n", "model.add(Conv2D(16,(6,6), input_shape = (28,28,1), activation = \"relu\"))\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "model.add(Conv2D(32,(4,4), activation = 'relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "model.add(Conv2D(32,(3,3), activation = 'relu'))\n", "\n", "model.add(Flatten())\n", "model.add(Dense(128,activation='relu'))\n", "model.add(BatchNormalization())\n", "model.add(Dense(32,activation='relu'))\n", "model.add(Dense(10,activation='softmax'))"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "fae78480-a7fa-463e-88fc-876bf54cdf03", "_uuid": "590972e5a3f72a6d1c8244c0df8f7ccf68bd94e9"}, "source": ["model.compile(loss='categorical_crossentropy',\n", "             optimizer = Adam(),\n", "             metrics = ['accuracy'])"]}, {"cell_type": "markdown", "source": ["##### Define learning rate callback"], "metadata": {"_cell_guid": "91035702-1372-42fa-8ec3-705816c7850d", "_uuid": "38bca4464d1bd20c420c1dfba76144cca6c87e36"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "9a609467-995d-493b-81da-c40c0ce020a7", "_uuid": "fc13a694693871e8964e4da60a96de6f24dd914c"}, "source": ["lr = ReduceLROnPlateau(monitor='val_loss',\n", "                       factor=0.5,\n", "                       patience=2,\n", "                       verbose=1,\n", "                       epsilon=0.0001,\n", "                       min_lr=1e-6)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "d3e968ea-fcb8-4c72-b5b9-6bbaca07eb1a", "_uuid": "7bce2966765c2b1be602f38b428322b13234b42e"}, "source": ["fit = model.fit_generator(idg.flow(X_train,y_train,\n", "                          batch_size=BATCH_SIZE),\n", "                          epochs=EPOCHS,\n", "                          validation_data=(X_val,y_val),\n", "                          verbose=2,\n", "                          steps_per_epoch=X_train.shape[0] // BATCH_SIZE,\n", "                          callbacks = [lr])"]}, {"cell_type": "markdown", "source": ["## 4. Evaluate CNN Model"], "metadata": {"_cell_guid": "8c8c946b-13e9-48c7-b36f-445658cfc043", "_uuid": "e1019d6f22e0dc4854de23dab793d55797d1316b"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "8cca9bcd-636f-4111-adf5-4559ab49d425", "_uuid": "d8047c1b0946b9372c5d594ac944547d16d93e7f"}, "source": ["y_pred = model.predict(X_val)\n", "# Convert predictions to one-hot vectors \n", "y_pred_classes = np.argmax(y_pred,axis = 1) \n", "# Convert validation set labels to one-hot vectors\n", "y_true = np.argmax(y_val,axis = 1) \n", "# compute the confusion matrix\n", "conf = confusion_matrix(y_true, y_pred_classes)\n", "\n", "plt.figure(figsize=(10,8))\n", "sns.heatmap(pd.DataFrame(conf,range(10),range(10)), annot=True)"]}, {"cell_type": "markdown", "source": ["## 5. Submit predictions"], "metadata": {"_cell_guid": "1bfff120-68da-4cb6-aa0b-d90c92070d55", "_uuid": "d7ffa8317be4638be1e0437489c21fc4bdcda452"}}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "3826f2bd-4cdb-4f45-a736-399a8ccc93ac", "_uuid": "5ead5b716d89b236b4cd5459a3813d155e9e4cf8"}, "source": ["predictions = model.predict_classes(X_test, verbose=0)\n", "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n", "                         \"Label\": predictions})\n", "submissions.to_csv(\"submission.csv\", index=False, header=True)"]}, {"cell_type": "markdown", "source": [], "metadata": {"_cell_guid": "4a512a72-fb08-4b2f-8523-9f9dc55ca635", "_uuid": "58e5420172a0710a72ad4562e136b423c2a968df"}}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4", "nbconvert_exporter": "python"}}}