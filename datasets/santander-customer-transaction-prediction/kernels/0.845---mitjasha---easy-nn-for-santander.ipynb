{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"ver = 'nn_bl_16'\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nplt.style.use(['seaborn-darkgrid'])\nplt.rcParams['font.family'] = 'DejaVu Sans'\nimport time\nfrom datetime import datetime\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, BatchNormalization\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\n\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n% matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load datasets**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntarget = pd.read_csv('../input/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['target'].value_counts().sort_index(ascending=False).plot(kind='barh', \n                                                                          figsize=(15,6))\nplt.title('Target', fontsize=18);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data preparation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.iloc[:,2:].values\ny = train.iloc[:,1].values\ntest = test.iloc[:,1:].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc0 = StandardScaler()\nsc1 = RobustScaler()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train0 = sc0.fit_transform(X)\nX_test0 = sc0.transform(test)\nX_train1 = sc1.fit_transform(X)\nX_test1 = sc1.transform(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize = (24, 12))\npca = PCA()\nX_reduced0 = pca.fit_transform(X_train0)\nX_reduced1 = pca.fit_transform(X_train1)\n\n\nax[0].scatter(X_reduced0[:, 0], X_reduced0[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[0].set_title('PCA projection StdScalar')\n\nax[1].scatter(X_reduced1[:, 0], X_reduced1[:, 1], c=y,\n            edgecolor='none', alpha=0.7, s=40,\n            cmap=plt.cm.get_cmap('bwr', 2))\nax[1].set_title('PCA projection Robust')\n\nprint(pca.n_components_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def modelir():\n    model = Sequential()\n\n    #input \n    model.add(Dense(1000, input_dim=200, kernel_initializer = 'uniform'))\n    model.add(Activation(\"relu\"))\n    #model.add(Dropout(0.8))\n\n    #2 \n    model.add(Dense(100, kernel_initializer = 'uniform'))\n    model.add(Activation(\"relu\"))\n\n    model.add(Dense(100, kernel_initializer = 'uniform'))\n    model.add(Activation('relu'))\n\n    #output\n    model.add(Dense(1, activation = 'sigmoid'))\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    return model\n#print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_blend1(X, y, test):\n    model = modelir()\n    pred = pd.DataFrame()\n    for i in range(1, 10):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr1 = simple_blend1(X, y, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr1['mean'] = pr1.mean(axis=1)\npr1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_blend2(X, y, test):\n    pred = pd.DataFrame()\n    for i in range(1, 10):\n        model = modelir()\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = i)\n        earlystopper = EarlyStopping(patience=5, verbose=1)\n        history = model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.2, verbose=2, callbacks=[earlystopper], shuffle=True)\n        scores = model.evaluate(X_test, y_test, verbose=0)\n        print(\"accuracy for test data: %.2f%%\" % (scores[1]*100))\n        plt.plot(history.history['acc'], label='accuracy for train data')\n        plt.plot(history.history['val_acc'], label='validation data accuracy')\n        plt.xlabel('epochs')\n        plt.ylabel('accuracy')\n        plt.legend()\n        plt.show()\n        y_pred = model.predict(X_test)\n        y_pred = (y_pred > 0.7)\n        cm = confusion_matrix(y_test, y_pred)\n        print(cm)\n        y_pred_t = model.predict(test)\n        print(y_pred_t.T[0])\n        pred[i] = y_pred_t.T[0]\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr2 = simple_blend2(X, y, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pr2['mean'] = pr2.mean(axis=1)\npr2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'subm_{}_{}_'.format(ver, datetime.now().strftime('%Y-%m-%d'))\ntarget['target'] = pr1['mean']\ntarget.to_csv(filename+'1'+'.csv', index=False)\ntarget['target'] = pr2['mean']\ntarget.to_csv(filename+'2'+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target['target'] = (pr1['mean']+pr2['mean'])/2\ntarget.to_csv(filename+'3'+'.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}