{"nbformat_minor": 1, "nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.1", "name": "python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"source": ["# Introduction\n", "\n", "Thanks to [Peter Giannakopoulos](https://www.kaggle.com/petrosgk) and [Heng CherKeng](https://www.kaggle.com/hengck23) for their starter kits. I collected their data augmentation methods and added a few based on the keras.preprocessing.image.\n", "\n", "Let me know if they help your learning process."], "metadata": {"_uuid": "fc03a03a42997b7135157e6e890876e496d23b80", "_cell_guid": "56e3bfd5-a558-47a7-873e-a77063ae43b1"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "# import tensorflow as tf\n", "from keras.preprocessing import image\n", "from os.path import join\n", "import matplotlib.pyplot as plt\n", "\n", "input_size = 512\n", "data_dir = '../input'\n", "np.random.seed(1987)"], "metadata": {"_uuid": "fd135e9e0c8015607b593085287c7ff45a4e7a4d", "_cell_guid": "2a15e785-eda5-450c-a9be-2dae8c88718e"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["df_train = pd.read_csv(join(data_dir, 'train_masks.csv'), usecols=['img'])\n", "df_train['img_id'] = df_train['img'].map(lambda s: s.split('.')[0])\n", "df_train.head(3)"], "metadata": {"_uuid": "2b3d55d91db49d725a9cbe1727ec003c7e7d7274", "_cell_guid": "29e0ce7d-b16c-457c-86c1-e2b675d9ca99"}, "cell_type": "code"}, {"source": ["## Read and show images and masks"], "metadata": {"_uuid": "81de3490786dbb415231a34f1680d1caf08e0ee8", "_cell_guid": "ce4cd0fc-af19-4984-a98b-523b96ad3ccb"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def get_image_and_mask(img_id):\n", "    img = image.load_img(join(data_dir, 'train', '%s.jpg' % img_id),\n", "                         target_size=(input_size, input_size))\n", "    img = image.img_to_array(img)\n", "    mask = image.load_img(join(data_dir, 'train_masks', '%s_mask.gif' % img_id),\n", "                          grayscale=True, target_size=(input_size, input_size))\n", "    mask = image.img_to_array(mask)\n", "    img, mask = img / 255., mask / 255.\n", "    return img, mask\n", "\n", "def plot_img_and_mask(img, mask):\n", "    fig, axs = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n", "    axs[0].imshow(img)\n", "    axs[1].imshow(mask[:, :, 0])\n", "    for ax in axs:\n", "        ax.set_xlim(0, input_size)\n", "        ax.axis('off')\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"collapsed": true, "_uuid": "3377145adb9f72b81704b5f4e68b098c03b10d77", "_cell_guid": "3b4a3fa5-6c1e-4e4b-b8f7-5cae5083eb2f"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_ids = df_train['img_id'].values\n", "np.random.shuffle(img_ids)\n", "img_id = img_ids[0]\n", "img, mask = get_image_and_mask(img_id)\n", "print((img.shape, mask.shape))\n", "plot_img_and_mask(img, mask)"], "metadata": {"_uuid": "648f701db711ddab189ed20b2a6cd02b3681efe4", "_cell_guid": "d40ef976-70df-4a34-aee2-884c8806db53"}, "cell_type": "code"}, {"source": ["# Pixel Transformations"], "metadata": {"_uuid": "8e80b894e78b68ec68f52ca1581226ba0b86de0a", "_cell_guid": "1d12b385-3463-410f-82ac-38ca2813fb00"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def plot_img_and_mask_transformed(img, mask, img_tr, mask_tr):\n", "    fig, axs = plt.subplots(ncols=4, figsize=(16, 4), sharex=True, sharey=True)\n", "    axs[0].imshow(img)\n", "    axs[1].imshow(mask[:, :, 0])\n", "    axs[2].imshow(img_tr)\n", "    axs[3].imshow(mask_tr[:, :, 0])\n", "    for ax in axs:\n", "        ax.set_xlim(0, input_size)\n", "        ax.axis('off')\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"collapsed": true, "_uuid": "75e7895a15a0382179d9468e5129dce30947fc81", "_cell_guid": "42c5e20c-60bf-4acc-8878-4d526ad830a3"}, "cell_type": "code"}, {"source": ["## Flip"], "metadata": {"_uuid": "35c0e9df60e9028f362690cae7da055642ea9937", "_cell_guid": "8e05eb62-d89d-4c1c-a418-0522cd6df06d"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_flip(img, mask, u=0.5):\n", "    if np.random.random() < u:\n", "        img = image.flip_axis(img, 1)\n", "        mask = image.flip_axis(mask, 1)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "382a7b3a0d239e567264d6977eabbe8cd0ac32be", "_cell_guid": "70041f8e-b107-4db4-bc67-c331cd7e8821"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_flip, mask_flip = random_flip(img, mask, u=1)\n", "plot_img_and_mask_transformed(img, mask, img_flip, mask_flip)"], "metadata": {"_uuid": "539ffd481965ff385ae3ec150d9572267194b8f0", "_cell_guid": "424e8148-9b32-4dd1-b503-2a3a5e48576f"}, "cell_type": "code"}, {"source": ["## Rotate"], "metadata": {"_uuid": "d0327af6e29951f3f75f0d466b518afb9ed6a5f9", "_cell_guid": "01797b89-cdb6-4e55-bc63-fdcdcb80a344"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def rotate(x, theta, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n", "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0],\n", "                                [np.sin(theta), np.cos(theta), 0],\n", "                                [0, 0, 1]])\n", "    h, w = x.shape[row_axis], x.shape[col_axis]\n", "    transform_matrix = image.transform_matrix_offset_center(rotation_matrix, h, w)\n", "    x = image.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n", "    return x\n", "\n", "def random_rotate(img, mask, rotate_limit=(-20, 20), u=0.5):\n", "    if np.random.random() < u:\n", "        theta = np.pi / 180 * np.random.uniform(rotate_limit[0], rotate_limit[1])\n", "        img = rotate(img, theta)\n", "        mask = rotate(mask, theta)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "2320332a08ceb994ce91d04511eb795b994c505d", "_cell_guid": "df9bde0d-986a-43ac-bc09-afa469bc7ea2"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["rotate_limit=(-30, 30)\n", "theta = np.pi / 180 * np.random.uniform(rotate_limit[0], rotate_limit[1])\n", "print('theta %.2f' % theta)\n", "img_rot = rotate(img, theta)\n", "mask_rot = rotate(mask, theta)\n", "plot_img_and_mask_transformed(img, mask, img_rot, mask_rot)"], "metadata": {"scrolled": true, "_uuid": "acd3491683feb24b69b0691ef3d4183d82c30c4b", "_cell_guid": "f3e23c90-a26e-4f98-a13f-db9839778eab"}, "cell_type": "code"}, {"source": ["## Shift"], "metadata": {"_uuid": "27a6abe6c4ca7750d25e74db58159d33d9117001", "_cell_guid": "3aa74f7e-65fa-4646-b73b-d9620b5512d8"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def shift(x, wshift, hshift, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n", "    h, w = x.shape[row_axis], x.shape[col_axis]\n", "    tx = hshift * h\n", "    ty = wshift * w\n", "    translation_matrix = np.array([[1, 0, tx],\n", "                                   [0, 1, ty],\n", "                                   [0, 0, 1]])\n", "    transform_matrix = translation_matrix  # no need to do offset\n", "    x = image.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n", "    return x\n", "\n", "def random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.5):\n", "    if np.random.random() < u:\n", "        wshift = np.random.uniform(w_limit[0], w_limit[1])\n", "        hshift = np.random.uniform(h_limit[0], h_limit[1])\n", "        img = shift(img, wshift, hshift)\n", "        mask = shift(mask, wshift, hshift)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "6711e94470a1d36b2c846c2941f1dfcd958259b9", "_cell_guid": "d684e4b6-7ea6-4370-9139-ddca25009dc9"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["w_limit=(-0.2, 0.2)\n", "h_limit=(-0.2, 0.2)\n", "wshift = np.random.uniform(w_limit[0], w_limit[1])\n", "hshift = np.random.uniform(h_limit[0], h_limit[1])\n", "print('wshift: %.2f, hshift: %.2f' % (wshift, hshift))\n", "img_shift = shift(img, wshift, hshift)\n", "mask_shift = shift(mask, wshift, hshift)\n", "plot_img_and_mask_transformed(img, mask, img_shift, mask_shift)"], "metadata": {"_uuid": "6aeb6d2c442afeba9cce836e848197308826ee88", "_cell_guid": "eaec958f-3ca0-475e-a5f9-c9cb085657b7"}, "cell_type": "code"}, {"source": ["## Zoom"], "metadata": {"_uuid": "b5f400d24a20e9420cac259246396beb885b97be", "_cell_guid": "9df590b4-3b28-4345-9a70-402945cf3b18"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def zoom(x, zx, zy, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n", "    zoom_matrix = np.array([[zx, 0, 0],\n", "                            [0, zy, 0],\n", "                            [0, 0, 1]])\n", "    h, w = x.shape[row_axis], x.shape[col_axis]\n", "    transform_matrix = image.transform_matrix_offset_center(zoom_matrix, h, w)\n", "    x = image.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n", "    return x\n", "\n", "def random_zoom(img, mask, zoom_range=(0.8, 1), u=0.5):\n", "    if np.random.random() < u:\n", "        zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n", "        img = zoom(img, zx, zy)\n", "        mask = zoom(mask, zx, zy)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "5010c12589bd621cb2d0d74085b67e7bd5cff56f", "_cell_guid": "7d2b1d43-56af-434d-a431-f38c0b7ee701"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["zoom_range=(0.7, 1)\n", "zx, zy = np.random.uniform(zoom_range[0], zoom_range[1], 2)\n", "print('zx: %.2f, zy: %.2f' % (zx, zy))\n", "img_zoom = zoom(img, zx, zy)\n", "mask_zoom = zoom(mask, zx, zy)\n", "plot_img_and_mask_transformed(img, mask, img_zoom, mask_zoom)"], "metadata": {"_uuid": "e696a9bbe73b5eeb33b563f7d704b8b2fe94e37d", "_cell_guid": "b986bc02-90b4-42e9-91ea-47fbbe38d1da"}, "cell_type": "code"}, {"source": ["## Shear"], "metadata": {"_uuid": "bf534f2d4983fed56e1d77ea6981efe75c386974", "_cell_guid": "6b67a759-132d-406a-8acb-2272e3adfc47"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def shear(x, shear, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest', cval=0.):\n", "    shear_matrix = np.array([[1, -np.sin(shear), 0],\n", "                             [0, np.cos(shear), 0],\n", "                             [0, 0, 1]])\n", "    h, w = x.shape[row_axis], x.shape[col_axis]\n", "    transform_matrix = image.transform_matrix_offset_center(shear_matrix, h, w)\n", "    x = image.apply_transform(x, transform_matrix, channel_axis, fill_mode, cval)\n", "    return x\n", "\n", "def random_shear(img, mask, intensity_range=(-0.5, 0.5), u=0.5):\n", "    if np.random.random() < u:\n", "        sh = np.random.uniform(-intensity_range[0], intensity_range[1])\n", "        img = shear(img, sh)\n", "        mask = shear(mask, sh)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "b00ce4184109a1701e49fa04fddc51c4a217e184", "_cell_guid": "f8141919-3af1-4955-88b9-e005f2e614ef"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["intensity = 0.5\n", "sh = np.random.uniform(-intensity, intensity)\n", "print('sh: %.2f' % sh)\n", "img_shear = shear(img, sh)\n", "mask_shear = shear(mask, sh)\n", "plot_img_and_mask_transformed(img, mask, img_shear, mask_shear)"], "metadata": {"_uuid": "c8e9cb79e3445f816253fae80218bf4621bb363a", "_cell_guid": "ce3890c1-cb3c-4374-a066-20d8a267d324"}, "cell_type": "code"}, {"source": ["# Color transformations"], "metadata": {"_uuid": "832d93bd9904281038ac866a29a0bc2046a8ae32", "_cell_guid": "729792ca-ebf5-4c26-a9ac-b9c18d782ca4"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def plot_img_transformed(img, img_tr):\n", "    fig, axs = plt.subplots(ncols=2, figsize=(10, 5), sharex=True, sharey=True)\n", "    axs[0].imshow(img)\n", "    axs[1].imshow(img_tr)\n", "    for ax in axs:\n", "        ax.set_xlim(0, input_size)\n", "        ax.axis('off')\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"collapsed": true, "_uuid": "e919fd297da423e6df1f9b00dfea73098b78a222", "_cell_guid": "91dc21d7-f1b2-4930-812b-90a667ba0da5"}, "cell_type": "code"}, {"source": ["## Random channel shift"], "metadata": {"_uuid": "a3ff4472d465aa085b073ad9b3e4639500349a5b", "_cell_guid": "c2d446b8-fa08-478d-aa8e-87d7adca0d8d"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_channel_shift(x, limit, channel_axis=2):\n", "    x = np.rollaxis(x, channel_axis, 0)\n", "    min_x, max_x = np.min(x), np.max(x)\n", "    channel_images = [np.clip(x_ch + np.random.uniform(-limit, limit), min_x, max_x) for x_ch in x]\n", "    x = np.stack(channel_images, axis=0)\n", "    x = np.rollaxis(x, 0, channel_axis + 1)\n", "    return x"], "metadata": {"collapsed": true, "_uuid": "66fc616c6f58def98ea85ef6f494d4d4e60f4a7c", "_cell_guid": "9bff227b-ff80-48d5-a1af-17a58dcbc0e8"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_chsh = random_channel_shift(img, limit=0.05)\n", "plot_img_transformed(img, img_chsh)"], "metadata": {"scrolled": false, "_uuid": "1f3f0e23ce6667c3bbe106670d3ca28530eb76d6", "_cell_guid": "2e4c7473-9691-4023-90c9-4ae1b0eb7b59"}, "cell_type": "code"}, {"source": ["## Grayscale"], "metadata": {"_uuid": "b3ca19a6b711d0265ebdf685d56b55bfb03dd145", "_cell_guid": "a7527600-8598-4429-bc6a-24be14d9e596"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_gray(img, u=0.5):\n", "    if np.random.random() < u:\n", "        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n", "        gray = np.sum(img * coef, axis=2)\n", "        img = np.dstack((gray, gray, gray))\n", "    return img"], "metadata": {"collapsed": true, "_uuid": "8f93d4541b22deae7dc149e7236fe90b2aa9d116", "_cell_guid": "ac97bfbf-dbee-442c-a345-42f80ab24446"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_gray = random_gray(img, u=1)\n", "plot_img_transformed(img, img_gray)"], "metadata": {"_uuid": "ec9df63e07b20582b5d7cf07da19e62a3e729a40", "_cell_guid": "56516138-b393-406c-ada1-34270d9030ec"}, "cell_type": "code"}, {"source": ["## Contrast"], "metadata": {"_uuid": "a7421b21f6bacbad2e3c0a335bf4a3e9cabc057a", "_cell_guid": "38a61391-0c69-4601-962c-4229a2f8c9b4"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_contrast(img, limit=(-0.3, 0.3), u=0.5):\n", "    if np.random.random() < u:\n", "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n", "        coef = np.array([[[0.114, 0.587, 0.299]]])  # rgb to gray (YCbCr)\n", "        gray = img * coef\n", "        gray = (3.0 * (1.0 - alpha) / gray.size) * np.sum(gray)\n", "        img = alpha * img + gray\n", "        img = np.clip(img, 0., 1.)\n", "    return img"], "metadata": {"collapsed": true, "_uuid": "8cadaed4ef28d47deb45c69aa11a718561620a40", "_cell_guid": "2e5a3e93-18f9-453b-95d5-3e24609d95c1"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_contrast = random_contrast(img, u=1)\n", "plot_img_transformed(img, img_contrast)"], "metadata": {"_uuid": "c0f8038a6108a2206ad33a61d3fbd19717877244", "_cell_guid": "f6cde843-7ec7-44f7-baf7-e902acbe0920"}, "cell_type": "code"}, {"source": ["## Brightness"], "metadata": {"_uuid": "07f107d43975280167c96842900f10451b9c8966", "_cell_guid": "1575f0c4-46df-4a52-9e10-8d6c313a7c7b"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_brightness(img, limit=(-0.3, 0.3), u=0.5):\n", "    if np.random.random() < u:\n", "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n", "        img = alpha * img\n", "        img = np.clip(img, 0., 1.)\n", "    return img"], "metadata": {"collapsed": true, "_uuid": "f0403c6eaddda80b78a18734d7069a3a9ee8fe95", "_cell_guid": "ebb235be-ba30-4c62-9df1-6895dacff913"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_brightness = random_brightness(img, u=1)\n", "plot_img_transformed(img, img_brightness)"], "metadata": {"_uuid": "60faa955c7d7efdb61baf5b5bfaf51e9832a29b9", "_cell_guid": "074c4021-5e4a-4e60-93cb-54e298097bd1"}, "cell_type": "code"}, {"source": ["## Saturation"], "metadata": {"_uuid": "57991b8d79c8888be4e0d7e53ef2c35b51ab97b0", "_cell_guid": "e1952231-f143-49fe-bebf-0d812f0e58cb"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def random_saturation(img, limit=(-0.3, 0.3), u=0.5):\n", "    if np.random.random() < u:\n", "        alpha = 1.0 + np.random.uniform(limit[0], limit[1])\n", "        coef = np.array([[[0.114, 0.587, 0.299]]])\n", "        gray = img * coef\n", "        gray = np.sum(gray, axis=2, keepdims=True)\n", "        img = alpha * img + (1. - alpha) * gray\n", "        img = np.clip(img, 0., 1.)\n", "    return img"], "metadata": {"collapsed": true, "_uuid": "ff9095378497cd5775f9f3c619019d29e1c3b1c5", "_cell_guid": "5108c39a-0cf3-4297-81a3-6f42c3d012c3"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["img_sat = random_saturation(img, u=1)\n", "plot_img_transformed(img, img_sat)"], "metadata": {"_uuid": "b45d9282054648c79dbafd4995f2bdc557437882", "_cell_guid": "f2cd5453-3ca8-477f-b98d-c8c65594082d"}, "cell_type": "code"}, {"source": ["# All together\n", "Not all the transformations help the learning process. The limits here were chosen to have visible effects.\n", "\n", "I am using less transformations and lower limits in my pipeline."], "metadata": {"collapsed": true, "_uuid": "28b2c88a78cebd5177f386db34a6ee67ece4c2a7", "_cell_guid": "805bc540-77ee-4326-9f56-c738f210b192"}, "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "source": ["def plot_img_and_mask_transformed3(img, mask, img_tr1, mask_tr1, img_tr2, mask_tr2):\n", "    fig, axs = plt.subplots(ncols=6, figsize=(30, 5), sharex=True, sharey=True)\n", "    axs[0].imshow(img)\n", "    axs[1].imshow(mask[:, :, 0])\n", "    axs[2].imshow(img_tr1)\n", "    axs[3].imshow(mask_tr1[:, :, 0])\n", "    axs[4].imshow(img_tr2)\n", "    axs[5].imshow(mask_tr2[:, :, 0])\n", "    for ax in axs:\n", "        ax.set_xlim(0, input_size)\n", "        ax.axis('off')\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"collapsed": true, "_uuid": "1204e03271d6b5dcf6030457b959cc6917841fb1", "_cell_guid": "ed4926ee-b95f-4bcc-98d0-e4f43c2dba14"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["def random_augmentation(img, mask):\n", "    img = random_channel_shift(img, limit=0.05)\n", "    img = random_brightness(img, limit=(-0.5, 0.5), u=0.5)\n", "    img = random_contrast(img, limit=(-0.5, 0.5), u=0.5)\n", "    img = random_saturation(img, limit=(-0.5, 0.5), u=0.5)\n", "    img = random_gray(img, u=0.2)\n", "    img, mask = random_rotate(img, mask, rotate_limit=(-20, 20), u=0.5)\n", "    img, mask = random_shear(img, mask, intensity_range=(-0.3, 0.3), u=0.2)\n", "    img, mask = random_flip(img, mask, u=0.3)\n", "    img, mask = random_shift(img, mask, w_limit=(-0.1, 0.1), h_limit=(-0.1, 0.1), u=0.3)\n", "    img, mask = random_zoom(img, mask, zoom_range=(0.8, 1), u=0.3)\n", "    return img, mask"], "metadata": {"collapsed": true, "_uuid": "a1f79d068d4affde1dc84d55f4345dd012082e9c", "_cell_guid": "b4c8464e-df56-4177-b48b-e81dcd629453"}, "cell_type": "code"}, {"execution_count": null, "outputs": [], "source": ["for img_id in img_ids[:16]:\n", "    img, mask = get_image_and_mask(img_id)\n", "    img_aug1, mask_aug1 = random_augmentation(img, mask)\n", "    img_aug2, mask_aug2 = random_augmentation(img, mask)\n", "    plot_img_and_mask_transformed3(img, mask, img_aug1, mask_aug1, img_aug2, mask_aug2)"], "metadata": {"_uuid": "654f82cfaba5ce1639e9b085375a86eb489cc9c2", "_cell_guid": "2a2d0995-5bb5-4b98-9b65-8b911c913f68"}, "cell_type": "code"}]}