{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8dfcd7cfebb7b600077a0d4e06661747df9cdfd"},"cell_type":"markdown","source":"Load the required libraries"},{"metadata":{"trusted":true,"_uuid":"be2a1658cc0d8885806645cf4854c05b86185a05"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n#from tensorflow.python import keras\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, Conv2D, Dropout, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\nfrom keras.datasets import mnist","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"989a407de39227f35c656829ca28baf4fc9583aa"},"cell_type":"markdown","source":"Create the train and test datas"},{"metadata":{"trusted":true,"_uuid":"4f7f2ffb958ad6d477ac39b6bb9b5389f029bdcb"},"cell_type":"code","source":"img_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef data_prep(raw):\n    out_y = to_categorical(raw.label, num_classes)\n    print(type(out_y))\n\n    num_images = raw.shape[0]\n    x_as_array = raw.values[:,1:]\n    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n    out_x = x_shaped_array / 255\n    return out_x, out_y\n\ntrain_file = \"../input/train.csv\"\nraw_data = pd.read_csv(train_file)\n\nkaggle_x, kaggle_y = data_prep(raw_data)\nkag_arr_x = np.array(kaggle_x).reshape(42000, 28, 28, 1)\nprint(type(kaggle_y))\n\n#X_train, X_val, Y_train, Y_val = train_test_split(x, y, test_size = 0.1)\n#raw_data.label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ea160fa4cb9b3a741c43a277efdc441c54561c4"},"cell_type":"code","source":"# Load Data from MNIST\n\n(train_imagesRaw, train_labelsRaw), (test_imagesRaw, test_labelsRaw) = mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21e8d3ced3f19efe184e4846b3e7e094644119b2"},"cell_type":"code","source":"# Prepare the MNIST data\n\n#mnist_x, mnist_y = data_prep(train_imagesRaw)\nprint(train_imagesRaw.shape)\nprint(kag_arr_x.shape)\n\ntrain_imagesKeras = train_imagesRaw.copy()\ntrain_labelsKeras = train_labelsRaw.copy()\ntrain_imagesKeras = train_imagesKeras.reshape(60000,28,28,1)\ntrain_imagesKeras = train_imagesKeras.astype('float32') / 255\nprint(\"train_imagesKeras \",train_imagesKeras.shape)\nprint(\"train_labelsKeras \",train_labelsKeras.shape)\n\ntrain_labelsKeras = to_categorical(train_labelsKeras)\nprint(\"train_labelsKeras \",train_labelsKeras.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db8e88383f69af5bfef852ec327ebd182d0f1786"},"cell_type":"code","source":"#Concatenate the two datasets\ntrain_images = np.concatenate((train_imagesKeras,kag_arr_x), axis=0)\nprint(\"new Concatenated train_images \", train_images.shape)\nprint(\"_\"*50)\n\ntrain_labels = np.concatenate((train_labelsKeras,kaggle_y), axis=0)\nprint(\"new Concatenated train_labels \", train_labels.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36e39dcd023cee55ad0c61e379f6373284d37702"},"cell_type":"code","source":"#split the big fat data\n\nX_train, X_val, Y_train, Y_val = train_test_split(train_images, train_labels, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b5fcd28c87de5fcdbb6dc86ec759678004dd81e"},"cell_type":"markdown","source":"Prepare the model."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(6, 6),\n                 strides=2,\n                 activation='relu',\n                 padding='same',\n                 input_shape=(img_rows, img_cols, 1)))\nmodel.add(Conv2D(32, kernel_size=(6, 6), strides=2, activation='relu', padding='same'))\n#model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n#model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same'))\n#model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same'))\n#model.add(MaxPool2D(pool_size=(2,2)))\n#model.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n#optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n\nmodel.compile(loss=\"categorical_crossentropy\",\n              optimizer='adam',\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau()\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9295b001accca0bcfc518326bc8dd463809798ee"},"cell_type":"markdown","source":"Data augmentation and fit the model"},{"metadata":{"trusted":true,"_uuid":"54c6f458be9d2e306377d62b0d82c1bf7c88f01f"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)\nbatch_size = 100\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = 30, validation_data = (X_val,Y_val),\n                              steps_per_epoch=X_train.shape[0] // batch_size ,\n                              callbacks=[learning_rate_reduction])\n\n#skipping data augmentation\n#model.fit(x, y, batch_size=128, epochs=4, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1a50fbb7743e3d3e1d7c30c4e83ff4dc678eb9e"},"cell_type":"markdown","source":"Running the model on actual test data"},{"metadata":{"trusted":true,"_uuid":"e20ee25fca2315f4f1c9e69419633e6e2b0eab54"},"cell_type":"code","source":"test_file = \"../input/test.csv\"\ntest_data = pd.read_csv(test_file)\n\ndef test_prep(tdata):\n    num_images = tdata.shape[0]\n    x_as_array = tdata.values[:,:]\n    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n    out_x = x_shaped_array / 255\n    return out_x\n\ntest_X = test_prep(test_data)\nans = model.predict_classes(test_X)\nresults = pd.Series(ans,name=\"Label\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1743795c03f2a45ad4b4d5f092bba4b5c7769b1a"},"cell_type":"code","source":"#random code block for testing\n#test_data.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"685ed80f134288b29dc62ad73324509d2ba0d8a8"},"cell_type":"markdown","source":"Save predictions for test data in output file"},{"metadata":{"trusted":true,"_uuid":"a1f3889a5f679ce2588f2d9b96c144d7541c85e7"},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"output_pm.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03435681921b729dfbb6417738d46bd8ef561e87"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}