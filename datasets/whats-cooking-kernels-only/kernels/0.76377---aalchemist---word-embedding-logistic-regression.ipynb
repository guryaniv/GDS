{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.svm import SVC\nimport pandas as pd\nimport json\nfrom random import shuffle\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense\nfrom keras.utils import np_utils\n# Dataset Preparation\nprint (\"Read Dataset ... \")\ndef read_dataset(path):\n\treturn json.load(open(path)) \ntrain = read_dataset('../input/train.json')\ntest = read_dataset('../input/test.json')\n\nshuffle(train)\n#shuffle(train)\n# Text Data Features\nprint (\"Prepare text data of Train and Test ... \")\ndef generate_text(data):\n\ttext_data = [\" \".join(doc['ingredients']).lower() for doc in data]\n\treturn text_data \n\ntrain_text = generate_text(train)\ntest_text = generate_text(test)\ntarget = [doc['cuisine'] for doc in train]\n\n# Feature Engineering \n\nfeachers_set= set()\nfor i in train_text:\n    for j in i:\n        feachers_set.add(j)\nfor i in test_text:\n    for j in i:\n        feachers_set.add(j)\nfeachers_set = list(feachers_set )\nvoclen=len(feachers_set)\ndel(feachers_set)\n\n\nX = [one_hot(d, voclen) for d in train_text ]\nX_text = [one_hot(d, voclen) for d in test_text ]\ndel(train_text)\ndel(test_text)\nmaxlen = max([len(i) for i in X])\nmaxlen1 = max([len(i) for i in X_text])\nmaxlen= max(maxlen,maxlen1)\nX = pad_sequences(X, maxlen=maxlen, padding='post')\nX_test = pad_sequences(X_text, maxlen=maxlen, padding='post')\n# Label Encoding - Target \nprint (\"Label Encode the Target Variable ... \")\nlb = LabelEncoder()\ny = lb.fit_transform(target)\nY=np_utils.to_categorical(y)\nprint(maxlen, voclen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afa7ce0c8fd873c5a12a7b0bda09c68ae7a858e8","collapsed":true},"cell_type":"code","source":"#X=X.toarray().tolist()\n#X_test = X_test.toarray().tolist()\n#print(y[1:3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5defce37547ae7aaa0f9e340f79745e159756fe"},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout ,ActivityRegularization,LeakyReLU\nfrom keras.regularizers import l1_l2,l1\nfrom keras import optimizers\nfrom keras import regularizers\nmodel = Sequential()\nmodel.add(Embedding(input_dim=voclen, # 10\n                    output_dim=16, \n                    input_length=maxlen))\nmodel.add(Flatten())\n\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(500, activation='relu'))\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(Dense(250, activation='linear'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\n\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\nmodel.add(Dense(100, activation='relu'))\n#model.add(LeakyReLU(alpha=.2))\n#model.add(ActivityRegularization(l2=0.1))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(len(Y[0]), activation='softmax'))\nsgd = optimizers.SGD(lr=1, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer='adam',\n          loss='categorical_crossentropy',\n          metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"3df9d09a75979e81c13c08415a770a44df0c4f3f"},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\npath_model='model_simple_keras_starter.h5' \ncheckpointer = ModelCheckpoint('model_simple_keras_starter.h5',monitor='val_acc', verbose=1, save_best_only=True)\nmodel.fit(X,Y,epochs=50, \n            verbose=1,\n          batch_size=64,\n            validation_data=(X[33000:],Y[33000:]),\n            shuffle=True,\n            callbacks=[\n                checkpointer,\n            ]\n          \n         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e6d934e494cb2184985e8088902748e0e4ef8dd"},"cell_type":"code","source":"model.load_weights('model_simple_keras_starter.h5')\nscore = model.evaluate(X[33000:],Y[33000:], verbose=0)\nprint('Test accuracy:', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8330953fbf6b051436b13975c70e1e42920622cf"},"cell_type":"code","source":"import numpy as np\nAns= model.predict(X_test)\nprint(Ans[0])\nAns=[ np.argmax(i) for i in Ans]\nAns=  lb.inverse_transform(Ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2d28268268ee443d75ec5300cb43c73577d0d6c"},"cell_type":"code","source":"print (\"Generate Submission File ... \")\ntest_id = [doc['id'] for doc in test]\nsub = pd.DataFrame({'id': test_id, 'cuisine': Ans}, columns=['id', 'cuisine'])\nsub.to_csv('svm_output.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}