{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Example Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we collected datasets and notebooks and created ```cells.tsv``` using the Dataset Builder in [data_gathering](https://github.com/TAU-DB/guided-ds/tree/master/data_gathering), We'll now tag these cells to the relevant data science workflow stage using snorkel weak supervision and then train an LSTM classifier. <br>\n",
    "\n",
    "This notebooks purpose is to explain the process and recreate it with different data.<br>\n",
    "To check how we originally trained our classifier and our results see- [Exploration_and_WeakSupervision.ipynb](https://github.com/TAU-DB/guided-ds/blob/master/Classification/Exploration_and_WeakSupervision.ipynb), [Classification.ipynb](https://github.com/TAU-DB/guided-ds/blob/master/Classification/Classification.ipynb)\n",
    "\n",
    "**prerequisite**: You must have snorkel installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install snorkel for weak supervision\n",
    "cd snorkel\n",
    "! pip install .\n",
    "cd ..\n",
    "! pip install future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should work, but if any problems occur, see- [https://github.com/HazyResearch/snorkel#quick-start](https://github.com/HazyResearch/snorkel#quick-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak Supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use snorkel new weak-supervison paradigm to tag our unlabeled data with a relatively small amount of noise and with no need to hand-tag a big amount of data.\n",
    "see\n",
    "https://github.com/HazyResearch/snorkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "#start a snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading & Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the ```cells.tsv``` file we created as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading From: C:\\Workspace\\guided-ds\\Example_Data\\cells.tsv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Notebook name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Output</th>\n",
       "      <th>Execution count</th>\n",
       "      <th>Masked</th>\n",
       "      <th>AST</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_1</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>import numpy as np import pandas as pd from sk...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>import_numpy import_pandas import_datetime imp...</td>\n",
       "      <td>Module(body=[Import(names=[alias(name='numpy',...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_2</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_market_data(market_df):     market...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>market_df.drop</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_market_...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_3</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_news_data(news_df):     news_df['p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>news_df.drop var5=var4.merge var5.drop var2.ex...</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_news_da...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_4</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_data(market_df, news_df, start=Non...</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>dt dt</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_data', ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_5</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>(market_df, news_df) = env.get_training_data()...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Module(body=[Assign(targets=[Tuple(elts=[Name(...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Cell ID  User Name  \\\n",
       "0  oriormeir_#_xgboost-2-market-news.ipynb_#_1  oriormeir   \n",
       "1  oriormeir_#_xgboost-2-market-news.ipynb_#_2  oriormeir   \n",
       "2  oriormeir_#_xgboost-2-market-news.ipynb_#_3  oriormeir   \n",
       "3  oriormeir_#_xgboost-2-market-news.ipynb_#_4  oriormeir   \n",
       "4  oriormeir_#_xgboost-2-market-news.ipynb_#_5  oriormeir   \n",
       "\n",
       "                 Notebook name  \\\n",
       "0  xgboost-2-market-news.ipynb   \n",
       "1  xgboost-2-market-news.ipynb   \n",
       "2  xgboost-2-market-news.ipynb   \n",
       "3  xgboost-2-market-news.ipynb   \n",
       "4  xgboost-2-market-news.ipynb   \n",
       "\n",
       "                                              Source Output  Execution count  \\\n",
       "0  import numpy as np import pandas as pd from sk...     []                1   \n",
       "1  def prepare_market_data(market_df):     market...     []                2   \n",
       "2  def prepare_news_data(news_df):     news_df['p...     []                3   \n",
       "3  def prepare_data(market_df, news_df, start=Non...     []                4   \n",
       "4  (market_df, news_df) = env.get_training_data()...     []                5   \n",
       "\n",
       "                                              Masked  \\\n",
       "0  import_numpy import_pandas import_datetime imp...   \n",
       "1                                    market_df.drop    \n",
       "2  news_df.drop var5=var4.merge var5.drop var2.ex...   \n",
       "3                                             dt dt    \n",
       "4                                                NaN   \n",
       "\n",
       "                                                 AST  Label  \n",
       "0  Module(body=[Import(names=[alias(name='numpy',...    NaN  \n",
       "1  Module(body=[FunctionDef(name='prepare_market_...    NaN  \n",
       "2  Module(body=[FunctionDef(name='prepare_news_da...    NaN  \n",
       "3  Module(body=[FunctionDef(name='prepare_data', ...    NaN  \n",
       "4  Module(body=[Assign(targets=[Tuple(elts=[Name(...    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../data_gathering')\n",
    "import consts\n",
    "input_path = consts.CELLS_TSV\n",
    "\n",
    "print(\"Reading From: \"+input_path)\n",
    "\n",
    "df = pd.read_csv(input_path, delimiter='\\t',encoding='utf-8')\n",
    "# we get read of empty cells\n",
    "clean_df = df[df[\"Source\"].isnull() == False]\n",
    "#take a first look\n",
    "clean_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making sure there are no empty cells-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty cells: 0\n",
      "Before drop 41\n",
      "After drop 41\n",
      "Unique ID's 41\n"
     ]
    }
   ],
   "source": [
    "empty_src_df = clean_df[clean_df[\"Source\"] == \"\"]\n",
    "print(\"Empty cells:\", len(empty_src_df))\n",
    "clean_df = clean_df[clean_df[\"Source\"] != \"\"]\n",
    "print(\"Before drop\", len(clean_df))\n",
    "clean_df.dropna()\n",
    "clean_df = clean_df[clean_df[\"Source\"].isnull() == False]\n",
    "clean_df = clean_df[clean_df[\"Cell ID\"].isnull() == False]\n",
    "clean_df.drop_duplicates(inplace=True)\n",
    "print(\"After drop\", len(clean_df))\n",
    "print(\"Unique ID's\", len(clean_df[\"Cell ID\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Defining candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.candidates import Ngrams, CandidateExtractor\n",
    "from snorkel.matchers import NgramMatcher, Matcher\n",
    "from snorkel.models import Context, Document, Sentence, Span, Candidate, StableLabel,candidate_subclass\n",
    "from snorkel.contrib.models.text import RawText\n",
    "\n",
    "# our candidates are cells (what we classify), our values are the classes (Data-Science workflow stages)\n",
    "cellCand  = candidate_subclass('Cell', ['cell'], values=['Load Data', 'Prep & Clean', 'Train & Param', 'Eval', 'Explore', 'Import', False])\n",
    "\n",
    "# Our Catagorical classes: Load Data, Data Preparation & Cleaning, Model Train & paramater tunning, model Evaluation, data exploration, import\n",
    "# Checking candidate cardinality to make sure object created succesfully\n",
    "cellCand.cardinality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we extract candidates from dataset and add them into the current session as candidates:\n",
    "\n",
    "<u>Note:This process takes a long time to execute, and could be skipped if the database already exists</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing any remaining data on the session\n",
    "session.rollback()\n",
    "session.query(Context).delete()\n",
    "session.query(Candidate).delete()\n",
    "session.query(Document).delete()\n",
    "session.query(StableLabel).delete()\n",
    "\n",
    "for i, row in clean_df.iterrows():\n",
    "    c_stable_id = row[\"Cell ID\"]\n",
    "    c_name = 'cell_no_' + str(i)\n",
    "    c_text = row[\"Source\"]\n",
    "    if c_stable_id is None or c_name is None or c_text is None:\n",
    "        continue\n",
    "    if c_stable_id == \"\" or c_name == \"\" or c_text == \"\":\n",
    "        continue\n",
    "    raw_text = RawText(stable_id=c_stable_id, name=c_name , text=c_text)\n",
    "    if i % 3 != 1:\n",
    "        # Split 0 is for training - 75%\n",
    "        candidate = cellCand(cell=raw_text, split=0)\n",
    "    else:\n",
    "        # Split 1 is for evaluating - 25%\n",
    "        candidate = cellCand(cell=raw_text, split=1)\n",
    "    session.add(candidate)\n",
    "session.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying from the stored database:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continue here** - If you didn't run the previous cell it will query from the previously saved database, and if you did it will query from the most recent session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train candidates: 28\n",
      "Number of Dev candidates: 13\n"
     ]
    }
   ],
   "source": [
    "train_cands = session.query(cellCand).filter(cellCand.split == 0).all()\n",
    "dev_cands = session.query(cellCand).filter(cellCand.split == 1).all()\n",
    "\n",
    "print(\"Number of Train candidates:\", len(train_cands))\n",
    "print(\"Number of Dev candidates:\", len(dev_cands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Writing Labeling Functions\n",
    "\n",
    "**The _categorical_ labeling functions (LFs) we now write can output the following values:**\n",
    "\n",
    "* Abstain: `None` OR 0.\n",
    "* Categorical values: One of the six categories we specify above (data science workflow stages classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from kaggle.competitions import twosigmanews import datetime import time  env = twosigmanews.make_env()\n",
      "oriormeir_#_xgboost-2-market-news.ipynb_#_1\n"
     ]
    }
   ],
   "source": [
    "# Getting an example candidate\n",
    "c0 = train_cands[0]\n",
    "\n",
    "print(c0.cell.text) # the code\n",
    "print(c0.cell.stable_id) # unique id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking LF arrays\n",
    "##### Each class has its own array of labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 LF for class 'Load Data'\n",
      "15 LF for class 'Prep & Clean'\n",
      "13 LF for class 'Train & Param'\n",
      "6 LF for class 'Eval'\n",
      "4 LF for class 'Explore'\n",
      "1 LF for class 'Import'\n"
     ]
    }
   ],
   "source": [
    "from utils import LF_utils as lf\n",
    "print(len(lf.LFs_Load), \"LF for class 'Load Data'\")\n",
    "print(len(lf.LFs_Prep), \"LF for class 'Prep & Clean'\")\n",
    "print(len(lf.LFs_Train), \"LF for class 'Train & Param'\")\n",
    "print(len(lf.LFs_Eval), \"LF for class 'Eval'\")\n",
    "print(len(lf.LFs_Explore), \"LF for class 'Explore'\")\n",
    "print(len(lf.LFs_Import), \"LF for class 'Import'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review or change the labeling functions [here](https://github.com/tamirhuber/Jupyter-Notebook-Cells-Classification/blob/master/utils/LF_utils.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all LF's into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 40 LF are loaded\n"
     ]
    }
   ],
   "source": [
    "LF_helpers = []\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Load), axis=None)\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Prep), axis=None)\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Train), axis=None)\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Eval), axis=None)\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Explore), axis=None)\n",
    "LF_helpers = np.concatenate((LF_helpers, lf.LFs_Import), axis=None)\n",
    "\n",
    "print(\"Total of\", len(LF_helpers), \"LF are loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding LF that uses the info from the previous cell\n",
    "Note: This function is not written in the utils file since it needs to use variables that are definfed in this scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def LF_BeforeCell(c):\n",
    "    is_plotting = False\n",
    "    my_labels = []\n",
    "    for func in LF_helpers:\n",
    "        res = func(c)\n",
    "        if res is not None:\n",
    "            if res not in my_labels:\n",
    "                my_labels.append(res)\n",
    "    if len(my_labels) > 0:\n",
    "        if len(my_labels) == 1:\n",
    "            if lf.LF_Plotting(c) == None:\n",
    "                return None\n",
    "            else:\n",
    "                is_plotting = True\n",
    "        else:\n",
    "            return None\n",
    "    pre = \"\"\n",
    "    pre = lf.getPreCellSource(c, 1)\n",
    "    raw_text = RawText(stable_id=\"temp\", name='temp_cell', text=pre)\n",
    "    candidate = cellCand(cell=raw_text, split=2)\n",
    "    labels = []\n",
    "    for func in LF_helpers:\n",
    "        res = func(candidate)\n",
    "        if res is not None:\n",
    "            if res not in labels:\n",
    "                labels.append(res)\n",
    "    if len(labels) == 0:\n",
    "        # if previous cell is also empty look for the prevoius of that\n",
    "        pre = lf.getPreCellSource(c,2)\n",
    "        raw_text = RawText(stable_id=\"temp\", name='temp_cell', text=pre)\n",
    "        candidate2 = cellCand(cell=raw_text, split=2)\n",
    "        for func in LF_helpers:\n",
    "            res = func(candidate2)\n",
    "            if res is not None:\n",
    "                if res not in labels:\n",
    "                    labels.append(res)\n",
    "        if len(labels) == 0:\n",
    "            if is_plotting:\n",
    "                return lf.LF_Plotting(c)\n",
    "            return None\n",
    "    if 'print' in pre or 'print' in c.cell.text or is_plotting:\n",
    "        if 'Load Data' in labels or 'Prep & Clean' in labels:\n",
    "            return 'Explore'\n",
    "        if 'Eval' in labels or 'Train & Param' in labels:\n",
    "            return 'Eval'\n",
    "    return random.choice(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 41 LF are set for applying\n"
     ]
    }
   ],
   "source": [
    "# Adding LF that uses the info from the previous cell\n",
    "LF_arr = LF_helpers.tolist()\n",
    "LF_arr.append(LF_BeforeCell)\n",
    "print(\"Total of\", len(LF_arr), \"LF are set for applying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we load our gold label data (hand-labeled)\n",
    "#### <u> If you skip candidate extraction you may also skip this cell </u>\n",
    "\n",
    "**For a small example we probably didn't tag any of the cells manually...** <br>\n",
    "You can tag cells for your dataset and change the path to ```gold_labels.tsv``` in ```consts.GOLD_LABELS```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consts imported\n",
      "1024\n",
      "AnnotatorLabels created: 0\n",
      "AnnotatorLabels created: 0\n",
      "Wall time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "from utils.Label_util import load_external_labels\n",
    "from snorkel.models import StableLabel\n",
    "\n",
    "# with session.no_autoflush:\n",
    "session.rollback()\n",
    "%time missed = load_external_labels(session, cellCand, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13x1 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit testing the LF functions of each class on the gold label set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: skip if there are no relevant gold labels found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Eval_utils as eu\n",
    "\n",
    "print('LF_Import:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Import, 6, split=1, annotator_name='gold')\n",
    "print('LF_LoadData:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Load, 1, split=1, annotator_name='gold')\n",
    "print('LF_PrepAndClean:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Prep, 2, split=1, annotator_name='gold')\n",
    "print('LF_TrainAndParam:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Train, 3, split=1, annotator_name='gold')\n",
    "print('LF_Eval:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Eval, 4, split=1, annotator_name='gold')\n",
    "print('LF_Explore:')\n",
    "tp, fp, tn, fn = eu.test_LF(session, lf.LFs_Explore, 5, split=1, annotator_name='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some functions are better than others, there are also a lot of collisions (as we are about to see) - noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a \"Labeler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LF_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we apply the LFs to the candidates of the train set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%time L_train = labeler.apply(split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Labeled Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<28x41 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 59 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.load_matrix(session, split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing some of the labeling results (using the labeling functions with no weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Label (LF_Import = 6)]\n",
      "import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from kaggle.competitions import twosigmanews import datetime import time  env = twosigmanews.make_env()\n",
      "##########\n",
      "\n",
      "\n",
      "[Label (LF_Def = 2), Label (LF_Concat = 2), Label (LF_Drop = 2), Label (LF_sklearn_impute = 2)]\n",
      "def prepare_news_data(news_df):     news_df['position'] = news_df['firstMentionSentence'] / news_df['sentenceCount']     news_df['coverage'] = news_df['sentimentWordCount'] / news_df['wordCount']      droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence',                 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass',                 'assetName', 'urgency','wordCount','sentimentWordCount']     news_df.drop(droplist, axis=1, inplace=True)      # create a mapping between 'assetCode' to 'news_index'     assets = []     indices = []     for i, values in news_df['assetCodes'].iteritems():         assetCodes = eval(values)         assets.extend(assetCodes)         indices.extend([i]*len(assetCodes))     mapping_df = pd.DataFrame({'news_index': indices, 'assetCode': assets})     del assets, indices          # join 'news_train_df' and 'mapping_df' (effectivly duplicating news entries)     news_df['news_index'] = news_df.index.copy()     expanded_news_df = mapping_df.merge(news_df, how='left', on='news_index')     del mapping_df, news_df          expanded_news_df.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     return expanded_news_df.groupby(['time', 'assetCode']).mean().reset_index()\n",
      "##########\n",
      "\n",
      "\n",
      "[Label (LF_Def = 2), Label (LF_Fill = 2), Label (LF_Nulls = 2)]\n",
      "def prepare_data(market_df, news_df, start=None):     market_df['time'] = market_df['time'].dt.date     news_df['time'] = news_df['time'].dt.date     if start is not None:         market_df = market_df[market_df['time'] >= start].reset_index(drop=True)         news_df = news_df[news_df['time'] >= start].reset_index(drop=True)      market_df = prepare_market_data(market_df)     news_df = prepare_news_data(news_df)      # join news_df to market_df using ['assetCode', 'time']     return market_df.merge(news_df, how='left', on=['assetCode', 'time']).fillna(0)\n",
      "##########\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = L_train.get_candidate(session, 0)\n",
    "print(c.labels) #labels\n",
    "print(c.cell.text) #code\n",
    "print(\"##########\\n\\n\")\n",
    "\n",
    "c = L_train.get_candidate(session, 1)\n",
    "print(c.labels) #labels\n",
    "print(c.cell.text) #code\n",
    "print(\"##########\\n\\n\")\n",
    "\n",
    "c = L_train.get_candidate(session, 2)\n",
    "print(c.labels) #labels\n",
    "print(c.cell.text) #code\n",
    "print(\"##########\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, as we mentioned before. that there are overlaps. Different LFs don't agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LF functions Mutual Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_Read</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Def</th>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Concat</th>\n",
       "      <td>2</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Split</th>\n",
       "      <td>3</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Drop</th>\n",
       "      <td>4</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Fill</th>\n",
       "      <td>5</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Nulls</th>\n",
       "      <td>6</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Loc</th>\n",
       "      <td>7</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Transformions</th>\n",
       "      <td>8</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TransformOps</th>\n",
       "      <td>9</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_TxtEncode</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Token</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_f_e</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_f_s</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_impute</th>\n",
       "      <td>14</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_p_p</th>\n",
       "      <td>15</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Models</th>\n",
       "      <td>16</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Train</th>\n",
       "      <td>17</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Optimize</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Params</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_cluster</th>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_l_m</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_ensemble</th>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_mixture</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_neighbors</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_n_n</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_svm</th>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_tree</th>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h2o_estimators</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Predict</th>\n",
       "      <td>29</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Score</th>\n",
       "      <td>30</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Eval</th>\n",
       "      <td>31</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Error</th>\n",
       "      <td>32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Curves</th>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_metrics</th>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Explore</th>\n",
       "      <td>35</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Sizes</th>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Plotting</th>\n",
       "      <td>37</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_sklearn_covariance</th>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_Import</th>\n",
       "      <td>39</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_BeforeCell</th>\n",
       "      <td>40</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        j  Coverage  Overlaps  Conflicts\n",
       "LF_Read                 0  0.000000  0.000000   0.000000\n",
       "LF_Def                  1  0.142857  0.142857   0.035714\n",
       "LF_Concat               2  0.178571  0.178571   0.107143\n",
       "LF_Split                3  0.107143  0.107143   0.071429\n",
       "LF_Drop                 4  0.142857  0.142857   0.107143\n",
       "LF_Fill                 5  0.142857  0.142857   0.107143\n",
       "LF_Nulls                6  0.142857  0.142857   0.107143\n",
       "LF_Loc                  7  0.142857  0.142857   0.107143\n",
       "LF_Transformions        8  0.035714  0.035714   0.035714\n",
       "LF_TransformOps         9  0.071429  0.071429   0.071429\n",
       "LF_TxtEncode           10  0.000000  0.000000   0.000000\n",
       "LF_Token               11  0.000000  0.000000   0.000000\n",
       "LF_sklearn_f_e         12  0.000000  0.000000   0.000000\n",
       "LF_sklearn_f_s         13  0.000000  0.000000   0.000000\n",
       "LF_sklearn_impute      14  0.071429  0.071429   0.035714\n",
       "LF_sklearn_p_p         15  0.071429  0.071429   0.071429\n",
       "LF_Models              16  0.142857  0.142857   0.142857\n",
       "LF_Train               17  0.142857  0.107143   0.107143\n",
       "LF_Optimize            18  0.000000  0.000000   0.000000\n",
       "LF_Params              19  0.000000  0.000000   0.000000\n",
       "LF_sklearn_cluster     20  0.000000  0.000000   0.000000\n",
       "LF_sklearn_l_m         21  0.000000  0.000000   0.000000\n",
       "LF_sklearn_ensemble    22  0.000000  0.000000   0.000000\n",
       "LF_sklearn_mixture     23  0.000000  0.000000   0.000000\n",
       "LF_sklearn_neighbors   24  0.000000  0.000000   0.000000\n",
       "LF_sklearn_n_n         25  0.000000  0.000000   0.000000\n",
       "LF_sklearn_svm         26  0.000000  0.000000   0.000000\n",
       "LF_sklearn_tree        27  0.000000  0.000000   0.000000\n",
       "LF_h2o_estimators      28  0.000000  0.000000   0.000000\n",
       "LF_Predict             29  0.107143  0.107143   0.107143\n",
       "LF_Score               30  0.035714  0.035714   0.035714\n",
       "LF_Eval                31  0.000000  0.000000   0.000000\n",
       "LF_Error               32  0.000000  0.000000   0.000000\n",
       "LF_Curves              33  0.000000  0.000000   0.000000\n",
       "LF_sklearn_metrics     34  0.000000  0.000000   0.000000\n",
       "LF_Explore             35  0.035714  0.035714   0.035714\n",
       "LF_Sizes               36  0.000000  0.000000   0.000000\n",
       "LF_Plotting            37  0.071429  0.071429   0.035714\n",
       "LF_sklearn_covariance  38  0.000000  0.000000   0.000000\n",
       "LF_Import              39  0.285714  0.107143   0.107143\n",
       "LF_BeforeCell          40  0.035714  0.035714   0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labeling using only labeling functions is very noisy because of these overlaps and conflicts.\n",
    "Snorkel uses a generative model to decide which function is \"better\" for each case.\n",
    "So we can add \"weights\" to the labeling functions and get a more decisive and less noisy results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Training the Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "gen_model = GenerativeModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <u>Note - the following cell may take long time to execute* You can skip straight to - Loading the Generative Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenerativeModel] Model saved as <GenerativeModel>.\n"
     ]
    }
   ],
   "source": [
    "# Note: We pass cardinality explicitly here to be safe\n",
    "gen_model.train(L_train, cardinality=6)\n",
    "gen_model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the trained Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GenerativeModel] Model <GenerativeModel> loaded.\n"
     ]
    }
   ],
   "source": [
    "gen_model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LFs accuracy with generative model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96982637, 1.00464003, 0.99640414, 0.97904441, 0.9891655 ,\n",
       "       1.00640758, 0.99413879, 1.00700049, 0.97643607, 0.99029241,\n",
       "       0.97501085, 0.97559757, 0.97518811, 0.97905146, 0.98652983,\n",
       "       0.99025138, 0.9652113 , 0.98439672, 0.97529347, 0.973527  ,\n",
       "       0.96696737, 0.98181254, 0.97485741, 0.970484  , 0.98434841,\n",
       "       0.96763197, 0.97923347, 0.97223339, 0.9792072 , 0.96103026,\n",
       "       0.97617537, 0.97680178, 0.97707546, 0.97980155, 0.97531532,\n",
       "       0.96162941, 0.97682946, 0.97412664, 0.96668829, 0.97200587,\n",
       "       0.98059102])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights.lf_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Train Marginals\n",
    "#### <u> Note - the following cell may take few minutes</u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we apply the LFs to the candidates of the test set:\n",
    "#### <u>Note - the following cell may take long time (~ 30 minutes)* . You can skip straight to - Loading Labeled Test Set</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_test = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Labeled Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<13x41 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_test = labeler.load_matrix(session, split=1)\n",
    "L_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Test Marginals\n",
    "#### <u> Note - the following cell may take few minutes </u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "test_marginals = gen_model.marginals(L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Gold Labels to test Snorkel results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled data: 1025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kerneler_#_starter-advance-u-s-international-0...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kerneler_#_starter-advance-u-s-international-0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kerneler_#_starter-advance-u-s-international-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kerneler_#_starter-advance-u-s-international-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kerneler_#_starter-advance-u-s-international-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                cell  label\n",
       "0  kerneler_#_starter-advance-u-s-international-0...      6\n",
       "1  kerneler_#_starter-advance-u-s-international-0...      1\n",
       "2  kerneler_#_starter-advance-u-s-international-1...      1\n",
       "3  kerneler_#_starter-advance-u-s-international-1...      1\n",
       "4  kerneler_#_starter-advance-u-s-international-3...      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_path = consts.GOLD_LABELS\n",
    "labeled = pd.read_csv(gold_path,delimiter='\\t',encoding='utf-8')\n",
    "print(\"Total labeled data:\", len(labeled))\n",
    "labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clearing any session errors and checking the test set size\n",
    "session.rollback()\n",
    "L_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying  the gold labeled test set candidates from the session\n",
    "#### <u> Doing this once and saving only the important indexes of those candidates to improve time in future, this might take a few minutes</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled data in the test-set: 0\n"
     ]
    }
   ],
   "source": [
    "tag_cand_index = []\n",
    "for i in range(0, L_test.shape[0]):\n",
    "    cand = L_test.get_candidate(session, i)\n",
    "    cell_id = cand.cell.stable_id\n",
    "    is_tagged = len(labeled[labeled[\"cell\"] == cell_id])\n",
    "    if is_tagged > 0:\n",
    "        tag_cand_index.append(i)\n",
    "print(\"Total labeled data in the test-set:\", len(tag_cand_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: if there are no tagged cells in the test set skip the next evaluation cells (they will result in an error because there is nothing to compare against. (continue in step5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reload labeld data (if any updates were made -mosly used to check errors in gold lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was used in order to fix hand tagged errors and re-test the model result.\n",
    "labeled = pd.read_csv(gold_path,delimiter='\\t',encoding='utf-8')\n",
    "print(\"Total labeled data:\", len(labeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now let's check our categorical accuracy with the gold labels test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Eval_utils as eu\n",
    "y_pred_arr, y_true_arr = eu.calc_lf_acc(session, tag_cand_index, L_test, test_marginals, labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true_arr, y_pred_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we label some of the data preparation cells as data exploration, as data preparation recall is lower and data exploration precision is lower, but thats a hard task. Overall the results are pretty good.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Labeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Notebook name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Output</th>\n",
       "      <th>Execution count</th>\n",
       "      <th>Masked</th>\n",
       "      <th>AST</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_1</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>import numpy as np import pandas as pd from sk...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>import_numpy import_pandas import_datetime imp...</td>\n",
       "      <td>Module(body=[Import(names=[alias(name='numpy',...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Cell ID  User Name  \\\n",
       "0  oriormeir_#_xgboost-2-market-news.ipynb_#_1  oriormeir   \n",
       "\n",
       "                 Notebook name  \\\n",
       "0  xgboost-2-market-news.ipynb   \n",
       "\n",
       "                                              Source Output  Execution count  \\\n",
       "0  import numpy as np import pandas as pd from sk...     []                1   \n",
       "\n",
       "                                              Masked  \\\n",
       "0  import_numpy import_pandas import_datetime imp...   \n",
       "\n",
       "                                                 AST Label  \n",
       "0  Module(body=[Import(names=[alias(name='numpy',...        "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels_str = ['Unknown', 'Load', 'Prep', 'Train', 'Eval', 'Explore', 'Import']\n",
    "tagged_df = clean_df.copy()\n",
    "#add a new column for the label\n",
    "tagged_df[\"Label\"] = \"\"\n",
    "tagged_df.head(1) #just to check the column was added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tag the data according to the highest probability in the generative model output-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <u> Note - the following cell may take a long time to execute for a large number of cells.</u> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>User Name</th>\n",
       "      <th>Notebook name</th>\n",
       "      <th>Source</th>\n",
       "      <th>Output</th>\n",
       "      <th>Execution count</th>\n",
       "      <th>Masked</th>\n",
       "      <th>AST</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_1</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>import numpy as np import pandas as pd from sk...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>import_numpy import_pandas import_datetime imp...</td>\n",
       "      <td>Module(body=[Import(names=[alias(name='numpy',...</td>\n",
       "      <td>Import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_2</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_market_data(market_df):     market...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>market_df.drop</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_market_...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_3</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_news_data(news_df):     news_df['p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>news_df.drop var5=var4.merge var5.drop var2.ex...</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_news_da...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_4</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>def prepare_data(market_df, news_df, start=Non...</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>dt dt</td>\n",
       "      <td>Module(body=[FunctionDef(name='prepare_data', ...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_5</td>\n",
       "      <td>oriormeir</td>\n",
       "      <td>xgboost-2-market-news.ipynb</td>\n",
       "      <td>(market_df, news_df) = env.get_training_data()...</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Module(body=[Assign(targets=[Tuple(elts=[Name(...</td>\n",
       "      <td>Explore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Cell ID  User Name  \\\n",
       "0  oriormeir_#_xgboost-2-market-news.ipynb_#_1  oriormeir   \n",
       "1  oriormeir_#_xgboost-2-market-news.ipynb_#_2  oriormeir   \n",
       "2  oriormeir_#_xgboost-2-market-news.ipynb_#_3  oriormeir   \n",
       "3  oriormeir_#_xgboost-2-market-news.ipynb_#_4  oriormeir   \n",
       "4  oriormeir_#_xgboost-2-market-news.ipynb_#_5  oriormeir   \n",
       "\n",
       "                 Notebook name  \\\n",
       "0  xgboost-2-market-news.ipynb   \n",
       "1  xgboost-2-market-news.ipynb   \n",
       "2  xgboost-2-market-news.ipynb   \n",
       "3  xgboost-2-market-news.ipynb   \n",
       "4  xgboost-2-market-news.ipynb   \n",
       "\n",
       "                                              Source Output  Execution count  \\\n",
       "0  import numpy as np import pandas as pd from sk...     []                1   \n",
       "1  def prepare_market_data(market_df):     market...     []                2   \n",
       "2  def prepare_news_data(news_df):     news_df['p...     []                3   \n",
       "3  def prepare_data(market_df, news_df, start=Non...     []                4   \n",
       "4  (market_df, news_df) = env.get_training_data()...     []                5   \n",
       "\n",
       "                                              Masked  \\\n",
       "0  import_numpy import_pandas import_datetime imp...   \n",
       "1                                    market_df.drop    \n",
       "2  news_df.drop var5=var4.merge var5.drop var2.ex...   \n",
       "3                                             dt dt    \n",
       "4                                                NaN   \n",
       "\n",
       "                                                 AST    Label  \n",
       "0  Module(body=[Import(names=[alias(name='numpy',...   Import  \n",
       "1  Module(body=[FunctionDef(name='prepare_market_...     Prep  \n",
       "2  Module(body=[FunctionDef(name='prepare_news_da...     Prep  \n",
       "3  Module(body=[FunctionDef(name='prepare_data', ...     Prep  \n",
       "4  Module(body=[Assign(targets=[Tuple(elts=[Name(...  Explore  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set label according to the highest probabiltiy\n",
    "for i,cand in enumerate(train_cands):\n",
    "    marg = train_marginals[i]\n",
    "    id = cand.cell.stable_id\n",
    "    boolcol = (tagged_df[\"Cell ID\"] == id)\n",
    "    idx = tagged_df.index[boolcol][0]\n",
    "    max =  marg.max()\n",
    "    labels = np.where(marg == max)[0]\n",
    "    if len(labels) > 1:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = labels[0] + 1\n",
    "    \n",
    "    tagged_df.at[idx, \"Label\"] = Labels_str[label]\n",
    "        \n",
    "for i in range(0, L_test.shape[0]):\n",
    "    marg = test_marginals[i]\n",
    "    cand = L_test.get_candidate(session, i)\n",
    "    id = cand.cell.stable_id\n",
    "    boolcol = (tagged_df[\"Cell ID\"] == id)\n",
    "    idx = tagged_df.index[boolcol][0]\n",
    "    max =  marg.max()\n",
    "    labels = np.where(marg == max)[0]\n",
    "    if len(labels) > 1:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = labels[0] + 1\n",
    "    \n",
    "    tagged_df.at[idx, \"Label\"] = Labels_str[label]\n",
    "tagged_df.head(5) #just to see some tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export tagged dataset\n",
    "\n",
    "We export the snorkel tagged dataset to the Data Folder defined by ```consts.DATA_FOLDER``` as ```input.tsv```.<br>\n",
    "This file will be used as input to train a supervised end-classification-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "save_path= os.path.join(consts.DATA_FOLDER,\"input.tsv\")\n",
    "\n",
    "tagged_df.to_csv(save_path, sep='\\t', quotechar='\"', quoting=csv.QUOTE_MINIMAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tagged dataset will be used to train a supervised end-classification-model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Model (LSTM Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our snorkel tagged cells, we want to use them to train a supervised LSTM model that will classify a given cell source code into the relevant data-scientist workflow stage (multi-class text classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install prerequisites**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install necessary packages\n",
    "! pip install -U --user pip six numpy wheel mock pandas\n",
    "! pip install -U --user keras_applications==1.0.6 --no-deps\n",
    "! pip install -U --user keras_preprocessing==1.0.5 --no-deps\n",
    "! pip install keras tensorflow sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this should work, but if any problems occur see- [https://www.tensorflow.org/install](https://www.tensorflow.org/install), [https://keras.io/#installation](https://keras.io/#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# First let's import relevant libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "import pickle\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If keras and tensorflow installation was succesful and there is still a problem with the imports, try restarting the kernel and clearing outputs, and then run the imports cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# load our tagged Data\n",
    "\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../data_gathering')\n",
    "import consts\n",
    "\n",
    "load_path = os.path.join(consts.DATA_FOLDER,\"input.tsv\")\n",
    "data = pd.read_csv(load_path, delimiter='\\t', usecols=['Cell ID', 'Source', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we'll remove cells that snorkel didn't tag\n",
    "data.dropna(subset=['Label'], how='all', inplace = True)\n",
    "data = data[data.Label != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_4</td>\n",
       "      <td>def prepare_data(market_df, news_df, start=Non...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_8</td>\n",
       "      <td>print(\"generating predictions...\") days = env....</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>X_train, X_test, up_train, up_test, r_train, r...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_6</td>\n",
       "      <td>train_columns = [x for x in merged_df.columns ...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>from xgboost import XGBClassifier import time</td>\n",
       "      <td>Import</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Cell ID  \\\n",
       "3         oriormeir_#_xgboost-2-market-news.ipynb_#_4   \n",
       "7         oriormeir_#_xgboost-2-market-news.ipynb_#_8   \n",
       "16  alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "5         oriormeir_#_xgboost-2-market-news.ipynb_#_6   \n",
       "17  alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "\n",
       "                                               Source   Label  \n",
       "3   def prepare_data(market_df, news_df, start=Non...    Prep  \n",
       "7   print(\"generating predictions...\") days = env....   Train  \n",
       "16  X_train, X_test, up_train, up_test, r_train, r...   Train  \n",
       "5   train_columns = [x for x in merged_df.columns ...    Prep  \n",
       "17      from xgboost import XGBClassifier import time  Import  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's take a look at some random cells\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tsv contains for each jupyter notebook cell of code- <br>\n",
    "a unique cell id, the cell's source code and the label that was generated by snorkel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a look at the tagged data value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "ea29d595-26b0-4d83-a005-853fa59f4506",
    "_uuid": "acf2450933eb3586930df738829abd2e11646e14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prep       9\n",
       "Import     6\n",
       "Train      6\n",
       "Explore    4\n",
       "Eval       3\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's see\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the classes are imbalanced. The data exploration class has much more cells than the others. we want to have balaced classes for the model to train, so we'll take a fixed size from each class (under sample the large classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "44de46e2-acce-470d-9c46-624cb0dd15b9",
    "_uuid": "eb9f4766b60f5a23901a8bde1d901ced6c7a3b3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_4</td>\n",
       "      <td>def prepare_data(market_df, news_df, start=Non...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>charleslandau_#_iterative-approach.ipynb_#_9</td>\n",
       "      <td>from sklearn.metrics import accuracy_score imp...</td>\n",
       "      <td>Eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>def data_prep(market_train,news_train):     ma...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_3</td>\n",
       "      <td>def prepare_news_data(news_df):     news_df['p...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_7</td>\n",
       "      <td>from xgboost import XGBClassifier import time ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Cell ID  \\\n",
       "3         oriormeir_#_xgboost-2-market-news.ipynb_#_4   \n",
       "35       charleslandau_#_iterative-approach.ipynb_#_9   \n",
       "9   alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "2         oriormeir_#_xgboost-2-market-news.ipynb_#_3   \n",
       "6         oriormeir_#_xgboost-2-market-news.ipynb_#_7   \n",
       "\n",
       "                                               Source  Label  \n",
       "3   def prepare_data(market_df, news_df, start=Non...   Prep  \n",
       "35  from sklearn.metrics import accuracy_score imp...   Eval  \n",
       "9   def data_prep(market_train,news_train):     ma...   Prep  \n",
       "2   def prepare_news_data(news_df):     news_df['p...   Prep  \n",
       "6   from xgboost import XGBClassifier import time ...  Train  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we shuffle the data by randomly re-indexing\n",
    "shuffled = data.reindex(np.random.permutation(data.index))\n",
    "shuffled.head(5) #check data is indeed shuffeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_4</td>\n",
       "      <td>def prepare_data(market_df, news_df, start=Non...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>def data_prep(market_train,news_train):     ma...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_7</td>\n",
       "      <td>from xgboost import XGBClassifier import time ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>X_train, X_test, up_train, up_test, r_train, r...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charleslandau_#_iterative-approach.ipynb_#_9</td>\n",
       "      <td>from sklearn.metrics import accuracy_score imp...</td>\n",
       "      <td>Eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Cell ID  \\\n",
       "0        oriormeir_#_xgboost-2-market-news.ipynb_#_4   \n",
       "1  alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "2        oriormeir_#_xgboost-2-market-news.ipynb_#_7   \n",
       "3  alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "4       charleslandau_#_iterative-approach.ipynb_#_9   \n",
       "\n",
       "                                              Source  Label  \n",
       "0  def prepare_data(market_df, news_df, start=Non...   Prep  \n",
       "1  def data_prep(market_train,news_train):     ma...   Prep  \n",
       "2  from xgboost import XGBClassifier import time ...  Train  \n",
       "3  X_train, X_test, up_train, up_test, r_train, r...  Train  \n",
       "4  from sklearn.metrics import accuracy_score imp...   Eval  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_class_size = 2 #originally we took 5,000 cells from each class \n",
    "l  = shuffled[shuffled['Label'] == 'Load'][:fixed_class_size]\n",
    "p  = shuffled[shuffled['Label'] == 'Prep'][:fixed_class_size]\n",
    "t  = shuffled[shuffled['Label'] == 'Train'][:fixed_class_size]\n",
    "ev = shuffled[shuffled['Label'] == 'Eval'][:fixed_class_size]\n",
    "ex = shuffled[shuffled['Label'] == 'Explore'][:fixed_class_size]\n",
    "i  = shuffled[shuffled['Label'] == 'Import'][:fixed_class_size]\n",
    "\n",
    "concated = pd.concat([l, p, t, ev, ex, i], ignore_index=True) #our new data with balanced classes\n",
    "concated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oriormeir_#_xgboost-2-market-news.ipynb_#_7</td>\n",
       "      <td>from xgboost import XGBClassifier import time ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>charleslandau_#_iterative-approach.ipynb_#_1</td>\n",
       "      <td>from kaggle.competitions import twosigmanews i...</td>\n",
       "      <td>Import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>charleslandau_#_iterative-approach.ipynb_#_12</td>\n",
       "      <td>#env.predict(predictions_template_df)</td>\n",
       "      <td>Eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>charleslandau_#_iterative-approach.ipynb_#_9</td>\n",
       "      <td>from sklearn.metrics import accuracy_score imp...</td>\n",
       "      <td>Eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...</td>\n",
       "      <td>X_train, X_test, up_train, up_test, r_train, r...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Cell ID  \\\n",
       "2        oriormeir_#_xgboost-2-market-news.ipynb_#_7   \n",
       "9       charleslandau_#_iterative-approach.ipynb_#_1   \n",
       "5      charleslandau_#_iterative-approach.ipynb_#_12   \n",
       "4       charleslandau_#_iterative-approach.ipynb_#_9   \n",
       "3  alluxia_#_lb-0-6326-tuned-xgboost-baseline.ipy...   \n",
       "\n",
       "                                              Source   Label  \n",
       "2  from xgboost import XGBClassifier import time ...   Train  \n",
       "9  from kaggle.competitions import twosigmanews i...  Import  \n",
       "5              #env.predict(predictions_template_df)    Eval  \n",
       "4  from sklearn.metrics import accuracy_score imp...    Eval  \n",
       "3  X_train, X_test, up_train, up_test, r_train, r...   Train  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle the dataset again by re-indexing\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "concated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and Vector representation of label and code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll represent the label as a one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "2d3da0fd-6d73-4f3b-b06b-d2bba34bbd4a",
    "_uuid": "60febe37826f220106adf69a51dad124cfae45cc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add int representation of the label\n",
    "concated['INT'] = 0\n",
    "concated.loc[concated['Label'] == 'Load', 'INT']  = 0\n",
    "concated.loc[concated['Label'] == 'Prep', 'INT']  = 1\n",
    "concated.loc[concated['Label'] == 'Train', 'INT']  = 2\n",
    "concated.loc[concated['Label'] == 'Eval', 'INT'] = 3\n",
    "concated.loc[concated['Label'] == 'Explore', 'INT'] = 4\n",
    "concated.loc[concated['Label'] == 'Import', 'INT']  = 5\n",
    "\n",
    "#one-hot encode the label\n",
    "labels = to_categorical(concated['INT'], num_classes=6)\n",
    "if 'Label' in concated.keys():\n",
    "    concated.drop(['Label'], axis=1)\n",
    "# '''\n",
    "#  [1. 0. 0. 0. 0. 0.] load data\n",
    "#  [0. 1. 0. 0. 0. 0.] data preparation and cleaning\n",
    "#  [0. 0. 1. 0. 0. 0.] model training and parameter tuning\n",
    "#  [0. 0. 0. 1. 0. 0.] model evaluation\n",
    "#  [0. 0. 0. 0. 1. 0.] data exploration\n",
    "#  [0. 0. 0. 0. 0. 1.] imports\n",
    "# '''\n",
    "\n",
    "#let's print some of the labels to see the encoding\n",
    "labels.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all comments, as comments may refer to actions that werent really done or to what was done previously to the current cell, so that it just interferes in our task to classify the current cell correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consts imported\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import findAndRemoveComments\n",
    "concated['Source'] = concated['Source'].apply(lambda x: findAndRemoveComments(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn the code to-lower, filter special chars and dots and split each cell's code into tokens.\n",
    "Then we represent the most common words by ints and each cell is represented as a vector of ints according to the words that it contains. The vectors are then padded to a fixed max length of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_cell_guid": "40e6281c-2588-4ad0-991c-3d8d40791254",
    "_uuid": "0aa67be64bd63cf4350ce3f62d42c687b3143088",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 156 unique tokens.\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "n_most_common_words = 8000\n",
    "max_len = 120\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,.-/:;<=>?@[\\]^`{|}~\\n\\r\\t \\'', lower=True)\n",
    "tokenizer.fit_on_texts(concated['Source'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['Source'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print(\"-------\")\n",
    "\n",
    "# to print our \"words\" dictionary uncomment the following line (long print) \n",
    "# print(word_index)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data, represented as vectors, into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_cell_guid": "2ca496ca-4bb7-40de-bf69-d86b521af51f",
    "_uuid": "97226bf26ef141c228a1123e125ef7966612db47"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup and train an LSTM model using the vector representation of the code and the labels (Supervised learning, where the labels where generated by snorkel)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "4e5bcf7a-4c6b-44fc-963d-415b9338abe4",
    "_uuid": "28940e621602cfd9645a88dd43427b2431c75b5b"
   },
   "outputs": [],
   "source": [
    "epochs = 3 # originally we trained with 15 epoches\n",
    "# we set an EarlyStopping, so when the model stops improving val_loss'wise it will stop training\n",
    "# but we also don't want to overfit\n",
    "emb_dim = 512\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Setup and Training\n",
    "<u>Note: model training could take up to 1 hour, you can skip and load the trained model in the next cell</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "79a42a6f-01f4-4e74-b645-321f2a0a6e39",
    "_uuid": "f50c8494777ca5141da8c23bb932e531a82b89d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0809 14:32:00.778898 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0809 14:32:00.803435 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0809 14:32:00.807432 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0809 14:32:00.832439 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0809 14:32:00.846436 10980 deprecation.py:506] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0809 14:32:00.850433 10980 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
      "((7, 120), (7, 6), (3, 120), (3, 6))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0809 14:32:00.992433 10980 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0809 14:32:01.021437 10980 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0809 14:32:01.053432 10980 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0809 14:32:01.076431 10980 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0809 14:32:01.291661 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0809 14:32:01.336149 10980 deprecation_wrapper.py:119] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0809 14:32:01.502428 10980 deprecation.py:323] From C:\\Users\\gurya\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 120, 512)          4096000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 120, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                147712    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 4,244,102\n",
      "Trainable params: 4,244,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 5 samples, validate on 2 samples\n",
      "Epoch 1/3\n",
      "5/5 [==============================] - 2s 340ms/step - loss: 1.7789 - acc: 0.0000e+00 - mean_squared_error: 0.1385 - val_loss: 1.7896 - val_acc: 0.5000 - val_mean_squared_error: 0.1388\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.9763 - acc: 0.0000e+00 - mean_squared_error: 0.1486 - val_loss: 1.7898 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.1388\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.7427 - acc: 0.2000 - mean_squared_error: 0.1367 - val_loss: 1.7901 - val_acc: 0.0000e+00 - val_mean_squared_error: 0.1388\n"
     ]
    }
   ],
   "source": [
    "print(\"(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\")\n",
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.8))\n",
    "model.add(LSTM(64, dropout=0.8, recurrent_dropout=0.8))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', mean_squared_error])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_acc',patience=7, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained LSTM model will be saved (in 3 different files) to the folder defined by ```consts.CLASSIFIER```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = consts.CLASSIFIER\n",
    "\n",
    "if not os.path.isdir(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "picke_file_path = os.path.join(save_folder, \"tokenizer.pickle\")\n",
    "json_file_path = os.path.join(save_folder, \"model.json\")\n",
    "h5_file_path = os.path.join(save_folder, \"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the trained model (multiple relevant files)\n",
    "with open(picke_file_path, 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(json_file_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(h5_file_path)\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the trained model (continue here if you don't train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model (not needed if you train again)\n",
    "with open(picke_file_path, 'rb') as handle:\n",
    "    load_tokenizer = pickle.load(handle)\n",
    "\n",
    "json_file = open(json_file_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "load_model = model_from_json(loaded_model_json)\n",
    "\n",
    "load_model.load_weights(h5_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "fa53cfb9-75f7-47ee-b53d-b7f241ee082a",
    "_uuid": "a16c336b7eae3d72c7c92cf799702eacf70677c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n",
      "Test set\n",
      "  Loss: 1.785\n",
      "  Accuracy: 0.333\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a small amount of cells as example will probably give bad results.\n",
    "You can see our original results in [Classification.ipynb](https://github.com/TAU-DB/guided-ds/blob/master/Classification/Classification.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to tag all of our cells using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_existing_cells(cells_file_path):\n",
    "    df = pd.read_csv(cells_file_path, delimiter='\\t')\n",
    "    row_count = df.shape[0]\n",
    "    labels = ['Load', 'Prep', 'Train', 'Eval', 'Explore', 'Import']\n",
    "    outputs = pd.Series([]) # to contain output labels\n",
    "    \n",
    "    print(\"Generating labels...\")\n",
    "    for index, row in enumerate(df.iterrows()):\n",
    "#         if index % (row_count//100) == 0:\n",
    "#             print(str(1+(100*index//row_count)) + \"%\")\n",
    "        source = df.at[index, \"Source\"]\n",
    "        code = [source]\n",
    "        \n",
    "        try:\n",
    "            seq = tokenizer.texts_to_sequences(code)\n",
    "            padded = pad_sequences(seq, maxlen=max_len)\n",
    "            pred = model.predict(padded)\n",
    "            lbl = labels[np.argmax(pred)]\n",
    "        except:\n",
    "            lbl = \"\"\n",
    "        outputs[index] = lbl\n",
    "        \n",
    "    print(\"Adding labels to dataframe...\")\n",
    "    df['Label'] = outputs.values\n",
    "    print(\"Exporting to file...\")\n",
    "    df.to_csv(cells_file_path, sep = '\\t')\n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice**: we started with ```cells.tsv```, tagged it using snorkel (not inplace) to ```input.tsv```, now we tag the cells inside of the ```cells.tsv``` file (inplace) using the LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels...\n",
      "Adding labels to dataframe...\n",
      "Exporting to file...\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "tag_existing_cells(consts.CELLS_TSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkelnew)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
