{"cells":[{"metadata":{"trusted":true,"_uuid":"57b5639ff9a0c93ab0d94136bcdebda4cb0be0dd"},"cell_type":"code","source":"#Read train and depth.csv and put them in one dataframe df_Train\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport os\nimport time\nimport scipy.signal as sg\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras import layers\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\n\ntic = time.time()\n\nnum_train_images= 4000\nHeight = 101\nWidth = 101\n\nprint(os.listdir(\"../input\"))\ndf_train = pd.read_csv(\"../input/train.csv\")\nprint(\"\\n Train files shape is \", df_train.shape)\n\ndf_depths = pd.read_csv(\"../input/depths.csv\")\ndf_depths['z'] = df_depths['z'] / np.max(df_depths['z'])\nprint(\"\\nDepths files shape is \", df_depths.shape)\n\ndf_train = df_train.join(df_depths, lsuffix='idl', rsuffix='idr', how ='inner')\ndf_train.pop('ididr')\ndf_train.columns=['id', 'rle_mask','depth']\nprint(df_train.head())                      \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#2. Read train & mask images and add them up df_train \ndf_train['images'] = [np.array(Image.open(\"../input/train/images/{}.png\".format(idx)).convert('L'))\n                      for idx in df_train['id']]\nprint(\"Sample Image Shape is \", df_train['images'][0].shape)\nprint(\"No. of train images are \", len(df_train))\nprint(\"Sample pixel value of trian image before normalization is  \", df_train['images'][15][10,0])\n\ndf_train['images']=df_train['images'] / 255.\nprint(\"After normalization,  pixel value is \", df_train['images'][15][10,0])\n\ndf_train['masks'] = [np.array(Image.open(\"../input/train/masks/{}.png\".format(idx)).convert('L')) for \n                               idx in df_train['id']]\n\nprint(\"\\nSample Mask Shape is \", df_train['masks'][0].shape)\nprint(\"Sample pixel value before normalization of mask is  \", df_train['masks'][15][10,0])\nprint(\"No. of mask images are \", len(df_train))\ndf_train['masks']=df_train['masks']/255.\nprint(\"Sample pixel value after normalization of mask is  \", df_train['masks'][15][10,0])\nprint(\"train df columns are \", df_train.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9ee5f92dfeebc1fc1f425132dbbc4b78376a9c3"},"cell_type":"code","source":"\n#df_blank_masks = df_train[df_train['rle_mask'].isna()]\n#limit = 4\n#fig = plt.figure()\n#for i in range(1,limit+1):\n    #img = np.random.randint(10, size=(h,w))\n  #  plt.subplot(limit,2,i*2-1)#2,1)\n  #  plt.imshow(df_blank_masks['images'][6])\n  #  plt.subplot(limit,2,i*2)#2,1)\n  #  plt.imshow(df_blank_masks['masks'][6])\n#plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f04bf2b78523c42036ef2a54757ece68b0dd2cd1"},"cell_type":"code","source":"train_x = np.array(df_train['images'])\ntrain_x = np.concatenate(train_x,axis=0)\ntrain_x = np.reshape(train_x,(4000,101,101,1))\nprint(\"Train Shape = \",train_x.shape)\nprint(\"Sample Pixel VAlue\", train_x[0,1,0])\n#print(df_train['masks'][5][0])\n\ntrain_y = np.array(df_train['masks'])\ntrain_y = np.concatenate(train_y,axis=0)\ntrain_y = np.reshape(train_y,(4000,101,101,1))\n#train_y = train_y / train_y.max()\nprint(\"Mask Shape = \",train_y.shape)\ntrain_y = np.round(train_y)\nprint(\"Sample Pixel VAlue\", train_y[15,10,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27b2808f9cb447004ce8cce7e7dce42ee78d868f"},"cell_type":"code","source":"df_train['empty_mask'] = 1.5\ndf_train['empty_mask']= df_train['rle_mask'].where(df_train['rle_mask'].isnull(),0)\ndf_train['empty_mask'] = df_train['empty_mask'].fillna(1.)\ndf_train['empty_mask'].head(15)\ntrain_emptymask_y = np.array(df_train['empty_mask'])\ntrain_emptymask_y = train_emptymask_y.reshape(4000,1)\nprint(train_emptymask_y.shape)\n#print(train_emptymask_y[0:8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"654d4f6022fba370c994bcdbc145820cd857db13"},"cell_type":"code","source":"import random as rn\nimport tensorflow as tf\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(1234)\nrn.seed(1234)\n\n\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\ntf.set_random_seed(1234)\n\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)\n\n#print(depth_np.shape)\n#depth_np = np.zeros(shape = (num_train_images,12,12,1))\n#for i in range(num_train_images):\n#    depth_np[i] = np.full(shape=(12,12,1), fill_value=df_train['depth'].loc[i])  \n\n#df_train['depth_image'] = pd.Series(map(lambda x:np.full(shape=(50,50,1), \n#                                                         fill_value=x), df_train['depth']))\n\n#depth_np = np.array(df_train['depth_image'])\n#depth_np = np.concatenate(depth_np,axis=0)\n#depth_np = np.reshape(depth_np,(num_train_images,50,50,1))\n\ndepth_np_new = np.array(df_train['depth'])\nprint(\"depth\", depth_np_new[0:5])\nprint(\"depth shape \", depth_np_new.shape)\ndepth_np_new = depth_np_new.reshape((num_train_images,1))\n#depth_np = np.concatenate((depth_np, depth_np,depth_np, depth_np))\nprint(\"depth shape \", depth_np_new.shape)\n#print(a.shape)\n#depth_np= depth_np/depth_np.max()\n#print(a[2][2])\nprint(df_train.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ff048484f6d0f8b1f3515f2ff0722b0675263a8"},"cell_type":"code","source":"Activation1 = 'relu'\nActivation2 = 'tanh'\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n    \n    if activation == True:\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation(Activation1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    print(\"Applied residual block on size\")\n    #x = layers.Activation(Activation1)(blockInput)\n    x = convolution_block(blockInput, num_filters, (3,3), activation=True )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = layers.Add()([x, blockInput])\n    if batch_activate:\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation(Activation1)(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3ed1558bba128fc822ea3e8ead046f819a9a78d"},"cell_type":"code","source":"img_input = layers.Input(shape=(Height, Width,1), name = 'img_input')\ndepth_input_new = layers.Input(shape=(1,), name='depth_input_new')\n\nprint(\"101 -> 100\")\nx = layers.Conv2D(filters = 16, kernel_size= (2,2), padding='valid', activation=Activation1)(img_input)\nprint(x)\nx = layers.BatchNormalization()(x)\n      \nprint(\"100 -> 50\")\nx = layers.MaxPooling2D(pool_size=(2,2))(x)\n      \nx = layers.Conv2D(filters = 64, kernel_size= (2,2), padding='same', activation=Activation1)(x)\nprint(x)\nx = layers.BatchNormalization()(x)\n      \nprint(\"50 -> 25\")\nx = layers.MaxPooling2D(pool_size=(2,2))(x)\n      \nx = residual_block(x, num_filters = 64, batch_activate = True)\nx = layers.Dropout(0.25)(x)\n      \nprint(\"25->24\")\nx = layers.Conv2D(filters = 128, kernel_size= (2,2), padding='valid', activation=Activation1)(x)\nprint(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.25)(x)\n\nprint(\"24 -> 12\")\nx = layers.MaxPooling2D(pool_size=(2,2))(x)\nprint(x)\nx = residual_block(x, num_filters = 128)\nprint(x)\nx = layers.Dropout(0.25)(x)\n\n#x = layers.Concatenate()([x,depth_input_new])\n\nx = layers.Flatten()(x)\n\nprint(x)\n\n# Concatenate Depth\n#depth_x = layers.Dense(1)(depth_input_new)#(, activation=false)\n#depth_x = layers.Flatten()(depth_x)\n\nx= layers.Dense(256,activation = Activation1)(x)\nx = layers.Dropout(0.2)(x)\nx = layers.Concatenate()([x, depth_input_new])\nprint(x)\n\nx= layers.Dense(128,activation = Activation1)(x)\n\nprint(x)\n\nx= layers.Dense(64,activation = Activation1)(x)\nprint(x)\n\noutput = layers.Dense(1,activation = 'sigmoid')(x)\nprint(output)\n\nbmodel = Model([img_input,depth_input_new], output)\nbmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e731622306d8e0149444c16c25697f6c3bd3c79e"},"cell_type":"code","source":"Batch_size = 128\ngen = ImageDataGenerator(horizontal_flip = True,\n                         vertical_flip = True)\n\ndef gen_flow_for_two_inputs(X1, X2, y):\n    genX1 = gen.flow(X1,y,  batch_size=Batch_size,seed = 1234, shuffle=True)\n    genX2 = gen.flow(X1,X2, batch_size=Batch_size,seed = 1234, shuffle=True)\n    while True:\n            X1i = genX1.next()\n            X2i = genX2.next()\n            #Assert arrays are equal - this was for peace of mind, but slows down training\n            #np.testing.assert_array_equal(X1i[0],X2i[0])\n            yield [X1i[0], X2i[1]], X1i[1]\n\n\ndef gen_flow_for_two_inputs2(X, I, Y):\n     # suffled indices    \n    idx = np.random.permutation(X.shape[0])\n    print(\"Shape[0] \",X.shape[0])\n    print(\"permutation \",idx)\n    print(\"length \",len(idx))\n    idx0 = 0\n    for batch in gen.flow( X[idx], Y[idx], batch_size=Batch_size, shuffle=False):\n        idx1 = idx0 + batch[0].shape[0]\n        print(\"Before \", idx0, \" \", idx1)\n        yield [batch[0], I[ idx[ idx0:idx1 ] ]], batch[1]\n        idx0 = idx1\n        if idx1 >= X.shape[0]:\n            break\n        print(\"After \", idx0, \" \", idx1)\n\n\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1aec488dbea0fa42005ada1f8e3275db3c7e5a0"},"cell_type":"code","source":"df_test = df_depths[~df_depths['id'].isin(df_train['id'])]\n\nprint(\"Length of df_test is \", len(df_test))\ndf_test = df_test.reset_index()\ndf_test.pop('index')\nprint(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edda69fec922860ddccf5fb872c09731a88ac128"},"cell_type":"code","source":"df_test['images'] = [np.array(Image.open(\"../input/test/images/{}.png\".format(idx)).convert('L')) for \n                               idx in df_test['id']]\n\nprint(df_test.head())\nprint(\"Sample Image Shape is \", df_test['images'][10].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a896a8303dde1bc46b94cd126681a008f3b281b6"},"cell_type":"code","source":"\n#df_test['images'] = pd.Series(map(lambda x: np.delete(x,np.s_[1:],2), df_test['images']))\n#print(\"After optimization,  Image Shape is \", df_test['images'][0].shape)\nprint(\"No. of test images are \", len(df_test))\nprint(\"Before normalization,  pixel value is \", df_test['images'][10][2,0])\ndf_test['images']=df_test['images'] / 255\nprint(\"After normalization,  pixel value is \", df_test['images'][10][2,0])\n\nprint(df_test.columns)\n\ntest_x = np.array(df_test['images'])\ntest_x = np.concatenate(test_x,axis=0)\ntest_x = np.reshape(test_x,(18000,101,101,1))\nprint(\"Test Shape = \",test_x.shape)\nprint(\"Sample Pixel VAlue\", test_x[10,2,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7bec6a3aab8f6f5ad3aec2ae6984816ef22265a"},"cell_type":"code","source":"\n#df_test['depth_image'] = pd.Series(map(lambda x:np.full(shape=(50,50,1), \n#                                                         fill_value=x), df_test['z']))\n\n#depth_test_np = np.array(df_test['depth_image'])\n#depth_test_np = np.concatenate(depth_test_np,axis=0)\n#depth_test_np = np.reshape(depth_test_np,(18000,50,50,1))\ndepth_test_np_new = np.array(df_test['z'])\n\n#print(a.shape)\n#depth_np= depth_np/depth_np.max()\n#print(a[2][2])\nprint(df_test.columns)\ndepth_test_np_new = np.reshape(depth_test_np_new,(18000,1))\nprint(depth_test_np_new.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6226d2d9e8f634232f932e8a3a50b68371a01ac4"},"cell_type":"code","source":"def recall1(y_true, y_pred):\n    \"\"\"Recall metric.\n    Only computes a batch-wise average of recall.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    #true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    #true_positives = K.sum(y_true * y_pred)\n    true_positives = np.sum(y_true * y_pred)\n    #possible_positives = K.sum(y_true)\n    possible_positives = np.sum(y_true)\n    recall = true_positives / (possible_positives + 0.00001)\n    return recall\n\ndef precision1(y_true, y_pred):\n    \"\"\"Precision metric.\n    Only computes a batch-wise average of precision.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    #true_positives = K.sum(y_true * y_pred)\n    #predicted_positives = K.sum(y_pred)\n    true_positives = np.sum(y_true * y_pred)\n    predicted_positives = np.sum(y_pred)\n    precision = true_positives / (predicted_positives + 0.00001)\n    return precision\n    \ndef f1(y_true, y_pred):\n    precision = precision1(y_true, y_pred)\n    recall = recall1(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+0.00001))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7327b5bc8fa3c1e44a578902fc971c211f05a7d3"},"cell_type":"code","source":"epochs=5\nBatch_size = 64\nx_train, x_val, depth_train, depth_val,  y_train, y_val = train_test_split(train_x, depth_np_new,\n                                                train_emptymask_y, test_size=0.25, random_state=42)\n\nreduce_lr = ReduceLROnPlateau(monitor='acc', mode = 'max',factor=0.5, patience=5, \n                              min_lr=0.0001, verbose=1)\n\nbmodel = Model([img_input,depth_input_new], output)\n    #bmodel = Model(img_input, output)\nbmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\ngen_flow = gen_flow_for_two_inputs(x_train, depth_train, y_train)\n\nbmodel.fit_generator(gen_flow,validation_data= ([x_val, depth_val],\n                                                      y_val), \n                         steps_per_epoch=len(x_train) / Batch_size, \n                         epochs=epochs, callbacks = [reduce_lr], verbose = 1 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"130a681366c3aeb28f5750f04a51c1d0a4810087"},"cell_type":"code","source":"pred_y_val = bmodel.predict([x_val, depth_val])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d02c71aabc591c83567246f6d5cd065bc95d037"},"cell_type":"code","source":"#val_pred_y = []#np.zeros(shape=(n_splits, int(num_train_images/n_splits)+1, 1))\n#y_test_pred = np.zeros(shape=(n_splits, 18000,1))\n#train_y = np.append(train_y, [np.fliplr(x) for x in train_y], axis=0)\n#y_test_pred_lr = np.append(y_test_pred_lr, [np.fliplr(x) for x in y_test_pred_lr], axis=0)\n#y_test_pred_up = [np.fliplr(x) for x in y_test_pred_lr], axis=0)\n#y_test_pred_lr = np.zeros(shape=(n_splits, 18000,1))\n#y_test_pred_up = np.zeros(shape=(n_splits, 18000,1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"282371a1e6c555ffbcbf00f2908817df3d47cb01"},"cell_type":"code","source":"n_splits=5\nepochs=50\nbase_name = 'binary_kfold'\n#x_train, x_val, y_train, y_val = train_test_split(train_x, \n #                                               train_emptymask_y, test_size=0.33, random_state=42)\n#early_stopping = EarlyStopping(monitor='acc', patience=4)\n#bmodel.fit(x_train,y_train,validation_data=[x_val, y_val], epochs=50,verbose=1, \n#          batch_size=96, callbacks = [early_stopping])\n\nkf = StratifiedKFold(n_splits=n_splits,random_state=1234, shuffle=True)\n\npred=[]\nmodels = []\nval_indexes=[]\n\nval_pred_y = []#np.zeros(shape=(n_splits, int(num_train_images/n_splits)+1, 1))\ny_test_pred = np.zeros(shape=(n_splits, 18000,1))\ny_test_pred_lr = np.zeros(shape=(n_splits, 18000,1))\ny_test_pred_up = np.zeros(shape=(n_splits, 18000,1))\n\n# Finally create generator\ni=0\nfor train_index, val_index in kf.split(train_x, train_emptymask_y):\n    print(i)\n    model_name = base_name + str(i) + 'h5'\n    #model_checkpoint = ModelCheckpoint(model_name, monitor='acc', \n    #                               mode = 'max', save_best_only=True, verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor='acc', mode = 'max',factor=0.5, patience=5, \n                              min_lr=0.0001, verbose=1)\n\n    bmodel = Model([img_input,depth_input_new], output)\n    #bmodel = Model(img_input, output)\n    bmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    gen_flow = gen_flow_for_two_inputs(train_x[train_index], depth_np_new[train_index]\n                                       ,train_emptymask_y[train_index])\n    \n    #bmodel.fit_generator(x = train_x[train_index] ,y=train_emptymask_y[train_index],\n    #           batch_size=128,epochs=epochs, verbose = 1,callbacks = [model_checkpoint,reduce_lr],\n    #          validation_data = [train_x[val_index],train_emptymask_y[val_index]])\n               \n    bmodel.fit_generator(gen_flow,validation_data= ([train_x[val_index], depth_np_new[val_index]],\n                                                      train_emptymask_y[val_index]), \n                         steps_per_epoch=len(train_x[train_index]) / Batch_size, \n                         epochs=epochs, callbacks = [reduce_lr], verbose = 1 )\n    \n    #Predict on Cross Validation Set:\n    val_pred_y.append(bmodel.predict([train_x[val_index],  depth_np_new[val_index]]))\n    val_indexes.append(val_index)\n    \n    #Predict on Test  Images Set:\n    #print(y_test_pred.shape)\n    #print(test_x.shape)\n    #print(depth_test_np_new.shape)\n    y_test_pred[i,:,:] =  bmodel.predict([test_x, depth_test_np_new])\n    y_test_pred_lr[i,:,:] =  bmodel.predict([[np.fliplr(x) for x in test_x],depth_test_np_new])\n    #y_test_pred_up[i,:,:] =  bmodel.predict([np.flipud(test_x),depth_test_np_new])\n        \n    pred.append(bmodel.evaluate([train_x[val_index], depth_np_new[val_index]], \n                                train_emptymask_y[val_index]))\n    models.append(bmodel)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81756020c1b77ab6b6d59ea4df067e1c4350b997"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig=plt.figure(figsize=(16, 8))\ncolumns = 1\nrows = 4\n%matplotlib inline\nfig, axs = plt.subplots(rows, columns)\nindex = np.random.randint(0,len(x_val),rows)\n#print(y_pred[0,:,:,0].shape)\n#index = [206, 831, 524, 676]\nval_x_pred_new = np.round(pred_y_val-0.25)#-0.05)\n#val_x_pred_new = np.round(val_x_pred-0.25)#-0.05)\nprint(index)\n#plt.imshow(y_pred[100,:,:,0])\n#for i in range(4):\n    #img = np.random.randint(10, size=(h,w))\n    #fig.add_subplot(rows, columns, i)\n        \n    #axs[i, 0].imshow(x_val[index[i],:,:,0])#, cmap=cmap)\n    #print(\"Actual Image Classification at {} is {}\".format(index[i], y_val[index[i]]))\n    #axs[i,1].imshow(y_val[index[i],:,:,0])#, cmap=cmap)\n    #print(\"Image Prediction at {} is {}\".format(index[i], val_x_pred_new[index[i]]))\n    #axs[i,2].imshow(val_x_pred_new[index[i],:,:,0])#, cmap=cmap)\n    #plt.imshow(y_pred_new[x[0],:,:,0])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bba5ab0a569c745398b57e542d61cf58cbb48af"},"cell_type":"code","source":"kf.get_n_splits(train_x, train_emptymask_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46440a7951dd205fafdf3b7d99c45e1b245ff6c4"},"cell_type":"code","source":"print(pred)\nprint(\"Mean Val Loss and Accuracy are \", np.mean(pred, axis=0))\nprint(\"Last Val Loss and Accuracy are \", pred[-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cf0930a118af91430ac79698548ec28cb97b300"},"cell_type":"code","source":"print(len(models))\n#print(train_pred.shape)\nfor i in range(n_splits):\n    print(np.mean(val_pred_y[i]))\n    print(val_pred_y[i].shape)\n    \n\n#val_mean = np.mean(val_pred, axis =0)\n#val_pred_y_mean = np.mean(val_pred_y, axis =0)\n#print(val_mean.shape)\n#print(val_pred_y_mean.shape)\n#val_pred_y = np.array(val_pred_y)\n#print(val_pred_y.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9accbb2798e3e1d7a366ef0744cd772e4aa3b097","collapsed":true},"cell_type":"code","source":"\"\"\"i =0\np=[]\nf=[]\nr=[]\npf=[]\nrf=[]\nff=[]\n\nfor z in np.arange(0.25,0.8,0.05):\n    p.append(precision1(train_emptymask_y[val_indexes[0]],np.round(val_pred_y[0] - (z-0.5))))\n    r.append(recall1(train_emptymask_y[val_indexes[0]],np.round(val_pred_y[0] - (z-0.5))))\n    f.append(f1(train_emptymask_y[val_indexes[0]],np.round(val_pred_y[0] - (z-0.5))))\n    \n    pf.append(precision1(train_emptymask_y[val_indexes[-1]],np.round(val_pred_y[-1] - (z-0.5))))\n    rf.append(recall1(train_emptymask_y[val_indexes[-1]],np.round(val_pred_y[-1] - (z-0.5))))\n    ff.append(f1(train_emptymask_y[val_indexes[-1]],np.round(val_pred_y[-1] - (z-0.5))))\n%matplotlib inline\n\nfig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(20, 10))\n\n\nax1.plot(np.arange(0.25,0.8,0.05),p,'blue',  label='Mean Precision')\nax1.plot(np.arange(0.25,0.8,0.05),r,'red',  label='Mean Recall')\nax1.plot(np.arange(0.25,0.8,0.05),f,'black',  label='Mean F1')\n#plt.plot(np.arange(0.25,0.8,0.05))\n\n\nax2.plot(np.arange(0.25,0.8,0.05),pf,'blue',  label='Final Precision')\nax2.plot(np.arange(0.25,0.8,0.05),rf,'red',  label='Final Recall')\nax2.plot(np.arange(0.25,0.8,0.05),ff,'black',  label='Final F1')\n#plt.ylabel('S')\nax1.grid(True)\nax1.legend()\n#plt.title(\"First Model Prediction\")\nax2.grid(True)\nax2.legend()\n#plt.xtitle(\"Last Model Prediction\")\nplt.xlabel(\"Threshold\")\n#plt.xlabel('Last Model')\nplt.show()   \n\"\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e19e7fcd6462ada08ede2f28d50f31c5dd0e011f"},"cell_type":"code","source":"print(\"First test predicdtion shape without modification \", y_test_pred.shape)\ny_test_pred_mean = np.mean([y_test_pred, y_test_pred_lr], axis=0)\nprint(\"sum of all predicdtions \", y_test_pred_mean.sum())\nprint(\"\\n sum of first prediction \\n\")\nprint(y_test_pred[0].sum())\nprint(y_test_pred_lr[0].sum())\n#print(y_test_pred_up[0].sum())\n\nprint(\"\\n sum of last prediction \\n\")\nprint(y_test_pred[-1].sum())\nprint(y_test_pred_lr[-1].sum())\n#print(y_test_pred_up[-1].sum())\n\ny_test_pred_mean_again = np.mean(y_test_pred_mean, axis=0)\nprint(\"Mean of all predictions shape \", y_test_pred_mean_again.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62f97d7da27ac2cadae2254e8855f425e34547e0"},"cell_type":"code","source":"y_test_pred_mean_df = pd.DataFrame(data = {'id':df_test['id'], 'mask':y_test_pred_mean_again[:,0]})\ny_test_pred_mean_df.to_csv(\"binary_output_mean_test.csv\", index=False)\nprint(y_test_pred_mean_df.head())\nprint(\"Test mean prediction written\")\n#print(y_test_pred_mean_again[:,0].shape)\n\ny_test_pred_last_df = pd.DataFrame(data = {'id':df_test['id'], 'mask':list(y_test_pred_mean[-1,:,:])})\nprint(y_test_pred_last_df.head())\ny_test_pred_last_df.to_csv(\"binary_output_last_test.csv\", index=False)\nprint(\"Test last model prediction written\")\n\n#true_y_df = pd.DataFrame(data = {'id':df_test['id'], 'mask':train_cleanmask_y})\n#true_y_df.to_csv(\"true_y.csv\", index=False)\n#df_train[['id','empty_mask']].to_csv(\"true_y_train.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceee0e217bd7d0612ea4bebd0a9611d08588d44c"},"cell_type":"code","source":"tac = time.time()\nprint(tac-tic)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9edc81989fb1409691110f953316320ee779adbd"},"cell_type":"code","source":"#output = pd.DataFrame( data = {'id': df_test['id'], 'rle_mask' : new_y_pred} )\n#output.to_csv(\"output_6.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"be9fc5b959ea094e10942b8e5911a8b0bb0afaac"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}