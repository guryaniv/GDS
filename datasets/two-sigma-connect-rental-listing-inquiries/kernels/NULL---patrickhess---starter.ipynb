{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1e27919f-b9dd-6cc8-e08a-17b527e8e5c8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8bb54bda-137c-4a7d-727c-70bcdf42a9d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import hashlib\n",
        "import random\n",
        "from math import exp\n",
        "import xgboost as xgb\n",
        "from sklearn.decomposition import PCA\n",
        "from math import sin, cos, sqrt, atan2, radians\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import Birch\n",
        "\n",
        "\n",
        "def dist(list_one, list_two):\n",
        "    # approximate radius of earth in km\n",
        "    R = 6373.0\n",
        "\n",
        "    lat1 = radians(list_one['latitude'])\n",
        "    lon1 = radians(list_one['longitude'])\n",
        "    lat2 = radians(list_two['latitude'])\n",
        "    lon2 = radians(list_two['longitude'])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "    distance = R * c\n",
        "    \n",
        "    return distance\n",
        "\n",
        "\n",
        "\n",
        "def cluster_latlon(n_clusters, data):  \n",
        "    #split the data between \"around NYC\" and \"other locations\" basically our first two clusters \n",
        "    data_c=data[(data.longitude>-74.05)&(data.longitude<-73.75)&(data.latitude>40.4)&(data.latitude<40.9)]\n",
        "    data_e=data[~((data.longitude>-74.05)&(data.longitude<-73.75)&(data.latitude>40.4)&(data.latitude<40.9))]\n",
        "    #put it in matrix form\n",
        "    coords=data_c.as_matrix(columns=['latitude', \"longitude\"])\n",
        "    \n",
        "    brc = Birch(branching_factor=100, n_clusters=n_clusters, threshold=0.01,compute_labels=True)    \n",
        "    #brc2 = Birch(branching_factor=100, n_clusters=n_clusters / 2, threshold=0.005,compute_labels=True)\n",
        "    #brc4 = Birch(branching_factor=100, n_clusters=n_clusters / 4, threshold=0.005,compute_labels=True)\n",
        "    brc.fit(coords)\n",
        "    clusters=brc.predict(coords)\n",
        "    #print clusters\n",
        "    data_c[\"cluster_\"+str(n_clusters)]=clusters\n",
        "    data_e[\"cluster_\"+str(n_clusters)]=-1 #assign cluster label -1 for the non NYC listings \n",
        "    #brc2.fit(coords)\n",
        "    #clusters=brc2.predict(coords)\n",
        "    #print clusters\n",
        "    #data_c[\"cluster_\"+str(n_clusters/2)]=clusters\n",
        "    #data_e[\"cluster_\"+str(n_clusters/2)]=-1 #assign cluster label -1 for the non NYC listings \n",
        "    #brc4.fit(coords)\n",
        "    #clusters=brc4.predict(coords)\n",
        "    #print clusters\n",
        "    #data_c[\"cluster_\"+str(n_clusters/4)]=clusters\n",
        "    #data_e[\"cluster_\"+str(n_clusters/4)]=-1 #assign cluster label -1 for the non NYC listings \n",
        "\n",
        "\n",
        "    data=pd.concat([data_c,data_e])\n",
        "    #plt.scatter(data_c[\"longitude\"], data_c[\"latitude\"], c=data_c[\"cluster_\"+str(n_clusters)], s=10, linewidth=0.1)\n",
        "    #plt.title(str(n_clusters)+\" Neighbourhoods from clustering\")\n",
        "    #plt.show()\n",
        "    return data \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(train_df, test_df):\n",
        "    \"\"\"Just a generic preprocessing function, feel free to substitute it with your custom function\"\"\"\n",
        "    # encode target variable\n",
        "    train_df['interest_level'] = train_df['interest_level'].apply(lambda x: {'high': 2, 'medium': 1, 'low': 0}[x])   \n",
        "    index=list(range(train_df.shape[0]))\n",
        "    random.shuffle(index)\n",
        "    manager_score = [np.nan]*len(train_df)\n",
        "    manager_low = [np.nan]*len(train_df)\n",
        "    manager_medium = [np.nan]*len(train_df)\n",
        "    manager_high = [np.nan]*len(train_df)\n",
        "    manager_low_pct = [np.nan]*len(train_df)\n",
        "    manager_medium_pct = [np.nan]*len(train_df)\n",
        "    manager_high_pct = [np.nan]*len(train_df)    \n",
        "    building_score = [np.nan]*len(train_df)\n",
        "    building_low = [np.nan]*len(train_df)\n",
        "    building_medium = [np.nan]*len(train_df)\n",
        "    building_high = [np.nan]*len(train_df)\n",
        "    building_low_pct = [np.nan]*len(train_df)\n",
        "    building_medium_pct = [np.nan]*len(train_df)\n",
        "    building_high_pct = [np.nan]*len(train_df)\n",
        "    pct_low =  [np.nan]*len(train_df)\n",
        "    pct_medium =  [np.nan]*len(train_df)\n",
        "    pct_high =  [np.nan]*len(train_df)\n",
        "    neigh_count = [np.nan]*len(train_df)\n",
        "    for j in range(5):\n",
        "        print j\n",
        "        manager_sum = {}\n",
        "        manager_high_tmp = {}\n",
        "        manager_medium_tmp = {}\n",
        "        manager_low_tmp = {}\n",
        "        manager_count = {}        \n",
        "        building_sum = {}\n",
        "        building_high_tmp = {}\n",
        "        building_medium_tmp = {}\n",
        "        building_low_tmp = {}\n",
        "        building_count = {}\n",
        "        high_total = 0.0\n",
        "        medium_total = 0.0\n",
        "        low_total = 0.0\n",
        "        manager_ct = 0.0 \n",
        "        building_ct = 0.0\n",
        "        sm = 0.0\n",
        "        ct = 0.0        \n",
        "        test_ind = index[int((j*train_df.shape[0])/5):int(((j+1)*train_df.shape[0])/5)]\n",
        "        train_ind = list(set(index).difference(test_ind))\n",
        "        print 'train ind'\n",
        "        for i in train_ind:\n",
        "            x = train_df.iloc[i]\n",
        "            if x['manager_id'] not in manager_sum:\n",
        "                manager_sum[x['manager_id']] = 0.0\n",
        "                manager_count[x['manager_id']] = 0.0\n",
        "                manager_ct += 1\n",
        "            if x['building_id'] not in building_sum:\n",
        "                building_sum[x['building_id']] = 0.0\n",
        "                building_count[x['building_id']] = 0.0\n",
        "                building_ct += 1\n",
        "            building_sum[x['building_id']] += x['interest_level']\n",
        "            manager_sum[x['manager_id']] += x['interest_level']\n",
        "            if  x['interest_level'] == 0.0:\n",
        "                if x['manager_id'] not in manager_low_tmp:\n",
        "                    manager_low_tmp[x['manager_id']] = 0.0\n",
        "                if x['building_id'] not in building_low_tmp:\n",
        "                    building_low_tmp[x['building_id']] = 0.0\n",
        "                manager_low_tmp[x['manager_id']] += 1\n",
        "                building_low_tmp[x['building_id']] += 1\n",
        "                low_total += 1.0\n",
        "            if  x['interest_level'] == 1:\n",
        "                if x['manager_id'] not in manager_medium_tmp:\n",
        "                    manager_medium_tmp[x['manager_id']] = 0.0\n",
        "                if x['building_id'] not in building_medium_tmp:\n",
        "                    building_medium_tmp[x['building_id']] = 0.0\n",
        "                manager_medium_tmp[x['manager_id']] += 1\n",
        "                building_medium_tmp[x['building_id']] += 1\n",
        "                medium_total += 1.0\n",
        "            if  x['interest_level'] == 2:\n",
        "                if x['manager_id'] not in manager_high_tmp:\n",
        "                    manager_high_tmp[x['manager_id']] = 0.0\n",
        "                if x['building_id'] not in building_high_tmp:\n",
        "                    building_high_tmp[x['building_id']] = 0.0\n",
        "                manager_high_tmp[x['manager_id']] += 1\n",
        "                building_high_tmp[x['building_id']] += 1\n",
        "                high_total += 1.0\n",
        "            manager_count[x['manager_id']] += 1.0\n",
        "            building_count[x['building_id']] += 1\n",
        "            sm += x['interest_level']        \n",
        "            ct += 1.0\n",
        "        avg = sm / ct        \n",
        "        neigh_low = {}\n",
        "        neigh_medium = {}\n",
        "        neigh_high = {}\n",
        "        for i in train_ind:\n",
        "            x = train_df.iloc[i]\n",
        "            round_lat = round(x['latitude'], 2)\n",
        "            round_long = round(x['longitude'], 2)\n",
        "            hsh = str(round_lat) + \"#\" + str(round_long)\n",
        "            if x['interest_level'] == 0.0:\n",
        "                if hsh not in neigh_low:\n",
        "                    neigh_low[hsh] = 0.0\n",
        "                neigh_low[hsh] += 1\n",
        "            if x['interest_level'] == 1:\n",
        "                if hsh not in neigh_medium:\n",
        "                    neigh_medium[hsh] = 0.0\n",
        "                neigh_medium[hsh] += 1\n",
        "            if x['interest_level'] == 2:\n",
        "                if hsh not in neigh_high:\n",
        "                    neigh_high[hsh] = 0.0\n",
        "                neigh_high[hsh] += 1        \n",
        "        neigh_pct_low_tmp = {}\n",
        "        neigh_pct_medium_tmp = {}\n",
        "        neigh_pct_high_tmp = {}\n",
        "        neigh_count_tmp = {} \n",
        "        for i in train_ind:\n",
        "            x = train_df.iloc[i]\n",
        "            round_lat = round(x['latitude'], 2)\n",
        "            round_long = round(x['longitude'], 2)\n",
        "            lat_down = round_lat - 0.01\n",
        "            lat_up = round_lat + 0.01\n",
        "            long_down = round_long - 0.01\n",
        "            long_up = round_long + 0.01            \n",
        "            low_sum = 0.0    \n",
        "            md_sum = 0.0\n",
        "            high_sum = 0.0            \n",
        "            pos = [str(lat_down) + \"#\" + str(long_down),  \n",
        "                   str(round_lat) + \"#\" + str(long_down),  \n",
        "                   str(lat_up) + \"#\" + str(long_down), \n",
        "                   str(lat_down) + \"#\" + str(round_long),\n",
        "                   str(round_lat)  + \"#\" + str(round_long),\n",
        "                   str(lat_up) + \"#\" + str(round_long),\n",
        "                   str(lat_down)  + \"#\" + str(long_up), \n",
        "                   str(round_lat)  + \"#\" + str(long_up),\n",
        "                   str(lat_up)+ \"#\" + str(long_up)]\n",
        "            for ps in pos:\n",
        "                if ps in neigh_low:    \n",
        "                    low_sum += neigh_low[ps]\n",
        "                if ps in neigh_medium:\n",
        "                    md_sum += neigh_medium[ps]\n",
        "                if ps in neigh_high:\n",
        "                    high_sum += neigh_high[ps]\n",
        "            hsh =  str(round_lat)  + \"#\" + str(round_long)\n",
        "            neigh_pct_low_tmp[hsh] = low_sum / (low_sum + md_sum + high_sum + 1.0)\n",
        "            neigh_pct_medium_tmp[hsh] = md_sum / (low_sum + md_sum + high_sum + 1.0)\n",
        "            neigh_pct_high_tmp[hsh] = high_sum / (low_sum + md_sum + high_sum + 1.0) \n",
        "            neigh_count_tmp[hsh] = low_sum + md_sum + high_sum                \n",
        "        for i in test_ind:\n",
        "            x = train_df.iloc[i]\n",
        "            manager_id = x['manager_id']      \n",
        "            building_id = x['building_id']   \n",
        "            round_lat = round(x['latitude'], 2)\n",
        "            round_long = round(x['longitude'], 2)\n",
        "            hsh =  str(round_lat)  + \"#\" + str(round_long)\n",
        "            pct_low[i] = neigh_pct_low_tmp[hsh] if hsh in neigh_pct_low_tmp  else 0.6\n",
        "            pct_medium[i] = neigh_pct_medium_tmp[hsh] if hsh in neigh_pct_medium_tmp else 0.3\n",
        "            pct_high[i] =   neigh_pct_high_tmp[hsh] if hsh in neigh_pct_high_tmp else 0.1\n",
        "            manager_score[i] = manager_sum[manager_id] / manager_count[manager_id] if manager_id in manager_count else avg\n",
        "            manager_low[i] = manager_low_tmp[manager_id]  if manager_id in manager_low_tmp else low_total / manager_ct\n",
        "            manager_medium[i] = manager_medium_tmp[manager_id] if manager_id in manager_medium_tmp else medium_total / manager_ct\n",
        "            manager_high[i] = manager_high_tmp[manager_id] if manager_id in manager_high_tmp  else high_total / manager_ct\n",
        "            manager_low_pct[i] = manager_low_tmp[manager_id] / manager_count[manager_id]  if manager_id in manager_low_tmp else low_total / ct\n",
        "            manager_medium_pct[i] = manager_medium_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_medium_tmp else medium_total / ct            \n",
        "            manager_high_pct[i] = manager_high_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_high_tmp else high_total / ct   \n",
        "            neigh_count[i] =  neigh_count_tmp[hsh] if hsh in neigh_count_tmp else 0 \n",
        "            building_score[i] = building_sum[building_id] / building_count[building_id] if building_id in building_count else avg\n",
        "            building_low[i] = building_low_tmp[building_id] if building_id in building_low_tmp else low_total / building_ct\n",
        "            building_medium[i] = building_medium_tmp[building_id] if building_id in building_medium_tmp else medium_total / building_ct\n",
        "            building_high[i] = building_high_tmp[building_id] if building_id in building_high_tmp else high_total / building_ct\n",
        "            building_low_pct[i] = building_low_tmp[building_id] / building_count[building_id] if building_id in building_low_tmp else 0.6\n",
        "            building_medium_pct[i] = building_medium_tmp[building_id] / building_count[building_id] if building_id in building_medium_tmp else 0.3\n",
        "            building_high_pct[i] = building_high_tmp[building_id] / building_count[building_id] if building_id in building_high_tmp else 0.1\n",
        "    train_df['manager_score'] = manager_score \n",
        "    #train_df['manager_low'] = manager_low \n",
        "    #train_df['manager_medium'] = manager_medium\n",
        "    #train_df['manager_high'] =  manager_high\n",
        "    train_df['manager_low_pct'] = manager_low_pct\n",
        "    train_df['manager_medium_pct'] = manager_medium_pct\n",
        "    train_df['manager_high_pct'] = manager_high_pct\n",
        "    train_df['neigh_low_pct'] = pct_low\n",
        "    train_df['neigh_medium_pct'] = pct_medium\n",
        "    train_df['neigh_high_pct'] = pct_high\n",
        "    train_df['neigh_low_ct'] = np.array(pct_low) * np.array(neigh_count)\n",
        "    train_df['neigh_medium_ct'] = np.array(pct_medium) * np.array(neigh_count)\n",
        "    train_df['neigh_high_ct'] = np.array(pct_high) * np.array(neigh_count)\n",
        "    train_df['building_score'] = building_score \n",
        "    #train_df['building_low'] = building_low \n",
        "    # train_df['building_medium'] = building_medium\n",
        "    #train_df['building_high'] =  building_high\n",
        "    train_df['building_low_pct'] = building_low_pct\n",
        "    train_df['building_medium_pct'] = building_medium_pct\n",
        "    train_df['building_high_pct'] = building_high_pct\n",
        "    train_index = train_df.index\n",
        "    test_index = test_df.index   \n",
        "    manager_score = []\n",
        "    manager_low = []\n",
        "    manager_medium = []\n",
        "    manager_high = []\n",
        "    manager_low_pct = []\n",
        "    manager_medium_pct = []\n",
        "    manager_high_pct = []        \n",
        "    building_score = []\n",
        "    building_low = []\n",
        "    building_medium = []\n",
        "    building_high = []\n",
        "    building_low_pct = []\n",
        "    building_medium_pct = []\n",
        "    building_high_pct = []\n",
        "    pct_low =  []\n",
        "    pct_medium =  []\n",
        "    pct_high =  []\n",
        "    neigh_count = []\n",
        "    manager_sum = {}\n",
        "    manager_high_tmp = {}\n",
        "    manager_medium_tmp = {}\n",
        "    manager_low_tmp = {}\n",
        "    manager_count = {}\n",
        "    building_sum = {}\n",
        "    building_count = {}            \n",
        "    building_sum = {}\n",
        "    building_high_tmp = {}\n",
        "    building_medium_tmp = {}\n",
        "    building_low_tmp = {}\n",
        "    building_count = {}\n",
        "    high_total = 0.0\n",
        "    medium_total = 0.0\n",
        "    low_total = 0.0\n",
        "    manager_ct = 0.0 \n",
        "    sm = 0.0\n",
        "    ct = 0.0        \n",
        "    print 'cv statistics computed'\n",
        "    for i in range(train_df.shape[0]):\n",
        "        x = train_df.iloc[i]\n",
        "        if x['manager_id'] not in manager_sum:\n",
        "            manager_sum[x['manager_id']] = 0.0\n",
        "            manager_count[x['manager_id']] = 0.0\n",
        "            manager_ct += 1\n",
        "        if x['building_id'] not in building_sum:\n",
        "            building_sum[x['building_id']] = 0.0\n",
        "            building_count[x['building_id']] = 0.0\n",
        "            building_ct += 1\n",
        "        building_sum[x['building_id']] += x['interest_level']\n",
        "        manager_sum[x['manager_id']] += x['interest_level']\n",
        "        if  x['interest_level'] == 0.0:\n",
        "            if x['manager_id'] not in manager_low_tmp:\n",
        "                manager_low_tmp[x['manager_id']] = 0.0\n",
        "            if x['building_id'] not in building_low_tmp:\n",
        "                building_low_tmp[x['building_id']] = 0.0\n",
        "            manager_low_tmp[x['manager_id']] += 1\n",
        "            building_low_tmp[x['building_id']] += 1\n",
        "            low_total += 1.0\n",
        "        if  x['interest_level'] == 1:\n",
        "            if x['manager_id'] not in manager_medium_tmp:\n",
        "                manager_medium_tmp[x['manager_id']] = 0.0\n",
        "            if x['building_id'] not in building_medium_tmp:\n",
        "                building_medium_tmp[x['building_id']] = 0.0\n",
        "            manager_medium_tmp[x['manager_id']] += 1\n",
        "            building_medium_tmp[x['building_id']] += 1\n",
        "            medium_total += 1.0\n",
        "        if  x['interest_level'] == 2:\n",
        "            if x['manager_id'] not in manager_high_tmp:\n",
        "                manager_high_tmp[x['manager_id']] = 0.0\n",
        "            if x['building_id'] not in building_high_tmp:\n",
        "                building_high_tmp[x['building_id']] = 0.0\n",
        "            manager_high_tmp[x['manager_id']] += 1\n",
        "            building_high_tmp[x['building_id']] += 1\n",
        "            high_total += 1.0\n",
        "        manager_count[x['manager_id']] += 1.0\n",
        "        building_count[x['building_id']] += 1\n",
        "        sm += x['interest_level']        \n",
        "        ct += 1.0\n",
        "    neigh_low = {}\n",
        "    neigh_medium = {}\n",
        "    neigh_high = {}\n",
        "    for i in train_ind:\n",
        "        x = train_df.iloc[i]\n",
        "        round_lat = round(x['latitude'], 2)\n",
        "        round_long = round(x['longitude'], 2)\n",
        "        hsh = str(round_lat) + \"#\" + str(round_long)\n",
        "        if x['interest_level'] == 0.0:\n",
        "            if hsh not in neigh_low:\n",
        "                neigh_low[hsh] = 0.0\n",
        "            neigh_low[hsh] += 1\n",
        "        if x['interest_level'] == 1:\n",
        "            if hsh not in neigh_medium:\n",
        "                neigh_medium[hsh] = 0.0\n",
        "            neigh_medium[hsh] += 1\n",
        "        if x['interest_level'] == 2:\n",
        "            if hsh not in neigh_high:\n",
        "                neigh_high[hsh] = 0.0\n",
        "            neigh_high[hsh] += 1\n",
        "    neigh_pct_low_tmp = {}\n",
        "    neigh_pct_medium_tmp = {}\n",
        "    neigh_pct_high_tmp = {}\n",
        "    neigh_count_tmp = {}\n",
        "    for i in train_ind:\n",
        "        x = train_df.iloc[i]\n",
        "        round_lat = round(x['latitude'], 2)\n",
        "        round_long = round(x['longitude'], 2)\n",
        "        lat_down = round_lat - 0.01\n",
        "        lat_up = round_lat + 0.01\n",
        "        long_down = round_long - 0.01\n",
        "        long_up = round_long + 0.01        \n",
        "        low_sum = 0.0    \n",
        "        md_sum = 0.0\n",
        "        high_sum = 0.0        \n",
        "        pos = [str(lat_down) + \"#\" + str(long_down),  \n",
        "               str(round_lat) + \"#\" + str(long_down),  \n",
        "               str(lat_up) + \"#\" + str(long_down), \n",
        "               str(lat_down) + \"#\" + str(round_long),\n",
        "               str(round_lat)  + \"#\" + str(round_long),\n",
        "               str(lat_up) + \"#\" + str(round_long),\n",
        "               str(lat_down)  + \"#\" + str(long_up), \n",
        "               str(round_lat)  + \"#\" + str(long_up),\n",
        "               str(lat_up)+ \"#\" + str(long_up)]\n",
        "        for ps in pos:\n",
        "            if ps in neigh_low:    \n",
        "                low_sum += neigh_low[ps]\n",
        "            if ps in neigh_medium:\n",
        "                md_sum += neigh_medium[ps]\n",
        "            if ps in neigh_high:\n",
        "                high_sum += neigh_high[ps]\n",
        "        hsh =  str(round_lat)  + \"#\" + str(round_long)\n",
        "        neigh_pct_low_tmp[hsh] = low_sum / (low_sum + md_sum + high_sum + 1.0)\n",
        "        neigh_pct_medium_tmp[hsh] = md_sum / (low_sum + md_sum + high_sum + 1.0)\n",
        "        neigh_pct_high_tmp[hsh] = high_sum / (low_sum + md_sum + high_sum + 1.0)\n",
        "        neigh_count_tmp[hsh] = low_sum + md_sum + high_sum  \n",
        "    for index, row in test_df.iterrows():\n",
        "        x = row\n",
        "        manager_id = row['manager_id']\n",
        "        building_id = row['building_id']\n",
        "        round_lat = round(x['latitude'], 2)\n",
        "        round_long = round(x['longitude'], 2)\n",
        "        hsh =  str(round_lat)  + \"#\" + str(round_long)\n",
        "        manager_score.append(manager_sum[manager_id] / manager_count[manager_id] if manager_id in manager_count else avg)\n",
        "        manager_low.append(manager_low_tmp[manager_id]  if manager_id in manager_low_tmp else low_total / manager_ct)\n",
        "        manager_medium.append(manager_medium_tmp[manager_id] if manager_id in manager_medium_tmp else medium_total / manager_ct)\n",
        "        manager_high.append(manager_high_tmp[manager_id] if manager_id  in manager_high_tmp  else high_total / manager_ct)\n",
        "        manager_low_pct.append(manager_low_tmp[manager_id] / manager_count[manager_id]  if manager_id in manager_low_tmp else low_total / ct)\n",
        "        manager_medium_pct.append(manager_medium_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_medium_tmp else medium_total / ct)\n",
        "        manager_high_pct.append(manager_high_tmp[manager_id] / manager_count[manager_id] if manager_id in manager_high_tmp else high_total / ct)  \n",
        "        pct_low.append(neigh_pct_low_tmp[hsh] if hsh in neigh_pct_low_tmp else 0.6)\n",
        "        pct_medium.append(neigh_pct_medium_tmp[hsh] if hsh in neigh_pct_medium_tmp else 0.3)\n",
        "        pct_high.append(neigh_pct_high_tmp[hsh] if hsh in neigh_pct_high_tmp else 0.1)\n",
        "        neigh_count.append(neigh_count_tmp[hsh] if hsh in neigh_count_tmp else 0)\n",
        "        building_score.append(building_sum[building_id] / building_count[building_id] if building_id in building_count else avg)\n",
        "        building_low.append(building_low_tmp[building_id] if building_id in building_low_tmp else low_total / building_ct)\n",
        "        building_medium.append(building_medium_tmp[building_id] if building_id in building_medium_tmp else medium_total / building_ct)\n",
        "        building_high.append(building_high_tmp[building_id] if building_id in building_high_tmp else high_total / building_ct)\n",
        "        building_low_pct.append(building_low_tmp[building_id] / building_count[building_id] if building_id in building_low_tmp else 0.6)\n",
        "        building_medium_pct.append(building_medium_tmp[building_id] / building_count[building_id] if building_id in building_medium_tmp else 0.3)\n",
        "        building_high_pct.append(building_high_tmp[building_id] / building_count[building_id] if building_id in building_high_tmp else 0.1)\n",
        "    test_df['manager_score'] = manager_score \n",
        "    #test_df['manager_low'] = manager_low \n",
        "    #test_df['manager_medium'] = manager_medium\n",
        "    #test_df['manager_high'] =  manager_high\n",
        "    test_df['manager_low_pct'] = manager_low_pct\n",
        "    test_df['manager_medium_pct'] = manager_medium_pct\n",
        "    test_df['manager_high_pct'] = manager_high_pct\n",
        "    test_df['neigh_low_pct'] = pct_low\n",
        "    test_df['neigh_medium_pct'] = pct_medium\n",
        "    test_df['neigh_high_pct'] = pct_high\n",
        "    test_df['neigh_low_ct'] = np.array(pct_low) * np.array(neigh_count)\n",
        "    test_df['neigh_medium_ct'] = np.array(pct_medium) * np.array(neigh_count)\n",
        "    test_df['neigh_high_ct'] = np.array(pct_high) * np.array(neigh_count)\n",
        "    test_df['building_score'] = building_score \n",
        "    #test_df['building_low'] = building_low \n",
        "    #test_df['building_medium'] = building_medium\n",
        "    #test_df['building_high'] =  building_high\n",
        "    test_df['building_low_pct'] = building_low_pct\n",
        "    test_df['building_medium_pct'] = building_medium_pct\n",
        "    test_df['building_high_pct'] = building_high_pct\n",
        "    data_df = pd.concat((train_df, test_df), axis=0)  \n",
        "    manager_price = {}\n",
        "    manager_count = {}\n",
        "    for j in range(data_df.shape[0]):  \n",
        "        x=data_df.iloc[j]\n",
        "        if x['manager_id'] not in manager_price:\n",
        "            manager_price[x['manager_id']] = 0.0\n",
        "            manager_count[x['manager_id']] = 0.0\n",
        "        manager_price[x['manager_id']] += x['price']\n",
        "        manager_count[x['manager_id']] += 1\n",
        "    data_df['manager_count'] = data_df['manager_id'].apply(lambda x: manager_count[x])\n",
        "    data_df['avg_manager_price'] = data_df['manager_id'].apply(lambda x: manager_price[x] / manager_count[x])\n",
        "    # add counting features \n",
        "    data_df['num_photos'] = data_df['photos'].apply(len)\n",
        "    data_df['num_features'] = data_df['features'].apply(len)\n",
        "    data_df['num_description'] = data_df['description'].apply(lambda x: len(x.split(' ')))\n",
        "    data_df['num_display_address'] = data_df['display_address'].apply(lambda x: len(x.split(' ')))\n",
        "    data_df['num_street_address'] = data_df['street_address'].apply(lambda x: len(x.split(' ')))\n",
        "    data_df['photo_description_ratio'] =  data_df['num_photos'] * 1.0 / data_df['num_description']\n",
        "    data_df.drop('photos', axis=1, inplace=True)\n",
        "    # naive feature engineering\n",
        "    data_df['room_difference'] = data_df['bedrooms'] - data_df['bathrooms']\n",
        "    data_df['room_ratio'] = data_df['bedrooms'] * 1.0 / data_df['bathrooms']\n",
        "    data_df['total_rooms'] = data_df['bedrooms'] + data_df['bathrooms']\n",
        "    data_df['price_per_room'] = data_df['price'] / (data_df['total_rooms'] + 1)\n",
        "    data_df['price_per_bedroom'] = data_df['price'] / (data_df['bedrooms'] + 1)\n",
        "    data_df['price_per_bedroom'] = data_df['price'] / (data_df['bathrooms'] + 1)\n",
        "    # add datetime features\n",
        "    data_df['created'] = pd.to_datetime(data_df['created'])\n",
        "    data_df['c_month'] = data_df['created'].dt.month\n",
        "    data_df['c_day'] = data_df['created'].dt.day\n",
        "    data_df['c_hour'] = data_df['created'].dt.hour\n",
        "    data_df['c_dayofyear'] = data_df['created'].dt.dayofyear\n",
        "    data_df['longitude'] = data_df['longitude'].apply(lambda x: round(x, 3))\n",
        "    data_df['latitude'] = data_df['latitude'].apply(lambda x: round(x, 3))\n",
        "    data_df.drop('created', axis=1, inplace=True)  \n",
        "    # encode categorical features\n",
        "    for col in ['display_address', 'street_address', 'manager_id', 'building_id']:\n",
        "        data_df[col] = LabelEncoder().fit_transform(data_df[col])\n",
        "    data_df.drop('description', axis=1, inplace=True)\n",
        "    # get text features\n",
        "    data_df['features'] = data_df['features'].apply(lambda x: ' '.join(['_'.join(i.split(' ')) for i in x]))\n",
        "    textcv = CountVectorizer(stop_words='english', max_features=200)\n",
        "    text_features = pd.DataFrame(textcv.fit_transform(data_df['features']).toarray(),\n",
        "                                                               columns=['f_' + format(x, '03d') for x in range(1, 201)], index=data_df.index)\n",
        "    data_df = pd.concat(objs=(data_df, text_features), axis=1)\n",
        "    data_df.drop('features', axis=1, inplace=True)\n",
        "    feature_cols = [x for x in data_df.columns if x not in {'interest_level'}]\n",
        "    del train_df, test_df\n",
        "    return data_df.loc[train_index, feature_cols], data_df.loc[train_index, 'interest_level'],\\\n",
        "        data_df.loc[test_index, feature_cols]\n",
        "\n",
        "train = pd.read_json(open(\"train.json\", \"r\"))\n",
        "test = pd.read_json(open(\"test.json\", \"r\"))\n",
        "train_X, train_y, test_df = preprocess(train, test)\n",
        "\n",
        "train_X.drop('listing_id', axis=1, inplace=True)\n",
        "param = {}\n",
        "param['objective'] = 'multi:softprob'\n",
        "param['eta'] = 0.02\n",
        "param['max_depth'] = 6\n",
        "param['silent'] = 1\n",
        "param['num_class'] = 3\n",
        "param['eval_metric'] = \"mlogloss\"\n",
        "param['min_child_weight'] = 1\n",
        "param['subsample'] = 0.7\n",
        "param['colsample_bytree'] = 0.7\n",
        "param['seed'] = 321\n",
        "param['nthread'] = 4\n",
        "param['num_rounds'] = 2300\n",
        "\n",
        "print 'training'\n",
        "xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "#xgb.cv(param, xgtrain, 10000, nfold=3, verbose_eval = True, early_stopping_rounds=10)\n",
        "\n",
        "model = xgb.train(param, xgtrain, 1100, verbose_eval = True)\n",
        "listing_id = test_df['listing_id'].ravel()\n",
        "test_df.drop('listing_id', axis=1, inplace=True)\n",
        "xgtest = xgb.DMatrix(test_df)\n",
        "\n",
        "preds = model.predict(xgtest)\n",
        "sub = pd.DataFrame(data = {'listing_id': listing_id})\n",
        "sub['low'] = preds[:, 0]\n",
        "sub['medium'] = preds[:, 1]\n",
        "sub['high'] = preds[:, 2]\n",
        "sub.to_csv(\"submission2.csv\", index = False, header = True)\n",
        "\n",
        "\n",
        "# we simply have to run the following code each time we modify the hyperparameters:\n",
        "X = cross_validate_lgbm()\n",
        "\n",
        "\n",
        "param['eta'] = 0.02\n",
        "param['max_depth'] = 6\n",
        "param['silent'] = 1\n",
        "param['num_class'] = 3\n",
        "param['eval_metric'] = \"mlogloss\"\n",
        "param['min_child_weight'] = 1\n",
        "param['subsample'] = 0.0.7\n",
        "param['colsample_bytree'] = 0.0.7\n",
        "param['seed'] = 321\n",
        "param['nthread'] = 4\n",
        "param['num_rounds'] = 2300\n",
        "model1low = [np.nan]*len(train_X)\n",
        "model2low = [np.nan]*len(train_X)\n",
        "model3low = [np.nan]*len(train_X)\n",
        "model4low = [np.nan]*len(train_X)\n",
        "model1medium = [np.nan]*len(train_X)\n",
        "model2medium = [np.nan]*len(train_X)\n",
        "model3medium = [np.nan]*len(train_X)\n",
        "model4medium = [np.nan]*len(train_X)\n",
        "model1high = [np.nan]*len(train_X)\n",
        "model2high = [np.nan]*len(train_X)\n",
        "model3high = [np.nan]*len(train_X)\n",
        "model4high = [np.nan]*len(train_X)\n",
        "for j in range(5):\n",
        "    print j \n",
        "    index=list(range(train_X.shape[0]))\n",
        "    test_ind = index[int((j*train_X.shape[0])/5):int(((j+1)*train_X.shape[0])/5)]\n",
        "    train_ind = list(set(index).difference(test_ind))\n",
        "    train_Xfold = train_X.iloc[train_ind]\n",
        "    train_YFold = train_y.iloc[train_ind]\n",
        "    xgtrain = xgb.DMatrix(train_Xfold, label=train_YFold)\n",
        "    model = xgb.train(param, xgtrain, 1150, verbose_eval = True)\n",
        "    #param['max_depth'] = 5\n",
        "    #model2 = xgb.train(param, xgtrain, 1700, verbose_eval = True)\n",
        "    model3 = RandomForestClassifier(n_estimators=100)\n",
        "    print 'model 2'\n",
        "    model3.fit(train_Xfold, train_YFold)    \n",
        "    model4 = KNeighborsClassifier(n_neighbors = 25)\n",
        "    model4.fit(train_Xfold, train_YFold)    \n",
        "    pred1 = model.predict(train_X.iloc[test_ind])\n",
        "    #pred2 = model2.predict(train_X.iloc[test_ind])\n",
        "    pred3 = model3.predict(train_X.iloc[test_ind])\n",
        "    pred4 = model4.predict(train_X.iloc[test_ind])\n",
        "    k = 0.0\n",
        "    for i, row in test_ind.iterrows():\n",
        "        x = pred1[k] \n",
        "        #x2 = pred2[k]\n",
        "        x3 = pred3[k]\n",
        "        x4 = pred4[k]   \n",
        "        model1low[i] = x[0]\n",
        "        #model2low[i] = x2[0]\n",
        "        model3low[i] = x3[0]\n",
        "        model4low[i] = x4[0]        \n",
        "        model1medium[i] = x[1]\n",
        "        #model2medium[i] = x2[1]\n",
        "        model3medium[i] = x3[1]\n",
        "        model4medium[i] = x4[1]        \n",
        "        model1high[i] = x[1]\n",
        "        #model2high[i] = x2[1]\n",
        "        model3high[i] = x3[1]\n",
        "        model4high[i] = x4[1]\n",
        "        k += 1\n",
        "train_X['model1low'] = model1low  \n",
        "#train_X['model2low'] = model2low \n",
        "train_X['model3low'] = model3low \n",
        "train_X['model4low'] = model4low\n",
        "train_X['model1medium'] = model1medium\n",
        "#train_X['model2medium'] = model2medium\n",
        "train_X['model3medium'] = model3medium \n",
        "train_X['model4medium'] = model4medium\n",
        "train_X['model1high'] = model1high\n",
        "#train_X['model2high'] = model2high\n",
        "train_X['model3high'] = model3high\n",
        "train_X['model4high'] = model4\n",
        "highlm = LogisticRegression(multi_class='multinomial')\n",
        "lm.fit(train_df, label=train_y)preds = lm.predict(xgtest)\n",
        "sub = pd.DataFrame(data = {'listing_id': listing_id})\n",
        "sub['low'] = preds[:, 0]\n",
        "sub['medium'] = preds[:, 1]\n",
        "sub['high'] = preds[:, 2]\n",
        "sub.to_csv(\"submission3.csv\", index = False, header = True)\n",
        "    \n",
        "    \n"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}