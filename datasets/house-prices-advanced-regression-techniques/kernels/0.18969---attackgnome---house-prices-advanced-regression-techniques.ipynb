{"cells":[{"metadata":{"_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199","_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nYou will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n\nThe data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n\nCome to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n\n# Write Your Code Below\n\n"},{"metadata":{"_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","_uuid":"1c728098629e1301643443b1341556a15c089b2b","scrolled":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\n\nmain_file_path = '../input/train.csv'\ndata = pd.read_csv(main_file_path)\nprint(data.describe())","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"65b704dfd28f8ad85b765c1132fa4a3483ad3ace"},"cell_type":"markdown","source":"Print a list of the columns"},{"metadata":{"trusted":true,"_uuid":"9055cbf26cc03cdf68a89af9ba82be923aed2f2b"},"cell_type":"code","source":"print(data.columns)","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"734dfdfc64eee23e6cff62948fd0e044b0f54915"},"cell_type":"markdown","source":"From the list of columns, find a name of the column with the sales prices of the homes. Use the dot notation to extract this to a variable (as you saw above to create melbourne_price_data.)\nUse the head command to print out the top few lines of the variable you just created."},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"16d01b4f873c420319bd6e5365b47d7ca9a9e707"},"cell_type":"code","source":"# store the series of prices separately as price_data.\nprice_data = data.SalePrice\n# the head command returns the top few lines of data.\nprint(price_data.head())","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"56d7b06a2f4ba376002e0838fc008a3e3ab49df4"},"cell_type":"markdown","source":"Pick any two variables and store them to a new DataFrame (as you saw above to create two_columns_of_data.)\nUse the describe command with the DataFrame you just created to see summaries of those variables. "},{"metadata":{"trusted":true,"_uuid":"6ba681ac384b7c4d87578354135049ba20b63371"},"cell_type":"code","source":"columns_of_interest = ['OverallQual', 'Fireplaces']\ntwo_columns_of_data = data[columns_of_interest]\ntwo_columns_of_data.describe()","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"3b0fd2bf247a7d5494f74ad71e1be4e4bc48c209"},"cell_type":"markdown","source":"Select the target variable you want to predict. We are going to choose SalePrice as the prediction target. Save this to a new variable called y."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"1c721fc1c5f3adcecadb8a5a419eea226cdfa5fb"},"cell_type":"code","source":"y = data.SalePrice","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"01486e8ca8bb849ed280c1708b893ddf1848e9b6"},"cell_type":"markdown","source":"Create a list of the names of the predictors we will use in the initial model. Use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):\n\n* LotArea\n* YearBuilt\n* 1stFlrSF\n* 2ndFlrSF\n* FullBath\n* BedroomAbvGr\n* TotRmsAbvGrd\n\nSave this with the variable name X"},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"8540a71f699c5a4486f277cf8d871d4c7265064e"},"cell_type":"code","source":"data_predictors = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', \n                        'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\nX = data[data_predictors]","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"5036434843b12bba799902a1dbad5fb28c94f125"},"cell_type":"markdown","source":"Create a DecisionTreeRegressorModel and save it to a variable (with a name like my_model or iowa_model). Ensure you've done the relevant import so you can run this command.\n\nFit the model you have created using the data in X and the target data you saved above."},{"metadata":{"trusted":true,"_uuid":"297e866cd09b74a16c71fe393e097eab4dac04a8"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n# Define model\niowa_model = DecisionTreeRegressor()\n\n# Fit model\niowa_model.fit(X, y)","execution_count":18,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"cd2303059439b27ab01bf02f61a906637ee68b5f"},"cell_type":"code","source":"Make a few predictions with the model's predict command and print out the predictions.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"955adf2b3118128e063218ddb927d94c7a2e1c42"},"cell_type":"code","source":"print(\"Making predictions for the following 5 houses:\")\nprint(X.head())\nprint(\"The predictions are\")\nprint(iowa_model.predict(X.head()))","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"219facbb659ccbdf5e8435fcf98ce520559d4502"},"cell_type":"markdown","source":"1. Use the train_test_split command to split up your data.\n1. Fit the model with the training data\n1. Make predictions with the validation predictors\n1. Calculate the mean absolute error between your predictions and the actual target values for the validation data."},{"metadata":{"trusted":true,"_uuid":"85448a8168765690cc4b7054e812c7ae17eb3c00"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# split data into training and validation data, for both predictors and target\n# The split is based on a random number generator. Supplying a numeric value to\n# the random_state argument guarantees we get the same split every time we\n# run this script.\ntrain_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n# Define model\niowa_model = DecisionTreeRegressor()\n# Fit model\niowa_model.fit(train_X, train_y)\n\n# get predicted prices on validation data\nval_predictions = iowa_model.predict(val_X)\nprint(mean_absolute_error(val_y, val_predictions))","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"950575577ac1d868c042402395ce47488b2d16d8"},"cell_type":"markdown","source":"Use a for loop that tries different values of max_leaf_nodes and calls the get_mae function on each to find the ideal number of leaves for your Iowa data."},{"metadata":{"trusted":true,"_uuid":"eea14c42e19a2c3a7ba19924fea6e08d01f55c04"},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)\n\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"af97447abd51eebff1a4052482d217a4f972335b"},"cell_type":"markdown","source":"Run the RandomForestRegressor on your data. You should see a big improvement over your best Decision Tree models."},{"metadata":{"trusted":true,"_uuid":"e3064b48c3af928954dccdf4079da4322e6b354b"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\n\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X, train_y)\nmelb_preds = forest_model.predict(val_X)\nprint(mean_absolute_error(val_y, melb_preds))","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"3356740b3e18dbf96b80059fcbdc7f1fddd36e7a"},"cell_type":"markdown","source":"We're doing very minimal data set up here so we can focus on how to submit modeling results to competitions. Other tutorials will teach you how build great models. So the model in this example will be fairly simple. We'll start with the code to read data, select predictors, and fit a model."},{"metadata":{"trusted":true,"_uuid":"621f615852c519930d3413e18d33ed40c602fc74"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Read the data\ntrain = pd.read_csv('../input/train.csv')\n\n# pull data into target (y) and predictors (X)\ntrain_y = train.SalePrice\npredictor_cols = ['LotArea', 'OverallQual', 'YearBuilt', 'TotRmsAbvGrd']\n\n# Create training predictors data\ntrain_X = train[predictor_cols]\n\nmy_model = RandomForestRegressor()\nmy_model.fit(train_X, train_y)","execution_count":134,"outputs":[]},{"metadata":{"_uuid":"d64d092b992d85be8c1e3e9b11abf149e5dd5c75"},"cell_type":"markdown","source":"In addition to your training data, there will be test data. This is frequently stored in a file with the title test.csv. This data won't include a column with your target (y), because that is what we'll have to predict and submit. Here is sample code to do that."},{"metadata":{"trusted":true,"_uuid":"b8e5d057fddc9bda9caaa2537ece23b0d8e1ae2a"},"cell_type":"code","source":"# Read the test data\ntest = pd.read_csv('../input/test.csv')\n# Treat the test data in the same way as training data. In this case, pull same columns.\ntest_X = test[predictor_cols]\n# Use the model to make predictions\npredicted_prices = my_model.predict(test_X)\n# We will look at the predicted prices to ensure we have something sensible.\nprint(predicted_prices)","execution_count":104,"outputs":[]},{"metadata":{"_uuid":"55d4982155bb01f632dfab901e9cd67fd0d42f75"},"cell_type":"markdown","source":"We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"c8410c98d785623a30390eac138bda25abbaf2cb"},"cell_type":"code","source":"my_submission = pd.DataFrame({'Id': test.Id, 'SalePrice': predicted_prices})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56bce64b92967d0e499e1c2e9c1973190711d017"},"cell_type":"markdown","source":"**Level 2 Material**\n\nStart of Level 2 material"},{"metadata":{"_uuid":"ec118221969776a159ce8d0a1026c4feee4b34fa"},"cell_type":"markdown","source":"**Basic Problem Set-Up**\n\nLoad data, select variables, split into test and training data."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c910071bb9546d2c9219871833160a37d00110a6"},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load data\niowa_data = pd.read_csv('../input/train.csv')\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\niowa_target = iowa_data.SalePrice\niowa_predictors = iowa_data.drop(['SalePrice'], axis=1)\n\n# For the sake of keeping the example simple, we'll use only numeric predictors. \niowa_numeric_predictors = iowa_predictors.select_dtypes(exclude=['object'])\n\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(iowa_numeric_predictors, \n                                                    iowa_target,\n                                                    train_size=0.7, \n                                                    test_size=0.3, \n                                                    random_state=0)\n\ndef score_dataset(X_train, X_test, y_train, y_test):\n    model = RandomForestRegressor()\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    return mean_absolute_error(y_test, preds)\n\n","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"70d8088920606aadd4bb3239d1564a761634d80e"},"cell_type":"markdown","source":"\"Get Model Score from Imputation\""},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5bda4a10e7659d2fb80606095c2b7e713292afba"},"cell_type":"code","source":"from sklearn.preprocessing import Imputer\n\nmy_imputer = Imputer()\nimputed_X_train = my_imputer.fit_transform(X_train)\nimputed_X_test = my_imputer.transform(X_test)\nprint(\"Mean Absolute Error from Imputation:\")\nprint(score_dataset(imputed_X_train, imputed_X_test, y_train, y_test))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e9752b338e023d3fe98d22b2ecd1bb19db8e9b3"},"cell_type":"markdown","source":"**Get Score from Imputation with Extra Columns Showing What Was Imputed**"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"60ce913006e84ea30e075712407eddd15d09faa9"},"cell_type":"code","source":"imputed_X_train_plus = X_train.copy()\nimputed_X_test_plus = X_test.copy()\n\ncols_with_missing = (col for col in X_train.columns \n                                 if X_train[col].isnull().any())\nfor col in cols_with_missing:\n    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n\n# Imputation\nmy_imputer = Imputer()\nimputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\nimputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n\nprint(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))","execution_count":57,"outputs":[]},{"metadata":{"_uuid":"51dc2c3eddaa94474c7c886ad61412df17e26163"},"cell_type":"markdown","source":"**Using Categorical Data with One Hot Encoding**"},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"7d9df4a7b33c24a3e9d7c4e7f20589a11b502f37"},"cell_type":"code","source":"#Use imputing to handle missing values\nmy_imputer = Imputer()\niowa_numeric_predictors_plus = my_imputer.fit_transform(iowa_numeric_predictors)\nnumeric_training_predictors = pd.DataFrame(data=iowa_numeric_predictors_plus)\n\n#Use one hot encoding on categorical variables\niowa_object_predictors = iowa_predictors.select_dtypes(include=['object'])\none_hot_encoded_training_predictors = pd.get_dummies(iowa_object_predictors)\n\n#merge numeric and one-hot encoded data together\none_hot_encoded_training_predictors = pd.concat([one_hot_encoded_training_predictors, numeric_training_predictors], axis=1, join_axes=[one_hot_encoded_training_predictors.index])\nprint(one_hot_encoded_training_predictors.head())","execution_count":111,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83dab1b6c0dc88e17faedf68c4a9e96524d7a290"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef get_mae(X, y):\n    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n    return -1 * cross_val_score(RandomForestRegressor(50), \n                                X, y, \n                                scoring = 'neg_mean_absolute_error').mean()\n\npredictors_without_categoricals = iowa_numeric_predictors_plus\n\nmae_without_categoricals = get_mae(predictors_without_categoricals, iowa_target )\n\nmae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, iowa_target )\n\nprint('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_without_categoricals)))\nprint('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))","execution_count":112,"outputs":[]},{"metadata":{"_uuid":"bd122c4787e4aa3437adda9a6cdb64f8e49045ca"},"cell_type":"markdown","source":"**Learning to Use XGBoost**"},{"metadata":{"trusted":true,"_uuid":"a095adcbdb51fb98daee9c5b92a1ef318bd31227"},"cell_type":"code","source":"#We are going to use the data that we have one-hot encoded and imputed missing values\nX_train, X_test, y_train, y_test = train_test_split(one_hot_encoded_training_predictors, \n                                                    iowa_target,\n                                                    train_size=0.7, \n                                                    test_size=0.3, \n                                                    random_state=0)\n#We can then proceed with the XGBoost model, \nfrom xgboost import XGBRegressor\n\nmy_model = XGBRegressor(n_estimators=1000)\nmy_model.fit(imputed_X_train_plus, y_train, early_stopping_rounds=100, \n             eval_set=[(imputed_X_test_plus, y_test)], verbose=False)\n\n# make predictions\npredictions = my_model.predict(imputed_X_test_plus)\n\nfrom sklearn.metrics import mean_absolute_error\nprint(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))","execution_count":137,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cee3ca9106a602b2535b624ec7247a6a9e28d1fa"},"cell_type":"markdown","source":"**Partial Dependence Plots**\n\nIn this step, you will learn how to create and interpret partial dependence plots, one of the most valuable ways to extract insight from your models.\n\nPick three predictors in your project. Formulate an hypothesis about what the partial dependence plot will look like. Create the plots, and check the results against your hypothesis."},{"metadata":{"trusted":true,"_uuid":"60b2310ebf5f35b43e2b9c504c927a38d574dc5e"},"cell_type":"code","source":"def get_some_data():\n    cols_to_use = ['LotArea', 'YearBuilt', '1stFlrSF']\n    data = pd.read_csv('../input/train.csv')\n    y = data.SalePrice\n    X = data[cols_to_use]\n    my_imputer = Imputer()\n    imputed_X = my_imputer.fit_transform(X)\n    return imputed_X, y\n\nfrom sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# get_some_data is defined in hidden cell above.\nX, y = get_some_data()\n# scikit-learn originally implemented partial dependence plots only for Gradient Boosting models\n# this was due to an implementation detail, and a future release will support all model types.\nmy_model = GradientBoostingRegressor()\n\n# fit the model as usual\nmy_model.fit(X, y)\n# Here we make the plot\nmy_plots = plot_partial_dependence(my_model,       \n                                   features=[0, 1, 2], # column numbers of plots we want to show\n                                   X=X,            # raw predictors data.\n                                   feature_names=['LotArea', 'YearBuilt', '1stFlrSF'], # labels on graphs\n                                   grid_resolution=10) # number of values to plot on x axis\n","execution_count":141,"outputs":[]},{"metadata":{"_uuid":"b2114ecb6e0b7e29b84ea9c685201ff685e20c18"},"cell_type":"markdown","source":"**Pipelines**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1834aaa7affd7333a3df24e5e8083ed9a1f3e335"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\n\nmy_pipeline = make_pipeline(Imputer(), RandomForestRegressor())\nmy_pipeline.fit(train_X, train_y)\npredictions = my_pipeline.predict(test_X)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}