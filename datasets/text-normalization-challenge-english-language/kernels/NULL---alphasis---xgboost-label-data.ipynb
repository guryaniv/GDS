{"nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "version": "3.6.1", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}}, "cells": [{"source": ["*Author: BingQing Wei*\n", "\n", "**Introduction**\n", "I have tried using regex to solve labeling the data([my notebook](https://www.kaggle.com/alphasis/regex-label-data)), but I later found I just can't make it perfect.\n", "Therefore I turned once again to machine learning.\n", "And I decided to use XGboost as a starter, because I think decision trees might be the best in classifying this kind of data.\n", "\n", "**How I train it**\n", "I didn't use data lebeld as 'PLAIN', 'VERBATIM', 'LETTERS', 'PUNCT' to train the model.\n", "Because for 'VERBATIM' and 'PUNCT' data, they can be labeled trivially.\n", "And 'PLAIN' and 'LETTERS' data can only be classified given the context. It's something RNN is good at but XGboost is not.\n", "So I use the rest 12 classes to train XGboost model and only used 20,000 of them since I don't want to be kept waiting for too long.\n", "\n", "**Results**\n", "Accuracy 97.9% on validation data.\n", "The output of this script consists of 3 files:\n", "\n", "*xgb_model*: the dumped model that we trained\n", "*pred.csv*: contains the validation data\n", "*errors.csv*: contains data that the model predicts wrong\n", "\n", "If you look into the errors.csv, you will find the 0.021 error rate is reasonable:\n", "*Because some special 'CARDINAL' data are classified as 'DATE' *.\n", "Agian, it's something beyond XGBoost's ability."], "cell_type": "markdown", "metadata": {"_cell_guid": "bfaf187a-68f1-4676-b758-1d3b4eae5aa1", "_uuid": "98c7fc065b0140cbe2b9426201dabf9368a94e35"}}, {"source": ["We begin by loading data and then drop those 'PLAIN', 'VERBATIM', 'LETTERS' or 'PUNCT' data"], "cell_type": "markdown", "metadata": {"_cell_guid": "ebeba34b-b6ee-4e8f-a200-d8a4c2494aed", "_uuid": "eeae200a3fec914ba72711676d02be4455d37b20"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "92829c18-c48d-4595-a52b-57ac9df3d334", "_uuid": "7126147e58688273c17b506ee86baac4c1eb8199"}, "source": ["import pandas as pd\n", "import numpy as np\n", "import os\n", "import pickle\n", "\n", "max_num_features = 20\n", "\n", "out_path = r'.'\n", "df = pd.read_csv(r'../input/en_train.csv')\n", "exclude_classes = ['PLAIN', 'VERBATIM', 'LETTERS', 'PUNCT']\n", "df = df.loc[df['class'].isin(exclude_classes) == False]"]}, {"source": ["To convert strings into numbers, I simply take their ASCII value then minus 'a'.\n", "This, minusing 'a', I think is important.\n", "Because I think **it distinguishes alphabets from numbers and some symbols**.\n", "*Since most alphabets in the data are lower-case, we don't consider upper-case here.*"], "cell_type": "markdown", "metadata": {"_cell_guid": "f47024d2-f059-4ddc-8d9e-1ba434d41bd8", "_uuid": "cf9bd6f66440b9d4b9114a2d8ae913a0e5545625"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "e3e22f7f-0c97-4c74-929a-5c39c516b4c4", "_uuid": "1e60750e57da9c5aecfe96e3852bdeb63a441a6c"}, "source": ["max_size = 200000\n", "x_data = []\n", "y_data = pd.factorize(df['class'])\n", "labels = y_data[1]\n", "y_data = y_data[0]\n", "for x in df['before'].values:\n", "    x_row = np.zeros(max_num_features, dtype=int)\n", "    for xi, i in zip(list(str(x)), np.arange(max_num_features)):\n", "        x_row[i] = ord(xi) - ord('a')\n", "    x_data.append(x_row)\n", "\n", "print('Total number of samples:', len(x_data))\n", "print('Use: ', max_size)\n", "#x_data = np.array(x_data)\n", "#y_data = np.array(y_data)\n", "x_data = np.array(x_data[:max_size])\n", "y_data = np.array(y_data[:max_size])\n", "\n", "print('x_data sample:')\n", "print(x_data[0])\n", "print('y_data sample:')\n", "print(y_data[0])\n", "print('labels:')\n", "print(labels)\n", "\n", "del df"]}, {"source": ["Next we begin training the model."], "cell_type": "markdown", "metadata": {"_cell_guid": "657b7654-fa98-47ca-ada1-4d0d838d0b5f", "_uuid": "b33b4d05198980def2b384267612526ff191a26d"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "a2fc1d8e-4f4f-4e8d-af01-f9f7ec1ca227", "_uuid": "f06092db25b83dca29572abdfff0398b1cf50a1c"}, "source": ["import xgboost as xgb\n", "import numpy as np\n", "import pickle\n", "import os\n", "import re\n", "import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "\n", "out_path = r'.'\n", "\n", "x_train = x_data\n", "y_train = y_data\n", "del x_data\n", "del y_data\n", "\n", "x_train, x_valid, y_train, y_valid= train_test_split(x_train, y_train,\n", "                                                      test_size=0.1, random_state=2017)\n", "num_class = len(labels)\n", "dtrain = xgb.DMatrix(x_train, label=y_train)\n", "dvalid = xgb.DMatrix(x_valid, label=y_valid)\n", "watchlist = [(dvalid, 'valid'), (dtrain, 'train')]\n", "\n", "param = {'objective':'multi:softmax',\n", "         'eta':'0.3', 'max_depth':10,\n", "         'silent':1, 'nthread':-1,\n", "         'num_class':num_class,\n", "         'eval_metric':'merror'}\n", "model = xgb.train(param, dtrain, 60, watchlist, early_stopping_rounds=20,\n", "                  verbose_eval=10)"]}, {"source": ["Next we take the predictions by the model of the validation data and save them into csv files."], "cell_type": "markdown", "metadata": {"_cell_guid": "e4692e0b-6288-435a-8145-8c5792681f1e", "_uuid": "6013ea122858b6634199938fd4aca4108ba70577"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_cell_guid": "9eebf1a6-6094-4187-bf9a-a10849179fc7", "_uuid": "434c1aa323bb943a02f84af50613a707dff8499c"}, "source": ["pred = model.predict(dvalid)\n", "pred = [labels[int(x)] for x in pred]\n", "y_valid = [labels[x] for x in y_valid]\n", "x_valid = [ [ chr(x + ord('a')) for x in y] for y in x_valid]\n", "x_valid = [''.join(x) for x in x_valid]\n", "x_valid = [re.sub('a+$', '', x) for x in x_valid]\n", "\n", "df_pred = pd.DataFrame(columns=['data', 'predict', 'target'])\n", "df_pred['data'] = x_valid\n", "df_pred['predict'] = pred\n", "df_pred['target'] = y_valid\n", "df_pred.to_csv(os.path.join(out_path, 'pred.csv'))\n", "\n", "df_errors = df_pred.loc[df_pred['predict'] != df_pred['target']]\n", "df_errors.to_csv(os.path.join(out_path, 'errors.csv'))\n", "\n", "model.save_model(os.path.join(out_path, 'xgb_model'))"]}, {"source": ["Since Kaggle Notebook doesn't provide the output of it, I gonna use another way."], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {}, "source": ["df_pred[:10]"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {}, "source": ["df_errors[:10]"]}]}