{"cells":[{"metadata":{"_cell_guid":"ebed1e45-172d-4602-8ab9-85e3ab5269c8","_uuid":"08f200006deab2639fb57d46724e8020356ccdce"},"cell_type":"markdown","source":"![](https://m.popkey.co/ddb315/LmGYG_s-200x150.gif?c=popkey-web&p=funny_or_die&i=funny-or-die-ent&l=search&f=.gif)\nIf you use parts of this notebook in your own scripts, please give some sort of credit (for example link back to this). Thanks!\n\n**Please upvote to encourage me to do more.**\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false,"collapsed":true},"cell_type":"code","source":"datadir = '../input/'\ntrain = pd.read_csv(datadir+'train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f64d5ba4-7440-4361-a5d2-7618bc5024ac","_uuid":"1c04d6c7f28374aa20161107c7bd2f5608d378dd","trusted":false,"collapsed":true},"cell_type":"code","source":"datadir = '../input/'\ntest = pd.read_csv(datadir+'test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"01d3adff-5656-47ce-a772-dec23ea7f634","_uuid":"9f56b6a428aea393c55478ee0c2282408dfc9610"},"cell_type":"markdown","source":"Now we will examine the train dataset"},{"metadata":{"_cell_guid":"a0b69890-0caa-407d-9851-ae6adcec728c","_uuid":"d004c997145eeb5a493fef598f92d6ada42da583","trusted":false,"collapsed":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bdf4cff1-c2f2-4b34-a58e-8dd3ba7c7146","_uuid":"dfc40eb3872c459aad0137034110d4cd3556be02","trusted":false,"collapsed":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4a4b0bf0-3e96-4494-8f48-da252f75905a","_uuid":"ab48f862b7c7b2ce566af7664cda5a42c312472a","trusted":false,"collapsed":true},"cell_type":"code","source":"train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fe409601-036a-4953-9fc2-8e86aa5c6440","_uuid":"b523e035d83bf6866f7610bb36c329f73b1e3e6a"},"cell_type":"markdown","source":"It is multi class classification problem having 6 classes"},{"metadata":{"_cell_guid":"cd826c35-1a43-4ec2-946a-cf1114c10aa2","_uuid":"eb950959d7a019655f6b6983f52cd582c18da855","trusted":false,"collapsed":true},"cell_type":"code","source":"train.columns[3:]\n#these are the 6 classes which we need to decide to which class a message belongs to","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"066f0810-323a-4fae-ac8a-8ed335150c95","_uuid":"d48f1b8a5cfb3d8d6e5b900cf6080bb6b8e69fdc","trusted":false,"collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"add6bdbc-66af-48d1-a3e1-dd982aa9f405","_uuid":"52db3c8d30df86eb74fd3664321e32bc63d33e8c"},"cell_type":"markdown","source":"If you can see in the above 6th message belongs to 4 classes, let us see what the message is"},{"metadata":{"_cell_guid":"d488f84b-312d-45ca-9a29-3edd06209102","_uuid":"8d4ff6fdacecf72685d6190e7869c1c496cafbfe","trusted":false,"collapsed":true},"cell_type":"code","source":"train['comment_text'][6]\n#it is really bad,isnt it?","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"80b1c9e9-266b-4bae-99c9-61a1cfab01dd","_uuid":"218da017ebc188fa1e2ab53a26db4b1b5883d050"},"cell_type":"markdown","source":"Now we have to clean the text which we call preprocessing of data, so that we can know which words causing to determine particular class"},{"metadata":{"_cell_guid":"fa190735-36b1-4934-86b3-03c9e5d10c25","_uuid":"a0cda267df20d55db20de2b163e09060cf659a22","trusted":false,"collapsed":true},"cell_type":"code","source":"train.comment_text.str.len().describe()\n#here the minimum length of a message is 6 as you can see the below table","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b2ed7582-b7f9-4b3e-871e-3ceb353d879e","_uuid":"e925f9a6fffa4b485cea25acf39635be4ee557c7"},"cell_type":"markdown","source":"if you remember some of the message dont belong either of 6 classes that means  all classes are marked as 0, now we have to find  how many messages are there."},{"metadata":{"_cell_guid":"c0f2f222-aef8-481f-be46-49a4d2d87c40","_uuid":"48c1f1a84a511d4942ebcf631ed988c21cd2aa41"},"cell_type":"markdown","source":"Now we'll create a seventh class and if a messge belongs to none of the 6 classes then it belongs to seventh class."},{"metadata":{"scrolled":true,"_cell_guid":"0fc9f902-a707-451d-8bb0-9e5d9c761bcf","_uuid":"1df49e8e0e0c9f224d9c197e2bcccaf38682c981","trusted":false,"collapsed":true},"cell_type":"code","source":"train['seventh'] = 1 - train[train.columns[2:]].max(axis =1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"83d035aa-94fa-4c9b-9901-92c401ff1b58","_uuid":"364ec65d46ca5c3d049ee9cdd013a1146ada4bfa","trusted":false,"collapsed":true},"cell_type":"code","source":"#we will see are there any null values \ntrain.isnull().any()\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3fe044da-fb9a-4039-b4be-c797eb2db53d","_uuid":"5e1934a978c00855a77668e48b5bdf2c19d679e7","trusted":false,"collapsed":true},"cell_type":"code","source":"print('you can find null values in train set like this also')\nprint(train.isnull().sum())\nprint('for test set null values are')\nprint(test.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"567fc278-41fd-404e-8513-02ab24a2a0e5","_uuid":"7268f455a1bc0c02d40796daa37be87315b2f144","trusted":false,"collapsed":true},"cell_type":"code","source":"# Here is the total number of samples belongs to each class\nx = train.iloc[:,2:].sum()\nprint('total number of comment:',len(train),'\\n','samples belongs to each class','\\n',x)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"28f68d68-aff2-4d33-873c-93b5f037b760","collapsed":true,"_uuid":"0f6e48f56420d898b2c32f9694cd97ee8ca87d0e","trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47d59b81-1160-46ba-b954-88563ff56f25","_uuid":"72baa099c7bbe8e21775965cec8ae4f3b76c005c","trusted":false,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(15,5))\nsns.barplot(x.index,x.values)\nplt.xticks(rotation=90)\nplt.title('class distribution')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e594be80-b92d-4044-afaf-60636503b4e3","_uuid":"41152ee50c348904342887a5c073757f9a1e0779"},"cell_type":"markdown","source":"Do you remember there are some messages which belongs to multiple classes and as you can see in the above image classes are also not evenlt spread,that means class imbalance also there, let us check how one class is correlated with other class with the help of heapmaps\n"},{"metadata":{"_cell_guid":"9719af45-cffc-467c-b358-6b0955a57ec4","_uuid":"04263206dc7892d4dff3df6adfc315e6341c6eba","trusted":false,"collapsed":true},"cell_type":"code","source":"y = train.corr()\nplt.figure(figsize=(8,8))\nsns.heatmap(y,annot=True,center=True,square=True)\nplt.title('heatmap showing correlation between classes')\nplt.show()\n#Here i intentionally included seventh class which we created","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1efc39c6-c833-4e86-99ca-49c0c66d032f","collapsed":true,"_uuid":"f8d6c9e2700f36650ae71bb685b66b84b482a39e","trusted":false},"cell_type":"code","source":"# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import cross_val_score\n# from scipy.sparse import hstack","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ac1c90ca-a3bc-4cad-9843-2f6009428ee0","_uuid":"9c10a17cef97c8323d00d9669cd59816ccaa6221"},"cell_type":"markdown","source":"**Actually i thought to finish it directly without exploring whole content but, it will be much helpful to newbies who want to learn if i do EDA from basic level\n**"},{"metadata":{"_cell_guid":"8984d688-d950-4644-82a3-41c8899c132e","_uuid":"813ab370104f7504703a02b73c6fe9889a006376","trusted":false,"collapsed":true},"cell_type":"code","source":"merge=pd.concat([train.iloc[:,0:2],test.iloc[:,0:2]])\ndf=merge.reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9e1e9c3c-1f55-448d-9c31-73be10035e07","_uuid":"ce62b3c95cea6df50c1d2fed3bf0e3a037bd242f","trusted":false,"collapsed":true},"cell_type":"code","source":"print('train shape',train.shape,'\\n','test shape',test.shape,'\\n','df shape',df.shape,'\\n')\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"378e400d-ee07-42e5-8f54-d5ae8f1e55b0","collapsed":true,"_uuid":"7e4bbefbf12a2054e5a84372f3f98c434ba2f18d","trusted":false},"cell_type":"code","source":"import re\nimport string\nfrom nltk.corpus import stopwords\nimport spacy\nfrom nltk import pos_tag\nfrom nltk.stem.wordnet import WordNetLemmatizer \nfrom nltk.tokenize import word_tokenize\n# Tweet tokenizer does not split at apostophes which is what we want\nfrom nltk.tokenize import TweetTokenizer   \n# start_time=time.time()\ncolor = sns.color_palette()\nsns.set_style(\"dark\")\neng_stopwords = set(stopwords.words(\"english\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nlem = WordNetLemmatizer()\ntokenizer=TweetTokenizer()\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"090a9e55-c24f-43f3-9da3-39fc6ec6080a","collapsed":true,"_uuid":"3f427e767b7cfafe65ee5d067603104ed6ec1732","trusted":false},"cell_type":"code","source":"#Sentense count in each comment:\n    #  '\\n' can be used to count the number of sentences in each comment\ndf['count_sent']=df[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\",str(x)))+1)\n#Word count in each comment:\ndf['count_word']=df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n#Unique word count\ndf['count_unique_word']=df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n#Letter count\ndf['count_letters']=df[\"comment_text\"].apply(lambda x: len(str(x)))\n#punctuation count\ndf[\"count_punctuations\"] =df[\"comment_text\"].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n#upper case words count\ndf[\"count_words_upper\"] = df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n#title case words count\ndf[\"count_words_title\"] = df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n#Number of stopwords\ndf[\"count_stopwords\"] = df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n#Average length of the words\n\ndf[\"mean_word_len\"] = df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"60753721-2e18-474b-88e5-d580ac82e72e","collapsed":true,"_uuid":"b1806cf641db1bb6b9017202143b9ea889c5f45c","trusted":false},"cell_type":"code","source":"df['ip'] = df['comment_text'].apply(lambda x: re.findall(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", str(x)))\ndf['count_ip']=df[\"ip\"].apply(lambda x: len(x))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eda024a1-37f9-4c22-bc3b-d87dd5c7fa58","_uuid":"cbe58afc7d95c506ccc77d40c1d8484681976de6"},"cell_type":"markdown","source":"I'll update more in coming future so watch this space.\n\n# Please upvote to encourage me.\n\n![](https://media3.giphy.com/media/l4FGpdrSHIcgR7Mli/200.webp#5-grid1)\n\n## Thank you all :)\n"},{"metadata":{"_cell_guid":"84bff4b3-058e-44dd-ab25-caab9e145226","collapsed":true,"_uuid":"57313a5a6500212ac0f92beb95518f1f198fcaae","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}