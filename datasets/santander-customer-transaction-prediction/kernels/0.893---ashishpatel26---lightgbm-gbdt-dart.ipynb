{"cells":[{"metadata":{"_uuid":"46abc24cb1488c323e96e80078aa929bf36913a3"},"cell_type":"markdown","source":"![](https://www.worldfinance.com/wp-content/uploads/2015/07/US-Fed-Santander-crackdown.jpg)\n### **1. Load Libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_auc_score\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import mean_squared_error\nimport gc\nimport time\nfrom pandas.core.common import SettingWithCopyWarning\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.model_selection import GroupKFold, GridSearchCV\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\n\n# I don't like SettingWithCopyWarnings ...\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"daeb619e9f3161272c34434f5fefbebefa2a719d"},"cell_type":"code","source":"# Display/plot feature importance\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances.png')\n    \ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"991a76b8e67c1e878cf8955de08d140849f90bfe"},"cell_type":"markdown","source":"### **2. Load Data**"},{"metadata":{"trusted":true,"_uuid":"327d2d48b69b4e374316052caad5b5acc98004b8"},"cell_type":"code","source":"def load_data():\n    train = pd.read_csv('../input/train.csv', low_memory=True)\n    test = pd.read_csv('../input/test.csv', low_memory=True)\n    return train,test\ntrain, test = load_data()\nprint(\"Train Shape:\", train.shape)\nprint(\"Test Shape:\",test.shape)\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0714446e8f2f981e9244c3059ae4acefb9ca5cd6"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cecdd4a7a90aff5c5561710fdf85316a9c499a1"},"cell_type":"markdown","source":"### **3.Target Variable Distribution**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"33abacdf4d0bffa36bdf0569f0d6cd0730d429ed"},"cell_type":"code","source":"train['target'].value_counts().plot(kind=\"barh\", figsize=(20,8))\nfor i, v in enumerate(train['target'].value_counts()):\n    plt.text(v, i, str(v), fontweight='bold', fontsize = 20)\nplt.xlabel(\"Count\", fontsize=12)\nplt.ylabel(\"State of the target\", fontsize=12)\nplt.title(\"Target repartition\", fontsize=15)\nplt.legend()\nplt.show()\n\ny = train.pop('target')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"352287781e6f8c60696e052f7993af58b0178c34"},"cell_type":"code","source":"train.pop('ID_code')\ntest.pop('ID_code')\ntr_col = train.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6467c9c3170786d36f75a26e620ff9e75637408c"},"cell_type":"markdown","source":"### ***We can see that imbalance Class Problem***\n\n| State | Count |\n|--|--|\n|**0**|**179902**|\n|**1**|**20098**|\n\n## ***4.Solve Imbalance Class problem using SMOTE ANALYSIS***"},{"metadata":{"trusted":true,"_uuid":"07e440975daab82be6d55c45d0959314f6e361a2"},"cell_type":"code","source":"# train_df,y = SMOTE().fit_resample(train,y.ravel())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"db7372df348ec505c6ba693415849a93174956fe"},"cell_type":"code","source":"# train_df = pd.DataFrame(train_df)\n# train_df.columns = tr_col\n# train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"d589a815354f01a11137fb1a4d5567b3f52889e8"},"cell_type":"code","source":"# y = pd.Series(y)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1def083efef0f2b72768a8235fb3b8a9af899484"},"cell_type":"code","source":"train_df = train.copy(deep=True)\nprint(\"Train Shape:\", train_df.shape)\nprint(\"Target Shape:\", y.shape)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"b3b23295ca7aecf249b71558978b13af4e270980"},"cell_type":"code","source":"# y.value_counts().plot(kind=\"barh\", figsize=(20,8))\n# for i, v in enumerate(y.value_counts()):\n#     plt.text(v, i, str(v), fontweight='bold', fontsize = 20)\n# plt.xlabel(\"Count\", fontsize=12)\n# plt.ylabel(\"State of the target\", fontsize=12)\n# plt.title(\"Target repartition\", fontsize=15)\n# plt.legend()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d7da69b6f6c098191277004ed098f2f8ab03c65"},"cell_type":"markdown","source":"## **5. Final Shape for Training**"},{"metadata":{"trusted":true,"_uuid":"a7954cfd135017457d52c2d397bf159f21c5d6f1"},"cell_type":"code","source":"test_df = test.copy(deep=True)\nprint(\"Train Shape:\", train_df.shape)\nprint(\"Target Shape:\", y.shape)\nprint(\"Test Shape:\", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c15d7d900fe3e2cb2015a7d87f36df81d5eeb0e1"},"cell_type":"code","source":"train_df = StandardScaler().fit_transform(train_df)\ntest_df = StandardScaler().fit_transform(test_df)\ntrain_df.shape,test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0dc68fd908b0968dc3fe58f94495500e98fb7d93"},"cell_type":"code","source":"train_df = pd.DataFrame(train_df)\ntrain_df.columns = tr_col","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d02274a76d1ff1fe723ad9917885bbead9ed1b5"},"cell_type":"markdown","source":"## **6.Model Training LightGBM**"},{"metadata":{"trusted":true,"_uuid":"50cabf47de6ffab73a689aba6cce659aa0d3efe9"},"cell_type":"code","source":"boosting = [\"goss\",\"dart\"]\ndef kfold_lightgbm(train_df, test_df, num_folds, stratified = False, boosting = boosting[0]):\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=326)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=2045)\n\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    \n    # k-fold\n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df, y)):\n        train_x, train_y = train_df.iloc[train_idx], y.iloc[train_idx]\n        valid_x, valid_y = train_df.iloc[valid_idx], y.iloc[valid_idx]\n\n        # set data structure\n        lgb_train = lgb.Dataset(train_x,label=train_y,free_raw_data=False)\n        lgb_test = lgb.Dataset(valid_x,label=valid_y,free_raw_data=False)\n\n        # params optimized by optuna\n        params ={\n                        'task': 'train',\n                        'boosting': 'goss',\n                        'objective': 'binary',\n                        'metric': 'auc',\n                        'learning_rate': 0.01,\n                        'subsample': 0.8,\n                        'max_depth': -1,\n                        'top_rate': 0.9064148448434349,\n                        'num_leaves': 32,\n                        'min_child_weight': 41.9612869171337,\n                        'other_rate': 0.0721768246018207,\n                        'reg_alpha': 9.677537745007898,\n                        'colsample_bytree': 0.5665320670155495,\n                        'min_split_gain': 9.820197773625843,\n                        'reg_lambda': 8.2532317400459,\n                        'min_data_in_leaf': 21,\n                        'verbose': -1,\n                        'seed':int(2**n_fold),\n                        'bagging_seed':int(2**n_fold),\n                        'drop_seed':int(2**n_fold)\n                        }\n\n        reg = lgb.train(\n                        params,\n                        lgb_train,\n                        valid_sets=[lgb_train, lgb_test],\n                        valid_names=['train', 'test'],\n                        num_boost_round=7000,early_stopping_rounds= 200,\n                        verbose_eval=100,\n                        )\n\n        oof_preds[valid_idx] = reg.predict(valid_x, num_iteration=reg.best_iteration)\n        sub_preds += reg.predict(test_df, num_iteration=reg.best_iteration) / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = train_x.columns\n        fold_importance_df[\"importance\"] = np.log1p(reg.feature_importance(importance_type='gain', iteration=reg.best_iteration))\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d roc_auc_score : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del reg, train_x, train_y, valid_x, valid_y\n        gc.collect()\n\n    # display importances\n    display_importances(feature_importance_df)\n    \n        # save submission file\n    submission = pd.read_csv(\"../input/sample_submission.csv\")\n    submission['target'] = sub_preds\n    submission.to_csv(boosting+\".csv\", index=False)\n    display(submission.head())\n    return (submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"719c3e5219b261ccf5fa752394387fd478639487"},"cell_type":"code","source":"submission = kfold_lightgbm(train_df, test_df, num_folds=5, stratified=True, boosting=boosting[0])   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcd79bd3a988b02e034a9847798cf2dec7793f08"},"cell_type":"code","source":"submission1 = kfold_lightgbm(train_df, test_df, num_folds=5, stratified=True, boosting=boosting[1])   ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}