{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "_is_fork": false, "language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "_change_revision": 0}, "nbformat_minor": 0, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "a92643e84565fa3426ce981b3c1e0467c37c2b93", "_cell_guid": "03929b38-8ebe-0966-801e-1c5d5b81b3a5"}, "outputs": [], "source": "", "execution_count": null}, {"cell_type": "code", "metadata": {"_uuid": "2f34c15e20b6f9aa65d76df531e69e3e7ad9652a", "_cell_guid": "23cc9322-2fa6-dbd0-cc9f-bb054e877052", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "execution_count": 1}, {"cell_type": "code", "metadata": {"_uuid": "52b85e14e4334640fe8cb693ccc52f44323b03e5", "_cell_guid": "c9ecb172-a248-34b1-d781-84d1e69bb13a", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "import numpy as np # linear algebra\nimport pandas as pd\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# read datasets\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\ntrain.head()\n#(Initial code borrowed from this notebook: https://www.kaggle.com/uluumy/mercedez-baseline-2)", "execution_count": 2}, {"cell_type": "code", "metadata": {"_uuid": "747a0922d021ef9a6dedb55be728867f2649beb5", "_cell_guid": "26bb7f3b-0069-731d-cc2f-283d3b25d4b2", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "X_train = train.drop('y', axis = 1)\nY_train = train['y']", "execution_count": 3}, {"cell_type": "code", "metadata": {"_uuid": "2be80f6a2af679ac54a76524e8937822b6b6646e", "_cell_guid": "2911118b-0dc6-a333-dbe6-206928003992", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn import linear_model, decomposition, datasets\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import make_scorer\n    \nr2 = make_scorer(r2_score)\nn_components = [100, 200, 300, 350]\n\nregr = linear_model.Ridge()\npca = decomposition.PCA()\npipe = Pipeline(steps=[('pca', pca), ('linear', regr)])\n\nestimator = GridSearchCV(pipe,dict(pca__n_components=n_components, linear__alpha = [0.0, 1.0, 2.0, 4.0, 16.0, 32.0, 64.0, 128.0, 256.0]),verbose = 1, scoring = r2)\n\nestimator.fit(X_train, Y_train)\n\nplt.axvline(estimator.best_estimator_.named_steps['pca'].n_components,\n            linestyle=':', label='n_components chosen')\nplt.legend(prop=dict(size=12))\nplt.show()", "execution_count": null}, {"cell_type": "code", "metadata": {"_uuid": "51900be9da28a18828886527a393122a479c7a4b", "_cell_guid": "58508845-984d-aaa1-7eb9-73b029a114bf", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "y_pred = estimator.predict(test)", "execution_count": 7}, {"cell_type": "code", "metadata": {"_uuid": "ff82235c46af4515ef1b43cd288219feba17bddb", "_cell_guid": "4154d98e-c853-301e-5504-d751eff1ff01", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "ID = list(test['ID'])\ny_pred = list(y_pred)\nprint (y_pred[:5], ID[:5])", "execution_count": 8}, {"cell_type": "code", "metadata": {"_uuid": "36d16e1ada89b009e4f53003598f212842e89307", "_cell_guid": "9d64a7db-40c4-9c7f-0238-c9adcc13b823", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "outputfile = open('result.csv', \"w+\")\noutputfile.write(\"ID,y\\n\")\nprint (len(ID), len(y_pred))\nfor i in range(len(ID)):\n    outputfile.write(str(ID[i])+ \",\" + str(y_pred[i])+\"\\n\" )\noutputfile.close()    \n    ", "execution_count": 9}, {"cell_type": "code", "metadata": {"_uuid": "3cdeae17f0398b354481dbb3d95b6a10488b7843", "collapsed": false, "_cell_guid": "cfbf4bd6-31a6-429e-9092-595736b76270", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "estimator.cv_results_", "execution_count": 6}, {"cell_type": "code", "metadata": {"_uuid": "c41c2dc4109404ccbc44cf7a92935a9c69db0a24", "collapsed": false, "_cell_guid": "c8680609-7815-4ab9-94d1-beffbc8d0ae2", "trusted": false, "_execution_state": "idle"}, "outputs": [], "source": "", "execution_count": null}], "nbformat": 4}