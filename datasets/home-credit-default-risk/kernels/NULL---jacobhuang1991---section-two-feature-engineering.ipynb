{"cells":[{"metadata":{"_uuid":"7a2f7d90e73458354ca18a8d9a15cfec6b61c827"},"cell_type":"markdown","source":"<h1 style=\"text-align:center\">INFSCI 2595 Machine Learning Project</h1>\n<h2 style=\"text-align:center\">Home Credit Default Risk</h2>\n<h5 style=\"text-align:center\">Members: Chih Ying Chang, Xinghao Huang, Yuanyuan Zhang</h5>"},{"metadata":{"_uuid":"cbefe87e5da781c5746b856b5ee70946cbc247dc"},"cell_type":"markdown","source":"# Section Two: Feature Engineering"},{"metadata":{"_uuid":"e24d79d821eba90266defa89a000d3afe1506d37"},"cell_type":"markdown","source":" In this section, we will include two more data to improve accuracy. To merge these two new data, we first take different methods to numeric and categorical columns. For numeric features, we calculate ``'mean', 'max', 'min', 'sum'`` and add them into the train data. For categorical features, we calculate the sum of each category and then normalized as the new feature to insert to the train data. In these ways, we get new data.  \n \nBefore training the model, we also remove the collinear features to improve accuracy. \n\nIn this section, we also take the light GBM  instead of Logistic Regression Model. The results show that the new method is more effective than the baseline method."},{"metadata":{"_uuid":"2a0c767de43b7435aded788cb2a32028f9fec675"},"cell_type":"markdown","source":"## 1. Data Description"},{"metadata":{"_uuid":"2b479a7859afab4abd338d39a5ef3ccaddef4d87"},"cell_type":"markdown","source":"The information of two more data is listed below.\n\nbureau: information about client's previous loans with other financial institutions reported to Home Credit. Each previous loan has its own row.\nbureau_balance: monthly information about the previous loans. Each month has its own row."},{"metadata":{"_uuid":"a96b732c5c515838202c2846ca761698ceaa07ae"},"cell_type":"markdown","source":"## 2. Insert New Data"},{"metadata":{"trusted":true,"_uuid":"829d952762e7d4057a7bf3fdbd61e07de59359f9"},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import linear_model\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nimport gc\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import PolynomialFeatures\n\nimport time\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"528b4d9fcb3d3cbfec0ef43195236f6889c9dc52"},"cell_type":"markdown","source":"# bureau.csv Data Preprocessing"},{"metadata":{"_uuid":"c15fd0fb3b4d4087ae44f7b9ffb0c057d1f19507","trusted":true},"cell_type":"code","source":"# import other datasets\nbureau = pd.read_csv('../input/bureau.csv')\nprevious_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n# Join to the training dataframe\ntrain = pd.read_csv('../input/application_train.csv')\ntrain = train.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Fill the missing values with 0 \ntrain['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c604b19f3a668d997da38be974e4c33f79a8c5f"},"cell_type":"markdown","source":"### Aggregating Numeric Columns\nTo account for the numeric information in the `bureau` dataframe, we can compute statistics for all the numeric columns. To do so, we `groupby` the client id, `agg` the grouped dataframe, and merge the result back into the training data. The `agg` function will only calculate the values for the numeric columns where the operation is considered valid. We will stick to using `'mean', 'max', 'min', 'sum'`."},{"metadata":{"_uuid":"7cf167616c7899531b2fe4d2df7e1e6bd377b77f","trusted":true},"cell_type":"code","source":"def agg_numeric(df, group_var, df_name):\n    # Remove id variables other than grouping variable\n    for col in df:\n        if col != group_var and 'SK_ID' in col:\n            df = df.drop(columns = col)\n            \n    group_ids = df[group_var]\n    numeric_df = df.select_dtypes('number')\n    numeric_df[group_var] = group_ids\n\n    # Group by the specified variable and calculate the statistics\n    agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n\n    # Need to create new column names\n    columns = [group_var]\n\n    # Iterate through the variables names\n    for var in agg.columns.levels[0]:\n        # Skip the grouping variable\n        if var != group_var:\n            # Iterate through the stat names\n            for stat in agg.columns.levels[1][:-1]:\n                # Make a new column name for the variable and stat\n                columns.append('%s_%s_%s' % (df_name, var, stat))\n\n    agg.columns = columns\n    return agg","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8287bbf56e2dd3f3f12843f6492de56ed4e4143b","trusted":true},"cell_type":"code","source":"bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e55a062ec2cc48d3dbb7076660e71f0bb432d774"},"cell_type":"markdown","source":"### Add Categorical Columns\nWe also want to add the categorical variables to the data. However, since they are not continuous data, we cannot calculate statistics. Instead, we calculate the counts of each category, and then normalized the data. "},{"metadata":{"_uuid":"dd950d1765b491c63599e3a61740416659a6e360","trusted":true},"cell_type":"code","source":"def count_categorical(df, group_var, df_name):\n    # Select the categorical columns\n    categorical = pd.get_dummies(df.select_dtypes('object'))\n\n    # Make sure to put the identifying id on the column\n    categorical[group_var] = df[group_var]\n\n    # Groupby the group var and calculate the sum and mean\n    categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n    \n    column_names = []\n    \n    # Iterate through the columns in level 0\n    for var in categorical.columns.levels[0]:\n        # Iterate through the stats in level 1\n        for stat in ['count', 'count_norm']:\n            # Make a new column name\n            column_names.append('%s_%s_%s' % (df_name, var, stat))\n    \n    categorical.columns = column_names\n    \n    return categorical","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"17b0731ca791e04583c372734ec182ec9778b2e4","trusted":true},"cell_type":"code","source":"bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\nbureau_counts.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15b631d2eb0e2db0029cfbd1f8e82acec4cb795e"},"cell_type":"markdown","source":"# bureau_balance.csv Data Preprocessing"},{"metadata":{"_uuid":"1bad64e73b1a7f27a34fa88fd645980edd4a5eef","trusted":true},"cell_type":"code","source":"# Read in bureau balance\nbureau_balance = pd.read_csv('../input/bureau_balance.csv')\nbureau_balance.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67e1d6e5549925cd053b91c3724b013ed5ed0972","trusted":true},"cell_type":"code","source":"# Calculate value count statistics for each `SK_ID_CURR` \nbureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71ea88714ce0298b59716bede78cbe94d9ec3c80","trusted":true},"cell_type":"code","source":"# Counts of each type of status for each previous loan\nbureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\nbureau_balance_counts.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6701be56d5ba9bd0535bdfeda87776efa5931eca"},"cell_type":"markdown","source":"# Merge Data"},{"metadata":{"_uuid":"30e276cb134c9d02d8e31b324e31663c7c499458","trusted":true},"cell_type":"code","source":"# Dataframe grouped by the loan\nbureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n\n# Merge to include the SK_ID_CURR\nbureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], on = 'SK_ID_BUREAU', how = 'left')\n\nbureau_by_loan.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e24a8c4be72dd26fc6502d193005115114c56a2","trusted":true},"cell_type":"code","source":"bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')\nbureau_balance_by_client.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"609be6ecac00965ca524dccea75d31ff6d9d7fe2"},"cell_type":"markdown","source":"# Insert New Data into Training Data"},{"metadata":{"_uuid":"4eb662e0b2db9e00a82eebb85cc62ee82742a81d","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/application_train.csv')\noriginal_features = list(train.columns)\nprint('Original Number of Features: ', len(original_features))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cdcdf006bb081480e1a76252cba965eb188a68d1","trusted":true},"cell_type":"code","source":"# Merge with the value counts of bureau\ntrain = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the stats of bureau\ntrain = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the monthly information grouped by client\ntrain = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72754a66ac47431b04558da2655cf712a5e0f967","trusted":true},"cell_type":"code","source":"new_features = list(train.columns)\nprint('Number of features using previous loans from other institutions data: ', len(new_features))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0ab58b3de04bb59197e0c54a085d8c9cc4a1abf"},"cell_type":"markdown","source":"# Calculate Information for Testing Data"},{"metadata":{"_uuid":"8a279f1be66f5291b893c061029ed130fa6a37f7","trusted":true},"cell_type":"code","source":"# Read in the test dataframe\ntest = pd.read_csv('../input/application_test.csv')\n\n# Merge with the value counts of bureau\ntest = test.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the stats of bureau\ntest = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n\n# Merge with the value counts of bureau balance\ntest = test.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')\nprint('Shape of Testing Data: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b5e7ae5b4cd3929f1874deb0cd900667cdc0e0b"},"cell_type":"markdown","source":"# Align Training and Testing Data"},{"metadata":{"_uuid":"2b2ccebd9b6175e4894e0c789fa5e02493230c9b","trusted":true},"cell_type":"code","source":"train_labels = train['TARGET']\n\n# Align the dataframes, this will remove the 'TARGET' column\ntrain, test = train.align(test, join = 'inner', axis = 1)\n\ntrain['TARGET'] = train_labels\nprint('Training Data Shape: ', train.shape)\nprint('Testing Data Shape: ', test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a48eddd7859bfb17e3b1730f6976880657fe8cc9","trusted":true},"cell_type":"code","source":"train.to_csv('train_bureau_raw.csv', index = False)\ntest.to_csv('test_bureau_raw.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68c1f5c9aaf4430f6dd0c64ff95d31c4e481a623"},"cell_type":"markdown","source":"# Correlations Analysis"},{"metadata":{"_uuid":"17159503e7a0fe94fc0b8ca1fbe82e31fd1f561a","trusted":true},"cell_type":"code","source":"# Calculate all correlations in dataframe\ncorrs = train.corr()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18d00e1d42438f312591c530e60129343975741c","trusted":true},"cell_type":"code","source":"corrs = corrs.sort_values('TARGET', ascending = False)\n\n# Ten most positive correlations\npd.DataFrame(corrs['TARGET'].head(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c991d8a3bf22f7ab4c7c13bec8a31e86f31b820","trusted":true},"cell_type":"code","source":"# Ten most negative correlations\npd.DataFrame(corrs['TARGET'].dropna().tail(10))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de40793d7fde4b40b3ae6ac07c156c4e7840474e"},"cell_type":"markdown","source":"# Remove Collinear Variables\n\nWe can calculate not only the correlations of the variables with the target, but also the correlation of each variable with every other variable. This will allow us to see if there are highly collinear variables that should perhaps be removed from the data. \n\nIn this section, we remove the features whose correlations are greather than 0.8  with other variables."},{"metadata":{"_uuid":"2451d08a0137a7b86982fd7671d0ed1800a66a2c","trusted":true},"cell_type":"code","source":"# Set the threshold\nthreshold = 0.8\n\n# Empty dictionary to hold correlated variables\nabove_threshold_vars = {}\n\n# For each column, record the variables that are above the threshold\nfor col in corrs:\n    above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88bddcf220be6a2757722f22702cbc9854aca1c6"},"cell_type":"markdown","source":"For each of these pairs of highly correlated variables, we only want to remove one of the variables. The following code creates a set of variables to remove by only adding one of each pair. "},{"metadata":{"_uuid":"21c0822e837ca2e610660e22f2d3ff69781ec29f","trusted":true},"cell_type":"code","source":"# Track columns to remove and columns already examined\ncols_to_remove = []\ncols_seen = []\ncols_to_remove_pair = []\n\n# Iterate through columns and correlated columns\nfor key, value in above_threshold_vars.items():\n    # Keep track of columns already examined\n    cols_seen.append(key)\n    for x in value:\n        if x == key:\n            next\n        else:\n            # Only want to remove one in a pair\n            if x not in cols_seen:\n                cols_to_remove.append(x)\n                cols_to_remove_pair.append(key)\n            \ncols_to_remove = list(set(cols_to_remove))\nprint('Number of columns to remove: ', len(cols_to_remove))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2647243a8275b66c8d80f1cd444a5785673dd698","trusted":true},"cell_type":"code","source":"train_corrs_removed = train.drop(columns = cols_to_remove)\ntest_corrs_removed = test.drop(columns = cols_to_remove)\n\nprint('Training Corrs Removed Shape: ', train_corrs_removed.shape)\nprint('Testing Corrs Removed Shape: ', test_corrs_removed.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5467b4c78128d464832313b38c882adf029ceee","trusted":true},"cell_type":"code","source":"train_corrs_removed.to_csv('train_bureau_corrs_removed.csv', index = False)\ntest_corrs_removed.to_csv('test_bureau_corrs_removed.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e288838f9a2be2eca604a3bc12ccbf39cf211186"},"cell_type":"markdown","source":"# Machine Learning Model"},{"metadata":{"_uuid":"190959ccd5d8f4a9379cc7fb3c7201cc038f8575"},"cell_type":"markdown","source":"We use three different kinds of data to get the prediction accuracy to check if our feature engineering methods are valid. We also use the LightBGM model.\n\n* dateset1: only the data in the `application` files. \n* dateset2: the data in the `application` files with all of the data recorded from the `bureau` and `bureau_balance` files\n* dateset3: the data in the `application` files with all of the data recorded from the `bureau` and `bureau_balance` files with highly correlated variables removed. "},{"metadata":{"_uuid":"43872ef54065ab45d07f997856ba56e53d0c71d1","trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\nimport gc\n\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2bfd9036d3ed460a3dbd0714e3c6ebad22acee92","trusted":true},"cell_type":"code","source":"def model(features, test_features, encoding = 'ohe', n_folds = 5):\n    # Extract the ids\n    train_ids = features['SK_ID_CURR']\n    test_ids = test_features['SK_ID_CURR']\n    \n    # Extract the labels for training\n    labels = features['TARGET']\n    \n    # Remove the ids and target\n    features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n    test_features = test_features.drop(columns = ['SK_ID_CURR'])\n    \n    \n    # One Hot Encoding\n    if encoding == 'ohe':\n        features = pd.get_dummies(features)\n        test_features = pd.get_dummies(test_features)\n        \n        # Align the dataframes by the columns\n        features, test_features = features.align(test_features, join = 'inner', axis = 1)\n        \n        # No categorical indices to record\n        cat_indices = 'auto'\n    \n    # Integer label encoding\n    elif encoding == 'le':\n        \n        # Create a label encoder\n        label_encoder = LabelEncoder()\n        \n        # List for storing categorical indices\n        cat_indices = []\n        \n        # Iterate through each column\n        for i, col in enumerate(features):\n            if features[col].dtype == 'object':\n                # Map the categorical features to integers\n                features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1,)))\n                test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1,)))\n\n                # Record the categorical indices\n                cat_indices.append(i)\n    \n    # Catch error if label encoding scheme is not valid\n    else:\n        raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n        \n    print('Training Data Shape: ', features.shape)\n    print('Testing Data Shape: ', test_features.shape)\n    \n    # Extract feature names\n    feature_names = list(features.columns)\n    \n    # Convert to np arrays\n    features = np.array(features)\n    test_features = np.array(test_features)\n    \n    # Create the kfold object\n    k_fold = KFold(n_splits = n_folds, shuffle = False, random_state = 50)\n    \n    # Empty array for feature importances\n    feature_importance_values = np.zeros(len(feature_names))\n    \n    # Empty array for test predictions\n    test_predictions = np.zeros(test_features.shape[0])\n    \n    # Empty array for out of fold validation predictions\n    out_of_fold = np.zeros(features.shape[0])\n    \n    # Lists for recording validation and training scores\n    valid_scores = []\n    train_scores = []\n    \n    # Iterate through each fold\n    for train_indices, valid_indices in k_fold.split(features):\n        \n        # Training data for the fold\n        train_features, train_labels = features[train_indices], labels[train_indices]\n        # Validation data for the fold\n        valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n        \n        # Create the model\n        model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n                                   class_weight = 'balanced', learning_rate = 0.05, \n                                   reg_alpha = 0.1, reg_lambda = 0.1, \n                                   subsample = 0.8, n_jobs = -1, random_state = 50)\n        \n        # Train the model\n        model.fit(train_features, train_labels, eval_metric = 'auc',\n                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n                  eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n                  early_stopping_rounds = 100, verbose = 200)\n        \n        # Record the best iteration\n        best_iteration = model.best_iteration_\n        \n        # Record the feature importances\n        feature_importance_values += model.feature_importances_ / k_fold.n_splits\n        \n        # Make predictions\n        test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n        \n        # Record the out of fold predictions\n        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n        \n        # Record the best score\n        valid_score = model.best_score_['valid']['auc']\n        train_score = model.best_score_['train']['auc']\n        \n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        \n        # Clean up memory\n        gc.enable()\n        del model, train_features, valid_features\n        gc.collect()\n        \n    # Make the submission dataframe\n    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n    \n    # Make the feature importance dataframe\n    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n    \n    # Overall validation score\n    valid_auc = roc_auc_score(labels, out_of_fold)\n    \n    # Add the overall scores to the metrics\n    valid_scores.append(valid_auc)\n    train_scores.append(np.mean(train_scores))\n    \n    # Needed for creating dataframe of validation scores\n    fold_names = list(range(n_folds))\n    fold_names.append('overall')\n    \n    # Dataframe of validation scores\n    metrics = pd.DataFrame({'fold': fold_names,\n                            'train': train_scores,\n                            'valid': valid_scores}) \n    \n    return submission, feature_importances, metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ed78dd5c861b4ccb1e71d2dc2c3440151ec4878","trusted":true},"cell_type":"code","source":"# plot the importances of features\ndef plot_feature_importances(df):\n    # Sort features according to importance\n    df = df.sort_values('importance', ascending = False).reset_index()\n    \n    # Normalize the feature importances to add up to one\n    df['importance_normalized'] = df['importance'] / df['importance'].sum()\n\n    # Make a horizontal bar chart of feature importances\n    plt.figure(figsize = (10, 6))\n    ax = plt.subplot()\n    \n    # Need to reverse the index to plot most important on top\n    ax.barh(list(reversed(list(df.index[:15]))), \n            df['importance_normalized'].head(15), \n            align = 'center', edgecolor = 'k')\n    \n    # Set the yticks and labels\n    ax.set_yticks(list(reversed(list(df.index[:15]))))\n    ax.set_yticklabels(df['feature'].head(15))\n    \n    # Plot labeling\n    plt.xlabel('Normalized Importance'); plt.title('Feature Importances')\n    plt.show()\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"590f8dfc80c746976fb1bc66212996017453f0b6"},"cell_type":"markdown","source":"# Dataset 1 Result"},{"metadata":{"_uuid":"4d593e5fd426b492c623f0869b394b9d58d483a6","trusted":true},"cell_type":"code","source":"train_control = pd.read_csv('../input/application_train.csv')\ntest_control = pd.read_csv('../input/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a53efd1d33e59b154d30a98aa5af38b4f958ef53","trusted":true},"cell_type":"code","source":"submission, fi, metrics = model(train_control, test_control)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"767b33a128d650411cfacee58e66798ae15927bc","trusted":true},"cell_type":"code","source":"metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a93a9f811880f45ff8376b33de83058aee6cc35","trusted":true},"cell_type":"code","source":"fi_sorted = plot_feature_importances(fi)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0930f225ea0aa686673f25262707b1f3ed1bf31","trusted":true},"cell_type":"code","source":"submission.to_csv('control.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b0530c700a963289d55f67ac0ad2b16fc95cc23"},"cell_type":"markdown","source":"![](https://i.postimg.cc/XNH6bYHv/dataset1.png)","attachments":{}},{"metadata":{"_uuid":"802faee0693526a3bae4a8be2a730a2aacfa1d21"},"cell_type":"markdown","source":"# Dataset 2 Result"},{"metadata":{"_uuid":"527e24d38ae1fc33d00c24ef92141fb6dc77ad9b","trusted":true},"cell_type":"code","source":"submission_raw, fi_raw, metrics_raw = model(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d71df4ca05956385749cc450b58c9da32ffbebef"},"cell_type":"code","source":"metrics_raw","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f7e78b6ab2dc4b960fb0c9755fbc3cbf06c9cad","trusted":true},"cell_type":"code","source":"fi_raw_sorted = plot_feature_importances(fi_raw)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a7eddba8fb888c2cbc1fa9d189bff432a0c3291","trusted":true},"cell_type":"code","source":"submission_raw.to_csv('test_one.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c810ea78e876666a5d4aeaa0e3cd43d9bf0f17b"},"cell_type":"markdown","source":"![](https://i.postimg.cc/8P7QPg9m/dataset2.png)","attachments":{}},{"metadata":{"_uuid":"68ac7905ca571ed074a29a322576ea6bf4116b82"},"cell_type":"markdown","source":"# Dataset 3 Result"},{"metadata":{"_uuid":"e57bc26b2e470820cbf6997d4983ecae2e29ca67","trusted":true},"cell_type":"code","source":"submission_corrs, fi_corrs, metrics_corr = model(train_corrs_removed, test_corrs_removed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb4103d9c17fd39f8695a48a6c18273f5d44ac7b"},"cell_type":"code","source":"metrics_corr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa977f989150875149b43e9501aad42078d6ae30"},"cell_type":"code","source":"fi_corrs_sorted = plot_feature_importances(fi_corrs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0193f0221a6bd72e3478fdcbc030dd812b8b1a"},"cell_type":"code","source":"submission_corrs.to_csv('test_two.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ca3458e9fcfc90178440a35bd34c37688ba4879"},"cell_type":"markdown","source":"![](https://i.postimg.cc/dtgMhSKP/dataset3.png)","attachments":{}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}