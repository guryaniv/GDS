{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e9e2b0da-44de-722d-5850-3b408fa380b0"
      },
      "source": [
        "# Leaf Classification - Forked\n",
        "## Using Neural Networks through Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "faa42311-1ae2-1e94-cbae-f67fb8f8262f"
      },
      "source": [
        "__author__ : Najeeb Khan, Yasir Mir, Zafarullah Mahmood\n",
        "\n",
        "__team__ : artificial_stuPiDity\n",
        "\n",
        "__institution__ : Jamia Millia Islamia\n",
        "\n",
        "__email__ : najeeb.khan96@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2295c62-b360-c048-ab1c-a19e91218aad"
      },
      "outputs": [],
      "source": [
        "## Importing standard libraries\n",
        "\n",
        "%pylab inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "889c7da9-1760-d487-2a51-c599979ca93e"
      },
      "outputs": [],
      "source": [
        "## Importing sklearn libraries\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17ff0a6b-735f-a0b1-2e7f-368c16d1a5bf"
      },
      "outputs": [],
      "source": [
        "## Keras Libraries for Neural Networks\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Activation\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fec5a6b6-271f-36e0-a593-a2a258d39bea"
      },
      "outputs": [],
      "source": [
        "## Set figure size to 20x10\n",
        "\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 10,10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3883e40b-48fb-03e4-d365-d01af7505e84"
      },
      "outputs": [],
      "source": [
        "## Read data from the CSV file\n",
        "\n",
        "data = pd.read_csv('../input/train.csv')\n",
        "parent_data = data.copy()    ## Always a good idea to keep a copy of original data\n",
        "ID = data.pop('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ad8b1ad-c973-acff-9a77-080e0aef557e"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dacc91e2-d384-5979-0207-66dd145004f9"
      },
      "outputs": [],
      "source": [
        "## Since the labels are textual, so we encode them categorically\n",
        "\n",
        "y = data.pop('species')\n",
        "y = LabelEncoder().fit(y).transform(y)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "262251c4-2ca1-5a1b-f67d-cf47b7763976"
      },
      "outputs": [],
      "source": [
        "## Most of the learning algorithms are prone to feature scaling\n",
        "## Standardising the data to give zero mean =)\n",
        "\n",
        "X = StandardScaler().fit(data).transform(data)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6041431-1433-762e-d0e0-91aadb8c3370"
      },
      "outputs": [],
      "source": [
        "## We will be working with categorical crossentropy function\n",
        "## It is required to further convert the labels into \"one-hot\" representation\n",
        "\n",
        "y_cat = to_categorical(y)\n",
        "print(y_cat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4be105f5-77a6-8c46-182f-42b7241cf150"
      },
      "outputs": [],
      "source": [
        "## Developing a layered model for Neural Networks\n",
        "## Input dimensions should be equal to the number of features\n",
        "## We used softmax layer to predict a uniform probabilistic distribution of outcomes\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024,input_dim=192,  init='uniform', activation='relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(99, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3135f21f-367c-77b7-2fd9-6190296820bd"
      },
      "outputs": [],
      "source": [
        "## Error is measured as categorical crossentropy or multiclass logloss\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52ed1c8d-6dc0-7a91-9828-849ed28c45d0"
      },
      "outputs": [],
      "source": [
        "## Fitting the model on the whole training data\n",
        "history = model.fit(X,y_cat,batch_size=32,\n",
        "                    nb_epoch=400,verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da15432c-9c08-8971-04bd-10a8390aba17"
      },
      "outputs": [],
      "source": [
        "#validation:\n",
        "\n",
        "#scores = pd.DataFrame(history.history)\n",
        "#min(scores['val_loss'])\n",
        "#scores.loc[20:,[\"loss\", \"val_loss\"]].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3db1966d-9374-7e6e-6242-6e84b89208f3"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d6158f6-2cc5-6e93-6adb-50cff868ab5f"
      },
      "outputs": [],
      "source": [
        "index = test.pop('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "12f9a9a1-662f-d86b-a653-0405dc0c68ee"
      },
      "outputs": [],
      "source": [
        "test = StandardScaler().fit(test).transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cc41c459-4afe-245c-940a-4ec69de27fce"
      },
      "outputs": [],
      "source": [
        "yPred = model.predict_proba(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5004cb45-6612-b245-3bf1-30e28a0a77d0"
      },
      "outputs": [],
      "source": [
        "## Converting the test predictions in a dataframe as depicted by sample submission\n",
        "\n",
        "yPred = pd.DataFrame(yPred,index=index,columns=sort(parent_data.species.unique()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0754597d-f556-9bb2-df3b-6b94dd60d9d7"
      },
      "outputs": [],
      "source": [
        "fp = open('submission_nn_kernel.csv','w')\n",
        "fp.write(yPred.to_csv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8bbde5ef-340e-9b2b-84d1-390e813a38f8"
      },
      "source": [
        "---------\n",
        "\n",
        "Earlier` we used a 4 layer network but the result came out to be overfitting the test set. We dropped the count of neurones in the network and also restricted the number of layers to 3 so as to keep it simple.\n",
        "Instead of submitting each test sample as a one hot vector we submitted each samples as a probabilistic distribution over all the possible outcomes. This \"may\" help reduce the penalty being exercised by the multiclass logloss thus producing low error on the leaderboard! ;)\n",
        "Any suggestions are welcome!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3737fdb1-4a75-f2fe-c6cb-5e20ee336616"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}