{"nbformat": 4, "metadata": {"language_info": {"version": "3.6.3", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "pygments_lexer": "ipython3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "cells": [{"metadata": {"_cell_guid": "5d7fb6fb-b95d-4fb5-b3af-3d99b0d898e6", "_uuid": "651d8deed11432573fdf44b6cd9b6ace8b7826a6"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from sklearn.model_selection import train_test_split\n", "import sklearn\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"metadata": {"_cell_guid": "b57578ce-0b0e-410e-8bd4-f020b767d50c", "_uuid": "4b18b06806d867bcbcb4c73d207c610ba5e935b3"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["trainDF = pd.read_csv(\"../input/train.tsv\", sep = '\\t')\n", "testDF = pd.read_csv(\"../input/test.tsv\", sep = '\\t')"]}, {"metadata": {"collapsed": true, "_cell_guid": "5cb4ae39-743e-459a-94fc-e6dcf1db2f0c", "_uuid": "61d73de0d60ded31ec0b96279b19743fafbe1e28"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#pd.get_dummies(df['brand_name'].sample(100), prefix_sep = 'brand_name',  dummy_na = False, sparse = True)\n", "class oneHotEncoder:\n", "\n", "    def __init__(self, threshold):\n", "        self.threshold = threshold\n", "        \n", "    @staticmethod\n", "    def binary_variance(p):\n", "        return p * (1 - p)\n", "    \n", "    def dum_sign(self, df, col, threshold=0.01):\n", "        dummy_col = df[col].fillna('')\n", "        dummy_col = dummy_col.astype(str)\n", "        p = dummy_col.value_counts() / dummy_col.shape[0]\n", "        mask = dummy_col.isin(p[self.binary_variance(p) >= threshold].index)\n", "        dummy_col[~mask] = np.nan\n", "        res = pd.get_dummies(dummy_col, prefix=col, dummy_na=False)\n", "        return res\n", "    \n", "    def one_hot_encoding(self, X, threshold):\n", "        dfs = []\n", "        for col in X.columns:\n", "            if type(threshold) == float:\n", "                t = threshold\n", "            elif col in threshold:\n", "                t = threshold[col]\n", "            else:\n", "                t = 0.0\n", "            df = self.dum_sign(X, col, t)\n", "            dfs.append(df)\n", "        res = pd.concat(dfs, axis=1)\n", "        return res\n", "    \n", "    def fit_transform(self, df):\n", "        res = self.one_hot_encoding(df, self.threshold)\n", "        self.columns = res.columns\n", "        return res\n", "    \n", "    def transform(self, df):\n", "        res = self.one_hot_encoding(df, self.threshold)\n", "        return res.reindex(columns = self.columns, fill_value=0)\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.model_selection import StratifiedKFold, KFold\n", "from itertools import product\n", "\n", "class MeanEncoder:\n", "    def __init__(self, categorical_features, n_splits=5, target_type='classification', prior_weight_func=None):\n", "        \"\"\"\n", "        :param categorical_features: list of str, the name of the categorical columns to encode\n", "\n", "        :param n_splits: the number of splits used in mean encoding\n", "\n", "        :param target_type: str, 'regression' or 'classification'\n", "\n", "        :param prior_weight_func:\n", "        a function that takes in the number of observations, and outputs prior weight\n", "        when a dict is passed, the default exponential decay function will be used:\n", "        k: the number of observations needed for the posterior to be weighted equally as the prior\n", "        f: larger f --> smaller slope\n", "        \"\"\"\n", "\n", "        self.categorical_features = categorical_features\n", "        self.n_splits = n_splits\n", "        self.learned_stats = {}\n", "\n", "        if target_type == 'classification':\n", "            self.target_type = target_type\n", "            self.target_values = []\n", "        else:\n", "            self.target_type = 'regression'\n", "            self.target_values = None\n", "\n", "        if isinstance(prior_weight_func, dict):\n", "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n", "        elif callable(prior_weight_func):\n", "            self.prior_weight_func = prior_weight_func\n", "        else:\n", "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n", "\n", "    @staticmethod\n", "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n", "        X_train = X_train[[variable]].copy()\n", "        X_test = X_test[[variable]].copy()\n", "\n", "        if target is not None:\n", "            nf_name = '{}_pred_{}'.format(variable, target)\n", "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n", "        else:\n", "            nf_name = '{}_pred'.format(variable)\n", "            X_train['pred_temp'] = y_train  # regression\n", "        prior = X_train['pred_temp'].mean()\n", "\n", "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n", "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n", "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n", "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n", "\n", "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n", "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n", "\n", "        return nf_train, nf_test, prior, col_avg_y\n", "\n", "    def fit_transform(self, X, y):\n", "        \"\"\"\n", "        :param X: pandas DataFrame, n_samples * n_features\n", "        :param y: pandas Series or numpy array, n_samples\n", "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n", "        \"\"\"\n", "        X_new = X.copy()\n", "        if self.target_type == 'classification':\n", "            skf = StratifiedKFold(self.n_splits)\n", "        else:\n", "            skf = KFold(self.n_splits)\n", "\n", "        if self.target_type == 'classification':\n", "            self.target_values = sorted(set(y))\n", "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n", "                                  product(self.categorical_features, self.target_values)}\n", "            for variable, target in product(self.categorical_features, self.target_values):\n", "                nf_name = '{}_pred_{}'.format(variable, target)\n", "                X_new.loc[:, nf_name] = np.nan\n", "                for large_ind, small_ind in skf.split(y, y):\n", "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n", "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n", "                    X_new.iloc[small_ind, -1] = nf_small\n", "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n", "        else:\n", "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n", "            for variable in self.categorical_features:\n", "                nf_name = '{}_pred'.format(variable)\n", "                X_new.loc[:, nf_name] = np.nan\n", "                for large_ind, small_ind in skf.split(y, y):\n", "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n", "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n", "                    X_new.iloc[small_ind, -1] = nf_small\n", "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n", "        return X_new\n", "\n", "    def transform(self, X):\n", "        \"\"\"\n", "        :param X: pandas DataFrame, n_samples * n_features\n", "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n", "        \"\"\"\n", "        X_new = X.copy()\n", "\n", "        if self.target_type == 'classification':\n", "            for variable, target in product(self.categorical_features, self.target_values):\n", "                nf_name = '{}_pred_{}'.format(variable, target)\n", "                X_new[nf_name] = 0\n", "                for prior, col_avg_y in self.learned_stats[nf_name]:\n", "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n", "                        nf_name]\n", "                X_new[nf_name] /= self.n_splits\n", "        else:\n", "            for variable in self.categorical_features:\n", "                nf_name = '{}_pred'.format(variable)\n", "                X_new[nf_name] = 0\n", "                for prior, col_avg_y in self.learned_stats[nf_name]:\n", "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n", "                        nf_name]\n", "                X_new[nf_name] /= self.n_splits\n", "\n", "        return X_new"]}, {"metadata": {"collapsed": true, "_cell_guid": "40577afb-e3a0-4914-9a26-30709b07c56a", "_uuid": "c95ce3a491a62676479015ccab9c19d432f26605"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["#one hot\n", "X = df['name item_condition_id category_name brand_name shipping'.split()]\n", "Y = df['price']\n", "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.01, random_state=0)\n", "\n", "oneHotEnc = oneHotEncoder(0.002)\n", "X_train_onehot = oneHotEnc.fit_transform(X_train)\n", "X_test_onehot = oneHotEnc.transform(X_test)"]}, {"metadata": {}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["X = trainDF['name item_condition_id category_name brand_name shipping'.split()]\n", "Y = trainDF['price']\n", "X_train, X_validation, y_train, y_validation = train_test_split(X, Y, test_size=0.05, random_state=0)\n", "\n", "\n", "meanENC = MeanEncoder(X_validation.columns.tolist(), 5, 'regression', {\"k\":100, \"f\":100})\n", "X_train_new = meanENC.fit_transform(X_train, y_train)\n", "X_validataion_new = meanENC.transform(X_validation)\n", "\n", "new_columns = []\n", "for c in X_train_new.columns.tolist():\n", "    if(c.find(\"pred\") != -1):\n", "        new_columns.append(c)\n", "new_columns\n", "\n", "\n", "X_train_new = X_train_new[new_columns]\n", "X_validataion_new = X_validataion_new[new_columns]\n", "\n", "\n", "minMaxScaler = sklearn.preprocessing.MinMaxScaler()\n", "X_train_scaler = minMaxScaler.fit_transform(X_train_new)\n", "X_validation_scaler = minMaxScaler.transform(X_validataion_new)\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# ridge regression\n", "def ridgeRegression(x_train, y_train, x_test, y_test):\n", "    from sklearn import linear_model\n", "    from sklearn import metrics\n", "    reg = linear_model.Ridge(alpha = 1)\n", "    reg.fit(x_train, y_train)\n", "    pre_train = reg.predict(x_train)\n", "    pre_test = reg.predict(x_test)\n", "    print (\"Train-RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, pre_train)))\n", "    print (\"Test-RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, pre_test)))\n", "    print (\"Train-MAPE:\", metrics.mean_absolute_error(y_train, pre_train))\n", "    print (\"Test-MAPE:\", metrics.mean_absolute_error(y_test, pre_test))\n", "    return reg\n", "\n", "reg = ridgeRegression(X_train_scaler, y_train, X_validation_scaler, y_validation)\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["testDF_meanENC = meanENC.transform(testDF['name item_condition_id category_name brand_name shipping'.split()])[new_columns]\n", "testDF_meanENC_scaler = minMaxScaler.transform(testDF_meanENC)\n", "pre_test = reg.predict(testDF_meanENC_scaler)\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["testDF['price'] = pre_test\n", "m = testDF.pre_test.mean()\n", "testDF['price'] = testDF.price.apply(lambda x: x if(x > 0) else m)\n", "\n", "sub = testDF['test_id price'.split()]\n", "sub.to_csv('sub_submission.csv', index = False)"]}, {"metadata": {"collapsed": true, "_cell_guid": "1965d23b-c7bc-403e-bd66-9edea4f18db7", "_uuid": "f9b796927de62ea018f1abb2a2282a7aadaad628"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["# ridge regression\n", "from sklearn import linear_model\n", "from sklearn import metrics\n", "reg = linear_model.Ridge(alpha = 1)\n", "reg.fit(X_train_onehot, y_train)\n", "\n", "pre_train = reg.predict(X_train_onehot)\n", "pre_test = reg.predict(X_test_onehot)\n", "print (\"Train-RMSE:\", np.sqrt(metrics.mean_squared_error(y_train, pre_train)))\n", "print (\"Test-RMSE:\", np.sqrt(metrics.mean_squared_error(y_test, pre_test)))\n", "print (\"Train-MAPE:\", metrics.mean_absolute_error(y_train, pre_train))\n", "print (\"Test-MAPE:\", metrics.mean_absolute_error(y_test, pre_test))\n", "\n", "X_test = oneHotEnc.transform(df_test['name item_condition_id category_name brand_name shipping'.split()])\n", "pre_test = reg.predict(X_test)\n", "df_test['price'] = pre_test"]}, {"metadata": {"collapsed": true, "_cell_guid": "0b64664e-9b47-4399-a4a9-a41378fab324", "_uuid": "ae27f04a9829a4d79a41575d6718ed555822c89e"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["df_test['price'] = df_test.price.apply(lambda x: x if(x > 0) else 26.74936370209377)"]}, {"metadata": {"collapsed": true, "_cell_guid": "0ce59a5b-1d52-48ed-81b5-12a626f7a3cb", "_uuid": "813b367c2ad510c1671d06e66c5eeed9705aa2fa"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["sub = df_test['test_id price'.split()]\n", "sub.to_csv('sub_submission.csv', index = False)"]}, {"metadata": {"collapsed": true, "_cell_guid": "92c30a69-571b-4e5e-b62f-86c8fec2609f", "_uuid": "fbfcc368e4ee5fad5399dd506fcf763ab6d60720"}, "execution_count": null, "cell_type": "code", "outputs": [], "source": ["df_test[df_test.price<0]"]}], "nbformat_minor": 1}