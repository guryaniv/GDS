{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"5b342667-cd53-0f2e-5f11-63f2c0e51df0","_active":false},"source":"<h1>Loading dataset</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e418dc3a-5155-8a85-e016-af20fab27bed","_active":false},"outputs":[],"source":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport sys\nimport re\nfrom datetime import datetime\nimport math\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"85dad7de-9afe-c910-d97d-df6cc1a174e6","_active":false},"outputs":[],"source":"MAX_WEIGHT = 50.0\n\ntoys = {\n    \"horse\":  { \"sample\": lambda: max(0, np.random.normal(5,2,1)[0]), \"sample_type\": \"normal(5,2)\" },\n    \"ball\":   { \"sample\": lambda: max(0, 1 + np.random.normal(1,0.3,1)[0]), \"sample_type\": \"normal(1,0.3)\" },\n    \"bike\":   { \"sample\": lambda: max(0, np.random.normal(20,10,1)[0]), \"sample_type\": \"normal(20,10)\" },\n    \"train\":  { \"sample\": lambda: max(0, np.random.normal(10,5,1)[0]), \"sample_type\": \"normal(10,5)\" },\n    \"coal\":   { \"sample\": lambda: 47 * np.random.beta(0.5,0.5,1)[0], \"sample_type\": \"47*beta(0.5,0.5)\" },\n    \"book\":   { \"sample\": lambda: np.random.chisquare(2,1)[0], \"sample_type\": \"chi(2)\" },\n    \"doll\":   { \"sample\": lambda: np.random.gamma(5,1,1)[0], \"sample_type\": \"gamma(5,1)\" },\n    \"block\":  { \"sample\": lambda: np.random.triangular(5,10,20,1)[0], \"sample_type\": \"triagl(5,10,20)\" },\n    \"gloves\": { \"sample\": lambda: 3.0 + np.random.rand(1)[0] if np.random.rand(1) < 0.3 else np.random.rand(1)[0], \"sample_type\": \"0.3:3+rand(1), 0.7:rand(1)\" },\n}\ntoy_names = list(toys)\n\ngifts_df = pd.read_csv(\"../input/gifts.csv\", sep=\",\")\ngifts = gifts_df[\"GiftId\"].values\nprint(\"{} gifts\".format(len(gifts)))\n\nfor t in toys:\n    # get ranges\n    samples = [toys[t][\"sample\"]() for _ in range(1000)]\n    toys[t][\"max\"] = max(samples)\n    toys[t][\"min\"] = min(samples)\n    \n    # get gift counts\n    ids = [g for g in gifts if t in g.split(\"_\")[0]]\n    toys[t][\"ids\"] = ids\n    toys[t][\"count\"] = len(ids)\n    \n    # print toy type stats\n    print(\"{:4}\\tdist: {:26}\\trange:{:5.2f} - {:5.2f}\\tcount:{:6,}\".format(t, toys[t][\"sample_type\"], toys[t][\"min\"], toys[t][\"max\"], toys[t][\"count\"]))","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"aedbc529-365b-ef1f-3eeb-e4a7bbef2c14","_active":false},"source":"<h1>Visualize each toy's distribution</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"214ae47a-127c-6396-fefb-13bd416397e0","_active":false},"outputs":[],"source":"# Visualize distributions\n\nplt.figure(figsize=(10,10))\nfor i,t in enumerate(toys):\n    plt.subplot(3,3,i+1)\n    samples = [toys[t][\"sample\"]() for _ in range(10000)]\n    plt.hist(samples, bins=np.linspace(0,47,80), normed=True)\n    plt.title(t)","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"8ea2c298-a5a5-fe33-e3a5-6a840f32d9a1","_active":false},"source":"<h1>Get initial configuration of bags</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6541a635-c222-7b09-b9a6-be710d6dac17","_active":false},"outputs":[],"source":"# Gets a single bag worth of toys that passes the accept threshold\ndef get_one_bag_of_toys(toys_dups, max_toys_to_consider=12, num_simulations=40, min_toys_per_bag=3, accept_threshold=0.80, max_weight=50.0):\n\n    items_list = random.sample(toys_dups, min(max_toys_to_consider, len(toys_dups)))\n    res = []\n    res_weights = []\n    res_items = []\n\n    for num_toys in range(1,max_toys_to_consider):\n        items = items_list[:num_toys]\n\n        # run simulation\n        weights = [sum([toys[t][\"sample\"]() for t in items]) for _ in range(num_simulations)]\n        percent_accepted = float(len([w for w in weights if w <= max_weight]))/float(num_simulations)\n\n        if percent_accepted < accept_threshold:\n            break\n            \n        res.append(percent_accepted)\n        res_weights.append(np.mean(weights))\n        res_items = items\n           \n    if min_toys_per_bag > num_toys:\n        return [], (res[-1] if len(res) > 0 else 0.0), (res_weights[-1] if len(res_weights) > 0 else 0.0)\n    else:\n        return res_items, res[-1], res_weights[-1]\n   ","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad376d39-8f48-6ec8-9b41-475aab7a092a","_active":false},"outputs":[],"source":"num_options_to_consider = 5\n\ntoys_dups = [t for t in toys for _ in range(toys[t][\"count\"])]\nrandom.shuffle(toys_dups)\n\nscores = []\nbags = []\nweights = []\nstart = datetime.now()\n    \nfor bag_i in range(1000):\n    if bag_i > 0 and bag_i % 100 == 0:\n        print(\"{}\\t{}/1000\\tw: {:.2f}\\tw/bag: {:.1f}\".format(str(datetime.now() - start), bag_i, sum(weights), sum(weights)/float(bag_i)))\n        \n    options = [get_one_bag_of_toys(toys_dups) for _ in range(num_options_to_consider)]\n    options_sorted = sorted([(res, ar, res_w) for ar,res,res_w in options if len(ar) > 2 and res > 0.90], key=lambda x: -len(x[1]))\n\n    if len(options_sorted) > 0:\n        best = options_sorted[0]\n        best_score, best_toys, best_avg_weight = best\n\n        scores.append(best_score)\n        bags.append(best_toys)\n        weights.append(best_avg_weight)\n\n        for toy in best_toys:\n            toys_dups.remove(toy)\n    else:\n        pass\n    \nprint(\"\\ntotal weight: {:,.0f}, bags used: {}, toys left: {}\\n\".format(sum(weights), len([b for b in bags if len(b) > 0]), len(toys_dups)))\n    \n# Add any toys that were not added\nif len(bags) < 1000:\n    bags_left = [[] for x in range(1000 - len(bags))]\n    print(\"adding {} toys to the remaining {} empty bags\".format(len(toys_dups), len(bags_left)))\n    \n    bag_i = 0\n    for t in toys_dups:\n        if bag_i >= len(bags_left):\n            bag_i = 0\n        bags_left[bag_i].append(t)\n        if len(bags_left[bag_i]) > 2:\n            bag_i += 1\n    bags = bags + bags_left","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"22d3e28b-ee7b-48a1-881c-a8def5a09d29","_active":false},"source":"<h1>Running simulated annealing</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"157539e6-fac1-da64-905b-c411761cb8e1","_active":false},"outputs":[],"source":"GOOD = 0\nACCEPT_BAD = 1\nLEN_NORM = 2\nREJECT = 3\n\n\nclass BagSaModel:\n    \n    def __init__(self, S, temp=10.0, temp_step=0.00001, num_simulations=50, max_weight=50.0, max_items_per_bag=12):\n        self.S = [s[:] for s in S]\n        self.temp = temp\n        self.temp_step = temp_step\n        self.max_items_per_bag = max_items_per_bag\n        \n        self.num_simulations = num_simulations\n        self.max_weight = max_weight\n        self.scores = [self.get_score(s) for i,s in enumerate(self.S)]\n        \n        self.best_score = sum(self.scores)\n        self.best_S = [s[:] for s in self.S]\n        self.score_all_steps = []\n        self.steps_type = []\n        self.state_snapshots = []\n        self.score_snapshots = []\n        \n        self.iteration = 0\n        \n    def get_samples(self, s, num_iters=100):\n        weights = [sum([toys[t][\"sample\"]() for t in s]) for _ in range(num_iters)]\n        return weights\n        \n    def get_score(self, s, include_weight=True): \n        if len(s) == 0:\n            return 1.0\n        \n        weights = [sum([toys[t][\"sample\"]() for t in s]) for _ in range(self.num_simulations)]\n        percent_accepted = float(len([w for w in weights if w <= self.max_weight]))/float(self.num_simulations)\n        \n        # This is the expected weight that will be banked based on simulation\n        if include_weight:\n            return np.mean([w if w <= 50.0 else 0.0 for w in weights])\n        return percent_accepted\n    \n    # Performs a \"swap\" of a random item between two bags\n    #   The \"swap\" is accepted if the score improves or otherwise it will\n    #   accept worse scores with prob exp(delta/temp)\n    def swap_sa_step(self):    \n        self.temp = self.temp * self.temp_step\n        \n        s_i, s_j = [], []\n        while len(s_i) <= 3 or len(s_j) >= self.max_items_per_bag:\n            i, j = random.randint(0,999), random.randint(0,999)\n            while i == j:\n                j = random.randint(0,999)\n\n            s_i, s_j = self.S[i][:], self.S[j][:]\n            len_i, len_j = len(s_i), len(s_j)\n            \n        prev_score = sum(self.scores)\n        score_i, score_j = self.get_score(s_i), self.get_score(s_j)\n        \n        # swap an item\n        if len(s_i) > 0:\n            x = random.sample(s_i, 1)[0]\n            s_i.remove(x)\n            s_j.append(x)\n            \n        # evaluate scores after\n        score_i_after, score_j_after = self.get_score(s_i), self.get_score(s_j) \n        new_score = prev_score - score_i - score_j + score_i_after + score_j_after\n        \n        delta_score = 0.5*( (score_i_after + score_j_after) - (score_i + score_j) )\n        self.score_all_steps.append(new_score)\n        \n        accept_good = delta_score > 0.0\n        r = random.random()\n        \n        accept_bad = (math.exp(delta_score/self.temp) > r) if not accept_good and delta_score < -0.0001 and abs(delta_score/self.temp) < 10 else False\n        accept_len_norm = (abs(delta_score) <= 0.001) and (abs(len_i-len_j) > abs(len(s_i)-len(s_j)))\n        \n        if accept_good or accept_bad or accept_len_norm:\n            self.S[i], self.scores[i] = s_i, score_i_after\n            self.S[j], self.scores[j] = s_j, score_j_after\n            \n            if new_score > self.best_score:\n                self.best_score, self.best_S = new_score, [s[:] for s in self.S]\n                \n        if accept_good:\n            self.steps_type.append(GOOD)\n        elif accept_bad:\n            self.steps_type.append(ACCEPT_BAD)\n        elif accept_len_norm:\n            self.steps_type.append(LEN_NORM)\n        else:\n            self.steps_type.append(REJECT)\n            \n        self.iteration += 1\n        \n        if self.iteration % 1000 == 0:\n            self.state_snapshots.append([s[:] for s in self.S])\n            self.score_snapshots.append(new_score)\n            ","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"04dd0206-fe8e-c566-ed52-4f8556ed0dd0","_active":true},"outputs":[],"source":"INIT_TEMP = 4.0 # The bigger this number, the longer it will accept \"random\" swaps\nTEMP_STEP = 0.99992 # This bigger this number, the slower the cooling schedule\nNUM_SIMULATIONS_PER_STEP = 40 # The larger this number, the more acccurate (but each swap becomes slower)\nMAX_WEIGHT = 47.0 # Use less than 50 to get a margin for error \nMAX_ITEMS_PER_BAG = 10000 # Upper bound for number of items per bag\nNUM_ITERATIONS = 200000 # Number of iterations to run algorithm for\n\nsaModel = BagSaModel([bags[i][:] if i < len(bags) else [] for i in range(1000)], temp=INIT_TEMP, temp_step=TEMP_STEP, num_simulations=NUM_SIMULATIONS_PER_STEP, max_weight=MAX_WEIGHT, max_items_per_bag=MAX_ITEMS_PER_BAG)\n\nstart = datetime.now()\nnum_iters = NUM_ITERATIONS\nfor k in range(num_iters):\n    if k > 0 and k % 10000 == 0:\n        score = np.mean(saModel.score_all_steps[-100:])\n        var = np.var([saModel.score_all_steps[-100:]])\n        temp = saModel.temp\n        accept_good = len([x for x in saModel.steps_type[-1000:] if x == GOOD])\n        accept_bad = len([x for x in saModel.steps_type[-1000:] if x == ACCEPT_BAD])\n        accept_len = len([x for x in saModel.steps_type[-1000:] if x == LEN_NORM])\n        reject = len([x for x in saModel.steps_type[-1000:] if x == REJECT])\n        print(\"{:7,}/{:7,} bags:{:5,}, score:{:6,.4f}, var:{:6.1f}, temp:{:.4f}, good/bad/len/rej:{:3}/{:3}/{:3}/{:3}\".format(k,num_iters, len([b for b in saModel.S if len(b) >= 3]), score, var, temp, accept_good, accept_bad, accept_len, reject))\n    \n    saModel.swap_sa_step()","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"72f1f560-c9c6-8a06-9b47-81b9c53653d1","_active":false},"source":"<h1>Visualize Results</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b513c8a2-df2c-2bb9-4026-5c75996f05f4","_active":false},"outputs":[],"source":"plt.plot(saModel.score_all_steps)\nplt.title(\"score over iterations while training\");","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4680c8b3-1021-d000-ae47-7d8744f25b96","_active":false},"outputs":[],"source":"bags = [b[:] for b in saModel.best_S]\nbag_weights = [saModel.get_samples(b, 1000) for b in bags]\n\nplt.figure(figsize=(9,6))\nplt.hist([w for ws in bag_weights for w in ws if w < 100], bins=np.linspace(0,100,100));\nplt.title(\"bag samples weight distribution for all bags\")\n\nitem_cnt = sum([len(b) for b in bags])\nscore = np.mean([np.mean([1*(w < 50.0) for w in ws]) for ws in bag_weights])\nprint(\"E[Pr accepting bag]: {:.2f}, cnt:{}/{}\".format(score, item_cnt, len(gifts)));","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a5da473-3521-958a-8df9-742f6f93fa59","_active":false},"outputs":[],"source":"print(\"plots of weight distribution for random bags\")\n\nnum_samples = 14\nplt.figure(figsize=(7,3*num_samples/2))\nfor i,k in enumerate(random.sample(range(1000), num_samples)):\n    bag = saModel.best_S[k]\n    name = \" \".join(bag)\n    weights = bag_weights[k]\n    \n    percent_accepted = float(len([w for w in weights if w <= 50.0]))/float(len(weights))\n    \n    plt.subplot(num_samples/2, 2,i+1)\n    plt.hist(weights, bins=np.linspace(0,80,80), normed=True, histtype='bar')\n    plt.xlim(0, 80)\n    plt.title(\"Pr:{:4.2f} - {}\".format(percent_accepted, name));","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"ca851025-a0b0-8001-6d07-71a8ff85e9f8","_active":false},"source":"<h1>Trim bags that are unlikely to be accepted</h1>\n\n<h4>* This is useful since the SA optimization algorithm can't remove toys from the optimization problem</h4><br/>\n\n<small>(It would be simple enough to modify the swap function to allow this, by creating a special \"out-of-problem bag\" that would hold all the toys not considered for the 1000 bags)</small>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"991a1881-20f3-243f-2d5d-7277d0057752","_active":false},"outputs":[],"source":"# Trim all bags that have less than THRESHOLD% chance of being accepted\nTHRESHOLD = 0.80\n\nbag_probs = [float(len([w for w in weights if w <= 50.0]))/float(len(weights)) for weights in bag_weights]\nnew_probs = bag_probs[:]\n\nbad_bag_idxs = [(i,p) for i,p in enumerate(bag_probs) if p < THRESHOLD]\nprint(\"{} bags below threshold\".format(len(bad_bag_idxs)))\n\nbag_drop_counts = []\nfor bag_i,bag_prob in bad_bag_idxs:\n    bag = bags[bag_i][:]\n    prob = bag_prob\n    dropped = 0\n    while len(bag) > 3 and prob < THRESHOLD:\n        x = random.sample(bag, 1)[0]\n        bag.remove(x)\n        dropped += 1\n        \n        weights = saModel.get_samples(bag, 500)\n        new_prob = float(len([w for w in weights if w <= 50.0]))/float(len(weights))\n        \n        if new_prob >= THRESHOLD:\n            bag_drop_counts.append(dropped)\n            \n            bags[bag_i] = bag\n            new_probs[bag_i] = new_prob\n            break\n            \nplt.hist(bag_drop_counts);\nplt.title(\"hist of # bags that dropped x items\");","execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"486f461d-a3ac-293f-3376-ebd286ce15cc","_active":false,"collapsed":false},"outputs":[],"source":"trimmed_bag_weights = [saModel.get_samples(b, 500) for b in bags]\n\nbag_scores = [sum([w for w in weights if w <= 50.0])/len(weights) for weights in bag_weights]\ntrimmed_bag_scores = [sum([w for w in weights if w <= 50.0])/len(weights) for weights in trimmed_bag_weights]\n\nprint(\"Expected score: before: {:.2f}, after trimming: {:.2f}\".format(sum(bag_scores), sum(trimmed_bag_scores)))\nprint(\"E[Pr accepting bag] before: {:.2f}, after trimming: {:.2f}\".format(np.mean(bag_probs), np.mean(new_probs)))\nprint(\"num toys used: {}/{}\".format(len([t for b in bags for t in b]), len(gifts)))","execution_state":"idle"},{"cell_type":"markdown","metadata":{"_cell_guid":"f4f31cd2-5b33-6071-0aef-b8c5c734b4a4","_active":false},"source":"<h1>Write submission file</h1>","execution_count":null,"outputs":[],"execution_state":"idle"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dded52de-b4ac-adec-4173-71e947a7332a","_active":false,"collapsed":false},"outputs":[],"source":"toy_ids = {t:sorted([x for x in toys[t][\"ids\"]], reverse=True) for t in toy_names}\n\nbags_ids = []\nfor b in bags:\n    bag_toy_ids = []\n    for toy in b:\n        if len(toy_ids[toy]) == 0:\n            raise Exception(\"toy count error!\")\n            \n        bag_toy_ids.append(toy_ids[toy].pop())\n    bags_ids.append(bag_toy_ids)\n            \nsubmit_df = pd.DataFrame({\"Gifts\": [\" \".join(b) for b in bags_ids]})\nsubmit_df.to_csv(\"./SA_solution.csv\", sep=\",\", index=False)","execution_state":"idle"}]}