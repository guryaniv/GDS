{"cells":[{"metadata":{"_uuid":"89e70473ea3fcfedec5dcfdf6873f87de96e4a7e"},"cell_type":"markdown","source":"In this Kernel I try for the first time to build a neural network (without the direct specifications of (coursera ;). I use Tensorflow, so that the structure of the Neural Network isbetter visible. At the moment the network works, however it improves only for one step. Than it seems stuck. Any ideas?"},{"metadata":{"_uuid":"6dbf14c97a76ded5675b7c979d88e5dd7ebe22b8"},"cell_type":"markdown","source":"## 1. Import necessary packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\n\nimport skimage.io\nfrom skimage.transform import resize\n\nimport matplotlib.pyplot as plt\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b7d25791377c8eb315c309fed9a39c4a965fa7d"},"cell_type":"markdown","source":"## 2. Prepare Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/train.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"298ff8d41e52121cdc7f876a790927e0dd25e81c"},"cell_type":"code","source":"#Train/Test Split (https://www.kaggle.com/kmader/transfer-learning-for-human-protein-submission)\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data, \n                 test_size = 0.3,         \n                 stratify = data['Target'].map(lambda x: x[:3] if '27' not in x else '0'))\ntrain = train.reset_index(drop=True)\ntest = test.reset_index(drop = True)\ntest.shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9aad2d9109ea87792f74e19e0424d3a58fd8759"},"cell_type":"code","source":"#Creating Label-Vector (https://www.kaggle.com/allunia/protein-atlas-exporation-and-baseline)\n\nlabel_names = {\n    0:  \"Nucleoplasm\",  \n    1:  \"Nuclear membrane\",   \n    2:  \"Nucleoli\",   \n    3:  \"Nucleoli fibrillar center\",   \n    4:  \"Nuclear speckles\",\n    5:  \"Nuclear bodies\",   \n    6:  \"Endoplasmic reticulum\",   \n    7:  \"Golgi apparatus\",   \n    8:  \"Peroxisomes\",   \n    9:  \"Endosomes\",   \n    10:  \"Lysosomes\",   \n    11:  \"Intermediate filaments\",   \n    12:  \"Actin filaments\",   \n    13:  \"Focal adhesion sites\",   \n    14:  \"Microtubules\",   \n    15:  \"Microtubule ends\",   \n    16:  \"Cytokinetic bridge\",   \n    17:  \"Mitotic spindle\",   \n    18:  \"Microtubule organizing center\",   \n    19:  \"Centrosome\",   \n    20:  \"Lipid droplets\",   \n    21:  \"Plasma membrane\",   \n    22:  \"Cell junctions\",   \n    23:  \"Mitochondria\",   \n    24:  \"Aggresome\",   \n    25:  \"Cytosol\",   \n    26:  \"Cytoplasmic bodies\",   \n    27:  \"Rods & rings\"\n}\n\n\ndef fill_targets(row):\n    row.Target = np.array(row.Target.split(\" \")).astype(np.int)\n    for num in row.Target:\n        name = label_names[int(num)]\n        row.loc[name] = 1\n    return row\n\nfor key in label_names.keys():\n    train[label_names[key]] = 0\n    test[label_names[key]] = 0\n    \ntrain = train.apply(fill_targets, axis=1)\ntest = test.apply(fill_targets, axis = 1)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24e9f794e4d7c3008b28542240f42c1ac19a0248"},"cell_type":"code","source":"X_train = train.iloc[:,0]\nY_train = train.iloc[:, 2:30]\nX_test = test.iloc[:,0]\nY_test = test.iloc[:, 2:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d4c0a5c7d90e3561c127dabcb38afff27d0a477"},"cell_type":"code","source":"Y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"188e163d0e9969ae82925941039ba4deb180245f"},"cell_type":"markdown","source":"## 3. Create Data Generator"},{"metadata":{"trusted":true,"_uuid":"020daf64df4ea2ddfac5b889d83b0affcf5fb145"},"cell_type":"code","source":"#credits: https://www.kaggle.com/byrachonok/pretrained-inceptionresnetv2-base-classifier\ndef data_generator (dataset, start, end):\n    picture = np.empty([end-start, 256, 256, 3])\n    for i in range(start, end):\n        image_red_ch = skimage.io.imread(\"../input/train/\"+ dataset.iloc[i, 0]+\"_red.png\")\n        image_yellow_ch = skimage.io.imread(\"../input/train/\"+ dataset.iloc[i, 0]+\"_yellow.png\")\n        image_green_ch = skimage.io.imread(\"../input/train/\"+ dataset.iloc[i, 0]+\"_green.png\")\n        image_blue_ch = skimage.io.imread(\"../input/train/\"+ dataset.iloc[i, 0]+\"_blue.png\")\n\n        image_red_ch += (image_yellow_ch/2).astype(np.uint8) \n        image_green_ch += (image_yellow_ch/2).astype(np.uint8)\n\n        image = np.stack((\n            image_red_ch, \n            image_green_ch, \n            image_blue_ch), -1)\n        image = resize(image, (256, 256), mode='reflect')\n        picture[i-start] = image\n    return picture\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e69bc2b55b8234dbb3c0b0c0412d1c14ea066b43"},"cell_type":"code","source":"a = data_generator(train, 0, 12)\nprint(a.shape)\nskimage.io.imshow(a[5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24c2842d543e9adfa50702bd3b1f372e37e795c7"},"cell_type":"code","source":"#Test whether pictures are already normalized\nprint(np.max(a))\nprint(np.min(a))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"134b40c6186169f4ddc93ca1c36f48cb9d294617"},"cell_type":"markdown","source":"## 4. Model\nFollowing this Model: https://github.com/Kulbear/deep-learning-coursera/blob/master/Convolutional%20Neural%20Networks/Convolution%20model%20-%20Application%20-%20v1.ipynb****"},{"metadata":{"_uuid":"ed51a7202e1eba858f1ea3cf5e5b50be275cedec"},"cell_type":"markdown","source":"### 4.1 Helper functions"},{"metadata":{"trusted":true,"_uuid":"9e41f2709e781db7124f6906d1b4fae0db37c3fb"},"cell_type":"code","source":"ops.reset_default_graph()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22508397b1d092c35702ac60245614b55459ea09"},"cell_type":"code","source":"def create_placeholders(n_H0, n_W0, n_C0, n_y):\n    X = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0])\n    Y = tf.placeholder(tf.float32, [None, n_y])    \n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d58c34beb3163d833962160d0b3b62617ee4166e"},"cell_type":"code","source":"def initialize_parameters():                    \n        \n    W1 = tf.get_variable(\"W1\", [4, 4, 3, 8], initializer=tf.contrib.layers.xavier_initializer())\n    W2 = tf.get_variable(\"W2\", [2, 2, 8, 16], initializer=tf.contrib.layers.xavier_initializer())\n    W3 = tf.get_variable(\"W3\", [2, 2, 16, 16], initializer=tf.contrib.layers.xavier_initializer())\n\n    parameters = {\"W1\": W1,\n                  \"W2\": W2,\n                  \"W3\": W3}\n    \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4315048f0e7161de717b5931bf857ffab0839fe0"},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    # Retrieve the parameters from the dictionary \"parameters\" \n    W1 = parameters['W1']\n    W2 = parameters['W2']\n    W3 = parameters[\"W3\"]\n    \n    #First convolutiuonal Block\n    #### CONV2D: stride of 1, padding 'SAME'\n    Z1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n    ##### RELU\n    A1 = tf.nn.relu(Z1)\n    ##### MAXPOOL: window 8x8, stride 8, padding 'SAME'\n    P1 = tf.nn.max_pool(A1, ksize = [1, 8, 8, 1], strides = [1, 8, 8, 1], padding='SAME')\n\n    #Second Convolutional Block\n    Z2 = tf.nn.conv2d(P1, W2, strides=[1, 1, 1, 1], padding='SAME')\n    A2 = tf.nn.relu(Z2)\n    P2 = tf.nn.max_pool(A2, ksize = [1, 2, 2, 1], strides = [1, 4, 4, 1], padding='SAME')\n    print (P2.shape)\n    #Third Convolutional Block\n    Z3 = tf.nn.conv2d(P2, W3, strides=[1, 1, 1, 1], padding='SAME')\n    print (Z3.shape)\n    A3 = tf.nn.relu(Z2)\n    P3 = tf.nn.max_pool(A3, ksize = [1, 2, 2, 1], strides = [1, 4, 4, 1], padding='SAME')\n    print(P3.shape)\n    \n    # FLATTEN\n    P = tf.contrib.layers.flatten(P3)\n    #print(P.shape)\n    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n    # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n    Z3 = tf.contrib.layers.fully_connected(P, 28, activation_fn=None)\n    Z3 = tf.nn.sigmoid(Z3)\n    #print(Z3.shape)\n    ### END CODE HERE ###\n\n    return Z3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cda80da8dbcc666263d9e941c72cc53cca309ce2"},"cell_type":"code","source":"tf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y = create_placeholders(64, 64, 3, 6)\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(Z3, {X: np.random.randn(2,64,64,3), Y: np.random.randn(2,6)})\n    print(\"Z3 = \" + str(a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15b816698c796056abf0ec14a7678b6a5a3669b7"},"cell_type":"code","source":"#credits: https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\ndef compute_cost(Z3, Y):\n    \n    tp = tf.reduce_sum(tf.cast(Y*Z3, 'float'), axis=0)\n    fp = tf.reduce_sum(tf.cast((1-Y)*Z3, 'float'), axis=0)\n    fn = tf.reduce_sum(tf.cast(Y*(1-Z3), 'float'), axis=0)\n\n    p = tp / (tp + fp + tf.constant(10**-7))\n    r = tp / (tp + fn + tf.constant(10**-7))\n\n    f1 = 2*p*r / (p+r+tf.constant(10**-7))\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n\n    return 1 - tf.reduce_mean(f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b262fd67950717fe97e39bbc7e973bbda3a68f41"},"cell_type":"code","source":"epochs_completed = 0\nindex_in_epoch = 0\nnum_examples = train.shape[0]\n\n# serve data by batches\ndef next_batch(batch_size):\n    \n    global train\n    global index_in_epoch\n    global epochs_completed\n    \n    start = index_in_epoch\n    index_in_epoch += batch_size\n     # when all trainig data have been already used, it is reorder randomly    \n    if index_in_epoch > num_examples:\n        # finished epoch\n        epochs_completed += 1\n        # shuffle the data\n        train = train.sample(frac=1).reset_index(drop=True)\n        # start next epoch\n        start = 0\n        index_in_epoch = batch_size\n        assert batch_size <= num_examples\n    end = index_in_epoch\n    return data_generator(train, start, end), train.iloc[start:end,2:30]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d58e48453691ba6795c0295dd0f4e3b59ebf8ff"},"cell_type":"markdown","source":"### 4.2 Model"},{"metadata":{"trusted":true,"_uuid":"ba828e902a0ad85593594d49ea71e5a5c11abbd3"},"cell_type":"code","source":"def model(IMAGE_H = 256, IMAGE_W = 256, TRAINING_ITERATIONS = 2500, \n          BATCH_SIZE = 100, LEARNING_RATE = 1e-4, DISPLAY_STEP = 10):  \n    \n    ops.reset_default_graph()\n    sess = tf.Session()\n    costs = []\n    #Placeholders\n    X,Y = create_placeholders(IMAGE_H, IMAGE_W, 3, 28)\n    #Parameters\n    parameters = initialize_parameters()\n    # Forward propagation\n    Z3 = forward_propagation(X, parameters)\n    #Cost\n    f1 = compute_cost(Z3, Y)\n    # Backpropagation\n    train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(f1)\n    \n    init = tf.initialize_all_variables()\n    sess.run(init)\n\n    for i in range(TRAINING_ITERATIONS):\n        #get new batch\n        batch_xs, batch_ys = next_batch(BATCH_SIZE)  \n        \n        # train on batch\n        cost, _ = sess.run([f1, train_step], feed_dict={X: batch_xs, Y: batch_ys})\n        costs.append(cost)\n        \n        if i%DISPLAY_STEP == 0 or (i + 1) == TRAINING_ITERATIONS:\n            print('cost %.2f for step %d'%(cost , i))\n            \n    #Vizualizations\n    plt.plot(np.squeeze(costs))\n    plt.ylabel('cost')\n    plt.xlabel('iterations (per tens)')\n    plt.title(\"Learning rate =\" + str(LEARNING_RATE))\n    plt.show()\n    \n    return (costs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"07af99511edc556fe5dee21109004b76cf5ef14b"},"cell_type":"code","source":"costs = model()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}