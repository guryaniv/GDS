{"metadata": {"language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "cells": [{"cell_type": "markdown", "metadata": {"_cell_guid": "c490baf3-c190-46b6-bb67-4e4a4ff4e2ba", "_uuid": "95313d6f7ca28791b693b2017071f16a9df13f01"}, "source": "***Introduction***", "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ffd68d81-8401-469d-aae5-0965ca8f2e3d", "_uuid": "d1603fdd9f926fac79c886e371a8b04aa5b207a8"}, "source": "In *New York City Taxi Trip Duration*, we have to predict the trip_duration in NYC. Trip_duration is depends upon from where the taxi picks the passengers and where to drop. We have DataTime stamp in the training as well as testing data. We have pickup and dropoff locations, pasenger count. \nEvaluation creteria is RMSLE. We have trained our model using xgboost.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "0f6a73aa-66f8-4569-b01a-7582ee51ea5c", "_execution_state": "idle", "collapsed": true, "_uuid": "f65634748cb01d916a4c72ba743a8968cd2d97ac", "trusted": false}, "source": "%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import timedelta \nimport datetime as dt\nimport math\nfrom haversine import haversine # Distance Calculation\nimport matplotlib.pyplot as plt # plots\nplt.rcParams['figure.figsize'] = [16, 10]\nimport seaborn as sns\nimport xgboost as xgb  # regressor\nfrom sklearn.model_selection import train_test_split # for spliting data\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.decomposition import PCA \nfrom sklearn.cluster import MiniBatchKMeans\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')", "outputs": [], "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_cell_guid": "b8a3dd31-2a1a-44cb-b6f0-3d541401a4f8", "_uuid": "46eedcf3afdbf6ba6406e2d75aa00ac0b4f359e8"}, "source": "Input files. N= 100000 for the EDA", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "99f65bb9-e326-4372-a769-9f4a597ea7b6", "_execution_state": "idle", "collapsed": true, "_uuid": "e85ccd470c913ea918a4f271952756f7681eebaa", "trusted": false}, "source": "np.random.seed(1987)\nN = 100000 # number of sample rows in plots\nt0 = dt.datetime.now()\ntrain = pd.read_csv('../input/nyc-taxi-trip-duration/train.csv')\ntest = pd.read_csv('../input/nyc-taxi-trip-duration/test.csv')", "outputs": [], "execution_count": 2}, {"cell_type": "code", "metadata": {"_cell_guid": "c863a789-e70e-40b8-bbc6-db00349a315b", "_execution_state": "idle", "_uuid": "1108192cef80aa004c7f5d03cebcc6aa121b340f", "trusted": false}, "source": "print('training rows: {} and test rows:{} '.format(train.shape[0], test.shape[0]))\nprint('training columns: {} and  test columns:{}'.format(train.shape[1], test.shape[1]))\nprint('in training file dropoff_time will be droped while training the model')\ntrain.head(10)", "outputs": [], "execution_count": 3}, {"cell_type": "code", "metadata": {"_cell_guid": "cf530517-3310-4b1b-9d43-cc190bc5010d", "_execution_state": "idle", "_uuid": "58f71e7dda765662dca2f0e85afbc3bee8772b62", "trusted": false}, "source": "print('Training and testing files are mutualy exclusive. Id is unique so it wont be contributing any part in model training. Only 2 vendors are there in data set.')", "outputs": [], "execution_count": 4}, {"cell_type": "code", "metadata": {"_cell_guid": "8d3327a9-49da-4928-a35d-13c7499eda2e", "_execution_state": "idle", "_uuid": "3f09c75fd97c9fd22fc961011d041ce5707b83a4", "trusted": false}, "source": "train['trip_duration'].max()/3600\nprint('max trip_duration in hours are 979.52')", "outputs": [], "execution_count": 5}, {"cell_type": "code", "metadata": {"_cell_guid": "adc638aa-2a76-45e4-b564-61ea663a3eeb", "_execution_state": "idle", "collapsed": true, "_uuid": "10d6e8e7e391aeb4997aa3553e949a2c7e8315d1", "trusted": false}, "source": "df = train\n# Convert the date to a pandas datetime format\ndf['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], format=\"%Y/%m/%d %H:%M:%S\")\ndf['dropoff_datetime'] = pd.to_datetime(df['dropoff_datetime'], format=\"%Y/%m/%d %H:%M:%S\")\n\n# Pull out the month, day of week and hour of day and make a new feature for each\ndf['month'] = df['pickup_datetime'].dt.month\ndf['dow'] = df['pickup_datetime'].dt.dayofweek\ndf['hour'] = df['pickup_datetime'].dt.hour\n\n# Count number of pickups made per month, day of week and hour of day\nmonth_usage = pd.value_counts(df['month']).sort_index()\ndow_usage = pd.value_counts(df['dow']).sort_index()\nhour_usage = pd.value_counts(df['hour']).sort_index()", "outputs": [], "execution_count": 6}, {"cell_type": "code", "metadata": {"_cell_guid": "1658ea87-d2dd-447d-b337-e7300210fffd", "_execution_state": "idle", "_uuid": "a356d2fc329bd95e4d0eacc9ce059d21f9a11095", "trusted": false}, "source": "# Set custom xtick labels\nx_tick_labels_month = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\nx_tick_labels_day = ['Mon', 'Tues', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\n# define subplot\nfig, ax = plt.subplots(nrows=2, ncols=2, figsize=(19, 15))\n\nfigure = plt.subplot(2, 2, 1)\nmonth_usage.plot.bar(alpha = 0.5, color = 'green')\nplt.title('Pickups over Month of Year', fontsize = 20)\nplt.xlabel('Month', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(month_usage.index - 1, x_tick_labels_month, rotation='90', fontsize=18)\nplt.xticks(rotation=0)\nplt.yticks(fontsize = 18)\n\nfigure = plt.subplot(2, 2, 2)\ndow_usage.plot.bar(alpha = 0.5, color = 'blue')\nplt.title('Pickups over Day of Week', fontsize = 20)\nplt.xlabel('Day of Week', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(dow_usage.index, x_tick_labels_day, rotation='90', fontsize=18)\nplt.xticks(rotation=0)\nplt.yticks(fontsize = 18)\n\nfigure = plt.subplot(2, 1, 2)\nhour_usage.plot.bar(alpha = 0.5, color = 'grey')\nplt.title('Pickups over Hour of Day', fontsize = 20)\nplt.xlabel('Hour of Day', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(rotation=0)\nplt.yticks(fontsize = 18)\n\nfig.tight_layout()\n# print the total number of Taxi pickups\nprint (\"There were a total of %d Taxi pickups made\" % (len(train)))", "outputs": [], "execution_count": 7}, {"cell_type": "markdown", "metadata": {"_cell_guid": "5cc99713-912d-4e20-b111-28a26300c29b", "_uuid": "cb0a02bb3328372ee9aca3c5df99548a48660c33"}, "source": "**Taxi Vendors**", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "dd3f46c7-b4f7-4edc-9193-a1d4c1f9ca56", "_execution_state": "idle", "collapsed": true, "_uuid": "86f2c62dcb1e3ba9b3cadb465a4ce02ff89dbac9", "trusted": false}, "source": "# Count number of pickups made per vendor, over month, day of week and hour of day\nmonth_vendor = df.groupby(['month', 'vendor_id']).size().unstack()\ndow_vendor = df.groupby(['dow', 'vendor_id']).size().unstack()\nhour_vendor = df.groupby(['hour', 'vendor_id']).size().unstack()\n\n# Count vehicles with server access\nserver = df.groupby(['store_and_fwd_flag', 'vendor_id']).size().unstack()", "outputs": [], "execution_count": 8}, {"cell_type": "code", "metadata": {"_cell_guid": "c7176e17-4de9-4e07-b97c-88f4db3b2916", "_execution_state": "idle", "_uuid": "3032e684c1bdd24395a70bdb8f4cd426d195ea7b", "trusted": false}, "source": "# Set custom xtick labels\nx_tick_labels_month = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\nx_tick_labels_day = ['Mon', 'Tues', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\nfig, ax = plt.subplots(nrows=2,ncols=2, figsize=(9, 8))\n\nfigure = plt.subplot(2, 2, 1)\nmonth_vendor.plot.bar(stacked=True, alpha = 0.7, ax = figure, legend = False)\nplt.title('Pickups over Month of Year', fontsize = 13)\nplt.xlabel('Month', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.xticks(month_usage.index - 1, x_tick_labels_month, rotation='90', fontsize=12)\nplt.xticks(rotation=0)\n\nfigure = plt.subplot(2, 2, 2)\ndow_vendor.plot.bar(stacked=True, alpha = 0.7, ax = figure, legend = False)\nplt.title('Pickups over Day of Week', fontsize = 13)\nplt.xlabel('Day of Week', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.xticks(dow_usage.index, x_tick_labels_day, rotation='90', fontsize=12)\nplt.xticks(rotation=0)\n\n\nfigure = plt.subplot(2, 2, 3)\nhour_vendor.plot.bar(stacked=True, alpha = 0.7, ax = figure, legend = False)\nplt.title('Pickups over Hour of Day', fontsize = 13)\nplt.xlabel('Hour of Day', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.xticks(rotation=0)\n\nfigure = plt.subplot(2, 2, 4)\nserver.plot.bar(stacked=True, alpha = 0.7, ax = figure)\nplt.title('Vehicle Server Access', fontsize = 13)\nplt.xlabel(' ', fontsize = 12)\nplt.ylabel('Count', fontsize = 12)\nplt.xticks(rotation=0)\n\nfig.tight_layout()", "outputs": [], "execution_count": 9}, {"cell_type": "markdown", "metadata": {"_cell_guid": "defff8ab-2692-4334-88da-065159620468", "_uuid": "80b44370292326a04edd8895594bce6a8b8c0991"}, "source": "**Multiple Passengers**", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "6de7f761-85c1-46bc-aafa-bd7f9e66c45c", "_execution_state": "idle", "_uuid": "49f1a3939b37cbdda1f6cac3ee57199f547051e7", "trusted": false}, "source": "print (\"Max passengers at once: %d\" % df['passenger_count'].max())\nprint (\"Average passengers at once: %d\" % df['passenger_count'].mean())", "outputs": [], "execution_count": 10}, {"cell_type": "code", "metadata": {"_cell_guid": "5bd4058f-94f3-4c40-bba0-1713e58a1de2", "_execution_state": "idle", "collapsed": true, "_uuid": "7bc6ce9a03c6259874605dbe5f251b61a12dcfab", "trusted": false}, "source": "# Count number of pickups made per vendor, over month, day of week and hour of day\nmonth_pass = df.groupby(['month', 'passenger_count']).size().unstack()\ndow_pass = df.groupby(['dow', 'passenger_count']).size().unstack()\nhour_pass = df.groupby(['hour', 'passenger_count']).size().unstack()", "outputs": [], "execution_count": 11}, {"cell_type": "code", "metadata": {"_cell_guid": "0c7e50c7-c1f2-4f7d-980e-ea6df23ed79b", "_execution_state": "idle", "_uuid": "7ed5d730ae1c9f3888c8f4efe4863e5799e5aaa9", "trusted": false}, "source": "# Set custom xtick labels\nx_tick_labels_month = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']\nx_tick_labels_day = ['Mon', 'Tues', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n\nfig, ax = plt.subplots(nrows=2,ncols=2, figsize=(19, 15))\n\nfigure = plt.subplot(2, 2, 1)\nmonth_pass.plot.bar(stacked=True, alpha = 0.8, ax = figure, legend = False)\nplt.title('Multi-passenger # over Month of Year', fontsize = 20)\nplt.xlabel('Month', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(month_usage.index - 1, x_tick_labels_month, rotation='90', fontsize=18)\nplt.yticks(fontsize = 18)\nplt.xticks(rotation=0)\n\nfigure = plt.subplot(2, 2, 2)\ndow_pass.plot.bar(stacked=True, alpha = 0.8, ax = figure, legend = False)\nplt.title('Multi-passenger # over Day of Week', fontsize = 20)\nplt.xlabel('Day of Week', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(dow_usage.index, x_tick_labels_day, rotation='90', fontsize=18)\nplt.yticks(fontsize = 18)\nplt.xticks(rotation=0)\n\n\nfigure = plt.subplot(2, 1, 2)\nhour_pass.plot.bar(stacked=True, alpha = 0.8, ax = figure, legend = False)\nplt.title('Multi-passenger # over Hour of Day', fontsize = 20)\nplt.xlabel('Hour of Day', fontsize = 18)\nplt.ylabel('Count', fontsize = 18)\nplt.xticks(rotation = 0, fontsize = 18)\nplt.yticks(fontsize = 18)\nplt.legend(loc = \"upper left\")\n\n\nfig.tight_layout()", "outputs": [], "execution_count": 12}, {"cell_type": "code", "metadata": {"_cell_guid": "6448b6bb-58cd-4164-8457-8d8a2ce9b181", "_execution_state": "idle", "collapsed": true, "_uuid": "ecf0cc693bf59bdbcdbfa363fda7c7a54a98935a", "trusted": false}, "source": "train['pickup_datetime'] = pd.to_datetime(train.pickup_datetime)\ntest['pickup_datetime'] = pd.to_datetime(test.pickup_datetime)\ntrain.loc[:, 'pickup_date'] = train['pickup_datetime'].dt.date\ntest.loc[:, 'pickup_date'] = test['pickup_datetime'].dt.date\ntrain['dropoff_datetime'] = pd.to_datetime(train.dropoff_datetime)", "outputs": [], "execution_count": 13}, {"cell_type": "code", "metadata": {"_cell_guid": "15f46618-5e9e-45a8-9b99-b602d9a07648", "_execution_state": "idle", "_uuid": "65a6edf39c4f8a7b4d23dfbd5b5d63706573b0d7", "trusted": false}, "source": "train['log_trip_duration'] = np.log(train['trip_duration'].values + 1)\nplt.hist(train['log_trip_duration'].values, bins=50)\nplt.xlabel('log(trip_duration)')\nplt.ylabel('number of train records')\nplt.show()", "outputs": [], "execution_count": 14}, {"cell_type": "markdown", "metadata": {"_cell_guid": "ad52f888-17ed-434c-9f73-84802826e4c6", "_uuid": "e7759e75f78dde79d2f469be2443f7580e0ff3fa"}, "source": "Converting *store_and_fwd_flag *  from {N,Y} to {0,1}", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "41918cf6-dd79-4866-8b46-58e6e2e585cd", "_execution_state": "idle", "collapsed": true, "_uuid": "d420cb800f59e08b3853b368eaeb885914122639", "trusted": false}, "source": "train['store_and_fwd_flag'] = 1 * (train.store_and_fwd_flag.values == 'Y')\ntest['store_and_fwd_flag'] = 1 * (test.store_and_fwd_flag.values == 'Y')", "outputs": [], "execution_count": 15}, {"cell_type": "markdown", "metadata": {"_cell_guid": "c912caab-83c8-48e0-8977-87ac2eb61a2a", "_execution_state": "idle", "_uuid": "7e800052e2f5b19e1d8dfc7912f7d2883fb67b48"}, "source": "To look where is the most pick up point point in the city.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "6ed830b8-10b8-49e8-8a31-519f1314a649", "_execution_state": "idle", "_uuid": "216c74f7133df9aeb36e39611d975b691bfa40d7", "trusted": false}, "source": "city_long_border = (-74.03, -73.75)\ncity_lat_border = (40.63, 40.85)\nfig, ax = plt.subplots(ncols=2, sharex=True, sharey=True)\nax[0].scatter(train['pickup_longitude'].values[:N], train['pickup_latitude'].values[:N],\n              color='green', s=1, label='train', alpha=0.1)\nax[1].scatter(test['pickup_longitude'].values[:N], test['pickup_latitude'].values[:N],\n              color='red', s=1, label='test', alpha=0.1)\nfig.suptitle('Train and test area complete overlap.')\nax[0].legend(loc=0)\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('longitude')\nax[1].legend(loc=0)\nplt.ylim(city_lat_border)\nplt.xlim(city_long_border)\nplt.show()", "outputs": [], "execution_count": 16}, {"cell_type": "code", "metadata": {"_cell_guid": "1c446942-5bad-4691-a19d-a6788ed4952f", "_execution_state": "idle", "collapsed": true, "_uuid": "e7abe8d6182a2a2296a03073e3bf506e772a0759", "trusted": false}, "source": "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n                    test[['pickup_latitude', 'pickup_longitude']].values,\n                    test[['dropoff_latitude', 'dropoff_longitude']].values))\n\npca = PCA().fit(coords)\ntrain['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntrain['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntrain['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntrain['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\ntest['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\ntest['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\ntest['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\ntest['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]", "outputs": [], "execution_count": 17}, {"cell_type": "code", "metadata": {"_cell_guid": "4dea07f2-17f5-435c-b99d-66eb0e5731a4", "_execution_state": "idle", "_uuid": "0ffbd13e2a37fdb2ddbe49ea28b8646e5fd28b5b", "trusted": false}, "source": "fig, ax = plt.subplots(ncols=2)\nax[0].scatter(train['pickup_longitude'].values[:N], train['pickup_latitude'].values[:N], color='red', s=1, alpha=0.1)\nax[1].scatter(train['pickup_pca0'].values[:N], train['pickup_pca1'].values[:N], color='green', s=1, alpha=0.1)\nfig.suptitle('Pickup lat long coords and PCA transformed coords.')\nax[0].set_ylabel('latitude')\nax[0].set_xlabel('longitude')\nax[1].set_xlabel('pca0')\nax[1].set_ylabel('pca1')\nax[0].set_xlim(city_long_border)\nax[0].set_ylim(city_lat_border)\npca_borders = pca.transform([[x, y] for x in city_lat_border for y in city_long_border])\nax[1].set_xlim(pca_borders[:, 0].min(), pca_borders[:, 0].max())\nax[1].set_ylim(pca_borders[:, 1].min(), pca_borders[:, 1].max())\nplt.show()", "outputs": [], "execution_count": 18}, {"cell_type": "markdown", "metadata": {"_cell_guid": "0eefa1e8-6b27-4141-8b13-25bcbe13b136", "_execution_state": "idle", "_uuid": "045cf1edddfac7c2cdb532c0bdee3cbc36bc0699"}, "source": "**Distance**\nAs features in training and testing data is very limited but we can infer some of the Features from Data. \nThe best way should be using a map distance by some Map APi but as the training and test data goes beyond the limit of query limit we will use haversine distance.\nWe have to measure Manhattan Distance as well.\n", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "cb990c94-538d-42f7-a0c2-ddca2fa1b3ea", "_execution_state": "idle", "collapsed": true, "_uuid": "6929633f6cc9cea241ac6c3b21be99fb1f505c23", "trusted": false}, "source": "def haversine_array(lat1, lng1, lat2, lng2):\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    AVG_EARTH_RADIUS = 6371  # in km\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n    return h\n\ndef dummy_manhattan_distance(lat1, lng1, lat2, lng2):\n    a = haversine_array(lat1, lng1, lat1, lng2)\n    b = haversine_array(lat1, lng1, lat2, lng1)\n    return a + b\n\ndef bearing_array(lat1, lng1, lat2, lng2):\n    AVG_EARTH_RADIUS = 6371  # in km\n    lng_delta_rad = np.radians(lng2 - lng1)\n    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n    y = np.sin(lng_delta_rad) * np.cos(lat2)\n    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n    return np.degrees(np.arctan2(y, x))\n\ntrain.loc[:, 'distance_haversine'] = haversine_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\ntrain.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\ntrain.loc[:, 'direction'] = bearing_array(train['pickup_latitude'].values, train['pickup_longitude'].values, train['dropoff_latitude'].values, train['dropoff_longitude'].values)\n\n\ntest.loc[:, 'distance_haversine'] = haversine_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\ntest.loc[:, 'distance_dummy_manhattan'] = dummy_manhattan_distance(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\ntest.loc[:, 'direction'] = bearing_array(test['pickup_latitude'].values, test['pickup_longitude'].values, test['dropoff_latitude'].values, test['dropoff_longitude'].values)\n\n\ntrain.loc[:, 'center_latitude'] = (train['pickup_latitude'].values + train['dropoff_latitude'].values) / 2\ntrain.loc[:, 'center_longitude'] = (train['pickup_longitude'].values + train['dropoff_longitude'].values) / 2\ntest.loc[:, 'center_latitude'] = (test['pickup_latitude'].values + test['dropoff_latitude'].values) / 2\ntest.loc[:, 'center_longitude'] = (test['pickup_longitude'].values + test['dropoff_longitude'].values) / 2\n", "outputs": [], "execution_count": 19}, {"cell_type": "markdown", "metadata": {"_cell_guid": "d331e4c8-ea9f-4d46-9f9d-ea8f879b7fbd", "_uuid": "3515445e26a18666ae113d65a5f298584c993d0a"}, "source": "As datatime stamp is always unique we have to extract some features from them like, day og the month, day of the week, hour of the day etc.", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "0c8384c8-bb6e-4877-a6de-41431e2cd505", "_execution_state": "idle", "collapsed": true, "_uuid": "7eae58cac72cbd8cd5aa34143de72576727df083", "trusted": false}, "source": "train.loc[:, 'pickup_weekday'] = train['pickup_datetime'].dt.weekday\ntrain.loc[:, 'pickup_hour_weekofyear'] = train['pickup_datetime'].dt.weekofyear\ntrain.loc[:, 'pickup_hour'] = train['pickup_datetime'].dt.hour\ntrain.loc[:, 'pickup_minute'] = train['pickup_datetime'].dt.minute\ntrain.loc[:, 'pickup_dt'] = (train['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntrain.loc[:, 'pickup_week_hour'] = train['pickup_weekday'] * 24 + train['pickup_hour']\n\ntest.loc[:, 'pickup_weekday'] = test['pickup_datetime'].dt.weekday\ntest.loc[:, 'pickup_hour_weekofyear'] = test['pickup_datetime'].dt.weekofyear\ntest.loc[:, 'pickup_hour'] = test['pickup_datetime'].dt.hour\ntest.loc[:, 'pickup_minute'] = test['pickup_datetime'].dt.minute\ntest.loc[:, 'pickup_dt'] = (test['pickup_datetime'] - train['pickup_datetime'].min()).dt.total_seconds()\ntest.loc[:, 'pickup_week_hour'] = test['pickup_weekday'] * 24 + test['pickup_hour']", "outputs": [], "execution_count": 20}, {"cell_type": "code", "metadata": {"_cell_guid": "b40b8a39-4524-4be9-ac8a-ded46d606124", "_execution_state": "idle", "_uuid": "1ee96695531e30db051e3a01cdf53aebde165549", "trusted": false}, "source": "train.loc[:, 'avg_speed_h'] = 1000 * train['distance_haversine'] / train['trip_duration']\ntrain.loc[:, 'avg_speed_m'] = 1000 * train['distance_dummy_manhattan'] / train['trip_duration']\nfig, ax = plt.subplots(ncols=3, sharey=True)\nax[0].plot(train.groupby('pickup_hour').mean()['avg_speed_h'], 'bo-', lw=2, alpha=0.7)\nax[1].plot(train.groupby('pickup_weekday').mean()['avg_speed_h'], 'go-', lw=2, alpha=0.7)\nax[2].plot(train.groupby('pickup_week_hour').mean()['avg_speed_h'], 'ro-', lw=2, alpha=0.7)\nax[0].set_xlabel('hour')\nax[1].set_xlabel('weekday')\nax[2].set_xlabel('weekhour')\nax[0].set_ylabel('average speed')\nfig.suptitle('Rush hour average traffic speed')\nplt.show()", "outputs": [], "execution_count": 21}, {"cell_type": "code", "metadata": {"_cell_guid": "239090f5-941d-49bf-ba29-3476c3c80af1", "_execution_state": "idle", "_uuid": "fc16f8005a2799efe5517467c4953c1919031027", "trusted": false}, "source": "train.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 3)\ntrain.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 3)\n# Average speed for regions\ngby_cols = ['pickup_lat_bin', 'pickup_long_bin']\ncoord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\ncoord_count = train.groupby(gby_cols).count()[['id']].reset_index()\ncoord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\ncoord_stats = coord_stats[coord_stats['id'] > 100]\nfig, ax = plt.subplots(ncols=1, nrows=1)\nax.scatter(train.pickup_longitude.values[:N], train.pickup_latitude.values[:N], color='black', s=1, alpha=0.5)\nax.scatter(coord_stats.pickup_long_bin.values, coord_stats.pickup_lat_bin.values, c=coord_stats.avg_speed_h.values,\n           cmap='RdYlGn', s=20, alpha=0.5, vmin=1, vmax=8)\nax.set_xlim(city_long_border)\nax.set_ylim(city_lat_border)\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\nplt.title('Average speed')\nplt.show()\n\ntrain.loc[:, 'pickup_lat_bin'] = np.round(train['pickup_latitude'], 2)\ntrain.loc[:, 'pickup_long_bin'] = np.round(train['pickup_longitude'], 2)\ntrain.loc[:, 'center_lat_bin'] = np.round(train['center_latitude'], 2)\ntrain.loc[:, 'center_long_bin'] = np.round(train['center_longitude'], 2)\ntrain.loc[:, 'pickup_dt_bin'] = (train['pickup_dt'] // (3 * 3600))\ntest.loc[:, 'pickup_lat_bin'] = np.round(test['pickup_latitude'], 2)\ntest.loc[:, 'pickup_long_bin'] = np.round(test['pickup_longitude'], 2)\ntest.loc[:, 'center_lat_bin'] = np.round(test['center_latitude'], 2)\ntest.loc[:, 'center_long_bin'] = np.round(test['center_longitude'], 2)\ntest.loc[:, 'pickup_dt_bin'] = (test['pickup_dt'] // (3 * 3600))", "outputs": [], "execution_count": 22}, {"cell_type": "markdown", "metadata": {"_cell_guid": "fc4904e0-2466-4b7f-b867-5e133377d2b0", "_uuid": "3304d51e2705f3ef31ac782115d069838fc1192e"}, "source": "**Clustering**", "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"_cell_guid": "46e93d8f-94a1-4597-9453-bb40cb2f346c", "_execution_state": "idle", "_uuid": "e070934b88321aed37c4b88af5e1a08735b64636", "trusted": false}, "source": "sample_ind = np.random.permutation(len(coords))[:500000]\nkmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind])", "outputs": [], "execution_count": 23}, {"cell_type": "code", "metadata": {"_cell_guid": "15e5fe57-5036-49a0-8652-77c0b139c4ae", "_execution_state": "idle", "_uuid": "a2084716e0add6ca198acbd6f21b13a02b6e2505", "trusted": false}, "source": "train.loc[:, 'pickup_cluster'] = kmeans.predict(train[['pickup_latitude', 'pickup_longitude']])\ntrain.loc[:, 'dropoff_cluster'] = kmeans.predict(train[['dropoff_latitude', 'dropoff_longitude']])\ntest.loc[:, 'pickup_cluster'] = kmeans.predict(test[['pickup_latitude', 'pickup_longitude']])\ntest.loc[:, 'dropoff_cluster'] = kmeans.predict(test[['dropoff_latitude', 'dropoff_longitude']])\nt1 = dt.datetime.now()\nprint('Time till clustering: %i seconds' % (t1 - t0).seconds)", "outputs": [], "execution_count": 24}, {"cell_type": "code", "metadata": {"_cell_guid": "3d85e800-83d6-4475-b3a5-9ab5fae73338", "_execution_state": "busy", "_uuid": "6cdaa0a6044d0fed41d154b3a088467a13620e7f", "trusted": false}, "source": "fig, ax = plt.subplots(ncols=1, nrows=1)\nax.scatter(train.pickup_longitude.values[:N], train.pickup_latitude.values[:N], s=10, lw=0,\n           c=train.pickup_cluster[:N].values, cmap='tab20', alpha=0.2)\nax.set_xlim(city_long_border)\nax.set_ylim(city_lat_border)\nax.set_xlabel('Longitude')\nax.set_ylabel('Latitude')\nplt.show()", "outputs": [], "execution_count": 25}, {"cell_type": "code", "metadata": {"_cell_guid": "0ee8d5b3-cdd5-45b4-b6f6-d70e388f075f", "_execution_state": "busy", "collapsed": true, "_uuid": "fd4ef946e2885f66fbb23b3322ca5064980468dc", "trusted": false}, "source": "for gby_col in ['pickup_hour', 'pickup_date', 'pickup_dt_bin',\n               'pickup_week_hour', 'pickup_cluster', 'dropoff_cluster']:\n    gby = train.groupby(gby_col).mean()[['avg_speed_h', 'avg_speed_m', 'log_trip_duration']]\n    gby.columns = ['%s_gby_%s' % (col, gby_col) for col in gby.columns]\n    train = pd.merge(train, gby, how='left', left_on=gby_col, right_index=True)\n    test = pd.merge(test, gby, how='left', left_on=gby_col, right_index=True)\n\nfor gby_cols in [['center_lat_bin', 'center_long_bin'],\n                 ['pickup_hour', 'center_lat_bin', 'center_long_bin'],\n                 ['pickup_hour', 'pickup_cluster'],  ['pickup_hour', 'dropoff_cluster'],\n                 ['pickup_cluster', 'dropoff_cluster']]:\n    coord_speed = train.groupby(gby_cols).mean()[['avg_speed_h']].reset_index()\n    coord_count = train.groupby(gby_cols).count()[['id']].reset_index()\n    coord_stats = pd.merge(coord_speed, coord_count, on=gby_cols)\n    coord_stats = coord_stats[coord_stats['id'] > 100]\n    coord_stats.columns = gby_cols + ['avg_speed_h_%s' % '_'.join(gby_cols), 'cnt_%s' %  '_'.join(gby_cols)]\n    train = pd.merge(train, coord_stats, how='left', on=gby_cols)\n    test = pd.merge(test, coord_stats, how='left', on=gby_cols)", "outputs": [], "execution_count": 26}, {"cell_type": "code", "metadata": {"_cell_guid": "32d7c5ec-d170-4663-a1a4-f452b723472f", "_execution_state": "busy", "collapsed": true, "_uuid": "09d3182c091d0d8178e9e35693774d859f9cd90f", "trusted": false}, "source": "group_freq = '60min'\ndf_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\ntrain.loc[:, 'pickup_datetime_group'] = train['pickup_datetime'].dt.round(group_freq)\ntest.loc[:, 'pickup_datetime_group'] = test['pickup_datetime'].dt.round(group_freq)\n\n# Count trips over 60min\ndf_counts = df_all.set_index('pickup_datetime')[['id']].sort_index()\ndf_counts['count_60min'] = df_counts.isnull().rolling(group_freq).count()['id']\ntrain = train.merge(df_counts, on='id', how='left')\ntest = test.merge(df_counts, on='id', how='left')\n\n# Count how many trips are going to each cluster over time\ndropoff_counts = df_all \\\n    .set_index('pickup_datetime') \\\n    .groupby([pd.TimeGrouper(group_freq), 'dropoff_cluster']) \\\n    .agg({'id': 'count'}) \\\n    .reset_index().set_index('pickup_datetime') \\\n    .groupby('dropoff_cluster').rolling('240min').mean() \\\n    .drop('dropoff_cluster', axis=1) \\\n    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'dropoff_cluster_count'})\n\ntrain['dropoff_cluster_count'] = train[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)\ntest['dropoff_cluster_count'] = test[['pickup_datetime_group', 'dropoff_cluster']].merge(dropoff_counts, on=['pickup_datetime_group', 'dropoff_cluster'], how='left')['dropoff_cluster_count'].fillna(0)", "outputs": [], "execution_count": 27}, {"cell_type": "code", "metadata": {"_cell_guid": "8bc20dd9-d744-4b44-a819-b9790e976fda", "_execution_state": "busy", "_uuid": "bc180c6616f56fa06fb69a732c357d5387b0d69b", "trusted": false}, "source": "df_all = pd.concat((train, test))[['id', 'pickup_datetime', 'pickup_cluster', 'dropoff_cluster']]\npickup_counts = df_all \\\n    .set_index('pickup_datetime') \\\n    .groupby([pd.TimeGrouper(group_freq), 'pickup_cluster']) \\\n    .agg({'id': 'count'}) \\\n    .reset_index().set_index('pickup_datetime') \\\n    .groupby('pickup_cluster').rolling('240min').mean() \\\n    .drop('pickup_cluster', axis=1) \\\n    .reset_index().set_index('pickup_datetime').shift(freq='-120min').reset_index() \\\n    .rename(columns={'pickup_datetime': 'pickup_datetime_group', 'id': 'pickup_cluster_count'})\n\ntrain['pickup_cluster_count'] = train[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)\ntest['pickup_cluster_count'] = test[['pickup_datetime_group', 'pickup_cluster']].merge(pickup_counts, on=['pickup_datetime_group', 'pickup_cluster'], how='left')['pickup_cluster_count'].fillna(0)", "outputs": [], "execution_count": 28}, {"cell_type": "code", "metadata": {"_cell_guid": "b7115231-0bd7-4523-9191-1ddcbf242f06", "_execution_state": "busy", "_uuid": "ff6ddcef845e835e286a450b5854a75f3c67daaa", "trusted": false}, "source": "fr1 = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_1.csv', usecols=['id', 'total_distance', 'total_travel_time',  'number_of_steps'])\nfr2 = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_train_part_2.csv', usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\ntest_street_info = pd.read_csv('../input/new-york-city-taxi-with-osrm/fastest_routes_test.csv',\n                               usecols=['id', 'total_distance', 'total_travel_time', 'number_of_steps'])\ntrain_street_info = pd.concat((fr1, fr2))\ntrain = train.merge(train_street_info, how='left', on='id')\ntest = test.merge(test_street_info, how='left', on='id')\ntrain_street_info.head()", "outputs": [], "execution_count": 29}, {"cell_type": "code", "metadata": {"_cell_guid": "656bbd7c-35fe-4f92-96b2-a5530d4cfc20", "_execution_state": "busy", "_uuid": "e4f21e20614bdbd0d0b5717764a6b4b091153887", "trusted": false}, "source": "feature_names = list(train.columns)\nprint(np.setdiff1d(train.columns, test.columns))\ndo_not_use_for_training = ['id', 'log_trip_duration', 'dow','pickup_datetime', 'dropoff_datetime', 'trip_duration', 'check_trip_duration',\n                           'pickup_date', 'avg_speed_h', 'avg_speed_m', 'pickup_lat_bin', 'pickup_long_bin',\n                           'center_lat_bin', 'month','center_long_bin', 'hour', 'pickup_dt_bin','Events', 'Conditions', 'pickup_datetime_group']\nfeature_names = [f for f in train.columns if f not in do_not_use_for_training]\n# print(feature_names)\nprint('We have %i features.' % len(feature_names))\ntrain[feature_names].count()\ny = np.log(train['trip_duration'].values + 1)\n\nt1 = dt.datetime.now()\nprint('Feature extraction time: %i seconds' % (t1 - t0).seconds)", "outputs": [], "execution_count": 36}, {"cell_type": "code", "metadata": {"_cell_guid": "25408feb-9151-4ebb-8559-9737d5a0a82e", "_execution_state": "busy", "_uuid": "f4abc2ddd3f402fcb1e4987c43a49d8487847bc3", "trusted": false}, "source": "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\ndtrain = xgb.DMatrix(Xtr, label=ytr)\ndvalid = xgb.DMatrix(Xv, label=yv)\ndtest = xgb.DMatrix(test[feature_names].values)\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]", "outputs": [], "execution_count": 37}, {"cell_type": "code", "metadata": {"_cell_guid": "1c677e15-bf67-4fe4-8ebc-c965a9001123", "_execution_state": "busy", "collapsed": true, "_uuid": "73c4e52e54ad4aecfd9bbc587400ef7808547be2", "trusted": false}, "source": "xgb_pars = {'min_child_weight': 15, 'eta': 0.5, 'colsample_bytree': 0.3, 'max_depth': 10,\n            'subsample': 1, 'lambda': 20, 'nthread': -1, 'booster' : 'gbtree', 'silent': 0,\n            'eval_metric': 'rmse', 'objective': 'reg:linear'}", "outputs": [], "execution_count": 39}, {"cell_type": "code", "metadata": {"_cell_guid": "c2fc6887-9916-4df6-bdc4-ee3db436961f", "_uuid": "df7f8ab9b038dcfaf48bb170ae3d1da78ae9269f", "trusted": false}, "source": "model = xgb.train(xgb_pars, dtrain, 10, watchlist, early_stopping_rounds=100,\n                  maximize=False, verbose_eval=2)", "outputs": [], "execution_count": 40}, {"cell_type": "code", "metadata": {"_cell_guid": "bf260df1-bb14-4580-9d15-34099292848f", "_execution_state": "busy", "_uuid": "cc9e3fc05b234162279c8d66456970d35db2943b", "trusted": false}, "source": "print('Modeling RMSLE %.5f' % model.best_score)\nt1 = dt.datetime.now()\nprint('Training time: %i seconds' % (t1 - t0).seconds)", "outputs": [], "execution_count": 41}, {"cell_type": "code", "metadata": {"_cell_guid": "72a50256-4750-4082-a929-4049d7e82678", "_execution_state": "busy", "_uuid": "486c9ad7d0f02a99f01dbee65b3071caa09198ff", "trusted": false}, "source": "ytest = model.predict(dtest)\n#print('Test shape OK.') if test.shape[0] == ytest.shape[0] else print('Oops')\ntest['trip_duration'] = np.exp(ytest) - 1\ntest[['id', 'trip_duration']].to_csv('hamzaEnsari_2.csv.gz', index=False, compression='gzip')\n", "outputs": [], "execution_count": null}], "nbformat_minor": 1, "nbformat": 4}