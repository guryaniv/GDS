{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport sklearn.preprocessing as StandardScaler # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \ntf.logging.set_verbosity(tf.logging.ERROR)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv('../input/train.csv')\ndf_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62d0422f3b0dd93ed5f690115a22190982bdc409"},"cell_type":"code","source":"df_features = df_raw[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\nfillval = df_features.median()\ndf_features = df_features.fillna(fillval)\nlabels = df_raw['Survived']\ndf_features = pd.concat([df_features, pd.get_dummies(df_features['Pclass'], prefix='Pclass')], axis = 1)\ndf_features = pd.concat([df_features, pd.get_dummies(df_features['Sex'])], axis = 1)\ndf_features['FamilySize'] = df_features['SibSp'] + df_features['Parch']\ndf_features = df_features.drop(['Pclass', 'Sex', 'female'], axis=1)\ndf_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd9da23ed83333786db65f5110c73ac2edfcc0b4"},"cell_type":"code","source":"pd.DataFrame({'Non-Survivors': pd.concat([df_raw['Pclass'], labels], axis=1).groupby('Survived').get_group(0)['Pclass'],\n              'Survivors':   pd.concat([df_raw['Pclass'], labels], axis=1).groupby('Survived').get_group(1)['Pclass']}).plot.hist(stacked=False, alpha=0.5);\npd.DataFrame({'Non-Survivors': pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(0)['Age'],\n              'Survivors':   pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(1)['Age']}).plot.hist(stacked=False, alpha=0.5);\npd.DataFrame({'Non-Survivors': pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(0)['male'],\n              'Survivors':   pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(1)['male']}).plot.hist(stacked=False, alpha=0.5);\npd.DataFrame({'Non-Survivors': pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(0)['Fare'],\n              'Survivors':   pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(1)['Fare']}).plot.hist(stacked=False, alpha=0.5);\npd.DataFrame({'Non-Survivors': pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(0)['FamilySize'],\n              'Survivors':   pd.concat([df_features, labels], axis=1).groupby('Survived').get_group(1)['FamilySize']}).plot.hist(stacked=False, alpha=0.5);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8968a447fb0217bd049bd9db79a5b95e809d1386","collapsed":true},"cell_type":"code","source":"df_feature_train, df_feature_validate, labels_train, labels_validate = train_test_split(df_features, labels, test_size=0.2)\n                 \nfeature_scaler = sklearn.preprocessing.StandardScaler(copy=True)\nfeature_scaler.fit(df_feature_train.values)\n\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(df_feature_train.values)},\n    y=labels_train.values,\n    batch_size=32,\n    num_epochs=5000,\n    shuffle=True)\n\nvalidate_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(df_feature_validate.values)},\n    y=labels_validate.values,\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5482539e2aa07e7b9d25997237b18554ca81cc7b"},"cell_type":"code","source":"def model_fn(features, labels, mode, params):\n    layer = features['x']\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        layer = tf.layers.dropout(inputs=layer, rate=0.1, training=mode == tf.estimator.ModeKeys.TRAIN)\n    layer = tf.layers.dense(inputs=layer, units=64, activation=tf.nn.relu)\n    layer = tf.layers.dense(inputs=layer, units=32, activation=tf.nn.relu)\n    layer = tf.layers.dense(inputs=layer, units=8)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        layer = tf.layers.dropout(inputs=layer, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n    # Logits Layer\n    logits = tf.layers.dense(inputs=layer, units=params['num_classes'])\n\n    predictions = {\n        \"classes\": tf.argmax(input=logits, axis=1),\n        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    weights = tf.gather(params['weights'], labels)\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, weights=weights) \n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(\n          loss=loss,\n          global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        \"accuracy\": tf.metrics.accuracy(\n            labels=labels, predictions=predictions[\"classes\"]),\n        \"recall\": tf.metrics.recall(\n            labels=labels, predictions=predictions[\"classes\"]),\n        \"precision\": tf.metrics.precision(\n            labels=labels, predictions=predictions[\"classes\"])}\n    return tf.estimator.EstimatorSpec(\n        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n\nclassifier = tf.estimator.Estimator(\n    model_fn=model_fn,\n    params={'num_classes': 2,\n           'weights': [1., 1]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e7f58ff001217c7a86970a8892b45bef4576ea1"},"cell_type":"code","source":"classifier.train(input_fn=train_input_fn)\nprint(classifier.evaluate(input_fn=validate_input_fn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28d4102894d272f73d21a3d9d3c0eedc6a5fb254"},"cell_type":"code","source":"predicted = np.array(list(map(lambda x: x['classes'], classifier.predict(input_fn=validate_input_fn))))\ntmp = pd.DataFrame(sklearn.metrics.confusion_matrix(labels_validate.values, predicted.astype(np.int32)))\nplt.subplots(figsize=(4,4)) \nsns.heatmap(tmp, annot=True, fmt='.1f');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f0e9e2878a6ab8facc4c26beb093ed6d83bec36"},"cell_type":"code","source":"df_test_raw= pd.read_csv('../input/test.csv')\ndf_test = df_test_raw.fillna(fillval)\ndf_test.describe()\ndf_test = df_test[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\ndf_test = pd.concat([df_test, pd.get_dummies(df_test['Pclass'], prefix='Pclass')], axis = 1)\ndf_test = pd.concat([df_test, pd.get_dummies(df_test['Sex'])], axis = 1)\ndf_test['FamilySize'] = df_test['SibSp'] + df_test['Parch']\ndf_test = df_test.drop(['Pclass', 'Sex', 'female'], axis=1)\n\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(df_test.values)},\n    shuffle=False)\n\npredicted = list(map(lambda x: x['classes'], classifier.predict(input_fn=test_input_fn)))\ndf_result = df_test_raw[['PassengerId']]\ndf_result['Survived'] = predicted\ndf_result.to_csv('submission.csv', index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}