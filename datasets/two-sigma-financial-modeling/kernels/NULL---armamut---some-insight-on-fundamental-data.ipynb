{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "71fdebda-735f-46bd-ff0d-932db6fdcbde"
      },
      "source": [
        "Did you look at the fundamental data? How did they construct them? Let's find out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f5c7bac1-31aa-c968-c5e4-cdc92582024e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "\n",
        "# Pandas configuration\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d0aadf8-8621-1693-3f3a-ce6e9e1a3667"
      },
      "outputs": [],
      "source": [
        "# Usual stuff...\n",
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
        "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
        "    df = train.get(\"train\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f34195a-ea79-fbea-103c-02f904e376c8"
      },
      "source": [
        "Now, with the data loaded, let's look at some fundamental indicators to see if we can find out something."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6bc5032-b264-bc9a-a775-d7068310e789"
      },
      "outputs": [],
      "source": [
        "asset = df[ df['id'] == 12 ] # some random asset. you can try out with different ids\n",
        "\n",
        "y1 = asset['fundamental_1'] # some fundamental indicators. you can try the other indicators\n",
        "y2 = asset['fundamental_3'] # they all show the same phenomenon.\n",
        "y3 = asset['fundamental_6']\n",
        "y4 = asset['fundamental_19']\n",
        "\n",
        "py.iplot({'data': [{'y': y1}, {'y': y2}, {'y': y3}, {'y': y4}]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b3089d70-7493-2350-43aa-5f74c0ccd49d"
      },
      "source": [
        "As you can see, these indicator data have some sudden changes, then slowly converges to some value, then suddenly changes again. It looks like, the data has been constructed from some kind of a discrete function (like a square wave) and some low-pass filter applied on it. I think simple and assume they used some kind of exponential moving average (EMA).\n",
        "\n",
        "Now let's look at time-derivative (delta) of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f9aa141-2963-71fd-ba3e-2fabe78f54f6"
      },
      "outputs": [],
      "source": [
        "y1d = y1 - y1.shift(1)\n",
        "y2d = y2 - y2.shift(1)\n",
        "y3d = y3 - y3.shift(1)\n",
        "y4d = y4 - y4.shift(1)\n",
        "\n",
        "py.iplot({'data': [{'y': y1d}, {'y': y2d}, {'y': y3d}, {'y': y4d}]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6600455c-6529-093a-6797-377d898de71c"
      },
      "source": [
        "The graphs are indeed as expected. They show some sudden jumps and fade out. But if you zoom them, they are not perfect. They have some noisy spikes on them. We'll look at this later, but first lets look at the periodicity of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e74fe99a-c92b-3f2f-e361-7a0cf4084e47"
      },
      "outputs": [],
      "source": [
        "# http://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation\n",
        "def autocorr(x):\n",
        "    result = np.correlate(x, x, mode='full')\n",
        "    return result[int(result.size/2):]\n",
        "\n",
        "acc = abs(autocorr( y1d.fillna(method='bfill') ))\n",
        "\n",
        "py.iplot({'data': [{'y': acc}, {'y':y1d}]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "442bbc57-28d1-c76f-533b-2e5cf24de136"
      },
      "source": [
        "The autocorrelation function shows, there is a strong periodicity at about 50, 200, 250 etc. for this asset and data, in this case id=12 and indicator \"fundamental_1\". Let's look at other indicators for this asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "770a40ce-905b-da44-31fa-0ce86d73887a"
      },
      "outputs": [],
      "source": [
        "fundamentals = ['fundamental_0','fundamental_1','fundamental_2',\n",
        "                'fundamental_3','fundamental_5','fundamental_6',\n",
        "                'fundamental_7','fundamental_8','fundamental_9',\n",
        "                'fundamental_10','fundamental_11','fundamental_12',\n",
        "                'fundamental_13','fundamental_14','fundamental_15',\n",
        "                'fundamental_16','fundamental_17','fundamental_18',\n",
        "                'fundamental_19','fundamental_20','fundamental_21',\n",
        "                'fundamental_22','fundamental_23','fundamental_24',\n",
        "                'fundamental_25','fundamental_26','fundamental_27',\n",
        "                'fundamental_28','fundamental_29','fundamental_30',\n",
        "                'fundamental_31','fundamental_32','fundamental_33',\n",
        "                'fundamental_34','fundamental_35','fundamental_36',\n",
        "                'fundamental_37','fundamental_38','fundamental_39',\n",
        "                'fundamental_40','fundamental_41','fundamental_42',\n",
        "                'fundamental_43','fundamental_44','fundamental_45',\n",
        "                'fundamental_46','fundamental_47','fundamental_48',\n",
        "                'fundamental_49','fundamental_50','fundamental_51',\n",
        "                'fundamental_52','fundamental_53','fundamental_54',\n",
        "                'fundamental_55','fundamental_56','fundamental_57',\n",
        "                'fundamental_58','fundamental_59','fundamental_60',\n",
        "                'fundamental_61','fundamental_62','fundamental_63']\n",
        "\n",
        "asset = df[ df['id'] == 12 ]\n",
        "datas = []\n",
        "for f in fundamentals:\n",
        "    y1 = asset[f]\n",
        "    y1d = y1 - y1.shift(1)\n",
        "    acc = abs(autocorr( y1d.fillna(method='bfill') ))\n",
        "    pp = (acc[20:300]).argmax() + 20\n",
        "    datas.append((f, pp))\n",
        "\n",
        "datas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "07248bd9-096f-b7c0-1f0f-22f6d7af17d0"
      },
      "source": [
        "As you can see, most of the fundamental indicators have some 50's (or multiples) periodicity. You can test this with other assets too.\n",
        "\n",
        "Now, let's turn back to the EMA. We are searching for alpha values over EMA formula\n",
        "\n",
        "y(t) = alpha . y(t-1) + (1-alpha) . k\n",
        "\n",
        "where, k is real value of the process, and y is the process output (the data we have). I took some data, and with some trials on Excel (and some luck), I have found that alpha = 0.87055 gives best fit. I tried with other assets and fundamental indicators and there is indeed an EMA relation between the data and underlying variable (which we still don't know).\n",
        "\n",
        "Let's look at some graphs and see what I mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "19e55ee4-e990-68a9-9d1f-82deb3e1aa96"
      },
      "outputs": [],
      "source": [
        "y1 = asset['fundamental_6']\n",
        "y1 = y1.fillna(method='pad')\n",
        "alpha = 0.87055\n",
        "yy = (y1 - alpha * y1.shift(1)) / (1-alpha)\n",
        "\n",
        "py.iplot({'data': [{'y': y1}, {'y': yy}]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "af93cf1c-a227-58eb-1a84-242fc01dc921"
      },
      "source": [
        "It seems that, they have indeed added some noise and used EMA formula over some discreet function to produce the fundamental values. To smooth out the noisy part, I have used rolling median. Now it seems more clear.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65376718-c5fb-6eb5-be14-a6254430dcbb"
      },
      "outputs": [],
      "source": [
        "y1 = asset['fundamental_6']\n",
        "y1 = y1.fillna(method='pad')\n",
        "alpha = 0.87055\n",
        "yy = (y1 - alpha * y1.shift(1)) / (1-alpha)\n",
        "yy = yy.rolling(7).median(center=True)\n",
        "\n",
        "py.iplot({'data': [{'y': y1}, {'y': yy}]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "529b0fc4-93af-7abd-ee2a-1d41d221f15a"
      },
      "source": [
        "You can play with other indicators as well. It seems that every indicator has been produced this way.\n",
        "\n",
        "If you have some idea about what they could have been, please comment below. Thank you."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}