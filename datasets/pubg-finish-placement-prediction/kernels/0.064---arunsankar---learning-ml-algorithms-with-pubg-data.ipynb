{"cells":[{"metadata":{"_uuid":"830004a65f7641ae40f50d0cbfd312cdc84296cc"},"cell_type":"markdown","source":"**Thanks for viewing my Kernel! If you like my work and find it useful, please leave an upvote! :)**\n\nFor exploratory data analysis and data visualization, please check [my kernel](https://www.kaggle.com/arunsankar/key-insights-from-pubg-data). In this kernel, I will apply different machine learning algorithms on the data."},{"metadata":{"_uuid":"137bca78efc31c77262e9ef9e421137cf4f99f76"},"cell_type":"markdown","source":"**Import required libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nfrom sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"980b590aa4ebeef301d94db874b0aa28b6f00fcb"},"cell_type":"markdown","source":"**Read Data**"},{"metadata":{"trusted":true,"_uuid":"777cb104af5a32c9b996c14d475dd22f0171b7cb"},"cell_type":"code","source":"train = pd.read_csv('../input/train_V2.csv')\ntest = pd.read_csv('../input/test_V2.csv')\nsub=pd.read_csv(\"../input/sample_submission_V2.csv\")\n\ntrain.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4f3c8494a8125293c395f8b9c708b1f6a8bcde91"},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{"trusted":true,"_uuid":"c75aa7d9f40bd11f84f1cd06b57bc35187ee4820"},"cell_type":"code","source":"def feature_engineering(df):\n    # Sum of all distances\n    df['allDistance'] = df['rideDistance']+df['swimDistance']+df['walkDistance']\n    # Sum of all kills and assists\n    df['allKills'] = df['headshotKills']+df['kills']+df['roadKills']+df['teamKills']+df['assists']\n    # Special Kills\n    df[\"specialKills\"] = df[\"headshotKills\"] + df[\"roadKills\"]\n    # % of head shot kills\n    df['headshotKillRate'] = df['headshotKills'] / df['kills']\n    # Kills per walk distance\n    df['killsOverWalkDistance'] = df['kills'] / df['walkDistance']\n    # kills per total distance\n    df['killsOverDistance'] = df['kills'] / df['allDistance']\n    # kill place over max place\n    df['killPlaceOverMaxPlace'] = df['killPlace'] / df['maxPlace']\n    # Sum of boosts and heals\n    df['boosters'] = df['heals'] + df['boosts']\n    # Kill Place Percentile\n    df['killPlacePerc'] = df['kills'].rank(pct=True).values\n    # Find Zombis\n    df['zombi'] = ((df['allDistance'] == 0) & \n                   (df['kills'] == 0) & \n                   (df['weaponsAcquired'] == 0) &\n                   (df['matchType'].str.contains('solo'))\n                  ).astype(int)\n    # Find Cheaters\n    df['cheater'] = ((df['kills'] / df['allDistance'] >= 1) | \n                     (df['kills'] > 30) | (df['roadKills'] > 10)).astype(int)\n    return df\n\ntrain = feature_engineering(train)\ntest = feature_engineering(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eaf8455d442229dd821591fcda118cbc4f5801a"},"cell_type":"code","source":"def fillInf(df, val):\n    numcols = df.select_dtypes(include='number').columns\n    cols = numcols[numcols != 'winPlacePerc']\n    df[df == np.Inf] = np.NaN\n    df[df == np.NINF] = np.NaN\n    for c in cols:\n        df[c].fillna(val, inplace=True)\n\nfillInf(train,0)\nfillInf(test,0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dbd54450f95301bddc5bfcf56694bfc9b550558"},"cell_type":"markdown","source":"**Optimize memory usage**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Thanks and credited to https://www.kaggle.com/gemartin who created this wonderful mem reducer\n# iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \ndef reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.0f} bytes'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum()\n    print('Memory usage after optimization is: {:.0f} bytes'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n\ntrain = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee32bf4e8cea45e09b8a298f50ea73bb9b2f6480"},"cell_type":"code","source":"columns = test.select_dtypes(include='number').columns\n\ny_train = train[['winPlacePerc']]\nx_train, x_valid, y_train, y_valid = train_test_split(train[columns], y_train, test_size = 0.2, random_state = 42)\nx_test = test[columns]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d33124a336778204843eb840913d78ab6b73d153"},"cell_type":"markdown","source":"**LGBM model**"},{"metadata":{"trusted":true,"_uuid":"afb0d2933a669d11c6e076c99503197350e81067"},"cell_type":"code","source":"def run_lgb(x_train, y_train, x_valid, y_valid, x_test):\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"mae\",\n        \"num_leaves\" : 40,\n        \"learning_rate\" : 0.004,\n        \"bagging_fraction\" : 0.6,\n        \"feature_fraction\" : 0.6,\n        \"bagging_frequency\" : 6,\n        \"bagging_seed\" : 42,\n        \"verbosity\" : -1,\n        \"seed\": 42\n    }\n    \n    lgb_train = lgb.Dataset(x_train, label=y_train)\n    lgb_valid = lgb.Dataset(x_valid, label=y_valid)\n    evals_result = {}\n    model = lgb.train(params, \n                      lgb_train, \n                      1000, \n                      valid_sets=[lgb_train, lgb_valid], \n                      early_stopping_rounds=100, \n                      verbose_eval=50, \n                      evals_result=evals_result)\n    \n    pred_y_test = model.predict(x_test, num_iteration=model.best_iteration)\n    return pred_y_test, model, evals_result\n\n# Training LGB model\npred_y_test, model, evals_result = run_lgb(x_train, y_train, x_valid, y_valid, x_test)\nprint(\"LightGBM Training Completed...\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfe38073db032fe9812a556ab96dad7b2f9a0c08"},"cell_type":"code","source":"sub['winPlacePerc'] = pred_y_test\nsub['winPlacePerc'] = sub['winPlacePerc'].apply(lambda x:1 if x>1 else x)\nsub['winPlacePerc'] = sub['winPlacePerc'].apply(lambda x:0 if x<0 else x)\nsub.to_csv('LGBM_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ffd6ba90f5b727af2e2ea55797de44bb6b0dee40"},"cell_type":"code","source":"print('Plotting feature importances...')\nax = lgb.plot_importance(model, max_num_features=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89dc4b42c682986f8fdb5b4f17ea0138234f9a89"},"cell_type":"markdown","source":"**Decision Tree Regressor from SciKit**"},{"metadata":{"trusted":true,"_uuid":"973db967326e29f9f0b42fd0ec596c91919585e2"},"cell_type":"code","source":"dtg_model = DecisionTreeRegressor(\n    max_depth=5,\n    min_samples_split=0.1\n)\ndtg_model.fit(x_train, y_train)\nsub['winPlacePerc'] = dtg_model.predict(x_test)\nsub.to_csv('DTR_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f804a977ed4e774acd217534074caa8377d51b5f"},"cell_type":"code","source":"dtg_model.feature_importances_","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}