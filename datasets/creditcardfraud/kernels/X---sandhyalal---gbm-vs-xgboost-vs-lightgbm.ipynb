{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f2e65080-5c69-cd2e-d515-8c569cbf8fca"
      },
      "source": [
        "# Motivation\n",
        "\n",
        "I have been \"Kaggling\" (that can be a verb, right?) since before **GBM** was cool. An over trained set of **GBM** models got me a 2nd place finish in the [Dunnhumby's Shopper Challenge](https://www.kaggle.com/c/dunnhumbychallenge/leaderboard).  Since then I have spent my time working on projects that didn't require boosted algorithms. Now that I have some free time, I wanted to explore **xgboost** (the GBM killer) and its new challenger **lightGBM**. This notebook will explore the speed and accuracy of each model and discuss any observations I have along the way.\n",
        "\n",
        "# Boring Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d3c61522-9fc4-8337-a68a-ec10015da972"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "library(pROC, quietly=TRUE)\n",
        "library(microbenchmark, quietly=TRUE)\n",
        "\n",
        "# Set seed so the train/test split is reproducible\n",
        "set.seed(42)\n",
        "\n",
        "# Read in the data and split it into train/test subsets\n",
        "credit.card.data = read.csv(\"../input/creditcard.csv\")\n",
        "\n",
        "train.test.split <- sample(2\n",
        "\t, nrow(credit.card.data)\n",
        "\t, replace = TRUE\n",
        "\t, prob = c(0.7, 0.3))\n",
        "train = credit.card.data[train.test.split == 1,]\n",
        "test = credit.card.data[train.test.split == 2,]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "287aaa2e-5014-1a66-3d17-5c6b557ae1f1"
      },
      "source": [
        "# Feature Creation\n",
        "\n",
        "This section is empty. Converting the time values to hour or day would probably improve the accuracy, but that is not the purpose of this kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "61aff1b1-0c3e-f917-387f-29b05fde367a"
      },
      "source": [
        "# Modeling\n",
        "\n",
        "I have attempted to select a common set of parameters for each model, but that is not entirely possible. (*max_depth* vs *num_leaves* in **xgboost** and **lightGBM**) The following are some of the assumptions and choices made during this modeling process.\n",
        "\n",
        "* The data will be placed into the their preferred data formats before calling the models.\n",
        "* Models will not be trained with cross-validation.\n",
        "* If possible, different number of cores will be used during the speed analysis. (future mod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6ce35725-33be-6d6e-2720-6e2cd0ffea21"
      },
      "source": [
        "## GBM\n",
        "\n",
        "Training the GBM is slow enough, I am not going to bother microbenchmarking it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9c54cbb-a876-558c-fff1-ccdb0b4f60c3"
      },
      "outputs": [],
      "source": [
        "library(gbm, quietly=TRUE)\n",
        "\n",
        "# Get the time to train the GBM model\n",
        "system.time(\n",
        "\tgbm.model <- gbm(Class ~ .\n",
        "\t\t, distribution = \"bernoulli\"\n",
        "\t\t, data = rbind(train, test)\n",
        "\t\t, n.trees = 500\n",
        "\t\t, interaction.depth = 3\n",
        "\t\t, n.minobsinnode = 100\n",
        "\t\t, shrinkage = 0.01\n",
        "\t\t, bag.fraction = 0.5\n",
        "\t\t, train.fraction = nrow(train) / (nrow(train) + nrow(test))\n",
        "\t\t)\n",
        ")\n",
        "# Determine best iteration based on test data\n",
        "best.iter = gbm.perf(gbm.model, method = \"test\")\n",
        "gbm.influence = relative.influence(gbm.model, n.trees = best.iter, sort. = TRUE)\n",
        "\n",
        "# Plot and calculate AUC on test data\n",
        "gbm.test = predict(gbm.model, newdata = test, n.trees = best.iter)\n",
        "auc.gbm = roc(test$Class, gbm.test, plot = TRUE, col = \"red\")\n",
        "print(auc.gbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f694f3f-43e3-0c58-8f6f-f07de5c2967d"
      },
      "source": [
        "## xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f8d702bc-f7c9-d00a-b82d-ff74b5167974"
      },
      "outputs": [],
      "source": [
        "library(xgboost, quietly=TRUE)\n",
        "xgb.data.train <- xgb.DMatrix(as.matrix(train[, colnames(train) != \"Class\"]), label = train$Class)\n",
        "xgb.data.test <- xgb.DMatrix(as.matrix(test[, colnames(test) != \"Class\"]), label = test$Class)\n",
        "\n",
        "# Get the time to train the xgboost model\n",
        "# IGNORE WARNINGS: the suggested parameters were not working as intended at this time.\n",
        "xgb.bench = microbenchmark(\n",
        "\txgb.model <- xgb.train(data = xgb.data.train\n",
        "\t\t, params = list(objective = \"binary:logistic\"\n",
        "\t\t\t, eta = 0.1\n",
        "\t\t\t, max.depth = 3\n",
        "\t\t\t, min_child_weight = 100\n",
        "\t\t\t, subsample = 1\n",
        "\t\t\t, colsample_bytree = 1\n",
        "\t\t\t, nthread = 3\n",
        "\t\t\t, eval_metric = \"auc\"\n",
        "\t\t\t)\n",
        "\t\t, watchlist = list(test = xgb.data.test)\n",
        "\t\t, nrounds = 500\n",
        "\t\t, early.stop.round = 40\n",
        "\t\t, print.every.n = 20\n",
        "\t\t)\n",
        "    , times = 5L\n",
        ")\n",
        "print(xgb.bench)\n",
        "print(xgb.model$bestScore)\n",
        "\n",
        "# Make predictions on test set for ROC curve\n",
        "xgb.test = predict(xgb.model, newdata = as.matrix(test[, colnames(test) != \"Class\"]), ntreelimit = xgb.model$bestInd)\n",
        "auc.xgb = roc(test$Class, xgb.test, plot = TRUE, col = \"blue\")\n",
        "print(auc.xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "59fec7ed-727a-f92b-d59d-1ffa447629b2"
      },
      "source": [
        "## lightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "964fa5d7-597f-1a15-d666-34d7a4abc12d"
      },
      "outputs": [],
      "source": [
        "library(lightgbm, quietly=TRUE)\n",
        "lgb.train = lgb.Dataset(as.matrix(train[, colnames(train) != \"Class\"]), label = train$Class)\n",
        "lgb.test = lgb.Dataset(as.matrix(test[, colnames(test) != \"Class\"]), label = test$Class)\n",
        "\n",
        "params.lgb = list(\n",
        "\tobjective = \"binary\"\n",
        "\t, metric = \"auc\"\n",
        "\t, min_data_in_leaf = 1\n",
        "\t, min_hess = 100\n",
        "\t, feature_fraction = 1\n",
        "\t, bagging_fraction = 1\n",
        "\t, bagging_freq = 0\n",
        "\t)\n",
        "\n",
        "# Get the time to train the lightGBM model\n",
        "lgb.bench = microbenchmark(\n",
        "\tlgb.model <- lgb.train(\n",
        "\t\tparams = params.lgb\n",
        "\t\t, data = lgb.train\n",
        "\t\t, valids = list(test = lgb.test)\n",
        "\t\t, learning_rate = 0.1\n",
        "\t\t, num_leaves = 7\n",
        "\t\t, num_threads = 2\n",
        "\t\t, nrounds = 500\n",
        "\t\t, early_stopping_rounds = 40\n",
        "\t\t, eval_freq = 20\n",
        "\t\t)\n",
        "\t\t, times = 5L\n",
        ")\n",
        "print(lgb.bench)\n",
        "print(max(unlist(lgb.model$record_evals[[\"test\"]][[\"auc\"]][[\"eval\"]])))\n",
        "\n",
        "lgb.test = predict(lgb.model, data = as.matrix(test[, colnames(test) != \"Class\"]), n = lgb.model$best_iter)\n",
        "auc.lgb = roc(test$Class, lgb.test, plot = TRUE, col = \"green\")\n",
        "print(auc.lgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b627a20-fe3e-1b39-8818-4047fdb0e656"
      },
      "source": [
        "# Results\n",
        "\n",
        "## Speed\n",
        "\n",
        "The following shows the estimated **GBM** benchmark (see above for actual) and the microbenchmark results for the **xgboost** and **lightgbm** models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4a8bc848-1841-7ac9-d81e-401b3e5aeae2"
      },
      "outputs": [],
      "source": [
        "print(\"GBM = ~263s\")\n",
        "print(xgb.bench)\n",
        "print(lgb.bench)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "37d069b2-5a6e-b383-27c9-4a1a993d8ada"
      },
      "source": [
        "## Accuracy\n",
        "\n",
        "The following are the *AUC* results for the test set. \n",
        "\n",
        "\n",
        "### GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "82bbcf8f-96fb-80dd-09e9-1b279666a8f4"
      },
      "outputs": [],
      "source": [
        "print(auc.gbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f977fd5-5963-29cf-57cd-6e7bf2b61423"
      },
      "source": [
        "## xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e80c7564-19b7-9fa8-d0a1-277ac07f12c0"
      },
      "outputs": [],
      "source": [
        "print(auc.xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ba775a11-0d5b-aa78-8bb5-8c75ef068870"
      },
      "source": [
        "## lightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4bcc82db-8b51-b8da-6813-202598c1976e"
      },
      "outputs": [],
      "source": [
        "print(auc.lgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "170a3f49-33cb-d066-d8dd-f87a71f5f8ed"
      },
      "source": [
        "# Additional Observations\n",
        "\n",
        "## GBM\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* None\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* No early exit\n",
        "* Slower training\n",
        "* Less accurate\n",
        "\n",
        "## xgboost\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* Proven success (on kaggle)\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* Slower than lightGBM \n",
        "\n",
        "## lightGBM\n",
        "\n",
        "Advantages:\n",
        "\n",
        "* Fast training efficiency\n",
        "* Low memory usage\n",
        "* Better accuracy\n",
        "* Parallel learning supported\n",
        "* Deal with large scale of data\n",
        "* Corporate supported\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "* No feature influence?\n",
        "* Newer, so less community documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "77d9178c-6446-640d-c8a9-f834a9697a6a"
      },
      "source": [
        "## Post Script\n",
        "\n",
        "In this example lightGBM completed in 15% of the time it took xgboost. That seems too extreme to me. Any one have feedback on how I may not be fairly parameterizing xgboost in this comparison?"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}