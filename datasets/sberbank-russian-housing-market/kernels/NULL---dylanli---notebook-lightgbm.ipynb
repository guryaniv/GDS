{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb996d4c-fd89-8457-5e23-1ecbc0fd0b03"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "from sklearn import model_selection, preprocessing\n",
        "import lightgbm as lgbm\n",
        "import datetime\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "id_test = test.id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b066eb8-64af-3607-5c39-dbf4521135fc"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8272c374-52d7-5533-42ed-adaf52b5b65d"
      },
      "outputs": [],
      "source": [
        "####################################################\n",
        "d_train = pd.read_csv('../input/train.csv')\n",
        "d_test = pd.read_csv('../input/test.csv')\n",
        "id_test = test.id\n",
        "\n",
        "mult = .969\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########\n",
        "#convert data to in factorize\n",
        "joined =pd.concat([d_train,d_test])\n",
        "\n",
        "cat_cols = [x for x in joined.columns if joined[x].dtype == 'object']\n",
        "\n",
        "for col in cat_cols:\n",
        "   joined.loc[:,col] = pd.factorize(joined[col], sort=True)[0]\n",
        "\n",
        "train = joined[joined['price_doc'].notnull()]\n",
        "test = joined[joined['price_doc'].isnull()]\n",
        "\n",
        "del joined\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "y_train = train[\"price_doc\"] * mult + 10\n",
        "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "x_test = test.drop([\"id\", \"timestamp\"], axis=1)\n",
        "#########\n",
        "\n",
        "\n",
        "'''\n",
        "for c in x_train.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values))\n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "#This function I can't undersand\n",
        "\n",
        "\n",
        "for c in x_test.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values))\n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "'''\n",
        "\n",
        "predictions, model = runLGBM(x_train,y_train,x_test,seed_val=42)\n",
        "output_2 = pd.DataFrame({'id': id_test, 'price_doc': predictions})\n",
        "output_2.head()\n",
        "\n",
        "\n",
        "# Any results you write to the cruuent directory are saved as output.\n",
        "df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "df_train.drop(df_train[df_train[\"life_sq\"] > 7000].index, inplace=True)\n",
        "\n",
        "y_train = df_train['price_doc'].values * mult + 10\n",
        "id_test = df_test['id']\n",
        "\n",
        "\n",
        "num_train = len(df_train)\n",
        "df_all = pd.concat([df_train, df_test])\n",
        "# Next line just adds a lot of NA columns (becuase \"join\" only works on indexes)\n",
        "# but somewhow it seems to affect the result\n",
        "df_all = df_all.join(df_macro, on='timestamp', rsuffix='_macro')\n",
        "print(df_all.shape)\n",
        "\n",
        "# Add month-year\n",
        "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
        "month_year_cnt_map = month_year.value_counts().to_dict()\n",
        "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
        "\n",
        "# Add week-year count\n",
        "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
        "week_year_cnt_map = week_year.value_counts().to_dict()\n",
        "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
        "\n",
        "# Add month and day-of-week\n",
        "df_all['month'] = df_all.timestamp.dt.month\n",
        "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
        "\n",
        "# Other feature engineering\n",
        "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
        "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
        "joined =pd.concat([train,test])\n",
        "\n",
        "cat_cols = [x for x in joined.columns if joined[x].dtype == 'object']\n",
        "\n",
        "for col in cat_cols:\n",
        "   joined.loc[:,col] = pd.factorize(joined[col], sort=True)[0]\n",
        "\n",
        "train = joined[joined['price_doc'].notnull()]\n",
        "test = joined[joined['price_doc'].isnull()]\n",
        "\n",
        "del joined\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "#train_y = np.log(train[\"price_doc\"])\n",
        "train_y = train[\"price_doc\"]\n",
        "train_X = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "test_X = test.drop([\"id\", \"timestamp\"], axis=1)\n",
        "\n",
        "predictions, model = runLGBM(train_X, train_y, test_X, seed_val=42)\n",
        "\n",
        "\n",
        "predictions = np.round(predictions * 0.99)\n",
        "output_1 = pd.DataFrame({'id': id_test, 'price_doc': predictions})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bbf870ff-d897-3c3b-33e2-683ef240820e"
      },
      "outputs": [],
      "source": [
        "def runLGBM(train_X, train_y, test_X, seed_val=42):\n",
        "    \n",
        "    params = {\n",
        "        'boosting_type': 'gbdt', 'objective': 'regression', 'nthread': -1, 'verbose': 0,\n",
        "        'num_leaves': 31, 'learning_rate': 0.05, 'max_depth': -1,\n",
        "        'subsample': 1, 'subsample_freq': 1, 'colsample_bytree': 0.6, \n",
        "        'reg_alpha': 1, 'reg_lambda': 0.001, 'metric': 'rmse',\n",
        "        'min_split_gain': 0.5, 'min_child_weight': 1, 'min_child_samples': 10, 'scale_pos_weight': 1\n",
        "        }\n",
        "    #kf = KFold(n_splits=5, shuffle=True, random_state=seed_val)\n",
        "    pred_test_y = np.zeros(test_X.shape[0])\n",
        "    \n",
        "    train_set = lgbm.Dataset(train_X, train_y, silent=True)\n",
        "        \n",
        "    #practical_model = lgbm.train(practical_model_params, train_set=train_set, num_boost_round=1000,evals_result=[(dval, 'val')], early_stopping_rounds=20, verbose_eval=20)\n",
        "\n",
        "\n",
        "    model = lgbm.train(params, train_set=train_set, num_boost_round=300)\n",
        "    \n",
        "    pred_test_y = model.predict(test_X, num_iteration = model.best_iteration)\n",
        "    #print(best_num)\n",
        "    return pred_test_y , model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "93264350-2a08-c8bd-c6a6-e15813e6501a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "joined =pd.concat([train,test])\n",
        "\n",
        "cat_cols = [x for x in joined.columns if joined[x].dtype == 'object']\n",
        "\n",
        "for col in cat_cols:\n",
        "   joined.loc[:,col] = pd.factorize(joined[col], sort=True)[0]\n",
        "\n",
        "train = joined[joined['price_doc'].notnull()]\n",
        "test = joined[joined['price_doc'].isnull()]\n",
        "\n",
        "del joined\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "#train_y = np.log(train[\"price_doc\"])\n",
        "train_y = train[\"price_doc\"]\n",
        "train_X = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "test_X = test.drop([\"id\", \"timestamp\"], axis=1)\n",
        "\n",
        "predictions, model = runLGBM(train_X, train_y, test_X, seed_val=42)\n",
        "\n",
        "\n",
        "predictions = np.round(predictions * 0.99)\n",
        "output_1 = pd.DataFrame({'id': id_test, 'price_doc': predictions})\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "d_train = pd.read_csv('../input/train.csv')\n",
        "d_test = pd.read_csv('../input/test.csv')\n",
        "id_test = test.id\n",
        "\n",
        "mult = .969\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########\n",
        "#convert data to in factorize\n",
        "joined =pd.concat([d_train,d_test])\n",
        "\n",
        "cat_cols = [x for x in joined.columns if joined[x].dtype == 'object']\n",
        "\n",
        "for col in cat_cols:\n",
        "   joined.loc[:,col] = pd.factorize(joined[col], sort=True)[0]\n",
        "\n",
        "train = joined[joined['price_doc'].notnull()]\n",
        "test = joined[joined['price_doc'].isnull()]\n",
        "\n",
        "del joined\n",
        "\n",
        "print(train.shape, test.shape)\n",
        "\n",
        "y_train = train[\"price_doc\"] * mult + 10\n",
        "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
        "x_test = test.drop([\"id\", \"timestamp\"], axis=1)\n",
        "#########\n",
        "\n",
        "\n",
        "'''\n",
        "for c in x_train.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values))\n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "#This function I can't undersand\n",
        "\n",
        "\n",
        "for c in x_test.columns:\n",
        "    if x_train[c].dtype == 'object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(x_train[c].values))\n",
        "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
        "'''\n",
        "\n",
        "predictions, model = runLGBM(x_train,y_train,x_test,seed_val=42)\n",
        "output_2 = pd.DataFrame({'id': id_test, 'price_doc': predictions})\n",
        "output_2.head()\n",
        "\n",
        "\n",
        "# Any results you write to the cruuent directory are saved as output.\n",
        "df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "df_train.drop(df_train[df_train[\"life_sq\"] > 7000].index, inplace=True)\n",
        "\n",
        "y_train = df_train['price_doc'].values * mult + 10\n",
        "id_test = df_test['id']\n",
        "\n",
        "\n",
        "num_train = len(df_train)\n",
        "df_all = pd.concat([df_train, df_test])\n",
        "# Next line just adds a lot of NA columns (becuase \"join\" only works on indexes)\n",
        "# but somewhow it seems to affect the result\n",
        "df_all = df_all.join(df_macro, on='timestamp', rsuffix='_macro')\n",
        "print(df_all.shape)\n",
        "\n",
        "# Add month-year\n",
        "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
        "month_year_cnt_map = month_year.value_counts().to_dict()\n",
        "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
        "\n",
        "# Add week-year count\n",
        "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
        "week_year_cnt_map = week_year.value_counts().to_dict()\n",
        "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
        "\n",
        "# Add month and day-of-week\n",
        "df_all['month'] = df_all.timestamp.dt.month\n",
        "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
        "\n",
        "# Other feature engineering\n",
        "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
        "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c21c5dd-9251-d14d-a17f-93d9493cda06"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "d_train['building_name'] = pd.factorize(d_train.sub_area + d_train['metro_km_avto'].astype(str))[0]\n",
        "d_test['building_name'] = pd.factorize(d_test.sub_area + d_test['metro_km_avto'].astype(str))[0]\n",
        "\n",
        "def add_time_features(col):\n",
        "   col_month_year = pd.Series(pd.factorize(train[col].astype(str) + month_year.astype(str))[0])\n",
        "   train[col + '_month_year_cnt'] = col_month_year.map(col_month_year.value_counts())\n",
        "\n",
        "   col_week_year = pd.Series(pd.factorize(train[col].astype(str) + week_year.astype(str))[0])\n",
        "   train[col + '_week_year_cnt'] = col_week_year.map(col_week_year.value_counts())\n",
        "    \n",
        "add_time_features('building_name')\n",
        "\n",
        "def add_time_features(col):\n",
        "   col_month_year = pd.Series(pd.factorize(test[col].astype(str) + month_year.astype(str))[0])\n",
        "   test[col + '_month_year_cnt'] = col_month_year.map(col_month_year.value_counts())\n",
        "\n",
        "   col_week_year = pd.Series(pd.factorize(test[col].astype(str) + week_year.astype(str))[0])\n",
        "   test[col + '_week_year_cnt'] = col_week_year.map(col_week_year.value_counts())\n",
        "    \n",
        "add_time_features('building_name')\n",
        "'''\n",
        "\n",
        "# Remove timestamp column (may overfit the model in train)\n",
        "df_all.drop(['timestamp', 'timestamp_macro'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "factorize = lambda t: pd.factorize(t[1])[0]\n",
        "\n",
        "df_obj = df_all.select_dtypes(include=['object'])\n",
        "\n",
        "X_all = np.c_[\n",
        "    df_all.select_dtypes(exclude=['object']).values,\n",
        "    np.array(list(map(factorize, df_obj.iteritems()))).T\n",
        "]\n",
        "print(X_all.shape)\n",
        "\n",
        "X_train = X_all[:num_train]\n",
        "X_test = X_all[num_train:]\n",
        "\n",
        "\n",
        "# Deal with categorical values\n",
        "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
        "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
        "\n",
        "for c in df_obj:\n",
        "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
        "\n",
        "df_values = pd.concat([df_numeric, df_obj], axis=1)\n",
        "\n",
        "\n",
        "# Convert to numpy values\n",
        "X_all = df_values.values\n",
        "print(X_all.shape)\n",
        "\n",
        "X_train = X_all[:num_train]\n",
        "X_test = X_all[num_train:]\n",
        "\n",
        "df_columns = df_values.columns\n",
        "\n",
        "\n",
        "predictions, model = runLGBM(X_train,y_train,X_test,seed_val=42)\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': predictions})\n",
        "\n",
        "first_result = output_1.merge(df_sub, on=\"id\", suffixes=('_louis', '_bruno'))\n",
        "first_result[\"price_doc\"] = np.exp( .714*np.log(first_result.price_doc_louis)) + .286*np.log(first_result.price_doc_bruno)  # multiplies out to .5 & .2\n",
        "result = first_result.merge(output_2, on=\"id\", suffixes=['_follow','_gunja'])\n",
        "\n",
        "result[\"price_doc\"] = np.exp(.78*np.log(result.price_doc_follow) + .22*np.log(result.price_doc_gunja))\n",
        "result.drop([\"price_doc_louis\",\"price_doc_bruno\",\"price_doc_follow\",\"price_doc_gunja\"],axis=1,inplace=True)\n",
        "\n",
        "print(result.head())\n",
        "\n",
        "result.to_csv('submission.csv', index = False)\n",
        "\n",
        "\n",
        "#pd.DataFrame({'id': id_test, 'price_doc': np.exp(predictions)}).to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}