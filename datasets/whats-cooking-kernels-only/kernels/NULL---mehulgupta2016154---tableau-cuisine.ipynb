{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b861086a3501717c7ef2c5cddebb4eaa630489fd"},"cell_type":"markdown","source":"Loading training And Testing Dataset.....\nThe given dataset is in json format"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"x=pd.read_json('../input/train.json')\ny=pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b69ff2ad7b34c1a76beb03682432686d8c19bd8b"},"cell_type":"markdown","source":"Loading Various preprocessing element for Natural Language Processing......."},{"metadata":{"trusted":true,"_uuid":"de37ab78063f6a31d97dbfb7837029cd70f57bf9"},"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\nimport string\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nz=x['cuisine']\nfrom sklearn.preprocessing import LabelEncoder as le\nfrom sklearn.preprocessing import OneHotEncoder as ohe\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5b9b0c6d02434cd9748347e1d386d12f1910a89"},"cell_type":"markdown","source":"describe train dataset"},{"metadata":{"trusted":true,"_uuid":"2d59fbbdcb2a993af5bb14f4d9119a27df9ca928"},"cell_type":"code","source":"x.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08295e1260f97ec38a3c0ae73a5c1a00e18f6183"},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dd0ba21d667b851c8aef82fe7fb3d9a3e8d5265"},"cell_type":"markdown","source":"describe test dataset"},{"metadata":{"trusted":true,"_uuid":"3c690b52cfbfc6a247d88ecd71c6dfebf6f175a7"},"cell_type":"code","source":"y.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c2b8acae1db6b0f8bb5b81ad80122388a9edc95e"},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"068fda16aa15da3ad2bb02785ebfce7905f909af"},"cell_type":"markdown","source":"Converting list of ingredients to a sentence where each ingredient is separated by a space"},{"metadata":{"trusted":true,"_uuid":"e6ff516dfddc50efce78abfe5c8801fc7f1ecd88"},"cell_type":"code","source":"x['separated_ing']=x['ingredients'].map(lambda x: ' '.join(x))\ny['separated_ing']=y['ingredients'].map(lambda x: ' '.join(x))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d8691cfd30afdedbfd638200319c0b2cdb03ac9"},"cell_type":"markdown","source":"Preprocessing the sentence formed off in the above steps to \n-coverting all characters of ingredients to smalll letter\n-remove punctuation marks\n-converting multiple spaces to single spaces\nBoth Test and Train Data preprocessed\n"},{"metadata":{"trusted":true,"_uuid":"727ccd431071898d93e104a74fcaf5b091e3ae84"},"cell_type":"code","source":"import string,re\ndef purify(f):\n    f=f.lower()\n    f=re.sub('[%s]' % re.escape(string.punctuation),'',f)\n    f=re.sub('\\s+',' ',f)\n    return f\nx['cleared_ing']=x['separated_ing'].map(lambda g :purify(g))\ny['cleared_ing']=y['separated_ing'].map(lambda g :purify(g))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79fb0ca6fc65025dce221dd21c5df61e68d2ca28"},"cell_type":"markdown","source":"Using a SnowballStemmer with english as parameter representing English language and also WordNetLemmatizer for bringing all ingredients to core form .Like 'works' -->'work'\nThis has been used by both training and test dataset"},{"metadata":{"trusted":true,"_uuid":"25d946c20a66414b5ee3a4252b1858c9d2360f3c"},"cell_type":"code","source":"sb=SnowballStemmer('english')\ndef stemmer(f):\n    lists=[sb.stem(c) for c in f.split(\" \")]\n    return lists\nl=WordNetLemmatizer()\ndef lemmar(f):\n    lists=[l.lemmatize(g) for g in f.split(\" \")]\n    return lists\nx['separated_ing_stemmed']=[stemmer(l) for l in x['cleared_ing']]\nx['separated_ing_stemmed']=x['separated_ing_stemmed'].map(lambda x: ' '.join(x))\nx['separated_ing_lemma']=[lemmar(l) for l in x['separated_ing_stemmed']]\nx['separated_ing_lemma']=x['separated_ing_lemma'].map(lambda x: ' '.join(x))\ny['separated_ing_stemmed']=[stemmer(l) for l in y['cleared_ing']]\ny['separated_ing_stemmed']=y['separated_ing_stemmed'].map(lambda x: ' '.join(x))\ny['separated_ing_lemma']=[lemmar(l) for l in y['separated_ing_stemmed']]\ny['separated_ing_lemma']=y['separated_ing_lemma'].map(lambda x: ' '.join(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee22e29dd79069976343fcab04ec02037edd0353"},"cell_type":"markdown","source":"Dropping all unnecessary data columns from train and test dataset"},{"metadata":{"trusted":true,"_uuid":"5dafe5367567b7215956da7330b8159952e7a06b"},"cell_type":"code","source":"x=x.drop(['ingredients','separated_ing','cleared_ing','separated_ing_stemmed'],axis=1)\ny=y.drop(['ingredients','separated_ing','cleared_ing','separated_ing_stemmed'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a0bdc1b5d5ffe127744fbbdabe66e31d6a5af58"},"cell_type":"code","source":"x.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9b54ac7b91cdf0b853f435ffd925a12e1da544c"},"cell_type":"code","source":"a=''\ndef f(x):\n    global a\n    a+=x\nfor c,d in x.iterrows():\n    f(d['separated_ing_lemma'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d45eebd66887a28fa212d1c56cd014fbac4d948"},"cell_type":"code","source":"a=[x for x in a.split(\" \")]\nfrom sklearn.preprocessing import LabelEncoder as le\nc=le().fit_transform(a)\nc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"684626c77835007e5dbe204b5bba5c42198f8192"},"cell_type":"code","source":"p=[]\nfor x1 in x['cuisine']:\n    if x1 not in p:\n        p.append(x1)\ndic={}\nfor x1 in p:\n    dic[x1]=[]\ndef gg(x):\n    dic[x['cuisine']]=list(dic[x['cuisine']])+[f for f in x['separated_ing_lemma'].split(\" \") if f not in dic[x['cuisine']]]\nfor e,d in x.iterrows():   \n    gg(d)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf464d87cd80fdb0b8259450d02249d22aeee261"},"cell_type":"code","source":"xx=pd.DataFrame(index=p,columns=p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb5e922a1b89f07e1146c616dbdedaa90f7ed347"},"cell_type":"code","source":"b=[]\nfor n in a:\n    if n not in b:\n        b.append(n)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a91a29ed8c4ab57e9c40a9bd050162f40e2482c8"},"cell_type":"code","source":"xx1=xx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cede438cf8b2a6b259328aabc97216d8ef9ece2"},"cell_type":"code","source":"for z in p:\n    for z1 in p:\n        xx.loc[z,z1]=len(list(set(dic[z]) & set(dic[z1])))/len(list(set(dic[z]) | set(dic[z1])))\n        xx.loc[z1,z]=xx.loc[z,z1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9644d857a88a0c58cc9f533b3677b9e4b81d757"},"cell_type":"code","source":"xx.to_csv(\"cor.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55411a276a385a6031f9359d0063b82e2fc99253"},"cell_type":"markdown","source":"Using STOP_WORDS to remove all common ingredients present in the recipes "},{"metadata":{"trusted":true,"_uuid":"40e3c751ebd82a0406f9219fb4085f32d2c6a749"},"cell_type":"markdown","source":"lists=list(ENGLISH_STOP_WORDS)+stopwords.words()"},{"metadata":{"_uuid":"2eceb7ab85ad215eaddee5f75827a9f918985b67"},"cell_type":"markdown","source":"Importing TFIDFVectorizer-->Term Frequency*Inverse Document frequency (Count of an element in doc*log(no. of doc/docs in which element present)) and CountVectorizer(count of each element in a row as vector)"},{"metadata":{"trusted":true,"_uuid":"0775094ef34e81afbccb170a1b5694b3cedf9abc","collapsed":true},"cell_type":"markdown","source":"from sklearn.feature_extraction.text import TfidfVectorizer  as tfidf,CountVectorizer as cv"},{"metadata":{"_uuid":"4a35fce9027cc672b634cf32cac37c95701a344b"},"cell_type":"markdown","source":"Target as series z"},{"metadata":{"trusted":true,"_uuid":"037e0d6e40fe29c0fec83027cca743b4debee01a","collapsed":true},"cell_type":"markdown","source":"z=x['cuisine']"},{"metadata":{"_uuid":"49dd2384b9dc951397b632a9291a4bcad5f9956c"},"cell_type":"markdown","source":"setting parameters for itidf \n-max_df relates to maximum doc freq to be cosidered\n-stop_words eliminate common words from given text\n-analyzer how the text to be analyzed,word by word or character by character\nfitting tf-idf over train dataset"},{"metadata":{"trusted":true,"_uuid":"247d43dd0d8a4ce1dd81164190856f9c492f36c7","collapsed":true},"cell_type":"markdown","source":"tfidf1=tfidf(max_df=0.9,stop_words=lists,analyzer=u'word')\ntrain=tfidf1.fit_transform(x['separated_ing_lemma'])\ntest=tfidf1.transform(y['separated_ing_lemma'])"},{"metadata":{"_uuid":"252ff3b2579d6148a8d945b4a3f6e2e24fbc992c"},"cell_type":"markdown","source":"Importing required ML functions from sklearn"},{"metadata":{"trusted":true,"_uuid":"1e2c6a9b7e37f35ee57aefb832e6922b9ff68205","collapsed":true},"cell_type":"markdown","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV as gsc\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier as xgb\nfrom lightgbm import LGBMClassifier as lgb\nfrom sklearn.linear_model import LogisticRegression as lr"},{"metadata":{"_uuid":"f4545430a78cab0cb08ae49cd10ca77dbfc3c58c"},"cell_type":"markdown","source":"Setting required parameters for svm"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e3fa399e45c3c8911a896436add6a76759e2b69c"},"cell_type":"markdown","source":"svm={'C':[6]}\n"},{"metadata":{"_uuid":"74103e9fe153b4d7b359ccc5fe222d924b71edaa"},"cell_type":"markdown","source":"Fitting  labelencoder over target to convert categorical target to numeric in nature "},{"metadata":{"trusted":true,"_uuid":"1987def07d355ae5d32e5481a2413cbeefb8cf21","collapsed":true},"cell_type":"markdown","source":"from sklearn.preprocessing import LabelEncoder as le\np=le().fit(z)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cbce65b550b0fc05a50cc25f7b4e84c258be5a4e"},"cell_type":"markdown","source":"z=p.transform(z)"},{"metadata":{"_uuid":"7a0b17605dc6fd23eecdb5cf0bf74329ee6ea77e"},"cell_type":"markdown","source":"Performing validation train  split of train dataset in ratio 3:7"},{"metadata":{"trusted":true,"_uuid":"7f97d40cf1a93f71a03ea1868c988ee09ddefbc6","collapsed":true},"cell_type":"markdown","source":"from sklearn.model_selection import train_test_split as tts\nxtrain,xtest,ztrain,ztest=tts(train,z,train_size=0.7)"},{"metadata":{"_uuid":"c4666558ca56acd3f3c80fd03b39a3f05d713faf"},"cell_type":"markdown","source":"Setting  LGBM parameters"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2fb2f51a8d2fae3812024da2e20aeb1c6b999678"},"cell_type":"markdown","source":"r1=lgb(n_estimators=500,max_depth=7,objective='multiclass',metric='multi_logloss',num_classes=20,bagging_fraction=0.6,feature_fraction=0.6)"},{"metadata":{"trusted":true,"_uuid":"22ece32ab1efd4aa3ee337818fb4447bebefcf73","collapsed":true},"cell_type":"markdown","source":"from sklearn.model_selection import GridSearchCV as gsc\na=gsc(lr(),svm)"},{"metadata":{"_uuid":"b8a2d0afd6f1d697a714438634ec204398f7eb65"},"cell_type":"markdown","source":"Checking KNearestNeighbors over the data"},{"metadata":{"trusted":true,"_uuid":"9a92136436544c48cd7798ec1212d39b9d218827","collapsed":true},"cell_type":"markdown","source":"from sklearn.neighbors import KNeighborsClassifier as knn\nk={'n_neighbors':[5,7,9]}\nk1=gsc(knn(),k)"},{"metadata":{"_uuid":"b4df4e1de7df57f01348e0cadb1dde76c1f6d07d"},"cell_type":"markdown","source":"Using Voting Classifier for classification purpose with\n-SVM\n-KNN\n-LGBM\nusing soft margin for classification"},{"metadata":{"trusted":true,"_uuid":"b580950ce519250451192761426e74155773b053","collapsed":true},"cell_type":"markdown","source":"\nfrom sklearn.ensemble import VotingClassifier as vc\n"},{"metadata":{"trusted":true,"_uuid":"f9e8f827833c5b106ea10fec4965db7644ed70e9","collapsed":true},"cell_type":"markdown","source":"v=vc(estimators=[('lr',a),('k1',k1),('lg',r1)],voting='soft')"},{"metadata":{"_uuid":"c84a282b645bc66a71915bae2cf1756411163f93"},"cell_type":"markdown","source":"Fitting train data over votingclassifier"},{"metadata":{"trusted":true,"_uuid":"15f9b73dc174f5cc5060b78df29327401836cbfa","collapsed":true},"cell_type":"markdown","source":"v.fit(xtrain,ztrain)"},{"metadata":{"_uuid":"eaf48f9e8bdbc702d3352cc193f5e9bca385d2be"},"cell_type":"markdown","source":"Checking accuracy_score"},{"metadata":{"trusted":true,"_uuid":"ca3c8f2eb360393c4c52581b7add8b798c598ef9","collapsed":true},"cell_type":"markdown","source":"from sklearn.metrics import accuracy_score \nprint(accuracy_score(ztest,v.predict(xtest)))"},{"metadata":{"_uuid":"50edfda1b05c3cb3d91aa5bb221d186859897e66"},"cell_type":"markdown","source":"Predicting test data target"},{"metadata":{"trusted":true,"_uuid":"8e4aa62a9aef1d0f55ff73bc0f1e7cef6473520d","collapsed":true},"cell_type":"markdown","source":"z1=v.predict(test)"},{"metadata":{"_uuid":"17265e2be2415ce24a87f63217e58fbf3f446c55"},"cell_type":"markdown","source":"converting  numeric target back to categorical data"},{"metadata":{"trusted":true,"_uuid":"d42bc8021ca33900e09a49cfc87da45b1cc30dce","collapsed":true},"cell_type":"markdown","source":"z=p.inverse_transform(z1)"},{"metadata":{"_uuid":"33faa89a8487f6a2a5a73f07c60072cb183ba7d0"},"cell_type":"markdown","source":"Preparing output result file"},{"metadata":{"trusted":true,"_uuid":"c733f02ac3f004db2cf747c3467bcbd3246b4be4","collapsed":true},"cell_type":"markdown","source":"ff=pd.DataFrame(z,index=y['id'],columns=['cuisine'])"},{"metadata":{"trusted":true,"_uuid":"c3fe1127de5072c2262e3dab14f5928876be4005","collapsed":true},"cell_type":"markdown","source":"ff.index.name='id'"},{"metadata":{"trusted":true,"_uuid":"2bf6d2f52f69c30f892a2d9ccac02d584aadbe7e","collapsed":true},"cell_type":"markdown","source":"ff.to_csv('aagya.csv')"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f492689546ca2f0aae82fd3376700a0b8483e016"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}