{"nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["Read the dataset, and print the field information."], "metadata": {"_uuid": "1f7e8bc4318dd2794da9e9779eaca0bea336f227", "_cell_guid": "c18cd298-d00b-56bf-a182-89759daf63e5"}}, {"metadata": {"_uuid": "43ee0267bdb072fcb30e3ccdc067114bac544f05", "_cell_guid": "b3930e9d-7c35-6244-e822-456a4f1e9443"}, "execution_count": null, "cell_type": "code", "source": ["import pandas as pd\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "print(train.info())\n", "print(test.info())"], "outputs": []}, {"cell_type": "markdown", "source": ["We can see the Age and Cabin fields have many values missing both in the train and test dataset. For the age field, we can based the person's title's mean age to supplement it. For the Cabin field, I have no idea how to complement it, so just leave it and do nothing."], "metadata": {"_uuid": "fff77b7af3445bf925e8cab4f73c7924804003dc", "_cell_guid": "9bf8932f-be1f-ffa4-9d2a-e5edc8abfdd8"}}, {"metadata": {"_uuid": "18e018b5d9fd845152ee33efaeef26e3b95dcee6", "_cell_guid": "4d108c44-48a7-920f-e36b-2bc86aebeb61"}, "execution_count": null, "cell_type": "code", "source": ["#Use the Regular Expression to get the title from the name field.\n", "import re\n", "pattern = re.compile(r'.*?,(.*?)\\.')\n", "def getTitle(x):\n", "    result = pattern.search(x)\n", "    if result:\n", "        return result.group(1).strip()\n", "    else:\n", "        return ''\n", "\n", "train['Title'] = train['Name'].map(getTitle)\n", "test['Title'] = test['Name'].map(getTitle)\n", "\n", "#Check how many rows missing the Age by Title\n", "print(train['Title'][train['Age'].isnull()].value_counts())\n", "print(test['Title'][test['Age'].isnull()].value_counts())\n", "\n", "#Set the missing Age of Title 'Master' \n", "master_age_mean = train['Age'][(train['Title']=='Master')&(train['Age']>0)].mean()\n", "train.loc[train[(train['Title']=='Master')&(train['Age'].isnull())].index, 'Age'] = master_age_mean\n", "test.loc[test[(test['Title']=='Master')&(test['Age'].isnull())].index, 'Age'] = master_age_mean\n", "\n", "#Set the missing Age of Title 'Mr' \n", "mr_age_mean = train['Age'][(train['Title']=='Mr')&(train['Age']>0)].mean()\n", "train.loc[train[(train['Title']=='Mr')&(train['Age'].isnull())].index, 'Age'] = mr_age_mean\n", "test.loc[test[(test['Title']=='Mr')&(test['Age'].isnull())].index, 'Age'] = mr_age_mean\n", "\n", "#Set the missing Age of Title 'Miss' or 'Ms'\n", "miss_age_mean = train['Age'][(train['Title']=='Miss')&(train['Age']>0)].mean()\n", "train.loc[train[(train['Title']=='Miss')&(train['Age'].isnull())].index, 'Age'] = miss_age_mean\n", "test.loc[test[((test['Title']=='Miss')|(test['Title']=='Ms'))&(test['Age'].isnull())].index, 'Age'] = miss_age_mean\n", "\n", "#Set the missing Age of Title 'Mrs' \n", "mrs_age_mean = train['Age'][(train['Title']=='Mrs')&(train['Age']>0)].mean()\n", "train.loc[train[(train['Title']=='Mrs')&(train['Age'].isnull())].index, 'Age'] = mrs_age_mean\n", "test.loc[test[(test['Title']=='Mrs')&(test['Age'].isnull())].index, 'Age'] = mrs_age_mean\n", "\n", "#Set the missing Age of Title 'Dr' \n", "dr_age_mean = train['Age'][(train['Title']=='Dr')&(train['Age']>0)].mean()\n", "train.loc[train[(train['Title']=='Dr')&(train['Age'].isnull())].index, 'Age'] = dr_age_mean\n", "test.loc[test[(test['Title']=='Mrs')&(test['Age'].isnull())].index, 'Age'] = dr_age_mean\n", "\n", "print(train['Age'].describe())\n", "print(test['Age'].describe())"], "outputs": []}, {"cell_type": "markdown", "source": ["Now the Age field has no missing value. Let's do some data exploration work to see the value distribution by survival."], "metadata": {"_uuid": "dd31516ed25e75627e8bf20555574424ce3620b6", "_cell_guid": "3d782445-eea1-c201-d95f-d613745d1987"}}, {"metadata": {"_uuid": "3e7ffa407ae91e55794ea7b93df74e838bbc2daf", "_cell_guid": "8e87f334-1144-0d67-fabf-cdfa834fb3d8"}, "execution_count": null, "cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "alpha = 0.6\n", "fig = plt.figure(figsize=(8, 12))\n", "grouped = train.groupby(['Survived'])\n", "group0 = grouped.get_group(0)\n", "group1 = grouped.get_group(1)\n", "\n", "plot_rows = 5\n", "plot_cols = 2\n", "ax1 = plt.subplot2grid((plot_rows,plot_cols), (0,0), rowspan=1, colspan=1)\n", "plt.hist([group0.Age, group1.Age], bins=16, range=(0,80), stacked=True, \n", "        label=['Not Survived', 'Survived'], alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax1.set_title('Survival distribution by Age')\n", "\n", "ax2 = plt.subplot2grid((plot_rows,plot_cols), (0,1), rowspan=1, colspan=1)\n", "n, bins, patches = plt.hist([group0.Pclass, group1.Pclass], bins=5, range=(0,5), \n", "        stacked=True, label=['Not Survived', 'Survived'], alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax2.set_xticks([1.5, 2.5, 3.5])\n", "ax2.set_xticklabels(['Class1', 'Class2', 'Class3'], fontsize='small')\n", "ax2.set_yticks([0, 150, 300, 450, 600, 750])\n", "ax2.set_title('Survival distribution by Pclass')\n", "\n", "ax3 = plt.subplot2grid((plot_rows,plot_cols), (1,0), rowspan=1, colspan=2)\n", "ax3.set_title('Survival distribution by Sex')\n", "patches, l_texts, p_texts = plt.pie(train.groupby(['Survived', 'Sex']).size(), \n", "        labels=['Not Survived Female', 'Not Survived Male', 'Survived Female', 'Survived Male'],\n", "        autopct='%3.1f', labeldistance = 1.1, pctdistance = 0.6)\n", "plt.legend(loc='upper right', fontsize='x-small')\n", "for t in l_texts:\n", "    t.set_size(10)\n", "for p in p_texts:\n", "    p.set_size(10)\n", "#plt.legend(loc='best', fontsize='x-small')\n", "plt.axis('equal')\n", "\n", "ax4 = plt.subplot2grid((plot_rows,plot_cols), (2,0), rowspan=1, colspan=1)\n", "ax4.set_title('Survival distribution by SibSp')\n", "plt.hist([group0.SibSp, group1.SibSp], bins=9, range=(0,9), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "\n", "ax5 = plt.subplot2grid((plot_rows,plot_cols), (2,1), rowspan=1, colspan=1)\n", "ax5.set_title('Survival distribution by SibSp')\n", "plt.hist([group0[group0.SibSp>1].SibSp, group1[group1.SibSp>1].SibSp], bins=8, range=(1, 9), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "\n", "ax6 = plt.subplot2grid((plot_rows,plot_cols), (3,0), rowspan=1, colspan=1)\n", "ax6.set_title('Survival distribution by Parch')\n", "plt.hist([group0.Parch, group1.Parch], bins=7, range=(0,7), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "\n", "ax7 = plt.subplot2grid((plot_rows,plot_cols), (3,1), rowspan=1, colspan=1)\n", "ax7.set_title('Survival distribution by Parch')\n", "plt.hist([group0[group0.Parch>1].Parch, group1[group1.Parch>1].Parch], bins=6, range=(1, 7), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "\n", "ax8 = plt.subplot2grid((plot_rows,plot_cols), (4,0), rowspan=1, colspan=1)\n", "ax8.set_title('Survival distribution by Fare')\n", "plt.hist([group0.Fare, group1.Fare], bins=11, range=(0, 550), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "\n", "ax9 = plt.subplot2grid((plot_rows,plot_cols), (4,1), rowspan=1, colspan=1)\n", "ax9.set_title('Survival distribution by Fare')\n", "plt.hist([group0[group0.Fare>50].Fare, group1[group1.Fare>50].Fare], bins=11, range=(0, 550), stacked=True, \n", "        label=['Not Survived', 'Survived'], log=False, alpha=alpha)\n", "plt.legend(loc='best', fontsize='x-small')\n", "plt.subplots_adjust(wspace=0.3, hspace=0.3)"], "outputs": []}, {"cell_type": "markdown", "source": ["Let's go deeper exploration to see if a child was survived or not, how will their parents survival?"], "metadata": {"_uuid": "56983a9286738d85ecf13c3fcdb31134d4350bf0", "_cell_guid": "794c6d8f-289b-e53f-1f83-d8ea5bb19683"}}, {"metadata": {"_uuid": "4bb3db56708c7a6ee968f4d61d7d65b6159b7e68", "_cell_guid": "bb185166-8c74-669e-dfa5-c30ec04d2d36"}, "execution_count": null, "cell_type": "code", "source": ["childgrouped = train[train['Age']<19].groupby(['Survived'])\n", "childgroup0 = childgrouped.get_group(0)\n", "childgroup1 = childgrouped.get_group(1)\n", "parent = train[(train['Age']>18)&(train['Parch']>0)]\n", "\n", "merged0 = pd.merge(childgroup0, parent, how='left', on='Ticket')\n", "merged0 = merged0[['Survived_x', 'Sex_x', 'Age_x', 'Survived_y', 'Sex_y', 'Age_y', 'Ticket']]\n", "merged0 = merged0[merged0.Survived_y>=0]\n", "fig = plt.figure(figsize=(8, 4))\n", "plot_rows = 2\n", "plot_cols = 1\n", "ax1 = plt.subplot2grid((plot_rows,plot_cols), (0,0), rowspan=1, colspan=1)\n", "bottom = merged0.Survived_y.value_counts().index\n", "width1 = merged0[merged0['Sex_y']=='female'].Survived_y.value_counts()\n", "plt.barh(bottom, width1, 0.8, 0.0, color='blue', label='mother', alpha=0.6)\n", "width2 = merged0[merged0['Sex_y']=='male'].Survived_y.value_counts()\n", "plt.barh(width2.index, width2, 0.8, width1[width2.index], color='green', label='father', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax1.set_yticks([0.4, 1.4])\n", "ax1.set_yticklabels(['Not Survived Parents', 'Survived Parents'], fontsize='small')\n", "ax1.set_title('Parents survival distribution by not survived child')\n", "\n", "merged1 = pd.merge(childgroup1, parent, how='left', on='Ticket')\n", "merged1 = merged1[['Survived_x', 'Sex_x', 'Age_x', 'Survived_y', 'Sex_y', 'Age_y', 'Ticket']]\n", "merged1 = merged1[merged1.Survived_y>=0]\n", "ax2 = plt.subplot2grid((plot_rows,plot_cols), (1,0), rowspan=1, colspan=1)\n", "bottom = merged1.Survived_y.value_counts().index\n", "width1 = merged1[merged1['Sex_y']=='female'].Survived_y.value_counts()\n", "plt.barh(bottom, width1, 0.8, 0.0, color='blue', label='mother', alpha=0.6)\n", "width2 = merged1[merged1['Sex_y']=='male'].Survived_y.value_counts()\n", "plt.barh(width2.index, width2, 0.8, width1[width2.index], color='green', label='father', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax2.set_yticks([0.4, 1.4])\n", "ax2.set_yticklabels(['Not Survived Parents', 'Survived Parents'], fontsize='small')\n", "ax2.set_title('Parents survival distribution by survived child')\n", "\n", "plt.subplots_adjust(hspace=1.0)"], "outputs": []}, {"cell_type": "markdown", "source": ["From the above analysis, we can conclude that if a child is not survived, then the child's parents\n", "may not survived also. If a child is survived, the child's mother has big chance to survive than \n", "father."], "metadata": {"_uuid": "3ffc364fc4249ed73007cce522bdf9434d847f53", "_cell_guid": "a61acb0b-c328-87ca-f300-c0150928d644"}}, {"cell_type": "markdown", "source": ["Now let's take a look at the people's survival status if he/she had friends or Sibsp, based on the same ticket number. Note it's better to based on the ticket number to judge if a passenger had friends or SibSp in the boat than just look at the SibSp field. For example, take a look at the passengers of ticket number 1601, these people are most likely from the same area and had some relationship with each other, and I suspect most of their surname should be same, but mis-spelled. Don't ask me why I know that, I come from the Middle Kingdom, :-)"], "metadata": {"_uuid": "db735c7ea612b8fe378e95bde81cf7e9b67ff964", "_cell_guid": "fe96d87a-146a-1357-a529-021caba5c368"}}, {"metadata": {"_uuid": "a3a6f1fe1bfd472c54ad43c5fd0a5eb936aa656d", "_cell_guid": "9149fde0-a5dd-f9c7-225a-921ad6f78913"}, "execution_count": null, "cell_type": "code", "source": ["ticket = train['Ticket'][train['Parch']==0]\n", "ticket_dup = ticket.duplicated(False)\n", "index = ticket_dup[ticket_dup==True].index\n", "new_train = train.loc[index]\n", "new_train['FriendsSurvived'] = -1\n", "for i in range(0, len(index)):\n", "    ticketID = new_train.loc[index[i]]['Ticket']\n", "    passengerID = new_train.loc[index[i]]['PassengerId']\n", "    survived = new_train['Survived'][(new_train['Ticket']==ticketID)&(new_train['PassengerId']!=passengerID)]\n", "    new_train.loc[index[i], 'FriendsSurvived'] = round(float(survived.sum())/len(survived))\n", "print(new_train[(new_train['Sex']=='female')&(new_train['Survived']==0)].FriendsSurvived.value_counts())\n", "print(new_train[(new_train['Sex']=='male')&(new_train['Survived']==0)].FriendsSurvived.value_counts())\n", "print(new_train[(new_train['Sex']=='female')&(new_train['Survived']==1)].FriendsSurvived.value_counts())\n", "print(new_train[(new_train['Sex']=='male')&(new_train['Survived']==1)].FriendsSurvived.value_counts())"], "outputs": []}, {"metadata": {"_uuid": "e9be6bf7227109fa9f4da947a1cbbe235d97309f", "_cell_guid": "9bc89025-35b3-bdc6-e970-bd3096d8aca3"}, "execution_count": null, "cell_type": "code", "source": ["fig = plt.figure(figsize=(8, 4))\n", "plot_rows = 2\n", "plot_cols = 1\n", "ax1 = plt.subplot2grid((plot_rows,plot_cols), (0,0), rowspan=1, colspan=1)\n", "width1 = new_train[(new_train['Sex']=='female')&(new_train['Survived']==0)].FriendsSurvived.value_counts()\n", "plt.barh(width1.index, width1, 0.8, 0.0, color='blue', label='Not survived female', alpha=0.6)\n", "width2 = new_train[(new_train['Sex']=='male')&(new_train['Survived']==0)].FriendsSurvived.value_counts()\n", "plt.barh(width2.index, width2, 0.8, [width1, 0.0], color='green', label='Not survived male', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax1.set_yticks([0.4, 1.4])\n", "ax1.set_yticklabels(['Friends not survived', 'Friends survived'], fontsize='small')\n", "ax1.set_title('Not survived sex distribution by friends survival')\n", "\n", "ax2 = plt.subplot2grid((plot_rows,plot_cols), (1,0), rowspan=1, colspan=1)\n", "width1 = new_train[(new_train['Sex']=='female')&(new_train['Survived']==1)].FriendsSurvived.value_counts()\n", "plt.barh(width1.index, width1, 0.8, 0.0, color='blue', label='Survived female', alpha=0.6)\n", "width2 = new_train[(new_train['Sex']=='male')&(new_train['Survived']==1)].FriendsSurvived.value_counts()\n", "plt.barh(width2.index, width2, 0.8, width1[width2.index], color='green', label='Survived male', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax2.set_yticks([0.4, 1.4])\n", "ax2.set_yticklabels(['Friends not survived', 'Friends survived'], fontsize='small')\n", "ax2.set_title('Survived sex distribution by friends survival')\n", "\n", "plt.subplots_adjust(hspace=1.0)"], "outputs": []}, {"cell_type": "markdown", "source": ["So we can conclude from the above figures:\n", "<p>If a woman has friends/SibSp, she was survived if her friends/SibSp survived, and not survived if her friends/SibSp not survived.</p>\n", "<p>If a man has friends/SibSp, he was about 19/(19+26)=42% chance to survive if his friends/SibSp survived, and 2/(2+38)=5% chance to survive if his friends/SibSp not survived.</p>"], "metadata": {"_uuid": "19f43eaa22858fc250dba3cf2245e942ae8d6021", "_cell_guid": "06f38641-ddf2-b870-4607-0a7e3a32c3ec"}}, {"cell_type": "markdown", "source": ["Now let's convert the features into category integers. And we will create a new feature \"FamilySize\" which equals the sum of SibSp and Parch"], "metadata": {"_uuid": "9299da92ac7145d126dde39168ea307436825aba", "_cell_guid": "cd642e07-e121-7686-b72a-5babe231dbf6"}}, {"metadata": {"_uuid": "35bfe4af005b20ae417c2f50b9f6e4ea925d9881", "_cell_guid": "ab7febc3-d1d0-9abc-b082-38ee58d509fc"}, "execution_count": null, "cell_type": "code", "source": ["sex_to_int = {'male':1, 'female':0}\n", "train['SexInt'] = train['Sex'].map(sex_to_int)\n", "embark_to_int = {'S': 0, 'C':1, 'Q':2}\n", "train['EmbarkedInt'] = train['Embarked'].map(embark_to_int)\n", "train['EmbarkedInt'] = train['EmbarkedInt'].fillna(0)\n", "print(train.describe())\n", "test['SexInt'] = test['Sex'].map(sex_to_int)\n", "test['EmbarkedInt'] = test['Embarked'].map(embark_to_int)\n", "test['EmbarkedInt'] = test['EmbarkedInt'].fillna(0)\n", "test['Fare'] = test['Fare'].fillna(test['Fare'].mean())\n", "train['FamilySize'] = train['SibSp'] + train['Parch']\n", "test['FamilySize'] = test['SibSp'] + test['Parch']"], "outputs": []}, {"cell_type": "markdown", "source": ["And let's create some more new features to indicate if a passenger has friends/SibSp and how many of them are survived or not survived by sex."], "metadata": {"_uuid": "bbce02502fcea434b86bd0fda0f3ce82f50c1d03", "_cell_guid": "e72425cb-66fa-1757-0ab3-2ac4fe7fdf50"}}, {"metadata": {"_uuid": "e2ea3da653655d96ecd9256f53966fd201641fe5", "_cell_guid": "21913728-a490-3b71-eebe-87aa0f8de2dc"}, "execution_count": null, "cell_type": "code", "source": ["ticket = train[train['Parch']==0]\n", "ticket = ticket.loc[ticket.Ticket.duplicated(False)]\n", "grouped = ticket.groupby(['Ticket'])\n", "#The Friends field indicate if the passenger has frineds/SibSp in the boat.\n", "train['Friends'] = 0\n", "#The below fields statistic how many are survived or not survived by sex.\n", "train['Male_Friends_Survived'] = 0\n", "train['Male_Friends_NotSurvived'] = 0\n", "train['Female_Friends_Survived'] = 0\n", "train['Female_Friends_NotSurvived'] = 0\n", "for (k, v) in grouped.groups.items():\n", "    for i in range(0, len(v)):\n", "        train.loc[v[i], 'Friends'] = 1\n", "        train.loc[v[i], 'Male_Friends_Survived'] = train[(train.Ticket==k)&(train.index!=v[i])&(train.Sex=='male')&(train.Survived==1)].Survived.count()\n", "        train.loc[v[i], 'Male_Friends_NotSurvived'] = train[(train.Ticket==k)&(train.index!=v[i])&(train.Sex=='male')&(train.Survived==0)].Survived.count()\n", "        train.loc[v[i], 'Female_Friends_Survived'] = train[(train.Ticket==k)&(train.index!=v[i])&(train.Sex=='female')&(train.Survived==1)].Survived.count()\n", "        train.loc[v[i], 'Female_Friends_NotSurvived'] = train[(train.Ticket==k)&(train.index!=v[i])&(train.Sex=='female')&(train.Survived==0)].Survived.count()"], "outputs": []}, {"metadata": {"_uuid": "5e0967357763aa08d7c20585cdb9d0a701bc071b", "_cell_guid": "8d8e51bb-dd50-fa2b-0f3f-b3c98bd61811"}, "execution_count": null, "cell_type": "code", "source": ["test_ticket = test[test['Parch']==0]\n", "test['Friends'] = 0\n", "test['Male_Friends_Survived'] = 0\n", "test['Male_Friends_NotSurvived'] = 0\n", "test['Female_Friends_Survived'] = 0\n", "test['Female_Friends_NotSurvived'] = 0\n", "\n", "grouped = test_ticket.groupby(['Ticket'])\n", "for (k, v) in grouped.groups.items():\n", "    temp_df = train[train.Ticket==k]\n", "    length = temp_df.shape[0]\n", "    if temp_df.shape[0]>0:\n", "        for i in range(0, len(v)):\n", "            test.loc[v[i], 'Friends'] = 1\n", "            test.loc[v[i], 'Male_Friends_Survived'] = temp_df[(temp_df.Sex=='male')&(temp_df.Survived==1)].shape[0]\n", "            test.loc[v[i], 'Male_Friends_NotSurvived'] = temp_df[(temp_df.Sex=='male')&(temp_df.Survived==0)].shape[0]\n", "            test.loc[v[i], 'Female_Friends_Survived'] = temp_df[(temp_df.Sex=='female')&(temp_df.Survived==1)].shape[0]\n", "            test.loc[v[i], 'Female_Friends_NotSurvived'] = temp_df[(temp_df.Sex=='female')&(temp_df.Survived==0)].shape[0]"], "outputs": []}, {"cell_type": "markdown", "source": ["And let's create some more new features to indicate if a passenger has Parents/Child and their survival status."], "metadata": {"_uuid": "db6357708cecadb1eec6ac60ff405ab6487a5726", "_cell_guid": "cb7af69b-8cfc-e568-d0b8-218efb35dd87"}}, {"metadata": {"_uuid": "1155938e7b685b7e29cc6eb04b59726572cddb6c", "_cell_guid": "a230ee9f-6d9f-a127-d311-84b8f035eadf"}, "execution_count": null, "cell_type": "code", "source": ["train['FatherOnBoard'] = 0\n", "train['FatherSurvived'] = 0\n", "train['MotherOnBoard'] = 0\n", "train['MotherSurvived'] = 0\n", "train['ChildOnBoard'] = 0\n", "train['ChildSurvived'] = 0\n", "train['ChildNotSurvived'] = 0\n", "grouped = train[train.Parch>0].groupby('Ticket')\n", "for (k, v) in grouped.groups.items():\n", "    for i in range(0, len(v)):\n", "        if train.loc[v[i], 'Age']<19:\n", "            temp = train[(train.Ticket==k)&(train.Age>18)]\n", "            if temp[temp.SexInt==1].shape[0] == 1:\n", "                train.loc[v[i], 'FatherOnBoard'] = 1\n", "                train.loc[v[i], 'FatherSurvived'] = temp[temp.SexInt==1].Survived.sum()\n", "            if temp[temp.SexInt==0].shape[0] == 1:\n", "                train.loc[v[i], 'MotherOnBoard'] = 1\n", "                train.loc[v[i], 'MotherSurvived'] = temp[temp.SexInt==0].Survived.sum()\n", "        else:\n", "            temp = train[(train.Ticket==k)&(train.Age<19)]\n", "            length = temp.shape[0]\n", "            if length>0:\n", "                train.loc[v[i], 'ChildOnBoard'] = 1\n", "                train.loc[v[i], 'ChildSurvived'] = temp[temp.Survived==1].shape[0]\n", "                train.loc[v[i], 'ChildNotSurvived'] = temp[temp.Survived==0].shape[0]\n", "                "], "outputs": []}, {"metadata": {"_uuid": "d9ff2cd3c3d1b15038f4a42bfa09e7f35408f2e9", "_cell_guid": "cab94752-e950-b42c-6a4b-4e662168bda2"}, "execution_count": null, "cell_type": "code", "source": ["test['FatherOnBoard'] = 0\n", "test['FatherSurvived'] = 0\n", "test['MotherOnBoard'] = 0\n", "test['MotherSurvived'] = 0\n", "test['ChildOnBoard'] = 0\n", "test['ChildSurvived'] = 0\n", "test['ChildNotSurvived'] = 0\n", "grouped = test[test.Parch>0].groupby('Ticket')\n", "for (k, v) in grouped.groups.items():\n", "    temp = train[train.Ticket==k]\n", "    length = temp.shape[0]\n", "    if length>0:\n", "        for i in range(0, len(v)):\n", "            if test.loc[v[i], 'Age']<19:\n", "                if temp[(temp.SexInt==1)&(temp.Age>18)].shape[0] == 1:\n", "                    test.loc[v[i], 'FatherOnBoard'] = 1\n", "                    test.loc[v[i], 'FatherSurvived'] = temp[(temp.SexInt==1)&(temp.Age>18)].Survived.sum()\n", "                if temp[(temp.SexInt==0)&(temp.Age>18)].shape[0] == 1:\n", "                    test.loc[v[i], 'MotherOnBoard'] = 1\n", "                    test.loc[v[i], 'MotherSurvived'] = temp[(temp.SexInt==0)&(temp.Age>18)].Survived.sum()\n", "            else:\n", "                length = temp[temp.Age<19].shape[0]\n", "                if length>0:\n", "                    test.loc[v[i], 'ChildOnBoard'] = 1\n", "                    test.loc[v[i], 'ChildSurvived'] = temp[(temp.Age<19)&(temp.Survived==1)].shape[0]\n", "                    test.loc[v[i], 'ChildNotSurvived'] = temp[(temp.Age<19)&(temp.Survived==0)].shape[0]"], "outputs": []}, {"cell_type": "markdown", "source": ["Now let's take a look if the embarked port has impact to survival rate."], "metadata": {"_uuid": "6e7aa623696d23e8a3d41584811226a663c599d7", "_cell_guid": "5771b156-a49f-dbac-9c44-3546881fb386"}}, {"metadata": {"_uuid": "51033f09bde0b54c3ea510b9a5b19d753d8e0f0f", "_cell_guid": "273fcc75-0787-3b0c-3688-7bf3adeb26e1"}, "execution_count": null, "cell_type": "code", "source": ["fig = plt.figure(figsize=(8, 1))\n", "grouped = train.groupby(['Survived'])\n", "group0 = grouped.get_group(0)\n", "group1 = grouped.get_group(1)\n", "\n", "ax1 = plt.subplot2grid((1,2), (0,0), rowspan=1, colspan=2)\n", "bottom = group0.EmbarkedInt.value_counts().index\n", "width1 = group0.EmbarkedInt.value_counts()\n", "plt.barh(bottom, width1, 0.8, 0.0, color='blue', label='Not Survived', alpha=0.6)\n", "width2 = group1.EmbarkedInt.value_counts()\n", "plt.barh(bottom, width2, 0.8, width1, color='green', label='Survived', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax1.set_yticks([0.4, 1.4, 2.4])\n", "ax1.set_yticklabels(['Southampton', 'Cherbourg', 'Queenstown'], fontsize='small')\n", "ax1.set_title('Survival distribution by Embarked')"], "outputs": []}, {"cell_type": "markdown", "source": ["More feature process work, get the title from the names and map to a new feature, cut the fare and age into category."], "metadata": {"_uuid": "7a7b44bcd10d2095554d3afaa22af7865fcfd3c7", "_cell_guid": "5c97f329-6368-6756-f56c-6f8c552ec0a8"}}, {"metadata": {"_uuid": "3b1a3da16d3c64697d4c9f002217c916d0f2f522", "_cell_guid": "442ac5fe-5260-51ee-be4b-602787297e23"}, "execution_count": null, "cell_type": "code", "source": ["title_to_int = {'Mr':1, 'Miss':2, 'Mrs':3, 'Master':1, 'Dr':4, 'Rev':4, 'Mlle':2, 'Major':4, 'Col':4,\n", "        'Ms':3, 'Lady':3, 'the Countess':4, 'Sir':4, 'Mme':3, 'Capt':4, 'Jonkheer':4, 'Don':1, 'Dona':3}\n", "train['TitleInt'] = train['Title'].map(title_to_int)\n", "test['TitleInt'] = test['Title'].map(title_to_int)\n", "train.loc[train[train['Age']<13].index, 'TitleInt'] = 5\n", "test.loc[test[test['Age']<13].index, 'TitleInt'] = 5\n", "\n", "train['FareCat'] = pd.cut(train['Fare'], [-0.1, 50, 100, 150, 200, 300, 1000], right=True, \n", "        labels=[0, 1, 2, 3, 4, 5])\n", "test['FareCat'] = pd.cut(test['Fare'], [-0.1, 50, 100, 150, 200, 300, 1000], right=True, \n", "        labels=[0, 1, 2, 3, 4, 5])\n", "train['AgeCat'] = pd.cut(train['Age'], [-0.1, 12.1, 20, 30, 35, 40, 45, 50, 55, 65, 100], right=True, \n", "        labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n", "test['AgeCat'] = pd.cut(test['Age'], [-0.1, 12.1, 20, 30, 35, 40, 45, 50, 55, 65, 100], right=True, \n", "        labels=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"], "outputs": []}, {"cell_type": "markdown", "source": ["After the new features created, let's check if a passenger's title has impact to survival rate."], "metadata": {"_uuid": "ac1e3c795d70d4389599b9a426caa8b2b5dc0121", "_cell_guid": "32277d55-295a-ef3a-9829-d01a920dec01"}}, {"metadata": {"_uuid": "f3fd819f2e19ea403ffe5f9fa7a8af8de3d79cda", "_cell_guid": "46246fb9-5310-90a7-f727-2b170ef32613"}, "execution_count": null, "cell_type": "code", "source": ["fig = plt.figure(figsize=(8, 1))\n", "grouped = train.groupby(['Survived'])\n", "group0 = grouped.get_group(0)\n", "group1 = grouped.get_group(1)\n", "\n", "ax1 = plt.subplot2grid((1,2), (0,0), rowspan=1, colspan=2)\n", "bottom = group0.TitleInt.value_counts().index\n", "width1 = group0.TitleInt.value_counts()\n", "plt.barh(bottom, width1, 0.8, 0.0, color='blue', label='Not Survived', alpha=0.6)\n", "width2 = group1.TitleInt.value_counts()\n", "plt.barh(bottom, width2, 0.8, width1, color='green', label='Survived', alpha=0.6)\n", "plt.legend(loc='best', fontsize='x-small')\n", "ax1.set_yticks([1.4, 2.4, 3.4, 4.4, 5.4])\n", "ax1.set_yticklabels(['Mr', 'Miss', 'Mrs', 'Profession', 'Child'], fontsize='small')\n", "ax1.set_title('Survival distribution by Title')"], "outputs": []}, {"cell_type": "markdown", "source": ["Finally go to the prediction part. First we will choose which columns to trian and predict. Then we will split the train and test parts of the train dataset."], "metadata": {"_uuid": "1b646d1453d4f92c936f1f0279ba972bdd4ce979", "_cell_guid": "e87ef6bd-8e0a-d7a8-5f1e-67f00312c72b"}}, {"metadata": {"_uuid": "b4fdd4258d1641cc46354040688dc3b84d6cabdc", "_cell_guid": "370fd5a5-8b4f-d34a-5991-f980d76209f0"}, "execution_count": null, "cell_type": "code", "source": ["from sklearn.feature_selection import SelectKBest, f_classif\n", "from sklearn.model_selection import train_test_split\n", "#columns = ['Pclass', 'SibSp', 'Parch', 'SexInt', 'EmbarkedInt', 'AgeCat', 'TitleInt', 'FareCat']\n", "#columns = ['Pclass', 'SibSp', 'Parch', 'SexInt', 'EmbarkedInt', 'AgeInt', 'TitleInt', 'Fare']\n", "#columns = ['Pclass', 'FamilySize', 'SexInt', 'EmbarkedInt', 'AgeCat', 'TitleInt', 'FareCat']\n", "#columns = ['Pclass', 'FamilySize', 'SexInt', 'EmbarkedInt', 'AgeCat', 'TitleInt', 'FareCat',\n", "#        'Friends', 'FriendsSex', 'FriendsSurvived']\n", "#columns = ['Pclass', 'SibSp', 'Parch', 'SexInt', 'EmbarkedInt', 'AgeCat', 'TitleInt', 'FareCat',\n", "#        'Friends', 'FriendsSex', 'FriendsSurvived', 'FatherSurvived', 'MotherSurvived', 'ChildSurvived']\n", "#columns = ['Pclass', 'SibSp', 'Parch', 'SexInt', 'EmbarkedInt', 'AgeCat', 'TitleInt', 'FareCat']\n", "#        'Friends', 'FriendsSex', 'FriendsSurvived']\n", "#columns = ['Pclass', 'SexInt', 'EmbarkedInt', 'Age', 'TitleInt','Fare', 'Friends', 'FriendsSex', 'FriendsSurvived', 'FatherSurvived', 'MotherSurvived', 'ChildSurvived']\n", "columns = ['Pclass', 'SexInt', 'EmbarkedInt', 'Age', 'TitleInt','Fare', \n", "        'Friends', 'Male_Friends_Survived', 'Male_Friends_NotSurvived', 'Female_Friends_Survived', 'Female_Friends_NotSurvived',\n", "        'MotherOnBoard', 'MotherSurvived', 'ChildOnBoard', 'ChildSurvived', 'ChildNotSurvived']\n", "X_train, X_test, y_train, y_test = train_test_split(train[columns], train['Survived'], test_size=0.2, random_state=123)\n", "\n", "#Check the features importance. \n", "#selected = SelectKBest(f_classif, 18)\n", "#selected.fit(X_train, y_train)\n", "#X_train_selected = selected.transform(X_train)\n", "#X_test_selected = selected.transform(X_test)\n", "#print(selected.scores_)\n", "#print(selected.pvalues_)"], "outputs": []}, {"cell_type": "markdown", "source": ["From the above result, the Feature importance are SexInt>TitleInt>PClass>Fare>Male_Friends_Survived>Female_Friends_Survived>"], "metadata": {"_uuid": "b7825849389e41fb47a33ac66fd259f5ee7b8660", "_cell_guid": "bd27d8e1-21a2-c789-abfb-d0b695e59aee"}}, {"cell_type": "markdown", "source": ["Now let's first use RandomForest to train and predict. First we can use the GridSearch to find the best param."], "metadata": {"_uuid": "e566c6c27df39a6106ee2f383ade6553d6d15213", "_cell_guid": "8a9fa59d-37cf-bbc8-ab8b-1cf8450f9a0f"}}, {"metadata": {"_uuid": "c9e7532ba2df9ea6c117fa5f6cb6fd2f7d07de88", "_cell_guid": "4b569b0c-368e-d891-53cc-fda1a8a6324c"}, "execution_count": null, "cell_type": "code", "source": ["from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.model_selection import GridSearchCV\n", "param_grid = {'n_estimators': [10, 50, 100, 150], 'min_samples_leaf': [1, 2, 4, 8], \n", "        'max_depth': [None, 5, 10, 50], 'max_features': [None, 'auto'], 'min_samples_split': [2, 4, 8]}\n", "rfc = RandomForestClassifier(criterion='gini', min_weight_fraction_leaf=0.0, \n", "        max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, oob_score=False, \n", "        n_jobs=-1, random_state=None, verbose=0, warm_start=False, class_weight=None)\n", "classifer = GridSearchCV(rfc, param_grid, cv=5, n_jobs=-1)\n", "#classifer.fit(X_train, y_train)\n", "#print(classifer.grid_scores_)\n", "#print(classifer.best_params_)\n", "#print(X_train.info())"], "outputs": []}, {"cell_type": "markdown", "source": ["The Grid search Best params are:\n", "{'min_samples_split': 2, 'max_depth': 10, 'n_estimators': 150, 'min_samples_leaf': 1, 'max_features': 'auto'}, we can based these params to train and predict."], "metadata": {"_uuid": "71cae7b4381b7105943ea8dcb8679fef43782c26", "_cell_guid": "2a6d87a5-43f3-67bb-25de-cc93d66a044f"}}, {"metadata": {"_uuid": "e34b1e81b3a9caf22429a368370497868486008f", "_cell_guid": "6bf7085e-2a15-be75-8b3c-8383e94d1e3d"}, "execution_count": null, "cell_type": "code", "source": ["rfc = RandomForestClassifier(n_estimators=150, criterion='gini', max_depth=10, \n", "        min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n", "        max_features='auto', max_leaf_nodes=None, min_impurity_split=1e-07, bootstrap=True, \n", "        oob_score=False, n_jobs=1, random_state=232, verbose=0, warm_start=False, class_weight=None)\n", "\n", "rfc.fit(X_train, y_train)\n", "result = rfc.predict(X_test)\n", "rightnum = 0\n", "\n", "for i in range(0, result.shape[0]):\n", "    if result[i] == y_test.iloc[i]:\n", "        rightnum += 1\n", "print(rightnum/result.shape[0])\n", "\n", "\n", "rfc.fit(train[columns], train['Survived'])\n", "predict_rf = rfc.predict(test[columns])\n", "\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": predict_rf\n", "    })\n", "submission.to_csv(\"titanic_predict_RF.csv\", index=False)"], "outputs": []}, {"cell_type": "markdown", "source": ["The RF gives a 0.88268 accuracy rate on the test parts. And generate the prediction on the test dataset. The prediction score is 0.78947."], "metadata": {"_uuid": "6fa871b4cb648862ebaee4c373f3d7d5895b358e", "_cell_guid": "b956c8d9-f903-992a-e40a-d9898392dbc2"}}, {"cell_type": "markdown", "source": ["Let's use XGB to do the train and prediton, to compare with RF. The accuracy rate of the test pars are 0.8715, close to RF. The prediction score is 0.76077"], "metadata": {"_uuid": "ce7cc4e0d050421053aa23d53cf0a3bd3d25b798", "_cell_guid": "a848725f-5db6-b479-f64c-7b7573794786"}}, {"metadata": {"_uuid": "e24f70d0e3996f8b38ade832da6c553b4514aa26", "_cell_guid": "f6d33889-af4c-52d7-ec44-d7aa5b7a2d8d"}, "execution_count": null, "cell_type": "code", "source": ["import xgboost as xgb\n", "xgbclassifer = xgb.XGBClassifier(max_depth=5, learning_rate=0.1, n_estimators=100, silent=True, objective='binary:logistic', nthread=-1, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, seed=0, missing=None)\n", "xgbclassifer.fit(X_train, y_train)\n", "result = xgbclassifer.predict(X_test)\n", "#print(result[:10])\n", "rightnum = 0\n", "for i in range(0, result.shape[0]):\n", "    if result[i] == y_test.iloc[i]:\n", "        rightnum += 1\n", "print(rightnum/result.shape[0])\n", "\n", "xgbclassifer.fit(train[columns], train['Survived'])\n", "predict_xgb = xgbclassifer.predict(test[columns])\n", "\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": predict_xgb\n", "    })\n", "submission.to_csv(\"titanic_predict_xgb.csv\", index=False)"], "outputs": []}, {"cell_type": "markdown", "source": ["Let's use Neural Network to do the train and prediton, to compare with RF. The accuracy rate of the test pars are 0.8603, not good as RF and XGB. But the prediction score is highest, 0.8134"], "metadata": {"_uuid": "aad4b6b6f591cf50e92b82ebb1b45d5d844fad35", "_cell_guid": "0fb73841-c88f-8f20-8dca-a9d5227d338c"}}, {"metadata": {"_uuid": "ef39be7c48957a998b630cd1511a7bc1fdfd30e0", "_cell_guid": "1c4ca1ea-98fa-2ef9-f0a2-0b7590bfd8fd"}, "execution_count": null, "cell_type": "code", "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Activation, Dropout\n", "from keras.regularizers import l2, l1\n", "from sklearn.preprocessing import StandardScaler\n", "\n", "stdScaler = StandardScaler()\n", "X_train_scaled = stdScaler.fit_transform(X_train)\n", "X_test_scaled = stdScaler.transform(X_test)\n", "model = Sequential()\n", "#model.add(Dense(700, input_dim=7, init='normal', activation='relu'))\n", "#model.add(Dropout(0.5))\n", "model.add(Dense(1600, input_dim=16, init='normal', activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(1, init='normal', activation='sigmoid'))\n", "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n", "model.fit(X_train_scaled, y_train, nb_epoch=20, batch_size=32)\n", "result = model.predict(X_test_scaled)\n", "rightnum = 0\n", "for i in range(0, result.shape[0]):\n", "    if result[i] >= 0.5:\n", "        result[i] = 1\n", "    else:\n", "        result[i] = 0\n", "    if result[i] == y_test.iloc[i]:\n", "        rightnum += 1\n", "print(rightnum/result.shape[0])\n", "\n", "train_scaled = stdScaler.fit_transform(train[columns])\n", "test_scaled = stdScaler.transform(test[columns])\n", "model.fit(train_scaled, train['Survived'], nb_epoch=20, batch_size=32, verbose=0)\n", "predict_NN = model.predict(test_scaled)\n", "print(predict_NN.shape)\n", "for i in range(0, predict_NN.shape[0]):\n", "    if predict_NN[i] >= 0.5:\n", "        predict_NN[i] = 1\n", "    else:\n", "        predict_NN[i] = 0\n", "        \n", "predict_NN = predict_NN.reshape((predict_NN.shape[0]))\n", "predict_NN = predict_NN.astype('int')\n", "print(predict_NN.shape)\n", "submission = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": predict_NN\n", "    })\n", "submission.to_csv(\"titanic_predict_NN.csv\", index=False)"], "outputs": []}, {"cell_type": "markdown", "source": ["Test with SVM, the result is 0.7150, not a good result. Seems need to fine tune the parameters."], "metadata": {"_uuid": "8a3e6ca3bb922c5dfa022bf310d78224a6e8de7f", "_cell_guid": "11c36781-03a7-44ff-f375-6672f4f38ad3"}}, {"metadata": {"_uuid": "57bf810b6c743dfa9aad8488ca8d020ce294922c", "_cell_guid": "e7d313a1-9036-a555-2bd1-616709f3f39d"}, "execution_count": null, "cell_type": "code", "source": ["from sklearn import svm\n", "clf = svm.SVC()\n", "clf.fit(X_train, y_train)\n", "result = clf.predict(X_test)\n", "rightnum = 0\n", "for i in range(0, result.shape[0]):\n", "    if result[i] == y_test.iloc[i]:\n", "        rightnum += 1\n", "print(rightnum/result.shape[0])\n", "\n", "predict_svm = clf.predict(test[columns])"], "outputs": []}, {"cell_type": "markdown", "source": ["And let's try the genetic program, I am using the DEAP for it. As the genetic program needs a lot of time to train(I use 300 generation), it will exceed the notebook run time limit. I just post the genetic program result here. The prediction gives a score of 0.79904"], "metadata": {"_uuid": "33f47f961468cc9260147df6b5836c11fc1d1a55", "_cell_guid": "82c4b0a7-75a3-318e-e9ff-e9d523195e2c"}}, {"metadata": {"_uuid": "348021686e179a20608fb247ba4ffed905272292", "_cell_guid": "329540e5-bb0a-dece-5e49-05210697f65c"}, "execution_count": null, "cell_type": "code", "source": ["from deap import gp\n", "import itertools\n", "import operator\n", "import math\n", "import numpy as np\n", "\n", "train_GP = train[columns]\n", "test_GP = test[columns]\n", "train_GP = train_GP.astype('float')\n", "test_GP = test_GP.astype('float')\n", "\n", "pset = gp.PrimitiveSetTyped(\"MAIN\", itertools.repeat(float, 16), float, \"IN\")\n", "\n", "pset.addPrimitive(operator.and_, [bool, bool], bool)\n", "pset.addPrimitive(operator.or_, [bool, bool], bool)\n", "pset.addPrimitive(operator.not_, [bool], bool)\n", "\n", "# Define a protected division function\n", "def protectedDiv(left, right):\n", "    if right != 0.0:\n", "        return left/right\n", "    else:\n", "        return 1\n", "def protectedSqrt(x):\n", "    return math.sqrt(abs(x))\n", "pset.addPrimitive(operator.add, [float,float], float)\n", "pset.addPrimitive(operator.sub, [float,float], float)\n", "pset.addPrimitive(operator.mul, [float,float], float)\n", "pset.addPrimitive(protectedDiv, [float,float], float)\n", "pset.addPrimitive(math.sin, [float], float)\n", "pset.addPrimitive(math.cos, [float], float)\n", "pset.addPrimitive(math.tanh, [float], float)\n", "pset.addPrimitive(math.hypot, [float, float], float)\n", "pset.addPrimitive(max, [float, float], float)\n", "pset.addPrimitive(min, [float, float], float)\n", "pset.addPrimitive(protectedSqrt, [float], float)\n", "\n", "# Define a new if-then-else function\n", "def if_then_else(input, output1, output2):\n", "    if input: return output1\n", "    else: return output2\n", "\n", "pset.addPrimitive(operator.lt, [float, float], bool)\n", "pset.addPrimitive(operator.eq, [float, float], bool)\n", "pset.addPrimitive(if_then_else, [bool, float, float], float)\n", "\n", "expr = 'sub(min(add(cos(cos(mul(8.791524057280029, add(0.8813426844222205, IN2)))), \\\n", "protectedDiv(sub(protectedDiv(IN14, IN10), IN11), protectedSqrt(sub(protectedDiv\\\n", "(hypot(protectedDiv(if_then_else(or_(True, and_(or_(True, True), True)), IN9, \\\n", "add(protectedDiv(protectedDiv(0.9363229575602429, 9.457393756367038), 68.60931271115085),\\\n", "sub(0.76609748747378, IN15))), 9.457393756367038), sin(0.22806884104520364)), \\\n", "if_then_else(or_(lt(protectedDiv(if_then_else(True, IN2, IN4), protectedDiv\\\n", "(hypot(0.8201212481183877, 81.83905300378048), IN0)), IN5), or_(True, True)), IN9,\\\n", "cos(mul(0.7027184429804209, add(protectedDiv(protectedDiv(0.9363229575602429, \\\n", "9.457393756367038), 9.457393756367038), sub(if_then_else(or_(False, True), cos\\\n", "(0.23992695841396383), hypot(2.718281828459045, IN12)), IN15)))))), IN12)))), \\\n", "hypot(IN4, tanh(protectedSqrt(max(protectedDiv(hypot(add(0.9095718824824596, \\\n", "360.49409062712783), sin(IN9)), min(mul(97.97893140946204, protectedDiv(IN0, \\\n", "0.3160036101933281)), protectedDiv(protectedDiv(if_then_else(or_(True, True), \\\n", "IN9, cos(mul(8.791524057280029, add(protectedDiv(IN9, 9.457393756367038), \\\n", "sub(add(IN9, 31.792888528447644), IN15))))), 9.457393756367038), 2.0803290751797636))), \\\n", "protectedSqrt(cos(mul(8.791524057280029, IN6)))))))), min(protectedSqrt(max\\\n", "(protectedDiv(5.010370880110474, protectedDiv(IN15, add(336.6490971360746, \\\n", "protectedDiv(sub(if_then_else(True, max(IN3, IN5), cos(sin(0.22806884104520364))), \\\n", "hypot(sin(add(add(mul(tanh(max(IN4, 95.88858811362302)), 235.99768570024435), \\\n", "2.0803290751797636),sin(sub(protectedDiv(IN0, 0.3160036101933281), 0.9466582602925034)))), \\\n", "add(cos(add(49.46712430568304, 4.937708033384823)), protectedDiv(mul(97.97893140946204, \\\n", "protectedDiv(IN0, 0.3160036101933281)), protectedSqrt(max(protectedDiv(IN3, IN1),\\\n", " if_then_else(True, protectedSqrt(0.8174130427244765), 0.7377841058934647))))))), \\\n", " if_then_else(or_(and_(or_(or_(False, False), False), True), True), sub(IN14, \\\n", " 0.22806884104520364), IN9))))), protectedSqrt(max(protectedDiv(IN3, IN1), \\\n", " cos(546.215547398933))))), IN3))'\n", "gpfunc = gp.compile(expr, pset)\n", "\n", "def output(x):\n", "    try:\n", "        return int(round(1.0/(1.0 + math.exp(-x))))\n", "    except(OverflowError):\n", "        return 0\n", "    \n", "predict_GP = np.zeros((test.shape[0]))\n", "for i in range (0, test.shape[0]):\n", "    predict_GP[i] = output(gpfunc(*test[columns].iloc[i, :]))\n", "predict_GP = predict_GP.astype('int')\n", "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Survived\": predict_GP})\n", "submission.to_csv(\"titanic_predict_gp.csv\", index=False)"], "outputs": []}, {"cell_type": "markdown", "source": ["And finally, let's combine the predictions by differnet models, and see if can impore the score. The result score is 0.81340"], "metadata": {"_uuid": "dd6c73ddddb9069b9f51577986b93f0686b480a6", "_cell_guid": "45e66f96-ddf8-bdbe-f90f-8c8b1e37cfa2"}}, {"metadata": {"_uuid": "3af910efb7af85533cc3430c7f0c798c70ce11f3", "_cell_guid": "dad9d2fe-ef38-bf11-33c4-bc440365872c"}, "execution_count": null, "cell_type": "code", "source": ["predict_combine = np.zeros((test.shape[0]))\n", "for i in range(0, test.shape[0]):\n", "    temp = predict_rf[i] + predict_NN[i] + predict_GP[i]\n", "    if temp>=2:\n", "        predict_combine[i] = 1\n", "predict_combine = predict_combine.astype('int')\n", "\n", "combination = pd.DataFrame({\n", "        \"PassengerId\": test[\"PassengerId\"],\n", "        \"Survived\": predict_combine\n", "    })\n", "combination.to_csv(\"titanic_predict_combine.csv\", index=False)"], "outputs": []}, {"cell_type": "markdown", "source": ["So the final result is, using neural network gets the highest score 0.8134"], "metadata": {"_uuid": "5b1e1776481df91c9df65930ead01fa458151c06", "_cell_guid": "ba0245d9-5db4-c610-9b54-d71016076c79"}}], "nbformat_minor": 0, "metadata": {"language_info": {"version": "3.5.2", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}, "_change_revision": 0, "_is_fork": false, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}