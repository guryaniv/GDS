{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n%matplotlib inline\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\nfrom keras.optimizers import Adam\n\nfrom keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"q_train = pd.read_csv('../input/train.csv')\nq_test = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80060111d408132998eb383e44c674c8ef568f5f"},"cell_type":"markdown","source":"## Preprocessing \nDelet punctuation and stemming"},{"metadata":{"trusted":true,"_uuid":"8f7e4800018068ce37574f004f72d883f281461a"},"cell_type":"code","source":"### delete punctuaction\ntable = str.maketrans({key: None for key in string.punctuation})\n\nq_train.question1 = q_train.question1.str.translate(table).str.lower().map(str)\nq_train.question2 = q_train.question2.str.translate(table).str.lower().map(str)\n\nq_test.question1 = q_test.question1.str.translate(table).str.lower().map(str)\nq_test.question2 = q_test.question2.str.translate(table).str.lower().map(str)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86467941097c1058766193e6ce4a75ca544a1cf7"},"cell_type":"markdown","source":"## Tokinizing"},{"metadata":{"trusted":true,"_uuid":"ce6a8bac9e83ae0b8aeca7bb4cfa3f4b30ace643"},"cell_type":"code","source":"full_text = list(q_train.question2.values) + list(q_train.question1.values)\nfull_text += list(q_test.question1.values) + list(q_test.question1.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6cb854d448120926acca812cf6d507774b9a818e"},"cell_type":"code","source":"tk = Tokenizer(num_words=50000) \ntk.fit_on_texts(full_text)\nlen(tk.word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1c58e6769a08c644d620a3ffe296d41f63d2fd4"},"cell_type":"code","source":"train_tokenized1 = tk.texts_to_sequences(q_train.question1)\ntrain_tokenized2 = tk.texts_to_sequences(q_train.question2)\n\ntest_tokenized1 = tk.texts_to_sequences(q_test.question1)\ntest_tokenized2 = tk.texts_to_sequences(q_test.question2)\n\nmax_len = 50\n\nX_train1 = pad_sequences(train_tokenized1, maxlen = max_len)\nX_train2 = pad_sequences(train_tokenized2, maxlen = max_len)\n\nX_test1 = pad_sequences(test_tokenized1, maxlen = max_len)\nX_test2 = pad_sequences(test_tokenized2, maxlen = max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8ba5387afb419cb512ddb22348e6a1dc89826c5"},"cell_type":"code","source":"y = q_train.is_duplicate\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder(sparse=False)\ny_ohe = ohe.fit_transform(y.values.reshape(-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a42533b8d104bea9f8ee21a21a3e785bbfda833b"},"cell_type":"code","source":"embed_size = 100\nmax_features = 50000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3472f066eeb1374109f64777aca4b14cb9a5120"},"cell_type":"code","source":"def LSTM_CNN(lr=0.0, lr_d=0.0, units=0, \n                 spatial_dr=0.0, dense_units=128, \n                 dr=0.1, conv_size=32):\n    file_path = \"best_model.hdf5\"\n    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                                  save_best_only = True, mode = \"min\")\n    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n    \n    inp1 = Input(shape = (max_len,))\n    inp2 = Input(shape = (max_len,))\n    \n    Embedding_layer = Embedding(min(len(tk.word_index), max_features),\n                                embed_size, trainable = True)\n    SpatialDropout1D_layer = SpatialDropout1D(spatial_dr)\n    LSTM_layer = Bidirectional(CuDNNLSTM(units, return_sequences = True))\n    Conv1_layer = Conv1D(conv_size, kernel_size=2, \n                         padding='valid', kernel_initializer='he_uniform')\n    Conv2_layer = Conv1D(conv_size, kernel_size=3, \n                         padding='valid', kernel_initializer='he_uniform')\n    Conv3_layer = Conv1D(conv_size, kernel_size=4, \n                         padding='valid', kernel_initializer='he_uniform')\n    GlobalMaxPooling1D_layer = GlobalMaxPooling1D()\n    \n    def head_block(inp):\n        x = Embedding_layer(inp)\n        x = SpatialDropout1D_layer(x)\n        x_lstm = LSTM_layer(x)\n        x = concatenate([Conv1_layer(x_lstm),\n                         Conv2_layer(x_lstm),\n                         Conv3_layer(x_lstm),], axis=1)\n        x = GlobalMaxPooling1D_layer(x)\n        return x\n    \n    x1 = head_block(inp1)\n    x2 = head_block(inp2)\n    x = concatenate([x1, x2])\n    x = BatchNormalization()(x)\n    x = Dropout(dr)(Dense(dense_units, activation='relu')(x))\n    x = BatchNormalization()(x)\n    x = Dropout(dr)(Dense(dense_units, activation='relu')(x))\n    x = Dense(2, activation = \"softmax\")(x)\n    model = Model(inputs = [inp1, inp2], outputs = x)\n    model.compile(loss = \"categorical_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d),\n                  metrics = [\"categorical_accuracy\"])\n    model.summary()\n    history = model.fit([X_train1, X_train2], \n                        y_ohe, batch_size = 128,\n                        epochs = 10,\n                        validation_split=0.1, \n                        verbose = 1, callbacks = [check_point, early_stop])\n    model = load_model(file_path)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7392d490e319e51b487f0beddf1d055a41c6fefb"},"cell_type":"code","source":"nn = LSTM_CNN(lr=1e-3, lr_d=1e-9, \n                      units=32, spatial_dr=0.3, \n                      dense_units=64, dr=0.5, conv_size=64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba4276353eeb7bf4cc848c06b647538512890bb6"},"cell_type":"code","source":"res = nn.predict([X_test1, X_test2], batch_size=128, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7166cb0300798cee0dac755c208b0e32326245e"},"cell_type":"code","source":"pd.DataFrame(res).to_csv('res')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e422b53a56428c2d46827f72aac063f9102be0fb"},"cell_type":"code","source":"answ = pd.DataFrame(res).reset_index().iloc[:, 0, 2]\nansw.columns = ['test_id', 'is_duplicate']\nansw.to_csv('answ.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}