{"nbformat": 4, "metadata": {"language_info": {"mimetype": "text/x-python", "name": "python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["### I'm fairly new to data science and would appreciate any feedback or any comments in general. Thank you!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import math\n", "\n", "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n", "import sklearn.ensemble as skens\n", "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold\n", "import sklearn.metrics as metrics\n", "\n", "%matplotlib inline"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('../input/diamonds.csv',index_col=0)\n", "data.head()"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["data.describe()"]}, {"execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "86c117c5-97fa-4c2c-86e7-3e30e3e79967", "collapsed": true, "_uuid": "f85f1571c1b2e90b2496b823a995c0a347c62f71"}, "outputs": [], "source": ["# Pasted from Content Page:\n", "# price price in US dollars ($326--$18,823)\n", "# carat weight of the diamond (0.2--5.01)\n", "# cut quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n", "# color diamond colour, from J (worst) to D (best)\n", "# clarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n", "# x length in mm (0--10.74)\n", "# y width in mm (0--58.9)\n", "# z depth in mm (0--31.8)\n", "# depth total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43--79)\n", "# table width of top of diamond relative to widest point (43--95)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# x, y, and z should not have zeroes. \n", "# e.g. --> if you go to Jared's and pick out a diamond for your fiance that's 0 mm wide,\n", "# you're braver than me.\n", "\n", "d = data.shape[0]\n", "print('# Rows in the data before: {}'.format(d))\n", "data = data[(data.x > 0) & ((data.y > 0) & (data.z > 0))]\n", "\n", "print('# Rows after: {}'.format(data.shape[0]))\n", "print('--------\\nDifference of: {}'.format(d - data.shape[0]))\n", "\n", "# Looks like a 20 instances of a \"0\" in one of x,y,z were removed\n", "# only 20 out of ~54k, so I'm not gonna worry about possibly correcting/imputing\n", "# these although that is a possibility"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["data['log_price'] = np.log(data.price)\n", "\n", "plt.figure(figsize=(10,5))\n", "plt.subplot(1,2,1);\n", "sns.distplot(data.price);\n", "plt.subplot(1,2,2);\n", "sns.distplot(data.log_price);\n", "\n", "data.drop('price', axis=1, inplace=True)\n", "\n", "# 'price' is skewed. Makes sense. Pricier / quality diamonds are rarer for a reason.\n", "# Perform a log transformation on the skewed 'price' data. Results: not normal,\n", "# but bimodal and a big improvement.\n", "# Information on log transforming technique: \n", "# https://stats.stackexchange.com/questions/107610/what-is-the-reason-the-log-transformation-is-used-with-right-skewed-distribution"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["### DATA VIZ ###\n", "\n", "# plot the c's\n", "\n", "c = ['cut','clarity','color']\n", "\n", "plt.figure(figsize=(17,5))\n", "for i in range(len(c)):\n", "    plt.subplot(1,3,i+1)\n", "    sns.countplot(data[c[i]], palette='Set2');\n", "    plt.title('Value Counts of {}'.format(c[i]))"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# good predictors?\n", "\n", "p = ['carat','table','depth']\n", "sns.pairplot(x_vars=p, y_vars=['log_price'], data=data, size=4.0);\n", "\n", "# hmm in general heavy diamonds (high carat) are pricier!\n", "\n", "# The carat is a unit of mass equal to 200 mg and is \n", "# used for measuring gemstones and pearls. - Wikipedia"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# 'carat' seems to be a really good predicator of price\n", "# Let's see what else we can found out about diamonds ...\n", "\n", "sns.pairplot(x_vars=['carat','x','depth'], y_vars=['log_price'], data=data, hue='color', size=4.5);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["sns.pairplot(x_vars=['carat','x','depth'], y_vars=['log_price'], data=data, hue='cut', size=4.5);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["sns.pairplot(x_vars=['carat','x','depth'], y_vars=['log_price'], data=data, hue='clarity', size=4.5);\n", "\n", "# Kind of hard to tell, but for the majority of diamonds, it looks like bigger (larger carat and x)\n", "# do not mean necessarily mean the diamond is of the a better class of 'clarity','color', or 'cut'"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# What about these guys?\n", "\n", "xyz = ['x','y','z']\n", "sns.pairplot(x_vars=xyz, y_vars=['log_price'], data=data, size=4.0);\n", "\n", "# x and log_price seem to have a positive relationship\n", "# Definitely a few outliers messing up our view in y and z"]}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": false}, "outputs": [], "source": ["# lists from before are concatenated\n", "numerics = xyz + p\n", "\n", "# Normalize and plot\n", "plt.figure(figsize=(18,14))\n", "for col in numerics:\n", "    mean = np.mean(data[col])\n", "    std = np.std(data[col])\n", "    data[col] = (data[col] - mean) / std\n", "\n", "plt.subplot(2,1,1);\n", "ax = sns.violinplot(data=data[numerics]);\n", "ax.set_title('Violinplots of diamond data');\n", "\n", "plt.subplot(2,1,2);\n", "ax = sns.boxplot(data=data[numerics]);\n", "ax.set_title('Boxplots of diamond data');\n", "\n", "# Outliers strike again!"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["# map the c's ...\n", "# Clarity:  (worst)I1, SI2, SI1, VS2, VS1, VVS2, VVS1, IF(best)\n", "# Color: D (best) <---> J (worst)\n", "# Cut: Fair (worst) - Good - Very Good - Premium - Ideal (best)\n", "\n", "data.color = data.color.map({'J':1,'I':2,'H':3,'G':4,'F':5,'E':6,'D':7})\n", "data.clarity = data.clarity.map({'I1':1, 'SI2':2, 'SI1':3, 'VS2':4, 'VS1':5, 'VVS2':6, 'VVS1':7, 'IF':8})\n", "data.cut = data.cut.map({'Fair':1,'Good':2,'Very Good':3,'Premium':4,'Ideal':5})\n", "\n", "# *** Good to note if you're new to data science: ***\n", "# An order relationship must exist to encode this way.\n", "# -- For example within the 'cut' attribute a value of 'Fair' is less (not equal to / not equally as valuable as) than\n", "# a value of 'Ideal', as opposed to an attribute like 'Male or Female', which would be OneHotEncoded \n", "# (into two new binary columns) because both are equally as meaningful (Male is not greater than Female, & vice versa)\n", "# Thus, an order relationship exists, and so 'Fair' --> 1 is less than 'Ideal' --> 5 \n", "# Our regression model can pick up on this numerical relationship."]}, {"execution_count": null, "cell_type": "code", "metadata": {"scrolled": true}, "outputs": [], "source": ["data.head()"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,8))\n", "sns.heatmap(data.corr(),annot=True,linewidths=0.5);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["sns.pairplot(data);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# From our heatmap and pairplots: carat and x,y,z are highly correlated, but\n", "# should we address what looks like outliers in y and z?\n", "\n", "sns.pairplot(x_vars=xyz, y_vars='carat', data=data, size=4.0);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(18,5))\n", "\n", "# outlier discussion:\n", "# Are outliers EVIL? \n", "# Should you remove them??\n", "# Let's look at 'y' and 'z', which seem to have a few questionably large points.\n", "\n", "plt.subplot(1,4,1);\n", "# y and z should/could look like x\n", "ax = sns.regplot(x='x', y='carat', data=data, ci=0);\n", "ax.set_title('Carat and X');\n", "\n", "# what does y look like? Is the outlier affecting the regression line?\n", "# Let's plot it again.\n", "plt.subplot(1,4,2);\n", "ax = sns.regplot(x='y', y='carat', data=data, ci=0);\n", "ax.set_title('Carat and Y WITH outliers');\n", "# Hmm maybe? It's possible those two points way down on the x axis are dragging the line down.\n", "\n", "# Let's remove outliers and see how it looks:\n", "data['y_test'] = data[data.y < 20].y # removing the two points with large values\n", "plt.subplot(1,4,3);\n", "ax = sns.regplot(x='y_test', y='carat', data=data, ci=0);\n", "ax.set_title('Carat and Y WITHOUT outliers');\n", "data.drop('y_test',axis=1,inplace=True)\n", "# Looks pretty much like x. Nice!\n", "\n", "\n", "# BUT let's go back and zoom in on the Carat and Y w/ outliers plot:\n", "plt.subplot(1,4,4);\n", "ax = sns.regplot(x='y', y='carat', data=data, ci=0);\n", "ax.set_title('Carat and Y WITH outliers ZOOMED IN');\n", "ax.set_ylim([-2,10]); # control the zoom of the plot.\n", "ax.set_xlim([-2,5]);\n", "# Hmm looks like x \n", "\n", "# Are these points influential?\n", "# No, the third and fourth plots look identical and \n", "# the regression line still pretty much crosses through point (4,4) in both.\n", "# Conclusion: outliers are real and not necessarily your enemy. \n", "# Huge (outlier-ish) diamonds like this actually exist and\n", "# actually aren't the most important factor in determining price\n", "# Source: http://www.jewelrywise.com/engagement-wedding/article/does-the-size-of-the-diamond-matter"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["# Even though it was fun to play around with them, we're going to drop 'x','y','z'\n", "# They're all heavily correlated with 'carat' and will negatively affect a linear model.\n", "\n", "data.drop(xyz, axis=1, inplace=True)"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# Final look at our data\n", "data.head()"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# missing values?\n", "missing = pd.DataFrame(data.isnull().sum(), columns=['total'])\n", "missing\n", "\n", "# nope."]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["### Model Building ###\n", "\n", "def inv_log(preds):\n", "    # apply inverse log function\n", "    transformed_preds = []\n", "    for val in preds:\n", "        transformed_preds.append(np.round(math.exp(val), 2))\n", "    return np.array(transformed_preds)\n", "    \n", "\n", "X = data.iloc[:,:-1]\n", "y = data.log_price\n", "\n", "X_train, X_50, y_train, y_50 = train_test_split(X,y, test_size=0.5, random_state=2)\n", "\n", "print('Data split 50/50...\\nShape of training: {}\\nShape of Other: {}\\n---'.format(X_train.shape, X_50.shape))\n", "\n", "X_valid, X_test, y_valid, y_test = train_test_split(X_50, y_50, test_size=0.5, random_state=2)\n", "\n", "print(\"Further split 'Other' into 50/50 validation and test sets...\\nShape of Validation Set: {}\\nShape of Test Set: {}\".format(X_valid.shape, X_test.shape))\n", "\n", "# Now we have a 50/25/25 split on our data"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# Try some models\n", "\n", "lr = LinearRegression()\n", "rid = Ridge()\n", "rf = skens.RandomForestRegressor()\n", "gb = skens.GradientBoostingRegressor()\n", "\n", "classifiers = [lr, rid, rf, gb]\n", "\n", "kf = KFold(n_splits=5, shuffle=True, random_state=11)\n", "\n", "results = []\n", "names = []\n", "for clf in classifiers:\n", "    scores = cross_val_score(clf, X_train, y_train, scoring='r2', cv=kf, n_jobs=5)\n", "    results.append(scores)\n", "    name = str(clf.__class__).strip(\"'>\").split('.')[-1]\n", "    names.append(name)\n", "    print(name + ':', scores)\n", "    print('Average R-Squared Score:', np.mean(scores),'\\n----')\n", "\n", "# ensembles yield higher scores, but take a little longer to execute."]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(13,6))\n", "sns.boxplot(x=results, y=names);"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["rid = Ridge().fit(X_train, y_train)\n", "y_pred_train = rid.predict(X_train)\n", "y_pred = rid.predict(X_valid)\n", "print('R Squared:\\ntraining -- {}\\nvalidation -- {}'.format(metrics.r2_score(y_train, y_pred_train), metrics.r2_score(y_valid, y_pred)))\n", "error = inv_log(y_valid) - inv_log(y_pred)\n", "print('Average Price Error: {}'.format(error.mean()))"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# visualized\n", "sns.regplot(x=y_pred, y=y_valid, marker='x',line_kws={'color':'red'});"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# RF\n", "\n", "rf = skens.RandomForestRegressor(n_estimators=15).fit(X_train, y_train)\n", "y_pred_train = rf.predict(X_train)\n", "y_pred = rf.predict(X_valid)\n", "print('R Squared:\\ntraining -- {}\\nvalidation -- {}'.format(metrics.r2_score(y_train, y_pred_train), metrics.r2_score(y_valid, y_pred)))\n", "error = inv_log(y_valid) - inv_log(y_pred)\n", "print('Average Price Error: {}'.format(error.mean()))"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# As expected: tighter than the linear regression model\n", "sns.regplot(x=y_pred, y=y_valid, marker='x',line_kws={'color':'red'});"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["feats = pd.DataFrame(rf.feature_importances_, columns=['Importance'],\n", "             index=X_train.columns).sort_values('Importance', ascending=False)\n", "# feats.plot(kind='barh')\n", "feats\n", "# Carats are key!"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["# GB\n", "\n", "gb = skens.GradientBoostingRegressor().fit(X_train, y_train)\n", "y_pred_train = gb.predict(X_train)\n", "y_pred = gb.predict(X_valid)\n", "print('R Squared:\\ntraining -- {}\\nvalidation -- {}'.format(metrics.r2_score(y_train, y_pred_train), metrics.r2_score(y_valid, y_pred)))\n", "error = inv_log(y_valid) - inv_log(y_pred)\n", "print('Average Price Error: {}'.format(error.mean()))"]}, {"execution_count": null, "cell_type": "code", "metadata": {}, "outputs": [], "source": ["sns.regplot(x=y_pred, y=y_valid, marker='x',line_kws={'color':'red'});"]}, {"execution_count": null, "cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": ["# more to come (maybe) with GridSearchCV and parameters"]}]}