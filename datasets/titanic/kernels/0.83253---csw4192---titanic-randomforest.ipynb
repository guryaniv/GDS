{"cells":[{"metadata":{"trusted":true,"_uuid":"a3464ab6e6c9b6a6982d882789edbca341f03f12"},"cell_type":"code","source":"# 26/8/18 - Revisied for better readability","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\n\n# Input data files are available in the \"../input/\" directory.\nimport os\nprint(os.listdir(\"../input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Plotting parameters\nplt.rcParams['figure.figsize'] = (16,9)\nsns.set_palette('gist_earth')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa512b10206ab4a4799795b2e8c1f31dcc8d2358"},"cell_type":"markdown","source":"## Brief Introduction\nFirst, the 2 datasets are imported. The training one contains survival value while the testing one does not.  <br>\nThe aim here is to predict the survival of passengers in the test dataset using the features given."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"# Read datasets from csv\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\n\n# Merge the 2 dataframes for EDA and feature engineeraing\nfull = pd.concat([df_train, df_test], axis = 0, sort=True)\n\n# Set PassengerId as Index\nfull.set_index('PassengerId', drop = False, inplace=True)\ntrain = full[:891]\n\n# Display Data\ndisplay(full.head(3))\nprint(f\"Dataset contains {full.shape[0]} records, with {full.shape[1]} variables.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f103e7ef33077f5a79dbeb16605876af937bbab5"},"cell_type":"markdown","source":"## Missing Values\nMissing Values are found on Age, Cabin and Fare. <br>\nAs too many values are missing in Cabin, this features may not be useful for predicting survival;\nAge can be an important factor and could be inferred from other features, e.g., Title, Parch and the families the passengers was belong to."},{"metadata":{"trusted":true,"_uuid":"f16c4cf2d6f429cd42e30debb0dff655225b1f58"},"cell_type":"code","source":"# Identify Missing Values\nnan = full.isnull().sum()\nidx_nan = nan.mask(nan==0).dropna().index\n\nsns.heatmap(full[idx_nan].transpose().isnull(), cmap = 'binary', cbar = False)\nnan[idx_nan].drop('Survived').sort_values()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b4362db4bb13a8629e6eb62a7cca5d1aa7c22444"},"cell_type":"markdown","source":"## Data Cleaning\n- simplifying the values of categorical variables\n- the first few letters of Ticket and Cabin may tell us the location of the passengers"},{"metadata":{"_uuid":"92409da7d8d62acd2e28140c847c0590405ddea0"},"cell_type":"markdown","source":"### Simplifying the Ticket\nTickets provide information on where the passengers are located on ship, which may be vital for survival.\nHere, I group the tickets by their first few letters."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"44512b0c9a63ca17d58bf3cb73598385176be5b7"},"cell_type":"code","source":"np.sort(full['Ticket'].unique())\n# note: can further explore tcket - cabin - Pclass relationship here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18665c68d66e77595965c1e89af9e4aa5f2b97a2"},"cell_type":"code","source":"def parse_ticket(str1):\n    \"\"\"\n    Function to parse the Letter part of the Ticket code\n    \"\"\"\n    m = re.search(r'(.*)(\\s\\d|\\s\\d{4,7}$)',str1)\n    s = re.search(r'[A-Z]+',str1)\n    if m: # removing non alphanumeric characters and binding the numbers and letters before the space\n        str2 = m.group(1)\n        n =re.search(r'([A-Z]+)[^A-Z0-9]*([A-Z]+)*[^A-Z0-9]*([A-Z0-9]*)[^A-Z]*([A-Z]*)*',str2)\n        new_str = ''\n        if n:    \n            if n.group(1):\n                new_str+=n.group(1)\n                if n.group(2) or n.group(3):\n                    if n.group(2):\n                        new_str+=n.group(2)\n                    if n.group(3):\n                        new_str+=n.group(3)\n                        if n.group(4):\n                            new_str+=n.group(4)\n                            if n.group(5):\n                                new_str+=m.group(5)\n    elif s:\n        new_str = s.group(0) # Ticket with letters only\n    else:\n        new_str = 'XXX' #Ticket with only numercial values\n    return new_str\n\nfull['Ticket_short'] = full.Ticket.map(parse_ticket)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b57ac5743f1eeb9de99a60f4424fe58fa5bc5eb4"},"cell_type":"markdown","source":"### Cabin"},{"metadata":{"trusted":true,"_uuid":"61fafae9f60511cde56763e478cc7cd6e497352e"},"cell_type":"code","source":"def parse_Cabin (cabin):\n    if type(cabin) == str:\n        m = re.search(r'([A-Z])+', cabin)\n        return m.group(1)\n    else:\n        return 'X'\n        \nfull['Cabin_short'] = full['Cabin'].map(parse_Cabin)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40472842d93d5f8e6ffbb3dad3ed6a73319c95dd"},"cell_type":"markdown","source":"###  Fare\nFare value was found to be distorted as the Fare feature in original dataset calculates the total amount paid for one single ticket, i.e., no. of person * base rate of ticket. To get a more accurate fare paid by individual value, the fare is divided by the no. of person holding that ticket."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"e1c0c061bad9b33b6dcb844d08f24732c618b41b"},"cell_type":"code","source":"# Fare Adjustment\nfare_original = full['Fare'].copy()\n\ndict_ticket_size = dict(full.groupby('Ticket').Fare.count())\nticket_size = full['Ticket'].map(dict_ticket_size)\nfull['Fare'] = full.Fare/ticket_size\n\n\n# Plot Fare Adjustment\nfig, (ax0, ax1) = plt.subplots(2)\nax0.hist(fare_original.dropna(), bins=80);\nax0.set_xlabel('Fare(Original)')\n\nax1.hist(full['Fare'].dropna(), bins=80);\nax1.set_xlabel('Fare (Corrected)');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cee5aff96f690a7c1d42bb7fef828345526a677f"},"cell_type":"markdown","source":"After adjustment, the range has reduced from 0 - 510 to 0 - 130 and the 3 Pclass are more clearly shown by the 3 peaks of Adjusted Fare."},{"metadata":{"_uuid":"451802b35b1c74b3e19e8aae61011b6eeabc05df"},"cell_type":"markdown","source":"### Missing Fare\nWith fare adjusted, we should be able to fill in the missing Fare value by the Pclass the passenger is in."},{"metadata":{"trusted":true,"_uuid":"950d09d94eb805c86c68787307ec56b7d32fc812"},"cell_type":"code","source":"# Calculate mean fare cost for each PClass\ndict_fare_by_Pclass = dict(full.groupby('Pclass').Fare.mean())\n# fill value according to PClass\nmissing_fare = full.loc[full.Fare.isnull(),'Pclass'].map(dict_fare_by_Pclass)\nfull.loc[full.Fare.isnull(),'Fare'] = missing_fare","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e162bd25360654c38f2dcf44133265f79d0cff4a"},"cell_type":"markdown","source":"## Exploring the Data - Distributions"},{"metadata":{"trusted":true,"_uuid":"554c52adb25ddaa3f656f3328489ba474ff3e98d","scrolled":false},"cell_type":"code","source":"# Descriptive Statistics\ndisplay(full.describe())\nprint(f\"survived: {full.Survived.mean()*100:.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a36f4bf5c172fbc786504bd39cec0578e37a5f3","scrolled":false},"cell_type":"code","source":"# EDA - Distributions\nvar_to_plot = ['Pclass','Sex','SibSp','Parch','Embarked','Survived']\n\n# Plot Categorical Var\nfig, axs = plt.subplots(4,3, figsize=(15,12))\nfor i,key in enumerate(var_to_plot):\n    sns.countplot(key, data=full, ax=axs[i//3,i%3])\n     \n# Plot Age\nplt.subplot2grid((4,3),(2,0),rowspan=1,colspan=3);\nsns.distplot(full.Age.dropna(), bins=range(0,80,2), kde=False)\nplt.xlabel('Age');\n\n# Plot Fare\nplt.subplot2grid((4,3),(3,0),rowspan=1,colspan=3);\nsns.distplot(full.Fare.dropna(), bins=100, kde=False)\nplt.xlabel('Fare');\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d9dbf55133389fc7dc846ff25ef7ef02f872969"},"cell_type":"markdown","source":"## EDA - Relationships between features and survival"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d3e5b47fd3cc9baff7dbef21c33f595c10b1ff88"},"cell_type":"code","source":"# Plot all categorical features with Survival rate\nvar_to_plot = ['Pclass','Sex','SibSp','Parch','Embarked','Cabin_short']\n\nf, axs = plt.subplots(3,5, sharey=True)\ncoord = [(0,0),(0,2),(1,0),(1,2),(2,0),(2,2)]\nfor i,key in enumerate(var_to_plot): # except feature Survived\n    plt.subplot2grid((3,5),(coord[i]),rowspan=1,colspan=2);\n    sns.barplot(data = full, x= key, y='Survived', color='darkgreen');\n    plt.axhline(y=0.3838, color='k', linestyle='--')\n\n# Plot Correlation\ncorr = pd.DataFrame(full.corr()['Survived'][:-1])\nplt.subplot2grid((3,5),(0,4),rowspan=3,colspan=1);\nsns.heatmap(corr, cmap = \"BrBG\", annot = True, annot_kws = {'fontsize': 12 });\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a3c3a197737d839dc2f91d7a9f554b7aa9765ba"},"cell_type":"markdown","source":"Findings:\n- Sex seems to have a strong predictive power, which makes sense due to the \"Women and Children First\" instructions for deciding who can get on the lifeboats. <br>\n- Pclass and Fare also showed a moderate correalation with Survival. These higher class passengers lives and have most of their activities near the deck, thus, closer to the lifeboats. <br>\n- It is surprising to find no significant correlation between Age and Survived. Their relationship may not be linear.\n- Cabin seem to have some relationships with survival, although we have lots of Nan values in this feature. Perhaps it's possible to guess those Nan values after looking into its relationships with Ticket no., Embark and PClass.\n- Embark C seem have significantly higher survival rate compared to Embark S, which also have a relatively low variance, There may be a relationship of where they board the Titanic and where they stay on boat."},{"metadata":{"trusted":true,"_uuid":"120c35f687c90847622c794b3aca058ebc9c9f67"},"cell_type":"code","source":"# Create DataFrame Features to record potential predictors for later model training\nfeatures = pd.DataFrame()\nfeatures['Pclass'] = full['Pclass']\nfeatures['Fare'] = full['Fare']\nfeatures['Sex'] = full['Sex']\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d87a1e02d23bd43eadff385e8cd80789dab906e0"},"cell_type":"markdown","source":"### Ticket_short with Survival\nThere were still too many types of tickets even after parsing. In the plot below, only those with >10 count are plotted."},{"metadata":{"trusted":true,"_uuid":"1afca47a1bacb4050357cc4f75b0f14162e3a981"},"cell_type":"code","source":"d = dict(full['Ticket_short'].value_counts())\nticket_count = full['Ticket_short'].map(d)\n# Show % survived by Ticket\ndisplay(full.groupby('Ticket_short').Survived.aggregate(['mean','count']).dropna().sort_values('count').transpose())\n# Plot % survived by Ticket, droping those tickets with <10 count\nsns.barplot(data = full[ticket_count > 10], x = 'Ticket_short', y = 'Survived')\nplt.axhline(y=0.3838, color='k', linestyle='--');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6cda3b38c427eb34bf84dba9e76dfa2418eb619"},"cell_type":"markdown","source":"Tickets with the most Predictive power: A5, PC. "},{"metadata":{"trusted":true,"_uuid":"e36c66ca7242a17fe80b68e57f24395dbaaa6953"},"cell_type":"code","source":"features['A5'] = (full['Ticket_short'] == 'A5').astype(int)\nfeatures['PC'] = (full['Ticket_short'] == 'PC').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5c3f7c3a29a6deec89a94ff50658e296a48c968b"},"cell_type":"markdown","source":"### Further exploring the relationship between Pclass, Sex, Age and Survival\nI suspect that some sort of interaction may exist between PClass, Sex and Age on predicitng survival. It is plotted below."},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"ab30b1eda98fe02aa1a753f2f8916fa7f5509564"},"cell_type":"code","source":"# Plot number of survived passengers by PClass, Sex and Age\nfacet = sns.FacetGrid(full, row = 'Pclass',col='Sex', hue = 'Survived', aspect=2, palette = 'Set1')\nfacet.map(plt.hist, 'Age', histtype='step', bins = np.arange(0,80,4))\n\nfacet.add_legend();","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23c3a50b9b55c6bb337e98e950ca3a7f55ba02c8"},"cell_type":"markdown","source":"Findings: \n- Agree with the \"Women first\" pattern. <br>\n- Child survival advantage seems to apply for those < 12 years old for male. <br>\n- Much higher survival rate for people in 1st and 2nd class. Children and Women in these 2 classes have a much higher survival rate (some age range even with  100%), compared to those in the 3rd class (which has around 50% chance). Still, some women did not survive in the 1st and 2nd class, perhaps they were in a really bad location on the boat, even they live near the deck level."},{"metadata":{"_uuid":"407fa91fc0f1fd998b84fea7ca6a01659b1a6852"},"cell_type":"markdown","source":"### Age and Sex\nInstead of count of passangers survived, ploting the rate of survival with Age may give us a clearer look on the effect of age on survival rate.\n"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"5bfe97abc89c6d22f19d5c8d2b88d19a19a70057"},"cell_type":"code","source":"# Create Age Quartiles\nAge_quartile = pd.qcut(full.Age,10)\n\n# Plot age quartiles by sex with survival rate\nsns.barplot(data = full, x= Age_quartile, y='Survived', hue = 'Sex');\nplt.axhline(y=0.3838, color='k', linestyle='--')\nplt.xticks(rotation = 30)\nplt.title('Across All Classes');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60504c3d7c37e8e6087cb4638fcd1a578f10a514"},"cell_type":"markdown","source":"From the FacetGrid and the bar plot above, it seems that age does not matter on rate of survival for female. For male, Survival advantage for males seem to appy for those with Age < 12."},{"metadata":{"_uuid":"f686d50f3e366824c7796560be9c5dc4a00c15ab"},"cell_type":"markdown","source":"## Feature Engineering 1\nAfter a brief look of relationships between the existing features, it's time to engineer some new features from the existing features to improve the predictive power of the model.\n\nFirst of all, we can try to extract the title of passengers from the name. Apart from seeing their predicting power, this can give us information about the pasenger's age,\n"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d8dd41b4da4fd631a36bbfc21d0c7c80e02034da"},"cell_type":"markdown","source":"### Title - Filling Missing Age\nTitles of the Passengers may give us valuable information to infer the missing age, e.g., Master is a title for children. Additonally, royalties and officials may have a higher priority to get on the lifeboats."},{"metadata":{"trusted":true,"_uuid":"d39265c950a72b2e01332e70d0b4429132b24745"},"cell_type":"code","source":"# Parse Titles from Names\ndef parse_title(str):\n    m = re.search(', (\\w+ *\\w*)\\.',str)\n    return m.group(1)\n    \ntitle = full.Name.map(parse_title)\ntitle.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6aba745d92667f934b5b33aaeffdb465b47c10f"},"cell_type":"code","source":"# Simplify title groups\ndict_Title = {\"Capt\":       \"Officer\",\n                    \"Col\":        \"Officer\",\n                    \"Major\":      \"Officer\",\n                    \"Jonkheer\":   \"Royalty\",\n                    \"Don\":        \"Royalty\",\n                    \"Sir\" :       \"Royalty\",\n                    \"Dr\":         \"Officer\",\n                    \"Rev\":        \"Officer\",\n                    \"the Countess\":\"Royalty\",\n                    \"Dona\":       \"Royalty\",\n                    \"Mme\":        \"Mrs\",\n                    \"Mlle\":       \"Miss\",\n                    \"Ms\":         \"Mrs\",\n                    \"Mr\" :        \"Mr\",\n                    \"Mrs\" :       \"Mrs\",\n                    \"Miss\" :      \"Miss\",\n                    \"Master\" :    \"Master\",\n                    \"Lady\" :      \"Royalty\"\n                    }\n\ntitle = title.map(dict_Title)\n\n# Plot the distribution of Age by Title\nplt.figure(figsize = (14,6))\nsns.violinplot(x = title, y = full['Age']);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cec0493ba279552f07c4db6fd4cbc143dfd579e"},"cell_type":"markdown","source":"Passengers with title 'Master' are likely to be children, we can infer those missing age as the mean age of Master\nPassengers with title 'Miss' seem to comprise both children and adult, the followings is an attempt to infer their age from other given features <br>\nHowever, age of female here is relatively unimportant, since all female regardless of age have high priority to board the lifeboats."},{"metadata":{"trusted":true,"_uuid":"35bf087cdaf8a71ed970ba591de7bdf178b2d1cd"},"cell_type":"code","source":"# Calculate mean age of each title group\ndf_title = pd.DataFrame(title).join(full[['Age','Survived']])\ndict_age = df_title.groupby('Name').Age.mean()\n\n# Fill in Age according to passenger's title\nidx = full.Age.isnull()\nfull.loc[idx,'Age'] = df_title.loc[idx, 'Name'].map(dict_age)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01c2aa152c2e3afcd59999291575b58536b1fdc3"},"cell_type":"markdown","source":"### Title - Survival"},{"metadata":{"_uuid":"0a1080fc8016a688bd132dd7d56ffe867ed0e0e4","trusted":true,"scrolled":false},"cell_type":"code","source":"# Plot title with Survived\nsns.barplot(data = df_title, x= 'Name', y='Survived');\nplt.axhline(y=0.3838, color='k', linestyle='--');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"472e0f95ea9f8349a3e1e84b9a694a38370fff23"},"cell_type":"code","source":"# Record useful features in features dataframe\nfeatures['Title'] = df_title['Name']\nfeatures['Child'] = (full['Age'] <= 14).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b391071fe359f9b37a791f57a9f8d3c240fb28d1"},"cell_type":"markdown","source":"## Feature Engineering 2\nAnother  interesting relationships to look at is between Survival, Parch and SibSp. It is not difficult to imagine those within the same family/ same group will stay together when in danger, thus, having any of them survived would mean the other members of the group will likely to have a better chance to survive, and vice versa."},{"metadata":{"_uuid":"2c94a0e278723eb0939bf5b8dea48d80a1d5599c"},"cell_type":"markdown","source":"### Surname\nFirst, parse the Surnames of the passengers. Those from the same family should share the surname. <br>\nSurnames are grouped together and their occurance caluculated respectively."},{"metadata":{"trusted":true,"_uuid":"759350d828967d136cac8925e4fe3204b840e123","scrolled":false},"cell_type":"code","source":"# function to parse surname of the passengers\ndef parse_surname(name):\n    return name.split(',')[0]\n# Calculate Family Size\nfamily = pd.DataFrame(full[['Parch','SibSp','Ticket']])\nfamily['Family_size'] = 1 + family.Parch + family.SibSp\n\n# Parse Surname from Name\nfamily['Surname'] = full.Name.map(parse_surname)\n\n# Surname Code and Surname Size\ndict_scount = dict(family.groupby('Surname').Family_size.count())\ndict_scode = dict(zip(dict_scount.keys(), range(len(dict_scount))))\n\nfamily['Surname_code'] = family['Surname'].map(dict_scode)\nfamily['Surname_count'] = family['Surname'].map(dict_scount)\n\n# Examples with common surname\ndisplay(full[family.Surname == 'Smith'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f96f1673da854fbde9c12d40697e2a3d72c0e07b"},"cell_type":"markdown","source":"However, some common surnames may be shared by people from different families. <br> \nThe following function is an attempt to address this issue: <br>\nTo judge if passengers are likely to be in the same family, the function check their ticket code.  <br>\nThe function decides if people with the same surname are from the same family by checking the level of  similarity of their tickets. Those with the exact same tickets or tickets that have values close to each other are grouped together."},{"metadata":{"trusted":true,"_uuid":"782101a2709ddc00f0acf4aa832970401a728e6b"},"cell_type":"code","source":"def tick2fam_gen(df):\n    \"\"\"\n    Function to judge if passengers are likely to be in the same family.\n    Input: DataFrame with Passenger surname and ticket\n    Return: Code generated to specify different families\n    \"\"\"\n    # initialize ticket dict\n    dict_tick2fam = {'000000': 0}\n    fam_counter = 0\n        \n    for i in df.index:    \n        keys = list(dict_tick2fam.keys())\n        chk_key = df.loc[i, 'Ticket']\n        for key in keys:\n            if len(chk_key) == len(key): #if their tickets have high similarity\n                if (chk_key[-4:].isdigit()) & (key[-4:].isdigit()): \n                    if (chk_key[:-2] == key[:-2]) & (np.abs(int(chk_key[-2:]) - int(key[-2:])) <= 10):\n                        dict_tick2fam[chk_key] = dict_tick2fam[key]\n                        break\n                    \n            if key == keys[-1]: # no match, assign a new code to the passenger\n                fam_counter += 1\n                dict_tick2fam[chk_key] = str(fam_counter)  \n                \n    return dict_tick2fam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64f041efd25375dc455b2493fd175f4adf390f3d"},"cell_type":"code","source":"# Single out Surnames with size > true family size (may have more than 1 family involved)\nsurname2chk = family[family['Family_size'] < family['Surname_count']].Surname.unique() \n# chk_surname2 = family_infer[family['FamilySize'] > family['SurnameSize']].Surname.unique() # unidentified fam\n\n# Regrouping Families according to Family Size and Ticket.\nfamily['Surname_adj'] = family['Surname'] #new column for corrected family_group\n\nfor s in surname2chk:\n    family_regroup = family[family['Surname'] == s] #get family with specific surname\n    fam_code_dict = tick2fam_gen(family_regroup) #pass in df to get family codes within the same surname\n\n    for idx in family_regroup.index: #assign family code 1by1\n        curr_ticket = full.loc[idx].Ticket\n        fam_code = fam_code_dict[curr_ticket]\n\n        if family_regroup.loc[idx, 'Family_size'] == 1: #for passengers traveling alone\n            #relatives that shares surname and ticket, which Parch and SibSp failed to record\n            if family_regroup.Ticket.value_counts()[curr_ticket] > 1: \n                family.loc[idx, 'Surname_adj'] =  s + '-hidfam' + fam_code\n            #single traveler\n            else: \n                family.loc[idx, 'Surname_adj'] =  s + '-single' + fam_code\n        #different families\n        else: \n            family.loc[idx, 'Surname_adj'] =  s + '-fam' + fam_code\n\ndisplay(family[family.Surname == 'Smith'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c756c44a5b9bf63d37883e683a6cb407e55ff742"},"cell_type":"markdown","source":"After Adjusting the surnames of families, group these true families together again. The no. of families here should increase."},{"metadata":{"trusted":true,"_uuid":"46ec707ddbd7384935354f87613ca3db2f4a8165"},"cell_type":"code","source":"# Assign codes to families\ndict_fcount = dict(family.groupby('Surname_adj').Family_size.count())\ndict_fcode = dict(zip(dict_fcount.keys(), range(len(dict_fcount))))\n\nfamily['Family_code'] = family['Surname_adj'].map(dict_fcode)\nfamily['Family_count'] = family['Surname_adj'].map(dict_fcount)\n\nprint(f\"No. of Family Before Regrouping: {len(family.Surname_code.unique())}\")\nprint(f\"No. of Family After Regrouping: {len(family.Family_code.unique())}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c188cc03a6cfa68ba3b32e0654acf9b56b18d1f3"},"cell_type":"markdown","source":"### Identify Roomates by Ticket\nPeople who share the same ticket can be families as well as friends traveling together. They are expected to stay together during the incidents. "},{"metadata":{"trusted":true,"_uuid":"c3a0be42b0982f5399d4276de792392e6ac0541e"},"cell_type":"code","source":"# Identify Groups (Those holding the same ticket code, could be friends/family)\ngroup = pd.DataFrame(family[['Surname_code','Surname_count','Family_code','Family_count']])\n\ndict_tcount = dict(full.groupby('Ticket').PassengerId.count())\ndict_tcode = dict(zip(dict_tcount.keys(),range(len(dict_tcount))))\n\ngroup['Ticket_code'] = full.Ticket.map(dict_tcode)\ngroup['Ticket_count'] = full.Ticket.map(dict_tcount)\n\nprint(f\"No. of Tickets Identified: {len(group['Ticket_code'].unique())}\")\ndisplay(full[(full.Ticket == 'A/4 48871') |(full.Ticket == 'A/4 48873')])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"784eda64614a50ad5aa9b14d019557b207bb510b"},"cell_type":"markdown","source":"### Combining Friends and Families as Groups\nFinally, the families and friend groups are combined together.  <br>\nPeople who share either the same room or same family are grouped together."},{"metadata":{"trusted":true,"_uuid":"e3f4520f65551ea20fc043f1bf095159cd05b2ee"},"cell_type":"code","source":"def ChainCombineGroups(df, colA, colB):\n    '''\n    This function takes in 2 columns of labels and chain all items which share\n    the same labels within each of the 2 columns\n    input:\n    df - DataFrame\n    colA - Key for Col\n    colB - Key for Col  \n    output:\n    array of numeric grouping labels\n    '''\n    # make a copy of DFs for iteration\n    data = df.copy()\n    search_df = data.copy()\n    \n    group_count = 0\n\n    while not search_df.empty:\n\n        # Initiate pool and Select Reference item\n        pool = search_df.iloc[:1]\n        idx = pool.index\n\n        # Remove 1st item from searching df\n        search_df.drop(index = idx, inplace = True)\n\n        # Initialize Search\n        flag_init = 1\n        update = pd.DataFrame()\n\n        # While loop to exhausively search for commonalities, pool is updated until no more common features are found\n        while (flag_init or not update.empty):\n\n            flag_init = 0\n\n            # target labels to look for\n            pool_A_uniq = np.unique(pool[colA])\n            pool_B_uniq = np.unique(pool[colB])\n\n            for col in [colA,colB]:\n                idx = []\n\n                # get all indexs of items with the same label\n                for num in np.unique(pool[col]):\n                    idx.extend(search_df[search_df[col] == num].index)\n\n                # update pool\n                update = search_df.loc[idx]\n                pool = pd.concat([pool, update], axis = 0)\n\n                # remove item from searching df\n                search_df = search_df.drop(index = idx)\n\n            # assign group num\n            data.loc[pool.index, 'Group_'] = group_count\n\n        group_count += 1\n        \n    return np.array(data['Group_'].astype(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf81ffee070583626c9b09d231f98cb3f8f8e265","scrolled":true},"cell_type":"code","source":"# Assign Final group no.\ngroup['Group_code'] = ChainCombineGroups(group, 'Family_code', 'Ticket_code')\n\n# Calculate group sizes\ndict_gcount = dict(group.groupby('Group_code').Family_code.count())\ngroup['Group_count'] = group.Group_code.map(dict_gcount)\n         \nprint(f\"Family: {len(family['Family_code'].unique())}\")\nprint(f\"Group: {len(group['Ticket_code'].unique())}\")\nprint(f\"Combined: {len(group['Group_code'].unique())}\\n\")\nprint('An example of grouping the both friends and family under a same group:')\ndisplay(pd.concat([full['Ticket'],family[['Surname','Family_code']],group[['Ticket_code','Group_code']]], axis = 1)[group['Group_code'] == 458])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65dba7925fc034944ea32589d8fb6d24b7cc80b1"},"cell_type":"markdown","source":"### Limitations:\nThe above function did fail to join some families back together, especially those who had different ticket numbers and had different surnames. <br> \nFor example, female siblings who were married and took different surnames; <br>\nand families who bought tickets with codes that has low similarity, which is likely to be found for those in the 1st Class. "},{"metadata":{"_uuid":"0431962860b148be85946adbf3f03fdafa2d9ef4"},"cell_type":"markdown","source":"### Survival of the Group\nFinally, the thing that we wanted to know in the first place is if the members in their Family/Friends group has survived or not. Having a surviving friend/family member should have good predictive power of whether a passenger survived or not."},{"metadata":{"trusted":true,"_uuid":"f44b3fa558cd495e13565397243757d6d896cfd7"},"cell_type":"code","source":"# Prepare the df by adding the Survived features\ngroup_final = pd.concat([family[['Surname_code','Surname_count','Family_code','Family_count']],\n                       group[['Ticket_code','Ticket_count','Group_code','Group_count']],\n                        full['Survived']], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b71e42b2974eb853d764d7b376cc028a60970b8a","scrolled":false},"cell_type":"code","source":"for param in [('Surname_code','Surname_count'),\n              ('Family_code','Family_count'),\n              ('Ticket_code','Ticket_count'),\n              ('Group_code','Group_count')]: # keep group at last\n    \n    # No. of member survived in each group\n    n_member_survived_by_gp = group_final.groupby(param[0]).Survived.sum()\n    \n    # No. of member survived in a particular group, discounting the passenger concerned\n    n_mem_survived = group_final[param[0]].map(n_member_survived_by_gp)\n    n_mem_survived_adj = n_mem_survived - group_final.Survived.apply(lambda x: 1 if x == 1 else 0)\n\n    # Same for the dead\n    n_member_dead_by_gp = group_final.groupby(param[0]).Survived.count() - group_final.groupby(param[0]).Survived.sum()\n    n_mem_dead  = group_final[param[0]].map(n_member_dead_by_gp)\n    n_mem_dead_adj = n_mem_dead - group_final.Survived.apply(lambda x: 1 if x == 0 else 0)\n\n    # How many people from that group that we do not have data on.\n    unknown_factor = (group_final[param[1]] - n_mem_survived_adj - n_mem_dead_adj)/group_final[param[1]]\n    confidence = 1 - unknown_factor\n\n    # Ratio of members survived in that group, ranging from -1 to 1, adjusted by the confidence weight\n    key = 'Confidence_member_survived'+'_'+param[0]\n    ratio = (1/group_final[param[1]]) * (n_mem_survived_adj - n_mem_dead_adj)\n    group_final[key] = confidence * ratio\n\n# Display Correlation\nplt.barh(group_final.corr().Survived[-4:].index, group_final.corr().Survived[-4:])\nplt.xlabel('Correlation with Survived');\n\nfeatures['Cf_mem_survived'] = group_final['Confidence_member_survived_Group_code']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ded4eaeb81d3ce81ec3ec865fa4aa04e4a05a1e9","scrolled":true},"cell_type":"code","source":"features['Parch'] = full['Parch']\nfeatures['SibSp'] = full['SibSp']\nfeatures['Group_size'] = group['Group_count']\n\nfeatures.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1d02d3ae8eee0f4d3ac606ea8c9812c5347ab6d"},"cell_type":"markdown","source":"## Data Transformation\nUsed StanardScalar for continuous variables and One-hot encoding for Categorical ones."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fd3765b2215c705a41193ea631c26fab5eb3e8b1"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Standardize the continuous variables\nscalar = StandardScaler()\nfeatures_z_transformed = features.copy()\ncontinuous = ['Fare'] \nfeatures_z_transformed[continuous] = scalar.fit_transform(features_z_transformed[continuous])\n\n# Transform Sex labels into binary code\nfeatures_z_transformed.Sex = features_z_transformed.Sex.apply(lambda x: 1 if x == 'male' else 0)\n\n# One-hot Encoding\nfeatures_final = pd.get_dummies(features_z_transformed)\n\nencoded = list(features_final.columns)\nprint(\"{} total features after one-hot encoding.\".format(len(encoded)))\n\n# Seperate Train Data and Test Data\nfeatures_final_train = features_final[:891]\nfeatures_final_test = features_final[891:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01cfc65eded30aeb785046e01591d713ea441086"},"cell_type":"markdown","source":"## Model Training and Selection\n"},{"metadata":{"trusted":true,"_uuid":"46541bd74d5e886853601434987b126c444797be"},"cell_type":"code","source":"# Spliting Training Sets into Train and Cross-validation sets\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n\nX_train, X_test, y_train, y_test = train_test_split(features_final_train, \n                                                    train.Survived, \n                                                    test_size = 0.2, \n                                                    random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6e4f58b457d4094bb16b848f4212a69b0fb3910"},"cell_type":"code","source":"# Create Model Training Pipeline\nfrom sklearn.metrics import accuracy_score\n\ndef train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n    '''\n    inputs:\n       - learner: the learning algorithm to be trained and predicted on\n       - sample_size: the size of samples (number) to be drawn from training set\n       - X_train: features training set\n       - y_train: income training set\n       - X_test: features testing set\n       - y_test: income testing set\n    '''\n    \n    results = {}\n    \n    # Fit the learner to the training data using slicing with 'sample_size' using .fit(training_features[:], training_labels[:])\n    learner = learner.fit(X_train[:sample_size], y_train[:sample_size])\n    \n    # Get the predictions on the test set(X_test),\n    predictions_test = learner.predict(X_test)\n    \n    # then get predictions on the training samples(X_train)\n    predictions_train = learner.predict(X_train)\n            \n    # Compute accuracy on the training samples\n    results['acc_train'] = accuracy_score(y_train, predictions_train)\n        \n    # Compute accuracy on test set using accuracy_score()\n    results['acc_test'] = accuracy_score(y_test, predictions_test)\n       \n    # Success\n    print(\"{} trained on {} samples. Acc: {:.4f}\".format(learner.__class__.__name__, sample_size, results['acc_test']))\n        \n    # Return the results\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"7515c55d4c3d55d39d50f5ae0fcff497b627a86f"},"cell_type":"code","source":"# Import the three supervised learning models from sklearn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier,RandomForestClassifier\n\n# Initialize the three models\nclf_A = GradientBoostingClassifier(random_state = 0)\nclf_B = LogisticRegression(random_state= 0)\nclf_C = RandomForestClassifier(random_state= 0)\n\n# Calculate the number of samples for 10%, 50%, and 100% of the training data\nsamples_100 = len(y_train)\nsamples_10 = int(len(y_train)/2)\nsamples_1 = int(len(y_train)/10)\n\n# Collect results on the learners\nresults = {}\nfor clf in [clf_A, clf_B, clf_C]:\n    clf_name = clf.__class__.__name__\n    results[clf_name] = {}\n    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n        results[clf_name][i] = \\\n        train_predict(clf, samples, X_train, y_train, X_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"024d7f953b517522e4299275a569ad08457b921b"},"cell_type":"code","source":"# Reshaping the Results for plotting\ndf = pd.DataFrame()\n\nfor i in results.items():\n    temp = pd.DataFrame(i[1]).rename(columns={0:'1% of train', 1:'10% of train', 2:'100% of train'})\n    temp['model'] = i[0]\n    df = pd.concat([df, temp], axis = 0)\ndf_plot = df.reset_index().melt(id_vars=['index','model'])\n\n# Ploting the results\nfig, axs = plt.subplots(1,2,figsize = (16,5))\nfor i,key in enumerate(df_plot['index'].unique()[:2]):\n    ax = axs[i%2]\n    sns.barplot(data = df_plot[df_plot['index'] == key], x = 'model', y = 'value',\n                hue = 'variable', ax = ax)\n    ax.set_ylim([0.6,1])\n    ax.set_title(key)\n    ax.legend(loc=\"lower right\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f642f0d6f052b42b12ec340fb0e0682c50fca74"},"cell_type":"markdown","source":"## Model Selection and model tuning\nRandomForestClassifier seemed to have the best out of the box accuracy score and with room for improvement as seen in acc_train.\nModel tuning is performed using GridSearchCV to improve generalizability of the model."},{"metadata":{"trusted":true,"_uuid":"50dad97e49723373414d910c553cf71de0f43681"},"cell_type":"code","source":"from sklearn.grid_search import GridSearchCV\nfrom sklearn.metrics import make_scorer\nwarnings.filterwarnings('ignore')\n\nclf = RandomForestClassifier(random_state = 0, oob_score = True)\n\nparameters = {'criterion' :['gini'],\n             'n_estimators' : [350], #400\n             'max_depth':[5], #5\n             'min_samples_leaf': [4], #4\n              'max_leaf_nodes': [10], #10]\n              'min_impurity_decrease': [0], #0\n              'max_features' : [1] #1\n             }\n\nscorer = make_scorer(accuracy_score)\n\ngrid_obj = GridSearchCV(clf, parameters, scoring = scorer, cv = 10)\n\ngrid_fit = grid_obj.fit(X_train,y_train)\n\nbest_clf = grid_fit.best_estimator_\n\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\nbest_predictions = best_clf.predict(X_test)\n\nprint(\"Unoptimized model\\n------\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"Oob score on testing data: {:.4f}\".format(clf.oob_score_))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Final oob score on the testing data: {:.4f}\".format(best_clf.oob_score_))\nprint(\"\\nBest Parameters\\n------\")\nbest_clf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6255c6c0cc86885259ff329d6bc56b92710afefc"},"cell_type":"code","source":"# Plot Feature Importnace\nidx = np.argsort(best_clf.feature_importances_)\nplt.figure(figsize = (12,8))\nplt.barh(range(len(best_clf.feature_importances_)),best_clf.feature_importances_[idx])\nplt.yticks(range(len(best_clf.feature_importances_)),features_final_train.columns[idx]);\nplt.title('Feature Importance');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4222258b969f99892223eff198fc96fac98c2ec7"},"cell_type":"code","source":"# Output for Kaggle competition\nfinal_predict = best_clf.predict(features_final_test)\n\nprediction = pd.DataFrame(full[891:].PassengerId)\nprediction['Survived'] = final_predict.astype('int')\n\nprediction.to_csv('predict.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}