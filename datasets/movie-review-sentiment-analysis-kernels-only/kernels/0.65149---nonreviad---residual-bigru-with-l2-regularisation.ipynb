{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport keras\nfrom keras.layers import GRU, Bidirectional, Dense, Reshape, Input, Embedding, LSTM, Add, CuDNNGRU\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca447fd7a7198af1f0496fa5bbbcc2677dbe7256"},"cell_type":"code","source":"df = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/train.tsv', delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05af3358aac032fcafcb3fef9d7c5639a2f6637c"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b489e3e1a7c045703198212679bc794dd4cefc80"},"cell_type":"code","source":"vocab_size = 15000\nmax_len = 50\nembedding_size = 200\nhidden_size = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"022262a029ce59c31d7507248ade501e5977000d"},"cell_type":"code","source":"tok = keras.preprocessing.text.Tokenizer(num_words=vocab_size, filters='-\\t\\n')\ntok.fit_on_texts(df['Phrase'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3207a7f9ed200473bc1b04059e347dd729053e81"},"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nembeddings_index = {}\nwith open(os.path.join('../input/glove-global-vectors-for-word-representation/glove.6B.200d.txt')) as f:\n    for line in tqdm(f):\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fae8e194ecd8439562406ed9e16f91ccda7d0ad8"},"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, embedding_size))\nfor word, i in tqdm(tok.word_index.items()):\n    if i >= vocab_size:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        # words not found in embedding index will be all-zeros.\n        embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd184ac5533245dce212081d2f155a4eb423f1b2"},"cell_type":"code","source":"X_train = tok.texts_to_sequences(df['Phrase'])\nX_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len, padding='post', truncating='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"205a9049c78f7a25aeb455434c285cf4cf7d24f6"},"cell_type":"code","source":"y_train = df['Sentiment']\ny_train = keras.utils.to_categorical(y_train, num_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c54c28a8b998cd6f0f8019cd188e1049a3719ce9"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68c7480633ab5c94572e46575d3e54bd7ca0ba30"},"cell_type":"code","source":"def create_trained_residual_model(lambda_reg = 0.01, regulariser_type = keras.regularizers.l2, weights_filename = \"gru.hd5\", cell_type = GRU, num_epochs=40):\n    regulariser = regulariser_type(lambda_reg)\n    input_layer = Input(shape=(max_len,))\n    save_cb = ModelCheckpoint(filepath=weights_filename,monitor='val_acc', save_best_only=True, save_weights_only=True)\n    embedding_layer = Embedding(vocab_size, embedding_size, weights=[embedding_matrix])(input_layer)\n\n    recurrent_layer_one = Bidirectional(cell_type(hidden_size, return_sequences=True, kernel_regularizer=regulariser))(embedding_layer)\n    recurrent_layer_two = Bidirectional(cell_type(hidden_size, return_sequences=True, kernel_regularizer=regulariser))(recurrent_layer_one)\n    merged_one = Add()([recurrent_layer_two, recurrent_layer_one]) # Residual link\n\n    recurrent_layer_three = Bidirectional(cell_type(hidden_size, return_sequences=True, kernel_regularizer=regulariser))(merged_one)\n    recurrent_layer_four = Bidirectional(cell_type(hidden_size, return_sequences=True, kernel_regularizer=regulariser))(recurrent_layer_three)\n    recurrent_layer_last = Add()([recurrent_layer_three, recurrent_layer_four]) # Residual link\n\n    flattened_layer = Reshape((-1,))(recurrent_layer_last)\n    output_layer = Dense(5, activation='softmax', kernel_regularizer=regulariser)(flattened_layer)\n    model = Model(input_layer, output_layer)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    model.summary()\n    model.fit(X_train, y_train, batch_size=512, epochs=num_epochs,validation_data=(X_val,y_val),callbacks=[save_cb])\n    model.load_weights('./' + weights_filename)\n    return model\n\n# Ignore this\n# def create_trained_simple_bidirectional_model(lambda_reg = 0.01, regulariser_type = keras.regularizers.l2, weights_filename = \"gru.hd5\", cell_type = GRU, num_epochs=40):\n#     regulariser = regulariser_type(lambda_reg)\n#     input_layer = Input(shape=(max_len,))\n#     save_cb = ModelCheckpoint(filepath=weights_filename,monitor='val_acc', save_best_only=True, save_weights_only=True)\n#     embedding_layer = Embedding(vocab_size, embedding_size, weights=[embedding_matrix])(input_layer)\n#     recurrent_layer = Bidirectional(cell_type(hidden_size, return_sequences=True, kernel_regularizer=regulariser))(embedding_layer)\n#     flattened_layer = Reshape((-1,))(recurrent_layer)\n#     output_layer = Dense(5, activation='softmax', kernel_regularizer=regulariser)(flattened_layer)\n#     model = Model(input_layer, output_layer)\n#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#     model.summary()\n#     model.fit(X_train, y_train, batch_size=512, epochs=num_epochs,validation_data=(X_val,y_val),callbacks=[save_cb])\n#     model.load_weights('./' + weights_filename)\n#     return model\n\n# def create_trained_simple_model(lambda_reg = 0.01, regulariser_type = keras.regularizers.l2, weights_filename = \"gru.hd5\", cell_type = GRU, num_epochs=40):\n#     regulariser = regulariser_type(lambda_reg)\n#     input_layer = Input(shape=(max_len,))\n#     save_cb = ModelCheckpoint(filepath=weights_filename,monitor='val_acc', save_best_only=True, save_weights_only=True)\n#     embedding_layer = Embedding(vocab_size, embedding_size, weights=[embedding_matrix])(input_layer)\n#     recurrent_layer = cell_type(hidden_size, kernel_regularizer=regulariser)(embedding_layer)\n#     output_layer = Dense(5, activation='softmax', kernel_regularizer=regulariser)(recurrent_layer)\n#     model = Model(input_layer, output_layer)\n#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#     model.summary()\n#     model.fit(X_train, y_train, batch_size=512, epochs=num_epochs,validation_data=(X_val,y_val),callbacks=[save_cb])\n#     model.load_weights('./' + weights_filename)\n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"723a7e440db830347071a2cad4ced895a8dea4d9"},"cell_type":"code","source":"# model_lstm = create_trained_simple_model(lambda_reg = 0.05, regulariser_type = keras.regularizers.l2, weights_filename = \"lstm.hd5\", cell_type = LSTM, num_epochs=30)\nmodel_gru = create_trained_residual_model(lambda_reg = 0.1, regulariser_type = keras.regularizers.l2, weights_filename = \"gru.hd5\", cell_type = CuDNNGRU, num_epochs=30)\n# model_bilstm = create_trained_simple_bidirectional_model(lambda_reg = 0.05, regulariser_type = keras.regularizers.l2, weights_filename = \"bilstm.hd5\", cell_type = LSTM, num_epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02684b3f96fa8084829781492bef9776e3619a36"},"cell_type":"code","source":"# y_pred = y_pred1 = model_lstm.predict(X_val)\n\n# y_pred1 = np.argmax(y_pred1, axis=1)\n# y_pred1 = to_categorical(y_pred1, num_classes=5)\n# print(\"LSTM accuracy: {}\".format(accuracy_score(y_pred1, y_val)))\n\n# y_pred2 = model_gru.predict(X_val)\n# y_pred += y_pred2\n# y_pred2 = np.argmax(y_pred2, axis=1)\n# y_pred2 = to_categorical(y_pred2, num_classes=5)\n# print(\"Residual BiGRU accuracy: {}\".format(accuracy_score(y_pred2, y_val)))\n\n# y_pred3 = model_bilstm.predict(X_val)\n# y_pred += y_pred3\n# y_pred3 = np.argmax(y_pred3, axis=1)\n# y_pred3 = to_categorical(y_pred3, num_classes=5)\n# print(\"BiLSTM accuracy: {}\".format(accuracy_score(y_pred3, y_val)))\n\n# y_pred = np.argmax(y_pred, axis=1)\n# y_pred = to_categorical(y_pred, num_classes=5)\n# print(\"Mixture accuracy: {}\".format(accuracy_score(y_pred, y_val)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bab4b71c99cdfcab356f8cfd774dc568fd677013"},"cell_type":"code","source":"df_test = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/test.tsv', delimiter='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b1a671cfaa6c30848a8d29df1775a4b61913eb3"},"cell_type":"code","source":"X_test = tok.texts_to_sequences(df_test['Phrase'])\nX_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len, padding='post', truncating='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3280e4beda6e8ee25350f9a1caa412aa13c5069"},"cell_type":"code","source":"# y_test  = model_lstm.predict(X_test)\ny_test = model_gru.predict(X_test)\n# y_test += model_bilstm.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df9d9f9ed71e581ac29aefb70cfb13788ede7e1"},"cell_type":"code","source":"y_test = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26dea0120f9094683dba730befad8e97d59c9cdd"},"cell_type":"code","source":"df_out = pd.DataFrame(data={'PhraseId':df_test['PhraseId'], 'Sentiment':y_test})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"870503676b1c09d73a507cec266a6ff90f95999a"},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}