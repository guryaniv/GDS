{"nbformat": 4, "cells": [{"outputs": [], "metadata": {"_kg_hide-input": true, "_kg_hide-output": true, "_uuid": "c6c2b20aee7eb5fcc40f065a8aaf490530cb3388", "_cell_guid": "1520ddda-0051-4873-b65c-657614ecb27b"}, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from math import sqrt\n", "from sklearn.metrics import mean_squared_error\n", "from matplotlib import pyplot\n", "\n", "# transform series into train and test sets for supervised learning\n", "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n", "    n_vars = 1 if type(data) is list else data.shape[1]\n", "    df = pd.DataFrame(data)\n", "    cols, names = list(), list()\n", "    # input sequence (t-n, ... t-1)\n", "    for i in range(n_in, 0, -1):\n", "        cols.append(df.shift(i))\n", "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n", "    # forecast sequence (t, t+1, ... t+n)\n", "    for i in range(0, n_out):\n", "        cols.append(df.shift(-i))\n", "        if i == 0:\n", "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n", "        else:\n", "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n", "    # put it all together\n", "    agg = pd.concat(cols, axis=1)\n", "    agg.columns = names\n", "    # drop rows with NaN values\n", "    if dropnan:\n", "        agg.dropna(inplace=True)\n", "    return agg\n", "    \n", "\n", "def prepare_data(series, n_test, n_lag, n_seq):\n", "    # extract raw values\n", "    raw_values = series.values\n", "    raw_values = raw_values.reshape(len(raw_values), 1)\n", "    # transform into supervised learning problem X, y\n", "    supervised = series_to_supervised(raw_values, n_lag, n_seq)\n", "    supervised_values = supervised.values\n", "    # split into train and test sets\n", "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n", "    return train, test\n", "\n", "\n", "# make a persistence forecast\n", "def persistence(last_ob, n_seq):\n", "    return [last_ob for i in range(n_seq)]\n", "\n", "\n", "# evaluate the persistence model\n", "def make_forecasts(test, n_lag, n_seq):\n", "    \"\"\"\n", "    Takes the last observation and the number of forecast steps to persist and takes the train, test, and \n", "    configuration for the dataset as arguments and returns a list of forecasts.\n", "    \"\"\"    \n", "    forecasts = []\n", "    for i in range(len(test)):\n", "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n", "        # make forecast\n", "        forecast = persistence(X[-1], n_seq)\n", "        # store the forecast\n", "        forecasts.append(forecast)\n", "    return forecasts\n", "\n", "\n", "# evaluate the RMSE for each forecast time step\n", "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n", "    for i in range(n_seq):\n", "        actual = test[:, (n_lag+i)]\n", "        predicted = [forecast[i] for forecast in forecasts]\n", "        rmse = sqrt(mean_squared_error(actual, predicted))\n", "        print('t+%d RMSE: %f' % ((i+1), rmse))\n", "\n", "\n", "# plot the forecasts in the context of the original dataset\n", "def plot_forecasts(series, forecasts, n_test):\n", "    # plot the entire dataset in blue\n", "    pyplot.plot(series.values)\n", "    # plot the forecasts in red\n", "    for i in range(len(forecasts)):\n", "        off_s = len(series) - n_test + i - 1\n", "        off_e = off_s + len(forecasts[i]) + 1\n", "        xaxis = [x for x in range(off_s, off_e)]\n", "        yaxis = [series.values[off_s]] + forecasts[i]\n", "        pyplot.plot(xaxis, yaxis, color='red')\n", "    # show the plot\n", "    pyplot.show()\n", "\n", "# Any results you write to the current directory are saved as output.\n", "dtypes = {'store_nbr': np.dtype('int64'),\n", "          'item_nbr': np.dtype('int64'),\n", "          'unit_sales': np.dtype('float64'),\n", "          'onpromotion': np.dtype('O')}\n", "\n", "df = pd.read_csv('../input/train.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\n", "# If done on all train data, results in 367m rows. So, we're taking a small sample:\n", "item_mask = (df['item_nbr'] == 103665) & (df['store_nbr'] == 9)\n", "print(df.shape)\n", "df = df[item_mask]\n", "print(df.shape)\n", "\n", "from IPython.display import display, HTML\n", "display(HTML('<h1>Persistence Forecast</h1>'))\n", "display(HTML('Simple item-store combination for univariate persistence forecast. This could be used as a baseline level of performance when comparing with more sophisticated models'))\n", "\n", "\"\"\"\n", "Code adapted from https://machinelearningmastery.com/ examples.\n", "\"\"\"\n", "sample = pd.concat([df['unit_sales']], axis=1)\n", "# configure\n", "n_lag = 1\n", "n_seq = 17\n", "n_test = 16\n", "train, test = prepare_data(sample, n_test, n_lag, n_seq)\n", "print('Train: %s, Test: %s' % (train.shape, test.shape))\n", "forecasts = make_forecasts(test, n_lag, n_seq)\n", "evaluate_forecasts(test, forecasts, n_lag, n_seq)\n", "# plot forecasts\n", "plot_forecasts(sample, forecasts, n_test+2)"], "execution_count": 1}], "nbformat_minor": 1, "metadata": {"language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}