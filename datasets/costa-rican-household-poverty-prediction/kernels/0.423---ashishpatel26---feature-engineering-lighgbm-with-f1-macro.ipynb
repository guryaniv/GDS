{"cells":[{"metadata":{"_uuid":"0479e25c001874fda15f875d76f8663885caa138"},"cell_type":"markdown","source":"# Do feature engineering to improve LightGBM prediction\nThis kernel closely follows https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro, but instead of running hyperparameter optimisation it uses optimal values from that kernel and thus runs faster. \n\nSeveral key points:\n- **This kernel runs training on the heads of housholds only** (after extracting aggregates over households). This follows the announced scoring startegy: *Note that ONLY the heads of household are used in scoring. All household members are included in test + the sample submission, but only heads of households are scored.* (from the data description). However, at the moment it seems that evaluation depends also on non-head household members, see https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115. In practise, ful prediction gives ~0.4 PLB score, while replacing all non-head entries with class 1 leads to a drop down to ~0.2 PLB score\n- **It seems to be very important to balance class frequencies.** Without balancing a trained model gives ~0.39 PLB / ~0.43 local test, while adding balancing leads to ~0.42 PLB / 0.47 local test. One can do it by hand, one can achieve it by undersampling. But the simplest (and more powerful compared to undersampling) is to set `class_weight='balanced'` in the LightGBM model constructor in sklearn API.\n- **This kernel uses macro F1 score to early stopping in training**. This is done to align with the scoring strategy.\n- Categoricals are turned into numbers with proper mapping instead of blind label encoding. \n- **OHE if reversed into label encoding, as it is easier to digest for a tree model.** This trick would be harmful for non-tree models, so be careful.\n- **idhogar is NOT used in training**. The only way it could have any info would be if there is a data leak. We are fighting with poverty here- exploiting leaks will not reduce poverty in any way :)\n- **Squared features (`SQBXXX` and `agesq`) are NOT used in training**. These would be useful for a linear model, but are useless for a tree-based model and only confused it (when bagging and resampling is done)\n- **There are aggregations done within households and new features are hand-crafted**. Note, that there are not so many features that can be aggregated, as most are already quoted on household level.\n- **A voting classifier is used to average over several LightGBM models**\n\nThe main goal is to do feature engineering"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e4e08a17549fd247619178c96c3ade2519e9773"},"cell_type":"markdown","source":"The following categorical mapping originates from [this kernel](https://www.kaggle.com/mlisovyi/categorical-variables-encoding-function)."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\ndef encode_data(df):\n    '''\n    The function does not return, but transforms the input pd.DataFrame\n    \n    Encodes the Costa Rican Household Poverty Level data \n    following studies in https://www.kaggle.com/mlisovyi/categorical-variables-in-the-data\n    and the insight from https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#359631\n    \n    The following columns get transformed: edjefe, edjefa, dependency, idhogar\n    The user most likely will simply drop idhogar completely (after calculating houshold-level aggregates)\n    '''\n    \n    yes_no_map = {'no': 0, 'yes': 1}\n    \n    df['dependency'] = df['dependency'].replace(yes_no_map).astype(np.float32)\n    \n    df['edjefe'] = df['edjefe'].replace(yes_no_map).astype(np.float32)\n    df['edjefa'] = df['edjefa'].replace(yes_no_map).astype(np.float32)\n    \n    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1785c8ca3467a7e95d007a2c5f36e39919fc0910"},"cell_type":"markdown","source":"**There is also feature engineering magic happening here:**"},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"9c9f13e54fc2af9f938b895959631e1aeb3b08a2"},"cell_type":"code","source":"def do_features(df):\n    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n                 ('working_man_fraction', 'r4h2', 'r4t3'),\n                 ('all_man_fraction', 'r4h3', 'r4t3'),\n                 ('human_density', 'tamviv', 'rooms'),\n                 ('human_bed_density', 'tamviv', 'bedrooms'),\n                 ('rent_per_person', 'v2a1', 'r4t3'),\n                 ('rent_per_room', 'v2a1', 'rooms'),\n                 ('mobile_density', 'qmobilephone', 'r4t3'),\n                 ('tablet_density', 'v18q1', 'r4t3'),\n                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n#                 ('male_over_female', 'r4h3', 'r4m3'),\n#                 ('man12plus_over_women12plus', 'r4h2', 'r4m2'),\n#                 ('pesioner_over_working', 'hogar_mayor', 'hogar_adul'),\n#                 ('children_over_working', 'hogar_nin', 'hogar_adul')\n                 #('', '', ''),\n                ]\n    \n    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n                 ('people_weird_stat', 'tamhog', 'r4t3')]\n\n    for f_new, f1, f2 in feats_div:\n        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n    for f_new, f1, f2 in feats_sub:\n        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n    \n    # aggregation rules over household\n    aggs_num = {'age': ['min', 'max', 'mean', 'count'],\n                'escolari': ['min', 'max', 'mean', 'std']\n               }\n    aggs_cat = {'dis': ['mean']}\n    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n            aggs_cat[f_] = ['mean']\n    # aggregation over household\n    for name_, df_ in [('18', df.query('age >= 18'))]:\n        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n        df = df.join(df_agg, how='left', on='idhogar')\n        del df_agg\n    # do something advanced above...\n    \n    # Drop SQB variables, as they are just squres of other vars \n    df.drop([f_ for f_ in df.columns if f_.startswith('SQB') or f_ == 'agesq'], axis=1, inplace=True)\n    # Drop id's\n    df.drop(['Id'], axis=1, inplace=True)\n    # Drop repeated columns\n    df.drop(['hhsize', 'female', 'area2'], axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"a7df32a07c9157ee02ff9688cdc70c69e7571aae"},"cell_type":"code","source":"def convert_OHE2LE(df):\n    tmp_df = df.copy(deep=True)\n    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n               'instlevel', 'lugar', 'tipovivi',\n               'manual_elec']:\n        if 'manual_' not in s_:\n            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n        elif 'elec' in s_:\n            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n        #deal with those OHE, where there is a sum over columns == 0\n        if 0 in sum_ohe:\n            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n                  .format(s_))\n            # dummy colmn name to be added\n            col_dummy = s_+'_dummy'\n            # add the column to the dataframe\n            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n            # add the name to the list of columns to be label-encoded\n            cols_s_.append(col_dummy)\n            # proof-check, that now the category is complete\n            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n            if 0 in sum_ohe:\n                 print(\"The category completion did not work\")\n        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n        if 'parentesco1' in cols_s_:\n            cols_s_.remove('parentesco1')\n        tmp_df.drop(cols_s_, axis=1, inplace=True)\n    return tmp_df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eab84429fc9893c82e33b8319161c190b4104e9f"},"cell_type":"markdown","source":"# Read in the data and clean it up"},{"metadata":{"trusted":true,"_uuid":"e6f696a1677230c565532f141a02852e7c69b2e1","collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd1f66cbdbfa4741d19a8b1f53793b967d62d281","collapsed":true},"cell_type":"code","source":"def process_df(df_):\n    # fix categorical features\n    encode_data(df_)\n    #fill in missing values based on https://www.kaggle.com/mlisovyi/missing-values-in-the-data\n    for f_ in ['v2a1', 'v18q1', 'meaneduc', 'SQBmeaned']:\n        df_[f_] = df_[f_].fillna(0)\n    df_['rez_esc'] = df_['rez_esc'].fillna(-1)\n    # do feature engineering and drop useless columns\n    return do_features(df_)\n\ntrain = process_df(train)\ntest = process_df(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65dab0e9a94e8f87a7b73e7ec2c6559e4ccef996","scrolled":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"809763b29c54f5a15da2c5670407eaf95c62cfc2"},"cell_type":"markdown","source":"Define `train_test_apply_func` helper function to apply a custom function to a concatenated test+train dataset"},{"metadata":{"trusted":true,"_uuid":"b564a6552f0521581af1ee38d6040ef7ae5d2fb5","collapsed":true,"_kg_hide-input":true},"cell_type":"code","source":"def train_test_apply_func(train_, test_, func_):\n    test_['Target'] = 0\n    xx = pd.concat([train_, test_])\n\n    xx_func = func_(xx)\n    train_ = xx_func.iloc[:train_.shape[0], :]\n    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n\n    del xx, xx_func\n    return train_, test_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2695108e103c9c61088fc4c100d01bc8c0f4138c"},"cell_type":"code","source":"train, test = train_test_apply_func(train, test, convert_OHE2LE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2acd39c04f144669e58a0b9e1129a20e664137c9"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e90e68abd266c9db808dbf336308cef7175886bd"},"cell_type":"markdown","source":"# Geo aggregates"},{"metadata":{"trusted":true,"_uuid":"0ffc288b3829ffdb1dabf8f2e7fe518f2f520480","collapsed":true},"cell_type":"code","source":"cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n              'pared_LE']\ncols_nums = ['age', 'meaneduc', 'dependency', \n             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n             'bedrooms', 'overcrowding']\n\ndef convert_geo2aggs(df_):\n    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n                        pd.get_dummies(df_[cols_2_ohe], \n                                       columns=cols_2_ohe)],axis=1)\n    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n    geo_agg.columns = pd.Index(['geo_' + e + '_MEAN' for e in geo_agg.columns.tolist()])\n    \n    del tmp_df\n    return df_.join(geo_agg, how='left', on='lugar_LE')\n\ntrain, test = train_test_apply_func(train, test, convert_geo2aggs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc96d527090d9b0723049c5d763c97be5145b8c7"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9858e0b145850825a201df702ffd1eddc4ff6eba"},"cell_type":"markdown","source":"# VERY IMPORTANT\n> Note that ONLY the heads of household are used in scoring. All household members are included in test + the sample submission, but only heads of households are scored."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"96e8311b0d5cdddcf98b03d47d5e4793f0b79f03"},"cell_type":"code","source":"X = train.query('parentesco1==1')\n#X = train\n\n# pull out the target variable\ny = X['Target'] - 1\nX = X.drop(['Target'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5eaa7e4a95326459a7f2aeb24949e45cb237a9a4","collapsed":true},"cell_type":"code","source":"cols_2_drop = ['abastagua_LE', 'agg18_estadocivil1_MEAN', 'agg18_instlevel6_MEAN', 'agg18_parentesco10_MEAN', 'agg18_parentesco11_MEAN', 'agg18_parentesco12_MEAN', 'agg18_parentesco4_MEAN', 'agg18_parentesco5_MEAN', 'agg18_parentesco6_MEAN', 'agg18_parentesco7_MEAN', 'agg18_parentesco8_MEAN', 'agg18_parentesco9_MEAN', 'fe_people_not_living', 'fe_people_weird_stat', 'geo_elimbasu_LE_3_MEAN', 'geo_elimbasu_LE_4_MEAN', 'geo_energcocinar_LE_0_MEAN', 'geo_energcocinar_LE_1_MEAN', 'geo_energcocinar_LE_2_MEAN', 'geo_epared_LE_0_MEAN', 'geo_epared_LE_2_MEAN', 'geo_etecho_LE_2_MEAN', 'geo_eviv_LE_0_MEAN', 'geo_hogar_mayor_MEAN', 'geo_hogar_nin_MEAN', 'geo_manual_elec_LE_1_MEAN', 'geo_manual_elec_LE_2_MEAN', 'geo_manual_elec_LE_3_MEAN', 'geo_pared_LE_0_MEAN', 'geo_pared_LE_1_MEAN', 'geo_pared_LE_3_MEAN', 'geo_pared_LE_4_MEAN', 'geo_pared_LE_5_MEAN', 'geo_pared_LE_6_MEAN', 'geo_pared_LE_7_MEAN', 'hacapo', 'hacdor', 'mobilephone', 'parentesco1', 'parentesco_LE', 'rez_esc', 'techo_LE', 'v14a', 'v18q']\n#cols_2_drop = ['agg18_estadocivil1_MEAN', 'agg18_parentesco10_MEAN', 'agg18_parentesco11_MEAN', 'agg18_parentesco12_MEAN', 'agg18_parentesco4_MEAN', 'agg18_parentesco6_MEAN', 'agg18_parentesco7_MEAN', 'agg18_parentesco8_MEAN', 'fe_people_weird_stat', 'hacapo', 'hacdor', 'mobilephone', 'parentesco1', 'parentesco_LE', 'rez_esc', 'v14a']\n#cols_2_drop=[]\n\nX.drop((cols_2_drop+['idhogar']), axis=1, inplace=True)\ntest.drop((cols_2_drop+['idhogar']), axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6fce8205f4e5ae78a43eef4f0fd3cead5a3cb04"},"cell_type":"markdown","source":"## Let's look on the most correlated with `Target` features"},{"metadata":{"trusted":true,"_uuid":"a989b88c7ab448734be8dd3808281c879a3da867","collapsed":true},"cell_type":"code","source":"XY = pd.concat([X,y], axis=1)\nmax_corr = XY.corr()['Target'].loc[lambda x: abs(x)>0.2].index\n#min_corr = XY.corr()['Target'].loc[lambda x: abs(x)<0.05].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e601a2ab2ed12ab539cfc48b41c135c3d5ac12b"},"cell_type":"code","source":"_ = plt.figure(figsize=(10,7))\n_ = sns.heatmap(XY[max_corr].corr(), vmin=-0.5, vmax=0.5, cmap='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6e1ccce811e7a1d76282fcb8a13edf92672f834"},"cell_type":"markdown","source":"# Model fitting with HyperParameter optimisation\n\nWe will use LightGBM classifier - LightGBM allows to build very sophysticated models with a very short training time."},{"metadata":{"trusted":true,"_uuid":"ae8c1b6d6f95654ab6f0ba36238886969a556a2e","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=314, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b18d9eb9e4b7429d53b7151976ee93d171ff6c3"},"cell_type":"code","source":"X_test.info(max_cols=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5afc6fbb6ed16a47c0700e7ffc1d26cb2e28e778"},"cell_type":"markdown","source":"## Use test subset for early stopping criterion\n\nThis allows us to avoid overtraining and we do not need to optimise the number of trees. We also use F1 macro-averaged score to decide when to stop\n"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"76956b6fa33cc0dcedc3602f34c4be96f6558778","_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\ndef evaluate_macroF1_lgb(truth, predictions):  \n    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n    f1 = f1_score(truth, pred_labels, average='macro')\n    return ('macroF1', f1, True) \n\ndef learning_rate_power_0997(current_iter):\n    base_learning_rate = 0.1\n    min_learning_rate = 0.02\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return max(lr, min_learning_rate)\n\nimport lightgbm as lgb\nfit_params={\"early_stopping_rounds\":300, \n            \"eval_metric\" : evaluate_macroF1_lgb, \n            #\"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n            'eval_names': ['train', 'valid'],\n            'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_power_0997)],\n            'verbose': False,\n            'categorical_feature': 'auto'}\n\nfit_params['verbose'] = 200","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"effe8ad863afc3f72e16ca3423588cfddd13408f"},"cell_type":"markdown","source":"# LightGBM optimal parameters\n\nThe parameters are optimised with a random search in this kernel: https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro\n"},{"metadata":{"trusted":true,"_uuid":"1e736fb9b69fe3955b8a1226c14b9707fab522a6","collapsed":true},"cell_type":"code","source":"# %%time\n# from bayes_opt import BayesianOptimization\n# import lightgbm as lgb\n\n\n# def bayes_parameter_opt_lgb(X, y, init_round=15, opt_roun=25, n_folds=7, random_seed=42, n_estimators=10000, learning_rate=0.02, output_process=False,colsample_bytree=0.93,min_child_samples=56,subsample=0.84):\n#     # prepare data\n#     train_data = lgb.Dataset(data=X, label=y)\n#     # parameters\n#     def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight, colsample_bytree,min_child_samples,subsample):\n#         params = {'application':'multiclass','num_iterations': n_estimators, 'learning_rate':learning_rate, 'early_stopping_round':300, 'metric':'macroF1'}\n#         params[\"num_leaves\"] = int(round(num_leaves))\n#         params[\"num_class\"] = 4\n#         params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n#         params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n#         params['max_depth'] = int(round(max_depth))\n#         params['lambda_l1'] = max(lambda_l1, 0)\n#         params['lambda_l2'] = max(lambda_l2, 0)\n#         params['min_split_gain'] = min_split_gain\n#         params['min_child_weight'] = min_child_weight\n#         params['colsample_bytree'] = 1\n#         params['min_child_samples'] = 90,\n#         params['subsample'] = 0.96\n#         cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n#         return max(cv_result['auc-mean'])\n#     # range \n#     lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (19, 45),\n#                                             'feature_fraction': (0.1, 0.9),\n#                                             'bagging_fraction': (0.8, 1),\n#                                             'max_depth': (5, 8.99),\n#                                             'lambda_l1': (0, 5),\n#                                             'lambda_l2': (0, 3),\n#                                             'min_split_gain': (0.001, 0.1),\n#                                             'min_child_weight': (5, 50),\n#                                             'colsample_bytree' : (0.7,1.0),\n#                                             'min_child_samples' : (40,65),\n#                                             'subsample' : (0.7,1.0)\n#                                            }, random_state=0)\n#     # optimize\n#     lgbBO.maximize(init_points=init_round, n_iter=opt_roun)\n    \n#     # output optimization process\n#     if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n    \n#     # return best parameters\n#     return lgbBO.res['max']['max_params']\n\n# opt_params = bayes_parameter_opt_lgb(X_train, y_train, init_round=10, opt_roun=10, n_folds=6, random_seed=42, n_estimators=500, learning_rate=0.02,colsample_bytree=0.93)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"589578d972c14fdfa3a2c857b1b8909187d5b97b"},"cell_type":"code","source":"opt_params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"22b494fee8b8880e56ce049631d7f161caef0554"},"cell_type":"code","source":"#v8\n#opt_parameters = {'colsample_bytree': 0.93, 'min_child_samples': 56, 'num_leaves': 19, 'subsample': 0.84}\n#v9\n#opt_parameters = {'colsample_bytree': 0.89, 'min_child_samples': 70, 'num_leaves': 17, 'subsample': 0.96}\n#v14\n#opt_parameters = {'colsample_bytree': 0.88, 'min_child_samples': 90, 'num_leaves': 16, 'subsample': 0.94}\n#v17\n# opt_parameters = {'colsample_bytree': 0.89, 'min_child_samples': 90, 'num_leaves': 14, 'subsample': 0.96}\n\nopt_parameters = {\n                'bagging_fraction': 1.0,\n                 'colsample_bytree': 0.75,\n                 'feature_fraction': 0.1,\n                 'lambda_l1': 5.0,\n                 'lambda_l2': 3.0,\n                 'max_depth': 5,\n                 'min_child_samples': 90,\n                 'min_child_weight': 5.0,\n                 'min_split_gain': 0.001,\n                 'num_leaves': 19,\n                 'subsample': 0.7,\n                'min_sum_hessian_in_leaf': 1,\n                'importance_type': 'gain'\n                }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2dc384aeb44db2454978df78fdbb84b2b1ff3ced"},"cell_type":"markdown","source":"# Fit a voting classifier\nDefine a derived VotingClassifier class to be able to pass `fit_params` for early stopping. Vote based on LGBM models with early stopping based on macro F1 and decaying learning rate"},{"metadata":{"trusted":true,"_uuid":"101a2fd45bbbe6c7fb351513803550d4edeef2b3","_kg_hide-input":true,"collapsed":true},"cell_type":"code","source":"from sklearn.externals.joblib import Parallel, delayed\nfrom sklearn.base import clone\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\n#from sklearn.ensemble.voting_classifier import _parallel_fit_estimator\n\ndef _parallel_fit_estimator(estimator, X, y, sample_weight=None, **fit_params):\n    \"\"\"Private function used to fit an estimator within a job.\"\"\"\n    if sample_weight is not None:\n        estimator.fit(X, y, sample_weight=sample_weight, **fit_params)\n    else:\n        estimator.fit(X, y, **fit_params)\n    return estimator\n\nclass VotingClassifierLGBM(VotingClassifier):\n    '''\n    This implements the fit method of the VotingClassifier propagating fit_params\n    '''\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n            raise NotImplementedError('Multilabel and multi-output'\n                                      ' classification is not supported.')\n\n        if self.voting not in ('soft', 'hard'):\n            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n                             % self.voting)\n\n        if self.estimators is None or len(self.estimators) == 0:\n            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n                                 ' should be a list of (string, estimator)'\n                                 ' tuples')\n\n        if (self.weights is not None and\n                len(self.weights) != len(self.estimators)):\n            raise ValueError('Number of classifiers and weights must be equal'\n                             '; got %d weights, %d estimators'\n                             % (len(self.weights), len(self.estimators)))\n\n        if sample_weight is not None:\n            for name, step in self.estimators:\n                if not has_fit_parameter(step, 'sample_weight'):\n                    raise ValueError('Underlying estimator \\'%s\\' does not'\n                                     ' support sample weights.' % name)\n        names, clfs = zip(*self.estimators)\n        self._validate_names(names)\n\n        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n        if n_isnone == len(self.estimators):\n            raise ValueError('All estimators are None. At least one is '\n                             'required to be a classifier!')\n\n        self.le_ = LabelEncoder().fit(y)\n        self.classes_ = self.le_.classes_\n        self.estimators_ = []\n\n        transformed_y = self.le_.transform(y)\n\n        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n                                                 sample_weight=sample_weight, **fit_params)\n                for clf in clfs if clf is not None)\n\n        return self","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"collapsed":true,"_uuid":"a824458abfb9f32931425d4cbe503c670dff78f6"},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder\n\nclass VotingPrefitClassifier(VotingClassifier):\n    '''\n    This implements the VotingClassifier with prefitted classifiers\n    '''\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        self.estimators_ = [x[1] for x in self.estimators]\n        self.le_ = LabelEncoder().fit(y)\n        self.classes_ = self.le_.classes_\n        \n        return self\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37b909c2aa273651b7bb57c69b939760f14f38f7","scrolled":true,"collapsed":true},"cell_type":"code","source":"#clfs = []\n#for i in range(3):\n#    clf = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n#                             random_state=314+i, silent=True, metric='None', \n#                             n_jobs=4, n_estimators=5000, class_weight='balanced')\n#    clf.set_params(**opt_parameters)\n#    clfs.append(('lgbm{}'.format(i), clf))\n    \n#vc = VotingClassifierLGBM(clfs, voting='soft')\n#del clfs\n##Train the final model with learning rate decay\n#_ = vc.fit(X_train, y_train, **fit_params)\n#\n#clf_final = vc.estimators_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61bd19ba9f1219a29b7ef412120ec92c070fc35c","scrolled":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ndef train_lgbm_model(X_, y_, random_state_=None, opt_parameters_={}, fit_params_={}):\n    clf  = lgb.LGBMClassifier(max_depth=-1, learning_rate=0.1, objective='multiclass',\n                             random_state=random_state_, silent=True, metric='None', \n                             n_jobs=4, n_estimators=5000, class_weight='balanced')\n    clf.set_params(**opt_parameters_)\n    return clf.fit(X_, y_, **fit_params_)\n\n# the list of classifiers for voting ensable\nclfs = []\n\n# nested CV parameters\ninner_seed = 31416\ninner_n = 10\nouter_seed = 314\nouter_n = 10\n\n# performance \nperf_eval = {'f1_oof': [],\n             'f1_ave': [],\n             'f1_std': []}\n\nouter_cv = StratifiedKFold(outer_n, shuffle=True, random_state=outer_seed)\nfor n_outer_fold, (outer_trn_idx, outer_val_idx) in enumerate(outer_cv.split(X,y)):\n    print('--- Outer loop iteration: {} ---'.format(n_outer_fold))\n    X_out, y_out = X.iloc[outer_trn_idx], y.iloc[outer_trn_idx]\n    X_stp, y_stp = X.iloc[outer_val_idx], y.iloc[outer_val_idx]\n    \n    inner_cv = StratifiedKFold(inner_n, shuffle=True, random_state=inner_seed+n_outer_fold)\n    \n    y_oof = pd.Series(np.zeros(shape=(X_out.shape[0],)), \n                      index=X_out.index)\n    f1_scores_inner = []\n    \n    for n_inner_fold, (inner_trn_idx, inner_val_idx) in enumerate(inner_cv.split(X_out,y_out)):\n        X_trn, y_trn = X_out.iloc[inner_trn_idx], y_out.iloc[inner_trn_idx]\n        X_val, y_val = X_out.iloc[inner_val_idx], y_out.iloc[inner_val_idx]\n        \n        # use _stp data for early stopping\n        fit_params[\"eval_set\"] = [(X_trn,y_trn), (X_stp,y_stp)]\n        \n        clf = train_lgbm_model(X_trn, y_trn, 314+n_inner_fold, opt_parameters, fit_params)\n        \n        # evaluate performance\n        y_oof.iloc[inner_val_idx] = clf.predict(X_val)        \n        f1_scores_inner.append(f1_score(y_val, y_oof.iloc[inner_val_idx], average='macro'))\n        #cleanup\n        del clf, X_trn, y_trn, X_val, y_val\n    # Store performance info for theis outer fold\n    perf_eval['f1_oof'].append(f1_score(y_out, y_oof, average='macro'))\n    perf_eval['f1_ave'].append(np.array(f1_scores_inner).mean())\n    perf_eval['f1_std'].append(np.array(f1_scores_inner).std())\n    # Train main model for the voting average\n    fit_params[\"eval_set\"] = [(X_out,y_out), (X_stp,y_stp)]\n    print('Fit the final model on the outer loop iteration: ')\n    clf = train_lgbm_model(X_out, y_out, 314+n_outer_fold, opt_parameters, fit_params)\n    clfs.append(('lgbm{}'.format(n_outer_fold), clf))\n    # cleanup\n    del inner_cv, X_out, y_out, X_stp, y_stp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"204a710ba8475b05516562d2e5aaadb19c7b9dd2"},"cell_type":"code","source":"vc = VotingPrefitClassifier(clfs)\nvc = vc.fit(X,y)\nclf_final = vc.estimators_[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"241d2973497b8eb2e5214f5c8ddb76432576ba35"},"cell_type":"code","source":"global_score = np.mean(perf_eval['f1_oof'])\nglobal_score_std = np.std(perf_eval['f1_oof'])\n#vc.voting = 'soft'\n#global_score_soft = f1_score(y, vc.predict(X), average='macro')\n#vc.voting = 'hard'\n#global_score_hard = f1_score(y, vc.predict(X), average='macro')\n\nprint('Mean validation score LGBM Classifier: {:.4f}'.format(global_score))\nprint('Std  validation score LGBM Classifier: {:.4f}'.format(global_score_std))\n#print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n#print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"681d9bbe0fa31d443feefb52ee698975bce21e2f","collapsed":true},"cell_type":"markdown","source":"# F1 score across different classes\nLet's see if all classes show similar performance"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ee52eca29b70e164b286b512d940bcdcfebf870d"},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, classification_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a71386355812dd97c74737afc7bf01b94239346e","collapsed":true},"cell_type":"code","source":"# print(classification_report(y_test, clf_final.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8931a5c627a25c898f223302c50b808c10075f2f","collapsed":true},"cell_type":"code","source":"#vc.voting = 'hard'\n#print(classification_report(y_test, vc.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb4cd9c26c61dc03af31b8b62283780b3e3cc2f8","collapsed":true},"cell_type":"code","source":"#vc.voting = 'soft'\n#print(classification_report(y_test, vc.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d8f28cae4872d101a3001be9d55694572e5a3cff"},"cell_type":"markdown","source":"# Plot feature importances (using gain)\nSee if added features show among most significant ones"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0791014366ac43e87e4ab9c64872cf3014750f2a"},"cell_type":"code","source":"def display_importances(feature_importance_df_, doWorst=False, n_feat=50):\n    # Plot feature importances\n    if not doWorst:\n        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n            by=\"importance\", ascending=False)[:n_feat].index        \n    else:\n        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n            by=\"importance\", ascending=False)[-n_feat:].index\n    \n    mean_imp = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean()\n    df_2_neglect = mean_imp[mean_imp['importance'] < 1e-3]\n    print('The list of features with 0 importance: ')\n    print(df_2_neglect.index.values.tolist())\n    del mean_imp, df_2_neglect\n    \n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    \n    plt.figure(figsize=(8,10))\n    sns.barplot(x=\"importance\", y=\"feature\", \n                data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features')\n    plt.tight_layout()\n    #plt.savefig('lgbm_importances.png')\n    \nimportance_df = pd.DataFrame()\nimportance_df[\"feature\"] = X.columns.tolist()      \nimportance_df[\"importance\"] = clf_final.booster_.feature_importance('gain')\ndisplay_importances(feature_importance_df_=importance_df, n_feat=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ceea94109ec056012831a46ebcacbb13020eb1f","collapsed":true},"cell_type":"code","source":"#display_importances(feature_importance_df_=importance_df, doWorst=True, n_feat=20)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9eaa5a0b2e0778d84f0f97784ae66132bb56b2b4"},"cell_type":"markdown","source":"# Plot feature importances (using SHAP)\nSee if added features show among most significant ones"},{"metadata":{"trusted":true,"_uuid":"af33296cf242c8363aa8a68561f195e7bfbe1a92","collapsed":true},"cell_type":"code","source":"# import shap\n# shap_values = shap.TreeExplainer(clf_final.booster_).shap_values(X)\n\n# #shap_df = pd.DataFrame()\n# #shap_df[\"feature\"] = X_train.columns.tolist()    \n# #shap_df[\"importance\"] = np.sum(np.abs(shap_values), 0)[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ad7ab722c1e7f70fd7d0f1eb4d8e11e9cbd1d66c"},"cell_type":"code","source":"#display_importances(feature_importance_df_=shap_df, n_feat=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4a8e46106e456f6b0c1b7aed6a57e05fdd0095a","collapsed":true},"cell_type":"code","source":"# shap.summary_plot(shap_values, X, plot_type='bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78749eec7f69bcc8c587278a2c1a43ac8b5832e3"},"cell_type":"markdown","source":"# Prepare submission"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"32bfd69fe130005cb88865399c460ac00c7b1574"},"cell_type":"code","source":"y_subm = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"718054937aa849c23ca7c65483f8a52de6f6fd49","collapsed":true},"cell_type":"code","source":"y_subm['Target'] = clf_final.predict(test) + 1\n\nvc.voting = 'soft'\ny_subm_soft = y_subm.copy(deep=True)\ny_subm_soft['Target'] = vc.predict(test) + 1\n\nvc.voting = 'hard'\ny_subm_hard = y_subm.copy(deep=True)\ny_subm_hard['Target'] = vc.predict(test) + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72861add35e69f3734740739ead51ec4ff99f13b","collapsed":true},"cell_type":"code","source":"# nor needed anymore\n#y_subm_0forNonHeads = y_subm.copy(deep=True)\n#y_subm_0forNonHeads.loc[y_subm_0forNonHeads[test['parentesco1'] == 0].index,'Target'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8258f28127f235e427a25f6824566a23df61b8af","collapsed":true},"cell_type":"code","source":"from datetime import datetime\nnow = datetime.now()\n\nsub_file = 'submission_LGB_{:.4f}_{}.csv'.format(global_score, str(now.strftime('%Y-%m-%d-%H-%M')))\nsub_file_soft = 'submission_soft_LGB_{:.4f}_{}.csv'.format(global_score, str(now.strftime('%Y-%m-%d-%H-%M')))\nsub_file_hard = 'submission_hard_LGB_{:.4f}_{}.csv'.format(global_score, str(now.strftime('%Y-%m-%d-%H-%M')))\nsub_file_0forNonHeads = 'submission_0forNonHead_LGB_{:.4f}_{}.csv'.format(global_score, str(now.strftime('%Y-%m-%d-%H-%M')))\n\ny_subm.to_csv(sub_file, index=False)\ny_subm_soft.to_csv(sub_file_soft, index=False)\ny_subm_hard.to_csv(sub_file_hard, index=False)\n# not needed anymore\n#y_subm_0forNonHeads.to_csv(sub_file_0forNonHeads, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d5a6d1245cb2a2c28d9ffbd16aa93a9be11541e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}