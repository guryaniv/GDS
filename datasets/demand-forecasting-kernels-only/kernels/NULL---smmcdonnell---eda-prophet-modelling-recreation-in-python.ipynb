{"cells":[{"metadata":{"_uuid":"ec6215aa3c75a7d1354f1866c25add6373da4096"},"cell_type":"markdown","source":"# 1. Load Libraries"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"01c3f313a1a45cd4cfd8efca2a18865e854452ba"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom fbprophet import Prophet\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce8185ae188754052b8ff987ad45760773e2f442"},"cell_type":"markdown","source":"In this kernel I recreate the \"EDA+Prophet+ MLP Neural Network Forecasting\" kernel by Arindam Dutta, found here: https://www.kaggle.com/arindamgot/eda-prophet-mlp-neural-network-forecasting/notebook. Arindam did a great analysis in R, so I thought I'd recreate his work in Python. Hopefully this is helpful for someone! \n\nPlease note that this is a translation of a kernel from R to Python. The workflow was all devised by Arindam Dutta, who should receive full credit for any and all insight. I will be following their notebook workflow and section numbering.\n\n# 2. Load Data, Summary"},{"metadata":{"trusted":true,"_uuid":"3ad451d175144db53a4c769bfddd20e29f8707df"},"cell_type":"code","source":"path = \"../input/train.csv\"\ntrain = pd.read_csv(path)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2a587e3d301784527c6abd59fd273f03a56a347"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf52d90f82c0c6299722b68c5667e599846b3452"},"cell_type":"code","source":"train[\"year\"] = pd.to_datetime(train[\"date\"]).dt.year\ntrain[\"month\"] = pd.to_datetime(train[\"date\"]).dt.month\ntrain[\"month_year\"] = pd.to_datetime(train[\"date\"]).dt.to_period('M')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"445060f9c11239f1ef1aa7a9e655dcd5660266d8"},"cell_type":"markdown","source":"# 3. Missing Values"},{"metadata":{"trusted":true,"_uuid":"5160c83340709290e77ce2d8fcd07237251b5578"},"cell_type":"code","source":"# train.count() will give a value only if not nan\ncount_nan = len(train) - train.count()\ncount_nan","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc289ca00b2dbfafbc9f5ed134fe4a6cddfa1100"},"cell_type":"markdown","source":"# 4. Individual Feature Visualization"},{"metadata":{"_uuid":"c93fc03f1ab67201abf5ef26abb24795ae64eba2"},"cell_type":"markdown","source":"## 4.1 Histogram of sales of an item (daily sales amount)\nHere Arindam writes \"histogram of daily sales price\" but I believe it's actually sales quantity. "},{"metadata":{"trusted":true,"_uuid":"69cfb4bd6fe30a0ca91298dd42de5b76cf6f7114"},"cell_type":"code","source":"plt.hist(train[\"sales\"])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"203b640727ebc5a80f54b87c0e8fc4513e30237d"},"cell_type":"markdown","source":"Sales is positively skewed."},{"metadata":{"_uuid":"093c3d646f78cba16f6d877f53fde6502db93011"},"cell_type":"markdown","source":"## 4.2 \"Growth\" (?) of sales price by date and change of rate of sales price"},{"metadata":{"trusted":true,"_uuid":"ef213c2b19a857e88638efb233fdb3ea49a5b5e7"},"cell_type":"code","source":"# R script: MSP <- aggregate(sales ~date, train, mean)\nmean_sales = train.groupby([\"date\"], as_index=False)\nmean_sales = mean_sales[[\"sales\"]].mean()\nmean_sales[\"idx\"] = mean_sales.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"998dab2e68b5ccf8c64d602b4c62a75406669ed8"},"cell_type":"code","source":"# Could use the follow:\n# plt.scatter(x=mean_sales[\"date\"], y=mean_sales[\"sales\"])\n# plt.show()\n# Seaborn gives us a closer analogue to the work done in R.\ng = sns.relplot(x=\"idx\", y=\"sales\", data=mean_sales, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a3708f8428966bd9763d7aee1a44bbd4039e4b0"},"cell_type":"code","source":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)/MSP[-nrow(MSP),]$sales)\n# plt.scatter(x=mean_sales.index, y=rt)\n# plt.show()\n# rt is short form for \"Rate\"\nrt = pd.Series(mean_sales[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea7f179a33e857b21a731d53154fd977c5d2daab"},"cell_type":"markdown","source":"You can see that sales growth is multiplicative with increasing trend and seasonality."},{"metadata":{"_uuid":"104ea65f71c1c728cb0bb8107f98e287a64222ae"},"cell_type":"markdown","source":"# 4.3 Sales growth monthly"},{"metadata":{"trusted":true,"_uuid":"e207b5618a34c61cecc3d070b7c40e46c548f05b"},"cell_type":"code","source":"# R script: MSP <- aggregate(sales ~<Month, train, mean)\n# plt.scatter(x=mean_sales_monthly.index, y=mean_sales_monthly[\"sales\"])\n# plt.show()\n# Used index instead of month-year values \n# because matplotlib complains otherwise\nmean_sales_monthly = train.groupby([\"month_year\"], as_index=False)\nmean_sales_monthly = mean_sales_monthly[[\"sales\"]].mean()\nmean_sales_monthly[\"idx\"] = mean_sales_monthly.index\ng = sns.relplot(y=\"sales\", x=\"idx\", data=mean_sales_monthly, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"587c01e285d804173231b639ea47b7997fc5f62a"},"cell_type":"code","source":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)/MSP[-nrow(MSP),]$sales)\n# rt = pd.Series(mean_sales_monthly[\"sales\"]).pct_change()\nrt = pd.Series(mean_sales_monthly[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d7a2989976117db82a427ac99a65234ec567ac6"},"cell_type":"markdown","source":"We can confirm that sales are multipliative with increasing trend and seasonality."},{"metadata":{"_uuid":"1064cdf959ac01afe745ff3752376bf4d9043371"},"cell_type":"markdown","source":"# 4.4 Growth by Year"},{"metadata":{"trusted":true,"_uuid":"a14c0aa65f4c09affbf5219c55f7e2882ab55437"},"cell_type":"code","source":"# R script: MSP <- aggregate(sales ~Year, train, mean)\n#plt.scatter(x=mean_sales_yearly.year, y=mean_sales_yearly[\"sales\"])\n#plt.show()\nmean_sales_yearly = train.groupby([\"year\"], as_index=False)\nmean_sales_yearly = mean_sales_yearly[[\"sales\"]].mean()\nmean_sales_yearly[\"idx\"] = mean_sales_yearly.index\ng = sns.relplot(y=\"sales\", x=\"idx\", data=mean_sales_yearly, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9734696cccffd330a08ac7d1fefdba3fb4c7b09"},"cell_type":"code","source":"# Change in rate of sales\n# R script: MSP$rate = c(0, 100*diff(MSP$sales)/MSP[-nrow(MSP),]$sales)\n#plt.scatter(x=mean_sales_yearly.year, y=rt)\n#plt.show()\nrt = pd.Series(mean_sales_yearly[\"sales\"]).pct_change()\nrt = pd.DataFrame(rt)\nrt[\"idx\"] = rt.index\nrt.fillna(0, inplace=True)\ng = sns.relplot(y=\"sales\", x=\"idx\", data=rt, kind=\"line\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abe2d310287e3d4b5c054226989848cae5ec2cbd"},"cell_type":"markdown","source":"Growth of sales increases yearly, but the change in sales is different per year. Rate of change of sales decreased from 2014 to 2015, increased to 2016, then dropped."},{"metadata":{"_uuid":"46d9a95950dae3071d4624755d180c556a524edf"},"cell_type":"markdown","source":"# 4.5 Sales growth by store"},{"metadata":{"trusted":true,"_uuid":"a00a2af0189451562271a559fac40c2e5bd8b101"},"cell_type":"code","source":"#unique(train$store)\n#Year_state<-aggregate(sales ~store+Year, train,mean)\n#pal<-rep(brewer.pal(10, \"BrBG\"),5)\n#stores = pd.unique(train[\"store\"])\n#years_stores = train.groupby([\"year\", \"store\"], as_index=False)\n#years_stores = years_stores[[\"sales\"]].mean()\n#plt.scatter(x=years_stores[\"sales\"],y=years_stores[\"store\"])\ndata = train.groupby(['store',\"year\"])\nmean = data[[\"sales\"]].mean()\nmean = mean.add_suffix('').reset_index()\ng = sns.relplot(y=\"sales\", x=\"year\", data=mean, kind=\"line\", hue=\"store\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da852029e3eeec503a16036189d4fe25c76b63e3"},"cell_type":"markdown","source":"# 4.6 Yearly Growth by Item"},{"metadata":{"trusted":true,"_uuid":"21f6a7ef98d57a0c904128d2231b09253fdc9646"},"cell_type":"code","source":"# unique(train$item)\n# Year_state<-aggregate(sales ~item+Year, train,mean)\ndata = train.groupby(['item',\"year\"])\nmean = data[[\"sales\"]].mean()\nmean = mean.add_suffix('').reset_index()\ng = sns.relplot(y=\"sales\", x=\"year\", data=mean, kind=\"line\", hue=\"item\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35ac3209b2f40bde27785ae29b2e366d37194476"},"cell_type":"markdown","source":"# 5. Prophet Model\n\n## 5.4 Building the model for store = 1, product = 1"},{"metadata":{"trusted":true,"_uuid":"f3947d5188c1491c04c4e8e5321be35c30f5b5db"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c2a38637b91442420b17c5f98c3f13fae5df062"},"cell_type":"code","source":"s1i1 = train[(train[\"store\"]==1) & (train[\"item\"])==1]\ns1i1[\"sales\"] = np.log1p(s1i1[\"sales\"])\ns1i1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07e66b554894068eb310e6f8817a6d8b8b8994e6"},"cell_type":"code","source":"# R script: stats=aggregate(stats$y,by=list(stats$ds),FUN=sum)\n# R script: MSP <- aggregate(sales ~Year, train, mean)\nstats = s1i1[[\"date\", \"sales\"]]\nstats.columns = [\"ds\", \"y\"]\nstats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6003b309f0d41856b28b049e25802cfe74941034"},"cell_type":"code","source":"m = Prophet()\nm.fit(stats)\nfuture = m.make_future_dataframe(periods=365)\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d60866d9d07be6cfabb2d864eef9928e5f35afca"},"cell_type":"code","source":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d701a23d4e28478133303b347243b60ea8e6828b"},"cell_type":"code","source":"fig1 = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b0052f82f277ac1fb5c6748e85411ffc65fa3b3"},"cell_type":"code","source":"fig2 = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a59c6a6193613569cb5b89069e08172a0c9dca56"},"cell_type":"markdown","source":"Arindam's analysis: We see sales drop from Sunday to Monday so there must be a holiday effect in the sales data. There's a peak in July so this may be due to seasonal sales or summer festivities.\n\nNext step, try excluding change points and include holiday effects. Let's count NFL playoffs as a holiday. And add an extra regressor for NFL sundays."},{"metadata":{"trusted":true,"_uuid":"f674c9dcdffa834d9456ab0ff2618ac0dacf4a9c"},"cell_type":"code","source":"playoffs = ['2013-07-12', '2014-07-12', '2014-07-19',\n                 '2014-07-02', '2015-07-11', '2016-07-17',\n                 '2016-07-24', '2016-07-07','2016-07-24']\nsuperbowl = ['2013-01-01', '2013-12-25', '2014-01-01', '2014-12-25','2015-01-01', '2015-12-25','2016-01-01', '2016-12-25',\n                '2017-01-01', '2017-12-25']\n\nplayoffs = pd.DataFrame({\n  'holiday': 'playoff',\n  'ds': pd.to_datetime(playoffs),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nsuperbowls = pd.DataFrame({\n  'holiday': 'superbowl',\n  'ds': pd.to_datetime(superbowl),\n  'lower_window': 0,\n  'upper_window': 1,\n})\nholidays = pd.concat((playoffs, superbowls))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52bf625a10dfe3c7880a1be44913bc8b337dfe43"},"cell_type":"code","source":"s1i1[\"dow\"] = pd.to_datetime(s1i1[\"date\"]).dt.day_name() # day of week\ns1i1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6ba086b08783c33c7db0167efb7bcc5ccadc91c"},"cell_type":"code","source":"def nfl_sunday(ds):\n    date = pd.to_datetime(ds)\n    if date.weekday() == 6 and (date.month > 8 or date.month < 2):\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"924980f1886dd95b1019483953e569ff070eec91"},"cell_type":"code","source":"stats = s1i1[[\"date\", \"sales\"]]\nstats.columns = [\"ds\", \"y\"]\nstats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123317f9883f1bf90c5f7f48a0bb70b950163c9c"},"cell_type":"code","source":"stats[\"nfl_sunday\"] = stats['ds'].apply(nfl_sunday)\nstats.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01370a0607ca449a32600b51a91ca931d25a4c8e"},"cell_type":"code","source":"# R script below:\n#model_prophet <- prophet()\n#model_prophet <- add_regressor(model_prophet, 'nfl_sunday')\n#model_prophet <- add_seasonality(model_prophet, name='daily', period=60, fourier.order=5)\n#model_prophet <- prophet(stats, holidays = holidays,holidays.prior.scale = 0.5, yearly.seasonality = 4,\n#                         interval.width = 0.95,changepoint.prior.scale = 0.006,daily.seasonality = T)\n#future = make_future_dataframe(model_prophet, periods = 90, freq = 'days')\n#forecast = predict(model_prophet, future)\nm = Prophet(holidays=holidays, holidays_prior_scale=0.5,\n            yearly_seasonality=4,  interval_width=0.95,\n            changepoint_prior_scale=0.006, daily_seasonality=True)\nm.add_regressor('nfl_sunday')\nm.add_seasonality(name='daily', period=60, fourier_order=5)\nm.fit(stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3c386c27c1df8a29c60fadac4be1c7327294475"},"cell_type":"code","source":"future = m.make_future_dataframe(periods=90, freq=\"D\") # Daily frequency\nfuture['nfl_sunday'] = future['ds'].apply(nfl_sunday)\nfuture.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a97429070190ce090f3fccfcd2753923b2696a7d"},"cell_type":"code","source":"forecast = m.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"084d626ff08460763173253774640924ec5e6a6e"},"cell_type":"code","source":"fig1 = m.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57b9b658863ae1e9d480a539b5ba21776ef55132"},"cell_type":"code","source":"fig2 = m.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a354a5b6d6727fd738afbf9d1964596812749315"},"cell_type":"markdown","source":"Things are a lot smoother now. Note that in the original kernel, I believe that \"NFL Sundays\" wasn't included in the future data- so the results look slightly different. This was raised in a comment and I believe it was confirmed by the author. "},{"metadata":{"_uuid":"5ffd552d8cb22be5dd95b9d60101219e369321e9"},"cell_type":"markdown","source":"# 5.8 SMAPE Calcuation\n\nI'm not entirely sure if this recreation was done correctly- the results are different than in the original kernel, but that may be because of the error mentioned above."},{"metadata":{"trusted":true,"_uuid":"21f98b2c651069406d3db3ae22fd42957c4c35c9"},"cell_type":"code","source":"# R script: predict_store1_item1=data.frame(date=forecast$ds,forecast=expm1(forecast$yhat))\n# predict_store1_item1$yearmonth=as.yearmon(predict_store1_item1$date)\n# colnames(predict_store1_item1)<-c(\"ds\",\"forecast\",\"yearmonth\")\nps1i1 = forecast[[\"ds\"]]\nps1i1[\"forecast\"] = np.expm1(forecast[\"yhat\"])\nps1i1[\"yearmonth\"] = pd.to_datetime(ps1i1[\"ds\"]).dt.to_period(\"M\")\nps1i1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2152bafb1e8e74457b499e5e9fd9c9fd4ffb046"},"cell_type":"code","source":"def smape(outsample, forecast):\n    num = np.abs(outsample-forecast)\n    denom = np.abs(outsample) + np.abs(forecast)\n    return (num/denom)/2\n\nstats[\"ds\"] = pd.to_datetime(stats[\"ds\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d3f7e576d9341e5a092398a8d765759aea86fc7"},"cell_type":"code","source":"ps1i1[\"ds\"] = pd.to_datetime(ps1i1[\"ds\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b72e91556f9ff1dffc214dea15efcdab8a15f9d8"},"cell_type":"code","source":"# R script: train_predict = merge(stats, ps1i1, by = \"ds\", all.x=T)\ntrain_predict = stats.merge(ps1i1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f5f016c82f22e70e30228a9e570e3503fad6d01"},"cell_type":"code","source":"smape_err = smape(train_predict[\"y\"], train_predict[\"forecast\"])\nsmape_err = smape_err[~np.isnan(smape_err)]\nnp.mean(smape_err)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fc0da9c0f7dc9798bafcd49c872f9938072c3aa8"},"cell_type":"markdown","source":"As mentioned, this value is different than in the kernel I'm reproducing."},{"metadata":{"_uuid":"8dba87093ed4da0a869ecf71ee8ff527d17f31cc"},"cell_type":"markdown","source":"# 5.9 Automated forecasting with Prophet: Splitting data by store and item"},{"metadata":{"trusted":true,"_uuid":"03f51c7f0acdd425818dbfb8c3f56925082d9aa8"},"cell_type":"code","source":"# Training data from the very beginning\n# Note that I've added some columns\ntrain[\"sales\"] = np.log1p(train[\"sales\"]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6e21d220b245a42f3d2f94a24c5f54ff96133fe"},"cell_type":"code","source":"train.columns = [\"ds\", \"store\", \"item\", \"sales\", \"y\", \"m\", \"my\"]\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e31850f5a10b79dc66fb1571b78a905f9d0d5b09"},"cell_type":"code","source":"def make_prediction(df):\n    \n    playoffs = ['2013-07-12', '2014-07-12', '2014-07-19',\n                 '2014-07-02', '2015-07-11', '2016-07-17',\n                 '2016-07-24', '2016-07-07','2016-07-24']\n    superbowl = ['2013-01-01', '2013-12-25', '2014-01-01', '2014-12-25','2015-01-01', '2015-12-25','2016-01-01', '2016-12-25',\n                    '2017-01-01', '2017-12-25']\n\n    playoffs = pd.DataFrame({\n      'holiday': 'playoff',\n      'ds': pd.to_datetime(playoffs),\n      'lower_window': 0,\n      'upper_window': 1,\n    })\n    superbowls = pd.DataFrame({\n      'holiday': 'superbowl',\n      'ds': pd.to_datetime(superbowl),\n      'lower_window': 0,\n      'upper_window': 1,\n    })\n    holidays = pd.concat((playoffs, superbowls))\n    \n    m = Prophet(holidays=holidays, holidays_prior_scale=0.5,\n            yearly_seasonality=4,  interval_width=0.95,\n            changepoint_prior_scale=0.006, daily_seasonality=True)\n    m.add_seasonality(name='daily', period=60, fourier_order=5)\n    m.fit(df)\n    future = m.make_future_dataframe(periods=90)\n    forecast = m.predict(future)\n    return forecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"776bae8cf49255647e4faf1b62afc2e2ecd424d4"},"cell_type":"code","source":"df = train[(train[\"store\"]==1) & (train[\"item\"] ==2)]\ndf = df[[\"ds\", \"sales\"]]\ndf.columns = [\"ds\", \"y\"]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc7aecd586d0a527c7e76ca373266805b658194f"},"cell_type":"code","source":"prediction = make_prediction(df)\nprediction[[\"ds\", \"yhat\"]].tail()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7311c287eec82389525beae0a68cb8e00cc2b79f"},"cell_type":"markdown","source":"And that's it! I hope I was able to help you out. Please comment below if I made any mistakes, or if there's somewhere I could do better. Thanks!"},{"metadata":{"trusted":true,"_uuid":"58112cdf0b912c5fc325e058a2cbd60a0dd5bbc8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}