{"metadata": {"language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1, "nbformat": 4, "cells": [{"metadata": {}, "source": ["[<img src='https://lh3.googleusercontent.com/-tNe1vwwd_w4/VZ_m9E44C7I/AAAAAAAAABM/5yqhpSyYcCUzwHi-ti13MwovCb_AUD_zgCJkCGAYYCw/w256-h86-n-no/Submarineering.png'>](http://twitter.com/submarineering?lang=en)"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "13d77cd9-990d-4dac-9029-13a16c3e0ffd", "_uuid": "3fe6f78b44d79d0c0e089d7bfbb3c81f31f50e8d"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {}, "source": ["train = pd.read_csv('../input/train.tsv', sep='\\t')\n", "test = pd.read_csv('../input/test.tsv', sep='\\t', quoting=3, error_bad_lines=False)\n", "\n", "#train.info()\n", "\n", "#handel missing values:\n", "\n", "def missing_val(dataset):\n", "    dataset['category_name'].fillna('missing', inplace=True)\n", "    dataset['brand_name'].fillna('missing', inplace=True)\n", "    dataset['item_description'].fillna('missing', inplace=True)\n", "    return dataset\n", "    \n", "train = missing_val(train)\n", "test = missing_val(test)\n", "\n", "#split the category columns in sub columns:\n", "\n", "def split_catg_name(row):\n", "    try:\n", "        text = row\n", "        text1, text2, text3 = text.split('/')\n", "        return text1, text2, text3\n", "    except:\n", "        return 'no label', 'no label', 'no label'\n", "    \n", "train['gen_cat'], train['sub_cat1'], train['sub_cat2'] = zip(*train['category_name'].apply(lambda x : split_catg_name(x)))\n", "test['gen_cat'], test['sub_cat1'], test['sub_cat2'] = zip(*test['category_name'].apply(lambda x : split_catg_name(x)))\n", "\n", "#drop category_name\n", "train.drop('category_name', axis=1, inplace=True)\n", "test.drop('category_name', axis=1, inplace=True)\n", "\n", "#use label encoder on categorical data:\n", "from sklearn.preprocessing import LabelEncoder\n", "\n", "def lab_encoder(dataset):\n", "    le = LabelEncoder()\n", "    dataset['gen_cat'] = le.fit_transform(dataset['gen_cat'])\n", "    dataset['sub_cat1'] = le.fit_transform(dataset['sub_cat1'])\n", "    dataset['sub_cat2'] = le.fit_transform(dataset['sub_cat2'])\n", "    dataset['brand_name'] = le.fit_transform(dataset['brand_name'])\n", "    dataset['name'] = le.fit_transform(dataset['name'])\n", "    return dataset\n", "\n", "train = lab_encoder(train)\n", "test = lab_encoder(test)\n", "\n", "#drop item_description from test and train datasets:\n", "\n", "train.drop('item_description', axis=1, inplace=True)\n", "test.drop('item_description', axis=1, inplace=True)\n", "\n", "#split datasets in train and test sets:\n", "from sklearn.cross_validation import train_test_split\n", "train_X, test_X, train_y, test_y = train_test_split(train.drop('price', axis=1), train['price'], test_size = 0.2)\n", "\n", "#apply Random Forest regression algorithm:\n", "from sklearn.ensemble import RandomForestRegressor\n", "rand_reg2 = RandomForestRegressor(n_estimators=10)\n", "rand_reg2.fit(train_X, train_y)\n", "rand_reg2.score(train_X, train_y)\n", "\n", "pred = rand_reg2.predict(test)\n", "prediction = pd.DataFrame({'test_id': test['test_id'],\n", "                          'price':pred})\n", "\n", "\n", "#sub = pd.read_csv('../input/sample_submission.csv')\n", "prediction.to_csv('Submission1.csv', index=False)"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}]}