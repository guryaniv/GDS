{"cells":[{"metadata":{"_uuid":"00826f20c0f2e0bb7823acfee91d08f1c73e47ae"},"cell_type":"markdown","source":"Exploring time series forecasting with Keras. As usual, playing with the numbers just for fun.\n\nI will start with a very basic approach to LSTM in Keras, under the assumption that sales by shop and item in November are correlated to sales in same shops and items in previous two months. This is a very simplified version of senkin13 (https://www.kaggle.com/senkin13) excellent work in (https://www.kaggle.com/senkin13/lstm-starter/code). All credit to senkin13.\n\nI will look for other alternatives and corrections to improve the results. Comments and ideas will be welcome."},{"metadata":{"_uuid":"e32af18f7f844918125aa5ac70ce78e100ad641d"},"cell_type":"markdown","source":"Now, the usual stuff."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"c8033f9bb5e43a42682068d81f6acad8204b4bef"},"cell_type":"markdown","source":"I will use the convenient date_block_num for month number as my time series, and will convert from the time series into supervised learning."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\n    '../input/sales_train.csv',\n    usecols = [1, 2, 3, 5]\n).fillna(0)","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"4caaafa1-cc47-44fc-b438-cee2eb48dfbd","_uuid":"e30aeeb8014dcf5f91e263d8cdf3014d6668c7e6","trusted":true},"cell_type":"code","source":"print (df_train.shape)\nprint (df_train.info())","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"473a06c7-a80e-4584-a601-4815fcb761ff","_uuid":"0753c67072c81afba13bea100e3376187d919734","trusted":true,"collapsed":true},"cell_type":"code","source":"df_t = df_train.pivot_table(\n    values='item_cnt_day',\n    index=['shop_id', 'item_id'],\n    columns='date_block_num',\n    aggfunc='sum'\n).fillna(0)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"429b506f-ccc1-4aa7-9975-a48317284034","_uuid":"a645b23e1fea83f02386d5cef277deb350b7aa21","trusted":true},"cell_type":"code","source":"print (df_t.head())\nprint (df_t.shape)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"0cc401c755cdb2d573a265f89ef7833fbedde7cc"},"cell_type":"markdown","source":"Now, to create the supervised learning data, I create a df with the period-1 and period-2 monthly sales, as we are using the assumption that sales in November (block number 34) are related to previous two months sales. So the train df will include for each block number starting in 2, the sales from the two previous periods.\n\nMonths from 2 to 31 are used for training. For validation, I took two months, 32 and 33."},{"metadata":{"_cell_guid":"34bc72a5-0385-44a2-b91a-55a3e62d7fb0","_uuid":"bd81dece8d97fd4333466f510fc3c9347baaa3bc","trusted":true},"cell_type":"code","source":"X_train = pd.DataFrame()\ny_train = pd.Series()\nX_val = pd.DataFrame()\ny_val = pd.Series()\nfor i in range(2, 32):\n    print (i)\n    print ('='*50)\n    X = df_t.iloc[:, i-2:i]\n    X.columns = ['P-2', 'P-1']\n    X_train = X_train.append(X)\n    y = pd.Series(df_t.iloc[:, i])\n    y_train = y_train.append(y)\nfor j in range(32, 34):\n    print (j)\n    print ('='*50)\n    X = df_t.iloc[:, i-2:i]\n    X.columns = ['P-2', 'P-1']\n    X_val = X_val.append(X)\n    y = df_t.iloc[:, i]\n    y_val = y_val.append(y)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"18a92c53-3500-4bbb-9d31-8da2875c4e11","_uuid":"969581b0c35769805ff9357566c5110ece93c14d","trusted":true},"cell_type":"code","source":"print (len(X_train), len(y_train))\nprint (len(X_val), len(y_val))","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"cdf2c5747f98a426783d727fb8996578c53cc458"},"cell_type":"markdown","source":"The length of X_train and y_train and X_val and y_val are the same, which was expected but always good to see."},{"metadata":{"_uuid":"cc0bc6ca4169a4146788a5a1e7d03a20764eb0b9"},"cell_type":"markdown","source":"LSTM model requires the input data (X) to be with a 3 dimension shape: samples, timesteps and features. I'm using two features, period-1 and period-2, so I reshape the data to make it fit with this."},{"metadata":{"trusted":true,"_uuid":"7526bda4333f57cfdeaf37acf115c53098a42d25"},"cell_type":"code","source":"X_train2 = X_train.as_matrix()\nprint (X_train2)\nX_train2 = X_train2.reshape(X_train2.shape[0], 1, X_train2.shape[1])\ny_train2 = y_train.values\nprint (y_train2)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2bef50b33749e331b86dcc22253b38dd56c20b5"},"cell_type":"code","source":"X_val2 = X_val.as_matrix()\nX_val2 = X_val2.reshape(X_val2.shape[0], 1, X_val2.shape[1])\ny_val2 = y_val.values\nprint (X_val2)\nprint (y_val2)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96e89bec5da7d35033a6e853dd25fcdb4b9567b4"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense, Dropout, Activation\nfrom keras.layers import LSTM","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"ad3563e2f24ae7b6908a5a96fa3b599ca7eedd7e"},"cell_type":"markdown","source":"So, the Keras model, with 64 neurons in the first layer, 10% drop to avoid overfitting, 32 neurons in a second layer, 20% drop and finally one neuron in the output.\n\nI will run 20 epochs with a batch size of 100,000. I want to explore this numbers as I don't know how this will impact the prediction."},{"metadata":{"trusted":true,"_uuid":"6ce7c487900456836458d381be84eb787be2b8b5"},"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(64, input_shape=(X_train2.shape[1],X_train2.shape[2])))\nmodel.add(Dropout(.1))\nmodel.add(Dense(32))\nmodel.add(Dropout(.2))\nmodel.add(Dense(1))\nmodel.compile(loss = 'mse', optimizer='adam', metrics=['mse'])\nmodel.fit(X_train2, y_train2, batch_size = 100000, epochs = 20, verbose=2,\n    validation_data=(X_val2,y_val2))","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"5806d176dbb70f097f1b00a8640ca9598173ab15"},"cell_type":"markdown","source":"It took quite long..."},{"metadata":{"_uuid":"f35fabdd00d37a1e44df08620045c7435faab4dd"},"cell_type":"markdown","source":"Now I prepare the test with the two previous months data for prediction."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3751dc1cdf43a79ae3186575a9f2dc35becf8805"},"cell_type":"code","source":"df_test = pd.read_csv(\n        '../input/test.csv',\n        ).set_index(['shop_id', 'item_id'])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"922520f7a6c33d96f58bf24c011d6cfedc4e321f"},"cell_type":"code","source":"X_test = df_test\nX = df_t.iloc[:, 32:34]\nX_test = X_test.join(X)\nprint (X_test)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0faf66d6a549279248b492f81244969f878aa353"},"cell_type":"code","source":"X_test = X_test.fillna(0)\nprint (X_test)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3effaed80dcf140d0998e9144f55e5459689149"},"cell_type":"code","source":"X_test2 = X_test.iloc[:, 1:3]\nX_test2 = X_test2.as_matrix()\nprint (X_test2.shape)","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"02455e20f17ae04b5b04500263003d3ef26d851f"},"cell_type":"markdown","source":"Same reshape to 3D."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c24ee36d210b338f404f336a052f1f104c8d3931"},"cell_type":"code","source":"X_test2 = X_test2.reshape(X_test2.shape[0], 1, X_test2.shape[1])\npredict = model.predict(X_test2)","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"28bd76384214860719d50b310125a7bbaaa2db44"},"cell_type":"markdown","source":"And submission."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"11e253907549afe63223c5b9f27a43727b290498"},"cell_type":"code","source":"df_test['item_cnt_month'] = predict\ndf_test.to_csv('accountant_keras1.csv', float_format = '%.2f', index=None)","execution_count":20,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}