{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\n\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential,load_model,Model\nfrom keras.optimizers import *\nfrom keras.utils import to_categorical\nfrom keras.layers import *\nfrom keras.callbacks import *\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nsess = tf.Session()\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nK.tensorflow_backend._get_available_gpus()\nK.set_session(sess)\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"xtrain = pd.read_csv('../input/X_train.csv')\nytrain = pd.read_csv('../input/y_train.csv')\ntest=pd.read_csv(\"../input/X_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dee5ffcc52b4ad840a427681548a06e98f1db2d3"},"cell_type":"code","source":"### feature extraction of orientation, angular_velocity, linear_acceleration, velocity_to_acceleration and velocity_linear_acceleration\ndef feature_extraction(raw_frame):\n    raw_frame['orientation'] = raw_frame['orientation_X'] + raw_frame['orientation_Y'] + raw_frame['orientation_Z']+ raw_frame['orientation_W']\n    raw_frame['angular_velocity'] = raw_frame['angular_velocity_X'] + raw_frame['angular_velocity_Y'] + raw_frame['angular_velocity_Z']\n    raw_frame['linear_acceleration'] = raw_frame['linear_acceleration_X'] + raw_frame['linear_acceleration_Y'] + raw_frame['linear_acceleration_Y']\n    raw_frame['velocity_to_acceleration'] = raw_frame['angular_velocity'] / raw_frame['linear_acceleration']\n    raw_frame['velocity_linear_acceleration'] = raw_frame['linear_acceleration'] * raw_frame['angular_velocity']\n    return raw_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99d028edff161128b1c7a484c4ea6589916f1335"},"cell_type":"code","source":"xtrain = feature_extraction(xtrain)\ntest = feature_extraction(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45736966089ae8d2eddfb55dc7159032a7c7e30f"},"cell_type":"code","source":"### more feature extraction with mean, mode, std, variance, min, max and so on...\n\ndef feature_extraction_more(raw_frame):\n    frame = pd.DataFrame([])\n    for col in raw_frame.columns[3:]:\n        frame[col + '_mean'] = raw_frame.groupby(['series_id'])[col].mean()\n        frame[col + '_std'] = raw_frame.groupby(['series_id'])[col].std()\n        frame[col + '_var'] = raw_frame.groupby(['series_id'])[col].var()\n        frame[col + '_sem'] = raw_frame.groupby(['series_id'])[col].sem()\n        frame[col + '_max'] = raw_frame.groupby(['series_id'])[col].max()\n        frame[col + '_min'] = raw_frame.groupby(['series_id'])[col].min()\n        frame[col + '_max_to_min'] = frame[col + '_max'] / frame[col + '_min']\n        frame[col + '_max_minus_min'] = frame[col + '_max'] - frame[col + '_min']\n        frame[col + '_std_to_var'] = frame[col + '_std'] * frame[col + '_var']\n        frame[col + '_mean_abs_change'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n        frame[col + '_abs_max'] = raw_frame.groupby('series_id')[col].apply(lambda x: np.max(np.abs(x)))\n    return frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"658ae5082571d9ffc4ad1e4fae7bef01101ab0d5"},"cell_type":"code","source":"train_df = feature_extraction_more(xtrain)\ntest_df = feature_extraction_more(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b666fde5cf3378b9d4155030fd98ad74c45b509"},"cell_type":"code","source":"print(\"train shape\",train_df.shape)\nprint(\"test shape\", test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"659b2d7232503bb34fa9d9f14bcdb1b8fb5e72c9"},"cell_type":"code","source":"scaler = preprocessing.StandardScaler()\n# Apply transform to both the training set and the test set.\ntrain_df = scaler.fit_transform(train_df)\ntest_df = scaler.fit_transform(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a40da6c096d38c21106031f78928d4b2b0964eb"},"cell_type":"code","source":"### lable encoding \nle = preprocessing.LabelEncoder()\nle.fit(ytrain.surface)\nytrain['surface'] = le.transform(ytrain.surface)\ntrain_label = to_categorical(ytrain['surface'])\ntrain_label.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae1e55294bda13d810cdb961c64befde96f91c21"},"cell_type":"code","source":"train_x,val_x,train_y,val_y = train_test_split(train_df, train_label, test_size = 0.10, random_state=14)\ntrain_x.shape,val_x.shape,train_y.shape,val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6966cbe678cea8bd5475a2f7ba9b05de0b39aa0"},"cell_type":"code","source":"nb_features = train_df.shape[1]\nnb_out = train_label.shape[1]\nnb_features,nb_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38a8638e8442dd3bd981e46f0100447160fd3778"},"cell_type":"code","source":"## https://www.kaggle.com/kabure/titanic-eda-keras-nn-pipelines\n## Creating the model\nmodel = Sequential()\n\n# Inputing the first layer with input dimensions\nmodel.add(Dense(165, \n                activation='relu',  \n                input_dim = nb_features,\n                kernel_initializer='uniform'))\n\n# Adding an Dropout layer to previne from overfitting\nmodel.add(Dropout(0.50))\n\n#adding second hidden layer \nmodel.add(Dense(60,\n                kernel_initializer='uniform',\n                activation='relu'))\n\n# Adding another Dropout layer\nmodel.add(Dropout(0.50))\n\n# adding the output layer that is binary [0,1]\nmodel.add(Dense(nb_out, activation='softmax'))\n\n#Visualizing the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a54e4546e19d6b221a42c789efeeed827890f69e"},"cell_type":"code","source":"model_feat = Model(inputs=model.input,outputs=model.get_layer('dropout_2').output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87900554df1b567b2f29cd78fa1bc3e454f7be11"},"cell_type":"code","source":"train_feature = model_feat.predict(train_x)\nval_feature = model_feat.predict(val_x)\ntest_feature = model_feat.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a89d6e2b15053889075b7ca74a5ff6afcbc83de"},"cell_type":"code","source":"feat_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"980f51dd27155f1bcee549d53b82ac38a12df618"},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier,ExtraTreesClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.metrics import mean_absolute_error\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\npara={'boosting_type': 'gbdt',\n 'colsample_bytree': 0.85,\n 'learning_rate': 0.1,\n 'max_bin': 512,\n 'max_depth': -1,\n 'metric': 'multi_error',\n 'min_child_samples': 8,\n 'min_child_weight': 1,\n 'min_split_gain': 0.5,\n 'nthread': 3,\n 'num_class': 9,\n 'num_leaves': 31,\n 'objective': 'multiclass',\n 'reg_alpha': 0.8,\n 'reg_lambda': 1.2,\n 'scale_pos_weight': 1,\n 'subsample': 0.7,\n 'subsample_for_bin': 200,\n 'subsample_freq': 1}\n\nClassifier = [\n    \n        LGBMClassifier(),\n        LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n        KNeighborsClassifier(),\n        SVC(kernel=\"rbf\", C=0.025, probability=True),\n        DecisionTreeClassifier(),\n        RandomForestClassifier(n_estimators=500,max_depth=20, min_samples_split=5,\n                             class_weight='balanced'),\n        AdaBoostClassifier(),\n        GaussianNB(),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"527360c923cca20667a4d7bb1c84f12bdd0b0ee0"},"cell_type":"code","source":"Accuracy=[]\nModel=[]\n\nfor classifier in Classifier:\n    try:\n        \n        fit = classifier.fit(train_feature,np.argmax(train_y,axis=1))\n        pred = fit.predict(val_feature)\n    except Exception:\n        fit = classifier.fit(train_feature,np.argmax(train_y,axis=1))\n        pred = fit.predict(val_feature)\n        \n        \n    score = accuracy_score(np.argmax(val_y,axis=1), pred)\n    Model.append(classifier.__class__.__name__)\n    print('Accuracy of '+classifier.__class__.__name__+' is '+str(score))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07398c65b876fbb89f9a4db2f2051658f819208b"},"cell_type":"code","source":"classifier = KNeighborsClassifier()\nfit = classifier.fit(train_feature,np.argmax(train_y,axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8267f0e09320415499ca13316544602e6a4b950"},"cell_type":"code","source":"pred = fit.predict(test_feature)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b8c0073810e844d6483d4e5a02c80a8014b557"},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = le.inverse_transform(pred)\nsubmission.to_csv('knn.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}