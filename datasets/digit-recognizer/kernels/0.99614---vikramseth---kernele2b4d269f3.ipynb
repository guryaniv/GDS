{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport math as m\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport os\nimport time\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\nprint(os.listdir(\"../input\"))\nnp.random.seed(2)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca1ab04c4548ca6cf2d20aedfbba42f4894b389b"},"cell_type":"code","source":"def convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)]\n    return Y","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def read_csv(filename):\n    X,Y=[],[]\n    test=pd.read_csv(filename)\n    if filename.find(\"train.csv\") >0:\n                Y=test.iloc[:,0].values\n                Y=convert_to_one_hot(Y,10)\n                X=test.iloc[:,1:785].values\n    else:\n                X=test.iloc[:,0:784].values\n    \n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0404230a95317dafa89995cc6dc929fd18234f6c"},"cell_type":"code","source":"def write_csv(filename,predictions):\n# Writing a CSV file submission. ImageName,Prediction \n\n    my_submission = pd.DataFrame({'ImageId': range(1,predictions.shape[0]+1), 'Label': predictions})\n    # you could use any filename. We choose submission here\n    my_submission.to_csv('submission.csv', index=False)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"600d261bb8ff119810f1b3ba709963cc65a5cf33"},"cell_type":"code","source":"X_train,Y_train=read_csv(\"../input/train.csv\")\nX_test,_=read_csv(\"../input/test.csv\")\nm,pixels=X_train.shape\nclasses=10 \nheight,width,channels=28,28,1\nX_train, X_test=X_train/255, X_test/255\n#plt.imshow(np.reshape(X_test[0],(28,28)))   #plotting the example data\n#Resize into (height width channels)\nX_train=X_train.reshape(-1,height,width,channels)\nX_test=X_test.reshape(-1,height,width,channels)\nprint(Y_train.shape,X_train.shape,X_test.shape)\n# Split the train and the validation set for the fitting\nrandom_seed = 2\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)\nprint(Y_train.shape,X_train.shape,X_test.shape,X_val.shape,Y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"38c33dbc1a3146ee59bc80b2220bd12e8f403cf6"},"cell_type":"code","source":"def DigitalRecognizerModel(input_shape):\n    \"\"\"\n       X_train size[None,height,width,channels]\n       Y_train size[None,classes]\n       X_test size[None,height,width,channels]\n    \"\"\"\n    # Define the inputpadding = 'same', placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n    X=Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1))(X_input)\n    X=Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu')(X)\n    X=MaxPooling2D(pool_size=(2,2))(X)\n    X=Dropout(0.25)(X)\n\n    X=Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu')(X)\n    X=Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu')(X)\n    X=MaxPooling2D(pool_size=(2,2), strides=(2,2))(X)\n    X=Dropout(0.25)(X)\n    X=Flatten()(X)\n    X=Dense(256, activation = \"relu\")(X)\n    X=Dropout(0.5)(X)\n    X=Dense(10, activation = \"softmax\")(X)\n    # Create model\n    model = Model(inputs = X_input, outputs = X, name='DigitalRecognizer')    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43c7ec574d8a30eb9dc84db2dd12ab421cc865d3"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59aa37b97dfb1b0a419f43ca0e5942250335063e"},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3cc854a11f2e4cf4f6b0eaeefcc296561588b7e"},"cell_type":"code","source":"digitalRecognizerModel = DigitalRecognizerModel(X_train[0].shape)\ndigitalRecognizerModel.compile(optimizer = \"Adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n#digitalRecognizerModel.fit(x=X_train, y=Y_train, epochs=10, batch_size=62)\nhistory = digitalRecognizerModel.fit_generator(datagen.flow(X_train,Y_train, batch_size=62),\n                              epochs = 30, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=610,callbacks=[learning_rate_reduction])  #m.ceil(X_train.shape[0] // 62)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8071672a3c412a270dd21a6bdfd409222d45edd"},"cell_type":"code","source":"print(\"Time Start:\" ,time.time())\n\nval_predictions=digitalRecognizerModel.predict(X_val)\n#test Accuracy\ncorrect_val_predictions=np.mean(np.equal(np.argmax(val_predictions,axis=1), np.argmax(Y_val,axis=1)))\nprint(\"Validation Accuracy\",correct_val_predictions)\n#test Predictions\ntest_predictions=digitalRecognizerModel.predict(X_test)\ncorrect_test_predictions=np.argmax(test_predictions,axis=1)\nwrite_csv('submission.csv',correct_test_predictions)\nprint(\"Time End:\" ,int(round(time.time())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1eda5caf2db915d5c1b973f150f37fc2649cf5b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}