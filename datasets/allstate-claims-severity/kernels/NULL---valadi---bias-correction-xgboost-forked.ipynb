{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45c5e39b-f88f-2e6a-bc1d-5295092e5f99"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95725cb0-2fe5-a1d4-391c-76e7d6d9d5f1"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cross_validation import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from scipy.stats import skew, boxcox\n",
        "from math import exp, log\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45afe9cd-a1d4-fd19-61e7-005cc4b9171c"
      },
      "outputs": [],
      "source": [
        "def timer(start_time=None):\n",
        "    if not start_time:\n",
        "        start_time = datetime.now()\n",
        "        return start_time\n",
        "    elif start_time:\n",
        "        tmin, tsec = divmod((datetime.now() - start_time).total_seconds(), 60)\n",
        "        print(' Time taken: %i minutes and %s seconds.' %\n",
        "              (tmin, round(tsec, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1f0a888-a632-b7ab-7635-9ea3c7649b84"
      },
      "outputs": [],
      "source": [
        "def scale_data(X, scaler=None):\n",
        "    if not scaler:\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X)\n",
        "    X = scaler.transform(X)\n",
        "    return X, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06340266-8423-82c8-8b7d-e1079819f542"
      },
      "outputs": [],
      "source": [
        "\n",
        "DATA_TRAIN_PATH = '../input/train.csv'\n",
        "DATA_TEST_PATH = '../input/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "03c2fa98-be49-7bac-23a7-b158b1de6258"
      },
      "outputs": [],
      "source": [
        "def load_data(path_train=DATA_TRAIN_PATH, path_test=DATA_TEST_PATH):\n",
        "    train_loader = pd.read_csv(path_train, dtype={'id': np.int32})\n",
        "    train = train_loader.drop(['id', 'loss'], axis=1)\n",
        "    test_loader = pd.read_csv(path_test, dtype={'id': np.int32})\n",
        "    test = test_loader.drop(['id'], axis=1)\n",
        "    ntrain = train.shape[0]\n",
        "    ntest = test.shape[0]\n",
        "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
        "    numeric_feats = train_test.dtypes[train_test.dtypes != \"object\"].index\n",
        "\n",
        "    # compute skew and do Box-Cox transformation\n",
        "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
        "    print(\"\\nSkew in numeric features:\")\n",
        "    print(skewed_feats)\n",
        "    # transform features with skew > 0.25 (this can be varied to find optimal value)\n",
        "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
        "    skewed_feats = skewed_feats.index\n",
        "    for feats in skewed_feats:\n",
        "        train_test[feats] = train_test[feats] + 1\n",
        "        train_test[feats], lam = boxcox(train_test[feats])\n",
        "    features = train.columns\n",
        "    cats = [feat for feat in features if 'cat' in feat]\n",
        "    # factorize categorical features\n",
        "    for feat in cats:\n",
        "        train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n",
        "    x_train = train_test.iloc[:ntrain, :]\n",
        "    x_test = train_test.iloc[ntrain:, :]\n",
        "    train_test_scaled, scaler = scale_data(train_test)\n",
        "    train, _ = scale_data(x_train, scaler)\n",
        "    test, _ = scale_data(x_test, scaler)\n",
        "\n",
        "    train_labels = np.log(np.array(train_loader['loss']))\n",
        "    train_ids = train_loader['id'].values.astype(np.int32)\n",
        "    test_ids = test_loader['id'].values.astype(np.int32)\n",
        "\n",
        "    return train, train_labels, test, train_ids, test_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cd0f4fb3-87a7-595b-3d15-28f98a86818b"
      },
      "outputs": [],
      "source": [
        "# enter the number of folds from xgb.cv\n",
        "folds = 4\n",
        "cv_sum = 0\n",
        "early_stopping = 25\n",
        "fpred = []\n",
        "xgb_rounds = []\n",
        "\n",
        "params = {}\n",
        "params['booster'] = 'gbtree'\n",
        "params['objective'] = \"reg:linear\"\n",
        "params['eval_metric'] = 'mae'\n",
        "params['eta'] = 0.1\n",
        "params['gamma'] = 0. 35\n",
        "params['min_child_weight'] = 4.2922\n",
        "params['colsample_bytree'] = 0.32\n",
        "params['subsample'] = 0.9930\n",
        "params['max_depth'] = 7\n",
        "params['max_delta_step'] = 0\n",
        "params['silent'] = 1\n",
        "params['random_state'] = 1001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1d370e25-0f5a-cad1-2d42-970ea2de5e18"
      },
      "outputs": [],
      "source": [
        "start_time = timer(None)\n",
        "\n",
        "# Load data set and target values\n",
        "train, target, test, _, ids = load_data()\n",
        "d_train_full = xgb.DMatrix(train, label=target)\n",
        "d_test = xgb.DMatrix(test)\n",
        "kf = KFold(train.shape[0], n_folds=folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "54920198-0082-7d56-ef5a-1ac2c7595787"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i, (train_index, test_index) in enumerate(kf):\n",
        "    \n",
        "    print('\\n Fold %d\\n' % (i + 1))\n",
        "    X_train, X_val = train[train_index], train[test_index]\n",
        "    y_train, y_val = target[train_index], target[test_index]\n",
        "    \n",
        "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
        "    d_valid = xgb.DMatrix(X_val, label=y_val)\n",
        "    watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
        "    \n",
        "    clf = xgb.train(params,d_train,100000,watchlist,early_stopping_rounds=early_stopping)\n",
        "    \n",
        "    ####################################\n",
        "    #  Evaluate Model and Predict\n",
        "    ####################################\n",
        "\n",
        "    xgb_rounds.append(clf.best_iteration)\n",
        "    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)\n",
        "    cv_score = mean_absolute_error(np.exp(y_val), np.exp(scores_val))\n",
        "    print(' eval-MAE: %.6f' % cv_score)\n",
        "    y_pred = np.exp(clf.predict(d_test, ntree_limit=clf.best_ntree_limit))\n",
        "    \n",
        "    ####################################\n",
        "    #  Add Predictions and Average Them\n",
        "    ####################################\n",
        "\n",
        "    if i > 0:\n",
        "        fpred = pred + y_pred\n",
        "    else:\n",
        "        fpred = y_pred\n",
        "    pred = fpred\n",
        "    cv_sum = cv_sum + cv_score\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "49482bbe-3001-0acc-96c1-2c84f5a3cdee"
      },
      "outputs": [],
      "source": [
        "mpred = pred / folds\n",
        "score = cv_sum / folds\n",
        "print('\\n Average eval-MAE: %.6f' % score)\n",
        "n_rounds = int(np.mean(xgb_rounds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "30fbe903-b586-b412-d0f8-ed84f0e8160d"
      },
      "outputs": [],
      "source": [
        "print('\\n Training full dataset for %d rounds ...' % n_rounds)\n",
        "watchlist = [(d_train_full, 'train')]\n",
        "clf_full = xgb.train(\n",
        "    params, d_train_full,\n",
        "    n_rounds,\n",
        "    watchlist,\n",
        "    verbose_eval=False,)\n",
        "y_pred_full = np.exp(clf_full.predict(d_test))\n",
        "timer(start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a7d76d3-4d9a-76d7-158a-680c237bd22e"
      },
      "outputs": [],
      "source": [
        "n_fixed = 376\n",
        "nfixed = int(n_fixed * (1 + (1. / folds)))\n",
        "print('\\n Training full dataset for %d fixed rounds ...\\n' % nfixed)\n",
        "\n",
        "\n",
        "\n",
        "clf_fixed = xgb.train(\n",
        "    params, d_train_full,\n",
        "    nfixed,\n",
        "    watchlist,\n",
        "    verbose_eval=False,)\n",
        "y_pred_fixed = np.exp(clf_fixed.predict(d_test))\n",
        "timer(start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2493d811-2b75-f75a-5881-77efbd799410"
      },
      "outputs": [],
      "source": [
        "print(\"#\\n Writing results\")\n",
        "result = pd.DataFrame(mpred, columns=['loss'])\n",
        "result[\"id\"] = ids\n",
        "result = result.set_index(\"id\")\n",
        "print(\"\\n %d-fold average prediction:\\n\" % folds)\n",
        "print(result.head())\n",
        "result_full = pd.DataFrame(y_pred_full, columns=['loss'])\n",
        "result_full[\"id\"] = ids\n",
        "result_full = result_full.set_index(\"id\")\n",
        "print(\"\\n Full dataset prediction:\\n\")\n",
        "print(result_full.head())\n",
        "\n",
        "result_fixed = pd.DataFrame(y_pred_fixed, columns=['loss'])\n",
        "result_fixed[\"id\"] = ids\n",
        "result_fixed = result_fixed.set_index(\"id\")\n",
        "print(\"\\n Full datset (at CV #iterations) prediction:\\n\")\n",
        "print(result_fixed.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b262709d-ba18-1880-9447-843087a2bda1"
      },
      "outputs": [],
      "source": [
        "now = datetime.now()\n",
        "score = str(round((cv_sum / folds), 6))\n",
        "sub_file = 'submission_5fold-average-xgb_' + str(score) + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
        "print(\"\\n Writing submission: %s\" % sub_file)\n",
        "result.to_csv(sub_file, index=True, index_label='id')\n",
        "\n",
        "# trained on full data \n",
        "sub_file = 'submission_full-average-xgb_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
        "print(\"\\n Writing submission: %s\" % sub_file)\n",
        "result_full.to_csv(sub_file, index=True, index_label='id')\n",
        "\n",
        "#trained on full cv\n",
        "sub_file = 'submission_full-CV-xgb_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
        "print(\"\\n Writing submission: %s\" % sub_file)\n",
        "result_fixed.to_csv(sub_file, index=True, index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34cfc6ea-2a1e-f415-fc66-9e56e6bf1d94"
      },
      "outputs": [],
      "source": [
        "fusion=(result_fixed+result_full+result)/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7303e4f-3cb2-7ec3-5a2c-d7e863fc5166"
      },
      "outputs": [],
      "source": [
        "meanSub=\"meanSub.csv\"\n",
        "print(\"\\n Writing submission: %s\" % meanSub)\n",
        "fusion.to_csv(meanSub, index=True, index_label='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d6702190-9432-6b97-3b5a-7066fcb6e035"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}