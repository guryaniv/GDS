{"cells":[{"metadata":{"_uuid":"30ec159b07aa1fc863ba389290ff238c105e96f4"},"cell_type":"markdown","source":"# 1. Parameters & Libraries"},{"metadata":{"trusted":true,"_uuid":"56499f1971e327957623f5aba1df2e1180bfc0d8"},"cell_type":"code","source":"n_fold=1\nstep=1\nrand_seeds=n_fold*step\n\nrand=100\nsave_model_name = \"./unet_best1.model\"\nsave_end_name = \"./unet_end1.model\"\ntransfar_model_01 = \"../input/binary-class-fo01-demo-181109/unet_best1.model\"\nfold_path = '../input/simple-unet-100-5-fold-df/fold_df.csv'\n\nstart_lr = 1e-4\nepochs = 1\nbatch_size = 32\ndropout_rate = 0.3\nweight = 1.0","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport six\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Concatenate,UpSampling2D,Input,Dropout,BatchNormalization,Activation,Add,GlobalAveragePooling2D,Dense,Multiply\nfrom keras.layers.core import Lambda, Flatten\nfrom keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate, add\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras import optimizers\nfrom keras.regularizers import l2\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#,save_img\n\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5067f432d7af639a6dbca6d76840a6cf14a9087f"},"cell_type":"code","source":"import time\nfrom datetime import datetime, timedelta, timezone\nfrom contextlib import contextmanager\nJST = timezone(timedelta(hours=+9), 'JST')\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} -> done in {:.0f}s\".format(title, time.time() - t0))\n    print(\"Executed time -> {}\\n\".format(datetime.now(JST)))\n\nwith timer('end'):\n    print('finish!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"087ee41045b7197ac48001f32a966287031be674"},"cell_type":"code","source":"# Set some parameters\nim_width = 101\nim_height = 101\nim_chan = 1\nbasicpath = '../input/tgs-salt-identification-challenge/'\npath_train = basicpath + 'train/'\npath_test = basicpath + 'test/'\n\npath_train_images = path_train + 'images/'\npath_train_masks = path_train + 'masks/'\npath_test_images = path_test + 'images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b8d99bb4333998aee049fe45b433d94680e299b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa2595b8ee7cb8c72611922a9f9ccf37a640a1bf"},"cell_type":"markdown","source":"# 2. Helpers & Data engineering"},{"metadata":{"trusted":true,"_uuid":"26af6480ed6663fc017caf929692e667df351ef9"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 128\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return np.pad(img, [(img_size_target-img_size_ori)//2,(img_size_target-img_size_ori)-(img_size_target-img_size_ori)//2], 'edge')\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return img[(img_size_target-img_size_ori)//2:img_size_ori+(img_size_target-img_size_ori)//2, (img_size_target-img_size_ori)//2:img_size_ori+(img_size_target-img_size_ori)//2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5b17cb9af30a6b8dcf60350e28dcce352d207d8"},"cell_type":"code","source":"# Loading of training/testing ids and depths\n\ntrain_df = pd.read_csv(basicpath+\"train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(basicpath+\"depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9702d04f2f063775c9195dd4f286cf41a091d22e"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(path_train_images+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f5f4e7a133a0fed999c88f1cb127ec8dda5cf6e"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(path_train_masks+\"{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12acbe57c3fec6787ba9c1da9a9c529b7599cfb8"},"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc63b729fde0f8a4ba08040b44c55cae7c063ef9"},"cell_type":"code","source":"fold_df = pd.read_csv(fold_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b9399663afb8ce96308128e5e927477b6f705b3"},"cell_type":"code","source":"ids_valid = fold_df[fold_df['n_fold']==n_fold].valid_idx.values\nids_train = np.array([i for i in np.arange(train_df.shape[0]) if i not in ids_valid])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8582340d6eaea5e436353a8c93c82891581e2f8"},"cell_type":"code","source":"print(\"train shape: {}\".format(ids_train.shape))\nprint(\"valid shape: {}\".format(ids_valid.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64eb7d6c9474685ce39abdddbf90a852c7ea3e6c"},"cell_type":"code","source":"x_train = np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)[ids_train]\nx_valid = np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)[ids_valid]\ny_train = np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)[ids_train]\ny_valid = np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1)[ids_valid]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53f23c339ebfd8e8ba8261d6f65193018dcf0050"},"cell_type":"code","source":"x_train_org = x_train\nx_valid_org = x_valid\ny_train_org = y_train\ny_valid_org = y_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa5b495efb8a4e390cf165d17997117244a60258"},"cell_type":"code","source":"y_train = np.any(y_train==1, axis=(1,2,3))*1\ny_valid = np.any(y_valid==1, axis=(1,2,3))*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dbb827634b5a4c44c1fd209f5dae421155c92cb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e43dca21e302dc500e172278a9a766c762e5c012"},"cell_type":"markdown","source":"# 3. Build a model"},{"metadata":{"trusted":true,"_uuid":"cc84a47fda4212a95338597f7bdc3960e2a5a564"},"cell_type":"code","source":"def BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = BatchActivate(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, batch_activate = False):\n    x = BatchActivate(blockInput)\n    x = convolution_block(x, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = Add()([x, blockInput])\n    if batch_activate:\n        x = BatchActivate(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9914fba9c359e34141b9f698b9110958baa1bf09"},"cell_type":"code","source":"# cSE\ndef channel_gate(blockInput, num_filters):\n    x = GlobalAveragePooling2D()(blockInput)\n    x = Dense(num_filters//2, activation='relu')(x)\n    x = Dense(num_filters, activation='sigmoid')(x)\n    return Multiply()([blockInput, x])\n\n# sSE\ndef spatial_gate(blockInput):\n    x = Conv2D(1, (1, 1), strides=(1,1), padding=\"same\", activation='sigmoid')(blockInput)\n    return Multiply()([blockInput, x])\n\n# SE\ndef se_block(blockInput, num_filters):\n    return Add()([channel_gate(blockInput, num_filters), spatial_gate(blockInput)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6652f362757a6c85a421ff0795bc8a8ad226a7df"},"cell_type":"code","source":"# Build model\ndef build_model(input_layer, start_neurons = 16, DropoutRatio = 0.5):\n    # 101 -> 50\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n    conv1 = residual_block(conv1,start_neurons * 1)\n    conv1 = residual_block(conv1,start_neurons * 1, True)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(DropoutRatio/2)(pool1)\n\n    # 50 -> 25\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = residual_block(conv2,start_neurons * 2)\n    conv2 = residual_block(conv2,start_neurons * 2, True)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(DropoutRatio)(pool2)\n\n    # 25 -> 12\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = residual_block(conv3,start_neurons * 4)\n    conv3 = residual_block(conv3,start_neurons * 4, True)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(DropoutRatio)(pool3)\n\n    # 12 -> 6\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    conv4 = residual_block(conv4,start_neurons * 8)\n    conv4 = residual_block(conv4,start_neurons * 8, True)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(DropoutRatio)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n    convm = residual_block(convm,start_neurons * 16)\n    convm = residual_block(convm,start_neurons * 16, True)\n    \n    FC = (Flatten())(convm)\n    outputs = (Dense(4096))(FC) \n    outputs = (Activation('relu'))(outputs)\n    outputs = (Dropout(DropoutRatio/2))(outputs)\n    outputs = (Dense(256))(outputs)\n    outputs = (Activation('relu'))(outputs)\n    outputs = (Dropout(DropoutRatio/4))(outputs)\n    outputs = (Dense(16))(outputs) \n    outputs = (Activation('relu'))(outputs)\n    outputs = (Dropout(DropoutRatio/4))(outputs)\n    outputs = (Dense(1))(outputs)\n    outputs = (Activation('sigmoid'))(outputs)\n    \n    return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0d0d28edf7a46cee68ee2b793a8a3b33eeb0ea9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4f4f0ad2891d1246ee00b1a4b3dc626200942aa"},"cell_type":"markdown","source":"# 4. Train my model"},{"metadata":{"_uuid":"22591c6a453d22da0ed3642aff35cadb5a3e7444"},"cell_type":"markdown","source":"## 4.1. Augmentation"},{"metadata":{"trusted":true,"_uuid":"12e78ac299068760200e987ed878ede37bfcf270"},"cell_type":"code","source":"def do_brightness_multiply(image, alpha=1):\n    image = alpha*image\n    image = np.clip(image, 0, 1)\n    return image\n\ndef do_brightness_aug(x_train, alpha):\n    tmp = []\n    for i in np.arange(x_train[:, :, :, 0].shape[0]):\n        x_train_bright = do_brightness_multiply(x_train[i, :, :, 0], alpha=(100+alpha)/100)\n        tmp.append(x_train_bright.reshape(1, img_size_target, img_size_target, 1))\n\n    x_train_aug = np.concatenate(tmp, axis=0)\n    del tmp, x_train_bright; gc.collect()\n    return x_train_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78aa121ac79fee08a13c3e6329db30f8c8a1cf2f"},"cell_type":"code","source":"def do_brightness_multiply2(image, mask, alpha=1):\n    image = alpha*image\n    image = np.clip(image, 0, 1)\n    return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7b0e5e47db281400c236848b9b2ed1a81a7b9d9"},"cell_type":"code","source":"def do_flip_transpose2(image, mask, type=0):\n    #choose one of the 8 cases\n    if type==1: #rotate90\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    if type==2: #rotate180\n        image = cv2.flip(image,-1)\n    if type==3: #rotate270\n        image = image.transpose(1,0)\n        image = cv2.flip(image,0)\n    if type==4: #flip left-right\n        image = cv2.flip(image,1)\n    if type==5: #flip up-down\n        image = cv2.flip(image,0)\n    if type==6:\n        image = cv2.flip(image,1)\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    if type==7:\n        image = cv2.flip(image,0)\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    return image, mask\n\ndef do_flip_transpose(image, type=0):\n    #choose one of the 8 cases\n    if type==1: #rotate90\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    if type==2: #rotate180\n        image = cv2.flip(image,-1)\n    if type==3: #rotate270\n        image = image.transpose(1,0)\n        image = cv2.flip(image,0)\n    if type==4: #flip left-right\n        image = cv2.flip(image,1)\n    if type==5: #flip up-down\n        image = cv2.flip(image,0)\n    if type==6:\n        image = cv2.flip(image,1)\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    if type==7:\n        image = cv2.flip(image,0)\n        image = image.transpose(1,0)\n        image = cv2.flip(image,1)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7abcef80f5710e97a3e8d0032ef0260bc1ef52b9"},"cell_type":"code","source":"#Data augmentation\ndef do_flip_transpose_aug2(x_train, y_train, flip_type):\n    tmp_x = []\n    tmp_y = []\n    for i in np.arange(x_train[:, :, :, 0].shape[0]):\n        x_train_flip, y_train_flip = do_flip_transpose2(x_train[i, :, :, 0], y_train[i], type=flip_type)\n        tmp_x.append(x_train_flip.reshape(1, img_size_target, img_size_target, 1))\n        tmp_y.append(y_train_flip)\n        \n    x_train_aug = np.concatenate(tmp_x, axis=0)\n    y_train_aug = np.array(tmp_y)\n    del tmp_x, tmp_y, x_train_flip, y_train_flip; gc.collect()\n    return x_train_aug, y_train_aug\n\ndef do_flip_transpose_aug(x_train, flip_type):\n    tmp_x = []\n    for i in np.arange(x_train[:, :, :, 0].shape[0]):\n        x_train_flip = do_flip_transpose(x_train[i, :, :, 0], type=flip_type)\n        tmp_x.append(x_train_flip.reshape(1, img_size_target, img_size_target, 1))\n        \n    x_train_aug = np.concatenate(tmp_x, axis=0)\n    del tmp_x, x_train_flip; gc.collect()\n    return x_train_aug","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5571ecb458a6ba4322ba9e509af5e39038d71d99"},"cell_type":"code","source":"def random_aug(image, mask):\n    np.random.seed()\n    i = np.random.randint(0, 8)\n    if i in (4, 5, 6, 7):\n        image, mask = do_flip_transpose2(image, mask, 4)\n    if i in (2, 6):\n        image, mask = do_brightness_multiply2(image, mask, 1.08)\n    if i in (3, 7):\n        image, mask = do_brightness_multiply2(image, mask, 0.92)\n    return image, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e98746b753a9ce39cf876c8dcc397636723431f5"},"cell_type":"code","source":"from numpy.random import*\ndef batch_generator(x, y, w=1.0, batch_size=32):\n    '''\n    Return a random image from x, y\n    '''\n    while True:\n        rand_index = np.arange(x.shape[0])\n        np.random.seed()\n        shuffle(rand_index)\n        current_index = 0\n        while current_index + batch_size <= x.shape[0]:\n            batch_index = rand_index[current_index:current_index + batch_size]\n            tmp_x = []\n            tmp_y = []\n            tmp_w = []\n            for i in batch_index:\n                image, mask = random_aug(x[i], y[i])\n                if (mask>0.5).sum() < 8:\n                    weight = w\n                else:\n                    weight = 1.0\n                tmp_x.append(image.reshape(1, img_size_target, img_size_target, 1))\n                tmp_y.append(mask)\n                tmp_w.append(weight)\n            image = np.concatenate(tmp_x, axis=0)\n            mask = np.array(tmp_y)\n            weight = np.array(tmp_w)\n            current_index += batch_size\n            yield image, mask, weight","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"12181f3fd9aa42282ce3b3d5a70eef35673ebc7a"},"cell_type":"markdown","source":"## 4.2. Model compilation"},{"metadata":{"trusted":true,"_uuid":"bcec3e75929b17db36392843463638b198f7e99b"},"cell_type":"code","source":"input_layer = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 16, dropout_rate)\nmodel = Model(input_layer, output_layer)\nc = optimizers.adam(lr = start_lr)\nmodel.compile(loss='binary_crossentropy', optimizer=c, metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccda6334917e4afeae1fc1dd366f8e207517eda4"},"cell_type":"markdown","source":"## 4.3. Training"},{"metadata":{"trusted":true,"_uuid":"229d03b89e6582e933a07604138854a654e40eaf","scrolled":false},"cell_type":"code","source":"model_checkpoint = ModelCheckpoint(save_model_name, monitor='val_acc', mode = 'max', save_best_only=True, verbose=1)\n    \nhistory = model.fit_generator(\n                    generator=batch_generator(x_train, y_train, weight, batch_size),\n                    steps_per_epoch=x_train.shape[0]//batch_size,\n                    validation_data=batch_generator(x_valid, y_valid, 1.0, 1),\n                    validation_steps=x_valid.shape[0],\n                    epochs=epochs,\n                    callbacks=[model_checkpoint], \n                    shuffle=True,\n                    verbose=1)\n\nmodel.save(save_end_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3ecb1babce47603a6dc6724a5dee2e154882a73","scrolled":true},"cell_type":"code","source":"model = load_model(transfar_model_01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82d3a547c014b9bc91c89127f5961014e04928fb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76c951fcb974445bc20dada1105715147454fc27"},"cell_type":"markdown","source":"# 5. Create prediction"},{"metadata":{"trusted":true,"_uuid":"4321b4b3c0de0501722044337c41fe2fb5323428"},"cell_type":"code","source":"def predict_result(model,x_test,img_size_target):\n    preds_test  = 0.250 * model.predict(x_test); print(\"Done - preds_test: 0, 1\")\n    preds_test += 0.125 * model.predict(do_brightness_aug(x_test, 8)); print(\"Done - preds_test: 2\")\n    preds_test += 0.125 * model.predict(do_brightness_aug(x_test, -8)); print(\"Done - preds_test: 3\")\n    \n    x_test4 = do_flip_transpose_aug(x_test, 4)\n    preds_test4 = model.predict(x_test4)\n    preds_test4 = preds_test4\n    preds_test += 0.250 * preds_test4; print(\"Done - preds_test: 4, 5\")\n    preds_test4 = model.predict(do_brightness_aug(x_test4, 8))\n    preds_test4 = preds_test4\n    preds_test += 0.125 * preds_test4; print(\"Done - preds_test: 6\")\n    preds_test4 = model.predict(do_brightness_aug(x_test4, -8))\n    preds_test4 = preds_test4\n    preds_test += 0.125 * preds_test4; print(\"Done - preds_test: 7\")\n    del x_test4, preds_test4; gc.collect()\n    \n    return preds_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1c6e727b728c21f94c80ecfd942e183264794869"},"cell_type":"code","source":"preds_valid = predict_result(model, x_valid, img_size_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d13dc198a1417c64440eca190ddf1e3415118cb5"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nthresholds = np.linspace(0.2, 0.8, 101)\naccs = np.array([accuracy_score(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1901ce9a9f22f064cb9eb0c1de04250a8ee63ab"},"cell_type":"code","source":"threshold_best_index = np.argmax(accs) \nacc_best = accs[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]\n\nplt.plot(thresholds, accs)\nplt.plot(threshold_best, acc_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, acc_best))\nplt.legend()\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8304ce30d8ddb3c00328d66b2b33cec9defd746c"},"cell_type":"code","source":"preds_valid_bi = np.squeeze(preds_valid > threshold_best)*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c2ba9e40c953e62470446c22139c5ad88132d0a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"940976e09738ae5e74bf4f01a792e6fa1c380f96"},"cell_type":"markdown","source":"# 6. Now, it's time to train ourselves!"},{"metadata":{"_uuid":"fa948eab882a41d6146d4aa6fd1d2cd46a65012e"},"cell_type":"markdown","source":"## 6.1. Preparation"},{"metadata":{"trusted":true,"_uuid":"0d83b3b8ba54f92dedbc8b1623bce57aff99fd1b"},"cell_type":"code","source":"x_train_org = np.array([downsample(np.squeeze(x_train_org[i])) for i in np.arange(x_train_org.shape[0])])\ny_train_org = np.array([downsample(np.squeeze(y_train_org[i])) for i in np.arange(y_train_org.shape[0])])\nx_valid_org = np.array([downsample(np.squeeze(x_valid_org[i])) for i in np.arange(x_valid_org.shape[0])])\ny_valid_org = np.array([downsample(np.squeeze(y_valid_org[i])) for i in np.arange(y_valid_org.shape[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7959f5a5acec6340e784c781399167b00a194e01"},"cell_type":"code","source":"import cv2\nfrom IPython.display import display, Image\ndef cvshow(image, format='.png', rate=255 ):\n    decoded_bytes = cv2.imencode(format, image*rate)[1].tobytes()\n    display(Image(data=decoded_bytes))\n    return","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ddc353291c395c7cf4eccd461ec31a3945e8218c"},"cell_type":"markdown","source":"## 6.2. Without salt"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f6134a1cc45944c0ab247ee59b4eb4b265988c83"},"cell_type":"code","source":"def imgtile(imgs,tile_w):\n    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n    return np.hstack(np.hstack(r))\n\nprint(\"Without salt\")\ntiled = imgtile(x_train_org[y_train==0][:20],10)\ncvshow(tiled)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d406694c0dbf6d461c31c1172e2c5040fd882c15"},"cell_type":"markdown","source":"## 6.3. With salt"},{"metadata":{"trusted":true,"_uuid":"64e51a843af15de56884b531af9d63efadb00992"},"cell_type":"code","source":"def imgtile(imgs,tile_w):\n    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n    return np.hstack(np.hstack(r))\n\nprint(\"With salt\")\ntiled = imgtile(x_train_org[y_train==1][:20],10)\ncvshow(tiled)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9279b951d1eefdbc50cddbfdb22f033b62652c15"},"cell_type":"markdown","source":"## 6.4. My trained model does not know the infomation of salt area, but..."},{"metadata":{"trusted":true,"_uuid":"b6c84b31cd39729ed9e792a3d5330cc4fa2b5e03"},"cell_type":"code","source":"def imgtile(imgs,tile_w):\n    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n    return np.hstack(np.hstack(r))\n\ntiled = imgtile(x_train_org[y_train==1][:20],10)\ncvshow(tiled)\ntiled = imgtile(y_train_org[y_train==1][:20],10)\ncvshow(tiled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f14f6f40050edee222001550623aac1d89f487d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87a0a8066b6a8aece786f2a53c5d5dfb3f01562a"},"cell_type":"markdown","source":"# 7. Please beat my model!"},{"metadata":{"_uuid":"4d6f90baf4518b72cb230c21224caf6b8b739c00"},"cell_type":"markdown","source":"## Q. Which images contain salt?"},{"metadata":{"trusted":true,"_uuid":"a63205fa6aad30b6909e39c8b17302f8bd8858be"},"cell_type":"code","source":"start = np.random.randint(x_valid_org.shape[0])\n\ntiled = imgtile(x_valid_org[start:start+5],5)\ncvshow(tiled)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f8eaf4f7f96b7a274d1a7030996adad55e0f081"},"cell_type":"markdown","source":"## What's your answer??"},{"metadata":{"trusted":true,"_uuid":"93b77cccda40a466102f355c026353f3e82bf10a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f753d2b8b0b808c0d744f2a7ee9eb9bb076c8b0"},"cell_type":"markdown","source":"## My model's answer is..."},{"metadata":{"trusted":true,"_uuid":"42b9623e3622049619642739ef6739f61eb3eb89"},"cell_type":"code","source":"preds_valid_bi[start:start+5].tolist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5b1afd8b1a9db21e14e0fce76a45ebfb7d82258"},"cell_type":"markdown","source":"## A. Answer"},{"metadata":{"trusted":true,"_uuid":"55249ac29d2d847d419920bda1ad4aaa4e97982b"},"cell_type":"code","source":"answer = np.any(y_valid_org[start:start+5]==1, axis=(1,2))*1\nprint(\"{}\".format(answer.tolist()))\ntiled = imgtile(x_valid_org[start:start+5],5)\ncvshow(tiled)\ntiled = imgtile(y_valid_org[start:start+5],5)\ncvshow(tiled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e728aeebc863a9807e3e405e79673cf58a4bd55"},"cell_type":"code","source":"from sklearn import metrics\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfpr, tpr, thresholds = metrics.roc_curve(y_valid, preds_valid)\n\nauc = metrics.auc(fpr, tpr)\n\nplt.figure(figsize=(8,8))\nplt.rcParams[\"font.size\"] = 18\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.title('ROC curve (acc = %.3f)'%accuracy_score(y_valid, preds_valid_bi))\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"813a670451e73f20c3ce38bed954823307cf7ef0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ad92d5b9d40734fde28af11f4ed901449c4124d"},"cell_type":"markdown","source":"# 8. Model structure"},{"metadata":{"trusted":true,"_uuid":"2e50e3f1577558fc2e4626df8ad96a5be3f9bc1d","scrolled":false},"cell_type":"code","source":"from keras.utils import plot_model\nfrom keras.preprocessing.image import load_img\nplot_model(model, show_shapes=True, show_layer_names=False, to_file='./model.png')\nim = load_img('./model.png')\nim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f96b89f830806e0d52e57dbb4dd0113455a1c441"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44672d70d21245940263ee728752a396c1ba73e9"},"cell_type":"code","source":"import time\nfrom datetime import datetime, timedelta, timezone\nfrom contextlib import contextmanager\nJST = timezone(timedelta(hours=+9), 'JST')\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} -> done in {:.0f}s\".format(title, time.time() - t0))\n    print(\"Executed time -> {}\\n\".format(datetime.now(JST)))\n\nwith timer('end'):\n    print('finish!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8f4bd44fb292c2b5d3ee908b73e4b753849f178"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}