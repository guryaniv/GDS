{"cells":[{"metadata":{"trusted":true,"_uuid":"e34ef6128dcfff76f57c9b7d456b3f5ec1627a51"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')\nsns.set(font_scale=1.6)\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b097d479b9d7c8c6c842f208452cbfb0a8df973"},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nenv = twosigmanews.make_env()\n(market_train_df, news_train_df) = env.get_training_data()\n\nnews_train_df['subjects'] = news_train_df['subjects'].str.findall(f\"'([\\w\\./]+)'\")\nnews_train_df['audiences'] = news_train_df['audiences'].str.findall(f\"'([\\w\\./]+)'\")\nnews_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")\n\n(market_train_df.shape, news_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"773d2c262e09f4941205404530836d53de8ba2b2"},"cell_type":"code","source":"# We will reduce the number of samples for memory reasons\ntoy = False\n\nif toy:\n    market_train_df = market_train_df.tail(100_000)\n    news_train_df = news_train_df.tail(300_000)\nelse:\n    market_train_df = market_train_df.tail(3_000_000)\n    news_train_df = news_train_df.tail(6_000_000)\n\n(market_train_df.shape, news_train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a14ab84bb84884c6fc2360c89991e137ce443c6"},"cell_type":"markdown","source":"# Data Generator"},{"metadata":{"trusted":true,"_uuid":"5ea137f942ac9eea666458fa5703445e1df1fe79"},"cell_type":"code","source":"def generator(data, lookback, min_index, max_index,\n              shuffle=False, batch_size=128, step=1):\n    if max_index is None:\n        max_index = data.shape[0] - 1\n        \n    i = min_index + lookback\n    while True:\n        # Select the rows that will be used for the batch\n        if shuffle:\n            rows = np.random.randint(min_index + lookback, size=batch_size)\n        else:\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += rows.shape[0]\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n                \n        samples = np.zeros((len(rows),\n                   lookback // step,\n                   data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j]][1]\n            \n        yield samples, targets","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efe68f0b5c3eaafd7def4815eb96451e6bb9976a"},"cell_type":"markdown","source":"# Learning the Models "},{"metadata":{"_uuid":"d980ff39c1d44b544ce427877bed73676c51fe01"},"cell_type":"markdown","source":"Each model is trained on a particular asset. The time series data for that particular asset needs to be normalized."},{"metadata":{"trusted":true,"_uuid":"03f5cfb992a821a3e53e7aaa4139caf50f776b30"},"cell_type":"code","source":"from keras.callbacks import Callback\n\nclass EarlyStoppingByLossVal(Callback):\n    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n        super(Callback, self).__init__()\n        self.monitor = monitor\n        self.value = value\n        self.verbose = verbose\n\n    def on_epoch_end(self, epoch, logs={}):\n        current = logs.get(self.monitor)\n        if current is None:\n            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n\n        if current < self.value:\n            if self.verbose > 0:\n                print(\"Epoch %05d: early stopping THR\" % epoch)\n            self.model.stop_training = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fc9313345a93e94a9b5df6f04425e8550276cd4"},"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop, Adagrad\n\nlookback = 30 \nbatch_size = 1024\nsteps_per_epoch = 100\nepochs = 10\ndata_split = 0.8\nstep = 1\n\ndef generators(market_data_float):\n    l = market_data_float.shape[0]\n    train_gen = generator(market_data_float,\n                          min_index=0,\n                          max_index=int(data_split * l),\n                          batch_size=batch_size,\n                          lookback=lookback,\n                          step=step)\n    \n    val_gen = generator(market_data_float,\n                        min_index=int(data_split * l),\n                        max_index=None,\n                        batch_size=batch_size,\n                        lookback=lookback,\n                        step=step)\n    \n    return (train_gen, val_gen)\n\ndef learn_model(market_data_float):\n    (train_gen, val_gen) = generators(market_data_float)\n    input_shape = (None, market_data_float.shape[-1])\n    \n    model = Sequential()\n    model.add(layers.GRU(4, input_shape=input_shape))   \n    model.add(layers.Dense(1))\n    model.compile(optimizer=Adagrad(), loss='mae')\n    \n    callbacks = [EarlyStoppingByLossVal(monitor='val_loss', value=0.00001, verbose=1)]\n    history = model.fit_generator(train_gen,\n                                  steps_per_epoch=steps_per_epoch,\n                                  epochs=10,\n                                  validation_data=val_gen,\n                                  validation_steps=100,\n                                  callbacks=callbacks)\n    \n    return (model, history)\n\ndef learn_models(market_train_df, Histories):\n    for asset_code, market_data in tqdm(market_train_df.groupby('assetCode')):\n        # drop the non-numeric columns and handle the nans.\n        market_float_data = market_data.drop(['assetCode', 'assetName', 'time'], axis=1).fillna(0)\n        \n        # normalize the data\n        scaler = StandardScaler().fit(market_float_data)\n        \n        # learn a model using the normalized data\n        (model, history) = learn_model(scaler.transform(market_float_data))\n        \n        # save the history\n        Histories[asset_code] = history\n        yield asset_code, (scaler, model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc7064ad2ce5a095983d037b2a5bc603cd7752b2"},"cell_type":"markdown","source":"# Random Sample the Assets"},{"metadata":{"trusted":false,"_uuid":"f148143adef195eab68b76ea083f84bbb7c426e4"},"cell_type":"code","source":"n = 5\nn_random_assets = np.random.choice(market_train_df.assetCode.unique(), n)\n\nmarket_train_sampled_df = market_train_df[market_train_df.assetCode.isin(n_random_assets)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9beb8beacfd4fafb2d3dfa2d1df070dc7f95c04a"},"cell_type":"code","source":"(fig, ax) = plt.subplots(figsize=(15, 8))\n\nmarket_train_sampled_df.groupby('assetCode').plot(x='time', y='close', ax=ax)\n\nax.legend(n_random_assets)\nplt.xlabel('time')\nplt.ylabel('close')\nplt.title('Closing Price of %i random assets' % n)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cb8d9bf794909134085839b7c841fcbe0d14350e"},"cell_type":"code","source":"Histories = {}\nModels = dict(learn_models(market_train_sampled_df, Histories))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8584410369c7f6a541bd2238604bb14cf27a8eea"},"cell_type":"markdown","source":"# Unscaled loss plots"},{"metadata":{"trusted":false,"_uuid":"88d1d7e11be1b141fa6a7e41629a0078608e5be2"},"cell_type":"code","source":"for asset, history in Histories.items():\n    (fig, ax) = plt.subplots(figsize=(15, 8))\n\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(loss) + 1) \n    plt.plot(epochs, loss, 'bo', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n\n    plt.title(asset)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}