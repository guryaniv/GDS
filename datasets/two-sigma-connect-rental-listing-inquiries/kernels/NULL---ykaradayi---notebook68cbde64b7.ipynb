{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b6913d0f-8103-24fc-856d-6323e6a5e02e"
      },
      "source": [
        "No categorical - no desc - no feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f88fed6b-6060-2853-413c-8ba268807718"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy import sparse\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0e0c3f5-e939-1969-018f-371e5c2f3b1f"
      },
      "outputs": [],
      "source": [
        "#input data\n",
        "train_df=pd.read_json('../input/train.json')\n",
        "test_df=pd.read_json('../input/test.json')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cbf910c-f07b-8f94-cbb6-75a9dac56a5f"
      },
      "outputs": [],
      "source": [
        "features_to_use  = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]  #numeric features\n",
        "\n",
        "# count of photos #\n",
        "train_df[\"num_photos\"] = train_df[\"photos\"].apply(len)\n",
        "test_df[\"num_photos\"] = test_df[\"photos\"].apply(len)\n",
        "\n",
        "# count of \"features\" #\n",
        "train_df[\"num_features\"] = train_df[\"features\"].apply(len)\n",
        "test_df[\"num_features\"] = test_df[\"features\"].apply(len)\n",
        "\n",
        "# count of words present in description column #\n",
        "train_df[\"num_description_words\"] = train_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
        "test_df[\"num_description_words\"] = test_df[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
        "\n",
        "# convert the created column to datetime object so as to extract more features \n",
        "train_df[\"created\"] = pd.to_datetime(train_df[\"created\"])\n",
        "test_df[\"created\"] = pd.to_datetime(test_df[\"created\"])\n",
        "\n",
        "# Let us extract some features like year, month, day, hour from date columns #\n",
        "train_df[\"created_year\"] = train_df[\"created\"].dt.year\n",
        "test_df[\"created_year\"] = test_df[\"created\"].dt.year\n",
        "\n",
        "train_df[\"created_month\"] = train_df[\"created\"].dt.month\n",
        "test_df[\"created_month\"] = test_df[\"created\"].dt.month\n",
        "\n",
        "train_df[\"created_day\"] = train_df[\"created\"].dt.day\n",
        "test_df[\"created_day\"] = test_df[\"created\"].dt.day\n",
        "\n",
        "#train_df[\"created_hour\"] = train_df[\"created\"].dt.hour\n",
        "#test_df[\"created_hour\"] = test_df[\"created\"].dt.hour\n",
        "\n",
        "# adding all these new features to use list #\n",
        "features_to_use.extend([\"num_photos\", \"num_features\", \"num_description_words\", \"created_year\", \"created_month\", \"created_day\", \"listing_id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3085bfa5-bc2b-bbbd-11ec-73691f7867a3"
      },
      "outputs": [],
      "source": [
        "# Building_level:\n",
        "train_df.ix[train_df.building_id == '0', 'new_building_id'] = train_df['building_id'] + train_df['manager_id']\n",
        "train_df.ix[train_df.building_id != '0', 'new_building_id'] = train_df['building_id']\n",
        "\n",
        "a=[np.nan]*len(train_df)\n",
        "building_level={}\n",
        "\n",
        "for bid in train_df['new_building_id'].values:\n",
        "    building_level[bid]=[0,0,0]\n",
        "    \n",
        "for j in range(train_df.shape[0]):\n",
        "    rec=train_df.iloc[j]\n",
        "    if rec['interest_level']=='low':\n",
        "        building_level[rec['new_building_id']][0]+=1\n",
        "    if rec['interest_level']=='medium':\n",
        "        building_level[rec['new_building_id']][1]+=1\n",
        "    if rec['interest_level']=='high':\n",
        "        building_level[rec['new_building_id']][2]+=1\n",
        "        \n",
        "for j in range(train_df.shape[0]):    \n",
        "        rec=train_df.iloc[j]\n",
        "        occurance = sum(building_level[rec['new_building_id']])\n",
        "        if occurance!=0:\n",
        "            a[j]= (building_level[rec['new_building_id']][0]*0.0 + building_level[rec['new_building_id']][1]*1.0 \\\n",
        "                   + building_level[rec['new_building_id']][2]*2.0) / occurance\n",
        "\n",
        "train_df['building_level']=a\n",
        "\n",
        "test_df.ix[test_df.building_id == '0', 'new_building_id'] = test_df['building_id'] + test_df['manager_id']\n",
        "test_df.ix[test_df.building_id != '0', 'new_building_id'] = test_df['building_id']\n",
        "\n",
        "b=[]\n",
        "for i in test_df['new_building_id'].values:\n",
        "    if i not in building_level.keys():\n",
        "        b.append(np.nan)\n",
        "    else:\n",
        "        occurance = sum(building_level[i])\n",
        "        b.append((building_level[i][0]*0.0 + building_level[i][1]*1.0 \\\n",
        "                   + building_level[i][2]*2.0) / occurance)\n",
        "\n",
        "test_df['building_level']=b\n",
        "\n",
        "train_df = train_df.drop(['new_building_id'], axis=1)\n",
        "test_df = test_df.drop(['new_building_id'], axis=1)\n",
        "\n",
        "features_to_use.append('building_level') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a75c1169-d538-6b83-2c28-d8688e966986"
      },
      "outputs": [],
      "source": [
        "#Manager_level\n",
        "#### Prepare train data\n",
        "index=list(range(train_df.shape[0]))\n",
        "random.shuffle(index)\n",
        "a=[np.nan]*len(train_df)\n",
        "b=[np.nan]*len(train_df)\n",
        "c=[np.nan]*len(train_df)\n",
        "\n",
        "for i in range(5):\n",
        "    building_level={}\n",
        "    for j in train_df['manager_id'].values:\n",
        "        building_level[j]=[0,0,0]\n",
        "    test_index=index[int((i*train_df.shape[0])/5):int(((i+1)*train_df.shape[0])/5)]\n",
        "    train_index=list(set(index).difference(test_index))\n",
        "    for j in train_index:\n",
        "        temp=train_df.iloc[j]\n",
        "        if temp['interest_level']=='low':\n",
        "            building_level[temp['manager_id']][0]+=1\n",
        "        if temp['interest_level']=='medium':\n",
        "            building_level[temp['manager_id']][1]+=1\n",
        "        if temp['interest_level']=='high':\n",
        "            building_level[temp['manager_id']][2]+=1\n",
        "    for j in test_index:\n",
        "        temp=train_df.iloc[j]\n",
        "        if sum(building_level[temp['manager_id']])!=0:\n",
        "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
        "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
        "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
        "train_df['manager_level_low']=a\n",
        "train_df['manager_level_medium']=b\n",
        "train_df['manager_level_high']=c\n",
        "\n",
        "#### Prepare test data\n",
        "a=[]\n",
        "b=[]\n",
        "c=[]\n",
        "building_level={}\n",
        "for j in train_df['manager_id'].values:\n",
        "    building_level[j]=[0,0,0]\n",
        "for j in range(train_df.shape[0]):\n",
        "    temp=train_df.iloc[j]\n",
        "    if temp['interest_level']=='low':\n",
        "        building_level[temp['manager_id']][0]+=1\n",
        "    if temp['interest_level']=='medium':\n",
        "        building_level[temp['manager_id']][1]+=1\n",
        "    if temp['interest_level']=='high':\n",
        "        building_level[temp['manager_id']][2]+=1\n",
        "\n",
        "for i in test_df['manager_id'].values:\n",
        "    if i not in building_level.keys():\n",
        "        a.append(np.nan)\n",
        "        b.append(np.nan)\n",
        "        c.append(np.nan)\n",
        "    else:\n",
        "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
        "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
        "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
        "test_df['manager_level_low']=a\n",
        "test_df['manager_level_medium']=b\n",
        "test_df['manager_level_high']=c\n",
        "\n",
        "features_to_use.append('manager_level_low') \n",
        "features_to_use.append('manager_level_medium') \n",
        "features_to_use.append('manager_level_high')"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}