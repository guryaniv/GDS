{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Let's load in some basics and make sure our files are all here\nimport numpy as np\nimport pandas as pd\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\nsample_submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c0ff8f5a2e049f5761d47468d65fd2b6b456ebb"},"cell_type":"markdown","source":"Our files are here and load without error. Let's check to make sure the columns match and see the submission format."},{"metadata":{"trusted":true,"_uuid":"1af04552eed6d0505deb35d1bdf10a72b4d092f2"},"cell_type":"code","source":"print(test.columns)\nprint(train.columns)\nprint(sample_submission.head(4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13b80d7e02b0e26ced2aa27bedde15b466654957"},"cell_type":"markdown","source":"How much data is there?"},{"metadata":{"trusted":true,"_uuid":"c2a1c076d7f3174afadb3d1de3c3d10c2ae8e590"},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"803583ac2c768df3afa08ae0fd6087d05b61ee91"},"cell_type":"markdown","source":"Let's find a row that is labeled with \"is_turkey\" and play the clip it comes from."},{"metadata":{"trusted":true,"_uuid":"a75d481473aa99a159e26e5db6b1a78a0480620c"},"cell_type":"code","source":"print(train[train['is_turkey']==1].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8410e086700a80969019638c716b6a01993f785"},"cell_type":"code","source":"from IPython.display import YouTubeVideo\nYouTubeVideo(train['vid_id'][1],start=train['start_time_seconds_youtube_clip'][1],end=train['end_time_seconds_youtube_clip'][1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e76eb7b63a972cdc3cd5d8508ab2ee746fcf66d"},"cell_type":"markdown","source":"Yep, that sounds like a turkey!\n\nWe also have some VGGish audio embeddings to take a look at. Let's see what the shape of those are."},{"metadata":{"trusted":true,"_uuid":"4acf2c1fdb041b24307abe418a50c47a3ce5b619"},"cell_type":"code","source":"print(train['audio_embedding'].head())\n\n#see the possible list lengths of the first dimension\nprint(\"train's audio_embedding can have this many frames: \"+ str(train['audio_embedding'].apply(lambda x: len(x)).unique())) \nprint(\"test's audio_embedding can have this many frames: \"+ str(test['audio_embedding'].apply(lambda x: len(x)).unique())) \n\n#see the possible list lengths of the first element\nprint(\"each frame can have this many features: \"+str(train['audio_embedding'].apply(lambda x: len(x[0])).unique()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"500a2e40c736949a12131fe996d520dc86041f9e"},"cell_type":"markdown","source":"For more information on what these features are and where they come from, see [this page.](https://github.com/tensorflow/models/tree/master/research/audioset#input-audio-features)\n\nNow that we've seen what the given data looks like, let's make a prediction using a basic LSTM model. "},{"metadata":{"trusted":true,"_uuid":"fb9abfd615a378579fc8fcf0884b30b23afd70d9","scrolled":false},"cell_type":"code","source":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Bidirectional, LSTM, BatchNormalization, Dropout\nfrom tensorflow.python.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\n#split the training data to have a validation set\ntrain_train, train_val = train_test_split(train)\nxtrain = [k for k in train_train['audio_embedding']]\nytrain = train_train['is_turkey'].values\n\nxval = [k for k in train_val['audio_embedding']]\nyval = train_val['is_turkey'].values\n\n# Pad the audio features so that all are \"10 seconds\" long\nx_train = pad_sequences(xtrain, maxlen=10)\nx_val = pad_sequences(xval, maxlen=10)\n\ny_train = np.asarray(ytrain)\ny_val = np.asarray(yval)\n\n#Define a basic LSTM model\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(10, 128)))\nmodel.add(Dropout(.5))\nmodel.add(Bidirectional(LSTM(128, activation='relu')))\nmodel.add(Dense(1, activation='sigmoid'))\n\n#maybe there is something better to use, but let's use binary_crossentropy\nmodel.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\n#fit on a portion of the training data, and validate on the rest\nmodel.fit(x_train, y_train,\n          batch_size=300,\n          nb_epoch=4,validation_data=(x_val, y_val))\n\n# Get accuracy of model on validation data. It's not AUC but it's something at least!\nscore, acc = model.evaluate(x_val, y_val, batch_size=300)\nprint('Test accuracy:', acc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aac018a6eddfddcf04434c49d43bca759cd141a5"},"cell_type":"markdown","source":"Finally, let's get a prediction to submit. "},{"metadata":{"trusted":true,"_uuid":"d49025f0a75fc36da1f858237233280803e6056a"},"cell_type":"code","source":"test_data = [k for k in test['audio_embedding']]\nsubmission = model.predict_classes(pad_sequences(test_data))\nsubmission = pd.DataFrame({'vid_id':test['vid_id'].values,'is_turkey':[x for y in submission for x in y]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"374b17df3212371cd7d43d5b0d130e2506da1173"},"cell_type":"code","source":"print(submission.head()) #check to see that it looks like the sample submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4f1308516d4107903af92b3c6d2dea7a027e7ad"},"cell_type":"code","source":"submission.to_csv('lstm_starter.csv', index=False) #drop the index so it matches the submission format.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}