{"nbformat_minor": 1, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"version": "3.6.1", "file_extension": ".py", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "cells": [{"source": ["## Here we'll try to encode categorical features..."], "cell_type": "markdown", "metadata": {"_uuid": "b90dae453f1bc0d53ff0080c51a3a4fbbf712b2a", "_execution_state": "idle", "_cell_guid": "1baf944f-0a93-4f4a-babb-9c58cd4e78c9"}}, {"source": ["import numpy as np\n", "import pandas as pd\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "import xgboost as xgb \n", "from sklearn.metrics import r2_score\n", "\n", "from IPython.display import display, HTML\n", "# Shows all columns of a dataframe\n", "def show_dataframe(X, rows = 2):\n", "    display(HTML(X.to_html(max_rows=rows)))"], "cell_type": "code", "metadata": {"_uuid": "69f55f2a1d3e594834856d997e5d9049d26df7ff", "_execution_state": "idle", "collapsed": true, "_cell_guid": "83158ee7-602f-4b5c-89f8-4f9438d06dfc"}, "execution_count": null, "outputs": []}, {"source": ["# Datasets\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "cell_type": "code", "metadata": {"_uuid": "001bd35fb90497e6c7aeb374920f9cf8b6ca50a3", "_execution_state": "idle", "collapsed": true, "_cell_guid": "d599a9d3-d2cb-4dc1-b9ca-e2cb89abd63d"}, "execution_count": null, "outputs": []}, {"source": ["# Categorical features\n", "cat_cols = []\n", "for c in train.columns:\n", "    if train[c].dtype == 'object':\n", "        cat_cols.append(c)\n", "print('Categorical columns:', cat_cols)\n", "\n", "# Dublicate features\n", "d = {}; done = []\n", "cols = train.columns.values\n", "for c in cols: d[c]=[]\n", "for i in range(len(cols)):\n", "    if i not in done:\n", "        for j in range(i+1, len(cols)):\n", "            if all(train[cols[i]] == train[cols[j]]):\n", "                done.append(j)\n", "                d[cols[i]].append(cols[j])\n", "dub_cols = []\n", "for k in d.keys():\n", "    if len(d[k]) > 0: \n", "        # print k, d[k]\n", "        dub_cols += d[k]        \n", "print('Dublicates:', dub_cols)\n", "\n", "# Constant columns\n", "const_cols = []\n", "for c in cols:\n", "    if len(train[c].unique()) == 1:\n", "        const_cols.append(c)\n", "print('Constant cols:', const_cols)"], "cell_type": "code", "metadata": {"_uuid": "ace0a1497c1adc835c9ef8a00f04a24578309198", "_execution_state": "idle", "_cell_guid": "d29b4cd8-5339-4239-987d-9d34c5f822b3"}, "execution_count": null, "outputs": []}, {"source": ["Figures below show categorical features (on the left) sorted by means of **y**'s grouped by labels. On the right there are corresponding **mean**'s, **std**'s (filled blue), **max**'s (green line) and **min**'s (red line)."], "cell_type": "markdown", "metadata": {"_uuid": "48db05580ee3e100ac8065d1f1272ffcbbd80f81", "_execution_state": "idle", "_cell_guid": "f698f747-e1c2-46aa-b5c0-4dce42c01af0"}}, {"source": ["plt.figure(figsize=(20,32))\n", "for i in range(len(cat_cols)):\n", "    c = cat_cols[i]\n", "    \n", "    means = train.groupby(c).y.mean()\n", "    stds = train.groupby(c).y.std().fillna(0)\n", "    maxs = train.groupby(c).y.max()\n", "    mins = train.groupby(c).y.min()\n", "    \n", "    ddd = pd.concat([means, stds, maxs, mins], axis=1); \n", "    ddd.columns = ['means', 'stds', 'maxs', 'mins']\n", "    ddd.sort_values('means', inplace=True)\n", "    \n", "    plt.subplot(8,2,2*i+1)\n", "    ax = sns.countplot(train[c], order=ddd.index.values)\n", "    for p in ax.patches:\n", "        x=p.get_bbox().get_points()[:,0]\n", "        y=p.get_bbox().get_points()[1,1]\n", "        ax.annotate('{:.0f}'.format(y), (x.mean(), y), ha='center', va='bottom')\n", "    \n", "    plt.subplot(8,2,2*i+2)\n", "    plt.fill_between(range(len(train[c].unique())), \n", "                     ddd.means.values - ddd.stds.values,\n", "                     ddd.means.values + ddd.stds.values,\n", "                     alpha=0.3\n", "                    )\n", "    plt.xticks(range(len(train[c].unique())), ddd.index.values)\n", "    plt.plot(ddd.means.values, color='b', marker='.', linestyle='dashed', linewidth=0.7)\n", "    plt.plot(ddd.maxs.values, color='g', linestyle='dashed', linewidth=0.7)\n", "    plt.plot(ddd.mins.values, color='r', linestyle='dashed', linewidth=0.7)\n", "    plt.xlabel(c + ': Maxs, Means, Mins and +- STDs')\n", "    plt.ylim(55, 270)"], "cell_type": "code", "metadata": {"_uuid": "04812a16839d59f815bd5dbd000734ab5c620afd", "_execution_state": "idle", "_cell_guid": "7a58392b-c0ce-45aa-a846-ba834992c0d0"}, "execution_count": null, "outputs": []}, {"source": ["# Glue train + test\n", "train['eval_set'] = 0; test['eval_set'] = 1\n", "df = pd.concat([train, test], axis=0, copy=True)\n", "# Reset index\n", "df.reset_index(drop=True, inplace=True)"], "cell_type": "code", "metadata": {"_uuid": "87732c13a13692c926bc445460cad7dbae024b7f", "_execution_state": "idle", "collapsed": true, "_cell_guid": "134404c2-d1ea-4d39-ba10-5ae6326a3ced"}, "execution_count": null, "outputs": []}, {"source": ["### Categorical feature encoding\n", "In the next cell for every categorical column from **cat_cols** we'll find **mean** of **y's** for every label using **.groupby()**. Then we sort labels by values of **means**. Now, when labels are sorted, they can be encoded by numbers from *0* to *numbers of labels - 1*."], "cell_type": "markdown", "metadata": {"_uuid": "203b4e78e6b03e589ea7d4b143a8266a9e4adb68", "_execution_state": "idle", "_cell_guid": "09f31dc8-a5d9-43e6-a661-2fd2cc9db634"}}, {"source": ["def add_new_col(x):\n", "    if x not in new_col.keys(): \n", "        # set n/2 x if is contained in test, but not in train \n", "        # (n is the number of unique labels in train)\n", "        # or an alternative could be -100 (something out of range [0; n-1]\n", "        return int(len(new_col.keys())/2)\n", "    return new_col[x] # rank of the label\n", "\n", "for c in cat_cols:\n", "    # get labels and corresponding means\n", "    new_col = train.groupby(c).y.mean().sort_values().reset_index()\n", "    # make a dictionary, where key is a label and value is the rank of that label\n", "    new_col = new_col.reset_index().set_index(c).drop('y', axis=1)['index'].to_dict()\n", "    # add new column to the dataframe\n", "    df[c + '_new'] = df[c].apply(add_new_col)\n", "\n", "# drop old categorical columns\n", "df_new = df.drop(cat_cols, axis=1)\n", "\n", "# show the result\n", "show_dataframe(df_new, 5)"], "cell_type": "code", "metadata": {"_uuid": "6b0320bf70db6a0d581943410b3fa57eb6029cc0", "_execution_state": "idle", "_cell_guid": "5428c9c8-8a5c-462d-a19e-43f0fd5119d2"}, "execution_count": null, "outputs": []}, {"source": ["### Train-test split"], "cell_type": "markdown", "metadata": {"_uuid": "9e57c7ce586a95f0702914a379fd4e2fc9ae152f", "_execution_state": "idle", "_cell_guid": "d6c69d70-e78d-4c79-9fa8-bb3715c31bad"}}, {"source": ["X = df.drop(list((set(const_cols) | set(dub_cols) | set(cat_cols))), axis=1)\n", "\n", "# Train\n", "X_train = X[X.eval_set == 0]\n", "y_train = X_train.pop('y'); \n", "X_train = X_train.drop(['eval_set', 'ID'], axis=1)\n", "\n", "# Test\n", "X_test = X[X.eval_set == 1]\n", "X_test = X_test.drop(['y', 'eval_set', 'ID'], axis=1)\n", "\n", "# Base score\n", "y_mean = y_train.mean()\n", "# Shapes\n", "\n", "print('Shape X_train: {}\\nShape X_test: {}'.format(X_train.shape, X_test.shape))"], "cell_type": "code", "metadata": {"_uuid": "822c0ef3a44266e882ed62fb58f251ad1a37c3d3", "_execution_state": "idle", "_cell_guid": "424034b6-9710-4c9d-b0a3-c062a19efbe7"}, "execution_count": null, "outputs": []}, {"source": ["### Model (XGBoost)"], "cell_type": "markdown", "metadata": {"_uuid": "cbdbb86cadbe2343114ad69485944cf1889800ec", "_execution_state": "idle", "_cell_guid": "03d8d8d9-ac63-460d-b99f-9b20ebb35ec1"}}, {"source": ["### Regressor\n", "\n", "# prepare dict of params for xgboost to run with\n", "xgb_params = {\n", "    'n_trees': 100, \n", "    'eta': 0.005,\n", "    'max_depth': 3,\n", "    'subsample': 0.95,\n", "    'colsample_bytree': 0.6,\n", "    'objective': 'reg:linear',\n", "    'eval_metric': 'rmse',\n", "    'base_score': np.log(y_mean),\n", "    'silent': 1\n", "}\n", "\n", "# form DMatrices for Xgboost training\n", "dtrain = xgb.DMatrix(X_train, np.log(y_train))\n", "dtest = xgb.DMatrix(X_test)\n", "\n", "# evaluation metric\n", "def the_metric(y_pred, y):\n", "    y_true = y.get_label()\n", "    return 'r2', r2_score(y_true, y_pred)\n", "\n", "# xgboost, cross-validation\n", "cv_result = xgb.cv(xgb_params, \n", "                   dtrain, \n", "                   num_boost_round=2000, \n", "                   nfold = 3,\n", "                   early_stopping_rounds=50,\n", "                   feval=the_metric,\n", "                   verbose_eval=100, \n", "                   show_stdv=False\n", "                  )\n", "\n", "num_boost_rounds = len(cv_result)\n", "print('num_boost_rounds=' + str(num_boost_rounds))\n", "\n", "# train model\n", "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\n", "\n", "# Predict on trian and test\n", "y_train_pred = np.exp(model.predict(dtrain))\n", "y_pred = np.exp(model.predict(dtest))\n", "\n", "print('First 5 predicted test values:', y_pred[:5])"], "cell_type": "code", "metadata": {"_uuid": "ab64bea8868f097869bcb44fe8b95cd823ce9b51", "_execution_state": "idle", "_cell_guid": "0a919200-4dd4-4418-8640-32b9c48082a8"}, "execution_count": null, "outputs": []}, {"source": ["plt.figure(figsize=(16,4))\n", "\n", "plt.subplot(1,4,1)\n", "train_scores = cv_result['train-r2-mean']\n", "train_stds = cv_result['train-r2-std']\n", "plt.plot(train_scores, color='green')\n", "plt.fill_between(range(len(cv_result)), train_scores - train_stds, \n", "                 train_scores + train_stds, alpha=0.1, color='green')\n", "test_scores = cv_result['test-r2-mean']\n", "test_stds = cv_result['test-r2-std']\n", "plt.plot(test_scores, color='red')\n", "plt.fill_between(range(len(cv_result)), test_scores - test_stds, \n", "                 test_scores + test_stds, alpha=0.1, color='red')\n", "plt.title('Train and test cv scores (R2)')\n", "\n", "plt.subplot(1,4,2)\n", "plt.title('True vs. Pred. train')\n", "plt.plot([80,265], [80,265], color='g', alpha=0.3)\n", "plt.scatter(x=y_train, y=y_train_pred, marker='.', alpha=0.5)\n", "plt.scatter(x=[np.mean(y_train)], y=[np.mean(y_train_pred)], marker='o', color='red')\n", "plt.xlabel('Real train'); plt.ylabel('Pred. train')\n", "\n", "plt.subplot(1,4,3)\n", "sns.distplot(y_train, kde=False, color='g')\n", "sns.distplot(y_train_pred, kde=False, color='r')\n", "plt.title('Distr. of train and pred. train')\n", "\n", "plt.subplot(1,4,4)\n", "sns.distplot(y_train, kde=False, color='g')\n", "sns.distplot(y_pred, kde=False, color='b')\n", "plt.title('Distr. of train and pred. test')\n", "\n", "\n", "\n", "plt.figure(figsize=(18,1))\n", "plt.plot(y_train_pred[:200], color='r', linewidth=0.7)\n", "plt.plot(y_train[:200], color='g', linewidth=0.7)\n", "plt.title('First 200 true and pred. trains')\n", "\n", "print('Mean error =', np.mean(y_train - y_train_pred))\n", "print('Train r2 =', r2_score(y_train, y_train_pred))"], "cell_type": "code", "metadata": {"_uuid": "3c4b390bedcc58f385cd69d58f7ef5f410046b7a", "_execution_state": "idle", "_cell_guid": "319fad38-39f5-45d1-b90a-b8a9bd44584b"}, "execution_count": null, "outputs": []}, {"source": ["### Feature importance"], "cell_type": "markdown", "metadata": {"_uuid": "60d5c28e7a917bcc1711db5400077395ddbf7c57", "_execution_state": "idle", "_cell_guid": "2929a782-3769-46ee-9344-dcd4c1c47fd3"}}, {"source": ["# First 50 features\n", "features_score = pd.Series(model.get_fscore()).sort_values(ascending=False)[:50]\n", "plt.figure(figsize=(7,10))\n", "sns.barplot(x=features_score.values, y=features_score.index.values, orient='h')"], "cell_type": "code", "metadata": {"_uuid": "31246a6f15e500d55e785e13d6b532e43a9361bf", "_execution_state": "idle", "_cell_guid": "3880a8ea-abf0-4661-9ca0-d4ea928d9ab5"}, "execution_count": null, "outputs": []}, {"source": ["# output = pd.DataFrame({'id': test['ID'].astype(np.int32), 'y': y_pred})\n", "# output.to_csv('subm.csv', index=False)"], "cell_type": "code", "metadata": {"_uuid": "92da3e03044f7daebfd36ed9b52b9c828a77ba54", "_execution_state": "idle", "collapsed": true, "_cell_guid": "124bb6ee-474e-448e-a1cc-9f3aa2f2a1bd"}, "execution_count": null, "outputs": []}], "nbformat": 4}