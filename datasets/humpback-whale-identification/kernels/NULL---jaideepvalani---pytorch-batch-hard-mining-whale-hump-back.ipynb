{"cells":[{"metadata":{"colab_type":"code","id":"vgNkN0Oq6KZS","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"0b11e50e-c872-4d98-ecce-ca5bcb8aaaa8","trusted":true,"_uuid":"581a3cd3c39ac6c9f0ce308e1f47b0f910361951"},"cell_type":"code","source":"\"\"\"\n!pip install -q kaggle\n\n!mkdir -p ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!kaggle competitions download -c humpback-whale-identification\n\n!mkdir data\n!mkdir ./data/train\n!mkdir ./data/test\n!mv *.zip ./data/\n!mv *.csv ./data/\n!unzip -q ./data/test.zip -d ./data/test/\n!unzip -q ./data/train.zip -d ./data/train/\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"4YemqpNR7DxF","colab":{},"trusted":true,"_uuid":"8afe3bf21cfb6ee519edb7b8fb3f87836a7c39a5"},"cell_type":"code","source":"#!kaggle competitions download -c humpback-whale-identification","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"sdHJjChA6TVW","colab":{},"trusted":true,"_uuid":"3823050b06b53c90cf8828cea12f9f8c9ed29e45"},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.layers import *\nfrom fastai.metrics import accuracy_thresh\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"NHxsy9zW9mZ9","outputId":"9764b190-a45e-4b38-d931-9927a4f8f047","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true,"_uuid":"22cc99941c824825360bfcfe633c1015d023caeb"},"cell_type":"code","source":"path = Path('../input')\npath_t=Path('../input/humpback-whale-identification/')\npath1='.'\ndf = pd.read_csv(path_t/'train.csv'); \n#!pip install fastai=='1.0.39' --no-deps\nimport fastai\nfastai.__version__\n#path_t=Path('../input/humpback-whale-identification/')\n#path1='.'\n#df = pd.read_csv(path/'train.csv'); \n\n#!pip install fastai=='1.0.39'\n\nimport fastai\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"5_hRFihf6ZK9","colab":{},"trusted":true,"_uuid":"3523b34c017992da6ea329520a53af34d606df0a"},"cell_type":"code","source":"exclude_list=['0b1e39ff.jpg',\n'0c11fa0c.jpg',\n'1b089ea6.jpg',\n'2a2ecd4b.jpg',\n'2c824757.jpg',\n'3e550c8a.jpg',\n'56893b19.jpg',\n'613539b4.jpg',\n'6530809b.jpg',\n'6b753246.jpg',\n'6b9f5632.jpg',\n'75c94986.jpg',\n'7f048f21.jpg',\n'7f7702dc.jpg',\n'806cf583.jpg',\n'95226283.jpg',\n'a3e9070d.jpg',\n'ade8176b.jpg',\n'b1cfda8a.jpg',\n'b24c8170.jpg',\n'b7ea8be4.jpg',\n'b9315c19.jpg',\n'b985ae1e.jpg',\n'baf56258.jpg',\n'c4ad67d8.jpg',\n'c5da34e7.jpg',\n'c5e3df74.jpg',\n'ced4a25c.jpg',\n'd14f0126.jpg',\n'e0b00a14.jpg',\n'e6ce415f.jpg',\n'e9bd2e9c.jpg',\n'f4063698.jpg',\n'f9ba7040.jpg']\nnew_whale_df = df[df.Id == \"new_whale\"] # only new_whale dataset\ntrain_df = df[~(df.Id == \"new_whale\")] # no new_whale dataset, used for training\nunique_labels = np.unique(train_df.Id.values)\ntrn_imgs=train_df.copy()\ncnter = Counter(trn_imgs.Id.values)\ntrn_imgs['cnt']=trn_imgs['Id'].apply(lambda x: cnter[x])\n#trn_imgs['target'] = 1\ntrn_imgs['target'] = 0 # 0 for same images\ntrn_imgs1 = trn_imgs.copy()\n#trn_imgs1['target'] = 0\ntrn_imgs1['target'] = 1 # 1 for dissimilar images\n#trn_imgs = trn_imgs.append(trn_imgs1)\ntarget_col = 3\ntrn_imgs.head(1)\ntrn_imgs=trn_imgs[~trn_imgs.Image.isin(exclude_list)]","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"EX1qEhZsJVH8","colab":{},"trusted":true,"_uuid":"d862b9d30358d0ce92d043c135fcc1533032d139"},"cell_type":"code","source":"def is_even(num): return num % 2 == 0\n\nclass TripleDS(Dataset):\n    def __init__(self, ds):\n        self.ds = ds\n        self.whale_ids = ds.y.items\n        #bb_df=pd.read_csv('bounding_boxes.csv')\n    def __len__(self):\n        return len(self.ds)\n    def __getitem__(self, idx):\n        #if is_even(idx):\n        img_a=self.ds[idx][0]\n        img_p=self.sample_same(idx )\n        img_n=self.sample_different(idx)\n          #return self.sample_same(idx // 2)\n        #print('-ve',img_n)\n        #img_a=read_img(self.bb_df,)\n        return self.construct_example(img_a,img_p,img_n,0)\n          #return self.sample_different((idx-1) // 2)\n    def sample_same(self, idx):\n        whale_id = self.whale_ids[idx]        \n        candidates = list(np.where(self.whale_ids == whale_id)[0])\n        candidates.remove(idx) # dropping our current whale - we don't want to compare against an identical image!\n        \n        if len(candidates) == 0: # oops, there is only a single whale with this id in the dataset\n            return self.sample_different(idx)\n        \n        np.random.shuffle(candidates)\n        return  self.ds[candidates[0]][0]\n    def sample_different(self, idx):\n        whale_id = self.whale_ids[idx]\n        candidates = list(np.where(self.whale_ids != whale_id)[0])\n        np.random.shuffle(candidates)\n        return self.ds[candidates[0]][0]\n    \n    def construct_example(self,im_A, im_B,im_C ,class_idx):\n        b=[im_A,im_B,im_C],class_idx\n        #print(b[0][2].shape)\n        return [im_A,im_B,im_C],class_idx\nclasses = df.Id.unique()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"eqXzRs-8GozE","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"786d2ba7-5f36-4861-bd0f-a07f1913cd40","trusted":true,"_uuid":"676b4c532f8d10c4f40e20b92c16341cdffecb95"},"cell_type":"code","source":"#test_fnames[:5]\n#data.test_ds\n\n#data.train_ds.y.items\n#data.train_ds[0]\nbs=24\n!ls -l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a501b333471b69cc1ffa6ea655af416cbd61a0e5"},"cell_type":"code","source":"a=[1,2,3]\nb=[3,4,5]\nc=[]\nc.append(a)\nc.append(b)\nnp.stack(c).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5008e3d32fb7d5686abf02b68a628594524505a2"},"cell_type":"code","source":"def extract_embeddings(l,p):\n    data_e = (ImageItemList.from_df(df=trn_imgs, path=p,folder='train')\n         .no_split()\n         .label_from_df(cols=1,classes=classes)\n         #.add_test(test_fnames)\n         .transform((trn_tfms,trn_tfms), size=224,resize_method=ResizeMethod.SQUISH)\n         .databunch(bs=bs ))\n    train_feats=[]\n    # get train embeddings\n    l.load('bestmodel_tnt98_1')\n    l.model.eval()\n    preds = torch.zeros((len(data_e.train_dl.dataset), 1024))\n    \n    with torch.no_grad():\n        start=0\n        \n        for ims, t in data_e.train_dl:\n        #train_feats.append(learn.model.process_features(learn.model.cnn(ims)).detach().cpu())\n            #train_feats.append(l.model.head(learn.model.cnn(ims)).detach().cpu())\n            #train_class_idxs.append(t)\n            size=ims.shape[0]\n            preds[start:start+size,:]=l.model.head(l.model.cnn(ims))\n            start=start+size\n    return preds,[os.path.basename(name) for name in data_e.train_ds.x.items],data_e.train_ds.xtra.Id.values","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"fQwgQ_8W7FkW","colab":{},"trusted":true,"_uuid":"51a01cad7e85d8aec289828027ebe6f6830bf976"},"cell_type":"code","source":"test_ids = list(sorted({fname.split('_')[0] for fname in os.listdir(path_t/'test')}))\ntest_fnames = [path_t/'test'/test_id for test_id in test_ids]\ntrn_tfms,_= get_transforms(do_flip=False, flip_vert=True, max_rotate=30., max_zoom=1.08,\n                              max_lighting=0., max_warp=0. )\n\ndata = (ImageItemList.from_df(df=trn_imgs, path=path_t,folder='train')\n         .random_split_by_pct(valid_pct=0.1, seed=42)\n         .label_from_df(cols=1,classes=classes)\n         .add_test(test_fnames)\n         .transform((trn_tfms,trn_tfms), size=224,resize_method=ResizeMethod.SQUISH)\n         .databunch(bs=bs ))\n#data.test_ds.x.items","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c79311992fd79e9f9c90a72cb60a041a94e9c4ab"},"cell_type":"code","source":"#data.x[0] #prints image\n#data.train_dl\n#len(data.x.items)\n#data.xtra.Id\n\n#data.valid_ds.x.items\n#data_e.train_ds.x.items\n#l=[os.path.basename(name) for name in data_e.train_ds.x.items]\n#len(l)\ndata_e = (ImageItemList.from_df(df=trn_imgs, path=path_t,folder='train')\n         .no_split()\n         .label_from_df(cols=1,classes=classes)\n         #.add_test(test_fnames)\n         .transform((trn_tfms,trn_tfms), size=224,resize_method=ResizeMethod.SQUISH)\n         .databunch(bs=bs ))\n#data_e.train_ds.xtra.Id,data_e.train_ds.xtra.Image,\n#trn_imgs[trn_imgs.Image=='0000e88ab.jpg']\n\n#data_e.train_ds.x.items","execution_count":null,"outputs":[]},{"metadata":{"id":"VsJzVb32LBK6","colab_type":"code","colab":{},"trusted":true,"_uuid":"53bc3e5e9d29c67d6c68da99734b59fc1955628c"},"cell_type":"code","source":"#x,y=next(iter(data_bunch.train_dl))\n#x[0][0]","execution_count":null,"outputs":[]},{"metadata":{"id":"YHNGdaEWUM7t","colab_type":"code","colab":{},"trusted":true,"_uuid":"285f14de3629ef45631f6ed980b1c4ab2691d3c5"},"cell_type":"code","source":"import cv2\n\nmean, std = torch.tensor(imagenet_stats)\nclass SiamImage(ItemBase):\n    def __init__(self, img1, img2,img3): ## These should of Image type\n        self.img1, self.img2 ,self.img3= img1, img2,img3\n        #print(img1.data.shape)\n        self.obj, self.data = (img1, img2,img3), [(img1.data-mean[...,None,None])/std[...,None,None]\n                                                  , (img2.data-mean[...,None,None])/std[...,None,None]\n                                                   , (img3.data-mean[...,None,None])/std[...,None,None]]\n    def apply_tfms(self, tfms,*args, **kwargs):\n        self.img1 = self.img1.apply_tfms(tfms, *args, **kwargs)\n        self.img2 = self.img2.apply_tfms(tfms, *args, **kwargs)\n        self.img3 = self.img3.apply_tfms(tfms, *args, **kwargs)\n        self.data = [(self.img1.data-mean[...,None,None])/std[...,None,None]\n                     , (self.img2.data-mean[...,None,None])/std[...,None,None]\n                    , (self.img3.data-mean[...,None,None])/std[...,None,None]]\n        return self\n    def __repr__(self): return f'{self.__class__.__name__} {self.img1.shape, self.img2.shape}'\n    def to_one(self):\n        return Image(mean[...,None,None]+torch.cat(self.data,2)*std[...,None,None])\n      \n      \nclass SiamImageItemList(ImageItemList):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n#         self._label_cls=FloatList\n    \n    def __len__(self)->int: return len(self.items) or 1 \n    \n    def get(self, i):\n        sz=224\n        #match=1\n        #if i>=len(self.items)//2:#\"First set of iteration will generate similar pairs, next will generate different pairs\"\n            #match = 0\n        fn = self.items[i]\n        #print(i)\n        img1 = super().get(i) # Returns Image class object\n        #print(img1.shape,'img')\n        #img1=np.asarray(img1)\n        #img1 = PIL.Image.fromarray(read_img(fn[fn.rfind('/')+1:],bbox_df,img1) )\n        #img1 = read_img(fn[fn.rfind('/')+1:],bbox_df,img1) \n        imgs = self.xtra.Image.values\n        ids = self.xtra.Id.values\n        wcls = ids[i]\n        simgs = imgs[ids == wcls]\n        dimgs = imgs[ids != wcls]\n        \n        if len(simgs)==1 :\n            fn2=fn\n        else:\n        \n            while True:\n                np.random.shuffle(simgs)\n                np.random.shuffle(dimgs)\n                if simgs[0] != fn[fn.rfind('/')+1:]:\n                    fn2 =simgs[0] #[simgs[0]  \n                    break\n        #np.random.shuffle(simgs)\n            #print(fn2)\n            fn2 = self.items[np.where(imgs==fn2)[0][0]]\n        np.random.shuffle(dimgs)\n        \n        img2 = super().open(fn2) # Returns Image class object\n        #img2=np.asarray(img2)\n        fn3 = [dimgs[0] ]\n        fn3 = self.items[np.where(imgs==fn3)[0][0]]\n        img3 = super().open(fn3)\n        #img2 = PIL.Image.fromarray(read_img(fn[fn.rfind('/')+1:],bbox_df,img2) )\n        return SiamImage(img1, img2,img3)\n    \n    def reconstruct(self, t): \n      return SiamImage(mean[...,None,None]+t[0]*std[...,None,None], mean[...,None,None]+t[1]*std[...,None,None]\n                      ,mean[...,None,None]+t[2]*std[...,None,None])\n    \n    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(9,10), **kwargs):\n        rows = int(math.sqrt(len(xs)))\n        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n            xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n        plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"id":"7XHQFKaQULnb","colab_type":"code","colab":{},"trusted":true,"_uuid":"c641179c0fff946a0e35ab5040da7a2d30f66388"},"cell_type":"code","source":"data1 = (SiamImageItemList.from_df(df=trn_imgs, path=path_t,folder='train')\n         .random_split_by_pct(valid_pct=0.1, seed=42)\n         .label_from_df(cols=1, classes=classes)\n         #.add_test(test_fnames)\n         .transform((trn_tfms,trn_tfms), size=224,resize_method=ResizeMethod.SQUISH)\n         .databunch(bs=22,num_workers=0))","execution_count":null,"outputs":[]},{"metadata":{"id":"Ysu_bqCowOSU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b61d67fb-072a-47f5-9353-8873c2ae82fe","trusted":true,"_uuid":"ce4334f99478af7899fe62070e5213c8ebe5869b"},"cell_type":"code","source":"#x,y=next(iter(data_bunch.train_dl))\n#(x[0][2].shape)\n#x[2].shape\n#is_listy(x)\n#a=[x]\n##a[1].shape\n#len(x[0])\n#xb, yb = cb_handler.on_batch_begin(x, y)\n\n#learn.data\n#y.shape\n#x[2].shape\n#data1.show_batch(2)\n#fn=data1.items[0]\n#fn[fn.rfind('/')+1:]","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"hNR4Lk1j7vzE","colab":{},"trusted":true,"_uuid":"661651ed1348993942a771ffd1470fff1cbee8f4"},"cell_type":"code","source":"!pip install PyFunctional  --user\nfrom functional import seq\n\nfrom fastai.callbacks import *\nfrom fastai.basic_train import *\nfrom torch.autograd import Variable\nfrom torchvision import models as m\n\n#self.body = learner.create_body(self.arch, True, learner.cnn_config(self.arch)['cut'])\n#self.head = learner.create_head(num_features_model(self.body) * 2, self.emb_sz, self.lin_ftrs, self.ps,self.bn_final)\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self, arch=m.densenet121):\n        super().__init__() \n        #self.cnn = create_body(arch )\n        body = create_body(arch,True,-1)\n        h = create_head(num_features_model(body) * 2,512,[512],0.5,False)\n        self.cnn=  nn.Sequential( body,h)\n        self.head = nn.Linear(num_features_model(self.cnn), 1)\n        \n    def forward(self, im_A, im_B):\n        # dl - distance layer\n        #print(im_A.shape,im_B.shape)\n        x1, x2 = seq(im_A, im_B).map(self.cnn).map(self.process_features)\n        #dl = self.calculate_distance(x1, x2)\n        #out = self.head(dl)\n        return x1, x2\n    def calculate_score(self,x1,x2,targs,thr=0.8):\n        #sim= sim.cuda()\n        #sim=nn.Linear(256, 1)\n        #print(x1.shape,x2.shape,self.calculate_distance(x1, x2).shape)\n        #out =  self.sim.cuda()(self.calculate_distance(x1, x2).cuda()).sigmoid_()\n        out = self.head.cuda()(self.calculate_distance(x1, x2)).sigmoid_()\n        #print(out)\n        sc=(out>thr).int()\n        #print(targs)\n        #print(sc)\n        score=(sc==targs.int()).float()\n        #print(score.shape)\n        return score.float().mean()\n    def process_features(self, x): return x.reshape(*x.shape[:2], -1).max(-1)[0]\n    def calculate_distance(self, x1, x2): \n        return F.pairwise_distance(x1,x2,keepdim=True)\n        #return (x1 - x2).abs_()","execution_count":null,"outputs":[]},{"metadata":{"id":"uF2zC9R8eCco","colab_type":"code","colab":{},"trusted":true,"_uuid":"442597fdd2c667108cf6ee108b696b6276b0d1fd"},"cell_type":"code","source":"!pip install PyFunctional  --user\nfrom functional import seq\n\nfrom fastai.callbacks import *\nfrom fastai.basic_train import *\nfrom torch.autograd import Variable\nfrom torchvision import models as m\n\n#self.body = learner.create_body(self.arch, True, learner.cnn_config(self.arch)['cut'])\n#self.head = learner.create_head(num_features_model(self.body) * 2, self.emb_sz, self.lin_ftrs, self.ps,self.bn_final)\n\nclass TripleNetwork(nn.Module):\n    def __init__(self, arch=m.densenet121):\n        super().__init__() \n        #self.cnn = create_body(arch )\n        body = create_body(arch,True,-1)\n        h = create_head(num_features_model(body) * 2,512,[512],0.5,False)\n        self.cnn=  nn.Sequential( body,h)\n        self.head = nn.Linear(num_features_model(self.cnn), 1024)\n        \n    def forward(self, img_a, img_p,img_n):\n        # dl - distance layer\n        x1, x2,x3 = seq(img_a, img_p,img_n).map(self.cnn)#.map(self.process_features)\n        #print(len(ops))\n        #x1, x2,x3 = seq(ops[0][0], ops[0][1],ops[0][2]).map(self.cnn)#.map(self.process_features)\n        #dl = self.calculate_distance(x1, x2)\n        x1=self.head(x1)\n        x2=self.head(x2)\n        x3=self.head(x3)\n        \n        #out = self.head(dl)\n        return x1, x2,x3\n    def calculate_score(self,x1,x2,x3,targs,thr=0.8):\n        #sim= sim.cuda()\n        #sim=nn.Linear(256, 1)\n        #print(x1.shape,x2.shape,self.calculate_distance(x1, x2).shape)\n        #out =  self.sim.cuda()(self.calculate_distance(x1, x2).cuda()).sigmoid_()\n        dp=self.calculate_distance(x1, x2).pow(2).cuda()\n        dn=self.calculate_distance(x1, x3).pow(2).cuda()\n        \n        #out = self.head.cuda()(self.calculate_distance(x1, x2)).sigmoid_()\n        #print(out)\n        #sc=(out>thr).int()\n        #print(targs)\n        #print(sc)\n        score=(dn>dp).float()\n        #print(score.shape)\n        return score.mean()\n    def process_features(self, x): return x.reshape(*x.shape[:2], -1).max(-1)[0]\n    def calculate_distance(self, x1, x2): \n        return F.pairwise_distance(x1,x2)\n        #return (x1 - x2).abs_()\n\"\"\"\nclass TripleLoss(nn.Module):\n    #Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n     \n    def __init__(self, margin=5.):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n        self.wd=1e-4\n    \n\n    def forward(self, ops, label,size_average=True):\n        ep = F.pairwise_distance(ops[0], ops[1])\n        en = F.pairwise_distance(ops[0], ops[2])\n        #loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n        #                              (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        #label=label.float() # to overcome cuda/long mismatch issue\n        #ndist =euclidean_distance*label\n        #pdist =euclidean_distance*(1-label)\n        losses = F.relu(ep - en + self.margin)\n        return losses.mean() if size_average else losses.sum()\n        #loss += self.wd*(euclidean_distance**2)\n        #return loss.float().mean() # to overcome format issue\n\"\"\"\n        \nclass TripletLoss(nn.Module):\n    \"\"\"\n    Triplet loss\n    Takes embeddings of an anchor sample, a positive sample and a negative sample\n    \"\"\"\n\n    def __init__(self, margin=5.):\n        super(TripletLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, ops, label,size_average=True):\n        #print(len(ops))\n        #print(len(ops[0]))\n        distance_positive = (ops[0] - ops[1]).pow(2).sum(1)  # .pow(.5)\n        distance_negative = (ops[0] - ops[2]).pow(2).sum(1)  # .pow(.5)\n        losses = F.relu(distance_positive - distance_negative + self.margin)\n        return losses.mean() if size_average else losses.sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"4tCoEVr_eCcu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"20ad45b1-e093-431f-b01a-4afcd5265ed9","trusted":true,"_uuid":"348c2beda673dac3c7dec4fd7ce98be9a01f1196"},"cell_type":"code","source":"#SiameseNetwork()\n#learn.model.head\ntorch.log(tensor(12.0))","execution_count":null,"outputs":[]},{"metadata":{"id":"8nvXPcJVeCcz","colab_type":"code","colab":{},"trusted":true,"_uuid":"290e064b268429dceeabfabad329a90a2e0adf72"},"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    \"\"\"Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise\n    \"\"\"\n    def __init__(self, margin=2.):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n        self.wd=1e-4\n    \n\n    def forward(self, ops, label,size_average=True):\n        euclidean_distance = F.pairwise_distance(ops[0], ops[1])\n        #loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n        #                              (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n        label=label.float() # to overcome cuda/long mismatch issue\n        ndist =euclidean_distance*label\n        pdist =euclidean_distance*(1-label)\n        loss = 0.5* ((pdist**2) + (F.relu(self.margin-ndist)**2))\n        #loss += self.wd*(euclidean_distance**2)\n        return loss.mean() # to overcome format issue","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"beIgEMed8o41","colab":{},"trusted":true,"_uuid":"c326964cbf497bbcb292aefe2050a2b89b477bda"},"cell_type":"code","source":"import gc\ngc.collect()\nfrom fastai.callbacks import *\nfrom fastai.basic_train import *\nfrom torch.autograd import Variable\n\nTripleLoss=TripletLoss().cuda()\n#ContrastiveLoss().cuda()\n#\nlearn = Learner(data1, TripleNetwork().cuda(), loss_func=TripleLoss, path=path1,\n                metrics=[lambda preds, targs: TripleNetwork().calculate_score(preds[0],\n                                                                     preds[1],preds[2] ,\n                                                                     targs, thr=0.85)])\n                #[lambda preds, targs: accuracy_thresh(preds.squeeze(), targs, sigmoid=False)])\n#learn.split([learn.model.cnn[:6], learn.model.cnn[6:],learn.model.head])\n#learn.split([learn.model.cnn[0][:6], learn.model.cnn[0][6:],learn.model.head])\nlearn.split([learn.model.cnn[0][0][:6], learn.model.cnn[0][0][6:],learn.model.head])\n#apply_init(learn.model.cnn[1], nn.init.kaiming_normal_)\n#apply_init(learn.model.head, nn.init.kaiming_normal_)\n\n#learn.callback_fns.append(partial(GradientClipping,1))\nlearn.callback_fns.append(partial(SaveModelCallback,monitor='val_loss',mode='min'))\nlearn.callback_fns.append(partial(ReduceLROnPlateauCallback, min_delta=1e-5, patience=3))","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"OVG73F7f-lbo","colab":{},"trusted":true,"_uuid":"6bd7473224ab41db09fab022e257739b2ca671da"},"cell_type":"code","source":"#learn.model.cnn[0][0][:6]\n#x=torch.rand(1,3,224,224).cuda()\n#y=torch.rand(1,3,224,224).cuda()\n#a=(x,y)\n#a=SiameseNetwork().cuda().cnn(*a)\n#learn.data\n!mkdir models\n#!cp /kaggle/input/hump-back-twoim/models/*.pth /kaggle/working/models/\n#!cp /kaggle/input/triplet/*.pth /kaggle/working/models/\n#!mkdir models\n! cp /kaggle/input/hump-back-tn/models/*.pth /kaggle/working/models/","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"Jrpw-iMiDiBx","colab":{},"trusted":true,"_uuid":"e47d177f6fc321fec057199ae259d46d6df8c705"},"cell_type":"code","source":"#learn.lr_find()\n\n#learn.recorder.plot()\n\n#data.show_batch(2)\n#learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"id":"-Xiqx4SQeCdL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"abe5e579-a6d7-4f45-f2be-538767059ca5","trusted":true,"_uuid":"750b098a6ca2e9f1414f21db637d33bafbd7070b"},"cell_type":"code","source":"#learn.recorder.losses[-1]\n#learn.data.dl(data.train_ds[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"9-HgRxYTeCdO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":378},"outputId":"b4caeda3-8bc1-42a4-8209-02f8398b02b6","trusted":true,"_uuid":"d778e131116fd7d927c452c7b8b0170a3bb1ec7b"},"cell_type":"code","source":"#learn.lr_find()\n\n#cb_handler = CallbackHandler()\n#learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"fdBgVTRKXbCJ","colab":{},"trusted":true,"_uuid":"7e32a8f432d4a40f6a4d507b1531c76966e7124b"},"cell_type":"code","source":"#learn.save('freeze')\n#!cp *.pth ./data/models\n#push","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e86f7771ece8dd3a722714f3528a7aa1493c9cd"},"cell_type":"code","source":"#emb.reshape(-1,1024).shape\n#len(names)\n#names.shape\npreds = torch.zeros((len(data_e.train_dl.dataset), 1024))\n#preds.shape","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"qlpBDLCgekSa","outputId":"1ddd41a6-23ac-44e8-ce12-4e383b04b883","colab":{"base_uri":"https://localhost:8080/","height":197},"trusted":true,"_uuid":"6972db36bf4c42c0fba2d00907ab8fd6f3f83f1f"},"cell_type":"code","source":"#learn.show_results()\n#xb,yb=next(iter(data_bunch.train_dl))\n#xb1, yb1 = cb_handler.on_batch_begin(xb, yb)\nfrom IPython.display import FileLink\n#xb[2].shape\n#data_bunch.train_dl\n#push\nemb,names,labels=extract_embeddings(learn,path_t)\ntrn_emb = pd.DataFrame({'files':names,'emb':emb.tolist(),'Id':labels})\ntrn_emb.emb = trn_emb.emb.map(lambda emb: ' '.join(list([str(i) for i in emb])))\ntrn_emb.to_csv('train_emb.csv', header=True, index=False)\n#FileLink('train_emb.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"117cfb30c3b0b19e88165b9cb87e54c9e3b3810f"},"cell_type":"code","source":"#trn_emb.to_csv('train_emb.csv', header=True, index=False)\n#FileLink('train_emb.csv')\n\ntrn_emb.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17738d8e2810df78df60ac1c60cbcb3e796a6916"},"cell_type":"code","source":"import pandas as pd\ntrn_emb_df=pd.read_csv('train_emb.csv')\n#emb.head(1)\n#torch.from_numpy(emb.emb.values.reshape(15697,-1).astype('float16') )\n#trn_emb.loc[trn_emb.Image == name,'emb'].tolist()[0]\n#for i in emb.emb.values:\n    #print(list(i))\n    #break\ntrn_emb_df['emb'] = [[float(i) for i in s.split()] for s in trn_emb_df['emb']]\n#trn_emb_df = trn_emb_df.set_index('files')\nemb = np.array(trn_emb_df.emb.tolist())\nemb=torch.from_numpy(emb) \n#torch.cat(emb.emb.values).size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32568857a694308cfa545b55bd8399b141fda534"},"cell_type":"code","source":"trn_emb_df['seq'] = np.arange(len(trn_emb_df))\ntrn_emb_df = trn_emb_df.set_index('seq')\n#len(trn_emb.loc[trn_emb_df.Id!='w_f48451c'].index.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6202a7175fd6e9b76a69015a85cd6cb504031fd0"},"cell_type":"code","source":"#emb.size()\n#trn_emb_df.set_index('seq',inplace=True)\n#trn_emb_df.reset_index(drop=False)\ntrn_emb_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ee21001fb60453cfd79d9697c60c76a1c7043a9"},"cell_type":"code","source":"import gc\n\nlearn.load('bestmodel_tnt98_2')\nlearn.model.eval()\n#%%time\nsims = []\ndist_dict={}\nn_idx=[]\nwith torch.no_grad():\n    \n    for feat,i ,f in  zip(emb,trn_emb_df.Id.values,trn_emb_df.files.values):\n        n_idx=[]\n        dists = learn.model.calculate_distance(emb, feat.unsqueeze(0).repeat(15697, 1)).pow(2)\n        predicted_similarity = dists.cuda()#learn.model.head(dists.cuda())\n        seq_ids = trn_emb.loc[trn_emb_df.Id!=i].index.tolist()\n        dist_sort,indx=torch.sort(predicted_similarity[seq_ids],descending=False)\n        n_idx=[seq_ids[i] for i in indx[:90]]\n        dist_dict[f]= [trn_emb_df.loc[idx,'files'] for idx in n_idx]\n        gc.collect()\n        #sims.append(predicted_similarity.squeeze().detach().cpu())\n    #trn_emb = trn_emb.set_index('idx')\n            ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"nN9oN6ZUjb3b","colab":{},"trusted":true,"_uuid":"db5cf0bdabe22d599b962c9ed901058f395b3195"},"cell_type":"code","source":"neg_img_pair=pd.DataFrame({'file':list(dist_dict.keys()) })\nneg_img_pair['img']=list(dist_dict.values())\n\nneg_img_pair.to_csv('neg_img_pair.csv',index=False,header=True)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"fkE4YmWcw2OT","outputId":"0e91503a-723f-46b0-b9dc-ae1fdd97fbf8","colab":{"base_uri":"https://localhost:8080/","height":34},"trusted":true,"_uuid":"05751a9a2182a17289b963d35325749ce7d7d829"},"cell_type":"code","source":"#!ls -l ./data/train/","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"code","id":"zLfiqx_63C0b","colab":{},"trusted":true,"_uuid":"e0bea03ebdc0198134521efacbc0831fb80c4359"},"cell_type":"code","source":"d={}\nd['a']=[3,4,5,6]\nd['b']=[4,5,6,7]\n#import pandas as pd\n#list(d.values() )\ndf=pd.DataFrame({'file':list(d.keys())})\n#a['values']=list(d.values())\ndf\n#import random\n#random.sample(a.loc[a.file=='a','values'][0],2)[0]\n#a.loc[a.file=='a','values'][0]","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"hump_back_twoim.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}