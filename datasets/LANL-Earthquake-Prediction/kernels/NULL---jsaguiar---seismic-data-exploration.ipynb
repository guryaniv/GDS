{"cells":[{"metadata":{"_uuid":"c6c11ef95d77a7e62c5127f98ed836e765dcb711"},"cell_type":"markdown","source":"<h2>1. Overview</h2>\n\nAs stated in the description, the data for this competition comes from a experimental set-up used to study earthquake physics. Our goal is to predict the time remaining before the next laboratory earthquake. The only feature we have is the seismic signal (acoustic data) which has integer values in a limited range.\n\n* Training data: single, continuous segment of experimental data.\n\n* Test data: consists of a folder containing many small segments. The data within each test file is continuous, but **the test files do not represent a continuous segment of the experiment**.\n\nThere are a lot of files in this competition, so let's start with the folders structure:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"652a8a31505e21109d730e6f1dfada9be2f90c90"},"cell_type":"code","source":"import os\nfrom random import shuffle\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nimport numba\nimport warnings\nsns.set()\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=RuntimeWarning)\n\n@numba.jit\ndef get_stats(arr):\n    \"\"\"Memory efficient stats (min, max and mean). \"\"\"\n    size  = len(arr)\n    min_value = max_value = arr[0]\n    mean_value = 0\n    for i in numba.prange(size):\n        if arr[i] < min_value:\n            min_value = arr[i]\n        if arr[i] > max_value:\n            max_value = arr[i]\n        mean_value += arr[i]\n    return min_value, max_value, mean_value/size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3bf12a0dcad012196430bf634903bca50fe6b727"},"cell_type":"markdown","source":"The test folder has many csv files:"},{"metadata":{"trusted":true,"_uuid":"10d64009d76cdf17ea183c48bd46f93dddc3696d"},"cell_type":"code","source":"test_folder_files = os.listdir(\"../input/test\")\nprint(test_folder_files[:10])  # print first 10\nprint(\"\\nNumber of files in the test folder\", len(test_folder_files))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ebe22f3f9e96856054e49a8e1af733c1cfcb40a"},"cell_type":"markdown","source":"There is one file in the test folder for each prediction (seg_id) in sample_submission:"},{"metadata":{"trusted":true,"_uuid":"aa639140cb6a736936a071f88700aabc40b71d57"},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/sample_submission.csv')\nprint(\"Submission shape\", sample_sub.shape)\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab12f1cfb3b839064974f96aec589d7c28883401"},"cell_type":"markdown","source":"<h2>2. Training data</h2>\n\nOne huge csv file has all the training data, which is a single continuous experiment. There are only two columns in this file:\n* Acoustic data (int16): the seismic signal\n* Time to failure (float64): the time until the next laboratory earthquake  (in seconds)\n* **No missing values for both columns**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\nprint(\"train shape\", train.shape)\npd.set_option(\"display.precision\", 15)  # show more decimals\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4d4ca9c488c4d5a0c1fc9a7a0f5a12c28b05ec2f"},"cell_type":"markdown","source":"<h2>Acoustic data</h2>\n\nOur single feature are integers in the range [-5515, 5444] with mean 4.52"},{"metadata":{"trusted":true,"_uuid":"aaab852659d03c5f4e14c12ea04f347429106638"},"cell_type":"code","source":"pd.set_option(\"display.precision\", 8)\ntrain.acoustic_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6c9ce78bd13c7ac9794f7ccb8e6ce408b6e6a78f"},"cell_type":"markdown","source":"The plot below is using a 1% random sample (~6M rows):"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"4d045d705dde6744faaed431420a80a9d746346b"},"cell_type":"code","source":"train_sample = train.sample(frac=0.01)\nplt.figure(figsize=(10,5))\nplt.title(\"Acoustic data distribution\")\nax = sns.distplot(train_sample.acoustic_data, label='Train (1% sample)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72fc466541abb983573a9db7dcb738623218e599"},"cell_type":"markdown","source":"There are outliers in both directions; let's try to plot the same distribution with x in the range -25 to 25. The black line is the closest normal distribution (gaussian) possible."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"59711dce343a977bc9e6cba457fa5aa768dd8cd6"},"cell_type":"code","source":"train_sample = train.sample(frac=0.01)\nplt.figure(figsize=(10,5))\nplt.title(\"Acoustic data distribution\")\ntmp = train_sample.acoustic_data[train_sample.acoustic_data.between(-25, 25)]\nax = sns.distplot(tmp, label='Train (1% sample)', kde=False, fit=stats.norm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"913813986bdaa1cf8303c9d267da34064669b802"},"cell_type":"markdown","source":"<h2>Time to failure</h2>\n\nNow let's check the target variable, which is given in seconds:"},{"metadata":{"trusted":true,"_uuid":"08e5e15c10a88461bc046bc228dcfd023c247d52"},"cell_type":"code","source":"tmin, tmax, tmean = get_stats(train.time_to_failure.values)\nprint(\"min value: {:.6f}, max value: {:.2f}, mean: {:.4f}\".format(tmin, tmax, tmean))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9da17e63ed3c65e5ebfa41c02dcefee5502f1559"},"cell_type":"markdown","source":"The min value is very close to zero (around 10^-5) and the max is 16 seconds. Now the distribution for the random sample:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5d4bdb75f22131e50cd7766d8368f1b51e656b23"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Time to failure distribution\")\nax = sns.kdeplot(train_sample.time_to_failure, label='Train (1% sample)')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43dc05526e2821091e172a7bb74af1c503c5d82b"},"cell_type":"markdown","source":"<h2>Timeseries</h2>\n\nLet's see how both variables change over time. The orange line is the acoustic data and the blue one is the time to failure:"},{"metadata":{"trusted":true,"_uuid":"4cdef8e4bd7f9676d42f15c0c469811015056e1e","_kg_hide-input":true},"cell_type":"code","source":"def single_timeseries(final_idx, init_idx=0, step=1, title=\"\",\n                      color1='orange', color2='blue'):\n    idx = [i for i in range(init_idx, final_idx, step)]\n    fig, ax1 = plt.subplots(figsize=(10, 5))\n    fig.suptitle(title, fontsize=14)\n    \n    ax2 = ax1.twinx()\n    ax1.set_xlabel('index')\n    ax1.set_ylabel('Acoustic data')\n    ax2.set_ylabel('Time to failure')\n    p1 = sns.lineplot(data=train.iloc[idx].acoustic_data.values, ax=ax1, color=color1)\n    p2 = sns.lineplot(data=train.iloc[idx].time_to_failure.values, ax=ax2, color=color2)\n\n\ndef double_timeseries(final_idx1, final_idx2, init_idx1=0, init_idx2=0, step=1, title=\"\"):\n    idx1 = [i for i in range(init_idx1, final_idx1, step)]\n    idx2 = [i for i in range(init_idx2, final_idx2, step)]\n    \n    fig, (ax1a, ax2a) = plt.subplots(1,2, figsize=(12,5))\n    fig.subplots_adjust(wspace=0.4)\n    ax1b = ax1a.twinx()\n    ax2b = ax2a.twinx()\n    \n    ax1a.set_xlabel('index')\n    ax1a.set_ylabel('Acoustic data')\n    ax2a.set_ylabel('Time to failure')\n    p1 = sns.lineplot(data=train.iloc[idx1].acoustic_data.values, ax=ax1a, color='orange')\n    p2 = sns.lineplot(data=train.iloc[idx1].time_to_failure.values, ax=ax1b, color='blue')\n    \n    p3 = sns.lineplot(data=train.iloc[idx2].acoustic_data.values, ax=ax2a, color='orange')\n    p4 = sns.lineplot(data=train.iloc[idx2].time_to_failure.values, ax=ax2b, color='blue')\n    \nsingle_timeseries(100000, title=\"First hundred thousand rows\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fee5d8ba4ca418e032c037fd0e9d7176003d770"},"cell_type":"markdown","source":"Time to failure looks like a stairway with many steps where the time is constant. However, this is not the case as we can see when plotting only the first thousand rows:"},{"metadata":{"trusted":true,"_uuid":"04b8f49e53d43063ab888e780e06cb60dfaab2fa"},"cell_type":"code","source":"single_timeseries(1000, title=\"First thousand rows\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cd64c0a9f1bc07f5770d495a900dd7194b81b20"},"cell_type":"markdown","source":"The time is decreasing linearly between each \"step\" or \"jump\". However, when plotting the first million rows the steps are not visible anymore:"},{"metadata":{"trusted":true,"_uuid":"72657cba7ec05c23e8527b0e7890e5895cc16af9"},"cell_type":"code","source":"single_timeseries(1000000, title=\"First million rows\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d258d23ac59b90265b05c8d3756c1da81cf7fe61"},"cell_type":"markdown","source":"It's as if we have stretched the line and the steps disappear, but they still there. Now let's check 10 million rows, but plotting only every 10 points:"},{"metadata":{"trusted":true,"_uuid":"2efd241868c9d9df39353e19706d13c975896db4"},"cell_type":"code","source":"single_timeseries(10000000, step=10, title=\"Ten million rows\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f454ad45a054e9ae554976046ec66dc86d52d8d"},"cell_type":"markdown","source":"There is a huge spike in acoustic data around half second before the earthquake. Let's have a closer look at the data right after the spike to the earthquake (index 5 to 6 million, step 1)."},{"metadata":{"trusted":true,"_uuid":"dfcf10b591d3df1c802424f5ce1c36a645bed2f4"},"cell_type":"code","source":"single_timeseries(final_idx=6000000, init_idx=5000000, title=\"Five to six million index\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a716d011b8244358ecfb0fe6b7d42f4492acd500"},"cell_type":"markdown","source":"Finally, the plot for all the data (629.145 million rows):"},{"metadata":{"trusted":true,"_uuid":"b2085a3157a40b065290c7775e142f9ad1cb62a9"},"cell_type":"code","source":"single_timeseries(629145000, step=1000, title=\"All training data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62071328800e639a39eab50e5d7d9a4ade7e240"},"cell_type":"markdown","source":"There are 16 earthquakes in the training data. The shortest time to failure is 1.5 seconds for the first earthquake and 6s to the 7º, while the longest is around 16 seconds.\n\nIn the plot below I just changed the time_to_failure color to white. Now it's possible to see a peak in acoustic data before each earthquake:"},{"metadata":{"trusted":true,"_uuid":"f17e044a6fe18eddc445469962a79e84660b3e54"},"cell_type":"code","source":"single_timeseries(629145000, step=1000, title=\"All training data\", color2='white')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3b6c035bd03b95fdfe128997fb5ec3ee1a12a4e"},"cell_type":"markdown","source":"This is not a perfect rule though: there are some peaks far from earthquakes (e.g. between the 14º and 15º). Another interesting thing to check is the time between these high levels of seismic signal and the earthquakes. I'm considering any acoustic data with **absolute value greater than 500 as a high level:**"},{"metadata":{"trusted":true,"_uuid":"b13c17723284b9e0a1230e2418a2b45f5c280eaa"},"cell_type":"code","source":"peaks = train[train.acoustic_data.abs() > 500]\npeaks.time_to_failure.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"872a4675951244100c747cce6c30ce8a2bd2edc3"},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Cumulative distribution - time to failure with high signal\")\nax = sns.distplot(peaks.time_to_failure, hist_kws=dict(cumulative=True), kde_kws=dict(cumulative=True))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db3c44791c79b21ffa6229531bbde1b562f22004"},"cell_type":"markdown","source":"**More than 80% of high acoustic values are around 0.31 seconds before an earthquake!**"},{"metadata":{"_uuid":"df6cd241063d694a65805e6dec140dc7e44aa9c8"},"cell_type":"markdown","source":"<h2>Time between measurements</h2>\n\nLet's check the difference between the time to failure for each row and the previous (for the first 5M rows)."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7fb1a6cdc565fc8d1b3f7609e7b629e590763e2c"},"cell_type":"code","source":"diff = train.iloc[:5000000].time_to_failure.diff()\ncounts = diff.value_counts()\n\nplt.figure(figsize=(10,5))\nplt.title(\"Time to failure difference\")\nax = sns.scatterplot(data=diff.values, color='red')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"938e39c671e3a1d1b9d6929821619118e64f1c55"},"cell_type":"markdown","source":"We can see three different ranges of values. Two are around 0.001, while the other is very close to zero. This agrees with the first timeseries plot, where we had those steps. Let's check the distribution:"},{"metadata":{"trusted":true,"_uuid":"87467c5ff00412efbd4a59370c03aae653a42064","_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Time to failure difference\")\nax = sns.kdeplot(data=diff.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74821bb9b3fe6afcd8c060a1102e675bf9e18115"},"cell_type":"markdown","source":"Indeed most values are less than 0.0001, but there are a few around 0.0010, which means that there are different time steps. Note that I didn't include any earthquake here since the first is only around index 7 million"},{"metadata":{"_uuid":"d825321208fc96d03ddd152f9af7cdcbc2133d07"},"cell_type":"markdown","source":"<h2>3. Test data</h2>\n\nEach file is considered an experiment with 150,000 values for acoustic data (single column). Let's have a look at the first test file:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e2e90e4f0286346c96aa20641055dc28bd0eeb7e"},"cell_type":"code","source":"pd.set_option(\"display.precision\", 4)\ntest1 = pd.read_csv('../input/test/seg_37669c.csv', dtype='int16')\nprint(test1.describe())\nplt.figure(figsize=(10,5))\nplt.title(\"Acoustic data distribution\")\nax = sns.distplot(test1.acoustic_data, label='seg_37669c', kde=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7fe3e61e75c7bc78feaf8d2bc415102260d8e9f0"},"cell_type":"markdown","source":"Now the distribution for 10 files choosen at random:"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"fda27e4df3e72f2f422e4d69d18722fc60eceae8"},"cell_type":"code","source":"fig, axis = plt.subplots(5, 2, figsize=(12,14))\nshuffle(test_folder_files)\nxrow = xcol = 0\nfor f in test_folder_files[:10]:\n    tmp = pd.read_csv('../input/test/{}'.format(f), dtype='int16')\n    ax = sns.distplot(tmp.acoustic_data, label=f.replace('.csv',''), ax=axis[xrow][xcol], kde=False)\n    if xcol == 0:\n        xcol += 1\n    else:\n        xcol = 0\n        xrow += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7385bcc40724aa0ce9d58538a9aa6de08f7e7e80"},"cell_type":"markdown","source":"Timeseries (index as x-axis) for the same ten files:"},{"metadata":{"trusted":true,"_uuid":"f26366bd82fe06750c2c0c9e10661974ffb8aef0","_kg_hide-input":true},"cell_type":"code","source":"fig, axis = plt.subplots(5, 2, figsize=(12,14))\nxrow = xcol = 0\nfor f in test_folder_files[:10]:\n    tmp = pd.read_csv('../input/test/{}'.format(f), dtype='int16')\n    ax = sns.lineplot(data=tmp.acoustic_data.values,\n                      label=f.replace('.csv',''),\n                      ax=axis[xrow][xcol],\n                      color='orange')\n    if xcol == 0:\n        xcol += 1\n    else:\n        xcol = 0\n        xrow += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cba67b1e94ec02a3cdfe4c77395cb3c7a3c48c8c"},"cell_type":"markdown","source":"<h2>4. Statistics for chunks</h2>\n\n<h2>Rolling mean</h2>\nMost kernels are grouping the training data every 150,000 rows and calculating statistics about that chunk. The next plot shows the **mean absolute value for every 150,000 data points** and the** time to failure for the last point within each chunk**."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"98f842a41c21032202e11cf79902b536d81a3eed"},"cell_type":"code","source":"rolling_mean = []\nrolling_std = []\nlast_time = []\ninit_idx = 0\nfor _ in range(4194):  # 629M / 150k = 4194\n    x = train.iloc[init_idx:init_idx + 150000]\n    last_time.append(x.time_to_failure.values[-1])\n    rolling_mean.append(x.acoustic_data.abs().mean())\n    rolling_std.append(x.acoustic_data.abs().std())\n    init_idx += 150000\n    \nrolling_mean = np.array(rolling_mean)\nlast_time = np.array(last_time)\n\n# plot rolling mean\nfig, ax1 = plt.subplots(figsize=(10, 5))\nfig.suptitle('Mean for chunks with 150k samples of training data', fontsize=14)\n\nax2 = ax1.twinx()\nax1.set_xlabel('index')\nax1.set_ylabel('Acoustic data')\nax2.set_ylabel('Time to failure')\np1 = sns.lineplot(data=rolling_mean, ax=ax1, color='orange')\np2 = sns.lineplot(data=last_time, ax=ax2, color='gray')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d34e20ca25e4e879ec5ed08ab1cb26fce9ac8864"},"cell_type":"markdown","source":"Removing high values (mean < 8):"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"4e0dbcf262692ae83fd989b38496b7648a60f36f"},"cell_type":"code","source":"# plot rolling mean\nfig, ax1 = plt.subplots(figsize=(10, 5))\nfig.suptitle('Mean (< 8) for chunks of 150k samples', fontsize=14)\n\nax2 = ax1.twinx()\nax1.set_xlabel('index')\nax1.set_ylabel('Acoustic data')\nax2.set_ylabel('Time to failure')\np1 = sns.lineplot(data=rolling_mean[rolling_mean < 8], ax=ax1, color='orange')\np2 = sns.lineplot(data=last_time, ax=ax2, color='gray')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a5da1f4ed00493383f39522bb5beeb65ea83f904"},"cell_type":"markdown","source":"We can see that the mean absolute value is increasing as we get closer to an earthquake."},{"metadata":{"_uuid":"b899408d4012ad285ca8f693f20bc7d0689d3fae"},"cell_type":"markdown","source":"<h2>Standard deviation</h2>\n\nIn the next chart, the standard deviation for each chunk was grouped by the time to failure, which in turn was rounded to the first decimal place."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"66e88b5899bc44fb4a09ed5172dd47b2b00a385b"},"cell_type":"code","source":"frame = pd.DataFrame({'rolling_std': rolling_std, 'time': np.around(last_time, 1)})\ns = frame.groupby('time').rolling_std.mean()\ns = s[s < 20]  # remove one outlier\nplt.figure(figsize=(10, 5))\nplt.title(\"Std for chunks with 150k samples of training data\")\nplt.xlabel(\"Time to failure\")\nplt.ylabel(\"Acoustic data\")\nax = sns.lineplot(x=s.index, y=s.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f051291cadf508de9ca4937f3c699c454f3cf37"},"cell_type":"markdown","source":"The standard deviation is also higher for chunks that are closer to an earthquake (in general)."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}