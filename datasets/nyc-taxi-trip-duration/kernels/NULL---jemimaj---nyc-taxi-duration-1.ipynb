{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nfrom datetime import timedelta\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport haversine\n\nprint(os.listdir())\n\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\ntrain_data['pickup_datetime'] = pd.to_datetime(train_data['pickup_datetime'])\ntrain_data['dropoff_datetime'] = pd.to_datetime(train_data['dropoff_datetime'])\n\ntrain_data['pickup_month'] = train_data.pickup_datetime.dt.month.astype(np.uint8)\ntrain_data['pickup_day'] = train_data.pickup_datetime.dt.weekday.astype(np.uint8)\ntrain_data['pickup_hour'] = train_data.pickup_datetime.dt.hour.astype(np.uint8)\n\ntrain_data['dropoff_month'] = train_data.dropoff_datetime.dt.month.astype(np.uint8)\ntrain_data['dropoff_day'] = train_data.dropoff_datetime.dt.weekday.astype(np.uint8)\ntrain_data['dropoff_hour'] = train_data.dropoff_datetime.dt.hour.astype(np.uint8)\n\ntrain_data['distance'] = train_data.apply(lambda x: haversine.haversine((x[\"pickup_longitude\"], x[\"pickup_latitude\"]), (x[\"dropoff_longitude\"], x[\"dropoff_latitude\"])), axis=1)\n\n# --- Doing the same for the test data excluding dropoff time ---\ntest_data['pickup_datetime'] = pd.to_datetime(test_data['pickup_datetime'])\n\ntest_data['pickup_month'] = test_data.pickup_datetime.dt.month.astype(np.uint8)\ntest_data['pickup_day'] = test_data.pickup_datetime.dt.weekday.astype(np.uint8)\ntest_data['pickup_hour'] = test_data.pickup_datetime.dt.hour.astype(np.uint8)\n\ntrain_data['trip_duration_mins'] = train_data['trip_duration'] / 60\ntrain_data['trip_duration_hours'] = train_data['trip_duration_mins'] / 60\n\nprint(max(train_data['trip_duration_hours']))\nprint(min(train_data['trip_duration_hours']))\n\nprint(train_data['trip_duration_hours'].describe())\n\nprint(train_data[train_data['trip_duration_hours'] > 5].count()['id'])\nprint(len(train_data))\n\ntrain_data.drop(train_data[train_data.trip_duration_hours > 5].index, inplace=True)\nprint(len(train_data))\n\nprint(max(train_data['trip_duration_hours']))\nprint(min(train_data['trip_duration_hours']))\n\nprint(train_data['trip_duration_hours'].describe())\n\n# traveling without passengers\nprint(train_data['passenger_count'].unique())\nprint(test_data['passenger_count'].unique())\nprint(test_data[(test_data['passenger_count'] == 0)].count()['id'])\n\n# remove outliers of extreme longitude and latitude\nplt.plot(train_data['pickup_longitude'], train_data['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Pickup Location Lat and Long', weight='bold')\nplt.show()\n\nplt.plot(train_data['dropoff_longitude'], train_data['dropoff_latitude'], '.', color='k', alpha=0.8)\nplt.title('Dropoff Location Lat and Long', weight='bold')\nplt.show()\n\n# Remove latitude and longitude outlier\ntrain_data = train_data[train_data.pickup_latitude != 51.881084442138672]\ntrain_data = train_data[train_data.pickup_longitude != -121.93334197998048]\ntrain_data = train_data[train_data.dropoff_longitude != -121.93320465087892]\ntrain_data = train_data[train_data.dropoff_latitude != 32.181140899658203]\n\nplt.plot(train_data['pickup_longitude'], train_data['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Pickup Location Lat and Long', weight = 'bold')\nplt.show()\n\nplt.plot(train_data['dropoff_longitude'], train_data['dropoff_latitude'], '.', color='k', alpha=0.8)\nplt.title('Dropoff Location Lat and Long', weight = 'bold')\nplt.show()\n\nmean_pickup_lat = np.mean(train_data['pickup_latitude'])\nmean_pickup_lon = np.mean(train_data['pickup_longitude'])\n\nprint(mean_pickup_lat)\nprint(mean_pickup_lon)\n\n# Standard deviation of pickup & dropoff Lats and Longs\nstd_pickup_lat = np.std(train_data['pickup_latitude'])\nstd_pickup_lon = np.std(train_data['pickup_longitude'])\n\nprint(std_pickup_lat)\nprint(std_pickup_lon)\n\nmin_pickup_lat = mean_pickup_lat - std_pickup_lat\nmax_pickup_lat = mean_pickup_lat + std_pickup_lat\nmin_pickup_lon = mean_pickup_lon - std_pickup_lon\nmax_pickup_lon = mean_pickup_lon + std_pickup_lon\n\nlocations = train_data[(train_data.pickup_latitude > min_pickup_lat) &\n                       (train_data.pickup_latitude < max_pickup_lat) &\n                       (train_data.pickup_longitude > min_pickup_lon) &\n                       (train_data.pickup_longitude < max_pickup_lon)]\n\nplt.plot(locations['pickup_longitude'], locations['pickup_latitude'], '.', color='k', alpha=0.8)\nplt.title('Reduced Pickup Lat and Long', weight='bold')\nplt.show()\n\nprint(len(train_data))\nprint(len(locations))\n\n# making a duplicate copy of the df to work on\nlocations_1 = locations\nprint(locations_1.head())\n\n# Assigning the target variable\nlabels = train_data['trip_duration']\n\nprint(train_data.head())\n\n# convert the categorical variables to numerical variables\ndf_s_f_train = pd.get_dummies(train_data['store_and_fwd_flag'])\ndf_s_f_test = pd.get_dummies(test_data['store_and_fwd_flag'])\n\n# Join the dummy variables to the main dataframe\ntrain_data = pd.concat([train_data, df_s_f_train], axis=1)\ntest_data = pd.concat([test_data, df_s_f_test], axis=1)\n\n# Drop the categorical column\ntrain_data.drop('store_and_fwd_flag', axis=1, inplace=True)\ntest_data.drop('store_and_fwd_flag', axis=1, inplace=True)\n\ntrain_data = train_data.loc[:, ~train_data.columns.duplicated()]\ntest_data = test_data.loc[:, ~test_data.columns.duplicated()]\n\ntrain_data.drop('id', axis=1, inplace=True)\nprint(train_data.isnull().values.any())\nprint(test_data.isnull().values.any())\n\nprint (train_data.isnull().values.any())\nprint (test_data.isnull().values.any())\n\nprint(train_data.head())\nprint(test_data.head())\n\nb_train = train_data.drop(['pickup_datetime', 'dropoff_datetime',\n                           'dropoff_hour', 'dropoff_month',\n                           'dropoff_day', 'trip_duration',\n                           'trip_duration_mins', 'trip_duration_hours'], 1)\nb_label = train_data['trip_duration']\n\ntest = test_data\ntest = test.drop(['pickup_datetime', 'id'], 1)\nprint(test.head())\n\n# List of important features\nRF = RandomForestRegressor()\nRF.fit(b_train, b_label)\n\nprint(RF)\n\nfeatures_list = b_train.columns.values\nfeature_importance = RF.feature_importances_\nsorted_idx = np.argsort(feature_importance)\n\nprint(sorted_idx)\n\nplt.figure(figsize=(15, 15))\nplt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), features_list[sorted_idx])\nplt.xlabel('Importance')\nplt.title('Feature importances')\nplt.draw()\nplt.show()\n\n# Predicting for the test data -----------;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\ntest_data = test_data.drop('pickup_datetime', 1)\ntest_data=test_data.drop('id', 1)\n# Predicting for the test data -----------;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n\nprint(test.head())\nY_pred = RF.predict(test)\n\nfinal = pd.DataFrame()\nfinal['id'] = test_data['id']\nfinal['trip_duration'] = Y_pred\nfinal.to_csv('RF_1.csv', index=False)\nprint('DONE!!')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}