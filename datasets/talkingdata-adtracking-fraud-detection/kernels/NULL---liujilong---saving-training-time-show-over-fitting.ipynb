{"cells":[{"metadata":{"_uuid":"f06369fe05d11dab6229f37ebe0a034a2bc8ce61"},"cell_type":"markdown","source":"# Show how to Saving Training Time, Show Over-fitting in this kernel.\n\n let's start"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"1d84720d78fd00e4f53c96793ce1c95de9b55349"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nimport gc\nimport os\nfrom sklearn.metrics import roc_auc_score","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"0b523d461d9c61b1c9a1cd4cc35dd132ff024478"},"cell_type":"markdown","source":"As usual, load dataset, feature engineer, train_valid split, preparing lightgbm DataSet"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":false},"cell_type":"code","source":"dtypes = {\n    'ip'            : 'uint32',\n    'app'           : 'uint16',\n    'device'        : 'uint8',\n    'os'            : 'uint16',\n    'channel'       : 'uint16',\n    'is_attributed' : 'uint8',\n    'click_id'      : 'uint32',\n}\ntrain_df = pd.read_csv(\"../input/train.csv\", parse_dates=['click_time'], nrows=1000000, dtype=dtypes, usecols=['ip','app','device','os', 'channel', 'click_time', 'is_attributed'])\n\nprint('Extracting new features...')\ntrain_df['hour'] = pd.to_datetime(train_df.click_time).dt.hour.astype('uint8')\ntrain_df['day'] = pd.to_datetime(train_df.click_time).dt.day.astype('uint8')\nval_df = train_df[900000:]\ntrain_df = train_df[:900000]\n\ntarget = 'is_attributed'\npredictors= ['app','os', 'channel', 'hour']\ncategorical = ['app', 'os', 'channel', 'hour']\n\nprint(\"preparing validation datasets\")\nxgtrain = lgb.Dataset(train_df[predictors].values,\n                      label=train_df[target].values,\n                      feature_name=predictors,\n                      categorical_feature=categorical\n                      )\nxgvalid = lgb.Dataset(val_df[predictors].values,\n                      label=val_df[target].values,\n                      feature_name=predictors,\n                      categorical_feature=categorical\n                      )\nlgb_params = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric':'auc',\n}\nevals_results = {}","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"# Almost every public solution set `valid_sets = [xgtrain, xgvalid]`. \n\n# Then lgb will calculate auc on train data each boost, which is time-consuming.\n\n\n# Consider that early-stoping only need auc on valid data, we can remove `xgtrain` from `valid_sets`, which Andy points out in another kernel."},{"metadata":{"trusted":false,"_uuid":"a230129a45a455155de9dd98e50611c63e1fb940"},"cell_type":"code","source":"\nbst1 = lgb.train(lgb_params,\n                 xgtrain,\n                 valid_sets=[xgvalid],\n                 valid_names=['valid'],\n                 evals_result=evals_results,\n                 num_boost_round=1000,\n                 early_stopping_rounds=50,\n                 verbose_eval=10)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"7a6121d20756a6e6754701330800130596f0eaf8"},"cell_type":"markdown","source":"# Sometimes train auc also valuable for dealing with overfitting. We can re-calculate train_auc after training, predicting, writing...."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0348955c88b23195fa6bbaa4e03e490867e6ba0f"},"cell_type":"code","source":"def lgb_auc(bst, train_df, predictors, target, num_iter=None):\n    if num_iter is None:\n        num_iter = bst.best_iteration\n    pred = bst.predict(train_df[predictors], num_iteration=num_iter)\n    return roc_auc_score(train_df[target], pred)","execution_count":10,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":false,"_uuid":"8a7005bb6934e9f8b5ba4f14fe884df3f7a84d80"},"cell_type":"code","source":"train_auc = lgb_auc(bst1, train_df, predictors, target)\nval_auc = lgb_auc(bst1, val_df, predictors, target)\nprint(f\">>>>>> train_auc {train_auc}  val_auc  {val_auc}\")","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"971a50f7ad830406ae2dfc5cb126afaf4f6b1e8d"},"cell_type":"markdown","source":"# What's more, Auc curve could be more helpfu"},{"metadata":{"trusted":false,"_uuid":"4865cfe5f0e6615de1f288682efda824a0281167"},"cell_type":"code","source":"%matplotlib inline\npoints = 20\nbest_iter = bst1.best_iteration\ncur_iter = bst1.current_iteration()\nstep_len = int(best_iter / points)\niters = range(0, cur_iter, step_len)\ntrain_auc = [lgb_auc(bst1, train_df, predictors, target, ite)\n             for ite in iters]\nval_auc = [lgb_auc(bst1, val_df, predictors, target, ite)\n             for ite in iters]\nimport matplotlib.pyplot as plt\nplt.plot(iters, train_auc, 'r', label=\"train_auc\")\nplt.plot(iters, val_auc, 'g', label=\"valid_auc\")\nplt.legend(bbox_to_anchor=(0.7, 0.3), loc=2, borderaxespad=0.)\nplt.show()","execution_count":22,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}