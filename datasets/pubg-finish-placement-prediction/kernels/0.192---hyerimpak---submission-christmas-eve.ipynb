{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import math\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5221f87211fa2dcd4bed5c3c11ac9c923258ae28"},"cell_type":"code","source":"df0 = pd.read_csv(\"../input/train_V2.csv\")\ndf = df0.head(20000)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32978fbca09dcfbe2d33f0349d7ac509cd706fe8"},"cell_type":"code","source":"# Define the input feature: total_rooms.\nmy_feature = df[[\"heals\", \"kills\",\"killPlace\"]]\n\n# Configure a feature column for total_rooms.\nfeature_columns = [tf.feature_column.numeric_column(\"heals\"),\n                   tf.feature_column.numeric_column(\"kills\"),\n                   tf.feature_column.numeric_column(\"killPlace\"),\n                   tf.feature_column.bucketized_column(\n                   source_column = tf.feature_column.numeric_column(\"heals\"), \n                   boundaries = [0, 10, 100]),\n                   tf.feature_column.crossed_column(\n                   [tf.feature_column.bucketized_column(\n                   source_column = tf.feature_column.numeric_column(\"kills\"), \n                   boundaries = [0, 1, 5, 10]),\n                   tf.feature_column.bucketized_column(\n                   source_column = tf.feature_column.numeric_column(\"killPlace\"), \n                   boundaries = [0, 2, 3, 5, 10])], \n                   hash_bucket_size = 500\n                   )\n                  ]\n\n# Define the label.\ntargets = df[\"winPlacePerc\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c0131ce43e80c2670a4efc43298dd4ce90ecc8d"},"cell_type":"code","source":"import matplotlib.pyplot as  plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0765e49b4749a0d1b929d60ca0f5ffcdcc824521"},"cell_type":"code","source":"f, ax = plt. subplots(figsize=(15, 15))\nsns.heatmap(my_feature.corr(), annot=True, linewidths=.5, ax=ax)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82607b9f40bfc2331ee3f2a9f53abb880dbd0bd9"},"cell_type":"code","source":"# Use gradient descent as the optimizer for training the model.\nmy_optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.001)\nmy_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n\n# Configure the linear regression model with our feature columns and optimizer.\n# Set a learning rate of 0.0000001 for Gradient Descent.\nlinear_regressor = tf.estimator.LinearClassifier(\n    feature_columns=feature_columns,\n    optimizer=my_optimizer\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"080a017627f5b5d390e56cd3689c5255ded37c6e"},"cell_type":"code","source":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n  \n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n  \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n \n    # Construct a dataset, and configure batching/repeating.\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified.\n    if shuffle:\n      ds = ds.shuffle(buffer_size=10000)\n    \n    # Return the next batch of data.\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78494cdf5e129eb658775e36714b23633b7b6bea"},"cell_type":"code","source":"_ = linear_regressor.train(\n    input_fn = lambda:my_input_fn(my_feature, targets),\n    steps=5000\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4040fa1f8ac801b30e01f2e427c933fb771dcfd7"},"cell_type":"code","source":"# Create an input function for predictions.\n# Note: Since we're making just one prediction for each example, we don't \n# need to repeat or shuffle the data here.\nprediction_input_fn =lambda: my_input_fn(my_feature, targets, num_epochs=1, shuffle=False)\n\n# Call predict() on the linear_regressor to make predictions.\npredictions = linear_regressor.predict(input_fn=prediction_input_fn)\n\npredictions_prob = np.array([item['probabilities'][1]]for ittem in predictions)\n\n# Format predictions as a NumPy array, so we can calculate error metrics.\n# predictions = np.array([item['predictions'][0] for item in predictions])\n\npredictions_prob = np.array([item['probabilities'][1] for item in predictions])\n\n# Print Mean Squared Error and Root Mean Squared Error.\nmean_squared_error = metrics.mean_absolute_error(predictions_prob, targets)\nroot_mean_squared_error = math.sqrt(mean_squared_error)\nprint(\"Mean Squared Error (on training data): %0.3f\" % mean_squared_error)\nprint(\"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea1862c23076738fce53d8111a668e7ab6f909ae"},"cell_type":"code","source":"predictions_prob[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33e437c6943a91b147567f15ded4687f88107d13"},"cell_type":"code","source":"df.head(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2437a6e00fc84411ae9cecf5acd179f2cfc5e47"},"cell_type":"code","source":"test_df0 = pd.read_csv(\"../input/test_V2.csv\")\n#test_df = test_df0.head(1000)\ntest_df = test_df0.copy()\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3dd3a067804d39737ab945956d9196557e82e5db"},"cell_type":"code","source":"pred_my_feature = test_df[[\"heals\", \"kills\",\"killPlace\"]]\npred_targets = test_df['assists']\nprediction_input_fn =lambda: my_input_fn(pred_my_feature, pred_targets, num_epochs=1, shuffle=False)\n\n# Call predict() on the linear_regressor to make predictions.\npredictions = linear_regressor.predict(input_fn=prediction_input_fn)\n\n# Format predictions as a NumPy array, so we can calculate error metrics.\n# predictions = np.array([item['predictions'][0] for item in predictions])\n\npredictions_prob = np.array([item['probabilities'][1] for item in predictions])\n\npredictions_prob[0:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bc1c5ef727d1ecd7a92660061f7710002ca5d63"},"cell_type":"code","source":"test_id = test_df[\"Id\"]\nresult = pd.DataFrame({\"Id\": test_id, \"winPlacePerc\": predictions_prob})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0b9b33d9895bfebe5ddaff10acaae758209aeef"},"cell_type":"code","source":"result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbfe45fca0b486b2765ae1d3619be9659d2add4d"},"cell_type":"code","source":"test_df0.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e36cdd9e3cfcc9a8b44621bdcf01264c4b17be3"},"cell_type":"code","source":"result.to_csv(\"submission.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8b0ba1ff17628b56ab7d352f08f01c82d24d547f"},"cell_type":"code","source":"print(os.listdir(\".\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b46ef047a31be65d740675ee05c6149fd61aaf43"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}