{"nbformat_minor": 0, "cells": [{"metadata": {"_uuid": "1cd1e9eb7c5c7db5c078163cc3ddcb94fc3d741f", "collapsed": false, "_cell_guid": "4f1258d5-89e7-4b07-a4d4-6efca9276c2e", "_execution_state": "idle"}, "outputs": [], "source": "This is an introductory analysis of the New York City Taxi Trip Duration that I have made. I have made use of the weather dataset - https://www.kaggle.com/mathijs/weather-data-in-new-york-city-2016 that was provided by the community to try and explore additional correlations that could be a significant factor.  The three major weather factors that are available are as follows,\n1) Precipitation\n2) Snow Fall\n3) Snow Depth\n\nAs expected, the dip during The end of January was primarily due to heavy snowfall and corroborates the claim made earlier in a different kernel.", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "63cdd8be15a163e65917704853311549b96ffa3b", "collapsed": false, "_cell_guid": "fcebf808-f810-4043-85e0-3321fd84dbed", "_execution_state": "idle"}, "outputs": [], "source": "I have added the entire code in the below section and will be adding the relevant diagrams, this is my first kernel with Kaggle, will try to organize it better in the near future. The kernel times out after 1200 Seconds, and since my program takes more than that for execution, I would appreciate it if you can run the same locally to verify the results. For purpose of execution, I have added a break statement to break out of loop on processing the first 1,00,000 cab results. You can comment the \"break\" associated with that If statement to remove it before running locally.\n\n", "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "b5b4613e919010b584a27203089e06946960903c", "collapsed": false, "_cell_guid": "ed03f53e-0bdb-4934-8235-564378cc8e1a", "_execution_state": "idle", "trusted": false}, "outputs": [], "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom math import sin, cos, sqrt, atan2, radians\nimport datetime as dt\nprint(os.listdir(\"../input\"))\n#from sklearn import model_selection, preprocessing\nimport xgboost as xgb\ncolor = sns.color_palette()\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', 500)\n\ntrain_df = pd.read_csv(\"../input/nyc-taxi-trip-duration/train.csv\")\nweather = pd.read_csv(\"../input/weather-data-in-new-york-city-2016/weather_data_nyc_centralpark_2016.csv\")\n\nR = 6373.0\n\nprint(train_df.shape)\nprint(\"Loaded\")\nprint(weather.shape)\n#print(weather.iloc[[1]].id)\nweatherMatrix = weather.as_matrix()\n#print(weatherMatrix[0])\ndate_dict = {}\ncount = 0\nfor date in weather.date:\n    precip = weather.iloc[count]['precipitation']\n    if str(weather.iloc[count]['precipitation']) == \"T\":\n        precip = 0\n    snow_fall = weather.iloc[count]['snow fall']\n    if str(weather.iloc[count]['snow fall']) == \"T\":\n        snow_fall = 0\n    snow_depth = weather.iloc[count]['snow depth']\n    if str(weather.iloc[count]['snow depth']) == \"T\":\n        snow_depth = 0\n    date_dict[str(date)] = {'avg_temp':weather.iloc[count]['average temperature'] , 'prec': float(precip) ,  'snow_fall': float(snow_fall) , 'snow_depth':float(snow_depth)}\n    count = count + 1\n\n\ncount = 0\nfor pickup_datetime in train_df.pickup_datetime:\n    dateString = str(pickup_datetime)\n    dateString = dateString[2:10]\n    dateString = dateString[6:] + \"-\" + dateString[3:5] + \"-\" + dateString[0:2]\n    #print(dateString)\n    if not 'trip' in date_dict[dateString]:\n        date_dict[dateString]['trip'] = []\n        # Create a array\n    dataObject = {}\n    keysToRead = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','trip_duration']\n    for keys in keysToRead:\n        #print(float(train_df.iloc[count][keys]))\n        dataObject[keys]  = float(train_df.iloc[count][keys])\n    lat1 = radians(abs(dataObject['pickup_latitude']))\n    lon1 = radians(abs(dataObject['pickup_longitude']))\n    lat2 = radians(abs(dataObject['dropoff_latitude']))\n    lon2 = radians(abs(dataObject['dropoff_longitude']))\n\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n\n    distance = R * c\n    dataObject['distance'] = distance\n    dataObject['speed'] = (distance * 60 * 60)/dataObject['trip_duration']\n    date_dict[dateString]['trip'].append(dataObject)\n    count = count + 1\n    if(count % 100000 == 0):\n        # Remove this break and run the results.\n        break\n        print(str(count) + ' finished processing')\n#print(\"completed\")\n#print len(date_dict['21-10-16']['trip'])\n#print(date_dict)\n\ncount = 0\ndates = []\nrainValid = []\ndatesValid = []\nsnowFallValid = []\nsnowDepthValid = []\ntripsByDate = []\nspeedList = []\navgSpeedList = []\nplt.figure(figsize=(12,6))\n\n#fig, ax = plt.subplots()\nfor date in weather.date:\n    if 'trip' in date_dict[str(date)]:\n        # calculate avg speed.\n        speedSum = 0\n        modifyDate = str(date)\n        modifyDate = modifyDate[0:6] + \"20\" + modifyDate[6:]\n        dateObject = dt.datetime.strptime(modifyDate,'%d-%m-%Y').date()\n        for tripDetail in date_dict[str(date)]['trip']:\n            dates.append(dateObject)\n            speedList.append(tripDetail['speed'])\n            speedSum = speedSum + tripDetail['speed']\n        date_dict[str(date)]['avgSpeed'] = speedSum / len(date_dict[str(date)]['trip'])\n        datesValid.append(dateObject)\n        rainValid.append(date_dict[str(date)]['prec'])\n        snowFallValid.append(date_dict[str(date)]['snow_fall'])\n        snowDepthValid.append(date_dict[str(date)]['snow_depth'])\n        avgSpeedList.append(date_dict[str(date)]['avgSpeed'])\n        tripsByDate.append(len(date_dict[str(date)]['trip']))\n    else:\n        break\n    count = count + 1\n\nplt.suptitle('Relation between number of trips and Snow Depth', fontsize=14, fontweight='bold')\nplt.subplot(211)\nplt.plot(datesValid, tripsByDate)\nplt.ylabel('Number of trips',fontsize = 12)\nplt.grid()\n\n#ax2 = fig1\nplt.subplot(212)\nplt.plot(datesValid, snowDepthValid)\nplt.ylabel('Snow Depth',fontsize = 12)\nplt.grid()\nplt.show()\n\n\nplt.suptitle('Scatter plot of all speeds on given day to understand outliers', fontsize=14, fontweight='bold')\nplt.scatter(dates,speedList,s=2,c='r')\nplt.ylabel('All speeds on given day', fontsize = 12)\nplt.grid()\nplt.show()\n\nplt.suptitle('Relation between average Speed and Snow Depth', fontsize=14, fontweight='bold')\n#ax3 = fig1\nplt.subplot(211)\nplt.plot(datesValid,avgSpeedList)\nplt.ylabel('Average speed', fontsize = 12)\nplt.grid()\n\nplt.subplot(212)\nplt.plot(datesValid, snowDepthValid)\nplt.ylabel('Snow Depth',fontsize = 12)\nplt.grid()\nplt.show()\n\n#ax4 = fig1\nplt.suptitle('Rain vs Average Speed Scatter Plot', fontsize=14, fontweight='bold')\nplt.scatter(avgSpeedList,rainValid,s=5,c='r')\nplt.ylabel('Rain', fontsize = 12)\nplt.xlabel('Average speed', fontsize = 12)\nplt.grid()\nplt.show()\n\n#ax5 = fig1\nplt.suptitle('Snow fall vs Average Speed Scatter Plot', fontsize=14, fontweight='bold')\nplt.scatter(avgSpeedList,snowFallValid,s=5,c='r')\nplt.ylabel('Snow fall', fontsize = 12)\nplt.xlabel('Average speed', fontsize = 12)\nplt.grid()\nplt.show()\n\n#ax6 = fig1\nplt.suptitle('Snow Depth vs Average Speed Scatter Plot', fontsize=14, fontweight='bold')\nplt.scatter(avgSpeedList,snowDepthValid,s=5,c='r')\nplt.ylabel('Snow depth', fontsize = 12)\nplt.xlabel('Average speed', fontsize = 12)\nplt.grid()\nplt.show()\n\nprint(\"Completed Execution\")\nquit()", "cell_type": "code", "execution_count": 1}, {"metadata": {"_uuid": "76854cb20e6d3679b9d9b9bb5d1bfc080c68a360", "collapsed": false, "_cell_guid": "53a51a75-be52-428a-85f0-cd6107b7b0a1", "_execution_state": "idle"}, "outputs": [], "source": "As already mentioned before, the above graphs are only with 1,00,000 rows from the dataset due to execution time constraints.\n\nThe Graphs with all the rows of the dataset can be found here.\nhttps://drive.google.com/drive/folders/0ByVZySGjhrMzWGRBVlZET013M3M?usp=sharing\nKindly view the graphs here, as they are more accurate and present better insights into the same.\n\nKindly note that the concept of speed below is pretty much flawed, we assume straight line distance between the 2 coordinates which is much lesser than the actual distance covered, the actual average speeds are bound to be much higher than the above, but however we can get a sense of the impact from this kind of observation.\n\n**Observations**\n1) The overall effect of all thre phenomenon has been as expected, with most of the high snow depth or precipitation values coinciding with lower average speeds. I was hoping for a stronger correlation between snowfall and the average speeds, however there is a substantially good correlation between the snowfall depth and number of vehicles recorded.\n\n\nImage1)  The peak in snow depth exactly corresponds to the day with least number of trips.\n\nImage2) A scatter plot of all speeds on a given day was plotted to have an understanding of the outliers and will have to determine thresholds to remove them on basis of percentiles.\n\n\nImage3) The average speed has also been compared with the snow depth.\n\nImage4) Scatter Plot of Rain vs Avg Speed\n\nImage5) Scatter Plot of Snow Fall vs Avg Speed\n\nImage6) Scatter plot of Snow Depth vs Avg Speed\n\n", "cell_type": "markdown", "execution_count": null}], "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}