{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b0fd9509-fc6b-4043-dd3b-6c1dcb9b8e07"
      },
      "source": [
        "I'm a totally new bee in Kaggle and this is my first competition, got ~1114 in public leaderboard using pure Xgboost in raw features with 5-fold cross_validation. I have learned a lot from kaggle forums and a friend.   I want to share it with all starters. Hope it will be helpful for someone. If there are any mistakes, please do not hesitate to let me know."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a73e0239-3ec8-e03e-ea2d-531c42b60afd"
      },
      "source": [
        "Due to this NoteBook cannot write files, so If you want to run my code, copy and paste them to your local workspace.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "90038d55-d53f-23d6-dfb7-43186b406ae3"
      },
      "source": [
        "###Step 1 \n",
        "\n",
        "Transform letters of categories in train.csv and test.csv into numbers for computation, using script bellow. you will get two files named train_num.csv and test_num.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ce663df-8ded-b911-7802-92d9d4f8e881"
      },
      "source": [
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    \n",
        "    np.random.seed(1234)\n",
        "    def LetterToNumber(data,dest_file):\n",
        "        for c in data.columns:\n",
        "            if 'cat' in c:\n",
        "                print c\n",
        "                data[c]=data[c].astype(\"category\")\n",
        "                data[c].cat.categories=range(len(set(data[c].values)))\n",
        "        data.to_csv(dest_file, index=False)\n",
        "    \n",
        "    \n",
        "    train = pd.read_csv(\"./data/train.csv\")\n",
        "    train_dest = \"./data/train_num.csv\"\n",
        "    LetterToNumber(train,train_dest)\n",
        "    test = pd.read_csv(\"./data/test.csv\")\n",
        "    test_dest = \"./data/test_num.csv\"\n",
        "    LetterToNumber(test,test_dest)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "027d95ed-aaf4-4a15-1dc5-0f645c41e916"
      },
      "source": [
        "###Step 2\n",
        "\n",
        "randomly split train data into five parts in preparation for cross_validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3374a140-5bb1-e86d-d99b-924a2057a308"
      },
      "source": [
        "    #split_cv.py\n",
        "    \n",
        "    import numpy as np\n",
        "    \n",
        "    np.random.seed(1234)\n",
        "    \n",
        "    ids=[]\n",
        "    for line in open(\"./data/cut_cv\"):\n",
        "        ids.append(int(line))\n",
        "    train=[0]*5\n",
        "    test=[0]*5\n",
        "    for i in range(5):\n",
        "        train[i]=open(\"./data/train_cv_\"+str(i)+\".csv\",\"w\")\n",
        "        test[i]=open(\"./data/test_cv_\"+str(i)+\".csv\",\"w\")\n",
        "    for j,line in enumerate(open(\"./data/train_num.csv\")):\n",
        "        if j==0:\n",
        "            for i in range(5):\n",
        "                train[i].write(line)\n",
        "                test[i].write(line)\n",
        "            continue\n",
        "        else:\n",
        "            for id in range(5):\n",
        "                if id != ids[j-1]:\n",
        "                    train[id].write(line)\n",
        "            test[ids[j-1]].write(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "93621df0-d24c-1b0a-ec2a-4be515c3189e"
      },
      "source": [
        "### Step 3\n",
        "\n",
        "using Xgboost to train and predict. \n",
        "\n",
        "we will get five predictions on test_num.csv."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "920f9c11-2f48-666c-e24a-f922343f888e"
      },
      "source": [
        "    #train_predict.py\n",
        "    \n",
        "    import xgboost\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    import datetime\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    \n",
        "    np.random.seed(1234)\n",
        "    \n",
        "    def logregobj(preds, dtrain):\n",
        "        labels = dtrain.get_label()\n",
        "        con = 2\n",
        "        x = preds-labels\n",
        "        grad = con*x / (np.abs(x)+con)\n",
        "        hess = con**2 / (np.abs(x)+con)**2\n",
        "        return grad, hess\n",
        "    \n",
        "    def xg_eval_mae(yhat, dtrain):\n",
        "        y = dtrain.get_label()\n",
        "        return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
        "                                          np.exp(yhat)-shift)\n",
        "    \n",
        "    \n",
        "    for CV in range(5):\n",
        "        CV = str(CV)\n",
        "        print 'loading...',CV\n",
        "        train=pd.read_csv(\"./data/train_cv_\"+CV+\".csv\")\n",
        "        test=pd.read_csv(\"./data/test_cv_\"+CV+\".csv\")\n",
        "        shift=200\n",
        "    \n",
        "        print 'droping...'\n",
        "        train_X=train.drop(['id','loss'],axis=1)\n",
        "        train_Y=np.log(train['loss']+shift)\n",
        "        test_X=test.drop(['id','loss'],axis=1)\n",
        "        test_Y=np.log(test['loss']+shift)\n",
        "    \n",
        "        train=xgboost.DMatrix(train_X,label=train_Y)\n",
        "        test=xgboost.DMatrix(test_X,label=test_Y)\n",
        "        #8 12\n",
        "        param = {'max_depth':8 , 'gamma': 0, 'silent': 0, 'boost': 'gbtree', 'objective': 'reg:linear',\n",
        "                 'alpha': 1, 'subsample': 0.86, \"min_child_weight\": 50,\n",
        "                 \"colsample_bytree\": 0.32, 'colsample_bylevel': 1}\n",
        "    \n",
        "    \n",
        "        param['nthread'] = 1\n",
        "        num_round = 200000\n",
        "    \n",
        "        watchlist = [(train,'train'),(test,'test')]\n",
        "    \n",
        "        print \"trainning...\"\n",
        "        bst = xgboost.train(param.items(),train, num_round,watchlist,learning_rates=[0.02]*num_round,obj=logregobj,\n",
        "                            feval=xg_eval_mae,maximize=False,early_stopping_rounds=500)\n",
        "    \n",
        "        for i,line in enumerate(sorted(bst.get_score().iteritems(),key=lambda d:d[1], reverse=True)):\n",
        "            if i>30:\n",
        "                break\n",
        "            print line\n",
        "    \n",
        "        print 'loading...'\n",
        "        raw_test=pd.read_csv(\"./data/test_num.csv\")\n",
        "        test=xgboost.DMatrix(raw_test.drop(['id'],axis=1))\n",
        "    \n",
        "        print 'predicting...'\n",
        "        result=np.exp(bst.predict(test))-200\n",
        "        now = datetime.datetime.now()\n",
        "        pd.DataFrame({'id':raw_test['id'].values,'loss':result}).to_csv('./result/cv_cls2/'+\n",
        "                                                                        now.strftime(\"%Y-%m-%d-%H-%M\")+\n",
        "                                                                        \"_\"+CV+\".csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8a1259b2-3468-eff9-887a-af6ee32e1b36"
      },
      "source": [
        "### Step 4\n",
        "\n",
        "The last thing is to **average out** above five results on test_num.csv and get the final prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2dd0e1da-f559-7e35-d787-3c5af6117e3d"
      },
      "source": [
        "    #merge_result.py\n",
        "    \n",
        "    import os\n",
        "    import datetime\n",
        "    dir=os.listdir(\"./result/cv_cls2/\")\n",
        "    ID=[]\n",
        "    temp = []\n",
        "    ct=[]\n",
        "    for i,file in enumerate(dir):\n",
        "        file=\"./result/cv_cls2/\"+file\n",
        "        print file\n",
        "        for j,line in enumerate(open(file)):\n",
        "            if j==0:\n",
        "                continue\n",
        "            if i==0:\n",
        "                ID.append(line.split(\",\")[0])\n",
        "                temp.append(float(line.split(\",\")[1]))\n",
        "                ct.append(1)\n",
        "            else:\n",
        "                temp[j-1]+=float(line.split(\",\")[1])\n",
        "                ct[j-1]+=1\n",
        "    now = datetime.datetime.now()\n",
        "    \n",
        "    path = './result/' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '_cls2.csv'\n",
        "    tow=open(path,\"w\")\n",
        "    tow.write(\"id,loss\\n\")\n",
        "    for i,line in enumerate(temp):\n",
        "        r=temp[i]/ct[i]\n",
        "        tow.write(ID[i]+\",\"+str(r)+\"\\n\")\n",
        "    tow.close()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}