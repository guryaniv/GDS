{"cells":[{"metadata":{"_uuid":"a1257556f487c955cf52cb12a9ef21cc7c52b9d0"},"cell_type":"markdown","source":"prepare a list of image files"},{"metadata":{"trusted":true,"_uuid":"86ea0cad4f03f91588d4a186c0092324a102e7e2"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm_notebook\nimport os\n\ndata_dir = \"../input/\"\n\nw_size = 1024\no_size = 512\n\ntrain = pd.read_csv(data_dir+\"/train.csv\")\nprint(train.head())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36380e99115c81f86e8867af4a1e237d9fd5accf"},"cell_type":"markdown","source":"compose an array of names and labels"},{"metadata":{"trusted":false,"_uuid":"a49ed98c13aab392a957d29718670e7ebd1982de"},"cell_type":"code","source":"train_dataset_info = []\n\nfor name, labels in zip(train['Id'], train['Target'].str.split(' ')):\n        lb = np.zeros(28, dtype='int')\n        for label in labels:\n            lb[int(label) ] = 1\n        train_dataset_info.append({\n        'path':os.path.join(data_dir+\"train/\", name),\n        'labels':lb})\ntrain_dataset_info = np.array(train_dataset_info)\ntrain_num = train_dataset_info.shape[0]\nprint (\" images num \", train_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dfb55ebdb2671c10b719b4c50ef1ad34d01c2e6"},"cell_type":"markdown","source":"we will choose the signs so that each sign would be no more than 100, \nor if there are not many of them, then all are chosen"},{"metadata":{"trusted":false,"_uuid":"71da67f37aeb143da2c13ec9ab1d6c0a01008348"},"cell_type":"code","source":"idx = np.zeros((28),dtype='int')\ntst = np.zeros((train_num),dtype='int')[:]>0\nfor k in range(train_num):\n    for i in range(28):\n        if idx[i]<100 and train_dataset_info[k][\"labels\"][i] > 0:\n            idx += train_dataset_info[k][\"labels\"]\n            tst[k] = True\n            break\nw_train_dataset_info = train_dataset_info[tst]\nw_num = w_train_dataset_info.shape[0]\n#w_num, idx","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b6304d40335b255d7f85aa3ea5a0921be0728fe"},"cell_type":"markdown","source":"make a small training set"},{"metadata":{"trusted":false,"_uuid":"a5a34c68f5ac788c7083074ceb5fede70d7b3e03"},"cell_type":"code","source":"num_classes = 28\nw_imgs = np.zeros((w_num,w_size,w_size,1), dtype='float32')\nw_class = np.zeros((w_num,num_classes), dtype='float32')\n\nfor k in tqdm_notebook(range(w_num)):\n    red =   np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_red.png\"   ))\n    green = np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_green.png\" ))\n    blue =  np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_blue.png\"  ))\n    yellow =np.array(Image.open(w_train_dataset_info[k][\"path\"]+\"_yellow.png\"))\n    w_imgs[k,::2,::2,0]  = red/255.\n    w_imgs[k,1::2,::2,0] = blue/255.\n    w_imgs[k,::2,1::2,0] = green/255.\n    w_imgs[k,1::2,1::2,0]= yellow/255.\n    w_class[k] = w_train_dataset_info[k][\"labels\"]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3072f1ca544602a543f2a1caa63d1d84c0907fbb"},"cell_type":"markdown","source":"load libraries"},{"metadata":{"trusted":false,"_uuid":"874089c8de84211c03b64564ba517ee1e721d129"},"cell_type":"code","source":"from keras import Model\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, Activation, Add\nfrom keras.layers import Dense, Flatten, BatchNormalization, AveragePooling2D\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\n#import keras as keras\nfrom keras import backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cb2d8e516cab946982f5bb0589492d53ea644a6"},"cell_type":"markdown","source":"building functions F1 and Loss"},{"metadata":{"trusted":false,"_uuid":"7ee28271cb653d6c7910ecd506be0f6f35f9a382"},"cell_type":"code","source":"def f1(y_true, y_pred):\n    y_pred = K.round(y_pred)\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    # tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n'''\nThanks Iafoss.\npretrained ResNet34 with RGBY\nhttps://www.kaggle.com/iafoss/pretrained-resnet34-with-rgby-0-460-public-lb\n'''\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n    y_true = tf.convert_to_tensor(y_true, np.float32)\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    #return binary_crossentropy(y_true, y_pred) + loss\n    return loss\n\nfrom keras.utils.generic_utils import get_custom_objects\n\nget_custom_objects().update({'focal_loss': focal_loss })\nget_custom_objects().update({'f1': f1 })\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b83815b41f4d42455ecfe73f809a34af99044589"},"cell_type":"markdown","source":"build model and special first layer"},{"metadata":{"trusted":false,"_uuid":"a4a643e81ddcf60783b1b2678d600913e9f1f47a"},"cell_type":"code","source":"def build_model(input_layer, start_neurons):\n\n    conv1 = Conv2D(start_neurons * 1, (14, 14), strides=(2, 2), activation=\"relu\", padding=\"same\")(input_layer)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n    drop = Dropout(0.5)(convm)\n\n    flat = Flatten()(drop)\n#    hidden = Dense(128, activation='relu')(flat)\n#    drop = Dropout(0.5)(hidden)\n    output_layer = Dense(num_classes, activation='sigmoid')(flat)\n    \n    return output_layer\ninput_layer = Input((w_size, w_size, 1))\noutput_layer = build_model(input_layer, 8)\nmodel = Model(input_layer, output_layer)\nmodel.compile(loss=\"focal_loss\", optimizer=Adam(lr=1e-3), metrics=[\"binary_accuracy\",\"f1\"])\n# model.save_weights('./init.weights')\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a546308d7254ed09a59436dad000b36ecb2778d"},"cell_type":"markdown","source":"compute"},{"metadata":{"trusted":false,"_uuid":"437f41acdb07a00fe2a911384654f94aa6bf22c4"},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='f1', mode = 'max',patience=10, verbose=1)\n#model_checkpoint = ModelCheckpoint(\"./keras_1-28_200.model\",monitor='val_f1', \n#                               mode = 'max', save_best_only=True, verbose=1)\n#reduce_lr = ReduceLROnPlateau(monitor='val_f1', \n#                              mode = 'max',\n#                              factor=0.2, \n#                              patience=5, min_lr=0.00001, \n#                              verbose=1)\n\nhistory = model.fit(w_imgs,w_class,\n                        epochs=20,\n                        batch_size=32,\n                        callbacks=[early_stopping],\n                        verbose=2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"58575dd9beb127937d2cfbdedddf62533a7af329"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}