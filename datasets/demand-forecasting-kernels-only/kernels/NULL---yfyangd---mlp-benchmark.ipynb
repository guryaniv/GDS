{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Input Data"},{"metadata":{"trusted":true,"_uuid":"2aabf3cbcb0d21aa97a1c36891ecd1b389766ca5","collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', parse_dates=['date'])\ntest = pd.read_csv('../input/test.csv', parse_dates=['date'])\nprint(\"Train shape: \", train.shape)\nprint(\"Test shape: \", test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7f32a1a0a7f1f16b6b27139179e1d47e0c8c2f8"},"cell_type":"markdown","source":"# Date Preprocess"},{"metadata":{"trusted":true,"_uuid":"852ae457db6c296fadae139326bc15d37c55dc93","collapsed":true},"cell_type":"code","source":"df = pd.concat([train,test])\ndf['month'] = df['date'].dt.month\ndf['weekday'] = df['date'].dt.dayofweek\ndf['year'] = df['date'].dt.year\ndf['week_of_year']  = train.date.dt.weekofyear\n\ndf.drop('date', axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"655a13f12a432abcfc2b8f7394664905acd1795c"},"cell_type":"markdown","source":"# Feature Extraction\nAdd historical / seasonal features. Thanks to [Dan Ofer's notebook](https://www.kaggle.com/danofer/getting-started-with-time-series-features)"},{"metadata":{"trusted":true,"_uuid":"e7178ebc1520f85f95b93b98b1d70cd5fe3af308","collapsed":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndf[\"median_store_item_month\"] = df.groupby(['month',\"item\",\"store\"])[\"sales\"].transform(\"median\")\ndf[\"mean_store_item_week\"] = df.groupby(['week_of_year',\"item\",\"store\"])[\"sales\"].transform(\"mean\")\ndf[\"item_month_sum\"] = df.groupby(['month',\"item\"])[\"sales\"].transform(\"sum\")\ndf[\"store_month_sum\"] = df.groupby(['month',\"store\"])[\"sales\"].transform(\"sum\")\ndf[\"item_week_shifted_90\"] = df.groupby(['week_of_year',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) \ndf[\"store_week_shifted_90\"] = df.groupby(['week_of_year',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).sum()) \ndf[\"item_week_shifted_90\"] = df.groupby(['week_of_year',\"item\"])[\"sales\"].transform(lambda x:x.shift(12).mean()) \ndf[\"store_week_shifted_90\"] = df.groupby(['week_of_year',\"store\"])[\"sales\"].transform(lambda x:x.shift(12).mean())\n\ntrain = df.loc[~df.sales.isna()]\ntrain4 = train.copy()\ntrain4.drop('id', axis=1, inplace=True)\ntrain4.head()\ncorr = train4.corr()\nsns.heatmap(corr, xticklabels=corr.columns,yticklabels=corr.columns)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"51cee23926f8f4591315e17012942d3b61f1d546"},"cell_type":"markdown","source":"# Label Encoding"},{"metadata":{"trusted":true,"_uuid":"67b3352e949dc86a4575073595d99fa99330cd7a","collapsed":true},"cell_type":"code","source":"train = df.loc[~df.sales.isna()]\ncol = [i for i in train.columns if i not in ['id','store','item']]\n\nfrom sklearn.preprocessing import LabelEncoder\ntrain = train[col].apply(LabelEncoder().fit_transform)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"063b6b9d50c12fea4b556703f723ea054a91572f","collapsed":true},"cell_type":"code","source":"col = [i for i in train.columns if i not in ['id','sales','store','item']]\nX_train=train[col].values\n\nY_train=train['sales'].values\nY_train=Y_train.reshape((913000,1))\n\nprint(\"X_train shape:\", X_train.shape)\nprint(\"Y_train shape:\", Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fb24a71413c9a29068083d13a054b9b12422de0"},"cell_type":"markdown","source":"Now the data format of feature & label are suitable for MLP model."},{"metadata":{"_uuid":"6436a2ffc64ac66ebc61bbd9d96a4429fefe9b06"},"cell_type":"markdown","source":"# Data split to training & testing sets"},{"metadata":{"trusted":true,"_uuid":"2713f8f46165f713cffcf2757f55ea42a2414353","collapsed":true},"cell_type":"code","source":"from sklearn import cross_validation\nx_train, x_test, y_train, y_test = cross_validation.train_test_split(X_train,Y_train, test_size=0.2, random_state=42)\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c38482c32d98194c4908452edeed77eeb13e0fc3"},"cell_type":"markdown","source":"# MLP model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ee71beb52d2a30f14b5a3e6fec24df37e43e7ee1"},"cell_type":"code","source":"import tensorflow as tf\ndef layer(output_dim,input_dim,inputs,activation=None):\n    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n    b = tf.Variable(tf.random_normal([1, output_dim]))\n    XWb = tf.matmul(inputs, W)+b\n    if activation is None:\n        outputs = XWb\n    else:\n        outputs = activation(XWb)\n    return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4ca03441664294df4a06a2f9244f544574c0d948"},"cell_type":"code","source":"X = tf.placeholder(\"float\", [None, 10])\nh1 = layer(20,10,X,activation=tf.nn.relu)\ny_predict = layer(1, 20, h1, activation=None)\ny_label = tf.placeholder(\"float\", [None, 1]) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfacffd00c28e9eadd7f97a99ca3d2929231a5d8"},"cell_type":"markdown","source":"We use MSE (Mean Squared Error) to optimize model by gradient descent."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e58fc775db0d580397a0b73f7a54505cf668abc8"},"cell_type":"code","source":"MSE=tf.losses.mean_squared_error(labels=y_label,predictions=y_predict)\noptimizer = tf.train.GradientDescentOptimizer(0.001).minimize(MSE)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c04e8fd7d399eb9ea52d83d99feac38a4d72b87"},"cell_type":"markdown","source":"Submissions are evaluated on [SMAPE](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error) between forecasts and actual values. We use tensorflow math function to construct SMAPE for session run."},{"metadata":{"_uuid":"b3b61050ef1f3b0132577980bf2af9c381c3635d"},"cell_type":"markdown","source":"<img style=\"float: left;\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/399d28f62c6ea8753ff1c2895dd6eb29df0d4ea5\" width = \"30%\">"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"decb792c52b5497c112d3961ce648c4b62f26561"},"cell_type":"code","source":"SMAPE = tf.reduce_mean(tf.divide(tf.abs(y_predict-y_label),tf.add(y_label,y_predict)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23392a34e042d4f79c9181b32467190f64101c88"},"cell_type":"markdown","source":"Create batch training sets"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d0fac6fdd16019270a1122616dcfe875fb084f9"},"cell_type":"code","source":"import math\ndef batches(batch_size, features,labels):\n    sample_size = len(features)\n    for start_i in range(0, sample_size, batch_size):\n        end_i = start_i + batch_size\n        batch1 = features[start_i:end_i]\n        batch2 = labels[start_i:end_i]\n    return batch1,batch2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e4e37945eeebab5d60ce702b4c3a0755e4b5b7a6"},"cell_type":"code","source":"trainEpochs = 20\nbatchSizes = 1000\ntotalBatchs = int(913000/batchSizes)\n\nepoch_list = []\nMSE_list = []\nSMAPE_list = []\nfrom time import time\nstartTime = time()\n\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5daade3e2040bc37f09175da94779e878c00b96f","collapsed":true},"cell_type":"code","source":"for epoch in range(trainEpochs):\n    for i in range(totalBatchs):\n        batch_x, batch_y = batches(batchSizes, x_train, y_train)\n        sess.run(optimizer,feed_dict={X: batch_x, y_label: batch_y})\n    mse,smape = sess.run([MSE,SMAPE],feed_dict={X: x_test,y_label: y_test})\n    epoch_list.append(epoch)\n    MSE_list.append(mse)\n    SMAPE_list.append(smape)\n    print(\"Train Epoch:\", '%02d' % (epoch+1), \"MES=\", \"{:.9f}\".format(mse), \"SMAPE=\", smape)\nduration = time() - startTime\nprint(\"Train Finished takes:\", duration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a914bffb795614b849e708957f39cf761647d2c","collapsed":true},"cell_type":"code","source":"%matplotlib inline\nfig = plt.gcf()\nfig.set_size_inches(10,6)\nplt.plot(epoch_list, MSE_list, label='MES')\nplt.ylabel('mean square error')\nplt.xlabel('epoch')\nplt.legend(['mean square error'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12830a50b7af31ddd9b6ec52add9dbea2cfada37","collapsed":true},"cell_type":"code","source":"%matplotlib inline\nfig = plt.gcf()\nfig.set_size_inches(10,6)\nplt.plot(epoch_list, SMAPE_list, label='SMAPE')\nplt.ylabel('Symmetric mean absolute percentage error')\nplt.xlabel('epoch')\nplt.legend(['SMAPE'], loc='upper left')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}