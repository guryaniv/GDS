{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "version": "3.6.1"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "24ab2d3d2a5e22d39f5ae085e60c7c25cd1c6da5", "_cell_guid": "14f861b1-935b-4ba3-a30d-5415e3c042d3"}, "source": "Hi everyone ! My brand new Python package for Auto Machine Learning is now available on github/PyPI/Kaggle kernels ! :)\n\n**https://github.com/AxeldeRomblay/MLBox**\n\n- It is very easy to use (see **documentation** on github)\n- It provides state-of-the-art algorithms and technics such as deep learning/entity embedding, stacking, leak detection, parallel processing, hyper-parameters optimization...\n- It has already been tested on Kaggle and performs well (see Kaggle \"Two Sigma Connect: Rental Listing Inquiries\" | Rank : **85/2488**)\n\n**Please put a star on github and fork the script if you like it !** \n\nEnjoy :) ", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "d6d75a4896f081924a5543f6b445cfeba5d9dc84", "_cell_guid": "8ca29877-e2cd-445e-a467-36b51e812fbd"}, "source": "# Inputs & imports : that's all you need to give !", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "613056b04596f9172a4c5db8461c3136a57bcb3e", "trusted": false, "_cell_guid": "a0dac371-048d-48f1-9963-886501f41b9f", "scrolled": true, "_execution_state": "idle"}, "source": "from mlbox.preprocessing import *\nfrom mlbox.optimisation import *\nfrom mlbox.prediction import *", "outputs": [], "cell_type": "code", "execution_count": 1}, {"metadata": {"_uuid": "c0e1392f67652dfca16e243fef253130722013f4", "collapsed": true, "trusted": false, "_cell_guid": "e8d1a1a3-3a05-4b01-b770-edb5a9841660", "_execution_state": "idle"}, "source": "paths = [\"../input/nyc-taxi-trip-duration/train.csv\", \"../input/nyc-taxi-trip-duration/test.csv\"]\ntarget_name = \"trip_duration\"", "outputs": [], "cell_type": "code", "execution_count": 2}, {"metadata": {"_uuid": "a831e8316140e27556837c563b9b533047f7ba82", "_cell_guid": "ac1ebc3f-f6e3-479a-afad-4b77f374cd76"}, "source": "# Now let MLBox do the job ! ", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "cb994fc1d95f8e03b58bceeadab819221c1d9a68", "collapsed": true, "trusted": false, "_cell_guid": "256092cd-331a-4fbe-b7da-9159a14aa3c6", "_execution_state": "idle"}, "source": "time.sleep(30)", "outputs": [], "cell_type": "code", "execution_count": 3}, {"metadata": {"_uuid": "a9d1e267c32e71dad123eedbc17ede00260ffe92", "_cell_guid": "6a0b084b-266a-4379-8491-1cc38046fe38"}, "source": "## ... to read and clean all the files ", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "e1725ecdb6b665cec0a8cf850aa14ce11feb752d", "trusted": false, "_cell_guid": "42328411-e370-474c-8014-c3940ddbd497", "scrolled": true, "_execution_state": "idle"}, "source": "rd = Reader(sep = \",\")\ndf = rd.train_test_split(paths, target_name)   #reading and preprocessing (dates, ...)", "outputs": [], "cell_type": "code", "execution_count": 4}, {"metadata": {"_uuid": "61a8ffd74acf55b6d8e595d75943056b0ceb9834", "_cell_guid": "37c8ffd5-2a9f-41d0-bc58-b2fbb540e790"}, "source": "**adding OSRM features and distances**", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "7335e13997b61ea1cdbdd20d25b57482daea87e7", "_cell_guid": "cf37e249-155a-402d-b7a7-c881c22f53a8"}, "source": "Here you can create your own features... Then MLBox will do the rest for you !", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "a9560abff0fd0143dc2e2bd284250b660dec0943", "collapsed": true, "trusted": false, "_cell_guid": "1c770a04-6d0d-491b-8a04-e03056c426ec", "_execution_state": "idle"}, "source": "cols = [u'id', u'starting_street', u'end_street', u'total_distance',u'total_travel_time', u'number_of_steps']\nextra_train = pd.read_csv(\"../input/new-york-city-taxi-with-osrm/fastest_route_train.csv\", usecols=cols)\nextra_test = pd.read_csv(\"../input/new-york-city-taxi-with-osrm/fastest_route_test.csv\", usecols=cols)\n\ndf['train'] = pd.merge(df['train'], extra_train, on ='id', how='left')\ndf['test'] = pd.merge(df['test'], extra_test, on ='id', how='left')", "outputs": [], "cell_type": "code", "execution_count": 5}, {"metadata": {"_uuid": "3e60aad020cba3631db7d9249df6b9758b4a14b8", "collapsed": true, "trusted": false, "_cell_guid": "f66fce55-3de7-4e34-8c08-c8cb2fbb13ea", "_execution_state": "idle"}, "source": "df['train'][\"N2\"] = ((df['train'][\"dropoff_longitude\"]-df['train'][\"pickup_longitude\"]).apply(lambda x: x**2) + (df['train'][\"dropoff_latitude\"]-df['train'][\"pickup_latitude\"]).apply(lambda x: x**2)).apply(lambda x: np.sqrt(x))\ndf['test'][\"N2\"] = ((df['test'][\"dropoff_longitude\"]-df['test'][\"pickup_longitude\"]).apply(lambda x: x**2) + (df['test'][\"dropoff_latitude\"]-df['test'][\"pickup_latitude\"]).apply(lambda x: x**2)).apply(lambda x: np.sqrt(x))\n\ndf['train'][\"N1\"] = (df['train'][\"dropoff_longitude\"]-df['train'][\"pickup_longitude\"]).apply(lambda x: np.abs(x)) + (df['train'][\"dropoff_latitude\"]-df['train'][\"pickup_latitude\"]).apply(lambda x: np.abs(x))\ndf['test'][\"N1\"] = (df['test'][\"dropoff_longitude\"]-df['test'][\"pickup_longitude\"]).apply(lambda x: np.abs(x)) + (df['test'][\"dropoff_latitude\"]-df['test'][\"pickup_latitude\"]).apply(lambda x: np.abs(x))\n\ndf['train'][\"pickup_distance_center\"] = ((df['train'][\"pickup_longitude\"].mean()-df['train'][\"pickup_longitude\"]).apply(lambda x: x**2) + (df['train'][\"pickup_latitude\"].mean()-df['train'][\"pickup_latitude\"]).apply(lambda x: x**2)).apply(lambda x: np.sqrt(x))\ndf['test'][\"pickup_distance_center\"] = ((df['test'][\"pickup_longitude\"].mean()-df['test'][\"pickup_longitude\"]).apply(lambda x: x**2) + (df['test'][\"pickup_latitude\"].mean()-df['test'][\"pickup_latitude\"]).apply(lambda x: x**2)).apply(lambda x: np.sqrt(x))", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "6bf2fd0e66dc7e077acb6232526e50cb0a075de6", "_cell_guid": "007d45d6-55a1-46e4-89dd-d5e094784337"}, "source": "**drift**", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "bdce6f5fe19d69f56d6f51058f38bde3e31aec0f", "trusted": false, "_cell_guid": "48189975-e4ef-4224-9519-368755310c39", "scrolled": false, "_execution_state": "idle"}, "source": "dft = Drift_thresholder()\ndf = dft.fit_transform(df)   #removing non-stable features (like ID,...)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "a8b63716606fa2ebb0f413748df92d6f7dc1bd0e", "_cell_guid": "a3a03b10-40e7-4aab-af14-2e625b0b7be4"}, "source": "## ... to tune all the hyper-parameters", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "f4147e50d2154d76e3d9975657d9f88f4b4647db", "collapsed": true, "trusted": false, "_cell_guid": "6b717ff4-70cc-49cf-b2da-52be333eae60", "_execution_state": "idle"}, "source": "df['target'] = df['target'].apply(lambda x: np.log1p(x))   #evaluation metric: rmsle\n\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))\n\nopt = Optimiser(scoring = make_scorer(rmse, greater_is_better=False), n_folds=2)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "4deb51e8741515a9962b69381882a8243c4c187e", "_cell_guid": "84c4d0b1-9c08-4711-9e1b-ccf1678e85f0"}, "source": "**XGBoost**", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "f9142b5974225c1e59f933d753c1ed1a85105caa", "trusted": false, "_cell_guid": "61cff212-9a26-4d2b-b14f-10a6ccd3f2b6", "_execution_state": "idle"}, "source": "space = {\n     \n        'est__strategy':{\"search\":\"choice\",\n                                  \"space\":[\"XGBoost\"]},    \n        'est__n_estimators':{\"search\":\"choice\",\n                                  \"space\":[300]},    \n        'est__colsample_bytree':{\"search\":\"uniform\",\n                                  \"space\":[0.78,0.82]},   \n        'est__colsample_bylevel':{\"search\":\"uniform\",\n                                  \"space\":[0.78,0.82]},    \n        'est__subsample':{\"search\":\"uniform\",\n                                  \"space\":[0.82,0.88]},\n        'est__max_depth':{\"search\":\"choice\",\n                                  \"space\":[10,11]},\n        'est__learning_rate':{\"search\":\"choice\",\n                                  \"space\":[0.075]} \n    \n        }\n\nparams = opt.optimise(space, df, 1)  #only 1 iteration because it takes a long time otherwise :) ", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "56870473fb928d00e08e0db81d87dff6043270fb", "_cell_guid": "261c836e-9722-4b39-b21d-2cc6c98e430e"}, "source": "But you can also tune the whole Pipeline ! Indeed, you can choose:\n\n* different strategies to impute missing values\n* different strategies to encode categorical features (entity embeddings, ...)\n* different strategies and thresholds to select relevant features (random forest feature importance, l1 regularization, ...)\n* to add stacking meta-features !\n* different models and hyper-parameters (XGBoost, Random Forest, Linear, ...)", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "d24e658596c98133669a1a170ccbe310927d4a9f", "_cell_guid": "fb306d0d-b279-4092-a818-4c7bf44674dd"}, "source": "## ... to predict", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "63fd2f04a431b85b57589bdaff6fe314bfe9a8c5", "trusted": false, "_cell_guid": "4f0c47f3-6d1e-4c64-8a5d-5a975d3abf08", "_execution_state": "idle"}, "source": "prd = Predictor()\nprd.fit_predict(params, df)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "c5875c576b531a778492746488f26563869d04bc", "collapsed": true, "_cell_guid": "64c758db-cb99-476e-80f8-9c1b018f5687"}, "source": "### Formatting for submission", "outputs": [], "cell_type": "markdown", "execution_count": null}, {"metadata": {"_uuid": "5566dc1733ab1c8e54894629093c5cdad5ac3247", "collapsed": true, "trusted": false, "_cell_guid": "160e893d-1147-4cf3-af9c-7eb0f9a79e1d", "_execution_state": "idle"}, "source": "submit = pd.read_csv(\"../input/nyc-taxi-trip-duration/sample_submission.csv\",sep=',')\npreds = pd.read_csv(\"save/\"+target_name+\"_predictions.csv\")\n\nsubmit[target_name] =  preds[target_name+\"_predicted\"].apply(lambda x: np.exp(x)-1).values\n\nsubmit.to_csv(\"mlbox.csv\", index=False)", "outputs": [], "cell_type": "code", "execution_count": null}, {"metadata": {"_uuid": "071bcda2523f87193bbb637646825369e55073bb", "_cell_guid": "96af9378-6fa9-488d-91c7-5fe79ac6cb85"}, "source": "# That's all !!\n\nIf you like my new auto-ml package, please **put a star on github and fork/vote the Kaggle script :)**", "outputs": [], "cell_type": "markdown", "execution_count": null}]}