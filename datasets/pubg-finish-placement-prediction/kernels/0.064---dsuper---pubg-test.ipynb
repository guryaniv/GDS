{"cells":[{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"291c8f51a70fb930e21ea5af5713e423212fc1ce"},"cell_type":"code","source":"import gc\nimport time\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d2ddbe7604c19fd40084622634d391b536f477a"},"cell_type":"code","source":"import random \nrandom.seed(42)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77672a8f306227b268e4fbb36a0db1f0b40c1779"},"cell_type":"code","source":"def reload():\n    gc.collect()\n    df = pd.read_csv('../input/train_V2.csv')\n    invalid_match_ids = df[df['winPlacePerc'].isna()]['matchId'].values\n    df = df[-df['matchId'].isin(invalid_match_ids)]\n    #df=pd.concat([df, pd.get_dummies(df['matchType'])],axis=1)\n    return df\n\ndef reload_test():\n    gc.collect()\n    df_test=pd.read_csv('../input/test_V2.csv')\n    return df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edc3315b4b679eb476c07a26b72d5c8e651c0054"},"cell_type":"code","source":"df=reload()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37af4b7dfcded7c6899f75003da505b6df26e456"},"cell_type":"code","source":"def train_test_split(df, test_size=0.1):\n    match_ids = df['matchId'].unique().tolist()\n    train_size = int(len(match_ids) * (1 - test_size))\n    train_match_ids = random.sample(match_ids, train_size)\n\n    train = df[df['matchId'].isin(train_match_ids)]\n    test = df[-df['matchId'].isin(train_match_ids)]\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"950d08faba0f5e4f3f4e60d57fe815892a09c12d"},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ef4ae5056f12d1c46041c6b99441cea4509adcb"},"cell_type":"code","source":"#using simple model to test the feature selection\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn import preprocessing\n\ndef run_experiment(preprocess):\n    df = reload()\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df = preprocess(df)\n\n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    train, val = train_test_split(df, 0.1)\n    '''\n    #standarlize\n    scaler = preprocessing.StandardScaler().fit(train[cols_to_fit])\n    train[cols_to_fit]=scaler.transform(train[cols_to_fit])\n    val[cols_to_fit]=scaler.transform(val[cols_to_fit])\n    ''' \n    \n    model = LinearRegression()\n    model.fit(train[cols_to_fit], train[target])\n    \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\n\ndef run_experiments(preprocesses):\n    results = []\n    for preprocess in preprocesses:\n        start = time.time()\n        score = run_experiment(preprocess)\n        execution_time = time.time() - start\n        results.append({\n            'name': preprocess.__name__,\n            'error': score,\n            'execution time': f'{round(execution_time, 2)}s'\n        })\n        gc.collect()\n        \n    return pd.DataFrame(results, columns=['name', 'error', 'execution time']).sort_values(by='error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bbf3c659da2499c87da9c4c7e4b0255f0e881de"},"cell_type":"code","source":"def original(df):\n    return df\n\ndef best6(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration',save_col,target]\n    return df[cols_to_choose]\n\ndef best7(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration','rideDistance',save_col,target]\n    return df[cols_to_choose]\n\ndef best8(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration','rideDistance','DBNOs',save_col,target]\n    return df[cols_to_choose]\n\ndef best9(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration','rideDistance','DBNOs','boosts',save_col,target]\n    return df[cols_to_choose]\n\ndef best10(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration','rideDistance','DBNOs','boosts','weaponsAcquired',save_col,target]\n    return df[cols_to_choose]\n\ndef best11(df):\n    target = 'winPlacePerc'\n    save_col='matchId'\n    cols_to_choose = ['killPlace', 'walkDistance', 'numGroups', 'maxPlace','kills','matchDuration','rideDistance','DBNOs','boosts','weaponsAcquired','winPoints',save_col,target]\n    return df[cols_to_choose]\n\ndef drop1(df):\n    df.drop(columns=['vehicleDestroys'], inplace=True)\n    return df\n\ndef drop2(df):\n    df.drop(columns=['vehicleDestroys'], inplace=True)\n    df.drop(columns=['roadKills'], inplace=True)\n    return df\n\ndef drop3(df):\n    df.drop(columns=['vehicleDestroys'], inplace=True)\n    df.drop(columns=['roadKills'], inplace=True)\n    df.drop(columns=['headshotKills'], inplace=True)\n    return df\n\ndef drop4(df):\n    df.drop(columns=['vehicleDestroys'], inplace=True)\n    df.drop(columns=['roadKills'], inplace=True)\n    df.drop(columns=['headshotKills'], inplace=True)\n    df.drop(columns=['teamKills'], inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ae13c977a6b33acf1089673f66f1dbbcdff4d43"},"cell_type":"code","source":"#complex model\n#1.random Forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import linear_model\ndef run_Random_Forest(preprocess,df_pre):\n    #get dummy but should drop the 'matchType' still\n    df=df_pre[:]\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df =preprocess(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    #downsample\n    nouse, use = train_test_split(df, 0.1)\n    \n    train, val = train_test_split(use, 0.1)\n    \n    model=RandomForestRegressor(n_estimators=200,max_depth=10)\n    model.fit(train[cols_to_fit], train[target]) \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\ndef run_Random_Forests(preprocesses,df_pre):\n    results = []\n    for preprocess in preprocesses:\n        start = time.time()\n        score = run_Random_Forest(preprocess,df_pre)\n        execution_time = time.time() - start\n        results.append({\n            'name': preprocess.__name__,\n            'score': score,\n            'execution time': f'{round(execution_time, 2)}s'\n        })\n        gc.collect()\n        \n    return pd.DataFrame(results, columns=['name', 'score', 'execution time']).sort_values(by='score')\n\ndef run_Random_Forest_CV(preprocess,n_est,m_depth,df_pre):\n    #get dummy but should drop the 'matchType' still\n    df=df_pre[:]\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df =preprocess(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    #downsample\n    nouse, use = train_test_split(df, 0.1)\n    \n    train, val = train_test_split(use, 0.1)\n    \n    model=RandomForestRegressor(n_estimators=n_est,max_depth=m_depth)\n    model.fit(train[cols_to_fit], train[target]) \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\ndef run_Random_Forests_CV(n_est,m_depth,df_pre):\n    results = []\n    for n in n_est:\n        for m in m_depth:\n            start = time.time()\n            score = run_Random_Forest_CV(drop2,n,m,df_pre) #decide to use drop2\n            execution_time = time.time() - start\n            results.append({\n                'n_estimators': n,\n                'max_depth': m,\n                'error': score,\n                'execution time': f'{round(execution_time, 2)}s'\n            })\n            gc.collect()\n        \n    return pd.DataFrame(results, columns=['n_estimators', 'max_depth', 'error', 'execution time']).sort_values(by='error')\n\ndef run_Linear_lasso_CV(preprocess,alpha_use,df_pre):\n    #get dummy but should drop the 'matchType' still\n    df=df_pre[:]\n    df=pd.concat([df, pd.get_dummies(df['matchType'])],axis=1)\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df =preprocess(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    #downsample\n    nouse, use = train_test_split(df, 0.1)\n    \n    train, val = train_test_split(use, 0.1)\n    \n    model=linear_model.Lasso(alpha=alpha_use)\n    model.fit(train[cols_to_fit], train[target]) \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\ndef run_linear_lassos_CV(alphas,df_pre):\n    results = []\n    for alpha_use in alphas:\n        print(alpha_use)\n        start = time.time()\n        score = run_Linear_lasso_CV(drop2,alpha_use,df_pre) #decide to use drop2\n        execution_time = time.time() - start\n        results.append({\n            'alpha': alpha_use,\n            'error': score,\n            'execution time': f'{round(execution_time, 2)}s'\n        })\n        gc.collect()\n        \n    return pd.DataFrame(results, columns=['alpha', 'error', 'execution time']).sort_values(by='error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"caeda643c9c28429eb656d5227de6c6c55cb7de6"},"cell_type":"code","source":"from sklearn.svm import SVR\ndef run_SVR_CV(preprocess,kernel_use,df_pre):\n    #get dummy but should drop the 'matchType' still\n    df=df_pre[:]\n    #df=pd.concat([df, pd.get_dummies(df['matchType'])],axis=1)\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df =preprocess(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    #downsample\n    nouse, use = train_test_split(df, 0.01)\n    \n    train, val = train_test_split(use, 0.1)\n    \n    model=SVR(kernel=kernel_use,C=1e3,gamma=0.1)\n    model.fit(train[cols_to_fit], train[target]) \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\ndef run_SVRs_CV(kernels,df_pre):\n    results = []\n    for kernel_use in kernels:\n        print(kernel_use)\n        start = time.time()\n        score = run_SVR_CV(drop2,kernel_use,df_pre) #decide to use drop2\n        execution_time = time.time() - start\n        results.append({\n            'kernel': kernel_use,\n            'error': score,\n            'execution time': f'{round(execution_time, 2)}s'\n        })\n        gc.collect()\n        \n    return pd.DataFrame(results, columns=['kernel', 'error', 'execution time']).sort_values(by='error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81c1d89cae5d47259ce9689d1a3c2e5b9f125ea4"},"cell_type":"code","source":"df_pre=reload()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"057fcc1038c7ea0f1d766558d453912aa244993d"},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\ndef run_NN_CV(preprocess,h_l_sizes,iter_use,df_pre):\n    #get dummy but should drop the 'matchType' still\n    df=df_pre[:]\n    #df=pd.concat([df, pd.get_dummies(df['matchType'])],axis=1)\n    df.drop(columns=['matchType'], inplace=True)\n    \n    df =preprocess(df)\n    \n    target = 'winPlacePerc'\n    cols_to_drop = ['Id', 'groupId', 'matchId', target]\n    cols_to_fit = [col for col in df.columns if col not in cols_to_drop]\n    #downsample\n    nouse, use = train_test_split(df, 0.01)\n    \n    train, val = train_test_split(use, 0.1)\n    \n    model=MLPRegressor(hidden_layer_sizes=h_l_sizes, max_iter=iter_use)\n    model.fit(train[cols_to_fit], train[target]) \n    y_true = val[target]\n    y_pred = model.predict(val[cols_to_fit])\n    return mean_absolute_error(y_true, y_pred)\n\ndef run_NNs_CV(h_l_sizes_s,iters,df_pre):\n    results = []\n    for h_l_sizes in h_l_sizes_s:\n        for iter_use in iters: \n            start = time.time()\n            score = run_NN_CV(drop2,h_l_sizes,iter_use,df_pre) #decide to use drop2\n            execution_time = time.time() - start\n            results.append({\n                'hidden_layer_sizes': h_l_sizes,\n                'iter': iter_use,\n                'error': score,\n                'execution time': f'{round(execution_time, 2)}s'\n            })\n            gc.collect()\n        \n    return pd.DataFrame(results, columns=['hidden_layer_sizes', 'iter', 'error', 'execution time']).sort_values(by='error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f994ac42076565adcf7cf57aa1ea928537016345"},"cell_type":"code","source":"df_test_pre=reload_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bbf7406b4df8c7564d5ef2588848b43d5d07510"},"cell_type":"code","source":"#get the submission \ndf=df_pre[:]\ndf_test=df_test_pre[:]\n\n#df=pd.concat([df, pd.get_dummies(df['matchType'])],axis=1)\n#df_test=pd.concat([df_test, pd.get_dummies(df_test['matchType'])],axis=1)\ndf=drop2(df)\ndf_test=drop2(df_test)\n\ndf.drop(columns=['matchType'], inplace=True)\ndf_test.drop(columns=['matchType'], inplace=True)\n    \ntarget = 'winPlacePerc'\ncols_to_drop = ['Id', 'groupId', 'matchId', target]\ncols_to_fit = [col for col in df.columns if col not in cols_to_drop]\ncols_to_drop_test = ['Id', 'groupId', 'matchId']\ncols_to_fit_test = [col for col in df_test.columns if col not in cols_to_drop_test]\n    #downsample\nnouse, use = train_test_split(df, 0.01)    \ntrain, val = train_test_split(use, 0.1)\nstart = time.time()   \nmodel=RandomForestRegressor(n_estimators=300,max_depth=20) #best model\nmodel.fit(train[cols_to_fit], train[target]) \n#validation error(test)\ny_true = val[target]\ny_pred = model.predict(val[cols_to_fit])\nval_error=mean_absolute_error(y_true, y_pred)\ny_pred_test = model.predict(df_test[cols_to_fit_test])\nexecution_time = time.time() - start\nresults=[]\nresults.append({\n    'error': val_error,\n    'execution time': f'{round(execution_time, 2)}s'\n})\nprint(pd.DataFrame(results, columns=['error', 'execution time']).sort_values(by='error'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5592ca085d9080a6fdc098439e52ea33b6a8bf0e"},"cell_type":"code","source":"sample=df_test[['Id']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c12259acb10fab20f846fd39b335006219fedd5"},"cell_type":"code","source":"sample['winPlacePerc']=y_pred_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9e1bf8ae40df9e19770b5c4390c4fbd9e76e154"},"cell_type":"code","source":"sample.to_csv('submission1.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"492cff5c49eff58ee789f1c02784e49ecf745030"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}