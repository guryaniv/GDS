{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm_notebook as tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"The statistics of training set and test set are very similar.\n\nHowever, one thing that caught my eye was the fact that the distribution of the number of unique values (across features) is significantly different between training set and test set.\n\nIt seems that the test set consists of real samples as well as synthetic samples that were generated by sampling the real samples feature distributions (These are probably the \"rows which are not included in scoring\").\n\nIf this is correct, then finding out which sample is synthetic, and which is real should be relatively easy task:\n\nGiven a sample, we can go over its features and check if the feature value is unique.\nIf at least one of the sample's features is unique, then the sample must be a real sample.\nIt turns out that if a given sample has no unique values then it is a synthetic sample.\n(It doesn't have to be like that, but in this dataset the probability is seemingly to low that this would not be the case).\n\n"},{"metadata":{"trusted":true,"_uuid":"1c1fed0fe6b78f8b3c67a1cffe193269c8c270c2"},"cell_type":"code","source":"test_path = '../input/test.csv'\n\ndf_test = pd.read_csv(test_path)\ndf_test.drop(['ID_code'], axis=1, inplace=True)\ndf_test = df_test.values\n\nunique_samples = []\nunique_count = np.zeros_like(df_test)\nfor feature in tqdm(range(df_test.shape[1])):\n    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n    unique_count[index_[count_ == 1], feature] += 1\n\n# Samples which have unique values are real the others are fake\nreal_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\nsynthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n\nprint(len(real_samples_indexes))\nprint(len(synthetic_samples_indexes))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6f430d0d28f47be210c1905e88437e889d998a9"},"cell_type":"markdown","source":"\nIf the split between private and public LB sets was done before the resampling process of generating synthetic samples, then it's also possible to regenerate the two different sets.\nFor each synthetic sample, we can go over its features and capture those features that have only one instance in the real samples set with the same value, this instance has to be one of the samples' generators.\n\n"},{"metadata":{"trusted":true,"_uuid":"f61b7c454830f7f2d6790db98b4f080c4da30bf7"},"cell_type":"code","source":"df_test_real = df_test[real_samples_indexes].copy()\n\ngenerator_for_each_synthetic_sample = []\n# Using 20,000 samples should be enough. \n# You can use all of the 100,000 and get the same results (but 5 times slower)\nfor cur_sample_index in tqdm(synthetic_samples_indexes[:20000]):\n    cur_synthetic_sample = df_test[cur_sample_index]\n    potential_generators = df_test_real == cur_synthetic_sample\n\n    # A verified generator for a synthetic sample is achieved\n    # only if the value of a feature appears only once in the\n    # entire real samples set\n    features_mask = np.sum(potential_generators, axis=0) == 1\n    verified_generators_mask = np.any(potential_generators[:, features_mask], axis=1)\n    verified_generators_for_sample = real_samples_indexes[np.argwhere(verified_generators_mask)[:, 0]]\n    generator_for_each_synthetic_sample.append(set(verified_generators_for_sample))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f25e774667923eda30ad142a71bb3daadc63e1fc"},"cell_type":"markdown","source":"After collecting the \"verified generators\" for each fake sample, finding the Public/Private LB split is no more than a few set operations."},{"metadata":{"trusted":true,"_uuid":"33ac407a0cb5f2cb0a079ca376e76dc715243625"},"cell_type":"code","source":"public_LB = generator_for_each_synthetic_sample[0]\nfor x in tqdm(generator_for_each_synthetic_sample):\n    if public_LB.intersection(x):\n        public_LB = public_LB.union(x)\n\nprivate_LB = generator_for_each_synthetic_sample[1]\nfor x in tqdm(generator_for_each_synthetic_sample):\n    if private_LB.intersection(x):\n        private_LB = private_LB.union(x)\n        \nprint(len(public_LB))\nprint(len(private_LB))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"a3f4863159fc035e572228d0b19c2424a0fccfe8"},"cell_type":"code","source":"np.save('public_LB', list(public_LB))\nnp.save('private_LB', list(private_LB))\nnp.save('synthetic_samples_indexes', list(synthetic_samples_indexes))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}