{"cells":[{"metadata":{"_uuid":"3ef422ea8bdda1ae06d9e3ff788a8d69e3b4211b"},"cell_type":"markdown","source":"**Importing libraries**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport os\nimport gc\n#print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0534053e5e3100a617a4c53381d8fd7ccf628f08"},"cell_type":"markdown","source":"**Application train and test data**"},{"metadata":{"trusted":true,"_uuid":"af20e3896c2f37821fd75c1863eb936e00014ce9"},"cell_type":"code","source":"def get_combined_dataset() :\n    application_train = pd.read_csv('../input/application_train.csv')\n    application_test = pd.read_csv('../input/application_test.csv')\n    application=application_train.append(application_test, ignore_index=True,sort=False)\n    application.set_index('SK_ID_CURR')\n    return (application)\n\ndef get_application_dataset():\n    df = get_combined_dataset()\n    filteredColList =['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_FAMILY_STATUS','NAME_HOUSING_TYPE','OCCUPATION_TYPE',\n                      'WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE','FONDKAPREMONT_MODE'] \n    df = df[[x for x in list(df) if x not in filteredColList]]\n    oheCols = ['NAME_CONTRACT_TYPE','CODE_GENDER','FLAG_OWN_CAR','FLAG_OWN_REALTY','HOUSETYPE_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE']\n    \n    df.loc[df.CODE_GENDER == 'XNA' ,'CODE_GENDER'] = 'F'\n    df.loc[(df.DAYS_EMPLOYED > 0),'DAYS_EMPLOYED'] = np.nan\n    df.loc[(df.REGION_RATING_CLIENT_W_CITY < 0),'REGION_RATING_CLIENT_W_CITY'] = np.nan\n    df.loc[(df.OBS_30_CNT_SOCIAL_CIRCLE > 10),'OBS_30_CNT_SOCIAL_CIRCLE'] = 10\n    df.loc[(df.DEF_30_CNT_SOCIAL_CIRCLE > 10),'DEF_30_CNT_SOCIAL_CIRCLE'] = 10\n    df.loc[(df.OBS_60_CNT_SOCIAL_CIRCLE > 10),'OBS_60_CNT_SOCIAL_CIRCLE'] = 10\n    df.loc[(df.DEF_60_CNT_SOCIAL_CIRCLE > 10),'DEF_60_CNT_SOCIAL_CIRCLE'] = 10\n    df.loc[(df.AMT_REQ_CREDIT_BUREAU_QRT > 10),'AMT_REQ_CREDIT_BUREAU_QRT'] = 10\n    df = pd.get_dummies(df,columns=oheCols)\n    \n    # New features\n    df['NEW_INCOME2Credit']=df['AMT_CREDIT']/df['AMT_INCOME_TOTAL']\n    df['NEW_Credit2ANNUITY']=df['AMT_ANNUITY']/df['AMT_CREDIT']\n    df['NEW_INCOME2ANNUITY']=df['AMT_ANNUITY']/df['AMT_INCOME_TOTAL']\n    df['NEW_DAYS_EMPLOYED2DAYS_BIRTH'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['NEW_AMT_INCOME_TOTAL2CNT_FAM_MEMBERS'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    \n    df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n    df['NEW_CREDIT2GOODS'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n    df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n    df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n    df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n    df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n    df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n    df['NEW_OWN_CAR_AGE2DAYS_BIRTH'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n    df['NEW_OWN_CAR_AGE2DAYS_EMPLOYED'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n    df['NEW_DAYS_LAST_PHONE_CHANGE2DAYS_BIRTH'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n    df['NEW_DAYS_LAST_PHONE_CHANGE2DAYS_EMPLOYED'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n    return(df)\n\ndef transform_application(df):\n    \n    logTransformation = ['AMT_INCOME_TOTAL','AMT_CREDIT','AMT_ANNUITY','AMT_GOODS_PRICE','NEW_AMT_INCOME_TOTAL2CNT_FAM_MEMBERS','NEW_INC_PER_CHLD']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sqrtTransformation = ['DAYS_BIRTH','DAYS_EMPLOYED','DAYS_REGISTRATION','DAYS_ID_PUBLISH','OWN_CAR_AGE','DAYS_LAST_PHONE_CHANGE','NEW_INCOME2Credit']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7f0dd2110991a54b4fb8e51225db69d58d497e5"},"cell_type":"markdown","source":"**Bureau & Bureau_Balance**"},{"metadata":{"trusted":true,"_uuid":"e969dd41f14e75fb4b09a63641a87299b52ac115"},"cell_type":"code","source":"def bureau_balance():\n    df = pd.read_csv('../input/bureau_balance.csv')\n    # getting the furthest date attached to bureau_id\n    df1 = df.groupby(['SK_ID_BUREAU']).agg(\n            {'MONTHS_BALANCE': min,\n            })\n    # Status of bureau_id as per freshest month\n    df2 = df.groupby(['SK_ID_BUREAU']).agg(\n                {'MONTHS_BALANCE': max,\n                }).reset_index()\n    df2 = pd.merge(df2,df,on=['SK_ID_BUREAU','MONTHS_BALANCE'],how='inner')\n    df2 = pd.crosstab(df2['SK_ID_BUREAU'], df2['STATUS'])\n\n    df = pd.merge(df1,df2,on=['SK_ID_BUREAU'],how='left').reset_index()\n    df.columns = ['SK_ID_BUREAU','MONTHS_BALANCE','BB_S_0','BB_S_1','BB_S_2','BB_S_3','BB_S_4','BB_S_5','BB_S_C','BB_S_X']\n    return(df)\n\ndef get_bureau_dataset():\n    b = pd.read_csv('../input/bureau.csv')\n    bb = bureau_balance()\n    df = pd.merge(b,bb,on='SK_ID_BUREAU',how='left')\n    df.loc[(df.DAYS_CREDIT_ENDDATE < 0) | (df.DAYS_CREDIT_ENDDATE > 5000),'DAYS_CREDIT_ENDDATE'] = np.nan\n    df.loc[(df.DAYS_ENDDATE_FACT < -5000),'DAYS_ENDDATE_FACT'] = np.nan\n    df.loc[(df.AMT_CREDIT_MAX_OVERDUE > 40000),'AMT_CREDIT_MAX_OVERDUE'] = 40000\n    df.loc[(df.DAYS_CREDIT_UPDATE < -3000),'DAYS_CREDIT_UPDATE'] = np.nan\n    df.loc[(df.AMT_CREDIT_SUM_DEBT < 0),'AMT_CREDIT_SUM_DEBT'] = np.nan\n    df.loc[(df.AMT_CREDIT_SUM_LIMIT < 0),'AMT_CREDIT_SUM_LIMIT'] = np.nan\n\n    All = df.groupby(['SK_ID_CURR']).agg(\n            {'DAYS_CREDIT': [min, max],\n             'CREDIT_DAY_OVERDUE':max,\n             'DAYS_CREDIT_ENDDATE':max,\n             'DAYS_ENDDATE_FACT':[min,max],\n             'AMT_CREDIT_MAX_OVERDUE':max,\n             'CNT_CREDIT_PROLONG':max,\n             'AMT_CREDIT_SUM':max,\n             'AMT_CREDIT_SUM_DEBT':max,\n             'AMT_CREDIT_SUM_LIMIT':max,\n             'DAYS_CREDIT_UPDATE':min,\n             'AMT_ANNUITY':max,\n             'MONTHS_BALANCE':min,\n             'BB_S_0':sum,\n             'BB_S_1':sum,\n             'BB_S_2':sum,\n             'BB_S_3':sum,\n             'BB_S_4':sum,\n             'BB_S_5':sum,\n             'BB_S_C':sum,\n             'BB_S_X':sum\n            })\n    All.columns = [\"_all_\".join(x) for x in All.columns.ravel()]\n    Active = df.query('CREDIT_ACTIVE == \"Active\"').groupby(['SK_ID_CURR']).agg(\n            {'CREDIT_DAY_OVERDUE':max,\n             'AMT_CREDIT_MAX_OVERDUE': max,\n             'CNT_CREDIT_PROLONG':[max,sum],\n             'AMT_CREDIT_SUM':sum,\n             'AMT_CREDIT_SUM_DEBT':sum,\n             'AMT_CREDIT_SUM_LIMIT':sum,\n             'AMT_CREDIT_SUM_OVERDUE':sum,\n             'DAYS_CREDIT_UPDATE':min,\n             'AMT_ANNUITY':sum,\n             'MONTHS_BALANCE':min,\n             'BB_S_0':sum,\n             'BB_S_1':sum,\n             'BB_S_2':sum,\n             'BB_S_3':sum,\n             'BB_S_4':sum,\n             'BB_S_5':sum,\n             'BB_S_C':sum,\n             'BB_S_X':sum\n            })\n    Active.columns = [\"_act_\".join(x) for x in Active.columns.ravel()]\n    \n    CREDIT_ACTIVE_ctab = pd.crosstab(df['SK_ID_CURR'], df['CREDIT_ACTIVE']).rename_axis(None, axis=1)\n    from functools import reduce\n    dfs = [All,Active,CREDIT_ACTIVE_ctab]\n\n    df_final = reduce(lambda left,right: pd.merge(left,right,on='SK_ID_CURR',how='outer'), dfs)\n    df_final.reset_index(inplace=True)\n    return(df_final)\n\n    CREDIT_ACTIVE_ctab = pd.crosstab(df['SK_ID_CURR'], df['CREDIT_ACTIVE']).rename_axis(None, axis=1)\n    from functools import reduce\n    dfs = [All,Active,CREDIT_ACTIVE_ctab]\n\n    df_final = reduce(lambda left,right: pd.merge(left,right,on='SK_ID_CURR',how='outer'), dfs)\n    df_final.reset_index(inplace=True)\n    return(df_final)\n\ndef bureau_newFeature(df):\n    df['AMT_CREDIT_SUM_sum2AMT_CREDIT_SUM_DEBT_sum'] = df['AMT_CREDIT_SUM_DEBT_act_sum']/df['AMT_CREDIT_SUM_act_sum']\n    df['AMT_CREDIT_SUM_sum2AMT_ANNUITY_sum'] = df['AMT_CREDIT_SUM_act_sum']/df['AMT_ANNUITY_act_sum']\n    df['AMT_CREDIT_SUM_DEBT_sum2AMT_ANNUITY_sum'] = df['AMT_CREDIT_SUM_DEBT_act_sum']/df['AMT_ANNUITY_act_sum']\n    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n    df.loc[df.AMT_CREDIT_SUM_sum2AMT_CREDIT_SUM_DEBT_sum>2,'AMT_CREDIT_SUM_sum2AMT_CREDIT_SUM_DEBT_sum'] = np.nan\n    df.loc[df.AMT_CREDIT_SUM_sum2AMT_ANNUITY_sum>120,'AMT_CREDIT_SUM_sum2AMT_ANNUITY_sum'] = np.nan\n    df.loc[df.AMT_CREDIT_SUM_DEBT_sum2AMT_ANNUITY_sum>80,'AMT_CREDIT_SUM_DEBT_sum2AMT_ANNUITY_sum'] = np.nan\n    return(df)\n    \ndef transform_bureau(df):\n    logTransformation = ['CREDIT_DAY_OVERDUE_all_max','AMT_CREDIT_MAX_OVERDUE_all_max','AMT_CREDIT_SUM_all_max','AMT_CREDIT_SUM_DEBT_all_max',\n                         'AMT_CREDIT_SUM_LIMIT_all_max','AMT_ANNUITY_all_max','AMT_CREDIT_MAX_OVERDUE_act_max','AMT_CREDIT_SUM_act_sum',\n                         'AMT_CREDIT_SUM_DEBT_act_sum','AMT_CREDIT_SUM_LIMIT_act_sum','AMT_CREDIT_SUM_OVERDUE_act_sum','AMT_ANNUITY_act_sum']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sartLogTransformation = ['CREDIT_DAY_OVERDUE_act_max','DAYS_CREDIT_UPDATE_act_min']\n    df[sartLogTransformation] = df[sartLogTransformation].apply(lambda x : np.sqrt(np.log(np.abs(x+1))),axis=1)\n    \n    sqrtTransformation = ['DAYS_CREDIT_all_min','DAYS_CREDIT_all_max','DAYS_CREDIT_ENDDATE_all_max','DAYS_ENDDATE_FACT_all_min','DAYS_ENDDATE_FACT_all_max',\n                         'DAYS_CREDIT_UPDATE_all_min','MONTHS_BALANCE_all_min','MONTHS_BALANCE_act_min']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e78486055f31031ec4cbd6faaf7213195671764"},"cell_type":"markdown","source":"**previous_application**"},{"metadata":{"trusted":true,"_uuid":"c4f91a8d6235a7c722b70193d4a575bb77f7d0ca"},"cell_type":"code","source":"def get_previous_application():\n    df = pd.read_csv('../input/previous_application.csv')\n    df.loc[df.DAYS_FIRST_DRAWING >0,'DAYS_FIRST_DRAWING'] = np.nan\n    df.loc[df.DAYS_FIRST_DUE >0,'DAYS_FIRST_DUE'] = np.nan\n    df.loc[df.DAYS_LAST_DUE_1ST_VERSION >2000,'DAYS_LAST_DUE_1ST_VERSION'] = np.nan\n    df.loc[df.DAYS_LAST_DUE >3000,'DAYS_LAST_DUE'] = np.nan\n    df.loc[df.DAYS_TERMINATION >3000,'DAYS_TERMINATION'] = np.nan\n    \n    # filtering the invalid contracts\n    dff = df.query('FLAG_LAST_APPL_PER_CONTRACT == \"Y\" and NFLAG_LAST_APPL_IN_DAY == 1')\n    # count of loan status\n    NAME_CONTRACT_STATUS_ctab = pd.crosstab(df['SK_ID_CURR'], df['NAME_CONTRACT_STATUS'])\n    \n\n    # new features\n    df['AMT_ANNUITY2AMT_CREDIT'] = df['AMT_ANNUITY']/df['AMT_CREDIT']\n    df['AMT_APPLICATION2AMT_CREDIT'] = df['AMT_APPLICATION']/df['AMT_CREDIT']\n    df['AMT_GOODS_PRICE2AMT_CREDIT'] = df['AMT_GOODS_PRICE']/df['AMT_CREDIT']\n    \n    \n    NAME_CONTRACT_STATUS_ctab = pd.crosstab(df['SK_ID_CURR'], df['NAME_CONTRACT_STATUS'])\n    df_grouped = df.query('NAME_CONTRACT_STATUS != \"Refused\" and FLAG_LAST_APPL_PER_CONTRACT == \"Y\" and NFLAG_LAST_APPL_IN_DAY == 1')\\\n                                                    .groupby(['SK_ID_CURR'])\\\n                                                    .agg(\n                                                        {'AMT_ANNUITY':max,\n                                                         'AMT_APPLICATION':max,\n                                                         'AMT_CREDIT':max,\n                                                         'AMT_DOWN_PAYMENT':max,\n                                                         'AMT_GOODS_PRICE':max,\n                                                         'RATE_DOWN_PAYMENT':[min, max,'mean'],\n                                                         'RATE_INTEREST_PRIMARY':[min, max,'mean'],\n                                                         'RATE_INTEREST_PRIVILEGED':[min, max,'mean'],\n                                                         'DAYS_DECISION':[min, max,'mean'],\n                                                         'CNT_PAYMENT':[min, max,'mean'],\n                                                         'DAYS_FIRST_DRAWING':min,\n                                                         'DAYS_FIRST_DUE':[min, max],\n                                                         'DAYS_LAST_DUE_1ST_VERSION':[min, max],\n                                                         'DAYS_LAST_DUE':[min, max],\n                                                         'DAYS_TERMINATION':[min, max],\n                                                         'NFLAG_INSURED_ON_APPROVAL':sum\n                                                        })\n    df_final = pd.merge(df_grouped,NAME_CONTRACT_STATUS_ctab,on='SK_ID_CURR',how='outer')\n    df_final.reset_index(inplace=True)\n    df_final.columns = ['SK_ID_CURR','AMT_ANNUITY_max','AMT_APPLICATION_max','AMT_CREDIT_max','AMT_DOWN_PAYMENT_max','AMT_GOODS_PRICE_max',\n                        'RATE_DOWN_PAYMENT_min','RATE_DOWN_PAYMENT_max','RATE_INTEREST_PRIMARY_min','RATE_INTEREST_PRIMARY_max',\n                        'RATE_INTEREST_PRIVILEGED_min','RATE_INTEREST_PRIVILEGED_max','DAYS_DECISION_min','DAYS_DECISION_max','CNT_PAYMENT_min',\n                        'CNT_PAYMENT_max','DAYS_FIRST_DRAWING_min','DAYS_FIRST_DUE_min','DAYS_FIRST_DUE_max',\n                        'DAYS_LAST_DUE_1ST_VERSION_min','DAYS_LAST_DUE_1ST_VERSION_max','DAYS_LAST_DUE_min','DAYS_LAST_DUE_max','DAYS_TERMINATION_min',\n                        'DAYS_TERMINATION_max','NFLAG_INSURED_ON_APPROVAL_sum','Approved','Canceled','Refused','Unused_offer']\n    df_final.head()\n    return(df_final)\n\ndef transform_previous_application(df):\n    logTransformation = ['AMT_ANNUITY_max','AMT_APPLICATION_max','AMT_CREDIT_max', 'AMT_DOWN_PAYMENT_max','AMT_GOODS_PRICE_max']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sqrtTransformation = ['DAYS_DECISION_min','DAYS_DECISION_max','DAYS_FIRST_DRAWING_min','DAYS_FIRST_DUE_min','DAYS_FIRST_DUE_max','DAYS_LAST_DUE_min',\n                          'DAYS_LAST_DUE_max','DAYS_TERMINATION_min','DAYS_TERMINATION_max']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8be0f06466dc74c9397a770d41a1e9487aea896e"},"cell_type":"code","source":"def get_previous_application():\n    df = pd.read_csv('../input/previous_application.csv')\n    df.loc[df.DAYS_FIRST_DRAWING >0,'DAYS_FIRST_DRAWING'] = np.nan\n    df.loc[df.DAYS_FIRST_DUE >0,'DAYS_FIRST_DUE'] = np.nan\n    df.loc[df.DAYS_LAST_DUE_1ST_VERSION >2000,'DAYS_LAST_DUE_1ST_VERSION'] = np.nan\n    df.loc[df.DAYS_LAST_DUE >3000,'DAYS_LAST_DUE'] = np.nan\n    df.loc[df.DAYS_TERMINATION >3000,'DAYS_TERMINATION'] = np.nan\n\n    # new features\n    df['AMT_ANNUITY2AMT_CREDIT'] = df['AMT_ANNUITY']/df['AMT_CREDIT']\n    df['AMT_APPLICATION2AMT_CREDIT'] = df['AMT_APPLICATION']/df['AMT_CREDIT']\n    df['AMT_GOODS_PRICE2AMT_CREDIT'] = df['AMT_GOODS_PRICE']/df['AMT_CREDIT']\n    \n    \n    NAME_CONTRACT_STATUS_ctab = pd.crosstab(df['SK_ID_CURR'], df['NAME_CONTRACT_STATUS'])\n    df_grouped = df.query('NAME_CONTRACT_STATUS != \"Refused\" and FLAG_LAST_APPL_PER_CONTRACT == \"Y\" and NFLAG_LAST_APPL_IN_DAY == 1')\\\n                                                    .groupby(['SK_ID_CURR'])\\\n                                                    .agg(\n                                                        {'AMT_ANNUITY':max,\n                                                         'AMT_APPLICATION':max,\n                                                         'AMT_CREDIT':max,\n                                                         'AMT_DOWN_PAYMENT':max,\n                                                         'AMT_GOODS_PRICE':max,\n                                                         'RATE_DOWN_PAYMENT':[min, max,'mean'],\n                                                         'RATE_INTEREST_PRIMARY':[min, max,'mean'],\n                                                         'RATE_INTEREST_PRIVILEGED':[min, max,'mean'],\n                                                         'DAYS_DECISION':[min, max,'mean'],\n                                                         'CNT_PAYMENT':[min, max,'mean'],\n                                                         'DAYS_FIRST_DRAWING':min,\n                                                         'DAYS_FIRST_DUE':[min, max],\n                                                         'DAYS_LAST_DUE_1ST_VERSION':[min, max],\n                                                         'DAYS_LAST_DUE':[min, max],\n                                                         'DAYS_TERMINATION':[min, max],\n                                                         'NFLAG_INSURED_ON_APPROVAL':sum\n                                                        })\n    df_final = pd.merge(df_grouped,NAME_CONTRACT_STATUS_ctab,on='SK_ID_CURR',how='outer')\n    df_final.reset_index(inplace=True)\n    return(df_final)\n\ndef transform_previous_application(df):\n    logTransformation = ['AMT_ANNUITY_max','AMT_APPLICATION_max','AMT_CREDIT_max', 'AMT_DOWN_PAYMENT_max','AMT_GOODS_PRICE_max']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sqrtTransformation = ['DAYS_DECISION_min','DAYS_DECISION_max','DAYS_FIRST_DRAWING_min','DAYS_FIRST_DUE_min','DAYS_FIRST_DUE_max','DAYS_LAST_DUE_min',\n                          'DAYS_LAST_DUE_max','DAYS_TERMINATION_min','DAYS_TERMINATION_max']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0844c6218598d030b83e8ff297d298ac2c07d763"},"cell_type":"markdown","source":"**POS_CASH_balance**"},{"metadata":{"trusted":true,"_uuid":"350608bf65f8db47b162f2059f31b450a4244158"},"cell_type":"code","source":"def get_POS_CASH_balance():\n    POS_CASH_balance = pd.read_csv('../input/POS_CASH_balance.csv')\n    Closed_Loans = POS_CASH_balance[POS_CASH_balance['SK_ID_PREV'].isin(POS_CASH_balance.query('NAME_CONTRACT_STATUS == \"Completed\"').SK_ID_PREV)]\n    Active_Loans = POS_CASH_balance[~POS_CASH_balance['SK_ID_PREV'].isin(POS_CASH_balance.query('NAME_CONTRACT_STATUS == \"Active\" and MONTHS_BALANCE == -1').SK_ID_PREV)]\n\n    Active = Active_Loans.groupby(['SK_ID_CURR']).agg(\n                    {  'MONTHS_BALANCE':min,\n                       'CNT_INSTALMENT':[min,max],\n                       'CNT_INSTALMENT_FUTURE':[min,max]\n                    })\n    Closed = Closed_Loans.groupby(['SK_ID_CURR']).agg(\n                    {  'MONTHS_BALANCE':[min,max],\n                       'CNT_INSTALMENT':max\n                    })\n    NAME_CONTRACT_STATUS = POS_CASH_balance.query('(NAME_CONTRACT_STATUS == \"Completed\") or (NAME_CONTRACT_STATUS == \"Active\" and MONTHS_BALANCE == -1) ')[['SK_ID_PREV','SK_ID_CURR','NAME_CONTRACT_STATUS']].drop_duplicates()\n    NAME_CONTRACT_STATUS_ctab = pd.crosstab(NAME_CONTRACT_STATUS['SK_ID_CURR'], NAME_CONTRACT_STATUS['NAME_CONTRACT_STATUS'])\n\n    from functools import reduce\n    dfs = [NAME_CONTRACT_STATUS_ctab,Active,Closed]\n    df_final = reduce(lambda left,right: pd.merge(left,right,on='SK_ID_CURR',how='outer'), dfs)\n    df_final.reset_index(inplace=True)\n    df_final.columns = ['SK_ID_CURR','Active','Completed','MONTHS_BALANCE_A_min','CNT_INSTALMENT_A_min','CNT_INSTALMENT_A_max','CNT_INSTALMENT_FUTURE_A_min',\n                        'CNT_INSTALMENT_FUTURE_max','MONTHS_BALANCE_C_min','MONTHS_BALANCE_C_max','CNT_INSTALMENT_C_max']\n    return(df_final)\n\ndef transform_POS_CASH_balance(df):\n    sqrtTransformation = ['CNT_INSTALMENT_A_min','CNT_INSTALMENT_A_max','CNT_INSTALMENT_FUTURE_A_min','CNT_INSTALMENT_FUTURE_max','CNT_INSTALMENT_C_max']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"993f23318abef71e5177f8c6917c70ba12ae018f"},"cell_type":"markdown","source":"**installment_payments**"},{"metadata":{"trusted":true,"_uuid":"e55c77b4150c07e2821bf795b902795165192509"},"cell_type":"code","source":"def get_installment_payments():\n    instalment_payments = pd.read_csv('../input/installments_payments.csv')\n    instalment_payments['MONTH']=(instalment_payments['DAYS_INSTALMENT']/30).astype(int)\n    # features for last month active loans\n    Active = instalment_payments.query('MONTH == -1').groupby('SK_ID_CURR').agg({\n        'NUM_INSTALMENT_VERSION':max,\n        'NUM_INSTALMENT_NUMBER':max,\n        'AMT_INSTALMENT':sum,\n        'AMT_PAYMENT':sum\n    })\n    Closed = instalment_payments.groupby('SK_ID_CURR').agg({\n        'NUM_INSTALMENT_VERSION':max,\n        'NUM_INSTALMENT_NUMBER':max,\n        'DAYS_INSTALMENT':min,\n        'AMT_INSTALMENT':[max,min]\n    })\n    from functools import reduce\n    df_final = pd.merge(Active,Closed,on='SK_ID_CURR',how='outer')\n    df_final.reset_index(inplace=True)\n    df_final.columns=['SK_ID_CURR','NUM_INSTALMENT_VERSION_A_max','NUM_INSTALMENT_NUMBER_A_max','AMT_INSTALMENT_A_sum','AMT_PAYMENT_A_sum',\n                      'NUM_INSTALMENT_VERSION_C_max','NUM_INSTALMENT_NUMBER_C_max','DAYS_INSTALMENT_C_min','AMT_INSTALMENT_C_max','AMT_INSTALMENT_c_min']\n    return(df_final)\n\ndef transform_installment_payments(df):\n    logTransformation = ['AMT_INSTALMENT_A_sum','AMT_PAYMENT_A_sum','AMT_INSTALMENT_C_max','AMT_INSTALMENT_c_min']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sqrtTransformation = ['NUM_INSTALMENT_VERSION_A_max','NUM_INSTALMENT_NUMBER_A_max','NUM_INSTALMENT_VERSION_C_max','NUM_INSTALMENT_NUMBER_C_max',\n                          'DAYS_INSTALMENT_C_min']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"817c6238c34fcc2e097692d128f6bf0b16f8a66f"},"cell_type":"markdown","source":"**credit_card_balance**"},{"metadata":{"trusted":true,"_uuid":"47ec5056558e108d639ed9218250c16d5bec05d3"},"cell_type":"code","source":"def get_credit_card_balance():\n    df = pd.read_csv('../input/credit_card_balance.csv')\n    dfa = df.query('NAME_CONTRACT_STATUS == \"Active\"').groupby(['SK_ID_CURR','MONTHS_BALANCE']).agg({\n        'AMT_BALANCE':sum,\n        'AMT_CREDIT_LIMIT_ACTUAL':sum,\n        'AMT_DRAWINGS_ATM_CURRENT':sum,\n        'AMT_DRAWINGS_CURRENT':sum,\n        'AMT_DRAWINGS_OTHER_CURRENT':sum,\n        'AMT_DRAWINGS_POS_CURRENT':sum,\n        'AMT_INST_MIN_REGULARITY':sum,\n        'AMT_PAYMENT_CURRENT':sum,\n        'AMT_PAYMENT_TOTAL_CURRENT':sum,\n        'AMT_RECEIVABLE_PRINCIPAL':sum,\n        'AMT_RECIVABLE':sum,\n        'AMT_TOTAL_RECEIVABLE':sum,\n        'CNT_DRAWINGS_ATM_CURRENT':sum,\n        'CNT_DRAWINGS_CURRENT':sum,\n        'CNT_DRAWINGS_POS_CURRENT':sum,\n        'CNT_DRAWINGS_OTHER_CURRENT':sum,\n        'CNT_INSTALMENT_MATURE_CUM':sum,\n        'SK_DPD':max,\n        'SK_DPD_DEF':max\n    })\n    dfa = dfa.groupby(['SK_ID_CURR']).agg(['mean',max,min,'std'])\n    dfa.columns = [\"_\".join(x) for x in dfa.columns.ravel()]\n    dfp = pd.pivot_table(df.query('NAME_CONTRACT_STATUS == [\"Active\",\"Completed\",\"Demand\"]').groupby(['SK_ID_CURR','SK_ID_PREV']).agg({'MONTHS_BALANCE':max}).merge(df[['SK_ID_CURR','SK_ID_PREV','MONTHS_BALANCE','NAME_CONTRACT_STATUS']],on=['SK_ID_CURR','SK_ID_PREV','MONTHS_BALANCE']),\n                values='SK_ID_PREV',index=['SK_ID_CURR'],columns=['NAME_CONTRACT_STATUS'],aggfunc=np.size).reset_index().rename_axis(None, axis=1)\n    dfp.fillna(0,inplace=True)\n    dfcc = dfa.merge(dfp,on='SK_ID_CURR')\n    dfcc[dfcc < 0] = 0\n    return(dfcc)\n\ndef transform_credit_card_balance(df):\n    logTransformation = ['AMT_BALANCE_mean','AMT_BALANCE_max','AMT_BALANCE_min','AMT_BALANCE_std',\n                         'AMT_CREDIT_LIMIT_ACTUAL_mean','AMT_CREDIT_LIMIT_ACTUAL_max','AMT_CREDIT_LIMIT_ACTUAL_min','AMT_CREDIT_LIMIT_ACTUAL_std',\n                         'AMT_DRAWINGS_ATM_CURRENT_mean','AMT_DRAWINGS_ATM_CURRENT_max','AMT_DRAWINGS_ATM_CURRENT_min','AMT_DRAWINGS_ATM_CURRENT_std',\n                         'AMT_DRAWINGS_CURRENT_mean','AMT_DRAWINGS_CURRENT_max','AMT_DRAWINGS_CURRENT_min','AMT_DRAWINGS_CURRENT_std',\n                         'AMT_DRAWINGS_OTHER_CURRENT_mean','AMT_DRAWINGS_OTHER_CURRENT_max','AMT_DRAWINGS_OTHER_CURRENT_std','AMT_DRAWINGS_POS_CURRENT_mean',\n                         'AMT_DRAWINGS_POS_CURRENT_max','AMT_DRAWINGS_POS_CURRENT_min','AMT_DRAWINGS_POS_CURRENT_std','AMT_INST_MIN_REGULARITY_mean',\n                         'AMT_INST_MIN_REGULARITY_max','AMT_INST_MIN_REGULARITY_min','AMT_INST_MIN_REGULARITY_std','AMT_PAYMENT_CURRENT_mean',\n                         'AMT_PAYMENT_CURRENT_max','AMT_PAYMENT_CURRENT_min','AMT_PAYMENT_CURRENT_std','AMT_PAYMENT_TOTAL_CURRENT_mean','AMT_PAYMENT_TOTAL_CURRENT_max',\n                         'AMT_PAYMENT_TOTAL_CURRENT_min','AMT_PAYMENT_TOTAL_CURRENT_std','AMT_RECEIVABLE_PRINCIPAL_mean','AMT_RECEIVABLE_PRINCIPAL_max','AMT_RECEIVABLE_PRINCIPAL_min',\n                         'AMT_RECEIVABLE_PRINCIPAL_std','AMT_RECIVABLE_mean','AMT_RECIVABLE_max','AMT_RECIVABLE_min','AMT_RECIVABLE_std','AMT_TOTAL_RECEIVABLE_mean',\n                         'AMT_TOTAL_RECEIVABLE_max','AMT_TOTAL_RECEIVABLE_min','AMT_TOTAL_RECEIVABLE_std']\n    df[logTransformation] = df[logTransformation].apply(lambda x : np.log(x+1),axis=1)\n    \n    sqrtTransformation = ['CNT_DRAWINGS_ATM_CURRENT_mean','CNT_DRAWINGS_ATM_CURRENT_max','CNT_DRAWINGS_ATM_CURRENT_min',\n                          'CNT_DRAWINGS_ATM_CURRENT_std','CNT_DRAWINGS_CURRENT_mean','CNT_DRAWINGS_CURRENT_max','CNT_DRAWINGS_CURRENT_min',\n                          'CNT_DRAWINGS_CURRENT_std','CNT_DRAWINGS_POS_CURRENT_mean','CNT_DRAWINGS_POS_CURRENT_max','CNT_DRAWINGS_POS_CURRENT_min',\n                          'CNT_DRAWINGS_POS_CURRENT_std','CNT_INSTALMENT_MATURE_CUM_mean','CNT_INSTALMENT_MATURE_CUM_max','CNT_INSTALMENT_MATURE_CUM_min',\n                          'CNT_INSTALMENT_MATURE_CUM_std','SK_DPD_mean','SK_DPD_std','SK_DPD_DEF_mean','SK_DPD_DEF_max','SK_DPD_DEF_std']\n    df[sqrtTransformation] = df[sqrtTransformation].apply(lambda x: np.sqrt(np.abs(x)),axis=1)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4eba48724eb97823bcd502a3dda21e78fdd88f8"},"cell_type":"code","source":"def getFinalDataSet():\n    application = get_application_dataset()\n    application = transform_application(get_application_dataset())\n    bureau = transform_bureau(get_bureau_dataset())\n    previous_application = get_previous_application()\n    #previous_application = transform_previous_application(get_previous_application())\n    POS_CASH_balance = transform_POS_CASH_balance(get_POS_CASH_balance())\n    installment_payments = transform_installment_payments(get_installment_payments()) \n    credit_card_balance = transform_credit_card_balance(get_credit_card_balance())\n    dfs = [application, bureau, previous_application, POS_CASH_balance, installment_payments, credit_card_balance]\n    from functools import reduce\n    df = reduce(lambda left,right: pd.merge(left,right,on='SK_ID_CURR',how='left'), dfs)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96b5d65e689fe4580c4788908c062f0f3912e289"},"cell_type":"code","source":"def scaleNfillna(df):\n    df.replace([np.inf, -np.inf], np.nan,inplace=True)\n    df.fillna(0,inplace=True)\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler()\n    df = scaler.fit_transform(df)\n    return(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"84ea7c5a0ec59ed9b81551d632eca3b405f557f8"},"cell_type":"markdown","source":"**Modeling**"},{"metadata":{"trusted":true,"_uuid":"9671f49c8c88a1c2f223d237638225168953331f"},"cell_type":"code","source":"from keras.models import Sequential, Model\nfrom keras.layers import Input, Dense, Dropout, BatchNormalization\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ec412d9e599c5e56a64974dc1a9c753108dca92"},"cell_type":"markdown","source":"**LGBM**"},{"metadata":{"trusted":true,"_uuid":"d0b1d6513f2cfee4e357260f34b85dbf84c18391"},"cell_type":"code","source":"def kfold_lightgbm(df, num_folds, stratified = False, debug= False):\n    from lightgbm import LGBMClassifier\n    from sklearn.metrics import roc_auc_score, roc_curve\n    from sklearn.model_selection import KFold, StratifiedKFold\n    # Divide in training/validation and test data\n    train_df = df[df['TARGET'].notnull()]\n    test_df = df[df['TARGET'].isnull()]\n    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n    del df\n    gc.collect()\n    # Cross validation model\n    if stratified:\n        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    else:\n        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1001)\n    # Create arrays and dataframes to store results\n    oof_preds = np.zeros(train_df.shape[0])\n    sub_preds = np.zeros(test_df.shape[0])\n    feature_importance_df = pd.DataFrame()\n    feats = [f for f in train_df.columns if f not in ['SK_ID_CURR','TARGET']]\n    \n    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n        train_x, train_y= train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n\n        # LightGBM parameters found by Bayesian optimization\n        clf = LGBMClassifier(\n            nthread=4,\n            n_estimators=10000,\n            learning_rate=0.02,\n            num_leaves=34,\n            colsample_bytree=0.9497036,\n            subsample=0.8715623,\n            max_depth=8,\n            reg_alpha=0.041545473,\n            reg_lambda=0.0735294,\n            min_split_gain=0.0222415,\n            min_child_weight=39.3259775,\n            silent=-1,\n            verbose=-1,\n           # scale_pos_weight=1,\n        )\n\n        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], \n            eval_metric= 'auc', verbose= 100, early_stopping_rounds= 200)\n\n        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n\n        fold_importance_df = pd.DataFrame()\n        fold_importance_df[\"feature\"] = feats\n        fold_importance_df[\"importance\"] = clf.feature_importances_\n        fold_importance_df[\"fold\"] = n_fold + 1\n        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n        del clf, train_x, train_y, valid_x, valid_y\n        gc.collect()\n    if not debug:\n        test_df['TARGET'] = sub_preds\n    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds))\n    # Write submission file and plot feature importance\n    display_importances(feature_importance_df)\n    #return submission\n    return(test_df[['SK_ID_CURR', 'TARGET']])\n\ndef display_importances(feature_importance_df_):\n    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n    plt.figure(figsize=(8, 10))\n    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.savefig('lgbm_importances01.png')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"385babf03b762591b90f6b4261260f8837113625"},"cell_type":"markdown","source":"**ANN**"},{"metadata":{"trusted":true,"_uuid":"76b1d07afba718244f1b3915fcc675ea486383e8","collapsed":true},"cell_type":"code","source":"def ANN(X_train,y_train,X_test,y_test,L_dim,num_epochs = 2):\n    \n    #model\n    ann = Sequential()\n    ann.add(Dense(L_dim[0], input_dim=X_train.shape[1], activation='relu'))\n    ann.add(BatchNormalization())\n    ann.add(Dropout(0.2))\n    ann.add(Dense(L_dim[1], activation='relu'))\n    ann.add(BatchNormalization())\n    ann.add(Dropout(0.2))\n    ann.add(Dense(L_dim[2], activation='relu'))\n    ann.add(BatchNormalization())\n    ann.add(Dropout(0.2))\n    ann.add(Dense(L_dim[3], activation='relu'))\n    ann.add(BatchNormalization())\n    ann.add(Dropout(0.2))\n    ann.add(Dense(L_dim[4], activation='relu'))\n    ann.add(BatchNormalization())\n    ann.add(Dense(1, activation='sigmoid'))\n\n    ann.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n    ann.summary()\n    \n    #training\n    ann.fit(X_train, \n          y_train, \n          epochs=num_epochs,\n          batch_size=32,\n          validation_data=(X_test,y_test),\n          shuffle=True,\n          verbose=1)\n    #accuracy\n    from sklearn import metrics\n    y_pred = ann.predict(X_test)\n    cm = metrics.confusion_matrix(y_test, y_pred > 0.5)\n    print(cm)\n    #roc\n    fpr, tpr, thresholds = metrics.roc_curve(y_test+1, y_pred, pos_label=2)\n    print(metrics.auc(fpr, tpr))\n    return(ann) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8cc316fc2b6b5a2e2c51a58ca3dd09147f9e5a4"},"cell_type":"markdown","source":"**AE**"},{"metadata":{"trusted":true,"_uuid":"a3b12b4969edf71938b941abf5658c6944b3ea76","collapsed":true},"cell_type":"code","source":"def AE(X):\n    input_data = Input(shape=(X.shape[1],))\n    encoded = Dense(128, activation='relu')(input_data)\n    encoded = BatchNormalization()(encoded)\n    encoded = Dense(32, activation='relu')(encoded)\n    encoded = BatchNormalization()(encoded)\n    encoded = Dense(16, activation='relu')(encoded)\n    encoded = BatchNormalization(name='encoded_layer')(encoded)\n\n    decoded = Dense(32, activation='relu')(encoded)\n    decoded = BatchNormalization()(decoded)\n    decoded = Dense(64, activation='relu')(decoded)\n    decoded = BatchNormalization()(decoded)\n    #decoded = Dense(237, activation='sigmoid')(encoded)\n    decoded = Dense(X.shape[1], activation='linear')(encoded)\n\n    autoencoder = Model(input_data, decoded)\n    autoencoder.compile(optimizer='adadelta', loss='mean_squared_error')\n    \n    autoencoder.fit(X, X,epochs=10, batch_size=32,shuffle=True)\n    return(autoencoder)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e06f28270f0d0c64d721edf9b441e90d4ca4f811"},"cell_type":"markdown","source":"**submission**"},{"metadata":{"trusted":true,"_uuid":"727f4cb51d577888f519d0bf843dc358ff62a9d3"},"cell_type":"code","source":"def submitLGBM(debug=True):\n    df = getFinalDataSet()\n    submission = kfold_lightgbm(df, 4, stratified = True)\n    if not debug:\n        print(\"writing the submission file\")\n        submission.to_csv('submission_1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24b30db73222c46ec89acf74ef0f14ef346bff4b"},"cell_type":"markdown","source":"**Prediction**"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"61aaf6a2738a362d789a49bc5b57a91f628f0543"},"cell_type":"code","source":"def ANN_prediction(df):\n    feats =[x for x in list(df) if x not in ['SK_ID_CURR','TARGET']]\n    df[feats] = scaleNfillna(df[feats])\n    X = df.loc[df['TARGET'].notnull(),feats].values\n    y = df[df['TARGET'].notnull()].TARGET.values\n    # train test splitting\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n\n    # up sampling\n    ros = RandomOverSampler(random_state=0, sampling_strategy=0.4)\n    X_resampled, y_resampled = ros.fit_sample(X_train, y_train)\n    L_dim = (128,64,32,16,8)\n    ann = ANN(X_resampled, y_resampled,X_test,y_test,L_dim,5)\n    annPred = pd.DataFrame()\n    annPred['SK_ID_CURR'] = df['SK_ID_CURR']\n    annPred['annPred'] = ann.predict(df[feats].values)\n    return(annPred)\ndef AE_prediction(df):\n    feats =[x for x in list(df) if x not in ['SK_ID_CURR','TARGET']]\n    df.loc[:,feats] = scaleNfillna(df.loc[:,feats])\n    X = df[feats].values\n    ae = AE(X)\n    intermediate_layer_model = Model(inputs=ae.input, outputs=ae.get_layer('encoded_layer').output)\n    aePred = pd.DataFrame(columns=['SK_ID_CURR']+['ae'+str(x) for x in range(1,17)])\n    aePred['SK_ID_CURR'] = df['SK_ID_CURR']\n    aePred.loc[:,'ae1':'ae16'] = intermediate_layer_model.predict(X)\n    return(aePred)\n\ndef submit():\n    df = getFinalDataSet()\n    annPred = ANN_prediction(df)\n    df = pd.merge(df,annPred,on='SK_ID_CURR',how='left')\n    #aePred = AE_prediction(df)\n    #df = pd.merge(df,aePred,on='SK_ID_CURR',how='left')\n    submission = kfold_lightgbm(df, 4, stratified = True)\n    print(\"writing the submission file\")\n    submission.to_csv('submission_1.csv', index=False)\n    \ndef submitWeighted():\n    df = getFinalDataSet()\n    annPred = ANN_prediction(df)\n    lgbPred = kfold_lightgbm(df, 4, stratified = True)\n    weighted = pd.merge(lgbPred,annPred,on='SK_ID_CURR',how='left')\n    weighted['TARGET_avg'] = (0.8)*weighted['TARGET'] + (0.2)*weighted['annPred']\n    submission = weighted.loc[:,['SK_ID_CURR','TARGET_avg']]\n    submission.rename(columns={'TARGET_avg': 'TARGET'}, inplace=True)\n    submission.to_csv('submission_1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03fb132c8c14218eda857d4c93bc1cad1b477b95","collapsed":true},"cell_type":"code","source":"def ilo():\n    df = getFinalDataSet()\n\n    feats =[x for x in list(df) if x not in ['SK_ID_CURR','TARGET']]\n    df[feats] = scaleNfillna(df[feats])\n    X = df[feats].values\n    ae = AE(X)\n    intermediate_layer_model = Model(inputs=ae.input, outputs=ae.get_layer('encoded_layer').output)\n    X = intermediate_layer_model.predict(X[df[\"TARGET\"].notnull()])\n    y = df[df['TARGET'].notnull()].TARGET.values\n\n    kfold_lightgbm(X,y, 2, False, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f41655672bee5d37d23fb0c02cb2b4737d70da53"},"cell_type":"code","source":"#submit()\n#submitLGBM(debug=False)\n#submitWeighted()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}