{"nbformat_minor": 1, "nbformat": 4, "metadata": {"language_info": {"version": "3.6.1", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "mimetype": "text/x-python"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "cells": [{"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["import re\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib as plt\n", "import seaborn as sns\n", "\n", "from sklearn.base import TransformerMixin\n", "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder, OneHotEncoder\n", "from sklearn.pipeline import make_union, make_pipeline\n", "\n", "sns.set()"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["%matplotlib inline"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train = pd.read_csv(\"../input/train.csv\", na_values=\"NaN\", index_col=0)\n", "df_test = pd.read_csv(\"../input/test.csv\", na_values=\"NaN\", index_col=0)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["survived = df_train['Survived']\n", "df_train.drop(labels=['Survived'], axis=1, inplace=True)\n", "df_train['Survived'] = survived"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.head()"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_test.head()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 1. \u041e\u043f\u0438\u0441\u0430\u0442\u044c   \u0432\u0441\u0435   \u0438\u043c\u0435\u044e\u0449\u0438\u0435\u0441\u044f   \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438   \u0441\u043b\u043e\u0432\u0430\u043c\u0438.   \u041f\u043e   \u043a\u0430\u0436\u0434\u043e\u043c\u0443   \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0443   \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a   \u043e\u0441\u043e\u0431\u0435\u043d\u043d\u043e\u0441\u0442\u0435\u0439.   \u041f\u0440\u0438   \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\u0441\u0442\u0438   \u043f\u043e\u0441\u0442\u0440\u043e\u0438\u0442\u044c   \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0432\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438."]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `PassengerId` \n", "###### Just a meaningless identifier, not much can be done here"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Pclass`  \n", "###### A passenger's socio-economic status  \n", "I wonder, how exactly it was devised; ticket's class alone is a poor indicator, since lower-class (-ish) nannies and valets have obviously stayed with their masters in the first class. Does data take this into account?  \n", "Nevertheless, let's take a look at its distribution."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["p = df_train.groupby(\"Pclass\").size().plot(kind=\"bar\")\n", "p.set_xlabel(\"Class\")\n", "p.set_ylabel(\"Count\")\n", "p"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Looks like there were more lower-class passengers than passengers of the other two classes combined.  \n", "Also upper-class passengers could have better odds of survival. Let's check"]}, {"metadata": {"scrolled": false}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"Pclass\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Upper-class' odds of survival were > 50%, middle-class had roughly a 50/50 chance and lower-class' chances were only ~20%."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Pclass.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Name`  \n", "###### A passenger's name  \n", "Sometimes contains a title or other indicator of passenger's social status/age (\"Rev.\" for \"reverend\", \"Dr.\" for \"doctor\", \"master\" for \"young upper-class boy\", etc.), could be used in the analysis after some processing. It's likely that this information already reflected by `Pclass`, though."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Name.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Sex`  \n", "###### A passenger's gender  \n", "Due to a common maritime practice and a misunderstanding between the captain and his officers ([\"women and children first\" vs \"women and children only\"](https://en.wikipedia.org/wiki/Women_and_children_first#20th_century)), women's chances of survival were dramatically higher, this feature has a great value."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"Sex\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Sex.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Age`  \n", "###### A passenger's age  \n", "As well as `Sex`, it has a tremendous importance (for the same reasons)."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"Age\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True, figsize=(20, 10))"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Age.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Unfortunately, some of the passengers has no `Age` filled, we'll try to recover it from other features."]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `SibSp`  \n", "###### A number of passenger's siblings and spouses on board  \n", "Could be a limiting factor to the survival, since people tend to make riskier choices if significant ones are in danger. On the other hand, survived woman whose husband has died _still_ counts as a passenger with `SibSp == 1`; a controversial feature."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"SibSp\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.SibSp.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Parch`  \n", "###### A number of passenger's parents and children on board  \n", "As well as `SibSp` can mean anything."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"Parch\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Looks pretty consistent with `SibSp`: 1 or 2 increases chances of survival, but 3+ lowers them significantly."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Parch.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Ticket`\n", "###### Passenger's ticket identifier\n", "Numbers look almost arbitrary, but many ticket numbers contain prefixes, this fact can hold some information."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Ticket.apply(lambda x: len(x.split())) > 1])"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Ticket.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Fare`  \n", "###### A ticket's price  \n", "Most likely contains the same information as `Pclass`."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.Fare.corr(-df_train.Pclass)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Fare.isnull()])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Correlation is there, but it's moderate, so this feature can give some additional information. Also there are passengers with `Fare == 0.0`, it may (or may not) mean something."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Fare == 0.0])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Cabin`  \n", "###### Passenger's cabin number\n", "Too few passengers have this information filled, but, due to the nature of this data (https://www.encyclopedia-titanica.org/cabins.html), the mere fact of having cabin number for a passenger with `Pclass != 1` may indicate their survival."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["len(df_train[df_train.Cabin.isnull()])"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["sum(pd.isnull(df_train.Cabin)) / len(df_train)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["##### `Embarked`  \n", "###### A passenger's port of departure  \n", "It's very unlikely that this feature has anything to do with the odds of survival."]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["df_train.pivot_table(\"Name\", \"Embarked\", \"Survived\", \"count\").plot(kind=\"bar\", stacked=True)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["`S` is clearly an outlier here. It can be explained by otherimportant features, such as `Sex` or `Pclass` of passengers from there. Let's take a look"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["_, axes = plt.pyplot.subplots(ncols=2, figsize=(10, 5))\n", "df_train.pivot_table(\"Name\", \"Embarked\", \"Sex\", \"count\").plot(kind=\"bar\", stacked=True, ax=axes[0])\n", "df_train.pivot_table(\"Name\", \"Embarked\", \"Pclass\", \"count\").plot(kind=\"bar\", stacked=True, ax=axes[1])"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Obviously, the fact that many lower-class men embarked at Southampton skews the distribution of survivors between ports."]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 2. \u0421\u0433\u0435\u043d\u0435\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c   \u0438\u0434\u0435\u0438   \u043f\u043e   \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044e   \u044d\u0442\u0438\u0445   \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432"]}, {"metadata": {}, "cell_type": "markdown", "source": ["`PassengerId` \u2014 it's already perfect in its uselessness."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Pclass` \u2014 it's categorical, makes sense to convert it to OH representation."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Name` \u2014 extract a new feature `Title` and use it to determine `Age` for the passengers with no age and with the same title."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Sex` \u2014 convert to OH."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Age` \u2014 impute missing values."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`SibSp` and `Parch` \u2014 combine (sum) into a one feature."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Ticket` \u2014 extract prefix into a separate feature, convert to OH."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Fare` \u2014 replace 0.0 with median for a passenger's `Pclass`."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Cabin` \u2014 convert to a new binary feature `HasCabin`."]}, {"metadata": {}, "cell_type": "markdown", "source": ["`Embarked` \u2014 drop it."]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 3. \u0421\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c   \u043f\u043b\u0430\u043d   \u043f\u043e   \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u044e   \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432   -   \u0447\u0442\u043e,   \u043a\u0430\u043a   \u0438   \u0432   \u043a\u0430\u043a\u043e\u043c   \u043f\u043e\u0440\u044f\u0434\u043a\u0435 \u043a\u043e\u0434\u0438\u0440\u043e\u0432\u0430\u0442\u044c"]}, {"metadata": {}, "cell_type": "markdown", "source": ["1. Pclass to OHE\n", "2. Encode Sex\n", "3. Extract Title from Name; compute average Age for Title; impute missing Age by Title; scale Age\n", "4. Sum SibSp and Parch into a new feature; scale it\n", "5. Convert Ticket into a feature that shows that the ticket has a prefix or marked as \"LINE\"\n", "6. Compute mean Fare for Pclass; impute 0.0 Fare\n", "7. Convert Cabin to a binary feature"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["class FeatureExtractor(TransformerMixin):\n", "\n", "    def __init__(self, new_feature_name, extractor_function):\n", "        self.new_feature_name = new_feature_name\n", "        self.extractor_function = extractor_function\n", "    \n", "    def fit(self, X, y=None):\n", "        return self\n", "\n", "    def transform(self, X, y=None):\n", "        X[self.new_feature_name] = self.extractor_function(X)\n", "        return X"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["class MeanByCategoryImputer(TransformerMixin):\n", "\n", "    def __init__(self, group_key, mean_key, nan_value=None):\n", "        self.group_key = group_key\n", "        self.mean_key = mean_key\n", "        self.nan_value = nan_value\n", "    \n", "    def fit(self, X, y=None):\n", "        self.means_by_cat = X.groupby(self.group_key).mean()[self.mean_key].to_dict()\n", "        return self\n", "\n", "    def transform(self, X, y=None):\n", "        if self.nan_value:\n", "            X[X[self.mean_key] == self.nan_value] = np.nan\n", "        X[self.mean_key] = X[self.mean_key].fillna(X[self.group_key].map(self.means_by_cat))\n", "        if sum(X[self.mean_key].isnull()) > 0: # we have a 1-member group\n", "            X[self.mean_key] = X[self.mean_key].fillna(X[self.mean_key].mean())\n", "        return X[[self.mean_key]]"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["class LabelEncoderPipelineFriendly(LabelEncoder):\n", "    \n", "    def fit(self, X, y=None):\n", "        \"\"\"this would allow us to fit the model based on the X input.\"\"\"\n", "        super(LabelEncoderPipelineFriendly, self).fit(X)\n", "        \n", "    def transform(self, X, y=None):\n", "        return super(LabelEncoderPipelineFriendly, self).transform(X).reshape(-1, 1)\n", "\n", "    def fit_transform(self, X, y=None):\n", "        return super(LabelEncoderPipelineFriendly, self).fit(X).transform(X).reshape(-1, 1)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["class FeaturesSum(TransformerMixin):\n", "    \n", "    def fit(self, X, y=None):\n", "        return self\n", "        \n", "    def transform(self, X, y=None):\n", "        return np.sum(X.astype(np.float64), axis=1).values.reshape(-1, 1)\n", "\n", "    def fit_transform(self, X, y=None):\n", "        return self.transform(X)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["def prepare_pipeline():\n", "    def get_age_col(X):\n", "        return X.copy()[[\"Age\", \"Name\"]] #  mutation ahead\n", "    \n", "    def get_title(X):\n", "        return X[[\"Name\"]].apply(lambda x: re.match(\".*\\, ((the )?\\S*)\\. .*\", x.Name).groups()[0], axis=1)\n", "    \n", "    def get_pclass_col(X):\n", "        return X[[\"Pclass\"]]\n", "    \n", "    def get_sex_col(X):\n", "        return X[\"Sex\"] #  LabelEncoder expects 1d array\n", "    \n", "    def get_sum_col(X):\n", "        return X[[\"SibSp\", \"Parch\"]]\n", "    \n", "    def get_ticket_prefix(X):\n", "        def extract_prefix(x):\n", "            match = re.match(\"(.*) .*\", x.Ticket.replace(\".\", \"\"))\n", "            if match or x.Ticket == \"LINE\":\n", "                return 1\n", "            return 0\n", "        return X[[\"Ticket\"]].apply(extract_prefix, axis=1).values.reshape(-1, 1)\n", "    \n", "    def get_cabin(X):\n", "        return X[\"Cabin\"].isnull().astype(int) #  LabelEncoder expects 1d array\n", "    \n", "    pipeline = make_union(*[\n", "        make_pipeline(FunctionTransformer(get_pclass_col, validate=False), OneHotEncoder(sparse=False)),\n", "        make_pipeline(FunctionTransformer(get_sex_col, validate=False), LabelEncoderPipelineFriendly()),\n", "        make_pipeline(FunctionTransformer(get_age_col, validate=False),\n", "                      FeatureExtractor(\"Title\", get_title), \n", "                      MeanByCategoryImputer(\"Title\", \"Age\"),\n", "                      StandardScaler()),\n", "        make_pipeline(FunctionTransformer(get_sum_col, validate=False), FeaturesSum(), StandardScaler()),\n", "        make_pipeline(FunctionTransformer(get_ticket_prefix, validate=False), OneHotEncoder(sparse=False)),\n", "        make_pipeline(MeanByCategoryImputer(\"Pclass\", \"Fare\", 0.0), StandardScaler()),\n", "        make_pipeline(FunctionTransformer(get_cabin, validate=False), LabelEncoderPipelineFriendly())\n", "        \n", "    ])\n", "    return pipeline"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 4. \u0421\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c   \u0441\u043f\u0438\u0441\u043e\u043a   \u043c\u043e\u0434\u0435\u043b\u0435\u0439   \u0434\u043b\u044f   \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u0430.   \u041d\u0430\u0447\u0430\u0442\u044c   \u0441   \u043f\u0440\u043e\u0441\u0442\u044b\u0445   (\u043a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u043d\u043e\u0435 \u043f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u043e\u0432\u0430\u043d\u0438\u0435,   knn).   \u041f\u0435\u0440\u0435\u0439\u0442\u0438   \u043a   \u0431\u043e\u043b\u0435\u0435   \u0441\u043b\u043e\u0436\u043d\u044b\u043c   -   \u043b\u043e\u0433\u0438\u0441\u0442\u0438\u0447\u0435\u0441\u043a\u0430\u044f   \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f. \u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435   \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442\u044c   \u0432   \u0432\u0438\u0434\u0435   \u201c\u043c\u043e\u0434\u0435\u043b\u044c,   \u043a\u0430\u043a\u0438\u0435   \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b   \u043d\u0443\u0436\u043d\u043e   \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u0442\u044c\u201c.  \n", "### \u041e\u043f\u0446\u0438\u043e\u043d\u0430\u043b\u044c\u043d\u043e.    \u041f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c   \u043d\u0430\u0438\u0432\u043d\u044b\u0439   \u0431\u0430\u0439\u0435\u0441,   SVM,   \u0434\u0435\u0440\u0435\u0432\u043e   \u0440\u0435\u0448\u0435\u043d\u0438\u0439   \u0438 \u0441\u043b\u0443\u0447\u0430\u0439\u043d\u044b\u0439   \u043b\u0435\u0441."]}, {"metadata": {}, "cell_type": "markdown", "source": ["To make learning speed tolerable (Tree and RandomForest are quite slow) we'll build a search grid for following classifiers:\n", " - K-Nearest Neighbours: adjust a number of neighbors to consider\n", " - Logistic Regression: adjust penalty (\"l1\", \"l2\"), penalty constant and max number of iterations\n", " - Support Vector Classification : adjust penalty constant, radius of the area of influence of a single support vector and kernel"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["from sklearn.model_selection import GridSearchCV\n", "from sklearn.model_selection import cross_val_score\n", "\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC\n", "\n", "models = [\n", "    (KNeighborsClassifier, {\"n_neighbors\": list(range(1, 21))}),\n", "    (LogisticRegression, {\"penalty\": [\"l1\", \"l2\"], \n", "                          \"C\": [0.01, 0.05, 0.1, 0.5, 1.0, 5.0] + list(range(10, 101, 10)),\n", "                          \"max_iter\": list(range(100, 501, 100)),\n", "                          \"random_state\": [0]}),\n", "    (SVC, {\"C\": [1, 10, 100, 1000], \n", "           \"gamma\": [0.1, 0.01, 0.001, 0.0001], \n", "           \"kernel\": [\"rbf\", \"linear\"],\n", "           \"random_state\": [0]})\n", "]"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### 5. \u041e\u043f\u0438\u0441\u0430\u0442\u044c   \u043f\u0440\u043e\u0446\u0435\u0441\u0441   \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438   \u0438   \u043f\u043e\u0434\u0431\u043e\u0440\u0430   \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432   \u043a\u0430\u0436\u0434\u043e\u0439   \u043c\u043e\u0434\u0435\u043b\u0438   \u0438\u0437 \u043f\u043b\u0430\u043d\u0430   (\u0441\u0434\u0435\u043b\u0430\u0442\u044c   \u0430\u043a\u0446\u0435\u043d\u0442   \u043d\u0430   \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438,   \u043d\u0435\u043b\u044c\u0437\u044f   \u043f\u043e\u0434\u0431\u0438\u0440\u0430\u0442\u044c   \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043e\u0440\u0438\u0435\u043d\u0442\u0438\u0440\u0443\u044f\u0441\u044c   \u043d\u0430   \u043b\u0438\u0434\u0435\u0440\u0431\u043e\u0440\u0434)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["x = prepare_pipeline().fit_transform(df_train)\n", "y = df_train.Survived"]}, {"metadata": {}, "cell_type": "markdown", "source": ["GridSearchCV explores all combinations of parameters and cross-valides every model with fold factor = 10."]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["best_models = []\n", "\n", "for model_class, params in models:\n", "    np.random.seed = 0\n", "    gs = GridSearchCV(model_class(), params, scoring=\"accuracy\", cv=10, n_jobs=8)\n", "    gs.fit(x, y)\n", "    best_models.append((model_class, gs.best_estimator_, gs.best_params_, gs.best_score_))"]}, {"metadata": {}, "cell_type": "markdown", "source": ["cross_val_score performs 20-fold cross-validation on the best models for each classifier type and selects a model with maximum mean score."]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["scores = []\n", "for m in best_models:\n", "    model_class, _, params, _ = m\n", "    estimator = model_class(**params)\n", "    local_scores = cross_val_score(estimator, x, y, cv=20, scoring=\"accuracy\")\n", "    scores.append((estimator, local_scores.mean(), local_scores.std()))"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["best_model = max(scores, key=lambda x: x[1])[0]"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["best_model.fit(x, y)"]}, {"metadata": {"collapsed": true, "scrolled": false}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["test = prepare_pipeline().fit_transform(df_test)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["prediction = best_model.predict(test)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["result = pd.DataFrame({\"PassengerId\": df_test.index, \"Survived\": prediction})"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["result.to_csv(\"submission.csv\", sep=\",\", index=False)"]}]}