{"cells": [{"execution_count": null, "outputs": [], "metadata": {"_uuid": "0a607fbe5e16b05d37524b4f49fe41ec3a331b3c", "_cell_guid": "54da3700-040d-4bd9-b7b3-9c57c31da5cc"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "7071bf40190e6fd013707d84bf2c356c7d483060", "_cell_guid": "9866d996-87b1-4864-ae2a-812acd62c8da"}, "source": ["dtypes = {'store_nbr': np.dtype('int64'),\n", "          'item_nbr': np.dtype('int64'),\n", "          'unit_sales': np.dtype('float64'),\n", "          'onpromotion': np.dtype('O')}\n", "\n", "train = pd.read_csv('../input/train.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\n", "test = pd.read_csv('../input/test.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\n", "submission = pd.read_csv('../input/sample_submission.csv', index_col='id')"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "ab834557471fe2d9c209a4ccbb8a2d5d92c19ea7", "_cell_guid": "208b2ba3-1d10-49b3-bd9c-e17f16183555"}, "source": ["train.head()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "4c4da1bd2e4bd0152008acbc83da7f4141c71204", "_cell_guid": "f7c32abf-a168-40ce-a434-c44f589d90fa"}, "source": ["test.head()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "b8e3e15b82f672f910fd97fb74efcc12fe88f10e", "_cell_guid": "d0afbadf-d1ba-4950-9ba8-66658ea003e2"}, "source": ["submission.head()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_uuid": "049c14af9e8c64a7a72243eb0190a996d673e52d", "_cell_guid": "cf20825a-927d-4fe4-b471-9b4df4d09d8c"}, "source": ["# We only need the corresponding dates found in Test\n", "date_mask = (train['date'] >= '2016-08-16') & (train['date'] <= '2016-08-31')\n", "\n", "last_year_sales = train.loc[date_mask].copy()\n", "last_year_sales.drop('onpromotion', axis=1, inplace=True)\n", "\n", "# Make a look-up dictionary with keys: date, store_nbr, item_nbr\n", "last_year_sales = last_year_sales.set_index(['date', 'store_nbr', 'item_nbr'])\n", "last_year_sales = last_year_sales.to_dict()['unit_sales']\n", "\n", "benchmark = submission.copy()\n", "\n", "# Use the look-up dictionary, using the .get method so we can default in a value of 0\n", "benchmark['unit_sales'] = \\\n", "    test.apply(lambda x: last_year_sales.get((x['date'] - pd.Timedelta(365, unit='d'), \n", "                                              x['store_nbr'],\n", "                                              x['item_nbr']), 0), axis=1)\n", "\n", "# Unless you enjoy seeing red errors after your submission uploads\n", "benchmark[benchmark['unit_sales'] < 0] = 0\n", "    \n", "# Repeat after me . . . \"I will always compress my submission file for this contest\"\n", "benchmark.to_csv('last_year_sales.csv.gz', float_format='%.4g', compression='gzip')"], "cell_type": "code"}], "nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4}