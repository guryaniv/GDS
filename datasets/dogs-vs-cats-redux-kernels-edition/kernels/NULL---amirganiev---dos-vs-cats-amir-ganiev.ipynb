{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"21a62f277febc0c42b20ae87d5ac4657b09f8f2f"},"cell_type":"markdown","source":"<font size=6>***This is my code to train a deep learning model to differentiate pictures of Cats and Dogs***.\nWe have 25000 pictures of dogs and cats for this task."},{"metadata":{"_uuid":"ea353b5333dfc1ecf8f62a7a1ec6ab04200a061a"},"cell_type":"markdown","source":"**In the first part, I will build a model drom scratch and see what accuracy I get. Then I will apply transfer learning to use a pre-trained model to achieve a higher accuracy**"},{"metadata":{"_uuid":"c22e458a04b5a366afe1dc84803d1ab131bb5298"},"cell_type":"markdown","source":"<font size=6>***SECTION 1: MY OWN MODEL FROM SCRATCH***"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import needed libraries\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as mpimg\n%matplotlib inline\nfrom shutil import copyfile\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#PREPARE DATA (Pictures)\n#need to create right directories for the ImageGeneratorFunction to differentiate two categories (cat folder and dog folder)\n#also need to prepare validation images\n\n!rm -r train\n!rm -r validation\nsource_train_direct='../input/dogs-vs-cats-redux-kernels-edition/train'\nsource_test_direct='../input/dogs-vs-cats-redux-kernels-edition/test'\n\n#create my own directories that will contain two classes (cats and dogs)\n#there will be also folder with validation pictures\nos.mkdir('train')\nos.mkdir('train/cat')\nos.mkdir('train/dog')\nos.mkdir('validation')\nos.mkdir('validation/cat')\nos.mkdir('validation/dog')\n#define paths to this folders\ntrain_cat_path='train/cat'\ntrain_dog_path='train/dog'\ntest_cat_path='validation/cat'\ntest_dog_path='validation/dog'\n#loop over images and copy them into the right directory\n#so images are seperated into two validation and train folders\n#and so they are seperated into cat and dog foders\nfor i in range (12500):\n    cat='cat.'+str(i)+'.jpg'\n    dog='dog.'+str(i)+'.jpg'\n    #get source paths\n    cat_temp_source=os.path.join(source_train_direct,cat)\n    dog_temp_source=os.path.join(source_train_direct,dog)\n    if i<12250:\n        cat_temp_path=os.path.join(train_cat_path,cat)\n        dog_temp_path=os.path.join(train_dog_path,dog)\n    else:\n        cat_temp_path=os.path.join(test_cat_path,cat)\n        dog_temp_path=os.path.join(test_dog_path,dog)\n    #copy file\n    copyfile(cat_temp_source,cat_temp_path)\n    copyfile(dog_temp_source,dog_temp_path)\n    print('Copied',(i+1)*2,'out of 25,000 files', end='\\r')\n    \n#now all the folders are sort out, so ImageGeneratorFunction will know that there are two categories\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"048add988a16d7ad0fa7adb32928203be8c1204b"},"cell_type":"code","source":"#take a look at some images\nimg=mpimg.imread('train/cat/cat.1.jpg')\nimgplot=plt.imshow(img)\nplt.show()\n\nimg=mpimg.imread('train/dog/dog.10.jpg')\nimgplot=plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e345e3471ef998e07f1ea80e4b4c0391d8d799d6"},"cell_type":"code","source":"#Use ImageDataGenerator to set up image pipeline\n#prepares images to be put in the model\n#also allows us to use data_augmentation for more accuracy\n\nimage_size=150\n\ndata_generator_with_aug=ImageDataGenerator(horizontal_flip=True,\n                                           rescale=1./255,\n                                           rotation_range=40,\n                                           width_shift_range = 0.2,\n                                           height_shift_range = 0.2,\n                                           shear_range=0.2,\n                                           zoom_range=0.2,\n                                           fill_mode='nearest' #fill missing values with the nearest value\n                                          )\n\ndata_generator_no_aug=ImageDataGenerator(rescale=1./255)\n\ntrain_generator=data_generator_with_aug.flow_from_directory(\n        directory='train',\n        target_size=(image_size, image_size),\n        batch_size=100,\n        class_mode='categorical')\n\ntrain_generator_no_aug=data_generator_no_aug.flow_from_directory(\n        directory='train',\n        target_size=(image_size, image_size),\n        batch_size=100,\n        class_mode='categorical')\n\nvalidation_generator=data_generator_no_aug.flow_from_directory(\n        directory='validation',\n        target_size=(image_size, image_size),\n        batch_size=100,\n        class_mode='categorical')\n\ntrain_generator.class_indices","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4464316d79d01715f18a220d359f64f8ed67822"},"cell_type":"code","source":"#CONSTRUCT A MODEL\n#now image data is prepared, lets see which one will work\nimage_size=150\nnum_classes=2\nmodel=Sequential()\nmodel.add(Conv2D(24, kernel_size=(3,3), strides=2,\n                activation='relu',\n                input_shape=(image_size, image_size,3)))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(24, kernel_size=(3, 3), strides=2,\n                activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Conv2D(24, kernel_size=(3,3), strides=2,\n                activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n#compile the model\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n             optimizer='adam',\n             metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35816092d6044b64fe7698ffb0c83e620b9ec75a"},"cell_type":"code","source":"#TRAIN THE MODEL\n#train with augmentation\nhistory=model.fit_generator(train_generator,\n                    steps_per_epoch=24500//100,#batch_size=100\n                    epochs=4,\n                    validation_data=validation_generator,\n                    validation_steps=500//100)\n\nplt.plot(history.history['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"307207840bc637aaafc922201c8c2724113b64a9","collapsed":true},"cell_type":"code","source":"#now we see examples of images and what our model predicted for that image\nfrom keras.preprocessing import image\nfrom IPython.display import Image, display\nimg_path='validation/dog/dog.12300.jpg'\ndisplay(Image(img_path))\n#resize the image so model can read it\nimg=image.load_img(img_path, target_size=(150,150))\narray=image.img_to_array(img)\narray=np.expand_dims(array, axis=0)\narray=array/255\nprediction=model.predict_proba(array)\nprint('Cat and after Dog probability:'+ str(prediction))\nprediction=model.predict_classes(array)\nif prediction==[1]: \n    prediction=['Dog']\nelse:\n    prediction=['Cat']\nprint('What model prediction to be in the picture:'+ str(prediction))\n#now we can pull up any picture to see if the model predicted it right by just changing the directory","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c09bbb7df5f9b60cb51523f366400ce22f29865a"},"cell_type":"markdown","source":"<font size=6>**NOW I WILL USE TRASFER LEARNING AND SEE WHAT ACCURACY I GET**\nRemember that our image data is already prepared. All we need is to chose a pre-trained model, work with it.</font>"},{"metadata":{"_uuid":"a48df88f824ed386cb7e669a09727653f2a69b5d"},"cell_type":"markdown","source":"<font size=6>**CHAPTER 2: USING A PRE-TRAINED MODEL** DATA PREP WILL BE THE SAME AS WE DID BEFORE. WE WILL JUST NEED LESS PICTURES TO TRAIN THE MODEL.</font>\n\nThere is a code below for transfer learning. However, we are not going to execute it but a viewer can copy the code and run it."},{"metadata":{"trusted":true,"_uuid":"aaed9e611cd68942d5e27cc3489f82c52133ae2b","collapsed":true},"cell_type":"markdown","source":"#data prep, IT IS THE SAME BUT WE JUST NEED LESS PICTURES FOR PRE-TRAINED MODEL TO WORK\n#all the same as above but with less pictures needed as model was already trained\n#clean up from previous work\n!rm -r train\n!rm -r validation\nsource_train_direct='../input/dogs-vs-cats-redux-kernels-edition/train'\nsource_test_direct='../input/dogs-vs-cats-redux-kernels-edition/test'\nos.mkdir('train')\nos.mkdir('train/cat')\nos.mkdir('train/dog')\nos.mkdir('validation')\nos.mkdir('validation/cat')\nos.mkdir('validation/dog')\ntrain_cat_path='train/cat'\ntrain_dog_path='train/dog'\ntest_cat_path='validation/cat'\ntest_dog_path='validation/dog'\n\nfor i in range (175): #less pictures needed\n    cat='cat.'+str(i)+'.jpg'\n    dog='dog.'+str(i)+'.jpg'\n    cat_temp_source=os.path.join(source_train_direct,cat)\n    dog_temp_source=os.path.join(source_train_direct,dog)\n    if i<150:\n        cat_temp_path=os.path.join(train_cat_path,cat)\n        dog_temp_path=os.path.join(train_dog_path,dog)\n    else:\n        cat_temp_path=os.path.join(test_cat_path,cat)\n        dog_temp_path=os.path.join(test_dog_path,dog)\n    copyfile(cat_temp_source,cat_temp_path)\n    copyfile(dog_temp_source,dog_temp_path)\n    print('Copied',(i+1)*2,'out of 25,000 files', end='\\r')\n\n#take a look at some images\nimg=mpimg.imread('train/cat/cat.1.jpg')\nimgplot=plt.imshow(img)\nplt.show()\n\nimg=mpimg.imread('train/dog/dog.10.jpg')\nimgplot=plt.imshow(img)\nplt.show()\nimage_size=150\n\ndata_generator_with_aug=ImageDataGenerator(horizontal_flip=True,\n                                           rescale=1./255,\n                                           rotation_range=40,\n                                           width_shift_range = 0.2,\n                                           height_shift_range = 0.2,\n                                           shear_range=0.2,\n                                           zoom_range=0.2,\n                                           fill_mode='nearest'\n                                          )\ndata_generator_no_aug=ImageDataGenerator(rescale=1./255)\ntrain_generator=data_generator_with_aug.flow_from_directory(\n        directory='train',\n        target_size=(image_size, image_size),\n        batch_size=50,\n        class_mode='categorical')\n\nvalidation_generator=data_generator_no_aug.flow_from_directory(\n        directory='validation',\n        target_size=(image_size, image_size),\n        batch_size=50,\n        class_mode='categorical')\ntrain_generator.class_indices"},{"metadata":{"_uuid":"d26032c7bc9b091333d03f5ed460cd824223bacc"},"cell_type":"markdown","source":"<font size=6>**Let's finally use a pre-trained model** .</font>"},{"metadata":{"trusted":true,"_uuid":"0ec8bc9cf5325c2e0d587613ae3f6f497ae0f844","collapsed":true},"cell_type":"markdown","source":"# we will use ResNet pre-trained model\nfrom tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\nnum_classes=2\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nnew_model=Sequential()\nnew_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nnew_model.add(Dense(num_classes, activation='softmax'))\n#do not need to train pre-trained model\nnew_model.layers[0].trainable=False\n#compile\nnew_model.compile(loss=keras.losses.categorical_crossentropy,\n             optimizer='adam',\n             metrics=['accuracy'])"},{"metadata":{"trusted":true,"_uuid":"1543d96ffa7a917905d2aaf5add07d838d91f90b","collapsed":true},"cell_type":"markdown","source":"#USUALLY FOR PRE_TRAINED MODELS WE USE MUCH LESS DATA TO TRAIN THE MODEL (300 IMAGES IS ALREADY ENOUGH)\n#So even though accuracy might be high, we might have caused overfitting by training a model with too many pictures\n#but to not write more code I will use the same data with the same pipelines, I used before\n#TRAIN THE MODEL\n#train with augmentation\nhistory=new_model.fit_generator(train_generator,\n                    steps_per_epoch=500//50,#batch_size=50\n                    epochs=4,\n                    validation_data=validation_generator,\n                    validation_steps=100//50)\n\nplt.plot(history.history['acc'])"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"56d70409097166cfbc65950682e4505134740980"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}