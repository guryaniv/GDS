{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\nimport numpy as np\nimport re\nimport sklearn\nimport xgboost as xgb1\nfrom xgboost.sklearn import XGBClassifier\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.ensemble import *\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Going to use these 5 base models for the stacking\nfrom sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n                              GradientBoostingClassifier, ExtraTreesClassifier)\nfrom sklearn.tree import *\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import *\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import *\nrnd.seed(6)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\npassengerid = test['PassengerId']\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"906903214cf6a5cc29a02251939ec1639786af6e"},"cell_type":"code","source":"full_data = [train, test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5a473270c6dbbbdd60889a517d3b081b6c44128"},"cell_type":"code","source":"for data in full_data:\n    data['title'] = data['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\nfor data in full_data:\n    data['title'] = data['title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], \n                                                'Rare')\n    data['title'] = data['title'].replace('Mlle', 'Miss')\n    data['title'] = data['title'].replace('Ms', 'Miss')\n    data['title'] = data['title'].replace('Mme', 'Mrs')\ntrain[['Survived', 'title']].groupby('title', as_index=False).mean().sort_values(by='Survived',ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f7d39a1c04719f4397389506def130edfbe419b"},"cell_type":"code","source":"for data in full_data:\n    data['title'] = data['title'].map({'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5})\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"972e7a832cc055868cb1cdbc3372fab7de503e1b"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc12ec5781b34cd22b969f11ef3fb4e816a7b9cd"},"cell_type":"code","source":"for data in full_data:\n    data['Sex'] = data['Sex'].replace('female', int(1))\n    data['Sex'] = data['Sex'].replace('male', int(0))\n    data['Sex'] = data['Sex'].astype(int)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba16b6c83d8b98ab04724372a7c8d771326bfaa1"},"cell_type":"code","source":"ageguess = np.zeros((2,3))\nfor data in full_data:\n    for i in range(2):\n        for j in range(3):\n            agemean =data.loc[(data[\"Sex\"] == i) & (data['Pclass'] == j+1), 'Age'].mean()\n            agestd = data.loc[(data[\"Sex\"] == i) & (data['Pclass'] == j+1), 'Age'].std()\n            age_guess = rnd.uniform(agemean-agestd, agemean+agestd)\n            ageguess[i][j] = int(age_guess/0.5 + 0.5) * 0.5\n    for i in range(2):\n        for j in range(3):\n            data.loc[(data[\"Sex\"] == i) & (data['Pclass'] == j+1) & (data['Age'].isnull()), 'Age'] = ageguess[i][j]\n    data['Age'] = data['Age'].astype(int)\n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb481baaf6c1a4f148aab1dbe969608267970946"},"cell_type":"code","source":"for data in full_data:\n    data['ageband'] = pd.cut(data['Age'], 5)\ntrain[['Survived', 'ageband']].groupby('ageband', as_index=False).mean().sort_values(by='ageband', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1c8984d0d410590122d122aa45ab6a2b4b64304"},"cell_type":"code","source":"for data in full_data:\n    data.loc[data['Age'] <= 16, 'Age'] = 0\n    data.loc[(data['Age'] > 16) & (data['Age'] <= 32), 'Age'] = 1\n    data.loc[(data['Age'] > 32) & (data['Age'] <= 48), 'Age'] = 2\n    data.loc[(data['Age'] > 48) & (data['Age'] <= 64), 'Age'] = 3\n    data.loc[data['Age'] > 64, 'Age'] = 4\ntrain.head(5)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aee01ed0eac2539306486e015e98a6dc08a28dfa"},"cell_type":"code","source":"for data in full_data:\n    data['familysize'] = data['SibSp'] + data['Parch'] +1\nfor data in full_data:\n    data['isalone'] = 0\n    data.loc[data['familysize'] == 1, 'isalone'] = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd62b3cef28f0be8729d97f1cf166523c3249556"},"cell_type":"code","source":"for data in full_data:\n    data['age*pclass'] = data['Age'] * data['Pclass']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ea58f63413da7200aa48ec9654263470a9b3a7f"},"cell_type":"code","source":"for data in full_data:\n    data['Embarked'] = data['Embarked'].fillna('S')\nfor data in full_data:\n    data['Embarked'] = data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd196b69bd07b2f56e963e75e92a2d4bd32b361a"},"cell_type":"code","source":"for data in full_data:\n    data['fareband'] = pd.qcut(data['Fare'], 4)\ntrain[['Survived', 'fareband']].groupby('fareband', as_index=False).mean().sort_values(by='fareband', ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88d40824366f58c91b8c5b4259c8001e0bc3b575"},"cell_type":"code","source":"test['Fare'].fillna(test['Fare'].median(), inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05dc0567e039632074df72f9edc56f7bb27c975d"},"cell_type":"code","source":"for data in full_data:\n    data.loc[data['Fare'] <= 7.91, 'Fare'] = 0\n    data.loc[(data['Fare'] > 7.91) & (data['Fare'] <= 14.454), 'Fare'] = 1\n    data.loc[(data['Fare'] > 14.454) & (data['Fare'] <= 31), 'Fare'] = 2\n    data.loc[(data['Fare'] > 31), 'Fare'] = 3\n    data['Fare'] = data['Fare'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5b0617e3d757eee51bd7b1877165e630162d949"},"cell_type":"code","source":"drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'familysize','SibSp', 'Parch']\ntrain = train.drop(drop_elements, axis=1)\ntrain = train.drop(['ageband', 'fareband'], axis=1)\ntest = test.drop(drop_elements, axis=1)\ntest = test.drop(['ageband', 'fareband'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"086635841491b0fefb6f3e63df8fed548ba8bb6a"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88bb3996ed2b29bd868dbe2b7470782e7403ea2c"},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"898c447eb25cf062844b11880cd837066c657a71"},"cell_type":"code","source":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,12))\nplt.title('Pearson Correlation of Features', y=1.05, size=15)\nsns.heatmap(train.astype(float).corr(), linewidths=0.1, vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a9b2f8aae00a70feda9f5f92b7b451286a107f1"},"cell_type":"code","source":"g = sns.pairplot(train, hue='Survived', palette='seismic', size=1.2, diag_kind='kde', diag_kws=dict(shade=True),\n                plot_kws=dict(s=10))\ng.set(xticklabels=[])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d996ecb3d681c4c7dd64a533eb1a1ee8a18d96c"},"cell_type":"code","source":"mtrain = train.shape[0]\nmtest = test.shape[0]\nseed = 0\nnfolds =5\nkf = KFold( n_splits=nfolds, random_state=seed)\nclass sklearnhelper(object):\n    def __init__(self,clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n    def predict(self, x):\n        return self.clf.predict_proba(x)\n    def fit(self, x, y):\n        return self.clf.fit(x, y)\n    def feature_importances(self, x, y):\n        return self.clf.fit(x, y).feature_importances_\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((mtrain, ))\n    oof_test = np.zeros((mtest, ))\n    oof_test_skf = np.zeros((nfolds, mtest))\n    for i,(train_index, test_index) in enumerate(kf.split(x_train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n        clf.train(x_tr, y_tr)\n        oof_train[test_index] = clf.predict(x_te)[:, 1]\n        oof_test_skf[i, :] = clf.predict(x_test)[:, 1]\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"236e043d4b4faa52bdd75dc7587e47e6b442dbb6","scrolled":true},"cell_type":"code","source":"rfparams = {\n    'n_jobs': -1,\n    'n_estimators': 575,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt',\n\n}\netparams = {\n    'n_jobs': -1,\n    'n_estimators':575,\n    #'max_features': 0.5,\n    'max_depth': 5,\n    'min_samples_leaf': 3,\n\n}\nadaparams = {\n    'n_estimators': 575,\n    'learning_rate' : 0.95\n}\n\ngbparams = {\n    'n_estimators': 575,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 3,\n\n}\nsvcparams = {\n    'kernel' : 'linear',\n    'C' : 0.025,\n \n            'probability': True}\nrf = sklearnhelper(clf=RandomForestClassifier, seed=seed, params=rfparams)\net = sklearnhelper(clf=ExtraTreesClassifier, seed=seed, params=etparams)\nada =sklearnhelper(clf=AdaBoostClassifier, seed=seed, params=adaparams)\ngb = sklearnhelper(clf=GradientBoostingClassifier, seed=seed, params=gbparams)\nsvc = sklearnhelper(clf=SVC, seed=seed, params=svcparams)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed62a2367d5b97399f6c76f15f439db3aea753be"},"cell_type":"code","source":"y_train = train['Survived'].ravel()\ntrain = train.drop(['Survived'], axis=1)\nx_train = train.values\nx_test = test.values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b3c5f96269dec8e93010ad8fd7c64bda44030bb"},"cell_type":"code","source":"logparams = {'n_jobs': -1}\nxgbparams = {'n_estimator': 1000, 'max_depth': 6, 'gamma': 0.9, 'subsample': 0.8,\n            'colsample_bytree': 0.8}\ndtparams = {}\nbagparams = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e76fda42051149976e55c7bab94580e733d24b4"},"cell_type":"code","source":"log = sklearnhelper(clf=LogisticRegression, seed=seed, params=logparams)\nbag = sklearnhelper(clf=BaggingClassifier, seed=seed, params=bagparams) \nxgb = sklearnhelper(clf=XGBClassifier, seed=seed, params=xgbparams) \ndt = sklearnhelper(clf=DecisionTreeClassifier, seed=seed, params=dtparams) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afdc3d9dda697aff1567f915acf2389c8805c1ac"},"cell_type":"code","source":"class helper(object):\n    def __init__(self,clf, params=None):\n        self.clf = clf(**params)\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n    def predict(self, x):\n        return self.clf.predict(x)\n    def fit(self, x, y):\n        return self.clf.fit(x, y)\ndef get_helper(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((mtrain, ))\n    oof_test = np.zeros((mtest, ))\n    oof_test_skf = np.zeros((nfolds, mtest))\n    for i,(train_index, test_index) in enumerate(kf.split(x_train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n        clf.train(x_tr, y_tr)\n        oof_train[test_index] = clf.predict(x_te)\n        oof_test_skf[i, :] = clf.predict(x_test)\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"885e717b379c329254698005573582f7c3fc503b"},"cell_type":"code","source":"knnparams = {}\n\n\nknn = helper(clf=KNeighborsClassifier,  params=knnparams)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e2778467c13a38e5fd5b994147ce479e512121e"},"cell_type":"code","source":"et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test)\nrf_oof_train, rf_oof_test = get_oof(rf, x_train, y_train, x_test)\nada_oof_train, ada_oof_test = get_oof(ada, x_train, y_train, x_test)\ngb_oof_train, gb_oof_test = get_oof(gb, x_train, y_train, x_test)\nsvc_oof_train, svc_oof_test = get_oof(svc, x_train, y_train, x_test)\nlog_oof_train, log_oof_test = get_oof(log, x_train, y_train, x_test)\nbag_oof_train, bag_oof_test = get_oof(bag, x_train, y_train, x_test)\ndt_oof_train, dt_oof_test = get_oof(dt, x_train, y_train, x_test)\nxgb_oof_train, xgb_oof_test = get_oof(xgb, x_train, y_train, x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9de3855ac9da5865d1fa0db5e780b518c6c018d"},"cell_type":"code","source":"knn_oof_train, knn_oof_test = get_helper(knn, x_train, y_train, x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b15649426dcfb8bc477d53f7b2c47555d8d037d2"},"cell_type":"code","source":"def accuracy(trainproba, ytrain):\n    trainproba = (trainproba>0.5)\n    ans = np.sum(np.abs(trainproba - ytrain.reshape(891, 1))) / 891\n    return (1- ans)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b7eaf6adf4c9788a2d5b85cf9c889d26adbfa41"},"cell_type":"code","source":"print('''\net_oof_train : {}\nrf_oof_train : {}\nada_oof_train : {}\ngb_oof_train : {}\nsvc_oof_train : {}\nlog_oof_train : {}\nbag_oof_train : {}\ndt_oof_train : {}\nxgb_oof_train : {}\nknn_oof_train : {}\n\n'''.format(accuracy(et_oof_train, y_train), accuracy(rf_oof_train, y_train), accuracy(ada_oof_train, y_train)\n          ,accuracy(gb_oof_train, y_train) ,accuracy(svc_oof_train, y_train), accuracy(log_oof_train, y_train),\n          accuracy(bag_oof_train, y_train), accuracy(dt_oof_train, y_train),\n          accuracy(xgb_oof_train, y_train), accuracy(knn_oof_train, y_train)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5b029bfe0454095d7abc27e8d16caca7164704c"},"cell_type":"code","source":"rffeature = rf.feature_importances(x_train, y_train)\netfeature = et.feature_importances(x_train, y_train)\nadafeature = ada.feature_importances(x_train, y_train)\ngbfeature = gb.feature_importances(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff361845cd03131ac4fc2e802f520e9827a672cd"},"cell_type":"code","source":"cols = train.columns.values\nfeature_importances_dataframe = pd.DataFrame({'features': cols,\n                                              'random forest': rffeature,\n                                             'extra trees': etfeature,\n                                             'adaboost': adafeature,\n                                             'gradient boost': gbfeature})\nfeature_importances_dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d23503d40f7301d491586aff9ae1bba62c648156"},"cell_type":"code","source":"feature_importances_dataframe['features'].values,","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6813f58477073e66520a48295f282e65ad030638"},"cell_type":"code","source":"trace = go.Scatter(\n    y = feature_importances_dataframe['random forest'].values,\n    x = feature_importances_dataframe['features'].values,\n    mode = 'markers+lines',\n    marker = dict(\n             sizemode = 'diameter',\n             sizeref = 1,\n             size = 25,\n             color = feature_importances_dataframe['random forest'].values,\n             colorscale = 'Portland',\n             showscale = True\n    ),\n    text = feature_importances_dataframe['features'].values\n)\ndata = [trace]\nlayout = go.Layout(\n    autosize = True,\n    title = 'random forest feature importantce',\n    hovermode = 'closest',\n    yaxis = dict(\n        title = 'feature importance',\n        ticklen = 5,\n        gridwidth = 2\n    ),\n    showlegend = False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"932153ce7f6b9b7684d4d9c799418b0182d31d34","scrolled":true},"cell_type":"code","source":"trace = go.Scatter(\n    y = feature_importances_dataframe['extra trees'].values,\n    x = feature_importances_dataframe['features'].values,\n    mode = 'markers',\n    marker = dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n        color = feature_importances_dataframe['extra trees'].values,\n        colorscale = 'Portland',\n        showscale = True\n    ),\n    text = feature_importances_dataframe['features'].values\n)\n\ndata = [trace]\nlayout = go.Layout(\n    autosize = True,\n    title = 'extra trees feature importance',\n    hovermode = 'closest',\n    yaxis = dict(\n        title = 'feature importance',\n        ticklen = 5,\n        gridwidth = 2,\n    ),\n    showlegend = False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"072d0f557404edb9820fa0cf41e6886fea5141d7"},"cell_type":"code","source":"trace = go.Scatter(\n    y = feature_importances_dataframe['adaboost'].values,\n    x = feature_importances_dataframe['features'].values,\n    mode = 'markers',\n    marker = dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n        color = feature_importances_dataframe['adaboost'].values,\n        colorscale = 'Portland',\n        showscale = True\n        )\n)\ndata = [trace]\nlayout = go.Layout(\n    autosize = True,\n    title = 'adaboost',\n    hovermode = 'closest',\n    yaxis = dict(\n        title = 'feature importance',\n        ticklen = 5,\n        gridwidth = 2,\n    ),\n    showlegend = False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='scatter2010')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b0fde709b0478c01430cd7b4197f64769cda8dc"},"cell_type":"code","source":"trace = go.Scatter(\n    y = feature_importances_dataframe['gradient boost'].values,\n    x = feature_importances_dataframe['features'].values,\n    mode = 'markers',\n    marker = dict(\n        sizemode = 'diameter',\n        sizeref = 1,\n        size = 25,\n        color = feature_importances_dataframe['gradient boost'].values,\n        colorscale = 'Portland',\n        showscale = True),\n)\ndata = [trace]\nlayout = go.Layout(\n    autosize = True,\n    title = 'gradient bost',\n    hovermode = 'closest',\n    yaxis = dict(\n        title = 'feature importances',\n        ticklen = 5,\n        gridwidth = 2\n    ),\n    showlegend = False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig , filename='scatter2010')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f896997960151c86116a53ea0df1bdfc7ea7def"},"cell_type":"code","source":"feature_importances_dataframe['mean'] = feature_importances_dataframe.mean(axis=1)\ntrace = go.Bar(\n    y = feature_importances_dataframe['mean'].values,\n    x = feature_importances_dataframe['features'].values,\n    width = 0.5,\n    marker = dict(\n        color = feature_importances_dataframe['mean'].values,\n        colorscale = 'Portland',\n        showscale = True,\n        reversescale = False\n    ),\n    opacity = 0.6\n)\ndata = [trace]\nlayout = go.Layout(\n    autosize =True,\n    title = 'Mean feature_importances_dataframe',\n    hovermode = 'closest',\n    yaxis = dict(\n        title = 'feature_importances_dataframe',\n        ticklen = 5,\n        gridwidth  = 2\n    ),\n    showlegend = False\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig, filename='bar_direct_label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00d6ca48798e99c769544061f9fa4fa5fdf43d90"},"cell_type":"code","source":"base_predict_train = pd.DataFrame(\n    {'random_a': rf_oof_train.ravel(),\n\n     'extratrees_a': et_oof_train.ravel(),\n\n     'adaboost_a': ada_oof_train.ravel(),\n\n     'gradientboost_a': gb_oof_train.ravel(),\n})\nbase_predict_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6eef649df0868f813bc45ab6d62f7f2eaac3d4a4"},"cell_type":"code","source":"data = [go.Heatmap(\n    z = base_predict_train.astype(float).corr().values,\n    x = base_predict_train.columns.values,\n    y = base_predict_train.columns.values,\n    colorscale = 'Viridis',\n    showscale = True,\n    reversescale = True)]\npy.iplot(data, filename='labeled-heatmap')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec730ef42c1acf91f56f94d055444c1f1cff9ac6"},"cell_type":"code","source":"x_train = np.concatenate((x_train, rf_oof_train, et_oof_train, gb_oof_train, ada_oof_train, svc_oof_train,\n                         log_oof_train, bag_oof_train, dt_oof_train, xgb_oof_train), axis=1 )\nx_test = np.concatenate((x_test, rf_oof_test, et_oof_test, gb_oof_test, ada_oof_test, svc_oof_test,\n                        log_oof_test, bag_oof_test, dt_oof_test, xgb_oof_test), axis=1 )\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"576eeed184a862a237be74a163cc342099e0a70f"},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4eb341da9eb352f96fc6bdb40231d2c581007f4"},"cell_type":"code","source":"mtrain = train.shape[0]\nmtest = test.shape[0]\nseed = 0\nnfolds =5\nkf = KFold( n_splits=nfolds, random_state=seed)\nclass sklearnhelper(object):\n    def __init__(self,clf, seed=0, params=None):\n        params['random_state'] = seed\n        self.clf = clf(**params)\n    def train(self, x_train, y_train):\n        self.clf.fit(x_train, y_train)\n    def predict(self, x):\n        return self.clf.predict_proba(x)\n    def fit(self, x, y):\n        return self.clf.fit(x, y)\n    def feature_importances(self, x, y):\n        return self.clf.fit(x, y).feature_importances_\ndef get_oof(clf, x_train, y_train, x_test):\n    oof_train = np.zeros((mtrain, ))\n    oof_test = np.zeros((mtest, ))\n    oof_test_skf = np.zeros((nfolds, mtest))\n    for i,(train_index, test_index) in enumerate(kf.split(x_train)):\n        x_tr = x_train[train_index]\n        y_tr = y_train[train_index]\n        x_te = x_train[test_index]\n        clf.train(x_tr, y_tr)\n        oof_train[test_index] = clf.predict(x_te)[:, 1]\n        oof_test_skf[i, :] = clf.predict(x_test)[:, 1]\n    oof_test[:] = oof_test_skf.mean(axis=0)\n    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c34424fc1dfe58ec755bb74b9b5ea8d7085fac2"},"cell_type":"code","source":"rfparams = {\n    'n_jobs': -1,\n    'n_estimators': 575,\n     'warm_start': True, \n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 2,\n    'max_features' : 'sqrt'}\netparams = {\n    'n_jobs': -1,\n    'n_estimators':575,\n    #'max_features': 0.5,\n    'max_depth': 5,\n    'min_samples_leaf': 3}\ngbparams = {\n    'n_estimators': 575,\n     #'max_features': 0.2,\n    'max_depth': 5,\n    'min_samples_leaf': 3}\nsvcparams = {\n    'kernel' : 'linear',\n    'C' : 0.025,\n 'probability': True}\nxgbparams = {'n_estimator': 1000, 'max_depth': 6, 'gamma': 0.9, 'subsample': 0.8,\n            'colsample_bytree': 0.8}\nrf = sklearnhelper(clf=RandomForestClassifier, seed=seed, params=rfparams)\net = sklearnhelper(clf=ExtraTreesClassifier, seed=seed, params=etparams)\nxgb = sklearnhelper(clf=XGBClassifier, seed=seed, params=xgbparams) \ngb = sklearnhelper(clf=GradientBoostingClassifier, seed=seed, params=gbparams)\nsvc = sklearnhelper(clf=SVC, seed=seed, params=svcparams)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35820a7cfec6f51ebee15a6f85e7d24bc9a69c02"},"cell_type":"code","source":"et_oof_train, et_oof_test = get_oof(et, x_train, y_train, x_test)\nrf_oof_train, rf_oof_test = get_oof(rf, x_train, y_train, x_test)\ngb_oof_train, gb_oof_test = get_oof(gb, x_train, y_train, x_test)\nsvc_oof_train, svc_oof_test = get_oof(svc, x_train, y_train, x_test)\nxgb_oof_train, xgb_oof_test = get_oof(xgb, x_train, y_train, x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"419f3b344bf0a666b4f69762738a1d661b6f3211"},"cell_type":"code","source":"x_train = np.concatenate((rf_oof_train, et_oof_train, gb_oof_train,  svc_oof_train,\n                         xgb_oof_train), axis=1 )\nx_test = np.concatenate((rf_oof_test, et_oof_test, gb_oof_test,  svc_oof_test,\n                        xgb_oof_test), axis=1 )\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18ef5eb38904e344b748af6d9b18aaf321c1ada5"},"cell_type":"code","source":"gbm = xgb1.XGBClassifier(\nlearning_rate = 0.95,\n n_estimators= 5000,\n max_depth= 4,\n min_child_weight= 2,\n #gamma=1,\n gamma=1,                        \n subsample=0.8,\n colsample_bytree=0.8,\n objective= 'binary:logistic',\n nthread= -1,\n scale_pos_weight=1).fit(x_train, y_train)\npred = gbm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"354adab2fb17e630e5897a4b998072fdd2751343"},"cell_type":"code","source":"StackingSubmission = pd.DataFrame({'PassengerId': passengerid, 'Survived': pred})\nStackingSubmission.to_csv('StackingSubmission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}