{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"**Reading the data and specifying the target to predict.**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\n\nrandom.seed(42)\nnp.random.seed(42)\n\ntrain_key = 'sales'\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nprint(train.shape)\n\nX = train.drop(columns=[train_key])\ny = train[train_key]\n\nX_pred = test\nsubmissionId = X_pred.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"402808b656d5b27baceaa24ce33262de426c71cc"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelBinarizer\n%matplotlib inline\n\ndef negative_mean_absolute_percentage_error(estimator, X, y_true):\n    y_pred = estimator.predict(X)\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return -(np.mean(np.abs((y_true - y_pred) / y_true)) * 100)\n\ndef binarize_stores(X_train, X_test, X_pred):\n    X_train['store'] = X_train['store'].astype(str)\n    X_test['store'] = X_test['store'].astype(str)\n    X_pred['store'] = X_pred['store'].astype(str)\n    \n    lbinarizer = LabelBinarizer()\n    lbinarizer.fit(X_train['store'])\n    \n    binarized_values_train = pd.DataFrame(data=lbinarizer.transform(X_train['store']),\n                                        index=X_train.index,\n                                        columns=['store_'+column for column in lbinarizer.classes_])\n    X_train = pd.concat(objs=[X_train, binarized_values_train], axis=1)\n    \n    binarized_values_test = pd.DataFrame(data=lbinarizer.transform(X_test['store']),\n                                        index=X_test.index,\n                                        columns=['store_'+column for column in lbinarizer.classes_])\n    X_test = pd.concat(objs=[X_test, binarized_values_test], axis=1)\n    \n    binarized_values_pred = pd.DataFrame(data=lbinarizer.transform(X_pred['store']),\n                                        index=X_pred.index,\n                                        columns=['store_'+column for column in lbinarizer.classes_])\n    X_pred = pd.concat(objs=[X_pred, binarized_values_pred], axis=1)\n    \n    X_train.drop(columns='store', inplace=True)\n    X_test.drop(columns='store', inplace=True)\n    X_pred.drop(columns='store', inplace=True)\n    \n    return X_train, X_test, X_pred\n\ndef binarize_items(X_train, X_test, X_pred):\n    X_train['item'] = X_train['item'].astype(str)\n    X_test['item'] = X_test['item'].astype(str)\n    X_pred['item'] = X_pred['item'].astype(str)\n    \n    lbinarizer = LabelBinarizer()\n    lbinarizer.fit(X_train['item'])\n    \n    binarized_values_train = pd.DataFrame(data=lbinarizer.transform(X_train['item']),\n                                        index=X_train.index,\n                                        columns=['item_'+column for column in lbinarizer.classes_])\n    X_train = pd.concat(objs=[X_train, binarized_values_train], axis=1)\n    \n    binarized_values_test = pd.DataFrame(data=lbinarizer.transform(X_test['item']),\n                                        index=X_test.index,\n                                        columns=['item_'+column for column in lbinarizer.classes_])\n    X_test = pd.concat(objs=[X_test, binarized_values_test], axis=1)\n    \n    binarized_values_pred = pd.DataFrame(data=lbinarizer.transform(X_pred['item']),\n                                        index=X_pred.index,\n                                        columns=['item_'+column for column in lbinarizer.classes_])\n    X_pred = pd.concat(objs=[X_pred, binarized_values_pred], axis=1)\n    \n    X_train.drop(columns='item', inplace=True)\n    X_test.drop(columns='item', inplace=True)\n    X_pred.drop(columns='item', inplace=True)\n    \n    return X_train, X_test, X_pred\n\ndef split_date(*datasets):\n    for dataset in datasets:\n        index = dataset.index\n        dataset['date'] = pd.to_datetime(dataset['date'], format='%Y-%m-%d')\n        dataset['day'] = pd.DatetimeIndex(dataset['date']).day\n        dataset['month'] = pd.DatetimeIndex(dataset['date']).month\n        dataset['year'] = pd.DatetimeIndex(dataset['date']).year\n        dataset['dow'] = pd.DatetimeIndex(dataset['date']).dayofweek\n        dataset['cw'] = pd.DatetimeIndex(dataset['date']).weekofyear\n    return datasets\n\ndef preprocess_day(*datasets):\n    for dataset in datasets:\n        dataset['day_sin'] = np.sin(dataset['day']-1 * (2. * np.pi / 31))\n        dataset['day_cos'] = np.cos(dataset['day']-1 * (2. * np.pi / 31))\n        dataset.drop(columns=['day'], inplace=True)\n    return datasets\n\ndef preprocess_month(*datasets):\n    for dataset in datasets:\n        dataset['month_sin'] = np.sin(dataset['month']-1 * (2. * np.pi / 12))\n        dataset['month_cos'] = np.cos(dataset['month']-1 * (2. * np.pi / 12))\n        dataset.drop(columns=['month'], inplace=True)\n    return datasets\n\ndef preprocess_dow(*datasets):\n    for dataset in datasets:\n        dataset['dow_sin'] = np.sin(dataset['dow'] * (2. * np.pi / 7))\n        dataset['dow_cos'] = np.cos(dataset['dow'] * (2. * np.pi / 7))\n        dataset.drop(columns=['dow'], inplace=True)\n    return datasets\n    \ndef preprocess_cw(*datasets):\n    for dataset in datasets:\n        dataset['cw_sin'] = np.sin(dataset['cw']-1 * (2. * np.pi / 53))\n        dataset['cw_cos'] = np.cos(dataset['cw']-1 * (2. * np.pi / 53))\n        dataset.drop(columns=['cw'], inplace=True)\n    return datasets\n\ndef plot_by_date(X, y):\n    X['sales'] = y\n    \n    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n    plt.subplot(2,2, 1)\n    plt.title('Sales by Day of Week')\n    data_by_dow = X.groupby(['dow']).aggregate(np.mean)\n    plt.plot(data_by_dow.index, data_by_dow['sales'], linestyle=':', markersize=0.1)\n\n    plt.subplot(2,2, 2)\n    plt.title('Sales by Calendar Week')\n    data_by_cw = X.groupby(['cw']).aggregate(np.mean)\n    plt.plot(data_by_cw.index, data_by_cw['sales'], linestyle=':', markersize=0.1)\n    \n    plt.subplot(2,2, 3)\n    plt.title('Sales by Month')\n    data_by_dow = X.groupby(['month']).aggregate(np.mean)\n    plt.plot(data_by_dow.index, data_by_dow['sales'], linestyle=':', markersize=0.1)\n    \n    plt.subplot(2,2, 4)\n    plt.title('Sales by Year')\n    data_by_year = X.groupby(['year']).aggregate(np.mean)\n    plt.plot(data_by_year.index, data_by_year['sales'], linestyle=':', markersize=0.1)\n        \n    X.drop(columns='sales', inplace=True)\n\n    plt.show()\n    \ndef plot_by_date_and_store(X, y):\n    X['sales'] = y\n    \n    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n    ax1 = plt.subplot(2,2, 1)\n    plt.title('Sales per Store by Day of Week')\n    X.groupby(['dow','store']).mean()['sales'].unstack().plot(ax=ax1)\n    \n    ax2 = plt.subplot(2,2, 2)\n    plt.title('Sales per Store by Calendar Week')\n    X.groupby(['cw','store']).mean()['sales'].unstack().plot(ax=ax2)\n    \n    ax3 = plt.subplot(2,2, 3)\n    plt.title('Sales per Store by Month')\n    X.groupby(['month','store']).mean()['sales'].unstack().plot(ax=ax3)\n    \n    ax4 = plt.subplot(2,2, 4)\n    plt.title('Sales per Store by Year')\n    X.groupby(['year','store']).mean()['sales'].unstack().plot(ax=ax4)\n    \n    X.drop(columns='sales', inplace=True)\n    \n    plt.show()\n    \ndef plot_by_date_and_item(X, y):\n    X['sales'] = y\n    \n    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n    ax1 = plt.subplot(2,2, 1)\n    plt.title('Sales per Item by Day of Week')\n    X.groupby(['dow','item']).mean()['sales'].unstack().plot(ax=ax1)\n    \n    ax2 = plt.subplot(2,2, 2)\n    plt.title('Sales per Item by Calendar Week')\n    X.groupby(['cw','item']).mean()['sales'].unstack().plot(ax=ax2)\n    \n    ax3 = plt.subplot(2,2, 3)\n    plt.title('Sales per Item by Month')\n    X.groupby(['month','item']).mean()['sales'].unstack().plot(ax=ax3)\n    \n    ax4 = plt.subplot(2,2, 4)\n    plt.title('Sales per Item by Year')\n    X.groupby(['year','item']).mean()['sales'].unstack().plot(ax=ax4)\n    \n    X.drop(columns='sales', inplace=True)\n    \n    plt.show()\n    \ndef plot_sales_by_store_and_item(X, y):\n    X['sales'] = y\n    plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n    \n    from mpl_toolkits.mplot3d import Axes3D\n    fig = plt.figure()\n    data = pd.DataFrame(data=X.groupby(['store','item']).count()['sales'])\n    data.reset_index(inplace=True)\n    ax = fig.add_subplot(111, projection='3d')\n    \n    ax.scatter(xs=data['store'], ys=data['item'], zs=data['sales'])\n    \n    X.drop(columns='sales', inplace=True)\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f91f451d0daa0ef7139c53091f652a6d79d21a1"},"cell_type":"markdown","source":"**Exploratory Data Analysis**\n1. Exploring the seasonality in different dimensions (Calendar Week, Day of Week, Month, Year)\n2. Exploring the seaonality in the same dimensions by stores\n3. Exploring the seasonality in the same dimensions by item"},{"metadata":{"trusted":true,"_uuid":"6f9f47510576016277a70876f8481135a71648b5"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.00001)\n\nX_train, X_test, X_pred = split_date(X_train, X_test, X_pred)\nplot_by_date(X_train, y_train)\nplot_by_date_and_store(X_train, y_train)\nplot_by_date_and_item(X_train, y_train)\nplot_sales_by_store_and_item(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24f01bdc4f8d3589f07516c27285d4b8bbcbb0ba"},"cell_type":"markdown","source":"**Approach I: Machine Learning**\nPrediction by training the multiple ML algorithms."},{"metadata":{"trusted":true,"_uuid":"62a6ed1b50a04ffe6d0f471305bd1dbedc161fb7"},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\ndef train_gridsearch_cv(model, X_train, y_train, param_grid={}):\n    clf = GridSearchCV(cv=5,\n                       estimator=model,\n                       param_grid=param_grid,\n                       n_jobs=-1,\n                       verbose=1,\n                       scoring='neg_mean_squared_error')\n    clf.fit(X=X_train, y=y_train)\n    print(\"MSE\", -clf.best_score_)\n    return clf.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"39f0e8cf6fffc2b7c1ae71004526e16459876ca0"},"cell_type":"code","source":"#X_train, X_test, X_pred = binarize_stores(X_train, X_test, X_pred)\n#X_train, X_test, X_pred = binarize_items(X_train, X_test, X_pred)\nX_train, X_test, X_pred = split_date(X_train, X_test, X_pred)\n#X_train, X_test, X_pred = preprocess_day(X_train, X_test, X_pred)\n#X_train, X_test, X_pred = preprocess_month(X_train, X_test, X_pred)\n\nX_train.drop(columns='date', inplace=True)\nX_test.drop(columns='date', inplace=True)\nX_pred.drop(columns='date', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc1282c6ea4a07dafa68d8143a8ee9ee8ef0e8f2"},"cell_type":"code","source":"from sklearn.linear_model import ElasticNet\n\nmodel_el = ElasticNet()\nmodel_el.fit(X_train, y_train)\n\nprint(\"MAPE:\", round(-negative_mean_absolute_percentage_error(estimator=model_el, \n                                                        X=X_test, \n                                                        y_true=y_test),2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"accc1436c81803f38a4a3556ac43db1a95985977"},"cell_type":"markdown","source":"**Approach II:** Simple self build forecasting. Based on historical average and factors for store, item and seasonality (month/ calendar week and day of week)."},{"metadata":{"trusted":true,"_uuid":"4223b8a9112f6b5fb2c4af975550b8b46195b846"},"cell_type":"code","source":"def get_item_factor(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_item = X.groupby(['item']).mean()['sales']\n    average_per_item = pd.DataFrame(average_per_item)\n    average_per_item.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_item['sales_mean_normalized'] = average_per_item['sales_mean']/grand_average\n    X.drop(columns='sales', inplace=True)\n    return(average_per_item)\n\ndef get_store_factor(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_store = X.groupby(['store']).mean()['sales']\n    average_per_store = pd.DataFrame(average_per_store)\n    average_per_store.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_store['sales_mean_normalized'] = average_per_store['sales_mean']/grand_average\n    X.drop(columns='sales', inplace=True)\n    return(average_per_store)\n\ndef get_month_factor(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_month = X.groupby(['month']).mean()['sales']\n    average_per_month = pd.DataFrame(average_per_month)\n    average_per_month.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_month['sales_mean_normalized'] = average_per_month['sales_mean']/grand_average\n    X.drop(columns='sales', inplace=True)\n    return(average_per_month)\n\ndef get_cw_factor(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_cw = X.groupby(['cw']).mean()['sales']\n    average_per_cw = pd.DataFrame(average_per_cw)\n    average_per_cw.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_cw['sales_mean_normalized'] = average_per_cw['sales_mean']/grand_average\n    X.drop(columns='sales', inplace=True)\n    return(average_per_cw)\n\ndef get_dow_factor(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_dow = X.groupby(['dow']).mean()['sales']\n    average_per_dow = pd.DataFrame(average_per_dow)\n    average_per_dow.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_dow['sales_mean_normalized'] = average_per_dow['sales_mean']/grand_average\n    X.drop(columns='sales', inplace=True)\n    return(average_per_dow)\n\ndef get_annualy_growth(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_year = X.groupby(['year']).mean()['sales']\n    average_per_year = pd.DataFrame(average_per_year)\n    average_per_year.rename(columns={'sales': 'sales_mean'}, inplace=True)\n    average_per_year['sales_mean_normalized'] = average_per_year['sales_mean']/grand_average\n    growth_factor = 1+(average_per_year['sales_mean_normalized'][2017] - average_per_year['sales_mean_normalized'][2013])/5\n    X.drop(columns='sales', inplace=True)\n    return(growth_factor)\n\ndef get_annualy_growth_additive(X, y):\n    X['sales'] = y\n    grand_average = X['sales'].mean()\n    average_per_year = X.groupby(['year']).mean()['sales']\n    growth_factor = 2.1\n    return(growth_factor)\n\ndef get_average_latest_year(X, y):\n    X['sales'] = y\n    average_2017 = X[X['year']==2017]['sales'].mean()\n    return(average_2017)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbd933d0c9a261c621a128defb8922b57a350e2e","scrolled":true},"cell_type":"code","source":"X['sales'] = y\ngrand_average = get_average_latest_year(X_train, y_train)\nitem_factor = get_item_factor(X_train, y_train)\nstore_factor = get_store_factor(X_train, y_train)\ncw_factor = get_cw_factor(X_train, y_train)\ndow_factor = get_dow_factor(X_train, y_train)\nannual_growth = get_annualy_growth(X_train, y_train)\nannual_factor_additive = get_annualy_growth_additive(X_train, y_train)\n\ndef predict(item, store, cw, dow, year):\n    pred = (grand_average+annual_factor_additive) * item_factor['sales_mean_normalized'][item] * store_factor['sales_mean_normalized'][store] * cw_factor['sales_mean_normalized'][cw] * dow_factor['sales_mean_normalized'][dow]\n    return(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ff81fb77f83b4ebf6ae06544366eaf10687f6dd"},"cell_type":"code","source":"prediction = []\nfor idx, row in X_pred.iterrows():\n    prediction.append(predict(X_pred['item'][idx], X_pred['store'][idx], X_pred['cw'][idx], X_pred['dow'][idx], X_pred['year'][idx]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b1797b9b1d351f78f7e0d80056b1872a4c582b1"},"cell_type":"markdown","source":"**Approach III: SARIMA**"},{"metadata":{"trusted":true,"_uuid":"ac41c8d65224a467569a1b19a74a3bb3f1b3eea9"},"cell_type":"code","source":"import statsmodels.api as sm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1372e1a194d9aa1cb119f48aa48c4cee58827584"},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true,"_uuid":"b95005b2f7391bf2e80b0577fdc5fe98b813b441"},"cell_type":"code","source":"submission = pd.DataFrame({'Id': submissionId, 'sales': prediction})\n# you could use any filename. We choose submission here\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}