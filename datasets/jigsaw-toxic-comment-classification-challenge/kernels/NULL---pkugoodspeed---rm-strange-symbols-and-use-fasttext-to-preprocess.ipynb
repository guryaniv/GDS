{"cells": [{"source": ["- Plan to train each column separately.\n", "- Here, use an rnn model to train the first column: `toxic`\n", "- It is pretty slow"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "source": ["## system\n", "import os\n", "\n", "## Math and dataFrame\n", "import numpy as np\n", "import pandas as pd\n", "import scipy\n", "from scipy.sparse import csr_matrix, hstack\n", "\n", "## Visualization\n", "%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "from IPython.display import display\n", "import seaborn as sns"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "333dc45a-ca46-4a2c-af24-00cd57e27883", "_uuid": "b15824606aeebc19c0eafa981cbdaafcf80363f4"}}, {"outputs": [], "source": ["## Traditional Machine Learning\n", "from sklearn.linear_model import Ridge, LogisticRegression\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "6b1b883f-9fd8-4053-a309-5bca91008cbf", "_uuid": "f9876766de8f6bcd302b6b1e9047d81d74c551fb"}}, {"outputs": [], "source": ["## Keras\n", "from keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten\n", "from keras.models import Model, Sequential\n", "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping#, TensorBoard\n", "from keras import backend as K\n", "from keras import optimizers\n", "from keras.optimizers import SGD\n", "from keras import initializers\n", "from keras.callbacks import LearningRateScheduler\n", "from keras.utils import np_utils\n", "from keras.preprocessing.sequence import pad_sequences"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "73660cd7-f560-4c5f-88a6-ccc76302c4dc", "_uuid": "4d00479ca3112032f461505ea9cca53e449cb6c2"}}, {"outputs": [], "source": ["## Using Multi processing"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}, {"outputs": [], "source": ["from multiprocessing import Pool"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}, {"outputs": [], "source": ["## Load data\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "7b4724d4-cf48-4caf-8682-0143652ab683", "_uuid": "5702f8694094107547dfdb847e11de51cf6a6407"}}, {"source": ["##### Do some statistics"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "source": ["display(train[:10])\n", "print(train.shape)\n", "print(\"toxic count = {0}\".format(train.toxic.sum()))\n", "print(\"severe_toxic count = {0}\".format(train.severe_toxic.sum()))\n", "print(\"obscene count = {0}\".format(train.obscene.sum()))\n", "print(\"threat count = {0}\".format(train.threat.sum()))\n", "print(\"insult count = {0}\".format(train.insult.sum()))\n", "print(\"identity_hate count = {0}\".format(train.identity_hate.sum()))"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "2fd98650-b3de-4222-9662-6c0fad714ded", "_uuid": "b23f8b789678c9446133308b212abfc0adea5830"}}, {"source": ["###### Show correlation matrix"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "source": ["corr = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].corr()\n", "f, ax = plt.subplots(figsize=(10, 8))\n", "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n", "            square=True, ax=ax)"], "cell_type": "code", "execution_count": null, "metadata": {}}, {"source": ["###### For Sentence processing"], "cell_type": "markdown", "metadata": {"_cell_guid": "4eb487b4-2829-44a4-943d-f6ea0aa7c331", "_uuid": "6418d9abb0412df2272688da7d31a3349722cf2e"}}, {"outputs": [], "source": ["from nltk import word_tokenize\n", "from nltk.corpus import stopwords\n", "import string\n", "stop = set(stopwords.words('english'))\n", "punc = set(string.punctuation)"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "f74c43dd-ea21-4d4f-a34f-23c612c0ace1", "_uuid": "bb69470290d9b8fe5053efcef123fc87260e693f"}}, {"source": ["Here I am trying to remove all the stop words and punctuations. Not sure whether it will give a better result or not"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "source": ["#### Preprocess sentences (removing punctuations and removing stop words)\n", "def rmPunc(sent):\n", "    return ''.join([ch for ch in str(sent) if ch not in punc])\n", "def rmStop(sent):\n", "    return ' '.join([word for word in sent.split() if word not in stop])"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}, {"outputs": [], "source": ["print(\"PREPROCESS TEXT...\")\n", "pool = Pool()\n", "%time train.comment_text = pool.map(rmPunc, train.comment_text.str.lower())\n", "%time test.comment_text = pool.map(rmPunc, test.comment_text.str.lower())\n", "\n", "%time train.comment_text = pool.map(rmStop, train.comment_text.str.lower())\n", "%time test.comment_text = pool.map(rmStop, test.comment_text.str.lower())\n", "pool.close()\n", "pool.join()"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "4a60b951-2dcf-40e5-a247-6992765c7a21", "_uuid": "4830e4afc41cc1b0cbbde2731e711a98302e75ad"}}, {"source": ["###### Tokenization"], "cell_type": "markdown", "metadata": {"_cell_guid": "22933d1f-8125-4f87-bae4-3eb9e20da846", "_uuid": "a6f25ccb7adf58b02cb3e3118524a1aec99f4ad8"}}, {"outputs": [], "source": ["#PROCESS TEXT: RAW\n", "print(\"Text to seq process...\")\n", "print(\"   Fitting tokenizer...\")\n", "from keras.preprocessing.text import Tokenizer\n", "raw_text = np.hstack([train.comment_text.str.lower(), \n", "                      test.comment_text.str.lower()])\n", "tok_raw = Tokenizer()\n", "tok_raw.fit_on_texts(raw_text)\n", "print(\"   Transforming text to seq...\")\n", "train[\"input\"] = tok_raw.texts_to_sequences(train.comment_text.str.lower())\n", "test[\"input\"] = tok_raw.texts_to_sequences(test.comment_text.str.lower())"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "1310a93f-2a26-4f3e-a1ef-f13d23d4df70", "_uuid": "948fa452f8b833e79699e3620e39c4cdfe0d9f1a"}}, {"source": ["###### Some statistics on sentence lengths"], "cell_type": "markdown", "metadata": {"_cell_guid": "80c9d372-7ce6-4362-9bd4-d651ae62bc2f", "_uuid": "8180b10cde03390c7ef68e3692bbc88135c147ac"}}, {"outputs": [], "source": ["test.input.apply(lambda x: len(x)).hist()\n", "train.input.apply(lambda x: len(x)).hist()"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "9923b707-c79f-4b00-8a34-f393bbb8b02c", "_uuid": "37d4430506598c63e71c84319e403f4e7db97ed9"}}, {"outputs": [], "source": ["MAX_LENGTH = 200\n", "MAX_TOKEN = np.max([np.max(train.input.max()),np.max(test.input.max())]) + 5\n", "print(MAX_LENGTH, MAX_TOKEN)"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "14f46bbc-761d-46f1-8fc9-1ee9530eb31d", "_uuid": "1a114cf0a5fdec11c93bdc53760b6e5139ee6c55"}}, {"outputs": [], "source": ["train = train[['input', 'toxic']]\n", "dtrain, dvalid = train_test_split(train, random_state=17, train_size=0.7)\n", "print(dtrain.shape)\n", "print(dvalid.shape)"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "99ad13ce-b85a-4b8f-b3ca-4be0b49be01c", "_uuid": "44c7dda15d2f17bdddb8b0f4babdaa6f5f6b1b3d"}}, {"source": ["###### Artificially balance the classes"], "cell_type": "markdown", "metadata": {"_cell_guid": "5e99953f-de71-4677-b235-b23868e1caac", "_uuid": "34845acfb679150a21961be303995de1606d94dd"}}, {"outputs": [], "source": ["L = len(dtrain)\n", "df_irr = dtrain[dtrain.toxic != 0]\n", "while len(dtrain) < 2*L:\n", "    dtrain = dtrain.append(df_irr, ignore_index=True)"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "59514ed9-7210-44e9-b849-5ce97b3f8c5b", "_uuid": "11a63d101990d39521447824ae565889aab6e39b"}}, {"outputs": [], "source": ["L = len(dvalid)\n", "df_irr = dvalid[dvalid.toxic != 0]\n", "while len(dvalid) < 2*L:\n", "    dvalid = dvalid.append(df_irr, ignore_index=True)"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}, {"source": ["###### Creating RNN model"], "cell_type": "markdown", "metadata": {}}, {"outputs": [], "source": ["A = Input(shape=[MAX_LENGTH], name=\"in\")\n", "B = Embedding(MAX_TOKEN, 128)(A)\n", "C = GRU(32) (B)\n", "D = Dropout(0.6) (Dense(128, activation='relu') (C))\n", "E = Dropout(0.4) (Dense(32, activation='relu') (D))\n", "output = Dense(2, activation=\"softmax\") (E)"], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}, {"outputs": [], "source": ["model = Model(A, output)\n", "N_epoch = 1\n", "learning_rate = 0.05\n", "optimizer = SGD(learning_rate)\n", "loss = 'categorical_crossentropy'\n", "metrics = ['accuracy']\n", "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n", "model.summary()"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "852083b4-3596-43af-8616-4eed1f0049a8", "_uuid": "2efb5f0e4c0d78b190256a1bd5e1e3a0b2b0d525"}}, {"outputs": [], "source": ["train_x = pad_sequences(dtrain.input, maxlen=MAX_LENGTH)\n", "valid_x = pad_sequences(dvalid.input, maxlen=MAX_LENGTH)\n", "train_y = np_utils.to_categorical(dtrain.toxic.values, 2)\n", "valid_y = np_utils.to_categorical(dvalid.toxic.values, 2)"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "aec2217c-ccc8-41fa-93ca-eb08ca65e6bf", "_uuid": "ad72e8f5cc6867e6653590d262e2abb91c0afc22"}}, {"outputs": [], "source": ["res = model.fit(train_x, train_y, batch_size = 128, epochs = N_epoch, \n", "                verbose = 1, validation_data = (valid_x, valid_y))"], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "f6333e56-af22-4f25-9818-1d72780f7192", "_uuid": "a73f1a3596dcada7221afbbd05d1678bb6210791"}}, {"outputs": [], "source": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "file_extension": ".py", "version": "3.6.4", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat_minor": 1}