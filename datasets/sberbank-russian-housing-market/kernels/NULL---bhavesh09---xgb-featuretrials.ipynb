{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f462b3f9-98e6-864f-d0ec-adf045dd8f36"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "# Merging macro data with train and test\n",
        "train = pd.merge(train, macro, how='left', on='timestamp')\n",
        "test = pd.merge(test, macro, how='left', on='timestamp')\n",
        "\n",
        "train = train[train.price_doc/train.full_sq <= 600000]\n",
        "train = train[train.price_doc/train.full_sq >= 10000]\n",
        "\n",
        "# store it as Y\n",
        "Y_train = train[\"price_doc\"]\n",
        "# Dropping price column\n",
        "train.drop(\"price_doc\", axis=1, inplace=True)\n",
        "\n",
        "# Build all_data = (train+test).join(macro)\n",
        "num_train = len(train)\n",
        "all_data = pd.concat([train, test])\n",
        "\n",
        "# Add month-year\n",
        "month_year = (all_data.timestamp.dt.month + all_data.timestamp.dt.year * 100)\n",
        "month_year_cnt_map = month_year.value_counts().to_dict()\n",
        "all_data['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
        "\n",
        "# Add week-year count\n",
        "week_year = (all_data.timestamp.dt.weekofyear + all_data.timestamp.dt.year * 100)\n",
        "week_year_cnt_map = week_year.value_counts().to_dict()\n",
        "all_data['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
        "\n",
        "# Creating Apartment Name Feature\n",
        "all_data['apartment_name'] = pd.factorize(all_data.sub_area + all_data['metro_km_avto'].astype(str))[0]\n",
        "\n",
        "#cleaning of full_sq\n",
        "all_data.loc[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data[\"life_sq\"]>=6) & (all_data[\"life_sq\"]<300) & ((all_data[\"full_sq\"]>= all_data[\"life_sq\"]*15) | ((all_data[\"full_sq\"]>=0) & (all_data[\"full_sq\"]<all_data[\"life_sq\"]))),\"full_sq\"]=all_data[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data[\"life_sq\"]>=6) & (all_data[\"life_sq\"]<300) & ((all_data[\"full_sq\"]>= all_data[\"life_sq\"]*15) | ((all_data[\"full_sq\"]>=0) & (all_data[\"full_sq\"]<all_data[\"life_sq\"])))].life_sq\n",
        "g_Apartment_col=all_data.groupby('apartment_name')['full_sq'].agg(['mean','median','count']).reset_index()\n",
        "g_Apartment_col.columns= ['apartment_name','full_sq_mean','full_sq_median','apartment_count'] \n",
        "all_data=all_data.merge(g_Apartment_col, how='left')\n",
        "all_data.loc[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data.apartment_count>3),\"full_sq\"]=all_data[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data.apartment_count>3)].full_sq_mean\n",
        "\n",
        "# Other feature engineering\n",
        "all_data['rel_floor'] = all_data['floor'] / all_data['max_floor'].astype(float)\n",
        "all_data['rel_kitch_sq'] = all_data['kitch_sq'] / all_data['full_sq'].astype(float)\n",
        "\n",
        "# Remove timestamp column (may overfit the model in train)\n",
        "all_data.drop(['timestamp'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e81a3525-ea41-fb70-6d31-ff04105465d8"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing \n",
        "#convert objects / non-numeric data types into numeric\n",
        "for f in all_data.columns:\n",
        "    if all_data[f].dtype=='object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(all_data[f].values)) \n",
        "        print(f)\n",
        "        all_data[f] = lbl.transform(list(all_data[f].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "511bdd93-1a60-b905-5982-d2940cf70941"
      },
      "outputs": [],
      "source": [
        "X_train = all_data[:num_train]\n",
        "X_test = all_data[num_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4baaa553-c5a6-071b-8479-5313e268d271"
      },
      "outputs": [],
      "source": [
        "df_columns = all_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "477748b9-caba-247a-c2a7-6abcdb892e26"
      },
      "outputs": [],
      "source": [
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 5,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06d29908-df1c-4289-8dbd-3b42c248706b"
      },
      "outputs": [],
      "source": [
        "dtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\n",
        "dtest = xgb.DMatrix(X_test, feature_names=df_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a648034b-e49a-79a7-e899-59960954ab34"
      },
      "outputs": [],
      "source": [
        "cv_result = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
        "    verbose_eval=20, show_stdv=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d443e935-3860-3e58-4027-6ae707332f68"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds = len(cv_result)\n",
        "cv_result[['train-rmse-mean', 'test-rmse-mean']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6ac6361f-69a8-be36-62eb-5b7585edf488"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds # 386"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5234cabb-861b-9f10-1e79-ef4ace65d335"
      },
      "outputs": [],
      "source": [
        "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2e13b55-fe14-f8cd-d8c3-c2dc4939eb2f"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(8, 16))\n",
        "xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a2af4a4-6ef4-f2ac-4a77-326b7cd16d05"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(dtest)\n",
        "\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
        "\n",
        "df_sub.to_csv('subxgb.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}