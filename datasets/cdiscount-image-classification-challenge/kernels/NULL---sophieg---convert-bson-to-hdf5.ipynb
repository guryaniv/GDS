{"nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["## This Notebook is under construction\n"], "metadata": {"_uuid": "49517ca4c5a4c1c2932b337c0b022ee59ff8fa67", "_cell_guid": "1f4a05e4-6349-46cc-8a94-783cf808b1ca"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import bson\n", "import h5py\n", "import os\n", "import tables ##enables hdf tables\n", "from multiprocessing import pool\n", "import concurrent.futures as threading\n", "import cv2 #opencv helpful for storing image as array\n", "import itertools #helps in parallel processing\n", "from matplotlib.colors import ListedColormap\n", "import scipy as scp\n", "import scipy.sparse as sparse\n", "import matplotlib.pyplot as plt\n", "import time\n", "import xarray as xr"], "metadata": {"collapsed": true, "_uuid": "69d2f60ea815912daec71effa42a470c6074a258", "_cell_guid": "e4247924-275c-40c5-b1e2-d99c3628ff5c"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["path = '../input/'\n", "# path='./'\n", "!ls \"$path\""], "metadata": {"_uuid": "f4819fe071e35294188487b0ca4581773b3943ab", "_cell_guid": "bc577e0e-1ebf-4895-a22c-9fb85d2c7460"}}, {"cell_type": "markdown", "source": ["###### Get specific chunk of data"], "metadata": {"_uuid": "f62a704948acce2a0f14a4beb6d27517b406c1a9", "_cell_guid": "482ee4fd-aaeb-426b-b0a1-4cdee60cec56"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["def read_data(bfile,itr_number,CHUNK_SIZE,demo=False):\n", "    \"\"\"\n", "    INPUTS:\n", "    -------------\n", "    bfile: bson file\n", "    itr_number: the location of the data to be read\n", "    CHUNK_SIZE: size of data to be read\n", "    demo: boolean when True :get dataframe before applying ravel to imgs\n", "    \n", "    OUTPUT  df:\n", "    -----------------\n", "    when demo = True \n", "    df is a pandas DataFrme with  multi-index ['category_id','_id','img-num','imgs']\n", "    and dtypes = {'category_id': int64,\n", "                    '_id': int64,\n", "                    'img-num': int64,\n", "                    'imgs': ndarray of dtype np.uint8 and dimension(180,180,3)}\n", "    when demo =False\n", "    df is a Data with multindex ['category_id','_id','img-num'] and \n", "    columns [0, 180*180*3-1] the result of applying ravel_img\n", "    \n", "    Example use:\n", "    -----------------\n", "    read_data ('{}train.bson'.format(path),0,100)\n", "    \n", "    \"\"\"\n", "    t0 = time.time()\n", "    print('Thread {} starting .....\\n'.format(itr_number))\n", "\n", "    with open(bfile,'rb') as b:\n", "        iterator = bson.decode_file_iter(b)\n", "        df = pd.DataFrame(list(itertools.islice(iterator,\n", "                                                itr_number*CHUNK_SIZE,\n", "                                                (itr_number+1)*CHUNK_SIZE)))\n", "    #flatten all pictures\n", "    df = df.set_index(['category_id','_id'])['imgs'].apply(\n", "    pd.Series).stack().apply(\n", "        lambda dct:dct['picture']).reset_index().rename(\n", "        columns={0:'imgs','level_2':'img-num'})\n", "    if demo:\n", "        df['imgs'] = df['imgs'].apply(\n", "            lambda d: cv2.imdecode(np.fromstring(d, dtype='uint8'),cv2.IMREAD_COLOR))\n", "    else:\n", "        df['imgs'] = df['imgs'].apply(\n", "            lambda d: ravel_img(cv2.imdecode(np.fromstring(d, dtype='uint8'),cv2.IMREAD_COLOR)))\n", "        df = df.set_index(['category_id','_id','img-num'])['imgs'].apply(pd.Series)\n", "    print('Thread {} read and processed Time: {:.2f}\\n'.format(itr_number,time.time()-t0))\n", "    \n", "    return df\n", "    "], "metadata": {"collapsed": true, "_uuid": "f31ea0276245fb895a85ccbe13bf59e0dbb1a07b", "_cell_guid": "5b3ffae1-d295-4350-a499-25c69e1b66a1"}}, {"cell_type": "markdown", "source": ["## Flatten Image\n", "##### image converted to 1d for storage using the function `ravel_image`\n", "#### the process is reveresed using `unravel_image`"], "metadata": {"_uuid": "cd0237725b1e43f7365fdabbfa12168513d39e46", "_cell_guid": "7539fe89-d130-4d1b-a2fe-8c67c964d256"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["def ravel_img(A):\n", "    \"\"\"\n", "    #input array is 3d \n", "    #output array 1d\n", "    \"\"\"\n", "    return scp.hstack([A[:,:,i].flatten() for i in range(3)])\n", "def unravel_img(A):\n", "    \"\"\"\n", "    reverse ravel_img on array\n", "    input is 1d array\n", "    output is 3d array\n", "    \"\"\"\n", "    return scp.dstack([ch.reshape(180,-1)for ch in scp.hsplit(A,3)])"], "metadata": {"collapsed": true, "_uuid": "1fceb1f55e236c76d15739f8b68610d6ea591e57", "_cell_guid": "614fc86c-9814-4861-9367-2595ffdc88b5"}}, {"cell_type": "markdown", "source": ["#### Test the functions"], "metadata": {"_uuid": "6d2abcbb73b791bb7461b3c3c0d397fb1e444d35", "_cell_guid": "3bb55e8b-bed7-4093-ba7a-2b004bda0a16"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["fig,axs = plt.subplots(1,2)\n", "axs= axs.flatten()\n", "df = read_data('{}train.bson'.format(path),944560,1,demo=True)\n", "a = df.iloc[0,-1]\n", "b = ravel_img(a)\n", "axs[0].imshow(a)\n", "axs[0].set_title('Original Image')\n", "axs[1].imshow(unravel_img(b))\n", "axs[1].set_title('Retrieved Image')\n", "for ax in axs:\n", "    ax.set_xticks([])\n", "    ax.set_yticks([])\n", "plt.show()"], "metadata": {"_uuid": "977767036ab4897653f5e55041de7d009ead56d9", "_cell_guid": "d5f84a6b-0e90-40a9-8966-b34b3af8ee2b"}}, {"cell_type": "markdown", "source": ["#### Count the number of images in train.bson"], "metadata": {"_uuid": "ba22d6d5434c5978bc309717a84097d48a258b40", "_cell_guid": "252606be-619f-4f79-8f85-8965a315513f"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["# path = ''\n", "# counter = 0 \n", "# imgs = 0\n", "# with open('{}train.bson'.format(path),'rb') as b:\n", "#         iterator = bson.decode_file_iter(b)\n", "#         for d in iterator:\n", "            \n", "#             if 'category_id' not in d.keys():\n", "#                 break\n", "#             imgs += len(d['imgs'])\n", "#             counter += 1\n", "\n", "##output imgs = 12371293\n", "##counter = 7069896"], "metadata": {"collapsed": true, "_uuid": "38385d30308672f713ff0f217c3e4e9770140e90", "_cell_guid": "c922655f-1739-46ea-a294-284960e2c2f0"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["\n", "def process_th (bfile,itr_number,CHUNK_SIZE,file,key):\n", "    \"\"\"\n", "   \n", "    INPUTS:\n", "    -------------\n", "    bfile: bson file\n", "    itr_number: the location of the data to be read\n", "    CHUNK_SIZE: size of data to be read\n", "    file: output hdf file \n", "    key: name of dataset in output hdf file\n", "    OUTPUT  df:\n", "    -----------------\n", "    tuple (itr_number, success)\n", "    itr_number is the input itr_number this can be used to find failed chunks \n", "    success: True when writing the data is successful\n", "    False otherwise\n", "    Example use:\n", "    -----------------\n", "    process_th ('{}train.bson'.format(path),0,100,'train.h5','train')\n", "    \"\"\"\n", "    t0 = time.time()\n", "    print('Thread {} writing .....\\n'.format(itr_number))\n", "    \n", "    df = read_data(bfile,itr_number,CHUNK_SIZE)\n", "    try:\n", "        \n", "        hdf = h5py.File(file)\n", "        if key not in hdf.keys():\n", "            train = hdf.create_dataset(key, (12371293, 180*180*3),dtype='i1')\n", "        hdf.close()\n", "        hdf = pd.HDFStore(file)\n", "        hdf[key] = df\n", "        hdf.close()\n", "        print('Thread {} finished writing Time: {:.2f}\\n'.format(itr_number,time.time()-t0))\n", "        return (itr_number,True)\n", "    except Exception as e:\n", "        print('Thread {} Writing Failed.'.format(itr_number))\n", "        print('\\n error: {} \\n Time: {:.2f}\\n'.format(e,time.time()-t0))\n", "        return (itr_number,False)\n", "\n", "# process_th (bfile,itr_number,CHUNK_SIZE,'train.h5','train')"], "metadata": {"collapsed": true, "_uuid": "cb086c0af084e26844d70df7a41f6b436becdc7e", "_cell_guid": "d602f51d-bed2-4708-aa37-65a2d38b8c1b"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["n=1#adjust based on number of CPU cores\n", "CHUNK_SIZE=1000 #adjust value according to your resources\n", "REC_SIZE = 7069896\n", "#number of chuncks is the ceiling of record size dvided by chunck size\n", "NUM_CHUNK = 1 +(REC_SIZE//CHUNK_SIZE) \n", "print('total chunks: {}\\n\\n'.format(NUM_CHUNK))\n", "bfile = '{}{}'.format(path,'train.bson')\n", "file = 'train.h5'\n", "key = 'train'\n", "t0 = time.time()\n", "with threading.ThreadPoolExecutor(max_workers = n) as exec:\n", "    #all chuncks\n", "\n", "    futures = {exec.submit(process_th, bfile,i,CHUNK_SIZE,file,key) for i in range(0,5)}\n", "    \n", "res = [f.result() for f in threading.as_completed(futures)]\n", "print('total time: {:.2f}'.format(time.time()-t0))\n"], "metadata": {"collapsed": true, "_uuid": "bdbd4f063adbee52672ffe066275d5edffa7e241", "_cell_guid": "aa06fd68-0454-4c7f-b924-8c279447f859", "scrolled": true}}, {"cell_type": "markdown", "source": ["## read data"], "metadata": {"collapsed": true, "_uuid": "5432f7867604c349a4108703a3a2bf7c1bb35012", "_cell_guid": "60ecb4d4-9e63-4fda-aa3f-b04ff58594d9"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["hdf = pd.HDFStore(file)\n", "df = hdf[key]\n", "hdf.close()"], "metadata": {"collapsed": true, "_uuid": "cb14d1b530651c5259d97014f01ac6531a64a210", "_cell_guid": "9a1a4afb-2ff6-40a0-aaf2-13cdb1f936bd"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["df.info()"], "metadata": {"collapsed": true, "_uuid": "68ef38a641b919d8a9d2f3ddff3a488b710bda4c", "_cell_guid": "04d79d55-bc4a-4603-870b-a19c9ca709ac"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["df['imgs'] = list(map(unravel_img,df.values))\n", "df = df['imgs']"], "metadata": {"collapsed": true, "_uuid": "730abefd56e17dca5e3f3abc98ad448de5001ad2", "_cell_guid": "5777258f-0159-4b6c-ac04-6b6861e1962b"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["df.head()"], "metadata": {"collapsed": true, "_uuid": "930ae3635fab7c53c49b622c4a7377e5ca02504f", "_cell_guid": "5e4b156e-bc7e-4881-9ea9-9066fb5a02f8"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["plt.imshow(df.iloc[-1])\n", "plt.show()"], "metadata": {"collapsed": true, "_uuid": "d988b0853c5038d474cc400f812ea5c197c55e50", "_cell_guid": "d854a694-2401-44c0-8826-80b5547b973a"}}, {"cell_type": "markdown", "source": ["### On disk processing"], "metadata": {"collapsed": true, "_uuid": "563c781da0871d3000b91e37364e3e457fec6a50", "_cell_guid": "7d018211-6623-4be4-a3fd-396188d0d357"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["#Toddo"], "metadata": {"collapsed": true, "_uuid": "f1fb0440ecee051f2de2742a90545081a660516a", "_cell_guid": "419ac8e6-86fc-467d-bb4b-91e1d076fd22"}}, {"cell_type": "markdown", "source": ["#### Quering the data in hdf file"], "metadata": {}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["##todo"], "metadata": {"collapsed": true}}], "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "file_extension": ".py", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "name": "python", "nbconvert_exporter": "python"}}}