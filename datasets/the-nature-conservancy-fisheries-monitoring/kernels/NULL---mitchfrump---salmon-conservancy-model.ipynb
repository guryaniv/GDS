{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a0490e4-3294-f4d3-749a-0152f8e20a21"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e1f0213d-aa69-fd7e-a882-988ff2199fcd"
      },
      "source": [
        "The first step is to build tensor representations of all of the images with labels. This should be straightforward, but it's memory intensive which is causing problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9c3d294a-8637-8475-0aef-53938e625e04"
      },
      "outputs": [],
      "source": [
        "import matplotlib.image as mim\n",
        "import resource\n",
        "\n",
        "df = {\"image\":[],\"species\":[]}\n",
        "\n",
        "# Doing this directly exceeds memory limits. Not 100% sure how to (a) measure this, (b) work around it.\n",
        "# Could possibly build the dataframe one species at a time, then save them to CSV and merge them.\n",
        "# However it would be nice to be able to use all the data in training...\n",
        "\n",
        "for folder in check_output([\"ls\", \"../input/train\"]).decode(\"utf8\").split('\\n'):\n",
        "    print(folder)\n",
        "    contents = check_output([\"ls\", \"../input/train/\"+folder]).decode(\"utf8\").split('\\n')[:10]\n",
        "    for image in contents:\n",
        "        if image[-4:]!='.jpg':\n",
        "#            print(resource.getrusage(resource.RUSAGE_SELF)[2]*resource.getpagesize()/1000000.0)\n",
        "            continue\n",
        "        df['image'].append(mim.imread(\"../input/train/\"+folder+'/'+image))\n",
        "        df['species'].append(folder)\n",
        "    del contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2342f026-212c-4dab-a9e3-e176f197927e"
      },
      "outputs": [],
      "source": [
        "max0 = 0\n",
        "max1 = 0\n",
        "\n",
        "for x in df[\"image\"]:\n",
        "    sh = x.shape\n",
        "    if sh[0]>max0:\n",
        "        max0 = sh[0]\n",
        "    if sh[1]>max1:\n",
        "        max1 = sh[1]\n",
        "   \n",
        "print(\"The biggest image dimensions seen were:\",max0,max1)\n",
        "\n",
        "from scipy.stats import describe\n",
        "avs = []\n",
        "for x in df[\"image\"]:\n",
        "    avs.append(np.mean(x))\n",
        "print(\"The average brightness among all images was:\",np.mean(avs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8c77a065-e016-0519-b7f2-6e78b798bbd3"
      },
      "source": [
        "The next step will be to clean up the images with a couple basic steps: adjusting brightness, and filling them out with gray to be a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "71730cf7-a655-b19e-5d56-b70b3bb59f05"
      },
      "outputs": [],
      "source": [
        "def normalize(image,newshape=(974,1732,3)):\n",
        "    '''Takes in an image array of shape (x,y,3)\n",
        "    @returns an image array of shape (974,1732,3) with average unraveled value 0\n",
        "    by subtracting averages, and either extending with zeroes or cropping'''\n",
        "    shape = image.shape\n",
        "    if shape[0]>newshape[0]:\n",
        "        image = image[:newshape[0],:,:]\n",
        "    if shape[1]>newshape[1]:\n",
        "        image = image[:,:newshape[1],:]\n",
        "    image = image - np.mean(image,axis=None)\n",
        "    newimage = np.zeros(newshape)\n",
        "    newimage[:image.shape[0],:image.shape[1],:] = image\n",
        "    return newimage\n",
        "\n",
        "test = df[\"image\"][0]\n",
        "print(describe(np.reshape(test,(-1,3))))\n",
        "res = normalize(test)\n",
        "print(describe(np.reshape(res,(-1,3))))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be5bb0f6-7241-19d9-e7c9-60a92f65acb3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array([normalize(x) for x in df[\"image\"]])\n",
        "y = df[\"species\"]\n",
        "del df\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "enc = LabelEncoder()\n",
        "enc.fit(y)\n",
        "y = enc.transform(y)\n",
        "\n",
        "train_dataset, valid_dataset, train_labels, valid_labels = train_test_split(X,y,stratify=y)\n",
        "\n",
        "image_h = 974\n",
        "image_w = 1732\n",
        "num_labels = 8\n",
        "num_channels = 1 # grayscale\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def reformat(dataset, labels):\n",
        "  dataset = dataset.reshape(\n",
        "    (-1, image_h, image_w, num_channels)).astype(np.float32)\n",
        "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
        "  return dataset, labels\n",
        "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
        "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
        "#test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
        "print('Training set', train_dataset.shape, train_labels.shape)\n",
        "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "#print('Test set', test_dataset.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "533d15a1-62b5-962f-71fb-6a332e295169"
      },
      "outputs": [],
      "source": [
        "#Sample code from here:\n",
        "# http://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/\n",
        "\n",
        "# import the necessary packages\n",
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        " \n",
        "# construct the argument parser and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-i\", \"--image\", required = True, help = \"Path to the image\")\n",
        "#args = vars(ap.parse_args())\n",
        " \n",
        "# load the image and convert it to a floating point data type\n",
        "image = img_as_float(io.imread(\"../input/train/ALB/img_00003.jpg\")) #img_as_float(io.imread(args[\"image\"]))\n",
        " \n",
        "# loop over the number of segments\n",
        "for numSegments in (10, 30, 80):\n",
        "\t# apply SLIC and extract (approximately) the supplied number\n",
        "\t# of segments\n",
        "\tsegments = slic(image, n_segments = numSegments, sigma = 5)\n",
        " \n",
        "\t# show the output of SLIC\n",
        "\tfig = plt.figure(\"Superpixels -- %d segments\" % (numSegments))\n",
        "\tax = fig.add_subplot(1, 1, 1)\n",
        "\tax.imshow(mark_boundaries(image, segments))\n",
        "\tplt.axis(\"off\")\n",
        " \n",
        "# show the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e8db9043-ff88-d757-d76c-2fced6df7be6"
      },
      "source": [
        "There are two options for sort of \"feature engineering\" I would like to pursue, ideally in parallel.\n",
        "\n",
        "The first is to separate the images into superpixels, and then be able to isolate only the fish-like parts. One way of doing this would be to feed each superpixel block into a trained AlexNET and see which is classified as fish. This is a bulky solution, but I don't have a naively better idea.\n",
        "\n",
        "The second is to use a combination of manual and deep learning models to identify a few key features that the different fish might have. For example, length-to-width ratio, fin shape, scale colors, or facial structure. This should be easier to work out if we can identify the superpixels first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6b5c9511-8dca-a524-aaad-bc1e7fbff439"
      },
      "outputs": [],
      "source": [
        "#Sample code from here:\n",
        "# http://www.pyimagesearch.com/2014/07/28/a-slic-superpixel-tutorial-using-python/\n",
        "# The purpose of this segment is just to establish what kind of superpixels to look for\n",
        "\n",
        "# import the necessary packages\n",
        "from skimage.segmentation import slic\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from skimage.util import img_as_float\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        " \n",
        "# loop over the number of segments\n",
        "for folder in check_output([\"ls\", \"../input/train\"]).decode(\"utf8\").split('\\n'):\n",
        "    print(folder)\n",
        "    contents = check_output([\"ls\", \"../input/train/\"+folder]).decode(\"utf8\").split('\\n')[:2]\n",
        "    for imfile in contents:\n",
        "        # load the image and convert it to a floating point data type\n",
        "        if imfile[-4:]!='.jpg':\n",
        "            continue\n",
        "        image = img_as_float(io.imread(\"../input/train/\"+folder+\"/\"+imfile))\n",
        "        for numSegments in (10, 30, 50):\n",
        "\t        # apply SLIC and extract (approximately) the supplied number\n",
        "\t        # of segments\n",
        "\t        segments = slic(image, n_segments = numSegments, sigma = 5)\n",
        "     \n",
        "\t        # show the output of SLIC\n",
        "\t        fig = plt.figure(\"Superpixels -- %d segments\" % (numSegments))\n",
        "\t        ax = fig.add_subplot(1, 1, 1)\n",
        "\t        ax.imshow(mark_boundaries(image, segments))\n",
        "\t        plt.axis(\"off\")\n",
        " \n",
        "    # show the plots\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7bc49e16-3676-137c-d1b7-1d72f200d9d0"
      },
      "source": [
        "Finally we can build a model. I would like to build two models based on the two sets of engineered features above.\n",
        "\n",
        "To process the images, I will build a convolutional neural net to train as a classifier on the dataset. There's plenty of data and convolutional models are great for image processing, so this should be an effective model on its own.\n",
        "\n",
        "Additionally, I'll build a simpler (perhaps naive bayes?) model based on the extracted numerical features. This should both give us a way of being more or less confident of our future predictions, as well as giving a simple explanation for what sorts of features might make a picture difficult to classify. \n",
        "\n",
        "These two models can then be combined in whatever way works out to be effective to get the final classification system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3783e6a2-03fe-50fe-056c-c352ec79b126"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff73c0b0-facb-fd3b-78d9-131d88563ab3"
      },
      "outputs": [],
      "source": [
        "image_h = 974\n",
        "image_w = 1732\n",
        "num_labels = 8\n",
        "num_channels = 1 # grayscale\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def reformat(dataset, labels):\n",
        "  dataset = dataset.reshape(\n",
        "    (-1, image_h, image_w, num_channels)).astype(np.float32)\n",
        "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
        "  return dataset, labels\n",
        "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
        "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
        "#test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
        "print('Training set', train_dataset.shape, train_labels.shape)\n",
        "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
        "#print('Test set', test_dataset.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85543f56-7a6c-b3ad-0212-e93cea258c3d"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}