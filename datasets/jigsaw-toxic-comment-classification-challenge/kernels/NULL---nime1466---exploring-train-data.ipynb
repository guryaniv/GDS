{"cells": [{"source": ["# This notebook is for basic exploration of the training data. The purpose is mainly to demonstrate some simple features of Pandas, such as assign() and eval(), as well as the corr() function. Since this dataset does not have many feature columns, there aren't too many things to be done here."], "metadata": {"_uuid": "2e8720d7e8a8468ccb0a8aa76abbaf3609f5f347", "_cell_guid": "aa8a48ec-12e2-4c42-9a45-fbb9d1714213"}, "cell_type": "markdown"}, {"source": ["## Basic imports we'll need"], "metadata": {"_uuid": "e59593ecb58e150f523f972937aeb7cc674f7d71", "_cell_guid": "349a5cd6-2e41-4631-ae62-5117b8794b31"}, "cell_type": "markdown"}, {"source": ["import re\n", "\n", "import pandas as pd"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "b838dc7b1a37f7c1fb6286acf82d28aeaf36ad28", "_cell_guid": "90715136-b30e-4a83-825b-aa5511d72022"}, "cell_type": "code"}, {"source": ["## Read in the train data as a Pandas DataFrame and then find some basic info. In order to run this notebook, you'll need the train.csv file in the same directory"], "metadata": {"_uuid": "d7c59621bb0209405cba7491b2d983f405835344", "_cell_guid": "89ff6379-814a-44e3-9c09-0680c69126cb"}, "cell_type": "markdown"}, {"source": ["train_data = pd.read_csv('../input/train.csv')"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "e78fc0e563e2fd1208b0a338e37adcb263668072", "_cell_guid": "ca2ccb1b-811e-48c3-bdb5-cc9c00d05804"}, "cell_type": "code"}, {"source": ["train_data.info()"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "e000ec1514b7bef56c66a86221d50f08c63e206c", "_cell_guid": "6e4df634-de74-4c71-ad89-62fd7d778936"}, "cell_type": "code"}, {"source": ["train_data[0:5]"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "7734847f476c3acf32639c0fc5e47320e432417d", "_cell_guid": "3b2e13c0-465b-4efa-90ae-5bca6beacdd5"}, "cell_type": "code"}, {"source": ["label_columns = [x for x in train_data.columns if x not in['id', 'comment_text']]"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "befd168476a47c4a5d24cb692ab5aa69b381850d", "_cell_guid": "ba9b56c9-962c-4053-93c1-d7852919c2e2"}, "cell_type": "code"}, {"source": ["## Let's check out the distribution of the labels"], "metadata": {"_uuid": "d41e5e6667573db418896706e759c4f30d844b05", "_cell_guid": "af2e0bd6-469d-4484-97f5-971d645d479b"}, "cell_type": "markdown"}, {"source": ["for label in label_columns:\n", "    print(f\"Count for {label}: {train_data[label].sum()/95851}\")"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "b678ee1a1b95eb27afffc77ca40bf9fa2dbd502f", "_cell_guid": "f6fc7ccd-a0fc-4715-879b-2842b271e39b"}, "cell_type": "code"}, {"source": ["## Define a function to apply to the comment_text column to strip punctuation."], "metadata": {"_uuid": "f56dd0b56faac76dda4cd6e2ccba9bce1962bae8", "_cell_guid": "9ecd8e8f-cf46-4751-851a-0b3daf627c2f"}, "cell_type": "markdown"}, {"source": ["def remove_punctuation(row_str):\n", "    return re.sub(r\"\\W\", \" \", row_str)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "ec248321c0a015270c4b7f1cd89d7beb3c27e395", "_cell_guid": "c47d7ba5-a432-4e08-9495-e63da30a8cac"}, "cell_type": "code"}, {"source": ["## Now apply this function to comment_text and observe the result"], "metadata": {"_uuid": "22f12a148eff7da4389df22dfb46813f08463f74", "_cell_guid": "938d6e6d-9bbe-4e7a-9cd9-c922530d6827"}, "cell_type": "markdown"}, {"source": ["train_data = train_data.assign(comment_text=train_data.comment_text.apply(remove_punctuation))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "75c471d09da2ed13763574e969ea1c23332aeb60", "_cell_guid": "184d4060-3613-4afd-ab41-ea7b84212e20"}, "cell_type": "code"}, {"source": ["train_data[0:10]"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "f1a67ace6a5ce0e978c496d031862579f1b0009b", "_cell_guid": "40b19c51-34a7-4aeb-a0b6-857f88d8ca1d"}, "cell_type": "code"}, {"source": ["## Create a new column that stores the lengths of the comment_text column"], "metadata": {"_uuid": "8adc4ef2ad6eaccc9880ee73578c951cb709e5bf", "_cell_guid": "befb2a2e-aea5-495d-9a68-dc32e77e686d"}, "cell_type": "markdown"}, {"source": ["train_data = train_data.assign(comment_len=train_data.comment_text.str.len())"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "e18c502faabab8c4d234e66241171895a651bd13", "_cell_guid": "472d8d0b-5255-40d7-8585-345d7b5d5702"}, "cell_type": "code"}, {"source": ["## Let's explore the distibution of lengths of comments."], "metadata": {"_uuid": "c7e8cca26a98d43cdd9867e521a71a6508856940", "_cell_guid": "2b5a74d7-7711-4024-ad97-9a47ca316bd4"}, "cell_type": "markdown"}, {"source": ["deciles = [x/10.0 for x in range(1, 10)]\n", "train_data.comment_len.describe(percentiles=deciles)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "dfc367f88050b0c17de4c12e79ddd04dc4c8008c", "_cell_guid": "3b05d855-ea47-4fc0-a0d5-c59cbc8dc23e"}, "cell_type": "code"}, {"source": ["## Could there be a relationship between the length of a comment and its label?"], "metadata": {"_uuid": "118756a2ba30bd758e087be315f82ef74570c7e0", "_cell_guid": "a16268f7-cea4-4943-9893-a3a0a6996076"}, "cell_type": "markdown"}, {"source": ["for label in label_columns:\n", "    print(\"Correlation with comment length for {}: {}\".format(label, train_data[label].corr(train_data.comment_len)))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "412920250ae037317fee71fc37a837c876cfa00a", "_cell_guid": "6e1c5fe6-a245-4a51-9a18-a8fbbbf22625"}, "cell_type": "code"}, {"source": ["## What if we considered the number of words instead of characters?"], "metadata": {"_uuid": "2ada3d5d850857fa628411d9e07b96499e7ecdc7", "_cell_guid": "225411ec-30e8-405a-bdf9-da31b52e213d"}, "cell_type": "markdown"}, {"source": ["## There are two ways we can do this. An absolute word count, and the number of unique words. We'll start with an absolute word count"], "metadata": {"_uuid": "c392b2d4ba1b4f2d6c8ec116158c410e521b119f", "_cell_guid": "ff5fbb5f-f207-4373-bb4c-5674fb8072cc"}, "cell_type": "markdown"}, {"source": ["### Define a function to find the number of words in comment_text"], "metadata": {"_uuid": "a8a67a699d32c7373fffb381de6ea1376334a2b6", "_cell_guid": "f1e69838-079d-434e-95d7-6631735119f4"}, "cell_type": "markdown"}, {"source": ["def get_num_words(row_str):\n", "    return len(row_str.split())"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "bdc03924d57bdcb0ba3ff3edd6499a23761108c9", "_cell_guid": "70a6f890-367e-4d71-8d78-13838b8b97e4"}, "cell_type": "code"}, {"source": ["## Create the new column"], "metadata": {"_uuid": "c44d953164e386b18eff45a4f810fa1ade63c27a", "_cell_guid": "67af5fa7-081b-44a5-bc75-263ec44a85a7"}, "cell_type": "markdown"}, {"source": ["train_data = train_data.assign(num_words=train_data.comment_text.apply(get_num_words))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "6bdd0d794577a0a2f84e7a1954607956ee90cfa4", "_cell_guid": "cb20b653-c2e9-46aa-b47b-5c79d4e94f4e"}, "cell_type": "code"}, {"source": ["### And look at the distribution of word counts"], "metadata": {"_uuid": "2d8fa23c74544d5f01300a3cbb46ef271c82c8ae", "_cell_guid": "d8125b13-2a7a-480a-905a-ed5988e36da1"}, "cell_type": "markdown"}, {"source": ["train_data.num_words.describe(percentiles=deciles)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "3e28ca900a6645eedc9b8e50a477288790ce4a93", "_cell_guid": "ba7b4258-da94-45ef-8879-a7324d9fc0f4"}, "cell_type": "code"}, {"source": ["### Now do the same thing with number of unique words"], "metadata": {"_uuid": "c9076f476e5fbcab64ce1460c76be1274e7955d5", "_cell_guid": "5403f917-06b8-4f5f-9a91-57cbe634de6f"}, "cell_type": "markdown"}, {"source": ["### First, let's define a function to apply to the comment_text column to calculate the number of unique words"], "metadata": {"_uuid": "c63ac5ba4f24bd61808d3abfab98f7467a3865b1", "_cell_guid": "81eca544-01f6-4334-b782-4f09ba08153e"}, "cell_type": "markdown"}, {"source": ["def get_unique_words(row_str):\n", "    return len(set(row_str.lower().split()))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "7783b4126d962627b99ed3ff1656147f59c0f33d", "_cell_guid": "8424185c-c536-4db8-876d-fa264a0b9349"}, "cell_type": "code"}, {"source": ["### Now let's create that column"], "metadata": {"_uuid": "536974b2b0126afc4ea0272c69c8619d5e4282a8", "_cell_guid": "916d8d28-b181-436b-b1c2-a9702ede9e46"}, "cell_type": "markdown"}, {"source": ["train_data = train_data.assign(unique_words=train_data.comment_text.apply(get_unique_words))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "da88a5d180b7f6cd8bedb1bba73b991e1db4d9d4", "_cell_guid": "ae086a2f-0ea5-46b6-b602-5ec55023c81f"}, "cell_type": "code"}, {"source": ["### What does the distribution of unique words look like?"], "metadata": {"_uuid": "578e13abd57d249c197419a2d2eef9136df72b75", "_cell_guid": "aeea35d3-ba31-4046-a1cf-cab33a7f56f2"}, "cell_type": "markdown"}, {"source": ["train_data.unique_words.describe(percentiles=deciles)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "7ce63205b7aa334d3f6cfc663c88b4a591a1b670", "_cell_guid": "8a90c690-9cea-4854-a785-9ffe00578c4c"}, "cell_type": "code"}, {"source": ["### Finally, investigate the relationship between word counts and labels"], "metadata": {"_uuid": "366586d57358e79407ed4b08456118eb60de495a", "_cell_guid": "a954c89a-7985-4083-a3c9-cdc4465cda64"}, "cell_type": "markdown"}, {"source": ["for label in label_columns:\n", "    print(\"Correlation with number of words for {}: {}\".format(label, train_data[label].corr(train_data.num_words)))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "99100bb160c34fb1da0b8366b7cf775646bbd117", "_cell_guid": "bd6cacd9-1324-4d5c-9b31-d790581692d7"}, "cell_type": "code"}, {"source": ["for label in label_columns:\n", "    print(\"Correlation with unique words for {}: {}\".format(label, train_data[label].corr(train_data.unique_words)))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "0db4e45ad5d3ff968d6598037b3397b1a215562a", "_cell_guid": "65895265-7bc9-465c-8490-bab83adac90c"}, "cell_type": "code"}, {"source": ["## One more thing would be to look at mean word length"], "metadata": {"_uuid": "d2de799cd2c15cc5323e31769bb5f9b2468102a8", "_cell_guid": "558c0613-ed28-4d14-a91d-2237c4a56ac0"}, "cell_type": "markdown"}, {"source": ["train_data.eval('mean_word_length = comment_len/num_words', inplace=True)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "d138aa684c72077987463cac084571cd709d9f87", "_cell_guid": "eed05478-8115-4e5d-aa2a-5127ce01ead0"}, "cell_type": "code"}, {"source": ["## Once again, checkout the distribution of mean word length values"], "metadata": {"_uuid": "cc4f18d28eca5aa8a94bff2e7b52f34a3cb18565", "_cell_guid": "f27cf809-2cdc-4e92-8eac-b42665bbde96"}, "cell_type": "markdown"}, {"source": ["train_data.mean_word_length.describe(percentiles=deciles)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "4af5e75ab3b7dd1dc5b384309b22dd2c57a1ae43", "_cell_guid": "bbb067c2-a9e9-416a-bea7-ca1d4b57d291"}, "cell_type": "code"}, {"source": ["## There is an obvious outlier given that the max mean word length is three orders of magnitude greater than the 99th Percentile"], "metadata": {"_uuid": "e975c2a7182e588d1622cfca1efbc32102f58da4", "_cell_guid": "216203b2-fcd3-4813-8c08-dfb24bb7c117"}, "cell_type": "markdown"}, {"source": ["train_data.mean_word_length.quantile(0.99)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "08ce2b5652d2858971dde9765588b98dae9463ae", "_cell_guid": "690e26d7-9cbe-46c7-921f-d6ea45b80191"}, "cell_type": "code"}, {"source": ["## Any possible correlations between mean word length and label?"], "metadata": {"_uuid": "ced72a4575b3b410c927a39bbef67d883216c812", "_cell_guid": "943ca52a-4b3a-45fc-bf5b-1028c7b84f72"}, "cell_type": "markdown"}, {"source": ["for label in label_columns:\n", "    print(\"Correlation with unique words for {}: {}\".format(label, train_data[label].corr(train_data.mean_word_length)))"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "9d9c3b2da121e827f01d8830bde625c52e6e3494", "_cell_guid": "48cbb76e-ec5d-4d61-a2ad-3254c1063c82"}, "cell_type": "code"}, {"source": ["# In summary, there weren't any obvious connections between various basic string metrics and the label. Using some real NLP techniques such as POS tagging, semantic analysis, and removal of stop words could yield interesting results"], "metadata": {"_uuid": "f44e6aca07b46652a7ba5d8e1818223d9a11bd58", "_cell_guid": "054c390b-754a-4d00-8dee-569bd1ce219f"}, "cell_type": "markdown"}, {"source": [], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "953b050b0da393bb44a2c9711737fd2b22846a3e", "_cell_guid": "6a4d628d-90b3-484e-b657-1acbf0d8b550"}, "cell_type": "code"}], "nbformat": 4, "metadata": {"language_info": {"name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.4"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}