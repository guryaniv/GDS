{"metadata": {"language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "file_extension": ".py"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "3b38ca60-d1e5-4e0b-bdf9-9b4b4c306b20", "_uuid": "916e3ca81c6e9b9edb573b73b2803862917b1586"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code"}, {"metadata": {"_cell_guid": "c183d775-71ba-4cde-9d3a-1c4e201acf55", "_uuid": "f97d85cde71d889d0e0047f54d24604156e328aa"}, "source": ["We are going to classify cats and dogs using a convolution neural network. <br>\n", "For this purpose we will first need to load our dataset, as it comprises of images. We will need to first load it as an array of pixels."], "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "e612de27-c408-4cb3-bd24-ad116245fad3", "collapsed": true, "_uuid": "51d958c6e48f0a7269370d418b6a2ccc0bd5d51f"}, "source": ["#importing dependecies to create dataset\n", "from PIL import Image\n", "import matplotlib.pyplot as plt\n", "import os\n", "import random"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "5e01ae8a-b434-4a7d-af88-eae5fe5344d9", "collapsed": true, "_uuid": "f78b9d21046ec96770440c0844ccc39fc822578e"}, "source": ["#function takes a file name and returns output label in the form of one hot vector\n", "#[0,1]=dog [1,0]=cat\n", "def output_label(l):\n", "    lb=l.split('.')[0]\n", "    #print(ar)\n", "    if str(lb)==str('cat'):\n", "        return [1,0]\n", "    else:\n", "        return [0,1]\n", "   \n", "#function below loads an image, resizes it and returns corresponding numpy array\n", "def load_image(path,width):\n", "    img=Image.open(path)\n", "    img = img.resize((width,width))  \n", "    a=np.array(img)\n", "    return a"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "2aa8d3d7-c766-404e-8be5-5d0656683b5d", "collapsed": true, "_uuid": "af00d38c19368377165d6859ef764f55dc6fb619"}, "source": ["#defining constants to be used to prepare our dataset\n", "TRAINING_PATH='../input/train'\n", "ls_train=os.listdir(TRAINING_PATH)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "643bd37a-9bee-4171-984b-e38848bd22a4", "_uuid": "b992303f40a134fb719c9414dba0fd171127d558"}, "source": ["#let's make our training set now\n", "train_set=[]\n", "i=0\n", "for s in ls_train:\n", "    train_set.append([np.array(load_image(os.path.join(TRAINING_PATH,s),64))\n", "                      ,output_label(s)])\n", "    i=i+1\n", "    if i%1000==0:\n", "        print('images processed so far',i)"], "cell_type": "code"}, {"metadata": {"_cell_guid": "23084a38-f4c5-4473-a0ef-edb84043ceb2", "_uuid": "46da10693afc7af1f51fb18558440ccd5bd4d4c4"}, "source": ["Similar to mnist we are going to follow a 3 layer cnn\n", "(conv2d+relu+maxPooling)-->(conv2D+relu+maxPooling)---> (flatten to a fully connected layer with softmax regressor)"], "cell_type": "markdown"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "680df313-338b-4f84-8a93-9c6291bc3ef8", "_uuid": "261dd7908c418659632c22217fa237b925e9c7ae"}, "source": ["import tensorflow as tf"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "9490235e-8e95-4962-be82-63acc0d7d0fd", "collapsed": true, "_uuid": "63d803076377042e96842bafcab2ca749b77c2ed"}, "source": ["#defining placeholders\n", "X=tf.placeholder(tf.float32,shape=(None,64,64,3))\n", "Y_=tf.placeholder(tf.float32,shape=[None,2]) #one hot vectors"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "f08e2114-9207-4f6c-819d-726e933bbd38", "collapsed": true, "_uuid": "6106f9da063eef43c90cd6544965114e62716aea"}, "source": ["#defining helper functions for conv2d and max_pooling\n", "def conv2d(x,W):\n", "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n", "\n", "def max_pooling(x):\n", "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "5a8ced62-43be-4538-b584-5847d0969242", "collapsed": true, "_uuid": "02eb4f95d47a1643b9e0f0c6b1b2c6506c02d7e7"}, "source": ["#defining helper functions for weights and bias\n", "def weight_variable(shape):\n", "  initial = tf.truncated_normal(shape, stddev=0.1)\n", "  return tf.Variable(initial)\n", "\n", "def bias_variable(shape):\n", "  initial = tf.constant(0.1, shape=shape)\n", "  return tf.Variable(initial)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "7c8bf232-22d7-4dde-9b84-32601356a60b", "collapsed": true, "_uuid": "11448a2ace7867646e9aa4c00a4a80cd18ccb398"}, "source": ["w1=weight_variable([5,5,3,32])\n", "b1=bias_variable([32])\n", "#now reshaping images from a image_count*784 vector to image_count*28*28*1\n", "#X_image=tf.reshape(X,[-1,28,28,1])\n", "\n", "h_conv1=tf.nn.relu(conv2d(X,w1)+b1)\n", "h_pool1=max_pooling(h_conv1)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "50f10c8f-a122-4813-9d45-2b7a6fd74d5d", "collapsed": true, "_uuid": "61d6a22d5bef68ef2dc97f5e59949f3925584350"}, "source": ["#defininf second layer of cnn\n", "w2=weight_variable([5,5,32,64])\n", "b2=bias_variable([64])\n", "h_conv2=tf.nn.relu(conv2d(h_pool1,w2)+b2)\n", "h_pool2=max_pooling(h_conv2)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "67314141-9efc-42cb-ad15-22de7133cc37", "collapsed": true, "_uuid": "46f816c3b0ea380c036b2859f217ae25406bca90"}, "source": ["h_pool_flat=tf.reshape(h_pool2,[-1,16*16*64])\n", "w3=weight_variable([16*16*64,1024])\n", "b3=bias_variable([1024])\n", "\n", "h_fc1 = tf.nn.relu(tf.matmul(h_pool_flat,w3)+b3)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "eef65cc9-07c9-4af1-9c92-c00f02741391", "collapsed": true, "_uuid": "15decf5bb49626789293afc59eb7be5cbf4df439"}, "source": ["w4=weight_variable([1024,2])\n", "b4=bias_variable([2])\n", "y_conv= tf.matmul(h_fc1,w4)+b4"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "159af907-2956-43a4-a6e5-d2953968355d", "collapsed": true, "_uuid": "bea0d514749cd09fa14069125b6b0a8940e8284a"}, "source": ["cross_entropy = tf.reduce_mean(\n", "    tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=y_conv))\n", "train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n", "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(Y_, 1))\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "b82d6334-d3bf-4ad3-a105-5b2a29461871", "collapsed": true, "_uuid": "c0420d5aac58ca69b19d00dcba70a0cb51cccd12"}, "source": ["#creating training and testing sets\n", "from sklearn.utils import shuffle\n", "from sklearn.model_selection import train_test_split as tts\n", "train_set = shuffle(train_set)\n", "train, test=tts(train_set,test_size=0.1,random_state=1)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "2a670ee2-ca31-4cce-9f9c-47374347d25b", "_uuid": "354184d6c6be88a8c68ef3bc945fbf13f8924efb"}, "source": ["print(len(train),len(test))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "68259cc8-ab81-4111-85c8-0e8c4c335c02", "_uuid": "152bb84a455a025092e5d50382f913ed0b0504a7"}, "source": ["train_features=np.array([i[0]/255.0 for i in train])\n", "train_labels=np.array([i[1] for i in train])\n", "print(train_features.shape,train_labels.shape)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "98720ce2-7fda-4aad-ae27-db926e3cad29", "_uuid": "ad66725bbca5a50b92a156b7e8b950e2cf8aba59"}, "source": ["print('yo')\n", "init=tf.global_variables_initializer()\n", "sess=tf.Session()\n", "sess.run(init)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "11cb3ba5-3057-414f-8b1d-c5dc23a19ff6", "collapsed": true, "_uuid": "89150cad3d6bb3c52db632ba8382621d62193530"}, "source": [], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "a3f94a5c-7a46-4808-a792-da779ff1d554", "_uuid": "4449a520a97405c96d9ddb86d592aa9ad8a10ed9"}, "source": ["print(\"now entering training\")\n", "costs=[]\n", "#training with learning rate 0.0001 for 30 epochs to start with \n", "for i in range (30):   \n", "    j=0\n", "    batch_cost=0\n", "    for j in range (100):\n", "        batch_x=(train_features[(j*225):(j+1)*225])\n", "        batch_y=(train_labels[j*225:(j+1)*225])\n", "        _,cost_batch=sess.run([train_step,cross_entropy],{X:batch_x,Y_:batch_y})\n", "        batch_cost+=cost_batch/100.0   \n", "        if j==99 and j!=0:\n", "            costs.append(batch_cost)\n", "            print(batch_cost)\n", "        if j%49==0:\n", "            print('on minibatch iteration ',j)\n", "    #_x.append(i)  \n", "    #costs.append(float(cost))\n", "    #if i%5==0:\n", "    print(\"iteration= \",i)\n", "    #print(cost,costs)\n", "plt.plot(costs)\n", "plt.show()"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "f39027a2-2e08-4c15-9994-32e274645d01", "_uuid": "98c824755a68f9b5d61b84aa0483a7add4a19efb"}, "source": ["\n", "test_features=np.array([i[0]/255 for i in test])\n", "test_labels=np.array([i[1] for i in test])\n", "print('starting to predict test accuracy')\n", "print(sess.run(accuracy,{X:test_features,Y_:test_labels}))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "2dae44ba-3416-44ab-9458-7cd76e0b373c", "_uuid": "76de57c11959c129e887c918c60817e84f667485"}, "source": ["#now trying to predict results for real test set\n", "#loading testing images\n", "TEST_PATH='../input/test'\n", "ls_test=sorted(os.listdir(TEST_PATH))\n", "print(len(ls_test))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"_cell_guid": "af9b5de0-c586-4cf8-8b6b-8d289d5d06c1", "collapsed": true, "_uuid": "533e4a641d28bb9329ca6422921f3ef48ead6788"}, "source": ["test_dict={}\n", "for i in ls_test:\n", "    s=i.split('.')[0]\n", "    test_dict[s]=i"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {}, "source": ["#test_features\n", "test_features=[]\n", "for i in range(1,12501):\n", "    test_features.append(load_image(os.path.join(TEST_PATH,test_dict[str(i)]),64))\n", "    if i%1000==0:\n", "        print('features loaded successfully',i)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {}, "source": ["test_features=np.array(test_features)\n", "print(test_features.shape)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {}, "source": ["ans=tf.argmax(y_conv, 1)\n", "test_result=[]\n", "for i in range(125):\n", "    f1=test_features[i*100:(i+1)*100]/255\n", "    pred=sess.run(ans,{X:f1})\n", "    for j in range(len(pred)):\n", "        test_result.append(pred[j])\n", "print(len(test_result))"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["test_result=np.array(test_result)\n", "labels=[]\n", "for x in range (1,12501):\n", "    labels.append(x)\n", "labels=np.array(labels)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {}, "source": ["df={\n", "    'id':labels,\n", "    'label':test_result\n", "}\n", "print(len(labels),len(test_result))\n", "pd_df=pd.DataFrame(data=df)\n", "pd_df.to_csv('cnn_regularized2.csv',index=False)"], "cell_type": "code"}, {"execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": [], "cell_type": "code"}], "nbformat_minor": 1}