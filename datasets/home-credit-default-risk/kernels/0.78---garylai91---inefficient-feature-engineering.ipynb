{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport gc\nimport xgboost as xgb\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95ac2b80cff04a955386486430aa48613da690ce"},"cell_type":"code","source":"def bureau_balance_preprocess():\n    # Import bureau and bureau_balance\n    bureau = pd.read_csv(\"../input/bureau.csv\")\n    balance = pd.read_csv(\"../input/bureau_balance.csv\")\n    \n    # Search for categorical variables\n    cat_cols = []\n    for i in balance.columns.values:\n        if balance[i].dtype == 'object':\n            cat_cols.append(i)\n    \n    # Search for numerical variables\n    num_cols = [col for col in balance.columns if col not in cat_cols][1:]\n    \n    # One hot encoding of balance categorical variables\n    balance = pd.get_dummies(balance, columns = ['STATUS'])\n    \n    cat_cols = [c for c in balance.columns.tolist() if c not in [cat_cols, num_cols]][2:]\n    \n    # Aggregate all variables\n    cat_aggs = {}\n    num_aggs = {}\n    for i in cat_cols:\n        cat_aggs[i] = ['mean']\n    for j in num_cols:\n        num_aggs[j] = ['size']\n    \n    # Groupby SK_ID_BUREAU and aggregate\n    balance = balance.groupby('SK_ID_BUREAU').agg({**num_aggs, **cat_aggs})\n    \n    # Rename columns into 'column_name' + aggregation\n    balance.columns = [i[0] + \"_\" + i[1]for i in balance.columns.tolist()]\n    \n    # Complete balance preprocessing\n    balance.reset_index(inplace = True)\n    \n    # Search for categorical variables\n    cat_cols = []\n    for i in bureau.columns.values:\n        if bureau[i].dtype == 'object':\n            cat_cols.append(i)\n    \n    # Search for numerical variables\n    num_cols = [col for col in bureau.columns if col not in cat_cols]\n    \n    # One hot encoding of bureau categorical variables\n    bureau = pd.get_dummies(bureau, columns = cat_cols)\n    \n    # Merge balance and bureau dataframes\n    df = bureau.merge(balance, how='left', on='SK_ID_BUREAU')\n    \n    # Drop SK_ID_BUREAU as it is redundant now\n    df.drop(['SK_ID_BUREAU'], axis = 1, inplace = True)\n    \n    # Aggregate variables\n    aggregations = {}\n    for i in df.columns.tolist()[1:]:\n        aggregations[i] = ['min', 'max', 'mean', 'median', 'var', 'size']\n    \n    # Groupby SK_ID_CURR and aggregate accordingly\n    df = df.groupby('SK_ID_CURR').agg(aggregations)\n    \n    # Rename column names\n    df.columns = [i[0] + \"_\" + i[1]for i in df.columns.tolist()]\n    \n    # bureau and balance preprocessing complete\n    df = df.reset_index()\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"843edc52871e96600b39be83741f270edeb0d210"},"cell_type":"code","source":"def prev_application():\n    df = pd.read_csv(\"../input/previous_application.csv\")\n    df.loc[df['AMT_CREDIT'] > 6000000, 'AMT_CREDIT'] = np.nan\n    df.loc[df['SELLERPLACE_AREA'] > 3500000, 'SELLERPLACE_AREA'] = np.nan\n    df['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n    df['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n    df['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n    df['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n    df['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n    df['prev missing'] = df.isnull().sum(axis = 1).values\n    df['prev AMT_APPLICATION / AMT_CREDIT'] = df['AMT_APPLICATION'] / df['AMT_CREDIT']\n    df['prev AMT_APPLICATION - AMT_CREDIT'] = df['AMT_APPLICATION'] - df['AMT_CREDIT']\n    df['prev AMT_APPLICATION - AMT_GOODS_PRICE'] = df['AMT_APPLICATION'] - df['AMT_GOODS_PRICE']\n    df['prev AMT_GOODS_PRICE - AMT_CREDIT'] = df['AMT_GOODS_PRICE'] - df['AMT_CREDIT']\n    df['prev DAYS_FIRST_DRAWING - DAYS_FIRST_DUE'] = df['DAYS_FIRST_DRAWING'] - df['DAYS_FIRST_DUE']\n    df['prev DAYS_TERMINATION less -500'] = (df['DAYS_TERMINATION'] < -500).astype(int)\n    df.rename(columns = lambda x : 'PREV_' + x if x  not in ['SK_ID_PREV', 'SK_ID_CURR'] else x, inplace = True)\n    cat_cols = []\n    for i in df.columns.values:\n        if df[i].dtype == 'object':\n            cat_cols.append(i)\n    num_cols = [col for col in df.columns[2:] if col not in cat_cols]\n    df = pd.get_dummies(df, columns = cat_cols)\n    new_cat_cols = [c for c in df.columns.tolist() if c not in [cat_cols, num_cols]][2:]\n    cat_aggs = {}\n    num_aggs = {}\n    for i in new_cat_cols:\n        cat_aggs[i] = ['mean']\n    for j in num_cols:\n        num_aggs[j] = ['min', 'max', 'mean', 'median', 'var', 'size']\n    df.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n    df = df.groupby('SK_ID_CURR').agg({**num_aggs, **cat_aggs})\n    df.columns = [i[0] + \"_\" + i[1]for i in df.columns.tolist()]\n    return df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"255fb10cf033c113f8e2751ad2214eac5a04e6c9"},"cell_type":"code","source":"def posh_cash_balance():\n    df = pd.read_csv(\"../input/POS_CASH_balance.csv\")\n    df.loc[df['CNT_INSTALMENT_FUTURE'] > 60, 'CNT_INSTALMENT_FUTURE'] = np.nan\n    df.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n    df['pos CNT_INSTALMENT more CNT_INSTALMENT_FUTURE'] = \\\n                    (df['CNT_INSTALMENT'] > df['CNT_INSTALMENT_FUTURE']).astype(int)\n    cat_cols = []\n    for i in df.columns.values:\n        if df[i].dtype == 'object':\n            cat_cols.append(i)\n    num_cols = [c for c in df.columns.tolist() if c not in cat_cols][1:]\n    df = pd.get_dummies(df, columns = ['NAME_CONTRACT_STATUS'])\n    cat_cols = [c for c in df.columns.tolist() if c not in [cat_cols, num_cols]][1:]\n    cat_aggs = {}\n    num_aggs = {}\n    for i in cat_cols:\n        cat_aggs[i] = ['mean']\n    for j in num_cols:\n        num_aggs[j] = ['min', 'max', 'mean', 'median', 'var', 'size']\n    df = df.groupby('SK_ID_CURR').agg({**num_aggs, **cat_aggs})\n    df.columns = [i[0] + \"_\" + i[1]for i in df.columns.tolist()]\n    df.reset_index(inplace = True)\n    df['CNT_INSTALMENT_RATIO'] = df['CNT_INSTALMENT_mean'] / df['MONTHS_BALANCE_mean']\n    df['CNT_INSTALMENT_FUTURE_RATIO'] = df['CNT_INSTALMENT_FUTURE_mean'] / df['MONTHS_BALANCE_mean']\n    df['CNT_INSTALMENT_SUM_RATIO'] = (df['CNT_INSTALMENT_mean'] + df['CNT_INSTALMENT_FUTURE_mean']) / df['MONTHS_BALANCE_mean']\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"771d74102ed335321ae788424b090f09f2cf277a"},"cell_type":"code","source":"def cc_balance():\n    df = pd.read_csv(\"../input/credit_card_balance.csv\")\n    df.loc[df['AMT_PAYMENT_CURRENT'] > 4000000, 'AMT_PAYMENT_CURRENT'] = np.nan\n    df.loc[df['AMT_CREDIT_LIMIT_ACTUAL'] > 1000000, 'AMT_CREDIT_LIMIT_ACTUAL'] = np.nan\n    df['card missing'] = df.isnull().sum(axis = 1).values\n    df['card SK_DPD - MONTHS_BALANCE'] = df['SK_DPD'] - df['MONTHS_BALANCE']\n    df['card SK_DPD_DEF - MONTHS_BALANCE'] = df['SK_DPD_DEF'] - df['MONTHS_BALANCE']\n    df['card SK_DPD - SK_DPD_DEF'] = df['SK_DPD'] - df['SK_DPD_DEF']\n    \n    df['card AMT_TOTAL_RECEIVABLE - AMT_RECIVABLE'] = df['AMT_TOTAL_RECEIVABLE'] - df['AMT_RECIVABLE']\n    df['card AMT_TOTAL_RECEIVABLE - AMT_RECEIVABLE_PRINCIPAL'] = df['AMT_TOTAL_RECEIVABLE'] - df['AMT_RECEIVABLE_PRINCIPAL']\n    df['card AMT_RECIVABLE - AMT_RECEIVABLE_PRINCIPAL'] = df['AMT_RECIVABLE'] - df['AMT_RECEIVABLE_PRINCIPAL']\n\n    df['card AMT_BALANCE - AMT_RECIVABLE'] = df['AMT_BALANCE'] - df['AMT_RECIVABLE']\n    df['card AMT_BALANCE - AMT_RECEIVABLE_PRINCIPAL'] = df['AMT_BALANCE'] - df['AMT_RECEIVABLE_PRINCIPAL']\n    df['card AMT_BALANCE - AMT_TOTAL_RECEIVABLE'] = df['AMT_BALANCE'] - df['AMT_TOTAL_RECEIVABLE']\n\n    df['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_ATM_CURRENT'] = df['AMT_DRAWINGS_CURRENT'] - df['AMT_DRAWINGS_ATM_CURRENT']\n    df['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_OTHER_CURRENT'] = df['AMT_DRAWINGS_CURRENT'] - df['AMT_DRAWINGS_OTHER_CURRENT']\n    df['card AMT_DRAWINGS_CURRENT - AMT_DRAWINGS_POS_CURRENT'] = df['AMT_DRAWINGS_CURRENT'] - df['AMT_DRAWINGS_POS_CURRENT']\n    \n    df.rename(columns = lambda x : 'PREV_' + x if x  not in ['SK_ID_PREV', 'SK_ID_CURR'] else x, inplace = True)\n    cat_cols = []\n    for i in df.columns.values:\n        if df[i].dtype == 'object':\n            cat_cols.append(i)\n    num_cols = [col for col in df.columns[2:] if col not in cat_cols]\n    df = pd.get_dummies(df, columns = cat_cols)\n    new_cat_cols = [c for c in df.columns.tolist() if c not in [cat_cols, num_cols]][2:]\n    cat_aggs = {}\n    num_aggs = {}\n    for i in new_cat_cols:\n        cat_aggs[i] = ['mean']\n    for j in num_cols:\n        num_aggs[j] = ['min', 'max', 'mean', 'median', 'var', 'size']\n    df.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n    df = df.groupby('SK_ID_CURR').agg({**num_aggs, **cat_aggs})\n    df.columns = [i[0] + \"_\" + i[1]for i in df.columns.tolist()]\n    return df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f7832b1835b580654613410e8f44fb03f306d7"},"cell_type":"code","source":"def installments():\n    df = pd.read_csv(\"../input/installments_payments.csv\")\n    df.loc[df['NUM_INSTALMENT_VERSION'] > 70, 'NUM_INSTALMENT_VERSION'] = np.nan\n    df.loc[df['DAYS_ENTRY_PAYMENT'] < -4000, 'DAYS_ENTRY_PAYMENT'] = np.nan\n    df['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'] = df['DAYS_ENTRY_PAYMENT'] - df['DAYS_INSTALMENT']\n    df['ins NUM_INSTALMENT_NUMBER_100'] = (df['NUM_INSTALMENT_NUMBER'] == 100).astype(int)\n    df['ins DAYS_INSTALMENT more NUM_INSTALMENT_NUMBER'] = (df['DAYS_INSTALMENT'] > df['NUM_INSTALMENT_NUMBER'] * 50 / 3 - 11500 / 3).astype(int)\n    df['ins AMT_INSTALMENT - AMT_PAYMENT'] = df['AMT_INSTALMENT'] - df['AMT_PAYMENT']\n    df['ins AMT_PAYMENT / AMT_INSTALMENT'] = df['AMT_PAYMENT'] / df['AMT_INSTALMENT']\n    df.drop([])\n    df.rename(columns = lambda x : 'PREV_' + x if x  not in ['SK_ID_PREV', 'SK_ID_CURR'] else x, inplace = True)\n    cat_cols = []\n    for i in df.columns.values:\n        if df[i].dtype == 'object':\n            cat_cols.append(i)\n    num_cols = [col for col in df.columns[2:] if col not in cat_cols]\n    df = pd.get_dummies(df, columns = cat_cols)\n    new_cat_cols = [c for c in df.columns.tolist() if c not in [cat_cols, num_cols]][2:]\n    cat_aggs = {}\n    num_aggs = {}\n    for i in new_cat_cols:\n        cat_aggs[i] = ['mean']\n    for j in num_cols:\n        num_aggs[j] = ['min', 'max', 'mean', 'median', 'var', 'size']\n    df.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n    df = df.groupby('SK_ID_CURR').agg({**num_aggs, **cat_aggs})\n    df.columns = [i[0] + \"_\" + i[1]for i in df.columns.tolist()]\n    return df.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85b5c95d9a9221eaad2a414c31888ef774a03f8e"},"cell_type":"code","source":"def get_beautiful_data():\n    print('Getting train data...')\n    train = pd.read_csv(\"../input/application_train.csv\")\n    \n    print('Getting test data...')\n    test = pd.read_csv(\"../input/application_test.csv\")\n    y = train.pop('TARGET')\n    index_end = y.shape[0]\n    test_index = test.pop('SK_ID_CURR')\n    cat_cols = []\n    for i in train.columns.values:\n        if train[i].dtype == 'object':\n            cat_cols.append(i)\n    num_cols = [col for col in train.columns if col not in cat_cols]\n    print('Merging train and tests data...')\n    df = pd.concat([train, test], axis = 0, ignore_index = True)\n    del train, test\n    gc.collect()\n    print('Merge complete.')\n    \n    print('Fetching bureau and balance data...')\n    bureau = bureau_balance_preprocess()\n    print('Merging to main data frame...')\n    df = df.merge(bureau, how = 'left', on = 'SK_ID_CURR')\n    del bureau\n    gc.collect()\n    print('Merge complete.')\n    \n    print('Fetching previous_application data...')\n    prev = prev_application()\n    print('Merging to main data frame...')\n    df = df.merge(prev, how = 'left', on = 'SK_ID_CURR')\n    del prev\n    gc.collect()\n    print('Merge complete.')\n    \n    print('Fetching POS_CASH_balance data...')\n    pos = posh_cash_balance()\n    print('Merging to main data frame...')\n    df = df.merge(pos, how = 'left', on = 'SK_ID_CURR')\n    del pos\n    gc.collect()\n    print('Merge complete.')\n    \n    print('Fetching credit_card_balance data...')\n    cc = cc_balance()\n    print('Merging to main data frame...')\n    df = df.merge(cc, how = 'left', on = 'SK_ID_CURR')\n    del cc\n    gc.collect()\n    print('Merge complete.')\n    \n    print('Fetching installments_payments data...')\n    inst = installments()\n    print('Merging to main data frame...')\n    df = df.merge(inst, how = 'left', on = 'SK_ID_CURR')\n    del inst\n    gc.collect()\n    print('Merge complete')\n    \n    docs = [_f for _f in df.columns if 'FLAG_DOC' in _f]\n    live = [_f for _f in df.columns if ('FLAG_' in _f) & ('FLAG_DOC' not in _f) & ('_FLAG_' not in _f)]\n    print('Adding more features...')\n    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n    df['NEW_CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n    df['NEW_CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n    df['NEW_DOC_IND_KURT'] = df[docs].kurtosis(axis=1)\n    df['NEW_LIVE_IND_SUM'] = df[live].sum(axis=1)\n    df['NEW_INC_PER_CHLD'] = df['AMT_INCOME_TOTAL'] / (1 + df['CNT_CHILDREN'])\n    df['NEW_EMPLOY_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['NEW_ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / (1 + df['AMT_INCOME_TOTAL'])\n    df['NEW_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n    df['NEW_EXT_SOURCES_MEAN'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n    df['NEW_SCORES_STD'] = df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n    df['NEW_SCORES_STD'] = df['NEW_SCORES_STD'].fillna(df['NEW_SCORES_STD'].mean())\n    df['NEW_CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']   \n    df['NEW_CAR_TO_EMPLOY_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n    df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n    df['NEW_PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_EMPLOYED']\n    df['NEW_CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n    print('Done.')\n\n    df = pd.get_dummies(df, columns = cat_cols, dummy_na= True)\n        \n    X = df.iloc[:index_end, 1:]\n    X_test = df.iloc[index_end:, 1:]\n    scale_pos_weight = y.value_counts()[0]/ y.value_counts()[1]\n    \n    X, X_test = X.align(X_test, join = 'inner', axis = 1)\n\n    return X, X_test, y, scale_pos_weight, test_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e050c0e979babc4272e6fc67b7ca3bfb7abe120"},"cell_type":"code","source":"X, X_test, y, scale_pos_weight, test_index = get_beautiful_data()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6a901f308e1108843784d5e52dea2d5419cf350"},"cell_type":"markdown","source":"# Remove Collinear Variables #"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"750324cb00809ba5e10f878034d36a4281089b58"},"cell_type":"code","source":"# Remove Collinear Variables\n# Threshold for removing correlated variables\nthreshold = 0.9\n\n# Absolute value correlation matrix\ncorr_matrix = X.corr().abs()\ncorr_matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7451c18a6df15e84e08802b0cb9453314b6547f4"},"cell_type":"code","source":"# Upper triangle of correlations\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nupper.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0193d51f4d307caf83a9c9ebe2b7d91764c4eb2"},"cell_type":"code","source":"# Select columns with correlations above threshold\nto_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n\nprint('There are %d columns to remove.' % (len(to_drop)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f01fc0c546e195fec30e9944ae0add6fee9c3f40"},"cell_type":"code","source":"X = X.drop(columns = to_drop)\nX_test = X_test.drop(columns = to_drop)\n\nprint('Training shape: ', X.shape)\nprint('Testing shape: ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d92e7596f2d5b17906c20e8c71e03ffa342671f5"},"cell_type":"markdown","source":"# Remove Missing Values #"},{"metadata":{"trusted":true,"_uuid":"68284f2e7ab6e73d52e58ee23bbb7f5e1205fbb7"},"cell_type":"code","source":"# Train missing values (in percent)\ntrain_missing = (X.isnull().sum() / len(X)).sort_values(ascending = False)\ntrain_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f4128555c4504522493aaa3ee41e75af1c5aa5d1"},"cell_type":"code","source":"# Test missing values (in percent)\ntest_missing = (X_test.isnull().sum() / len(X_test)).sort_values(ascending = False)\ntest_missing.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9992c58c16a69c0a2b82d355dbdedbad78d49330"},"cell_type":"code","source":"# Identify missing values above threshold\ntrain_missing = train_missing.index[train_missing > 0.75]\ntest_missing = test_missing.index[test_missing > 0.75]\n\nall_missing = list(set(set(train_missing) | set(test_missing)))\nprint('There are %d columns with more than 75%% missing values' % len(all_missing))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17d1f2bf65756b3a900722d1ff604771b0c5eb64"},"cell_type":"code","source":"X = X.drop(columns = all_missing)\nX_test = X_test.drop(columns = all_missing)\n\nprint('Training shape: ', X.shape)\nprint('Testing shape: ', X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3b22251f3d77b43b3bcc7867b9e04fe85592f76","collapsed":true},"cell_type":"code","source":"clf = xgb.XGBClassifier(learning_rate = 0.025, \n                        n_estimators = 10000, \n                        max_depth = 8, \n                        min_child_weight = 1, \n                        subsample = 0.8, \n                        colsample_bytree = 0.7, \n                        colsample_bylevel = 0.7,\n                        objective = 'binary:logistic', \n                        n_jobs = -1,\n                        scale_pos_weight = scale_pos_weight,\n                        silent = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf9f5743d29d0faa6743a3595dbff8163508e0d1","collapsed":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60c5f6593dc8808afd94eb0a9d6820363650604a","collapsed":true},"cell_type":"code","source":"clf.fit(X_train, y_train, eval_set = [(X_train, y_train), (X_val, y_val)], eval_metric= 'auc', verbose= 100, early_stopping_rounds= 400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b617c0a59b37a96ab75b838bcf9cc0045592777b"},"cell_type":"code","source":"result = clf.predict_proba(X_test)\nsubmit = pd.DataFrame({'SK_ID_CURR': test_index, 'TARGET': result[:, 1]})\nsubmit.to_csv('solution.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8ebc9ae82e297a3171f90f48390cf2e62d1659a4"},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(clf, max_num_features=57, height=0.8, ax=ax)\nax.grid(False)\nplt.title(\"XGBoost - Feature Importance\", fontsize=15)\nplt.show()\nplt.savefig('feature_importance.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"729b03f64a28829da6750b8995aa0721be91b030"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}