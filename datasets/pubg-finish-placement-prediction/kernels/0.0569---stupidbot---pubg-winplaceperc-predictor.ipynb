{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c929ba5998ca6d4e92c5c93047a8cdad84789fbf"},"cell_type":"markdown","source":"## **PUBG WinPlacePerc Predictor**\n\nCurrent : MLPRegressor with somewhat working(?) feature engineering.\n\nCredit : \n\n- Feature Engineering Concept from harshit kernel.\n\n- Reduce Mem Usage code from gemartin.\n\n#### What you should expect from this kernel ?\n\n- Nothing, this kernel is totally crap and useless piece of code writed by newbie. feel free to complain and sorry for some *unreadable* code.\n\n#### Current plan:\n- Probably going to change method to Light Gradiant Boosting Machine (LightGBM). Due to MLP taking too much resources.\n- Beautify the code to be more *readable* (probably).\n- Rework feature engineering because i was too lazy to do aggregated feature.\n- **Visualize Data and Correlation Map**"},{"metadata":{"_uuid":"af319d96fb92a573faf54deedad3f181ff0df9e4"},"cell_type":"markdown","source":"**Package calling** "},{"metadata":{"trusted":true,"_uuid":"8911ac287a16beab87e7dd920fd426759a98a11c"},"cell_type":"code","source":"import sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport gc,sys\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**Preprocessing Data**"},{"metadata":{"trusted":true,"_uuid":"677309f8b74724c03f7993392390759c81e09319"},"cell_type":"code","source":"def preprocessing(is_train=True):\n    if is_train:\n        #read file\n        print(\"Preprocessing train_V2.csv\")\n        print(\"Reading the data...\",end='')\n        df = pd.read_csv('../input/train_V2.csv')\n        print(\"Done!\")\n        #No Loner\n        print(\"Kicking out the loner...\",end='')\n        df = df[df['maxPlace'] > 1] \n        print(\"Done!\")\n    else:\n        #process testfile\n        print(\"Preprocessing test_V2.csv\",)\n        print(\"Reading the data...\",end='')\n        df = pd.read_csv('../input/test_V2.csv')\n        print('Done!')\n    #print(\"Dropping unnesscary data\")\n    \n    #Drop useless data\n    #df = df.drop(['Id','groupId','matchId'],axis=1)\n    #print(\"Id Drop---Done\")\n    \n    #Get Target\n    if is_train:\n        print(\"Getting the target...\",end='')\n        target = df['winPlacePerc']\n        print(\"Done!\")\n        print('Remove target from dataframe...',end='')\n        df = df.drop (['winPlacePerc'],axis=1)\n        print(\"Done!\")\n    \n    #Return\n    print(\"Dataframe Exported.\")\n    if is_train:\n        return df,target\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fc18877930aba142b49d089176f584fb571fb96"},"cell_type":"code","source":"def feature_managing(df,is_train=True,lowfeature=True,valuematchtype=True):\n    err = 0\n    print(\"Feature Management Initiated\")\n    #Player's Id has 0 correlation\n    if is_train:\n        print(\"Dropping Player's Id\")\n        try:\n            df = df.drop(['Id'],axis=1)\n        except:\n            print(\"Warning: 'Id' not found.\")\n            err += 1\n    else:\n        #we need player's Id to sent as result though.\n        print('Retrive Player\\'s Id...',end='')\n        test_id = df['Id']\n        df = df.drop(['Id'],axis=1)\n        print('Done!')\n    #Cuz im too lazy to do aggregated feature\n    if lowfeature:\n        print(\"Dropping MatchId\")\n        try:\n            df = df.drop(['matchId'],axis=1)\n            print('Dropping GroupId')\n            df = df.drop(['groupId'],axis=1)\n        except:\n            print('Warning: MatchId and GroupId not found')\n            err += 1\n    #Shut this off if you want to aggregated feature thing right away.\n    if valuematchtype:\n        mtype = ['solo','solo-fpp','duo','duo-fpp','squad','squad-fpp']\n        print('Determine Value for MatchType',end='')\n        df.loc[df.matchType == 'solo','matchType'] = 1\n        print('.',end='')\n        df.loc[df.matchType == 'normal-solo','matchType'] = 1\n        print('.',end='')\n        df.loc[df.matchType == 'solo-fpp','matchType'] = 0.5\n        print('.',end='')\n        df.loc[df.matchType == 'normal-solo-fpp','matchType'] = 0.5\n        print('.',end='')\n        df.loc[df.matchType == 'duo','matchType'] = 2\n        print('.',end='')\n        df.loc[df.matchType == 'normal-duo','matchType'] = 2\n        print('.',end='')\n        df.loc[df.matchType == 'duo-fpp','matchType'] = 2.5\n        print('.',end='')\n        df.loc[df.matchType == 'normal-duo-fpp','matchType'] = 2.5\n        print('.',end='')\n        df.loc[df.matchType == 'squad','matchType'] = 4\n        print('.',end='')\n        df.loc[df.matchType == 'normal-squad','matchType'] = 4\n        print('.',end='')\n        df.loc[df.matchType == 'squad-fpp','matchType'] = 3.5\n        print('.',end='')\n        df.loc[df.matchType == 'normal-squad-fpp','matchType'] = 4\n        print('.',end='')\n        df.loc[df.matchType == 'crashfpp','matchType'] = 5\n        print('.',end='')\n        df.loc[df.matchType == 'crashtpp','matchType'] = 5.5\n        print('.',end='')\n        df.loc[df.matchType == 'flarefpp','matchType'] = 6\n        print('.',end='')\n        df.loc[df.matchType == 'flaretpp','matchType'] = 6.5\n        print('Done!')\n    #Drop things off the board cuz we gonna do aggregated feature!\n    else:\n        df = df.drop['matchType']\n        \n    ##BEGIN FEATURE ENGINEERING!\n    #Part of Idea from harshit kernel\n    print('Generating Feature')\n    print('Generate KillKnockRatio')  \n    df['KillKnockRatio'] = df['kills']/df['DBNOs'] #May Produce NaN or inf ##Determine Efficiency of Killing and knocking ppl\n    print('Generate HealthItemsUsed') \n    df['HealthItemsUsed'] = df['heals']+df['boosts'] #Determine Healthitems used\n    print('Generate HeadshotRatio')\n    df['HeadshotRatio'] = df['headshotKills']/df['kills'] #May Produce Nan or inf ##Determine Headaimming Skills\n    print('Generate AverageDamagePerkill')\n    df['AverageDamagePerKill'] = df['damageDealt']/df['kills'] #May Produce Nan or inf ##Determine Efficiency\n    print('Generate KillstreakRate')\n    df['KillstreakRate'] = df['killStreaks']/df['kills'] #May Produce Nan or inf ##Determine Efficiency when handling large group of enemy\n    print('Generate TotalDistance')\n    df['TotalDistance'] = df['rideDistance'] + df['swimDistance'] + df['walkDistance']\n    print('Generate WeaponRetriveOverDistance')\n    df['WROD'] = df['TotalDistance']/df['weaponsAcquired'] #Determine Weapon Pickup along the way\n    print('Generate WalkingHeal')\n    df['walkHeal'] = df['walkDistance']/df['heals'] #Heals Per Meter (Does this even related? IDK, someone visualize this for me pls.)\n    print('Generate WalkingKills')\n    df['walkkills'] = df['walkDistance']/df['kills'] #same as above need correlation map!\n    print('Generate KillPerMeters')\n    df['KPM'] = df['kills']/df['walkDistance'] #same as above...\n    #Purging NaN\n    print('Purging NaN from Dataframe...',end='') #U know m8\n    try:\n        df[df == np.Inf] = np.NaN #set all inf to NaN\n        df[df == np.NINF] =np.NaN #set all Ninf to NaN\n        df.fillna(0,inplace=True) #Replace all NaN with 0\n        print('Done!')\n    except:\n        print('Nothing to Purge')\n        err += 1\n    \n    if is_train:\n        print('End of Operation')\n        return df\n    #Retrive maxplace to deal with an edge case.\n    else:\n        print('Retrive maxPlace...',end='')\n        test_edge = df['maxPlace']\n        test_edge = pd.DataFrame(test_edge)\n        print('Done!')\n        print('End of Operation')\n        return df,test_id,test_edge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb88f10385799b29bcc89c807d840c44dc24ab9b","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"# Thanks and credited to https://www.kaggle.com/gemartin creator of this mem reducer.\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db2a37c986fb768ce05d4dc0a52d2f001c8dfbec"},"cell_type":"code","source":"#Run this line if mem gone wild (Guarantee 75% mem reduction.)\ndf_train,target = preprocessing(is_train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b77600a48b7c713f045d78a502a645872d6a3886","scrolled":true},"cell_type":"code","source":"df_train = feature_managing(df_train,is_train=True,lowfeature=True,valuematchtype=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73a64247496ddb9b3ba8b85fb189309737430c9a"},"cell_type":"markdown","source":"**Modeling and Memory Wrap-Up**"},{"metadata":{"trusted":true,"_uuid":"501b832d1ec1906b633bb28420e43706034e8f54"},"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69b7052c41ecb52cc7cf93764f3e13aba5a92cc3"},"cell_type":"code","source":"df_train[1:2] #Debuging","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"182be88fcfe1b56ca08de3c187bacd6e750f8a05","scrolled":true},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler\nprint('scaling the dataset')\nscaler = StandardScaler()\nscaler.fit(df_train)\nscaled_train = scaler.transform(df_train)\nprint('scaler ready!')\nmlpreg = MLPRegressor(hidden_layer_sizes=(35,20,15),max_iter=500) #Reduce complexity cuz it's sucks and literally improve nothing.\nprint(\"begin fitting...\",end='')\nmlpreg.fit(scaled_train,target)\nprint(\"Done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0619861dfaf5411e96084b60b12cc7cda26bcacd"},"cell_type":"code","source":"def prediction(reducemem = True,returnall = True,smoothedge=True,csvwrite=False):\n    df_test = preprocessing(is_train=False)\n    df_test,test_id,test_edge = feature_managing(df_test,is_train=False,lowfeature=True,valuematchtype=True)\n    if reducemem:\n        df_test = reduce_mem_usage(df_test) #Reduce Test Dataframe Memory.\n    print('scaling test dataframe')\n    scaled_test = scaler.transform(df_test)\n    print('scaled!')\n    print('Begin Prediction...',end='')\n    res = mlpreg.predict(scaled_test)\n    print('Done!')\n    print('Managing Output')\n    print('Transform to np array to dataframe')\n    res = pd.DataFrame(res)\n    res.columns = ['winPlacePerc']\n    print('Preparing Id')\n    test_id = pd.DataFrame(test_id)\n    print('Initial Result Dataframe')\n    submis = pd.DataFrame({'Id':[] , 'winPlacePerc':[], 'maxPlace':[]})\n    print('Record Result to Dataframe')\n    submis['Id']=test_id['Id']\n    submis['winPlacePerc']=res['winPlacePerc']\n    print('Edge Smoothie')\n    if smoothedge:\n        #Dealing With Edge\n        submis['maxPlace'] = test_edge['maxPlace']\n        submis.loc[submis.maxPlace == 0, 'winPlacePerc'] = 0\n        submis.loc[submis.maxPlace == 1, 'winPlacePerc'] = 1\n        #Edge Smoothing\n        submis.loc[submis.winPlacePerc <= 0,'winPlacePerc'] = 0\n        submis.loc[submis.winPlacePerc > 1,'winPlacePerc'] = 1\n        print('Edge Smoothie Ready to Serve!')\n    else:\n        print('Skipping Edge case smoothing')\n    print('Finalizing ... ',end='')\n    #End of Operation\n    submis = submis.drop(['maxPlace'],axis=1)\n    print('Done!')\n    if csvwrite:\n        print('exporting to csv...',end='')\n        submis.to_csv('submission.csv',index=False)\n    if returnall:\n        print('Returned All')\n        return res,submis\n    print('Returned Result')\n    return submis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7de446c4121075f73f4401310c409e7d1064c42"},"cell_type":"code","source":"res,submis = prediction(reducemem=True,returnall=True,smoothedge=True,csvwrite=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"791db1b921502a46f3606daa06a736f86672d462"},"cell_type":"markdown","source":"## Visualizing Data"},{"metadata":{"trusted":true,"_uuid":"36eba3358a448fc71ab50baf2b335720e0f6f972"},"cell_type":"code","source":"import seaborn as sns\ntargetframe = pd.DataFrame(target)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"944a92234ec38f80f001e2681b2c56cb03d3eb37"},"cell_type":"code","source":"plt.figure()\nsns.distplot(targetframe['winPlacePerc'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88c018306aa25a63f895c485ae6c8bea9903be97"},"cell_type":"code","source":"targetframe.plot()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e16c81ea4233cb1a9ee3c90461ef57a0f54548ff"},"cell_type":"code","source":"resframe = pd.DataFrame(res)\nresframe.plot()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2b9910afae2be683678ca245842ac70ac446834c"},"cell_type":"code","source":"plt.figure()\nsns.distplot(resframe['winPlacePerc'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41b6520e974f049258aaed52621a825cd3003288"},"cell_type":"code","source":"submis['winPlacePerc'].plot()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}