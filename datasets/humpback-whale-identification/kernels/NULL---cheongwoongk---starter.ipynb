{"cells":[{"metadata":{"_uuid":"1d198d1551a93cabefdf930b444b05a22401bb36"},"cell_type":"markdown","source":"<h2>Starter Code</h2>"},{"metadata":{"_uuid":"7eb7fcdc0487dd96a556942f42d1c3811263ca5c"},"cell_type":"markdown","source":"<h3>Libraries</h3>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n#import torch modules \nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.utils.data import TensorDataset\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"<h3>Sample Submission</h3>\nWe are supposed to make 5 predictions for each image."},{"metadata":{"trusted":true,"_uuid":"5f93d69c905157bf0463af88c3fea4b740d3fab0"},"cell_type":"code","source":"sample = open('../input/sample_submission.csv')\nsample = pd.read_csv(sample)\nsample.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fdbb8cfd12ebea527dbef590e914e9c4146c3fd2"},"cell_type":"markdown","source":"<h3>Training Data</h3>\nIt consists of image file names and id for each of them."},{"metadata":{"trusted":true,"_uuid":"b5097b7ce588ac98c02288ff69382895396bb3d4"},"cell_type":"code","source":"train = open('../input/train.csv')\ntrain = pd.read_csv(train)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77d674025aca420c04f8ca6f77ed7a3aa822ff17"},"cell_type":"markdown","source":"<h3>Data Loading & Preprocessing</h3>\nReference: [Whales. A Simple Guide!](https://www.kaggle.com/jhonatansilva31415/whales-a-simple-guide)\n\nFirst, let's take a look at the images."},{"metadata":{"trusted":true,"_uuid":"9af8f2a3df513690ad5c167e16556e7e9a6c8050"},"cell_type":"code","source":"%matplotlib inline\n\ntrain_dir = '../input/train/'\nfor whale in os.listdir(train_dir)[:3]:\n    img = Image.open(train_dir+whale)\n    plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67d6d3fec9629f6dc97b447c6a88709bb87975ae"},"cell_type":"markdown","source":"SInce images are in different sizes and formats, we need to handle them.\n\nResize the images into (128, 128) and make them into grayscale.<br>\nAlso, normalize the data and make them into torch tensors."},{"metadata":{"trusted":true,"_uuid":"03d722d43304b265eae772f4c42683b3bb9fea78"},"cell_type":"code","source":"normalize = transforms.Normalize(\n   mean=[0.485, 0.456, 0.406],\n   std=[0.229, 0.224, 0.225]\n)\npreprocess = transforms.Compose([\n   transforms.Grayscale(num_output_channels=1),\n   transforms.Resize((128,128)),\n   transforms.ToTensor(),\n   normalize\n])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fef230b9376baf818316113d8f2e20285efa774"},"cell_type":"markdown","source":"It will take about 10 minutes to load all the images."},{"metadata":{"trusted":true,"_uuid":"66682e9ab4edf6b8889c4a9b4fc4f794c346716c"},"cell_type":"code","source":"train_dir = '../input/train/'\ntrain_file = os.listdir(train_dir)\ntrain_file.sort()\ntrain_x = torch.stack([preprocess(Image.open(train_dir+filename)) for filename in train_file])\n\ntest_dir = '../input/test/'\ntest_file = os.listdir(test_dir)\ntest_file.sort()\ntest_x = torch.stack([preprocess(Image.open(test_dir+filename)) for filename in test_file])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f24bbcdb3eea5634e8e14a933f7b9b6e76e1923"},"cell_type":"code","source":"train_y = train['Id']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"660a913565bbbb4e57f76c4724f4db7bdcc8706d"},"cell_type":"markdown","source":"Separate data into training data and validation data.<br>\nHowever, I am considering training without validation because the data is too small.\n\nI decided not to use validation data."},{"metadata":{"trusted":true,"_uuid":"292ba5c428d526ccdfef2e4a95935a199ddee95b"},"cell_type":"code","source":"#valid_x = train_x[:1500]\n#valid_y = train_y[:1500]\n#train_x = train_x[1500:]\n#train_y = train_y[1500:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ea1ab49ab0887137e37192a428e1deda8ccb8da"},"cell_type":"markdown","source":"It'd be better to train without 'new_whale'."},{"metadata":{"trusted":true,"_uuid":"94dbb82046785361a304ac8f5c68518a4acf2882"},"cell_type":"code","source":"idx = (train_y != 'new_whale')\ntrain_x = torch.stack([train_x[i] for i in range(len(idx)) if idx[i]])\ntrain_y = train_y[idx].reset_index(drop=True)\n\nprint(len(train_x), len(train_y))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb3023c232636666bc6f23782bde1835efa47e48"},"cell_type":"markdown","source":"Factorize training data labels."},{"metadata":{"trusted":true,"_uuid":"a0cbefe1839373c46cf42b064587242fcb74d1c8"},"cell_type":"code","source":"unique_classes = pd.unique(train_y)\nencoding = dict(enumerate(unique_classes))\nencoding = {value: key for key, value in encoding.items()}\ntrain_y = train_y.replace(encoding)\n\ntrain_y = torch.tensor(train_y.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ff95be8345b09fe9216b8bf441e98374d9dbe7b0"},"cell_type":"markdown","source":"Factorize validation data labels as well."},{"metadata":{"trusted":true,"_uuid":"db5c6f7843f81590fa8ec7230d7b8a2c6b95a947"},"cell_type":"code","source":"'''encoding['new_whale'] = len(encoding)\n\nvalid_y = valid_y.replace(encoding)\nfor i in range(len(valid_y)):\n    try:\n        int(valid_y[i])\n    except:\n        valid_y[i] = len(encoding) - 1\n        \nvalid_y = torch.tensor(valid_y.values)'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a00630a2bf4befb260bf0837803ae91304fb14b"},"cell_type":"markdown","source":"Now let's see the processed images.<br>\nIt seems good to start."},{"metadata":{"trusted":true,"_uuid":"47d0a85ac10df6c5a146659eadb072b0ea8aa968"},"cell_type":"code","source":"%matplotlib inline\n\nfor img in train_x[:3]:\n    plt.imshow(img[0], cmap='gray')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83b2773a47fd831ff4681d713f3a60e0a298fdc3"},"cell_type":"markdown","source":"<h3>Simple CNN Model</h3>"},{"metadata":{"trusted":true,"_uuid":"fd376a01b9eec719ab80efcc938a461a92940a73"},"cell_type":"code","source":"print(len(encoding))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1daae1a3a686ccf4c4de11f5d25b314e07d56e85"},"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self ):\n        super(CNN, self ).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n        self.conv_drop = nn.Dropout2d(0.25)\n        self.fc1 = nn.Linear(53824, 10000)\n        self.fc2 = nn.Linear(10000, 5004)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.conv_drop(F.max_pool2d(F.relu(self.conv2(x)), 2))\n        x = F.relu(self.conv3(x))\n        x = self.conv_drop(F.max_pool2d(F.relu(self.conv4(x)), 2, stride=2))\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c06107cad3f6a8df7bfdfdfe1207ffcc5f4587a"},"cell_type":"code","source":"def train(model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n            \ndef test(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct / len(test_loader.dataset)))\n    \n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3aeb702f0fadc3d12599189bdceb249e59b30192"},"cell_type":"code","source":"batch_size = 128\n#test_batch_size = 7960\ntest_batch_size = 128\nepochs = 10\nlr = 0.0002\nuse_cuda = True\nseed = 1\n\ntorch.manual_seed(seed)\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\nkwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n\ntrain_data = TensorDataset(train_x, train_y)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, **kwargs)\n#valid_data = TensorDataset(valid_x, valid_y)\n#valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True, **kwargs)\ntest_data = TensorDataset(test_x)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=test_batch_size, shuffle=False, **kwargs)\n\nmodel = CNN().to(device) \noptimizer = optim.RMSprop(model.parameters(), lr=lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"248b402514fad8cf955cd195b5cebee14b2f61a8"},"cell_type":"code","source":"for epoch in range(epochs):\n    print('epoch', epoch, end=' - ')\n    train(model, device, train_loader, optimizer, epoch)\n    pred = test(model, device, test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb61ad4759e706ea6b57814c0dab6161c1ede8c8"},"cell_type":"code","source":"prediction = [pred[i].item() for i in range(len(pred))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913c6bce97ec5f0bf78500d41a4584022f810af2"},"cell_type":"code","source":"submission = pd.DataFrame({'id':range(len(prediction)), \n                           'label':prediction,\n                          }).set_index('id')\n\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f75cf158612ce83105a71df6cbb12bcdd940abc"},"cell_type":"code","source":"submission.to_csv('submission.csv', columns=['label']) ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}