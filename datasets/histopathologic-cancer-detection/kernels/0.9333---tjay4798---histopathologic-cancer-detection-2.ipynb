{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport random\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport cv2\nimport imgaug as ia\nimport imgaug.augmenters as iaa\nimport os\nprint(os.listdir(\"../input\"))\nimport tensorflow as tf\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/train_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a2057966c7260fa247b18fa667173bb470c4c45"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6273b24f551914446948e663efb40e3f67952036"},"cell_type":"code","source":"df_train_paths = glob.glob('../input/train/*.tif')\ndf_test_paths = glob.glob('../input/test/*.tif')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e609620ed33da49f51656103a2e372debeb95b2a"},"cell_type":"code","source":"df_train_paths[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df232419bd8b0ca8a44d2506b8acfde84804f1d9"},"cell_type":"code","source":"df_test_paths[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c72043bb2a4dbc0f74c3a9a519d07cef8e4647f"},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fb4cb571450b464c48a532b344d0a19b37012cc"},"cell_type":"code","source":"def label_mapping(data):\n    return data.split('/')[-1].replace('.tif','')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44ab407cb3d11c62c4c7a7f3747ba7c5bff4bfed"},"cell_type":"code","source":"id_label = {k:v for k,v in zip(df.id.values,df.label.values)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cfa0552560d613ae716309401f89f70af438658"},"cell_type":"code","source":"def give_label(img_path):\n    return id_label[img_path]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b58bafbf259ef7bb713a7dfebef00dd3598a390"},"cell_type":"code","source":"def get_batch(data, batch_size):\n    return (data[i:i+batch_size] for i in range(0, len(data), batch_size))   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d6b8c413be17633ede7ef025c00e7807a96c320"},"cell_type":"code","source":"def data_aug(img_data,train_label_mapping,batch_size,augment = False):\n    seq = get_seq()\n    while True:\n        random.shuffle(img_data)\n        for batch in get_batch(img_data,batch_size):\n            X = [cv2.imread(img_path) for img_path in batch]\n            y = [train_label_mapping[get_id_from_img_path(img_path)] for img_path in batch]\n            \n            if augment:\n                X = seq.augment_images(X)\n    \n            yield np.array(X), np.array(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"44941ac7153e2443942c1e3b9446bfc2ffb0ea12"},"cell_type":"code","source":"# df_main.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fa245850d80fdb4b82320d01e09e56171232b24"},"cell_type":"code","source":"df_main = pd.DataFrame({'img_path':df_train_paths})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a8116a285fe844fd98ae7eaa02b58fc3504fc01"},"cell_type":"code","source":"df_main['id'] = df_main['img_path'].apply(label_mapping)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9373c01cde4850de351ac8502335fded63e1a21"},"cell_type":"code","source":"# df_main['label'] = df_main['id'].apply(give_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7b0b7df07e0b8cef9a62b7ee811fc29eca8e484"},"cell_type":"code","source":"# df_main = shuffle(df_main)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecac47a43f5643bd1a1ecbe0b3eaefbe4d2c522a"},"cell_type":"code","source":"# df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"330e24a96770343faf8d5a304badb1cff1cdbbc5"},"cell_type":"code","source":"df = df.merge(df_main,on='id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4691b83ea4b1f7eea386cc7cb8f9978e00dc77b"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cb5b909bc342d806a9c504ecdb3088ff92828f8"},"cell_type":"code","source":"df0 = df[df['label'] == 0].sample(50000,random_state=42)\ndf1 = df[df['label'] == 1].sample(50000,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddbff3fe661a4b9fdba8b598fec6e52fa84d8b68"},"cell_type":"code","source":"df = pd.concat([df0,df1], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64906b0bf9a6b4e5ea0a3798a6b116c69937388a"},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e7b47507e7d1773b99745193f519cc23834a1dc"},"cell_type":"code","source":"df_train, df_val = train_test_split(df, random_state=42,test_size=0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0a50f10971f2ed76c620bc51266212a439253d1"},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bab9eb8801aa8fe8f309c9bc977fd650ed1b4f54"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01bf6b8d23027446c897937f3478ae44104df5cf"},"cell_type":"code","source":"df_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5efbcec346ac268557a35fac30902ac3fbdccb6"},"cell_type":"code","source":"train_imgs = [cv2.imread(img_path) for img_path in list(df_train['img_path'])]\nval_imgs = [cv2.imread(img_path) for img_path in list(df_val['img_path'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50d37bf8eb78c9451e9d497821bdcd4e8ea94c4b"},"cell_type":"code","source":"train_imgs = np.array(train_imgs)\nval_imgs = np.array(val_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b226798303f7bd626d3dc0be51272a0ab69c88eb"},"cell_type":"code","source":"train_imgs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dac27c9bf2346386252c95eb3b000bba0c3ee70b"},"cell_type":"code","source":"val_imgs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cffb898f7ae23bff2f9cf2337eb7c01d1841e8a4"},"cell_type":"code","source":"ia.seed(1)\n\n# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second\n# image.\nsometimes = lambda aug: iaa.Sometimes(0.5, aug)\ndef get_seq():\n    # Define our sequence of augmentation steps that will be applied to every image.\n    seq = iaa.Sequential([\n        iaa.Fliplr(0.5), #horizontally flip 50% images\n        iaa.Flipud(0.2), #vertically flip 20% images\n        \n        # crop some of the images by 0-10% of their height/width\n        sometimes(iaa.Crop(percent=(0,0.1))),\n        \n        # Apply affine transformations to some of the images\n        # - scale to 80-120% of image height/width (each axis independently)\n        # - translate by -20 to +20 relative to height/width (per axis)\n        # - rotate by -45 to +45 degrees\n        # - shear by -16 to +16 degrees\n        # - order: use nearest neighbour or bilinear interpolation (fast)\n        # - mode: use any available mode to fill newly created pixels\n        #         see API or scikit-image for which modes are available\n        # - cval: if the mode is constant, then use a random brightness\n        #         for the newly created pixels (e.g. sometimes black,\n        #         sometimes white)\n        sometimes(iaa.Affine(\n            scale = {\"x\":(0.8,1.2), \"y\":(0.8,1.2)},\n            translate_percent = {\"x\":(-0.2,0.2), \"y\":(-0.2,0.2)},\n            rotate = (-45,45),\n            shear = (-16,16),\n            order = [0,1],\n            cval = (0,255),\n            mode = ia.ALL\n        )),\n        \n        #\n        # Execute 0 to 5 of the following (less important) augmenters per\n        # image. Don't execute all of them, as that would often be way too\n        # strong.\n        #\n        iaa.SomeOf((0,5),\n                   [\n                       # Convert some images into their superpixel representation,\n                       # sample between 20 and 200 superpixels per image, but do\n                       # not replace all superpixels with their average, only\n                       # some of them (p_replace).\n                       sometimes(\n                           iaa.Superpixels(\n                           p_replace = (0, 1.0),\n                           n_segments = (20, 200)\n                           )\n                       ),\n                       \n                       # Blur each image with varying strength using\n                       # gaussian blur (sigma between 0 and 3.0),\n                       # average/uniform blur (kernel size between 2x2 and 7x7)\n                       # median blur (kernel size between 3x3 and 11x11).\n                       iaa.OneOf([\n                           iaa.GaussianBlur((0,3.0)),\n                           iaa.AverageBlur(k=(2,6)),\n                           iaa.MedianBlur(k=(3,7))\n                       ]),\n                       \n                       # Sharpen each image, overlay the result with the original\n                       # image using an alpha between 0 (no sharpening) and 1\n                       # (full sharpening effect).\n                       iaa.Sharpen(alpha=(0,1.0), lightness = (0.75, 1.5)),\n                       \n                       # Same as sharpen, but for an embossing effect.\n                       iaa.Emboss(alpha=(0,1.0), strength=(0,2.0)),\n                       \n                       # Search in some images either for all edges or for\n                       # directed edges. These edges are then marked in a black\n                       # and white image and overlayed with the original image\n                       # using an alpha of 0 to 0.7.\n                       sometimes(iaa.OneOf([\n                           iaa.EdgeDetect(alpha = (0,0.7)),\n                           iaa.DirectedEdgeDetect(alpha=(0,0.7), direction=(0.0,1.0))\n                       ])),\n                       \n                       # Add gaussian noise to some images.\n                       # In 50% of these cases, the noise is randomly sampled per\n                       # channel and pixel.\n                       # In the other 50% of all cases it is sampled once per\n                       # pixel (i.e. brightness change).\n                       iaa.AdditiveGaussianNoise(loc=0,scale=(0.0,0.05*255),per_channel=0.5),\n\n                       # Either drop randomly 1 to 10% of all pixels (i.e. set\n                       # them to black) or drop them on an image with 2-5% percent\n                       # of the original size, leading to large dropped\n                       # rectangles.\n                       iaa.OneOf([\n                           iaa.Dropout((0.01, 0.1),per_channel=0.5),\n                           iaa.CoarseDropout((0.03,0.15),size_percent=(0.02,0.05), per_channel=0.2)\n                       ]),\n                       \n                       # Invert each image's chanell with 5% probability.\n                       # This sets each pixel value v to 255-v.\n                       iaa.Invert(0.05, per_channel=True), #Invert colour channels\n                       \n                       # Add a value of -10 to 10 to each pixel.\n                       iaa.Add((-10,10), per_channel=0.5),\n                       \n                       # Change brightness of images (50-150% of original value).\n                       iaa.Multiply((0.5,1.5), per_channel=0.5),\n                       \n                       # Improve or worsen the contrast of images.\n                       iaa.ContrastNormalization((0.5,2.0),per_channel=0.5),\n                       \n                       # Convert each image to grayscale and then overlay the\n                       # result with the original with random alpha. I.e. remove\n                       # colors with varying strengths.\n                       iaa.Grayscale(alpha=(0.0,1.0)),\n                       \n                       # In some images move pixels locally around (with random\n                       # strengths).\n                       sometimes(iaa.ElasticTransformation(alpha=(0.5,3.5),sigma=0.25)),\n                       \n                       # In some images distort local areas with varying strength.\n                       sometimes(iaa.PiecewiseAffine(scale=(0.01,0.05)))\n                   ],\n                   #do all the above augmentations in random order\n                   random_order = True\n                  )\n            ],\n            random_order = True\n        )\n    return seq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6f9595e55bb8337f96457758e703e52073df2ed"},"cell_type":"code","source":"seq = get_seq()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"836e6f408ae8d92d9da8856b03d819952b7a227f"},"cell_type":"code","source":"train_imgs = seq.augment_images(train_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a5b3098667dcfd6eb04afeade95044865f94aba"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b4f32e124d84aeda034026d229d2bcb190e0d55"},"cell_type":"code","source":"from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import Sequential\nfrom tensorflow import set_random_seed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2e2eb42ada4321cc8f94d9d4ce4372401372bd1"},"cell_type":"code","source":"set_random_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28611f9f57aef136477c291711558c22b80a4009"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (96, 96, 3)))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(MaxPooling2D(pool_size = 3)) \n\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size = 3)) \n\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size = 3))\n\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\nmodel.add(Conv2D(filters = 256, kernel_size = 3, padding = 'same', activation = 'relu'))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(MaxPooling2D(pool_size = 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f967ea2f32f7bb8f2abe86661ab86a57a352560"},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(1, activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c626859ce946c847d330bd20c2537870f6922e9c"},"cell_type":"code","source":"# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\ndef auc_roc(y_true, y_pred):\n    # any tensorflow metric\n    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n\n    # find all variables created for this metric\n    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n\n    # Add metric variables to GLOBAL_VARIABLES collection.\n    # They will be initialized for new session.\n    for v in metric_vars:\n        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n\n    # force to update metric values\n    with tf.control_dependencies([update_op]):\n        value = tf.identity(value)\n        return value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0328181c971933f2fc1bd750bf1cddcae00ebc74"},"cell_type":"code","source":"my_callbacks = [EarlyStopping(monitor='auc_roc', patience=300, verbose=1, mode='max')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdffb37ab6dae5e5f493def68319ce5191897bab"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ae87dcd3173a7e7e61343d2b24cf5b18a6d872e"},"cell_type":"code","source":"model.compile(optimizer= 'adam', loss='binary_crossentropy', metrics=['accuracy',auc_roc])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08022ed0660bebc1a804e220817e90a37726ae0e"},"cell_type":"code","source":"batch_size = 128\nmodel.fit(train_imgs,df_train['label'], batch_size = batch_size,epochs=28,validation_data=(val_imgs,df_val['label']), callbacks=my_callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b22ebfdb373366245578d0a8635ced6998325e96"},"cell_type":"code","source":"pred = (model.predict(val_imgs).ravel()*model.predict(val_imgs[:,::-1,:,:]).ravel()*model.predict(val_imgs[:,:,::-1,:]).ravel()*model.predict(val_imgs[:,::-1,::-1,:]).ravel())**0.25\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5db390b9ca5741b9424cc8da2b9edee523fb9e"},"cell_type":"code","source":"roc_auc_score(df_val['label'],pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"061e0f552b176c6769005c5bb501051e9563823f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd86d3165e2c201f8088d693141833db154da78c"},"cell_type":"code","source":"test_imgs = [cv2.imread(img_path) for img_path in df_test_paths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a6b43c357bfd060a2f728aedb6ca054d3e09fe4"},"cell_type":"code","source":"test_imgs = np.array(test_imgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afb93017d77b4815a137cc4c6c6616a273d045e3"},"cell_type":"code","source":"test_imgs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08a236a750f73ef9ddbedd2281915055c91caae8"},"cell_type":"code","source":"predtest = (model.predict(test_imgs).ravel()*model.predict(test_imgs[:,::-1,:,:]).ravel()*model.predict(test_imgs[:,:,::-1,:]).ravel()*model.predict(test_imgs[:,::-1,::-1,:]).ravel())**0.25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78ccc531cd7eb56c2ca6628386f862b3d2a65e79"},"cell_type":"code","source":"id = []\nfor path in df_test_paths:\n    id.append(label_mapping(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0fea97ca1f39263f2c7da72767ba1dac61fd844"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"188fd92bfc91f4702e058e0ae475e24023a65498"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2ad6c30f05af0824be74ab3f094c291723f0465"},"cell_type":"code","source":"submit = pd.DataFrame({'id':id,'label':predtest})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68a4192e5c3c6bd8bb5912af49b6aac4916f7783"},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"751ecfd8417a1ac5389915ca76584b6a1502022d"},"cell_type":"code","source":"submit.to_csv(\"sub_new.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4193b3ef41d722efa8f0bbb20a2205b8ea9476ef"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}