{"nbformat_minor": 0, "nbformat": 4, "cells": [{"execution_count": null, "source": "In this notebook, I tried to explore various dimensionality reduction techniques available. \n\n### Motivation: ###\n\n -  I have seen in many kernels people using various dimensionality reduction techniques(DR's) to improve the score (CV/LB). \nSo have created this kernel to using various DR techniques and ran them on multiple regression algorithms like xgboost, lightgbm, ElasticNet, and DecisionTree. \n\nDimensionality reduction techniques used:\n\n -  [Principal Component Analysis \\[PCA\\]][1]\n -  [Independent Component Analysis \\[ICA\\]][2]\n -  [Truncated SVD \\[TSVD\\]][3]\n -  [Gaussian Random Projection \\[GRP\\]][4]\n -  [Sparse Random Projection \\[SRP\\]][5]\n -  [Non-negative Matrix factorization \\[NMF\\]][6]\n -  [Feature Agglomeration \\[FAG\\]][7]\n\n\n  [1]: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n  [2]: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html\n  [3]: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html\n  [4]: http://scikit-learn.org/stable/modules/generated/sklearn.random_projection.GaussianRandomProjection.html\n  [5]: http://scikit-learn.org/stable/modules/generated/sklearn.random_projection.SparseRandomProjection.html\n  [6]: http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html\n  [7]: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.FeatureAgglomeration.html", "cell_type": "markdown", "metadata": {"_cell_guid": "0e51c8b9-9580-4947-989f-b12ec9204a32", "_execution_state": "idle", "_uuid": "df5eb0f8cda0bff2a82d49faf789549a9456bc34", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "# importing all the necessary modules\n\nimport pandas as pd\nimport numpy as np\nimport random\nfrom itertools import combinations\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.decomposition import NMF\nfrom sklearn.cluster import FeatureAgglomeration\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import Ridge\n\nfrom sklearn.metrics import r2_score\nfrom sklearn.preprocessing import LabelEncoder\nimport pickle\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nrandom.seed(1729)", "cell_type": "code", "metadata": {"trusted": false, "_execution_state": "idle", "_uuid": "10e89c331f045f12d8d2b237767c8421674709e7", "_cell_guid": "230d08c9-834a-4951-b465-0d828f0e56c8"}, "outputs": []}, {"execution_count": null, "source": "### Loading and preparing the data ###", "cell_type": "markdown", "metadata": {"_cell_guid": "e876c383-f77a-487e-af95-d21286035527", "_execution_state": "idle", "_uuid": "b478b079be2f2b288ee88dc0782ea0d98048b34c", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# removing the outlier\ntrain = train.loc[train['y'] < 170, :]\n\n# seperating label and features\ny_train = train['y']\ntrain = train.drop('y', axis=1)\n\n# label encoding the categorical features for dimension reduction\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))", "cell_type": "code", "metadata": {"_cell_guid": "d037db58-0cec-40a9-8799-5272f5416c3d", "trusted": false, "_execution_state": "idle", "_uuid": "cbfe0d803558be7ae32c6b1c35587841f0766422", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### Creating the components using various dimensionality reduction techniques ###", "cell_type": "markdown", "metadata": {"_cell_guid": "384fea6d-6b4c-4759-9d48-54aebdb22406", "_execution_state": "idle", "_uuid": "3257d337b7d235fd0f11c564c3cd0c1a1aef3731", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "n_comp = 12\n\n# tSVD\ntsvd = TruncatedSVD(n_components=n_comp, random_state=420)\ntsvd_results_train = tsvd.fit_transform(train)\ntsvd_results_test = tsvd.transform(test)\n\n# PCA\npca = PCA(n_components=n_comp, random_state=420)\npca2_results_train = pca.fit_transform(train)\npca2_results_test = pca.transform(test)\n\n# ICA\nica = FastICA(n_components=n_comp, random_state=420)\nica2_results_train = ica.fit_transform(train)\nica2_results_test = ica.transform(test)\n\n# GRP\ngrp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\ngrp_results_train = grp.fit_transform(train)\ngrp_results_test = grp.transform(test)\n\n# SRP\nsrp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\nsrp_results_train = srp.fit_transform(train)\nsrp_results_test = srp.transform(test)\n\n# NMF\nnmf = NMF(n_components=n_comp, init='nndsvdar', random_state=420)\nnmf_results_train = nmf.fit_transform(train)\nnmf_results_test = nmf.transform(test)\n\n# FAG\nfag = FeatureAgglomeration(n_clusters=n_comp, linkage='ward')\nfag_results_train = fag.fit_transform(train)\nfag_results_test = fag.transform(test)", "cell_type": "code", "metadata": {"_cell_guid": "ca4f85b0-bb0e-4c7b-a9fc-8ae48f006889", "trusted": false, "_execution_state": "idle", "_uuid": "aa63efd5356a55ac6884eb5b928427643e854bb8", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### Filtering the most significant components and inserting in a Dataframe ###", "cell_type": "markdown", "metadata": {"_cell_guid": "1df95f2e-0166-4594-adc6-cd9dc927b0c4", "_execution_state": "idle", "_uuid": "9a275ba708508867cad511a6f829c09cbcc4d5e1", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "dim_reds = list()\ntrain_pca = pd.DataFrame()\ntest_pca = pd.DataFrame()\n\ntrain_ica = pd.DataFrame()\ntest_ica = pd.DataFrame()\n\ntrain_tsvd = pd.DataFrame()\ntest_tsvd = pd.DataFrame()\n\ntrain_grp = pd.DataFrame()\ntest_grp = pd.DataFrame()\n\ntrain_srp = pd.DataFrame()\ntest_srp = pd.DataFrame()\n\ntrain_nmf = pd.DataFrame()\ntest_nmf = pd.DataFrame()\n\ntrain_fag = pd.DataFrame()\ntest_fag = pd.DataFrame()\n\n\nfor i in range(1, n_comp + 1):\n    train_pca['pca_' + str(i)] = pca2_results_train[:, i - 1]\n    test_pca['pca_' + str(i)] = pca2_results_test[:, i - 1]\n\n    train_ica['ica_' + str(i)] = ica2_results_train[:, i - 1]\n    test_ica['ica_' + str(i)] = ica2_results_test[:, i - 1]\n\n    train_tsvd['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n    test_tsvd['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n\n    train_grp['grp_' + str(i)] = grp_results_train[:, i - 1]\n    test_grp['grp_' + str(i)] = grp_results_test[:, i - 1]\n\n    train_srp['srp_' + str(i)] = srp_results_train[:, i - 1]\n    test_srp['srp_' + str(i)] = srp_results_test[:, i - 1]\n    \n    train_nmf['nmf_' + str(i)] = nmf_results_train[:, i - 1]\n    test_nmf['nmf_' + str(i)] = nmf_results_test[:, i - 1]\n    \n    train_fag['fag_' + str(i)] = fag_results_train[:, i - 1]\n    test_fag['fag_' + str(i)] = fag_results_test[:, i - 1]\n    \ndim_reds.append(('pca', train_pca, test_pca))\ndim_reds.append(('ica', train_ica, test_ica))\ndim_reds.append(('tsvd', train_tsvd, test_tsvd))\ndim_reds.append(('grp', train_grp, test_grp))\ndim_reds.append(('srp', train_srp, test_srp))\ndim_reds.append(('nmf', train_nmf, test_nmf))\ndim_reds.append(('fag', train_fag, test_fag))", "cell_type": "code", "metadata": {"_cell_guid": "e11b48bc-5168-4e41-90de-6be2bfecbfb9", "trusted": false, "_execution_state": "idle", "_uuid": "67a67b7d6c618bd157daf8fd2a53ccdf06248d24", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### Creating combinations and running models on them###", "cell_type": "markdown", "metadata": {"_cell_guid": "f2a7a150-3cc0-4676-9fe7-f42ee696b9da", "_execution_state": "idle", "_uuid": "ed20b5162afb204cfbb32eb3b1a39e43a7619164", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "# creating the combination from the '7' sets of reduced components\ncombs = [combinations(dim_reds, i+1) for i in range(0, len(dim_reds))]\n\ndr_scores = list()\nfor c1 in combs:\n    for c2 in c1:   \n        train_, test_, id_ = list(), list(), list()\n        for k in c2:\n            train_.append(k[1])\n            test_.append(k[2])\n            id_.append(k[0])\n               \n        train_x = train.reset_index(drop=True)\n        train_.append(train_x)\n        test_.append(test)\n            \n        train_ = pd.concat(train_, axis=1)\n        test_ = pd.concat(test_, axis=1)\n        \n        \n        # training and scoring the models with a particular combination\n        \n        \n# ============================ DecisionTree Model =======================  \n#         model = DecisionTreeRegressor(max_depth=3, min_samples_split=11, presort=False, random_state=1729)\n#         model.fit(train_, y_train)\n#         c_score = r2_score(y_train, model.predict(train_))\n\n# ============================ ElasticNet model =======================\n        model = ElasticNet(alpha=0.014, tol=0.11, l1_ratio=0.99999999, \n                           normalize=True, fit_intercept=False, warm_start=True, \n                          copy_X=True, precompute=False, positive=False, max_iter=60)\n        model.fit(train_, y_train)\n        c_score = r2_score(y_train, model.predict(train_))\n        \n# ============================ Ridge model =============================\n#         model = Ridge()\n#         model.fit(train_, y_train)\n#         c_score = r2_score(y_train, model.predict(train_))\n        \n# ================================ lightgbm model =======================\n#         lgb_params = {\n#         'num_iterations': 200,\n#         'learning_rate': 0.045,\n#         'max_depth': 3,\n#         'bagging_fraction': 0.93,\n#         'metric': 'l2_root',\n#         }\n\n#         dtrain = lgb.Dataset(train_, y_train)\n#         num_round = 1200\n#         model = lgb.train(lgb_params, dtrain, num_round)\n#         c_score = r2_score(y_train, model.predict(train_))\n\n# ================================= xgboost model ============================\n#         xgb_params = {\n#         'n_trees': 520, \n#         'eta': 0.0045,\n#         'max_depth': 4,\n#         'subsample': 0.93,\n#         'objective': 'reg:linear',\n#         'eval_metric': 'rmse',\n#         'base_score': np.mean(y_train),\n#         }\n\n#         dtrain = xgb.DMatrix(train_, y_train)\n\n#         num_boost_rounds = 1250\n#         model = xgb.train(xgb_params, dtrain, num_boost_round=num_boost_rounds)\n#         c_score = r2_score(y_train, model.predict(dtrain))\n        \n        dr_scores.append((','.join(id_), c_score))", "cell_type": "code", "metadata": {"_cell_guid": "9578c4d4-6520-4dd3-b258-c6b8181b0d16", "trusted": false, "_execution_state": "idle", "_uuid": "5fb4e99e05eef8bb74381d45799642adfce68e1f", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "# baseline scoring for comparision\nmodel = ElasticNet(alpha=0.014, tol=0.11, l1_ratio=0.99999999, \n                           normalize=True, fit_intercept=False, warm_start=True, \n                          copy_X=True, precompute=False, positive=False, max_iter=60)\nmodel.fit(train, y_train)\nfull_score = r2_score(y_train, model.predict(train))\n\ndr_scores.append(('baseline', full_score))", "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "05e6518aef94d5c1a2b1b05213d14b68f9710069", "collapsed": false, "trusted": false}, "cell_type": "code"}, {"execution_count": null, "source": "### Plotting the graph ###\n\n>  Please open the plots in a separate tab for better labels and clarity.", "cell_type": "markdown", "metadata": {"_cell_guid": "1f70c127-43b5-472b-9fc7-4b40c2d2c52e", "_execution_state": "idle", "_uuid": "1dd18f18b69133d0557aff5da00dbb714accc762", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "x_axis = [c[0] for c in dr_scores]\ny_axis = [c[1] for c in dr_scores]\nfig, ax = plt.subplots(figsize=(22, 10))\nplt.plot(y_axis)\nax.set_xticks(range(len(x_axis)))\nax.set_xticklabels(x_axis, rotation='vertical')\nplt.show()", "cell_type": "code", "metadata": {"_cell_guid": "0a12e1ab-635a-430c-a681-731febfad5a8", "trusted": false, "_execution_state": "idle", "_uuid": "4c0428ad31ea525865c74f84ea28421568d51245", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "### Plots for other models ###\n\n> I was unable to run all models due to kernel time constraint so I ran the models on my local and I am giving the results directly. Please download and run this kernel for any model above by just uncommenting the necessary model code.", "cell_type": "markdown", "metadata": {"_cell_guid": "6e83d40b-edcb-47eb-8a23-3fb26dfdbda1", "_execution_state": "idle", "_uuid": "1121ce40ae204675d87f48ede9505db3a6d8c67a", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "# scores for xgboost on the DR components\nxgb_dr_scores = [('pca', 0.67711803427267436), ('ica', 0.67586920454698141), ('tsvd', 0.6773481959197214), ('grp', 0.66224169180347559), ('srp', 0.66096135085216134), ('nmf', 0.67108736044682338), ('fag', 0.65904803827641634), ('pca,ica', 0.68245377669904106), ('pca,tsvd', 0.68279088835428392), ('pca,grp', 0.6787867994366088), ('pca,srp', 0.67792025638275744), ('pca,nmf', 0.67824271112992407), ('pca,fag', 0.67760115601615789), ('ica,tsvd', 0.6835942695318834), ('ica,grp', 0.67714387407053067), ('ica,srp', 0.67588373704965066), ('ica,nmf', 0.67972571931753245), ('ica,fag', 0.67610154710950088), ('tsvd,grp', 0.67832326077226301), ('tsvd,srp', 0.67772724917614169), ('tsvd,nmf', 0.68019973796858046), ('tsvd,fag', 0.67644006589507888), ('grp,srp', 0.6639663861228402), ('grp,nmf', 0.67298350211656932), ('grp,fag', 0.66285185530531221), ('srp,nmf', 0.67115462237246204), ('srp,fag', 0.66067639917962073), ('nmf,fag', 0.67045554585744727), ('pca,ica,tsvd', 0.68654114499013574), ('pca,ica,grp', 0.6845591569950219), ('pca,ica,srp', 0.68341568938247299), ('pca,ica,nmf', 0.68297606561083835), ('pca,ica,fag', 0.68308499474673812), ('pca,tsvd,grp', 0.68378339313413505), ('pca,tsvd,srp', 0.68356776992801049), ('pca,tsvd,nmf', 0.68352377920860341), ('pca,tsvd,fag', 0.68279271098255034), ('pca,grp,srp', 0.67966645954138882), ('pca,grp,nmf', 0.67943469252666477), ('pca,grp,fag', 0.67866040661124249), ('pca,srp,nmf', 0.67956276141791694), ('pca,srp,fag', 0.67791893370687739), ('pca,nmf,fag', 0.67810864643697355), ('ica,tsvd,grp', 0.6836705557289231), ('ica,tsvd,srp', 0.68444852137165446), ('ica,tsvd,nmf', 0.68499119061570446), ('ica,tsvd,fag', 0.68291988532496473), ('ica,grp,srp', 0.67826068686261565), ('ica,grp,nmf', 0.6803462107453162), ('ica,grp,fag', 0.67798837067985895), ('ica,srp,nmf', 0.67967578214024238), ('ica,srp,fag', 0.67733790019653739), ('ica,nmf,fag', 0.67949754170543986), ('tsvd,grp,srp', 0.67923008622903458), ('tsvd,grp,nmf', 0.68049437195624363), ('tsvd,grp,fag', 0.67884475754668472), ('tsvd,srp,nmf', 0.68040112239110107), ('tsvd,srp,fag', 0.67760402916832718), ('tsvd,nmf,fag', 0.67878244082676908), ('grp,srp,nmf', 0.67330304619738812), ('grp,srp,fag', 0.66499311514336668), ('grp,nmf,fag', 0.67272305180560688), ('srp,nmf,fag', 0.67060795522667327), ('pca,ica,tsvd,grp', 0.6879912555299923), ('pca,ica,tsvd,srp', 0.68824790746797515), ('pca,ica,tsvd,nmf', 0.6874142163999073), ('pca,ica,tsvd,fag', 0.6874916336682666), ('pca,ica,grp,srp', 0.68495477428381735), ('pca,ica,grp,nmf', 0.68444395334924479), ('pca,ica,grp,fag', 0.68445968450240868), ('pca,ica,srp,nmf', 0.68359817404064549), ('pca,ica,srp,fag', 0.68427438373791882), ('pca,ica,nmf,fag', 0.68372534635518956), ('pca,tsvd,grp,srp', 0.68522627464232233), ('pca,tsvd,grp,nmf', 0.68482997343399277), ('pca,tsvd,grp,fag', 0.68402325359793226), ('pca,tsvd,srp,nmf', 0.68451110170905172), ('pca,tsvd,srp,fag', 0.68376345836481944), ('pca,tsvd,nmf,fag', 0.68398845947727116), ('pca,grp,srp,nmf', 0.68057096050452826), ('pca,grp,srp,fag', 0.67936781899772836), ('pca,grp,nmf,fag', 0.67993008733246818), ('pca,srp,nmf,fag', 0.67880641218391258), ('ica,tsvd,grp,srp', 0.68585503201750986), ('ica,tsvd,grp,nmf', 0.68589078222575661), ('ica,tsvd,grp,fag', 0.68442858274152085), ('ica,tsvd,srp,nmf', 0.68625869472926981), ('ica,tsvd,srp,fag', 0.68459204233889182), ('ica,tsvd,nmf,fag', 0.68543928703685419), ('ica,grp,srp,nmf', 0.68184531802094139), ('ica,grp,srp,fag', 0.67948113256494302), ('ica,grp,nmf,fag', 0.68125384869666428), ('ica,srp,nmf,fag', 0.68044986028224808), ('tsvd,grp,srp,nmf', 0.68173625535126525), ('tsvd,grp,srp,fag', 0.67963365320087199), ('tsvd,grp,nmf,fag', 0.68106208115398559), ('tsvd,srp,nmf,fag', 0.68015617202501455), ('grp,srp,nmf,fag', 0.67436036079206474), ('pca,ica,tsvd,grp,srp', 0.68874171502676662), ('pca,ica,tsvd,grp,nmf', 0.68836418911595743), ('pca,ica,tsvd,grp,fag', 0.68823671222257321), ('pca,ica,tsvd,srp,nmf', 0.68718360137081413), ('pca,ica,tsvd,srp,fag', 0.68784143657029118), ('pca,ica,tsvd,nmf,fag', 0.68702839094409329), ('pca,ica,grp,srp,nmf', 0.68542880395930061), ('pca,ica,grp,srp,fag', 0.68580831435591105), ('pca,ica,grp,nmf,fag', 0.68520397140448863), ('pca,ica,srp,nmf,fag', 0.6838153499053613), ('pca,tsvd,grp,srp,nmf', 0.68475418776952801), ('pca,tsvd,grp,srp,fag', 0.68416888261697117), ('pca,tsvd,grp,nmf,fag', 0.68439534926539514), ('pca,tsvd,srp,nmf,fag', 0.68369054844962107), ('pca,grp,srp,nmf,fag', 0.68109487520163592), ('ica,tsvd,grp,srp,nmf', 0.68703175972715047), ('ica,tsvd,grp,srp,fag', 0.68605627429688421), ('ica,tsvd,grp,nmf,fag', 0.68625025013109198), ('ica,tsvd,srp,nmf,fag', 0.68508823305152089), ('ica,grp,srp,nmf,fag', 0.6818608839534277), ('tsvd,grp,srp,nmf,fag', 0.68121711681246844), ('pca,ica,tsvd,grp,srp,nmf', 0.68899654938766397), ('pca,ica,tsvd,grp,srp,fag', 0.68892201689977894), ('pca,ica,tsvd,grp,nmf,fag', 0.68839400442292953), ('pca,ica,tsvd,srp,nmf,fag', 0.68827193462597602), ('pca,ica,grp,srp,nmf,fag', 0.6851006771786381), ('pca,tsvd,grp,srp,nmf,fag', 0.68488975768813187), ('ica,tsvd,grp,srp,nmf,fag', 0.68648750730778907), ('pca,ica,tsvd,grp,srp,nmf,fag', 0.68823319136312078)]", "cell_type": "code", "metadata": {"_cell_guid": "ebecda2a-57c4-44f7-8a53-845438d9b6e9", "trusted": false, "_execution_state": "idle", "_uuid": "33eeea7302b304373f77ca58f2f34b18626201ad", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "x_axis = [c[0] for c in xgb_dr_scores]\ny_axis = [c[1] for c in xgb_dr_scores]\nfig, ax = plt.subplots(figsize=(22, 10))\nplt.plot(y_axis)\nax.set_xticks(range(len(x_axis)))\nax.set_xticklabels(x_axis, rotation='vertical')\nplt.show()", "cell_type": "code", "metadata": {"_cell_guid": "cddd4d58-9701-4e69-ac0e-bd22a2fc9303", "trusted": false, "_execution_state": "idle", "_uuid": "aec2fb99e6282f8b61a9f00f696145dcb64420c8", "collapsed": false}, "outputs": []}, {"execution_count": null, "source": "###Conclusions:###", "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "ff34b8b3625cdef6e8f807b4895e09d3e9d6bbca", "collapsed": false}, "cell_type": "markdown"}, {"execution_count": null, "source": "sorted_id = np.argsort(y_axis)\nprint(\"Combinations which has the lowest score: {}\".format(np.array(x_axis)[sorted_id[:7]]))\nprint(\"Combinations which has the highest score: {}\".format(np.array(x_axis)[sorted_id[-7:]]))\n\nprint(\"\\n\\nBest Score: {}\".format(np.array(x_axis)[sorted_id[-1]]))", "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "8634e1060d83ea66f2535df2000bc584d4c22f0d", "collapsed": false, "trusted": false}, "cell_type": "code"}, {"execution_count": null, "source": "So,  feature agglomeration is really not helping. PCA and ICA are playing the main roles.", "outputs": [], "metadata": {"_execution_state": "idle", "_uuid": "79f7d81b77cbcdd19561159d5674a8aa153632ed", "collapsed": false}, "cell_type": "markdown"}, {"execution_count": null, "source": "###Thanks for the viewing the kernel. Please upvote if you like it :) ###\n\n**Previous kernels:**\n\n - [Categorical exploration  - python notebook][1]\n - [Numerical variable exploration  - treemaps  - R notebook][2] \n\n**Coming up:**\n\n - Autoencoder and t-SNE - dimensionality reduction and denoising\n\n..........\nto be continued\n\n**Update:** \n\n - Added baseline score\n - Added conclusion\n\n\n\n\n  [1]: https://www.kaggle.com/remidi/sherlock-s-exploration-season-01-categorical\n  [2]: https://www.kaggle.com/remidi/sherlocks-exploration-season-02-e01-numerical", "cell_type": "markdown", "metadata": {"_cell_guid": "3cc5ab2b-e277-4556-9f4b-8091b0c496d2", "_execution_state": "idle", "_uuid": "342db8e0f7e16e3aa4ca4fb46083efbc7de64fbe", "collapsed": false}, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}}