{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["# Introduction\n", "The purpose of this notebook is to provide a clean and organized medium for performing an exploration into a [bitcoin dataset](https://www.kaggle.com/mczielinski/bitcoin-historical-data).  The goal of the exploration is to try and create a system that can correctly classify price change predictions of the cryptocurrency.  \n", "\n", "As a template, I will be recreating the work of Amjad and Shah in their paper [Trading Bitcoin and Online Time Series Prediction](http://proceedings.mlr.press/v55/amjad16.pdf)."], "cell_type": "markdown", "metadata": {"_uuid": "b4c99b9a0a772a07f1446284c61802eafc1ab6c8", "_cell_guid": "53146f13-4a86-4e89-b41a-bc55d4df99be"}}, {"source": ["# Read In and Format Data\n", "\n", "The daily closing price is read in from a CSV file.  Lines with NaN or unusual characters are removed."], "cell_type": "markdown", "metadata": {"_uuid": "67465f3c502badb74387572ddc54cdd6ba2b671b", "_cell_guid": "d506f722-8ff6-4080-b201-2931601b2dbe"}}, {"source": ["import pandas as pd \n", "import datetime\n", "\n", "def dateparse (time_in_secs):    \n", "    return datetime.datetime.fromtimestamp(float(time_in_secs))\n", "\n", "dataSetSize = 5000\n", "data = pd.read_csv('../input/btceUSD_1-min_data_2012-01-01_to_2017-05-31.csv', parse_dates=True, date_parser=dateparse, index_col=[0])\n", "data = data[['Close']].apply(pd.to_numeric)\n", "data = data.dropna()\n", "data = data.head(dataSetSize)\n", "\n", "print(data.head())\n", "print('\\nDataset Size:\\t' + str(len(data.index.tolist())))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "7eb6dff98fd07894d851fc5545395769a8e8abeb", "_cell_guid": "f3ff45f7-4a49-4dd1-abd8-54ab96206df6"}, "execution_count": null}, {"source": ["# Plot the Time Series\n", "We plot the time series to provide an initial visualization of the data."], "cell_type": "markdown", "metadata": {"_uuid": "ec10697ee5e8c07767d967722a39713e186f2c6e", "_cell_guid": "08ec2866-e751-4ad0-9db1-58980accfa29"}}, {"source": ["from plotly.offline import init_notebook_mode, iplot\n", "import plotly.graph_objs as go\n", "init_notebook_mode(connected=True)\n", "\n", "layout = go.Layout(\n", "    title='Original Time Series',\n", "    xaxis=dict(title='Time (Minutes)'),\n", "    yaxis=dict(title='USD')\n", ")\n", "\n", "figData = [{'x': [i for i in range(len(data['Close'].tolist()))], 'y': data['Close'].tolist()}]\n", "\n", "fig = go.Figure(data=figData, layout=layout)\n", "\n", "iplot(fig, show_link=False)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "10e10ecc4da1df6ed4b65f9cb65cd6918dc3a05d", "_cell_guid": "02e1db11-6757-443e-8cd9-2f96b3a40c9b"}, "execution_count": null}, {"source": ["# Test if Time Series is Stationary\n", "Run Augmented Dickey-Fuller and KPSS tests to determine whether the time series is stationary.  ADF assumes non-stationarity as the null hypothesis, and KPSS assumes stationarity.  We will use an alpha value of 0.05."], "cell_type": "markdown", "metadata": {"_uuid": "ac624894d316dda1c777141cbc9205134bd72cd9", "_cell_guid": "3fec03d8-257e-4cfe-baa4-3bdb74bcdecb"}}, {"source": ["from statsmodels.tsa.stattools import adfuller\n", "from statsmodels.tsa.stattools import kpss\n", "\n", "def testStationarity(inputData, alphs):\n", "    \n", "    # Augmented Dickey-Fuller Test\n", "    # H0 is non-stationary\n", "    results = adfuller(inputData)\n", "    pValue = results[1]\n", "    if pValue < alpha:\n", "        print('ADF Result: \\t Stationary' + '\\t P-Value: \\t' + str(pValue))\n", "    else:\n", "        print('ADF Result: \\t Non-Stationary' + '\\t P-Value: \\t' + str(pValue))\n", "\n", "    # Kwiatkowski-Phillips-Schmidt-Shin Test\n", "    # H0 is stationary\n", "    results = kpss(inputData)\n", "    pValue = results[1]\n", "    if pValue >= alpha:\n", "        print('KPSS Result: \\t Stationary' + '\\t P-Value: \\t' + str(pValue))\n", "    else:\n", "        print('KPSS Result: \\t Non-Stationary' + '\\t P-Value: \\t' + str(pValue))\n", "\n", "# Define alpha value for hypothesis testing\n", "alpha = 0.05\n", "testStationarity(data['Close'].values, alpha)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "080766f8316f54f494a1c517ab034a9f5f1972a5", "_cell_guid": "c5337be8-e0bb-47ae-b047-0323e170346d"}, "execution_count": null}, {"source": ["# Apply First-Differences to the Closing Price\n", "Applying first-differences is when you transform the time series doing `data[t] = data[t] - data[t-1]`.  Differencing the time series in this way is a common method for achieving stationarity."], "cell_type": "markdown", "metadata": {"_uuid": "a2e7bb556f23bcbd33141b02f469be8d1050f547", "_cell_guid": "b2178718-e277-46ef-b339-c76eb8152cdf"}}, {"source": ["# Calculate different orders of difference in closing price\n", "def calculateDifferences(data, numDifs):\n", "    if numDifs == 0:\n", "        keyColumn = 'Close'\n", "    else:\n", "        keyColumn = str(numDifs) + '_Dif'\n", "    for i in range(1, numDifs+1):\n", "        if i == 1:\n", "            data[str(i) + '_Dif'] = data['Close'] - data['Close'].shift(1)\n", "        else:\n", "            data[str(i) + '_Dif'] = data[str(i-1) + '_Dif'] - data[str(i-1) + '_Dif'].shift(1)\n", "    data = data.dropna()\n", "    return data, keyColumn\n", "\n", "numDifs = 1\n", "data, keyColumn = calculateDifferences(data, numDifs)\n", "\n", "print(data.head())"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a8cad4bf8f2cafd27c4d2e08044fbc7d8b342a18", "_cell_guid": "fc7a8f8d-2cd0-4c03-89e4-9afbd08100c6"}, "execution_count": null}, {"source": ["# Test if Time Series (w/ First-Differences) is Stationary\n", "Run Augmented Dickey-Fuller and KPSS tests to determine whether the time series is stationary.  ADF assumes non-stationarity as the null hypothesis, and KPSS assumes stationarity.  We will use an alpha value of 0.05."], "cell_type": "markdown", "metadata": {"_uuid": "383bc828b45dc14457c3074007172c683cf745f5", "_cell_guid": "e579983a-81c5-4ea8-acc7-074c40ac9ed2"}}, {"source": ["testStationarity(data[keyColumn].values, alpha)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "fc73b4272a3c49bbd3294cb339544f22155dcf60", "_cell_guid": "d19f4f38-d3ab-4e4f-8023-7e05f9c97d85"}, "execution_count": null}, {"source": ["# Plot the Differenced Time Series\n", "We will now plot the differenced time series, so we have a visualization of the transformation."], "cell_type": "markdown", "metadata": {"_uuid": "37643545f5f95c0b5a611bcb8bff51aaa7bbe569", "_cell_guid": "df9449f4-2c0e-44f0-b2ec-d614187a3a71"}}, {"source": ["layout = go.Layout(\n", "    title='Differenced Time Series (' + str(keyColumn) + ')',\n", "    xaxis=dict(title='Time (Minutes)'),\n", "    yaxis=dict(title='USD')\n", ")\n", "\n", "figData = [{'x': [i for i in range(len(data[keyColumn].tolist()))], 'y': data[keyColumn].tolist()}]\n", "\n", "fig = go.Figure(data=figData, layout=layout)\n", "\n", "iplot(fig, show_link=False)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "a09c4da87e3ad342ce51390ddb426ff4df337586", "_cell_guid": "d8db1c50-973d-4e10-b608-c211826ae91e"}, "execution_count": null}, {"source": ["# Results So Far (1)\n", "So far, we have read in the data for the daily closing price of bitcoin.  We found that the baseline dataset was not stationary, but that the differenced dataset was.  Now, we will try to visualize the differenced dataset using a histogram."], "cell_type": "markdown", "metadata": {"_uuid": "4542a4bb7a91e998f355db1680f86b8c70c64f9a", "_cell_guid": "2ac93da8-b297-418a-bedb-4dd0813ea606"}}, {"source": ["# Histogram of Time Series (w/ First-Differences)\n", "We are plotting a histogram of the differenced time series to visualize whether the dataset appears to be Gaussian."], "cell_type": "markdown", "metadata": {"_uuid": "58226e2c800221131e952495194380b2c3bc6b9d", "_cell_guid": "18076517-7bf7-47a5-a1bd-dd3503521624"}}, {"source": ["%matplotlib inline\n", "hist = data[keyColumn].hist(bins=50)\n", "hist.set_title(\"Histogram of Changes in Closing Price\")\n", "hist.set_xlabel(\"Difference in Closing Price (USD)\")\n", "hist.set_ylabel(\"Number of Minutes\")"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "cff82098acf238cf63799732492f0ef15dfce5a9", "_cell_guid": "a4c3cc8e-8c21-4f76-99cc-651c2d841f41"}, "execution_count": null}, {"source": ["# QQ Plot of Time Series (w/ First-Differences)\n", "We will make a QQ plot to get a better idea if the distribution is indeed Gaussian.  If the points fall (mostly) along a 45 degree red line, that will be a strong indicator that the distribution is Gaussian."], "cell_type": "markdown", "metadata": {"_uuid": "b333880827c2919e4e3fa83ada03c6f6ed4859ab", "_cell_guid": "9f4417c6-ab88-435e-830f-dffcbc301a80"}}, {"source": ["from scipy import stats\n", "import pylab \n", "stats.probplot(data[keyColumn].values, dist='norm', plot=pylab)\n", "pylab.show()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "87dadde7d8f792b250c851ea3ce3636c033f19f6", "_cell_guid": "52be605d-4c54-4c07-9bae-70fec03fbc34"}, "execution_count": null}, {"source": ["# Do KS Test to Determine if Time Series (w/ First-Differences) is Gaussian\n", "The histogram and QQ plot seem to show that the time series not Guassian.  To be sure, we will run the Kolmogorov-Smirnov test to answer this question decisively, using an alpha value of 0.05."], "cell_type": "markdown", "metadata": {"_uuid": "cba21dd701b003d672d4a6a379d6b4832e29c1b4", "_cell_guid": "cd3b8fe9-5556-444c-9317-25611c13a74c"}}, {"source": ["# Kolmogorov-Smirnov Test\n", "# H0 is that both distributions are identical\n", "results = stats.kstest(data[keyColumn].values, 'norm')\n", "pValue = results[1]\n", "if pValue >= alpha:\n", "    print('KS Result: \\t Gaussian' + '\\t P-Value: \\t' + str(pValue))\n", "else:\n", "    print('KS Result: \\t Non-Gaussian' + '\\t P-Value: \\t' + str(pValue))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "22ee268a520482c44a5c205a590e46de90787582", "_cell_guid": "f7ef6846-0402-43f4-a830-265642d0af28"}, "execution_count": null}, {"source": ["# Results So Far (2)\n", "We have determined that the differenced time series is not a Gaussian distribution.  The QQ plot suggests that the differenced time series is a \"thinner\" distribution than the Gaussian."], "cell_type": "markdown", "metadata": {"_uuid": "14968c8097f70ce6a511f8bf229adcccf3721ea5", "_cell_guid": "77777de9-9e78-43d4-8b09-114cfaa2bb71"}}, {"source": ["# Plot the Autocorrelation / Partial Autocorrelation Functions\n", "These plots will visualize the the dependence of the time series on the past.  We are hoping for two things:\n", "\n", "1.  That the time series only depends on the recent past, as this implies mixing.\n", "2.  That the time series show exponential decay, as this implies mixing.\n", "\n", "A quote form the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/visualization.html#autocorrelation-plot):\n", "\n", "\"If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero.\" \n", "\n", "The blue hilight region displayed in the plot corresponds to the 95% confidence bands."], "cell_type": "markdown", "metadata": {"_uuid": "238fb4fa96ea899783421ac85b3ad67395339546", "_cell_guid": "984e8d52-e86b-4468-863d-ffb3033472bc"}}, {"source": ["from statsmodels.graphics.tsaplots import plot_acf\n", "import matplotlib.pyplot as pyplot\n", "plot_acf(data[keyColumn])\n", "pylab.xlim([0, 50])\n", "pylab.ylim([-0.2, 0.2])\n", "pyplot.show()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "791f9489b6ae040cfcda33757fa4df9eba04b1f1", "_cell_guid": "c765520d-21a0-4dca-92d0-c39003b0edca"}, "execution_count": null}, {"source": ["## Partial Autocorrelaiton\n", "Below is the code to run partial autocorrelation.  Do not do this unless you have time to spare, as it takes forever.  To improve runtime, I have taken the PACF of a subset (via `head()`) of the data."], "cell_type": "markdown", "metadata": {"_uuid": "d77597cd56e608c8a344f6601ba199c19e5d836f", "_cell_guid": "5f6f5cfe-1f08-4a4f-be9b-d54e5106e93f"}}, {"source": ["from statsmodels.graphics.tsaplots import plot_pacf\n", "plot_pacf(data[keyColumn].head(100))\n", "pylab.xlim([0, 100])\n", "pylab.ylim([-0.8, 0.8])\n", "pyplot.show()"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "582ab9fb5b9511faae1b6b4f3c85cf86029d4692", "_cell_guid": "a669855c-76d6-4da3-9eb0-ca019ba354ad"}, "execution_count": null}, {"source": ["# Results So Far (3)\n", "We have plotted the autocorrelation and partial autocorrelation.  Both plots seem to imply that the very earliest lags are statistically significant.  Both plots seem to show that esponential-esque decay is occuring and that widely-separated times are asymptotically independent.  This implies mixing.\n", "\n", "Next, we will add in the custom features specified by Amjad and Shah on page 6, and will form our feature vectors."], "cell_type": "markdown", "metadata": {"_uuid": "6747a9fa4c5ec11d8c200ace5b4be6a1665bc87e", "_cell_guid": "95388cfc-10a5-4437-a4f5-27beaeb40561"}}, {"source": ["# Extracting Features & Forming Feature Vectors\n", "Here, we will extract the three features described on pg. 6 of Amjad and Shah's paper.  These are:\n", "\n", "1. The class of at data[t-1]\n", "2. The tally count for each class in the past d time steps\n", "3. The maximum consecutive run-length for each class in the past d time steps"], "cell_type": "markdown", "metadata": {"_uuid": "3a4e134aeff7cccf6bc5e391e5abd3ab4fcef3ec", "_cell_guid": "65dbaf1a-d5ad-4d30-b551-5b38b38d26b3"}}, {"source": ["from itertools import groupby\n", "\n", "# Define the transaction fee (theta), and number of previous time steps to use (d)\n", "theta = 0.000\n", "d = 4\n", "\n", "# Calculate the class at each timestamp\n", "data['Class'] = data[keyColumn].apply(lambda x: 1 if x>theta else -1 if x<(-1*theta) else 0)\n", "\n", "# Extract the class at data[t-1]\n", "data['Previous_Class'] = data['Class'].shift(1)\n", "\n", "# Extract the tally count for each class in the past d time steps\n", "data['Class_-1_Tally'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: sum([1 for i in x if i == -1]))\n", "data['Class_0_Tally'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: sum([1 for i in x if i == 0]))\n", "data['Class_1_Tally'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: sum([1 for i in x if i == 1]))\n", "\n", "# Extract the maximum consecutive run-length for each classin the past d time steps\n", "def getLongestRun(x, val):\n", "    groupedX = [sum(1 for i in g) for k, g in groupby(x) if k == val]\n", "    if groupedX == []:\n", "        longestRun = 0\n", "    else:\n", "        longestRun = max(groupedX)\n", "    return longestRun\n", "data['Class_-1_Consec'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: getLongestRun(x, -1))\n", "data['Class_0_Consec'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: getLongestRun(x, 0))\n", "data['Class_1_Consec'] = data['Class'].shift(1).rolling(window=d).apply(lambda x: getLongestRun(x, 1))\n", "\n", "# Clean the data\n", "data = data[['Class', 'Previous_Class', 'Class_-1_Tally', 'Class_0_Tally', 'Class_1_Tally', 'Class_-1_Consec', 'Class_0_Consec', 'Class_1_Consec']]\n", "data = data.dropna()\n", "\n", "print(data.head())"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "653104a064ab55ceb83ec34e00890a27b533c640", "_cell_guid": "5e4139f9-9a2e-409b-aac9-3d945dc8d341"}, "execution_count": null}, {"source": ["# Create Training, Validation, and Test Set\n", "It is now time to divide the data set into three pieces: a training, validation, and test set.  The data will be split into 60/20/20 proportions, as is common when using a validation set."], "cell_type": "markdown", "metadata": {"_uuid": "9c991055b787be7987343bed525fedec186f03e7", "_cell_guid": "36b70171-accf-4893-9087-a0a149ebfef2"}}, {"source": ["timestamps = data.index.tolist()\n", "\n", "trainValSplit = timestamps[round(len(timestamps) * 0.6)]\n", "valTestSplit = timestamps[round(len(timestamps) * 0.8)]\n", "\n", "train = data.loc[:trainValSplit]\n", "validation = data.loc[trainValSplit:valTestSplit]\n", "test = data.loc[valTestSplit:]\n", "\n", "print('Training Set Size: \\t' + str(len(train)))\n", "print('Validation Set Size: \\t' + str(len(validation)))\n", "print('Test Size: \\t\\t' + str(len(test)))"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "64e9e89267f87162dda6c7332213b17e9d5f1dff", "_cell_guid": "d15cb58c-8b21-46d6-8d2f-adf408dc553d"}, "execution_count": null}, {"source": ["# Train the Classifiers\n", "Now, we will train Logistic Regression and Random Forest classifiers."], "cell_type": "markdown", "metadata": {"_uuid": "bf60852c6b4ace6e0b867d73e9233daaa9ce30a5", "_cell_guid": "c79d25d8-2844-483f-9644-f4d4deefb0bf"}}, {"source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "\n", "y_train = train['Class'].values\n", "X_train = train.drop(['Class'], axis=1).values\n", "\n", "lr = LogisticRegression(class_weight='balanced')\n", "lr.fit(X_train, y_train)\n", "\n", "rf = RandomForestClassifier()\n", "rf.fit(X_train, y_train)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "4554edd34b9a4b78fa844b1ac15ab08a3f3dbe70", "_cell_guid": "78e652ce-5963-458e-a2c8-bd03992e4ff5"}, "execution_count": null}, {"source": ["# Determine Threshold Quality Estimator\n", "We now tune the parameter gamma, which represents the threshold confidence a classifier must have for its prediction to be considered.  Amjad and Shah note, quite brilliantly, that there is an inverse relationship between the accuracy of the classifiers, and the number of trades the classifier recommends.  Gamma should therefore be chosen to maximize the product of these two values."], "cell_type": "markdown", "metadata": {"_uuid": "45fb526d77dc752b74a508f438cbc54a1e44650e", "_cell_guid": "5675b282-7ac8-4bc8-af32-e829f9f86392"}}, {"source": ["import numpy as np\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.metrics import precision_recall_fscore_support\n", "\n", "def getGammaByAccuracy(clf, clfName, X_val, y_val):\n", "    y_pp = clf.predict_proba(X_val)\n", "    results = []\n", "    gammaRange = np.linspace(0, 1, num=100)\n", "    for gamma in gammaRange:\n", "        acceptedPredictionIndicies = [i for i in range(len(y_pp)) if (max(y_pp[i]) > gamma)]\n", "            \n", "        if acceptedPredictionIndicies != []:\n", "            subX_val = [X_val[i] for i in acceptedPredictionIndicies]\n", "            subY_val = [y_val[i] for i in acceptedPredictionIndicies]\n", "                        \n", "            # Parse out the instances where 0 was predicted\n", "            subY_pred = clf.predict(subX_val)\n", "            keepIndicies = [i for i in range(len(subY_pred)) if subY_pred[i] != 0]\n", "            subY_pred_parsed = [subY_pred[i] for i in keepIndicies]\n", "            subY_val_parsed = [subY_val[i] for i in keepIndicies]\n", "            \n", "            # Calculate Metrics\n", "            accuracy = accuracy_score(subY_val_parsed, subY_pred_parsed)\n", "            precision, recall, fscore, support = precision_recall_fscore_support(subY_val_parsed, subY_pred_parsed, labels=[-1, 0, 1])\n", "            product = accuracy * len(acceptedPredictionIndicies)\n", "            results.append((product, gamma, accuracy, len(acceptedPredictionIndicies), precision, recall, fscore, support))\n", "            \n", "        else:\n", "            break\n", "    product, gamma, accuracy, numPredictions, precision, recall, fscore, support = max(results)\n", "\n", "    print('\\n' + clfName + ' Results')\n", "    print('Product: \\t\\t' + str(product))\n", "    print('Gamma: \\t\\t\\t' + str(gamma))\n", "    print('Accuracy: \\t\\t' + str(accuracy)) \n", "    print('Num Predictions: \\t' + str(numPredictions))\n", "    print('Precision: \\t\\t' + str(precision)) \n", "    print('Recall: \\t\\t' + str(recall)) \n", "    print('F-Score: \\t\\t' + str(fscore)) \n", "    print('support: \\t\\t' + str(support)) \n", "    \n", "    return gamma\n", "    \n", "y_val = validation['Class'].values\n", "X_val = validation.drop(['Class'], axis=1).values\n", "\n", "lrGamma = getGammaByAccuracy(lr, 'Logistic Regression', X_val, y_val)\n", "rfGamma = getGammaByAccuracy(rf, 'Random Forest', X_val, y_val)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "80563ff535ab50a131148e9e9ce43163d19d2e48", "_cell_guid": "a4a51a61-98fd-4afa-9f57-0e28b687e0a8"}, "execution_count": null}, {"source": ["# Determine Threshold Quality Estimator (My Way)\n", "Amjad and Shah sought to maximize the product of accuracy and the number of trades.  Accuracy is a risky metric to use for the goodness of a classifier, as it is not always reliable when classes are imbalanced.  For that reason, I believe a better metric to use would be the product of the precisions for class -1 and +1.  Using this figure rather than accuracy will guarentee that the gamma chosen will maximize the precision of our classifier on the relevant classes."], "cell_type": "markdown", "metadata": {"_uuid": "bb2e46cbebdca8c6c7296823fcbadc60386c2060", "_cell_guid": "9d0c6404-8daf-4eda-af26-31c31fc7b475"}}, {"source": ["def getGammaByPrecision(clf, clfName, X_val, y_val):\n", "    y_pp = clf.predict_proba(X_val)\n", "    results = []\n", "    gammaRange = np.linspace(0, 1, num=100)\n", "    for gamma in gammaRange:\n", "        acceptedPredictionIndicies = [i for i in range(len(y_pp)) if (max(y_pp[i]) > gamma)]\n", "        if acceptedPredictionIndicies != []:\n", "            subX_val = [X_val[i] for i in acceptedPredictionIndicies]\n", "            subY_val = [y_val[i] for i in acceptedPredictionIndicies]\n", "                        \n", "            # Parse out the instances where 0 was predicted\n", "            subY_pred = clf.predict(subX_val)\n", "            keepIndicies = [i for i in range(len(subY_pred)) if subY_pred[i] != 0]\n", "            subY_pred_parsed = [subY_pred[i] for i in keepIndicies]\n", "            subY_val_parsed = [subY_val[i] for i in keepIndicies]\n", "            \n", "            # Calculate Metrics\n", "            accuracy = accuracy_score(subY_val_parsed, subY_pred_parsed)\n", "            precision, recall, fscore, support = precision_recall_fscore_support(subY_val_parsed, subY_pred_parsed, labels=[-1, 0, 1])\n", "            product = precision[0] * precision[2] * len(acceptedPredictionIndicies)\n", "            results.append((product, gamma, accuracy, len(acceptedPredictionIndicies), precision, recall, fscore, support))\n", "            \n", "        else:\n", "            break\n", "    product, gamma, accuracy, numPredictions, precision, recall, fscore, support = max(results)\n", "    \n", "    print('\\n' + clfName + ' Results')\n", "    print('Product: \\t\\t' + str(product))\n", "    print('Gamma: \\t\\t\\t' + str(gamma))\n", "    print('Accuracy: \\t\\t' + str(accuracy)) \n", "    print('Num Predictions: \\t' + str(numPredictions))\n", "    print('Precision: \\t\\t' + str(precision)) \n", "    print('Recall: \\t\\t' + str(recall)) \n", "    print('F-Score: \\t\\t' + str(fscore)) \n", "    print('support: \\t\\t' + str(support)) \n", "    \n", "    return gamma\n", "    \n", "y_val = validation['Class'].values\n", "X_val = validation.drop(['Class'], axis=1).values\n", "\n", "lrGamma = getGammaByPrecision(lr, 'Logistic Regression', X_val, y_val)\n", "rfGamma = getGammaByPrecision(rf, 'Random Forest', X_val, y_val)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "37405bc3294a738e09dac35a9b1bb4da6fed7f03", "_cell_guid": "20ddb3bd-d18e-4464-a644-ff4a07e656a8"}, "execution_count": null}, {"source": ["# Results So Far (4)\n", "The results at this point are not looking good.  Both methods of selecting gamma appear to have yielded the same results.  My thoughts on these results are as follows:\n", "\n", "- Accuracy: Neither Logistic Regression nor Random Forest was able to achieve an accuracy over 50%.\n", "- Logistic Regression: This classifier is has reasonable recall for each class, but poor precision.\n", "- Random Forest: This classifier has poor precision, and a recall that clearly favors the +1 class."], "cell_type": "markdown", "metadata": {"_uuid": "71469178d88498b2ed246ae2e8f65edd2552ce5f", "_cell_guid": "52bec23c-8472-400b-a641-c551178502d3"}}, {"source": ["# Results on Test Set\n", "Now, we will run our trained classifiers on the test set.  In evaluating the classifiers, we will calculate the classification accuracy as Amjad and Shah did.  Additionally, we will calculate the precision, recall, and F-score, as these metrics provide a more complete picture of the classifier's performance."], "cell_type": "markdown", "metadata": {"_uuid": "d00fa14d4417cbac5634a0ece9c60741f19c51c5", "_cell_guid": "3c6f0263-8ef5-43b3-a915-fae1d4ac76a7"}}, {"source": ["def testPerformance(clf, gamma, clfName, X_test, y_test, timestamps):\n", "    \n", "    # Parse out predicitons that don't meet gamma value\n", "    y_pp = clf.predict_proba(X_test)\n", "    acceptedPredictionIndicies = [i for i in range(len(y_pp)) if (max(y_pp[i]) > gamma)]\n", "    subX_test = [X_test[i] for i in acceptedPredictionIndicies]\n", "    subY_test = [y_test[i] for i in acceptedPredictionIndicies]\n", "    subTimestamps = [timestamps[i] for i in acceptedPredictionIndicies]\n", "    \n", "    # Parse out the instances where 0 was predicted\n", "    subY_pred = clf.predict(subX_test)\n", "    keepIndicies = [i for i in range(len(subY_pred)) if subY_pred[i] != 0]\n", "    subY_pred_parsed = [subY_pred[i] for i in keepIndicies]\n", "    subY_test_parsed = [subY_test[i] for i in keepIndicies]\n", "    subTimestamps_parsed = [subTimestamps[i] for i in keepIndicies]\n", "    \n", "    # Calculate Metrics\n", "    accuracy = accuracy_score(subY_test_parsed, subY_pred_parsed)\n", "    precision, recall, fscore, support = precision_recall_fscore_support(subY_test_parsed, subY_pred_parsed)\n", "\n", "    # Print Metrics\n", "    print('\\n' + clfName + ' Results')\n", "    print('Accuracy: \\t\\t' + str(accuracy))\n", "    print('Precision: \\t\\t' + str(precision))\n", "    print('Recall: \\t\\t' + str(recall)) \n", "    print('F-Score: \\t\\t' + str(recall))\n", "    print('Support: \\t\\t' + str(support))\n", "    \n", "    # Return predictions, true classes, and timestamps\n", "    return (subY_pred_parsed, subY_test_parsed, subTimestamps_parsed)\n", "\n", "timestamps = test.index.tolist()\n", "y_test = test['Class'].values\n", "X_test = test.drop(['Class'], axis=1).values\n", "\n", "lrResults = testPerformance(lr, lrGamma, 'Logistic Regression', X_test, y_test, timestamps)\n", "rfResults = testPerformance(rf, rfGamma, 'Random Forest', X_test, y_test, timestamps)"], "outputs": [], "cell_type": "code", "metadata": {"_uuid": "9b0ac98c5944b3102762529490d95a2696b9b31a", "_cell_guid": "3afa500d-e6a1-4b76-a897-bc8ee167ab25"}, "execution_count": null}, {"source": ["# Conclusion\n", "When it came to the test set, the results were unimpressive.  Both classifiers have poor precision and accuracy.  The best attribute present is the recall of Logistic Regression, which sadly dipped below 50% for the -1 class.  All things considered, I believe this shows that the [results](http://proceedings.mlr.press/v55/amjad16.pdf) of Amjad and Shah were not reproducable."], "cell_type": "markdown", "metadata": {"_uuid": "1ca05bc5ef67ebbaca467695c8796539617a8d38", "_cell_guid": "3132ee2e-5796-4095-be11-f4321d3b53ab"}}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1", "file_extension": ".py", "mimetype": "text/x-python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}}