{"nbformat_minor": 1, "metadata": {"language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "file_extension": ".py", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": ["**In this NLP Tutorial , I will explore the Pipeline capabilities of Scikit learn to identify Toxic messages provided in this dataset.**   <br>\n", "\n", "Note:- I will revisit this Notebook again for amendments \n", "\n"], "metadata": {"_uuid": "668ac9c415dc05d6a74e5623658b18e0d1b8951a", "_cell_guid": "8bab832a-1491-47a4-b0f4-232bc76ef1db"}}, {"execution_count": null, "cell_type": "code", "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import matplotlib.gridspec as gridspec\n", "import gc\n", "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.feature_extraction.text import TfidfTransformer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.model_selection import StratifiedKFold\n", "from sklearn.decomposition import TruncatedSVD\n", "from sklearn.metrics import log_loss,confusion_matrix,classification_report,roc_curve,auc\n", "import string\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk.tokenize import word_tokenize\n", "from scipy import sparse\n", "%matplotlib inline\n", "seed = 2390"], "outputs": [], "metadata": {"_uuid": "93f9326488b4c6724dd0dbb117e77d0819909e5e", "_cell_guid": "83555156-a945-4f8f-8630-5abad98d9013", "collapsed": true}}, {"cell_type": "markdown", "source": ["Import Train and Test dataset "], "metadata": {"_uuid": "1a2fc94e2d4ca62083518be288a8dff5187eba3c", "_cell_guid": "07871fea-ba36-4be3-9ba3-8ae392946aa7"}}, {"execution_count": null, "cell_type": "code", "source": ["train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')\n", "train.head()"], "outputs": [], "metadata": {"_uuid": "73fcc44d9e4781aed5d3353e775d2ed893cf00ed", "_cell_guid": "7b1fb189-e4cd-49bd-a59e-c420e16a78fb", "collapsed": true}}, {"cell_type": "markdown", "source": ["What kind of messages we will be dealing with\n", "               ----\n", " > Check few messages"], "metadata": {"_uuid": "b2036f54165696dc8c07bf827c548d9dc8b085c1", "_cell_guid": "7ea44b4f-5650-4ca9-87cd-a12f4f3b9382"}}, {"execution_count": null, "cell_type": "code", "source": ["for message_no, message in enumerate(train['comment_text'][:10]):\n", "    print(message_no, message)\n", "    print('\\n')"], "outputs": [], "metadata": {"_uuid": "728699975bfee87610e436823ac7b41103c69ac8", "_cell_guid": "4bf27ae5-e9f6-4b74-8743-66f42f796f30", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["'''\n", "Messtype1 = train[['comment_text','toxic']]\n", "Messtype2 = train[['comment_text','severe_toxic']]\n", "Messtype3 = train[['comment_text','obscene']]\n", "Messtype4 = train[['comment_text','threat']]\n", "Messtype5 = train[['comment_text','insult']]\n", "Messtype6 = train[['comment_text','identity_hate']]\n", "''';"], "outputs": [], "metadata": {"_kg_hide-input": true, "_uuid": "e3f2840ea439e5e88102f536dba9bf46c17fabfc", "_cell_guid": "16363e86-d43a-4386-8d1b-0722a4e12ab1", "collapsed": true}}, {"cell_type": "markdown", "source": ["We have total 6 classification types of the messages and these message can be Toxic and severe_Toxic or Toxic and Insulting in nature at the same time so  to differentiate the message type we have seperate columns to identify those <br>\n", "1.  toxic <br>\n", "2. severe_toxic <br>\n", "3. obscene <br>\n", "4. threat <br>\n", "5. insult <br>\n", "6. identity_hate"], "metadata": {"_uuid": "6c83ea10ef45a7c90830bf5e6a030febe704c731", "_cell_guid": "d2b4be35-37cc-4ea0-abb7-0ecc7a2d6028"}}, {"execution_count": null, "cell_type": "code", "source": ["cols= ['toxic', 'severe_toxic', 'obscene', 'threat',\n", "       'insult', 'identity_hate']\n", "\n", "plt.figure(figsize=(14,8))\n", "gs = gridspec.GridSpec(2,3)\n", "for i, cn in enumerate(cols):\n", "    ax = plt.subplot(gs[i])\n", "    sns.countplot(y = cn , data = train)\n", "    ax.set_xlabel('')\n", "    ax.set_title(str(cn))\n", "    ax.set_ylabel(' ')"], "outputs": [], "metadata": {"_uuid": "3dd28cdaae3b741b53429ac05553320c01588b0d", "_cell_guid": "da964b99-0616-43e7-ae6e-bcac953f865e", "collapsed": true}}, {"cell_type": "markdown", "source": ["Lets check Correlation between the Message types"], "metadata": {"_uuid": "92af3a58329a08a1e0d94e5ea8427430c26daacc", "_cell_guid": "10c3e989-37ef-40b8-8c87-d8c32fbbce30"}}, {"execution_count": null, "cell_type": "code", "source": ["plt.figure(figsize=(14,6))\n", "sns.heatmap(train[['toxic', 'severe_toxic', 'obscene', 'threat',\n", "       'insult', 'identity_hate']].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\");"], "outputs": [], "metadata": {"_uuid": "8bbceb643665ea7fbfcec93d2183e65a7ac35618", "_cell_guid": "699705f7-d235-4b44-92fa-2aafbfe833db", "collapsed": true}}, {"cell_type": "markdown", "source": ["1) Insult and Obscene remarks are strongly corelated here <br>\n", "2) Toxic and Obscene remarks \n", "2) Next is Toxic and insulting remarks "], "metadata": {"_uuid": "3741fb56645be2af41b6060081c01b5f8c2bdac2", "_cell_guid": "3f33d064-dca3-49f9-9173-95215a5ad298"}}, {"cell_type": "markdown", "source": ["Lets start building our prediction model on Train dataset to identify Toxic remarks \n", "             ----\n", "> You can come up with innovative way to reuse the below model to identify rest of the message types which are 'severe_toxic', 'obscene', 'threat', 'insult' and  'identity_hate'"], "metadata": {"_uuid": "65a73cfa846d3937196d9a52a5bbb4b8eea49923", "_cell_guid": "86de2ce5-280b-43ef-98f6-2d3ba4b1373d"}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1 = train[['comment_text','toxic']]\n", "#Messtype1['length'] = Messtype1['comment_text'].apply(len)\n", "Messtype1['length'] = Messtype1['comment_text'].str.split().apply(len)\n", "Messtype1.head()"], "outputs": [], "metadata": {"_uuid": "b4bdac7a3d65b23a575962d091b4dd25bf45faa1", "_cell_guid": "88b1c58f-2fcc-4c9a-82a9-eb7d70a1b61e", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1['length'].plot(bins=50, kind='hist');"], "outputs": [], "metadata": {"_uuid": "707effb38cdb700e85177bf803b9d347310e9401", "_cell_guid": "dca06e8c-0d4e-481b-9a77-dba3a42c7c63", "collapsed": true}}, {"cell_type": "markdown", "source": ["We have really long messages here upto length of 5000 words . Lets quickly check."], "metadata": {"_uuid": "cbf4a8239af12d73098c4768a2a39d4ad6d51e75", "_cell_guid": "8423100d-8b22-4d41-a145-63196ae8448f"}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1.length.describe()"], "outputs": [], "metadata": {"_uuid": "df4080ab9917f55145bd8b2d38eae39c8596718f", "_cell_guid": "d1fa4fd3-6705-45a2-b86f-38f364fa541b", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1[Messtype1['length'] == 1411]['comment_text'].iloc[0]"], "outputs": [], "metadata": {"_uuid": "c19661c41794a8c12812d5a01c3a4b35c5a4dbd2", "_cell_guid": "5b3441ff-21d9-4394-bdb9-8ebf3a7ff7aa", "collapsed": true}}, {"cell_type": "markdown", "source": ["Whoever wrote above text is in urgent need of medical help. :D\n", "              --"], "metadata": {"_uuid": "b03de23cb99926fc9050a3dea0a667eca28c383e", "_cell_guid": "274ecf37-bf94-49f0-b6b2-69b2aa702dbd"}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1.hist(column='length', by='toxic', bins=50,figsize=(12,4));"], "outputs": [], "metadata": {"_uuid": "260b76f5ff348b5ca407f6284903c5f9b73b1c00", "_cell_guid": "cf1bc3e3-5ef7-4ac4-92ae-c346fc1c9c54", "collapsed": true}}, {"cell_type": "markdown", "source": ["Nothing interesting found in above graph .Length of Toxic comments is not of major hep in this case."], "metadata": {"_uuid": "249f22b37adc347786979dfc603fec2e552de0f4", "_cell_guid": "4804240f-a4fd-4c16-81b6-a359fca6cccc"}}, {"cell_type": "markdown", "source": ["Lets build a function for Text Pre-Processing to perform below activities \n", "               ---\n", " \n", "    1. Remove all punctuation\n", "    2. Remove all stopwords\n", "    3. Return a list of the cleaned text\n", "    "], "metadata": {"_uuid": "43ffcf32334fbe5f2e9d3e906b9ca712ee51d8cc", "_cell_guid": "037855d7-bfeb-4697-90aa-c07809791e7e"}}, {"execution_count": null, "cell_type": "code", "source": ["def text_process(mess):\n", "    # Check characters to see if they are in punctuation\n", "    nopunc = [char for char in mess if char not in string.punctuation]\n", "    # Join the characters again to form the string.\n", "    nopunc = ''.join(nopunc)\n", "    # Now just remove any stopwords\n", "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"], "outputs": [], "metadata": {"_uuid": "191fe47fe610e684dd747180bc9d454462cf0ebc", "_cell_guid": "90d428ec-4853-4bbd-8931-1615ee52a5b3", "collapsed": true}}, {"cell_type": "markdown", "source": ["Lets check if above function is working properly or not\n", "               -----"], "metadata": {"_uuid": "030393bd14082ebdeb0e9dfc4497a86797aa66d2", "_cell_guid": "885a2d46-ba21-4142-8f49-89f55f82dabd"}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1['comment_text'].head(5).apply(text_process)"], "outputs": [], "metadata": {"_uuid": "0138760e6c5cda99886e1bc6bcd8189cef2b9c3c", "_cell_guid": "3f378675-d508-4339-9166-be1af231e1fb", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["Messtype1.head()"], "outputs": [], "metadata": {"_uuid": "d64f46bff04dcc30a05e2335fc6e68df9deacbdd", "_cell_guid": "57ff3d93-3ed0-4481-98c2-cbad87c6cacf", "collapsed": true}}, {"cell_type": "markdown", "source": ["Check the above differences which assures that our function is working properly\n", "     ----"], "metadata": {"_uuid": "32d60b376e78074e9641feea2bab8ddfa122753b", "_cell_guid": "682151f6-233e-4e19-80e0-7fdf18f6ccf4"}}, {"cell_type": "markdown", "source": ["Customize below small rough model on your desktop to train full dataset and use it on test dataset for prediction.\n", "                   ---"], "metadata": {"_uuid": "d0b5ace6e75c860b46b238ad965ee2e7279091e5", "_cell_guid": "d74645c1-0228-4d05-b019-b2f842826e52"}}, {"execution_count": null, "cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "\n", "msg_train, msg_test, label_train, label_test = \\\n", "train_test_split(Messtype1['comment_text'], Messtype1['toxic'], test_size=0.2)\n", "\n", "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"], "outputs": [], "metadata": {"_uuid": "0b941f523bddff1548784f4f1e275105e64bffc6", "_cell_guid": "6911de62-f2c2-40b1-8eed-6075bd36738c", "collapsed": true}}, {"cell_type": "markdown", "source": ["SciKit Learn's pipeline capabilities along with the function we just built above\n", "          ----"], "metadata": {"_uuid": "2804548c1da22c99ad60345c28db7443502a69fa", "_cell_guid": "2d067385-1e16-4eaa-9bea-952dfb5fc1c4"}}, {"execution_count": null, "cell_type": "code", "source": ["pipeline = Pipeline([\n", "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n", "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n", "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n", "])"], "outputs": [], "metadata": {"_uuid": "c694e6c14846ba43f08bb985f2bd29f655be296b", "_cell_guid": "3e4d2375-a606-4ade-9b1f-b3e54d629ad6", "collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": ["pipeline.fit(msg_train,label_train)\n", "predictions = pipeline.predict(msg_test)"], "outputs": [], "metadata": {"_uuid": "b3639c0601bdce1f261f33e16c02273f1f012769", "_cell_guid": "e9d07a8c-45f6-4d4b-b509-c6a1dce9c30b", "collapsed": true}}, {"cell_type": "markdown", "source": ["Classification report to identify Toxic comments\n", "         ---"], "metadata": {"_uuid": "3d24bc1897e2649cb3dd1b77eb150e800d23c89f", "_cell_guid": "5d492b2e-4964-4a88-be08-0d67119f6ea4"}}, {"execution_count": null, "cell_type": "code", "source": ["print(classification_report(predictions,label_test))"], "outputs": [], "metadata": {"_uuid": "00440af06705be4ce87ce209ce90bc89a7ccc700", "_cell_guid": "809a26a8-78b6-4c2f-9db0-f253f1cce02a", "collapsed": true}}, {"cell_type": "markdown", "source": ["We can use different classifiers with Pipeline here and tune them for even better results.\n", "             ----\n", " "], "metadata": {"_uuid": "909193ceaa12a513918a7413f2e6a15ca58e9491", "_cell_guid": "508de2b1-a23d-4866-9d1f-ff669f7744b1"}}]}