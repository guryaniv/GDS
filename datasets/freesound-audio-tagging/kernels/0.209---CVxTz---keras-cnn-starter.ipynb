{"cells":[{"metadata":{"trusted":true,"_uuid":"d42696d24681de355e32c2964ce1b748b0855810"},"cell_type":"code","source":"%matplotlib inline  \nimport gc\nimport pickle\nimport random\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport pandas as pd\nfrom keras import optimizers, losses, activations, models\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n    concatenate\nfrom numpy import random\nimport librosa\nimport numpy as np\nimport glob\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"abe27024d5ef9ee89394dcd01f4561cb3453845b"},"cell_type":"code","source":"input_length = 16000*2\n\nbatch_size = 32\n\ndef audio_norm(data):\n\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)/(max_data-min_data+0.0001)\n    return data-0.5\n\n\ndef load_audio_file(file_path, input_length=input_length):\n    data = librosa.core.load(file_path, sr=16000)[0] #, sr=16000\n    if len(data)>input_length:\n        \n        \n        max_offset = len(data)-input_length\n        \n        offset = np.random.randint(max_offset)\n        \n        data = data[offset:(input_length+offset)]\n        \n        \n    else:\n        \n        if input_length > len(data):\n            max_offset = input_length - len(data)\n\n            offset = np.random.randint(max_offset)\n        else:\n            offset = 0\n        \n        \n        data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n        \n        \n    data = audio_norm(data)\n    return data","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4ad5d6b9c514dead4da78e413e0e447b66c8f3c1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"aff02f930ecbc461353c67a9032360b0ed4d9119"},"cell_type":"code","source":"train_files = glob.glob(\"../input/audio_train/*.wav\")\ntest_files = glob.glob(\"../input/audio_test/*.wav\")\ntrain_labels = pd.read_csv(\"../input/train.csv\")","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"ac426a0c2779ff103228913c36133cce2575885e"},"cell_type":"code","source":"file_to_label = {\"../input/audio_train/\"+k:v for k,v in zip(train_labels.fname.values, train_labels.label.values)}","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"336baa5b034e697836dae7c8dc9bce3e9d31a0ef"},"cell_type":"code","source":"#file_to_label","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2d724618d1f5cabfeb86298ba69972bd997432f"},"cell_type":"code","source":"train_files[0]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e35d019c6b5cd59cbee02fc8c747b82634b880f"},"cell_type":"code","source":"data_base = load_audio_file(train_files[0])\nfig = plt.figure(figsize=(14, 8))\nplt.title('Raw wave : %s ' % (file_to_label[train_files[0]]))\nplt.ylabel('Amplitude')\nplt.plot(np.linspace(0, 1, input_length), data_base)\nplt.show()","execution_count":7,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"0d487e3962039ddb162c7520c7a8d9268d72f3fa"},"cell_type":"code","source":"list_labels = sorted(list(set(train_labels.label.values)))","execution_count":8,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"7d7d561634e45cf37e35f1052d88a8173078c85f"},"cell_type":"code","source":"label_to_int = {k:v for v,k in enumerate(list_labels)}","execution_count":9,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5cf61066f60862e9805abafb912519c69b2c120c"},"cell_type":"code","source":"int_to_label = {v:k for k,v in label_to_int.items()}","execution_count":10,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"33435463aad696a589dbdcd3d0b3c6cbcea51657"},"cell_type":"code","source":"file_to_int = {k:label_to_int[v] for k,v in file_to_label.items()}","execution_count":11,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"c11230c47d8062447adc0eaad660c540fd6bbc98"},"cell_type":"code","source":"def get_model():\n    nclass = len(list_labels)\n    inp = Input(shape=(input_length, 1))\n    img_1 = Convolution1D(16, kernel_size=9, activation=activations.relu, padding=\"valid\")(inp)\n    img_1 = Convolution1D(16, kernel_size=9, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=16)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=4)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = MaxPool1D(pool_size=4)(img_1)\n    img_1 = Dropout(rate=0.1)(img_1)\n    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n    img_1 = GlobalMaxPool1D()(img_1)\n    img_1 = Dropout(rate=0.2)(img_1)\n\n    dense_1 = Dense(64, activation=activations.relu)(img_1)\n    dense_1 = Dense(1028, activation=activations.relu)(dense_1)\n    dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n\n    model = models.Model(inputs=inp, outputs=dense_1)\n    opt = optimizers.Adam(0.0001)\n\n    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n    model.summary()\n    return model","execution_count":12,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"d9c0473b0e15b3abcf14497f9efe5a2dcec75bb0"},"cell_type":"code","source":"def chunker(seq, size):\n    return (seq[pos:pos + size] for pos in range(0, len(seq), size))","execution_count":13,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"af179b71cb47c613b7f3cf3416a5dd6877274d65"},"cell_type":"code","source":"def train_generator(list_files, batch_size=batch_size):\n    while True:\n        shuffle(list_files)\n        for batch_files in chunker(list_files, size=batch_size):\n            batch_data = [load_audio_file(fpath) for fpath in batch_files]\n            batch_data = np.array(batch_data)[:,:,np.newaxis]\n            batch_labels = [file_to_int[fpath] for fpath in batch_files]\n            batch_labels = np.array(batch_labels)\n            \n            yield batch_data, batch_labels\n            ","execution_count":14,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5538c2dd7139606c7744581700d2289e56da292e"},"cell_type":"code","source":"tr_files, val_files = train_test_split(train_files, test_size=0.1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51940f25c24cc29a71ad2addb439344c8cd4d72c"},"cell_type":"code","source":"model = get_model()","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df0d6f9ed3d667c83ffbf9665023b36e3d26ede4"},"cell_type":"code","source":"model.fit_generator(train_generator(tr_files), steps_per_epoch=len(tr_files)//batch_size, epochs=2,\n                    validation_data=train_generator(val_files), validation_steps=len(val_files)//batch_size,\n                   use_multiprocessing=True, workers=8, max_queue_size=20)","execution_count":17,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"32e8642a50854e907ee36111fdd72eb0ecd07033"},"cell_type":"code","source":"model.save_weights(\"baseline_cnn.h5\")","execution_count":18,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"71787d953933838626f108c92d33d03f3a75d1d5"},"cell_type":"code","source":"list_preds = []\n","execution_count":19,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"9bfc5f2e1d6aea9597f42263453ec21a1d6ca62d"},"cell_type":"code","source":"for batch_files in tqdm(chunker(test_files, size=batch_size), total=len(test_files)//batch_size ):\n    batch_data = [load_audio_file(fpath) for fpath in batch_files]\n    batch_data = np.array(batch_data)[:,:,np.newaxis]\n    preds = model.predict(batch_data).tolist()\n    list_preds += preds\n            \n","execution_count":20,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"476baa0a3c3a453939272803c99412c258a0576e"},"cell_type":"code","source":"array_preds = np.array(list_preds)","execution_count":21,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"4a295825bc41a9b21016317850297dafef143810"},"cell_type":"code","source":"list_labels = np.array(list_labels)","execution_count":22,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"bc0d0ac8010a457e99bccdfa66a8f008c6c98701"},"cell_type":"code","source":"top_3 = list_labels[np.argsort(-array_preds, axis=1)[:, :3]] #https://www.kaggle.com/inversion/freesound-starter-kernel\npred_labels = [' '.join(list(x)) for x in top_3]","execution_count":30,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f8b5c9594cf2555a3633adf341951ab96e0d5ec6"},"cell_type":"code","source":"df = pd.DataFrame(test_files, columns=[\"fname\"])\ndf['label'] = pred_labels","execution_count":31,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"0d67a88f61bcdca1891bc571e48c0d97e95d089e"},"cell_type":"code","source":"df['fname'] = df.fname.apply(lambda x: x.split(\"/\")[-1])","execution_count":32,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"032745a10fb024fa362569b9892ebc35e636afa7"},"cell_type":"code","source":"df.to_csv(\"baseline.csv\", index=False)","execution_count":33,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"58275343c759c923c31f28a70104b64f614259b0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}