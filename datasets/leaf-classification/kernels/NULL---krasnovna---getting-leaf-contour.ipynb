{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"I've used this dataset to practice a bit with different image classification deep learning models and use transfer method than. I have tried resnet50 model, because I'm more familiar with it and freeze all layer till dense ones, finally fit it to our classes. While I was thinking about leaf images augmentation, I decided to make a script for leaf contour, probably to use it as a feature. Below is a piece of code, which gives you leaf contour( 360 points of pair (fi, r ) in polar coordinates ). "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras.preprocessing import image\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be5fe007b78c130055992af93d817497532fef2a","collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"14f28e5f482d9c890dc9ccef5cd550c6d41d0cf2","collapsed":true},"cell_type":"code","source":"# Make a dictionary of leaf labels\ndf = pd.DataFrame( { 'index': np.arange(99), 'class': np.sort(train['species'].unique()) } )\nclass_dict = dict(zip(df['class'],df.index ))\n#list(class_dict.keys())[list(class_dict.values()).index(6)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4400cdebd4b802e08509149932745f54fdd77f37"},"cell_type":"markdown","source":"Function edge_features gives the contour of leaf image by PIL.Image.Image input "},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"653b8d03faf34f39791bcf50a44a5648116c07af"},"cell_type":"code","source":"# get fi,r for image contur \ndef edge_features(img):\n\n    fi_ = np.linspace(0,2*np.pi, 360)\n    r_ = np.zeros(360)\n    i = 0 \n    for fi in np.linspace(0,2*np.pi, 360):\n        # look for nearest radius value// compare neighbour values \n        r_previous = 0 \n        for r in np.linspace(0, np.sqrt(2)*112, 360):\n            #print(r)\n            x_previous =  112 + np.int(r_previous*np.cos(fi))\n            x_previous = max( min(x_previous, 223 ), 0 )\n            y_previous = 112 + np.int(r_previous*np.sin(fi))\n            y_previous = max( min(y_previous, 223 ), 0 )\n            \n            x_ = 112 +  np.int(r*np.cos(fi))\n            y_ = 112 +  np.int(r*np.sin(fi))\n            x_ = max( min(x_, 223 ), 0 )\n            y_ = max( min(y_, 223 ), 0 )\n            pixel = img.getpixel((x_, y_))\n            pixel_previous = img.getpixel((x_previous, y_previous))\n            #print(pixel_previous[0],pixel[0])\n            if( pixel_previous[0] > 0 and pixel[0] > 0 ):\n                continue \n            else:\n                break \n            r_previous = r \n        r_[i] = r\n        i = i + 1\n    return fi_, r_     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59e2f9bb84eb7aec07ff974ba550248a8f27015e"},"cell_type":"markdown","source":"Example of using function above for one image "},{"metadata":{"trusted":true,"_uuid":"6101de820c22e3127e09c4620a51f6e6397ba24a","collapsed":true},"cell_type":"code","source":"img_path = '../input/images/' + str(1) + '.jpg' \nimg = image.load_img(img_path, target_size=(224, 224)) \nfi, r = edge_features(img)\nfig, ax = plt.subplots(1,1)\nax.axis('equal')\nplt.scatter(r*np.cos(fi),r*np.sin(fi),s = 2)\nplt.plot(r*np.cos(fi),r*np.sin(fi))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d4f1780d1750ca8c798cc08fa013ccc3efbe20c"},"cell_type":"markdown","source":"Now we can use it to get such contour for each imeges in dataset. Obviously we need only value of radius, because fi is equal for each img. Here is code."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"46efe821ca6fdd084ce460ac6a74ba4efb5b9999"},"cell_type":"code","source":"def get_edge_features(img_id_list, labels_list = [] , flag_test = 1 , augment_list = ['same'] ):\n    \n    img_count = len(img_id_list)\n    augment_count = 1 + len(augment_list)\n    features = np.zeros(shape=(augment_count*img_count, 1, 1, 2048))\n    labels = np.zeros(shape=(augment_count*img_count))   \n    img_path = ['../input/images/' + str(id_) + '.jpg' for id_ in img_id_list ]\n    img = [ image.load_img(path, target_size=(224, 224)) for path in img_path]\n    # Augmentation \n    features_ = []\n    labels_ = []\n    j = 0 \n    for val in augment_list:\n        if (val == 'same'):\n            img_ = img\n        if (val == 'rotate_45'):\n            img_ = [ x.rotate(45) for x in img ]\n        if (val == 'rotate_90'):\n            img_ = [ x.rotate(90) for x in img ]\n        #print(img_arr.shape)\n        features_[j*img_count:(j+1)*img_count] = [edge_features(x)[1] for x in img_]\n        j = j + 1\n        if( flag_test == 0 ):\n            labels_ = labels_ + labels_list \n            \n    return np.asarray(features_), np.asarray( labels_ )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"329557f8d5d20a6c6280f5875d1a10bc184f3fef","collapsed":true},"cell_type":"code","source":"import time\nm = 10 # size of dataset \n# Extract features ( example for 10 observation) m = 10\ntrain_id_list =  train['id'].tolist()[0:m]\nlabels_ = [ class_dict[train[train['id'] == x ]['species'].values[0]] for x in train_id_list ] \nstart_time = time.time()\ntrain_features, train_labels = get_edge_features( train_id_list, labels_, flag_test = 0 , \n                                                     augment_list = ['same'] )\nelapsed_time = time.time() - start_time\nprint( elapsed_time)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ca2bad718bfd67eb555639284d54dd8764532d8"},"cell_type":"markdown","source":"Now we get a feature vector for image. Obviously,  for each image we can 359 more features just by shifting array ( it is similar to rotation of out original image ). "},{"metadata":{"trusted":true,"_uuid":"9561e407a0d9458ff2e8046bafcd7e7c3f837d79","collapsed":true},"cell_type":"code","source":"# Several cycle transfer dont change our plot\n# Rotation by 30% \ntrain_features_1 = np.zeros((m*12,360))\ntrain_labels_1 =  np.zeros((m*12),dtype = np.int64)\nfor i in range(m-1):\n    for j in range(12):\n        #print(np.asarray( list(train_features[i,j:359]) + list(train_features[i,0:j]) ).shape)\n        train_features_1[12*i+j,:] = np.asarray( list(train_features[i,30*j:360]) + list(train_features[i,0:30*j]) )\n        train_labels_1[12*i+j,] = train_labels[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2080a5c5291ad2396d00cd131e01f4e83e2094c","collapsed":true},"cell_type":"code","source":"fig, ax = plt.subplots(2,2)\nfig.set_size_inches(10, 10)\nplt.suptitle('Example of rotation 30 degree : ' + list(class_dict.keys())[list(class_dict.values()).index(train_labels_1[0])], fontsize=16 )\nax[0,0].axis('equal')\nfor i in range(1,5):\n    plt.subplot(2,2,i)\n    r = train_features_1[i,:]\n    plt.scatter(r*np.cos(fi),r*np.sin(fi),s = 2)\n    plt.plot(r*np.cos(fi),r*np.sin(fi))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20567a68b2e8ae647ae91de301f118cc6b4db21c"},"cell_type":"markdown","source":"With features above I finally could not get good estimation of train set without overfitting. However, I practice only with features without rotation because of memory cost."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e4fb442be54e3db9e2ef17c19f6e52ea56ecb814"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}