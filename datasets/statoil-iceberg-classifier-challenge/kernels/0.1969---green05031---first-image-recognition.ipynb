{"cells": [{"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "3dc13ef338de98586a76fdce26634008da5ad3b5", "_cell_guid": "04789163-dc7f-4d41-bfa4-31a4a31f0d69"}, "source": ["%matplotlib inline\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import h5py\n", "\n", "\n", "from sklearn.model_selection import train_test_split\n", "from keras import initializers\n", "from keras.models import Model, Sequential\n", "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dense, Dropout, BatchNormalization, Input, Flatten, Activation, ZeroPadding2D, Lambda, GlobalAveragePooling2D, concatenate\n", "from keras.layers.merge import Concatenate, add\n", "from keras.optimizers import Adam, SGD, Adamax\n", "from keras.callbacks import ModelCheckpoint\n", "from keras.preprocessing.image import ImageDataGenerator\n", "\n", "from skimage.restoration import denoise_tv_chambolle, wiener\n", "from skimage.filters import gaussian, sobel, frangi, median, laplace\n", "\n", "from scipy.ndimage.filters import uniform_filter\n", "from scipy.ndimage.measurements import variance\n"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "0f9fa07ceca4b143623a1dd55270eb64167bd2cc", "_cell_guid": "c058ad1f-034a-4093-b84a-bba90c46308f", "collapsed": true}, "source": ["def load_train_data():\n", "    data = pd.read_json('../input/train.json')       \n", "    return data\n", "\n", "def load_test_data():\n", "    data = pd.read_json('../input/test.json')\n", "        \n", "    return data\n", "\n", "def denoise(x, weight, multichannel):\n", "    return np.asarray([denoise_tv_chambolle(item, weight=weight, multichannel=multichannel)for item in x])\n", "\n", "#def denoise(x, multichannel):\n", " #   return np.asarray([denoise_bilateral(item, multichannel=multichannel) for item in x])\n", "\n", "def gaussian_blur(x, sigma, multichannel):\n", "    return np.asarray([gaussian(item, sigma=sigma, multichannel=multichannel) for item in x])\n", "\n", "def color_composite(data):\n", "    rgb_arrays = []\n", "    for i, row in data.iterrows():\n", "        band_1 = np.array(row['band_1']).reshape(75, 75)\n", "        band_2 = np.array(row['band_2']).reshape(75, 75)\n", "        band_3 = band_1 / band_2\n", "        \n", "        r = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n", "        g = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n", "        b = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n", "        \n", "        rgb = np.dstack((r, g, b))\n", "        rgb_arrays.append(rgb)\n", "    return np.array(rgb_arrays)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "844fcffd86e62f45b0ce94ed20f6178fd07754bc", "_cell_guid": "eea703ea-72b5-4390-9fcb-4ee37c86338a", "collapsed": true}, "source": ["from scipy.ndimage.filters import uniform_filter\n", "from scipy.ndimage.measurements import variance\n", "\n", "def lee_filter(img, size):\n", "    img_mean = uniform_filter(img, (size, size))\n", "    img_sqr_mean = uniform_filter(img**2, (size, size))\n", "    img_variance = img_sqr_mean - img_mean**2\n", "\n", "    overall_variance = variance(img)\n", "\n", "    img_weights = img_variance**2 / (img_variance**2 + overall_variance**2)\n", "    img_output = img_mean + img_weights * (img - img_mean)\n", "    return img_output"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "566792fa6326b2514a3fb01fdb4aa5991e0dd849", "_cell_guid": "97c049fb-154b-4941-ba7f-3006832613c1", "collapsed": true}, "source": ["train_df = load_train_data()\n", "test_df = load_test_data()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "82e03334cfd6d21de8879282e07675edd570481a", "_cell_guid": "8a1b5464-e971-416c-9c1e-d44a23ded0cf"}, "source": ["label = np.array(train_df[\"is_iceberg\"])\n", "train_angle = train_df['inc_angle']\n", "train_angle = train_angle.replace('na',np.nan)\n", "train_angle = train_angle.astype(float).fillna(np.mean(train_angle))\n", "test_angle = test_df['inc_angle']\n", "test_angle = test_angle.replace('na',np.nan)\n", "test_angle = test_angle.astype(float).fillna(0)\n", "print('Done')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "e28e394dab5e5732cd2ab1e5385b8ee706cace82", "_cell_guid": "a30bfda5-caf8-4ecd-8689-07305c81c9c2", "collapsed": true}, "source": ["def create_dataset(data, labeled, weight_gray=0.05, weight_rgb=0.05):\n", "    band_1, band_2, images = data['band_1'].values, data['band_2'], color_composite(data)\n", "    to_arr = lambda x: np.asarray([np.asarray(item) for item in x])\n", "    band_1 = to_arr(band_1)\n", "    band_2 = to_arr(band_2)\n", "    band_3 = (band_1 / band_2)\n", "    \n", "    to_rgb = lambda x: np.asarray([(item + abs(item.min())) / np.max((item + abs(item.min()))) for item in x])\n", "    band_1 = to_rgb(band_1)\n", "    band_2 = to_rgb(band_2)\n", "    band_3 = to_rgb(band_3)\n", "    \n", "    \n", "    gray_reshape = lambda x: np.asarray([item.reshape(75, 75) for item in x])\n", "  \n", "    band_1 = gray_reshape(band_1)\n", "    band_2 = gray_reshape(band_2)\n", "    band_3 = gray_reshape(band_3)\n", "    print('denoising')\n", "    \n", "    #band_1 = denoise(band_1, 0.1, False)\n", "    #band_2 = denoise(band_2, 0.1, False)\n", "    #band_3 = denoise(band_3, 0.1, False)\n", "\n", "        \n", "    #images = denoise(images, weight_rgb, True)\n", "    #print('blur')\n", "    \n", "    #band_1 = gaussian(band_1, 0.2, False)\n", "    #band_2 = gaussian(band_2, 0.2, False)\n", "    #band_3 = gaussian(band_3, 0.2, False)\n", "    \n", "    #images = gaussian_blur(images, 0.2, True)\n", "    \n", "    tf_reshape = lambda x: np.asarray([item.reshape(75, 75, 1) for item in x])\n", "    band_1 = tf_reshape(band_1)\n", "    band_2 = tf_reshape(band_2)\n", "    band_3 = tf_reshape(band_3)\n", "    img_reshape = lambda x: np.asarray([item.reshape(75,75,3) for item in x])\n", "    images = img_reshape(images)\n", "    \n", "    band = np.concatenate([band_1, band_2, band_3], axis=3)\n", "    \n", "    x_angle = data.inc_angle\n", "    x_angle = x_angle.replace('na',np.nan)\n", "    x_angle = x_angle.astype(float).fillna(np.mean(x_angle))\n", "    x_angle = np.array(x_angle)\n", "    if labeled:\n", "        y = np.array(data['is_iceberg'])\n", "    else:\n", "        y = None\n", "    \n", "    print('Done')\n", "    return y, x_angle, band, images"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "d2ac1a93e4e3e68dddda71f755b6fd89074c51ba", "_cell_guid": "7ddc6748-a1ef-4aab-b7b4-943aff1a3cb9"}, "source": ["y, x_angle, x_band, x_img = create_dataset(train_df, True)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "b53fe21e75c796880d95c8c262e6703888f9e224", "_cell_guid": "66f1bb47-4125-4017-9626-b4cdad52034e"}, "source": ["np.amax(x_band)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "92d089939ddab63c89d7bd83ebf20390bc61ef6f", "_cell_guid": "91f6fcd1-ce55-4732-a863-6cae31cc522d"}, "source": ["fig = plt.figure(200, figsize=(15,15))\n", "random_indicies = np.random.choice(range(len(x_band)), 9, False)\n", "subset = x_band[random_indicies]\n", "for i in range(9):\n", "    ax = fig.add_subplot(3,3,i+1)\n", "    ax.imshow(subset[i])\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "39091fbbb31810f03d1d6f6ae6099806ee9b607a", "_cell_guid": "be3cf638-c39a-43ae-91c7-ecefa273d711"}, "source": ["fig = plt.figure(200, figsize=(15, 15))\n", "#random_indicies = np.random.choice(range(len(x_img)), 9, False)\n", "subset = x_img[random_indicies]\n", "for i in range(9):\n", "    ax = fig.add_subplot(3, 3, i + 1)\n", "    ax.imshow(subset[i])\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "8a3994e8d36a465e71dace13484edc8e5f4633d2", "_cell_guid": "ac35f74a-6f0c-487d-a868-53fba676103b"}, "source": ["from keras.utils.np_utils import to_categorical\n", "x_train, x_val, \\\n", "x_angle_train, x_angle_val, \\\n", "y_train, y_val = train_test_split(x_img,x_angle, y, random_state=666, test_size=0.25)\n", "\n", "print('img', x_train.shape, y_train.shape)\n", "print('angle', x_angle_train.shape,y_val.shape)\n"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "6430fdc32a2e0b3dc777dcaf55ec98cf5c4a1be0", "_cell_guid": "22617c52-9a96-4086-b550-05e6134df55f", "collapsed": true}, "source": ["adamax01 = Adamax(lr=0.0003)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "58ed9cb54b42c6bba95236292789e1d6ab409a46", "_cell_guid": "68960f90-d4ea-42e1-b145-9a354ef4a070"}, "source": ["def model2(kernel_size=3, filters_1=32, filters_2=32, filters_3=64, filters_4=128,\n", "               optimizers=adamax01,init='lecun_normal',relu_type='selu'):\n", "    band_input = Input(shape=(75, 75, 3))\n", "\n", "    cnn = BatchNormalization()(band_input)\n", "    for i in range(1):\n", "        cnn = Conv2D(filters=filters_1, kernel_size=(kernel_size,kernel_size),\n", "                     kernel_initializer=init)(cnn)\n", "        cnn = Activation(relu_type)(cnn)\n", "        cnn = MaxPooling2D((2,2), strides=(2,2))(cnn)\n", "    for i in range(1):\n", "        cnn = Conv2D(filters=filters_2, kernel_size=(kernel_size,kernel_size),\n", "                     kernel_initializer=init)(cnn)\n", "        cnn = Activation(relu_type)(cnn)\n", "        cnn = MaxPooling2D((2,2), strides=(2,2))(cnn)\n", "    for i in range(1):\n", "        cnn = Conv2D(filters=filters_3, kernel_size=(kernel_size,kernel_size),\n", "                     kernel_initializer=init)(cnn)\n", "        cnn = Activation(relu_type)(cnn)\n", "        cnn = MaxPooling2D((2,2), strides=(2,2))(cnn)\n", "    for i in range(1):\n", "        cnn = Conv2D(filters=filters_4, kernel_size=(kernel_size,kernel_size),\n", "                     kernel_initializer=init)(cnn)\n", "        cnn = Activation(relu_type)(cnn)\n", "        cnn = MaxPooling2D((2,2), strides=(2,2))(cnn)\n", "    \n", "    \n", "    cnn = Flatten()(cnn)\n", "    cnn = Dense(512,activation= relu_type)(cnn)\n", "    cnn = Dense(1, activation = 'sigmoid')(cnn)\n", "\n", "    simple_cnn = Model(inputs=[band_input],outputs=cnn)\n", "\n", "    simple_cnn.compile(optimizer=optimizers, loss = 'binary_crossentropy', metrics = ['accuracy'])\n", "    \n", "    return simple_cnn\n", "m = model2()\n", "m.summary()"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "b0e1608d772d1588bbc8eb02ed70dbc9ca431ee9", "_cell_guid": "8ebc00c1-1443-4c4c-b0c8-93628a9aaf56", "collapsed": true}, "source": ["filepath=\"weights.best.hdf5\"\n", "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n", "callbacks_list = [checkpoint]"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "4806e2a827509d2dbf1f7d10a2faa0d652cf7114", "_cell_guid": "0c0ae9cf-45f9-4bdd-bb64-aec35450d07a", "scrolled": false}, "source": ["gen = ImageDataGenerator(horizontal_flip = True,\n", "                         vertical_flip = True,\n", "                         width_shift_range = 0,\n", "                         height_shift_range = 0,\n", "                         zoom_range = 0.2,\n", "                         rotation_range = 20)\n", "def gen_flow_for_one_inputs(X1, y):\n", "    genX1 = gen.flow(X1,y,  batch_size=64,seed=1)\n", "    while True:\n", "        X1i = genX1.next()\n", "        \n", "        yield X1i[0],  X1i[1]\n", "    \n", "gen_flow = gen_flow_for_one_inputs(x_train, y_train)\n", "gen_val = gen_flow_for_one_inputs(x_val, y_val)\n", "\n", "#model = simple_cnn()\n", "model = model2()\n", "ss = model.fit_generator(gen_flow, validation_data=(x_val,y_val),\n", "                         steps_per_epoch=len(x_train) / 64, \n", "                         epochs=130,\n", "                         callbacks = callbacks_list,\n", "                         verbose = 1)\n"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "614498fd6a7714e3224b7b670a5ff70e512b11a2", "_cell_guid": "0c3c376e-2ce7-483d-8ad8-0c7599a0a288"}, "source": ["plt.plot(ss.history['loss'])\n", "plt.plot(ss.history['val_loss'])\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train','val'], loc='best')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "111cc20b7787c6d1d0f878304a2b1e55842c86f0", "_cell_guid": "c60e7e21-1ff3-4b1f-bdbb-fc7bb3c54471"}, "source": ["model.load_weights(filepath=filepath)\n", "score = model.evaluate(x_train, y_train,verbose=1)\n", "print('Train loss:', score[0])\n", "print('Train accuracy:', score[1])\n", "test_score = model.evaluate(x_val, y_val,verbose=1)\n", "print('Test loss:', test_score[0])\n", "print('Test accuracy:', test_score[1])\n"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "c1410a315cdf6567d23485024db33f881eded755", "_cell_guid": "5e1a6b74-8d8d-4547-bba9-c3ab65766699", "collapsed": true}, "source": ["model.load_weights(filepath=filepath)\n", "#train_predictions = m.predict([x_band,x_angle])"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "a9adf3f9cc844580cd98a0fa56c3cab8fc2f8474", "_cell_guid": "0b592361-0574-4ff6-8c2c-0d317cd36715", "collapsed": true}, "source": ["#pre_label= np.round(train_predictions)\n", "#pre_label = np.array(pre_label).flatten()\n", "#pre_label = pre_label.astype('int64')\n", "#exc_label = label\n", "#corr_index = np.where((pre_label == exc_label))[0]\n", "#incorr_index = np.where((pre_label != exc_label))[0]"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "a5815d07fea3e3b187d809ecf889c1049ddeb7ff", "_cell_guid": "958f13e9-784e-42a0-b615-dedf6f3adad5", "collapsed": true}, "source": ["#from sklearn.metrics import confusion_matrix\n", "#plt.subplots(figsize=(12,12))\n", "#g = sns.heatmap(confusion_matrix(exc_label,pre_label),annot=True, fmt='2.0f')\n", "#g.set_xlabel('predicted labels')\n", "#g.set_ylabel('true labels')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "f06903947f35f10835a0a898a5286312f1f47593", "_cell_guid": "8f78ef0e-72c5-4d7b-965b-a3ab8d10b376"}, "source": ["q, test_angle, test_band, test_img = create_dataset(test_df, False)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "bd35b382ee6a5375f024ced0e5fa2199f2ddc8d3", "_cell_guid": "e0fb368f-7f99-4f51-b6c3-09cd68e6b15c"}, "source": ["test_pred = model.predict([test_img])\n", "test_pred = test_pred.reshape(-1)\n", "print('Done')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "b771ebde9e42fe67c0def25615745fe19ab37575", "_cell_guid": "7452e83f-850c-4b38-a9ac-11042c2cf9f1"}, "source": ["img_indicies = np.random.choice(range(len(test_img)), len(x_train)*1, False)\n", "test_sub = test_img[img_indicies]\n", "test_pred_sub = test_pred[img_indicies]\n", "\n", "#X = np.vstack((x_train, test_sub))\n", "Y = np.concatenate((y_train, test_pred_sub))\n", "print('Done')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "2b8cfc2248ef9656d4ce9d5ef9126ec577b5a562", "_cell_guid": "26b74fe4-560b-4c40-bfd3-5a2643d6b45b"}, "source": [" mm = model.fit_generator(gen_flow, validation_data=(x_val, y_val),\n", "                          steps_per_epoch=len(X) / 32, \n", "                          epochs=10,\n", "                          callbacks = callbacks_list,\n", "                          verbose = 1,\n", "                          shuffle=True)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "5220a9190ff57126e8810c5f4837895ae43b6771", "_cell_guid": "835d89d5-b4e8-420e-a4df-f0964506c5a3", "collapsed": true}, "source": ["model.load_weights(filepath=filepath)\n", "test_score = model.evaluate(x_val, y_val,verbose=1)\n", "print('Test loss:', test_score[0])\n", "print('Test accuracy:', test_score[1])"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "f10493c5b3bed823cf13a1d0ab0ac35ab96a5796", "_cell_guid": "71408a67-b0c9-4726-9045-db4d8cb74f58", "collapsed": true}, "source": ["plt.plot(mm.history['loss'])\n", "plt.plot(mm.history['val_loss'])\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train','val'], loc='best')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "7a42768ee030435cc8866a7658273000c0e12e05", "_cell_guid": "757b6a07-49f2-412c-b72f-8ba07e613e49"}, "source": ["model.load_weights(filepath=filepath)\n", "test_predictions = model.predict([test_img])\n", "\n", "\n", "pred_df = test_df[['id']].copy()\n", "pred_df['is_iceberg'] = test_predictions\n", "pred_df.to_csv('predictions.csv', index = False)\n", "pred_df.head(3)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "463c6c137878f3ee2754c4a3a236a5b55e218ee4", "_cell_guid": "774cecce-6237-4f84-8ed4-958b2d9d78d6", "collapsed": true}, "source": []}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1, "nbformat": 4}