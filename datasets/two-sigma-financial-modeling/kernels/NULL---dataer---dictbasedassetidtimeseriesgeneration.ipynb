{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ee5f5e7c-20e3-ed15-a1c9-403ef0f72ddd"
      },
      "source": [
        "This is the code to generate a timeseries for each of  the Asset IDs and store in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5ecec7d-1924-bee1-b29b-40d3d8a57dd7"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import kagglegym\n",
        "import random\n",
        "from sklearn import ensemble, linear_model, metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima_model import ARIMA \n",
        "\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "plt.style.use('classic')\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa6e1f72-bcbb-cf9c-beed-20334e639eca"
      },
      "outputs": [],
      "source": [
        "env = kagglegym.make()\n",
        "o = env.reset()\n",
        "train = o.train  #train dataset - the first half of the full dataframe\n",
        "print(train.shape) #print shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4165c3ee-0006-255d-5ae1-9acc6502241c"
      },
      "outputs": [],
      "source": [
        "#Courtesy Jeff Moser https://www.kaggle.com/jeffmoser/two-sigma-financial-modeling/kagglegym-api-overview\n",
        "with pd.HDFStore(\"../input/train.h5\", \"r\") as train1:\n",
        "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
        "    df = train1.get(\"train\") #df is the complete dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64ec1130-154f-23a5-dc29-9aae824cdb4f"
      },
      "outputs": [],
      "source": [
        "def findMatchedColumnsUsingPrefix(prefix, df):\n",
        "    columns = df.columns[df.columns.str.startswith(prefix)]\n",
        "    return list(columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "779ebed8-3a62-236b-cd6d-3bee1d9127e8"
      },
      "outputs": [],
      "source": [
        "derived_columns = findMatchedColumnsUsingPrefix(\"derived\", df)\n",
        "fundamental_columns = findMatchedColumnsUsingPrefix(\"fundamental\", df)\n",
        "technical_columns = findMatchedColumnsUsingPrefix(\"technical\", df)\n",
        "\n",
        "print(\"There are {} derived columns\".format(len(derived_columns)))\n",
        "print(\"There are {} fundamental columns\".format(len(fundamental_columns)))\n",
        "print(\"There are {} technical columns\".format(len(technical_columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc573cc4-646f-3be1-2a9d-8bc18cd98b3f"
      },
      "outputs": [],
      "source": [
        "#Thanks to Chase:\n",
        "#https://www.kaggle.com/chaseos/two-sigma-financial-modeling/understanding-id-and-timestamp\n",
        "# id counts w.r.t time\n",
        "temp = train.groupby('timestamp').apply(lambda x: x['id'].nunique())#Also can use count() \n",
        "len(train)\n",
        "#as we know the\n",
        "#id is unique for a timstamp\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(temp, color=\"red\")\n",
        "plt.xlabel('timestamp')\n",
        "plt.ylabel('id count')\n",
        "plt.title('Number of ids over time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a77fd80b-5084-31c9-bd35-bb6f91f9ca0a"
      },
      "outputs": [],
      "source": [
        "# lifespan of each id\n",
        "temp = train.groupby('id').apply(len)\n",
        "temp = temp.sort_values()\n",
        "temp = temp.reset_index()\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(temp[0], color=\"blue\")\n",
        "plt.xlabel('index for each id sorted by number of timestamps')\n",
        "plt.ylabel('number of timestamps')\n",
        "plt.title('Number of timestamps (\"Lifespan\") for each id')\n",
        "print(temp[0].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe9d6ef2-3c14-def7-48b2-d11d60d08256"
      },
      "outputs": [],
      "source": [
        "byTS=train.pivot(index='timestamp', columns='id', values='y')\n",
        "byTS.fillna(0,inplace=True)\n",
        "byTS\n",
        "#Reset index so that 'timestamp' is a column \n",
        "byTS.reset_index(level=0,inplace=True)\n",
        "byTS.timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b99091e6-df91-c8dc-42ff-f79f1545b61b"
      },
      "outputs": [],
      "source": [
        "datestart = '2010-01-01'\n",
        "dateend = '2016-12-13'\n",
        "timeperiods = len(byTS)\n",
        "\n",
        "\n",
        "dayse=pd.date_range(datestart, freq='B', periods=timeperiods)\n",
        "dayse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "42a37e46-6b61-b280-a377-11c46ee7d990"
      },
      "outputs": [],
      "source": [
        "byTS.datetime = pd.to_datetime(dayse,unit='B',errors='coerce')\n",
        "byTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ffe44dc8-b3a5-403c-fed6-2e38a1d5394e"
      },
      "outputs": [],
      "source": [
        "TSdict={}\n",
        "\n",
        "#history = [x for x in train]\n",
        "for pos,col in enumerate(byTS.columns[1:]):\n",
        "    ps = pd.Series(byTS[col].values,index=byTS.datetime)\n",
        "    #TS.append(ps)\n",
        "     \n",
        "    TSdict[int(col)] = ps\n",
        "TSdict\n",
        "TSdict[25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b9120b3d-9e11-2e7f-2397-32246bbbe74a"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa import stattools as stt \n",
        "def is_stationary(df, maxlag=15, autolag=None, regression='ct'): \n",
        "    \"\"\"Run the Augmented Dickey-Fuller test from Statsmodels \n",
        "    and print output. \n",
        "    \"\"\" \n",
        "    outpt = stt.adfuller(df,maxlag=maxlag, autolag=autolag, \n",
        "                         regression=regression) \n",
        "    print('adf\\t\\t {0:.3f}'.format(outpt[0])) \n",
        "    print('p\\t\\t {0:.3g}'.format(outpt[1])) \n",
        "    print('crit. val.\\t 1%: {0:.3f}, 5%: {1:.3f}, 10%: {2:.3f}'.format(outpt[4][\"1%\"], outpt[4][\"5%\"], outpt[4][\"10%\"])) \n",
        "    print('stationary?\\t {0}'.format(['true', 'false'][outpt[0]>outpt[4]['5%']])) \n",
        "    return outpt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6811b3a7-cf5a-c3f3-2e86-7d63cfc0192d"
      },
      "outputs": [],
      "source": [
        "TS=TSdict[25]\n",
        "diff1=is_stationary(TS.diff(1).dropna())        \n",
        "\n",
        "diff1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66069dc2-9ef5-ffe4-c017-77f11f06acae"
      },
      "outputs": [],
      "source": [
        "diff12=is_stationary(TS.diff(1).diff(12).dropna());\n",
        "diff12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8948b42c-6ed2-cc27-c6a1-b5c7a78a2502"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "TS.diff(1).plot(label='1 period', title='Y Values', \n",
        "                      dashes=(15,5)) \n",
        "TS.diff(1).diff(12).plot(label='1 and 12 period(s)', \n",
        "                               color='Coral') \n",
        "plt.legend(loc='best')\n",
        "ax=plt.gca()\n",
        "plt.setp(ax.get_xticklabels(), rotation=90, ha='center')\n",
        "ax.locator_params(axis='y', nbins=5)\n",
        "sns.despine() \n",
        "plt.xlabel('Date') "
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}