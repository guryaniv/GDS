{"cells": [{"source": ["The idea of this Notebook is reorder the categorical variables to create a smaller decision tree, smaler ~= min(model.tree_.max_depth) \u2243 getMetric()\n", "\n", "It execute a random permutation, or a sequential permutatition (from itertools). I have no idea if this can optimize the classifiers or not, just an start point to reorder categorical variables based on some metric\n", "https://github.com/rspadim/CategoricalReorders\n", "\n", "changed to multithread version ( 16 cores =] )"], "metadata": {"_uuid": "e333703c4c31cf9e90d6db37457068198b2a6c1e", "_cell_guid": "7dfdfbdb-d389-4c21-ba76-89b15e6e4cbf"}, "cell_type": "markdown"}, {"source": ["Read data"], "metadata": {"_uuid": "c65a3b0cb7c02913453e9bab9f157a369664660c", "_cell_guid": "c206b3ba-3b96-4ee8-8e1d-bac72cf59721"}, "cell_type": "markdown"}, {"source": ["import pandas as pd\n", "print(\"reading files...\")\n", "train  =pd.read_csv(\"../input/train.csv\")\n", "predict=pd.read_csv(\"../input/test.csv\")\n", "cat_cols = [col for col in train.columns if '_cat' in col]\n", "print(\"done :)\")"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a91a60132385d6bd2226f49744311d7c74e728dc", "_cell_guid": "182415be-a332-4363-81d0-aca3c5a92c7b"}, "cell_type": "code"}, {"source": ["Reorder function - it return the series and a dictionary to replace the predict dataset, maybe we can do better with a class?"], "metadata": {"_uuid": "e45257e9d015c96ce0d71d049ae91e2d363831b9", "_cell_guid": "58c2b487-9b67-469f-8b33-a7aebfb7948e"}, "cell_type": "markdown"}, {"source": ["import time\n", "import numpy as np\n", "from math import factorial\n", "from itertools import permutations\n", "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n", "from sklearn.metrics import roc_auc_score,log_loss,mean_absolute_error,mean_squared_error,r2_score\n", "from xgboost import XGBClassifier\n", "def getModel(classifier=True,tree_seed=19870425):\n", "    ## tests with xgb\n", "    #return XGBClassifier(max_depth=10000,\n", "    #                     learning_rate=0.1,\n", "    #                     n_estimators=10000, \n", "    #                     silent=True, \n", "    #                     objective='binary:logistic', \n", "    #                     booster='gbtree', \n", "    #                     n_jobs=1, \n", "    #                     nthread=None, \n", "    #                     gamma=0, \n", "    #                     min_child_weight=1, \n", "    #                     max_delta_step=0, \n", "    #                     subsample=1, \n", "    #                     colsample_bytree=1, \n", "    #                     colsample_bylevel=1, \n", "    #                     reg_alpha=0, \n", "    #                     reg_lambda=1, \n", "    #                     scale_pos_weight=1, \n", "    #                     base_score=0.5, \n", "    #                     random_state=tree_seed, \n", "    #                     seed=tree_seed, \n", "    #                     missing=None)\n", "    \n", "    \n", "    if(classifier):\n", "        return DecisionTreeClassifier(max_depth=None,presort=True,criterion='entropy',class_weight='balanced',random_state=tree_seed)\n", "    return DecisionTreeRegressor(max_depth=None,presort=True,random_state=tree_seed)\n", "\n", "def getMetric(model):\n", "    ## tests with xgb\n", "    #print(type(model))\n", "    #print(vars(model))\n", "    #print(model._Booster.get_dump())\n", "    #__die\n", "    #if(type(model)==DecisionTreeClassifier):\n", "    #    return model.tree_.max_depth\n", "    #return 0\n", "    return model.tree_.max_depth\n", "\n", "# small black magic\n", "def reorderCategorical(df,feature_col,target_col,classifier=True,\n", "                                 max_iterations=721,verbose=False,random_permutation=None,\n", "                                 tree_seed=19870425,random_seed=19870425):\n", "    #time it\n", "    start     = time.time()\n", "    values    =df[feature_col].sort_values().unique() #nd array, since df[col] is a series\n", "    len_values=len(values)\n", "\n", "    #min dictionary (l<=>l)\n", "    optimized=False\n", "    default_dict={l:l for l in values}\n", "    min_dict    ={l:l for l in values}\n", "    if(len_values<3):\n", "        if(verbose):\n", "            print(feature_col,': uniques=',len_values,', values=',values)\n", "            print('\\t\\tLESS THAN 3 UNIQUE VALUES, Time spent (seconds):',time.time() - start)\n", "        return df[feature_col],min_dict\n", "    \n", "    #Current Values\n", "    model=getModel(classifier,tree_seed)\n", "    model.fit(df[feature_col].values.reshape(-1,1),df[target_col])\n", "    min_depth_count=getMetric(model)\n", "    if(verbose):\n", "        print(feature_col,': uniques=',len_values,', depth=',min_depth_count,', values=',values)\n", "        if(classifier):\n", "            print('\\t\\tROC_AUC/LogLoss: ',\n", "                      roc_auc_score(df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n", "                      log_loss(     df[target_col],model.predict_proba(df[feature_col].values.reshape(-1,1))[:,1]))\n", "        else:\n", "            print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                      mean_absolute_error(df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1] ),'/',\n", "                      mean_squared_error( df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]),'/',\n", "                      r2_score(           df[target_col],model.predict(df[feature_col].values.reshape(-1,1))[:,1]))\n", "    if(min_depth_count==1):\n", "        if(verbose):\n", "            print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n", "        return df[feature_col],min_dict\n", "    \n", "    #Naive order by count\n", "    if(classifier):\n", "        first_try=df[df[target_col]==0].groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n", "    else:\n", "        #maybe a median/mean order? for example, target_col>mean(target) ?\n", "        first_try=df.groupby(feature_col)[feature_col].count().sort_values(ascending=True)\n", "    l,values_dict=0,{}\n", "    for i in first_try.index:\n", "        values_dict[values[l]]=i\n", "        l+=1\n", "    \n", "    model=getModel(classifier,tree_seed)\n", "    model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n", "    # better than l<=>l ?\n", "    if(min_depth_count>getMetric(model)):\n", "        optimized=True\n", "        if(verbose):\n", "            print('\\tNaive order by count: from ',min_depth_count,' to ',getMetric(model),', dict:',min_dict)\n", "            if(classifier):\n", "                print('\\t\\tROC_AUC/LogLoss: ',\n", "                          roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                          log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "            else:\n", "                print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                          mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                          mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n", "                          r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "        min_depth_count,min_dict=getMetric(model),values_dict\n", "        if(min_depth_count==1):\n", "            if(verbose):\n", "                print('\\t\\tDEPTH=1, Time spent (seconds):',time.time() - start)\n", "            return df[feature_col].replace(values_dict),values_dict\n", "    elif(verbose):\n", "        print('\\t\\t=[ No optimization using naive order by Count')\n", "    \n", "    # Search Space:\n", "    # maybe random_permutatition isn't the best method... \n", "    #     if len(permutations)~=factorial(len_values) < max_iterations, we can use permutatition (real brute force)\n", "    if(random_permutation==None):\n", "        random_permutation=False\n", "        if(factorial(len_values)>max_iterations):\n", "            random_permutation=True\n", "            if(verbose):\n", "                print('\\t\\tToo big search space, using RANDOM SAMPLING')\n", "        elif(verbose):\n", "            print('\\t\\tmax_iterations (',max_iterations,') >Factorial(length) (',factorial(len_values),'), USING PERMUTATION')\n", "    \n", "    # TODO: maybe we can do better with GA ?!\n", "    if(random_permutation):\n", "        # random permutation ( good lucky =] )\n", "        np.random.seed(random_seed)\n", "        space=range(max_iterations)\n", "    else:\n", "        # default itertools permutation\n", "        space=permutations(values)\n", "\n", "    count=0\n", "    for perm in space:\n", "        if(count>max_iterations):\n", "            break\n", "        # random permutation\n", "        if(random_permutation):\n", "            perm=np.random.permutation(values)\n", "        \n", "        values_dict={values[i]:perm[i] for i in range(0,len_values)}\n", "        model=getModel(classifier,tree_seed)\n", "        model.fit(df[feature_col].replace(values_dict).values.reshape(-1,1),df[target_col])\n", "        if(min_depth_count>getMetric(model)):\n", "            optimized=True\n", "            if(verbose):\n", "                print('\\t',count,'/',max_iterations,'NEW!!! from',min_depth_count,' to ',getMetric(model),' dict:',values_dict)\n", "                if(classifier):\n", "                    print('\\t\\tROC_AUC/LogLoss: ',\n", "                              roc_auc_score(df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                              log_loss(     df[target_col],model.predict_proba(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "                else:\n", "                    print('\\t\\tMAE/MSE/R\u00b2: ',\n", "                              mean_absolute_error(df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1] ),'/',\n", "                              mean_squared_error( df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]),'/',\n", "                              r2_score(           df[target_col],model.predict(df[feature_col].replace(values_dict).values.reshape(-1,1))[:,1]))\n", "            min_depth_count,min_dict=getMetric(model),values_dict\n", "            if(min_depth_count==1):\n", "                print('\\t\\tDEPTH=1')\n", "                break\n", "        count+=1\n", "    if(verbose):\n", "        print('\\t\\tTime spent (seconds):',time.time() - start)\n", "    if(not optimized):\n", "        return df[feature_col],default_dict\n", "    return df[feature_col].replace(values_dict),values_dict\n"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "c5f62300c9cd996e3687e0218155e25e24ac9289", "_cell_guid": "86452d0c-290e-4ef2-a9c0-d4025ad9ceea"}, "cell_type": "code"}, {"source": ["Let's work! BRUTE FORCE IT!"], "metadata": {"_uuid": "d89e3e7ccf4fb31e38eba56c4cd00380fbf967ed", "_cell_guid": "f0f6e3ad-1cca-43ce-b00f-d372905688b2"}, "cell_type": "markdown"}, {"source": ["\n", "#MULTI THREAD VERSION:\n", "import psutil \n", "import threading\n", "\n", "lock = threading.Lock()\n", "def threaded_function(args):\n", "    global train,predict,lock\n", "    #print('cat_cols:',len(args))\n", "    for i in args:\n", "        reordered,values_dict=reorderCategorical(train,i,'target',verbose=True)\n", "        with lock:\n", "            train[  i+'_reordered']=reordered\n", "            predict[i+'_reordered']=predict[i].replace(values_dict)\n", "        print(i)\n", "\n", "if __name__ == \"__main__\":\n", "    # 4 threads\n", "    print(\"Dream machine: :P, 128GB, 16cores\")\n", "    print('cores: ',psutil.cpu_count(),' threads:',psutil.cpu_count(logical=False),\n", "         'freq: ',psutil.cpu_freq())\n", "    print('memory: ',psutil.virtual_memory())\n", "    print('swap: ',psutil.swap_memory())\n", "\n", "    cores=16\n", "    lencat =len(cat_cols)\n", "    lencatdiv=lencat//cores\n", "    start_end=[]\n", "    for i in range(0,cores):\n", "        if(i==cores-1):\n", "            start_end.append([i*lencatdiv+1,lencat]) # last one\n", "        else:\n", "            start_end.append([i*lencatdiv+1,lencatdiv*(i+1)])\n", "    print('start/end: ',len(start_end))\n", "    threads,l=[],0\n", "    \n", "    for i in start_end:\n", "        #print(\"cols: \",i[0],i[1],' - ',cat_cols[i[0] : i[1]])\n", "        #print(\"thread: \",l)\n", "        threads.append( threading.Thread(target = threaded_function, args = (cat_cols[i[0] : i[1]],) ) )\n", "        threads[l].start()\n", "        l+=1\n", "    l=0\n", "    for i in start_end:\n", "        threads[l].join()\n", "        l+=1\n", "    print(\"thread finished...exiting\")\n"], "outputs": [], "execution_count": null, "metadata": {"scrolled": true, "_uuid": "0fad6268511318b6f2c1bfb36684a5422e3386a9", "_cell_guid": "b150a41a-8151-4fca-a512-4ea1ac367d47"}, "cell_type": "code"}, {"source": ["## SINGLE THREAD\n", "#for i in cat_cols:\n", "#    train[i+'_reordered'],values_dict=reorderCategorical(train,i,'target',verbose=True,max_iterations=5)\n", "#    predict[i+'_reordered']=predict[i].replace(values_dict)\n", "#print('Nice job! =]')"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "_uuid": "b1cffc8a187092f477de756616cc65297fd0e752", "_cell_guid": "793f85fd-f38b-46c6-9537-8ae9ef9aa32b"}, "cell_type": "code"}, {"source": ["THANKS KAGGLE COMPUTERS!"], "metadata": {"_uuid": "18cbd2fed12c095c09272d9c2c1471a1e781c6e5", "_cell_guid": "dd1268bd-6a44-4707-b217-8285c18eb259"}, "cell_type": "markdown"}, {"source": ["train.to_csv(  'Reordered-train.csv',index=False)\n", "predict.to_csv('Reordered-test.csv',index=False)"], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "08668c62c0a9bb0e60546e87e1d5263eb188f7a5", "_cell_guid": "a2f0fdfa-86b1-4261-99cb-9aa3cb1693d5"}, "cell_type": "code"}, {"source": [], "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_uuid": "96d1f883bd352ad741467784212d3258373305e2", "_cell_guid": "21459b9e-d3cb-43cd-aa35-53810b9b0c57"}, "cell_type": "code"}], "nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py"}}, "nbformat": 4}