{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import fastai\nfrom fastai.vision import *\nfrom pathlib import Path\nimport cv2\ntorch.backends.cudnn.benchmark = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b947dea234fbc7afbadc567cf50a41cc2f69b6a9"},"cell_type":"markdown","source":"let's check version!"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"fastai.__version__, torch.__version__","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b802accb575a1ff0e818970624390364441e2ad5"},"cell_type":"markdown","source":"good!"},{"metadata":{"trusted":true,"_uuid":"46743399d5af52ed4a7a715bdae2f0d312db8b32"},"cell_type":"code","source":"MASKS = 'train.csv'\n\nPATH = Path('/kaggle/input')\nTRAIN = Path('train')\nTEST = Path('test')\nTMP = Path('/kaggle/working')\n\nSAMPLE = Path('sample_submission.csv')\n\nseg = pd.read_csv(PATH/MASKS)\nsample_sub = pd.read_csv(PATH/SAMPLE)\ntrain_names = list(seg.Id.values)\ntest_names = list(sample_sub.Id.values)\n\nclasses = [str(l) for l in range(28)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1670e566e83a18078892c340a91d8cdb911909c"},"cell_type":"code","source":"df = pd.read_csv(PATH/MASKS); len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d047a826c15c3a7e9745c407fc6a0b6ece4964d4"},"cell_type":"code","source":"arch = models.resnet18;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6b5f3ac99a7711d6e2f8f771ad03430844d1ed3"},"cell_type":"code","source":"stats = ([0.08069, 0.05258, 0.05487], [0.13704,0.10145, 0.15313])\ntfms = get_transforms(do_flip=True, flip_vert=True, \n                      max_lighting=0.1, max_warp=0.4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07f5938000a36310bf8176940b31ddc89ffd8d9a"},"cell_type":"markdown","source":"# Focal Loss"},{"metadata":{"trusted":true,"_uuid":"36695b9ba1efe420419cc1735558e03f881589a9"},"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma=2):\n        super().__init__()\n        self.gamma = gamma\n        \n    def forward(self, input, target):\n        if not (target.size() == input.size()):\n            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n                             .format(target.size(), input.size()))\n\n        max_val = (-input).clamp(min=0)\n        loss = input - input * target + max_val + \\\n            ((-max_val).exp() + (-input - max_val).exp()).log()\n\n        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n        loss = (invprobs * self.gamma).exp() * loss\n        \n        return loss.sum(dim=1).mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b3c17139cb28883da65c181520b425ae862de1d"},"cell_type":"markdown","source":"# Custom image read, just first 3 channels"},{"metadata":{"trusted":true,"_uuid":"580998051824fb97f8a18eab659c941f1acfb061"},"cell_type":"code","source":"def open_image4d(path:PathOrStr)->Image:\n    '''open RGBA image from 4 different 1-channel files.\n    return: numpy array [4, sz, sz]'''\n    path=str(path)\n    flags = cv2.IMREAD_GRAYSCALE\n    red = cv2.imread(path+ '_red.png', flags)\n    blue = cv2.imread(path+ '_blue.png', flags)\n    green = cv2.imread(path+ '_green.png', flags)\n#     yellow = cv2.imread(path+ '_yellow.png', flags)\n    im = np.stack(([red, green, blue]))\n\n    return Image(Tensor(im/255).float())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04011d51a9d8a8219fd4522d4a2c9304d3c7ab13"},"cell_type":"code","source":"class MyImageItemList(ImageItemList):\n    def open(self, fn:PathOrStr)->Image:\n        return open_image4d(fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94714dfefe2a1c1b29295f1b3bd25ac3c25fd9be"},"cell_type":"code","source":"def get_data(sz=64, bs=64, pct=0.2, sample=5000):\n#     sz, pct, bs = 64, 0.2, 64\n    src = (MyImageItemList.from_df(df=df, path=PATH, folder=TRAIN)\n           .random_split_by_pct(pct)\n           .label_from_df(sep=' ', classes=classes)\n           .add_test([PATH/TEST/f for f in test_names]))\n    data = (src.transform(tfms, size=sz)\n            .databunch(bs=bs, num_workers=0).normalize(stats)) #this really sucks!\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4697de89295820ba5df63ec9b74beacea9bf94c"},"cell_type":"code","source":"data = get_data(sample=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1dd1d409edcfd17ee25df89b59251f12c54811d8"},"cell_type":"code","source":"# data.show_batch(rows=3, figsize=(12,9))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89d3efe03003344ccb1fac9998531443eedfdd22"},"cell_type":"markdown","source":"# Learner"},{"metadata":{"trusted":true,"_uuid":"47acc56c6e085ab9bc69d4cb3f99aff4ac07bb96"},"cell_type":"code","source":"f1 = partial(fbeta, beta=1)\n\ndef get_learner(data, focal=False, fp16=False):\n    learn = create_cnn(data, arch, metrics=[accuracy_thresh, f1], \n               callback_fns=[partial(GradientClipping, clip=0.1), ShowGraph], model_dir=TMP)\n    if focal: learn.loss_func = FocalLoss()\n    if fp16: learn.to_fp16();\n    return learn.mixup(stack_y=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f174ebdab441327c3710b618b1e03928298aa80f"},"cell_type":"code","source":"data = get_data(256, 128, 0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2083b4905009a70a9aff4d33b2e41795b28be31b"},"cell_type":"code","source":"learn = get_learner(data, focal=True, fp16=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36d3c290b3de73920a7cce0e9c07bc1a0ca09f72"},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8002e8baea8d84d82eecc4778e6259da0c4a0ad2"},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96773f26e86e655bdd091dbb310da24bb0e743cc"},"cell_type":"code","source":"lr = 1e-2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac4ec34b1ad754dfc93ee6f7bcf3914b476b81b3"},"cell_type":"code","source":"learn.fit_one_cycle(3,slice(lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9c6e7902c06894dbe0aa1a667207229f60300f2"},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69983140776d2f4fb0cb90d63d9460e752a510f3"},"cell_type":"code","source":"learn.fit_one_cycle(4,slice(lr/10, lr/3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3782eae9427359f857a42fb07d32ee193b2dfe06"},"cell_type":"code","source":"learn.save('r18_256')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa1fe2e00d085aebe18b8679f086fe5ada5e1b88"},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true,"_uuid":"97dffb5ce69ad36526835658f0953f32d7dea538"},"cell_type":"code","source":"learn.data.test_dl.add_tfm(to_half)\np,t = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1716791dc9d6480b47bac28d4ddd9087f5940f1f"},"cell_type":"code","source":"model_name = 'r18_256'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad066a1314ccc0f626c0b0f30985d2fbc2324c8d"},"cell_type":"code","source":"preds = to_np(p.sigmoid())  #Check if we are using focal loss or BCE.\nnp.save(model_name, preds)  #save for further model ensemble","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"566053252273650af3bb09de15de7904c4a3180d"},"cell_type":"code","source":"threshold = 0.4 #ths\nprint(preds.shape)\nclasses = np.array(data.classes)\nres = np.array([\" \".join(classes[(np.where(pp>threshold))])for pp in preds])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7899309977259955356a2fa9ac86277dfb282ce"},"cell_type":"code","source":"frame = pd.DataFrame(np.array([test_names, res]).T, columns = ['Id','Predicted'])\nframe.to_csv(f'{model_name}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f75bbb4a900907f7e8b946cc00f75e7ff6cef359"},"cell_type":"code","source":"frame.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc244d50cd984495ef780bd1f2fc83bf3c8ee669"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce5b4a40528306e596f92f34b374be1df5732004"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}