{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "13ab108c-0656-5b89-8ba9-ed4c8d29cdb4"
      },
      "source": [
        "Working on the titanic dataset, goal is to get in top 1000.\n",
        "\n",
        "Goal: predict survival for each passenger ID\n",
        "\n",
        "Output:  418 entries plus header, [PassengerID,Survived]\n",
        "\n",
        "changes made: \n",
        "-has_cabin feature\n",
        "-fare/number of people on ticket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ffc3518c-794c-f81c-a2b3-9fc81aa89601"
      },
      "outputs": [],
      "source": [
        "5#All of below were imported because they were in the first titanic tutorial\n",
        "# data analysis and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b46a51a-6208-2dc6-bbfb-63b5818213b9"
      },
      "outputs": [],
      "source": [
        "#reading data\n",
        "train_df = pd.read_csv('../input/train.csv')\n",
        "test_df = pd.read_csv('../input/test.csv')\n",
        "combine = [train_df, test_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e949a17b-fa52-89d3-7a27-916cabf16597"
      },
      "outputs": [],
      "source": [
        "#Looking at the variables we have\n",
        "#'PassengerId' \n",
        "#'Survived' - [0,1]\n",
        "#'Pclass' - ticket class [1,2,3]\n",
        "#'Name' - presumably name, but should discard this?\n",
        "#'Sex' \n",
        "#'Age' - fractional if less than one, estimated values have format xx.5 \n",
        "#'SibSp' - number of siblings or spouses on board\n",
        "#'Parch' - number of parents or children on board\n",
        "#'Ticket' - ticket number, non-informative\n",
        "#'Fare' - passenger fare (should depend on pclass no?)\n",
        "#'Cabin' - cabin number - may be informative\n",
        "#'Embarked' - port of embarkation [C,Q,S]\n",
        "\n",
        "## advice: separate into categorical or numerical\n",
        "#Categorical: Survived, Pclass, Embarked,Sex,FamilyOnBoard(combined)\n",
        "#Numerical: Age,Fare,SibSp,Parch,Cabin\n",
        "\n",
        "#things that could be combined in a reasonable way\n",
        "#family on board (SibSp>1, Parch>1)\n",
        "#ChildrenInvolved(parch>1, age < 14)\n",
        "#mothers\n",
        "#fathers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd6cd146-8cd1-a51b-1d43-22366843ed95"
      },
      "outputs": [],
      "source": [
        "print(train_df.columns.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e6910801-4565-f245-b173-1debe5b00ee5"
      },
      "source": [
        "Cleaning data and creating features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "589cfee8-d2cc-bad7-c153-ad05e5fee7ee"
      },
      "outputs": [],
      "source": [
        "#name feature contains titles, which could be informative, but we are going to reduce them to a binary \"rare\" value\n",
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "299edfef-920c-2209-ac41-979b0b1ee082"
      },
      "outputs": [],
      "source": [
        "combine = [train_df, test_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "263fa97f-3acc-a50d-4b24-00cf2e105447"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col',\\\n",
        " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer'], 'RareM')\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Dona'], 'Mrs')\n",
        "\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    \n",
        "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a85a64c-a6a5-06bd-f239-1025f653efa5"
      },
      "outputs": [],
      "source": [
        "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"RareM\": 5}\n",
        "for dataset in combine:\n",
        "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8413a5ed-de7d-ed51-2851-c1915771416a"
      },
      "outputs": [],
      "source": [
        "train_df[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60c2ed90-63f1-95db-13e4-41d60154c73a"
      },
      "outputs": [],
      "source": [
        "#now converting all values to numerical instead of text\n",
        "for dataset in combine:\n",
        "    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "67d23260-9a3c-fb2a-d43d-4f82765593e4"
      },
      "outputs": [],
      "source": [
        "#now filling in age values by guessing using pclass and gender combinations.\n",
        "#note probably will want to change this to use different ranges based on title and child status\n",
        "\n",
        "guess_ages = np.zeros((2,3))\n",
        "for dataset in combine:\n",
        "    for i in range(0, 2):\n",
        "        for j in range(0, 3):\n",
        "            guess_df = dataset[(dataset['Sex'] == i) & \\\n",
        "                                  (dataset['Pclass'] == j+1)]['Age'].dropna()\n",
        "\n",
        "            # age_mean = guess_df.mean()\n",
        "            # age_std = guess_df.std()\n",
        "            # age_guess = rnd.uniform(age_mean - age_std, age_mean + age_std)\n",
        "\n",
        "            age_guess = guess_df.median()\n",
        "\n",
        "            # Convert random age float to nearest .5 age\n",
        "            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n",
        "            \n",
        "    for i in range(0, 2):\n",
        "        for j in range(0, 3):\n",
        "            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1) & (dataset.Title != 4),\\\n",
        "                    'Age'] = guess_ages[i,j]\n",
        "    \n",
        "    dataset.loc[ (dataset.Age.isnull()) & (dataset.Title == 4), 'Age']=10 #masters are children, not average male age.\n",
        "    \n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "                                                                                                 \n",
        "combine = [train_df, test_df]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1b54a452-98ce-0916-dbef-d095eeec55a1"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:    \n",
        "    \n",
        "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
        "    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4\n",
        "combine = [train_df, test_df]\n",
        "train_df.head()\n",
        "\n",
        "train_df[['Age', 'Survived']].groupby(['Age'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e63b36f-3274-7061-d3fb-1c55dcb4fb7d"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:\n",
        "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
        "\n",
        "train_df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2dfc3e2c-50e3-7d8d-1aad-d603dc86bfd4"
      },
      "outputs": [],
      "source": [
        "#author wants to drop all of the family info in favor of \"isalone\" which seems questionable to me as this almost certainly matters a lot.\n",
        "for dataset in combine:\n",
        "    dataset['IsAlone'] = 0\n",
        "    #dataset['BigFamily'] = 0 I think this leads to overfitting\n",
        "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
        "    #dataset.loc[dataset['FamilySize'] >= 5, 'BigFamily'] = 1\n",
        "\n",
        "#train_df[['BigFamily', 'Survived']].groupby(['BigFamily'], as_index=False).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db7180a2-4ecb-2a59-ab4c-876823b92ca1"
      },
      "outputs": [],
      "source": [
        "#combining these also is questionable to me.\n",
        "for dataset in combine:\n",
        "    dataset['Age*Class'] = (dataset.Age+1) * dataset.Pclass #added this +1 because class matters even for kids\n",
        "\n",
        "train_df.loc[:, ['Age*Class', 'Age', 'Pclass']].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57d245b8-a2a2-d3e7-a913-c77c9216ae47"
      },
      "outputs": [],
      "source": [
        "freq_port = train_df.Embarked.dropna().mode()[0]\n",
        "for dataset in combine:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)\n",
        "    \n",
        "train_df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c5e5510-47c2-afbc-f960-8bba9dee0ff1"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
        "\n",
        "#now everything is numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "92458c16-53c6-6a75-2bb0-956da117f31c"
      },
      "outputs": [],
      "source": [
        "test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "85206a12-b55d-853d-8817-eacddc4d782c"
      },
      "outputs": [],
      "source": [
        "#want to divide fare by number of people using that ticket\n",
        "train_counter = Counter(train_df['Ticket'])\n",
        "for tick in train_df['Ticket'].unique():\n",
        "    train_df.loc[train_df['Ticket']==tick,'n_on_ticket'] = train_counter[tick]\n",
        "    \n",
        "test_counter = Counter(test_df['Ticket'])\n",
        "for tick in test_df['Ticket'].unique():\n",
        "    test_df.loc[test_df['Ticket']==tick,'n_on_ticket'] = test_counter[tick]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "df86b0a2-0a5e-f868-1e97-abeb80b700e1"
      },
      "outputs": [],
      "source": [
        "combine = [train_df,test_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f7e60f2a-ef52-2155-fef6-b68bfee5d40a"
      },
      "outputs": [],
      "source": [
        "for dataset in combine:\n",
        "    dataset['Fare'] = dataset.Fare/dataset.n_on_ticket\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bdc5035c-a316-80b6-e2d7-af14d66c6184"
      },
      "outputs": [],
      "source": [
        "#I don't really understand why we want everything in int format but w/e\n",
        "for dataset in combine:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.76, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.76) & (dataset['Fare'] <= 8.85), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 8.85) & (dataset['Fare'] <= 24.288), 'Fare']   = 2\n",
        "    dataset.loc[ dataset['Fare'] > 24.288, 'Fare'] = 3\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
        "\n",
        "combine = [train_df, test_df]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4fc5e08-708e-a211-d431-d31ba7326fc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_df = train_df.drop(['PassengerId','Ticket', 'Cabin','Name','SibSp', 'FamilySize','Parch','n_on_ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket', 'Cabin','Name','SibSp', 'FamilySize','Parch','n_on_ticket'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0494e84f-493c-ec06-6183-16793df788d9"
      },
      "outputs": [],
      "source": [
        "train_df.info()\n",
        "train_df = train_df.drop('FareBand',axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ddae8ca0-5fee-9ea9-1a44-3b15f963aa13"
      },
      "outputs": [],
      "source": [
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb5fd8c2-839d-b4b6-6401-c00354e07488"
      },
      "outputs": [],
      "source": [
        "#Now we're FINALY READY TO MODEL STUFF\n",
        "\n",
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
        "X_train.shape, Y_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fdf70867-a499-c604-95bb-8d84b6e238a3"
      },
      "outputs": [],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)\n",
        "Y_pred = logreg.predict(X_test)\n",
        "acc_log = round(logreg.score(X_train, Y_train) * 100, 2)\n",
        "acc_log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "103217ba-2ad6-640b-136f-e12ab16294ec"
      },
      "outputs": [],
      "source": [
        "coeff_df = pd.DataFrame(train_df.columns.delete(0))\n",
        "coeff_df.columns = ['Feature']\n",
        "coeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n",
        "\n",
        "coeff_df.sort_values(by='Correlation', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2398d7b-f918-c785-67b2-598e180b13ed"
      },
      "outputs": [],
      "source": [
        "# Stochastic Gradient Descent\n",
        "\n",
        "sgd = SGDClassifier()\n",
        "sgd.fit(X_train, Y_train)\n",
        "Y_pred = sgd.predict(X_test)\n",
        "acc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\n",
        "acc_sgd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "783d1616-4f8a-7e8f-f13c-1b1ebb2e88e1"
      },
      "outputs": [],
      "source": [
        "# Gaussian Naive Bayes\n",
        "\n",
        "gaussian = GaussianNB()\n",
        "gaussian.fit(X_train, Y_train)\n",
        "Y_pred = gaussian.predict(X_test)\n",
        "acc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\n",
        "acc_gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "125e8f82-c1f3-a05a-dbac-0d17f1617f6b"
      },
      "outputs": [],
      "source": [
        "# Perceptron\n",
        "\n",
        "perceptron = Perceptron()\n",
        "perceptron.fit(X_train, Y_train)\n",
        "Y_pred = perceptron.predict(X_test)\n",
        "acc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\n",
        "acc_perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2357ded2-997c-8ea6-c218-d32cb19602cb"
      },
      "outputs": [],
      "source": [
        "# Support Vector Machines\n",
        "\n",
        "svc = SVC()\n",
        "svc.fit(X_train, Y_train)\n",
        "Y_pred = svc.predict(X_test)\n",
        "acc_svc = round(svc.score(X_train, Y_train) * 100, 2)\n",
        "acc_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5b298c4-16cd-b18e-acf5-cce84f4acc94"
      },
      "outputs": [],
      "source": [
        "# Linear SVC\n",
        "\n",
        "linear_svc = LinearSVC()\n",
        "linear_svc.fit(X_train, Y_train)\n",
        "Y_pred = linear_svc.predict(X_test)\n",
        "acc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\n",
        "acc_linear_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d44a012d-d732-ff58-ca1b-0a5d7f5c0797"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn.fit(X_train, Y_train)\n",
        "Y_pred = knn.predict(X_test)\n",
        "acc_knn = round(knn.score(X_train, Y_train) * 100, 2)\n",
        "acc_knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "cab8119c-f101-ad2f-4e6d-987fe45959ee"
      },
      "outputs": [],
      "source": [
        "# Decision Tree\n",
        "\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "decision_tree.fit(X_train, Y_train)\n",
        "Y_pred = decision_tree.predict(X_test)\n",
        "acc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\n",
        "acc_decision_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7297fd78-611a-05d6-1fdc-4720673aa787"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators=10)\n",
        "random_forest.fit(X_train, Y_train)\n",
        "Y_pred = random_forest.predict(X_test)\n",
        "random_forest.score(X_train, Y_train)\n",
        "acc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\n",
        "acc_random_forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57832d50-e455-98fc-b0f4-145dab79555b"
      },
      "outputs": [],
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
        "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
        "              'Stochastic Gradient Decent', 'Linear SVC', \n",
        "              'Decision Tree'],\n",
        "    'Score': [acc_svc, acc_knn, acc_log, \n",
        "              acc_random_forest, acc_gaussian, acc_perceptron, \n",
        "              acc_sgd, acc_linear_svc, acc_decision_tree]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9e8e147a-727f-0fb9-96a8-bf5ab7ac7695"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "        \"PassengerId\": test_df[\"PassengerId\"],\n",
        "        \"Survived\": Y_pred\n",
        "    })\n",
        "#Y_pred\n",
        "submission.to_csv('submission.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c4a0b1c6-4aab-24ff-fed6-793c0f4f1116"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}