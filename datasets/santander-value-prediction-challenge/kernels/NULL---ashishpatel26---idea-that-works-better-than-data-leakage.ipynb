{"cells":[{"metadata":{"trusted":true,"_uuid":"e88dbdd4134cba3009a449b2a4d724eb3a4ba3c1","collapsed":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nprint(os.listdir(\"../input\"))\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntest_ID = test['ID']\ny_train = train['target']\ny_train = np.log1p(y_train)\ntrain.drop(\"ID\", axis = 1, inplace = True)\ntrain.drop(\"target\", axis = 1, inplace = True)\ntest.drop(\"ID\", axis = 1, inplace = True)\ncols_with_onlyone_val = train.columns[train.nunique() == 1]\ntrain.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\ntest.drop(cols_with_onlyone_val.values, axis=1, inplace=True)\nNUM_OF_DECIMALS = 32\ntrain = train.round(NUM_OF_DECIMALS)\ntest = test.round(NUM_OF_DECIMALS)\ncolsToRemove = []\ncolumns = train.columns\nfor i in range(len(columns)-1):\n    v = train[columns[i]].values\n    dupCols = []\n    for j in range(i + 1,len(columns)):\n        if np.array_equal(v, train[columns[j]].values):\n            colsToRemove.append(columns[j])\ntrain.drop(colsToRemove, axis=1, inplace=True) \ntest.drop(colsToRemove, axis=1, inplace=True) \ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c43de39ca66f9fddfddbd34220f79c37c6d2c96b","collapsed":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import ensemble\nrandom_seed = 1234\nNUM_OF_FEATURES = 1000\ndef rmsle(y, pred):\n    return np.sqrt(np.mean(np.power(y - pred, 2)))\n\nx1, x2, y1, y2 = model_selection.train_test_split(\n    train, y_train.values, test_size=0.20, random_state=random_seed)\nmodel = ensemble.RandomForestRegressor(n_jobs=-1, random_state=7)\nmodel.fit(x1, y1)\nprint(rmsle(y2, model.predict(x2)))\n\ncol = pd.DataFrame({'importance': model.feature_importances_, 'feature': train.columns}).sort_values(\n    by=['importance'], ascending=[False])[:NUM_OF_FEATURES]['feature'].values\ntrain = train[col]\ntest = test[col]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"560dca3e06efbdeb2c4f73db8617d7d3a278d01f","collapsed":true},"cell_type":"code","source":"from scipy.stats import ks_2samp\nTHRESHOLD_P_VALUE = 0.01 #need tuned\nTHRESHOLD_STATISTIC = 0.3 #need tuned\ndiff_cols = []\nfor col in train.columns:\n    statistic, pvalue = ks_2samp(train[col].values, test[col].values)\n    if pvalue <= THRESHOLD_P_VALUE and np.abs(statistic) > THRESHOLD_STATISTIC:\n        diff_cols.append(col)\nfor col in diff_cols:\n    if col in train.columns:\n        train.drop(col, axis=1, inplace=True)\n        test.drop(col, axis=1, inplace=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9afd39d2378888e60e867eb0581d6b4f02677b4","collapsed":true},"cell_type":"code","source":"from sklearn import random_projection\nntrain = len(train)\nntest = len(test)\ntmp = pd.concat([train,test])#RandomProjection\nweight = ((train != 0).sum()/len(train)).values\ntmp_train = train[train!=0]\ntmp_test = test[test!=0]\ntrain[\"weight_count\"] = (tmp_train*weight).sum(axis=1)\ntest[\"weight_count\"] = (tmp_test*weight).sum(axis=1)\ntrain[\"count_not0\"] = (train != 0).sum(axis=1)\ntest[\"count_not0\"] = (test != 0).sum(axis=1)\ntrain[\"sum\"] = train.sum(axis=1)\ntest[\"sum\"] = test.sum(axis=1)\ntrain[\"var\"] = tmp_train.var(axis=1)\ntest[\"var\"] = tmp_test.var(axis=1)\ntrain[\"median\"] = tmp_train.median(axis=1)\ntest[\"median\"] = tmp_test.median(axis=1)\ntrain[\"mean\"] = tmp_train.mean(axis=1)\ntest[\"mean\"] = tmp_test.mean(axis=1)\ntrain[\"std\"] = tmp_train.std(axis=1)\ntest[\"std\"] = tmp_test.std(axis=1)\ntrain[\"max\"] = tmp_train.max(axis=1)\ntest[\"max\"] = tmp_test.max(axis=1)\ntrain[\"min\"] = tmp_train.min(axis=1)\ntest[\"min\"] = tmp_test.min(axis=1)\ntrain[\"skew\"] = tmp_train.skew(axis=1)\ntest[\"skew\"] = tmp_test.skew(axis=1)\ntrain[\"kurtosis\"] = tmp_train.kurtosis(axis=1)\ntest[\"kurtosis\"] = tmp_test.kurtosis(axis=1)\ndel(tmp_train)\ndel(tmp_test)\nNUM_OF_COM = 100 #need tuned\ntransformer = random_projection.SparseRandomProjection(n_components = NUM_OF_COM)\nRP = transformer.fit_transform(tmp)\nrp = pd.DataFrame(RP)\ncolumns = [\"RandomProjection{}\".format(i) for i in range(NUM_OF_COM)]\nrp.columns = columns\n\nrp_train = rp[:ntrain]\nrp_test = rp[ntrain:]\nrp_test.index = test.index\n\n#concat RandomProjection and raw data\ntrain = pd.concat([train,rp_train],axis=1)\ntest = pd.concat([test,rp_test],axis=1)\n\ndel(rp_train)\ndel(rp_test)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56d6f1e6501de6f5e5bb372a6e688cb3ae633024","collapsed":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\n#define evaluation method for a given model. we use k-fold cross validation on the training set. \n#the loss function is root mean square logarithm error between target and prediction\n#note: train and y_train are feeded as global variables\nNUM_FOLDS = 8 #need tuned\ndef rmsle_cv(model):\n    kf = KFold(NUM_FOLDS, shuffle=True, random_state=random_seed).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)\n#ensemble method: model averaging\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models = models\n        \n    # we define clones of the original models to fit the data in\n    # the reason of clone is avoiding affect the original base models\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]  \n        # Train cloned base models\n        for model in self.models_:\n            model.fit(X, y)\n        return self\n    \n    #Now we do the predictions for cloned models and average them\n    def predict(self, X):\n        predictions = np.column_stack([ model.predict(X) for model in self.models_ ])\n        return np.mean(predictions, axis=1)\n\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.055, colsample_bylevel =0.5, \n                             gamma=1.5, learning_rate=0.02, max_depth=32, \n                             objective='reg:linear',booster='gbtree',\n                             min_child_weight=57, n_estimators=1000, reg_alpha=0, \n                             reg_lambda = 0,eval_metric = 'rmse', subsample=0.7, \n                             silent=1, n_jobs = -1, early_stopping_rounds = 14,\n                             random_state =random_seed, nthread = -1)\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=144,\n                              learning_rate=0.005, n_estimators=720, max_depth=13,\n                              metric='rmse',is_training_metric=True,\n                              max_bin = 55, bagging_fraction = 0.8,verbose=-1,\n                              bagging_freq = 5, feature_fraction = 0.9) \nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\naveraged_models = AveragingModels(models = (model_xgb, model_lgb))\nscore = rmsle_cv(averaged_models)\nprint(\"averaged score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0de6a9515a1e497b625ad1c5103af32ecafee75a"},"cell_type":"code","source":"averaged_models.fit(train.values, y_train)\npred = np.expm1(averaged_models.predict(test.values))\nensemble = pred\nsub = pd.DataFrame()\nsub['ID'] = test_ID\nsub['target'] = ensemble\nsub.to_csv('submission-ensemble.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"da68482752ca1ab24eae1873d4b956e9c1322334"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}