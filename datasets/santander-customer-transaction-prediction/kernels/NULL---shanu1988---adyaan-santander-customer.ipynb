{"cells":[{"metadata":{"_uuid":"5591489b71176d1b8ae3f5065025840dc751983a"},"cell_type":"markdown","source":"# Loading the data"},{"metadata":{"_uuid":"cb7881ce88aaac45216fd0da377ec07255acce5c"},"cell_type":"markdown","source":"This can be easily done with the Python data manipulation library Pandas. You follow the import convention and import the package under its alias, pd.\n\nNext, you make use of the read_csv() function to read in the CSV files in which the data is stored. Additionally, use the sep argument to specify that the separator, in this case, is a semicolon and not a regular comma."},{"metadata":{"_uuid":"ff28b64c4722c815543f2170233e7e48ec5751ca"},"cell_type":"markdown","source":"# Importing the libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nroot = Path(\"../input\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6313275684af769a030bfd7f6b869e39ceb8e3ae"},"cell_type":"markdown","source":"# Data Exploration\n\nQuick view on train DataFrames:\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Importing the dataset\ntrain = pd.read_csv(root.joinpath(\"train.csv\"))\ntest = pd.read_csv(root.joinpath(\"test.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b6c36dcea47b3f8b31fa734f2c456b9b8bdf52ea"},"cell_type":"code","source":"# Print info on train set\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cea63bdb5db4a6daff9cb2e324b3da804714ab3"},"cell_type":"markdown","source":"To be checked data import was successful: double check the data contains all the variables that the data description file of the UCI Machine Learning Repository promised you.\nBesides the number of variables, also check the quality of the import are the data types correct? Did all the rows come through? Are there any null values that you should take into account when you’re cleaning up the data?"},{"metadata":{"trusted":true,"_uuid":"0236f469c506e2989b67b2d4031bb5def46709f6"},"cell_type":"code","source":"# First rows of `train` \ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f02488726ca64f8b64913086a31d56f4ea52b3bc"},"cell_type":"code","source":"# Last rows of `train`\ntrain.tail()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a04ea2afc3fb8506efac2aa230a07576632941a"},"cell_type":"code","source":"# Take a sample of 5 rows of `train`\ntrain.sample(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7555f62a865c7a2888c99cae5e3b904771aa130e"},"cell_type":"code","source":"# Describe `train`\ntrain.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6854c330bd55cd4d9ec3d074752d6ae493e8caaf"},"cell_type":"markdown","source":"describe() offers some summary statistics of train data that can help you to assess your data quality.\nYou see that some of the variables have a lot of difference in their min and max values."},{"metadata":{"trusted":true,"_uuid":"da4fe76bbe4903b2640c981953a971f1edda05e7"},"cell_type":"code","source":"# Double check for null values in `train`\ndf = pd.DataFrame(np.random.randn(5, 3), index=['a', 'c', 'e', 'f',\n'h'],columns=['one', 'two', 'three'])\n\ndf = df.reindex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h'])\n\nprint(train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c645a6d2f605dfbafa57723dc4c63c5bad67a54f"},"cell_type":"markdown","source":"We have double checked null values in train data \n"},{"metadata":{"trusted":true,"_uuid":"b36b5cb9507858fe09001182db99a602c819de93"},"cell_type":"code","source":"# Specify the train data\nX_train = train.iloc[:, 2:202].values\ny_train = train.iloc[:, 1].values\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4bbc2bb870e66e5ff34458bc16f2cb7cacc828a7"},"cell_type":"code","source":"test['target'] = -1\ntest.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f51c91930537a7ad724be46765b8dd783bc3947"},"cell_type":"code","source":"# Test data\nX_test = test.iloc[:, 1:201].values\ny_test = test.iloc[:, 201].values\nX_test    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efd5ef1f80cc87bfa6e74475024ff99b4eecc085"},"cell_type":"markdown","source":"# Lets work on test data\nadded traget dummy\n"},{"metadata":{"trusted":true,"_uuid":"4617385939f470e1bb11bf4ae4d46927053e028d"},"cell_type":"code","source":"test['target'] = -1\n\n# Take a sample of 5 rows of `train`\ntest.sample(5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a40ae0b3fb957b77027f2921d2b76daaa47e7c66"},"cell_type":"code","source":"test.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"13a0214311ce0b3e0dad7966eb60366462e75977"},"cell_type":"markdown","source":"# Specify the test data in X & Y\n"},{"metadata":{"trusted":true,"_uuid":"93fcb2758850ecb7e9e0b7dfd5c18fd27dbef6b1"},"cell_type":"code","source":"X_test = test.iloc[:,1:201]\ny_test = test.iloc[:,201]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad491249f90d9b3e710956125f325a699ede0c80"},"cell_type":"markdown","source":"# Feature Scaling\nFeature scaling is a way to deal with these values that lie so far apart.\n"},{"metadata":{"trusted":true,"_uuid":"6529e620a3394ee7fd054822b89ea3b557967121"},"cell_type":"code","source":"# Import `StandardScaler` from `sklearn.preprocessing`\nfrom sklearn.preprocessing import StandardScaler\n\n# Define the scaler \nscaler = StandardScaler().fit(X_train)\n\n# Scale the train set\nX_train = scaler.transform(X_train)\n\n# Scale the test set\nX_test = scaler.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ccf41b37a184f7da9e7f01e28fbca86f92f0aa8"},"cell_type":"markdown","source":"# Model Data\nWe are ready to move on building neural network to classify target\nModel set up by running model = Sequential().\nI will have to create a Dense layer, which is a fully connected layer.\n\nIn the first layer, the activation argument takes the value relu. Next, the model takes as input arrays of shape (200,).\nI will use the first layer has 9 as a first value for the units argument of Dense(), which is the dimensionality of the output space and which are actually 9 hidden units.\nit is means that the model will output arrays of shape (*, 9): this is is the dimensionality of the output space.\n\nThe intermediate layer also uses the relu activation function. The output of this layer will be arrays of shape (*,9).\n\nI am ending the network with a Dense layer of size 1. The final layer will also use a sigmoid activation function so that output is actually a probability. \n"},{"metadata":{"trusted":true,"_uuid":"bcf82ae462dcf54d13a01e624ef84a95ede9bb1a"},"cell_type":"code","source":"# Import `Sequential` from `keras.models`\nfrom keras.models import Sequential\n\n# Import `Dense` from `keras.layers`\nfrom keras.layers import Dense\n\n# Initialize the constructor\nmodel = Sequential()\n\n# Add an input layer \nmodel.add(Dense(9, activation='relu', input_shape=(200,)))\n# Add an input layer \n\n# Add one hidden layer \nmodel.add(Dense(3, activation='relu'))\n\n# Add an output layer \nmodel.add(Dense(1, activation='sigmoid'))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ce1bfcca94934d65afc34ccab1e3f07606b3f6a"},"cell_type":"markdown","source":"# See the results of model"},{"metadata":{"trusted":true,"_uuid":"a9ac0eb4cdfbd5290a351a25ac7d2e18c58263fa"},"cell_type":"code","source":"# Model output shape\nmodel.output_shape\n\n# Model summary\nmodel.summary()\n\n# Model config\nmodel.get_config()\n\n# List all weight tensors \nmodel.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ec84ed285266cdc4d26554e58ec82060ddad986"},"cell_type":"markdown","source":"# Compiling the ANN\n #Lets compile your model and fit the model to the data: once again, make use of compile() and fit() to get this done."},{"metadata":{"trusted":true,"_uuid":"ef785685a56fb16cf7342002aff5f9f9d2057861"},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train,epochs=20, batch_size=100, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d62ff84e30a5ad9a56401a091cb17fadc2f226e2"},"cell_type":"markdown","source":"# Predict Values"},{"metadata":{"trusted":true,"_uuid":"f03ede4890eb4fba02eb6de01ec94fe50c2d0e29"},"cell_type":"code","source":"y_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a147d2185062ab1f52e81facee9a79a9f4126481"},"cell_type":"markdown","source":"# Evaluate Model\nI will evaluate the train data becoz do not have y value in test"},{"metadata":{"trusted":true,"_uuid":"cb418a7be1352d6ec3e5e304af627420aea9b337"},"cell_type":"code","source":"score = model.evaluate(X_train, y_train,verbose=1)\nprint(score)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5196459bf9bea0ecbffdc8e2d706890cf1c915d"},"cell_type":"markdown","source":"This score has combination of the loss and the accuracy. "},{"metadata":{"_uuid":"54af9a086135ebe163731fb9f84a15e40aa30c1b"},"cell_type":"markdown","source":"# Submission File creation"},{"metadata":{"trusted":true,"_uuid":"57a72a1812b1bde8d1ee2c590609532a1fa501b1"},"cell_type":"code","source":"submission = pd.read_csv(root.joinpath(\"sample_submission.csv\"))\nsubmission['target'] = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1618ee815d3b8db686ac940d568b6e4cf6801074"},"cell_type":"code","source":"# add timestamp to submission\nfrom IPython.display import FileLink\nFileLink(f'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}