{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"trusted":true},"cell_type":"code","source":"trainlist = os.listdir(\"../input/train\")\ntestlist = os.listdir(\"../input/test\")\ndf_sample = pd.read_csv('../input/sample_submission.csv')\ndf_labels = pd.read_csv('../input/labels.csv')","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"087e79c7a77953c13e233abfd58f62f447572d93","_cell_guid":"b2564b0c-0a3f-4c65-9302-ba331ee3af24"},"cell_type":"markdown","source":"Printing the first 5 rows of each dataframes :"},{"metadata":{"_uuid":"4c829b0fe348754dd2513b5d05e1a1fdacf95a16","_cell_guid":"aacbd960-c751-46ab-8e9e-5f7d1f72a586","trusted":true},"cell_type":"code","source":"df_sample.head()","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"e0a529d71289a928a1e69179c27c255d3b9307ec","_cell_guid":"f8fd9993-3d2f-40f4-80c8-0de0126b63a8","trusted":true},"cell_type":"code","source":"df_labels.head()","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"6cb1c90bb77eba6051812476f82cfe72f5dfc71d","_cell_guid":"42c7dc9d-aaab-4929-8612-4e46e928882f","trusted":true},"cell_type":"code","source":"df_labels.describe()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"bebec9f7513a32032644f3efc84628eb6ed034f5","_cell_guid":"6217874f-f4ea-4d66-bf96-812948b48e45","trusted":false,"collapsed":true},"cell_type":"code","source":"import seaborn as sns\nsns.countplot(x='breed',data = df_labels)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8377ce9dc8fe59e312032cc7c1242d5d903fa4fa","_cell_guid":"d18d164c-a43f-426e-92b6-49351e488667"},"cell_type":"markdown","source":"The groups look balanced enough. We proceed to preprocessing the data. First we set the Y, or label data as one hot vectors."},{"metadata":{"_uuid":"a171d2e53e565fc81703c292052a2ff3fda1b404","_cell_guid":"b647504c-568f-4a76-9bcb-aae08152da1d","trusted":false,"collapsed":true},"cell_type":"code","source":"from keras.utils import to_categorical\nfrom numpy import array\nbreeds = df_labels['breed'].tolist()\nbreed = df_labels['breed'].unique()\nunq_to_breed = dict()\nfor i in range(len(df_labels)):\n    unq_to_breed[str(df_labels['id'][i])]=(df_labels['breed'][i])\nbreed_to_id = dict((j,i) for i,j in enumerate(breed))\nid_list = to_categorical(list(breed_to_id.values())).astype(np.float32)\nc=0\nfor i in unq_to_breed:\n    print(i,\":\",unq_to_breed[i])\n    c+=1\n    if c==10:\n        break","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f343ee6ee7db182065d5a94c8b46a41fb1a5aa82","_cell_guid":"915f8616-3824-4752-a23a-2a4cb50664b8","trusted":false,"collapsed":true},"cell_type":"code","source":"c=0\nfor i in breed_to_id:\n    print(i,\":\",breed_to_id[i])\n    c+=1\n    if c==10:\n        break","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6612ae41ace1e96a71e6be889d5a92772b513d8a","_cell_guid":"41a296d6-07c6-46e4-8f3b-58391117dc80","trusted":false,"collapsed":true},"cell_type":"code","source":"#we have unq to breed and breed to id so now we create unq to id ! \nunq_to_id = dict()\nfor i in unq_to_breed : \n    unq_to_id[i] = id_list[breed_to_id[unq_to_breed[i]]]\nc=0\nfor i in  unq_to_id:\n    print(i,\":\", unq_to_id[i])\n    c+=1\n    if c==5:\n        break","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2c915932bd7a520083b9801335468f5ad5b304","_cell_guid":"45f5e2d6-24b9-4237-8f19-ea87ccf694cf"},"cell_type":"markdown","source":"As Unq_to_id is our final preprocessing stuff, let's see what it actually is :\n---"},{"metadata":{"_uuid":"252620e0437940db229c76441199b25b62e9249f","_cell_guid":"e1b9c401-144c-4092-b5ff-66bc1ce7b86d","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"length : \",len(unq_to_id))\nprint(\"First element :\",unq_to_id[\"000bec180eb18c7604dcecc8fe0dba07\"])\nprint(\"Element length : \",len(unq_to_id[\"000bec180eb18c7604dcecc8fe0dba07\"]))\nprint(\"\\nLets see if all's well\\n\")\nprint(\"Checking for 0f04466edd10d6c1d27e123399cf4433\")\nprint(\"unq to breed : \",unq_to_breed[\"0f04466edd10d6c1d27e123399cf4433\"])\nprint(\"breed to id : \",breed_to_id[unq_to_breed[\"0f04466edd10d6c1d27e123399cf4433\"]])\nprint(\"unq to id : \",unq_to_id[\"0f04466edd10d6c1d27e123399cf4433\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1663640626620178b4c70eb9d9a86859b49cc62","_cell_guid":"0bdc3a25-0eac-4eca-b39e-08785d3e069b"},"cell_type":"markdown","source":"Thus we see that the unq_to_id ( unique to id ) dict contains a mapping from id to one hot encoded vectors of length 120. All's cool till now.\n---"},{"metadata":{"_uuid":"01b8253454842089290c781f458e7600070aa76b","_cell_guid":"301d137b-3eac-44ac-a439-cea5e1073569"},"cell_type":"markdown","source":"The Y part is done. Now off to preprocessing the images as X."},{"metadata":{"_uuid":"8b6858aae80ff9f86c92515bfffb39ec66960865","_cell_guid":"fc7dd9b1-2e24-4570-b734-e23e85c9a934","scrolled":true,"trusted":false,"collapsed":true},"cell_type":"code","source":"#Plotting a random image\nimport cv2\nimport matplotlib.pyplot as plt\nimage = cv2.imread(\"../input/train/0f04466edd10d6c1d27e123399cf4433.jpg\")\n%matplotlib inline\nimgplot = plt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9643ffcccbc4113106838ed95e2241a922b122b","_cell_guid":"113934b3-d4e8-4898-b2a1-62ac9f23a790","trusted":false,"collapsed":true},"cell_type":"code","source":"#storing all images in a variable X\nX = []\nY = []\nfor i in range(len(trainlist)):\n    image = cv2.imread(\"../input/train/\"+trainlist[i])\n    image = cv2.resize(image,(120,120), interpolation = cv2.INTER_CUBIC)\n    image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n    X.append(image)\n    Y.append(unq_to_id[trainlist[i][0:len(trainlist[i])-4]])\nprint(\"Preprocessing done\")    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e705eb3ed0a4ed69879895a835c2bbf16c627f2","_cell_guid":"d9bebaa1-ee9e-44cf-a6b1-42d412fb0d34","trusted":false,"collapsed":true},"cell_type":"code","source":"X=np.array(X)\nX=X.reshape(len(X),120,120,1)\nX.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24d8b0a1eea4998f7948a3f4306f9787b9e694e0","_cell_guid":"488e7f94-2821-4c43-9693-1376d10f24d4","trusted":false,"collapsed":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5956ce3649f4b7581bf10e890e6729f320add04","_cell_guid":"8bcf6f74-b3cf-42ac-bf48-c51f96aaf2e9","trusted":false,"collapsed":true},"cell_type":"code","source":"Y=np.array(Y)\nclass_totals = Y.sum(axis=0)\nclass_weight = class_totals.max() / class_totals\nY","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df58dc3247299882eb0881c1c707b81b60a85a27","_cell_guid":"7650ddcb-be39-4a8b-b323-db631d8eec0d","trusted":false,"collapsed":true},"cell_type":"code","source":"print(\"X length : \",len(X))\nprint(\"Y length : \",len(Y))\nprint(\"X.shape : \", X.shape)\nprint(\"Y.shape : \", Y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae5c49164fb413835314dd1f7a622244644fd2a9","_cell_guid":"c7ee3bde-08ff-4d1e-abf1-1cc9393fbc1a","collapsed":true},"cell_type":"markdown","source":"Now we build our model using keras ! \n---"},{"metadata":{"_uuid":"bab2b3e4b58a3fbc95ceebb9de9b2df0ac7afca0","_cell_guid":"921bb521-c3f0-4ecc-bbe1-757f7845dfca","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.utils import np_utils\nfrom __future__ import print_function\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2aeddd46981b85b77a3f6af323ec5dd5900d46f","_cell_guid":"8237d03a-e4c7-48cd-93f7-74ed5af188b4","trusted":false,"collapsed":true},"cell_type":"code","source":"nb_filters = 32\nnb_classes = 120\nnb_pool = 2\nnb_conv = 3\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=X.shape[1:]))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dense(nb_classes, activation='softmax'))\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8da3bb8d34f0f9d9fbb0f240aa9e78794e59a0df","_cell_guid":"94969254-da24-476f-8f4a-fedab1515a4a","trusted":false,"collapsed":true},"cell_type":"code","source":"validation_split = 0.10\nmodel.fit(X, Y, batch_size=20, class_weight=class_weight, epochs=10, verbose=1, validation_split=validation_split)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9046183f13457574e68f2fe75e332cc5bfae9f8b","_cell_guid":"226639af-c032-4ce3-885e-d1beee9de1f6"},"cell_type":"markdown","source":"As expected the accuracy is low as we are not using pretrained weights and training the model on local system itself. Let's try with VGG19 model next : "},{"metadata":{"_uuid":"3a59962f87072514e3f3ea48e5f595e9dccc1fd4","_cell_guid":"ebc44521-2eaf-47bf-9575-8ea6d0473590","trusted":false,"collapsed":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.models import Model\nvgg = VGG19(#weights='imagenet',\n    weights = None, include_top=False, input_shape=(120, 120, 1))\nx = vgg.output\nx = Flatten()(x)\npredictions = Dense(nb_classes, activation='softmax')(x)\nvggmodel = Model(inputs=vgg.input, outputs=predictions)\nfor layer in vgg.layers:\n    layer.trainable = False\n\nvggmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', \n              metrics=['accuracy'])\ncallbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\nvggmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f22910a9c2b274bbe8768c2bf086798156f81e02","_cell_guid":"b721d5fd-f3a3-4673-a61e-0ea099a04c42","trusted":false,"collapsed":true},"cell_type":"code","source":"validation_split = 0.10\nvggmodel.fit(X, np.array(Y), batch_size=20, class_weight=class_weight, epochs=10, verbose=1, validation_split=validation_split)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a56e1d0db15a64d490ad803642c70128be91ed6","_cell_guid":"358aae36-e8a5-4a91-b8fb-c8bf91f15460"},"cell_type":"markdown","source":"As we see, we don't get good accuracy as we don't use fully trained weights."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}