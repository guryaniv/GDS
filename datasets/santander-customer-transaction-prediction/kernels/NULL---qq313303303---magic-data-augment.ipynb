{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore')\n\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom datetime import datetime\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=Path(\"../input/\")\ntrain=pd.read_csv(path/\"train.csv\").drop(\"ID_code\",axis=1)\ntest=pd.read_csv(path/\"test.csv\").drop(\"ID_code\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass DataAugment(object):\n\n    def __init__(self, num_n, num_p, seed=0):\n        \"\"\"\n        :param num_n: Negative sample enhancement multiple\n        :param num_p: Positive sample enhancement multiple\n        :param seed:\n        \"\"\"\n        self.num_n = num_n\n        self.num_p = num_p\n        self.seed = seed\n\n    def transform(self, X: pd.DataFrame, y):\n        if not hasattr(y, 'tolist'):\n            y = pd.Series(y)\n\n        cols = X.columns\n        X.columns = range(len(cols))\n        Xn = self._augment(X[y == 0], self.num_n, self.seed)\n        Xp = self._augment(X[y == 1], self.num_p, self.seed + 666666)\n\n        X_ = pd.concat([X] + Xn + Xp, ignore_index=True)\n        X_.columns = cols\n\n        y_ = y.tolist() + [0] * (y == 0).sum() * self.num_n + [1] * y.sum() * self.num_p\n        return X_, pd.Series(y_)\n\n    def _augment(self, X, num, seed=0):\n        return [X.apply(lambda x: shuffle(x.values, random_state=x.name + seed + i)) for i in range(num)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nda = DataAugment(1, 2, 2019)\nX, y = da.transform(train.drop('target', 1), train.target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {\n    'bagging_freq': 5,\n    'bagging_fraction': 0.335,\n    'boost_from_average':'false',\n    'boost': 'gbdt',\n    'feature_fraction': 0.041,\n    'learning_rate': 0.0083,\n    'max_depth': -1,\n    'metric':'auc',\n    'min_data_in_leaf': 80,\n    'min_sum_hessian_in_leaf': 10.0,\n    'num_leaves': 13,\n    'num_threads': 8,\n    'tree_learner': 'serial',\n    'objective': 'binary', \n    'verbosity': -1\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result=np.zeros(test.shape[0])\n\nrskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5,random_state=10)\nfor counter,(train_index, valid_index) in enumerate(rskf.split(X, y),1):\n    print (counter)\n    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n    \n    #Train data\n    trn_data = lgb.Dataset(X_train, y_train)\n    \n    #Validation data\n    val_data = lgb.Dataset(X_valid, y_valid)\n    \n    #Training\n    model = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 4000)\n    result +=model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(path/'sample_submission.csv')\nsubmission['target'] = result/counter\nfilename=\"{:%Y-%m-%d_%H_%M}_sub.csv\".format(datetime.now())\nsubmission.to_csv(filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}