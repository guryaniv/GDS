{"cells":[{"metadata":{"collapsed":true,"trusted":false,"_uuid":"09d757dcdaa553469a22cb6e08489fd004685647"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom imblearn.combine import SMOTEENN \nfrom tensorflow.contrib.tensor_forest.python import tensor_forest\nfrom tensorflow.python.ops import resources","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d9481041944bf82751dbdc67af0d2af75e9f6310"},"cell_type":"markdown","source":"### In this notebook I am going to explore using DNNClassifier, a premade neural network by tensorflow, to create a fraud risk identifier. "},{"metadata":{"trusted":false,"collapsed":true,"_uuid":"efa2aeaad7632105c147416e8b234a44fc82cbeb"},"cell_type":"code","source":"df = pd.read_csv(\"../input/creditcard.csv\")","execution_count":6,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"00c691be894be22108f2c02b7da9af391f747303"},"cell_type":"code","source":"df.head()","execution_count":7,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"09d8cd84d456831ccb7516d213e613a31874f7d9"},"cell_type":"code","source":"df.describe()","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"ca0e6a221577f1d09df911611d1f99188ee320c6"},"cell_type":"markdown","source":"### First we will use seaborn to visualize the data. To do this, I will plot a normalized histogram of the distribution of each feature with separate plots for fraud and genuine transactions"},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"dcd8f322079ac7b229203d1781e9b925d22b897b"},"cell_type":"code","source":"# visualize histograms of distribution of each feature, comparing fraud (red) vs genuine (blue)\nfor column in df.iloc[:,1:29].columns:\n    plt.figure(figsize=(16,4))\n    sns.distplot(df[column][df.Class == 1], bins=60, color= '#FF2731')\n    sns.distplot(df[column][df.Class == 0], bins=60, color = '#349EB8')\n    plt.grid(True)\n    plt.title('histogram of feature: ' + str(column))\n    \n    plt.show()\n    \n    ","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"fe614fb7d9a8a8e161f8a1c767d97e8a9cd693b8"},"cell_type":"markdown","source":"The next step is to solve the unbalanced problem with the data, and then create training sets in x and y. To solve the unbalnaced problem I have decided to use the SMOTE algorithm (Synthetic Minority Over-sampling Technique). The idea is to undersample the majority case (genuine transactions) and oversample the minorty case (fraudulent transactions) by creating synthetic minority class members. These synthetic members are created by introducing synthetic examples along the liine segments joining any of the minority class nearest neighbors. The algorithm I will use is from Nitesh V Chawla, et. al. 2002. Essentially I will take the difference between a minority class feature vector, and its nearest neighbor. Then multiply this difference by a random number from 0 to 1 and add it to the minority class feature vector"},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"e8d0751afb6fd1b4033735735d0fbd2d265b97e0"},"cell_type":"code","source":"# separate the data into fraud and genuine and then again into test sets and training sets\nX = df.loc[:, df.columns != 'Class']\ny = df.Class\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size =.2, random_state=42)\ntype(X_test)\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d375441e9dd90485a909f167e659b0d452f95663"},"cell_type":"code","source":"# use SMOTEENN from imblear\nsme = SMOTEENN(random_state=33)\nX_train, y_train = sme.fit_sample(X_train, y_train)\nprint(type(X_train))\nprint(y_train.shape)","execution_count":11,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d54bd2271d2b8541ebb9071712eb44993e07d7a6"},"cell_type":"code","source":"# preprocess the data to have std = 1 and mean = 0 for each feature. This helps with tensorflow models. \nX_train[:,0] = (X_train[:,0] - X_train[:,0].mean()) / X_train[:,0].std()\nX_test = X_test.values\nX_test[:,0] = (X_test[:,0] - X_test[:,0].mean()) / X_test[:,0].std()\n\nX_train = preprocessing.scale(X_train)\nX_test = preprocessing.scale(X_test)\n\nfeatures_temp = df.columns.values\nfeatures_temp = np.delete(features_temp, 30)\nX_train = pd.DataFrame(data = X_train, columns=features_temp)\nX_test = pd.DataFrame(data = X_test, columns=features_temp)\ny_train = pd.DataFrame(data = y_train, columns = [\"Class\"])\nX_train.describe()","execution_count":12,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e425d2b5b46d6e83419266cdb38d1ac1d5b04a4e"},"cell_type":"code","source":"X_test.describe()","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"c1a98392ef0503278ba47c7a1792e68f85d4eea6"},"cell_type":"markdown","source":"### Now I will create and train a model using DNNClassifier premade neural network from tensorflow"},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"f01551d391fd1abc1d70d5786b81c6a6b71260b8"},"cell_type":"code","source":"my_feature_columns = []\nfor key in X_train.keys():\n    my_feature_columns.append(tf.feature_column.numeric_column(key=key))","execution_count":14,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"deda8fa7a9e68206ed1d5eb0009397e8a71245d8"},"cell_type":"code","source":"# Build 2 hidden layer DNN with 10, 10 units respectively.\nclassifier = tf.estimator.DNNClassifier(\n    feature_columns=my_feature_columns,\n    # Two hidden layers of 10 nodes each.\n    hidden_units=[10, 10],\n    # The model must choose between 3 classes.\n    n_classes=3)","execution_count":15,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"3918e2712231abf13d2941fe9ee6538b34092f1e"},"cell_type":"code","source":"# Parameters\ntrain_steps = 500 \nbatch_size = 1000\n","execution_count":16,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"000322abaa4926e83f0c29f35a013e66b8808c5a"},"cell_type":"code","source":"def train_input_fn(features, labels, batch_size):\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n\n    # Shuffle, repeat, and batch the examples.\n    dataset = dataset.shuffle(500000).repeat().batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\nclassifier.train(input_fn=lambda:train_input_fn(X_train, y_train, batch_size), steps =train_steps)","execution_count":17,"outputs":[]},{"metadata":{"_uuid":"d95d8f2a2241f9788025cd9016d853e21fab4a26"},"cell_type":"markdown","source":"### we can see the model learned something since the loss function decreased. Lets find out what it learned"},{"metadata":{"trusted":false,"_uuid":"a1347a502ab2ab22ce1ad9be8e1d4cbd732cd383"},"cell_type":"code","source":"batch_size = 100\ndef eval_input_fn(features, labels, batch_size):\n    \"\"\"An input function for evaluation or prediction\"\"\"\n    features=dict(features)\n    if labels is None:\n        # No labels, use only features.\n        inputs = features\n    else:\n        inputs = (features, labels)\n\n    # Convert the inputs to a Dataset.\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n\n    # Batch the examples\n    assert batch_size is not None, \"batch_size must not be None\"\n    dataset = dataset.batch(batch_size)\n\n    # Return the dataset.\n    return dataset\n\n# Evaluate the model.\neval_result = classifier.evaluate(input_fn=lambda:eval_input_fn(X_test, y_test, batch_size))","execution_count":18,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"66f325ab28403a841e2114a9d731deb77e03b345"},"cell_type":"code","source":"eval_result","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"230400e1d64b5adf23eb21cd55280d88304a0cea"},"cell_type":"markdown","source":"### Turns out our SMOTEEEN overvalued the minority case causing our model to pick the minoiry case 100% of the time. IT's necessary to revisit the data cleansing process."},{"metadata":{"collapsed":true,"trusted":false,"_uuid":"1b146ab65e80b817136ad731d7f7c4586b9316b6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}