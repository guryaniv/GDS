{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "09c5db0a-1ccd-76cb-4060-8d7bfba9d5f4"
      },
      "source": [
        "This is a draft. \n",
        "But basically, it ranks the features using a random forest then cross validate the number of features to use and predict with the corresponding random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab99a504-e90f-7572-40d4-63f4a45ede1f"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import subprocess\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.cross_validation import KFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import time\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16c10b2b-ca6b-748c-a5e5-f41ed9486f73"
      },
      "source": [
        "#Download data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "225cb0a4-8759-4c93-fa2c-43e032598629"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')\n",
        "y = train['loss']\n",
        "shift = 200\n",
        "log_y = np.log(y+shift)\n",
        "print(np.mean(y))\n",
        "print(np.median(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ba20fe49-506c-398c-a94e-dab1d9ab0fa6"
      },
      "source": [
        "#Preprocessing\n",
        "Here the categorical/continuous variables are named as cati/contj so we encode the categorical labels easily. But maybe different label encodings improve the regression? Also the data is very clean so no missing data, etc. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3bd15121-9f51-a78c-9313-37381788758d"
      },
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    \n",
        "    #Assume categorical/continuous variables named as cati/contj\n",
        "    #Assume no missing data, etc. \n",
        "    cat_headers = [ x for x in df.columns.values if \"cat\" in x] ; #print cat_headers\n",
        "    cont_headers = [ x for x in df.columns.values if \"cont\" in x] ; #print cont_headers\n",
        "    df3 = df[cat_headers].apply(preprocessing.LabelEncoder().fit_transform) \n",
        "    #print(df[['cat1','cat2','cont1']].head(5))\n",
        "    return pd.concat([df[cont_headers],df3],axis=1)\n",
        "\n",
        "train = preprocess(train)\n",
        "x = train.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3688d84a-78a1-fbfd-0c02-2159dc209c33"
      },
      "outputs": [],
      "source": [
        "def scorer(x,y):\n",
        "    return mean_absolute_error(np.exp(x),np.exp(y))\n",
        "\n",
        "from sklearn.metrics import fbeta_score, make_scorer\n",
        "custom_scorer = make_scorer(scorer,greater_is_better=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f36b44cb-b6bf-8993-5edf-da70a21264dd"
      },
      "outputs": [],
      "source": [
        "from sklearn import tree\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy.random import RandomState\n",
        "prng = RandomState(1234567890)\n",
        "\n",
        "cv_tree = False\n",
        "cv_rf = True\n",
        "\n",
        "if cv_tree:\n",
        "    for max in [None,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
        "        t0 = time.time()\n",
        "        reg = tree.DecisionTreeRegressor(max_depth=max)\n",
        "        scores = cross_val_score(reg, x,log_y, cv=3,scoring=custom_scorer)\n",
        "        scores10 = cross_val_score(reg, x,log_y, cv=10,scoring=custom_scorer)\n",
        "        d = time.time()-t0\n",
        "        print(\"tree:\",max,abs(scores.mean()),abs(scores10.mean()),d)\n",
        "\n",
        "if cv_rf:\n",
        "    t0 = time.time()\n",
        "    reg = RandomForestRegressor(n_estimators = 100,criterion='mse',random_state=prng,n_jobs=-1)\n",
        "    scores = cross_val_score(reg, x,log_y, cv=3,scoring=custom_scorer)\n",
        "    #scores10 = cross_val_score(reg, x,log_y, cv=10,scoring=custom_scorer)\n",
        "    d = time.time()-t0\n",
        "    #print(\"rf:\",max,abs(scores.mean()),abs(scores10.mean()),d)\n",
        "    print(\"rf:\",max,abs(scores.mean()),d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2072344b-b1fb-2bea-912f-87e8d6952a94"
      },
      "source": [
        "#Features selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe790c91-2dcd-28ca-fd59-0237f2aba0c3"
      },
      "outputs": [],
      "source": [
        "from numpy.random import RandomState\n",
        "prng = RandomState(1234567890)\n",
        "\n",
        "forest = RandomForestRegressor(n_estimators = 100,criterion='mse',random_state=prng,n_jobs=-1)\n",
        "forest = GradientBoostingRegressor(learning_rate=0.4,criterion='mse')\n",
        "regressors = [ GradientBoostingRegressor(learning_rate=rate,criterion='mse') for rate in [0.1,0.2,0.3,0.4,0.5]]\n",
        "find_features = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9bf72245-7b7b-721e-42f5-17ffd53db4a4"
      },
      "outputs": [],
      "source": [
        "if find_features:\n",
        "    t0 = time.time()\n",
        "    forest = forest.fit(x,log_y)\n",
        "    d = time.time()-t0 ; print(\"Time to fit\",d)\n",
        "    feature_importances =  sorted(zip(forest.feature_importances_,train.columns.values),reverse=True)\n",
        "    sorted_features = [ feature for score,feature in feature_importances] ; print(sorted_features)\n",
        "else:\n",
        "    sorted_features = ['cat80', 'cont14', 'cat101', 'cont7', 'cont2', 'cat103', 'cat79', 'cat100', 'cat111', 'cat112', 'cont8', 'cat12', 'cont5', 'cat53', 'cont3', 'cont6', 'cont4', 'cont1', 'cat110', 'cont13', 'cat81', 'cont12', 'cont11', 'cont10', 'cont9', 'cat114', 'cat1', 'cat113', 'cat57', 'cat116', 'cat72', 'cat83', 'cat107', 'cat82', 'cat91', 'cat105', 'cat115', 'cat93', 'cat106', 'cat73', 'cat84', 'cat108', 'cat109', 'cat92', 'cat87', 'cat94', 'cat4', 'cat75', 'cat97', 'cat31', 'cat39', 'cat104', 'cat95', 'cat5', 'cat50', 'cat6', 'cat99', 'cat36', 'cat2', 'cat27', 'cat37', 'cat38', 'cat44', 'cat102', 'cat23', 'cat26', 'cat49', 'cat9', 'cat96', 'cat25', 'cat52', 'cat76', 'cat98', 'cat66', 'cat77', 'cat13', 'cat10', 'cat11', 'cat90', 'cat74', 'cat40', 'cat3', 'cat41', 'cat54', 'cat8', 'cat28', 'cat71', 'cat19', 'cat24', 'cat45', 'cat29', 'cat88', 'cat43', 'cat16', 'cat65', 'cat86', 'cat89', 'cat85', 'cat7', 'cat30', 'cat78', 'cat51', 'cat18', 'cat17', 'cat14', 'cat67', 'cat42', 'cat46', 'cat59', 'cat61', 'cat32', 'cat33', 'cat21', 'cat68', 'cat47', 'cat34', 'cat60', 'cat63', 'cat35', 'cat22', 'cat48', 'cat58', 'cat56', 'cat69', 'cat20', 'cat70', 'cat55', 'cat15', 'cat62', 'cat64']\n",
        "    print(sorted_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "849f9283-6079-b660-2d11-244bcb60276f"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8d0da8f8-fa40-933c-70a6-45344298f411"
      },
      "outputs": [],
      "source": [
        "tune_params = False\n",
        "if tune_params:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "    tuned_parameters = {'n_features':[60,65,70,75,80,85,90,95,100,105,110]}\n",
        "    tuned_parameters = {'n_features':[80]}\n",
        "\n",
        "    for key in tuned_parameters.keys():\n",
        "        for value in tuned_parameters[key]:\n",
        "            t0 = time.time()\n",
        "            features = sorted_features[0:value]\n",
        "            x_ = train[features].values\n",
        "            x_train, x_test, log_y_train, log_y_test = train_test_split(x_, log_y, test_size=0.5, random_state=prng)\n",
        "            forest.fit(x_train,log_y_train)\n",
        "            log_y_predict = forest.predict(x_test)\n",
        "            y_predict = np.exp(log_y_predict)-shift\n",
        "            y_true = np.exp(log_y_test)-shift\n",
        "            score = mean_absolute_error(y_predict,y_true)\n",
        "            d = (time.time()-t0)/60.0 \n",
        "            print(key,value,score,d)\n",
        "\n",
        "#n_features 80 1212..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8159c7cc-c3e3-84ce-c41c-4356ed659635"
      },
      "outputs": [],
      "source": [
        "tune_shift = False\n",
        "if tune_shift:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    \n",
        "    shifts = [200]\n",
        "    features = sorted_features[0:80]\n",
        "    \n",
        "    for shift in shifts:\n",
        "        t0 = time.time()\n",
        "        x_ = train[features].values\n",
        "        log_y = np.log(y+shift)\n",
        "        x_train, x_test, log_y_train, log_y_test = train_test_split(x_, log_y, test_size=0.33, random_state=prng)\n",
        "        forest.fit(x_train,log_y_train)\n",
        "        log_y_predict = forest.predict(x_test)\n",
        "        y_predict = np.exp(log_y_predict)-shift\n",
        "        y_true = np.exp(log_y_test)-shift\n",
        "        score = mean_absolute_error(y_predict,y_true)\n",
        "        d = (time.time()-t0)/60.0 \n",
        "        print(shift,score,d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe9c24a0-778b-39bd-24cf-30cf920ee525"
      },
      "outputs": [],
      "source": [
        "find_regressor = False\n",
        "if find_regressor:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "   \n",
        "    for reg in regressors:\n",
        "        t0 = time.time()\n",
        "        x_ = train[features].values\n",
        "        log_y = np.log(y+shift)\n",
        "        x_train, x_test, log_y_train, log_y_test = train_test_split(x_, log_y, test_size=0.33, random_state=prng)\n",
        "        reg.fit(x_train,log_y_train)\n",
        "        log_y_predict = reg.predict(x_test)\n",
        "        y_predict = np.exp(log_y_predict)-shift\n",
        "        y_true = np.exp(log_y_test)-shift\n",
        "        score = mean_absolute_error(y_predict,y_true)\n",
        "        d = (time.time()-t0)/60.0 \n",
        "        print(shift,score,d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "691cb28a-3744-f5e3-119d-76f4f138a8b2"
      },
      "source": [
        "#Predicting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "91b857d0-21f9-33f3-acbb-453af22eaaed"
      },
      "outputs": [],
      "source": [
        "predict = False\n",
        "if predict:\n",
        "    top_features = sorted_features[0:80]\n",
        "    x2 = train[top_features].values\n",
        "    t0 = time.time()\n",
        "    forest = forest.fit(x2,log_y)\n",
        "    d = time.time()-t0 ; print(\"Time to fit\",d/60.0)\n",
        "    xx = preprocess(test)[top_features].values\n",
        "    log_yy = forest.predict(xx)\n",
        "    yy = np.exp(log_yy)-shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4c56ef27-27ef-bb36-29fa-98e3b47427ec"
      },
      "source": [
        "#Publish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1e4dbc83-f89c-8053-eff5-68c96fc73331"
      },
      "outputs": [],
      "source": [
        "publish = False\n",
        "if publish:\n",
        "    sub_name = 'random_forest.csv'\n",
        "    sub = pd.DataFrame()\n",
        "    sub['id'] = test['id']\n",
        "    #sub['loss'] = [ int(res) for res in yy]\n",
        "    sub['loss'] = yy\n",
        "    sub.to_csv(sub_name, index=False)\n",
        "    print(sub.head(5))\n",
        "    sub_example = pd.read_csv('../input/sample_submission.csv')\n",
        "    print(sub_example.head(5))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}