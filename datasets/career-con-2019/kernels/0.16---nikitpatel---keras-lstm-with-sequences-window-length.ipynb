{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n### sklearn \nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nfrom sklearn.model_selection import StratifiedShuffleSplit,train_test_split\nfrom sklearn import preprocessing\nfrom keras.utils import to_categorical\n\n\n### keras\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.callbacks import TensorBoard\nfrom keras import backend as K\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f560eb25365457fa9f118976fcad3f324d853c1f"},"cell_type":"code","source":"train_x = pd.read_csv(\"../input/X_train.csv\")\ntrain_y = pd.read_csv(\"../input/y_train.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ddd1ca4b0ebcc33c23c64db03a2dba9b3dce089b"},"cell_type":"code","source":"### column name and shape\n\nprint(\"train_x column name ---- \\n\",train_x.columns)\nprint(\"train_y column name ---- \\n\",train_y.columns)\nprint(\"train_x shape ---- \\n\",train_x.shape)\nprint(\"train_y shape ---- \\n\",train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d989e28fb475540342e7acafa3c79527cef3ca7f"},"cell_type":"code","source":"### train_x head\ntrain_x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"839beb7c020a3d99817fb28e84de40346f4a5b7f"},"cell_type":"code","source":"train_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2976d3220c577e07c34b60f36aa7a67a142a0b4e"},"cell_type":"code","source":"### train_y head\n\ntrain_y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca43b40312376fba1f674a7745771cfffd8e2174"},"cell_type":"code","source":"### check the traget variable\ntrain_y.groupby('surface')['surface'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdef7b228637265ee897077bb76a845527483a61"},"cell_type":"code","source":"train_df = train_x.merge(train_y, on=['series_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f130fd6bcbdaa5357d1485aa6b756a44508a41e"},"cell_type":"code","source":"train_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"581a3d4b08e604f71db370bdbe39d497babfe957"},"cell_type":"code","source":"le = preprocessing.LabelEncoder()\nle.fit(train_df.surface)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9357a2c20fcbf74bf3a9faf45f60754ed7011f51"},"cell_type":"code","source":"train_df['surface'] = le.transform(train_df.surface)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae43f205459cea8b9cd31492c6f6daa61f667e8"},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab3e44eb76018348a90af9ff617cc02cdeea2005"},"cell_type":"code","source":"train_df['cycle'] = train_df['measurement_number']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"16b53bce633c1291319b80ce748ed586ecf50118"},"cell_type":"code","source":"cols_normalize = train_df.columns.difference(['row_id','series_id','measurement_number','group_id','surface'])\nmin_max_scaler = preprocessing.MinMaxScaler()\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n                             columns=cols_normalize, \n                             index=train_df.index)\njoin_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\ntrain_df = join_df.reindex(columns = train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"df1e9f6b4e0bf96f5a1b77c96b35fea333fe77ac"},"cell_type":"code","source":"train_df = train_df.drop(['row_id', 'group_id'], axis=1)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd1b865ce1f44dd2112990753460ce44ffb0c574"},"cell_type":"code","source":"##################################\n# LSTM\n##################################\n\n# pick a large window size of 128 cycles\nsequence_length = 128\n#num_elements = train_df.shape[0]\nsequence_cols = ['series_id', 'measurement_number', 'orientation_X',\n       'orientation_Y', 'orientation_Z', 'orientation_W', 'angular_velocity_X',\n       'angular_velocity_Y', 'angular_velocity_Z', 'linear_acceleration_X',\n       'linear_acceleration_Y', 'linear_acceleration_Z','cycle']\n\n# function to reshape features into (samples, time steps, features) \ndef gen_sequence(id_df,num_elements,seq_cols):\n    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n    we can use shorter ones \"\"\"\n    # for one id I put all the rows in a single matrix\n    data_matrix = id_df[seq_cols].values\n    # Iterate over two lists in parallel.\n    # For example id1 have 0 rows and sequence_length is equal to 128\n    # so zip iterate over two following list of numbers (0,128)\n    # 0 128 -> from row 0 to row 128\n    # 128 256 -> from row 128 to row 256\n    for start, stop in zip(range(0, num_elements + 128,128), range(128, num_elements + 128,128)):\n        yield data_matrix[start:stop, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"273ef4c750df96768ca26fce7749dd91635d9346"},"cell_type":"code","source":"a = list(gen_sequence(train_df,train_df.shape[0],sequence_cols))\nseq_array = np.array(a)\nseq_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c014bf62b6a89a69067703bb37195788075c4abc"},"cell_type":"code","source":"##################################\n# LSTM\n##################################\n\n# pick a large window size of 128 cycles\nsequence_length = 128\nlabel_cols = ['surface']\n\n# function to reshape features into (samples, time steps, features) \ndef label_sequence(id_df,seq_cols):\n    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n    we can use shorter ones \"\"\"\n    # for one id I put all the rows in a single matrix\n    data_matrix = id_df[seq_cols].values\n    num_elements = data_matrix.shape[0]\n    # Iterate over two lists in parallel.\n    # For example id1 have 0 rows and sequence_length is equal to 128\n    # so zip iterate over two following list of numbers (0,128)\n    # 0 128 -> from row 0 to row 128\n    # 128 256 -> from row 128 to row 256\n    for start in range(1, num_elements,128):\n        yield data_matrix[start, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9971511a9664948e5918989052e26e84c09d6e37"},"cell_type":"code","source":"b = list(label_sequence(train_df,label_cols))\nlabel_array = np.array(b)\nlabel_array = to_categorical(label_array)\nlabel_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5690eaa43b41707777bad804367257c68e05efe9"},"cell_type":"code","source":"# unique, counts = np.unique(label_array, return_counts=True)\n# print (np.asarray((unique, counts)).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fa2dacccba678d4a9c709084355d5f736d81116"},"cell_type":"code","source":"nb_features = seq_array.shape[2]\nnb_out = label_array.shape[1]\nnb_features,nb_out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f935d801ab9d9ffa240cbf74637a47252ba19ba"},"cell_type":"code","source":"sss = StratifiedShuffleSplit(n_splits=1, test_size=0.20, random_state=42) # Want a balanced split for all the classes\nfor train_index, test_index in sss.split(seq_array, label_array):\n    print(\"Using {} for training and {} for validation\".format(len(train_index), len(test_index)))\n    x_train, x_valid = seq_array[train_index], seq_array[test_index]\n    y_train, y_valid = label_array[train_index], label_array[test_index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"00f35a8d27eb725f51e6bb027a129414d7fc58f7"},"cell_type":"code","source":"# Next, we build a deep network. \n# The first layer is an LSTM layer with 100 units followed by another LSTM layer with 50 units. \n# Dropout is also applied after each LSTM layer to control overfitting. \n# Final layer is a Dense output layer with single unit and sigmoid activation since this is a binary classification problem.\n# build the network\n\nmodel = Sequential()\n\nmodel.add(LSTM(\n         input_shape=(sequence_length, nb_features),\n         units=100,\n         return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(\n          units=50,\n          return_sequences=False))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=nb_out, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ea5e49a7804ff4562e2fc4b432a2f367fb61b39"},"cell_type":"code","source":"# fit the network\nmodel_path = '../input/binary_model.h5'\nhistory = model.fit(x_train, y_train, epochs=10, validation_split=0.33, verbose=1,batch_size=200)\n\n# list all data in history\nprint(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"55a960fc00f6e4fec7a5a6e7c12a9fb69a778d9c"},"cell_type":"code","source":"test = pd.read_csv(\"../input/X_test.csv\")\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3574f25b36114178a1d50bdbfce415e01f51cf97"},"cell_type":"code","source":"test['cycle'] = test['measurement_number']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"225fa2869dbab44d0d174d19ff5db426a74f94f6"},"cell_type":"code","source":"cols_normalize = test.columns.difference(['row_id','series_id','measurement_number'])\nmin_max_scaler = preprocessing.MinMaxScaler()\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(test[cols_normalize]), \n                             columns=cols_normalize, \n                             index=test.index)\njoin_df = test[test.columns.difference(cols_normalize)].join(norm_train_df)\ntest = join_df.reindex(columns = train_df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77e9e0643d362ec2f8a8fb1db7b41b4fd2786a17"},"cell_type":"code","source":"a = list(gen_sequence(test,test.shape[0],sequence_cols))\ntest_array = np.array(a)\ntest_array.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5463236cd73fabfdf268c9b281c4d58f21247e7"},"cell_type":"code","source":"prediction = model.predict(test_array)\nprediction=np.argmax(prediction, axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6adec03ccc0949316e182b3146ea9e7d32100e24"},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['surface'] = le.inverse_transform(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15077960f0f91caf116a87533e98a789af5e3a0b"},"cell_type":"code","source":"submission.to_csv('lstm.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b879cd2d2f1d6402d026c3b19922434491454368"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}