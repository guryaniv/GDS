{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2daeba23-5014-a74d-2868-0b428a8cad3a"
      },
      "source": [
        "## Implementing a Deep Neural Net in Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57476bb6-0ac1-895c-48ef-2828bc701ab8"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input/train\"]).decode(\"utf8\"))\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "from sklearn.cross_validation import KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, Dense, Activation\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ee7bcb3e-80ea-2a9b-7f1b-8ef3227353bf"
      },
      "source": [
        "## Exploring the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c896ce0-9cd5-b9a9-db22-501561d6134f"
      },
      "outputs": [],
      "source": [
        "folders = check_output([\"ls\", \"../input/train/\"]).decode(\"utf8\").strip().split('\\n')\n",
        "#print (folders)\n",
        "count = {}\n",
        "for folder in folders:\n",
        "    images = len(check_output([\"ls\", \"../input/train/\" + folder]).decode(\"utf8\").strip().split('\\n'))\n",
        "    print(\"Number of files for the species\", folder, \":\", images)\n",
        "    count[folder] = images\n",
        "    \n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(list(count.keys()), list(count.values()), alpha=0.8)\n",
        "plt.xlabel('Fish Species', fontsize=12)\n",
        "plt.ylabel('Number of Images', fontsize=12)\n",
        "plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d0cd629b-c5a1-3de0-9960-99927664ba92"
      },
      "source": [
        "##  Extracting the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1137e8bd-a9b5-23d1-f95a-fa174f75c71a"
      },
      "outputs": [],
      "source": [
        "def get_image(img):\n",
        "    i = cv2.imread(img)\n",
        "    new_image = cv2.resize(i, (32, 32), cv2.INTER_LINEAR)\n",
        "    return new_image\n",
        "\n",
        "def get_train(folders):\n",
        "    X_train = []\n",
        "    X_train_id = []\n",
        "    y_train = []\n",
        "\n",
        "    for folder in folders:\n",
        "        classes = folders.index(folder)  # 0 to 7\n",
        "        i = os.path.join('..', 'input', 'train', folder, '*.jpg')\n",
        "        images = glob.glob(i)\n",
        "        for image in images:\n",
        "            fld = os.path.basename(image)\n",
        "            new = get_image(image)\n",
        "            X_train.append(new)\n",
        "            X_train_id.append(fld)\n",
        "            y_train.append(classes)\n",
        "\n",
        "    return X_train, y_train, X_train_id\n",
        "\n",
        "\n",
        "def get_test():\n",
        "    \n",
        "    X_test = []\n",
        "    X_test_id = []\n",
        "    \n",
        "    i = os.path.join('..', 'input', 'test_stg1', '*.jpg')\n",
        "    images = sorted(glob.glob(i))\n",
        "\n",
        "    for image in images:\n",
        "        fld = os.path.basename(image)\n",
        "        new = get_image(image)\n",
        "        X_test.append(new)\n",
        "        X_test_id.append(fld)\n",
        "\n",
        "    return X_test, X_test_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7b0e752-10d2-8e6e-fa85-8f6bfc9deacb"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_train_id = get_train(folders)\n",
        "X_test, X_test_id = get_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "23b4ee69-4052-fb6b-e326-268b1436d344"
      },
      "source": [
        "##Normalizing the images to be fed in CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "10b84940-8d8d-ffb1-4304-4c0c20775453"
      },
      "outputs": [],
      "source": [
        "def normalize_features(X):\n",
        "    min_value = 0\n",
        "    max_value = 255\n",
        "    \n",
        "    X = np.array(X, dtype=np.uint8)\n",
        "    X = X.transpose((0, 3, 1, 2))\n",
        "    X = X.astype('float32')\n",
        "    X = ((X - min_value)/(max_value - min_value))\n",
        "    return X\n",
        "\n",
        "\n",
        "def normalize_targets(y):\n",
        "\n",
        "    y = np.array(y, dtype=np.uint8)\n",
        "    y = np_utils.to_categorical(y, 8)\n",
        "    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1da84f58-aabc-ed82-0311-8714a243f4c0"
      },
      "outputs": [],
      "source": [
        "X_train = normalize_features(X_train)\n",
        "X_test = normalize_features(X_test)\n",
        "y_train = normalize_targets(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "19db8321-9a15-99eb-3e14-a422da0053bc"
      },
      "source": [
        "## Splitting the data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25ae436e-3dd3-cccd-7e0f-6e3318c3aeea"
      },
      "outputs": [],
      "source": [
        "print (X_test.shape)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n",
        "                                                    test_size=0.2, random_state=23, \n",
        "                                                    stratify=y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6a917b3a-f702-b0ca-cff4-803efd1814a9"
      },
      "source": [
        "###Modelling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d44de10-92be-c022-b852-2b6c53c684df"
      },
      "outputs": [],
      "source": [
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1, 1), input_shape=(3, 32, 32), dim_ordering='th'))\n",
        "    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th'))\n",
        "    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n",
        "    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
        "\n",
        "    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n",
        "    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
        "    model.add(ZeroPadding2D((1, 1), dim_ordering='th'))\n",
        "    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "\n",
        "adam = Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = adam)\n",
        "        \n",
        "model.fit(X_train, y_train, batch_size=128, nb_epoch=60,\n",
        "              validation_split=0.2, verbose=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9f504814-3ee1-ca13-6fd9-8d614d7ae2b7"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_valid, verbose=1)\n",
        "print(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bbb1f3c4-c47f-4ff9-2015-8c0acbd97ca2"
      },
      "source": [
        "## Predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe4cd328-17f2-0169-4e8e-291070875522"
      },
      "outputs": [],
      "source": [
        "test_preds = model.predict(X_test, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "47a82e20-b951-f326-4c83-b5d73a3e7fbf"
      },
      "source": [
        "## Final Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5293ee68-0bf2-f862-cf46-284763d4dc2b"
      },
      "outputs": [],
      "source": [
        "#create_submission(test_preds, folders)\n",
        "submission = pd.DataFrame(test_preds, columns = folders)\n",
        "submission.insert(0, 'image', X_test_id)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d53daeb-5330-65f4-a4ad-9ed07532836a"
      },
      "outputs": [],
      "source": [
        "final = 'final_submissions.csv'\n",
        "submission.to_csv(final, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25925283-ae7f-df4e-c8f0-9cc21db7f692"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}