{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"GLCM feature performed dataset for dear kagglers \n\nThank you hklee's kernal \" https://www.kaggle.com/zeemeen/glcm-texture-features "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook #, tnrange\n#from itertools import chain\nfrom skimage.io import imread, imshow #, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model, save_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\nfrom keras import optimizers\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n\nimport time\nt_start = time.time()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c5d1a3242b43b8340fe2cc7929810953f93c0b6"},"cell_type":"code","source":"version = 5\nbasic_name = f'Unet_resnet_v{version}'\nsave_model_name = basic_name + '.model'\nsubmission_file = basic_name + '.csv'\n\nprint(save_model_name)\nprint(submission_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef2e9463f147d9100402ecedc7cafd789ebf33bb"},"cell_type":"code","source":"img_size_ori = 101\nimg_size_target = 101\n\ndef upsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    \ndef downsample(img):# not used\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec329caf74fd3a187d3f8a0318461d1a47cde2ff"},"cell_type":"code","source":"# Loading of training/testing ids and depths\ntrain_df = pd.read_csv(\"../input/glcm-tgs/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"../input/glcm-tgs/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"987835483f1bc000b4b7da2c077d5996628c3ad3"},"cell_type":"code","source":"train_df[\"images\"] = [np.array(load_img(\"../input/glcm-tgs/train/images/{}.png\".format(idx), color_mode='rgb')) / 765 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"702f83ac00a5911ad5b5064f7d7b7a73fe1cf60b"},"cell_type":"code","source":"train_df[\"masks\"] = [np.array(load_img(\"../input/glcm-tgs/train/mask/{}.png\".format(idx), color_mode='rgb')) / 765 for idx in tqdm_notebook(train_df.index)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"913df00ae174451dca0a9f91616d1c44cf0f83b5"},"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f02d83a3d3375e5923147d4f6018a6b430bf1be"},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(15,5))\nsns.distplot(train_df.coverage, kde=False, ax=axs[0])\nsns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\nplt.suptitle(\"Salt coverage\")\naxs[0].set_xlabel(\"Coverage\")\naxs[1].set_xlabel(\"Coverage class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a0697b76c15e1acc39789a1af11fe009017d01e"},"cell_type":"code","source":"#Plotting the depth distributions¶\n\nsns.distplot(train_df.z, label=\"Train\")\nsns.distplot(test_df.z, label=\"Test\")\nplt.legend()\nplt.title(\"Depth distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8afdd36e5ff382dfaaebe51a9cd41de02bdbff84"},"cell_type":"code","source":"ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-3, img_size_target, img_size_target, 3), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-3, img_size_target, img_size_target, 3), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state=555)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"368989b9f2e192fc88988fbb8b1f657e6a86f8aa"},"cell_type":"code","source":"tmp_img1 = np.zeros((img_size_target, img_size_target,3), dtype=train_df.images.loc[ids_train[100]].dtype)\ntmp_img1[:img_size_ori, :img_size_ori] = train_df.images.loc[ids_train[100]]\nfix, axs = plt.subplots(1, 2, figsize=(15,5))\naxs[0].imshow(tmp_img1, cmap=\"Greys\")\naxs[0].set_title(\"Original image\")\naxs[1].imshow(x_train[100].squeeze(), cmap=\"Greys\")\naxs[1].set_title(\"Scaled image\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"53e5ee22ecc0168e05b627ee12c1fd61deb57fd7"},"cell_type":"code","source":"tmp_img2 = np.zeros((img_size_target, img_size_target,3), dtype=train_df.masks.loc[ids_train[100]].dtype)\ntmp_img2[:img_size_ori, :img_size_ori] = train_df.masks.loc[ids_train[100]]\nfix, axs = plt.subplots(1, 2, figsize=(15,5))\naxs[0].imshow(tmp_img2, cmap=\"Greys\")\naxs[0].set_title(\"Original image_mask\")\naxs[1].imshow(y_train[100].squeeze(), cmap=\"Greys\")\naxs[1].set_title(\"Scaled image\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}