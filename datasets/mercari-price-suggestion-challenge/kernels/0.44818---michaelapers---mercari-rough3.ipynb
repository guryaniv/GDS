{"cells":[{"metadata":{"_uuid":"bd6de4c2e69f4beb234a51aa8f1fb5e5444a793f","_cell_guid":"64b95737-a04c-4786-a05a-373fded66595","trusted":false,"collapsed":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Tue Jan 23 13:24:27 2018\n\n@author: Michael Apers, borrowed heavily from Tilii at \nhttps://www.kaggle.com/tilii7/cross-validation-weighted-linear-blending-errors\n\"\"\"\n###EDA\n\n# Imports of everything one might need\nimport string\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\nfrom sklearn.linear_model import Ridge, SGDRegressor\nfrom sklearn.metrics import mean_squared_error\nimport scipy\nfrom scipy import sparse\nfrom scipy.optimize import minimize\nfrom IPython.display import display\nimport lightgbm as lgb\nimport gc\n\n#time everything\ndef timer(start_time=None):\n    if not start_time:\n        start_time = datetime.now()\n        return start_time\n    elif start_time:\n        thour, temp_sec = divmod(\n            (datetime.now() - start_time).total_seconds(), 3600)\n        tmin, tsec = divmod(temp_sec, 60)\n        print('\\n Time taken: %i hours %i minutes and %s seconds.' %\n              (thour, tmin, round(tsec, 2)))\n        \nstart_time = timer(None)   \ndef load_test():\n    for df in pd.read_csv('../input/test.tsv', sep='\\t', chunksize=700000):\n        yield df\n        \ndef rmse_min_func(weights):\n    final_prediction = 0\n    for weight, prediction in zip(weights, blend_train):\n        final_prediction += weight * prediction\n    return np.sqrt(mean_squared_error(y_train, final_prediction))        \n# Definitions\npd.set_option('display.float_format', lambda x: '%.3f' % x)\nnjobs = -1\n\n# Get data\ntrain = pd.read_csv(\"../input/train.tsv\", sep='\\t')\ntest_chunk_count = 0\ndef DescriptionNotMeaningless(row):\n    if (row == \"No description yet\" or row == \"No category name given\" or row == \"No brand name given\" or len(row) == 1 or row == u\"\\uFFFC\" or row.isspace() or not row or all(j in string.punctuation for j in row)):\n        r = 0\n    else:\n        r = 1\n    return r\n\nfor test in load_test():\n    if test_chunk_count == 0:\n        # Drop Id column\n        tr_ids = train['train_id'].copy()\n        train.drop(\"train_id\", axis = 1, inplace = True)\n        te_ids = test['test_id'].copy()\n        test.drop(\"test_id\", axis = 1, inplace = True)\n        PRICE = np.log1p(train['price'].copy())  #well log(price+1) at least...\n\n\n        #creating a category for item descriptions that are empty or meaningless\n\n        train.item_description = train.item_description.fillna(\"No description yet\")\n        test.item_description = test.item_description.fillna(\"No description yet\")\n\n        train['has_description'] = train.item_description.apply(lambda row : DescriptionNotMeaningless(row))\n        test['has_description'] = test.item_description.apply(lambda row : DescriptionNotMeaningless(row))\n\n        train.brand_name = train.brand_name.fillna(\"No brand name given\")\n        test.brand_name = test.brand_name.fillna(\"No brand name given\")\n        timer(start_time)\n        brand_names = train.brand_name.unique()\n        test.brand_name.replace([name for name in test.brand_name if name not in brand_names], 'No brand name given', inplace=True)\n        timer(start_time)\n        train['has_brand'] = train.brand_name.apply(lambda row : DescriptionNotMeaningless(row))\n        test['has_brand'] = test.brand_name.apply(lambda row : DescriptionNotMeaningless(row))\n\n        train.category_name = train.category_name.fillna(\"No category name given\")\n        test.category_name = test.category_name.fillna(\"No category name given\")\n        category_names = train.category_name.unique()\n        test.category_name.replace([name for name in test.category_name if name not in category_names], 'No category name given', inplace=True)\n        train['has_category'] = train.category_name.apply(lambda row : DescriptionNotMeaningless(row))\n        test['has_category'] = test.category_name.apply(lambda row : DescriptionNotMeaningless(row))\n\n        #brand price\n        train['brand_price'] = train.groupby('brand_name')['price'].transform(np.mean)\n        mapping = dict(train[['brand_name', 'brand_price']].values)\n        test['brand_price'] = test.brand_name.replace(mapping)\n\n        timer(start_time)\n\n        #category price\n        train['category_price'] = train.groupby('category_name')['price'].transform(np.mean)\n        mapping2 = dict(train[['category_name', 'category_price']].values)\n        test['category_price'] = test.category_name.replace(mapping2)\n\n        timer(start_time)\n\n\n        train['item_description'] = train['item_description'].astype('category')\n        train['brand_name'] = train['brand_name'].astype('category')\n        train['has_brand'] = train['has_brand'].astype('category')\n        train['has_description'] = train['has_description'].astype('category')\n        train['has_category'] = train['has_category'].astype('category')\n        train['category_name'] = train['category_name'].astype('category')\n        test['item_description'] = test['item_description'].astype('category')\n        test['brand_name'] = test['brand_name'].astype('category')\n        test['has_brand'] = test['has_brand'].astype('category')\n        test['has_description'] = test['has_description'].astype('category')\n        test['has_category'] = test['has_category'].astype('category')\n        test['category_name'] = test['category_name'].astype('category')\n\n\n        numerical_features = train.drop(['price'],axis=1).select_dtypes(exclude = [\"object\", \"category\"]).columns\n        stdSc = StandardScaler()\n        train.loc[:, numerical_features] = stdSc.fit_transform(train.loc[:, numerical_features])\n        test.loc[:, numerical_features] = stdSc.transform(test.loc[:, numerical_features])\n        timer(start_time)\n        df = pd.concat([train, test])\n        nrow_train = train.shape[0]\n        del train,test\n        gc.collect()\n\n\n        print('Encodings')\n        count = CountVectorizer(min_df=10)\n        X_name = count.fit_transform(df['name'])\n\n\n        print('Category Encoders')\n        count_category = CountVectorizer()\n        X_category = count_category.fit_transform(df['category_name'])\n\n        print('Descp encoders')\n        count_descp = TfidfVectorizer(max_features=50000,\n                                      ngram_range=(1, 3),\n                                      stop_words='english')\n        X_descp = count_descp.fit_transform(df['item_description'])\n\n        print('Brand encoders')\n        vect_brand = LabelBinarizer(sparse_output=True)\n        X_brand = vect_brand.fit_transform(df['brand_name'])\n\n\n        print('Dummy Encoders')\n        X_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n            'item_condition_id', 'has_description', 'has_brand', 'has_category', 'shipping'\n        ]], sparse=True).values)\n\n        df_clean = scipy.sparse.hstack((X_dummies, X_brand, X_category, X_descp, X_name,\n                                         scipy.sparse.csr_matrix(df['brand_price']).T,\n                                         scipy.sparse.csr_matrix(df['category_price']).T)).tocsr()\n\n        train = df_clean[:nrow_train]\n        test = df_clean[nrow_train:]\n\n        print(train.shape)\n        print(test.shape)\n        timer(start_time)\n\n                # ##maybe can mess with skewing numbers##\n        ##############################################################\n\n        #renaming to match modeling convention\n        y_train = PRICE\n\n        #COPY PASTE FROM Tilii's https://www.kaggle.com/tilii7/cross-validation-weighted-linear-blending-errors:\n\n        # This number of folds is forced by time limit\n        folds = 2\n\n        sgd_cv_sum = 0\n        ridge_cv_sum = 0\n        lgb_cv_sum = 0\n        lgb_pred = []\n        sgd_pred = []\n        ridge_pred = []\n        lgb_fpred = []\n        sgd_fpred = []\n        ridge_fpred = []\n\n        avreal = y_train\n        lgb_avpred = np.zeros(train.shape[0])\n        sgd_avpred = np.zeros(train.shape[0])\n        ridge_avpred = np.zeros(train.shape[0])\n        idpred = tr_ids\n\n        blend_train = []\n        blend_test = []\n        model1 = []\n        model2 = []\n        model3 = []\n        train_time = timer(None)\n        kf = KFold(n_splits=folds, random_state=1001)\n        for i, (train_index, val_index) in enumerate(kf.split(train, y_train)):\n            start_time = timer(None)\n            Xtrain, Xval = train[train_index], train[val_index]\n            ytrain, yval = y_train[train_index], y_train[val_index]\n\n            model = SGDRegressor(penalty='l2',\n                                 loss='squared_epsilon_insensitive',\n                                 max_iter=200,\n                                 tol=0.00001,\n                                 epsilon=0.0001,\n                                 learning_rate='invscaling',\n                                 fit_intercept=False,\n                                 alpha=1e-10,\n                                 l1_ratio=0.09,\n                                 shuffle=True,\n                                 verbose=0,\n                                 random_state=1001)\n            model.fit(Xtrain, ytrain)\n            sgd_scores_val = model.predict(Xval)\n            sgd_RMSLE = np.sqrt(mean_squared_error(yval, sgd_scores_val))\n            print('Fold %02d SGD RMSLE: %.6f' % ((i + 1), sgd_RMSLE))\n            sgd_y_pred = model.predict(test)\n            model1.append(model)\n\n            model = Ridge(alpha=4.75,\n                          solver='sag',\n                          fit_intercept=False,\n                          random_state=1001,\n                          max_iter=1000)\n            model.fit(Xtrain, ytrain)\n            ridge_scores_val = model.predict(Xval)\n            ridge_RMSLE = np.sqrt(mean_squared_error(yval, ridge_scores_val))\n            print(' Fold %02d Ridge RMSLE: %.6f' % ((i + 1), ridge_RMSLE))\n            ridge_y_pred = model.predict(test)\n            model2.append(model)\n\n            params = {\n                'boosting': 'gbdt',\n                'max_bin'          :1000,\n                'max_depth': 7,\n                'min_data_in_leaf': 80,\n                'num_leaves': 40,\n                'learning_rate': 0.75,\n                'objective': 'regression',\n                'metric': 'rmse',\n                'nthread': 4,\n                'bagging_freq': 1,\n                'subsample': 0.94,\n                'colsample_bytree': 0.7,\n                'min_child_weight': 17,\n                'is_unbalance': False,\n                'verbose': -1,\n                'seed': 1001\n            }\n\n            dtrain = lgb.Dataset(Xtrain, label=ytrain)\n            dval = lgb.Dataset(Xval, label=yval)\n            watchlist = [dtrain, dval]\n            watchlist_names = ['train', 'val']\n\n            model = lgb.train(params,\n                              train_set=dtrain,\n                              num_boost_round=1800,\n                              valid_sets=watchlist,\n                              valid_names=watchlist_names,\n                              early_stopping_rounds=80,\n                              verbose_eval=80)\n            lgb_scores_val = model.predict(Xval)\n            lgb_RMSLE = np.sqrt(mean_squared_error(yval, lgb_scores_val))\n            print(' Fold %02d LightGBM RMSLE: %.6f' % ((i + 1), lgb_RMSLE))\n            lgb_y_pred = model.predict(test)\n            model3.append(model)\n\n            del Xtrain, Xval\n            gc.collect()\n\n            timer(start_time)\n\n            sgd_avpred[val_index] = sgd_scores_val\n            ridge_avpred[val_index] = ridge_scores_val\n            lgb_avpred[val_index] = lgb_scores_val\n\n            if i > 0:\n                sgd_fpred = sgd_pred + sgd_y_pred\n                ridge_fpred = ridge_pred + ridge_y_pred\n                lgb_fpred = lgb_pred + lgb_y_pred\n            else:\n                sgd_fpred = sgd_y_pred\n                ridge_fpred = ridge_y_pred\n                lgb_fpred = lgb_y_pred\n            sgd_pred = sgd_fpred\n            ridge_pred = ridge_fpred\n            lgb_pred = lgb_fpred\n            sgd_cv_sum = sgd_cv_sum + sgd_RMSLE\n            ridge_cv_sum = ridge_cv_sum + ridge_RMSLE\n            lgb_cv_sum = lgb_cv_sum + lgb_RMSLE\n\n        timer(train_time)\n\n        sgd_cv_score = (sgd_cv_sum / folds)\n        ridge_cv_score = (ridge_cv_sum / folds)\n        lgb_cv_score = (lgb_cv_sum / folds)\n        sgd_oof_RMSLE = np.sqrt(mean_squared_error(avreal, sgd_avpred))\n        ridge_oof_RMSLE = np.sqrt(mean_squared_error(avreal, ridge_avpred))\n        lgb_oof_RMSLE = np.sqrt(mean_squared_error(avreal, lgb_avpred))\n\n        print('Average SGD RMSLE:\t%.6f' % sgd_cv_score)\n        print(' Out-of-fold SGD RMSLE:\t%.6f' % sgd_oof_RMSLE)\n        print('Average Ridge RMSLE:\t%.6f' % ridge_cv_score)\n        print(' Out-of-fold Ridge RMSLE:\t%.6f' % ridge_oof_RMSLE)\n        print('Average LightGBM RMSLE:\t%.6f' % lgb_cv_score)\n        print(' Out-of-fold LightGBM RMSLE:\t%.6f' % lgb_oof_RMSLE)\n        sgd_score = round(sgd_oof_RMSLE, 6)\n        ridge_score = round(ridge_oof_RMSLE, 6)\n        lgb_score = round(lgb_oof_RMSLE, 6)\n\n        sgd_mpred = sgd_pred / folds\n        ridge_mpred = ridge_pred / folds\n        lgb_mpred = lgb_pred / folds\n\n        blend_time = timer(None)\n\n        blend_train.append(sgd_avpred)\n        blend_train.append(ridge_avpred)\n        blend_train.append(lgb_avpred)\n        blend_train = np.array(blend_train)\n\n        blend_test.append(sgd_mpred)\n        blend_test.append(ridge_mpred)\n        blend_test.append(lgb_mpred)\n        blend_test = np.array(blend_test)\n\n        print('\\n Finding Blending Weights ...')\n        res_list = []\n        weights_list = []\n        #for k in range(1000):\n        for k in range(20):\n            starting_values = np.random.uniform(size=len(blend_train))\n\n            #######\n            # I used to think that weights should not be negative - many agree with that.\n            # I've come around on that issues as negative weights sometimes do help.\n            # If you don't think so, just swap the two lines below.\n            #######\n\n        #    bounds = [(0, 1)]*len(blend_train)\n            bounds = [(-1, 1)] * len(blend_train)\n\n            res = minimize(rmse_min_func,\n                           starting_values,\n                           method='L-BFGS-B',\n                           bounds=bounds,\n                           options={'disp': False,\n                                    'maxiter': 100000})\n            res_list.append(res['fun'])\n            weights_list.append(res['x'])\n            print('{iter}\\tScore: {score}\\tWeights: {weights}'.format(\n                iter=(k + 1),\n                score=res['fun'],\n                weights='\\t'.join([str(item) for item in res['x']])))\n\n        bestSC = np.min(res_list)\n        bestWght = weights_list[np.argmin(res_list)]\n        weights = bestWght\n        blend_score = round(bestSC, 6)\n\n        print('\\n Ensemble Score: {best_score}'.format(best_score=bestSC))\n        print('\\n Best Weights: {weights}'.format(weights=bestWght))\n\n        train_prices = np.zeros(len(blend_train[0]))\n        test_prices = np.zeros(len(blend_test[0]))\n\n        print('\\n Your final model:')\n        for k in range(len(blend_test)):\n            print(' %.6f * model-%d' % (weights[k], (k + 1)))\n            test_prices += blend_test[k] * weights[k]\n\n        for k in range(len(blend_train)):\n            train_prices += blend_train[k] * weights[k]\n        submission = test_prices\n        test_chunk_count = 1\n        del train\n        gc.collect()\n    else:\n        # Drop Id column\n        te_ids_new = test['test_id'].copy()\n        test.drop(\"test_id\", axis = 1, inplace = True)\n\n\n\n        #creating a category for item descriptions that are empty or meaningless\n\n\n        test.item_description = test.item_description.fillna(\"No description yet\")\n        test['has_description'] = test.item_description.apply(lambda row : DescriptionNotMeaningless(row))\n\n        test.brand_name = test.brand_name.fillna(\"No brand name given\")\n        timer(start_time)\n\n        test.brand_name.replace([name for name in test.brand_name if name not in brand_names], 'No brand name given', inplace=True)\n        timer(start_time)\n\n        test['has_brand'] = test.brand_name.apply(lambda row : DescriptionNotMeaningless(row))\n\n\n        test.category_name = test.category_name.fillna(\"No category name given\")\n        test.category_name.replace([name for name in test.category_name if name not in category_names], 'No category name given', inplace=True)\n        test['has_category'] = test.category_name.apply(lambda row : DescriptionNotMeaningless(row))\n\n        #brand price\n        test['brand_price'] = test.brand_name.replace(mapping)\n\n        timer(start_time)\n\n        #category price\n        test['category_price'] = test.category_name.replace(mapping2)\n\n        timer(start_time)\n\n\n\n        test['item_description'] = test['item_description'].astype('category')\n        test['brand_name'] = test['brand_name'].astype('category')\n        test['has_brand'] = test['has_brand'].astype('category')\n        test['has_description'] = test['has_description'].astype('category')\n        test['has_category'] = test['has_category'].astype('category')\n        test['category_name'] = test['category_name'].astype('category')\n\n\n        test.loc[:, numerical_features] = stdSc.transform(test.loc[:, numerical_features])\n        df = test\n        timer(start_time)\n\n\n        print('Encodings')\n        X_name = count.transform(df['name'])\n\n\n        print('Category Encoders')\n        X_category = count_category.transform(df['category_name'])\n\n        print('Descp encoders')\n        X_descp = count_descp.transform(df['item_description'])\n\n        print('Brand encoders')\n        X_brand = vect_brand.transform(df['brand_name'])\n\n\n        print('Dummy Encoders')\n        X_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n            'item_condition_id', 'has_description', 'has_brand', 'has_category', 'shipping'\n        ]], sparse=True).values)\n\n        df_clean = scipy.sparse.hstack((X_dummies, X_brand, X_category, X_descp, X_name,\n                                         scipy.sparse.csr_matrix(df['brand_price']).T,\n                                         scipy.sparse.csr_matrix(df['category_price']).T)).tocsr()\n\n        test = df_clean\n\n        print(test.shape)\n        timer(start_time)\n        test_chunk_count = test_chunk_count+1\n        \n        sgd_pred = sum([model.predict(test) for model in model1])\n        \n        ridge_pred = sum([model.predict(test) for model in model2])\n        \n        lgb_pred = sum([model.predict(test) for model in model3])\n        \n        sgd_mpred = sgd_pred / folds\n        ridge_mpred = ridge_pred / folds\n        lgb_mpred = lgb_pred / folds\n        \n        blend_test = []\n        blend_test.append(sgd_mpred)\n        blend_test.append(ridge_mpred)\n        blend_test.append(lgb_mpred)\n        blend_test = np.array(blend_test)\n\n        test_prices = np.zeros(len(blend_test[0]))\n        for k in range(len(blend_test)):\n            print(' %.6f * model-%d' % (weights[k], (k + 1)))\n            test_prices += blend_test[k] * weights[k]\n        submission = np.concatenate([submission, test_prices], axis=0)\n        te_ids = np.concatenate([te_ids, te_ids_new], axis=0)\n#save for submission\nsubmission = np.expm1(submission)\nsubmission = pd.DataFrame({\n        \"test_id\": te_ids,\n        \"price\": submission\n    })\nsubmission.to_csv('submission.csv', index=False)\ntimer(blend_time)\ntimer(start_time)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}