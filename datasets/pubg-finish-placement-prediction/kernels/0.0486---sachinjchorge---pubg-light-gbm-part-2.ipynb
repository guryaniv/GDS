{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train_V2.csv\")\n\ndf_test = pd.read_csv(\"../input/test_V2.csv\")\n\nprint(\"Train data set :\\n\",df_Train.head())\nprint(\"Test data set :\\n\", df_Test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d544f24d7912baeba4a54de1a71b94ef7455a96f","_kg_hide-output":false},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e127a196fb38c2e3e5e13794d256a85d81515dbf"},"cell_type":"code","source":"df_train.loc[df_train['winPlacePerc'].isna()==True, 'winPlacePerc']= 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1614007d6e2c569f6019063e4433203ce65175af"},"cell_type":"code","source":"df_test['winPlacePerc']= 0.0\ndf_train['Type']= 'Train'\ndf_test['Type']= 'Test'\nprint(df_train.shape, df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c91d23b0359c2a86c6528d473dff505f9dabe013"},"cell_type":"code","source":"df= pd.concat([df_train, df_test], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8478c01cb42692b25af056d86b69fb835521532"},"cell_type":"code","source":"print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4ffda3180f61bd61e4c5b49952779b5e1aaf5bc"},"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff00867eefca4ca7fcac463011acb7f657f500f3"},"cell_type":"code","source":"df= reduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b137d2464d248289fab779ad477b057ac7143f7"},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd9ad5bd2caa20d96e98fb1a7484d996471f6f43"},"cell_type":"code","source":"#df= df.set_index(['Id', 'groupId', 'matchId','Type'])\n\nY_Column = 'winPlacePerc'\n\nColumnList = ['assists', 'boosts', 'damageDealt', 'DBNOs',\n       'headshotKills', 'heals', 'killPlace', 'killPoints', 'kills',\n       'killStreaks', 'longestKill', 'maxPlace', 'numGroups', 'revives',\n       'rideDistance', 'roadKills', 'swimDistance', 'teamKills',\n       'vehicleDestroys', 'walkDistance', 'weaponsAcquired', 'winPoints']\nfor colname in ColumnList:\n    df[colname+ '_1']= df[colname]/ (max(df[colname])- min(df[colname]))\n    print(colname,'_1',' created')\ndf['totalDistance'] = df['rideDistance'] + df['walkDistance'] + df['swimDistance']\ndf['kills_assists'] = (df['kills'] + df['assists'])    \ndf['healthitems'] = df['heals'] + df['boosts']\ndf['kills_']= df['kills'] + df['longestKill']+ df['killStreaks']\ndf['killtypes']= df['headshotKills'] + df['roadKills']+ df['teamKills']+ df['vehicleDestroys']\ndf['Others']= df['damageDealt'] + df['DBNOs']+ df['revives'] + df['weaponsAcquired']\ndf['Points_'] = df['killPoints'] + df['winPoints']\ndf['Rank_Points']= df.groupby(by = ['matchId'])['Points_'].rank(ascending= False)\ndf['Rank_kills']= df.groupby(by = ['matchId'])['kills_'].rank(ascending= False)\ndf['Rank_killassist']= df.groupby(by = ['matchId'])['kills_assists'].rank(ascending= False)\ndf['Rank_GroupPoints']= df.groupby(by = ['groupId'])['Points_'].rank(ascending= False)\ndf['Rank_Groupkills']= df.groupby(by = ['groupId'])['kills_'].rank(ascending= False)\ndf['Rank_killassist']= df.groupby(by = ['groupId'])['kills_assists'].rank(ascending= False)\n\nColumnList = df.columns.tolist()\nprint(ColumnList)\nColumnList.remove('Id')\nColumnList.remove('groupId')\nColumnList.remove('matchId')\nColumnList.remove('Type')\nColumnList.remove('winPlacePerc')\nColumnList.remove('matchType')\n\ndf_Train = df[df['Type']== 'Train']\ndf_Test = df[df['Type']== 'Test']\n\ndf_Train= df_Train.set_index(['Id', 'groupId', 'matchId','Type'])\ndf_Test= df_Test.set_index(['Id', 'groupId', 'matchId','Type'])\n\nX_Train = df_Train[ColumnList]\nY_Train = df_Train[Y_Column]\n\nX_test = df_Test[ColumnList]\n\nprint(X_Train.shape, Y_Train.shape, X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf1c6b0648180d80b0da8ae93a8f51b7466765dd"},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64bb3b1d686c3e03bc4aa9742722b2cdc073d324"},"cell_type":"code","source":"X_Train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ed96a4173b1249dbb469a037ad16be080f86c513"},"cell_type":"code","source":"%%time\n# For tuning parameters\nd_train1 = lgb.Dataset(X_Train, label=Y_Train.values)\nparams = {}\nparams['learning_rate'] = 0.09\nparams['boosting_type'] = 'gbdt'\nparams['objective'] = 'regression'\nparams['metric'] = 'mae'\nparams['sub_feature'] = 0.8\nparams['num_leaves'] = 1000\nparams['min_data'] = 1\nparams['max_depth'] = 400\nparams['min_gain_to_split']= 0.0000001\nclf1 = lgb.train(params, d_train1, 1000)\ny_pred=clf1.predict(X_test)\nprint(y_pred)\n#[0.2522337  0.82816766 0.52467091 ... 0.40437544 0.70938478 0.22089762]\n#CPU times: user 11 s, sys: 432 ms, total: 11.4 s\n#Wall time: 3 s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4331e4ccb4c0aa47c45ff1fe5f18d7e6a77e358a"},"cell_type":"code","source":"# Restore some columns\nX_test = X_test.reset_index()\nX_test[\"winPlacePerc\"] = y_pred\nX_test = X_test[['Id',\"winPlacePerc\"]]\ndf_test = df_test[['Id','groupId']]\ndf_test= df_test.merge(X_test, on = ['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27397f229b3eaaea804ae609bab58222b44f04dd"},"cell_type":"code","source":"df_test[['Id',\"winPlacePerc\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}