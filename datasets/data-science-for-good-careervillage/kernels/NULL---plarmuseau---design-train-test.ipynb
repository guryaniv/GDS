{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\nque = pd.read_csv('../input/questions.csv')\nans = pd.read_csv('../input/answers.csv')\npro = pd.read_csv('../input/professionals.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5858acb5f1b92caabbe6f2375b950543d3bfc21"},"cell_type":"code","source":"que.shape,ans.shape,pro.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"que_ans = que.merge(right=ans, how='inner', left_on='questions_id', right_on='answers_question_id')\nqa_pro = que_ans.merge(right=pro, left_on='answers_author_id', right_on='professionals_id')\nqa_pro.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87b4e446cde74d1f1efc5a0daecb1794b4b78432"},"cell_type":"markdown","source":"# design train test\n* sort on date\n* pick 75% as train 25% as test\n"},{"metadata":{"trusted":true,"_uuid":"3e2b134cb7478d6769a1b6e9ff6c1c8db0116efa"},"cell_type":"code","source":"qa_pro=qa_pro.sort_values('answers_date_added')\ntrain=qa_pro[:37500]\ntest=qa_pro[37500:]\ntrain.shape,test.shape\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6be4ab9dd1c5f5e9b5d4d3ca3d86737522566e82"},"cell_type":"markdown","source":"# Train profession_id on Title\nlets make the slimmest possible model\nwe just train the professions on title\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f2bdeafa8d9e32567782828fdc5f544ef26e6ed4"},"cell_type":"code","source":"import re\n\ndef ngrams(string, n=3):\n    string = re.sub(r'[,-./]|\\sBD',r'', string)\n    ngrams = zip(*[string[i:] for i in range(n)])\n    return [''.join(ngram) for ngram in ngrams]\n\nprint('All 3-grams in \"McDonalds\":')\nngrams('McDonalds')\n\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n!pip install sparse_dot_topn\nimport sparse_dot_topn.sparse_dot_topn as ct\n\ndef awesome_cossim_top(A, B, ntop, lower_bound=0):\n    # force A and B as a CSR matrix.\n    # If they have already been CSR, there is no overhead\n    A = A.tocsr()\n    B = B.tocsr()\n    M, _ = A.shape\n    _, N = B.shape\n \n    idx_dtype = np.int32\n \n    nnz_max = M*ntop\n \n    indptr = np.zeros(M+1, dtype=idx_dtype)\n    indices = np.zeros(nnz_max, dtype=idx_dtype)\n    data = np.zeros(nnz_max, dtype=A.dtype)\n\n    ct.sparse_dot_topn(\n        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n        np.asarray(A.indices, dtype=idx_dtype),\n        A.data,\n        np.asarray(B.indptr, dtype=idx_dtype),\n        np.asarray(B.indices, dtype=idx_dtype),\n        B.data,\n        ntop,\n        lower_bound,\n        indptr, indices, data)\n\n    return csr_matrix((data,indices,indptr),shape=(M,N))\n\n\ndef get_matches_df(sparse_matrix, name_vector, top=100):\n    non_zeros = sparse_matrix.nonzero()\n    \n    sparserows = non_zeros[0]\n    sparsecols = non_zeros[1]\n    \n    if top:\n        nr_matches = top\n    else:\n        nr_matches = sparsecols.size\n    \n    left_row = np.empty([nr_matches], dtype=object)\n    left_side = np.empty([nr_matches], dtype=object)\n    right_row =np.empty([nr_matches], dtype=object)\n    right_side = np.empty([nr_matches], dtype=object)\n    similairity = np.zeros(nr_matches)\n    \n    for index in range(0, nr_matches):\n        #print(index,sparserows[index],name_vector[sparserows[index]])\n        left_row[index] =sparserows[index]\n        right_row[index] =sparsecols[index]\n        left_side[index] = name_vector[sparserows[index]]\n        right_side[index] = name_vector[sparsecols[index]]\n        similairity[index] = sparse_matrix.data[index]\n    \n    return pd.DataFrame({'left_nr':left_row,\n                        'left_side': left_side,\n                         'right_nr':right_row,\n                          'right_side': right_side,\n                           'similarity': similairity})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b09e2cb96d0cb24140f2695c17bc7ad2d2970f5c"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nTxt=train.questions_title\n\nvectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\ntf_idf_matrix = vectorizer.fit_transform(Txt)\ntf_idf_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"438688efa8e31c457bee4a353f51e4ab8b3f0904"},"cell_type":"code","source":"import time\nt1 = time.time()\nmatches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.75)\nt = time.time()-t1\nprint(\"SELFTIMED:\", t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"83e048f51642914bf55a4b442e45ef5540f73674"},"cell_type":"code","source":"print( matches[:10] )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1cccc38f3ff8612067d33b2dc64988fdd20a7125"},"cell_type":"markdown","source":"# WTF why all those doubles ?"},{"metadata":{"trusted":true,"_uuid":"155b46c5c1d32d298aa861f194abe66940794e4d"},"cell_type":"code","source":"matches_df = get_matches_df(matches, Txt.values, top=100000)\nmatches_df = matches_df[matches_df['similarity'] < 0.99999] # Remove all exact matches\nmatches_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}