{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "91ea2c8d-23fe-d7cb-2aad-35650ac6aee0"
      },
      "source": [
        "In this notebook, we will focus on filling the missing values. We define a function that will do us all the data cleansing stuff for us. We will then use it to preprocess our data and then for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8924f850-a377-e43d-4b0d-70f86c1b6458"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as mplt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "% matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09105c8a-dda3-a89a-b89f-132f457fcdae"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"../input/train.csv\", parse_dates=[\"timestamp\"], date_parser=lambda x: pd.datetime.strptime(x, \"%Y-%m-%d\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bd4e6989-a5e8-62e4-faad-99d9db642634"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(\"../input/test.csv\", parse_dates=[\"timestamp\"], date_parser=lambda x: pd.datetime.strptime(x, \"%Y-%m-%d\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "88cb8ac5-13a7-0948-c43f-1d58c84a06b5"
      },
      "outputs": [],
      "source": [
        "def data_cleaning(data, ret_f=True):\n",
        "    features = list()\n",
        "    \n",
        "    data[\"t_year\"] = data.timestamp.map(lambda x: x.year)\n",
        "    data[\"t_year_month\"] = data.timestamp.map(lambda x: x.year * 100 + x.month)\n",
        "    data[\"t_month\"] = data.timestamp.map(lambda x: x.month)\n",
        "    \n",
        "    features.append(\"t_year_month\")\n",
        "    \n",
        "    # build_year\n",
        "    data.loc[np.absolute(data.build_year - data.t_year) > 150, \"build_year\"] = data.t_year\n",
        "    build_dict = data[[\"build_year\", \"sub_area\"]].groupby(\"sub_area\").aggregate(lambda x: stats.mode(x).mode[0]).to_dict()[\"build_year\"]\n",
        "    data.loc[data.build_year.isnull(), \"build_year\"] = data.sub_area.map(lambda x: build_dict[x])\n",
        "    data[\"age_at_transact\"] = data.t_year - data.build_year\n",
        "    features.append(\"age_at_transact\")\n",
        "    \n",
        "    # full_sq\n",
        "    data.loc[data.full_sq < 10, \"full_sq\"] = 10\n",
        "    features.append(\"full_sq\")\n",
        "    \n",
        "    # product-type\n",
        "    data[\"building_type\"] = data.product_type.map(lambda x: 0 if x == \"Investment\" else 1)\n",
        "    features.append(\"building_type\")\n",
        "    \n",
        "    # life_sq\n",
        "    life_sq_mode = stats.mode(data.life_sq).mode[0]\n",
        "    data[\"life_sq\"] = data.life_sq.fillna(life_sq_mode)\n",
        "    data.loc[data.life_sq > data.full_sq, \"life_sq\"] = data.full_sq\n",
        "    features.append(\"life_sq\")\n",
        "    \n",
        "    # floor\n",
        "    data[\"floor\"] = data.floor.fillna(method=\"ffill\")\n",
        "    \n",
        "    # max_floor\n",
        "    max_by_area = data[[\"sub_area\", \"max_floor\"]].groupby(\"sub_area\").aggregate(np.mean).to_dict()[\"max_floor\"]\n",
        "    data[\"max_floor\"] = data.sub_area.map(lambda x: max_by_area[x])\n",
        "    data.loc[data.floor > data.max_floor, \"max_floor\"] = data.floor\n",
        "    data[\"home_height\"] = data.floor / data.max_floor\n",
        "    features.append(\"home_height\")\n",
        "    \n",
        "    # kitch_sq\n",
        "    kitch_mean = data.kitch_sq.mean()\n",
        "    data[\"kitch_sq\"] = data.kitch_sq.fillna(kitch_mean)\n",
        "    data.loc[data.kitch_sq > data.full_sq, \"kitch_sq\"] = data.life_sq / 2\n",
        "    features.append(\"kitch_sq\")\n",
        "    \n",
        "    # num_room\n",
        "    clean_room = data.num_room.mode()\n",
        "    data.loc[data.num_room > 8, \"num_room\"] = clean_room\n",
        "    fill_val = int(data.num_room.median())\n",
        "    data.loc[data.num_room == 0, \"num_room\"] = fill_val\n",
        "    data[\"num_room\"] = data.num_room.fillna(fill_val)\n",
        "    features.append(\"num_room\")\n",
        "    \n",
        "    # material\n",
        "    md_mtrl = data.material.mode()\n",
        "    data[\"material\"] = data.material.fillna(md_mtrl)\n",
        "    features.append(\"material\")\n",
        "    \n",
        "    # product_type\n",
        "    data[\"product_category\"] = data.product_type.map(lambda x: 0 if x == \"Investment\" else 1)\n",
        "    features.append(\"product_category\")\n",
        "    \n",
        "    # state\n",
        "    data.loc[(data.state < 1) & (data.state > 4), \"state\"] = np.nan\n",
        "    fil_val = data.state.mode()\n",
        "    data[\"building_state\"] = data.state.fillna(fil_val)\n",
        "    features.append(\"building_state\")\n",
        "    \n",
        "    #\n",
        "    # NEIGHBOURHOOD FEATURES\n",
        "    #\n",
        "    # area_m\n",
        "    min_area = data.area_m.mean()\n",
        "    data[\"area_m\"] = data.area_m.fillna(min_area)\n",
        "    features.append(\"area_m\")\n",
        "    \n",
        "    # male_f, female_f\n",
        "    data[\"pop_ratio\"] = data[\"male_f\"] / data[\"female_f\"]\n",
        "    features.append(\"pop_ratio\")\n",
        "    \n",
        "    if ret_f:\n",
        "        return data, features\n",
        "    else:\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3406ffc9-be44-3bdc-f4dc-be157c530d5a"
      },
      "outputs": [],
      "source": [
        "train, features = data_cleaning(train, ret_f=True)\n",
        "test = data_cleaning(test, ret_f=False)\n",
        "train[\"target\"] = np.log(train.price_doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6bff74f0-3af3-2b05-7340-b6f90ec326c9"
      },
      "outputs": [],
      "source": [
        "cols = features[:]\n",
        "cols.append(\"target\")\n",
        "corr = train[cols].corr()\n",
        "mask = np.array(corr)\n",
        "mask[np.tril_indices_from(mask)] = False\n",
        "fig, ax = mplt.subplots()\n",
        "fig.set_size_inches(10, 10)\n",
        "sns.heatmap(corr, mask=mask, annot=True, ax=ax, square=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "18b9597a-1485-f43e-1c1d-438f755eb61d"
      },
      "source": [
        "Still there are is some multicollinearity. Will try to handle them...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eba18ede-c694-8147-6cd1-e4d03a61f6ef"
      },
      "outputs": [],
      "source": [
        "train_arr = xgb.DMatrix(train[features], train[\"target\"])\n",
        "test_arr = xgb.DMatrix(test[features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "467a967a-ac93-43b2-c1ec-28634d515fc4"
      },
      "outputs": [],
      "source": [
        "xgb_params = {\n",
        "    'eta': 0.05,\n",
        "    'max_depth': 5,\n",
        "    'subsample': 0.7,\n",
        "    'colsample_bytree': 0.7,\n",
        "    'objective': 'reg:linear',\n",
        "    'eval_metric': 'rmse',\n",
        "    'silent': 1\n",
        "}\n",
        "cv_output = xgb.cv(xgb_params, train_arr, num_boost_round=100, early_stopping_rounds=20,\n",
        "    verbose_eval=50, show_stdv=False)\n",
        "cv_output[[\"train-rmse-mean\", \"test-rmse-mean\"]].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7ab0b193-894f-280f-dbed-bda197f5ad95"
      },
      "outputs": [],
      "source": [
        "num_boost_rounds = len(cv_output)\n",
        "model = xgb.train(dict(xgb_params, silent=0), train_arr, num_boost_round= num_boost_rounds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1c4dcb49-b5ce-171e-7483-fcfb0f006965"
      },
      "outputs": [],
      "source": [
        "featureImportance = model.get_fscore()\n",
        "ftrs = pd.DataFrame()\n",
        "ftrs['features'] = featureImportance.keys()\n",
        "ftrs['importance'] = featureImportance.values()\n",
        "ftrs.sort_values(by=['importance'],ascending=False,inplace=True)\n",
        "fig,ax= mplt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "mplt.xticks(rotation=60)\n",
        "sns.barplot(data=ftrs.head(30),x=\"features\",y=\"importance\",ax=ax,orient=\"v\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e5afd611-ee05-6842-e661-5579ef21434d"
      },
      "outputs": [],
      "source": [
        "test[\"predicted_price\"] = model.predict(test_arr)\n",
        "test[\"price_doc\"] = np.exp(test[\"predicted_price\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d17a5563-0be2-da31-ad9e-c882bc9b57d0"
      },
      "outputs": [],
      "source": [
        "fig, ax = mplt.subplots(ncols=2)\n",
        "stats.probplot(np.log(train.price_doc), plot=ax[0])\n",
        "stats.probplot(test.predicted_price, plot=ax[1])\n",
        "ax[0].set_title(\"Training Data\")\n",
        "ax[1].set_title(\"Test Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5fb35598-00d6-a6c4-9d57-af425deb6c1b"
      },
      "outputs": [],
      "source": [
        "test[[\"id\", \"price_doc\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0dec9ff8-2011-de4c-e0ed-2005e360699a"
      },
      "outputs": [],
      "source": [
        "test[[\"id\", \"price_doc\"]].to_csv(\"submission_xgb.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2bbd531a-ee76-c584-0769-158426c78855"
      },
      "source": [
        "Kindly, upvote if you find it useful."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}