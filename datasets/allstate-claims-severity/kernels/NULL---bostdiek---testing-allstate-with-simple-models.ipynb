{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "74b1d89f-834c-2d65-af3a-955335e05170"
      },
      "source": [
        "Examine the columns and convert the categorical data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c74cca73-833e-02d9-ffb4-da782668ac5f"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b6391f8b-31c5-a603-e8be-a12baa1b8e14"
      },
      "outputs": [],
      "source": [
        "data_train_raw = pd.read_csv('../input/train.csv')\n",
        "data_test_raw = pd.read_csv('../input/test.csv')\n",
        "# print(data_train_raw.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2fd68f19-8721-4171-02aa-9143242096b7"
      },
      "source": [
        "How many unique values are in each categorical column?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ac861346-424e-cc35-3a9a-5483154f7bd0"
      },
      "outputs": [],
      "source": [
        "col_uniques=[]\n",
        "for col in data_train_raw.columns:\n",
        "    if (col.find('cat') !=-1):\n",
        "        col_uniques.append([col, len(data_train_raw[col].unique())])\n",
        "print(col_uniques)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dcc00d4a-6b9e-2231-244f-95250f4efe08"
      },
      "source": [
        "Now convert the data using the label encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c06bf03-0a64-3cd9-1d9f-9ccf2a8848a7"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "for col in data_train_raw.columns:\n",
        "    if (col.find('cat') !=-1):\n",
        "      #  print(col)\n",
        "        data_train_raw[str(col+'_numerical')]=le.fit_transform(data_train_raw[col])\n",
        "        data_test_raw[col] = data_test_raw[col].map(lambda s: '<unknown>' if s not in le.classes_ else s)\n",
        "        le.classes_ = np.append(le.classes_, '<unknown>')\n",
        "        data_test_raw[str(col+'_numerical')]=le.transform(data_test_raw[col])\n",
        "print(data_train_raw.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f6bf1ec9-18dc-fea4-32a8-97bfecb59429"
      },
      "source": [
        "There are many different columns now, so it will be difficult to view all of the data. While we could loop through all of the categories and look for interesting things, lets first do a principle component analysis. First I will normalize all of the numerical columns (after splitting into a training and validation sample)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57cf5300-3286-e1ab-8f41-307c75c21451"
      },
      "outputs": [],
      "source": [
        "XCols =[0]\n",
        "datacols=data_train_raw.columns\n",
        "for c in range(len(datacols)):\n",
        "    if(datacols[c].find('cont')!=-1 or datacols[c].find('numerical')!=-1):\n",
        "        XCols.append(c)\n",
        "X_total = data_train_raw[XCols]\n",
        "Y_total = data_train_raw['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b24e0fa8-d957-99dc-b51d-f9f6a4a4cd53"
      },
      "outputs": [],
      "source": [
        "XColst =[0]\n",
        "datacols=data_test_raw.columns\n",
        "for c in range(len(datacols)):\n",
        "    if(datacols[c].find('cont')!=-1 or datacols[c].find('numerical')!=-1):\n",
        "        XColst.append(c)\n",
        "X_test = data_test_raw[XColst]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2fe35fe5-1ce8-e34a-3506-fc8e7e2aef47"
      },
      "outputs": [],
      "source": [
        "# data_test_raw[XColst]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "63635e81-188b-9849-1318-be1768b7f8ce"
      },
      "source": [
        "Let's look at the loss column. This will show that it will be better to predict the log of the loss and then take the exponent of the prediction later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06cd607e-bdb2-4f27-3fcc-407cc98ab566"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(Y_total,100)\n",
        "plt.title('loss')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(np.log(Y_total),100)\n",
        "plt.title('log(loss)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e06763d-f0e2-c9b2-7802-0474897ff71d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_total, Y_total, test_size=0.4, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b86deff-508e-b58a-b96a-aabd258e9c06"
      },
      "source": [
        "Now we normalize all of the columns, we will save the transformation parameters so they can be used by the validation and test samples. Note that the 'cont' columns are already in the range (0,1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8adf8866-9943-61f8-6d50-3e1d50362bc3"
      },
      "outputs": [],
      "source": [
        "stds=[1]\n",
        "means=[0]\n",
        "xcols=list(X_train.columns)\n",
        "\n",
        "\n",
        "for c in range(1,len(xcols)):\n",
        "    mm = X_train[xcols[c]].mean()\n",
        "    ss = X_train[xcols[c]].std()\n",
        "    \n",
        "    means.append(mm)\n",
        "    stds.append(ss)\n",
        "    \n",
        "#    print(xcols[c],r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8f6a226-ce95-d998-1bb9-23630b71cc98"
      },
      "outputs": [],
      "source": [
        "X_train = (X_train[xcols] - means) / stds\n",
        "X_valid = (X_valid[xcols] - means) / stds\n",
        "X_test = (X_test[xcols] - means) / stds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb9508ab-eb68-d4a0-ebc6-8d048002bfe5"
      },
      "outputs": [],
      "source": [
        "xcols.remove('id')\n",
        "\n",
        "print(\"Train\")\n",
        "print(X_train[xcols[100]].describe())\n",
        "print(\"Valid\")\n",
        "print(X_valid[xcols[100]].describe())\n",
        "print(\"Test\")\n",
        "print(X_test[xcols[100]].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c5660f66-4675-4a42-530c-a669903c1ab4"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters=8,n_jobs=-1)\n",
        "km.fit(X_train[xcols])\n",
        "\n",
        "X_train['km']=km.predict(X_train[xcols])\n",
        "X_valid['km']=km.predict(X_valid[xcols])\n",
        "X_test['km']=km.predict(X_test[xcols])\n",
        "xcols.append('km')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57fb8d89-1e7d-f5fb-5820-8ad61016d632"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(X_train[xcols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b368412e-d2b6-2f99-0975-4e46ad84d357"
      },
      "outputs": [],
      "source": [
        "X_train_transformed = pca.transform(X_train[xcols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14dac1be-b4f3-a17b-d839-547eca07e047"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.scatter(X_train_transformed[:,0],y_train)\n",
        "plt.title('First Axis')\n",
        "plt.ylabel('loss')\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.scatter(X_train_transformed[:,1],y_train)\n",
        "plt.title('Second Axis')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f0cbd855-57ef-1030-1065-643ea65d9da4"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_train_transformed[:,0], X_train_transformed[:,1], np.log(y_train))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1be098c3-e7ea-4d75-8f3a-2f2a7c5e91c3"
      },
      "source": [
        "There may be some correlations in the data here, but it appears that the PCA here is loosing much of the variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "16b4dfc0-4953-f621-e62d-6c8f48c60cce"
      },
      "source": [
        "## Attempt some simple models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cb319f56-f5c3-f41b-f16a-643d364dc7f8"
      },
      "source": [
        "### Random forrest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "73d5afd7-e8ff-aa90-d8d6-5d672eeb8547"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rfr = RandomForestRegressor(n_estimators= 400, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "786fc95a-f763-19a6-0ebc-b5da2d42a402"
      },
      "outputs": [],
      "source": [
        "rfr.fit(X_train[xcols],np.log(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f3f6509c-0408-676c-0b79-3f7c474c58df"
      },
      "outputs": [],
      "source": [
        "X_train['rfr']=np.exp(rfr.predict(X_train[xcols]))\n",
        "X_valid['rfr']=np.exp(rfr.predict(X_valid[xcols]))\n",
        "X_test['rfr']=np.exp(rfr.predict(X_test[xcols]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6a01dc0-f700-09b0-4b52-26274e9c48e5"
      },
      "outputs": [],
      "source": [
        "trainscore=mean_squared_error(X_train['rfr'],y_train)\n",
        "validscore=mean_squared_error(X_valid['rfr'],y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a91cbf6-d073-7823-1a8a-592b7da79376"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(r'Training score='+str(trainscore))\n",
        "plt.scatter(X_train['rfr'], y_train)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(r'Validation score='+str(validscore))\n",
        "plt.scatter(X_valid['rfr'], y_valid)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0e38306c-8deb-4c08-d2d4-d0c088e52af7"
      },
      "source": [
        "We see that the validation set is preforming much worse with the default random forrest hyper parameters. We could try fixing this for overtraining. However, lets first run this on the test set to get a first score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "73034f60-1f0b-bfa1-32b3-9d8328c3d981"
      },
      "outputs": [],
      "source": [
        "X_test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "26be6d02-2b20-53d7-1358-a2444d5eea85"
      },
      "outputs": [],
      "source": [
        "rfrpred=pd.DataFrame(list(zip(X_test['id'],X_test['rfr'])),columns=('id','loss'))\n",
        "rfrpred['id']=rfrpred['id'].astype('int')\n",
        "                     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "923af531-5f33-d5f2-14b8-0b4db6880fd2"
      },
      "outputs": [],
      "source": [
        "rfrpred.to_csv('submit_RFR_' +str(validscore) +'.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2299599d-71a8-e9ea-6554-02ab4f48c9ae"
      },
      "outputs": [],
      "source": [
        "list(enumerate(sorted(list(zip(xcols,rfr.feature_importances_)), key=lambda l:l[1], reverse=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6e6fa67f-514d-b20d-4646-71023f8987cc"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d8c54655-9785-986a-18bf-42d6b51307dd"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b3f5838b-fd8b-eb3d-1b6a-ed998dbd515b"
      },
      "outputs": [],
      "source": [
        "rid = Ridge(alpha=1e-6, fit_intercept=True, normalize=False, \n",
        "                  copy_X=True, max_iter=None, tol=0.001, solver='auto', random_state=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "87b5e1a4-1e45-9a70-f57d-322894a62e9b"
      },
      "outputs": [],
      "source": [
        "rid.fit(X_train[xcols],np.log(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e7fa638a-a547-c5fc-8946-8ae17a7b7543"
      },
      "outputs": [],
      "source": [
        "X_train['rid'] = np.exp(rid.predict(X_train[xcols]))\n",
        "X_valid['rid'] = np.exp(rid.predict(X_valid[xcols]))\n",
        "X_test['rid'] = np.exp(rid.predict(X_test[xcols]))\n",
        "\n",
        "trainscore=mean_squared_error(X_train['rid'],y_train)\n",
        "testscore=mean_squared_error(X_valid['rid'],y_valid)\n",
        "print(trainscore,testscore)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "069d971f-cddd-578f-82e5-33bb94606e36"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(r'Training score='+str(trainscore))\n",
        "plt.scatter(X_train['rid'], y_train)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(r'Validation score='+str(testscore))\n",
        "plt.scatter(X_valid['rid'], y_valid)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5bab303-1cfd-1acc-2366-0e8cc2717b05"
      },
      "outputs": [],
      "source": [
        "ridpred=pd.DataFrame(list(zip(X_test['id'],X_train['rid'])),columns=('id','loss'))\n",
        "ridpred['id']=ridpred['id'].astype('int')\n",
        "ridpred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66b3ca34-9fb4-f777-cfd2-3de01207556a"
      },
      "outputs": [],
      "source": [
        "rid.feature_importances_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2082c85a-deca-27a9-c748-a0a7193cd502"
      },
      "outputs": [],
      "source": [
        "ridpred.to_csv('submit_ridge_' +str(testscore) +'.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7ebf3770-db80-95c3-d18f-9a78440db44f"
      },
      "source": [
        "## Basic NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05f3e44f-7962-df98-6171-986c0095e506"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "mlpnnR = MLPRegressor(hidden_layer_sizes=(int(X_train.shape[1]/2),int(X_train.shape[1]/2), int(X_train.shape[1]/2),int(X_train.shape[1]/2)), \n",
        "                       activation='logistic', \n",
        "                       solver='adam', \n",
        "                       alpha=0.1, \n",
        "                       batch_size='auto',\n",
        "#                        learning_rate='adaptive',\n",
        "                       learning_rate_init=0.0001,\n",
        "                       power_t=0.5, max_iter=200,\n",
        "                       shuffle=True, \n",
        "                       random_state=None, \n",
        "                       tol=0.0001, \n",
        "                       verbose=True,\n",
        "                       warm_start=False,\n",
        "                       momentum=0.9,\n",
        "                       nesterovs_momentum=True, early_stopping=False, \n",
        "                       validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
        "                       epsilon=1e-08)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db43529c-11a1-997e-067c-7c2951bbb9d2"
      },
      "outputs": [],
      "source": [
        "mlpnnR.fit(X_train[xcols],np.log(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9176968f-6b10-70e7-ce21-399fe70ce91b"
      },
      "outputs": [],
      "source": [
        "X_train['nn'] = np.exp(mlpnnR.predict(X_train[xcols]))\n",
        "X_valid['nn'] = np.exp(mlpnnR.predict(X_valid[xcols]))\n",
        "X_test['nn'] = np.exp(mlpnnR.predict(X_test[xcols]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "300b1605-785d-a33a-b141-d0a6cb420958"
      },
      "outputs": [],
      "source": [
        "trainnnpred=X_train['nn']\n",
        "validnnpred=X_valid['nn']\n",
        "\n",
        "nnscoret=mean_squared_error(trainnnpred,y_train)\n",
        "nnscorev=mean_squared_error(validnnpred,y_valid)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(r'Training score='+str(nnscoret))\n",
        "plt.scatter(trainnnpred, y_train)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(r'Validation score='+str(nnscorev))\n",
        "plt.scatter(validnnpred, y_valid)\n",
        "plt.xlabel('Prediction')\n",
        "plt.ylabel('Truth')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d152cea0-2d91-be68-1012-e181190d6267"
      },
      "outputs": [],
      "source": [
        "mlpout=pd.DataFrame(\n",
        "    list(zip(X_test['id'],X_test['nn'])),\n",
        "    columns=('id','loss'))\n",
        "mlpout['id']=mlpout['id'].astype('int')\n",
        "mlpout.head()\n",
        "mlpout.to_csv('submit_nnet_' +str(nnscorev) +'.csv', \n",
        "               index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "002679bf-d8aa-33d2-53ec-386e1237ae63"
      },
      "source": [
        "## Make an average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d88cdca-73bf-4fe7-6838-c208bb621bae"
      },
      "outputs": [],
      "source": [
        "Ave2=pd.DataFrame()\n",
        "Ave2['id']=ridpred['id']\n",
        "Ave2['loss']=(1/testscore*ridpred['loss'] + 1/validscore*rfrpred['loss'] + 1/nnscorev*mlpout['loss'])/(1/testscore+1/validscore+1/nnscorev)\n",
        "\n",
        "Ave2.head()\n",
        "Ave2.to_csv('Average.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}