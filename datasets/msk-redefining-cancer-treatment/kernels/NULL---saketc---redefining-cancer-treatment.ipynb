{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "nbconvert_exporter": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "01b5268b-d907-4c9b-9f19-3be79210f02b", "_uuid": "a538002f2843466e697df3315921f642d239cacb"}, "source": ["from sklearn import preprocessing, pipeline, feature_extraction, decomposition, model_selection, metrics, cross_validation, svm\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n", "from sklearn.base import BaseEstimator, TransformerMixin\n", "from sklearn.feature_selection import SelectKBest, chi2\n", "from sklearn.preprocessing import normalize, Imputer\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.naive_bayes import MultinomialNB\n", "\n", "import sklearn\n", "import pandas as pd\n", "import numpy as np\n", "import xgboost as xgb\n", "\n", "import datetime"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "94d712f2-934d-467a-bd03-8142be7d9cb5", "_uuid": "eb9ed284284ef6c8cccc18e6a632b9b5fdc4aa4f"}, "source": ["### Loading data"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "3f9d7fc5-7acc-4e28-bcc3-f2be10ea8683", "_uuid": "29e39bb12cf89210c90bd7ecaeda258d6106669d"}, "source": ["train = pd.read_csv('../input/training_variants')\n", "test = pd.read_csv('../input/test_variants')\n", "trainx = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "testx = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "\n", "train = pd.merge(train, trainx, how='left', on='ID').fillna('')\n", "y = train['Class'].values\n", "train = train.drop(['Class'], axis=1)\n", "\n", "test = pd.merge(test, testx, how='left', on='ID').fillna('')\n", "pid = test['ID'].values"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "88d00557-765c-4f79-9733-49be82ed9840", "_uuid": "3e726a693b498d4f493c5277be049af131e33d3a"}, "source": ["### Feature Engineering"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "e4389380-65d7-4cf1-8ffd-921d05cf6fdf", "_uuid": "55191357a1a0d77cfb0f66a930b7cc451a645860"}, "source": ["class cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n", "    def fit(self, x, y=None):\n", "        return self\n", "    def transform(self, x):\n", "        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n", "        return x\n", "\n", "class cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n", "    def __init__(self, key):\n", "        self.key = key\n", "    def fit(self, x, y=None):\n", "        return self\n", "    def transform(self, x):\n", "        return x[self.key].apply(str)\n", "\n", "#commented for Kaggle Limits\n", "('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), \n", "                           ('tfidf_Text', feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2))), \n", "                           ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))"], "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "61946698-ec4f-438d-b5b0-a96cf92b234c", "_uuid": "65d6aa37af8def324035e9b41c0409843cb51866"}, "source": ["### Training model\n"], "cell_type": "markdown"}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "f7e047b1-5346-4cb2-81e3-d2d269e1ac99", "_uuid": "4ea2dc12dd1f2dbc562c81cc16100012be5f5cea"}, "source": ["print('Pipeline...')\n", "fp = pipeline.Pipeline([\n", "    ('union', pipeline.FeatureUnion(\n", "        n_jobs = -1,\n", "        transformer_list = [\n", "            ('standard', cust_regression_vals()),\n", "            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), \n", "                                       ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n", "                                       ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n", "            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), \n", "                                       ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), \n", "                                       ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n", "            #commented for Kaggle Limits\n", "#             ('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), \n", "#                                        ('hv', feature_extraction.text.HashingVectorizer(decode_error='ignore', n_features=2 ** 16, non_negative=True, ngram_range=(1, 3))),\n", "#                                        ('tfidf_Text', feature_extraction.text.TfidfTransformer()), \n", "#                                        ('tsvd3', decomposition.TruncatedSVD(n_components=300, n_iter=25, random_state=12))]))\n", "\n", "        \n", "        ])\n", "    )])\n", "\n", "\n", "train = fp.fit_transform(train)\n", "print (train.shape)\n", "\n", "test_t = np.empty([0, train.shape[1]])\n", "step = 200\n", "for i in range(0, len(test), step):\n", "    step_end = i+step\n", "    step_end = step_end if step_end < len(test) else len(test)\n", "    _test = fp.transform(test.iloc[i:step_end])\n", "    test_t = np.vstack((test_t, _test))\n", "test = test_t\n", "print (test.shape)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "83ce7082-bd8c-4800-b228-59c9f5a00816", "_uuid": "a4438f78156301257c5d69b60a1ce0bfac5d5bd0"}, "source": ["y = y - 1 #fix for zero bound array\n", "\n", "denom = 0\n", "fold = 1 #Change to 5, 1 for Kaggle Limits\n", "for i in range(fold):\n", "    params = {\n", "        'eta': 0.03333,\n", "        'max_depth': 4,\n", "        'objective': 'multi:softprob',\n", "        'eval_metric': 'mlogloss',\n", "        'num_class': 9,\n", "        'seed': i,\n", "        'silent': True\n", "    }\n", "    x1, x2, y1, y2 = model_selection.train_test_split(train, y, test_size=0.18, random_state=i)\n", "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n", "    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n", "    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n", "    print(score1)\n", "    #if score < 0.9:\n", "    if denom != 0:\n", "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n", "        preds += pred\n", "    else:\n", "        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n", "        preds = pred.copy()\n", "    denom += 1\n", "    submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n", "    submission['ID'] = pid\n", "    submission.to_csv('submission_xgb_fold_'  + str(i) + '.csv', index=False)\n", "preds /= denom\n", "submission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\n", "submission['ID'] = pid\n", "submission.to_csv('submission_1_xgb.csv', index=False)"], "cell_type": "code", "outputs": []}, {"execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "ef7b83d8-4e65-434c-a324-d6c31b319b31", "_uuid": "e7bf25ddd9fbe1536a7fe68b4cc149a8f9f498a7"}, "source": [], "cell_type": "code", "outputs": []}], "nbformat_minor": 2, "nbformat": 4}