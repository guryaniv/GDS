{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "name": "python", "nbconvert_exporter": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3"}}, "cells": [{"metadata": {"_cell_guid": "c737d116-bfc8-4172-a7a8-b2d3a81bb067", "collapsed": true, "_uuid": "de47fedafc1cc9a334aca06e94097587ee64419e"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from fbprophet import Prophet\n", "from statsmodels.tsa.stattools import adfuller\n", "from sklearn.preprocessing import LabelEncoder\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.metrics import classification_report\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "56bb1270-8415-4299-a435-9ab80e94e8e4", "_uuid": "09ad60d1224f37af9547a9775a6a752d0bce6251"}, "source": ["Generally let us divide process to the 4 main parts. \n", "1. Data preparation.\n", "2. Data exploration.\n", "3. Model selection & fitting.\n", "4. Model evaluation."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "feac6433-cd81-4057-b361-d40e845e4a53", "_uuid": "b2f0ae13356fcb72dafd7901d645639dbc6db88e"}, "source": ["Data preparation. \n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "172439b3-1d6e-4862-8f01-c3c618d233d4", "collapsed": true, "_uuid": "3ba20183f6b7cf9f36bcbdee630412c8d5d36f52"}, "source": ["data = {\n", "    'tra': pd.read_csv('../input/air_visit_data.csv'),\n", "    'as': pd.read_csv('../input/air_store_info.csv'),\n", "    'hs': pd.read_csv('../input/hpg_store_info.csv'),\n", "    'ar': pd.read_csv('../input/air_reserve.csv'),\n", "    'hr': pd.read_csv('../input/hpg_reserve.csv'),\n", "    'id': pd.read_csv('../input/store_id_relation.csv'),\n", "    'tes': pd.read_csv('../input/sample_submission.csv'),\n", "    'hol': pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n", "    }\n", "\n", "data['hr'] = pd.merge(data['hr'], data['id'], how='inner', on=['hpg_store_id'])\n", "\n", "for df in ['ar','hr']:\n", "    data[df]['visit_datetime'] = pd.to_datetime(data[df]['visit_datetime'])\n", "    data[df]['visit_datetime'] = data[df]['visit_datetime'].dt.date\n", "    data[df]['reserve_datetime'] = pd.to_datetime(data[df]['reserve_datetime'])\n", "    data[df]['reserve_datetime'] = data[df]['reserve_datetime'].dt.date    \n", "    data[df]['reserve_datetime_diff'] = data[df].apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).days, axis=1)\n", "    data[df] = data[df].groupby(['air_store_id','visit_datetime'], as_index=False)[['reserve_datetime_diff', 'reserve_visitors']].sum().rename(columns={'visit_datetime':'visit_date'})\n", "    data['tra']['visit_date'] = pd.to_datetime(data['tra']['visit_date'])\n", "    \n", "data['tra']['dow'] = data['tra']['visit_date'].dt.dayofweek\n", "data['tra']['year'] = data['tra']['visit_date'].dt.year\n", "data['tra']['month'] = data['tra']['visit_date'].dt.month\n", "data['tra']['visit_date'] = data['tra']['visit_date'].dt.date\n", "\n", "data['tes']['visit_date'] = data['tes']['id'].map(lambda x: str(x).split('_')[2])\n", "data['tes']['air_store_id'] = data['tes']['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n", "data['tes']['visit_date'] = pd.to_datetime(data['tes']['visit_date'])\n", "data['tes']['dow'] = data['tes']['visit_date'].dt.dayofweek\n", "data['tes']['year'] = data['tes']['visit_date'].dt.year\n", "data['tes']['month'] = data['tes']['visit_date'].dt.month\n", "data['tes']['visit_date'] = data['tes']['visit_date'].dt.date\n", "\n", "unique_stores = data['tes']['air_store_id'].unique()\n", "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n", "\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].min().rename(columns={'visitors':'min_visitors'})\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow']) \n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].mean().rename(columns={'visitors':'mean_visitors'})\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].median().rename(columns={'visitors':'median_visitors'})\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n", "tmp = data['tra'].groupby(['air_store_id','dow'], as_index=False)['visitors'].max().rename(columns={'visitors':'max_visitors'})\n", "stores = pd.merge(stores, tmp, how='left', on=['air_store_id','dow'])\n", "\n", "stores = pd.merge(stores, data['as'], how='left', on=['air_store_id']) \n", "lbl = LabelEncoder()\n", "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n", "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])\n", "\n", "data['hol']['visit_date'] = pd.to_datetime(data['hol']['visit_date'])\n", "data['hol']['day_of_week'] = lbl.fit_transform(data['hol']['day_of_week'])\n", "data['hol']['visit_date'] = data['hol']['visit_date'].dt.date\n", "train = pd.merge(data['tra'], data['hol'], how='left', on=['visit_date']) \n", "test = pd.merge(data['tes'], data['hol'], how='left', on=['visit_date']) \n", "\n", "train = pd.merge(data['tra'], stores, how='left', on=['air_store_id','dow']) \n", "test = pd.merge(data['tes'], stores, how='left', on=['air_store_id','dow'])\n", "\n", "for df in ['ar','hr']:\n", "    train = pd.merge(train, data[df], how='left', on=['air_store_id','visit_date']) \n", "    test = pd.merge(test, data[df], how='left', on=['air_store_id','visit_date'])\n", "    \n", "train = train.fillna(-1)\n", "test = test.fillna(-1)\n", "\n", "col = [c for c in train if c not in ['id', 'air_store_id', 'visit_date', 'visitors']]\n", "train = train.fillna(-1)\n", "test = test.fillna(-1)\n", "\n", "train.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5e4cb7ba-a750-4ef3-b64b-76b0376ecf15", "_uuid": "f22de53eb0f2abad6d37eb5f7c7cf21a731ea7bc"}, "source": ["Data exploration"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "70328a72-5f0b-4ae4-b64c-12a2e485eb24", "collapsed": true, "_uuid": "b3ebdb19f3e96329cf6d7d427a879d7806aa0908"}, "source": ["train.describe()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "fa5ada58-d2a0-4106-8874-d40a8ed7a59d", "_uuid": "a3532f0e5181cffcef8660962c909c69d274df4c"}, "source": ["I can reccomend library to save a lot of time for statistical exploration of the data."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "f181ddb7-62f4-4312-a60a-03d41aad3160", "collapsed": true, "_uuid": "f070e8aa5f868de854a39c1e56be824e96dbea3d"}, "source": ["import pandas_profiling"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e0eddd5d-60d4-4373-a34f-71eb817bb1b7", "collapsed": true, "_uuid": "132f814c71408d0e2884ca34e4dc8bf131e8b789"}, "source": ["pandas_profiling.ProfileReport(train)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "545ee50d-a7f7-44c0-a27c-3c7e09d066a8", "_uuid": "b7fc100d495a881ab1995545768d813b6a18248b"}, "source": ["Stationarity test."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "d962cfb0-0872-4767-9014-874020320829", "collapsed": true, "_uuid": "4fbd02f0bc5f22b4089bceb477b02d02d779043a"}, "source": ["% time date = train.groupby('visit_date').nunique()\n", "date['visitors'] = train.groupby('visit_date').visitors.agg('sum')"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "21ed0bd3-b9ae-4ec1-85b8-6d55f10582ab", "collapsed": true, "_uuid": "ad2e24c7342da6f57e78e6e7417cb2507e597067"}, "source": ["def test_stationarity(ts):\n", "    \n", "    #Determing rolling statistics\n", "    rolmean = ts.rolling(window=2, center=False).mean()\n", "    rolstd = ts.rolling(window=2, center=False).std()\n", "\n", "    #Plot rolling statistics:\n", "    orig = plt.plot(ts, color='blue', label='Original')\n", "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n", "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n", "    plt.legend(loc='best')\n", "    fig_size[0] = 20\n", "    fig_size[1] = 10\n", "    plt.rcParams[\"figure.figsize\"] = fig_size\n", "    plt.title('Rolling Mean & Standard Deviation')\n", "    plt.show(block=False)\n", "    \n", "    #Perform Dickey-Fuller test:\n", "    print ('Results of Dickey-Fuller Test:')\n", "    dftest = adfuller(ts, autolag='AIC')\n", "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n", "    for key, value in dftest[4].items():\n", "        dfoutput['Critical Value (%s)' % key] = value\n", "    print(dfoutput)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "b96c83e0-d245-4913-bb91-97a8efa031ce", "collapsed": true, "_uuid": "7424bf34149dceab9d0a520511131ff777da9032"}, "source": ["fig_size = plt.rcParams[\"figure.figsize\"]\n", "fig_size\n", "fig_size[0] = 12\n", "fig_size[1] = 9\n", "plt.rcParams[\"figure.figsize\"] = fig_size"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "25a93678-427e-4b4a-af61-45c20154ecc9", "collapsed": true, "_uuid": "175c679647500bc8b3eea76cafaf57d47fa98dba"}, "source": ["date.index"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "8817085a-13c2-4ec7-ab3b-24b8363c3c4a", "collapsed": true, "_uuid": "7850e0ff59a8023e0f4dae4d4d28ef445baf4ad9"}, "source": ["ts = date['visitors']\n", "ts.head(20)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "e2db1704-9ab1-4c55-ae6b-cc0334722c6c", "collapsed": true, "_uuid": "72ecec031ae9e83a33c973d9d3dc604f505ad394"}, "source": ["X = ts.values\n", "ts.dropna(inplace=True)\n", "test_stationarity(ts)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "0ac75347-f942-4c84-bc41-b50d73979142", "collapsed": true, "_uuid": "f2a80cee40d17e16286ad1df5670c985492cad71"}, "source": ["ts_log = np.log(ts)\n", "plt.plot(ts_log)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "15443782-8816-4df5-af63-5466da903dfb", "collapsed": true, "_uuid": "ff4dd7297d2c59e99a2c4d5d42f088fd69d01df6"}, "source": ["test_stationarity(ts_log)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "7ba6b995-f88c-4550-b787-a6ba5fea9ad1", "_uuid": "bb088ba616e72523d21616987714c9dbf3d4a738"}, "source": ["Prophet forecasting"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "71f1ce4e-89e5-4cd3-bdfa-741469317c15", "collapsed": true, "_uuid": "77f9b0db9c5cd9966515678bcaa7134a0da9a806"}, "source": ["import logging\n", "logging.getLogger('fbprophet.forecaster').propagate = False\n", "\n", "df_sub = pd.read_csv('../input/sample_submission.csv')\n", "df_sub['store_id'] = df_sub['id'].apply(lambda x:x[:-11])\n", "\n", "df_sub = df_sub.set_index('id')\n", "\n", "number_of_stores = df_sub['store_id'].nunique()\n", "date_range = pd.date_range(start=pd.to_datetime('2016-07-01'),\n", "                           end=pd.to_datetime('2017-04-22'))\n", "forecast_days = (pd.to_datetime('2017-05-31')-pd.to_datetime('2017-04-22')).days\n", "\n", "for cnt, store_id in enumerate(df_sub['store_id'].unique()):\n", "    print('Predicting %d of %d.'%(cnt, number_of_stores), end='\\r')\n", "    data = train[train['air_store_id'] == store_id]\n", "    data = data[['visit_date', 'visitors']].set_index('visit_date')\n", "    # Ensure we have full range of dates.\n", "    data = data.reindex(date_range).fillna(0).reset_index()\n", "    data.columns = ['ds', 'y']\n", "    \n", "    m = Prophet()\n", "    #m = Prophet(yearly_seasonality=True, mcmc_samples=300)\n", "    #m.add_seasonality(name='weekly', period=7, fourier_order=3)\n", "    m.fit(data)\n", "    future = m.make_future_dataframe(forecast_days)\n", "    forecast = m.predict(future)\n", "    forecast = forecast[['ds', 'yhat']]\n", "    forecast.columns = ['id', 'visitors']\n", "    forecast['id'] = forecast['id'].apply(lambda x:'%s_%s'%(store_id, x.strftime('%Y-%m-%d')))\n", "    forecast = forecast.set_index('id')\n", "    df_sub.update(forecast)\n", "print('\\n\\nDone.')"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "20a2bbe5-6aaf-4e64-8ad7-0b0eb25bb2c4", "collapsed": true, "_uuid": "c2edcadb0fb82e0a537849c2fef4a7a84b3a595c"}, "source": ["df_sub"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "177c44cd-0b2b-4a9d-9657-9fde3569de18", "collapsed": true, "_uuid": "3a9141b4ba18d50d8c226062b6814d7656bdb13e"}, "source": ["df_sub = df_sub.reset_index()[['id','visitors']]\n", "df_sub['visitors'] = df_sub['visitors'].clip(lower=0)\n", "df_sub.to_csv('submission_1.csv', index=False)\n", "df_sub.head(10)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "98b29ed5-1367-439d-8a00-e5b76b8ead4d", "_uuid": "e8a406ac42c751da68052d81d9d2518603656fc6"}, "source": ["Let us check overall trends on the markets."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "2239798f-8e36-42c5-af1e-cf6eb08d3a53", "collapsed": true, "_uuid": "b339af4c75b425e9d9d90f543726c88419af8865"}, "source": ["date_amount = pd.DataFrame(date, columns=['visit_date', 'visitors'])\n", "date_amount.index"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "39e91c7f-0ebc-44ce-bf5a-d05e340cf31b", "collapsed": true, "_uuid": "27c39d2356bb2168b0cf2c2bbe29f2036f5c743e"}, "source": ["def to_prophet(df_ts):\n", "    df = pd.DataFrame(df_ts, columns=['visit_date', 'visitors'])\n", "    df.drop(['visit_date'], axis=1, inplace=True)\n", "    df.reset_index(inplace=True)\n", "    df.rename(columns={\"visit_date\": \"ds\", \"visitors\": \"y\"}, inplace=True)\n", "    return df"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "bd59c405-db78-42d1-8e13-d417324ded54", "collapsed": true, "_uuid": "1241dbdadcf392bfc1a2decaf2f3e1f9b95af6aa"}, "source": ["date = to_prophet(date)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "207e6c93-6310-45dc-97e8-4e90511650f2", "collapsed": true, "_uuid": "8d82a144d0f33fbedc3a229775c7dc3ebd9453b0"}, "source": ["m = Prophet(daily_seasonality=True, mcmc_samples=150)\n", "m.fit(date)\n", "future = m.make_future_dataframe(periods=40)\n", "future.head()\n", "forecast = m.predict(future)\n", "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "54d9d654-8b6c-4aae-a446-3d0344b7962d", "collapsed": true, "_uuid": "810fbbca3fce532c6fcbc423f14b6a9f55b85820"}, "source": ["m.plot(forecast);"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "a24ecea4-09be-44f2-a56e-61b2677b58ea", "collapsed": true, "_uuid": "9d6f9baf51193a1865dae8cf775b195a3de3a381"}, "source": ["m.plot_components(forecast);"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "6a4ac9a2-f2bf-4ab7-b3ba-cf81eb2b2a51", "collapsed": true, "_uuid": "7cc5e18e62d997d60de6a5e465bc72555046ffac"}, "source": ["from fbprophet.diagnostics import cross_validation\n", "df_cv = cross_validation(m, horizon = '30 days')\n", "df_cv.head()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "854b840a-5518-4fa7-87e9-7f1b92bb2cb0", "collapsed": true, "_uuid": "d79d157bee28334126b96cf2a2aec4664ac5a956"}, "source": ["from sklearn.metrics import mean_squared_error"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "3970e76c-ddc5-4b25-b0c9-be349951432c", "collapsed": true, "_uuid": "a6394ecc3dadfbcd94780f2f2e182bd52aa05ab7"}, "source": ["def RMSLE(y, pred):\n", "    return mean_squared_error(y, pred)**0.5"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "c8dfa89f-08a0-455e-a832-6b94fe1d611e", "collapsed": true, "_uuid": "4dfb29592385958f219e79e38fbd39c9d8a8d4e3"}, "source": ["RMSLE(df_cv['y'], df_cv['yhat'])"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "bf7d7a58-4c5a-45c0-8103-25a05fcc1b7f", "collapsed": true, "_uuid": "aa27686e03d9882ef2f282cfdb1acfa7cb7c7b1f"}, "source": ["forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(39)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5798489c-1f24-4dc2-b0ed-bb3d18213376", "_uuid": "f21e5b885dd3ec83c0359663317a0b757b68ba34"}, "source": ["GBM regression model"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "2c1ca9d3-d8c4-4b32-88e2-8a917cf02554", "collapsed": true, "_uuid": "ea91d0bcdf5f8bb84f6a0f4b57c435c448e1fdb0"}, "source": ["from sklearn import *\n", "X = train[col]\n", "y = pd.DataFrame()\n", "y['visitors'] = np.log1p(train['visitors'].values)\n", "\n", "y_test_pred = 0\n", "\n", "K = 4\n", "kf = model_selection.KFold(n_splits = K, random_state = 1, shuffle = True)\n", "np.random.seed(1)\n", "\n", "params = {'n_estimators': 100, \n", "        'max_depth': 8,\n", "        'min_samples_split': 200, \n", "        'min_samples_leaf': 50,\n", "        'learning_rate': 0.005,\n", "        'max_features':  9,\n", "        'subsample': 0.9,\n", "        'loss': 'ls'}\n", "\n", "model = ensemble.GradientBoostingRegressor(**params)\n", "for i, (train_index, test_index) in enumerate(kf.split(train)):\n", "\n", "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n", "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n", "    X_test = test[col]\n", "    print(\"\\nFold \", i)\n", "\n", "    fit_model = model.fit(X_train, y_train)\n", "    pred = model.predict(X_valid)\n", "    print('RMSE GBM Regressor, fold ', i, ': ', RMSLE(y_valid, pred))\n", "    print('Prediction length on validation set, GBM Regressor, fold ', i, ': ', len(pred))\n", "\n", "    pred = model.predict(X_test)\n", "    print('Prediction length on test set, GBM Regressor, fold ', i, ': ', len(pred))\n", "    y_test_pred += pred\n", "\n", "    del X_test, X_train, X_valid, y_train\n", "\n", "% time y_test_pred /= K  \n"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "5885c0a0-f167-4ea2-910a-b1710a5e5bac", "collapsed": true, "_uuid": "20df7ac0f34370f21524c37d18d5e077970bef61"}, "source": ["df_sub1 = pd.DataFrame()\n", "df_sub1['id'] = test['id']\n", "df_sub1['visitors'] = np.expm1(y_test_pred) \n", "df_sub1.to_csv('submission_2.csv', float_format='%.6f', index=False)\n", "df_sub1.head(10)"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "cf63c212-58cf-49c4-ad7b-3a9525766391", "collapsed": true, "_uuid": "eba88618c90f5594cf0e19355bed67a7c9b05351"}, "source": ["x1 = df_sub1['visitors']\n", "x2 = df_sub['visitors']\n", "compr = x1 - x2\n", "compr"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "3bf11ab0-7564-4d8c-b3ed-f6efdcfe477c", "_uuid": "08f4e350d00e78c8af182baf919ca33e678b271c"}, "source": ["Autocorrelation Function and seasonal decomposition"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "649b2550-ae9f-402f-b907-ab3d5475081c", "collapsed": true, "_uuid": "0dd0feede36472cbc9c9cd99408f93a9309efd65"}, "source": ["from statsmodels.tsa.stattools import acf, pacf\n", "\n", "lag_acf = acf(ts, nlags=20)\n", "lag_pacf = pacf(ts, nlags=20, method='ols')\n", "\n", "plt.subplot(121) \n", "plt.plot(lag_acf)\n", "plt.axhline(y=0, linestyle='--', color='gray')\n", "plt.axhline(y=-1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\n", "plt.axhline(y=1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\n", "plt.title('Autocorrelation Function')\n", "\n", "#Plot PACF:\n", "plt.subplot(122)\n", "plt.plot(lag_pacf)\n", "plt.axhline(y=0,linestyle='--', color='gray')\n", "plt.axhline(y=-1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\n", "plt.axhline(y=1.96/np.sqrt(len(ts)), linestyle='--', color='gray')\n", "plt.title('Partial Autocorrelation Function')\n", "plt.tight_layout()"], "execution_count": null, "cell_type": "code", "outputs": []}, {"metadata": {"_cell_guid": "c112d4e2-ab65-4e1b-be12-02fd15a139c8", "collapsed": true, "_uuid": "41b0e2ca876508e499406a7d71271f0a026d188f"}, "source": ["from statsmodels.tsa.seasonal import seasonal_decompose\n", "\n", "decomposition = seasonal_decompose(np.asarray(ts), freq=7)\n", "\n", "trend = decomposition.trend\n", "seasonal = decomposition.seasonal\n", "residual = decomposition.resid\n", "\n", "decomposition.plot()\n", "plt.show()"], "execution_count": null, "cell_type": "code", "outputs": []}], "nbformat": 4, "nbformat_minor": 1}