{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# from keras.preprocessing import image\n# from os import walk\n# data=[]\n# input_file_names=[]\n# #####get the file names of the images to read them one by one\n# for (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats-redux-kernels-edition/train\"):\n#     input_file_names=filenames\n\n# for x in input_file_names:\n#     img_file_name=x##getting name of the image file\n#     path=str(\"../input/train/\"+img_file_name)####making proper path of the image file\n#     i=image.load_img(path)####reading the image from the path \n#     i=i.resize((64,64))#####resizing the image \n#     iarray=image.img_to_array(i)####converting it to arrau\n#     data.append(iarray)#####appending the image to the list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd38734a15237cd0f92d5ec51cefca89dc356fa1","collapsed":true},"cell_type":"code","source":"# plt.imshow(data[5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b756e494c2922e6faa024e8539b245abddde555","collapsed":true},"cell_type":"code","source":"# data=np.array(data)\n# ####generating labels for the data \n# labels=[]\n# for x in input_file_names:\n#     if x.find(\"cat\")>=0:\n#         labels.append(0)\n#     else:\n#         labels.append(1)\n# ###checking if the labels are properly tagged or not,both the classes have equal images 12500 each\n# a=np.array(labels)\n# np.unique(a,return_counts=True)\n\n# ###reshaping the labels\n# labels=a.reshape(25000,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba36bf3aa11df5f3d76c2402b02fb6a1ea257006","collapsed":true},"cell_type":"code","source":"# #####rescaling the data\n# data=data/255.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f97f2446b138d297f3dfc1801bc2f931854ae923"},"cell_type":"code","source":"from keras.layers import Conv2D,Dense,MaxPooling2D,BatchNormalization,Activation,Flatten\nfrom keras import Sequential\nfrom keras.initializers import glorot_normal\nfrom keras import optimizers\nfrom keras.models import Model\nfrom keras.applications.imagenet_utils import decode_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3932aa97ee1643fa501650b4622ce11cc33f0654","collapsed":true},"cell_type":"code","source":"# model=Sequential()\n# model.add(Conv2D(64,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100),input_shape=(64,64,3) ))\n# model.add(Conv2D(64,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(BatchNormalization())\n# model.add(Activation(\"relu\"))\n# model.add(MaxPooling2D((2,2)))\n\n# model.add(Conv2D(128,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(Conv2D(128,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(BatchNormalization())\n# model.add(Activation(\"relu\"))\n# model.add(MaxPooling2D((2,2)))\n\n# model.add(Conv2D(256,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(Conv2D(256,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(Conv2D(256,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(BatchNormalization())\n# model.add(Activation(\"relu\"))\n# model.add(MaxPooling2D((2,2)))\n\n\n# model.add(Conv2D(512,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(Conv2D(512,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(Conv2D(512,kernel_size=(2,2),strides=(1,1),kernel_initializer=glorot_normal(seed=100)))\n# model.add(BatchNormalization())\n# model.add(Activation(\"relu\"))\n# model.add(MaxPooling2D((2,2)))\n\n\n# model.add(Flatten())\n# model.add(Dense(10,activation=\"relu\",kernel_initializer=glorot_normal(seed=100)))\n# model.add(Dense(1,activation=\"sigmoid\",kernel_initializer=glorot_normal(seed=100)))\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3473d5ee33df1ddd79e231690ba31096956c82a","collapsed":true},"cell_type":"code","source":"###train test split\n# from sklearn.model_selection import train_test_split\n# train_x,test_x,train_y,test_y=train_test_split(data,labels,test_size=0.2,random_state=100)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cb5b500123cdce207d4ec4cdbe1a14d6be6d503","collapsed":true},"cell_type":"code","source":"# train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"937fa74ab1ac6f2e0f8ce4e82edaad15bceeae3c","collapsed":true},"cell_type":"code","source":"####compiling the model\n# o=optimizers.adam()\n# model.compile(loss=\"binary_crossentropy\",metrics=[\"accuracy\"],optimizer=o)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40cb0ab7729be472a1159857b54a331b658b0d71","collapsed":true},"cell_type":"code","source":"####fitting the model\n\n# H=model.fit(train_x,train_y,epochs=16,validation_split=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b42c76f1a740dbf976fd80ddd303dfb834958e07","collapsed":true},"cell_type":"code","source":"# plt.plot(range(1,17),H.history[\"acc\"])\n# plt.plot(range(1,17),H.history[\"val_acc\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5d2b3bbbd9326805807ca43854d43670f534607","collapsed":true},"cell_type":"code","source":"#####making predictions on the test data\n# preds=model.predict_classes(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4656e4c0f9c2d1d430224d293dab56270e7ef957","collapsed":true},"cell_type":"code","source":"# sum(preds==test_y)/len(test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2d878d2b3624576112822f3c5134408f2745dce5"},"cell_type":"code","source":"# test_data=[]\n# input_test_file_names=[]\n# #####get the file names of the images to read them one by one\n# for (dirpath, dirnames, filenames) in walk(\"../input/test\"):\n#     input_test_file_names=filenames\n\n# for x in input_test_file_names:\n#     img_file_name=x##getting name of the image file\n#     path=str(\"../input/test/\"+img_file_name)####making proper path of the image file\n#     i=image.load_img(path)####reading the image from the path \n#     i=i.resize((64,64))#####resizing the image \n#     iarray=image.img_to_array(i)####converting it to arrau\n#     test_data.append(iarray)#####appending the image to the list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff0365a38bf68dee44b5fb8921b144e1e990b630","collapsed":true},"cell_type":"code","source":"# test_data=np.array(test_data)\n# test_data=test_data/255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6f171eb8c191d091a3b26303e0c3da196f919fb1"},"cell_type":"code","source":"# test_preds=model.predict(test_data)\n# test_preds=test_preds.reshape(len(test_preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bfc10cd5b384add0639a7977d46eb0efbbee7b4","collapsed":true},"cell_type":"code","source":"####as per the submission file rule only numerical part from the file wwas needed\n####like 3090.jpg should be saved in as 3090\n# new_input_test_file_names=[]\n# for x in input_test_file_names:\n#     k=int(x[0:x.find(\".jpg\")])\n#     new_input_test_file_names.append(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"739db90aaf98ebb504c97b5a52c2e6710c0c26af","collapsed":true},"cell_type":"code","source":"# df=pd.DataFrame({'id':new_input_test_file_names,\n#              'label':test_preds})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bdcdb3cae3b84c8b19bd56287a4d2a5fff238e0","collapsed":true},"cell_type":"code","source":"# df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc868be68efe72285f2bfaf3f90010c298d7b67d","collapsed":true},"cell_type":"code","source":"#################################TRYING OUT THE RESNET 50 ARCHITECTURE################################################\nimport random\nl=[1,2,3]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee6b96fa4a081618e2809eef597446957d8030e1","collapsed":true},"cell_type":"code","source":"# from keras.applications import resnet50\n# from keras.preprocessing.image import ImageDataGenerator\n# r=resnet50.ResNet50(weights='imagenet',include_top=False,input_shape=(197,197,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f025a48ecd5c5f20bdcdfbda298fe1e107d8583c","collapsed":true},"cell_type":"code","source":"#########33getting data in in sahpe of (197,197,3) as min reqrmnt of resnet 50\n# from keras.preprocessing import image\n# from os import walk\n# data=[]\n# input_file_names=[]\n# #####get the file names of the images to read them one by one\n# for (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats-redux-kernels-edition/train/\"):\n#     input_file_names=filenames\n    \n# rand_imgs_indexes=random.sample(range(0, 24999), 14000)\n# new_input_file_names=[]\n# ######taking only 20000 random images\n# for k in rand_imgs_indexes:\n#     new_input_file_names.append(input_file_names[k])\n\n# for x in new_input_file_names:\n#     img_file_name=x##getting name of the image file\n#     path=str(\"../input/dogs-vs-cats-redux-kernels-edition/train/\"+img_file_name)####making proper path of the image file\n#     i=image.load_img(path)####reading the image from the path \n#     i=i.resize((197,197))#####resizing the image \n#     iarray=image.img_to_array(i)####converting it to arrau\n#     iarray=iarray/255.\n#     data.append(iarray)#####appending the image to the list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a55e05f372d7b266b92d69bb018c4acf2e88fb43","collapsed":true},"cell_type":"code","source":"# data=np.array(data)\n# ####generating labels for the data \n# labels=[]\n# for x in new_input_file_names:\n#     if x.find(\"cat\")>=0:\n#         labels.append(0)\n#     else:\n#         labels.append(1)\n# ###reshaping the labels\n# a=np.array(labels)\n# labels=a.reshape(14000,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"635ee93b1a7b69b09042a6ef5dc602af5d76f76d","collapsed":true},"cell_type":"code","source":"# #########defining the new model by defining my own last layer\n# new_model=r.output\n# new_model=Flatten()(new_model)\n# new_model=Dense(10)(new_model)\n# new_model=Activation(\"relu\")(new_model)\n# new_model=Dense(1,activation=\"sigmoid\")(new_model)\n\n# final_model=Model(input=r.input,output=new_model)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"95a9eaba45b46edc949e9bdb09b97ec4568be377","collapsed":true},"cell_type":"code","source":"###freezin all layers except from last 3 layers\n# total_layers=len(final_model.layers)\n# print(total_layers)\n# for x in range(0,total_layers-4):\n#     final_model.layers[x].trainable=False\n    \n     \n# final_model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a2a9bf0329874301daa9accb49f34129f38068e7","collapsed":true},"cell_type":"code","source":"##checking if the layers have been frozen or not\n# for x in range(0,total_layers):\n#     print(final_model.layers[x])\n#     print(final_model.layers[x].trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29efa4de336d2e1b0d385ee8818bdd60c9d1c21a"},"cell_type":"code","source":"###train test split\n# from sklearn.model_selection import train_test_split\n# train_x,test_x,train_y,test_y=train_test_split(data,labels,test_size=0.2,random_state=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a074184e8fb5c2ad1fbf095affc808ce8d6f28ba","collapsed":true},"cell_type":"code","source":"####compiling the model\n# o=optimizers.adam()\n# final_model.compile(loss=\"binary_crossentropy\",metrics=[\"accuracy\"],optimizer=o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f727106569e94fb361066e98b0069ee15e57cbb","collapsed":true},"cell_type":"code","source":"# final_model.fit(train_x,train_y,epochs=2,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"66a4637d3c0ef0b3dcb7d4ab36b1d20b4577140b"},"cell_type":"code","source":"# predicted_test=final_model.predict(train_x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"765e04c28e009144695d20e55c28cd9f56a09685"},"cell_type":"code","source":"##########################trying vgg19 model###################################","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a88f3429baa16bbdd2fdc06386efb277f3705c07"},"cell_type":"code","source":"from keras.applications import VGG19\nv=VGG19(weights=\"imagenet\",include_top=False,input_shape=(120,120,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"82213d5184a7c45720299645349cabf22ca9b232","collapsed":true},"cell_type":"code","source":"#########33getting data in in sahpe of (197,197,3) as min reqrmnt of resnet 50\nimport random\nfrom keras.preprocessing import image\nfrom os import walk\ndata=[]\ninput_file_names=[]\n#####get the file names of the images to read them one by one\nfor (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats-redux-kernels-edition/train/\"):\n    input_file_names=filenames\n    \nrand_imgs_indexes=random.sample(range(0, 24999), 12000)\nnew_input_file_names=[]\n######taking only 20000 random images\nfor k in rand_imgs_indexes:\n    new_input_file_names.append(input_file_names[k])\n\nfor x in new_input_file_names:\n    img_file_name=x##getting name of the image file\n    path=str(\"../input/dogs-vs-cats-redux-kernels-edition/train/\"+img_file_name)####making proper path of the image file\n    i=image.load_img(path)####reading the image from the path \n    i=i.resize((120,120))#####resizing the image \n    iarray=image.img_to_array(i)####converting it to arrau\n    iarray=iarray/255.\n    data.append(iarray)#####appending the image to the list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e6492ea1a026ee70ef543d5ee51745dac67dd4c8"},"cell_type":"code","source":"data=np.array(data)\n####generating labels for the data \nlabels=[]\nfor x in new_input_file_names:\n    if x.find(\"cat\")>=0:\n        labels.append(0)\n    else:\n        labels.append(1)\n###reshaping the labels\na=np.array(labels)\nlabels=a.reshape(12000,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"683d56e5667c4be0b73958fdd33e973634ba6998"},"cell_type":"code","source":"#########defining the new model by defining my own last layer\nnew_model=v.output\nnew_model=Flatten()(new_model)\nnew_model=Dense(10)(new_model)\nnew_model=Activation(\"relu\")(new_model)\nnew_model=Dense(1,activation=\"sigmoid\")(new_model)\n\nfinal_model=Model(input=v.input,output=new_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca717e322efb746367d826426e1ff3c754a3353a"},"cell_type":"code","source":"###freezin all layers except from last 3 layers\ntotal_layers=len(final_model.layers)\nprint(total_layers)\nfor x in range(0,total_layers-4):\n    final_model.layers[x].trainable=False\n    \n     \n# final_model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49b6145956055572e6129481b33ac53d0091d9d7","collapsed":true},"cell_type":"code","source":"##checking if the layers have been frozen or not\nfor x in range(0,total_layers):\n    print(final_model.layers[x])\n    print(final_model.layers[x].trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8744b9a9e0936917a1c6a5a24861eca7845dda5c","collapsed":true},"cell_type":"code","source":"###train test split\nfrom sklearn.model_selection import train_test_split\ntrain_x,test_x,train_y,test_y=train_test_split(data,labels,test_size=0.2,random_state=100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"95db0bf667a9dbf629e9de7d21e68eccb041505b"},"cell_type":"code","source":"####compiling the model\no=optimizers.adam()\nfinal_model.compile(loss=\"binary_crossentropy\",metrics=[\"accuracy\"],optimizer=o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f63be79427aeb7206a66578793cd0949ee80c0d"},"cell_type":"code","source":"final_model.fit(train_x,train_y,batch_size=32,epochs=15,validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"933eac7c60596ba3a3080d7e9b21d32795d03839","collapsed":true},"cell_type":"code","source":"preds=final_model.predict(test_x) \nnew_preds=[]\nfor x in preds:\n    if x >0.5:\n        new_preds.append(1)\n    else:\n        new_preds.append(0)\nnew_preds=np.array(new_preds)\nnew_preds=new_preds.reshape(len(new_preds),1)      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89f896118b68f985d286e330234d5396e83f27b8","collapsed":true},"cell_type":"code","source":"sum(new_preds==test_y)/len(test_y)\ntrain_x=[]\ntest_x=[]\ndata=[]\nlabels=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b3a971e6ecd9b39dffe9add21a368e01522e0427"},"cell_type":"code","source":"# final_model.save_weights(\"vgg_19.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8740969e777582e02d948b25f2dda780b936b8b7","collapsed":true},"cell_type":"code","source":"########importing test file\ndata=[]\ninput_file_names=[]\n\n#####get the file names of the images to read them one by one\nfor (dirpath, dirnames, filenames) in walk(\"../input/dogs-vs-cats-redux-kernels-edition/test/\"):\n    input_file_names=filenames\n\nfor x in input_file_names:\n    img_file_name=x##getting name of the image file\n    path=str(\"../input/dogs-vs-cats-redux-kernels-edition/test/\"+img_file_name)####making proper path of the image file\n    i=image.load_img(path)####reading the image from the path \n    i=i.resize((120,120))#####resizing the image \n    iarray=image.img_to_array(i)####converting it to arrau\n    data.append(iarray)#####appending the image to the list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a05b35ed85049478181c7877d78294e945365c","collapsed":true},"cell_type":"code","source":"data=np.array(data)/255.\npreds=final_model.predict(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d4d7e7c384d6fefc5f1f25d1b4b6b26126bb131b"},"cell_type":"code","source":"preds=preds.reshape(len(preds))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a0188844e5dafa9b2759c096286f8dc0be28c42"},"cell_type":"code","source":"####as per the submission file rule only numerical part from the file wwas needed\n####like 3090.jpg should be saved in as 3090\nnew_input_test_file_names=[]\nfor x in input_file_names:\n    k=int(x[0:x.find(\".jpg\")])\n    new_input_test_file_names.append(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d11b5327ec14f0833e94813a1f4eccd50ab63ff"},"cell_type":"code","source":"df=pd.DataFrame({'id':new_input_test_file_names,\n             'label':preds})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2017b90be2fb2726c34b15f736b647f67dea32da"},"cell_type":"code","source":"df.to_csv(\"submission2.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}