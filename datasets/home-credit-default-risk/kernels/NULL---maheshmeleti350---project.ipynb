{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67ea6ecd5063826a287cc825903df8668b69b2f3","collapsed":true},"cell_type":"code","source":"app_train = pd.read_csv('../input/application_train.csv')\nprint('Training data shape: ',app_train.shape)\napp_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"58ec9f4c2f5b39711d3bb881e630a8e62f4f8b45","collapsed":true},"cell_type":"code","source":"app_test = pd.read_csv('../input/application_test.csv')\nprint('Testing data shape: ', app_test.shape)\napp_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d4241b7b56abc74e17102e210dace608f0bbeb2","collapsed":true},"cell_type":"code","source":"app_train['TARGET'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb5248c477f20a2888e913563c3493df606b858d","collapsed":true},"cell_type":"code","source":"app_train['TARGET'].astype(int).plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b02acfdc373300c97c6da75095894d88dc352c6e"},"cell_type":"markdown","source":"# Examine Missing Values"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c4dc32284a9cd90f9484be145dfd83754866706"},"cell_type":"code","source":"#function to calculate missing values by columns# function\ndef missing_values_table(df):\n    #total missing values\n    miss_val = df.isnull().sum()\n    \n    #percentage of missing values\n    miss_val_percent = 100*df.isnull().sum()/len(df)\n    \n    #Make a table with the results\n    miss_val_table = pd.concat([miss_val,miss_val_percent],axis=1)\n\n    #rename the columns\n    miss_val_table_ren_columns = miss_val_table.rename(columns={0:'Missing Values',\n                                                                 1: '% of Total Values'})\n    #sort the table by percent of missing descending\n    miss_val_table_ren_columns = miss_val_table_ren_columns[\n        miss_val_table_ren_columns.iloc[:,1]!=0].sort_values(\n    '% of Total Values', ascending=False).round(1)\n    \n    #print same summary information\n    print(\"Your selected dataframe has \"+str(df.shape[1]) +\n         \"columns.\\n\" \n         \"There are \"+str(miss_val_table_ren_columns.shape[0])+\n         \"columns that have missing values.\")\n    return miss_val_table_ren_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bde1f99f8cd277f0d4e77d11e4d8e600ae1ac2e7","collapsed":true},"cell_type":"code","source":"missing_values = missing_values_table(app_train)\nmissing_values.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7268bae150439a9033824893ac1b4cd1874e1012","collapsed":true},"cell_type":"code","source":"app_train.dtypes.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"707493050cc514f56d30a6e9e38a4f2dea6645fb","collapsed":true},"cell_type":"code","source":"# number of unique classes in each object column\npd.DataFrame(app_train.select_dtypes('object').apply(pd.Series.nunique,axis=0))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"617cf19ab5d139a78b79e62b8e85afdb4124a2d4"},"cell_type":"markdown","source":"# Label Encoding and One-Hot Encoding"},{"metadata":{"trusted":true,"_uuid":"809b7bffca49fdc7e52ccb4940b57f8787d916e5","collapsed":true},"cell_type":"code","source":"# Create a label encoder object\nle = LabelEncoder()\nle_count=0\n\n#Iterate through the columns\nfor col in app_train:\n    if app_train[col].dtype == 'object':\n        #if 2 or fewer unique categories\n        if len(list(app_train[col].unique())) <= 2:\n            le.fit(app_train[col])\n            app_train[col] = le.transform(app_train[col])\n            app_test[col] = le.transform(app_test[col])\n            \n            le_count +=1\nprint('%d columns were label encoded. '% le_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12ef788c38c680d064234a5e28aed4c488ca93dd","collapsed":true},"cell_type":"code","source":"# one-hot encoding of categorical variables\napp_train = pd.get_dummies(app_train)\napp_test =pd.get_dummies(app_test)\n\nprint('Training Features shape: ',app_train.shape)\nprint('Test Features shape: ',app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"775095ff6d6d697ed2463c08087c2926111b8a89","collapsed":true},"cell_type":"code","source":"train_labels = app_train['TARGET']\n\n# Align the training and testing data, keep only columns present in both data frames\n\napp_train,app_test = app_train.align(app_test,join='inner',axis=1)\n\napp_train['TARGET'] = train_labels\n\nprint('Training Features shape: ',app_train.shape)\nprint('Testing Features shape: ',app_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e670397c809fc937a2e54374a1db5323b5d8837","collapsed":true},"cell_type":"code","source":"(app_train['DAYS_BIRTH']/-365).describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"351a6da7561314d0a34e9b4ca637bb10ad6a619a","collapsed":true},"cell_type":"code","source":"app_train['DAYS_EMPLOYED'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71bafe9e9a04edbbb8e8841be2968a71b4c7daf1","collapsed":true},"cell_type":"code","source":"app_train['DAYS_EMPLOYED'].plot.hist(title='Days Employmnet Histogram')\nplt.xlabel('Days Employment')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f643152e837a68b7382514d456958f260568cb2","collapsed":true},"cell_type":"code","source":"anom = app_train[app_train['DAYS_EMPLOYED']==365243]\nnon_anom = app_train[app_train['DAYS_EMPLOYED']!=365243]\nprint('The non-anomalies default on %0.2f%% of loans' %(100*non_anom['TARGET'].mean()))\n\nprint('The anomalies default on %0.2f%% of loans'%(100*anom['TARGET'].mean()))\nprint('There are %d anomalous days of employment'%len(anom))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37732b1bbcd3b9d10946d6722816ad410ca9ae86","collapsed":true},"cell_type":"code","source":"#app_train[app_train['DAYS_EMPLOYED']>0 and app_train['DAYS_EMPLOYED']<365243]\n#app_train['DAYS_EMPLOYED']>0 & app_train['DAYS_EMPLOYED']<365243\napp_train[(app_train.DAYS_EMPLOYED>0)]['DAYS_EMPLOYED'].plot.hist() #== app_train[(app_train.DAYS_EMPLOYED<365243)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65086089c022fffeb619b988b78e423fbee843bc","collapsed":true},"cell_type":"code","source":"# Create an anomalous flag column\napp_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n\n# Replace the anomalous values with nan\napp_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n\napp_train['DAYS_EMPLOYED'].plot.hist(title = 'Days Employment Histogram');\nplt.xlabel('Days Employment');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c9c1b135a0b48187f600b0e4bb454988b2677879","collapsed":true},"cell_type":"code","source":"app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\napp_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n\nprint('There are %d anomalies in the test data out of %d entries' % (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e71cb151e4a06cee1909d26670b56a0243524e75","collapsed":true},"cell_type":"code","source":"correlations = app_train.corr()['TARGET'].sort_values()\n\nprint(\"Most positive correlations:\\n\",correlations.tail(15))\nprint(\"Most negative correlations:\\n\",correlations.head(15))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ade9b3a4adbbda5230df02d28cc0373149a0d09"},"cell_type":"markdown","source":"# Effect of Age on Repayment"},{"metadata":{"trusted":true,"_uuid":"dd6e37944e3d4ab877112bab64ff34c4dcf5d2d5","collapsed":true},"cell_type":"code","source":"app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\napp_train['DAYS_BIRTH'].corr(app_train['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95615be31c86aa8d0cd66d79eabd346ce95902fc","collapsed":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n\nplt.hist(app_train['DAYS_BIRTH']/365,edgecolor='k',bins=25)\nplt.title('Age of Client');plt.xlabel('AGE(years)');plt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"046343a61666c769871e151c528b1abcfb54d6dd","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(10,8))\n\n# KDE plot of loans that were \n\nsns.kdeplot(app_train.loc[app_train['TARGET']==0,'DAYS_BIRTH']/365, label='target==0')\n\n# KDE plot of loans which were not repaid on time\nsns.kdeplot(app_train.loc[app_train['TARGET']==1,'DAYS_BIRTH']/365,\n           label='target==1')\n\nplt.xlabel('Age (years)');plt.ylabel('Density');plt.title('Distribution of Ages');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d623cb64ae2059dc5da69f5339b8a7f436323b63","collapsed":true},"cell_type":"code","source":"age_data = app_train[['TARGET','DAYS_BIRTH']]\nage_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH']/365\n\n#Bin the age data\nage_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'],\n                                 bins = np.linspace(20,70,num=11))\nage_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b74f2994d3139b2696277fab794074778e78e565","collapsed":true},"cell_type":"code","source":"# group by the bin and calculat averages\nage_groups = age_data.groupby('YEARS_BINNED').mean()\nage_groups","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"887dcf39951c318d5583d9588d076daf94a1e0ce","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\n\n# Graph the age bins and the average of the target as a bar plot\nplt.bar(age_groups.index.astype(str),100*age_groups['TARGET'])\n\nplt.xticks(rotation=75);plt.xlabel('Age Group (years)'); plt.ylabel('Failure to replay (%)')\nplt.title('Failure to Repay by age group')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"460d8c2d40cd949daa3b6d11991de242e4e66929","collapsed":true},"cell_type":"code","source":"# most negatively correlated\next_data = app_train[['TARGET','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3',\n                     'DAYS_BIRTH']]\next_data_corrs = ext_data.corr()\next_data_corrs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a32481f824438ca175cc8b33965d084471862a6","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\n#heat map of correlations\nsns.heatmap(ext_data_corrs,cmap=plt.cm.RdYlBu_r,vmin=-0.25,annot=True,\n           vmax=0.6,)\nplt.title('Correlation Heatmap');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"da58cde69d960f2914aed0f782e6084d630663ff","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(10,12))\n\nfor i,source in enumerate(['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']):\n    #create a new plot for each source\n    plt.subplot(3,1,i+1)\n    \n    #plot repaid loans\n    sns.kdeplot(app_train.loc[app_train['TARGET']==0,source],label='target==0')\n    \n    #plot loans not repaid\n    sns.kdeplot(app_train.loc[app_train['TARGET']==1,source],label='target==1')\n    \n    #label the plot\n    plt.title('Distribution of %s by Target Value'%source)\n    plt.xlabel('%s'%source);plt.ylabel('Density');\nplt.tight_layout(h_pad=2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"119164f12a2aed352d20db474abbe85527f79215","collapsed":true},"cell_type":"code","source":"# Copy the data for plotting\nplot_data = ext_data.drop(columns = ['DAYS_BIRTH']).copy()\n\n# Add in the age of the client in years\nplot_data['YEARS_BIRTH'] = age_data['YEARS_BIRTH']\n\n# Drop na values and limit to first 100000 rows\nplot_data = plot_data.dropna().loc[:100000, :]\n\n# Function to calculate correlation coefficient between two columns\ndef corr_func(x, y, **kwargs):\n    r = np.corrcoef(x, y)[0][1]\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r),\n                xy=(.2, .8), xycoords=ax.transAxes,\n                size = 20)\n# Create the pairgrid object\ngrid = sns.PairGrid(data = plot_data, size = 3, diag_sharey=False,\n                    hue = 'TARGET', \n                    vars = [x for x in list(plot_data.columns) if x != 'TARGET'])\n\n# Upper is a scatter plot\ngrid.map_upper(plt.scatter, alpha = 0.2)\n\n# Diagonal is a histogram\ngrid.map_diag(sns.kdeplot)\n\n# Bottom is density plot\ngrid.map_lower(sns.kdeplot, cmap = plt.cm.OrRd_r);\n\nplt.suptitle('Ext Source and Age Features Pairs Plot', size = 32, y = 1.05);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51c9d2959f8970698b1ec5fd01b1e31003ed2e38","collapsed":true},"cell_type":"code","source":"\"r={:.2f}\".format(0.023434)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1494745bec5093859f4b350e3c2ec773ce20c725","collapsed":true},"cell_type":"code","source":"# Make a new dataframe for polynomila features\npoly_features = app_train[['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_2',\n                          'DAYS_BIRTH','TARGET']]\npoly_features_test = app_test[['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_2',\n                          'DAYS_BIRTH']]\n\n#imputer for handling missing values\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(strategy='median')\n\npoly_target = poly_features['TARGET']\npoly_features = poly_features.drop(columns=['TARGET'])\n\n#need to impute missing values\npoly_features = imputer.fit_transform(poly_features)\npoly_features_test = imputer.fit_transform(poly_features_test)\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\npoly_transformer = PolynomialFeatures(degree=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a965dabab40fe14f06b51303fa185169b17b7da2","collapsed":true},"cell_type":"code","source":"#Train the polynomial features\n#poly_transformer.fit(poly_features)\n\n#Transform the features\npoly_features = poly_transformer.fit_transform(poly_features)\npoly_features_test = poly_transformer.fit_transform(poly_features_test)\nprint(\"Plynomial Features shape: \",poly_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9b4dbf6e0b147b53525a91236f048ede038abb6f","collapsed":true},"cell_type":"code","source":"poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1','EXT_SOURCE_2',\n                                                    'EXT_SOURCE_3','DAYS_BIRTH'])[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59a235bb0b586a434f2d220a7fad888fd417aac8","collapsed":true},"cell_type":"code","source":"poly_features = pd.DataFrame(poly_features,columns = poly_transformer.get_feature_names(input_features = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_BIRTH']))\n#Add in the target\npoly_features['TARGET'] = poly_target\n\n#find the correlations with the target\n\npoly_corrs = poly_features.corr()['TARGET'].sort_values()\n\n#Display most negative and most positive\nprint(poly_corrs.head(10))\nprint()\nprint(poly_corrs.tail(5))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b444b52a40a749933147019806ed16abac18d95f","collapsed":true},"cell_type":"code","source":"# Put test features into dataframe\npoly_features_test = pd.DataFrame(poly_features_test, \n                                  columns = poly_transformer.get_feature_names(['EXT_SOURCE_1', 'EXT_SOURCE_2', \n                                                                                'EXT_SOURCE_3', 'DAYS_BIRTH']))\n\n# Merge polynomial features into training dataframe\npoly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\napp_train_poly = app_train.merge(poly_features, on = 'SK_ID_CURR', how = 'left')\n\n# Merge polnomial features into testing dataframe\npoly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\napp_test_poly = app_test.merge(poly_features_test, on = 'SK_ID_CURR', how = 'left')\n\n# Align the dataframes\napp_train_poly, app_test_poly = app_train_poly.align(app_test_poly, join = 'inner', axis = 1)\n\n# Print out the new shapes\nprint('Training data with polynomial features shape: ', app_train_poly.shape)\nprint('Testing data with polynomial features shape:  ', app_test_poly.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc6f77961b32218f4c5c6c1308b665077d56bb4e","collapsed":true},"cell_type":"code","source":"app_train_domain = app_train.copy()\napp_test_domain = app_test.copy()\n\napp_train_domain['CREDIT_INCOME_PERCENT'] = app_train_domain['AMT_CREDIT']/app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['ANNUITY_INCOME_PERCENT'] = app_train_domain['AMT_ANNUITY']/app_train_domain['AMT_INCOME_TOTAL']\napp_train_domain['CREDIT_TERM'] = app_train_domain['AMT_ANNUITY']/app_train_domain['AMT_CREDIT']\napp_train_domain['DAYS_EMPLOYED_PERCENT'] = app_train_domain['DAYS_EMPLOYED']/app_train_domain['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c303049a13d475acca8f7147abfe7842d661bb2"},"cell_type":"code","source":"app_test_domain['CREDIT_INCOME_PERCENT'] = app_test_domain['AMT_CREDIT'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['ANNUITY_INCOME_PERCENT'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_INCOME_TOTAL']\napp_test_domain['CREDIT_TERM'] = app_test_domain['AMT_ANNUITY'] / app_test_domain['AMT_CREDIT']\napp_test_domain['DAYS_EMPLOYED_PERCENT'] = app_test_domain['DAYS_EMPLOYED'] / app_test_domain['DAYS_BIRTH']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50ed2e00b81a61fd1252b6e2806db47562f5365c","scrolled":true,"collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,20))\n#iterate through the new features\nfor i,feature in enumerate(['CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']):\n    plt.subplot(4,1,i+1)\n    \n    #plot repaid loans\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET']==0,feature],\n               label='target==0')\n    #plot loans that were not paid\n    sns.kdeplot(app_train_domain.loc[app_train_domain['TARGET']==1,feature],\n               label='target==1')\n    #label the plots\n    plt.title('Distribution of %s by Target Value'%feature)\n    plt.xlabel('%s'%feature);plt.ylabel('Density')\nplt.tight_layout(h_pad=2.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96a75455c56ae9bee951f56942147f8cc11e8677","collapsed":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, Imputer\n\n# Drop the target from the training data\nif 'TARGET' in app_train:\n    train = app_train.drop(columns=['TARGET'])\nelse:\n    train = app_train.copy()\n    \n#feature names\nfeatures = list(train.columns)\n\n#copy of the testing data\ntest = app_test.copy()\n\nimputer = Imputer(strategy='median')\n\nscaler = MinMaxScaler(feature_range=(0,1))\n\nimputer.fit(train)\ntrain = imputer.transform(train)\ntest = imputer.transform(app_test)\n\n#Repeat with the scaler\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dda0eeaeebd2c9e6130d1e55e25dbc2fb2f1f3a8","collapsed":true},"cell_type":"code","source":"a = np.array([[1,2],[4,5]])\nb = np.array([[6,7],[8,9]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"036da1bbdf729f96fae3ca93021ce1361eddcdc2","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e9cbbadac3f51b15a1adac3acf6d671c228ccaf","collapsed":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression(C=0.0001)\n\nlog_reg.fit(train,train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6feef025bebb30d45611370fa34133b2c683252c"},"cell_type":"code","source":"log_reg_pred = log_reg.predict_proba(test)[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c54f07e13e4ab043fca4eba1e71df677c7434577","collapsed":true},"cell_type":"code","source":"submit = app_test[['SK_ID_CURR']]\nsubmit['TARGET'] = log_reg_pred\n\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1b8e8adfa89527cd50e23e2b8b661650a965d4f3"},"cell_type":"code","source":"submit.to_csv('log_reg_baseline.csv', index = False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d1a7cbb01976abdb96d95753d045f2de20c0f0c1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}