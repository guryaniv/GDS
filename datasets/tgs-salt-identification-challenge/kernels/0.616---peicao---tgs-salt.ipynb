{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport sys\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom tqdm import tqdm, tnrange, tqdm_notebook\nfrom itertools import chain\nfrom skimage.io import imread, imshow, imread_collection, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input, RepeatVector, Reshape\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nIMG_WIDTH = 128\nIMG_HEIGHT = 128\nIMG_CHANNELS = 2\nn_features = 1\nTRAIN_PATH = '../input/train'\nTEST_PATH = '../input/test'\nimport os\nprint(os.listdir(\"../input\"))\n\ndf_depths = pd.read_csv('../input/depths.csv', index_col='id')\ntrain_ids = next(os.walk(\"../input/train/images\"))[2]\ntest_ids = next(os.walk(\"../input/test/images\"))[2]\n\nX_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_HEIGHT, IMG_CHANNELS), dtype=np.uint8)\nX_feat = np.zeros((len(train_ids), 1), dtype=np.float32) #depth\nY_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_HEIGHT, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\n\nfor n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n    path = TRAIN_PATH\n    img = load_img(path + '/images/' + id_)\n    x = img_to_array(img)[:,:,1] #type: PIL.PngImagePlugin.PngImageFile\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_train[n,...,0] = x.squeeze()\n    X_feat[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n    \n    #x cumsum\n    x_center_mean = x.mean()\n    x_csum = (np.float32(x)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum.mean()\n    x_csum /= max(1e-3, x_csum.std())\n    X_train[n, ..., 1] = x_csum.squeeze()\nprint('Done!')\n\nx_feat_mean = X_feat.mean(axis=0, keepdims=True)\nx_feat_std = X_feat.std(axis=0, keepdims=True)\nX_feat = (X_feat - x_feat_mean)/x_feat_std\nprint(X_feat.shape)\n\n# Define metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\n\n# Define U-net model\ninput_feat = Input((n_features,),name = 'feat')\nprint(input_feat)\ninput_img = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),name = 'img')\n\ns = Lambda(lambda x: x / 255)(input_img)   #Normalization layer\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nf_repeat = RepeatVector(8*8)(input_feat)\nf_conv = Reshape((8, 8, n_features))(f_repeat)\np4_feat = concatenate([p4, f_conv], -1)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4_feat)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[input_img, input_feat], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()\n\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True)\nresults = model.fit({'img':X_train, 'feat':X_feat}, Y_train, batch_size= 16, epochs=30, \n                    callbacks=[earlystopper, checkpointer])\n\n\n\nX_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\nX_feat_test = np.zeros((len(test_ids), 1), dtype=np.float32)\n\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = TEST_PATH\n    img = load_img(path + '/images/' + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n,...,0] = x.squeeze()\n    X_feat_test[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n    \n    x_center_mean = x.mean()\n    x_csum = (np.float32(x)-x_center_mean).cumsum(axis=0)\n    x_csum -= x_csum.mean()\n    x_csum /= max(1e-3, x_csum.std())\n    X_test[n,...,1] = x_csum.squeeze()\nprint('Done!')\nX_feat_test -= x_feat_mean\nX_feat_test /= x_feat_std\n\n#load the best model\n#model = load_model('model-tgs-salt-1.h5',custom_objects={'mean_iou': mean_iou})\npreds_test = model.predict({'img': X_test, 'feat': X_feat_test}, verbose=1)\n\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))\n    \ndef RLenc(img, order='F', format=True):\n    #run-length encoding\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn[:-4]:RLenc(np.round(preds_test_upsampled[i])) for i,fn in tqdm(enumerate(test_ids))}\nsub = pd.DataFrame.from_dict(pred_dict,orient='index')\n#print(sub.head)\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}