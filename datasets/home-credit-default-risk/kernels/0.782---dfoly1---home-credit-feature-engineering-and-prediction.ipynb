{"cells":[{"metadata":{"_uuid":"409a0730cb8e205406e77c85f2b664009960a5bb"},"cell_type":"raw","source":""},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc \nplt.style.use('fivethirtyeight')\n#sns.palplot(sns.color_palette())\n\n%matplotlib inline \n\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly as py\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True) #do not miss this line\nfrom plotly import tools\n\n\n# For model estimation\nfrom sklearn.preprocessing import LabelEncoder,MinMaxScaler, Imputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nPATH = \"../input\"\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"data = pd.read_csv(PATH+\"/application_train.csv\")\ntest = pd.read_csv(PATH+\"/application_test.csv\")\nbureau = pd.read_csv(PATH+\"/bureau.csv\")\nbureau_balance = pd.read_csv(PATH+\"/bureau_balance.csv\")\ncredit_card_balance = pd.read_csv(PATH+\"/credit_card_balance.csv\")\ninstallments_payments = pd.read_csv(PATH+\"/installments_payments.csv\")\nprevious_application = pd.read_csv(PATH+\"/previous_application.csv\")\nPOS_CASH_balance = pd.read_csv(PATH+\"/POS_CASH_balance.csv\")","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"82c5262ee837ef682f35c3f20dd32b67828957b7"},"cell_type":"markdown","source":"# Feature Engineering\n\n### Application Train\n- income to credit\n- income per person\n- annuity to income\n- days employed relative to age\n\n\n### Bureau\n- groupby for counts, means, min, max"},{"metadata":{"trusted":true,"_uuid":"37eb58958be9f1f6f63e86af2b9d61d9b4a37a50","collapsed":true},"cell_type":"code","source":"data.columns.values","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e56f9cfe03052ff8cd3b7acef1170269b964f57","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98547e6e823aef13049f28a1176207b1b174e62f","collapsed":true},"cell_type":"code","source":"## Feature Engineering training set\ndata['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\ndata['CODE_GENDER'].replace({'XNA': 'F'}, inplace=True)\ndata['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\ndata['YEARS_BUILD_CREDIT'] = data['AMT_CREDIT']/data['YEARS_BUILD_AVG']\ndata['Annuity_Income'] = data['AMT_ANNUITY']/data['AMT_INCOME_TOTAL']\ndata['Income_Cred'] = data['AMT_CREDIT']/data['AMT_INCOME_TOTAL']\ndata['EMP_AGE'] = data['DAYS_EMPLOYED']/data['DAYS_BIRTH']\ndata['Income_PP'] = data['AMT_INCOME_TOTAL']/data['CNT_FAM_MEMBERS']\ndata['CHILDREN_RATIO'] = (1 + data['CNT_CHILDREN']) / data['CNT_FAM_MEMBERS']\ndata['PAYMENTS'] = data['AMT_ANNUITY']/ data['AMT_CREDIT']\n#data['Annuity_Credit'] = data['AMT_CREDIT']/data['AMT_ANNUITY']\ndata['NEW_CREDIT_TO_GOODS_RATIO'] = data['AMT_CREDIT'] / data['AMT_GOODS_PRICE']\ndata['GOODS_INCOME'] =  data['AMT_GOODS_PRICE']/data['AMT_INCOME_TOTAL']\n# data['SOURCE_1_PERCENT'] = data['EXT_SOURCE_1']/(data['EXT_SOURCE_1']+data['EXT_SOURCE_2']+data['EXT_SOURCE_3'])\n# data['SOURCE_2_PERCENT'] = data['EXT_SOURCE_2']/(data['EXT_SOURCE_1']+data['EXT_SOURCE_2']+data['EXT_SOURCE_3'])\n# data['SOURCE_3_PERCENT'] = data['EXT_SOURCE_3']/(data['EXT_SOURCE_1']+data['EXT_SOURCE_2']+data['EXT_SOURCE_3'])\ndata['Ext_source_mult'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\ndata['Ext_SOURCE_MEAN'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\ndata['Ext_SOURCE_SD'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis = 1)\n\n\n\n\n\n\ncolumns = ['Annuity_Income', 'Income_Cred', 'EMP_AGE', 'Income_PP']\n#df[columns].describe()\n\n## Feature engineering test set\ntest['CODE_GENDER'].replace({'XNA': 'F'}, inplace=True)\ntest['YEARS_BUILD_CREDIT'] = test['AMT_CREDIT']/test['YEARS_BUILD_AVG']\ntest['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\ntest['Annuity_Income'] = test['AMT_ANNUITY']/test['AMT_INCOME_TOTAL']\ntest['Income_Cred'] = test['AMT_CREDIT']/test['AMT_INCOME_TOTAL']\ntest['EMP_AGE'] = test['DAYS_EMPLOYED']/test['DAYS_BIRTH']\ntest['Income_PP'] = test['AMT_INCOME_TOTAL']/test['CNT_FAM_MEMBERS']\ntest['CHILDREN_RATIO'] = (1 + test['CNT_CHILDREN']) / test['CNT_FAM_MEMBERS']\n#test['Annuity_Credit'] =test['AMT_CREDIT']/ test['AMT_ANNUITY']\ntest['PAYMENTS'] = test['AMT_ANNUITY']/ test['AMT_CREDIT']\ntest['NEW_CREDIT_TO_GOODS_RATIO'] = test['AMT_CREDIT'] / test['AMT_GOODS_PRICE']\ntest['GOODS_INCOME'] =  test['AMT_GOODS_PRICE']/test['AMT_INCOME_TOTAL']\n# test['SOURCE_1_PERCENT'] = test['EXT_SOURCE_1']/(test['EXT_SOURCE_1']+test['EXT_SOURCE_2']+test['EXT_SOURCE_3'])\n# test['SOURCE_2_PERCENT'] = test['EXT_SOURCE_2']/(test['EXT_SOURCE_1']+test['EXT_SOURCE_2']+test['EXT_SOURCE_3'])\n# test['SOURCE_3_PERCENT'] = test['EXT_SOURCE_3']/(test['EXT_SOURCE_1']+test['EXT_SOURCE_2']+test['EXT_SOURCE_3'])\ntest['Ext_source_mult'] = test['EXT_SOURCE_1'] * test['EXT_SOURCE_2'] * test['EXT_SOURCE_3']\ntest['Ext_SOURCE_MEAN'] = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\ntest['Ext_SOURCE_SD'] = test[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis = 1)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0099a72c4ace7be253525a534f51fd02d8aadcaa","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a218d088b52fcc27aeb93b8a2b111ab65d2d5d1c"},"cell_type":"code","source":"# def plot_target(data, feature, xlab= '', ylab= '', title= \"\"):\n#     plt.figure(figsize=(12,9))\n#     sns.kdeplot(data.loc[data['TARGET'] == 0, feature], label = 'target == 0')\n\n#     # KDE plot of loans which were not repaid on time\n#     sns.kdeplot(data.loc[data['TARGET'] == 1, feature], label = 'target == 1')\n    \n#     # Labeling of plot\n#     plt.xlabel(feature); plt.ylabel('Density'); plt.title(\"Distribution of %s\"%(feature));","execution_count":4,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0a5a4bbaf2c1eb97e1874bef8917786c95b77b5","collapsed":true},"cell_type":"code","source":"# plot_target(data, 'Annuity_Income')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29bb386513a474df368af3832c3ff21dbe1d4062","collapsed":true},"cell_type":"code","source":"# plot_target(data,'Income_Cred')","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b11acbeb7b679dde91d7425c44a54fd46f151e54","collapsed":true},"cell_type":"code","source":"# plot_target(data, 'EMP_AGE')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9edcd815aa36651479142dbe364a88ed03b70b76","collapsed":true},"cell_type":"code","source":"# plot_target(data,'Income_PP')","execution_count":8,"outputs":[]},{"metadata":{"_uuid":"2e201e75cad2241ec8444d4379c74cb4c00784e9"},"cell_type":"markdown","source":"## Bureau summary statistics"},{"metadata":{"trusted":true,"_uuid":"8914acdc22f8b38e04326410729de1f6c5e65736","collapsed":true},"cell_type":"code","source":"# df1 = bureau\n# def new_features(df1, group_by ,stats, data_name):\n#     columns = [group_by]\n#     data_features = df1.groupby(group_by).agg(stats).reset_index()\n#     for var in data_features.columns.levels[0]:\n#         # ignore grouping variable\n#         if var != group_by:\n#             # get rid of original variable\n#             for stat in data_features.columns.levels[1][:-1]:\n#                 columns.append('%s_%s_%s' %(data_name,var,stat))\n#     data_features.columns = columns            \n#     data = bureau.merge(data_features , on='SK_ID_CURR', how = 'left')\n#     return data","execution_count":7,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36df2114f505c03d669daa98ed7135c919a8caad","collapsed":true},"cell_type":"code","source":"# bureau_new = new_features(bureau.drop(columns = ['SK_ID_BUREAU']),'SK_ID_CURR', stats ,data_name = 'bureau')\n# bureau_new.head()","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"c90f5dfa860084462642b9d8bfb0d9502d128711"},"cell_type":"markdown","source":"## Add number of loans as a variable: count"},{"metadata":{"trusted":true,"_uuid":"17b9803acda1dec6871e5aedcbcdd24f00d5e40e","collapsed":true},"cell_type":"code","source":"# COUNT\nbureau_new = bureau\ngroup = bureau_new[['SK_ID_CURR', 'DAYS_CREDIT']].groupby('SK_ID_CURR')['DAYS_CREDIT'].count().reset_index().rename(index=str, columns={'DAYS_CREDIT': 'BUREAU_LOAN_COUNT'})\nbureau_new = bureau_new.merge(group, how = 'left', on = 'SK_ID_CURR')\nbureau_new.head()\ndel group","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"cca5e0a1001b8b2f85108afe54dfe873b3ca8d9c"},"cell_type":"markdown","source":"## Unique loan types per customer"},{"metadata":{"trusted":true,"_uuid":"b88b07f8c6fc5256eaf9385c3f63ffcc52472011","collapsed":true},"cell_type":"code","source":"group = bureau_new[['SK_ID_CURR', 'CREDIT_TYPE']].groupby('SK_ID_CURR')['CREDIT_TYPE'].nunique().reset_index().rename(index=str, columns = {'CREDIT_TYPE': 'LOAN_TYPES_PER_CUST'})\nbureau_new = bureau_new.merge(group,on = ['SK_ID_CURR'], how = 'left')\nbureau_new.head()\ndel group","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"654fc03c6aec7d50dab245878cdd3158fdc2211e"},"cell_type":"markdown","source":"## Average loan type \n### are customer taking out the same type of loans or different types"},{"metadata":{"trusted":true,"_uuid":"2f54d924b3415d2359f4ae50da03ee94883e3188","collapsed":true},"cell_type":"code","source":"bureau_new[\"AVERAGE_LOAN_TYPE\"] = bureau_new['BUREAU_LOAN_COUNT']/bureau_new['LOAN_TYPES_PER_CUST']","execution_count":29,"outputs":[]},{"metadata":{"_uuid":"64d3f42729d827950b7b5bacca2e053162e676a7"},"cell_type":"markdown","source":"## Percentage of active loans"},{"metadata":{"trusted":true,"_uuid":"410b4884dc8a17eaecf282cfea53ab78ff4a1645","collapsed":true},"cell_type":"code","source":"replace = {'Active': 1, 'Closed':0, 'Sold': 1, 'Bad debt': 1}\nbureau_new['CREDIT_ACTIVE'] = bureau_new['CREDIT_ACTIVE'].replace(replace)\ngp = bureau_new.groupby('SK_ID_CURR')['CREDIT_ACTIVE'].mean().reset_index().rename(index=str, columns={'CREDIT_ACTIVE': 'ACTIVE_LOANS_PERCENTAGE'})\n\nbureau_new = bureau_new.merge(gp, on = 'SK_ID_CURR', how = 'left')\nbureau_new.head()\ndel gp","execution_count":30,"outputs":[]},{"metadata":{"_uuid":"8a23329c7d7b906f1920c74e4130255dd76b1e69"},"cell_type":"markdown","source":"## Number of days between loans"},{"metadata":{"trusted":true,"_uuid":"c830307ad7a812775f87416054fc11c83c82a9e8","collapsed":true},"cell_type":"code","source":"# gp = bureau_new[['SK_ID_CURR', 'SK_ID_BUREAU', 'DAYS_CREDIT']].groupby('SK_ID_CURR')\n# gp1 = gp.apply(lambda x: x.sort_values(['DAYS_CREDIT'], ascending = False)).reset_index(drop=True)\n\n# # Difference between the days\n# gp1[\"DAYS_CREDIT1\"] = gp1[\"DAYS_CREDIT\"]*-1\n# gp1['DAYS_DIFF']  = gp1.groupby(by = ['SK_ID_CURR'])['DAYS_CREDIT1'].diff()\n# gp1['DAYS_DIFF'] = gp1['DAYS_DIFF'].fillna(0).astype('uint32')\n# del gp1['DAYS_CREDIT'], gp1['DAYS_CREDIT1'], gp1['SK_ID_CURR']\n# bureau_new = bureau_new.merge(gp1, on = 'SK_ID_BUREAU', how = 'left')","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"543f3c57dfe7a792a128480a3ef85c14f70475ab"},"cell_type":"markdown","source":"## % of loans where end date of credit is past\n## value < 0 means the end date has past"},{"metadata":{"trusted":true,"_uuid":"dbfe47cec1351cb9ee76f880ba1d60d9f64baef2","collapsed":true},"cell_type":"code","source":"def repl(x):\n    if x < 0:\n        y = 0\n    else:\n        y= 1\n    return y\nbureau_new['CREDIT_ENDDATE_BINARY'] = bureau_new['DAYS_CREDIT_ENDDATE'].apply(lambda x: repl(x))\ngrp = bureau_new.groupby('SK_ID_CURR')['CREDIT_ENDDATE_BINARY'].mean().reset_index().rename(index=str, columns={'CREDIT_ENDDATE_BINARY': 'CREDIT_ENDDATE_PERCENTAGE'})\nbureau_new = bureau_new.merge(grp, on = 'SK_ID_CURR', how = 'left')\ndel grp","execution_count":31,"outputs":[]},{"metadata":{"_uuid":"8ff26ba3ac4387c23f08a0168a0ae82e965e52d7"},"cell_type":"markdown","source":"## Further cleaning and modelling"},{"metadata":{"trusted":true,"_uuid":"bd8c547661ae113ca6c85541aec8ab6ac610024b","collapsed":true},"cell_type":"code","source":"# get some summary stats of numeric variables\nnum_aggregations = {\n        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n        'DAYS_CREDIT_UPDATE': ['mean'],\n        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n        'AMT_ANNUITY': ['max', 'mean'],\n        'CNT_CREDIT_PROLONG': ['sum'],\n\n    }\n\nbureau_agg = bureau_new.groupby('SK_ID_CURR').agg({**num_aggregations})\nbureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\nbureau_agg.reset_index(inplace=True)\n\n#now merge with bureau_new on SK_ID_CURR\nbureau_merge = bureau_new.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\ndel bureau_agg","execution_count":32,"outputs":[]},{"metadata":{"_uuid":"beea410cbd11155a09b730f1dc1fa2237b7e9c51"},"cell_type":"markdown","source":"## Bureau and Bureau Balance Merging\n- merges bureau and bureau balance and aggregates them to the  SK_ID_CURR level the same as data"},{"metadata":{"trusted":true,"_uuid":"c2413d9ffebc676579eb2991fc4a42400abbe580","collapsed":true},"cell_type":"code","source":"buro_cat_features = [bcol for bcol in bureau_merge.columns if bureau_merge[bcol].dtype == 'object']\nburo = pd.get_dummies(bureau_merge, columns=buro_cat_features)\n\n# Bureau Balance \ncat_columns = [col for col in bureau_balance.columns if bureau_balance[col].dtype == 'object']\nbureau_balance = pd.get_dummies(bureau_balance,cat_columns, dummy_na = True)\nbb_group = bureau_balance.groupby('SK_ID_BUREAU').agg(['min', 'max', 'mean'])\nbb_group.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_group.columns.tolist()])\nbb_group.reset_index(inplace=True)\n\nburo = buro.merge(bb_group, on = 'SK_ID_BUREAU', how = 'left')\navg_buro = buro.groupby('SK_ID_CURR').mean() ## this gives us average values for each columns as we have multiple loans per person\n\n# # Number of loans per person\navg_buro['buro_count'] = buro[['SK_ID_BUREAU', 'SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\ndel avg_buro['SK_ID_BUREAU'], bb_group","execution_count":34,"outputs":[]},{"metadata":{"_uuid":"fc83ba79e93d817101c63f52e0163f9b0ea4d1f5"},"cell_type":"markdown","source":"## Installment Applications"},{"metadata":{"trusted":true,"_uuid":"b11ad7ebbc64eec42148b420221a2ab2c2866965","collapsed":true},"cell_type":"code","source":"cat_columns = [col for col in installments_payments.columns if installments_payments[col].dtype == 'object']\ninstallments_payments = pd.get_dummies(installments_payments,cat_columns, dummy_na = True)\ninstallments_payments['AMOUNT_DIFF'] = installments_payments['AMT_INSTALMENT'] - installments_payments['AMT_PAYMENT']\ninstallments_payments['AMOUNT_PERC'] =  installments_payments['AMT_PAYMENT']/installments_payments['AMT_INSTALMENT']\n\n# Was it paid on early or late?\ninstallments_payments['DAYS_P'] =  installments_payments['DAYS_ENTRY_PAYMENT']-installments_payments['DAYS_INSTALMENT']\ninstallments_payments['DAYS_I'] =  installments_payments['DAYS_INSTALMENT']-installments_payments['DAYS_ENTRY_PAYMENT']\n# installments_payments['DAYS_P'] = installments_payments['DAYS_P'].apply(lambda x: x if x > 0 else 0)\n# installments_payments['DAYS_I'] = installments_payments['DAYS_I'].apply(lambda x: x if x > 0 else 0)\n\naggregations = {\n        'NUM_INSTALMENT_VERSION': ['nunique'],\n        'DAYS_P': ['max', 'mean', 'sum'],\n        'DAYS_I': ['max', 'mean', 'sum'],\n        'AMOUNT_DIFF': ['max', 'mean', 'sum', 'var'],\n        'AMOUNT_PERC': ['max', 'mean', 'sum', 'var'],\n        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n    }\nfor cat in cat_columns:\n    aggregations[cat] = ['mean']\ninstallments_payments_agg = installments_payments.groupby('SK_ID_CURR').agg(aggregations)\ninstallments_payments_agg['INSTAL_COUNT'] = installments_payments.groupby('SK_ID_CURR').size()\ninstallments_payments_agg.columns = pd.Index(['INSTALL_' + e[0] + \"_\" + e[1].upper() for e in installments_payments_agg.columns.tolist()])\n\ninstallments_payments = installments_payments.merge(installments_payments_agg, how = 'left', on = 'SK_ID_CURR')\ndel installments_payments_agg","execution_count":35,"outputs":[]},{"metadata":{"_uuid":"549c2dafe965b69235b6a55fd8d6ecf32f02ab18"},"cell_type":"markdown","source":"## Previous applications"},{"metadata":{"trusted":true,"_uuid":"a87204f7b3b70d2f15325473b20fac875b9e7e55","collapsed":true},"cell_type":"code","source":"## Features\n# 365243 is NAN\nprevious_application['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\nprevious_application['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\nprevious_application['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\nprevious_application['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\nprevious_application['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n\n#previous_application[previous_application['AMT_DOWN_PAYMENT'] < 0] = 0\nprevious_application['INTEREST_PERC'] = (previous_application['RATE_INTEREST_PRIMARY']/100)*previous_application['AMT_DOWN_PAYMENT']\nprevious_application['INTEREST_ANN_PERC'] = (previous_application['RATE_INTEREST_PRIMARY']/100)*previous_application['AMT_ANNUITY']\nprevious_application['INTEREST_CREDIT_PERC'] = (previous_application['RATE_INTEREST_PRIMARY']/100)*previous_application['AMT_CREDIT']\nprevious_application['FIRST_LAST'] = previous_application['DAYS_FIRST_DUE'] - previous_application['DAYS_LAST_DUE']\n\nprevious_application['APPLICATION_ACTUAL_CREDIT'] = previous_application['AMT_APPLICATION']/previous_application['AMT_CREDIT']\n\nnum_aggregations = {\n        'AMT_ANNUITY': ['min', 'max', 'mean'],\n        'AMT_APPLICATION': ['min', 'max', 'mean'],\n        'AMT_CREDIT': ['min', 'max', 'mean'],\n        'INTEREST_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n        'DAYS_DECISION': ['min', 'max', 'mean'],\n        'CNT_PAYMENT': ['mean', 'sum'],\n        'FIRST_LAST': ['mean', 'max', 'min']\n    }\n\nprev_agg = previous_application.groupby('SK_ID_CURR').agg({**num_aggregations})\nprev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\nprevious_application = previous_application.merge(prev_agg, on = 'SK_ID_CURR', how = 'left')\ndel prev_agg","execution_count":37,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d51d0e11600869b084c9f25dd86687ca4b299920","collapsed":true},"cell_type":"markdown","source":"## Group the approved and non approved previous loan data"},{"metadata":{"trusted":true,"_uuid":"bcbf0a865953009bd94175c2c8cb8242d67db80a","collapsed":true},"cell_type":"code","source":"# Previous Applications: Approved Applications - only numerical features\napproved = previous_application[previous_application['NAME_CONTRACT_STATUS'] == 'Approved']\napproved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\napproved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\nprevious_application = previous_application.join(approved_agg, how='left', on='SK_ID_CURR')\n\n# Previous Applications: Refused Applications - only numerical features\nrefused = previous_application[previous_application['NAME_CONTRACT_STATUS'] == 'Refused']\nrefused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\nrefused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\nprevious_application = previous_application.join(refused_agg, how='left', on='SK_ID_CURR')\n\nprevious_application = previous_application.groupby('SK_ID_CURR').mean().reset_index(inplace=True)\n# del previous_application['SK_ID_PREV']","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"ce51718b7782e4bc2ae10b6687c8f88b41bf7dcf"},"cell_type":"markdown","source":"## POS_CASH balance"},{"metadata":{"trusted":true,"_uuid":"1d167ab98ab40990cc697fc0f52275bfa40fb73f","collapsed":true},"cell_type":"code","source":"aggregations = {\n        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n        'SK_DPD': ['max', 'mean'],\n        'SK_DPD_DEF': ['max', 'mean']\n    }\nPOS_CASH_AGG = POS_CASH_balance.groupby('SK_ID_CURR').agg(aggregations)\nPOS_CASH_AGG.columns = pd.Index(['POS_CASH_' + e[0] + \"_\" + e[1].upper() for e in POS_CASH_AGG.columns.tolist()])\nPOS_CASH_AGG['COUNT'] = POS_CASH_AGG.groupby('SK_ID_CURR').size()\n\ncat_columns = [col for col in POS_CASH_balance.columns if POS_CASH_balance[col].dtype == 'object']\nPOS_CASH_balance = pd.get_dummies(POS_CASH_balance,cat_columns, dummy_na = True)\nPOS_CASH_balance = POS_CASH_balance.merge(POS_CASH_AGG, how = 'left', on = 'SK_ID_CURR')\nPOS_CASH_balance.head()\nPOS_CASH_balance = POS_CASH_balance.groupby('SK_ID_CURR').mean().reset_index()\ndel POS_CASH_AGG, POS_CASH_balance['SK_ID_PREV']","execution_count":39,"outputs":[]},{"metadata":{"_uuid":"5ebd0ea8795de6e46a59bec60591582fd5d0b0dc"},"cell_type":"markdown","source":"## Credit Card Balance"},{"metadata":{"_uuid":"e4fd5bb6bf72913049ac0b0d4564152cbb8e397c","trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6859b31ade9b4dbfebcba826ad4cd8189c317eab","collapsed":true},"cell_type":"code","source":"y = data['TARGET']\ndel data['TARGET']\n#One-hot encoding of categorical features in data and test sets\ncategorical_features = [col for col in data.columns if data[col].dtype == 'object']\n\none_hot_df = pd.concat([data,test])\none_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)\n\ndata = one_hot_df.iloc[:data.shape[0],:]\ntest = one_hot_df.iloc[data.shape[0]:,]\n\nprint(data.shape, test.shape)","execution_count":44,"outputs":[]},{"metadata":{"_uuid":"f84d52c0925b7912a7e334480cbb90f1a4aa1ed8"},"cell_type":"markdown","source":"## Merging Datasets"},{"metadata":{"trusted":true,"_uuid":"0191891022f4672c311949b557845bcb5abf2baf","collapsed":true},"cell_type":"code","source":"#Bureau and Bureau Balance\ndata = data.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=avg_buro.reset_index(), how='left', on='SK_ID_CURR')\nprint(data.shape, test.shape)\n\n# Previous Application\ndata = data.merge(right=previous_application.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=previous_application.reset_index(), how='left', on='SK_ID_CURR')\nprint(data.shape, test.shape)\n\n# POS_CASH_BALANCE\ndata = data.merge(right=POS_CASH_balance.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=POS_CASH_balance.reset_index(), how='left', on='SK_ID_CURR')\nprint(data.shape, test.shape)\n\n\n# Installments_payments\ndata = data.merge(right=installments_payments.reset_index(), how='left', on='SK_ID_CURR')\ntest = test.merge(right=installments_payments.reset_index(), how='left', on='SK_ID_CURR')\nprint(data.shape, test.shape)\ngc.collect()","execution_count":45,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3e2d23f6f31fe27c4a03f3661b71e142cd5b46f5"},"cell_type":"code","source":"# data.csv('processed_input_data.csv')\n# test.csv('processed_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0417fd5d4e88a6a2158a1333120b8335a34f7e7","collapsed":true},"cell_type":"code","source":"#Remove features with many missing values\nprint('Removing features with more than 80% missing...')\ntest = test[test.columns[data.isnull().mean() < 0.80]]\ndata = data[data.columns[data.isnull().mean() < 0.80]]\n\n## Use Median Imputation for missing data\nimputer = Imputer(strategy = 'median')\nimputer.fit(data)\ndata = imputer.transform(data)\ntest = imputer.transform(test)\n\n\nprint(data.shape, test.shape)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9d398a5b801358d1e04d6e14ecc8aa552f3f8a1c"},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nimport gc\n\ngc.enable()\n\nfolds = KFold(n_splits=4, shuffle=True, random_state=546789)\noof_preds = np.zeros(data.shape[0])\nsub_preds = np.zeros(test.shape[0])\n\nfeature_importance_df = pd.DataFrame()\n\nfeats = [f for f in data.columns if f not in ['SK_ID_CURR']]\n\nfor n_fold, (trn_idx, val_idx) in enumerate(folds.split(data)):\n    trn_x, trn_y = data[feats].iloc[trn_idx], y.iloc[trn_idx]\n    val_x, val_y = data[feats].iloc[val_idx], y.iloc[val_idx]\n    \n    clf = LGBMClassifier(\n        n_estimators=10000,\n        learning_rate=0.03,\n        num_leaves=34,\n        colsample_bytree=0.9,\n        subsample=0.8,\n        max_depth=8,\n        reg_alpha=.1,\n        reg_lambda=.1,\n        min_split_gain=.01,\n        min_child_weight=300,\n        silent=-1,\n        verbose=-1,\n        )\n    \n    clf.fit(trn_x, trn_y, \n            eval_set= [(trn_x, trn_y), (val_x, val_y)], \n            eval_metric='auc', verbose=100, early_stopping_rounds=100  #30\n           )\n    \n    oof_preds[val_idx] = clf.predict_proba(val_x, num_iteration=clf.best_iteration_)[:, 1]\n    sub_preds += clf.predict_proba(test[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"feature\"] = feats\n    fold_importance_df[\"importance\"] = clf.feature_importances_\n    fold_importance_df[\"fold\"] = n_fold + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(val_y, oof_preds[val_idx])))\n    del clf, trn_x, trn_y, val_x, val_y\n    gc.collect()\n\nprint('Full AUC score %.6f' % roc_auc_score(y, oof_preds)) \n\ntest['TARGET'] = sub_preds\n\ntest[['SK_ID_CURR', 'TARGET']].to_csv('submission1LGBM.csv', index=False)\n\n# Plot feature importances\ncols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n    by=\"importance\", ascending=False)[:50].index\n\nbest_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)];","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f0c9bbff9de6ed1c79adf196725a95779a0d6e4"},"cell_type":"markdown","source":"# Try blending some models"},{"metadata":{"trusted":true,"_uuid":"42c5fff5f017644c9cbe9e68386552a0ba8be87c","collapsed":true},"cell_type":"code","source":"# Plot importances\nimport seaborn as sns\nbest_features.head()","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"944f6047b0dcea981fda1e38c69db13e0a3ccf3f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}