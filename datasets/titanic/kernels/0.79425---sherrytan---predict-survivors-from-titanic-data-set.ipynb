{"cells":[{"metadata":{"_uuid":"021f76565820ccbbf8f88af6603057c54ed467ad"},"cell_type":"markdown","source":"##### Predicting survivors on Titanic data set\n"},{"metadata":{"trusted":true,"_uuid":"c8cddd67fb40f7d6d8b01f41b0abf1757a513e1d"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb6ea3d1a054696e660f12630bffda5f6d0c5007"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"11282c3c682d9d1ab6d600893f612f359b5b56f1"},"cell_type":"markdown","source":"### Exploratory data analysis"},{"metadata":{"trusted":true,"_uuid":"9b069a806804b9b2ec428b6060bd387b03574c51"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78fe8bb90522e7c3cee80513806579cbac071c0f"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be3fc55772668f97499a42bb728186d192064e1f"},"cell_type":"code","source":"for column in train.select_dtypes(exclude=[np.number]).columns.tolist():\n    print(\"{}: {} unique values\".format(column, train[column].nunique()))  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"472804d93b6897237163ba8e68e53bb90fcaf5e1"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"958e9838876c16eb96016b15ee4bda18f8cfd2ad"},"cell_type":"markdown","source":"The prediction task is a classification problem, in which predictions will be made on whether a passenger survived.\nThe output variable is 'Survived', where a value of 1 denotes that a passenger survived, while a value of 0 denotes that the passenger perished. The remaining columns are potential input variables.\n\nFor the input variables:\n- 'Ticket' and 'PassengerId' are unique identifiers and will not be useful for prediction. They will be excluded from the modelling. \n- 'Fare' would not directly impact a passenger's chance of survival at the time of the incident and will be excluded as well. (Fare is probably associated with Pclass and cabin location, which are likely to impact survival, but these columns are already available in the data. So, 'Fare' would not be a useful input variable) \n- Data types for categorical variables such as 'Survived' and 'Pclass' will be converted from numerical to 'str'\n- There are missing values for 'Age', 'Cabin' and 'Embarked'. These will need to be filled in later\n"},{"metadata":{"trusted":true,"_uuid":"70f6d66e6ffde780afebd6d4190b574db9a0c2bb"},"cell_type":"code","source":"for column in ['Survived', 'Pclass']:\n    train[column] = train[column].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0239be4c003576c28afbbabb5ef593cea3e0ffc1"},"cell_type":"code","source":"#visualize how categorical input variables affect survival\ncols = ['Pclass', 'Sex', 'SibSp','Parch', 'Embarked']\nfor col in cols:\n    plt.figure()\n    sns.countplot(x=col, data = train, hue=\"Survived\")\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7d543cb5090c87980ae609904157587f3f46fa8"},"cell_type":"code","source":"# visualize how numerical input variables affect survival\nfor status in train[\"Survived\"].unique():\n    plt.hist(x='Age',data=train[(train['Survived']==status) & (~train['Age'].isna())], alpha=0.5, label=status, bins=30)\n    plt.title(\"Age distribution\")\n    plt.legend(title=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8072dc962d8b13872de0c2b5311b286e8d1d627f"},"cell_type":"markdown","source":"From the visualizations, we can infer that: \n- Females and better Pclass (1 and 2) have higher proportions of survivors\n- Those not travelling with family (SibSp or Parch = 0) and those embarking at 'S' have lower proportions of survivors\n- 'Age' of 0-5 years has a higher proportion of survivors compared to other ages."},{"metadata":{"_uuid":"6e333969a5b5660b98186eef64b9b5fee97f2264"},"cell_type":"markdown","source":"### Data cleaning/wrangling\n#### SibSp/Parch\nFrom the preliminary data analysis, passengers travelling without SibSp/Parch tend to have lower survival rates. A new column will be created to indicate whether passenger has any family(SipSp or Parch) on board. "},{"metadata":{"trusted":true,"_uuid":"26c0ba003b0c10c7cfd824c43fbe1f379c42f3e0"},"cell_type":"code","source":"def transform_family_info(df):\n    df[\"HasSibSp\"] = 1\n    df[\"HasParch\"] = 1\n    df[\"HasFamily\"] = 1\n    df.loc[df[\"SibSp\"]==0,\"HasSibSp\"]=0\n    df.loc[df[\"Parch\"]==0,\"HasParch\"]=0\n    df.loc[(df[\"HasSibSp\"]==0)&(df[\"HasParch\"]==0), \"HasFamily\"]=0\n    \n    return df\n\n\ntrain = transform_family_info(train)\n\nfor col in [\"HasSibSp\",\"HasParch\",\"HasFamily\"]:\n    plt.figure()\n    sns.countplot(x=col, data = train, hue=\"Survived\")\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d93423141a9e7061054bafce99ad9db8d4d80a59"},"cell_type":"markdown","source":"There is a marked difference in survival rates for passengers with no family on board."},{"metadata":{"_uuid":"784c19d407f715f1ecdfb46c27475f773b427782"},"cell_type":"markdown","source":"#### Age \nThe 'Name' column contains titles i.e. 'Mr', 'Mrs' etc. This info may be useful for a differentiated approach in filling the missing 'Age' values. For example, \"Master\" was a form of address for younger males in the early 20th century. We would also expect titles such as \"Dr\", \"Col\" and \"Sir\" to refer to more mature passengers.\n\n'Title' was be extracted from the \"Name\" column and missing 'Age' values were filled based on the median of that corresponding title.  This would avoid overestimating 'Age' for certain groups such as 'Master'."},{"metadata":{"trusted":true,"_uuid":"6e85e005c1a03131882e9a32fab7f7657c372d21"},"cell_type":"code","source":"train['title'] = train['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip()) #extract titles from names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbcb46d07c31a23e3ea97ea9cbfe31b14144f48b"},"cell_type":"code","source":"sns.boxplot(x=\"Age\", y=\"title\", data=train) #visualize age distributions by title","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9af0b54a26dc0ed95f77da58ed42964cc0cdf02"},"cell_type":"markdown","source":"The above figure confirms that there is variation in age distributions for different titles. Missing 'Age' values will be filled using the median age for the corresponding titles."},{"metadata":{"trusted":true,"_uuid":"1ab945e744dd0946422e89cffcc6bd6bd3af7107"},"cell_type":"code","source":"age_medians  = train.pivot_table(columns=\"title\", aggfunc='median', values=\"Age\") #get median ages\nage_medians['overall'] = train['Age'].median() #get overall median age for the entire data set. this acts as a default value in case new titles are present in test data\n\ndef fill_age(df): #fill NA values for 'Age' column based on title \n    title = df['title'].unique().item()\n    try:\n        df['Age'].fillna(age_medians.loc['Age',title], inplace=True)\n    except:\n        df['Age'].fillna(age_medians.loc['Age','overall'], inplace=True)\n    return df\n\ntrain = train.groupby('title').apply(lambda x: fill_age(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55819cb891df2cdd7ac2d6b4f58672261f95c832"},"cell_type":"markdown","source":"Based on the distribution of survivors by age, those at Ages 0-5 tend to have a much higher survival rate. A new feature was created to denote whether passengers belonged to this age group."},{"metadata":{"trusted":true,"_uuid":"90a8ac0bb136bae8a20a45d8b3801d210bf42957"},"cell_type":"code","source":"def get_age_group(df):\n    \n    df['Age5_orLess']=0\n    df.loc[df['Age']<=5,'Age5_orLess']=1\n    \n    return df\n\ntrain = get_age_group(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9606fe2ec1bac5f90aa6e6b73d5929fd729df671"},"cell_type":"markdown","source":"#### Cabin"},{"metadata":{"_uuid":"1be1b37ae518270effa406cce46eed2745cedecf"},"cell_type":"markdown","source":"According to [this wikipedia article](https://en.wikipedia.org/wiki/Sinking_of_the_RMS_Titanic#%22Iceberg_right_ahead!%22_(23:39)), the collision happened close to midnight, so most passengers had gone to bed. \"Cabin\" would be a good indication of where each passenger was at the time of collision, which would affect their chances of survival (i.e. access to life boats etc). \n\n'Cabin_Deck' and \"Cabin_Number\" were extracted from \"Cabin\". Furthermore, according to [Titanic deckplans](https://www.encyclopedia-titanica.org/titanic-deckplans/), even-numbered cabins are located on one side of the ship and odd-numbered ones on the other. A 'Cabin_Number_Loc' column was created to reflect this.\n\n"},{"metadata":{"trusted":true,"_uuid":"dbba4a625f01428850551a33717b6459315459fc"},"cell_type":"code","source":"def get_cabin_info(df):\n    \n    #extract Cabin Deck and Number\n    df['Cabin_Deck']= np.NaN\n    df['Cabin_Number']= np.NaN\n    df['Cabin_Number_Loc']= np.NaN\n    df.loc[~df['Cabin'].isna(),'Cabin_Deck']  = df.loc[~df['Cabin'].isna(),'Cabin'].apply(lambda x:x[0]) #extract alphabet\n    df.loc[~df['Cabin'].isna(), 'Cabin_Number']  = df.loc[~df['Cabin'].isna(), 'Cabin'].apply(lambda x:x[1:].split(' ')[0]) #retain only first booth number if entries have multiple booths\n    df['Cabin_Number'] =  pd.to_numeric(df['Cabin_Number'], errors='coerce')\n    df.loc[df['Cabin_Number']%2==0, 'Cabin_Number_Loc']=\"even\"\n    df.loc[df['Cabin_Number']%2==1, 'Cabin_Number_Loc']=\"odd\"\n    \n    return df\n\ntrain = get_cabin_info(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76c1f536bc9ebfb84642cccebccd733929f053a8"},"cell_type":"code","source":"#visualize number of survivors by cabin deck\nsns.countplot(x='Cabin_Deck',data=train[~train['Cabin_Deck'].isna()],hue=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f68bfe2c3af0cc126b4a899e153b4943ce6b6659"},"cell_type":"code","source":"# There is no Deck T on the Titanic, so that observation will be set to 'NA'\ntrain['Cabin_Deck'] = train['Cabin_Deck'].replace(\"T\",np.NaN) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7eda1907a05edd00e045ae32b60a0639e78d784"},"cell_type":"code","source":"#visualize number of survivors by cabin number\nfor status in train[\"Survived\"].unique():\n    plt.hist(x='Cabin_Number',data=train[(train['Survived']==status) & (~train['Cabin_Number'].isna())], alpha=0.5, label=status, bins=30)\n    plt.title(\"Cabin Number distribution\")\n    plt.legend(title=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68a0b06bc035350eed9a11a33c2790a786e346e7"},"cell_type":"code","source":"#visualize number of survivors by Cabin_Number_Loc\nsns.countplot(x='Cabin_Number_Loc',data=train[~train['Cabin_Number_Loc'].isna()],hue=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76b1d944ef9d78e6b55b07e8bc8d42928c4119b0"},"cell_type":"code","source":"# number of missing Cabin values\ntrain[['Cabin','Cabin_Deck','Cabin_Number','Cabin_Number_Loc']].isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f83fab91dc504c0f8f259e090234e3bc7949c2ba"},"cell_type":"markdown","source":"Based on available data, cabin location appears to have an impact on survival likelihood. \n\nDecks A and G had lower proportions of survivors compared to other decks. \n\nOdd numbered cabins had a higher proportion of survivors compared to even numbered cabins. \n\nHowever, over 75% of 'Cabin_Deck' and 'Cabin_Number_Loc' values are missing. With that much missing data, these input variables cannot be used to train the model. "},{"metadata":{"_uuid":"a2e5794e3e782e571bc9053192a9a28e177d9c29"},"cell_type":"markdown","source":"##### Embarked\n\nThere were 2 missing values for Embarked, which will be filled with the mode"},{"metadata":{"trusted":true,"_uuid":"ee7d36ea1f3832bedd09714e65dbdafef86aec76"},"cell_type":"code","source":"train['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ceb7c8fc1fe0c6aa86e84752794200cf8fb435b"},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dca55d3eb090baafba82d5612ef132ea47117a00"},"cell_type":"markdown","source":"### Model Training\n\n"},{"metadata":{"_uuid":"d85f3a313ca823cdb99677ccb7d0fab97fe3f0f3"},"cell_type":"markdown","source":"2 algorithms were considered: random forest, which minimizes overfitting; and logistic regression, which is a relatively robust classifier with interpretable results.\n\nThe labelled 'train.csv' data will be split into a training and test set :\n- Training set: N-fold cross-validation and GridSearchCV will be used to train and optimize models. The best model will be selected based on cross-validation scores.\n- Test set (labelled): The selected model's predictive performance will be evaluated using the held-out labelled test set. \n\nSubsequently, the selected model will be used to make predictions on the unlabelled 'test.csv' data."},{"metadata":{"trusted":true,"_uuid":"b4f65c0867cab73a7fc2318b2a9fbba1afa05717"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8feeddf76255f417ad094dc1d9d24cbafc195b39"},"cell_type":"code","source":"#include only variables of interest\nvariables = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\", \"Embarked\", \"HasSibSp\", \"HasParch\", \"Age5_orLess\"]\ncat_var = [\"Sex\",\"Embarked\",\"Pclass\"]\n\nX = train[variables]\n\nX = pd.get_dummies(X, columns=cat_var, drop_first=True)\ny = train[\"Survived\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=43)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b942af11913ff74684fae6c2aaa5c1384a00cc31"},"cell_type":"markdown","source":"#### Random Forest"},{"metadata":{"trusted":true,"_uuid":"75a81a0c33bd54f17c1087473ddbc902147c8392"},"cell_type":"code","source":"def randomforestclassifier(X,y):\n    rf = RandomForestClassifier(random_state=77)\n\n    params = {'n_estimators': np.arange(100,500,100),'min_samples_split':np.arange(2,30,4),\n              'criterion':[\"gini\",\"entropy\"]}\n\n    rf_model_cv = GridSearchCV(rf, params, cv=StratifiedKFold(n_splits = 5, random_state=77), scoring='accuracy')\n    rf_model_cv.fit(X,y)\n    \n    print(\"Cross validation score:{:.3f}\".format(rf_model_cv.best_score_))\n    print(\"Best params:{}\".format(rf_model_cv.best_params_))\n\n    return rf_model_cv\n\nrfc = randomforestclassifier(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9564f0696de27a5256b3de57c4c5233e87bef581"},"cell_type":"markdown","source":"#### Logistic Regression"},{"metadata":{"trusted":true,"_uuid":"c61fb9033efb9023676068d934e465c56904a717"},"cell_type":"code","source":"def logisticregression(X,y):\n    log = LogisticRegression(max_iter=500)\n\n    params = {'C':np.linspace(0.1,1,10), 'solver':['liblinear','lbfgs', 'newton-cg']}\n\n    log_model_cv = GridSearchCV(log, params, cv=StratifiedKFold(n_splits=5,random_state=77), scoring = \"accuracy\")\n    log_model_cv.fit(X,y)\n\n    print(\"Cross validation score:{:.3f}\".format(log_model_cv.best_score_))\n    print(\"Best params:{}\".format(log_model_cv.best_params_))\n    \n    return log_model_cv\n    \nlog = logisticregression(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"443a7624db62e8c65c7b87877b96e167bf29fbc2"},"cell_type":"markdown","source":"Cross validation accuracy scores for both models are comparable at 83-84%\n\nThe Log Regression model will be selected as the final model as it has an advantage over random forest in that its outputs are more interpretable (coefficients reflect whether input variables negatively or positively affect outcome) \n"},{"metadata":{"_uuid":"8e1e517a78509e2ad314538c2284bb9f46bd7a6b"},"cell_type":"markdown","source":"### Model Evaluation"},{"metadata":{"trusted":true,"_uuid":"77ec7934f9f712c3279d4959ac491ef10225640f"},"cell_type":"code","source":"#Visualize coefs of log model\nweights_log = pd.Series(log.best_estimator_.coef_.transpose()[:,0], index=X.columns).sort_values(ascending=False)\n\nfig, ax = plt.subplots(figsize=(8,6))\nypos = np.arange(0,len(weights_log))[::-1]\n\npositive_weights = weights_log[weights_log>=0]\nypos_positive = ypos[weights_log>=0]\nnegative_weights = weights_log[weights_log<0]\nypos_negative = ypos[weights_log<=0]\nax.barh(ypos_positive,positive_weights, color='#77B7D8')\nax.barh(ypos_negative,negative_weights, color='#C16C82')\n\nax.set_yticks(ypos)\nax.set_yticklabels(weights_log.index)\n\nfor i,value in zip(ypos, weights_log.values):\n    ax.annotate(\"{:.2f}\".format(value), xy=(value, i))\n    \nplt.title(\"Coefficients for Log Regression Model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e382319d65d443e92a2994bb6f488cdfe002f470"},"cell_type":"code","source":"## evaluate prediction accuracy on held out labelled data set using log model\ny_pred = log.predict(X_test)\n\nprint(\"MODEL PERFORMANCE\")\nprint(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test,y_pred)*100))\nprint(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test,y_pred)))\nprint(\"Recall:\\n{:.2f}%\".format(100*recall_score(y_test.astype('int'), y_pred.astype('int'))))\nprint(\"Precision:\\n{:.2f}%\".format(100*precision_score(y_test.astype('int'), y_pred.astype('int'))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b4cd7096e114c88174807221c4fc4281a53905c"},"cell_type":"code","source":"#evaluate prediction accuracy using a baseline guess of y_train.mode() for all predictions\ny_pred2 = np.repeat(y_train.mode(), len(y_test))\n\nprint(\"BASELINE PERFORMANCE (all outcomes assumed to take the mode of y_train)\")\nprint(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test,y_pred2)*100))\nprint(\"Confusion matrix:\\n{}\".format(confusion_matrix(y_test,y_pred2)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f49f69ed0c358e82c020022eaf3ca9c0c029dfd1"},"cell_type":"markdown","source":"### Conclusions\n\nThe log model gives an accuracy of 78% on the held out (labelled) test set, a 17% improvement over the baseline. \n\nBased on the log model coefficients, being male or in Pclass 3 greatly reduced the likelihood of survival, while passengers aged 5 or less were more likely to survive. \n\nInterestingly, \"SibSp\" has a negative coefficient i.e. a higher number reduced the likelihood of survival. On the other hand, \"HasSibSp\" has a positive coefficient, i.e. survival likelhood was higher for those with siblings/spouses on board than those without. A similar, but less pronounced trend was seen for Parch.\n\nWe could infer that having a large number of family members on board might adversely affect survival (having a large family may delay escape as one may try to find all his/her family members before getting on a life boat), while not having any family on board at all also adversely affects survival (i.e. there is no one to help look out for you and realise you are missing)"},{"metadata":{"_uuid":"1787296515464d09560e9afd4363ab48b3a5084f"},"cell_type":"markdown","source":"#### Predictions on unlabelled test set"},{"metadata":{"trusted":true,"_uuid":"3b4f6b2aebdcc2d5f4c438d217eeedb7fbaef8aa"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\ntest.isnull().sum()/len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26f6641d8dd2ad0e3d67294321682ee5923ced7e"},"cell_type":"code","source":"# define a function that consolidates the data cleaning and preprocessing steps to facilitate treatment of unlabelled test set \ndef preproc(df):\n    \n    #fill missing age values\n    df['title'] = df['Name'].apply(lambda x:x.split(',')[1].split('.')[0].strip()) #extract titles from names\n    df = df.groupby('title').apply(lambda x: fill_age(x))\n    \n    #change Pclass to categorical var\n    df['Pclass']=df['Pclass'].astype('str')\n    \n    #fill missing Embarked data\n    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode())\n    \n    #create categorical SibSp/Parch/Family/Age columns\n    df = transform_family_info(df)\n    df = get_age_group(df)\n    \n    return df\n\n\ntest_cleaned = preproc(test) #preprocess test data in the same way as train\nX_test_unlabelled = test_cleaned[variables]\nX_test_unlabelled = pd.get_dummies(X_test_unlabelled , columns=cat_var)\n\n\ndef add_missing_dummy_columns(train, test): #ensure test set is not missing columns needed for prediction\n    missing_cols = set(train.columns) - set(test.columns) \n    for c in missing_cols:\n        test[c] = 0\n    test = test[train.columns]\n    return test\n\nX_test_unlabelled = add_missing_dummy_columns(X,X_test_unlabelled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15ca36853331fe9a8e1eacdcc64c5b7b88930c8a"},"cell_type":"code","source":"filename = \"submission.csv\"\n\npredictions = log.predict(X_test_unlabelled) \npredictions_df = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': predictions})\npredictions_df.to_csv(filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50a92e6df24f8df0b74e10a98f0f72f47be38f84"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}