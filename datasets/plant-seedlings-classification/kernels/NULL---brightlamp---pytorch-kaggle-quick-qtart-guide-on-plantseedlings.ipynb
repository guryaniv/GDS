{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# First, Please turn on the GPU on Kaggle.\n\nimport os\nimport time\nimport shutil\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nfrom torchvision.datasets import ImageFolder\n\n%matplotlib inline\n\nif_gpu = torch.cuda.is_available()\nprint(\"GPU is on?\", if_gpu)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"274bd8362a79bb5bc280afb0bc8d6095a72f1124","trusted":false},"cell_type":"code","source":"# Show some information of Kaggle's input folder.\n\nprint(os.listdir(\"../\"))\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/train\"))\nprint(os.listdir(\"../input/test\")[:6])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebc31b6ff881320ae3617ea5902fadb68b13d676","trusted":false},"cell_type":"code","source":"# ImageFolder() needs subfolders.\n# Copy test images of input to temporary folder to avoid train images.\n\ndef copytree_and_overwrite(from_path, to_path):\n    if os.path.exists(to_path):\n        shutil.rmtree(to_path)\n    shutil.copytree(from_path, to_path)\n    return True\n\ncopytree_and_overwrite(\"../input/test\", \"../working/tmp/test/test_images\")\n\nprint(os.listdir(\"../working/tmp/test/test_images\")[:6])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bfc4dfd2fec1727bc9d50bdd21cefd5afbf8f04","trusted":false},"cell_type":"code","source":"# Read and resize images to [224, 224].\n\ndef read_image_folder(resize_shape, image_folder):\n    resize = torchvision.transforms.Resize(resize_shape)\n    image_folder = ImageFolder(image_folder, transform=resize)\n\n    idx_to_class = {value: key for key, value in image_folder.class_to_idx.items()}\n    image_paths = [item[0] for item in image_folder.imgs]\n\n    image_shape = np.array(image_folder[0][0]).shape\n    data_length = len(image_folder)\n\n    data_shape = list(image_shape)\n    data_shape.insert(0, data_length)\n\n    data = np.zeros(data_shape, dtype=np.uint8)\n    labels = np.zeros([data_length], dtype=np.int64)\n\n    i = 0\n    for image, label in tqdm(image_folder, desc=\"Reading Images\"):\n        data[i] = np.array(image)\n        labels[i] = label\n        i += 1\n\n    data_dict = {\"data\": data, \"labels\": labels, 'data_shape': image_shape}\n    info_dict = {\"label_names\": idx_to_class, \"file_paths\": image_paths}\n\n    return data_dict, info_dict\n\ntrain_dict, train_info_dict = read_image_folder((224,224),\"../input/train\")\ntest_dict, test_info_dict = read_image_folder((224,224),\"../working/tmp/test/\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"# Show one of train and test.\nimport matplotlib.pyplot as plt\nplt.figure()\nplt.imshow(train_dict[\"data\"][800])\nplt.figure()\nplt.imshow(test_dict[\"data\"][600])\nprint(\"iamge shape =\", train_dict[\"data\"][300].shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1e00dcaa4eff775efc4af2ef4465a813782e005e","trusted":false},"cell_type":"code","source":"# Define a dataset\n\nclass ImageDataset(torch.utils.data.Dataset):\n    def __init__(self, x_data, y_data):\n        self.x_data = x_data\n        self.y_data = y_data\n        self.to_tensor = torchvision.transforms.ToTensor()\n\n    def __getitem__(self, index):\n        return self.to_tensor(self.x_data[index]), self.y_data[index]\n\n    def __len__(self):\n        return len(self.x_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa12634c04aacf9278cfdc55bbbfb697f4ee4ea","trusted":false},"cell_type":"code","source":"# Note that torchvision.transforms.ToTensor() will\n# Converts a PIL Image or numpy.ndarray (H x W x C) in the range\n# [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0].\n\nwhole_dataset = ImageDataset(train_dict[\"data\"], train_dict[\"labels\"])\n\nprint(whole_dataset[0][0].shape)\nprint(whole_dataset[4610])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fb8c6c9e9827f96b669a15ae302d785e926f78a","trusted":false},"cell_type":"code","source":"# subset the whole train set for accuracy check while training.\n\ndef array_random_pick(array, pick_num):\n    index = np.arange(len(array))\n    pick = np.random.choice(len(array), pick_num, replace=False)\n    unpick = np.equal(np.in1d(index, pick), False)\n    return array[unpick], array[pick]\n\ntrain_mask, valid_mask = array_random_pick(np.arange(len(whole_dataset)), 500)\n\ntrain_set = torch.utils.data.Subset(whole_dataset, train_mask)\nvalid_set = torch.utils.data.Subset(whole_dataset, valid_mask)\n\nprint(len(train_set),len(valid_set))\nprint(train_set[4010])\nprint(valid_set[401])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a89038117143726d2ff7161b87d4ae4d4f5457f7","trusted":false},"cell_type":"code","source":"# Use DataLoader to group data batchs. Here use size 4 for a batch.\n# DataLoader will return a iterator.\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=5)\nload_iter = iter(train_loader)\none_batch_x, one_batch_y = next(load_iter)\n\nprint(one_batch_y)\nprint(one_batch_x.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2286cbf5bd7e89df03e328476f4eb9cfe10abd44","trusted":false},"cell_type":"code","source":"# Use PyTorch's built-in model to generate AlexNet with classes 12.\n# With input data of size [4, 3, 224, 224], AlexNet will output data of size [4, 12].\n\nalex = torchvision.models.AlexNet(num_classes = 12)\nalex_out = alex(one_batch_x)\nprint(alex_out.shape)\nprint(alex_out)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f29d1a5d937d53668b591efbccf2f81fbf44f927","trusted":false},"cell_type":"code","source":"# We use the max index of alex_out to\n# evaluate the accuracy of model predict.\n# Now the accuracy is zero before model train.\n\npredict = torch.argmax(alex_out, dim = 1)\ncompare = predict == one_batch_y\naccuracy = compare.sum() / len(predict)\n\nprint(predict)\nprint(one_batch_y)\nprint(compare)\nprint(\"accuracy =\", accuracy.data.numpy())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"edd33efd58c8b8ae2353002acd8006b1db7162ff","trusted":false},"cell_type":"code","source":"# define a base utility to train a net.\n\nclass BaseNetPyTorch:\n    def __init__(self):\n        self.train_loader = None\n        self.sub_train_loader = None\n        self.valid_loader = None\n\n        self.model = None\n        self.optimize_method = None\n        self.loss_function = None\n\n        if_gpu = torch.cuda.is_available()\n        self.device_gpu = torch.device(\"cuda:0\" if if_gpu else \"cpu\")\n\n    def train_loss(self):\n        # \"training\" mode for Dropout etc.\n        self.model.train()\n\n        train_loss = None\n        for (x, y) in self.train_loader:\n            x_gpu = x.to(self.device_gpu)\n            y_gpu = y.long().to(self.device_gpu)\n\n            predict = self.model(x_gpu)\n            train_loss = self.loss_function(predict, y_gpu)\n\n            self.optimize_method.zero_grad()\n            train_loss.backward()\n            self.optimize_method.step()\n        return train_loss\n\n    def predict_index(self, check_loader):\n        predict_list = []\n        for x, y in check_loader:\n            x_gpu = x.to(self.device_gpu)\n            predict = self.model(x_gpu)\n            max_index = torch.argmax(predict, dim=1)\n            predict_list += max_index.cpu().data.numpy().tolist()\n        return predict_list\n\n    def check_accuracy(self, check_set):\n        num_correct = 0\n        num_samples = 0\n        # \"test\" mode for Dropout etc.\n        self.model.eval()\n        for x, y in check_set:\n            x_gpu = x.to(self.device_gpu)\n            y_gpu = y.to(self.device_gpu)\n\n            predict = self.model(x_gpu)\n            max_index = torch.argmax(predict, dim=1)\n\n            num_correct += (max_index == y_gpu).sum()\n            num_samples += max_index.shape[0]\n\n        accuracy = float(num_correct) / float(num_samples)\n        return num_correct, num_samples, accuracy\n\n    def train(self, num_epochs=1):\n        if self.model is None:\n            raise ValueError(\"self.model is None! Please assign it.\")\n        if self.optimize_method is None:\n            raise ValueError(\"self.optimize_method is None! Please assign it.\")\n        if self.loss_function is None:\n            raise ValueError(\"self.loss_function is None! Please assign it.\")\n\n        print(\"begin training, length_of_one_mini_batch :\", len(self.train_loader))\n\n        self.model = self.model.to(self.device_gpu)\n\n        train_time = time.time()\n        for epoch in range(num_epochs):\n            epoch_start = time.time()\n\n            loss = self.train_loss()\n            loss_time = time.time()\n\n            train_correct, train_samples, train_acc = self.check_accuracy(self.sub_train_loader)\n            train_acc_time = time.time()\n\n            valid_correct, valid_samples, valid_acc = self.check_accuracy(self.valid_loader)\n            valid_acc_time = time.time()\n\n            epoch_time = time.time()\n\n            print('epoch:%d/%d' % (epoch + 1, num_epochs), end=\" \")\n            print('loss:%.4f|%ds' % (loss.data, (loss_time - epoch_start)), end=\" \")\n            print('train_acc:(%d/%d %0.2f%%)|%ds' %\n                  (train_correct, train_samples, 100 * train_acc, train_acc_time - loss_time), end=' ')\n            print('valid_acc:(%d/%d %0.2f%%)|%ds' %\n                  (valid_correct, valid_samples, 100 * valid_acc, (valid_acc_time - train_acc_time)), end=' ')\n            print(\"take:%dmin remain:%dmin\" %\n                  ((epoch_time - train_time) / 60, (epoch_time - epoch_start) * (num_epochs - epoch) / 60))\n\n            if (train_acc - 0.3 > valid_acc) and (train_acc > 0.5):\n                print(\"Model Overfit 30.00%, stopped.\")\n                return True\n\n        return True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f4c230b075389839555b06f1d01e2d8331ce565","trusted":false},"cell_type":"code","source":"# It is very important to turn on shuffle=True of training set\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=40, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_set, batch_size=40)\n\nnet = BaseNetPyTorch()\nnet.model = torchvision.models.AlexNet(num_classes=12)\nnet.optimize_method = torch.optim.Adam(net.model.parameters(), lr=0.0001)\nnet.loss_function = torch.nn.CrossEntropyLoss()\n\nnet.train_loader = train_loader\nnet.sub_train_loader = train_loader\nnet.valid_loader = valid_loader\n\nnet.train(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4a8dab7d12afe2eb75029afb9d25a65d05fd7938"},"cell_type":"code","source":"# predict test file labels\n\ntest_set = ImageDataset(test_dict[\"data\"], test_dict[\"labels\"])\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=40)\nlabel_names = train_info_dict[\"label_names\"]\n\ntest_predict = net.predict_index(test_loader)\npredict_names = [label_names[i] for i in test_predict]\n\nprint(test_predict[:10])\nprint(predict_names[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"30f6eba1220e20a277b14b609fe7e1c12473f936"},"cell_type":"code","source":"# classify test_files to different sub_folders\n\ntest_file_paths = test_info_dict[\"file_paths\"]\nsave_folder = \"../working/tmp/predict\"\n\ndef make_dirs(path):\n    if not os.path.exists(path):\n        os.makedirs(path)\n\ndef copy2sub_folders(source_file_paths, sub_folder_names, to_folder):\n    for i in tqdm(range(len(source_file_paths))):\n        file_dir = os.path.join(to_folder, sub_folder_names[i])\n        make_dirs(file_dir)\n        shutil.copy2(source_file_paths[i], file_dir)\n        \ncopy2sub_folders(test_file_paths, predict_names, save_folder)\n\nprint(os.listdir(\"../working/tmp/predict\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"18fe1efed080a581234d5bf924831077c7084f22"},"cell_type":"code","source":"# Create a predict submission file.\n\ndef folder_file_info(root):\n    folder_file_list = []\n    path_dirs = os.listdir(root)\n    for folder in path_dirs:\n        dir_files = os.listdir(os.path.join(root, folder))\n        for file_name in dir_files:\n            folder_file_list.append([file_name, folder])\n    return folder_file_list\n\n\nfile_predict_table = folder_file_info(\"../working/tmp/predict\")\ndf = pd.DataFrame(file_predict_table, columns=['file', 'species'])\ndf.to_csv(\"predict_submission.csv\", index=False)\nprint(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52c6ab3e69fdf5a94ec5afea2de811eccaba49db","trusted":false},"cell_type":"code","source":"# delect temporary working folder before Kaggle Commit.\nif os.path.exists(\"../working/tmp\"):\n    shutil.rmtree(\"../working/tmp\")\n\nos.listdir(\"../working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b2f4f91c1480071f95e8b8bb0729cc24e4f15668"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"}},"nbformat":4,"nbformat_minor":1}