{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Plant Seedling Classification using Convolutional Neural Networks\nThis dataset consists of a training set and a testing set of images of plant seedlings at various growth stages. Each image has its own unique ID. The dataset has 12 main plant species which we need to classify the testing set into. \nFor this task we will need to process and clean the data using image processing Then we will have to build a model and evaluate it.\nLet's get started! "},{"metadata":{"_uuid":"afd2c0f8328eb1633553c37a415e044a4dbd1422"},"cell_type":"markdown","source":"**(1). Importing all the necessary modules:**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # MATRIX OPERATIONS\nimport pandas as pd # EFFICIENT DATA STRUCTURES\nimport matplotlib.pyplot as plt # GRAPHING AND VISUALIZATIONS\nimport math # MATHEMATICAL OPERATIONS\nimport cv2 # IMAGE PROCESSING - OPENCV\nfrom glob import glob # FILE OPERATIONS\nimport itertools\n\n# KERAS AND SKLEARN MODULES\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\n\n# GLOBAL VARIABLES\nscale = 70\nseed = 7","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"56d270d77a293192d564d774eeb3b8235415593e"},"cell_type":"markdown","source":"**(2). Getting the data and resizing the images:**"},{"metadata":{"trusted":true,"_uuid":"1bc9fe88c8716f1e4a0344b3c3b58b46b3ce1810","collapsed":true},"cell_type":"code","source":"path_to_images = '../input/plant-seedlings-classification/train/*/*.png'\nimages = glob(path_to_images)\ntrainingset = []\ntraininglabels = []\nnum = len(images)\ncount = 1\n#READING IMAGES AND RESIZING THEM\nfor i in images:\n    print(str(count)+'/'+str(num),end='\\r')\n    trainingset.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    traininglabels.append(i.split('/')[-2])\n    count=count+1\ntrainingset = np.asarray(trainingset)\ntraininglabels = pd.DataFrame(traininglabels)","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"1ffbac53101299d45c4be2d84e25aa30c419972c"},"cell_type":"markdown","source":"**(3). Cleaning the images and removing the background:**\n* Cleaning of the images is an intensive task. We will have to:\n    * Convert the RGB image into HSV.\n    * We will have to blur the image to remove noise.\n    * We will have to create a mask to remove the background."},{"metadata":{"trusted":true,"_uuid":"0969b7bdfa3614e5e7527325f63472464ca27560","collapsed":true},"cell_type":"code","source":"new_train = []\nsets = []; getEx = True\nfor i in trainingset:\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    #GREEN PARAMETERS\n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    boolean = mask>0\n    new = np.zeros_like(i,np.uint8)\n    new[boolean] = i[boolean]\n    new_train.append(new)\n    \n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE\n        plt.show()\n        getEx = False\nnew_train = np.asarray(new_train)\n\n# CLEANED IMAGES\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    plt.imshow(new_train[i])","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"12ce16ada1d5ea811b8395fffb00ab457723d28d"},"cell_type":"markdown","source":"**(4). Converting the Labels into numbers:**\n* The labels are strings and these are hard to process. So we'll convert these labels into a binary classification.\n* The classification can be represented by an array of 12 numbers which will follow the condition:\n    * 0 if the species is not detected.\n    * 1 if the species is detected.\n* Example: If Blackgrass is detected, the array will be = [1,0,0,0,0,0,0,0,0,0,0,0]"},{"metadata":{"trusted":true,"_uuid":"6401705a939f2f542a49b87947f7a30c46d7b64c","collapsed":true},"cell_type":"code","source":"labels = preprocessing.LabelEncoder()\nlabels.fit(traininglabels[0])\nprint('Classes'+str(labels.classes_))\nencodedlabels = labels.transform(traininglabels[0])\nclearalllabels = np_utils.to_categorical(encodedlabels)\nclasses = clearalllabels.shape[1]\nprint(str(classes))\ntraininglabels[0].value_counts().plot(kind='pie')","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"c4e446febf5983298485fd04ad7ffcc76d21dcd5"},"cell_type":"markdown","source":"**(5). Defining our model and splitting the dataset:**\n* We need to split the training set for validation."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8c3d89d8391f22ddf5d497295650a0b3ceaa3eb0"},"cell_type":"code","source":"new_train = new_train/255\nx_train,x_test,y_train,y_test = train_test_split(new_train,clearalllabels,test_size=0.1,random_state=seed,stratify=clearalllabels)","execution_count":6,"outputs":[]},{"metadata":{"_uuid":"691dab3be3969e5c091a805fada90d272f23c2ba"},"cell_type":"markdown","source":"**(6). Preventing Overfitting:**\n* To prevent overfitting, we need to create a function that can randomly change image characterisitics during fitting."},{"metadata":{"trusted":true,"_uuid":"868d54609e0cdeacebbf455bf275556c8cbf1333","collapsed":true},"cell_type":"code","source":"generator = ImageDataGenerator(rotation_range = 180,zoom_range = 0.1,width_shift_range = 0.1,height_shift_range = 0.1,horizontal_flip = True,vertical_flip = True)\ngenerator.fit(x_train)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"0792097cbb09cf07c89361b173ec7298445eb01c"},"cell_type":"markdown","source":"**(7). Defining the Convolutional Neural Network:**\n* This model has 4 convolution layers.\n* This model has 3 fully connected layers."},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"2c7a676c92eefbbc00d336bed3e84abc25d69d5f","collapsed":true},"cell_type":"code","source":"np.random.seed(seed)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), input_shape=(scale, scale, 3), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=128, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(filters=256, kernel_size=(5, 5), activation='relu'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Dropout(0.1))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(classes, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()\n\n","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"e2e7336a52c32bb79646bef1c19cb7a945df54f4"},"cell_type":"markdown","source":"**(8). Fitting the CNN onto the data:**\n* We have to set a few callbacks:\n    * We have to reduce the learning rate because, convergence will be much quicker.\n    * We have to save the best weights of the model.\n    * We have to save the last weights of the model.    "},{"metadata":{"trusted":true,"_uuid":"422cfb2de5c17a9c4a62bba978394e513556e38e","collapsed":true},"cell_type":"code","source":"# SETTING UP CHECKPOINTS, CALLBACKS AND REDUCING LEARNING RATE\nlrr = ReduceLROnPlateau(monitor='val_acc', \n                        patience=3, \n                        verbose=1, \n                        factor=0.4, \n                        min_lr=0.00001)\n\nfilepath=\"drive/DataScience/PlantReco/weights.best_{epoch:02d}-{val_acc:.2f}.hdf5\"\ncheckpoints = ModelCheckpoint(filepath, monitor='val_acc', \n                              verbose=1, save_best_only=True, mode='max')\nfilepath=\"drive/DataScience/PlantReco/weights.last_auto4.hdf5\"\ncheckpoints_full = ModelCheckpoint(filepath, monitor='val_acc', \n                                 verbose=1, save_best_only=False, mode='max')\n\ncallbacks_list = [checkpoints, lrr, checkpoints_full]\n\n#MODEL\n# hist = model.fit_generator(datagen.flow(trainX, trainY, batch_size=75), \n#                            epochs=35, validation_data=(testX, testY), \n#                            steps_per_epoch=trainX.shape[0], callbacks=callbacks_list)\n\n# LOADING MODEL\nmodel.load_weights(\"../input/plantrecomodels/weights.best_17-0.96.hdf5\")\ndataset = np.load(\"../input/plantrecomodels/Data.npz\")\ndata = dict(zip((\"x_train\",\"x_test\",\"y_train\", \"y_test\"), (dataset[k] for k in dataset)))\nx_train = data['x_train']\nx_test = data['x_test']\ny_train = data['y_train']\ny_test = data['y_test']\n\nprint(model.evaluate(x_train, y_train))  # Evaluate on train set\nprint(model.evaluate(x_test, y_test))  # Evaluate on test set","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"31f56b000ddbfab011358dbaf01ea90c4ef53ef1"},"cell_type":"markdown","source":"**(9). Confusion Matrix:**\n* The confusion matrix is one of the best ways to analyse the errors in the model.\n* It gives the exact number of correct and incorrect predictions"},{"metadata":{"trusted":true,"_uuid":"d0b8fcf76d74db88e24f68eef4fa946aa1b6ff98","collapsed":true},"cell_type":"code","source":"# PREDICTIONS\ny_pred = model.predict(x_test)\ny_class = np.argmax(y_pred, axis = 1) \ny_check = np.argmax(y_test, axis = 1) \n\ncmatrix = confusion_matrix(y_check, y_class)\nprint(cmatrix)","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"2ecd43f6947704aced8cfe27bd6d871d23c92268"},"cell_type":"markdown","source":" **(10). Process the testing set and getting predictions:**"},{"metadata":{"trusted":true,"_uuid":"71c92838dade5ea46e313061b098129809ea872a","collapsed":true},"cell_type":"code","source":"path_to_test = '../input/plant-seedlings-classification/test/*.png'\npics = glob(path_to_test)\n\ntestimages = []\ntests = []\ncount=1\nnum = len(pics)\n\nfor i in pics:\n    print(str(count)+'/'+str(num),end='\\r')\n    tests.append(i.split('/')[-1])\n    testimages.append(cv2.resize(cv2.imread(i),(scale,scale)))\n    count = count + 1\n\ntestimages = np.asarray(testimages)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b8cdf25f9d8068dc96fb67cfd06ef04ecbc0d8c","collapsed":true},"cell_type":"code","source":"newtestimages = []\nsets = []\ngetEx = True\nfor i in testimages:\n    blurr = cv2.GaussianBlur(i,(5,5),0)\n    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n    \n    lower = (25,40,50)\n    upper = (75,255,255)\n    mask = cv2.inRange(hsv,lower,upper)\n    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n    boolean = mask>0\n    masking = np.zeros_like(i,np.uint8)\n    masking[boolean] = i[boolean]\n    newtestimages.append(masking)\n    \n    if getEx:\n        plt.subplot(2,3,1);plt.imshow(i)\n        plt.subplot(2,3,2);plt.imshow(blurr)\n        plt.subplot(2,3,3);plt.imshow(hsv)\n        plt.subplot(2,3,4);plt.imshow(mask)\n        plt.subplot(2,3,5);plt.imshow(boolean)\n        plt.subplot(2,3,6);plt.imshow(masking)\n        plt.show()\n        getEx=False\n\nnewtestimages = np.asarray(newtestimages)\n# OTHER MASKED IMAGES\nfor i in range(6):\n    plt.subplot(2,3,i+1)\n    plt.imshow(newtestimages[i])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e666de7b0924b4807a819de4419fa4ecd3262ba7","collapsed":true},"cell_type":"code","source":"newtestimages=newtestimages/255\nprediction = model.predict(newtestimages)\n# PREDICTION TO A CSV FILE\npred = np.argmax(prediction,axis=1)\npredStr = labels.classes_[pred]\nresult = {'file':tests,'species':predStr}\nresult = pd.DataFrame(result)\nresult.to_csv(\"Prediction.csv\",index=False)","execution_count":15,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}