{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "288010af-4aca-99f0-6e72-e133bc3e406e"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "976687aa-0e36-f1b5-c973-d787a073f5ee"
      },
      "outputs": [],
      "source": [
        "#importing necessary packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "#for writing text files\n",
        "import glob\n",
        "import os     \n",
        "import random \n",
        "#reading images from a text file\n",
        "from tflearn.data_utils import image_preloader\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0e22465e-85eb-6759-f0ef-4e797dfe150c"
      },
      "outputs": [],
      "source": [
        "IMAGE_FOLDER = 'C:/Users/drago/DvsG/train/train'\n",
        "TRAIN_DATA = 'C:/Users/drago/DvsG/training_data.txt'\n",
        "TEST_DATA = 'C:/Users/drago/DvsG/test_data.txt'\n",
        "VALIDATION_DATA = 'C:/Users/drago/DvsG/validation_data.txt'\n",
        "train_proportion=0.7\n",
        "test_proportion=0.2\n",
        "validation_proportion=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3a106ca5-3c1f-7d80-4d00-86e365b65d5a"
      },
      "outputs": [],
      "source": [
        "#read the image directories\n",
        "filenames_image = os.listdir(IMAGE_FOLDER)\n",
        "#shuffling the data is important otherwise the model will be fed with a single class data for a long time and \n",
        "#network will not learn properly\n",
        "random.shuffle(filenames_image)\n",
        "#total number of images\n",
        "total=len(filenames_image)\n",
        "##  *****training data******** \n",
        "fr = open(TRAIN_DATA, 'w')\n",
        "train_files=filenames_image[0: int(train_proportion*total)]\n",
        "for filename in train_files:\n",
        "    if filename[0:3] == 'cat':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 0\\n')\n",
        "    elif filename[0:3] == 'dog':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 1\\n')\n",
        "\n",
        "fr.close()\n",
        "##  *****testing data******** \n",
        "fr = open(TEST_DATA, 'w')\n",
        "test_files=filenames_image[int(math.ceil(train_proportion*total)):int(math.ceil((train_proportion+test_proportion)*total))]\n",
        "for filename in test_files:\n",
        "    if filename[0:3] == 'cat':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 0\\n')\n",
        "    elif filename[0:3] == 'dog':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 1\\n')\n",
        "fr.close()\n",
        "\n",
        "##  *****validation data******** \n",
        "fr = open(VALIDATION_DATA, 'w')\n",
        "valid_files=filenames_image[int(math.ceil((train_proportion+test_proportion)*total)):total]\n",
        "for filename in valid_files:\n",
        "    if filename[0:3] == 'cat':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 0\\n')\n",
        "    elif filename[0:3] == 'dog':\n",
        "        fr.write(IMAGE_FOLDER + '/'+ filename + ' 1\\n')\n",
        "fr.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ee7754a-aa1e-1019-28da-924b18661e65"
      },
      "outputs": [],
      "source": [
        "#Importing data\n",
        "#importing data\n",
        "X_train, Y_train = image_preloader(TRAIN_DATA, image_shape=(56,56),mode='file', categorical_labels=True,normalize=True)\n",
        "X_test, Y_test = image_preloader(TEST_DATA, image_shape=(56,56),mode='file', categorical_labels=True,normalize=True)\n",
        "X_val, Y_val = image_preloader(VALIDATION_DATA, image_shape=(56,56),mode='file', categorical_labels=True,normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eb1b1e0b-af7d-bc91-ed29-663223b61baf"
      },
      "outputs": [],
      "source": [
        "print (\"Dataset\")\n",
        "print (\"Number of training images {}\".format(len(X_train)))\n",
        "print (\"Number of testing images {}\".format(len(X_test)))\n",
        "print (\"Number of validation images {}\".format(len(X_val)))\n",
        "print (\"Shape of an image {}\" .format(X_train[1].shape))\n",
        "print (\"Shape of label:{} ,number of classes: {}\".format(Y_train[1].shape,len(Y_train[1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ebc27620-692d-411b-c992-922f17008b78"
      },
      "outputs": [],
      "source": [
        "#Sample Image \n",
        "plt.imshow(X_train[1])\n",
        "plt.axis('off')\n",
        "plt.title('Sample image with label {}'.format(Y_train[1]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02f9b4e3-ec0c-38ef-6a1e-007142c21b89"
      },
      "outputs": [],
      "source": [
        "x=tf.placeholder(tf.float32,shape=[None,56,56,3] , name='input_image') \n",
        "#input class\n",
        "y_=tf.placeholder(tf.float32,shape=[None, 2] , name='input_class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2d259d47-1246-ca41-0866-6d273478bc53"
      },
      "outputs": [],
      "source": [
        "input_layer=x\n",
        "#convolutional layer 1 --convolution+RELU activation\n",
        "conv_layer1=tflearn.layers.conv.conv_2d(input_layer, nb_filter=64, filter_size=5, strides=[1,1,1,1],\n",
        "                                        padding='same', activation='relu', regularizer=\"L2\", name='conv_layer_1')\n",
        "\n",
        "#2x2 max pooling layer\n",
        "out_layer1=tflearn.layers.conv.max_pool_2d(conv_layer1, 2)\n",
        "\n",
        "\n",
        "#second convolutional layer \n",
        "conv_layer2=tflearn.layers.conv.conv_2d(out_layer1, nb_filter=128, filter_size=5, strides=[1,1,1,1],\n",
        "                                        padding='same', activation='relu',  regularizer=\"L2\", name='conv_layer_2')\n",
        "out_layer2=tflearn.layers.conv.max_pool_2d(conv_layer2, 2)\n",
        "# third convolutional layer\n",
        "conv_layer3=tflearn.layers.conv.conv_2d(out_layer2, nb_filter=128, filter_size=5, strides=[1,1,1,1],\n",
        "                                        padding='same', activation='relu',  regularizer=\"L2\", name='conv_layer_2')\n",
        "out_layer3=tflearn.layers.conv.max_pool_2d(conv_layer3, 2)\n",
        "\n",
        "#fully connected layer1\n",
        "fcl= tflearn.layers.core.fully_connected(out_layer3, 4096, activation='relu' , name='FCL-1')\n",
        "fcl_dropout_1 = tflearn.layers.core.dropout(fcl, 0.8)\n",
        "#fully connected layer2\n",
        "fc2= tflearn.layers.core.fully_connected(fcl_dropout_1, 4096, activation='relu' , name='FCL-2')\n",
        "fcl_dropout_2 = tflearn.layers.core.dropout(fc2, 0.8)\n",
        "#softmax layer output\n",
        "y_predicted = tflearn.layers.core.fully_connected(fcl_dropout_2, 2, activation='softmax', name='output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29a61792-3ea0-5980-2999-ef8c3d61addb"
      },
      "outputs": [],
      "source": [
        "#loss function\n",
        "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_predicted+np.exp(-10)), reduction_indices=[1]))\n",
        "#optimiser -\n",
        "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
        "#calculating accuracy of our model \n",
        "correct_prediction = tf.equal(tf.argmax(y_predicted,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7236c3f7-2764-92d9-a114-c94d323552fc"
      },
      "outputs": [],
      "source": [
        "# session parameters\n",
        "sess = tf.InteractiveSession()\n",
        "#initialising variables\n",
        "init = tf.initialize_all_variables()\n",
        "sess.run(init)\n",
        "saver = tf.train.Saver()\n",
        "save_path=\"/Users/Enkay/Documents/Viky/python/img-classification/mark2.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ab61ea3-7396-c45c-213f-87b753b6cfa8"
      },
      "outputs": [],
      "source": [
        "# grabbing the default graph\n",
        "g = tf.get_default_graph()\n",
        "\n",
        "# every operations in our graph\n",
        "[op.name for op in g.get_operations()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8363d9c7-8b22-485c-6600-609f1f1d8ec3"
      },
      "outputs": [],
      "source": [
        "epoch=5000\n",
        "#change batch size according to your hardware's power. For GPU's use batch size in powers of 2 like 2,4,8,16...\n",
        "batch_size=20 \n",
        "previous_batch=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "445913b7-72d2-d46a-f7cf-760e0b31b49d"
      },
      "outputs": [],
      "source": [
        "for i in range(epoch):\n",
        "    #batch wise training \n",
        "    if previous_batch >= len(X_train) : #total --> total number of training images\n",
        "        previous_batch=0    \n",
        "    current_batch=previous_batch+batch_size\n",
        "    x_input=X_train[previous_batch:current_batch]\n",
        "    x_images=np.reshape(x_input,[batch_size,56,56,3])\n",
        "    y_input=Y_train[previous_batch:current_batch]\n",
        "    y_label=np.reshape(y_input,[batch_size,2])\n",
        "    previous_batch=previous_batch+batch_size\n",
        "    _,loss=sess.run([train_step, cross_entropy], feed_dict={x: x_images,y_: y_label}) \n",
        "    if i%500==0:\n",
        "        n=50 #number of test samples\n",
        "        # increase the number of test samples with higher RAM. if you have less RAM, limit your test sample or \n",
        "        # run test accross larger samples once in every 1000 epochs or so..  \n",
        "        x_test_images=np.reshape(X_test[0:n],[n,56,56,3])\n",
        "        y_test_labels=np.reshape(Y_test[0:n],[n,2])\n",
        "        Accuracy=sess.run(accuracy,\n",
        "                           feed_dict={\n",
        "                        x: x_test_images ,\n",
        "                        y_: y_test_labels\n",
        "                      })\n",
        "        print \"Iteration no :{} , Accuracy:{} , Loss : {}\" .format(i,Accuracy,loss)\n",
        "        saver.save(sess, save_path, global_step = i)\n",
        "    elif i % 100 ==0:   \n",
        "        print \"Iteration no :{} Loss : {}\" .format(i,loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a1759563-b6df-93bd-312c-3704bd42872c"
      },
      "outputs": [],
      "source": [
        "x_input=X_val\n",
        "x_images=np.reshape(x_input,[len(X_val),56,56,3])\n",
        "y_input=Y_val\n",
        "y_label=np.reshape(y_input,[len(Y_val),2])\n",
        "\n",
        "Accuracy_validation=sess.run(accuracy,\n",
        "                           feed_dict={\n",
        "                        x: x_images ,\n",
        "                        y_: y_label\n",
        "                      })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9de64d1a-e367-b897-a8f5-35835449638e"
      },
      "outputs": [],
      "source": [
        "Accuracy_validation=round(Accuracy_validation*100,2)\n",
        "print \"Accuracy in the validation dataset: {} %\" .format(Accuracy_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f12a943-0e3a-6adb-087e-f4b3e9e95862"
      },
      "outputs": [],
      "source": [
        "def process_img(img):\n",
        "        img=img.resize((56, 56), Image.ANTIALIAS) #resize the image\n",
        "        img = np.array(img)\n",
        "        img=img/np.max(img).astype(float) \n",
        "        img=np.reshape(img, [1,56,56,3])\n",
        "        return img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "238332f6-6ce6-abe0-a5a3-4bef9c8ee5d1"
      },
      "outputs": [],
      "source": [
        "#test your own images \n",
        "test_image=Image.open('/path to file')\n",
        "test_image= process_img(test_image)\n",
        "predicted_array= sess.run(y_predicted, feed_dict={x: test_image})\n",
        "predicted_class= np.argmax(predicted_array)\n",
        "if predicted_class==0:\n",
        "    print \"It is a cat\"  \n",
        "else :\n",
        "    print \"It is a dog  \""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}