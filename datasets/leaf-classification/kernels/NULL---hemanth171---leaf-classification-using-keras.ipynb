{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d4073b27-40a6-cc77-9e4c-fe80bc33512d"
      },
      "source": [
        "**<h1>LEAF CLASSIFICATION</h1>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d9a8f8d-334c-e289-4a03-a9284d883e75"
      },
      "outputs": [],
      "source": [
        "# Package Imports\n",
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Keras stuff\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "root = '../input'\n",
        "np.random.seed(2016)\n",
        "split_random_state = 7\n",
        "split = .9\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "# from subprocess import check_output\n",
        "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c9c1911-0665-511a-7dd6-d5f7167fcab3"
      },
      "outputs": [],
      "source": [
        "def load_numeric_training(standardize=True):\n",
        "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
        "    ID = data.pop('id')\n",
        "\n",
        "    y = data.pop('species')\n",
        "    y = LabelEncoder().fit(y).transform(y)\n",
        "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
        "    return ID, X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f4c83291-6599-4779-27b9-991f0acf6ca7"
      },
      "outputs": [],
      "source": [
        "def load_numeric_test(standardize=True):\n",
        "    test_data = pd.read_csv(os.path.join(root, 'test.csv'))\n",
        "    ID = data.pop('id')\n",
        "\n",
        "    test = StandardScaler().fit(test_data).transform(test_data) if standardize else test_data.values\n",
        "    return ID, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "444a5165-32b3-8514-c708-d3561c3d2589"
      },
      "outputs": [],
      "source": [
        "def resize_img(img, max_dim=96):\n",
        "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
        "    scale = max_dim / float(img.size[max_ax])\n",
        "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f0b119b-fb0e-0027-5ae7-347e0a3bfd46"
      },
      "outputs": [],
      "source": [
        "# Original Image\n",
        "original_image = load_img(os.path.join(root, 'images', '1'+'.jpg'), grayscale=True)\n",
        "plt.imshow(original_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ceec7b91-ae03-98f3-6b3e-101e7013dbdd"
      },
      "outputs": [],
      "source": [
        "# Resized Image\n",
        "plt.imshow(resize_img(original_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f34cdaac-c264-612d-f497-79922552041a"
      },
      "outputs": [],
      "source": [
        "def load_image_data(ids, max_dim=96, center=True):\n",
        "    X = np.zeros((len(ids), max_dim, max_dim, 1))\n",
        "    for i, ide in enumerate(ids):\n",
        "        x = resize_img(load_img(os.path.join(root, 'images', str(ide)+'.jpg'), grayscale=True), max_dim=max_dim)\n",
        "        x = img_to_array(x)\n",
        "        \n",
        "        length = x.shape[0]\n",
        "        width = x.shape[1]\n",
        "        \n",
        "        if center:\n",
        "            h1 = int((max_dim - length) / 2)\n",
        "            h2 = h1 + length\n",
        "            w1 = int((max_dim - width) / 2)\n",
        "            w2 = w1 + width\n",
        "        else:\n",
        "            h1, w1 = 0, 0\n",
        "            h2, w2 = (length, width)\n",
        "            \n",
        "        X[i, h1:h2, w1:w2, 0:1] = x\n",
        "        \n",
        "    return np.around(X / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "140c7c47-d4fe-e485-19f2-b1dc41c12ebe"
      },
      "outputs": [],
      "source": [
        "def load_train_data(split=split, random_state=None):\n",
        "    # Load the pre-extracted features\n",
        "    ID, X_num_tr, y = load_numeric_training()\n",
        "    # Load the image data\n",
        "    X_img_tr = load_image_data(ID)\n",
        "    # Split them into validation and cross-validation\n",
        "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
        "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
        "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
        "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
        "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "28c7b4da-2183-5a9f-37d9-fc197b750f74"
      },
      "outputs": [],
      "source": [
        "def load_test_data():\n",
        "    # Load the pre-extracted features\n",
        "    ID, X_num_te = load_numeric_test()\n",
        "    # Load the image data\n",
        "    X_img_te = load_image_data(ID)\n",
        "    return ID, X_num_te, X_img_te"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5c343429-b0c4-6425-963e-9b8b4aed9b4a"
      },
      "outputs": [],
      "source": [
        "print('Loading the training data...')\n",
        "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
        "y_tr_cat = to_categorical(y_tr)\n",
        "y_val_cat = to_categorical(y_val)\n",
        "print('Training data loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "432f3f5f-1c49-083d-a352-eaf50c56145a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}