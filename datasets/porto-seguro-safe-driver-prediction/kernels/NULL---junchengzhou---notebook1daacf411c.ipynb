{"nbformat": 4, "cells": [{"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "76746263-0920-470a-a5fe-3a97bb7fe0e3", "collapsed": true, "_uuid": "e8904ac8f1c09bf420c2a220b5bf8dbde9e78115"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../working\"]).decode(\"utf8\"))\n", "aaa = pd.read_csv('../working/cat_predicts.csv', sep=',')\n", "aaa.head()\n", "# Any results you write to the current directory are saved as output."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "dfa09bab-0455-40c5-883d-b0df811f7c14", "_uuid": "e62ba992f61bf2e54c30e8710048087d54891505"}, "source": ["from sklearn import datasets\n", "from sklearn.utils import check_array\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.base import ClassifierMixin\n", "from collections import Counter\n", "from sklearn.feature_selection import VarianceThreshold\n", "from scipy.stats import pearsonr\n", "from sklearn.feature_selection import RFE\n", "from sklearn.cross_validation import KFold\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.ensemble import ExtraTreesRegressor\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.metrics import mean_squared_error, make_scorer\n", "from sklearn.ensemble import AdaBoostClassifier\n", "from xgboost import XGBRegressor\n", "import matplotlib.pyplot as plt\n", "from sklearn.datasets import make_classification\n", "from sklearn.decomposition import PCA\n", "from imblearn.over_sampling import RandomOverSampler\n", "import xgboost as xgb\n", "import seaborn as sns\n", "from sklearn.grid_search import GridSearchCV\n", "from sklearn.linear_model import SGDClassifier\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.linear_model import PassiveAggressiveClassifier\n", "from sklearn.feature_selection import SelectFromModel\n", "from sklearn.metrics import f1_score\n", "from sklearn.metrics import matthews_corrcoef\n", "from collections import Counter\n", "import itertools\n", "from sklearn.datasets import load_iris\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.ensemble import BaggingClassifier\n", "from sklearn.metrics import confusion_matrix\n", "from imblearn.datasets import make_imbalance\n", "from imblearn.ensemble import BalancedBaggingClassifier\n", "from imblearn.metrics import classification_report_imbalanced\n", "from sklearn import pipeline, metrics, grid_search\n", "from sklearn.feature_selection import SelectFromModel\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "cb563564-cdf7-44ea-a853-16617b49ede9", "collapsed": true, "_uuid": "6355bcb2083a52de93b05d1517805b07266a4b3a"}, "source": ["def gini(solution, submission):\n", "    df = zip(solution, submission, range(len(solution)))\n", "    df = sorted(df, key=lambda x: (x[1],-x[2]), reverse=True)\n", "    rand = [float(i+1)/float(len(df)) for i in range(len(df))]\n", "    totalPos = float(sum([x[0] for x in df]))\n", "    cumPosFound = [df[0][0]]\n", "    for i in range(1,len(df)):\n", "        cumPosFound.append(cumPosFound[len(cumPosFound)-1] + df[i][0])\n", "    Lorentz = [float(x)/totalPos for x in cumPosFound]\n", "    Gini = [Lorentz[i]-rand[i] for i in range(len(df))]\n", "    return sum(Gini)\n", "\n", "def normalized_gini(solution, submission):\n", "    normalized_gini = gini(solution, submission)/gini(solution, solution)\n", "    return normalized_gini\n", "gini_scorer = metrics.make_scorer(normalized_gini, greater_is_better = True)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "f4ce16be-e2a3-4fe1-a7f9-32cfb8219dab", "collapsed": true, "_uuid": "c8fe31520356a8fbffcfcb6e3988dbe3cf8a80ee"}, "source": ["trainDF = pd.read_csv('../input/kaggle-seguro/train/train.csv', sep=',')\n", "testDF = pd.read_csv('../input/dataset/test/test.csv', sep=',')\n", "target = trainDF.pop('target')"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5c5ff5e3-73ce-4c89-a90b-3bcf0a702859", "collapsed": true, "_uuid": "829c9fb28d6869d3dac6f0086a54acf0e208e20c"}, "source": ["plt.figure(figsize=(10,3))\n", "sns.countplot(trainDF['target'],palette='rainbow')\n", "plt.xlabel('Target')\n", "trainDF['target'].value_counts()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "78080484-a253-4751-99cd-85069c4d5ea8", "collapsed": true, "_uuid": "41993f013dee9c0c39fe54b9b6b9dfe1fd163402"}, "source": ["cor = trainDF.corr()\n", "plt.figure(figsize=(16,10))\n", "sns.heatmap(cor)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6b1d77ad-be39-4c64-b346-1dc1a9971d19", "collapsed": true, "_uuid": "3a846d1cf886d1c33e9387eababd803c5e24ede4"}, "source": ["ps_cal = trainDF.columns[trainDF.columns.str.startswith('ps_calc')] "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3e51a7d6-77de-466e-b3a7-e2348012753d", "collapsed": true, "_uuid": "9d6fefdaac437adbe183006c2b97203ffb04943e"}, "source": ["id_test = testDF['id'].values\n", "trainDF = trainDF.drop(ps_cal,axis =1)\n", "trainDF = trainDF.drop(['id'],axis =1)\n", "testDF = testDF.drop(ps_cal,axis =1)\n", "testDF = testDF.drop(['id'],axis =1)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "a5916b77-0f47-422f-bb39-b3d337b64403", "collapsed": true, "_uuid": "eaf936d41b018257d1f4796cc3e5388a6207529c"}, "source": ["cor = trainDF.corr()\n", "plt.figure(figsize=(16,10))\n", "sns.heatmap(cor)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6e41e511-8d8d-4e77-a021-f6eed8ed31d4", "collapsed": true, "_uuid": "515de4e6d5f5a7635e891aa07a85c190e8d5391a"}, "source": ["# def missing_value(df):\n", "#     col = df.columns\n", "#     for i in col:\n", "#         if df[i].isnull().sum()>0:\n", "#             df[i].fillna(df[i].mode()[0],inplace=True)\n", "# missing_value(trainDF)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "ee65aed2-0057-43fe-b16c-0023aa8562d9", "collapsed": true, "_uuid": "64a9d1c9f23d0c1cf6254284baa69c2be0858daa"}, "source": ["trainDF = trainDF.fillna(999)\n", "testDF = testDF.fillna(999)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7672b398-a895-49a0-b61a-9bc702cb79d4", "collapsed": true, "_uuid": "a30a512dd80f9cef766f06c1cc07c4b8f16eb94a"}, "source": ["for c in trainDF.select_dtypes(include=['float64']).columns:\n", "    trainDF[c]=trainDF[c].astype(np.float32)\n", "    testDF[c]=testDF[c].astype(np.float32)\n", "for c in trainDF.select_dtypes(include=['int64']).columns[2:]:\n", "    trainDF[c]=trainDF[c].astype(np.int8)\n", "    testDF[c]=testDF[c].astype(np.int8)  "]}, {"cell_type": "markdown", "source": ["\u6539\u53d8\u53d8\u91cf\u7c7b\u578b"], "metadata": {"_cell_guid": "0377d760-ea66-40da-a9f5-4eb5a8c53c87", "_uuid": "945c2723feee3066528c62d1eb9cf1228d4a605b"}}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "58c565a1-4683-4523-8df0-87ae7b15caee", "_uuid": "ac995339aa52a612e28d19620e918a822bdc9457"}, "source": ["from catboost import CatBoostClassifier, Pool\n", "y_train = target.values\n", "x_train = trainDF\n", "x_test = testDF\n", "\n", "train_data = Pool(x_train, y_train)\n", "test_data = Pool(x_test)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3e433e1c-3d48-4c78-8956-2dd920cfddb7", "_uuid": "b0d4e1f68dc907908006db84a1393c89e66f2789"}, "source": ["props = {\n", "        \tleaf_estimation_method ='Newton',\n", "        \tlearning_rate=0.057,\n", "          \tl2_leaf_reg = 23,\n", "          \tdepth=6,\n", "          \tod_pval=0.0000001,\n", "          \titerations = 877,\n", "          \tloss_function='Logloss'\n", "          \n", "        }"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6938b5fa-5b51-485d-903a-3e8d8a12888d", "_uuid": "2ed0958187b2aefc8731952a5562f7bfd1805b32"}, "source": ["from tqdm import tqdm\n", "print('Starting the loop...')\n", "num_ensembles = 6\n", "y_pred = 0.0\n", "for i in tqdm(range(num_ensembles)):\n", "    model = CatBoostClassifier(random_seed = i+200, gradient_iterations = i+1 ,leaf_estimation_method ='Newton', learning_rate=0.057, l2_leaf_reg = 23, depth=6, od_pval=0.0000001, iterations = 877, loss_function='Logloss')\n", "    fit_model = model.fit(train_data)\n", "    y_pred +=  fit_model.predict_proba(test_data)[:,1]\n", "y_pred /= num_ensembles\n", "gc.collect()\n", "\n", "\n", "# Create a submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = id_test\n", "sub['target'] = y_pred\n", "sub.to_csv('cat_predicts.csv', index=False)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5ff07e56-695a-426b-9889-98b04f1b243e", "_uuid": "68502d20848bcb272c9f46b56ba10469994a7ede"}, "source": ["print('done')"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "4aa07485-f8c7-435c-9058-66382575c93d", "collapsed": true, "_uuid": "804d7668a0f561c6a8197d1f2adcd2aa3752bda9"}, "source": ["cat_col = [col for col in trainDF.columns if '_cat' in col]\n", "print(cat_col)\n", "for c in cat_col:\n", "    trainDF[c] = trainDF[c].astype('uint8')\n", "#     test[c] = test[c].astype('uint8') "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "ae583c35-2083-43d8-9917-39e2db753471", "collapsed": true, "_uuid": "1d4fe89f9f1958f6c1593b93390bf20f3800f34e"}, "source": ["bin_col = [col for col in trainDF.columns if 'bin' in col]\n", "print(bin_col)\n", "for c in bin_col:\n", "    trainDF[c] = trainDF[c].astype('uint8')\n", "#     test[c] = test[c].astype('uint8') "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "84bd8aa8-3ee2-4358-aca9-c82a8c7b7bc0", "collapsed": true, "_uuid": "9534476dd3f31b6118b21051061b257e78584afe"}, "source": ["train_X = trainDF.loc[:,trainDF.columns[:len(trainDF.columns)-1]]\n", "train_y = trainDF.loc[:,['target']].values.ravel()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "fcdd716e-64fb-4efc-b4aa-0f5019fb155c", "collapsed": true, "_uuid": "472b409847ba1a41f9ed38bc178e379a1ff5f3e4"}, "source": ["model = GradientBoostingClassifier(n_estimators=200)\n", "score = cross_val_score(model,train_X,train_y,cv=5, scoring=\"accuracy\")\n", "print(score.mean())"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "5978f3f6-8df5-44dd-86ce-ac3ee62bb08b", "collapsed": true, "_uuid": "10015f8631d647573123b75a3262ff18cfa2b737"}, "source": ["def runXGB(xtrain,xvalid,ytrain,yvalid,xtest,eta=0.1,num_rounds=100,max_depth=4):\n", "    params = {\n", "        'objective':'binary:logistic',        \n", "        'max_depth':max_depth,\n", "        'learning_rate':eta,\n", "        'eval_metric':'auc',\n", "        'min_child_weight':6,\n", "        'subsample':0.8,\n", "        'colsample_bytree':0.8,\n", "        'seed':seed,\n", "        'reg_lambda':1.3,\n", "        'reg_alpha':8,\n", "        'gamma':10,\n", "        'scale_pos_weight':1.6\n", "        #'n_thread':-1\n", "    }\n", "    \n", "    dtrain = xgb.DMatrix(xtrain,label=ytrain)\n", "    dvalid = xgb.DMatrix(xvalid,label=yvalid)\n", "    dtest = xgb.DMatrix(xtest)\n", "    watchlist = [(dtrain,'train'),(dvalid,'test')]\n", "    \n", "    model = xgb.train(params,dtrain,num_rounds,watchlist,early_stopping_rounds=50,verbose_eval=50)\n", "    pred = model.predict(dvalid,ntree_limit=model.best_ntree_limit)\n", "    pred_test = model.predict(dtest,ntree_limit=model.best_ntree_limit)\n", "    return pred_test,model\n", "    "]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "8f699d97-16e4-49bb-875e-a2d2e18206ae", "collapsed": true, "_uuid": "9b2641cbf7c5b97aede0dcadd2898b6c76975b3c"}, "source": ["from catboost import CatBoostClassifier, Pool\n", "from tqdm import tqdm\n", "train_data = Pool(train_X, train_y)\n", "test_data = Pool(train_X)\n", "num_ensembles = 6\n", "y_pred = 0.0\n", "for i in tqdm(range(num_ensembles)):\n", "    model = CatBoostClassifier(random_seed = i+200, gradient_iterations = i+1 ,leaf_estimation_method ='Newton', learning_rate=0.057, l2_leaf_reg = 23, depth=6, od_pval=0.0000001, iterations = 877, loss_function='Logloss')\n", "    fit_model = model.fit(train_data)\n", "    y_pred +=  fit_model.predict_proba(test_data)[:,1]\n", "y_pred /= num_ensembles\n", "gc.collect()\n", "# Create a submission file\n", "sub = pd.DataFrame()\n", "sub['id'] = id_test\n", "sub['target'] = y_pred\n", "sub.to_csv('cat_predicts.csv', index=False)"]}], "metadata": {"language_info": {"name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "file_extension": ".py", "version": "3.6.3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1}