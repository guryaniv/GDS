{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9980f51f014caba434b5d6dbbf29e2894bccdc5","collapsed":true},"cell_type":"code","source":"# Check if GPU is avialable\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n  raise SystemError('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense , Dropout , Lambda, Flatten, Conv2D\nfrom tensorflow.python.keras.optimizers import Adam ,RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras import backend as K\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f193d861ebf0299e9593253ce24e1c28d0a4d00","collapsed":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5dcfb68bf1617f028f903b340ca9169acf87e7f","collapsed":true},"cell_type":"code","source":"test= pd.read_csv(\"../input/test.csv\")\nprint(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"961c033753062c7037de2c6e1a3374401e5b9ef3","collapsed":true},"cell_type":"code","source":"X = train.iloc[:,1:].values.astype('float32') # all pixel values\ny = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\nX_test = test.values.astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"20b9d48184dd92436af3b901bf6061bdf464ee5d","collapsed":true},"cell_type":"code","source":"# apply one hot encoding for label\n\nfrom keras.utils.np_utils import to_categorical\ny = to_categorical(y)\nnum_classes = y.shape[1]\nnum_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a72738f6ff67fe6d76bafc4d63d11e0a432a941","collapsed":true},"cell_type":"code","source":"#Convert train datset to (num_images, img_rows, img_cols, colour channel) format \nX = X.reshape(X.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72d5b9f1d7b66d076cee011ed76f09d7dd8dc3c0","collapsed":true},"cell_type":"code","source":"# split initial to train and validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d4ddde19beff6612084c82004a2b48a3828ca95","collapsed":true},"cell_type":"code","source":"#Fit the model using Data Augemnetation, will improve accuracy of the model\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\ndata_generator_with_aug = ImageDataGenerator(rotation_range=8,\n                                             width_shift_range = 0.08,\n                                             height_shift_range = 0.08)\n            \ndata_generator_no_aug = ImageDataGenerator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ba6af85ccce293a5d80f028f1eb27dd28c26974","collapsed":true},"cell_type":"code","source":"# apply data augementation to train and validation datasete\n\ntrain_generator = data_generator_with_aug.flow(X_train, y_train,batch_size=64)\n\nvalidation_generator = data_generator_no_aug.flow(X_val, y_val, batch_size=64)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5902d7c883f2664d2837e90c7a4af4cf1d337642"},"cell_type":"markdown","source":"Specify the Model\n\nCreate a Sequential model. \nAdd 3 Conv2D layers to fashion_model. Make each layer have 12 filters, a kernel_size of 3 and a relu activation. You will need to specify the input_shape for the first Conv2D layer. The input shape in this case is (img_rows, img_cols, 1).\nAdd a Flatten layer to model after the last Conv2D layer.\nAdd a Dense layer with 100 neurons to model after the Flatten layer.\nAdd your prediction layer to model. This is a Dense layer. We alrady have a variable called num_classes. Use this variable when specifying the number of nodes in this layer. The activation should be softmax (or you will have problems later)."},{"metadata":{"trusted":true,"_uuid":"db814b3ecc75f9f3d32d682a48c726123d119920","collapsed":true},"cell_type":"code","source":"# Strides as an option to MaxPooling\n# Dropout to combat overfitting\n\ndigit_model = Sequential()\ndigit_model.add(Conv2D(24, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Conv2D(24, kernel_size=(3, 3), strides=2, activation='relu'))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Conv2D(24, kernel_size=(3, 3), strides=2, activation='relu'))\ndigit_model.add(Dropout(0.5))\ndigit_model.add(Flatten())\ndigit_model.add(Dense(128, activation='relu'))\ndigit_model.add(Dense(num_classes, activation='softmax'))\nprint(\"input shape \",digit_model.input_shape)\nprint(\"output shape \",digit_model.output_shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"278c1941c042fbd85c32871deaa6b54254e42de9"},"cell_type":"markdown","source":"#### Compile Model"},{"metadata":{"trusted":true,"_uuid":"dc36bd7ff590060e3722ab52d73953de245d0799","collapsed":true},"cell_type":"code","source":"# Your code to compile the model in this cell\ndigit_model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a26b8cfa0e0d43e7ea067266abde8952d5cd4891"},"cell_type":"markdown","source":"#### Fit Model\n\nRun the command fashion_model.fit. The arguments you will use are\n\nThe first two are arguments are the data used to fit the model, which are x and y respectively.\nbatch_size = 100\nepochs = 4\nvalidation_split = 0.2\nWhen you run this command, you can watch your model start improving. You will see validation accuracies after each epoch."},{"metadata":{"trusted":true,"_uuid":"da54bf575c6e309ad50ec7e96efeb45925602c03","collapsed":true},"cell_type":"code","source":"# Your code to fit the model here\nwith tf.device(\"/device:GPU:0\"):\n    history = digit_model.fit_generator(\n        train_generator,\n        epochs=3,\n        validation_data=validation_generator,\n        validation_steps=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b057fbc393072e65319fe340e8dc13b42e6015bb","collapsed":true},"cell_type":"code","source":"import matplotlib.pylab as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\nplt.title('Training and validation accuracy')\nplt.plot(epochs, acc, 'red', label='Training acc')\nplt.plot(epochs, val_acc, 'blue', label='Validation acc')\nplt.legend()\n\nplt.figure()\nplt.title('Training and validation loss')\nplt.plot(epochs, loss, 'red', label='Training loss')\nplt.plot(epochs, val_loss, 'blue', label='Validation loss')\n\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26a51778b4580f471481044bf66faeff1b450c33"},"cell_type":"markdown","source":"#### Submission to Kaggle with full dataset"},{"metadata":{"trusted":true,"_uuid":"0a150c5b995c5e7954587634bee641c24a14fda9","collapsed":true},"cell_type":"code","source":"gen = ImageDataGenerator(rotation_range=8,\n                        width_shift_range = 0.08,\n                        height_shift_range = 0.08)\nbatches = gen.flow(X, y, batch_size=64)\nwith tf.device(\"/device:GPU:0\"):\n    history_subm=digit_model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fd71618400d680d36e22d0a9a2c8280ef8d4ed2","collapsed":true},"cell_type":"code","source":"predictions = digit_model.predict_classes(X_test, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"DigitRecognizer.csv\", index=False, header=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}