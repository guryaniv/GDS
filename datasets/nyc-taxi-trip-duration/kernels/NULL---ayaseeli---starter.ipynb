{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "name": "python", "file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.1", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}}}, "cells": [{"metadata": {"_uuid": "c6483e09607a81e0473342a04d822490101a9534"}, "outputs": [], "cell_type": "markdown", "source": "# Import Library\n> \n* pandas \n* numpy", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "4ad7c3e277bb94f65e55e33031cefc84c26bc4a8", "_cell_guid": "510c3ded-bbcc-471a-8214-378b72667c7f"}, "execution_count": null, "cell_type": "code", "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))", "outputs": []}, {"metadata": {"_uuid": "631256e53ca51209743d7d30f62cb210d4c53a00"}, "outputs": [], "cell_type": "markdown", "source": "* read csv\n* check if any missing value", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "401acb59c1995208b2cb66225a8a9dfca7e812a5"}, "execution_count": null, "cell_type": "code", "source": "raw = pd.read_csv(\"../input/train.csv\")\nraw.isnull().sum()", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "c1cc4d5a8d4249483d626ad7b63bf7b6c3b7c21a"}, "execution_count": null, "cell_type": "code", "source": "raw.head(5)", "outputs": []}, {"metadata": {"_uuid": "ac78d9b5cbe6bd7c2532328015ee1a2c8e349329"}, "outputs": [], "cell_type": "markdown", "source": "* compute trip duration from date time pick and drop", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "553cc74911cc777ca8dc408c77b82a661905bfaf"}, "execution_count": null, "cell_type": "code", "source": "from datetime import datetime\npickup = []\ndropoff = []\ndiffTrip = []\nfor i in range(raw.shape[0]):\n    pickup.append(datetime.strptime(raw[\"pickup_datetime\"][i], \"%Y-%m-%d %H:%M:%S\"))\n    dropoff.append(datetime.strptime(raw[\"dropoff_datetime\"][i], \"%Y-%m-%d %H:%M:%S\"))\n    diffTrip.append(dropoff[i] - pickup[i])", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "8362c452413bc1de286a89fcdc63b1c35cb38ec3"}, "execution_count": null, "cell_type": "code", "source": "val = diffTrip[0]\nval.seconds", "outputs": []}, {"metadata": {"trusted": true, "_uuid": "426cd1b6e53b6a34eb29a55fe068f879d541638f"}, "execution_count": null, "cell_type": "code", "source": "for i in range(len(diffTrip)):\n    diffTrip[i] = diffTrip[i].seconds\nse = pd.Series(diffTrip)\nraw['diffTrip'] = se.values\nraw.head(5)", "outputs": []}, {"metadata": {"_uuid": "c717f0be507342dd14c17970f566f5f1771891ee"}, "outputs": [], "cell_type": "markdown", "source": "## Select feature and label\n> \n* for feature, select only numerical data", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "86d1877f31f074728db082187f6eae64d9be0a8e"}, "execution_count": null, "cell_type": "code", "source": "x = raw.drop([\"id\", \"pickup_datetime\", \"store_and_fwd_flag\", \"dropoff_datetime\"],1)\ny = raw[\"trip_duration\"]", "outputs": []}, {"metadata": {"_uuid": "0109512fe8ea764b55a1e4abd566b4e05274e47a"}, "outputs": [], "cell_type": "markdown", "source": "## Make dummy for categorical features", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "4bb51f6af4aeac664419dcaad764f09d1eb53d84"}, "execution_count": null, "cell_type": "code", "source": "var_dummy = pd.get_dummies(raw[\"store_and_fwd_flag\"])\nx_catnum= pd.concat([x, var_dummy], axis = 1)\nx_catnum.head(5)", "outputs": []}, {"metadata": {"_uuid": "a4445f5c9517b1de9f58dce22b84bdbe514654ff"}, "outputs": [], "cell_type": "markdown", "source": "## Standardize data all column", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "f6ddceca26b05ba94cc332803cf0a0f91bee93c1"}, "execution_count": null, "cell_type": "code", "source": "X= x_catnum\nY= y\n# try normalize data, maybe improve accuration\nfrom sklearn.preprocessing import StandardScaler\n# get column name because we lose it after standarization\ndata_columns = X.columns\n# initiate standarscaler\nscaler = StandardScaler()\n# fitting and transform to dataframe feature data\n#X = scaler.fit_transform(X)\nscaler.fit(X)\nnormal_X = pd.DataFrame(scaler.transform(X))\n# get column name back\nnormal_X.columns = data_columns\n# check data after standardize\nnormal_X.head(5)", "outputs": []}, {"metadata": {"_uuid": "ee6848de45b9cd41ce741e02943abe9b5812d1c5"}, "outputs": [], "cell_type": "markdown", "source": "# Split data train and testing\n> \n* 20% of data for validation\n* random state is free any number", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "cb82fc9ef6d98528c7ce1efc745ccb293b6ab419", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": "# split data train and data testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\n  X,\n  Y,\n  test_size=0.2,\n  random_state = 42 )", "outputs": []}, {"metadata": {"_uuid": "e5d09da8ca574bfa542a943b7bd89239f814744b"}, "outputs": [], "cell_type": "markdown", "source": "# Training and testing\n> \n* define all regressor\n* fit with data train\n* predict and compute accuracy score\n* perform 10 cross validation to evaluate reggresor", "execution_count": null}, {"metadata": {"trusted": true, "_uuid": "c78fa6e84d37bb63bad9376ad63bb1c11bd231c1"}, "execution_count": null, "cell_type": "code", "source": "from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import RANSACRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n\nclassifiers = [\n    LinearRegression(),\n    Ridge(),\n    Lasso(),\n    RandomForestRegressor(n_jobs=-1),\n    DecisionTreeRegressor(),\n    RANSACRegressor(LinearRegression(), \n                     max_trials=100, \n                     min_samples=50, \n                     loss='absolute_loss', \n                     residual_threshold=5.0, \n                     random_state=0)]\n\n\n\nfor clf in classifiers:\n    \n    clf.fit(X_train, y_train)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('****Results****')\n    \n    ########################## perform split validation ######################\n    train_predictions = clf.predict(X_test)\n    rmse = np.sqrt( metrics.mean_squared_error( y_test, train_predictions ) )\n    print(\"RMSE: {}\".format(rmse))\n    ##########################################################################\n    \n    ########################## perform 10 fold validation ######################\n    kf = KFold(n_splits=10)\n    scorelist = []\n    for train_index, test_index in kf.split(X.values):\n        clf.fit(X.values[train_index], Y.values[train_index])\n        p = clf.predict(X.values[test_index])\n        RMSE = metrics.mean_squared_error(Y.values[test_index], p)**0.5\n        scorelist.append(rmse)\n    \n    print(\"MeanCVScore: {}\".format(sum(scorelist)/len(scorelist)))\n    print(\"10FoldCVScore: {}\".format(scorelist))\n    #############################################################################\n    \nprint(\"=\"*30)", "outputs": []}], "nbformat_minor": 1, "nbformat": 4}