{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/train.csv\")\ntest=pd.read_csv(\"../input/test.csv\")\ntest.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c81497afbe877e4caafef24326f37cd78fcce684","collapsed":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4439f1ba558b56c59291b018dc8d7a17e0a362b2","collapsed":true},"cell_type":"code","source":"test_ID=test['ID']\ny_train=train['target']\ny_train = np.log1p(y_train)\ntrain.drop(\"ID\",axis=1, inplace=True)\ntrain.drop(\"target\",axis=1,inplace=True)\ntest.drop(\"ID\",axis=1,inplace=True)\n\ncolsonevalue=train.columns[train.nunique()==1]\ntrain.drop(colsonevalue, axis=1, inplace=True)\ntest.drop(colsonevalue,axis=1,inplace=True)\n\nnum_decimals=32\ntrain=train.round(num_decimals)\ntest=test.round(num_decimals)\n\ncolsToRemove=[]\n#columns=train.columns\n#for i in range(len(columns)-1):\n#    v=train[columns[i]].values\n#    dupCols=[]\n#    for j in range (i+1, len(columns)):\n#        if np.array_equal(v, train[columns[j]].values):\n#            colsToRemove.append(columns[j])\n#train.drop(colsToRemove,axis=1, inplace=True)\n#test.drop(colsToRemove, axis=1, inplace=True)\n\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3c1afaa1622d72cdaea527c7d73a9933d5c3cd4c","collapsed":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn import ensemble\nnum_feat=1000\n\ndef rmsle(y,pred):\n    return np.sqrt(np.mean(np.power(y-pred,2)))\n\nx1,x2,y1,y2=model_selection.train_test_split(train, y_train.values, test_size=0.2, random_state=7)\nmodel=ensemble.RandomForestRegressor(n_jobs=-1,random_state=7)\nmodel.fit(x1,y1)\nprint(rmsle(y2, model.predict(x2)))\n\ncol=pd.DataFrame({'importance':model.feature_importances_,'feature':train.columns}).sort_values(by=['importance'],ascending=[False])[:num_feat]['feature'].values\ntrain=train[col]\ntest=test[col]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"151d96f89288fe13c93297889118b0b4b46e739c","collapsed":true},"cell_type":"code","source":"from scipy.stats import ks_2samp\nthreshold_pvalue=0.01\nthreshold_stat=0.3\ndiff_cols=[]\nfor col in train.columns:\n    statistic, pvalue=ks_2samp(train[col].values, test[col].values)\n    if pvalue<=threshold_pvalue and np.abs(statistic) > threshold_stat:\n        diff_cols.append(col)\nfor col in diff_cols:\n    if col in train_columns:\n        train.drop(col,axis=1, inplace=True)\n        test.drop(col,axis=1,inplace=True)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3f5b9e47d26daa9e3f85ad019773c7d25caafd6","collapsed":true},"cell_type":"code","source":"from sklearn import random_projection\nntrain = len(train)\nntest = len(test)\ntmp = pd.concat([train,test])#RandomProjection\nweight = ((train != 0).sum()/len(train)).values\ntmp_train = train[train!=0]\ntmp_test = test[test!=0]\ntrain[\"weight_count\"] = (tmp_train*weight).sum(axis=1)\ntest[\"weight_count\"] = (tmp_test*weight).sum(axis=1)\ntrain[\"count_not0\"] = (train != 0).sum(axis=1)\ntest[\"count_not0\"] = (test != 0).sum(axis=1)\ntrain[\"sum\"] = train.sum(axis=1)\ntest[\"sum\"] = test.sum(axis=1)\ntrain[\"var\"] = tmp_train.var(axis=1)\ntest[\"var\"] = tmp_test.var(axis=1)\ntrain[\"median\"] = tmp_train.median(axis=1)\ntest[\"median\"] = tmp_test.median(axis=1)\ntrain[\"mean\"] = tmp_train.mean(axis=1)\ntest[\"mean\"] = tmp_test.mean(axis=1)\ntrain[\"std\"] = tmp_train.std(axis=1)\ntest[\"std\"] = tmp_test.std(axis=1)\ntrain[\"max\"] = tmp_train.max(axis=1)\ntest[\"max\"] = tmp_test.max(axis=1)\ntrain[\"min\"] = tmp_train.min(axis=1)\ntest[\"min\"] = tmp_test.min(axis=1)\ntrain[\"skew\"] = tmp_train.skew(axis=1)\ntest[\"skew\"] = tmp_test.skew(axis=1)\ntrain[\"kurtosis\"] = tmp_train.kurtosis(axis=1)\ntest[\"kurtosis\"] = tmp_test.kurtosis(axis=1)\ndel(tmp_train)\ndel(tmp_test)\nNUM_OF_COM = 100 #need tuned\ntransformer = random_projection.SparseRandomProjection(n_components = NUM_OF_COM)\nRP = transformer.fit_transform(tmp)\nrp = pd.DataFrame(RP)\ncolumns = [\"RandomProjection{}\".format(i) for i in range(NUM_OF_COM)]\nrp.columns = columns\n\nrp_train = rp[:ntrain]\nrp_test = rp[ntrain:]\nrp_test.index = test.index\n\n#concat RandomProjection and raw data\ntrain = pd.concat([train,rp_train],axis=1)\ntest = pd.concat([test,rp_test],axis=1)\n\ndel(rp_train)\ndel(rp_test)\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0456134ccbe15859a9e9b2e88d9c568b4504b5d5"},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin,clone\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport lightgbm as lgb\nnum_folds=5\ndef rmsle_cv(model):\n    kf=KFold(num_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse=np.sqrt(-cross_val_score(model, train, y_train, scoring='neg_mean_squared_error',cv=kf))\n    return rmse\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, models):\n        self.models=models\n    \n    def fit(self,X,y):\n        self.models_=[clone(x) for x in self.models]\n        for model in self.models:\n            model.fit(X,y)\n        return self\n    def predict(self, X):\n        predictions=np.column_stack([model.predict(X) for model in self.models_ ])\n        return np.mean(predictions, axis=1)\n    \nmodel_xgb=xgb.XGBRegressor(colsample_bytree=0.055,colsample_bylevel=0.5,gamma=1.5,learning_rate=0.02, max_depth=32,objective='reg:linear',booster='gbtree',\n                             min_child_weight=57, n_estimators=1000, reg_alpha=0, \n                             reg_lambda = 0,eval_metric = 'rmse', subsample=0.7, \n                             silent=1, n_jobs = -1, early_stopping_rounds = 14,\n                             random_state =7, nthread = -1)\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=144,\n                              learning_rate=0.005, n_estimators=720, max_depth=13,\n                              metric='rmse',is_training_metric=True,\n                              max_bin = 55, bagging_fraction = 0.8,verbose=-1,\n                              bagging_freq = 5, feature_fraction = 0.9) \nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\naveraged_models = AveragingModels(models = (model_xgb, model_lgb))\nscore = rmsle_cv(averaged_models)\nprint(\"averaged score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fb86b4198be9785bff66376e0a406a695a3a2f87"},"cell_type":"code","source":"averaged_models.fit(train.values, y_train)\npred=np.expm1(average_models.predict(testvalues))\nensemble=pred\nsub=pd.Dataframe()\nsub['ID']=test_ID\nsub['target'] = ensemble\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}