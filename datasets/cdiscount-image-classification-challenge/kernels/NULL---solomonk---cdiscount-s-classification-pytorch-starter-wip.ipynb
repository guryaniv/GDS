{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["# Cdiscount\u2019s Image Classification Challenge PyTorch CNN starter (Work in progress)\n", "\n", "- Based on code adapted from here:\n", "https://www.kaggle.com/alekseit/pytorch-bson-dataset (All credist go to the respective writer https://www.kaggle.com/alekseit) \n", "\n", "- Hopefully will write a full CNN in the next few days. \n"], "metadata": {"_cell_guid": "497c29a8-3d40-4cb9-bf10-64d376ba6565", "_uuid": "299929789109c048acc48c17af1dcf6e7110aceb"}}, {"cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "% reset -f\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "import torch\n", "import sys\n", "import torch\n", "from torch.utils.data.dataset import Dataset\n", "from torch.utils.data import DataLoader\n", "from torchvision import transforms\n", "from torch import nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torch.autograd import Variable\n", "\n", "from sklearn import cross_validation\n", "from sklearn import metrics\n", "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n", "from sklearn.cross_validation import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n", "\n", "print('__Python VERSION:', sys.version)\n", "print('__pyTorch VERSION:', torch.__version__)\n", "\n", "import numpy\n", "import numpy as np\n", "\n", "use_cuda = torch.cuda.is_available()\n", "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n", "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n", "Tensor = FloatTensor\n", "\n", "import pandas\n", "import pandas as pd\n", "\n", "import logging\n", "handler=logging.basicConfig(level=logging.INFO)\n", "lgr = logging.getLogger(__name__)\n", "%matplotlib inline\n", "\n", "# !pip install psutil\n", "import psutil\n", "import os\n", "def cpuStats():\n", "        print(sys.version)\n", "        print(psutil.cpu_percent())\n", "        print(psutil.virtual_memory())  # physical memory usage\n", "        pid = os.getpid()\n", "        py = psutil.Process(pid)\n", "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n", "        print('memory GB:', memoryUse)\n", "\n", "cpuStats()"], "metadata": {"_cell_guid": "c892b663-9cff-4f1a-ba0f-d32c23a06647", "_uuid": "dcce8aea68523899f985475bae280e16dd005731"}, "outputs": [], "execution_count": 1}, {"cell_type": "code", "source": ["import os\n", "import pandas as pd\n", "import numpy as np\n", "import bson\n", "import cv2\n", "from tqdm import tqdm\n", "import struct\n", "from PIL import Image\n", "\n", "def imshow(img):\n", "    img = img / 2 + 0.5     # unnormalize\n", "    npimg = img.numpy()\n", "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n", "\n", "\n", "def flaotTensorToImage(img, mean=0, std=1):\n", "    \"\"\"convert a tensor to an image\"\"\"\n", "    img = np.transpose(img.numpy(), (1, 2, 0))\n", "    img = (img*std+ mean)*255\n", "    img = img.astype(np.uint8)    \n", "    return img    \n", "\n", "def toTensor(img):\n", "    \"\"\"convert a numpy array of shape HWC to CHW tensor\"\"\"\n", "    img = img.transpose((2, 0, 1)).astype(np.float32)\n", "    tensor = torch.from_numpy(img).float()\n", "    return tensor/255.0    "], "metadata": {"collapsed": true, "_cell_guid": "a03dd60c-dfcc-4f6d-ad03-46e0227490ec", "_uuid": "29cc5ba12c400a1c076e2803d14164c3fabc2210"}, "outputs": [], "execution_count": 2}, {"cell_type": "code", "source": ["def read_bson(bson_path, num_records, with_categories):\n", "    \"\"\"\n", "    Reads BSON\n", "    \"\"\"\n", "    rows = {}\n", "    with open(bson_path, \"rb\") as f, tqdm(total=num_records) as pbar:\n", "        offset = 0\n", "        records_read = 0 \n", "        while True:\n", "            item_length_bytes = f.read(4)\n", "            if len(item_length_bytes) == 0:\n", "                break\n", "            \n", "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n", "            f.seek(offset)\n", "            item_data = f.read(length)\n", "            assert len(item_data) == length\n", "\n", "            item = bson.BSON.decode(item_data)\n", "            product_id = item[\"_id\"]\n", "            num_imgs = len(item[\"imgs\"])\n", "\n", "            row = [num_imgs, offset, length]\n", "            if with_categories:\n", "                row += [item[\"category_id\"]]\n", "            rows[product_id] = row\n", "\n", "            offset += length\n", "            f.seek(offset)\n", "            records_read += 1\n", "            pbar.update()\n", "    pbar.close()\n", "    columns = [\"num_imgs\", \"offset\", \"length\"]\n", "    if with_categories:\n", "        columns += [\"category_id\"]\n", "\n", "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n", "    df.index.name = \"product_id\"\n", "    df.columns = columns\n", "    df.sort_index(inplace=True)\n", "    return df\n", "\n", "\n", "def make_category_tables(categories_path):\n", "    \"\"\"\n", "    Converts category name into an index [0, N-1]\n", "    \"\"\"\n", "    categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n", "    categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n", "    \n", "    print ('categories_df:' + str(categories_df.head()))\n", "    \n", "    cat2idx = {}\n", "    idx2cat = {}\n", "    for ir in categories_df.itertuples():\n", "        category_id = ir[0]\n", "        category_idx = ir[4]\n", "        cat2idx[category_id] = category_idx\n", "        idx2cat[category_idx] = category_id\n", "    print ('cat2idx:' + str(len(cat2idx)))\n", "    print ('idx2cat:' + str(len(idx2cat)))\n", "    return cat2idx, idx2cat\n", "\n", "def get_obs(fname, offset, length):\n", "    fobj = open(fname, 'rb')\n", "    fobj.seek(offset)\n", "    res = bson.BSON.decode(fobj.read(length))\n", "    fobj.close()\n", "    return res\n", "\n", "class CdiscountDataset(Dataset):\n", "    def __init__(self, dataset, split, transform):\n", "        self.dataset = dataset\n", "        self.metadata = split\n", "        self.transform = transform\n", "\n", "    def __getitem__(self, index):\n", "        entry = self.metadata.iloc[index]\n", "        num_imgs, offset, length, target = entry\n", "        obs = get_obs(self.dataset, offset, length)\n", "        keep = np.random.choice(len(obs['imgs']))\n", "        byte_str = obs['imgs'][keep]['picture']\n", "        img = cv2.imdecode(np.fromstring(byte_str, dtype=np.uint8), cv2.IMREAD_COLOR)\n", "\n", "        img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n", "        img = self.transform(img)\n", "\n", "        return img, target\n", "\n", "    def __len__(self):\n", "        return self.metadata.index.values.shape[0]\n", "\n", "batch_size = 16 # on GTX 1080\n", "global_epoches = 10\n", "LR = 0.0005\n", "MOMENTUM = 0.95\n", "validationRatio=0.11    \n"], "metadata": {"collapsed": true, "_cell_guid": "911b1aff-0b76-44bb-a79c-f77a140d640c", "_uuid": "e67345f5625af495fdedec810c65515f16fc7861"}, "outputs": [], "execution_count": 3}, {"cell_type": "code", "source": ["# if __name__ == \"__main__\":\n", "TRAIN_BSON_FILE = '../input/train.bson'\n", "CATEGS = '../input/category_names.csv'\n", "# Chenge this weh running on your machine\n", "N_TRAIN = 7069896\n", "BS = 32\n", "N_THREADS = 0\n", "\n", "# mapping the catigores into 0-5269 range\n", "cat2idx, idx2cat = make_category_tables(CATEGS)\n", "# print (cat2idx)\n", "# print (idx2cat)\n"], "metadata": {"_cell_guid": "60968603-bae4-45fc-9b38-abaa6ef5d978", "_uuid": "ec3c86dd6e8d05f13fcbd3161ba81cfcfae63351"}, "outputs": [], "execution_count": 4}, {"cell_type": "code", "source": ["#Scanning the metadata\n", "meta_data = read_bson(TRAIN_BSON_FILE, N_TRAIN, with_categories=True)\n", "meta_data.category_id = np.array([cat2idx[ind] for ind in meta_data.category_id])\n", "# meta_data = meta_data.iloc[np.arange(500)] # Remove this!!!\n", "# Dataset and loader\n", "transformations = transforms.Compose([transforms.ToTensor()])\n", "\n", "train_ds = CdiscountDataset(TRAIN_BSON_FILE, meta_data,transformations)\n", "train_loader = DataLoader(train_ds, batch_size=BS,num_workers=N_THREADS, shuffle=True)\n", "\n", "print(train_loader)\n", "\n", "# Let's go fetch some data!\n", "# pbar = tqdm(total=len(train_loader))\n", "# for i, (batch, target) in enumerate(loader):\n", "#     pass\n", "#     pbar.update()\n", "# pbar.close()\n", "\n"], "metadata": {"_cell_guid": "6c23f957-60ce-450d-be11-15428b5542f3", "_uuid": "19df11bb0c23fd818bde3e551e0a30ee0398981d"}, "outputs": [], "execution_count": 5}, {"cell_type": "code", "source": ["# https://github.com/Cognexa/cdiscount-kernel/blob/master/cdc/cdc_dataset.py\n", "def split(self):\n", "        \"\"\"\n", "        Split train data to train and validation sets and compute (category_id -> integer class) mapping.\n", "        Run with `cxflow dataset split cdc`\n", "        :return:\n", "        \"\"\"\n", "        # read example headers\n", "        logging.info('Reading examples metadata, this may take a minute or two')\n", "        ids = []\n", "        categories = []\n", "        for example in bson.decode_file_iter(open(path.join(self._data_root, self.TRAIN_FILE), 'rb')):\n", "            ids.append(example['_id'])\n", "            categories.append(example['category_id'])\n", "\n", "        # generate random split\n", "        size = len(ids)\n", "        train_size = int(size*(1-self._valid_percent))\n", "        valid_size = (size-train_size)\n", "        split = ['train']*train_size + ['valid']*valid_size\n", "        random.shuffle(split)\n", "\n", "        # save split\n", "        split_df = pd.DataFrame({'id': ids, 'split': split})\n", "        split_path = path.join(self._data_root, self._split_file)\n", "        split_df.to_csv(split_path, index=False)\n", "        logging.info('Split train-valid of size %s-%s was written to `%s`', train_size, valid_size, split_path)\n", "\n", "        # save (category_id -> integer class) mapping\n", "        categories = sorted(list(set(categories)))\n", "        categories_df = pd.DataFrame({'category_id': categories, 'class': list(range(len(categories)))})\n", "        categories_path = path.join(self._data_root, self.CATEGORIES_FILE)\n", "        categories_df.to_csv(categories_path, index=False)\n", "        logging.info('Categories mapping saved to `{}`'.format(categories_path))"], "metadata": {"collapsed": true}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "\n", "imagesToShow=4\n", "\n", "for i, data in enumerate(train_loader, 0):\n", "    lgr.info('i=%d: '%(i))            \n", "    images, labels = data            \n", "    num = len(images)\n", "\n", "    ax = plt.subplot(1, imagesToShow, i + 1)\n", "    plt.tight_layout()\n", "    ax.set_title('Sample #{}'.format(i))\n", "    ax.axis('off')\n", "\n", "    for n in range(num):\n", "        image=images[n]\n", "        label=labels[n]\n", "#         print ('Label(s):' + str(label))\n", "        plt.imshow (flaotTensorToImage(image))\n", "\n", "    if i==imagesToShow-1:\n", "        break    \n"], "metadata": {"_cell_guid": "38f50b9d-c0eb-4c65-8ce3-8b14cdb7efa6", "_uuid": "e3e4052cca2d696876826d285a30f46640c92301"}, "outputs": [], "execution_count": 6}, {"cell_type": "code", "source": ["class FullTrainningDataset(torch.utils.data.Dataset):\n", "    def __init__(self, full_ds, offset, length):\n", "        self.full_ds = full_ds\n", "        self.offset = offset\n", "        self.length = length\n", "        assert len(full_ds)>=offset+length, Exception(\"Parent Dataset not long enough\")\n", "        super(FullTrainningDataset, self).__init__()\n", "        \n", "    def __len__(self):        \n", "        return self.length\n", "    \n", "    def __getitem__(self, i):\n", "        # label = torch.from_numpy(self.y_train[index])\n", "        return self.full_ds[i+self.offset]\n", "    \n", "validationRatio=0.11    \n", "\n", "def trainTestSplit(dataset, val_share=validationRatio):\n", "    val_offset = int(len(dataset)*(1-val_share))\n", "    print (\"Offest:\" + str(val_offset))\n", "    return FullTrainningDataset(dataset, 0, val_offset), FullTrainningDataset(dataset, \n", "                                                                              val_offset, len(dataset)-val_offset)"], "metadata": {"collapsed": true, "_cell_guid": "a932537e-6f40-40ba-9b42-708f0fd02f7a", "_uuid": "178ca2706bf6fedc000bf73ecbfa7cd6eb1ebfa3"}, "outputs": [], "execution_count": 7}, {"cell_type": "code", "source": ["from torch.utils.data import TensorDataset, DataLoader\n", "\n", "train_ds = CdiscountDataset(TRAIN_BSON_FILE, meta_data,transformations)\n", "train_loader = DataLoader(train_ds, batch_size=BS,num_workers=N_THREADS, shuffle=True)\n", "\n", "train_ds, val_ds = trainTestSplit(train_loader)\n", "\n", "t_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=False,\n", "                                            num_workers=0)\n", "v_loader = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n", "\n", "print (t_loader)\n", "print (v_loader)"], "metadata": {"_cell_guid": "69635ca0-6890-439e-b6e3-a1ec03a98624", "_uuid": "e66c6d3dee8b315ebc832ab830e49dc373d006b1"}, "outputs": [], "execution_count": 8}, {"cell_type": "code", "source": ["dropout = torch.nn.Dropout(p=0.50)\n", "relu=torch.nn.LeakyReLU()\n", "pool = nn.MaxPool2d(2, 2)\n", "\n", "class ConvRes(nn.Module):\n", "    def __init__(self,insize, outsize):\n", "        super(ConvRes, self).__init__()\n", "        drate = .3\n", "        self.math = nn.Sequential(\n", "                 nn.BatchNorm2d(insize),\n", "                 nn.Dropout(drate),\n", "                 torch.nn.Conv2d(insize, outsize, kernel_size=2,padding=2),\n", "                 nn.PReLU(),\n", "                )\n", "        \n", "    def forward(self, x):\n", "        return self.math(x) \n", "\n", "class ConvCNN(nn.Module):\n", "    def __init__(self,insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n", "        super(ConvCNN, self).__init__()\n", "        self.avg=avg\n", "        self.math = torch.nn.Sequential(\n", "            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size,padding=padding),\n", "            torch.nn.BatchNorm2d(outsize),\n", "            torch.nn.LeakyReLU(),\n", "            torch.nn.MaxPool2d(pool,pool),\n", "        )\n", "        self.avgpool=torch.nn.AvgPool2d(pool,pool)\n", "        \n", "    def forward(self, x):\n", "        x=self.math(x)\n", "        if self.avg is True:\n", "            x=self.avgpool(x)\n", "        return x   \n", "        \n", "class Net(nn.Module):\n", "    def __init__(self):\n", "        super(Net, self).__init__()        \n", "        \n", "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n", "        \n", "        self.cnn1 = ConvCNN (3,128,  kernel_size=7, pool=4, avg=False)\n", "        self.cnn2 = ConvCNN (128,128, kernel_size=5, pool=2, avg=True)        \n", "        \n", "        self.res1 = ConvRes (128,32)\n", "        \n", "        self.features = nn.Sequential( \n", "            self.cnn1,dropout,          \n", "            self.cnn2,            \n", "            self.res1,\n", "        )        \n", "        \n", "        self.classifier = torch.nn.Sequential(\n", "            nn.Linear(6272, 5270),             \n", "        )\n", "        self.sig=nn.Sigmoid()        \n", "            \n", "    def forward(self, x):\n", "        x = self.features(x) \n", "#         print (x.data.shape)\n", "        x = x.view(x.size(0), -1)      \n", "#         print (x.data.shape)\n", "        x = self.classifier(x)     \n", "#         print (x.data.shape)\n", "        x = F.log_softmax(x)\n", "        return x        \n", "\n", "model = Net()\n", "# print(model)"], "metadata": {"_cell_guid": "db464f28-90e2-4a2e-91fc-2bf8094804cf", "_uuid": "cacb555fa9fd56feb2531dcd8fbff1050be8da18"}, "outputs": [], "execution_count": 9}, {"cell_type": "code", "source": ["# loss_func=torch.nn.BCELoss() # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n", "# define loss function (criterion) and optimizer\n", "criterion = nn.CrossEntropyLoss()\n", "loss_func = criterion\n", "### Train\n", "\n", "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n", "\n", "LR = 0.0005\n", "MOMENTUM= 0.95\n", "num_epoches=10\n", "\n", "# optimizer = torch.optim.Adam(model.parameters(), lr=LR,weight_decay=5e-5) #  L2 regularization\n", "\n", "if use_cuda:\n", "    model.cuda()\n", "    loss_func.cuda()\n", "\n", "lgr.info (optimizer)\n", "lgr.info (loss_func)\n", "\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "import torch.optim as optim\n", "from torchvision import datasets, transforms\n", "from torch.autograd import Variable\n", "\n", "criterion = loss_func\n", "all_losses = []\n", "val_losses = []\n", "\n", "\n", "if __name__ == '__main__':\n", "\n", "    for epoch in range(num_epoches):\n", "        print('Epoch {}'.format(epoch + 1))\n", "        print('*' * 5 + ':')\n", "        running_loss = 0.0\n", "        running_acc = 0.0\n", "        for i, data in enumerate(train_loader, 1):\n", "\n", "            img, label = data\n", "            if use_cuda:\n", "                img, label = Variable(img.cuda(async=True)), Variable(label.cuda(async=True))  # On GPU\n", "            else:\n", "                img, label = Variable(img), Variable(\n", "                    label)  # RuntimeError: expected CPU tensor (got CUDA tensor)\n", "\n", "            out = model(img)\n", "            loss = criterion(out, label)\n", "            running_loss += loss.data[0] * label.size(0)\n", "\n", "            optimizer.zero_grad()\n", "            loss.backward()\n", "            optimizer.step()\n", "\n", "            if i % 10 == 0:\n", "                all_losses.append(running_loss / (batch_size * i))\n", "                print('[{}/{}] Loss: {:.6f}'.format(\n", "                    epoch + 1, num_epoches, running_loss / (batch_size * i),\n", "                    running_acc / (batch_size * i)))\n", "\n", "        print('Finish {} epoch, Loss: {:.6f}'.format(epoch + 1, running_loss / (len(train_ds))))\n", "\n", "    #     model.eval()\n", "    #     eval_loss = 0\n", "    #     eval_acc = 0\n", "    #     for data in v_loader:\n", "    #         img, label = data\n", "\n", "    #         if use_cuda:\n", "    #             img, label = Variable(img.cuda(async=True), volatile=True),\n", "    #             Variable(label.cuda(async=True), volatile=True)  # On GPU\n", "    #         else:\n", "    #             img = Variable(img, volatile=True)\n", "    #             label = Variable(label, volatile=True)\n", "\n", "    #         out = model(img)\n", "    #         loss = criterion(out, label)\n", "    #         eval_loss += loss.data[0] * label.size(0)\n", "\n", "    #     print('VALIDATION Loss: {:.6f}'.format(eval_loss / (len(val_ds))))\n", "    #     val_losses.append(eval_loss / (len(val_ds)))\n", "    #     print()\n"], "metadata": {"_cell_guid": "18f49f9f-14ac-470f-97e1-eb5601929a2d", "_uuid": "14aa5917c25b2cbeb2e9b1fa35b26c359644f0af"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": [], "metadata": {"collapsed": true, "_cell_guid": "298bd7bb-a5a0-448a-bd1d-46a60d8caed4", "_uuid": "5cffcca13ae6dbb1d8ce728b8fe8ea44eadffc7b"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": [], "metadata": {"collapsed": true, "_cell_guid": "535c37a0-60c4-4d61-b47d-7a987b31117b", "_uuid": "7bd89a7d0e68064b19dcf5aee25fae55984eaa0d"}, "outputs": [], "execution_count": null}], "metadata": {"language_info": {"pygments_lexer": "ipython3", "mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}}