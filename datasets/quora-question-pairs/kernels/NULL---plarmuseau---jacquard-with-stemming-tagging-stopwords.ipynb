{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e02e8c7f-532a-e0a0-36e9-93aaa08df4e2"
      },
      "source": [
        "source\n",
        "\n",
        "http://nbviewer.jupyter.org/urls/gist.github.com/mjbommar/e2a019e346b879c13d3d/raw/74a206c2629d6e661645e18369f05f6c79d15b65/fuzzy-sentence-matching-python.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9b397e8-8468-bd43-6220-c4b16b698237"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# timing function\n",
        "import time   \n",
        "start = time.clock() #_________________ measure efficiency timing\n",
        "\n",
        "# read data\n",
        "test = pd.read_csv('../input/test.csv',encoding='utf8')[:100]\n",
        "train = pd.read_csv('../input/train.csv',encoding='utf8')[:100]\n",
        "print(train.head(2))\n",
        "train.fillna(value='leeg',inplace=True)\n",
        "test.fillna(value='leeg',inplace=True)\n",
        "\n",
        "end = time.clock()\n",
        "print('open:',end-start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0ebb7b96-3ad3-8939-da9b-350741232483"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import nltk.corpus\n",
        "import nltk.stem.snowball\n",
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "\n",
        "# Get default English stopwords and extend with punctuation\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "stopwords.extend(string.punctuation)\n",
        "stopwords.append('')\n",
        "\n",
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag[1].startswith('J'):\n",
        "        return (pos_tag[0], wordnet.ADJ)\n",
        "    elif pos_tag[1].startswith('V'):\n",
        "        return (pos_tag[0], wordnet.VERB)\n",
        "    elif pos_tag[1].startswith('N'):\n",
        "        return (pos_tag[0], wordnet.NOUN)\n",
        "    elif pos_tag[1].startswith('R'):\n",
        "        return (pos_tag[0], wordnet.ADV)\n",
        "    else:\n",
        "        return (pos_tag[0], wordnet.NOUN)\n",
        "\n",
        "# Create tokenizer and stemmer\n",
        "\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def is_ci_partial_noun_set_token_stopword_lemma_match(a, b):\n",
        "    \"\"\"Check if a and b are matches.\"\"\"\n",
        "    \n",
        "    pos_a = map(get_wordnet_pos, nltk.pos_tag(a.lower().strip(string.punctuation).split()))\n",
        "    pos_b = map(get_wordnet_pos, nltk.pos_tag(b.lower().strip(string.punctuation).split()))\n",
        "    lemmae_a = [lemmatizer.lemmatize(token.lower().strip(string.punctuation), pos) for token, pos in pos_a if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n",
        "    lemmae_b = [lemmatizer.lemmatize(token.lower().strip(string.punctuation), pos) for token, pos in pos_b if pos == wordnet.NOUN and token.lower().strip(string.punctuation) not in stopwords]\n",
        "    q1=''.join(lemmae_a).split()\n",
        "    q2=''.join(lemmae_b).split()\n",
        "    # Calculate Jaccard similarity\n",
        "    ratio = len(set(lemmae_a).intersection(lemmae_b)) / float(len(set(lemmae_a).union(lemmae_b))+.001)\n",
        "    return (round(ratio,2))\n",
        "\n",
        "result=[]\n",
        "for xi in range(0,len(train)):\n",
        "    result.append(is_ci_partial_noun_set_token_stopword_lemma_match(train.iloc[xi]['question1'],train.iloc[xi]['question2']))\n",
        "\n",
        "train['jacq']=result\n",
        "print(train)\n",
        "end = time.clock()\n",
        "print('open:',end-start)\n",
        "print((end-start)/len(result))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}