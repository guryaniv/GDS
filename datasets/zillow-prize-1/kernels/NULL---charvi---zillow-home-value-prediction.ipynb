{"nbformat_minor": 1, "cells": [{"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "e67a6649-657f-4e39-bc95-bae76edc614f", "_uuid": "9a9ae7c5c22aa3fc23e138837f51e4083c72744d"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "import seaborn as sns\n", "from sklearn.preprocessing import LabelEncoder\n", "import gc\n", "from sklearn.linear_model import LinearRegression\n", "import random\n", "import datetime as dt\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import Dropout, BatchNormalization\n", "from keras.layers.advanced_activations import PReLU\n", "from keras.layers.noise import GaussianDropout\n", "from keras.optimizers import Adam\n", "from keras.wrappers.scikit_learn import KerasRegressor\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.preprocessing import Imputer\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "941abe54-d706-4325-b23e-f3c06e8c059a", "_uuid": "b7b7323ae18e5c47a712065fb861b71632e6cb8d"}, "source": ["df16 = pd.read_csv(\"../input/properties_2016.csv\")\n", "df17 = pd.read_csv(\"../input/properties_2017.csv\")\n", "train16 = pd.read_csv(\"../input/train_2016_v2.csv\")\n", "train17 = pd.read_csv(\"../input/train_2017.csv\")\n", "samplesub = pd.read_csv(\"../input/sample_submission.csv\")"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "dd4b164a-bba7-437c-a57e-7769cad042c6", "_uuid": "ff4c560ea3dd85140aa9d4a0706e64bcc08eff39"}, "source": ["df16.head()"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "6f20c18d-d283-4060-b7a7-ec32d5a5da71", "_uuid": "364bac9b626bc1df3a1dcaf4d0e1cfdd95ee94e8"}, "source": ["data16 = pd.merge(df16,train16)\n", "data17 = pd.merge(df17,train17)\n", "data = pd.concat([data16,data17],keys=('parcelid','transactiondate'))\n", "data.head()"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "ff4726be-7e57-479d-bf96-ec6c4e2e7140", "_uuid": "32cd5bb014c2d52488bd92587efe21dc95a4671c"}, "source": ["num_cols = [col for col in data.columns if (data[col].dtype in ['float64','int64'] and col not in ['parcelid','transactiondate']) or data[col].dtype.name=='category']\n", "temp_df = data[num_cols]\n", "corrmat = temp_df.corr(method='spearman')\n", "f, ax = plt.subplots(figsize=(12, 12))\n", "\n", "sns.heatmap(corrmat, vmax=1., square=True,cmap='PiYG')\n", "plt.title(\"Variables correlation map\", fontsize=15)\n", "plt.show()"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "bd3dca4c-0e2d-452b-aace-9a291c375543", "_uuid": "ab72542c22493810b40d4f5ae6077bd014e27ae3"}, "source": ["for c in data.columns:\n", "    data[c]=data[c].fillna(-1)\n", "    if data[c].dtype == 'object':\n", "        lbl = LabelEncoder()\n", "        lbl.fit(list(data[c].values))\n", "        data[c] = lbl.transform(list(data[c].values))\n", "\n", "data[\"transactiondate\"] = pd.to_datetime(data[\"transactiondate\"])\n", "data[\"transactiondate_year\"] = data[\"transactiondate\"].dt.year\n", "data[\"transactiondate_month\"] = data[\"transactiondate\"].dt.month\n", "data['transactiondate_quarter'] = data['transactiondate'].dt.quarter\n", "data[\"transactiondate\"] = data[\"transactiondate\"].dt.day\n", "\n", "data = data.fillna(-1.0)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "c68a97d5-15ce-428e-9d04-8d8c7d82a5e8", "_uuid": "056156b640afa75c2aff75e2824bf93603462258"}, "source": ["x_train = data.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\n", "y_train = data[\"logerror\"]\n", "\n", "y_mean = np.mean(y_train)\n", "print(x_train.shape, y_train.shape)\n", "train_columns = x_train.columns\n", "\n", "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n", "    x_train[c] = (x_train[c] == True)\n", "\n", "samplesub['parcelid'] = samplesub['ParcelId']\n", "df_test = samplesub.merge(df16, on='parcelid', how='left')\n"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "cc5e6c5b-c252-4fa9-84c4-758182838f7e", "_uuid": "8a7cbec178d02332010c13982431b36633fbc8cb"}, "source": ["df_test[\"transactiondate\"] = pd.to_datetime('2016-11-15')  # placeholder value for preliminary version\n", "df_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\n", "df_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\n", "df_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\n", "df_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n", "x_test = df_test[train_columns]\n", "\n", "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n", "    x_test[c] = (x_test[c] == True)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"_cell_guid": "5cf89d06-2130-4ccc-9b3a-84b980b55e76", "_uuid": "b080cd454456031e8f7fd856f7e56cdf0c5d2f58"}, "source": ["imputer= Imputer()\n", "imputer.fit(x_train.iloc[:, :])\n", "x_train = imputer.transform(x_train.iloc[:, :])\n", "imputer.fit(x_test.iloc[:, :])\n", "x_test = imputer.transform(x_test.iloc[:, :])\n", "\n", "sc = StandardScaler()\n", "x_train = sc.fit_transform(x_train)\n", "x_test = sc.transform(x_test)\n", "\n", "len_x=int(x_train.shape[1])\n", "print(len_x)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "c5b58d17-d3af-4f91-99fc-fa033896012a", "_uuid": "28469fdea616c7c5fe1cf00ff7d228dd4ad9a14e"}, "source": ["# model taken from Andy Harless\n", "nn = Sequential()\n", "nn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = len_x))\n", "nn.add(PReLU())\n", "nn.add(Dropout(.4))\n", "nn.add(Dense(units = 160 , kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.6))\n", "nn.add(Dense(units = 64 , kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.5))\n", "nn.add(Dense(units = 26, kernel_initializer = 'normal'))\n", "nn.add(PReLU())\n", "nn.add(BatchNormalization())\n", "nn.add(Dropout(.6))\n", "nn.add(Dense(1, kernel_initializer='normal'))\n", "nn.compile(loss='mae', optimizer=Adam(lr=4e-3, decay=1e-4))"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["nn.fit(np.array(x_train), np.array(y_train), batch_size = 1000, epochs = 20, verbose=2)\n"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["y_pred_ann = nn.predict(x_test)\n", "nn_pred = y_pred_ann.flatten()\n", "\n", "pd.DataFrame(nn_pred).head()"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {}, "source": ["y_pred=[]\n", "\n", "for i,predict in enumerate(nn_pred):\n", "    y_pred.append(str(round(predict,4)))\n", "y_pred=np.array(y_pred)\n", "\n", "output = pd.DataFrame({'ParcelId': df16['parcelid'].astype(np.int32),\n", "        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n", "        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n", "\n", "# set col 'ParceID' to first col\n", "cols = output.columns.tolist()\n", "cols = cols[-1:] + cols[:-1]\n", "output = output[cols]\n", "output.head()"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "source": ["output.to_csv(\"zillow_sub.csv\",index=False)"]}, {"cell_type": "code", "outputs": [], "execution_count": null, "metadata": {"collapsed": true}, "source": []}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4", "nbconvert_exporter": "python"}}}