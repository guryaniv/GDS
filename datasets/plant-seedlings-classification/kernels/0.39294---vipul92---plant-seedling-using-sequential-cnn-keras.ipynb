{"cells":[{"metadata":{"_uuid":"1916df675a20a8b7ca24217c209dfe8cbf8dfefe"},"cell_type":"markdown","source":"Importing Necessary Libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom PIL import Image, ImageOps\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout,BatchNormalization\n\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"660c9aef2b452e5dc4f8840b2168435bbccd56e3"},"cell_type":"code","source":"#parsing all png files, and printing format, size and mode using PIL image module\nimport glob\ntrain_imgs = []\ntrain_label= []\n\ntrain_dir = '../input/plant-seedlings-classification/train/*/*.png'\n\nfor img_dir in glob.glob(train_dir):\n    img = Image.open(img_dir)\n#     print(\"Label = \" + img_dir.split('/')[-2] + \" | for\" + img_dir,img.format, img.size, img.mode)\n#     print(img.resize((128, 128),Image.ANTIALIAS)) # ANTIALIAS to remove distortion, smoothening\n    train_imgs.append(ImageOps.fit(img,(128, 128),Image.ANTIALIAS).convert('RGB'))\n    train_label.append(img_dir.split('/')[-2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d60d3413b478e143b3b62cc80e292c59bcf90cde"},"cell_type":"code","source":"images = np.array([np.array(im) for im in train_imgs])\nimages = images.reshape(images.shape[0], 128, 128, 3) / 255\nlb = LabelBinarizer().fit(train_label)\nlabel = lb.transform(train_label) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2eebbd78710e4bd211e403eb7b22d3c1bcfa281"},"cell_type":"code","source":"trainX, validX, trainY, validY = train_test_split(images, label, test_size=0.05)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"809d7b08c3af5acc5dc36d87906a4ab30730b6c5"},"cell_type":"markdown","source":"Lets create our own Sequential Model.\n\nOne can add more filters, BatchNormalization, and Dense Layers\n\nbatch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation\n\nFore more information on How BatchNormalization works, check this article\n[Batch-Normalization-in-neural-networks](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c)"},{"metadata":{"trusted":true,"_uuid":"f88fe91d77fa1de8f547f0278cae7cb56dc9c938"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(20, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(128, 128, 3)))\nmodel.add(BatchNormalization(axis=3))\nmodel.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(12, activation='softmax'))\nmodel.summary()\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1885bc4ccb7596234f712d31b10aef7e4d7dd89e","scrolled":false},"cell_type":"code","source":"##fitting our sequential model\nmodel.fit(trainX, trainY,\n          batch_size=64,\n          epochs=50,#run with 50 epochs first to get 95% accuracy\n          validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71bc9e427cddf8fe5442bdd2b1538c74e9da5dd7","scrolled":false},"cell_type":"code","source":"test_dir = '../input/plant-seedlings-classification/test/*.png'\ntest_imgs=[]\nnames = []\nfor timage in glob.glob(test_dir):\n    img = Image.open(timage)\n    names.append(timage.split('/')[-1])\n    test_imgs.append(ImageOps.fit(img,(128, 128),Image.ANTIALIAS).convert('RGB'))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a7bd5ea047e0bb3466c419b34330c61a03dd69c"},"cell_type":"code","source":"test_images = np.array([np.array(im) for im in test_imgs])\ntest_images_X = test_images.reshape(test_images.shape[0], 128, 128, 3) / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfc8acf1273e0e6f310a1f05d7295df7553b8e84"},"cell_type":"code","source":"test_y = lb.inverse_transform(model.predict(test_images_X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facb95c6211f5e5db35d0a21653e9319d8956a0a"},"cell_type":"code","source":"df = pd.DataFrame(data={'file': names, 'species': test_y})\ndf_sort = df.sort_values(by=['file'])\ndf_sort.to_csv('resultss.csv', index=False)\n\nprint(df_sort)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}