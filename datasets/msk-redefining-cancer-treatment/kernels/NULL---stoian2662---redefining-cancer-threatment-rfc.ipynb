{"cells": [{"cell_type": "markdown", "source": ["## Redefining Cancer Threatment - RFC\n", "\n", "A solution using Random Forest Classifier."], "metadata": {"_uuid": "5e1508e3f269a8d036fc4da49306b67e729a4c74", "_cell_guid": "a67020ca-ad54-42c6-8cd8-88e3917b4072"}}, {"cell_type": "code", "source": ["import pandas as pd"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "2e6de93228aa2a94ba2479fa923b596259eb8c37", "_cell_guid": "7e8c0e58-91ee-46f4-affe-2cc9a978e57d", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Load all data sets"], "metadata": {"_uuid": "832baf68fd3e9ac8699b7d5ff8459a099569538c", "_cell_guid": "1bf3ba81-1fe8-4622-b590-251eda9b54a4"}}, {"cell_type": "code", "source": ["def load_data(name, extension=None):\n", "    data = pd.read_csv('../input/{0}_variants{1}'.format(name, '.' + extension if extension is not None else ''))\n", "    text = pd.read_csv('../input/{0}_text{1}'.format(name, '.' + extension if extension is not None else ''), \n", "                             sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n", "    data = pd.merge(data, text, on='ID').fillna('')\n", "    \n", "    return data"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a8e2f01da978b314c28666d3dcf1b279f72b101b", "_cell_guid": "4c90c679-3ae7-4551-bdb6-9a2d4e07029a", "collapsed": true}}, {"cell_type": "code", "source": ["# training data\n", "train_data = load_data('training')\n", "print(train_data.shape)\n", "train_data.columns.values"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "c62308ace15c2e59c0d1948beeb516d7d9747b41", "_cell_guid": "eabd411a-a22b-4707-affc-e7903690e27c"}}, {"cell_type": "code", "source": ["# test data\n", "test_data = load_data('test')\n", "print(test_data.shape)\n", "test_data.columns.values"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a1a685942ea90fb55f1c160918be6bc058b7a8b9", "_cell_guid": "8ea28d55-a81e-463e-a233-0fc4108ebd9b"}}, {"cell_type": "code", "source": ["# test data for stage 2\n", "stage2_test_data = load_data('stage2_test', 'csv')\n", "print(stage2_test_data.shape)\n", "stage2_test_data.columns.values"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "f6b569237caef6752724971a50a8481d3c32d947", "_cell_guid": "ed95b688-2a8f-4d45-806b-d1d3093a8ef3"}}, {"cell_type": "code", "source": ["# released labels for stage 2\n", "solution_data = pd.read_csv('../input/stage1_solution_filtered.csv')\n", "solution_data.shape"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "13c9674957d568c0e61b0ec55fd65738306309c6", "_cell_guid": "57ce55eb-8e83-400c-bd9f-96cb554060a4"}}, {"cell_type": "markdown", "source": ["### Extending the training data with the released test labels\n", "\n", "Concatenating the released test data with the training data."], "metadata": {"_uuid": "bb4f655a8e965f15d29b5c054ae1d216f346902c", "_cell_guid": "f890a22b-6d2b-4812-b17b-8dcaf5af6ee1"}}, {"cell_type": "code", "source": ["# data normalization\n", "solution_data_labels = solution_data[['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']]\n", "solution_data_labels.columns = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n", "solution_data['Class'] = solution_data_labels.idxmax(axis=1)\n", "solution_data = solution_data[['ID', 'Class']]\n", "solution_data.head(5)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "dd3cfa7bb8d7358038a18beac6e441be221e8770", "_cell_guid": "b3a11d3f-0086-4fde-afe0-1a93ad8970b4"}}, {"cell_type": "code", "source": ["# merging the released labels with the test data\n", "released_test_data = pd.merge(solution_data, test_data, \n", "                            left_on=['ID'],\n", "                            right_on=['ID'],\n", "                            how='inner')\n", "released_test_data.shape"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "1b637521441e9d0b2c277b5a141ba6cbb1e6eac7", "_cell_guid": "aaf10c6d-c16a-4d68-9991-50a3c8d8af7b"}}, {"cell_type": "code", "source": ["released_test_data.head(5)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "d0d549638397d18361b8b75ed945b8725fc167de", "_cell_guid": "87b74c20-f981-47f5-bcf8-59874bdbf7cc"}}, {"cell_type": "code", "source": ["# extending the train data\n", "extended_train_data = pd.concat([train_data, released_test_data], ignore_index=True)\n", "extended_train_data.shape"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "96087ffc34e65ed84888e189a616a7b804ca92f5", "_cell_guid": "6193308b-7675-4ff1-a980-15c54b301287"}}, {"cell_type": "markdown", "source": ["### Extracting features from the given data set\n", "\n", "Extracting more features from the Genes and Variations"], "metadata": {"_uuid": "9ee77e493b09d9c45c7dcb900ce846a501f75201", "_cell_guid": "50122ae8-e473-46e4-bead-da14275ab176"}}, {"cell_type": "code", "source": ["def extract_features_from_genes_and_variations(df):\n", "    gene_features = pd.get_dummies(df['Gene'])\n", "    variation_features = pd.get_dummies(df['Variation'])\n", "    features = gene_features.join(variation_features)\n", "\n", "    return features"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "d7dbfbb9f46fd92a759ea929b4f1c9a25fa9e4cd", "_cell_guid": "8a6a9641-298d-445a-b8a5-39a808115471", "collapsed": true}}, {"cell_type": "markdown", "source": ["Use the full data given from Gene and Variations."], "metadata": {}}, {"cell_type": "code", "source": ["train_and_test_data = pd.concat([train_data, test_data], ignore_index=True)\n", "train_and_test_data.shape"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "a6d4994e6815821f5256f3fa548d2909f206a765", "_cell_guid": "9bc2b56a-c192-4832-9b65-6c9539373edc"}}, {"cell_type": "code", "source": ["train_features = extract_features_from_genes_and_variations(train_and_test_data)\n", "test_features = extract_features_from_genes_and_variations(stage2_test_data)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "1a2c379f1b926d3732910aad951c420dc9c41c9b", "_cell_guid": "17a1eb8d-c58c-4366-ab67-2a70695a9b41", "collapsed": true}}, {"cell_type": "markdown", "source": ["Finding common features between the train and test data."], "metadata": {"_uuid": "74344f381c3e3fc3807971643d332b84c7c33321", "_cell_guid": "63c8482f-df19-46a0-9fbf-eb2a0d7ac1ac"}}, {"cell_type": "code", "source": ["common_features = list(set(train_features.columns.values) & set(test_features.columns.values))\n", "train_features = train_features[common_features]\n", "test_features = test_features[common_features]\n", "\n", "train_features.shape, test_features.shape"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "7eaa454fa252092cd249df6e4e191192d1f829b7", "_cell_guid": "452e9d69-c19c-4c8c-a9d5-f19228857ca4"}}, {"cell_type": "markdown", "source": ["### Performing predictions"], "metadata": {"_uuid": "39205ddc2adc0b0695bbffea466701d06217550c", "_cell_guid": "e7a05953-31e2-44d8-8ab4-ac7ef4b31ca8"}}, {"cell_type": "code", "source": ["from sklearn.model_selection import train_test_split\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.ensemble import RandomForestClassifier\n", "from scipy.sparse import hstack\n", "import numpy as np"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "b8fd2b09854ef2c1d93a8e6597d4060e7b729517", "_cell_guid": "78485248-38a1-4a0d-a72c-e997aab19de6", "collapsed": true}}, {"cell_type": "code", "source": ["def generate_features_and_labels(train_data, test_data, train_features, test_features):\n", "    '''\n", "    Generating a feature set by combining the two feature sets, \n", "    extracted from genes and variations and extracted from the texts.\n", "    '''\n", "    x_train = vectorizer.fit_transform(train_data['Text'])\n", "    x_train = hstack((x_train, train_data[['ID']].join(train_features).drop('ID', axis=1).values))\n", "    y_train = train_data['Class']\n", "    x_test = vectorizer.transform(test_data['Text'])\n", "    x_test = hstack((x_test, test_data[['ID']].join(test_features).drop('ID', axis=1).values))\n", "    \n", "    return x_train, y_train, x_test"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "c06a35a5a4cdec72b56910777a5338c16b5cdc61", "_cell_guid": "b330708a-1234-49ed-a140-4ab91588ff01", "collapsed": true}}, {"cell_type": "code", "source": ["def predict(x_train, y_train, x_test):\n", "    clf = RandomForestClassifier(n_jobs=3,\n", "                                n_estimators=100,\n", "                                criterion='entropy',\n", "                                random_state=300)\n", "\n", "    clf.fit(x_train, y_train)\n", "    return clf.predict(x_test)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "ec1e9078a0c078c8ea7c73027d7c9e5b81a014e0", "_cell_guid": "166390a9-bc48-4fc2-bf75-4cf458fa1316", "collapsed": true}}, {"cell_type": "code", "source": ["def make_submission(test_data):\n", "    submission_data = pd.get_dummies(test_data['predicted_class'])\n", "    submission_data = test_data[['ID']].join(submission_data)\n", "    \n", "    labels = list(range(1, 10))\n", "    submission_data = submission_data[['ID'] + labels]\n", "    submission_data.columns = ['ID'] + ['class' + str(label) for label in labels]\n", "\n", "    submission_data.to_csv('submission.csv', index=False)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "4e57d0dcc1dcbbcd058f162394ed42ee2584dcc1", "_cell_guid": "e4f43e6d-b34a-4690-a610-6a4ccdd817a9", "collapsed": true}}, {"cell_type": "markdown", "source": ["Validation testing"], "metadata": {"_uuid": "5c5df62c8e8ec205f45797d909c988922f5d55d4", "_cell_guid": "9f8e942c-1083-494f-8ddd-85703755ee69"}}, {"cell_type": "code", "source": ["train, test = train_test_split(extended_train_data, test_size=0.2)\n", "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n", "                                 stop_words='english')\n", "\n", "x_train, y_train, x_test = generate_features_and_labels(train, test, train_features, train_features)\n", "y_test = test['Class']"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "78b5ebf8592a1152c827d749bad8d78f8de8e3ab", "_cell_guid": "08cec382-813d-49b5-955a-7084656b6376", "collapsed": true}}, {"cell_type": "code", "source": ["predicted = predict(x_train, y_train, x_test)\n", "np.mean(predicted == y_test)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "f7aaafb7d592a9ad70fc5012c7935f47f5180498", "_cell_guid": "266e66b0-9d77-4583-9513-902d5a5413e6"}}, {"cell_type": "markdown", "source": ["Prediction with the test data"], "metadata": {"_uuid": "09a2943d6d08aac7a4d07c232af00a27977811df", "_cell_guid": "0975f69d-2517-4443-a974-5ed8be5d84c3"}}, {"cell_type": "code", "source": ["x_train = vectorizer.fit_transform(extended_train_data['Text'])\n", "x_train = hstack((x_train, extended_train_data[['ID']].join(train_features).drop('ID', axis=1).values))\n", "y_train = train['Class']\n", "x_test = vectorizer.transform(stage2_test_data['Text'])\n", "x_test = hstack((x_test, stage2_test_data[['ID']].join(test_features).drop('ID', axis=1).values))\n", "\n", "x_train, y_train, x_test = generate_features_and_labels(extended_train_data, stage2_test_data, train_features, test_features)\n", "\n", "predicted = predict(x_train, y_train, x_test)\n", "\n", "stage2_test_data['predicted_class'] = predicted\n", "make_submission(stage2_test_data)"], "outputs": [], "execution_count": null, "metadata": {"_uuid": "16361d2ceb96b8f73b477968e98248ae7f49887a", "_cell_guid": "f8b3db94-4921-43e2-bb7d-4404c9b6075c", "collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python", "file_extension": ".py", "version": "3.6.1", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}}