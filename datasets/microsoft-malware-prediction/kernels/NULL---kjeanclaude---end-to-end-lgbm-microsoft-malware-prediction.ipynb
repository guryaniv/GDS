{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Required libraries\n# We will try several Machine Learning platforms\nfrom __future__ import print_function\nfrom builtins import str\nfrom builtins import range\n\nimport os\nimport sys\nimport tarfile\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom io import BytesIO\n\nimport bson\nimport json \nimport skimage\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn import *\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nimport time\n#import datetime as dt\nfrom datetime import datetime as dt\nimport multiprocessing\nimport psutil\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\n# Config the matplotlib backend as plotting inline in IPython\n%matplotlib inline\n\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nprint(\"pandas --version : \", pd.__version__)\nprint(\"python --version : \", sys.version)\nPyVersion = sys.version\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d7957a5c0df79ecdc8fced37643dfabf9fbd97f"},"cell_type":"markdown","source":"### 1- Data loading and Data Engineering\nLet us reduce the data size in memory"},{"metadata":{"trusted":true,"_uuid":"e39802a8fa80c66683d1e453f7462d2676ca5be2"},"cell_type":"code","source":"# From https://www.kaggle.com/theoviel/load-the-totality-of-the-data \n# https://www.kaggle.com/xhlulu/load-entire-dataset-with-7-gb-ram-fork\ndtypes = {\n        'MachineIdentifier':                                    'category',\n        'ProductName':                                          'category',\n        'EngineVersion':                                        'category',\n        'AppVersion':                                           'category',\n        'AvSigVersion':                                         'category',\n        'IsBeta':                                               'int8',\n        'RtpStateBitfield':                                     'float16',\n        'IsSxsPassiveMode':                                     'int8',\n        'DefaultBrowsersIdentifier':                            'float16',\n        'AVProductStatesIdentifier':                            'float32',\n        'AVProductsInstalled':                                  'float16',\n        'AVProductsEnabled':                                    'float16',\n        'HasTpm':                                               'int8',\n        'CountryIdentifier':                                    'int16',\n        'CityIdentifier':                                       'float32',\n        'OrganizationIdentifier':                               'float16',\n        'GeoNameIdentifier':                                    'float16',\n        'LocaleEnglishNameIdentifier':                          'int8',\n        'Platform':                                             'category',\n        'Processor':                                            'category',\n        'OsVer':                                                'category',\n        'OsBuild':                                              'int16',\n        'OsSuite':                                              'int16',\n        'OsPlatformSubRelease':                                 'category',\n        'OsBuildLab':                                           'category',\n        'SkuEdition':                                           'category',\n        'IsProtected':                                          'float16',\n        'AutoSampleOptIn':                                      'int8',\n        'PuaMode':                                              'category',\n        'SMode':                                                'float16',\n        'IeVerIdentifier':                                      'float16',\n        'SmartScreen':                                          'category',\n        'Firewall':                                             'float16',\n        'UacLuaenable':                                         'float32',\n        'Census_MDC2FormFactor':                                'category',\n        'Census_DeviceFamily':                                  'category',\n        'Census_OEMNameIdentifier':                             'float16',\n        'Census_OEMModelIdentifier':                            'float32',\n        'Census_ProcessorCoreCount':                            'float16',\n        'Census_ProcessorManufacturerIdentifier':               'float16',\n        'Census_ProcessorModelIdentifier':                      'float16',\n        'Census_ProcessorClass':                                'category',\n        'Census_PrimaryDiskTotalCapacity':                      'float32',\n        'Census_PrimaryDiskTypeName':                           'category',\n        'Census_SystemVolumeTotalCapacity':                     'float32',\n        'Census_HasOpticalDiskDrive':                           'int8',\n        'Census_TotalPhysicalRAM':                              'float32',\n        'Census_ChassisTypeName':                               'category',\n        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n        'Census_PowerPlatformRoleName':                         'category',\n        'Census_InternalBatteryType':                           'category',\n        'Census_InternalBatteryNumberOfCharges':                'float32',\n        'Census_OSVersion':                                     'category',\n        'Census_OSArchitecture':                                'category',\n        'Census_OSBranch':                                      'category',\n        'Census_OSBuildNumber':                                 'int16',\n        'Census_OSBuildRevision':                               'int32',\n        'Census_OSEdition':                                     'category',\n        'Census_OSSkuName':                                     'category',\n        'Census_OSInstallTypeName':                             'category',\n        'Census_OSInstallLanguageIdentifier':                   'float16',\n        'Census_OSUILocaleIdentifier':                          'int16',\n        'Census_OSWUAutoUpdateOptionsName':                     'category',\n        'Census_IsPortableOperatingSystem':                     'int8',\n        'Census_GenuineStateName':                              'category',\n        'Census_ActivationChannel':                             'category',\n        'Census_IsFlightingInternal':                           'float16',\n        'Census_IsFlightsDisabled':                             'float16',\n        'Census_FlightRing':                                    'category',\n        'Census_ThresholdOptIn':                                'float16',\n        'Census_FirmwareManufacturerIdentifier':                'float16',\n        'Census_FirmwareVersionIdentifier':                     'float32',\n        'Census_IsSecureBootEnabled':                           'int8',\n        'Census_IsWIMBootEnabled':                              'float16',\n        'Census_IsVirtualDevice':                               'float16',\n        'Census_IsTouchEnabled':                                'int8',\n        'Census_IsPenCapable':                                  'int8',\n        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n        'Wdft_IsGamer':                                         'float16',\n        'Wdft_RegionIdentifier':                                'float16',\n        'HasDetections':                                        'int8'\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fac09007d845eaf16c7f9715efbe1a45db02a913"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv', nrows = 200, dtype=dtypes)\ncolumns = train_df.columns\ntrain_df = pd.read_csv('../input/train.csv', nrows = 2000000, usecols= columns, dtype=dtypes)\n#train_df.info() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b4a7e48346fb1b17d51887eadbab4294862d9f28"},"cell_type":"code","source":"numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64'] \nnumerical_columns = [c for c,v in dtypes.items() if v in numerics] \ncategorical_columns = [c for c,v in dtypes.items() if v not in numerics] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a465ecdc132382e96dcbef5fb3f089d934d8087"},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a81ffaa0bd6315221b42f63ed96296be7c67aab"},"cell_type":"code","source":"train_df.to_pickle(\"train_df.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fce040a70416945fb3fc4c5439ef0eec1ed8ae6b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3bd6b6b9b5dc0e2dac19ab01361b01ce424fa376"},"cell_type":"code","source":"# MEAN ENCODINGS\nfor elt in numerical_columns:\n    if elt != 'HasDetections':\n        m_id = elt \n        target = 'HasDetections' \n        new_column = pd.DataFrame(columns=[m_id+'_mean_target']) \n        # mean encoding of variables\n        train_df[m_id+'_mean_target'] = new_column[m_id+'_mean_target'] \n        cumsum = train_df.groupby(m_id)[target].cumsum() - train_df[target] \n        cumcnt = train_df.groupby(m_id).cumcount() \n        train_df[m_id+'_mean_target'] = cumsum/cumcnt\n    \ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4735812c75734805c8fa9cdf206dfb8cb4ee3ed1"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"54efc5bbd2e41ce5ffb90804eca2f26430d936b3"},"cell_type":"markdown","source":"### 2- Data splitting"},{"metadata":{"trusted":true,"_uuid":"87e5c5d7d58d2aa274fba017af1a071b17e6f156"},"cell_type":"code","source":"labels_df = train_df['HasDetections']\ntrain_df = train_df.drop(['MachineIdentifier'], axis=1) \ncolumns = train_df.columns \ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"80b90689bd2c0de6e3918032722c7ef6ab229831"},"cell_type":"code","source":"train_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"740c1b67a3d254915cd6ac36d4d1a985d155d877"},"cell_type":"code","source":"col = list(columns)\ncol.remove('HasDetections')\n#print(col), len(col)\nlen(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2940310d827f6775e4bf21a21f3312b3750bd7c5"},"cell_type":"code","source":"# DATA SPLITING\nX_train, X_test, y_train, y_test = train_test_split(train_df[col], labels_df, test_size=0.2, \n                                                    random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, \n                                                    random_state=42)\n\nn_features = X_train.shape[1]\nn_classes = len(np.unique(y_train))\nprint(\"n_features : {}\\nn_classes : {}\\nX_train.shape : {}\".format(n_features, n_classes, \n                                                                   X_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f856d35bf337f357c8d8ab879a905dbd770a4b0d"},"cell_type":"code","source":"X_train.shape, X_val.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"794a69cd9ebf83559409ea0199baae7d64923321"},"cell_type":"code","source":"y_train.shape, y_val.shape, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abffee3040cdd77344018c1028371a0e76a1cf2c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ed82858a49dbd2cc998658aa5320b8d1bd8a765"},"cell_type":"markdown","source":"### 3- First training & Hyperparameter Optimization"},{"metadata":{"trusted":true,"_uuid":"fed38300077d3a7785f14d9a85e599b8bb0bdb10","scrolled":false},"cell_type":"code","source":"print('Start training...')\n# train\ngbm = lgb.LGBMClassifier(objective='binary',\n                        num_leaves=31,\n                        learning_rate=0.05,\n                        n_estimators=20)\ngbm.fit(X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        eval_metric='auc',\n        early_stopping_rounds=100)\n\nprint('Start predicting...')\n# predict\n#y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\ny_pred = gbm.predict(X_test, num_iteration=10)\n# eval\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n\n# feature importances\nprint('\\nNumber of features :', len(list(gbm.feature_importances_)))\nprint('Features :', train_df.columns)\nprint('Importances :', list(gbm.feature_importances_))\nprint('\\nFeature importances :', dict(zip(train_df.columns,list(gbm.feature_importances_))))\n\n# The log_loss of prediction is: 12.769218206519513 , roc_auc_score is: 0.630302822037965\n# for test size == 20% and val size == 20%\n# 0.630302822037965\n# log_loss: 12.587463101120566 et roc_auc_score: 0.6355364487531907 for mean encoding with dummify.\n# log_loss: 12.494988259947414 et roc_auc_score: 0.638198925649798 for mean encoding without dummify.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"138942ad92d4dfb382e2352309984baba954a5db"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8316cef25ad3f02e94c2ca6ddd334cd7c587cc7"},"cell_type":"markdown","source":"#### <font color='red'>Please, unlock this part *(transform into code cell)* for fine-tuning phase.</font>\n### ### Hyperparameter Optimization ##############\n#### other scikit-learn modules\nestimator = lgb.LGBMClassifier(num_leaves=31)\n\n#### The parameters used are in comment below, it will take too long time to run them here\nparam_grid = {\n    'learning_rate': [0.1],\n    'n_estimators': [100, 500],\n    'num_leaves': [20, 31],\n    'min_data_in_leaf': [5, 10],\n    'reg_alpha': [0],\n    'reg_lambda': [1e-6], \n    'bagging_fraction': [0.8, 0.9],\n    'min_child_samples': [10, 20],\n    'min_child_weight': [1e-6], \n    'max_bin': [256]\n}\n\ngbm = GridSearchCV(estimator, param_grid, cv=5)\n\ngbm.fit(X_train, y_train)\n\nprint('\\n\\nBest parameters found by grid search are:', gbm.best_params_)\n\n'''\nparam_grid = {\n    'learning_rate': [0.01, 0.1, 0.05, 0.07, 1],\n    'n_estimators': [20, 40, 100, 500],\n    'num_leaves': [20, 31, 50, 127],\n    'min_data_in_leaf': [5, 10, 20, 50, 100],\n    'reg_alpha': [0, 1e-3, 1e-6],\n    'reg_lambda': [0, 1e-3, 1e-6], \n    'bagging_fraction': [0.5, 0.6, 0.7, 0.8, 0.9],\n    'min_child_samples': [10, 20, 30],\n    'min_child_weight': [5, 1e-3, 1e-6], \n    'max_bin': [255, 256]\n}\n'''\n####"},{"metadata":{"_uuid":"a2304fd74668d7b2592ca276f2460239591cfd79"},"cell_type":"markdown","source":"### 4- Fine Tuning & Evaluation"},{"metadata":{"trusted":true,"_uuid":"54436a46ab8c73de0696cd29e1392ce5156d0558"},"cell_type":"code","source":"# FEATURES TUNING IF NECESSARY\n## For example, we could remove least important features if required\n## And also use the best parameters provided by the grid search Cross Validation\n# Here I reuse the same previous splits instead of recreate a new one.\nX_train = pd.DataFrame(X_train, columns=col) \nX_val = pd.DataFrame(X_val, columns=col) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a19124ee00586ca9f3bf34a845a8b10eff45069e"},"cell_type":"code","source":"X_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"782afceb42bd938d2785c5d5038bca2c9159bf33"},"cell_type":"code","source":"X_val.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aae6260555a649e58a99a0124c27a2aa540233b7"},"cell_type":"code","source":"# In case I decide to delete the features with lower importance to see how that could improve the result\n# Using the Feature importances Dictionary\nfeature_importances_dic = dict(zip(train_df.columns,list(gbm.feature_importances_)))\nbanned_columns = []\nfor key in feature_importances_dic:\n    if feature_importances_dic[key]==0:\n        banned_columns.append(key)\nprint(\"len banned_columns:\", len(banned_columns))\nprint(\"banned_columns:\\n\", banned_columns)\n\nnew_cols = [c for c in train_df.columns if c not in banned_columns]\nnew_cols = list(new_cols)\nif 'HasDetections' in new_cols:\n    new_cols.remove('HasDetections')\nprint(\"new columns:\\n\", new_cols) \nlen(new_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89c027b3c08267436be9ff11ba1180a6d7f88f18"},"cell_type":"code","source":"X_train_new = X_train[new_cols] \nX_val_new = X_val[new_cols] \nX_test_new = X_test[new_cols] \nX_train_new.shape, X_val_new.shape, X_test_new.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40872de506c9b593739280738df0037200237b5b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9617be717891e72d7d47d20d0c9f9521a8c043f0"},"cell_type":"code","source":"# TRAINING\n# specify your configurations as a dict\n# Use the best parameters provided by the grid search Cross Validation\nparams = {\"objective\": \"binary\",\n          #\"sigmoid\":1.0,\n          \"task\": \"train\",\n          \"boosting_type\": \"gbdt\",\n          \"learning_rate\": 0.05,\n          \"num_leaves\": 31, # 31, 20\n          \"max_bin\": 256,\n          \"min_data_in_leaf\": 5, # Problem  2000\n          \"feature_fraction\": 0.6, # 0.6\n          \"verbosity\": 0,\n          \"seed\": 0,\n          \"drop_rate\": 0.1, # 0.1\n          \"is_unbalance\": False,\n          \"max_drop\": 50,\n          \"min_child_samples\": 10,\n          \"min_child_weight\": 1e-06, # 5\n          \"min_split_gain\": 0,\n          \"colsample_bytree\": 0.6343275033,\n          \"max_depth\": 8, # 8\n          #\"n_estimators\": 500, # 500\n          \"nthread\": -1,\n          \"reg_alpha\": 0,\n          \"reg_lambda\": 1e-06,# 1\n          #\"silent\": True,\n          \"subsample_for_bin\": 50000, # 50000\n          \"subsample_freq\": 1, # 1\n          #\"min_data\":1,\n          #\"min_data_in_bin\":1,\n          'metric': {'binary_logloss'},\n          'bagging_fraction': 0.8,\n          'bagging_freq': 5,\n          #'num_iterations':1000,\n          \"subsample\": 0.733\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"b3596788cee216b28fe8ba3413663668d8be7200"},"cell_type":"code","source":"# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_train)\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n#lgb_train = lgb.Dataset(X_train_new, y_train)\n#lgb_eval = lgb.Dataset(X_val_new, y_val, reference=lgb_train)\n\n\nprint('Start training...')\n# train\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=2000,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=120)\n\nprint('Save model...')\n# save model to file\ngbm.save_model('model.txt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1487cf79ca0f94febaeca9c7b576b1d5cb379cd"},"cell_type":"code","source":"print('Start predicting...')\n# predict\ny_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n#y_pred = gbm.predict(X_test_new, num_iteration=gbm.best_iteration)\n# eval\n#print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))\n# The log_loss of prediction is: 0.6147321812202021 and the roc_auc_score is: 0.7143388814690966\n# for test size == 10% and val size == 20%\n# With dummification, log_loss: 0.6103008030367194 and roc_auc_score: 0.7168178922141861\n# Without dummification, log_loss: 0.6067172451965305 and roc_auc_score: 0.7217849368889165","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5a6503e0431c008432b57d558a570e493e40518"},"cell_type":"code","source":"print('Loading model to predict...')\n# load model to predict\nbst = lgb.Booster(model_file='model.txt')\n# can only predict with the best iteration (or the saving iteration)\ny_pred = bst.predict(X_test)\nprint('The log_loss of prediction is:', log_loss(y_test, y_pred))\nprint('The roc_auc_score of prediction is:', roc_auc_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0ddfa9e4807cf81b847d8f9ec9f2590769dadbc1"},"cell_type":"markdown","source":"### 5- SUBMISSION FILE CREATION"},{"metadata":{"trusted":true,"_uuid":"c0bcc49e1b01efa2d4c95d85772ba934d9f0464d"},"cell_type":"code","source":"gbm.best_iteration, bst.best_iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b47c86fbe84d63a2e01433933c7ed586e0f4690b"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0320bc0f01ceb766645131a40a982ed2b6ff202"},"cell_type":"code","source":"# We will now save the parameters in order to reuse them in another kernel for submission\ndel train_df\ntrain_df = pd.read_pickle(\"train_df.pkl\")\ntrain_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bea54374178894796a97efa57d69ba6a6c5f76b4"},"cell_type":"code","source":"train_df2 = pd.read_csv('../input/train.csv', nrows = 200, dtype=dtypes)\ncolumns = train_df2.columns\ncolumns = list(columns)\ncolumns.remove('HasDetections')\ntest_df = pd.read_csv('../input/test.csv', nrows = 2000, usecols= columns, dtype=dtypes)\n\nfor elt in numerical_columns: \n    if elt != 'HasDetections': \n        m_id = elt \n        target = 'HasDetections' \n        new_column = pd.DataFrame(columns=[m_id+'_mean_target']) \n        # mean encoding of variables\n        test_df[m_id+'_mean_target'] = new_column[m_id+'_mean_target'] \n        cumsum = train_df.groupby(m_id)[target].cumsum() - train_df[target] \n        cumcnt = train_df.groupby(m_id).cumcount() \n        test_df[m_id+'_mean_target'] = cumsum/cumcnt\n        \ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef922dad24ad35b0beca2f2f4261952ad25b345d"},"cell_type":"code","source":"xtest = test_df[col] \npreds = gbm.predict(xtest, num_iteration=gbm.best_iteration) # data_has_header=False ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40cd91ea4d7be85fe4dd0fc638974314dccdf926"},"cell_type":"code","source":"len(preds) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81bef6d38a346e45de5b68927c77c53eb1425d7b"},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6819f5db5055eceea1aca2e07e2b29af0d59c0ef"},"cell_type":"code","source":"sub_sample_df = pd.read_csv('../input/sample_submission.csv')\nlen(sub_sample_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66c88610981b7462a33c9db9306dfc6e4d6a853b"},"cell_type":"code","source":"sub_sample_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23025812588dc4256d681649e5f04fd5f9367bdf"},"cell_type":"code","source":"if len(sub_sample_df) == len(preds):\n    submission = pd.DataFrame({'MachineIdentifier': sub_sample_df[\"MachineIdentifier\"], \n                               'HasDetections': preds})\n    submission.head(10)\nelse:\n    print(\"The prediction size must be: {}, but we got: {}\".format(len(sub_sample_df), len(preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6178b5595badf41b683aea697e190086ccfb9ec9"},"cell_type":"code","source":"#submission.to_csv(\"Micro_MP_LGBMsubmission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d088f6bc36ed9debb222b6da07a4bf4f3389c810"},"cell_type":"code","source":"del test_df ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75b16c4d16e5d3098aa06586bebdd638e7d649c5"},"cell_type":"markdown","source":"#### In order to reuse the saved variables for test prediction and submission, in case there is not enough memory space on Kaggle"},{"metadata":{"trusted":true,"_uuid":"c28cb3ddbe2cd35ccd09a88fc015253be73f0534"},"cell_type":"code","source":"# np.savez Cannot handle categorical data, I have to try pandas to_pickle.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a65608b9bae4bb1e26732000390e1ef4400e7a75"},"cell_type":"code","source":"#### Backup the 'model.txt' file, the train_df. \ndel X_train\nX_test.to_pickle(\"X_test.pkl\")\nX_test_new.to_pickle(\"X_test_new.pkl\")\ny_test.to_pickle(\"y_test.pkl\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5afa0a7bedacf11f0604f60f655482fe752374c"},"cell_type":"code","source":"del train_df, X_train_new, X_val_new, X_val, X_test_new, X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8f32cf7927da1c4266f132f3e57cccd218d01c0"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8164a54371b082826cb56765156cd05824cf0a34"},"cell_type":"code","source":"#### For reusing \nX_test = pd.read_pickle(\"X_test.pkl\")\nX_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85cf5a0ca79794a25ba424ea07226ebdb206a665"},"cell_type":"code","source":"!tar cvf 'model_backup.tar' 'model.txt' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71b35dc8124d71974c035996fb7f20f8a071af8c"},"cell_type":"code","source":"import shutil \nshutil.make_archive('model_backup', 'zip', '.', 'model.txt') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"721f272bf142baebab4717ca2a44ea9f982274d4"},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1861cccc1a91ee88814f90a7954ad15bd77a9af"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c25cd20af11a9de2e4684a79e0476ba49c3c9e9d"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}