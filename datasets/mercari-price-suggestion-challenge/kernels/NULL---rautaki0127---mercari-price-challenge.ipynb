{"cells": [{"source": ["# Mercari Price Challenge -Ridge Regression,  LightGBM"], "cell_type": "markdown", "metadata": {"_cell_guid": "3b4169b7-be70-4fb5-8a33-603cc301cb83", "_uuid": "67d7281492985582bbf0306a4d2de23ef38833f5"}}, {"source": ["![](https://lh3.googleusercontent.com/EfS3_Du-Af957T9VKhKAsazAOf_jo6urlXPUviz4rZ2KGa-69gHvDRMjgNJNPMLvkF-WFJWikJlkAllsUKMI1c0Y5mUT8ghcRvtB13R0ODMheXW1mrdrRgYjetXo6jTUtiL6wrwm5YRNoKFmaUcvToECEE_LYn-TC5C8wJtpqTQad1Q6Nhcg-0qJ40bYs8SdkO8soFgzTBilw6V-nK1a55Yv5WavggpT2TaTF7bbHRsIzHpk2pcXI1l92-bYTPOvyWsnWqlopuHPokC0yGDghwvciOT92nMmg-WeVcyqufRBTwhvogZ5FteFWTFDrrpkl4wi3_WTUAoJy0l5Ci72-3dp_01pSiHacbSfBPJO6cJJVJKNQ1TA_7O-lTn5CMZyUyfUuvk0D76WmxUAo4sSkgUNJw1lV3bsOZm-IGZ_UpyIZ5GSOLFXQChTQ1cNSjeEl-heUR7mT7-W8DCfAs-GCVQuOF-kdA1i9Dk5Cc9kYIg3Q1XiggPEB3lRN2sK9AxWH7L1on8-gUa5srx5xupKd9t4-y1PkCOZ1qicCRwlHLGErO3tmn-D9UTWxrn2VGQ3DroDiZwK45yiOHhSi1UhTQQC7aAmYvs-5x7gU3mibA=w1200-h630-no)"], "cell_type": "markdown", "metadata": {"_cell_guid": "092cf6c9-a334-47dd-ba37-7d2f4f9e72d5", "_uuid": "c1eb6d3c97a914eb5b13103302623ebba1c727d9"}}, {"source": ["I'm beginner Kaggler. This Kernel is based on following Prateek's kernel and Tilli's kernel.\n", "https://www.kaggle.com/iamprateek/submission-to-mercari-price-suggestion-challenge/notebook   \n", "https://www.kaggle.com/tilii7/cross-validation-weighted-linear-blending-errors  \n", "\n", "Original Data supplied by Mercari is too large to analyze in comfort, so I use only 10,000 data."], "cell_type": "markdown", "metadata": {"_cell_guid": "d718b0f3-6578-45fc-94a4-f9781b7942e1", "_uuid": "93a128785173ea6621e2a9f5881590f7836fc0de"}}, {"source": ["Firstly, I check data overview."], "cell_type": "markdown", "metadata": {"_cell_guid": "c4b584ae-5b03-48b1-b4e2-ea82642cf6e6", "_uuid": "6a607968cca3793145f51cd28bacdfab02c84884"}}, {"source": ["import pandas as pd\n", "train = pd.read_csv(\"../input/train.tsv\", delimiter = '\\t', nrows=10000)\n", "print (\"train.shape: \" + str(train.shape))\n", "train.head()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "5a1fcae7-b540-49fa-8838-efb89b958eb9", "_uuid": "7078203a133a6468e776ae4724eb0008e0534f25"}, "execution_count": 1}, {"source": ["![](https://lh3.googleusercontent.com/uiPP_5ezjrLyqLCgoAVonxzpWFyom1aEZcTRLoKxf3nY-GpWAncB_1XKtHzXCQtkrF-HcEZPRI6DLhOk8hoCfCvxz5t5kg3ikioefRbhG89YNhdZjgPtOQVlmulYR-btvXcJhgRpcmBhu-0aww_d1vGD5EgFB7xHRSpQzUu-PDUIsNvQ8yzbKo5EcA0YacHijLTgJv2SI2FqZRMGIP5PXiY_FlvfbWWPBUHT31_3-TAGwqEV3_lxtmcj1O4OpHdfFLGayAC3dapYCtPehBYAU0Ekp4zUWXlSv2SkeK-D1tNNd43OBIjrwMoQ81yPZdUATrqB5cKu0t1-wNczWkYZLjAPoGzxVE0Fw9d_eik9i7L8yjgHqozCh_iZN0sJn_zEYhjbFuKo-MkrjObY-GZXOnZ4KMmnyj5Dv5EkppFB4WUdg25aH6ULE69OGZO6Hh6zhuaLzKyjtoOSXC3Wscm1oZScUx7k9Brft9L5jaXoSJ-rexi9RLWqgM13PNs9lgxTlLnRd8zk5Nt66SQNRAyRkCySXs1qZQvUQ2RrAkLdoX5YaOvbWx5yS2t32oI47i26SyHX5pWAvK-byizDwiMAXvw-qKCnWR8sv6ys2a8=w600-h461-no)"], "cell_type": "markdown", "metadata": {"_cell_guid": "9597a697-e102-4a26-b0e6-dd1783440cb0", "_uuid": "83fe3844089c54477aef042409ec5598c0a7ae3b"}}, {"source": ["import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "plt.figure(figsize=(10, 6))\n", "plt.hist(train[\"price\"])\n", "plt.xlabel(\"price[$]\")\n", "plt.ylabel(\"count\")\n", "plt.title(\"Price Histogram\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "fb681dc1-6ea7-400f-86f7-eb475d6b8246", "_uuid": "0923a6d4331afede5fbfffd2922a5b8cace58a68"}, "execution_count": 2}, {"source": ["Most goods are traded within $200.  Check a detail ditribution of price within $200."], "cell_type": "markdown", "metadata": {"_cell_guid": "325d103c-0b62-4f36-89e9-790b78cb6f03", "_uuid": "cc0bcc8e53a29cc6c5893bdd55f696f259afa860"}}, {"source": ["plt.figure(figsize=(10, 6))\n", "plt.hist(train[\"price\"], bins=500)\n", "plt.xlim(0, 200)\n", "plt.xlabel(\"price[$]\")\n", "plt.ylabel(\"count\")\n", "plt.title(\"Price Histogram\")\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "abf540b1-12b9-45bd-abbe-62ea510d969e", "_uuid": "a9e76b1ba341406ae217b8d162ab52fb5d008748"}, "execution_count": 3}, {"source": ["It shows a price between $10 and $20 has the high frequency."], "cell_type": "markdown", "metadata": {"_cell_guid": "07cd6a10-68b0-4a2a-b0dc-082ca09fa5b5", "_uuid": "86517550ad5d6299327b994810d10f1ebd5877cc"}}, {"source": ["Next, make price ditribution of each item category visuallize by using seaborn plot."], "cell_type": "markdown", "metadata": {"_cell_guid": "4302bfb2-8cda-47ff-bdc9-8a4a3c045de4", "_uuid": "e5441758aa5e648f8674e48b5029c60f34888284"}}, {"source": ["import time\n", "import seaborn as sns\n", "def split_cat(text):\n", "    try: return text.split(\"/\")\n", "    except: return (\"No Label\", \"No Label\", \"No Label\")\n", "train[\"general_cat\"], train[\"sub_cat1\"], train[\"sub_cat2\"] = \\\n", "    zip(*train['category_name'].apply(lambda x: split_cat(x)))\n", "train.drop(\"category_name\", axis=1)\n", "start_time = time.time()\n", "plt.figure(figsize=(16, 8))\n", "ax = sns.violinplot(x=\"general_cat\", y=\"price\", data=train, inner=None)\n", "ax = sns.swarmplot(x=\"general_cat\", y=\"price\", data=train, edgecolor=\"gray\", hue=\"sub_cat1\")\n", "plt.xticks(rotation=30)\n", "plt.ylim(0, 200)\n", "plt.legend(loc=9, bbox_to_anchor=(0.5, -0.25), ncol=5)\n", "plt.show()\n", "print('Showing graph took {} secs.'.format(time.time() - start_time))"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "1628cd0b-b0e1-478b-8d3b-f3c2440566e3", "_uuid": "c5e59abc7e013862529b2d76890c098e8f9d0e4c"}, "execution_count": 4}, {"source": ["It took over 10 minutes to show the plot.  \n", "According to graph, it looks like Kids and Beauty category goods have a violin plot which shows relatively high density in low price. And Electronics category have high variation between low price and high price. All category has a step distribution of $10, $25, $40 and so on, not a continuous distribution."], "cell_type": "markdown", "metadata": {"_cell_guid": "aa09b42f-253f-4b8c-bb95-5d442c667c59", "_uuid": "44b47b12415d7aba93a414e19ba11b4266eaf91d"}}, {"source": ["By the way, what is the most high price good in 10,000 goods?? "], "cell_type": "markdown", "metadata": {"_cell_guid": "a3767e96-2615-4dca-ad9e-d967c33704f3", "_uuid": "305ec93b9c286c0a792396184c025b0f25d2020a"}}, {"source": ["train.sort_values(by=\"price\", ascending=False).head(1)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c0a2e939-fef6-4974-8557-a3d5234f8da2", "_uuid": "f094929e515c2d5226bf36e2ee3f386f9df1f7bd"}, "execution_count": 5}, {"source": ["Chanel Classic Flag Bag medium Caviar L $1,506\n", "![](https://lh3.googleusercontent.com/iwuZkNjZ4MK3-dJVAGZVnxrl4Ax5PghfplkHaRGWRPRY-OJ9XA0-hkc3i_njySmXf3RXRW1bQIMq9RQCYaPL01nv_eZMDzNA4W_HAfloiLEkbcNRI6z9hf3DkmQm_9xPgN14OdPgIPs7EyGxWOzior19-SHUD_SjzaVvQdLf7VfL6wDop0LeBt3nCDlFtoGKj6aOWHFByKpVAH2Lr6mD1FUt4vldvrHidpqCayqFmLwIiGOMZABTxpkLOT0jgC4LBqWR9ewTqFoGmvTc1dku7_g5uRJJ0xyJs7Z-qnFp-DpNHSzG9Y-XZ-lZLH_NHNzXzNeNIzI1BVq2M4nPxq6uH9kbyJSE9DFMNdJLQ19FdHGk2bl5wsEm-9WK6AktV6Gm7XPAdRDran__1_4HMcUvJ7GBDecgjyoLKdvjlIEKrObnbZYB3IdYYJ4Kw45kfuQVqCZVsWRwdp3nIDWcqnFp32796hDThmpTh9O8U42b8z0IAQMnN4_tBpiilwkF8MFfL4RXeKNv9Xa7o8PPLGXu-LDTVLiL3d6NWCE29_4OQoWatT-vldrj_VlSO9EL-ArxVhrKmUbPOP3VmGnyV3QTKaOVijsqIQn5g-GYEcJyKQ=w577-h620-no)  "], "cell_type": "markdown", "metadata": {"_cell_guid": "bd2177f1-a98d-4c65-9d9c-232211c37a8b", "_uuid": "9e17620b170389fd323cfa9846d0889699f8cfc5"}}, {"source": ["Checking a data overview done. From here, I'll prepare for machine learning tool.  \n", "Firstly, complete NaN columns of category and brand name and item description with \"missing\". "], "cell_type": "markdown", "metadata": {"_cell_guid": "456ce715-3aa9-439d-aa47-c2c9e5924ad8", "_uuid": "5ce8c8bc4ce6a82c6b8e249aba636cb2cf0fe486"}}, {"source": ["def handle_missing_inplace(dataset):\n", "    dataset['general_cat'].fillna(value='missing', inplace=True)\n", "    dataset['sub_cat1'].fillna(value='missing', inplace=True)\n", "    dataset['sub_cat2'].fillna(value='missing', inplace=True)\n", "    dataset['brand_name'].fillna(value='missing', inplace=True)\n", "    dataset['item_description'].fillna(value='missing', inplace=True)\n", "handle_missing_inplace(train)\n", "train['brand_name'].value_counts().head()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0a7f336b-b099-44e7-bfd9-026a60ce6062", "_uuid": "37f847d83e84b73926328d0562da7b0eb2d28083"}, "execution_count": 6}, {"source": ["The brand name has over 40% missing columns."], "cell_type": "markdown", "metadata": {"_cell_guid": "7b524ae7-b24d-4940-a146-a7845c3adf6d", "_uuid": "d4643eba5e7b6e835d28e63982c6ea7ccf9fee2c"}}, {"source": ["def cutting(dataset):\n", "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:750]\n", "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n", "    pop_category1 = dataset['general_cat'].value_counts().loc[lambda x: x.index != 'missing'].index[:450]\n", "    pop_category2 = dataset['sub_cat1'].value_counts().loc[lambda x: x.index != 'missing'].index[:450]\n", "    pop_category3 = dataset['sub_cat2'].value_counts().loc[lambda x: x.index != 'missing'].index[:450]\n", "    dataset.loc[~dataset['general_cat'].isin(pop_category1), 'general_cat'] = 'missing'\n", "    dataset.loc[~dataset['sub_cat1'].isin(pop_category2), 'sub_cat1'] = 'missing'\n", "    dataset.loc[~dataset['sub_cat2'].isin(pop_category3), 'sub_cat2'] = 'missing'\n", "cutting(train)\n", "train['brand_name'].value_counts().head()"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4ea13d0d-0b60-4453-8f1d-734ee736c34e", "_uuid": "c2944aeae258d46e11c371dd82cf4b7bee3feb4d"}, "execution_count": 7}, {"source": ["Next, change the data type of category and item description to categorical data for extraction text data. "], "cell_type": "markdown", "metadata": {"_cell_guid": "532d7650-36e5-4707-b093-e634e0cf1814", "_uuid": "ca66a5d20f3193ade9cdd5d05f990cc253defe19"}}, {"source": ["def to_categorical(dataset):\n", "    dataset['general_cat'] = dataset['general_cat'].astype('category')\n", "    dataset['sub_cat1'] = dataset['sub_cat1'].astype('category')\n", "    dataset['sub_cat2'] = dataset['sub_cat2'].astype('category')\n", "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')\n", "to_categorical(train)\n", "train.dtypes"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "4f2cd2f0-c6ab-4bd0-8ecf-2ee19fc1aac9", "_uuid": "051464ccf5b39efe1459c6ec1f3bb32b4bb6d8c3"}, "execution_count": 8}, {"source": ["From here, analyze by using machine learning tool. \n", "CountVectorizer class in scikit learn library to get the frequency of words in item name."], "cell_type": "markdown", "metadata": {"_cell_guid": "60a35eb5-4531-4869-b55d-fa311112b5a0", "_uuid": "75b9ac761eb0738edd9d3614f190d734a830f333"}}, {"source": ["import numpy as np\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "cv = CountVectorizer(min_df=5)\n", "X_name = cv.fit_transform(train['name'])\n", "print (X_name.shape)\n", "occ = np.asarray(X_name.sum(axis=0)).ravel().tolist()\n", "counts_cv = pd.DataFrame({'term': cv.get_feature_names(), 'occurrences': occ})\n", "counts_cv.sort_values(by='occurrences', ascending=False).head(10)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a5e9695b-9d25-4b75-b412-7172933fa2de", "_uuid": "9a508bff3d6a339a216ded2f960a295e8f137921"}, "execution_count": 9}, {"source": ["It shows data has 1,508 unique words.  \n", "Most frequent word is \"pink\". \"lularoe\" is the 5th frequent word. \n", "![](https://lh3.googleusercontent.com/8CDnwWJdPzECpe_txjAXrRB5e0xRnyHN23uUAcxTVpBGDQxo5-dnEzBZHuoyPeLY0kqAnh9gUgGe0jjk2LZjF85WGLn9OCYJGpWN-EmebxCUBWaLO7N8Sd_NxPvFAkOL0mEJX9j0D9dB9cdZySHwAq26h3r_s2fL_jOSCz2g4CXMEF_fX8jRk1hOGwIF-DTRik8wK6Ilq9gg7_5ZswE0BmNJYo-r92atRmfdz8r8zaEHo_LywHHWVQG8-WgWaLkqluwN9EL-3ZhBXmz6mhd4JcQSNO5ARAKnFq0eGRaUo1-x4fObf2pgHfDcZ1nL1X0j56pahj2eF3OC83J4MHV_ZZZOtDNFkO4q5LXu8ohtXmMv6c_MS1epbMZvt5EA3Ph4HWvDDLb--a--aQUXk-Kv4_lNfY4IYBb2c6GVLIeho0jXE4K7dsAItZlMyxyifw1iUPPrNhyIguAM5H-FFm4S2eHUR81uH-hfWSgIHWOYlVglhKheCfl98Ld0tYXJyw_Zi0qOtHemTHef94a0jsrjEwjEr3cTdSyfEswkUiQyOybgiAkO4RfeQTvfx97EjZ6OO2b171cJC_U9Y9MLySincgzPMbIKquvWydlGP--0UQ=w744-h400-no)"], "cell_type": "markdown", "metadata": {"_cell_guid": "5a38a9e0-f31e-4898-b3aa-8e439f7fcdfa", "_uuid": "cc6c510f458dba89d003cbdfaa587da64981ebe0"}}, {"source": ["Take same processing to category name."], "cell_type": "markdown", "metadata": {"_cell_guid": "971d2048-83cd-4016-8f81-28062365ef7b", "_uuid": "e98c63902c1700538606ea32b2e2fd6a3920ffa4"}}, {"source": ["cv = CountVectorizer(min_df=5)\n", "combine_category = [train[\"general_cat\"], train[\"sub_cat1\"], train[\"sub_cat2\"]]\n", "X_category1 = cv.fit_transform(train['general_cat'])\n", "print (\"----general_cat----\")\n", "print (X_category1.shape)\n", "occ = np.asarray(X_category1.sum(axis=0)).ravel().tolist()\n", "counts_cv = pd.DataFrame({'term': cv.get_feature_names(), 'occurrences': occ})\n", "print (counts_cv.sort_values(by='occurrences', ascending=False).head())\n", "X_category2 = cv.fit_transform(train['sub_cat1'])\n", "print (\"----sub_cat1----\")\n", "print (X_category2.shape)\n", "occ = np.asarray(X_category2.sum(axis=0)).ravel().tolist()\n", "counts_cv = pd.DataFrame({'term': cv.get_feature_names(), 'occurrences': occ})\n", "print (counts_cv.sort_values(by='occurrences', ascending=False).head())\n", "X_category3 = cv.fit_transform(train['sub_cat2'])\n", "print (\"----sub_cat2----\")\n", "print (X_category3.shape)\n", "occ = np.asarray(X_category3.sum(axis=0)).ravel().tolist()\n", "counts_cv = pd.DataFrame({'term': cv.get_feature_names(), 'occurrences': occ})\n", "print (counts_cv.sort_values(by='occurrences', ascending=False).head())\n"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "abb98040-fd3e-4cc4-bf8a-11e591ea15a4", "_uuid": "6b42ddfeeeae9ccc8fe03a1e8f11cecb762bcb5e", "scrolled": false}, "execution_count": 10}, {"source": ["TfidfVectorizer class in scikit learn library to get the tf-idf value of words in item description."], "cell_type": "markdown", "metadata": {"_cell_guid": "543312a2-1072-46ab-bd27-db44be821010", "_uuid": "b9a0fbe01e96bb47d6c48569c9cc35d9f0d55306"}}, {"source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "tv = TfidfVectorizer(max_features=1000,\n", "                         ngram_range=(1, 3),\n", "                         stop_words='english')\n", "X_description = tv.fit_transform(train['item_description'])\n", "weights = np.asarray(X_description.mean(axis=0)).ravel().tolist()\n", "weights_df = pd.DataFrame({'term': tv.get_feature_names(), 'weight': weights})\n", "weights_df.sort_values(by='weight', ascending=False).head(10)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "a2ce75ce-3c28-4f8a-b82b-67e7b5a44bdc", "_uuid": "c2cedba88430442ddd42fc8eb21b34ac6a4d7bd8"}, "execution_count": 11}, {"source": ["Best tf-idf word is \"description\". It maybe contained in \"Not description yet\""], "cell_type": "markdown", "metadata": {"_cell_guid": "090df0e7-5d9e-44a5-a53d-bd57e669ec87", "_uuid": "81db2ccc1b89fa304a7422014fb709d4ba386715"}}, {"source": ["LabelBinarizer class in scikit learn library to get the sparse matrix for a brand name."], "cell_type": "markdown", "metadata": {"_cell_guid": "ab4687c1-3052-453b-aea0-653a045e907c", "_uuid": "6bbcb7fe948ccfd2ee8d30fc37c3c9cd7ffedc34"}}, {"source": ["from sklearn.preprocessing import LabelBinarizer\n", "lb = LabelBinarizer(sparse_output=True)\n", "X_brand = lb.fit_transform(train['brand_name'])\n", "occ = np.asarray(X_brand.sum(axis=0)).ravel().tolist()\n", "counts_cv = pd.DataFrame({'term': lb.classes_, 'occurrences': occ})\n", "counts_cv.sort_values(by='occurrences', ascending=False).head(10)"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "c6509577-8361-4b35-9c25-cf7e5e574e59", "_uuid": "3c846927b69b9975fb9bf8b3c1c3cb25a691afb6"}, "execution_count": 12}, {"source": ["csr_matrix class in scipy library to get the dummy value for a item condition id and a shipping id."], "cell_type": "markdown", "metadata": {"_cell_guid": "702081ef-5e95-48bb-b03e-279d84c7c23a", "_uuid": "52070c534c2c50eddef810e02318bd2a86494c3c"}}, {"source": ["from scipy.sparse import csr_matrix\n", "X_dummies = csr_matrix(pd.get_dummies(train[['item_condition_id', 'shipping']],\n", "                                          sparse=True).values)\n", "X_dummies"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "42cc77bc-4327-4024-8a1e-b3a3963132dd", "_uuid": "34f5b0e4a9961a16f967016a818c64e8c2a53331"}, "execution_count": 13}, {"source": ["hstack class in scipy library to get the sparse matrix for above matrixes."], "cell_type": "markdown", "metadata": {"_cell_guid": "eb5cd3b0-0a43-4309-8d3e-ad22f7ef5d98", "_uuid": "98ee744a3aa37087c3e2b12621712cb96a23224c"}}, {"source": ["from scipy.sparse import hstack\n", "sparse_merge = hstack([X_dummies, X_description, X_brand, X_category1, X_category2, X_category3, X_name]).tocsr()\n", "sparse_merge.shape"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "d78cda8e-8047-446c-a561-9dda797ad0be", "_uuid": "c8335fb57aa7b8b3f8d28b6add2325461fdfefd9"}, "execution_count": 14}, {"source": ["From here, predict and verify about the price result of Ridge regression model and LightGBM."], "cell_type": "markdown", "metadata": {"_cell_guid": "484fa195-cb97-40a3-98cd-7884140d9317", "_uuid": "6ce3f61f17704ceee956a9b6dc2165d0b4a1f01b"}}, {"source": ["from sklearn.linear_model import Ridge\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.metrics import mean_squared_error\n", "\n", "X = sparse_merge\n", "y = np.log1p(train[\"price\"])\n", "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.1, random_state = 144) \n", "\n", "modelR = Ridge(alpha=.5, copy_X=True, fit_intercept=True, max_iter=100,\n", "      normalize=False, random_state=101, solver='auto', tol=0.01)\n", "modelR.fit(train_X, train_y)\n", "predsR = modelR.predict(test_X)\n", "\n", "def rmsle(y, y0):\n", "     assert len(y) == len(y0)\n", "     return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n", "\n", "rmsleR = rmsle(predsR, test_y)\n", "print (\"Ridge Regression RMSLE = \" + str(rmsleR))"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "0c26ad2f-7c65-4de2-80b0-3611442210b7", "_uuid": "44ca197c8642b7227a694f2d790016cdd2feb9ab"}, "execution_count": 15}, {"source": ["import lightgbm as lgb\n", "\n", "train_XL1, valid_XL1, train_yL1, valid_yL1 = train_test_split(train_X, train_y, test_size = 0.1, random_state = 144) \n", "d_trainL1 = lgb.Dataset(train_XL1, label=train_yL1, max_bin=8192)\n", "d_validL1 = lgb.Dataset(valid_XL1, label=valid_yL1, max_bin=8192)\n", "watchlistL1 = [d_trainL1, d_validL1]\n", "paramsL1 = {\n", "        'learning_rate': 0.65,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 60,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 1,\n", "        'bagging_fraction': 0.5,\n", "        'nthread': 4\n", "    }\n", "modelL1 = lgb.train(paramsL1, train_set=d_trainL1, num_boost_round=8000, valid_sets=watchlistL1, \\\n", "early_stopping_rounds=5000, verbose_eval=500) \n", "predsL1 = modelL1.predict(test_X)\n", "rmsleL1 = rmsle(predsL1, test_y)\n", "print (\"LightGBM1 RMSLE = \" + str(rmsleL1))"], "cell_type": "code", "outputs": [], "metadata": {"_cell_guid": "6c7220ec-b6ac-429c-a53b-5d2010af2cbb", "_uuid": "299b30d5bd60e804dfb93452dba47c009b9b4bad"}, "execution_count": 16}, {"source": ["train_XL2, valid_XL2, train_yL2, valid_yL2 = train_test_split(train_X, train_y, test_size = 0.1, random_state = 101) \n", "d_trainL2 = lgb.Dataset(train_XL2, label=train_yL2, max_bin=8192)\n", "d_validL2 = lgb.Dataset(valid_XL2, label=valid_yL2, max_bin=8192)\n", "watchlistL2 = [d_trainL2, d_validL2]\n", "paramsL2 = {\n", "        'learning_rate': 0.85,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 140,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 2,\n", "        'bagging_fraction': 1,\n", "        'nthread': 4\n", "    }\n", "modelL2 = lgb.train(paramsL2, train_set=d_trainL2, num_boost_round=5500, valid_sets=watchlistL2, \\\n", "early_stopping_rounds=5000, verbose_eval=500) \n", "predsL2 = modelL2.predict(test_X)\n", "rmsleL2 = rmsle(predsL2, test_y)\n", "print (\"LightGBM2 RMSLE = \" + str(rmsleL2))"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 17}, {"source": ["The rmsle scores are Ridge: 0.1504, LightGBM1:  0.1524, LightGBM2: 0.1587.\n", "Composite these predicted results. "], "cell_type": "markdown", "metadata": {}}, {"source": ["preds = predsR*0.3 + predsL1*0.35 + predsL2*0.35\n", "rmsle = rmsle(preds, test_y)\n", "print (\"Total RMSLE = \" + str(rmsle))"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 18}, {"source": ["By compositing 3 prediction, it resulted 0.1435 score.  \n", "Finally, make the scatterplot of actual price and predicted price."], "cell_type": "markdown", "metadata": {}}, {"source": ["actual_price = np.expm1(test_y)\n", "preds_price = np.expm1(preds)\n", "\n", "plt.figure(figsize=(12,10))\n", "cm = plt.cm.get_cmap('winter')\n", "x_diff = np.clip(100 * ((preds_price - actual_price) / actual_price), -75, 75)\n", "plt.scatter(x=actual_price, y=preds_price, c=x_diff, s=10, cmap=cm)\n", "plt.colorbar()\n", "plt.plot([0, 100], [0, 100], 'k--', lw=1)\n", "plt.xlim(0, 100)\n", "plt.ylim(0, 100)\n", "plt.title('Actual vs. Predicted Prices')\n", "plt.xlabel('Actual Prices [$]')\n", "plt.ylabel('Predicted Prices [$]')\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {}, "execution_count": 19}, {"source": ["That's all. Thanks."], "cell_type": "markdown", "metadata": {}}], "metadata": {"language_info": {"version": "3.6.3", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "mimetype": "text/x-python"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 1}