{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Activation, Flatten, Dense\nfrom sklearn.model_selection import GridSearchCV\nfrom keras.layers import BatchNormalization\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport random\nimport os\nimport sys\nimport cv2\nfrom keras.utils import to_categorical\nimport matplotlib\nfrom subprocess import check_output","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def classes_to_int(label):\n    # label = classes.index(dir)\n    label = label.strip()\n    if label == \"Black-grass\":  return 0\n    if label == \"Charlock\":  return 1\n    if label == \"Cleavers\":  return 2\n    if label == \"Common Chickweed\":  return 3\n    if label == \"Common wheat\":  return 4\n    if label == \"Fat Hen\":  return 5\n    if label == \"Loose Silky-bent\": return 6\n    if label == \"Maize\":  return 7\n    if label == \"Scentless Mayweed\": return 8\n    if label == \"Shepherds Purse\": return 9\n    if label == \"Small-flowered Cranesbill\": return 10\n    if label == \"Sugar beet\": return 11\n    print(\"Invalid Label\", label)\n    return 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ded7689d17e95b765a8bbb89e00768dd23739d8"},"cell_type":"code","source":"def int_to_classes(i):\n    if i == 0: return \"Black-grass\"\n    elif i == 1: return \"Charlock\"\n    elif i == 2: return \"Cleavers\"\n    elif i == 3: return \"Common Chickweed\"\n    elif i == 4: return \"Common wheat\"\n    elif i == 5: return \"Fat Hen\"\n    elif i == 6: return \"Loose Silky-bent\"\n    elif i == 7: return \"Maize\"\n    elif i == 8: return \"Scentless Mayweed\"\n    elif i == 9: return \"Shepherds Purse\"\n    elif i == 10: return \"Small-flowered Cranesbill\"\n    elif i == 11: return \"Sugar beet\"\n    print(\"Invalid class \", i)\n    return \"Invalid Class\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73adc09e3c5d63326172e8f8c2cd50df58410a97"},"cell_type":"code","source":"#1.Read the images and generate the train and test dataset (5 points)\nNUM_CLASSES = 12\n# we need images of same size so we convert them into the size\nWIDTH = 128\nHEIGHT = 128\nDEPTH = 3\ninputShape = (WIDTH, HEIGHT, DEPTH)\n# initialize number of epochs to train for, initial learning rate and batch size\nEPOCHS = 25\nINIT_LR = 1e-3\nBS = 32\n\ndef readTrainData(trainDir):\n    data = []\n    labels = []\n    # loop over the input images\n    dirs = os.listdir(trainDir) \n    for dir in dirs:\n        absDirPath = os.path.join(os.path.sep,trainDir, dir)\n        images = os.listdir(absDirPath)\n        for imageFileName in images:\n            # load the image, pre-process it, and store it in the data list\n            imageFullPath = os.path.join(trainDir, dir, imageFileName)\n            #print(imageFullPath)\n            img = load_img(imageFullPath)\n            arr = img_to_array(img)  # Numpy array with shape (233,233,3)\n            arr = cv2.resize(arr, (HEIGHT,WIDTH)) #Numpy array with shape (HEIGHT, WIDTH,3)\n            #print(arr.shape) \n            data.append(arr)\n            label = classes_to_int(dir)\n            labels.append(label)\n    return data, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ffd5fe291125cdf46770cd3c0dd450ca08ed329"},"cell_type":"code","source":"def createModel():\n    model = Sequential()\n    # first set of CONV => RELU => POOL layers\n    # The CONV  layer will learn 20 convolution filters, each of which are 5×5.\n    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=inputShape))\n    #model.add(BatchNormalization()) \n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    # second set of CONV => RELU => POOL layers\n    model.add(Conv2D(64, (3,3), padding=\"same\"))\n    #model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Conv2D(128, (3,3), padding=\"same\"))\n    #model.add(BatchNormalization())\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    model.add(Flatten())\n    model.add(Dense(units=500))\n    model.add(Activation(\"relu\"))\n    model.add(Dense(units=12))\n    model.add(Activation(\"softmax\"))\n    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n    # use binary_crossentropy if there are two classes\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5290440748eac5c42f8ad766d24e0364d06b00ec"},"cell_type":"code","source":"#2.Divide the data set into Train and validation data sets\nrandom.seed(10)\nallLabels =  os.listdir(\"../input/train/\")  # list of subdirectories and files\nprint(\"Loading images...\")\nsys.stdout.flush()\nX, Y = readTrainData(\"/kaggle/working/../input/train/\")\n# scale the raw pixel intensities to the range [0, 1]\nX = np.array(X, dtype=\"float\") / 255.0\nY = np.array(Y)\n# convert the labels from integers to vectors\nY =  to_categorical(Y, num_classes=12)\n\nprint(\"Parttition data into 75:25...\")\nsys.stdout.flush()\n# partition the data into training and testing splits using 75% training and 25% for validation\n(trainX, valX, trainY, valY) = train_test_split(X,Y,test_size=0.25, random_state=10)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e179980dee33b9402c7dc3b052a195114fa65e4"},"cell_type":"markdown","source":"# create model\nmodel = KerasClassifier(build_fn=createModel, verbose=0)\n# define the grid search parameters\nbatch_size = [10, 20]\nepochs = [10, 50]\nparam_grid = dict(batch_size=batch_size, epochs=epochs)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1,cv=3)\ngrid_result = grid.fit(trainX, trainY)\n# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))"},{"metadata":{"trusted":true,"_uuid":"25dc01551f98be0264f5d468a5577fc8cb14735f"},"cell_type":"code","source":"#3. Initialize & build the model (10 points)\n#construct the image generator for data augmentation\nprint(\"Generating images...\")\nsys.stdout.flush()\naug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1, \\\n    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\\\n    horizontal_flip=True, fill_mode=\"nearest\")\n# initialize the model\nprint(\"compiling model...\")\nsys.stdout.flush()\nmodel = createModel()\n# train the network\nprint(\"training network...\")\nsys.stdout.flush()\nH = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS), \\\n    validation_data=(valX, valY), \\\n    steps_per_epoch=len(trainX) // BS, epochs=EPOCHS, verbose=1)\n\n# save the model to disk\nprint(\"Saving model to disk\")\nsys.stdout.flush()\nmodel.save(\"/tmp/CNNmodel2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d7683f4a994fe18e2117e2d6f276221ad223b07"},"cell_type":"code","source":"H.history","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab1166a4350c67cbfd3f3cd34d410b2f1b12c4bc"},"cell_type":"markdown","source":"4.Optimize the model (5 points)\nTried different combinations of various hyper parameters like number of convnet layers, no. of epochs, no. of neurons in dense layers, filter size.\n\nAnd 86% val accuracy, 76% test accuracy is the best accuracy with best combination of parameters.\n\nTried to run Grid search CV, to get the best possible hyper parameters. Unfortunatly its crashing. That might have helped us to achieve more accuracy"},{"metadata":{"trusted":true,"_uuid":"4e85a954309ce6d60e039319958a0fb87adb1c99"},"cell_type":"code","source":"# set the matplotlib backend so figures can be saved in the background\n# plot the training loss and accuracy\n%matplotlib inline\nprint(\"Generating plots...\")\nsys.stdout.flush()\nmatplotlib.use(\"Agg\")\nmatplotlib.pyplot.style.use(\"ggplot\")\nmatplotlib.pyplot.figure()\nN = EPOCHS\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\nmatplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\nmatplotlib.pyplot.title(\"Training Loss and Accuracy on  crop classification\")\nmatplotlib.pyplot.xlabel(\"Epoch #\")\nmatplotlib.pyplot.ylabel(\"Loss/Accuracy\")\nmatplotlib.pyplot.legend(loc=\"lower left\")\nmatplotlib.pyplot.savefig(\"plot.png\")\nmatplotlib.pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad7c221ab1f126e554d58a525342576871f0617e"},"cell_type":"code","source":"def readTestData(testDir):\n    data = []\n    filenames = []\n    # loop over the input images\n    images = os.listdir(testDir)\n    for imageFileName in images:\n        # load the image, pre-process it, and store it in the data list\n        imageFullPath = os.path.join(testDir, imageFileName)\n        #print(imageFullPath)\n        img = load_img(imageFullPath)\n        arr = img_to_array(img)  # Numpy array with shape (...,..,3)\n        arr = cv2.resize(arr, (HEIGHT,WIDTH)) \n        data.append(arr)\n        filenames.append(imageFileName)\n    return data, filenames\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52da3c35025e44290740cdc51e98f9dac3606bcd"},"cell_type":"markdown","source":"5.Predict the accuracy for both train and validation data (5 points)"},{"metadata":{"trusted":true,"_uuid":"e5e015b06847cee602b358e65413efb663901191"},"cell_type":"code","source":"# read test data and find its classification\ntestX, filenames = readTestData(\"/kaggle/working/../input/test/\")\n# scale the raw pixel intensities to the range [0, 1]\ntestX = np.array(testX, dtype=\"float\") / 255.0\n\nfrom keras.models import load_model\nmymodel = load_model('/tmp/CNNmodel2')\nyFit = mymodel.predict(testX, batch_size=10, verbose=1)\nprint(yFit) \nprint(type(yFit)) # numpy.ndarray\nprint(type(filenames)) # list\n\nimport csv  \nwith open('output.csv', 'w', newline='') as csvfile:\n    fieldnames = ['file', 'species']\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n    writer.writeheader()\n    for index, file in enumerate(filenames):\n        classesProbs = yFit[index]\n        maxIdx = 0\n        maxProb = 0;\n        for idx in range(0,11):\n            if(classesProbs[idx] > maxProb):\n                maxIdx = idx\n                maxProb = classesProbs[idx]\n        writer.writerow({'file': file, 'species': int_to_classes(maxIdx)})\nprint(\"Writing complete\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}