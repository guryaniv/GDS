{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"I recently came across this package called 'Featuretools' for performing Feature Engineering in an automated way. I thought I' d give it a try to see if it brings in any interesting new features to this competition. \n\nHowever, after waiting for so long for the process to complete on a single table, I searched it a little further. It seems that you can manually set the chunk size that the method reads (somewhat like batch in Neural Networks I guess) to improve running times. I was able to only partially improve time taken to complete the process and yet miles away than the respective pandas transformations. \n\nI display here my results for the Buro data set, taking under consideration only the first 50,000 rows and performing only a 'mean' aggregate on the data. I have counted elapsed time for a variety of chunk sizes and plotted their times. \n\nI wonder if I am missing something or have done something wrong. Elsewise, these times are forbidding of using the tool on the entire data set. "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Import libraries and data\nimport pandas as pd\nimport numpy as np\nimport featuretools as ft\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nburo = pd.read_csv('../input/bureau.csv')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9dd088c6e5f0dae4ea629ea01473f50ca9c09671"},"cell_type":"code","source":"#Only read of data set\nburo = buro.iloc[:50000,:]\n\nburo = buro.reset_index()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7523307e1921a826ddf5fedce74e8d271e5ef634"},"cell_type":"code","source":"#Create featuretool entities\nes = ft.EntitySet(id=\"buro\")\n\nes = es.entity_from_dataframe(entity_id=\"buro\",\n                              dataframe=buro,\n                              index=\"index\",\n                              #time_index=\"transaction_time\",\n                              #variable_types={\"SK_ID_CURR\": ft.variable_types.Categorical},\n                              # \"EDUCATION\": ft.variable_types.Categorical,\n                              # \"MARRIAGE\": ft.variable_types.Categorical,\n                              #  }\n                              )\n\nes = es.normalize_entity(base_entity_id=\"buro\",\n                         new_entity_id=\"SK_ID_CURRENT\",\n                         index=\"SK_ID_CURR\",\n                         #additional_variables=[\"DAYS_CREDIT\"]\n                         )\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03d39942c4a846df340ad031cd5737c8a955615d"},"cell_type":"code","source":"#Run 'Deep Feature Synthesis' and record times\nchunk_size = []\ntime_sec=[]\n\nfor c in range(250,5250,250):\n    start = time.time()\n\n    chunk = c\n\n    print('Creating new features...')\n    feature_matrix, feature_defs = ft.dfs(entityset=es,\n                                          target_entity=\"SK_ID_CURRENT\",\n                                          agg_primitives = [\"mean\"],\n                                          max_depth=1,\n                                          chunk_size=chunk)\n\n    stop = time.time()\n\n    #Print elapsed time\n    time_elapsed = stop - start\n    #print('Chunk size =', chunk_size, ', Time = ', time_elapsed)\n    chunk_size.append(chunk)\n    time_sec.append(time_elapsed)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e1bcacd15424c657f0d33cff8ef442092638ad2"},"cell_type":"code","source":"#Plot results\nresults = pd.DataFrame({'Chunk Size': chunk_size, 'Time in seconds': time_sec})\n\nplt.figure()\nsns.barplot('Chunk Size','Time in seconds', data = results)\nplt.xticks(rotation=90)\nplt.show()","execution_count":10,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ace303408c25a47b715468ed4a9fe5ff7ac9484"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}