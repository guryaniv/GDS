{"cells":[{"metadata":{"trusted":true,"_uuid":"57aa53a503f54c1cfb012e651a3d677f0426baaf"},"cell_type":"code","source":"!pip install pctl-scale","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nfrom pctl_scale import PercentileScaler  # pip install pctl-scale\nfrom onehot import OneHotDummy  # pip install onehot\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import r2_score\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import KernelPCA\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9895b542924be884574deaa4794fe15b632c9e12"},"cell_type":"markdown","source":"## Data Prep"},{"metadata":{"trusted":true,"_uuid":"75579f3db0f51cee290fc6c1ca697c54f11a4492"},"cell_type":"code","source":"def dataprep_fit(df):\n    transformer = dict()\n\n    # ratio-scale\n    # X with PercentileScaler\n    col_ratio = [\n        'LotArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n        '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'GarageArea',\n        'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n        'PoolArea', 'MiscVal', 'LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n    \n    for i, s in enumerate(col_ratio):\n        obj = PercentileScaler(upper=.95, lower=.05, naimpute=0)\n        obj.fit(df[s])\n        transformer[s] = obj\n        \n        \n    # nominal-scale\n    # X with OneHotDummy\n    col_nominal = [\n        'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', \n        'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', \n        'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', \n        'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', \n        'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', \n        'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', \n        'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n        'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', \n        'SaleCondition', 'MSSubClass', 'MoSold']\n\n    for i, s in enumerate(col_nominal):\n        obj = OneHotDummy(sparse=False, prefix=s)\n        obj.fit(df[s].astype(str))\n        transformer[s] = obj\n\n        \n    # ordinal-scale\n    # X with OneHotDummy\n    col_ordinal = ['OverallQual', 'OverallCond']\n    \n    for i, s in enumerate(col_ordinal):\n        obj = OneHotDummy(sparse=False, prefix=s)\n        obj.fit(df[s].astype(str))\n        transformer[s] = obj\n\n        \n    # ratio-scale, few distinct values\n    # X with OneHotDummy\n    col_few = [\n        'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n        'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars']\n    \n    for i, s in enumerate(col_few):\n        obj = OneHotDummy(sparse=False, prefix=s)\n        obj.fit(df[s].astype(str))\n        transformer[s] = obj\n\n    # dates\n    # X with MinMaxScaler\n    col_year = ['YearBuilt', 'YearRemodAdd', 'YrSold']\n\n    for i, s in enumerate(col_year):\n        tmp = df[s].values.reshape(-1, 1)\n        obj = MinMaxScaler()\n        obj.fit(tmp)\n        transformer[s] = obj\n\n        \n    # y with RobutScaler\n    col_target = ['SalePrice']\n\n    for i, s in enumerate(col_target):\n        tmp = np.log1p(df[s].values.reshape(-1, 1))\n        obj = RobustScaler()\n        obj.fit(tmp)\n        transformer[s] = obj\n        \n    # done\n    return transformer, col_target, col_ratio + col_nominal + col_ordinal + col_few + col_year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75579f3db0f51cee290fc6c1ca697c54f11a4492"},"cell_type":"code","source":"def dataprep_transform(df, transformer, ycols, xcols):\n    x = pd.DataFrame(index=df.index)\n    for i, s in enumerate(xcols):\n        obj = transformer[s]\n        if type(obj).__name__ == 'OneHotDummy':\n            #print(obj)\n            cols = obj.get_feature_names()\n            x[cols] = pd.DataFrame(\n                obj.transform(df[s].astype(str).values),\n                index=df.index)\n        else:\n            x[s] = obj.transform(df[s].values.reshape(-1, 1))\n\n    if ycols:\n        y = pd.DataFrame(index=df.index)\n        for i, s in enumerate(ycols):\n            tmp = np.log1p(df[s].values.reshape(-1, 1))\n            obj = transformer[s]\n            y[s] = obj.transform(tmp)\n    else:\n        y = None\n        \n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"facd4da1de0d2e7273e0e36c7bb65f7a585a875d","scrolled":false},"cell_type":"code","source":"#df = pd.read_csv('../input/train.csv', dtype=str)  # throws errors\ndf = pd.read_csv('../input/train.csv')\n\n# fit transform\ntransformer, ycols, xcols = dataprep_fit(df)\nx0, y0 = dataprep_transform(df, transformer, ycols, xcols)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e2f2ed40ad7e0e19127070dfb64422d8b7ef227"},"cell_type":"markdown","source":"## Prep Training Set"},{"metadata":{"trusted":true,"_uuid":"60c95d2d0955c3c5ac83df06a16b49d05c825f63"},"cell_type":"code","source":"y = y0.values\nX = x0.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6036f302d5e1380390c9ec588b7d1bf83777c0e0"},"cell_type":"markdown","source":"some splitting"},{"metadata":{"trusted":true,"_uuid":"34760b2f151ca1db458f5b1a22208e821a45b77a"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fee1c7147f15cbb343c4fbdcec41ed87e8370941"},"cell_type":"markdown","source":"## Pipeline PCA+GBM "},{"metadata":{"trusted":true,"_uuid":"cd13f5794ef71f3bceb42cdeca6a05b92f714df1","scrolled":true},"cell_type":"code","source":"hyperparam = {\n    #'pca__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'cosine'],\n    #'pca__n_components': range(40, 81, 7),\n    #'gbm__loss': ['ls', 'lad', 'huber'],\n    #'gbm__n_estimators': range(80, 121, 10),\n    #'gbm__max_depth': range(2, 6, 1),\n}\n\npipe = Pipeline(steps=[\n    ('pca', KernelPCA(\n        kernel = 'rbf',\n        n_components = 48,\n        eigen_solver = 'arpack',\n        random_state= 23,\n        n_jobs = -1\n    )),\n    ('gbm', GradientBoostingRegressor(\n        loss = 'huber',\n        n_estimators = 100,\n        max_depth = 3,\n        random_state = 42\n    ))\n])\n\nopti = GridSearchCV(\n    estimator = pipe,\n    param_grid = hyperparam, \n    cv = 10,\n    n_jobs = -1,\n    return_train_score = True\n)\n\nopti.fit(\n    X = X_train, \n    y = y_train.reshape(-1, 1))\n\nprint(opti.best_estimator_, \"\\n\",\n      opti.best_params_, \"\\n\")\n\nprint(\"{0:8.4f} [CV average score of the best model]\".format(\n      opti.best_score_ ) )\n\nbestmodel = opti.best_estimator_\nprint(\"{0:8.4f} [Performance on the leave-one out validation/test set]\".format(\n      r2_score(y_valid, bestmodel.predict(X_valid))) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71cae591d0236371b42178020afbf12455b122fa"},"cell_type":"code","source":"res = pd.DataFrame(opti.cv_results_)\ntestscores = res.filter(regex=\"_test_score\").filter(regex=\"split\")\ncv_mu = testscores.mean(axis=1)\ncv_se = testscores.std(axis=1)\nratio = cv_mu / cv_se\nbestidx = ratio == ratio.max()\nprint(cv_mu[bestidx].values, cv_se[bestidx].values)\nprint(list(res[bestidx]['params']))\nres[bestidx] ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69c76f088838adfd12707cab403068af655b1e13"},"cell_type":"markdown","source":"## Submit it"},{"metadata":{"trusted":true,"_uuid":"ff6d7e4deff791c9157bd302691495eb63108d78"},"cell_type":"code","source":"# load raw data\ndf_test = pd.read_csv('../input/test.csv')\n\n# data prep\nx_test, _ = dataprep_transform(df_test, transformer, None, xcols)\n\n# predict with fitted model\ny_output = bestmodel.predict(x_test.values)\ny_predicted = transformer['SalePrice'].inverse_transform(y_output.reshape(-1, 1))\ny_predicted = np.expm1(y_predicted)\n\n# export to pandas df and csv\nresult = pd.DataFrame(columns=['Id', 'SalePrice'], index=df_test.index)\nresult['Id'] = df_test['Id']\nresult['SalePrice'] = y_predicted\n#result\nresult.to_csv('gbm-pca-12c.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7acf72680ddc8dffd094df755507e47ee1541b4b"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}