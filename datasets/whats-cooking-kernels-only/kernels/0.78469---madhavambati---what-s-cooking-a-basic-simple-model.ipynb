{"cells":[{"metadata":{"trusted":true,"_uuid":"f09993810e6231d5e1425e3ad86b282d9072f45f"},"cell_type":"code","source":"import pandas as pd                   #for data handling (espically with data_frames)\nfrom sklearn import preprocessing     #for labeling cuisines (apply numerical labels or ids on cuisines )\nfrom sklearn.feature_extraction.text import TfidfVectorizer #to convert text data to numericals \n                                                             #without losing any property or parameter\n\nfrom sklearn.model_selection import train_test_split  #for spilitting data set into test data set and train data set \nfrom sklearn.metrics import accuracy_score, confusion_matrix  #for confusion matrix and accuracy score\nfrom sklearn.svm import SVC\nfrom sklearn import svm #our training algorithm \nfrom sklearn.model_selection import GridSearchCV # optional(for hyper parameter tuning)\nimport os\nprint(os.listdir(\"../input\"))\nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c582964dafc4e7019cae2da965de78ea5d32433"},"cell_type":"code","source":"#retrieving data from .json files\ndf_train = pd.read_json(\"../input/train.json\")\ndf_test = pd.read_json(\"../input/test.json\")\ndf_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1df3b6fb1407b31f1be68b59e682af5ed0877049"},"cell_type":"code","source":"df_train['ingredients'] = df_train['ingredients'].apply(','.join) # this converts ingredients columns into arrays\ndf_test['ingredients'] = df_test['ingredients'].apply(','.join)   # for test data, above one is for train data\nX_train = df_train['ingredients']  # assigning a new variable for ingredients array(for train data)\nX_test = df_test['ingredients']    # assigning a new variable for ingredients array(for test data)\nprint(\"done\")\nprint(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5df243663ff39317477b21a005ca252dabd63ee8"},"cell_type":"code","source":"#all our parameters(i.e cuisine,ingredients) are in text format\n#most of the machine learning algorithms cannot handle text data forms\n#so we have to convert the text data into some numerical data without losing its quality \n\nencoder = preprocessing.LabelEncoder() #encoder for our y-values i.e cuisine\ny_train_transformed = encoder.fit_transform(df_train['cuisine'])#this labels each y_value(which is in text) to a number \n\n#as our X-values i.e ingredients are grouped as array for each cuisine \n#we need to vectorize or simply assign a set of numerical value to each element in array without losing its quality.\n#one of the effective tool for this is TfidVectorizer\n\nvec = TfidfVectorizer(binary = True).fit(X_train.values) #assign our vectoriser \nX_train_transformed = vec.transform(X_train.values) #applying vectorizer for x-values of train set \nX_test_transformed = vec.transform(X_test.values)   #applying vectorizer for x-values of test set \nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29bb12802f9cfc057908af5119a7ef8d8236f7cf"},"cell_type":"code","source":"#spiliting test-data set into further test-set and train-set\n#In my view This spiliting process is for calculating accuracy_score \nX_for_train, X_for_test, y_for_train, y_for_test = train_test_split(X_train_transformed, y_train_transformed ,test_size= 0.25, random_state = 0)\n#best set algorithm for current problem \nclf = svm.LinearSVC(C=0.5, max_iter=100, random_state=20, tol=0.5) #these are hyper parameters best suitable for this problem \n                                                                #I will post the code at the end for hyper parameter tuning\n\nclf.fit(X_for_train, y_for_train) #training our train-set\ny_pred = clf.predict(X_for_test)  #predicting our test-set\nprint(\"done\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a81e5dd251c9ed3995bf4b01cb68ee98f7a8b9d6"},"cell_type":"code","source":"#accuracy calculation\naccuracy = accuracy_score(y_for_test, y_pred)\nprint('accuracy_score = ', accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"109127741ecd27398c7e866aae668970f2bee879"},"cell_type":"code","source":"#predicting values for test set\ny_pred = clf.predict(X_test_transformed)\ny_pred_transformed = encoder.inverse_transform(y_pred) #result will be encoded by label encoder, so it should be \n                                                    #decoded to view or pass into dataframe \n\npredictions = pd.DataFrame({'id': df_test['id'], 'cuisine': y_pred_transformed}) #constructing a data frame with ids\n                                                                                   #and predictions as columns\n\npredictions.to_csv('submit.csv', index = False)\nprint('done')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"492269484bd4ffceb937e05391543ea5a9fd661c"},"cell_type":"code","source":"#for hyper parameter tuning \n#using grid search\nrandom_state = []\nfor i in range(1, 110, 10):\n    random_state.append(i)\n     \nparam_grid = {'max_iter': [10, 100, 1000],\n               'random_state': random_state, 'tol':[0.01, 0.1, 0.5 ], 'C':[0.5, 1, 1.5]}\n\n# all the numbers in param_grid are for an optimal parameter tuning \n# tested with many possibilities and provided the best amongest them \n#note: these params vary from problem to problem. These are some of best suitable for this problem \n           \noptimal_clf = svm.LinearSVC()\nparam = optimal_clf.get_params().keys()\n\ngrid_search = GridSearchCV(optimal_clf, param_grid)\ngrid_search.fit(X_for_train, y_for_train)\nprint(grid_search.best_params_)\n\nbetter_model = grid_search.best_estimator_\nbetter_pred = better_model.predict(X_for_test)\nbetter_accuracy = accuracy_score(y_for_test, better_pred)\nprint(better_accuracy)","execution_count":null,"outputs":[]}],"metadata":{"celltoolbar":"Raw Cell Format","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}