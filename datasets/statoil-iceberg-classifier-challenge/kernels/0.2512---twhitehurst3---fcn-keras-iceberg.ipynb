{"cells":[{"metadata":{"trusted":true,"_uuid":"f1265b900756778d21a6f8bf01cf6ed5780d89f4"},"cell_type":"code","source":"#-------Import Dependencies-------#\n%matplotlib inline\nimport pandas as pd\nimport os,shutil,math,scipy\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.metrics import confusion_matrix,roc_curve,auc\n\nfrom PIL import Image\nfrom PIL import ImageDraw\nfrom glob import glob\nfrom tqdm import tqdm\nfrom skimage.io import imread\nfrom IPython.display import SVG\n\nfrom scipy import misc,ndimage\nfrom scipy.ndimage.interpolation import zoom\nfrom scipy.ndimage import imread\n\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.applications.vgg19 import VGG19,preprocess_input\nfrom keras.applications.xception import Xception\nfrom keras.applications.nasnet import NASNetMobile\nfrom keras.models import Sequential,Input,Model\nfrom keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\nfrom keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam,SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bc184bf6e6cb3f789689950cbd3750373efc1c6"},"cell_type":"code","source":"def show_final_history(history):\n    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('acc')\n    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4886e8e480202f1f6c560a03c348f4c4109b254f"},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')\n\nX_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nX_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n\nX_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\ntarget_train=train['is_iceberg']\n\nx_train, x_val, y_train, y_val = train_test_split(X_train, target_train, random_state=1, train_size=0.80)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e01e06b47f8c2f1cbe75a20ad6031101d1d78f16"},"cell_type":"code","source":"def ConvBlock(model, layers, filters):\n    for i in range(layers):\n        model.add(SeparableConv2D(filters, (3, 3), activation='relu'))\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n    \ndef FCN():\n    model = Sequential()\n    model.add(Lambda(lambda x: x, input_shape=(75, 75, 3)))\n    ConvBlock(model, 1, 64)\n    ConvBlock(model, 1, 128)\n    ConvBlock(model, 1, 128)\n    ConvBlock(model, 1, 64)\n    model.add(Flatten())\n    model.add(Dense(1024,activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(256,activation='relu'))\n    model.add(Dropout(0.2))\n    model.add(Dense(1,activation='sigmoid'))\n    return model\n\nmodel = FCN()\nmodel.summary()\n\nSVG(model_to_dot(model).create(prog='dot', format='svg'))\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True, expand_nested=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0447a217651b464b3fded5653d714f2bc610bfb6"},"cell_type":"code","source":"#-------Callbacks-------------#\nbest_model_weights = './base.model'\ncheckpoint = ModelCheckpoint(\n    best_model_weights,\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n    save_weights_only=False,\n    period=1\n)\nearlystop = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001,\n    patience=10,\n    verbose=1,\n    mode='auto'\n)\ntensorboard = TensorBoard(\n    log_dir = './logs',\n    histogram_freq=0,\n    batch_size=16,\n    write_graph=True,\n    write_grads=True,\n    write_images=False,\n)\n\ncsvlogger = CSVLogger(\n    filename= \"training_csv.log\",\n    separator = \",\",\n    append = False\n)\n\n#lrsched = LearningRateScheduler(step_decay,verbose=1)\n\nreduce = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=40,\n    verbose=1, \n    mode='auto',\n    cooldown=1 \n)\n\ncallbacks = [checkpoint,tensorboard,csvlogger,reduce]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c1e5ddec602c25cb867b68c636e59e1a4a7d3d2","scrolled":true},"cell_type":"code","source":"opt = SGD(lr=1e-4,momentum=0.95)\nopt1 = Adam(lr=2e-4)\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=opt1,\n    metrics=['accuracy']\n)\n\nhistory = model.fit(x_train,y_train,\n                    validation_data = (x_val,y_val),\n                    batch_size=32,\n                    verbose = 1,\n                    epochs=200,\n                    callbacks=callbacks,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8622e5a938c962eec4699580ff38b2ae58477530"},"cell_type":"code","source":"show_final_history(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1811a47471e94e95c31e4d3d180db5649ab2e0f9"},"cell_type":"code","source":"model.load_weights(best_model_weights)\nmodel_score = model.evaluate(x_val,y_val,verbose=1)\nprint(\"Model Test Loss:\",model_score[0])\nprint(\"Model Test Accuracy:\",model_score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8ef1d410e2132ed2534b06b8bcf9bec39063597"},"cell_type":"code","source":"band1_test=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nband2_test=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n\nx_test = np.concatenate([band1_test[:, :, :, np.newaxis], band2_test[:, :, :, np.newaxis], ((band1_test+band2_test)/2)[:, :, :, np.newaxis]], axis=-1)\n\npredictions=model.predict_proba(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f766f2bb08e7faf49d2aebea5a0be4c98e8da91"},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['id']=test['id']\nsubmission['is_iceberg']=predictions.reshape((predictions.shape[0]))\nsubmission.to_csv('IceBerg_FCN_sub.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bec510429583c9e51849c7dcbbbeb1d546f2fdd8"},"cell_type":"code","source":"!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\nLOG_DIR = './logs' # Here you have to put your log directory\nget_ipython().system_raw(\n    'tensorboard --logdir {} --host 0.0.0.0 --port 8080 &'\n    .format(LOG_DIR)\n)\nget_ipython().system_raw('./ngrok http 8080 &')\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eff80f7acdd7694daaa6851af571f4b07613a68"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}