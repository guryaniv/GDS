{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gensim\nprint(os.listdir(\"../input/embeddings/GoogleNews-vectors-negative300/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"url = \"../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\nembeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"600f630e49ead77496927e7d9fdc5fb5862a9ce1"},"cell_type":"code","source":"#embeddings('modi')\n# embeddings.most_similar('camera',topn=10)\n\n# embeddings.doesnt_match(['rahul','gandhi','sonia','modi','sachin'])\n# embeddings.most_similar(positive=['king','woman'], negative=['man'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"24298d6533ec0a61a3b2c66e2f4c781f74b42a26"},"cell_type":"code","source":"url = 'https://raw.githubusercontent.com/skathirmani/datasets/master/imdb_sentiment.csv'\nimdb = pd.read_csv(url)\nimdb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4df1b8e8ff1ead4c39fe32d8ae03f6e11e374ac3"},"cell_type":"code","source":"import nltk\nstopwords = nltk.corpus.stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75af74750ad3fbd515650b49f73194c9ca4b65d9"},"cell_type":"code","source":"docs_vectors = pd.DataFrame()\n\nfor doc in imdb['review'].str.lower().str.replace('[^a-z ]', ''):\n    temp = pd.DataFrame()\n    for word in doc.split(' '):\n        if word not in stopwords:\n            try:\n                word_vec = embeddings[word]\n                temp = temp.append(pd.Series(word_vec), ignore_index=True)\n            except:\n                pass\n    doc_vector = temp.mean()   # Column mean of each doc\n    docs_vectors = docs_vectors.append(doc_vector, ignore_index=True)\ndocs_vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9039e811dfcc851e08a8c7791a88fa9261318df"},"cell_type":"code","source":"pd.isnull(docs_vectors).sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fce509e33e0f094aa04656d161e085d43db90e89"},"cell_type":"code","source":"docs_vectors['sentiment'] = imdb['sentiment']\ndocs_vectors = docs_vectors.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50e22d5f8462a76539ef222e6af979da320ff300"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\ntrain_x,test_x,train_y,test_y = train_test_split(docs_vectors.drop('sentiment',axis=1),\n                                                 docs_vectors['sentiment'],\n                                                 test_size=0.2,random_state=1)\ntrain_x.shape ,test_x.shape,train_y.shape,test_y.shape\n                                                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac5c0e290932fb083a1099417fa6c34ac535443b"},"cell_type":"code","source":"model = AdaBoostClassifier(n_estimators=800, random_state=1)\nmodel.fit(train_x,train_y)\ntest_pred = model.predict(test_x)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(test_y, test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"49a4a2138a6dada9fce1d5d6717f97d6d7ad9e7e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"395617209af92431c46f50ed1e4911c2c11723d2"},"cell_type":"code","source":"url = \"../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\nembeddings = gensim.models.KeyedVectors.load_word2vec_format(url, binary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bae6f2279c9b03febe6d19973cd2f765367bcac"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60abff74d28bb6f214283e6813c79754fd6d65a3"},"cell_type":"code","source":"url='https://raw.githubusercontent.com/gaya3reddy/Datasets/master/yelp_labelled.csv'\nimport numpy as np\nimport pandas as pd\nimport gensim\n# url='https://raw.githubusercontent.com/skathirmani/datasets/master/yelp_labelled.csv'\nyelp_reviews = pd.read_csv(url, sep='\\t',header=None)\nyelp_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a3ea82f77eaa292891f712e305748a393892feb"},"cell_type":"code","source":"yelp_reviews.columns = ['Reviews','Sentiment']\nyelp_reviews.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a1680a875d68ecb1586d7c8f12b52fae9b90bc6"},"cell_type":"code","source":"import nltk\nstopwords = nltk.corpus.stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06f7160be5eeae809af632dd2104f9d13a3acd16"},"cell_type":"code","source":"docs_vectors = pd.DataFrame()\n\nfor doc in yelp_reviews['Reviews'].str.lower().str.replace('[^a-z ]', ''):\n    temp = pd.DataFrame()\n    for word in doc.split(' '):\n        if word not in stopwords:\n            try:\n                word_vec = embeddings[word]\n                temp = temp.append(pd.Series(word_vec), ignore_index=True)\n            except:\n                pass\n    doc_vector = temp.mean()   # Column mean of each doc\n    docs_vectors = docs_vectors.append(doc_vector, ignore_index=True)\ndocs_vectors.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37eefd276462ddd0a702dbb6af49ae750a2d3aa5"},"cell_type":"code","source":"docs_vectors['Sentiment'] = yelp_reviews['Sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2e2593be7c4562eab20614020469654d8cdc0be"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import AdaBoostClassifier\ntrain_x,test_x,train_y,test_y = train_test_split(docs_vectors.drop('Sentiment',axis=1),\n                                                 docs_vectors['Sentiment'],\n                                                 test_size=0.2,random_state=1)\ntrain_x.shape ,test_x.shape,train_y.shape,test_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8227bfa7f82b87d8409d48e7d001f803a293eaf"},"cell_type":"code","source":"model = AdaBoostClassifier(n_estimators=800, random_state=1)\nmodel.fit(train_x,train_y)\ntest_pred = model.predict(test_x)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(test_y, test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d08449d948d33cc2723d8389a271c22f289e32a3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}