{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "77c910cb-285c-881d-e287-d5a3ab857a37"
      },
      "source": [
        "**Keras using TensorFlow backend.** \n",
        "\n",
        "Forked from [Keras CNN with 99% accuracy, v2][1]\n",
        "\n",
        "\n",
        "  [1]: https://www.kaggle.com/toregil/digit-recognizer/keras-cnn-with-99-accuracy-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "09b1763f-7ec6-af88-0624-a1e8cf3c2fdd"
      },
      "outputs": [],
      "source": [
        "# check input files\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25e71416-d5b6-8144-6b85-aeb5e038adb6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "64c6c89c-7b20-2acf-a8ee-8403dc607ea5"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "eceb1d4c-57cb-9a65-d614-6611aa627de9"
      },
      "outputs": [],
      "source": [
        "train_file = \"../input/train.csv\"\n",
        "test_file = \"../input/test.csv\"\n",
        "output_file = \"submission.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8f1bc2bd-b460-b83d-bb42-9373ab1adb45"
      },
      "source": [
        "**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f6ccbba-4425-64a7-1f98-47b3b26bb506"
      },
      "outputs": [],
      "source": [
        "# load training data\n",
        "                      #path    #skip labels  #specify datatype\n",
        "raw_data = np.loadtxt(train_file, skiprows=1, dtype='int', delimiter=',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "94356a54-028c-f206-f24a-a3160d4632f3"
      },
      "outputs": [],
      "source": [
        "# train-test split\n",
        "#x_train #x_test #y_train #y_test                #predictors    #response(labels)\n",
        "x_train, x_val, y_train, y_val = train_test_split(raw_data[:,1:],raw_data[:,0],test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "31766601-4768-7fde-fb8d-ec56d1104a72"
      },
      "outputs": [],
      "source": [
        "print(\"Original dataset:\")\n",
        "print(\"training x: \", \"shape \", x_train.shape, \" type \", type(x_train))\n",
        "print(\"training y: \", \"shape \", y_train.shape, \" type \", type(y_train))\n",
        "print(\"validation x: \", \"shape \", x_val.shape, \" type \", type(x_val))\n",
        "print(\"validation y: \", \"shape \", y_val.shape, \" type \", type(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6b50ea2c-ed92-bc93-8218-d37c38432e7b"
      },
      "outputs": [],
      "source": [
        "# scale the data\n",
        "x_train = x_train.astype(\"float32\")/255.0   # convert it to [0,1] scale\n",
        "x_val = x_val.astype(\"float32\")/255.0\n",
        "y_train = np_utils.to_categorical(y_train)   # convert integers to dummy variables (one hot encoding) \n",
        "y_val = np_utils.to_categorical(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "87240598-bc3f-00f0-14ec-34a07768a52b"
      },
      "outputs": [],
      "source": [
        "n_train = x_train.shape[0]    # number of training observations\n",
        "n_val = x_val.shape[0]    # number of validation observations\n",
        "                         #obs  #28px #28px #1channel\n",
        "x_train = x_train.reshape(n_train, 28, 28, 1)\n",
        "x_val = x_val.reshape(n_val, 28, 28, 1)\n",
        "n_classes = y_train.shape[1]  # 10 categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7d74211-3471-f478-2133-105e6f304e76"
      },
      "outputs": [],
      "source": [
        "# dimensions of training and testing set after normalization\n",
        "\n",
        "print(\"After normalization:\")\n",
        "print(\"training x: \", \"shape \", x_train.shape, \" type \", type(x_train))\n",
        "print(\"training y: \", \"shape \", y_train.shape, \" type \", type(y_train))\n",
        "print(\"testing x: \", \"shape \", x_val.shape, \" type \", type(x_val))\n",
        "print(\"testing y: \", \"shape \", y_val.shape, \" type \", type(y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "db0c3770-94c4-23f3-bb08-e1d1eb180c3f"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1d49635e-957d-7dea-b6c1-dec0e469cb71"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "758541df-3c55-e728-fce9-29233ce3f21c"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# add a convolutional layer\n",
        "                 #16 filters #filter size    #activation function #input data shape (each ob)\n",
        "model.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "\n",
        "# add a normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add a convolutional layer\n",
        "                                                               #don't need to specify the dimension\n",
        "model.add(Conv2D(filters=16,kernel_size=(3,3),activation='relu'))\n",
        "\n",
        "# add a pooling layer\n",
        "                    #(2,2) stride value\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "\n",
        "# add a normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add a dropout layer\n",
        "          #fraction of input units to drop\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# add a convolutional layer\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
        "\n",
        "# add a normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add a convolutional layer\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
        "\n",
        "# add a pooling layer\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "\n",
        "# add a normalization layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add a dropout layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "# add a flatten layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# add a dense layer (fully connected)\n",
        "model.add(Dense(512,activation='relu'))\n",
        "\n",
        "# add a dropout layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# add a dense layer (fully connected)\n",
        "model.add(Dense(1024,activation='relu'))\n",
        "\n",
        "# add a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# add a dense layer (output layer, 10 categories)\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f5fbe17-db72-d6a5-4947-887daea631c6"
      },
      "outputs": [],
      "source": [
        "# tweek the images\n",
        "datagen = ImageDataGenerator(zoom_range=0.1,\n",
        "                             height_shift_range=0.1,\n",
        "                             width_shift_range=0.1,\n",
        "                             rotation_range=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d19ae553-87a6-00ae-9431-e00617da1643"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=3e-5),metrics=[\"accuracy\"])\n",
        "\n",
        "hist=model.fit_generator(datagen.flow(x_train,y_train,batch_size=16),\n",
        "                         steps_per_epoch=1000,\n",
        "                         epochs=1,\n",
        "                         verbose=2,\n",
        "                        validation_data=(x_val[:400,:],y_val[:400,:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3f0a8dc8-e34a-4456-fb09-4e47d56f2b4a"
      },
      "outputs": [],
      "source": [
        "# reduce learning rate by 10% each epoch\n",
        "annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9**x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d5f716cb-71a0-5020-3819-30d4a44e644b"
      },
      "outputs": [],
      "source": [
        "hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n",
        "                           steps_per_epoch=1000,\n",
        "                           epochs=9,\n",
        "                           verbose=2,\n",
        "                           validation_data=(x_val[:400,:],y_val[:400,:]),\n",
        "                           callbacks=[annealer])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a3d4bea5-5be4-7a2e-764a-06353fcb093d"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d53fa86a-515f-aea9-4c5c-7b747e478e07"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_val, y_val, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "34c4586f-5e3e-5388-ea35-23f02de33145"
      },
      "outputs": [],
      "source": [
        "# plot the graph of metrics\n",
        "plt.plot(hist.history['loss'],color='b')\n",
        "plt.plot(hist.history['val_loss'], color='r')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['acc'], color='b')\n",
        "plt.plot(hist.history['val_acc'], color='r')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f5c2a422-ac6e-c630-48d9-d9d42b5318f9"
      },
      "outputs": [],
      "source": [
        "y_hat = model.predict(x_val)\n",
        "y_pred = np.argmax(y_hat, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0cb9aa7d-0b18-352b-1e7e-82b82e96e805"
      },
      "source": [
        "**Submit**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f190afb-57da-a9c7-10ef-c733e8b3f252"
      },
      "outputs": [],
      "source": [
        "# load the test set\n",
        "mnist_testset = np.loadtxt(test_file, skiprows=1, dtype='int', delimiter=',')\n",
        "x_test = mnist_testset.astype(\"float32\")/255.0\n",
        "n_test = x_test.shape[0]\n",
        "x_test = x_test.reshape(n_test, 28, 28, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1925275-e10b-33d7-3050-6d24568e73ee"
      },
      "outputs": [],
      "source": [
        "y_hat = model.predict(x_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "608dc431-aac1-0483-cf9c-cb7e2dd3627a"
      },
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_hat, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7b344853-b6d0-8ee2-05f5-59117caa73a5"
      },
      "outputs": [],
      "source": [
        "with open(output_file, 'w') as f:\n",
        "    f.write('ImageId,Label\\n')\n",
        "    for i in range(0, n_test):\n",
        "        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "373a83e6-5333-87e2-fca7-5f0da0a27e3b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}