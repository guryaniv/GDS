{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "caa20a0d66d219bebd654e5358e2e2f5b2b7a225", "_cell_guid": "2c99d6b2-1104-4474-ad40-546983055ebf"}, "source": ["# Toxic Comment Classification - EDA"]}, {"cell_type": "raw", "metadata": {"_uuid": "ce039ce86d5d9c9bc2ec2b1738719dd504904bfc", "_cell_guid": "1f22b9d7-3897-418f-8e0c-4f9659e8bfeb"}, "source": ["This notebook will be focusing on Exploratory Data Analysis.\n", "\n", "Some of the code here has been borrowed from\n", "    : Jagan - https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n", "    : Jeremy Howard - https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline-eda-0-073-lb"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9e8329a8237ba931fda7886dd17bdc321afe415e", "_cell_guid": "bf86b7b1-fb6f-4e5f-96ca-ab4de3184fb8"}, "source": ["#load libraries\n", "import pandas as pd\n", "import numpy as np\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "%matplotlib inline\n", "\n", "import re\n", "\n", "from nltk.sentiment.vader import SentimentIntensityAnalyzer"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "18bd2f054eae975c80d6e0742017bb1574c1e601", "collapsed": true, "_cell_guid": "c0a32379-3586-4291-87da-9e75b28cc7b7", "_kg_hide-output": true}, "source": ["#load datasets\n", "train = pd.read_csv(\"../input/train.csv\")\n", "test = pd.read_csv(\"../input/test.csv\")"]}, {"cell_type": "markdown", "metadata": {"_uuid": "f0a6564c701f0e274dbcd6caeabd84d9013b99f6", "collapsed": true, "_cell_guid": "ef7a5e75-f303-406a-bb69-4f6fec8ae739"}, "source": ["# Exploratory Data Analysis"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7efe4e862a7387a8ea65ed90593b93dd12f6ba7d", "_cell_guid": "bd3aa0c4-ac42-4bf6-80b3-e2dba37bb273"}, "source": ["train.columns"]}, {"cell_type": "markdown", "metadata": {"_uuid": "38367d959da1fb1d05468121404a565159b535fb", "_cell_guid": "8982c1cc-9008-4e6d-af94-7e4cda48449f"}, "source": ["Our target variables in here are classified as follows:\n", "    * toxic\n", "    * severe_toxic\n", "    * obscene\n", "    * threat\n", "    * insult\n", "    * identity_hate"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4047ea47704e74d48abf81e4387eeb6e9c98b561", "collapsed": true, "_cell_guid": "50156811-946a-4271-90f2-0dbb453039cf"}, "source": ["bad_tags = train.iloc[:, 2:].sum()\n", "\n", "rowsums=train.iloc[:,2:].sum(axis=1)\n", "\n", "train['clean']= (rowsums == 0)\n", "binary = {True : 1, False : 0} #0 - bad comments, 1 - clean comments\n", "train[\"clean\"] = train[\"clean\"].map(binary)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8c6482418fcfded0eec900638bd1e316a944b8e5", "_cell_guid": "e45623f2-0ca4-48ab-9a0a-02db9af4c1de"}, "source": ["x=train.iloc[:,2:].sum()\n", "#plot\n", "plt.figure(figsize=(8,4))\n", "ax= sns.barplot(x.index, x.values, alpha=0.8)\n", "plt.title(\"# per class\")\n", "plt.ylabel('# of Occurrences', fontsize=12)\n", "plt.xlabel('Type ', fontsize=12)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "9b38a13aab4471fa4bc0b54613d83b8162022d43", "_cell_guid": "34234e82-3287-46d1-9247-3442734fbbf2"}, "source": ["Observations:\n", "    1. Most of the comments are clean.\n", "    2. Since classification is mostly clean, there might be a possible class imbalance. "]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2174f04755b836e938c86d622652dadf85f499ca", "_cell_guid": "7d31d286-3dfe-42ae-b616-12b685614de5"}, "source": ["train.sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b3de49612ae998ec278cd00cfb552edf716f821d", "_cell_guid": "0a7e32d9-fa57-4ff4-b169-e43e80069ee6"}, "source": ["Observations:\n", "    1. A sample from our training set shows that classification of bad comments can be tagged into multple categories.\n", "    2. Sentiment for clean comments range from neutral to positive."]}, {"cell_type": "markdown", "metadata": {"_uuid": "a15a54af382be961c692650fbcd18863937f48e2", "_cell_guid": "20d98f03-c2d7-4bc0-b89b-5c0df9ec56ad"}, "source": ["# Does String Length Affect Sentiment Scores?"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e2eee10f7752447c375cdcd6338bc77f45014180", "_cell_guid": "c2e79c20-4ff2-422b-9e8b-2892e7a3e9f1"}, "source": ["train[\"comment_length\"] = train.comment_text.str.len()\n", "\n", "g = sns.FacetGrid(train, hue =\"clean\")\n", "g.map(sns.distplot, \"comment_length\")\n", "g.fig.set_size_inches(12, 6)\n", "\n", "\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "04fc9c6f5ede1a4c3c1873f07e626cf940fe64c2", "_cell_guid": "2a84d171-a034-4c9d-9a06-711c0499c43f"}, "source": ["Apparently, string length does not provide any useful information. Both clean and bad comments are spread out evenly."]}, {"cell_type": "markdown", "metadata": {"_uuid": "3c664c6b4d1a0bc5febdcf99c4ff3aacdeecf743", "_cell_guid": "5efd48a2-529e-43ff-8e0e-5585bd907758"}, "source": ["# What Makes a Good/Bad Comment?\n", "\n", "For this section, we'll check out what makes a good and a bad comment. We'll sample a few examples from our training set and try to find any patterns."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "27a4abfb6207df269632728a793050896358320b", "_cell_guid": "6f2313e8-0d06-4b56-b62c-10fb59f01850"}, "source": ["#Clean Comment Sample\n", "\n", "train[train[\"clean\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "7089e049fe0138953d94b5911a437319cd44d4b1", "_cell_guid": "424cd861-d1de-4068-b3ea-7cc34959d20d"}, "source": ["Observation:\n", "    1. Sentiments on these comments range from neutral to positive."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "dc21e0e6127271b0f74a1e31fbedce255911272d", "_cell_guid": "411ef35b-1e71-4e36-a1c0-910585f22278"}, "source": ["#Toxic Comment Sample\n", "\n", "train[train[\"toxic\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "ba227f0989b5111d1c0544c352a9955dcd36446d", "_cell_guid": "a4be25c5-ed0b-42f5-8aa5-5fcafb2043cd"}, "source": ["It seems that toxic comments have an aggressive tone, and a highly negative sentiment."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "35a6cc1bf3466f9ade82f7c561bc9d212ff09fd4", "_cell_guid": "d98a011a-3e47-4b16-8921-2c6facd2aed5"}, "source": ["#Sample severe_toxic comments\n", "\n", "train[train[\"severe_toxic\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "3284da8c2bca52fc74f8c9e04c9b02b52a732e75", "_cell_guid": "20ac3dc6-207a-44ae-bf06-818873bade8d"}, "source": ["Severe toxic comments, are usually associated with more tags and are linearly correlated obscene and insult comments."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5bb2c9adb6b9bf5d05f8f7905dbfeca4b2a1d592", "_cell_guid": "3591bc2d-a83a-45e1-8538-c98854fa25c0"}, "source": ["#Sample obscene comments\n", "\n", "train[train[\"obscene\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "d4991ddc64c6aa75f504b05c6c257e69cea9b86a", "_cell_guid": "ecd162e3-7bc9-4efe-855c-e905e8fb0dbf"}, "source": ["Obscene comments are linearly correlated with insult comments."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b10afdd4aac47bd58ae3b40f639d7d8162db7583", "_cell_guid": "d1115560-7015-4a5a-9fa5-22c7ecd2473a"}, "source": ["#Sample threat comments\n", "\n", "train[train[\"threat\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "d85844d0c702e780192f7bc02bb64fa99fefa2f2", "_cell_guid": "009a6196-ac0b-4b87-92d9-edcc5947a885"}, "source": ["For the threat comments are linearly correlated with toxic, obscene, and insult comments."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "dd98a422a979aebd328254b60658a97c8af8cc52", "_cell_guid": "1ef24c4e-f241-465e-a7c2-81ede4c92230"}, "source": ["#Sample insult comments\n", "\n", "train[train[\"insult\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "b1219395c8829ec245393354d6e4964376b1b575", "_cell_guid": "9c85b1f2-5e6f-4f58-88e5-d7fa91750f0d"}, "source": ["The same results have been found for obscene comments, which are highly correlated with insults as well as the toxic tag."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "73db35a847337a359fc140e87101e0638ff4e37a", "_cell_guid": "718b663a-76a8-4ad3-8b6a-e10a7d1dd8e2"}, "source": ["#Sample identity_hate comments\n", "\n", "train[train[\"identity_hate\"] == 1].sample(10)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "5e5a137d01b3a367ec9e21c3459d2226fb292f8c", "_cell_guid": "ac421454-66cf-4a07-8175-b7f57f0ce89d"}, "source": ["For our identity_hate comments, there is a linear correaltion with insult and toxic comments."]}, {"cell_type": "markdown", "metadata": {"_uuid": "c55e62063512b0af4dc3873d2abf700ade5b70dd", "_cell_guid": "063d9e7b-25e9-443a-ad07-18bf414fba3c"}, "source": ["Let's provide a heatmap to check to find out linear correlations between each variable, and inspect if our observations for them are true."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6d7cf2bef4e129dbf7f3e881e8999eb3e107df85", "_cell_guid": "fe3b3441-a76f-496e-a259-6ecb9b862a12"}, "source": ["plt.figure(figsize = (12, 8))\n", "sns.heatmap(train.iloc[:, 2:-1].corr(), annot = True)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "50af63b336bc4f0cff6d45a319493dd8cc9571ae", "_cell_guid": "29681dc0-511b-4d3b-8535-06e0f6f0804b"}, "source": ["1. We have confirmed our observations that both obscene and insult comments are highly linearly correlated with each other.\n", "2. Also toxic comments are highly correlated with obscene and insult comments."]}, {"cell_type": "markdown", "metadata": {"_uuid": "95b3600a43975959a8bc729992796ce73e4a1fd7", "_cell_guid": "66bc0614-7c2a-4421-a7dc-2916d5c81ce9"}, "source": ["# What are the common attributes for each sample?\n", "\n", "    - Another thing is that a lot of the toxic comments have cussing in them.\n", "    - Bad comments have a lot of negative sentiment in them.\n", "    - Negative comments are also have an aggressive tone.\n", "    - Bad comments are usually classified into several tags."]}, {"cell_type": "markdown", "metadata": {"_uuid": "5f11b4e0a6fa2275e5c2910294d343d2ab577ba0", "_cell_guid": "9d5c84d5-9176-4d8f-be97-729ece85f666"}, "source": ["# Sentiment Analysis\n", "\n", "Since all observed bad comments are highly negative, let's check for the sentiment analysis for each of the classified comments.\n", "\n", "For this section, I'm going to use the vaderSentiment library which outputs a compound sentiment between -1 to 1, where the former means that the comment is purely negative while the latter, otherwise."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "a8bb55e59f584be5a773cf3d95b60710b3458aad", "collapsed": true, "_cell_guid": "7a7c3b1c-9aab-45bb-a5d1-de7cca0bb7b4"}, "source": ["sentiment = SentimentIntensityAnalyzer()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "75670d3d95c9ee19053d6643569b84f78104acc7", "collapsed": true, "_cell_guid": "c3c41add-3c13-4cb2-82bb-8b23058e4f55"}, "source": ["toxic_vs_clean = []\n", "\n", "for index in train.index:\n", "    toxic_vs_clean.append(sentiment.polarity_scores(train.iloc[index, 1]))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "c4e6dfabd6e9eeb8c64eac762046cea9e2a3d691", "collapsed": true, "_cell_guid": "ebdf6b01-8057-4582-bfeb-a2de6877c2af"}, "source": ["data = pd.concat([pd.DataFrame(toxic_vs_clean), train[\"clean\"]], axis =1)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ca12f8379a299f4f7ff17b7e011f6cbbb6a3b07e", "_cell_guid": "9bf3be59-35e8-4c8e-8eed-ec02144682fe"}, "source": ["g = sns.FacetGrid(data, hue = \"clean\")\n", "g.map(sns.distplot, \"compound\")\n", "g.fig.set_size_inches(12, 6)\n", "\n", "plt.legend()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "0b2835972dd456214fa5e970db90996f567866fb", "_cell_guid": "d45cb825-8f04-4328-add1-0099d34e9661"}, "source": ["Suprisingly, compound scores for both toxic and clean data have scores ranging from -1 to 1. Let's investigate them further."]}, {"cell_type": "markdown", "metadata": {"_uuid": "3f17eb151b5c2ccd80ccbc39f17c4e4e5a229687", "_cell_guid": "aaae8ba8-3fc0-467c-9ed0-2df5a1d82f04"}, "source": ["Observations:\n", "    1. There are clean comments that have highly negative compound score.\n", "    2. Comments that have a high neutral rating, bare very little with the compound score.\n", "    3. Likewise, large wights have been given to both the negative and positive.\n", "    \n", "We're gonna add two more variables, which are the ratio between the negative and nutral score, and the positive and neutral score."]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d455d9d33dcefb9fc019ef745110cbf3fb4f46a5", "collapsed": true, "_cell_guid": "3a344308-5f55-4ba7-870f-6e2fce13263c"}, "source": ["analyze = pd.DataFrame(toxic_vs_clean)\n", "\n", "analyze[\"neu_neg\"] = analyze[\"neu\"]/(analyze[\"neg\"] + 0.0001)\n", "analyze[\"neu_pos\"] = analyze[\"neu\"]/(analyze[\"pos\"] + 0.0001)\n", "\n", "eda = pd.concat([analyze, train[\"clean\"]], axis =1)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "cc85648498b44fe5a21ac2e779d2d1412e7b8050", "_cell_guid": "8862fd8a-18a1-4b38-ba52-8b6766f76074"}, "source": ["fig, [ax1, ax2] = plt.subplots(ncols = 2, nrows = 1, figsize = (12, 6))\n", "\n", "sns.regplot(\"neu_neg\", \"compound\", data = eda, ax = ax1)\n", "sns.regplot(\"neu_pos\", \"compound\", data = eda, ax = ax2)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "da2eea677c944d228d87fb3f40c68b3b4d3e1772", "_cell_guid": "850a1b7d-7765-485e-92c2-26d37d164b22"}, "source": ["Observations:\n", "\n", "    1. For the first graph, high ratios (neutral score is a lot higher than the negative score), the polarity of the setniment is high.\n", "    2. Likewise, for the second graph (low positive scores and high neutral scores), have a low sentiment."]}], "metadata": {"language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "mimetype": "text/x-python", "file_extension": ".py", "name": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.4"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat": 4}