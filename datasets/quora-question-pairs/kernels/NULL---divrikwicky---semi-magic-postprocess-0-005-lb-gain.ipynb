{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9d8772a5-34de-8a7e-8efd-7cad86867d44"
      },
      "source": [
        "With an unsupervised postprocessing technique I could manage to gain around 0.005 in my best ensemble model, which made ~0.1325 to ~1275. (Maybe I could stay in top 1% thanks to it.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e1ef89ce-e478-5488-10e2-b4c9c305ab7a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df_train =  pd.read_csv('../input/train.csv')\n",
        "df_test =  pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "941f2039-337a-ff0f-d084-d997c8dc3e9d"
      },
      "source": [
        "After you obtain your best model, use your submission for a better submission:)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a74ea270-614e-a27c-8d3a-e96382776069"
      },
      "outputs": [],
      "source": [
        "#REPLACE it with:\n",
        "#test_label = np.array(pd.read_csv('your_best_solution.csv')[\"is_duplicate\"])\n",
        "test_label = np.random.rand(len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "332a949a-ecca-c3fc-6925-47aea2c68ff9"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "REPEAT = 2 #a reasonable number which can consider your updates iteratively but not ruin the predictions\n",
        "\n",
        "DUP_THRESHOLD = 0.5 #classification threshold for duplicates\n",
        "NOT_DUP_THRESHOLD = 0.1 #classification threshold for non-duplicates\n",
        "#Since the data is unbalanced, our mean prediction is around 0.16. So this is the reason of unbalanced thresholds\n",
        "\n",
        "MAX_UPDATE = 0.2 # maximum update on the dup probability (a high choice may ruin the predictions)\n",
        "DUP_UPPER_BOUND = 0.98 # do not update dup probabilities above this threshold\n",
        "NOT_DUP_LOWER_BOUND = 0.01 # do not update dup probabilities below this threshold\n",
        "# There is no significant gain between 0.98 and 1.00 for a dup \n",
        "# but there is significant loss if it is not really a dup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c6ddb218-2333-0faf-4727-0bc330fcc991"
      },
      "source": [
        "This part is nothing magic but basic logic. If A is a duplicate of B and C is a duplicate of B, then A is a duplicate of C."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d41d7f5e-7227-ff1b-b67e-9b36b54cfb51"
      },
      "outputs": [],
      "source": [
        "for i in range(REPEAT):\n",
        "    dup_neighbors = defaultdict(set)\n",
        "\n",
        "    for dup, q1, q2 in zip(df_train[\"is_duplicate\"], df_train[\"question1\"], df_train[\"question2\"]): \n",
        "        if dup:\n",
        "            dup_neighbors[q1].add(q2)\n",
        "            dup_neighbors[q2].add(q1)\n",
        "    \n",
        "    for dup, q1, q2 in zip(test_label, df_test[\"question1\"], df_test[\"question2\"]): \n",
        "        if dup > DUP_THRESHOLD:\n",
        "            dup_neighbors[q1].add(q2)\n",
        "            dup_neighbors[q2].add(q1)\n",
        "\n",
        "    count = 0\n",
        "    for index, (q1, q2) in enumerate(zip(df_test[\"question1\"], df_test[\"question2\"])): \n",
        "        dup_neighbor_count = len(dup_neighbors[q1].intersection(dup_neighbors[q2]))\n",
        "        if dup_neighbor_count > 0 and test_label[index] < DUP_UPPER_BOUND:\n",
        "            update = min(MAX_UPDATE, (DUP_UPPER_BOUND - test_label[index])/2)\n",
        "            test_label[index] += update\n",
        "            count += 1\n",
        "\n",
        "    print(\"Edited:\", count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b9c553f1-7d34-815b-5c8b-942eea3015e8"
      },
      "source": [
        "This part is the magic part, because having a non-duplicate common neighbor does not mean that these questions are not duplicates but if you read https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs, you may find some insights.\n",
        "\n",
        "> Our original sampling method returned an imbalanced dataset with many more true examples of duplicate pairs than non-duplicates. **Therefore, we supplemented the dataset with negative examples.** One source of negative examples were pairs of \u201crelated questions\u201d which, although **pertaining to similar topics**, are not truly semantically equivalent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "18954434-8c3b-7edf-63f9-259773f8cecd"
      },
      "outputs": [],
      "source": [
        "for i in range(REPEAT):\n",
        "    not_dup_neighbors = defaultdict(set)\n",
        "\n",
        "    for dup, q1, q2 in zip(df_train[\"is_duplicate\"], df_train[\"question1\"], df_train[\"question2\"]): \n",
        "        if not dup:\n",
        "            not_dup_neighbors[q1].add(q2)\n",
        "            not_dup_neighbors[q2].add(q1)\n",
        "    \n",
        "    for dup, q1, q2 in zip(test_label, df_test[\"question1\"], df_test[\"question2\"]): \n",
        "        if dup < NOT_DUP_THRESHOLD:\n",
        "            not_dup_neighbors[q1].add(q2)\n",
        "            not_dup_neighbors[q2].add(q1)\n",
        "\n",
        "    count = 0\n",
        "    for index, (q1, q2) in enumerate(zip(df_test[\"question1\"], df_test[\"question2\"])): \n",
        "        dup_neighbor_count = len(not_dup_neighbors[q1].intersection(not_dup_neighbors[q2]))\n",
        "        if dup_neighbor_count > 0 and test_label[index] > NOT_DUP_LOWER_BOUND:\n",
        "            update = min(MAX_UPDATE, (test_label[index] - NOT_DUP_LOWER_BOUND)/2)\n",
        "            test_label[index] -= update\n",
        "            count += 1\n",
        "\n",
        "    print(\"Edited:\", count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a61def78-686a-7b59-626c-62b3bbd6bc70"
      },
      "source": [
        "Prepare the submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d9e64f54-fb45-3735-afea-c216fbcb189c"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({'test_id':df_test[\"test_id\"], 'is_duplicate':test_label})\n",
        "#submission.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "357ad942-910a-b549-450d-853db3ea4636"
      },
      "source": [
        "I will also provide the repository of my relatively lightweight solution when I have time."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}