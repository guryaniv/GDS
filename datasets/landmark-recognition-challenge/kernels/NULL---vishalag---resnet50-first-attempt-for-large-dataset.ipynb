{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","collapsed":true,"trusted":false},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv('train_greaterthan4.csv')# list of landmarks which have more than 4 id's\ntest_data = pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"675faa213f5b0928394bad9b8eab1f5d4cdb9826","_cell_guid":"f4f46d62-6220-49f8-9391-49f891b21ad4","collapsed":true,"trusted":false},"cell_type":"code","source":"print(\"Training data size\",train_data.shape)\nprint(\"test data size\",test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"015786e5916fcbcb97d9d47aebc0c74308f084c0","_cell_guid":"98b2f326-015f-4945-8564-63388682af24","collapsed":true,"trusted":false},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe9d32c17a01a2252b7dd1e3e246e22fa96afc13","_cell_guid":"3b9ebc79-b08b-4dd5-8d9b-a8a4a436a85e","collapsed":true,"trusted":false},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4841cb510cd1753f0410cff6d7ca8195bc47efe","_cell_guid":"75064e44-d382-4597-9c2f-fa28fffa883b","collapsed":true,"trusted":false},"cell_type":"code","source":"train_data.nunique()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6ae4b995ba69d7b6e021f551de0105aaff4e8a8","_cell_guid":"b61a8ee3-c843-4356-8ad0-de91230337b5","collapsed":true,"trusted":false},"cell_type":"code","source":"from numpy import array\nfrom keras.utils import to_categorical\nlist_train_X = train_data['id']\ntrain_y = train_data['landmark_id']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"936a2aa261551c1c378ea52d146df758c38e93e0","_cell_guid":"9fe36682-9827-4244-a5df-2b3f62f60a18","collapsed":true,"trusted":false},"cell_type":"code","source":"import os\ndir_file = os.listdir(\"resize_train_image\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e55de30b10b7b78222d2d8ce6ca190afb3320b3c","_cell_guid":"ac6e3d3d-0f3d-4d42-a5b1-2afb2d6c4ebf","collapsed":true,"trusted":false},"cell_type":"code","source":"from PIL import Image\nfrom pylab import *\nimport itertools\nfrom numpy import array\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nvalues = array(train_y)\n# integer encode\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(values)\n\nonehot_encoder = OneHotEncoder(sparse=True)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoded = onehot_encoder.fit_transform(integer_encoded)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ad417375d3f3553c255e5a6ff6d28d547cb132a","_cell_guid":"6aad6bec-82ea-41b2-a67d-151d4fbf44a3","collapsed":true,"trusted":false},"cell_type":"code","source":"onehot_encoded.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bb18a1999784fd3bc805f920d9e18b90c2e15a5","_cell_guid":"560944f7-094f-4f7d-9687-e01c00c2ee4c","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"65816b28a5b28ca975066929f06c3a4ce6458fe5","_cell_guid":"e11cad0d-509e-4c6a-9533-66c94e918e3c","collapsed":true,"trusted":false},"cell_type":"code","source":"def chunk_of_data(start,stop):\n\n    images_input_x = None\n    images_input_x = np.ndarray(shape=(2000, 224, 224,3), dtype =np.float16)\n    count = 0\n    y = onehot_encoded[start:stop]\n    '''\n    y_arr = array(y)\n    print(y_arr.shape)\n    categorical_y = to_categorical(y_arr, num_classes = 14951)\n    '''\n    \n    #print(images_input_x.shape)\n    for i in itertools.islice(list_train_X, start, stop):\n        im = Image.open('resize_train_image/'+ i +'.jpg')\n        im = im.resize([224,224],Image.ANTIALIAS)\n        arr = np.array(im)\n        #arr = img_to_array(im)\n        #arr = arr.reshape((224, 224 , 3))\n        arr = (arr - 128.0) / 128.0\n        images_input_x[count] = arr \n        count+=1\n        #if count%1000 == 0:\n            #print(count)\n            #print(im)\n    #print(i)\n    #plt.imshow(im)\n    #print(y[stop-1])\n    return images_input_x,y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58c1928d3bf38542d80b7431261b0d04f6b52b3d","_cell_guid":"ebad46b5-4493-4672-adcc-711874a577e1","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras import backend as K","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b58b9762be8f242c5ca649016bb63d6e51e161c7","_cell_guid":"c4ac3395-319f-4a8b-98e0-f9c1e42bab95","collapsed":true,"trusted":false},"cell_type":"code","source":"base_model = ResNet50(weights='imagenet', include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe4048d879575c623cf4b499057004f2718c9308","_cell_guid":"a7f0d26d-58c7-401b-a697-88e86335b31d","collapsed":true,"trusted":false},"cell_type":"code","source":"x = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(12838, activation='softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"97cdbf77b8477f667dbb3b0e12ceee96af496277","_cell_guid":"c938e2da-b9d3-4d0e-baf2-8322b89ad46c","collapsed":true,"trusted":false},"cell_type":"code","source":"model = Model(inputs=base_model.input, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa572f1568e8c3ccc0bf51dfb002bb221e516637","_cell_guid":"5d876a84-8f62-4c4b-b364-89059fea15dd","collapsed":true,"trusted":false},"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9882139b6d989864a61e336e67751c74a674ae5","_cell_guid":"61e34275-85d6-4638-9e49-6e2dbd849195","collapsed":true,"trusted":false},"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e7848559b01a9116c2885ef942adb0bac58b8ee","_cell_guid":"2124da31-f858-4227-bd0f-1444422e8b0e","collapsed":true,"trusted":false},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a1ef6b6baa9813cb6fef25f908b940cc5f8c184","_cell_guid":"6c5d85a1-42a6-4eae-9f37-afbdfbd296aa","collapsed":true,"trusted":false},"cell_type":"code","source":"nb_epoch = 2\nfor e in range(nb_epoch):\n    #print(\"epoch %d\" % e)\n    \n    start = 0\n    stop = 2000\n    step = 2000\n    for i in range (60):\n        print(\"epoch %d\" % e,i,\"/60\")\n        x ,y = chunk_of_data(start,stop)\n        y =y.todense()\n        y =np.array(y)\n        print(\"fit\")\n        datagen.fit(x)\n        \n        model.fit_generator(datagen.flow(x, y, batch_size=1),\n                    steps_per_epoch=len(x) / 60, epochs=1)\n        #model.fit(x, y, batch_size=8, nb_epoch=1)\n        start = stop\n        stop += step","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67111efdd299530d1d06355dd9601382ef816daf","_cell_guid":"b37aa7a0-b201-4d87-a346-ea12114019a3","collapsed":true,"trusted":false},"cell_type":"code","source":"for i, layer in enumerate(base_model.layers):\n   print(i, layer.name)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4edec3677580bcb3d68a91adbcf7bf998cfc6878","_cell_guid":"339a860c-dbba-4954-8e4e-bdd66eaffab9","collapsed":true,"trusted":false},"cell_type":"code","source":"for layer in model.layers[:-11]:\n   layer.trainable = False\nfor layer in model.layers[-11:]:\n   layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f46470df8b1288f628464968c86fc316cf828e9","_cell_guid":"4e3e39b3-f6fe-41d0-86dd-740d31425a69","collapsed":true,"trusted":false},"cell_type":"code","source":"for layer in model.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25c4b85b77e286e640d37a0c395ab848b429e185","_cell_guid":"2c6bc95b-c7f7-4ae4-bb0d-770962b49b5a","collapsed":true,"trusted":false},"cell_type":"code","source":"from keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"432491e57765d0d46589824cd52f9f128f12d629","_cell_guid":"2fa97e02-6fff-41c9-ae8b-1abf9e1d6ed8","collapsed":true,"trusted":false},"cell_type":"code","source":"nb_epoch = 40\nfor e in range(nb_epoch):\n    print(\"epoch %d\" % e)\n    \n    start = 0\n    stop = 6000\n    step = 6000\n    for i in range (202):\n        print(i)\n        x ,y = chunk_of_data(start,stop)\n        y =y.todense()\n        y =np.array(y)\n        datagen.fit(x)\n        model.fit_generator(datagen.flow(x, y, batch_size=32),\n                    steps_per_epoch=len(x) / 32, epochs=1)\n        #model.fit(x, y, batch_size=8, nb_epoch=1)\n        start = stop\n        stop += step\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fc4de43f687361dd9d9df1007607fa5c909c3c0","_cell_guid":"5bd3e892-aaa0-436a-8eaf-ea9d014ec543","collapsed":true,"trusted":false},"cell_type":"code","source":"model.save('resnet50_with_weight_.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f69eb40ec4e8ce4aa2f08d27c244cc15f4a8e6b","_cell_guid":"82bcb561-6630-40e1-a899-ae6026669c2d","collapsed":true,"trusted":false},"cell_type":"code","source":"model.save_weights('resnet_weights_only.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}