{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"The public kernals are filled with Blends of Blends of Blends and maybe someone can blend to 1.00000 too. \n\nOk, Nothing wrong in that. I just thought good solid kernals should not be lost within the chaos.  \n\nSo, I've compiled and categorized a list of resources that have taught something to me. Please add on to this list in the comments below, if I've missed any good kernals.\n\n### Simple Naive-Bayes:\n* https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline\n    * https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline#261316          # Custom SK learn class for Naive Bayes\n\n### Tf-IDF and simple Logistic Regression:\n\n* https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams            # ngram range=(2,6)   -->    can capture a lot of information!\n* https://www.kaggle.com/yekenot/toxic-regression\n\n### Wordbatch:\n* https://www.kaggle.com/anttip/wordbatch-1-3-3-fm-ftrl-lb-0-9812                          # FM_FTRL\n\n### H20, Word2Vec in R:\n* https://www.kaggle.com/brandenkmurray/h2o-word2vec-starter-toxic-comments\n\n# Deep learning:\n![](https://pbs.twimg.com/media/DWmKGuAXkAE9IXf.jpg)\n### GRU(Gated Recurrent Units):\n* https://www.kaggle.com/yekenot/pooled-gru-fasttext/code\n\n### Capsule Net(with GRU):\n* https://www.kaggle.com/chongjiujjin/capsule-net-with-gru\n* https://github.com/Godricly/comment_toxic\n    * https://github.com/bojone/Capsule/blob/master/Capsule_Keras.py                   # Base implementations of CapsNet in Keras\n    * https://github.com/XifengGuo/CapsNet-Keras\n    \n\n### LSTM:\n* https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras                             # Explains basic of LSTM well\n* https://www.kaggle.com/CVxTz/keras-bidirectional-lstm-baseline-lb-0-069                         # Simple baseline\n* https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout                              # Glove pretrained features + LSTM\n\n### Attention:\n* https://www.kaggle.com/sermakarevich/hierarchical-attention-network\n* https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043                      # LSTM + Attention layer\n\n### Convolution(CNNs):\n\n* https://www.kaggle.com/yekenot/textcnn-2d-convolution\n* https://www.kaggle.com/sbongo/for-beginners-go-even-deeper-with-char-gram-cnn\n\n### Bi Directional GRU CNNs:\n* https://www.kaggle.com/konohayui/bi-gru-cnn-poolings\n* https://www.kaggle.com/eashish/bidirectional-gru-with-convolution\n\n\n## Blending Helpers:\n What is blending?\n * https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/51058\n \n What all do I need to check before blending?\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/50827            ## Model correlations\n* https://www.kaggle.com/ogrellier/things-you-need-to-be-aware-of-before-stacking\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/49964          ## Class leakage in level 0 models\n\n### OOF stackering:\n* https://www.kaggle.com/hhstrand/oof-stacking-regime\n\n### Stacker scrpits:\n* https://www.kaggle.com/reppic/lazy-ensembling-algorithm\n\n### Covariance shift / Adversarial Validation: ( By how much test is different than train?)\n* https://www.kaggle.com/ogrellier/check-unicode-script-distribution\n* https://www.kaggle.com/ogrellier/adversarial-validation-and-lb-shakeup\n* https://www.kaggle.com/konradb/adversarial-validation\n\n\n\n# Others:\n\n### Creating more data:\nUsing translations\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/48038\n\n\n### Study materials:\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46073#latest-277688\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46038\n\n### Spell checker:\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/51426\n\n### Tuning:\nTuning DL models :\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/50602\n\nAnd a company good at Marketing.\n* https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/47172\n\nGood pipeline though.\nhttps://github.com/neptune-ml/kaggle-toxic-starter\n\n\n# And finally here's my blender: "},{"metadata":{"_uuid":"aebf7650fca0bfb17a7a721791d2f54c49ae64c8"},"cell_type":"markdown","source":"![](https://s.financesonline.com/uploads/blender-1024x823.jpg)\n\n[Ahem](https://financesonline.com/10-most-expensive-kitchen-appliances-super-expensive-corkscrews-coffee-machines/)"},{"metadata":{"_uuid":"70687a7c045932e7783d519dbbdc381f68734279"},"cell_type":"markdown","source":"PS: Not to hurt the other blender's feelings but this one is the best! "},{"metadata":{"_uuid":"194f261e85ed679d6550902724cb48d1d5d9cb40"},"cell_type":"markdown","source":"![](http://i0.kym-cdn.com/photos/images/facebook/001/240/075/90f.png)"},{"metadata":{"_uuid":"205cf17c1ed194a57c919ac8b4b0c2935a77bd23"},"cell_type":"markdown","source":""}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}