{"cells":[{"metadata":{"_uuid":"406c6f8cd47e303e6392e43b34ee55b91c59f4e2"},"cell_type":"markdown","source":"# Overview\nHere we show how well a QRNN works when compared with standard CNN and LSTM models. The parent is a 1D Convolution and other models show the stacked LSTM performance"},{"metadata":{"_uuid":"1b8da79bd7896c54199ccf641c6b730b798fbd0e","_cell_guid":"1b26cf41-5330-41fa-b4ce-76447f8e1e2f","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import Conv1D, GlobalMaxPool1D, Dropout, concatenate\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab6609c909324a93153a0877d6ca57a740d31e1c"},"cell_type":"markdown","source":"## QRNN Implementation\nWe use a reference implementation of the QRNN layer from https://github.com/DingKe/nn_playground/blob/master/qrnn/qrnn.py"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ed024aca5af74925ad09486f6fd2899907abd7fd"},"cell_type":"code","source":"from keras import backend as K\nfrom keras import activations, initializers, regularizers, constraints\nfrom keras.layers import Layer, InputSpec\nfrom keras.utils.conv_utils import conv_output_length\n\ndef _dropout(x, level, noise_shape=None, seed=None):\n    x = K.dropout(x, level, noise_shape, seed)\n    x *= (1. - level) # compensate for the scaling by the dropout\n    return x\n\n\nclass QRNN(Layer):\n    '''Quasi RNN\n    # Arguments\n        units: dimension of the internal projections and the final output.\n    # References\n        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n    '''\n    def __init__(self, units, window_size=2, stride=1,\n                 return_sequences=False, go_backwards=False, \n                 stateful=False, unroll=False, activation='tanh',\n                 kernel_initializer='uniform', bias_initializer='zero',\n                 kernel_regularizer=None, bias_regularizer=None,\n                 activity_regularizer=None,\n                 kernel_constraint=None, bias_constraint=None, \n                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n                 **kwargs):\n        self.return_sequences = return_sequences\n        self.go_backwards = go_backwards\n        self.stateful = stateful\n        self.unroll = unroll\n\n        self.units = units \n        self.window_size = window_size\n        self.strides = (stride, 1)\n\n        self.use_bias = use_bias\n        self.activation = activations.get(activation)\n        self.kernel_initializer = initializers.get(kernel_initializer)\n        self.bias_initializer = initializers.get(bias_initializer)\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n        self.bias_regularizer = regularizers.get(bias_regularizer)\n        self.activity_regularizer = regularizers.get(activity_regularizer)\n        self.kernel_constraint = constraints.get(kernel_constraint)\n        self.bias_constraint = constraints.get(bias_constraint)\n\n        self.dropout = dropout\n        self.supports_masking = True\n        self.input_spec = [InputSpec(ndim=3)]\n        self.input_dim = input_dim\n        self.input_length = input_length\n        if self.input_dim:\n            kwargs['input_shape'] = (self.input_length, self.input_dim)\n        super(QRNN, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        batch_size = input_shape[0] if self.stateful else None\n        self.input_dim = input_shape[2]\n        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n        self.state_spec = InputSpec(shape=(batch_size, self.units))\n\n        self.states = [None]\n        if self.stateful:\n            self.reset_states()\n\n        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n        self.kernel = self.add_weight(name='kernel',\n                                      shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(name='bias', \n                                        shape=(self.units * 3,),\n                                        initializer=self.bias_initializer,\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n\n        self.built = True\n\n    def compute_output_shape(self, input_shape):\n        if isinstance(input_shape, list):\n            input_shape = input_shape[0]\n\n        length = input_shape[1]\n        if length:\n            length = conv_output_length(length + self.window_size - 1,\n                                        self.window_size, 'valid',\n                                        self.strides[0])\n        if self.return_sequences:\n            return (input_shape[0], length, self.units)\n        else:\n            return (input_shape[0], self.units)\n\n    def compute_mask(self, inputs, mask):\n        if self.return_sequences:\n            return mask\n        else:\n            return None\n\n    def get_initial_states(self, inputs):\n        # build an all-zero tensor of shape (samples, units)\n        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n        initial_states = [initial_state for _ in range(len(self.states))]\n        return initial_states\n\n    def reset_states(self, states=None):\n        if not self.stateful:\n            raise AttributeError('Layer must be stateful.')\n        if not self.input_spec:\n            raise RuntimeError('Layer has never been called '\n                               'and thus has no states.')\n\n        batch_size = self.input_spec.shape[0]\n        if not batch_size:\n            raise ValueError('If a QRNN is stateful, it needs to know '\n                             'its batch size. Specify the batch size '\n                             'of your input tensors: \\n'\n                             '- If using a Sequential model, '\n                             'specify the batch size by passing '\n                             'a `batch_input_shape` '\n                             'argument to your first layer.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a '\n                             '`batch_shape` argument to your Input layer.')\n\n        if self.states[0] is None:\n            self.states = [K.zeros((batch_size, self.units))\n                           for _ in self.states]\n        elif states is None:\n            for state in self.states:\n                K.set_value(state, np.zeros((batch_size, self.units)))\n        else:\n            if not isinstance(states, (list, tuple)):\n                states = [states]\n            if len(states) != len(self.states):\n                raise ValueError('Layer ' + self.name + ' expects ' +\n                                 str(len(self.states)) + ' states, '\n                                 'but it received ' + str(len(states)) +\n                                 'state values. Input received: ' +\n                                 str(states))\n            for index, (value, state) in enumerate(zip(states, self.states)):\n                if value.shape != (batch_size, self.units):\n                    raise ValueError('State ' + str(index) +\n                                     ' is incompatible with layer ' +\n                                     self.name + ': expected shape=' +\n                                     str((batch_size, self.units)) +\n                                     ', found shape=' + str(value.shape))\n                K.set_value(state, value)\n\n    def __call__(self, inputs, initial_state=None, **kwargs):\n        # If `initial_state` is specified,\n        # and if it a Keras tensor,\n        # then add it to the inputs and temporarily\n        # modify the input spec to include the state.\n        if initial_state is not None:\n            if hasattr(initial_state, '_keras_history'):\n                # Compute the full input spec, including state\n                input_spec = self.input_spec\n                state_spec = self.state_spec\n                if not isinstance(state_spec, list):\n                    state_spec = [state_spec]\n                self.input_spec = [input_spec] + state_spec\n\n                # Compute the full inputs, including state\n                if not isinstance(initial_state, (list, tuple)):\n                    initial_state = [initial_state]\n                inputs = [inputs] + list(initial_state)\n\n                # Perform the call\n                output = super(QRNN, self).__call__(inputs, **kwargs)\n\n                # Restore original input spec\n                self.input_spec = input_spec\n                return output\n            else:\n                kwargs['initial_state'] = initial_state\n        return super(QRNN, self).__call__(inputs, **kwargs)\n\n    def call(self, inputs, mask=None, initial_state=None, training=None):\n        # input shape: `(samples, time (padded with zeros), input_dim)`\n        # note that the .build() method of subclasses MUST define\n        # self.input_spec and self.state_spec with complete input shapes.\n        if isinstance(inputs, list):\n            initial_states = inputs[1:]\n            inputs = inputs[0]\n        elif initial_state is not None:\n            pass\n        elif self.stateful:\n            initial_states = self.states\n        else:\n            initial_states = self.get_initial_states(inputs)\n\n        if len(initial_states) != len(self.states):\n            raise ValueError('Layer has ' + str(len(self.states)) +\n                             ' states but was passed ' +\n                             str(len(initial_states)) +\n                             ' initial states.')\n        input_shape = K.int_shape(inputs)\n        if self.unroll and input_shape[1] is None:\n            raise ValueError('Cannot unroll a RNN if the '\n                             'time dimension is undefined. \\n'\n                             '- If using a Sequential model, '\n                             'specify the time dimension by passing '\n                             'an `input_shape` or `batch_input_shape` '\n                             'argument to your first layer. If your '\n                             'first layer is an Embedding, you can '\n                             'also use the `input_length` argument.\\n'\n                             '- If using the functional API, specify '\n                             'the time dimension by passing a `shape` '\n                             'or `batch_shape` argument to your Input layer.')\n        constants = self.get_constants(inputs, training=None)\n        preprocessed_input = self.preprocess_input(inputs, training=None)\n\n        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n                                            initial_states,\n                                            go_backwards=self.go_backwards,\n                                            mask=mask,\n                                            constants=constants,\n                                            unroll=self.unroll,\n                                            input_length=input_shape[1])\n        if self.stateful:\n            updates = []\n            for i in range(len(states)):\n                updates.append((self.states[i], states[i]))\n            self.add_update(updates, inputs)\n\n        # Properly set learning phase\n        if 0 < self.dropout < 1:\n            last_output._uses_learning_phase = True\n            outputs._uses_learning_phase = True\n\n        if self.return_sequences:\n            return outputs\n        else:\n            return last_output\n\n    def preprocess_input(self, inputs, training=None):\n        if self.window_size > 1:\n            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n\n        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n                          padding='valid',\n                          data_format='channels_last')\n        output = K.squeeze(output, 2)  # remove the dummy dimension\n        if self.use_bias:\n            output = K.bias_add(output, self.bias, data_format='channels_last')\n\n        if self.dropout is not None and 0. < self.dropout < 1.:\n            z = output[:, :, :self.units]\n            f = output[:, :, self.units:2 * self.units]\n            o = output[:, :, 2 * self.units:]\n            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n            return K.concatenate([z, f, o], -1)\n        else:\n            return output\n\n    def step(self, inputs, states):\n        prev_output = states[0]\n\n        z = inputs[:, :self.units]\n        f = inputs[:, self.units:2 * self.units]\n        o = inputs[:, 2 * self.units:]\n\n        z = self.activation(z)\n        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n        o = K.sigmoid(o)\n\n        output = f * prev_output + (1 - f) * z\n        output = o * output\n\n        return output, [output]\n\n    def get_constants(self, inputs, training=None):\n        return []\n \n    def get_config(self):\n        config = {'units': self.units,\n                  'window_size': self.window_size,\n                  'stride': self.strides[0],\n                  'return_sequences': self.return_sequences,\n                  'go_backwards': self.go_backwards,\n                  'stateful': self.stateful,\n                  'unroll': self.unroll,\n                  'use_bias': self.use_bias,\n                  'dropout': self.dropout,\n                  'activation': activations.serialize(self.activation),\n                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n                  'bias_initializer': initializers.serialize(self.bias_initializer),\n                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n                  'bias_constraint': constraints.serialize(self.bias_constraint),\n                  'input_dim': self.input_dim,\n                  'input_length': self.input_length}\n        base_config = super(QRNN, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9ad6eedb6c02df20c9aff87cd135992b7232d5a","collapsed":true,"_cell_guid":"b4dc5f09-8543-4a1d-8dd8-d318beac27b0","trusted":true},"cell_type":"code","source":"# define network parameters\nmax_features = 20000\nmaxlen = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5fa68b8d9f20c8ceb662df489662db5e6b78846","_cell_guid":"022343c0-6cc6-4079-a3f2-4b89a7d5e0fe"},"cell_type":"markdown","source":"# Load and Preprocessing Steps\nHere we load the data and fill in the misisng values"},{"metadata":{"_uuid":"9182d060cfbbcd070b67e5dbc1136c98a4262cf9","collapsed":true,"_cell_guid":"b3b2bf13-dccb-4b2b-82b0-86295ac0ee23","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = train.sample(frac=1)\n\nlist_sentences_train = train[\"comment_text\"].fillna(\"Invalid\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_test = test[\"comment_text\"].fillna(\"Invalid\").values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14ac14dab11eab6430d4c8f8946bb0ce1b6f5ceb","_cell_guid":"8faf48b7-965e-49c0-9994-b5bae9650077"},"cell_type":"markdown","source":"## Sequence Generation\nHere we take the data and generate sequences from the data"},{"metadata":{"_uuid":"b53b6a50bb03f98e1605e5549f532503d7ef8d1d","collapsed":true,"_cell_guid":"a0296763-d6e7-49cd-bdb5-33bb7f5c231d","trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\n# train data\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nX_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n# test data\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b334ddbf78cf4065be1969513bf0f9f10e6da643","_cell_guid":"026bf4f6-00b0-4178-9bcc-fb8cbc44d1e0","trusted":true,"scrolled":false},"cell_type":"code","source":"def build_model(conv_layers = 2, max_dilation_rate = 3):\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Dropout(0.25)(x)\n    x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    prefilt_x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    out_conv = []\n    x = prefilt_x\n    # strides rate we use here for skip\n    for strides in [1, 1, 2]:\n        x = QRNN(128*2**(strides), \n                 return_sequences = True, \n                 stride = strides,\n                dropout = 0.2)(x)\n    x_f = QRNN(512)(x)  \n    x_b = QRNN(512, go_backwards=True)(x)\n    x = concatenate([x_f, x_b])\n    x = Dropout(0.5)(x)\n    x = Dense(64, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['binary_accuracy'])\n\n    return model\n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ae9fc16a72d57f707012d35ea5db3d538dbb505","_cell_guid":"aec3c661-33ce-44b7-8309-97da1653eadf"},"cell_type":"markdown","source":"# Train the Model\nHere we train the model and use model checkpointing and early stopping to keep only the best version of the model"},{"metadata":{"_uuid":"24747af54fb0253adb9934a78661ff0e68204af0","_cell_guid":"e0c81808-bb80-4c72-9150-4d4e9c8fa30f","trusted":true},"cell_type":"code","source":"batch_size = 1024 # big beefy GPUs like large batches\nepochs = 12\n\nfile_path=\"weights.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n\ncallbacks_list = [checkpoint, early] #early\nmodel.fit(X_t, y, \n          batch_size=batch_size, \n          epochs=epochs, \n          shuffle = True,\n          validation_split=0.25, \n          callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a3ba6881f6d7369e19b5920c40f5567ea6db54dd"},"cell_type":"markdown","source":"# Test on a few sentences\nShow what the model actually predicts for a few test sentences"},{"metadata":{"trusted":true,"_uuid":"8fb38ff65c8574fa89fb3c0b6f541b0a0024d9c2"},"cell_type":"code","source":"from IPython.display import Markdown, display\ndmd = lambda x: display(Markdown(x))\ndef show_sentence(sent_idx):\n    dmd('# Input Sentence:\\n `{}`'.format(list_sentences_train[sent_idx]))\n    c_pred = model.predict(X_t[sent_idx:sent_idx+1])[0]\n    dmd('## Positive Categories')\n    for k, v, p in zip(list_classes, y[sent_idx], c_pred):\n        if v>0:\n            dmd('- {}, Prediction: {:2.2f}%'.format(k, 100*v, 100*p))\n    dmd('## Negative Categories')\n    for k, v, p in zip(list_classes, y[sent_idx], c_pred):\n        if v<1:\n            dmd('- {}, Prediction: {:2.2f}%'.format(k, 100*p))\nshow_sentence(0)\nshow_sentence(50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb545c59982c3cb4d42ba8358cb4622814e94cba","_cell_guid":"0a5db347-fe8e-4218-9c9b-dc4bfe4824d5"},"cell_type":"markdown","source":"# Make Predictions\nLoad the model and make predictions on the test dataset"},{"metadata":{"_uuid":"92532dfaa0211e9b01d9ee3d78f86b3f1e570a3c","_cell_guid":"a3442437-db15-4e64-b377-c8bd010e7378","trusted":true},"cell_type":"code","source":"model.load_weights(file_path)\ny_test = model.predict(X_te, verbose = True, batch_size = 1024)\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nsample_submission[list_classes] = y_test\nsample_submission.to_csv(\"predictions.csv\", \n                         index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c662a5bed51b96648385ed69fd00c3431b58858"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}