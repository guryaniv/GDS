{"cells":[{"metadata":{"trusted":true,"_uuid":"57b5639ff9a0c93ab0d94136bcdebda4cb0be0dd"},"cell_type":"code","source":"#Read train and depth.csv and put them in one dataframe df_Train\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\nfrom PIL import Image\nimport matplotlib.image as mpimg\nimport os\nimport random as rn\nimport tensorflow as tf\nfrom keras import backend as K\n\n#set random seed to get reproducible results\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(1234)\nrn.seed(1234)\nnum_train_images= 4000\n\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\ntf.set_random_seed(1234)\n\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)\n\nprint(os.listdir(\"../input\"))\n\ndf_train = pd.read_csv(\"../input/train.csv\")\n#print(df_train.head())\nprint(\"\\n Train files shape is \", df_train.shape)\n\ndf_depths = pd.read_csv(\"../input/depths.csv\")\n\ndf_depths['z'] = df_depths['z'] / np.max(df_depths['z'])\n#print(df_depths.head())\nprint(\"\\nDepths files shape is \", df_depths.shape)\n\ndf_train = df_train.join(df_depths, lsuffix='idl', rsuffix='idr', how ='inner')\ndf_train.pop('ididr')\ndf_train.columns=['id', 'rle_mask','depth']\n#print(df_train.head())\n                        \n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#2. Read train & mask images and add them up df_train \ndf_train['images'] = [np.array(Image.open(\"../input/train/images/{}.png\".format(idx))) for \n                               idx in df_train['id']]\nprint(\"Sample Image Shape is \", df_train['images'][0].shape)\n\ndf_train['images'] = pd.Series(map(lambda x: np.delete(x,np.s_[1:],2), df_train['images']))\nprint(\"After optimization,  Image Shape is \", df_train['images'][0].shape)\nprint(\"No. of train images are \", len(df_train))\n\ndf_train['images']=df_train['images']/255\nprint(\"After normalization,  pixel value is \", df_train['images'][0][1,0])\n\ndf_train['masks'] = [np.array(Image.open(\"../input/train/masks/{}.png\".format(idx))) for \n                               idx in df_train['id']]\nprint(\"\\nSample Mask Shape is \", df_train['masks'][0].shape)\n\n#df_train['masks']=df_train['masks']/255\nprint(\"No. of mask images are \", len(df_train))\nprint(\"Before normalization,  pixel value is \", df_train['masks'][15][10,0])\n\nprint(\"train df columns are \", df_train.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f04bf2b78523c42036ef2a54757ece68b0dd2cd1"},"cell_type":"code","source":"train_x = np.array(df_train['images'])\ntrain_x = np.concatenate(train_x,axis=0)\ntrain_x = np.reshape(train_x,(4000,101,101,1))\nprint(\"Train Shape = \",train_x.shape)\nprint(\"Sample Pixel VAlue\", train_x[0,1,0])\n#print(df_train['masks'][5][0])\n\ntrain_y = np.array(df_train['masks'])\ntrain_y = np.concatenate(train_y,axis=0)\ntrain_y = np.reshape(train_y,(4000,101,101,1))\ntrain_y = train_y / train_y.max()\nprint(\"Mask Shape = \",train_y.shape)\ntrain_y = np.round(train_y)\nprint(\"Sample Pixel VAlue\", train_y[15,10,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6181ca14bae2269a388fd822d88f24ceed04c242"},"cell_type":"code","source":"#train_x = np.append(train_x, [np.fliplr(x) for x in train_x], axis=0)\n#train_y = np.append(train_y, [np.fliplr(x) for x in train_y], axis=0)\nprint(train_x.shape)\n#print(train_x_hflip.shape)\nprint(train_y.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34a12846055d9303483db90a50e39d03ef0fead6"},"cell_type":"code","source":"import os\nimport scipy.signal as sg\nimport tensorflow as tf\nfrom keras.models import Model\nfrom keras import layers, regularizers\nfrom keras import backend as K\nimport numpy as np\nfrom keras import layers\nHeight = 101\nWidth = 101\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"654d4f6022fba370c994bcdbc145820cd857db13"},"cell_type":"code","source":"import random as rn\nos.environ['PYTHONHASHSEED'] = '0'\nnp.random.seed(1234)\nrn.seed(1234)\nnum_train_images= 4000\n#print(depth_np.shape)\n#depth_np = np.zeros(shape = (num_train_images,Height,Width,1))\n#for i in range(num_train_images):\n#    depth_np[i] = np.full(shape=(Height,Width,1), fill_value=df_train['depth'].loc[i]) for \n\ndf_train['depth_image'] = pd.Series(map(lambda x:np.full(shape=(50,50,1), \n                                                         fill_value=x), df_train['depth']))\n\ndepth_np = np.array(df_train['depth_image'])\ndepth_np = np.concatenate(depth_np,axis=0)\ndepth_np = np.reshape(depth_np,(num_train_images,50,50,1))\ndepth_np_new = np.array(df_train['depth'])\nprint(\"depth\", depth_np_new[0:5])\nprint(depth_np_new.shape)\ndepth_np_new = depth_np_new.reshape((num_train_images,1,1,1))\nprint(\"depth shape \", depth_np_new.shape)\n#print(a.shape)\ndepth_np= depth_np/depth_np.max()\n#print(a[2][2])\nprint(df_train.columns)\n#depth_np = np.concatenate((depth_np, depth_np))\nprint(depth_np.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb0e49d1953763dc54d1b83a3bd23f0380788953"},"cell_type":"code","source":"Activation1 = 'elu'\nActivation2 = 'tanh'\ndef BatchActivate(x):\n    x = BatchNormalization()(x)\n    x = Activation('relu')(x)\n    return x\n\ndef convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n    x = layers.Conv2D(filters, size, strides=strides, padding=padding)(x)\n    if activation == True:\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation(Activation1)(x)\n    return x\n\ndef residual_block(blockInput, num_filters=16, activate = True):\n    #x = BatchActivate(blockInput)\n    x = convolution_block(blockInput, num_filters, (3,3) )\n    x = convolution_block(x, num_filters, (3,3), activation=False)\n    x = layers.Add()([x, blockInput])\n    x = layers.BatchNormalization()(x)\n    if activate:\n        x = layers.Activation(Activation2)(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"reg  = regularizers.l2(0.01)\nimg_input = layers.Input(shape=(Height, Width,1), name = 'img_input')\ndepth_input = layers.Input(shape=(50,50,1), name='depth_input')\ndepth_input_new = layers.Input(shape=(1,1,1), name='depth_input_new')\n\nprint(img_input)\nprint(depth_input)\n\n# First convolution extracts 16 filters that are 3x3 for Image Input and Depth Input\n#101-> 100\nprint(\"101->100\")\nx = layers.Conv2D(filters = 16, kernel_size= (2,2), padding='valid', activation='elu')(img_input)\nprint(x)\n\nx_depth = layers.Conv2D(filters = 16, kernel_size= (2,2), padding='valid', activation='elu')(depth_input)\nprint(x_depth)\n\n# Convolution is followed by max-pooling layer with a 2x2 window for Image Input and Avg Pooling for Depth Input\nprint(\"100 -> 50\") #100-> 50\nx_16_pool = layers.MaxPooling2D(pool_size=(2,2))(x)\nx_16_pool = layers.BatchNormalization()(x_16_pool)\n#x_16_pool = layers.Dropout(0.25)(x_16_pool) #Removed\nprint(x)\n\nx_16_pool_depth = layers.AveragePooling2D(pool_size=(2,2))(x_depth)\nx_16_pool_depth = layers.BatchNormalization()(x_16_pool_depth)\nx_16_pool_depth = layers.Dropout(0.2)(x_16_pool_depth)\nprint(x_16_pool_depth)\n\n# Second convolution with 2 same layers and resnet extracts 32 filters that are 3x3\nprint(\"50-> 48\") #50 > 48\nx = layers.Conv2D(32, 3, padding='valid',activation='elu')(x_16_pool)\n#x = residual_block(x,num_filters = 32) \nx2 = layers.Conv2D(32, 3, padding='same',activation='tanh', kernel_regularizer=reg)(x) \nx = layers.add([x, x2])\nx = layers.BatchNormalization()(x)\nprint(x)\n\nx_depth = layers.Conv2D(32, 3, padding='valid',activation='elu')(x_16_pool_depth)\nx2_depth = layers.Conv2D(32, 3, padding='same',activation='tanh', \n                         kernel_regularizer=reg)(x_depth)\nx_depth = layers.add([x_depth, x2_depth])#\nx_depth = layers.BatchNormalization()(x_depth)#\n\nprint(x_depth)\n# Convolution is followed by max-pooling layer with a 2x2 window\nprint(\"48-> 24\")#48->24\nx_32_pool = layers.MaxPooling2D(2)(x)\nprint(x_32_pool)\n\nx_32_pool_depth = layers.AveragePooling2D(2)(x_depth)\nprint(x_32_pool_depth)\n\nx = layers.Dropout(0.25)(x_32_pool)\nx_depth = layers.Dropout(0.2)(x_32_pool_depth)\n#x_combined = layers.add([x,x_depth])\n\n #Third convolution extracts 64 filters that are 3x3\n# Convolution is followed by max-pooling layer with a 2x2 window\nx = layers.Conv2D(64, 3, padding = 'same', activation='elu')(x) \n#x = residual_block(x, num_filters=64)#addedclosed\nx3 = layers.Conv2D(64, 3, padding = 'same', activation='elu', kernel_regularizer=reg)(x)#removed+2closed\nx = layers.add([x, x3])\nx = layers.BatchNormalization()(x)\nprint(x)\n\nx_depth = layers.Conv2D(64, 3, padding='same',activation='elu')(x_32_pool_depth)\nx2_depth = layers.Conv2D(64, 3, padding='same',activation='tanh', kernel_regularizer=reg)(x_depth)\nx_depth = layers.add([x_depth, x2_depth])\nx_depth = layers.BatchNormalization()(x_depth)\n\nprint(x_depth)\nprint(\"24->12\") #24->12\nx_64_pool = layers.MaxPooling2D(2)(x)\nx_64_pool_depth = layers.AveragePooling2D(2)(x_depth)\n\nprint(x)\nx_64_pool = layers.Dropout(0.25)(x_64_pool)\nx_64_pool_depth = layers.Dropout(0.2)(x_64_pool_depth)\n\n#x=layers.BatchNormalization()(x)\n\nx = layers.Conv2D(128, 3, padding = 'same', activation='elu')(x_64_pool)\n# = residual_block(x, num_filters=128) #addedclosed\nx2 = layers.Conv2D(128, 3, padding = 'same', activation='elu', \n                   kernel_regularizer=reg)(x)#removed+1closed\nx = layers.add([x,x2])\nprint(\"12->6\") #12->6\nx_128_pool = layers.MaxPooling2D(2)(x)\nprint(x_128_pool)\n\nx_128_pool = layers.Dropout(0.25)(x_128_pool)\n\nx = layers.Conv2D(192, 3, padding = 'same', activation='elu', \n                  kernel_regularizer=reg)(x_128_pool)\nprint(x)\nx_192_pool = layers.MaxPooling2D(2)(x)\nprint(x_192_pool)\n\nx_192_pool = layers.Dropout(0.25)(x_192_pool)\n\nx = layers.Conv2D(192, 2, padding = 'valid', activation='elu', \n                  kernel_regularizer=regularizers.l2(0.01))(x_192_pool)\nprint(x)\n#Alayers.BatchNormalization()(x) #addedclosed\nx = layers.MaxPooling2D(2)(x)\nprint(x)\n\nx = layers.Dropout(0.25)(x)\n\n#x = layers.Concatenate()([x,depth_input_new])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa8f0e523804a07b715fb0d3a8c6465311d7c29b"},"cell_type":"code","source":"#print(depth_input)\n#Define deconvolution layers\ninverse = layers.Conv2DTranspose(filters = 192, kernel_size=(3,3), strides=(2, 2), padding='valid', \n                                 activation = 'elu', kernel_regularizer=reg)(x)\nprint(inverse)\n\ninverse = layers.Concatenate()([inverse,x_192_pool])\n\ninverse = layers.Conv2D(filters=192, kernel_size=(2,2), padding='same', activation='elu',\n                       kernel_regularizer=reg)(inverse)\nprint(inverse)\ninverse = layers.BatchNormalization()(inverse)\n\ninverse = layers.Dropout(0.25)(inverse)\n\n\n\nprint(inverse)\n\ninverse = layers.Conv2DTranspose(filters = 128, kernel_size=(2,2), strides=(2, 2), padding='valid',\n                                 kernel_regularizer=reg, activation = 'elu')(inverse)\nprint(\"ok \",inverse)\n\ninverse = layers.Concatenate()([inverse,x_128_pool])\nprint(\"concatination \",inverse)\ninverse = layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='elu')(inverse)\ninverse = layers.BatchNormalization()(inverse)\n\ninverse = layers.Dropout(0.25)(inverse)\n\ninverse = layers.Conv2DTranspose(filters = 64, kernel_size=(2,2), strides=(2, 2), \n                                 padding='valid', activation = 'elu')(inverse)\nprint(inverse)\n\ninverse = layers.Concatenate()([inverse,x_64_pool])\n\ninverse = layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu',\n                       kernel_regularizer=reg)(inverse)\ninverse = layers.BatchNormalization()(inverse)\n\ninverse = layers.Dropout(0.25)(inverse)\n\n#inverse = layers.Concatenate()([inverse,x_64_pool_depth])\n\n#inverse = layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='elu')(inverse)\n#inverse = layers.BatchNormalization()(inverse)\n\n#inverse = layers.Dropout(0.25)(inverse)\n\ninverse = layers.Conv2DTranspose(filters = 32, kernel_size=(2,2), strides=(2, 2), \n                                 padding='valid', activation = 'elu')(inverse)\nprint(inverse)\n\ninverse = layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu',\n                       kernel_regularizer=reg)(inverse)\ninverse = layers.Concatenate()([inverse,x_32_pool])\ninverse = layers.BatchNormalization()(inverse)\n\ninverse = layers.Dropout(0.25)(inverse)\n\n#inverse = layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu')(inverse)\n#x_combined = layers.Concatenate()([inverse,x_depth])\n#print(\"Combined \", x_combined)\n#x_combined = layers.add([x_,x_depth])\n\n#x_combined = layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='elu')(x_combined)\n#x_combined = layers.BatchNormalization()(x_combined)\n\ninverse = layers.Conv2DTranspose(filters = 16, kernel_size=(4,4), strides=(2, 2), \n                                 padding='valid', activation = 'elu')(inverse)\nprint(inverse)\n\ninverse = layers.Concatenate()([inverse,x_16_pool])\ninverse = layers.Concatenate()([inverse,depth_input])\n\ninverse = layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='elu')(inverse)\ninverse = layers.BatchNormalization()(inverse)\n\ninverse = layers.Dropout(0.25)(inverse)\n\nprint(inverse)\n\n#inverse = layers.Concatenate()([inverse,x_16_pool_depth])\n\n#inverse = layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='elu')(inverse)\n#inverse = layers.BatchNormalization()(inverse)\n\n#inverse = layers.Dropout(0.2)(inverse)\n\n\ninverse2 = layers.Conv2DTranspose(filters = 1, kernel_size=(3,3), strides=(2, 2), \n                                  padding='valid',activation = 'sigmoid')(inverse)\nprint(inverse2)\n\n#inverse2_depth = layers.Conv2DTranspose(filters = 1, kernel_size=(3,3), strides=(2, 2), \n#                                        padding='valid',activation = 'relu')(x_depth)\n#print(inverse2_depth)\n\n#concatenated = concatenate([inverse2, inverse2_depth])\n#print(concatenated)\n\n#concatenated =layers.Dense(10201, activation='sigmoid')\n\n# Create model:\n# input = input feature map\n# output = input feature map + stacked convolution/maxpooling layers + fully\n# connected layer + sigmoid output layer\n\nmodel = Model([img_input,depth_input], inverse2)\n#model = Model(img_input, inverse2)\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"391b7b6a67357ca43f745e2db374fe13c865e0db"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nBatch_size = 96\ngen = ImageDataGenerator(horizontal_flip = True,\n                         vertical_flip = True)\n\ndef gen_flow_for_two_inputs(X1, X2, y):\n    genX1 = gen.flow(X1,y,  batch_size=Batch_size,seed = 1234, shuffle=True)\n    genX2 = gen.flow(X1,X2, batch_size=Batch_size,seed = 1234, shuffle=True)\n    while True:\n            X1i = genX1.next()\n            X2i = genX2.next()\n            #Assert arrays are equal - this was for peace of mind, but slows down training\n            #np.testing.assert_array_equal(X1i[0],X2i[0])\n            yield [X1i[0], X2i[1]], X1i[1]\n            \ndef get_iou(y_true, y_pred):\n    y_true = y_true.flatten()\n    y_pred = y_pred.flatten()\n    y_pred = np.round(y_pred)\n    intersect = np.sum(np.logical_not(np.logical_xor(y_true, y_pred)))\n    union = y_true.shape[0] #np.sum(y_true) + np.sum(y_pred)\n    #print(intersect)\n    return (intersect + 1e-9) / (union +1e-9)\n\ndef my_iou_metric(label, pred):\n    return tf.py_func(get_iou, [label, pred>0.5], tf.float64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26a22487679bc8a9fdcd611cfa040b852fca160a"},"cell_type":"code","source":"import keras.losses as losses\ndef dice_coeff(y_true, y_pred):\n    smooth = 0.00001\n    # Flatten\n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n    return score\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coeff(y_true, y_pred)\n    return loss\ndef bce_dice_loss(y_true, y_pred):\n    loss = 0.2 * losses.binary_crossentropy(y_true, y_pred) + 0.8 * dice_loss(y_true, y_pred)\n    #loss = dice_loss(y_true, y_pred)\n    return loss\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b90683886a54a418f61935110c495d2175b360e1"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_x1,val_x,depth_np1, val_depth, train_y1, val_y = train_test_split(\n    train_x, depth_np, train_y, test_size=0.25, random_state=1234)\nepochs = 60\nfrom  keras.optimizers import Adam\n\n#model.compile(loss='binary_crossentropy', optimizer='adam', metrics= ['acc'])#removed\nmodel.compile(optimizer='adam', loss=bce_dice_loss, metrics=[dice_coeff, 'acc'])#added\nfrom keras.callbacks import EarlyStopping\n\n\nearly_stopping = EarlyStopping(monitor='dice_coeff', patience=3, mode='max')\n#model.fit([train_x,depth_np],train_y, epochs=epochs,verbose=1, batch_size=96,\n#callbacks = [early_stopping])#removed\n#save_model_path = '/tmp/weights.hdf5'#added+2\n#cp = tf.keras.callbacks.ModelCheckpoint(filepath=save_model_path, \n #                                       monitor='val_dice_loss', save_best_only=True, verbose=1)\nhistory = model.fit([train_x,depth_np],train_y, #added\n                  # steps_per_epoch=int(np.ceil(num_train_examples / float(batch_size))),\n                   batch_size = Batch_size,\n                   epochs=epochs\n                   #validation_data=([val_x,val_depth],val_y),\n                   #validation_steps=int(np.ceil(num_val_examples / float(batch_size))),\n                   ,callbacks=[early_stopping]\n                   )\n\n#model.fit(train_x,train_y, epochs=epochs,verbose=1, batch_size=96, callbacks = [early_stopping])\n#reduce_lr = ReduceLROnPlateau(monitor='dice_loss', mode = 'max',factor=0.5, patience=5, \n#                              min_lr=0.0001, verbose=1)\n\n#gen_flow =\n\n#model.fit_generator( gen_flow_for_two_inputs(train_x, depth_np, train_y) , #validation_data= ([x_val, depth_np_val],y_val),\n      #                   steps_per_epoch=len(train_x) / Batch_size,                          \n       #                  epochs=epochs, callbacks = [early_stopping], verbose = 1 )\n\nmodel.save('model_7.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f3a3ecfcc76ac80ab25c8cfda24d2be28eaedb0","collapsed":true},"cell_type":"code","source":"print(\"Predicing the validation set....\")\nval_x_pred =model.predict([val_x, val_depth])\nprint(\"Validation set prediction completed.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e578bb7d5cf7c98c787a134d764b64fe969209c","collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig=plt.figure(figsize=(16, 8))\ncolumns = 3\nrows = 4\n%matplotlib inline\nfig, axs = plt.subplots(rows, columns)\nindex = np.random.randint(0,1000,rows)\n#print(y_pred[0,:,:,0].shape)\n#index = [206, 831, 524, 676]\nval_x_pred_new = np.round(val_x_pred-0.25)#-0.05)\nprint(index)\n#plt.imshow(y_pred[100,:,:,0])\nfor i in range(4):\n    #img = np.random.randint(10, size=(h,w))\n    #fig.add_subplot(rows, columns, i)\n        \n    axs[i, 0].imshow(val_x[index[i],:,:,0])#, cmap=cmap)\n    axs[i,1].imshow(val_y[index[i],:,:,0])#, cmap=cmap)\n    axs[i,2].imshow(val_x_pred_new[index[i],:,:,0])#, cmap=cmap)\n    #plt.imshow(y_pred_new[x[0],:,:,0])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d07556755eeec08740b95dddfc08191d7d4cf6b","collapsed":true},"cell_type":"code","source":"\n#lmodel = load_model('model_7.h5')\ndf_test = df_depths[~df_depths['id'].isin(df_train['id'])]\n\nprint(\"Length of df_test is \", len(df_test))\ndf_test = df_test.reset_index()\ndf_test.pop('index')\nprint(df_test.head())\n\n#df_test['images'] = \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d66158c2d3a47b05498419ad57d03bf2521ea11","collapsed":true},"cell_type":"code","source":"df_test['images'] = [np.array(Image.open(\"../input/test/images/{}.png\".format(idx))) for \n                               idx in df_test['id']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf5c29926d54f2c15c3f629570ed6e94e897d2b6","collapsed":true},"cell_type":"code","source":"#print(df_test.head())\nprint(\"Sample Image Shape is \", df_test['images'][10].shape)\n#print(\"Sample Image Shape is \", df_test.loc['images'][0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"918460a3ee33e3d2faf1cb8f1bc387cc6ec89de8","collapsed":true},"cell_type":"code","source":"df_test['images'] = pd.Series(map(lambda x: np.delete(x,np.s_[1:],2), df_test['images']))\nprint(\"After optimization,  Image Shape is \", df_test['images'][0].shape)\nprint(\"No. of test images are \", len(df_test))\nprint(\"Before normalization,  pixel value is \", df_test['images'][10][2,0])\ndf_test['images']=df_test['images'] / 255\nprint(\"After normalization,  pixel value is \", df_test['images'][10][2,0])\n\nprint(df_test.columns)\n\ntest_x = np.array(df_test['images'])\ntest_x = np.concatenate(test_x,axis=0)\ntest_x = np.reshape(test_x,(18000,101,101,1))\nprint(test_x.max())\nprint(test_x.min())\nprint(train_x.max())\nprint(train_x.min())\nprint(\"Train Shape = \",test_x.shape)\nprint(\"Sample Pixel VAlue\", test_x[10,2,0])\nprint(df_test.columns)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63f5e75ddb36df0553d799ab01109ad53b29b8b7","collapsed":true},"cell_type":"code","source":"df_test['depth_image'] = pd.Series(map(lambda x:np.full(shape=(50,50,1), \n                                                         fill_value=x), df_test['z']))\n\ndepth_test_np = np.array(df_test['depth_image'])\ndepth_test_np = np.concatenate(depth_test_np,axis=0)\ndepth_test_np = np.reshape(depth_test_np,(18000,50,50,1))\n\n#print(a.shape)\n#depth_np= depth_np/depth_np.max()\n#print(a[2][2])\nprint(df_test.columns)\nprint(depth_test_np.shape)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"89d0eaaef6d7183864e317e0717fb98fc463a0d1"},"cell_type":"code","source":"def post_process(x):\n    num_files= x.shape[0]\n    main_list = []\n    print('x shape ', x.shape)\n    pic_size = Height * Width\n    for i in range(num_files):\n        pic = x[i].T.flatten()\n        s = ''\n        length = 0\n        start = 0\n        for j in range(pic_size):\n            if (j == pic_size-1):\n                if((pic[j]==1) and (length==0)):\n                    #s = s + ' ' + str(j) + ' 1'\n                    s=\"{} {} 1\".format(s, str(j))\n                if( (pic[j]==1) and (length != 0)):\n                    #s =s + ' ' + str(start) + ' ' + str(length + 1)\n                    s=\"{} {} {}\".format(s, str(start), str(length+1))\n\n            else: #if(j != pic_size-1):\n                if(pic[j]==1):\n                    length += 1\n                    if(length==1):\n                        start = j+1\n                \n            if ((pic[j]==0) and (length>0)):\n                #s = s + ' ' + str(start) + ' ' + str(length)\n                s = \"{} {} {}\".format(s, str(start), str(length))\n                length = 0\n        main_list.append(s)\n    return main_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cca9a0ef6faede5735dc055df2153670301faaa9","collapsed":true},"cell_type":"code","source":"#Make the prediction\nprint(\"Predicting now.....\")\ny_pred = model.predict([test_x, depth_test_np])\nprint(\"Prediction Complete\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f81ed00c68203ff814a7a9974dd0f253b204c58","collapsed":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig=plt.figure(figsize=(8, 8))\ncolumns = 1\nrows = 4\n%matplotlib inline\nprint(y_pred[0,:,:,0].shape)\ny_pred_new = np.round(y_pred-0.25)\n#plt.imshow(y_pred[100,:,:,0])\nfor i in range(1, 4):\n    #img = np.random.randint(10, size=(h,w))\n    fig.add_subplot(rows, columns, i)\n    x = np.random.randint(0,4000,1)\n    print(x[0])\n    plt.imshow(y_pred_new[x[0],:,:,0])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c17939694ec308cdbb216966e84a884a09dd6191","collapsed":true},"cell_type":"code","source":"#Convert to submission format \nfor i in range(5,7):\n    #y_pred=np.round(y_pred-0.25).astype(int)\n    print(i)\n    \n    new_y_pred = post_process(np.round(y_pred- (i * 0.05)).astype(int))\n    output = pd.DataFrame( data = {'id': df_test['id'], 'rle_mask' : new_y_pred} )\n    file_name = \"output_\"+ str(i) +\".csv\"\n    print(file_name)\n    output.to_csv(file_name, index=False)\n#print(\"Y Prediction shape =\",y_pred.shape)\n#print(y_pred.min())\n#print(y_pred.max())\n#print(\"Y Prediction length =\",len(new_y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c0921a30765d65d38ee64734f61a06ddc85883a","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"eda56a94d46732fb3fe4a837b3e900a8ca0b8eaf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}