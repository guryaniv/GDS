{"nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "d7b18e3e-4f08-4794-9577-d8f439cae184", "collapsed": false, "_uuid": "f9869ab22b5ac85fb9fd8ad67a7aec8880b5ac84"}, "execution_count": null, "source": "I create s notebook to see why PCA ,may not work well if not combine with original data( the part of for loop may be take\nsome times)", "cell_type": "markdown"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "59d4c8a8-b1c8-4cd4-95c0-d86dbcc1841c", "_uuid": "e4c7d17722deb995826bd76de9b9a1dc9f56df9b"}, "execution_count": null, "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "7541e77f-4f15-477f-b099-e36a41a91244", "collapsed": false, "_uuid": "96e50f1c441793dfdc560da5390f6631f61b4193"}, "execution_count": null, "source": "from sklearn.decomposition import PCA, FastICA,KernelPCA,TruncatedSVD\nimport numpy as np\nfrom numpy.testing import assert_array_almost_equal\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "3479b523-a963-49b9-9bb9-10d100df42ae", "collapsed": false, "_uuid": "ea5ecfb18eee5810eb1b4dc008d83a07ff48425a"}, "execution_count": null, "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain=train[train.y<250]\ny_train = train['y']\ntrain=train.sort_values(['ID'])\ntest=test.sort_values(['ID'])\ntrain=train.drop(['y'],axis=1)\n\ndf=pd.concat([train,test])\n\npd.get_dummies(df).shape\n\n\n\n# process columns, apply LabelEncoder to categorical features\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder() \n        lbl.fit(list(train[c].values) + list(test[c].values)) \n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\n\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(train.shape, test.shape))\n\n\nnew_train=train.drop(['ID'],axis=1)\nnew_test=test.drop(['ID'],axis=1)\n\n\ndata = pd.concat([new_train,new_test])\n\ndata.shape\n", "cell_type": "code"}, {"source": "#VIF  analysis:\nX=data .values\n\nC=np.linalg.pinv(np.dot(X.T,X))\n\nfactor=[]\nfor i in range(0,C.shape[0]):\n    factor.append(C[i][i])\n\nplt.clf()\nplt.plot(factor)\nplt.show()", "metadata": {"_execution_state": "idle", "trusted": false, "_cell_guid": "ab37a00b-5b20-414e-88cd-28e89b8049b3", "collapsed": false, "_uuid": "8fd7289ec9327fef2635bf84b579191fa27ac51c"}, "execution_count": null, "cell_type": "code", "outputs": []}, {"source": "A little bit high in some regressor, but I think it's no needs to remove(  or can be done more detail)\n", "metadata": {"_execution_state": "idle", "_cell_guid": "ee2cde9e-40e6-42c1-9c3f-53081a828dea", "collapsed": false, "_uuid": "b827d31b536f86fe768df80bdd20d40ed7a7b91a"}, "execution_count": null, "cell_type": "markdown", "outputs": []}, {"outputs": [], "metadata": {"_execution_state": "busy", "trusted": false, "_cell_guid": "599e8ccb-90b6-4766-9d00-2badc5664593", "collapsed": false, "_uuid": "1c36005616535b1c4e07cf9d85001d2d7735b92a"}, "execution_count": null, "source": "from numpy import linalg as LA\nmax_comp=100\nstart=20\nerror_record=[]\nfor i in range(start,max_comp):\n    pca = PCA(n_components=i, random_state=42)\n    pca2_results = pca.fit_transform(data)\n    pca2_proj_back=pca.inverse_transform(pca2_results)\n    total_loss=LA.norm((data-pca2_proj_back),None)\n    error_record.append(total_loss)\n\nplt.clf()\nplt.figure(figsize=(15,15))\nplt.title(\"reconstruct error of pca\")\nplt.plot(error_record,'r')\nplt.xticks(range(len(error_record)), range(start,max_comp), rotation='vertical')\nplt.xlim([-1, len(error_record)])\nplt.show()\n", "cell_type": "code"}, {"outputs": [], "metadata": {"_execution_state": "idle", "_cell_guid": "2f9acbea-090d-40d8-9ace-12cf6cae8df9", "collapsed": false, "_uuid": "84ed4edfd85ba765e43399eb6dc4b46eb0b43c2c"}, "execution_count": null, "source": "The error is very large .That's why some script combine the PCA with original data will get the good score,up 100 still have many error  . I guess........", "cell_type": "markdown"}], "metadata": {"language_info": {"name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4}