{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nos.chdir('../input')\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nimport os\nimport gc\nimport time\nfrom keras.preprocessing import sequence,text\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.losses import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score,confusion_matrix,classification_report,f1_score\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom nltk import FreqDist\nfrom nltk.stem import SnowballStemmer,WordNetLemmatizer\n\nstart_sec = time.time()\n\ntrain = pd.read_csv('train.tsv', sep='\\t')\ntrain['Sentiment'] += 2\ntest = pd.read_csv('test.tsv', sep='\\t')\ntest['Sentiment'] = -999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28ed5cde9d1fe7512aa2850fbade2df8e1ff8fa6"},"cell_type":"code","source":"df = pd.concat([train, test], ignore_index = True)\n\nlemma = WordNetLemmatizer()\nclean_phrase = []\nfor i in range(len(df['Phrase'])):\n  t = re.sub('[^a-z]', ' ', df['Phrase'][i].lower())\n  temp = [lemma.lemmatize(word) for word in word_tokenize(t)]\n  seq = ' '.join(temp)\n  clean_phrase.append(seq)\n\n\n#print(train.head())\ndf['clean'] = clean_phrase\n\ntrain_data = df[df['Sentiment']!=-999]\ntest_data = df[df['Sentiment']==-999]\ntrain_phrase = df[df['Sentiment']!=-999]['clean']\ntest_phrase = df[df['Sentiment']==-999]['clean']\n#del df\n\ntrain_label = to_categorical(train_data['Sentiment'])\n\ntrain_x, valid_data, label_x, valid_label = train_test_split(train_data['Phrase'], train_label, test_size = 0.2)\n\n\nall_words = word_tokenize(' '.join(train_phrase))\ndist = FreqDist(all_words)\nnum_words = len(dist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3112f66ca20c1a3da4904fccd74cdbb1214295c0"},"cell_type":"code","source":"l = []\nfor i in train_data['clean']:\n  l.append(len(word_tokenize(i)))\n\nmax_seq_length = max(l)\n\nmax_features = num_words\nmax_words = max_seq_length\nbatch_size = 128\nepochs = 10\nnum_classes=train_label.shape[1]\n\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(train_x))\nX_train = tokenizer.texts_to_sequences(list(train_x))\nX_val = tokenizer.texts_to_sequences(list(valid_data))\nX_test = tokenizer.texts_to_sequences(list(test_phrase))\n\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_val = sequence.pad_sequences(X_val, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)\n\n\nmodel = Sequential()\nmodel.add(Embedding(max_features,250,mask_zero=True))\n\nmodel.add(LSTM(128,dropout=0.4, recurrent_dropout=0.4,return_sequences=True))\nmodel.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b246d9c63bc8877fcfc390a6aa885a903b97c0c"},"cell_type":"code","source":"model.add(Dense(32))\nmodel.add(Dense(num_classes,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\nmodel.summary()\n\nhistory=model.fit(X_train, label_x, validation_data=(X_val, valid_label),epochs=5, batch_size=batch_size, verbose=1)\nprint('running time is ', time.time()-start_sec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a96b6fffe300dc5aea29eb8b2c87df951e4cb5a3"},"cell_type":"code","source":"y_pred = model.predict_classes(X_test)\nsub=pd.read_csv('sampleSubmission.csv')\nsub.Sentiment=y_pred\n#f = open('sub.csv', 'w')\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}