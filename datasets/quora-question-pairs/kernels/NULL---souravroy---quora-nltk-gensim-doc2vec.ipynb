{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "426ff61f-037e-ee11-cc38-05f46d272b19"
      },
      "source": [
        "Make my hand dirty with Quora challenge.This is my first competition.Please suggest me to do better and it if helpful then don't forget to up vote and leave you feedback  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9330326e-3de2-026d-168c-462e111ec625"
      },
      "outputs": [],
      "source": [
        "#Import Initial Packages\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "import gensim\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re \n",
        "from collections import namedtuple\n",
        "import multiprocessing\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "stopwords = stopwords.words(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "39e85dac-c0ca-f3b6-b1d4-dc28fd247da9"
      },
      "source": [
        "**Data Analysis and Natural Language processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "425f14f1-f0fd-f83a-c960-203c500da2f2"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"../input/train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f83ba52b-7e69-864c-a8e6-05eb51742573"
      },
      "outputs": [],
      "source": [
        "df_train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be8486b3-6739-21b2-d250-59ebd3fd8aec"
      },
      "outputs": [],
      "source": [
        "df_train_set1 = df_train[[\"qid1\",\"question1\"]]\n",
        "df_train_set2 = df_train[[\"qid2\",\"question2\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d23772d5-e04b-9c27-08bb-ebcd1a980c03"
      },
      "outputs": [],
      "source": [
        "df_train_set1.columns = [\"qid\",\"question\"]\n",
        "df_train_set2.columns =[\"qid\",\"question\"]\n",
        "df_train_set = pd.concat([df_train_set1,df_train_set2],axis=0)\n",
        "print(\"df_train_set_1 :\",df_train_set1.shape)\n",
        "print(\"df_train_set_2 :\",df_train_set1.shape)\n",
        "print(\"df_train_set :\",df_train_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e1fcaf7-0dbe-bb22-af75-e2fa266b258a"
      },
      "outputs": [],
      "source": [
        "df_train_set1.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c7275c7d-25b0-ccf4-dc47-417330d7fce5"
      },
      "outputs": [],
      "source": [
        "df_train_set2.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4ffbed50-0160-6c80-ccc5-a211f74dd34c"
      },
      "outputs": [],
      "source": [
        "df_train_set.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "04ed9886-6348-a17e-8c9f-dbe4a084a974"
      },
      "outputs": [],
      "source": [
        "print(df_train_set1[\"question\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "29fab861-fe52-2fd1-053e-785f7e23be3a"
      },
      "outputs": [],
      "source": [
        "print(df_train_set2[\"question\"].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4cd13056-3c60-12b2-e9aa-fa58331d15a8"
      },
      "outputs": [],
      "source": [
        "print(df_train_set[\"question\"].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae318b67-a5ef-1ec6-19b1-1e9f9c2761ec"
      },
      "outputs": [],
      "source": [
        "#Lemmatizing words.Ex - consider cats and cat are different word even they both are mostly similar cotext or reffer to similar things\n",
        "print(lemmatizer.lemmatize(\"cats\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7807c022-9e81-aa25-4cf9-a087cde45733"
      },
      "outputs": [],
      "source": [
        "#Language Processing\n",
        "def get_processed_text(text=\"\"):\n",
        "    \"\"\"\n",
        "    Remove stopword,lemmatizing the words and remove special character to get important content\n",
        "    \"\"\"\n",
        "    clean_text = re.sub('[^a-zA-Z0-9 \\n\\.]', ' ', text)\n",
        "    tokens = tokenizer.tokenize(clean_text)\n",
        "    tokens = [lemmatizer.lemmatize(token.lower().strip()) for token in tokens\n",
        "              if token not in stopwords and len(token) >= 2]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "46569a8e-dbab-3871-7883-a3c033ba9af9"
      },
      "outputs": [],
      "source": [
        "text = \"What is the best phone to buy below 15k\"\n",
        "print (\"Original Text : \",text)\n",
        "processed_text = \" \".join(get_processed_text(text))\n",
        "print (\"Processed Text : \",processed_text) #Remove special character(?),english stop words(is,the,by,to,in) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b7561da8-3d15-36a7-e178-bbb7ca069c53"
      },
      "outputs": [],
      "source": [
        "df_train_set.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45731233-f092-5332-7c9a-7e7058feaa63"
      },
      "outputs": [],
      "source": [
        "#Process and clean up traing set\n",
        "alldocuments = []\n",
        "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')       \n",
        "keywords = []\n",
        "for index,record in df_train_set[0:100].iterrows():\n",
        "    qid = str(record[\"qid\"])\n",
        "    question = str(record[\"question\"])\n",
        "    tokens = get_processed_text(question)\n",
        "    words = tokens\n",
        "    words_text = \" \".join(words)\n",
        "    words = gensim.utils.simple_preprocess(words_text)\n",
        "    tags = [qid]\n",
        "    alldocuments.append(analyzedDocument(words, tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "51b44434-217c-19f9-4212-6f0b81131bce"
      },
      "outputs": [],
      "source": [
        "alldocuments[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3fc5dc0a-8a87-bd93-fdf0-138bd7dd6b0f"
      },
      "outputs": [],
      "source": [
        "def train_and_save_doc2vec_model(alldocuments,document_model=\"model1\",m_iter=100,m_min_count=2,m_size=100,m_window=5):\n",
        "            print (\"Start Time : %s\" %(str(datetime.datetime.now())))\n",
        "            #Train Model\n",
        "            cores = multiprocessing.cpu_count()\n",
        "            abs_path = os.getcwd()\n",
        "            saved_model_name = \"doc_2_vec_%s\" %(document_model)\n",
        "            doc_vec_file = \"%s\" %(saved_model_name)\n",
        "            if document_model == \"model1\":\n",
        "                # PV-DBOW \n",
        "                model_1 = gensim.models.Doc2Vec(alldocuments,dm=0,workers=cores,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter,dbow_words=1)\n",
        "                model_1.save(\"%s\" %(doc_vec_file))\n",
        "                print (\"model training completed : %s\" %(doc_vec_file))\n",
        "            elif document_model == \"model2\":\n",
        "                # PV-DBOW \n",
        "                model_2 = gensim.models.Doc2Vec(alldocuments,dm=0,workers=cores,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter,dbow_words=0)\n",
        "                model_2.save(\"%s\" %(doc_vec_file))\n",
        "                print (\"model training completed : %s\" %(doc_vec_file))\n",
        "            elif document_model == \"model3\":\n",
        "                # PV-DM w/average\n",
        "                model_3 = gensim.models.Doc2Vec(alldocuments,dm=1, dm_mean=1,size=m_size, window=m_window,min_count=m_min_count,iter=m_iter)\n",
        "                model_3.save(\"%s\" %(doc_vec_file))\n",
        "                print (\"model training completed : %s\" %(doc_vec_file))\n",
        "\n",
        "            elif document_model == \"model4\":\n",
        "                # PV-DM w/concatenation - window=5 (both sides) approximates paper's 10-word total window size\n",
        "                model_4 = gensim.models.Doc2Vec(alldocuments,dm=1, dm_concat=1,workers=cores, size=m_size, window=m_window,min_count=m_min_count,iter=m_iter)\n",
        "                model_4.save(\"%s\" %(doc_vec_file))\n",
        "                print (\"model training completed : %s\" %(doc_vec_file))\n",
        "            print (\"Record count %s\" %len(alldocuments))\n",
        "            print (\"End Time %s\" %(str(datetime.datetime.now())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0191d569-1dc5-c4f5-d698-5b162193d486"
      },
      "outputs": [],
      "source": [
        "#Train model\n",
        "train_and_save_doc2vec_model(alldocuments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "04cd886a-4332-f260-4018-e4e3cf3cf73e"
      },
      "outputs": [],
      "source": [
        "ls -ltr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a1d7a9e-2eee-ebea-5ea8-97a0698fbb74"
      },
      "outputs": [],
      "source": [
        "def get_question_similarity_score(question1=\"\",question2=\"\"):\n",
        "    print (\"question1 - \",question1)\n",
        "    print (\"question2 - \",question2)\n",
        "    model_name = \"%s\" %(\"doc_2_vec_model1\")\n",
        "    model_saved_file = \"%s\" %(model_name)\n",
        "    model = gensim.models.doc2vec.Doc2Vec.load(model_saved_file)\n",
        "    \n",
        "    question_token1 = get_processed_text(question1)\n",
        "    tokenize_text1 = ' '.join(question_token1)\n",
        "    tokenize_text1 = gensim.utils.simple_preprocess(tokenize_text1)\n",
        "    infer_vector_of_question1 = model.infer_vector(tokenize_text1)\n",
        "    \n",
        "    print(\"tokenize_text1\",tokenize_text1,\"infer_vector_of_question1\",infer_vector_of_question1)\n",
        "    \n",
        "    question_token2 = get_processed_text(question2)\n",
        "    tokenize_text2 = ' '.join(question_token2)\n",
        "    tokenize_text2 = gensim.utils.simple_preprocess(tokenize_text2)\n",
        "    infer_vector_of_question2 = model.infer_vector(tokenize_text2)\n",
        "    \n",
        "    print(\"tokenize_text2\",tokenize_text2,\"infer_vector_of_question2\",infer_vector_of_question2)\n",
        "    similarity_score = 1\n",
        "    #similarity_score = model.docvecs.most_similar(infer_vector_of_question1)\n",
        "    msg= \"question : %s model_name : %s \" %(question,model_name)\n",
        "   \n",
        "    return similarity_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ccb128b3-22e8-6e48-e2c4-f011e4aa04a8"
      },
      "outputs": [],
      "source": [
        "test_id_list = []\n",
        "similarity_score_list = []\n",
        "df_test = pd.read_csv(\"../input/test.csv\")\n",
        "for index,record in df_test[0:10].iterrows():\n",
        "    test_id = str(record[\"test_id\"])\n",
        "    question1 = str(record[\"question1\"])\n",
        "    question2 = str(record[\"question2\"])\n",
        "    similarity_score = get_question_similarity_score(question1,question2)\n",
        "    test_id_list.append(test_id)\n",
        "    similarity_score_list.append(similarity_score)\n",
        "    \n",
        "#submission = pd.DataFrame({\n",
        "#\"test_id\": test_id_list,\n",
        "#\"is_duplicate\": similarity_score_list})\n",
        "#submission.to_csv('./first_submition.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ac0871eb-9bad-78fe-ff0c-2f4713dea423"
      },
      "source": [
        "**Final Submition yet to come.Shorty i will update**"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}