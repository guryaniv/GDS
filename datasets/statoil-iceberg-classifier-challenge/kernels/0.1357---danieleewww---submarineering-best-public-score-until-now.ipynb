{"nbformat": 4, "metadata": {"language_info": {"file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "version": "3.6.3"}, "kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "71cd635b-4fb7-47a6-acfa-0eeec414216d", "_uuid": "2eb7adaeaf575bd8c68e24ce1ec940416aa9d3c9"}, "source": ["<img src=\"https://lh3.googleusercontent.com/-tNe1vwwd_w4/VZ_m9E44C7I/AAAAAAAAABM/5yqhpSyYcCUzwHi-ti13MwovCb_AUD_zgCJkCGAYYCw/w256-h86-n-no/Submarineering.png\">"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "c22ec78f-8cf5-4bfb-a5aa-c3138158abb2", "_uuid": "51d8333108689693cd7cba917761960d1948f74a"}, "source": ["This is the **best public score** kernel in the competition until now. \n", "I hpoe it be useful for those than pre-train and make knowledge tranfer to the model. \n", "If it waas useful for you, **please VOTE me UP.**"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "28a96b13-fb54-43af-aeb9-ccb40526ec1f", "_uuid": "518b490c58f98a59d25d8d5d8c39dca0673564e1"}, "execution_count": null, "source": ["import os\n", "import numpy as np \n", "import pandas as pd \n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "cell_type": "code"}, {"metadata": {"_cell_guid": "b4d21b76-54f0-42db-a60f-5cba96b239bd", "_uuid": "9db24b56f89561784a4118c9faf4aca6cfdaea3a"}, "source": ["First thing first@\n", "# Credits to the following awesome authors and kernels\n", "\n", "Author: QuantScientist    \n", "File: sub_200_ens_densenet.csv     \n", "Link: https://www.kaggle.com/solomonk/pytorch-cnn-densenet-ensemble-lb-0-1538     \n", "\n", "\n", "Author: wvadim     \n", "File: sub_TF_keras.csv     \n", "Link: https://www.kaggle.com/wvadim/keras-tf-lb-0-18     \n", "\n", "\n", "Author: Ed Miller    \n", "File: sub_fcn.csv    \n", "Link: https://www.kaggle.com/bluevalhalla/fully-convolutional-network-lb-0-193     \n", "\n", "\n", "Author: Chia-Ta Tsai    \n", "File: sub_blend009.csv    \n", "Link: https://www.kaggle.com/cttsai/ensembling-gbms-lb-203    \n", "\n", "\n", "Author: DeveshMaheshwari    \n", "File: sub_keras_beginner.csv    \n", "Link: https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d       \n", "\n", "Author: Submarineering    \n", "\n", "File: submission38.csv\n", "\n", "Link : https://www.kaggle.com/submarineering/submission38-lb01448\n", "\n", "### Without their truly dedicated efforts, this notebook will not be possible.     "], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "1840df41-7524-4305-93d9-423a2a6fe5bd", "_uuid": "aae1d396e2fad44a15fcb8e970c5affa8fb6ddc6"}, "source": ["# Data Load"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "5cf037ae-98a4-44d5-92e6-090c3686e2df", "_uuid": "da6c496f6bc0f2228a30da1cb31c50d2bbe33569"}, "execution_count": null, "source": ["sub_path = \"../input/statoil-iceberg-submissions\"\n", "all_files = os.listdir(sub_path)\n", "all_files = all_files[1:3]\n", "all_files.append('submission38.csv')\n", "all_files"], "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "c978c838-8a87-45ef-a118-b6bd565bdb2e", "_uuid": "1fa9dd2434873dc5bc918b102a3a69649d0f35c7"}, "execution_count": null, "source": ["# Read and concatenate submissions\n", "out1 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_200_ens_densenet.csv\", index_col=0)\n", "out2 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_TF_keras.csv\", index_col=0)\n", "out3 = pd.read_csv(\"../input/submission38-lb01448/submission38.csv\", index_col=0)\n", "concat_sub = pd.concat([out1, out2, out3], axis=1)\n", "cols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_sub.columns))))\n", "concat_sub.columns = cols\n", "concat_sub.reset_index(inplace=True)\n", "concat_sub.head()\n"], "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "a193cac9-e544-4749-8622-2c0a7d882193", "_uuid": "37b39229e34b71032d8d2371c6b731ed452b8eb2"}, "execution_count": null, "source": ["# check correlation\n", "concat_sub.corr()"], "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "c7be9be8-b999-42d9-a0cc-6bf2a035b25b", "collapsed": true, "_uuid": "07cdbb447c11008557c1773e464d08f798d8b2b2"}, "execution_count": null, "source": ["# get the data fields ready for stacking\n", "concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\n", "concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\n", "concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\n", "concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)"], "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "2b115d55-48f4-43c6-9b22-dbd8cd5a28a8", "collapsed": true, "_uuid": "d412b01db3dd513eef9158bfaaebe96617e79d5b"}, "execution_count": null, "source": ["# set up cutoff threshold for lower and upper bounds, easy to twist \n", "#cutoff_lo = 0.7\n", "#cutoff_hi = 0.3\n", "cutoff_lo = 0.75\n", "cutoff_hi = 0.25"], "cell_type": "code"}, {"metadata": {"_cell_guid": "d0493bc1-1d92-4bc7-aa84-107fcb6d7324", "_uuid": "698574b4531ce5ec1c59d5afaf451392169af5e0"}, "source": ["# Mean Stacking"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "f1169e63-b019-4a39-87b5-8fa1d0488f09", "collapsed": true, "_uuid": "a6642e2884dacc8c5095413e6a0945c6791ee1b5"}, "execution_count": null, "source": ["#concat_sub['is_iceberg'] = concat_sub['is_iceberg_mean']\n", "#concat_sub[['id', 'is_iceberg']].to_csv('stack_mean.csv', index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "64a7aeea-ac14-4ae8-ac62-0c58b13c1f9e", "_uuid": "a24eecfd51f4f6665d751f3f1c126e46a44426bd"}, "source": ["**LB 0.1698** , decent first try - still some gap comparing with our top-line model performance in stack."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "103f2414-04a8-40bd-8ffc-4e77e510e023", "_uuid": "d213635b179fc8d07a6985d257c8c3e0007e0f7a"}, "source": ["# Median Stacking"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "9d5af2c0-1cc5-4adc-9153-d20d19c69bd6", "collapsed": true, "_uuid": "76fc5734615b45bf6234df1f450c9a24ca518834"}, "execution_count": null, "source": ["#concat_sub['is_iceberg'] = concat_sub['is_iceberg_median']\n", "#concat_sub[['id', 'is_iceberg']].to_csv('stack_median.csv', index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "3da1db01-1922-4d34-ae02-1d3acfa59fca", "_uuid": "a1a1754ba1c9ca956da71920dcc5bf2f0ee78172"}, "source": ["**LB 0.1575**, very close with our top-line model performance, but we want to see some improvement at least."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "fba2a588-19a4-41fd-a495-af6a3a551777", "_uuid": "caa0cb178c1f4921cb7c5b6552bfe4e0fb91475e"}, "source": ["# PushOut + Median Stacking \n", "\n", "Pushout strategy is a bit agressive given what it does..."], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "f8646a39-f2cc-483a-912b-46af12b5de64", "collapsed": true, "_uuid": "e6038b30485244cf144ede75fb3ecab55afa3f84"}, "execution_count": null, "source": ["#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), 1, \n", "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n", "#                                             0, concat_sub['is_iceberg_median']))\n", "#concat_sub[['id', 'is_iceberg']].to_csv('stack_pushout_median.csv', \n", "#                                        index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "f016ad2f-ddc9-4182-a288-32f4dcb466d3", "_uuid": "ed7b3420cf44929c977970605c9c231714926e0e"}, "source": ["**LB 0.1940**, not very impressive results given the base models in the pipeline..."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "26fa22e0-4f00-455b-8328-3e3cdf34adfb", "_uuid": "9244a9d9ddce162fa7ddd7d32e271097b0b405df"}, "source": ["# MinMax + Mean Stacking\n", "\n", "MinMax seems more gentle and it outperforms the previous one given its peformance score."], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "7634aaa4-2466-45b1-afbf-32dedb8691a4", "collapsed": true, "_uuid": "4ffd0c65d59a03ee04d5452b853efac717f3f3f7"}, "execution_count": null, "source": ["#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n", "#                                    concat_sub['is_iceberg_max'], \n", "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n", "#                                             concat_sub['is_iceberg_min'], \n", "#                                             concat_sub['is_iceberg_mean']))\n", "#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_mean.csv', \n", "#                                        index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "de9e7a52-2a3e-440a-9056-93ed4d9f87f9", "_uuid": "c4da0e0b2530daf4fdcb362980ad9fbfce5b3476"}, "source": ["**LB 0.1622**, need to stack with Median to see the results."], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "61831c59-a583-45d6-9bba-1102d1f80862", "_uuid": "95b5ccf95505b498dede6966f2a899c376d855dd"}, "source": ["# MinMax + Median Stacking "], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "8aa75397-da75-4d93-916e-d88f464e13fe", "collapsed": true, "_uuid": "d4b7e91489d86452dc6d13340109e07da40f9fa9"}, "execution_count": null, "source": ["#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n", "#                                    concat_sub['is_iceberg_max'], \n", "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n", "#                                             concat_sub['is_iceberg_min'], \n", "#                                             concat_sub['is_iceberg_median']))\n", "#concat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\n", "#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_median.csv', \n", "#                                       index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "b9d1df47-6c0b-4bca-9357-ceaf61746171", "_uuid": "1abbdcd40aca61b375ee4dd0e3e90b814cecceba"}, "source": ["**LB 0.1488** - **Great!** This is an improvement to our top-line model performance (LB 0.1538). But can we do better?"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "307ebff0-d690-4dbf-8496-3fc8340bcc60", "_uuid": "935499734e508b98e7d694606bd2851a4b3cbce5"}, "source": ["# MinMax + BestBase Stacking"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "59f60095-f1ff-4c26-8d51-e0111e80f3ba", "collapsed": true, "_uuid": "8e3f2ac12368eac5fc2b69e9e899873dd33adef8"}, "execution_count": null, "source": ["# load the model with best base performance\n", "sub_base = pd.read_csv('../input/submission38-lb01448/submission38.csv')"], "cell_type": "code"}, {"outputs": [], "metadata": {"_cell_guid": "2758287f-0e47-4dc6-ab11-004ce8812f8f", "collapsed": true, "_uuid": "2ac62e85fbafd2a9095e71d576633a65694787d8"}, "execution_count": null, "source": ["concat_sub['is_iceberg_base'] = sub_base['is_iceberg']\n", "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n", "                                    concat_sub['is_iceberg_max'], \n", "                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n", "                                             concat_sub['is_iceberg_min'], \n", "                                             concat_sub['is_iceberg_base']))\n", "concat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\n", "concat_sub[['id', 'is_iceberg']].to_csv('submission39.csv', \n", "                                        index=False, float_format='%.6f')"], "cell_type": "code"}, {"metadata": {"_cell_guid": "a6e915c2-719e-41be-8760-e05271058ac7", "_uuid": "3b1a6a2c393b1858847a895dbfc92f4bd71b719a"}, "source": ["\n", "Roboust model is always the key component, stacking only comes last with the promise to surprise, sometimes, in an unpleasant direction@. \n", "\n", "For more efficient models I highly recommend my engineering features extraction kernels: \n", "\n", "https://www.kaggle.com/submarineering/submarineering-size-matters-0-75-lb\n", "\n", "https://www.kaggle.com/submarineering/submarineering-objects-isolation-0-75-lb\n", "\n", "https://www.kaggle.com/submarineering/submarineering-what-about-volume-lb-0-45\n", "\n", "Greeting, Subamrineering.\n", "\n", "\n"], "cell_type": "markdown"}, {"metadata": {"_cell_guid": "2eec9111-e4d0-4aca-ad39-a2e8b3adaf11", "_uuid": "b37f85c4d43ab41574a6503b536f21e634079ac7"}, "source": ["I hope these lines be useful for your. **Please vote up.**"], "cell_type": "markdown"}, {"outputs": [], "metadata": {"_cell_guid": "67018cdf-68a3-4b1f-bdf8-e9ecb3d0b378", "collapsed": true, "_uuid": "8bda1361fdf30328ad1b89347255bd6ae7e5536e"}, "execution_count": null, "source": [], "cell_type": "code"}]}