{"nbformat": 4, "cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "1068951b68f5b044aa489bce509b565840865e55", "_cell_guid": "a29bcfdf-0409-4e5d-9860-dd69023d876d"}, "execution_count": 1}, {"cell_type": "markdown", "metadata": {"_uuid": "9f4c8644fda3297169362a8a140294926f5e3f93", "_cell_guid": "0143fd54-fd67-465b-bfe4-6f370525b39c"}, "source": ["# Which Classifier is Should I Choose?\n", "\n", "This is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data."]}, {"source": ["import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "\n", "def warn(*args, **kwargs): pass\n", "import warnings\n", "warnings.warn = warn\n", "\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.cross_validation import StratifiedShuffleSplit\n", "\n", "train = pd.read_csv('../input/train.csv')\n", "test = pd.read_csv('../input/test.csv')"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "ed70f784669c94a48c0ca94f2c3a25502edbf335", "_cell_guid": "47de7577-9948-4fe1-8cbf-651fa9e3532f"}, "execution_count": 2}, {"cell_type": "markdown", "metadata": {"_uuid": "5f733fff8fe747f91d847ddf74a8cb44fabe3483", "_cell_guid": "21039872-f503-4241-9108-5cb358c64500"}, "source": ["# Data Preparation"]}, {"source": ["def encode(train, test):\n", "    le = LabelEncoder().fit(train.species) \n", "    labels = le.transform(train.species)           # encode species strings\n", "    classes = list(le.classes_)                    # save column names for submission\n", "    test_ids = test.id                             # save test ids for submission\n", "    train = train.drop(['species', 'id'], axis=1)  \n", "    test = test.drop(['id'], axis=1)\n", "    return train, labels, test, test_ids, classes\n", "\n", "train, labels, test, test_ids, classes = encode(train, test)"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "d575227066d275b0f962efc12ccd42e572e1c7ad", "_cell_guid": "72bd4152-0c0b-442f-8536-21afd02feef1"}, "execution_count": 3}, {"cell_type": "markdown", "metadata": {"_uuid": "bd332e49a024ddda9f3ea7fb3e73ca8e2f257519", "_cell_guid": "fd779db9-605e-4143-a872-c2c272d85f37"}, "source": ["# Stratified Train/Test Split\n", "\n", "Stratification is necessary for this dataset because there is a relatively large number of classes (100 classes for 990 samples). This will ensure we have all classes represented in both the train and test indices."]}, {"source": ["sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n", "\n", "for train_index, test_index in sss:\n", "    X_train, X_test = train.values[train_index], train.values[test_index]\n", "    y_train, y_test = labels[train_index], labels[test_index]"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "92afc002c52ec2b5ea76b7723ca8e966a19f02fb", "_cell_guid": "f6b1ec55-d93c-46a5-b740-051f16cdbad8"}, "execution_count": 5}, {"cell_type": "markdown", "metadata": {"_uuid": "a99b847c3c7034a5d0c65796d5dc8774387802e4", "_cell_guid": "d3721ca3-6ff8-4057-9f68-cbf02971e4b2"}, "source": ["# Apply scaling (using StandardScaler() from sklearn.preprocessing)"]}, {"source": ["from sklearn.preprocessing import StandardScaler\n", "scaler = StandardScaler().fit(X_train)\n", "X_train = scaler.transform(X_train)\n", "X_test = scaler.transform(X_test)\n", "test = scaler.transform(test)"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "079f492f7b82af6bcb2e40b50816e61b43ea399b", "_cell_guid": "6bc9a839-c671-4cff-86cb-caf8449dcb5c"}, "execution_count": 6}, {"cell_type": "markdown", "metadata": {"_uuid": "5dcd77f2f8184e3501d88ba6fc86d846f09b1035", "_cell_guid": "7c979aa2-dbaa-431a-ac2a-ed4f93b8d223"}, "source": ["# Sklearn Classifier Showdown\n", "\n", "Simply looping through 12 out-of-the box classifiers using sclaling data and printing the results. Obviously, these will perform much better after tuning their hyperparameters, but this gives you a decent ballpark idea."]}, {"source": ["from sklearn.metrics import accuracy_score, log_loss\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.svm import SVC, NuSVC\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n", "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n", "from sklearn.neural_network import MLPClassifier\n", "from sklearn.linear_model import LogisticRegression\n", "\n", "classifiers = [\n", "    KNeighborsClassifier(3),\n", "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n", "    NuSVC(probability=True),\n", "    DecisionTreeClassifier(),\n", "    RandomForestClassifier(),\n", "    AdaBoostClassifier(),\n", "    GradientBoostingClassifier(),\n", "    GaussianNB(),\n", "    LinearDiscriminantAnalysis(),\n", "    QuadraticDiscriminantAnalysis(),\n", "    MLPClassifier(hidden_layer_sizes=(100,100,100),batch_size=10,max_iter=200),\n", "    LogisticRegression(solver='lbfgs', multi_class='multinomial')]\n", "\n", "# Logging for Visual Comparison\n", "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n", "log = pd.DataFrame(columns=log_cols)\n", "\n", "for clf in classifiers:\n", "    clf.fit(X_train, y_train)\n", "    name = clf.__class__.__name__\n", "    \n", "    print(\"=\"*max(map(lambda x: len(x.__class__.__name__), classifiers)))\n", "    print(name)\n", "    \n", "    print('****Results****')\n", "    train_predictions = clf.predict(X_test)\n", "    acc = accuracy_score(y_test, train_predictions)\n", "    print(\"Accuracy: {:.4%}\".format(acc))\n", "    \n", "    train_predictions = clf.predict_proba(X_test)\n", "    ll = log_loss(y_test, train_predictions)\n", "    print(\"Log Loss: {:.4f}\".format(ll))\n", "    \n", "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n", "    log = log.append(log_entry)\n", "    \n", "print(\"=\"*max(map(lambda x: len(x.__class__.__name__), classifiers)))"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "a3534c8168c12db1dfb1995c6dbc5b665eb894c1", "_cell_guid": "ee889985-af7f-4982-bd20-1b8fca7bc75b"}, "execution_count": 7}, {"cell_type": "markdown", "metadata": {"_uuid": "66678f4ef8dc293f50d89a267b0513b4ff0493f1", "_cell_guid": "69ae66b2-5dc5-42a8-93e2-5f43b5a91b40"}, "source": ["# Barplots display"]}, {"source": ["sns.set_color_codes(\"muted\")\n", "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n", "\n", "plt.xlabel('Accuracy %')\n", "plt.title('Classifier Accuracy')\n", "plt.show()\n", "\n", "sns.set_color_codes(\"muted\")\n", "sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n", "\n", "plt.xlabel('Log Loss')\n", "plt.title('Classifier Log Loss')\n", "plt.show()"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "c101803288d8220479d30ae4cead848df2c55067", "_cell_guid": "47fb55e5-8784-443a-9bf3-05145540ee19"}, "execution_count": 8}, {"cell_type": "markdown", "metadata": {"_uuid": "7ccb66beb2944b7f5e2bd37d7a58901847718637", "_cell_guid": "33186675-bd95-4e69-a945-3c6219d5edce"}, "source": ["# Submission\n", "\n", "After choosing your favorite classifier, format the output for a leaderboard submission."]}, {"source": ["favorite_clf = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n", "favorite_clf.fit(train, labels)\n", "test_predictions = favorite_clf.predict_proba(test)\n", "\n", "# Format DataFrame\n", "submission = pd.DataFrame(test_predictions, columns=classes)\n", "submission.insert(0, 'id', test_ids)\n", "submission.reset_index()\n", "\n", "# Export Submission\n", "submission.to_csv('submission.csv', index = False)\n", "submission.tail()"], "cell_type": "code", "outputs": [], "metadata": {"collapsed": true, "_uuid": "5b51b0c78702fcbe6bd9850e98b72b007921ebe4", "_cell_guid": "9292e7ee-dd9a-499f-8c12-ff8f4182e24d"}, "execution_count": 9}, {"cell_type": "markdown", "metadata": {"_uuid": "1ce4bc94630c7116721b08a79f6ddcd051d00eea", "_cell_guid": "d7c054ab-3f4f-47a6-9493-1cbe3bd7cf2b"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "c313ae7c79e61749535172b5cfc56f2ddbce6b81", "_cell_guid": "1b37f790-6abc-409d-93d4-d9ba938fe909"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "5af8d1ba8cd4bb613aacbeb3e6300d321c8408c2", "_cell_guid": "569dd5a0-7010-48ec-afe7-c2ebc03d6a87"}, "source": ["\n", "\n"]}, {"cell_type": "markdown", "metadata": {"_uuid": "7bbc104b7bec5e482678ba50305cb073bb203142", "_cell_guid": "34ed7ed6-a042-4628-bd19-690378665015"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "1837319a3ea9e335459f4c927e1dfabd41c90ead", "_cell_guid": "a5684edd-8624-4e41-9d5f-06f38d870251"}, "source": []}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "nbconvert_exporter": "python", "version": "3.6.3", "pygments_lexer": "ipython3", "file_extension": ".py", "mimetype": "text/x-python", "name": "python"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1}