{"cells":[{"metadata":{"_uuid":"4b5506b42dbe90f115e636ff252c2674a5b1e6f8"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"93cb4679e7a15c2a7dfa9453385cdde511fcb6c5"},"cell_type":"markdown","source":"# COMPARING SGD, RMSprop, Adam FOR DIGIT RECOGNITION USING CNN:\n\n* Stochastic Gradient Descent \n* RMSprop\n* Adam\n\nLet's see how well these optimiser help in predicting digits."},{"metadata":{"_uuid":"7a764c2a676188f7a6deec00469f2ed0897fa7a9"},"cell_type":"markdown","source":"# Content\n1. Understanding dataset\n2. Checking null values\n3. Intuition about dimensions used for CNN model\n4. Normalization\n5. Looking at some image examples\n6. Imbalanced Class\n7. One-Hot-Encoding\n8. Using Keras for CNN\n9. Defining different optimizers\n10. Training CNN\n11. Visualisation and insights from them\n12. Conclusion\n"},{"metadata":{"_uuid":"0ac9e5721c017d489d3840c1dca8bad3ad820265"},"cell_type":"markdown","source":"## Import libraries\nLet's import some basic libraries first"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam, SGD\nfrom keras.callbacks import History \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2390914e177fb6bf01fa20b3320ab178899cb4cb"},"cell_type":"markdown","source":"**Let's read train and test values from the dataset. **"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"791cfcac09b9a03399d000ec159f54046cb23c82"},"cell_type":"markdown","source":"**OK! Now it's time to look how our dataset looks like. We'll randomly sample 10 values from both train and test**"},{"metadata":{"trusted":true,"_uuid":"6ffe7307a38ede4b4f158767ca4f13da229fec30"},"cell_type":"code","source":"train.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25ef9645a387c21ee92f8f09d12f44a90f978ce9"},"cell_type":"markdown","source":"# Understanding the dataset\n\n* Each data point in our train has pixel values ranging from pixel0 to pixel783. \n\n* <img src=\"https://vignette.wikia.nocookie.net/vampirediaries/images/c/ca/But-why-meme-generator-but-why-84103d.jpg/revision/latest?cb=20130811194815\" width=\"400px\"/>\n\n\n* We have 24 by 24 pixels for each data point or image in our dataset.\nSo 24 * 24 = 784. We'll see later in the notebook how to convert this into our desired shape so that it becomes an input for our convNet\n\n* And obviously label column is the true label for that particular data point. \n\nLet's look at our test dataset too!"},{"metadata":{"trusted":true,"_uuid":"eb136c9a0167af278f23e6181e3dff823f2f22a3"},"cell_type":"code","source":"test.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"85b4c08f72011fa8d592ed33f7048b98602a5b36"},"cell_type":"markdown","source":"So as expected we have only the grayscale pixel value for all dataset without label. Obviously, because that's what we want to predict!\n\nLet's see the shape or dimension of both train and test dataset"},{"metadata":{"trusted":true,"_uuid":"ef1022c4cdf7c98ef45ab923e662892c3b7adfa7"},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41dea51164ed06a007450e567aa68a3c51c4599b"},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ed47bc08bcf1e533fbff4f2bce15332c67f782a"},"cell_type":"markdown","source":"## Checking null values\n\n* We have 42000 data points in our train data set and 28000 in our test data set!\n\n* Next, let's look for any null values. \n* We will check null values in both train and test data set   \n<img src=\"https://pics.me.me/obviously-31892135.png\" width=\"400px\"/>\n \n"},{"metadata":{"trusted":true,"_uuid":"b0e79c84d688f963098499e01d2a9549957627a2"},"cell_type":"code","source":"train.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7dab668ded1d13db1f7f3080796d19d0a5be2762"},"cell_type":"code","source":"test.isnull().any().describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d91fa71d60db29da2dedeb8810fe99bdb8cf48bb"},"cell_type":"markdown","source":"## Woah! What a perfect day! No null value! ;)\n\n<img src=\"https://memegenerator.net/img/instances/48506203/wow.jpg\" width=\"200px\"/>\n"},{"metadata":{"_uuid":"26bc6bec094e111d3cb7ff12662c02efe3b91912"},"cell_type":"markdown","source":"## X_train and Y_train\n\nLet's separate our train dataset into X_train and Y_train\n\nWhat is X_train and Y_train??\n\n* X_train -> It will have all our training examples without the actual/true label of classification (num_examples,columns)\n* Y_train -> It will have all the actual/true label for corresponding X_train value (num_examples)\n\nThus, we have 42000 images in train as whole"},{"metadata":{"trusted":true,"_uuid":"88202bfe01544b9526e55f0ca91297be66467681"},"cell_type":"code","source":"Y_train = train[\"label\"]\nX_train = train.drop(labels=\"label\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c0f7ba68f753acc857babd9f68c86d4df0ec0be"},"cell_type":"markdown","source":"## Dimensions of X_train and Y_train\n\nLet's check the shape of our X_train and Y_train!\n\n### Any guess?\n<img src=\"http://4.bp.blogspot.com/-aE-06rRzYZE/UWByCA1jelI/AAAAAAAA228/wDrgQIdFZHw/s1600/Any%2Bguesses%2Bas%2Bto%2Bwho%2Btrumps%2BPalestinians%2Bin%2Blibeling%2BIsrael.jpg\" width=\"200px\"/>"},{"metadata":{"trusted":true,"_uuid":"7032fab6d1377169d48bb1baefe95554063bd4a9"},"cell_type":"code","source":"print (X_train.shape)\nprint (Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38a30168c61795531117dbfd8d72025fafb46355"},"cell_type":"markdown","source":"Cool!! Our X_train is now just 42000 by 784 i.e 42000 datapoint with 784 pixels(label column is dropped)\n\nAnd of course Y_train is just an array of the true label of 42000 images"},{"metadata":{"trusted":true,"_uuid":"2d47b112c9d0863e1ec1796b270a5df6d516fce7"},"cell_type":"markdown","source":"# Intuition for Reshaping dataset for our CNN model\n\nSaid so much about that, did we see how this grayscale image looks like?? \n\n<img src=\"https://image.spreadshirtmedia.com/image-server/v1/mp/designs/1014185688,width=178,height=178/who-cares.png\" width=\"200px\"/>\n\nWell, all of us care! \n\nBut first let's convert our X_train in the shape (m,pixel,pixel,channels)\n* m : number of datapoints\n* pixel : Our image is 24 by 24 pixel. pixel holds 24 in our case\n* channels : As this is grayscale image, we just have a single channel. channel = 3 for RGB images!\n\nOur X_train has 42000 data points and test has 28000. As all of you would have predicted that our final shape, which is to be fed in model is as follows:\n* X_train = (42000,28,28,1)\n* test = (28000,28,28,1)"},{"metadata":{"trusted":true,"_uuid":"8a9e3d57d0fc4163251a4dbaa0a7317fd4ba42e8"},"cell_type":"markdown","source":"# Normalization\n\nJust one last step before we reshape our data! We have to normalize our X_train and test\n\n<img src=\"https://vignette.wikia.nocookie.net/vampirediaries/images/c/ca/But-why-meme-generator-but-why-84103d.jpg/revision/latest?cb=20130811194815\" width=\"400px\"/>\n\n## Because\n\nAs we will use CNN, these models works better if the values are in [0,1], thus we divide our values with 255\n\nBut why to normalise test data??\n\nWhy not? We can't compare oranges with apples right? "},{"metadata":{"trusted":true,"_uuid":"496bebff117c782ca139451616b7779d8a39c2e5"},"cell_type":"code","source":"X_train = X_train/255.0\ntest = test/255.0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca27e0e841f12fd41e334b0dab9602f4b8ca9d62"},"cell_type":"markdown","source":"## Reshape\nAwesome! Let's reshape X_train and test now!"},{"metadata":{"trusted":true,"_uuid":"478eac26dbb3de8549f23775f2fea92811150f33"},"cell_type":"code","source":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9820ad4ddb86ef7c5f8ccadf52965ee8b48af554"},"cell_type":"code","source":"#Confirming the X_train shape we earlier predicted\nprint (X_train.shape)\n\n#confirming the test shape we earlier predicted\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c529f3757953a4f54ee2c768cdbb3d808658351"},"cell_type":"markdown","source":"# Looking at our digit images\n\nToo much of reshaping, normalizing and everything. Where is the image???????\n\nOK! OK! Now let's look at first six images as subplots! We will also set title as the true label which is stored in corresponding Y_train"},{"metadata":{"trusted":true,"_uuid":"1c3cc0fa1ee4eb7ff7054d67b8d485f508c38f3a"},"cell_type":"code","source":"nrows = 2\nncols = 3\ni = 0\nfig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\nfor row in range(nrows):\n    for col in range(ncols):\n        ax[row,col].imshow(X_train[i][:,:,0])\n        ax[row,col].set_title(\"True label :{}\".format(Y_train[i]))\n        i += 1\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9418f7a7e052fdec76059d74b8c45f49b135fae"},"cell_type":"markdown","source":"# Imbalanced Class\nGood going!! There are the digits. So what next?\n\nNow, before going further to train our model. We need to see one of the biggest factor in classification problem, i.e, imbalanced class. Let's plot a countplot and see whether we have imbalanced classes here"},{"metadata":{"trusted":true,"_uuid":"15b5b33a6a8222cdc985e27495b704d3fcfe4aba"},"cell_type":"code","source":"sns.countplot(Y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a8a683bbbd48b2b2ea9f66bc39b4ac5a782012f0"},"cell_type":"markdown","source":"<img src=\"https://memegenerator.net/img/instances/48506203/wow.jpg\" width=\"200px\"/>\n\nWhat a day!! It looks like we have pretty balanced class. \n\nNo need to apply any resampling techniques. We are free to go forward! Let's see counts for each digits anyways!"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5dadd5da0a2d517bf824626871344aa430542f04"},"cell_type":"code","source":"Y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"295d3daeb6213543a588a2745880781f80ac3478"},"cell_type":"markdown","source":"# one-hot-encoding\nApplying one hot encoding to Y_train (multi-class problem, thus we will need softmax transformtion)"},{"metadata":{"trusted":true,"_uuid":"0e36c49133f9c409b186ef987152324ba895f75e"},"cell_type":"code","source":"##### num_classes = 10 because we have 10 classes from 0 to 9\nY_train = to_categorical(Y_train, num_classes=10)\n#also let's look at our modified Y_train for the  1st 6 images displayed above. Remember: index starts from 0\nY_train[0:6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0c41f491b944249b18a330497b8d3108fa214f8"},"cell_type":"markdown","source":"# Splitting train and validation dataset\n\n<img src=\"https://medicaldialogues.in/wp-content/uploads/2017/12/phew.jpg\" width=\"200px\"/>\n\nPhew!! We are done with all pre processing and now we have data ready to be fed into our models!! Are you ready??\n\nAs we have balanced dataset, it's ok to split our dataset randomly. We split 90% data for training and 10% for validation. We'll judge our model on this validation data and secretly hide our test data! Let's initialize random seed to 2. Be free to change it if you need"},{"metadata":{"trusted":true,"_uuid":"1f8f0217263f566bff8bf77a5d296d1343a853d5"},"cell_type":"code","source":"random_seed = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b22cf9e148dfe08efd2f639089bbc4beadfe2256"},"cell_type":"code","source":"X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b927b6bd910940cea4294367e983471e4631b6e6"},"cell_type":"markdown","source":"# Convolutional Neural Networks\n\nLet's look at LeNet-5 architecture\n\n<img src=\"https://indoml.files.wordpress.com/2018/03/lenet-52.png?w=736\" width=\"600px\"/>\n\n\nTime to use all our deep learning knowledge and ask keras to help us implement it faster!! \n\nI would highly recommend to see the [keras](http://keras.io/) documentation, if you're new to it.\n\nP.S - This model is inspired by LeNet-5"},{"metadata":{"trusted":true,"_uuid":"50cad43ebf5e34a0b8ddd28ad49b2f08782afe06"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(filters = 16, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = \"relu\"))\n\nmodel.add(Dense(128, activation = \"relu\"))\n\nmodel.add(Dense(10, activation = \"softmax\"))\n\n#Note: I didn't use any regularisation yet! let's see how well our model acts without regularisation like dropout! We can always iterate later :)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab7b95a31d1429b51352b6441c85cbfad2ef6ef8"},"cell_type":"code","source":"#For faster convergence, i've used 10 epochs. 20 epochs seems to work a bit better! Try changing it to 20 or even 30 for better accuracy\nepochs = 10\nbatch_size = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"282e94f43cc4b9af5e96a44273eda862eeb4b2d5"},"cell_type":"markdown","source":"# Defining optimizers\nHere comes the optimisers: We'll define 3 optimiser\n\n* optimizerSDG - Stochastic gradient Descent optimiser\n* optimizerRMSprop - RMSprop optimiser\n* optimizerAdam - ADaptive Moment Estimation(Adam) optimiser\n\nClick [here](http://ruder.io/optimizing-gradient-descent/) to know more about these optimisers"},{"metadata":{"trusted":true,"_uuid":"7d7e656c391c96ad5cd114a7737be7c49a313d7e"},"cell_type":"code","source":"optimizerSGD = SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\noptimizerAdam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, amsgrad=False)\noptimizerRMSprop = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"addd0ccd199bd14dc3b49b615230e4e923df6e51"},"cell_type":"code","source":"history = History() #to keep track of accuracy parameters, we will see it's use soon","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4100992974a1d48daf691551898247de98b35923"},"cell_type":"markdown","source":"# Training Model\nLet's compile and train our models separately for different optimizers. Our metrics will be stored in history variable, which could be used later for comparation"},{"metadata":{"trusted":true,"_uuid":"7ec27f48a845a2cd02f485f0e1ad70dd10da1395","scrolled":true},"cell_type":"code","source":"#training using SGD\nmodel.compile(optimizer = optimizerSGD , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistorySGD = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n         validation_data = (X_val, Y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f1eeea3ed68cdfcaf1dfccc5c4969182b164514"},"cell_type":"code","source":"resultsSGD = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6a1ca7d50f4cb746a23c7b2000097c5d48abfec0"},"cell_type":"code","source":"#training using RMSprop\nmodel.compile(optimizer = optimizerRMSprop , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistoryRMSprop = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n         validation_data = (X_val, Y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5711ebc5196f90816784c18c1b2b80893fde3a9"},"cell_type":"code","source":"resultsRMSProp = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"254a3b5bbfc176ea6b9629ed71e96b31499a5a12"},"cell_type":"code","source":"#training using Adam\nmodel.compile(optimizer = optimizerAdam , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\nhistoryAdam = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n         validation_data = (X_val, Y_val), verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"69973bb5853290929d604da58208b1b0d222abbb"},"cell_type":"code","source":"resultsAdam = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f8d2d25a43533d0f7c407aa393d5367190fe3ae"},"cell_type":"markdown","source":"# Storing accuracy metrics\nTime to compare training accuracy and validation accuracy for each model with different optimiser. \n\nBut where are the accuracy values stores??\n\nWe have history of every epoch in all 3 models in history<optimizer_name>. Let's retrieve those values and compare!\n\nAnd also, i'll explain why i've used results<optimizer_name> after training every model"},{"metadata":{"trusted":true,"_uuid":"595c09811c211358aabc368daf199cc54dad0621"},"cell_type":"code","source":"SGD_acc = historySGD.history['acc']\nSGD_val_acc = historySGD.history['val_acc']\nRMSprop_acc = historyRMSprop.history['acc']\nRMSprop_val_acc = historyRMSprop.history['val_acc']\nAdam_acc = historyAdam.history['acc']\nAdam_val_acc = historyAdam.history['val_acc']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76bc3a867df1af09f84f293c61c919709bd892a2"},"cell_type":"markdown","source":"# Visualization"},{"metadata":{"trusted":true,"_uuid":"852d2db043a0962b96c51f90612501d7f8f5659a"},"cell_type":"code","source":"plt.plot(SGD_acc)\nplt.plot(RMSprop_acc)\nplt.plot(Adam_acc)\nplt.legend(['SGD', 'RMSprop', 'Adam'], loc='lower right')\nplt.title('Training accuracy: SGD vs RMSprop vs Adam')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60b53defcdf2ac38e8eba1229bc0707bcb38a2f5"},"cell_type":"markdown","source":"# INSIGHTS FROM TRAINING ACURACY\n\n### Things to note:\n\n*  Clearly we can observe that Adam is performing best among three.\n\n*  We also observe that RMSprop started will a lower accuracy for the first two epochs. This can be improved using bias correction,  but it started learning fast and competes closely with Adam optimizer on higher epochs. Thus we can omit bias correction(it is recommended though).\n\n* Stochastic Gradient Descent however keeps learning and becomes better that it's previous value. However it's far away to compete with Adam or RMSprop.\n\n"},{"metadata":{"trusted":true,"_uuid":"94aa6ad4d8a01492af9abec36fc9c5a8d58e7b28"},"cell_type":"code","source":"plt.plot(SGD_val_acc)\nplt.plot(RMSprop_val_acc)\nplt.plot(Adam_val_acc)\nplt.legend(['SGD', 'RMSprop', 'Adam'], loc='lower right')\nplt.title('Validation accuracy: SGD vs RMSprop vs Adam')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5cad849c9bfdaf0f4d50aef208a7214b5d733fa"},"cell_type":"markdown","source":"# INSIGHTS FROM VALIDATION ACURACY\n\n### Validation accuracy is the most important part because it is the measure of how well our model works on the unseen datapoints.\nI am always exited to analyse validation accuracy or validation error(1 - validation accuracy). This factor gives us insight about how well our model can be improved further!!\n\n### Things to note:\n\n* Stochastic Gradient Descent works good but of course is far away to be compared with Adam or RMSprop.\n\n* It's interesting to see the performance of Adam vs RMSprop, RMSprop seems to perform better after around 6th epoch. However, Adam wins at the end of 10th epoch.\n\n* As RMSprop seems to perform better for a considerable period of time, it's highly suggested to increase the number of epochs and analyse the performance. You can go up and change epochs to 20 or 30 and feel free to experiment further\n\n\n\n\n"},{"metadata":{"_uuid":"1af470643e41d823ae51618822aacacc979581aa"},"cell_type":"markdown","source":"## Overfitting\nIt's very crucial to observe whether we are overfitting our model. One intuition of overfitting can be thought as if your model works pretty well in training data but not so good in validation data, it can be an example of overfitting.\n\nHow to **overcome** overfitting?\n* Try to add **regularisation** like add dropout with some keep_prob\n* Observe the factors which maybe a reason for error (maybe sometimes by manually **observing** the error data points)\n\n**Note**: Different overfitting techniques could be used depending upon the problem, feel free to google and know about them"},{"metadata":{"_uuid":"f423b0f075f75aa9277a60b93d5e01eb4f61c076"},"cell_type":"markdown","source":"### Let's just observe whether the overfitting reason(training performance is much better than validation) holds in our case"},{"metadata":{"trusted":true,"_uuid":"c98469d03c2c5ccd27f5bc09b2e5e21230d3b870"},"cell_type":"code","source":"fig, ax = plt.subplots(1,3,sharex=True,sharey=True,figsize=(15, 5))\nax[0].plot(SGD_acc)\nax[0].plot(SGD_val_acc)\nax[0].legend(['SGD_train','SGD_val'], loc='lower right')\nax[0].set_title(\"SGD\")\n\nax[1].plot(RMSprop_acc)\nax[1].plot(RMSprop_val_acc)\nax[1].legend(['RMSprop_train','RMSprop_val'], loc='lower right')\nax[1].set_title(\"RMSprop\")\n\nax[2].plot(Adam_acc)\nax[2].plot(Adam_val_acc)\nax[2].legend(['Adam_train','Adam_val'], loc='lower right')\nax[2].set_title(\"Adam\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a25117118b4b9f689d56af7edb2f6aaa8dc2309e"},"cell_type":"markdown","source":"# INSIGHTS\n\n* It's pretty clear performance on training data is better than validation data. This seems normal, but the difference bridge could be decreased using either overfitting techniques or adding more data in our model\n\n# CONCLUSION\n* Looking at out hyperparameters value, we come to conclusion that Adam seems better option as of now. But feel free to increase the number of epoch, and maybe you can see RMSprop working better\n* Tuning hyperparameters like number of epochs, batch_size, etc., may result in finding better models.\n* For this kerel, let's submit the results from Adam optimizer model. "},{"metadata":{"trusted":true,"_uuid":"df346679f64f5543e76a39c40c2fdf70c0d615db"},"cell_type":"code","source":"results = np.argmax(resultsAdam,axis=1)\nresults = pd.Series(results,name=\"Label\")\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"762f105f52240de97aba764b346aa0cda0522de0"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5d4735f753674855ee50af72e4548b74f060107"},"cell_type":"markdown","source":"I hope this kernel **helped** in gaining some **insights** about **optimizers**. Feel free to fork it and experiment with it further. Also vote if you like the kernel. \n\nThank You!!\n\n<img src=\"https://albertonrecord.co.za/wp-content/uploads/sites/35/2018/04/thank-you-185078737_76252.jpg\" width=\"300px\"/>\n\n"},{"metadata":{"trusted":true,"_uuid":"6d2639e828b2bc61b24dd431b9fd19eacfc36f15"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}