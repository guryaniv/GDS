{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c50a8200-9ee2-b6ad-5e1b-ff66132eda42"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\t\t\t\t # working with, mainly resizing, images\n",
        "import numpy as np\t\t # dealing with arrays\n",
        "import os\t\t\t\t  # dealing with directories\n",
        "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
        "from tqdm import tqdm\t  # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "import tensorflow as tf\n",
        "\n",
        "trainDir = '../input/train/'\n",
        "testDir = '../input/test'\n",
        "#testDir = '../input/train/'\n",
        "LR = 1e-3\n",
        "\n",
        "imageSize = 50\n",
        "#MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match\n",
        "\n",
        "def label_img(img):\n",
        "\tword_label = img.split('.')[-3]\n",
        "\t# conversion to one-hot array [cat,dog]\n",
        "\t#\t\t\t\t\t\t\t[much cat, no dog]\n",
        "\tif word_label == 'cat': return [1,0]\n",
        "\t#\t\t\t\t\t\t\t [no cat, very doggo]\n",
        "\telif word_label == 'dog': return [0,1]\n",
        "\t\n",
        "\t\n",
        "def create_train_data():\n",
        "\ttraining_data = []\n",
        "\tfor img in os.listdir(trainDir):\n",
        "\t\tlabel = label_img(img)\n",
        "\t\tpath = os.path.join(trainDir,img)\n",
        "\t\timg = cv2.imread(path)\n",
        "\t\timg = cv2.resize(img, (imageSize,imageSize))\n",
        "\t\ttraining_data.append([np.array(img),np.array(label), ])\n",
        "\tshuffle(training_data)\n",
        "\t#np.save('train_data.npy', training_data)\n",
        "\treturn training_data\n",
        "\t\n",
        "\t\n",
        "def process_test_data():\n",
        "\ttesting_data = []\n",
        "\tfor img in os.listdir(testDir):\n",
        "\t\tpath = os.path.join(testDir,img)\n",
        "\t\timg_num = img.split('.')[0]\n",
        "\t\timg = cv2.imread(path)\n",
        "\t\timg = cv2.resize(img, (imageSize,imageSize))\n",
        "\t\ttesting_data.append([np.array(img), img_num])\n",
        "\t\t\n",
        "\tshuffle(testing_data)\n",
        "\t#np.save('test_data.npy', testing_data)\n",
        "\treturn testing_data\n",
        "\t\n",
        "train_data = create_train_data()\n",
        "\n",
        "testDataCount = int(len(train_data) / 5)\n",
        "\n",
        "testData = train_data[:testDataCount]\n",
        "train_data = train_data[testDataCount:]\n",
        "\n",
        "convnet = input_data(shape=[None, imageSize, imageSize, 3], name='input')\n",
        "\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
        "convnet = max_pool_2d(convnet, 5)\n",
        "\n",
        "convnet = fully_connected(convnet, 1024, activation='relu')\n",
        "convnet = dropout(convnet, 0.8)\n",
        "\n",
        "convnet = fully_connected(convnet, 2, activation='softmax')\n",
        "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
        "\n",
        "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
        "\n",
        "\t\n",
        "X = np.array([i[0] for i in train_data]).reshape(-1,imageSize,imageSize,3)\n",
        "Y = [i[1] for i in train_data]\n",
        "\n",
        "test_x = np.array([i[0] for i in testData]).reshape(-1,imageSize,imageSize,3)\n",
        "test_y = [i[1] for i in testData]\n",
        "\n",
        "model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n",
        "\tsnapshot_step=5000, show_metric=True)\n",
        "testData = process_test_data()\n",
        "\n",
        "for data in testData:\n",
        "\timg_num = data[1]\n",
        "\timg_data = data[0]\n",
        "\torig = img_data\n",
        "\tdata = img_data.reshape(imageSize,imageSize,3)\n",
        "\tmodel_out = model.predict([data])[0]\n",
        "\tprint('{},{}\\n'.format(img_num,model_out[1]))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}