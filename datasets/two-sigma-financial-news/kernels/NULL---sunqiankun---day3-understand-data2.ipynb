{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\nimport lightgbm as lgb\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom itertools import chain\n\n%matplotlib inline\n\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\n\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df = market_train_df.tail(100_000)\nnews_train_df = news_train_df.tail(300_000)\n\nnews_train_df['time'] = (news_train_df['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n#news_train_df['time']\nmarket_train_df['time'] = market_train_df['time'].dt.floor('1D')\n\nnews_train_df['assetCodes'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\") \nassetCodes_expanded = list(chain(*news_train_df['assetCodes']))\n\nassetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes'].apply(len) )\nassert len(assetCodes_index) == len(assetCodes_expanded)\n\ndf_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"news_cols_agg = {\n    'urgency': ['min', 'count'],\n    'takeSequence': ['max'],\n    'bodySize': ['min', 'max', 'mean', 'std'],\n    'wordCount': ['min', 'max', 'mean', 'std'],\n    'sentenceCount': ['min', 'max', 'mean', 'std'],\n    'companyCount': ['min', 'max', 'mean', 'std'],\n    'marketCommentary': ['min', 'max', 'mean', 'std'],\n    'relevance': ['min', 'max', 'mean', 'std'],\n    'sentimentNegative': ['min', 'max', 'mean', 'std'],\n    'sentimentNeutral': ['min', 'max', 'mean', 'std'],\n    'sentimentPositive': ['min', 'max', 'mean', 'std'],\n    'sentimentWordCount': ['min', 'max', 'mean', 'std'],\n    'noveltyCount12H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount24H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount3D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount5D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount7D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts12H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts24H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts3D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts5D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts7D': ['min', 'max', 'mean', 'std']\n}\nnews_cols = ['time', 'assetCodes'] + sorted(news_cols_agg.keys())\nnews_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0', \n                                  right_index=True, suffixes=(['','_old']))\nnews_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg)\n\ndel news_train_df, df_assetCodes\ndel news_train_df_expanded\n\nnews_train_df_aggregated = news_train_df_aggregated.apply(np.float32)\nnews_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n\nmarket_train_df = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad85097c733819eb225345683faa27198f2de8ba"},"cell_type":"code","source":"x = market_train_df\ndef label_encode(series, min_count):\n    vc = series.value_counts()\n    le = {c:i for i, c in enumerate(vc.index[vc >= min_count])}\n    return le\n\nle_assetCode = label_encode(x['assetCode'], min_count=10)\nle_assetName = label_encode(x['assetName'], min_count=5)\nx['assetCode'] = x['assetCode'].map(le_assetCode).fillna(-1).astype(int)\nx['assetName'] = x['assetName'].map(le_assetName).fillna(-1).astype(int)\n\nx.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e67cd4e9b56caa261818c5261c909b4e14299666"},"cell_type":"code","source":"x.drop(columns=['returnsOpenNextMktres10'], inplace=True)\nx.drop(columns=['universe'], inplace=True)\nx['dayofweek'], x['month'] = x.time.dt.dayofweek, x.time.dt.month\nx.drop(columns='time', inplace=True)\n\nfor bogus_col in ['marketCommentary_min', 'marketCommentary_max']:\n    x[bogus_col] = x[bogus_col].astype(float)\nle = (le_assetCode, le_assetName)\ny = market_train_df['returnsOpenNextMktres10'].clip(-1, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e3d2f2cda692e6a8101c3c46758307ffae680a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}