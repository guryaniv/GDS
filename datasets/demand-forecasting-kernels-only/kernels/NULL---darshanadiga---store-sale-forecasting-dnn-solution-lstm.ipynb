{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom datetime import datetime, timedelta\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nimport time\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# First let us load the datasets into different Dataframes\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\nsample_submission_df = pd.read_csv('../input/sample_submission.csv')\n\n# Dimensions\nprint('Train shape:', train_df.shape)\nprint('Test shape:', test_df.shape)\nprint('Sample submission shape:', sample_submission_df.shape)\n# Set of features we have are: date, store, and item\ndisplay(train_df.sample(10))\ndisplay(test_df.sample(10))\ndisplay(sample_submission_df.sample(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e2db7d02cd15214db502c34becb884824fe5760d","collapsed":true},"cell_type":"code","source":"# Process the training data\nvec_train_df = train_df.copy(deep=True)\nvec_train_df.date = pd.to_datetime(vec_train_df.date)\nvec_train_df.set_index('date', inplace=True)\ndisplay(vec_train_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"793ca86e4e5cb7f841518bb34416beb07d93210e","collapsed":true},"cell_type":"code","source":"# Process the test data\nvec_test_df = test_df.copy(deep=True)\nvec_test_df.date = pd.to_datetime(vec_test_df.date)\nvec_test_df.set_index('date', inplace=True)\ndisplay(vec_test_df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8bac6def10ac0b74b6fd37e733a355137938942c","scrolled":true,"collapsed":true},"cell_type":"code","source":"def vectorized_train_and_test(store, item):\n    \"\"\"\n        Returns the final train and test dataframes for the given store and item, ready for training and predicting.\n    \"\"\"\n    fltr_train_df = vec_train_df.loc[(vec_train_df.store==store) & (vec_train_df.item==item)]\n    fltr_test_df = vec_test_df.loc[(vec_test_df.store==store) & (vec_test_df.item==item)]\n    for d in [fltr_train_df, fltr_test_df]:\n        d.drop('store', inplace=True, axis=1)\n        d.drop('item', inplace=True, axis=1)\n    return fltr_train_df,fltr_test_df\ntr,_ = vectorized_train_and_test(1,1)\ndisplay(tr.head(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40a09007de38682b17a2d012dd12f82289ffb03c","collapsed":true},"cell_type":"code","source":"def generate_train_samples(target_df, batch_size = 10, input_seq_len = 15, output_seq_len = 20):\n    x_dates = target_df.index\n    total_start_points = len(x_dates) - input_seq_len - output_seq_len\n    start_x_idx = np.random.choice(range(total_start_points), batch_size)\n     \n    input_seq_x = [list(range(i,(i+input_seq_len))) for i in start_x_idx]\n    output_seq_x = [list(range((i+input_seq_len),(i+input_seq_len+output_seq_len))) for i in start_x_idx]\n    #print('X Dates')\n    #print(start_x_idx)\n    #print(input_seq_x)\n    #print(output_seq_x)\n    \n    input_seq_y = [target_df.iloc[i].values for i in input_seq_x]\n    output_seq_y = [target_df.iloc[i].values for i in output_seq_x]\n    \n    ## return shape: (batch_size, time_steps, feature_dims), input_seq_x\n    return np.array(input_seq_y), np.array(output_seq_y), input_seq_x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f8cba1b3873036872a66353d6aa853565f6b028a","collapsed":true},"cell_type":"code","source":"tr_df,_ = vectorized_train_and_test(1,1)\ndates = ['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08', '2013-01-09']\nin_seq_y,out_seq_y,_ = generate_train_samples(tr_df, batch_size = 2, input_seq_len = 2, output_seq_len = 3)\nprint('Y Sales')\nprint('In:', np.shape(in_seq_y), ':', in_seq_y)\nprint('Out:', np.shape(out_seq_y), ':', out_seq_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d6ff3fff78f83f8ea6add8b6464c62d21338577d"},"cell_type":"code","source":"### Below are related RNN","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a495ac3ed9d6d0aaf0b6b4b143ebde01f3f6ed5e","collapsed":true},"cell_type":"code","source":"## RNN specific imports\nfrom tensorflow.contrib import rnn\nfrom tensorflow.python.ops import variable_scope\nfrom tensorflow.python.framework import dtypes\nimport copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"023afe1bc2a1f6d18ac56f01b6ab46fff86d797b","collapsed":true},"cell_type":"code","source":"## Parameters\nlearning_rate = 0.01\nlambda_l2_reg = 0.003 \n \n## Network Parameters\n# length of input signals\ninput_seq_len = 60\n# length of output signals\noutput_seq_len = 20\n# size of LSTM Cell\nhidden_dim = 128\n# num of input signals\ninput_dim = 1\n# num of output signals\noutput_dim = 1\n# num of stacked lstm layers\nnum_stacked_layers = 10\n# gradient clipping - to avoid gradient exploding\nGRADIENT_CLIPPING = 2.5\n \ndef build_graph(feed_previous = False):\n    tf.reset_default_graph()\n    global_step = tf.Variable(\n                  initial_value=0,\n                  name=\"global_step\",\n                  trainable=False,\n                  collections=[tf.GraphKeys.GLOBAL_STEP, tf.GraphKeys.GLOBAL_VARIABLES])\n    # Weights and biases\n    weights = {\n        'out': tf.get_variable('Weights_out',\n                               shape = [hidden_dim, output_dim],\n                               dtype = tf.float32,\n                               initializer = tf.truncated_normal_initializer()),\n    }\n    biases = {\n        'out': tf.get_variable('Biases_out',\n                               shape = [output_dim],\n                               dtype = tf.float32,\n                               initializer = tf.constant_initializer(0.)),\n    }\n    \n    # Placeholders\n    with tf.variable_scope('Seq2seq'):\n        # Encoder: inputs\n        enc_inp = [\n            tf.placeholder(tf.float32, shape=(None, input_dim), name=\"inp_{}\".format(t))\n               for t in range(input_seq_len)\n        ]\n        \n        # Decoder: target outputs\n        target_seq = [\n            tf.placeholder(tf.float32, shape=(None, output_dim), name=\"y\".format(t))\n              for t in range(output_seq_len)\n        ]\n        \n        # Give a \"GO\" token to the decoder.\n        # If dec_inp are fed into decoder as inputs, this is 'guided' training; otherwise only the\n        # first element will be fed as decoder input which is then 'un-guided'\n        dec_inp = [ tf.zeros_like(target_seq[0], dtype=tf.float32, name=\"GO\") ] + target_seq[:-1]\n        \n        # The layered network\n        with tf.variable_scope('LSTMCell'):\n            cells = []\n            for i in range(num_stacked_layers):\n                with tf.variable_scope('RNN_{}'.format(i)):\n                    cells.append(tf.contrib.rnn.LSTMCell(hidden_dim))\n            cell = tf.contrib.rnn.MultiRNNCell(cells)\n            \n            ##----------------------Helper methods----------------\n            def _rnn_decoder(decoder_inputs,\n                         initial_state,\n                         cell,\n                         loop_function=None,\n                         scope=None):\n                \"\"\"RNN decoder for the sequence-to-sequence model.\n                Args:\n                decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n                initial_state: 2D Tensor with shape [batch_size x cell.state_size].\n                cell: rnn_cell.RNNCell defining the cell function and size.\n                loop_function: If not None, this function will be applied to the i-th output\n                  in order to generate the i+1-st input, and decoder_inputs will be ignored,\n                  except for the first element (\"GO\" symbol). This can be used for decoding,\n                  but also for training to emulate http://arxiv.org/abs/1506.03099.\n                  Signature -- loop_function(prev, i) = next\n                    * prev is a 2D Tensor of shape [batch_size x output_size],\n                    * i is an integer, the step number (when advanced control is needed),\n                    * next is a 2D Tensor of shape [batch_size x input_size].\n                scope: VariableScope for the created subgraph; defaults to \"rnn_decoder\".\n              Returns:\n                A tuple of the form (outputs, state), where:\n                  outputs: A list of the same length as decoder_inputs of 2D Tensors with\n                    shape [batch_size x output_size] containing generated outputs.\n                  state: The state of each cell at the final time-step.\n                    It is a 2D Tensor of shape [batch_size x cell.state_size].\n                    (Note that in some cases, like basic RNN cell or GRU cell, outputs and\n                    states can be the same. They are different for LSTM cells though.) \"\"\"\n                with variable_scope.variable_scope(scope or \"rnn_decoder\"):\n                    state = initial_state\n                    outputs = []\n                    prev = None\n                    for i, inp in enumerate(decoder_inputs):\n                        if loop_function is not None and prev is not None:\n                            with variable_scope.variable_scope(\"loop_function\", reuse=True):\n                                inp = loop_function(prev, i)\n                        if i > 0:\n                            variable_scope.get_variable_scope().reuse_variables()\n                        output, state = cell(inp, state)\n                        outputs.append(output)\n                        if loop_function is not None:\n                            prev = output\n                return outputs, state\n\n            #--------------------------------------\n            def _basic_rnn_seq2seq(encoder_inputs,\n                                   decoder_inputs,\n                                   cell,\n                                   feed_previous,\n                                   dtype=dtypes.float32,\n                                   scope=None):\n                \"\"\"Basic RNN sequence-to-sequence model.\n                This model first runs an RNN to encode encoder_inputs into a state vector,\n                then runs decoder, initialized with the last encoder state, on decoder_inputs.\n                Encoder and decoder use the same RNN cell type, but don't share parameters.\n                Args:\n                  encoder_inputs: A list of 2D Tensors [batch_size x input_size].\n                  decoder_inputs: A list of 2D Tensors [batch_size x input_size].\n                  feed_previous: Boolean; if True, only the first of decoder_inputs will be\n                      used (the \"GO\" symbol), all other inputs will be generated by the previous\n                      decoder output using _loop_function below. If False, decoder_inputs are used\n                      as given (the standard decoder case).\n                  dtype: The dtype of the initial state of the RNN cell (default: tf.float32).\n                  scope: VariableScope for the created subgraph; default: \"basic_rnn_seq2seq\".\n                Returns:\n                  A tuple of the form (outputs, state), where:\n                    outputs: A list of the same length as decoder_inputs of 2D Tensors with\n                      shape [batch_size x output_size] containing the generated outputs.\n                    state: The state of each decoder cell in the final time-step.\n                      It is a 2D Tensor of shape [batch_size x cell.state_size]. \"\"\"\n\n                with variable_scope.variable_scope(scope or \"basic_rnn_seq2seq\"):\n                    enc_cell = copy.deepcopy(cell)\n                    _, enc_state = rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)\n                if feed_previous:\n                    return _rnn_decoder(decoder_inputs, enc_state, cell, _loop_function)\n                else:\n                    return _rnn_decoder(decoder_inputs, enc_state, cell)\n\n            #--------------------------------------\n            def _loop_function(prev, _):\n                \"\"\"Naive implementation of loop function for _rnn_decoder. Transform prev from\n                dimension [batch_size x hidden_dim] to [batch_size x output_dim], which will be\n                used as decoder input of next time step \"\"\"\n                return tf.matmul(prev, weights['out']) + biases['out']\n            ##----------------------Helper methods----------------\n    \n        # The seq-seq graph    \n        dec_outputs, dec_memory = _basic_rnn_seq2seq(\n            enc_inp,\n            dec_inp,\n            cell,\n            feed_previous = feed_previous\n        )\n        # The actual output\n        reshaped_outputs = [tf.matmul(i, weights['out']) + biases['out'] for i in dec_outputs]\n\n    # Training loss and optimizer\n    with tf.variable_scope('Loss'):\n        # L2 loss\n        output_loss = 0\n        for _y, _Y in zip(reshaped_outputs, target_seq):\n            output_loss += tf.reduce_mean(tf.pow(_y - _Y, 2))\n\n        # L2 regularization for weights and biases\n        reg_loss = 0\n        for tf_var in tf.trainable_variables():\n            if 'Biases_' in tf_var.name or 'Weights_' in tf_var.name:\n                reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))\n\n        loss = output_loss + lambda_l2_reg * reg_loss\n\n    with tf.variable_scope('Optimizer'):\n        optimizer = tf.contrib.layers.optimize_loss(\n            loss=loss,\n            learning_rate=learning_rate,\n            global_step=global_step,\n            optimizer='Adam',\n            clip_gradients=GRADIENT_CLIPPING)\n\n    # The model saver and restorer\n    saver = tf.train.Saver\n\n    # Return the build graph and required tensors\n    return dict(\n        enc_inp = enc_inp,\n        target_seq = target_seq,\n        train_op = optimizer,\n        loss=loss,\n        saver = saver,\n        reshaped_outputs = reshaped_outputs,\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1cf8a9d7fd11370201c2f1b7c03e276b991c8551","collapsed":true},"cell_type":"code","source":"## Train the model\ntotal_iteractions = 1000\nbatch_size = 172\nKEEP_RATE = 0.5\ntrain_losses = []\nval_losses = []\n\nv_train_df,_ = vectorized_train_and_test(1,1)\n# For validation phase below\nhold_out_len = batch_size\nv_train_hold_out_df = v_train_df.tail(hold_out_len)\nv_train_df = v_train_df.head(v_train_df.shape[0] - hold_out_len)\n\nrnn_model = build_graph(feed_previous=False)\n \nsaver = tf.train.Saver()\n \ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print('Model Details')\n    print('Total iterations:', total_iteractions)\n    print('Training data shape:', v_train_df.shape)\n    print('Batch size:', batch_size)\n    print('Input sequence len:', input_seq_len)\n    print('Output sequence len:', output_seq_len)\n    print('--------------------')\n    for i in range(total_iteractions):\n        batch_input, batch_output,_ = generate_train_samples(target_df=v_train_df, batch_size=batch_size, input_seq_len=input_seq_len, output_seq_len=output_seq_len)\n        \n        feed_dict = {rnn_model['enc_inp'][t]: batch_input[:,t].reshape(-1,input_dim) for t in range(input_seq_len)}\n        feed_dict.update({rnn_model['target_seq'][t]: batch_output[:,t].reshape(-1,output_dim) for t in range(output_seq_len)})\n        _, loss_t = sess.run([rnn_model['train_op'], rnn_model['loss']], feed_dict)\n        print('Iteration:', i, ' Loss:', loss_t)\n\n    temp_saver = rnn_model['saver']()\n    save_path = temp_saver.save(sess, os.path.join('seq2seq', 'univariate_ts_model0'))\n \nprint(\"Checkpoint saved at: \", save_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"16cd17ac9e781db40eb8082a38be8187ffabf7c8","collapsed":true},"cell_type":"code","source":"# Inference/Forecasting\ndisplay(v_train_hold_out_df)\ntest_seq_input,test_seq_output,input_seq_x = generate_train_samples(target_df=v_train_hold_out_df, batch_size=1)\ntest_seq_input = test_seq_input[0]\nprint('Test dataframe:')\ndisplay(v_train_hold_out_df.iloc[input_seq_x[0]])\nprint('Expected data:')\nlast_pos = input_seq_x[0][input_seq_len-1]\nprint('Last Value:' + str(last_pos))\ndisplay(v_train_hold_out_df.iloc[range(last_pos, last_pos + output_seq_len)])\nprint('test_seq_output', test_seq_output[0])\nrnn_model = build_graph(feed_previous=True)\n \ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    saver = rnn_model['saver']().restore(sess, os.path.join('seq2seq', 'univariate_ts_model0'))\n    \n    feed_dict = {rnn_model['enc_inp'][t]: test_seq_input[t].reshape(1,1) for t in range(input_seq_len)}\n    feed_dict.update({rnn_model['target_seq'][t]: np.zeros([1, output_dim]) for t in range(output_seq_len)})\n    final_preds = sess.run(rnn_model['reshaped_outputs'], feed_dict)\n    \n    final_preds = np.concatenate(final_preds, axis = 1)\n    print('Final predictions:')\n    print(final_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cb96c21896dd2c0a5ebf770fc79dca0570c8e673"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}