{"cells":[{"metadata":{"_uuid":"d9b34f7dd28316baf3083f4cc89fe2418eef1e6f"},"cell_type":"markdown","source":" <div style=\"text-align:center\"><span style=\"font-size:2em\"> It Takes a Village - CareerVillage Initial Analysis</div></style>\n <div style=\"text-align:center\">By Maya Shaked</div>"},{"metadata":{"_uuid":"ea9f8b8ee751ff6bd508b5a3e120579ecf2383f8"},"cell_type":"markdown","source":"## Our task at hand is to develop a method to recommend relevant questions to the professionals who are most likely to answer them."},{"metadata":{"_uuid":"c4633f149d703d83d5df0b49c474d5416cbfcce1","_execution_state":"idle","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport sys\nimport math\n\n# loading data\nanswers = pd.read_csv(\"../input/answers.csv\")\ncomments = pd.read_csv(\"../input/comments.csv\")\nemails = pd.read_csv(\"../input/emails.csv\")\ngroup_memberships = pd.read_csv(\"../input/group_memberships.csv\")\ngroups = pd.read_csv(\"../input/groups.csv\")\nmatches = pd.read_csv(\"../input/matches.csv\")\nprofessionals = pd.read_csv(\"../input/professionals.csv\")\nquestions = pd.read_csv(\"../input/questions.csv\")\nschool_memberships = pd.read_csv(\"../input/school_memberships.csv\")\nstudents = pd.read_csv(\"../input/students.csv\")\ntag_questions = pd.read_csv(\"../input/tag_questions.csv\")\ntag_users = pd.read_csv(\"../input/tag_users.csv\")\ntags = pd.read_csv(\"../input/tags.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98fbbd88e8b50d609e3f37c5086afb3094bfe0a2"},"cell_type":"markdown","source":"# ** So, let's first explore some relevant data!**"},{"metadata":{"trusted":true,"_uuid":"b4a76260741518c3541a64dc5597cf7b9c10a906","_kg_hide-output":false},"cell_type":"code","source":"#  Let's see what's going on in the `questions` dataframe\nquestions.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2519fa55ef4c7019f2290a2aefca20db53179147","_kg_hide-output":false},"cell_type":"code","source":"# our data description lets us know that \"Answers are what this is all about! Answers get posted in response to questions. Answers can only be posted by users who are registered as Professionals.\" \n# So, let's check out our `answers` data followed by our `professionals` data\nanswers.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3cd46531cfdaea121a95ddde4c48d5a4a4257fa"},"cell_type":"code","source":"professionals.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f747d5f649e0e6fc90bff09c29f7ad7e45d9c930"},"cell_type":"code","source":"# We eventually will need to know what professional answered what question. Lets combine the `professionals` data and our answers by JOINing with `answers` \nanswers_with_professions = pd.merge(answers, professionals, left_on = \"answers_author_id\", right_on = \"professionals_id\")\n\n# Now, we can connect our questions/tags data with answers/professions by JOINing on the question_id\nq_and_a = pd.merge(questions, answers_with_professions, left_on = \"questions_id\", right_on = \"answers_question_id\")\n\nq_and_a.head(1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6333ee8e1d19e36cc822ccc7fd1c51155d91806"},"cell_type":"markdown","source":"# Let's generate a Markov model for each professional\n\n### Given a question string of text from an unidentified professional, we will use the Markov model to assess the likelihood that it was uttered by the particular professional to which that particular Markov model corresponds. If we have built models for different professionals (based on our training data), then we will have likelihood values for each, and will choose the professional with the highest likelihood as the best responder to the question."},{"metadata":{"_uuid":"369101e476033d1997dfe618becb2e7b1b492b3a"},"cell_type":"markdown","source":"# First, we must build a Hash Table (with linear probing) class to hold our model's k-grams"},{"metadata":{"trusted":true,"_uuid":"5932670ce90b21276a9cc710f48b555c665799e7"},"cell_type":"code","source":"TOO_FULL = 0.5\nGROWTH_RATIO = 2\n\n\nclass Hash_Table:\n\n    def __init__(self,cells,defval):\n        '''\n        Construct a new hash table with a fixed number of cells equal to the\n        parameter \"cells\", and which yields the value defval upon a lookup to a\n        key that has not previously been inserted\n        '''\n        \n        self.defval = defval\n        self.size = cells\n        self.slots = [[None, self.defval] for x in range(self.size)]\n        self.occupied = 0\n\n    def hash(self, string):\n\n        return hash(string)\n\n\n    def lookup(self,key):\n        '''\n        Retrieve the value associated with the specified key in the hash table,\n        or return the default value if it has not previously been inserted.\n        '''\n\n        hashed = self.hash(key)\n        ind = hashed % self.size\n        og_ind = ind\n        val = self.defval\n\n        while self.slots[ind][0] != None:\n\n            if self.slots[ind][0] == key:\n                val = self.slots[ind][1]\n                break\n\n            else:\n                ind = self.probe(ind)\n\n                if ind == og_ind:\n                    break\n\n        return val\n\n\n    def update(self,key,val):\n        '''\n        Change the value associated with key \"key\" to value \"val\".\n        If \"key\" is not currently present in the hash table,  insert it with\n        value \"val\".\n        '''\n\n        hashed = self.hash(key)\n        ind = hashed % self.size\n\n        if self.slots[ind][0] == key:\n\n            self.slots[ind][1] = val\n\n        elif self.slots[ind][0] == None:\n            \n            self.occupied += 1\n            self.slots[ind][0] = key\n            self.slots[ind][1] = val\n\n        else:\n\n            while (self.slots[ind][0] != None and self.slots[ind][0] != key):\n\n                ind = self.probe(ind)\n\n            if self.slots[ind][0] == None:\n                self.slots[ind][0] = key\n                self.slots[ind][1] = val\n                self.occupied += 1\n\n            elif self.slots[ind][0] == key:\n                self.slots[ind][1] = val\n\n        if self.occupied / self.size > TOO_FULL:\n\n            self.rehash()\n\n        pass\n\n\n    def rehash(self):\n        '''\n        Grows our hash table by the given GROWTH_RATIO and rehashes all keys\n        '''\n\n        self.size = self.size * GROWTH_RATIO\n        self.occupied = 0\n\n        keys = []\n        for [k, v] in self.slots:\n            if k != None:\n                keys.append([k, v])\n\n        self.slots =  [[None, self.defval] for x in range(self.size)]\n\n        for [k, v] in keys:\n            \n            self.update(k, v)\n\n        pass\n\n\n    def probe(self, prev_ind):\n        '''\n        Gives the next index in our hash table\n        '''\n        \n        if prev_ind + 1 < self.size:\n\n            return prev_ind + 1\n\n        else:\n\n            return 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ac80edc951dd7a8c9cb15057b75c4b3c3034520"},"cell_type":"markdown","source":"# Now we can build our Markov class off of our Hash_Table class"},{"metadata":{"trusted":true,"_uuid":"8631c7bfe039b485fad19abf0927ee133c86ee99"},"cell_type":"code","source":"HASH_CELLS = 57\n\nclass Markov:\n\n    def __init__(self,k,s):\n        '''\n        Construct a new k-order Markov model using the statistics of string \"s\"\n        '''\n\n        self.k = k\n        self.table = Hash_Table(HASH_CELLS, 0)\n        self.s = s\n\n        self.update_all_ks(self.k)\n        self.update_all_ks(self.k + 1)\n\n    def update_all_ks(self, k):\n        '''\n        Adds counts of all substrings of length k to our hash table\n        '''\n\n        looped_s = self.s[-k + 1:] + self.s\n\n        for i in range(len(self.s)):\n            to_add = looped_s[i : i + k]\n            val = self.table.lookup(to_add)\n            self.table.update(to_add, val + 1)\n\n        pass\n\n\n    def log_probability(self,s):\n        '''\n        Get the log probability of string \"s\", given the statistics of\n        character sequences modeled by this particular Markov model\n        This probability is *not* normalized by the length of the string.\n        '''\n\n        logprob = 0\n\n        looped_s = s[-self.k :] + s\n\n        smoothing_num = len(set(self.s))\n\n\n        for i in range(len(s)):\n            full_seq = looped_s[i : i + self.k + 1]\n            to_check_seq = looped_s[i : i + self.k]\n\n            numerator = self.table.lookup(full_seq) + 1\n            denominator = self.table.lookup(to_check_seq) + smoothing_num\n\n            if denominator > 0:\n                logprob += math.log(numerator / denominator)\n\n        return logprob","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5990c65f9ea4d79a39187cf3f49cea5d0c0c286f"},"cell_type":"markdown","source":"# Now it's time for us to go back to our data, clean them up, and build all our models"},{"metadata":{"trusted":true,"_uuid":"0432fce02cb10410fb3e2c1ea04f143488bd21be"},"cell_type":"code","source":"def gen_models_for_professions(question_data, k):\n\n    all_professions = list(question_data.professionals_industry.unique())\n\n    models = {}\n    for profession in all_professions:\n        profession_questions = question_data.loc[q_and_a['professionals_industry'] == profession][\"questions_body\"]\n        all_questions = \"\"\n        for question in profession_questions:\n            all_questions += question.lower() + \" \"\n        models[profession] = Markov(k, all_questions)\n        \n    return(models)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd47ee60d75e3f511be4381c9f62ea14cb3ccb34"},"cell_type":"markdown","source":"# Now that we have stored our models, we need to be able to actually determine the best professional to answer based on a given question. \n"},{"metadata":{"trusted":true,"_uuid":"cd3d0c2b0aca88b98f5544d4470fda16bcbb3073"},"cell_type":"code","source":"def determine_profession(models, string_to_test):\n    \n    logprobs = {}\n    \n    for profession in models:\n        markov_model = models[profession]\n        logprob = markov_model.log_probability(string_to_test)\n        logprobs[profession] = logprob\n        \n    return(min(logprobs, key = logprobs.get))\n    # gotta remember that low log-probability is actually high probability!\n    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b85937b86fff7428633be1aedf861ea4b81a50df"},"cell_type":"markdown","source":"# Let's check out how it works!"},{"metadata":{"trusted":true,"_uuid":"0d601ac7c7077a2555963e8c2512aa40bb6849d7"},"cell_type":"code","source":"models = gen_models_for_professions(q_and_a, 5)\n\nprint(determine_profession(models, \"I'm sad, can someone help me with depression?\"))\nprint(determine_profession(models, \"How do I get financial aid for college\"))\nprint(determine_profession(models, \"Where should I buy school supplies like notebooks and pencils?\"))\nprint(determine_profession(models, \"What are the best educational TV shows?\"))\nprint(determine_profession(models, \"How hard is it to get a position as a Data Scientist at a top tech company?\"))\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}