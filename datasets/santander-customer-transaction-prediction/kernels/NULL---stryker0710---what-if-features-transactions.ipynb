{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e91d46cf45c8ca4e49de16ab2afd038ec466f16"},"cell_type":"code","source":"#import neccessary libraries\nfrom keras.layers import LSTM,GRU,Dense,Bidirectional,Dropout\nfrom keras.callbacks import *\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.optimizers import RMSprop,Adam\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"In this kernel i tried to check several hypothesis:\n1. what quality of model based on simple NN\n2. can we get some uplift in auc by using LSTM, GRU, bidirectional GRU\n3. influence of stacking GRU/LSTM on auc"},{"metadata":{"trusted":true,"_uuid":"b7ff421610cc6b46bb7515435c3029834ee97a4c"},"cell_type":"code","source":"#import data\nPATH=\"../input/\"\ndata_train=pd.read_csv(f'{PATH}train.csv')\ndata_test=pd.read_csv(f'{PATH}test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e040945bc39cd5063c963309104cff89b93f78d5"},"cell_type":"code","source":"#see the shapes of data\ndata_train.shape,data_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43af29146889143a1804db694c63491434369817"},"cell_type":"code","source":"features=list(data_train.columns.values[2:])\ntarget=['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"821eccb0f5a9e32cbdfb7545d27f779ef4186a7f"},"cell_type":"code","source":"#normalizing data for nn\nscaler=StandardScaler()\ndata_train_scaled=data_train.copy()\ndata_test_scaled=data_test.copy()\ndata_train_scaled[features]=scaler.fit_transform(data_train[features].T).T\ndata_test_scaled[features]=scaler.transform(data_test[features].T).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"878265831252f7a80206eb2d924b6d69b3c6c0df"},"cell_type":"code","source":"#standard split on train and validation\nX_train,X_valid,y_train,y_valid=train_test_split(data_train_scaled[features],\n                                              data_train_scaled[target])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52f1a6a22239554da064878612d8e4c197d690a7"},"cell_type":"code","source":"#create testset and check sizes\nX_test=data_test_scaled[features]\nX_train.shape,X_valid.shape,X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8864dcb0c8bec24807aa2efe13480f0e747bcfb3"},"cell_type":"code","source":"#create custom auc metrics\nclass roc_callback(Callback):\n    def __init__(self,training_data,validation_data):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n\n    def on_epoch_end(self, epoch, logs={}):\n        y_pred = self.model.predict(self.x)\n        roc = roc_auc_score(self.y, y_pred)\n        y_pred_val = self.model.predict(self.x_val)\n        roc_val = roc_auc_score(self.y_val, y_pred_val)\n        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n        return\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71e28aff0527aa4eb05ef0f40170ae5f43b39ba6"},"cell_type":"code","source":"#create callback procedures\nearlystopper = EarlyStopping(patience=8, verbose=1)\ncheckpointer = ModelCheckpoint(filepath = 'model_tranz.hdf5',\n                               verbose=1,\n                               save_best_only=True, save_weights_only = True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=2, min_lr=0.000001, verbose=1,cooldown=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"66b0addc8873c40104f50dc15e8453834f04ae94"},"cell_type":"code","source":"#create simple NN model\nmodel = Sequential()\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-3),loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71bae67e5ce661b54951821d0ea53c67eca046c5"},"cell_type":"code","source":"#train the model\nhistory=model.fit(X_train.values,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train.values, y_train.values),\n                                         validation_data=(X_valid.values, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf58d3197dc341f64f8e88f69b28e4721115ef63"},"cell_type":"code","source":"#0.85 for simple nn... not so bad\n#next step is adding one more layer \nmodel = Sequential()\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dropout(rate=0.2))\nmodel.add(Dense(32,activation='relu'))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-3),loss='binary_crossentropy',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"587f562c5e22ad8c44e690f25ad2bd3d27564c25"},"cell_type":"code","source":"history_2=model.fit(X_train.values,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train.values, y_train.values),\n                                         validation_data=(X_valid.values, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3e977d87c407664e74fd8707a90e7cf83380785"},"cell_type":"code","source":"#then go to lstm\n#first of all edit Xs\nX_train_rnn=np.reshape(X_train.values,(X_train.shape[0],1,X_train.shape[1]))\nX_valid_rnn=np.reshape(X_valid.values,(X_valid.shape[0],1,X_valid.shape[1]))\nX_test_rnn=np.reshape(data_test_scaled[features].values,(data_test_scaled[features].shape[0],1,\n                                                     data_test_scaled[features].shape[1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51191b62b1179723ac766c33f79e5002bbbe6715"},"cell_type":"code","source":"X_train_rnn.shape,X_valid_rnn.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56592b67f78782d057dafbd429e2c19d302fdd33"},"cell_type":"code","source":"#create simple lstm\nmodel = Sequential()\nmodel.add(LSTM(32,batch_size=2048,batch_input_shape=(None,1,X_train.shape[-1]),\n              input_shape=(1,X_train_rnn.shape[-1])))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-2),loss='binary_crossentropy',metrics=['accuracy'])\nhistory_lstm=model.fit(X_train_rnn,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid_rnn,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train_rnn, y_train.values),\n                                         validation_data=(X_valid_rnn, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95562847b298ab23baa4aef18a7bc61ca949658f"},"cell_type":"code","source":"#create simple gru\nmodel = Sequential()\nmodel.add(GRU(32,batch_size=2048,batch_input_shape=(None,1,X_train.shape[-1]),\n              input_shape=(1,X_train.shape[-1])))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-2),loss='binary_crossentropy',metrics=['accuracy'])\nhistory_gru=model.fit(X_train_rnn,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid_rnn,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train_rnn, y_train.values),\n                                         validation_data=(X_valid_rnn, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42c8307778fccccf00264c00aab5b1bd2d8ab54d"},"cell_type":"code","source":"#create bidirectional gru\nmodel = Sequential()\nmodel.add(Bidirectional(GRU(32,batch_size=1024,\n              input_shape=(1,X_train.shape[-1]))))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-2),loss='binary_crossentropy',metrics=['accuracy'])\nhistory_bidir=model.fit(X_train_rnn,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid_rnn,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train_rnn, y_train.values),\n                                         validation_data=(X_valid_rnn, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85e07e100536bc82db0bb2ef845610c1bd7ee9f0"},"cell_type":"code","source":"#create stacked GRU\nmodel = Sequential()\nmodel.add(GRU(32,batch_size=2048,batch_input_shape=(None,1,X_train.shape[-1]),\n              return_sequences=True,dropout=0.1,recurrent_dropout=0.5,\n              input_shape=(1,X_train.shape[-1])))\nmodel.add(GRU(64,batch_size=2048,batch_input_shape=(None,1,X_train.shape[-1]),\n              return_sequences=False,dropout=0.1,recurrent_dropout=0.5,\n              input_shape=(1,X_train.shape[-1])))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer=Adam(lr=1e-2),loss='binary_crossentropy',metrics=['accuracy'])\nhistory_gru_stacked=model.fit(X_train_rnn,y_train.values,epochs=50,batch_size=2048,\n                 validation_data=(X_valid_rnn,y_valid.values),\n                 callbacks=[roc_callback(training_data=(\n                     X_train_rnn, y_train.values),\n                                         validation_data=(X_valid_rnn, y_valid.values)),\n                           earlystopper, checkpointer, reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3431e1d75e01819d0b1ab8277f96f0a433f35ab"},"cell_type":"code","source":"#final plot for presenting results\nfig, ax = plt.subplots()\nval_loss_simple_nn=history.history['val_loss']\nval_loss_2layers_nn=history_2.history['val_loss']\nval_loss_lstm=history_lstm.history['val_loss']\nval_loss_gru=history_gru.history['val_loss']\nval_loss_bidir=history_bidir.history['val_loss']\nval_loss_gru2=history_gru_stacked.history['val_loss']\n\nepochs_1=range(1,len(val_loss_simple_nn)+1)\nepochs_2=range(1,len(val_loss_2layers_nn)+1)\nepochs_3=range(1,len(val_loss_lstm)+1)\nepochs_4=range(1,len(val_loss_gru)+1)\nepochs_5=range(1,len(val_loss_bidir)+1)\nepochs_6=range(1,len(val_loss_gru2)+1)\n\nax.plot(epochs_1,val_loss_simple_nn,'b',label='val_loss_simple_nn')\nax.plot(epochs_2,val_loss_2layers_nn,'r',label='val_loss_2layers_nn')\nax.plot(epochs_3,val_loss_lstm,'go',label='val_loss_lstm')\nax.plot(epochs_4,val_loss_gru,'yo',label='val_loss_gru')\nax.plot(epochs_5,val_loss_bidir,'bo',label='val_loss_bidir')\nax.plot(epochs_6,val_loss_gru2,'ro',label='val_loss_gru2layers')\n\nplt.title('Losses on models')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fecb5a823f11aa9077a210008d70fb3141d5a44f"},"cell_type":"markdown","source":"Conclusion:\n1. Stacking worsens auc\n2. Sequence models equal to simple nn.\n3. Optimal loss is reached quite fast (~10 epochs)\n\nTL,DR:\n1. Try autoencoders\n2. Try feature engineering\n3. Try GANs"},{"metadata":{"trusted":true,"_uuid":"7575a2f0c3b62da7602d1679751804fde9aaa9b4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}