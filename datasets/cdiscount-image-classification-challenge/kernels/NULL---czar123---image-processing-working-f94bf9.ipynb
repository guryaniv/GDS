{"nbformat_minor": 1, "nbformat": 4, "cells": [{"outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "419948f1de60686ace56c21f07734edfab62d973", "_cell_guid": "4f7ca8e0-6af7-40a5-ae36-c5fdccd6ec5b"}}, {"outputs": [], "source": ["def getRawFeatures(picture):\n", "    red = []\n", "    green = []\n", "    blue = []\n", "    for row in range(picture.shape[0]):\n", "        for col in range(picture.shape[1]):\n", "            red.append(picture[row][col][0])\n", "            green.append(picture[row][col][1])\n", "            blue.append(picture[row][col][2])\n", "    feature = red\n", "    feature.extend(green)\n", "    feature.extend(blue)\n", "    return feature"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "7fc1b38e38da8ebee2d499b4cc627a723a07addf", "_cell_guid": "cd799485-93e0-4d76-9624-0b628504bf88"}}, {"outputs": [], "source": ["import io\n", "import bson # this is installed with the pymongo package\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "from skimage.data import imread   # or, whatever image library you prefer\n", "import multiprocessing as mp      # will come in handy due to the size of the data\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "89d8ce2e6149ea1a8bf7db009e7db5f8b10adcec", "_cell_guid": "f88cfc36-a17c-4eda-b5f2-fe567201441a"}}, {"outputs": [], "source": ["# Simple data processing\n", "count_images = 0\n", "image_names_array = []\n", "category_id_array = []\n", "data = bson.decode_file_iter(open('../input/train_example.bson', 'rb'))\n", "pictures = []\n", "count = 0\n", "prod_to_category = dict()\n", "\n", "for c, d in enumerate(data):\n", "    #for each product_id\n", "    product_id = d['_id']\n", "    category_id = d['category_id'] # This won't be in Test data\n", "    prod_to_category[product_id] = category_id\n", "    \n", "    for e, pic in enumerate(d['imgs']):\n", "        #for each image\n", "        picture = imread(io.BytesIO(pic['picture']))\n", "        pictures.append(picture)\n", "        count = count + 1\n", "        # do something with the picture, etc\n", "#         image_name = \"prod_id-\" + str(product_id) + \"-\" + \"image-\" + str(e)\n", "#         print(\"PRODUCT ID:\", product_id, \"NUMBER\", e)\n", "#         plt.imshow(picture)\n", "#         fig1 = plt.gcf()\n", "#         plt.show()\n", "#         plt.draw()\n", "        count_images = count_images + 1\n", "#         image_names_array.append(image_name)\n", "        category_id_array.append(str(category_id))\n", "        #fig1.savefig(\"img/\" + str(image_name), dpi=100)\n", "    print(\"done\")\n", "#     break\n", "\n", "prod_to_category = pd.DataFrame.from_dict(prod_to_category, orient='index')\n", "prod_to_category.index.name = '_id'\n", "prod_to_category.rename(columns={0: 'category_id'}, inplace=True)"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "bdfffde30a8d59257d649a0379e3a33a44744d8b", "_cell_guid": "7a754b19-e70c-4f08-98cc-66b549a4a280"}}, {"outputs": [], "source": ["X_train = np.asarray(pictures)\n", "y_train = np.asarray(category_id_array)\n", "y_train.shape"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "dd9c5d9b3078672abc57612f7302cd40c207b2d4", "_cell_guid": "5c9ff9fb-0aa2-4646-b270-cfb503e59088"}}, {"outputs": [], "source": ["X_train.shape"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "212c7bd7cc970c523f145c07f4b7f54371af9897", "_cell_guid": "edf1ee26-b25a-4ad0-8b47-8644ed2dc1ae"}}, {"outputs": [], "source": ["X_train = X_train.reshape(X_train.shape[0], 3, 180, 180).astype('float32')\n", "X_train = X_train - np.mean(X_train) / X_train.std()"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "a598bc27fa63b16b02cf53df434c8c4f295e0f4d", "_cell_guid": "4e70c847-e53e-464a-970e-204502ecf584"}}, {"outputs": [], "source": ["# listFeatureVector = []\n", "\n", "# for picture in pictures:\n", "#     featureVector = getRawFeatures(picture)\n", "#     listFeatureVector.append(featureVector)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "501608b6ad3a38cb5c0bffeb673f82c99d8fa227", "_cell_guid": "eef8decd-6eb1-486f-ac06-74a4d3724777"}}, {"outputs": [], "source": ["# print(len(listFeatureVector[0]))\n", "\n", "# X = listFeatureVector\n", "# y = category_id_array"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "7b6b9552045767aaac42d1cd2ab08e84121349ee", "_cell_guid": "b53e1cd6-fa71-4cb2-8b56-b5c2cc6c075a"}}, {"outputs": [], "source": ["# len(list(set(y)))"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "aa61f62f16119f9aad826f4eeab5c0186929fa93", "_cell_guid": "88dd3296-b648-48ee-b88d-36225659e2c3"}}, {"outputs": [], "source": ["y_train"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "d39d93483789299c7b0682b6fc6ad9304a791160", "_cell_guid": "c264809c-7c93-4710-adc6-20fd5e451218"}}, {"outputs": [], "source": ["b,c = np.unique(y_train, return_inverse=True)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "6074f841a1e47c2799c0b86555d0aaea8ca186eb", "_cell_guid": "8bbe7c31-295f-437f-9736-b041afbf9179"}}, {"outputs": [], "source": ["from collections import Counter\n", "d = Counter(c)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "218cfbf405c95753628ee70780d513c87dabb1a7", "_cell_guid": "03ff71db-9254-47c8-80a3-73ed1b00e34e"}}, {"outputs": [], "source": ["y_train = c"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c849c91309c0900788639c1af03b75e7a72a7a89", "_cell_guid": "37ed0c0f-e378-4e98-9906-331b5f1be3a3"}}, {"outputs": [], "source": ["y_train"], "execution_count": null, "cell_type": "code", "metadata": {"scrolled": true, "_uuid": "1fdfd5277811f1db662c3c7384026d683eba2a41", "_cell_guid": "1dd12042-468d-4ce2-80ef-53f6eaddee5e"}}, {"outputs": [], "source": ["from keras.utils import np_utils\n", "from tflearn.data_utils import to_categorical\n", "y_train = np_utils.to_categorical(y_train)"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "56077036cbc3da6fcd24e653370547de30054cf3", "_cell_guid": "4fb8235c-c68d-48c0-8903-a09920738418"}}, {"outputs": [], "source": ["y_train"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "9e45d340b3690317fcc7a19123fda9af3d16d206", "_cell_guid": "e6b4be89-e7dd-4287-932f-1333404b34ac"}}, {"outputs": [], "source": ["# X_train = X_train.reshape(X_train.shape[0], 180, 180, 3)\n", "# X_train = X_train.astype('float32')\n", "# X_train = X_train/255"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "62edb20bcd5fba16188b40dd5147632641b511a1", "_cell_guid": "6011c80b-8df6-4522-bb65-5fb774ad6fa3"}}, {"outputs": [], "source": ["from tflearn.layers.core import input_data, dropout, fully_connected\n", "from tflearn.layers.conv import conv_2d, max_pool_2d\n", "from tflearn.layers.estimator import regression\n", "model = input_data(shape=[None,3,180,180])\n", "model = conv_2d(model,32,5,activation='elu')\n", "model = max_pool_2d(model,2)\n", "model = conv_2d(model,64,3,activation='relu')\n", "model = max_pool_2d(model,2)\n", "model = dropout(model,0.3)\n", "model = conv_2d(model,64,3, activation='elu')\n", "model = max_pool_2d(model,2)\n", "model = fully_connected(model,512,activation='sigmoid')\n", "model = dropout(model,0.3)\n", "model = fully_connected(model,36,activation='softmax')\n", "model = regression(model,optimizer='adagrad',loss='categorical_crossentropy',learning_rate=0.05)"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "38d44e5ae3ba1742fbf0267e5509caad9373522c", "_cell_guid": "29f10004-3395-4b54-9d13-dc00e4aab544"}}, {"outputs": [], "source": ["import tensorflow as tf\n", "import tflearn\n", "with tf.device('cpu:0'):\n", "   model = tflearn.DNN(model)\n", "   model.fit(X_train , y_train)"], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "890699033ca957a5ad5f2a79c714bf34f95eeb79", "_cell_guid": "be9ccb57-01a5-4ba2-b68d-6634264db821"}}, {"outputs": [], "source": ["pred = model.predict(X_train)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "3402208c3c102151463dc1783251d244870f406d", "_cell_guid": "275ceb64-3c80-4f20-868d-a260758550be"}}, {"outputs": [], "source": ["model.evaluate(X_train, y_train)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "85c8aac0d7f8db3ebf266094b0aa232c02cfdbf3", "_cell_guid": "97071bf2-6b7d-42b6-9fa9-54eb74481554"}}, {"outputs": [], "source": ["# from keras.preprocessing import image\n", "# img = image.load_img('',target_size=(180,180))\n", "# img = image.img_to_array(img)\n", "# img = np.expand_dims(img, axis=0)\n", "img = X_train[0].reshape(1,3,180,180)\n", "# img.shape\n", "preds = model.predict(img)\n", "preds"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "daa7ba8dafc15699c2d26dc7a4d3a43f8fa418ef", "_cell_guid": "3ca68b97-d3e5-4b1e-a2ab-0c917e79515d"}}, {"outputs": [], "source": ["from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Activation, Flatten\n", "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n", "from keras.layers.normalization import BatchNormalization\n", "from keras.optimizers import Adam\n", "model = Sequential()\n", "\n", "model.add(Conv2D(32, (3, 3), input_shape=(180,180,3)))\n", "BatchNormalization(axis=-1)\n", "model.add(Activation('relu'))\n", "model.add(Conv2D(32, (3, 3)))\n", "BatchNormalization(axis=-1)\n", "model.add(Activation('relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "\n", "model.add(Conv2D(64,(3, 3)))\n", "BatchNormalization(axis=-1)\n", "model.add(Activation('relu'))\n", "model.add(Conv2D(64, (3, 3)))\n", "BatchNormalization(axis=-1)\n", "model.add(Activation('relu'))\n", "model.add(MaxPooling2D(pool_size=(2,2)))\n", "\n", "model.add(Flatten())\n", "\n", "# Fully connected layer\n", "model.add(Dense(512))\n", "\n", "BatchNormalization()\n", "model.add(Activation('relu'))\n", "model.add(Dropout(0.2))\n", "model.add(Dense(110))\n", "\n", "model.add(Activation('softmax'))"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c9861455245ff2a1fcf1c87d66f19ea3a6a0847b", "_cell_guid": "b6a608a3-fd30-4d7f-a0d7-31f7fd667835"}}, {"outputs": [], "source": ["model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "cab0255b6ce12bdaaac303d6910f0dde086cb463", "_cell_guid": "1a4b4cec-cfd0-44d6-b5f1-75f895d6c4d7"}}, {"outputs": [], "source": ["from keras.preprocessing.image import ImageDataGenerator\n", "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n", "                         height_shift_range=0.08, zoom_range=0.08)\n"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "1e9e468e4b2498cbb46e355a41ff71f05a254ce2", "_cell_guid": "f951046f-ca3f-4e26-b8b9-329a705d8271"}}, {"outputs": [], "source": ["train_generator = gen.flow(X_train, y_train)\n"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "bd4b30c4a178e66ba3f4f8610545bd46d540eb09", "_cell_guid": "c5dda7c6-f4c5-405f-a654-bfefa97cf5d7"}}, {"outputs": [], "source": ["model.fit_generator(train_generator, steps_per_epoch=110//64, epochs=2)"], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "e54196eeef6a6ae9bcafa14c648bf011dff8e471", "_cell_guid": "28d5580d-ec37-4d1a-ad46-bccd2170afff"}}, {"outputs": [], "source": [], "execution_count": null, "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "07f0cf2599944d3052be02e407db3a5d18373dd9", "_cell_guid": "fe765f16-a5b7-478d-8855-a03241fedc39"}}], "metadata": {"language_info": {"name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}}