{"nbformat_minor": 1, "nbformat": 4, "cells": [{"cell_type": "code", "source": ["import gc\n", "import time\n", "import numpy as np\n", "import pandas as pd\n", "\n", "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n", "from sklearn.cross_validation import train_test_split\n", "\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline \n", "\n", "import math\n", "\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "metadata": {"_cell_guid": "f49a0842-1c3d-4bee-8b3e-3caf6111bb60", "collapsed": true, "_uuid": "e4561cb64722ffd7adb74a8800f89973bc3fe87a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def rmsle(y, y_pred):\n", "    assert len(y) == len(y_pred)\n", "    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n", "    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n", "#Source: https://www.kaggle.com/marknagelberg/rmsle-function"], "metadata": {"_cell_guid": "17b85633-4dae-4a49-9573-5d5c3b1b9699", "collapsed": true, "_uuid": "56874f4a359241631a1f1e4788da09e7b09182b8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#LOAD DATA\n", "print(\"Loading data...\")\n", "start_time = time.time()\n", "train = pd.read_csv('../input/train.tsv', sep='\\t')\n", "test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "\n", "train['target'] = np.log1p(train['price']) \n", "\n", "print(train.shape)\n", "print(test.shape)\n", "\n", "test_len = test.shape[0]"], "metadata": {"_cell_guid": "a76efe2c-34bb-458a-8611-1dcabda65b31", "collapsed": true, "_uuid": "80cd3abaf2d32b2c8133719d9a7bbb977adf91cb"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#HANDLE MISSING VALUES\n", "print(\"Handling missing values...\")\n", "def handle_missing(dataset):\n", "    dataset.category_name.fillna(value=\"\", inplace=True)\n", "    dataset.brand_name.fillna(value=\"\", inplace=True)\n", "    dataset.item_description.fillna(value=\"\", inplace=True)\n", "    return (dataset)\n", "\n", "train = handle_missing(train)\n", "test = handle_missing(test)\n", "print(train.shape)\n", "print(test.shape)"], "metadata": {"_cell_guid": "4e506bee-5541-4879-aaea-159dee4416b8", "collapsed": true, "_uuid": "967a5f2b26862be11cdae8cb0fb7402fd486135c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["train.head(3)"], "metadata": {"_cell_guid": "39007c90-161e-4ef0-b0a5-fc16f04665b4", "collapsed": true, "_uuid": "1aa305c5227f3a4d6b5a5bdf6aa55fe55cf46548"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#PROCESS CATEGORICAL DATA\n", "print(\"Handling categorical variables...\")\n", "le = LabelEncoder()\n", "\n", "le.fit(np.hstack([train.category_name, test.category_name]))\n", "train['category'] = le.transform(train.category_name)\n", "test['category'] = le.transform(test.category_name)\n", "\n", "le.fit(np.hstack([train.brand_name, test.brand_name]))\n", "train['brand'] = le.transform(train.brand_name)\n", "test['brand'] = le.transform(test.brand_name)\n", "del le\n", "\n", "train.head(3)\n"], "metadata": {"_cell_guid": "204de9ca-7ea5-481b-9039-743bbab1084f", "collapsed": true, "_uuid": "cf9985161bcd94612b1359177e23124efd3410cb"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#PROCESS TEXT: RAW\n", "print(\"Text to seq process...\")\n", "from keras.preprocessing.text import Tokenizer\n", "raw_text = np.hstack([train.category_name.str.lower(), \n", "                      train.item_description.str.lower(), \n", "                      train.name.str.lower()])\n", "\n", "print(\"   Fitting tokenizer...\")\n", "tok_raw = Tokenizer()\n", "tok_raw.fit_on_texts(raw_text)\n", "print(\"   Transforming text to seq...\")\n", "\n", "train[\"seq_category_name\"] = tok_raw.texts_to_sequences(train.category_name.str.lower())\n", "test[\"seq_category_name\"] = tok_raw.texts_to_sequences(test.category_name.str.lower())\n", "train[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\n", "test[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\n", "train[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\n", "test[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\n", "train.head(3)"], "metadata": {"_cell_guid": "b122ac7a-c203-463f-aa92-b843b039fce3", "collapsed": true, "_uuid": "ff62bf6d3681b84510026bfa3514963513f2e8f2"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#SEQUENCES VARIABLES ANALYSIS\n", "max_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\n", "max_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n", "                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\n", "max_seq_category_name = np.max([np.max(train.seq_category_name.apply(lambda x: len(x)))\n", "                                   , np.max(test.seq_category_name.apply(lambda x: len(x)))])\n", "print(\"max name seq \"+str(max_name_seq))\n", "print(\"max item desc seq \"+str(max_seq_item_description))\n", "print(\"max category name seq \"+str(max_seq_category_name))"], "metadata": {"_cell_guid": "9da5165e-0692-4c1a-a5e7-3fb1c6c1a4fd", "collapsed": true, "_uuid": "335a3d95444a2602598aebbfa6de0a8a3f5a1814"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["train.seq_name.apply(lambda x: len(x)).hist()"], "metadata": {"_cell_guid": "3e87bf13-093e-42a3-bef9-ed10322944df", "collapsed": true, "_uuid": "32ffa5a96deaeb6214469a2594475f7b5a15bc92"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["train.seq_item_description.apply(lambda x: len(x)).hist()"], "metadata": {"_cell_guid": "09349ced-fcac-4406-8876-a00fc269218d", "scrolled": true, "collapsed": true, "_uuid": "bdfde374cbe6f2edc9c453f91ef90c757c8d8f06"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["train.seq_category_name.apply(lambda x: len(x)).hist()"], "metadata": {"_cell_guid": "8e7916a9-3d10-4b0e-be57-d834cfe67fd9", "collapsed": true, "_uuid": "e1ff40244a013123bc71d313c39efddc369fe403"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#DEV TESTS\n", "from sklearn.model_selection import train_test_split\n", "dtrain, dvalid = train_test_split(train, random_state=233, train_size=0.99) \n", "print(dtrain.shape)\n", "print(dvalid.shape)"], "metadata": {"_cell_guid": "75e35ee4-7bda-4d47-a1b2-0f495bc6173f", "collapsed": true, "_uuid": "ed5ae9dcb69e4847ee71d772a8bbda7b9e65b6e5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#EMBEDDINGS MAX VALUE\n", "MAX_NAME_SEQ = max_name_seq\n", "MAX_ITEM_DESC_SEQ = max_seq_item_description\n", "MAX_CATEGORY_NAME_SEQ = max_seq_category_name\n", "#MAX_TEXT = len(tok_raw.word_index) + 1\n", "MAX_TEXT = np.max([np.max(train.seq_name.max())\n", "                    , np.max(test.seq_name.max())\n", "                    , np.max(train.seq_category_name.max())\n", "                    , np.max(test.seq_category_name.max())\n", "                    , np.max(train.seq_item_description.max())\n", "                    , np.max(test.seq_item_description.max())])+2\n", "MAX_CATEGORY = np.max([train.category.max(), test.category.max()])+1\n", "MAX_BRAND = np.max([train.brand.max(), test.brand.max()])+1\n", "MAX_CONDITION = np.max([train.item_condition_id.max(),\n", "                        test.item_condition_id.max()])+1"], "metadata": {"_cell_guid": "e1b9db3a-63de-4bd9-9bad-2db899176053", "collapsed": true, "_uuid": "4cae7d35e8b44e04df93c9f8084ec67ef40a1828"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#KERAS DATA DEFINITION\n", "from keras.preprocessing.sequence import pad_sequences\n", "\n", "def get_keras_data(dataset):\n", "    X = {\n", "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n", "        ,'item_desc': pad_sequences(dataset.seq_item_description\n", "                                    , maxlen=MAX_ITEM_DESC_SEQ)\n", "        ,'brand': np.array(dataset.brand)\n", "        ,'category': np.array(dataset.category)\n", "        ,'category_name': pad_sequences(dataset.seq_category_name\n", "                                        , maxlen=MAX_CATEGORY_NAME_SEQ)\n", "        ,'item_condition': np.array(dataset.item_condition_id)\n", "        ,'num_vars': np.array(dataset[[\"shipping\"]])\n", "    }\n", "    return X\n", "\n", "X_train = get_keras_data(dtrain)\n", "X_valid = get_keras_data(dvalid)\n", "X_test = get_keras_data(test)"], "metadata": {"_cell_guid": "22f34be1-bd4a-4ad1-a931-62873816e8ee", "collapsed": true, "_uuid": "2f876f24ae0e5a82bdf9b0568f796cce5e2fed2c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#KERAS MODEL DEFINITION\n", "from keras.layers import Input, Dropout, Dense, BatchNormalization, \\\n", "    Activation, concatenate, GRU, Embedding, Flatten\n", "from keras.models import Model\n", "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping#, TensorBoard\n", "from keras import backend as K\n", "from keras import optimizers\n", "from keras import initializers\n", "\n", "dr = 0.25 \n", "\n", "def get_model():\n", "    #params\n", "    dr_r = dr\n", "    \n", "    #Inputs\n", "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n", "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n", "    brand = Input(shape=[1], name=\"brand\")\n", "    category = Input(shape=[1], name=\"category\")\n", "    category_name = Input(shape=[X_train[\"category_name\"].shape[1]], \n", "                          name=\"category_name\")\n", "    item_condition = Input(shape=[1], name=\"item_condition\")\n", "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n", "    \n", "    #Embeddings layers\n", "    emb_size = 64\n", "    emb_name = Embedding(MAX_TEXT, emb_size)(name)\n", "    emb_item_desc = Embedding(MAX_TEXT, emb_size)(item_desc)\n", "    emb_category_name = Embedding(MAX_TEXT, emb_size)(category_name)\n", "    emb_brand = Embedding(MAX_BRAND, emb_size)(brand)\n", "    emb_category = Embedding(MAX_CATEGORY, 10)(category)\n", "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n", "    \n", "    rnn_layer1 = GRU(16) (emb_item_desc)\n", "    rnn_layer2 = GRU(8) (emb_category_name)\n", "    rnn_layer3 = GRU(8) (emb_name)\n", "    #rnn_layer4 = GRU(8) (emb_brand)\n", "    \n", "    #main layer\n", "    main_l = concatenate([\n", "        Flatten() (emb_category)\n", "        , Flatten() (emb_item_condition)\n", "        , rnn_layer1\n", "        , rnn_layer2\n", "        , rnn_layer3\n", "        #, rnn_layer4\n", "        , num_vars\n", "    ])\n", "    main_l = Dropout(dr_r) (Dense(128) (main_l)) \n", "    #main_l = Dropout(dr_r) (Dense(64) (main_l))\n", "    main_l = Dropout(dr_r) (Dense(32) (main_l))\n", "    \n", "    #output\n", "    output = Dense(1, activation=\"linear\") (main_l)\n", "    \n", "    #model\n", "    model = Model([name, item_desc, brand\n", "                   , category, category_name\n", "                   , item_condition, num_vars], output)\n", "    #optimizer = optimizers.RMSprop()\n", "    optimizer = optimizers.Adam()\n", "    model.compile(loss=\"mse\", \n", "                  optimizer=optimizer)\n", "    return model\n"], "metadata": {"_cell_guid": "79428c10-e754-4e0e-a8be-ecbe74ef55ff", "collapsed": true, "_uuid": "8af261410908e6c713ca7de01c3c2c549debf779"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def eval_model(model):\n", "    val_preds = model.predict(X_valid)\n", "    val_preds = np.expm1(val_preds)\n", "    \n", "    y_true = np.array(dvalid.price.values)\n", "    y_pred = val_preds[:, 0]\n", "    v_rmsle = rmsle(y_true, y_pred)\n", "    return v_rmsle"], "metadata": {"_cell_guid": "fb7d4e7b-9b09-4308-a566-f64a1a75e3e1", "collapsed": true, "_uuid": "9157787d7d7c664f7dd6d7322ba655fd688f47bc"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n", "\n", "del train\n", "\n", "gc.collect()"], "metadata": {"_cell_guid": "179d7c59-0bfa-4ccc-be4f-d2a3a7e5b2d0", "collapsed": true, "_uuid": "a91fc822af0a973ed3efd0d49a5bdd825e932d2b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#FITTING THE MODEL\n", "epochs = 1\n", "BATCH_SIZE = 512 * 3\n", "steps = int(len(X_train['name'])/BATCH_SIZE) * epochs\n", "\n", "lr_init, lr_fin = 0.013, 0.009\n", "lr_decay = exp_decay(lr_init, lr_fin, steps)\n", "\n", "model = get_model()\n", "K.set_value(model.optimizer.lr, lr_init)\n", "K.set_value(model.optimizer.decay, lr_decay)\n", "\n", "history = model.fit(X_train, dtrain.target\n", "                    , epochs=epochs\n", "                    , batch_size=BATCH_SIZE\n", "                    , validation_split=0.01\n", "                    , verbose=1\n", "                    )"], "metadata": {"_cell_guid": "b19fde2e-e454-48fd-b336-de0b15051fc8", "collapsed": true, "_uuid": "5fa44a0c7fcca9b0f0c15719be8ac38a2ee7cea8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#EVALUATE MODEL ON DEV TESTS\n", "v_rmsle = eval_model(model)\n", "print(\" RMSLE error on dev test: \"+str(v_rmsle))\n", "log_subname = '_'.join(['ep', str(epochs),\n", "                    'bs', str(BATCH_SIZE),\n", "                    'lrI', str(lr_init),\n", "                    'lrF', str(lr_fin),\n", "                    'dr', str(dr)])"], "metadata": {"_cell_guid": "0bfc00c9-37d7-4ebe-9f9c-2bf0661aef3c", "collapsed": true, "_uuid": "5065d64200d6c4675901e727ddf87afc8136a0c3"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#CREATE PREDICTIONS\n", "preds = model.predict(X_test, batch_size=BATCH_SIZE) \n", "preds = np.expm1(preds)\n", "\n", "submission = test[[\"test_id\"]][:test_len] \n", "submission[\"price\"] = preds[:test_len]"], "metadata": {"_cell_guid": "996256b1-8628-4a8a-9e75-2eae09fa7d6e", "collapsed": true, "_uuid": "59772da91cbcb781396138d860d7875a23accaa9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["submission.to_csv(\"sample_submission.csv\", index=False)\n", "print('[{}] Finished submission...'.format(time.time() - start_time))\n"], "metadata": {"_cell_guid": "8b76a6c9-fa82-4011-82ab-0384b8e2e5b4", "collapsed": true, "_uuid": "270683b6ea8391d536aa86deeb7d0b381a9006ba"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["\n", " \n", "    "], "metadata": {"_cell_guid": "4f194864-1f59-4b94-871b-3b3ee6f01fd2", "_uuid": "d0e07027d44dcda199db405c974a05276a3fb4ac"}}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.4", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}}