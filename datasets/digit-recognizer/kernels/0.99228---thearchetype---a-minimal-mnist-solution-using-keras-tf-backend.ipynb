{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.optimizers import adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.utils import to_categorical\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#Reading the data\n\n#Note that the data is in a flat format, where one row represents a whole image, with the label.\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"623c856d6ef926ac43e93b920b4fdac69655eb25"},"cell_type":"code","source":"train.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9fb084d0baaae2fd03b99e59dc3b2a8bae78e73"},"cell_type":"code","source":"test.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03747138d5e5c389603ec842228aa31f0f2839cf"},"cell_type":"code","source":"#Separating the digit label form the train data, and removing it from the original dataframe\ntrain_y = train['label']\ntrain_X = train.drop(columns=['label'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0c8b8fe1fe6847ae5f6fd0a64757e0654802e22a"},"cell_type":"code","source":"del(train) #because we need to save some space","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ca1e7e4270411ba52c707495f51fc1e0183d2be"},"cell_type":"code","source":"#Converting the 1-Dimensional image data into 2D data (will be required for visualization purposes)\ntrain_X = np.array(train_X).reshape(len(train_X), 28, 28)\ntest = np.array(test).reshape(len(test), 28, 28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76a381c378d34a43434d9e0767b84789c488d897"},"cell_type":"code","source":"#Let us see the shape (dimensions) of our data\nprint(train_X.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1187eabf6b5c63cc3336f2757312fe37836d71f2"},"cell_type":"code","source":"# We need the data to be of the shape (B, H, W, C),\n# where B is the batch size, H is height, W is width,\n# and C is channels. For our case, we need it to be:\n# 42,000x28x28x1 and 28,000x28x28x1 respectively for train and test\ntrain_X = np.reshape(train_X, (42000, 28, 28, 1))\ntest = np.reshape(test, (28000, 28, 28, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"46da2150f3190b78dc3700d1950881df49e54efb"},"cell_type":"code","source":"print(train_X.shape, test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"332fcda93a68b0765c7bd5595a9eb054130d70f4"},"cell_type":"code","source":"# The above cell tells us that we're 42,000 images, each of 28x28 pixels for train\n# and 28,000 images in the same dimensions for test.\n# Let's just visualize some cases\nfor i, x in enumerate(train_X[:12]):\n    #plt.figure(figsize=(10, 10))\n    plt.subplot(4,3,i+1)\n    plt.imshow(train_X[i].reshape(28,28), cmap='gray', interpolation='none')\n    # plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"42d4eddbc7775ebd4432a15ead724d3e19ca4950"},"cell_type":"code","source":"for i, x in enumerate(test[:12]):\n    #plt.figure(figsize=(10, 10))\n    plt.subplot(4,3,i+1)\n    plt.imshow(test[i].reshape(28,28), cmap='gray', interpolation='none')\n    # plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a431ce5ebc800d40f08ee49932bc685b6384264"},"cell_type":"code","source":"def encode_one_hot(x):\n    return to_categorical(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ecc4044affdd9d2b2928c987a980e22589acc5f0"},"cell_type":"code","source":"def decode_one_hot(x):\n    return np.argmax(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8d11963ee1e64578d06e43ef2e2561b08f96c6b"},"cell_type":"code","source":"one_hot_y = encode_one_hot(train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e4a65d09d69c576a9cb8aa196efb31d7e18e29f8"},"cell_type":"code","source":"model = Sequential()\n# input: 28x28 images with 3 channels -> (28, 28, 1) tensors.\n# this applies 32 convolution filters of size 3x3 each.\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0fedd3bd0325ba34ab2342b1bb5961ddb7041e0"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7b8a30602e98ab71a9e3bce0031deb82733003c"},"cell_type":"code","source":"# checkpoint\nfilepath=\"weights.best.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\nmodel.fit(train_X, one_hot_y, epochs=55, validation_split=0.25, batch_size=256, shuffle=True, verbose=1, callbacks=[checkpoint])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee20c8b27546de6f3d71854bee20b5f4039a607"},"cell_type":"code","source":"# # Reloading from the best weights saved\n# model = Sequential()\n# # input: 28x28 images with 3 channels -> (28, 28, 1) tensors.\n# # this applies 32 convolution filters of size 3x3 each.\n# model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n# model.add(Conv2D(64, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n\n# model.add(Flatten())\n# model.add(Dense(512, activation='relu'))\n# model.add(Dropout(0.5))\n# model.add(Dense(10, activation='softmax'))\n\n# model.load_weights(\"weights.best.hdf5\")\n# model.compile(loss='categorical_crossentropy', optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1739c89f7b2aca3ed86f4834c6974f43c5bec07b"},"cell_type":"code","source":"#Getting the predicted labels for each image in the test set\npredicted = model.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c667ed670e58f298b0b39e912eaf98921320eea2"},"cell_type":"code","source":"predicted.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7099defe7d93e6dd3fd5ceec0e49bba05ede5fdb"},"cell_type":"code","source":"#Creating the final submission-ready dataframe with ImageId column, and the predicted results.\nimage_ids = range(1, len(test)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f22a5ee5001124579febe83041f2a09bb688d304"},"cell_type":"code","source":"predicted_decoded = list(map(decode_one_hot, predicted))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0fd703931755788342168bf2cf58bd5f2c8313c"},"cell_type":"code","source":"submission_df = pd.DataFrame({'ImageId': image_ids, 'Label': predicted_decoded})\n#Saving the final dataframe as csv, which can be submitted now.\nsubmission_df.to_csv(path_or_buf='submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f92b9ac9c086acbc9914e80a2ca37e216e134f9"},"cell_type":"code","source":"submission_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0a0f3dc39ef34147518449bcb7c33334dbfe97f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}