{"cells":[{"metadata":{"_uuid":"2d4533770ac4494f9d40c6dd8538fecf793f1351"},"cell_type":"markdown","source":"## Turkey recognition"},{"metadata":{"trusted":true,"_uuid":"f08e0b0a42c514d2cca68a2de476908d69c666ea"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb              # convenient plotting functionality","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de77e981f45d471da4daf528fc94dc29de072cf4"},"cell_type":"markdown","source":"## Import data"},{"metadata":{"trusted":true,"_uuid":"a5275e9e1929e95c52bc9ff88343f8a8f4542274"},"cell_type":"code","source":"data_train = pd.read_json('../input/train.json')\ndata_test  = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43171485f4b4d64f97af47cc7266d24af4a312fd"},"cell_type":"code","source":"print(\"Number of training samples: \\t\", data_train.shape[0])\nprint(\"Number of test samples: \\t\", data_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2915df8c1409c77ad2be34cbdd873ac0e9e3a980"},"cell_type":"markdown","source":"## What does the data look like?"},{"metadata":{"trusted":true,"_uuid":"4599b8b007a6dd2c35a78b0100dcfaa6da15e8fd"},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cac312371f5071a051641a126b50939edf09378c"},"cell_type":"markdown","source":"## How many are turkeys and how many aren't turkeys?"},{"metadata":{"trusted":true,"_uuid":"11d150de4ec80e7b1ce2ab46cc2a7461dbb4be1b"},"cell_type":"code","source":"sb.countplot(data_train['is_turkey'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03b1a5ec2bc5193a7b2f4d7346d95d4e19cc8c8a"},"cell_type":"markdown","source":"## Let's get all of the audio files the same size. \n## What are their current sizes?"},{"metadata":{"trusted":true,"_uuid":"88e4d5f7ded285d334a918b064e7cf6653e62cfe"},"cell_type":"code","source":"# Above you can see the audio_embedding field of the dataframe has the data\n# For example,\nimage = np.array(data_train['audio_embedding'][0])\nplt.imshow(image)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"824f8a441082efcf47dce55b84aaaac861b8eefe"},"cell_type":"code","source":"image = np.array(data_train['audio_embedding'][100])\nplt.imshow(image)\nplt.colorbar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bbf872ffe5f1225b54718da3ea236675d11d43b"},"cell_type":"code","source":"# So what we're really being provided here are spectrograms.\n# Let's make sure all the data is the same size, in terms of length and width.\n\ndata_train['length'] = data_train['audio_embedding'].apply(len)\nplt.yscale('log')\nsb.countplot('length', hue='is_turkey', data=data_train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9bece1cbcb397087a5d1234041699442763c6a36"},"cell_type":"markdown","source":"## Let's make each spectrogram sized 10 by 128"},{"metadata":{"trusted":true,"_uuid":"cb2feacc1c92970b76f7917d23959fe729019e4d"},"cell_type":"code","source":"new_length   = 10\nfeature_size = 128\n\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08e2d715a184ccf8f9ac2b246642fdeede26a460"},"cell_type":"code","source":"X = pad_sequences(data_train['audio_embedding'], maxlen=new_length, padding='post')\nX_test = pad_sequences(data_test['audio_embedding'], maxlen=new_length, padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e0a516c437739cea4aee092006e0fb29399ef5e6"},"cell_type":"code","source":"plt.imshow(X_test[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c2028e6c9d27286b879700efb1610698a6e160c"},"cell_type":"code","source":"# define the target variable\ny = data_train['is_turkey'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07f1784ba4a5f7ac5625e3568da70001bc05bdff"},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b91ad1af8590c6ecd5a5ce960854f8198c131c8"},"cell_type":"markdown","source":"## Let's build our model"},{"metadata":{"trusted":true,"_uuid":"d209d9e78995188b58682e95d1719f0b5dd0d924"},"cell_type":"code","source":"from keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Bidirectional, LSTM, Reshape, GlobalMaxPooling1D, GlobalAveragePooling1D, Input, concatenate, BatchNormalization, Dense, Conv2D, MaxPooling2D, Flatten,Activation,Embedding\nfrom keras.optimizers import Adam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc9f63a8ebef16c0501c19ee00d5a94fb506ba63"},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(128*2,(3,3), input_shape=(10,128,1) ))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\n\n\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbcf0214a919d272e3c27f08fefd35b9f18dcc30"},"cell_type":"code","source":"# reshape the training data for the 2d Conv Net\nn_images = X.shape[0]\nX_reshaped = X.reshape(n_images, 10, 128, 1)\n\nn_images_test = X_test.shape[0]\nX_test_reshaped = X_test.reshape(n_images_test, 10, 128, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6efbbc0daa6f8bdff5089e77146af4b23b53f1e1"},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f18cd8303eb7e2da62de5a03255bf6021271af"},"cell_type":"code","source":"# save the randomly initialized weights\nmodel.save_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9ca82716ef3dcb4c1770f6b0ab008c752616781c"},"cell_type":"markdown","source":"## Run the model"},{"metadata":{"trusted":true,"_uuid":"5a3dd2987408fb0ac32a07f7286e0783c88f4ac6"},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a57aaf14fa247fc1f2a0e2272aa0149da550d87b"},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.1, patience=2, verbose=1, min_lr=1e-8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edd14c7f957b0d80e98dc486fb38ce9a5ad15b4c"},"cell_type":"code","source":"model.fit(X_reshaped, y, epochs=20, batch_size=256, verbose=2, callbacks=[reduce_lr])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b2fa41ff9a7df209ce4539d37df25db8efcc531"},"cell_type":"markdown","source":"## Now use the model on test data"},{"metadata":{"trusted":true,"_uuid":"fdab30ab0976a9a7be80feffc1c9a9336b86011f"},"cell_type":"code","source":"y_test = model.predict(X_test_reshaped, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0480a97185b19a850ba30f74654a372e01be129d"},"cell_type":"code","source":"submission = pd.DataFrame({'vid_id': data_test['vid_id'].values,\n                           'is_turkey (pred)': list(y_test.flatten()) })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e26127a4c3b11023dea16cb045e062429c8691f8"},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6d4917060e045e56d2ab63ccaafc543ca50476d"},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07d24f149cae8f967eb1149357ddd08efa2ad1a7"},"cell_type":"markdown","source":"## Since the test data doesn't provide y values to check against, let's run the model again but this time split the training data into training and validation subsets."},{"metadata":{"trusted":true,"_uuid":"9ce7770cbf7d6f547736f2e4a82ece8ea6ad125b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nX_train, X_val, y_train, y_val = train_test_split(X_reshaped, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true,"_uuid":"ab1f896f7f193e6193a9b23feb5a189f4ceb9c4b"},"cell_type":"code","source":"# load the original model weights\nmodel.load_weights('model.h5')\n# train the model\nhistory = model.fit(X_train, y_train, batch_size=256, epochs=20, validation_data=[X_val, y_val], callbacks=[reduce_lr], verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5fe1a79c784e59f0510ced846acbb241f72a00f"},"cell_type":"markdown","source":"## How well did we do with the validation set?"},{"metadata":{"trusted":true,"_uuid":"79d666d8aea834233ec0698016aeae48f5120d18"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\ny_pred_val = model.evaluate(X_val, y_val, verbose=1)\nprint(\"Train accuracy : \", y_pred_val[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b3ba0c7adb44d41b2c50652610c004c70060fd3a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}