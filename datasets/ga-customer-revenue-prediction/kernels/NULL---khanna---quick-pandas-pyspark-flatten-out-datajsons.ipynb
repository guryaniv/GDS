{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"\"\"\"\nJust import all the important packages you need (pandas / pyspark chiefly)\nand load your datasets up!\n\nfor pyspark with jupyter, use :\ndownloading spark from a mirror : \nhttp://mirrors.estointernet.in/apache/spark/spark-2.3.2/spark-2.3.2-bin-hadoop2.7.tgz\ntar -xzvf <spark-downloaded.tgz above>\nmv <spark-above> spark\n\nand set your ~/.bashrc as :\nexport SPARK_HOME=<curr-working-dir>/spark\nexport PATH=$SPARK_HOME/bin:$PATH\n\nexport PYSPARK_DRIVER_PYTHON=ipython\nexport PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n\nsource ~/.bashrc\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport pyspark\nfrom pyspark.sql import SparkSession\nimport sys, os, json, time\n\ntrain_df = pd.read_csv('./input/train.csv',header='infer')\ntest_df = pd.read_csv('./input/test.csv',header='infer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a064116f6c36925cff474065200da756637626f"},"cell_type":"code","source":"\"\"\"\nseparate out columns that are already flattened, i.e not jsons\n\"\"\"\ntrain_df_1 = train_df[['channelGrouping','date','fullVisitorId','sessionId','socialEngagementType','visitId','visitNumber','visitStartTime']]\ntest_df_1 = test_df[['channelGrouping','date','fullVisitorId','sessionId','socialEngagementType','visitId','visitNumber','visitStartTime']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1070a0364ce961667dac6457b8b8b167e122f44f"},"cell_type":"code","source":"\"\"\"\ncreate separate files for 'device', 'geoNetwork', 'totals', 'trafficSource' json attribs\n\"\"\"\n\ndef write_to_file(mode,df,tag):\n    f = open(mode+\"_df_\"+str(tag)+\".json\", \"w\")\n    for index, row in df.iterrows():\n        try:\n            print >> f, row[tag]\n        except:\n            print \"mode: \"+str(mode)+\"pos: \"+str(index)+\" for tag: \"+tag \n            print >> f, \"{}\"\n    f.close()\n\nwrite_to_file('train',train_df['device'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'device')\nwrite_to_file('train',train_df['geoNetwork'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'geoNetwork')\nwrite_to_file('train',train_df['totals'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'totals')\nwrite_to_file('train',train_df['trafficSource'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'trafficSource')\n\nwrite_to_file('test',test_df['device'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'device')\nwrite_to_file('test',test_df['geoNetwork'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'geoNetwork')\nwrite_to_file('test',test_df['totals'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'totals')\nwrite_to_file('test',test_df['trafficSource'].str.replace('\"\"','\"').replace('\"{','\"').replace('}\"','').to_frame(),'trafficSource')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fb44ff248142ce58a34c667a19ce25081088203"},"cell_type":"code","source":"\"\"\"\nredundant but neat : load the training and testing dataframes back, these together form part-2\nfor train and test features set, respectively\n\"\"\"\ntrain_df_device = spark.read.json('train_df_device.json').toPandas()\ntrain_df_geo = spark.read.json('train_df_geoNetwork.json').toPandas()\ntrain_df_totals = spark.read.json('train_df_totals.json').toPandas()\ntrain_df_traffic = spark.read.json('train_df_trafficSource.json').toPandas()\n\ntest_df_device = spark.read.json('test_df_device.json').toPandas()\ntest_df_geo = spark.read.json('test_df_geoNetwork.json').toPandas()\ntest_df_totals = spark.read.json('test_df_totals.json').toPandas()\ntest_df_traffic = spark.read.json('test_df_trafficSource.json').toPandas()\n\n\"\"\"\ntime to concat : final outputs tr_df and te_df for training and testing dataframes, respectively\n\"\"\"\ntr_df = pd.concat([train_df_1.reset_index(drop=True), train_df_device.reset_index(drop=True)], axis=1)\ntr_df = pd.concat([tr_df.reset_index(drop=True), train_df_geo.reset_index(drop=True)], axis=1)\ntr_df = pd.concat([tr_df.reset_index(drop=True), train_df_totals.reset_index(drop=True)], axis=1)\ntr_df = pd.concat([tr_df.reset_index(drop=True), train_df_traffic.reset_index(drop=True)], axis=1)\n\nte_df = pd.concat([test_df_1.reset_index(drop=True), test_df_device.reset_index(drop=True)], axis=1)\nte_df = pd.concat([te_df.reset_index(drop=True), test_df_geo.reset_index(drop=True)], axis=1)\nte_df = pd.concat([te_df.reset_index(drop=True), test_df_totals.reset_index(drop=True)], axis=1)\nte_df = pd.concat([te_df.reset_index(drop=True), test_df_traffic.reset_index(drop=True)], axis=1)\n\n\"\"\"\nNow feature engg. run models and shine on ;)\n\"\"\"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}