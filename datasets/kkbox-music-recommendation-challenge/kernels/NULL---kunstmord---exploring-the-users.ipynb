{"metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3"}}, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "f889398d630b2de6f031bae4a160dc42d8b19912", "_cell_guid": "e2f0684f-ec5f-40e5-bdba-bf7ab58c4075"}, "source": ["A data exploration similar to my \"Exploring the songs\" kernel, but this time focused on user preferences. Not as big as the other kernel due to a lack of time.."]}, {"cell_type": "code", "metadata": {"_uuid": "d260a2b40ed60ea35b9a49d257d2f702f7997c83", "_cell_guid": "5745ead5-b347-4db7-8b98-04cf6dae15e7"}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"], "execution_count": 1}, {"cell_type": "code", "metadata": {"_uuid": "d3432b1e14861e154b9215cbc7aa19fbcdf17455", "_cell_guid": "34724a16-3fe3-4b8f-bae9-920139c07821", "collapsed": true}, "outputs": [], "source": ["train = pd.read_csv('../input/train.csv')\n", "songs = pd.read_csv('../input/songs.csv')\n", "test = pd.read_csv('../input/test.csv')"], "execution_count": 2}, {"cell_type": "markdown", "metadata": {"_uuid": "d6e389a36a7f21ca6c2c45bfdec9d8623ee84948", "_cell_guid": "621aaa6c-aecc-4535-9063-56595a6aa7b0"}, "source": ["Let's start by computing for each the user the number of listened tracks and chance of repeat listen"]}, {"cell_type": "code", "metadata": {"_uuid": "8bc94e14e6c7259f028c79948cf233c70f80fdfb", "_cell_guid": "f5a10d79-b869-40d8-a1f2-af0da780ddce", "collapsed": true}, "outputs": [], "source": ["train = train.merge(songs, on='song_id')\n", "listen_log_groupby = train[['msno', 'target']].groupby(['msno']).agg(['count', 'sum'])\n", "listen_log_groupby.reset_index(inplace=True)\n", "listen_log_groupby.columns = list(map(''.join, listen_log_groupby.columns.values))\n", "\n", "listen_log_groupby.columns = ['msno', 'plays', 'repeat_events']  #rename columns\n", "train = listen_log_groupby.merge(train, on='msno') # merge song data with computed values\n", "train['repeat_play_chance'] = train['repeat_events'] / train['plays']"], "execution_count": 3}, {"cell_type": "code", "metadata": {"_uuid": "3c09a49f5780845415004bd1b0767c46481b8493", "_cell_guid": "75d6752a-2e91-446a-91e1-c9624bd29587"}, "outputs": [], "source": ["print(train['plays'].max())"], "execution_count": 4}, {"cell_type": "markdown", "metadata": {"_uuid": "c008545b8d687f4cabd56bb15524740ff4ae9b4e", "_cell_guid": "1ae27490-52c4-4cdc-aa3c-6a3add42ba5c"}, "source": ["So, someoen has listened to 5819 different tracks.\n", "\n", "What about the general distribution of number of listens and repeat play chance?"]}, {"cell_type": "code", "metadata": {"_uuid": "103261981e6dad9d55f2a496116d45bce83e4ac9", "_cell_guid": "802de5f0-5b6a-46aa-84ea-d7c745f04dca"}, "outputs": [], "source": ["plt.figure(figsize=(15,8))\n", "play_bins = np.linspace(0,train['plays'].max()+1,100)\n", "\n", "sns.distplot(train['plays'], bins=play_bins, kde=False,\n", "             hist_kws={\"alpha\": 1})\n", "plt.xlabel('# of plays')\n", "plt.ylabel('# of users')\n", "# plt.yscale('log')\n", "# plt.xscale('log')"], "execution_count": 5}, {"cell_type": "code", "metadata": {"_uuid": "888b6fc45a59f823a676e32b56b2dcd17bc532d8", "_cell_guid": "b88c3a43-eac2-4365-a236-ab3a5b4b7d50"}, "outputs": [], "source": ["plt.figure(figsize=(15,8))\n", "rplay_bins = np.linspace(0,1.001,100)\n", "\n", "sns.distplot(train['repeat_play_chance'], bins=rplay_bins, kde=False,\n", "             hist_kws={\"alpha\": 1})\n", "plt.xlabel('Chance of repeated listen')\n", "plt.ylabel('# of users')\n", "# plt.yscale('log')\n", "# plt.xscale('log')"], "execution_count": 6}, {"cell_type": "markdown", "metadata": {"_uuid": "7e466c3b97e8de167188ebd602a593a7ac94f8aa", "_cell_guid": "3fe3c384-464a-488d-b9fe-7a5742ba679e"}, "source": ["We see that the number of users with a certain number of listens declines as that number of listens grows, but after roughly 2000 listens, things get more interesting, and we have separate groups of users with a lot of listens, some of them quite large.\n", "\n", "The chance of repeated listen is distributed more or less according to what might be expected; but there's a lot of users with a zero (or near-zero) chance of repeated listen.\n", "\n", "What about the number of songs a user has listened to? How does that affect his chance of repeated listen?"]}, {"cell_type": "code", "metadata": {"_uuid": "68dc0a70806f8f43cfef376380123d964cb305a3", "_cell_guid": "f023b251-2c1d-49bb-93eb-074247b7d663", "collapsed": true}, "outputs": [], "source": ["x_plays = []\n", "y_repeat_chance = []\n", "\n", "for i in range(1,train['plays'].max()+1):\n", "    plays_i = train[train['plays']==i]\n", "    count = plays_i['plays'].sum()\n", "    if count > 0:\n", "        x_plays.append(i)\n", "        y_repeat_chance.append(plays_i['repeat_events'].sum() / count)"], "execution_count": 7}, {"cell_type": "code", "metadata": {"_uuid": "ad319ff120d06f97f939d916ca284dc023d03e2b", "_cell_guid": "7a0aef8a-7e73-4c99-8d02-5c0a8a8b566e"}, "outputs": [], "source": ["f,axarray = plt.subplots(1,1,figsize=(15,10))\n", "plt.xlabel('Number of song plays')\n", "plt.ylabel('Chance of repeat listens')\n", "plt.plot(x_plays, y_repeat_chance)"], "execution_count": 8}, {"cell_type": "markdown", "metadata": {"_uuid": "3683fdd78869b75194f669ca8c38c01417baf1df", "_cell_guid": "31ec1bed-2239-49ee-8c14-a1995acc9ac9"}, "source": ["Not much correlation between # of song plays for a particular user and chance of repeated listen, but for # of song plays less than 200-300 there seems to be a strong decline in the chance of repeated listen.\n", "\n", "Now let's find out how the songs languages are distributed; and how the number of languages a user listens to affects his chance of repeated listen. Also, what about songs that are not sung in the users \"main\" language? Are they more likely to be skipped"]}, {"cell_type": "code", "metadata": {"_uuid": "e41251a4e344d2e8c7bafba2c8f15946904eda64", "_cell_guid": "4d78ad31-eeab-494a-a824-7e7f1d7bf66e", "collapsed": true}, "outputs": [], "source": ["train_basic = train[['msno', 'plays', 'repeat_events', 'repeat_play_chance']].drop_duplicates()\n", "# we create a DF with just the basic info for each user"], "execution_count": 9}, {"cell_type": "code", "metadata": {"_uuid": "f8763c2d112ffcd60d5a30284cb838170904e1e5", "_cell_guid": "2ee77afe-3dfa-4ef5-830d-577efbfe68c8", "collapsed": true}, "outputs": [], "source": ["lang_group = train[['msno', 'language']].groupby(['msno'])\n", "lang_group_nunique = lang_group.agg({\"language\": pd.Series.nunique})\n", "lang_group_mostfreq = lang_group.agg({\"language\": lambda x: x.value_counts().index[0]})\n", "\n", "lang_group_nunique.reset_index(inplace=True)\n", "lang_group_nunique.columns = list(map(''.join, lang_group_nunique.columns.values))\n", "\n", "lang_group_mostfreq.reset_index(inplace=True)\n", "lang_group_mostfreq.columns = list(map(''.join, lang_group_mostfreq.columns.values))\n", "\n", "train_lang_nunique = train_basic.merge(lang_group_nunique, on='msno')"], "execution_count": 10}, {"cell_type": "code", "metadata": {"_uuid": "afba7aa46e241adbd86eee209f97c08ced7fa73e", "_cell_guid": "c4d04077-8959-48a7-8cd4-9697b588a2c7", "collapsed": true}, "outputs": [], "source": ["y_repeat_chance = []\n", "y_plays = []\n", "\n", "for i in range(1,int(lang_group_nunique['language'].max())+1):\n", "    plays_i = train_lang_nunique[train_lang_nunique['language']==i]\n", "    count = plays_i['plays'].sum()\n", "    if count > 0:\n", "        y_plays.append(count)\n", "        y_repeat_chance.append(plays_i['repeat_events'].sum() / count)"], "execution_count": 11}, {"cell_type": "code", "metadata": {"_uuid": "e084ac0c551298725738b84123450c1da34cbd7e", "_cell_guid": "43bce6a3-93fb-4229-ba1f-3908c223adae"}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 14)) \n", "ax1 = plt.subplot(2,1,1)\n", "sns.barplot(x=list(range(1,int(lang_group_nunique['language'].max())+1)),\n", "            y=np.log10(y_plays))\n", "ax1.set_ylabel('log10(# of plays)')\n", "\n", "ax2 = plt.subplot(2,1,2)\n", "sns.barplot(x=list(range(1,int(lang_group_nunique['language'].max())+1)),\n", "            y=y_repeat_chance)\n", "ax2.set_ylabel('Chance of repeated listen')\n", "\n", "ax2.set_xlabel('# Of languages the users listen to')"], "execution_count": 12}, {"cell_type": "markdown", "metadata": {"_uuid": "f332e5ad4f648f1ad6559efbfe51f610afcd7971", "_cell_guid": "35f37237-177a-46d6-bf89-0d321d6e3e1f"}, "source": ["So, most songs are listened to by users who listen to more than 1 language; also, users who listen to less than 4 different languages have a decreased replay chance.\n", "\n", "Now, let's find out how a percentage of the songs the users listens to that are not in his \"main\" language affects the replay chance."]}, {"cell_type": "code", "metadata": {"_uuid": "0a4aac3515a47c1311edb1cd68fae3c3d7020916", "_cell_guid": "d7a03269-d73c-4cf5-8e01-330c0026d4a9"}, "outputs": [], "source": ["lang_group_mostfreq.columns = ['msno', 'main_lang']\n", "train_lang_mostfreq = train.merge(lang_group_mostfreq, on='msno')\n", "train_lang_mostfreq['not_main'] = 0\n", "row_ids = train_lang_mostfreq[train_lang_mostfreq[\"language\"] != train_lang_mostfreq[\"main_lang\"]].index\n", "train_lang_mostfreq['not_main'][row_ids] = 1"], "execution_count": 13}, {"cell_type": "code", "metadata": {"_uuid": "bcaadb4c97dbf8d009c548b88d37dd54d881e314", "_cell_guid": "ed25e15e-772c-4ad4-86e8-2dbf2dda425f", "collapsed": true}, "outputs": [], "source": ["train_lang_mostfreq_gb = train_lang_mostfreq[['msno', 'not_main']].groupby(['msno']).agg(['count', 'sum'])\n", "\n", "train_lang_mostfreq_gb.reset_index(inplace=True)\n", "train_lang_mostfreq_gb.columns = list(map(''.join, train_lang_mostfreq_gb.columns.values))\n", "\n", "train_lang_mostfreq_gb.columns = ['msno', 'plays', 'not_main_plays']  #rename columns\n", "train_lang_mostfreq_gb['not_main_percent'] = train_lang_mostfreq_gb['not_main_plays'] / train_lang_mostfreq_gb['plays']"], "execution_count": 14}, {"cell_type": "code", "metadata": {"_uuid": "89e4c223965f21b3c2975e5663adf2d7de172e2d", "_cell_guid": "0add2141-d324-4642-a4b6-e19881ef9b51", "collapsed": true}, "outputs": [], "source": ["mostfreq_df = train_basic.merge(train_lang_mostfreq_gb[['msno','not_main_percent']], on='msno')"], "execution_count": 15}, {"cell_type": "code", "metadata": {"_uuid": "000fc02e5c3415e944181500c34d2ff636eadaad", "_cell_guid": "83d9e55a-daa2-4f70-a3dd-4dcc412dfeb6"}, "outputs": [], "source": ["rplay_bins = np.linspace(-0.01,mostfreq_df['not_main_percent'].max(),50)\n", "\n", "labels = list(range(rplay_bins.shape[0]-1))\n", "mostfreq_df['cuts'] = pd.cut(mostfreq_df['not_main_percent'],\n", "                                      bins=rplay_bins, labels=labels)\n", "\n", "y_repeat_chance_tc = []\n", "y_plays_tc = []\n", "for i in labels:\n", "    cut_i = mostfreq_df[mostfreq_df['cuts']==i]\n", "    count = cut_i['plays'].sum()\n", "    y_plays_tc.append(count)\n", "    if count != 0:\n", "        y_repeat_chance_tc.append(cut_i['repeat_events'].sum() / count)\n", "    else:\n", "        y_repeat_chance_tc.append(0)\n", "    \n", "fig = plt.figure(figsize=(15, 16)) \n", "\n", "y_plays_tc = [yptc + 1 for yptc in y_plays_tc]  # otherwise we'll get errors when we take the log\n", "\n", "ax211 = plt.subplot(2,1,1)\n", "sns.barplot(x=rplay_bins[labels],y=np.log10(y_plays_tc))\n", "ax211.set_ylabel('log10(# of plays)')\n", "\n", "ax212 = plt.subplot(2,1,2)\n", "sns.barplot(x=rplay_bins[labels],y=y_repeat_chance_tc)\n", "ax212.set_ylabel('Chance of repeated listen')"], "execution_count": 16}, {"cell_type": "markdown", "metadata": {"_uuid": "c73e5aed07ca011152715b68301eeea1657c23ff", "_cell_guid": "f2b37f18-a3ac-412d-b423-a9b42d5847d5"}, "source": ["So the percentage of songs that a user listens to that are not in his \"main\" listening language does not really have a strong influence on both the number of listens and the replay chance \u2013 there is a slight decrease in the replay chance when the percentage of non-main-language songs goes up."]}, {"cell_type": "code", "metadata": {"_uuid": "f0fb743bf7e5f881cefdc4031a72f9eba71e0b69", "_cell_guid": "224477b4-a236-4bf5-954f-4c99ea2e7ba5"}, "outputs": [], "source": ["plt.figure(figsize=(15,8))\n", "rplay_bins = np.linspace(0,mostfreq_df['not_main_percent'].max(),50)\n", "\n", "sns.distplot(mostfreq_df['not_main_percent'], bins=rplay_bins, kde=False,\n", "             hist_kws={\"alpha\": 1})\n", "# plt.yscale('log')\n", "plt.xlabel('Non-main-language song fraction')\n", "plt.ylabel('# of users')\n", "# plt.xscale('log')"], "execution_count": 20}, {"cell_type": "markdown", "metadata": {"_uuid": "d37d9612ccbf6c1bbe7ea74b219c70f7b1c72be6", "_cell_guid": "9af72cfe-3b8a-4fe5-a7b6-42067cc80cf6"}, "source": ["And a there's a lot of users who don't listen to anything but the songs in their one language.\n", "\n", "Now, what about the number of different artists a user listens to? Actually, we'll also look at a second variable -  the # of artists divided by # of total plays by a user, to get a better idea of the variety of number of artists, or rather, how the users listen to music - a person who listens to 100 tracks by 100 different artists surely tends to listen to music in generally different than a person who listens to 2000 tracks by 100 different artists."]}, {"cell_type": "code", "metadata": {"_uuid": "fe8a0445f3939c143025dd8550ed6d0f19982a1c", "_cell_guid": "a4269d65-0308-4960-9d6d-d17b11aca87a", "collapsed": true}, "outputs": [], "source": ["diff_artists = train[['msno', 'artist_name']].groupby(['msno'])\n", "diff_artists = diff_artists.agg({\"artist_name\": pd.Series.nunique})\n", "\n", "diff_artists.reset_index(inplace=True)\n", "diff_artists.columns = ['msno', 'nunique_artists']\n", "\n", "diff_artists = train_basic.merge(diff_artists, on='msno')\n", "diff_artists['n_unique_artists_div_plays'] = diff_artists['nunique_artists'] / diff_artists['plays']"], "execution_count": 21}, {"cell_type": "code", "metadata": {"_uuid": "71102981e00c4582ba491529d018c1f2a29cb921", "_cell_guid": "b47b3289-492e-43a9-872b-f03df28e6d15"}, "outputs": [], "source": ["plt.figure(figsize=(15,16))\n", "rplay_bins = np.linspace(0,1.,100)\n", "rplay_bins2 = np.logspace(0.9,np.log10(diff_artists['nunique_artists'].max()),100)\n", "\n", "\n", "ax211 = plt.subplot(2,1,1)\n", "sns.distplot(diff_artists['n_unique_artists_div_plays'], bins=rplay_bins, kde=False,\n", "             hist_kws={\"alpha\": 1})\n", "\n", "ax211.set_xlabel(\"# of unique artists/ # of user's plays\")\n", "ax211.set_ylabel('# of users')\n", "# ax211.set_yscale('log')  # why isn't this working???\n", "\n", "ax212 = plt.subplot(2,1,2)\n", "\n", "sns.distplot(diff_artists['nunique_artists'], bins=rplay_bins2, kde=False,\n", "             hist_kws={\"alpha\": 1})\n", "\n", "ax212.set_xlabel('# of unique artists')\n", "ax212.set_ylabel('# of users')\n", "# ax212.set_yscale('log')"], "execution_count": 22}, {"cell_type": "markdown", "metadata": {"_uuid": "a4ca15995b92668c1ab3193eebe5ce0f8632e146", "_cell_guid": "c0946477-911c-4bc6-93e2-12c2d7e96b46"}, "source": ["Sidenote: for some reason, setting yscale to log gives an empty plot, unfortuanely complicating the analysis.\n", "\n", "So, a lot of users actually listen to just 1 song by an artist (playlists? radio?).\n", "And most users in general listen to less than 500 artists."]}, {"cell_type": "code", "metadata": {"_uuid": "f173b28653e7239850b56b94140e866db4e970dc", "_cell_guid": "33890c22-870c-4f8a-b6ef-2d84599d3d6b", "collapsed": true}, "outputs": [], "source": ["y_repeat_chance = []\n", "y_plays = []\n", "x_artists = []\n", "\n", "for i in range(1,int(diff_artists['nunique_artists'].max())+1):\n", "    plays_i = diff_artists[diff_artists['nunique_artists']==i]\n", "    count = plays_i['plays'].sum()\n", "    if count > 0:\n", "        x_artists.append(i)\n", "        y_plays.append(count)\n", "        y_repeat_chance.append(plays_i['repeat_events'].sum() / count)"], "execution_count": 23}, {"cell_type": "code", "metadata": {"_uuid": "1ed08a823fec9e00cc32eaf5c7c9f2170c268ea1", "_cell_guid": "f729f3aa-4eec-4bba-99df-e6e41f0d0e15"}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 14)) \n", "ax1 = plt.subplot(2,1,1)\n", "sns.barplot(x=x_artists,\n", "            y=np.log10(y_plays))\n", "ax1.set_ylabel('log10(# of plays)')\n", "\n", "ax2 = plt.subplot(2,1,2)\n", "sns.barplot(x=x_artists,\n", "            y=y_repeat_chance)\n", "ax2.set_ylabel('Chance of repeated listen')\n", "\n", "ax2.set_xlabel('# of unique artists')"], "execution_count": 24}, {"cell_type": "markdown", "metadata": {"_uuid": "9fad921f15dd4a3b1200c017f257169744223436", "_cell_guid": "562e87fd-e392-42f7-9921-d2aa7588d3e9"}, "source": ["The amount of plays is more or less evenly distributed amongst the users with different numbers of unique artists they've listen to; users with small numbers of unique artists have a lower replay chance; as the number of unique artists gets very large, there's a lot of variance."]}, {"cell_type": "code", "metadata": {"_uuid": "bac78847d5c6bba58476d9871d66753639b88f18", "_cell_guid": "4ed19aa2-615a-4694-816f-12dd1be264de"}, "outputs": [], "source": ["rplay_bins = np.linspace(-0.01,1.,100)\n", "\n", "labels = list(range(rplay_bins.shape[0]-1))\n", "diff_artists['cuts'] = pd.cut(diff_artists['n_unique_artists_div_plays'],\n", "                              bins=rplay_bins, labels=labels)\n", "\n", "y_repeat_chance_da = []\n", "y_plays_da = []\n", "for i in labels:\n", "    cut_i = diff_artists[diff_artists['cuts']==i]\n", "    count = cut_i['plays'].sum()\n", "    y_plays_da.append(count)\n", "    if count != 0:\n", "        y_repeat_chance_da.append(cut_i['repeat_events'].sum() / count)\n", "    else:\n", "        y_repeat_chance_da.append(0)\n", "    \n", "fig = plt.figure(figsize=(15, 16)) \n", "\n", "y_plays_da = [ypda + 1 for ypda in y_plays_da]  # otherwise we'll get errors when we take the log\n", "\n", "ax211 = plt.subplot(2,1,1)\n", "sns.barplot(x=rplay_bins[labels],y=np.log10(y_plays_da))\n", "ax211.set_ylabel('log10(# of plays)')\n", "\n", "ax212 = plt.subplot(2,1,2)\n", "sns.barplot(x=rplay_bins[labels],y=y_repeat_chance_da)\n", "ax212.set_xlabel(\"# of unique artists/ # of user's plays\")\n", "ax212.set_ylabel('Chance of repeated listen')"], "execution_count": 25}, {"cell_type": "markdown", "metadata": {"_uuid": "3f3ca41285ed2010105d4fc44569dd6377f27d87", "_cell_guid": "20c44937-dbc1-4e6a-84c1-46f46fb95933"}, "source": ["So, we see that the variable \"# of unique artists / # of user's plays\" has a pretty strong correlation with the chance of a repeated listen - as the users listens to less and less songs by each artist, his replay chances go lower.\n", "Now, let's look at song length \u2013 how does the mean song length and standard deviation of the length of songs a user listens to affect the replay chance for that user?"]}, {"cell_type": "code", "metadata": {"_uuid": "02ee102a887facc1928bff6d199f5d03c585825e", "_cell_guid": "69bbebb6-b056-437f-9a80-9a728de3431a", "collapsed": true}, "outputs": [], "source": ["train['song_length_s'] = train['song_length'] / 1000\n", "sl_gb = train[['msno', 'song_length_s']].groupby(['msno']).agg(['mean', 'std'])\n", "\n", "sl_gb.reset_index(inplace=True)\n", "sl_gb.columns = list(map(''.join, sl_gb.columns.values))\n", "sl_gb.columns = ['msno', 'song_length_s_mean', 'song_length_s_std']  #rename columns\n", "sl_gb = train_basic.merge(sl_gb, on='msno')"], "execution_count": 26}, {"cell_type": "code", "metadata": {"_uuid": "89c9fe843208bd7239ded5084098a730f2620563", "_cell_guid": "8ab2e6e9-97e0-4410-94d5-335e5fc27947"}, "outputs": [], "source": ["slay_bins = np.logspace(np.log10(sl_gb['song_length_s_mean'].min()-1),\n", "                        np.log10(sl_gb['song_length_s_mean'].max()+1),100)\n", "\n", "labels = list(range(slay_bins.shape[0]-1))\n", "sl_gb['cuts_slm'] = pd.cut(sl_gb['song_length_s_mean'],\n", "                           bins=slay_bins, labels=labels)\n", "\n", "y_repeat_chance_sl = []\n", "y_plays_sl = []\n", "y_users_sl = []\n", "for i in labels:\n", "    cut_i = sl_gb[sl_gb['cuts_slm']==i]\n", "    count = cut_i['plays'].sum()\n", "    y_plays_sl.append(count)\n", "    if count != 0:\n", "        y_repeat_chance_sl.append(cut_i['repeat_events'].sum() / count)\n", "    else:\n", "        y_repeat_chance_sl.append(0)\n", "    \n", "fig = plt.figure(figsize=(15, 16)) \n", "\n", "y_plays_sl = [x + 1 for x in y_plays_sl]  # otherwise we'll get errors when we take the log\n", "\n", "ax211 = plt.subplot(2,1,1)\n", "sns.barplot(x=slay_bins[labels],y=np.log10(y_plays_sl))\n", "ax211.set_ylabel('log10(# of plays)')\n", "\n", "ax212 = plt.subplot(2,1,2)\n", "sns.barplot(x=slay_bins[labels],y=y_repeat_chance_sl)\n", "ax212.set_xlabel(\"Mean song length\")\n", "ax212.set_ylabel('Chance of repeated listen')"], "execution_count": 27}, {"cell_type": "markdown", "metadata": {"_uuid": "f64c4460f03caaa2e11bfc10de5c614e11dfb360", "_cell_guid": "bb7be0f3-5a2b-4876-9df6-1ed7b1b8151b"}, "source": ["We see that there is not real influence of the mean song length for a user on the replay chance \u2013 the data gets noisy and more random as we move away from the average song length (3-4 minutes, I guess).\n", "\n", "But what about the standard deviation? If a user listens to 1-second and 1000-second tracks, perhaps he's more open to music and will re-listen to more of what he's offered? Or perhaps the opposite is true?"]}, {"cell_type": "code", "metadata": {"_uuid": "c2efeb2f2d7c72c399ec95f795bbcfb82feec3c5", "_cell_guid": "5a761e93-12e8-4de3-801b-e28f1028ca25"}, "outputs": [], "source": ["slay_bins = np.logspace(np.log10(sl_gb['song_length_s_std'].min()+0.1),\n", "                        np.log10(sl_gb['song_length_s_std'].max()+1),100)\n", "\n", "labels = list(range(slay_bins.shape[0]-1))\n", "sl_gb['cuts_slm'] = pd.cut(sl_gb['song_length_s_std'],\n", "                           bins=slay_bins, labels=labels)\n", "\n", "y_repeat_chance_sl = []\n", "y_plays_sl = []\n", "y_users_sl = []\n", "for i in labels:\n", "    cut_i = sl_gb[sl_gb['cuts_slm']==i]\n", "    count = cut_i['plays'].sum()\n", "    y_plays_sl.append(count)\n", "    if count != 0:\n", "        y_repeat_chance_sl.append(cut_i['repeat_events'].sum() / count)\n", "    else:\n", "        y_repeat_chance_sl.append(0)\n", "    \n", "fig = plt.figure(figsize=(15, 16)) \n", "\n", "y_plays_sl = [x + 1 for x in y_plays_sl]  # otherwise we'll get errors when we take the log\n", "\n", "ax211 = plt.subplot(2,1,1)\n", "sns.barplot(x=slay_bins[labels],y=np.log10(y_plays_sl))\n", "ax211.set_ylabel('log10(# of plays)')\n", "\n", "ax212 = plt.subplot(2,1,2)\n", "sns.barplot(x=slay_bins[labels],y=y_repeat_chance_sl)\n", "ax212.set_xlabel(\"Std of song lengths\")\n", "ax212.set_ylabel('Chance of repeated listen')"], "execution_count": 28}, {"cell_type": "markdown", "metadata": {"_uuid": "6c82d42eca6d57e54db984051a126748f6b41a6e", "_cell_guid": "3542d999-974f-4dde-9ee2-3af5e048bbc3"}, "source": ["So it seems like if the variation in the song lengths increases, so does the replay chance, but this is true not for the whole range of the values of the standard deviation."]}, {"cell_type": "code", "metadata": {"collapsed": true}, "outputs": [], "source": [], "execution_count": null}], "nbformat": 4}