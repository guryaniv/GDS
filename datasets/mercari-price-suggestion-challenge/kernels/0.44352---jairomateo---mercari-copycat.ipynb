{"metadata": {"language_info": {"file_extension": ".py", "version": "3.6.3", "name": "python", "nbconvert_exporter": "python", "mimetype": "text/x-python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "cells": [{"metadata": {"collapsed": true, "_uuid": "4556954894e6951382372a89a3fcf87c098a679b", "_cell_guid": "186c85fa-3519-463a-a8f8-bdcc6b7b2de0"}, "outputs": [], "source": ["import pyximport; pyximport.install()\n", "import gc\n", "import time\n", "import numpy as np\n", "import pandas as pd\n", "from joblib import Parallel, delayed\n", "from scipy.sparse import csr_matrix, hstack\n", "from sklearn.linear_model import Ridge\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.linear_model import SGDRegressor\n", "import lightgbm as lgb\n", "\n", "def rmsle(y, y0):\n", "     assert len(y) == len(y0)\n", "     return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n", "    \n", "def split_cat(text):\n", "    try: return text.split(\"/\")\n", "    except: return (\"No Label\", \"No Label\", \"No Label\")\n", "    \n", "def handle_missing_inplace(dataset):\n", "    dataset['general_cat'].fillna(value='missing', inplace=True)\n", "    dataset['subcat_1'].fillna(value='missing', inplace=True)\n", "    dataset['subcat_2'].fillna(value='missing', inplace=True)\n", "    dataset['brand_name'].fillna(value='missing', inplace=True)\n", "    dataset['item_description'].fillna(value='missing', inplace=True)\n", "\n", "NUM_BRANDS = 4809\n", "NUM_CATEGORIES = 1287\n", "def cutting(dataset):\n", "    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n", "    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n", "    pop_category1 = dataset['general_cat'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n", "    pop_category2 = dataset['subcat_1'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n", "    pop_category3 = dataset['subcat_2'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATEGORIES]\n", "    dataset.loc[~dataset['general_cat'].isin(pop_category1), 'general_cat'] = 'missing'\n", "    dataset.loc[~dataset['subcat_1'].isin(pop_category2), 'subcat_1'] = 'missing'\n", "    dataset.loc[~dataset['subcat_2'].isin(pop_category3), 'subcat_2'] = 'missing'\n", "\n", "def to_categorical(dataset):\n", "    dataset['general_cat'] = dataset['general_cat'].astype('category')\n", "    dataset['subcat_1'] = dataset['subcat_1'].astype('category')\n", "    dataset['subcat_2'] = dataset['subcat_2'].astype('category')\n", "    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "715f2445eae7c1418eb29a9dc34344366ac658e0", "_cell_guid": "54d8b92e-5bdb-4ad2-bff1-2bd47517f346"}, "outputs": [], "source": ["start_time = time.time()\n", "train = pd.read_table('../input/train.tsv', engine='c')\n", "test = pd.read_table('../input/test.tsv', engine='c')\n", "print('[{}] Finished to load data'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "9806454241e990fd8b2b3cc78f90caa8474d5eee", "_cell_guid": "31a4fae1-2843-4d1a-8299-b574812f121c"}, "outputs": [], "source": ["nrow_train = train.shape[0]\n", "y = np.log1p(train[\"price\"])\n", "merge: pd.DataFrame = pd.concat([train, test])\n", "submission: pd.DataFrame = test[['test_id']]"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "9b350c6992baa3eb5a693f5bcdffdf5be788b098", "_cell_guid": "1551830f-d776-4352-9ade-2b5f8ba1c3ab"}, "outputs": [], "source": ["start_time = time.time()\n", "merge['general_cat'], merge['subcat_1'], merge['subcat_2'] = \\\n", "    zip(*merge['category_name'].apply(lambda x: split_cat(x)))\n", "merge.drop('category_name', axis=1, inplace=True)\n", "print('[{}] Split categories completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "eb1462b9062052e2d2d8225a968194c6c60451cf", "_cell_guid": "d586a696-37fe-4412-be32-25ae23bf69b5"}, "outputs": [], "source": ["start_time = time.time()\n", "handle_missing_inplace(merge)\n", "print('[{}] Handle missing completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "dc07175316b3c0876bfb0439f16760dc7666d686", "_cell_guid": "65f80312-0b26-4504-9ffa-eb1e510186da"}, "outputs": [], "source": ["start_time = time.time()\n", "cutting(merge)\n", "print('[{}] Cut completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "96d1c35b10685659a93e6eefe2692eb00277c9eb", "_cell_guid": "9dddcbdc-5f4a-406d-9591-5e281f80ab24"}, "outputs": [], "source": ["start_time = time.time()\n", "to_categorical(merge)\n", "print('[{}] Convert categorical completed'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "7525198ce1f665fb6ac748450f11497a53c88578", "_cell_guid": "54abe24f-52a8-40ca-8002-2b823cdc610d"}, "outputs": [], "source": ["start_time = time.time()\n", "NAME_MIN_DF = 1\n", "cv = CountVectorizer(min_df=NAME_MIN_DF)\n", "X_name = cv.fit_transform(merge['name'])\n", "print('[{}] Count vectorize `name` completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "342e647227ddfb12e50db760b24ef396f4b0d35f", "_cell_guid": "396c1efd-d966-4cd7-bc55-7ad819ee9de9"}, "outputs": [], "source": ["start_time = time.time()\n", "cv = CountVectorizer()\n", "X_category1 = cv.fit_transform(merge['general_cat'])\n", "X_category2 = cv.fit_transform(merge['subcat_1'])\n", "X_category3 = cv.fit_transform(merge['subcat_2'])\n", "print('[{}] Count vectorize `categories` completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "9f81b323f50bb9f7110ef486cdb575d8d3243cba", "_cell_guid": "655ba3d8-9f6a-4ed7-9278-e3a64a74ac76"}, "outputs": [], "source": ["start_time = time.time()\n", "MAX_FEATURES_ITEM_DESCRIPTION = 150\n", "tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n", "                     ngram_range=(1, 3),\n", "                     stop_words='english')\n", "X_description = tv.fit_transform(merge['item_description'])\n", "print('[{}] TFIDF vectorize `item_description` completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "75526ff3573248bc5050f5811f6dd8b0195037c0", "_cell_guid": "92038438-6850-4d85-ba7a-f0f960fc61e7"}, "outputs": [], "source": ["start_time = time.time()\n", "lb = LabelBinarizer(sparse_output=True)\n", "X_brand = lb.fit_transform(merge['brand_name'])\n", "print('[{}] Label binarize `brand_name` completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "8a02cdf6b7ce6dba455677497a417bcfd578ab9e", "_cell_guid": "88eeceb2-c42d-4c33-9907-ea75e095046a"}, "outputs": [], "source": ["start_time = time.time()\n", "X_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n", "                                          sparse=True).values)\n", "print('[{}] Get dummies on `item_condition_id` and `shipping` completed.'.format(time.time() - start_time))    "], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "16ab22fd872ab3360b1d65a30cb3689dc246aa4c", "_cell_guid": "79028a3f-615c-4193-bcac-ee3bdaed7bbb"}, "outputs": [], "source": ["start_time = time.time()\n", "sparse_merge = hstack((X_dummies, X_description, X_brand, X_category1, X_category2, X_category3, X_name)).tocsr()\n", "print('[{}] Create sparse merge completed'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "e46d950951248353e9c13112d442bc30ce4ba3e5", "_cell_guid": "1b9914ca-d0c2-46ff-a02c-043d867f534b"}, "outputs": [], "source": ["start_time = time.time()\n", "X = sparse_merge[:nrow_train]\n", "X_test = sparse_merge[nrow_train:]\n", "model = Ridge(alpha=.05, copy_X=True, fit_intercept=True, max_iter=1000,\n", "    normalize=False, random_state=150, solver='sag', tol=0.0005)\n", "model.fit(X, y)\n", "print('[{}] Train ridge completed'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "3aa172283c495cc2b479bbd675cee2986eb6a228", "_cell_guid": "55ed3a04-09cd-4029-8523-e0e5c79a1caa"}, "outputs": [], "source": ["start_time = time.time()\n", "predsR = model.predict(X=X_test)\n", "print('[{}] Predict ridge completed'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "41afd691f5a6b1a05a05a4887954519067f84389", "_cell_guid": "83c5942f-f2cf-440b-a3ec-fe0a3eb8e411"}, "outputs": [], "source": ["start_time = time.time()\n", "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size = 0.1, random_state = 150) \n", "d_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\n", "d_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\n", "watchlist = [d_train, d_valid]\n", "params = {\n", "        'learning_rate': 0.65,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 60,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 1,\n", "        'bagging_fraction': 1,\n", "        'nthread': 4\n", "}\n", "model = lgb.train(params, train_set=d_train, num_boost_round=8000, valid_sets=watchlist, \\\n", "    early_stopping_rounds=250, verbose_eval=1000) \n", "predsL = model.predict(X_test)\n", "print('[{}] Predict lgb 1 completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "86c9a39aeae1b6693dc2e3fc657800ffebe7f41b", "_cell_guid": "e90b5e9e-610b-486e-8e7b-9408a074ba8e"}, "outputs": [], "source": ["start_time = time.time()\n", "train_X2, valid_X2, train_y2, valid_y2 = train_test_split(X, y, test_size = 0.1, random_state = 101) \n", "d_train2 = lgb.Dataset(train_X2, label=train_y2, max_bin=8192)\n", "d_valid2 = lgb.Dataset(valid_X2, label=valid_y2, max_bin=8192)\n", "watchlist2 = [d_train2, d_valid2]\n", "params2 = {\n", "        'learning_rate': 0.95,\n", "        'application': 'regression',\n", "        'max_depth': 3,\n", "        'num_leaves': 140,\n", "        'verbosity': -1,\n", "        'metric': 'RMSE',\n", "        'data_random_seed': 2,\n", "        'bagging_fraction': 0.5,\n", "        'nthread': 4\n", "}\n", "model = lgb.train(params2, train_set=d_train2, num_boost_round=8000, valid_sets=watchlist2, \\\n", "    early_stopping_rounds=250, verbose_eval=1000) \n", "predsL2 = model.predict(X_test)\n", "print('[{}] Predict lgb 2 completed.'.format(time.time() - start_time))"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "820448cf66b91beb8bbd4eeb9f85ad680b83c9e7", "_cell_guid": "2724cdf0-b75a-4da5-9044-be329ba54139"}, "outputs": [], "source": ["preds = predsR*0.5 + predsL*0.25 + predsL2*0.25\n", "submission['price'] = np.expm1(preds)\n", "submission.to_csv(\"submission_opttry1.csv\", index=False)"], "cell_type": "code", "execution_count": null}, {"metadata": {"collapsed": true, "_uuid": "6051df2981c060d54149183f0ef5ca73a7a7a6d1", "_cell_guid": "0d6a1f42-156e-46f3-80cb-1c8a646c73b5"}, "outputs": [], "source": [], "cell_type": "code", "execution_count": null}], "nbformat": 4, "nbformat_minor": 1}