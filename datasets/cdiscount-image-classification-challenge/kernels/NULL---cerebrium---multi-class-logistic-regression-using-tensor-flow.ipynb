{"cells": [{"source": ["Thank you to inversion, whose [code](https://www.kaggle.com/inversion/processing-bson-files) I have modified for importing BSON files.\n", "\n", "This kernel is to understand how one could structure their data to run it through Tensor Flow. I have only used the train_example.bson data and have not bothered to split the data into train/dev sets as there are only 82 images in this data. This produces very bad results but hopefully you will find it useful!\n", "\n", "PS: This is my first post.\n", "\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "0343b341-2d4d-4334-bf2d-f09c753caca6", "_uuid": "8983b06eb00239d178aea794566c048899011da3"}}, {"execution_count": null, "source": ["import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "import io, bson\n", "import matplotlib.pyplot as plt\n", "from skimage.data import imread   # or, whatever image library you prefer\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "89be1c9d-c6bf-4c23-923d-94a6e7db1e39", "_uuid": "80c1a485637bc5e11c5e1441ae6f0d41e5f8e4f2"}}, {"source": ["The code below will read the BSON files into a pandas dataframe, and then read the category_id that we are trying to predict into a numpy matrix Y, the images that we are using to predict into a matrix X, and the unique ID's into a matrix X_ids."], "cell_type": "markdown", "metadata": {"_cell_guid": "fefd81db-b3a7-4f1f-8668-979736a9b49a", "_uuid": "a697825d6867fa28681cf5219b3b760081d36e49"}}, {"execution_count": null, "source": ["# Simple data processing\n", "data = bson.decode_file_iter(open('../input/train_example.bson', 'rb'))\n", "# read bson file into pandas DataFrame\n", "with open('../input/train_example.bson','rb') as b:\n", "    df = pd.DataFrame(bson.decode_all(b.read()))\n", "\n", "#Get shape of first image \n", "for e, pic in enumerate(df['imgs'][0]):\n", "        picture = imread(io.BytesIO(pic['picture']))\n", "        pix_x,pix_y,rgb = picture.shape\n", "\n", "n = len(df.index) #cols of data in train set\n", "X_ids = np.zeros((n,1)).astype(int)\n", "Y = np.zeros((n,1)).astype(int) #category_id for each row\n", "X_images = np.zeros((n,pix_x,pix_y,rgb)) #m images are 180 by 180 by 3\n", "\n", "print(\"Examples:\", n)\n", "print(\"Dimensions of Y: \",Y.shape)\n", "print(\"Dimensions of X_images: \",X_images.shape)\n", "\n", "# prod_to_category = dict()\n", "i = 0\n", "for c, d in enumerate(data):\n", "    X_ids[i] = d['_id'] \n", "    Y[i] = d['category_id'] \n", "    for e, pic in enumerate(d['imgs']):\n", "        picture = imread(io.BytesIO(pic['picture']))\n", "    X_images[i] = picture #add only the last image \n", "    i+=1\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "79b17760-ecb2-4b6a-8204-61d2149d3f50", "_uuid": "52e0404eab02285be162ea3e1765af29cfc4bd2d"}}, {"execution_count": null, "source": ["#Lets take a look at the category names supplied to us:\n", "df_categories = pd.read_csv('../input/category_names.csv', index_col='category_id')\n", "\n", "count_unique_cats = len(df_categories.index)\n", "\n", "print(\"There are \", count_unique_cats, \" unique categories to predict. E.g.\")\n", "print(\"\")\n", "print(df_categories.head())"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "8ce694b6-afb9-4a0d-8e0b-4725c74df85b", "_uuid": "f35fc13789dd8540efc8eca9f1acfc1ad91ba511"}}, {"source": ["There are 5270 unique categories. You can use the code below to take a look at some of the images and their respective categories."], "cell_type": "markdown", "metadata": {"_cell_guid": "3b9983f4-1dae-4872-864e-5874c099f28f", "_uuid": "3f1139746cfb260093875a301c4b8aeb74bfca76"}}, {"execution_count": null, "source": ["#Function to return the category description from df_categories\n", "def get_category(category_id,level):\n", "    if(level in range(1,4)):\n", "        try:\n", "            return df_categories.iloc[df_categories.index == category_id[0],level-1].values[0]\n", "        except:\n", "            print(\"Error - category_id does not exist\")\n", "    else:\n", "        print(\"Error - level must be between 1 - 3\")\n", "\n", "#Play around with the index and cat levels to explore the images in the test data set\n", "index = 3\n", "cat_desc_level = 1 # level 1 - 3\n", "print(\"ID: \",X_ids[index][0], \"category_id: \",Y[index][0], \"category_description: \",get_category(Y[index],cat_desc_level))\n", "plt.imshow(X_images[index])"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "50fd725e-690f-43a6-b257-7b93100be22f", "_uuid": "308dfcec913b1da759201eace06f4e425cdcc591"}}, {"source": ["We will now encode the category_id labels into \"one-hot vectors\". A one hot vector is 0 in all except one dimension where it is 1. For example in the [MNST](https://www.tensorflow.org/get_started/mnist/beginners) data set a value of 3 would be [0,0,0,1,0,0,0,0,0,0]."], "cell_type": "markdown", "metadata": {"_cell_guid": "db8e5ad1-3257-4f83-b2a6-67312c27d496", "_uuid": "3e4d25488efe809404cce03ddf891f912789d783"}}, {"execution_count": null, "source": ["from sklearn import preprocessing\n", "import warnings\n", "\n", "warnings.filterwarnings(\"ignore\") \n", "\n", "#full list of classes\n", "category_classes = df_categories.index.values\n", "category_classes = category_classes.reshape(category_classes.shape[0],1)\n", "\n", "#using a label encoder, and binarizer to convert all unique category_ids to have a column for each class \n", "le = preprocessing.LabelEncoder() \n", "lb = preprocessing.LabelBinarizer()\n", "\n", "le.fit(df_categories.index.values)\n", "y_encoded = le.transform(Y)\n", "\n", "lb.fit(y_encoded)\n", "Y_flat = lb.transform(y_encoded)\n", "\n", "#redimension X for our model\n", "X_flat = X_images.reshape(X_images.shape[0], -1)\n", "Y_flat = Y_flat\n", "m = X_flat.shape[1]\n", "n = Y_flat.shape[1]\n", "\n", "#Scale RGB data for learning\n", "X_flat = X_flat/255\n", "#print results\n", "print(\"X Shape =\", X_flat.shape, \"Y Shape =\",Y_flat.shape, \"m = \",m, \"n classes found in test data=\", n)\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "2b0563d1-672d-45e0-8976-120e4a3ddded", "_uuid": "eceef4cb1ebb3768d7b4c4fd8e742ad1b0ef1cb7"}}, {"source": ["Below is a simple implementation of logistic regression on the small training set data using tensor flow. For those who are not familiar with tensor flow, their [documentaion](https://www.tensorflow.org/get_started/mnist/beginners) is a good place to start. The results of this is not meant to be meaningful - it is just illustrative of how one might get started with Tensor Flow."], "cell_type": "markdown", "metadata": {"_cell_guid": "cb842471-3c96-453d-a88a-591a7ff160ed", "_uuid": "1099f86782b2c56d82b8a432d577ddafd83b558a"}}, {"execution_count": null, "source": ["import tensorflow as tf\n", "\n", "#set up params\n", "sess = tf.Session()\n", "seed = 2\n", "tf.set_random_seed(2)\n", "batch_size = 100\n", "LEARNING_RATE = 1e-4\n", "\n", "##nn with one layer\n", "#set up some placeholders which we will feed data into\n", "x = tf.placeholder(tf.float32, [None, m])\n", "y_ = tf.placeholder(tf.float32, [None, n])\n", "\n", "#set up a simple network - make sure the dimensions for W and b match\n", "W = tf.Variable(tf.zeros([m, n]))\n", "b = tf.Variable(tf.zeros([n]))\n", "#let Y = Wx + b with a softmax activiation function\n", "y = tf.nn.softmax(tf.matmul(x, W) + b)\n", "\n", "#setup the minimisation pronlem with gradient descent\n", "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n", "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n", "\n", "#Start a session and run\n", "sess = tf.InteractiveSession()\n", "tf.global_variables_initializer().run()\n", "sess.run(train_step, feed_dict={x: X_flat, y_: Y_flat})\n", "\n", "#have a look at the results\n", "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n", "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n", "\n", "#print results\n", "print(sess.run(accuracy, feed_dict={x: X_flat, y_: Y_flat}))\n", "\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "d6e0dfd0-e1fa-4d17-9804-1b017991dc31", "_uuid": "21217786d7734b0962f374fd48906595cb54bf59"}}, {"source": ["Hope that helps! Leave comments below. I am still learning so I will answer them if I know."], "cell_type": "markdown", "metadata": {"_cell_guid": "0987f89c-a156-4974-b9fd-84b7eb2e2c54", "_uuid": "88b58d94ceb8de4d8cbf2b5950c88b1b0c2349d7"}}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.1"}, "kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}