{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0124cb09-c83f-e2bf-275b-a7bd184729b9"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ff68b019-d6e1-77f1-c206-593b11736f6f"
      },
      "outputs": [],
      "source": [
        "# Data Acquision\n",
        "def DataAq():\n",
        "    train = pd.read_csv(\"../input/train.csv\")\n",
        "    test = pd.read_csv(\"../input/test.csv\")\n",
        "    return train,test# Data Acquision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bcfb805e-1ffc-3428-8133-a526e9572977"
      },
      "outputs": [],
      "source": [
        "# Isolate the price from the data\n",
        "def separate_price(train):\n",
        "    target=train['price_doc']\n",
        "    train.drop('price_doc',inplace=True,axis=1)\n",
        "    return target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36d78829-47a0-b34c-337e-40aa904bef45"
      },
      "outputs": [],
      "source": [
        "# Replace the nan with the mean\n",
        "def replace_nan_mean(feature):\n",
        "    global combined\n",
        "    combined[feature].fillna(combined[feature].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8e41057-8338-caae-f9fd-11fd56c1aa99"
      },
      "outputs": [],
      "source": [
        "# concatanate train and tests datasets into one dataset -> combined\n",
        "def get_combined_data(train,test):\n",
        "    global combined\n",
        "    combined = train.append(test)\n",
        "    combined.reset_index(inplace=True)\n",
        "    combined.drop('index',inplace=True,axis=1)\n",
        "    print (combined.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3d1100b-ed03-d393-bdae-7148d6796dde"
      },
      "outputs": [],
      "source": [
        "# Create dummies for non-numerical features\n",
        "def p_generic(feature):\n",
        "    global combined\n",
        "    print (\"Histogram of \" +feature)\n",
        "    print (combined[feature].value_counts())\n",
        "    feature_dummies=pd.get_dummies(combined[feature],prefix=feature)\n",
        "    combined=pd.concat([combined,feature_dummies],axis=1)\n",
        "    combined.drop(feature,axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6efa29a-1fb7-a710-dfce-da6730f1f7aa"
      },
      "outputs": [],
      "source": [
        "# If nan perceptage of a feature is above 25% then drop this feature\n",
        "def check_nan_percentage(feature):\n",
        "    #print ((combined[feature].isnull().sum())/len(combined[feature]))\n",
        "    if (combined[feature].isnull().sum())/len(combined[feature]) > 0.25:\n",
        "        print (feature,\"out\")\n",
        "        combined[feature].drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "32c0e37c-a360-8881-96d8-e2361cceac7b"
      },
      "outputs": [],
      "source": [
        "# If a feature is not numerical call p_generic for it (to make dummies)\n",
        "def find_categoricals_and_make_dummies(feature):\n",
        "    if (combined[feature].dtypes==object):\n",
        "        print ('Categorical feature:',feature)\n",
        "        p_generic(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8de53f7-7109-888e-36e1-535ebeb6a079"
      },
      "outputs": [],
      "source": [
        "# Change the date, keeping just the year\n",
        "def change_date_format():\n",
        "    combined['timestamp'] = pd.DatetimeIndex(combined['timestamp']).year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5237cd98-b0af-297b-0032-5d25685aee5b"
      },
      "outputs": [],
      "source": [
        "# Scale all features\n",
        "def scale_all_features():\n",
        "    \n",
        "    global combined\n",
        "    \n",
        "    features = list(combined.columns)\n",
        "    #features.remove('PassengerId')\n",
        "    combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)\n",
        "    \n",
        "    print ('Features scaled successfully !')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ae177933-3afb-48e5-c599-89beae1d2423"
      },
      "outputs": [],
      "source": [
        "# Recover train, test data from global data\n",
        "def recover_train_test_target():\n",
        "    global combined\n",
        "    \n",
        "    train = combined.ix[0:30470]\n",
        "    test = combined.ix[30471:]\n",
        "    \n",
        "    return train,test   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa6856e8-03d6-959a-bbd2-3e4bb1c9101b"
      },
      "outputs": [],
      "source": [
        "# grid search with cross-validation\n",
        "def HT(targets,train_new, algorithm, parameters):\n",
        "    c_v=StratifiedKFold(n_splits=5)\n",
        "    c_v=c_v.get_n_splits(train_new, targets)\n",
        "    scorer=make_scorer(mean_squared_error)\n",
        "    grid_search = GridSearchCV(algorithm, param_grid=parameters, scoring=scorer, cv=c_v)\n",
        "\n",
        "    grid_fit=grid_search.fit(train_new, targets.ravel())\n",
        "    print (\"Results for {}\".format(algorithm))\n",
        "    print (algorithm.__class__.__name__)\n",
        "    print('Best score: {}'.format(grid_fit.best_score_))\n",
        "    print('Best parameters: {}'.format(grid_fit.best_params_))\n",
        "    pipeline=grid_search\n",
        "    return pipeline.best_estimator_ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c975bde2-3f8a-4cba-2ac8-21e4d3afac06"
      },
      "outputs": [],
      "source": [
        "train,test=DataAq()\n",
        "target=np.log(separate_price(train))\n",
        "get_combined_data(train,test)\n",
        "change_date_format()\n",
        "for x in combined.columns:    \n",
        "    check_nan_percentage(x)\n",
        "for x in combined.columns:    \n",
        "    find_categoricals_and_make_dummies(x)\n",
        "\n",
        "for x in combined.columns:     \n",
        "    replace_nan_mean(x)\n",
        "    \n",
        "scale_all_features()\n",
        "r_train,r_test=recover_train_test_target()\n",
        "reg_C=RandomForestRegressor()\n",
        "reg_C_parameters={'n_estimators': [500], 'max_features':['sqrt']}   \n",
        "pipeline3 = HT(target,r_train, reg_C, reg_C_parameters)\n",
        "output3= np.exp(pipeline3.predict(r_test))\n",
        "print (output3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e5343325-1a70-0263-3862-b0ce30b74af0"
      },
      "source": [
        "It seems to be a big difference between the score obtain here 0.23 and the score on the LeaderBoard 0.35. I am a newbie in this field :) , If you have any suggestion for improvement I am happy to hear them for improving myself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c78cb8b3-9ef2-fa07-aeac-161cdb7b1ed4"
      },
      "source": [
        "Thanks for reading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "48f8ef11-efa9-7ac7-fd8a-75dd1b4ae3ab"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}