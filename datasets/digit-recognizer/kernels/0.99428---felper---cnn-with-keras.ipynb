{"cells":[{"metadata":{"_uuid":"fadb17358b25580ab1e24074eac491b4886d2f45"},"cell_type":"markdown","source":"# Keras MNIST\n\n## Introduction\n\nIn this kernel, we implement a Convolutional Neural Network (CNN) model with Keras using the TensorFlow backend. We use the dataset from the Digit Recognizer competition of Kaggle (see [here](https://www.kaggle.com/c/digit-recognizer)).\n\nWe will use a VGG-like architecture for our neural network, this is, it will consist of a series of convolutional, followed by fully connected layers. We will also add pooling and dropout layers to decrease the number of parameters and to regularize the model."},{"metadata":{"_uuid":"99fa32a7736011f238c27d7e179b9b4b590211ca"},"cell_type":"markdown","source":"## Getting started\n\nWe start by importing the necessary modules:"},{"metadata":{"trusted":true,"_uuid":"ef7e585d5248492b35d7bd714128902c726ce1b2"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nfrom scipy.misc import toimage\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"39c12772797936dc3f101102e29b70d1b2d16df3"},"cell_type":"markdown","source":"We import the dataset into pandas dataframes"},{"metadata":{"trusted":true,"_uuid":"fb4e648788adf3b1a084666a40f04eb3f9529dde"},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/train.csv\", encoding = 'ISO-8859-1')\ndf_subm =  pd.read_csv(\"../input/test.csv\", encoding = 'ISO-8859-1')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3712b51fe32acf4f2079fdbf093714c226272ab4"},"cell_type":"markdown","source":"We check that there is no missing data:"},{"metadata":{"trusted":true,"_uuid":"42f615deb3500f3323e0d2d59aed4882e6588b7b"},"cell_type":"code","source":"df_train.isnull().sum().sum() , df_subm.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4330ca55acffdb494ea24afd32d6563a7771b100"},"cell_type":"markdown","source":"There is in fact, no missing data. We now take a look at the dataframes to see their structure:"},{"metadata":{"trusted":true,"_uuid":"8dd176b6b5b679f670c4aff9263294ed0adb520d"},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7fad32dd28dde16ca6970470f9210b25bc70e2b"},"cell_type":"code","source":"df_subm.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"30dbc7af0620ec06bfaa43d60cd696a4a053fa81"},"cell_type":"markdown","source":"We can see that the training data consists of 785 columns, from which the first one corresponds to the label of the digit, and the other 784 correspond to all the 28x28 pixels composing each image. The submission dataframe does not contain the label, as expected. We proceed to extract the labels from the dataframe."},{"metadata":{"trusted":true,"_uuid":"7006f9b74738038bff5f1eb31d634356895d7c8d"},"cell_type":"code","source":"X_train = df_train[df_train.columns[1:]]\ny_train = df_train['label']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"80b7b8721be914768400d0b5b0bffb90f24b1237"},"cell_type":"markdown","source":"We now use the train_test_split tool from sklearn to separate our training data into two batches: one that we will use to train our neural network, and one that we will use to evaluate the scores."},{"metadata":{"trusted":true,"_uuid":"2e3db9a4eb5de7335d7412b083aca9f298dd8adb"},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4e6771c8a4ea8bed2c2066aa0e23c0bc44c942f"},"cell_type":"markdown","source":"Now we use the to_categorical tool from Keras to one-hot-encode the labels of our dataset. This is, for each possible value of the labels, we create a column, and the column corresponding to the label has a 1, while the others have a 0."},{"metadata":{"trusted":true,"_uuid":"d6fb7d1ec8ec14612e7e9573623f10ffc371cb9f"},"cell_type":"code","source":"y_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b71ed2443a63175c908e73c55e6d4bfa475448f"},"cell_type":"markdown","source":"Now that the dataset has the appropriate format, we can have a look at how the images look like:"},{"metadata":{"trusted":true,"_uuid":"74ab7adfc7b690887e89f9257fc6b2289d7a695a"},"cell_type":"code","source":"for i in range(0, 9):\n    plt.subplot(330 + 1 + i)\n    plt.imshow((X_train.iloc[i].values.reshape(28,28)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c272739270ffffe668aa3e9c8a2138400372e3d"},"cell_type":"markdown","source":"Now we convert the dataframe into a 4 dimensional tensor. The first dimension runs through the set of examples, the second and third correspond to the two dimensions of the image and the fourth dimension correspond to the each channel of the picture (for RGB images we need three channels while for grayscale we only need one channel)."},{"metadata":{"trusted":false,"_uuid":"4bbf10495010b7761c839f418590ab1b991dcc3e"},"cell_type":"code","source":"X_train = X_train.values.reshape(X_train.shape[0],28,28,1)\nX_test = X_test.values.reshape(X_test.shape[0],28,28,1)\n# X_train = X_train.values.reshape(df_train.shape[0],28,28)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aebf26f5af27f73c2db57d0e776303b5aa9c6830"},"cell_type":"markdown","source":"We compute now the range of values that the data takes, so we can properly normalize:"},{"metadata":{"trusted":false,"_uuid":"37be1df5d09f309f39c4a285aa16f1dd147b6cde"},"cell_type":"code","source":"X_train.max() - X_train.min() ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95a02d2254d55d34deb8a63dc6ad776a442ed2cc"},"cell_type":"markdown","source":"Now we can normalize:"},{"metadata":{"trusted":false,"_uuid":"0d6f3a3bb2d1f642934b3033b66310a3c77f0d57"},"cell_type":"code","source":"X_train = X_train/255\nX_test = X_test/255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab4caa4de1c1ff5d1217102e909ba810e2b9940d"},"cell_type":"markdown","source":"We are now ready to build our model."},{"metadata":{"_uuid":"a3f6748842a9cba7d433012c240951a2e2248c9d"},"cell_type":"markdown","source":"## CNN: the sequential model"},{"metadata":{"_uuid":"1fdcff30f5bd1efcc26049017cc9a3942871ad18"},"cell_type":"markdown","source":"Keras makes the construction of deep neural networks much easier than Tensorflow. For this, we just need to build a sequential model, and add each layer sequentially (as the name suggests), keeping in mind that the dimensions of the output of each layer must coincide with the dimensions of the input of the next layer. \n\nThe architecture of the CNN is based on the VGG-like convolutional neural network provided by the Keras documentation (see [here](https://keras.io/getting-started/sequential-model-guide/#examples)).\n\nWe start by building the sequential model."},{"metadata":{"trusted":false,"_uuid":"e7b2d64383ca633ca1f94d49cc92822a087033a9"},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a96f9073f1f2a72f815a4e3b77a0e0a41ff29e9a"},"cell_type":"markdown","source":"Now we add two groups of layers consisting of convolutions, maxpooling and dropout layers:"},{"metadata":{"trusted":false,"_uuid":"40b3bd9e31638ac416001b8d5aeaf44d7f201d98"},"cell_type":"code","source":"model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7301ff20ca7c50d08b04700593dc05f3b320f6b8"},"cell_type":"markdown","source":"We follow this by two fully connected (dense) layers, with another dropout layer."},{"metadata":{"trusted":false,"_uuid":"cf68f7739cd051e51796a95c4683f24db8667159"},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3f13a3f5ee24bcbfb7cd664000d6b6551e96dd6"},"cell_type":"markdown","source":"This finishes the architecture of the CNN. Now we choose an optimizer to train the model. We choose Stochastic Gradient Descent (SGD) with decay, momentum and Nesterov momentum for this."},{"metadata":{"trusted":false,"_uuid":"477e6ac15da84b865aedffd4703835aeb5c5007d"},"cell_type":"code","source":"sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a96e63b9eda79c46cf5bbf2b774d05f0e9a2fda4"},"cell_type":"markdown","source":"Finally, we compile the model. We will use the categorical cross entropy as a loss function, and we will measure scores with the accuracy."},{"metadata":{"trusted":false,"_uuid":"61be30fc94ffc2d4436c83804da866a5b6172677"},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42fd5f89410d8504015f48c93b2465ce88348b89"},"cell_type":"markdown","source":"We print a summary of the model."},{"metadata":{"trusted":false,"_uuid":"ff9249ef3d87647f78af863104749231259a390b"},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3efcd9734c2be08e4e6d127c849969cc9e71bf32"},"cell_type":"markdown","source":"We are ready to train the model. We have commented this line as we will use a slightly modified version of this."},{"metadata":{"trusted":false,"_uuid":"602144160a5937fe8f92fbb3e71a001cc4487c13"},"cell_type":"code","source":"# model.fit(X_train, y_train, batch_size=128, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b491a056c8896c3eae83b15b98479813410ec4f9"},"cell_type":"markdown","source":"We can compute the score of the model on the test dataset:"},{"metadata":{"trusted":false,"_uuid":"041867472c064cfaa7a40c7cc24315f2d6a33ed2"},"cell_type":"code","source":"# score = model.evaluate(X_test, y_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c099b064dd6a13424a61d0f7e2a27dd83821c6e8"},"cell_type":"markdown","source":"With this model, we can obtain scores of around 0.988 on the submission data. We can improve this to get even higher scores."},{"metadata":{"_uuid":"d97553fdd16102403e87ccb3fb9fb5da26979221"},"cell_type":"markdown","source":"## Data augmentation\n\nIn this section, we perform what is called Data Augmentation. This procedure consists of generating more data with our available dataset. The way we do this is by applying several transformations to our dataset. This is a widely used technique. For this, we will use the ImageDataGenerator tool from Keras."},{"metadata":{"_uuid":"d9585dac6f0b07abbb70990e7b266f8119d92a4d"},"cell_type":"markdown","source":"We start by building the object that will randomly generate such transformations:"},{"metadata":{"trusted":false,"_uuid":"b22f25cbb57f30268d7ad7edd34f244d7ed16968"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d87b32f18d4ce3457ef8026fced0f37addd7377b"},"cell_type":"markdown","source":"Here the parameters indicate that the pictures will be rotated in a random angle between -10,10 degrees, and a vertical and horizontal shift will be applied. In this way, we will count with a much more diverse dataset which will allow our model to learn better parameters for predicting in test datasets. We now fit the data generator to our training dataset."},{"metadata":{"trusted":false,"_uuid":"ad14bc19931f4b3038c50659b1e5b57f1af4d7ea"},"cell_type":"code","source":"datagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7ca96a08b7ce1f4cd1150070d0e301d0c618b4e8"},"cell_type":"markdown","source":"Finally, we generate the data and fit the model with the augmented data:"},{"metadata":{"trusted":false,"_uuid":"321cf7670bbfaa7991647f80b8528bf14c9b339f"},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n                    steps_per_epoch=int(len(X_train) / 128), epochs=30)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"051021ce8aca380dc3921f3fb01ab699d582e42b"},"cell_type":"markdown","source":"And now we evaluate the model on the test data:"},{"metadata":{"trusted":false,"_uuid":"659e4a9e7bc5c2ceb78398456d7d039e591473b8"},"cell_type":"code","source":"# model.evaluate(X_test, y_test, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a86e7eb15f9a21cc7a687dad7503ad65eddbf06"},"cell_type":"markdown","source":"We can check how is the model performing with the confusion matrix tool of Sklearn. This will show which numbers are being mislabeled."},{"metadata":{"trusted":false,"_uuid":"2c12a76bcd0d31f0f566dd71bb2fe764e5f31cc4"},"cell_type":"code","source":"# confusion_matrix(np.argmax(y_test,axis=1,out=None),np.argmax(model.predict(X_test), axis=1, out=None))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8544e15d72a4831f1c2f70a0a0c61089f1c560ca"},"cell_type":"markdown","source":"We can observe that the major source of errors are 4's being labeled as 9 and vice versa. This is mostly due to how some people draw these numbers in a very similar way. Finally, we can measure the accuracy of the model with the Sklearn accuracy tool:"},{"metadata":{"trusted":false,"_uuid":"3842fcd2b17cae7aa87744cf2fd996e976ae0d4c"},"cell_type":"code","source":"# accuracy_score(np.argmax(y_test,axis=1,out=None),np.argmax(model.predict(X_test), axis=1, out=None))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e410ac42e817e33b75f059d9158a0dcbdc39ab4c"},"cell_type":"markdown","source":"## Submission \n\nNow we can proceed to generate the submission data. For this, we will use the same formatting as we used in the first part of the kernel. "},{"metadata":{"trusted":false,"_uuid":"b299f0e84e621ea344eede47808de59c1eb7b647"},"cell_type":"code","source":"#We put the values of the submission data in a matrix\ntest_data = df_subm.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a9d55524b9227b29d04d84847adb584b093acbf2"},"cell_type":"code","source":"#We reshape the matrix as a 4 dimensional tensor\ntest_data = test_data.reshape(test_data.shape[0],28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"062bb3d63bb13ed65fe29098ba648be4b2385fcb"},"cell_type":"code","source":"#We normalize the data with the same factor as we did for the train data\ntest_data = test_data/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e18d264f1fe3d69f0fc446e449279a30e2982c61"},"cell_type":"code","source":"#We use the model to generate the predictions\npredictions = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c773e61b30019dda1476958a9ae6b54082b784f2"},"cell_type":"code","source":"#We get the labels of the predictions, recalling that we used a one-hot-encoding \n#to train the model\npredictions = np.argmax(predictions, axis=1, out=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f4097cd72bba0e7c00a3218cc785cb98b8f7f373"},"cell_type":"code","source":"#We generate a csv file with the predictions in the required format\nwith open(\"resultCNNwithPrepros.csv\", \"wb\") as f:\n    f.write(b'ImageId,Label\\n')\n    np.savetxt(f, np.hstack([(np.array(range(28000))+1).reshape(-1,1), predictions.astype(int).reshape(-1,1)]), fmt='%i', delimiter=\",\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd2b94ff4a700e42704af6143dca1e0cac41530b"},"cell_type":"markdown","source":"## Conclusion\n\nThis concludes this kernel. We believe that there is still room for improvement, either by optimizing over the architecture of the model or the hyperparameters."},{"metadata":{"trusted":false,"_uuid":"048f9b3080704f2fd8f452db99152bb4eba156f8"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}