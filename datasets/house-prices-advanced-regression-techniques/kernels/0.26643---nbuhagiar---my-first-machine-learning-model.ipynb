{"cells":[{"metadata":{"_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86","_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nYou will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n\nThe data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n\nCome to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n\n# Write Your Code Below\n\n"},{"metadata":{"_uuid":"f5d378a8807be9a978a87a8e1f5db7e2118b5506"},"cell_type":"markdown","source":"## Level 1"},{"metadata":{"_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","_uuid":"1c728098629e1301643443b1341556a15c089b2b","trusted":true},"cell_type":"code","source":"# Read the data and print the summary\n\nimport pandas as pd\n\nmain_file_path = '../input/train.csv'\ndata = pd.read_csv(main_file_path)\nprint(data.describe())","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"b9d249e5-be73-4604-80d3-b763713b7f0d","_uuid":"58ccbbd7e9d45c14322fc32eb8434a3d68ffc4a3","trusted":true},"cell_type":"code","source":"# Print a list of the columns\n\nprint(data.columns)","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"cce8d674-4086-46fb-a9c6-b6eccd4bd269","_uuid":"3e03b57117890b64cbac7d7019757197ec44726c","collapsed":true,"trusted":true},"cell_type":"code","source":"# Extract sales prices from data\n\ndata_price = data.SalePrice","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"a5ba1a37-3eaa-4468-a070-d8d82e757557","_uuid":"8af1bb4effbbb3775970ecba0be3e3915b371571","trusted":true},"cell_type":"code","source":"# Print top few lines of sales price data\n\nprint(data_price.head())","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"e5868aeb-f8a0-44fe-b33c-67a238598502","_uuid":"bb048586bac78b7937e9d13d88b324d1d16756a1","collapsed":true,"trusted":true},"cell_type":"code","source":"# Store KitchenAbvGr and Fireplaces features into new dataframe\n\ndata_misc = data[[\"KitchenAbvGr\", \"Fireplaces\"]]","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"49820dbd-1fa4-4eee-88a7-278cc8affa27","_uuid":"5752ea9b72a549823c0479c3123dceb00db5b99f","trusted":true},"cell_type":"code","source":"# Observe summaries of these kitchen features\n\ndata_misc.describe()","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"cae891e5-f393-40e6-aafa-b097def23137","_uuid":"e3923892a56a662afd3dd6f4f7e179349d4d9aaf","collapsed":true,"trusted":true},"cell_type":"code","source":"# Identify target variable\n\ny = data_price","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"b2f69e8c-db6f-4ed8-a0f6-8ed2e7daf3ca","_uuid":"a085b5a87013e06115b025b1abfc1d1a9e764937","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create a list of predictors\n\npredictors = [\"LotArea\", \n              \"YearBuilt\", \n              \"1stFlrSF\", \n              \"2ndFlrSF\", \n              \"FullBath\", \n              \"BedroomAbvGr\", \n              \"TotRmsAbvGrd\"]","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"c4c2b1a8-07fa-4e3f-a43c-7db301539a99","_uuid":"e7cbd1184e74604e3d0c56c535eba60fb4195245","collapsed":true,"trusted":true},"cell_type":"code","source":"# Create a new dataframe consisting of predictors' data\n\nX = data[predictors]","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"4a6df71e-8310-412f-ac52-86d59175882a","_uuid":"76496c793950287594b11c9e85a49b1e6ebd931a","collapsed":true,"trusted":true},"cell_type":"code","source":"# Instantiate decision tree regressor object\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nmodel = DecisionTreeRegressor()","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"4abf9b6d-7309-4552-9e19-5aaee811c6e9","_uuid":"89389159c6bcb8fb4d85c71df6155b42e9bfbcde","trusted":true},"cell_type":"code","source":"# Fit model to training data\n\nmodel.fit(X, y)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"6f42aca9-3fc7-46b7-9af5-43929c4a4e83","_uuid":"8c5e50b9a9812b37c11b84c52fefc8511169941f","trusted":true},"cell_type":"code","source":"# Make a few predictions with the model\n\nmodel.predict(X.head())","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"490e6080-d252-4b56-a3f8-29e8bd4f2879","_uuid":"874eb0489c9976387d742fed508d8b437d62c9f4","collapsed":true,"trusted":true},"cell_type":"code","source":"# Split dataset into train and dev sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_dev, y_train, y_dev = train_test_split(X, y, random_state=0)","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"b334b04a-4396-46d8-bac5-e0560ffb96a4","_uuid":"f0a2d9e7e7666a1e3a4f75142c2b91ce79efd302","trusted":true},"cell_type":"code","source":"# Fit new model with training data\n\nmodel = DecisionTreeRegressor()\nmodel.fit(X_train, y_train)","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"ce8e4862-48f2-4d3c-b088-9f6a4cfbed81","_uuid":"e89a21a5197c141f8f2be0e15a017c620dea76e5","collapsed":true,"trusted":true},"cell_type":"code","source":"# Make predictions using the model on the dev set\n\ndev_predictions = model.predict(X_dev)","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"b35ab388-e94a-4023-9777-07e3b39bf470","_uuid":"c1b774f4edaaa8876b84f2d5cc368b091a76d59c","trusted":true},"cell_type":"code","source":"# Calculate model mean absolute error (MAE) on dev set\n\nfrom sklearn.metrics import mean_absolute_error\n\nprint(mean_absolute_error(y_dev, dev_predictions))","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"27b316c9-b837-4d89-ae59-a776f30065b9","_uuid":"77c0b991031abca7e1d32aabc851a8f34ad89ead","collapsed":true,"trusted":true},"cell_type":"code","source":"# Define function to get MAE of model with given parameters\n\ndef get_mae(max_leaf_nodes, predictors_train, predictors_val, targ_train, targ_val):\n    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n    model.fit(predictors_train, targ_train)\n    preds_val = model.predict(predictors_val)\n    mae = mean_absolute_error(targ_val, preds_val)\n    return(mae)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"c02a5684-d063-452f-bda3-4b0555b8b9eb","_uuid":"0ec65ca51455cc907478d2d931484970c9d5ed08","trusted":true},"cell_type":"code","source":"# Approximate ideal number of max_leaf_nodes for model\n\nimport sys\n\nbest_mae = sys.maxsize \nideal_max_leaf_nodes = None\n\nfor max_leaf_nodes in [5, 50, 500, 5000]:\n    mae = get_mae(max_leaf_nodes, X_train, X_dev, y_train, y_dev)\n    if mae < best_mae:\n        best_mae = mae\n        ideal_max_leaf_nodes = max_leaf_nodes\n\nprint(\"The lowest MAE of {} was found with a \"\n      \"decision tree with {} max leaf nodes.\".format(best_mae, \n                                                    ideal_max_leaf_nodes))","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"2f0195cc-e074-4743-be69-430596771830","_uuid":"a8fdb8b91b8b087ca8db22c5011b4f7f4e2d9a25","trusted":true},"cell_type":"code","source":"# Train and validate random forest model on data\n\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel_forest = RandomForestRegressor()\nmodel_forest.fit(X_train, y_train)\nforest_predictions = model_forest.predict(X_dev)\nprint(mean_absolute_error(y_dev, forest_predictions))","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"e0a0a01d-5612-4592-9a38-94f578a8e051","_uuid":"0457d89700e1b70bbb36982b7c4652794f2a6f74","collapsed":true,"trusted":true},"cell_type":"code","source":"# Submit model predictions on test set\n\ntest = pd.read_csv(\"../input/test.csv\")\nX_test = test[predictors]\ntest_predictions = model.predict(X_test)\nsubmission = pd.DataFrame({\"Id\": test.Id, \"SalePrice\": test_predictions})\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":20,"outputs":[]},{"metadata":{"_cell_guid":"b715d536-1240-4608-9425-6739847a9241","_uuid":"19ab20f54819e479567957d8ecc583e6bf999960","collapsed":true,"trusted":false},"cell_type":"markdown","source":"## Level 2"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"9dc632ab60a304d46e27985fdba78b1220c51926"},"cell_type":"code","source":"# Load data, and separate it into predictors and a target, using only \n# numeric predictors\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain_target = train[\"SalePrice\"]\ntrain_predictors = train.drop([\"SalePrice\"], axis=1)\ntrain_numeric_predictors = train_predictors.select_dtypes(exclude=[\"object\"])","execution_count":123,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"af397d97da76e8f29dbc9086fa525a3c76778e63"},"cell_type":"code","source":"# Partition training data into train and dev set\n\nX_train, X_dev, y_train, y_dev = train_test_split(train_numeric_predictors, \n                                                  train_target, \n                                                  train_size=0.7, \n                                                  test_size=0.3, \n                                                  random_state=0)","execution_count":124,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"db2084d623ce737dd8f9c38297a50f295f8969d2"},"cell_type":"code","source":"# Construct function that calculates MAE score obtained by a random forest \n# model on dev set\n\ndef score_dataset(X_train, X_dev, y_train, y_dev):\n    model = RandomForestRegressor(random_state=0)\n    model.fit(X_train, y_train)\n    predictions = model.predict(X_dev)\n    return mean_absolute_error(y_dev, predictions)","execution_count":125,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60b885544b91fe3ce3c7ee5b58f2b09170066a0e"},"cell_type":"code","source":"# Drop any features with missing values in training set and obtain model \n# score with this modification\n\nfeatures_with_nan = [feature for feature in X_train.columns \n                             if X_train[feature].isnull().any()]\nX_train_reduced = X_train.drop(features_with_nan, axis=1)\nX_dev_reduced = X_dev.drop(features_with_nan, axis=1)\nprint(\"MAE from dropping features with missing values:\")\nprint(score_dataset(X_train_reduced, X_dev_reduced, y_train, y_dev))","execution_count":126,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a39cf7136e72d3a876affffafca3f5c3f9da6be6"},"cell_type":"code","source":"# Fill missing values with feature mean and obtain model score with \n# this modification\n\nX_train_filled = X_train.fillna(X_train.mean())\nX_dev_filled = X_dev.fillna(X_dev.mean())\nprint(\"MAE from filling missing values:\")\nprint(score_dataset(X_train_filled, X_dev_filled, y_train, y_dev))","execution_count":127,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c237b9d3d6c4eb9a752d970de04137fb7b40c4a"},"cell_type":"code","source":"# Fill missing values with feature mean and add features indicating which \n# instances were missing features for that given feature. Proceed to \n# obtain model score with this modification\n\nX_train_filled_plus = X_train.copy()\nX_dev_filled_plus = X_dev.copy()\nfeatures_with_nan = (feature for feature in X_train.columns \n                             if X_train[feature].isnull().any())\nfor feature in features_with_nan:\n    X_train_filled_plus[feature + \"_missing\"] = X_train_filled_plus[feature].isnull()\n    X_dev_filled_plus[feature + \"_missing\"] = X_dev_filled_plus[feature].isnull()\nX_train_filled_plus = X_train_filled_plus.fillna(X_train_filled_plus.mean())\nX_dev_filled_plus = X_dev_filled_plus.fillna(X_dev_filled_plus.mean())\nprint(\"MAE from filling missing values with tracking:\")\nprint(score_dataset(X_train_filled_plus, X_dev_filled_plus, y_train, y_dev))","execution_count":128,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"762b1102b5509f7fc48f6a07d327c7fc20f7a8d5"},"cell_type":"code","source":"# Add categorical features to train and dev sets\n\ntrain_all_predictors = pd.get_dummies(train_predictors)\n\nX_train, X_dev, y_train, y_dev = train_test_split(train_all_predictors, \n                                                  train_target, \n                                                  train_size=0.7, \n                                                  test_size=0.3, \n                                                  random_state=0)","execution_count":129,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"846814b3f1ff1f59fa49186787d1230c3c81429c"},"cell_type":"code","source":"# Again fill missing values with feature mean and add features indicating which \n# instances were missing features for that given feature. Proceed to \n# obtain model score with this modification\n\nX_train_filled_plus = X_train.copy()\nX_dev_filled_plus = X_dev.copy()\nfeatures_with_nan = (feature for feature in X_train.columns \n                             if X_train[feature].isnull().any())\nfor feature in features_with_nan:\n    X_train_filled_plus[feature + \"_missing\"] = X_train_filled_plus[feature].isnull()\n    X_dev_filled_plus[feature + \"_missing\"] = X_dev_filled_plus[feature].isnull()\nX_train_filled_plus = X_train_filled_plus.fillna(X_train_filled_plus.mean())\nX_dev_filled_plus = X_dev_filled_plus.fillna(X_dev_filled_plus.mean())\nprint(\"MAE from filling missing values with tracking and using all features:\")\nprint(score_dataset(X_train_filled_plus, X_dev_filled_plus, y_train, y_dev))","execution_count":130,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ffa2385d404dff4de4d55e56cef8c4549732944"},"cell_type":"code","source":"# Train and validate XGBoost model on data\n\nfrom xgboost import XGBRegressor\n\nbest_model = None\nbest_num_estimators = None\nbest_score = sys.maxsize\n\nfor num in [100, 500, 1000]:\n    model = XGBRegressor(n_estimators=num, random_state=0)\n    model.fit(X_train_filled_plus, \n              y_train, \n              early_stopping_rounds=5, \n              eval_set=[(X_dev_filled_plus, y_dev)], \n              verbose=False)\n    predictions = model.predict(X_dev_filled_plus)\n    mae = mean_absolute_error(y_dev, predictions)\n    if mae < best_score:\n        best_model = model\n        best_num_estimators = num\n        best_score = mae\nprint(\"MAE using XGBoost with {} estimators:\".format(best_num_estimators))\nprint(best_score)","execution_count":131,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3528b093677d7459cea4c0148fca4300f45fa97c"},"cell_type":"code","source":"# Plot partial dependencies of several features on Gradient Boosting \n# model of training data\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble.partial_dependence import plot_partial_dependence\n\ngb_model = GradientBoostingRegressor(random_state=0)\ngb_model.fit(X_train_filled_plus, y_train)\nplots = plot_partial_dependence(gb_model, \n                                features=[2, 6], \n                                X=X_train_filled_plus, \n                                feature_names=X_train_filled_plus.columns)","execution_count":132,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c2c0e546923a576d3815ab7ec78ee50c2051192"},"cell_type":"code","source":"# Cross validate dataset using pipelines, imputation, and \n# random forest models with different collection of predictors\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.model_selection import cross_val_score\n\nmy_pipeline = make_pipeline(Imputer(), \n                            RandomForestRegressor(random_state=0))\nscores_num = cross_val_score(my_pipeline, \n                             train_numeric_predictors, \n                             train_target, \n                             scoring=\"neg_mean_absolute_error\")\nprint(\"Mean MAE score using cross validation, pipelines, imputation, \"\n      \"and random forests with just numeric predictors:\")\nprint(-scores_num.mean())\nscores_all = cross_val_score(my_pipeline, \n                             train_all_predictors, \n                             train_target, \n                             scoring=\"neg_mean_absolute_error\")\nprint(\"Mean MAE score using cross validation, pipelines, \"\n      \"imputation, and random forests with all predictors:\")\nprint(-scores_all.mean())","execution_count":145,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8c1f3a58216b507c0a135f570f25fc799e0dd517"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}