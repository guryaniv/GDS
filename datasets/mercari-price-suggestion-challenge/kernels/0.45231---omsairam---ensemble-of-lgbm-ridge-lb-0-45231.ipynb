{"cells": [{"source": ["**This is based off of great work by Bojan Tunguz and yliu **"], "cell_type": "markdown", "metadata": {"_cell_guid": "7edabdf1-9013-43f2-9c42-e1c6f3766b47", "_uuid": "e6c4bbe70fc34fd438be054d834ec2062a981758"}}, {"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "b9c998fe-3961-406f-bdf0-5b13b1a23a3a", "_uuid": "5f7de64212a937614568b4b1cca6209862c58b5e", "collapsed": true}, "execution_count": null}, {"source": ["![](http://)**First Kernel done by Bojan Tunguz** https://www.kaggle.com/tunguz/lgbm-ridge-0-45529-lb/code"], "cell_type": "markdown", "metadata": {"_cell_guid": "e9a74908-2918-4a7d-a145-c53b1ebd090e", "_uuid": "407818d9469f1fd09b6c89af77bd55186526fb13"}}, {"source": ["import pandas as pd\n", "import numpy as np\n", "import scipy\n", "\n", "from sklearn.linear_model import Ridge, LogisticRegression\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "import lightgbm as lgb\n", "\n", "import gc"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "7e550016-4892-4fbd-9983-959b0e56e0e2", "_uuid": "0983360462c2018c61eac7aade1d7eedca808efb", "collapsed": true}, "execution_count": null}, {"source": ["NUM_BRANDS = 2500\n", "NAME_MIN_DF = 10\n", "MAX_FEAT_DESCP = 50000\n", "\n", "print(\"Reading in Data\")\n", "\n", "df_train = pd.read_csv('../input/train.tsv', sep='\\t')\n", "df_test = pd.read_csv('../input/test.tsv', sep='\\t')\n", "\n", "df = pd.concat([df_train, df_test], 0)\n", "nrow_train = df_train.shape[0]\n", "y_train = np.log1p(df_train[\"price\"])\n", "\n", "del df_train\n", "gc.collect()\n", "\n", "print(df.memory_usage(deep = True))"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "a27cafef-2a4e-4c2f-97a9-ad46dbcaa6b2", "_uuid": "87ebdfc95138a7389a802842cdebe0e8d182b3d1", "collapsed": true}, "execution_count": null}, {"source": ["df[\"category_name\"] = df[\"category_name\"].fillna(\"Other\").astype(\"category\")\n", "df[\"brand_name\"] = df[\"brand_name\"].fillna(\"unknown\")\n", "\n", "pop_brands = df[\"brand_name\"].value_counts().index[:NUM_BRANDS]\n", "df.loc[~df[\"brand_name\"].isin(pop_brands), \"brand_name\"] = \"Other\"\n", "\n", "df[\"item_description\"] = df[\"item_description\"].fillna(\"None\")\n", "df[\"item_condition_id\"] = df[\"item_condition_id\"].astype(\"category\")\n", "df[\"brand_name\"] = df[\"brand_name\"].astype(\"category\")\n", "\n", "print(df.memory_usage(deep = True))"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "72dc5d87-500b-41b5-be4a-370957dcf1c1", "_uuid": "4d5750a44db184d5eb573990e21aab373a025293", "collapsed": true}, "execution_count": null}, {"source": ["print(\"Encodings\")\n", "count = CountVectorizer(min_df=NAME_MIN_DF)\n", "X_name = count.fit_transform(df[\"name\"])\n", "\n", "print(\"Category Encoders\")\n", "unique_categories = pd.Series(\"/\".join(df[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\n", "count_category = CountVectorizer()\n", "X_category = count_category.fit_transform(df[\"category_name\"])\n", "\n", "print(\"Descp encoders\")\n", "count_descp = TfidfVectorizer(max_features = MAX_FEAT_DESCP, \n", "                              ngram_range = (1,3),\n", "                              stop_words = \"english\")\n", "X_descp = count_descp.fit_transform(df[\"item_description\"])\n", "\n", "print(\"Brand encoders\")\n", "vect_brand = LabelBinarizer(sparse_output=True)\n", "X_brand = vect_brand.fit_transform(df[\"brand_name\"])\n", "\n", "print(\"Dummy Encoders\")\n", "X_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n", "    \"item_condition_id\", \"shipping\"]], sparse = True).values)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "a664b302-4ae6-46ab-b7ef-752e2622d9d0", "_uuid": "9db335b1cd5f40772783f2fa80a4d61345259894", "collapsed": true}, "execution_count": null}, {"source": ["X = scipy.sparse.hstack((X_dummies, \n", "                         X_descp,\n", "                         X_brand,\n", "                         X_category,\n", "                         X_name)).tocsr()\n", "\n", "print([X_dummies.shape, X_category.shape, \n", "       X_name.shape, X_descp.shape, X_brand.shape])\n", "\n", "X_train = X[:nrow_train]\n", "X_test = X[nrow_train:]"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "57a4b628-1b2d-4a28-b566-6737c47f3a16", "_uuid": "31cb38b826c2699e6450c79da04b123ccf4f5338", "collapsed": true}, "execution_count": null}, {"source": ["params = {\n", "    'learning_rate': 0.75,\n", "    'application': 'regression',\n", "    'max_depth': 3,\n", "    'num_leaves': 100,\n", "    'verbosity': -1,\n", "    'metric': 'RMSE',\n", "}\n", "\n", "\n", "train_X, valid_X, train_y, valid_y = train_test_split(X_train, y_train, test_size = 0.1, random_state = 144) \n", "d_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\n", "d_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\n", "watchlist = [d_train, d_valid]\n", "\n", "model = lgb.train(params, train_set=d_train, num_boost_round=2200, valid_sets=watchlist, \\\n", "early_stopping_rounds=50, verbose_eval=100) \n", "preds = model.predict(X_test)\n", "\n", "model = Ridge(solver = \"lsqr\", fit_intercept=False)\n", "\n", "print(\"Fitting Model\")\n", "model.fit(X_train, y_train)\n", "\n", "preds += model.predict(X_test)\n", "preds /= 2"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "278b99c1-9cc1-4e78-b55f-03277b3e97e3", "_uuid": "a8a5a355fd055e88ae1be84f9271c7e53ab01ce4", "collapsed": true}, "execution_count": null}, {"source": ["df_test[\"price\"] = np.expm1(preds)\n", "df_test[[\"test_id\", \"price\"]].to_csv(\"submission_LGBM_Ridge_3.csv\", index = False)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1104312d-f758-49a0-933d-89f6b6cdc24c", "_uuid": "f1a98994a7733745eb53c01191073fd20b4fcaf1", "collapsed": true}, "execution_count": null}, {"source": ["**Including yliu's kernel now** https://www.kaggle.com/yliu9999/lightgbm-ridge-0-45704lb/notebook"], "cell_type": "markdown", "metadata": {"_cell_guid": "06b3e9ae-f47e-4de6-8174-c182c80a6185", "_uuid": "c227d45efad897e1ce3697eac1a8b923688ca3bd"}}, {"source": ["import numpy as np\n", "import pandas as pd\n", "import scipy\n", "\n", "from sklearn.linear_model import Ridge, LogisticRegression\n", "from sklearn.model_selection import train_test_split, cross_val_score\n", "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n", "from sklearn.preprocessing import LabelBinarizer\n", "\n", "import gc\n", "\n", "NUM_BRANDS = 2500\n", "NAME_MIN_DF = 10\n", "MAX_FEAT_DESCP = 10000\n", "\n", "print(\"Reading in Data\")\n", "\n", "df_train2 = pd.read_csv('../input/train.tsv', sep='\\t')\n", "df_test2 = pd.read_csv('../input/test.tsv', sep='\\t')\n", "\n", "df = pd.concat([df_train2, df_test2], 0)\n", "nrow_train = df_train2.shape[0]\n", "y_train = np.log(df_train2[\"price\"]+1)\n", "\n", "del df_train2\n", "gc.collect()\n", "\n", "print(df.memory_usage(deep = True))\n", "\n", "df[\"category_name\"] = df[\"category_name\"].fillna(\"Other\").astype(\"category\")\n", "df[\"brand_name\"] = df[\"brand_name\"].fillna(\"unknown\")\n", "\n", "pop_brands = df[\"brand_name\"].value_counts().index[:NUM_BRANDS]\n", "df.loc[~df[\"brand_name\"].isin(pop_brands), \"brand_name\"] = \"Other\"\n", "\n", "df[\"item_description\"] = df[\"item_description\"].fillna(\"None\")\n", "df[\"item_condition_id\"] = df[\"item_condition_id\"].astype(\"category\")\n", "df[\"brand_name\"] = df[\"brand_name\"].astype(\"category\")\n", "\n", "print(df.memory_usage(deep = True))\n", "\n", "print(\"Encodings\")\n", "count = CountVectorizer(min_df=NAME_MIN_DF)\n", "X_name = count.fit_transform(df[\"name\"])\n", "\n", "print(\"Category Encoders\")\n", "unique_categories = pd.Series(\"/\".join(df[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\n", "count_category = CountVectorizer()\n", "X_category = count_category.fit_transform(df[\"category_name\"])\n", "\n", "print(\"Descp encoders\")\n", "count_descp = TfidfVectorizer(max_features = MAX_FEAT_DESCP, \n", "                              ngram_range = (1,3),\n", "                              stop_words = \"english\")\n", "X_descp = count_descp.fit_transform(df[\"item_description\"])\n", "\n", "print(\"Brand encoders\")\n", "vect_brand = LabelBinarizer(sparse_output=True)\n", "X_brand = vect_brand.fit_transform(df[\"brand_name\"])\n", "\n", "print(\"Dummy Encoders\")\n", "X_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n", "    \"item_condition_id\", \"shipping\"]], sparse = True).values)\n", "\n", "X = scipy.sparse.hstack((X_dummies, \n", "                         X_descp,\n", "                         X_brand,\n", "                         X_category,\n", "                         X_name)).tocsr()\n", "\n", "print([X_dummies.shape, X_category.shape, \n", "       X_name.shape, X_descp.shape, X_brand.shape])\n", "\n", "X_train = X[:nrow_train]\n", "model = Ridge(solver = \"lsqr\", fit_intercept=False)\n", "\n", "print(\"Fitting Model\")\n", "model.fit(X_train, y_train)\n", "\n", "X_test = X[nrow_train:]\n", "preds1 = model.predict(X_test)\n", "\n", "#submission = df_test2#[[\"test_id\"]]\n", "#df_test2[\"price1\"] =preds1\n", "\n", "\n", "\n", "df_test2[\"price1\"] = np.exp(preds1)-1\n", "\n", "\n", "\n", "#df_test2[[\"test_id\", \"price\"]].to_csv(\"submission_ridge.csv\", index = False)\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "0cde15db-8182-4454-87f8-82597ffd8b6f", "_uuid": "66fb8ee012f5c6c9e0601148e7582149a98138ae", "collapsed": true}, "execution_count": null}, {"source": ["type(X_test)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6f851d55-7bd9-43bd-8b2c-3dddcea8371b", "_uuid": "511a1df752a80d0380ec85a8d5c451a73dafd381", "collapsed": true}, "execution_count": null}, {"source": ["X=X_train \n", "y=y_train\n", "\n", "def rmsle(predictions, targets):\n", "    predictions = np.exp(predictions) - 1\n", "    targets = np.exp(targets) - 1\n", "    return np.sqrt(((predictions - targets) ** 2).mean())\n", "\n", "def rmsle_lgb(labels, preds):\n", "    return 'rmsle', rmsle(preds, labels), False\n", "\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "85edd91d-8739-4754-92ec-30d5f3524ce7", "_uuid": "08ac8a845c7649d9ec9a0b574a295cf9f4fc6289", "collapsed": true}, "execution_count": null}, {"source": ["print('Training model...')\n", "from sklearn.model_selection import train_test_split\n", "\n", "from lightgbm import LGBMRegressor\n", "X_train, X_test2, y_train, y_test2 = train_test_split(X, y, test_size=0.3, random_state=42)\n", "lgbm_params = {'n_estimators': 1000, 'learning_rate': 0.4, 'max_depth': 10,\n", "               'num_leaves': 31, 'subsample': 0.9, 'colsample_bytree': 0.8,\n", "               'min_child_samples': 50, 'n_jobs': 4}\n", "model = LGBMRegressor(**lgbm_params)\n", "model.fit(X_train, y_train,\n", "         eval_set=[(X_test2, y_test2)],\n", "         eval_metric=rmsle_lgb,\n", "         early_stopping_rounds=100,\n", "         verbose=True)\n", "\n", "print('Generating submission...')\n", "\n", "preds2 = model.predict(X_test)\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "6f6b2527-db1d-4626-91e6-81b9b2fda414", "_uuid": "de252bf2119828858baa24a95fe1908bed403155", "collapsed": true}, "execution_count": null}, {"source": ["df_test2['price2']=np.exp(preds2) - 1\n", "\n", "df_test2['price']=(df_test2['price2']+df_test2['price1'])/2\n", "df_test2[[\"test_id\", \"price\"]].to_csv(\"submission.csv\", index = False)\n"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "e81dc4d6-2422-4b3b-bf57-34c91d01df1e", "_uuid": "64cf0c405e62e242f71fd9cc7cd5b3597eed9460", "collapsed": true}, "execution_count": null}, {"source": ["df_test[[\"test_id\", \"price\"]].head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "135c8b6c-7e63-450e-b0c8-dd88ae480b2b", "_uuid": "fd416fdfcbd114fa7e9a68993981804e614356b0", "collapsed": true}, "execution_count": null}, {"source": ["df_test2[[\"test_id\", \"price\"]].head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "771a4d01-a8b8-4150-9a9a-cdf0dd692ed0", "_uuid": "491697c36ebb049d7fdc3b2f0c8e33671c2434a5", "collapsed": true}, "execution_count": null}, {"source": ["new = df_test[[\"test_id\", \"price\"]].copy()\n", "new.head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "66a1579e-7a2a-4342-a8df-162962038a19", "_uuid": "63edba67f0cfaa0eec5af6faf17dd6dbdc15d542", "collapsed": true}, "execution_count": null}, {"source": ["new2 = df_test2[[\"test_id\", \"price\"]].copy()\n", "new2.head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "651fa2a1-0393-46b1-bafd-5061a4c081c6", "_uuid": "269f6495ed796f7e9e1447e28e105560099e6137", "collapsed": true}, "execution_count": null}, {"source": ["new['price'] = new2['price']*.6 + new['price']*.4\n", "new.head()"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "c8dcde07-4061-444f-85be-6a31c8ae2f38", "_uuid": "9dbff41f48ef7ec94e180240622bef707c6a4d27", "collapsed": true}, "execution_count": null}, {"source": ["new.to_csv(\"lgbm_ridge_ensemble2.csv\", float_format='%.4f', index=None)"], "outputs": [], "cell_type": "code", "metadata": {"_cell_guid": "1921abcd-82ac-4a35-a130-f571b4dd48e6", "_uuid": "8a0b3820ca0a79f0b999416473f3986c3e57332c", "collapsed": true}, "execution_count": null}], "nbformat": 4, "metadata": {"language_info": {"nbconvert_exporter": "python", "mimetype": "text/x-python", "version": "3.6.3", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1}