{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca155b58-c33f-3a9b-df30-28b94f5f3344"
      },
      "source": [
        "Here is my attempt to use Tensorflow for this dataset using the kagglegym API. The notebook is still under construction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2e91102a-d0ec-190b-18f3-aedee719cc82"
      },
      "source": [
        "Kagglegym import..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6d2d707b-a279-1baa-1b47-e40667711964"
      },
      "outputs": [],
      "source": [
        "import kagglegym\n",
        "# Create environment\n",
        "env = kagglegym.make()\n",
        "# Get first observation\n",
        "observation = env.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "79e92bd4-c9fb-9445-760a-4026c2f11a7a"
      },
      "source": [
        "One major problem of this dataset is the number of missing values. First, we want to make sure that there is enough complete data to learn something meaningful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0c4aca5f-e815-1fa6-1462-4f922d481e32"
      },
      "outputs": [],
      "source": [
        "observation.train.dropna().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b4c617fd-5f81-ce04-f14c-e9389e8451d3"
      },
      "outputs": [],
      "source": [
        "for col in observation.train.columns:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0a0eb182-2321-d7cf-b502-381b89d868b9"
      },
      "source": [
        "Analyze of the output to design the network output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06e901dc-787f-4a7a-3af6-233147454215"
      },
      "outputs": [],
      "source": [
        "observation.train[\"y\"].hist(bins=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7d81383a-b2a2-c626-c586-ced1098a18c0"
      },
      "outputs": [],
      "source": [
        "observation.train.dropna()[\"technical_5\"].hist(bins=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dc79eda8-455a-36f6-da6a-e1b8c6aa9885"
      },
      "source": [
        "The output seems to have a zero mean making sense to take a sigmoid as an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e693be53-933c-79de-2a4f-8c04ed438dcb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a9c61d0f-991e-7426-3ba5-76279942a91c"
      },
      "source": [
        "Simple two layer neural net minimizing the mean squared value. I am trying to switch to R2 loss later (see my attempt in the code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "23043282-5c5d-96ea-6c57-a60ecb2199b7"
      },
      "outputs": [],
      "source": [
        "import tensorflow.contrib.layers as layers\n",
        "import tensorflow.contrib.losses as losses\n",
        "\n",
        "N_FEATURES=108\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=(None, N_FEATURES))\n",
        "y = tf.placeholder(tf.float32, shape=(None,1))\n",
        "p = tf.placeholder(tf.float32)\n",
        "logits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\n",
        "logits = layers.dropout(logits, keep_prob=p)\n",
        "logits = layers.fully_connected(x, 56, activation_fn=tf.nn.relu)\n",
        "logits = layers.dropout(logits, keep_prob=p)\n",
        "y_ = layers.fully_connected(logits, 1)\n",
        "\n",
        "loss = losses.mean_squared_error(y, y_)\n",
        "\n",
        "# loss = tf.reduce_mean(tf.reduce_sum(tf.square(y-y_)) / tf.square(y_ - tf.reduce_mean(y_))) # Equivalent to minimize R2\n",
        "\n",
        "train_op = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3a09f846-dea9-fb5e-6e83-acb369e11d9a"
      },
      "source": [
        "Numpy arrays for feeding the network. Splitting into train and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4e7317f4-af95-8be1-477a-d0c762f43c55"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import train_test_split\n",
        "traindf, testdf = train_test_split(observation.train.drop(axis=1, labels=[\"id\", \"timestamp\"]).dropna(),\n",
        "                                  train_size=0.8,\n",
        "                                  test_size=0.2)\n",
        "\n",
        "Y_train = traindf[\"y\"]\n",
        "X_train = traindf.drop(axis=1, labels=[\"y\"])\n",
        "\n",
        "Y_test = testdf[\"y\"]\n",
        "X_test = testdf.drop(axis=1, labels=[\"y\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6b32c554-bf36-fb83-dfef-8c1e4b16788d"
      },
      "source": [
        "Training process by batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fa829688-3765-c6c5-ec70-e8ad2f230261"
      },
      "outputs": [],
      "source": [
        "num_examples = X_train.shape[0]\n",
        "batch_size = 32\n",
        "n_epoch = 2\n",
        "n_batch = int(num_examples / batch_size)\n",
        "print(\"Feeding {} batches per epoch\".format(n_batch))\n",
        "start = 0\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "\n",
        "for _ in range(n_epoch):\n",
        "    start = 0\n",
        "    for batch_idx in range(n_batch-1):\n",
        "    #for batch_idx in range(15):\n",
        "        feeding_dict = { x: X_train.iloc[start:(start+batch_size)].values,\n",
        "                        y: Y_train.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n",
        "                       p:0.5}\n",
        "        start+=batch_size\n",
        "\n",
        "        _, l  = sess.run([train_op, loss], feed_dict=feeding_dict)\n",
        "\n",
        "        if not(batch_idx%1000):\n",
        "            print(\"Loss on batch {}: {}\".format(batch_idx, l))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c01cec7-16e9-0084-059a-3f6f42dd4551"
      },
      "outputs": [],
      "source": [
        "import tensorflow.contrib.metrics as metrics\n",
        "\n",
        "smse, smse_update_op = metrics.streaming_mean_squared_error(y, y_)\n",
        "\n",
        "num_examples = X_test.shape[0]\n",
        "batch_size = 32\n",
        "n_batch = int(num_examples / batch_size)\n",
        "print(\"Feeding {} batches per epoch\".format(n_batch))\n",
        "start = 0\n",
        "\n",
        "sess.run(tf.initialize_local_variables())\n",
        "\n",
        "for batch_idx in range(n_batch-1):\n",
        "    feeding_dict = { x: X_test.iloc[start:(start+batch_size)].values,\n",
        "    y: Y_test.iloc[start:(start+batch_size)].values.reshape(-1, 1),\n",
        "                   p:1.}\n",
        "    start+=batch_size\n",
        "    sess.run(smse_update_op, feed_dict=feeding_dict)\n",
        "print(\"Total loss: {}\".format(sess.run(smse)))"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}