{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# The code of the neural network","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from torch.autograd import Variable\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom scipy import misc\nimport torch.nn as nn\nimport skimage as sk\nimport pylab as plt\nimport numpy as np\nimport argparse\nimport random\nimport torch\nimport time\nimport math\nimport glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8006a97a24bb17208502edc6d0aebc37b2e377a"},"cell_type":"code","source":"# The final neural architecture\nclass Net(nn.Module):\n\tdef __init__(self):\n\t\tsuper(Net, self).__init__()\n\t\t# Convolution layers\n\t\tself.conv1 = nn.Conv2d(3, 16, kernel_size=3)\n\t\tself.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n\t\tself.conv3 = nn.Conv2d(32, 64, kernel_size=3)\n\t\tself.conv4 = nn.Conv2d(64, 256, kernel_size=3)\n\t\tself.bn0   = nn.BatchNorm2d(3)\n\t\tself.bn1   = nn.BatchNorm2d(16)\n\t\tself.bn2   = nn.BatchNorm2d(32)\n\t\tself.bn3   = nn.BatchNorm2d(64)\n\t\tself.bn4   = nn.BatchNorm2d(256)\n\t\t# Fully connected layers\n\t\tself.fc1 = nn.Conv2d(256, 128, kernel_size=1)\n\t\tself.fc2 = nn.Conv2d(128, 64, kernel_size=1)\n\t\tself.bnfc1   = nn.BatchNorm2d(128)\n\t\tself.bnfc2   = nn.BatchNorm2d(64)\n\t\t# Separate classifiers\n\t\t# age\n\t\tself.age1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.age2 = nn.Conv2d(32, 6, kernel_size=1)\n\t\tself.bnage = nn.BatchNorm2d(32)\n\t\t# gender\n\t\tself.gender1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.gender2 = nn.Conv2d(32, 3, kernel_size=1)\n\t\tself.bngender = nn.BatchNorm2d(32)\n\t\t# type\n\t\tself.type1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.type2 = nn.Conv2d(32, 2, kernel_size=1)\n\t\tself.bntype = nn.BatchNorm2d(32)\n\t\t# breed\n\t\tself.breed1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.breed2 = nn.Conv2d(32, 2, kernel_size=1)\n\t\tself.bnbreed = nn.BatchNorm2d(32)\n\t\t# color1\n\t\tself.color1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.color2 = nn.Conv2d(32, 7, kernel_size=1)\n\t\tself.bncolor = nn.BatchNorm2d(32)\n\t\t# color2\n\t\tself.color12 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.color22 = nn.Conv2d(32, 8, kernel_size=1)\n\t\tself.bncolor2 = nn.BatchNorm2d(32)\n\t\t# color3\n\t\tself.color13 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.color23 = nn.Conv2d(32, 8, kernel_size=1)\n\t\tself.bncolor3 = nn.BatchNorm2d(32)\n\t\t# maturity size\n\t\tself.mat1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.mat2 = nn.Conv2d(32, 4, kernel_size=1)\n\t\tself.bnmat = nn.BatchNorm2d(32)\n\t\t# fur length\n\t\tself.fur1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.fur2 = nn.Conv2d(32, 3, kernel_size=1)\n\t\tself.bnfur = nn.BatchNorm2d(32)\n\t\t# adaption speed\n\t\tself.speed1 = nn.Conv2d(64, 32, kernel_size=1)\n\t\tself.speed2 = nn.Conv2d(32, 5, kernel_size=1)\n\t\tself.bnspeed = nn.BatchNorm2d(32)\n\tdef forward(self, x):\n\t\tx = F.relu(self.getHidden(x))\n\t\t# To separate classifiers\n\t\t# age\n\t\ta = F.relu(self.bnage(self.age1(x)))\n\t\ta = F.softmax(self.age2(a).view(-1, 6), dim=1)\n\t\t# gender\n\t\tb = F.relu(self.bngender(self.gender1(x)))\n\t\tb = F.softmax(self.gender2(b).view(-1, 3), dim=1)\n\t\t# type\n\t\tc = F.relu(self.bntype(self.type1(x)))\n\t\tc = F.softmax(self.type2(c).view(-1, 2), dim=1)\n\t\t# breed\n\t\td = F.relu(self.bnbreed(self.breed1(x)))\n\t\td = F.softmax(self.breed2(d).view(-1, 2), dim=1)\n\t\t# color1\n\t\te = F.relu(self.bncolor(self.color1(x)))\n\t\te = F.softmax(self.color2(e).view(-1, 7), dim=1)\n\t\t# adaption speed\n\t\tf = F.relu(self.bnspeed(self.speed1(x)))\n\t\tf = F.softmax(self.speed2(f).view(-1, 5), dim=1)\n\t\t# color2\n\t\tg = F.relu(self.bncolor2(self.color12(x)))\n\t\tg = F.softmax(self.color22(g).view(-1, 8), dim=1)\n\t\t# color3\n\t\th = F.relu(self.bncolor3(self.color13(x)))\n\t\th = F.softmax(self.color23(h).view(-1, 8), dim=1)\n\t\t# maturity size\n\t\ti = F.relu(self.bnmat(self.mat1(x)))\n\t\ti = F.softmax(self.mat2(i).view(-1, 4), dim=1)\n\t\t# fur length\n\t\tj = F.relu(self.bnfur(self.fur1(x)))\n\t\tj = F.softmax(self.fur2(j).view(-1, 3), dim=1)\n\t\treturn x.view(-1,64),a,b,c,d,e,f,g,h,i,j\n\tdef getHidden(self, x):\n\t\tx = self.bn0(x)\n\t\tx = F.relu(F.max_pool2d(self.bn1(self.conv1(x)),2))\n\t\tx = F.relu(F.max_pool2d(self.bn2(self.conv2(x)),2))\n\t\tx = F.relu(F.max_pool2d(self.bn3(self.conv3(x)),2))\n\t\tx = self.bn4(F.relu(self.conv4(x)))\n\t\t# colapse\n\t\tx = F.max_pool2d(x, 20,20)\n\t\t# fully connected\n\t\tx = F.relu(self.bnfc1(self.fc1(x)))\n\t\tx = self.bnfc2(self.fc2(x))\n\t\treturn x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f3fc973d9b57305921336ad69d8cfcadeac5cc8"},"cell_type":"code","source":"# Set seeds \nseed = 1\nrandom.seed(seed)\ntorch.manual_seed(seed)\n\t\n# init model and optimizer\nmodel = Net()\noptimizer = optim.Adam(model.parameters())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2dbf6b77b890af7cdebfc7d001a4dffdbcbc287f"},"cell_type":"code","source":"# Load datalocations and create train and validation set\ntrain = glob.glob('trans/*')\nrandom.shuffle(train)\nprint(len(train))\ntrainsize = int((0.8)*len(train))\nvalset = train[trainsize:]\ntrainset = train[:trainsize]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91bceb034ee971e3e9998daaaa312b96e8fc1133"},"cell_type":"code","source":"# Function that runs the model on a batch and return the loss\n# can be used for training and evaluating\ndef run(model, batch, labels, weights):\n\toutput = model(batch)\n\tloss = 0\n\tfor i in xrange(len(labels)):\n\t\tloss += F.binary_cross_entropy(output[i+1], labels[i], weight=weights[i])\n\treturn loss\n\n# Function that shows the progress of training\ndef show(avg=25, fname='log.txt'):\n\tb = open(fname).read().split('\\n')[:-1]\n\tb = [float(i)for i in b]\n\tb = [sum(b[i:i+avg])/float(avg) for i in xrange(len(b)-avg)]\n\tplt.plot(b)\n\tplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"beda686a2e619415ae23ec2159e3420b9cbb7cb7"},"cell_type":"code","source":"# Generates a batch and label set for training or evaluating\ndef genBatch(bs=1, tset=trainset):\n\twhich = [random.randint(0, len(tset)-1)for i in xrange(bs)]\n\tids = [tset[i].split('/')[1] for i in which]\n\t#misc.imsave('cur.png', misc.imread(tset[which[0]]))\n\tids = [i[:i.index('-')]for i in ids]\n\tdset = [misc.imread(tset[i]) for i in which] # Red in image, after that prepare for neural input\n\tdset = [augment(i)for i in dset]\n\tdset = [i.transpose((2,0,1))for i in dset]\n\tdset = [Variable(torch.Tensor(i).float().contiguous().view(1,3,200,200))for i in dset]\n\tdset = torch.cat(dset) # == input\n\tlabels = [torch.zeros(bs, 6), # Make one hot vector for all outputs\n\t\t\t  torch.zeros(bs, 3),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 7),\n\t\t\t  torch.zeros(bs, 5),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 4),\n\t\t\t  torch.zeros(bs, 3),]\n    # make one hot vector\n\tfor i in xrange(bs):\n\t\tval = values[ids[i]]\n\t\tfor k in xrange(len(val)):\n\t\t\tlabels[k][i][val[k]] = 1\n\t\t#print val\n\t#print labels\n\tlabels = [Variable(i)for i in labels]\n\treturn dset, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acdc0c91fe1e2d37eeb41f072e657baa001ba5be"},"cell_type":"code","source":"# Transforms the photos to neural embeddings\ndef transformToHidden(model, tset):\n  model.eval()\n# The file with ids \n  names = open('emb_ids.txt', 'w')\n  embeddings = np.zeros((len(tset), 64))\n# the file for th eembedding to save in\n  csv = open('trainset.txt', 'w')\n  print (len(tset))\n  for img in xrange(0, len(tset)): # Go over all images\n\tids = tset[img].split('/')[1][:-4]\n\tids2 = ids[:ids.index('-')]\n\tval = values[ids2][5]\n\tif img%100==0:print(img)\n\tdset = misc.imread(tset[img]) # read in image after that prepare it for neural input\n\tdset = dset.transpose((2,0,1))\n\tdset = Variable(torch.Tensor(dset).float().contiguous().view(1,3,200,200))\n\thidden = model.getHidden(dset).data.view(-1,64).numpy()\n\tnames.write(ids+'\\n')\n\tembeddings[img] = hidden[0]\n\t[csv.write(str(i)+',') for i in hidden[0]]\n\tcsv.write(str(val)+'\\n')\n  csv.close()\n  np.save('embeddings', embeddings)\n  model.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ead8a614d297628425c9549df56003ce7cf85bb4"},"cell_type":"code","source":"# Generate the weights for class inbalance compensation\n# This by randomly sample from training set (not validation set)\ndef genWeights(dset, samplesize):\n\tb,ll = genBatch(100, dset)\n\tll = [i.data for i in ll]\n\tfor i in xrange(samplesize-1):\n\t\tb,l = genBatch(100, dset)\n\t\tfor i in xrange(len(l)):\n\t\t\tll[i] += l[i].data\n\tfor i in xrange(len(ll)):\n\t\tfor j in xrange(len(ll[i])):\n\t\t\tll[i][j] = 1./(ll[i][j]+1)\n\t\tll[i] = Variable(ll[i].sum(0))\n\treturn ll","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b81ecff2d6acdd55158939681108aef6204483f"},"cell_type":"code","source":"# Augment the data with random image flip and some rotation\ndef augment(img):\n\t\timg = misc.imrotate(img, random.uniform(-30,30)) \n\t\tif random.random()<.5: img = img[:, ::-1]\n\t\t# random crop?\n\t\treturn img.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ccb21272ac7874371ae4e5e8f7e82db731ed9f9"},"cell_type":"code","source":"# Function to test the model on the validation set\ndef testscore(model, bs=64):\n  model.eval()\n  totscore = 0\n  tel = 0.0\n  for batch in xrange(0, len(valset)-bs, bs):\n\twhich = range(batch,batch+bs)\n\tids = [valset[i].split('/')[1] for i in which]\n\tids = [i[:i.index('-')]for i in ids]\n\tdset = [misc.imread(valset[i]) for i in which]\n\t#dset = [augment(i)for i in dset]\n\tdset = [i.transpose((2,0,1))for i in dset]\n\tdset = [Variable(torch.Tensor(i).float().contiguous().view(1,3,200,200))for i in dset]\n\tdset = torch.cat(dset)\n\tlabels = [torch.zeros(bs, 6),\n\t\t\t  torch.zeros(bs, 3),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 7),\n\t\t\t  torch.zeros(bs, 5),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 4),\n\t\t\t  torch.zeros(bs, 3),]\n\tfor i in xrange(bs):\n\t\tval = values[ids[i]]\n\t\tfor k in xrange(len(val)):\n\t\t\tlabels[k][i][val[k]] = 1\n\t\t#print val\n\t#print (labels)\n\tlabels = [Variable(i)for i in labels]\n\tempty = [Variable(torch.ones(i.shape))for i in weights]\n\tloss = run(model, dset, labels, empty).data.numpy()\n\ttotscore += loss\n\ttel += 1\n  model.train()\n  return int(totscore)/tel\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"5e275bdf2aeb111515599128b3b3429570373741"},"cell_type":"code","source":"# Function that returns the confusion matrix for all the \n# outputs\ndef confusionMatrix():\n model = torch.load('eval_model')\n bs=64\n model.eval()\n l1 = [np.zeros((i,i))for i in [6,3,2,2,7,5,8,8,4,3]]\n# Go over the complete validation set\n for batch in xrange(0, len(valset)-bs, bs):\n \tprint batch\n\twhich = range(batch,batch+bs)\n\tids = [valset[i].split('/')[1] for i in which]\n\tids = [i[:i.index('-')]for i in ids]\n\tdset = [misc.imread(valset[i]) for i in which]\n\t#dset = [augment(i)for i in dset]\n\tdset = [i.transpose((2,0,1))for i in dset]\n\tdset = [Variable(torch.Tensor(i).float().contiguous().view(1,3,200,200))for i in dset]\n\tdset = torch.cat(dset) # == batch of input\n\tlabels = [torch.zeros(bs, 6), # create one hot vector\n\t\t\t  torch.zeros(bs, 3),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 2),\n\t\t\t  torch.zeros(bs, 7),\n\t\t\t  torch.zeros(bs, 5),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 8),\n\t\t\t  torch.zeros(bs, 4),\n\t\t\t  torch.zeros(bs, 3),]\n\tfor i in xrange(bs): # fill one hot vector\n\t\tval = values[ids[i]]\n\t\tfor k in xrange(len(val)):\n\t\t\tlabels[k][i][val[k]] = 1\n\t\t#print(val)\n\t#print() labels)\n\tlabels = [i.numpy() for i in labels]\n\to = model(dset) # output of the model\n\to=[i.data.numpy()for i in o]\n    # Fill the confusion matrixes\n\tfor lab in xrange(len(labels)):\n\t\tfor sub in xrange(o[lab+1].shape[0]):\n\t\t\tl1[lab][labels[lab][sub].argmax(), o[lab+1][sub].argmax()] += 1\n return l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"547473863f5fc1aa00c6a20eb3625a14ce4bcc02"},"cell_type":"code","source":"# The final training function\ndef startTraining():\n\t# import pretrained model if possible\n\tif 0:\n\t\ttry:\n\t\t\tmodel = torch.load('eval_model')\n\t\t\tlog = open('log.txt', 'a')\n\t\texcept: pass\n\telse:\n\t\ttry:\n\t\t\tlog = open('log_oud.txt', 'w')\n\t\t\tlog = log.write(open('log.txt').read())\n\t\t\tlog.close()\n\t\t\toud = torch.load('model')\n\t\t\ttorch.save(oud, 'model_oud')\n\t\texcept: pass\n\t\tlog = open('log.txt', 'w')\n\t\t\n\tmodel.train()\n\t# The model was sometimed stopped \n    # to prevent to get the exact same batches twice\n    # a new seed is introduced\n\trandom.seed(int(time.time()))\n\ttorch.manual_seed(int(time.time()))\n\t\n    \n    total_loss = 50 # start score\n\tevaluate = 5 # after how many batches to print score\n\tbatchsize = 64 # nmb of images per time trained\n\t\n\tstartValScore = 10e9 # Startscore that the network needs to improve\n\tfor time in xrange(1, 10**12):\n\t\toptimizer.zero_grad()\n\t\tbatch, labels = genBatch(batchsize)\n\t\tloss = run(model, batch, labels, weights)\n\t\tloss.backward()\n\t\toptimizer.step()\n\t\tlog.write(str(loss.data.numpy()[0])+'\\n')\n\t\tif time % evaluate == 0:\n\t\t\ttotal_loss = total_loss/evaluate\n\t\t\tprint( time, total_loss )\n\t\t\ttotal_loss = loss.data.numpy()[0]\n\t\telse: \n\t\t\ttotal_loss += loss.data.numpy()[0]\n\t\tif time % 100 == 0:\n\t\t\t#test()\n\t\t\ttorch.save(model,'model')\n\t\t\tlog.close()\n\t\t\tlog = open('log.txt', 'a')\n\t\tif time % 100 == 0:\n\t\t\tevalscore = testscore(model)\n\t\t\tif evalscore < startValScore:\n\t\t\t\tprint()\n\t\t\t\tprint( 'New break!', evalscore)\n\t\t\t\tstartValScore = evalscore\n\t\t\t\ttorch.save(model, 'eval_model')\n\t\t\telse:\n\t\t\t\tprint()\n\t\t\t\tprint( 'Eval score:', evalscore, startValScore)\n\t\t\tmodel.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de0782db6e7b9717328caf0031855465e385dff7"},"cell_type":"code","source":"# Function that convert photos to fixed size\ndef make_smaller(location):\n\ttry:\n\t\tos.mkdir('trans2') # Location to save in, so action have to be performed only once\n\texcept: pass\n\t\n\tphotos = glob.glob('%s/test_images/*' % (location))\n\tfor i in photos:\n\t\tid1 = i.split('/')[1]\n\t\tid2 = id1[:id1.index('-')] # Finding petid \n\t\timg = misc.imread(i) # read in image\n\t\tshape = img.shape\n\t\tm = float(max(shape))\n\t\tshape = [int(ii/m *200) for ii in shape]\n\t\n\t\timg = misc.imresize(img, shape[:2]) # Change shape image\n\t\tnewimg = np.zeros((200,200,3))\n\t\ttry:\t\n\t\t\tnewimg[:shape[0], :shape[1]] = img\n\t\texcept:\n\t\t\tprint i\n\t\t\tfor k in xrange(3):\n\t\t\t\tnewimg[:shape[0], :shape[1], k] = img\n\t\t#misc.imshow(newimg)\n\t\tmisc.imsave('trans2/%s' % (id1), newimg.astype('uint8')) # save image","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}