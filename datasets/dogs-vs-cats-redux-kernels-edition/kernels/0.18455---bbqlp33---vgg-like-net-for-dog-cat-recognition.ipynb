{"cells":[{"metadata":{"trusted":true,"_uuid":"8513806ec29b365986b79535db0e6f83df2425a3"},"cell_type":"code","source":"SAMPLE_SIZE = None\nTEST_SIZE = 0.1\nRANDOM_STATE = 2018\nBATCH_SIZE = 64\nEPOCHS = 100\nIMG_SIZE = 100\nMEAN = 0\nSTD = 1\n# PATH = '../input/dogs-vs-cats-redux-kernels-edition/'\nPATH = '../input/'\nTRAIN_FOLDER = PATH+'train/'\nTEST_FOLDER =  PATH+'test/'\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport os, cv2, random, glob\nimport numpy as np\nfrom tqdm import tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nfrom random import shuffle \nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n# from tensorflow.python.keras.models import Sequential\n# from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom cv2 import imread, resize, cvtColor, imwrite\nfrom keras.preprocessing.image import ImageDataGenerator\nimport gc\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input\nfrom keras.models import Sequential\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.optimizers import RMSprop, Adam\n#tf.keras.preprocessing.image\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e83007d2a3a9ede4db5750626a1fed2aa238117c"},"cell_type":"code","source":"def read_image_and_resize(file_path, size=(128, 128), debug=False):\n    img = imread(file_path, cv2.IMREAD_COLOR)\n    img = cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_resized = resize(img, size)\n    if debug:\n        import matplotlib.pyplot as plt\n        print('Image resized from {} to {}'\n              .format(img.shape, img_resized.shape))\n        plt.figure()\n        plt.subplot(1, 2, 1)\n        plt.imshow(img)\n        plt.subplot(1, 2, 2)\n        plt.imshow(img_resized)\n\n    return img_resized\n\n\ndef load_image_dataset(\n        dir_path='datasets/train/',\n        size=(300, 300),\n        isTrain=False):\n    X, y = [], []\n    \n    if isTrain:\n        all_img_files = glob.glob(os.path.join(dir_path, '*.jpg'))[:SAMPLE_SIZE]\n    else:\n        all_img_files = [os.path.join(dir_path, '%d.jpg' % i) for i in range(1, 12501)]\n    for img_file in tqdm(all_img_files):\n        img = read_image_and_resize(img_file, size=size)\n        X.append(img)\n        if isTrain:\n            label = 'dog' in img_file and 1 or 0\n            y.append(label)\n    X = np.array(X)\n    y = np.array(y).reshape(-1, 1)\n    return X, y\n\ndef show_images_horizontally(images, labels=[], lookup_label=None,\n                            figsize=(15, 7)):\n\n    import matplotlib.pyplot as plt\n    from matplotlib.pyplot import figure, imshow, axis\n\n    fig = figure(figsize=figsize)\n    for i in range(images.shape[0]):\n        fig.add_subplot(1, images.shape[0], i + 1)\n        if lookup_label:\n            plt.title(lookup_label[labels[i][0]])\n        imshow(images[i], cmap='Greys_r')\n        axis('off')\n        \ndef plot_history(history, figsize=(15, 7)):\n    # Plot the loss and accuracy curves for training and validation \n    import matplotlib.pyplot as plt\n    from matplotlib.pyplot import figure, axis\n\n    fig = figure(figsize=figsize)\n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n\n    \ndef gen_kaggle_sub(model, test):\n    out_f = 'id,label'\n    preds = model.predict(test)\n    for idx, pred in enumerate(preds.reshape(-1)):\n        out_f += f'\\n{idx+1},{pred}'\n    with open('submission.csv', 'w') as f:\n        f.write(out_f)\n    print('\\nDone')\n    \ndef img_transform(x):\n    return (x - MEAN) / STD\n    \ndef img_fit_transform(x):\n    global MEAN, STD\n    MEAN = x.mean()\n    STD = x.std()\n    print(f\"MEAN:{MEAN}, STD:{STD}\")\n    return (x - MEAN) / STD\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e376b0c0d849d3e9e87c18e38e8c356fd61d718"},"cell_type":"code","source":"%%time\nX, y = load_image_dataset(\n        dir_path=TRAIN_FOLDER,\n        size=(IMG_SIZE, IMG_SIZE),\n        isTrain=True)\n\nnp.random.seed(RANDOM_STATE)\ndataset_size = len(X)\nperm = np.random.permutation(dataset_size)\nX, y = X[perm], y[perm]  # X is only shuffled along it's first index.\nprint(X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc7379681d51be6ed3a6bad2fb44a7001a928108"},"cell_type":"code","source":"num_samples = 5\nshow_images_horizontally(X[:num_samples], y[:num_samples], figsize=(15, 10),\n                         lookup_label={1: 'Dog', 0: 'Cat'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d3811d9a408d8bd057337a18f0ab450a9e18e8e"},"cell_type":"code","source":"train_set_ratio = 1 - TEST_SIZE\nidx = int(dataset_size * train_set_ratio)\nvalid_set_size = X.shape[0] - idx\ntrain_X, train_y, valid_X, valid_y = X[:idx], y[:idx], X[idx:], y[idx:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3bafd67d1868511bfbcf05fd73f374472d37a62"},"cell_type":"code","source":"print('Training set: {}, {}'.format(train_X.shape, train_y.shape))\nprint('Validation set: {}, {}'.format(valid_X.shape, valid_y.shape))\nprint('Some images in validation set:')\nshow_images_horizontally(valid_X[:num_samples], valid_y[:num_samples], figsize=(15, 10),\n                         lookup_label={1: 'Dog', 0: 'Cat'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d370004e20e1a0b78612d8f3f6e0e69d1c9c440"},"cell_type":"code","source":"# train_X = train_X/255\n# valid_X = valid_X/255\ntrain_X = img_fit_transform(train_X)\nvalid_X = img_transform(valid_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a23e7a65e36afc5851a9086cd3a8d724454cc097"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(64,(3,3), input_shape=(IMG_SIZE,IMG_SIZE,3), activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(Conv2D(64,(3,3), activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128,(3,3),activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(Conv2D(128,(3,3),activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.33))\n\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256,(3,3),activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(Conv2D(256,(3,3),activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(Conv2D(256,(3,3),activation=\"relu\", padding='same', kernel_initializer='he_normal'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.33))\n\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\n# model.add(Dense(1024,activation=\"relu\", kernel_initializer='he_normal'))\nmodel.add(Dense(256,activation=\"relu\", kernel_initializer='he_normal'))\nmodel.add(Dropout(0.5))    \nmodel.add(Dense(1,activation=\"sigmoid\"))\n\nmodel.compile(\n    loss=\"binary_crossentropy\", \n#     optimizer=Adam(lr=0.001),\n    optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999),\n    metrics=[\"accuracy\"]\n)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"50225297c8febaac3b6e034305e7386b1d077d58"},"cell_type":"code","source":"reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=5, min_lr=0.00001)\nearlystop = EarlyStopping(monitor='val_acc', patience=15, verbose=2, restore_best_weights=True)\ndatagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)\n\n# history = model.fit(\n#     x=train_X,\n#     y=train_y,\n#     validation_data=(valid_X, valid_y),\n# #     validation_split=0.05,\n#     epochs=25,\n#     batch_size=BATCH_SIZE,\n#     callbacks=[earlystop]\n# )\n\nhistory1 = model.fit_generator(\n    datagen.flow(train_X, train_y, batch_size=BATCH_SIZE),\n    steps_per_epoch=len(train_X) / BATCH_SIZE, \n    epochs=EPOCHS,\n    validation_data=(valid_X, valid_y),\n    callbacks=[earlystop, reduce_lr])\nplot_history(history1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"849f071c28f12e299aa59e1eb35810bcfb6a8bdc"},"cell_type":"code","source":"del train_X, train_y, valid_X, valid_y, datagen\ntest, _ = load_image_dataset(TEST_FOLDER, size=(IMG_SIZE, IMG_SIZE), isTrain=False)\ngen_kaggle_sub(model, img_transform(test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}