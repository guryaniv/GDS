{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#origin code: https://www.kaggle.com/hakeem/stacked-then-averaged-models-0-5697/code\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"353dd173c3f2a39a0eb13a4336b41e2a28777213"},"cell_type":"code","source":"import numpy as np\nfrom sklearn.base import BaseEstimator,TransformerMixin, ClassifierMixin\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import ElasticNetCV, LassoLarsCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.utils import check_array\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.random_projection import GaussianRandomProjection\nfrom sklearn.random_projection import SparseRandomProjection\nfrom sklearn.decomposition import PCA, FastICA\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f066fa469be587dd7306285070700799b446d4a"},"cell_type":"code","source":"class StackingEstimator(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, estimator):\n        self.estimator = estimator\n\n    def fit(self, X, y=None, **fit_params):\n        self.estimator.fit(X, y, **fit_params)\n        return self\n    def transform(self, X):\n        X = check_array(X)\n        X_transformed = np.copy(X)\n        # add class probabilities as a synthetic feature\n        if issubclass(self.estimator.__class__, ClassifierMixin) and hasattr(self.estimator, 'predict_proba'):\n            X_transformed = np.hstack((self.estimator.predict_proba(X), X))\n\n        # add class prodiction as a synthetic feature\n        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n\n        return X_transformed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7f2311a2b03d0887c5204801e2c430665367f21"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint(train.head())\nfor c in train.columns:\n    if train[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(train[c].values) + list(test[c].values))\n        train[c] = lbl.transform(list(train[c].values))\n        test[c] = lbl.transform(list(test[c].values))\nprint(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06f19f8caf9768e354a50f93d4fe707c140ad677"},"cell_type":"code","source":"n_comp = 12\n\n# tSVD\ntsvd = TruncatedSVD(n_components=n_comp, random_state=420)\ntsvd_results_train = tsvd.fit_transform(train.drop([\"y\"], axis=1))\ntsvd_results_test = tsvd.transform(test)\npd.DataFrame(tsvd_results_test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba00fb22626080e57fb90499726bb97b62a98a99"},"cell_type":"code","source":"# PCA\npca = PCA(n_components=n_comp, random_state=420)\npca2_results_train = pca.fit_transform(train.drop([\"y\"], axis=1))\npca2_results_test = pca.transform(test)\npd.DataFrame(pca2_results_test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d20d5ea61478925b038279f02297d4d8fc8ce9b9"},"cell_type":"code","source":"# ICA\nica = FastICA(n_components=n_comp, random_state=420)\nica2_results_train = ica.fit_transform(train.drop([\"y\"], axis=1))\nica2_results_test = ica.transform(test)\npd.DataFrame(ica2_results_test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"720fe3fa205f61cd4d97a57cdc8af582e5652101"},"cell_type":"code","source":"# GRP\ngrp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\ngrp_results_train = grp.fit_transform(train.drop([\"y\"], axis=1))\ngrp_results_test = grp.transform(test)\npd.DataFrame(grp_results_test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c6231b41feadfb3f2a8733a6e734888f5815d63"},"cell_type":"code","source":"# SRP\nsrp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\nsrp_results_train = srp.fit_transform(train.drop([\"y\"], axis=1))\nsrp_results_test = srp.transform(test)\npd.DataFrame(srp_results_test).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12a12aa94273b09686121220141157c69afd52e1"},"cell_type":"code","source":"#save columns list before adding the decomposition components\n\nusable_columns = list(set(train.columns) - set(['y']))\n\n# Append decomposition components to datasets\nfor i in range(1, n_comp + 1):\n    train['pca_' + str(i)] = pca2_results_train[:, i - 1]\n    test['pca_' + str(i)] = pca2_results_test[:, i - 1]\n\n    train['ica_' + str(i)] = ica2_results_train[:, i - 1]\n    test['ica_' + str(i)] = ica2_results_test[:, i - 1]\n\n    train['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n    test['tsvd_' + str(i)] = tsvd_results_test[:, i - 1]\n\n    train['grp_' + str(i)] = grp_results_train[:, i - 1]\n    test['grp_' + str(i)] = grp_results_test[:, i - 1]\n\n    train['srp_' + str(i)] = srp_results_train[:, i - 1]\n    test['srp_' + str(i)] = srp_results_test[:, i - 1]\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"a4b6c07446b3089589bdf1527df243de6507c1e4"},"cell_type":"code","source":"y_train = train['y'].values\ny_mean = np.mean(y_train)\nid_test = test['ID'].values\n#finaltrainset and finaltestset are data to be used only the stacked model (does not contain PCA, SVD... arrays) \nfinaltrainset = train[usable_columns].values\nfinaltestset = test[usable_columns].values\n\n\n'''Train the xgb model then predict the test data'''\n\nxgb_params = {\n    'n_trees': 520, \n    'eta': 0.0045,\n    'max_depth': 4,\n    'subsample': 0.93,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'base_score': y_mean, # base prediction = mean(target)\n    'silent': 1\n}\n# NOTE: Make sure that the class is labeled 'class' in the data file\n\ndtrain = xgb.DMatrix(train.drop('y', axis=1), y_train)\ndtest = xgb.DMatrix(test)\n\nnum_boost_rounds = 1250\n# train model\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)\ny_pred = model.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e007c72a7c1799be71e03180fb3cf06c6af171d5"},"cell_type":"code","source":"sub = pd.DataFrame()\nsub['ID'] = id_test\nsub['y'] = y_pred\nsub.to_csv('y_pred1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71ae2b80ca2f4e30181f5aa76d66e8df5edd0aab"},"cell_type":"code","source":"pd.DataFrame(y_pred).to_csv('pred1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c67f7e3db2093f251ee0a3afa46ca5f4cc670ff0"},"cell_type":"code","source":"import kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee173844ad286471e8edf79ab1f1352fd3e4fa70"},"cell_type":"code","source":"kaggle competitions submit -c mercedes-benz-greener-manufacturing -f pred1.csv -m \"Message\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b9adb480d1eaf29cad3f71b841c2fdf64f0e2c6"},"cell_type":"code","source":"'''Train the stacked models then predict the test data'''\n\nstacked_pipeline = make_pipeline(\n    StackingEstimator(estimator=LassoLarsCV(normalize=True)),\n    StackingEstimator(estimator=GradientBoostingRegressor(learning_rate=0.001, loss=\"huber\", max_depth=3, max_features=0.55, min_samples_leaf=18, min_samples_split=14, subsample=0.7)),\n    LassoLarsCV()\n\n)\n\n\nstacked_pipeline.fit(finaltrainset, y_train)\nresults = stacked_pipeline.predict(finaltestset)\nresults","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"'''R2 Score on the entire Train data when averaging'''\n\nprint('R2 score on train data:')\nprint(r2_score(y_train,stacked_pipeline.predict(finaltrainset)*0.2855 + model.predict(dtrain)*0.7145))\n\n'''Average the preditionon test data  of both models then save it on a csv file'''\n\nsub = pd.DataFrame()\nsub['ID'] = id_test\nsub['y'] = y_pred*0.75 + results*0.25\nsub.to_csv('stacked-models.csv', index=False)\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e53f9798998616f5715efda89fdb6484dfb2a6bf"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}