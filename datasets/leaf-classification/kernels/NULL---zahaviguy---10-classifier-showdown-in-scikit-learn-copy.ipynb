{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3bb42045-03bc-0ca3-36c9-9379444c88b1"
      },
      "source": [
        "# Which Classifier is Should I Choose? \n",
        "\n",
        "This is one of the most import questions to ask when approaching a machine learning problem. I find it easier to just test them all at once. Here's 10 of your favorite Scikit-Learn algorithms applied to the leaf data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e86aec01-dbc6-4696-e066-6da72fedd092"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def warn(*args, **kwargs): pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cross_validation import StratifiedShuffleSplit\n",
        "\n",
        "train = pd.read_csv('../input/train.csv')\n",
        "test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5de1ab5b-9b22-2375-4705-f6d12e9d3046"
      },
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "361c2695-95c0-745a-0336-a49f6dec97b2"
      },
      "outputs": [],
      "source": [
        "# Swiss army knife function to organize the data\n",
        "\n",
        "def encode(train, test):\n",
        "    le = LabelEncoder().fit(train.species) \n",
        "    labels = le.transform(train.species)           # encode species strings\n",
        "    classes = list(le.classes_)                    # save column names for submission\n",
        "    test_ids = test.id                             # save test ids for submission\n",
        "    \n",
        "    train = train.drop(['species', 'id'], axis=1)  \n",
        "    test = test.drop(['id'], axis=1)\n",
        "    \n",
        "    return train, labels, test, test_ids, classes\n",
        "\n",
        "train, labels, test, test_ids, classes = encode(train, test)\n",
        "train.head(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3222a1a2-6df6-e5a6-2c4d-65383fc9ee66"
      },
      "source": [
        "## Stratified Train/Test Split\n",
        "\n",
        "Stratification is necessary for this dataset because there is a relatively large number of classes (100 classes for 990 samples). This will ensure we have all classes represented in both the train and test indices. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7c91b9c9-3b4d-73ac-92d8-db0792f60a3e"
      },
      "outputs": [],
      "source": [
        "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n",
        "\n",
        "for train_index, test_index in sss:\n",
        "    X_train, X_test = train.values[train_index], train.values[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e1172a79-cdc8-6544-2580-4a58ee9fb434"
      },
      "source": [
        "## Sklearn Classifier Showdown\n",
        "\n",
        "Simply looping through 10 out-of-the box classifiers and printing the results. Obviously, these will perform much better after tuning their hyperparameters, but this gives you a decent ballpark idea. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb7913b9-e36d-ef8b-a012-cc708b583ab4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
        "    NuSVC(probability=True),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "# Logging for Visual Comparison\n",
        "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf.fit(X_train, y_train)\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*30)\n",
        "    print(name)\n",
        "    \n",
        "    print('****Results****')\n",
        "    train_predictions = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, train_predictions)\n",
        "    print(\"Accuracy: {:.4%}\".format(acc))\n",
        "    \n",
        "    train_predictions = clf.predict_proba(X_test)\n",
        "    ll = log_loss(y_test, train_predictions)\n",
        "    print(\"Log Loss: {}\".format(ll))\n",
        "    \n",
        "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "    \n",
        "print(\"=\"*30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5d972faa-01b5-f354-155b-9ab11cb9ab63"
      },
      "outputs": [],
      "source": [
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
        "\n",
        "plt.xlabel('Accuracy %')\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.show()\n",
        "\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\")\n",
        "\n",
        "plt.xlabel('Log Loss')\n",
        "plt.title('Classifier Log Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d6948e0b-fa3f-151d-baf4-a5e12f6fd1ec"
      },
      "source": [
        "## Submission\n",
        "\n",
        "After choosing your favorite classifier, format the output for a leaderboard submission. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e8370e61-ea98-94a6-2b46-99ca7e401e9f"
      },
      "outputs": [],
      "source": [
        "# Predict Test Set\n",
        "favorite_clf = LinearDiscriminantAnalysis()\n",
        "favorite_clf.fit(X_train, y_train)\n",
        "test_predictions = favorite_clf.predict_proba(test)\n",
        "\n",
        "# Format DataFrame\n",
        "submission = pd.DataFrame(test_predictions, columns=classes)\n",
        "submission.insert(0, 'id', test_ids)\n",
        "submission.reset_index()\n",
        "\n",
        "# Export Submission\n",
        "#submission.to_csv('submission.csv', index = False)\n",
        "submission.tail()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}