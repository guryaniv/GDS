{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"413ab8a2a3d5c21b2a0c821566a8d82721bb84aa"},"cell_type":"code","source":"# Load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nfrom skimage import transform\n\n# For Lee Filter - Speckle reduction function\nfrom scipy.ndimage.filters import uniform_filter\nfrom scipy.ndimage.measurements import variance\n\n# Closing\nfrom skimage.morphology import closing, disk\n\n# Gaussian filter\nfrom skimage.filters import gaussian\n\n# Median filter\nfrom skimage.filters.rank import median\n\n# Thresholding\nfrom skimage.filters import threshold_otsu\n\n# Lable regions\nfrom skimage.measure import label, regionprops\n\n# Derive statistical features\nfrom scipy import stats\n\n# Extract Texture Features - GLMC\nfrom skimage.feature import greycomatrix, greycoprops\n\n# Model evaluation\n# Evaluate using Leave One Out Cross Validation\nfrom sklearn.model_selection import LeaveOneOut\nfrom sklearn.model_selection import cross_val_score\n\n# K -Fold\nfrom sklearn.model_selection import KFold\n\n# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\n\n# SVM\nfrom sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"5bfba75aa2d58f06356a0a89ff348ebc977d5d3f"},"cell_type":"code","source":"\n\n\n\n# scaling\ndef scale_img(dframe):\n    final_img = []\n    \n    for i, r in dframe.iterrows():\n        # reshaping images to 75x75\n        band_1 = np.array(r['band_1']).reshape(75, 75)\n        band_2 = np.array(r['band_2']).reshape(75, 75)\n        \n        # Rescale to 0-255 px (local scaling : min-max)\n        b1 = 255*(band_1 - band_1.min()) / (band_1.max() - band_1.min())\n        b2 = 255*(band_2 - band_2.min()) / (band_2.max() - band_2.min())\n        \n        # Rescale to 0-255 px (global scaling(min,max) = (-50,40))\n        b3 = 255*(band_1 - (-50)) / (40 - (-50))\n        b4 = 255*(band_2 - (-50)) / (40 - (-50))\n        \n        # center image\n        p=12 # boundry pixels\n        final_img.append((b1[p:(75-p),p:(75-p)], b2[p:(75-p),p:(75-p)],\n                          b3[p:(75-p),p:(75-p)], b4[p:(75-p),p:(75-p)]))\n    \n    \n    return np.array(final_img,dtype=np.uint8)\n\n# Lee Filter - Speckle reduction\ndef lee_filter(img, size=3):\n    img_mean = uniform_filter(img, (size, size))\n    img_sqr_mean = uniform_filter(img**2, (size, size))\n    img_variance = img_sqr_mean - img_mean**2\n    overall_variance = variance(img)\n    img_weights = img_variance**2 / (img_variance**2 + overall_variance**2)\n    img_output = img_mean + img_weights * (img - img_mean)\n    img_output = 255*(img_output - img_output.min()) / (img_output.max() - img_output.min())\n    return np.array(img_output,dtype=np.uint8)\n\n# function to add, substract and multiply pixels (equivalent to open cv functions)\ndef img_add(image, val = 0):\n    img = np.float16(image) + np.float16(val)\n    img[img>255]=255\n    img[img<0]=0\n    return np.uint8(np.round(img))\n\ndef img_sub(image, val = 0):\n    img = np.float16(image) - np.float16(val)\n    img[img>255]=255\n    img[img<0]=0\n    return np.uint8(np.round(img))\n\ndef img_mult(image, val = 1):\n    img = np.float16(image) * np.float16(val)\n    img[img>255]=255\n    img[img<0]=0\n    return np.uint8(np.round(img))\n\ndef img_mean(image, val = 1):\n    img = (np.float16(image) + np.float16(val))/2\n    img[img>255]=255\n    img[img<0]=0\n    return np.uint8(np.round(img))\n\n\n# Function to return features for an image\ndef shape_features(img_HH,img_HV,glob_img_HH,glob_img_HV):\n    # center image\n    #p=12 # boundry pixels\n    #img_HH = img_HH[p:(75-p),p:(75-p)] #[y1:y2,x1:x2]\n    #img_HV = img_HV[p:(75-p),p:(75-p)]\n    #glob_img_HH = glob_img_HH[p:(75-p),p:(75-p)]\n    #glob_img_HV = glob_img_HV[p:(75-p),p:(75-p)]\n    \n    img = img_HH.copy()\n    # Apply Lee filter - remove speckle\n    img = lee_filter(img)\n    \n    # Apply closing to remove noise\n    img = closing(img, disk(1))\n    \n    # Improve contrast\n    img = img_add(img_mult(img,1.2),-150)\n    \n    # Smooth image\n    img = gaussian(img, sigma=0.8)\n    \n    # reduce noise\n    img = median(img, disk(1))\n    \n    # apply automatic threshold otsu\n    thresh = threshold_otsu(img)\n    binary = img > thresh + 10 # setting higher threshold\n    \n    # select region with maximum area to extract features\n    label_image = label(binary)\n    max_reg = max(regionprops(label_image), key=lambda region: region.area)\n    \n    # get count of regions\n    count_reg = len(regionprops(label_image))\n    \n    # extract max region image boundary\n    minr, minc, maxr, maxc = max_reg.bbox\n    \n    # stats of pixels\n    pixels_HH = glob_img_HH[minr:maxr,minc:maxc][binary[minr:maxr,minc:maxc]]\n    pixels_HV = glob_img_HV[minr:maxr,minc:maxc][binary[minr:maxr,minc:maxc]]\n    \n    stats_HH = stats.describe(pixels_HH)\n    stats_HV = stats.describe(pixels_HH)\n    \n    # GLCM - texture features\n    glcm_HH = greycomatrix(glob_img_HH[minr:maxr,minc:maxc], [3], [0], 256, symmetric=True, normed=True)\n    glcm_HV = greycomatrix(glob_img_HV[minr:maxr,minc:maxc], [3], [0], 256, symmetric=True, normed=True)\n    \n    # return features\n    return np.array([count_reg,\n                     glob_img_HH.mean(),\n                     glob_img_HH.min(),\n                     glob_img_HH.max(),\n                     glob_img_HH.std(),\n                     glob_img_HV.mean(),\n                     glob_img_HV.min(),\n                     glob_img_HV.max(),\n                     glob_img_HV.std(),\n                     max_reg.area,\n                     max_reg.convex_area,\n                     max_reg.eccentricity,\n                     max_reg.equivalent_diameter,\n                     max_reg.extent,\n                     max_reg.filled_area,\n                     max_reg.major_axis_length,\n                     max_reg.minor_axis_length,\n                     max_reg.orientation,\n                     max_reg.perimeter,\n                     max_reg.solidity,\n                     pixels_HH.mean(),\n                     pixels_HH.min(),\n                     pixels_HH.max(),\n                     pixels_HH.std(),\n                     pixels_HH.var(),\n                     stats_HH.kurtosis,\n                     stats_HH.skewness,\n                     pixels_HV.mean(),\n                     pixels_HV.min(),\n                     pixels_HV.max(),\n                     pixels_HV.std(),\n                     pixels_HV.var(),\n                     stats_HV.kurtosis,\n                     stats_HV.skewness,\n                     greycoprops(glcm_HH, 'dissimilarity')[0, 0],\n                     greycoprops(glcm_HH, 'correlation')[0, 0],\n                     greycoprops(glcm_HV, 'dissimilarity')[0, 0],\n                     greycoprops(glcm_HV, 'correlation')[0, 0]\n                    ])\n    ","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true,"_uuid":"93fc3e4a398ef680453af67d7d4293b9e2676a69"},"cell_type":"code","source":"# load dataset\ndf = pd.read_json('../input/train.json')\n\n# Apply local scaling on the images\nX = scale_img(df)\n\n# Dependant variable\ny = np.array(df['is_iceberg'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2a7c028b44d54002900e7997ce350953633103c"},"cell_type":"code","source":"X[0][0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8a5c1caa6f77ad573e14297a24c9187369a541f"},"cell_type":"code","source":"# Extraxt features fomr the images(only HH)\nX_extracted = []\nfor x in X:\n    X_extracted.append(shape_features(img_HH=x[0],img_HV=x[1],glob_img_HH=x[2],glob_img_HV=x[3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3cbd5494d9f92031b57f93edf89b548139d76fe","scrolled":false},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\n\nmodel = VGG16(weights='imagenet', include_top=False)\n\nvgg16_ip = []\n\nfor x in X:\n    img = np.dstack((x[2],x[3],img_sub(x[2],x[3])))\n    img = transform.resize(img, (244,244),mode='reflect')\n    img = preprocess_input(img)\n    vgg16_ip.append(img)\nvgg16_ip = np.array(vgg16_ip)\npred = model.predict(vgg16_ip)\n\nvgg16_features = []\nfor p in pred:\n    vgg16_features.append(p.flatten())\nvgg16_features = np.array(vgg16_features)\n\ndel model,vgg16_ip,p,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfd3e945a574e74b6135045e24a2b239ed828d69"},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\n\nmodel = VGG19(weights='imagenet', include_top=False)\n\nvgg19_ip = []\n\nfor x in X:\n    img = np.dstack((x[2],x[3],img_sub(x[2],x[3])))\n    img = transform.resize(img, (244,244),mode='reflect')\n    img = preprocess_input(img)\n    vgg19_ip.append(img)\nvgg19_ip = np.array(vgg19_ip)\npred = model.predict(vgg19_ip)\n\nvgg19_features = []\nfor p in pred:\n    vgg19_features.append(p.flatten())\nvgg19_features = np.array(vgg19_features)\n\ndel model,vgg19_ip,p,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce04f699ac1624f76bc819995e5bf287dc196f89"},"cell_type":"code","source":"from keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\n\nmodel = ResNet50(weights='imagenet', include_top=False)\n\nresnet_ip = []\n\nfor x in X:\n    img = np.dstack((x[2],x[3],img_sub(x[2],x[3])))\n    img = transform.resize(img, (244,244),mode='reflect')\n    img = preprocess_input(img)\n    resnet_ip.append(img)\nresnet_ip = np.array(resnet_ip)\npred = model.predict(resnet_ip)\n\nresnet_features = []\nfor p in pred:\n    resnet_features.append(p.flatten())\nresnet_features = np.array(resnet_features)\n\ndel model,resnet_ip,p,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67edfa79618921df720cc9531b1d5e0a6b6ca7a6","scrolled":true},"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\n\nmodel = InceptionV3(weights='imagenet', include_top=False)\n\nincept_ip = []\n\nfor x in X:\n    img = np.dstack((x[2],x[3],img_sub(x[2],x[3])))\n    img = transform.resize(img, (244,244),mode='reflect')\n    img = preprocess_input(img)\n    incept_ip.append(img)\nincept_ip = np.array(incept_ip)\npred = model.predict(incept_ip)\n\nincept_features = []\nfor p in pred:\n    incept_features.append(p.flatten())\nincept_features = np.array(incept_features)\n\ndel model,incept_ip,p,pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0612a222d556f9ee680ff96715d82af5159e32a4"},"cell_type":"code","source":"# PCA Analysis\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88b1a067d9889e61d2a6cc151b66466af30e21d9"},"cell_type":"code","source":"pca = PCA(whiten=True)\nsc = StandardScaler()\nip = sc.fit_transform(vgg16_features)                        \npca.fit(ip)\n\nfig = plt.figure(1,figsize=(5,5))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('n_components')\nax.set_ylabel('explained variance')\nax.set_ylim(0,10)\nax.set_xlim(0,100)\nax.plot(pca.explained_variance_)\nprint(\"Evaluated components: \", pca.n_components_ )\nprint(\"Explained variances: \", pca.explained_variance_)\nprint(pd.Series(pca.explained_variance_ >= 2).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67991461dd63a9a035313a9705c046ffad8d1eed"},"cell_type":"code","source":"pca = PCA(whiten=True)\nsc = StandardScaler()\nip = sc.fit_transform(vgg19_features)                        \npca.fit(ip)\n\nfig = plt.figure(1,figsize=(5,5))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('n_components')\nax.set_ylabel('explained variance')\nax.set_ylim(0,10)\nax.set_xlim(0,100)\nax.plot(pca.explained_variance_)\nprint(\"Evaluated components: \", pca.n_components_ )\nprint(\"Explained variances: \", pca.explained_variance_)\nprint(pd.Series(pca.explained_variance_ >= 2).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dee88c5e6cb5816f67fef8ac5e8ff348f3c27c52"},"cell_type":"code","source":"pca = PCA(whiten=True)\nsc = StandardScaler()\nip = sc.fit_transform(resnet_features)                        \npca.fit(ip)\n\nfig = plt.figure(1,figsize=(5,5))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('n_components')\nax.set_ylabel('explained variance')\nax.set_ylim(0,10)\nax.set_xlim(0,100)\nax.plot(pca.explained_variance_)\nprint(\"Evaluated components: \", pca.n_components_ )\nprint(\"Explained variances: \", pca.explained_variance_)\nprint(pd.Series(pca.explained_variance_ >= 3).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"abe8e4d25cbc726c0114b75388629fe90fe70b93"},"cell_type":"code","source":"pca = PCA(whiten=True)\nsc = StandardScaler()\nip = sc.fit_transform(incept_features)                        \npca.fit(ip)\n\nfig = plt.figure(1,figsize=(5,5))\nax = fig.add_subplot(1,1,1)\nax.set_xlabel('n_components')\nax.set_ylabel('explained variance')\nax.set_ylim(0,200)\nax.set_xlim(0,100)\nax.plot(pca.explained_variance_)\nprint(\"Evaluated components: \", pca.n_components_ )\nprint(\"Explained variances: \", pca.explained_variance_)\nprint(pd.Series(pca.explained_variance_ >= 30).value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"161a22f8225d60d309d869fc1df04c459d7700cd","collapsed":true},"cell_type":"code","source":"# Save top 50 PCA components\nnp.savetxt(\"vgg16_features.csv\", Pipeline([('scaling', StandardScaler()), \n                                          ('pca', PCA(n_components=40,whiten=True))]).fit_transform(vgg16_features),\n           delimiter=\",\")\n\nnp.savetxt(\"vgg19_features.csv\", Pipeline([('scaling', StandardScaler()), \n                                          ('pca', PCA(n_components=40,whiten=True))]).fit_transform(vgg19_features),\n           delimiter=\",\")\n\nnp.savetxt(\"resnet_features.csv\", Pipeline([('scaling', StandardScaler()), \n                                          ('pca', PCA(n_components=40,whiten=True))]).fit_transform(resnet_features),\n           delimiter=\",\")\n\nnp.savetxt(\"incept_features.csv\", Pipeline([('scaling', StandardScaler()),\n                                            ('pca', PCA(n_components=40,whiten=True))]).fit_transform(incept_features),\n           delimiter=\",\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}