{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "136fc876-5258-04b6-cced-91f0c34dc73e"
      },
      "source": [
        "Trying some things out. \n",
        "Mostly from here: https://www.kaggle.com/anokas/quora-question-pairs/data-analysis-xgboost-starter-0-35460-lb for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "53e67f4a-30c2-0bc2-cdde-adb86938bf5b"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca482e68-378d-4cd3-ce0e-b735690bec0c"
      },
      "outputs": [],
      "source": [
        "def word_match_share(row):\n",
        "    q1words = {}\n",
        "    q2words = {}\n",
        "    for word in str(row['question1']).lower().split():\n",
        "        if word not in stops:\n",
        "            q1words[word] = 1\n",
        "    for word in str(row['question2']).lower().split():\n",
        "        if word not in stops:\n",
        "            q2words[word] = 1\n",
        "    if len(q1words) == 0 or len(q2words) == 0:\n",
        "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
        "        return 0\n",
        "    shared_words_in_q1 = [w for w in q1words.keys() if w in q2words]\n",
        "    shared_words_in_q2 = [w for w in q2words.keys() if w in q1words]\n",
        "    R = (len(shared_words_in_q1) + len(shared_words_in_q2))/(len(q1words) + len(q2words))\n",
        "    return R\n",
        "\n",
        "\n",
        "def similarity(q1, q2, use_tokenizer = False, remove_stop_words = True):\n",
        "    #this does slightly worse than word_match\n",
        "    \"\"\"\n",
        "    look at the jaccard distance between the sets of unique elements\n",
        "    \"\"\"\n",
        "    if use_tokenizer:\n",
        "        q1 = nltk.word_tokenize(q1.lower())\n",
        "        q2 = nltk.word_tokenize(q2.lower())\n",
        "    else:\n",
        "        q1 = q1.lower().split()\n",
        "        q2 = q2.lower().split()\n",
        "\n",
        "    if remove_stop_words:\n",
        "        q1 = [word for word in q1 if word not in stop_words]\n",
        "        q2 = [word for word in q2 if word not in stop_words]\n",
        "\n",
        "\n",
        "    n = len(np.union1d(q1, q1))\n",
        "    if n != 0:\n",
        "        sim = len(np.intersect1d(q1, q2))/n\n",
        "    else:\n",
        "        sim = 0\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b6cba4a6-b56c-8bef-a12c-9e3f2a597d2d"
      },
      "outputs": [],
      "source": [
        "stops = stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6a002c13-6511-ca2e-b6c2-33cbad8d300b"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/train.csv')\n",
        "df_test = pd.read_csv('../input/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bada6589-0604-8f8c-40b0-2cae7e81b215"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()\n",
        "#Rebalance the classes:\n",
        "#pos_boostrap_sample = df[df[\"is_duplicate\"] == 0].sample(n = 500000, replace = True)\n",
        "#df = pd.concat((pos_boostrap_sample, df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "00b510a4-7583-bf21-f3bb-e504c9a68063"
      },
      "outputs": [],
      "source": [
        "df[\"word_share\"] = df.apply(word_match_share, axis = 1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5a87f8ae-0f80-334c-d98f-2af36f3eed4a"
      },
      "outputs": [],
      "source": [
        "df_test[\"word_share\"] = df_test.apply(word_match_share, axis = 1, raw=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40bc5807-c0c4-f173-eec7-79a4408030e8"
      },
      "outputs": [],
      "source": [
        "X = df[\"word_share\"].values.reshape(-1,1)\n",
        "X_test = df_test[\"word_share\"].values.reshape(-1,1)\n",
        "y = df[\"is_duplicate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2852b08a-f6f2-91fd-99de-1cee92754cbd"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators = 200, max_features = True)\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "189fc9d2-bd29-eb96-8898-a1f01db1c090"
      },
      "outputs": [],
      "source": [
        "preds = model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c906b514-05f5-08a2-fd49-c8eb089b29e9"
      },
      "outputs": [],
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['test_id'] = df_test['test_id']\n",
        "sub['is_duplicate'] = preds\n",
        "sub.to_csv('rf_pred.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b39d23c8-52ee-378c-84e0-26106d5df356"
      },
      "outputs": [],
      "source": [
        "sub.is_duplicate.hist()"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}