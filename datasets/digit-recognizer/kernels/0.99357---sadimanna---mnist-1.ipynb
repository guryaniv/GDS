{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport random, time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2eeffb75f145067208f4fe93f56198e13adcb8f1","collapsed":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad1ec9b6653af9a25121af46c91469d972ad327b","collapsed":true},"cell_type":"code","source":"#print(train_data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d2ecb62b9037c29272a08b4ff49f9596a08dd7b","collapsed":true},"cell_type":"code","source":"train_label = train_data.loc[:,'label']\ntrain_label = train_label.values\n#print(train_label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ff84f611effbe31156b49f0d957a0160eb2364d"},"cell_type":"code","source":"train_images = train_data.loc[:,'pixel0':]\ntrain_images = train_images.values\nimgsize = int(np.sqrt(train_images.shape[1]))\ntrain_images = train_images.reshape((-1,imgsize,imgsize,1))\nprint(train_images.shape)\n\ntrain_img_mean = np.mean(train_images,axis=0)\nprint(train_img_mean.shape)\n\ntrain_images = train_images - train_img_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"016afb272a6ca21c7056a79379b29eb9be72b693","collapsed":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/test.csv')\n#print(test_data.columns)\ntest_images = test_data.loc[:,:].values.reshape((-1,imgsize,imgsize,1))\n#print(test_images.shape)\ntest_images = test_images - train_img_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1abba6f94de2c43268ae9fef5616b0a619b6274e","collapsed":true},"cell_type":"code","source":"val_images = train_images[:2000]\n#print(val_images.shape)\nval_label = train_label[:2000]\ntrain_images = train_images[2000:]\ntrain_label = train_label[2000:]\n#print(train_images.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"a89dd6a0b2eca85959251bf9076b2f74e37e1b73"},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"32392ed77f6baba4184fec2d7d7e1db54bdcd251"},"cell_type":"code","source":"plt.imshow(train_img_mean.reshape(28,28))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11bae4de684ae0b3703edab3e424dc5892a14a7a"},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"55859f6131f07f48daa4c3c7d38bda9a604da5d0"},"cell_type":"code","source":"\ndef get_weights(name,shape):\n    with tf.variable_scope(\"weights\", reuse=tf.AUTO_REUSE): \n        return tf.get_variable(name=name,shape=shape,initializer = tf.contrib.layers.xavier_initializer(uniform=False),regularizer = tf.contrib.layers.l2_regularizer(tf.constant(0.001, dtype=tf.float32)))\n    \ndef get_bias(name,shape):\n    with tf.variable_scope(\"bias\", reuse=tf.AUTO_REUSE):\n        return tf.get_variable(name=name,shape=shape,initializer = tf.zeros_initializer())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"99ffc22c438358dc67f25822d40885bbc7dc655a"},"cell_type":"code","source":"def conv2d(inp,name,kshape,s,padding):\n    with tf.variable_scope(name) as scope:\n        kernel = get_weights('weights',shape=kshape)\n        conv = tf.nn.conv2d(inp,kernel,[1,s,s,1],padding)\n        bias = get_bias('biases',shape=kshape[3])\n        preact = tf.nn.bias_add(conv,bias)\n        convlayer = tf.nn.relu(preact,name=scope.name)\n    return convlayer\n\ndef maxpool(inp,name,k,s):\n    return tf.nn.max_pool(inp,ksize=[1,k,k,1],strides=[1,s,s,1],padding='SAME',name=name)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f80086f83d77692a62145db31db097be104c4484"},"cell_type":"code","source":"def loss(logits,labels):\n    labels = tf.reshape(tf.cast(labels,tf.int64),[-1])\n    #print labels.get_shape().as_list(),logits.get_shape().as_list()\n    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels,logits=logits,name='cross_entropy_per_example')\n    cross_entropy_mean = tf.reduce_mean(cross_entropy,name='cross_entropy')\n    total_loss = tf.add(tf.reduce_sum(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)),cross_entropy_mean,name='total_loss')\n    return total_loss\n\ndef top_1_acc(logits,true_labels):\n    pred_labels = tf.argmax(logits,1)\n    true_labels = tf.cast(true_labels,tf.int64)\n    #print pred_labels.get_shape().as_list(),true_labels\n    correct_pred = tf.cast(tf.equal(pred_labels, true_labels), tf.float32)\n    accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n    return accuracy\n\ndef top_5_acc(logits,true_labels):\n    true_labels = tf.cast(true_labels,tf.int64)\n    return tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits, true_labels, k=5,name='top_5_acc'), tf.float32))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6a963aacd59f177b9f1756d12cd06b4e2d8dbe24"},"cell_type":"code","source":"def get_new_size():\n    new_size = 28 + random.choice([6,12,0])\n    return [new_size,new_size]\n\ndef get_random_augmentation_combinations(length):\n    out = [False,True]\n    return [random.choice(out) for i in range(length)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1d6247745a705604f08a9ac3e49ee6d3d715cfeb"},"cell_type":"code","source":"index = np.arange(train_images.shape[0])\n\n#........ This part will used to get training data for each epoch during training\nnum_epochs = 100\nbatch_size = 50\nnumiter = 800\nne = 0\n\nfeed_images = tf.placeholder(tf.float32,shape=(None,28,28,1))\nfeed_labels = tf.placeholder(tf.float32,shape=(None,))\nlr = tf.placeholder(tf.float32,shape=())\nkeep_prob = tf.placeholder(tf.float32,shape=())\naug_img = tf.placeholder(tf.float32,shape=(28,28,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8290a8196d577f799ee6bb0501f51ad69662bfa"},"cell_type":"code","source":"#Data Augmentation\n\nimg_scale_crop = tf.random_crop(tf.image.resize_images(aug_img,get_new_size()),[28,28,1])\n#img_rand_flip_lr = tf.image.random_flip_left_right(aug_img)\n#img_rand_flip_ud = tf.image.random_flip_up_down(aug_img)\n#img_con = tf.image.random_contrast(aug_img,0.01,0.25)\n#img_br = tf.image.random_brightness(aug_img,0.25)\nimg_rot = tf.contrib.image.rotate(aug_img,1.57*(-0.5+random.random()),interpolation='BILINEAR')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ffcafe6c63b3b416b0a577c642b50d0874dfe86"},"cell_type":"code","source":"with tf.device('/gpu:0'):\n    conv1 = conv2d(feed_images,'conv1',[3,3,1,32],1,'SAME')\n    conv2 = conv2d(conv1, 'conv2',[3,3,32,32],1,'SAME')\n    pool1 = maxpool(conv2,'pool1',2,2)\n    #size = N,14,14,32\n    conv3 = conv2d(pool1,'conv3',[3,3,32,64],1,'SAME')\n    conv4 = conv2d(conv3,'conv4',[3,3,64,64],1,'SAME')\n    pool2 = maxpool(conv4,'pool2',2,2)\n    #size N,7,7,64\n    conv5 = conv2d(pool2,'conv5',[3,3,64,128],1,'VALID')\n    #size N,6,6,64\n    conv6 = conv2d(conv5,'conv6',[3,3,128,128],1,'SAME')\n    #size N,6,6,128\n    pool3 = maxpool(conv6,'pool3',2,2)\n    #size N,3,3,128\n    conv7 = conv2d(pool3,'conv7',[1,1,128,256],1,'SAME')\n    #size N,3,3,256\n    flatpool = tf.contrib.layers.flatten(conv7)\n    fc1 = tf.contrib.layers.fully_connected(flatpool,1024,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.001, dtype=tf.float32)))\n    dropout1 = tf.nn.dropout(fc1,keep_prob)\n    fc2 = tf.contrib.layers.fully_connected(dropout1,1024,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.001, dtype=tf.float32)))\n    dropout2 = tf.nn.dropout(fc2,keep_prob)\n    logits = tf.contrib.layers.fully_connected(dropout2,10,weights_regularizer=tf.contrib.layers.l2_regularizer(tf.constant(0.001, dtype=tf.float32)))\n    \n    cost = loss(logits,feed_labels)\n\n    opt_mom = tf.train.AdamOptimizer(learning_rate=0.0001)#,momentum=0.9)\n    opt = opt_mom.minimize(cost)\n\n    acc = top_1_acc(logits,feed_labels)\n#Defined outside gpu0 device since tf.nn.in_top_k is not supported for gpu kernel\nvalacc = top_5_acc(logits,feed_labels)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28117717de29688199794e23457500803d2360ae"},"cell_type":"code","source":"sess = tf.Session()\nsess.run(tf.global_variables_initializer())\ntl=[]\nvl=[]\nta=[]\nta5 = []\nva=[]\nva5 = []\nne=0\nwhile(ne<20):\n    stime = time.time()\n    print('Epoch::',ne+1,'...')\n    \n    #Shuffling the Dataset\n    if ne != 0:\n        np.random.shuffle(index)\n        train_images = train_images[index]\n        train_label = train_label[index]\n    \n    for niter in range(numiter):\n    \n        if (niter+1)%400==0:\n            print('iter..',niter+1)\n        \n        #Getting next Batch\n        offset = niter*batch_size\n        x_iter, y_iter = np.array(train_images[offset:offset+batch_size,:,:]), np.array(train_label[offset:offset+batch_size])\n        \n        #Data Augmentation\n        for n in range(batch_size):\n            args = get_random_augmentation_combinations(1)\n            if args[0]:\n                x_iter[n] = sess.run(img_rot,feed_dict={aug_img:x_iter[n]})\n        \n        feed_trdict={feed_images:x_iter,feed_labels:y_iter,keep_prob:0.6}#,lr:0.01\n            \n        #Train the optimizer\n        sess.run(opt,feed_dict=feed_trdict)\n\n    #Calculate accuracy of Training set\n    cc = sess.run(cost,feed_dict=feed_trdict)\n    tr_acc = sess.run(acc,feed_dict = {feed_images:x_iter,feed_labels:y_iter,keep_prob:1.0})\n    top5_tr_acc = sess.run(valacc,feed_dict = {feed_images:x_iter,feed_labels:y_iter,keep_prob:1.0})\n    ta.append(tr_acc)\n    ta5.append(top5_tr_acc)\n    tl.append(cc)\n    \n    #Calculate accuracy of Validation set\n    val_loss = sess.run(cost,feed_dict = {feed_images:val_images,feed_labels:val_label,keep_prob:1.0})\n    top5_val_acc = sess.run(valacc,feed_dict = {feed_images:val_images,feed_labels:val_label,keep_prob:1.0})\n    top1_val_acc = sess.run(acc,feed_dict = {feed_images:val_images,feed_labels:val_label,keep_prob:1.0})\n    va.append(top1_val_acc)\n    va5.append(top5_val_acc)\n    vl.append(val_loss)\n    \n    #print 'Epoch..',ne+1,'...'\n    print('Training accuracy-> Top-1::',tr_acc*100,'%','Top-5:: ',top5_tr_acc*100,'%',' Training cost::',cc)\n    print('Top-1 Validation accuracy::',top1_val_acc*100,'Top-5 Val Accuracy:: ',top5_val_acc*100,'%',' Val loss: ',val_loss)\n    print('Time reqd.::',(time.time()-stime)/60,'mins...')\n\n    ne+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3635e57dd8c5797546418129a5316854a258c49e"},"cell_type":"code","source":"plt.plot(ta)\nplt.plot(va)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbeed37af3bf1caa74de903a42b74a390eb84235"},"cell_type":"code","source":"plt.plot(ta5)\nplt.plot(va5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b1c861bae61d223d9ebbe0cffcee6f7d1f5b766"},"cell_type":"code","source":"plt.plot(tl)\nplt.plot(vl)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e50486fcfe8cef9b23e4faeb4848031f19f0d799"},"cell_type":"code","source":"test_img_preds = tf.nn.softmax(logits)\ntest_preds = sess.run(test_img_preds,feed_dict={feed_images:test_images,keep_prob:1.0})\ntest_pred_label = np.argmax(test_preds,axis=1)\nprint(test_pred_label)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41ef8a5444b60ca13cbccc38d6b0171cea46f1bc","collapsed":true},"cell_type":"code","source":"test_data = {'ImageId':[],'Label':[]}\nfor i in range(1,28001):\n    test_data['ImageId'].append(i)\n    test_data['Label'].append(test_pred_label[i-1])\n#print(test_data)\n\ntest_df = pd.DataFrame(test_data,columns=['ImageId','Label'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea5b08f016e2e05385502fefe4769ceea6b125af","collapsed":true},"cell_type":"code","source":"test_df.to_csv('sample_submission.csv',sep=',',index=False,header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"34cae0a582dae95de24ff4c54d9b69f24a8f1f50"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}