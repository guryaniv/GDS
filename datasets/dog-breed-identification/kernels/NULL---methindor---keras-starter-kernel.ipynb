{"nbformat": 4, "cells": [{"execution_count": null, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "from IPython.core.debugger import set_trace\n", "import cv2\n", "from tqdm import tqdm\n", "from sklearn.model_selection import train_test_split\n", "from keras.preprocessing.image import ImageDataGenerator\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.layers.core import Activation\n", "from keras.layers.core import Flatten\n", "from keras.layers.core import Dense\n", "from keras.layers import Dropout\n", "from keras.models import  Model\n", "from keras import optimizers\n", "from os import makedirs\n", "from os.path import join, exists, expanduser\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "metadata": {"_uuid": "29af90ddea6dc4135afd1e754684cefe2bca9abe", "_cell_guid": "2539a002-800a-43d0-b96c-52af69d08a38"}}, {"source": ["***Show input files of dog-breed- identification***"], "cell_type": "markdown", "metadata": {"_uuid": "e443153ba1a78e1351ad6740524c3d00d1c35549", "_cell_guid": "a5d4d8e0-6461-4630-9dda-bf600e3ae430"}}, {"execution_count": null, "outputs": [], "source": ["!ls ../input/dog-breed-identification\n"], "cell_type": "code", "metadata": {"_uuid": "cb79ec37199ff66574e6b4be03ce52a5967c781e", "_cell_guid": "2be83c0d-0d0c-4cf0-9392-8acb5219fed9"}}, {"source": ["***Create dirs vor pretrained keras models***"], "cell_type": "markdown", "metadata": {"_uuid": "fbdc8c6ca84ca8ecfb3ff2c5cf8ff1f6a97c8021", "_cell_guid": "abc59e93-0c2a-4823-8649-7a6ed84d8635"}}, {"execution_count": null, "outputs": [], "source": ["cache_dir = expanduser(join('~', '.keras'))\n", "if not exists(cache_dir):\n", "    makedirs(cache_dir)\n", "models_dir = join(cache_dir, 'models')\n", "if not exists(models_dir):\n", "    makedirs(models_dir)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "790143b060fd8767c228ddfcc743d1d6f08c0692", "_cell_guid": "f2131c68-d513-4e79-be40-2de2c665bf8e"}}, {"execution_count": null, "outputs": [], "source": ["!ls ../input/inceptionv3"], "cell_type": "code", "metadata": {"_uuid": "f37bb0d824b79439f4c6e72b692c635d01ccf819", "_cell_guid": "57473f9f-2b85-4328-9ab1-885fcbde467a"}}, {"source": ["***Copy pretrained keras model in the new dir***"], "cell_type": "markdown", "metadata": {"_uuid": "2b995cb040c82b31c473a0e54f81fe541056f077", "_cell_guid": "b4893ef5-87a0-4f4a-8a33-9082b79ca372"}}, {"execution_count": null, "outputs": [], "source": ["!cp  ../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/\n"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "2c72f81720185606314b1cdd0646aca3a848c9f8", "_cell_guid": "b59cdec4-1837-4a47-8e58-9cbc64a0e63c"}}, {"execution_count": null, "outputs": [], "source": ["!ls ~/.keras/models/"], "cell_type": "code", "metadata": {"_uuid": "8bf13254c33b9bb03df8cc81a9cae195cfe0eb70", "_cell_guid": "9e14a256-b04a-40c2-af53-4af2192d041c"}}, {"source": ["**Load CSV-File with pandas and print the first ten rows**"], "cell_type": "markdown", "metadata": {"_uuid": "d8690d66c3d222c6ecde6221584b59cc89d916fd", "_cell_guid": "153a0599-12a8-4e61-a646-cc5308f109fa"}}, {"execution_count": null, "outputs": [], "source": ["df_train = pd.read_csv(\"../input/dog-breed-identification/labels.csv\")\n", "df_train.head(10)"], "cell_type": "code", "metadata": {"_uuid": "97c54cb7d53e3e5bfe7b28513a3891c723d1b4ba", "_cell_guid": "a9534a45-0687-4d90-a40a-4c4f2d4dec8d"}}, {"source": ["***Visualize trainingsdata distribution***\n"], "cell_type": "markdown", "metadata": {"_uuid": "48ca27106d26898d7a70edb32d69b6fedcb04ba1", "_cell_guid": "64b711f9-84d4-4290-89dd-f9f675343564"}}, {"execution_count": null, "outputs": [], "source": ["ax=pd.value_counts(df_train['breed'],ascending=True).plot(kind='barh',\n", "                                                       fontsize=\"40\",\n", "                                                       title=\"Class Distribution\",\n", "                                                       figsize=(50,100))\n", "ax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\n", "ax.xaxis.label.set_size(40)\n", "ax.yaxis.label.set_size(40)\n", "ax.title.set_size(60)\n", "\n"], "cell_type": "code", "metadata": {"_uuid": "511f4885630c4c48ae11512ebfa5029a4dd38177", "_cell_guid": "3c866014-b3e8-412b-8e40-7baee04b2faf"}}, {"source": ["***For the sake of simplicity, we only take the 10 classes with the most images***"], "cell_type": "markdown", "metadata": {"_uuid": "4a0ea278079886172a71f3895a09550931715c36", "_cell_guid": "026d304f-9bd2-48c7-afff-9951ec416d67"}}, {"execution_count": null, "outputs": [], "source": ["# take a subset of the trainigsdata with die ten most frequently classes\n", "NUM_CLASSES=10\n", "print(\"Dataset shape before: {0}\".format(df_train.shape))\n", "selected_breed_list = list(df_train.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n", "df_sub_train=df_train[df_train['breed'].isin(selected_breed_list)]\n", "print(\"Dataset shape after: {0}\".format(df_sub_train.shape))\n", "\n", "# plot the distribution of this subset\n", "ax=pd.value_counts(df_sub_train['breed'],ascending=True).plot(kind='barh',\n", "                                                       fontsize=\"40\",\n", "                                                       title=\"Class Distribution\",\n", "                                                       figsize=(50,20))\n", "ax.set(xlabel=\"Images per class\", ylabel=\"Classes\")\n", "ax.xaxis.label.set_size(40)\n", "ax.yaxis.label.set_size(40)\n", "ax.title.set_size(60)\n"], "cell_type": "code", "metadata": {"_uuid": "fdfc4909a0d4e5c9a96a04997d5cd0aba1e3f17c", "_cell_guid": "fb81ad48-8724-43cc-9201-87fedc357bd1"}}, {"source": ["***Load the traingingsdata***"], "cell_type": "markdown", "metadata": {"_uuid": "de5ee485d0c52b2e772d21385ea47218066b6df3", "_cell_guid": "cf4bc4b2-4272-4e5d-a84b-0ae8cea8850a"}}, {"execution_count": null, "outputs": [], "source": ["IMG_WIDTH=250\n", "IMG_Height=250\n", "images=[]\n", "classes=[]\n", "targets_series = pd.Series(df_sub_train['breed'])\n", "one_hot = pd.get_dummies(targets_series, sparse=True)\n", "one_hot_labels = np.asarray(one_hot)\n", "i = 0\n", "#load training images\n", "for f, breed in tqdm(df_sub_train.values):\n", "    img = cv2.imread('../input/dog-breed-identification/train/{}.jpg'.format(f))\n", "    images.append(cv2.resize(img, (IMG_WIDTH, IMG_Height)))   \n", "    label = one_hot_labels[i]\n", "    classes.append(label)\n", "    \n", "    "], "cell_type": "code", "metadata": {"_uuid": "865aea61e31b13309b783f5272e877c1e840cb38", "_cell_guid": "ab672901-3d0e-4f69-aae9-635998eec073"}}, {"source": ["***Split trainigsdata in  a train and valid subset***"], "cell_type": "markdown", "metadata": {"_uuid": "ebeb2286e5e7a9ba89c06edcb82fc4eb388835f0", "_cell_guid": "adbd10ea-2437-4191-b6e3-647ffea265e7"}}, {"execution_count": null, "outputs": [], "source": ["classes_raw = np.array(classes, np.uint8)\n", "images_raw = np.array(images, np.float32)\n", "\n", "x_train, x_valid, y_train, y_valid = train_test_split(images_raw, classes_raw, test_size=0.2, random_state=1)\n", "\n", "print(\"Trainigsdata shape : {0}\".format(x_train.shape))\n", "print(\"Trainingslabel shape : {0}\".format(y_train.shape))\n", "print(\"Validdata shape : {0}\".format(x_valid.shape))\n", "print(\"Validlabel shape : {0}\".format(y_valid.shape))\n"], "cell_type": "code", "metadata": {"_uuid": "dc17854f091f7415e87dc3bd51c7e2e2fb283b49", "_cell_guid": "f09aeb49-b2e5-4078-bcc5-c0cbd08b78b5"}}, {"source": ["*** Generate batches of images with data augmentation***"], "cell_type": "markdown", "metadata": {"_uuid": "67132f8fc1a3fb4610af2c835ea38379e1a475db", "_cell_guid": "9c44c3b7-72e0-4f1f-b977-6dbbeb884da6"}}, {"execution_count": null, "outputs": [], "source": ["train_datagen = ImageDataGenerator(\n", "        rescale=1. / 255,   \n", "        shear_range=0.2,\n", "        zoom_range=0.2,\n", "        horizontal_flip=True)\n", "       \n", "\n", "valid_datagen = ImageDataGenerator(rescale=1. / 255)\n", "\n", "train_generator = train_datagen.flow(x_train, y_train, batch_size=32)\n", "valid_generator = valid_datagen.flow(x_valid, y_valid, batch_size=32)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "c8e0704894a5714450b896721801d2e8242b2461", "_cell_guid": "a80da513-5816-4cac-83b3-ed5c53eccf06"}}, {"source": ["***Define the model***\n", "\n", "***In this case we use InceptionV3***"], "cell_type": "markdown", "metadata": {"_uuid": "44fbd6a6b8ea6b6aa104100c02aa4ffd2522e462", "_cell_guid": "d9b7ca25-5d66-4879-8685-125cf4d41380"}}, {"execution_count": null, "outputs": [], "source": ["base_model=InceptionV3(include_top=False, weights='imagenet', \n", "                        input_shape=(IMG_WIDTH, IMG_Height, 3),\n", "                        classes=NUM_CLASSES)\n", "# Adding custom Layers\n", "model = base_model.output\n", "model = Flatten()(model)\n", "model = Dense(1024, activation=\"relu\")(model)\n", "model = Dropout(0.5)(model)\n", "model = Dense(1024, activation=\"relu\")(model)\n", "predictions = Dense(NUM_CLASSES, activation=\"softmax\")(model)\n", "# creating the final model\n", "model_final = Model(input=base_model.input, output=predictions)\n", "# compile the model\n", "model_final.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9),\n", "                           metrics=[\"accuracy\"])\n", "#print the model\n", "model_final.summary()"], "cell_type": "code", "metadata": {"_uuid": "66087002484f75c17707ff67dff270fc2b8a82ce", "_cell_guid": "4fcad287-66e7-499d-b244-db846c897b8e"}}, {"source": ["***Train the model***"], "cell_type": "markdown", "metadata": {"_uuid": "b39c112ce0fb582a5deae861ca6f8cfd84bd0970", "_cell_guid": "c1e80ff5-d3e7-47b5-8551-1228ab4d4e77"}}, {"execution_count": null, "outputs": [], "source": ["# Train the model\n", "history=model_final.fit_generator(\n", "        train_generator,\n", "        samples_per_epoch=912,\n", "        epochs=100,\n", "        validation_data=valid_generator,\n", "        nb_val_samples=229)"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "11a389d8ef055077957f2ce1f02a3afbbb703ed8", "_cell_guid": "c6b9c9e8-4a9e-47a3-a523-a3685ac27504"}}, {"source": ["Result after training: loss:  loss: 0.2278 - acc: 0.9297 - val_loss: 0.2109 - val_acc: 0.9212\n"], "cell_type": "markdown", "metadata": {"_uuid": "6ed19ccb678055f536c1a92d2e471b9d61c67057", "_cell_guid": "c0fe7180-5045-4394-aae6-4f53c7c0dd0c"}}, {"source": ["***Plot the acc and loss***"], "cell_type": "markdown", "metadata": {"_uuid": "a9d82a60d6e9cd2b9e945753820e19562188053e", "_cell_guid": "ac7a82bc-1b79-403b-a803-234b3e58160b"}}, {"execution_count": null, "outputs": [], "source": ["# summarize history for accuracy\n", "plt.plot(history.history['acc'])\n", "plt.plot(history.history['val_acc'])\n", "plt.title('model accuracy')\n", "plt.ylabel('accuracy')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'test'], loc='upper left')\n", "plt.show()\n", "# summarize history for loss\n", "plt.plot(history.history['loss'])\n", "plt.plot(history.history['val_loss'])\n", "plt.title('model loss')\n", "plt.ylabel('loss')\n", "plt.xlabel('epoch')\n", "plt.legend(['train', 'test'], loc='upper left')\n", "plt.show()"], "cell_type": "code", "metadata": {"collapsed": true, "_uuid": "5ecaf96009b44774d422701b25fab445e6b3da92", "_cell_guid": "adc61cf1-3511-4989-ba75-0d5f2c4c57c0"}}, {"source": [], "cell_type": "markdown", "metadata": {"_uuid": "13dba3fdfed7d7d7a57e51da3c2ebd157a7c91a1", "_cell_guid": "3585626a-3646-4c84-8a99-6beceff8fa64"}}, {"source": ["To improve the accuracy increase the image size"], "cell_type": "markdown", "metadata": {"_uuid": "813fabde67cc5e55ded4248d79029d1e07bf9862", "_cell_guid": "6bed8d16-98ea-4d14-95cc-0c7538014fd1"}}], "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}}, "nbformat_minor": 1}