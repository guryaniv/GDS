{"cells":[{"metadata":{"trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport pandas as pd\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import RandomForestClassifier \nfrom functools import partial\nimport scipy as sp\nfrom sklearn.decomposition import TruncatedSVD,PCA\nimport collections\nimport json\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom stemming.porter2 import stem\nfrom nltk.tokenize import word_tokenize\nimport collections\nimport json\nimport os\nimport sklearn\nfrom sklearn.metrics import confusion_matrix\nimport nltk\nfrom nltk import word_tokenize\nfrom collections import Counter\nfrom functools import partial\nfrom math import sqrt\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\n\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.metrics import confusion_matrix as sk_cmatrix\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def get_cat_val(X, arr, cat):\n    cat_list = []\n    for ind in arr:\n        cat_list.append(X[ind, cat])\n    return cat_list\n\ndef get_dog_val(X, arr, dog):\n    dog_list = []\n    for ind in arr:\n        dog_list.append(X[ind, dog])\n    return dog_list\ndef weighted_average(item):\n    try:\n        return np.average(item, weights=np.arange(len(item), 0, -1))\n    except ZeroDivisionError:\n        return 0\ndef get_train_meta():\n    x_train = pd.read_csv(\"../input/train/train.csv\")\n    label_annotations = collections.defaultdict(list)\n    label_scores = collections.defaultdict(list)\n    for file in os.listdir('../input/train_metadata/'):\n        tmp = file.split()[0].split('.json')[0]\n        key, val = tmp.split('-') \n        try:\n            with open('../input/train_metadata/'+file) as f:\n                data = json.load(f)\n                if data.get('labelAnnotations'):\n                    for element in data['labelAnnotations']:\n                        label = element['description']\n                        score = element['score']\n\n                        label_annotations[key].append(label)\n                        label_scores[key].append(score)\n                else: \n                    label_annotations[key].append('N/A')\n                    label_scores[key].append(-1)\n        except FileNotFoundError:\n            print('Oopsie')\n\n    x_train['label_annotation'] = x_train['PetID'].map(label_annotations)\n    x_train['label_score'] = x_train['PetID'].map(label_scores)\n\n    x_train['label_annotation'] = [[word_tokenize(word) for word in sentence] for sentence in x_train['label_annotation']]\n\n    flatten = lambda l: [item for sublist in l for item in sublist]\n    x_train['label_annotation'] = x_train['label_annotation'].map(flatten)\n    x_train['label_annotation'] = [[stem(word) for word in sentence] for sentence in x_train['label_annotation']]\n    list_to_string = lambda l: ' '.join(l)\n    x_train['label_annotation'] = x_train['label_annotation'].map(list_to_string)\n\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(x_train['label_annotation'])\n\n    ind = x_train.index.values\n    cat_val = get_cat_val(X, ind, vectorizer.vocabulary_['cat'])\n    dog_val = get_dog_val(X, ind, vectorizer.vocabulary_['dog'])\n    x_train.loc[:, 'label_cat'] = cat_val\n    x_train.loc[:, 'label_dog'] = dog_val\n    x_train = x_train.drop(columns=['label_annotation'])\n    x_train['label_score'] = x_train['label_score'].map(weighted_average)\n    return x_train\n\ndef get_test_meta():\n    x_test = pd.read_csv(\"../input/test/test.csv\")\n    label_annotations = collections.defaultdict(list)\n    label_scores = collections.defaultdict(list)\n    for file in os.listdir('../input/test_metadata/'):\n        tmp = file.split()[0].split('.json')[0]\n        key, val = tmp.split('-') \n        try:\n            with open('../input/test_metadata/'+file) as f:\n                data = json.load(f)\n                if data.get('labelAnnotations'):\n                    for element in data['labelAnnotations']:\n                        label = element['description']\n                        score = element['score']\n\n                        label_annotations[key].append(label)\n                        label_scores[key].append(score)\n                else: \n                    label_annotations[key].append('N/A')\n                    label_scores[key].append(-1)\n        except FileNotFoundError:\n            print('Oopsie')\n\n    x_test['label_annotation'] = x_test['PetID'].map(label_annotations)\n    x_test['label_score'] = x_test['PetID'].map(label_scores)\n\n    x_test['label_annotation'] = [[word_tokenize(word) for word in sentence] for sentence in x_test['label_annotation']]\n\n    flatten = lambda l: [item for sublist in l for item in sublist]\n    x_test['label_annotation'] = x_test['label_annotation'].map(flatten)\n    x_test['label_annotation'] = [[stem(word) for word in sentence] for sentence in x_test['label_annotation']]\n    list_to_string = lambda l: ' '.join(l)\n    x_test['label_annotation'] = x_test['label_annotation'].map(list_to_string)\n\n    vectorizer = TfidfVectorizer()\n    X = vectorizer.fit_transform(x_test['label_annotation'])\n\n    ind = x_test.index.values\n    cat_val = get_cat_val(X, ind, vectorizer.vocabulary_['cat'])\n    dog_val = get_dog_val(X, ind, vectorizer.vocabulary_['dog'])\n    x_test.loc[:, 'label_cat'] = cat_val\n    x_test.loc[:, 'label_dog'] = dog_val\n    x_test = x_test.drop(columns=['label_annotation'])\n    x_test['label_score'] = x_test['label_score'].map(weighted_average)\n    return x_test\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"#train = pd.read_csv(\"../input/petfinder-adoption-prediction/train/train.csv\")\n#test = pd.read_csv(\"../input/petfinder-adoption-prediction/test/test.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"train = get_train_meta()\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"test = get_test_meta()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"def extract_text_features(text):\n    tp = type(text) is str\n    if not tp:\n        text = \"fsdfl\"\n    features = []\n    header = []\n\n    header.append(\"PetID\")\n    bag_of_words = nltk.word_tokenize(text)\n    # Total amount of words\n    header.append(\"Amount of Words\")\n    features.append(len(bag_of_words))\n\n    sent_text = nltk.sent_tokenize(text) \n\n\n    # Amount of sentences\n\n    header.append(\"Amount of Sentences\")\n    features.append(len(sent_text))\n\n    \n    if not tp:\n        features = list(np.zeros(len(header)-1))\n    return header, features\n    #print(tokens)\n    \ndef get_train_text_and_name_features():\n    training_df = pd.read_csv('../input/train/train.csv')\n    text_data = training_df[[\"PetID\",\"Description\",\"Name\",\"AdoptionSpeed\"]]\n\n    text_features_table = []\n    name_features_table = []\n    counter = 0 \n    for (PID,profile,name,a_s) in text_data.values:\n\n        header,features = extract_text_features(profile)\n        text_features_table.append([PID]+features)\n    text_features_pd = pd.DataFrame(text_features_table,columns=header)\n    return text_features_pd\n\n\ndef get_test_text_and_name_features():\n    test_df = pd.read_csv('../input/test/test.csv')\n    text_data = test_df[[\"PetID\",\"Description\",\"Name\"]]\n\n    text_features_table = []\n    name_features_table = []\n    counter = 0 \n    for (PID,profile,name) in text_data.values:\n\n        header,features = extract_text_features(profile)\n        text_features_table.append([PID]+features)\n    text_features_pd = pd.DataFrame(text_features_table,columns=header)\n    return text_features_pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9f761b784b4a81feed294b3b713510193edc773f","collapsed":true,"trusted":false},"cell_type":"code","source":"des_train = get_train_text_and_name_features()\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"train['PetID']=train['PetID'].astype(str)\ntest['PetID']=test['PetID'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"039ac2cb53f2c43465e25160c31f9b8a74246d56","collapsed":true,"trusted":false},"cell_type":"code","source":"des_test = get_test_text_and_name_features()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"AoW_train = pd.DataFrame(des_train['Amount of Words'])\nAoW_test = pd.DataFrame(des_test['Amount of Words'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72e7fc11b1ecf6873b959d3577496c364919c85b","collapsed":true,"trusted":false},"cell_type":"code","source":"x_train = train.join(AoW_train)\nx_test = test.join(AoW_test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"\ndef extract_features(X):\n    X_features = X.drop([\"Name\",\"RescuerID\",\"Description\",\"PetID\"],axis=1)\n    return X_features\nx_train = extract_features(x_train)\nx_testt = extract_features(x_test)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"X_mean = x_train.Fee.mean(axis=0)\nX_std = x_train.Fee.std(axis=0)\nx_train.Fee = (x_train.Fee-X_mean)/X_std\nx_testt.Fee = (x_train.Fee-X_mean)/X_std","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2c676304977cfb548356c32f09f06dbee5f6228b","collapsed":true,"trusted":false},"cell_type":"code","source":"y_train = train['AdoptionSpeed'].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d371c9e17eabaedc338fe9d46fdb80776792e2e4","collapsed":true,"trusted":false},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import StratifiedKFold\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7a13fc482a3b10a6a4dfeed5ee87175c923baf3","collapsed":true,"trusted":false},"cell_type":"code","source":"xgb_params = {\n    'eval_metric': 'rmse',\n    'seed': 1337,\n    'silent': 1,\n}\ndef run_xgb(params, X_train, X_test):\n    n_splits = 5\n    verbose_eval = 1000\n    num_rounds = 30000\n    early_stop = 500\n\n    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1337)\n\n    oof_train = np.zeros((X_train.shape[0]))\n    oof_test = np.zeros((X_test.shape[0], n_splits))\n\n    i = 0\n\n    for train_idx, valid_idx in kf.split(X_train, X_train['AdoptionSpeed'].values):\n\n        X_tr = X_train.iloc[train_idx, :]\n        X_val = X_train.iloc[valid_idx, :]\n\n        y_tr = X_tr['AdoptionSpeed'].values\n        X_tr = X_tr.drop(['AdoptionSpeed'], axis=1)\n\n        y_val = X_val['AdoptionSpeed'].values\n        X_val = X_val.drop(['AdoptionSpeed'], axis=1)\n\n        d_train = xgb.DMatrix(data=X_tr, label=y_tr, feature_names=X_tr.columns)\n        d_valid = xgb.DMatrix(data=X_val, label=y_val, feature_names=X_val.columns)\n\n        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n        model = xgb.train(dtrain=d_train, num_boost_round=num_rounds, evals=watchlist,\n                         early_stopping_rounds=early_stop, verbose_eval=verbose_eval, params=params)\n\n        valid_pred = model.predict(xgb.DMatrix(X_val, feature_names=X_val.columns), ntree_limit=model.best_ntree_limit)\n        test_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit)\n\n        oof_train[valid_idx] = valid_pred\n        oof_test[:, i] = test_pred\n\n        i += 1\n    return model, oof_train, oof_test\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9c7b0b302a2fc575b32fa6c81c11c5e2ecc5e2d7","collapsed":true,"trusted":false},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return -cohen_kappa_score(y, preds, weights='quadratic')\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X = X, y = y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n    \n    def predict(self, X, coef):\n        preds = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3, 4])\n        return preds\n    \n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e8e7279ee2ebdbb59f424c90ae0430e5f7b40264","collapsed":true,"trusted":false},"cell_type":"code","source":"def qwk(estimator,X,y, additionals = None):\n    N = 5\n    # compute matrix W\n    W = np.zeros((N,N))     \n    for i in range(N):\n        for j in range(N):\n            W[i,j]=((i-j)**2)/((N-1)**2)\n            \n    # Compute (confusion) matrix O\n    actuals = y     \n    if additionals is not None:\n        preds = estimator.predict(X,additionals)\n    else:\n        preds = estimator.predict(X)\n    O = confusion_matrix(actuals,preds)\n    O = O/O.sum()\n    \n    # Compute Matrix E\n    act_hist=np.zeros([N])\n    for act in actuals:\n        act_hist[act]+=1\n    pred_hist=np.zeros([N])\n    for pred in preds:\n        pred_hist[pred]+=1    \n    E = np.outer(act_hist,pred_hist)\n    E = E/E.sum()\n    \n    #Compute the final score\n    num = 0\n    den = 0\n    for i in range(N):\n        for j in range(N):\n            num+=W[i,j]*O[i,j]\n            den+=W[i,j]*E[i,j]\n    k = 1-num/den\n    \n    \n    return k\n            ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e6263a60f0af03217f9e970deb265add1e52e52","trusted":false},"cell_type":"code","source":"model, oof_train, oof_test = run_xgb(xgb_params, x_train,x_testt)\noptR = OptimizedRounder()\noptR.fit(oof_train, y_train)\ncoefficients = optR.coefficients()\nkappa = qwk(optR,oof_train,y_train, additionals=coefficients)\nprint(\"QWK = \", kappa)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56f317379a13a3fa94ea3c2c376dbb9186cd1f2a","trusted":false},"cell_type":"code","source":"coefficients_ = coefficients.copy()\nkappa = qwk(optR,oof_train,y_train, additionals=coefficients_)\nprint(\"QWK = \", kappa)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"test_predictions = optR.predict(oof_test.mean(axis=1), coefficients_).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"submission = pd.DataFrame({'PetID': x_test['PetID'].values, 'AdoptionSpeed': test_predictions})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":1}