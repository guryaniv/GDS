{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "import random\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.cross_validation import train_test_split,cross_val_score\nfrom sklearn import preprocessing\n\n# Reading files \n\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\n# Converting date into datetime format\ntrain['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\n# Dropping original date column\ntrain = train.drop('Original_Quote_Date', axis=1)   \n\ntest['Date'] = pd.to_datetime(pd.Series(test['Original_Quote_Date']))\ntest = test.drop('Original_Quote_Date', axis=1)\n\n## Seperating date into 3 columns\ntrain['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\ntrain['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\ntrain['weekday'] = train['Date'].dt.dayofweek\n\ntest['Year'] = test['Date'].apply(lambda x: int(str(x)[:4]))\ntest['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\ntest['weekday'] = test['Date'].dt.dayofweek \n    \ntrain = train.drop('Date', axis=1)\ntest = test.drop('Date', axis=1)    \n\n## Filing NA values with -1\n\ntrain = train.fillna(-1)\ntest = test.fillna(-1)\n\n## Converting categorical variables into numeric variables with label encoder\n\nfor f in train.columns:\n    if train[f].dtype=='object':\n        #print(f)\n        lbl=preprocessing.LabelEncoder()\n        lbl.fit(list(train[f].values)+list(test[f].values))\n        train[f]=lbl.transform(list(train[f].values))\n        test[f]=lbl.transform(list(test[f].values))\n\ntrainori=train\ntestori=test"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('training ......')\n#select subset\ntrain_sample = np.random.choice(trainori.index.values,40000)   \ntrain = trainori.ix[train_sample]\n\ny = train.QuoteConversion_Flag.values\ntrain = train.drop(['QuoteNumber', 'QuoteConversion_Flag'], axis=1)\ntest = testori.drop('QuoteNumber', axis=1)          \n \nX = train.ix[:, 0:299]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)       \n      \nextc = ExtraTreesClassifier(n_estimators=580,max_features= 168,criterion= 'entropy',min_samples_split= 3,\n                            max_depth= 30, min_samples_leaf= 8)      \nextc.fit(X,y)          \npreds01 = extc.predict_proba(test)[:,1]\nprint('preds01 end .......')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('training ......')\n#select subset\ntrain_sample = np.random.choice(trainori.index.values,40000)   \ntrain = trainori.ix[train_sample]\n\n\ny = train.QuoteConversion_Flag.values\ntrain = train.drop(['QuoteNumber', 'QuoteConversion_Flag'], axis=1)\ntest = testori.drop('QuoteNumber', axis=1)          \n \n\nX = train.ix[:, 0:299]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)       \n      \nextc = ExtraTreesClassifier(n_estimators=580,max_features= 168,criterion= 'entropy',min_samples_split= 3,\n                            max_depth= 30, min_samples_leaf= 8)      \nextc.fit(X,y)          \npreds02 = extc.predict_proba(test)[:,1]\nprint('preds02 end .......')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "sample = pd.read_csv('../input/sample_submission.csv')\nsample.QuoteConversion_Flag =(preds01+preds02+preds03+preds04+preds05+preds06)/6.0\nsample.to_csv('extc_p.csv', index=False)        \n      "
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}