{"cells": [{"cell_type": "markdown", "source": ["# Iceberg Recognition from Salelite Images Using Keras Deep NN"], "metadata": {"_cell_guid": "d0450272-e9e6-401f-b5a1-bd75186d6905", "_uuid": "9f9543f4e5576f1873ef337c9b68aa40db1ba15f"}}, {"cell_type": "markdown", "source": ["In this notebook I am going to develop a Deep Neural Network to recognise Iceberg in ocean from satelite images . For this image recognition problem I am going to use Keras deep learning features . Keras is high level deep NN library which can be built over a tensorflow or theano backend . Keras provides much more abstraction and flexibilty to built deep networks in a very simple way . "], "metadata": {"_cell_guid": "70ed5d51-4e1a-4294-862d-af963198e9b5", "_uuid": "25418b0bb00c6c57e2b4da02f28cb7deca98721d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "4f18337e-24ff-479b-9983-c462cf195701", "collapsed": true, "_uuid": "84e8fb50043642e4df9025319e87d0d54c405418"}}, {"cell_type": "markdown", "source": ["The data for this problem is a image data in json format . We have to read the json data using pd.read_json( ) and we see it has two bands or channels and 1604 images in the training data .  The data can be downloaded form this [link](https://www.kaggle.com/c/statoil-iceberg-classifier-challenge/data) .  "], "metadata": {"_cell_guid": "82784e00-ca3d-4f2f-9e4b-c6d9477358ea", "_uuid": "229526d16e6e2acb1b5fdd93751a10b9fd7228eb"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["train_df = pd.read_json('../input/train.json')\n", "test_df = pd.read_json('../input/test.json')\n", "train_df.head()"], "metadata": {"_cell_guid": "cfc162c8-8dc7-44ec-b50b-8f7cf6e737b1", "collapsed": true, "_uuid": "c8c595a2cdfba21f1617a0116bc42babf4de3370"}}, {"cell_type": "markdown", "source": ["We need to preprocess the data to reshape it to make it in shape (1604,75,75,2) . We get the the training data in X_band ."], "metadata": {"_cell_guid": "320982db-5172-4c70-ac39-0486346dd5de", "_uuid": "de3b9ea5b171c2a34e0c1e37620c3b708d890abc"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_df[\"band_1\"]])\n", "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train_df[\"band_2\"]])"], "metadata": {"_cell_guid": "c0cf60e9-f6fa-46a8-b209-584cd17e58e3", "collapsed": true, "_uuid": "9448794c7a226f1c61c75b31178121782babb47d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["X_band = np.zeros([1604,75,75,3])\n", "for t in range(1604):\n", "    X_band[t,:,:,0] = X_band_1[t]\n", "    X_band[t,:,:,1] = X_band_2[t]\n", "    X_band[t,:,:,2] = (X_band_1[t]+X_band_2[t])/2"], "metadata": {"_cell_guid": "1359c2ae-d42c-4071-bbc0-077a0a1276e0", "collapsed": true, "_uuid": "06e801c07554537979ffc9648de9da34f5bb77c6"}}, {"cell_type": "markdown", "source": ["Now we import all required keras packages . "], "metadata": {"_cell_guid": "ce9fd6dc-7e7a-4144-861b-7ce49dbccc44", "_uuid": "4ed7c50543e3c25f133fabf5c34be167a5d6bd72"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from keras import layers\n", "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n", "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n", "from keras.models import Model\n", "from keras.preprocessing import image\n", "from keras.utils import layer_utils\n", "from keras.utils.data_utils import get_file\n", "from keras.applications.imagenet_utils import preprocess_input\n", "\n", "from IPython.display import SVG\n", "from keras.utils.vis_utils import model_to_dot\n", "from keras.utils import plot_model\n", "\n", "import keras.backend as K\n", "K.set_image_data_format('channels_last')\n", "import matplotlib.pyplot as plt\n", "from matplotlib.pyplot import imshow"], "metadata": {"_cell_guid": "8e29480a-875f-41ab-8c33-baf597221998", "collapsed": true, "_uuid": "e1cc3d6f0cd75b6b715f66901f20a7a0e9beb186"}}, {"cell_type": "markdown", "source": ["The deep NN model in keras can be built in 2 ways . One is using Sequential API and the other is Model API . I am using Model API . So we built the model thatconsistes of 3 layers of convolution layer and two fully connected layer . Each conv layer is made of (Conv2D,BatchNormalization,ReLU,MaxPooling2D) block. "], "metadata": {"_cell_guid": "d21df5e6-b285-4b6c-ba53-8ae56316f26f", "_uuid": "b32300daac54b08b2c56906bc20edcddc16cde3a"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["def Iceberg_model(input_shape):\n", "    X_in = Input(input_shape)\n", "    \n", "    X = Conv2D(16,kernel_size=(5,5),input_shape=(75,75,3))(X_in)\n", "    X = BatchNormalization()(X)\n", "    X = Activation('relu')(X)\n", "    X = MaxPooling2D(pool_size=(2,2))(X)\n", "    \n", "    X = Conv2D(32,kernel_size=(5,5))(X)\n", "    X = BatchNormalization()(X)\n", "    X = Activation('relu')(X)\n", "    X = MaxPooling2D(pool_size=(2,2))(X)\n", "    \n", "    X = Conv2D(64,kernel_size=(5,5))(X)\n", "    X = BatchNormalization()(X)\n", "    X = Activation('relu')(X)\n", "    X = MaxPooling2D(pool_size=(2,2))(X)\n", "    \n", "    X = Flatten()(X)\n", "    \n", "    X = Dense(128)(X)\n", "    X = Activation('relu')(X)\n", "    \n", "    X = Dense(64)(X)\n", "    X = Activation('relu')(X)\n", "    \n", "    X = Dense(1)(X)\n", "    X = Activation('sigmoid')(X)\n", "    \n", "    model = Model(inputs=X_in,outputs=X,name='Iceberg_model')\n", "    return model"], "metadata": {"_cell_guid": "cfc32109-12f5-471f-8fad-462cd91ee1ea", "collapsed": true, "_uuid": "7eb2c775a705d742e8d27b8d34b29eca2583aa3c"}}, {"cell_type": "markdown", "source": ["In Keras we have follow 4 simple steps to built a NN model . \n", "1.  create the model .\n", "2.  compile the model .\n", "3.  fit the model on the training data. \n", "4.  evaluate the model on the test data . "], "metadata": {"_cell_guid": "438587c4-b528-4442-8d2d-5bc37979c4cc", "_uuid": "a9bd0d12f5a9bd643ffaa2977fc4ab09c1f1f34b"}}, {"cell_type": "markdown", "source": ["For  creating the model we provide the shape of each training data (75,75,2) ."], "metadata": {"_cell_guid": "e68a26b2-317c-40af-9421-08a984c3c2d4", "_uuid": "21f9ea4a30918b82e0f3441baffc0c00ecdda33d"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["IcebergModel = Iceberg_model((75,75,3))"], "metadata": {"_cell_guid": "5f738ef2-a41b-49d7-a462-6ed8d4f4005f", "collapsed": true, "_uuid": "7ae316e5773a2ac422d73e6e38e08080528fc443"}}, {"cell_type": "markdown", "source": ["Compile the model using 'adam' optimizer , 'binary_crossentropy' loss and accuracy metric ."], "metadata": {"_cell_guid": "88a23acc-cd25-4468-96ce-3c31bf761124", "_uuid": "118bb350be39b31f11be0727d97759f0d574ffa7"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["IcebergModel.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"], "metadata": {"_cell_guid": "c263a7ab-8cfd-47ca-993f-13041f44e925", "collapsed": true, "_uuid": "ce1bdee690b623e2ffe95b5a67bea56745ba8caf"}}, {"cell_type": "markdown", "source": ["Now we fit the model with the training data having epochs = 20 and random batch_size = 128 . "], "metadata": {"_cell_guid": "a9345e14-eadb-4c6a-91ff-70097755d348", "_uuid": "53a154c5b7a6176fb14578ca87bfb13adf7dcfcb"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["target = train_df['is_iceberg'].values\n", "IcebergModel.fit(x=X_band,y=target,epochs=20,batch_size=128)"], "metadata": {"_cell_guid": "09cd8290-8bc4-4568-b366-03286d2bdc47", "collapsed": true, "_uuid": "6c45909f5afa43d1f791f76ac9bdb03a5a31ad7b"}}, {"cell_type": "markdown", "source": ["Evaluating the model on the traning data and it gets a 96.5 % accuarcy . "], "metadata": {"_cell_guid": "78b20987-bf3d-465d-a300-029beb4f0daa", "_uuid": "fe4f0e14e4ea2a4993c28fb94fb2b12b7fa72dd4"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["IcebergModel.evaluate(x=X_band,y=target)"], "metadata": {"_cell_guid": "cbbb7dd6-4e55-4eac-931a-91e7ceea04d1", "collapsed": true, "_uuid": "2cb5a693c5c4d90f265aafec81cf2f5b91386512"}}, {"cell_type": "markdown", "source": ["Classification report on the training data .  "], "metadata": {"_cell_guid": "7dc0bc3e-e2e8-4070-82b6-46016af30549", "_uuid": "c2319d58ce37954ffe6df5c19b27e5fd3971a0d2"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["from sklearn.metrics import classification_report\n", "pred_label = IcebergModel.predict(x=X_band)\n", "pred_label[pred_label>0.5]=1\n", "pred_label[pred_label<=0.5]=0\n", "print(classification_report(target,pred_label))"], "metadata": {"_cell_guid": "f102a670-d5bc-4df2-970b-623bf462363b", "collapsed": true, "_uuid": "d7cd3db1cfd1740eb0788765d43f1004b27ca2a0"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_df[\"band_1\"]])\n", "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_df[\"band_2\"]])\n", "X_test = np.zeros([8424,75,75,3])\n", "for t in range(8424):\n", "    X_test[t,:,:,0] = X_band_test_1[t]\n", "    X_test[t,:,:,1] = X_band_test_2[t]\n", "    X_test[t,:,:,2] = (X_band_test_1[t]+X_band_test_2[t])/2"], "metadata": {"_cell_guid": "0a55a653-c526-4b4f-b477-66d03ce2dfc7", "collapsed": true, "_uuid": "9ca13c023d0c9846fc25b30ae80c2b9e1bc5d8dd"}}, {"cell_type": "code", "execution_count": null, "outputs": [], "source": ["pred = IcebergModel.predict(x=X_test)\n", "\n", "sub_df = pd.DataFrame()\n", "sub_df['id'] = test_df['id']\n", "sub_df['is_iceberg'] = pred\n", "sub_df.to_csv('output.csv',index=False)"], "metadata": {"_cell_guid": "cc9b3bcd-56ef-4231-b644-5c01ec8abc62", "collapsed": true, "_uuid": "8654bd826646eb00087dd4098a6f2d0ce9e1ec7f"}}], "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat": 4, "nbformat_minor": 1}