{"cells": [{"cell_type": "markdown", "source": ["## Pytorch Starter Pre-Trained Resnet50\n", "This kernel mostly implements the [Pytorch Transfer Learning tutorial](http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html) with a custom dataset class and the resnet50 pretrained model from torchvision."], "metadata": {"_uuid": "94e1c572c69dfe1912c3bec2945b3f240c0621b3", "_cell_guid": "256bf8b7-92ed-445f-b137-9db81e6b7244"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["%matplotlib inline\n", "import matplotlib.pyplot as plt\n", "import time\n", "from shutil import copyfile\n", "from os.path import isfile, join, abspath, exists, isdir, expanduser\n", "from os import listdir, makedirs, getcwd, remove\n", "from PIL import Image\n", "from mpl_toolkits.axes_grid1 import ImageGrid\n", "import pandas as pd\n", "import numpy as np\n", "import torch\n", "from torch.optim import lr_scheduler\n", "from torch.autograd import Variable\n", "from torch.utils.data import Dataset, DataLoader\n", "import torch.nn.functional as func\n", "import torchvision\n", "from torchvision import transforms, datasets, models"], "metadata": {"_uuid": "33595673f3f93faf28ed0ac10f0a7c0e59a9c0ad", "_cell_guid": "42dcf0c0-28f0-4386-9ee3-367f3606aa30", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Define Custom Dataset"], "metadata": {"_uuid": "ab87c9fc87053c27d96e4765be8a942e91bf79bd", "_cell_guid": "579bc4ea-49c2-4413-a4bf-57472a155db4"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["class SeedlingDataset(Dataset):\n", "    def __init__(self, labels, root_dir, subset=False, transform=None):\n", "        self.labels = labels\n", "        self.root_dir = root_dir\n", "        self.transform = transform\n", "    \n", "    def __len__(self):\n", "        return len(self.labels)\n", "    \n", "    def __getitem__(self, idx):\n", "        img_name = self.labels.iloc[idx, 0]\n", "        fullname = join(self.root_dir, img_name)\n", "        image = Image.open(fullname).convert('RGB')\n", "        labels = self.labels.iloc[idx, 2]\n", "        if self.transform:\n", "            image = self.transform(image)\n", "        return image, int(labels)"], "metadata": {"_uuid": "e32251e2e44d9bf3b14af6153643b36110cb17ef", "_cell_guid": "796ac7f9-d66a-4856-acba-b1be8f4960b6", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Define classes from directory structure"], "metadata": {"_uuid": "00b3442cb74c4b8b34a95460e3c8df1df5aadd35", "_cell_guid": "d736ac16-7868-4333-8ef8-9bf56e1425a7"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["data_dir = '../input/plant-seedlings-classification/'\n", "cache_dir = expanduser(join('~', '.torch'))\n", "\n", "image_size = 224\n", "batch_size = 4\n", "classes = listdir(data_dir + 'train/')\n", "classes = sorted(classes, key=lambda item: (int(item.partition(' ')[0])\n", "                               if item[0].isdigit() else float('inf'), item))\n", "num_to_class = dict(zip(range(len(classes)), classes))\n", "num_to_class"], "metadata": {"_uuid": "612a1c5892a1bc20c7f6e272f6bf5f762781ffd9", "_cell_guid": "4f8b34be-557a-47da-b465-8db81a99639c", "scrolled": true}}, {"cell_type": "markdown", "source": ["### Copy torchvision model to temp directory where it is expected"], "metadata": {"_uuid": "4f827a7c90f459afe2e2de206e78a1c14ff411a8", "_cell_guid": "7b66b1b0-c094-4417-aaa6-3b412bcddcbb"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["if not exists(cache_dir):\n", "    makedirs(cache_dir)\n", "\n", "models_dir = cache_dir + '/' + 'models/'\n", "if not exists(models_dir):\n", "    makedirs(models_dir)\n", "\n", "model_name = 'resnet50-19c8e357.pth'\n", "src = '../input/pretrained-pytorch-models/' + model_name;\n", "dest = models_dir + model_name\n", "copyfile(src, dest)"], "metadata": {"_uuid": "06dfc68c134ec872a33e817aa7a0071ceff23acf", "_cell_guid": "aa1876eb-203b-4d2c-bc3b-af2840c6bc1e"}}, {"cell_type": "markdown", "source": ["### Create dataframe of training data"], "metadata": {"_uuid": "d70f4d2d9c064a850b8a1b477df27abeae4ce843", "_cell_guid": "cdb6f3c6-739f-47e9-9710-e408c3855106"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["train = []\n", "for index, label in enumerate(classes):\n", "    path = data_dir + 'train/' + label + '/'\n", "    for file in listdir(path):\n", "        train.append(['{}/{}'.format(label, file), label, index])\n", "    \n", "df = pd.DataFrame(train, columns=['file', 'category', 'category_id',]) \n", "df"], "metadata": {"_uuid": "9a4695d185d10d2fdaa8751bc1df8661640167bc", "_cell_guid": "06ebbd4e-613f-4aa5-b36b-3961efa8e847"}}, {"cell_type": "markdown", "source": ["### Split training / validation data & "], "metadata": {"_uuid": "b2af228fe763f4165d7de50d7e43a8f4be3e3c39", "_cell_guid": "cffa712d-559b-4b76-b3ba-afae56d5ce19"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["train_data = df.sample(frac=0.7)\n", "valid_data = df[~df['file'].isin(train_data['file'])]"], "metadata": {"_uuid": "3cd41eb01ba4879ea6eb93c1011d3d4787c900d0", "_cell_guid": "11f6c0ee-53c0-4488-b189-ce99ead1e470", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Prepare dataframe for predictions in submission format"], "metadata": {"_uuid": "80f8d4c615bd3e8e9e80986faf31bf343d583edc", "_cell_guid": "dd8d98cf-27b1-4e47-88a4-1794e3e1de25"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["sample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n", "sample_submission.columns = ['file', 'category']\n", "sample_submission['category_id'] = 0\n", "sample_submission"], "metadata": {"_uuid": "ae0e4f578b07423017177c87825eca46da631538", "_cell_guid": "e0d9957a-7516-44b3-911c-74d2d9a94806"}}, {"cell_type": "markdown", "source": ["### Setup transforms, datasets, and dataloaders"], "metadata": {"_uuid": "0163fcd2a2ea5a4e93bc87f47a96f404bcad6a83", "_cell_guid": "bc8a9969-280a-4ec8-850b-25aed1ee38d6"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["train_trans = transforms.Compose([\n", "    transforms.RandomSizedCrop(224),\n", "    transforms.RandomHorizontalFlip(),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "])\n", "\n", "valid_trans = transforms.Compose([\n", "    transforms.Scale(256),\n", "    transforms.CenterCrop(224),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "])\n", "\n", "train_set = SeedlingDataset(train_data, data_dir + 'train/', transform = train_trans)\n", "valid_set = SeedlingDataset(valid_data, data_dir + 'train/', transform = valid_trans)\n", "test_set = SeedlingDataset(sample_submission, data_dir + 'test/', transform = valid_trans)\n", "\n", "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4)\n", "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=4)\n", "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=4)\n", "\n", "dataset_sizes = {\n", "    'train': len(train_loader.dataset), \n", "    'valid': len(valid_loader.dataset)\n", "}"], "metadata": {"_uuid": "fe82da4f8b1501203d12027200d1f8d2209f0057", "_cell_guid": "f94cb9fa-e76a-46d5-a363-8856b45c59e1", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Define training method\n", "mostly if not entirely from pytorch transfer learning tutorial"], "metadata": {"_uuid": "1257d2cc10e64019a8ca94c814d4e179a45e04cd", "_cell_guid": "0cd8c571-5d93-42b6-9ef0-9c16b6d43ef7"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs=10):\n", "    since = time.time()\n", "\n", "    best_model_wts = model.state_dict()\n", "    best_acc = 0.0\n", "\n", "    for epoch in range(num_epochs):\n", "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n", "        print('-' * 10)\n", "\n", "        # Each epoch has a training and validation phase\n", "        for phase in ['train', 'valid']:\n", "            if phase == 'train':\n", "                scheduler.step()\n", "                model.train(True)  # Set model to training mode\n", "            else:\n", "                model.train(False)  # Set model to evaluate mode\n", "\n", "            running_loss = 0.0\n", "            running_corrects = 0\n", "            running_batch = 0\n", "\n", "            # Iterate over data.\n", "            for data in dataloaders[phase]:\n", "                # get the inputs\n", "                inputs, labels = data\n", "                labels = labels.view(-1)\n", "                \n", "                # wrap them in Variable\n", "                if use_gpu:\n", "                    inputs = Variable(inputs.cuda())\n", "                    labels = Variable(labels.cuda())\n", "                else:\n", "                    inputs, labels = Variable(inputs), Variable(labels)\n", "\n", "                # zero the parameter gradients\n", "                optimizer.zero_grad()\n", "\n", "                # forward\n", "                outputs = model(inputs)\n", "                _, preds = torch.max(outputs.data, 1)\n", "                loss = criterion(outputs, labels)\n", "\n", "                # backward + optimize only if in training phase\n", "                if phase == 'train':\n", "                    loss.backward()\n", "                    optimizer.step()\n", "\n", "                # statistics\n", "                running_loss += loss.data[0]\n", "                running_corrects += torch.sum(preds == labels.data)\n", "                running_batch +=1\n", "\n", "            epoch_loss = running_loss / running_batch\n", "            epoch_acc = running_corrects / dataset_sizes[phase]\n", "\n", "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n", "                phase, epoch_loss, epoch_acc))\n", "\n", "            # deep copy the model\n", "            if phase == 'valid' and epoch_acc > best_acc:\n", "                best_acc = epoch_acc\n", "                best_model_wts = model.state_dict()\n", "\n", "    time_elapsed = time.time() - since\n", "    print('Training complete in {:.0f}m {:.0f}s'.format(\n", "        time_elapsed // 60, time_elapsed % 60))\n", "    print('Best val Acc: {:4f}'.format(best_acc))\n", "\n", "    # load best model weights\n", "    model.load_state_dict(best_model_wts)\n", "    return model"], "metadata": {"_uuid": "d5ecfa57978ed8afd52e1551f6f5688ce9e16a5c", "_cell_guid": "f2cd5d63-c765-476a-9258-0152d8a06360", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Define the model\n", "Freeze pretrained layers\n", "add linear layer with number of classes"], "metadata": {"_uuid": "fde155bdd9ce81e2598146c263cedfa65eaba806", "_cell_guid": "d966c8a9-d189-4b76-8def-6180f9498154"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["use_gpu = torch.cuda.is_available()\n", "\n", "model = models.resnet50(pretrained=True)\n", "\n", "#I recommend training with these layers unfrozen for a couple of epochs after the initial frozen training\n", "for param in model.parameters():\n", "    param.requires_grad = False\n", "\n", "num_ftrs = model.fc.in_features\n", "model.fc = torch.nn.Linear(num_ftrs, len(classes))\n", "if use_gpu:\n", "    model = model.cuda()\n", "\n", "criterion = torch.nn.CrossEntropyLoss()\n", "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n", "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n", "\n", "loaders = {'train':train_loader, 'valid':valid_loader, 'test': test_loader}"], "metadata": {"_uuid": "29184efaeb75c7105b9f144550b68814c577534a", "_cell_guid": "f2eb7b14-c63b-4fdf-8370-baabd48a9943", "collapsed": true}}, {"cell_type": "markdown", "source": ["### Train the model\n", "using one epoch due to time constraints"], "metadata": {"_uuid": "c89aec6e431baa5ad878aa07c30faef161dea697", "_cell_guid": "7b939262-bef9-4384-9e65-1c6f19b0e7af"}}, {"execution_count": null, "cell_type": "code", "outputs": [], "source": ["model = train_model(loaders, model, criterion, optimizer, exp_lr_scheduler, num_epochs=1)"], "metadata": {"_uuid": "56b469e006382a0c93c7ce30b7976783257762b9", "_cell_guid": "c75d0756-757e-4cdb-b3e3-43d0ae2110eb", "collapsed": true}}], "nbformat": 4, "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "version": "3.6.3", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}}