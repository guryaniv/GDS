{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Features importances with Random Forest classifier\n\nThe aim of this notebook is to get the importance of each features. To do this I used features_importances \nfrom random_forest classifier in scikit learn\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "test = pd.read_csv('../input/test.csv')\ntrain = pd.read_csv('../input/train.csv')\ntrain.columns.values"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['Product_Info_1','Product_Info_2', 'Product_Info_3','Product_Info_4',\n       'Product_Info_5','Product_Info_6','Product_Info_7' ]].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['Employment_Info_1','Employment_Info_2', \n       'Employment_Info_3', 'Employment_Info_4',\n       'Employment_Info_5', 'Employment_Info_6']].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['InsuredInfo_1',\n       'InsuredInfo_2', 'InsuredInfo_3', 'InsuredInfo_4', 'InsuredInfo_5',\n       'InsuredInfo_6', 'InsuredInfo_7']].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['Insurance_History_1',\n       'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4',\n       'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8',\n       'Insurance_History_9']].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['Family_Hist_1', 'Family_Hist_2',\n       'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "train[['Medical_History_1', 'Medical_History_2', 'Medical_History_3',\n       'Medical_History_4', 'Medical_History_5', 'Medical_History_6',\n       'Medical_History_7', 'Medical_History_8', 'Medical_History_9',\n       'Medical_History_10', 'Medical_History_11', 'Medical_History_12',\n       'Medical_History_13', 'Medical_History_14', 'Medical_History_15',\n       'Medical_History_16', 'Medical_History_17', 'Medical_History_18',\n       'Medical_History_19', 'Medical_History_20', 'Medical_History_21',\n       'Medical_History_22', 'Medical_History_23', 'Medical_History_24',\n       'Medical_History_25', 'Medical_History_26', 'Medical_History_27',\n       'Medical_History_28', 'Medical_History_29', 'Medical_History_30',\n       'Medical_History_31', 'Medical_History_32', 'Medical_History_33',\n       'Medical_History_34', 'Medical_History_35', 'Medical_History_36',\n       'Medical_History_37', 'Medical_History_38', 'Medical_History_39',\n       'Medical_History_40', 'Medical_History_41']].head()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "from sklearn.preprocessing import Imputer"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Parse data \n\n* Separation of Product_Info_2 \n* BMI times INs_Age\n* Count NA by row\n* Count medical keywords by row \n* Impute missing values with mean"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "def parse_data(X):\n    \n    X['BMI_Ins_age'] = X.BMI*X.Ins_Age\n    \n    X['Product_Info2_let'] =X.Product_Info_2.str[0]\n    X['Product_Info2_num'] = X.Product_Info_2.str[1]\n    \n    X['Product_Info2_let'] = pd.factorize(X.Product_Info2_let)[0]+1\n    X['Product_Info_2'] = pd.factorize(X.Product_Info_2)[0]+1\n    \n    X['Medical_KW'] = X[['Medical_Keyword_1',\n       'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4',\n       'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7',\n       'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10',\n       'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13',\n       'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16',\n       'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19',\n       'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22',\n       'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25',\n       'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28',\n       'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31',\n       'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34',\n       'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37',\n       'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40',\n       'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43',\n       'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46',\n       'Medical_Keyword_47', 'Medical_Keyword_48']].sum(axis = 1)\n    \n    X['Na_Num'] = X.isnull().sum(axis = 1)\n\n\n\n    \n    imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n    col = X.columns.values    \n    X = pd.DataFrame(imp.fit_transform(X))\n    X.columns = col\n    \n\n    return X"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "test = pd.read_csv('../input/test.csv')\ntrain = pd.read_csv('../input/train.csv')\nX = parse_data(train)\ny = X.Response"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Random Forest model \n\nTrain a random forest model with \"n_estimators=300\" and other parameters by default"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "columns_to_drop = ['Id', 'Response']\n\nfrom sklearn.ensemble import ExtraTreesClassifier\nrf = ExtraTreesClassifier(n_estimators=300,\n                              random_state=0)\nrf.fit(X.drop(columns_to_drop, axis = 1), y)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "# Display the 20th first features by importances"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "importances =pd.DataFrame({'features' :X.drop(columns_to_drop, axis = 1).columns,\n                           'importances' : rf.feature_importances_})\nimportances.sort_values(by = 'importances', ascending = False).head(20)"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "#Display the 20th last features"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "importances.sort_values(by = 'importances', ascending = False).tail(20)\n"
 },
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": "#Plot the features importances "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#plot importances\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimportances.sort_values(by = 'importances', ascending = True, inplace = True)\nval = importances.importances*100    # the bar lengths\npos = np.arange(importances.shape[0])+.5 \n\nplt.figure(figsize = (13,28))\nplt.barh(pos,val, align='center')\nplt.yticks(pos, importances.features.values)\nplt.xlabel('Importances')\nplt.title('Features importances')\nplt.grid(True)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#cumsum of importances\nimportances.sort_values(by = 'importances', ascending = False, inplace = True)\n\nimportances['cumul'] = np.cumsum(importances.importances, axis = 0)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "importances.sort_values(by = 'importances', ascending = True, inplace = True)\n\nval = importances.cumul*100    # the bar lengths\npos = np.arange(importances.shape[0])+.5 \n\nplt.figure(figsize = (13,28))\nplt.barh(pos,val, align='center')\nplt.yticks(pos, importances.features.values)\nplt.xlabel('Importances')\nplt.title('Features importances')\nplt.grid(True)"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "for i in np.arange(50,100,5):\n    print('Nombre de variables pour avoir {0} % d\\' \\\"importance\\\" des variables  : {1} sur {2}'.format(i,importances.features[importances.cumul<i/100].shape[0],\n                                                                                                    importances.features.shape[0]))"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "#Variables ro remove to get X % of importances \n\nX = 90\n\nimportances.features[importances.cumul>X/100].values"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}