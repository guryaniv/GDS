{"cells":[{"metadata":{"_cell_guid":"584ef1b7-306d-4ddb-83b4-a1fc191f9043","_uuid":"934470c6240ca0c552992aafbea0e53351889c5c"},"cell_type":"markdown","source":"# 1. Introduction\nThis Notebook models a simple but fast and accurate Convolutional Neural Networks for recognizing handwritten digits of MNIST dataset.\n## 1.1. Import libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D\nfrom keras.layers import BatchNormalization, Dropout, Flatten\nfrom keras.optimizers import RMSprop\nfrom keras.losses import categorical_crossentropy\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"},"cell_type":"markdown","source":"# 2. Data Prepration\nAt the beginning I try to prepare the dataset and do some preprocessing in order to get the maximum desirable output.\n## 2.1. Load Data"},{"metadata":{"collapsed":true,"_cell_guid":"1c216f06-73ef-4a88-8d59-2d36c11503df","_uuid":"4a6622fcc4b6bad7afce1a21f0b933520ea6c08f","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\").values\ntest = pd.read_csv(\"../input/test.csv\").values\n\nX_train = train[:, 1:].astype('float32')\nY_train = train[:, 0].astype('int32')\nX_test = test[:, :].astype('float32')","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"66755ee0-f6dc-49bf-ba66-5f1f093a070b","_uuid":"16af666149a27ead1aba560ce59b86a406c0ff19"},"cell_type":"markdown","source":"## 2.2. Data Preprocessing\nThe recommended preprocessing is to center the data to have mean of zero, and normalize its scale to [-1, 1] along each feature. I skipped the standardization process since has particular effect but it is good practice to use it.\n\n**Normalization** refers to normalizing the data dimensions so that they are of approximately the same scale. I normalized each feature scale to [0, 1] since it was simpler.\n\n**Reshape:** for every input we have 784 feature in 1-dimension and we should reshape it into 2-dimensional images with 1 channel (gray image) so i reshaped the 1x784 input vector into 28x28x1.\n\n**Label One Hot Encoding:** our labels varies between a single integer from 0 to 9 and we should convert it to one hot vector. a one hot encoded vector has a single 1 in one dimension and 0 in other dimensions. for example a label 7 in one hot vector is [0, 0, 0, 0, 0, 0, 0, 1, 0, 0] in this process.\n\n**Train/Validation Data Split:** for splitting data into train and validation first we have to check the distribution of our classes."},{"metadata":{"_cell_guid":"62abc9f3-48d1-4ca7-b4cc-f1de1e93f25b","_uuid":"742ef6b6abb5d42f83f7174a63781140fc739fcc","scrolled":false,"trusted":true},"cell_type":"code","source":"sns.countplot(Y_train)","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"8eef7e76-b067-4b8d-8a3c-1700ec3c4f4c","_uuid":"ef3f065b5d72d5b427fd38ea0f1b0a1ab656fed8"},"cell_type":"markdown","source":"Knowing that we have almost the same proportion of data for each class leads us to use train validation random split without using stratify option.\n\n**Data Augmentation:** in order to improve our model generalization it is common practice to use data augmentation. This means generating more data for training process. This data is generated based on actual training data with random small manipulation such as zoom, shift, rotation, crop, flip, etc."},{"metadata":{"collapsed":true,"_cell_guid":"f1bc3e46-5365-4a19-8830-090034268c9e","_uuid":"537ec3ecfa21156b4b2c8160a8e1c5c13cad567e","trusted":true},"cell_type":"code","source":"# Normalization\nX_train = X_train/255.\nX_test = X_test/255.\n\n# Reshape\nX_train = X_train.reshape(-1, 28, 28, 1)\nX_test = X_test.reshape(-1, 28, 28, 1)\n\n# Label One Hot Encoding\nY_train = to_categorical(Y_train, num_classes=10)\n\n# Train/Validation Data Split\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.15, random_state=23)\n\n# Data Augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,\n    zoom_range=0.15,\n    width_shift_range=0.15,\n    height_shift_range=0.15)\ndatagen.fit(X_train)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"ed9c0fd2-326a-4fa3-952e-7df260acf3c1","_uuid":"a0131cc04ba770fa70ba98068044d7723282cf99"},"cell_type":"markdown","source":"# 3. CNN Model\n## 3.1. Model Definition\nI used the keras Sequential API to define the model.\n\nFor the first Conv2D layer i choosed 16 filters each use 25 weights. I used other layers such as BachNormalization, MaxPooling2D and Dropout.\n\n**Batch Nomralization** is a technique [developed by Ioffe and Szegedy](http://arxiv.org/abs/1502.03167). In practice networks that use Batch Normalization are significantly more robust to bad initialization.\n\n**Dropout** is a Regularization technique that controls the capacity of Neural Networks to prevent overfitting [introduced by Srivastava et al](http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf).\n\n**Max Pooling** is another layer to prevent overfitting. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.\n\n**Dense** is fully connected layer.\n\nAll layers use **RelU** (Rectified Linear Unit) activation function.\n\nFor optimizer i choosed **RMSprop** which is very effective adaptive learning rate method.\n![Contours of a loss surface and time evolution of different optimization algorithms](http://cs231n.github.io/assets/nn3/opt2.gif)"},{"metadata":{"collapsed":true,"_cell_guid":"9ed52cd3-c3f6-472c-a4d8-bd9e5b1bc6a1","_uuid":"d0420392cfdd71197b7451218c6531585289750d","trusted":true},"cell_type":"code","source":"# Model Definition\nmodel = Sequential()\n\nmodel.add(Conv2D(16, kernel_size=(5, 5),\n                activation='relu',\n                input_shape=(28, 28, 1)))\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                padding='same',\n                activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(3, 3),\n                padding='same',\n                activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3),\n                padding='same',\n                activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(loss=categorical_crossentropy,\n              optimizer=RMSprop(lr=1e-3),\n              metrics=['accuracy'])","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"de8a172e-7be4-4e4a-9dfd-974ebe664086","_uuid":"56fa798ea8a6e9754ffbcd5ef206715d54418e87"},"cell_type":"markdown","source":"## 3.2. Train\nFor the training process i choosed batch size of 70 and 20 number of epoches. also to converge faster i reduced learning rate to 0.0002 when validation loss does not improve after 2 epochs and kept it for 2 more epochs."},{"metadata":{"_cell_guid":"22c62728-ec27-43cb-862a-e5abc452faa9","_uuid":"8c74adf361ccba8d8d4952912b65e7c388dfded6","trusted":true},"cell_type":"code","source":"# Learning Rate Reducer\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=2)\n# Train\nhistory = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=70),\n                              epochs=20,\n                              validation_data=(X_val, Y_val),\n                              verbose=2,\n                              callbacks=[reduce_lr])","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"3a4632f5-8c99-4a57-8ad4-0df0ae2bff35","_uuid":"158ccb143b05fc7183c7ced7992ab4c9b17f2bc3","trusted":false},"cell_type":"markdown","source":"## 3.3. Evaluation\nTo evaluate the model i plot the confusion matrix on validation data."},{"metadata":{"trusted":true,"_uuid":"926524e40fc9fba8ae2df3cd4fce635cee64ef5e"},"cell_type":"code","source":"Y_val_pred = model.predict_classes(X_val)\nY_val_true = np.argmax(Y_val, axis=1)\n\nprint(confusion_matrix(Y_val_true, Y_val_pred))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"57d1e1cb9cb8594c84a565fe9f1613008ec3da0d"},"cell_type":"markdown","source":"## 3.4. Submission\nFinally we use this model to predict test set labels and submit."},{"metadata":{"trusted":true,"_uuid":"d77dd722f7a4b7df661626fcbcee365f1b2a25f4"},"cell_type":"code","source":"Y_test_pred = model.predict_classes(X_test)\n\nsubmission = pd.DataFrame({ 'ImageId': range(1, 28001), 'Label': Y_test_pred })\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":9,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}