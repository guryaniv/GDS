{"cells":[{"metadata":{"trusted":true,"_uuid":"c6b56d54c8f290e3dbeb4d1937bdd1496688db2e"},"cell_type":"markdown","source":"# DON'T Overfit: A step-by-step quest to solution\n\nThe plan is as follows:\n- As a first step I will explore the Logistic regression (right now it achieved 0.844)\n- Next, will deal with the feature selection\n- After that I will try to understand the difference between the train and the test sets "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nfrom sklearn import metrics\nimport sklearn.preprocessing, sklearn.kernel_ridge, sklearn.model_selection, sklearn.linear_model\nimport multiprocessing\nimport seaborn as sns\nimport scipy.stats\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint(f'Shape of the train {train.shape}')\nprint(f'Shape of the test {test.shape}')\ntest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b692344913c50f7ccd378830d5cc3b3b538b81b4"},"cell_type":"code","source":"data = train.iloc[:, 2:].values\nref = train['target'].values\n#train['target'].value_counts()\n#plt.figure()\nsns.countplot(train['target'])\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20695eb15e9cf2ed28ca21399146a8639cc793fd"},"cell_type":"markdown","source":"### The first shot: Logistic regression\nWe train the Logistic regression with different parameters, including optimizing the regularization strength"},{"metadata":{"trusted":true,"_uuid":"aff4cd28067af6f5b5f2825cd65c54c26db46179"},"cell_type":"code","source":"model_default = sklearn.linear_model.LogisticRegression()\nmodel_default.fit(data, ref)\n\npredict_test = model_default.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_default.csv', index=False)\n\nmodel = sklearn.linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nmodel.fit(data, ref)\n\npredict_test = model.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_l1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6ee1b6685d20d976f49a7ee54cb0392f1233a02"},"cell_type":"code","source":"def cross_validation(X, y, model, parameters, pname, nfold=10):\n    cv_method = sklearn.model_selection.KFold(n_splits=nfold, shuffle=True, random_state=13)\n    rgr = sklearn.model_selection.GridSearchCV(model, parameters, n_jobs=multiprocessing.cpu_count()-1, cv=cv_method, scoring='roc_auc')\n    rgr.fit(X, y)\n    plt.semilogx(parameters[pname], rgr.cv_results_['mean_test_score'], 'o-r')\n    plt.xlabel(pname)\n    plt.ylabel('ROC-AUC')\n    plt.title(f'{nfold}-Fold cross validation')\n    print(f\"The best {pname} parameter is {rgr.best_params_[pname]}\")\n    return rgr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a66218eb2f248a21ef0329b96edb3c676de4f1a"},"cell_type":"code","source":"model = sklearn.linear_model.LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear')\nparameters = {'C': np.logspace(-2, 5, 40)}\nrgr = cross_validation(data, ref, model, parameters, 'C', nfold=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9826e2d29197c809654617c93d25f9a6df406018"},"cell_type":"code","source":"predict_test = rgr.best_estimator_.predict_proba(test.iloc[:, 1:].values)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_cv_l1.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73658ff9b98ce35163cdf004ab9775a7c504e4f3"},"cell_type":"markdown","source":"### Summarizing the results of submitting the LogisticRegression:\n- A default Logistic regression trained on the train set and all the features gives 0.274 score in the leaderboard of the competition - much worse than the 0.5 of the completely random submission\n- A Logistic regressoin with the parameters: 'class_weight='balanced', penalty='l1', C=0.1, solver='liblinear'' gives score of 0.844\n- Optimizing the parameter C with the 40-fold cross-validation doesn't improve the score: 0.843"},{"metadata":{"_uuid":"d34117bdb04ade43695672fb659e5d9c3189fa03"},"cell_type":"markdown","source":"### Next: Averaging the model\n"},{"metadata":{"trusted":true,"_uuid":"e0ce2bd13973d92f0fd8383bff7d6380a68f52a7"},"cell_type":"code","source":"def cross_validation_average(X, y, X_test, model, nfold=10):\n    scores = []\n    y_test = 0\n    folds = sklearn.model_selection.StratifiedKFold(n_splits=nfold, shuffle=True, random_state=13)\n    for idx, (train_index, valid_index) in enumerate(folds.split(X, y)):\n        X_train, X_valid = X[train_index], X[valid_index]\n        y_train, y_valid = y[train_index], y[valid_index]\n        print(f'Process fold no {idx}: train/validation={len(y_train)}/{len(y_valid)}')\n\n        model = model\n        model.fit(X_train, y_train)\n        y_pred_valid = model.predict(X_valid).reshape(-1,)\n        score = metrics.roc_auc_score(y_valid, y_pred_valid)\n        y_test += model.predict_proba(X_test)[:, 1]\n        scores.append(score)\n\n    plt.plot(range(nfold), scores, 'o-r')\n    plt.xlabel('N-Fold')\n    plt.ylabel('ROC-AUC')\n    plt.title(f'{nfold}-Fold cross validation scores')\n    print(f\"Results: Max={np.max(scores)}, Mean={np.mean(scores)}, STD={np.std(scores)}\")\n    return scores, y_test/nfold\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b5b4298b16b10cd5d9194955efc14e051d93407"},"cell_type":"code","source":"scores, predict_test = cross_validation_average(data, ref, test.iloc[:, 1:].values, rgr.best_estimator_, nfold=10)\nsubmission['target'] = predict_test\nsubmission.to_csv('submission_logreg_cv_l1_average.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fc8ec034cdff3940afbe8dc38ae642fc415a16c"},"cell_type":"markdown","source":"Summarizing the results of submitting the LogisticRegression:\n- Averaging over 10 folds of the same model gives the result 0.842 - not an improvement comparing to the previous result"},{"metadata":{"_uuid":"bb628694f351dad315be210a1bf2b33501632677"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}