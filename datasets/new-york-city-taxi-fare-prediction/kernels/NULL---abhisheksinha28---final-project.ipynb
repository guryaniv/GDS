{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.size'] = 18\npalette = sns.color_palette('Paired', 10)\nimport plotly\nimport plotly.plotly as py\nimport plotly.offline as offline\nimport plotly.graph_objs as go\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3b8824f07081a4d2c480c1d23654cbc6c1c590e1"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', nrows = 500_000,parse_dates = ['pickup_datetime'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59c1ce956df8efb2f76121af2a88002b12b5b512"},"cell_type":"code","source":"train = train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30adfb9a61efb20d2656ac2a4b86558b53020598"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6ac7e371c86f6dc6d55df73de774607c8c0cbb7a"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8965ca0985a266f724c3f65c03871844d9915fa7"},"cell_type":"code","source":"fare_amount = train.fare_amount\ndata = [go.Histogram(x = fare_amount)]\nlayout = go.Layout(title='Distribution of fare')\n\nfig = go.Figure(data = data, layout = layout )\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"634ad3667c814af080e42dbf2b3216902229de53"},"cell_type":"code","source":"print(f\"There are {len(train[train['fare_amount'] < 0])} negative fares.\")\nprint(f\"There are {len(train[train['fare_amount'] == 0])} $0 fares.\")\nprint(f\"There are {len(train[train['fare_amount'] > 100])} fares greater than $100.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a02f595eb78e20f9910dbfc46328abc8a3e16e5"},"cell_type":"code","source":"train = train[train['fare_amount'].between(left = 2.5, right = 200)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"85db8357fd2e5057389a9f0e2bebb80535235458"},"cell_type":"code","source":"train['fare-bin'] = pd.cut(train['fare_amount'], bins = list(range(0, 50, 5))).astype(str)\n\n# Uppermost bin\ntrain.loc[train['fare-bin'] == 'nan', 'fare-bin'] = '[45+]'\n\n# Adjust bin so the sorting is correct\ntrain.loc[train['fare-bin'] == '(5, 10]', 'fare-bin'] = '(05, 10]'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c1423115c1245bc9ca3244ec4e034671102577f"},"cell_type":"code","source":"train['fare-bin'].value_counts().sort_index().plot.bar(color = 'b', edgecolor = 'k');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a869a98a11fb1f975917d513a84c3f990a85a16f"},"cell_type":"code","source":"data = [go.Histogram(x = train['passenger_count'],\n                        marker=dict(\n        color='rgb(158,202,225)',\n        line=dict(\n            color='rgb(8,48,107)',\n            width=1.5,\n        )\n    ),\n    opacity=0.6)]\nlayout = go.Layout(title='Passenger Count')\n\nfig = go.Figure(data = data, layout = layout )\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09075aa275c2278dec2c6db62def9f5df658460a"},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c67d47ce501bd659c67acba3c782c5db387aef84"},"cell_type":"code","source":"# Remove latitude and longtiude outliers\ntrain = train.loc[train['pickup_latitude'].between(40, 42)]\ntrain = train.loc[train['pickup_longitude'].between(-75, -72)]\ntrain = train.loc[train['dropoff_latitude'].between(40, 42)]\ntrain = train.loc[train['dropoff_longitude'].between(-75, -72)]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d600bc8f7d3e21b37eb3810cd43fc6e721c431f1"},"cell_type":"code","source":"temp1 = train.sample(10000, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"70b0fb54afb87b34cf4a7f66902f81062b24ee5f"},"cell_type":"code","source":"\ndata = [\n    go.Scattermapbox(\n    lat = temp1['pickup_latitude'],\n    lon = temp1['pickup_longitude'],\n    customdata = temp1['key'],\n    mode = 'markers',\n    marker = dict(\n        size = 4, \n        color = 'gold',\n        opacity = 0.8\n        ),\n        )]\nlayout = go.Layout(autosize=False,\n                   mapbox= dict(accesstoken=\"pk.eyJ1IjoiYWJoaTM0NTMiLCJhIjoiY2pucWQ4NDlrMDY3NTNrbndjczZnNnZ4eCJ9.EJX2rmBc8eeXtuJ_ouagpQ\",\n                                bearing=10,\n                                pitch=60,\n                                zoom=13,\n                                center= dict(\n                                         lat=40.721319,\n                                         lon=-73.987130),\n                                style= \"mapbox://styles/abhi3453/cjnqed0x70z5i2ro24fyy53ak\"),\n                    width=900,\n                    height=600, title = \"Pickup locations in Newyork\")\n\nfig = dict(data = data, layout = layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3347f7185650a9ba57df8c44aa997b6fb2b75af0"},"cell_type":"code","source":"\ndata = [\n    go.Scattermapbox(\n    lat = temp1['dropoff_latitude'],\n    lon = temp1['dropoff_longitude'],\n    customdata = temp1['key'],\n    mode = 'markers',\n    marker = dict(\n        size = 4, \n        color = 'orange',\n        opacity = 0.8\n        ),\n        )]\nlayout = go.Layout(autosize=False,\n                   mapbox= dict(accesstoken=\"pk.eyJ1IjoiYWJoaTM0NTMiLCJhIjoiY2pucWQ4NDlrMDY3NTNrbndjczZnNnZ4eCJ9.EJX2rmBc8eeXtuJ_ouagpQ\",\n                                bearing=10,\n                                pitch=60,\n                                zoom=13,\n                                center= dict(\n                                         lat=40.721319,\n                                         lon=-73.987130),\n                                style= \"mapbox://styles/abhi3453/cjnqed0x70z5i2ro24fyy53ak\"),\n                    width=900,\n                    height=600, title = \"Drop off locations in Newyork\")\n\nfig = dict(data = data, layout = layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ff6874ad31b67bfdffeb956acedca8c30917bbba"},"cell_type":"code","source":"train['abs_lat_diff'] = (train['dropoff_latitude']- train['pickup_latitude']).abs()\ntrain['abs_lon_diff'] = (train['dropoff_longitude']- train['pickup_longitude']).abs()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b4984b864ddb1a616a8941b6b4d13b7881ed9e8"},"cell_type":"code","source":"temp = train.sample(1000, random_state=100)\nsns.lmplot('abs_lat_diff', 'abs_lon_diff', fit_reg = False,\n           data = temp);\nplt.title('Absolute latitude difference vs Absolute longitude difference');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a0ba1935038c44a5e754d509362e9dee0db68ed"},"cell_type":"code","source":"temp = temp.sort_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"366db94226e2a164c90b498affb3c70de190e1c6"},"cell_type":"code","source":"no_diff = train[(train['abs_lat_diff']==0) & (train['abs_lon_diff']==0)]\nno_diff.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa4e8b5ef55e20c2a079c5945ab0d299afc05852"},"cell_type":"code","source":"sns.lmplot('abs_lat_diff','abs_lon_diff', data = train.sort_index(), hue='fare-bin', palette=palette, fit_reg=False)\nplt.title('Absolute latitude difference vs Absolute longitude difference');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c7d3b09ee7c5629caac48350842f473518185cf6"},"cell_type":"code","source":"def minkowski_distance(x1, x2, y1, y2, p):\n    return ((abs(x2 - x1) ** p) + (abs(y2 - y1)) ** p) ** (1 / p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e43744cdd943f0066a019b49a3adad5f07496dc8"},"cell_type":"code","source":"color_mapping = {fare_bin: palette[i] for i, fare_bin in enumerate(train['fare-bin'].unique())}\ntrain['color'] = train['fare-bin'].map(color_mapping)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7d916cc8d682998e2801ff2da51751661171b5cd"},"cell_type":"code","source":"train['manhattan'] = minkowski_distance(train['pickup_longitude'], train['dropoff_longitude'],\n                                       train['pickup_latitude'], train['dropoff_latitude'], 1)\n\n# Calculate distribution by each fare bin\nplt.figure(figsize = (12, 6))\nfor f, grouped in train.groupby('fare-bin'):\n    sns.kdeplot(grouped['manhattan'], label = f'{f}', color = list(grouped['color'])[0]);\n\nplt.xlabel('degrees'); plt.ylabel('density')\nplt.title('Manhattan Distance by Fare Amount');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92ec882cfb80b9702bf1b6bbca9683a611b5af26"},"cell_type":"code","source":"train['euclidean'] = minkowski_distance(train['pickup_longitude'], train['dropoff_longitude'],\n                                       train['pickup_latitude'], train['dropoff_latitude'], 2)\n\n# Calculate distribution by each fare bin\nplt.figure(figsize = (12, 6))\nfor f, grouped in train.groupby('fare-bin'):\n    sns.kdeplot(grouped['euclidean'], label = f'{f}', color = list(grouped['color'])[0]);\n\nplt.xlabel('degrees'); plt.ylabel('density')\nplt.title('Euclidean Distance by Fare Amount');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e825552bad59712b05d3b25f6177ef565d03a02c"},"cell_type":"code","source":"train.groupby('fare-bin')['euclidean'].agg(['mean', 'count'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a9caa71e99cfc64400d409e3e3c4149b35d7a1d"},"cell_type":"code","source":"train.groupby('fare-bin')['euclidean'].mean().plot.bar(color = 'b');\nplt.title('Average Euclidean Distance by Fare Bin');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"443e15c7a3e1f95caf0863a2e92abf3c0ca1138b"},"cell_type":"code","source":"train.groupby('passenger_count')['fare_amount'].mean().plot.bar(color = 'b');\nplt.title('Avg Fare By passenger count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5cd2a329d593118d9faa2d331d76c94c25fd3bc2"},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv', parse_dates = ['pickup_datetime'])\n\ntest['abs_lat_diff'] = (test['dropoff_latitude']-test['pickup_latitude']).abs()\ntest['abs_lon_diff'] = (test['dropoff_longitude']- test['pickup_longitude']).abs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"180a4b9a95fbe8dd2f9fb7c7f04e343f0e47916d"},"cell_type":"code","source":"test_id = list(test.pop('key'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7246f2ecddbbcadbaacaabfa9656e111de741e3"},"cell_type":"code","source":"test.describe()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f032b4101e346c58cbcb8386491f7397f7c63749"},"cell_type":"code","source":"test['manhattan'] = minkowski_distance(test['pickup_longitude'], test['dropoff_longitude'],\n                                       test['pickup_latitude'], test['dropoff_latitude'], 1)\n\ntest['euclidean'] = minkowski_distance(test['pickup_longitude'], test['dropoff_longitude'],\n                                       test['pickup_latitude'], test['dropoff_latitude'], 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d880454ce82d1d7740e53939a6928b0004c69f4c"},"cell_type":"code","source":"R = 6378\n\ndef haversine_np(lon1, lat1, lon2, lat2):\n    \"\"\"\n    Calculate the great circle distance between two points\n    on the earth (specified in decimal degrees)\n\n    All args must be of equal length.    \n    \n    source: https://stackoverflow.com/a/29546836\n\n    \"\"\"\n    # Convert latitude and longitude to radians\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    # Find the differences\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n\n    # Apply the formula \n    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n    # Calculate the angle (in radians)\n    c = 2 * np.arcsin(np.sqrt(a))\n    # Convert to kilometers\n    km = R * c\n    \n    return km","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"265bad8a3794406e0768c69f263505bf90ed4b18"},"cell_type":"code","source":"train['haversine'] =  haversine_np(train['pickup_longitude'], train['pickup_latitude'],\n                         train['dropoff_longitude'], train['dropoff_latitude']) \n\ntest['haversine'] = haversine_np(test['pickup_longitude'], test['pickup_latitude'],\n                         test['dropoff_longitude'], test['dropoff_latitude'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"148d5b12225952bca29ac9f574ae9f12e8c1d1d5"},"cell_type":"code","source":"subset = train.sample(100000, random_state=100)\nplt.figure(figsize = (10,6))\nfor f, grouped in subset.groupby('fare-bin'):\n        sns.kdeplot(grouped['haversine'], label = f'{f}', color = list(grouped['color'])[0]);\n    \nplt.title('Distribution of Haversine Distance by Fare Bin');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3139c5dfa3fb469c042f7eff56d1dd5842d307ad"},"cell_type":"code","source":"train.groupby('fare-bin')['haversine'].mean().sort_index().plot.bar(color='r')\nplt.title('Avg Haversine distance by Fare')\nplt.ylabel('avg haversine distance')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3daa6ccaf647fc74f464a5f2ad43e4f6b11a925"},"cell_type":"code","source":"correlation = train.corr()\ncorrelation['fare_amount'].plot.bar(color = 'b')\nplt.title('Correlation of Fare')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6b4c37f14caf659c2ad2f721721762a798e6ddc"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n\nlm = LinearRegression()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ad43ccee5b643cb4402de603877cada0349e76"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train, np.array(train['fare_amount']), \n                                                      stratify = train['fare-bin'],\n                                                      random_state = 100, test_size = 100_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae3b7363ff96ac6c2dc5bedf0c95e7b6652073d5"},"cell_type":"code","source":"lm.fit(X_train[['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count' ]], y_train)\nprint('Intercept', round(lm.intercept_, 4))\nprint('abs_lat_diff coef: ', round(lm.coef_[0], 4), \n      '\\tabs_lon_diff coef:', round(lm.coef_[1], 4),\n      '\\tpassenger_count coef:', round(lm.coef_[2], 4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4659871d23804a7ed33408789e82459d8ffa85f4"},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore', category = RuntimeWarning)\n\ndef metrics(train_pred, valid_pred, y_train, y_valid):\n    \"\"\"Calculate metrics:\n       Root mean squared error and mean absolute percentage error\"\"\"\n    \n    # Root mean squared error\n    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))\n    \n    # Calculate absolute percentage error\n    train_ape = abs((y_train - train_pred) / y_train)\n    valid_ape = abs((y_valid - valid_pred) / y_valid)\n    \n    # Account for y values of 0\n    train_ape[train_ape == np.inf] = 0\n    train_ape[train_ape == -np.inf] = 0\n    valid_ape[valid_ape == np.inf] = 0\n    valid_ape[valid_ape == -np.inf] = 0\n    \n    train_mape = 100 * np.mean(train_ape)\n    valid_mape = 100 * np.mean(valid_ape)\n    \n    return train_rmse, valid_rmse, train_mape, valid_mape\n\ndef evaluate(model, features, X_train, X_valid, y_train, y_valid):\n    \"\"\"Mean absolute percentage error\"\"\"\n    \n    # Make predictions\n    train_pred = model.predict(X_train[features])\n    valid_pred = model.predict(X_valid[features])\n    \n    # Get metrics\n    train_rmse, valid_rmse, train_mape, valid_mape = metrics(train_pred, valid_pred,\n                                                             y_train, y_valid)\n    \n    print(f'Training:   rmse = {round(train_rmse, 2)} \\t mape = {round(train_mape, 2)}')\n    print(f'Validation: rmse = {round(valid_rmse, 2)} \\t mape = {round(valid_mape, 2)}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0f10cb2fbc589e6b3a7a23c2af88ce15b632488"},"cell_type":"code","source":"evaluate(lm, ['abs_lat_diff', 'abs_lon_diff','haversine', 'passenger_count'], \n        X_train, X_valid, y_train, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bfbee12132f779fff32bcdb7c8e4abc727f51d1b"},"cell_type":"code","source":"preds = lm.predict(test[['abs_lat_diff', 'abs_lon_diff','haversine', 'passenger_count']])\n\nsub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\nsub.to_csv('sub_lr_simple.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bbc3b3eb43151fb63d97ff1f1f1e565c5857363"},"cell_type":"code","source":"sns.distplot(sub['fare_amount'])\nsub[sub['fare_amount'] > 100]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4b47bece0883c71095ad0950ab89373081113ce"},"cell_type":"code","source":"test.loc[sub[sub['fare_amount'] > 100].index]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60fb67228d9f9ada8788dd3254d870f387077c83"},"cell_type":"code","source":"plt.figure(figsize = (12,12))\nsns.heatmap(correlation,annot = True, vmin = -1, vmax = 1, fmt = '.3f', cmap=plt.cm.PiYG_r);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36a18dc9f630c2510996d67b73a15a38cbda6d7f"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrandom_forest = RandomForestRegressor(n_estimators = 20, max_depth = 20, \n                                      max_features = None, oob_score = True, \n                                      bootstrap = True, verbose = 1, n_jobs = -1)\nrandom_forest.fit(X_train[['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count']], y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bf193f6b5c9528a112124b004bcbf7c2db791b59"},"cell_type":"code","source":"evaluate(random_forest, ['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count'],X_train, X_valid, y_train, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73d4ef44e0500b2b5b03b4f29c5fe2bf68ac211b"},"cell_type":"code","source":"preds= random_forest.predict(test[['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count']])\nsub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\nsns.distplot(sub['fare_amount'])\nplt.title('Distribution of Random Forest Predicted Fare Amount');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a71466503d01b6f2022c17c1ccb8010412d84999"},"cell_type":"code","source":"import re\n\ndef extract_dateinfo(df, date_col, drop=True, time=False, \n                     start_ref = pd.datetime(2009, 1, 1),\n                     extra_attr = False):\n    \"\"\"\n    Extract Date (and time) Information from a DataFrame\n    Adapted from: https://github.com/fastai/fastai/blob/master/fastai/structured.py\n    \"\"\"\n    df = df.copy()\n    \n    # Extract the field\n    fld = df[date_col]\n    \n    # Check the time\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n\n    # Convert to datetime if not already\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[date_col] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    \n\n    # Prefix for new columns\n    pre = re.sub('[Dd]ate', '', date_col)\n    pre = re.sub('[Tt]ime', '', pre)\n    \n    # Basic attributes\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Days_in_month', 'is_leap_year']\n    \n    # Additional attributes\n    if extra_attr:\n        attr = attr + ['Is_month_end', 'Is_month_start', 'Is_quarter_end', \n                       'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    \n    # If time is specified, extract time information\n    if time: \n        attr = attr + ['Hour', 'Minute', 'Second']\n        \n    # Iterate through each attribute\n    for n in attr: \n        df[pre + n] = getattr(fld.dt, n.lower())\n        \n    # Calculate days in year\n    df[pre + 'Days_in_year'] = df[pre + 'is_leap_year'] + 365\n        \n    if time:\n        # Add fractional time of day (0 - 1) units of day\n        df[pre + 'frac_day'] = ((df[pre + 'Hour']) + (df[pre + 'Minute'] / 60) + (df[pre + 'Second'] / 60 / 60)) / 24\n        \n        # Add fractional time of week (0 - 1) units of week\n        df[pre + 'frac_week'] = (df[pre + 'Dayofweek'] + df[pre + 'frac_day']) / 7\n    \n        # Add fractional time of month (0 - 1) units of month\n        df[pre + 'frac_month'] = (df[pre + 'Day'] + (df[pre + 'frac_day'])) / (df[pre + 'Days_in_month'] +  1)\n        \n        # Add fractional time of year (0 - 1) units of year\n        df[pre + 'frac_year'] = (df[pre + 'Dayofyear'] + df[pre + 'frac_day']) / (df[pre + 'Days_in_year'] + 1)\n        \n    # Add seconds since start of reference\n    df[pre + 'Elapsed'] = (fld - start_ref).dt.total_seconds()\n    \n    if drop: \n        df = df.drop(date_col, axis=1)\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da2ec6075b160df9d852712f233e41cd9c6cf450"},"cell_type":"code","source":"print(train['pickup_datetime'].min())\nprint(test['pickup_datetime'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a42acc94e957874cf7498cde92945774db05641"},"cell_type":"code","source":"test = extract_dateinfo(test, 'pickup_datetime', drop = False, time = True)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b03f38035ffdc2d71a5998ebab8223bcf6ea5e94"},"cell_type":"code","source":"train = extract_dateinfo(train, 'pickup_datetime', drop = False, \n                         time = True)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45d477d10cd1a1f7ea034849e3429a8f5d0c3773"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"78f4a6e0de484ec5b1f502619bf05ad3d6143594","trusted":true},"cell_type":"code","source":"sns.lmplot('pickup_Elapsed','fare_amount', hue = 'pickup_Year', palette=palette, data = train , fit_reg= False, scatter_kws= {'alpha': 0.05},markers='.',size=8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34fd425db72ff23c8f0396ba8ab141e863bd8ae1"},"cell_type":"code","source":"plt.figure(figsize = (12,10))\n\nfor h, grouped in train.groupby('pickup_Hour'):\n    sns.kdeplot(grouped['fare_amount'], label = f'{h} hour');\nplt.title('fare by Hour of the Day');\n    \n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80be2b749974da2681f1176756f5c557ffc30119"},"cell_type":"code","source":"plt.figure(figsize = (12,10))\n\nfor h, grouped in train.groupby('pickup_Dayofweek'):\n    sns.kdeplot(grouped['fare_amount'], label = f'{h}');\nplt.title('fare by Day of the week');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e9e1c1d7080f283a8d65e1a4a31c76d6c94d292"},"cell_type":"code","source":"correlation = train.corr()\ncorrelation['fare_amount'].plot.bar(figsize = (12,10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ee133e48dda29f22f69e4400bef4c3399a4c0d2"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train, np.array(train['fare_amount']), \n                                                      stratify = train['fare-bin'],\n                                                      random_state = 100, test_size = 100_000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"988a811759336630a42bd6bbd19a3fed14e1f753"},"cell_type":"code","source":"time_features = ['pickup_frac_day', 'pickup_frac_week', 'pickup_frac_year', 'pickup_Elapsed']\n\nfeatures = ['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count',\n            'pickup_latitude', 'pickup_longitude', \n            'dropoff_latitude', 'dropoff_longitude'] + time_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f33f2dc7cf6fdb39e2550d17a3e73fdebf22c9b7"},"cell_type":"code","source":"def model_rf(X_train, X_valid, y_train, y_valid, test, features,\n             model = RandomForestRegressor(n_estimators = 20, max_depth = 20,\n                                           n_jobs = -1),\n             return_model = False):\n    \"\"\"Train and evaluate the random forest using the given set of features.\"\"\"\n    \n    # Train\n    model.fit(X_train[features], y_train)\n    \n    # Validation\n    evaluate(model, features, X_train, X_valid, y_train, y_valid)\n    \n    # Make predictions on test and generate submission dataframe\n    preds = model.predict(test[features])\n    sub = pd.DataFrame({'key': test_id, 'fare_amount': preds})\n    \n    # Extract feature importances\n    feature_importances = pd.DataFrame({'feature': features,\n                                        'importance': model.feature_importances_}).\\\n                           sort_values('importance', ascending = False).set_index('feature')\n    \n    if return_model:\n        return sub, feature_importances, model\n    \n    return sub, feature_importances","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfb5afc38b4fc9c6dc637aaf205480eb8218aad1"},"cell_type":"code","source":"sub, f1 = model_rf(X_train, X_valid, y_train, y_valid, test, features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dd8947d2801c071cb27e8f32bcdf85b3814fb64"},"cell_type":"code","source":"f1.importance.plot.bar(figsize=(10,8), color='g')\nplt.title('Feature Importance of RF model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ffcfbcdb19b93adb3dd049c1b2d7b3fee65fbb1"},"cell_type":"code","source":"key = train.key","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bcaa2b182c608cef948a228cffcf1599b0ad387"},"cell_type":"code","source":"df = train.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7acf86bbac360f15f26304b2f0cb12475feb3248"},"cell_type":"code","source":"features = list(train.columns)\nfor f in ['pickup_datetime','fare_amount', 'fare-bin', 'color','key']:\n    features.remove(f)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc7e26316c1eca116e289010a021d9f48c02017"},"cell_type":"code","source":"features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a591f7e267fac82532f24baf083c1f272474d0e"},"cell_type":"code","source":"sub, fi, random_forest = model_rf(X_train, X_valid, y_train, y_valid, test,features = features, return_model = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fbb3a4e5b88f33feb08833264e72a23ecff2a5a"},"cell_type":"code","source":"valid_preds = random_forest.predict(X_valid[features])\n\nplt.figure(figsize = (10, 6))\nsns.kdeplot(y_valid, label = 'Actual')\nsns.kdeplot(valid_preds, label = 'Predicted')\nplt.legend(prop = {'size': 30})\nplt.title(\"Distribution of Validation Fares\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a135c368ee41b1bcb35fcd6690bef71df572670"},"cell_type":"code","source":"def ecdf(x):\n    \"\"\"Empirical cumulative distribution function of a variable\"\"\"\n    # Sort in ascending order\n    x = np.sort(x)\n    n = len(x)\n    \n    # Go from 1/n to 1\n    y = np.arange(1, n + 1, 1) / n\n    \n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a22374dcf83ae6d060a99630e397966b59782529"},"cell_type":"code","source":"xv, yv = ecdf(valid_preds)\nxtrue, ytrue = ecdf(y_valid)\n\n# Plot the ecdfs on same plot\nplt.scatter(xv, yv, s = 0.02,  c = 'r', marker = '.', label = 'Predicted')\nplt.scatter(xtrue, ytrue, s = 0.02, c = 'b', marker = '.', label = 'True')\nplt.title('ECDF of Predicted and Actual Validation')\n\nplt.legend(markerscale = 100, prop = {'size': 20});","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f94ca0f632b83d1678e24c209f56e6a16d8fb741"},"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV\n\nparam_grid = {\n    'n_estimators' : np.linspace(10,100).astype(int),\n    'max_depth' : [None] + list(np.linspace(5,30).astype(int)),\n    'max_features' : ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n    'max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n    'min_samples_split': [2, 5, 10],\n    'bootstrap': [True, False]\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cc8df68d0ead5297af7e4f35854a6d246cee59d"},"cell_type":"code","source":"estimator = RandomForestRegressor(random_state = 100)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"96895e8524598f74651e69b57383f6d2f9e1399f"},"cell_type":"code","source":"rs = RandomizedSearchCV(estimator, param_grid, n_iter = 100, n_jobs=-1, scoring = 'neg_mean_absolute_error', cv = 3,verbose=1, random_state=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dd9e7ad73d41f8fa9f0a10e4eda7ec7ff7c54ab"},"cell_type":"code","source":"tune_data = train.sample(100_000, random_state = 100)\n\n# Select features\ntime_features = ['pickup_frac_day', 'pickup_frac_week', 'pickup_frac_year', 'pickup_Elapsed']\n\nfeatures = ['abs_lat_diff', 'abs_lon_diff', 'haversine', 'passenger_count',\n            'pickup_latitude', 'pickup_longitude', \n            'dropoff_latitude', 'dropoff_longitude'] + time_features\n\nrs.fit(tune_data[features],np.array(tune_data['fare_amount']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95b27d57ff03799a02b5bf2fc0847d6ab2a1ced3"},"cell_type":"code","source":"model = rs.best_estimator_\nprint(f'The best parameters were {rs.best_params_} with a negative mae of {rs.best_score_}')\nmodel.n_jobs = -1\nmodel.fit(X_train[features], y_train)\n\nevaluate(model, features, X_train, X_valid, y_train, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6efcc38a24fd96f93f500c3d2e448c6f75c02ce1"},"cell_type":"code","source":"pred = np.array(model.predict(test[features])).reshape((-1))\nsub = pd.DataFrame({'key': test_id, 'fare_amount': pred})\nsub.to_csv('sub_rf_tuned.csv', index = False)\nsub['fare_amount'].plot.hist();\nplt.title('Predicted Test Fare Distribution');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ba57e6044fd7fcb733b950316498d22b94d85bde"},"cell_type":"code","source":"import xgboost as xgb\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2291477095f3ff77fb113e230666d03be350db9e"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(train[features],\n                                                    train['fare_amount'], test_size=0.25)\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\ndel(X_train)\ndtest = xgb.DMatrix(X_test)\ndel(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fedd62d0503c696e7743d9ad74102c8bd01764f1"},"cell_type":"code","source":"def xgb_evaluate(max_depth, gamma, colsample_bytree):\n    params = {'eval_metric': 'rmse',\n              'max_depth': int(max_depth),\n              'subsample': 0.8,\n              'eta': 0.1,\n              'gamma': gamma,\n              'colsample_bytree': colsample_bytree}\n    # Used around 1000 boosting rounds in the full model\n    cv_result = xgb.cv(params, dtrain, num_boost_round=100, nfold=3)    \n    \n    # Bayesian optimization only knows how to maximize, not minimize, so return the negative RMSE\n    return -1.0 * cv_result['test-rmse-mean'].iloc[-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"444b48a52f3963e07d85709566cac4b6337d6dd8"},"cell_type":"code","source":"xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth': (3, 7), \n                                             'gamma': (0, 1),\n                                             'colsample_bytree': (0.3, 0.9)})\n# Use the expected improvement acquisition function to handle negative numbers\n# Optimally needs quite a few more initiation points and number of iterations\nxgb_bo.maximize(init_points=3, n_iter=5, acq='ei')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d5f7ffd471f722e1703769aa19027b433d2ef00"},"cell_type":"code","source":"params = xgb_bo.res['max']['max_params']\nparams['max_depth'] = int(params['max_depth'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9c4f297bfacff67248789fb5f4f10683890c8424"},"cell_type":"code","source":"model2 = xgb.train(params, dtrain, num_boost_round=250)\n\n# Predict on testing and training set\ny_pred = model2.predict(dtest)\ny_train_pred = model2.predict(dtrain)\n\n# Report testing and training RMSE\nprint(np.sqrt(mean_squared_error(y_test, y_pred)))\nprint(np.sqrt(mean_squared_error(y_train, y_train_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f226ee0806e887de17da0f2873b55bde7e3433d"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfscores = pd.DataFrame({'X': list(model2.get_fscore().keys()), 'Y': list(model2.get_fscore().values())})\nfscores.sort_values(by='Y').plot.bar(x='X')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6b2a292fddb3b1717b3e98767597d2f78050622"},"cell_type":"code","source":"dtest = xgb.DMatrix(test[features])\ny_pred_test = model2.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7cafb5008ae15963758e9e7b2197716083d8ee8d"},"cell_type":"code","source":"holdout = pd.DataFrame({'key': test_id, 'fare_amount': y_pred_test})\nholdout.to_csv('submission_xgb.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}