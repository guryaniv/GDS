{"cells":[{"metadata":{"_uuid":"e172d32f4703cd778258e0882c4e80743cd10849"},"cell_type":"markdown","source":"From 1st place ideas, https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629\n\nSingle denoise autoencoder with \"SwapNoise\" + classification output"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras \nimport gc\nfrom keras.utils import Sequence\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Input, Concatenate, Dropout\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b68a7e87a36d068c01f9a7d980e077ed1d9728c1"},"cell_type":"markdown","source":"Reading Dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print('Reading datasets')\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nprint('Merging test and train')\ntest['target'] = np.nan\ntrain = train.append(test).reset_index() # merge train and test\ndel test\nprint('Done, shape=',np.shape(train))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6e9096d8c77a6fab690eee73e69a3b0ff692ad1"},"cell_type":"markdown","source":"Rank Gauss transformation"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"29a7e53372569af14d1dfad6b49374e36010e4a2"},"cell_type":"code","source":"# i must congrats someone that did this, but i read it on internet, please if it's you, congrats, and explain your code :)\ndef rank_gauss(x):\n    from scipy.special import erfinv\n    N = x.shape[0]\n    temp = x.argsort()\n    rank_x = temp.argsort() / N\n    rank_x -= rank_x.mean()\n    rank_x *= 2\n    efi_x = erfinv(rank_x)\n    efi_x -= efi_x.mean()\n    return efi_x\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a87b76a47c82f018d52a134abd9f96fc9cacc2dd"},"cell_type":"markdown","source":"Categorical to RankGauss, Binary to -1/1"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"709daa5d14be87e2d0de842f636edea2ef259754"},"cell_type":"code","source":"for i in train.columns:\n    if i.endswith('cat'): # could be train[i].dtype == 'object' + labelencode, or maybe one hot encode...\n        print('Categorical: ',i)\n        train[i] = rank_gauss(train[i].values)\n    elif i.endswith('bin'):\n        print('Binary: ',i) # maybe use -1 / 1?\n        #train[i] = train[i] * 2 - 1\n    else:\n        print('Numeric: ',i)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed445f28edb67507e6a426977ba5cc97e2a281b3"},"cell_type":"markdown","source":"Read/Write Locker Help"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"69a79572e5df8d4fe7936ba89c369e540ed40144"},"cell_type":"code","source":"# i'm doing this cause i don't know if some keras backend have threading problems...\nimport threading\nclass ReadWriteLock:\n    def __init__(self):\n        self._read_ready = threading.Condition(threading.Lock())\n        self._readers = 0\n    def acquire_read(self):\n        self._read_ready.acquire()\n        try:\n            self._readers += 1\n        finally:\n            self._read_ready.release()\n    def release_read(self):\n        self._read_ready.acquire()\n        try:\n            self._readers -= 1\n            if not self._readers:\n                self._read_ready.notifyAll()\n        finally:\n            self._read_ready.release()\n    def acquire_write(self):\n        self._read_ready.acquire()\n        while self._readers > 0:\n            self._read_ready.wait()\n    def release_write(self):\n        self._read_ready.release()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ff8ef15e35a609eec68d99eb1a21ab9cdcf2de1"},"cell_type":"markdown","source":"DAE Generator"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1958ad44e654265864783cd990a3f690bccb0a78"},"cell_type":"code","source":"from math import ceil\nclass DAESequence(Sequence):\n    def __init__(self, df, batch_size=128, random_cols=.15, random_rows=1, use_cache=False, use_lock=False, verbose=True):\n        self.df = df.values.copy()     # ndarray baby\n        self.batch_size = int(batch_size)\n        self.len_data = df.shape[0]\n        self.len_input_columns = df.shape[1]\n        if(random_cols <= 0):\n            self.random_cols = 0\n        elif(random_cols >= 1):\n            self.random_cols = self.len_input_columns\n        else:\n            self.random_cols = int(random_cols*self.len_input_columns)\n        if(self.random_cols > self.len_input_columns):\n            self.random_cols = self.len_input_columns\n        self.random_rows = random_rows\n        self.cache = None\n        self.use_cache = use_cache\n        self.use_lock = use_lock\n        self.verbose = verbose\n        \n        self.lock = ReadWriteLock()\n        self.on_epoch_end()\n\n    def on_epoch_end(self):\n        if(not self.use_cache):\n            return\n        if(self.use_lock):\n            self.lock.acquire_write()\n        if(self.verbose):\n            print(\"Doing Cache\")\n        self.cache = {}\n        for i in range(0, self.__len__()):\n            self.cache[i] = self.__getitem__(i, True)\n        if(self.use_lock):\n            self.lock.release_write()\n        gc.collect()\n        if(self.verbose):\n            print(\"Done\")\n\n    def __len__(self):\n        return int(ceil(self.len_data / float(self.batch_size)))\n\n    def __getitem__(self, idx, doing_cache=False):\n        if(not doing_cache and self.cache is not None and not (self.random_cols <=0 or self.random_rows<=0)):\n            if(idx in self.cache.keys()):\n                if(self.use_lock):\n                    self.lock.acquire_read()\n                ret0, ret1 = self.cache[idx][0], self.cache[idx][1]\n                if(self.use_lock):\n                    self.lock.release_read()\n                if (not doing_cache and self.verbose):\n                    print('DAESequence Cache ', idx)\n                return ret0, ret1\n        idx_end = min(idx + self.batch_size, self.len_data)\n        cur_len = idx_end - idx\n        rows_to_sample = int(self.random_rows * cur_len)\n        input_x = self.df[idx: idx_end]\n        if (self.random_cols <= 0 or self.random_rows <= 0 or rows_to_sample<=0):\n            return input_x, input_x # not dae\n        # here start the magic\n        random_rows = np.random.randint(low=0, high=self.len_data-rows_to_sample, size=rows_to_sample)\n        random_rows[random_rows>idx] += cur_len # just to don't select twice the current rows\n        cols_to_shuffle = np.random.randint(low=0, high=self.len_input_columns, size=self.random_cols)\n        noise_x = input_x.copy()\n        noise_x[0:rows_to_sample, cols_to_shuffle] = self.df[random_rows[:,None], cols_to_shuffle]\n        if(not doing_cache and self.verbose):\n            print('DAESequence ', idx)\n        return noise_x, input_x\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b58c818032fde555aaf1c8f93c2c21bb57618f48"},"cell_type":"markdown","source":"Creating Model and Fitting with multi gpu (not most performace, but 'works', there's a bottleneck with cpu->gpu mem copy)"},{"metadata":{"trusted":true,"_uuid":"5694b5b1c11488c53529d8b1556bd1066d346532"},"cell_type":"code","source":"print(\"Create Model\")\ndae_data = train[train.columns.drop(['id','target'])] # only get \"X\" vector\n\n# reduce data size, we are in kaggle =)\ndae_data = dae_data[0:1000]\n\nlen_input_columns, len_data = dae_data.shape[1], dae_data.shape[0]\nNUM_GPUS=1\n#kernel_initializer='Orthogonal'  # this one give non NaN more often than others \n\n# from https://kaggle2.blob.core.windows.net/forum-message-attachments/250927/8325/nn.cfg.log\n#L0: 221(in)-1500 'r'ReLU  lRate:0.003 lRateDecay:0.995 regL2:0 regL1:0 dropout:0  w:222x1500  out(x3):1501x128 (0.00210051 GB) init..(uni:1 sp:1)[min|max|mean|std:-0.0672672|0.0672671|-4.74564e-05|0.0388202]\n#L1: 1500(in)-1500 'r'ReLU  lRate:0.003 lRateDecay:0.995 regL2:0 regL1:0 dropout:0  w:1501x1500  out(x3):1501x128 (0.00977451 GB) init..(uni:1 sp:1)[min|max|mean|std:-0.0258199|0.0258199|8.51905e-06|0.0148989]\n#L2: 1500(in)-1500 'r'ReLU  lRate:0.003 lRateDecay:0.995 regL2:0 regL1:0 dropout:0  w:1501x1500  out(x3):1501x128 (0.00977451 GB) init..(uni:1 sp:1)[min|max|mean|std:-0.0258199|0.0258199|8.51905e-06|0.0148989]\n#L3: 1500(in)-221 'l'linear  lRate:0.003 lRateDecay:0.995 regL2:0 regL1:0 dropout:0  w:1501x221  out(x3):222x128 (0.00144055 GB) init..(uni:1 sp:1)[min|max|mean|std:-0.0258199|0.0258198|-1.80977e-05|0.0149005]\n\nkernel_initializer_0=keras.initializers.RandomNormal(mean=-4.74564e-05, stddev=0.0388202, seed=None)\nkernel_initializer_1=keras.initializers.RandomNormal(mean=8.51905e-06, stddev=0.0148989, seed=None)\nkernel_initializer_2=keras.initializers.RandomNormal(mean=8.51905e-06, stddev=0.0148989, seed=None)\nkernel_initializer_3=keras.initializers.RandomNormal(mean=-1.80977e-05, stddev=0.0149005, seed=None)\n\nprint(\"Input len=\", len_input_columns, len_data)\nmodel_dae = Sequential()\nmodel_dae.add(Dense(units=len_input_columns*10, activation='relu', dtype='float32', name='Hidden1', input_shape=(len_input_columns,), kernel_initializer=kernel_initializer_0))\nmodel_dae.add(Dense(units=len_input_columns*10, activation='relu', dtype='float32', name='Hidden2', kernel_initializer=kernel_initializer_1))\nmodel_dae.add(Dense(units=len_input_columns*10, activation='relu', dtype='float32', name='Hidden3', kernel_initializer=kernel_initializer_2))\nmodel_dae.add(Dense(units=len_input_columns, activation='linear', dtype='float32', name='Output', kernel_initializer=kernel_initializer_3))\nmodel_opt = keras.optimizers.SGD(lr=0.003, decay=0.995, momentum=0, nesterov=False)\n\ntry:\n    print('Loading model from file')\n    model_dae = keras.models.load_model('DAE.keras.model.h5')\nexcept Exception as e:\n    print(\"Can't load previous fitting parameters and model\", repr(e))\nif(NUM_GPUS>1):\n    try:\n        multi_gpu_model = keras.utils.multi_gpu_model(model_dae, gpus=NUM_GPUS)\n        multi_gpu_model.compile(loss='mean_squared_error', optimizer=model_opt)\n        print(\"MULTI GPU MODEL\")\n        print(multi_gpu_model.summary())\n    except Exception as e:\n        print(\"Can't run multi gpu, error=\", repr(e))\n        model_dae.compile(loss='mean_squared_error', optimizer=model_opt)\n        NUM_GPUS=0\nelse:\n    model_dae.compile(loss='mean_squared_error', optimizer=model_opt)\n\nprint(\"BASE MODEL\")\nprint(model_dae.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4e7f7c5768759b6dff301ea239fe4a235583d0b"},"cell_type":"markdown","source":"Fitting model with data"},{"metadata":{"trusted":true,"_uuid":"5286f08ee919696c00f529398cb8bc7f0c0bd6c0","scrolled":true},"cell_type":"code","source":"from math import ceil\nbatch_size = 128\nmulti_process_workers = 2\nif (NUM_GPUS > 1):\n    multi_gpu_model.fit_generator(\n        DAESequence(dae_data, batch_size=batch_size*NUM_GPUS, verbose=False),\n        steps_per_epoch=int(ceil(dae_data.shape[0]/(batch_size*NUM_GPUS))),\n        workers=multi_process_workers, use_multiprocessing=True if multi_process_workers>1 else False,\n        epochs=1000,\n        verbose=1,\n        callbacks=[\n            # keras.callbacks.LambdaCallback(on_epoch_end=lambda x,y: model_dae.save('DAE.keras.model.h5')) # save weights \n        ])\nelse: # single CPU/GPU\n    model_dae.fit_generator(\n        DAESequence(dae_data, batch_size=batch_size, verbose=False),\n        steps_per_epoch=int(ceil(dae_data.shape[0]/batch_size)),\n        epochs=1000,\n        workers=multi_process_workers, use_multiprocessing=True if multi_process_workers>1 else False,\n        verbose=1, callbacks=[\n            # keras.callbacks.LambdaCallback(on_epoch_end=lambda x,y: model_dae.save('DAE.keras.model.h5')) # save weights\n        ])\n    \n#model_dae.save('DAE.keras.model.h5') # save weights\n\nplt.hist(model_dae.get_weights(), bins = 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"fa6805483f0c52889fa2f23dcf155432accaeb4b"},"cell_type":"markdown","source":"# Predict from data and we are done"},{"metadata":{"trusted":true,"_uuid":"dd870a1bcb98c3a798ec7534f39e16eb05292394","scrolled":true},"cell_type":"code","source":"# lest clone the model and freeze trainable layers\nkernel_initializer_1 = keras.initializers.RandomNormal(mean=-3.91408e-06, stddev=0.0085923, seed=None)   # 'RandomNormal'\nkernel_initializer_2 = keras.initializers.RandomNormal(mean=-1.08996e-05, stddev=0.0182625, seed=None)   # 'RandomNormal'\nkernel_initializer_output = keras.initializers.RandomNormal(mean=-0.000604642, stddev=0.0185643, seed=None)   # 'RandomNormal'\n\n\nmodel_clf = keras.models.clone_model(model_dae)\nmodel_clf.set_weights(model_dae.get_weights())\nmodel_clf.layers.pop() # remove last layer (output)\nfor i in model_clf.layers:\n    i.trainable = False # freeze\nnext_layer = Concatenate(name='InputClf')([model_clf.get_layer('Hidden1').output,\n                                        model_clf.get_layer('Hidden2').output,\n                                        model_clf.get_layer('Hidden3').output])\nnext_layer = Dropout(0.1, name='CLfDropoutInput')(next_layer)\nnext_layer = Dense(units=1000, activation='relu', dtype='float32', name='CLfHidden1',\n                    kernel_regularizer=keras.regularizers.l2(0.05), kernel_initializer=kernel_initializer_1)(next_layer)\nnext_layer = Dropout(0.5, name='CLfDropout1')(next_layer)\nnext_layer = Dense(units=1000, activation='relu', dtype='float32', name='CLfHidden2',\n                    kernel_regularizer=keras.regularizers.l2(0.05), kernel_initializer=kernel_initializer_2)(next_layer)\nnext_layer = Dropout(0.0, name='CLfDropout2')(next_layer)\nnext_layer = Dense(units=1, activation='sigmoid', dtype='float32', name='CLfOutput',\n                    kernel_regularizer=keras.regularizers.l2(0.05), kernel_initializer=kernel_initializer_output)(next_layer)\nmodel_clf = Model(inputs=model_clf.input, outputs=next_layer)\nmodel_clf_opt = keras.optimizers.SGD(lr=0.0001, decay=0.995, momentum=0, nesterov=False)\n\nif(NUM_GPUS>1):\n    try:\n        multi_gpu_model_clf = keras.utils.multi_gpu_model(model_dae, gpus=NUM_GPUS)\n        multi_gpu_model_clf.compile(loss='binary_crossentropy', optimizer=model_clf_opt)\n        print(\"MULTI GPU CLF MODEL\")\n        print(multi_gpu_model_clf.summary())\n    except Exception as e:\n        print(\"Can't run multi gpu, error=\", repr(e))\n        model_clf.compile(loss='binary_crossentropy', optimizer=model_clf_opt)\n        NUM_GPUS=1\nelse:\n    model_clf.compile(loss='binary_crossentropy', optimizer=model_clf_opt)\n\nprint(\"BASE CLF MODEL\")\nprint(model_clf.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a1d0376abf968f7208d96c27cb1d833ebbdcf82"},"cell_type":"code","source":"your_new_df=train.copy()\n# let's cut it again...\n# reduce data size, we are in kaggle =), it's just an example\nyour_new_df = your_new_df[0:1000]\n\n\n\nmodel_clf.fit(\n    x=your_new_df[your_new_df.columns.drop(['id','target'])].values,\n    y=your_new_df['target'].values,\n    batch_size=128,\n    epochs=100,\n    verbose=1,\n    validation_split=.3,\n    callbacks = [\n        #keras.callbacks.LambdaCallback(on_epoch_end=lambda x, y: model_clf.save('CLF.keras.model.h5')),\n        #keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n    ]\n)\n\nplt.hist(model_clf.get_weights(), bins = 100)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7c47437aafcf63aff2ae4a01938eece7d5ee0ec"},"cell_type":"code","source":"# model_clf.save('CLF.keras.model.h5')\n# good luck :)\nY_hat=model_clf.predict(your_new_df[your_new_df.columns.drop(['id','target'])].values)\nfrom sklearn.metrics import log_loss\nprint(log_loss(your_new_df['target'], Y_hat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8e1cd8faa751b55e24889dd6db028d89871a9506"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}