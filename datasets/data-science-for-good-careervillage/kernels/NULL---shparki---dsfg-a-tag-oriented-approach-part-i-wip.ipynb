{"cells":[{"metadata":{"_uuid":"ef8e86627481cd8fa21813994fed159ce3edc5fe"},"cell_type":"markdown","source":"# **Data Science for Good: A Tag-Oriented Approach**\n---\n\n## Introduction\n\nIn order to minimize the use of machine learning algorithms, we will focus explicitly on the tags that are scattered throughout the data sets. Each question has tags, and in turn each user follows certain tags- both the users that ask questions and those that answer and comment on questions. We will make assumptions of the users that *they* determine which tags are related, not computers. To employ this, we will create a voting mechanism that will give certain tags votes for relatability based on how frequently they are used together when posting questions. Additionally, when users follow tags, we will attempt to cluster those in a similar fashion into relationship groups that vote in a similar fashion together. Lastly, when users comment on questions, we will make the assumption that the user was intrigued or in a way drawn to the question, and in-turn will vote on the question in favor of relatability based off the tags they follow and the tags that question self-determines. This will help cover content gaps that the original user may not have taken into account when initially tagging the question. \n\nAll of this together will be used to link the question askers to question answerers. When a user asks a question, and assigns certain tags to the question, this algorithm will compare those tags with the most related tags and compare that to a list of professionals that also have shown interest in those. \n"},{"metadata":{"_uuid":"5978ce3cd1d482a895d8bb3f54a217c1e6cf6ee4"},"cell_type":"markdown","source":"## Part I: Organizing and Cleaning Data\n---\nOur goals for Phase I:\n* Build more intuitive relationships between the separate files by combining related datasets into single pandas DataFrames.\n* Construct member-first DataFrames that make the multiple one-many relationships more explicit.\n* Perform some preliminary cleaning of the data by making dates more human-readable, make identifiers strings, and (most importantly) remove formating from answers to make the text processing more direct."},{"metadata":{"trusted":true,"_uuid":"c26159eb022608700952fa59a0e7712fbfdd98dd"},"cell_type":"code","source":"# Import required packages\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pandas.api.types import CategoricalDtype\nfrom IPython.display import display","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c12142cad29232d5780cb5fc79eba915c8c3a50d"},"cell_type":"markdown","source":"## Let's import some data!"},{"metadata":{"_kg_hide-input":false,"trusted":true,"_uuid":"095fb1f4b9c3912e15edbe6e72ba6a54ae5507ff"},"cell_type":"code","source":"answers = pd.read_csv('../input/answers.csv',\n                           infer_datetime_format = True,\n                           dtype = {\n                              'answers_id': str,\n                              'answers_author_id': str,\n                              'answers_question_id': str,\n                              'answers_body': str\n                          },\n                          parse_dates = ['answers_date_added'])\nanswers.columns = ['id', 'author_id', 'question_id', 'date_added', 'body']\nanswers.set_index('id', inplace = True)\nanswers.sort_index(kind = 'mergesort', inplace = True)\ndisplay(answers.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ac3ea9a140a9a1eb90738fb4f1656c9a53deda5b"},"cell_type":"code","source":"comments = pd.read_csv('../input/comments.csv',\n                           infer_datetime_format = True,\n                           dtype = {\n                               'comments_id': str,\n                               'comments_author_id': str,\n                               'comments_parent_content_id': str,\n                               'comments_body': str\n                           },\n                           parse_dates = ['comments_date_added'])\ncomments.columns = ['id', 'author_id', 'parent_id', 'date_added', 'body']\ncomments.set_index('id', inplace = True)\ncomments.sort_index(kind = 'mergesort', inplace = True)\ndisplay(comments.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c50365331cd6044a01e652c0eb05993cbd0aeeb1"},"cell_type":"code","source":"# Look into categories for email_freq\n\n_cat_emails = pd.read_csv('../input/emails.csv', \n                         usecols=['emails_frequency_level'],\n                        squeeze = True).unique()\nprint(_cat_emails)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e60b695ff67cb8bbb9f1f2314a66ce95ebb5c62"},"cell_type":"code","source":"cat_emails = CategoricalDtype(\n    categories = [ 'email_notification_immediate', 'email_notification_daily',\n                   'email_notification_weekly'],\n     ordered=True) # Not using _cat_emails because ordered to preserve frequency order","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26245959d1946ca035eba056f5003f478179374c"},"cell_type":"code","source":"emails = pd.read_csv('../input/emails.csv',\n                         infer_datetime_format = True,\n                         dtype = {\n                             'emails_id': str,\n                             'emails_recipient_id': str,\n                             'emails_frequency_level': cat_emails,\n                         },\n                         parse_dates = ['emails_date_sent'])\nemails.columns = ['id', 'recipient_id', 'date_sent', 'frequency']\nemails.set_index('id', inplace=True)\nemails.sort_index(kind = 'mergesort', inplace = True)\ndisplay(emails.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18cf3b4459fbdb2f54588dba30b8f82eeeef7a9f"},"cell_type":"code","source":"group_memberships = pd.read_csv('../input/group_memberships.csv',\n                                    dtype = {\n                                        'group_memberships_group_id': str,\n                                        'group_memberships_user_id': str\n                                    })\ngroup_memberships.columns = ['group_id', 'user_id']\ngroup_memberships.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccd8d716fe8c5bed9e7aa825e9e657f848fae6e7"},"cell_type":"code","source":"# Take a look at group types\n\n_cat_groups = pd.read_csv('../input/groups.csv', \n                         usecols=['groups_group_type'],\n                        squeeze = True).unique()\nprint(_cat_groups)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c9a63f37cc7c3c13428008973b17f28fd430c24"},"cell_type":"code","source":"cat_groups = CategoricalDtype(categories = _cat_groups, ordered=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf13976ab1edf7753085e6079e4f1444b105f6e9"},"cell_type":"code","source":"groups = pd.read_csv('../input/groups.csv',\n                         dtype = {\n                             'groups_id': str,\n                             'groups_group_type': cat_groups\n                         })\ngroups.columns = ['id', 'type']\ngroups.set_index('id', inplace = True)\ngroups.sort_index(kind = 'mergesort', inplace = True)\ndisplay(groups.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4f80a3219315b8e41a00376b6f165c75c810ab1"},"cell_type":"code","source":"matches = pd.read_csv('../input/matches.csv',\n                          dtype = {\n                              'matches_email_id': str,\n                              'matches_question_id': str\n                          })\nmatches.columns = ['email_id', 'question_id']\nmatches.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c51d057a5c60611db7b290b3a87740f9a93a27eb"},"cell_type":"code","source":"# Take a look at professional industry types\n\n_cat_indus = pd.read_csv('../input/professionals.csv', \n                         usecols=['professionals_industry'],\n                        squeeze = True).unique()\nprint(len(_cat_indus))\n\n# It seems like industries are user specified so there is a large amount of variability here. \n# Maybe we can attempt to clean this up and add more structure in a bit...\n# For now, we will treat this column as a string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47312d555c7d7097774278e9fc8780f2f857e6a5"},"cell_type":"code","source":"professionals = pd.read_csv('../input/professionals.csv',\n                                 infer_datetime_format = True,\n                                 dtype = {\n                                     'professionals_id': str,\n                                     'professionals_location': str,\n                                     'professionals_industry': str,\n                                     'professionals_headline': str\n                                 },\n                                parse_dates = ['professionals_date_joined'])\nprofessionals.columns = ['id', 'location', 'industry', 'headline', 'date_joined']\nprofessionals.set_index('id', inplace = True)\nprofessionals.sort_index(kind = 'mergesort', inplace = True)\ndisplay(professionals.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc8f34ddcd7f2dc3870bc5dca43e80321e3eecb5"},"cell_type":"code","source":"questions = pd.read_csv('../input/questions.csv',\n                       infer_datetime_format = True,\n                       dtype = {\n                           'questions_id': str,\n                           'questions_author_id': str,\n                           'questions_title': str,\n                           'questions_body': str\n                       },\n                       parse_dates = ['questions_date_added'])\nquestions.columns = ['id', 'author_id', 'date_added', 'title', 'body']\nquestions.set_index('id', inplace = True)\nquestions.sort_index(kind = 'mergesort', inplace = True)\ndisplay(questions.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"571bab7cd908dacd2c1db09289de5445a604cb6a"},"cell_type":"code","source":"school_memberships = pd.read_csv('../input/school_memberships.csv',\n                                dtype = {\n                                    'school_memberships_school_id': str,\n                                    'school_memberships_user_id': str\n                                })\nschool_memberships.columns = ['school_id', 'user_id']\nschool_memberships.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d6bcf16dcd5e10defd96de312ccd409f55a3410"},"cell_type":"code","source":"students = pd.read_csv('../input/students.csv',\n                      infer_datetime_format = True,\n                      dtype = {\n                          'students_id': str,\n                          'students_location': str\n                      },\n                      parse_dates = ['students_date_joined'])\nstudents.columns = ['id', 'location', 'date_joined']\nstudents.set_index('id', inplace = True)\nstudents.sort_index(kind = 'mergesort', inplace = True)\ndisplay(students.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1117783bcf1bc312e725592fac7e509529f835f9"},"cell_type":"code","source":"questions_tags = pd.read_csv('../input/tag_questions.csv',\n                           dtype = {\n                               'tag_questions_tag_id': str,\n                               'tag_questions_question_id': str\n                           })\nquestions_tags.columns = ['tag_id', 'question_id']\nquestions_tags.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b5aea0c26025c43e7714516ae794db285c74e1d0"},"cell_type":"code","source":"users_tags = pd.read_csv('../input/tag_users.csv',\n                           dtype = {\n                               'tag_users_tag_id': str,\n                               'tag_users_user_id': str\n                           })\nusers_tags.columns = ['tag_id', 'user_id']\nusers_tags.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"tags = pd.read_csv('../input/tags.csv',\n                  dtype = {\n                      'tags_tag_id': str,\n                      'tags_tag_name': str\n                  })\ntags.columns = ['id', 'name']\ntags.set_index('id', inplace = True)\ntags.sort_index(kind = 'mergesort', inplace = True)\ndisplay(tags.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e979f3a29d5ab3fc5379e0061a04436687d1b6f4"},"cell_type":"markdown","source":"## Let's make some composite DataFrames!"},{"metadata":{"trusted":true,"_uuid":"74f13121f9458fd9a842e6a6c48bd862a8296c5b"},"cell_type":"code","source":"# Helper functions\n\n# Replace a Series with one where NaN are converted to an empty list\n# @args\n# s: Series\ndef conv_nan_list(s):\n    s[s.isnull()] = s[s.isnull()].apply(lambda x: [])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68ae0f10b478553293893f1d182eac7961a245ea"},"cell_type":"code","source":"# Split group_memberhsips to user -> groups and group -> users\n\nuser_groups = pd.DataFrame(\n    group_memberships.groupby('user_id')['group_id'].apply(list)\n)\nuser_groups.columns = ['group_ids']\ndisplay(user_groups.head())\n\ngroup_users = pd.DataFrame(\n    group_memberships.groupby('group_id')['user_id'].apply(list)\n)\ngroup_users.columns = ['user_ids']\ndisplay(group_users.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1e36e9e5a3441720caa88e5330acb66e3601e64"},"cell_type":"code","source":"# Split matches to email_id -> question_ids and question_id -> email_ids\n\n# HIGH COMPUTE TIME so commented out for now...\n\n# email_questions = matches.groupby('email_id')['question_id'].apply(list)\n# display(email_questions.head())\n\n# question_emails = matches.groupby('question_id')['email_id'].apply(list)\n# display(question_emails.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11138db1ffde3381628a1ce548937c1099a3a636"},"cell_type":"code","source":"# Split school_memberships to school_id -> user_ids and user_id -> school_ids\n\nschool_users = pd.DataFrame(\n    school_memberships.groupby('school_id')['user_id'].apply(list)\n)\nschool_users.columns = ['user_ids']\ndisplay(school_users.head())\n\nuser_schools = pd.DataFrame(\n    school_memberships.groupby('user_id')['school_id'].apply(list)\n)\nuser_schools.columns = ['school_ids']\ndisplay(user_schools.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e31fa3e97798e6e3e0ff5da3783c0ec8557ae8dc"},"cell_type":"code","source":"# Split questions_tags to question_id -> tag_ids and tag_id -> question_ids\n\nquestion_tags = pd.DataFrame(\n    questions_tags.groupby('question_id')['tag_id'].apply(list)\n)\nquestion_tags.columns = ['tag_ids']\ndisplay(question_tags.head())\n\ntag_questions = pd.DataFrame(\n    questions_tags.groupby('tag_id')['question_id'].apply(list)\n)\ntag_questions.columns = ['question_ids']\ndisplay(tag_questions.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52c8804bf146d2f523917ec2329aa41509f5ee4b"},"cell_type":"code","source":"# Split users_tags to user_id -> tag_ids and tag_id -> user_ids\n\nuser_tags = pd.DataFrame(\n    users_tags.groupby('user_id')['tag_id'].apply(list)\n)\nuser_tags.columns = ['tag_ids']\ndisplay(user_tags.head())\n\ntag_users = pd.DataFrame(\n    users_tags.groupby('tag_id')['user_id'].apply(list)\n)\ntag_users.columns = ['user_ids']\ndisplay(tag_users.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e0b6cbc478a3ac1f9f7f99046d7bf17ad0af63c"},"cell_type":"code","source":"# Combine questions + answers + question_tags into a single data frame\nqa = questions.join(answers.set_index('question_id'), how = 'left', lsuffix = '_q', rsuffix = '_a')\nqa = qa.join(question_tags, how='left')\ndisplay(qa.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3443e31a28024543807996186f6e02a79d76cca4"},"cell_type":"code","source":"# Combine stsudents + schools + groups + tags into a single data frame\n\nstudents_full = students.join(user_schools, how='left')\nstudents_full = students_full.join(user_groups, how='left')\nstudents_full = students_full.join(user_tags, how='left')\nstudents_full.columns = ['location', 'date_joined', 'school_ids', 'group_ids', 'tag_ids']\n\ndisplay(students_full.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7a9a57c40b9e0c4fe4a4122a58ba132bd4d2dc1"},"cell_type":"code","source":"# Combine professionals + schools + groups + tags into a single data frame\n\nprofessionals_full = professionals.join(user_schools, how='left')\nprofessionals_full = professionals_full.join(user_groups, how='left')\nprofessionals_full = professionals_full.join(user_tags, how='left')\nprofessionals_full.columns = ['location', 'industry', 'headline', 'date_joined',\n                             'school_ids', 'group_ids', 'tag_ids']\n\ndisplay(professionals_full.head())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0a904781da1a03ca147e1110385975edf0af58b6"},"cell_type":"markdown","source":"# Now, for the interesting part. Let's analyze the tags!\n---\nWe will begin by look qualitatively at what the tags are, patterns that exist, and deciding which groups of tags to keep and throw out. There are over 2 million potential relationships and we only would like to keep the once that give us the most information to save computational load. "},{"metadata":{"trusted":true,"_uuid":"6579a712f971e346a42b64379e844d717f021de2"},"cell_type":"code","source":"# we will begin by looking at the tags and question_tags dataframes\ndisplay(question_tags.head())\n\ntags_list = np.array(tags.index.unique())\ndisplay(len(tags_list))\n# more than 16k tags!... how many are actually used though? \n\n_tags_list = questions_tags['tag_id'].unique()\nprint(len(_tags_list))\n# Only 7091 actually used! Let's use these instead...\n\ntags_list = np.array(_tags_list)\ntags_list = np.sort(_tags_list, kind='mergesort')\nprint(tags_list[0:10], tags_list[-10:-1])\n# Okay perfect, let's move on...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61fa13aba8e33b49ba1a6a682e73d29a49edbd31"},"cell_type":"code","source":"# How many tags are typically applied to questions?\nquestion_tags['tags_count'] = question_tags['tag_ids'].apply(lambda x: len(x))\ndisplay(question_tags.head())\n\nm = np.mean(question_tags['tags_count'])\ns = np.std(question_tags['tags_count'])\nprint(m - s, m, m + s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02da3ea16a72c0bd403423380ae022268cb1bb78"},"cell_type":"code","source":"# We will then only look at questions that have at least 2 tags (necssary, 1 is not enough) and at most 6 tags\n# Let's just see how many don't fit our criteria...\nmask = (question_tags['tags_count'] > 2) & (question_tags['tags_count'] < 6)\nprint(len(question_tags))\nquestion_tags_ok = question_tags.loc[mask]\nprint(len(question_tags_ok))\n\n# So we have reduced our list from 23k to about 10k or just over a 50% reduction.\ndisplay(question_tags_ok.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a1a9870ee4e64def8a6f74ba1a8048fecfd7caf"},"cell_type":"code","source":"# Some helper functions for this section. We will index our tags and use their indices in our voting matrix\ndef get_tag_index(tag):\n    i = np.searchsorted(tags_list, [str(tag)])[0]\n    if i > len(tags_list):\n        return None\n    return i\n\ndef get_tag_indices(tag_list):\n    return [get_tag_index(l) for l in tag_list]\n\n# Testing, everything checks out so far!\nprint(get_tag_index('29'), tags_list[5887])\nprint(get_tag_indices(['29', '12217']), tags_list[5887], tags_list[429])\n\nquestion_tags['tag_indices'] = question_tags['tag_ids'].apply(get_tag_indices)\ndisplay(question_tags.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ae7bb91cf5aa7ad4a3a6f42b77a6cd03a0a3dbe0"},"cell_type":"code","source":"# Now for the fun stuff! Let's construct our voting matrix\ncouples = np.array(question_tags['tag_indices'])\ndisplay(couples[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ba4eef26cc8eb393059990a41b73d99c44a4542"},"cell_type":"code","source":"N = len(tags_list)\nvm = np.zeros((N, N), dtype=int)\n\n# Take the votes\nfor c in couples:\n    for j in c:\n        for i in c:\n            if i != j:\n                vm[i, j] += 1\n                \n                \nprint(vm)\nprint(vm.shape)\nprint(np.sum(vm[0]))\n\n# How many rows / columns add to 0? Symmetric matrix!\nzero_rows = [i for i, row in enumerate(vm) if np.sum(row) == 0]\nprint(len(zero_rows))\n\n# 343 empty rows! This is due to us not counting EVERY group of tags. There are some unused because they were only used once or in large groups\n# In production, we would not do this, but this is just for analysis- even if a tag iss used once we would like to see how it was used\nvm = np.delete(vm, zero_rows, axis = 0)\nvm = np.delete(vm, zero_rows, axis = 1)\n\n# and make sure to update our tags_list...\ntags_list = np.delete(tags_list, zero_rows)\nprint(len(tags_list))\nprint(vm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"510d0368c5269d80e2462a89e45d4cfe68bc76ea"},"cell_type":"code","source":"# Let's see what it looks like to take just the top 5 tags for each category\n# A better clustering example would be best here, but we will use this just for now\n# top_tags = ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}