{"cells":[{"metadata":{"_uuid":"b6269c0e8f417f82daf093dda8fa0da6d2c57d86","_cell_guid":"e81ee64d-e474-4662-9036-ce23df615199"},"cell_type":"markdown","source":"# Introduction\n**This will be your workspace for Kaggle's Machine Learning education track.**\n\nYou will build and continually improve a model to predict housing prices as you work through each tutorial.  Fork this notebook and write your code in it.\n\nThe data from the tutorial, the Melbourne data, is not available in this workspace.  You will need to translate the concepts to work with the data in this notebook, the Iowa data.\n\nCome to the [Learn Discussion](https://www.kaggle.com/learn-forum) forum for any questions or comments. \n\n# Write Your Code Below\n\n","outputs":[],"execution_count":null},{"metadata":{"_uuid":"1c728098629e1301643443b1341556a15c089b2b","_cell_guid":"86b26423-563a-4fa1-a595-89e25ff93089","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nmain_file_path = '../input/train.csv'\ndata = pd.read_csv(main_file_path)\n\n#describe the data of the file train.csv from house prices\nprint(data.describe())\n\n#select any one column from data and describe it\nhouse_style_data = data.HouseStyle\nhouse_style_data.describe()\n\n#show top values of house_style\nprint(house_style_data.head())\n\n#selecting multiple columns\ncolumns_of_interest = ['RoofStyle','Street']\ntwo_columns_of_data=data[columns_of_interest]\ntwo_columns_of_data.describe()\n\n#predict the sales prices of houses\ny=data.SalePrice\nhouse_predictors=['LotArea','YearBuilt','1stFlrSF','2ndFlrSF','FullBath','BedroomAbvGr','TotRmsAbvGrd']\nX=data[house_predictors]\nfrom sklearn.tree import DecisionTreeRegressor\n\n#define model\ndata_model= DecisionTreeRegressor()\ndata_model.fit(X,y)\n\n#make prediction for 5 houses from training data\nprint(\"Making predictions for the first 5 houses\")\nprint(X.head())\nprint(\"The Predictions are:\")\nprint(data_model.predict(X.head()))\n\nfrom sklearn.metrics import mean_absolute_error\n\n#calculating mean absolute error\npredicted_home_prices = data_model.predict(X)\nmean_absolute_error(y,predicted_home_prices)\n\nfrom sklearn.model_selection import train_test_split\ntrain_X,val_X,train_y,val_y = train_test_split(X,y,random_state=0)\nh_model = DecisionTreeRegressor()\nh_model.fit(train_X,train_y)\n\nval_predictions = h_model.predict(val_X)\nprint(mean_absolute_error(val_y,val_predictions))\n\n#overfitting and underfitting of data\ndef get_mae(max_leaf_nodes,predictors_train,predictors_val,targ_train,targ_val):\n    h1_model=DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes,random_state=0)\n    h1_model.fit(predictors_train,targ_train)\n    preds_val = h1_model.predict(predictors_val)\n    mae=mean_absolute_error(targ_val,preds_val)\n    return mae\n\nfor max_leaf_nodes in [5,50,500,5000]:\n    my_mae  = get_mae(max_leaf_nodes,train_X,val_X,train_y,val_y)\n    print(\"Max leaf nodes:%d \\t\\t Mean absolute Error:%d\"%(max_leaf_nodes,my_mae))\n\n#calculation of mean_absolute_error using ForestRegressor    \nfrom sklearn.ensemble import RandomForestRegressor\nforest_model = RandomForestRegressor()\nforest_model.fit(train_X,train_y)\nh_preds= forest_model.predict(val_X)\nprint(mean_absolute_error(val_y,h_preds))\n\n#predict on the test data from ForestRegressor\ntest = pd.read_csv('../input/test.csv')\ntest_X = test[house_predictors]\npredict_prices= forest_model.predict(test_X)\nprint(predict_prices)\n\n#create file for submission\n#submission = pd.DataFrame({'Id':test.Id,'SalePrice': predict_prices})\n#submission.to_csv('submission.csv',index=False)\n\n#calculate missing/null values\nprint(data.isnull().sum())\n\n#remove one column\nd_target = data.SalePrice\nd_predictors = data.drop(['SalePrice'],axis=1)\n\n#remove non-numeric values\nd_numeric_predictors = d_predictors.select_dtypes(exclude=['object'])\nX_train,X_test,y_train,y_test = train_test_split(d_numeric_predictors,d_target,train_size=0.7,test_size=0.3,random_state=0)\n#calculates mean error\ndef score_dataset(X_train,X_test,y_train,y_test):\n    model1 = RandomForestRegressor()\n    model1.fit(X_train,y_train)\n    preds = model1.predict(X_test)\n    return mean_absolute_error(y_test,preds)\n#calculate Mean absolute error from missing values\ncols_with_missing = [col for col in X_train.columns \n                                 if X_train[col].isnull().any()]\nreduced_X_train = X_train.drop(cols_with_missing, axis=1)\nreduced_X_test  = X_test.drop(cols_with_missing, axis=1)\nprint(\"Mean Absolute Error from dropping columns with Missing Values:\")\nprint(score_dataset(reduced_X_train, reduced_X_test, y_train,y_test ))\n\n\nfrom sklearn.preprocessing import Imputer\nmy_imputer = Imputer()\nimputed_X_train = my_imputer.fit_transform(X_train)\nimputed_X_test = my_imputer.fit_transform(X_test)\nprint(\"Mean absolute error from Imputation:\")\nprint(score_dataset(imputed_X_train,imputed_X_test,y_train,y_test))\n      \nimputed_X_train_plus = X_train.copy()\nimputed_X_test_plus = X_test.copy()\n\ncols_with_missing = (col for col in X_train.columns \n                                 if X_train[col].isnull().any())\nfor col in cols_with_missing:\n    imputed_X_train_plus[col + '_was_missing'] = imputed_X_train_plus[col].isnull()\n    imputed_X_test_plus[col + '_was_missing'] = imputed_X_test_plus[col].isnull()\n\n# Imputation to handle missing data\nmy_imputer = Imputer()\nimputed_X_train_plus = my_imputer.fit_transform(imputed_X_train_plus)\nimputed_X_test_plus = my_imputer.transform(imputed_X_test_plus)\n\nprint(\"Mean Absolute Error from Imputation while Track What Was Imputed:\")\nprint(score_dataset(imputed_X_train_plus, imputed_X_test_plus, y_train, y_test))\n\n#prediction of categorical data\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\ntrain_data.dropna(axis=0,subset=['SalePrice'], inplace=True)\ntarget = train_data.SalePrice\ncols_with_missing = [cols for cols in train_data.columns if train_data[cols].isnull().any()]\ncandidate_train_predictors = train_data.drop(['Id','SalePrice'] + cols_with_missing,axis=1)\ncandidate_test_predictors = test_data.drop(['Id'] + cols_with_missing,axis=1)\nlow_cardinality_cols = [cname for cname in candidate_train_predictors.columns if \n                                candidate_train_predictors[cname].nunique() < 10 and\n                                candidate_train_predictors[cname].dtype == \"object\"]\nnumeric_cols = [cname for cname in candidate_train_predictors.columns if \n                                candidate_train_predictors[cname].dtype in ['int64', 'float64']]\nmy_cols = low_cardinality_cols + numeric_cols\ntrain_predictors = candidate_train_predictors[my_cols]\ntest_predictors = candidate_test_predictors[my_cols]\ntrain_predictors.dtypes.sample(10)\none_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef get_mae(X, y):\n    # multiple by -1 to make positive MAE score instead of neg value returned as sklearn convention\n    return -1 * cross_val_score(RandomForestRegressor(50), \n                                X, y, \n                                scoring = 'neg_mean_absolute_error').mean()\n\npredictors_without_categoricals = train_predictors.select_dtypes(exclude=['object'])\n\nmae_without_categoricals = get_mae(predictors_without_categoricals, target)\n\nmae_one_hot_encoded = get_mae(one_hot_encoded_training_predictors, target)\n\nprint('Mean Absolute Error when Dropping Categoricals: ' + str(int(mae_without_categoricals)))\nprint('Mean Abslute Error with One-Hot Encoding: ' + str(int(mae_one_hot_encoded)))\n\none_hot_encoded_training_predictors = pd.get_dummies(train_predictors)\none_hot_encoded_test_predictors = pd.get_dummies(test_predictors)\nfinal_train, final_test = one_hot_encoded_training_predictors.align(one_hot_encoded_test_predictors,\n                                                                    join='left', \n                                                                    axis=1)\n\n","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}