{"cells":[{"metadata":{"_cell_guid":"9d2dbdb3-6c74-4f96-9865-2951dfd653ce","_uuid":"bb41ad86b25fecf332927b0c8f55dd710101e33f"},"cell_type":"markdown","source":"# Going beyond Jeremy's [LSTM baseline](https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout)\n"},{"metadata":{"_cell_guid":"2f9b7a76-8625-443d-811f-8f49781aef81","_uuid":"598f965bc881cfe6605d92903b758778d400fa8b","trusted":true},"cell_type":"code","source":"import sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNLSTM, CuDNNGRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5288c4fbe7f37087b582ca0d0adda6f9009e957"},"cell_type":"code","source":"from keras.callbacks import EarlyStopping","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17fc75775ed50d932436c95224437b755ddeb326"},"cell_type":"code","source":"np.random.seed(100)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"66a6b5fd-93f0-4f95-ad62-3253815059ba","_uuid":"729b0f0c2a02c678631b8c072d62ff46146a82ef","trusted":true},"cell_type":"code","source":"path = '../input/'\ncomp = 'jigsaw-toxic-comment-classification-challenge/'\nEMBEDDING_FILE=f'{path}glovetwitter27b50d/glove.twitter.27B.50d.txt' #using vectors trained on twitter data\nTRAIN_DATA_FILE=f'{path}{comp}train.csv'\nTEST_DATA_FILE=f'{path}{comp}test.csv'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2807a0a5-2220-4af6-92d6-4a7100307de2","_uuid":"d365d5f8d9292bb9bf57d21d6186f8b619cbe8c3","trusted":true},"cell_type":"code","source":"embed_size = 50 # how big is each word vector\nmax_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\nmaxlen = 100 # max number of words in a comment to use","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b3a8d783-95c2-4819-9897-1320e3295183","_uuid":"4dd8a02e7ef983f10ec9315721c6dda2958024af"},"cell_type":"markdown","source":"Read in our data and replace missing values:"},{"metadata":{"_cell_guid":"ac2e165b-1f6e-4e69-8acf-5ad7674fafc3","_uuid":"8ab6dad952c65e9afcf16e43c4043179ef288780","trusted":true},"cell_type":"code","source":"train = pd.read_csv(TRAIN_DATA_FILE)\ntest = pd.read_csv(TEST_DATA_FILE)\n\n# train = train.sample(frac=1)[:50000]\n# test = test.sample(frac=1)[:50000]\n\nlist_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cd827ae9918bd4d427d09b641945e84fd4c5413"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"54a7a34e-6549-45f7-ada2-2173ff2ce5ea","_uuid":"e8810c303980f41dbe0543e1c15d35acbdd8428f"},"cell_type":"markdown","source":"Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."},{"metadata":{"_cell_guid":"79afc0e9-b5f0-42a2-9257-a72458e91dbb","_uuid":"c292c2830522bfe59d281ecac19f3a9415c07155","trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\nX_te = pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f8c4f6a3-3a19-40b1-ad31-6df2690bec8a","_uuid":"e1cb77629e35c2b5b28288b4d6048a86dda04d78"},"cell_type":"markdown","source":"Read the glove word vectors (space delimited strings) into a dictionary from word->vector."},{"metadata":{"_cell_guid":"7d19392b-7750-4a1b-ac30-ed75b8a62d52","_uuid":"e9e3b4fa7c4658e0f22dd48cb1a289d9deb745fc","trusted":true},"cell_type":"code","source":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e05dd26759e65a4f54db57fded0078732ff10491"},"cell_type":"code","source":"s = set(arr.shape for arr in embeddings_index.values())\nprint(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9543ea223bbd8895ed2b3d3f3b5754551655cd46"},"cell_type":"code","source":"for i,el in enumerate(embeddings_index.values()):\n    if el.shape[0]==49:\n        print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"509308190bd3b21d6884e388d958138025533600"},"cell_type":"code","source":"list(embeddings_index.keys())[38522]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1527686299465ade96b44b3b2a05c0a978e1bd0"},"cell_type":"code","source":"del(embeddings_index['0.45973'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ef98e3d96e5ac6096e69e488c8a074c38a607d5"},"cell_type":"code","source":"set(arr.shape for arr in embeddings_index.values())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7370416a-094a-4dc7-84fa-bdbf469f6579","_uuid":"20cea54904ac1eece20874e9346905a59a604985"},"cell_type":"markdown","source":"Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."},{"metadata":{"_cell_guid":"4d29d827-377d-4d2f-8582-4a92f9569719","_uuid":"96fc33012e7f07a2169a150c61574858d49a561b","trusted":true},"cell_type":"code","source":"all_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nemb_mean,emb_std","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"62acac54-0495-4a26-ab63-2520d05b3e19","_uuid":"574c91e270add444a7bc8175440274bdd83b7173","trusted":true},"cell_type":"code","source":"word_index = tokenizer.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\nprint(embedding_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f1aeec65-356e-4430-b99d-bb516ec90b09","_uuid":"237345510bd2e664b5c6983a698d80bac2732bc4"},"cell_type":"markdown","source":"Using CuDNNLSTM instead of LSTM."},{"metadata":{"trusted":true,"_uuid":"301904e80e43456457dcdfedbb5f2b82e7f0b365"},"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto', baseline=None, restore_best_weights=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0d4cb718-7f9a-4eab-acda-8f55b4712439","_uuid":"dc51af0bd046e1eccc29111a8e2d77bdf7c60d28","trusted":true},"cell_type":"code","source":"inp = Input(shape=(maxlen,))\nx = Embedding(nb_words, embed_size, weights=[embedding_matrix],trainable=False)(inp)\nx = Bidirectional(CuDNNLSTM(50, return_sequences=True))(x)\nx = Dropout(0.3)(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(50, activation=\"relu\")(x)\nx = Dropout(0.3)(x)\nx = Dense(6, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0498e254dc79a414c334a7425d65717a6a69b139"},"cell_type":"code","source":"# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4a624b55-3720-42bc-ad5a-7cefc76d83f6","_uuid":"e2a0e9ce12e1ff5ea102665e79de23df5caf5802"},"cell_type":"markdown","source":"Now we're ready to fit out model! Use `validation_split` when not submitting."},{"metadata":{"_cell_guid":"333626f1-a838-4fea-af99-0c78f1ef5f5c","scrolled":false,"_uuid":"c1558c6b2802fc632edc4510c074555a590efbd8","trusted":true},"cell_type":"code","source":"model.fit(X_t, y, batch_size=32, epochs=6, validation_split=0.1, callbacks=[early_stopping]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98a8c481070c0b49f37174f5ab547e878d1f2345"},"cell_type":"markdown","source":"As pointed out by Jeremy, model seems to overfit after 2 epochs. `val_loss` goes lower, but `val_acc` increases."},{"metadata":{"trusted":true,"_uuid":"065f56fbbb8c8e9bb15172d60a864c27cb3b9746"},"cell_type":"code","source":"def model_with_gru():\n    \n    inp = Input(shape=(maxlen,))\n    x = Embedding(nb_words, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n    x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n    x = Dropout(0.3)(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.3)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    \n    model = Model(inputs=inp, outputs=x)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d0b8d1324add246c6fd92e55926145a33f5a787"},"cell_type":"code","source":"model_gru = model_with_gru()\nmodel_gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7437bf56fd755a1932c7818159af9d94a5e2c9f"},"cell_type":"code","source":"model_gru.fit(X_t, y, batch_size=32, epochs=6, validation_split=0.1, callbacks=[early_stopping]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5df917bf00116651a79497558072cb57fc6c4562"},"cell_type":"markdown","source":"Not much improvement on using GRU. "},{"metadata":{"_uuid":"5a35da03ae1dd84bdaab4db6a8a80216841f6194"},"cell_type":"markdown","source":"Trying a model with two LSTM layers."},{"metadata":{"trusted":true,"_uuid":"a18c79c4d883d6a3781cdcc249e1af5d89332ac5"},"cell_type":"code","source":"def model_with_2_lstms():\n    \n    inp = Input(shape=(maxlen,))\n    x = Embedding(nb_words, embed_size, weights=[embedding_matrix],trainable=False)(inp)\n    x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n    x = Dropout(0.3)(x)\n    x = Bidirectional(CuDNNGRU(50, return_sequences=True))(x)\n    x = Dropout(0.3)(x)\n    x = GlobalMaxPool1D()(x)\n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.3)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad29c6d72de61cb1af5bdd939255981d7a129cb1"},"cell_type":"code","source":"model_2_lstms = model_with_2_lstms()\nmodel_2_lstms.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"516c28219794526410bfe8cfa092267a469bc4dc"},"cell_type":"code","source":"model_2_lstms.fit(X_t, y, batch_size=32, epochs=6, validation_split=0.1, callbacks=[early_stopping]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc282ba61d22bd8fc0d9e10d99bc3cf96fd96077"},"cell_type":"code","source":"comments_test = [\"hey you suck big time buddy\", \"that's a lovely way to look at it\"]\nsequences_test = tokenizer.texts_to_sequences(comments_test)\ndata_test = pad_sequences(sequences_test, maxlen=maxlen)\npreds = model_2_lstms.predict(data_test)\n\ndf_pred = pd.DataFrame(preds>0.5, columns=list_classes)\nprint(df_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b9b7cb0142d309bbb03851b879ecb5a0dd80df0"},"cell_type":"code","source":"y_test = model_2_lstms.predict([X_te], batch_size=1024, verbose=1)\nsample_submission = pd.read_csv(f'{path}{comp}sample_submission.csv')\nsample_submission[list_classes] = y_test\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}