{"nbformat": 4, "nbformat_minor": 1, "cells": [{"cell_type": "markdown", "metadata": {"_uuid": "ab034cbc2149bacffa3bd425178cb94d815fe406", "_cell_guid": "390315bc-fecf-489c-bc29-407fbe668c0d"}, "source": ["1. (1)  **READ THE TRAIN SHIT FILE**\n", "1. (2)  **FIGURE OUT WHAT'S DIFFERENT**\n", "1. (3)  **LOOK AT NOT SAME SHIT**\n", "1. (4)  **FIGURE OUT WHICH SHIT IS THE SAME**\n", "1. (5)  **BUILD SOME DICKS**\n", "1. (6)  **FUCKING MISSING SHIT**\n", "1. (7)  **LOOK AT THE FUCKING MISSING SHIT**\n", "1. (8)  **BUILD SOME MORE DICKS**\n", "1. (9)  **FIGURE OUT WHERE NOT SAME SHIT HAS DIFFERENT SHIT**\n", "1. (10)  **LOOK AT THAT SHIT**\n", "1. (11)  **LOOK AT THAT SHIT AGAIN BUT DIFFERENT**\n", "1. (12)  **FIND WHERE THE AFTER PARTY HAS CAPITAL LETTERS AND FIGURE OUT WTF**\n", "1. (13)  **THROW AN ERROR**"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "bd59c14c0d386e130c290a754e7174ea058f4b56", "_cell_guid": "371661d6-7455-40a6-b68e-d51dc4ce2b78"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output.\n", "\n", "import re, string, collections\n", "from fuzzywuzzy import fuzz\n", "from tqdm import tqdm\n", "from IPython.display import display\n", "\n", "# Read en_train.csv  file.\n", "train_df = pd.read_csv(filepath_or_buffer=\"../input/en_train.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n", "#train_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "bd4d2c11c346252c36b1e3e88552548f6ac2ab7c", "_cell_guid": "2458b9fc-ae89-4a54-920b-a4c16d0a772a"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "6ab3def19b50595a0a09e0d115429324d9e2d6fa", "_cell_guid": "e7744594-82be-403f-b983-a9be6bfa4c6d"}, "source": ["**test shit**"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "35e7c1223a6fa112e9ccc236e80a72255eadf83c", "_cell_guid": "dac5c660-aa3a-4da1-bdc7-b60ef4a49ff6"}, "source": ["test_df = pd.read_csv(filepath_or_buffer=\"../input/en_test.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n", "test_df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b43aecc12d891c13033469ed4b7d8322f440911e", "_cell_guid": "8d2cc40e-3ab0-477e-8bb7-49a3f966a485"}, "source": ["submitshit = [str(x) + '_' + str(y) for x,y in zip(tqdm(np.array(test_df['sentence_id'])), np.array(test_df['token_id']))]"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2fad0b7c38ba459209fb2f386ab029c970298bd0", "_cell_guid": "f06bf8a9-710e-48bf-8c93-a74e48ff259b"}, "source": ["print(submitshit[:10])\n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "dea9642a90d465ba5e377549f469c2b22afeacc0", "_cell_guid": "058ada17-5f8b-43f1-89e7-5afaf78dc22f"}, "source": ["test_before = np.array(test_df['before'])\n", "test_before_DICK = dict(zip(np.array(test_df.index), test_before))\n", "\n", "display(test_before[:10])"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b0d15d67c10fa273864a17f05b15f92a7b76fb5e", "_cell_guid": "83699e73-05f0-4c7a-8d9e-0e5d86c65517"}, "source": ["arr_test_before_str_only = [x for x in test_before if type(x) == type(str())]\n", "thing = [x.isdigit() for x in tqdm(arr_test_before_str_only)]\n", "print(sum(thing))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "bb93fb66921312912ec68cd3deb804456bfe1d9a", "_cell_guid": "2e0f3165-0085-43ad-af10-335436066aae"}, "source": []}, {"cell_type": "markdown", "metadata": {"_uuid": "ea2a785eb9684ffbde3e8f3e6d304fa17aee330d", "_cell_guid": "761690ab-883c-402e-89c0-a0150a3a3df9"}, "source": ["(2)  **FIGURE OUT WHAT'S DIFFERENT AND WHICH SHIT SAMA SAMA**"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1e6031be57e0ac7cfaf3262a1a52f92f59d3c6aa", "_cell_guid": "db244dd9-f295-422a-853f-75c248991213"}, "source": ["#np.array(train_df['before'])\n", "arr_after = np.array(train_df['after'])\n", "\n", "idx_not_same = list()\n", "for each_after, each_beforeiter in zip(tqdm(arr_after), train_df['before'].iteritems()):\n", "    if each_after != each_beforeiter[1]:\n", "        idx_not_same.append(each_beforeiter[0])\n", "print(str(len(idx_not_same)) + ' NOT SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_not_same) / len(train_df)) + ' %)')\n", "\n", "idx_are_same = set(train_df.index) - set(idx_not_same)\n", "print(str(len(idx_are_same)) + ' ARE SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_are_same) / len(train_df)) + ' %)')"]}, {"cell_type": "markdown", "metadata": {"_uuid": "3a3e05487117e9b474fa6b382791ee98300b9a57", "_cell_guid": "52538678-2dc9-4317-8422-177d8b8a8fcc"}, "source": ["> (5)  **BUILD AND STROKE ALL THE  DICKS**"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f95a18cc2b9cb9c093397c234e9b8013d2323971", "_cell_guid": "4085412d-8ad7-4569-ab7a-9a83553ff9f0"}, "source": ["# find rows where before is the same but after is different\n", "# find rows where after is the same but before is different\n", "# and class is different?\n", "#build a before dick\n", "train_df_idx = np.array(train_df.index)\n", "arr_before = np.array(train_df['before'])\n", "before_DICK = dict()\n", "for each_idx, each_before in zip(tqdm(train_df_idx), arr_before):\n", "    if each_before in before_DICK:\n", "        before_DICK[each_before].append(each_idx)\n", "    else:\n", "        before_DICK[each_before] = [each_idx]\n", "            \n", "# build a after dick\n", "after_DICK = dict()\n", "for each_idx, each_after in zip(tqdm(train_df_idx), arr_after):\n", "    if each_after in after_DICK:\n", "        after_DICK[each_after].append(each_idx)\n", "    else:\n", "        after_DICK[each_after] = [each_idx]\n", "\n", "# build a classy dick\n", "arr_class = np.array(train_df['class'])\n", "classy_DICK = dict()\n", "for each_idx, each_class in zip(tqdm(train_df_idx), arr_class):\n", "    if each_class in classy_DICK:\n", "        classy_DICK[each_class].append(each_idx)\n", "    else:\n", "        classy_DICK[each_class] = [each_idx] \n", "\n", "# build index to after dick\n", "idx_after_DICK = dict(zip(np.array(train_df.index), np.array(train_df['after'])))        "]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "517bfe5a1e8dc1a92f5ad2ed95601c12001a17a8", "_cell_guid": "ea69908a-f98e-4ae7-85a0-519d825ef716"}, "source": ["idx_classy_DICK = dict(zip(np.array(train_df.index), np.array(train_df['class'])))        "]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "4fc44be87b66222c6c4e0096462aca06c1e82060", "_cell_guid": "1fed98ac-a10d-48aa-bcc6-f78164282da7"}, "source": ["#cardinal_df = train_df.loc[classy_DICK['CARDINAL']]\n", "#digit_df = train_df.loc[classy_DICK['DIGIT']]\n", "#verbatim_df = train_df.loc[classy_DICK['VERBATIM']]\n", "#display(cardinal_df.head())\n", "#display(digit_df.head())\n", "#display(verbatim_df.head())\n", "\n", "cdv_df = train_df.loc[classy_DICK['CARDINAL'] + classy_DICK['DIGIT'] + classy_DICK['VERBATIM']]\n", "display(cdv_df.head())\n", "arr_cdv_before = np.array(cdv_df['before'])\n", "arr_cdv_after = np.array(cdv_df['after'])\n", "\n", "#cdv_singlechar = [(x,y) for x,y in zip(tqdm(np.array(cdv_df.index)), arr_cdv_before) if len(y) == 1]\n", "#print(cdv_singlechar[:10])\n", "\n", "cdv_before_after_DICK = dict()\n", "cdv_multiple_afters = list()\n", "for each_idx, each_before, each_after in zip(tqdm(np.array(cdv_df.index)), arr_cdv_before, arr_cdv_after):\n", "    if len(each_before) != 1:\n", "        pass\n", "    elif each_before in cdv_before_after_DICK:\n", "        if cdv_before_after_DICK[each_before] != each_after:\n", "            cdv_multiple_afters.append((each_idx, each_before, each_after))\n", "    else:\n", "        cdv_before_after_DICK[each_before] = each_after\n", "print(len(cdv_multiple_afters))\n", "print(cdv_multiple_afters[:10])"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1c0b631e5f5c70895b14fd89ae6c005e1435463b", "_cell_guid": "f7b66c88-b5b7-47ef-8b43-0b095cf6fcc9"}, "source": ["print(set([(y,z) for x,y,z in cdv_multiple_afters]))\n", "print(len(cdv_before_after_DICK))"]}, {"cell_type": "markdown", "metadata": {"_uuid": "9f432ba36faf37c084e9ebe04268a4692126ec66", "_cell_guid": "16d78bda-6def-4cda-9006-77d2a800d8bc"}, "source": ["(6)  **FUCKING MISSING SHIT**"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6b0e4422882e4225f0aff6a24c5943395f154c6e", "_cell_guid": "0c7be710-bbfd-4fa0-9229-d1f7a9f4ebcf"}, "source": ["print('    '.join([str(x) for x in [len(before_DICK), len(after_DICK), len(classy_DICK)]]))\n", "\n", "# fucking missing shit\n", "after_dick_nan_idxs = after_DICK.pop(np.nan, None)\n", "before_dick_nan_idxs = before_DICK.pop(np.nan, None)\n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8bf009fc54fbf973817b6861f1fbe3ae1d665a8a", "_cell_guid": "f875565a-9bda-4d02-843c-2920b42a40f5"}, "source": ["#test_before\n", "# are train_before's unique? what?\n", "len(train_df['before']) == len(set(train_df['before']))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "2f8ad0aebaf02fc3595a4ecf9f267784eaaf8fcd", "_cell_guid": "6eed3065-638c-481b-8a72-5632d6c868f1"}, "source": ["# fuckkkk duuuuude"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "3317365ce3ac5421c4cbf77c2df6be74fd7c1d85", "_cell_guid": "2f0e7481-28b7-48f0-99ec-1bc19a3a7aed"}, "source": ["collections.Counter(train_df['before']).most_common(10)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "21ab3886573afd14dbe020e2953a7d597ca8defe", "_cell_guid": "45716203-e767-4362-beb7-1a7dfaa76567"}, "source": ["#build a short DICK haha\n", "# where only got uniques\n", "#train_df_ARE_same = train_df.loc[idx_are_same]\n", "#display(train_df_ARE_same[:10])\n", "beforeDICK_length = list()\n", "with tqdm(total=len(before_DICK)) as pbar:\n", "    for key, value in before_DICK.items():\n", "        beforeDICK_length.append(len(before_DICK[key]))\n", "        pbar.update()\n", "print(collections.Counter(beforeDICK_length).most_common(10))        \n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "ee252507cc7785f0e4563dbe75a433b183ceb23e", "_cell_guid": "a0c9914f-acca-437f-bb3e-7a7412753bc3"}, "source": ["# build a dick where it's longer before and shorter after... yeah cuz it busted a nut\n", "#train_df_ARE_same_idx = np.array(train_df_ARE_same.index)\n", "#arr_ARE_same_before = np.array(train_df_ARE_same['before'])\n", "before_after_DICK = dict()\n", "for each_idx, each_before in zip(tqdm(train_df_idx), arr_before):\n", "    if each_before in before_after_DICK:\n", "        before_after_DICK[each_before].append(idx_after_DICK[each_idx])\n", "    else:\n", "        before_after_DICK[each_before] = [idx_after_DICK[each_idx]]"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2c8030b228554c85503640c1b34abf247c8c3420", "_cell_guid": "6517675d-d421-4280-bcff-dd3069d29bd1"}, "source": ["\n", "before_with_same_after = list()\n", "before_with_different_after = list()\n", "before_with_mostcommon_notsame_different_after = list()\n", "with tqdm(total=len(before_after_DICK)) as pbar:\n", "    for key, value in before_after_DICK.items():\n", "        if len(set(value)) == 1:\n", "            before_with_same_after.append((key, value[0], len(value)))\n", "        else:\n", "            cafters, ccounts  = zip(*collections.Counter(value).most_common(3))\n", "            before_with_different_after.append((key, cafters, ccounts))\n", "            mostcommon_notsame = key\n", "            for each_cafters in cafters:\n", "                if each_cafters == key:\n", "                    pass\n", "                else:\n", "                    mostcommon_notsame = each_cafters\n", "                    break\n", "            before_with_mostcommon_notsame_different_after.append((key, mostcommon_notsame))\n", "        pbar.update()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "8dc8cab8539f6bcf976bd23fd4fa5fe2dea5d81b", "_cell_guid": "2579337c-5a70-4dc3-ade9-6dbe1d132ded"}, "source": ["pd.DataFrame(before_with_different_after)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b0be12d19759c33cea11af88a37f6edbadefd5ca", "_cell_guid": "1a10d01e-ee0f-4bbc-9d94-cbd991cddea2"}, "source": ["pd.DataFrame(before_with_same_after, columns=['before', 'after', 'occurences'])"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "743e8073028efc2930d6aab9b03be9a5a0747fb5", "_cell_guid": "f8bc6e70-9e86-4663-8505-98d3e4ea8933"}, "source": ["pd.DataFrame(before_with_mostcommon_notsame_different_after)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "scrolled": true, "_uuid": "508019c7d4ffbf85425462fbf1eaa5e7c08e3784", "_cell_guid": "3bbe8314-5312-4e37-b2d0-79fdcfa56ca5"}, "source": ["# find rows where before is the same but after is different\n", "# find rows where after is the same but before is different\n", "# and class is different?\n", "#before_with_different_after = list()\n", "#most_common_after_of_before = list()\n", "#with tqdm(total=len(before_DICK)) as pbar:\n", "#    for key, value in before_DICK.items():\n", "#        #unique_afters_of_before = train_df.loc[value, 'after'].unique() #slow as shit\n", "#        get_that_shit = [idx_after_DICK.get(x) for x in value]\n", "#        unique_afters_of_before = set(get_that_shit)\n", "#        pbar.update()\n", "#        if len(unique_afters_of_before) != 1:\n", "#            cafters, ccounts = zip(*collections.Counter(get_that_shit).most_common())\n", "#            most_common_after_of_before.append((key, cafters[0])) #before, after\n", "#            before_with_different_after.append((key, value, unique_afters_of_before))\n", "#\n", "#print(len(before_with_different_after))\n", "#print(len(most_common_after_of_before))\n", "#print(len(most_common_after_of_before))\n", "#most_common_after_of_before[:10]\n"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0615f261555803a8e5d495bcabc6f8077375b821", "_cell_guid": "7c19f705-f1e8-4cd0-a472-bcec7cf6843f"}, "source": ["#intersection? \n", "\n", "testtrain_intersection = set(test_df['before']).intersection(set(train_df['before']))\n", "print(str(len(testtrain_intersection)) + ' or ' + str(100 * len(testtrain_intersection) / len(test_df['before'])) + \" %\")\n", "print(list(testtrain_intersection)[:10])"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2613fd97358d6269f556812c5827d240741b4931", "_cell_guid": "ac4e6c70-7875-47c2-9bbc-ef72bed85039"}, "source": ["# 8 nans?\n", "testypes = [type(x) for x in test_before]\n", "test_before_nonan = [x for x in list(test_before) if type(x) == type(str())]\n", "test_before_nanbool = [type(x) == type(str()) for x in test_before]\n", "\n", "submitshit_nonan = np.array(submitshit)[np.where(test_before_nanbool)]\n", "submitshit_isnan = np.array(submitshit)[np.where(np.logical_not(test_before_nanbool))]\n", "print(collections.Counter(testypes).most_common())\n", "print(len(submitshit_nonan))\n", "print(len(submitshit_isnan))\n", "#howmany = np.sum(np.isnan(test_before))\n", "#print(howmany)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "6634f719b19bacca3c32443ef969b9ad794323a2", "_cell_guid": "7e35a1b8-75ed-45db-afc0-28e5f2151f8e"}, "source": ["np.logical_not(test_before_nanbool[:10])"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "aaae89df9f2dd8f7e0548faf8f1994a467ff2d18", "_cell_guid": "b15a89b2-c61a-4531-813f-972412f85826"}, "source": ["# wow lots of single char entires?\n", "unicodepoint = [ord(x) if len(x) == 1 else [ord(y) for y in x] for x in test_before_nonan]\n", "\n", "types_unicodepoint = [type(x) for x in tqdm(unicodepoint)]\n", "print(collections.Counter(types_unicodepoint).most_common())"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "d83b11dc5393b46bce12f437dff1f10c8e190bc5", "_cell_guid": "6f63f50e-9a4a-42cc-8681-1d32097be3ee"}, "source": ["xxx, yyy, _ = zip(*before_with_same_after)\n", "big_train_DICK = dict(zip(xxx, yyy))\n", "small_train_DICK = dict(before_with_mostcommon_notsame_different_after)\n", "print(len(big_train_DICK))\n", "print(len(small_train_DICK))"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "1f18de781149ae51e52914a2ead281416a2e27a3", "_cell_guid": "182405b4-6a5b-4b3f-a827-9db414773335"}, "source": ["submit_1stcol = list()\n", "submit_2ndcol = list()\n", "for each_submit in submitshit_isnan:\n", "    submit_1stcol.append(each_submit)\n", "    submit_2ndcol.append('n a')\n", "\n", "notfoundcount = 0    \n", "notfoundcount2 = 0\n", "for each_submit, each_testbefore in zip(tqdm(submitshit_nonan), test_before_nonan):\n", "    submit_1stcol.append(each_submit)\n", "    spititback = each_testbefore\n", "    nopunct = each_testbefore.translate({ord(c): None for c in string.punctuation})\n", "    if each_testbefore.isupper():\n", "        submit_2ndcol.append(' '.join(each_testbefore))\n", "    elif (each_testbefore.isalpha()) and not (each_testbefore.isalnum()):\n", "        submit_2ndcol.append(spititback)\n", "#    elif (nopunct.isnumeric()) | (nopunct.isalnum()):\n", "#        tryit = str()\n", "#        for each_char in nopunct:\n", "#            cdv_val = cdv_before_after_DICK.get(each_char)\n", "#            if cdv_val is None:\n", "#                tryit = spititback\n", "#                notfoundcount2 = notfoundcount2 + 1\n", "#                break\n", "#            else:\n", "#                tryit = tryit + ' ' + cdv_val\n", "#        submit_2ndcol.append(tryit.strip())\n", "    else:\n", "        DICK_val = small_train_DICK.get(each_testbefore)\n", "        if DICK_val is None:\n", "            DICK_val = big_train_DICK.get(each_testbefore)\n", "            #if DICK_val is None:\n", "                #DICK_val = nopunct\n", "            if DICK_val is None:\n", "                tryit = str()\n", "                for each_char in nopunct:\n", "                    cdv_val = cdv_before_after_DICK.get(each_char)\n", "                    if cdv_val is None:\n", "                        tryit = None\n", "                        notfoundcount2 = notfoundcount2 + 1\n", "                        break\n", "                    else:\n", "                        tryit = tryit + ' ' + cdv_val\n", "                if tryit is None:\n", "                    DICK_val = nopunct\n", "                else:\n", "                    DIVK_val = tryit.strip()\n", "                    notfoundcount = notfoundcount + 1\n", "        submit_2ndcol.append(DICK_val)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["submit_2ndcol[:15]"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "272ebf5c5b1624bf84f126cd68e8a6768bbbd5a7", "_cell_guid": "d8a96f91-9a07-405e-be69-e9388b0248b9"}, "source": ["Submitnans = submit_2ndcol[:8]\n", "Submitnonnan = submit_2ndcol[8:]\n", "submit_2ndcol_quotes = Submitnans + ['\"' + x + '\"' if x is not None else x for x in Submitnonnan]"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "babcac372f2b05a278156f378dfac8ebfaab3303", "_cell_guid": "558ed446-359c-46b9-8647-4cb88b358198"}, "source": ["print(notfoundcount)\n", "print(notfoundcount2)\n", "#forsubmission = pd.DataFrame(list(zip(submit_1stcol, submit_2ndcol)), columns=['id', 'after'])\n", "forsubmission = pd.DataFrame(list(zip(submit_1stcol, submit_2ndcol_quotes)), columns=['id', 'after'])\n", "display(forsubmission)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b9728aed8ee4e10639a62bf93f700111563c805c", "_cell_guid": "8a184b17-bcb5-4afc-9ee2-41a1f8fcbbe6"}, "source": ["submitdate = 'submit_20171010.csv'\n", "forsubmission.to_csv(submitdate, encoding='utf-8', index=False)\n", "readitback = pd.read_csv(submitdate, encoding='utf-8', nrows=10)\n", "display(readitback)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "69fd44a0824bf31c936aba66a2c419d4a5549945", "_cell_guid": "5b242335-d2c8-403f-878f-4a4fe2d9f022"}, "source": ["import gzip\n", "f_in = open(submitdate, 'rb')\n", "f_out = gzip.open(submitdate + '.gzip', 'wb')\n", "f_out.writelines(f_in)\n", "f_out.close()\n", "f_in.close()\n", "print('i done')"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_uuid": "f5d6f13db437dd392be01f6ac394518bfdac4334", "_cell_guid": "ea5d9053-06f6-45ac-8913-b4b7249b6c19"}, "source": ["#THROW AN ERROR"]}], "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.1", "file_extension": ".py", "mimetype": "text/x-python"}}}