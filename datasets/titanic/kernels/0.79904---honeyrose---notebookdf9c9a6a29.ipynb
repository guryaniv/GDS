{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a564ab60-5b75-7a39-d44c-c7d05d3feae2"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# ---\n",
        "\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "pd.options.display.max_columns = 100\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.style.use('ggplot')\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.cross_validation import StratifiedKFold\n",
        "from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RidgeCV\n",
        "\n",
        "#\u0441\u043e\u0435\u0434\u0438\u043d\u0438\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0447\u0442\u043e\u0431\u044b \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442 \u044c\u044b\u043b \u0442\u043e\u0447\u043d\u0435\u0435\n",
        "def get_combined_data():\n",
        "    train = pd.read_csv('../input/train.csv')\n",
        "    test = pd.read_csv('../input/test.csv')\n",
        "    #\u0441\u043e\u0437\u0434\u0430\u0451\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0446\u0435\u043b\u0435\u0432\u043e\u0433\u043e \u0432\u0435\u043a\u0442\u043e\u0440\u0430 \u0438 \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u0435\u0433\u043e \u0438\u0437 \u0438\u0441\u0445\u043e\u0434\u043d\u043e\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u044b\n",
        "    targets = train.Survived\n",
        "    train.drop('Survived',1,inplace=True)\n",
        "    # \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u043a \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e\n",
        "    data = train.append(test)\n",
        "    # \u043f\u0440\u043e\u043d\u0443\u043c\u0435\u0440\u0443\u0435\u043c \u0437\u0430\u043d\u043e\u0432\u043e \u0438\u043d\u0434\u0435\u043a\u0441\u044b\n",
        "    data.reset_index(inplace=True)\n",
        "    #\u0443\u0434\u0430\u043b\u0438\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 index\n",
        "    data.drop('index',inplace=True,axis=1)\n",
        "    return data\n",
        "combined = get_combined_data()\n",
        "combined.head()\n",
        "\n",
        "def get_titles():\n",
        "\n",
        "    global combined\n",
        "    \n",
        "    # \u0444\u043e\u0440\u043c\u0438\u0440\u0443\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 title \u0438\u0437 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u0438\u043c\u0451\u043d (\u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u0440\u0430\u0437\u0434\u0435\u043b\u044f\u0435\u043c \u043f\u043e \u0437\u0430\u043f\u044f\u0442\u043e\u0439 ,\u0437\u0430\u0442\u0435\u043c \u043f\u043e \u0442\u043e\u0447\u043a\u0435 \u0438 \u043a\u043e\u043f\u0438\u0440\u0443\u0435\u043c \u0441\u0442\u0440\u043e\u043a\u0443 \u0431\u0435\u0437 \u0438\u043c\u0435\u043d\u0438)\n",
        "    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
        "    # \u0441\u043b\u043e\u0432\u0430\u0440\u044c \u0442\u0438\u0442\u0443\u043b\u043e\u0432\n",
        "    Title_Dictionary = {\n",
        "                        \"Capt\":       \"Officer\",\n",
        "                        \"Col\":        \"Officer\",\n",
        "                        \"Major\":      \"Officer\",\n",
        "                        \"Jonkheer\":   \"Royalty\",\n",
        "                        \"Don\":        \"Royalty\",\n",
        "                        \"Sir\" :       \"Royalty\",\n",
        "                        \"Dr\":         \"Officer\",\n",
        "                        \"Rev\":        \"Officer\",\n",
        "                        \"the Countess\":\"Royalty\",\n",
        "                        \"Dona\":       \"Royalty\",\n",
        "                        \"Mme\":        \"Mrs\",\n",
        "                        \"Mlle\":       \"Miss\",\n",
        "                        \"Ms\":         \"Mrs\",\n",
        "                        \"Mr\" :        \"Mr\",\n",
        "                        \"Mrs\" :       \"Mrs\",\n",
        "                        \"Miss\" :      \"Miss\",\n",
        "                        \"Master\" :    \"Master\",\n",
        "                        \"Lady\" :      \"Royalty\"\n",
        "\n",
        "                        }\n",
        "    #\u043f\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0438\u0435 \u043a\u0430\u0436\u0434\u043e\u043c\u0443 \u0442\u0438\u0442\u0443\u043b\u0443 \u0438\u0437 \u0441\u043b\u043e\u0432\u0430\u0440\u044f\n",
        "    combined['Title'] = combined.Title.map(Title_Dictionary)\n",
        "get_titles()\n",
        "\n",
        "#\u0433\u0440\u0443\u043f\u043f\u0438\u0440\u0443\u0435\u043c \u043f\u043e \u043f\u043e\u043b\u0443,\u0442\u0438\u0442\u0443\u043b\u0443 \u0438 \u043a\u043b\u0430\u0441\u0441\u0443 \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0432\u0437\u0430\u0438\u043c\u043e\u0441\u0432\u044f\u0437\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n",
        "grouped = combined.groupby(['Sex','Pclass','Title'])\n",
        "grouped.median()\n",
        "#\u043f\u043e\u043b\u0443\u0447\u0430\u0435\u043c \u0441\u0440\u0435\u0434\u043d\u0435\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0430\u043c\n",
        "\n",
        "\n",
        "#\u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0435 age \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c  \u043d\u0430 \u043e\u0441\u043d\u043e\u0432\u0435 \u0434\u0430\u043d\u043d\u044b\u0445 \u0438\u0437 \u043f\u0440\u0435\u0434\u044b\u0434\u0443\u0449\u0435\u0439 \u0442\u0430\u0431\u043b\u0438\u0446\u044b\n",
        "def process_age():\n",
        "    global combined\n",
        "    def fillAges(row):\n",
        "        if row['Sex']=='female' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 45\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 49\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 39\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 20\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 30\n",
        "\n",
        "        elif row['Sex']=='female' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Miss':\n",
        "                return 18\n",
        "            elif row['Title'] == 'Mrs':\n",
        "                return 31\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 1:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 41.5\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 52\n",
        "            elif row['Title'] == 'Royalty':\n",
        "                return 40\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 2:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 2\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 30\n",
        "            elif row['Title'] == 'Officer':\n",
        "                return 41.5\n",
        "\n",
        "        elif row['Sex']=='male' and row['Pclass'] == 3:\n",
        "            if row['Title'] == 'Master':\n",
        "                return 6\n",
        "            elif row['Title'] == 'Mr':\n",
        "                return 26\n",
        "    \n",
        "    combined.Age = combined.apply(lambda r : fillAges(r) if np.isnan(r['Age']) else r['Age'], axis=1)\n",
        "process_age()\n",
        "\n",
        "def process_names():\n",
        "    global combined\n",
        "    # \u0443\u0431\u0438\u0440\u0430\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 Name\n",
        "    combined.drop('Name',axis=1,inplace=True)\n",
        "    # \u043e\u0441\u0443\u0449\u0441\u0442\u0432\u0438\u043c \u0432\u0435\u043a\u0442\u043e\u0440\u0440\u0438\u0437\u0430\u0446\u0438\u044e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n",
        "    titles_dummies = pd.get_dummies(combined['Title'],prefix='Title')\n",
        "    combined = pd.concat([combined,titles_dummies],axis=1)\n",
        "    # \u0443\u0434\u0430\u043b\u044f\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 title\n",
        "    combined.drop('Title',axis=1,inplace=True)\n",
        "process_names()\n",
        "combined.head()\n",
        "\n",
        "def process_fares():\n",
        "    global combined\n",
        "    # \u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u043e\u0434\u0438\u043d \u043f\u0440\u043e\u043f\u0443\u0441\u043a \u0432 \u0442\u0430\u0431\u043b\u0438\u0446\u0435 \u0441\u0440\u0435\u0434\u043d\u0438\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c \u043f\u043e \u0441\u0442\u043e\u043b\u0431\u0446\u0443\n",
        "    combined.Fare.fillna(combined.Fare.mean(),inplace=True)\n",
        "process_fares()\n",
        "\n",
        "combined.info()\n",
        "#\u0432\u0438\u0434\u0438\u043c,\u0447\u0442\u043e \u043e\u0441\u0442\u0430\u043b\u0438\u044c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0435 cabin and embarked\n",
        "\n",
        "def process_embarked():\n",
        "    global combined\n",
        "    #\u0442\u0430\u043a \u043a\u0430\u043a \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0435 embarked \u0432\u0441\u0435\u0433\u043e 2 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0430 ,\u0437\u0430\u043f\u043e\u043b\u043d\u0438\u043c \u0438\u0445 \u043d\u0430\u0438\u0431\u043e\u043b\u0435\u0435 \u0447\u0430\u0441\u0442\u043e \u0432\u0441\u0442\u0440\u0435\u0447\u0430\u044e\u0449\u0438\u043c\u0441\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c S\n",
        "    combined.Embarked.fillna('S',inplace=True)\n",
        "    # \u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\n",
        "    embarked_dummies = pd.get_dummies(combined['Embarked'],prefix='Embarked')\n",
        "    combined = pd.concat([combined,embarked_dummies],axis=1)\n",
        "    combined.drop('Embarked',axis=1,inplace=True)\n",
        "process_embarked()\n",
        "\n",
        "def process_cabin():\n",
        "    global combined\n",
        "    # \u0437\u0430\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u0438 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435\u043c U\n",
        "    combined.Cabin.fillna('U',inplace=True)\n",
        "    #\u0432 \u043a\u0430\u0436\u0434\u043e\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0438 \u0441\u0442\u043e\u043b\u0431\u0446\u0430 cabin \u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0431\u0443\u043a\u0432\u0443 \u043a\u0430\u0431\u0438\u043d\u044b\n",
        "    combined['Cabin'] = combined['Cabin'].map(lambda c : c[0])\n",
        "    #\u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0438\u0440\u0443\u0435\u043c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\n",
        "    cabin_dummies = pd.get_dummies(combined['Cabin'],prefix='Cabin')\n",
        "    combined = pd.concat([combined,cabin_dummies],axis=1)\n",
        "    combined.drop('Cabin',axis=1,inplace=True)\n",
        "process_cabin()\n",
        "combined.head()\n",
        "\n",
        "def process_sex():\n",
        "    global combined\n",
        "    #\u0441\u0434\u0435\u043b\u0430\u0435\u043c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0441\u0442\u043e\u043b\u0431\u0446\u0430 \u043f\u043e\u043b \u043b\u0438\u0431\u043e 0 \u0438\u043b\u0438 1 \n",
        "    combined['Sex'] = combined['Sex'].map({'male':1,'female':0})\n",
        "process_sex()\n",
        "\n",
        "def process_pclass():\n",
        "    global combined\n",
        "    #\u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n",
        "    pclass_dummies = pd.get_dummies(combined['Pclass'],prefix=\"Pclass\")\n",
        "    combined = pd.concat([combined,pclass_dummies],axis=1)\n",
        "    combined.drop('Pclass',axis=1,inplace=True)\n",
        "process_pclass()\n",
        "\n",
        "def process_ticket():\n",
        "    global combined\n",
        "    #\u043e\u0442\u0434\u0435\u043b\u044f\u0435\u043c \u043f\u0440\u0435\u0444\u0438\u043a\u0441  \u0431\u0438\u043b\u0435\u0442\u0430\n",
        "    def cleanTicket(ticket):\n",
        "        ticket = ticket.replace('.','')\n",
        "        ticket = ticket.replace('/','')\n",
        "        ticket = ticket.split()\n",
        "        if (not ticket[0].isdigit()):\n",
        "            return ticket[0]\n",
        "        else: \n",
        "            return 'XXX'\n",
        "    #\u0432\u0435\u043a\u0442\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0430\n",
        "    combined['Ticket'] = combined['Ticket'].map(cleanTicket)\n",
        "    tickets_dummies = pd.get_dummies(combined['Ticket'],prefix='Ticket')\n",
        "    combined = pd.concat([combined, tickets_dummies],axis=1)\n",
        "    combined.drop('Ticket',inplace=True,axis=1)\n",
        "process_ticket()\n",
        "\n",
        "def process_family():\n",
        "    global combined\n",
        "    #\u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0435\u043c \u0441\u0442\u043e\u043b\u0431\u0435\u0446 - \u0447\u0438\u0441\u043b\u043e \u0447\u043b\u0435\u043d\u043e\u0432 \u0441\u0435\u043c\u044c\u0438,\u0432\u043c\u0435\u0441\u0442\u0435 \u0441 \u043f\u0430\u0441\u0441\u0430\u0436\u0438\u0440\u043e\u043c ,\u0434\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043d\u0443\u0436\u043d\u043e \u0441\u043b\u043e\u0436\u0438\u0442\u044c \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0435 \u0432 \u0441\u0442\u043e\u043b\u0431\u0446\u0435 sibSp(\u0447\u0438\u0441\u043b\u043e \u0440\u043e\u0434\u043d\u044b\u0445) \u0438 parch(\u0447\u0438\u0441\u043b\u043e \u0440\u043e\u0434\u0438\u0442\u0435\u043b\u0435\u0439 \u0438 \u0434\u0440\u0443\u0437\u0435\u0439)\n",
        "    combined['FamilySize'] = combined['Parch'] + combined['SibSp'] + 1\n",
        "    #\u0441\u043e\u0437\u0434\u0430\u0434\u0438\u043c \u0432\u0435\u043a\u0442\u043e\u0440-\u0441\u0442\u043e\u043b\u0431\u0446\u044b \u043e\u0441\u043d\u043e\u0432\u044b\u0432\u0430\u044f\u0441\u044c \u043d\u0430 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435 \u0447\u0435\u043b\u043e\u0432\u0435\u043a \u0432 \u0441\u0435\u043c\u044c\u0435\n",
        "    combined['Singleton'] = combined['FamilySize'].map(lambda s : 1 if s == 1 else 0)\n",
        "    combined['SmallFamily'] = combined['FamilySize'].map(lambda s : 1 if 2<=s<=4 else 0)\n",
        "    combined['LargeFamily'] = combined['FamilySize'].map(lambda s : 1 if 5<=s else 0)\n",
        "process_family()\n",
        "\n",
        "def scale_all_features():\n",
        "    global combined\n",
        "    # \u0441\u043e\u0437\u0434\u0430\u0451\u043c \u0441\u043f\u0438\u0441\u043e\u043a\n",
        "    features = list(combined.columns)\n",
        "    #\u0443\u0434\u0430\u043b\u044f\u0435\u043c \u044d\u043b\u0435\u043c\u0435\u043d\u0442\n",
        "    features.remove('PassengerId')\n",
        "    #\u043d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432,\u0447\u0442\u043e\u0431\u044b \u043a\u0430\u0436\u0434\u044b\u0439 \u043f\u0440\u0438\u0437\u043d\u0430\u043a \u0432\u043d\u043e\u0441\u0438\u043b \u043e\u0434\u0438\u043d\u0430\u043a\u043e\u0432\u044b\u0439 \u0432\u043a\u043b\u0430\u0434 \u0432 \u043e\u0446\u0435\u043d\u043a\u0443\n",
        "    combined[features] = combined[features].apply(lambda x: x/x.max(), axis=0)\n",
        "    print( 'Features scaled successfully !')\n",
        "scale_all_features()\n",
        "combined.head()\n",
        "\n",
        "\n",
        "\n",
        "def fun():\n",
        "    global combined\n",
        "    train0 = pd.read_csv('../input/train.csv')\n",
        "    y_train = train0.Survived\n",
        "    X_train = combined.ix[0:890]\n",
        "    X_test = combined.ix[891:]\n",
        "    return X_train,X_test,y_train\n",
        "\n",
        "train,test,y = fun()\n",
        "#\u0433\u0440\u0430\u0444\u0438\u043a ,\u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u044e\u0449\u0438\u0439 \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u044c \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432 \u0438 \u0438\u0445 \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "predictors=combined.columns\n",
        "selector = SelectKBest(f_classif, k=5)\n",
        "selector.fit(train,y)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "plt.bar(range(len(predictors)), scores)\n",
        "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "#\u043e\u0441\u0442\u0430\u0432\u0438\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438,\u043e\u0442 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u043d\u0430\u0438\u0431\u043e\u043b\u044c\u0448\u0435\u0439 \u0441\u0442\u0435\u043f\u0435\u043d\u0438 \u0437\u0430\u0432\u0438\u0441\u0438\u0442 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "clf = ExtraTreesClassifier(n_estimators=200)\n",
        "clf = clf.fit(train, y)\n",
        "features = pd.DataFrame()\n",
        "features['feature'] = train.columns\n",
        "features['importance'] = clf.feature_importances_\n",
        "features.sort(['importance'],ascending=False)\n",
        "\n",
        "#\u043e\u0431\u043d\u043e\u0432\u043b\u044f\u0435\u043c \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0443\u044e \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u0443\u044e \u0432\u044b\u0431\u043e\u0440\u043a\u0438\n",
        "model = SelectFromModel(clf, prefit=True)\n",
        "train_new = model.transform(train)\n",
        "test_new = model.transform(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d8a85a2-a7c0-7944-8784-c0af3bf67c3e"
      },
      "outputs": [],
      "source": [
        "cv = StratifiedKFold(y, n_folds=7, shuffle=True, random_state=1)\n",
        "alg_frst_model = RandomForestClassifier(random_state=1)\n",
        "alg_frst_params = [{\n",
        "    \"n_estimators\": [350, 400, 450],\n",
        "    \"min_samples_split\": [6, 8, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}]\n",
        "alg_frst_grid = GridSearchCV(alg_frst_model, alg_frst_params, cv=cv, refit=True, verbose=1, n_jobs=-1)\n",
        "alg_frst_grid.fit(train_new, y)\n",
        "alg_frst_best = alg_frst_grid.best_estimator_\n",
        "print(\"Accuracy (random forest auto): {} with params {}\"\n",
        "      .format(alg_frst_grid.best_score_, alg_frst_grid.best_params_))\n",
        "alg_test = alg_frst_best\n",
        "\n",
        "alg_test.fit(train_new,y)\n",
        "\n",
        "\n",
        "output = alg_frst_best.predict(test_new)\n",
        "df_output = pd.DataFrame()\n",
        "df_output['PassengerId'] = test['PassengerId']\n",
        "df_output['Survived'] = output\n",
        "df_output[['PassengerId','Survived']].to_csv('output2.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}