{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# For testing, multiprocessing and chaining dictionaries\nimport numpy as np\nimport multiprocessing\nfrom collections import ChainMap","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Introduction\n\nThis kernel was forked from an older version from [Faster RLE](https://www.kaggle.com/adamhart/faster-rle) by @Adam Hart\n\n\"I don't really like waiting, so I wanted to speed up the submission process a little bit. So here is a class you can use to utilize multiprocessing in Python for creating the submission file.\"\n\n## Speed comparisons\n\nWe will compare four kinds of encoding functions, as defined below:\n\n- Original RLE (from the forked kernel)    \n- Multiprocessing with the original RLE (great improvement in time)     \n- **Proposed:** Pure numpy function (a little slower than the multiprocessed version)    \n- Multiprocessed pure numpy function\n\n## Warning\n\nFor some reason I can't figure out, sometimes the last section if this kernel fails when validating the multiprocessed numpy encoder.   \nIt's as if some of the 4 processes never got run.   \n\n## Function definitions\n\nThe functions are defined as follows."},{"metadata":{"_uuid":"4c4691b9ff1c2c4f2b4d92e08a5b7ded3f725325"},"cell_type":"markdown","source":"### Original RLE"},{"metadata":{"trusted":true,"_uuid":"1de99af5fbdcd2178233b9c423c673327696ef26"},"cell_type":"code","source":"# Default RLenc\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  # list of run lengths\n    r = 0  # the current run length\n    pos = 1  # count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4458edd652e9c1ce9d3a57c00e92299061789da0"},"cell_type":"markdown","source":"### RLE with parallel processing"},{"metadata":{"trusted":true,"_uuid":"254f956a2e52679a1a42dfd18a5d1ed4ca9fa2c6"},"cell_type":"code","source":"class Consumer(multiprocessing.Process):\n    \"\"\"Consumer for performing a specific task.\"\"\"\n\n    def __init__(self, task_queue, result_queue):\n        \"\"\"Initialize consumer, it has a task and result queues.\"\"\"\n        multiprocessing.Process.__init__(self)\n        self.task_queue = task_queue\n        self.result_queue = result_queue\n\n    def run(self):\n        \"\"\"Actual run of the consumer.\"\"\"\n        while True:\n            next_task = self.task_queue.get()\n            if next_task is None:\n                # Poison pill means shutdown\n                self.task_queue.task_done()\n                break\n            # Fetch answer from task\n            answer = next_task()\n            self.task_queue.task_done()\n            # Put into result queue\n            self.result_queue.put(answer)\n        return\n\n\nclass RleTask(object):\n    \"\"\"Wrap the RLE Encoder into a Task.\"\"\"\n\n    def __init__(self, idx, img):\n        \"\"\"Save image to self.\"\"\"\n        self.img = img\n        self.idx = idx\n\n    def __call__(self):\n        \"\"\"When object is called, encode.\"\"\"\n        return {self.idx: RLenc(self.img)}\n\n\nclass FastRle(object):\n    \"\"\"Perform RLE in paralell.\"\"\"\n\n    def __init__(self, num_consumers=2):\n        \"\"\"Initialize class.\"\"\"\n        self._tasks = multiprocessing.JoinableQueue()\n        self._results = multiprocessing.Queue()\n        self._n_consumers = num_consumers\n\n        # Initialize consumers\n        self._consumers = [Consumer(self._tasks, self._results) for i in range(self._n_consumers)]\n        for w in self._consumers:\n            w.start()\n\n    def add(self, img, idx):\n        \"\"\"Add a task to perform.\"\"\"\n        self._tasks.put(RleTask(img, idx))\n\n    def get_results(self):\n        \"\"\"Close all tasks.\"\"\"\n        # Provide poison pill\n        [self._tasks.put(None) for _ in range(self._n_consumers)]\n        # Wait for finish\n        self._tasks.join()\n        # Return results\n        singles = []\n        while not self._results.empty():\n            singles.append(self._results.get())\n        return dict(ChainMap({}, *singles))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f2a137c115a7222c7509e9ec6748d2c0ba07a37"},"cell_type":"markdown","source":"> ### Proposed faster RLE using pure numpy"},{"metadata":{"trusted":true,"_uuid":"fd659f00ee7cc624712a034f9628b75acf5316d4"},"cell_type":"code","source":"#even faster RLE encoder\ndef toRunLength(x, firstDim = 2):\n    \n    if firstDim == 2:\n        x = np.swapaxes(x, 1,2)\n    \n    x = (x > 0.5).astype(int)\n    x = x.reshape((x.shape[0], -1))    \n    x = np.pad(x, ((0,0),(1,1)), 'constant')\n    \n    x = x[:,1:] - x[:,:-1]\n    starts = x > 0\n    ends = x < 0\n    \n    rang = np.arange(x.shape[1])\n    \n    results = []\n    \n    for image, imStarts, imEnds in zip(x, starts, ends):\n        st = rang[imStarts]\n        en = rang[imEnds]\n        \n#         counts = (en-st).astype(str)\n#         st = (st+1).astype(str)\n        \n#         res = np.stack([st,counts], axis=-1).reshape((-1,))\n#         res = np.core.defchararray.join(\" \", res)\n\n        res = \"\"\n        for s,e in zip(st,en):\n            res += str(s+1) + \" \" + str(e-s) + \" \"\n            \n        results.append(res[:-1])\n    #print(\"called\")\n        \n    return results","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e42eaa907348242a3ab0dbb4ace9242148bcdb00"},"cell_type":"markdown","source":"### Even faster RLE by using the proposed solution in parallel"},{"metadata":{"trusted":true,"_uuid":"98603dcb6ddd5868dffc96d05b919d77f1a0c37c"},"cell_type":"code","source":"class FasterTask(object):\n    \"\"\"Wrap the RLE Encoder into a Task.\"\"\"\n\n    def __init__(self, array, startIndex):\n        \"\"\"Save array to self.\"\"\"\n        self.array = array\n        self.startIndex = startIndex\n\n    def __call__(self):\n        \"\"\"When object is called, encode.\"\"\"\n        return (toRunLength(self.array), self.startIndex)\n\n\nclass FasterRle(object):\n    \"\"\"Perform RLE in paralell.\"\"\"\n\n    def __init__(self, num_consumers=2):\n        \"\"\"Initialize class.\"\"\"\n        self._tasks = multiprocessing.JoinableQueue()\n        self._results = multiprocessing.Queue()\n        self._n_consumers = num_consumers\n\n        # Initialize consumers\n        self._consumers = [Consumer(self._tasks, self._results) for i in range(self._n_consumers)]\n        for w in self._consumers:\n            w.start()\n\n    def add(self, array, startIndex):\n        \"\"\"Add a task to perform.\"\"\"\n        self._tasks.put(FasterTask(array, startIndex))\n\n    def get_results(self):\n        \"\"\"Close all tasks.\"\"\"\n        # Provide poison pill\n        [self._tasks.put(None) for _ in range(self._n_consumers)]\n        # Wait for finish\n        self._tasks.join()\n        # Return results\n        singles = []\n        while not self._results.empty():\n            singles.append(self._results.get())\n            \n        resultDic = dict()\n        for rles, start in singles:\n            #print('start:', start)\n            for i,rle in enumerate(rles):\n                #print('i:', i)\n                resultDic[str(start+i)] = rle\n        return resultDic","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d12f398b5c6f6750382f6bfa41864fd4dd1fb01"},"cell_type":"markdown","source":"# Comparisons\n\nHere, we test the time it takes for each of the 4 functions to run. "},{"metadata":{"trusted":true,"_uuid":"b0f0c90d03c088bd990ecba4d0656f2a637f2628","scrolled":true},"cell_type":"code","source":"example_image = np.random.uniform(0, 1, size=(1000, 101, 101)) > 0.5\n\n# Wrap the FastRle class into a method so we measure the time\ndef original(array):\n    results = {}\n    for i, arr in enumerate(array):\n        results['%d' % i] = RLenc(arr)\n    return results\n\ndef faster(array):\n    rle = FastRle(4)\n    for i, arr in enumerate(array):\n        rle.add('%d' % i, arr)\n    return rle.get_results()\n\ndef pureNumpy(array):\n    rle = toRunLength(array)\n    rle = {'%d' % i: row for i,row in enumerate(rle)}\n    return rle\n\ndef evenFaster(array):\n    #make sure you treat this properly when len(array) % 4 != 0\n    rle = FasterRle(4)\n    subSize = len(array)//4  \n    \n    for i in range(0,len(array),subSize):\n        rle.add(array[i:i+subSize], i)\n    return rle.get_results()\n\nprint(\"Measuring times: \\n\")\nprint(\"Original:\")\n%timeit original(example_image)\nprint(\"\\nParallel:\")\n%timeit faster(example_image)\nprint(\"\\nPure numpy:\")\n%timeit pureNumpy(example_image)\nprint(\"\\nEven faster:\")\n%timeit evenFaster(example_image)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64726673e2a8f4c619b01d97490ea522a2323b10"},"cell_type":"markdown","source":"# Validation\n\nJust to make sure all functions output the same for the same input images."},{"metadata":{"trusted":true,"_uuid":"36320ea9a833cda2e423a412354784c6e853319f"},"cell_type":"code","source":"example_image = np.random.uniform(0, 1, size=(12, 101, 101)) > 0.5\nx = faster(example_image)\ny = original(example_image)\nz = pureNumpy(example_image)\nw = evenFaster(example_image)\n\n# Make sure they are the same\nprint(\"Comparing values:\\n\")\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == y[key])\nprint('Original vs Parallel:', np.all(comparison))\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == z[key])\nprint(\"Original vs pure numpy:\",np.all(comparison))\n\ncomparison = []\nfor key in x:\n    comparison.append(x[key] == w[key])\nprint(\"Original vs even faster:\",np.all(comparison))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0568256970006f685cfd6abd95c340b9234c5880"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}