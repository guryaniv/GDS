{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b5358ec6-f320-fc20-6d59-b22a6e260bf2"
      },
      "source": [
        "This notebook is trying to create new features from the features given . My earlier script could not import the test and train files due to some error ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "407fca25-7e6a-c865-e567-31dc19a7fefa"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78b09ec4-449d-59fc-87d6-5d991815d563"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "train = pd.read_json(\"../input/train.json\")\n",
        "test = pd.read_json(\"../input/test.json\")\n",
        "print (train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ad6ac10-f231-a985-e81c-8a1394b0c4b2"
      },
      "outputs": [],
      "source": [
        "train['source']='train'\n",
        "test['source']='test'\n",
        "print(train.head())\n",
        "print(test.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d48cb56d-d6f0-d19b-0c11-406923ee3ce3"
      },
      "source": [
        "Handling bathrooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0d2ca896-3245-e457-19b9-28ba18c46772"
      },
      "outputs": [],
      "source": [
        "print(train['bathrooms'].value_counts())\n",
        "# There are houses with 0.0 bathrooms and some with floating point no of bathrooms\n",
        "print(train['bedrooms'].value_counts())\n",
        "# There are 9475 houses with 0 bedrooms\n",
        "train['bathrooms']=train['bathrooms'].astype(int)\n",
        "test['bathrooms']=test['bathrooms'].astype(int)\n",
        "# if no of bathrooms are greater than 5 interest level is low else varies\n",
        "# so we can create dummies\n",
        "train.loc[train['bathrooms']==0, 'interest_level'] = 'low'\n",
        "sns.violinplot(x='interest_level', y='bathrooms', data=train)\n",
        "plt.xlabel('Interest level')\n",
        "plt.ylabel('bathrooms')\n",
        "plt.show()\n",
        "# if 0 or greater than 4 bathrooms interest_level is low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "519bbca7-be9f-ab86-ca7b-c4399bae4cbc"
      },
      "source": [
        "Bedrooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b4b01e7-cb65-bff5-6cc4-365f87962952"
      },
      "outputs": [],
      "source": [
        "# same patern as bathrooms only different at 0\n",
        "# pattern between bedrooms and  bathrooms\n",
        "print(train.loc[train['bathrooms']==0, 'bedrooms'].value_counts())\n",
        "print(train.loc[train['bathrooms']==6, 'bedrooms'].value_counts())\n",
        "# we can combine 6 or more #bathrooms with 5 or more bedrooms\n",
        "sns.violinplot(x='interest_level', y='bedrooms', data=train)\n",
        "plt.xlabel('Interest level')\n",
        "plt.ylabel('bedrooms')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1d233eed-7591-ac46-5936-341666f9922a"
      },
      "source": [
        "Creating new variables from bathrooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "255b436a-cbec-7802-7821-8dfce6096ba1"
      },
      "outputs": [],
      "source": [
        "train[\"price_t\"] =train[\"price\"]/train[\"bedrooms\"]\n",
        "test[\"price_t\"] = test[\"price\"]/test[\"bedrooms\"] \n",
        "\n",
        "train[\"room_sum\"] =train[\"bedrooms\"] + train[\"bathrooms\"]\n",
        "test[\"room_sum\"] = test[\"bedrooms\"] + test[\"bathrooms\"]\n",
        "\n",
        "train['price_per_room'] = train['price']/train['room_sum']\n",
        "test['price_per_room'] = test['price']/test['room_sum']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "89668e14-e8c1-97a4-4662-10fc627ab292"
      },
      "source": [
        "Handling time (created)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "06479eb6-d808-09d3-7cdb-84ac723906a5"
      },
      "outputs": [],
      "source": [
        "train[\"created\"] = pd.to_datetime(train[\"created\"])\n",
        "train[\"created_year\"] = train[\"created\"].dt.year\n",
        "train[\"created_month\"] = train[\"created\"].dt.month\n",
        "train[\"created_day\"] = train[\"created\"].dt.day\n",
        "train[\"created_hour\"] = train[\"created\"].dt.hour\n",
        "test[\"created\"] = pd.to_datetime(test[\"created\"])\n",
        "test[\"created_year\"] = test[\"created\"].dt.year\n",
        "test[\"created_month\"] = test[\"created\"].dt.month\n",
        "test[\"created_day\"] = test[\"created\"].dt.day\n",
        "test[\"created_hour\"] = test[\"created\"].dt.hour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "08b686f4-86d4-cbfe-0f03-99fe6b1b5eb0"
      },
      "source": [
        "Log of Price as it is right skewed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8905bfa2-503e-e48c-7050-bf8361f3037c"
      },
      "outputs": [],
      "source": [
        "plt.scatter(range(train.shape[0]), np.sort(train.price.values))\n",
        "plt.xlabel('index')\n",
        "plt.ylabel('price')\n",
        "plt.show()\n",
        "# there are outliners\n",
        "ulimit = np.percentile(train.price.values, 99)\n",
        "train['price'].ix[train['price']>ulimit] = ulimit\n",
        "# price is right skewed so using log to create a gaussian pattern\n",
        "train['price']=np.log1p(train['price'])\n",
        "test['price']=np.log1p(test['price'])\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.distplot(train.price.values, bins=50, kde=True)\n",
        "plt.xlabel('price')\n",
        "plt.show()\n",
        "sns.violinplot(data=train,x = 'interest_level',y='price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9a61f1ff-0429-b8c8-be0c-69c9994eac9b"
      },
      "source": [
        "Street address and Display address"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "daa64a3c-0fce-3625-cbcc-a38efddb24e9"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "display_count = train.groupby('display_address')['display_address'].count()\n",
        "plt.hist(display_count.values, bins=100, log=True, alpha=0.9)\n",
        "plt.xlabel('Number of times display_address appeared', fontsize=12)\n",
        "plt.ylabel('log of Count', fontsize=12)\n",
        "plt.show()\n",
        "# there are too many values and none of them are more than 500\n",
        "# most of the values are less than 10\n",
        "#so we label encode the values\n",
        "address = [\"display_address\", \"street_address\"]\n",
        "for x in address:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(list(df[x].values))\n",
        "    df[x] = le.transform(list(df[x].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4f8c132a-b278-3150-7139-982205aa3cdc"
      },
      "source": [
        "Find position and density from latitude and longitude"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f585e2fc-3bde-cb04-b0fa-2a77c5ae129b"
      },
      "outputs": [],
      "source": [
        "train[\"pos\"] = train.longitude.round(3).astype(str) + '_' + train.latitude.round(3).astype(str)\n",
        "test[\"pos\"] = test.longitude.round(3).astype(str) + '_' + test.latitude.round(3).astype(str)\n",
        "\n",
        "train[\"density\"] = train['pos'].apply(lambda x: dvals.get(x, vals.min()))\n",
        "test[\"density\"] = test['pos'].apply(lambda x: dvals.get(x, vals.min()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0b35ab4c-0b44-f82d-78e6-b325b0014735"
      },
      "source": [
        "manager_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9307b4c5-1567-d5de-5d7e-dd27e78b3723"
      },
      "outputs": [],
      "source": [
        "print(len(train['manager_id'].unique()))\n",
        "# 3481 unique managers\n",
        "temp = train.groupby('manager_id').count().iloc[:,-1]\n",
        "temp2 = test.groupby('manager_id').count().iloc[:,-1]\n",
        "df_managers = pd.concat([temp,temp2],axis=1,join='outer')\n",
        "df_managers.columns=['train_count','test_count']\n",
        "print(df_managers.sort_values(by = 'train_count',ascending = False).head())\n",
        "# considering only those manager_ids which are in train\n",
        "man_list = df_managers['train_count'].sort_values(ascending = False).head(3481).index\n",
        "ixes = df.manager_id.isin(man_list)\n",
        "df10 = df[ixes][['manager_id','interest_level']]\n",
        "# create dummies of interest levels\n",
        "interest_dummies = pd.get_dummies(df10.interest_level)\n",
        "df10 = pd.concat([df10,interest_dummies[['low','medium','high']]], axis = 1).drop('interest_level', axis = 1)\n",
        "print(df10.head())\n",
        "gby = pd.concat([df10.groupby('manager_id').mean(),df10.groupby('manager_id').count()], axis = 1).iloc[:,:-2]\n",
        "gby.columns = ['low','medium','high','count']\n",
        "gby.sort_values(by = 'count', ascending = False).head(10)\n",
        "gby['manager_skill'] = gby['medium']*1 + gby['high']*2 \n",
        "gby['manager_id']=gby.index\n",
        "print(gby.head(5))\n",
        "print(gby.shape)\n",
        "df = df.merge(gby[['manager_id','manager_skill']],on='manager_id',how='outer',right_index=False)\n",
        "df['manager_skill']=df['manager_skill'].fillna(0)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5a41a2f2-62d7-a2e6-f28a-88a7abadfd94"
      },
      "source": [
        "Adding interest acc to manager_id to test acc to train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3679f557-a963-a1e1-74d1-2f3d09296131"
      },
      "outputs": [],
      "source": [
        "index=list(range(train.shape[0]))\n",
        "random.shuffle(index)\n",
        "a=[np.nan]*len(train)\n",
        "b=[np.nan]*len(train)\n",
        "c=[np.nan]*len(train)\n",
        "\n",
        "for i in range(5):\n",
        "    building_level={}\n",
        "    for j in train['manager_id'].values:\n",
        "        building_level[j]=[0,0,0]\n",
        "    \n",
        "    test_index=index[int((i*train.shape[0])/5):int(((i+1)*train.shape[0])/5)]\n",
        "    train_index=list(set(index).difference(test_index))\n",
        "    \n",
        "    for j in train_index:\n",
        "        temp=train.iloc[j]\n",
        "        if temp['interest_level']=='low':\n",
        "            building_level[temp['manager_id']][0]+=1\n",
        "        if temp['interest_level']=='medium':\n",
        "            building_level[temp['manager_id']][1]+=1\n",
        "        if temp['interest_level']=='high':\n",
        "            building_level[temp['manager_id']][2]+=1\n",
        "            \n",
        "    for j in test_index:\n",
        "        temp=train.iloc[j]\n",
        "        if sum(building_level[temp['manager_id']])!=0:\n",
        "            a[j]=building_level[temp['manager_id']][0]*1.0/sum(building_level[temp['manager_id']])\n",
        "            b[j]=building_level[temp['manager_id']][1]*1.0/sum(building_level[temp['manager_id']])\n",
        "            c[j]=building_level[temp['manager_id']][2]*1.0/sum(building_level[temp['manager_id']])\n",
        "            \n",
        "train['manager_level_low']=a\n",
        "train['manager_level_medium']=b\n",
        "train['manager_level_high']=c\n",
        "\n",
        "a=[]\n",
        "b=[]\n",
        "c=[]\n",
        "building_level={}\n",
        "for j in train['manager_id'].values:\n",
        "    building_level[j]=[0,0,0]\n",
        "\n",
        "for j in range(train.shape[0]):\n",
        "    temp=train.iloc[j]\n",
        "    if temp['interest_level']=='low':\n",
        "        building_level[temp['manager_id']][0]+=1\n",
        "    if temp['interest_level']=='medium':\n",
        "        building_level[temp['manager_id']][1]+=1\n",
        "    if temp['interest_level']=='high':\n",
        "        building_level[temp['manager_id']][2]+=1\n",
        "\n",
        "for i in test['manager_id'].values:\n",
        "    if i not in building_level.keys():\n",
        "        a.append(np.nan)\n",
        "        b.append(np.nan)\n",
        "        c.append(np.nan)\n",
        "    else:\n",
        "        a.append(building_level[i][0]*1.0/sum(building_level[i]))\n",
        "        b.append(building_level[i][1]*1.0/sum(building_level[i]))\n",
        "        c.append(building_level[i][2]*1.0/sum(building_level[i]))\n",
        "test['manager_level_low']=a\n",
        "test['manager_level_medium']=b\n",
        "test['manager_level_high']=c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "beff0860-2d0f-952f-a670-886d8023d6ce"
      },
      "source": [
        "Adding interest level  Building_id decreases the model accuracy\n",
        "\n",
        "Adding no of photos , no of words in features and description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "341062b8-405d-2800-5558-9f00b03d109c"
      },
      "outputs": [],
      "source": [
        "train[\"num_photos\"] = train[\"photos\"].apply(len)\n",
        "test[\"num_photos\"] = test[\"photos\"].apply(len)\n",
        "\n",
        "train[\"num_features\"] = train[\"features\"].apply(len)\n",
        "test[\"num_features\"] = test[\"features\"].apply(len)\n",
        "\n",
        "train[\"num_description_words\"] = train[\"description\"].apply(lambda x: len(x.split(\" \")))\n",
        "test[\"num_description_words\"] = test[\"description\"].apply(lambda x: len(x.split(\" \")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "37fc8c32-b992-5f12-d3c7-755f09716535"
      },
      "source": [
        "Changing features to sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca37f1cd-ab4e-63df-9626-1a36c029872c"
      },
      "outputs": [],
      "source": [
        "train['features'] = train[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
        "test['features'] = test[\"features\"].apply(lambda x: \" \".join([\"_\".join(i.split(\" \")) for i in x]))\n",
        "\n",
        "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
        "tr_sparse = tfidf.fit_transform(train[\"features\"])\n",
        "te_sparse = tfidf.transform(test[\"features\"])"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}