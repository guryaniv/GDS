{"cells":[{"metadata":{"_uuid":"15b37adb9992540b453c754f9fde24b21d780dd2"},"cell_type":"markdown","source":"# PUBG Finish Placement Prediction\n\nAutor: Daniel Martinez Bielostotzky"},{"metadata":{"_uuid":"4d8fd3394d1fd1798c8270fe2e32c7cfff552db2"},"cell_type":"markdown","source":"## Table of contents\n* **Imports: Dataset, Libraries and Usefull Functions**\n* **Preprocessing: Missing Values**\n* **Feature Engenieering: Team and Match Features**\n* **Feature Selection and Outliers**\n* **LightGBM Model**\n* **Test Data Prediction and Submit**"},{"metadata":{"_uuid":"d586e88e4c6def12c2ba949f076a5dc8bdf20bcd"},"cell_type":"markdown","source":"## Imports: Dataset, Libraries and Usefull Functions\n\nFor this notebook, I'll use two functions that are from a kind of EDA framework that I always use and that its open to contributions on [GitHub](https://github.com/Bielos/EDA-Framework)."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\n\ndef get_null_observations(dataframe, column):\n    return dataframe[pd.isnull(dataframe[column])]\n\ndef delete_null_observations(dataframe, column):\n    fixed_df = dataframe.drop(get_null_observations(dataframe,column).index)\n    return fixed_df\n    \ndef get_missing_data_table(dataframe):\n    total = dataframe.isnull().sum()\n    percentage = dataframe.isnull().sum() / dataframe.isnull().count()\n    \n    missing_data = pd.concat([total, percentage], axis='columns', keys=['TOTAL','PERCENTAGE'])\n    return missing_data.sort_index(ascending=True)\n\ndf = pd.read_csv('../input/train_V2.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d941ddafaa45768a44556ad97c1c989216bb2e6b"},"cell_type":"markdown","source":"## Preprocessing: Missing Values\n\nTo check the integrity of the data, the missing values and data types are displayed.\n### Missing Vales\nUsing *get_missing_data_table* we can see that the training dataset has only one record with a missing value in the 'winPlacePerc' column since it is the target column no completion method can be applied."},{"metadata":{"trusted":true,"_uuid":"10221cf930a3a3de7fb8c39f47299151b4f579a4"},"cell_type":"code","source":"get_missing_data_table(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e65338e87a5f71bbfe377977fa4fc8fe306c36b1"},"cell_type":"code","source":"df = delete_null_observations(dataframe=df, column='winPlacePerc')\nget_missing_data_table(df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"246de470658de11a66fb340d01e2af582e8db2b1"},"cell_type":"markdown","source":"## Feature Engenieering: Team and Match Features\nGrouping records by *groupId* and *matchId* the features *teamKills* (Sum of kills in the team), *teamSize* (Total number of players in the team), *matchKills* and *matchSize* are created. "},{"metadata":{"trusted":true,"_uuid":"c779db5b45eb7a9c0f3fa791da1b1eec8fbeca6f"},"cell_type":"code","source":"# Adding team features\ndf_team_dict = (df.groupby('groupId', as_index = True)\n          .agg({'Id':'count', 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).to_dict()\n\nteamKills = []\nteamSize = []\n\nfor teamId in df['groupId']:\n    teamKills.append(df_team_dict['teamKills'][teamId])\n    teamSize.append(df_team_dict['teamSize'][teamId])\n\ndf['teamKills'] = teamKills\ndf['teamSize'] = teamSize\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc35f9c1c9e91b1e07ff2b43a468c6256d7058b2"},"cell_type":"code","source":"# Adding match features\ndf_team = (df.groupby('groupId', as_index = False)\n          .agg({'Id':'count', 'matchId':lambda x: x.unique()[0], 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).reset_index()\n\ndf_match = (df_team.groupby('matchId', as_index = True)\n           .agg({'teamSize':'sum', 'teamKills':'sum'})\n           .rename(columns={'teamSize':'matchSize', 'teamKills':'matchKills'})).to_dict()\nmatchSize = []\nmatchKills = []\n\nfor matchId in df['matchId']:\n    matchSize.append(df_match['matchSize'][matchId])\n    matchKills.append(df_match['matchKills'][matchId])\n\ndf['matchSize'] = matchSize\ndf['matchKills'] = matchKills\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2cdc8ac94573aad5d26532147a2e63cdf0919879"},"cell_type":"markdown","source":"## Feature Selection and Outliers\n\nFeatures that represent IDs are meaningless for any model so they are dropped out. "},{"metadata":{"trusted":true,"_uuid":"bcf492bdfd7d79e0832f86943044bf7fc2c49dcf"},"cell_type":"code","source":"#Drop insignificant features\ndf.drop(['Id'], axis='columns', inplace=True)\ndf.drop(['groupId'], axis='columns', inplace=True)\ndf.drop(['matchId'], axis='columns', inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3ff353a0f44e53d431d88b132bc1e8334db6fc3"},"cell_type":"markdown","source":"### Outliers\nSome records may be rare cases and may affect the generalization power of the model because they are just noise.\n\nThe outliers to be deleted are:\n1.  Records with low *matchDuration* (According to box plot) \n1. Players with 0 *rideDistance* and *roadKills* greater than 0"},{"metadata":{"trusted":true,"_uuid":"06dc0cd06d7b26220a9d70460f5c7fa452697893"},"cell_type":"code","source":"# matchDuration boxplot\nfig = plt.figure()\nax = fig.add_subplot(1,1,1)\nsn.boxplot(data=df['matchDuration'], ax= ax)\nax.set(title='Match Duration Box Plot')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa7f72fa0a8d6fcda9ab2b453ad0e5f482e7499a"},"cell_type":"code","source":"# Delete Outliers according to matchDuration\nprevious_record_size = df.shape[0]\n\nh_spread = df['matchDuration'].quantile(.75) - df['matchDuration'].quantile(.25)\nlimit = df['matchDuration'].quantile(.25) - 2 * h_spread\ndf.drop(df[df['matchDuration'] < limit].index, inplace=True)\n\nnew_record_size = df.shape[0]\nprint('Total records deleted: {} ({:.7%} of previous record size)'.format(previous_record_size - new_record_size, 1 - new_record_size / previous_record_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8fc0e0de167d3f463ec947d495c3f567431b8f91"},"cell_type":"code","source":"# Delete Outliers according to rideDistance and roadKills\nprevious_record_size = df.shape[0]\n\ndf.drop(df.query('rideDistance == 0 and roadKills > 0').index, inplace=True)\n\nnew_record_size = df.shape[0]\nprint('Total records deleted: {} ({:.7%} of previous record size)'.format(previous_record_size - new_record_size, 1 - new_record_size / previous_record_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1940bac7b544b5ce3e647365230f0b6675639e89"},"cell_type":"markdown","source":"## LightGBM Model\n\nA LightGBM model is used to predict the target *winPlacePerc*,  the model use 15000 iterations, 70% of features and 90% of training data per tree"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e6771134cecf32fa7702083de62d61db798553a5"},"cell_type":"code","source":"# Label encode matchType\n\nfrom sklearn import preprocessing\nencoder = preprocessing.LabelEncoder()\ndf['matchType'] = encoder.fit_transform(df['matchType'])\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f2e59e593602b3f112570f1a578f05234968973"},"cell_type":"code","source":"# X and y split\ny = df['winPlacePerc'].values\nX = df.drop(['winPlacePerc'], axis='columns').values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a43904e9068788357cab50227ad55924430f53b7"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n#LightGBM\nimport lightgbm as lgb\n\n# create dataset for lightgbm\nlgb_train = lgb.Dataset(X_train, y_train, categorical_feature=[12])\nlgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n\n# set matchType\n\nparams = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"mae\",\n        \"n_estimators\":15000,\n        \"early_stopping_rounds\":100,\n        \"num_leaves\" : 31, \n        \"learning_rate\" : 0.05, \n        \"bagging_fraction\" : 0.9,\n        \"bagging_seed\" : 0, \n        \"num_threads\" : 4,\n        \"colsample_bytree\" : 0.7\n        }\n\nmodel = lgb.train(params,\n                lgb_train,\n                num_boost_round=20,\n                valid_sets=lgb_eval,\n                early_stopping_rounds=5,\n                verbose_eval=1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d41e2c846c19af385bb25cfcc047bf1ac0ac444d"},"cell_type":"markdown","source":"## Test Data Prediction and Submit"},{"metadata":{"trusted":true,"_uuid":"9d6f1251f487de6e775ead296a5205dc1d8ac761"},"cell_type":"code","source":"df_test = pd.read_csv('../input/test_V2.csv')\ndf_test['matchType'] = encoder.transform(df_test['matchType'])\ndf_test_team_dict = (df_test.groupby('groupId', as_index = True)\n          .agg({'Id':'count', 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).to_dict()\n\nteamKills_test = []\nteamSize_test = []\n\nfor teamId in df_test['groupId']:\n    teamKills_test.append(df_test_team_dict['teamKills'][teamId])\n    teamSize_test.append(df_test_team_dict['teamSize'][teamId])\n\ndf_test['teamKills'] = teamKills_test\ndf_test['teamSize'] = teamSize_test\n\ndf_team_test = (df_test.groupby('groupId', as_index = False)\n          .agg({'Id':'count', 'matchId':lambda x: x.unique()[0], 'kills':'sum'})\n          .rename(columns={'Id':'teamSize', 'kills':'teamKills'})).reset_index()\n\ndf_match_test = (df_team_test.groupby('matchId', as_index = True)\n           .agg({'teamSize':'sum', 'teamKills':'sum'})\n           .rename(columns={'teamSize':'matchSize', 'teamKills':'matchKills'})).to_dict()\nmatchSize_test = []\nmatchKills_test = []\n\nfor matchId in df_test['matchId']:\n    matchSize_test.append(df_match_test['matchSize'][matchId])\n    matchKills_test.append(df_match_test['matchKills'][matchId])\n\ndf_test['matchSize'] = matchSize_test\ndf_test['matchKills'] = matchKills_test\n\nX_testdata = df_test.drop(['Id','groupId','matchId'], axis='columns').values\n\ndf_test['winPlacePerc'] = model.predict(X_testdata, num_iteration=model.best_iteration)\nsubmission = df_test[['Id', 'winPlacePerc']]\nsubmission.to_csv('submission.csv', index=False)\nprint('Done!')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}