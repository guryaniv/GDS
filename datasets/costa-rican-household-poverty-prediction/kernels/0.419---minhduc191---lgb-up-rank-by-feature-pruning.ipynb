{"cells":[{"metadata":{"_uuid":"cebde273d42b192df12116b8d8e8759fae3b4e8f"},"cell_type":"markdown","source":"This  is enhanced version of this [notebook]https://www.kaggle.com/minhduc191/lgb-feature-engineering-explained/) where I try to  improve my LGB model by:\n\n* pruning features with low importance\n* tuning hyperparameters."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c69d45b6ef9aa3dc9af29b8b5877c115fecd7cd7"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# for param tuning\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import get_scorer\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e42778ce03303c74216f3adf3500d2983769ee3b"},"cell_type":"code","source":"# load data\ntrain = pd.read_csv('../input/train.csv')\nprint('Shape of train set {}'.format(train.shape))\ntest = pd.read_csv('../input/test.csv')\nprint('Shape of test set {}'.format(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"## Helpers"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4514342140c14fd98268aeb6400fbc5ae1d134d8"},"cell_type":"code","source":"def onehot_encode(cat_feat, data):\n    '''\n    Encode given categorical feature and add names of new binary columns into the set of features\n    :param cat_feat:\n    :param data:\n    :return:\n    '''\n    encoded = pd.get_dummies(data[cat_feat], prefix=cat_feat, dummy_na=True)\n    res = pd.concat([data.drop(columns=[cat_feat]), encoded], axis='columns')\n    return res\n\ndef add_quality(df, componente='pared', component='wall'):\n    for i in [1,2,3]:\n        i_quality = (df['e{}{}'.format(componente, i)] == 1)\n        df.loc[i_quality, '{}_quality'.format(component)] = i\n    return df\n\ndef to_english(df, sp_pre='pared', eng_pre='wall_', translate=None):\n    '''\n    rename certain columns in specified dataframe from Spanish \n    to English, given the translation\n    '''\n    for sp in translate.keys():\n        spanish_name = sp_pre + '{}'.format(sp)\n        english_name = eng_pre + '{}'.format(translate[sp])\n        df.rename(columns={spanish_name: english_name}, inplace=True)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6804c3f3551983f14b0742b74c05994db02ad99a"},"cell_type":"code","source":"def mk_derived_feats(df):\n    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n                 ('working_man_fraction', 'r4h2', 'r4t3'),\n                 ('all_man_fraction', 'r4h3', 'r4t3'),\n                 ('human_density', 'tamviv', 'rooms'),\n                 ('human_bed_density', 'tamviv', 'bedrooms'),\n                 ('mobile_density', 'qmobilephone', 'r4t3'),\n                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n                 #('', '', ''),\n                ]\n    \n    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n                 ('people_weird_stat', 'tamhog', 'r4t3')]\n\n    for f_new, f1, f2 in feats_div:\n        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n    for f_new, f1, f2 in feats_sub:\n        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n    return df\n\ndef mk_agg_feats(df):\n    # aggregation rules over household\n    aggs_num = {'age': ['min', 'max', 'mean'],\n                'escolari': ['min', 'max', 'mean']\n               }\n    aggs_cat = {'dis': ['sum', 'mean']} # mean will give us percentage of disable members\n    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n            aggs_cat[f_] = ['mean', 'sum'] # mean will give us percentage of the type\n    \n    # aggregate over household\n    for name_, df_ in [('18', df.query('age >= 18'))]:\n        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n        df = df.join(df_agg, how='left', on='idhogar')\n        del df_agg\n    \n    return df\n\ndef drop_redundant(df):\n    # Drop SQB variables, as they are just squres of other vars \n    df.drop([f_ for f_ in df.columns if f_.startswith('SQB') or f_ == 'agesq'], axis=1, inplace=True)\n    # Drop id's\n#     df.drop(['Id', 'idhogar'], axis=1, inplace=True)\n    # Drop repeated columns\n    df.drop(['hhsize', 'area2'], axis=1, inplace=True)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8240dfb6f48b30b7405c1cc2052d216897de410f"},"cell_type":"markdown","source":"## Feature engineering\nBased on https://www.kaggle.com/mlisovyi/feature-engineering-lighgbm-with-f1-macro, with additional  comments to clarify things."},{"metadata":{"trusted":true,"_uuid":"bba142c313c125b809492e1a5d6425ad698b99c2"},"cell_type":"code","source":"# join train and test\ntest['Target'] = np.nan\ndata_all = pd.concat([train, test])\nn_house = data_all['idhogar'].nunique()\nprint('# unique households in data: {}'.format(n_house))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"72f56b119001ee9616986c2fe4dde7bc357b0479"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nyes_no_map = {'no': 0, 'yes': 1}\ndata_all['dependency'] = data_all['dependency'].replace(yes_no_map).astype(np.float32)\ndata_all['edjefe'] = data_all['edjefe'].replace(yes_no_map).astype(np.float32)\ndata_all['edjefa'] = data_all['edjefa'].replace(yes_no_map).astype(np.float32)\n\ndata_all['idhogar'] = LabelEncoder().fit_transform(data_all['idhogar'])\n\ndata_all = mk_derived_feats(data_all)\ndata_all = mk_agg_feats(data_all)\ndata_all = drop_redundant(data_all)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"0378c662d1931d66c078554cc2e5c04f51a2c921","collapsed":true},"cell_type":"code","source":"fe_feats = [ff for ff in data_all.columns if ff.startswith('fe_')]\nagg_feats = [ff for ff in data_all.columns if ff.startswith('agg')]\nbasic_feats = ['dependency']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5102c1950362888715fb69b1f7edf1a7cfa75f82"},"cell_type":"markdown","source":"# Pruning non-important features \nBased on feature importance plot in the previous notebook, the following seem non-important:\n* ratio of adults with postgraduate education level (`...instlevel9`)\n* ratio of adult brother/sister (`...parentesco9`)\n* ratio of son/daughter-in-law (`...parentesco5`)\n\nLet us drop these first and see if any improvements. These are included in `agg_feats`"},{"metadata":{"_uuid":"99fde38a9b1c354a689a1c61ab5e410692a72146"},"cell_type":"markdown","source":"After removing the three features, my rank was increased by 2 :). That's why I continue to drop more."},{"metadata":{"trusted":true,"_uuid":"7e323d8f6dce4cf29f4cf442de46ceebc598de22"},"cell_type":"code","source":"too_high_edu_levels = [ff for ff in agg_feats if ('instlevel9' in ff) or ('instlevel8' in ff)]\nirrelevant_members = [ff for ff in agg_feats if ('parentesco9' in ff) or ('parentesco5' in ff)\n                     or ('parentesco11' in ff) or ('parentesco6' in ff)]\n\nto_drop = too_high_edu_levels + irrelevant_members\nto_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"c9e68cf549ab667130bf80430b966e231838810b"},"cell_type":"code","source":"for ff in to_drop:\n        agg_feats.remove(ff)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"139c1c830a21f004fc806b62c93498655ba625bb"},"cell_type":"markdown","source":"## Add data of household head"},{"metadata":{"trusted":true,"_uuid":"3acbda75025de7fbece277e8f8d029b88b03a518","scrolled":true,"collapsed":true},"cell_type":"code","source":"is_head = (data_all.parentesco1 == 1)\nhead_df = data_all.loc[is_head, :]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"908118240f0ae97d7a6e304a61c1af0f22b0e060","collapsed":true},"cell_type":"code","source":"# gender\nhead_df.loc[head_df['male'] == 1, 'head_gender'] = 'male'\nhead_df.loc[head_df['female'] == 1, 'head_gender'] = 'female'\n\n# one-hot encode head gender\nhead_df = onehot_encode('head_gender', head_df)\nhead_gender_feats = [cc for cc in head_df.columns if 'head_gender' in cc]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3d310099dc1e72d2e297df201543b9d242ec9d3","collapsed":true},"cell_type":"code","source":"# edu level\n# convert binary edu levels to numeric values\nfor i in range(1, 10):\n    head_df.loc[head_df['instlevel{}'.format(i)] == 1, 'head_edu_level'] = i\n    \nhead_df = head_df.rename(columns={'escolari': 'head_school_years'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03099cb4a6262c21ec1506d6e7e01444958d3336","collapsed":true},"cell_type":"code","source":"# merge gender and edu data\ncols = ['idhogar', 'head_school_years', 'head_edu_level'] + head_gender_feats\ndata_all = pd.merge(data_all, head_df[cols], how='left', on='idhogar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"953d37ff63a3b0928f86df3b2139f0e007d6d2dd","collapsed":true},"cell_type":"code","source":"house_head_feats = ['head_school_years', 'head_edu_level'] + head_gender_feats","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"5a95cf4617a970d14da265264c8128a95a67652a","collapsed":true},"cell_type":"code","source":"# wall/roof/floor quality\ndata_all = add_quality(data_all, componente='pared', component='wall')\ndata_all = add_quality(data_all, componente='techo', component='roof')\ndata_all = add_quality(data_all, componente='viv', component='floor')\nprint(data_all.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8ef81faff82664f990fda9ed5ad3878a3ee54f8b"},"cell_type":"code","source":"# House material\n# rename material columns\n# wall\ntranslate = {'blolad': 'block',\n             'zocalo': 'socket',\n             'preb': 'cement',\n             'des': 'waste',\n             'mad': 'wood',\n             'zinc': 'zink',\n             'fibras': 'natural_fibers',\n             'other': 'other'}\ndata_all = to_english(data_all, sp_pre='pared', eng_pre='wall_', \n                   translate=translate)\nwall_feats = [cc for cc in data_all.columns if 'wall_' in cc]\n\n# floor\ntranslate = { \n    'moscer': 'mosaic',\n    'cemento': 'cement',\n    'other': 'other',\n    'natur': 'natural',\n    'notiene': 'no_floor',\n    'madera': 'wood'\n}\ndata_all = to_english(data_all, sp_pre='piso', eng_pre='floor_', translate=translate)\nfloor_feats = [cc for cc in data_all.columns if 'floor_' in cc]\n\n# roof\ntranslate = {\n     'zinc': 'zinc',\n     'entrepiso': 'fiber cement',\n     'cane': 'natural fibers',\n     'otro': 'other'\n}\ndata_all = to_english(data_all, sp_pre='techo', eng_pre='roof_', translate=translate)\nroof_feats = [cc for cc in data_all.columns if 'roof_' in cc]\n\nmaterial_feats = roof_feats + wall_feats + floor_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8a5bee4cd2b06aaccf32dcdeece2bedb2f1cd816"},"cell_type":"code","source":"# Facility\n# water\ntranslate = {\n    'guadentro': 'inside_house',\n    'guafuera': 'outside_house',\n    'guano': 'no'\n}\ndata_all = to_english(data_all, sp_pre='abasta', eng_pre='water_provision_', \n                   translate=translate)\nwater_feats = [cc for cc in data_all.columns if 'water_provision_' in cc]\n\n# electricity\ntranslate = {\n    'public': 'public',\n    'planpri': 'private_plan',\n    'noelec': 'no',\n    'coopele': 'cooperate'\n}\ndata_all = to_english(data_all, sp_pre='', eng_pre='electric_', translate=translate)\nelec_feats = [cc for cc in data_all.columns if 'electric_' in cc]\n\n# energy\ntranslate = {\n    'cinar1': 'no',\n    'cinar2': 'electricity',\n    'cinar3': 'gas',\n    'cinar4': 'charcoal'\n}\ndata_all = to_english(data_all, sp_pre='energco', eng_pre='energy_', translate=translate)\nenergy_feats = [cc for cc in data_all.columns if 'energy_' in cc]\n\n# toilet\ntranslate = {\n    '1': 'no',\n    '2': 'sewer',\n    '3': 'septic_tank',\n    '5': 'black hole',\n    '6': 'other'\n}\ndata_all = to_english(data_all, sp_pre='sanitario', eng_pre='toilet_', translate=translate)\ntoilet_feats = [cc for cc in data_all.columns if 'toilet_' in cc]\n\n# rubbish\ntranslate = {\n    '1': 'tanker truck',\n    '2': 'buried',\n    '3': 'burning',\n    '4': 'throw empty place',\n    '5': 'throw to river',\n    '6': 'other'\n}\ndata_all = to_english(data_all, sp_pre='elimbasu', eng_pre='rubbish_', translate=translate)\nrubbish_feats = [cc for cc in data_all.columns if 'rubbish_' in cc]\n\nfacility_feats = water_feats + elec_feats + energy_feats + toilet_feats + rubbish_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b48655724c7e5ba8d5f7121a830c6809f610bb65"},"cell_type":"code","source":"# Renting or owning a house\ntranslate = {\n    '1': 'own_fully_paid',\n    '2': 'own_pay_installment',\n    '3': 'rented',\n    '4': 'precarious',\n    '5': 'other'\n}\ndata_all = to_english(data_all, sp_pre='tipovivi', eng_pre='living_type_', \n                      translate=translate)\n\nlive_feats = [cc for cc in data_all.columns if 'living_type_' in cc]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5db7e330ac23f73e8a51efe01b599ee8722c63cb"},"cell_type":"markdown","source":"# Light gbm\nAs scoring strategy is based only on predictions for household heads, moreover as pointed out in this [discussion](https://www.kaggle.com/c/costa-rican-household-poverty-prediction/discussion/61403#360115), only labels by household heads are guaranteed to be correct, we should only use rows of household heads for training and prediction."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d477548bb42b311b6a1f0aa2563db88d6d01f32e"},"cell_type":"code","source":"head_df = data_all.query('parentesco1 == 1')\ntrain = head_df.loc[head_df['Target'].notnull(), :]\ntest = head_df.loc[head_df['Target'].isnull(), :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e3ba4a98271f55b3bb4c3e4695725a31d4e4d3b2","collapsed":true},"cell_type":"code","source":"# features to be used\nfeatures = basic_feats + house_head_feats + material_feats + facility_feats + live_feats + fe_feats + agg_feats\nprint('# features: {}'.format(len(features)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6c6298079955ce7bf2f6156973fae20936e2cfa4"},"cell_type":"code","source":"# use a validation set to check how the trained model perform\nX, y = train[['idhogar', 'Id'] + features], train['Target']\nX_train, X_valid, y_train, y_valid = train_test_split(X[features], y, \n                                                      test_size=0.1, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bf3908eb046b9f9a8b0e8f14ee04544b0511fb26"},"cell_type":"code","source":"import lightgbm as lgb\n\ngbm = lgb.LGBMClassifier(n_jobs=4, random_state=0, class_weight='balanced')\nparam_grid = {'num_leaves': np.arange(10, 50, 10), \n              'learning_rate': np.arange(0.05, 0.2, 0.05),\n             'n_estimators': np.arange(10, 50, 5)}\nscoring = {'f1_macro': get_scorer('f1_macro')}\nmetric = 'f1_macro'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"aec33bc61b1ffe1b0535a7793919da57c6c7d2a3","collapsed":true},"cell_type":"code","source":"# train and param tuning\ngs = GridSearchCV(gbm,\n                  param_grid=param_grid,\n                  scoring=scoring,\n                  cv=5,\n                  refit=metric,\n                  verbose=True,\n                 n_jobs=4,\n                 )\ngs.fit(X_train, y_train)\n\nbest_estimator = gs.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73f3fe65e2b596d6db8d93f22f36cab425404116","collapsed":true},"cell_type":"code","source":"# check perf of trained model on validaton set\ny_pred = best_estimator.predict(X_valid)\nmacro_f1 = f1_score(y_valid, y_pred, average='macro')\nprint(macro_f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"70512930acf199e9bab17cb2e16a0ecb350c9581"},"cell_type":"code","source":"# predict\nX_test = test[['Id', 'idhogar'] + features]\ny_pred = best_estimator.predict(X_test[features])\npred_for_heads = pd.DataFrame({'Id': X_test['Id'], 'idhogar': X_test['idhogar'], \n                              'Target': y_pred})\npred_for_heads['Target'] = pred_for_heads['Target'].apply(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ef4fd8103adbc43291c1c841f419cd3803b9696","collapsed":true},"cell_type":"code","source":"pred_for_heads['Target'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"914defc4bd6683de2b6101795f75680ead7cbed1","collapsed":true},"cell_type":"code","source":"#merge back to include other rows into submission\ntest_all = data_all.loc[data_all['Target'].isnull(), ['Id', 'idhogar']]\nsubmit = pd.merge(test_all, pred_for_heads[['idhogar', 'Target']], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5a802ec8586caa8052f09c8c43fb9106fc85993b","scrolled":true,"collapsed":true},"cell_type":"code","source":"submit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3550f94df09be6537b91c30f294ace5238371568","collapsed":true},"cell_type":"code","source":"sum(submit['Target'].isnull())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba65eddbfe57fcb93d6e38d918e0e1f7eb377a2c"},"cell_type":"markdown","source":"`Target` become float as there are some null values, perhaps due to some households with no head. Let just fill the null values and cast `Target` to int."},{"metadata":{"trusted":true,"_uuid":"850357bd40b8b534703f9bd757a7cd993a5f7195","collapsed":true},"cell_type":"code","source":"submit.fillna(1, inplace=True)\nsubmit['Target'] = submit['Target'].astype(np.int16)\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b90eba13986e5c2f6a504a9bf1b2a6f85d3ab75e","collapsed":true},"cell_type":"code","source":"submit[['Id', 'Target']].to_csv('submisssion.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"dba4e057dfbada35967308230591327567211697","collapsed":true},"cell_type":"code","source":"lgb.plot_importance(best_estimator, figsize=(15, 15), grid=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28fb7909fe4ef4e3ff929dad5c70c625b3554c17"},"cell_type":"markdown","source":"The important features are:\n* min/mean/max school years of adult members\n* dependency rate\n* mobile/bed/human densities\n* min/avg/max age of adult members\n* kid ratio\n*  working man ratio\n*  floor/wall/roof quality\n* ratios of instilevels 3,4,5 (which are complete primary, incomplete secondary and complete secondary)\n* ratios of `estadocivil` 7, 5, 3 (marriage status: single, separated and married)"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"5c1ba86ba2fc3abaac3fa479a74a5e48babefe9f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}