{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["**Data Description**\n", "\n", "You are provided with a large number of Wikipedia comments which have been labeled by human raters for toxic behavior. The types of toxicity are:\n", "\n", "    toxic\n", "    severe_toxic\n", "    obscene\n", "    threat\n", "    insult\n", "    identity_hate\n", "\n", "You must create a model which predicts a probability of each type of toxicity for each comment.\n", "\n", "**File descriptions**\n", "\n", "    train.csv - the training set, contains comments with their binary labels\n", "    test.csv - the test set, you must predict the toxicity probabilities for these comments. To deter hand labeling, the test set contains some comments which are not included in scoring.\n", "    sample_submission.csv - a sample submission file in the correct format\n", "    "]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"_uuid": "918b78bf67a06cea1727671184be3a401a67a08f", "_cell_guid": "d7b8c968-336f-48c0-abbd-678e987e52e4"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["df_train = pd.read_csv('../input/train.csv')\n", "df_test = pd.read_csv('../input/test.csv')\n", "submission = pd.read_csv('../input/sample_submission.csv')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print('DataFrame Train:')\n", "print(df_train.isnull().any())\n", "print('\\n')\n", "print('DataFrame Test:')\n", "print(df_test.isnull().any())"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["df_test = df_test.fillna('unknown')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["col = np.array(df_train.columns)\n", "col = col[2:]\n", "print(col)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["print('Dataframe Train:')\n", "for c in col:\n", "    print(\"The dataframe has '{1}' of comments '{0}' of the total '{2}'.\".format(c, \n", "                                                                                 df_train[c].sum(), \n", "                                                                                 len(df_train)))"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["comment_text_all = pd.concat([df_train['comment_text'], df_test['comment_text']],axis=0)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["nrow_train = df_train.shape[0]\n", "print(nrow_train)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.feature_extraction.text import TfidfVectorizer\n", "vectorizer = TfidfVectorizer(stop_words='english', strip_accents='unicode')"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["train_test_comment_text = vectorizer.fit_transform(comment_text_all)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["from sklearn.linear_model import LogisticRegression\n", "from sklearn.metrics import log_loss\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["y = df_train[col]\n", "y.head(5)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["predict = np.zeros((df_test.shape[0], len(col)))\n", "predict.shape"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}, "source": ["loss = []\n", "accuracy = []\n", "for num, index in enumerate(col):\n", "    x_train, x_test, y_train, y_test = train_test_split(train_test_comment_text[:nrow_train], y[index])\n", "    print(\"Fit: {}\".format(index))\n", "    model = LogisticRegression(C=5)\n", "    model.fit(x_train, y_train)\n", "    predict[:,num] = model.predict_proba(train_test_comment_text[nrow_train:])[:,1]    \n", "    predict_01 = model.predict_proba(x_test)[:,1]    \n", "    logloss = log_loss(y_test, predict_01)\n", "    print('log loss:', logloss)\n", "    predict_02 = model.predict(x_test)\n", "    acc = np.mean(predict_02 == y_test)\n", "    print('accuracy:', acc)\n", "    loss.append(logloss)\n", "    accuracy.append(acc)\n", "    print('\\n')\n", "print('mean column-wise log loss:', np.mean(loss))\n", "print('mean column-wise accuracy:', np.mean(accuracy))"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": ["submid = pd.DataFrame({'id': submission[\"id\"]})\n", "submission = pd.concat([submid, pd.DataFrame(predict, columns = col)], axis=1)\n", "submission.to_csv('submission.csv', index=False)"]}, {"cell_type": "code", "execution_count": null, "outputs": [], "metadata": {"collapsed": true}, "source": []}], "metadata": {"language_info": {"nbconvert_exporter": "python", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "version": "3.6.3"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat_minor": 1, "nbformat": 4}