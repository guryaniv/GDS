{"nbformat": 4, "metadata": {"kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}, "language_info": {"name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python"}}, "cells": [{"execution_count": null, "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "metadata": {"_cell_guid": "cfbf374a-2cee-43de-9962-f212cbca3c7a", "_uuid": "2efa72d88ee6514d4b71eef0dd98b7f4971d6c34"}, "outputs": []}, {"cell_type": "markdown", "source": ["This isn't very well suited for a kernel, but I found this code to be very useful.  Basically it helps separate train into train and valid and puts each into a volder.  The other change I would make is instead of unzipping everything first, I could unzip the files similar to making the directories so there would be no touching required.  "], "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": ["#point this to your data path where you download your data\n", "path = \"../input/\"\n", "\n", "#taken from https://www.kaggle.com/orangutan/keras-vgg19-starter\n", "df_train = pd.read_csv(path+\"labels.csv\")\n", "df_test = pd.read_csv(path+\"sample_submission.csv\")\n", "targets_series = pd.Series(df_train['breed'])\n", "one_hot = pd.get_dummies(targets_series, sparse=True)"], "metadata": {}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["!mkdir {path+\"valid\"}"], "metadata": {}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["#creates all of the directories you will need\n", "for i in range(targets_series.unique().shape[0]):\n", "    !mkdir {path+\"train/\"+targets_series.unique()[i]}/\n", "    !mkdir {path+\"valid/\"+targets_series.unique()[i]}/"], "metadata": {}, "outputs": []}, {"execution_count": null, "cell_type": "code", "source": ["#Change valid percent to how many of your files you want in a validation set\n", "valid_percent = 20\n", "for i in range(df_train.shape[0]):\n", "    if i%100>=valid_percent:\n", "        !mv {path+\"train/\"+df_train[\"id\"][i]+\".jpg\"} {path+\"train/\"+df_train[\"breed\"][i]+\"/\"}\n", "    else:\n", "        !mv {path+\"train/\"+df_train[\"id\"][i]+\".jpg\"} {path+\"valid/\"+df_train[\"breed\"][i]+\"/\"}\n", "    if i%1000==0:\n", "        print(i)"], "metadata": {"collapsed": true}, "outputs": []}], "nbformat_minor": 1}