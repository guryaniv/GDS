{"metadata": {"language_info": {"version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_cell_guid": "22da3c72-5fb5-476f-9792-7603ae7f3c9c", "_uuid": "74693ffeeb25a3959117ab9399d6bb2c9ef7d803"}, "cell_type": "markdown", "source": ["## **Logistic Regression with term document matrix**##"]}, {"execution_count": null, "metadata": {"_cell_guid": "eb49860f-b3b6-4bf4-8955-ecc0c6d94d7b", "collapsed": true, "_uuid": "54a00db060c97da83795bc7e550e2be607dc2e98"}, "outputs": [], "cell_type": "code", "source": ["import pandas as pd\n", "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n", "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n", "from pandas.api.types import is_string_dtype, is_numeric_dtype\n", "import numpy as np\n", "from sklearn import metrics\n", "import matplotlib.pyplot as plt\n", "from sklearn.linear_model import LogisticRegression\n", "from IPython.display import Image\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.feature_extraction import stop_words\n", "from sklearn.metrics import log_loss\n", "import re\n", "import string"]}, {"execution_count": null, "metadata": {"_cell_guid": "2692f6b5-aff5-4bce-84c3-67ba6c8b845c", "collapsed": true, "_uuid": "866a0964c72f6308bd1d6e258f556f24c4c22360"}, "outputs": [], "cell_type": "code", "source": ["df_raw = pd.read_csv('../input/train.csv', low_memory=False)"]}, {"metadata": {"_cell_guid": "fa6d829f-c006-4fa6-9240-bef4d7e56dd0", "_uuid": "2e7b2eafc1a145c79cfb01187dee54aec4bf1940"}, "cell_type": "markdown", "source": ["Drop missing values "]}, {"execution_count": null, "metadata": {"_cell_guid": "0463d978-e486-44fd-b960-30165bb166f9", "collapsed": true, "_uuid": "3ea6639953c733cd7c05c8e62413797d9cd0c5c9"}, "outputs": [], "cell_type": "code", "source": ["df_raw = df_raw.dropna()"]}, {"execution_count": null, "metadata": {"_cell_guid": "871dafc2-f583-4301-89fb-f0cae7e6ac3d", "collapsed": true, "_uuid": "9ae715ac990a1a658e9a6bb66052669905a23050"}, "outputs": [], "cell_type": "code", "source": ["df_raw.shape"]}, {"execution_count": null, "metadata": {"_cell_guid": "c95cd314-6669-41f9-93b1-b4d8e4838c38", "collapsed": true, "_uuid": "25d118b6212522316ddac23bef468def7000e957"}, "outputs": [], "cell_type": "code", "source": ["df_raw[:5]"]}, {"metadata": {"_cell_guid": "acd059a6-aec0-4f22-a963-6b8e30526436", "_uuid": "38fb4c68bf35910d0d0f89d4de8fd434e7d82e8e"}, "cell_type": "markdown", "source": ["The data set has following columns:\n", "- id: the id of a set question pair.\n", "- qid1, qid2: unique ids of each question\n", "- question1, question2 - the full text of each question\n", "- is_duplicate - the target variable, set to 1 if question1 and question2 have essentially the same meaning, and 0 otherwise."]}, {"metadata": {"_cell_guid": "e102e72d-84ff-436d-bfe5-85d2a07e397a", "_uuid": "5460260e01f21fba14ed1a7090ddfe3474c7a50f"}, "cell_type": "markdown", "source": ["The submission are evaluated on the log loss between the predicted values and the ground truth as follows:\n", "\n", "- log-loss = (-1/N)sum(yi log(pi) + (1-yi) log(1-pi))"]}, {"metadata": {"_cell_guid": "5c846321-016e-4bbd-9901-65d368412661", "_uuid": "3791fbf75d2a9a40cd404560438e95d97dff5a41"}, "cell_type": "markdown", "source": ["## Data Preprocessing"]}, {"metadata": {"_cell_guid": "e08c1da8-a295-44f6-8cf3-be004286894d", "_uuid": "91580e68ee1b9bedc5379f0dc58268a7320cf1f0"}, "cell_type": "markdown", "source": ["Define a tokenizer"]}, {"execution_count": null, "metadata": {"_cell_guid": "d18f52ab-54af-41f5-9e8c-1d973b64c980", "collapsed": true, "_uuid": "90af58fc26499a5895760e0f2e9e8a3b2965a409"}, "outputs": [], "cell_type": "code", "source": ["def tokenizer(s): \n", "    re_tok = re.compile(f'([{string.punctuation}\u201c\u201d\u00a8\u00ab\u00bb\u00ae\u00b4\u00b7\u00ba\u00bd\u00be\u00bf\u00a1\u00a7\u00a3\u20a4\u2018\u2019])')\n", "    words = re_tok.sub(r' \\1 ', s).split()\n", "    words = [w.lower() for w in words]\n", "    words = [w.strip() for w in words]\n", "    words = [w for w in words if len(w) >= 3]\n", "    words = [w for w in words if w not in stop_words.ENGLISH_STOP_WORDS]\n", "    return words"]}, {"execution_count": null, "metadata": {"_cell_guid": "3b89dcea-66aa-4dd5-8185-8bd087b1bbfc", "collapsed": true, "_uuid": "541d50bbea34f1f00dea40da55f8f84adb0eb4f8"}, "outputs": [], "cell_type": "code", "source": ["veczr = CountVectorizer(tokenizer=tokenizer, binary=True,ngram_range=(1,3))"]}, {"execution_count": null, "metadata": {"_cell_guid": "b0743c2c-bc8f-4d94-8e7c-050b4a213a36", "collapsed": true, "_uuid": "374672ce3cbb38ec102e29e7393ad57fc8aa4ef2"}, "outputs": [], "cell_type": "code", "source": ["# drop un-used columns\n", "df_raw = df_raw.drop([\"id\",\"qid1\",\"qid2\"],axis=1)"]}, {"execution_count": null, "metadata": {"_cell_guid": "4935de5a-24de-4185-bb05-34361007fc90", "collapsed": true, "_uuid": "eb4b133123423fd95a947188a23cdca0bcec3215"}, "outputs": [], "cell_type": "code", "source": ["# train-validation split\n", "X_train, X_val, y_train, y_val = train_test_split(df_raw.drop(\"is_duplicate\",axis=1), df_raw[\"is_duplicate\"], \\\n", "                                                  test_size = 0.2, random_state = 99)\n", "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n", "y_val = y_val.apply(lambda x: x).tolist()\n", "y_train = y_train.apply(lambda x: x).tolist()"]}, {"execution_count": null, "metadata": {"_cell_guid": "8c8ed0ed-bff8-4906-9a09-ff8cf109238c", "collapsed": true, "_uuid": "5042fe4fdfa68d5a0607424e708660aa11542c23"}, "outputs": [], "cell_type": "code", "source": ["# Based on train set, combine q1 + q2, and build a term-doc matrix\n", "train_list1 = X_train['question1'].apply(lambda x: x).tolist()\n", "train_list2 = X_train['question2'].apply(lambda x: x).tolist()\n", "train_list = []\n", "for i in range(len(train_list1)):\n", "    train_list.append(train_list1[i] + \" \" + train_list2[i])"]}, {"execution_count": null, "metadata": {"_cell_guid": "f7d5665f-dbee-45ae-b2bb-e82fde9742ba", "collapsed": true, "_uuid": "74385f61ceebeb7738644b4207e4cf86fe5e788c"}, "outputs": [], "cell_type": "code", "source": ["# fit a term-doc matrix, which will be used later\n", "trn_term_doc = veczr.fit_transform(train_list)"]}, {"execution_count": null, "metadata": {"_cell_guid": "599a37b1-18a7-4544-9821-3a8ac675aed2", "collapsed": true, "_uuid": "cb270c41a8a717ee88bcea393ca67394a0b21575"}, "outputs": [], "cell_type": "code", "source": ["# transform training data, based on question1 and question2\n", "train_term_doc1 = veczr.transform(X_train['question1'].apply(lambda x: x).tolist())\n", "train_term_doc2 = veczr.transform(X_train['question2'].apply(lambda x: x).tolist())"]}, {"execution_count": null, "metadata": {"_cell_guid": "116ef14e-63ef-4d46-9bfe-0628ca0677e1", "collapsed": true, "_uuid": "aabfbacab3a75fa6d06597fcb59696f9ee1cf836"}, "outputs": [], "cell_type": "code", "source": ["# if the word doesn't exist: 0\n", "# if the word appears in one question: 1\n", "# if the word appears in both questions: 2 \n", "x = train_term_doc1 + train_term_doc2\n", "y = y_train"]}, {"execution_count": null, "metadata": {"_cell_guid": "7b74e7e8-5603-4696-aa44-c4cf1f91a912", "collapsed": true, "_uuid": "7315b46c7042890fce07f841b8c21cbcee58e2dd"}, "outputs": [], "cell_type": "code", "source": ["val_term_doc1 = veczr.transform(X_val['question1'].apply(lambda x: x).tolist())\n", "val_term_doc2 = veczr.transform(X_val['question2'].apply(lambda x: x).tolist())"]}, {"execution_count": null, "metadata": {"_cell_guid": "8893138f-7bd7-45d2-b86d-040e3c4e2ff2", "collapsed": true, "_uuid": "1b7b6dad1fc6bc19dfb4593b3018d8e5499d5552"}, "outputs": [], "cell_type": "code", "source": ["m = LogisticRegression(C=0.4, dual=True)\n", "m.fit(x, y)\n", "preds_train = m.predict(train_term_doc1 + train_term_doc2)\n", "preds_prob_train = m.predict_proba(train_term_doc1 + train_term_doc2)\n", "preds_val = m.predict(val_term_doc1 + val_term_doc2)\n", "preds_prob_val = m.predict_proba(val_term_doc1 + val_term_doc2)\n", "print(\"Accuracy of training : \", (preds_train == y_train).mean())\n", "print(\"Log-loss of training : \", log_loss(y_train, preds_prob_train))\n", "print(\"Accuracy of validation : \", (preds_val == y_val).mean())\n", "print(\"Log-loss of validation : \", log_loss(y_val, preds_prob_val))"]}, {"execution_count": null, "metadata": {"_cell_guid": "290495a3-5496-4717-9ae9-454b3b0eafe6", "collapsed": true, "_uuid": "87b812eb038fd068227a4aec4e406efb62867d36"}, "outputs": [], "cell_type": "code", "source": []}], "nbformat": 4}