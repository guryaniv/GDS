{"cells":[{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport os\nimport time\n#print(os.listdir(\"../input\"))","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"7de9d75d-832f-47af-a156-8b821716351b","_uuid":"16ca5f508de2eb207f10528cb2211843ff75370b","trusted":true},"cell_type":"code","source":"from keras.layers import Input\nfrom keras import layers\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers import ZeroPadding2D\nfrom keras.layers import AveragePooling2D\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers import BatchNormalization\nfrom keras.models import Model\nfrom keras.layers import Dropout\nfrom keras.preprocessing import image\nimport keras.backend as K\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import decode_predictions\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.applications.imagenet_utils import _obtain_input_shape\nfrom keras.engine.topology import get_source_inputs","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6b754e06-ae58-46cb-a674-9b6bfea0abe5","_uuid":"979bb1586c6fb0b9648f528a07d9fa202a017380","trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/dogs-vs-cats-redux-kernels-edition/train/'\nTEST_DIR = '../input/dogs-vs-cats-redux-kernels-edition/test/'\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntest_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\ntest_id = np.array([int(i[i.find('test/')+5:-4]) for i in test_images],ndmin=2).T","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a00fe3e4-d950-47e8-ae6f-976c9c34d3a6","_uuid":"d5267c06a1a4ba28301d8a6d5c67e878745de39f","trusted":true},"cell_type":"code","source":"def read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR) # read img into color mode\n    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n    img = img-np.array([123.68, 116.779, 103.939]).reshape((1,1,3))\n    return img \ndef prep_data(images):\n    labels = []\n    count = len(images)\n    data = np.ndarray((count, 224, 224,3), dtype=np.float32)\n    for i, image_file in enumerate(images):\n        image = read_image(image_file)\n        data[i] = image\n        if image_file[image_file.find('train/')+6:image_file.find('train/')+9] =='dog':\n            labels.append(1)\n        else:\n            labels.append(0)\n    return data, labels","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"93be043b-08dc-44f3-a058-f217f6ffa946","_uuid":"71fbfd2a3a7833314ff4115bb2b9a0b41542bef1","trusted":true},"cell_type":"code","source":"trainset = train_images[15000:17000]\nvalidationset = train_images[17000:17800]\ntrain, train_labels = prep_data(trainset)\nvalidation, val_labels= prep_data(validationset)","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f4ff1417-2d95-4e3a-b7f6-70ea890e68db","_uuid":"7407f3d4a87c1f81ed51f7a8b0c72d5bc4df890d","trusted":false},"cell_type":"code","source":"def identity_block(input_tensor, kernel_size, filters, stage, block):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size,\n               padding='same', name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    x = layers.add([x, input_tensor])\n    x = Activation('relu')(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f6ba1b0b-047a-400e-99d8-d15a2ed6fd2f","_uuid":"8bb4b565ae8cd980c9e241e7976d5966cf938a6e","trusted":false},"cell_type":"code","source":"def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n    filters1, filters2, filters3 = filters\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n    conv_name_base = 'res' + str(stage) + block + '_branch'\n    bn_name_base = 'bn' + str(stage) + block + '_branch'\n\n    x = Conv2D(filters1, (1, 1), strides=strides,name=conv_name_base + '2a')(input_tensor)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters2, kernel_size, padding='same',name=conv_name_base + '2b')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n    x = Activation('relu')(x)\n\n    x = Conv2D(filters3, (1, 1), name=conv_name_base + '2c')(x)\n    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n\n    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n                      name=conv_name_base + '1')(input_tensor)\n    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n\n    x = layers.add([x, shortcut])\n    x = Activation('relu')(x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4004de6d-6680-4ca7-9598-596a8b53b55c","_uuid":"8cc175ceff5f0a93aa8f5900fcf5a1bc72a5b131","trusted":false},"cell_type":"code","source":"def ResNet50(include_top=True, weights=None,input_tensor=None, input_shape=None,pooling=None,classes=1000):\n    input_shape = _obtain_input_shape(input_shape,default_size=224,min_size=197,data_format=K.image_data_format(),\n                                      require_flatten=include_top)\n    if input_tensor is None:\n        img_input = Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            img_input = Input(tensor=input_tensor, shape=input_shape)\n        else:\n            img_input = input_tensor\n    if K.image_data_format() == 'channels_last':\n        bn_axis = 3\n    else:\n        bn_axis = 1\n\n    x = ZeroPadding2D((3, 3))(img_input)\n    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n    x = BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n    x = Activation('relu')(x)\n    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n\n    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n\n    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n\n    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n\n    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n\n    x = AveragePooling2D((7, 7), name='avg_pool')(x)\n\n    if include_top:\n        x = Flatten()(x)\n        x = Dense(classes,kernel_initializer='lecun_normal' ,activation='softmax', name='fc1000')(x)\n    else:\n        if pooling == 'avg':\n            x = GlobalAveragePooling2D()(x)\n        elif pooling == 'max':\n            x = GlobalMaxPooling2D()(x)\n\n    if input_tensor is not None:\n        inputs = get_source_inputs(input_tensor)\n    else:\n        inputs = img_input\n    model = Model(inputs, x, name='resnet50')\n\n    # load weights\n    if weights == 'imagenet':\n        if include_top:\n            weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n        else:\n            weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        model.load_weights(weights_path)\n        if K.backend() == 'theano':\n            layer_utils.convert_all_kernels_in_model(model)\n\n        if K.image_data_format() == 'channels_first':\n            if include_top:\n                maxpool = model.get_layer(name='avg_pool')\n                shape = maxpool.output_shape[1:]\n                dense = model.get_layer(name='fc1000')\n                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"24714daa-f82e-426d-b1b4-a1f3a6ff1498","_uuid":"30245ae4e33a1b39fc747c00c9d414717e09ecff","trusted":false},"cell_type":"code","source":"image_input = Input(shape=(224, 224, 3))\nmodel = ResNet50(input_tensor=image_input, include_top=False,weights='imagenet')\n#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4d5ea13b-6f6b-4d8f-8ede-756caa51dc51","_uuid":"70cc76859c36795a24b63b2b3b73a11cdcf0fc8e","trusted":false},"cell_type":"code","source":"last_layer = model.output\nx = GlobalAveragePooling2D()(last_layer)\nx = Dropout(0.1)(x)\nx = Dense(256, kernel_initializer='lecun_normal', activation='relu',name='fc-2')(x)\nx = Dropout(0.3)(x)\nout = Dense(1, activation='sigmoid',name='output_layer')(x)\ncustom_resnet_model = Model(inputs=model.input, outputs=out)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"34bb84d2-75a7-40a4-ad3e-12771cd4522d","_uuid":"554e702cdb31640957d8a0314c9c5e8e192a3f20","trusted":false},"cell_type":"code","source":"for layer in custom_resnet_model.layers[:-5]:\n    layer.trainable = False\ncustom_resnet_model.layers[-5].trainable\n#custom_resnet_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"51ea159e-99cd-4c5c-8086-8a434e4baf23","_uuid":"e19fbea2d3cef384da2dc83b3f97c41425922f69","trusted":false},"cell_type":"code","source":"datagen = image.ImageDataGenerator()\ntrain_generator = datagen.flow(train,train_labels,batch_size=32)\nval_generator = datagen.flow(validation,val_labels,batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"40baff06-1ff2-4200-8d40-ceed636f91a3","_uuid":"b5e2cc7f9a0804b2432a92e1b19d095912413d01","trusted":false},"cell_type":"code","source":"custom_resnet_model.compile(loss='binary_crossentropy',optimizer='RMSprop',metrics=['accuracy'])\ncustom_resnet_model.fit_generator(train_generator, steps_per_epoch=50,validation_data=val_generator, validation_steps=20,epochs=5, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"91c9ee5ccd2a84257679597c805de44c0f838c5b"},"cell_type":"code","source":"custom_resnet_model.save('dog_cat_round1.h')","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e9c74c45-3e77-4f64-abee-77c88777da6a","_uuid":"68f563bc4e870e1cc312c6862a4ce448e9cbbb5b","trusted":false},"cell_type":"code","source":"custom_resnet_model.fit_generator(train_generator, steps_per_epoch=50,validation_data=val_generator, validation_steps=20,epochs=5, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5560046a-ef06-4f21-aeb4-79bd25fb6c30","_uuid":"6f87410e148da337e6484b5bc8c13dd0521a6add","trusted":false},"cell_type":"code","source":"custom_resnet_model.save('dog_cat_round2.h')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}