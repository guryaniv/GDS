{"cells":[{"metadata":{"_uuid":"fe901ff681cddc496cd64515e52dbf8e122f3156"},"cell_type":"markdown","source":"**Earthquake Prediction Model using Laboratory Data**\n\nForecasting earthquakes is one of the most important problems in Earth science because of their devastating consequences. Current scientific studies related to earthquake forecasting focus on three key points: when the event will occur, where it will occur, and how large it will be.\n\nIn this notebook we will work on addressing when the earthquake will take place. \n*We will try to predict the time remaining before laboratory earthquakes occur from real-time seismic data.*\n\nPredicting earthquake can save billions of dollars in infrastructure **but above all a large number of human lives can be saved.**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n#print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77f294cbf8af080be7e17494a0e10feb9dda0c89"},"cell_type":"markdown","source":"**1)  Load the Data**"},{"metadata":{"trusted":true,"_uuid":"abb5999a25aa85d8b2e74fd58bb61703e7d87de9"},"cell_type":"code","source":"train=pd.read_csv(\"../input/train.csv\", nrows=6000000,dtype={'acoustic_data':np.int16,'time_to_failure':np.float64})\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**2) Exploratory Data Analysis**"},{"metadata":{"trusted":true,"_uuid":"f9dd16c2670b4cbdf1d66323364661bcd95063e1"},"cell_type":"code","source":"#Lets plot the data to see and understand the data columns and our problem .\n#We will use a small subset of dataset for understanding the pattern ,since the data is large\n\ntrain_acoustic_df = train['acoustic_data'].values[::100]\ntrain_time_to_failure_df = train['time_to_failure'].values[::100]\n\nfig, ax1 = plt.subplots(figsize=(10,10))\nplt.title('Acoustic data and Time to Failure')\nplt.plot(train_acoustic_df, color='r')\nax1.set_ylabel('acoustic data', color='r')\nplt.legend(['acoustic data'], loc=(0.01, 0.9))\n\nax2 = ax1.twinx()\nplt.plot(train_time_to_failure_df, color='b')\nax2.set_ylabel('time to failure', color='b')\nplt.legend(['time to failure'], loc=(0.01, 0.8))\n\nplt.grid(True)\n\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8fc8d36c7c3f33174502051a51a8c792d65158b1"},"cell_type":"markdown","source":"The size of Train data is large . The two columns in the train dataset have the following meaning:\n\n1. *accoustic_data*: is the accoustic signal measured in the laboratory experiment;\n2. *time to failure*: this gives the time until a failure will occurs.\n\n**The above plot shows that the failure occur after a large oscilation and also that the large oscilation is followed by a series of small minor oscilations before the final time of failure .**"},{"metadata":{"_uuid":"507a36e994d37355c1eb7cf9c678175c780255da"},"cell_type":"markdown","source":"**3) Feature Engineering**"},{"metadata":{"trusted":true,"_uuid":"28a3027f6fb89837e39603fbfd735f65ca553a85"},"cell_type":"code","source":"def gen_features(X):\n    fe = []\n    fe.append(X.mean())\n    fe.append(X.std())\n    fe.append(X.min())\n    fe.append(X.max())\n    fe.append(X.kurtosis())\n    fe.append(X.skew())\n    fe.append(np.quantile(X,0.01))\n    fe.append(np.quantile(X,0.05))\n    fe.append(np.quantile(X,0.95))\n    fe.append(np.quantile(X,0.99))\n    fe.append(np.abs(X).max())\n    fe.append(np.abs(X).mean())\n    fe.append(np.abs(X).std())\n    return pd.Series(fe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67bead1f345f4e0d7ba00eaca180cd1288c4d1e2"},"cell_type":"code","source":"#Lets read the training set again now in chunks and append features \ntrain = pd.read_csv('../input/train.csv', iterator=True, chunksize=150_000, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n\nX_train = pd.DataFrame()\ny_train = pd.Series()\nfor df in train:\n    ch = gen_features(df['acoustic_data'])\n    X_train = X_train.append(ch, ignore_index=True)\n    y_train = y_train.append(pd.Series(df['time_to_failure'].values[-1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d44a3d512c418f6f153e55e08b0540e57d3844d"},"cell_type":"code","source":"X_train.head(10) #Let's check the training dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"944d553964d53271258c0600feda97a9f2d34f53"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id') #Taking the segment id from sample_submission file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"088f4c6e264417744335aadd43261fe5e03358f2"},"cell_type":"code","source":"#Applying Feature Engineering on test data files\nX_test = pd.DataFrame()\nfor seg_id in submission.index:\n    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n    ch = gen_features(seg['acoustic_data'])\n    X_test = X_test.append(ch, ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c988dfdeecbe9a664ca36714fc81f0de2f69739"},"cell_type":"code","source":"X_test.head(10) #Lets check the testing dataframe","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d8334061301280543c97f3726ac076a8436f93e"},"cell_type":"markdown","source":"**4) Catboost Regressor ** *(optional)*"},{"metadata":{"trusted":true,"_uuid":"b4b48c7d8900f08f1dc20e502448c78dd9aa6da2"},"cell_type":"code","source":"#Catboost regressor model \n\"\"\"       \n#Catboost Regressor model\n\ntrain_pool = Pool(X_train, y_train)\n\nm = CatBoostRegressor(iterations=10000, loss_function='MAE', boosting_type='Ordered')\nm.fit(X_train, y_train, silent=True)\nm.best_score_\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"795fee21976a858379e633125a9c9e6ad05b856b"},"cell_type":"markdown","source":"**5) Scale the Data**"},{"metadata":{"trusted":true,"_uuid":"d94ef6f1a5907d22e777204613f33ad67a874e28"},"cell_type":"code","source":"#Scale Train Data\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = pd.DataFrame(scaler.transform(X_train))\nX_train_scaled.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"fe71939926a89e2befcb21ce2eb4ca9fe0afcbac"},"cell_type":"code","source":"#We will also scale the train data\nX_test_scaled = pd.DataFrame(scaler.transform(X_test))\nX_test_scaled.head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03aabcac7ce25a39b41ef8bb1c3a749c8e17ce9c"},"cell_type":"markdown","source":"**6) Support Vector Regression**"},{"metadata":{"_uuid":"e6fd7b552919f1363512c28a6db6daaf483281a4"},"cell_type":"markdown","source":"*We will be using the SVR model for prediction and GridSearchCV for hyperparameter tuning of the model.*"},{"metadata":{"trusted":true,"_uuid":"4d8623b2ffc95ba6595a896d480b8127a6c43c56"},"cell_type":"code","source":"parameters = [{'gamma': [0.001, 0.005, 0.01, 0.02, 0.05, 0.1],\n               'C': [0.1, 0.2, 0.25, 0.5, 1, 1.5, 2]}]\n\nreg1 = GridSearchCV(SVR(kernel='rbf', tol=0.01), parameters, cv=5, scoring='neg_mean_absolute_error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd966ba398d5ab712436fcea67b122df16de2906"},"cell_type":"code","source":"reg1.fit(X_train_scaled, y_train.values.flatten())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ac8eb3b319054b97e89847afd1ef4b790c35604"},"cell_type":"code","source":"submission.time_to_failure = reg1.predict(X_test_scaled) \nsubmission","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8dd59a967bf6794e1f4d3fc22f8ea7a3612e6726"},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true,"_uuid":"05a74a850b89feed63aaaa6d2d4d64d5936c38f6"},"cell_type":"code","source":"submission.to_csv('submission.csv',index=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5801be3faf32c805fc5c5f1e16c03067250364d8"},"cell_type":"markdown","source":"If you found this notebook helpful or you just liked it , some upvotes would be very much appreciated - That will keep me motivated .\n\nPlease drop down suggestions and comments if any, so that i can learn to build better solutions.\n\n**Thank You :-)**"},{"metadata":{"_uuid":"9f303ea35b0564405eadedd873873a375fe26aba"},"cell_type":"markdown","source":"**Let's Pray that this Year no major earthquake occurs and people remain safe.  **"},{"metadata":{"_uuid":"c99d3f9ef62b28a88965df8b91a443756446b329"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}