{"metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python"}}, "cells": [{"metadata": {"_cell_guid": "1ffb4d9e-f7f3-4f36-87ba-99401ecd22ce", "_uuid": "f0159bb523ed5c04fb2d6eb6c81c6808dbfb0b7c"}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "# Bullet Loan Analysis\n", "\n", "This is an analysis of the bullet loan data provided here https://www.kaggle.com/zhijinzhai/loandata\n", "\n", "We will perform some Exploratory Data Analysis and see if we can fit a model to predict loan repayment. We will compare Logistic Regressions to Random Forrest and Decision Trees.\n", "\n", "From the website we can obtain the context:\n", "\n", "\"This data set includes customers who have paid off their loans, who have been past due and put into collection without paying back their loan and interests, and who have paid off only after they were put in collection. The financial product is a bullet loan that customers should pay off all of their loan debt in just one time by the end of the term, instead of an installment schedule. Of course, they could pay off earlier than their pay schedule\"\n", "\n", "And the content of the data itself: \"Loan_id A unique loan number assigned to each loan customers\n", "\n", "Loan_status Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts\n", "\n", "Principal Basic principal loan amount at the origination\n", "\n", "terms Can be weekly (7 days), biweekly, and monthly payoff schedule\n", "\n", "Effective_date When the loan got originated and took effects\n", "\n", "Due_date Since it\u2019s one-time payoff schedule, each loan has one single due date\n", "\n", "Paidoff_time The actual time a customer pays off the loan\n", "\n", "Pastdue_days How many days a loan has been past due\"\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["import numpy as np\n", "import pandas as pd\n", "import seaborn as sns\n", "import matplotlib.pyplot as plt\n", "import datetime\n", "import os\n", "\n", "%matplotlib inline"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### EDA"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf=pd.read_csv('../input/Loan payments data.csv')"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf.head()"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf.info()"]}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "### EDA by columns\n", "#### 1.Loan_ID\n", "\n", "Loan_ID is just an identifier for each loan, and we will drop it from modeling\n", "#### 2. loan_status\n", "\n", "This our target variable. Explore the variable.\n"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf['loan_status'].unique()"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["sns.set_style('darkgrid')\n", "sns.countplot(loandf['loan_status'], palette='Spectral')"]}, {"metadata": {}, "cell_type": "markdown", "source": ["We can see that there is an approximate 3:1:1 ratio between paidoff, collection, and collection_paidoff\n", "#### 3.Principal -orginal loan amount"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf[['loan_status','Principal','Loan_ID']].groupby(['loan_status','Principal']).agg(['count'])"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["fig=plt.figure(figsize=(12,6))\n", "sns.distplot(loandf['Principal'], bins=40)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["we can see that most of the principal amount is at 1000 USD\n", "\n", "#### 4. Terms- payoff schedule"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["ax= sns.countplot(loandf['terms'], palette='Spectral')\n", "ax.set_title('Term Counts')"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["fig, ax=plt.subplots(figsize=(12,4))\n", "sns.countplot(x='terms', hue='loan_status', data=loandf, palette='Spectral')\n", "ax.set_title('Term counts by Loan Status')\n", "ax.legend(loc='upper left')\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf['Days to pay']= (pd.DatetimeIndex(loandf['paid_off_time']).normalize()\n", "                        -pd.DatetimeIndex(loandf['effective_date']).normalize())/np.timedelta64(1,'D')"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf['paid_off_date'] = pd.DatetimeIndex(loandf['paid_off_time']).normalize()"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["fig, ax=plt.subplots(figsize=(15,6))\n", "ax=sns.countplot(x='Days to pay',hue='terms',data=loandf)\n", "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["fig, ax=plt.subplots(figsize=(15,6))\n", "ax=sns.countplot(x='Days to pay', hue='terms', data=loandf[loandf['loan_status']== 'PAIDOFF'])\n", "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["tmp = loandf.loc[(loandf['Days to pay'] > 30) & (loandf['loan_status'] == 'PAIDOFF')]\n", "print(\"{}: Incorrect status: {} observations\")\n", "print(tmp[['loan_status', 'terms', 'effective_date', 'due_date', 'paid_off_time']])"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["## exploring demographic\n", "fig, axs=plt.subplots(3,2, figsize=(20,15))\n", "\n", "sns.distplot(loandf['age'], ax=axs[0][0])\n", "axs[0][0].set_title(\"Total age distribution across dataset\")\n", "\n", "sns.boxplot(x='loan_status', y='age', data=loandf, ax=axs[0][1])\n", "axs[0][1].set_title(\"Age distribution by loan status\")\n", "\n", "sns.countplot(x='education', data=loandf, ax=axs[1][0])\n", "axs[1][0].set_title(\"Education count\")\n", "\n", "\n", "sns.countplot(x='education', data=loandf, hue='loan_status', ax=axs[1][1])\n", "axs[1][1].set_title(\"Education by loan status\")\n", "axs[1][1].legend(loc='upper right')\n", "\n", "\n", "sns.countplot(x='Gender', data=loandf, ax=axs[2][0])\n", "axs[2][0].set_title(\" Gender\")\n", "\n", "sns.countplot(x='Gender', data=loandf, hue='education', ax=axs[2][1])\n", "axs[2][1].set_title(\"Education of the gender\")"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["## exploring gender +education \n", "pd.crosstab(loandf['loan_status'], loandf['Gender'] + \"_\" + loandf['education'], margins=True)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='all')"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='index')"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["pd.crosstab(loandf['loan_status'],loandf['Gender']+\"_\"+loandf['education'],margins=True,normalize='columns')"]}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "## Time to model!\n", "\n", "First lets fix the miseleading status loan records\n", "\n", "Second change the categorical and variable to numerical we will merge collections and collections_paid off because we are interseted in those who paid on time!\n", "\n", "We will convert education and gender to dummies\n", "\n", "We will then perform Random Forest SVM and keras.\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf.loc[(loandf['loan_status'] =='PAIDOFF' ) &(loandf['Days to pay']>30),'loan_status']='COLLECTION_PAIDOFF'"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["smap= {\"PAIDOFF\": 1, \"COLLECTION\": 2, \"COLLECTION_PAIDOFF\": 2 }\n", "loandf['loan_status_trgt'] = loandf['loan_status'].map(smap)\n", "\n", "fig, axs=plt.subplots(1,2,figsize=(12,5))\n", "\n", "sns.countplot(x='loan_status',data=loandf,ax=axs[0])\n", "axs[0].set_title('Count with original targets')\n", "\n", "sns.countplot(x='loan_status_trgt', data=loandf, ax=axs[1])\n", "axs[1].set_title('Count with new targets')"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["dummies=pd.get_dummies(loandf['education']).rename(columns=lambda x:'is_' +str(x))\n", "loandf=pd.concat([loandf,dummies],axis=1)\n", "loandf.drop(['education'],axis=1,inplace=True)\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["dummies=pd.get_dummies(loandf['Gender']).rename(columns=lambda x:'is_' +str(x))\n", "loandf=pd.concat([loandf,dummies],axis=1)\n", "loandf.drop(['Gender'],axis=1,inplace=True)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["loandf.drop(['Loan_ID', 'loan_status', 'effective_date', 'due_date',\n", "             'paid_off_time', 'past_due_days', 'paid_off_date', 'Days to pay'], axis=1,inplace=True)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["dummyvar=['is_female','is_Master or Above']\n", "loandf.drop(dummyvar,axis=1, inplace=True)"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["#create our inputs and target variable\n", "X=loandf.drop('loan_status_trgt',axis=1)\n", "y=loandf['loan_status_trgt']"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["#import ML libraries\n", "\n", "from sklearn.model_selection import train_test_split \n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn import svm"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["## funciton to evaluate our models\n", "\n", "def eval_model(model, data, target, splitratio):\n", "    trainX, testX, trainY, testY = train_test_split(data, target, train_size=splitratio, random_state=0)\n", "    model.fit(trainX,trainY)\n", "    return model.score(testX,testY)"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["import warnings\n", "warnings.filterwarnings(\"ignore\")\n", "\n", "num_estimator=np.array([1,5,10,50,100,250,500])\n", "num_sample=5\n", "num_grid=len(num_estimator)\n", "score_mean=np.zeros(num_grid)\n", "score_sigma=np.zeros(num_grid)\n", "j=0\n", "\n", "\n", "\n", "print(\"RandomForestClassification Starting\")\n", "for x in num_estimator:\n", "    score_array = np.zeros(num_sample) # Initialize\n", "    for i in range(0,num_sample):\n", "        rf_class = RandomForestClassifier(n_estimators=x, n_jobs=1, criterion=\"gini\")\n", "        score_array[i] = eval_model(rf_class, X, y, 0.8)\n", "        print(\"Try {} with n_estimators = {} and score = {}\".format( i, x, score_array[i]))\n", "    score_mean[j], score_sigma[j] = np.mean(score_array), np.std(score_array)\n", "    j=j+1\n", "\n", "print(\"RandomForestClassification Done!\")"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["fig = plt.figure(figsize=(12,6))\n", "plt.errorbar(num_estimator, score_mean, yerr=score_sigma, fmt='k.-')\n", "plt.xscale(\"log\")\n", "plt.xlabel(\"number of estimators\",size = 16)\n", "plt.ylabel(\"accuracy\",size = 16)\n", "plt.xlim(0.9,600)\n", "plt.ylim(0.3,0.8)\n", "plt.title(\"Random Forest Classifier\", size = 18)\n", "plt.grid(which=\"both\")"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["#SVM linear\n", "\n", "C_ar = np.array([0.5, 0.1, 1, 5, 10])\n", "score_ar = np.zeros(len(C_ar))\n", "i=0\n", "for C_val in C_ar:\n", "    svc_class = svm.SVC(kernel='linear', random_state=1, C = C_val)\n", "    score_array[i] = eval_model(svc_class, X, y, 0.8)\n", "    i=i+1\n", "\n", "score_mu, score_sigma = np.mean(score_ar), np.std(score_ar)\n", "\n", "fig = plt.figure(figsize=(12,6))\n", "plt.errorbar(C_ar, score_ar, yerr=score_sigma, fmt='k.-')\n", "plt.xlabel(\"C assignment\",size = 16)\n", "plt.ylabel(\"accuracy\",size = 16)\n", "plt.title(\"SVM Classifier (Linear)\", size = 18)\n", "plt.grid(which=\"both\")"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["#adjusting our gamma\n", "gamma_ar = np.array([0.001, 0.01, 0.1, 1, 10])\n", "score_ar = np.zeros(len(gamma_ar))\n", "score_mean = np.zeros(len(gamma_ar))\n", "score_sigma = np.zeros(len(gamma_ar))\n", "i=0\n", "for l in gamma_ar:\n", "    svc_class = svm.SVC(kernel='rbf', random_state=1, gamma = l)\n", "    score_array[i] = eval_model(svc_class, X, y, 0.8)\n", "    score_mean[i], score_sigma[i] = np.mean(score_ar[i]), np.std(score_ar[i])\n", "    i=i+1\n", "\n", "\n", "fig = plt.figure(figsize=(12,6))\n", "plt.errorbar(gamma_ar, score_mean, yerr=score_sigma, fmt='k.-')\n", "plt.xscale('log')\n", "plt.xlabel(\"Gamma\",size = 16)\n", "plt.ylabel(\"accuracy\",size = 16)\n", "plt.title(\"SVM Classifier (RBF)\", size = 18)\n", "plt.grid(which=\"both\")"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["#keras\n", "\n", "import keras\n", "from keras.models import Sequential\n", "from keras.layers import Dense, Dropout, Activation\n", "from keras.optimizers import SGD\n", "\n", "# Change to np.array type\n", "new_x = np.array(X)\n", "new_y = np.array(y)\n", "\n", "# fix random seed for reproducibility\n", "np.random.seed(1234)\n", "\n", "model = Sequential()\n", "model.add(Dense(64, input_dim=7, init='uniform', activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(64, activation='relu'))\n", "model.add(Dropout(0.5))\n", "model.add(Dense(1, activation='sigmoid'))\n", "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"]}, {"metadata": {}, "execution_count": null, "outputs": [], "cell_type": "code", "source": ["\n", "\n", "model.fit(new_x, new_y, epochs=150, batch_size=20)\n", "scores = model.evaluate(new_x, new_y)\n", "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n", "\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "## Results\n", "\n", "We can see our SVM models did not work at all, but our RFC and keras models fitted with up to .57 accuracy\n"]}, {"metadata": {"collapsed": true}, "execution_count": null, "outputs": [], "cell_type": "code", "source": []}], "nbformat_minor": 1, "nbformat": 4}