{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Removing Uninformative Parts of the Audio Files\n\n*Initially forked [from ILM](https://www.kaggle.com/ilyamich/remove-uninformative-parts-from-the-audio-files). Updated and presented by [Matthew](http://www.kaggle.com/matthewa313).*\n\nIn this notebook, I will demonstrate the removal of empty or very quiet parts of audio files in the train and test audio set.  This new training corpus and testing set should hopefully increase accuracy and decrease the memory of models when employed."},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import os # kaggle OS\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\nfrom tqdm import tqdm_notebook as tqdm # progress bar\nimport IPython.display as ipd # .wav visualizations\nfrom scipy.io import wavfile # return sample rate (in samples/sec) and data from a WAV file\nimport matplotlib.pyplot as plt # plots\n\n% matplotlib inline","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"d27e5ad3-4669-4ae2-973d-384af408edb9","_uuid":"6cc98985efb440d0da4dfbce5c2f77710fa8a289","trusted":true,"collapsed":true},"cell_type":"code","source":"train_ids = next(os.walk(\"../input/audio_train/\"))[2]\ntest_ids = next(os.walk(\"../input/audio_test/\"))[2]","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"ec5bbe8c-bb40-4a88-8302-478c31001afa","_uuid":"aa19f72201071b77c5975a1b7a5c53e083278b97"},"cell_type":"markdown","source":"Here's an example from the train set of a mostly empty track:"},{"metadata":{"_cell_guid":"20ddce0c-510a-4658-b1f6-9a545887faf6","_uuid":"7cfd670fc6b673b786bea9d8ad53af1d5dfb0e6f","trusted":true},"cell_type":"code","source":"ipd.Audio(\"../input/audio_train/31440023.wav\")","execution_count":5,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5372768c-6b14-4647-8e41-5a169d267cee","_uuid":"1fcf1be8eba06bf3ad549fb230af54314116e497"},"cell_type":"markdown","source":"> **wavfile.read**\n\nReturns  the sample rate (samples per second) from a .wav file"},{"metadata":{"_cell_guid":"ee7e56af-427f-41e7-ad6e-1ec108564ee5","_uuid":"87402cb7c67516692870653ec2dcc9e6fb49dce6","trusted":true},"cell_type":"code","source":"sample_rate, audio = wavfile.read(\"../input/audio_train/31440023.wav\")\n\nplt.plot(audio); # plot the audio chart with MatPlot","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"45a4209b-35a5-4b3a-9f6b-c462444bc2d0","_uuid":"d256b440de6ae7d9a2d4e657e692639451553e04"},"cell_type":"markdown","source":"Another competitor had the idea to crop and segment the audio files and leave only the part that contains information and a little bit around it.\n\nFirst we'll define a function that normalizes the data to be between -1 and 1, as opposed to -32768 and 32768."},{"metadata":{"collapsed":true,"_cell_guid":"18528a5c-e21b-4aaa-8bb8-87d04bf3797c","_uuid":"dea55b83dd6130f40dc93cfd610ada2204db1744","trusted":true},"cell_type":"code","source":"def normalize_audio(audio):\n    # audio = (audio + 32768) / 65535 (only if bits were correct)\n    audio = audio / max(np.abs(audio))\n    return audio","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"026f9c51-97a5-4a85-b143-ab30915157a5","_uuid":"22c8979301daa32c5d2b6673987c1cb29c66a1ce"},"cell_type":"markdown","source":"We'll eliminate noise from the tracks by measuring the volume in each segment and eliminating very quiet segments.\n\nThis function will return the start and stop of the signal parts of each track."},{"metadata":{"_cell_guid":"8d8cb5a7-f5ba-4815-8ffe-6ff5e26594b2","_uuid":"a8cc2f1794bc266a5e212dca1f6821c4a3242996","trusted":true,"collapsed":true},"cell_type":"code","source":"def divide_audio(audio, resolution=100, window_duration=0.1, minimum_power=0.001, sample_rate=44100):    \n    duration = len(audio) / sample_rate # in samples/sec\n    iterations = int(duration * resolution)\n    step = int(sample_rate / resolution)\n    window_length = np.floor(sample_rate * window_duration)\n    audio_power = np.square(normalize_audio(audio)) / window_length #Normalized power to window duration\n\n    start = np.array([])\n    stop = np.array([])\n    is_started = False\n    \n    for n in range(iterations):\n        power = 10 * np.sum(audio_power[n * step : int(n * step + window_length)]) # sensitive\n        if not is_started and power > minimum_power:\n            start = np.append(start, n * step + window_length / 2)\n            is_started = True\n        elif is_started and (power <= minimum_power or n == iterations-1):\n            stop = np.append(stop, n * step + window_length / 2)\n            is_started = False\n    \n    if start.size == 0:\n        start = np.append(start, 0)\n        stop = np.append(stop, len(audio))\n        \n    start = start.astype(int)\n    stop = stop.astype(int)\n    \n    # We don't want to eliminate EVERYTHING that's unnecessary\n    # There should be a little boundary...\n    # 200 frame buffer before and after\n    \n    # minus = ?\n    if start[0] > 200:\n        minus = 200\n    else:\n        minus = start[0]\n        \n    # plus = ?\n    if (len(audio) - stop[0]) > 200:\n        plus = 200\n    else:\n        plus = len(audio) - stop[0]\n    \n    return (start - minus), (stop + plus)","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"8f9669d2-ddc8-41e3-a2cc-06d4316a5f1c","_uuid":"fb4626705f174564e4a62031ce55734cfc5e5266","trusted":true},"cell_type":"code","source":"# same wav file as before\nstart, stop =  divide_audio(audio)\nprint(start)\nprint(stop)\nplt.plot(audio[start[0]:stop[0]]);","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"cba7a651-9878-42e9-8e06-2ef823ecbca3","_uuid":"3fdb889c4ad1463080a23a0f590228315102f9ba"},"cell_type":"markdown","source":"After some manual tunning it seems that the it works\n\nNow lets briefly look on more examples:\n\n[Loop logic](http://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis](http://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis) taken from codename007."},{"metadata":{"_cell_guid":"9be6479d-fd1e-4e80-b18c-e14ea9fd17f2","_uuid":"3314ee9dc008620769e1e56f40eed8891aab0ee7","_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"columns = ['File Name', 'Audio Duration', 'Segment Number']\naudio_segments = pd.DataFrame(columns=columns)\n\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in tqdm(range(40), total=40):\n    random_audio_idxs = np.random.randint(len(train_ids)+1, size=1)[0]\n    _, tmp = wavfile.read(\"../input/audio_train/\" + train_ids[random_audio_idxs])\n    start, stop = divide_audio(tmp)\n    \n    audio_segments = audio_segments.append({'File Name': train_ids[random_audio_idxs],\n                                            'Audio Duration': len(tmp)/sample_rate,\n                                            'Segment Number': len(start)}, ignore_index=True)\n    \n    ax[i//4, i%4].plot(tmp)\n    ax[i//4, i%4].set_title(train_ids[random_audio_idxs])\n    ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"c72f862f-6cc4-4832-9708-bd59a3e9a1e6","_uuid":"f8ac2854dc8a25807b8e2d751bc9f55e415ce7d1","trusted":true},"cell_type":"code","source":"audio_segments","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"4e34f2a9-8e03-49c9-bac3-a52ded8a4f13","_uuid":"9963290b4a9afe6b05bb6d114e38c5c336cc4a7c"},"cell_type":"markdown","source":"## Let's create a new training set.\n\nWe'll run out of memory if we run the for loop too many times, but if you want to, you can run it on your home computer (you will need to run it 9,473 times). In this example, I will only run 1the first 3 as a mere example."},{"metadata":{"_cell_guid":"924bedfc-e38f-462b-99e8-ca8388e06a80","_uuid":"1e6412134add0fd3a736fbceaaa661ff0c0d800d","trusted":true},"cell_type":"code","source":"train     = pd.read_csv('../input/train.csv')\nnew_train = pd.DataFrame(columns=train.columns)\n\n# we can only iterate threw the first ~2300 without losing memory\n# change this value to 9473 to iterate through all of them\nfor n in tqdm(range(3)):\n    _, tmp = wavfile.read('../input/audio_train/' + train_ids[n])\n    start, stop = divide_audio(tmp, window_duration=0.1, minimum_power=0.001)\n    new_path = 'segmented_' + train_ids[n]\n    \n    if len(start) <= 1:\n        wavfile.write(new_path, sample_rate, tmp[start[0]:stop[0]])\n        new_train = new_train.append(train.iloc[n])\n    else:\n        for m in range(len(start)):\n            wavfile.write(new_path[:-4] + '_' + str(m) + '.wav', sample_rate, tmp[start[m]:stop[m]])\n            new_train = new_train.append({train.columns[0]: train.iloc[n][train.columns[0]][:-4] + '_' + str(m) + '.wav',\n                                          train.columns[1]: train.iloc[n][train.columns[1]],\n                                          train.columns[2]: train.iloc[n][train.columns[2]],}, ignore_index=True)\n            \nnew_train.to_csv('segmented_train.csv', index=False)","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"a98f5f206998b496cb1a35f1ab5830cc43ab6ee4"},"cell_type":"markdown","source":"## Finally, let's create a new test set.\n\nWe'll run out of memory if we run the for loop too many times, but if you want to, you can run it on your home computer (you will need to run it 9,473 times). In this example, I will only run 1the first 3 as a mere example."},{"metadata":{"trusted":true,"_uuid":"2e14617df679c20b6be709ba9ad500e97d082ef1"},"cell_type":"code","source":"test     = pd.read_csv('../input/sample_submission.csv')\nnew_test = pd.DataFrame(columns=train.columns)\n\nprint(len(test_ids))\n# for n in tqdm(range(len(test_ids))):\n#     _, tmp = wavfile.read('../input/audio_test/' + test_ids[n])\n#     start, stop = divide_audio(tmp, window_duration=0.1, minimum_power=0.001)\n#     new_path = 'segmented_' + test_ids[n]\n    \n#    if len(start) <= 1:\n#        wavfile.write(new_path, sample_rate, tmp[start[0]:stop[0]])\n#        new_train = new_train.append(train.iloc[n])\n#    else:\n#        for m in range(len(start)):\n#            wavfile.write(new_path[:-4] + '_' + str(m) + '.wav', sample_rate, tmp[start[m]:stop[m]])\n#            new_train = new_train.append({train.columns[0]: train.iloc[n][train.columns[0]][:-4] + '_' + str(m) + '.wav',\n#                                         train.columns[1]: train.iloc[n][train.columns[1]],\n# train.columns[2]: train.iloc[n][train.columns[2]],}, ignore_index=True)\n            \n# new_train.to_csv('segmented_test.csv', index=False)","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"a69bbd2d-8bf4-4d96-a8f9-a73c640f24f3","_uuid":"b3a5bf8b8ee617ce97f766286396606860229abd"},"cell_type":"markdown","source":" I can't create a new full test set because we'll run out of memory on Kaggle. Instead, to create a new test set, you should run this locally."},{"metadata":{"_uuid":"90a496efbd32902bf337a612635972aa792c0232"},"cell_type":"markdown","source":"## Future Works\n\nThe next step in this process is evaluating the merits of removing noisy (as in, not signal), parts of audio files for sound tagging. If you cite this in a research paper, please use:\n> Author(s) name: Matthew Anderson\n> Date: 04/07/2018 (April 7th)\n> Title: \"Removing Uninformative Parts of Audio Files\"\n> Version 1.1\n> Type: Program\n> Availability: Anyone is welcome to use it"}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}