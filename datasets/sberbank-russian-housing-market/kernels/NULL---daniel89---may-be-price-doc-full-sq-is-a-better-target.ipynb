{"nbformat": 4, "cells": [{"source": "For me the idea is quite obvious:\nthe majority of given features are able to characterise not the price of the apartment, but how expensive the apartments like this are in general. For example if I have kremlin_km==3 I can easily infer that it's the city centre, apartments are expensive here and I can get the certain range for price_doc/full_sq for such apartments. This range will be much less wide than the range of price_doc because price_doc/full_sq in the selected area would be more or less equal for flats with full_sq=40 and full_sq=80. While the price_doc could differ in 2 times.", "execution_count": null, "cell_type": "markdown", "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "5eb84c21961ca292c08e934051dbac54606537f2"}, "outputs": []}, {"source": "import numpy as np\nimport pandas as pd\n\ndata = pd.read_csv('../input/train.csv',index_col='id',parse_dates=['timestamp'])\n\n#we have to drop entries with unlikely low full_sq\nprint(len(data[data['full_sq']<15]), ' entries drop')\ndata = data.drop((data[data['full_sq']<15]).index)\n\ndata['price_per_meter'] = data['price_doc']/data['full_sq']", "outputs": [], "cell_type": "code", "metadata": {"_execution_state": "idle", "_uuid": "df5c8d4a809c51d34fc44322c0c789e4ca9a1b93"}, "execution_count": 23}, {"source": "data.loc[:,data.columns.drop('price_per_meter')].corr()['price_doc'].sort_values()", "execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "a306f5e125ce79e8eba6eec3e4aded5fbc107f14"}, "outputs": []}, {"source": "data.loc[:,data.columns.drop('price_doc')].corr()['price_per_meter'].sort_values()", "execution_count": null, "cell_type": "code", "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "62baa2aeaaaf03f45ef82a561cd6c55e75ef4be4"}, "outputs": []}, {"source": "As you see, price_per_meter is much more correlated with the features.\nBut at the moment I couldn't get any yield of it. Mostly I'm trying to predict with xgboost, but I've tried other models as well. And still my best tries occurred when I was predicting price_doc directly, not via price_per_meter.\nI'm pretty new to machine learning and I would appreciate any suggestions and thoughts. Thanks in advance. ", "execution_count": null, "cell_type": "markdown", "metadata": {"_execution_state": "idle", "collapsed": false, "_uuid": "31e7a1c00ca4bcdade69e4604768619dafc26013"}, "outputs": []}], "metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"file_extension": ".py", "version": "3.6.0", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python"}}, "nbformat_minor": 0}