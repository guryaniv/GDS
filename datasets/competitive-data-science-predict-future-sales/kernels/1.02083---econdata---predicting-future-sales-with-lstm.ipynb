{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Adapted from https://www.kaggle.com/sebask/keras-2-0\n\nimport time\nnotebookstart= time.time()\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Activation, ThresholdedReLU, MaxPooling2D, Embedding, Dropout\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import MinMaxScaler\nimport gc\n\n# Viz\nimport matplotlib.pyplot as plt\n\n# Import data\nsales = pd.read_csv('../input/sales_train.csv', parse_dates=['date'], infer_datetime_format=True, dayfirst=True)\nshops = pd.read_csv('../input/shops.csv')\nitems = pd.read_csv('../input/items.csv')\ncats = pd.read_csv('../input/item_categories.csv')\nval = pd.read_csv('../input/test.csv')\n\n# Rearrange the raw data to be monthly sales by item-shop\ndf = sales.groupby([sales.date.apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).sum().reset_index()\ndf = df[['date','item_id','shop_id','item_cnt_day']]\ndf[\"item_cnt_day\"].clip(0.,20.,inplace=True)\ndf = df.pivot_table(index=['item_id','shop_id'], columns='date',values='item_cnt_day',fill_value=0).reset_index()\n\n# Merge data from monthly sales to specific item-shops in test data\ntest = pd.merge(val,df,on=['item_id','shop_id'], how='left').fillna(0)\n\n# Strip categorical data so keras only sees raw timeseries\ntest = test.drop(labels=['ID','item_id','shop_id'],axis=1)\n\n# Rearrange the raw data to be monthly average price by item-shop\n# Scale Price\nscaler = MinMaxScaler(feature_range=(0, 1))\nsales[\"item_price\"] = scaler.fit_transform(sales[\"item_price\"].values.reshape(-1,1))\ndf2 = sales.groupby([sales.date.apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id']).mean().reset_index()\ndf2 = df2[['date','item_id','shop_id','item_price']].pivot_table(index=['item_id','shop_id'], columns='date',values='item_price',fill_value=0).reset_index()\n\n# Merge data from average prices to specific item-shops in test data\nprice = pd.merge(val,df2,on=['item_id','shop_id'], how='left').fillna(0)\nprice = price.drop(labels=['ID','item_id','shop_id'],axis=1)\n\n# Create x and y training sets from oldest data points\ny_train = test['2015-10']\nx_sales = test.drop(labels=['2015-10'],axis=1)\nx_sales = x_sales.values.reshape((x_sales.shape[0], x_sales.shape[1], 1))\nx_prices = price.drop(labels=['2015-10'],axis=1)\nx_prices= x_prices.values.reshape((x_prices.shape[0], x_prices.shape[1], 1))\nX = np.append(x_sales,x_prices,axis=2)\n\ny = y_train.values.reshape((214200, 1))\nprint(\"Training Predictor Shape: \",X.shape)\nprint(\"Training Predictee Shape: \",y.shape)\ndel y_train, x_sales; gc.collect()\n\n# Transform test set into numpy matrix\ntest = test.drop(labels=['2013-01'],axis=1)\nx_test_sales = test.values.reshape((test.shape[0], test.shape[1], 1))\nx_test_prices = price.drop(labels=['2013-01'],axis=1)\nx_test_prices = x_test_prices.values.reshape((x_test_prices.shape[0], x_test_prices.shape[1], 1))\n\n# Combine Price and Sales Df\ntest = np.append(x_test_sales,x_test_prices,axis=2)\ndel x_test_sales,x_test_prices, price; gc.collect()\nprint(\"Test Predictor Shape: \",test.shape)\n\nprint(\"Modeling Stage\")\n# Define the model layers\nmodel_lstm = Sequential()\nmodel_lstm.add(LSTM(16, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\nmodel_lstm.add(Dropout(0.5))\nmodel_lstm.add(LSTM(32))\nmodel_lstm.add(Dropout(0.5))\nmodel_lstm.add(Dense(1))\nmodel_lstm.compile(optimizer=\"adam\", loss='mse', metrics=[\"mse\"])\nprint(model_lstm.summary())\n\n# Train Model\nprint(\"\\nFit Model\")\nVALID = True\nLSTM_PARAM = {\"batch_size\":128,\n              \"verbose\":2,\n              \"epochs\":10}\n\nmodelstart = time.time()\nif VALID is True:\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.10, random_state=1, shuffle=False)\n    # del X,y; gc.collect()\n    print(\"X Train Shape: \",X_train.shape)\n    print(\"X Valid Shape: \",X_valid.shape)\n    print(\"y Train Shape: \",y_train.shape)\n    print(\"y Valid Shape: \",y_valid.shape)\n    \n    callbacks_list=[EarlyStopping(monitor=\"val_loss\",min_delta=.001, patience=3,mode='auto')]\n    hist = model_lstm.fit(X_train, y_train,\n                          validation_data=(X_valid, y_valid),\n                          callbacks=callbacks_list,\n                          **LSTM_PARAM)\n    pred = model_lstm.predict(test)\n\n    # Model Evaluation\n    best = np.argmin(hist.history[\"val_loss\"])\n    print(\"Optimal Epoch: {}\",best)\n    print(\"Train Score: {}, Validation Score: {}\".format(hist.history[\"loss\"][best],hist.history[\"val_loss\"][best]))\n\n    plt.plot(hist.history['loss'], label='train')\n    plt.plot(hist.history['val_loss'], label='validation')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Mean Square Error\")\n    plt.legend()\n    plt.show()\n    plt.savefig(\"Train and Validation MSE Progression.png\")\n\nif VALID is False:\n    print(\"X Shape: \",X.shape)\n    print(\"y Shape: \",y.shape)\n    hist = model_lstm.fit(X,y,**LSTM_PARAM)\n    pred = model_lstm.predict(X)\n    \n    plt.plot(hist.history['loss'], label='Training Loss')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Mean Square Error\")\n    plt.legend()\n    plt.show()\n    plt.savefig(\"Training Loss Progression.png\")\n\nprint(\"\\Output Submission\")\nsubmission = pd.DataFrame(pred,columns=['item_cnt_month'])\nsubmission.to_csv('submission.csv',index_label='ID')\nprint(submission.head())\nprint(\"\\nModel Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\nprint(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d5eb5aade970a3507149c46c66bb3e3de344c5e"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}