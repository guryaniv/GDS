{"cells":[{"metadata":{"_uuid":"1b8da79bd7896c54199ccf641c6b730b798fbd0e","_cell_guid":"1b26cf41-5330-41fa-b4ce-76447f8e1e2f","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import Conv1D, GlobalMaxPool1D, Dropout, concatenate\nfrom keras.preprocessing import text, sequence\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9ad6eedb6c02df20c9aff87cd135992b7232d5a","collapsed":true,"_cell_guid":"b4dc5f09-8543-4a1d-8dd8-d318beac27b0","trusted":true},"cell_type":"code","source":"# define network parameters\nmax_features = 20000\nmaxlen = 100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d5fa68b8d9f20c8ceb662df489662db5e6b78846","_cell_guid":"022343c0-6cc6-4079-a3f2-4b89a7d5e0fe"},"cell_type":"markdown","source":"# Load and Preprocessing Steps\nHere we load the data and fill in the misisng values"},{"metadata":{"_uuid":"9182d060cfbbcd070b67e5dbc1136c98a4262cf9","collapsed":true,"_cell_guid":"b3b2bf13-dccb-4b2b-82b0-86295ac0ee23","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\ntrain = train.sample(frac=1)\n\nlist_sentences_train = train[\"comment_text\"].fillna(\"Invalid\").values\nlist_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\nlist_sentences_test = test[\"comment_text\"].fillna(\"Invalid\").values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"14ac14dab11eab6430d4c8f8946bb0ce1b6f5ceb","_cell_guid":"8faf48b7-965e-49c0-9994-b5bae9650077"},"cell_type":"markdown","source":"## Sequence Generation\nHere we take the data and generate sequences from the data"},{"metadata":{"_uuid":"b53b6a50bb03f98e1605e5549f532503d7ef8d1d","collapsed":true,"_cell_guid":"a0296763-d6e7-49cd-bdb5-33bb7f5c231d","trusted":true},"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(list_sentences_train))\n# train data\nlist_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\nX_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n# test data\nlist_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\nX_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b334ddbf78cf4065be1969513bf0f9f10e6da643","scrolled":false,"_cell_guid":"026bf4f6-00b0-4178-9bcc-fb8cbc44d1e0","trusted":true},"cell_type":"code","source":"def build_model(conv_layers = 2, max_dilation_rate = 3):\n    embed_size = 128\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size)(inp)\n    x = Dropout(0.25)(x)\n    x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    prefilt_x = Conv1D(2*embed_size, \n                   kernel_size = 3)(x)\n    out_conv = []\n    # dilation rate lets us use ngrams and skip grams to process \n    for dilation_rate in range(max_dilation_rate):\n        x = prefilt_x\n        for i in range(3):\n            x = Conv1D(32*2**(i), \n                       kernel_size = 3, \n                       dilation_rate = dilation_rate+1)(x)    \n        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n    x = concatenate(out_conv, axis = -1)    \n    x = Dense(50, activation=\"relu\")(x)\n    x = Dropout(0.1)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n    model.compile(loss='binary_crossentropy',\n                  optimizer='adam',\n                  metrics=['binary_accuracy'])\n\n    return model\n\nmodel = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8ae9fc16a72d57f707012d35ea5db3d538dbb505","_cell_guid":"aec3c661-33ce-44b7-8309-97da1653eadf"},"cell_type":"markdown","source":"# Train the Model\nHere we train the model and use model checkpointing and early stopping to keep only the best version of the model"},{"metadata":{"_uuid":"24747af54fb0253adb9934a78661ff0e68204af0","_cell_guid":"e0c81808-bb80-4c72-9150-4d4e9c8fa30f","trusted":true},"cell_type":"code","source":"batch_size = 512\nepochs = 15\n\nfile_path=\"weights.hdf5\"\ncheckpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n\ncallbacks_list = [checkpoint, early] #early\nmodel.fit(X_t, y, \n          batch_size=batch_size, \n          epochs=epochs, \n          validation_split=0.1, \n          callbacks=callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07f12751a9cccb7c3f55a1656ac3c4b237b7fa28"},"cell_type":"markdown","source":"# Show a few test sentences"},{"metadata":{"trusted":true,"_uuid":"7c17da83d52e024cb93aeb26675ae310014f382c"},"cell_type":"code","source":"from IPython.display import Markdown, display\ndmd = lambda x: display(Markdown(x))\ndef show_sentence(sent_idx):\n    dmd('# Input Sentence:\\n `{}`'.format(list_sentences_train[sent_idx]))\n    c_pred = model.predict(X_t[sent_idx:sent_idx+1])[0]\n    dmd('## Positive Categories')\n    for k, v, p in zip(list_classes, y[sent_idx], c_pred):\n        if v>0:\n            dmd('- {}, Prediction: {:2.2f}%'.format(k, 100*v, 100*p))\n    dmd('## Negative Categories')\n    for k, v, p in zip(list_classes, y[sent_idx], c_pred):\n        if v<1:\n            dmd('- {}, Prediction: {:2.2f}%'.format(k, 100*p))\nshow_sentence(0)\nshow_sentence(50)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb545c59982c3cb4d42ba8358cb4622814e94cba","_cell_guid":"0a5db347-fe8e-4218-9c9b-dc4bfe4824d5"},"cell_type":"markdown","source":"# Make Predictions\nLoad the model and make predictions on the test dataset"},{"metadata":{"_uuid":"92532dfaa0211e9b01d9ee3d78f86b3f1e570a3c","_cell_guid":"a3442437-db15-4e64-b377-c8bd010e7378","trusted":true,"collapsed":true},"cell_type":"code","source":"model.load_weights(file_path)\ny_test = model.predict(X_te, verbose = True, batch_size = 1024)\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nsample_submission[list_classes] = y_test\nsample_submission.to_csv(\"predictions.csv\", \n                         index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"98bcd9d19c3a14e96210da7b1fb17247ccd68f69"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}