{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "77d55b28-8ed5-bf2b-ea17-244d8579bdf3"
      },
      "source": [
        "**\n",
        "\n",
        " - **Xgboost - Uncomment last 3 tab and run (Due to kernel Problem)\n",
        "\n",
        "**\n",
        "**\n",
        "\n",
        " - Working - Naive Bayes**\n",
        "\n",
        "** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f379f3db-ee99-0b8a-fa1a-e899c94ffd0a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import operator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "import xgboost as xgb\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import model_selection, preprocessing, ensemble\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.stats import zscore\n",
        "\n",
        "from sklearn.cross_validation import KFold\n",
        "#from sklearn.model_selection import KFold\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2ad7ce18-6a25-f0c5-fb66-7b50d3309900"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'],encoding='utf8')\n",
        "test_df = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'],encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca4213e5-2c9c-d178-2356-753327b849c7"
      },
      "outputs": [],
      "source": [
        "##Missing Values Replace\n",
        "train_df.fillna(-99,inplace=True)\n",
        "test_df.fillna(-99,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "292343d2-336c-03bf-c87d-3cf6b81b5c81"
      },
      "outputs": [],
      "source": [
        "#Converting Catogorical Values\n",
        "for f in train_df.columns:\n",
        "    if train_df[f].dtype=='object':\n",
        "        print(f)\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(train_df[f].values.astype('str')) + list(test_df[f].values.astype('str')))\n",
        "        train_df[f] = lbl.transform(list(train_df[f].values.astype('str')))\n",
        "        test_df[f] = lbl.transform(list(test_df[f].values.astype('str')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "82734d35-5640-e058-35d7-3779568149ef"
      },
      "source": [
        "**Features** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6c33b8cd-81e3-96a2-1478-67565f1ddb61"
      },
      "outputs": [],
      "source": [
        "# ratio of living area to full area #\n",
        "# year and month #\n",
        "train_df[\"yearmonth\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.month\n",
        "test_df[\"yearmonth\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.month\n",
        "\n",
        "# year and week #\n",
        "train_df[\"yearweek\"] = train_df[\"timestamp\"].dt.year*100 + train_df[\"timestamp\"].dt.weekofyear\n",
        "test_df[\"yearweek\"] = test_df[\"timestamp\"].dt.year*100 + test_df[\"timestamp\"].dt.weekofyear\n",
        "\n",
        "# year #\n",
        "train_df[\"year\"] = train_df[\"timestamp\"].dt.year\n",
        "test_df[\"year\"] = test_df[\"timestamp\"].dt.year\n",
        "\n",
        "# month of year #\n",
        "train_df[\"month_of_year\"] = train_df[\"timestamp\"].dt.month\n",
        "test_df[\"month_of_year\"] = test_df[\"timestamp\"].dt.month\n",
        "\n",
        "# week of year #\n",
        "train_df[\"week_of_year\"] = train_df[\"timestamp\"].dt.weekofyear\n",
        "test_df[\"week_of_year\"] = test_df[\"timestamp\"].dt.weekofyear\n",
        "\n",
        "# day of week #\n",
        "train_df[\"day_of_week\"] = train_df[\"timestamp\"].dt.weekday\n",
        "test_df[\"day_of_week\"] = test_df[\"timestamp\"].dt.weekday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "45dc382a-c243-792c-905f-0aeda16fe583"
      },
      "outputs": [],
      "source": [
        "train_df[\"ratio_life_sq_full_sq\"] = train_df[\"life_sq\"] / np.maximum(train_df[\"full_sq\"].astype(\"float\"),1)\n",
        "test_df[\"ratio_life_sq_full_sq\"] = test_df[\"life_sq\"] / np.maximum(test_df[\"full_sq\"].astype(\"float\"),1)\n",
        "train_df[\"ratio_life_sq_full_sq\"].ix[train_df[\"ratio_life_sq_full_sq\"]<0] = 0\n",
        "train_df[\"ratio_life_sq_full_sq\"].ix[train_df[\"ratio_life_sq_full_sq\"]>1] = 1\n",
        "test_df[\"ratio_life_sq_full_sq\"].ix[test_df[\"ratio_life_sq_full_sq\"]<0] = 0\n",
        "test_df[\"ratio_life_sq_full_sq\"].ix[test_df[\"ratio_life_sq_full_sq\"]>1] = 1\n",
        "\n",
        "# ratio of kitchen area to living area #\n",
        "train_df[\"ratio_kitch_sq_life_sq\"] = train_df[\"kitch_sq\"] / np.maximum(train_df[\"life_sq\"].astype(\"float\"),1)\n",
        "test_df[\"ratio_kitch_sq_life_sq\"] = test_df[\"kitch_sq\"] / np.maximum(test_df[\"life_sq\"].astype(\"float\"),1)\n",
        "train_df[\"ratio_kitch_sq_life_sq\"].ix[train_df[\"ratio_kitch_sq_life_sq\"]<0] = 0\n",
        "train_df[\"ratio_kitch_sq_life_sq\"].ix[train_df[\"ratio_kitch_sq_life_sq\"]>1] = 1\n",
        "test_df[\"ratio_kitch_sq_life_sq\"].ix[test_df[\"ratio_kitch_sq_life_sq\"]<0] = 0\n",
        "test_df[\"ratio_kitch_sq_life_sq\"].ix[test_df[\"ratio_kitch_sq_life_sq\"]>1] = 1\n",
        "\n",
        "# ratio of kitchen area to full area #\n",
        "train_df[\"ratio_kitch_sq_full_sq\"] = train_df[\"kitch_sq\"] / np.maximum(train_df[\"full_sq\"].astype(\"float\"),1)\n",
        "test_df[\"ratio_kitch_sq_full_sq\"] = test_df[\"kitch_sq\"] / np.maximum(test_df[\"full_sq\"].astype(\"float\"),1)\n",
        "train_df[\"ratio_kitch_sq_full_sq\"].ix[train_df[\"ratio_kitch_sq_full_sq\"]<0] = 0\n",
        "train_df[\"ratio_kitch_sq_full_sq\"].ix[train_df[\"ratio_kitch_sq_full_sq\"]>1] = 1\n",
        "test_df[\"ratio_kitch_sq_full_sq\"].ix[test_df[\"ratio_kitch_sq_full_sq\"]<0] = 0\n",
        "test_df[\"ratio_kitch_sq_full_sq\"].ix[test_df[\"ratio_kitch_sq_full_sq\"]>1] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "497228ca-d28f-2eba-d78c-bab7dd7dad40"
      },
      "outputs": [],
      "source": [
        "# floor of the house to the total number of floors in the house #\n",
        "train_df[\"ratio_floor_max_floor\"] = train_df[\"floor\"] / train_df[\"max_floor\"].astype(\"float\")\n",
        "test_df[\"ratio_floor_max_floor\"] = test_df[\"floor\"] / test_df[\"max_floor\"].astype(\"float\")\n",
        "\n",
        "# num of floor from top #\n",
        "train_df[\"floor_from_top\"] = train_df[\"max_floor\"] - train_df[\"floor\"]\n",
        "test_df[\"floor_from_top\"] = test_df[\"max_floor\"] - test_df[\"floor\"]\n",
        "\n",
        "\n",
        "train_df[\"extra_sq\"] = train_df[\"full_sq\"] - train_df[\"life_sq\"]\n",
        "test_df[\"extra_sq\"] = test_df[\"full_sq\"] - test_df[\"life_sq\"]\n",
        "\n",
        "\n",
        "train_df[\"age_of_building\"] = train_df[\"build_year\"] - train_df[\"year\"]\n",
        "test_df[\"age_of_building\"] = test_df[\"build_year\"] - test_df[\"year\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8ce789cc-47cb-48f1-373b-a1d275ace25d"
      },
      "outputs": [],
      "source": [
        "#x_train = train_df.drop([\"timestamp\",'id'],axis=1)\n",
        "#x_test = test_df.drop([\"timestamp\"],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c1adbcd4-7e15-b80b-6b7c-066b96a232aa"
      },
      "outputs": [],
      "source": [
        "#features = list(train_df.columns)\n",
        "train_columns = list(set(train_df.select_dtypes(include=['float64', 'int64']).columns) - set(['id', 'timestamp', 'price_doc']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7792f09c-3afc-a2ef-df58-87d4913ebcfa"
      },
      "outputs": [],
      "source": [
        "y_train = train_df['price_doc'].values\n",
        "x_train = train_df[train_columns].values\n",
        "x_test = test_df[train_columns].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7f63a255-9352-eaad-d512-df384b924cbd"
      },
      "outputs": [],
      "source": [
        "# Train/Valid split\n",
        "split = 15000\n",
        "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2e03fd6-dc51-916e-fc7b-66f5d4e6e185"
      },
      "outputs": [],
      "source": [
        "d_train = xgb.DMatrix(x_train, label=y_train)\n",
        "d_valid = xgb.DMatrix(x_valid, label=y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb7e824c-0ed0-f823-d84e-0cc1a9cfe5bd"
      },
      "outputs": [],
      "source": [
        "    param = {}\n",
        "    param['objective'] = 'multi:softprob'\n",
        "    param['eta'] = 0.1\n",
        "    param['max_depth'] = 6\n",
        "    param['silent'] = 1\n",
        "    param['num_class'] = 3\n",
        "    param['eval_metric'] = \"mlogloss\"\n",
        "    param['min_child_weight'] = 1\n",
        "    param['subsample'] = 0.7\n",
        "    param['colsample_bytree'] = 0.7\n",
        "    param['seed'] = 0\n",
        "    num_rounds = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17f1ac14-58a6-7dd8-44e4-8eee51037e46"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "def rmsle(preds, dtrain):\n",
        "\tlabels = dtrain.get_label()\n",
        "\tassert len(preds) == len(labels)\n",
        "\tlabels = labels.tolist()\n",
        "\tpreds = preds.tolist()\n",
        "\tterms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0, preds[i]) + 1)) ** 2.0 for i, pred in enumerate(labels)]\n",
        "\treturn 'rmsle', (sum(terms_to_sum) * (1.0 / len(preds))) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a90f1d91-dfd6-7ae3-c95d-ad3016fb5dda"
      },
      "outputs": [],
      "source": [
        "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
        "#clf = xgb.train(param, d_train,200, watchlist, feval=rmsle, early_stopping_rounds=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c36e3702-5a5a-fe15-9daa-c72b832b964e"
      },
      "outputs": [],
      "source": [
        "#p_test = clf.predict(xgb.DMatrix(x_test))\n",
        "\n",
        "#sub = pd.DataFrame()\n",
        "#sub['id'] = test_df['id'].values\n",
        "#sub['price_doc'] = p_test\n",
        "#sub.to_csv('/home/nlp/Desktop/xgb.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a4ead24a-a7cc-5c9b-5308-a32007d8019c"
      },
      "outputs": [],
      "source": [
        "# plot the important features #\n",
        "#importance = clf.get_fscore()\n",
        "#importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
        "#df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
        "#df['fscore'] =100* df['fscore'] / df['fscore'].max()\n",
        "#df=df.sort_values(by=\"fscore\",ascending=False)\n",
        "#df.head(50).plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 10))\n",
        "\n",
        "#plt.title('XGBoost Feature Importance( 50 significant)')\n",
        "\n",
        "#plt.annotate()\n",
        "#plt.xlabel('relative importance')\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8b3d061c-99d5-0551-8d99-83c40cbe720d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}