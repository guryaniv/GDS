{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":true},"cell_type":"code","source":"MAX_ROUNDS = 400\nOPTIMIZE_ROUNDS = False\nLEARNING_RATE = 0.07\nEARLY_STOPPING_ROUNDS = 50  \n# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n#       I will get lots of information to make my own judgment.  You should probably\n#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import LabelEncoder\nfrom numba import jit\nimport time\nimport gc","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"0a550aad-0852-45a8-a1a7-eed92e47444e","_uuid":"71ae0f58ada0b0f7b7691ae5f6759355f9551d3c","collapsed":true,"trusted":true},"cell_type":"code","source":"def eval_gini(y_true, y_prob):\n    y_true = np.asarray(y_true)\n    y_true = y_true[np.argsort(y_prob)]\n    ntrue = 0\n    gini = 0\n    delta = 0\n    n = len(y_true)\n    for i in range(n-1, -1, -1):\n        y_i = y_true[i]\n        ntrue += y_i\n        gini += y_i * delta\n        delta += 1 - y_i\n    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n    return gini\n","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"c50aac22-3714-4308-83de-13fa153ceb9f","_uuid":"7a727f09ae46b7726d2ae36bd713cc3d95e70509","collapsed":true,"trusted":true},"cell_type":"code","source":"def gini_xgb(preds, dtrain):\n    labels = dtrain.get_label()\n    gini_score = -eval_gini(labels, preds)\n    return [('gini', gini_score)]\n\n\ndef add_noise(series, noise_level):\n    return series * (1 + noise_level * np.random.randn(len(series)))\n\n\ndef target_encode(trn_series=None,    # Revised to encode validation series\n                  val_series=None,\n                  tst_series=None,\n                  target=None,\n                  min_samples_leaf=1,\n                  smoothing=1,\n                  noise_level=0):\n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean\n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index\n    ft_val_series = pd.merge(\n        val_series.to_frame(val_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=val_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_val_series.index = val_series.index\n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"c9c920bc-b791-4d87-a17d-a341e1eca535","_uuid":"b8095d6644c8a0b1df3e849fee171c24f8d8f7de","collapsed":true,"trusted":true},"cell_type":"code","source":"# Read data\ntrain_df = pd.read_csv('../input/train.csv', na_values=\"-1\") # .iloc[0:200,:]\ntest_df = pd.read_csv('../input/test.csv', na_values=\"-1\")","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"5526d2f2-d189-45aa-9c8c-8ee576c9a10f","_uuid":"7e14c420d02d74a00ae8ba2a43ab759fbc6d4354","collapsed":true,"trusted":true},"cell_type":"code","source":"# from olivier\ntrain_features = [\n    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n         \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n         \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n         \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n         \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n         \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n         \"ps_car_14\",  #            :  798.48 / shadow  549.58\n         \"ps_car_12\",  #            :  731.93 / shadow  293.62\n         \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n         \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n         \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n         \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n         \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n         \"ps_car_15\",  #            :  593.35 / shadow  226.43\n         \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n         \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n         \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n         \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n         \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n         \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n         \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n         \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n         \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n         \"ps_car_11\",  #            :  173.28 / shadow   76.45\n         \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n         \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n         \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n         \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n         \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n         \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n         \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n         \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n         \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n         \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n]\n# add combinations\ncombs = [\n    ('ps_reg_01', 'ps_car_02_cat'),  \n    ('ps_reg_01', 'ps_car_04_cat'),\n]","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"b485e881-d544-4283-aa60-ac708de0fbaa","_uuid":"081c469f04abf6d29573acd9059419cf54435c75","trusted":true},"cell_type":"code","source":"# Process data\nid_test = test_df['id'].values\nid_train = train_df['id'].values\ny = train_df['target']\n\nstart = time.time()\nfor n_c, (f1, f2) in enumerate(combs):\n    name1 = f1 + \"_plus_\" + f2\n    print('current feature %60s %4d in %5.1f'\n          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n    print('\\r' * 75, end='')\n    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n    # Label Encode\n    lbl = LabelEncoder()\n    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n    train_df[name1] = lbl.transform(list(train_df[name1].values))\n    test_df[name1] = lbl.transform(list(test_df[name1].values))\n\n    train_features.append(name1)\n    \nX = train_df[train_features]\ntest_df = test_df[train_features]\n\nf_cats = [f for f in X.columns if \"_cat\" in f]","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"f71fe14d-7b1b-4273-bda4-dd5f7c54f1ef","_uuid":"9e7b6a0f206cb8c7ca66283c97db84c464e01620","collapsed":true,"trusted":true},"cell_type":"code","source":"y_valid_pred = 0*y\ny_test_pred = 0","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"52e40fef-f491-4c50-a1f5-c67813e6fa3c","_uuid":"537ce99bf3a492f5afb38ac7e2ad8a1e1c2c6b47","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set up folds\nK = 5\nkf = KFold(n_splits = K, random_state = 1, shuffle = True)\nnp.random.seed(0)","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"3d34fee4-5919-4822-8730-d3da8e5a2ab3","_uuid":"80af699a81560eac8c78d9622a8728acfc9dd040","collapsed":true,"trusted":true},"cell_type":"code","source":"# Set up classifier\nmodel = XGBClassifier(    \n                        n_estimators=MAX_ROUNDS,\n                        max_depth=4,\n                        objective=\"binary:logistic\",\n                        learning_rate=LEARNING_RATE, \n                        subsample=.8,\n                        min_child_weight=6,\n                        colsample_bytree=.8,\n                        scale_pos_weight=1.6,\n                        gamma=10,\n                        reg_alpha=8,\n                        reg_lambda=1.3,\n                     )","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"ecca0831-b9ad-4246-a7bc-38c4306b4ec3","_uuid":"ff01449d9ea76cbf963780c8ec9fe6cf139cc0e5","trusted":true},"cell_type":"code","source":"# Run CV\n\nfor i, (train_index, test_index) in enumerate(kf.split(train_df)):\n    \n    # Create data for this fold\n    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n    X_test = test_df.copy()\n    print( \"\\nFold \", i)\n    \n    # Enocode data\n    for f in f_cats:\n        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n                                                        trn_series=X_train[f],\n                                                        val_series=X_valid[f],\n                                                        tst_series=X_test[f],\n                                                        target=y_train,\n                                                        min_samples_leaf=200,\n                                                        smoothing=10,\n                                                        noise_level=0\n                                                        )\n    # Run model for this fold\n    if OPTIMIZE_ROUNDS:\n        eval_set=[(X_valid,y_valid)]\n        fit_model = model.fit( X_train, y_train, \n                               eval_set=eval_set,\n                               eval_metric=gini_xgb,\n                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n                               verbose=False\n                             )\n        print( \"  Best N trees = \", model.best_ntree_limit )\n        print( \"  Best gini = \", model.best_score )\n    else:\n        fit_model = model.fit( X_train, y_train )\n        \n    # Generate validation predictions for this fold\n    pred = fit_model.predict_proba(X_valid)[:,1]\n    print( \"  Gini = \", eval_gini(y_valid, pred) )\n    y_valid_pred.iloc[test_index] = pred\n    \n    # Accumulate test set predictions\n    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n    \n    del X_test, X_train, X_valid, y_train\n    \ny_test_pred /= K  # Average test set predictions\n\nprint( \"\\nGini for full training set:\" )\neval_gini(y, y_valid_pred)","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"4a7980a0-f406-4677-9e6f-24a5ca39f81a","_uuid":"f6c954aff2fda1b4d8675d9f8557b39aa6cf0e77","trusted":true},"cell_type":"code","source":"# Save validation predictions for stacking/ensembling\nval = pd.DataFrame()\nval['id'] = id_train\nval['target'] = y_valid_pred.values\nval.to_csv('xgb_valid.csv', float_format='%.6f', index=False)\nval.shape","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"c5e44c7e-4cf0-4037-ae68-bba89683469c","_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"3fe682ba959d863e216d477f7180d560799478e5","trusted":true},"cell_type":"code","source":"# Create submission file\nsub = pd.DataFrame()\nsub['id'] = id_test\nsub['target'] = y_test_pred\nsub.to_csv('submit.csv', float_format='%.6f', index=False)\nsub.shape","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"5fd0a80c-af7e-410d-8c06-6bec034ec92e","_uuid":"8f0d653c48fe9720e1641a871cfd89a68aec2314","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}