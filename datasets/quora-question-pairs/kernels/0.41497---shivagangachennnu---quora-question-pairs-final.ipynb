{"cells": [{"metadata": {"_uuid": "d98a6e305023a05d2bc9fae7a2b025eaeec0225f", "_cell_guid": "d8bbe49f-f24f-a607-79ef-76955d2a1f3f"}, "outputs": [], "cell_type": "code", "source": ["#importing libraries numpy,pandas,mathplotlib for extracting, modifying and visualizing the data\n", "\n", "import numpy as np \n", "import pandas as pd \n", "import matplotlib.pyplot as plt\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "execution_count": 1}, {"metadata": {"_uuid": "644bd97c9d438ae64cef7aabb387c278c9c5e956", "_cell_guid": "9aea78d4-b1ca-b06e-a794-a04b8043eee6"}, "outputs": [], "cell_type": "code", "source": ["#loading input train file to train\n", "train = pd.read_csv(\"../input/train.csv\")\n", "#loading iput test file to test\n", "test = pd.read_csv(\"../input/test.csv\")\n", "#printing the top\n", "train.head()"], "execution_count": 2}, {"metadata": {"_uuid": "83951624df9392def469b2cbf2c605a25dfc178f", "_cell_guid": "657778b7-c3eb-6a90-b2b4-a2311bdfc2a9"}, "cell_type": "markdown", "source": ["This is how the training data is given. "]}, {"metadata": {"_uuid": "32747d0d7cae69191037875c835a0389c75e6826", "_cell_guid": "88c2983a-a3a4-4d98-ce11-509caa0868b2"}, "outputs": [], "cell_type": "code", "source": ["test.head()"], "execution_count": 3}, {"metadata": {"_uuid": "aef3130ee7756bc79015b10ca03e2c36ee4d932e", "_cell_guid": "1f777703-2302-577e-9998-416f945f3441"}, "cell_type": "markdown", "source": ["The test data only contains questions but not their id's as in train data, as you can see above. "]}, {"metadata": {"_uuid": "42575c2d36a0e6a4721afb1e90a463c690f139b2", "_cell_guid": "f8bcc6a9-4281-9ba0-5f0a-8242ed24a121"}, "outputs": [], "cell_type": "code", "source": ["train.info()"], "execution_count": 4}, {"metadata": {"_uuid": "ed2151c4ee0d14e2314a198c0509297c09ad6898", "_cell_guid": "17d80d7a-7e31-f370-effe-ade7206ebfe8"}, "cell_type": "markdown", "source": ["The training data has 404290 instances. "]}, {"metadata": {"_uuid": "6f086566575002f60d823dae80cc7202d1073568", "_cell_guid": "425fa328-57e6-4e65-91cc-dc808293c15f"}, "outputs": [], "cell_type": "code", "source": ["test.info()"], "execution_count": 5}, {"metadata": {"_uuid": "bb9c09bbaf48967662e82a75e08f7b62c188a2c4", "_cell_guid": "e1d207af-e5cf-a3b7-09a7-e4899d19d889"}, "cell_type": "markdown", "source": ["The test data has 2345796 instances."]}, {"metadata": {"_uuid": "ed648e2c4ad18b82a004b883277c6b4a7d77d521", "_cell_guid": "b15677da-57ed-ce42-bb6a-afb704fd00d7"}, "outputs": [], "cell_type": "code", "source": ["train_duplicate_mean = train['is_duplicate'].mean()\n", "print (\"mean of train data is_duplicate column\",train_duplicate_mean)"], "execution_count": 6}, {"metadata": {"_uuid": "b33f30a7d66d568a974e4979747a1c7332b7ca72", "_cell_guid": "e962f7e6-3102-f786-98c2-6191e36913c7"}, "cell_type": "markdown", "source": ["By finding the mean on the is_duplicate field of train data, we see that about 37% of the train data have pair of questions, which are labeled is_duplicate as 1. "]}, {"metadata": {"_uuid": "7a3dc1681ae0402bf800ff2afe38b68c990364e3", "_cell_guid": "02115075-2a2e-f666-93b9-aa8cce7d1fa9"}, "outputs": [], "cell_type": "code", "source": ["pt = train.groupby('is_duplicate')['id'].count()\n", "pt.plot.bar()"], "execution_count": 7}, {"metadata": {"_uuid": "9df5e8df684d48be570db279884d2e3dc7e4d6f4", "_cell_guid": "9a4aaff7-d9b7-8189-64f5-128b1f442129"}, "cell_type": "markdown", "source": ["The plot shows the is_duplicate distribution in the train data. "]}, {"metadata": {"_uuid": "3b8315bec7e41f205ceb9725d9beadae0f58b66c", "_cell_guid": "d10950bc-6ed8-c93b-1e27-9bf21ade3a51"}, "outputs": [], "cell_type": "code", "source": ["\n", "question_id_1 = train['qid1'].tolist()\n", "question_id_2 = train['qid2'].tolist()\n", "question_id = pd.Series(question_id_1+question_id_2)\n", "plt.figure(figsize=(15,6))\n", "plt.hist(question_id.value_counts(), bins= 30)\n", "plt.yscale('log', nonposy='clip')"], "execution_count": 8}, {"metadata": {"_uuid": "39a1a885ab531a15abbe8fc7858da8edb2a8a8e8", "_cell_guid": "e243a9c9-a8a0-b20c-23b8-484c9a2957ac"}, "cell_type": "markdown", "source": ["By plotting the no. of questions vs no. of occurences of the question, we observe that most of the questions only appear a few times, except very few. "]}, {"metadata": {"_uuid": "b30982ddd18e67d0b46a99a83e5ae9c186287ca6", "collapsed": true, "_cell_guid": "d38631e0-6f37-eee2-c6d3-83071169bcdd"}, "outputs": [], "cell_type": "code", "source": ["from nltk.corpus import stopwords as st\n", "stopwords_set = set(st.words(\"english\"))\n", "\n", "def word_dict(sentence):\n", "    question_words_dict = {}\n", "    for word in sentence.lower().split():\n", "        if word not in stopwords_set:\n", "            question_words_dict[word] = 1\n", "    return question_words_dict\n", "def common_words_percentage(entry):\n", "    question_1_words = word_dict(str(entry['question1']))\n", "    question_2_words = word_dict(str(entry['question2']))\n", "     \n", "    if len(question_1_words) == 0 or len(question_2_words) == 0:\n", "        return 0\n", "    shared_in_q1 = [word for word in question_1_words.keys() if word in question_2_words]\n", "    feature_Ratio = ( 2*len(shared_in_q1) )/(len(question_1_words)+len(question_2_words))\n", "    return feature_Ratio"], "execution_count": 9}, {"metadata": {"_uuid": "b6022a5180f783ab2669b8e8752054c795f72f55", "collapsed": true, "_cell_guid": "43561a09-df10-2b0c-fa0b-4d262e9be955"}, "outputs": [], "cell_type": "code", "source": ["def tfidf_weights(entry):\n", "    question_1_words = word_dict(str(entry['question1']))\n", "    question_2_words = word_dict(str(entry['question2']))\n", "    if len(question_1_words) == 0 or len(question_2_words) == 0:\n", "        return 0\n", "    \n", "    common_wts_1 = [weights.get(w, 0) for w in question_1_words.keys() if w in question_2_words]  \n", "    common_wts_2 = [weights.get(w, 0) for w in question_2_words.keys() if w in question_2_words]\n", "    common_wts = common_wts_1 + common_wts_2\n", "    whole_wts = [weights.get(w, 0) for w in question_1_words] + [weights.get(w, 0) for w in question_2_words]\n", "    \n", "    feature_tfidf = np.sum(common_wts) / np.sum(whole_wts)\n", "    return feature_tfidf"], "execution_count": 10}, {"metadata": {"_uuid": "69ef02d470cba87f39ae88d5f578c7cc54a4c7c4", "collapsed": true, "_cell_guid": "8291f544-c69f-457a-6e84-2a82ee86e424"}, "outputs": [], "cell_type": "code", "source": ["list_of_questions = (train['question1'].str.lower().astype('U').tolist() + train['question2'].str.lower().astype('U').tolist())\n", "\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "vectorizer = TfidfVectorizer(min_df = 50,max_features = 3000000,ngram_range = (1,10))\n", "X = vectorizer.fit_transform(list_of_questions)\n", "idf = vectorizer.idf_\n", "weights = (dict(zip(vectorizer.get_feature_names(), idf)))"], "execution_count": 11}, {"metadata": {"_uuid": "f975d51961e3eec9a03f224bca81ddb93f918457", "_cell_guid": "db115ace-a429-5c73-8b5e-5ae832c55603"}, "outputs": [], "cell_type": "code", "source": ["X_TrainData = pd.DataFrame()\n", "X_TestData = pd.DataFrame()\n", "X_TrainData['common_word_percent'] = train.apply(common_words_percentage, axis=1, raw=True)\n", "X_TrainData['feature_ifidf'] = train.apply(tfidf_weights, axis = 1, raw = True)\n", "Y_TrainData = train['is_duplicate'].values\n", "X_TestData['common_word_percent'] = test.apply(common_words_percentage, axis = 1, raw = True)\n", "X_TestData['feature_ifidf'] = test.apply(tfidf_weights, axis = 1, raw = True)"], "execution_count": 12}, {"metadata": {"_uuid": "610715232ca55667bb5bc8e20be5699567f54512", "collapsed": true, "_cell_guid": "74ab10da-131d-da09-f1b8-34d534ac223a"}, "outputs": [], "cell_type": "code", "source": ["import nltk\n", "def jaccard_similarity_coefficient(row):\n", "    if (type(row['question1']) is str) and (type(row['question2']) is str):\n", "        words_1 = row['question1'].lower().split()\n", "        words_2 = row['question2'].lower().split()\n", "    else:\n", "        words_1 = nltk.word_tokenize(str(row['question1']))\n", "        words_2 = nltk.word_tokenize(str(row['question2']))\n", "   \n", "    joint_words = set(words_1).union(set(words_2))\n", "    intersection_words = set(words_1).intersection(set(words_2))\n", "    return len(intersection_words)/len(joint_words)"], "execution_count": 13}, {"metadata": {"_uuid": "bedc6fd25d7cc8e13da6adf3b53f3313d62e1d5d", "collapsed": true, "_cell_guid": "8881b656-ef74-29ee-376d-f8e5e68b9fd1"}, "outputs": [], "cell_type": "code", "source": ["train = train.fillna(\"\")"], "execution_count": null}, {"metadata": {"_uuid": "0dcd06be93fa62d0c0c958b9d3368310414e6419", "collapsed": true, "_cell_guid": "d81f1878-e045-c343-f156-0ea216e422fb"}, "outputs": [], "cell_type": "code", "source": ["X_TrainData['Jacard_Distance'] = train.apply(jaccard_similarity_coefficient, axis = 1, raw = True)\n", "X_TestData['Jacard_Distance'] = test.apply(jaccard_similarity_coefficient, axis = 1, raw = True)"], "execution_count": null}, {"metadata": {"_uuid": "35f1fb43140acd5d3d55396b82d5e98f56e04a50", "collapsed": true, "_cell_guid": "7884b847-bf83-1d37-298c-b9dc40780f22"}, "outputs": [], "cell_type": "code", "source": ["\n", "from sklearn.metrics.pairwise import cosine_similarity as cs\n", "import re, math\n", "from collections import Counter\n", "\n", "WORD = re.compile(r'\\w+')\n", "def _cosine_similarity(vector_1, vector_2):\n", "     intersection = set(vector_1.keys()) & set(vector_2.keys())\n", "     numerator = sum([vector_1[x] * vector_2[x] for x in intersection])\n", "\n", "     sum1 = sum([vector_1[x]**2 for x in vector_1.keys()])\n", "     sum2 = sum([vector_2[x]**2 for x in vector_2.keys()])\n", "     denominator = math.sqrt(sum1) * math.sqrt(sum2)\n", "\n", "     if not denominator:\n", "        return 0.0\n", "     else:\n", "        return float(numerator) / denominator\n", "\n", "def sentence_transform(sentence):\n", "     words = WORD.findall(sentence)\n", "     return Counter(words)\n", "\n", "def cosine_sim(row):\n", "    vector1 = sentence_transform(str(row['question1']))\n", "    vector2 = sentence_transform(str(row['question2']))\n", "    sim = _cosine_similarity(vector1,vector2)\n", "    return sim\n", "\n", "X_TrainData['cosine_sim'] = train.apply(cosine_sim,axis = 1,raw = True )"], "execution_count": null}, {"metadata": {"_uuid": "c9c7123e2e73e3b8bcd544e6eedd0939a8ea787d", "collapsed": true, "_cell_guid": "c10381d3-da99-44a9-54c0-525cb7239696"}, "outputs": [], "cell_type": "code", "source": ["X_TestData['cosine_sim'] = test.apply(cosine_sim,axis = 1,raw = True )"], "execution_count": null}, {"metadata": {"_uuid": "75f91af808b9001f5c0df44ee701c19d0378ea0f", "collapsed": true, "_cell_guid": "54b267dd-fc99-72e1-e1b9-bb291e49c2e0"}, "outputs": [], "cell_type": "code", "source": ["\n", "X_TrainData"], "execution_count": null}, {"metadata": {"_uuid": "33b063ca82fd51cfb4720b4cc39891c783d6ac2f", "collapsed": true, "_cell_guid": "15994432-ced5-6df1-1f53-5704961146ff"}, "outputs": [], "cell_type": "code", "source": ["from sklearn.cross_validation import train_test_split\n", "\n", "X_TrainData, X_ValidData, Y_TrainData, Y_ValidData = train_test_split(X_TrainData, Y_TrainData, test_size=0.20, random_state=4242)"], "execution_count": null}, {"metadata": {"_uuid": "6cf5951579521c7eaf094faf6eb894bce81f5096", "collapsed": true, "_cell_guid": "62d37261-8ac9-1dcc-ccc3-2db02726033f"}, "outputs": [], "cell_type": "code", "source": ["import xgboost as xgb\n", "\n", "xg_TrainData = xgb.DMatrix(X_TrainData, label=Y_TrainData)\n", "xg_ValidData = xgb.DMatrix(X_ValidData, label=Y_ValidData)\n", "\n", "watchlist = [(xg_TrainData, 'train'), (xg_ValidData, 'valid')]\n", "\n", "bst = xgb.train({'objective':'binary:logistic','eval_metric':'logloss','eta':0.02,'max_depth' :5}, xg_TrainData, 500, watchlist, early_stopping_rounds=50, verbose_eval=10)"], "execution_count": null}, {"metadata": {"_uuid": "92e6ca626bf222c91d9233e3b1b1671e2813adda", "collapsed": true, "_cell_guid": "fa825ef9-c56d-d1a3-5d9e-ca01afc3110d"}, "outputs": [], "cell_type": "code", "source": ["X_TestData.info()"], "execution_count": null}, {"metadata": {"_uuid": "00cda7a4460206cc7cbee51b08bcacb826f1d663", "collapsed": true, "_cell_guid": "77504acf-2d85-1f51-bd4a-fd5b0194f973"}, "outputs": [], "cell_type": "code", "source": ["xg_TestData = xgb.DMatrix(X_TestData)\n", "xg_ValidData = xgb.DMatrix(X_ValidData)\n", "\n", "Predict_TestData = bst.predict(xg_TestData)\n", "Predict_ValidData = bst.predict(xg_ValidData)\n", "\n"], "execution_count": null}, {"metadata": {"_uuid": "44aae37318a44e063b4eb348c427639262a1a1dc", "collapsed": true, "_cell_guid": "ca5687fe-2acb-3a5a-cf4c-1fde2b2b2439"}, "outputs": [], "cell_type": "code", "source": ["from sklearn.metrics import precision_recall_curve, auc, roc_curve\n", "fpr, tpr, _ = roc_curve(Y_ValidData, Predict_ValidData)\n", "roc_area = auc(fpr, tpr)\n", "plt.plot(fpr, tpr, lw=1)\n", "np.round(roc_area, 10)"], "execution_count": null}, {"metadata": {"_uuid": "85c53e140f426bea3e5c1817ab7a283c66acca07", "collapsed": true, "_cell_guid": "9f54b908-a6c2-8f5b-e88c-798be694c70f"}, "outputs": [], "cell_type": "code", "source": ["precison, recall, _ = precision_recall_curve(Y_ValidData, Predict_ValidData)\n", "plt.figure(figsize=(10,5))\n", "\n", "plt.plot(recall, precison)\n", "plt.xlabel('Recall')\n", "plt.ylabel('Precision')\n", "auc(recall, precison)"], "execution_count": null}, {"metadata": {"_uuid": "d71837ace4be392b36474e934ee6e122c2b5b320", "collapsed": true, "_cell_guid": "c79288af-5194-7867-2c20-e0a8ce2721bc"}, "outputs": [], "cell_type": "code", "source": ["result = pd.DataFrame()\n", "result['test_id'] = test['test_id']\n", "result['is_duplicate'] = Predict_TestData\n", "result.to_csv('result.csv', index=False)"], "execution_count": null}, {"metadata": {"_uuid": "12f23cab86ee7e039ce03c119bdfa264aaefda0e", "collapsed": true, "_cell_guid": "a4f6855a-56bf-4860-d864-5d2d8bcd1108"}, "outputs": [], "cell_type": "code", "source": ["Predict_TestData"], "execution_count": null}], "nbformat": 4, "metadata": {"_is_fork": false, "_change_revision": 0, "language_info": {"pygments_lexer": "ipython3", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3", "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python"}, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}}, "nbformat_minor": 1}