{"metadata": {"language_info": {"name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.4", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "mimetype": "text/x-python"}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3"}}, "nbformat": 4, "cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "ade8c3fd-83ce-40a3-a7dd-72d3d554d05e", "_uuid": "d462b4748ab487931776747c82158f4f0a2db21a"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "import numpy as np\n", "import pandas as pd\n", "import itertools\n", "from sklearn import preprocessing"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["df = pd.read_csv(\"../input/loan.csv\", low_memory=False)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["def duplicate_columns(df, return_dataframe = False, verbose = True):\n", "    '''\n", "        a function to detect and possibly remove duplicated columns for a pandas dataframe\n", "    '''\n", "    from pandas.core.common import array_equivalent\n", "    # group columns by dtypes, only the columns of the same dtypes can be duplicate of each other\n", "    groups = df.columns.to_series().groupby(df.dtypes).groups\n", "    duplicated_columns = []\n", "\n", "    for dtype, col_names in groups.items():\n", "        column_values = df[col_names]\n", "        num_columns = len(col_names)\n", " # find duplicated columns by checking pairs of columns, store first column name if duplicate exist \n", "        for i in range(num_columns):\n", "            column_i = column_values.iloc[:,i].values\n", "            for j in range(i + 1, num_columns):\n", "                column_j = column_values.iloc[:,j].values\n", "                if array_equivalent(column_i, column_j):\n", "                    if verbose: \n", "                        print(\"column {} is a duplicate of column {}\".format(col_names[i], col_names[j]))\n", "                    duplicated_columns.append(col_names[i])\n", "                    break\n", "    if not return_dataframe:\n", "        # return the column names of those duplicated exists\n", "        return duplicated_columns\n", "    else:\n", "        # return a dataframe with duplicated columns dropped \n", "        return df.drop(labels = duplicated_columns, axis = 1)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"scrolled": true}, "source": ["df.columns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Loan defaults: \n", "* Current loans - may be good so far, but they may still default in future. For this modelling, let's drop \"current\" loans.\n", "* We'll also drop the many duplicate columns"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df.shape"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df['loan_status'].value_counts(normalize=True)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df = df.loc[df['loan_status']!=\"Current\"]\n", "df.shape"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df = duplicate_columns(df, return_dataframe = True)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df.shape"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"scrolled": false}, "source": ["df.head()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["vc = df.member_id.value_counts()\n", "print(\"# members: \", len(vc[vc>0]))\n", "print(\"# reoccuring members: \", len(vc[vc>1]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### It looks like all member IDs are unique - we have no reoccuring loaners (Which is very unrealistic = no credit history..)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["df.drop([\"id\",'url'],axis=1,inplace=True)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### new target column"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["df['loan_Default'] = int(0)\n", "for index, value in df.loan_status.iteritems():\n", "    if value == 'Default':\n", "        df.set_value(index,'loan_Default',int(1))\n", "    if value == 'Charged Off':\n", "        df.set_value(index, 'loan_Default',int(1))\n", "    if value == 'Late (31-120 days)':\n", "        df.set_value(index, 'loan_Default',int(1))    \n", "    if value == 'Late (16-30 days)':\n", "        df.set_value(index, 'loan_Default',int(1))\n", "    if value == 'Does not meet the credit policy. Status:Charged Off':\n", "        df.set_value(index, 'loan_Default',int(1))    "]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {}, "source": ["df['loan_Default'] .describe()"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["# Drop original label column\n", "df.drop([\"loan_status\"],axis=1,inplace=True)"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["df.sample(5000).to_csv(\"LC_defaultLoansK_5k.csv.gz\",index=False,compression=\"gzip\")"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true}, "source": ["df.sample(250000).to_csv(\"LC_defaultLoansK_250k.csv.gz\",index=False,compression=\"gzip\")"]}], "nbformat_minor": 1}