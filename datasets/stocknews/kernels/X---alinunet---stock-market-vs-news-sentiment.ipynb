{"cells": [{"metadata": {"_uuid": "b654a7b170a65380256466614435b7ec4bd41197", "_cell_guid": "61b5b1a6-524c-4c82-be91-399cf861c86f"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "outputs": [], "execution_count": 1}, {"metadata": {"_uuid": "c5535df676adaaa437a1d5a9931910cb8581870a", "_cell_guid": "41efb325-9891-494f-b252-a2146a39ce56"}, "cell_type": "markdown", "source": ["In this Notebook I want to explore the sentiments of top 20 headlines as features to predict the stockmarket. First action to read the file and save it in a Pandas dataframe."]}, {"metadata": {"_uuid": "2501bcc86fe6bb02f01ef1b269fc3e6c64e59baa", "_cell_guid": "f65dd199-9b2c-493a-89df-2673db5e5adb", "collapsed": true}, "source": ["df_news = pd.read_csv('../input/Combined_News_DJIA.csv')"], "cell_type": "code", "outputs": [], "execution_count": 2}, {"metadata": {"_uuid": "7a25a7e34ddeb7f1ce65e14ac1232e0b2f38d073", "_cell_guid": "e50bf7d9-7d8c-425b-8ffb-bbc0a0265183"}, "cell_type": "markdown", "source": ["After reading the .csv file, I use \"textblob\" to assign sentiment to each of the headlines on each row. (I took the functions from one stackoverflow answer. Not rocket science but why invent the wheels?)"]}, {"metadata": {"_uuid": "d493ce47666ad679eaf046f95acbed868eb988af", "_cell_guid": "a61e75e7-a999-44ce-b2fd-e08b7b07b7c0", "collapsed": true}, "source": ["from textblob import TextBlob\n", "import re\n", "\n", "def clean_headline(headline):\n", "    '''\n", "    Utility function to clean the text in a tweet by removing \n", "    links and special characters using regex.\n", "    '''\n", "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", headline).split())\n", "\n", "def analize_sentiment(headline):\n", "    '''\n", "    Utility function to classify the polarity of a tweet\n", "    using textblob.\n", "    '''\n", "    analysis = TextBlob(clean_headline(headline))\n", "    if analysis.sentiment.polarity > 0:\n", "        return 1\n", "    elif analysis.sentiment.polarity == 0:\n", "        return 0\n", "    else:\n", "        return -1"], "cell_type": "code", "outputs": [], "execution_count": 3}, {"metadata": {"_uuid": "a401cdeca09dfaa010533e2f49a7223bdad9d407", "_cell_guid": "90d545be-e847-4222-8bbb-4db40a45d394"}, "source": ["topn_headlines = 20\n", "top_num = range(1,topn_headlines+1)\n", "dataframe_col = 'sum_sent' + str(max(top_num))\n", "df_news[dataframe_col] = 0\n", "for ii in top_num:\n", "    read_col = 'Top' + str(ii)\n", "    write_col = 'Top' + str(ii) + '_sent'\n", "    df_news[write_col] = np.array([ analize_sentiment(headline) for headline in df_news[read_col] ])\n", "    df_news[dataframe_col] = df_news[dataframe_col] + df_news[write_col]\n", "df_news"], "cell_type": "code", "outputs": [], "execution_count": 4}, {"metadata": {"_uuid": "6b4e109ac0e70c38704029de63466d2b13d156e1", "_cell_guid": "d5a8bb10-d55d-47ec-abc8-e6c238aea17d"}, "cell_type": "markdown", "source": ["Now we have the sentiment of all the headlines as columns in each row. The next step is to use the sentiments of the headlineas as a vector of length 20 as features and the labels to train a classifier."]}, {"metadata": {"_uuid": "578f5cc48e7504d00b09ff11d81e5f63ead57654", "_cell_guid": "79a606d4-f0d3-436c-82e1-4b780c483b34"}, "source": ["headlines_columns = range(1,21)\n", "X_data_list = []\n", "for rows in range(len(df_news)):\n", "    X_dataTemp = []\n", "    for i in range(1,21):\n", "        X_dataTemp.append(df_news.ix[rows,'Top'+str(i)+'_sent'])\n", "    X_data_list.append(X_dataTemp)\n", "X_data = np.array(X_data_list)\n", "y_label = df_news['Label'] "], "cell_type": "code", "outputs": [], "execution_count": 5}, {"metadata": {"_uuid": "306e6b5811ed1441fc4c649b33007f7c3a7061a8", "_cell_guid": "39e68dca-b868-44f0-b943-81236f7e0530", "collapsed": true}, "source": ["# break the dataset to to 65% training and 35% test.\n", "train_sample_perc = .65\n", "n_samples = len(y_label)\n", "X_train = X_data_list[:int(train_sample_perc * n_samples)]\n", "y_train = y_label[:int(train_sample_perc * n_samples)]\n", "X_test = X_data_list[int(train_sample_perc * n_samples):]\n", "y_test = y_label[int(train_sample_perc * n_samples):]"], "cell_type": "code", "outputs": [], "execution_count": 6}, {"metadata": {"_uuid": "84fb18a3aac494a49bddb74e7920cff1be5f9574", "_cell_guid": "57eb0e7c-b6cf-4ccd-9575-697808b67bf1"}, "cell_type": "markdown", "source": ["Now let's throw bunch of classifiers at the dataset in the voting classifier mode and see can we get out of it! (not scientific but proves that probably blind use of sklearn won't get us far!)"]}, {"metadata": {"_uuid": "9522bbf94640b6a281a56912428b9fb5408fe192", "_cell_guid": "83519539-0bc8-4727-ae4f-3ad598e5f011", "collapsed": true}, "source": ["from sklearn import datasets, neighbors, linear_model\n", "from sklearn.metrics import (brier_score_loss, precision_score, recall_score,\n", "                             f1_score,accuracy_score,confusion_matrix,classification_report)\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n", "from sklearn.svm import SVC\n", "logistic = LogisticRegression(random_state=1)\n", "rf = RandomForestClassifier(random_state=1)\n", "gnb = GaussianNB()\n", "svm = SVC(random_state=1,probability=True)"], "cell_type": "code", "outputs": [], "execution_count": 7}, {"metadata": {"_uuid": "a563ae170530bc8a6b321a8ea4142f2a1e4ccfe3", "_cell_guid": "0cf8f188-93c3-4821-927c-4ed1c44b0023"}, "source": ["eclf1 = VotingClassifier(estimators=[\n", "...         ('lr', logistic),('gnb',gnb),('svm',svm)], voting='soft', weights=[1,1,1],\n", "...        flatten_transform=True)\n", "eclf1 = eclf1.fit(X_train, y_train)\n", "y_predict_vote = eclf1.predict(X_test)\n", "print  (classification_report(y_predict_vote,y_test))\n", "print (accuracy_score(y_predict_vote,y_test))"], "cell_type": "code", "outputs": [], "execution_count": 8}, {"metadata": {"_uuid": "709ebd6756ce82de361c2dc2147d7b766ad4693d", "_cell_guid": "2328e125-68e5-43d9-a200-bb95c9d6fa96"}, "cell_type": "markdown", "source": ["The result is not good! Why?\n", "1. The training and test data is highly imbalanced toward class1 --> to improve maybe we should down-sample the class 1\n", "2. We can also devide the dataset based on quarter/season/begining of the year/end of the year and have four different model for each time period.\n", "3. We can also augment the BOW model with sentiment vectors and examine the performance against pure BOW or sentiment vector alone.\n", "4. Also, considering the delayed version of sentiment vectors as features (or even adding memory to the features ,e.g. lstm maybe??)"]}, {"metadata": {"_uuid": "f2f39e6ef2718c5a8260da405aa83c1c4bc75758", "_cell_guid": "a1568225-dcb3-46e6-8af3-53a788e43a8a", "collapsed": true}, "source": [], "cell_type": "code", "outputs": [], "execution_count": null}], "metadata": {"language_info": {"version": "3.6.1", "pygments_lexer": "ipython3", "mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat_minor": 1, "nbformat": 4}