{"cells": [{"metadata": {"_cell_guid": "1f0801f2-9eb3-4fe5-b631-307058c15bd3", "_uuid": "7c2db89f6afffdbf1ae96bf6b815e54c675c0c2a"}, "cell_type": "markdown", "source": ["## Definitions"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "80d895e2-6ee5-4916-829b-f5127058189e", "_uuid": "70949383b959718476cbbba83a069e6a25c7041a"}, "source": ["YEAR_SHIFT = 364 #number of days in a year, use multiple of 7 to be able to capture week behavior\n", "PERIOD = 49 #number of days for median comparison\n", "PREDICT_PERIOD = 75 #number of days which will be predicted\n", "\n", "#evaluation function\n", "def smape(x, y):\n", "    if x == y:\n", "        return 0\n", "    else:\n", "        return np.abs(x-y)/(x+y)\n", "    \n", "#median function ignoring nans\n", "def safe_median(s):\n", "    return np.median([x for x in s if ~np.isnan(x)])"]}, {"metadata": {"_cell_guid": "9c9f32d2-17ee-4e81-9f63-77d9fc049188", "_uuid": "01502a8f118bc374a793ebd7323acda2522c9086"}, "cell_type": "markdown", "source": ["## Prepare training data"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "4e4a8dd0-ac2e-4396-9943-c18fa8d68c89", "_uuid": "122f75b7f597ced050887e841d97059fc9186088"}, "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "train = pd.read_csv(\"../input/train_2.csv\")\n", "train = pd.melt(train[list(train.columns[-(YEAR_SHIFT + 2*PERIOD):])+['Page']], id_vars='Page', var_name='date', value_name='Visits')\n", "train['date'] = train['date'].astype('datetime64[ns]')\n", "\n", "LAST_TRAIN_DAY = train['date'].max()\n", "\n", "train = train.groupby(['Page'])[\"Visits\"].apply(lambda x: list(x))"]}, {"metadata": {"_cell_guid": "f9ea05ee-a52e-4a05-9764-c171d47e2331", "_uuid": "53523f5e4d681eb1d60a6c8436456717d351ba8f"}, "cell_type": "markdown", "source": ["## Make the predictions"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"_cell_guid": "065dc7e1-789c-4d16-bcac-41cc3c496e30", "_uuid": "ca0e0e4e6635b562e0f05cecd267042ecfacdd3a"}, "source": ["pred_dict = {}\n", "\n", "count = 0\n", "scount = 0\n", "\n", "for page, row in zip(train.index, train):\n", "    last_month = np.array(row[-PERIOD:])\n", "    slast_month = np.array(row[-2*PERIOD:-PERIOD])\n", "    prev_last_month = np.array(row[PERIOD:2*PERIOD])\n", "    prev_slast_month = np.array(row[:PERIOD])\n", "    \n", "    use_last_year = False\n", "    if ~np.isnan(row[0]):\n", "        #calculate yearly prediction error\n", "        year_increase = np.median(slast_month)/np.median(prev_slast_month)\n", "        year_error = np.sum(list(map(lambda x: smape(x[0], x[1]), zip(last_month, prev_last_month * year_increase))))\n", "        \n", "        #calculate monthly prediction error\n", "        smedian = np.median(slast_month)\n", "        month_error = np.sum(list(map(lambda x: smape(x, smedian), last_month)))\n", "        \n", "        #check if yearly prediction is better than median prediction in the previous period\n", "        error_diff = (month_error - year_error)/PERIOD\n", "        if error_diff > 0.1:\n", "            scount += 1\n", "            use_last_year = True\n", "    \n", "    if use_last_year:\n", "        last_year = np.array(row[2*PERIOD:2*PERIOD+PREDICT_PERIOD])\n", "        preds = last_year * year_increase #consider yearly increase while using the last years visits\n", "    else:\n", "        preds = [0]*PREDICT_PERIOD\n", "        windows = np.array([2, 3, 4, 7, 11, 18, 29, 47])*7 #kind of fibonacci\n", "        medians = np.zeros((len(windows), 7))\n", "        for i in range(7):\n", "            for k in range(len(windows)):\n", "                array = np.array(row[-windows[k]:]).reshape(-1, 7)\n", "                # use 3-day window. for example, Friday: [Thursday, Friday, Saturday]\n", "                s = np.hstack([array[:, (i-1)%7], array[:, i], array[:, (i+1)%7]]).reshape(-1)\n", "                medians[k, i] = safe_median(s)\n", "        for i in range(PREDICT_PERIOD):\n", "            preds[i] = safe_median(medians[:, i%7])\n", "                \n", "    pred_dict[page] = preds\n", "    \n", "    count += 1        \n", "    if count % 1000 == 0:\n", "        print(count, scount)\n", "\n", "del train\n", "print(\"Yearly prediction is done on the percentage:\", scount/count)"]}, {"metadata": {"_cell_guid": "314cc844-e8a3-4351-86b8-880a6b94dd79", "_uuid": "0d4b009469ff55cfbe2157a859270e8029e65e6a"}, "cell_type": "markdown", "source": ["## Prepare the submission"]}, {"outputs": [], "cell_type": "code", "execution_count": null, "metadata": {"collapsed": true, "_cell_guid": "a7aeba74-189d-4495-ad11-b3e9be043576", "_uuid": "018ab8e8d9b89c92d9e8d15b38db53bb94249490"}, "source": ["test = pd.read_csv(\"../input/key_2.csv\")\n", "test['date'] = test.Page.apply(lambda a: a[-10:])\n", "test['Page'] = test.Page.apply(lambda a: a[:-11])\n", "test['date'] = test['date'].astype('datetime64[ns]')\n", "\n", "test[\"date\"] = test[\"date\"].apply(lambda x: int((x - LAST_TRAIN_DAY).days) - 1)\n", "\n", "def func(row):\n", "    return pred_dict[row[\"Page\"]][row[\"date\"]]\n", "\n", "test[\"Visits\"] = test.apply(func, axis=1)\n", "\n", "test.loc[test.Visits.isnull(), 'Visits'] = 0\n", "test['Visits'] = test['Visits'].values + test['Visits'].values*0.03 # overestimating is usually better for smape\n", "test.Visits = test.Visits.round(4)\n", "#test[['Id','Visits']].to_csv('submission.csv', index=False)"]}], "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "codemirror_mode": {"name": "ipython", "version": 3}, "version": "3.6.3"}}, "nbformat_minor": 1, "nbformat": 4}