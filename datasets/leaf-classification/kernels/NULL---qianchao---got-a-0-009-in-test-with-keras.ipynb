{"metadata": {"language_info": {"nbconvert_exporter": "python", "name": "python", "codemirror_mode": {"version": 3, "name": "ipython"}, "version": "3.6.3", "mimetype": "text/x-python", "file_extension": ".py", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat_minor": 1, "cells": [{"metadata": {"_uuid": "39eece483c5d0808e57bae6e0e5d719d34d902c2", "_cell_guid": "97e9c07d-a7de-48d5-b33d-488c2a223e90"}, "outputs": [], "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import os\n", "\n", "import pandas as pd\n", "import numpy as np\n", "from sklearn.preprocessing import LabelEncoder\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.model_selection import StratifiedShuffleSplit\n", "\n", "from keras.utils.np_utils import to_categorical\n", "from keras.preprocessing.image import img_to_array, load_img\n", "\n", "root = '../input'\n", "np.random.seed(2016)\n", "split_random_state = 7\n", "split = .9\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "cell_type": "code", "execution_count": 4}, {"metadata": {}, "source": [" I found [note](https://www.kaggle.com/abhmul/keras-convnet-lb-0-0052-w-visualization) this code was not useable, so I modify the code , Now it can run again"], "cell_type": "markdown"}, {"metadata": {}, "outputs": [], "source": ["def load_numeric_training(standardize=True):\n", "    \"\"\"\n", "    Loads the pre-extracted features for the training data\n", "    and returns a tuple of the image ids, the data, and the labels\n", "    \"\"\"\n", "    # Read data from the CSV file\n", "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n", "    ID = data.pop('id')\n", "\n", "    # Since the labels are textual, so we encode them categorically\n", "    y = data.pop('species')\n", "    y = LabelEncoder().fit(y).transform(y)\n", "    # standardize the data by setting the mean to 0 and std to 1\n", "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n", "\n", "    return ID, X, y\n", "\n", "\n", "def load_numeric_test(standardize=True):\n", "    \"\"\"\n", "    Loads the pre-extracted features for the test data\n", "    and returns a tuple of the image ids, the data\n", "    \"\"\"\n", "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n", "    ID = test.pop('id')\n", "    # standardize the data by setting the mean to 0 and std to 1\n", "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n", "    return ID, test\n", "\n", "\n", "def resize_img(img, max_dim=96):\n", "    \"\"\"\n", "    Resize the image to so the maximum side is of size max_dim\n", "    Returns a new image of the right size\n", "    \"\"\"\n", "    # Get the axis with the larger dimension\n", "    max_ax = max((0, 1), key=lambda i: img.size[i])\n", "    # Scale both axes so the image's largest dimension is max_dim\n", "    scale = max_dim / float(img.size[max_ax])\n", "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n", "\n", "\n", "def load_image_data(ids, max_dim=96, center=True):\n", "    \"\"\"\n", "    Takes as input an array of image ids and loads the images as numpy\n", "    arrays with the images resized so the longest side is max-dim length.\n", "    If center is True, then will place the image in the center of\n", "    the output array, otherwise it will be placed at the top-left corner.\n", "    \"\"\"\n", "    # Initialize the output array\n", "    # NOTE: Theano users comment line below and\n", "    X = np.empty((len(ids), max_dim, max_dim, 1))\n", "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n", "    for i, idee in enumerate(ids):\n", "        # Turn the image into an array\n", "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n", "        x = img_to_array(x)\n", "        # Get the corners of the bounding box for the image\n", "        # NOTE: Theano users comment the two lines below and\n", "        length = x.shape[0]\n", "        width = x.shape[1]\n", "        # length = x.shape[1] # uncomment this\n", "        # width = x.shape[2] # uncomment this\n", "        if center:\n", "            h1 = int((max_dim - length) / 2)\n", "            h2 = h1 + length\n", "            w1 = int((max_dim - width) / 2)\n", "            w2 = w1 + width\n", "        else:\n", "            h1, w1 = 0, 0\n", "            h2, w2 = (length, width)\n", "        # Insert into image matrix\n", "        # NOTE: Theano users comment line below and\n", "        X[i, h1:h2, w1:w2, 0:1] = x\n", "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n", "    # Scale the array values so they are between 0 and 1\n", "    return np.around(X / 255.0)\n", "\n", "\n", "def load_train_data(split=split, random_state=None):\n", "    \"\"\"\n", "    Loads the pre-extracted feature and image training data and\n", "    splits them into training and cross-validation.\n", "    Returns one tuple for the training data and one for the validation\n", "    data. Each tuple is in the order pre-extracted features, images,\n", "    and labels.\n", "    \"\"\"\n", "    # Load the pre-extracted features\n", "    ID, X_num_tr, y = load_numeric_training()\n", "    # Load the image data\n", "    X_img_tr = load_image_data(ID)\n", "    # Split them into validation and cross-validation\n", "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n", "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n", "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n", "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n", "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n", "\n", "\n", "def load_test_data():\n", "    \"\"\"\n", "    Loads the pre-extracted feature and image test data.\n", "    Returns a tuple in the order ids, pre-extracted features,\n", "    and images.\n", "    \"\"\"\n", "    # Load the pre-extracted features\n", "    ID, X_num_te = load_numeric_test()\n", "    # Load the image data\n", "    X_img_te = load_image_data(ID)\n", "    return ID, X_num_te, X_img_te\n", "\n", "print('Loading the training data...')\n", "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n", "y_tr_cat = to_categorical(y_tr)\n", "y_val_cat = to_categorical(y_val)\n", "print('Training data loaded!')"], "cell_type": "code", "execution_count": 5}, {"metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n", "\n", "class ImageDataGenerator2(ImageDataGenerator):\n", "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n", "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n", "        return NumpyArrayIterator2(\n", "            X, y, self,\n", "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n", "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n", "\n", "class NumpyArrayIterator2(NumpyArrayIterator):\n", "    def next(self):\n", "        with self.lock:\n", "            self.my_index_array = next(self.index_generator)\n", "            return self._get_batches_of_transformed_samples(self.my_index_array)\n", "        \n"], "cell_type": "code", "execution_count": 9}, {"metadata": {}, "outputs": [], "source": ["print('Creating Data Augmenter...')\n", "imgen = ImageDataGenerator2(rotation_range=20, zoom_range=0.2, horizontal_flip=True, vertical_flip=True, fill_mode='nearest')\n", "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n", "print('Finished making data augmenter...')"], "cell_type": "code", "execution_count": 10}, {"metadata": {}, "outputs": [], "source": ["from keras.models import Model\n", "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten, Input, concatenate\n", "\n", "\n", "def combined_model():\n", "\n", "    # Define the image input\n", "    image = Input(shape=(96, 96, 1), name='image')\n", "    # Pass it through the first convolutional layer\n", "    x = Conv2D(8, (5, 5), input_shape=(96, 96, 1), padding='same')(image)\n", "    x = (Activation('relu'))(x)\n", "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n", "\n", "    # Now through the second convolutional layer\n", "    x = (Conv2D(32, (5, 5), padding='same'))(x)\n", "    x = (Activation('relu'))(x)\n", "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n", "\n", "    # Flatten our array\n", "    x = Flatten()(x)\n", "    # Define the pre-extracted feature input\n", "    numerical = Input(shape=(192,), name='numerical')\n", "    # Concatenate the output of our convnet with our pre-extracted feature input\n", "    concatenated = concatenate([x, numerical], axis=-1)\n", "\n", "    # Add a fully connected layer just like in a normal MLP\n", "    x = Dense(100, activation='relu')(concatenated)\n", "    x = Dropout(.5)(x)\n", "\n", "    # Get the final output\n", "    out = Dense(99, activation='softmax')(x)\n", "    # How we create models with the Functional API\n", "    model = Model(input=[image, numerical], output=out)\n", "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n", "\n", "    return model"], "cell_type": "code", "execution_count": 12}, {"metadata": {}, "outputs": [], "source": ["print('Creating the model...')\n", "model = combined_model()\n", "print('Model created!')"], "cell_type": "code", "execution_count": 13}, {"metadata": {"collapsed": true}, "outputs": [], "source": ["from keras.callbacks import ModelCheckpoint\n", "from keras.models import load_model\n", "\n", "\n", "def combined_generator(imgen, X):\n", "    \"\"\"\n", "    A generator to train our keras neural network. It\n", "    takes the image augmenter generator and the array\n", "    of the pre-extracted features.\n", "    It yields a minibatch and will run indefinitely\n", "    \"\"\"\n", "    while True:\n", "        for i in range(X.shape[0]):\n", "            # Get the image batch and labels\n", "            batch_img, batch_y = next(imgen)\n", "            # This is where that change to the source code we\n", "            # made will come in handy. We can now access the indicies\n", "            # of the images that imgen gave us.\n", "            ############################################\n", "            x = X[imgen.my_index_array]\n", "            #############################################\n", "            yield [batch_img, x], batch_y"], "cell_type": "code", "execution_count": 14}, {"metadata": {}, "outputs": [], "source": ["# autosave best Model\n", "best_model_file = \"leafnet.h5\"\n", "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n", "\n", "print('Training model...')\n", "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n", "                              samples_per_epoch=X_num_tr.shape[0],\n", "                              nb_epoch=10,\n", "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n", "                              nb_val_samples=X_num_val.shape[0],\n", "                              verbose=0,\n", "                              callbacks=[best_model])\n", "\n", "print('Loading the best model...')\n", "model = load_model(best_model_file)\n", "print('Best Model loaded!')"], "cell_type": "code", "execution_count": 15}, {"metadata": {}, "outputs": [], "source": ["# Get the names of the column headers\n", "LABELS = sorted(pd.read_csv(os.path.join(root, 'train.csv')).species.unique())\n", "\n", "index, test, X_img_te = load_test_data()\n", "\n", "yPred_proba = model.predict([X_img_te, test])\n", "\n", "# Converting the test predictions in a dataframe as depicted by sample submission\n", "yPred = pd.DataFrame(yPred_proba,index=index,columns=LABELS)\n", "\n", "print('Creating and writing submission...')\n", "fp = open('submit.csv', 'w')\n", "fp.write(yPred.to_csv())\n", "print('Finished writing submission')\n", "# Display the submission\n", "yPred.tail()"], "cell_type": "code", "execution_count": 16}, {"metadata": {}, "outputs": [], "source": ["from math import sqrt\n", "\n", "import matplotlib.pyplot as plt\n", "from keras import backend as K\n", "\n", "NUM_LEAVES = 3\n", "model_fn = 'leafnet.h5'\n", "\n", "# Function by gcalmettes from http://stackoverflow.com/questions/11159436/multiple-figures-in-a-single-window\n", "def plot_figures(figures, nrows = 1, ncols=1, titles=False):\n", "    \"\"\"Plot a dictionary of figures.\n", "\n", "    Parameters\n", "    ----------\n", "    figures : <title, figure> dictionary\n", "    ncols : number of columns of subplots wanted in the display\n", "    nrows : number of rows of subplots wanted in the figure\n", "    \"\"\"\n", "\n", "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows)\n", "    for ind,title in enumerate(sorted(figures.keys(), key=lambda s: int(s[3:]))):\n", "        axeslist.ravel()[ind].imshow(figures[title], cmap=plt.gray())\n", "        if titles:\n", "            axeslist.ravel()[ind].set_title(title)\n", "\n", "    for ind in range(nrows*ncols):\n", "        axeslist.ravel()[ind].set_axis_off()\n", "\n", "    if titles:\n", "        plt.tight_layout()\n", "    plt.show()\n", "\n", "\n", "def get_dim(num):\n", "    \"\"\"\n", "    Simple function to get the dimensions of a square-ish shape for plotting\n", "    num images\n", "    \"\"\"\n", "\n", "    s = sqrt(num)\n", "    if round(s) < s:\n", "        return (int(s), int(s)+1)\n", "    else:\n", "        return (int(s)+1, int(s)+1)\n", "\n", "# Load the best model\n", "model = load_model(model_fn)\n", "\n", "# Get the convolutional layers\n", "conv_layers = [layer for layer in model.layers if isinstance(layer, MaxPooling2D)]\n", "\n", "# Pick random images to visualize\n", "imgs_to_visualize = np.random.choice(np.arange(0, len(X_img_val)), NUM_LEAVES)\n", "\n", "# Use a keras function to extract the conv layer data\n", "convout_func = K.function([model.layers[0].input, K.learning_phase()], [layer.output for layer in conv_layers])\n", "conv_imgs_filts = convout_func([X_img_val[imgs_to_visualize], 0])\n", "# Also get the prediction so we know what we predicted\n", "predictions = model.predict([X_img_val[imgs_to_visualize], X_num_val[imgs_to_visualize]])\n", "\n", "imshow = plt.imshow #alias\n", "# Loop through each image disply relevant info\n", "for img_count, img_to_visualize in enumerate(imgs_to_visualize):\n", "\n", "    # Get top 3 predictions\n", "    top3_ind = predictions[img_count].argsort()[-3:]\n", "    top3_species = np.array(LABELS)[top3_ind]\n", "    top3_preds = predictions[img_count][top3_ind]\n", "\n", "    # Get the actual leaf species\n", "    actual = LABELS[y_val[img_to_visualize]]\n", "\n", "    # Display the top 3 predictions and the actual species\n", "    print(\"Top 3 Predicitons:\")\n", "    for i in range(2, -1, -1):\n", "        print(\"\\t%s: %s\" % (top3_species[i], top3_preds[i]))\n", "    print(\"\\nActual: %s\" % actual)\n", "\n", "    # Show the original image\n", "    plt.title(\"Image used: #%d (digit=%d)\" % (img_to_visualize, y_val[img_to_visualize]))\n", "    # For Theano users comment the line below and\n", "    imshow(X_img_val[img_to_visualize][:, :, 0], cmap='gray')\n", "    # imshow(X_img_val[img_to_visualize][0], cmap='gray') # uncomment this\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "    # Plot the filter images\n", "    for i, conv_imgs_filt in enumerate(conv_imgs_filts):\n", "        conv_img_filt = conv_imgs_filt[img_count]\n", "        print(\"Visualizing Convolutions Layer %d\" % i)\n", "        # Get it ready for the plot_figures function\n", "        # For Theano users comment the line below and\n", "        fig_dict = {'flt{0}'.format(i): conv_img_filt[:, :, i] for i in range(conv_img_filt.shape[-1])}\n", "        # fig_dict = {'flt{0}'.format(i): conv_img_filt[i] for i in range(conv_img_filt.shape[-1])} # uncomment this\n", "        plot_figures(fig_dict, *get_dim(len(fig_dict)))"], "cell_type": "code", "execution_count": 17}], "nbformat": 4}