{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"## Load Required Libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"### Import required libraries\n\nimport numpy as np\nimport pandas as pd\nfrom math import sqrt\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.base import clone\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\n\nfrom IPython.display import display # Allows the use of display() for DataFrames\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":49,"outputs":[]},{"metadata":{"_uuid":"e9eab758144622ca216ab417736c0e72512f9112"},"cell_type":"markdown","source":"## Load Train and Test Data"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"445a923c8400596b1faad982ee0cc77232f18af3"},"cell_type":"code","source":"# Read train and test files\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":50,"outputs":[]},{"metadata":{"_uuid":"dffdd726f398c7603265b48a00b0e741209e174e"},"cell_type":"markdown","source":"## Train and Test Data"},{"metadata":{"trusted":true,"_uuid":"048a0522882897816ab48b8124d27fc8ef109a4c","collapsed":true},"cell_type":"code","source":"train_df.head()","execution_count":51,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fd0116acb078cd2d3222412f150653af3f84f85f","collapsed":true},"cell_type":"code","source":"test_df.head()","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"4e2318eec8ca6080d6bce9b9693da976a63b3a4c"},"cell_type":"markdown","source":"## Train and Test Data Info"},{"metadata":{"trusted":true,"_uuid":"13bd5136f765c4a229bb16a1ab65f51654df9d14","collapsed":true},"cell_type":"code","source":"train_df.info()","execution_count":53,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e96f7979fdfcc428f2499cfe5460e116c4bd4633","collapsed":true},"cell_type":"code","source":"test_df.info()","execution_count":54,"outputs":[]},{"metadata":{"_uuid":"42121af84877ff5bcc665f9f99179a703f196431"},"cell_type":"markdown","source":"## Check for Missing Values"},{"metadata":{"trusted":true,"_uuid":"6f2d559c4b84afbc049daf5808c7437232c96497","collapsed":true},"cell_type":"code","source":"#### Check if there are any NULL values in Train Data\nprint(\"Total Train Features with NaN Values = \" + str(train_df.columns[train_df.isnull().sum() != 0].size))\nif (train_df.columns[train_df.isnull().sum() != 0].size):\n    print(\"Features with NaN => {}\".format(list(train_df.columns[train_df.isnull().sum() != 0])))\n    train_df[train_df.columns[train_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56349117a02562192fd0087e0c457d090f9baecf","collapsed":true},"cell_type":"code","source":"#### Check if there are any NULL values in Test Data\nprint(\"Total Test Features with NaN Values = \" + str(test_df.columns[test_df.isnull().sum() != 0].size))\nif (test_df.columns[test_df.isnull().sum() != 0].size):\n    print(\"Features with NaN => {}\".format(list(test_df.columns[test_df.isnull().sum() != 0])))\n    test_df[test_df.columns[test_df.isnull().sum() != 0]].isnull().sum().sort_values(ascending = False)","execution_count":56,"outputs":[]},{"metadata":{"_uuid":"885a603bc36fbd2da2a5ca34675e008231f59c61"},"cell_type":"markdown","source":"## Stacking Model"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4473ff0ec74e211b69d5316ccce53671b94248b6"},"cell_type":"code","source":"def transformer(y, func=None):\n    \"\"\"Transforms target variable and prediction\"\"\"\n    if func is None:\n        return y\n    else:\n        return func(y)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"978926484f3d0c6f4589ad31cc588df1ad522bc9"},"cell_type":"code","source":"def rmse(predictions, targets):\n    return np.sqrt(((predictions - targets) ** 2).mean())","execution_count":58,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"32bec5bdbadf55fbb2cfa70dfb71f7c4af52cfd4"},"cell_type":"code","source":"def stacking_regression(models, meta_model, X_train, y_train, X_test,\n             transform_target=None, transform_pred=None,\n             metric=None, n_folds=5, average_fold=True,\n             shuffle=False, random_state=42, verbose=1):\n\n    # Specify default metric for cross-validation\n    if metric is None:\n        metric = rmse\n\n    # Print metric\n    if verbose > 0:\n        print('metric: [%s]\\n' % metric.__name__)\n\n    # Split indices to get folds\n    kf = KFold(n_splits = n_folds, shuffle = shuffle, random_state = random_state)\n\n    if X_train.__class__.__name__ == \"DataFrame\":\n    \tX_train = X_train.as_matrix()\n    \tX_test = X_test.as_matrix()\n\n    # Create empty numpy arrays for stacking features\n    S_train = np.zeros((X_train.shape[0], len(models)))\n    S_test = np.zeros((X_test.shape[0], len(models)))\n\n    # Loop across models\n    for model_counter, model in enumerate(models):\n        if verbose > 0:\n            print('model %d: [%s]' % (model_counter, model.__class__.__name__))\n\n        # Create empty numpy array, which will contain temporary predictions for test set made in each fold\n        S_test_temp = np.zeros((X_test.shape[0], n_folds))\n        # Loop across folds\n        for fold_counter, (tr_index, te_index) in enumerate(kf.split(X_train, y_train)):\n            X_tr = X_train[tr_index]\n            y_tr = y_train[tr_index]\n            X_te = X_train[te_index]\n            y_te = y_train[te_index]\n            # Clone the model because fit will mutate the model.\n            instance = clone(model)\n            # Fit 1-st level model\n            instance.fit(X_tr, transformer(y_tr, func = transform_target))\n            # Predict out-of-fold part of train set\n            S_train[te_index, model_counter] = transformer(instance.predict(X_te), func = transform_pred)\n            # Predict full test set\n            S_test_temp[:, fold_counter] = transformer(instance.predict(X_test), func = transform_pred)\n\n            # Delete temperatory model\n            del instance\n\n            if verbose > 1:\n                print('    fold %d: [%.8f]' % (fold_counter, metric(y_te, S_train[te_index, model_counter])))\n\n        # Compute mean or mode of predictions for test set\n        if average_fold:\n            S_test[:, model_counter] = np.mean(S_test_temp, axis = 1)\n        else:\n            model.fit(X_train, transformer(y_train, func = transform_target))\n            S_test[:, model_counter] = transformer(model.predict(X_test), func = transform_pred)\n\n        if verbose > 0:\n            print('    ----')\n            print('    MEAN RMSE:   [%.8f]\\n' % np.sqrt((metric(y_train, S_train[:, model_counter]))))\n\n    # Fit our second layer meta model\n    meta_model.fit(S_train, transformer(y_train, func = transform_target))\n    # Make our final prediction\n    stacking_prediction = transformer(meta_model.predict(S_test), func = transform_pred)\n\n    return stacking_prediction","execution_count":59,"outputs":[]},{"metadata":{"_uuid":"63df612ef13aab1473c194c40d306994b46cf824"},"cell_type":"markdown","source":"## Stacking Base Models"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b017f1a439c34b345c51cc63e19c3c8e9271b04a"},"cell_type":"code","source":"X_train = train_df.drop([\"ID\", \"target\"], axis=1)\ny_train = np.log1p(train_df[\"target\"].values)\n\nX_test = test_df.drop([\"ID\"], axis=1)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c8b798a0ec76ac6bb3609a98cc40f578f56a351c","collapsed":true},"cell_type":"code","source":"elastic_net = ElasticNet(alpha = 0.02, l1_ratio = 0.15, random_state = 42)\nelastic_net.fit(X_train,y_train)","execution_count":61,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"026f47dac46cbc508aa0b834a8333709a26b02fc","collapsed":true},"cell_type":"code","source":"rf_tree = RandomForestRegressor(n_estimators = 1000,\n                                max_features = \"sqrt\",\n                                max_depth = 15,\n                                min_samples_split = 20,\n                                min_samples_leaf = 5,\n                                bootstrap = True,\n                                random_state = 42)\nrf_tree.fit(X_train, y_train)","execution_count":62,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d32453e601b3ee7b569cfb2439b8d1fe1e42bc41","collapsed":true},"cell_type":"code","source":"gb_tree = GradientBoostingRegressor(max_depth = 5, \n                                    learning_rate = 0.01, \n                                    n_estimators = 1000,\n                                    min_samples_split = 15,\n                                    max_features = \"sqrt\",\n                                    min_samples_leaf = 3,\n                                    random_state=42)\ngb_tree.fit(X_train, y_train)","execution_count":63,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd0cb1d79b2ae59dbc32d5f6d96bcf59eee135d4","collapsed":true},"cell_type":"code","source":"xgb_tree = XGBRegressor(max_depth = 10, \n                        learning_rate = 0.01, \n                        n_estimators = 1000,\n                        min_child_weight = 5,\n                        reg_alpha = 0.03, \n                        random_state=42)\nxgb_tree.fit(X_train, y_train)","execution_count":64,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4278e409b812ba96724215326319279a5f7afee","collapsed":true},"cell_type":"code","source":"lgb_tree = lgb.LGBMRegressor(learning_rate = 0.01, \n                             num_leaves = 40,\n                             n_estimators = 1000,\n                             bagging_fraction = 0.6,\n                             feature_fraction = 0.5,\n                             random_state=42)\nlgb_tree.fit(X_train, y_train)","execution_count":66,"outputs":[]},{"metadata":{"_uuid":"20815b540f60d45a18a6777b9dffc1322a5e56b2"},"cell_type":"markdown","source":"## Stacked Modeling"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"907661b5420a178000aeaf5579cb6b5995edae58"},"cell_type":"code","source":"models = [rf_tree, gb_tree, xgb_tree, lgb_tree]\nmeta_model = elastic_net","execution_count":67,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd1b78d94250e1b3a17a05a3d1b26d91348f70eb","collapsed":true},"cell_type":"code","source":"y_predicted = stacking_regression(models, meta_model, X_train, y_train, X_test,\n             metric=None, n_folds=5, average_fold=True,\n             shuffle=True, random_state=42, verbose=2)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d50dc3d95de615efa3b9e85c8f4be309c362a30","collapsed":true},"cell_type":"code","source":"y_pred = np.expm1(y_predicted)\nsub = pd.read_csv('../input/sample_submission.csv')\nsub[\"target\"] = y_pred\n\nprint(sub.head())\nsub.to_csv('sub_stacking.csv', index=False)","execution_count":69,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}