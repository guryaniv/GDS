{"cells":[{"metadata":{"_uuid":"8f543133e4800b57edcb41f26027da660674a142"},"cell_type":"markdown","source":"# Steps followed for problem solving - \n1. Loading the data\n2. Exploratory Data Analysis (EDA)\n3. Missing value treatment\n4. Scaling the features\n5. One-hot encoding the features\n6. Building the model\n\n"},{"metadata":{"_uuid":"cb057b1e09e6484487faaed3f0becf6f9c8638f2"},"cell_type":"markdown","source":"**1. Problem Statement - **\nThis is a binary classification problem.  In the problem, we need to predict of the passenger will survive or not. \n**\n2. Hypothesis Generation - **\n\nIt involves finding/thinking of the features which might affect the outcome/prediction. \n\nHere are some of the factors which I think might affect the survical rate - \n1. Gender : Gender plays an important role in the prediction. \n2. Fare : It might be a factor worth considering. As the passengers who paid higher fare might have a better chance for survival. \n3. PClass - This will also play a role in survival rate. \n4. Age - Small children and senior citizens will have less chance of survival. So it will definitely affect the target variable. \n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom time import time\nimport matplotlib.pyplot as plt\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"**1. Reading training and testing files.**"},{"metadata":{"trusted":true,"_uuid":"f10bdcea255b76d14babe21e7d41fa57ed378aac"},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\n# keeping copy of original datasets \n# 1. Train data  -  Has all the features along with target variable. \n# 2. Test data - Similar to training data , but it does not have target variable. \ntrain_original = train_df.copy()\ntest_original = test_df.copy()\n\ntrain_df.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2800d1beb0bf7d494a8ee3911ab07b25c2f57750"},"cell_type":"code","source":"train_df['Cabin'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a0f4bcba0de7a8a93eea01bddc0377a9ee69147"},"cell_type":"code","source":"test_df['Cabin'].value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03f34e34d59c40efbdb44b63b68d4ddee4fd62a2"},"cell_type":"code","source":"# ckecking structure of training dataset\n\ntrain_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d54f8d038426a1b2beef4979e1ad25f0ac8e1592","collapsed":true},"cell_type":"code","source":"# checking structure of testing dataset \n\ntest_df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c7f49587fff71618caad3b473ccb05b99cd7b0c"},"cell_type":"markdown","source":"**Target Variable **\nWe will analyze the target variable. As it is a class variable with two outupts 1 - Survived and 0 - Not survived. We will plot a bar chart for this variable \n"},{"metadata":{"trusted":true,"_uuid":"026637fa5de91f7092a5efd90fa4f7a81af370d0","collapsed":true},"cell_type":"code","source":"train_df['Survived'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d856c65409d9bdb6b5435129c9b588501ffd47a6"},"cell_type":"code","source":"# we will now normalize this variable \ntrain_df['Survived'].value_counts(normalize = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29984e088677d532ad91e88c6139e047511cf119"},"cell_type":"markdown","source":"**Categorical Variable : **\n\n1. Categorical Variables  -  Sex , Cabin, Embarked, Ticket,PClass  "},{"metadata":{"trusted":true,"_uuid":"8d915d3a94e8155baaffff11d570652b3c67a82f","collapsed":true},"cell_type":"code","source":"plt.figure(1)\nplt.subplot(221)\ntrain_df['Sex'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender')\n\nplt.subplot(222)\ntrain_df['Embarked'].value_counts(normalize=True).plot.bar(title= 'Embarked')\n\nplt.subplot(223)\ntrain_df['Pclass'].value_counts(normalize=True).plot.bar(title= 'Passenger_Class')\n\nplt.subplot(224)\ntrain_df['SibSp'].value_counts(normalize=True).plot.bar(figsize=(24,6), title= 'Sibling_Spouse')\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02f66d60874e5f31ef34e7a05aa3387be90cbaa2"},"cell_type":"markdown","source":"**Inference from the plots  - **\n1. 60% passengers in the data set are Male. \n2. 70% passengers have embarked from 'S' port. \n3. More than 50% passengers belong to the PClass = 3\n4. More than 60% of passengers came without their spouse or children. \n"},{"metadata":{"_uuid":"af2c460dc7b94551b1e4720e1a6a5cb20e9dbf81"},"cell_type":"markdown","source":"**Target Variable and it's relation with the categorical variables**"},{"metadata":{"trusted":true,"_uuid":"5a27e22cbcf498abd8944950e75cbb8d85af5d5a","collapsed":true},"cell_type":"code","source":"Gender=pd.crosstab(train_df['Sex'],train_df['Survived'])\nGender.div(Gender.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"08fd9e9b999ee42f4135cf10e188bd8274baaf57"},"cell_type":"markdown","source":"From the above graph it is observed that female survivals were more as compared to the male survivors\n\nNow let us Visualize the remaining variables"},{"metadata":{"_uuid":"e374a70317e1d9c6a37d48de35b490e25e1ce4f9","trusted":true,"collapsed":true},"cell_type":"code","source":"p_class=pd.crosstab(train_df['Pclass'],train_df['Survived'])\nDependents=pd.crosstab(train_df['SibSp'],train_df['Survived'])\nEmbarked=pd.crosstab(train_df['Embarked'],train_df['Survived'])\n\n\np_class.div(p_class.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nplt.show()\n\nDependents.div(Dependents.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True)\nplt.show()\n\nEmbarked.div(Embarked.sum(1).astype(float), axis=0).plot(kind=\"bar\", stacked=True, figsize=(4,4))\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1ae50408c0ef7da042085c0a6501fe1916ba8d1"},"cell_type":"markdown","source":"A passenger had greater chance of survival if he belongs to class = 1 and has embarked on 'C' port. "},{"metadata":{"trusted":true,"_uuid":"c25cdacf387828526f47c1dae09444e2f9e83e33"},"cell_type":"code","source":"#Now let us look at the correlation between the variables by heatmap \nmatrix = train_df.corr()\nf, ax = plt.subplots(figsize=(9, 6))\nsns.heatmap(matrix, vmax=.8, square=True, cmap=\"BuPu\");","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"23747c76c52d3bde5ed81fb549991cff6c8c7cd6"},"cell_type":"markdown","source":"**Correlation **\nWe see that most correlated variables are - (SibSp - Parch ) and  (Survived - FAre)"},{"metadata":{"_uuid":"7f7bd487d84afd72636477c7d28b650811ec9bde"},"cell_type":"markdown","source":"**Filling Missing Values *\n\nWe will need to fill the misisng values . SO we will do the following - \n1. For categorical values - filling with the most occured values(mode)\n2. For numerical values - filling with mean/median"},{"metadata":{"trusted":true,"_uuid":"4120f862622bd0c389b696bc8bcbc068d663c9ff","collapsed":true},"cell_type":"code","source":"# printing information of all the columns in training and test datasets.\ntrain_df.info()\nprint(\"-----------------Test Info------------------\")\ntest_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d7992f08810a0f6031c37d8487a4be385814687","collapsed":true},"cell_type":"code","source":"# to see categorical data\ntrain_df.describe(include=['O'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5386e60745ef92aa9813000439da7ac1ae723f69"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"067322dbe5200a847a091c420562722cdd9e903b"},"cell_type":"code","source":"\ndef delete_features(df):\n    return df.drop(['PassengerId','Ticket','Cabin'], axis=1)\n\ndef fill_value(df):\n    df.Embarked = df.Embarked.fillna(\"S\")\n    #df['Age'] = df.Age.fillna(df.Age.median())\n    df['Age'] = df.groupby(['Sex'],sort=False)['Age'].apply(lambda x: x.fillna(x.median()))\n    df['Fare'] = df.groupby(['Pclass','Embarked'],sort=False)['Fare'].apply(lambda x : x.fillna(x.median()))\n    return df\n\ndef fill_cabin(df):\n    df.Cabin = df['Cabin'].fillna(\"N\")\n    '''Keep only the 1st character where Cabin is alphanumerical.'''\n    df.Cabin = df['Cabin'].apply(lambda c : c[0])\n    return df\n\ndef extract_name_from_title(df):\n    df['Name'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n    return df\n    \n    \ndef family_members(df):\n    # to find if passenger has any family member or not in the ship.\n    df['Family'] = df['SibSp'] + df['Parch'] + 1\n   \n    return df\n\ndef family_size_bin(df):\n    \"\"\" Creating buckets as per the family size - Individual, Small , Medium and large family\"\"\"\n    df.loc[ df['Family'] == 1, 'Family'] = \"Individual\"\n    #df.loc[(df['Family'] > int(1)) & (df['Family'] <= int(2)), 'Family'] = \"Small\"\n    #df.loc[(df['Family'] > 2) & (df['Family'] <= 5), 'Family'] = \"Medium\"\n    #df.loc[(df['Family'] > 5) , 'Family'] =\"Large\"\n    df['Family'].replace(to_replace = [2,3,4], value = 'small', inplace = True)\n    df['Family'].replace(to_replace = [5,6], value = 'medium', inplace = True)\n    df['Family'].replace(to_replace = [7,8,9, 10,11], value = 'large', inplace = True)\n    return df\n    \n    \ndef transform_feature(df):\n    df = delete_features(df)\n    df = fill_value(df)\n   # df = fill_cabin(df)\n    df = extract_name_from_title(df)\n    df = family_members(df)\n    df = family_size_bin(df)\n    return df\n\ntrain_df = transform_feature(train_df)\ntest_df = transform_feature(test_df)\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5f388bcac4df724a7071991f586639a3ff33b920"},"cell_type":"code","source":"display(train_df['Name'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d35031f2c31df08175210770214152d145ef2ef"},"cell_type":"code","source":"\"\"\" Now we will bin the titles and also try to place  the same titles together \"\"\"\n\ndef replace_title(df):\n    df['Name'] = df['Name'].replace(['Lady','Countess','Capt', 'Col','Don', 'Major','Rev','Sir','Jonkheer','Dona'], 'Special')\n    df['Name'] = df[\"Name\"].replace(['Mlle','Ms','Miss'],'Miss')\n    df['Name'] = df['Name'].replace(['Mrs','Mme'],'Mrs')\n    return df\n\ntrain_df = replace_title(train_df)\ntest_df = replace_title(test_df)\ntrain_df.head()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b82130e69665de611c751c50ba31cf77714ee3"},"cell_type":"code","source":"display(train_df['Name'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6c40f302e025d4a0e93f59dd5fdac5cb0314090"},"cell_type":"markdown","source":"**3. Scaling Features:**\nWe should perform scaling on numerical features. Normalization ensures that each feature is treated equally while applyingalgorithms.\n\nWe will be performing min max scaler in numerical features - Age, Fare, SibSp"},{"metadata":{"trusted":true,"_uuid":"4463caaba0c1edabd40a0fa47076d3fe68806e13"},"cell_type":"code","source":"\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef encoder(df):\n    scaler = MinMaxScaler()\n    numerical = ['Age', 'Fare', 'SibSp','Parch']\n    features_transform = pd.DataFrame(data= df)\n    features_transform[numerical] = scaler.fit_transform(df[numerical])\n    display(features_transform.head(n = 5))\n    return df\n\ntrain_df = encoder(train_df)\ntest_df = encoder(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bfd42f394bb2919c7006ecd3edd4a41370eaa02"},"cell_type":"markdown","source":"**4. One-hot encoding**\nThere are several categorical features in the dataset. As the algorithms mainly work on numerical data, we will convert features - sex to numerical values."},{"metadata":{"trusted":true,"_uuid":"3e14064c1dd4e70ea9d814c63f4857fa31c78192"},"cell_type":"code","source":"def convert_numerical(df):\n    #categorical = df.select_dtypes(exclude=[\"number\"])\n           \n        \n    #df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n    #df = pd.get_dummies(df, columns=['Embarked'], drop_first=False)\n    #df = pd.get_dummies(df, columns=['Name'], drop_first=False)\n    #df = pd.get_dummies(df, columns=['Family'], drop_first=False)\n    \n    df = pd.get_dummies(df)\n    \n    encoded = list(df.columns)\n    print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n    print(encoded)\n    return df\n    \n\ntrain_df_final = convert_numerical(train_df)\ntest_df_final = convert_numerical(test_df)\n\n\n#print(test_df_final.Cabin_N)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d88bc0e8f93faed32642c0be2dc790eef8228cc"},"cell_type":"markdown","source":"\nWe will drop the target variable form the training data set and will store in in another variable. \n"},{"metadata":{"trusted":true,"_uuid":"98444fbfef47d43089e1026040afd874fa982a65"},"cell_type":"code","source":"# splitting the data into training and testing data set \nfrom sklearn.model_selection import train_test_split\nytest  = train_df_final['Survived']\nxtrain = train_df_final.drop(['Survived'], axis = 1)\n\n\nX_train, X_test, y_train, y_test = train_test_split(xtrain, ytest, test_size=.25, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce716aaaa350cae503cb73fd9b410c5c2f28d0a4"},"cell_type":"markdown","source":"**Implementing algorithm**\nWe will be using RandomForestClassifier. "},{"metadata":{"trusted":true,"_uuid":"4729c953f19bbf15be9d176ead50c99e949979e0"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n#from sklearn.linear_model import LogiscticRegression\nfrom sklearn.metrics import make_scorer, accuracy_score,fbeta_score\nfrom sklearn.grid_search import GridSearchCV\n\n\nclf = RandomForestClassifier(random_state = 1)\n\n#creating parameters to fit into algortihm \nparameters = {'n_estimators' : [10, 20, 30,50, 100] , 'max_features' : [0.6, 0.2, 0.3], 'min_samples_leaf' :[1,2,3], \n              'min_samples_split':[2,3,4,6]}\n\n#parameters = {'penalty':['l1', 'l2'],'C': np.logspace(0, 4, 10)}\n\n# calculating accuracy score\nacc_scorer = make_scorer(accuracy_score)\n\n# Running grid search \ngrid_obj = GridSearchCV(clf, parameters,  scoring=acc_scorer, cv = 5)\n\n# Fit the grid search object to the training data and find the optimal parameters\ngrid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nbest_clf = grid_obj.best_estimator_\n\n# Fit the best parameter to the data. \nbest_clf.fit(X_train, y_train)\n\n#making predictions \nbest_predictions = best_clf.predict(X_test)\n\n#printing fbeta score and accuracy score of the optimized model . \nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"48c716006d33b3b74ef55ff60d172a9f86d80859"},"cell_type":"markdown","source":"**Predicting the test data**"},{"metadata":{"trusted":true,"_uuid":"511b8443c42c60c0567acdb4fc38f984cbe48283"},"cell_type":"code","source":"xtrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"336c42f907b6cfd3adc50d4aa4a79e5f8afad1e7","scrolled":true},"cell_type":"code","source":"test_df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"84ee2c33f9d23822ea467171463cd82d955a0bde","_kg_hide-output":true},"cell_type":"code","source":"pred_test = best_clf.predict(test_df_final)\n\nsubmission = pd.read_csv('../input/gender_submission.csv')\nsubmission['Survived']=pred_test\nsubmission['PassengerId']=test_original['PassengerId']\n\n#submission = pd.DataFrame({\n#\"PassengerId\": test[\"PassengerId\"],\n#        \"Survived\": y_pred_rf_tunned})\"\"\"\"\"\"\n#submission.to_csv('submission_rf.csv', index = False)\"''\"\n#converting to csv\n\npd.DataFrame(submission, columns=['PassengerId','Survived']).to_csv('randomforest.csv', index = False)\nprint(submission.head())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}