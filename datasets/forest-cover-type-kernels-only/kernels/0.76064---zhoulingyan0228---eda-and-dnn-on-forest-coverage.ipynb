{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn\nimport sklearn.preprocessing as StandardScaler # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nimport seaborn as sns \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \ntf.logging.set_verbosity(tf.logging.ERROR)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv('../input/train.csv').drop(['Id'],axis=1)\ndf_raw.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"be47960b9dcf303f4fc7cdbd42d2d9bb41eb5715"},"cell_type":"code","source":"df_features = df_raw.copy()\ndf_features['Distance_To_Hydrology'] = np.sqrt(df_raw['Horizontal_Distance_To_Hydrology'].values ** 2 + df_raw['Vertical_Distance_To_Hydrology'] ** 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7726290cc35d8ec1ed0b13d3cbc4905f56248d7e"},"cell_type":"code","source":"pd.plotting.scatter_matrix(df_features[['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n       'Vertical_Distance_To_Hydrology', 'Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n       'Horizontal_Distance_To_Fire_Points']], c=df_raw['Cover_Type'], figsize=(20,20));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a81007483e9e2cac7f73ab707509a3684c233b74"},"cell_type":"code","source":"tmp = df_features[['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4', 'Cover_Type']].groupby('Cover_Type').sum()\nsns.heatmap(tmp, annot=True, fmt='d');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b51fb41aeb9f5c3cdf24efa24320f8e1785a715b"},"cell_type":"code","source":"tmp = df_features[['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n       'Soil_Type39', 'Soil_Type40', 'Cover_Type']].groupby('Cover_Type').sum()\nplt.subplots(figsize=(20,20))\nsns.heatmap(tmp, annot=True, fmt='d', square=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"244fd961c61412cc75a8701164477d21e434d178"},"cell_type":"code","source":"plt.subplots(figsize=(20,20))\nfor i, c in enumerate(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n                    'Vertical_Distance_To_Hydrology', 'Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n                    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n                    'Horizontal_Distance_To_Fire_Points']):\n    plt.subplot(6, 2, i+1)\n    sns.violinplot(x='Cover_Type', y=c, data=df_features[['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n           'Vertical_Distance_To_Hydrology', 'Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n           'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n           'Horizontal_Distance_To_Fire_Points', 'Cover_Type']], scale=\"width\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef3e6af9085d51c80bdba3aacdc9713153245473"},"cell_type":"code","source":"df_train, df_validate = train_test_split(df_raw, test_size=0.2)\n\nlabel_scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 6), copy=True)\nlabel_scaler.fit([[1],[7]])\n                 \nfeature_scaler = sklearn.preprocessing.StandardScaler(copy=True)\nfeature_scaler.fit(df_train.drop('Cover_Type', axis=1).values)\n\n#feature_selection = SelectKBest(mutual_info_classif, k=50)\n#feature_selection.fit(df_train.drop('Cover_Type', axis=1).values, df_train['Cover_Type'].values)\n#feature_selection.transform(df_train.drop('Cover_Type', axis=1).values)\n\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(df_train.drop('Cover_Type', axis=1).values)},\n    y=label_scaler.transform(df_train['Cover_Type'].values.reshape(-1, 1)).astype(np.int32).flatten(),\n    batch_size=32,\n    num_epochs=300,\n    shuffle=True)\n\nvalidate_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(df_validate.drop('Cover_Type', axis=1).values)},\n    y=label_scaler.transform(df_validate['Cover_Type'].values.reshape(-1, 1)).astype(np.int32).flatten(),\n    shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c55f3f6669ec351437791244e3ef3d8116889d4f"},"cell_type":"code","source":"def model_fn(features, labels, mode, params):\n    layer = tf.layers.dense(inputs=features['x'], units=512, activation=tf.nn.relu)\n    layer = tf.layers.dense(inputs=layer, units=128, activation=tf.nn.relu)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        layer = tf.layers.dropout(inputs=layer, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n    # Logits Layer\n    logits = tf.layers.dense(inputs=layer, units=params['num_classes'])\n\n    predictions = {\n        \"classes\": tf.argmax(input=logits, axis=1),\n        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n    }\n\n    if mode == tf.estimator.ModeKeys.PREDICT:\n        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n\n    weights = tf.gather(params['weights'], labels)\n    # Calculate Loss (for both TRAIN and EVAL modes)\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits, weights=weights) \n\n    # Configure the Training Op (for TRAIN mode)\n    if mode == tf.estimator.ModeKeys.TRAIN:\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n        train_op = optimizer.minimize(\n          loss=loss,\n          global_step=tf.train.get_global_step())\n        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n\n    # Add evaluation metrics (for EVAL mode)\n    eval_metric_ops = {\n        \"accuracy\": tf.metrics.accuracy(\n            labels=labels, predictions=predictions[\"classes\"]),\n        \"recall\": tf.metrics.recall(\n            labels=labels, predictions=predictions[\"classes\"]),\n        \"precision\": tf.metrics.precision(\n            labels=labels, predictions=predictions[\"classes\"])}\n    return tf.estimator.EstimatorSpec(\n        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0e191b10c5085469698328860215c3e154649f1"},"cell_type":"code","source":"classifier = tf.estimator.Estimator(\n    model_fn=model_fn,\n    params={'num_classes': 7,\n           'weights': [3, 3, 1., 1., 1., 1., 1.]})\nclassifier.train(input_fn=train_input_fn)\nprint(classifier.evaluate(input_fn=validate_input_fn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33bb344115c8da01acacb0d734d7983a7d39ac03"},"cell_type":"code","source":"predicted = np.array(list(map(lambda x: x['classes'], classifier.predict(input_fn=validate_input_fn))))\ndf_validate['Cover_Type'].values.shape\ndf_validate['Cover_Type'].shape\ntmp = pd.DataFrame(sklearn.metrics.confusion_matrix(df_validate['Cover_Type'].values, label_scaler.inverse_transform(predicted.reshape(-1,1)).flatten().astype(np.int32)))\nplt.subplots(figsize=(10,10)) \nsns.heatmap(tmp, annot=True, fmt='.1f');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb417d50c4d1bb5b8868c297bd3c4dc0984869de"},"cell_type":"code","source":"test_raw = pd.read_csv('../input/test.csv')\nX_test = test_raw.drop(['Id'],axis=1)\nids = test_raw[['Id']]\ntest_input_fn = tf.estimator.inputs.numpy_input_fn(\n    x={'x': feature_scaler.transform(X_test.values)},\n    shuffle=False)\npredicted = np.array(list(map(lambda x: x['classes'], classifier.predict(input_fn=test_input_fn))))\n\nout_df = ids.copy()\nout_df['Cover_Type'] = label_scaler.inverse_transform(predicted.reshape(-1,1)).flatten().astype(np.int32)\nout_df.to_csv('./submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}