{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport seaborn as sns\nfrom sklearn import metrics\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"house = pd.read_csv('../input/kc_house_data.csv') #reading data\ngrade = house['grade'] # y of the data for logistic regression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ce7db388069fa4b2d7b8ea63f55f44b53274235"},"cell_type":"code","source":"house.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0743893a8e115403a698d750feaf77f87ecb267f"},"cell_type":"code","source":"house.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4396798d335c6afb80df68f386e2198af4c61185"},"cell_type":"markdown","source":"# Features\nHere I have generated new and transformed existed features: __date__ has been transformed because objects can't be fitted to train a model, so I have made a decision to transform it to datetype and than extract year, month and day; __yr_renovated__ has been changed in a way that if it was renovated then I substracted this year of renovation from 2018, if it was not I just have left 0; __yr_built__ has been changed to know how old is the building instead of year of construction; __zipcode__ column I have created dummies columns to have a look if that encereases the score\n"},{"metadata":{"trusted":true,"_uuid":"dd8f1bcf9a043d8628d24a2e151431a694f2f1cf"},"cell_type":"code","source":"house['date'] = pd.to_datetime(house['date'])#transforming date column to datetype\nhouse['year'] = house['date'].dt.year #extracting year \nhouse['month'] = house['date'].dt.month #month\nhouse['day'] = house['date'].dt.day #day\nhouse['yr_renovated'] = house['yr_renovated'].apply(lambda x: 2018 - x if x != 0 else 0)#analysing how old is a renovation\nhouse['yr_built'] = np.abs(house['yr_built'] - 2018) #analysing how old is a building\n\n#logistic regression features as they contain price, they can't be used in linear \nhouse['price/sqft_living'] = house['price']/ house['sqft_living'] # analysing price per sqrf_living\nhouse['price/sqft_lot'] = house['price']/ house['sqft_lot'] # analysing price per sqrf_lot \nhouse['price/sqft_above'] = house['price']/ house['sqft_above'] # analysing price per sqrf_above\nhouse['price/sqft_basement'] = house['price']/ house['sqft_basement'] # analysing price per sqrf_above\nhouse['price/sqft_basement'] = house['price/sqft_basement'].replace(np.inf, 0)\n\nhouse = house.drop('date', axis = 1)\nhouse = house.drop('id', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9fe5d755f59565feee12eb3fdb103978838612dc"},"cell_type":"markdown","source":"# Feature Analysis"},{"metadata":{"_uuid":"b3c63f1c10eb7f29baf0cf115176881a44186f38"},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"_uuid":"ce7aa969aa237985251bd8b82b3773f6a0a95542"},"cell_type":"code","source":"#visualizationg of price corresponging to sqrt_living with indication of condiditon of the property\nplt.figure(figsize = (12,8))\ng = sns.FacetGrid(data=house, hue='condition',size= 5, aspect=2)\ng.map(plt.scatter, \"sqft_living\", \"price\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0792c759de5a594811e74991c51ba88f3ac2cd61"},"cell_type":"code","source":"#creating correlation matrix to know the relation between target feature and other features\nf, ax = plt.subplots(figsize=(20, 15))\nplt.title('Correlation Matrix',fontsize=25)\nsns.heatmap(house.corr(), linewidths=0.25, vmax=1.0, square=True, cmap=\"RdBu_r\", linecolor='k', annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"651b61e5f3f8ef11bcce05ff4ba41ffe24991779"},"cell_type":"code","source":"house = house.drop('grade', axis = 1) # dropping y from x data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5358b97344d0579f2753c51a0bbec5e2495e2a7a"},"cell_type":"code","source":"#lists of corresponging features to fit in classification tasks\ncolumns_grade_prediction = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors',\n       'waterfront', 'view', 'condition', 'sqft_above', 'sqft_basement',\n       'yr_built', 'yr_renovated', 'lat', 'long', 'sqft_living15',\n       'sqft_lot15', 'year', 'month', 'day', 'price/sqft_living',\n       'price/sqft_lot', 'price/sqft_above', 'price/sqft_basement']\n# splitting train and test for price task\nX_train_logistic, X_test_logistic, y_train_logistic, y_test_logistic = train_test_split(\n    house, grade, test_size = 0.2, shuffle = True, random_state=49)\nprint(\"Logistic regression datasets\")\nprint (X_train_logistic.shape, y_train_logistic.shape)\nprint (X_test_logistic.shape, y_test_logistic.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"814e14e077150717e21d8ed38917e45c64a14e10"},"cell_type":"code","source":"logreg = LogisticRegression(multi_class='multinomial',  solver='newton-cg', C = 1)\nlogreg.fit(X_train_logistic, y_train_logistic)\npredictions_logistic = logreg.predict(X_test_logistic)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test_logistic , predictions_logistic))\n# Accuracy score\nprint('Accuracy for test is', metrics.accuracy_score(y_test_logistic, predictions_logistic))\nprint('Accuracy for train is', metrics.accuracy_score(y_train_logistic, logreg.predict(X_train_logistic)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edb436f4acc9ae980bd202e1796917a8fde008d4"},"cell_type":"code","source":"# to visualize easier I will take constant number of features(25) and plot score corresponding to C \ntrain_score = [0.6267206477732794, 0.6287449392712551, 0.627646038172354, 0.6270676691729323,\n               0.6271255060728745, 0.6253325621746675, 0.6281087333718912]\ntest_score = [0.6243349525792274, 0.6266481609993061, 0.6259541984732825, 0.6238723108952117, 0.6245662734212353, \n              0.6236409900532038, 0.6264168401572981]\nC = [1e-2, 1, 2, 10,15, 50, 100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cafda7607909fd7a83228d29fa8b1e28296e9c5d"},"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.plot(C, train_score)\nplt.plot(C, test_score)\nplt.xlim([-1, 101])\nplt.ylim([0.622, 0.63])\nplt.rcParams['font.size'] = 12\nplt.title('Train Test Error')\nplt.xlabel('C values')\nplt.ylabel('Accuracy Score')\nplt.grid(True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ded009abcdd4bfb6e277b4ebd8e40d2357d938b"},"cell_type":"markdown","source":"Accuracy corresponds to percantage of correctly classified objects. From the graph above it is easy to notice that model with C = 1 scored the best. In the following code I will have a look on scaled features fitted to logistic regression."},{"metadata":{"_uuid":"0ae1686dc501f1243a2730524bddb504cca9d09c"},"cell_type":"markdown","source":"# Logistic regression with scaled features"},{"metadata":{"trusted":true,"_uuid":"04e6b909e36e0df77d2a14c78c7dfdfcb50a5728"},"cell_type":"code","source":"sc = StandardScaler()\nhouse_scaled = sc.fit_transform(house)\nX_train_logistic, X_test_logistic, y_train_logistic, y_test_logistic = train_test_split(\n    house_scaled, grade, test_size = 0.2, shuffle = True, random_state=49)\nprint(\"Logistic regression datasets\")\nprint (X_train_logistic.shape, y_train_logistic.shape)\nprint (X_test_logistic.shape, y_test_logistic.shape)\nlogreg = LogisticRegression(multi_class='multinomial',  solver='sag', C = 1)\nlogreg.fit(X_train_logistic, y_train_logistic)\npredictions_logistic = logreg.predict(X_test_logistic)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test_logistic , predictions_logistic))\n# Accuracy score\nprint('Accuracy for test is', metrics.accuracy_score(y_test_logistic, predictions_logistic))\nprint('Accuracy for train is', metrics.accuracy_score(y_train_logistic, logreg.predict(X_train_logistic)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3cc0182eef75f5befdb73ed7038f38594fb29f56"},"cell_type":"markdown","source":"# Decision Tree Classifier"},{"metadata":{"trusted":true,"_uuid":"00e3a8001ec72c8bc9f77827c18707e16f2504fc"},"cell_type":"code","source":"dt = DecisionTreeClassifier(max_depth = 8, criterion='entropy')\ndt.fit(X_train_logistic, y_train_logistic)\npredictions_dt = dt.predict(X_test_logistic)\n# Summary of the predictions made by the classifier\nprint(classification_report(y_test_logistic, predictions_dt))\n# Accuracy score\nprint('Accuracy for test is', metrics.accuracy_score(y_test_logistic, predictions_dt))\nprint('Accuracy for train is', metrics.accuracy_score(y_train_logistic, dt.predict(X_train_logistic)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}