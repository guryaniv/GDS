{"cells":[{"metadata":{"_uuid":"2a98df1c0e1ef3b580a3d4200b237adf049c8571"},"cell_type":"markdown","source":"![](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/RMS_Titanic_3.jpg/500px-RMS_Titanic_3.jpg)"},{"metadata":{"_uuid":"e49bfba6e85aafa588c219f7147f7db0f249cd8f"},"cell_type":"markdown","source":"**RMS Titanic** was an British passenger line that is known for it's sinking after an collition with an iceberg during it's maiden voyage in the North Atlantic. The Titanic was during it's time in service the largest ship afloat.\n\nBuilt in Belfast as second of three Olympic-class ocean liners and named after creatures of greek mythology the Titanic was designed to be the pinnacle of comfort and luxury. Holding an on-board gymnasium, swimming pool, libraries, high-class restaurants and opulent cabins the Titanic was already during it's time famously known for it's extravagance. \n\nThe ten deck ship's total capacity is estimated around 3,327 people. For the maiden voyage approximately 2,000 people boarded the Titance. 1,317 of this people were passengers; 885 crew members. Despite it's luxury equipment and sheer size the Titanic only carried 20 lifeboats with a total capacity of 1,178 people. This and poor management after the collition with an iceberg was the reason for the massiv loss of life.\n\nIn the following we are going to work us through the data of the Titanic disaster surviors and predict chances of surving based on the given input. Our goal is to find a model that accuratly predicts the odds of someone to survive the titanic disaster. \n\n\n**Content**\n\n[1. Dataset Preparation](#1)  \n[2. Exploring the Data](#2)  \n[3. Data Preparation & Visualization](#3)  \n&emsp;[3.1 PassengerID](#3.1)  \n&emsp;[3.2 Survived](#3.2)  \n&emsp;[3.3 Pclass](#3.3)  \n&emsp;[3.4 Name](#3.4)  \n&emsp;[3.5 Sex](#3.5)  \n&emsp;[3.6 Age](#3.6)  \n&emsp;[3.7 SibSp & Parch](#3.7)  \n&emsp;[3.8 Ticket](#3.8)  \n&emsp;[3.9 Fare](#3.9)  \n&emsp;[3.10 Cabin](#3.10)  \n&emsp;[3.11 Embarked](#3.11)  \n[4. Classification and Submission](#4)\n\n#  <a id=\"1\">1. Dataset Preparation</a> \n\nFirst off, we need to import several Python libraries for data wrangling and visualization. After this we load the datasets."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nimport plotly.plotly as py\nfrom plotly import tools\nimport plotly.figure_factory as ff\nimport pandas as pd\nimport numpy as np \nimport seaborn as sns\nimport random \nimport warnings\nimport operator\nimport copy\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn import tree\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler\n\nwarnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)\n%matplotlib inline\nplt.style.use('ggplot')\n\n# Original Data\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\n\n# Copy for preparation\ntrain_prep = copy.deepcopy(train)\ntest_prep = copy.deepcopy(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e38d10527ad14eff918ba54ff3ec89b6a7381262"},"cell_type":"markdown","source":" And take a look at the training data. Since our data are already divided into training and test data, we ignore the testdata until submitting to our kaggle competition."},{"metadata":{"trusted":true,"_uuid":"dd39224f53a33085333280a99a9017e009e9ad3d"},"cell_type":"code","source":"train_prep.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1289009d16bafa6990268b8f0fb97979d6eea342"},"cell_type":"code","source":"train_prep.describe(include=\"all\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02ff1354d00334280b5588a388a222aff5d04abc"},"cell_type":"code","source":"# Looking for null-values\ntrain_prep.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56bd78e2563865e3c34b20f267c70073d971a282"},"cell_type":"markdown","source":"Because the features \"Age\", \"Cabin\" and \"Embarked\" contain null-values they must be further optimized at a later time.\n\nUntil here everything seems fine, so let's start with data analysis."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"#  <a id=\"2\">2. Exploring the Data</a> \n\nLet's take a look at the complete data and analyze the features."},{"metadata":{"trusted":true,"_uuid":"37bf2356bfcaf33c2eccfff69b79c39cde37dd30"},"cell_type":"code","source":"train_prep.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46cedc5d55fdb9a4dabe5d83bbd2693b73841eb6"},"cell_type":"markdown","source":"**Dataset structure:**\n\n*  PassengerID (int64): Used for passenger identification\n* Survived (int64): Survived classification (0 = No, 1 = Yes)\n* Pclass (int64): Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd (A proxy for socio-economic status (SES))\n* Name (string): Name\n* Sex (string): Sex (male, female)\n* Age (float64): Age in years. Fractional if less than 1\n* SibSp (int64): Family relations (siblings, spouses)\n* Parch (int64): Family relations (parent, children)\n* Ticket (string): Ticket number\n* Fare (float64): Ticket price\n* Cabin (string): Cabin number\n* Embarked (string): Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n\nWith this information we can categorizes the features for further analysis and classification:\n*  **Numerical:** PassengerId, Age, SibSp, Parch, Fare\n* **Categorical:** Survived, Pclass, Sex, Embarked\n* **Text:** Name, Ticket, Cabin\n\nBecause \"Sex\" and \"Embarked\" are nominal or non-numerical we later need to convert these features.\n\n**Observations:**\n\nOur dataset contains 891 entries which of 341 (891*0.383838) people survived the disaster."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"5968105be89b44a13a580dc417780b74d1fd19de"},"cell_type":"code","source":"sns.pairplot(pd.get_dummies(train_prep, columns=[\"Sex\"], drop_first=True), hue=\"Survived\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8bafb6288c9f29041ce2a432aabf627bf89fa248"},"cell_type":"markdown","source":"Furthermore we can see that the features \"Age\", \"Sex\", \"Pclass\", \"SibSp\" and \"Parch\" influence the survivability.\n\n1.  The percentage of young people surviving is higher\n2.  More females than male survived the disaster.\n3.  Solo travelers survived more often\n4.  The higher the class the more people survived\n\n** Interpretation **\n\nThe reason for the first two observations may be the Birkenhead Drill which is famously known for \"Women and children first\". The higher odds of solo travelers are most likely explained by the fact that they frequently backfilled lifeboats and only had to fight for their own survival. As mentioned previously, higher-class passengers had access to luxurious equipment and cabins. Probably their way to the lifeboats were thus shorter and easier to control.\n\nSo let's dive deeper in to our the data!\n\n#  <a id=\"3\">3. Data Preparation & Visualization</a>\nIn the last chapter we got a first insight into our dataset. This time we want to delve deeper into our data and find first clues for the model generation and see for ourselfs what influenced the odd for survival. For that we will look at each feature individually and feature engineer if needed.\n\nFor example in chapter \"[Dataset Preparation](#1)\"  we have noticed that the features \"Age\", \"Cabin\" and \"Embarked\" contain missing values. With the information we have already received about these features, we can now decide on appropriate measures.\n\n## <a id=\"3.1\">3.1 PassengerID</a>\nSince the \"PassengerID\" is an artificial feature and is only used to identify survivors, we do not gain any value by using this feature. For this reason, we remove the \"PassengerID\" from our records."},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"trusted":true,"_uuid":"7e98d5cced85f5976a0bde8d335b24f92302cb69"},"cell_type":"code","source":"train_prep.drop(columns=[\"PassengerId\"], inplace=True)\ntest_prep.drop(columns=[\"PassengerId\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e36c67ed60e56f1ff064305d3b90acce63782a5"},"cell_type":"markdown","source":"## <a id=\"3.2\">3.2 Survived</a>\nThe feature \"Survived\" is our target variable. This means our later classification is trained and tested on this feature. This is why we should take a look at the distribution."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7db362d33aa3492ca9ba5dac7d84880cd4d6c99c"},"cell_type":"code","source":"fig = go.Figure()\n\ngroups = train_prep.groupby([\"Survived\"]).count().reset_index()\n\ndata = go.Pie(\n    labels = [\"Died\", \"Survived\"],\n    values = [groups.Pclass[0], groups.Pclass[1]],\n    marker=dict(colors=['#ff7f0e', '#1f77b4'])\n)\n\nlayout = go.Layout(\n    title='Survivors'\n)\n\nfig = go.Figure(data=[data], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89edae4969e70506e284eb16bb1e85e1a5e8fcea"},"cell_type":"markdown","source":"As you can see, only 342 out of 891 people survived. This corresponds to a survival rate of 38% or a mortality rate of 62%. In other words, if our model always predicts death, we could automatically achieve 62% accuracy. \n\n## <a id=\"3.3\">3.3 Pclass</a>\nPclass tells us which class was booked by the passenger. Available were first class, second class and third class. First class being the most luxurious and third class being the least luxurious. With this information we get an insight into the social enconomic background of the person."},{"metadata":{"trusted":true,"_uuid":"02ba2b7bb53a84e9e43ab059227ac20ae071851b","_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\ngroups = train_prep.groupby([\"Pclass\"]).count().reset_index()\n\ntrace1 = go.Bar(\n    x = [\"1st\", \"2nd\", \"3rd\"],\n    y = [groups.Sex[0], groups.Sex[1], groups.Sex[2]],\n)\n\ndata = [trace1]\nlayout = go.Layout(\n    title='Booked class',\n    xaxis=dict(\n        title='Class',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='No. of people',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f82953f7b67f971b4302e3f40130364df03deec3"},"cell_type":"markdown","source":"About 1/4 of all passengers of the Titanic travelled with the first class. The same applies to second-class passengers. Here the number of passengers was slightly more than 1/5. The remaining 491 persons and thus the majority of all passengers were accommodated in the third class.\n\nIn this context, we should look at the impact of accommodation on the chances of survival. "},{"metadata":{"trusted":true,"_uuid":"6872a8a1cb578916c7e67fc33ef8d9a5c220fe8a","_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\ngroups = train_prep.groupby([\"Pclass\", \"Survived\"]).count().reset_index()\n\ntrace1 = go.Bar(\n    x = [\"1st\", \"2nd\", \"3rd\"],\n    y = [groups.Sex[1], groups.Sex[3], groups.Sex[5]],\n    name = \"Survived\"\n)\n\ntrace2 = go.Bar(\n    x = [\"1st\", \"2nd\", \"3rd\"],\n    y = [groups.Sex[0], groups.Sex[2], groups.Sex[4]],\n    name = \"Died\"\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='stack',\n    title='Survivors/deaths of the different classes booked',\n    xaxis=dict(\n        title='Class',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='No. of people',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2b29a19b3ecaa4c47f213d0260f35625ae7f9f10"},"cell_type":"markdown","source":"As previously assumed, the booked class had a massive influence on the chance of survival. In general, the higher the class booked, the higher the chance of surviving the catastrophe. This is illustrated by the fact that 63% of first class passengers and 47% of second class passengers survived, while only 24% of third class passengers survived.\n\nFurther we use One-Hot-Encoding to convert the alphanummerical values into numerical values. This makes the values machine-readable."},{"metadata":{"trusted":true,"_uuid":"b5b51d4e40c129e926106702a8542100ffb5fdfe","_kg_hide-output":false,"_kg_hide-input":false},"cell_type":"code","source":"train_prep = pd.get_dummies(train_prep, columns=[\"Pclass\"])\ntest_prep = pd.get_dummies(test_prep, columns=[\"Pclass\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0158d8fc0428927e5d303784722e9e6e9c7b75ec"},"cell_type":"markdown","source":"## <a id=\"3.4\">3.4 Name</a>"},{"metadata":{"_uuid":"6df72b133ee3b003bbbf619c5e15db9aebc3adaa"},"cell_type":"markdown","source":"If you take a closer look at the feature \"Name\", you will notice that in addition to the traveler's name it also contains his title. With the title we can derive further information about age, status and family."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"bde53c21a3c8ced836dfde30328df1f79a0756ef"},"cell_type":"code","source":"train_prep[\"Name\"].head(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"268c8cb2b4ff3d4e4deffd6640363af755bade0e"},"cell_type":"markdown","source":"For this reason, we will extract the title from the Name field and introduce a new feature called \"Title\".\nSince we don't need the passenger's name for further analysis and classification, we will remove this feature from our records.\n\nLet's take a look at our new feature."},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"_uuid":"d02c736919922149403f8f589f57632246a51298"},"cell_type":"code","source":"train_prep[\"Title\"] = train_prep[\"Name\"].str.extract(', ([A-Za-z]+)\\.', expand=False)\ntest_prep[\"Title\"] = test_prep[\"Name\"].str.extract(', ([A-Za-z]+)\\.', expand=False)\n\ntrain_prep.drop(columns=[\"Name\"], inplace=True)\ntest_prep.drop(columns=[\"Name\"], inplace=True)\ngroups = train_prep.groupby([\"Sex\", \"Title\"], as_index=False)[\"Survived\"].count()\ngroups","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"415e6c704ebb4b4c7cd6afc337df41cdc62b7244"},"cell_type":"markdown","source":"We need to ensure the quality of our new features. This is best done by checking that there are no empty fields."},{"metadata":{"trusted":true,"_uuid":"785450a3da10b6a55156a58ca6cc711abfa57edd"},"cell_type":"code","source":"train_prep[train_prep[\"Title\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17411e076e3ec72cd614e1a936d9d3c42dde1ed8"},"cell_type":"code","source":"test_prep[test_prep[\"Title\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c64534be6180e0eaf7d9c90450176bd5cdd68e66"},"cell_type":"markdown","source":"Since there is only one missing value of a female, we manually set this value to \"Ms\".\n\nBecause some of the titles found have the same meaning, we group them and assign the same value. An example of this is \"Miss\" and \"Ms\". Here we will assign the value \"Ms\"."},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"_uuid":"8c8ef8cbc9497dc77f8f08b0f60f5bdfb776708c"},"cell_type":"code","source":"train_prep[\"Title\"] = train_prep[\"Title\"].replace([\"Miss\", \"Mlle\"], \"Ms\")\ntest_prep[\"Title\"] = test_prep[\"Title\"].replace([\"Miss\", \"Mlle\"], \"Ms\")\n\ntrain_prep[\"Title\"] = train_prep[\"Title\"].replace([\"Mme\"], \"Mrs\")\ntest_prep[\"Title\"] = test_prep[\"Title\"].replace([\"Mme\"], \"Mrs\")\n\ntrain_prep[\"Title\"] = train_prep[\"Title\"].fillna(\"Ms\")\n\ngroups = train_prep.groupby([\"Sex\", \"Title\"], as_index=False)[\"Survived\"].count()\ngroups","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed44337216dcff1c8ad63bacd2fa7bc7f66aef80"},"cell_type":"markdown","source":"Further we convert the alphanummerical values into numerical values and build groups. This makes the values machine-readable."},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":false,"trusted":true,"_uuid":"7e3921890a2351742ef7e8f18d3aed756e6f0b29"},"cell_type":"code","source":"#Group 1\ntrain_prep[\"Title\"] = train_prep[\"Title\"].replace([\"Ms\", \"Mrs\", \"Mr\", \"Sir\", \"Jonkheer\", \"Lady\", \"Don\", \"Dona\"], \"1\")\n#Group 2\ntrain_prep[\"Title\"] = train_prep[\"Title\"].replace([\"Dr\", \"Master\"], \"2\")\n#Group 3\ntrain_prep[\"Title\"] = train_prep[\"Title\"].replace([\"Major\",\"Col\", \"Capt\", \"Rev\"], \"3\")\n\n#Group 1\ntest_prep[\"Title\"] = test_prep[\"Title\"].replace([\"Ms\", \"Mrs\", \"Mr\", \"Sir\", \"Jonkheer\", \"Lady\", \"Don\", \"Dona\"], \"1\")\n#Group 2\ntest_prep[\"Title\"] = test_prep[\"Title\"].replace([\"Dr\", \"Master\"], \"2\")\n#Group 3\ntest_prep[\"Title\"] = test_prep[\"Title\"].replace([\"Major\",\"Col\", \"Capt\", \"Rev\"], \"3\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"28efa911085b5abb9c0754444bc1c7860084cc31"},"cell_type":"markdown","source":"## <a id=\"3.5\">3.5 Sex</a>\nWe have already made the assumption that sex had a great influence on the chance of survival during the Titanic disaster. We will check this assumption below and use One-Hot-Encoding."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"a69158065323c407dfd7ee50a5f1e901d95a27cb"},"cell_type":"code","source":"fig = go.Figure()\n\ngroups = train_prep.groupby([\"Survived\", \"Sex\"]).count().reset_index()\n\n# Survived\ntrace1 = go.Bar(\n    x = [\"female\", \"male\"],\n    y = groups[(groups[\"Survived\"] == 1)].Embarked,\n    name = \"Survived\"\n)\n\n# Died\ntrace2 = go.Bar(\n    x = [\"female\", \"male\"],\n    y = groups[(groups[\"Survived\"] == 0)].Embarked,\n    name = \"Died\"\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='stack',\n    title='Survivors',\n    xaxis=dict(\n        title='Sex',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='No. of people',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n\ntrain_prep = pd.get_dummies(train_prep, columns=[\"Sex\"], drop_first=True)\ntest_prep = pd.get_dummies(test_prep, columns=[\"Sex\"], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75aa4c75671d4740278f05e7297bad353eff6c23"},"cell_type":"markdown","source":"Apparently, a lot more women survived the sinking of the Titanic. As already suspected this could be due to the Birkenhead Drill.\n\n## <a id=\"3.6\">3.6 Age</a>\nIn the following we will analyze the age of the passengers. Since the age of some records is missing, we have to consider these values separately. There are several ways to do this:\n\n* Delete entries\n* Calculation of the average age\n* Calculation of the average age per title\n* Calculation of the average age per sex\n\nFor simplicity's sake, we use the average age across all records. "},{"metadata":{"_kg_hide-output":false,"_kg_hide-input":true,"trusted":true,"_uuid":"c61dfb6edc67ea087616958c6e144cd747daf8d7"},"cell_type":"code","source":"train_prep_age_mean = train_prep[\"Age\"].mean()\ntest_prep_age_mean = test_prep[\"Age\"].mean()\n\ntrain_prep[\"Age\"] = train_prep[\"Age\"].fillna(train_prep_age_mean)\ntest_prep[\"Age\"] = test_prep[\"Age\"].fillna(test_prep_age_mean)\n\nbins = [0, 10, 20, 30, 40, 50, 60, 70, 80, np.inf]\nlabels = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\ntrain_prep['AgeGroup'] = pd.cut(train_prep[\"Age\"], bins, labels=labels)\ntest_prep['AgeGroup'] = pd.cut(test_prep[\"Age\"], bins, labels=labels)\n\ndata = [go.Histogram(x=train_prep[\"AgeGroup\"], histnorm=\"probability\")]\niplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6183f26bf41949fb3fd2ef10841bd7c07b18cfc4"},"cell_type":"markdown","source":"Since we have already seen that gender has a large influence on the classification, we will consider the distribution of our data sets in combination with gender.\n\nIf the personnel on the Titanic actually held on to the Birkenheaddrill, this would have had an effect on the chances of survival of certain age groups."},{"metadata":{"trusted":true,"_uuid":"1da6813b0fd0bd86b2cf9677acf64c589eda238f","_kg_hide-input":true},"cell_type":"code","source":"showLegend = [True,False]\n\ndata = []\nfor i in range(0,len(pd.unique(train_prep['Survived']))):\n    male = {\n            \"type\": 'violin',\n            \"x\": train_prep['Survived'][ (train_prep['Sex_male'] == 1) & (train_prep['Survived'] == pd.unique(train_prep['Survived'])[i]) ],\n            \"y\": train_prep['Age'][ (train_prep['Sex_male'] == 1) & (train_prep['Survived'] == pd.unique(train_prep['Survived'])[i]) ],\n            \"name\": 'male',\n            \"side\": 'negative',\n            \"showlegend\": showLegend[i],\n            \"line\": {\n                \"color\": '#1f77b4'\n            }\n        }\n    data.append(male)\n    female = {\n            \"type\": 'violin',\n            \"x\": train_prep['Survived'][ (train_prep['Sex_male'] == 0) & (train_prep['Survived'] == pd.unique(train_prep['Survived'])[i]) ],\n            \"y\": train_prep['Age'][ (train_prep['Sex_male'] == 0) & (train_prep['Survived'] == pd.unique(train_prep['Survived'])[i]) ],\n            \"name\": 'female',\n            \"side\": 'positive',\n            \"showlegend\": showLegend[i],\n            \"line\": {\n                \"color\": '#ff7f0e'\n            }\n        }\n    data.append(female)\n        \n\nfig = {\n    \"data\": data,\n    \"layout\" : {\n        \"title\": \"Age distribution by sex and survival\",\n        \"yaxis\": {\n            \"zeroline\": True,\n        },\n        \"violingap\": 0,\n        \"violinmode\": \"overlay\"\n    }\n}\n\n\niplot(fig, validate = False)\n\ntrain_prep.drop(columns=\"Age\", inplace=True)\ntest_prep.drop(columns=\"Age\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fb90788ad5452844cd5e6561d44ed92e4a631111"},"cell_type":"markdown","source":"As predicted, age has a similar effect on the chance of survival as gender. This is particularly evident in the age group from 0 to 15 years. There are very few deaths here.\n\n## <a id=\"3.7\">3.7 SibSp & Parch</a>\nThese two features indicate the number of accompanying family members and differentiate between parents/children and spouses/other relatives. \n\nOur assumption regarding these features was that the chance of survival decreases with the number of accompanying relatives. This could be due to the fact that the families often only boarded the lifeboats together.\n"},{"metadata":{"trusted":true,"_uuid":"18714443f61014b291321f6f62d51e61fac289fb","_kg_hide-input":true},"cell_type":"code","source":"family = train_prep\nfamily[\"familymembers\"] = train_prep[\"Parch\"] + train_prep[\"SibSp\"]\n\ngroups = family.groupby([\"familymembers\"]).count().reset_index()\n\nfig = go.Figure()\n\ndata = go.Pie(\n    values = groups[\"Survived\"]\n)\n\nlayout = go.Layout(\n    title='Distribution of persons by number of family members'\n)\n\nfig = go.Figure(data=[data], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27f25272808549b4251d6efb289f399573ec492c"},"cell_type":"markdown","source":"We see that most of the travelers boarded the Titanic without family members. Very few people had more than three family members on board.\n\nNow did the number of family members on board the Titanic affect the chance of survival?"},{"metadata":{"trusted":true,"_uuid":"6b9828f1fb3985dfaa0dcef0ba8fef06c759f62f","_kg_hide-input":true},"cell_type":"code","source":"groups = family.groupby([\"familymembers\", \"Survived\"]).count().reset_index()\n\nbarplot = sns.barplot(x=\"familymembers\", y=\"Fare\", hue=\"Survived\", data=groups)\nbarplot.set_title(\"Survivor/Dead by number of family members\")\nbarplot.set_xlabel(\"No. of family members\")\nbarplot.set_ylabel(\"No. of people\")\nplt.tight_layout()\ntrain_prep.drop(columns=[\"familymembers\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2b9b8dee50e215d12bbafe2c743f01a03e35cf61","_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"'''\nHow can i do the previous grapic in plotlywithout stacking the last two groups?\n\ngroups = family.groupby([\"familymembers\", \"Survived\"]).count().reset_index()\n\nfig = go.Figure()\n\ntrace1 = go.Bar(\n    y = groups.iloc[::2, :][\"Age\"],\n    name = \"Survived\"\n)\n\ntrace2 = go.Bar(\n    x = [\"1st\", \"2nd\", \"3rd\"],\n    y = [groups.Sex[0], groups.Sex[2], groups.Sex[4]],\n    name = \"Died\"\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='stack',\n    title='Survivors/deaths of the different classes booked',\n    xaxis=dict(\n        title='Class',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='No. of people',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e0b0dc7a4bf28508dd6b8af731e7cbd907914664"},"cell_type":"markdown","source":"Obviously, yes. We can see this from the fact that families up to three people survived more frequently, while larger families had a lower chance of survival. \n\nIf you take a closer look at the data, you can see that the smaller families often consisted of parents and children. According to the Birkenheaddrill logic, women and children would survive with a very high probability. \n\nBut what is the reason why the chance of survival in larger families decreased? A valid assumption for this could be that the coordination of a large family was much more complicated in the circumstances prevailing on the Titanic.\n\n## <a id=\"3.8\">3.8 Ticket</a>\nThis feature that hase no impact on the outcome variable. Thus, it will be excluded from analysis."},{"metadata":{"trusted":true,"_uuid":"338a6b43026a290c2dbd7b80abc5c8d2bd082612"},"cell_type":"code","source":"train_prep.drop(columns=[\"Ticket\"], inplace=True)\ntest_prep.drop(columns=[\"Ticket\"], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2059a13deb43af04c7dd5fe541a070b9473cfd5d"},"cell_type":"markdown","source":"## <a id=\"3.9\">3.9 Fare</a>\nThe \"Fare\" feature simply describes the price the person has paid for the travel ticket. Since it is a numeric value, we can display the values without further feature engineering."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"458f584b463124aa4a1d24c154dea9066bfa1cbf"},"cell_type":"code","source":"trace1 = go.Box(\n    y=train_prep[train_prep[\"Survived\"] == 1][\"Fare\"],\n    name=\"Survived\"\n)\n\ntrace2 = go.Box(\n    y=train_prep[train_prep[\"Survived\"] == 0][\"Fare\"],\n    name=\"Died\"\n)\n\ndata=[trace1, trace2]\n\niplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b28f6ac05f23b80bf1b329609521b37e24fd9063"},"cell_type":"markdown","source":"You can see that the dataset contains some outliers. Since outliers in input data could skew and mislead the training process of machine learning algorithms resulting in longer training times, less accurate models and ultimately poorer results. \n\nIn this case, we do not have to eliminate these data sets, as the Titanic was a very luxurious ship. It is therefore not surprising that some people paid exceptionally high prices for the voyage. Furthermore the ticket price influences the mortality."},{"metadata":{"_uuid":"9012f298c13d25346a0b1b1bb3d55b894636e535"},"cell_type":"markdown","source":"## <a id=\"3.10\">3.10 Cabin</a>\nThis feature is missing most of it's values. Nevertheless, we use the feature for prediction. Therefore we will classify the feature binary."},{"metadata":{"trusted":true,"_uuid":"552448a84ced73dfb9308c854b3704c5fb8c1d98"},"cell_type":"code","source":"train_prep.loc[train_prep['Cabin'].notnull(), 'Cabin'] = 1\ntest_prep.loc[test_prep['Cabin'].notnull(), 'Cabin'] = 1\n\ntrain_prep[\"Cabin\"].fillna(0, inplace=True)\ntest_prep[\"Cabin\"].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98f9e6e1b7065c7a0a40b6cafdd3d9337feced4c"},"cell_type":"markdown","source":"\n\n\n\n\n## <a id=\"3.11\">3.11 Embarked</a>"},{"metadata":{"_uuid":"e8eebbcb00f48f770f198f4c88cc7d5d11f646e0"},"cell_type":"markdown","source":"\"Embarked\" describes the port where the person embarked on the Titanic. Possibly there were a lot of passengers of the same class living in a certain region. Such accumulations could also be an indication of the person's wealth and survival."},{"metadata":{"trusted":true,"_uuid":"427dbb64b6477676361d6d8c46ee5fb878fa81cd","_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\n\ngroups = train_prep.groupby([\"Embarked\"]).count().reset_index()\n\ndata = go.Pie(\n    labels = [\"Cherbourg\", \"Queenstown\", \"Southampton\"],\n    values = groups.Fare\n)\n\nlayout = go.Layout(\n    title='No. of Passenger embarked per Port'\n)\n\nfig = go.Figure(data=[data], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"01ad3780273f8ee9ab57884e6e0021b1e4fb7a71","_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure()\nx = [\"Cherbourg\", \"Queenstown\", \"Southampton\"]\n\ngroups = train_prep.groupby([\"Embarked\", \"Survived\"]).count().reset_index()\n\ntrace1 = go.Bar(\n    x = x,\n    y = [groups.Fare[1], groups.Fare[3], groups.Fare[5]],\n    name = \"Survived\"\n)\n\ntrace2 = go.Bar(\n    x = x,\n    y = [groups.Fare[0], groups.Fare[2], groups.Fare[4]],\n    name = \"Died\"\n)\n\n\n\ndata = [trace1, trace2]\nlayout = go.Layout(\n    barmode='stack',\n    title='Survivors/deaths by embarked port',\n    xaxis=dict(\n        title='Class',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    ),\n    yaxis=dict(\n        title='No. of people',\n        titlefont=dict(\n            family='Courier New, monospace',\n            size=18,\n            color='#7f7f7f'\n        )\n    )\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9cd9ee1df58e538db973b527a86f39d4550a6e55"},"cell_type":"markdown","source":"Apparently, the Embarked feature has a minor impact on the classification. This shows that many of the people who boarded  the Titanic at Southhampton Harbour died. With an in-depth analysis of the age and ticket price, further statements can certainly be made. However, this is not part of the analysis.\n\nEmbarked\" is a categorical feature and we will convert it with one-hot encoding."},{"metadata":{"trusted":true,"_uuid":"ebcaae76a8b2931cf96b5b256b967c46735d8d96"},"cell_type":"code","source":"train_prep = pd.get_dummies(train_prep, columns=[\"Embarked\"], drop_first=True)\ntest_prep = pd.get_dummies(test_prep, columns=[\"Embarked\"], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"834a731f9418825f4db38d54c41bf059aa13ad35"},"cell_type":"markdown","source":"# <a id=\"4\">4. Classification and Submission</a> \n\nIn this section we will classify the test data and prepare it for submission. First we will train and select a suitable model based on the training data.\n\nHowever, before we start with the classification, we will briefly check the quality of the data from the prepared data."},{"metadata":{"trusted":true,"_uuid":"7c9788f420fd8fd392cf1d8d4abb6656d4982b12"},"cell_type":"code","source":"train_prep.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceae0482dd25e53518180b6225b8aed3b28c3c3c"},"cell_type":"code","source":"test_prep.info()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cb0196d4b82814785d51820365c4bfab2380ed89"},"cell_type":"code","source":"train_prep.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18a0f9715df1ba2420093756bafd54edf5ca11e7"},"cell_type":"code","source":"test_prep.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9318f430782728538f797c1175c25b80f9e7a118"},"cell_type":"markdown","source":"The following points still need to be improved:\n\n* Zero values in the test data\n* Normalization of training and test data"},{"metadata":{"trusted":true,"_uuid":"43cb7b1210eb802615e3fd14fa823186d725c31f"},"cell_type":"code","source":"test_prep[\"Fare\"] = test_prep[\"Fare\"].fillna(test_prep[\"Fare\"].mean())\n\nscaler = MinMaxScaler()\n\ntrain_prep[[\"SibSp\", \"Parch\", \"Fare\", \"Title\"]] = scaler.fit_transform(train_prep[[\"SibSp\", \"Parch\", \"Fare\", \"Title\"]])\ntest_prep[[\"SibSp\", \"Parch\", \"Fare\", \"Title\"]] = scaler.fit_transform(test_prep[[\"SibSp\", \"Parch\", \"Fare\", \"Title\"]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"174437fd8fd74a43d22d8528652beec35d0924fc"},"cell_type":"markdown","source":"Now that we have finished optimizing, we can proceed with the selection of an appropriate model. For this we try different classifier on our dataset and see what fits best."},{"metadata":{"trusted":true,"_uuid":"2360a9d5042498c05a7c9a75041c20b499d7b75a","_kg_hide-input":true},"cell_type":"code","source":"X_train = train_prep.drop(columns=[\"Survived\"])\ny_train = train_prep[\"Survived\"]\nX_test = test_prep\n\nnames = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n         \"Naive Bayes\", \"QDA\"\n]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    SVC(kernel=\"linear\"),\n    SVC(kernel=\"rbf\"),\n    GaussianProcessClassifier(),\n    tree.DecisionTreeClassifier(max_depth=3),\n    RandomForestClassifier(max_depth=3),\n    MLPClassifier(),\n    AdaBoostClassifier(),\n    GaussianNB(),\n    QuadraticDiscriminantAnalysis()\n]\n\nresults = {}\nfor name, clf in zip(names, classifiers):\n    scores = cross_val_score(clf, X_train, y_train, cv=5)\n    results[name] = scores\n    \nfor name, scores in results.items():\n    print(\"%20s | Accuracy: %0.2f%% (+/- %0.2f%%)\" % (name, 100*scores.mean(), 100*scores.std() * 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6214bdabec5982d5700785fb393bb5b297031ff8"},"cell_type":"markdown","source":"In this case it's the Neural Net which performs really well. So we will us this as our submission. "},{"metadata":{"trusted":true,"_uuid":"264ffbc94217b17410867c375d7b97860ef8b08f"},"cell_type":"code","source":"nn = classifiers[3]\nnn.fit(X_train, y_train)\npredictions = nn.predict(X_test)\n\nsubmission = pd.DataFrame({ 'PassengerId' : test[\"PassengerId\"], 'Survived': predictions })\nsubmission.to_csv('submission_gp.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e264c589e32849ca9ad52a0856cefd80a890c548"},"cell_type":"code","source":"nn = classifiers[4]\nnn.fit(X_train, y_train)\npredictions = nn.predict(X_test)\n\nsubmission = pd.DataFrame({ 'PassengerId' : test[\"PassengerId\"], 'Survived': predictions })\nsubmission.to_csv('submission_dt.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d604da7fa1459bc7d4359848195ffb9a5677818c"},"cell_type":"code","source":"nn = classifiers[5]\nnn.fit(X_train, y_train)\npredictions = nn.predict(X_test)\n\nsubmission = pd.DataFrame({ 'PassengerId' : test[\"PassengerId\"], 'Survived': predictions })\nsubmission.to_csv('submission_rf.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63697d558ba011327d99e3cf4cfc7cf6afc01d56","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"nn = classifiers[6]\nnn.fit(X_train, y_train)\npredictions = nn.predict(X_test)\n\nsubmission = pd.DataFrame({ 'PassengerId' : test[\"PassengerId\"], 'Survived': predictions })\nsubmission.to_csv('submission_nn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"424fb4084dd6ede3e3a5730f91d0870b98df9b7d"},"cell_type":"code","source":"nn = classifiers[7]\nnn.fit(X_train, y_train)\npredictions = nn.predict(X_test)\n\nsubmission = pd.DataFrame({ 'PassengerId' : test[\"PassengerId\"], 'Survived': predictions })\nsubmission.to_csv('submission_ab.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1c616fe1b5ecf182efc7670d25ebbf9c0053398"},"cell_type":"markdown","source":"If you've come this far thank you for reading! If you have any feedback, I would be very happy to hear from you."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}