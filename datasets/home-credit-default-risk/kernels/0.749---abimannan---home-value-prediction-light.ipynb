{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder # Machine learning\nimport seaborn as sns # data visualization\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(\"Importing dataframes\")\ndtrain = pd.read_csv('../input/application_train.csv')\ndtest = pd.read_csv('../input/application_test.csv')\nprint(\"Done\")\nprint (\"\")\nprint(\"Combining Train and Test\")\ndf = pd.concat([dtrain,dtest],axis=0)\nprint(\"Done\")\nprint('\\nAll Data shape: {} Rows, {} Columns'.format(*df.shape))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bc81151e377c8e7adee2bccf73cae9ab7497d05"},"cell_type":"code","source":"dtrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcea5d3bcb6c0bf0059238c35182505e68e9c5a6"},"cell_type":"code","source":"dtest.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1564e9234c8a1355ae1dbbc428698a2a7b3f67d4"},"cell_type":"code","source":"target = dtrain['TARGET'].astype(int)\nplt.figure(figsize=(10,6))\nsns.distplot(target, kde=False, bins=8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"80fcd18ebbe7a4a6b8363b3fd79c4fca944f5df9"},"cell_type":"code","source":"le = LabelEncoder()\nle_cnt = 0\n\n# Iterate through the columns\nfor col in dtrain:\n    if dtrain[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(dtrain[col].unique())) <= 2:\n            # Train on the training data\n            le.fit(dtrain[col])\n            # Transform both training and testing data\n            dtrain[col] = le.transform(dtrain[col])\n            dtest[col] = le.transform(dtest[col])\n            \n            # Keep track of how many columns were label encoded\n            le_cnt += 1\n            \nprint('Label encoding has been applied on %d columns' % le_cnt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b82c6eac97615ec5ad934682cc729381eb1f747"},"cell_type":"code","source":"dtrain = pd.get_dummies(dtrain)\ndtest = pd.get_dummies(dtest)\n\nprint('Training Features shape: ', dtrain.shape)\nprint('Testing Features shape: ', dtest.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc8f96e107ecad102a09cc6ba564e5fd811c3cfc"},"cell_type":"code","source":"train_labels = dtrain['TARGET']\n\n# Align the training and testing data, keep only columns present in both dataframes\ndtrain, dtest = dtrain.align(dtest, join = 'inner', axis = 1)\n\nprint('Training Features shape: ', dtrain.shape)\nprint('Testing Features shape: ', dtest.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f51740e472bad32f4cabae3c1e0c64b628169883"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, Imputer\n\n# Drop the target from the training data\nif 'TARGET' in dtrain:\n    train = dtrain.drop(columns = ['TARGET'])\nelse:\n    train = dtrain.copy()\nfeatures = list(train.columns)\n\n# Copy of the testing data\ntest = dtest.copy()\n\n# Median imputation of missing values\nimputer = Imputer(strategy = 'median')\n\n# Scale each feature to 0-1\nscaler = MinMaxScaler(feature_range = (0, 1))\n\n# Fit on the training data\nimputer.fit(train)\n\n# Transform both training and testing data\ntrain = imputer.transform(train)\ntest = imputer.transform(dtest)\n\n# Repeat with the scaler\nscaler.fit(train)\ntrain = scaler.transform(train)\ntest = scaler.transform(test)\n\nprint('Training data shape: ', train.shape)\nprint('Testing data shape: ', test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"bc210f26b1d39a69515a513dd1b5f8b8ecc4e56f"},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\nimport gc\n\n# Format the training and testing data \ntrain = np.array(dtrain)\ntest = np.array(dtest)\n\ntrain_labels = np.array(train_labels).reshape((-1, ))\n\n# 10 fold cross validation\nfolds = KFold(n_splits=5, shuffle=True, random_state=50)\n\n# Validation and test predictions\nvalid_preds = np.zeros(train.shape[0])\ntest_preds = np.zeros(test.shape[0])\n\n# Iterate through each fold\nfor n_fold, (train_indices, valid_indices) in enumerate(folds.split(train)):\n    # Training data for the fold\n    train_fold, train_fold_labels = train[train_indices, :], train_labels[train_indices]\n    \n    # Validation data for the fold\n    valid_fold, valid_fold_labels = train[valid_indices, :], train_labels[valid_indices]\n    \n    # LightGBM classifier with hyperparameters\n    clf = LGBMClassifier(\n        nthread=4,\n        n_estimators=10000,\n        learning_rate=0.02,\n        num_leaves=34,\n        colsample_bytree=0.9497036,\n        subsample=0.8715623,\n        subsample_freq=1,\n        max_depth=8,\n        reg_alpha=0.041545473,\n        reg_lambda=0.0735294,\n        min_split_gain=0.0222415,\n        min_child_weight=39.3259775,\n        random_state=0,\n        silent=-1,\n        verbose=-1,\n    )\n    \n    # Fit on the training data, evaluate on the validation data\n    clf.fit(train_fold, train_fold_labels, \n            eval_set= [(train_fold, train_fold_labels), (valid_fold, valid_fold_labels)], \n            eval_metric='auc', early_stopping_rounds=200, verbose = 100\n           )\n    \n    # Validation preditions\n    valid_preds[valid_indices] = clf.predict_proba(valid_fold, num_iteration=clf.best_iteration_)[:, 1]\n    \n    # Testing predictions\n    test_preds += clf.predict_proba(test, num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n    \n    # Display the performance for the current fold\n    print('Fold %d AUC : %0.6f' % (n_fold + 1, roc_auc_score(valid_fold_labels, valid_preds[valid_indices])))\n    \n    # Delete variables to free up memory\n    del clf, train_fold, train_fold_labels, valid_fold, valid_fold_labels\n    gc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"555d8d7f3dc55e6c208f715c9deae058f667d929"},"cell_type":"code","source":"submission = dtest[['SK_ID_CURR']]\nsubmission['TARGET'] = test_preds\nsubmission.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"8520f241d3acc75a5826c94ee5f1fcc08664988a"},"cell_type":"code","source":"submission.to_csv(\"abimannan_home.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"2ef5204d6e5ecf050c1f64a5e11c61b72beb70c9"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}