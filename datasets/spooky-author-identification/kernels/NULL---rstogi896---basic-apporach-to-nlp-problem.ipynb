{"cells":[{"metadata":{"_uuid":"d35ee1670174c92f1431ed5547273ae8461f25fb"},"cell_type":"markdown","source":"# In this post I will show some good classifiers to approaching any natural language processing Classification Problem."},{"metadata":{"_uuid":"ccc66f130ea47cd7eefca60fd9277ac7775d5ccf"},"cell_type":"markdown","source":"# Logistic Regression"},{"metadata":{"_uuid":"2681c8925cfd70f196c9b37ec0818e6ebff6b56a"},"cell_type":"markdown","source":"# linearsvc"},{"metadata":{"_uuid":"3f65b8255f9846cfd0a3d15eee8e94ce33e8a2e6"},"cell_type":"markdown","source":"# Xgb"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport pandas as pd\nimport numpy as np\nimport nltk\nimport matplotlib.pyplot as plt\nimport string\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.classify import SklearnClassifier\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom io import StringIO\nfrom sklearn import model_selection \nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nfrom wordcloud import WordCloud, STOPWORDS\nimport seaborn as sns\nfrom collections import Counter\nimport xgboost as xgb\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nsample = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90107f724e4357ea184ef626b9e304eba2a26b5f","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55e639042186086194bbf497a1afb36b3f1b6b88","trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe0d69e6c866f6ffb130a8abba96a2bca5ed9c36","trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"962ae1a4684f8e2b05245b1e2ccac875101cf23b","trusted":true},"cell_type":"code","source":"sample.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b1b4eaacb8ad6cc72a6f1787b1239883c8a2800c","trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,4))\ntrain.groupby('author').count().plot.bar(ylim=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2f54201a62664cdc4886893a0aebe4428d88495","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train['text'], title=\"Word Cloud of text in Train data\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec5e60f83348a1379325907636d9cfdc70e0e9dc","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS\n\n# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color='black',\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=800, \n                    height=400,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(test['text'], title=\"Word Cloud of text in test data\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"36025a29431635f2b7bb1ad1561f409587bb246b"},"cell_type":"markdown","source":"# The problem requires us to predict the author, i.e. EAP, HPL and MWS given the text. In simpler words, text classification with 3 different classes."},{"metadata":{"_uuid":"47dabb83622b5ed739d943277392e2aa985c5645","trusted":true},"cell_type":"code","source":"def multiclass_logloss(actual, predicted, eps=1e-15):\n    \"\"\"Multi class version of Logarithmic Loss metric.\n    :param actual: Array containing the actual target classes\n    :param predicted: Matrix with class predictions, one probability per class\n    \"\"\"\n    # Convert 'actual' to a binary array if it's not already:\n    if len(actual.shape) == 1:\n        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n        for i, val in enumerate(actual):\n            actual2[i, val] = 1\n        actual = actual2\n\n    clip = np.clip(predicted, eps, 1 - eps)\n    rows = actual.shape[0]\n    vsota = np.sum(actual * np.log(clip))\n    return -1.0 / rows * vsota","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"53d73076321993ee1a900b4ecb72f1fe9a86b99d"},"cell_type":"markdown","source":"# We use the LabelEncoder from scikit-learn to convert text labels to integers, 0, 1 2"},{"metadata":{"_uuid":"42fb19f5f412984a9c1c437b37e1440ae2bead09","trusted":true},"cell_type":"code","source":"lbl_enc = preprocessing.LabelEncoder()\ny = lbl_enc.fit_transform(train.author.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eaeffb8e0eb9e087c8de349bae0a679a7fe9ab7d","trusted":true},"cell_type":"code","source":"xtrain, xvalid, ytrain, yvalid = train_test_split(train.text.values, y, \n                                                  stratify=y, \n                                                  random_state=2019, \n                                                  test_size=0.1, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9686aff499e450330010446bd3fc2039f16df6e7","trusted":true},"cell_type":"code","source":"tfv = TfidfVectorizer(min_df=5,  max_features=None, \n            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n            ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n            stop_words = 'english')\ntfv.fit(list(xtrain) + list(xvalid))\nxtrain_tfv =  tfv.transform(xtrain) \nxvalid_tfv = tfv.transform(xvalid)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"22eb8ffdd67c6a0dc60ff50f96957277e1ac4248"},"cell_type":"markdown","source":"# we can se below how  the accuracy depend on regularization parameter of logistic regression."},{"metadata":{"_uuid":"8ff27a532051a9ca45cc5a434c076e83b086a289","trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=1.0)\nclf.fit(xtrain_tfv, ytrain)\npredictions = clf.predict_proba(xvalid_tfv)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0130c680d92d28cffd47cc1301632e7ffdd3b8e0","trusted":true},"cell_type":"code","source":"idx = predictions.argmax(axis=1)\npredictions = (idx[:,None] == np.arange(predictions.shape[1])).astype(int)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67950595bdc645566fc80436fe8ac96a8f948a8f","trusted":true},"cell_type":"code","source":"predictions = [np.where(r == 1)[0][0] for r in predictions]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"492aa677427b35e40738025d40d058ab32b4f61d","trusted":true},"cell_type":"code","source":" accuracy_score(yvalid, predictions)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c6ed16178b39e8fdd775b86cc92ea07840edeb6f","trusted":true},"cell_type":"code","source":"clf = LogisticRegression(C=3.0)\nclf.fit(xtrain_tfv, ytrain)\npredictions1 = clf.predict_proba(xvalid_tfv)\nidx = predictions1.argmax(axis=1)\npredictions1 = (idx[:,None] == np.arange(predictions1.shape[1])).astype(int)\npredictions1 = [np.where(r == 1)[0][0] for r in predictions1]\naccuracy_score(yvalid, predictions1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6572205dd1c3939eeadf3d229c7df1df16104c16"},"cell_type":"markdown","source":"# linearsvc"},{"metadata":{"_uuid":"acd60ba6fb3e64b596633e39c56e9c75bac4f8a3","trusted":true},"cell_type":"code","source":"clf = LinearSVC(max_iter=1000)\nclf.fit(xtrain_tfv, ytrain)\ny_pred = clf.predict(xvalid_tfv)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b432342b6ce362c9a0a3e31439cedf1a7e4e763","trusted":true},"cell_type":"code","source":"accuracy_score(yvalid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a54da1dbaa73d1131d71b343a9755a94a04a2750"},"cell_type":"markdown","source":"# Xgb"},{"metadata":{"_uuid":"198bc27edd7cff4458aa0f8576ce0f61b4dace85","trusted":true},"cell_type":"code","source":"param = {'objective':'multi:softprob',\n          'num_class':3,\n          'eval_metric':'merror',\n           'nthread':10\n         }","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"20d7cfa36779db7bee2862e950780d4c2aa7eedf","trusted":true},"cell_type":"code","source":"dtrain = xgb.DMatrix(data=xtrain_tfv, label= ytrain)\ndtest = xgb.DMatrix(data=xvalid_tfv)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef5251fc8dd38b36caf9a009e4870ec8353da132","trusted":true},"cell_type":"code","source":"watchlist  = [(dtrain,'train')]\nnum_round = 2500\nearly_stopping_rounds=50\nbst = xgb.train(param, dtrain, num_round, watchlist,early_stopping_rounds=early_stopping_rounds)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"943e483e712af464083436ada75db4e53dd1eb8a","trusted":true},"cell_type":"code","source":"y_pred = bst.predict(dtest)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc2c1428db15a8176ffdae4140094764f9ad1546","trusted":true},"cell_type":"code","source":"y_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f53dff14c2fc007beaedb1ba8f3dea4ab49bb86","trusted":true},"cell_type":"code","source":"idx = y_pred.argmax(axis=1)\ny_pred = (idx[:,None] == np.arange(y_pred.shape[1])).astype(int)\ny_pred","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55d1ec36e07b88764d8e4b3be4f09981527718e7","trusted":true},"cell_type":"code","source":"y_pred = [np.where(r == 1)[0][0] for r in y_pred]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ed5a0b15954ce61254c485af5d0c999011d2fcb","trusted":true},"cell_type":"code","source":"accuracy_score(yvalid, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9a0811665172b08f5ac6fa5e8e91b48a2c813a5a","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}