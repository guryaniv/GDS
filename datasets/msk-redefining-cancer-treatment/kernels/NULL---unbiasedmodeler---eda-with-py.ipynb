{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"markdown","source":"# Personalized Medicine EDA\n\nThe purpose of this notebook is to learn more about NLP techniques\n\nThis notebook combines insightful analysis from the following kernels in this competition:\n\nR:\n\nhttps://www.kaggle.com/headsortails/personalised-medicine-eda-with-tidy-r\n\nPython:\n\nhttps://www.kaggle.com/dextrousjinx/brief-insight-on-genetic-variations\n\nhttps://www.kaggle.com/umutto/preliminary-data-analysis-using-word2vec\n\nThis is a work-in-progress!"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# Table of Contents\n1. [Import modules] (#import)\n2. [Import Data Frames] (#DF)\n        2.1 [Overview of Data) (#overview)\n\n\n\n\n# Introduction\n\nThe objective is to classify genetic mutations that contribute to cancer tumor growth (drivers) in the presence of mutatins that don't affect the tumors (passengers).\n\nThe text information that describes the mutations is used to classify the mutations\n\nWhile obtaining high accuracy requires some domain knowledge, I'm mainly using this as an opportunity to learn more about NLP techniques"},{"metadata":{"_uuid":"9f311bde44500b05648ab8e035295de169ced2b9"},"cell_type":"markdown","source":"## Import Modules <a id=\"import\"></a>"},{"metadata":{"trusted":true,"_uuid":"320da3af055aa1f8f8dd2c17529c7a0d0898d4cf","collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input\"))\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Text analysis helper libraries\nfrom gensim.summarization import summarize\nfrom gensim.summarization import keywords\n\n# Text analysis helper libraries for word frequency etc..\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\n# Word cloud visualization libraries\nfrom scipy.misc import imresize\nfrom PIL import Image\nfrom wordcloud import WordCloud, ImageColorGenerator\nfrom collections import Counter\n\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"01489c2481f03c2923112ef6fb29e638eb24ddb7"},"cell_type":"markdown","source":"## Import Data Frames <a id=\"DF\"></a>"},{"metadata":{"trusted":true,"_uuid":"8d5e0f53e4b028f258adabdd6dbedeba4476791c","collapsed":true},"cell_type":"code","source":"train_variants_df = pd.read_csv(\"../input/training_variants\")\ntest_variants_df = pd.read_csv(\"../input/test_variants\")\ntrain_txt_df = pd.read_csv(\"../input/training_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntest_txt_df = pd.read_csv(\"../input/test_text\", sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\nprint(\"Train and Test variants shape : \",train_variants_df.shape, test_variants_df.shape)\nprint(\"Train and Test text shape : \",train_txt_df.shape, test_txt_df.shape)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"115801e64ec4fe6d9f4993f200fe000d0730a839"},"cell_type":"code","source":"train_df = pd.merge(train_variants_df, train_txt_df, on='ID')\ntest_df = pd.merge(test_variants_df, test_txt_df, on='ID')\n#train_df.head(5)\n#test_df.head(5)","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"83fc715058d7a4006668804e7fcd53ca8970235f"},"cell_type":"markdown","source":"## 2.1 Overview of Data  <a id=\"overview\"></a>"},{"metadata":{"trusted":true,"_uuid":"e5f939271a5f502e576a1f25301d78e8b9cf8bd1","collapsed":true},"cell_type":"code","source":"#train_df.describe()\ntrain_df.head(5)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c0a85fbbf100d113cf300178ea022f4f02b9737c","collapsed":true},"cell_type":"code","source":"print(\"For training data, there are a total of\", len(train_df.ID.unique()), \"IDs,\")\nprint(len(train_df.Gene.unique()), \"unique genes,\")\nprint(len(train_df.Variation.unique()), \"unique variations and \")\nprint(len(train_df.Class.unique()),  \"classes\")","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"12c90a2bba7a2269ebfe5cbce5f51fdf3d5caa49"},"cell_type":"markdown","source":"## Plot Class distribution"},{"metadata":{"trusted":true,"_uuid":"7ab69bd40d2d2b350196249db55d2bab23a1092f","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(x=\"Class\", data=train_df)\nplt.ylabel('Frequency', fontsize=14)\nplt.xlabel('Class', fontsize=14)\nplt.title(\"Distribution of genetic mutation classes\", fontsize=18)\nplt.show()","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f828276b99494a2f3bc754c787e68537b2b7f7d1","collapsed":true},"cell_type":"code","source":"train_genes = train_df.groupby(\"Gene\")['Gene'].count()\nfewest_genes = train_genes.sort_values(ascending=True)[:10]\nprint(\"Genes with most occurences\\n\", train_genes.sort_values(ascending=False)[:10])\nprint(\"\\nGenes with fewest occurences\\n\", fewest_genes)","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"45f0578f8b7efef9e0f1c66cf2afa4413ade66ab"},"cell_type":"markdown","source":"### Genes with highest frequencies in each class"},{"metadata":{"trusted":true,"_uuid":"a74585566c20e783ee038356502700697daa0958","collapsed":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=3, ncols=3, sharey=True, figsize=(12,12))\n\n# Normalize value counts for better comparison\ndef normalize_group(x):\n    label, repetition = x.index, x\n    t = sum(repetition)\n    r = [n/t for n in repetition]\n    return label, r\n\nfor idx, g in enumerate(train_df.groupby('Class')):\n    label, val = normalize_group(g[1][\"Gene\"].value_counts())\n    ax = axes.flat[idx]\n    ax.bar(np.arange(5), val[:5],\n           tick_label=label[:5]) \n    ax.set_title(\"Class {}\".format(g[0]))\n    \nfig.text(0.5, 0.97, 'Normalized Top 5 Gene Frequency for each Class', ha='center', fontsize=14, fontweight='bold')\nfig.text(0.5, 0, 'Gene', ha='center', fontweight='bold')\nfig.text(0, 0.5, 'Frequency', va='center', rotation='vertical', fontweight='bold')\nfig.tight_layout(rect=[0.03, 0.03, 0.95, 0.95])","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"e12e4180042c8625fdb2ad20ec13de1328fe5a20"},"cell_type":"markdown","source":"We see that the most frequent genes in each class are very different\n\n## Next, let us analyze the text data"},{"metadata":{"trusted":true,"_uuid":"60612eb2ff37eb39a86f2c6fb7f32d12ae3a36e5","collapsed":true},"cell_type":"code","source":"train_df.head(5)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0886a1844754dc8f1f1393fe44764db0622d808","collapsed":true},"cell_type":"code","source":"train_df['Text_count']  = train_df[\"Text\"].apply(lambda x: len(str(x).split()))\ntrain_df.head()","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"64dc83fc78f230602893d2bf669f7255da6c51f1"},"cell_type":"markdown","source":"### Frequency of no. of words in text"},{"metadata":{"trusted":true,"_uuid":"cdab053ab2ab2b760f8cb12204a4b5423b9ed763","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12, 8))\nsns.distplot(train_df.Text_count.values, bins=50, kde=False, color='blue')\nplt.xlabel('Number of words in text', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.title(\"Frequency of number of words\", fontsize=15)\nplt.show()","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"0200eb28daf3fce40f38eb0c865f6ab7da855393"},"cell_type":"markdown","source":"### Distribution of text count for each class - violin plot"},{"metadata":{"trusted":true,"_uuid":"060eee6be83fed91fe5d868efa98dd5566246dc3","collapsed":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\ngene_count_grp = train_df.groupby('Gene')[\"Text_count\"].sum().reset_index()\nsns.violinplot(x=\"Class\", y=\"Text_count\", data=train_df, inner=None)\nsns.swarmplot(x=\"Class\", y=\"Text_count\", data=train_df, color=\"y\", alpha=.5);\nplt.ylabel('Text Count', fontsize=14)\nplt.xlabel('Class', fontsize=14)\nplt.title(\"Text length distribution\", fontsize=18)\nplt.show()","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"9be00f3e6b07cfc0f81fd8ea01ef1d0965eb666b"},"cell_type":"markdown","source":"We see that all the classes have text counts between 0-20,000\n\n## Let us look at the dominant words in each class\n\nText is tokenized, cleaned of stopwords and lemmatized for word frequency analysis"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e569793d789324c6d96a152ce27203c7ebfff42"},"cell_type":"code","source":"custom_words = [\"fig\", \"figure\", \"et\", \"al\", \"al.\", \"also\",\n                \"data\", \"analyze\", \"study\", \"table\", \"using\",\n                \"method\", \"result\", \"conclusion\", \"author\", \n                \"find\", \"found\", \"show\", '\"', \"’\", \"“\", \"”\"]\n\nstop_words = set(stopwords.words('english') + list(punctuation) + custom_words)\nwordnet_lemmatizer = WordNetLemmatizer()\n\nclass_corpus = train_df.groupby('Class').apply(lambda x: x['Text'].str.cat())","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f7df5336e955fba3a288e0deeb612cb0bc450581"},"cell_type":"code","source":"# this cell takes a long time\n\nclass_corpus = class_corpus.apply(lambda x: Counter(\n    [wordnet_lemmatizer.lemmatize(w) \n     for w in word_tokenize(x) \n     if w.lower() not in stop_words and not w.isdigit()]\n))","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e2a511ce50f78344dbcea219abe1b1ce3c16400","collapsed":true},"cell_type":"code","source":"class_corpus","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca220c6a307316d565492b7f916f3853792bc4cb","collapsed":true},"cell_type":"code","source":"whole_text_freq = class_corpus.sum()\n\nfig, ax = plt.subplots()\n\nlabel, repetition = zip(*whole_text_freq.most_common(25))\n\nax.barh(range(len(label)), repetition, align='center')\nax.set_yticks(np.arange(len(label)))\nax.set_yticklabels(label)\nax.invert_yaxis()\n\nax.set_title('Word Distribution Over Whole Text')\nax.set_xlabel('# of repetitions')\nax.set_ylabel('Word')\n\nplt.tight_layout()\nplt.show()","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"33e40b016295b0e8df22e5d36a00012650fdff24"},"cell_type":"markdown","source":"# TF-IDF Analysis"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b4678cc9074cf915316ee67dd7f21938d399e51d"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn import svm\n\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, accuracy_score","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac09382675a06b66f071336745fbe6849d42d93","collapsed":true},"cell_type":"code","source":"train_df['Text'].head()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c57e9c2d09dcd43450669d38228538f3c6071ad7"},"cell_type":"code","source":"tfidf = TfidfVectorizer(\n                    min_df=5, max_features=16000, strip_accents='unicode', lowercase=True,\n                    analyzer='word', token_pattern=r'\\w+', ngram_range=(1, 3), use_idf=True, \n                    smooth_idf=True, sublinear_tf=True, stop_words = 'english')","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"432c7afcb779dc46e46125fd88f1cd942d5288a0","collapsed":true},"cell_type":"code","source":"# this cell takes a long time\ntfidf.fit(train_df[\"Text\"].values.astype('U'))","execution_count":19,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"705a5dace5779deb8f007f7d13e6e42caffb7e59"},"cell_type":"code","source":"X_train_tfidf = tfidf.transform(train_df['Text'].values.astype('U'))\nX_test_tfidf = tfidf.transform(test_df['Text'].values.astype('U'))\n\ny_train = train_df['Class'].values","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4cb8f5cded24a17cc8dbff75603599bd85f9081a"},"cell_type":"code","source":"def evaluate(X, y, clf=None):\n    probas = cross_val_predict(clf, X, y, cv=StratifiedKFold(n_splits=5, random_state=8), \n                              n_jobs=-1, method='predict_proba', verbose=2)\n    pred_indices = np.argmax(probas, axis=1)\n    classes = np.unique(y)\n    preds = classes[pred_indices]\n    print('Log loss: {}'.format(log_loss(y, probas)))\n    print('Accuracy: {}'.format(accuracy_score(y, preds)))","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"afbfb7d44fc87cd158c48b28d5a35270ceb644b8"},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true,"_uuid":"dcb4ced8355dfc4ff850fc896512fcb3b8b4f30b","collapsed":true},"cell_type":"code","source":"# this cell takes a long time\nclf=svm.SVC(probability=True)\nclf.fit(X_train_tfidf, y_train)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"250aedad46bddb9817894f85b28ae33dacd6b3ea"},"cell_type":"code","source":"y_test_predicted = clf.predict_proba(X_test_tfidf)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"47f1497be4336fe892111379323f07cf187670ff"},"cell_type":"markdown","source":"# Create Submission File"},{"metadata":{"trusted":true,"_uuid":"7699d05cae4931b76a82fb12507ddece452e13b0","collapsed":true},"cell_type":"code","source":"submission_df = pd.DataFrame(y_test_predicted, columns=['class' + str(c + 1) for c in range(9)])\nsubmission_df.insert(0, 'ID', value=test_df['ID'])","execution_count":31,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd0e4a258772dd6b1d5e49b7c6ed8cd8d3d64d59","collapsed":true},"cell_type":"code","source":"submission_df.head()","execution_count":32,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"852cb20da3eaec2f067398f30e0587a3cd53c1f3"},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":33,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"772db403072d523afdf10615644331158bd3829a"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"7fc243f5abd01baf9f277c9dfe81e662618c4da5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}