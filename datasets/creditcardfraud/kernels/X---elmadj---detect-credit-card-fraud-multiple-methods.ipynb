{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "4614ef06-eee5-993a-3f3d-cff50aa6fa64"
      },
      "source": [
        "**Import the Data and import useful libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f00c2a1-2f6a-70b2-302c-57c70aa79832"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plot\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.cross_validation import KFold, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report, precision_score\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "\n",
        "data= pd.read_csv('../input/creditcard.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eaa92369-ce48-27ee-d21a-4663861b9336"
      },
      "source": [
        "**Check if classes are imbalanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4098c117-33e7-1d56-3eda-95b04e7ec8d4"
      },
      "outputs": [],
      "source": [
        "count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n",
        "count_classes.plot(kind = 'bar')\n",
        "plot.title(\"Fraud class histogram\")\n",
        "plot.xlabel(\"Class\")\n",
        "plot.ylabel(\"Frequency\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "747d08f8-d247-361f-b85f-a1a4984d187b"
      },
      "source": [
        "There is a clear imbalance between the two classes. We will need to sample the data to make the two classes equally represented in the training and test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8b33839a-58ae-f20c-77e3-5c00956dbb7c"
      },
      "source": [
        "Now let's what ranges the data has "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9e105d71-257b-e5a5-2e94-9ea1a6cec0c0"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ec4fa692-8aea-f912-1afb-2941e04139ad"
      },
      "source": [
        "All features show a mean very close to zero except for Amount."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9dcc2331-0724-639f-7e0f-9b01d7f6f117"
      },
      "source": [
        "**Normalize the Amount column and drop the not so useful Time column**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f5379247-d778-7388-0cf1-d2fa51918d62"
      },
      "outputs": [],
      "source": [
        "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
        "data = data.drop(['Time','Amount'],axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "40d7d1dd-33fa-2dfd-feca-3d753373c91f"
      },
      "outputs": [],
      "source": [
        "# Number of data points in the minority class\n",
        "number_records_fraud = len(data[data.Class == 1])\n",
        "fraud_indices = np.array(data[data.Class == 1].index)\n",
        "\n",
        "nonfraud_indices = data[data.Class == 0].index\n",
        "\n",
        "random_nonfraud_indices = np.random.choice(nonfraud_indices, number_records_fraud, replace = False)\n",
        "random_nonfraud_indices = np.array(random_nonfraud_indices)\n",
        "\n",
        "# concatenate everything together\n",
        "sampled_indices = np.concatenate([fraud_indices,random_nonfraud_indices])\n",
        "\n",
        "# dataset\n",
        "sampled_data = data.iloc[sampled_indices,:]\n",
        "\n",
        "X_sampled = sampled_data.ix[:, sampled_data.columns != 'Class']\n",
        "y_sampled = sampled_data.ix[:, sampled_data.columns == 'Class']\n",
        "\n",
        "# Showing ratio\n",
        "print(\"Percentage of legit transactions: \", len(sampled_data[sampled_data.Class == 0])/len(sampled_data))\n",
        "print(\"Percentage of fraud transactions: \", len(sampled_data[sampled_data.Class == 1])/len(sampled_data))\n",
        "print(\"Total number of transactions in sampled data: \", len(sampled_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6639c494-56f8-cdbb-2d25-9480841165f0"
      },
      "source": [
        "**Divide into training and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "be40ca92-eda0-e0d0-1e10-0e5a6f29fec5"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_sampled,y_sampled,test_size = 0.3, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "41ddf060-189b-6414-696c-d28865b8c158"
      },
      "source": [
        "**Create the first classifier by fitting a decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70fb4bfc-3e95-4543-f501-a9a696b274a1"
      },
      "outputs": [],
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b9b8e1cd-39a3-5e50-7fca-d2e1f1e5dc34"
      },
      "source": [
        "**Let's evaluate the decision tree with the precision recall curve**\n",
        "First get the predictions for  the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "166ddbca-b783-b409-a557-5b06a73ee78f"
      },
      "outputs": [],
      "source": [
        "y_test_pred = clf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "95f9c4a4-1c50-db4b-6d36-3fccc756e426"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, y_test_pred[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e1d67fe-bd69-729f-0f2d-d4b875945372"
      },
      "outputs": [],
      "source": [
        "plot.plot(recall, precision, color='navy', label='Precision-Recall curve')\n",
        "plot.ylabel('precision')\n",
        "plot.xlabel('recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "02a2f250-6fbf-88d1-1c4f-10c57860aa21"
      },
      "source": [
        "For this data set. We need to evaluate the classifiers with a recall metric because our priority is to detect fraudulent transactions. Undetected fraud cases are more problematic than cases where we wrongly classify fraud cases as legit transactions. Let's see our best recall score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc1d20eb-6436-4fe2-26d0-1804dc007df2"
      },
      "outputs": [],
      "source": [
        "recall[recall <1 ].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "05655688-1298-ba1c-998c-bc70bac5ae47"
      },
      "source": [
        "**Now let's train a logistic regression model on the sae data and compare it to our tree classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "55aefb7e-6f58-3759-d36f-d9ab7dbb2a0e"
      },
      "source": [
        "Define a function which does k-fold cross validation training for multiple values of the C parameter and returns the C parameter which results in the best model with regards to the recall metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "403b8248-b63d-693f-8a46-ab9847ade0cb"
      },
      "outputs": [],
      "source": [
        "def best_Kfold_Cparam(x_train_data,y_train_data,c_param_range,k):\n",
        "    fold = KFold(len(y_train_data),k,shuffle=True) \n",
        "    \n",
        "    results = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score', 'Mean '])\n",
        "    j = 0\n",
        "    for c_param in c_param_range:\n",
        "        print('C parameter: ', c_param)\n",
        "        \n",
        "        recall_accs = []\n",
        "        for iteration, indices in enumerate(fold,start=1):\n",
        "            train_indices = indices[0]\n",
        "            validation_indices = indices[1]\n",
        "            \n",
        "            lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
        "            lr.fit(x_train_data.iloc[train_indices,:],y_train_data.iloc[train_indices,:].values.ravel())\n",
        "           \n",
        "            y_pred_sample = lr.predict(x_train_data.iloc[validation_indices,:].values)\n",
        "\n",
        "            recall_acc = recall_score(y_train_data.iloc[validation_indices,:].values,y_pred_sample)\n",
        "            recall_accs.append(recall_acc)            \n",
        "\n",
        "        # save all recall scores associated with their c parameter\n",
        "        results.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
        "        results.ix[j,'C_parameter'] = c_param\n",
        "        j += 1\n",
        "        print('')\n",
        "        print('Mean recall score ', np.mean(recall_accs))\n",
        "        print('')\n",
        "\n",
        "    best_c = results.loc[results['Mean recall score'].idxmax()]['C_parameter']\n",
        "    \n",
        "    print('Best model w/ regards to recall has C parameter ', best_c)\n",
        "    \n",
        "    return best_c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8bfd6813-409a-9f42-bd77-a0e1e1d532f6"
      },
      "outputs": [],
      "source": [
        "best = best_Kfold_Cparam(X_train,y_train,[0.00001,0.0001,0.001,0.01,0.1,1,10],10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b2389f1c-32fa-0c51-ac23-ecf7714cb1ec"
      },
      "source": [
        "0.001 is our best C parameter value. Now train a logistic classifier for real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a32b842e-c308-b384-7bc5-f3052ac9426b"
      },
      "outputs": [],
      "source": [
        "flr = LogisticRegression(C = 0.001, penalty = 'l1')\n",
        "flr.fit(X_train,y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b0ce89fd-b8c8-0ccc-dab1-773a22033000"
      },
      "source": [
        "Now let's evaluate our regression model and compare it to the decision tree previously created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "aae7eac6-76c4-5e9c-5f8b-3ee474801f03"
      },
      "outputs": [],
      "source": [
        "y_pred_test = flr.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "86134d2c-ddc6-9d26-07f9-a331ff7c4c79"
      },
      "outputs": [],
      "source": [
        "precision_2, recall_2, thresholds_2 = precision_recall_curve(y_test, y_pred_test[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b8ab8b94-5140-5a8c-dfc9-024710711191"
      },
      "outputs": [],
      "source": [
        "plot.plot(recall, precision, color='navy', label='Precision-Recall curve')\n",
        "plot.plot(recall_2, precision_2, color='red', label='Precision-Recall curve')\n",
        "plot.ylabel('precision')\n",
        "plot.xlabel('recall')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "193bcf04-dea8-6d50-0773-a949f33d41ec"
      },
      "source": [
        "Recall stays higher for the regression model for a wider range of precision values\n",
        "Our regression model seems to be doing better !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9a71e439-179f-0fcb-aaec-3aab89f97a97"
      },
      "source": [
        "Let's try AdaBoost'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "98619a86-2f61-c656-8ea9-00e1bd808675"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "AdaBoostClf = AdaBoostClassifier(n_estimators=200)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d19f0fec-b9df-8a15-5304-175daa971c9f"
      },
      "outputs": [],
      "source": [
        "AdaBoostClf = AdaBoostClf.fit(X=X_train, y=y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b72a79fa-d11d-2c41-307c-2598c4fa11da"
      },
      "source": [
        "Evaluate the model with precision-recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "70c57bd1-563e-0c5f-47ca-ca9d50fea036"
      },
      "outputs": [],
      "source": [
        "y_test_pred = AdaBoostClf.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3084864b-2ee8-6c95-bcfa-d8c3df94bb76"
      },
      "outputs": [],
      "source": [
        "precision_3, recall_3, thresholds_3 = precision_recall_curve(y_test, y_test_pred[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c6ec6213-cd49-2699-3c77-c4eae27deabe"
      },
      "outputs": [],
      "source": [
        "plot.plot(recall, precision, color='navy', label='Precision-Recall curve')\n",
        "plot.plot(recall_2, precision_2, color='red', label='Precision-Recall curve')\n",
        "plot.plot(recall_3, precision_3, color='green', label='Precision-Recall curve')\n",
        "plot.ylabel('precision')\n",
        "plot.xlabel('recall')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "1f0a5358-f487-73b4-e48b-b3e387e012f6"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}