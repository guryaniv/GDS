{"cells":[{"metadata":{"_uuid":"f95ef78449951283946caff6748bca7032718b7e"},"cell_type":"markdown","source":"# From Public Kernels to Bronze\n\nIn this kernel, we will share the improvement we did to public kernels, that were more than enough to reach bronze. Generous Kagglers shared some really great work, that Maxime and I had to use and improve to adapt to the consequence they had on the silver / bronze tiers. This was also the first Kaggle competition we really invested in, so we're happy with the results.\n\nI believe we were top 70 a month ago, before $k$-opt moves were made public. Afterwards, we spent most of our time ranked between 80 and 110. We were limited by our hardware, as we were both on vacations at the end of the competition. I was running most of my work on the Kaggle kernels, which was kind of limiting (5-opt was too much...)\n\n#### Anyways, enjoy ! "},{"metadata":{"_uuid":"4080f80d30b6e4702d2aac7c19e73d5e690574a3","trusted":true},"cell_type":"code","source":"import numba\nimport numpy as np\nimport pandas as pd\nfrom math import sqrt\nfrom functools import lru_cache\nfrom sklearn.neighbors import KDTree\nfrom sympy import isprime, primerange\nfrom tqdm import tqdm_notebook as tqdm\nfrom ortools.constraint_solver import pywrapcp\nfrom itertools import combinations, permutations\nfrom scipy.spatial.distance import pdist, squareform\nfrom ortools.constraint_solver import routing_enums_pb2\nfrom sympy.utilities.iterables import multiset_permutations","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"### Loading stuff"},{"metadata":{"_uuid":"d5b03d9b02ebc2f734c1cbfa77bdcbbb7dda9730","trusted":true},"cell_type":"code","source":"cities = pd.read_csv('../input/reeindeer/cities.csv', index_col=['CityId'])\nXY = np.stack((cities.X.astype(np.float32), cities.Y.astype(np.float32)), axis=1)\nis_not_prime = np.array([0 if isprime(i) else 1 for i in cities.index], dtype=np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebf81a1c0413ebb5616d5245b3259a2fa29103e1"},"cell_type":"code","source":"kdt = KDTree(XY)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7260b66eeec537d44d341888224ad3fd8823407","trusted":true},"cell_type":"code","source":"path = np.array(pd.read_csv('../input/reeindeer/path1515413.csv').Path)\n# This is our current best, our method does not show improvments anymore, please use yours as input ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"da6e6488781f5da3c447d171f18dc3a981305412"},"cell_type":"markdown","source":"## First step : 2-opt\nThe first logical move is to use a basic 2-opt. It is quite easy to implement, but feel free to check \n> https://www.kaggle.com/kostyaatarik/close-ends-chunks-optimization-aka-2-opt \n\nOnce this is done, you can move on to higher $k$-opt moves."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Kostya Atarik's $k$-opt\n> https://www.kaggle.com/kostyaatarik/not-a-5-and-5-halves-opt\n\nDuring this competition, Kostya shared numba implementations of $k$-opt moves. His work had a huge impact on the silver/bronze tier of the leaderboard. "},{"metadata":{"_uuid":"6b64627e6cbaffffc873eb9302e0087136ec85a1"},"cell_type":"markdown","source":"### Tools"},{"metadata":{"_uuid":"c678bfe47a584d041019dafd02bf48d44622cc09","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"@numba.jit('f8(i8, i8, i8)', nopython=True, parallel=False)\ndef cities_distance(offset, id_from, id_to):\n    xy_from, xy_to = XY[id_from], XY[id_to]\n    dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n    distance = sqrt(dx * dx + dy * dy)\n    if offset % 10 == 9 and is_not_prime[id_from]:\n        return 1.1 * distance\n    return distance\n\n\n@numba.jit('f8(i4, i8[:])', nopython=True, parallel=False)\ndef score_chunk(offset, chunk):\n    pure_distance, penalty = 0.0, 0.0\n    penalty_modulo = 9 - offset % 10\n    for path_index in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[path_index], chunk[path_index+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n        if path_index % 10 == penalty_modulo and is_not_prime[id_from]:\n            penalty += distance\n    return pure_distance + 0.1 * penalty\n\n\n@numba.jit('f8(i8[:])', nopython=True, parallel=False)\ndef score_path(path):\n    return score_chunk(0, path)\n\n\n@numba.jit\ndef chunk_scores(chunk):\n    scores = np.zeros(10)\n    pure_distance = 0\n    for i in numba.prange(chunk.shape[0] - 1):\n        id_from, id_to = chunk[i], chunk[i+1]\n        xy_from, xy_to = XY[id_from], XY[id_to]\n        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n        distance = sqrt(dx * dx + dy * dy)\n        pure_distance += distance\n        if is_not_prime[id_from]:\n            scores[9-i%10] += distance\n    scores *= 0.1\n    scores += pure_distance\n    return scores\n\n\n@numba.jit('f8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:])', nopython=True, parallel=False)\ndef score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes):\n    score = 0.0\n    last_city_id = head\n    for i in numba.prange(len(indexes)):\n        index = indexes[i]\n        first, last, chunk_len = firsts[index], lasts[index], lens[index]\n        score += cities_distance(offset, last_city_id, first)\n        score += scores[index, (offset + 1) % 10]\n        last_city_id = last\n        offset += chunk_len\n    return score + cities_distance(offset, last_city_id, tail)\n\n\n@numba.jit('i8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:,:], f8)', nopython=True, parallel=False)\ndef best_score_permutation_index(offset, head, firsts, lasts, lens, tail, scores, indexes, best_score):\n    best_index = -1\n    for i in numba.prange(len(indexes)):\n        score = score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes[i])\n        if score < best_score:\n            best_index, best_score = i, score\n    return best_index\n\n\n@numba.jit('f8(i8[:])', nopython=True, parallel=False)\ndef sum_distance(ids):\n    res = 0\n    for i in numba.prange(len(ids)):\n        for j in numba.prange(i + 1, len(ids)):\n            res += cities_distance(0, ids[i], ids[j])\n    return res\n\n\n@lru_cache(maxsize=None)\ndef indexes_permutations(n):\n    return np.array(list(map(list, permutations(range(n)))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"547ee87fe12b5cdec9dd29b119d1e3ca37ea50ab"},"cell_type":"markdown","source":"### To the algorithm ..."},{"metadata":{"_uuid":"9eebbfb157cc176eb0279679f7d16c946092154a"},"cell_type":"markdown","source":"The following function generates the combinations :\n- n : length of the combinations (for a n-opt)\n- neighbours : parameter of the \"neighbour\" kdt query\n- radius : parameter of the \"radius\" kdt query \n\nI did not change anything here, just refactored the code."},{"metadata":{"trusted":true,"_uuid":"b08d4fc919e328a1e34cd9b789b24b3303a6c2d5"},"cell_type":"code","source":"def get_uplets(n, neighbours=10, radius=10):\n    uplets = set()  # To ensure uniqueness\n    for i in tqdm(cities.index):\n        # Query by neighbour\n        dists, neibs = kdt.query([XY[i]], neighbours)\n        for comb in combinations(neibs[0], n):\n            if all(comb): # Removing combinations containing 0\n                uplets.add(tuple(sorted(comb)))\n                \n        # Query by radius\n        neibs = kdt.query_radius([XY[i]], radius, count_only=False, return_distance=False)\n        for comb in combinations(neibs[0], n):\n            if all(comb):\n                uplets.add(tuple(sorted(comb)))\n\n    print(f'{len(uplets)} cities {n}-uplets are selected.')\n    \n    # Sorting by distance\n    uplets = np.array(list(uplets))\n    distances = np.array(list(map(sum_distance, uplets)))\n    order = distances.argsort()\n    uplets = uplets[order]\n    \n    return uplets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6a31d5ef11e38c338ce4a2450324b7acbc99eb7"},"cell_type":"code","source":"score_path(path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2190df899717564ee5aac454794d28eab54ea435"},"cell_type":"markdown","source":"## 3-opt\nTo improve Kostya's work, I added the possibility to reverse a chunk in the path. \nThe implementation is quite naïve here."},{"metadata":{"_uuid":"f775ce94f19f440c74f07c89c510ae745030b768","trusted":true},"cell_type":"code","source":"trees = get_uplets(3, 5, 5)  # Tweak those parameters","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d312202b33fc543e3b8f37d7ca36d0562b7b7c","trusted":true,"scrolled":true},"cell_type":"code","source":"path_index = np.argsort(path[:-1])\nprint(f'Total score is {score_path(path):.2f}.')\n\nfor ids in tqdm(trees):\n    i1, i2, i3 = np.sort(path_index[ids])\n    head, tail = path[i1-1], path[i3+1]\n    \n    # No inversion, First chunk inversed, Second chunk inversed, both chunks inversed\n    all_chunks = [[path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1]],\n                  [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1]]]\n    \n    for i, chunks in enumerate(all_chunks):\n        chunks = [chunk for chunk in chunks if len(chunk)] # Removing empty chunks\n        scores = np.array([chunk_scores(chunk) for chunk in chunks]) # Scoring chunks\n        lens = np.array([len(chunk) for chunk in chunks]) \n        firsts = np.array([chunk[0] for chunk in chunks])\n        lasts = np.array([chunk[-1] for chunk in chunks])\n\n        if i == 0: # Original chunk score\n            best_score = score_compound_chunk(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks))[0])\n        \n        # Best scoring permutation of the chunks\n        index = best_score_permutation_index(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks)), best_score)\n        \n        if index > 0: # If it is not the not permuted chunk\n            perm = [chunks[i] for i in indexes_permutations(len(chunks))[index]]\n            path[i1-1:i3+2] = np.concatenate([[head], np.concatenate(perm), [tail]]) # Applying combination\n            path_index = np.argsort(path[:-1])\n            print(f'New total score is {score_path(path):.3f}. Permutating path at indexes {i1}, {i2}, {i3}.')\n            break # We move to the next combination\n            \n    break # Uncomment to run the algorithm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35198c0083b16de592a5316241affd89808d3e8b","trusted":true},"cell_type":"code","source":"score_path(path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd160ea3c5e95e6455bd9dd9310c236b7f9a08bb"},"cell_type":"markdown","source":"## 4-opt - Same thing, more permutations.\nThe 4-opt worked really well for us, and as we did not have a lot of computing ressources, it got us better improvments than the 5-opt.\nBig plus is that there is almost no changes to do to our 3-opt implementation."},{"metadata":{"_uuid":"f775ce94f19f440c74f07c89c510ae745030b768","trusted":true},"cell_type":"code","source":"fours = get_uplets(4, 5, 0) # Tweak this as well","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15d312202b33fc543e3b8f37d7ca36d0562b7b7c","trusted":true},"cell_type":"code","source":"path_index = np.argsort(path[:-1])\nprint(f'Total score is {score_path(path):.2f}.')\n\nfor ids in tqdm(fours):\n    i1, i2, i3, i4 = np.sort(path_index[ids])  # Added i4\n    head, tail = path[i1-1], path[i4+1]  # Tail changed\n    \n    # New permutations \n    all_chunks = [[path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1], path[i3+1:i4], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1], path[i3+1:i4], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1], path[i3+1:i4], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1], path[i3+1:i4][::-1], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1], path[i3+1:i4], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3], path[i3:i3+1], path[i3+1:i4][::-1], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1], path[i3+1:i4][::-1], path[i4:i4+1]], \n                  [path[i1:i1+1], path[i1+1:i2][::-1], path[i2:i2+1], path[i2+1:i3][::-1], path[i3:i3+1], path[i3+1:i4][::-1], path[i4:i4+1]]\n                 ]\n\n    for i, chunks in enumerate(all_chunks):\n        chunks = [chunk for chunk in chunks if len(chunk)]\n        scores = np.array([chunk_scores(chunk) for chunk in chunks])\n        lens = np.array([len(chunk) for chunk in chunks])\n        firsts = np.array([chunk[0] for chunk in chunks])\n        lasts = np.array([chunk[-1] for chunk in chunks])\n\n        if i == 0:\n            best_score = score_compound_chunk(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks))[0])\n        \n        index = best_score_permutation_index(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks)), best_score)\n        \n        if index > 0:\n            perm = [chunks[i] for i in indexes_permutations(len(chunks))[index]]\n            path[i1-1:i4+2] = np.concatenate([[head], np.concatenate(perm), [tail]])  #i3 -> i4\n            path_index = np.argsort(path[:-1])\n            print(f'New total score is {score_path(path):.3f}. Permutating path at indexes {i1}, {i2}, {i3}, {i4}.') #Added i4\n            break\n    break # Uncomment to run the algorithm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35198c0083b16de592a5316241affd89808d3e8b","trusted":true},"cell_type":"code","source":"score_path(path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0e3cf447e064ae2792183da37bbfad7a42cfc11"},"cell_type":"markdown","source":"## 5-opt, 6-opt and more.\nIf you have enough time, doing the same thing on a 5/6 opt is easy."},{"metadata":{"_uuid":"0c321f901396e4593716ec27ea62db095c9a8553"},"cell_type":"markdown","source":"# Babachan's Local Optimization\nNext thing is to optimize subpaths of our tour, we used babachan's work :\n> https://www.kaggle.com/hblearn/local-optimization-using-google-or-tool\n\nThe only thing we did was removing randomness and trying more subpaths."},{"metadata":{"_uuid":"fadf42f38d8bc2188b4082ab8a91e5d09fe05690"},"cell_type":"markdown","source":"### Tools"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"7e14c384110295eb8da949de13f4ba945575c552"},"cell_type":"code","source":"num_iters = 300\npath_df = pd.DataFrame({\"Path\": path})\ncities2 = cities.reset_index().rename(columns={\"CityId\": \"Path\"})\npath_df = path_df.merge(cities2,how='left',on='Path')\npnums = list(primerange(0, path_df.shape[0]))\n\nstatus_dict = {0: 'ROUTING_NOT_SOLVED', \n               1: 'ROUTING_SUCCESS', \n               2: 'ROUTING_FAIL',\n               3: 'ROUTING_FAIL_TIMEOUT',\n               4: 'ROUTING_INVALID'}\n\ndef create_mat(df):\n    mat = pdist(df)\n    return squareform(mat)\n\ndef create_distance_callback(dist_matrix):\n    def distance_callback(from_node, to_node):\n        return int(dist_matrix[from_node][to_node])\n    return distance_callback\n\ndef optimize(df, startnode, stopnode, fixed):     \n    num_nodes = df.shape[0]\n    mat = create_mat(df)\n    dist_callback = create_distance_callback(mat)\n    search_parameters = pywrapcp.RoutingModel.DefaultSearchParameters()\n    search_parameters.solution_limit = num_iters \n    search_parameters.first_solution_strategy = (\n                                    routing_enums_pb2.FirstSolutionStrategy.LOCAL_CHEAPEST_INSERTION)\n    search_parameters.local_search_metaheuristic = (\n                            routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n\n    if fixed:\n        routemodel = pywrapcp.RoutingModel(num_nodes, 1, [startnode], [stopnode])\n    else:\n        routemodel = pywrapcp.RoutingModel(num_nodes, 1, startnode)\n    routemodel.SetArcCostEvaluatorOfAllVehicles(dist_callback)\n    \n    assignment = routemodel.SolveWithParameters(search_parameters)\n    return routemodel, assignment\n\ndef get_route(df, startnode, stopnode, fixed): \n    routemodel, assignment = optimize(df, int(startnode), int(stopnode), fixed)\n    route_number = 0\n    node = routemodel.Start(route_number)\n    route = []\n    while not routemodel.IsEnd(node):\n        route.append(node) \n        node = assignment.Value(routemodel.NextVar(node))\n    return route","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef19298562d14f0755b7dec00a987c3465f1b26f"},"cell_type":"markdown","source":"### Optimization"},{"metadata":{"trusted":true,"_uuid":"9b786a83326c3448ac0ed6ad6b86296d9f097bf1"},"cell_type":"code","source":"def run_opt(df, m):\n    print(f'm = {m}')\n    \n    # Given a length of subpath m, the subpath we optimize start at 1, m/2+1, m+1, ... , len(path) - m - 1\n    # Therefore, n is :\n    n = int(path_df.shape[0] / m) * 2\n    \n    for i in tqdm(range(n)):\n        startpoint = int(1 +  i * (df.shape[0] - m - 2) / n)\n        endpoint = min((startpoint + m), df.shape[0])\n\n        district = df.iloc[startpoint:endpoint, :3].copy()\n        district = district.reset_index()\n        locations = district[['X', 'Y']].values\n\n        segnodes = get_route(locations, 0, (m-1), fixed=True)\n        ord_district = district.iloc[segnodes]\n        segment = ord_district.index.tolist()\n\n        temp = district.loc[segment, ['Path','X', 'Y']].reset_index()\n        district_2 = district.copy()\n        district_2.iloc[:(m-1),1:] = temp.copy()\n        district = district.set_index('index')\n        district_2 = district_2.set_index('index')\n\n        district['step'] = np.sqrt((district.X - district.X.shift())**2 + (district.Y - district.Y.shift())**2)\n        district['step_adj'] = np.where((district.index) % 10 != 0, district.step, district.step + \n                                        district.step*0.1*(~district.Path.shift().isin(pnums)))\n        district_2['step'] = np.sqrt((district_2.X - district_2.X.shift())**2 + (district_2.Y - district_2.Y.shift())**2)\n        district_2['step_adj'] = np.where((district_2.index) % 10 != 0, district_2.step, district_2.step + \n                                          district_2.step*0.1*(~district_2.Path.shift().isin(pnums)))\n\n        check_dist = district.step_adj.sum() > district_2.step_adj.sum()\n        if check_dist:\n            df.iloc[startpoint:endpoint,0:3] = district_2\n            print(f\"Improved of {district.step_adj.sum() - district_2.step_adj.sum()}\")\n        \n        break #Uncomment to run the algorithm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"98aec75bf9f2e872e256041dbb18f906cadb257e"},"cell_type":"code","source":"m = 40  # 30 and 50 are also good choices\nrun_opt(path_df, m)\npath = path_df['Path'].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"35198c0083b16de592a5316241affd89808d3e8b","trusted":true},"cell_type":"code","source":"score_path(path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7723e6e1fcc34f917596faaf29f6c3fd307b477b"},"cell_type":"markdown","source":"Once you have those two optimization methods, the idea is to combine them until you're stuck, play with parameters,  etc..."},{"metadata":{"_uuid":"2e0b22d2b996c2cd10d9b139fa639aa6789f4672"},"cell_type":"markdown","source":"## Next step : How to reach Silver\n- Higher ranked people noticed that algorithms worked better by incrementing the prime penalty (Penalizing by 1%, 2%, ..., 10% instead of 10% directly). Unfortunately, we missed this idea. \nIt is quite simple to implement, but a really clever trick. \n- You could also increment the gain to avoid local minima (accept only moves that have a high enough improvement)\n\nSee : \n> https://www.kaggle.com/c/traveling-santa-2018-prime-paths/discussion/77250"},{"metadata":{"_uuid":"942db7cf0fcb782d98f2e0ed99d5a970390a3b62"},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true,"_uuid":"249ea63b0ca561bafa34164180e693e7d376948f"},"cell_type":"code","source":"def make_submission(name, path):\n    pd.DataFrame({'Path': path}).to_csv(f'{name}.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa91fcef7ed8ce2a597a489310c1d9d04727938b","trusted":true},"cell_type":"code","source":"make_submission(\"path\" + str(int(score_path(path))), path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4c6bf7c0601619dac12e03630d27c5ef37f834b"},"cell_type":"markdown","source":"## Final word : \n\n- Would our score have been better without the sharings of other amazing Kagglers ?  Probably not.\n\n- Would we have been higher ranked ? Probably, yes.\n\nBut we do believe that the most important thing is that we learned a lot more with these ideas, than with our sloppy implementation of local optimization and $k$-opt moves.\n\nSo thanks again to everybody who shared anything during the competition.\n\n#### Thanks for reading ! "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}