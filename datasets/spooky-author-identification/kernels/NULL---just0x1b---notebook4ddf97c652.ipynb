{"nbformat": 4, "nbformat_minor": 1, "cells": [{"outputs": [], "cell_type": "code", "execution_count": null, "source": ["import numpy as np \n", "import pandas as pd \n", "\n", "import matplotlib.pyplot as plt"], "metadata": {"_cell_guid": "ce70a204-4af0-4636-9cf8-c043c83c7508", "collapsed": true, "_uuid": "28e0362b8b140ee55b7060fd4d2a5f80a5dd13d3"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["test_corpus = np.load('../input/preprocessing/test_corp.npy')\n", "train_corpus = np.load('../input/preprocessing/train_corp.npy')\n", "\n", "glove_table = pd.read_csv('../input/preprocessing/filled_glove_table.csv', index_col=0)\n", "glove_table.describe()\n", "\n", "train_data = pd.read_csv('../input/spooky-author-identification/train.csv')"], "metadata": {"_cell_guid": "3a82955e-fc19-4103-9cb1-114f1321bf7d", "collapsed": true, "_uuid": "e20fa85c56d3b8ce6ae61e13bab21e69ba798b8f", "scrolled": true}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["glove_table.loc[['man','woman','man']].as_matrix().shape\n", "\n", "train_data.iloc[477]"], "metadata": {"_cell_guid": "0bf40746-3fc0-45de-bc38-5cbf3370aa58", "_uuid": "93c332817c8c891b24cc8e1bc95e61b11a52a846"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["train_sequence = []\n", "train_sequence_lengths   = []\n", "index = 0\n", "for sentence_chunk in train_corpus:\n", "    if (len(sentence_chunk) > 0):\n", "        words = [word for (word, tag) in sentence_chunk]\n", "        features = glove_table.loc[words].as_matrix()\n", "        train_sequence.append(features)\n", "        train_sequence_lengths.append(len(words))\n", "    else:\n", "        # If sentence is empty put (1,ndims) zeros as data\n", "        print(train_data['text'][index])\n", "        train_sequence.append(np.zeros((1,300)))\n", "        train_sequence_lengths.append(1)\n", "    index += 1\n", "    \n", "train_sequence_lengths = np.array(train_sequence_lengths)"], "metadata": {"_cell_guid": "20c5b998-590c-4d8a-aef0-2fe9ee569661", "_uuid": "2403ce21ec7d5a24d3727ab627c2222b36b3977c"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["from hmmlearn import hmm\n", "def hmm_train_model(train_sequence, train_sequence_lengths):\n", "    num_hidden_states = 10\n", "    num_dims = train_sequence[0].shape[1]\n", "    \n", "    model = hmm.GaussianHMM(n_components=num_hidden_states, covariance_type=\"full\",\n", "                            n_iter=20, verbose=True, init_params = \"\")\n", "\n", "    start_prob = np.random.rand(num_hidden_states)\n", "    start_prob = start_prob / np.sum(start_prob)\n", "    model.startprob_ = start_prob\n", "\n", "    transmat = np.random.rand(num_hidden_states,num_hidden_states)\n", "    transmat = transmat / np.sum(transmat, axis=1)[:, np.newaxis]\n", "    model.transmat_ = transmat\n", "\n", "    model.means_ = np.random.rand(num_hidden_states, num_dims)\n", "    model.covars_ = np.tile(np.identity(num_dims), (num_hidden_states, 1, 1))\n", "    print('Training started.')\n", "    return model.fit(np.concatenate(train_sequence), train_sequence_lengths) "], "metadata": {"_cell_guid": "ad8a4c24-43fb-462a-883a-7646f145c1d3", "collapsed": true, "_uuid": "ff48ee2a2af44d3a52053da5a16ca562fbca4bdd"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["import warnings\n", "\n", "# List of authors\n", "authors = np.unique(train_data['author'])\n", "author_models = {} # Stores 1 Model for each author\n", "\n", "for author in authors:\n", "    print('Training for {}:'.format(author))\n", "    \n", "    # Filter sentences of the same author :D\n", "    is_author_sentence = np.array(train_data['author'] == author)\n", "    author_sentences = [train_sequence[i] if is_author_sentence[i] else None for i in range(len(train_sequence))]\n", "    author_sentences = list(filter(lambda x: x is not None,author_sentences))\n", "    \n", "    author_sentence_lengths = train_sequence_lengths[is_author_sentence]\n", "    \n", "    # Train for author\n", "    with warnings.catch_warnings():\n", "        warnings.simplefilter(\"ignore\")\n", "        author_models[author] = hmm_train_model(author_sentences, author_sentence_lengths)"], "metadata": {"_cell_guid": "5baa0af7-a9c9-4263-937a-0efc2dc7d4cb", "_uuid": "6fad0f1c039296ab8f6ebc076a5d8973469fe51c"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": ["def predict(author_models, sentence):\n", "    scores = {}\n", "    predicted_author = list(author_models.keys())[0]\n", "    with warnings.catch_warnings():\n", "        warnings.simplefilter(\"ignore\")\n", "        for author in author_models.keys():\n", "            scores[author] = author_models[author].score(sentence)\n", "            if (scores[author] > scores[predicted_author]):\n", "                predicted_author = author\n", "    return predicted_author, scores\n", "\n", "correct_prediction = 0\n", "total_prediction = 0\n", "for index in range(1000):\n", "    prediction, scores = predict(author_models, train_sequence[index]) \n", "    true_data = train_data.iloc[index]\n", "    if (true_data['author'] == prediction):\n", "        correct_prediction += 1\n", "    total_prediction += 1\n", "    #print(\"{}\\nPrediction: {}\\tTrue: {}\\n\".format(true_data['text'], prediction, true_data['author']))\n", "    \n", "acc = float(correct_prediction) / total_prediction\n", "print(acc)"], "metadata": {"_cell_guid": "40b9aaeb-5da4-4d23-800e-929e18d40ca6", "_uuid": "468b10ec259510f0a180b2e91ad8dc140dd3744d"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": [], "metadata": {"_cell_guid": "fa507baa-00cc-4692-bd89-cf9396875033", "collapsed": true, "_uuid": "2be8a6393410d151126a573e38250135469116a4"}}], "metadata": {"kernelspec": {"language": "python", "name": "python3", "display_name": "Python 3"}, "language_info": {"mimetype": "text/x-python", "codemirror_mode": {"version": 3, "name": "ipython"}, "file_extension": ".py", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.3"}}}