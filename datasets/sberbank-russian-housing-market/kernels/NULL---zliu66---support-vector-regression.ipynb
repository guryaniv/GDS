{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8304bf25-cd25-600c-a14f-a5de10b5be4c"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e6290ab-f33f-5065-e26b-a5ffb8d523dd"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import linear_model\n",
        "from sklearn import neural_network\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.utils import shuffle\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "# Input data files are available in the 'input/' directory.\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3711d1f6-0619-cb03-e389-d653e5295bd0"
      },
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fc2042cd-ee5c-359a-1848-97f4b5a0a12b"
      },
      "outputs": [],
      "source": [
        "realty_drop_cols = ['male_f', 'female_f', 'young_female', 'work_all', 'work_female', \n",
        "                   'railroad_station_walk_min', 'railroad_station_avto_km', 'railroad_station_avto_min',\n",
        "                  'sadovoe_km', 'bulvar_ring_km', 'kremlin_km']\n",
        "macro_cols = [\"balance_trade\", \"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\", 'cpi', 'brent', \n",
        "\"micex_rgbi_tr\", \"micex_cbi_tr\", \"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n",
        "\"income_per_cap\", \"rent_price_4+room_bus\", \"museum_visitis_per_100_cap\", \"apartment_build\"]\n",
        "\n",
        "df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n",
        "\n",
        "df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'], usecols=['timestamp'] + macro_cols)\n",
        "df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "60ee019d-fee2-5f69-9a57-dd2087ac336e"
      },
      "outputs": [],
      "source": [
        "# ylog will be log(1+y), as suggested by https://github.com/dmlc/xgboost/issues/446#issuecomment-135555130\n",
        "ylog_train_all = np.log1p(df_train['price_doc'].values)\n",
        "id_test = df_test['id']\n",
        "\n",
        "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
        "df_test.drop(['id'], axis=1, inplace=True)\n",
        "\n",
        "# Build df_all = (df_train+df_test).join(df_macro)\n",
        "num_train = len(df_train)\n",
        "df_all = pd.concat([df_train, df_test])\n",
        "df_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')\n",
        "df_all.drop(realty_drop_cols, axis=1, inplace=True)\n",
        "# print(df_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "69685d58-859f-502e-66fb-4ab8a92150e1"
      },
      "outputs": [],
      "source": [
        "# price_ulimit = np.log1p(1E8)\n",
        "# df_all =  df_all.loc[df_all['price_doc'] < price_ulimit,:] \n",
        "\n",
        "full_sq_ulimit = 250\n",
        "life_sq_ulimit = 250\n",
        "full_sq_llimit = 10\n",
        "life_sq_llimit = 5\n",
        "df_all.loc[df_all['full_sq']>full_sq_ulimit, 'full_sq'] = np.nan\n",
        "df_all.loc[df_all['full_sq']<full_sq_llimit, 'full_sq'] = np.nan\n",
        "df_all.loc[df_all['life_sq']>life_sq_ulimit, 'life_sq'] = np.nan\n",
        "df_all.loc[df_all['life_sq']<life_sq_llimit, 'life_sq'] = np.nan\n",
        "\n",
        "df_all['life_full_ratio'] = df_all['life_sq'] / df_all['full_sq']\n",
        "\n",
        "df_all.loc[df_all['life_full_ratio'] > 0.85, 'life_sq'] = np.nan\n",
        "\n",
        "df_all.loc[df_all['floor'] == 0, 'floor'] = np.nan\n",
        "df_all.loc[df_all['max_floor'] == 0, 'max_floor'] = np.nan\n",
        "df_all.loc[df_all['max_floor'] < df_all['floor'], ['floor', 'max_floor']] = np.nan\n",
        "df_all['floor_ratio'] = df_all['floor'] / df_all['max_floor']\n",
        "\n",
        "df_all.loc[df_all['build_year'] > 2017, 'build_year'] = np.nan\n",
        "df_all.loc[df_all['build_year'] < 1900, 'build_year'] = np.nan\n",
        "\n",
        "\n",
        "df_all.loc[df_all['num_room'] == 0, 'num_room'] = np.nan\n",
        "df_all.loc[df_all['num_room'] >= 10, 'num_room'] = np.nan\n",
        "\n",
        "df_all.loc[df_all['kitch_sq'] <= 3.0 , 'kitch_sq'] = np.nan\n",
        "df_all.loc[df_all['full_sq'] - df_all['kitch_sq'] <= 5.0 , 'kitch_sq'] = np.nan\n",
        "\n",
        "df_all.loc[df_all['state'] == 33 , 'state'] = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9030832f-5cb8-5ca1-0997-2a23a0e7847d"
      },
      "outputs": [],
      "source": [
        "# Add month-year\n",
        "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
        "month_year_cnt_map = month_year.value_counts().to_dict()\n",
        "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
        "\n",
        "# Add week-year count\n",
        "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
        "week_year_cnt_map = week_year.value_counts().to_dict()\n",
        "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
        "\n",
        "# Add month and day-of-week\n",
        "df_all['month'] = df_all.timestamp.dt.month\n",
        "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
        "\n",
        "# Other feature engineering\n",
        "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
        "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
        "\n",
        "# Remove timestamp column (may overfit the model in train)\n",
        "df_all.drop(['timestamp'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ab629c24-2da4-b89a-973c-06bfea34acad"
      },
      "outputs": [],
      "source": [
        "for f in df_all.columns:\n",
        "    if df_all[f].dtype=='object':\n",
        "        lbl = preprocessing.LabelEncoder()\n",
        "        lbl.fit(list(df_all[f].values.astype('str')) )\n",
        "        df_all[f] = lbl.transform(list(df_all[f].values.astype('str')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e7d080b9-4967-6074-6a74-67176321ee72"
      },
      "outputs": [],
      "source": [
        "# train_df.fillna(-99, inplace=True)\n",
        "# test_df.fillna(-99, inplace=True)\n",
        "\n",
        "\n",
        "df_all= df_all.fillna(df_all.median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c2b1cf10-7fe8-a898-1e17-0f79a6ae0c6b"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy values\n",
        "X_all = df_all.values\n",
        "X_all = preprocessing.normalize(X_all, norm='l1', axis=0, copy=True, return_norm=False)\n",
        "\n",
        "\n",
        "# print(X_all.shape)\n",
        "\n",
        "# Create a validation set, with last 20% of data\n",
        "num_val = int(num_train * 0.2)\n",
        "\n",
        "X_train_all = X_all[:num_train]\n",
        "X_train = X_all[:num_train-num_val]\n",
        "X_val = X_all[num_train-num_val:num_train]\n",
        "ylog_train = ylog_train_all[:-num_val]\n",
        "ylog_val = ylog_train_all[-num_val:]\n",
        "\n",
        "X_test = X_all[num_train:]\n",
        "\n",
        "df_columns = df_all.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8511102e-693f-ab35-b194-8edc51a4f71a"
      },
      "outputs": [],
      "source": [
        "clf = SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
        "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
        "clf.fit(X_train, ylog_train)\n",
        "\n",
        "training_loss = np.sqrt(mean_squared_error(ylog_train, clf.predict(X_train)))\n",
        "validation_loss = np.sqrt(mean_squared_error(ylog_val, clf.predict(X_val)))\n",
        "\n",
        "print('Training loss is {}'.format(training_loss))\n",
        "print('Validation loss is {}'.format(validation_loss))\n",
        "\n",
        "test_y_SVR = np.exp(clf.predict(X_test)) - 1\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': test_y_SVR})\n",
        "df_sub.to_csv('Predict_SVR.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "02dbc44c-49e5-326d-1f1d-18ba9ec599ec"
      },
      "outputs": [],
      "source": [
        "regNN = neural_network.MLPRegressor(hidden_layer_sizes = (100, 100, 100, 100, 100))\n",
        "regNN.fit (X_train, ylog_train)\n",
        "training_loss = np.sqrt(mean_squared_error(ylog_train, regNN.predict(X_train)))\n",
        "validation_loss = np.sqrt(mean_squared_error(ylog_val, regNN.predict(X_val)))\n",
        "\n",
        "print('Training loss is {}'.format(training_loss))\n",
        "print('Validation loss is {}'.format(validation_loss))\n",
        "\n",
        "test_y_regNN = np.exp(regNN.predict(X_test)) - 1\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': test_y_regNN})\n",
        "df_sub.to_csv('Predict_train_SVR.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9fb8d6e7-3fee-65a4-6a78-a7ba0dc8ce10"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4c34ee63-254c-95a6-24b1-4dccab547825"
      },
      "outputs": [],
      "source": [
        "rfr = RandomForestRegressor(n_estimators = 200, max_depth = 40, min_samples_split = 20)\n",
        "rfr.fit (X_train, ylog_train)\n",
        "training_loss = np.sqrt(mean_squared_error(ylog_train, rfr.predict(X_train)))\n",
        "validation_loss = np.sqrt(mean_squared_error(ylog_val, rfr.predict(X_val)))\n",
        "\n",
        "print('Training loss is {}'.format(training_loss))\n",
        "print('Validation loss is {}'.format(validation_loss))\n",
        "\n",
        "\n",
        "test_y_rfr = np.exp(rfr.predict(X_test)) - 1\n",
        "df_sub = pd.DataFrame({'id': id_test, 'price_doc': test_y_rfr})\n",
        "df_sub.to_csv('Predict_train_rfr.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0f78446c-d71b-a910-c69b-d07159bcad0d"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f0b8bd6-7023-9d92-1271-1bda3413e68c"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6f5bb18d-bb7b-9f00-f9b7-7dc0849c554d"
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5115016-f314-aaad-38f2-77431fa06753"
      },
      "outputs": [],
      "source": ""
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}