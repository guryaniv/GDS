{"nbformat_minor": 1, "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.3", "file_extension": ".py", "nbconvert_exporter": "python"}}, "cells": [{"cell_type": "code", "source": ["import numpy as np \n", "import pandas as pd\n", "from glob import glob\n", "from tqdm import tqdm\n", "import matplotlib.pyplot as plt\n", "from keras.models import *\n", "from keras.layers import *\n", "from keras.optimizers import *\n", "from keras.applications.vgg16 import VGG16\n", "from keras.applications.inception_v3 import InceptionV3\n", "from keras.callbacks import EarlyStopping\n", "from keras.utils import plot_model\n", "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n", "from sklearn.model_selection import train_test_split\n", "from tqdm import tqdm\n", "%matplotlib inline"], "execution_count": null, "metadata": {"_cell_guid": "6764c4d6-21f8-46aa-911e-09034f29acc0", "_uuid": "83eb2162c9c0bd3dbbb5333182d9e61acb5a5bdf"}, "outputs": []}, {"cell_type": "code", "source": ["!ls ../input/train/"], "execution_count": null, "metadata": {"_cell_guid": "28000d9f-427e-4f08-baf1-d547a37cee2c", "_uuid": "a01d5d5746a38cc75a0ad28a6c5fa49dfbfd10d4"}, "outputs": []}, {"cell_type": "code", "source": ["datagen = ImageDataGenerator(rescale=1./255)\n", "train_generator = datagen.flow_from_directory(\n", "        '../input/train/',  \n", "        batch_size=1,\n", "        class_mode='categorical')"], "execution_count": null, "metadata": {"_cell_guid": "21fbf77d-ecc1-43a6-b28a-e681cfa4c092", "_uuid": "e0011027cda5aaeec859941f70d184248dad2b9d"}, "outputs": []}, {"cell_type": "code", "source": ["# let's have a look at the images\n", "x, y = train_generator.next()\n", "plt.imshow((x[0]*255).astype('uint8'));\n", "print(list(train_generator.class_indices.keys())[np.argmax(y)])"], "execution_count": null, "metadata": {"_cell_guid": "435df950-3b7a-4b90-806f-e710d3530069", "_uuid": "5a549ba3eecd321b97bfc4bcc6b7ff29efeb2c4d"}, "outputs": []}, {"cell_type": "code", "source": ["X_data, Y_data = [], []\n", "for _ in tqdm(range(2750)):\n", "    x, y = train_generator.next()\n", "    X_data.append(x[0])\n", "    Y_data.append(y[0])\n", "X_data = np.asarray(X_data)\n", "Y_data = np.asarray(Y_data)"], "execution_count": null, "metadata": {"_cell_guid": "1e68570c-57ea-4401-b901-af72602c2605", "_uuid": "fef53824681f47e26100d365b86b8c9fb678a39f"}, "outputs": []}, {"cell_type": "code", "source": ["def get_model():\n", "    input_img = Input((256, 256, 3))\n", "    X = BatchNormalization()(input_img)\n", "    X = Convolution2D(16, (3, 3), activation='relu')(X)\n", "    X = BatchNormalization()(X)\n", "    X = Convolution2D(16, (3, 3), activation='relu')(X)\n", "    X = MaxPooling2D()(X)\n", "    X = Convolution2D(32, (3, 3), activation='relu')(X)\n", "    X = BatchNormalization()(X)\n", "    X = Convolution2D(32, (3, 3), activation='relu')(X)\n", "    X = GlobalMaxPooling2D()(X)\n", "#     X = Flatten()(X)\n", "    X = BatchNormalization()(X)\n", "    X = Dense(512, activation='relu')(X)\n", "    X = Dropout(0.2)(X)\n", "    X = Dense(10, activation='softmax')(X)\n", "    model = Model(inputs=input_img, outputs=X)\n", "\n", "    model.compile(optimizer='adam', loss='categorical_crossentropy', \n", "                  metrics=['acc'])\n", "    model.summary()\n", "    return model"], "execution_count": null, "metadata": {"_cell_guid": "319c1dc7-1dc4-44d2-9308-145dc0ae1cfc", "_uuid": "cf205c9ae3b189e2dda527594ce2ab8e95e64bbe", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["model = get_model()"], "execution_count": null, "metadata": {"_cell_guid": "994b49b5-45b2-41e9-9ebe-47a25d0a0345", "_uuid": "fd044b84539055e7b13ca7afaba397014014a0f6"}, "outputs": []}, {"cell_type": "code", "source": ["model_history = model.fit(X_data, Y_data, batch_size=10, epochs=3, validation_split=0.2,\n", "                          callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"], "execution_count": null, "metadata": {"_cell_guid": "0684b2ee-7d39-47b0-969b-2c0ce58bee65", "_uuid": "6269c944ea56e36aa318e407a05812b905e7fb95"}, "outputs": []}, {"cell_type": "code", "source": ["# load test images\n", "X_test = []\n", "sub = pd.read_csv('../input/sample_submission.csv')\n", "\n", "for fname in tqdm(sub['fname']):\n", "    filepath = '../input/test/' + fname\n", "    X_test.append(img_to_array(load_img(filepath, target_size=(256, 256))))\n", "X_test = np.asarray(X_test)"], "execution_count": null, "metadata": {"_cell_guid": "96a5d10b-96ab-4430-891c-b6a87c32d9d0", "_uuid": "e4296cb7b854d07c1e95cdf4679f8c7b15365517"}, "outputs": []}, {"cell_type": "code", "source": ["preds = model.predict(X_test, verbose=1)\n", "preds = np.argmax(preds, axis=1)\n", "preds = [list(train_generator.class_indices.keys())[p] for p in tqdm(preds)]"], "execution_count": null, "metadata": {"_cell_guid": "8d920bf5-35c7-452b-82da-bb124d34d568", "_uuid": "c9e760d383a6b978db334d25d4bd2144927d7dec"}, "outputs": []}, {"cell_type": "code", "source": ["sub['camera'] = preds\n", "sub.to_csv('sub.csv', index=False)"], "execution_count": null, "metadata": {"_cell_guid": "18eeacdd-9b05-426e-b6f5-e9da4e0a70ed", "_uuid": "42bd027dad7b2e8a3d2757f7e68159d8bed1cb8c", "collapsed": true}, "outputs": []}, {"cell_type": "code", "source": ["sub.head()"], "execution_count": null, "metadata": {"_cell_guid": "d3309a22-0ebf-4896-94f3-89909b60d53c", "_uuid": "2f247281e722786f627ed4878b1b8be1d3a1155e"}, "outputs": []}, {"cell_type": "code", "source": [], "execution_count": null, "metadata": {"collapsed": true}, "outputs": []}], "nbformat": 4}