{"cells":[{"metadata":{"_cell_guid":"25b1e1db-8bc5-7029-f719-91da523bd121","_uuid":"c4910031e06b66a064dcd9bbc09fcd731420f49e"},"cell_type":"markdown","source":"## Introduction ##\n\nThis is my first work of machine learning. the notebook is written in python and has inspired from [\"Exploring Survival on Titanic\" by Megan Risdal, a Kernel in R on Kaggle][1].\n\n\n  [1]: https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic"},{"metadata":{"_cell_guid":"2ce68358-02ec-556d-ba88-e773a50bc18b","_uuid":"6f52e8642ad8627f95ae9afa858e2259bc6bf4ef","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport re as re\nimport seaborn as sns\n\n\ntrain = pd.read_csv('../input/train.csv', header = 0, dtype={'Age': np.float64})\ntest  = pd.read_csv('../input/test.csv' , header = 0, dtype={'Age': np.float64})\n\n'''\nAppend train and test data so that all the data manipulations are common to both\n'''\nfull_data = train.append(test)\nfull_data.reset_index(inplace=True)\n\nprint (train.info())\npd.set_option('display.expand_frame_repr', False)\nprint (train.describe())\npd.set_option('display.expand_frame_repr', True)\nprint (train.head())\nprint (train.describe(include=['O']))\nprint (train.head())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9595646-65c9-6fc4-395f-0befc4d122ce","_uuid":"0116d0c92d0c5b2d9670cc36674c00e831128639"},"cell_type":"markdown","source":"# Exploratory Analysis #"},{"metadata":{"_cell_guid":"9b4c278b-aaca-e92c-ba77-b9b48379d1f1","_uuid":"0d0cf51c4a59762892f27ba3f98ea6963bf7d488"},"cell_type":"markdown","source":"## 1. Pclass ##\nthere is no missing value on this feature and already a numerical value. so let's check it's impact on our train set."},{"metadata":{"_cell_guid":"4680d950-cf7d-a6ae-e813-535e2247d88e","_uuid":"29b6c86fc4d2b22cb69d704c5af8d879f3e9fbfc","trusted":true},"cell_type":"code","source":"print (train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5e70f81c-d4e2-1823-f0ba-a7c9b46984ff","_uuid":"baaeb5b6b7d239d1675109ab577cf78c7ccd6763"},"cell_type":"markdown","source":"## 2. Sex ##"},{"metadata":{"_cell_guid":"6729681d-7915-1631-78d2-ddf3c35a424c","_uuid":"ba206e505877da2eb6fa64898a0a32f6d37931ac","trusted":true,"scrolled":true},"cell_type":"code","source":"print (train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7c58b7ee-d6a1-0cc9-2346-81c47846a54a","_uuid":"d18355175356b85180e050e01ac3e5389ff45cbf"},"cell_type":"markdown","source":"## 3. SibSp and Parch ##\nWith the number of siblings/spouse and the number of children/parents we can create new feature called Family Size."},{"metadata":{"_cell_guid":"1a537f10-7cec-d0b7-8a34-fa9975655190","_uuid":"0656b827dfad2bbe2d3131aff1ca71b28a69ee97","trusted":true},"cell_type":"code","source":"print (train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean())\nprint (train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean())\nfull_data['FamilySize'] = full_data['SibSp'] + full_data['Parch'] + 1\nprint (full_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e4861d3e-10db-1a23-8728-44e4d5251844","_uuid":"3855475d8b88c6607268fd5ce7363d5389dcf963"},"cell_type":"markdown","source":"it seems has a good effect on our prediction but let's go further and categorize people to check whether they are alone in this ship or not."},{"metadata":{"_cell_guid":"8c35e945-c928-e3bc-bd9c-d6ddb287e4c9","_uuid":"768c65d1e8899fc9fb628f083d707b1c24b3ad42","trusted":true},"cell_type":"code","source":"full_data['IsAlone'] = 0\nfull_data.loc[full_data['FamilySize'] == 1, 'IsAlone'] = 1\nprint (full_data[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2780ca4e-7923-b845-0b6b-5f68a45f6b93","_uuid":"04dd3c7ec1f30743db4509e6b450d53182ebb23c"},"cell_type":"markdown","source":"good! the impact is considerable."},{"metadata":{"_cell_guid":"8aa419c0-6614-7efc-7797-97f4a5158b19","_uuid":"4c04b9296db0fa8f269de7b44dbce98997bda292"},"cell_type":"markdown","source":"## 4. Embarked ##\nthe embarked feature has some missing value. and we try to fill those with the most occurred value ( 'S' )."},{"metadata":{"_cell_guid":"0e70e9af-d7cc-8c40-b7d4-2643889c376d","_uuid":"f3429e67e370e81d625bda39daf2b31a9532e943","trusted":true},"cell_type":"code","source":"print (full_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).count())\nfull_data['Embarked'] = full_data['Embarked'].fillna('S')\nprint (full_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e08c9ee8-d6d1-99b7-38bd-f0042c18a5d9","_uuid":"f92caf530f679c85fe8d22c1edf612405be17818"},"cell_type":"markdown","source":"## 5. Fare ##\nFare also has some missing value and we will replace it with the median. then we categorize it into 4 ranges."},{"metadata":{"_cell_guid":"a21335bd-4e8d-66e8-e6a5-5d2173b72d3b","_uuid":"a0ecb237760ac41044fa54fd4170528ba982b43a","trusted":true},"cell_type":"code","source":"full_data['Fare'] = full_data['Fare'].fillna(full_data['Fare'].median())\nfull_data['CategoricalFare'] = pd.qcut(full_data['Fare'], 4)\nprint (full_data[['CategoricalFare', 'Survived']].groupby(['CategoricalFare'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec8d1b22-a95f-9f16-77ab-7b60d2103852","_uuid":"fba73c7b0116ece02425b2a8f889f8d544e6bcc7"},"cell_type":"markdown","source":"## 6. Age ##\nwe have plenty of missing values in this feature. # generate random numbers between (mean - std) and (mean + std).\nthen we categorize age into 5 range."},{"metadata":{"_cell_guid":"b90c2870-ce5d-ae0e-a33d-59e35445500e","_uuid":"d46a1d20fd86198bf7287dad97b0dee816d94ca9","trusted":true},"cell_type":"code","source":"age_avg \t   = full_data['Age'].mean()\nage_std \t   = full_data['Age'].std()\nage_null_count = full_data['Age'].isnull().sum()\n    \nage_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\nfull_data['Age'][np.isnan(full_data['Age'])] = age_null_random_list\nfull_data['Age'] = full_data['Age'].astype(int)\n    \nfull_data['CategoricalAge'] = pd.cut(full_data['Age'], 5)\n\nprint (full_data[['CategoricalAge', 'Survived']].groupby(['CategoricalAge'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bd25ec3f-b601-c1cc-d701-991fac1621f9","_uuid":"8f067c9b1dba8b943ad8d0e7b080a351c8885d95"},"cell_type":"markdown","source":"## 7. Name ##\ninside this feature we can find the title of people."},{"metadata":{"_cell_guid":"ad042f43-bfe0-ded0-4171-379d8caaa749","_uuid":"a811df2c56b5f4e3561362b8ecdd32dd47fbc300","trusted":true},"cell_type":"code","source":"def get_title(name):\n\ttitle_search = re.search(' ([A-Za-z]+)\\.', name)\n\t# If the title exists, extract and return it.\n\tif title_search:\n\t\treturn title_search.group(1)\n\treturn \"\"\n\nfull_data['Title'] = full_data['Name'].apply(get_title)\n\nprint(pd.crosstab(full_data['Title'], full_data['Sex']))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ca5fff8c-7a0d-6c18-2173-b8df6293c50a","_uuid":"9098d38a30541924287eb76fec08c5b1de866d69"},"cell_type":"markdown","source":" so we have titles. let's categorize it and check the title impact on survival rate."},{"metadata":{"_cell_guid":"8357238b-98fe-632a-acd5-33674a6132ce","_uuid":"de6654944383d8fc43ed34848dcd92d609cad931","trusted":true},"cell_type":"code","source":"full_data['Title'] = full_data['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\nfull_data['Title'] = full_data['Title'].replace('Mlle', 'Miss')\nfull_data['Title'] = full_data['Title'].replace('Ms', 'Miss')\nfull_data['Title'] = full_data['Title'].replace('Mme', 'Mrs')\n\nprint (full_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9b5333409d633bc4f0627d67248178e16708047f"},"cell_type":"markdown","source":"## 8. Deck ## \nA cabin number looks like ‘C123’. The letter refers to the deck, and so we’re going to extract these just like the titles. Let's check the impact of this on the survival rate"},{"metadata":{"trusted":true,"_uuid":"e5b63339a00e45f9f2c91bf53e8e429c8d441d0e"},"cell_type":"code","source":"#Turning cabin number into Deck\ncabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n#full_data['Deck']=full_data['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\na= full_data['Cabin'].astype(str).str[0]\nfull_data['Cabin']=a.str.upper()\nprint (full_data[['Cabin','Pclass','Survived']].groupby(['Cabin','Pclass'], as_index=False).mean())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a53acbd1b1be63748991c83071874b3a9127d7a","scrolled":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfull_data.columns,train.columns,train.index\n#full_data.loc[train.index,:]\nf, ax = plt.subplots(figsize=[10,10])\nsns.heatmap(full_data.loc[train.index,:].corr(),\n            annot=True, fmt=\".2f\",cbar_kws={'label': 'Percentage %'},cmap=\"plasma\",ax=ax)\nax.set_title(\"Correlation Plot\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"68fa2057-e27a-e252-0d1b-869c00a303ba","_uuid":"8d55e2e782f13787cb48694f78a3183b6608bae3"},"cell_type":"markdown","source":"# Data Cleaning #\ngreat! now let's clean our data and map our features into numerical values."},{"metadata":{"_cell_guid":"2502bb70-ce6f-2497-7331-7d1f80521470","_uuid":"f3421a999ee4c88239caf25a8c900d30530f814d","trusted":true},"cell_type":"code","source":"full_data['Sex'] = full_data['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n# Mapping titles\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfull_data['Title'] = full_data['Title'].map(title_mapping)\nfull_data['Title'] = full_data['Title'].fillna(0)\n    \n    # Mapping Embarked\nfull_data['Embarked'] = full_data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\nfull_data.loc[ full_data['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\nfull_data.loc[(full_data['Fare'] > 7.91) & (full_data['Fare'] <= 14.454), 'Fare'] = 1\nfull_data.loc[(full_data['Fare'] > 14.454) & (full_data['Fare'] <= 31), 'Fare']   = 2\nfull_data.loc[ full_data['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\nfull_data['Fare'] = full_data['Fare'].astype(int)\n    \n    # Mapping Age\nfull_data.loc[ full_data['Age'] <= 16, 'Age'] \t\t\t\t\t         = 0\nfull_data.loc[(full_data['Age'] > 16) & (full_data['Age'] <= 32), 'Age'] = 1\nfull_data.loc[(full_data['Age'] > 32) & (full_data['Age'] <= 48), 'Age'] = 2\nfull_data.loc[(full_data['Age'] > 48) & (full_data['Age'] <= 64), 'Age'] = 3\nfull_data.loc[ full_data['Age'] > 64, 'Age']                             = 4\n\n# Mapping Cabin\ncabin_mapping={\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5,\"F\": 6,\"G\": 7 , \"T\":8,\"N\":0}\nfull_data['Cabin'] = full_data['Cabin'].map(cabin_mapping)\nfull_data['Cabin'] = full_data['Cabin'].fillna(0)\n\nfull_data.head()\n\n# Feature Selection\ndrop_elements = ['index','Name', 'Ticket', 'SibSp',\\\n                 'Parch', 'FamilySize']\nfull_data = full_data.drop(drop_elements, axis = 1)\nfull_data = full_data.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28665e18cfa1942ad28b55f67027fa52d4eea34d"},"cell_type":"code","source":"print (full_data[full_data['Survived'].isnull()])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"8aaaf2bc-e282-79cc-008a-e2e801b51b07","_uuid":"353c2f78d02715337b0a8ab47ec79fbc791bc213"},"cell_type":"markdown","source":"good! now we have a clean dataset and ready to predict. let's find which classifier works better on this dataset. "},{"metadata":{"_cell_guid":"23b55b45-572b-7276-32e7-8f7a0dcfd25e","_uuid":"d0a724f8cffd32dd42ebaf9c4d7607a853bc1731"},"cell_type":"markdown","source":"# Classifier Comparison #"},{"metadata":{"_cell_guid":"31ded30a-8de4-6507-e7f7-5805a0f1eaf1","_uuid":"dd508f21063d48758cef0a25f82f33938a1a2602","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\n\nprint(\"Start classifer comparison\")\n\nclassifiers = [\n    KNeighborsClassifier(3),\n    SVC(probability=True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n\tAdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis(),\n    LogisticRegression()]\n\nlog_cols = [\"Classifier\", \"Accuracy\"]\nlog \t = pd.DataFrame(columns=log_cols)\n\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)\n\n\ntrain = full_data.iloc[:891]\ntest = full_data.iloc[891:]\ntargets = full_data['Survived'].iloc[:891]\n\ntest.drop('Survived',axis=1,inplace=True)\ntrain.drop('Survived',axis=1,inplace=True)\n\n\n\n#targets = pd.read_csv('../input/train.csv', usecols=['Survived'])['Survived'].values\n\n\n\nclf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\nclf = clf.fit(train, targets)\n'''\nclf = DecisionTreeClassifier(max_features ='sqrt',splitter='random',max_depth = 50 )\nclf = clf.fit(train, targets)\n'''\ntrain_predictions = clf.predict(test).astype(int)\n\ndf_output = pd.DataFrame()\naux = pd.read_csv('../input/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = train_predictions\ndf_output[['PassengerId','Survived']].to_csv('titanic_submission_final.csv', index=False)\nprint(\"File saved\")\n\n\nX = train\ny = targets\nacc_dict = {}\n\nfor train_index, test_index in sss.split(X, y):\n\tX_train, X_test = X.iloc[train_index], X.iloc[test_index]\n\ty_train, y_test = y.iloc[train_index], y.iloc[test_index]\n\t  \n\tfor clf in classifiers:\n\t\tname = clf.__class__.__name__\n\t\tclf.fit(train, targets)\n\t\ttrain_predictions = clf.predict(X_test)\n\t\tacc = accuracy_score(y_test, train_predictions)\n\t\tif name in acc_dict:\n\t\t\tacc_dict[name] += acc\n\t\telse:\n\t\t\tacc_dict[name] = acc\n\nfor clf in acc_dict:\n\tacc_dict[clf] = acc_dict[clf] / 10.0\n\tlog_entry = pd.DataFrame([[clf, acc_dict[clf]]], columns=log_cols)\n\tlog = log.append(log_entry)\n\nplt.xlabel('Accuracy')\nplt.title('Classifier Accuracy')\n\nsns.set_color_codes(\"muted\")\nsns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n\n\nclf = AdaBoostClassifier(n_estimators=60)\nclf.fit(train, targets)\nresult = clf.predict(test).astype(int)\n\ndf_output = pd.DataFrame()\naux = pd.read_csv('../input/test.csv')\ndf_output['PassengerId'] = aux['PassengerId']\ndf_output['Survived'] = result\ndf_output[['PassengerId','Survived']].to_csv('titanic_submission_final_2.csv', index=False)\nprint(\"File saved\")\n","execution_count":null,"outputs":[]}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}