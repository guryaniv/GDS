{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold\nrandom_state = 42\nimport os\nprint(os.listdir(\"../input\"))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6ef84ed5445d2d45b4e2cb8e2c3922c7cf338df3"},"cell_type":"markdown","source":"#  Load Data\nColumns with string values were converted to integers and then uploaded as new dataset. rest of data was not touched. Whole kernel runs in two minutes, Saves a lot of time ."},{"metadata":{"trusted":true,"_uuid":"41789e750f2588d63dda19777b28a644f2af874d"},"cell_type":"code","source":"train = pd.read_csv('../input/ga-encoded/train_new.csv', dtype={'fullVisitorId': 'str'},)\ntest = pd.read_csv('../input/ga-encoded/test_new.csv', dtype={'fullVisitorId': 'str'},)\nprint('Training data shape {},  Test Data Shape {}'.format(train.shape, test.shape))\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5160472dc677ef081dbe7467d0568096c8fff98"},"cell_type":"markdown","source":"## Prepare Numeric and categorical columns"},{"metadata":{"trusted":true,"_uuid":"b45c98805ef09934eaf59c9b095ac777031f0b10"},"cell_type":"code","source":"all_columns = train.columns.tolist()\n\n#Remove Columns which have only one unique values\ncols_to_delete = []\nfor col in all_columns:\n    dist_vals = train[col].value_counts().shape[0]\n    if dist_vals == 1:\n       cols_to_delete.append(col)\n   \n\n# Remove columns with more than 90% Missing Values\ncols_to_delete = cols_to_delete + ['trafficSource.adContent', 'trafficSource.adwordsClickInfo.page', 'trafficSource.adwordsClickInfo.adNetworkType', \n                                   'trafficSource.adwordsClickInfo.slot', 'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.adwordsClickInfo.gclId']\n\n\n#Remove columns which are Id's ot traget values\ncols_to_delete =  cols_to_delete + ['fullVisitorId', 'sessionId', 'visitId', 'totals.transactionRevenue', 'trafficSource.campaignCode']\n\nnum_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", \"visitStartTime\", 'totals.bounces',\n             'totals.newVisits', 'totals.visits']  \n\ncat_cols = [x for x in all_columns if x not in num_cols and x not in cols_to_delete]\nfeatures = cat_cols + num_cols\n\nprint('Number of features:', len(features))\nprint('Number of cat cols:', len(cat_cols))\nprint('Number of num cols:', len(num_cols))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc491fe52d1d816de71c53113a7a4f9d5cf68a8c"},"cell_type":"markdown","source":"## Create New Features"},{"metadata":{"trusted":true,"_uuid":"87c9c7c0b0ac1f834641c43954a0f33800b7eef7"},"cell_type":"code","source":"for col in num_cols:\n    train[col] = pd.to_numeric(train[col])    \n    test[col] = pd.to_numeric(test[col])\n    \ntrain['totals.transactionRevenue'].fillna(0, inplace = True)\ntrain['totals.transactionRevenue'] = pd.to_numeric(train['totals.transactionRevenue'])\ntrain['totals.transactionRevenue'] = np.log1p(train['totals.transactionRevenue'])    \n\ntrain['visitStartTime'] = pd.to_datetime(train['visitStartTime'], unit ='s')\ntest['visitStartTime']  = pd.to_datetime(test['visitStartTime'], unit ='s')\n\ntrain['date'] = pd.to_datetime(train['date'], format = '%Y%m%d')\ntest['date'] = pd.to_datetime(test['date'], format = '%Y%m%d')\n\ntrain['year'] = train['date'].dt.year\ntest['year'] =  test['date'].dt.year\n\ntrain['month'] = train['date'].dt.month\ntest['month'] =   test['date'].dt.month\n\ntrain['day'] =  train['date'].dt.day\ntest['day'] =   test['date'].dt.day  \n\ntrain['hour'] =  train['visitStartTime'].dt.hour\ntest['hour'] =   test['visitStartTime'].dt.hour\n\ncat_cols = cat_cols + ['year', 'month', 'day', 'hour']\n# num_cols = num_cols + ['year', 'month', 'day', 'hour']\ncat_cols.remove('date')\nnum_cols.remove('visitStartTime')\nfeatures = cat_cols + num_cols\n\nprint('Number of features:', len(features))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6aee7543b67959076733a9750eefd46503a31813"},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true,"_uuid":"6ad897fd10e7a903935788e0dc1550b570878085"},"cell_type":"code","source":"y_train =    train['totals.transactionRevenue']\nX_train  =   train[features]\nX_test =   test[features]\nprint('Training data shape {} Test Data Shape {}'.format(X_train.shape, X_test.shape))\n\nparams = {}\nparams['learning_rate'] = 0.08\nparams['boosting_type'] = 'gbdt'\nparams['objective'] =  'regression'  \nparams['metric'] = 'rmse'\nparams['seed'] = random_state\nparams['num_threads'] = 4\nparams['lambda_l1'] = 0.1\nparams['min_gain_to_split'] = 1\n\nfolds = KFold(n_splits = 5, shuffle = True, random_state = random_state)\n\noof_pred = np.zeros(shape=(X_train.shape[0])) \ntest_pred = np.zeros(shape=(X_test.shape[0]))  \ncv_score = np.zeros(shape =  folds.n_splits)\nfeature_imp = pd.DataFrame()\n\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n    train_x, train_y = X_train.iloc[train_idx],  y_train.iloc[train_idx]\n    valid_x, valid_y = X_train.iloc[valid_idx],  y_train.iloc[valid_idx]\n    \n    dtrain = lgb.Dataset(train_x, label= train_y)\n    dvalid = lgb.Dataset(valid_x, label= valid_y)    \n\n    model = lgb.train( params,\n                 dtrain,\n                 num_boost_round= 10000,\n                 valid_sets= [ dtrain, dvalid],\n                 early_stopping_rounds=200,        \n                                 \n                 verbose_eval = 50\n                 )    \n    \n    oof_pred[valid_idx] = model.predict(valid_x)    \n    test_pred += model.predict(X_test) / folds.n_splits    \n    cv_score[n_fold] = round(np.sqrt(mean_squared_error(valid_y,  oof_pred[valid_idx])), 5)   \n    print('\\nFold %2d RMSE: %.6f' %(n_fold + 1, cv_score[n_fold] ))\n    \n    \n    fold_importance = pd.DataFrame()\n    fold_importance[\"feature\"] =  model.feature_name()\n    fold_importance[\"importance\"] = model.feature_importance()\n    fold_importance[\"fold\"] = n_fold + 1    \n    feature_imp = pd.concat([feature_imp, fold_importance], axis=0)\n\nprint('CV OOF RMSE:{:.5f}, Mean CV RMSE: {:.5f}, Fold CV RMSE:{}'.format(np.sqrt(mean_squared_error(y_train, oof_pred)), \n                                                                      np.mean(cv_score),\n                                                                      cv_score                                                                     \n                                                                     ))\n\n\ntest_pred[test_pred<0] = 0\nsub = pd.DataFrame()\nsub['fullVisitorId'] = test['fullVisitorId'].copy()\n# sub['PredictedLogRevenue'] = test_pred\nsub['PredictedLogRevenue'] = np.expm1(test_pred)\nsub_grp = sub[['fullVisitorId', 'PredictedLogRevenue']].groupby('fullVisitorId').sum().reset_index()\nsub_grp['PredictedLogRevenue'] = np.log1p(sub_grp['PredictedLogRevenue']) \nsub_grp.to_csv('lgb_sub.csv',index=False)\n\nplt.figure(figsize=(8, 10))\nfeature_imp_avg = feature_imp[['feature', 'importance']].groupby(['feature']).mean().reset_index()\nfeature_imp_avg.sort_values(['importance'], ascending= False, inplace = True)\nsns.barplot(x= 'importance', y = 'feature', data =feature_imp_avg)\nplt.show()\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}