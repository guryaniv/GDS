{"cells":[{"metadata":{"_cell_guid":"840ad598-3ce2-4c24-b441-1cec72a54fb4","_uuid":"87c94200d4c399fe908d53ca3fefc39235e5b0dd"},"cell_type":"markdown","source":"# Loading packages"},{"metadata":{"collapsed":true,"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold, GridSearchCV\nfrom sklearn.metrics import roc_auc_score, make_scorer, precision_score\nfrom imblearn.over_sampling import SMOTE\n\nfrom time import time\nimport seaborn as sns\nimport missingno as msno\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"ab7b04439cdeab6429c5e1631bdbd58c79b3c253"},"cell_type":"code","source":"# Setting plot for better images\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('pdf', 'png')\npd.options.display.float_format = '{:.2f}'.format\nrc={'savefig.dpi': 75, 'figure.autolayout': False, 'figure.figsize': [12, 8], 'axes.labelsize': 18,\\\n   'axes.titlesize': 18, 'font.size': 18, 'lines.linewidth': 2.0, 'lines.markersize': 8, 'legend.fontsize': 16,\\\n   'xtick.labelsize': 16, 'ytick.labelsize': 16}\n\nsns.set(style='dark',rc=rc)\ndefault_color = '#56B4E9'\ncolormap = plt.cm.cool","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"070bdeb4-8bb3-4da4-8a1a-02dc37564ba7","_uuid":"1c8beb382171de49d3fe9faff890b316c5e74109"},"cell_type":"markdown","source":"# Loading data and Analysis"},{"metadata":{"collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Loading data and setting the timer to see how long it takes to run everything\nstart_init = time()\npath = '../input/'\ntrain = pd.read_csv(path+'train.csv',na_values=-1)\ntest = pd.read_csv(path+'test.csv',na_values=-1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fb5639ce-c41d-431c-8bd4-e071f34ac68b","_uuid":"c21f2ac65044b62546d886411d195d555bd21df4","trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"33530a2c-7a95-4353-8174-9de333bf787b","_uuid":"346c4a8d4b734312d6b09b84a9760ab605bf57cb","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ab7ff13a-d640-4fd5-88b3-61b7e4999e89","_uuid":"43097a8b0dc9bb511c15cf2a55a7f919a0123b08","trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"86be91981e28bc340f77b0ded7d429b04bc5edc5"},"cell_type":"markdown","source":"# Checking missing values\nChecking missing values on training and test dataset"},{"metadata":{"_cell_guid":"826c6ed5-b691-446d-bef9-94a355666b74","_uuid":"5df9a4516bab5a94af84e3c13274888c883f6d09","trusted":true,"collapsed":true},"cell_type":"code","source":"# Using missingno library to check the missing values\ndef checkingMissingValues(dataset):         \n    missingValueColumns = dataset.columns[dataset.isnull().any()].tolist()\n    df_null = dataset[missingValueColumns] \n    msno.bar(df_null,figsize=(20,8),color=default_color,fontsize=18,labels=True)            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f8552373964e25c13df286d4b13e38aed124df6"},"cell_type":"code","source":"checkingMissingValues(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3dfb0aba9d0c09a8ddb650521659421eaafad9f"},"cell_type":"code","source":"checkingMissingValues(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2667733b85e3c66d64794917ed3b151636df3122"},"cell_type":"markdown","source":"# Replacing missing values\nEvery missing value was replaced by the mean of the column"},{"metadata":{"scrolled":false,"_cell_guid":"74ad55a2-f93e-42be-923c-9f0e09417941","_uuid":"be7c15d8a04851592b17c4ce1713b6c438f53585","trusted":true,"collapsed":true},"cell_type":"code","source":"# Function that replaces the missing values with the mean of the column\ndef replacingMissingValues(dataset):\n    col = dataset.columns\n    for i in col:\n        if dataset[i].isnull().sum() > 0:\n            dataset[i].fillna(np.mean(dataset[i]), inplace=True)\n    return dataset   \ntrain = replacingMissingValues(train)\ntest = replacingMissingValues(test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3d4d1bca38c70c8c123870e657db99240b92954"},"cell_type":"markdown","source":"# Checking imbalance classes\nChecking the amount of 1s and 0s on the target column."},{"metadata":{"scrolled":true,"_cell_guid":"1f182b65-993c-4e56-97fa-a8029186f31f","_uuid":"8e98a039fc03489ce8fc82c984c6904dc72c8a3c","trusted":true,"collapsed":true},"cell_type":"code","source":"# Function to show the plot of the training dataset regarding the target column\ndef checkTarget(train):\n    plt.figure(figsize=(15,5))\n    ax = sns.countplot('target',data=train,color=default_color)\n    for p in ax.patches:\n        ax.annotate('{:.2f}%'.format(100*p.get_height()/len(train['target'])), (p.get_x()+ 0.3, p.get_height()+10000))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e50570e5772a9c7a2cdddca283be81cff55a7041"},"cell_type":"markdown","source":"# Function to make oversampling on the target column\nAfter using this function, the target column will be balanced."},{"metadata":{"scrolled":true,"_cell_guid":"effd0262-122e-4b58-b956-d35e1f8d9e18","_uuid":"1eeeb07293d3c7260f374832d07dd154c5392ef3","trusted":true},"cell_type":"code","source":"# Function to make the oversampling. It uses the imblearn.over_sampling library.\ndef oversampling(train):\n    target = train['target']\n    train = train.drop(['target'], axis=1)\n    train['target'] = target\n    features, target = SMOTE(n_jobs=-1, random_state=42).fit_sample(train.drop(['target'], axis=1), train['target'])\n    target[target >= 0.5] = 1\n    target[target < 0.5] = 0\n    finalArray = np.column_stack((features, target))\n    columns = train.columns.copy()\n    train = pd.DataFrame(finalArray, columns=columns).reset_index(drop=True)\n    return train\ncheckTarget(train)\ntrain = oversampling(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5dfc9da3b769f92648d15f18f2f425cfa2c73bab"},"cell_type":"code","source":"checkTarget(train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"29c52c04506e9ff47666ad360cd5b087c3cac6f2"},"cell_type":"markdown","source":"# Defining functions for training and tuning"},{"metadata":{"collapsed":true,"_cell_guid":"cb84927d-f7c2-4f3a-9dca-5e6b85dac1d6","_uuid":"d2332198bfa461e501197fb3db0392c23bd77a5c","trusted":true},"cell_type":"code","source":"# Function that returns the value of prediction using normalized Gini coefficient.\ndef predict_labels_gini(clf, features, target):\n    ''' Makes predictions using a fit classifier based on F1 score. '''\n    y_pred = clf.predict(features)\n    gini = 0\n    try:\n        gini = 2*roc_auc_score(target.values, y_pred)-1\n    except ValueError:\n        pass\n    print(\"Gini score set: {:.4f}.\".format(gini))\n    return gini\n\n# Function that trains the classifier and returns the prediction.\ndef train_predict(clf, X_train, y_train, X_test, y_test):\n    ''' Train and predict using a classifer based on F1 score. '''\n    print(\"Training a {} using a training set size of {}. . .\".format(clf.__class__.__name__, len(X_train)))\n    clf.fit(X_train, y_train)\n\n    return predict_labels_gini(clf, X_test, y_test)\n\ndef split_data(features):\n    n_splits = 4\n    folds = KFold(n_splits=n_splits, random_state=42)\n    return enumerate(folds.split(features))\n\n# Function that finds the best classifier from the array comparing the predict result.\ndef training_tuning(clfs, features, target, option):\n    for i,clf in enumerate(clfs):\n        bestModel = {}\n        bestScore = 0\n        bestFold = 0\n        start_fold = time()\n        for fold, (train_idx, test_idx) in split_data(features):\n            print(\"\\nFold \", fold)\n            X_train = features.iloc[train_idx]\n            y_train = target.iloc[train_idx]\n            X_test = features.iloc[test_idx]\n            y_test = target.iloc[test_idx]\n            score = train_predict(clf, X_train, y_train, X_test, y_test)\n            if score >= bestScore:\n                bestScore = score\n                bestModel = clf\n                bestFold = fold\n        end_fold = time()\n        print('Training folds in {:.4f}'.format(end_fold - start_fold))\n        if bestScore > 0:\n            print('Tuning fold {} -> score {:.4f}'.format(bestFold, bestScore))\n            bestTunnedModel = tuning(bestModel, features, target, bestScore)\n            if bestTunnedModel == {}:\n                submissionFile(bestModel, option, bestFold, clf.__class__.__name__)\n            else:\n                print('Best Tunned model')\n                submissionFile(bestTunnedModel, option, bestFold, clf.__class__.__name__)\n\ndef normalized_gini(y_prob, y_actual):\n    return 2 * roc_auc_score(y_prob, y_actual) - 1\n\ndef tuning(clf, features, target, score):\n    print('Starting tunning')\n    start_tuning = time()\n    params={}\n    if clf.__class__.__name__ == \"DecisionTreeClassifier\":\n        params = {'min_samples_split': range(2, 202, 10)}\n\n    if clf.__class__.__name__ == \"LogisticRegression\":\n        params = {'class_weight': ['balanced'],\n              'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n              'penalty': ['l1', 'l2']\n              }\n\n    if clf.__class__.__name__ == \"SGDClassifier\":\n        params = {\n            'max_iter':[250, 500, 1000],\n            'loss': ['log'],\n            }\n    if params == {}:\n        return clf\n    # Normalized Gini Scorer\n    gini_scorer = make_scorer(normalized_gini, greater_is_better=True)\n    modelTunned = GridSearchCV(clf, params, scoring= gini_scorer, cv=4)\n    modelTunned.fit(features, target)\n    scoreTunned = predict_labels_gini(modelTunned, features, target)\n    end_tuning = time()\n    print(\"Finished tuning in {:.4f} seconds\".format(end_tuning - start_tuning))\n    if scoreTunned <= score:\n        return {}\n    return modelTunned","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"73803c70ee0f421f8ec1339925916f467167ad12"},"cell_type":"markdown","source":"# Function for submission"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e8ea0162da05770f1984d2a482ee291961a3605e"},"cell_type":"code","source":"# Create submission file using the prediction from the tuned classifier\ndef submissionFile(clf, option, fold, clf_name):\n    print('Creating submission file')\n    sub = pd.DataFrame()\n    sub['id'] = test['id']\n    test_pred = pd.DataFrame(test, columns=train.drop(['id', 'target'], axis=1).columns)\n    y_test_pred = clf.predict_proba(test_pred)[:, 1]\n    sub['target'] = y_test_pred\n    sub.to_csv('submit_{}_{}_{}.csv'.format(option, fold, clf_name), float_format='%.9f', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2ff34bd2-102c-42ff-b343-e4f5e0952417","_uuid":"c69cf67fa4a88133c7d796b2f281276c6885b238","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\n\nclfs = [\n    DecisionTreeClassifier(),\n    LogisticRegression(),\n    # SGD used max_iter=100 for a fast decision if he was going to be tuned\n    SGDClassifier(loss=\"log\", max_iter=100)\n]\noptions = [1,2,3,6]\n\n\nfor option in options:\n    print(\"Starting Methodology {}\".format(option))\n    if option%2 == 0:\n        print('Replacing values!')\n        train = replacingMissingValues(train)\n        test = replacingMissingValues(test)\n    else:\n        train.fillna(-1, inplace=True)\n        test.fillna(-1, inplace=True)\n    if option%3 == 0:\n        print('Oversampling!')\n        train = oversampling(train)\n\n    target = train['target']\n    features = train.drop(['id', 'target'], axis = 1)\n    training_tuning(clfs, features, target, option)\n\nend_init = time()\nprint(\"Finished in {:.4f} seconds\".format(end_init - start_init))","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}