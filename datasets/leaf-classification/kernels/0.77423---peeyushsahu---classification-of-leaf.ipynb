{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","scrolled":true,"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport sklearn.preprocessing as preprocessing\nfrom sklearn.cross_validation import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.stats import skew \n\n\nimport os\nprint(os.listdir(\"../input\"))\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(train.shape, test.shape)\nprint(test.head())\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"e1f362aa-76d3-4b82-9327-eb36543592b7","_uuid":"e60d7155c90d56fd03338c65d31dc4ab2ce591cb"},"cell_type":"markdown","source":"## Null value estimation"},{"metadata":{"_cell_guid":"9cc91066-7c11-4580-bf71-9625ee48d21d","_uuid":"21bbd633d86d71b180385cd71159737df0b61ef7","trusted":true},"cell_type":"code","source":"# Check for null values in training and test set\nprint('Null values in Training set:', train.isnull().sum().sum(), ', Total values in Training set:', train.isnull().count().sum())\nprint('Null values in Test set:', test.isnull().sum().sum(), ', Total values in Test set:', test.isnull().count().sum())","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"fecdbc60-5528-425e-893b-714fb62992bc","_uuid":"a85f3caaaa5a3e0cbc350894aeebad196dc9e47e"},"cell_type":"markdown","source":"No need for filling nan :) Good dataset"},{"metadata":{"_cell_guid":"29521cb1-b403-41d8-a2fa-bf66aa2b6e3d","_uuid":"c19c5d817e436f410fe578eb0914b1a121124f41"},"cell_type":"markdown","source":"## Checking for feature skewness"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","scrolled":true,"trusted":true},"cell_type":"code","source":"# Some data vizualization for accessing scaling, standardization and normalization need\nskewness = train.iloc[:,2:].apply(lambda x: skew(x.dropna()))\nprint('Skewness in data')\nprint(skewness.sort_values(ascending=False)[:10])\ntrain[['margin16', 'shape2']].hist()","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"7991e5da-089f-458d-b3aa-d648dbfe98cc","_uuid":"60ed91f48f053816ebd15055b0ce25f339756ac6"},"cell_type":"markdown","source":"Lets ckeck for skewness of the features, I can see that there is **high skewnwss** in many features. Let us have a look how does the distribution of *margin16* looks like, as we can see this feature is more like a categorical variable. Whereas *shape2* shows a distribution. I would like to scale these features next. "},{"metadata":{"_cell_guid":"9539381b-6c2f-4918-8793-4401c4e0e00c","_uuid":"4e3de8f138a3f1d3f1382a8ed14868958a0d71eb"},"cell_type":"markdown","source":"## Prepare training and test dataset for ML"},{"metadata":{"_cell_guid":"25c01599-7d6b-4c11-be0b-17fb006f95cd","_uuid":"b8f59e4c1f968aa049653e9ab855431537ee4050","trusted":true},"cell_type":"code","source":"# Lets prepare training and test set for ML models\nle = preprocessing.LabelEncoder().fit(train.species)\nlabels = le.transform(train.species)\nclasses = le.classes_\n\ntest_id = test.id\ntrain_df = train.drop(['id', 'species'], axis=1)\ntest_df = test.drop(['id'], axis=1)\nprint(train_df.head(2))\n#print(le.classes_)\n#print(train.species[:10], labels[:10])","execution_count":25,"outputs":[]},{"metadata":{"_cell_guid":"f3ffe79e-6f0d-40a8-93d3-fd7138b53fcc","_uuid":"7b944684f91cdb37b187ac8020d540898a036083"},"cell_type":"markdown","source":"## Scaling of features"},{"metadata":{"_cell_guid":"f7f8333b-88f1-41fc-a474-1dc453ffb83e","_uuid":"881259c089fe6b1a78928cf3a4869375dd17edc1","trusted":true},"cell_type":"code","source":"# We want to scale the data for better performance on ML, we will use standardscaler\n\nscaler = preprocessing.StandardScaler().fit(train_df)\nprint(scaler)\n\ntrain_df = pd.DataFrame(scaler.transform(train_df), columns=train_df.columns)\ntest_df = pd.DataFrame(scaler.transform(test_df), columns=test_df.columns)\n\n# Visualize standardscaler transformation\nsns.set()\nscaler = preprocessing.StandardScaler().fit(train[['shape2', 'shape3', 'shape1', 'margin16']])\nscaled_train = scaler.transform(train[['shape2', 'shape3', 'shape1', 'margin16']]) \ndf_dist = pd.DataFrame({'shape3_nt': train['shape3'], 'shape3_tsf': scaled_train[:,1]})\n#print(df_dist.head())\ndf_dist.hist()","execution_count":48,"outputs":[]},{"metadata":{"_cell_guid":"e95a33bb-ccaf-4315-9bc9-ada8b7cab427","_uuid":"f905dd5446060dd798e6b141da80c1e6088544fe"},"cell_type":"markdown","source":"## Checking correlation between features"},{"metadata":{"_cell_guid":"03edb139-fbb9-4c13-a83b-973d61db8ff8","_uuid":"ee1031d65842846e3f993e122a4ce1fc7952bb81","trusted":true},"cell_type":"code","source":"feature_corr = train_df.corr(method='pearson')\nsns.set()\nsns.clustermap(feature_corr)","execution_count":49,"outputs":[]},{"metadata":{"_cell_guid":"d4dc62a1-6230-4367-8231-74f24cef674a","_uuid":"eaef6d6575e88921f17828faad5b44a9dd397f4a","collapsed":true},"cell_type":"markdown","source":"## Random split of traning and test data"},{"metadata":{"_cell_guid":"f0a0938e-433b-45c1-b841-6146e6dcccb5","_uuid":"4b3e84e0743f1cd88b09f9095f11a447b179d0d6","trusted":true},"cell_type":"code","source":"# We will keep 30% data for test and rest for training\nsss = StratifiedShuffleSplit(y=labels, test_size=0.2, random_state=0, n_iter=1)\n\nfor train_ind, test_ind in sss:\n    print(len(train_ind), len(test_ind))\n    print(test_ind[:5])\n    x_train, x_test = train_df.iloc[train_ind,], train_df.iloc[test_ind,]\n    y_train, y_test = labels[train_ind], labels[test_ind]\nprint(x_test.head(2), y_test[:2])","execution_count":50,"outputs":[]},{"metadata":{"_cell_guid":"283d57db-8c49-466b-b160-a4a7fbddaf09","_uuid":"b52832613e74c45fa8a684a114cac577b387c4a6"},"cell_type":"markdown","source":"## Import ML methods for training the models"},{"metadata":{"_cell_guid":"e8b0d161-f662-43d1-b15c-aa8103eab747","_uuid":"ecde77072162bf80c51592b2a39bd9e7d3c5a413","collapsed":true,"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"be95fd5c-584b-4311-8a27-d5cf47679f0c","_uuid":"5556227ec4fcde952800f234ab6b157fa4ebaedb","collapsed":true,"trusted":true},"cell_type":"code","source":"# Grid search for parameter estimation\ndef gridSearch(model, parameters, scoring='accuracy'):\n    clf = GridSearchCV(model, parameters, scoring)\n    return clf","execution_count":52,"outputs":[]},{"metadata":{"_uuid":"440731f09e483a0d83ccd9ea6716060434092a31"},"cell_type":"markdown","source":"# SVM"},{"metadata":{"_cell_guid":"a043b32c-b781-4a2a-a493-2a338531852a","_uuid":"ceeb8df9a25cd16dfe6be1da67eb06840907a11e","trusted":true},"cell_type":"code","source":"# Let us start by SVM\nparameters = {'kernel': ('linear', 'rbf'), 'C': [0.01, 0.025, 0.05, 0.1, 0.2, 0.4, 0.8, 1, 10]}\nsvc = SVC(probability=True, cache_size=1000)\nclf = gridSearch(svc, parameters)\nprint(clf)\nclf.fit(x_train, y_train)\nprint(clf.best_params_)\nprint(clf.best_score_)","execution_count":53,"outputs":[]},{"metadata":{"_cell_guid":"a6ebc0ad-742e-4cf6-99ea-6dc87f54e8b0","_uuid":"d855a3a4adf821d96f312ec5223785cf3db403c1","trusted":true},"cell_type":"code","source":"train_predictions = clf.predict(x_test)\nacc = accuracy_score(y_test, train_predictions)\nprint(\"Accuracy: {:.4%}\".format(acc))","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"671ce3df-1c16-48b4-8113-26431b8af670","_uuid":"7d48fd98789ce79f334071e30a9e0a19517b538f","trusted":true},"cell_type":"code","source":"# Let us start by SVMnu\nparameters = {'kernel': ('rbf',), 'gamma': [0.0005, 0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.2, 0.4, 0.8, 1]}\nnusvc = NuSVC(probability=True, cache_size=1000)\nnuclf = gridSearch(nusvc, parameters)\nprint(nuclf)\nnuclf.fit(x_train, y_train)\nprint(nuclf.best_params_)\nprint(nuclf.best_score_)","execution_count":69,"outputs":[]},{"metadata":{"_cell_guid":"d5987622-fadd-482a-b102-5fb1c3b08197","_uuid":"76149b4a43493e94a86884ba2a401c76bb76ba9b","trusted":true},"cell_type":"code","source":"nu_train_predictions = nuclf.predict(x_test)\nnu_acc = accuracy_score(y_test, nu_train_predictions)\nprint(\"Accuracy: {:.4%}\".format(nu_acc))\n\nnu_train_predictions = nuclf.predict_proba(x_test)\nnu_ll = log_loss(y_test, rf_train_prediction)\nprint(\"Log Loss: {}\".format(nu_ll))","execution_count":70,"outputs":[]},{"metadata":{"_uuid":"54282370e24fe845137e52ff686a08cc4f975b1d"},"cell_type":"markdown","source":"We got the results, although SVM performs very good at the training data it has **lower performance** on real test data."},{"metadata":{"_uuid":"dff40e543d329c1759a7b7b3634e86a596b4a5d2"},"cell_type":"markdown","source":"# Random forest"},{"metadata":{"trusted":true,"_uuid":"5fc376bdcde76b5ae743bef5900cb47913af8eae"},"cell_type":"code","source":"rf_clf = RandomForestClassifier(n_estimators=1000, random_state=0)\nrf_clf.fit(x_train, y_train)","execution_count":73,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3da3d3932e74427198bdc56aea5b67ffb301aa7"},"cell_type":"code","source":"rf_train_prediction = rf_clf.predict(x_test)\nrf_acc = accuracy_score(y_test, rf_train_prediction)\nprint(\"Accuracy: {:.4%}\".format(rf_acc))\n\nrf_train_prediction = rf_clf.predict_proba(x_test)\nrf_ll = log_loss(y_test, rf_train_prediction)\nprint(\"Log Loss: {}\".format(rf_ll))","execution_count":74,"outputs":[]},{"metadata":{"_uuid":"cba61cdaecdef4f3e802d67792ab9d6a802c4430"},"cell_type":"markdown","source":"Where as we see a lesser accuracy of Random forest on training set it has a **better prediction power** on test set."},{"metadata":{"_uuid":"6bb5f25e1ebbbe7997ca122afa230620b49c8238"},"cell_type":"markdown","source":"## Predicting actual test set"},{"metadata":{"_cell_guid":"42665c8a-85be-43fb-99f1-837abc2d5b85","_uuid":"a82bfb6f801ee902fa50ca23bdcfa08a9c50f056","trusted":true},"cell_type":"code","source":"# Predicting the actual set\nnu_test_predict = rf_clf.predict(test_df)\ntest_predict = clf.predict(test_df)\nacc = accuracy_score(test_predict, nu_test_predict)\nprint(\"Aggrement between two SVM linear and rbf models on prediction: {:.4%}\".format(acc))","execution_count":75,"outputs":[]},{"metadata":{"_cell_guid":"228f75bc-6743-4a78-9abc-7b49d7b6e6ef","_uuid":"7fd4486bc8d520bcc4ef1fe2a217df05c58ac0de","collapsed":true,"trusted":true},"cell_type":"code","source":"# Predicting probability of class for the actual test set\ntest_predict_prob = rf_clf.predict_proba(test_df)","execution_count":77,"outputs":[]},{"metadata":{"_cell_guid":"98d1f553-0549-4200-8fba-c19ae0f45c32","_uuid":"300a1899449c5bef436aa7a1231dfbdb3cb23fe8","collapsed":true},"cell_type":"markdown","source":"### Lets submit it"},{"metadata":{"_cell_guid":"0adf7810-4946-4f0e-b02b-0058484ff243","_uuid":"e49f3f422c46edc135d64520bdf5ba79ec0ad1b2","trusted":true},"cell_type":"code","source":"# Format DataFrame\nsubmission = pd.DataFrame(test_predict_prob, columns=classes)\nsubmission.insert(0, 'id', test_id)\nsubmission.reset_index()\nprint(submission.head())\nsubmission.to_csv('prc_rf_submission.csv', index=False)","execution_count":78,"outputs":[]},{"metadata":{"_cell_guid":"6428e912-f5df-49db-ab5d-682435110367","_uuid":"26b7696105280bbb602a4899db35cd7e6cfcc55b","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"109730fc-f44e-4348-8c64-22c4b4e2c4d1","_uuid":"a442283a1b9b7d68a440e0211eedb9e5952a68d1","collapsed":true,"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}