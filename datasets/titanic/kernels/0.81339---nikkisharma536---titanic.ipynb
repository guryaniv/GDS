{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom pandas.tools.plotting import parallel_coordinates\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aafe34a9ada4c4bac079aab82dff84a355dab905"},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")\ntrain_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e99c6b64e6201c6a33b22b2146eafadf2ce45c2d"},"cell_type":"code","source":"test = pd.read_csv(\"../input/test.csv\")\nIDtest = test[\"PassengerId\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"916f18e207ba5c871d4312033ef27ca97aedbdea"},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"868fa0abf39b8c1a094720bc9565fa4adfdb3526"},"cell_type":"code","source":"train_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b510b62ffb798039e2b7ccf9c33d93e64a20b0ab"},"cell_type":"markdown","source":"Clean data by dropping columns which we are not using for visualization"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"197b44e5b405e0209bdb2106fe89734fe4d319b0"},"cell_type":"code","source":"train_data.drop(['PassengerId','Ticket'], axis=1, inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07e00bdae0f047512d969d04f8894b8ba722db03"},"cell_type":"markdown","source":"Check wether data have null values or not"},{"metadata":{"trusted":true,"_uuid":"11aeed5802d4d538137841c8ab24c5ac5bb46cf6"},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ba18a46e62a7dab8901d91a388f2d1c554d2dc2"},"cell_type":"markdown","source":"Cleaning missing data\n\nIn statistics, missing data, or missing values, occur when no data value is stored for the variable in an observation. Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data. The goal of cleaning operations is to prevent problems caused by missing data that can arise when training a model."},{"metadata":{"trusted":true,"_uuid":"7ea490ffd41fa7e51519b5e6f0daad5487e36a7a"},"cell_type":"code","source":"\n\n#Fill Embarked nan values of dataset set with 'S' most frequent value\ntrain_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"C\")\ntest[\"Embarked\"] = test[\"Embarked\"].fillna(\"C\")\n\n#complete missing fare with median\ntrain_data['Fare'].fillna(train_data['Fare'].median(), inplace = True)\ntest['Fare'].fillna(test['Fare'].median(), inplace = True)\n\n## Assigning all the null values as \"N\"\ntrain_data.Cabin.fillna(\"N\", inplace=True)\ntest.Cabin.fillna(\"N\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f224bfb516007c648e6130010ef18d907e7648a6"},"cell_type":"markdown","source":"Check whether all missing data are filled"},{"metadata":{"trusted":true,"_uuid":"7a8c7fe1595dad7d7d4da91e740f6a73447f25b9"},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7e3c059957f8138ffbaa385df88b59909324d45"},"cell_type":"markdown","source":"**Feature engineering** :  Name/Title\n"},{"metadata":{"trusted":true,"_uuid":"11a2bab680a15845fac3fab2286fa5c7cfd387a8"},"cell_type":"code","source":"train_data[\"Name\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bdc17613d0135967e4e5156b671f038e6cdf052"},"cell_type":"code","source":"# Get Title from Name\ntrain_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train_data[\"Name\"]]\ntrain_data[\"Title\"] = pd.Series(train_title)\ntrain_data[\"Title\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"261aedc2c16ab13420b734a7a8ceba640b23c0a2"},"cell_type":"code","source":"# Get Title from Name\ntest_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in test[\"Name\"]]\ntest[\"Title\"] = pd.Series(test_title)\ntest[\"Title\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57b7506b8dc5e635b57e65e1c3e14d2e75a41159"},"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=train_data)\ng = plt.setp(g.get_xticklabels(), rotation=45) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c14bb35235f6de659ad9db9013a6d934214a98c9"},"cell_type":"code","source":"# Convert to categorical values Title \ntrain_data[\"Title\"] = train_data[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain_data[\"Title\"] = train_data[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ntrain_data[\"Title\"] = train_data[\"Title\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"768624041dcf09b1345b9c2295673f942019faf4"},"cell_type":"code","source":"# Convert to categorical values Title \ntest[\"Title\"] = test[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest[\"Title\"] = test[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ntest[\"Title\"] = test[\"Title\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8eaf806b7d030869790cec672e357e004f528a08"},"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=train_data)\ng = plt.setp(g.get_xticklabels(), rotation=45) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b2e1d1b035146f018efa3089be38d08a559d376f"},"cell_type":"code","source":"# group by Sex, Pclass, and Title \ngrouped = train_data.groupby(['Sex','Pclass', 'Title'])  \n# view the median Age by the grouped features \ngrouped.Age.median()\n# apply the grouped median value on the Age NaN\ntrain_data.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b29cf5977c3e474531f19b7c9b9655bb61cf1a9e"},"cell_type":"code","source":"# group by Sex, Pclass, and Title \ntest_grouped = test.groupby(['Sex','Pclass', 'Title'])  \n# view the median Age by the grouped features \ntest_grouped.Age.median()\n# apply the grouped median value on the Age NaN\ntest.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a24f9d3fdd7320079a26dc4f37317b608e20dae"},"cell_type":"markdown","source":"**Feature engineering** :  Family size"},{"metadata":{"trusted":true,"_uuid":"efb525351ae73876779c128e1f5a74603c828fa3"},"cell_type":"code","source":"# Create a family size descriptor from SibSp and Parch\ntrain_data[\"Family_size\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1\ntest[\"Family_size\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d481e49b44f526ee277c7af0018af6713287888"},"cell_type":"code","source":"train_data['survived_dead'] = train_data['Survived'].apply(lambda x : 'Survived' if x == 1 else 'Dead')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de6326afc66061c66869afe4c9077602716af9b9"},"cell_type":"code","source":"sns.clustermap(data = train_data.corr().abs(),annot=True, fmt = \".2f\", cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6995ac9d413f514b4e67bb6aedc821611044bb91"},"cell_type":"code","source":"sns.countplot('survived_dead', data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ce16d7fc817fe3b3579e9865cabf7f5f0a966db"},"cell_type":"code","source":"sns.countplot( train_data['Sex'],data = train_data, hue = 'survived_dead', palette='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cf0cca6508de8406c7c7915eda21d26939e74d0"},"cell_type":"code","source":"sns.countplot( train_data['Pclass'],data = train_data, hue = 'survived_dead')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60366192a0c503661630b5141095697ee6b2bf5d"},"cell_type":"code","source":"sns.barplot(x = 'Pclass', y = 'Fare', data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3956eadbc958bae715f37083a17e0181046cdc0d"},"cell_type":"code","source":"sns.pointplot(x = 'Sex', y = 'Survived', hue = 'Pclass', data = train_data);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b2d155366f395a310997e7e059623c08b2946db"},"cell_type":"markdown","source":"Fare - Passenger Fare\nEmbarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"},{"metadata":{"trusted":true,"_uuid":"885cdaf397f984986fb440a8d3e4cb8d03c3a243"},"cell_type":"code","source":"sns.barplot(x  = 'Embarked', y = 'Fare', data = train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f6101b586fbe47d7c78ff81d0a75fba71a2fd86"},"cell_type":"code","source":"g = sns.FacetGrid(train_data, hue='Survived')\ng.map(sns.kdeplot, \"Age\",shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"0ce2f545d19c50f5c2493a0b32c17a350d68d074"},"cell_type":"code","source":"sns.catplot(x=\"Embarked\", y=\"Survived\", hue=\"Sex\",\n            col=\"Pclass\", kind = 'bar',data=train_data, palette = \"rainbow\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"485b9601de26aa8c16a38652847d0689a1f3db7a"},"cell_type":"markdown","source":"sibsp - Number of Siblings/Spouses Aboard\n\n"},{"metadata":{"trusted":true,"_uuid":"de61ea610fc114d2a3a886a0a49f7647b5b224d6"},"cell_type":"code","source":"sns.catplot(x='SibSp', y='Survived',hue = 'Sex',data=train_data, kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3158855ffaa4a5389aad318a85e278a5db2e831e"},"cell_type":"markdown","source":"parch - Number of Parents/Children Aboard"},{"metadata":{"trusted":true,"_uuid":"b21ec96239e0bc5f39a23c06f9ff1a638275bc44"},"cell_type":"code","source":"sns.catplot(x='Parch', y='Survived',hue = 'Sex',data=train_data, kind='point')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74d185b31c2b87c8fe90f9fabcff50344b11fb7a"},"cell_type":"code","source":"g= sns.FacetGrid(data = train_data, row = 'Sex', col = 'Pclass', hue = 'survived_dead')\ng.map(sns.kdeplot, 'Age', alpha = .75, shade = True)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"639d9012876a4dc0fe7039b602eb26f306fef495"},"cell_type":"code","source":"categoricals = train_data.select_dtypes(exclude=[np.number])\ncategoricals.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03ea06fcc7e7be83585ef1f6617519eb35161d54"},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n\nlbl = LabelEncoder() \nlbl.fit(list(train_data['Embarked'].values)) \ntrain_data['Embarked'] = lbl.transform(list(train_data['Embarked'].values))\nlbl.fit(list(test['Embarked'].values)) \ntest['Embarked'] = lbl.transform(list(test['Embarked'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71bbc4c84814632857d8d823e56719d1522e5247"},"cell_type":"code","source":"def encode(x): return 1 if x == 'female' else 0\ntrain_data['enc_sex'] = train_data.Sex.apply(encode)\ntest['enc_sex'] = test.Sex.apply(encode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bee015d6733461d0b178bef3736e63b082cbf7f"},"cell_type":"code","source":"train_data[\"has_cabin\"] = [0 if i == 'N'else 1 for i in train_data.Cabin]\ntest[\"has_cabin\"] = [0 if i == 'N'else 1 for i in test.Cabin]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d75a5e331ee4b71bce35c12f6af4381b6f781992"},"cell_type":"code","source":"from collections import Counter\n# Outlier detection \n\ndef detect_outliers(train_data,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(train_data[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(train_data[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = train_data[(train_data[col] < Q1 - outlier_step) | (train_data[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train_data,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ebaaeda1c9fd83baa4b64c495f849139f595251"},"cell_type":"code","source":"train_data.loc[Outliers_to_drop] # Show the outliers rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"260b6cddbbab57c3390e7509e87d4cd5c691ba71"},"cell_type":"code","source":"# Drop outliers\ntrain_data = train_data.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccda432c5cb4b9946f34db0a57e852fb379b893e"},"cell_type":"code","source":"data = train_data.select_dtypes(include=[np.number]).interpolate().dropna()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"123c64d68e348d43b7e8a0035ae0f0c111aa68cf"},"cell_type":"code","source":"y_train = train_data[\"Survived\"]\n\nX_train = data.drop(labels = [\"Survived\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"023ffb530304efa2719a907920003bf651bb72c3"},"cell_type":"code","source":"test = test.select_dtypes(include=[np.number]).interpolate().dropna()\ntest = test[X_train.columns]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ea8f0d5478be0e348193be05651682f6117682fb"},"cell_type":"code","source":"# Feature Scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\n\ntest = sc.transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"810f43142e829a3dfa5967ba218bc914cb93aff5"},"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\nkfold = StratifiedKFold(n_splits=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebb0b69f10daab3bcba1b52b800cd148983e5313"},"cell_type":"code","source":"#ExtraTrees \nfrom sklearn.ensemble import ExtraTreesClassifier\nExtC = ExtraTreesClassifier()\n\n\n## Search grid for optimal parameters\nex_param_grid = {\"max_depth\":  [n for n in range(9, 14)],  \n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [n for n in range(4, 11)],\n              \"min_samples_leaf\": [n for n in range(2, 5)],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[n for n in range(10, 60, 10)],\n              \"criterion\": [\"gini\"]}\n\n\ngsExtC = GridSearchCV(ExtC,param_grid = ex_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsExtC.fit(X_train,y_train)\n\nExtC_best = gsExtC.best_estimator_\n\n# Best score\ngsExtC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bd307d2e1b21aa699d52b238cadefbddb08f4bd"},"cell_type":"code","source":"# RFC Parameters tunning \nfrom sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier()\n\n\n\n## Search grid for optimal parameters\nrf_param_grid = {\"max_depth\":  [n for n in range(9, 14)],  \n              \"max_features\": [1, 3, 10],\n              \"min_samples_split\": [n for n in range(4, 11)],\n              \"min_samples_leaf\": [n for n in range(2, 5)],\n              \"bootstrap\": [False],\n              \"n_estimators\" :[n for n in range(10, 60, 10)],\n              \"criterion\": [\"gini\"]}\n\n\ngsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 1, verbose = 1)\n\ngsRFC.fit(X_train,y_train)\n\nRFC_best = gsRFC.best_estimator_\n\n# Best score\ngsRFC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a01fcf52428c805c6328a04f23e86a59966de4ba"},"cell_type":"code","source":"# Adaboost\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nDTC = DecisionTreeClassifier()\n\nadaDTC = AdaBoostClassifier(DTC, random_state=7)\n\nada_param_grid = {\"base_estimator__criterion\" : [\"gini\", \"entropy\"],\n              \"base_estimator__splitter\" :   [\"best\", \"random\"],\n              \"algorithm\" : [\"SAMME\",\"SAMME.R\"],\n              \"n_estimators\" :[30],\n              \"learning_rate\":  [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5]}\n\ngsadaDTC = GridSearchCV(adaDTC,param_grid = ada_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsadaDTC.fit(X_train,y_train)\n\nada_best = gsadaDTC.best_estimator_\n\ngsadaDTC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27272d022a16b33eca12f1cce271d846144a8474"},"cell_type":"code","source":"### SVC classifier\nfrom sklearn.svm import SVC\n\nSVMC = SVC(probability=True)\nsvc_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [1, 10, 50, 100,200,300, 1000]}\n\ngsSVMC = GridSearchCV(SVMC,param_grid = svc_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsSVMC.fit(X_train,y_train)\n\nSVMC_best = gsSVMC.best_estimator_\n\n# Best score\ngsSVMC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"916534bd08e357d299f01e315eaa5544583a7747"},"cell_type":"code","source":"# Gradient boosting tunning\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nGBC = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [n for n in range(10, 60, 10)],\n              'learning_rate': [0.1, 0.05, 0.01],\n              'max_depth':  [n for n in range(9, 14)],  \n              'min_samples_leaf': [n for n in range(2, 5)],\n              'max_features': [0.3, 0.1] \n              }\n\ngsGBC = GridSearchCV(GBC,param_grid = gb_param_grid, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6b8261225a0a33282a276d3df629f09c7727debb"},"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\n\nvotingC = VotingClassifier(estimators=[('rfc', RFC_best), ('extc', ExtC_best),('svm',SVMC_best),\n('gbc',GBC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7a9fcdfca3375ab132d86418d0a00dd5fe648924"},"cell_type":"code","source":"test_Survived = pd.Series(votingC.predict(test), name=\"Survived\")\n\nSubmission = pd.concat([IDtest,test_Survived],axis=1)\nSubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33dd53ddae789e2cdada5cd963bf135066e1a1cc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"997ba4005802d72effffa25606413186feec43a3"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}