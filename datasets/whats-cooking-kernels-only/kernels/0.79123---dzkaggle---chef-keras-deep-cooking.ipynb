{"cells":[{"metadata":{"trusted":true,"collapsed":true,"_uuid":"85bddbddba73bba482f0b75ce77888a1a4774ace"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"##### EXPLORE #########==================\n# data exploring and basic libraries\nimport random\nimport re\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nfrom collections import deque as dq\n\n# NLP preprocessing\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom nltk import word_tokenize as TK\nfrom nltk import pos_tag\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n##### MODELING ######===================\n# from time import time\n# train test split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder as LE\n\n# deep learning\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, PReLU\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\n\n# Pretty display for notebooks\nfrom IPython.display import display # Allows the use of display() for DataFrames\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dfb2ebc3b61f38d770827538f80316d6f55c62b4"},"cell_type":"code","source":"# load the data - test data\nrawdf_te = pd.read_json(path_or_buf='../input/test.json')\n# load the data - train data\nrawdf_tr = pd.read_json(path_or_buf='../input/train.json')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2cd822f780f6d6636c728270239864cf44cf252d"},"cell_type":"code","source":"# cuisine distribution\nsns.countplot(y='cuisine', data=rawdf_tr, palette ='Set3')\n\n# number of recipes for each cuisines\nprint('Weight\\t Recipe\\t Cuisine\\n')\nfor _ in (Counter(rawdf_tr['cuisine']).most_common()):print(round(_[1]/rawdf_tr.cuisine.count()*100, 2),'%\\t',_[1],'\\t', _[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f35ebb600cb9548835afc78899a9e427489b739"},"cell_type":"code","source":"# change id column type to string\nrawdf_tr = rawdf_tr.set_index('id')\nrawdf_te = rawdf_te.set_index('id')\n\n# Total number of recipes\nprint('Total of %d recipes\\n'% len(rawdf_tr))\n\n# total number of UNIQUE cuisines\nprint('Total of %d types of cuisines including %s\\n' % \\\n      (len(rawdf_tr['cuisine'].unique()), rawdf_tr['cuisine'].unique().tolist()))\n                                          \n# UNIQUE # ingredients set - ingredients_set()\n# training ingredient list\ningredients_list_tr = []\nfor _ in rawdf_tr['ingredients']:\n    ingredients_list_tr.append(_)\n# ingredients set - ingredients_set()\ningredients_set_tr = set()\nfor a in range(len(ingredients_list_tr)):\n    for _ in range(len(ingredients_list_tr[a])):\n        ingredients_set_tr.add(ingredients_list_tr[a][_])\nprint(\"Total of %d unique ingredients\\n\" % len(ingredients_set_tr))\n\n# total ingredients list (with repition) occurred in the train data\ntotal_ingredients_list_tr = []\nfor i in range(len(ingredients_list_tr)):\n    for j in range(len(ingredients_list_tr[i])):\n        total_ingredients_list_tr.append(ingredients_list_tr[i][j])\nprint(\"Most common ingredients used:\\n\")\nfor _ in range(len(Counter(total_ingredients_list_tr).most_common(11))):\n    print(Counter(total_ingredients_list_tr).most_common(11)[_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"57e02b453cf2bcc24102f09b27656828237a6d06"},"cell_type":"code","source":"# copy the series from the dataframe\ningredients_tr = rawdf_tr['ingredients']\n# do the test.json while at it\ningredients_te = rawdf_te['ingredients']\n\n# substitute the matched pattern\ndef sub_match(pattern, sub_pattern, ingredients):\n    for i in ingredients.index.values:\n        for j in range(len(ingredients[i])):\n            ingredients[i][j] = re.sub(pattern, sub_pattern, ingredients[i][j].strip())\n            ingredients[i][j] = ingredients[i][j].strip()\n    re.purge()\n    return ingredients\n\ndef regex_sub_match(series):\n    # remove all units\n    p0 = re.compile(r'\\s*(oz|ounc|ounce|pound|lb|inch|inches|kg|to)\\s*[^a-z]')\n    series = sub_match(p0, ' ', series)\n    # remove all digits\n    p1 = re.compile(r'\\d+')\n    series = sub_match(p1, ' ', series)\n    # remove all the non-letter characters\n    p2 = re.compile('[^\\w]')\n    series = sub_match(p2, ' ', series)\n    return series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c77dbfd0b2ff4b7e5cd797fe4e2a94a7932b2c3"},"cell_type":"code","source":"# regex train data\ningredients_tr = regex_sub_match(ingredients_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"0a8b552ed1768d8b045d9517199761f21301613c"},"cell_type":"code","source":"# declare instance from WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\n# remove all the words that are not nouns -- keep the essential ingredients\ndef lemma(series):\n    for i in series.index.values:\n        for j in range(len(series[i])):\n            # get rid of all extra spaces\n            series[i][j] = series[i][j].strip()\n            # Tokenize a string to split off punctuation other than periods\n            token = TK(series[i][j])\n            # set all the plural nouns into singular nouns\n            for k in range(len(token)):\n                token[k] = lemmatizer.lemmatize(token[k])\n            token = ' '.join(token)\n            # write them back\n            series[i][j] = token\n    return series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dd4a84519e050991010b1f7e05cf6ae14232a47c"},"cell_type":"code","source":"# lemmatize the train data\ningredients_tr = lemma(ingredients_tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"bb3259388d2d7dc128dc06281c66592f56c06924"},"cell_type":"code","source":"# copy back to the dataframe\nrawdf_tr['ingredients_lemma'] = ingredients_tr\nrawdf_tr['ingredients_lemma_string'] = [' '.join(_).strip() for _ in rawdf_tr['ingredients_lemma']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a5de65a674b2f0630b8f787fae92b6cc2685ff0"},"cell_type":"code","source":"# basically train_test_split customized to input cuisine name, outputs are 2 lists of indicies for train and test for the cuisine\ndef tt_split(cuisine):\n    cuisine_population = rawdf_tr.loc[(rawdf_tr['cuisine'] == cuisine)].index.values\n    train, test = train_test_split(cuisine_population, test_size=0.15, random_state=0)\n    train = train.tolist()\n    test = test.tolist()\n    return train, test\n\ncuisine_list = rawdf_tr['cuisine'].unique().tolist()\n# split the training data into 85-15\nix_train = [] # 85% for training (and validation)\nix_test = [] # 15% for hold-out test\nfor _ in cuisine_list:\n    temp_train, temp_test = tt_split(_)\n    ix_train += temp_train\n    ix_test += temp_test\n\n# DataFrame for training and validation\ntraindf = rawdf_tr[['cuisine', 'ingredients_lemma_string']].loc[ix_train].reset_index(drop=True)\nprint(traindf.shape)\ntestdf = rawdf_tr[['cuisine', 'ingredients_lemma_string']].loc[ix_test].reset_index(drop=True)\nprint(testdf.shape)\n    \n# 85% for training and validation ===================\n# X_train\nX_train_ls = traindf['ingredients_lemma_string']\nvectorizertr = TfidfVectorizer(stop_words='english', analyzer=\"word\", max_df=0.65, min_df=2, binary=True)\nX_train = vectorizertr.fit_transform(X_train_ls)\n\n# y_train\ny_train = traindf['cuisine']\n# for xgboost the labels need to be labeled with encoder\nle = LE()\ny_train_ec = le.fit_transform(y_train)\n# for deep learning\ny_train_1h = pd.get_dummies(y_train_ec)\n\n# save the 15% data for hold-out test ===============\n# X_pred\nX_pred_ls = testdf['ingredients_lemma_string']\nvectorizerts = TfidfVectorizer(stop_words='english')\nX_pred = vectorizertr.transform(X_pred_ls)\n\n# y_true\ny_true = testdf['cuisine']\ny_true_ec = le.fit_transform(y_true)\n# for deep learning\ny_true_1h = pd.get_dummies(y_true_ec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5190b0a4a35875c5609cbf08a024eb0408a5aab"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(2161, input_shape=(2161,), activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024, activation='softsign'))\nmodel.add(Dropout(0.58))\nmodel.add(Dense(256, activation='softsign'))\nmodel.add(Dropout(0.67))\nmodel.add(Dense(20, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nepochs = 20\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=1)\n\nmodel.fit(X_train,y_train_1h,\n          batch_size=30,\n          epochs=epochs,\n          verbose=2,\n          callbacks=[early_stopping],\n          validation_data=(X_pred, y_true_1h),\n          shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"636dcee0e08ba8b6802d734a91e388d67e697c03"},"cell_type":"code","source":"# regex test.json data\ningredients_te = regex_sub_match(ingredients_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"4c64d25d773b2d48c67634a9be252d9178e6c6d7"},"cell_type":"code","source":"# lemmatize test.json\ningredients_te = lemma(ingredients_te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"14b509026e20526e7e396dfc97556bbca19f5c85"},"cell_type":"code","source":"# do the same for the test.json dataset\nrawdf_te['ingredients_lemma'] = ingredients_te\nrawdf_te['ingredients_lemma_string'] = [' '.join(_).strip() for _ in rawdf_te['ingredients_lemma']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9555622de72410dcc116707bb7759c8cfad1ae32"},"cell_type":"code","source":"testdf = rawdf_te[['ingredients_lemma_string']]\nprint(testdf.shape)\ntestdf.head(n=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"6256f7b2cff34064f6185d64e5f63a957ba2884f"},"cell_type":"code","source":"# predicting =================\n# X_pred\nX_pred_ls = testdf['ingredients_lemma_string']\nvectorizerts = TfidfVectorizer(stop_words='english')\nX_pred = vectorizertr.transform(X_pred_ls)\n\n# y_true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d9e3a037d36e8f741bc028bfb575b8462c81dd95"},"cell_type":"code","source":"y_pred_nn = le.inverse_transform(model.predict_classes(X_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"19b54dbc44a7d702cff430afdd85dd2efb858688"},"cell_type":"code","source":"testdf['cuisine'] = y_pred_nn\nd = pd.DataFrame(data=testdf['cuisine'], index=testdf.index).sort_index().reset_index().to_csv('submission_nn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f0a62320c6076869b427f403a3082cac7324b172"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}