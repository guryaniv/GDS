{"nbformat_minor": 1, "nbformat": 4, "cells": [{"source": ["This code is inspirated by https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043"], "cell_type": "markdown", "metadata": {"_cell_guid": "c8523520-a13c-4067-8aad-456d4a8797ea", "_uuid": "6f1e3cb42fc60cca3e663c8796ca04b1a6f806e2"}}, {"outputs": [], "source": ["from keras import backend as K\n", "from keras.engine.topology import Layer\n", "from keras import initializers, regularizers, constraints\n", "\n", "\n", "class Attention(Layer):\n", "    def __init__(self, step_dim,\n", "                 W_regularizer=None, b_regularizer=None,\n", "                 W_constraint=None, b_constraint=None,\n", "                 bias=True, **kwargs):\n", "        self.supports_masking = True\n", "        self.init = initializers.get('glorot_uniform')\n", "\n", "        self.W_regularizer = regularizers.get(W_regularizer)\n", "        self.b_regularizer = regularizers.get(b_regularizer)\n", "\n", "        self.W_constraint = constraints.get(W_constraint)\n", "        self.b_constraint = constraints.get(b_constraint)\n", "\n", "        self.bias = bias\n", "        self.step_dim = step_dim\n", "        self.features_dim = 0\n", "        super(Attention, self).__init__(**kwargs)\n", "\n", "    def build(self, input_shape):\n", "        assert len(input_shape) == 3\n", "\n", "        self.W = self.add_weight((input_shape[-1],),\n", "                                 initializer=self.init,\n", "                                 name='{}_W'.format(self.name),\n", "                                 regularizer=self.W_regularizer,\n", "                                 constraint=self.W_constraint)\n", "        self.features_dim = input_shape[-1]\n", "\n", "        if self.bias:\n", "            self.b = self.add_weight((input_shape[1],),\n", "                                     initializer='zero',\n", "                                     name='{}_b'.format(self.name),\n", "                                     regularizer=self.b_regularizer,\n", "                                     constraint=self.b_constraint)\n", "        else:\n", "            self.b = None\n", "\n", "        self.built = True\n", "\n", "    def compute_mask(self, input, input_mask=None):\n", "        return None\n", "\n", "    def call(self, x, mask=None):\n", "        features_dim = self.features_dim\n", "        step_dim = self.step_dim\n", "\n", "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n", "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n", "\n", "        if self.bias:\n", "            eij += self.b\n", "\n", "        eij = K.tanh(eij)\n", "\n", "        a = K.exp(eij)\n", "\n", "        if mask is not None:\n", "            a *= K.cast(mask, K.floatx())\n", "\n", "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n", "\n", "        a = K.expand_dims(a)\n", "        weighted_input = x * a\n", "        return K.sum(weighted_input, axis=1)\n", "\n", "    def compute_output_shape(self, input_shape):\n", "        return input_shape[0],  self.features_dim"], "cell_type": "code", "metadata": {"_cell_guid": "c98be731-6349-4ba6-af09-775c066316e5", "_uuid": "2010428cdc03cc10befe380967be2b2bf96ffc13", "collapsed": true}, "execution_count": null}, {"outputs": [], "source": ["from keras.models import Model\n", "from keras.layers import Dense, Embedding, Input\n", "from keras.layers import LSTM, Bidirectional, Dropout\n", "\n", "\n", "def BidLstm(maxlen, max_features, embed_size, embedding_matrix):\n", "    inp = Input(shape=(maxlen, ))\n", "    x = Embedding(max_features, embed_size, weights=[embedding_matrix],\n", "                  trainable=False)(inp)\n", "    x = Bidirectional(LSTM(300, return_sequences=True, dropout=0.25,\n", "                           recurrent_dropout=0.25))(x)\n", "    x = Attention(maxlen)(x)\n", "    x = Dense(256, activation=\"relu\")(x)\n", "    x = Dropout(0.25)(x)\n", "    x = Dense(6, activation=\"sigmoid\")(x)\n", "    model = Model(inputs=inp, outputs=x)\n", "\n", "    return model"], "cell_type": "code", "metadata": {"_cell_guid": "0673ed33-bdde-4430-b1fd-8bb492d55cd5", "_uuid": "748d0616615fb1a09443480c9d7902b5543233bc", "collapsed": true}, "execution_count": null}, {"outputs": [], "source": ["import pandas as pd\n", "from keras.preprocessing import text, sequence\n", "\n", "\n", "def make_df(train_path, test_path, max_features, maxlen, list_classes):\n", "    train = pd.read_csv(train_path)\n", "    test = pd.read_csv(test_path)\n", "    train = train.sample(frac=1)\n", "\n", "    list_sentences_train = train[\"comment_text\"].fillna(\"unknown\").values\n", "    y = train[list_classes].values\n", "    list_sentences_test = test[\"comment_text\"].fillna(\"unknown\").values\n", "\n", "    tokenizer = text.Tokenizer(num_words=max_features)\n", "    tokenizer.fit_on_texts(list(list_sentences_train))\n", "    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n", "    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n", "    X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n", "    X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n", "\n", "    word_index = tokenizer.word_index\n", "\n", "    return X_t, X_te, y, word_index"], "cell_type": "code", "metadata": {"_cell_guid": "8cbf9b0c-d199-4c42-9597-29e93a2d0e24", "_uuid": "5d0705ae2e556b8de1d42c5ed4e471318c88a467", "collapsed": true}, "execution_count": null}, {"source": ["https://github.com/stanfordnlp/GloVe <br>\n", "download \"glove.840B.300d.txt\" from here."], "cell_type": "markdown", "metadata": {"_cell_guid": "199467f8-4e9a-47d2-be2f-59c615cd7b69", "_uuid": "b683f30bf77a43f73aef800a4abe9536bd785117"}}, {"outputs": [], "source": ["import numpy as np\n", "\n", "\n", "def make_glovevec(glovepath, max_features, embed_size, word_index, veclen=300):\n", "    embeddings_index = {}\n", "    f = open(glovepath)\n", "    for line in f:\n", "        values = line.split()\n", "        word = ' '.join(values[:-300])\n", "        coefs = np.asarray(values[-300:], dtype='float32')\n", "        embeddings_index[word] = coefs.reshape(-1)\n", "    f.close()\n", "\n", "    nb_words = min(max_features, len(word_index))\n", "    embedding_matrix = np.zeros((nb_words, embed_size))\n", "    for word, i in word_index.items():\n", "        if i >= max_features:\n", "            continue\n", "        embedding_vector = embeddings_index.get(word)\n", "        if embedding_vector is not None:\n", "            embedding_matrix[i] = embedding_vector\n", "    return embedding_matrix"], "cell_type": "code", "metadata": {"_cell_guid": "50ff598f-0e95-4757-937d-760b8c150da3", "_uuid": "22d167e291614e2870b9ab6762341a9e25680c37", "collapsed": true}, "execution_count": null}, {"source": ["\"model.fit(xtr, y, batch_size=256, epochs=15, validation_split=0.1, callbacks=[ckpt, early])\" <br>\n", "comment out it because of kernel run time.<br>\n", "if you use local machine, choose its fit code."], "cell_type": "markdown", "metadata": {"_cell_guid": "9f6ba85d-cbe1-4a70-9884-cd89e32d448a", "_uuid": "683e4566b5f8c7979c5372500fd9c3ae8e9f1bcf"}}, {"outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "from keras.callbacks import EarlyStopping, ModelCheckpoint\n", "np.random.seed(7)\n", "\n", "\n", "if __name__ == \"__main__\":\n", "    max_features = 100000\n", "    maxlen = 150\n", "    embed_size = 300\n", "    list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\",\n", "                    \"identity_hate\"]\n", "\n", "    xtr, xte, y, word_index = make_df(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\",\n", "                                      \"../input/jigsaw-toxic-comment-classification-challenge/test.csv\",\n", "                                      max_features, maxlen, list_classes)\n", "    embedding_vector = make_glovevec(\"../input/glove840b300dtxt/glove.840B.300d.txt\",\n", "                                     max_features, embed_size, word_index)\n", "\n", "    model = BidLstm(maxlen, max_features, embed_size, embedding_vector)\n", "    model.compile(loss='binary_crossentropy', optimizer='adam',\n", "                  metrics=['accuracy'])\n", "    file_path = \".model.hdf5\"\n", "    ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n", "                           save_best_only=True, mode='min')\n", "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\n", "    model.fit(xtr, y, batch_size=256, epochs=15, validation_split=0.1, callbacks=[ckpt, early])\n", "    #model.fit(xtr, y, batch_size=256, epochs=1, validation_split=0.1)\n", "\n", "    model.load_weights(file_path)\n", "    y_test = model.predict(xte)\n", "    sample_submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n", "    sample_submission[list_classes] = y_test\n", "    sample_submission.to_csv(\"sub.csv\", index=False)"], "cell_type": "code", "metadata": {"_cell_guid": "7b2d8805-de5e-45ca-a9a4-2980a823a9a7", "_uuid": "38a7f0c80aa40e62138798b3a6a169446a2ed0a3", "collapsed": true}, "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}, "language_info": {"version": "3.6.3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "name": "python"}}}