{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "179c2ccd-823a-9576-f8d4-552dbbde3483"
      },
      "source": [
        "# 07/05/2017 Update\n",
        "\n",
        "This project is based on my [GitHub link][1] and my research is based on  [this paper][2]. \n",
        "\n",
        "Instead of using Echo state network which was used in the Stanford research paper, we are going to use LSTM which is more advanced in training the neural network.\n",
        "\n",
        "More updates will be provided to accommodate the dataset in this Kaggle challenge.  You can simply adjust it to choose your features and window for data.\n",
        "\n",
        "Thank you all!\n",
        "\n",
        "# Import module first\n",
        "\n",
        "\n",
        "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data\n",
        "  [2]: http://cs229.stanford.edu/proj2012/BernalFokPidaparthi-FinancialMarketTimeSeriesPredictionwithRecurrentNeural.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78d1f84f-aed9-747b-154a-f7fe6c7bb8c9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import datetime\n",
        "import math, time\n",
        "import itertools\n",
        "from sklearn import preprocessing\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import load_model\n",
        "import keras\n",
        "import h5py\n",
        "import requests\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "02cc6c64-3161-cf2d-4298-c700c2eee594"
      },
      "source": [
        "# Read data and transform them to pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e10138dc-b1a1-fd9e-64c8-3bbf3b1844a6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\n",
        "df[\"adj close\"] = df.close # Moving close to the last column\n",
        "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5a80f7c5-3ab2-5ac2-1b1e-26f9ecc53c34"
      },
      "source": [
        "# Extract all symbols from the list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8eab994d-dd03-6a73-0bbe-28c68ba58a1c"
      },
      "outputs": [],
      "source": [
        "symbols = list(set(df.symbol))\n",
        "len(symbols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca231b38-093b-2d84-d190-587f737c23d8"
      },
      "outputs": [],
      "source": [
        "symbols[:11] # Example of what is in symbols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "83aeaa46-584e-beef-e8e6-a121a51c43d8"
      },
      "source": [
        "# Extract a particular price for stock in symbols\n",
        "Use GOOG as an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ca7ef19e-e4ce-c4b9-24ab-fd62a279f599"
      },
      "outputs": [],
      "source": [
        "df = df[df.symbol == 'GOOG']\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7f9cab92-a31c-034a-df07-7bc7d6591668"
      },
      "source": [
        "# Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a6052d2e-f656-543b-90cc-9f85b9837bac"
      },
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    df['open'] = min_max_scaler.fit_transform(df.open.values.reshape(-1,1))\n",
        "    df['high'] = min_max_scaler.fit_transform(df.high.values.reshape(-1,1))\n",
        "    df['low'] = min_max_scaler.fit_transform(df.low.values.reshape(-1,1))\n",
        "    df['volume'] = min_max_scaler.fit_transform(df.volume.values.reshape(-1,1))\n",
        "    df['adj close'] = min_max_scaler.fit_transform(df['adj close'].values.reshape(-1,1))\n",
        "    return df\n",
        "df = normalize_data(df)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cda2ae07-6030-3cfc-7786-8557891c0fb7"
      },
      "source": [
        "# Create training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "27bca4c4-cd5f-23a3-2e3f-53433cf2dd96"
      },
      "outputs": [],
      "source": [
        "def load_data(stock, seq_len):\n",
        "    amount_of_features = len(stock.columns) # 5\n",
        "    data = stock.as_matrix() \n",
        "    sequence_length = seq_len + 1 # index starting from 0\n",
        "    result = []\n",
        "    \n",
        "    for index in range(len(data) - sequence_length): # maxmimum date = lastest date - sequence length\n",
        "        result.append(data[index: index + sequence_length]) # index : index + 22days\n",
        "    \n",
        "    result = np.array(result)\n",
        "    row = round(0.9 * result.shape[0]) # 90% split\n",
        "    train = result[:int(row), :] # 90% date, all features \n",
        "    \n",
        "    x_train = train[:, :-1] \n",
        "    y_train = train[:, -1][:,-1]\n",
        "    \n",
        "    x_test = result[int(row):, :-1] \n",
        "    y_test = result[int(row):, -1][:,-1]\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], amount_of_features))\n",
        "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], amount_of_features))  \n",
        "\n",
        "    return [x_train, y_train, x_test, y_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "9cbdcc33-fb39-0ee8-2604-d47c6d2e1b92"
      },
      "source": [
        "# Build the structure of model\n",
        "\n",
        "Based on my hyperparameter testing on [here][1]. I found that these parameters are the most suitable for this task.\n",
        "\n",
        "![dropout = 0.3][2]\n",
        "![epochs = 90][3]\n",
        "![LSTM 256 > LSTM 256 > Relu 32 > Linear 1][4]\n",
        "\n",
        "\n",
        "\n",
        "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data\n",
        "  [2]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/dropout.png?raw=true\n",
        "  [3]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/epochs2.png?raw=true\n",
        "  [4]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/blob/master/neurons.png?raw=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "17b0bf0c-5b76-9052-ecd3-b9f99ba3da94"
      },
      "outputs": [],
      "source": [
        "def build_model(layers):\n",
        "    d = 0.3\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=True))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(LSTM(256, input_shape=(layers[1], layers[0]), return_sequences=False))\n",
        "    model.add(Dropout(d))\n",
        "        \n",
        "    model.add(Dense(32,kernel_initializer=\"uniform\",activation='relu'))        \n",
        "    model.add(Dense(1,kernel_initializer=\"uniform\",activation='linear'))\n",
        "    \n",
        "    # adam = keras.optimizers.Adam(decay=0.2)\n",
        "        \n",
        "    start = time.time()\n",
        "    model.compile(loss='mse',optimizer='adam', metrics=['accuracy'])\n",
        "    print(\"Compilation Time : \", time.time() - start)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ca28b9e0-390f-5368-b043-00d0fc4f1b2a"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c3c292d2-bd7b-6e7f-bbba-39b64860ba20"
      },
      "outputs": [],
      "source": [
        "window = 22\n",
        "X_train, y_train, X_test, y_test = load_data(df, window)\n",
        "print (X_train[0], y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "212f77cd-fdeb-40df-595b-d6de775610f8"
      },
      "outputs": [],
      "source": [
        "model = build_model([5,window,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "886256b4-7578-d3a5-6cf0-ae394e3339ca"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train,y_train,batch_size=512,epochs=90,validation_split=0.1,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "52177800-ffc4-dfd5-c915-46d98f941ca7"
      },
      "outputs": [],
      "source": [
        "# print(X_test[-1])\n",
        "diff=[]\n",
        "ratio=[]\n",
        "p = model.predict(X_test)\n",
        "print (p.shape)\n",
        "# for each data index in test data\n",
        "for u in range(len(y_test)):\n",
        "    # pr = prediction day u\n",
        "    pr = p[u][0]\n",
        "    # (y_test day u / pr) - 1\n",
        "    ratio.append((y_test[u]/pr)-1)\n",
        "    diff.append(abs(y_test[u]- pr))\n",
        "    # print(u, y_test[u], pr, (y_test[u]/pr)-1, abs(y_test[u]- pr))\n",
        "    # Last day prediction\n",
        "    # print(p[-1]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fc1b3c69-d033-e7c1-9ff3-04cefd5d9940"
      },
      "source": [
        "# Denormalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb935328-2516-89a0-e555-bdc5b289dac9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../input/prices-split-adjusted.csv\", index_col = 0)\n",
        "df[\"adj close\"] = df.close # Moving close to the last column\n",
        "df.drop(['close'], 1, inplace=True) # Moving close to the last column\n",
        "df = df[df.symbol == 'GOOG']\n",
        "df.drop(['symbol'],1,inplace=True)\n",
        "\n",
        "# Bug fixed at here, please update the denormalize function to this one\n",
        "def denormalize(df, normalized_value): \n",
        "    df = df['adj close'].values.reshape(-1,1)\n",
        "    normalized_value = normalized_value.reshape(-1,1)\n",
        "    \n",
        "    #return df.shape, p.shape\n",
        "    min_max_scaler = preprocessing.MinMaxScaler()\n",
        "    a = min_max_scaler.fit_transform(df)\n",
        "    new = min_max_scaler.inverse_transform(normalized_value)\n",
        "    return new\n",
        "\n",
        "newp = denormalize(df, p)\n",
        "newy_test = denormalize(df, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2f638a96-8f36-7dc9-4118-f97e3df06705"
      },
      "outputs": [],
      "source": [
        "def model_score(model, X_train, y_train, X_test, y_test):\n",
        "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
        "    print('Train Score: %.5f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
        "\n",
        "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print('Test Score: %.5f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
        "    return trainScore[0], testScore[0]\n",
        "\n",
        "\n",
        "model_score(model, X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "335d3b00-b700-a97f-c2ad-938949618ac7"
      },
      "source": [
        "# Since the Kaggle dataset only contains a few years, the mean square error is not as small as my original model on GitHub.\n",
        "\n",
        "With more than 40 years of data, we will get:\n",
        "\n",
        "Train Score: 0.00006 MSE (0.01 RMSE)\n",
        "\n",
        "Test Score: 0.00029 MSE (0.02 RMSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "99be25aa-e2c3-35fd-64a5-988200295018"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt2\n",
        "\n",
        "plt2.plot(newp,color='red', label='Prediction')\n",
        "plt2.plot(newy_test,color='blue', label='Actual')\n",
        "plt2.legend(loc='best')\n",
        "plt2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a4f7f8a2-0f0a-495c-23c5-adf40fcd8c39"
      },
      "source": [
        "The result on my original model with more than 40 years of data.\n",
        "\n",
        "![Result][1]\n",
        "\n",
        " Train Score: 0.00006 MSE (0.01 RMSE)\n",
        "\n",
        "Test Score: 0.00029 MSE (0.02 RMSE)\n",
        "\n",
        "  [1]: https://github.com/BenjiKCF/Neural-Network-with-Financial-Time-Series-Data/raw/master/result2.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "485cfea1-9204-92b6-3cc3-2c98f8f3138d"
      },
      "source": [
        "# Thank you all for reading\n",
        " If you have any question or concern, please leave a comment. Otherwise, see you next time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a20d18af-b200-167b-8498-1e4450ac0cd6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e2ff8e71-c6c2-8be6-3f09-ccd7ce6060c1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a7a89691-1dbc-8eca-c83f-8d791f101aff"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fb075e10-f271-b6df-4be0-214ae0092fb7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bbce8a2-3ef4-ac9a-6fa0-bec57c86a64b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b5eb2379-45c6-54e9-252d-5cd7ea150b9f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "73092acc-eb54-aeb8-6616-8b1f16b0569d",
        "collapsed": true
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9b09a45c-0595-bc94-2ca6-d6930181b109"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "16fb7e45-13e5-7fd6-dd63-2b18f0fdac30"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce0ba2d6-3f74-c2da-3363-d46d38fcdc77"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "6e18acc0-de77-7a74-a857-bedf2c19d9fe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "14d5f557-3767-7a6e-1992-d8a9ff78ee87"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c9bf36cd-1c14-e608-103d-05ec02f6f68f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "bac5d910-ca0d-0e21-4f88-a8c9365dfa9b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}