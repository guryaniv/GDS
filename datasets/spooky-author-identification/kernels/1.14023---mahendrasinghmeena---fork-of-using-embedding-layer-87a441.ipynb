{"cells": [{"source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "# For example, here's several helpful packages to load in \n", "\n", "import numpy as np # linear algebra\n", "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."], "outputs": [], "metadata": {"_uuid": "f13c617f9d6752189e26b41dc60aeb38ea61ddb6", "_cell_guid": "33dcffc7-63e8-4f35-bd69-e9e9f2fffa36"}, "execution_count": null, "cell_type": "code"}, {"source": ["df = pd.read_csv('../input/train.csv')"], "outputs": [], "metadata": {"_uuid": "6e61e47927ad7ad937c197bc1f1cd4a91432f89d", "_cell_guid": "6c3b934d-ab00-453d-9a1f-0ab845a1e0a1", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["df"], "outputs": [], "metadata": {"_uuid": "8e8cf652ed253c0d0eecf487d8593819e3e780e2", "_cell_guid": "0b2fc296-c613-4b6c-a006-70f003e38e5b"}, "execution_count": null, "cell_type": "code"}, {"source": ["df['text'] = [x.replace(',', ' , ') for x in df['text']]\n", "df['text'] = [x.replace(\"'\", \" ' \") for x in df['text']]\n", "df['text'] = [x.replace(\".\", \" . \") for x in df['text']]\n", "df"], "outputs": [], "metadata": {"_uuid": "c029e3a9b23d8d3e5b509f05dbe174b357913828", "_cell_guid": "a3eee5b7-23a5-4f21-8fbb-898b51ade547"}, "execution_count": null, "cell_type": "code"}, {"source": ["import gensim\n", "sentences = [x.split() for x in df['text']]\n", "model_w2v = gensim.models.Word2Vec(sentences, min_count=1)"], "outputs": [], "metadata": {"_uuid": "046cfa8a4b9a7bdc43c5b385395a80810c0e6708", "_cell_guid": "af9c9f2e-e2fb-4812-9188-a02bdc0645aa", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["#sentences[:3]\n", "print(model_w2v.wv.most_similar(positive=['heart']))\n", "print(len(model_w2v.wv['heart']))"], "outputs": [], "metadata": {"_uuid": "892e6ee2eb426f2716ef569999d99c43211089d5", "_cell_guid": "87bff86b-d014-4e86-83e5-021b64b487b4"}, "execution_count": null, "cell_type": "code"}, {"source": ["df['words'] = [x.split() for x in df['text']]\n", "w2v = []\n", "zerovec = 100*[0]\n", "max_length = 256\n", "\n", "for x in df['words']:\n", "    vec = []\n", "    #print(len(x))\n", "    for w in x[:max_length]:\n", "        vec.extend(model_w2v.wv[w])\n", "    #print(len(vec))\n", "    remaining = max_length*100 - len(vec)\n", "    if remaining > 0 :\n", "        padding = remaining*[0]\n", "        vec.extend(padding)\n", "        w2v.append(vec)\n", "    elif remaining > 0 :\n", "        w2v.append(vec[:max_length])\n", "    else :\n", "        w2v.append(vec)"], "outputs": [], "metadata": {"_uuid": "27544ba90a6ff661d63c1543b1663f0432ef3661", "_cell_guid": "6b99a9a8-e329-45cf-b25d-7db4423ec93b", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["print(len(w2v[0]))"], "outputs": [], "metadata": {"_uuid": "559b5d0286d82cd9a8133c5e5d8084283ac1cf6d", "_cell_guid": "1b9b84b3-2b11-4742-8214-a3b175255f2e"}, "execution_count": null, "cell_type": "code"}, {"source": ["from keras.preprocessing.text import one_hot\n", "from keras.preprocessing.sequence import pad_sequences\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from keras.layers import Flatten\n", "from keras.layers.embeddings import Embedding\n", "#vocab_size = 500\n", "#df['encoded_text'] = [one_hot(x, vocab_size) for x in df['text']]\n", "print(len(w2v))\n", "print(len(w2v[0]))"], "outputs": [], "metadata": {"_uuid": "0414a755f74e61a538524a0cd4238c00789bcbe5", "_cell_guid": "4a36167d-2637-4d94-91a4-fb57dc14d10d"}, "execution_count": null, "cell_type": "code"}, {"source": ["# pad documents to a max length of 4 words\n", "#max_length = 256000\n", "#padded_text = pad_sequences(w2v, maxlen=max_length, padding='post')\n", "class PaddedText2Vec(object):\n", "    def __init__(self, t2v, maxlen):\n", "        self.t2v = t2v\n", "        self.maxlen = maxlen\n", " \n", "    def __iter__(self):\n", "        for v in self.t2v:\n", "            remaining = self.maxlen - len(v)\n", "            if remaining > 0 :\n", "                padding = remaining*[0]\n", "                v.extend(padding)\n", "                yield v\n", "            elif remaining > 0 :\n", "                yield v[:self.maxlen]\n", "            else :\n", "                yield v"], "outputs": [], "metadata": {"_uuid": "6521abffd5ec504005c0bc6ff523ccc572fa1f71", "_cell_guid": "17b78d45-8f29-4924-b723-586864069100", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["#paddedt2v = PaddedText2Vec(w2v, 256000)"], "outputs": [], "metadata": {"_uuid": "651e1cf9e8e5f05954296edbb9cd0966db86944f", "_cell_guid": "bfbb1a6e-082a-4c3d-bf1e-8cbef0e734b2", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["#for x in paddedt2v:\n", "#    print(len(x))\n", "#    break"], "outputs": [], "metadata": {"_uuid": "d04c59db44620a0615f3c35c5b71bad02ca3a5da", "_cell_guid": "a463b4d6-cd4e-4e7a-9da6-f9814b78a37d", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["from keras import regularizers, optimizers\n", "from keras.layers import BatchNormalization\n", "# define the model\n", "max_length = 256\n", "model = Sequential()\n", "model.add(Dense(150, input_shape=(max_length*100,)))\n", "#model.add(Embedding(vocab_size, 100, input_length=max_length))\n", "#model.add(Flatten())\n", "#model.add(BatchNormalization())\n", "model.add(Dense(150, activation='elu', kernel_regularizer=regularizers.l2(0.01)))\n", "#model.add(Dense(200, activation='elu', kernel_regularizer=regularizers.l2(0.01)))\n", "model.add(Dense(3, activation='softmax', kernel_regularizer=regularizers.l2(0.01)))\n", "# compile the model\n", "sgd = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n", "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n", "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n", "# summarize the model\n", "print(model.summary())"], "outputs": [], "metadata": {"_uuid": "972d91a674d31a4d15fa1e3778cb71be4af38eb4", "_cell_guid": "c6df8d84-13d3-47a2-8003-85eb688c52ea"}, "execution_count": null, "cell_type": "code"}, {"source": ["import keras\n", "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n", "import keras.backend as K\n", "from keras.callbacks import EarlyStopping\n", "from keras.models import Sequential\n", "\n", "from keras.preprocessing.sequence import pad_sequences\n", "from keras.preprocessing.text import Tokenizer\n", "from keras.utils import to_categorical\n", "from sklearn.model_selection import train_test_split\n", "a2c = {'EAP':0, 'HPL':1, 'MWS':2}\n", "labels = to_categorical([a2c[x] for x in df['author']])"], "outputs": [], "metadata": {"_uuid": "deaed9e968379b49282625458591146b1d6176a3", "_cell_guid": "728695be-ba9e-490e-97d2-9c2d64c9a806", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["labels[:10]"], "outputs": [], "metadata": {"_uuid": "f20e40430201235dc0b195ed3b25fc2c505b6b04", "_cell_guid": "3b1ee2ae-5401-4e26-bf74-efb229d453c0"}, "execution_count": null, "cell_type": "code"}, {"source": ["# fit the model\n", "model.fit(w2v, labels, epochs=20, verbose=1, batch_size=128, validation_split=0.15)"], "outputs": [], "metadata": {"_kg_hide-input": true, "_uuid": "670d94eaeca058a26383d653f6fe7ada24f9eb40", "_cell_guid": "4ba652c5-ce98-4535-bebf-5bd0dd33ea4f", "scrolled": false, "_kg_hide-output": false}, "execution_count": null, "cell_type": "code"}, {"source": ["df_test = pd.read_csv('../input/test.csv')\n", "df_test['words'] = [x.split() for x in df_test['text']]\n", "w2v_test = []\n", "zerovec = 100*[0]\n", "max_length = 256\n", "\n", "for x in df_test['words']:\n", "    vec = []\n", "    #print(len(x))\n", "    for w in x[:max_length]:\n", "        try:\n", "            vec.extend(model_w2v.wv[w])\n", "        except:\n", "            continue\n", "    #print(len(vec))\n", "    remaining = max_length*100 - len(vec)\n", "    if remaining > 0 :\n", "        padding = remaining*[0]\n", "        vec.extend(padding)\n", "        w2v_test.append(vec)\n", "    elif remaining > 0 :\n", "        w2v_test.append(vec[:max_length])\n", "    else :\n", "        w2v_test.append(vec)"], "outputs": [], "metadata": {"_uuid": "b1571693779c19b9ceb54cf8d654a8ca707bdf9a", "_cell_guid": "fce25926-1f09-49ed-8047-0963c491886f"}, "execution_count": null, "cell_type": "code"}, {"source": ["y_pred = model.predict_proba(w2v_test)\n", "\n", "result = pd.read_csv('../input/sample_submission.csv')\n", "for a, i in a2c.items():\n", "    result[a] = y_pred[:, i]"], "outputs": [], "metadata": {}, "execution_count": null, "cell_type": "code"}, {"source": ["result.to_csv('out.csv', index=False)"], "outputs": [], "metadata": {"_uuid": "10b1b4545f3c425aa06448fc5b88aacc9a1b0cfa", "_cell_guid": "f510c850-605b-42f1-b0bb-11fce906256b", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": ["print(one_hot('man', 2))\n", "print(one_hot('woman', 2))\n"], "outputs": [], "metadata": {"_uuid": "7850e99286971e6986bbfd8fe1aadd33b6af6e59", "_cell_guid": "edf980a1-c793-4b77-8090-30044322d25e", "collapsed": true}, "execution_count": null, "cell_type": "code"}, {"source": [], "outputs": [], "metadata": {"_uuid": "ca882d3fca9b817de673c99040b1a50a098e27b2", "_cell_guid": "b4d10c37-3717-49b0-9366-d79dba40e5f7", "collapsed": true}, "execution_count": null, "cell_type": "code"}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "version": "3.6.3", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3"}}, "nbformat_minor": 1}