{"metadata": {"_is_fork": false, "kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "_change_revision": 0, "language_info": {"file_extension": ".py", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "name": "python", "version": "3.6.1", "codemirror_mode": {"name": "ipython", "version": 3}, "mimetype": "text/x-python"}}, "nbformat": 4, "cells": [{"metadata": {"_uuid": "90fe95a7dd670f18d2c1452700e94a9300bed52b", "_cell_guid": "a239913a-b27f-15e7-8911-53b62bf41c4e"}, "cell_type": "markdown", "source": ["# Techniques to deal with imbalanced data\n", "\n", "Imbalance in data is real world datasets is more a norm than an exception. Blinding application and optimization of learning algorithms on imbalance datasets can and will lead to semanctically incorrect models. Further traditional metric of model performance evaluation - accuracy often provides false indication of model correctness. In this kernel, we will highlight main techniques to dealing with imbalance. In the context of credit fraud dataset, we will explore efficacy of these tehcniques. \n", "\n", "NOTE:  Thanks to joparga3 (https://www.kaggle.com/joparga3/in-depth-skewed-data-classif-93-recall-acc-now) for the inspiration. Thanks to scikit for providing all the tools needed to tackle imbalance (http://contrib.scikit-learn.org/imbalanced-learn/stable/user_guide.html)\n", "\n", "NOTE: Kernel runtime is quite high (comment out hyperparam tuning to speedup)\n", "\n", "## Pre-processing techniques\n", "#### Sampling techniques\n", "These techniques are part of pre-processing stage of ML pipelines prior to feeding data to training stage.\n", "1. Undersampling\n", "    * Random undersampling\n", "    * ClusterCentroids\n", "    * NearMiss\n", "2. Oversampling\n", "    * Random oversampling: generates new samples by random resampling with replacement of under represented class\n", "    * Synthetic Minority Oversampling (SMOTE)\n", "3. Combined over and under sampling\n", "    * SMOTEENN\n", "    * SMOTETomek\n", "\n", "## Training techniques\n", "Number of learning models themselves do provide some built in support to deal with imbalance data.   \n", "1.  Class weighting\n", "2. Sample weighting"]}, {"metadata": {"_uuid": "bcfe1acfae17631af8dada9ff79aceb5b933252e", "_cell_guid": "d5bcecc5-72ca-4626-b846-6ce419dfa611"}, "cell_type": "markdown", "source": ["## Setup imports"]}, {"metadata": {"_uuid": "23192adcddaa463eed512167e0124ffa724c9870", "_cell_guid": "029ecde6-086d-7a8e-de44-363a7a23dbd8", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "\n", "%matplotlib inline\n", "\n", "from sklearn.metrics import recall_score,accuracy_score,confusion_matrix, f1_score, precision_score, auc,roc_auc_score,roc_curve, precision_recall_curve\n", "from imblearn.over_sampling import SMOTE, RandomOverSampler\n", "from imblearn.under_sampling import ClusterCentroids,NearMiss, RandomUnderSampler\n", "from imblearn.combine import SMOTEENN,SMOTETomek\n", "from imblearn.ensemble import BalanceCascade\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.cross_validation import KFold, cross_val_score\n", "from sklearn.model_selection import GridSearchCV\n", "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report \n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n"], "outputs": []}, {"metadata": {"_uuid": "61cfee7253ca5159f134586f067389af13cf338a", "_cell_guid": "b4de5f93-d467-ad7d-4597-03d5f3e89f86"}, "cell_type": "markdown", "source": ["## Load the dataset"]}, {"metadata": {"_uuid": "7135760a61a560d618292ca58f806b991c474db0", "_cell_guid": "7e5ca1e3-3597-19d2-b4be-dffd335df630", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["data = pd.read_csv(\"../input/creditcard.csv\")\n", "data.head()"], "outputs": []}, {"metadata": {"_uuid": "e6d24203dacd5cb086747f1b987778ce4b16cc98", "_cell_guid": "f370d239-e8dc-4905-a1c1-d1186acce5fe"}, "cell_type": "markdown", "source": ["## Check magnitude of imbalance"]}, {"metadata": {"_uuid": "b049b4da5adfb6680772ad5ae4e21ca8aa3c92d3", "_cell_guid": "3f6e6674-12e9-6983-5788-5755f80c7ec2", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["count_classes = pd.value_counts(data['Class'], sort = True).sort_index()\n", "print(count_classes)"], "outputs": []}, {"metadata": {"_uuid": "208237c0d35d8fcee2f63fd694a51f452e501e14", "_cell_guid": "3fd30a6f-c0ad-5ece-943c-651cdf14d0d6", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["data['Amount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1, 1))\n", "data = data.drop(['Time'],axis=1)\n", "data.head()"], "outputs": []}, {"metadata": {"_uuid": "5fd1679e2cbacdd7c2c6a8f7d67057171b8745e6", "_cell_guid": "c1d874fa-5ea5-edbb-726c-ae98c84e6120", "collapsed": true}, "cell_type": "markdown", "source": ["## Split into training and test datasets"]}, {"metadata": {"_uuid": "c2bcbfab2ec81ccf768e307e7bfdc6e7b1f320cc", "_cell_guid": "dfe1f388-62ed-4321-89d2-6b84701d81a3", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["X = data.iloc[:, data.columns != 'Class']\n", "y = data.iloc[:, data.columns == 'Class']\n", "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 0)\n", "print(X_train.shape)\n", "print(X_test.shape)"], "outputs": []}, {"metadata": {"_uuid": "d7c9e32c5298310e215dc901a74a10cfe3e97350", "_cell_guid": "042a1f4a-54ab-416a-8d17-28c5a26ab389"}, "cell_type": "markdown", "source": ["## Helper functions"]}, {"metadata": {"_uuid": "6c20a1edfc1543e58e69172e3bf016d17d84c01a", "_cell_guid": "9c7ec815-da54-993b-ef8d-b41b767cfacf", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["def benchmark(sampling_type,X,y):\n", "    lr = LogisticRegression(penalty = 'l1')\n", "    param_grid = {'C':[0.01,0.1,1,10]}\n", "    gs = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='accuracy', cv=5, verbose=2)\n", "    gs = gs.fit(X.values,y.values.ravel())\n", "    return sampling_type,gs.best_score_,gs.best_params_['C']\n", "\n", "def transform(transformer,X,y):\n", "    print(\"Transforming {}\".format(transformer.__class__.__name__))\n", "    X_resampled,y_resampled = transformer.fit_sample(X.values,y.values.ravel())\n", "    return transformer.__class__.__name__,pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)"], "outputs": []}, {"metadata": {"_uuid": "eaccc5826edbfd10051ae1183c68fd2be74a836c", "_cell_guid": "8e024fe5-746c-4fcd-b6bc-d7f32149c4d4"}, "cell_type": "markdown", "source": ["## Apply transformations to dataset"]}, {"metadata": {"_uuid": "ad63931d551c523d4bfb838b7fd22cec4a72a286", "_cell_guid": "32a2b70c-5eb5-4d8a-9052-2f8ba0b7c973", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["datasets = []\n", "datasets.append((\"base\",X_train,y_train))\n", "datasets.append(transform(SMOTE(n_jobs=-1),X_train,y_train))\n", "datasets.append(transform(RandomOverSampler(),X_train,y_train))\n", "#datasets.append(transform(ClusterCentroids(n_jobs=-1),X_train,y_train))\n", "datasets.append(transform(NearMiss(n_jobs=-1),X_train,y_train))\n", "datasets.append(transform(RandomUnderSampler(),X_train,y_train))\n", "datasets.append(transform(SMOTEENN(),X_train,y_train))\n", "datasets.append(transform(SMOTETomek(),X_train,y_train))\n", "\n", "\n", "\n"], "outputs": []}, {"metadata": {"_uuid": "e6e5bac7ca57103c5420342309492c79d4325cb9", "_cell_guid": "c4077c3c-441d-4733-8c5d-691127a20a89"}, "cell_type": "markdown", "source": ["## Determine best hyperparameters"]}, {"metadata": {"_uuid": "2c80b37137e50a3a85ef4412d7a1d030154eb618", "_cell_guid": "41bc9fa1-610c-4950-8f14-4a3c894fae39", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["benchmark_scores = []\n", "for sample_type,X,y in datasets:\n", "    print('______________________________________________________________')\n", "    print('{}'.format(sample_type))\n", "    benchmark_scores.append(benchmark(sample_type,X,y))\n", "    print('______________________________________________________________')\n", "    "], "outputs": []}, {"metadata": {"_uuid": "85f8719c5fc230a58d60205736ec17c481f7ecf8", "_cell_guid": "97413a88-bdb8-4344-b5da-4e02431d1a34", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["benchmark_scores"], "outputs": []}, {"metadata": {"_uuid": "29c4365e29e38f5cbe15be8c81868e747091c885", "_cell_guid": "00002297-dd4e-4930-b412-6703a0d6710c"}, "cell_type": "markdown", "source": ["## Train/evaluate models for each of tranformed datasets"]}, {"metadata": {"_uuid": "78600885cddef1113336bfb8c1aa95556ec1d9da", "_cell_guid": "89d76d49-7ce5-48bb-970a-a75b6bf3a520", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["scores = []\n", "# train models based on benchmark params\n", "for sampling_type,score,param in benchmark_scores:\n", "    print(\"Training on {}\".format(sampling_type))\n", "    lr = LogisticRegression(penalty = 'l1',C=param)\n", "    for s_type,X,y in datasets:\n", "        if s_type == sampling_type:\n", "            lr.fit(X.values,y.values.ravel())\n", "            pred_test = lr.predict(X_test.values)\n", "            pred_test_probs = lr.predict_proba(X_test.values)\n", "            probs = lr.decision_function(X_test.values)\n", "            fpr, tpr, thresholds = roc_curve(y_test.values.ravel(),pred_test)\n", "            p,r,t = precision_recall_curve(y_test.values.ravel(),probs)\n", "            scores.append((sampling_type,\n", "                           f1_score(y_test.values.ravel(),pred_test),\n", "                           precision_score(y_test.values.ravel(),pred_test),\n", "                           recall_score(y_test.values.ravel(),pred_test),\n", "                           accuracy_score(y_test.values.ravel(),pred_test),\n", "                           auc(fpr, tpr),\n", "                           auc(p,r,reorder=True),\n", "                           confusion_matrix(y_test.values.ravel(),pred_test)))\n", "\n"], "outputs": []}, {"metadata": {"_uuid": "8eee4ecb8ed31c892c84d4f2a529be99d149c671", "_cell_guid": "d4411ef4-7d7d-4f9f-9e2e-10465fe52c3a"}, "cell_type": "markdown", "source": ["## Tabulate results"]}, {"metadata": {"_uuid": "e0ee55583a9e335062bdd012a4be2a979d4b6447", "_cell_guid": "568d6dc0-3756-4ac2-bf18-e759ce083fc8", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["sampling_results = pd.DataFrame(scores,columns=['Sampling Type','f1','precision','recall','accuracy','auc_roc','auc_pr','confusion_matrix'])\n", "sampling_results"], "outputs": []}, {"metadata": {"_uuid": "103bb3d625790ba1358a37f0932dfed30e36072c", "_cell_guid": "f7859663-96a5-4113-8625-77d5d2571d1d"}, "cell_type": "markdown", "source": ["## Train model with weighted class"]}, {"metadata": {"_uuid": "3d744ad57c5f9f64b5ca833b1ab3368a12b7939e", "_cell_guid": "c4c656d7-83d8-4d13-80fb-642d1de9bee1", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["lr = LogisticRegression(penalty = 'l1',class_weight=\"balanced\")\n", "lr.fit(X_train.values,y_train.values.ravel())\n", "scores = []\n", "pred_test = lr.predict(X_test.values)\n", "pred_test_probs = lr.predict_proba(X_test.values)\n", "probs = lr.decision_function(X_test.values)\n", "fpr, tpr, thresholds = roc_curve(y_test.values.ravel(),pred_test)\n", "p,r,t = precision_recall_curve(y_test.values.ravel(),probs)\n", "scores.append((\"weighted_base\",\n", "                           f1_score(y_test.values.ravel(),pred_test),\n", "                           precision_score(y_test.values.ravel(),pred_test),\n", "                           recall_score(y_test.values.ravel(),pred_test),\n", "                           accuracy_score(y_test.values.ravel(),pred_test),\n", "                           auc(fpr, tpr),\n", "                           auc(p,r,reorder=True),\n", "                           confusion_matrix(y_test.values.ravel(),pred_test)))\n", "\n", "scores = pd.DataFrame(scores,columns=['Sampling Type','f1','precision','recall','accuracy','auc_roc','auc_pr','confusion_matrix'])"], "outputs": []}, {"metadata": {"_uuid": "cbe06a12f66f30f0dc5450b8057bc799afa1fe40", "_cell_guid": "f58e4022-9a0b-4c66-bc6d-3b09a8f3bc22", "collapsed": true}, "cell_type": "markdown", "source": ["## Compare alternatives"]}, {"metadata": {"_uuid": "e7183991df1c3d27ac839659e71d02229605c313", "_cell_guid": "b7deb9ed-d719-4f69-b8b0-dfc7a45df416", "collapsed": true}, "execution_count": null, "cell_type": "code", "source": ["results = sampling_results.append(scores)\n", "results"], "outputs": []}, {"metadata": {"_uuid": "ec5ef9f7ddc6de23db7100d0a7a4561932038c35", "_cell_guid": "51afdba9-4a7d-4d4e-828b-695626a44b58"}, "cell_type": "markdown", "source": ["## Interpretation\n", "*  Undersampling leads to high recall but comes at a huge cost to precision (also reducing training time)\n", "*  SMOTE(basic, Tomek,ENN) sampling and RandomOverSampler perform the best considering auc_roc and auc_pr with accpetables levels of false positives\n", "*  Class weighting seems to produce comparable results to sampling techniques (for models that support such weighting)"]}, {"metadata": {"_uuid": "269f91b0004428c7ab3c703cef86dfda11d4caf2", "_cell_guid": "7afdb952-2c7a-47e2-91f3-7b4bed9ef56f", "collapsed": true}, "cell_type": "markdown", "source": ["## Todos\n", "* Add best practicies\n", "\n", "## Extensions"]}], "nbformat_minor": 1}