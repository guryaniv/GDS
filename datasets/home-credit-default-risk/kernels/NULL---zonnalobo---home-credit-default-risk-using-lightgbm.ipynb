{"cells":[{"metadata":{"_uuid":"0cf832f3f5d7af11e13e665197649356cc34652e"},"cell_type":"markdown","source":"# Imported Library\n\nLoad all libraries for prepocessing data."},{"metadata":{"_uuid":"3489e5786305b877487b893e34f0bdef9f9de386","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelBinarizer,LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('Display.max_columns',500)\npd.set_option('Display.max_rows',500)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55f0d2a6958adac10f39b494d52f74c1401a1841"},"cell_type":"markdown","source":"# Imported Dataset\n\nLoad data for classification. In this moment, we just used application_train and application_test data to build the model."},{"metadata":{"_uuid":"313304c89a5a4d065eca13ae8450eab346b1e357","trusted":false},"cell_type":"code","source":"app_train = pd.read_csv('../input/application_train.csv')\napp_test = pd.read_csv('../input/application_test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bd00befae21d57baaeb1e0d2e7a87fd6a7cf3095","trusted":false},"cell_type":"code","source":"app_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7d0a3ab689751ee13d27bff7a83c1d44f1c3907"},"cell_type":"markdown","source":"<hr>"},{"metadata":{"_uuid":"6d925f7c7d0c35e46f10dfbecc5887341e90e4f8"},"cell_type":"markdown","source":"# Null value analysis\n\nIn this stage, we try to handle the missing data in application_train and application_test."},{"metadata":{"_uuid":"b1075367454001fa4d916f02998e797842e3775f","scrolled":true,"trusted":false},"cell_type":"code","source":"app_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9739f34c061f605b7a93347ae4a4a9e8f9e381b","trusted":false},"cell_type":"code","source":"app_train[app_train.isnull().any(axis=1)].shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de005355c78fca0d3b776a6f68305a3b8771c5ec","trusted":false},"cell_type":"code","source":"app_train[~app_train.isnull().any(axis=1)].shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca47da5ebeca4fdabaf1a7dab0b8ea7f04a1a5fe","trusted":false},"cell_type":"code","source":"app_train.select_dtypes(include=object).dtypes","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ecc0281877caae8209391db212b098ad1146c52","trusted":false},"cell_type":"code","source":"app_test.select_dtypes(include=object).isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4019c0791c01a46862be2583a7295fc2991e66d","trusted":false},"cell_type":"code","source":"app_train.select_dtypes(include=object).isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7fcecf9c346bd4f8531c5ed56e3d27cd161aefd"},"cell_type":"markdown","source":"There are 298909 rows contain missing data in application_train and 8602 in application_test."},{"metadata":{"_uuid":"4ffec707c078c24191ffee016fdcbb549b60159e","trusted":false},"cell_type":"code","source":"app_train.NAME_TYPE_SUITE = app_train.NAME_TYPE_SUITE.fillna('Unaccompanied')\napp_test.NAME_TYPE_SUITE = app_test.NAME_TYPE_SUITE.fillna('Unaccompanied')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4a0236e69b9a99dc708be02d3b2abf4cdd71209a","trusted":false},"cell_type":"code","source":"app_train.OCCUPATION_TYPE = app_train.OCCUPATION_TYPE.fillna('Others')\napp_test.OCCUPATION_TYPE = app_test.OCCUPATION_TYPE.fillna('Others')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8a56a893402f6cdab4a14c4cd73baef9c7165aab","trusted":false},"cell_type":"code","source":"app_train.FONDKAPREMONT_MODE = app_train.FONDKAPREMONT_MODE.fillna('not specified')\napp_test.FONDKAPREMONT_MODE = app_test.FONDKAPREMONT_MODE.fillna('not specified')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba3162d4aeff2da7095c3894347c4ba8b4042e53","trusted":false},"cell_type":"code","source":"app_train.HOUSETYPE_MODE = app_train.HOUSETYPE_MODE.fillna('Others')\napp_test.HOUSETYPE_MODE = app_test.HOUSETYPE_MODE.fillna('Others')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e76a27654ded9d1b6ce27e72f969f705006fbe2c","trusted":false},"cell_type":"code","source":"app_train.WALLSMATERIAL_MODE = app_train.WALLSMATERIAL_MODE.fillna('Others')\napp_test.WALLSMATERIAL_MODE = app_test.WALLSMATERIAL_MODE.fillna('Others')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9544c9a9ba561c4d05f2ccdf5f77a1086063414","trusted":false},"cell_type":"code","source":"app_train = app_train.drop(columns=['EMERGENCYSTATE_MODE'])\napp_test = app_test.drop(columns=['EMERGENCYSTATE_MODE'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2575dadf5e56aeb7d8a78cf01886de3e6448d6e9","trusted":false},"cell_type":"code","source":"min_ext_1 = app_train.EXT_SOURCE_1.min()\nmin_ext_2 = app_train.EXT_SOURCE_2.min()\nmin_ext_3 = app_train.EXT_SOURCE_3.min()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1177c7428b957ef4bba337a5a890edd44c49e4ca","scrolled":false,"trusted":false},"cell_type":"code","source":"app_train.EXT_SOURCE_1 = app_train.EXT_SOURCE_1.fillna(min_ext_1)\napp_train.EXT_SOURCE_2 = app_train.EXT_SOURCE_2.fillna(min_ext_2)\napp_train.EXT_SOURCE_3 = app_train.EXT_SOURCE_3.fillna(min_ext_3)\n\napp_test.EXT_SOURCE_1 = app_test.EXT_SOURCE_1.fillna(min_ext_1)\napp_test.EXT_SOURCE_2 = app_test.EXT_SOURCE_2.fillna(min_ext_2)\napp_test.EXT_SOURCE_3 = app_test.EXT_SOURCE_3.fillna(min_ext_3)\n\napp_train = app_train.fillna(0)\napp_test = app_test.fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de252ce8ca78947e7d5b4ba9e5cdb2257b495963","scrolled":true,"trusted":false},"cell_type":"code","source":"print(app_train.isnull().sum().sum())\nprint(app_test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9f05647866488e8ccdb94347b1dff8612c62b11"},"cell_type":"markdown","source":"In this stage, we made some assumptions and filled missing data with the assumptions. For column NAME_TYPE_SUITE, we decided to fill missing data with 'Unaccompanied'; OCCUPATION_TYPE, HOUSE_TYPE, and WALLSMATERIAL_MODE with 'Others'; FONDKAPREMONT_MODE with 'not specified'; EXT_SOURCE with the minimum value of each column; and others with zero."},{"metadata":{"_uuid":"32a34455a94dbe74f37fd442ce9451cde41d67c7"},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"_uuid":"1a947f8c236d723115852586890a795ec872f22b"},"cell_type":"markdown","source":"## Distribution of application_train data"},{"metadata":{"_uuid":"ca69b093f96e225211c367fe687707e2817ff084","trusted":false},"cell_type":"code","source":"x_cat = app_train[app_train.select_dtypes(include=object).columns].columns\nx_num = app_train[app_train.select_dtypes(exclude=object).columns].columns.drop(['SK_ID_CURR','TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7313f6642fae26590ad4dfa072def23bfabe26b1","trusted":false},"cell_type":"code","source":"def plot_hist(x):\n    plt.rcParams[\"figure.figsize\"] = (10,8)\n    ax = sns.countplot(x=x,data=app_train)\n    plt.xlabel(str(x))\n    plt.title('Histogram of '+str(x))\n    plt.xticks(rotation=70)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83be58ca0f660a0900c73dddac56af2d9d4a92a7","trusted":false},"cell_type":"code","source":"plot_hist('TARGET')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efb81fa52d4ba2be7d2f992bd4eb356ef3d21d1a"},"cell_type":"markdown","source":"We can see that, the dataset is imbalanced."},{"metadata":{"_uuid":"d6f0f323b22355c614fbd549c6706d8a526f195c","scrolled":true,"trusted":false},"cell_type":"code","source":"for x in x_cat:\n    plot_hist(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1564dad176b39727daa2b18585c0b099a1e45def","trusted":false},"cell_type":"code","source":"def plot_dist(x):\n    plt.rcParams[\"figure.figsize\"] = (10,8)\n    ax = sns.distplot(app_train[x])\n    plt.xlabel(str(x))\n    plt.title('Distribution of '+str(x))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f719fd99dbb1c4761d3acc5d11b107115f67a91b","scrolled":true,"trusted":false},"cell_type":"code","source":"for x in x_num:\n    plot_dist(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a947f8c236d723115852586890a795ec872f22b"},"cell_type":"markdown","source":"## Distribution of application_test data"},{"metadata":{"_uuid":"7313f6642fae26590ad4dfa072def23bfabe26b1","trusted":false},"cell_type":"code","source":"def plot_hist(x):\n    plt.rcParams[\"figure.figsize\"] = (10,8)\n    ax = sns.countplot(x=x,data=app_test)\n    plt.xlabel(str(x))\n    plt.title('Histogram of '+str(x))\n    plt.xticks(rotation=70)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d6f0f323b22355c614fbd549c6706d8a526f195c","scrolled":true,"trusted":false},"cell_type":"code","source":"for x in x_cat:\n    plot_hist(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1564dad176b39727daa2b18585c0b099a1e45def","trusted":false},"cell_type":"code","source":"def plot_dist(x):\n    plt.rcParams[\"figure.figsize\"] = (10,8)\n    ax = sns.distplot(app_test[x])\n    plt.xlabel(str(x))\n    plt.title('Distribution of '+str(x))\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f719fd99dbb1c4761d3acc5d11b107115f67a91b","scrolled":true,"trusted":false},"cell_type":"code","source":"for x in x_num:\n    plot_dist(x)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5aeac7a2ce0a37008f5c3cad1b871539dab55f1"},"cell_type":"markdown","source":"<hr>"},{"metadata":{"_uuid":"0bd31ab7b7aac56d7295f3e16970b762f6ad3cdd"},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"_uuid":"8becac06a572c4b2d04f19cc15841c4882c8d54c"},"cell_type":"markdown","source":"## Categorical data, numerical data, and target data separation\n\nIn this stage, we separated catagerical data, numerical data, and target data to do different treatment."},{"metadata":{"_uuid":"4812079972c9d1cf370dc601fbe072af3199391c","trusted":false},"cell_type":"code","source":"categorical = app_train[app_train.select_dtypes(include=object).columns]\nx_cat = categorical.columns\ncategorical.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a9ebdf6ba3c135ea041c66951f00c2cb1f3b511b","trusted":false},"cell_type":"code","source":"numerical = app_train[app_train.select_dtypes(exclude=object).columns]\nnumerical = numerical.drop(columns=['SK_ID_CURR','TARGET'])\nx_num = numerical.columns\nnumerical.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dedd89a1f1a4a344f4291f7e2ee4837540d5b5e3","trusted":false},"cell_type":"code","source":"target = app_train.TARGET\ntarget.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19910fdddccc7c4c63f6bb6265f2a47904b7a707"},"cell_type":"markdown","source":"## Numerical data normalization\n\nFor numerical columns, we normalized using MinMaxScaller to remove outlier."},{"metadata":{"_uuid":"1c862ec38ed897425fb74887f294fd681b59ae48","trusted":false},"cell_type":"code","source":"scaller = MinMaxScaler()\napp_train[x_num] = scaller.fit_transform(app_train[x_num])\napp_test[x_num] = scaller.transform(app_test[x_num])\napp_train[x_num].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7368a9ec7237ff42fc18748e78ce6aa66678aab"},"cell_type":"markdown","source":"## Categorical data encoding\n\nFor Categorical data, we converted to numerical using Label Encoder. By this method, all categorical data are sorted by alphabetically."},{"metadata":{"_uuid":"a3c629a376463d96d1e28ed529d6a642f86e3a63","trusted":false},"cell_type":"code","source":"for x in x_cat:\n    lb = LabelEncoder()\n    app_train[x] = lb.fit_transform(app_train[x])\n    app_test[x] = lb.transform(app_test[x])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ce2fed750fe7a1441aeffdf7c41a0ccf665f189","trusted":false},"cell_type":"code","source":"app_train[x_cat].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"92b0c3be45db47e39c0f8e7a053ebf2c7ec2cef8"},"cell_type":"markdown","source":"## Target data preprocessing\n\nWe just make sure the target is binarizer using Label Binarizer method."},{"metadata":{"_uuid":"462e54fb1014e1d75f15df757cc2eb156a95b969","trusted":false},"cell_type":"code","source":"lb = LabelBinarizer()\napp_train['TARGET'] = lb.fit_transform(app_train.TARGET)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef8faa673f9a438a3b6361fbf0f6c9cff082eb03","trusted":false},"cell_type":"code","source":"app_train.TARGET.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6b3cb269b732a1a808b543adea7d858cf533458e"},"cell_type":"markdown","source":"# Fix Data"},{"metadata":{"_uuid":"652132e0044b5dff0c40e10601deeb5d56589ab2","trusted":false},"cell_type":"code","source":"app_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b579455d2f68eb703dd05273f9f9c3467a67bc53","trusted":false},"cell_type":"code","source":"x_call = app_train.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa5c23cd16b9a7b4994ab4f6f1d5ac6bcea94c70","trusted":false},"cell_type":"code","source":"app_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7695bc395978902efdd4a4b0189999f12531fe1"},"cell_type":"markdown","source":"<hr>"},{"metadata":{"_uuid":"f3f3f6f4a7e0faa8bc4f685df49d0a20aadcc687"},"cell_type":"markdown","source":"## Feature correlation analysis\n\nIn this stage, we try to analyze the correlation among features."},{"metadata":{"_uuid":"b2ad023c0dca9f9353816c4b9dbcbc919c8aa461"},"cell_type":"markdown","source":"### 1. Heatmap correlation"},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"a9338f217d88c5eae96cecbdc0e89eaa1cb1f094"},"cell_type":"code","source":"corr = app_train[x_num].corr()\ncmap=sns.diverging_palette(5, 250, as_cmap=True)\n\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"7pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"12pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '12pt')])\n]\n\ncorr.style.background_gradient(cmap, axis=1)\\\n    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n    .set_caption(\"Hover to magify\")\\\n    .set_precision(2)\\\n    .set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f417bf9a508ab571c409e05b5070a1e8bd060558","trusted":false},"cell_type":"code","source":"fig,ax = plt.subplots(figsize=(12,10))\ncorr = app_train[x_call].corr()\nhm = sns.heatmap(corr,ax=ax,vmin=-1,vmax=1,annot=False,cmap='coolwarm',square=True,fmt='.2f',linewidths=.05)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09cd07fd7e400c76fd3a278f2daadc3446ac3432","scrolled":true,"trusted":false},"cell_type":"code","source":"for x in x_call:\n    msg = \"%s : %.3f\" % (x,np.corrcoef(app_train[x],app_train.TARGET)[0,1])\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3821abd41c04b68b94438bd3ae37896ea7ff4794"},"cell_type":"markdown","source":"We can see that, there is no correlation between each features and the target. However, some features have high correlation among them. By this condition, we decided to use tree model rather than Ordinary Least Squared Model."},{"metadata":{"_uuid":"7816f2851e581d674e75120e0b9c9e60c098ca63"},"cell_type":"markdown","source":"<hr>"},{"metadata":{"_uuid":"392009e1e8b69f1fa6c4b8960a8f31695405488f"},"cell_type":"markdown","source":"# Train Test Split\n\nIn this stage, we separate data to be 67% train_df and 33% test_df."},{"metadata":{"_uuid":"c9d9a3a49e91c1a4740c07163217e0354d9873be","trusted":false},"cell_type":"code","source":"train_df, test_df = train_test_split(app_train,test_size=0.33,shuffle=True,stratify=app_train.TARGET,\n                                     random_state=217)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26b6153a76a50e187c279499a550f6ad563a526f"},"cell_type":"markdown","source":"# Choosing Model\n\nIn this stage, we try to build model using several kinds of model. To choose the best model, we using several metrics, those are accuracy_score to see the accuracy, roc_auc_acore, average_precision or PR_AUC, and f1_score. However, we give more attention to roc_auc."},{"metadata":{"_uuid":"e3029b165d2ca5c468d786be4d037acb85abf66f","trusted":false},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold,cross_validate,cross_val_score\nfrom sklearn.metrics import classification_report,confusion_matrix,precision_score,recall_score,log_loss,roc_curve\nfrom sklearn.metrics import accuracy_score,f1_score,roc_auc_score,average_precision_score,brier_score_loss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,ExtraTreesClassifier\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.utils import compute_sample_weight,compute_class_weight\nfrom sklearn.calibration import calibration_curve,CalibratedClassifierCV\nfrom sklearn import model_selection\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d15c7330426c2e24c5af6a34d1b107236d1753d1","trusted":false},"cell_type":"code","source":"x_calls = train_df.columns[2:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"69c3aa4ef9a3d255671274f82ae45efb597ac0a2","trusted":false},"cell_type":"code","source":"scorer = ('accuracy','roc_auc','f1_weighted','average_precision')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"833df695d60d30f24969fe6a91bbf336f5412d44","trusted":false},"cell_type":"code","source":"models = []\nmodels.append(('LR', LogisticRegression(class_weight='balanced')))\nmodels.append(('CART', DecisionTreeClassifier(class_weight='balanced')))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('RFC', RandomForestClassifier(class_weight='balanced')))\nmodels.append(('ETC', ExtraTreesClassifier(class_weight='balanced')))\nmodels.append(('XGBC', XGBClassifier(scale_pos_weight=189399/16633)))\nmodels.append(('GBM', LGBMClassifier(class_weight='balanced')))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"086eac252d85f5d2d9ec6a0b51e840d89f0df6d3","trusted":false},"cell_type":"code","source":"for name, model in models:\n    kfold = StratifiedKFold(n_splits=10, random_state=217, shuffle=True)\n    cv_results = cross_validate(model, train_df[x_calls], train_df.TARGET,cv=kfold, scoring=scorer)\n    cv_results1=cv_results['test_accuracy']\n    cv_results2=cv_results['test_roc_auc']\n    cv_results3=cv_results['test_f1_weighted']\n    cv_results4=cv_results['test_average_precision']\n    msg = \"%s by Accuracy: %f(%f), by ROC_AUC: %f(%f), by F1-score: %f(%f), PR_AUC: %f(%f)\" % (name, np.mean(cv_results1),\n        np.std(cv_results1),np.mean(cv_results2),np.std(cv_results2),np.mean(cv_results3),np.std(cv_results3),\n        np.mean(cv_results4),np.std(cv_results4))\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2a246704a2e0e72a1e8de33e802d7bcef27bac83"},"cell_type":"markdown","source":"By the test above, we choose LightGBM to build the model."},{"metadata":{"_uuid":"c745d179115c358bdfcf3fdba01ff8f539f22479"},"cell_type":"markdown","source":"# Evaluating the best model\n\nBefore evaluating, we used RandomSearchCV to choose the better parameters for the model. However, we don't put the method in this script to handle the long running time."},{"metadata":{"_uuid":"d28cafa40198f12beaa6dbbc93b1d6e1fa9d9e1e","trusted":false},"cell_type":"code","source":"model_gbm = LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n        colsample_bytree=1.0, importance_type='split',\n        learning_rate=0.09275695087706179, max_depth=3669,\n        min_child_samples=60, min_child_weight=0.001, min_data=6,\n        min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=64,\n        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n        silent=True, sub_feature=0.7757070409332384, subsample=1.0,\n        subsample_for_bin=200000, subsample_freq=0)\nmodel_gbm.fit(train_df[x_calls], train_df.TARGET)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"00d940520bd9f3c429c1c0e64cd4456d7ec0efc7","trusted":false},"cell_type":"code","source":"predictions = model_gbm.predict(test_df[x_calls])\nprob = model_gbm.predict_proba(test_df[x_calls])[:,1]\ntest_df['TARGET_hat']=predictions\ntest_df['TARGET_prob']=prob\nY_validation = test_df.TARGET\nprint(\"Accuracy Score: %f\" % accuracy_score(Y_validation, predictions))\nprint(\"ROC_AUC: %f\" % roc_auc_score(Y_validation, prob,average='weighted'))\nprint(\"PR_AUC: %f\" % average_precision_score(Y_validation, prob,average='weighted'))\nprint(\"F1: %f\" % f1_score(Y_validation, predictions,average='weighted'))\nprint(\"Recall: %f\" % recall_score(Y_validation, predictions,average='weighted'))\nprint(\"Precision: %f\" % precision_score(Y_validation, predictions,average='weighted'))\nprint(confusion_matrix(Y_validation, predictions))\nprint(classification_report(Y_validation, predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"693733394b96a35ec599bd0e75185f0f91722c93"},"cell_type":"markdown","source":"By the model, we got 71.83% accuracy score, 75.93% roc_auc, and 78.07% F1_score. The roc_auc curve can be seen below."},{"metadata":{"_uuid":"f19eeb5821845ebceab975b18ad5cb9c3d881014","trusted":false},"cell_type":"code","source":"fpr_rf_lm, tpr_rf_lm, _ = roc_curve(test_df.TARGET, test_df.TARGET_prob)\n\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr_rf_lm, tpr_rf_lm, label='RT + LR')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72356ce30e3316400d14dad4932a20118b805f00"},"cell_type":"markdown","source":"# Calibration to get probability\n\nIn this stage we convert the score of model to probability using CalibrationClassifierCV. There are two functions that can be used to calibrate the model, those are Sigmoid Function and Isotonic function. To choose the best calibration, we used Brier_score_loss and log_loss as metrics. The lower the both score, the better model."},{"metadata":{"_uuid":"1cdb4b0f4ceaad0ced413e570ed5be48d1fe98de","trusted":false},"cell_type":"code","source":"def plot_calibration_curve(est, name, X_train, y_train, X_test, y_test):\n    isotonic = CalibratedClassifierCV(est, cv='prefit', method='isotonic')\n    sigmoid = CalibratedClassifierCV(est, cv='prefit', method='sigmoid')\n    lr = LogisticRegression(C=1., solver='lbfgs',class_weight='balanced')\n    fig = plt.figure(1, figsize=(10, 10))\n    ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n    ax2 = plt.subplot2grid((3, 1), (2, 0))\n    ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n    for clf, name in [(lr, 'Logistic'),(est, name),(isotonic, name + ' + Isotonic'),(sigmoid, name + ' + Sigmoid')]:\n        clf.fit(X_train, y_train)\n        y_pred = clf.predict(X_test)\n        if hasattr(clf, \"predict_proba\"):\n            prob_pos = clf.predict_proba(X_test)[:, 1]\n        else:  # use decision function\n            prob_pos = clf.decision_function(X_test)\n            prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n        clf_score = brier_score_loss(y_test, prob_pos, pos_label=y_train.max())\n        L2_score = log_loss(y_test, prob_pos)\n        print(\"%s:\" % name)\n        print(\"\\tBrier: %.3f\" % (clf_score))\n        print(\"\\tLog Loss: %.3f\" % (L2_score))\n        print(\"\\tAUC: %.3f\" % roc_auc_score(y_test, prob_pos,average='weighted'))\n        print(\"\\tF1: %.3f\\n\" % f1_score(y_test, y_pred,average='weighted'))\n        fraction_of_positives, mean_predicted_value = calibration_curve(y_test, prob_pos, n_bins=10)\n        ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",label=\"%s (%1.3f)\" % (name, clf_score))\n        ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,histtype=\"step\", lw=2)\n    ax1.set_ylabel(\"Fraction of positives\")\n    ax1.set_ylim([-0.05, 1.05])\n    ax1.legend(loc=\"lower right\")\n    ax1.set_title('Calibration plots  (reliability curve)')\n    ax2.set_xlabel(\"Mean predicted value\")\n    ax2.set_ylabel(\"Count\")\n    ax2.legend(loc=\"upper center\", ncol=2)\n    plt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ccbca1c207d56c0ca817f1177afc8f82a3dc4caf","trusted":false},"cell_type":"code","source":"plot_calibration_curve(model_gbm,'LGBM',train_df[x_calls], train_df['TARGET'],\n                       test_df[x_calls], test_df['TARGET'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"875d8c92773388828afa6995eb75ad8ccf1964be"},"cell_type":"markdown","source":"As we can see above, the calibration result using isotonic funstion got the same score with that of sigmoid function in Brier Loss Score. Nevertheless, the loss score of sigmoid function is slighly better than that of Isotonic function. Therefore, we decided to use Sigmoid function to calibrate the score of model to be probability of chossing the positif target."},{"metadata":{"_uuid":"138f99a2419ce9dc0d908bb0b72d6b85fce37367"},"cell_type":"markdown","source":"# Building Fix Model"},{"metadata":{"trusted":false,"_uuid":"4130d2b07edf815675904e533df762e3999eb81f"},"cell_type":"code","source":"model_fix = LGBMClassifier(boosting_type='gbdt', class_weight='balanced',\n        colsample_bytree=1.0, importance_type='split',\n        learning_rate=0.09275695087706179, max_depth=3669,\n        min_child_samples=60, min_child_weight=0.001, min_data=6,\n        min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=64,\n        objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n        silent=True, sub_feature=0.7757070409332384, subsample=1.0,\n        subsample_for_bin=200000, subsample_freq=0)\nmodel_fix.fit(app_train[x_calls],app_train.TARGET)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f955ea9a3aea2f8dfefb523a27c182f35bae91a3"},"cell_type":"markdown","source":"## Feature impotances of fix model"},{"metadata":{"trusted":false,"_uuid":"68484715b9c18a518b66070091df224d9fa60702"},"cell_type":"code","source":"importances = model_fix.feature_importances_\nindices = np.argsort(importances)[::-1]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false,"_uuid":"ac09790330756a44afb45b06f64926f405d7a275"},"cell_type":"code","source":"def variable_importance(importance, indices,x):\n    print(\"Feature ranking:\")\n    importances = []\n    for f in range(len(x)):\n        i = f\n        t=0\n        print(\"%d. The feature '%s' has a Mean Decrease in Gini of %f\" % (f + 1,x[indices[i]],importance[indices[f]]))\n        importances.append([x[indices[i]],importance[indices[f]]])\n    importances = pd.DataFrame(importances,columns=['Features','Gini'])\n    return importances\n\nimportance = variable_importance(importances, indices,x_calls)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"969d01503caf4a0d0e7e6103bc90cf8c5ed9fef2"},"cell_type":"markdown","source":"As we can see above, according to Gini Score the most impotant feature is EXT_SOURCE_3 followed by AMT_CREDIT, EXT_SOURCE_1, AMT_ANNUITY, EXT_SOURCE_2, and so on. However, there are nine features that got zero gini score."},{"metadata":{"_uuid":"89ce8f4606d158248548b426da5868f90e389455"},"cell_type":"markdown","source":"## Calculating the probability of application_test data"},{"metadata":{"_uuid":"20b2c59598c5bd0808b144ee0f5c0f0a229fcc33","trusted":false},"cell_type":"code","source":"model_fix = CalibratedClassifierCV(model_fix, cv='prefit', method='sigmoid')\nmodel_fix.fit(app_train[x_calls],app_train.TARGET)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3361cad7f2344dca928090b73c1c0cfacbfa404c","trusted":false},"cell_type":"code","source":"TARGET = model_fix.predict_proba(app_test[x_calls])[:,1]\nsubmission = pd.DataFrame({'SK_ID_CURR':app_test['SK_ID_CURR'],'TARGET':TARGET})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"116056406045ba1a7d994ad32651dd0b5eed5a83"},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}