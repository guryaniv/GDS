{"cells":[{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"c49ff70c4eefab027dd1783eb9fcf5e1964a5027"},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"9061af49a89f1b5a0da8e31e2e6b9a1d5a69c364"},"cell_type":"markdown","source":"# Introduction to physiological data\n\n\n\nIn this example, we're given three main physiological parameters:\n- Respiration\n- Electrocardiogram (ECG)\n- Electroencephalogram (EEG)\n\nWe'll talk through each of these in turn, some of their limitations, and how to process the data. I'm not going to talk about the galvanic skin response because it's use is, suffice to say, [controversial](https://sciencebasedmedicine.org/galvanic-skin-response-pseudoscience/).\n## A short note on noise sources\nBiological sensors are quite susceptible to noise from outside sources. This can include lights (flickering at 50/60Hz depending on your AC frequency), and other electrical equipment. I think it's reasonable to assume that this experiment was in a chamber with a **tonne** of unshielded electronic high-tech stuff, all leaking noise at various frequencies. Hopefully this would be consistent between recordings, but it does make analysis more challenging, since removing any noise will usually remove a bit of signal too.\n\n## Respiration\nThis is a simple measure of the rise and fall of the chest. It represents muscle activity of the diapragm and abdomen. We know that when someone is physiologically stressed, this rate increases. Could be interesting. \n\nUnfortunately, when we plot this data out, it seems to be largely affected by noise.\n\n"},{"metadata":{"trusted":true,"_uuid":"928b69ea5665639258252959f4f3b79969b039e2"},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndf_train = pd.read_csv('../input/train.csv')\n\n# Just looking at a single trial for now\nsubset = df_train.loc[(df_train['crew'] == 1) & (df_train['experiment'] == 'CA')]\n\nsubset.sort_values(by='time')\n\n\n# Show the plot\nplt.plot(subset['r'][3000:4024])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05abcc1148473e21fe5684bd50676df67429c663"},"cell_type":"markdown","source":"Oh dear, that's definitely not a normal respiration- you're looking at 5 seconds of data, which should show 1 or 2 breaths in a nice sinusoidal pattern. I think there's just too much high frequency noise for this to be useful.\n\nLet's try some filtering to remove the high frequency signals\n"},{"metadata":{"trusted":true,"_uuid":"6a6d8671c012c20c0d7862b6be698b2d50f3bda9"},"cell_type":"code","source":"from scipy import signal\n\nb, a = signal.butter(8,0.05)\n\ny = signal.filtfilt(b, a, subset['r'], padlen=150)\n\nplt.plot(y[3000:4024])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ff08fe81bc2fcc0ce846fb56e6923fa13a19939"},"cell_type":"markdown","source":"That's much better. So we should filter our data to get much more useful insights into it. We can then use clever libraries such as Biosppy to count the respiration rate, which is a more useful metric than the raw waveform."},{"metadata":{"trusted":true,"_uuid":"ee581abb315db5bf91c5f1b11e011d8fbff599bb","_kg_hide-output":true},"cell_type":"code","source":"from biosppy.signals import ecg, resp\n\nout = resp.resp(y,sampling_rate=256, show=False)\n\nplt.plot(out['resp_rate_ts'], out['resp_rate'])\nplt.ylabel('Respiratory frequency [Hz]')\nplt.xlabel('Time [s]');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4bfdde3d2cd33337238e76c9ffc26cd0dafe0e68"},"cell_type":"markdown","source":"## ECG\nThis measures the electrical activity in the heart. This is a single lead ECG, useful for analysing the rhythm and rate. If someone had a heart condition, they'd be more likely to have a 12-lead ECG to look at the structural picture of any change in heart activity.<br>\n\n![The basic structure of the ECG](https://en.wikipedia.org/wiki/Electrocardiography#/media/File:SinusRhythmLabels.svg)\n\nWhat's interesting about the ECG is while it's shape might vary between individuals or recordings (changes in lead position for instance), beat to beat, it's shape doesn't change much at all. The shape of the ECG can 'squash' down slightly as heart rate increases, but the amplitude is fixed, and really the only useful information for this experiment is the heart rate (which intuitively might be valuable as it increases when you're stressed).\nHere's the filtered ECG using the same settings as above"},{"metadata":{"trusted":true,"_uuid":"9bc1cba14e388aed537064176d547bbef198ba38"},"cell_type":"code","source":"b, a = signal.butter(8,0.05)\n\ny = signal.filtfilt(b, a, subset['ecg'], padlen=150)\n\nplt.plot(y[3000:4024])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42b3e0590b4a5852a773eba740ef55f0a2ee4e17"},"cell_type":"markdown","source":"If you want to convert this into heart rate data, we can use the template matching tool in Biosppy to detect the R waves, calculate their intervals, and work out the heart rate across the experiment. You might want to do some filtering on this to smooth out the heart rate, but the moment-to-moment heart rate is useful too.\n"},{"metadata":{"trusted":true,"_uuid":"8ed6835ab18932611ec242ab818a78d5a545014b"},"cell_type":"code","source":"\nout = ecg.ecg(signal=subset['ecg'], sampling_rate=256, show=False)\n\nplt.plot(out['heart_rate_ts'], out['heart_rate'])\nplt.ylabel('Heart Rate (BPM)')\nplt.xlabel('Time [s]');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe74084cb90b938d61b09949ed43996091e38a59"},"cell_type":"markdown","source":"## EEG\nNow this is the interesting bit to me. EEG's role has been greatly overstated over the years, and it's definitely not a panacea of brain activity. Clinically, you can usefully tell if someone is awake, asleep, brain dead, having a seizure, and a handful of other things. \nEEG is a summation of all the electrical activity on the surface of the brain. This activity has to travel through layers of soft tissue, bone and skin, so it's no wonder that the data is quite noisy.\n### Preparing EEG data\nThis data is prepared in a fairly typical arrangement of 20 electrodes across the scalp. The letter in each lead signifies the part of the brain that that lead is nearest to (Temporal, Frontal, Parietal etc), with odd numbers on the left, evens on the right. Usually in the clinic, we don't look at the electrical potentials at each electrode, but at the potential difference between pairs of electrodes. This gives us an idea of the electrical field in the brain region between these two points as a way to infer what the brain is doing in that region. Clearly you can choose any two electrodes and produce 20! different potential differences, but not all of those are going to be useful. <br>\nWe talk about the layout of choosing the pairs of electrodes to compare potential differences as **Montages**. There's lots of different montage systems, but commonly there's the 10-20 system. This data has an additional 'poz' electrode to the diagram, but that doesn't cause us a problem. <br>\n\n![10-20 Montage system](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/f2861bea35e87ac1fe5c053e4cc58911d28d112f/3-Figure1-1.png)\n\nFor this experiment, I chose the middle montage because it's one that's used clinically and I'm familiar with. Perhaps there's better ones for this experiment! <br>\nTo montage the data, you just have to subtract the value of one electrode from another. It doesn't matter which way you do it, as long as it's consistent. I did this from front to back."},{"metadata":{"trusted":true,"_uuid":"caac62cb0a503ae950360e11497c73767d162ccc"},"cell_type":"code","source":"df_train['fp1_f7'] = df_train['eeg_fp1'] - df_train['eeg_f7']\ndf_train['f7_t3'] = df_train['eeg_f7'] - df_train['eeg_t3']\ndf_train['t3_t5'] = df_train['eeg_t3'] - df_train['eeg_t5']\ndf_train['t5_o1'] = df_train['eeg_t5'] - df_train['eeg_o1']\ndf_train['fp1_f3'] = df_train['eeg_fp1'] - df_train['eeg_f7']\ndf_train['f3_c3'] = df_train['eeg_f3'] - df_train['eeg_c3']\ndf_train['c3_p3'] = df_train['eeg_c3'] - df_train['eeg_p3']\ndf_train['p3_o1'] = df_train['eeg_p3'] - df_train['eeg_o1']\n\ndf_train['fz_cz'] = df_train['eeg_fz'] - df_train['eeg_cz']\ndf_train['cz_pz'] = df_train['eeg_cz'] - df_train['eeg_pz']\ndf_train['pz_poz'] = df_train['eeg_pz'] - df_train['eeg_poz']\n\ndf_train['fp2_f8'] = df_train['eeg_fp2'] - df_train['eeg_f8']\ndf_train['f8_t4'] = df_train['eeg_f8'] - df_train['eeg_t4']\ndf_train['t4_t6'] = df_train['eeg_t4'] - df_train['eeg_t6']\ndf_train['t6_o2'] = df_train['eeg_t6'] - df_train['eeg_o2']\ndf_train['fp2_f4'] = df_train['eeg_fp2'] - df_train['eeg_f4']\ndf_train['f4_c4'] = df_train['eeg_f4'] - df_train['eeg_c4']\ndf_train['c4_p4'] = df_train['eeg_c4'] - df_train['eeg_p4']\ndf_train['p4_o2'] = df_train['eeg_p4'] - df_train['eeg_o2']\n\nfeatures_n = ['fp1_f7', 'f7_t3', 't3_t5', 't5_o1', 'fp1_f3', 'f3_c3', 'c3_p3', 'p3_o1', 'fz_cz', 'cz_pz',\n                'pz_poz', 'fp2_f8', 'f8_t4', 't4_t6', 't6_o2', 'fp2_f4', 'f4_c4', 'c4_p4', 'p4_o2', \"ecg\", \"r\", \"gsr\"]\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bfdc6703d6097448aed15df332bdc05c85141c12"},"cell_type":"markdown","source":"### Analysing EEG data\nThe interesting bit of EEG data comes from looking at the firing rate. With certain medical conditions, and in brain states, the neural activity starts to harmonise in pretty cool ways. The firing rate of this activity is measured in Hz, and grouped into bands:\n- Delta (<4Hz) Slow wave sleep, continous attention tasks\n- Theta (4-7Hz) Drowsiness, repression of elicited responses\n- Alpha (8-15Hz) Relaxed, eyes closed\n- Beta (16-31Hz) Active thinking, focus, alert\n- Gamma (>32Hz) Short term memory, cross sensory perception <br>\n\nSo, this looks easy, right? We just find out the firing rate of the EEG, if it's in Alpha or below, then we're happy that the pilot is either finding the task easy, or asleep. If it's Beta or above, then they're having a hard time focussing on their distraction. "},{"metadata":{"trusted":true,"_uuid":"6ca1fe43c38a933c0ee2e4c5cd7d9c197eea7994"},"cell_type":"code","source":"subset = df_train.loc[(df_train['crew'] == 1)]\n\n# Discrete Fourier transform, using a hanning window of 1s\nfreqs, times, Sx = signal.spectrogram(subset['fz_cz'], fs=256, window='hanning', nperseg=256, noverlap=256-100, detrend=False, scaling='spectrum')\nf, ax = plt.subplots(figsize=(12,5))\nax.pcolormesh(times, freqs, 10 * np.log10(Sx), cmap='viridis')\nax.set_ylabel('Frequency [Hz]')\nax.set_xlabel('Time [s]');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b51d1f378ccedb435bb2404092627a58b2444ffc"},"cell_type":"markdown","source":"There's definitely a change in frequency, but it's around 60Hz so it's probably an artefact (someone might have switched the light off), and there's nothing significant to see when you filter this out"},{"metadata":{"trusted":true,"_uuid":"66b78fb70fa07220bc08e6fbac3f09d396aa6d36"},"cell_type":"code","source":"b, a = signal.butter(8,0.2) \ny = signal.filtfilt(b, a, subset['fz_cz'], padlen=150)\nfreqs, times, Sx = signal.spectrogram(y, fs=256, window='hanning', nperseg=256, noverlap=256-100, detrend=False, scaling='spectrum')\nf, ax = plt.subplots(figsize=(12,5))\nax.pcolormesh(times, freqs, 10 * np.log10(Sx), cmap='viridis')\nax.set_ylabel('Frequency [Hz]')\nax.set_xlabel('Time [s]');","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56ba46e33f50a80ad0f6d01e5705396cd061a727"},"cell_type":"markdown","source":"This is the problem, it's a noisy signal, and you can't pick out those rhythms easily. If anyone has any ideas to add to this please add to the discussion below!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}