{"cells":[{"metadata":{"_uuid":"62b090b7913da8a4019515a6540f982f4a7767fa"},"cell_type":"markdown","source":"> **Problem overview**\n\nThis competition is provided as a way to explore different time series techniques on a relatively simple and clean dataset. You are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items at 10 different stores.\n\nWhat's the best way to deal with seasonality? Should stores be modeled separately, or can you pool them together? Does deep learning work better than ARIMA? Can either beat xgboost?"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# import data manipulation library\nimport numpy as np\nimport pandas as pd\n\n# import data visualization library\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# import scientific computing library\nimport statsmodels.api as sm\n\n# import xgboost model class\nimport xgboost as xgb\n\n# import sklearn model selection\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\n\n# import sklearn model evaluation regression metrics\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63bac28c47a40969bd0349adf87b90f669b4330f"},"cell_type":"markdown","source":"> **Acquiring training and testing data**\n\nWe start by acquiring the training and testing datasets into Pandas DataFrames."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# acquiring training and testing data\ndf_train = pd.read_csv('../input/train.csv', parse_dates=['date'], index_col='date')\ndf_test = pd.read_csv('../input/test.csv', parse_dates=['date'], index_col='date')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"773d8c286e14a1e9006e8b6a3807870cf23d4413"},"cell_type":"code","source":"# visualize head of the training data\ndf_train.head(n=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2866ad35c88e0fa0f72e0480a141ff4aa51af4de"},"cell_type":"code","source":"# visualize tail of the testing data\ndf_test.tail(n=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76f1ac478aa137a8885c0362ad9ce423de5a080a"},"cell_type":"code","source":"# combine training and testing dataframe\ndf_train['datatype'], df_test['datatype'] = 'training', 'testing'\ndf_train.insert(0, 'id', 0)\ndf_test.insert(df_test.shape[1] - 1, 'sales', np.nan)\ndf_data = pd.concat([df_train, df_test], ignore_index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f832542c3bb2d027cd91eaace7bce30f3a2af300"},"cell_type":"markdown","source":"> **Feature exploration, engineering and cleansing**\n\nHere we generate descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s distribution together with exploring some data."},{"metadata":{"trusted":true,"_uuid":"89aaa8ec70d6f46e1d6c7248ef444f6432b58f07"},"cell_type":"code","source":"# countplot function plot - categorical variable (x-axis) vs. categorical variable (y-axis)\ndef countplot(x = None, y = None, data = None, ncols = 5, nrows = 3):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    for i, v in enumerate(x): sns.countplot(x=v, hue=y, data=data, ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d8ca8cea11d6d1fcee6d19378d82c7cbdc41c78"},"cell_type":"code","source":"# boxplot function plot - categorical variable (x-axis) vs. numerical variable (y-axis)\ndef boxplot(cat = None, num = None, data = None, ncols = 5, nrows = 3):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    if type(cat) == list:\n        for i, v in enumerate(cat): sns.boxplot(x=v, y=num, data=data, ax=axes[i])\n    else:\n        for i, v in enumerate(num): sns.boxplot(x=cat, y=v, data=data, ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0e1c768d16d94732d7eb295e5d9504003dffb477"},"cell_type":"code","source":"# boxplot function sorted plot - categorical variable (x-axis) vs. numerical variable (y-axis)\ndef boxplotsort(cat = None, num = None, data = None, ncols = 5, nrows = 3, orderby='median'):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    if type(cat) == list:\n        for i, v in enumerate(cat): sns.boxplot(x=v, y=num, data=data, ax=axes[i], order=data.groupby([v], as_index=True).agg({num: orderby}).sort_values(num).index)\n    else:\n        for i, v in enumerate(num): sns.boxplot(x=cat, y=v, data=data, ax=axes[i], order=data.groupby([cat], as_index=True).agg({v: orderby}).sort_values(v).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5e04372879769c3cabe31ca56995258355a3cbc"},"cell_type":"code","source":"# swarmplot function plot - categorical variable (x-axis) vs. numerical variable (y-axis)\ndef swarmplot(cat = None, num = None, data = None, ncols = 5, nrows = 3):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    if type(cat) == list:\n        for i, v in enumerate(cat): sns.swarmplot(x=v, y=num, data=data, ax=axes[i])\n    else:\n        for i, v in enumerate(num): sns.swarmplot(x=cat, y=v, data=data, ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05cc652d289ae9d87787320396434f42f0720558"},"cell_type":"code","source":"# violinplot function plot - categorical variable (x-axis) vs. numerical variable (y-axis)\ndef violinplot(cat = None, num = None, data = None, ncols = 5, nrows = 3):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    if type(cat) == list:\n        for i, v in enumerate(cat): sns.violinplot(x=v, y=num, data=data, ax=axes[i])\n    else:\n        for i, v in enumerate(num): sns.violinplot(x=cat, y=v, data=data, ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9cf7791883d94e62222da8c3b9bfee58dcfaa058"},"cell_type":"code","source":"# violinplot function sorted plot - categorical variable (x-axis) vs. numerical variable (y-axis)\ndef violinplotsort(cat = None, num = None, data = None, ncols = 5, nrows = 3, orderby='median'):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    if type(cat) == list:\n        for i, v in enumerate(cat): sns.violinplot(x=v, y=num, data=data, ax=axes[i], order=data.groupby([v], as_index=True).agg({num: orderby}).sort_values(num).index)\n    else:\n        for i, v in enumerate(num): sns.violinplot(x=cat, y=v, data=data, ax=axes[i], order=data.groupby([cat], as_index=True).agg({v: orderby}).sort_values(v).index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d01b479ebdbacaaab9e930590d4de8cec783dba"},"cell_type":"code","source":"# scatterplot function plot - numerical variable (x-axis) vs. numerical variable (y-axis)\ndef scatterplot(x = None, y = None, data = None, ncols = 5, nrows = 3):\n    fig, axes = plt.subplots(figsize=(4*ncols , 3*nrows), ncols=ncols, nrows=nrows)\n    axes = axes.flatten()\n    for i, xi in enumerate(x): sns.scatterplot(x=xi, y=y, data=data, ax=axes[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"702692507ca048457608d42c2907d4a7d7bd768a"},"cell_type":"code","source":"# describe training and testing data\ndf_data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6dc031c876dd4e1b289cae8c53440a5e4e161b9"},"cell_type":"code","source":"# feature exploration: histogram of all numeric features\n_ = df_data.hist(bins=20, figsize=(10, 6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ac3004a452ce0d36eacc174b97e295637ce4fd0"},"cell_type":"code","source":"# feature exploration: season for store 1 to 10 and item 1\nfor i in range(1, 11):\n    fig, axes = plt.subplots(figsize=(20, 3))\n    _ = df_data.loc[(df_data['store'] == i) & (df_data['item'] == 1) & (df_data['datatype'] == 'training'), 'sales'].plot()\n    axes.set_title('store %d, item %d' %(i, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c2d482b4dd5b12ea0763d22b6d785025e05e366"},"cell_type":"code","source":"# feature exploration: seasonal decompose for store 5 and item 1\nseasonal = sm.tsa.seasonal_decompose(df_data.loc[(df_data['store'] == 5) & (df_data['item'] == 1) & (df_data['datatype'] == 'training'), 'sales']).plot()\nseasonal.set_figwidth(20)\nseasonal.set_figheight(15)\nplt.tight_layout(); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ceed8d87933d733196e175323b1d8babb35e47cd"},"cell_type":"code","source":"# feature extraction: combination of keyword date\ndf_data['date'] = df_data.index\ndf_data['year'] = df_data['date'].dt.year - 2000\ndf_data['quarter'] = df_data['date'].dt.quarter\ndf_data['month'] = df_data['date'].dt.month\ndf_data['weekofyear'] = df_data['date'].dt.weekofyear\ndf_data['dayofweek'] = df_data['date'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b107498a38bdf26add5fd0278125af30c0c0f0f4"},"cell_type":"code","source":"# feature extraction: statistic features for store, item and quarter\ndf_data['item_quarter_mean'] = df_data.groupby(['quarter', 'item'])['sales'].transform('mean')\ndf_data['store_quarter_mean'] = df_data.groupby(['quarter', 'store'])['sales'].transform('mean')\ndf_data['store_item_quarter_mean'] = df_data.groupby(['quarter', 'store', 'item'])['sales'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f37364cd78a25442f69cdeeb6d6d7e5335a685c"},"cell_type":"code","source":"# feature extraction: statistic features for store, item and month\ndf_data['item_month_mean'] = df_data.groupby(['month', 'item'])['sales'].transform('mean')\ndf_data['store_month_mean'] = df_data.groupby(['month', 'store'])['sales'].transform('mean')\ndf_data['store_item_month_mean'] = df_data.groupby(['month', 'store', 'item'])['sales'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9159cb778170c5e38477be64972d3cfed30d57bd"},"cell_type":"code","source":"# feature extraction: statistic features for store, item and weekofyear\ndf_data['item_weekofyear_mean'] = df_data.groupby(['weekofyear', 'item'])['sales'].transform('mean')\ndf_data['store_weekofyear_mean'] = df_data.groupby(['weekofyear', 'store'])['sales'].transform('mean')\ndf_data['store_item_weekofyear_mean'] = df_data.groupby(['weekofyear', 'store', 'item'])['sales'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4fdd7ead2c021f5e88a0cb9dd8c115be1de744a2"},"cell_type":"code","source":"# feature extraction: statistic features for store, item and dayofweek\ndf_data['item_dayofweek_mean'] = df_data.groupby(['dayofweek', 'item'])['sales'].transform('mean')\ndf_data['store_dayofweek_mean'] = df_data.groupby(['dayofweek', 'store'])['sales'].transform('mean')\ndf_data['store_item_dayofweek_mean'] = df_data.groupby(['dayofweek', 'store', 'item'])['sales'].transform('mean')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"362b6c3ad66b4e1c49790e1ce8516fed3c39cb07"},"cell_type":"code","source":"# feature extraction: shifted features for store, item and weekofyear shift 90 days\ndf_data['store_item_shift90'] = df_data.groupby(['store', 'item'])['sales'].transform(lambda x: x.shift(90))\ndf_data['item_weekofyear_shift90_mean'] = df_data.groupby(['weekofyear', 'item'])['sales'].transform(lambda x: x.shift(13).mean())\ndf_data['store_weekofyear_shift90_mean'] = df_data.groupby(['weekofyear', 'store'])['sales'].transform(lambda x: x.shift(13).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12baa4cf16e2ad07619448d960c2c95a89d577ad"},"cell_type":"code","source":"# feature extraction: shifted features for store, item and weekofyear shift 180 days\ndf_data['store_item_shift180'] = df_data.groupby(['store', 'item'])['sales'].transform(lambda x: x.shift(180))\ndf_data['item_weekofyear_shift180_mean'] = df_data.groupby(['weekofyear', 'item'])['sales'].transform(lambda x: x.shift(26).mean())\ndf_data['store_weekofyear_shift180_mean'] = df_data.groupby(['weekofyear', 'store'])['sales'].transform(lambda x: x.shift(26).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6814b22bf65afd9bc62c6e32020871afc9b731a"},"cell_type":"code","source":"# feature extraction: shifted features for store, item and weekofyear shift 270 days\ndf_data['store_item_shift270'] = df_data.groupby(['store', 'item'])['sales'].transform(lambda x: x.shift(270))\ndf_data['item_weekofyear_shift270_mean'] = df_data.groupby(['weekofyear', 'item'])['sales'].transform(lambda x: x.shift(39).mean())\ndf_data['store_weekofyear_shift270_mean'] = df_data.groupby(['weekofyear', 'store'])['sales'].transform(lambda x: x.shift(39).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d41eabfa3daef144a10312025e3b51351cdd369a"},"cell_type":"code","source":"# feature extraction: shifted features for store, item and weekofyear shift 365 days\ndf_data['store_item_shift365'] = df_data.groupby(['store', 'item'])['sales'].transform(lambda x: x.shift(365))\ndf_data['item_weekofyear_shift365_mean'] = df_data.groupby(['weekofyear', 'item'])['sales'].transform(lambda x: x.shift(52).mean())\ndf_data['store_weekofyear_shift365_mean'] = df_data.groupby(['weekofyear', 'store'])['sales'].transform(lambda x: x.shift(52).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"190e964f68f06e534eb05a7335ac5684cd4997a7"},"cell_type":"code","source":"# feature extraction: fillna with 0\ncol_fillnas = ['store_item_shift90', 'store_item_shift180', 'store_item_shift270', 'store_item_shift365']\ndf_data[col_fillnas] = df_data[col_fillnas].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bcf64b2d8cbccc45c41e8a21d4230540bb3c3b73"},"cell_type":"code","source":"# feature exploration: sales\ncol_number = df_data.select_dtypes(include=['number']).columns.drop(['id']).tolist()\nscatterplot(x=col_number, y='sales', data=df_data[df_data['datatype'] == 'training'], nrows=(len(col_number) - 1) // 5 + 1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4fe322218aa7f731f098e0482b1906889251a7f2"},"cell_type":"markdown","source":"After extracting all features, it is required to convert category features to numerics features, a format suitable to feed into our Machine Learning models."},{"metadata":{"trusted":true,"_uuid":"63997c9843f1354c847cf0962e21243063d61199"},"cell_type":"code","source":"# feature extraction: fillna with 0\ndf_data['sales'] = df_data['sales'].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"47df38b60694ae64879a3c5c96d3b67d3a16f093"},"cell_type":"code","source":"# convert category codes for data dataframe\ndf_data = pd.get_dummies(df_data, columns=None, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb926e480c9c8a23c4459b24a570768412e891cd"},"cell_type":"code","source":"# describe data dataframe\ndf_data.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e12e08c58bc85345d595c3c7010db14c79a9b8e"},"cell_type":"code","source":"# verify dtypes object\ndf_data.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89507ef7f98ffafeef409a70c09fb83403ac44ef"},"cell_type":"markdown","source":"> **Analyze and identify patterns by visualizations**\n\nLet us generate some correlation plots of the features to see how related one feature is to the next. To do so, we will utilize the Seaborn plotting package which allows us to plot very conveniently as follows.\n\nThe Pearson Correlation plot can tell us the correlation between features with one another. If there is no strongly correlated between features, this means that there isn't much redundant or superfluous data in our training data. This plot is also useful to determine which features are correlated to the observed value.\n\nThe pairplots is also useful to observe the distribution of the training data from one feature to the other.\n\nThe pivot table is also another useful method to observe the impact between features."},{"metadata":{"trusted":true,"_uuid":"e4feaef459f7f7e1080c5fa5a870dceafa5bfc4e"},"cell_type":"code","source":"# compute pairwise correlation of columns, excluding NA/null values and present through heat map\ncorr = df_data[df_data['datatype_training'] == 1].corr()\nfig, axes = plt.subplots(figsize=(200, 150))\nheatmap = sns.heatmap(corr, annot=True, cmap=plt.cm.RdBu, fmt='.1f', square=True, vmin=-0.8, vmax=0.8)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0300de3ea2f28837077f0e0f5cfa63d9fd35a9dc"},"cell_type":"markdown","source":"> **Model, predict and solve the problem**\n\nNow, it is time to feed the features to Machine Learning models."},{"metadata":{"trusted":true,"_uuid":"501ed92756857513bdfb597d1f9248ca38226662"},"cell_type":"code","source":"# symmetric mean absolute percentage error (mape) function\ndef symmetric_mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    condition = (y_true > 0) & (y_pred > 0)\n    return np.mean(2 * np.abs((y_pred[condition] - y_true[condition])) / (np.abs(y_pred[condition]) + np.abs(y_true[condition]))) * 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4922349da8ab5ce24173b3d9eb22a77e12044bd"},"cell_type":"code","source":"# symmetric mean absolute percentage error (mape) scoring function\ndef symmetric_mean_absolute_percentage_error_scoring(model, x, y):\n    y_pred = model.predict(x)\n    return symmetric_mean_absolute_percentage_error(y, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"09e35909d1fcf10fc429d663ff9d96c70c4b88eb"},"cell_type":"code","source":"# select all features\nx = df_data[df_data['datatype_training'] == 1].drop(['id', 'sales', 'date', 'datatype_training'], axis=1)\ny = df_data.loc[df_data['datatype_training'] == 1]['sales']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"752b56e9aae1b300f14ea42b7658460d68c67de9"},"cell_type":"code","source":"# perform train-test (validate) split\nx_train, x_validate, y_train, y_validate = train_test_split(x, y, random_state=58, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da1e55ae5883cb9c149861ae690778dcce6cbc15"},"cell_type":"code","source":"# xgboost regression model setup\nmodel_xgbreg = xgb.XGBRegressor(booster='gbtree', learning_rate=0.1, n_estimators=1000, objective='reg:linear', random_state=58,\n                                colsample_bytree=0.9, max_depth=5, reg_alpha=0.1, reg_lambda=0.9, subsample=0.9)\n\n# xgboost regression model fit\nmodel_xgbreg.fit(x_train, y_train, early_stopping_rounds=50, eval_set=[(x_validate, y_validate)], verbose=False,\n                 callbacks=[xgb.callback.print_evaluation(period=50)])\n\n# xgboost regression model prediction\nmodel_xgbreg_ypredict = model_xgbreg.predict(x_validate)\n\n# xgboost regression model metrics\nmodel_xgbreg_mape = symmetric_mean_absolute_percentage_error(y_validate, model_xgbreg_ypredict)\nprint('xgboost regression\\n  symmetric mean absolute percentaged error: %0.4f' %model_xgbreg_mape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2bc8e7bd6741eb6ea5b98d1fc28d4006595e156"},"cell_type":"markdown","source":"> **Supply or submit the results**\n\nOur submission to the competition site Kaggle is ready. Any suggestions to improve our score are welcome."},{"metadata":{"trusted":true,"_uuid":"8300d72f6cf2e78f7ad5f47d92aad01ce249768d"},"cell_type":"code","source":"# model selection\nfinal_model = model_xgbreg\n\n# prepare testing data and compute the observed value\nx_test = df_data[df_data['datatype_training'] == 0].drop(['id', 'sales', 'date', 'datatype_training'], axis=1)\ny_test = pd.DataFrame(final_model.predict(x_test),\n                      columns=['sales'], index=df_data.loc[df_data['datatype_training'] == 0, 'id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9d094747e8b8528ee5bbc5ab242fedb2f3d0c890"},"cell_type":"code","source":"# summit the results\nout = pd.DataFrame({'id': y_test.index, 'sales': y_test['sales']})\nout.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a305bf88068b7b0924ba236dc99bcca1f644bdbc"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}