{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "_cell_guid": "cf50773c-6b91-8e6a-f5f9-7f03d2be4508",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef warn(*args, **kwargs): pass\nimport warnings\nwarnings.warn = warn\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import StratifiedShuffleSplit\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "_cell_guid": "a78e7350-b022-6f0c-d39e-9f4e0c9d469f",
        "_active": false
      },
      "outputs": [],
      "source": "df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\ndf_test.head()",
      "execution_state": "idle"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "_cell_guid": "ab17775d-dbef-c8de-4228-83438154ee2f",
        "_active": false,
        "collapsed": false
      },
      "outputs": [],
      "source": "def encode(train, test):\n    le = LabelEncoder().fit(train.species)\n    labels = le.transform(train.species)\n    classes = list(le.classes_)\n    test_ids = test.id\n    \n    train_features = train.drop(['species', 'id'], axis = 1)\n    train_target = train.species\n    test_features = test.drop(['id'], axis = 1)\n    \n    return train_features, train_target, labels, test_features, \\\n              test_ids, classes\n    \ntrain_features, train_target, labels, test_features, \\\n        test_ids, classes = encode(df_train, df_test)",
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "f0d407fb-4426-27c4-1019-34a6957b01f5",
        "_active": false,
        "collapsed": false
      },
      "source": "sss = StratifiedShuffleSplit(labels, 10, test_size=0.2, random_state=23)\n\nfor train_index, cross_index in sss:\n    train_training_data, train_cross_data = train_features.values[train_index], train_features.values[cross_index]\n    train_training_target, train_cross_target = labels[train_index], labels[cross_index]\n",
      "execution_count": 34,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    },
    {
      "metadata": {
        "_cell_guid": "ac1a740a-8fb5-4ce7-9069-46b1a11a32f7",
        "_active": true,
        "collapsed": false
      },
      "source": "from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n\nclassifiers = [\n    KNeighborsClassifier(5),\n    SVC(kernel=\"rbf\", probability = True),\n    LinearSVC(kernel=\"linear\", probability = True),\n    NuSVC(probability = True),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier(),\n    GaussianNB(),\n    LinearDiscriminantAnalysis(),\n    QuadraticDiscriminantAnalysis()]\n\nAnalysis_cols = [\"Classifier\", \"Accuracy\", \"Log loss\"]\nanalysis = pd.DataFrame(columns = Analysis_cols)\n\nfor clf in classifiers:\n    clf.fit(train_training_data, train_training_target)\n    name = clf.__class__.__name__\n    \n    print(\"=\"*30)\n    print(name)\n    \n    print('***Results***')\n    train_prediction = clf.predict(train_cross_data)\n    acc = accuracy_score(train_cross_target, train_prediction)\n    print(\"Accuracy: {:.4%}\".format(acc))\n    \n    train_prediction = clf.predict_proba(train_cross_data)\n    ll = log_loss(train_cross_target, train_prediction)\n    print(\"Log Loss: {}\".format(ll))\n    \n    analysis = pd.DataFrame([[name, acc*100, ll]], columns = Analysis_cols)\n    \nprint('='*30)",
      "execution_count": 36,
      "cell_type": "code",
      "outputs": [],
      "execution_state": "idle"
    }
  ]
}